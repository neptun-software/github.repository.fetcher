{
  "metadata": {
    "timestamp": 1736565276204,
    "page": 87,
    "hasNextPage": true,
    "endCursor": "Y3Vyc29yOjkw",
    "completionStatus": "IN_PROGRESS"
  },
  "repositories": [
    {
      "nameWithOwner": "mindspore-ai/mindspore",
      "stars": 4362,
      "defaultBranch": "master",
      "files": [
        {
          "name": ".clang-format",
          "type": "blob",
          "size": 3.9423828125,
          "content": "---\nLanguage:        Cpp\n# BasedOnStyle:  Google\nAccessModifierOffset: -1\nAlignAfterOpenBracket: Align\nAlignConsecutiveAssignments: false\nAlignConsecutiveDeclarations: false\nAlignEscapedNewlines: Left\nAlignOperands:   true\nAlignTrailingComments: true\nAllowAllParametersOfDeclarationOnNextLine: true\nAllowShortBlocksOnASingleLine: false\nAllowShortCaseLabelsOnASingleLine: false\nAllowShortFunctionsOnASingleLine: All\nAllowShortIfStatementsOnASingleLine: true\nAllowShortLoopsOnASingleLine: true\nAlwaysBreakAfterDefinitionReturnType: None\nAlwaysBreakAfterReturnType: None\nAlwaysBreakBeforeMultilineStrings: true\nAlwaysBreakTemplateDeclarations: Yes\nBinPackArguments: true\nBinPackParameters: true\nBraceWrapping:\n  AfterClass:      false\n  AfterControlStatement: false\n  AfterEnum:       false\n  AfterFunction:   false\n  AfterNamespace:  false\n  AfterObjCDeclaration: false\n  AfterStruct:     false\n  AfterUnion:      false\n  AfterExternBlock: false\n  BeforeCatch:     false\n  BeforeElse:      false\n  IndentBraces:    false\n  SplitEmptyFunction: true\n  SplitEmptyRecord: true\n  SplitEmptyNamespace: true\nBreakBeforeBinaryOperators: None\nBreakBeforeBraces: Attach\nBreakBeforeInheritanceComma: false\nBreakInheritanceList: BeforeColon\nBreakBeforeTernaryOperators: true\nBreakConstructorInitializersBeforeComma: false\nBreakConstructorInitializers: BeforeColon\nBreakAfterJavaFieldAnnotations: false\nBreakStringLiterals: true\nColumnLimit:     120\nCommentPragmas:  '^ IWYU pragma:'\nCompactNamespaces: false\nConstructorInitializerAllOnOneLineOrOnePerLine: true\nConstructorInitializerIndentWidth: 4\nContinuationIndentWidth: 2\nCpp11BracedListStyle: true\nDerivePointerAlignment: false\nDisableFormat:   false\nExperimentalAutoDetectBinPacking: false\nFixNamespaceComments: true\nForEachMacros:\n#  - foreach\n  - Q_FOREACH\n  - BOOST_FOREACH\nIncludeBlocks:   Preserve\nIncludeCategories:\n  - Regex:           '^<ext/.*\\.h>'\n    Priority:        2\n  - Regex:           '^<.*\\.h>'\n    Priority:        1\n  - Regex:           '^<.*'\n    Priority:        2\n  - Regex:           '.*'\n    Priority:        3\nIncludeIsMainRegex: '([-_](test|unittest))?$'\nIndentCaseLabels: true\nIndentPPDirectives: None\nIndentWidth:     2\nIndentWrappedFunctionNames: false\nJavaScriptQuotes: Leave\nJavaScriptWrapImports: true\nKeepEmptyLinesAtTheStartOfBlocks: false\nMacroBlockBegin: ''\nMacroBlockEnd:   ''\nMaxEmptyLinesToKeep: 1\nNamespaceIndentation: None\nObjCBinPackProtocolList: Never\nObjCBlockIndentWidth: 2\nObjCSpaceAfterProperty: false\nObjCSpaceBeforeProtocolList: true\nPenaltyBreakAssignment: 2\nPenaltyBreakBeforeFirstCallParameter: 1\nPenaltyBreakComment: 300\nPenaltyBreakFirstLessLess: 120\nPenaltyBreakString: 1000\nPenaltyBreakTemplateDeclaration: 10\nPenaltyExcessCharacter: 1000000\nPenaltyReturnTypeOnItsOwnLine: 200\nPointerAlignment: Right\nRawStringFormats:\n  - Language:        Cpp\n    Delimiters:\n      - cc\n      - CC\n      - cpp\n      - Cpp\n      - CPP\n      - 'c++'\n      - 'C++'\n    CanonicalDelimiter: ''\n    BasedOnStyle:    google\n  - Language:        TextProto\n    Delimiters:\n      - pb\n      - PB\n      - proto\n      - PROTO\n    EnclosingFunctions:\n      - EqualsProto\n      - EquivToProto\n      - PARSE_PARTIAL_TEXT_PROTO\n      - PARSE_TEST_PROTO\n      - PARSE_TEXT_PROTO\n      - ParseTextOrDie\n      - ParseTextProtoOrDie\n    CanonicalDelimiter: ''\n    BasedOnStyle:    google\nReflowComments:  true\nSortUsingDeclarations: true\nSpaceAfterCStyleCast: false\nSpaceAfterTemplateKeyword: true\nSpaceBeforeAssignmentOperators: true\nSpaceBeforeCpp11BracedList: false\nSpaceBeforeCtorInitializerColon: true\nSpaceBeforeInheritanceColon: true\nSpaceBeforeParens: ControlStatements\nSpaceBeforeRangeBasedForLoopColon: true\nSpaceInEmptyParentheses: false\nSpacesBeforeTrailingComments: 2\nSpacesInAngles:  false\nSpacesInContainerLiterals: true\nSpacesInCStyleCastParentheses: false\nSpacesInParentheses: false\nSpacesInSquareBrackets: false\nStandard:        Auto\nStatementMacros:\n  - Q_UNUSED\n  - QT_REQUIRE_VERSION\nTabWidth:        2\nUseTab:          Never\nSortIncludes:    false\n...\n\n"
        },
        {
          "name": ".gitattributes",
          "type": "blob",
          "size": 0.47265625,
          "content": "mindspore/ccsrc/plugin/device/ascend/kernel/dvm/prebuild/aarch64/libdvm.a filter=lfs diff=lfs merge=lfs -text\nmindspore/ccsrc/plugin/device/ascend/kernel/dvm/prebuild/x86_64/libdvm.a filter=lfs diff=lfs merge=lfs -text\nmindspore/ccsrc/plugin/device/ascend/kernel/internal/prebuild/x86_64/ms_kernels_internal.tar.gz filter=lfs diff=lfs merge=lfs -text\nmindspore/ccsrc/plugin/device/ascend/kernel/internal/prebuild/aarch64/ms_kernels_internal.tar.gz filter=lfs diff=lfs merge=lfs -text\n"
        },
        {
          "name": ".gitee",
          "type": "tree",
          "content": null
        },
        {
          "name": ".github",
          "type": "tree",
          "content": null
        },
        {
          "name": ".gitignore",
          "type": "blob",
          "size": 3.5751953125,
          "content": "# MindSpore\nbuild/\nmindspore/lib\noutput\n*.ir\n*.patch\nst_tests\nkernel_meta/\nsomas_meta/\ntrace_code_graph_*\nms_kernels_internal/\n\n# mindspore lite java\nmindspore/lite/java/.gradle/\nmindspore/lite/java/gradle\nmindspore/lite/java/gradlew\nmindspore/lite/java/gradlew.bat\nmindspore/lite/java/java/.gradle\nmindspore/lite/java/java/build\nmindspore/lite/java/java/gradle\nmindspore/lite/java/java/gradlew\nmindspore/lite/java/java/gradlew.bat\nmindspore/lite/java/java/app/build\nmindspore/lite/java/java/app/libs\n\n# flatbuffer\nmindspore/lite/tools/converter/parser/tflite/schema_generated.h\nmindspore/lite/tools/converter/parser/caffe/caffe.pb.cc\nmindspore/lite/tools/converter/parser/caffe/caffe.pb.h\nmindspore/lite/tools/converter/parser/onnx/onnx.pb.h\nmindspore/lite/tools/converter/parser/onnx/onnx.pb.h\nmindspore/lite/tools/converter/schema/*.h\nmindspore/lite/tools/converter/schema/inner\nmindspore/lite/schema/*.h\nmindspore/lite/schema/inner\n\nmindspore/lite/src/litert/kernel/opencl/cl/fp16/*.inc\nmindspore/lite/src/litert/kernel/opencl/cl/fp32/*.inc\n\n# Cmake files\nCMakeFiles/\ncmake_install.cmake\nCMakeCache.txt\nMakefile\ncmake-build-debug\n\n# Dynamic libraries\n*.so\n*.so.*\n*.dylib\n\n# Static libraries\n*.la\n*.lai\n*.a\n*.lib\n\n# Protocol buffers\n*_pb2.py\n*.pb.h\n*.pb.cc\n*.pb\n*_grpc.py\n\n# Object files\n*.o\n\n# Editor\n.vscode\n.idea/\n\n# Cquery\n.cquery_cached_index/\ncompile_commands.json\n\n# Ctags and cscope\ntags\nTAGS\nCTAGS\nGTAGS\nGRTAGS\nGSYMS\nGPATH\ncscope.*\n\n# Python files\n*__pycache__*\n.pytest_cache\n\n# Mac files\n*.DS_Store\n\n# Test results\ntest_temp_summary_event_file/\n*.dot\n*.dat\n*.svg\n*.perf\n*.info\n*.ckpt\n*.shp\n*.pkl\n*.pb\n.clangd\nmindspore/python/mindspore/version.py\nmindspore/python/mindspore/default_config.py\nmindspore/python/mindspore/device_target.py\nmindspore/python/mindspore/package_name.py\nmindspore/python/mindspore/.commit_id\nmindspore/python/mindspore/lib\n\n# lite test file\nmindspore/lite/test/do_test/\n\n# lite opencl compile file\n*.cl.inc\n\n# auto gen code files\nmindspore/core/ops/auto_generate/gen_lite_ops.h\nmindspore/core/ops/auto_generate/gen_lite_ops.cc\nmindspore/core/ops/auto_generate/gen_ops_name.h\nmindspore/core/ops/auto_generate/gen_ops_primitive.h\nmindspore/core/ops/auto_generate/gen_ops_def.cc\nmindspore/core/ops/auto_generate/gen_ops_def.h\nmindspore/python/mindspore/ops_generate/ops.yaml\nmindspore/python/mindspore/ops_generate/ops_doc.yaml\nmindspore/python/mindspore/ops_generate/inner_ops.yaml\nmindspore/python/mindspore/ops_generate/inner_ops_doc.yaml\nmindspore/python/mindspore/ops/auto_generate/cpp_create_prim_instance_helper.py\nmindspore/python/mindspore/ops/auto_generate/gen_arg_handler.py\nmindspore/python/mindspore/ops/auto_generate/gen_arg_dtype_cast.py\nmindspore/python/mindspore/ops/auto_generate/gen_ops_def.py\nmindspore/python/mindspore/ops/auto_generate/gen_pyboost_func.py\nmindspore/python/mindspore/ops/auto_generate/pyboost_inner_prim.py\nmindspore/python/mindspore/ops/auto_generate/gen_inner_ops_def.py\nmindspore/python/mindspore/ops/auto_generate/gen_extend_func.py\nmindspore/python/mindspore/ops/auto_generate/gen_ops_prim.py\nmindspore/ccsrc/pipeline/pynative/op_function/auto_generate/\nmindspore/ccsrc/runtime/pynative/op_function/auto_generate/\nmindspore/ccsrc/kernel/pyboost/auto_generate/\nmindspore/ccsrc/plugin/device/cpu/kernel/pyboost/auto_generate/\nmindspore/ccsrc/plugin/device/gpu/kernel/pyboost/auto_generate/\nmindspore/ccsrc/plugin/device/ascend/kernel/pyboost/auto_generate/\nmindspore/ccsrc/plugin/device/ascend/kernel/opapi/aclnn_kernel_register_auto.cc\nmindspore/ccsrc/plugin/device/ascend/kernel/opapi/aclnn_auto_gen/\n\n# ascendc compile\nmindspore/ccsrc/plugin/device/ascend/kernel/ascendc/build_out/\n"
        },
        {
          "name": ".gitmodules",
          "type": "blob",
          "size": 0.9404296875,
          "content": "[submodule \"akg\"]\n\tpath = akg\n\turl = https://gitee.com/mindspore/akg.git\n[submodule \"graphengine\"]\n\tpath = graphengine\n\turl = https://gitee.com/mindspore/graphengine.git\n[submodule \"tests/models\"]\n\tpath = tests/models\n\turl = https://gitee.com/mindspore/models.git\n[submodule \"mindspore/lite/src/litert/kernel/cpu/bolt/bolt\"]\n\tpath = mindspore/lite/src/litert/kernel/cpu/bolt/bolt\n\turl = https://gitee.com/mindspore/bolt.git\n[submodule \"tests/st/networks/mindcv\"]\n\tpath = tests/st/networks/mindcv\n\turl = https://gitee.com/mindspore-lab/mindcv.git\n[submodule \"tests/st/networks/mindocr\"]\n\tpath = tests/st/networks/mindocr\n\turl = https://gitee.com/mindspore-lab/mindocr.git\n\tbranch = overfit\n[submodule \"tests/st/networks/mindone\"]\n\tpath = tests/st/networks/mindone\n\turl = https://gitee.com/mindspore-lab/mindone.git\n\tbranch = ms2.3\n[submodule \"tests/st/networks/mindformers\"]\n\tpath = tests/st/networks/mindformers\n\turl = https://gitee.com/mindspore/mindformers.git\n"
        },
        {
          "name": ".jenkins",
          "type": "tree",
          "content": null
        },
        {
          "name": "CMakeLists.txt",
          "type": "blob",
          "size": 6.3876953125,
          "content": "cmake_minimum_required(VERSION 3.14.0)\nproject(MindSpore)\n\nif(CMAKE_CXX_COMPILER_ID STREQUAL \"GNU\")\n    if(CMAKE_CXX_COMPILER_VERSION VERSION_LESS 7.3.0)\n        message(FATAL_ERROR \"GCC version must be 7.3.0 and above, but found ${CMAKE_CXX_COMPILER_VERSION}\")\n    elseif(CMAKE_CXX_COMPILER_VERSION VERSION_GREATER 11.3.0)\n        message(WARNING \"GCC version ${CMAKE_CXX_COMPILER_VERSION} is greater than 11.3.0, may cause unknown problems.\")\n    endif()\nendif()\n\ninclude(${CMAKE_SOURCE_DIR}/cmake/options.cmake)\ninclude(${CMAKE_SOURCE_DIR}/cmake/check_requirements.cmake)\ninclude(${CMAKE_SOURCE_DIR}/cmake/ascend_variables.cmake)\n\n#generate code\nif(DEFINED ENV{ENABLE_GEN_CODE})\n    set(ENABLE_GEN_CODE $ENV{ENABLE_GEN_CODE})\nendif()\nset(ENABLE_GEN_CODE on)\nset(CMAKE_CXX_FLAGS \"${CMAKE_CXX_FLAGS} -DENABLE_GEN_CODE\")\n\nset(CMAKE_MODULE_PATH ${CMAKE_MODULE_PATH} \"${CMAKE_SOURCE_DIR}/cmake/modules/\")\nif(CMAKE_SYSTEM_NAME MATCHES \"Linux\")\n    if(NOT ENABLE_GLIBCXX)\n        add_compile_definitions(_GLIBCXX_USE_CXX11_ABI=0)\n    endif()\nendif()\n\nif(${CMAKE_SYSTEM_NAME} MATCHES \"Darwin\")\n    set(MACOSX_CXX_WARNING_FLAGS \"-Wno-inconsistent-missing-override \\\n        -Wno-unused-lambda-capture -Wno-unneeded-internal-declaration -Wno-unused-variable \\\n        -Wno-return-std-move\")\n    if(\"${CMAKE_CXX_COMPILER_ID}\" MATCHES \"Clang\" AND CMAKE_CXX_COMPILER_VERSION VERSION_GREATER 13.1)\n        set(MACOSX_CXX_WARNING_FLAGS \"${MACOSX_CXX_WARNING_FLAGS} -Wno-unused-but-set-variable\")\n    endif()\n    set(CMAKE_CXX_FLAGS_RELEASE\n        \"$ENV{CXXFLAGS} -O2 ${MACOSX_CXX_WARNING_FLAGS} -DHALF_ENABLE_CPP11_USER_LITERALS=0 -D_FORTIFY_SOURCE=2\")\nelseif(ENABLE_SYM_FILE)\n    set(CMAKE_CXX_FLAGS_RELEASE \"$ENV{CXXFLAGS} -O2 -g -ggdb -Wl,--build-id=uuid -Wl,--allow-shlib-undefined \\\n        -DHALF_ENABLE_CPP11_USER_LITERALS=0 -D_FORTIFY_SOURCE=2\")\nelse()\n    if(NOT MSVC)\n    set(CMAKE_CXX_FLAGS_RELEASE \"$ENV{CXXFLAGS} -O2 -Wl,--allow-shlib-undefined -s \\\n        -DHALF_ENABLE_CPP11_USER_LITERALS=0 -D_FORTIFY_SOURCE=2\")\n    endif()\nendif()\n\nif(ENABLE_PYTHON)\n    add_compile_definitions(ENABLE_PYTHON)\n    add_compile_definitions(ENABLE_MINDDATA_PYTHON)\nendif()\n\nif(${CMAKE_SYSTEM_NAME} MATCHES \"Darwin\")\n    set(CMAKE_CXX_FLAGS_DEBUG \"$ENV{CXXFLAGS} -O0 -g2 -ggdb -fno-inline-functions -fno-omit-frame-pointer \\\n        -D_LIBCPP_INLINE_VISIBILITY='' -D_LIBCPP_DISABLE_EXTERN_TEMPLATE=1 -DHALF_ENABLE_CPP11_USER_LITERALS=0 \\\n        -D_FORTIFY_SOURCE=2 -Wno-cpp ${MACOSX_CXX_WARNING_FLAGS}\")\nelse()\n    if(NOT MSVC)\n    set(CMAKE_CXX_FLAGS_DEBUG \"$ENV{CXXFLAGS} -O0 -g2 -ggdb -fno-inline-functions -fno-omit-frame-pointer \\\n        -Wl,--allow-shlib-undefined -D_LIBCPP_INLINE_VISIBILITY='' -D_LIBCPP_DISABLE_EXTERN_TEMPLATE=1 \\\n        -DHALF_ENABLE_CPP11_USER_LITERALS=0 -D_FORTIFY_SOURCE=2 -Wno-cpp\")\n    endif()\nendif()\n\nif(NOT MSVC)\nset(CMAKE_CXX_FLAGS \"${CMAKE_CXX_FLAGS} -I/usr/local/include -std=c++17 \\\n    -Werror -Wall -Wno-deprecated-declarations -fPIC\")\nelse()\nset(CMAKE_CXX_FLAGS \"${CMAKE_CXX_FLAGS} /std:c++17\")\nendif()\nset(CMAKE_EXPORT_COMPILE_COMMANDS ON)\n\nset(PYBIND11_CPP_STANDARD -std=c++17)\nset(CMAKE_CXX_FLAGS \"${CMAKE_CXX_FLAGS} ${OPTION_CXX_FLAGS}\")\n\nif(ENABLE_AKG AND CMAKE_SYSTEM_NAME MATCHES \"Linux\")\n    add_subdirectory(\"${CMAKE_SOURCE_DIR}/akg\")\nendif()\n\ninclude(${CMAKE_SOURCE_DIR}/cmake/mind_expression.cmake)\ninclude_directories(${CMAKE_CURRENT_SOURCE_DIR})\ninclude_directories(${CMAKE_CURRENT_SOURCE_DIR}/third_party/securec/include)\ninclude_directories(${CMAKE_CURRENT_SOURCE_DIR}/third_party/flatbuffers/include)\ninclude_directories(${CMAKE_CURRENT_SOURCE_DIR}/third_party/flatbuffers/include/flatbuffers)\n\nif(MSVC AND NOT ENABLE_GPU)\n    find_program(CCACHE_EXE ccache)\n    if(CCACHE_EXE)\n        message(STATUS \"using ccache to speed windows compilation.\")\n        file(COPY ${CCACHE_EXE} DESTINATION ${CMAKE_BINARY_DIR}/cl.exe)\n        set(CMAKE_VS_GLOBALS\n            \"CLToolExe=cl.exe\"\n            \"CLToolPath=${CMAKE_BINARY_DIR}\"\n            \"TrackFileAccess=false\"\n            \"UseMultiToolTask=true\"\n            \"DebugInformationFormat=OldStyle\"\n        )\n    endif()\nendif()\n\nif(ENABLE_FAST_HASH_TABLE)\nset(CMAKE_CXX_FLAGS \"${CMAKE_CXX_FLAGS} -DENABLE_FAST_HASH_TABLE=1\")\ninclude_directories(${CMAKE_CURRENT_SOURCE_DIR}/third_party/robin_hood/include)\nendif()\n\ninclude(${CMAKE_SOURCE_DIR}/cmake/dependency_utils.cmake)\nfind_package(Python3 COMPONENTS Interpreter Development)\nif(Python3_FOUND)\n    set(PYTHON_INCLUDE_DIRS \"${Python3_INCLUDE_DIRS}\")\n    set(PYTHON_LIBRARIES \"${Python3_LIBRARIES}\")\n    if(WIN32)\n        if(Python3_DIR)\n            message(\"Python3_DIR set already: \" ${Python3_DIR})\n        else()\n            string(LENGTH ${PYTHON_LIBRARIES} PYTHON_LIBRARIES_LEN)\n            string(LENGTH \"libpythonxx.a\" Python3_NAME_LEN)\n            math(EXPR Python3_DIR_LEN  ${PYTHON_LIBRARIES_LEN}-${Python3_NAME_LEN})\n            string(SUBSTRING ${Python3_LIBRARIES} 0 ${Python3_DIR_LEN} Python3_DIR)\n            message(\"Python3_DIR: \" ${Python3_DIR})\n        endif()\n        link_directories(${Python3_DIR})\n    endif()\nelse()\n    find_python_package(py_inc py_lib)\n    set(PYTHON_INCLUDE_DIRS \"${py_inc}\")\n    set(PYTHON_LIBRARIES \"${py_lib}\")\nendif()\nmessage(\"PYTHON_INCLUDE_DIRS = ${PYTHON_INCLUDE_DIRS}\")\nmessage(\"PYTHON_LIBRARIES = ${PYTHON_LIBRARIES}\")\ninclude_directories(${PYTHON_INCLUDE_DIRS})\n\ninclude(${CMAKE_SOURCE_DIR}/cmake/utils.cmake)\nfind_and_use_mold()\n\nset(MS_CCSRC_PATH ${CMAKE_SOURCE_DIR}/mindspore/ccsrc)\nset(MS_CCSRC_BUILD_PATH ${BUILD_PATH}/mindspore/mindspore/ccsrc)\n\nif(NOT MSVC)\nset(CMAKE_CXX_FLAGS \"${CMAKE_CXX_FLAGS} -fvisibility=hidden\")\nendif()\n\ninclude(${CMAKE_SOURCE_DIR}/cmake/init.cmake)\nadd_subdirectory(mindspore/core)\nif(ENABLE_D OR ENABLE_ACL OR ENABLE_TESTCASES)\n    include(${CMAKE_SOURCE_DIR}/cmake/dependency_graphengine.cmake)\nendif()\n\nadd_subdirectory_with_faster_option(mindspore/ccsrc)\n\nif(ENABLE_TESTCASES OR ENABLE_CPP_ST)\n    add_subdirectory(tests)\nendif()\n\n# packaging\nfile(READ ${CMAKE_SOURCE_DIR}/version.txt VERSION_NUMBER)\nstring(REPLACE \"\\n\" \"\" VERSION_NUMBER ${VERSION_NUMBER})\nif(${VERSION_NUMBER} MATCHES \".*dev.*\")\n    message(\"building dev mode\")\n    set(BUILD_DEV_MODE ON)\nendif()\n\nif(ONLY_BUILD_DEVICE_PLUGINS)\n    include(cmake/package_plugin.cmake)\nelseif(MODE_ASCEND_ACL)\n    include(cmake/package_tar.cmake)\nelseif(CMAKE_SYSTEM_NAME MATCHES \"Windows\")\n    include(cmake/package_win.cmake)\nelseif(CMAKE_SYSTEM_NAME MATCHES \"Darwin\")\n    include(cmake/package_mac.cmake)\nelse()\n    include(cmake/package.cmake)\nendif()\n"
        },
        {
          "name": "CONTRIBUTING.md",
          "type": "blob",
          "size": 7.3896484375,
          "content": "# MindSpore contributing guidelines\n\n[查看中文](./CONTRIBUTING_CN.md)\n\n<!-- TOC -->\n\n- [MindSpore contributing guidelines](#mindspore-contributing-guidelines)\n    - [Contributor License Agreement](#contributor-license-agreement)\n    - [Getting Started](#getting-started)\n    - [Contribution workflow](#contribution-workflow)\n        - [Code style](#code-style)\n        - [Fork-Pull development model](#fork-pull-development-model)\n        - [Report issues](#report-issues)\n        - [Propose PRs](#propose-prs)\n\n<!-- /TOC -->\n\n## Contributor License Agreement\n\nIt's required to sign CLA before your first code submission to MindSpore community.\n\nFor individual contributor, please refer to [ICLA online document](https://www.mindspore.cn/icla) for the detailed information.\n\n## Getting Started\n\n- Fork the repository on [Github](https://github.com/mindspore-ai/mindspore) or [Gitee](https://gitee.com/mindspore/mindspore).\n- Read the [README.md](README.md) and [install page](https://www.mindspore.cn/install/en) for project information and build instructions.\n\n## Contribution Workflow\n\n### Code style\n\nPlease follow this style to make MindSpore easy to review, maintain and develop.\n\n- Coding guidelines\n\n    The *Python* coding style suggested by [Python PEP 8 Coding Style](https://pep8.org/) and *C++* coding style suggested by [Google C++ Coding Guidelines](http://google.github.io/styleguide/cppguide.html) are used in MindSpore community. The [CppLint](https://github.com/cpplint/cpplint), [CppCheck](http://cppcheck.sourceforge.net), [CMakeLint](https://github.com/cmake-lint/cmake-lint), [CodeSpell](https://github.com/codespell-project/codespell), [Lizard](http://www.lizard.ws), [ShellCheck](https://github.com/koalaman/shellcheck) and [PyLint](https://pylint.org) are used to check the format of codes, installing these plugins in your IDE is recommended.\n\n- Unittest guidelines\n\n    The *Python* unittest style suggested by [pytest](http://www.pytest.org/en/latest/) and *C++* unittest style suggested by [Googletest Primer](https://github.com/google/googletest/blob/master/docs/primer.md) are used in MindSpore community. The design intent of a testcase should be reflected by its name of comment.\n\n- Refactoring guidelines\n\n    We encourage developers to refactor our code to eliminate the [code smell](https://en.wikipedia.org/wiki/Code_smell). All codes should conform to needs to the coding style and testing style, and refactoring codes are no exception. [Lizard](http://www.lizard.ws) threshold for nloc (lines of code without comments) is 100 and for cnc (cyclomatic complexity number) is 20, when you receive a *Lizard* warning, you have to refactor the code you want to merge.\n\n- Document guidelines\n\n    We use *MarkdownLint* to check the format of markdown documents. MindSpore CI modifies the following rules based on the default configuration.\n    - MD007 (unordered list indentation): The **indent** parameter is set to **4**, indicating that all content in the unordered list needs to be indented using four spaces.\n    - MD009 (spaces at the line end): The **br_spaces** parameter is set to **2**, indicating that there can be 0 or 2 spaces at the end of a line.\n    - MD029 (sequence numbers of an ordered list): The **style** parameter is set to **ordered**, indicating that the sequence numbers of the ordered list are in ascending order.\n\n    For details, please refer to [RULES](https://github.com/markdownlint/markdownlint/blob/master/docs/RULES.md).\n\n### Fork-Pull development model\n\n- Fork MindSpore repository\n\n    Before submitting code to MindSpore project, please make sure that this project have been forked to your own repository. It means that there will be parallel development between MindSpore repository and your own repository, so be careful to avoid the inconsistency between them.\n\n- Clone the remote repository\n\n    If you want to download the code to the local machine, `git` is the best way:\n\n    ```shell\n    # For GitHub\n    git clone https://github.com/{insert_your_forked_repo}/mindspore.git\n    git remote add upstream https://github.com/mindspore-ai/mindspore.git\n    # For Gitee\n    git clone https://gitee.com/{insert_your_forked_repo}/mindspore.git\n    git remote add upstream https://gitee.com/mindspore/mindspore.git\n    ```\n\n- Develop code locally\n\n    To avoid inconsistency between multiple branches, checking out to a new branch is `SUGGESTED`:\n\n    ```shell\n    git checkout -b {new_branch_name} origin/master\n    ```\n\n    Taking the master branch as an example, MindSpore may create version branches and downstream development branches as needed, please fix bugs upstream first.\n    Then you can change the code arbitrarily.\n\n- Push the code to the remote repository\n\n    After updating the code, you should push the update in the formal way:\n\n    ```shell\n    git add .\n    git status # Check the update status\n    git commit -m \"Your commit title\"\n    git commit -s --amend #Add the concrete description of your commit\n    git push origin {new_branch_name}\n    ```\n\n- Pull a request to MindSpore repository\n\n    In the last step, your need to pull a compare request between your new branch and MindSpore `master` branch. After finishing the pull request, the Jenkins CI will be automatically set up for building test. Your pull request should be merged into the upstream master branch as soon as possible to reduce the risk of merging.\n\n### Report issues\n\nA great way to contribute to the project is to send a detailed report when you encounter an issue. We always appreciate a well-written, thorough bug report, and will thank you for it!\n\nWhen reporting issues, refer to this format:\n\n- What version of env (mindspore, os, python etc) are you using?\n- Is this a BUG REPORT or FEATURE REQUEST?\n- What kind of issue is, add the labels to highlight it on the issue dashboard.\n- What happened?\n- What you expected to happen?\n- How to reproduce it?(as minimally and precisely as possible)\n- Special notes for your reviewers?\n\n**Issues advisory:**\n\n- **If you find an unclosed issue, which is exactly what you are going to solve,** please put some comments on that issue to tell others you would be in charge of it.\n- **If an issue is opened for a while,** it's recommended for contributors to precheck before working on solving that issue.\n- **If you resolve an issue which is reported by yourself,** it's also required to let others know before closing that issue.\n- **If you want the issue to be responded as quickly as possible,** please try to label it, you can find kinds of labels on [Label List](https://gitee.com/mindspore/community/blob/master/sigs/dx/docs/labels.md)\n\n### Propose PRs\n\n- Raise your idea as an *issue* on [GitHub](https://github.com/mindspore-ai/mindspore/issues) or [Gitee](https://gitee.com/mindspore/mindspore/issues)\n- If it is a new feature that needs lots of design details, a design proposal should also be submitted.\n- After reaching consensus in the issue discussions and design proposal reviews, complete the development on the forked repo and submit a PR.\n- None of PRs is not permitted until it receives **2+ LGTM** from approvers. Please NOTICE that approver is NOT allowed to add *LGTM* on his own PR.\n- After PR is sufficiently discussed, it will get merged, abandoned or rejected depending on the outcome of the discussion.\n\n**PRs advisory:**\n\n- Any irrelevant changes should be avoided.\n- Make sure your commit history being ordered.\n- Always keep your branch up with the master branch.\n- For bug-fix PRs, make sure all related issues being linked.\n"
        },
        {
          "name": "CONTRIBUTING_CN.md",
          "type": "blob",
          "size": 6.43359375,
          "content": "# MindSpore贡献指南\n\n[View English](./CONTRIBUTING.md)\n\n<!-- TOC -->\n\n- [MindSpore贡献指南](#mindspore贡献指南)\n    - [贡献者许可协议](#贡献者许可协议)\n    - [快速入门](#快速入门)\n    - [贡献流程](#贡献流程)\n        - [代码风格](#代码风格)\n        - [Fork-Pull开发模型](#fork-pull开发模型)\n        - [报告Issue](#报告issue)\n        - [提交PR](#提交pr)\n        - [本地代码自检](#本地代码自检)\n\n<!-- /TOC -->\n\n## 贡献者许可协议\n\n向MindSpore社区提交代码之前，您需要签署《贡献者许可协议（CLA）》。\n\n个人贡献者请参见[ICLA在线文件](https://www.mindspore.cn/icla)。\n\n## 快速入门\n\n- 在[Github](https://github.com/mindspore-ai/mindspore)或[Gitee](https://gitee.com/mindspore/mindspore)上fork代码仓。\n- 参见[README_CN.md](README_CN.md)和[安装页面](https://www.mindspore.cn/install)了解项目信息和构建说明。\n\n## 贡献流程\n\n### 代码风格\n\n请遵循此风格，以便MindSpore审查、维护和开发。\n\n- 编码指南\n\n    MindSpore社区使用[Python PEP 8 编码风格](https://pep8.org/)和[谷歌C++编码风格](http://google.github.io/styleguide/cppguide.html)。建议在IDE中安装以下插件，用于检查代码格式：[CppLint](https://github.com/cpplint/cpplint)、[CppCheck](http://cppcheck.sourceforge.net)、[CMakeLint](https://github.com/cmake-lint/cmake-lint)、[CodeSpell](https://github.com/codespell-project/codespell)、[Lizard](http://www.lizard.ws)、[ShellCheck](https://github.com/koalaman/shellcheck)和[PyLint](https://pylint.org)。\n\n- 单元测试指南\n\n    MindSpore社区使用Python单元测试框架[pytest](http://www.pytest.org/en/latest/)和C++单元测试框架[Google Test Primer](https://github.com/google/googletest/blob/master/docs/primer.md)。注释名称需反映测试用例的设计意图。\n\n- 重构指南\n\n    我们鼓励开发人员重构我们的代码，以消除[代码坏味道](https://zh.wikipedia.org/wiki/%E4%BB%A3%E7%A0%81%E5%BC%82%E5%91%B3)。所有代码都要符合编码风格和测试风格，重构代码也不例外。无注释的代码行（nloc）的[Lizard](http://www.lizard.ws)阈值为100，圈复杂度（cnc）的阈值为20。当收到Lizard警告时，必须重构要合并的代码。\n\n- 文档指南\n\n    我们使用MarkdownLint来检查Markdown文档格式。MindSpore CI基于默认配置修改了以下规则。\n    - MD007（无序列表缩进）：参数**indent**设置为**4**，表示无序列表中的所有内容都需要缩进4个空格。\n    - MD009（行尾空格）：参数**br_spaces**设置为**2**，表示行尾可以有0或2个空格。\n    - MD029（有序列表的序列号）：参数**style**设置为**ordered**，表示升序。\n\n    有关详细信息，请参见[规则](https://github.com/markdownlint/markdownlint/blob/master/docs/RULES.md)。\n\n### Fork-Pull开发模型\n\n- Fork MindSpore代码仓\n\n    在提交代码至MindSpore项目之前，请确保已fork此项目到您自己的代码仓。MindSpore代码仓和您自己的代码仓之间可能会并行开发，请注意它们之间的一致性。\n\n- 克隆远程代码仓\n\n    如果您想将代码下载到本地计算机，最好使用git方法：\n\n    ```shell\n    # 在GitHub上：\n    git clone https://github.com/{insert_your_forked_repo}/mindspore.git\n    git remote add upstream https://github.com/mindspore-ai/mindspore.git\n    # 在Gitee上：\n    git clone https://gitee.com/{insert_your_forked_repo}/mindspore.git\n    git remote add upstream https://gitee.com/mindspore/mindspore.git\n    ```\n\n- 本地开发代码。\n\n    为避免分支不一致，建议切换到新分支：\n\n    ```shell\n    git checkout -b {新分支名称} origin/master\n    ```\n\n    以master分支为例，如果MindSpore需要创建版本分支和下游开发分支，请先修复上游的bug，\n    再更改代码。\n\n- 将代码推送到远程代码仓。\n\n    更新代码后，以正式的方式推送更新：\n\n    ```shell\n    git add .\n    git status # 查看更新状态。\n    git commit -m \"你的commit标题\"\n    git commit -s --amend # 添加commit的具体描述。\n    git push origin {新分支名称}\n    ```\n\n- 将请求拉取到MindSpore代码仓。\n\n    在最后一步中，您需要在新分支和MindSpore主分支之间拉取比较请求。完成拉取请求后，Jenkins CI将自动设置，进行构建测试。拉取请求应该尽快合并到上游master分支中，以降低合并的风险。\n\n### 报告Issue\n\n发现问题后，建议以报告issue的方式为项目作出贡献。错误报告应尽量书写规范，内容详尽，感谢您对项目作出的贡献。\n\n报告issue时，请参考以下格式：\n\n- 说明您使用的环境版本（MindSpore、OS、Python等）。\n- 说明是错误报告还是功能需求。\n- 说明issue类型，添加标签可以在issue板上突出显示该issue。\n- 问题是什么？\n- 期望如何处理？\n- 如何复现？（尽可能精确具体地描述）\n- 给审核员的特别说明。\n\n**Issue咨询：**\n\n- **解决issue时，请先评论**，告知他人由您来负责解决该issue。\n- **对于长时间未关闭的issue**，建议贡献者在解决该issue之前进行预先检查。\n- **如您自行解决了自己报告的issue**，仍需在关闭该issue之前告知他人。\n- **如需issue快速响应**，可为issue添加标签。标签详情，参见[标签列表](https://gitee.com/mindspore/community/blob/master/sigs/dx/docs/labels.md)。\n\n### 提交PR\n\n- 在[GitHub](https://github.com/mindspore-ai/mindspore/issues)或[Gitee](https://gitee.com/mindspore/mindspore/issues)上通过issue提出您的想法。\n- 如果是需要大量设计细节的新功能，还应提交设计方案。\n- 经issue讨论和设计方案评审达成共识后，在已fork的代码仓开发，并提交PR。\n- 任何PR至少需要位2位审批人的LGTM标签。请注意，审批人不允许在自己的PR上添加LGTM标签。\n- 经充分讨论后，根据讨论的结果合并、放弃或拒绝PR。\n\n**PR咨询：**\n\n- 避免不相关的更改。\n- 确保您的commit历史记录有序。\n- 确保您的分支与主分支始终一致。\n- 用于修复错误的PR中，确保已关联所有相关问题。\n\n### 本地代码自检\n\n在开发过程中，建议使用pre-push功能进行本地代码自检，可以在本地进行类似CI门禁上Code Check阶段的代码扫描，提高上库时跑门禁的成功率。使用方法请参见[pre-push快速指引](scripts/pre_commit/README_CN.md)。\n"
        },
        {
          "name": "LICENSE",
          "type": "blob",
          "size": 11.0908203125,
          "content": "                                 Apache License\n                           Version 2.0, January 2004\n                        http://www.apache.org/licenses/\n\n   TERMS AND CONDITIONS FOR USE, REPRODUCTION, AND DISTRIBUTION\n\n   1. Definitions.\n\n      \"License\" shall mean the terms and conditions for use, reproduction,\n      and distribution as defined by Sections 1 through 9 of this document.\n\n      \"Licensor\" shall mean the copyright owner or entity authorized by\n      the copyright owner that is granting the License.\n\n      \"Legal Entity\" shall mean the union of the acting entity and all\n      other entities that control, are controlled by, or are under common\n      control with that entity. For the purposes of this definition,\n      \"control\" means (i) the power, direct or indirect, to cause the\n      direction or management of such entity, whether by contract or\n      otherwise, or (ii) ownership of fifty percent (50%) or more of the\n      outstanding shares, or (iii) beneficial ownership of such entity.\n\n      \"You\" (or \"Your\") shall mean an individual or Legal Entity\n      exercising permissions granted by this License.\n\n      \"Source\" form shall mean the preferred form for making modifications,\n      including but not limited to software source code, documentation\n      source, and configuration files.\n\n      \"Object\" form shall mean any form resulting from mechanical\n      transformation or translation of a Source form, including but\n      not limited to compiled object code, generated documentation,\n      and conversions to other media types.\n\n      \"Work\" shall mean the work of authorship, whether in Source or\n      Object form, made available under the License, as indicated by a\n      copyright notice that is included in or attached to the work\n      (an example is provided in the Appendix below).\n\n      \"Derivative Works\" shall mean any work, whether in Source or Object\n      form, that is based on (or derived from) the Work and for which the\n      editorial revisions, annotations, elaborations, or other modifications\n      represent, as a whole, an original work of authorship. For the purposes\n      of this License, Derivative Works shall not include works that remain\n      separable from, or merely link (or bind by name) to the interfaces of,\n      the Work and Derivative Works thereof.\n\n      \"Contribution\" shall mean any work of authorship, including\n      the original version of the Work and any modifications or additions\n      to that Work or Derivative Works thereof, that is intentionally\n      submitted to Licensor for inclusion in the Work by the copyright owner\n      or by an individual or Legal Entity authorized to submit on behalf of\n      the copyright owner. For the purposes of this definition, \"submitted\"\n      means any form of electronic, verbal, or written communication sent\n      to the Licensor or its representatives, including but not limited to\n      communication on electronic mailing lists, source code control systems,\n      and issue tracking systems that are managed by, or on behalf of, the\n      Licensor for the purpose of discussing and improving the Work, but\n      excluding communication that is conspicuously marked or otherwise\n      designated in writing by the copyright owner as \"Not a Contribution.\"\n\n      \"Contributor\" shall mean Licensor and any individual or Legal Entity\n      on behalf of whom a Contribution has been received by Licensor and\n      subsequently incorporated within the Work.\n\n   2. Grant of Copyright License. Subject to the terms and conditions of\n      this License, each Contributor hereby grants to You a perpetual,\n      worldwide, non-exclusive, no-charge, royalty-free, irrevocable\n      copyright license to reproduce, prepare Derivative Works of,\n      publicly display, publicly perform, sublicense, and distribute the\n      Work and such Derivative Works in Source or Object form.\n\n   3. Grant of Patent License. Subject to the terms and conditions of\n      this License, each Contributor hereby grants to You a perpetual,\n      worldwide, non-exclusive, no-charge, royalty-free, irrevocable\n      (except as stated in this section) patent license to make, have made,\n      use, offer to sell, sell, import, and otherwise transfer the Work,\n      where such license applies only to those patent claims licensable\n      by such Contributor that are necessarily infringed by their\n      Contribution(s) alone or by combination of their Contribution(s)\n      with the Work to which such Contribution(s) was submitted. If You\n      institute patent litigation against any entity (including a\n      cross-claim or counterclaim in a lawsuit) alleging that the Work\n      or a Contribution incorporated within the Work constitutes direct\n      or contributory patent infringement, then any patent licenses\n      granted to You under this License for that Work shall terminate\n      as of the date such litigation is filed.\n\n   4. Redistribution. You may reproduce and distribute copies of the\n      Work or Derivative Works thereof in any medium, with or without\n      modifications, and in Source or Object form, provided that You\n      meet the following conditions:\n\n      (a) You must give any other recipients of the Work or\n          Derivative Works a copy of this License; and\n\n      (b) You must cause any modified files to carry prominent notices\n          stating that You changed the files; and\n\n      (c) You must retain, in the Source form of any Derivative Works\n          that You distribute, all copyright, patent, trademark, and\n          attribution notices from the Source form of the Work,\n          excluding those notices that do not pertain to any part of\n          the Derivative Works; and\n\n      (d) If the Work includes a \"NOTICE\" text file as part of its\n          distribution, then any Derivative Works that You distribute must\n          include a readable copy of the attribution notices contained\n          within such NOTICE file, excluding those notices that do not\n          pertain to any part of the Derivative Works, in at least one\n          of the following places: within a NOTICE text file distributed\n          as part of the Derivative Works; within the Source form or\n          documentation, if provided along with the Derivative Works; or,\n          within a display generated by the Derivative Works, if and\n          wherever such third-party notices normally appear. The contents\n          of the NOTICE file are for informational purposes only and\n          do not modify the License. You may add Your own attribution\n          notices within Derivative Works that You distribute, alongside\n          or as an addendum to the NOTICE text from the Work, provided\n          that such additional attribution notices cannot be construed\n          as modifying the License.\n\n      You may add Your own copyright statement to Your modifications and\n      may provide additional or different license terms and conditions\n      for use, reproduction, or distribution of Your modifications, or\n      for any such Derivative Works as a whole, provided Your use,\n      reproduction, and distribution of the Work otherwise complies with\n      the conditions stated in this License.\n\n   5. Submission of Contributions. Unless You explicitly state otherwise,\n      any Contribution intentionally submitted for inclusion in the Work\n      by You to the Licensor shall be under the terms and conditions of\n      this License, without any additional terms or conditions.\n      Notwithstanding the above, nothing herein shall supersede or modify\n      the terms of any separate license agreement you may have executed\n      with Licensor regarding such Contributions.\n\n   6. Trademarks. This License does not grant permission to use the trade\n      names, trademarks, service marks, or product names of the Licensor,\n      except as required for reasonable and customary use in describing the\n      origin of the Work and reproducing the content of the NOTICE file.\n\n   7. Disclaimer of Warranty. Unless required by applicable law or\n      agreed to in writing, Licensor provides the Work (and each\n      Contributor provides its Contributions) on an \"AS IS\" BASIS,\n      WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or\n      implied, including, without limitation, any warranties or conditions\n      of TITLE, NON-INFRINGEMENT, MERCHANTABILITY, or FITNESS FOR A\n      PARTICULAR PURPOSE. You are solely responsible for determining the\n      appropriateness of using or redistributing the Work and assume any\n      risks associated with Your exercise of permissions under this License.\n\n   8. Limitation of Liability. In no event and under no legal theory,\n      whether in tort (including negligence), contract, or otherwise,\n      unless required by applicable law (such as deliberate and grossly\n      negligent acts) or agreed to in writing, shall any Contributor be\n      liable to You for damages, including any direct, indirect, special,\n      incidental, or consequential damages of any character arising as a\n      result of this License or out of the use or inability to use the\n      Work (including but not limited to damages for loss of goodwill,\n      work stoppage, computer failure or malfunction, or any and all\n      other commercial damages or losses), even if such Contributor\n      has been advised of the possibility of such damages.\n\n   9. Accepting Warranty or Additional Liability. While redistributing\n      the Work or Derivative Works thereof, You may choose to offer,\n      and charge a fee for, acceptance of support, warranty, indemnity,\n      or other liability obligations and/or rights consistent with this\n      License. However, in accepting such obligations, You may act only\n      on Your own behalf and on Your sole responsibility, not on behalf\n      of any other Contributor, and only if You agree to indemnify,\n      defend, and hold each Contributor harmless for any liability\n      incurred by, or claims asserted against, such Contributor by reason\n      of your accepting any such warranty or additional liability.\n\n   END OF TERMS AND CONDITIONS\n\n   APPENDIX: How to apply the Apache License to your work.\n\n      To apply the Apache License to your work, attach the following\n      boilerplate notice, with the fields enclosed by brackets \"[]\"\n      replaced with your own identifying information. (Don't include\n      the brackets!)  The text should be enclosed in the appropriate\n      comment syntax for the file format. We also recommend that a\n      file or class name and description of purpose be included on the\n      same \"printed page\" as the copyright notice for easier\n      identification within third-party archives.\n\n   Copyright [yyyy] [name of copyright owner]\n\n   Licensed under the Apache License, Version 2.0 (the \"License\");\n   you may not use this file except in compliance with the License.\n   You may obtain a copy of the License at\n\n       http://www.apache.org/licenses/LICENSE-2.0\n\n   Unless required by applicable law or agreed to in writing, software\n   distributed under the License is distributed on an \"AS IS\" BASIS,\n   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n   See the License for the specific language governing permissions and\n   limitations under the License.\n"
        },
        {
          "name": "NOTICE",
          "type": "blob",
          "size": 0.0576171875,
          "content": "MindSpore\nCopyright 2019-2020 Huawei Technologies Co., Ltd\n"
        },
        {
          "name": "OWNERS",
          "type": "blob",
          "size": 0.6181640625,
          "content": "approvers:\n- kingxian\n- guoqi1024\n- baochong\n- zhaizhiqiang\n- stsuteng\n- kisnwang\n\nfiles:\n  \"akg\":\n    approvers:\n    - gaoxiong1\n    - ckey_dou\n    - anyrenwei\n\n  \"graphengine\":\n    approvers:\n    - jjfeing\n    - guoqi1024\n    - baochong\n    - liujunzhu\n    - kisnwang\n    - yuchaojie\n    - hwcaifubi\n\n  \"version.txt\":\n    approvers:\n    - jjfeing\n    - guoqi1024\n    - baochong\n    - kisnwang\n    - yuchaojie\n    - hwcaifubi\n  \n  \".*\\\\.md$\":\n    approvers:\n    - kingxian\n    - guoqi1024\n    - baochong\n    - zhaizhiqiang\n    - stsuteng\n    - kisnwang\n    - gemini524\n    - Hanshize\n    - rudy_tan\n    - luojianing1\n    - tjulyj33\n"
        },
        {
          "name": "README.md",
          "type": "blob",
          "size": 16.166015625,
          "content": "![MindSpore Logo](https://gitee.com/mindspore/mindspore/raw/master/docs/MindSpore-logo.png \"MindSpore logo\")\n\n[![PyPI - Python Version](https://img.shields.io/pypi/pyversions/mindspore.svg)](https://pypi.org/project/mindspore)\n[![PyPI](https://badge.fury.io/py/mindspore.svg)](https://badge.fury.io/py/mindspore)\n[![Downloads](https://static.pepy.tech/badge/mindspore)](https://pepy.tech/project/mindspore)\n[![DockerHub](https://img.shields.io/docker/pulls/mindspore/mindspore-cpu.svg)](https://hub.docker.com/r/mindspore/mindspore-cpu)\n[![LICENSE](https://img.shields.io/github/license/mindspore-ai/mindspore.svg?style=flat-square)](https://github.com/mindspore-ai/mindspore/blob/master/LICENSE)\n[![Slack](https://img.shields.io/badge/slack-chat-green.svg?logo=slack)](https://join.slack.com/t/mindspore/shared_invite/zt-dgk65rli-3ex4xvS4wHX7UDmsQmfu8w)\n[![PRs Welcome](https://img.shields.io/badge/PRs-welcome-brightgreen.svg?style=flat-square)](https://gitee.com/mindspore/mindspore/pulls)\n\n[查看中文](./README_CN.md)\n\n<!-- TOC -->\n\n- [What Is MindSpore](#what-is-mindspore)\n    - [Automatic Differentiation](#automatic-differentiation)\n    - [Automatic Parallel](#automatic-parallel)\n- [Installation](#installation)\n    - [Pip mode method installation](#pip-mode-method-installation)\n    - [Source code compilation installation](#source-code-compilation-installation)\n    - [Docker Image](#docker-image)\n- [Quickstart](#quickstart)\n- [Docs](#docs)\n- [Community](#community)\n    - [Governance](#governance)\n    - [Communication](#communication)\n- [Contributing](#contributing)\n- [Maintenance phases](#maintenance-phases)\n- [Maintenance status](#maintenance-status)\n- [Release Notes](#release-notes)\n- [License](#license)\n\n<!-- /TOC -->\n\n## What Is MindSpore\n\nMindSpore is a new open source deep learning training/inference framework that\ncould be used for mobile, edge and cloud scenarios. MindSpore is designed to\nprovide development experience with friendly design and efficient execution for\nthe data scientists and algorithmic engineers, native support for Ascend AI\nprocessor, and software hardware co-optimization. At the meantime MindSpore as\na global AI open source community, aims to further advance the development and\nenrichment of the AI software/hardware application ecosystem.\n\n<img src=\"https://gitee.com/mindspore/mindspore/raw/master/docs/MindSpore-architecture.png\" alt=\"MindSpore Architecture\"/>\n\nFor more details please check out our [Architecture Guide](https://www.mindspore.cn/tutorials/en/master/beginner/introduction.html).\n\n### Automatic Differentiation\n\nCurrently, there are two automatic differentiation techniques in mainstream deep learning frameworks:\n\n- **Operator Overloading (OO)**: Overloading the basic operators of the programming language to encapsulate their gradient rules. Record the operation trajectory of the network during forward execution in an operator overloaded manner, then apply the chain rule to the dynamically generated data flow graph to implement automatic differentiation.\n- **Source Transformation (ST)**: This technology is evolving from the functional programming framework and performs automatic differential transformation on the intermediate expression (the expression form of the program during the compilation process) in the form of just-in-time compilation (JIT), supporting complex control flow scenarios, higher-order functions and closures.\n\nPyTorch used OO. Compared to ST, OO generates gradient graph in runtime, so it does not need to take function call and control flow into consideration, which makes it easier to develop. However, OO can not perform gradient graph optimization in compilation time and the control flow has to be unfolded in runtime, so it is difficult to achieve extreme optimization in performance.\n\nMindSpore implemented automatic differentiation based on ST. On the one hand, it supports automatic differentiation of automatic control flow, so it is quite convenient to build models like PyTorch. On the other hand, MindSpore can perform static compilation optimization on neural networks to achieve great performance.\n\n<img src=\"https://gitee.com/mindspore/mindspore/raw/master/docs/Automatic-differentiation.png\" alt=\"Automatic Differentiation\" width=\"600\"/>\n\nThe implementation of MindSpore automatic differentiation can be understood as the symbolic differentiation of the program itself. Because MindSpore IR is a functional intermediate expression, it has an intuitive correspondence with the composite function in basic algebra. The derivation formula of the composite function composed of arbitrary basic functions can be derived. Each primitive operation in MindSpore IR can correspond to the basic functions in basic algebra, which can build more complex flow control.\n\n### Automatic Parallel\n\nThe goal of MindSpore automatic parallel is to build a training method that combines data parallelism, model parallelism, and hybrid parallelism. It can automatically select a least cost model splitting strategy to achieve automatic distributed parallel training.\n\n<img src=\"https://gitee.com/mindspore/mindspore/raw/master/docs/Automatic-parallel.png\" alt=\"Automatic Parallel\" width=\"600\"/>\n\nAt present, MindSpore uses a fine-grained parallel strategy of splitting operators, that is, each operator in the figure is split into a cluster to complete parallel operations. The splitting strategy during this period may be very complicated, but as a developer advocating Pythonic, you don't need to care about the underlying implementation, as long as the top-level API compute is efficient.\n\n## Installation\n\n### Pip mode method installation\n\nMindSpore offers build options across multiple backends:\n\n| Hardware Platform | Operating System | Status |\n| :---------------- | :--------------- | :----- |\n| Ascend910 | Ubuntu-x86 | ✔️ |\n|  | Ubuntu-aarch64 | ✔️ |\n|  | EulerOS-aarch64 | ✔️ |\n|  | CentOS-x86 | ✔️ |\n|  | CentOS-aarch64 | ✔️ |\n| GPU CUDA 10.1 | Ubuntu-x86 | ✔️ |\n| CPU | Ubuntu-x86 | ✔️ |\n|  | Ubuntu-aarch64 | ✔️ |\n|  | Windows-x86 | ✔️ |\n\nFor installation using `pip`, take `CPU` and `Ubuntu-x86` build version as an example:\n\n1. Download whl from [MindSpore download page](https://www.mindspore.cn/versions/en), and install the package.\n\n    ```bash\n    pip install https://ms-release.obs.cn-north-4.myhuaweicloud.com/1.2.0-rc1/MindSpore/cpu/ubuntu_x86/mindspore-1.2.0rc1-cp37-cp37m-linux_x86_64.whl\n    ```\n\n2. Run the following command to verify the install.\n\n    ```python\n    import numpy as np\n    import mindspore.context as context\n    import mindspore.nn as nn\n    from mindspore import Tensor\n    from mindspore.ops import operations as P\n\n    context.set_context(mode=context.GRAPH_MODE, device_target=\"CPU\")\n\n    class Mul(nn.Cell):\n        def __init__(self):\n            super(Mul, self).__init__()\n            self.mul = P.Mul()\n\n        def construct(self, x, y):\n            return self.mul(x, y)\n\n    x = Tensor(np.array([1.0, 2.0, 3.0]).astype(np.float32))\n    y = Tensor(np.array([4.0, 5.0, 6.0]).astype(np.float32))\n\n    mul = Mul()\n    print(mul(x, y))\n    ```\n\n    ```text\n    [ 4. 10. 18.]\n    ```\n\nUse pip mode method to install MindSpore in different environments. Refer to the following documents.\n\n- [Using pip mode method to install MindSpore in Ascend environment](https://gitee.com/mindspore/docs/blob/master/install/mindspore_ascend_install_pip_en.md)\n- [Using pip mode method to install MindSpore in GPU environment](https://gitee.com/mindspore/docs/blob/master/install/mindspore_gpu_install_pip_en.md)\n- [Using pip mode method to install MindSpore in CPU environment](https://gitee.com/mindspore/docs/blob/master/install/mindspore_cpu_install_pip_en.md)\n\n### Source code compilation installation\n\nUse the source code compilation method to install MindSpore in different environments. Refer to the following documents.\n\n- [Using the source code compilation method to install MindSpore in Ascend environment](https://gitee.com/mindspore/docs/blob/master/install/mindspore_ascend_install_source_en.md)\n- [Using the source code compilation method to install MindSpore in GPU environment](https://gitee.com/mindspore/docs/blob/master/install/mindspore_gpu_install_source_en.md)\n- [Using the source code compilation method to install MindSpore in CPU environment](https://gitee.com/mindspore/docs/blob/master/install/mindspore_cpu_install_source_en.md)\n\n### Docker Image\n\nMindSpore docker image is hosted on [Docker Hub](https://hub.docker.com/r/mindspore),\ncurrently the containerized build options are supported as follows:\n\n| Hardware Platform | Docker Image Repository | Tag | Description |\n| :---------------- | :---------------------- | :-- | :---------- |\n| CPU | `mindspore/mindspore-cpu` | `x.y.z` | Production environment with pre-installed MindSpore `x.y.z` CPU release. |\n|  |  | `devel` | Development environment provided to build MindSpore (with `CPU` backend) from the source, refer to <https://www.mindspore.cn/install/en> for installation details. |\n|  |  | `runtime` | Runtime environment provided to install MindSpore binary package with `CPU` backend. |\n| GPU | `mindspore/mindspore-gpu` | `x.y.z` | Production environment with pre-installed MindSpore `x.y.z` GPU release. |\n|  |  | `devel` | Development environment provided to build MindSpore (with `GPU CUDA10.1` backend) from the source, refer to <https://www.mindspore.cn/install/en> for installation details. |\n|  |  | `runtime` | Runtime environment provided to install MindSpore binary package with `GPU CUDA10.1` backend. |\n\n> **NOTICE:** For GPU `devel` docker image, it's NOT suggested to directly install the whl package after building from the source, instead we strongly RECOMMEND you transfer and install the whl package inside GPU `runtime` docker image.\n\n- CPU\n\n    For `CPU` backend, you can directly pull and run the latest stable image using the below command:\n\n    ```bash\n    docker pull mindspore/mindspore-cpu:1.1.0\n    docker run -it mindspore/mindspore-cpu:1.1.0 /bin/bash\n    ```\n\n- GPU\n\n    For `GPU` backend, please make sure the `nvidia-container-toolkit` has been installed in advance, here are some install guidelines for `Ubuntu` users:\n\n    ```bash\n    DISTRIBUTION=$(. /etc/os-release; echo $ID$VERSION_ID)\n    curl -s -L https://nvidia.github.io/nvidia-docker/gpgkey | apt-key add -\n    curl -s -L https://nvidia.github.io/nvidia-docker/$DISTRIBUTION/nvidia-docker.list | tee /etc/apt/sources.list.d/nvidia-docker.list\n\n    sudo apt-get update && sudo apt-get install -y nvidia-container-toolkit nvidia-docker2\n    sudo systemctl restart docker\n    ```\n\n    Then edit the file daemon.json:\n\n    ```bash\n    $ vim /etc/docker/daemon.json\n    {\n        \"runtimes\": {\n            \"nvidia\": {\n                \"path\": \"nvidia-container-runtime\",\n                \"runtimeArgs\": []\n            }\n        }\n    }\n    ```\n\n    Restart docker again:\n\n    ```bash\n    sudo systemctl daemon-reload\n    sudo systemctl restart docker\n    ```\n\n    Then you can pull and run the latest stable image using the below command:\n\n    ```bash\n    docker pull mindspore/mindspore-gpu:1.1.0\n    docker run -it -v /dev/shm:/dev/shm --runtime=nvidia --privileged=true mindspore/mindspore-gpu:1.1.0 /bin/bash\n    ```\n\n    To test if the docker image works, please execute the python code below and check the output:\n\n    ```python\n    import numpy as np\n    import mindspore.context as context\n    from mindspore import Tensor\n    from mindspore.ops import functional as F\n\n    context.set_context(mode=context.PYNATIVE_MODE, device_target=\"GPU\")\n\n    x = Tensor(np.ones([1,3,3,4]).astype(np.float32))\n    y = Tensor(np.ones([1,3,3,4]).astype(np.float32))\n    print(F.tensor_add(x, y))\n    ```\n\n    ```text\n    [[[ 2.  2.  2.  2.],\n    [ 2.  2.  2.  2.],\n    [ 2.  2.  2.  2.]],\n\n    [[ 2.  2.  2.  2.],\n    [ 2.  2.  2.  2.],\n    [ 2.  2.  2.  2.]],\n\n    [[ 2.  2.  2.  2.],\n    [ 2.  2.  2.  2.],\n    [ 2.  2.  2.  2.]]]\n    ```\n\nIf you want to learn more about the building process of MindSpore docker images,\nplease check out [docker](https://gitee.com/mindspore/mindspore/blob/master/scripts/docker/README.md) repo for the details.\n\n## Quickstart\n\nSee the [Quick Start](https://www.mindspore.cn/tutorials/en/master/beginner/quick_start.html)\nto implement the image classification.\n\n## Docs\n\nMore details about installation guide, tutorials and APIs, please see the\n[User Documentation](https://gitee.com/mindspore/docs).\n\n## Community\n\n### Governance\n\nCheck out how MindSpore Open Governance [works](https://gitee.com/mindspore/community/blob/master/governance.md).\n\n### Communication\n\n- [MindSpore Slack](https://join.slack.com/t/mindspore/shared_invite/zt-dgk65rli-3ex4xvS4wHX7UDmsQmfu8w) - Communication platform for developers.\n- IRC channel at `#mindspore` (only for meeting minutes logging purpose)\n- Video Conferencing: TBD\n- Mailing-list: <https://mailweb.mindspore.cn/postorius/lists>\n\n## Contributing\n\nWelcome contributions. See our [Contributor Wiki](https://gitee.com/mindspore/mindspore/blob/master/CONTRIBUTING.md) for\nmore details.\n\n## Maintenance phases\n\nProject stable branches will be in one of the following states:\n\n| **State**       | **Time frame**    | **Summary**                                          |\n|-------------|---------------|--------------------------------------------------|\n| Planning    | 1 - 3 months  | Features are under planning.                     |\n| Development | 3 months      | Features are under development.                  |\n| Maintained  | 6 - 12 months | All bugfixes are appropriate. Releases produced. |\n| Unmaintained| 0 - 3 months  | All bugfixes are appropriate. No Maintainers and No Releases produced.                                                 |\n| End Of Life (EOL) |  N/A |  Branch no longer accepting changes.    |\n\n## Maintenance status\n\n| **Branch** | **Status**   | **Initial Release Date** | **Next Phase**                         | **EOL Date**|\n|------------|--------------|--------------------------|----------------------------------------|-------------|\n| **r2.2**   | Maintained   | 2023-10-18               | Unmaintained <br> 2024-10-18 estimated |             |\n| **r2.1**   | Maintained   | 2023-07-29               | Unmaintained <br> 2024-07-29 estimated |             |\n| **r2.0**   | Maintained   | 2023-06-15               | Unmaintained <br> 2024-06-15 estimated |             |\n| **r1.10**  | End Of Life  | 2023-02-02               |                                        | 2024-02-02  |\n| **r1.9**   | End Of Life  | 2022-10-26               |                                        | 2023-10-26  |\n| **r1.8**   | End Of Life  | 2022-07-29               |                                        | 2023-07-29  |\n| **r1.7**   | End Of Life  | 2022-04-29               |                                        | 2023-04-29  |\n| **r1.6**   | End Of Life  | 2022-01-29               |                                        | 2023-01-29  |\n| **r1.5**   | End Of Life  | 2021-10-15               |                                        | 2022-10-15  |\n| **r1.4**   | End Of Life  | 2021-08-15               |                                        | 2022-08-15  |\n| **r1.3**   | End Of Life  | 2021-07-15               |                                        | 2022-07-15  |\n| **r1.2**   | End Of Life  | 2021-04-15               |                                        | 2022-04-29  |\n| **r1.1**   | End Of Life  | 2020-12-31               |                                        | 2021-09-30  |\n| **r1.0**   | End Of Life  | 2020-09-24               |                                        | 2021-07-30  |\n| **r0.7**   | End Of Life  | 2020-08-31               |                                        | 2021-02-28  |\n| **r0.6**   | End Of Life  | 2020-07-31               |                                        | 2020-12-30  |\n| **r0.5**   | End Of Life  | 2020-06-30               |                                        | 2021-06-30  |\n| **r0.3**   | End Of Life  | 2020-05-31               |                                        | 2020-09-30  |\n| **r0.2**   | End Of Life  | 2020-04-30               |                                        | 2020-08-31  |\n| **r0.1**   | End Of Life  | 2020-03-28               |                                        | 2020-06-30  |\n\n## Release Notes\n\nThe release notes, see our [RELEASE](https://gitee.com/mindspore/mindspore/blob/master/RELEASE.md).\n\n## License\n\n[Apache License 2.0](https://gitee.com/mindspore/mindspore/blob/master/LICENSE)\n"
        },
        {
          "name": "README_CN.md",
          "type": "blob",
          "size": 14.9609375,
          "content": "![MindSpore标志](https://gitee.com/mindspore/mindspore/raw/master/docs/MindSpore-logo.png \"MindSpore logo\")\n\n[![PyPI - Python Version](https://img.shields.io/pypi/pyversions/mindspore.svg)](https://pypi.org/project/mindspore)\n[![PyPI](https://badge.fury.io/py/mindspore.svg)](https://badge.fury.io/py/mindspore)\n[![Downloads](https://static.pepy.tech/badge/mindspore)](https://pepy.tech/project/mindspore)\n[![DockerHub](https://img.shields.io/docker/pulls/mindspore/mindspore-cpu.svg)](https://hub.docker.com/r/mindspore/mindspore-cpu)\n[![LICENSE](https://img.shields.io/github/license/mindspore-ai/mindspore.svg?style=flat-square)](https://github.com/mindspore-ai/mindspore/blob/master/LICENSE)\n[![Slack](https://img.shields.io/badge/slack-chat-green.svg?logo=slack)](https://join.slack.com/t/mindspore/shared_invite/zt-dgk65rli-3ex4xvS4wHX7UDmsQmfu8w)\n[![PRs Welcome](https://img.shields.io/badge/PRs-welcome-brightgreen.svg?style=flat-square)](https://gitee.com/mindspore/mindspore/pulls)\n\n[View English](./README.md)\n\n<!-- TOC -->\n\n- [MindSpore介绍](#mindspore介绍)\n    - [自动微分](#自动微分)\n    - [自动并行](#自动并行)\n- [安装](#安装)\n    - [pip方式安装](#pip方式安装)\n    - [源码编译方式安装](#源码编译方式安装)\n    - [Docker镜像](#docker镜像)\n- [快速入门](#快速入门)\n- [文档](#文档)\n- [社区](#社区)\n    - [治理](#治理)\n    - [交流](#交流)\n- [贡献](#贡献)\n- [分支维护策略](#分支维护策略)\n- [现有分支维护状态](#现有分支维护状态)\n- [版本说明](#版本说明)\n- [许可证](#许可证)\n\n<!-- /TOC -->\n\n## MindSpore介绍\n\nMindSpore是一种适用于端边云场景的新型开源深度学习训练/推理框架。\nMindSpore提供了友好的设计和高效的执行，旨在提升数据科学家和算法工程师的开发体验，并为Ascend AI处理器提供原生支持，以及软硬件协同优化。\n\n同时，MindSpore作为全球AI开源社区，致力于进一步开发和丰富AI软硬件应用生态。\n\n<img src=\"https://gitee.com/mindspore/mindspore/raw/master/docs/MindSpore-architecture-zh.png\" alt=\"MindSpore Architecture\"/>\n\n欲了解更多详情，请查看我们的[总体架构](https://www.mindspore.cn/tutorials/zh-CN/master/beginner/introduction.html)。\n\n### 自动微分\n\n当前主流深度学习框架中有两种自动微分技术：\n\n- **操作符重载法**： 通过操作符重载对编程语言中的基本操作语义进行重定义，封装其微分规则。 在程序运行时记录算子过载正向执行时网络的运行轨迹，对动态生成的数据流图应用链式法则，实现自动微分。\n- **代码变换法**： 该技术是从功能编程框架演进而来，以即时编译（Just-in-time Compilation，JIT）的形式对中间表达式（程序在编译过程中的表达式）进行自动差分转换，支持复杂的控制流场景、高阶函数和闭包。\n\nPyTorch采用的是操作符重载法。相较于代码变换法，操作符重载法是在运行时生成微分计算图的， 无需考虑函数调用与控制流等情况， 开发更为简单。 但该方法不能在编译时刻做微分图的优化， 控制流也需要根据运行时的信息来展开， 很难实现性能的极限优化。\n\nMindSpore则采用的是代码变换法。一方面，它支持自动控制流的自动微分，因此像PyTorch这样的模型构建非常方便。另一方面，MindSpore可以对神经网络进行静态编译优化，以获得更好的性能。\n\n<img src=\"https://gitee.com/mindspore/mindspore/raw/master/docs/Automatic-differentiation.png\" alt=\"Automatic Differentiation\" width=\"600\"/>\n\nMindSpore自动微分的实现可以理解为程序本身的符号微分。MindSpore IR是一个函数中间表达式，它与基础代数中的复合函数具有直观的对应关系。复合函数的公式由任意可推导的基础函数组成。MindSpore IR中的每个原语操作都可以对应基础代数中的基本功能，从而可以建立更复杂的流控制。\n\n### 自动并行\n\nMindSpore自动并行的目的是构建数据并行、模型并行和混合并行相结合的训练方法。该方法能够自动选择开销最小的模型切分策略，实现自动分布并行训练。\n\n<img src=\"https://gitee.com/mindspore/mindspore/raw/master/docs/Automatic-parallel.png\" alt=\"Automatic Parallel\" width=\"600\"/>\n\n目前MindSpore采用的是算子切分的细粒度并行策略，即图中的每个算子被切分为一个集群，完成并行操作。在此期间的切分策略可能非常复杂，但是作为一名Python开发者，您无需关注底层实现，只要顶层API计算是有效的即可。\n\n## 安装\n\n### pip方式安装\n\nMindSpore提供跨多个后端的构建选项：\n\n| 硬件平台      | 操作系统        | 状态  |\n| :------------ | :-------------- | :--- |\n| Ascend 910    | Ubuntu-x86      | ✔️   |\n|               | Ubuntu-aarch64  | ✔️   |\n|               | EulerOS-aarch64 | ✔️   |\n|               | CentOS-x86      | ✔️   |\n|               | CentOS-aarch64  | ✔️   |\n| GPU CUDA 10.1 | Ubuntu-x86      | ✔️   |\n| CPU           | Ubuntu-x86      | ✔️   |\n|               | Ubuntu-aarch64  | ✔️   |\n|               | Windows-x86     | ✔️   |\n\n使用`pip`命令安装，以`CPU`和`Ubuntu-x86`build版本为例：\n\n1. 请从[MindSpore下载页面](https://www.mindspore.cn/versions)下载并安装whl包。\n\n    ```bash\n    pip install https://ms-release.obs.cn-north-4.myhuaweicloud.com/1.2.0-rc1/MindSpore/cpu/ubuntu_x86/mindspore-1.2.0rc1-cp37-cp37m-linux_x86_64.whl\n    ```\n\n2. 执行以下命令，验证安装结果。\n\n    ```python\n    import numpy as np\n    import mindspore.context as context\n    import mindspore.nn as nn\n    from mindspore import Tensor\n    from mindspore.ops import operations as P\n\n    context.set_context(mode=context.GRAPH_MODE, device_target=\"CPU\")\n\n    class Mul(nn.Cell):\n        def __init__(self):\n            super(Mul, self).__init__()\n            self.mul = P.Mul()\n\n        def construct(self, x, y):\n            return self.mul(x, y)\n\n    x = Tensor(np.array([1.0, 2.0, 3.0]).astype(np.float32))\n    y = Tensor(np.array([4.0, 5.0, 6.0]).astype(np.float32))\n\n    mul = Mul()\n    print(mul(x, y))\n    ```\n\n    ```text\n    [ 4. 10. 18.]\n    ```\n\n使用pip方式，在不同的环境安装MindSpore，可参考以下文档。\n\n- [Ascend环境使用pip方式安装MindSpore](https://gitee.com/mindspore/docs/blob/master/install/mindspore_ascend_install_pip.md)\n- [GPU环境使用pip方式安装MindSpore](https://gitee.com/mindspore/docs/blob/master/install/mindspore_gpu_install_pip.md)\n- [CPU环境使用pip方式安装MindSpore](https://gitee.com/mindspore/docs/blob/master/install/mindspore_cpu_install_pip.md)\n\n### 源码编译方式安装\n\n使用源码编译方式，在不同的环境安装MindSpore，可参考以下文档。\n\n- [Ascend环境使用源码编译方式安装MindSpore](https://gitee.com/mindspore/docs/blob/master/install/mindspore_ascend_install_source.md)\n- [GPU环境使用源码编译方式安装MindSpore](https://gitee.com/mindspore/docs/blob/master/install/mindspore_gpu_install_source.md)\n- [CPU环境使用源码编译方式安装MindSpore](https://gitee.com/mindspore/docs/blob/master/install/mindspore_cpu_install_source.md)\n\n### Docker镜像\n\nMindSpore的Docker镜像托管在[Docker Hub](https://hub.docker.com/r/mindspore)上。\n目前容器化构建选项支持情况如下：\n\n| 硬件平台   | Docker镜像仓库                | 标签                       | 说明                                       |\n| :----- | :------------------------ | :----------------------- | :--------------------------------------- |\n| CPU    | `mindspore/mindspore-cpu` | `x.y.z`                  | 已经预安装MindSpore `x.y.z` CPU版本的生产环境。       |\n|        |                           | `devel`                  | 提供开发环境从源头构建MindSpore（`CPU`后端）。安装详情请参考<https://www.mindspore.cn/install> 。 |\n|        |                           | `runtime`                | 提供运行时环境安装MindSpore二进制包（`CPU`后端）。         |\n| GPU    | `mindspore/mindspore-gpu` | `x.y.z`                  | 已经预安装MindSpore `x.y.z` GPU版本的生产环境。       |\n|        |                           | `devel`                  | 提供开发环境从源头构建MindSpore（`GPU CUDA10.1`后端）。安装详情请参考<https://www.mindspore.cn/install> 。 |\n|        |                           | `runtime`                | 提供运行时环境安装MindSpore二进制包（`GPU CUDA10.1`后端）。 |\n\n> **注意：** 不建议从源头构建GPU `devel` Docker镜像后直接安装whl包。我们强烈建议您在GPU `runtime` Docker镜像中传输并安装whl包。\n\n- CPU\n\n    对于`CPU`后端，可以直接使用以下命令获取并运行最新的稳定镜像：\n\n    ```bash\n    docker pull mindspore/mindspore-cpu:1.1.0\n    docker run -it mindspore/mindspore-cpu:1.1.0 /bin/bash\n    ```\n\n- GPU\n\n    对于`GPU`后端，请确保`nvidia-container-toolkit`已经提前安装，以下是`Ubuntu`用户安装指南：\n\n    ```bash\n    DISTRIBUTION=$(. /etc/os-release; echo $ID$VERSION_ID)\n    curl -s -L https://nvidia.github.io/nvidia-docker/gpgkey | apt-key add -\n    curl -s -L https://nvidia.github.io/nvidia-docker/$DISTRIBUTION/nvidia-docker.list | tee /etc/apt/sources.list.d/nvidia-docker.list\n\n    sudo apt-get update && sudo apt-get install -y nvidia-container-toolkit nvidia-docker2\n    sudo systemctl restart docker\n    ```\n\n    编辑文件 daemon.json:\n\n    ```bash\n    $ vim /etc/docker/daemon.json\n    {\n        \"runtimes\": {\n            \"nvidia\": {\n                \"path\": \"nvidia-container-runtime\",\n                \"runtimeArgs\": []\n            }\n        }\n    }\n    ```\n\n    再次重启docker:\n\n    ```bash\n    sudo systemctl daemon-reload\n    sudo systemctl restart docker\n    ```\n\n    使用以下命令获取并运行最新的稳定镜像：\n\n    ```bash\n    docker pull mindspore/mindspore-gpu:1.1.0\n    docker run -it -v /dev/shm:/dev/shm --runtime=nvidia --privileged=true mindspore/mindspore-gpu:1.1.0 /bin/bash\n    ```\n\n    要测试Docker是否正常工作，请运行下面的Python代码并检查输出：\n\n    ```python\n    import numpy as np\n    import mindspore.context as context\n    from mindspore import Tensor\n    from mindspore.ops import functional as F\n\n    context.set_context(mode=context.PYNATIVE_MODE, device_target=\"GPU\")\n\n    x = Tensor(np.ones([1,3,3,4]).astype(np.float32))\n    y = Tensor(np.ones([1,3,3,4]).astype(np.float32))\n    print(F.tensor_add(x, y))\n    ```\n\n    ```text\n    [[[ 2.  2.  2.  2.],\n    [ 2.  2.  2.  2.],\n    [ 2.  2.  2.  2.]],\n\n    [[ 2.  2.  2.  2.],\n    [ 2.  2.  2.  2.],\n    [ 2.  2.  2.  2.]],\n\n    [[ 2.  2.  2.  2.],\n    [ 2.  2.  2.  2.],\n    [ 2.  2.  2.  2.]]]\n    ```\n\n如果您想了解更多关于MindSpore Docker镜像的构建过程，请查看[docker](https://gitee.com/mindspore/mindspore/blob/master/scripts/docker/README.md) repo了解详细信息。\n\n## 快速入门\n\n参考[快速入门](https://www.mindspore.cn/tutorials/zh-CN/master/beginner/quick_start.html)实现图片分类。\n\n## 文档\n\n有关安装指南、教程和API的更多详细信息，请参阅[用户文档](https://gitee.com/mindspore/docs)。\n\n## 社区\n\n### 治理\n\n查看MindSpore如何进行[开放治理](https://gitee.com/mindspore/community/blob/master/governance.md)。\n\n### 交流\n\n- [MindSpore Slack](https://join.slack.com/t/mindspore/shared_invite/zt-dgk65rli-3ex4xvS4wHX7UDmsQmfu8w) 开发者交流平台。\n- `#mindspore`IRC频道（仅用于会议记录）\n- 视频会议：待定\n- 邮件列表：<https://mailweb.mindspore.cn/postorius/lists>\n\n## 贡献\n\n欢迎参与贡献。更多详情，请参阅我们的[贡献者Wiki](https://gitee.com/mindspore/mindspore/blob/master/CONTRIBUTING.md)。\n\n## 分支维护策略\n\nMindSpore的版本分支有以下几种维护阶段：\n\n| **状态**       | **持续时间**    | **说明**                                          |\n|-------------|---------------|--------------------------------------------------|\n| Planning    | 1 - 3 months  | 特性规划。                     |\n| Development | 3 months      | 特性开发。                  |\n| Maintained  | 6 - 12 months | 允许所有问题修复的合入，并发布版本。 |\n| Unmaintained| 0 - 3 months  | 允许所有问题修复的合入，无专人维护，不再发布版本。                                                 |\n| End Of Life (EOL) |  N/A |  不再接受修改合入该分支。    |\n\n## 现有分支维护状态\n\n| **分支名** | **当前状态**  | **上线时间**          | **后续状态**                           | **EOL 日期**|\n|------------|--------------|----------------------|----------------------------------------|------------|\n| **r2.2**   | Maintained   | 2023-10-18           | Unmaintained <br> 2024-10-18 estimated |            |\n| **r2.1**   | Maintained   | 2023-07-29           | Unmaintained <br> 2024-07-29 estimated |            |\n| **r2.0**   | Maintained   | 2023-06-15           | Unmaintained <br> 2024-06-15 estimated |            |\n| **r1.10**  | End Of Life  | 2023-02-02           |                                        | 2024-02-02 |\n| **r1.9**   | End Of Life  | 2022-10-26           |                                        | 2023-10-26 |\n| **r1.8**   | End Of Life  | 2022-07-29           |                                        | 2023-07-29 |\n| **r1.7**   | End Of Life  | 2022-04-29           |                                        | 2023-04-29 |\n| **r1.6**   | End Of Life  | 2022-01-29           |                                        | 2023-01-29 |\n| **r1.5**   | End Of Life  | 2021-10-15           |                                        | 2022-10-15 |\n| **r1.4**   | End Of Life  | 2021-08-15           |                                        | 2022-08-15 |\n| **r1.3**   | End Of Life  | 2021-07-15           |                                        | 2022-07-15 |\n| **r1.2**   | End Of Life  | 2021-04-15           |                                        | 2022-04-29 |\n| **r1.1**   | End Of Life  | 2020-12-31           |                                        | 2021-09-30 |\n| **r1.0**   | End Of Life  | 2020-09-24           |                                        | 2021-07-30 |\n| **r0.7**   | End Of Life  | 2020-08-31           |                                        | 2021-02-28 |\n| **r0.6**   | End Of Life  | 2020-07-31           |                                        | 2020-12-30 |\n| **r0.5**   | End Of Life  | 2020-06-30           |                                        | 2021-06-30 |\n| **r0.3**   | End Of Life  | 2020-05-31           |                                        | 2020-09-30 |\n| **r0.2**   | End Of Life  | 2020-04-30           |                                        | 2020-08-31 |\n| **r0.1**   | End Of Life  | 2020-03-28           |                                        | 2020-06-30 |\n\n## 版本说明\n\n版本说明请参阅[RELEASE](https://gitee.com/mindspore/mindspore/blob/master/RELEASE.md)。\n\n## 许可证\n\n[Apache License 2.0](https://gitee.com/mindspore/mindspore/blob/master/LICENSE)\n"
        },
        {
          "name": "RELEASE.md",
          "type": "blob",
          "size": 331.6015625,
          "content": "# MindSpore Release Notes\n\n[查看中文](./RELEASE_CN.md)\n\n## MindSpore 2.3.0 Release Notes\n\n### Major Features and Improvements\n\n#### AutoParallel\n\n- [STABLE] Extend functional parallelism. [mindspore.shard](https://www.mindspore.cn/docs/en/r2.3.0/api_python/mindspore/mindspore.shard.html) supports now the Graph mode. In Graph mode, the parallel sharding strategy of input and weight can be set for nn.Cell/function. For other operators, the parallel strategy can be automatically configured through \"sharding_propagation\". Add [mindspore.reshard](https://www.mindspore.cn/docs/en/r2.3.0/api_python/mindspore/mindspore.reshard.html) interface that supports manual rearranging and set up a precise sharding strategy ([mindspore.Layout](https://www.mindspore.cn/docs/en/r2.3.0/api_python/mindspore/mindspore.Layout.html)) for tensors.\n- [STABLE] Added Callback interface [mindspore.train.FlopsUtilizationCollector](https://www.mindspore.cn/docs/en/r2.3.0/api_python/train/mindspore.train.FlopsUtilizationCollector.html) statistical model flops utilization information MFU and hardware flops utilization information HFU.\n- [STABLE] Add functional communication API [mindspore.communication.comm_func](https://www.mindspore.cn/docs/en/r2.3.0/api_python/mindspore.communication.comm_func.html).\n- [BETA] Optimize the memory usage of interleaved pipeline in O0 and O1 mode.\n- [BETA] AutoParallel supports automatic pipeline strategy generation in multi-nodes scenarios (not supported in single-node scenario). Need to set `parallel_mode` to ``auto_parallel`` and `search_mode` to ``recursive_programming``.\n\n#### PyNative\n\n- [STABLE] Optimize the basic data structure of PyNative and improve operator API performance.\n- [STABLE] Tensor supports [register_hook](https://www.mindspore.cn/docs/en/r2.3.0/api_python/mindspore/Tensor/mindspore.Tensor.register_hook.html) so that users can print or modify the gradient with respect to the tensor.\n- [STABLE] The PyNative mode supports the recompute function. You can use the recompute interface to reduce the peak device memory of the network.\n\n#### FrontEnd\n\n- [STABLE] Optimize Checkpoint saving and loading basic processes to improve performance by 20%.\n- [STABLE] Support CRC verification of Checkpoint files during saving and loading processes to enhance security.\n\n#### Dataset\n\n- [STABLE] Support Ascend processing backend for the following transforms: Equalize, Rotate, AutoContrast, Posterize, AdjustSharpness, Invert, Solarize, ConvertColor, Erase.\n- [STABLE] Support video files reading and parsing function. For more detailed information, see APIs: [mindspore.dataset.vision.DecodeVideo](https://www.mindspore.cn/docs/en/r2.3.0/api_python/dataset_vision/mindspore.dataset.vision.DecodeVideo.html), [mindspore.dataset.vision.read_video](https://www.mindspore.cn/docs/en/r2.3.0/api_python/dataset_vision/mindspore.dataset.vision.read_video.html#mindspore.dataset.vision.read_video), and [mindspore.dataset.vision.read_video_timestamps](https://www.mindspore.cn/docs/en/r2.3.0/api_python/dataset_vision/mindspore.dataset.vision.read_video_timestamps.html#mindspore.dataset.vision.read_video_timestamps).\n- [STABLE] Support specifying the `max_rowsize` parameter as -1 in `mindspore.dataset.GeneratorDataset`, `mindspore.dataset.Dataset.map` and `mindspore.dataset.Dataset.batch` interfaces. The size of shared memory used by the dataset multiprocessing will be dynamically allocated according to the size of the data. The `max_rowsize` parameter does not need to be adjusted manually.\n\n#### Inference\n\n- [STABLE] 14 large models such as LLaMa2, LLaMa3, and Qwen1.5 are added to support the integrated training and inference architecture to unify scripts, distributed strategies, and runtime. The period from training to inference deployment of typical large models is reduced to days. Large operators are integrated to reduce the inference latency and effectively improve the network throughput.\n\n#### PIJIT\n\n- [BETA] Support bytecode parsing for Python 3.8 and Python 3.10 to expand the supporting version of Python.\n- [BETA] Support dynamic shape and symbolic shape as input to enable the dynamic input scenarios.\n- [BETA] Enable single-step composition capability to optimize compile time\n- [BETA] Support bytecode capture with side effects (STORE_ATTR, STORE_GLOBAL, LIST_APPEND, dict.pop) by bytecode tuning, enabling auto-mixed precision, reduction of cleavage diagrams, and improved performance.\n\n#### Profiler\n\n- [STABLE] Provides a hierarchical Profiler function, controls different levels of performance data collection through the profiler_level parameter.\n- [STABLE] Profiler analyse adds a new mode parameter to configure asynchronous parsing mode to parallelize performance data parsing and training.\n- [STABLE] The Profiler adds a new data_simplification parameter, which allows users to control whether to delete redundant data after parsing the performance data to save hard disk space.\n- [STABLE] The Profiler enhances the memory analysis function. Users can collect the memory application and release information of the framework, CANN and hardware through the profile_memory parameter, and visualize and analyze the information through the [MindStudio tool](https://www.hiascend.com/forum/thread-0230130822583032044-1-1.html).\n- [BETA] In Pynative mode, Timeline integrates host profiling information, including task time and user side stack information.\n\n#### Dump\n\n- [STABLE] Enhanced synchronous & asynchronous dump functionality and adds L2Norm information to statistics dumps, and the statistic_category field to allow users to customize which statistics to save, improving dump usability. For details about the support for synchronous/asynchronous dump, see [Dump Introduction](https://www.mindspore.cn/tutorials/experts/en/r2.3.0/debug/dump.html#dump-introduction).\n- [STABLE] Improved synchronous dump functionality: Enables overflow and exception dumps through the op_debug_mode field.\n- [STABLE] Enhanced synchronous dump functionality: The stat_calc_mode field enables device-side computation of statistics (default is host-side), and the sample_mode field is configured to perform sample-based dumps, improving dump performance.\n- [STABLE] Enhanced asynchronous dump functionality: Now supports saving in complex64 and complex128 formats.\n\n#### Runtime\n\n- [Stable] Supports multi-level compilation of the staic graph by setting [mindspore.set_context(jit_config={\"jit_level\": \"O0/O1/O2\"})](https://www.mindspore.cn/docs/en/r2.3.0/api_python/mindspore/mindspore.set_context.html). The default value is empty, the framework automatically selects the optimization level according to the product category, O2 for Altas training products and O0 for the rest of the products.\n- [Stable] Staic graph supports multi-stream concurrent execution of communication calculations in O0/O1.\n- [STABLE] Add memory management API [mindspore.hal.memory](https://www.mindspore.cn/docs/en/r2.3.0/api_python/mindspore.hal.html#memory).\n- [Beta] The memory pool supports virtual memory defragmentation, and virtual memory is enabled by default under graph O0/O1.\n\n#### Ascend\n\n- [STABLE] Provide an operator memory out of bounds access detection switch on the Ascend platform, where users can detect internal memory out of bounds issues of operators on the Ascend platform by setting `mindspore.set_context (Ascend_configuration={\"op_debug_option\": \"oom\"})`.\n- [BETA] The environment variable [MS_SIMULATION_LEVEL](https://www.mindspore.cn/docs/en/r2.3.0/note/env_var_list.html) supports graph compilation O0 execution mode on the Ascend platform, which can support compilation performance and runtime memory analysis\n- [BETA] Ascend platform supports [AscendC custom operators](https://www.mindspore.cn/tutorials/experts/en/r2.3.0/operation/op_custom_ascendc.html) through AOT.\n\n### API Change\n\n#### New APIs\n\n- [STABLE] Adds [mindspore.mint](https://www.mindspore.cn/docs/en/r2.3.0/api_python/mindspore.mint.html) API, provides a lot of functional, nn, optimizer interfaces. The API usage and functions are consistent with the mainstream usage in the industry, which is convenient for users to refer to and use. The mint interface is currently an experimental interface and performs better than ops in `jit_level=\"O0\"` and pynative mode. Currently, the graph sinking mode and CPU/GPU backend are not supported, and it will be gradually improved in the future.\n\n  | mindspore.mint  |  |   | |\n  |:----|:----|:----|:----|\n  | mindspore.mint.eye |mindspore.mint.rand_like|mindspore.mint.isfinite|mindspore.mint.any|\n  | mindspore.mint.ones |mindspore.mint.rand|mindspore.mint.log|mindspore.mint.greater_equal|\n  | mindspore.mint.ones_like |mindspore.mint.gather|mindspore.mint.logical_and|mindspore.mint.all|\n  | mindspore.mint.zeros |mindspore.mint.permute|mindspore.mint.logical_not|mindspore.mint.mean|\n  | mindspore.mint.zeros_like |mindspore.mint.repeat_interleave|mindspore.mint.logical_or|mindspore.mint.prod|\n  | mindspore.mint.arange |mindspore.mint.abs|mindspore.mint.mul|mindspore.mint.sum|\n  | mindspore.mint.broadcast_to |mindspore.mint.add|mindspore.mint.neg|mindspore.mint.eq|\n  | mindspore.mint.cat |mindspore.mint.clamp|mindspore.mint.negative|mindspore.mint.ne|\n  | mindspore.mint.index_select |mindspore.mint.cumsum|mindspore.mint.pow|mindspore.mint.greater|\n  | mindspore.mint.max |mindspore.mint.atan2|mindspore.mint.reciprocal|mindspore.mint.gt|\n  | mindspore.mint.min |mindspore.mint.arctan2|mindspore.mint.rsqrt|mindspore.mint.isclose|\n  | mindspore.mint.scatter_add |mindspore.mint.ceil|mindspore.mint.sigmoid|mindspore.mint.le|\n  | mindspore.mint.narrow |mindspore.mint.unique|mindspore.mint.sin|mindspore.mint.less_equal|\n  | mindspore.mint.nonzero |mindspore.mint.div|mindspore.mint.sqrt|mindspore.mint.lt|\n  | mindspore.mint.normal |mindspore.mint.divide|mindspore.mint.square|mindspore.mint.maximum|\n  | mindspore.mint.tile |mindspore.mint.erf|mindspore.mint.sub|mindspore.mint.minimum|\n  | mindspore.mint.topk |mindspore.mint.erfinv|mindspore.mint.tanh|mindspore.mint.inverse|\n  | mindspore.mint.sort |mindspore.mint.exp|mindspore.mint.bmm|mindspore.mint.searchsorted|\n  | mindspore.mint.stack |mindspore.mint.floor|mindspore.mint.matmul|mindspore.mint.argmax|\n  | mindspore.mint.where |mindspore.mint.flip|mindspore.mint.split|mindspore.mint.cos|\n  | mindspore.mint.less |||\n\n  | mindspore.mint.nn|\n  |:----|\n  | mindspore.mint.nn.Dropout  |\n  | mindspore.mint.nn.Unfold |\n  | mindspore.mint.nn.Fold |\n  | mindspore.mint.nn.Linear|\n  | mindspore.mint.nn.BCEWithLogitsLoss |\n\n  | mindspore.mint.nn.functional||\n  |:----|:----|\n  |mindspore.mint.nn.functional.batch_norm |mindspore.mint.nn.functional.group_norm|\n  |mindspore.mint.nn.functional.fold |mindspore.mint.nn.functional.layer_norm|\n  |mindspore.mint.nn.functional.max_pool2d |mindspore.mint.nn.functional.linear|\n  |mindspore.mint.nn.functional.binary_cross_entropy |mindspore.mint.nn.functional.unfold|\n  |mindspore.mint.nn.functional.sigmoid |mindspore.mint.nn.functional.one_hot|\n  |mindspore.mint.nn.functional.tanh |mindspore.mint.nn.functional.elu|\n  |mindspore.mint.nn.functional.binary_cross_entropy_with_logits |mindspore.mint.nn.functional.gelu|\n  |mindspore.mint.nn.functional.dropout|mindspore.mint.nn.functional.leaky_relu|\n  |mindspore.mint.nn.functional.embedding  |mindspore.mint.nn.functional.silu|\n  |mindspore.mint.nn.functional.grid_sample|mindspore.mint.nn.functional.softplus|\n  |mindspore.mint.nn.functional.relu|mindspore.mint.nn.functional.softmax|\n  |mindspore.mint.nn.functional.pad||\n\n  | mindspore.mint.optim |\n  |:----|\n  | mindspore.mint.optim.AdamW |\n\n  | mindspore.mint.linalg |\n  |:----|\n  | mindspore.mint.linalg.inv |\n\n### Non-compatible Interface Changes\n\n- Interface name: `Profiler`\n\n  Changes: The performance data file generated by parsing is streamlined to save space. Delete the FRAMEWORK directory data and other redundant data after exporting the performance data. Retain only the deliverables of the profiler and the original performance data in the PROF_XXX directory to save space. Data simplification mode can be turned off by configuring the `data_simplification` parameter to `False`, which will be consistent with the performance data files generated by the historical version.\n- Interface name: The `saved_data` field in the configuration file of the dump function is `\"tensor\"`.\n\n  Changes: The name of the file to be dumped to disks is changed. `\"/\"` is replaced with `\"_\"`, and the operator name is changed to the global name of the operator.\n\n  <table>\n  <tr>\n  <td style=\"text-align:center\"> Original interface </td> <td style=\"text-align:center\"> v2.1 interface </td>\n  </tr>\n  <tr>\n  <td><pre>\n  File name format:\n  {op_type}.{op_name}.{task_id}.{stream_id}.\n  {timestamp}.{input_output_index}.{slot}.{format}.npy\n  </br>\n  Example:\n  Conv2D.Conv2D-op12.0.0.1623124369613540.\n  output.0.DefaultFormat.npy\n  </pre>\n  </td>\n  <td><pre>\n  File name format:\n  {op_type}.{op_name}.{task_id}.{stream_id}.\n  {timestamp}.{input_output_index}.{slot}.{format}.npy\n  </br>\n  Example:\n  Conv2D.Default_network-WithLossCell__backbone-AlexNet_conv3\n  -Conv2d_Conv2D-op12.0.0.1623124369613540.output.0.DefaultFormat.npy\n  </pre>\n  </td>\n  </tr>\n  </table>\n- Interface name: The `saved_data` field in the Dump function configuration file is `\"statistic\"`.\n\n  Changes: By default, `'max'`, `'min'`, `'avg'`, `'count'`, `'negative zero count'`, `'positive zero count'`, `'nan count'`,  `'negative inf count'` ,`'positive inf count'`,`'zero count'` and `'md5'`. In the 2.3 version, the `'max'`, `'min'`, and `'l2norm'` statistical items are saved by default. You can customize statistical items by configuring `'statistic_category'`.\n\n### Contributors\n\ncaifubi;candanzg;ccsszz;chaiyouheng;changzherui;chenfei_mindspore;chengbin;chengfeng27;Chong;dairenjie;DavidFFFan;DeshiChen;dingjinshan;douzhixing;emmmmtang;Erpim;fary86;fengyixing;fuhouyu;gaoyong10;GuoZhibin;guozhijian;halo;haozhang;hejianheng;Henry Shi;horcham;huandong1;huangbingjian;Jackson_Wong;jiangchenglin3;jiangshanfeng;jiangzhenguang;jiaorui;bantao;jiaxueyu;jijiarong;JuiceZ;jxl;kairui_kou;lanzhineng;LiangZhibo;lichen;limingqi107;linqingke;liubuyu;liujunzhu;liuluobin;liyan2022;liyejun;LLLRT;looop5;lujiale;luochao60;luoyang;lvxudong;machenggui;maning202007;Margaret_wangrui;master_2;mengyuanli;moran;Mrtutu;NaCN;nomindcarry;panzhihui;pengqi;qiuyufeng;qiuzhongya;Renyuan Zhang;shaoshengqi;Shawny;shen_haochen;shenhaojing;shenwei41;shij1anhan;shilishan;shiziyang;shunyuanhan;shuqian0;TAJh;tanghuikang;tan-wei-cheng;Thibaut;tianxiaodong;TronZhang;TuDouNi;VectorSL;wang_ziqi;wanghenchang;wangjie;weiyang;wudawei;wujiangming;wujueying;XianglongZeng;xiaotianci;xiaoxin_zhang;xiaoxiongzhu;xiaoyao;XinDu;xuxinglei;yangchen;yanghaoran;yanglong;yangruoqi713;yangzhenzhang;yangzishuo;Yanzhi_YI;yao_yf;yefeng;yide12;YijieChen;YingLai Lin;yuchaojie;YuJianfeng;zangqx;zhaiyukun;zhangminli;zhangqinghua;ZhangZGC;zhengxinQian;zhengzuohe;zhouyaqiang0;zhuguodong;zhupuxu;zichun_ye;zjun;zlq2020;ZPaC;zuochuanyong;zyli2020;阿琛;狄新凯;范吉斌;冯一航;胡彬;宦晓玲;黄勇;康伟;雷仪婧;李良灿;李林杰;刘崇鸣;刘力力;刘勇琪;刘子涵;吕浩宇;王禹程;熊攀;徐安越;徐永飞;俞涵;张王泽;张栩浩;郑裔;周莉莉;周先琪;朱家兴;邹文祥\n\nContributions of any kind are welcome!\n\n## MindSpore 2.3.0-rc2 Release Notes\n\n### Major Features and Improvements\n\n#### AutoParallel\n\n- [STABLE] Transpose/Sub/Add/Mul/Div/ReLU/Softmax/Sigmoid supports layout configuration.\n- [STABLE] The collective communication precision will affect network convergence. The configuration item [force_fp32_communication](https://www.mindspore.cn/docs/en/r2.3.0rc2/api_python/mindspore/mindspore.set_auto_parallel_context.html) is provided in the interface mindspore.set_auto_parallel_context. When set to True, the communication type of the reduce communication operator can be forced to be converted to float32.\n- [BETA] Pipeline parallel support Interleave. Optimize the performance when micro batch is limited.\n- [BETA] Optimize checkpoint transformation speed when using pipeline parallel, support single stage transform.\n\n#### PyNative\n\n- [BETA] Support [recompute](https://www.mindspore.cn/docs/en/r2.3.0rc2/api_python/mindspore/mindspore.recompute.html) on PyNative mode.\n- [STABLE] Support [register_hook](https://www.mindspore.cn/docs/en/r2.3.0rc2/api_python/mindspore/Tensor/mindspore.Tensor.register_hook.html#mindspore.Tensor.register_hook) on PyNative mode.\n\n### API Change\n\nAdd timeout environment variables in [dynamic networking](https://www.mindspore.cn/tutorials/experts/en/r2.3.0rc2/parallel/dynamic_cluster.html) scenarios:\n\n- `MS_TOPO_TIMEOUT`: Cluster networking phase timeout time in seconds.\n- `MS_NODE_TIMEOUT`: Node heartbeat timeout in seconds.\n- `MS_RECEIVE_MSG_TIMEOUT`: Node timeout for receiving messages in seconds.\n\nAdded new environment variable `MS_ENABLE_LCCL` to support the use of LCCL communication library.\n\n### Bug Fixes\n\n- [#I9CR96](https://gitee.com/mindspore/mindspore/issues/I9CR96) Fix the issue of insufficient timeout time causing failure for dynamic networking startup in large-scale clusters.\n- [#I94AQQ](https://gitee.com/mindspore/mindspore/issues/I94AQQ) Fixed the problem of incorrect output shape of ops.Addcdiv operator in graph mode.\n\n### Contributors\n\nThanks goes to these wonderful people:\n\nbantao,caifubi,changzherui,chenfei_mindspore,chenweifeng,dairenjie,dingjinshan,fangzehua,fanyi20,fary86,GuoZhibin,hanhuifeng,haozhang,hedongdong,Henry Shi,huandong1,huangbingjian,huoxinyou,jiangchenglin3,jiangshanfeng,jiaorui,jiaxueyu,jxl,kairui_kou,lichen,limingqi107,liuluobin,LLLRT,looop5,luochao60,luojianing,maning202007,NaCN,niyuxin94520,nomindcarry,shiziyang,tanghuikang,TronZhang,TuDouNi,VectorSL,wang_ziqi,wanghenchang,wudawei,XianglongZeng,xiaoxiongzhu,xiaoyao,yanghaoran,Yanzhi_YI,yao_yf,yide12,YijieChen,YingLai Lin,yuchaojie,YuJianfeng,zangqx,zhanghanLeo,ZhangZGC,zhengzuohe,zhouyaqiang0,zichun_ye,zjun,ZPaC,zyli2020,冯一航,李林杰,刘力力,王禹程,俞涵,张栩浩,朱家兴,邹文祥\n\nContributions of any kind are welcome!\n\n## MindSpore Lite 2.3.0-rc2 Release Notes\n\n### Major Features and Improvements\n\n- [STABLE] Support the configuration of FlashAttention related properties in the configuration file used by the cloud-side conversion tool.\n- [STABLE] Support multi-devices memory sharing.\n\n### Contributors\n\nThanks goes to these wonderful people:\n\nemmmmtang,熊攀\n\nContributions of any kind are welcome!\n\n## MindSpore 2.3.0-rc1 Release Notes\n\n### Major Features and Improvements\n\n#### DataSet\n\n- [STABLE] Support integrity check, encryption and decryption check for MindRecord to protect the integrity and security of user data.\n- [STABLE] MindRecord api changes: FileWriter.open_and_set_header is deprecated since it has been integrated into FilterWriter, if the old version code reports an error, delete this call; Add type checking for data in FileWriter to ensure that the data type defined by the Schema matches the real data type; The return value of all methods under Mindrecord are removed, replaced by an exception when processing error is occurred.\n- [STABLE] Support Ascend processing backend for the following transforms: ResizedCrop, HorizontalFlip, VerticalFlip, Perspective, Crop, Pad, GaussianBlur, Affine.\n- [STABLE] Optimized the content of data processing part in model migration guide, providing more examples to compare with third-party frameworks.\n- [STABLE] Optimized the parsing efficiency of TFRecordDataset in multiple data columns scenario, improving the parsing performance by 20%.\n\n#### PIJIT\n\n- [BETA]PIJit analyzes and adjusts the Python bytecode and performs graph capture and graph optimization on the execution flow. Supported Python codes are executed in static graph mode, and unsupported ones are divided into subgraphs and executed in dynamic graph mode, automatically achieving dynamic and static unification. Users can enable the PIJit function by decorating the function with @jit(mode=\"PIJit\", jit_config={options:value}).\n\n#### Inference\n\n- [DEMO] The integrated architecture of large model inference, upgrade, training, and promotion unifies scripts, distributed policies, and runtime. The period from training to inference deployment of typical large models is reduced to days. Large operators are integrated to reduce the inference latency and effectively improve the network throughput.\n\n#### AutoParallel\n\n- [STABLE] Add msrun startup method to launch distributed job with single instruction.\n- [STABLE] Add to be deprecated hint for RankTable startup method.\n- [STABLE] Eliminate redundant constants in graph mode to improve compilation performance and memory overhead.\n- [STABLE] The subgraph scenario optimizer parallelizes the first subgraph inline, allowing some computation and communication masking under pipeline parallelism to be performed.\n- [STABLE] Communication information export: export model communication information (communication domain, communication volume) during compilation, and input it to the cluster as the basis for communication scheduling.\n- [STABLE] Pipeline parallel inference is optimized, eliminates shared weights forwarding between stages, improving execution performance. Supports automatic broadcast of pipeline inference results, improving the usability of autoregressive inference.\n- [STABLE] Operator-level parallel sharding supports the configuration of the mapping between the device layout and tensor layout during MatMul/Add/LayerNorm/GeLU/BiasAdd operator sharding.\n- [STABLE] Supports gradient communication and backward calculation overlapping in the data parallel dimension.\n- [STABLE] Single device simulation compilation, used to simulate the compilation process of a certain device in multi device distributed training, assisting in analyzing the compilation processes and memory usage on the front and back ends.\n- [STABLE] Implement ops.Tril sharding to reduce the memory and performance requirements on a single device.\n- [BETA] Supports the fusion between communication operators and computing operators, in order to overlap communication overheads with computation and improve network performance.\n- [BETA] Load checkpoints and compile graphs in parallel to accelerate fault recovery.\n\n#### Runtime\n\n- [BETA] Support O0/O1/O2 multi-level compilation to improve static graph debugging and tuning capabilities.\n\n#### FrontEnd\n\n- [STABLE] The framework supports the bfloat16 data type. dtype=mindspore.bfloat16 can be specified when a tensor is created.\n- [STABLE] The syntax support capability of the rewrite component is optimized, syntaxs such as class variables, functions, and control flows can be parsed.\n- [STABLE] New context setting: debug_level. User can use mindspore.set_context(debug_level=mindspore.DEBUG) to get more debug information.\n\n#### Profiler\n\n- [BETA] Dynamically start and stop profiling. Users can collect profiling data in real time according to the training situation, reducing the amount of data collected.\n- [BETA] Profiling the communication operator time-consuming matrix. Users can find cluster communication performance bottlenecks by analyzing the communication operator time-consuming matrix.\n- [BETA] Improve the performance of Ascend environment in parsing profiling data.\n- [BETA] Supports offline analysis of data generated by Profiling. Users can collect data first and then parse the data as needed.\n- [BETA] Supports collecting performance data of HBM, PCIe, and l2_cache to enrich performance analysis indicators.\n\n#### Dump\n\n- [BETA] The statistical information saved by Dump records MD5 values, and users can determine small differences in tensor values through MD5 values.\n- [BETA] Dump supports the float16 data type and supports users to locate float16 type operator accuracy issues.\n\n#### PyNative\n\n- [STABLE] Reconstruct the single operator calling process for dynamic graphs to improve the performance of dynamic graphs.\n\n#### Ascend\n\n- [BETA] Support set configuration options of CANN, which are divided into two categories: global and session. Users can configure them through mindspore.set_context(Ascend_configuration={\"ge_options\": {\"global\": {\"global_option\": \"option_value\"}, \"session\": {\"session option\": \"option_value\"}}).\n\n#### API Change\n\n- Add mindspore.hal API to support stream, event, and device management capabilities.\n- Add mindspore.multiprocessing API to provide the capability of creating multiple processes.\n\n#### Operators\n\n- [BETA] mindspore.ops.TopK now supports the second input k as an int32 type tensor.\n\n### Bug Fixes\n\n- [#I92H93] Fixed the issue of 'Launch kernel failed' when using the Print operator to print string objects on the Ascend platform.\n- [#I8S6LY] Fixed RuntimeError: Attribute dyn_input_sizes of Default/AddN-op1 is [const vector]{}, of which size is less than 0 error of variable-length input operator, such as AddN or Concat, for dynamic shape process in graph mode on the Ascend platform.\n- [#I9ADZS] Fixed the data timeout issue in network training due to inefficient dataset recovery in the fault recovery scenario.\n\n### Contributors\n\nThanks goes to these wonderful people:\n\nAlanCheng511，AlanCheng712，bantao，Bingliang，BJ-WANG，Bokai Li，Brian-K，caifubi，cao1zhg，CaoWenbin，ccsszz，chaiyouheng，changzherui，chenfei_mindspore，chengbin，chengfeng27，chengxb7532，chenjianping，chenkang，chenweifeng，Chong，chuht，chujinjin，Cynthia叶，dairenjie，DavidFFFan，DeshiChen，douzhixing，emmmmtang，Erpim，fangzhou0329，fary86，fengxun，fengyixing，fuhouyu，gaoshuanglong，gaoyong10，GaoZhenlong，gengdongjie，gent1e，Greatpan，GTT，guoqi，guoxiaokang1，GuoZhibin，guozhijian，hangq，hanhuifeng，haozhang，hedongdong，hejianheng，Henry Shi，heyingjiao，HighCloud，Hongxing，huandong1，huangbingjian，HuangLe02，huangxinjing，huangziling，hujiahui8，huoxinyou，jiangchenglin3，jianghui58，jiangshanfeng，jiaorui，jiaxueyu，JichenZhao，jijiarong，jjfeing，JoeyLin，JuiceZ，jxl，kairui_kou，kate，KevinYi，kisnwang，lanzhineng，liangchenghui，LiangZhibo，lianliguang，lichen，ligan，lihao，limingqi107，ling，linqingke，liruyu，liubuyu，liuchao，liuchengji，liujunzhu，liuluobin，liutongtong9，liuzhuoran2333，liyan2022，liyejun，LLLRT，looop5，luochao60，luojianing，luoyang，LV，machenggui，maning202007，Margaret_wangrui，MaZhiming，mengyuanli，MooYeh，moran，Mrtutu，NaCN，nomindcarry，panshaowu，panzhihui，PingqiLi，qinzheng，qiuzhongya，Rice，shaojunsong，Shawny，shenwei41，shenyaxin，shunyuanhan，silver，Songyuanwei，tangdezhi_123，tanghuikang，tan-wei-cheng，TingWang，TronZhang，TuDouNi，VectorSL，WANG Cong，wang_ziqi，wanghenchang，wangpingan，wangshaocong，wangtongyu6，weiyang，WinXPQAQ，wtcheng，wudawei，wujiangming，wujueying，wuweikang，wwwbby，XianglongZeng，xiaosh，xiaotianci，xiaoxin_zhang，xiaoxiongzhu，xiaoyao，XinDu，xingzhongfan，yanghaoran，yangluhang，yangruoqi713，yangzhenzhang，yangzishuo，yanjiaming，Yanzhi_YI，yao_yf，yefeng，yeyunpeng2020，yide12，YijieChen，YingLai Lin，YingtongHu，youshu，yuchaojie，YuJianfeng，zangqx，zby，zhaiyukun，zhangdanyang，zhanghaibo，zhanghanLeo，zhangminli，zhangqinghua，zhangyanhui，zhangyifan，zhangyinxia，zhangyongxian，ZhangZGC，zhanzhan，zhaoting，zhengyafei，zhengzuohe，ZhihaoLi，zhouyaqiang0，zhuguodong，zhumingming，zhupuxu，zichun_ye，zjun，zlq2020，ZPaC，zuochuanyong，zyli2020，陈宇，代宇鑫，狄新凯，范吉斌，冯一航，胡彬，宦晓玲，黄勇，康伟，李良灿，李林杰，刘崇鸣，刘力力，刘勇琪，吕浩宇，没有窗户的小巷，王禹程，吴蕴溥，熊攀，徐安越，徐永飞，许哲纶，俞涵，张峻源，张树仁，张王泽，张栩浩，郑裔，周莉莉，周先琪，朱家兴，邹文祥\n\nContributions of any kind are welcome!\n\n## MindSpore 2.2.13 Release Notes\n\n### API Change\n\nAdd timeout environment variables in dynamic networking scenarios:\n\n- `MS_TOPO_TIMEOUT`: Cluster networking phase timeout time in seconds.\n- `MS_CLUSTER_RETRY_NUM`: Number of node's retrying registration during cluster networking phase.\n- `MS_NODE_TIMEOUT`: Node heartbeat timeout in seconds.\n- `MS_RECEIVE_MSG_TIMEOUT`: Node timeout for receiving messages in seconds.\n\n### Bug Fixes\n\n- [#I9CR96] Fix the issue of insufficient timeout time causing failure for dynamic networking startup in large-scale clusters.\n\n### Contributors\n\nThanks goes to these wonderful people:\n\nZPaC, limingqi107, lizhenyu, jiangshanfeng\n\nContributions of any kind are welcome!\n\n## MindSpore 2.2.12 Release Notes\n\n### Major Features and Improvements\n\n- [STABLE] Optimize scnarios where network parameters are initialized by fp32, and optimizer parallel mode is on, reducing the amount of Cast operator.\n- [STABLE] Add detection and processing capabilities to silent fault detection. Silent faults may lead to error during training procedures, this helps users to prevent or lower the cost of fault location, which caused by silent faults.\n\n### Bug Fixes\n\n- [#I97D1L] Fix ReduceLROnPlateau, LRScheduler, CosineAnnealingWarmRestarts dynamic learning rate related interface sample error.\n- [#I970HV] Fix the problem where order of AllGather/ReduceScatter between two cards is not preserved.\n- [#I99JPI] Fix load checkpoint for bfloat16 parameter during vague load mode.\n\n### Contributors\n\nThanks goes to these wonderful people:\n\nyao_yf, YijieChen, 冯一航, yuchaojie, 李良灿, YuJianfeng, huangxinjing, GuoZhibin, looop5\n\nContributions of any kind are welcome!\n\n## MindSpore 2.2.11 Release Notes\n\n### Major Features and Improvements\n\n#### scipy\n\n- [STABLE] Add new API mindspore.scipy.optimize.linear_sum_assignment in scipy module to solve the linear sum assignment problem. It can find the least-cost assignment based on a given cost matrix.\n\n### Bug Fixes\n\n- [#I8JVRU] Fixed the problem where the results of the bernoulli random operator running twice on the GPU are probabilistically consistent.\n- [#I8OC32] Fixed the segmentation fault error because the MatrixSetDiagV3 operator does not verify abnormal input.\n\n### Contributors\n\nThanks goes to these wonderful people:\n\nfary86, wanghenchang, haozhang, mengyuanli, emmmmtang, luoyang, zhupuxu, zhangyongxian, liuluobin, LLLRT, TuDouNi, hujiahui8, wangtongyu6, ligan, zhuguodong, yanghaoran, YingtongHu, liyejun, zjun, 徐永飞, chuht, 张树仁, 徐安越, DeshiChen, shenyaxin, liujunzhu, shunyuanhan, yuchaojie, yao_yf, 没有窗户的小巷, yeyunpeng2020, weiyang, KevinYi, hedongdong, zhouyaqiang0, Margaret_wangrui, zhanghaibo, moran, huangziling, 朱家兴, GuoZhibin, 李良灿, jiaxueyu, gaoyong10, Greatpan, 宦晓玲, melody, 俞涵, jiangshanfeng, XinDu, ling, caifubi, zhangyinxia, gengdongjie, Erpim, XianglongZeng, zhangminli, fengyixing, 冯一航, 黄勇, panzhihui, 胡彬, linqingke, wangshaocong\n\nContributions of any kind are welcome!\n\n## MindSpore Lite 2.2.11 Release Notes\n\n### Bug Fixes\n\n- [#I8TPLY] Fixed SSD MobileNetV2 FPN network inference error on Atlas inference series products(configured with Ascend 310P AI processor).\n\n### Contributors\n\nThanks goes to these wonderful people:\n\nwangtongyu6, zhuguodong, 徐永飞, 徐安越, yeyunpeng2020, moran, XinDu, gengdongjie.\n\nContributions of any kind are welcome!\n\n## MindSpore 2.2.10 Release Notes\n\n### Major Features and Improvements\n\n#### Operators\n\n- [STABLE] FastGelu, BatchMatMul, AllReduce, AllGather, Broadcast, ReduceScatter support bfloat16 data type\n- [STABLE] AllGather support uint8 data type\n\n### Bug Fixes\n\n- [#I8ALW3] Fixed networks including Faster R-CNN, DeepText, MaskRCNN-ResNet50, which had errors while training RandomChoiceWithMask operator in Ascend 910 8P scenario.\n- [#I8LKG7] Fixed graph compilation error of UNet-2D in Ascend 910 1P/8P scenario.\n- [#I8KU3X] Fixed CRNN-ResNet34 network, which stuck in training phase in Ascend 910 1P/8P PyNative mode.\n- [#I8KTHH] Fixed BERT network error when training without allreduce grouped fusion with enable_parallel_optimizer=True, in Ascend 910 8P scenario.\n\n### Contributors\n\nThanks goes to these wonderful people:\n\n李林杰, TuDouNi, chengxb7532, Henry Shi, rms-infer-type, 朱家兴, zhouyaqiang0, tanghuikang, gaoyong10, gengdongjie, yao_yf, hujiahui8, hanhuifeng, shenyaxin, KevinYi, 冯一航, chengfeng27, JuiceZ, zhangyanhui, jijiarong, xiaoxiongzhu, 没有窗户的小巷, ling, liyan2022, haozhang, zangqx, xiaoyao, liujunzhu, 胡彬, panzhihui, wangshaocong, linqingke, jianghui58, qiuzhongya, yangruoqi713, zhangminli, moran, 王禹程, shaojunsong, wangtongyu6, zhupuxu, luoyang, 徐安越, qinzheng, caifubi, 徐永飞, chenkang, youshu, XinDu, liubuyu, jxl, yeyunpeng2020, huoxinyou, yefeng, jiaorui, wangpingan, cao1zhg, zjun, zyli2020, yanjiaming, Cynthia叶, 胡安东, 李良灿, liruyu, liuluobin, lihao, huangbingjian, YijieChen, jjfeing, looop5, 刘力力, xiaoxin_zhang, yangluhang, chenweifeng, jiangshanfeng, zichun_ye, 陈宇, NaCN, ligan, YingLai Lin, huangziling, chenjianping, DeshiChen, chengbin, kairui_kou, ccsszz, yanghaoran, zhangdanyang, Yanzhi_YI, zhengzuohe, hangq, TronZhang, wanghenchang, HighCloud, 吕浩宇, VectorSL, ZPaC, mengyuanli, maning202007, 刘勇琪, r1chardf1d0, fary86, 刘崇鸣, yuchaojie, douzhixing, fengyixing\n\nContributions of any kind are welcome!\n\n## MindSpore Lite 2.2.10 Release Notes\n\n### Bug Fixes\n\n- [#I8K7CC] Optimize error message when non-string segments are passed to get_model_info.\n\n### Contributors\n\nThanks goes to these wonderful people:\n\ngengdongjie, zhangyanhui, xiaoxiongzhu, wangshaocong, jianghui58, moran, wangtongyu6, 徐安越, qinzheng, 徐永飞, youshu, XinDu, yeyunpeng2020, yefeng, wangpingan, zjun, 胡安东, 刘力力, 陈宇, chenjianping, kairui_kou, zhangdanyang, hangq, mengyuanli, 刘崇鸣\n\nContributions of any kind are welcome!\n\n## MindSpore 2.2.1 Release Notes\n\n### Bug Fixes\n\n- [#I7R3R5] Fixed the problem that the network precision of the ResNet-50 on the Ascend platform deteriorates.\n- [#I8A9RH] Fixed an issue where the DBNet(ResNet-50) network precision on the Ascend platform deteriorates.\n- [#I8B8IW] Fixed the segment error caused by out-of-bounds multi-dimensional tensor assignment.\n- [#I8J0F4] Fixed an issue where the multidimensional Tensor extension dimension fails to be executed in the dynamic graph.\n- [#I87P3P] Fixed an issue where the compilation cache fails to be loaded during secondary training on the Ascend platform.\n- [#I86GP9] Fixed an issue where the UNet3D network inference precision deteriorates on the Ascend platform.\n- [#I89B4K] Fixed an issue where the dynamic rank execution of dynamic graphs on the Windows platform is suspended.\n- [#I8CX0C] Fixed an issue where dynamic images occasionally fail in mixed precision mode on the Ascend platform.\n- [#I8BGCF] Fixed an issue where a segment error occurs when the command is executed in dynamic diagram mode of the AirNet network on the Ascend platform.\n- [#I8L5DS] Fixed an issue where the ResNet-50 image segmentation network dynamic image is executed slowly on the Ascend platform.\n\n### Contributors\n\nThanks goes to these wonderful people:\n\nyufan, dingcheng, lvzhangcheng, zhunaipan, fangwenyi, weiyang, changzherui, chujinjin, zangqingxiang, yuchaojie, wuweikang, tanghuikang, xiaoyao, huangbinjian, zhoupeichen, chenfei_mindspore, hedongdong, wangnan, zhengzuohe, yanghaoran, zouliqin, luoyang, liuchongmin, lujiale, machenggui, wangcong, lixiangyi, wangting, huangyong\n\nContributions of any kind are welcome!\n\n## MindSpore Lite 2.2.1 Release Notes\n\n### Bug Fixes\n\n- [#I88055] Fixed a function issue caused by incorrect format setting of the gridsample operator in MindSpore Lite inference.\n- [#I8D80Y] The MindSpore Lite inference single-operator invoking process resources are not released and exits abnormally.\n\n### Contributors\n\nThanks goes to these wonderful people:\n\nzhanghaibo, wangsiyuan, wangshaocong, chenjianping\n\nContributions of any kind are welcome!\n\n## MindSpore 2.2.0 Release Notes\n\n### Major Features and Improvements\n\n#### DataSet\n\n- [STABLE] The `row_size` parameter of data operation map/batch is extended to support passing list, which stands for [Input Shared Memory, Output Shared Memory], so as to flexibly control the size of shared memory in multi-process mode.\n- [STABLE] Provide 100% mindspore.dataset and mindspore.dataset.transforms samples for reference.\n- [STABLE] ConcatDataset supports global sampling. After combining data from multiple sources using concat operation, data can be globally sampled randomly to enhance data diversity.\n- [STABLE] When the model.train API is used for training, TimeMonitor(.., data_time=True) can be used to monitor data processing performance in real time.\n- [STABLE] Introduced the jemalloc library to solve the problem of slow memory rise due to untimely memory debris recovery in extreme scenarios.\n\n#### FrontEnd\n\n- [STABLE] Support adding decorator @lazy_inline to make a graph generated from cell being inlined lazily, which can improve the compilation performance effectively.\n- [STABLE] Optimize the function of mixed precision training, support automatic rewriting of Python scripts through rewrite to achieve mixed precision strategies, and support automatic parsing of functions, branch statements, and other syntax.\n- [STABLE] Mixed precision function optimization, ReWrite supports syntax parsing of class functions and branch statements, and extends O1 functionality.\n- [STABLE] Optimize the dynamic learning rate function and add APIs such as MultiStepLR; function get_lr and global_step decoupling, extending optimizer module functionality.\n- [STABLE] Optimize API code samples, API difference tables, and tutorials for using higher-order functions.\n\n#### Operator\n\n- [STABLE] Add new operator primitive `mindspore.ops.Dense`.\n- [STABLE] Add the random number operator state management feature, which allows the random number operator to save the state of the random number, and can be stably reproduced in scenarios such as model parallelism and recalculation. Currently, it only supports CPU/GPU platforms, and the involved random number operators include: `mindspore.ops.Multinomial`, `mindspore.ops.MultinomialWithReplacement`, `mindspore.ops.ParameterizedTruncatedNormal`, `mindspore.ops.StandardLaplace`, `mindspore.ops.StandardLaplace`, `mindspore.ops.Uniform`, `mindspore.ops.UniformInt`, `mindspore.ops.UniformReal`, `mindspore.ops.UniformInt`, `mindspore.ops.Dropout`, `mindspore.ops.RandomChoiceWithMask`, `mindspore.ops.RandomCategorical`, `mindspore.ops.RandomShuffle`, `mindspore.ops.RandamGamma`, `mindspore.ops.RandomPoisson` and `mindspore.ops.TruncatedNormal`.\n- [STABLE] When a GPU operator encounters an illegal input scenario, it supports asynchronously printing error logs in the CUDA kernel of the operator to the Host side and interrupting the execution of the current CUDA Stream, improving the efficiency of user operator problem positioning.\n\n#### PyNative\n\n- [STABLE] Support viewing mechanism in PyNative mode.\n- [STABLE] Function enhancement in PyNative mode: sens supports dict input type.\n\n#### Ascend\n\n- [STABLE] Supports user configurable operator high-precision/high-performance mode, users can use `context.set_context(ascend_config={\"op_precision_mode\": \"/path/to/op_precision_config_file\"})` to configure high-precision/high-performance modes for some TBE operators.\n- [BETA] Supports user configurable operators for fp16-in and fp32-out, users can use `context.set_context(ascend_config={\"precision_mode\": \"force_fp32\"})` to configure fp16-in and fp32-out for the TBE Cube operators.\n- [BETA] Remove the strong binding between `jit_level=\"O3\"` and GE processes, so users no longer need to set `jit_level=\"O3\"` when executing GE processes.\n\n#### Parallel\n\n- [STABLE] Support the gradient accumulation feature in non-pipeline parallel scenarios in semi-automatic/fully automatic mode. Users can enable gradient accumulation by writing `net = GradAccumulationCell(net, micro_size)`. The gradient accumulation feature is compatible with the  lazy_inline feature.\n\n#### Inference\n\nSince version 2.2, the MindSpore main release package does not provide the inference interface enabling for the Ascend 310. If you need to use the inference interface, install the MindSpore Lite release package or download the MindSpore version earlier than 2.0. For details about how to install and use MindSpore Lite, see <https://www.mindspore.cn/lite/en>. HUAWEI Ascend 310 (Ascend) is an energy-efficient and highly integrated AI processor for edge scenarios. It supports inference on MindIR models. In the earlier version, MindSpore provides two methods for enabling inference on the Ascend 310 hardware:\n\n1. The MindSpore main release package provides the matching Ascend 310 version that supports C++ inference interfaces.\n2. The MindSpore Lite release package provides the matching Ascend version and supports C++ and Java inference.\n\nThe C++ APIs provided by the two solutions are basically the same. In the future, MindSpore Lite is used instead of building and maintaining two sets of interfaces. The original 310 inference service built based on the MindSpore main release package can be switched to MindSpore Lite with a few modifications. For details, see <https://www.mindspore.cn/docs/en/master/faq/inference.html>.\n\n### Bug fixes\n\n- [I7SDA0] Fixed an issue where the accuracy of the CRNN network deteriorates on the NES platform.\n- [I7T4QK] Fixed an issue where the inference precision of the WGAN network deteriorates on the OptiX OSN 8800 platform.\n- [I7TJ8Z] Fixed an issue where the inference precision of the LGTM network deteriorates on the OptiX OSN 8800 platform.\n- [I7M58O] Fixed ASR-dynamic network training core dump issue on Ascend platform.\n- [I7L6B6] Fixed an issue where child processes do not exit in some scenarios when dataset is in multi-process mode.\n- [I7L7AE] Fixed an issue where dataset pipeline contains repeat operations and dynamic batchinfo.get_epoch_num() is incorrectly used in dataset.batch.\n- [I7UY7G] Rectify the file permission modification error in OBSMindDataset.\n\n### Contributors\n\nThanks goes to these wonderful people:\nbantao, Bingliang, BJ-WANG, Brian-K, caifubi, ccsszz, changzherui, chenfei_mindspore, chengfeng27, chenhaozhe, chenjianping, chenkang, chenweifeng, chuht, chujinjin, CShu0507, Cynthia叶, DeshiChen, douzhixing, Erpim, Etienne, fary86, fengxun, fengyixing, gaoshuanglong, Gaoxiong, gaoyong10, GaoZhenlong, Greatpan, GuoZhibin, guozhijian, hangq, hanhuifeng, haozhang, hedongdong, Henry Shi, HighCloud, Hongxing, huangbingjian, huanghui, huangxinjing, huangziling, hujiahui8, huoxinyou, HWalkingMan, jianghui58, jiangshanfeng, jiaorui, jijiarong, jjfeing, JuiceZ, jxl, KevinYi, kisnwang, KXiong, lanzhineng, Li Qingguo, LiangZhibo, lianliguang, ligan, lihao, Lihoon, limingqi107, ling, linqingke, liruyu, liubuyu, liuchao, liujunzhu, liuluobin, liupeng303, liutongtong9, liyan2022, liyejun, looop5, luochao60, luojianing, luoyang, machenggui, maning202007, Margaret_wangrui, MaZhiming, mengyuanli, moran, NaCN, nomindcarry, panshaowu, panzhihui, qinzheng, qiuzhongya, r1chardf1d0, shaojunsong, shenwei41, shenyaxin, shenzhangyi, Shira Zaloshinski, shunyuanhan, tangdezhi_123, tanghuikang, tan-wei-cheng, tan-wei-cheng-3260, TronZhang, TuDouNi, VectorSL, wang_ziqi, wanghenchang, wangpingan, wangshaocong, wangtongyu6, wtcheng, wujueying, XianglongZeng, xiaotianci, xiaoxin_zhang, xiaoxiongzhu, xiaoyao, xiaoyuanyuan, XinDu, xujinliang, xupan, yanghaoran, yangluhang, yangruoqi713, yangsijia, yangzhenzhang, yangzishuo, yanjiaming, Yanzhi_YI, yao_yf, yefeng, yeyunpeng2020, yide12, YijieChen, YingLai Lin, YingtongHu, yonibaehr, youshu, yuchaojie, YuJianfeng, zangqx, zhaizhiqiang, zhangbuxue, zhangchunlei, zhangdanyang, zhangdong, zhanghaibo, zhangminli, zhangqi, zhangqinghua, zhangyanhui, zhangyifan, zhangyongxian, zhangzhen, zhangzheng, zhanzhan, zhengzuohe, ZhihaoLi, zhoufeng, zhouyaqiang0, zhuguodong, zhupuxu, zichun_ye, zjun, ZPaC, zuochuanyong, zyli2020, 陈宇, 程超, 范吉斌, 冯浩, 冯一航, 胡彬, 宦晓玲, 黄勇, 雷元哲, 黎冠新, 李良灿, 李林杰, 刘崇鸣, 刘力力, 刘思铭, 刘勇琪, 吕浩宇, 没有窗户的小巷, 沈竞兴, 王禹程, 王振邦, 徐安越, 徐永飞, 俞涵, 张澍坤, 周超, 朱家兴\n\nContributions of any kind are welcome!\n\n## MindSpore Lite 2.2.0 Release Notes\n\n### Major Features and Improvements\n\n#### FlashAttention Operator Fusion\n\n- [STABLE] The OptiX OSN Ascend 910 series supports the FlashAttention large operator fusion of the LLAMA and stable diffusion models.\n\n## MindSpore 2.1.1 Release Notes\n\n### Bug fixes\n\n- [I7Q9RX] The Ascend platform supports adaptive identification of different hardware types.\n- [I7SDA0] Fixed an issue where the accuracy of the CRNN network deteriorates on the NES platform.\n- [I7T4QK] Fixed an issue where the inference precision of the WGAN network deteriorates on the OptiX OSN 8800 platform.\n- [I7TJ8Z] Fixed an issue where the inference precision of the LGTM network deteriorates on the OptiX OSN 8800 platform.\n\n### Contributors\n\nThanks goes to these wonderful people:\n\nchangzherui, chenfei_mindspore, chenjianping, chenkang, chenweifeng, chujinjin, fangwenyi, GuoZhibin, guozhijian, hangq, hanhuifeng, haozhang, hedongdong, You Shu, Zhou Feng, Dai Yuxin\n\nContributions of any kind are welcome!\n\n## MindSpore Lite 2.1.1 Release Notes\n\n### Major Features and Improvements\n\n- [STABLE] MindSpore Lite Cloud Inference adds support for Python 3.8 and Python 3.9\n\n## MindSpore 2.1.0 Release Notes\n\n### Major Features and Improvements\n\n#### FrontEnd\n\n- [BETA] JIT Fallback supports variable scenarios. In static graph mode, JIT Fallback supports return of Dict type and Scalar type, supports property setting of non-Parameter type objects, supports partial in-place modification operations of List, and supports third-party libraries such as NumPy. Moreover, it supports related operations of user-defined classes and supports Python basic operators and built-in functions to use more data types. It is compatible with features like control flow, side effects, automatic differentiation. For more details, please refer to [Static Graph Syntax Support](https://www.mindspore.cn/docs/en/r2.1/note/static_graph_syntax_support.html).\n\n- [BETA] In static graph mode, the error message of using undefined variables in the control flow scene is optimized. When using variables defined in if, while, and for control flow branches, the variables need to be initialized and defined before the control flow.\n\n- [STABLE] Add module ReWrite, support the ability to modify multiple network in batches based on customized rules.\n\n- [BETA] Add optim_ex module for optimizers, extend the current functionality, support parameter grouping for every parameter in the optimizer, and support parameter modification by assignment while training.\n\n- [STABLE] Optimize PyTorch and MindSpore API Mapping Table, specify the differences between APIs among functionality, parameter, input, output and specialized cases.\n\n#### PyNative\n\n- Optimize the performance of dynamic shape scenes in PyNative mode.\n\n#### DataSet\n\n- [STABLE] Optimize the memory structure of MindRecord data files. Memory consumption can be reduced 60% when loading 100TB+ data for training.\n- [STABLE] Support single-thread execution of data processing pipeline, and users can add code in the data pipeline for debugging.\n- [STABLE] Optimize the performance of TFRecordDataset to improve the performance of dataset loading by 60%+. Optimize the performance of batch to improve the performance by 30% for the scenarios with large number of batch.\n- [STABLE] Optimize API documentation of [mindspore.dataset](https://www.mindspore.cn/docs/en/r2.1/api_python/mindspore.dataset.html) and [mindspore.dataset.transforms](https://www.mindspore.cn/docs/en/r2.1/api_python/mindspore.dataset.transforms.html). Four new sample libraries have been added to show the effect of data enhancement, namely: [Load & Process Datasets Using Data Pipeline](https://www.mindspore.cn/docs/en/r2.1/api_python/mindspore.dataset.html#quick-start-of-dataset-pipeline), [Visual Transformation Sample Library](https://www.mindspore.cn/docs/en/r2.1/api_python/mindspore.dataset.transforms.html#module-mindspore.dataset.vision), [Text Transform Sample Library](https://www.mindspore.cn/docs/en/r2.1/api_python/mindspore.dataset.transforms.html#module-mindspore.dataset.text), [Audio Transform Sample Library](https://www.mindspore.cn/docs/en/r2.1/api_python/mindspore.dataset.transforms.html#module-mindspore.dataset.audio)\n\n#### AutoParallel\n\n- [STABLE] Support offload parameters or intermediate activations to the CPU or NVMe storage during training process. Users can enable this offload feature by configuring context to scale up the trainable model size.\n\n- [STABLE] Enhanced automatic parallel capability including:\n\n  1. Performance of automatic strategy for typical networks is no less than 90% of default configuration.\n\n  2. Support 3D hybrid parallel training: automatic operator-level strategy generation combined with manual configured pipeline partition.\n\n#### Runtime\n\n- [STABLE] Upgrade OpenMPI version to 4.1.4.\n- [STABLE] Upgrade NCCL version to 2.16.5.\n- [STABLE] Assign rank id continuously in same node when using dynamic cluster to launch distributed jobs.\n- [STABLE] No adaptation code is required for Scheduler node. The script of Scheduler could be identical to that of Worker.\n\n#### Ascend\n\n- [STABLE] Support dump assisted debug information for operator AIC Error scenario. The information includes the operator task name, stream ID, input/output/workspace address and so on.\n- [STABLE] Provide default processing mechanism, which skips its execution,  for CANN operators for empty Tensor output scenarios.\n- [STABLE] Supplement debug information when network model fails to execute in graph mode. The debug information will saved in a CSV file in rank_${id}/exec_order/, recording the task ID and stream ID of each task.\n\n#### Profiler\n\n- [STABLE] The Profiler supports the collection of time-consuming data from all phases on the Host side.\n- [BETA] The Profiler supports the collection of memory data from all phases on the Host side.\n- [BETA] The Profiler supports the collection of data processing operator time consumption.\n\n### API Change\n\n- `mindspore.dataset.GraphData`, `mindspore.dataset.Graph`, `mindspore.dataset.InMemoryGraphDataset`, `mindspore.dataset. ArgoverseDataset` are no longer evolved and are deprecated. Use [MindSpore Graph Learning](https://gitee.com/mindspore/graphlearning) for related functional replacements. When replacing networks in Model repositories that use this API, please refer to [GCN](https://gitee.com/mindspore/graphlearning/tree/master/model_zoo/gcn) for GCN and [GAT](https://gitee.com/mindspore/graphlearning/tree/master/model_zoo/gat).\n- `mindspore.set_context` adds `jit_syntax_level` option, which is used to set JIT syntax support level. For more details, please refer to [set_context](https://www.mindspore.cn/docs/en/r2.1/api_python/mindspore/mindspore.set_context.html).\n- Change the `model.infer_predict_layout` interface, which has a new parameter skip_backend_compile with a default value of False. Set to True when the user wants to skip the backend compilation process to get the parameter slicing strategy.\n\n#### Operators\n\n- Add operator primitive for `mindspore.ops.ApplyAdamWithAmsgradV2`. It is recommended to call this operator through API `mindspore.nn.Adam`.\n- Add operator primitive for `mindspore.ops.UpsampleTrilinear3D`. It is recommended to call this operator through API `mindspore.ops.interpolate`.\n- Add operator primitive for `mindspore.ops.UpsampleNearest3D`. It is recommended to call this operator through API `mindspore.ops.interpolate`.\n\n#### API Deprecation\n\n- Deprecate operator primitive `mindspore.ops.ScatterNonAliasingAdd`. It is recommended to use operator primitive `mindspore.ops.TensorScatterAdd` as a replacement.\n\n#### Backwards Incompatible Change\n\n- Interface name: `mindspore.nn.Dense`, `mindspore.nn.Conv1d`, `mindspore.nn.Conv1dTranspose`, `mindspore.nn.Conv2d`, `mindspore.nn.Conv2dTranspose`, `mindspore.nn.Conv3d`, `mindspore.nn.Conv3dTranspose`\n\n  Changes: Change initialization parameter strategy. The default value of weight_init is changed from \"normal\" to None, and the default value of bias_init is changed from \"zeros\" to None.\n\n  Description: The default initialization method for weights has been changed from \"normal\" to internal HeUniform initialization. The default initialization method of bias is changed from \"zeros\" to internal Uniform initialization.\n\n  <table>\n  <tr>\n  <td style=\"text-align:center\"> Original interface </td> <td style=\"text-align:center\"> v2.1 interface </td>\n  </tr>\n  <tr>\n  <td><pre>\n  mindspore.nn.Dense(in_channels,\n                     out_channels,\n                     weight_init='normal',\n                     bias_init='zeros',\n                     has_bias=True,\n                     activation=None)\n  </pre>\n  </td>\n  <td><pre>\n  mindspore.nn.Dense(in_channels,\n                     out_channels,\n                     weight_init=None,\n                     bias_init=None,\n                     has_bias=True,\n                     activation=None)\n  </pre>\n  </td>\n  </tr>\n  <tr>\n  <td><pre>\n  mindspore.nn.Conv1d(in_channels,\n                      out_channels,\n                      kernel_size,\n                      stride=1,\n                      pad_mode='same',\n                      padding=0,\n                      dilation=1,\n                      group=1,\n                      has_bias=False,\n                      weight_init='normal',\n                      bias_init='zeros')\n  </pre>\n  </td>\n  <td><pre>\n  mindspore.nn.Conv1d(in_channels,\n                      out_channels,\n                      kernel_size,\n                      stride=1,\n                      pad_mode='same',\n                      padding=0,\n                      dilation=1,\n                      group=1,\n                      has_bias=False,\n                      weight_init=None,\n                      bias_init=None)\n  </pre>\n  </td>\n  </tr>\n  <tr>\n  <td><pre>\n  mindspore.nn.Conv1dTranspose(in_channels,\n                               out_channels,\n                               kernel_size,\n                               stride=1,\n                               pad_mode='same',\n                               padding=0,\n                               dilation=1,\n                               group=1,\n                               has_bias=False,\n                               weight_init='normal',\n                               bias_init='zeros')\n  </pre>\n  </td>\n  <td><pre>\n  mindspore.nn.Conv1dTranspose(in_channels,\n                               out_channels,\n                               kernel_size,\n                               stride=1,\n                               pad_mode='same',\n                               padding=0,\n                               dilation=1,\n                               group=1,\n                               has_bias=False,\n                               weight_init=None,\n                               bias_init=None)\n  </pre>\n  </td>\n  </tr>\n  <tr>\n  <td><pre>\n  mindspore.nn.Conv2d(in_channels,\n                      out_channels, kernel_size,\n                      stride=1,\n                      pad_mode='same',\n                      padding=0,\n                      dilation=1,\n                      group=1,\n                      has_bias=False,\n                      weight_init='normal',\n                      bias_init='zeros',\n                      data_format='NCHW')\n  </pre>\n  </td>\n  <td><pre>\n  mindspore.nn.Conv2d(in_channels,\n                      out_channels,\n                      kernel_size,\n                      stride=1,\n                      pad_mode='same',\n                      padding=0,\n                      dilation=1,\n                      group=1,\n                      has_bias=False,\n                      weight_init=None,\n                      bias_init=None,\n                      data_format='NCHW')\n  </pre>\n  </td>\n  </tr>\n  <tr>\n  <td><pre>\n  mindspore.nn.Conv2dTranspose(in_channels,\n                               out_channels,\n                               kernel_size,\n                               stride=1,\n                               pad_mode='same',\n                               padding=0,\n                               output_padding=0,\n                               dilation=1,\n                               group=1,\n                               has_bias=False,\n                               weight_init='normal',\n                               bias_init='zeros')\n  </pre>\n  </td>\n  <td><pre>\n  mindspore.nn.Conv2dTranspose(in_channels,\n                               out_channels,\n                               kernel_size,\n                               stride=1,\n                               pad_mode='same',\n                               padding=0,\n                               output_padding=0,\n                               dilation=1,\n                               group=1,\n                               has_bias=False,\n                               weight_init=None,\n                               bias_init=None)\n  </pre>\n  </td>\n  </tr>\n  <tr>\n  <td><pre>\n  mindspore.nn.Conv3d(in_channels,\n                      out_channels,\n                      kernel_size,\n                      stride=1,\n                      pad_mode='same',\n                      padding=0,\n                      dilation=1,\n                      group=1,\n                      has_bias=False,\n                      weight_init='normal',\n                      bias_init='zeros',\n                      data_format='NCDHW')\n  </pre>\n  </td>\n  <td><pre>\n  mindspore.nn.Conv3d(in_channels,\n                      out_channels,\n                      kernel_size,\n                      stride=1,\n                      pad_mode='same',\n                      padding=0,\n                      dilation=1,\n                      group=1,\n                      has_bias=False,\n                      weight_init=None,\n                      bias_init=None,\n                      data_format='NCDHW')\n  </pre>\n  </td>\n  </tr>\n  <tr>\n  <td><pre>\n  mindspore.nn.Conv3dTranspose(in_channels,\n                               out_channels,\n                               kernel_size,\n                               stride=1,\n                               pad_mode='same',\n                               padding=0,\n                               dilation=1,\n                               group=1,\n                               output_padding=0,\n                               has_bias=False,\n                               weight_init='normal',\n                               bias_init='zeros',\n                               data_format='NCDHW')\n  </pre>\n  </td>\n  <td><pre>\n  mindspore.nn.Conv3dTranspose(in_channels,\n                               out_channels,\n                               kernel_size,\n                               stride=1,\n                               pad_mode='same',\n                               padding=0,\n                               dilation=1,\n                               group=1,\n                               output_padding=0,\n                               has_bias=False,\n                               weight_init=None,\n                               bias_init=None,\n                               data_format='NCDHW')\n  </pre>\n  </td>\n  </tr>\n  </table>\n\n### Bug Fixes\n\n- [I6TKLW] Fix the issue of MobileNetV2 network performance degradation on the Ascend platform.\n- [I7CP5H] Fix the issue where ASR network training failed on the Ascend platform.\n- [I7I3EZ] Fix the issue that caused run_check() failure due to changes to the enumeration interface in Pillow version 10.0.0. If encountered in a lower version of MindSpore, install versions of Pillow below 10.0.0 to avoid this issue.\n- [I7IZ8K] Fix accuracy issues with the assignsub interface in PyNative mode.\n- [I7HGY0] Fix the issue that the loss of the functional programming does not converge in the PyNative data_sink mode.\n- [I7J4N3] Fix the issue that the generation of Step Trace failed in Profiler dynamic Shape mode\n- [I7J4N3] Fix the issue that there is no data displayed in the MindInsight parallel strategy view.\n- [I79YY4] Fix SiLU operator error when high-order differential in PyNative mode.\n- [I6NQJQ] Fix the issue of probabilistic failure in dynamic shape scenarios of the ScatterUpdate operator in PyNative mode.\n- [I6Y4G5] Fix the issue of failure in dynamic Shape scenarios of the Conv3D operator in Graph mode.\n\n### Contributors\n\nThanks goes to these wonderful people:\n\nalashkari,anzhengqi,archer2049,B.L.LAN,baihuawei,bichaoyang,BJ-WANG,Bokai Li,Brian-K,caifubi,caiyimeng,cathwong,changzherui,ChenDonYY,chenfei_mindspore,chengang,chengbin,chenhaozhe,chenjianping,chenkang,chenweifeng,chuht,chujinjin,davidanugraha,DavidFFFan,DeshiChen,douzhixing,emmmmtang,Erpim,Ethan,fangwenyi,fangzehua,fangzhou0329,fary86,fengyixing,gaoshuanglong,Gaoxiong,gaoyong10,gengdongjie,gongdaguo1,Greatpan,GuoZhibin,guozhijian,hangq,hanhuifeng,haozhang,hedongdong,Henry Shi,heterogeneous_to_backoff_2_0,huangbingjian,huanghui,huangxinjing,hujiahui8,hujingsong,huoxinyou,jachua,jiahongQian,jianghui58,jiangzhenguang,jiaorui,jiaoy1224,jijiarong,jjfeing,JoeyLin,json,JuiceZ,jxl,kairui_kou,KevinYi,kisnwang,KXiong,laiyongqiang,lanzhineng,liangchenghui,liangzelang,LiangZhibo,lianliguang,lichen,ligan,lijunbin,limingqi107,ling,linqingke,liubuyu,liuchao,liuchuting,liujunzhu,liuluobin,liutongtong9,liuyang811,lixiao,liyan2022,liyejun,liyuxia,looop5,luochao60,luojianing,luoyang,luoyuan,lyqlola,maning202007,maoyaomin,Margaret_wangrui,mayadong,MaZhiming,melody,mengyuanli,michaelzhu_70ab,Mohammad Motallebi,moran,NaCN,nomindcarry,OwenSec,panfengfeng,panshaowu,panzhihui,pkuliuliu,qinzheng,qiuzhongya,qujianwei,r1chardf1d0,Renyuan Zhang,RobinGrosman,shaojunsong,shenwei41,Soaringfish,tangdezhi_123,tanghuikang,tan-wei-cheng,TinaMengtingZhang,TronZhang,TuDouNi,VectorSL,wang_ziqi,wanghenchang,wangnan39,wangpingan,wangshaocong,wangshengnan123,wangtongyu6,weichaoran,wind-zyx,wqx,wtcheng,wujueying,wYann,XianglongZeng,xiaohanzhang,xiaotianci,xiaoyao,XinDu,xulei,xumengjuan1,xupan,xwkgch,yanghaoran,yangluhang,yangruoqi713,yangshuo,yangsijia,yangzhenzhang,yanzhenxiang2020,Yanzhi_YI,yao_yf,yefeng,yeyunpeng2020,Yi_zhang95,yide12,YijieChen,YingLai Lin,YingtongHu,youshu,yuchaojie,yuedongli,YuJianfeng,zangqx,ZengZitao,zhangbuxue,zhangdanyang,zhangdong,zhangfanghe,zhangqi,zhangqinghua,zhangyanhui,zhangyinxia,zhangyongxian,zhangzhaoju,zhanzhan,zhengzuohe,ZhidanLiu,zhixinaa,zhoufeng,zhouyaqiang0,zhuguodong,zhupuxu,zhuyuxiao,zichun_ye,zjun,zlq2020,zong_shuai,ZPaC,zuochuanyong,zyli2020,陈宇,范吉斌,冯一航,胡彬,宦晓玲,黄勇,雷元哲,李良灿,李林杰,刘崇鸣,刘力力,刘勇琪,吕浩宇,吕昱峰（Nate.River）,没有窗户的小巷,沈竞兴,十六夜,王程浩,王禹程,王振邦,徐安越,徐永飞,杨旭华,于振华,俞涵,张清华,张澍坤,张栩浩,张学同,赵英灼,周超,周洪叶,朱家兴\n\nContributions of any kind are welcome!\n\n## MindSpore Lite 2.1.0 Release Notes\n\n### Major Features and Improvements\n\n#### MindSpore Lite Cloud Inference\n\n- [STABLE] Supports high-performance inference for single-device large model and single-node multi-device distributed large model at Ascend backend.\n- [STABLE] Python API Ascend backend supports multiple models sharing workspace memory.\n- [STABLE] [The weights can be shared by multiple models through ModelGroup](https://mindspore.cn/lite/docs/en/r2.1/use/cloud_infer/runtime_cpp.html#multiple-models-sharing-weights). For example, weights can be shared between full models and incremental models in the large model scenario.\n\n#### API\n\nThe [Python](https://www.mindspore.cn/lite/api/en/r2.1/mindspore_lite/mindspore_lite.ModelGroup.html) and [C++](https://mindspore.cn/lite/api/en/r2.1/generate/classmindspore_ModelGroup.html) ModelGroup interface is added. The interface definition is as follows:\n\n```python\nclass ModelGroup\n    def __init__(self, flags=ModelGroupFlag.SHARE_WORKSPACE)\n    def add_model(self, models)\n    def cal_max_size_of_workspace(self, model_type, context)\n```\n\n```C++\n// class ModelGroup\nModelGroup(ModelGroupFlag flags = ModelGroupFlag::kShareWorkspace);\nStatus AddModel(const std::vector<std::string> &model_path_list);\nStatus AddModel(const std::vector<std::pair<const void *, size_t>> &model_buff_list);\nStatus AddModel(const std::vector &model_list);\nStatus AddModel(const std::vector &model_list);\n```\n\n## MindSpore 2.0.0 Release Notes\n\n### Major Features and Improvements\n\n#### PyNative\n\n- [STABLE] Dynamic shape is fully supported on framework. For detailed operator support, refer to [Dynamic Shape Support Status of nn Interface](https://www.mindspore.cn/docs/en/master/note/dynamic_shape_nn.html), [Dynamic Shape Support Status of ops Interface](https://www.mindspore.cn/docs/en/master/note/dynamic_shape_func.html), and [Dynamic Shape Support Status of primitive Interface](https://www.mindspore.cn/docs/en/master/note/dynamic_shape_primitive.html).\n\n#### AutoParallel\n\n- [STABLE] Build new MindFormers independent repositpry, providing distributed parallel suite, replacing mindspore.nn.transformer module.\n- [DEMO] Distributed parallel operator Gather supports the BatchDim attribute.\n- [DEMO] Streamline parallel supports specifying any dimension of the input data as the Batch dimension.\n\n### API Change\n\n#### operator\n\n- Add operator primitive for `mindspore.ops.AdaptiveAvgPool2D` .\n- Add operator primitive for `mindspore.ops.BatchToSpaceNDV2` .\n- Add operator primitive for `mindspore.ops.CeLU` .\n- Add operator primitive for `mindspore.ops.ExtractVolumePatches` .\n- Add operator primitive for `mindspore.ops.FFTWithSize` .\n- Add operator primitive for `mindspore.ops.FillDiagonal` .\n- Add operator primitive for `mindspore.ops.FractionalMaxPool3DWithFixedKsize` .\n- Add operator primitive for `mindspore.ops.Im2Col` .\n- Add operator primitive for `mindspore.ops.MaskedScatter` .\n- Add operator primitive for `mindspore.ops.MatrixBandPart` .\n- Add operator primitive for `mindspore.ops.MatrixInverse` .\n- Add operator primitive for `mindspore.ops.MaxPoolWithArgmaxV2` .\n- Add operator primitive for `mindspore.ops.Ormqr` .\n- Add operator primitive for `mindspore.ops.RandpermV2` .\n- Add operator primitive for `mindspore.ops.ResizeBicubic` .\n- Add operator primitive for `mindspore.ops.Triu` .\n- Add operator primitive for `mindspore.ops.Zeta` .\n\n#### Backwards Incompatible Change\n\n- Interface: mindspore.ops.MultitypeFuncGraph\n\n  Change: The interface parameter doc_url is used as a test feature in MindSpore 2.0.0.rc1 version. After the optimization of MindSpore 2.0.0 version, users do not need to configure this parameter, so this parameter is deleted in MindSpore 2.0.0 version.\n\n  <table>\n  <tr>\n  <td style=\"text-align:center\"> Original Interface </td> <td style=\"text-align:center\"> Interface v2.0.0 </td>\n  </tr>\n  <tr>\n  <td><pre>\n  mindspore.ops.MultitypeFuncGraph（name, read_value=False, doc_url=\"\"）\n  </pre>\n  </td>\n  <td><pre>\n  mindspore.ops.MultitypeFuncGraph（name, read_value=False）\n  </pre>\n  </td>\n  </tr>\n  </table>\n\n- Interface: mindspore.set_context(auto_tune_mode=\"GA,RL\")\n\n  Change: The AutoTune tool has been deprecated, delete auto_tune_mode option, new tuning tools will be planned in the future.\n\n- Interface: mindspore.set_context(mode=PYNATIVE_MODE)\n\n  Change: The default value is changed from GRAPH_MODE to PYNATIVE_MODE.\n\n  Description: If the running mode is not set and the diagram mode needs to be set, use the following method:\n  mindspore.set_context(mode=GRAPH_MODE).\n\n  <table>\n  <tr>\n  <td style=\"text-align:center\"> Original Interface </td> <td style=\"text-align:center\"> Interface v2.0.0-rc1 </td>\n  </tr>\n  <tr>\n  <td><pre>\n  mindspore.set_context(mode=GRAPH_MODE)\n  </pre>\n  </td>\n  <td><pre>\n  mindspore.set_context(mode=PYNATIVE_MODE)\n  </pre>\n  </td>\n  </tr>\n  </table>\n\n- Interface: mindspore.train.Model.train\n\n  Change: The default value of dataset_sink_mode is changed from True to False.\n\n  Description: If dataset_sink_mode is not set and the data sinking mode needs to be set, use the following method:\n  Model.train(dataset_sink_mode=True).\n\n  <table>\n  <tr>\n  <td style=\"text-align:center\"> Original Interface </td> <td style=\"text-align:center\"> Interface v2.0.0-rc1 </td>\n  </tr>\n  <tr>\n  <td><pre>\n  Model.train(dataset_sink_mode=True)\n  </pre>\n  </td>\n  <td><pre>\n  Model.train(dataset_sink_mode=False)\n  </pre>\n  </td>\n  </tr>\n  </table>\n\n- Interface: mindspore.export\n\n  Change: The file_format parameter is changed from AIR to no default value.\n\n  Description: If file_format is not set in the original mode, you need to set file_format additionally. In this case, use the following method:\n  mindspore.export(net, *inputs, file_name, file_format=\"AIR\", **kwargs).\n\n  <table>\n  <tr>\n  <td style=\"text-align:center\"> Original Interface </td> <td style=\"text-align:center\"> Interface v2.0.0-rc1 </td>\n  </tr>\n  <tr>\n  <td><pre>\n  mindspore.export(net, *inputs, file_name,\n                   file_format=\"AIR\", **kwargs)\n  </pre>\n  </td>\n  <td><pre>\n  mindspore.export(net, *inputs, file_name,\n                   file_format, **kwargs)\n  </pre>\n  </td>\n  </tr>\n  </table>\n\n- Interface: mindspore.ops.norm\n\n  Change: The ord parameter function is extended to support multiple forms.\n\n  <table>\n  <tr>\n  <td style=\"text-align:center\"> Original Interface </td> <td style=\"text-align:center\"> Interface v2.0.0-rc1 </td>\n  </tr>\n  <tr>\n  <td><pre>\n  ops.norm(input_x, axis, p=2, keep_dims=False, epsilon=1e-12)\n  >>> # Example:\n  >>> input = Tensor(np.array([[[1.0, 2.0], [3.0, 4.0]],\n  ...                          [[5.0, 6.0], [7.0, 8.0]]]).astype(np.float32))\n  >>> output = ops.norm(input, [0, 1], p=2)\n  </pre></td>\n  <td><pre>\n  ops.norm(A, ord=None, dim=None, keepdim=False, *, dtype=None)\n  >>> # Example:\n  >>> input = Tensor(np.array([[[1.0, 2.0], [3.0, 4.0]],\n  ...                          [[5.0, 6.0], [7.0, 8.0]]]).astype(np.float32))\n  >>> output = ops.norm(input, ord=2, dim=(0, 1))\n  </pre>\n  </td>\n  </tr>\n  </table>\n\n- Interface: mindspore.Tensor.norm\n\n  Change: The ord parameter function is extended to support multiple forms.\n\n  Description: For details, see the example of ops.norm.\n\n  <table>\n  <tr>\n  <td style=\"text-align:center\"> Original Interface </td> <td style=\"text-align:center\"> Interface v2.0.0-rc1 </td>\n  </tr>\n  <tr>\n  <td><pre>\n  Tensor.norm(axis, p=2, keep_dims=False, epsilon=1e-12)\n  </pre>\n  </td>\n  <td><pre>\n  Tensor.norm(ord=None, dim=None, keepdim=False, *, dtype=None)\n  </pre>\n  </td>\n  </tr>\n  </table>\n\n- Interface: mindspore.ops.dropout\n\n  Change: The seed0 and seed1 parameters are deleted and seed=None parameter is added. Instead of returning Tensors and masks, only Tensors are returned. The input parameter training=True is added.\n\n  <table>\n  <tr>\n  <td style=\"text-align:center\"> Original Interface </td> <td style=\"text-align:center\"> Interface v2.0.0-rc1 </td>\n  </tr>\n  <tr>\n  <td><pre>\n  ops.dropout(x, p=0.5, seed0=0, seed1=0)\n  >>> # Example:\n  >>> input = Tensor(((20, 16), (50, 50)),\n  ...                mindspore.float32)\n  >>> output, mask = dropout(x, p=0.5)\n  </pre>\n  </td>\n  <td><pre>\n  ops.dropout(input, p=0.5, training=True, seed=None)\n  >>> # Example:\n  >>> input = Tensor(((20, 16), (50, 50)),\n  ...                mindspore.float32)\n  >>> output = ops.dropout(input, p=0.5，training=True)\n  </pre>\n  </td>\n  </tr>\n  </table>\n\n- Interface: mindspore.ops.dropout2d\n\n  Change: Return value is changed from Tensor and mask to Tensor only. The input parameter training=True is added.\n\n  <table>\n  <tr>\n  <td style=\"text-align:center\"> Original Interface </td> <td style=\"text-align:center\"> Interface v2.0.0-rc1 </td>\n  </tr>\n  <tr>\n  <td><pre>\n  ops.dropout2d(x, p=0.5)\n  >>> # Example:\n  >>> input = Tensor(np.ones([2, 1, 2, 3]),\n  ...                mindspore.float32)\n  >>> output, mask = dropout2d(input, 0.5)\n  </pre>\n  </td>\n  <td><pre>\n  ops.dropout2d(input, p=0.5, training=True)\n  >>> # Example:\n  >>> input = Tensor(np.ones([2, 1, 2, 3]),\n  ...                mindspore.float32)\n  >>> output = ops.dropout2d(input, 0.5, training=True)\n  </pre>\n  </td>\n  </tr>\n  </table>\n\n- Interface: mindspore.ops.dropout3d\n\n  Change: Return value is changed from Tensor and mask to Tensor only. The input parameter training=True is added.\n\n  <table>\n  <tr>\n  <td style=\"text-align:center\"> Original Interface </td> <td style=\"text-align:center\"> Interface v2.0.0-rc1 </td>\n  </tr>\n  <tr>\n  <td><pre>\n  ops.dropout3d(x, p=0.5)\n  >>> # Example:\n  >>> input = Tensor(np.ones([2, 1, 2, 3]),\n  ...                mindspore.float32)\n  >>> output, mask = dropout3d(input, 0.5)\n  </pre>\n  </td>\n  <td><pre>\n  ops.dropout3d(input, p=0.5, training=True)\n  >>> # Example:\n  >>> input = Tensor(np.ones([2, 1, 2, 3]),\n  ...                mindspore.float32)\n  >>> output = ops.dropout3d(input, 0.5, training=True)\n  </pre>\n  </td>\n  </tr>\n  </table>\n\n- Interface: mindspore.ops.std\n\n  Change: The interface is reconstructed, and the interface usage mode is more consistent with user habits.\n\n  Description: If parameter `unbiased` has been set, use the following alternative: `unbiased=False` -> `ddof=0`, `unbiased=True` -> `ddof=1`.\n\n  <table>\n  <tr>\n  <td style=\"text-align:center\"> Original Interface </td> <td style=\"text-align:center\"> Interface v2.0.0-rc1 </td>\n  </tr>\n  <tr>\n  <td><pre>\n  ops.std(input_x, axis=(), unbiased=True, keep_dims=False)\n  </pre>\n  </td>\n  <td><pre>\n  ops.std(input, axis=None, ddof=0, keepdims=False)\n  </pre>\n  </td>\n  </tr>\n  </table>\n\n- Interface: mindspore.load_param_into_net\n\n  Change: Parameters that are not loaded in the ckpt are added as return values.\n\n  <table>\n  <tr>\n  <td style=\"text-align:center\"> Original Interface </td> <td style=\"text-align:center\"> Interface v2.0.0-rc1 </td>\n  </tr>\n  <tr>\n  <td><pre>\n  net_param = load_param_into_net()\n  </pre>\n  </td>\n  <td><pre>\n  net_param, ckpt_param = load_param_into_net()\n  </pre>\n  </td>\n  </tr>\n  </table>\n\n- Interface: mindspore.nn.BCELoss\n\n  Change: The default value of `reduction` is changed from 'none' to 'mean'.\n\n  <table>\n  <tr>\n  <td style=\"text-align:center\"> Original Interface </td> <td style=\"text-align:center\"> Interface v2.0.0-rc1 </td>\n  </tr>\n  <tr>\n  <td><pre>\n  BCELoss(weight=None, reduction='none')\n  >>> # Example:\n  >>> weight = Tensor(np.array([[1.0, 2.0, 3.0],\n  ...                           [4.0, 3.3, 2.2]]),\n  ...                 mindspore.float32)\n  >>> loss = nn.BCELoss(weight=weight, reduction='mean')\n  >>> logits = Tensor(np.array([[0.1, 0.2, 0.3],\n  ...                           [0.5, 0.7, 0.9]]),\n  ...                 mindspore.float32)\n  >>> labels = Tensor(np.array([[0, 1, 0], [0, 0, 1]]),\n  ...                 mindspore.float32)\n  >>> output = loss(logits, labels)\n  >>> print(output)\n  >>> 1.8952923\n  </pre>\n  </td>\n  <td><pre>\n  BCELoss(weight=None, reduction='mean')\n  >>> # Example:\n  >>> weight = Tensor(np.array([[1.0, 2.0, 3.0],\n  ...                           [4.0, 3.3, 2.2]]),\n  ...                 mindspore.float32)\n  >>> loss = nn.BCELoss(weight=weight)\n  >>> logits = Tensor(np.array([[0.1, 0.2, 0.3],\n  ...                           [0.5, 0.7, 0.9]]),\n  ...                 mindspore.float32)\n  >>> labels = Tensor(np.array([[0, 1, 0], [0, 0, 1]]),\n  ...                 mindspore.float32)\n  >>> output = loss(logits, labels)\n  >>> print(output)\n  >>> 1.8952923\n  </pre>\n  </td>\n  </tr>\n  </table>\n\n- Interface: mindspore.ops.split\n\n  Change: The interface is reconstructed. The interface usage mode is more suitable for users. The sequence of the second and third parameters is adjusted, and the split_size_or_sections function is modified and extended.\n\n  <table>\n  <tr>\n  <td style=\"text-align:center\"> Original Interface </td> <td style=\"text-align:center\"> Interface v2.0.0-rc1 </td>\n  </tr>\n  <tr>\n  <td><pre>\n  ops.split(input_x, axis=0, output_num=1)\n  >>> # Example:\n  >>> input = Tensor(np.array([[1, 1, 1, 1], [2, 2, 2, 2]]),\n  ...                mindspore.int32)\n  >>> output = ops.split(input, axis=1, output_num=4)\n  </pre>\n  </td>\n  <td><pre>\n  ops.split(tensor, split_size_or_sections, axis=0)\n  >>> # Example:\n  >>> input = Tensor(np.array([[1, 1, 1, 1], [2, 2, 2, 2]]),\n  ...                mindspore.int32)\n  >>> output = ops.split(input, split_size_or_sections=1, axis=1)\n  </pre>\n  </td>\n  </tr>\n  </table>\n\n- Interface: mindspore.Tensor.split\n\n  Change: The interface is reconstructed. The interface usage mode is more suitable for users. The positions of the two parameters is adjusted, and the split_size_or_sections function is modified and extended.\n\n  Description: For details, see the example of ops.split.\n\n  <table>\n  <tr>\n  <td style=\"text-align:center\"> Original Interface </td> <td style=\"text-align:center\"> Interface v2.0.0-rc1 </td>\n  </tr>\n  <tr>\n  <td><pre>\n  Tensor.split(axis=0, output_num=1)\n  </pre>\n  </td>\n  <td><pre>\n  Tensor.split(split_size_or_sections, axis=0)\n  </pre>\n  </td>\n  </tr>\n  </table>\n\n- Interface: mindspore.ops.pad\n\n  Change: Modify the parameter name paddings to padding, and the mode and value functions are added.\n\n  <table>\n  <tr>\n  <td style=\"text-align:center\"> Original Interface </td> <td style=\"text-align:center\"> Interface v2.0.0-rc1 </td>\n  </tr>\n  <tr>\n  <td><pre>\n  ops.pad(input_x, paddings)\n  >>> # Example:\n  >>> input_x = Tensor(np.array([[-0.1, 0.3, 3.6],\n  ...                            [0.4, 0.5, -3.2]]),\n  ...                  mindspore.float32)\n  >>> paddings = ((1, 2), (2, 1))\n  >>> output = ops.pad(input_x, paddings)\n  </pre>\n  </td>\n  <td><pre>\n  ops.pad(input_x, padding, mode='constant', value=None)\n  >>> # Example:\n  >>> input_x = Tensor(np.array([[-0.1, 0.3, 3.6],\n  ...                            [0.4, 0.5, -3.2]]),\n  ...                  mindspore.float32)\n  >>> paddings = (2, 1, 1, 2)\n  >>> output = ops.pad(input_x, paddings)\n  </pre>\n  </td>\n  </tr>\n  </table>\n\n- Interface: mindspore.ops.meshgrid\n\n  Change: The input parameter is changed from `inputs` to `*input`.\n\n  <table>\n  <tr>\n  <td style=\"text-align:center\"> Original Interface </td> <td style=\"text-align:center\"> Interface v2.0.0-rc1 </td>\n  </tr>\n  <tr>\n  <td><pre>\n  ops.meshgrid(inputs, indexing='xy')\n  >>> # Example:\n  >>> x = Tensor(np.array([1, 2, 3, 4]).astype(np.int32))\n  >>> y = Tensor(np.array([5, 6, 7]).astype(np.int32))\n  >>> z = Tensor(np.array([8, 9, 0, 1, 2]).astype(np.int32))\n  output = ops.meshgrid((x, y, z), indexing='xy')\n  </pre>\n  </td>\n  <td><pre>\n  ops.meshgrid(*inputs, indexing='xy')\n  >>> # Example:\n  >>> x = Tensor(np.array([1, 2, 3, 4]).astype(np.int32))\n  >>> y = Tensor(np.array([5, 6, 7]).astype(np.int32))\n  >>> z = Tensor(np.array([8, 9, 0, 1, 2]).astype(np.int32))\n  output = ops.meshgrid(x, y, z, indexing='xy')\n  </pre>\n  </td>\n  </tr>\n  </table>\n\n- Interface: mindspore.ops.max\n\n  Change: Return value exchange sequence. The value is changed from \"index, value\" to \"value, index\".\n\n  <table>\n  <tr>\n  <td style=\"text-align:center\"> Original Interface </td> <td style=\"text-align:center\"> Interface v2.0.0-rc1 </td>\n  </tr>\n  <tr>\n  <td><pre>\n  ops.max(x, axis=0, keep_dims=False)\n  >>> # Example:\n  >>> input = Tensor(np.array([0.0, 0.4, 0.6, 0.7, 0.1]),\n  ...                mindspore.float32)\n  >>> index, output = ops.max(input)\n  >>> print(index, output)\n  >>> 3 0.7\n  </pre>\n  </td>\n  <td><pre>\n  ops.max(input, axis=None, keepdims=False, *, initial=None, where=True, return_indices=False)\n  >>> # Example:\n  >>> input = Tensor(np.array([0.0, 0.4, 0.6, 0.7, 0.1]),\n  ...                mindspore.float32)\n  >>> output, index = ops.max(input, axis=0)\n  >>> print(output, index)\n  </pre>\n  </td>\n  </tr>\n  </table>\n\n- Interface: mindspore.ops.min\n\n  Change: Return value exchange sequence. The value is changed from \"index, value\" to \"value, index\".\n\n  <table>\n  <tr>\n  <td style=\"text-align:center\"> Original Interface </td> <td style=\"text-align:center\"> Interface v2.0.0-rc1 </td>\n  </tr>\n  <tr>\n  <td><pre>\n  ops.min(x, axis=0, keep_dims=False)\n  >>> # Example:\n  >>> input = Tensor(np.array([0.0, 0.4, 0.6, 0.7, 0.1]),\n  ...                mindspore.float32)\n  >>> index, output = ops.min(input)\n  >>> 0 0.0\n  </pre>\n  </td>\n  <td><pre>\n  ops.min(input, axis=None, keepdims=False, *, initial=None, where=True, return_indices=False)\n  >>> # Example:\n  >>> input = Tensor(np.array([0.0, 0.4, 0.6, 0.7, 0.1]),\n  ...                mindspore.float32)\n  >>> output, index = ops.min(input, keepdims=True)\n  >>> 0.0 0\n  </pre>\n  </td>\n  </tr>\n  </table>\n\n- Interface: mindspore.ops.random_gamma\n\n  Change: The seed2 parameter is deleted and seed=0 is changed to None. The framework behavior is unified and complies with the actual application scenarios and habits of users.\n\n  <table>\n  <tr>\n  <td style=\"text-align:center\"> Original Interface </td> <td style=\"text-align:center\"> Interface v2.0.0-rc1 </td>\n  </tr>\n  <tr>\n  <td><pre>\n  ops.random_gamma(shape, alpha, seed=0, seed2=0)\n  </pre>\n  </td>\n  <td><pre>\n  ops.random_gamma(shape, alpha, seed=None)\n  </pre>\n  </td>\n  </tr>\n  </table>\n\n- Interface: mindspore.ops.standard_laplace\n\n  Change: The seed2 parameter is deleted and seed=0 is changed to None. The framework behavior is unified and complies with the actual application scenarios and habits of users.\n\n  <table>\n  <tr>\n  <td style=\"text-align:center\"> Original Interface </td> <td style=\"text-align:center\"> Interface v2.0.0-rc1 </td>\n  </tr>\n  <tr>\n  <td><pre>\n  ops.standard_laplace(shape, seed=0, seed2=0)\n  </pre>\n  </td>\n  <td><pre>\n  ops.standard_laplace(shape, seed=None)\n  </pre>\n  </td>\n  </tr>\n  </table>\n\n- Interface: mindspore.ops.standard_normal\n\n  Change: The seed2 parameter is deleted and seed=0 is changed to None. The framework behavior is unified and complies with the actual application scenarios and habits of users.\n\n  <table>\n  <tr>\n  <td style=\"text-align:center\"> Original Interface </td> <td style=\"text-align:center\"> Interface v2.0.0-rc1 </td>\n  </tr>\n  <tr>\n  <td><pre>\n  ops.standard_normal(shape, seed=0, seed2=0)\n  </pre>\n  </td>\n  <td><pre>\n  ops.standard_normal(shape, seed=None)\n  </pre>\n  </td>\n  </tr>\n  </table>\n\n- Interface: mindspore.ops.bernoulli\n\n  Change: The default value of seed is changed from -1 to None. Meets the actual application scenario.\n\n  <table>\n  <tr>\n  <td style=\"text-align:center\"> Original Interface </td> <td style=\"text-align:center\"> Interface v2.0.0-rc1 </td>\n  </tr>\n  <tr>\n  <td><pre>\n  ops.bernoulli(x, p=0.5, seed=-1)\n  </pre>\n  </td>\n  <td><pre>\n  ops.bernoulli(input, p=0.5, seed=None)\n  </pre>\n  </td>\n  </tr>\n  </table>\n\n- Interface: mindspore.data_sink\n\n  Change: Deleted the steps parameter. Parameter name jit is changed to jit_config, and new input_signature parameter is added. The usability is improved to meet the requirements of actual application scenarios.\n\n  <table>\n  <tr>\n  <td style=\"text-align:center\"> Original Interface </td> <td style=\"text-align:center\"> Interface v2.0.0-rc1 </td>\n  </tr>\n  <tr>\n  <td><pre>\n  mindspore.data_sink(fn, dataset, steps,\n                      sink_size=1, jit=False)\n  </pre>\n  </td>\n  <td><pre>\n  mindspore.data_sink(fn, dataset, sink_size=1,\n                      jit_config=None, input_signature=None)\n  </pre>\n  </td>\n  </tr>\n  </table>\n\n- Interface: mindspore.ops.conv2d\n\n  Change: Extend Interface Function. Add the bias parameter and modify the parameter name and parameter sequence.\n\n  <table>\n  <tr>\n  <td style=\"text-align:center\"> Original Interface </td> <td style=\"text-align:center\"> Interface v2.0.0-rc1 </td>\n  </tr>\n  <tr>\n  <td><pre>\n  conv2d(inputs, weight, pad_mode=\"valid\",\n         padding=0, stride=1, dilation=1, group=1)\n  </pre>\n  </td>\n  <td><pre>\n  conv2d(input, weight, bias=None, stride=1,\n         pad_mode=\"valid\", padding=0, dilation=1, groups=1)\n  </pre>\n  </td>\n  </tr>\n  </table>\n\n- Interface: mindspore.dataset.vision.Pad\n\n  Change: Adjust the input parameter padding of Pad, RandomCrop, and RandomCropWithBbox. When the input length of Padding is 2, the first value is used to fill the left/upper boundary, the second value is used to fill the right/lower boundary, and the first value is used to fill the left/right boundary. Fill the upper/lower boundary with the second value.\n\n  Description: The padding parameter whose size is 2 is not compatible with the effect of the earlier version. The padding parameter needs to be explicitly represented (left, right, top, and bottom).\n\n  <table>\n  <tr>\n  <td style=\"text-align:center\"> Original Interface </td> <td style=\"text-align:center\"> Interface v2.0.0-rc1 </td>\n  </tr>\n  <tr>\n  <td><pre>\n  mindspore.dataset.vision.Pad(padding=(1,2))\n  Indicates that the left/upper part of the image is filled with 1 pixel,\n  and the right/down part is filled with 2 pixels.\n  </pre>\n  </td>\n  <td><pre>\n  mindspore.dataset.vision.Pad(padding=(1,2,1,2))\n  Indicates that the left/upper part of the image is filled with 1 pixel,\n  and the right/down part is filled with 2 pixels.\n  </pre>\n  </td>\n  </tr>\n  </table>\n\n- Interface: mindspore.dataset.Dataset.map\n\n  Change: Delete the column_order parameter. In most cases, output_columns and column_order have the same value. Therefore, column_order does not need to be transferred. To adjust the sequence of data columns, use mindspore.dataset.Dataset.project.\n\n  Description:\n\n  1. If the column sequence does not need to be changed, delete the column_order parameter.\n  2. If you need to specify the data column sequence, delete the column_order parameter and add a project method to the end of the parameter for column transformation (as in the following example).\n\n  <table>\n  <tr>\n  <td style=\"text-align:center\"> Original Interface </td> <td style=\"text-align:center\"> Interface v2.0.0-rc1 </td>\n  </tr>\n  <tr>\n  <td><pre>\n  >>> dataset = dataset.map(operations=[transforms],\n  ...                       input_columns=[\"column_a\"],\n  ...                       output_columns=[\"column_b\", \"column_c\"],\n  ...                       column_order=[\"column_c\", \"column_b\"])\n  </pre>\n  </td>\n  <td><pre>\n  >>> dataset = dataset.map(operations=[transforms],\n  ...                       input_columns=[\"column_a\"],\n  ...                       output_columns=[\"column_b\", \"column_c\"])\n  >>> dataset = dataset.project([\"column_c\", column_b\"])\")\n  </pre>\n  </td>\n  </tr>\n  </table>\n\n- Interface: mindspore.dataset.Dataset.batch\n\n  Change: Delete the column_order parameter. In most cases, output_columns and column_order have the same value. Therefore, column_order does not need to be transferred. To adjust the sequence of data columns, use mindspore.dataset.Dataset.project.\n\n  Description:\n\n  1. If the column sequence does not need to be changed, delete the column_order parameter.\n  2. If you need to specify the data column sequence, delete the column_order parameter and add a project method to the end of the parameter for column transformation (as in the following example).\n\n  <table>\n  <tr>\n  <td style=\"text-align:center\"> Original Interface </td> <td style=\"text-align:center\"> Interface v2.0.0-rc1 </td>\n  </tr>\n  <tr>\n  <td><pre>\n  >>> dataset = dataset.batch(batch_size=4,\n  ...                         input_columns=[\"column_a\"],\n  ...                         output_columns=[\"column_b\", \"column_c\"],\n  ...                         column_order=[\"column_c\", \"column_b\"])\n  </pre>\n  </td>\n  <td><pre>\n  >>> dataset = dataset.batch(batch_size=4, input_columns=[\"column_a\"]\n  ...                         output_columns=[\"column_b\", \"column_c\"])\n  >>> dataset = dataset.project([\"column_c\", column_b\"])\")\n  </pre>\n  </td>\n  </tr>\n  </table>\n\n- Interface: mindspore.dataset.Dataset.batch\n\n  Change: Split the batch method into two methods: batch and padded_batch. The pad_info parameter is moved from the batch method to the padded_batch method.\n\n  Description: To use the pad_info parameter, use the padded_batch method instead.\n\n  <table>\n  <tr>\n  <td style=\"text-align:center\"> Original Interface </td> <td style=\"text-align:center\"> Interface v2.0.0-rc1 </td>\n  </tr>\n  <tr>\n  <td><pre>\n  >>> dataset = dataset.batch(batch_size=4,\n  ...                         drop_remainder=True, pad_info=...)\n  </pre>\n  </td>\n  <td><pre>\n  >>> dataset = dataset.padded_batch(batch_size=4,\n  ...                                drop_remainder=True, pad_info=...)\n  </pre>\n  </td>\n  </tr>\n  </table>\n\n### Bug fixes\n\n- [I62I3J] fix inference failure of BGCF network on Ascend 310\n- [I7C2W3] fix error issuse of null pointer when enabling multiple loss in parallel pipeline scenarios\n\n### Contributors\n\nThanks goes to these wonderful people:\n\nalashkari,anzhengqi,archer2049,B.L.LAN,baihuawei,bichaoyang,BJ-WANG,Bokai Li,Brian-K,caifubi,caiyimeng,cathwong,changzherui,ChenDonYY,chenfei_mindspore,chengang,chengbin,chenhaozhe,chenjianping,chenkang,chenweifeng,chuht,chujinjin,davidanugraha,DavidFFFan,DeshiChen,douzhixing,emmmmtang,Erpim,Ethan,fangwenyi,fangzehua,fangzhou0329,fary86,fengyixing,gaoshuanglong,Gaoxiong,gaoyong10,gengdongjie,gongdaguo1,Greatpan,GuoZhibin,guozhijian,hangq,hanhuifeng,haozhang,hedongdong,Henry Shi,heterogeneous_to_backoff_2_0,huangbingjian,huanghui,huangxinjing,hujiahui8,hujingsong,huoxinyou,jachua,jiahongQian,jianghui58,jiangzhenguang,jiaorui,jiaoy1224,jijiarong,jjfeing,JoeyLin,json,JuiceZ,jxl,kairui_kou,KevinYi,kisnwang,KXiong,laiyongqiang,lanzhineng,liangchenghui,liangzelang,LiangZhibo,lianliguang,lichen,ligan,lijunbin,limingqi107,ling,linqingke,liubuyu,liuchao,liuchuting,liujunzhu,liuluobin,liutongtong9,liuyang811,lixiao,liyan2022,liyejun,liyuxia,looop5,luochao60,luojianing,luoyang,luoyuan,lyqlola,maning202007,maoyaomin,Margaret_wangrui,mayadong,MaZhiming,melody,mengyuanli,michaelzhu_70ab,Mohammad Motallebi,moran,NaCN,nomindcarry,OwenSec,panfengfeng,panshaowu,panzhihui,pkuliuliu,qinzheng,qiuzhongya,qujianwei,r1chardf1d0,Renyuan Zhang,RobinGrosman,shaojunsong,shenwei41,Soaringfish,tangdezhi_123,tanghuikang,tan-wei-cheng,TinaMengtingZhang,TronZhang,TuDouNi,VectorSL,wang_ziqi,wanghenchang,wangnan39,wangpingan,wangshaocong,wangshengnan123,wangtongyu6,weichaoran,wind-zyx,wqx,wtcheng,wujueying,wYann,XianglongZeng,xiaohanzhang,xiaotianci,xiaoyao,XinDu,xulei,xumengjuan1,xupan,xwkgch,yanghaoran,yangluhang,yangruoqi713,yangshuo,yangsijia,yangzhenzhang,yanzhenxiang2020,Yanzhi_YI,yao_yf,yefeng,yeyunpeng2020,Yi_zhang95,yide12,YijieChen,YingLai Lin,YingtongHu,youshu,yuchaojie,yuedongli,YuJianfeng,zangqx,ZengZitao,zhangbuxue,zhangdanyang,zhangdong,zhangfanghe,zhangqi,zhangqinghua,zhangyanhui,zhangyinxia,zhangyongxian,zhangzhaoju,zhanzhan,zhengzuohe,ZhidanLiu,zhixinaa,zhoufeng,zhouyaqiang0,zhuguodong,zhupuxu,zhuyuxiao,zichun_ye,zjun,zlq2020,zong_shuai,ZPaC,zuochuanyong,zyli2020,陈宇,范吉斌,冯一航,胡彬,宦晓玲,黄勇,雷元哲,李良灿,李林杰,刘崇鸣,刘力力,刘勇琪,吕浩宇,吕昱峰（Nate.River）,没有窗户的小巷,沈竞兴,十六夜,王程浩,王禹程,王振邦,徐安越,徐永飞,杨旭华,于振华,俞涵,张清华,张澍坤,张栩浩,张学同,赵英灼,周超,周洪叶,朱家兴\n\nContributions of any kind are welcome!\n\n## MindSpore 2.0.0-rc1 Release Notes\n\n### Major Features and Improvements\n\n#### FrontEnd\n\n- [BETA] Statement with \"return\", \"return None\" and with no return of function are supported in `GRAPH_MODE`.\n- [BETA] Object with `list` type are supported in `GRAPH_MODE`.\n- [BETA] Statement with \"raise\" are supported in variable condition situation in `GRAPH_MODE`.\n- [STABLE] Functional call supports data sinking mode.\n- [BETA] The Transformer layer in nn module is added to provide easy-to-use Transformer APIs. Batch_size does not need to be defined. Dynamic seq_length is supported.\n\n#### DataSet\n\n- [STABLE] In the Ascend environment，the timeout waiting time in data sink mode is adjusted to 1900s by default. This solves the problem that the GetNext operator may time out due to environment resource competition and large computing workload in data sinking mode.\n- [STABLE] MindRecord supports to query the schemas and number samples. MindRecord provides multi-process writing mode, allowing users to generate MindRecord data files in parallel.\n- [STABLE] The Dataset pipeline can process any Python object. For details, see [Supporting Python Objects in Dataset Pipeline](https://www.mindspore.cn/tutorials/en/r2.0/advanced/dataset/python_objects.html).\n\n#### AutoParallel\n\n- [STABLE] The strategies of whole parameters can be saved when saving strategy.\n- [STABLE] The Conv3D/MaxPool3D/AvgPool3D distributed operator is supported.\n- [STABLE] Support operator-level parallelism and optimizer-level parallelism under the PyNative with shard: parallel training and the Model API are decoupled to provide basic parallel expression capabilities.\n- [STABLE] Support operator-level parallelism, and optimizer-level parallelism under the Graph mode: parallel training and the Model API are decoupled to provide basic parallel expression capabilities.\n- [BETA] Supports customized distributed graph segmentation, improving the flexibility of distributed training.\n\n#### Runtime\n\n- [STABLE] Control flow supports subgraph sink.\n- [STABLE] Support CUDA 11.6.\n- [STABLE] Support for operator selection and execution of List/Tuple/Scalar type kernel to match native Python expression.\n- [STABLE] Kernel that is not supported by hardware can automatically select CPU kernel.\n- [STABLE] Support heterogeneous execution within subgraph.\n\n#### Ascend\n\n- [STABLE] Support overflow detection scheme and HCCL runtime overflow check.\n- [STABLE] Support dump of communication operators.\n\n#### Profiler\n\n- [STABLE] Rich Profiler collection item configuration, users can collect performance data in more detail.\n\n#### Dump\n\n- [BETA] Single card in PyNatvie mode supports operator overflow detection.\n- [BETA] Graph mode supports hccl operator dump.\n\n### API Change\n\n- [STABLE] Add computing APIs, such as MaxUnpool, ReplicationPad, and GaussianNLLLoss.\n  For details, visit <https://www.mindspore.cn/docs/en/r2.0/api_python/mindspore.html>.\n- [STABLE] Extend inventory API functions, such as AvgPool, pad, norm, and interplate.\n\n#### operator\n\n- [BETA] Add operator primitive for `mindspore.ops.AdaptiveAvgPool3D`.\n- [BETA] Add operator primitive for `mindspore.ops.AffineGrid`.\n- [BETA] Add operator primitive for `mindspore.ops.Angle`.\n- [BETA] Add operator primitive for `mindspore.ops.BartlettWindow`.\n- [BETA] Add operator primitive for `mindspore.ops.Bernoulli`.\n- [BETA] Add operator primitive for `mindspore.ops.BesselI0`.\n- [BETA] Add operator primitive for `mindspore.ops.BesselI1`.\n- [BETA] Add operator primitive for `mindspore.ops.BesselJ0`.\n- [BETA] Add operator primitive for `mindspore.ops.BesselJ1`.\n- [BETA] Add operator primitive for `mindspore.ops.BesselK0`.\n- [BETA] Add operator primitive for `mindspore.ops.BesselK0e`.\n- [BETA] Add operator primitive for `mindspore.ops.BesselK1`.\n- [BETA] Add operator primitive for `mindspore.ops.BesselK1e`.\n- [BETA] Add operator primitive for `mindspore.ops.BesselY0`.\n- [BETA] Add operator primitive for `mindspore.ops.BesselY1`.\n- [BETA] Add operator primitive for `mindspore.ops.Bincount`.\n- [BETA] Add operator primitive for `mindspore.ops.BlackmanWindow`.\n- [BETA] Add operator primitive for `mindspore.ops.ChannelShuffle`.\n- [BETA] Add operator primitive for `mindspore.ops.Cholesky`.\n- [BETA] Add operator primitive for `mindspore.ops.Col2Im`.\n- [BETA] Add operator primitive for `mindspore.ops.Complex`.\n- [BETA] Add operator primitive for `mindspore.ops.ComplexAbs`.\n- [BETA] Add operator primitive for `mindspore.ops.Cross`.\n- [BETA] Add operator primitive for `mindspore.ops.CTCLossV2`.\n- [BETA] Add operator primitive for `mindspore.ops.Cummin`.\n- [BETA] Add operator primitive for `mindspore.ops.Diag`.\n- [BETA] Add operator primitive for `mindspore.ops.Digamma`.\n- [BETA] Add operator primitive for `mindspore.ops.Expand`.\n- [BETA] Add operator primitive for `mindspore.ops.Fmax`.\n- [BETA] Add operator primitive for `mindspore.ops.Gcd`.\n- [BETA] Add operator primitive for `mindspore.ops.Geqrf`.\n- [BETA] Add operator primitive for `mindspore.ops.GLU`.\n- [BETA] Add operator primitive for `mindspore.ops.GridSampler2D`.\n- [BETA] Add operator primitive for `mindspore.ops.GridSampler3D`.\n- [BETA] Add operator primitive for `mindspore.ops.HammingWindow`.\n- [BETA] Add operator primitive for `mindspore.ops.Heaviside`.\n- [BETA] Add operator primitive for `mindspore.ops.Hypot`.\n- [BETA] Add operator primitive for `mindspore.ops.Igamma`.\n- [BETA] Add operator primitive for `mindspore.ops.IndexFill`.\n- [BETA] Add operator primitive for `mindspore.ops.InplaceIndexAdd`.\n- [BETA] Add operator primitive for `mindspore.ops.InplaceUpdateV2`.\n- [BETA] Add operator primitive for `mindspore.ops.Lcm`.\n- [BETA] Add operator primitive for `mindspore.ops.LeftShift`.\n- [BETA] Add operator primitive for `mindspore.ops.LogicalXor`.\n- [BETA] Add operator primitive for `mindspore.ops.Logit`.\n- [BETA] Add operator primitive for `mindspore.ops.LogSpace`.\n- [BETA] Add operator primitive for `mindspore.ops.LuUnpack`.\n- [BETA] Add operator primitive for `mindspore.ops.MatrixDiagPartV3`.\n- [BETA] Add operator primitive for `mindspore.ops.MatrixDiagV3`.\n- [BETA] Add operator primitive for `mindspore.ops.MatrixSetDiagV3`.\n- [BETA] Add operator primitive for `mindspore.ops.MaxPool3DWithArgmax`.\n- [BETA] Add operator primitive for `mindspore.ops.MaxUnpool2D`.\n- [BETA] Add operator primitive for `mindspore.ops.MaxUnpool3D`.\n- [BETA] Add operator primitive for `mindspore.ops.MultiMarginLoss`.\n- [BETA] Add operator primitive for `mindspore.ops.MultinomialWithReplacement`.\n- [BETA] Add operator primitive for `mindspore.ops.Mvlgamma`.\n- [BETA] Add operator primitive for `mindspore.ops.NanToNum`.\n- [BETA] Add operator primitive for `mindspore.ops.NextAfter`.\n- [BETA] Add operator primitive for `mindspore.ops.Orgqr`.\n- [BETA] Add operator primitive for `mindspore.ops.Polygamma`.\n- [BETA] Add operator primitive for `mindspore.ops.ResizeBilinearV2`.\n- [BETA] Add operator primitive for `mindspore.ops.RightShift`.\n- [BETA] Add operator primitive for `mindspore.ops.ScatterNdDiv`.\n- [BETA] Add operator primitive for `mindspore.ops.ScatterNdMul`.\n- [BETA] Add operator primitive for `mindspore.ops.SearchSorted`.\n- [BETA] Add operator primitive for `mindspore.ops.Sinc`.\n- [BETA] Add operator primitive for `mindspore.ops.Trace`.\n- [BETA] Add operator primitive for `mindspore.ops.Tril`.\n- [BETA] Add operator primitive for `mindspore.ops.TrilIndices`.\n- [BETA] Add operator primitive for `mindspore.ops.TriuIndices`.\n- [BETA] Add operator primitive for `mindspore.ops.UniqueConsecutive`.\n- [STABLE] Add operator primitive for `mindspore.ops.Cummax`.\n- [STABLE] Add operator primitive for `mindspore.ops.FillV2`.\n- [STABLE] Add operator primitive for `mindspore.ops.IsClose`.\n- [STABLE] Add operator primitive for `mindspore.ops.MatrixSolve`.\n- [STABLE] Add operator primitive for `mindspore.ops.Median`.\n- [STABLE] Add operator primitive for `mindspore.ops.MultilabelMarginLoss`.\n- [STABLE] Add operator primitive for `mindspore.ops.NonZero`.\n- [STABLE] Add operator primitive for `mindspore.ops.Pdist`.\n- [STABLE] Add operator primitive for `mindspore.ops.Polar`.\n- [STABLE] Add operator primitive for `mindspore.ops.RandomGamma`.\n- [STABLE] Add operator primitive for `mindspore.ops.RandomPoisson`.\n- [STABLE] Add operator primitive for `mindspore.ops.RandomShuffle`.\n- [STABLE] Add operator primitive for `mindspore.ops.Renorm`.\n- [STABLE] Add operator primitive for `mindspore.ops.ScatterNdMax`.\n- [STABLE] Add operator primitive for `mindspore.ops.ScatterNdMin`.\n- [STABLE] Add operator primitive for `mindspore.ops.Svd`.\n- [STABLE] Add operator primitive for `mindspore.ops.TripletMarginLoss`.\n\n#### Deleted APIs\n\n- The `mindspore.compression` feature was deprecated at MindSpore 1.8 and is removed in this version.\n  The following `mindspore.nn.quant` interfaces are also removed simultaneously: `mindspore.nn.FakeQuantWithMinMaxObserver`, `mindspore.nn.Conv2dBnFoldQuantOneConv`, `mindspore.nn.Conv2dBnFoldQuant`, `mindspore.nn.Conv2dBnWithoutFoldQuant`, `mindspore.nn.Conv2dQuant`, `mindspore.nn.DenseQuant`, `mindspore.nn.ActQuant`, `mindspore.nn.TensorAddQuant`, `mindspore.nn.ActQuant`, `mindspore.nn.MulQuant`. Please use [MindSpore Golden Stick](https://gitee.com/mindspore/golden-stick) instead to implement QuantAwareTraining in MindSpore.\n- The `mindspore.dataset.close_pool`, `mindspore.dataset.to_device`, and `mindspore.dataset.set_dynamic_columns` interfaces are discarded in earlier version and being removed in this version.\n\n#### Backwards Incompatible Change\n\n- Interface: mindspore.set_context(mode=PYNATIVE_MODE)\n\n  Change: The default value is changed from GRAPH_MODE to PYNATIVE_MODE.\n\n  Description: If the running mode is not set and the diagram mode needs to be set, use the following method:\n  mindspore.set_context(mode=GRAPH_MODE).\n\n  <table>\n  <tr>\n  <td style=\"text-align:center\"> Original Interface </td> <td style=\"text-align:center\"> Interface v2.0.0-rc1 </td>\n  </tr>\n  <tr>\n  <td><pre>\n  mindspore.set_context(mode=GRAPH_MODE)\n  </pre>\n  </td>\n  <td><pre>\n  mindspore.set_context(mode=PYNATIVE_MODE)\n  </pre>\n  </td>\n  </tr>\n  </table>\n\n- Interface: mindspore.train.Model.train\n\n  Change: The default value of dataset_sink_mode is changed from True to False.\n\n  Description: If dataset_sink_mode is not set and the data sinking mode needs to be set, use the following method:\n  Model.train(dataset_sink_mode=True).\n\n  <table>\n  <tr>\n  <td style=\"text-align:center\"> Original Interface </td> <td style=\"text-align:center\"> Interface v2.0.0-rc1 </td>\n  </tr>\n  <tr>\n  <td><pre>\n  Model.train(dataset_sink_mode=True)\n  </pre>\n  </td>\n  <td><pre>\n  Model.train(dataset_sink_mode=False)\n  </pre>\n  </td>\n  </tr>\n  </table>\n\n- Interface: mindspore.export\n\n  Change: The file_format parameter is changed from AIR to no default value.\n\n  Description: If file_format is not set in the original mode, you need to set file_format additionally. In this case, use the following method:\n  mindspore.export(net, *inputs, file_name, file_format=\"AIR\", **kwargs).\n\n  <table>\n  <tr>\n  <td style=\"text-align:center\"> Original Interface </td> <td style=\"text-align:center\"> Interface v2.0.0-rc1 </td>\n  </tr>\n  <tr>\n  <td><pre>\n  mindspore.export(net, *inputs, file_name,\n                   file_format=\"AIR\", **kwargs)\n  </pre>\n  </td>\n  <td><pre>\n  mindspore.export(net, *inputs, file_name,\n                   file_format, **kwargs)\n  </pre>\n  </td>\n  </tr>\n  </table>\n\n- Interface: mindspore.ops.norm\n\n  Change: The ord parameter function is extended to support multiple forms.\n\n  <table>\n  <tr>\n  <td style=\"text-align:center\"> Original Interface </td> <td style=\"text-align:center\"> Interface v2.0.0-rc1 </td>\n  </tr>\n  <tr>\n  <td><pre>\n  ops.norm(input_x, axis, p=2, keep_dims=False, epsilon=1e-12)\n  >>> # Example:\n  >>> input = Tensor(np.array([[[1.0, 2.0], [3.0, 4.0]],\n  ...                          [[5.0, 6.0], [7.0, 8.0]]]).astype(np.float32))\n  >>> output = ops.norm(input, [0, 1], p=2)\n  </pre></td>\n  <td><pre>\n  ops.norm(A, ord=None, dim=None, keepdim=False, *, dtype=None)\n  >>> # Example:\n  >>> input = Tensor(np.array([[[1.0, 2.0], [3.0, 4.0]],\n  ...                          [[5.0, 6.0], [7.0, 8.0]]]).astype(np.float32))\n  >>> output = ops.norm(input, ord=2, dim=(0, 1))\n  </pre>\n  </td>\n  </tr>\n  </table>\n\n- Interface: mindspore.Tensor.norm\n\n  Change: The ord parameter function is extended to support multiple forms.\n\n  Description: For details, see the example of ops.norm.\n\n  <table>\n  <tr>\n  <td style=\"text-align:center\"> Original Interface </td> <td style=\"text-align:center\"> Interface v2.0.0-rc1 </td>\n  </tr>\n  <tr>\n  <td><pre>\n  Tensor.norm(axis, p=2, keep_dims=False, epsilon=1e-12)\n  </pre>\n  </td>\n  <td><pre>\n  Tensor.norm(ord=None, dim=None, keepdim=False, *, dtype=None)\n  </pre>\n  </td>\n  </tr>\n  </table>\n\n- Interface: mindspore.ops.dropout\n\n  Change: The seed0 and seed1 parameters are deleted and seed=None parameter is added. Instead of returning Tensors and masks, only Tensors are returned. The input parameter training=True is added.\n\n  <table>\n  <tr>\n  <td style=\"text-align:center\"> Original Interface </td> <td style=\"text-align:center\"> Interface v2.0.0-rc1 </td>\n  </tr>\n  <tr>\n  <td><pre>\n  ops.dropout(x, p=0.5, seed0=0, seed1=0)\n  >>> # Example:\n  >>> input = Tensor(((20, 16), (50, 50)),\n  ...                mindspore.float32)\n  >>> output, mask = dropout(x, p=0.5)\n  </pre>\n  </td>\n  <td><pre>\n  ops.dropout(input, p=0.5, training=True, seed=None)\n  >>> # Example:\n  >>> input = Tensor(((20, 16), (50, 50)),\n  ...                mindspore.float32)\n  >>> output = ops.dropout(input, p=0.5，training=True)\n  </pre>\n  </td>\n  </tr>\n  </table>\n\n- Interface: mindspore.ops.dropout2d\n\n  Change: Return value is changed from Tensor and mask to Tensor only. The input parameter training=True is added.\n\n  <table>\n  <tr>\n  <td style=\"text-align:center\"> Original Interface </td> <td style=\"text-align:center\"> Interface v2.0.0-rc1 </td>\n  </tr>\n  <tr>\n  <td><pre>\n  ops.dropout2d(x, p=0.5)\n  >>> # Example:\n  >>> input = Tensor(np.ones([2, 1, 2, 3]),\n  ...                mindspore.float32)\n  >>> output, mask = dropout2d(input, 0.5)\n  </pre>\n  </td>\n  <td><pre>\n  ops.dropout2d(input, p=0.5, training=True)\n  >>> # Example:\n  >>> input = Tensor(np.ones([2, 1, 2, 3]),\n  ...                mindspore.float32)\n  >>> output = ops.dropout2d(input, 0.5, training=True)\n  </pre>\n  </td>\n  </tr>\n  </table>\n\n- Interface: mindspore.ops.dropout3d\n\n  Change: Return value is changed from Tensor and mask to Tensor only. The input parameter training=True is added.\n\n  <table>\n  <tr>\n  <td style=\"text-align:center\"> Original Interface </td> <td style=\"text-align:center\"> Interface v2.0.0-rc1 </td>\n  </tr>\n  <tr>\n  <td><pre>\n  ops.dropout3d(x, p=0.5)\n  >>> # Example:\n  >>> input = Tensor(np.ones([2, 1, 2, 3]),\n  ...                mindspore.float32)\n  >>> output, mask = dropout3d(input, 0.5)\n  </pre>\n  </td>\n  <td><pre>\n  ops.dropout3d(input, p=0.5, training=True)\n  >>> # Example:\n  >>> input = Tensor(np.ones([2, 1, 2, 3]),\n  ...                mindspore.float32)\n  >>> output = ops.dropout3d(input, 0.5, training=True)\n  </pre>\n  </td>\n  </tr>\n  </table>\n\n- Interface: mindspore.ops.std\n\n  Change: The interface is reconstructed, and the interface usage mode is more consistent with user habits.\n\n  Description: If parameter `unbiased` has been set, use the following alternative: `unbiased=False` -> `ddof=0`, `unbiased=True` -> `ddof=1`.\n\n  <table>\n  <tr>\n  <td style=\"text-align:center\"> Original Interface </td> <td style=\"text-align:center\"> Interface v2.0.0-rc1 </td>\n  </tr>\n  <tr>\n  <td><pre>\n  ops.std(input_x, axis=(), unbiased=True, keep_dims=False)\n  </pre>\n  </td>\n  <td><pre>\n  ops.std(input, axis=None, ddof=0, keepdims=False)\n  </pre>\n  </td>\n  </tr>\n  </table>\n\n- Interface: mindspore.load_param_into_net\n\n  Change: Parameters that are not loaded in the ckpt are added as return values.\n\n  <table>\n  <tr>\n  <td style=\"text-align:center\"> Original Interface </td> <td style=\"text-align:center\"> Interface v2.0.0-rc1 </td>\n  </tr>\n  <tr>\n  <td><pre>\n  net_param = load_param_into_net()\n  </pre>\n  </td>\n  <td><pre>\n  net_param, ckpt_param = load_param_into_net()\n  </pre>\n  </td>\n  </tr>\n  </table>\n\n- Interface: mindspore.nn.BCELoss\n\n  Change: The default value of `reduction` is changed from 'none' to 'mean'.\n\n  <table>\n  <tr>\n  <td style=\"text-align:center\"> Original Interface </td> <td style=\"text-align:center\"> Interface v2.0.0-rc1 </td>\n  </tr>\n  <tr>\n  <td><pre>\n  BCELoss(weight=None, reduction='none')\n  >>> # Example:\n  >>> weight = Tensor(np.array([[1.0, 2.0, 3.0],\n  ...                           [4.0, 3.3, 2.2]]),\n  ...                 mindspore.float32)\n  >>> loss = nn.BCELoss(weight=weight, reduction='mean')\n  >>> logits = Tensor(np.array([[0.1, 0.2, 0.3],\n  ...                           [0.5, 0.7, 0.9]]),\n  ...                 mindspore.float32)\n  >>> labels = Tensor(np.array([[0, 1, 0], [0, 0, 1]]),\n  ...                 mindspore.float32)\n  >>> output = loss(logits, labels)\n  >>> print(output)\n  >>> 1.8952923\n  </pre>\n  </td>\n  <td><pre>\n  BCELoss(weight=None, reduction='mean')\n  >>> # Example:\n  >>> weight = Tensor(np.array([[1.0, 2.0, 3.0],\n  ...                           [4.0, 3.3, 2.2]]),\n  ...                 mindspore.float32)\n  >>> loss = nn.BCELoss(weight=weight)\n  >>> logits = Tensor(np.array([[0.1, 0.2, 0.3],\n  ...                           [0.5, 0.7, 0.9]]),\n  ...                 mindspore.float32)\n  >>> labels = Tensor(np.array([[0, 1, 0], [0, 0, 1]]),\n  ...                 mindspore.float32)\n  >>> output = loss(logits, labels)\n  >>> print(output)\n  >>> 1.8952923\n  </pre>\n  </td>\n  </tr>\n  </table>\n\n- Interface: mindspore.ops.split\n\n  Change: The interface is reconstructed. The interface usage mode is more suitable for users. The sequence of the second and third parameters is adjusted, and the split_size_or_sections function is modified and extended.\n\n  <table>\n  <tr>\n  <td style=\"text-align:center\"> Original Interface </td> <td style=\"text-align:center\"> Interface v2.0.0-rc1 </td>\n  </tr>\n  <tr>\n  <td><pre>\n  ops.split(input_x, axis=0, output_num=1)\n  >>> # Example:\n  >>> input = Tensor(np.array([[1, 1, 1, 1], [2, 2, 2, 2]]),\n  ...                mindspore.int32)\n  >>> output = ops.split(input, axis=1, output_num=4)\n  </pre>\n  </td>\n  <td><pre>\n  ops.split(tensor, split_size_or_sections, axis=0)\n  >>> # Example:\n  >>> input = Tensor(np.array([[1, 1, 1, 1], [2, 2, 2, 2]]),\n  ...                mindspore.int32)\n  >>> output = ops.split(input, split_size_or_sections=1, axis=1)\n  </pre>\n  </td>\n  </tr>\n  </table>\n\n- Interface: mindspore.Tensor.split\n\n  Change: The interface is reconstructed. The interface usage mode is more suitable for users. The positions of the two parameters is adjusted, and the split_size_or_sections function is modified and extended.\n\n  Description: For details, see the example of ops.split.\n\n  <table>\n  <tr>\n  <td style=\"text-align:center\"> Original Interface </td> <td style=\"text-align:center\"> Interface v2.0.0-rc1 </td>\n  </tr>\n  <tr>\n  <td><pre>\n  Tensor.split(axis=0, output_num=1)\n  </pre>\n  </td>\n  <td><pre>\n  Tensor.split(split_size_or_sections, axis=0)\n  </pre>\n  </td>\n  </tr>\n  </table>\n\n- Interface: mindspore.ops.pad\n\n  Change: Modify the parameter name paddings to padding, and the mode and value functions are added.\n\n  <table>\n  <tr>\n  <td style=\"text-align:center\"> Original Interface </td> <td style=\"text-align:center\"> Interface v2.0.0-rc1 </td>\n  </tr>\n  <tr>\n  <td><pre>\n  ops.pad(input_x, paddings)\n  >>> # Example:\n  >>> input_x = Tensor(np.array([[-0.1, 0.3, 3.6],\n  ...                            [0.4, 0.5, -3.2]]),\n  ...                  mindspore.float32)\n  >>> paddings = ((1, 2), (2, 1))\n  >>> output = ops.pad(input_x, paddings)\n  </pre>\n  </td>\n  <td><pre>\n  ops.pad(input_x, padding, mode='constant', value=None)\n  >>> # Example:\n  >>> input_x = Tensor(np.array([[-0.1, 0.3, 3.6],\n  ...                            [0.4, 0.5, -3.2]]),\n  ...                  mindspore.float32)\n  >>> paddings = (2, 1, 1, 2)\n  >>> output = ops.pad(input_x, paddings)\n  </pre>\n  </td>\n  </tr>\n  </table>\n\n- Interface: mindspore.ops.meshgrid\n\n  Change: The input parameter is changed from `inputs` to `*input`.\n\n  <table>\n  <tr>\n  <td style=\"text-align:center\"> Original Interface </td> <td style=\"text-align:center\"> Interface v2.0.0-rc1 </td>\n  </tr>\n  <tr>\n  <td><pre>\n  ops.meshgrid(inputs, indexing='xy')\n  >>> # Example:\n  >>> x = Tensor(np.array([1, 2, 3, 4]).astype(np.int32))\n  >>> y = Tensor(np.array([5, 6, 7]).astype(np.int32))\n  >>> z = Tensor(np.array([8, 9, 0, 1, 2]).astype(np.int32))\n  output = ops.meshgrid((x, y, z), indexing='xy')\n  </pre>\n  </td>\n  <td><pre>\n  ops.meshgrid(*inputs, indexing='xy')\n  >>> # Example:\n  >>> x = Tensor(np.array([1, 2, 3, 4]).astype(np.int32))\n  >>> y = Tensor(np.array([5, 6, 7]).astype(np.int32))\n  >>> z = Tensor(np.array([8, 9, 0, 1, 2]).astype(np.int32))\n  output = ops.meshgrid(x, y, z, indexing='xy')\n  </pre>\n  </td>\n  </tr>\n  </table>\n\n- Interface: mindspore.ops.max\n\n  Change: Return value exchange sequence. The value is changed from \"index, value\" to \"value, index\".\n\n  <table>\n  <tr>\n  <td style=\"text-align:center\"> Original Interface </td> <td style=\"text-align:center\"> Interface v2.0.0-rc1 </td>\n  </tr>\n  <tr>\n  <td><pre>\n  ops.max(x, axis=0, keep_dims=False)\n  >>> # Example:\n  >>> input = Tensor(np.array([0.0, 0.4, 0.6, 0.7, 0.1]),\n  ...                mindspore.float32)\n  >>> index, output = ops.max(input)\n  >>> print(index, output)\n  >>> 3 0.7\n  </pre>\n  </td>\n  <td><pre>\n  ops.max(input, axis=None, keepdims=False, *, initial=None, where=True, return_indices=False)\n  >>> # Example:\n  >>> input = Tensor(np.array([0.0, 0.4, 0.6, 0.7, 0.1]),\n  ...                mindspore.float32)\n  >>> output, index = ops.max(input, axis=0)\n  >>> print(output, index)\n  </pre>\n  </td>\n  </tr>\n  </table>\n\n- Interface: mindspore.ops.min\n\n  Change: Return value exchange sequence. The value is changed from \"index, value\" to \"value, index\".\n\n  <table>\n  <tr>\n  <td style=\"text-align:center\"> Original Interface </td> <td style=\"text-align:center\"> Interface v2.0.0-rc1 </td>\n  </tr>\n  <tr>\n  <td><pre>\n  ops.min(x, axis=0, keep_dims=False)\n  >>> # Example:\n  >>> input = Tensor(np.array([0.0, 0.4, 0.6, 0.7, 0.1]),\n  ...                mindspore.float32)\n  >>> index, output = ops.min(input)\n  >>> 0 0.0\n  </pre>\n  </td>\n  <td><pre>\n  ops.min(input, axis=None, keepdims=False, *, initial=None, where=True, return_indices=False)\n  >>> # Example:\n  >>> input = Tensor(np.array([0.0, 0.4, 0.6, 0.7, 0.1]),\n  ...                mindspore.float32)\n  >>> output, index = ops.min(input, keepdims=True)\n  >>> 0.0 0\n  </pre>\n  </td>\n  </tr>\n  </table>\n\n- Interface: mindspore.ops.random_gamma\n\n  Change: The seed2 parameter is deleted and seed=0 is changed to None. The framework behavior is unified and complies with the actual application scenarios and habits of users.\n\n  <table>\n  <tr>\n  <td style=\"text-align:center\"> Original Interface </td> <td style=\"text-align:center\"> Interface v2.0.0-rc1 </td>\n  </tr>\n  <tr>\n  <td><pre>\n  ops.random_gamma(shape, alpha, seed=0, seed2=0)\n  </pre>\n  </td>\n  <td><pre>\n  ops.random_gamma(shape, alpha, seed=None)\n  </pre>\n  </td>\n  </tr>\n  </table>\n\n- Interface: mindspore.ops.standard_laplace\n\n  Change: The seed2 parameter is deleted and seed=0 is changed to None. The framework behavior is unified and complies with the actual application scenarios and habits of users.\n\n  <table>\n  <tr>\n  <td style=\"text-align:center\"> Original Interface </td> <td style=\"text-align:center\"> Interface v2.0.0-rc1 </td>\n  </tr>\n  <tr>\n  <td><pre>\n  ops.standard_laplace(shape, seed=0, seed2=0)\n  </pre>\n  </td>\n  <td><pre>\n  ops.standard_laplace(shape, seed=None)\n  </pre>\n  </td>\n  </tr>\n  </table>\n\n- Interface: mindspore.ops.standard_normal\n\n  Change: The seed2 parameter is deleted and seed=0 is changed to None. The framework behavior is unified and complies with the actual application scenarios and habits of users.\n\n  <table>\n  <tr>\n  <td style=\"text-align:center\"> Original Interface </td> <td style=\"text-align:center\"> Interface v2.0.0-rc1 </td>\n  </tr>\n  <tr>\n  <td><pre>\n  ops.standard_normal(shape, seed=0, seed2=0)\n  </pre>\n  </td>\n  <td><pre>\n  ops.standard_normal(shape, seed=None)\n  </pre>\n  </td>\n  </tr>\n  </table>\n\n- Interface: mindspore.ops.bernoulli\n\n  Change: The default value of seed is changed from -1 to None. Meets the actual application scenario.\n\n  <table>\n  <tr>\n  <td style=\"text-align:center\"> Original Interface </td> <td style=\"text-align:center\"> Interface v2.0.0-rc1 </td>\n  </tr>\n  <tr>\n  <td><pre>\n  ops.bernoulli(x, p=0.5, seed=-1)\n  </pre>\n  </td>\n  <td><pre>\n  ops.bernoulli(input, p=0.5, seed=None)\n  </pre>\n  </td>\n  </tr>\n  </table>\n\n- Interface: mindspore.data_sink\n\n  Change: Deleted the steps parameter. Parameter name jit is changed to jit_config, and new input_signature parameter is added. The usability is improved to meet the requirements of actual application scenarios.\n\n  <table>\n  <tr>\n  <td style=\"text-align:center\"> Original Interface </td> <td style=\"text-align:center\"> Interface v2.0.0-rc1 </td>\n  </tr>\n  <tr>\n  <td><pre>\n  mindspore.data_sink(fn, dataset, steps,\n                      sink_size=1, jit=False)\n  </pre>\n  </td>\n  <td><pre>\n  mindspore.data_sink(fn, dataset, sink_size=1,\n                      jit_config=None, input_signature=None)\n  </pre>\n  </td>\n  </tr>\n  </table>\n\n- Interface: mindspore.ops.conv2d\n\n  Change: Extend Interface Function. Add the bias parameter and modify the parameter name and parameter sequence.\n\n  <table>\n  <tr>\n  <td style=\"text-align:center\"> Original Interface </td> <td style=\"text-align:center\"> Interface v2.0.0-rc1 </td>\n  </tr>\n  <tr>\n  <td><pre>\n  conv2d(inputs, weight, pad_mode=\"valid\",\n         padding=0, stride=1, dilation=1, group=1)\n  </pre>\n  </td>\n  <td><pre>\n  conv2d(input, weight, bias=None, stride=1,\n         pad_mode=\"valid\", padding=0, dilation=1, groups=1)\n  </pre>\n  </td>\n  </tr>\n  </table>\n\n- Interface: mindspore.dataset.vision.Pad\n\n  Change: Adjust the input parameter padding of Pad, RandomCrop, and RandomCropWithBbox. When the input length of Padding is 2, the first value is used to fill the left/upper boundary, the second value is used to fill the right/lower boundary, and the first value is used to fill the left/right boundary. Fill the upper/lower boundary with the second value.\n\n  Description: The padding parameter whose size is 2 is not compatible with the effect of the earlier version. The padding parameter needs to be explicitly represented (left, right, top, and bottom).\n\n  <table>\n  <tr>\n  <td style=\"text-align:center\"> Original Interface </td> <td style=\"text-align:center\"> Interface v2.0.0-rc1 </td>\n  </tr>\n  <tr>\n  <td><pre>\n  mindspore.dataset.vision.Pad(padding=(1,2))\n  Indicates that the left/upper part of the image is filled with 1 pixel,\n  and the right/down part is filled with 2 pixels.\n  </pre>\n  </td>\n  <td><pre>\n  mindspore.dataset.vision.Pad(padding=(1,2,1,2))\n  Indicates that the left/upper part of the image is filled with 1 pixel,\n  and the right/down part is filled with 2 pixels.\n  </pre>\n  </td>\n  </tr>\n  </table>\n\n- Interface: mindspore.dataset.Dataset.map\n\n  Change: Delete the column_order parameter. In most cases, output_columns and column_order have the same value. Therefore, column_order does not need to be transferred. To adjust the sequence of data columns, use mindspore.dataset.Dataset.project.\n\n  Description:\n\n  1. If the column sequence does not need to be changed, delete the column_order parameter.\n  2. If you need to specify the data column sequence, delete the column_order parameter and add a project method to the end of the parameter for column transformation (as in the following example).\n\n  <table>\n  <tr>\n  <td style=\"text-align:center\"> Original Interface </td> <td style=\"text-align:center\"> Interface v2.0.0-rc1 </td>\n  </tr>\n  <tr>\n  <td><pre>\n  >>> dataset = dataset.map(operations=[transforms],\n  ...                       input_columns=[\"column_a\"],\n  ...                       output_columns=[\"column_b\", \"column_c\"],\n  ...                       column_order=[\"column_c\", \"column_b\"])\n  </pre>\n  </td>\n  <td><pre>\n  >>> dataset = dataset.map(operations=[transforms],\n  ...                       input_columns=[\"column_a\"],\n  ...                       output_columns=[\"column_b\", \"column_c\"])\n  >>> dataset = dataset.project([\"column_c\", column_b\"])\")\n  </pre>\n  </td>\n  </tr>\n  </table>\n\n- Interface: mindspore.dataset.Dataset.batch\n\n  Change: Delete the column_order parameter. In most cases, output_columns and column_order have the same value. Therefore, column_order does not need to be transferred. To adjust the sequence of data columns, use mindspore.dataset.Dataset.project.\n\n  Description:\n\n  1. If the column sequence does not need to be changed, delete the column_order parameter.\n  2. If you need to specify the data column sequence, delete the column_order parameter and add a project method to the end of the parameter for column transformation (as in the following example).\n\n  <table>\n  <tr>\n  <td style=\"text-align:center\"> Original Interface </td> <td style=\"text-align:center\"> Interface v2.0.0-rc1 </td>\n  </tr>\n  <tr>\n  <td><pre>\n  >>> dataset = dataset.batch(batch_size=4,\n  ...                         input_columns=[\"column_a\"],\n  ...                         output_columns=[\"column_b\", \"column_c\"],\n  ...                         column_order=[\"column_c\", \"column_b\"])\n  </pre>\n  </td>\n  <td><pre>\n  >>> dataset = dataset.batch(batch_size=4, input_columns=[\"column_a\"]\n  ...                         output_columns=[\"column_b\", \"column_c\"])\n  >>> dataset = dataset.project([\"column_c\", column_b\"])\")\n  </pre>\n  </td>\n  </tr>\n  </table>\n\n- Interface: mindspore.dataset.Dataset.batch\n\n  Change: Split the batch method into two methods: batch and padded_batch. The pad_info parameter is moved from the batch method to the padded_batch method.\n\n  Description: To use the pad_info parameter, use the padded_batch method instead.\n\n  <table>\n  <tr>\n  <td style=\"text-align:center\"> Original Interface </td> <td style=\"text-align:center\"> Interface v2.0.0-rc1 </td>\n  </tr>\n  <tr>\n  <td><pre>\n  >>> dataset = dataset.batch(batch_size=4,\n  ...                         drop_remainder=True, pad_info=...)\n  </pre>\n  </td>\n  <td><pre>\n  >>> dataset = dataset.padded_batch(batch_size=4,\n  ...                                drop_remainder=True, pad_info=...)\n  </pre>\n  </td>\n  </tr>\n  </table>\n\n### Bug fixes\n\n- [I66PE6] fix AssignSub primitive abnormal input leads to coredump.\n\n- [I6F5E6] fix data_sink function timeout on Ascend.\n\n### Others\n\n- Windows support is still being optimized,this version does not support now.It will be available for download in version 2.0.\n\n### Contributors\n\nThanks goes to these wonderful people:\n\nalashkari,anzhengqi,archer2049,B.L.LAN,baihuawei,bichaoyang,BJ-WANG,Bokai Li,Brian-K,caifubi,caiyimeng,cathwong,changzherui,ChenDonYY,chenfei_mindspore,chengang,chengbin,chenhaozhe,chenjianping,chenkang,chenweifeng,chuht,chujinjin,davidanugraha,DavidFFFan,DeshiChen,douzhixing,emmmmtang,Erpim,Ethan,fangwenyi,fangzehua,fangzhou0329,fary86,fengyixing,gaoshuanglong,Gaoxiong,gaoyong10,gengdongjie,gongdaguo1,Greatpan,GuoZhibin,guozhijian,hangq,hanhuifeng,haozhang,hedongdong,Henry Shi,heterogeneous_to_backoff_2_0,huangbingjian,huanghui,huangxinjing,hujiahui8,hujingsong,huoxinyou,jachua,jiahongQian,jianghui58,jiangzhenguang,jiaorui,jiaoy1224,jijiarong,jjfeing,JoeyLin,json,JuiceZ,jxl,kairui_kou,KevinYi,kisnwang,KXiong,laiyongqiang,lanzhineng,liangchenghui,liangzelang,LiangZhibo,lianliguang,lichen,ligan,lijunbin,limingqi107,ling,linqingke,liubuyu,liuchao,liuchuting,liujunzhu,liuluobin,liutongtong9,liuyang811,lixiao,liyan2022,liyejun,liyuxia,looop5,luochao60,luojianing,luoyang,luoyuan,lyqlola,maning202007,maoyaomin,Margaret_wangrui,mayadong,MaZhiming,melody,mengyuanli,michaelzhu_70ab,Mohammad Motallebi,moran,NaCN,nomindcarry,OwenSec,panfengfeng,panshaowu,panzhihui,pkuliuliu,qinzheng,qiuzhongya,qujianwei,r1chardf1d0,Renyuan Zhang,RobinGrosman,shaojunsong,shenwei41,Soaringfish,tangdezhi_123,tanghuikang,tan-wei-cheng,TinaMengtingZhang,TronZhang,TuDouNi,VectorSL,wang_ziqi,wanghenchang,wangnan39,wangpingan,wangshaocong,wangshengnan123,wangtongyu6,weichaoran,wind-zyx,wqx,wtcheng,wujueying,wYann,XianglongZeng,xiaohanzhang,xiaotianci,xiaoyao,XinDu,xulei,xumengjuan1,xupan,xwkgch,yanghaoran,yangluhang,yangruoqi713,yangshuo,yangsijia,yangzhenzhang,yanzhenxiang2020,Yanzhi_YI,yao_yf,yefeng,yeyunpeng2020,Yi_zhang95,yide12,YijieChen,YingLai Lin,YingtongHu,youshu,yuchaojie,yuedongli,YuJianfeng,zangqx,ZengZitao,zhangbuxue,zhangdanyang,zhangdong,zhangfanghe,zhangqi,zhangqinghua,zhangyanhui,zhangyinxia,zhangyongxian,zhangzhaoju,zhanzhan,zhengzuohe,ZhidanLiu,zhixinaa,zhoufeng,zhouyaqiang0,zhuguodong,zhupuxu,zhuyuxiao,zichun_ye,zjun,zlq2020,zong_shuai,ZPaC,zuochuanyong,zyli2020,陈宇,范吉斌,冯一航,胡彬,宦晓玲,黄勇,雷元哲,李良灿,李林杰,刘崇鸣,刘力力,刘勇琪,吕浩宇,吕昱峰（Nate.River）,没有窗户的小巷,沈竞兴,十六夜,王程浩,王禹程,王振邦,徐安越,徐永飞,杨旭华,于振华,俞涵,张清华,张澍坤,张栩浩,张学同,赵英灼,周超,周洪叶,朱家兴\n\nContributions of any kind are welcome!\n\n## MindSpore Lite 2.0.0-rc1 Release Notes\n\n### Major Features and Improvements\n\n#### MindSpore Lite Cloud Inference\n\nThe original MindSpore Lite is mainly used for edge devices such as mobile phones and head units. Cloud inference is added to support scenarios with multiple backend hardware resources on the cloud, supports Ascend and NVIDIA GPU inference cards, and efficiently utilizes multi-core resources on the cloud.\n\nThe original cloud inference integrated through MindSpore training can be changed to MindSpore Lite. For details, see [Quick Start to Cloud-side Inference](https://mindspore.cn/lite/docs/en/r2.0/quick_start/one_hour_introduction_cloud.html). To retain the original integration method, see [Inference](https://mindspore.cn/docs/en/r2.0/faq/inference.html).\n\n- [STABLE] Support MindIR model files.\n- [STABLE] Third-party Onnx, TensorFlow, and Caffe models can be converted to MindIR model files using the MindSpore Lite conversion tool.\n- [STABLE] One release package supports multiple hardware backends: Ascend 310/310P/910, NVIDIA GPU, CPU.\n- [STABLE] Supports the `Model` interface and `ModelParallelRunner` concurrent inference interface.\n- [STABLE] Supports C++, Python, and Java inference interfaces.\n\n#### API\n\n- Due to the defects of the original Python API that many configuration parameters and complex usage, the usability of The Python APIs are optimized in version 2.0. The optimizations include class construction methods and class attribute adjustment. In addition, the Python APIs in version 2.0 and later will be integrated into the cloud-side inference scenario, which are incompatible with Python APIs of the earlier versions. For details, see [Python API](https://www.mindspore.cn/lite/api/en/r2.0/mindspore_lite.html).\n\n## MindSpore 2.0.0-alpha Release Notes\n\n### Major Features and Improvements\n\n#### PyNative\n\n- The default mode of MindSpore is switched to PyNative. If you want to manually set the mode, please refer to [Computational Graph](https://www.mindspore.cn/tutorials/en/r2.0.0-alpha/advanced/compute_graph.html).\n- Support dynamic shape without padding, three networks are supported as demos: Transformer-GPU, YOLOV5-GPU, ASR-Ascend. Transformer-GPU and YOLOV5-GPU can be downloaded from [models](https://gitee.com/mindspore/models/tree/dynamic_shape). Only the following operators are available on Ascend backend: Add、Assign、BatchMatMul、BiasAdd、BiasAddGrad、Cast、Conv2D、Conv2DBackpropFilter、Conv2DBackpropInput、CTCLoss、Div、Dropout、DropoutDoMask、Equal、ExpandDims、Gather、GetNext、LayerNorm、LayerNormGrad、LessEqual、Load、Log、LogicalAnd、LogicalNot、LogicalOr、LogSoftmax、LogSoftmaxGrad、MatMul、Maximum、Mul、Neg、NotEqual、NPUAllocFloatStatus、NPUClearFloatStatus、OneHot、RealDiv、Reciprocal、ReduceMean、ReduceSum、ReLU、ReluGrad、Reshape、Select、Softmax、StridedSlice、Sub、Tile、Transpose、UnsortedSegmentSum、ZerosLike。The remaining operators have not been fully verified, please use them as appropriate.\n\n#### DataSet\n\n- The TFRecordDataset API can directly read TFRecord files compressed by GZIP or ZLIB.\n- The NumpySlicesDataset API can process data of different dimensions at the same time.\n- Optimize the structure of error log to display more clear call stack information for debugging.\n- Fixed `mindspore.dataset.config.set_seed` does not take effect for random seeds in distributed training scenarios.\n\n#### AutoParallel\n\n- Supports more operators with distributed implements.\n\n  Element Wise Operators:AddN, BitwiseAnd, BitwiseOr, BitwiseXor, CumProd, HShrink, HSigmoid, IsFinite, Mish, MulNoNan, Rint, SeLU, SoftShrink, TruncateDiv, TruncateMod, Xdivy Xlogy, InplaceAdd, InplacSub, InplaceUpdate, Cdist, L2Loss, Lerp.\n\n  Math Operators:SquaredDifference, Erfinv, MaskedFill, SplitV, Gamma, KLDivLoss, LinSpace.\n\n  Scatter Operators:ScatterAdd,ScatterDiv,ScatterMax,ScatterMul,ScatterNdAdd,ScatterNdSub,ScatterNdUpdate,ScatterSub,TensorScatterAdd,TensorScatterDiv,TensorScatterMax,TensorScatterMax,TensorScatterMul,TensorScatterAdd,TensorScatterUpdate.\n\n- Add new apis `transform_checkpoints` and `transform_checkpoint_by_rank` to transfer the distributed checkpoint files by strategy files. Please refer to [Distributed Resilience Training and Inference](https://www.mindspore.cn/tutorials/experts/en/r2.0.0-alpha/parallel/resilience_train_and_predict.html)。\n\n### API Change\n\n#### operator\n\n- [STABLE] Add operator primitive for `mindspore.ops.AdaptiveMaxPool3D`.\n- [STABLE] Add operator primitive for `mindspore.ops.AdjustHue`.\n- [STABLE] Add operator primitive for `mindspore.ops.BartlettWindow`.\n- [STABLE] Add operator primitive for `mindspore.ops.BesselJ0`.\n- [STABLE] Add operator primitive for `mindspore.ops.BesselJ1`.\n- [STABLE] Add operator primitive for `mindspore.ops.BesselK0`.\n- [STABLE] Add operator primitive for `mindspore.ops.BesselK0e`.\n- [STABLE] Add operator primitive for `mindspore.ops.BesselK1`.\n- [STABLE] Add operator primitive for `mindspore.ops.BesselK1e`.\n- [STABLE] Add operator primitive for `mindspore.ops.BesselY0`.\n- [STABLE] Add operator primitive for `mindspore.ops.BesselY1`.\n- [STABLE] Add operator primitive for `mindspore.ops.Betainc`.\n- [STABLE] Add operator primitive for `mindspore.ops.Bincount`.\n- [STABLE] Add operator primitive for `mindspore.ops.BlackmanWindow`.\n- [STABLE] Add operator primitive for `mindspore.ops.Bucketize`.\n- [STABLE] Add operator primitive for `mindspore.ops.CombinedNonMaxSuppression`.\n- [STABLE] Add operator primitive for `mindspore.ops.CompareAndBitpack`.\n- [STABLE] Add operator primitive for `mindspore.ops.Complex`.\n- [STABLE] Add operator primitive for `mindspore.ops.DataFormatVecPermute`.\n- [STABLE] Add operator primitive for `mindspore.ops.EuclideanNorm`.\n- [STABLE] Add operator primitive for `mindspore.ops.Expand`.\n- [STABLE] Add operator primitive for `mindspore.ops.ExtractGlimpse`.\n- [STABLE] Add operator primitive for `mindspore.ops.FillDiagonal`.\n- [STABLE] Add operator primitive for `mindspore.ops.FractionalAvgPool`.\n- [STABLE] Add operator primitive for `mindspore.ops.FractionalMaxPool`.\n- [STABLE] Add operator primitive for `mindspore.ops.Gcd`.\n- [STABLE] Add operator primitive for `mindspore.ops.HammingWindow`.\n- [STABLE] Add operator primitive for `mindspore.ops.Histogram`.\n- [STABLE] Add operator primitive for `mindspore.ops.HSVToRGB`.\n- [STABLE] Add operator primitive for `mindspore.ops.Lcm`.\n- [STABLE] Add operator primitive for `mindspore.ops.LeftShift`.\n- [STABLE] Add operator primitive for `mindspore.ops.ListDiff`.\n- [STABLE] Add operator primitive for `mindspore.ops.LogSpace`.\n- [STABLE] Add operator primitive for `mindspore.ops.Lstsq`.\n- [STABLE] Add operator primitive for `mindspore.ops.MatrixDiagPartV3`.\n- [STABLE] Add operator primitive for `mindspore.ops.MatrixDiagV3`.\n- [STABLE] Add operator primitive for `mindspore.ops.MatrixExp`.\n- [STABLE] Add operator primitive for `mindspore.ops.MatrixPower`.\n- [STABLE] Add operator primitive for `mindspore.ops.MaxPool3DWithArgmax`.\n- [STABLE] Add operator primitive for `mindspore.ops.MaxUnpool2D`.\n- [STABLE] Add operator primitive for `mindspore.ops.MultilabelMarginLoss`.\n- [STABLE] Add operator primitive for `mindspore.ops.NextAfter`.\n- [STABLE] Add operator primitive for `mindspore.ops.Orgqr`.\n- [STABLE] Add operator primitive for `mindspore.ops.ReduceStd`.\n- [STABLE] Add operator primitive for `mindspore.ops.RGBToHSV`.\n- [STABLE] Add operator primitive for `mindspore.ops.RightShift`.\n- [STABLE] Add operator primitive for `mindspore.ops.SampleDistortedBoundingBoxV2`.\n- [STABLE] Add operator primitive for `mindspore.ops.ScaleAndTranslate`.\n- [STABLE] Add operator primitive for `mindspore.ops.ScatterAddWithAxis`.\n- [STABLE] Add operator primitive for `mindspore.ops.ScatterNdDiv`.\n- [STABLE] Add operator primitive for `mindspore.ops.ScatterNdMax`.\n- [STABLE] Add operator primitive for `mindspore.ops.ScatterNdMul`.\n- [STABLE] Add operator primitive for `mindspore.ops.STFT`.\n- [STABLE] Add operator primitive for `mindspore.ops.Trace`.\n- [STABLE] Add operator primitive for `mindspore.ops.UpsampleNearest3D`.\n- [STABLE] Add operator primitive for `mindspore.ops.UpsampleTrilinear3D`.\n- [STABLE] Add distributed weight conversion interface `mindspore.parallel.transform_checkpoints`.\n- [STABLE] Add distributed weight conversion interface `mindspore.parallel.transform_checkpoint_by_rank`.\n\n#### Backwards Incompatible Change\n\n##### Python API\n\n- The `mindspore.ms_function` interface is renamed to `mindspore.jit`, and `mindspore.ms_function` will be deprecated and removed in a future version.\n- The `mindspore.ms_class` interface is renamed to `mindspore.jit_class`, and `mindspore.ms_class` will be deprecated and removed in a future version.\n- The `mindspore.ops.ms_kernel` interface is renamed to `mindspore.ops.kernel`, and `mindspore.ops.ms_kernel` will be deprecated and removed in a future version.\n- The `mindspore.dataset.map` interface parameter `column_order` does not take effect, use`mindspore.dataset.project`.\n- The `mindspore.dataset.close_pool` and `mindspore.dataset.to_device` and `mindspore.dataset.set_dynamic_columns` are deprecated and removed in this version.\n\n### Bug fixes\n\n- Fixed an issue where the mixed precision functional interface could not modify the backend driver in graph mode\n- Fixed the problem that users can automatically transfer device_id in the single-P scenario for the following networks:（mobilenetv1/fasterrcnn/yolov3/yolov4/yolov5/unet/openpose/simplepose/crnn/gnmtv2/faceattribute/facequality/facedetection）\n\n### Contributors\n\nThanks goes to these wonderful people:\n\nAGroupofProbiotocs, anzhengqi, askmiao, baihuawei, baiyangfan, bai-yangfan, bingyaweng, BowenK, buxue, caifubi, CaoJian, caojian05, caozhou, Cathy, changzherui, chenbo116, chenfei, chengxianbin, chenhaozhe, chenjianping, chenzomi, chenzupeng, chujinjin, cj, cjh9368, Corleone, damon0626, danish, Danish, davidmc, dayschan, doitH, dong-li001, fary86, fuzhiye, Gaoxiong, GAO_HYP_XYJ, gengdongjie, Gogery, gongdaguo, gray0v0, gukecai, guoqi, gzhcv, hangq, hanhuifeng2020, Harshvardhan, He, heleiwang, hesham, hexia, Hoai, HuangBingjian, huangdongrun, huanghui, huangxinjing, huqi, huzhifeng, hwjiaorui, Jiabin Liu, jianghui58, Jiaqi, jin-xiulang, jinyaohui, jjfeing, John, jonyguo, JulyAi, jzg, kai00, kingfo, kingxian, kpy, kswang, liuyongqi, laiyongqiang, leonwanghui, liangchenghui, liangzelang, lichen_101010, lichenever, lihongkang, lilei, limingqi107, ling, linqingke, Lin Xh, liubuyu, liuwenhao4, liuxiao78, liuxiao93, liuyang_655, liuzhongkai, Lixia, lixian, liyanliu, liyong, lizhenyu, luopengting, lvchangquan, lvliang, lz, maning202007, Margaret_wangrui, mengyuanli, Ming_blue, ms_yan, ougongchang, panfengfeng, panyifeng, Payne, Peilin, peixu_ren, Pengyongrong, qianlong, qianjiahong, r1chardf1d0, riemann_penn, rmdyh, Sheng, shenwei41, simson, Simson, Su, sunsuodong, tao_yunhao, tinazhang, VectorSL, , Wan, wandongdong, wangdongxu, wangmin,  wangyue01, wangzhe, wanyiming, Wei, wenchunjiang, wilfChen, WilliamLian, wsc, wudenggang, wukesong, wuweikang, wuxuejian, Xiao Tianci, Xiaoda, xiefangqi, xinyunfan, xuanyue, xuyongfei, yanghaitao, yanghaitao1, yanghaoran, YangLuo, yangruoqi713, yankai, yanzhenxiang2020, yao_yf, yepei6, yeyunpeng, Yi, yoni, yoonlee666, yuchaojie, yujianfeng, yuximiao, zengzitao, Zhang,  zhanghuiyao, zhanghui_china, zhangxinfeng3, zhangyihui, zhangz0911gm, zhanke, zhanyuan, zhaodezan, zhaojichen, zhaoting, zhaozhenlong, zhengjun10, zhiqwang, zhoufeng, zhousiyi, zhouyaqiang, zhouyifengCode, Zichun, Ziyan, zjun, ZPaC, wangfengwfwf, zymaa, gerayking, shu-kun-zhang.\n\nContributions of any kind are welcome!\n\n## MindSpore 1.10.1 Release Notes\n\n### Bug fixes\n\n- Fixed the issue that the specified axis is not considered in logsumexp anti-overflow processing\n- Fixed the compilation dependency of proto file\n- Fixed the issue that the print operator printing result is not normal\n- Fixed the issue that the equal operator is out of range\n- Fixed the problem that when function wrapped by @jit，the cell id is not correct\n- Fixed the GNN scenario data type verification error\n- Fixed the problem that the dataset.map multi-process degenerates into threads\n\n### Contributors\n\nThanks goes to these wonderful people:\n\narcher2049, caifubi, chenfei_mindspore, gaoshuanglong, Greatpan, guozhijian, huoxinyou, Kxiong, lanzhineng, lijunbin, liubuyu, liuchuting, luochao60, lyqlola, nomindcarry, TuDouNi, xiaotianci, xupan, yangshuo, yefeng, YingtongHu, yuchaojie, zhoufeng, ZPaC, 刘勇琪, 吕昱峰, 王禹程, 于振华.\n\nContributions of any kind are welcome!\n\n## MindSpore 1.10.0 Release Notes\n\n### Major Features and Improvements\n\n#### DataSet\n\n- [STABLE]The timeout waiting time is adjusted in data sinking mode. The default value is 600s after adjusted. This solves the isuses that the GetNext operator may timeout due to environment resource competition and large computing workload when training in sink mode.\n\n### Bug fixes\n\n- Fixed an issue where some Primitive operators in AMP cannot be instantiated in graph mode and the interface is unavailable.\n- Fixed an issue of DynamicRNN execution failure in LSTM network under the scenario of computational force segmentation on Ascend platform.\n- Fixed DEVICE_ID cannot be set by single card train scripts parameters in mobilenet, fasterrcnn, yolo, etc.\n\n### Contributors\n\nThanks goes to these wonderful people:\n\nAGroupofProbiotocs, anzhengqi, askmiao, baihuawei, baiyangfan, bai-yangfan, bingyaweng, BowenK, buxue, caifubi, CaoJian, caojian05, caozhou, Cathy, changzherui, chenbo116, chenfei, chengxianbin, chenhaozhe, chenjianping, chenzomi, chenzupeng, chujinjin, cj, cjh9368, Corleone, damon0626, danish, Danish, davidmc, dayschan, doitH, dong-li001, fary86, fuzhiye, Gaoxiong, GAO_HYP_XYJ, gengdongjie, Gogery, gongdaguo, gray0v0, gukecai, guoqi, gzhcv, hangq, hanhuifeng2020, Harshvardhan, He, heleiwang, hesham, hexia, Hoai, HuangBingjian, huangdongrun, huanghui, huangxinjing, huqi, huzhifeng, hwjiaorui, Jiabin Liu, jianghui58, Jiaqi, jin-xiulang, jinyaohui, jjfeing, John, jonyguo, JulyAi, jzg, kai00, kingfo, kingxian, kpy, kswang, liuyongqi, laiyongqiang, leonwanghui, liangchenghui, liangzelang, lichen_101010, lichenever, lihongkang, lilei, limingqi107, ling, linqingke, Lin Xh, liubuyu, liuwenhao4, liuxiao78, liuxiao93, liuyang_655, liuzhongkai, Lixia, lixian, liyanliu, liyong, lizhenyu, luopengting, lvchangquan, lvliang, lz, maning202007, Margaret_wangrui, mengyuanli, Ming_blue, ms_yan, ougongchang, panfengfeng, panyifeng, Payne, Peilin, peixu_ren, Pengyongrong, qianlong, qianjiahong, r1chardf1d0, riemann_penn, rmdyh, Sheng, shenwei41, simson, Simson, Su, sunsuodong, tao_yunhao, tinazhang, VectorSL, , Wan, wandongdong, wangdongxu, wangmin,  wangyue01, wangzhe, wanyiming, Wei, wenchunjiang, wilfChen, WilliamLian, wsc, wudenggang, wukesong, wuweikang, wuxuejian, Xiao Tianci, Xiaoda, xiefangqi, xinyunfan, xuanyue, xuyongfei, yanghaitao, yanghaitao1, yanghaoran, YangLuo, yangruoqi713, yankai, yanzhenxiang2020, yao_yf, yepei6, yeyunpeng, Yi, yoni, yoonlee666, yuchaojie, yujianfeng, yuximiao, zengzitao, Zhang,  zhanghuiyao, zhanghui_china, zhangxinfeng3, zhangyihui, zhangz0911gm, zhanke, zhanyuan, zhaodezan, zhaojichen, zhaoting, zhaozhenlong, zhengjun10, zhiqwang, zhoufeng, zhousiyi, zhouyaqiang, zhouyifengCode, Zichun, Ziyan, zjun, ZPaC, wangfengwfwf, zymaa, gerayking, shu-kun-zhang.\n\nContributions of any kind are welcome!\n\n## MindSpore Lite 1.10.0 Release Notes\n\n### Bug fixes\n\n- Fixed potential accuracy problem of arithmetic type CPU kernels at dynamical shape case.\n- Fixed the Incorrect Write Address of the Deconv Quantization Operator.\n\n## MindSpore 1.9.0 Release Notes\n\n### Major Features and Improvements\n\n#### FrontEnd\n\n- [STABLE] Add the object-oriented and functional combination programming paradigm, add mixed-precision APIs for combination programming paradigms such as `mindspore.amp.LossScaler`, `mindspore.amp.DynamicLossScaler`, `mindspore.amp.StaticLossScaler`, `mindspore.amp.auto_mixed_precision` and `mindspore.amp.all_finite`.\n\n### API Change\n\n#### operator\n\n- [STABLE] Add nn interface for `nn.AdaptiveAvgPool3d`.\n- [STABLE] Add functional interface for `ops.adaptive_avg_pool3d`.\n- [STABLE] Add functional interface for `ops.addcdiv`.\n- [STABLE] Add functional interface for `ops.addcmul`.\n- [STABLE] Add GPU and CPU support for `ops.approximate_equal`.\n- [STABLE] Add GPU support for `ops.atanh`.\n- [STABLE] Add GPU support for `ops.bessel_i0`.\n- [STABLE] Add Ascend support for `ops.bessel_i0e`.\n- [STABLE] Add GPU support for `ops.bessel_i1`.\n- [STABLE] Add Ascend and GPU support for `ops.bessel_i1e`.\n- [STABLE] Add GPU support for `ops.bessel_j0`.\n- [STABLE] Add GPU support for `ops.bessel_j1`.\n- [STABLE] Add GPU support for `ops.bessel_k0`.\n- [STABLE] Add GPU support for `ops.bessel_k0e`.\n- [STABLE] Add GPU support for `ops.bessel_k1`.\n- [STABLE] Add GPU support for `ops.bessel_k1e`.\n- [STABLE] Add GPU support for `ops.bessel_y0`.\n- [STABLE] Add GPU support for `ops.bessel_y1`.\n- [STABLE] Add functional interface for `ops.bias_add`.\n- [STABLE] Add GPU support for `ops.bitwise_and`.\n- [STABLE] Add GPU support for `ops.bitwise_or`.\n- [STABLE] Add GPU support for `ops.bitwise_xor`.\n- [STABLE] Add Ascend support for `ops.grid_sample`.\n- [STABLE] Add CPU support for `ops.inplace_update`.\n- [STABLE] Add Ascend and GPU support for `ops.isclose`.\n- [STABLE] Add Ascend support for `ops.isnan`.\n- [STABLE] Add GPU support for `ops.lerp`.\n- [STABLE] Add functional interface for `ops.random_poisson`.\n- [STABLE] Add functional interface for `ops.reverse_sequence`.\n- [STABLE] Add GPU support for `ops.scatter_mul`.\n- [STABLE] Add functional interface for `ops.scatter_nd_max`.\n- [STABLE] Add functional interface for `ops.scatter_nd_min`.\n- [STABLE] Add GPU support for `ops.SparseToDense`.\n- [STABLE] Add functional interface for `ops.square`.\n- [STABLE] Add GPU support for `ops.standard_laplace`.\n- [STABLE] Add functional interface for `ops.std`.\n- [STABLE] Add Ascend and GPU support for `ops.trunc`.\n- [STABLE] Add functional interface for `ops.unsorted_segment_sum`.\n- [STABLE] Add functional interface for `ops.xdivy`.\n- [STABLE] Add GPU support for `ops.xlogy`.\n- Deprecate `ops.poisson` and use `ops.random_poisson` instead.\n- Deprecate `ops.SparseApplyAdagrad` and use `ops.SparseApplyAdagradV2` instead.\n\n### Bug fixes\n\n- [BUGFIX] The logic of the auto mixed precision (amp) O2 level is revised. In addition to the `BatchNorm1d` and `BatchNorm2d` operators, the other two operators `BatchNorm3d` and `LayerNorm` are added. The four operators still use the float32 data type when calculating.\n\n- [BUGFIX] Fix the problem that when processing string type data, if `output_numpy=True` is specified when calling the `create_dict_iterator` or `create_tuple_iterator` interface, the obtained data will be of type `numpy.bytes_`. After this fixing, these interfaces will directly return `numpy.str_` type data, and users do not need to perform string decoding operations on it. Likewise, when performing user defined processing functions, the received data will also be of type `numpy.str_` directly, matching the original source data type.\n\n### Contributors\n\nThanks goes to these wonderful people:\n\nAGroupofProbiotocs, anzhengqi, askmiao, baihuawei, baiyangfan, bai-yangfan, bingyaweng, BowenK, buxue, caifubi, CaoJian, caojian05, caozhou, Cathy, changzherui, chenbo116, chenfei, chengxianbin, chenhaozhe, chenjianping, chenzomi, chenzupeng, chujinjin, cj, cjh9368, Corleone, damon0626, danish, Danish, davidmc, dayschan, doitH, dong-li001, fary86, fuzhiye, Gaoxiong, GAO_HYP_XYJ, gengdongjie, Gogery, gongdaguo, gray0v0, gukecai, guoqi, gzhcv, hangq, hanhuifeng2020, Harshvardhan, He, hesham, hexia, Hoai, HuangBingjian, huangdongrun, huanghui, huangxinjing, huqi, huzhifeng, hwjiaorui, Jiabin Liu, jianghui58, Jiaqi, jin-xiulang, jinyaohui, jjfeing, John, jonyguo, JulyAi, jzg, kai00, kingfo, kingxian, kpy, kswang, liuyongqi, laiyongqiang, leonwanghui, liangchenghui, liangzelang, lichen_101010, lichenever, lihongkang, lilei, limingqi107, ling, linqingke, Lin Xh, liubuyu, liuwenhao4, liuxiao78, liuxiao93, liuyang_655, liuzhongkai, liyanliu, lizhenyu, lvchangquan, lvliang, lz, maning202007, Margaret_wangrui, mengyuanli, Ming_blue, ms_yan, panfengfeng, panyifeng, Payne, peixu_ren, Pengyongrong, qianjiahong, r1chardf1d0, riemann_penn, rmdyh, Sheng, shenwei41, simson, Simson, Su, sunsuodong, tao_yunhao, tinazhang, VectorSL, Wan, wandongdong, wangdongxu, wangmin,  wangyue01, wangzhe, wanyiming, Wei, wenchunjiang, wilfChen, WilliamLian, wsc, wudenggang, wukesong, wuweikang, Xiao Tianci, Xiaoda, xiefangqi, xinyunfan, xuanyue, xuyongfei, yanghaitao, yanghaoran, YangLuo, yangruoqi713, yankai, yanzhenxiang2020, yao_yf, yepei6, yeyunpeng, Yi, yoni, yoonlee666, yuchaojie, yujianfeng, yuximiao, zengzitao, Zhang,  zhanghuiyao, zhanghui_china, zhangxinfeng3, zhangyihui, zhangz0911gm, zhanyuan, zhaojichen, zhaoting, zhaozhenlong, zhengjun10, zhiqwang, zhoufeng, zhousiyi, zhouyaqiang, zhouyifengCode, Zichun, Ziyan, zjun, ZPaC, wangfengwfwf, zymaa, gerayking, shu-kun-zhang.\n\nContributions of any kind are welcome!\n\n## MindSpore 1.8.1 Release Notes\n\n### API Change\n\n#### operator\n\n- [STABLE] Add GPU and CPU support for ops.ApplyAdagradDA.\n- [STABLE] Add CPU support for ops.ApplyAdagradV2.\n- [STABLE] Add Ascend dynamic shape support for ops.ApplyCenteredRmsProp.\n- [STABLE] Add CPU support for ops.ApplyFtrl.\n- [STABLE] Add CPU support for ops.ApplyGradientDescent.\n- [STABLE] Add CPU support for ops.ApplyPowerSign.\n- [STABLE] Add GPU and CPU support for ops.ApplyProximalAdagrad.\n- [STABLE] Add Ascend dynamic shape support for ops.ApplyRmsProp.\n- [STABLE] Add functional interface for ops.max.\n- [STABLE] Add functional interface for ops.atan2.\n- [STABLE] Add GPU support for ops.cummax.\n- [STABLE] Add GPU and CPU support for ops.cummin.\n- [STABLE] Add GPU support for ops.diag.\n- [STABLE] Add functional interface for ops.expand_dims.\n- [STABLE] Add functional interface for ops.gather_elements.\n- [STABLE] Add GPU support for ops.grid_sample.\n- [STABLE] Add Ascend support for ops.hardswish.\n- [BETA] Add GPU support for ops.index_fill.\n- [BETA] Add CPU support for ops.inplace_update.\n- [BETA] Add GPU support for nn.InstanceNorm1d.\n- [BETA] Add GPU support for nn.InstanceNorm2d.\n- [BETA] Add GPU support for nn.InstanceNorm3d.\n- [STABLE] Add functional interface for ops.log1p.\n- [STABLE] Add GPU and CPU support for ops.masked_fill.\n- [BETA] Add GPU support for ops.matrix_diag_part.\n- [BETA] Add GPU support for ops.matrix_diag.\n- [BETA] Add GPU support for ops.matrix_set_diag.\n- [STABLE] Add GPU support for ops.max_pool3d.\n- [STABLE] Add functional interface for ops.nll_loss.\n- [STABLE] Add functional interface for ops.one_hot.\n- [STABLE] Add functional interface for ops.pad.\n- [STABLE] Add CPU support for ops.random_gamma.\n- [STABLE] Add functional interface for ops.amax.\n- [STABLE] Add functional interface for ops.mean.\n- [STABLE] Add functional interface for ops.amin.\n- [STABLE] Add functional interface for ops.prod.\n- [STABLE] Add Ascend, GPU, and CPU support for ops.renorm.\n- [BETA] Add Ascend, GPU, and CPU support for ops.tensor_scatter_elements.\n- [STABLE] Add GPU support for ops.scatter_max.\n- [STABLE] Add GPU support for ops.scatter_min.\n- [STABLE] Add functional interface for ops.scatter_nd.\n- [STABLE] Add GPU support for ops.scatter_nd_max.\n- [STABLE] Add functional interface for ops.scatter_update.\n- [STABLE] Add CPU support for ops.binary_cross_entropy_with_logits.\n- [STABLE] Add functional interface for ops.smooth_l1_loss.\n- [STABLE] Add CPU support for ops.space_to_batch_nd.\n- [STABLE] Add GPU and CPU support for ops.SparseApplyAdagrad.\n- [STABLE] Add GPU and CPU support for ops.sparse_segment_mean.\n- [STABLE] Add functional interface for ops.squeeze.\n- [STABLE] Add CPU support for ops.standard_laplace.\n- [BETA] Add Ascend, GPU, and CPU support for nn.ReflectionPad1d.\n- [BETA] Add Ascend, GPU, and CPU support for nn.ReflectionPad2d.\n- [STABLE] Add Ascend, GPU, and CPU support for nn.SiLU.\n- [STABLE] Add functional interface for ops.transpose.\n- [STABLE] Add CPU support for ops.uniform_candidate_sampler.\n- [STABLE] Add functional interface for ops.uniform.\n- [STABLE] Add GPU support for ops.unique_with_pad.\n- [STABLE] Add functional interface for ops.unstack.\n- [BETA] Add GPU and CPU support for ops.interpolate.\n- [STABLE] Add CPU support for ops.xdivy.\n- [STABLE] Add CPU support for ops.xlogy.\n\n## MindSpore 1.8.0 Release Notes\n\n### Major Features and Improvements\n\n#### FrontEnd\n\n- [BETA] Add `mindspore.train.Model.fit` API, add `mindspore.train.callback.EarlyStopping` and `mindspore.train.callback.ReduceLROnPlateau` in Callback.\n- [BETA] Support custom operator implemented by Julia.\n- [BETA] Support custom operator implemented by MindSpore Hybrid DSL.\n- [STABLE] The export() interface supports the export of a model using a custom encryption algorithm, and the load() interface supports the import of a model using a custom decryption algorithm.\n- [BETA] [Unified_Dynamic_and_Static_Graphs] [Usability] Constant-type data (tuple/list/dict is supported in Version 1.8) can be set to be variable during graph compiling.\n- [BETA] [Unified_Dynamic_and_Static_Graphs] JIT fallback is used to support the control flow capability in the constant scenario.\n- [STABLE] [Unified_Dynamic_and_Static_Graphs] The Python raise statement is supported in the graph mode constant scenario.\n- [STABLE] [Unified_Dynamic_and_Static_Graphs] The Python assert statement is supported in the graph mode constant scenario.\n- [STABLE] [Unified_Dynamic_and_Static_Graphs] The Python print statement is supported in the graph mode constant scenario.\n- [STABLE] [Unified_Dynamic_and_Static_Graphs] The str.format() method is supported in the graph mode.\n- [STABLE] [Unified_Dynamic_and_Static_Graphs] The slice method can be used to assign a value to the list in the graph mode.\n- [STABLE] [Unified_Dynamic_and_Static_Graphs] The instances of custom classes can be created and invoked in the graph mode.\n- [STABLE] [Unified_Dynamic_and_Static_Graphs] Obtaining the properties of a class from the Cell array and the custom class array is supported.\n- [STABLE] [Unified_Dynamic_and_Static_Graphs] isinstance supports scenario expanding in the graph mode.\n- [STABLE] Rename the custom operator decorator 'ms_hybrid' to 'ms_kernel'.\n- [BETA] Custom operator Hybrid DSL is supported on the backend of CPU.\n- [BETA] Custom operator Ascend backend adds custom scheduling primitive syntax support.\n\n#### PyNative\n\n- [STABLE] Implement the AdamWeightDecay operator to replace the original small operator combination mode.\n- [STABLE] In PyNative mode, execute the optimizer by unifying the dynamic and static graphs.\n- [STABLE] Optimize the execution performance of PyNative bprop graph and ms_function.\n\n#### Auto Parallel\n\n- [STABLE] Docking the AllToAll single-operator mode. Support AllToAll Operator in the graph compilation level O0.\n- [STABLE] Whole-graph offloading supports MPI launching. In Whole-graph offloading, launching with MPI is supported.\n- [STABLE] Seeds of model weights provide parallel interface configuration. If you do not set the random number of seeds through the mindspore.set_seed command, the weights initialized by each parameter is determined by the current fragment index. If the random number of seeds are configured, the initialization results of the same shape and weight of the same segmentation policy are the same.\n- [STABLE] The HCCL shields internal full-mesh and non-full-mesh connections. Both fully-connected AllToAllv and hierarchical AllToAllv are allowed in one training session.\n- [BETA] CPU optimizer fusion. Multiple optimizer operators are combined according to data types through cross-parameter fusion, improving performance. Currently, It has been verified on CPU AdamWeightDecay optimizer. You can use the flatten_weights method in the network cell class to enable this function.\n\n#### Executor\n\n- [STABLE] Provide southbound API.\n- [STABLE] Multi-actor fusion execution to optimize the execution performance during runtime.\n- [STABLE] Nopop operators (eg. reshape) execute elimination.\n- [STABLE] Embedded cache architecture switches unified distributed runtime.\n- [STABLE] Parameter Server switches unified distributed runtime.\n- [STABLE] Support Parameter Server mode training on CPU.\n\n#### DataSet\n\n- [STABLE] When using the map operation for dataset objects and the parameters like: num_parallel_workers > 1 and python_multiprocessing=True, the multi-process mechanism is optimized, so that the data channel and child processes are mapped one by one, avoiding excessive file handle occupation, and closing_pool interface is also deleted.\n- [STABLE] Add a batch of Vision, Text and Audio data augmentation operations.\n- [STABLE] Fix a bug where the flat_map method of the Dataset class does not flatten the result.\n- [STABLE] Unify import paths of dataset augmentation APIs to provide more easier way to use. Refer to [latest api usages](https://www.mindspore.cn/docs/en/r1.8/api_python/mindspore.dataset.vision.html).\n\n### API Change\n\n#### operator\n\n- [STABLE] Add GPU support for ops.adaptive_avg_pool2d.\n- [BETA] Add Ascend, GPU, and CPU support for ops.adaptive_max_pool2d .\n- [BETA] Add CPU support for ops.approximate_equal.\n- [STABLE] Add CPU support for ops.argmin.\n- [BETA] Add CPU support for ops.assign_sub.\n- [STABLE] Add GPU support for ops.bernoulli.\n- [BETA] Add CPU support for ops.bessel_i0.\n- [BETA] Add CPU support for ops.bessel_i0e.\n- [BETA] Add CPU support for ops.bessel_i1.\n- [BETA] Add CPU support for ops.bessel_i1e Add CPU support.\n- [STABLE] Add CPU support for ops.bessel_j0.\n- [STABLE] Add CPU support for ops.bessel_j1.\n- [STABLE] Add CPU support for ops.bessel_k0.\n- [STABLE] Add CPU support for ops.bessel_k0e.\n- [BETA] Add CPU support for ops.bessel_k1.\n- [BETA] Add CPU support for ops.bessel_k1e.\n- [STABLE] Add CPU support for ops.bessel_y0.\n- [STABLE] Add CPU support for ops.bessel_y1.\n- [STABLE] Add CPU support for ops.bitwise_and.\n- [STABLE] Add CPU support for ops.bitwise_or.\n- [STABLE] Add CPU support for ops.bitwise_xor.\n- [STABLE] Add functional interface for ops.broadcast_to.\n- [BETA] Add GPU and CPU support for ops.ceil.\n- [BETA] Add GPU support for ops.col2im.\n- [BETA] Add functional interface for ops.concat.\n- [STABLE] Add GPU support for ops.cosh.\n- [STABLE] Add Ascend and CPU support for ops.ctc_greedy_decoder.\n- [BETA] Add GPU and CPU support for ops.DataFormatDimMap.\n- [BETA] Add GPU and CPU support for ops.dropout2d.\n- [BETA] Add CPU support for ops.dropout3d.\n- [BETA] Add CPU support for ops.erf.\n- [BETA] Add CPU support for ops.erfc.\n- [STABLE] Add functional interface for ops.expand_dims.\n- [STABLE] Add GPU and CPU support for ops.fast_gelu.\n- [STABLE] Add Ascend dynamic shape support for ops.flatten.\n- [BETA] Add GPU and CPU support for ops.ger.\n- [STABLE] Add Ascend, GPU, and CPU support for ops.gumbel_softmax.\n- [BETA] Add GPU and CPU support for ops.hardshrink.\n- [BETA] Add CPU support for ops.index_add.\n- [BETA] Add CPU support for ops.inplace_add.\n- [BETA] Add CPU support for ops.inplace_sub.\n- [STABLE] Add CPU support for ops.intopk.\n- [STABLE] Add GPU and CPU support for ops.inv.\n- [STABLE] Add GPU and CPU support for ops.invert.\n- [BETA] Add CPU support for ops.isclose.\n- [STABLE] Add CPU support for ops.lerp.\n- [BETA] Add CPU support for ops.linspace.\n- [BETA] Add functional interface for ops.log_softmax.\n- [BETA] Add Ascend, GPU, and CPU support for ops.norm.\n- [BETA] Add CPU support for ops.lrn.\n- [BETA] Add GPU support for ops.masked_select.\n- [BETA] Add GPU and CPU support for ops.matrix_band_part.\n- [BETA] Add GPU and CPU support for ops.matrix_solve.\n- [BETA] Add CPU support for ops.meshgrid.\n- [STABLE] Add CPU support for ops.mish.\n- [BETA] Add GPU support forops.nonzero.\n- [STABLE] Add GPU and CPU support for ops.padding.\n- [BETA] Add Ascend dynamic shape support for ops.pow.\n- [BETA] Add functional interface for ops.range.\n- [BETA] Add Ascend dynamic shape support for ops.round.\n- [STABLE] Add Ascend dynamic shape support for ops.scatter_add.\n- [STABLE] Add Ascend dynamic shape support for ops.scatter_div.\n- [BETA] Add GPU support for ops.scatter_max.\n- [BETA] Add GPU support for ops.scatter_min.\n- [BETA] Add CPU support for ops.scatter_nd_add.\n- [STABLE] Add GPU and CPU support for ops.scatter_nd_div.\n- [STABLE] Add GPU and CPU support for ops.scatter_nd_min.\n- [STABLE] Add GPU and CPU support for ops.scatter_nd_mul.\n- [BETA] Add CPU support for ops.scatter_nd_sub.\n- [STABLE] Add Ascend dynamic shape support for ops.scatter_update.\n- [BETA] Add Ascend dynamic shape support for ops.select.\n- [BETA] Add GPU and CPU support for ops.selu.\n- [BETA] Add GPU and CPU support for ops.soft_shrink.\n- [BETA] Add CPU support for ops.softsign.\n- [STABLE] Add GPU support for ops.tan.\n- [BETA] Add Ascend and CPU support ops.tensor_scatter_add.\n- [STABLE] Add GPU and CPU support for ops.tensor_scatter_div.\n- [STABLE] Add GPU and CPU support for ops.tensor_scatter_mul.\n- [BETA] Add Ascend and CPU support for ops.tensor_scatter_sub.\n- [STABLE] Add Ascend, GPU, and CPU support for nn.AdaptiveAvgPool1d.\n- [STABLE] Add Ascend, GPU, and CPU support for nn.AdaptiveMaxPool1d.\n- [BETA] Add Ascend, GPU, and CPU support for nn.BiDense.\n- [STABLE] Add Ascend, GPU, and CPU support for nn.ConstantPad1d.\n- [STABLE] Add Ascend, GPU, and CPU support for nn.ConstantPad2d.\n- [STABLE] Add Ascend, GPU, and CPU support for nn.ConstantPad3d.\n- [STABLE] Add Ascend, GPU, and CPU support for nn.Hardtanh.\n- [STABLE] Add Ascend, GPU, and CPU support for nn.HuberLoss.\n- [STABLE] Add Ascend, GPU, and CPU support for nn.RReLU.\n- [STABLE] Add Ascend, GPU, and CPU support for nn.Tanhshrink.\n- [STABLE] Add Ascend, GPU, and CPU support for nn.Threshold.\n- [STABLE] Add Ascend, GPU, and CPU support for nn.ZeroPad2d.\n- [BETA] Add GPU support for ops.unique_consecutive.\n- [STABLE] Add CPU support for ops.unsorted_segment_max.\n- [STABLE] Add CPU support for ops.unsorted_segment_min.\n- [STABLE] Add GPU support for ops.unsorted_segment_prod.\n\n#### Backwards Incompatible Change\n\n##### Python API\n\n- DVPP simulation algorithm is no longer supported. Remove `mindspore.dataset.vision.c_transforms.SoftDvppDecodeRandomCropResizeJpeg` and `mindspore.dataset.vision.c_transforms.SoftDvppDecodeResizeJpeg` interfaces.\n- Add `on_train_epoch_end` method in LossMonitor, which implements printing metric information in the epoch level when it is used in `mindspore.train.Model.fit`.\n- TimeMonitor printing content changes, and the printed content is added to \"train\" or \"eval\" to distinguish between training and inference phases.\n- `filter_prefix` of `mindspore.load_checkpoint` interface: empty string (\"\") is no longer supported, and the matching rules are changed from strong matching to fuzzy matching.\n\n#### Import Optimization\n\nAPIs in `mindspore.context`, `mindspore.parallel`, `mindspore.profiler` and `mindspore.train` can be directly used in `mindspore`. The original usage can still be supported.\n\nFor examples:\n\n- `mindspore.context.set_context` can be simplified to `mindspore.set_context`.\n- `mindspore.parallel.set_algo_parameters` can be simplified to `mindspore.set_algo_parameters`.\n- `mindspore.profiler.Profiler` can be simplified to `mindspore.Profiler`.\n- `mindspore.train.callback.Callback` can be simplified to `mindspore.train.Callback`.\n\nThe API pages are aggregated to <https://www.mindspore.cn/docs/en/r1.8/api_python/mindspore.html>.\n\n### Contributors\n\nThanks goes to these wonderful people:\n\nAGroupofProbiotocs, anzhengqi, askmiao, baihuawei, baiyangfan, bai-yangfan, bingyaweng, BowenK, buxue, caifubi, CaoJian, caojian05, caozhou, Cathy, changzherui, chenbo116, chenfei, chengxianbin, chenhaozhe, chenjianping, chenzomi, chenzupeng, chujinjin, cj, cjh9368, Corleone, damon0626, danish, Danish, davidmc, dayschan, doitH, dong-li001, fary86, fuzhiye, Gaoxiong, GAO_HYP_XYJ, gengdongjie, Gogery, gongdaguo, gray0v0, gukecai, guoqi, gzhcv, hangq, hanhuifeng2020, Harshvardhan, He, heleiwang, hesham, hexia, Hoai, HuangBingjian, huangdongrun, huanghui, huangxinjing, huqi, huzhifeng, hwjiaorui, Jiabin Liu, jianghui58, Jiaqi, jin-xiulang, jinyaohui, jjfeing, John, jonyguo, JulyAi, jzg, kai00, kingfo, kingxian, kpy, kswang, liuyongqi, laiyongqiang, leonwanghui, liangchenghui, liangzelang, lichen_101010, lichenever, lihongkang, lilei, limingqi107, ling, linqingke, Lin Xh, liubuyu, liuwenhao4, liuxiao78, liuxiao93, liuyang_655, liuzhongkai, Lixia, lixian, liyanliu, liyong, lizhenyu, luopengting, lvchangquan, lvliang, lz, maning202007, Margaret_wangrui, mengyuanli, Ming_blue, ms_yan, ougongchang, panfengfeng, panyifeng, Payne, Peilin, peixu_ren, Pengyongrong, qianlong, qianjiahong, r1chardf1d0, riemann_penn, rmdyh, Sheng, shenwei41, simson, Simson, Su, sunsuodong, tao_yunhao, tinazhang, VectorSL, , Wan, wandongdong, wangdongxu, wangmin,  wangyue01, wangzhe, wanyiming, Wei, wenchunjiang, wilfChen, WilliamLian, wsc, wudenggang, wukesong, wuweikang, wuxuejian, Xiao Tianci, Xiaoda, xiefangqi, xinyunfan, xuanyue, xuyongfei, yanghaitao, yanghaitao1, yanghaoran, YangLuo, yangruoqi713, yankai, yanzhenxiang2020, yao_yf, yepei6, yeyunpeng, Yi, yoni, yoonlee666, yuchaojie, yujianfeng, yuximiao, zengzitao, Zhang,  zhanghuiyao, zhanghui_china, zhangxinfeng3, zhangyihui, zhangz0911gm, zhanke, zhanyuan, zhaodezan, zhaojichen, zhaoting, zhaozhenlong, zhengjun10, zhiqwang, zhoufeng, zhousiyi, zhouyaqiang, zhouyifengCode, Zichun, Ziyan, zjun, ZPaC, wangfengwfwf, zymaa, gerayking, shu-kun-zhang.\n\nContributions of any kind are welcome!\n\n## MindSpore Lite 1.8.0 Release Notes\n\n### Major Features and Improvements\n\n#### API\n\n- [STABLE] Add C++ and Python APIs for model conversion.\n- [STABLE] Add Python APIs for model inference.\n\n#### Post-Training Quantization\n\n- [STABLE] Support perlayer quantization, and built-in CLE to optimize perlayer quantization accuracy.\n\n## MindSpore 1.7.0 Release Notes\n\n### Major Features and Improvements\n\n#### OS\n\n- [STABLE] Support Python 3.8 (Linux/Windows/Mac).\n- [STABLE] Installation improved with more detailed install guide and automated shell scripts.\n- [STABLE] Support operator computing with multi-thread under Windows.\n- [STABLE] Compatible with GCC from version 7.3 to 9.x.\n\n#### FrontEnd\n\n- [STABLE] Support dynamic weight decay for optimizers, that is weight decay value will change according to the increasing step during training.\n- [STABLE] Add four methods to create Tensor, which are `mindspore.numpy.rand()`, `mindspore.numpy.randn()`, `mindspore.numpy.randint()`, and `mindspore.ops.arange()`.\n- [STABLE] Add `mindspore.train.callback.History` in Callback.\n- [BETA] Support custom operator implemented by Julia operator.\n- [STABLE] Support accessing attributes and methods of user-defined classes  through `mindspore.ms_class` class decorator.\n- [STABLE] Support training when a network has side effect operations and control flow statements at the same time.\n- [STABLE] Support for more complex control flow syntax, such as a for loop statement in the body of a while loop.\n- [STABLE] Improve the performance of networks with complex syntax control flow statements by decreasing the num of subgraphs.\n\n#### PyNative\n\n- [STABLE] Add Hook functions in PyNative mode, including register_forward_pre_hook, register_forward_hook of the forward hook interface, register_backward_hook of the reverse hook interface.\n- [STABLE] Optimize the execution performance of PyNative mode, and execute the front-end Python and the back-end C++ in parallel.\n\n#### Auto Parallel\n\n- [STABLE] Support TopK routing, data parallel and optimizer state parallel when enable MoE.\n- [STABLE] Support AllGather/ReduceScatter communication operator fusion. Support AllReuduce fusion by the data volume size in DATA_PARALLEL mode.\n- [STABLE] Support ops.clip_by_global_norm in the parallel mode.\n- [STABLE] Support AdaSum optimizer in the parallel mode.\n- [STABLE] Support automatic optimizer state parallel.\n- [STABLE] Support AlltoAll configurable. Support automatically add virtualdataset cell.\n- [STABLE] Support automatically inference trainable parameters in pipeline parallel training.\n- [STABLE] Support clusters where the device number is not the power of 2.\n- [STABLE] Support sharding propagation in auto-parallel mode.\n- [STABLE] Support optimizer offload under the unified runtime.\n- [STABLE] Support Adafactor operator on CPU.\n- [STABLE] Support sharding at H/W axis for Conv2d/Conv2DTranspose operator. Support operators such as ResizeBilinear，ROIAlign, CropAndResize, BoundingBoxEncode, IOU and RandomChoiceWithMask.\n\n#### Executor\n\n- [BETA] [Failure Recovery Under Data Parallel Training](https://www.mindspore.cn/tutorials/experts/en/r1.7/parallel/train_gpu.html) Support auto failure recovery under data parallel training mode.\n- [BETA] Support searching for the number of threads under the CPU to obtain the optimal number of threads for execution. The entire search process takes 50 steps, and the overall performance will reach a stable state after 50 steps. When testing performance, data after 50 steps need to be used as a standard.\n\n#### DataSet\n\n- [STABLE] Add dataset operations mapping between TensorFlow.data module and MindSpore.dataset module, [check list](https://www.mindspore.cn/docs/en/r1.7/note/api_mapping/tensorflow_api_mapping.html#tf-data).\n- [STABLE] Python multiprocessing optimization and make processes exit normally.\n- [STABLE] Support [Dataset Autotune](https://www.mindspore.cn/tutorials/experts/en/master/dataset/dataset_autotune.html) for tuning the speed of dataset pipeline automatically.\n- [BETA]  [Dataset Offload](https://www.mindspore.cn/tutorials/experts/en/master/dataset/dataset_offload.html) support new data augmentation operations: RandomColorAdjust, RandomSharpness, TypeCast.\n- Output a single data column when `__getitem__/__next__` methods of GeneratorDataset return a single NumPy object.\n- Use `ulimit -u 10240` to increase the number of threads/processes available to the current user when specify too many processes or threads for loading dataset may cause RuntimeError: can't start new thread.\n\n### API Change\n\n#### Backwards Incompatible Change\n\n##### Python API\n\n- Modify the gradient return value type of the hook corresponding to the register_backward_hook function, and change the gradient return value to the tuple type uniformly.([!31876](https://gitee.com/mindspore/mindspore/pulls/31876))\n- Deprecated usage: `import mindspore.dataset.engine.datasets as ds`. Use `import mindspore.dataset as ds` instead as recommended in [mindspore doc](https://www.mindspore.cn/docs/en/r1.7/api_python/mindspore.dataset.html).\n- Add `mindspore.ms_class` interface, as class decorator for user-defined classes. It allows MindSpore to identify user-defined classes and access their attributes and methods([!30855](https://gitee.com/mindspore/mindspore/pulls/30855))\n- Deprecate `mindspore.SparseTensor` and use `mindspore.COOTensor` instead. ([!28505](https://gitee.com/mindspore/mindspore/pulls/28505))\n- Add Tensor init arg `internal` for internal use.\n\n### Contributors\n\nThanks goes to these wonderful people:\n\nAGroupofProbiotocs, anzhengqi, askmiao, baihuawei, baiyangfan, bai-yangfan, bingyaweng, BowenK, buxue, caifubi, CaoJian, caojian05, caozhou, Cathy, changzherui, chenbo116, chenfei, chengxianbin, chenhaozhe, chenjianping, chenzomi, chenzupeng, chujinjin, cj, cjh9368, Corleone, damon0626, danish, Danish, davidmc, dayschan, doitH, dong-li001, fary86, fuzhiye, Gaoxiong, GAO_HYP_XYJ, gengdongjie, Gogery, gongdaguo, gray0v0, gukecai, guoqi, gzhcv, hangq, hanhuifeng2020, Harshvardhan, He, heleiwang, hesham, hexia, Hoai, HuangBingjian, huangdongrun, huanghui, huangxinjing, huqi, huzhifeng, hwjiaorui, Jiabin Liu, jianghui58, Jiaqi, jin-xiulang, jinyaohui, jjfeing, John, jonyguo, JulyAi, jzg, kai00, kingfo, kingxian, kpy, kswang, liuyongqi, laiyongqiang, leonwanghui, liangchenghui, liangzelang, lichen_101010, lichenever, lihongkang, lilei, limingqi107, ling, linqingke, Lin Xh, liubuyu, liuwenhao4, liuxiao78, liuxiao93, liuyang_655, liuzhongkai, Lixia, lixian, liyanliu, liyong, lizhenyu, luopengting, lvchangquan, lvliang, lz, maning202007, Margaret_wangrui, mengyuanli, Ming_blue, ms_yan, ougongchang, panfengfeng, panyifeng, Payne, Peilin, peixu_ren, Pengyongrong, qianlong, qianjiahong, r1chardf1d0, riemann_penn, rmdyh, Sheng, shenwei41, simson, Simson, Su, sunsuodong, tao_yunhao, tinazhang, VectorSL, , Wan, wandongdong, wangdongxu, wangmin,  wangyue01, wangzhe, wanyiming, Wei, wenchunjiang, wilfChen, WilliamLian, wsc, wudenggang, wukesong, wuweikang, wuxuejian, Xiao Tianci, Xiaoda, xiefangqi, xinyunfan, xuanyue, xuyongfei, yanghaitao, yanghaitao1, yanghaoran, YangLuo, yangruoqi713, yankai, yanzhenxiang2020, yao_yf, yepei6, yeyunpeng, Yi, yoni, yoonlee666, yuchaojie, yujianfeng, yuximiao, zengzitao, Zhang,  zhanghuiyao, zhanghui_china, zhangxinfeng3, zhangyihui, zhangz0911gm, zhanke, zhanyuan, zhaodezan, zhaojichen, zhaoting, zhaozhenlong, zhengjun10, zhiqwang, zhoufeng, zhousiyi, zhouyaqiang, zhouyifengCode, Zichun, Ziyan, zjun, ZPaC, wangfengwfwf, zymaa, gerayking.\n\nContributions of any kind are welcome!\n\n## MindSpore Lite 1.7.0 Release Notes\n\n### Major Features and Improvements\n\n#### Post quantization\n\n- [STABLE] Support post quantization to run dynamic quantization algorithm.\n- [BETA] Support post quantized model to run on NVIDIA GPU.\n\n# MindSpore 1.6.0\n\n## MindSpore 1.6.0 Release Notes\n\n### Major Features and Improvements\n\n#### OS\n\n- [STABLE] Support macOS with CPU(X86)\n- [BETA] Supoport macOS with CPU(M1)\n\n#### FrontEnd\n\n- [STABLE] Support JIT Fallback feature in Graph mode.\n- [STABLE] Support compile cache feature in Graph mode.\n- [STABLE] Add new optimizers, including ASGD and Rprop.\n- [STABLE] Add new initializers, including Identity, Orthogonal, Dirac, Sparse and VarianceScaling.\n- [STABLE] Support resuming training when an exception occurs in the process.\n- [STABLE] Change `mindspore.nn.LSTMCell` from single-layer LSTM to single-cell LSTM.\n- [BETA] Introduce `mindspore.ops.Custom` to customize your own operators for Ascend(AICore, AICPU), GPU, CPU backends, and the custom type can be one of TBE, AKG, pure Python function or prebuild binary(called aot operator).\n\n#### PyNative\n\n- [STABLE] Support heterogeneous feature in PyNative mode.\n- [STABLE] Optimize memory allocation in PyNative mode.\n\n#### Auto Parallel\n\n- [STABLE] Support configuring the output shard strategy of the MatMul distributed operator.\n- [STABLE] Support multi-instances parallel.\n- [STABLE] Support activation slice communication and calculation overlap in Transformer.\n- [STABLE] Support heterogeneous parallel tensor swap.\n- [STABLE] Add implementations of distributed operator of ResizeNearestNeighbor.\n- [STABLE] Add a communication operator named NeighborExchangeV2 that supports data exchange between adjacent 8 rank ids.\n- [STABLE] Pipeline parallel support GPU platform.\n- [STABLE] Add cell-level data parallel interface.\n- [STABLE] Support gradient AllReduce fusion according to the amount of data.\n- [STABLE] Support a sharding strategy search algorithm called sharding propagation.\n\n#### Executor\n\n- [STABLE] Support multigraph sink and subgraph sink of MindRT.\n- [STABLE] Support memory swap to break the device memory size limit on Ascend platform.\n- [STABLE] Support dynamic deployment of distributed training cluster(GPU).\n- [BETA] Support automatic failover of parameter server.\n\n#### DataSet\n\n- [STABLE] Support overwrite feature in MindRecord.\n- [STABLE] Log improvement and more friendly to users.\n- [BETA] Support new feature [Dataset Offload](https://www.mindspore.cn/docs/programming_guide/en/r1.6/enable_dataset_offload.html) to speed up data processing by heterogeneous computing.\n- [BETA] Support new feature [Dataset Autotune](https://www.mindspore.cn/docs/programming_guide/en/r1.6/enable_auto_tune.html) to adjust parallelism of dataset pipeline automatically.\n\n#### GraphKernel Fusion\n\n- [STABLE] Support kernel fusion and generation for CPU backend.\n\n#### Federated Learning\n\n- [STABLE] FL-Client framework and model decoupling.\n- [BETA] Support Cross-silo federated learning framework.\n\n#### Debug\n\n- [STABLE] Support dump in cell level(Ascend).\n- [STABLE] Support dump Tensor statistics(Ascend/GPU).\n- [STABLE] Support displaying corresponding code lines for fusion nodes.\n- [STABLE] Support passing dump flag in Ascend backend in order to dump correct operators after fusion transformation.\n\n### API Change\n\n#### Backwards Incompatible Change\n\n##### Python API\n\n###### `mindspore.dataset.MindDataset` interface changes input parameter dataset_file([!27542](https://gitee.com/mindspore/mindspore/pulls/27542))\n\n`MindDataset` contains the input parameter `dataset_file`, which is in the singular format. It can receive a single file path or a list that stores multiple file paths. Thus It is preferred to change the input parameter `dataset_file` into plural format. In addition, the input parameters of most dataset API, such as `TFRecordDataset`, are in plural formart (`dataset_files`). To ensure consistency, the input parameter `dataset_file` of MindDataset is changed to plural formart as `dataset_files`,  we can see the updated version in api of [mindspore.dataset.MindDataset](https://www.mindspore.cn/docs/en/master/api_python/dataset/mindspore.dataset.MindDataset.html#mindspore.dataset.MindDataset).\n\n###### Delete `mindspore.Tensor`'s property `virtual_flag`([!26989](https://gitee.com/mindspore/mindspore/pulls/26989))\n\n###### Delete `mindspore.Parameter`'s property `is_init`([!26989](https://gitee.com/mindspore/mindspore/pulls/26989))\n\n###### Delete `mindspore.nn.ROC`'s interface `roc`([!25713](https://gitee.com/mindspore/mindspore/pulls/25713))\n\n###### The `shard()` interface of primitive is changed from `shard(strategy)` to `shard(in_strategy=None, out_strategy=None)`\n\n###### The `set_auto_parallel_context()` interface of context is changed from\n\n###### `set_auto_parallel_context(parallel_mode=AUTO_PARALLEL, auto_parallel_search_mode=\"dynamic_programming\")` to `set_auto_parallel_context(parallel_mode=AUTO_PARALLEL, search_mode=\"dynamic_programming\")`\n\n#### Collect Data and Create Landscape\n\n##### Python API\n\n###### `mindspore.train.callback.SummaryCollector` interface's parameter `collect_specified_data` add new operations `collect_landscape` ([!26229](https://gitee.com/mindspore/mindspore/pulls/26229))\n\n`collect_landscape` can collect the parameters needed to create the loss landscape. we can see the updated version in api of [mindspore.train.callback.SummaryCollector](https://www.mindspore.cn/docs/en/master/api_python/mindspore/mindspore.SummaryCollector.html#mindspore.SummaryCollector).\n\n###### `mindspore.train.callback` add new interface `SummaryLandscape` ([!26229](https://gitee.com/mindspore/mindspore/pulls/26229))\n\n`SummaryLandscape` can help you to collect loss landscape information. It can create landscape in PCA direction or random direction by calculating loss. We can see the updated version in api of [mindspore.train.callback.SummaryLandscape](https://www.mindspore.cn/docs/en/master/api_python/mindspore/mindspore.SummaryLandscape.html#mindspore.SummaryLandscape).\n\n### Bug fixes\n\n#### Executor\n\n- Fix process hanging while calling MPI_comm_create in asymmetric pipeline split scenario. ([!28707](https://gitee.com/mindspore/mindspore/pulls/28707))\n- Fix the execution error when the weights are shared between graph mode and PyNative mode.([!26635](https://gitee.com/mindspore/mindspore/pulls/26635))\n- Fixed the probability coredump when free memory under PyNative mode.([!25472](https://gitee.com/mindspore/mindspore/pulls/25472))\n\n#### Dataset\n\n- Fix memory increase abnormally when running dataset for a long time. ([!26237](https://gitee.com/mindspore/mindspore/pulls/26237))\n- Fix saving MindRecord files with Chinese path on Windows. ([!28378](https://gitee.com/mindspore/mindspore/pulls/28378))\n\n## MindSpore Lite\n\n### Major Features and Improvements\n\n#### Converter and runtime\n\n- [STABLE] Add more fusion patterns in the converter tool to improve runtime performance.\n- [STABLE] Support take OpenGL texture as input and output of inference.\n- [STABLE] Refactor the JAVA API.\n- [BETA] Support inference on Ascend310.\n\n#### x86 backend optimization\n\n- [STABLE] Optimize kernels for x86 using Advanced Vector Extensions(AVX512).\n\n#### ARM backend optimization\n\n- [STABLE] Support heterogeneous parallel inference, including splitting operators, constructing heterogeneous subgraphs, and heterogeneous parallel scheduling between CPUs and GPUs.\n- [STABLE] Add more FP16 operators.\n\n#### Post quantization\n\n- [STABLE] Post quantization supports debugging.\n- [STABLE] Full quantization supports choosing non-quantized nodes.\n- [STABLE] Mixed bit quantization supports auto-tune.\n\n#### Training on Device\n\n- [STABLE] Support user-defined algorithm models to access the federated learning framework.\n\n### Contributors\n\nThanks goes to these wonderful people:\n\nAGroupofProbiotocs, anzhengqi, askmiao, baihuawei, baiyangfan, bai-yangfan, bingyaweng, BowenK, buxue, caifubi, CaoJian, caojian05, caozhou, Cathy, changzherui, chenbo116, chenfei, chengxianbin, chenhaozhe, chenjianping, chenzomi, chenzupeng, chujinjin, cj, cjh9368, Corleone, damon0626, danish, Danish, davidmc, dayschan, doitH, dong-li001, fary86, fuzhiye, Gaoxiong, GAO_HYP_XYJ, gengdongjie, Gogery, gongdaguo, gray0v0, gukecai, guoqi, gzhcv, hangq, hanhuifeng2020, Harshvardhan, He, heleiwang, hesham, hexia, Hoai, HuangBingjian, huangdongrun, huanghui, huangxinjing, huqi, huzhifeng, hwjiaorui, Jiabin Liu, jianghui58, Jiaqi, jin-xiulang, jinyaohui, jjfeing, John, jonyguo, JulyAi, jzg, kai00, kingfo, kingxian, kpy, kswang, liuyongqi, laiyongqiang, leonwanghui, liangchenghui, liangzelang, lichen_101010, lichenever, lihongkang, lilei, limingqi107, ling, linqingke, Lin Xh, liubuyu, liuwenhao4, liuxiao78, liuxiao93, liuyang_655, liuzhongkai, Lixia, lixian, liyanliu, liyong, lizhenyu, luopengting, lvchangquan, lvliang, lz, maning202007, Margaret_wangrui, mengyuanli, Ming_blue, ms_yan, ougongchang, panfengfeng, panyifeng, Payne, Peilin, peixu_ren, Pengyongrong, qianlong, qianjiahong, r1chardf1d0, riemann_penn, rmdyh, Sheng, shenwei41, simson, Simson, Su, sunsuodong, tao_yunhao, tinazhang, VectorSL, , Wan, wandongdong, wangdongxu, wangmin, [wangnan39@huawei.com](mailto:wangnan39@huawei.com), wangyue01, wangzhe, wanyiming, Wei, wenchunjiang, wilfChen, WilliamLian, wsc, wudenggang, wukesong, wuweikang, wuxuejian, Xiao Tianci, Xiaoda, xiefangqi, xinyunfan, xuanyue, xuyongfei, yanghaitao, yanghaitao1, yanghaoran, YangLuo, yangruoqi713, yankai, yanzhenxiang2020, yao_yf, yepei6, yeyunpeng, Yi, yoni, yoonlee666, yuchaojie, yujianfeng, yuximiao, zengzitao, Zhang, [zhanghaibo5@huawei.com](mailto:zhanghaibo5@huawei.com), zhanghuiyao, zhanghui_china, zhangxinfeng3, zhangyihui, zhangz0911gm, zhanke, zhanyuan, zhaodezan, zhaojichen, zhaoting, zhaozhenlong, zhengjun10, zhiqwang, zhoufeng, zhousiyi, zhouyaqiang, zhouyifengCode, Zichun, Ziyan, zjun, ZPaC, wangfengwfwf, zymaa, gerayking.\n\nContributions of any kind are welcome!\n\n# MindSpore 1.5.2\n\n## MindSpore 1.5.2 Release Notes\n\n### Bug fixes\n\n- Fix code specification, pclint, codedex alarm.\n- Repair NN Abnormal output of graphnorm operator.\n- Fixed the problem of poor performance in scenes with dynamic rnngrad batch size of 16 times.\n\n### Contributors\n\nThanks goes to these wonderful people:\n\nAdel, AGroupofProbiotocs, anthonyaje, anzhengqi, askmiao, baihuawei, baiyangfan, bai-yangfan, bingyaweng, BowenK, buxue, caifubi, CaoJian, caojian05, caozhou, Cathy, changzherui, chenbo116, chenfei, chengxianbin, chenhaozhe, chenjianping, chenzomi, chenzupeng, chujinjin, cj, cjh9368, Corleone, damon0626, danish, Danish, davidmc, dayschan, doitH, dong-li001, eric, Eric, fary86, fuzhiye, Gaoxiong, GAO_HYP_XYJ, gengdongjie, Gogery, gongdaguo, gray0v0, gukecai, guoqi, gzhcv, hangq, hanhuifeng2020, Harshvardhan, He, heleiwang, hexia, Hoai, HuangBingjian, huangdongrun, huanghui, huangxinjing, huqi, huzhifeng, hwjiaorui, Islam Amin, Jesse, , Jiabin Liu, jianghui58, jiangzhiwen, Jiaqi, jin-xiulang, jinyaohui, jjfeing, John, Jonathan, jonyguo, JulyAi, jzg, kai00, kingfo, kingxian, kpy, kswang, laiyongqiang, leonwanghui, Li, liangchenghui, liangzelang, lichen_101010, lichenever, lihongkang, lilei, limingqi107, ling, linqingke, Lin Xh, liubuyu, liuwenhao4, liuxiao78, liuxiao93, liuyang_655, liuzhongkai, Lixia, lixian, liyanliu, liyong, lizhenyu, luopengting, luoyang, lvchangquan, lvliang, lz, mahdi, Mahdi, maning202007, Margaret_wangrui, mayang, mengyuanli, Ming_blue, nhussain, ougongchang, panfengfeng, panyifeng, Payne, Peilin, peixu_ren, Pengyongrong, qianlong, qianjiahong, r1chardf1d0, riemann_penn, rmdyh, Sheng, shenwei41, simson, Simson, Su, sunsuodong, tao_yunhao, tinazhang, VectorSL, , Wan, wandongdong, wangdongxu, wangmin, wangnan39@huawei.com, wangyue01, wangzhe, wanyiming, Wei, wenchunjiang, wilfChen, WilliamLian, wsc, wudenggang, wukesong, wuweikang, wuxuejian, Xiao Tianci, Xiaoda, xiefangqi, xinyunfan, xuanyue, xulei2020, Xun, xuyongfei, yanghaitao, yanghaitao1, yanghaoran, YangLuo, yangruoqi713, yankai, yanzhenxiang2020, yao_yf, yepei6, yeyunpeng, Yi, yoni, yoonlee666, yuchaojie, yujianfeng, yuximiao, zengzitao, Zhang, zhanghaibo5@huawei.com, zhanghuiyao, zhanghui_china, zhangxinfeng3, zhangyihui, zhangz0911gm, zhanke, zhanyuan, zhaodezan, zhaojichen, zhaoting, zhaozhenlong, zhengjun10, Zhenglong Li, zhiqwang, zhoufeng, zhousiyi, zhouyaqiang, zhouyifengCode, Zichun, Zirui, Ziyan, zjun, ZPaC, wangfengwfwf, zymaa, gerayking.\n\nContributions of any kind are welcome!\n\n# MindSpore 1.5.1\n\n## MindSpore 1.5.1 Release Notes\n\n### Bug fixes\n\n- Fix code specification, pclint, codedex alarm.\n- Fix yolov4 network probabilistic segment error.\n\n### Contributors\n\nThanks goes to these wonderful people:\n\nAdel, AGroupofProbiotocs, anthonyaje, anzhengqi, askmiao, baihuawei, baiyangfan, bai-yangfan, bingyaweng, BowenK, buxue, caifubi, CaoJian, caojian05, caozhou, Cathy, changzherui, chenbo116, chenfei, chengxianbin, chenhaozhe, chenjianping, chenzomi, chenzupeng, chujinjin, cj, cjh9368, Corleone, damon0626, danish, Danish, davidmc, dayschan, doitH, dong-li001, eric, Eric, fary86, fuzhiye, Gaoxiong, GAO_HYP_XYJ, gengdongjie, Gogery, gongdaguo, gray0v0, gukecai, guoqi, gzhcv, hangq, hanhuifeng2020, Harshvardhan, He, heleiwang, hexia, Hoai, HuangBingjian, huangdongrun, huanghui, huangxinjing, huqi, huzhifeng, hwjiaorui, Islam Amin, Jesse, , Jiabin Liu, jianghui58, jiangzhiwen, Jiaqi, jin-xiulang, jinyaohui, jjfeing, John, Jonathan, jonyguo, JulyAi, jzg, kai00, kingfo, kingxian, kpy, kswang, laiyongqiang, leonwanghui, Li, liangchenghui, liangzelang, lichen_101010, lichenever, lihongkang, lilei, limingqi107, ling, linqingke, Lin Xh, liubuyu, liuwenhao4, liuxiao78, liuxiao93, liuyang_655, liuzhongkai, Lixia, lixian, liyanliu, liyong, lizhenyu, luopengting, luoyang, lvchangquan, lvliang, lz, mahdi, Mahdi, maning202007, Margaret_wangrui, mayang, mengyuanli, Ming_blue, nhussain, ougongchang, panfengfeng, panyifeng, Payne, Peilin, peixu_ren, Pengyongrong, qianlong, qianjiahong, r1chardf1d0, riemann_penn, rmdyh, Sheng, shenwei41, simson, Simson, Su, sunsuodong, tao_yunhao, tinazhang, VectorSL, , Wan, wandongdong, wangdongxu, wangmin, wangnan39@huawei.com, wangyue01, wangzhe, wanyiming, Wei, wenchunjiang, wilfChen, WilliamLian, wsc, wudenggang, wukesong, wuweikang, wuxuejian, Xiao Tianci, Xiaoda, xiefangqi, xinyunfan, xuanyue, xulei2020, Xun, xuyongfei, yanghaitao, yanghaitao1, yanghaoran, YangLuo, yangruoqi713, yankai, yanzhenxiang2020, yao_yf, yepei6, yeyunpeng, Yi, yoni, yoonlee666, yuchaojie, yujianfeng, yuximiao, zengzitao, Zhang, zhanghaibo5@huawei.com, zhanghuiyao, zhanghui_china, zhangxinfeng3, zhangyihui, zhangz0911gm, zhanke, zhanyuan, zhaodezan, zhaojichen, zhaoting, zhaozhenlong, zhengjun10, Zhenglong Li, zhiqwang, zhoufeng, zhousiyi, zhouyaqiang, zhouyifengCode, Zichun, Zirui, Ziyan, zjun, ZPaC, wangfengwfwf, zymaa, gerayking.\n\nContributions of any kind are welcome!\n\n# MindSpore 1.5.0\n\n## MindSpore 1.5.0 Release Notes\n\n### Major Features and Improvements\n\n#### NewModels\n\n- [STABLE] Add CV model on Ascend: Fast-SCNN\n- [BETA] Add CV models on Ascend: midas_V2, attgan, FairMOT, CenterNet_resnet101, SEResNext, YOLOV3-tiny, RetinaFace\n- [STABLE] Add CV models on GPU: ssd_mobilenetv1_fpn, shufflenetv1, tinyDarkNet, CNN-CTC, unet++, DeepText, SqueezeNet\n- [STABLE] Add NLP models on GPU: GRU, GNMT2, Bert-Squad\n- [STABLE] Add recommend models on GPU: NCF\n- [BETA] Add CV models on GPU: FaceAttribute, FaceDetection, FaceRecongnition SENet,\n- [BETA] Add Audio models on GPU: DeepSpeech2\n- [STABLE]`model_zoo` has been separated to an individual repository`models`\n\n#### FrontEnd\n\n- [STABLE] Support`while` and`break`,`continue` statements of training network in`GRAPH_MODE`.\n- [BETA] Support export MindIR file after model training in cloud side and evaluate in edge side by import the MindIR file.\n- [STABLE] Support forward mode auto-diff interface Jvp(Jacobian-Vector-Product).\n- [STABLE] Support backward mode auto-diff interface Vjp(Vector-Jacobian-Product).\n\n#### Auto Parallel\n\n- [STABLE] Support distributed pipeline inference.\n- [STABLE] Add implementation of the sparse attention and its distributed operator.\n- [STABLE] Add implementations of distributed operator of Conv2d/Conv2dTranspose/Conv2dBackpropInput/Maxpool/Avgpool/Batchnorm/Gatherd.\n- [STABLE] Support configuring the dataset strategy on distributed training and inference mode.\n- [STABLE] Add high level API of the Transformer module.\n\n#### Executor\n\n- [STABLE] Support AlltoAll operator.\n- [STABLE] CPU operator (Adam) performance optimization increased by 50%.\n- [BETA] Support Adam offload feature, reduce the static memory usage of Pangu large model by 50%.\n- [STABLE] MindSpore Ascend backend supports configuration operator generation and loading cache path.\n- [STABLE] MindSpore Ascend backend supports lazy build in PyNaitve mode and compilation performance improved by 10 times.\n- [STABLE] The function or Cell decorated by ms_function supports gradient calculation in PyNative mode.\n- [STABLE] The outermost network supports parameters of non tensor type in PyNative mode.\n\n#### DataSet\n\n- [BETA] Add a new method for class Model to support auto data preprocessing in scenario of Ascend 310 inference.\n- [STABLE] Add a new drawing tool to visualize detection/segmentation datasets.\n- [STABLE] Support a new tensor operation named ConvertColor to support color space transform of images.\n- [STABLE] Enhance the following tensor operations to handle multiple columns simultaneously: RandomCrop, RandomHorizontalFlip, RandomResize, RandomResizedCrop, RandomVerticalFlip.\n- [STABLE] Support electromagnetic simulation dataset loading and data augmentation.\n- [STABLE] Optimize the error logs of Dataset to make them more friendly to users.\n\n#### Federated Learning\n\n- [STABLE] Change the deployment environment of FL-Client.\n\n#### Running Data Recorder\n\n- [STABLE] RDR saves collected data files within directories named by Rank ID on distributed training on Ascend, GPU and CPU.\n\n#### GraphKernel Fusion\n\n### API Change\n\n#### Backwards Incompatible Change\n\n##### Python API\n\n###### New Recomputation Configuration for AutoParallel and SemiAutoParallel Scenarios\n\nConfiguring the recomputation of the communication operations generated by the model parallel and optimizer parallel to save the memory on the\ndevices. Users can pass `mp_comm_recompute` and `parallel_optimizer_comm_recompute` to enable the recomputation of the communication operations.\n\n### Bug fixes\n\n#### FrontEnd\n\n- Fix bug of too many subgraphs when network include`for` statement.([!23669](https://gitee.com/mindspore/mindspore/pulls/23669))\n\n#### Executor\n\n- RunTask failed when parameter_broadcast is enabled in PyNative mode. ([!23255](https://gitee.com/mindspore/mindspore/pulls/23255))\n- An illegal memory access was encountered in the dynamic shape net on GPU.\n- Fix tune failed for DynamicRnn. ([!21081](https://gitee.com/mindspore/mindspore/pulls/21081))\n\n#### Dataset\n\n- Optimize thread monitoring to solve the problem of running multiple multiprocessesing on Windwos. ([!23232](https://gitee.com/mindspore/mindspore/pulls/23232))\n- Fix bugs of Dataset tensor operations in lite mode. ([!21999](https://gitee.com/mindspore/mindspore/pulls/21999))\n- Fix memory increasing when using create_dict_iterator in for loop. ([!22529](https://gitee.com/mindspore/mindspore/pulls/22529))([!22529](https://gitee.com/mindspore/mindspore/pulls/22529))\n\n## MindSpore Lite\n\n### Major Features and Improvements\n\n#### Converter and runtime\n\n1. Optimize TDNN-like streaming model by reusing the result of last inference.\n2. Support dynamic filter Convolution.\n3. Support serializing float32 weight into float16 weight for reducing size of model file.\n4. Provide unified runtime API for developer reusing their code between cloud side and end side.\n5. Now developer can configure built-in pass as custom passes.\n6. Now user can specify format and shape of model inputs while converting model.\n7. Support multiple devices inference, includeing CPU, NPU, GPU. User can set devices in mindspore::Context.\n8. Support mixed precision inference. User can set inference precision by LoadConfig API.\n9. Support custom operator registration and enable inference on third-party hardware.\n\n#### ARM backend optimization\n\n1. Support the nchw data format of some Operators, such as Conv, InstanceNorm, etc. The performance of some models convertered from onnx and caffe is greatly improved.\n2. Fix bugs of memory leak on NPU.\n\n#### Post quantization\n\n1. Weight quantization supports mixed bit quantization.\n2. Full quantization supports data pre-processing.\n3. Adjust the quantization parameters from the command line to the configuration file.\n\n#### Training on Device\n\n1. Unify lite external api with MindSpore.\n2. Implement static memory allocator and common workspace for TOD，save memory 10-20%.\n3. Provide getgradients and setgradients interface，get and set optimizer params interfaces to support MOE Model.\n4. Support user specified output node when export IOD Model.\n5. Support more text  networks (tinybert,albert) and operators.\n\n#### Codegen\n\n1. Support kernel register for custom op. Third-party hardware like NNIE can be accessed through it.\n\n### API Change\n\n#### API Incompatible Change\n\n##### C++ API\n\n### Contributors\n\nThanks goes to these wonderful people:\n\nAdel, AGroupofProbiotocs, anthonyaje, anzhengqi, askmiao, baihuawei, baiyangfan, bai-yangfan, bingyaweng, BowenK, buxue, caifubi, CaoJian, caojian05, caozhou, Cathy, changzherui, chenbo116, chenfei, chengxianbin, chenhaozhe, chenjianping, chenzomi, chenzupeng, chujinjin, cj, cjh9368, Corleone, damon0626, danish, Danish, davidmc, dayschan, doitH, dong-li001, eric, Eric, fary86, fuzhiye, Gaoxiong, GAO_HYP_XYJ, gengdongjie, Gogery, gongdaguo, gray0v0, gukecai, guoqi, gzhcv, hangq, hanhuifeng2020, Harshvardhan, He, heleiwang, hexia, Hoai, HuangBingjian, huangdongrun, huanghui, huangxinjing, huqi, huzhifeng, hwjiaorui, Islam Amin, Jesse, , Jiabin Liu, jianghui58, jiangzhiwen, Jiaqi, jin-xiulang, jinyaohui, jjfeing, John, Jonathan, jonyguo, JulyAi, jzg, kai00, kingfo, kingxian, kpy, kswang, laiyongqiang, leonwanghui, Li, liangchenghui, liangzelang, lichen_101010, lichenever, lihongkang, lilei, limingqi107, ling, linqingke, Lin Xh, liubuyu, liuwenhao4, liuxiao78, liuxiao93, liuyang_655, liuzhongkai, Lixia, lixian, liyanliu, liyong, lizhenyu, luopengting, luoyang, lvchangquan, lvliang, lz, mahdi, Mahdi, maning202007, Margaret_wangrui, mayang, mengyuanli, Ming_blue, nhussain, ougongchang, panfengfeng, panyifeng, Payne, Peilin, peixu_ren, Pengyongrong, qianlong, qianjiahong, r1chardf1d0, riemann_penn, rmdyh, Sheng, shenwei41, simson, Simson, Su, sunsuodong, tao_yunhao, tinazhang, VectorSL, , Wan, wandongdong, wangdongxu, wangmin, wangnan39@huawei.com, wangyue01, wangzhe, wanyiming, Wei, wenchunjiang, wilfChen, WilliamLian, wsc, wudenggang, wukesong, wuweikang, wuxuejian, Xiao Tianci, Xiaoda, xiefangqi, xinyunfan, xuanyue, xulei2020, Xun, xuyongfei, yanghaitao, yanghaitao1, yanghaoran, YangLuo, yangruoqi713, yankai, yanzhenxiang2020, yao_yf, yepei6, yeyunpeng, Yi, yoni, yoonlee666, yuchaojie, yujianfeng, yuximiao, zengzitao, Zhang, zhanghaibo5@huawei.com, zhanghuiyao, zhanghui_china, zhangxinfeng3, zhangyihui, zhangz0911gm, zhanke, zhanyuan, zhaodezan, zhaojichen, zhaoting, zhaozhenlong, zhengjun10, Zhenglong Li, zhiqwang, zhoufeng, zhousiyi, zhouyaqiang, zhouyifengCode, Zichun, Zirui, Ziyan, zjun, ZPaC, wangfengwfwf, zymaa, gerayking.\n\nContributions of any kind are welcome!\n\n# MindSpore 1.4.0\n\n## MindSpore 1.4.0 Release Notes\n\n### Major Features and Improvements\n\n#### NewModels\n\n#### FrontEnd\n\n#### Auto Parallel\n\n- Add distributed operators: Conv2D/Conv2DTranspose/Conv2DBackpropInput/MaxPool/AvgPool/BatchNorm/GatherD\n- Support to configure shard strategy for dataset\n\n#### Executor\n\n#### DataSet\n\n- Add SlicePatchesOperation for Remote Sensing feature（[!18179](https://e.gitee.com/mind_spore/repos/mindspore/mindspore/pulls/18179)）\n\n#### FederatedLearning\n\n#### Running Data Recorder\n\n#### GraphKernel Fusion\n\n#### Profiler\n\n- [STABLE]  Support MS_DIAGNOSTIC_DATA_PATH for profiler feature.(Ascend/GPU)\n\n#### Dump\n\n- [STABLE]  Support MS_DIAGNOSTIC_DATA_PATH for dump feature.(Ascend/GPU/CPU)\n\n### API Change\n\n#### Backwards Incompatible Change\n\n##### Python API\n\n##### Command Line Interface\n\n###### Dump Config\n\nPreviously, we need to set the dump path in dump config file. To make the dump feature easier to use on cloud, we support new environment parameter `MS_DIAGNOSTIC_DATA_PATH`.\n\n| 1.3.0                          | 1.4.0                                                                                                                                        |\n| ------------------------------ | -------------------------------------------------------------------------------------------------------------------------------------------- |\n| `path` is a mandatory field. | `path` field is optional.  If `path` field is not provided or is empty string, `MS_DIAGNOSTIC_DATA_PATH` should be set in environment. |\n\n### Bug fixes\n\n#### FrontEnd\n\n#### Executor\n\n#### Dataset\n\n- Fix module 'signal' has no attribute 'SIGCHLD' problem under windows platform. ([!21232](https://gitee.com/mindspore/mindspore/pulls/21232))\n\n## MindSpore Lite\n\n### Major Features and Improvements\n\n#### Converter and runtime\n\n#### x86 backend optimization\n\n#### ARM backend optimization\n\n#### Cuda backend optimization\n\n#### OpenCL backend\n\n#### Post quantization\n\n#### Training on Device\n\n#### Codegen\n\n### API Change\n\n#### API Incompatible Change\n\n##### C++ API\n\n#### New features\n\n##### Java API\n\n### Bug fixes\n\n#### Deprecations\n\n### Contributors\n\nThanks goes to these wonderful people:\n\nAdel, AGroupofProbiotocs, anthonyaje, anzhengqi, askmiao, baihuawei, baiyangfan, bai-yangfan, bingyaweng, BowenK, buxue, caifubi, CaoJian, caojian05, caozhou, Cathy, changzherui, chenbo116, chenfei, chengxianbin, chenhaozhe, chenjianping, chenzomi, chenzupeng, chujinjin, cj, cjh9368, Corleone, damon0626, danish, Danish, davidmc, dayschan, doitH, dong-li001, eric, Eric, fary86, fuzhiye, Gaoxiong, GAO_HYP_XYJ, gengdongjie, Gogery, gongdaguo, gray0v0, gukecai, guoqi, gzhcv, hangq, hanhuifeng2020, Harshvardhan, He, heleiwang, hexia, Hoai, HuangBingjian, huangdongrun, huanghui, huangxinjing, huqi, huzhifeng, hwjiaorui, Islam Amin, Jesse, , Jiabin Liu, jianghui58, jiangzhiwen, Jiaqi, jin-xiulang, jinyaohui, jjfeing, John, Jonathan, jonyguo, JulyAi, jzg, kai00, kingfo, kingxian, kpy, kswang, laiyongqiang, leonwanghui, Li, liangchenghui, liangzelang, lichen_101010, lichenever, lihongkang, lilei, limingqi107, ling, linqingke, Lin Xh, liubuyu, liuwenhao4, liuxiao78, liuxiao93, liuyang_655, liuzhongkai, Lixia, lixian, liyanliu, liyong, lizhenyu, luopengting, luoyang, lvchangquan, lvliang, lz, mahdi, Mahdi, maning202007, Margaret_wangrui, mayang, mengyuanli, Ming_blue, nhussain, ougongchang, panfengfeng, panyifeng, Payne, Peilin, peixu_ren, Pengyongrong, qianlong, qianjiahong, r1chardf1d0, riemann_penn, rmdyh, Sheng, shenwei41, simson, Simson, Su, sunsuodong, tao_yunhao, tinazhang, VectorSL, , Wan, wandongdong, wangdongxu, wangmin, wangnan39@huawei.com, wangyue01, wangzhe, wanyiming, Wei, wenchunjiang, wilfChen, WilliamLian, wsc, wudenggang, wukesong, wuweikang, wuxuejian, Xiao Tianci, Xiaoda, xiefangqi, xinyunfan, xuanyue, xulei2020, Xun, xuyongfei, yanghaitao, yanghaitao1, yanghaoran, YangLuo, yangruoqi713, yankai, yanzhenxiang2020, yao_yf, yepei6, yeyunpeng, Yi, yoni, yoonlee666, yuchaojie, yujianfeng, yuximiao, zengzitao, Zhang, zhanghaibo5@huawei.com, zhanghuiyao, zhanghui_china, zhangxinfeng3, zhangyihui, zhangz0911gm, zhanke, zhanyuan, zhaodezan, zhaojichen, zhaoting, zhaozhenlong, zhengjun10, Zhenglong Li, zhiqwang, zhoufeng, zhousiyi, zhouyaqiang, zhouyifengCode, Zichun, Zirui, Ziyan, zjun, ZPaC, wangfengwfwf, zymaa, gerayking.\n\nContributions of any kind are welcome!\n\n# MindSpore 1.3.0\n\n## MindSpore 1.3.0 Release Notes\n\n### Major Features and Improvements\n\n#### NewModels\n\n- [STABLE] Add CV models on Ascend: CPM, FCN8s, SSD-ResNet50-FPN, EAST, AdvancedEast.\n- [STABLE] Add NLP models on Ascend: DGU, TextCNN, SentimentNet(LSTM).\n- [STABLE] Add CV models on GPU: Faster-RCNN, FCN8s, CycleGAN, AdvancedEast.\n- [BETA] Add CV models on Ascend: CycleGAN, PoseNet, SimCLR.\n- [BETA] Add NLP models on Ascend: DGU, EmoTect, Senta, KT-Net.\n- [BETA] Add NLP models on GPU: DGU, EmoTect.\n- [BETA] Add EPP-MVSNet: a novel deep learning network for 3D reconstruction from multi-view stereo, which has won the first place in Tanks & Temples leaderboard(until April 1, 2021)(GPU).\n\n#### FrontEnd\n\n- [STABLE] The default running mode of MindSpore is changed to Graph mode.\n- [STABLE] Support interface `run_check` to check whether MindSpore is working properly or not.\n- [STABLE] Support saving custom information in the checkpoint file.\n- [STABLE] Normal class adds mean parameter.\n- [STABLE] Support export YOLOv3-DarkNet53 and YOLOv4 ONNX model.\n- [STABLE] Support 40+ operator export ONNX model.\n- [STABLE] The Metric module supports `set_indexes` to select the inputs of `update` in the specified order.\n- [STABLE] Switch `_Loss` to an external API `LossBase` as the base class of losses.\n\n#### Auto Parallel\n\n- [STABLE] Add distributed operators: Select/GatherNd/ScatterUpdate/TopK.\n- [STABLE] Support basic pipeline parallelism.\n- [STABLE] Optimize sharding strategy setting of `Gather`.\n- [STABLE] Optimize mix precision and shared parameter scenarios.\n- [STABLE] Optimize distributed prediction scenarios.\n\n#### Executor\n\n- [STABLE] Support unified runtime in GPU and CPU backend.\n- [STABLE] MindSpore GPU support CUDA11 with cuDNN8.\n- [STABLE] MindSpore GPU inference performance optimization by integrating TensorRT.\n- [STABLE] MindSpore built on one Linux distribution can now be used on multiple Linux distributions with the same CPU architecture (e.g. EulerOS, Ubuntu, CentOS).\n- [STABLE] MindSpore now supports Ascend310 and Ascend910 environments with one single wheel package and provides an alternate binary package for Ascend310 specifically.\n- [STABLE] MindSpore Ascend support group convolution.\n\n#### DataSet\n\n- [STABLE] Support caching over MindRecord dataset.\n- [STABLE] Support new shuffle mode for MindRecord dataset.\n- [STABLE] Support a cropper tool for MindSpore Lite to allow the user to customize MindData binary file according to their script.\n- [STABLE] Support share memory mechanism to optimize the multi-processing efficiency of GeneratorDataset/Map/Batch.\n- [STABLE] Add features for the GNN dataset to support molecular dynamics simulation scenarios.\n\n#### FederatedLearning\n\n- [STABLE] Support Cross-device federated learning framework.\n- [STABLE] Support FL-Server distributed networking including TCP and HTTP communication.\n- [STABLE] Support FL-Server distributed federated aggregation，support autoscaling and fault tolerance.\n- [STABLE] Develop FL-Client framework.\n- [STABLE] Supports local differential privacy algorithms.\n- [STABLE] MPC-based security aggregation algorithm.\n- [STABLE] MindSpore Lite Device-side Inference & Training Interconnection with FL-Client.\n\n#### Running Data Recorder\n\n- [STABLE] Provide records of multi-stage computational graphs, memory allocation information and graph execution order when a \"Launch kernel failed\" occurs. (CPU)\n\n#### GraphKernel Fusion\n\n- [STABLE] Add options to control the optimization level.\n- [STABLE] Enhance the generalization ability on GPU. GraphKernel is enabled by default in 40+ networks which cover the field of NLP, CV, Recommender, NAS and Audio. The result shows their throughput is significantly improved, and you are Recommended enabling GraphKernel in your network.\n\n#### Debug\n\n- [STABLE] Unified dump function.\n\n### API Change\n\n#### Backwards Incompatible Change\n\n##### Python API\n\n###### `mindspore.dataset.Dataset.device_que` interface removes unused parameter `prefetch_size`([!18973](https://gitee.com/mindspore/mindspore/pulls/18973))\n\nPreviously, we have a parameter `prefetch_size` in `device_que` to define the prefetch number of records ahead of the user's request. But indeed this parameter is never used which means it is an ineffective parameter. Therefore, we remove this parameter in 1.3.0 and users can set this configuration by [mindspore.dataset.config.set_prefetch_size](https://www.mindspore.cn/docs/api/en/r1.3/api_python/mindspore.dataset.config.html#mindspore.dataset.config.set_prefetch_size).\n\n<table>\n<tr>\n<td style=\"text-align:center\"> 1.2.1 </td> <td style=\"text-align:center\"> 1.3.0 </td>\n</tr>\n<tr>\n<td>\n\n```python\ndevice_que(prefetch_size=None, send_epoch_end=True, create_data_info_queue=False)\n```\n\n</td>\n<td>\n\n```python\ndevice_que(send_epoch_end=True, create_data_info_queue=False)\n```\n\n</td>\n</tr>\n</table>\n\n###### `mindspore.nn.optim.thor` interface changes to lowercase `thor` and adds two parameters `enable_clip_grad` and `frequency`([!17212](https://gitee.com/mindspore/mindspore/pulls/17212))\n\nThe parameter `enable_clip_grad` is used for gradient clipping and another parameter `frequency` is used to control the update interval of second order information matrix.\n\n<table>\n<tr>\n<td style=\"text-align:center\"> 1.2.1 </td> <td style=\"text-align:center\"> 1.3.0 </td>\n</tr>\n<tr>\n<td>\n\n```python\nTHOR(net, learning_rate, damping, momentum, weight_decay=0.0, loss_scale=1.0, batch_size=32,\n     use_nesterov=False, decay_filter=lambda x: x.name not in [], split_indices=None)\n```\n\n</td>\n<td>\n\n```python\nthor(net, learning_rate, damping, momentum, weight_decay=0.0, loss_scale=1.0, batch_size=32,\n     use_nesterov=False, decay_filter=lambda x: x.name not in [], split_indices=None, enable_clip_grad=False,\n     frequency=100)\n```\n\n</td>\n</tr>\n</table>\n\n##### Dump Config\n\nPreviously, we could only dump tensor data for one or all steps. To make the dump feature easier to use, we changed the dump configuration format and dump structure. View the [New Dump Tutorial](https://www.mindspore.cn/tutorials/experts/en/master/debug/dump.html#dump-introduction).\n\n| 1.2.1                                                  | 1.3.0                                                                                       |\n| ------------------------------------------------------ | ------------------------------------------------------------------------------------------- |\n| `iteration` is an int.                               | `iteration` is a string.                                                                  |\n| `op_debug_mode` is in `async_dump_settings` field. | `op_debug_mode` is in `common_dump_settings` field. `async_dump_settings` is removed. |\n\n### Bug fixes\n\n#### FrontEnd\n\n- Fix exception when use import module in while body such as 'F.xxx'.([!17635](https://e.gitee.com/mind_spore/repos/mindspore/mindspore/pulls/17635))\n- Fix the exception of 'exceeding limit call depth' in compile graph process when using while expression with grad operation. ([!18662](https://e.gitee.com/mind_spore/repos/mindspore/mindspore/pulls/18662))\n\n#### Executor\n\n- Fix reallocate memory bug for communication op.([!14492](https://gitee.com/mindspore/mindspore/pulls/14492))\n- Replace memcpy_async op with tensor_move op.([!15204](https://gitee.com/mindspore/mindspore/pulls/15204))\n- Fix the build error when multiple python versions are installed in the environment. ([!19165](https://gitee.com/mindspore/mindspore/pulls/19165))\n- The warning when the te/topi/hccl version does not match is optimized, and fix the repeated warning. ([!18704](https://gitee.com/mindspore/mindspore/pulls/18704))\n- Fix the error in a cluster with more than 8 pcs in pynative mode. ([!16376](https://gitee.com/mindspore/mindspore/pulls/16376))\n- Fix graph ring problem in UB fusion.([!16109](https://gitee.com/mindspore/mindspore/pulls/16109))\n- Fix AllGather op select problem when the shape is not divisible by 16. ([!18878](https://gitee.com/mindspore/mindspore/pulls/18878))\n\n#### Dataset\n\n- Fix an out-of-memory error when ImagefolderDataset gets an illegal directory. ([!16196](https://gitee.com/mindspore/mindspore/pulls/16196))\n- Fix bugs of vision transformations in lite mode. ([!14722](https://gitee.com/mindspore/mindspore/pulls/14722),[!14774](https://gitee.com/mindspore/mindspore/pulls/14774),[!15050](https://gitee.com/mindspore/mindspore/pulls/15050))\n- Fix default numbers of parallel workers of MindData for those CPUs with fewer cores. ([!15921](https://gitee.com/mindspore/mindspore/pulls/15921))\n- Fix MindRecord writing failed probabilistically in multiprocessing. ([!15242](https://gitee.com/mindspore/mindspore/pulls/15242))\n\n## MindSpore Lite\n\n### Major Features and Improvements\n\n#### Converter and runtime\n\n1. Support Caffe model running on Hi3516D.\n2. Support delegate mechanism to run your models(part or whole) on user specified executor.\n3. Support control flow models.\n4. Support cross-compiling for iOS, so that we can inference models on iOS devices.\n\n#### x86 backend optimization\n\n1. Optimize kernels for x86 using Advanced Vector Extensions(AVX).\n\n#### ARM backend optimization\n\n1. Optimize fp16 kernels.\n2. Support arm32 fp16 instruction acceleration on ARMv8.2.\n\n#### Cuda backend optimization\n\n1. Support NV GPU backend base on delegate mechanism(use TensorRT as delegate).\n\n#### OpenCL backend\n\n1. Optimize the strategy of workgroup and blocksize to improve performance.\n2. Support OpenCL dynamic infershape.\n3. Support INT32 type ops.\n\n#### Post quantization\n\n1. Support fp32 training model converts to quantization training model.\n\n#### Training on Device\n\n1. Support fp32 training model export to quantization model after training process end.\n2. Unify APIs and output package name of training and inference.\n3. Simplify implementation of Train Session.\n4. Optimize train and infer compile, reduce libmindspore-lite-train.so memory.\n5. Training memory optimization:  memory reduce 10-50% compare with  r1.2.\n6. Training performance optimization:  for 1*1 special input shape Cov2DGradInput and SparseSoftmaxCrossEntropyWithLogits operator optimization, improved 10%-20%.\n7. Support more networks(transformer, albert).\n\n#### Codegen\n\n1. Support deployment on HarmonyOS for device.\n\n### API Change\n\n#### API Incompatible Change\n\n##### C++ API\n\n###### Unify LiteSession and TrainSession, Merge LiteSession And TrainSession.([!17356](https://gitee.com/mindspore/mindspore/pulls/17356))\n\nPreviously, Training on Device use TrainSession while Inference on Device use LiteSession. To simplify implementation, we move TrainSession functions to LiteSession as virtual function. and move APIs previous defined in train_session.h to lite_session.h.\n\n```cpp\nclass MS_API LiteSession {\n...\nstatic LiteSession *CreateTrainSession(const std::string &filename, const lite::Context *context,\n                                         bool train_mode = false, const lite::TrainCfg *cfg = nullptr);\n static LiteSession *CreateTransferSession(const std::string &filename_backbone, const std::string &filename_head,\n                                            const lite::Context *context, bool train_mode = false,\n                                            const lite::TrainCfg *cfg = nullptr);\nvirtual int Train() { return mindspore::lite::RET_ERROR; }\nvirtual int Eval() { return mindspore::lite::RET_OK; }\nvirtual int SetupVirtualBatch(int virtual_batch_multiplier, float lr = -1.0f, float momentum = -1.0f) {\n    return mindspore::lite::RET_ERROR;\n  }\nvirtual std::vector<tensor::MSTensor *> GetPredictions() const {\n    std::vector<tensor::MSTensor *> outputs;\n    return outputs;\n }\n...\n```\n\n###### Add Export API for Training on device, obsolete SaveToFile API.([!17356](https://gitee.com/mindspore/mindspore/pulls/17356))\n\nPreviously, Training on Device uses SaveToFile API to save the training model to file. Export API was added in this release to support more format, more model type(train or interface part of the model), and save weight quant model of train.\n\n```cpp\nvirtual int Export(const std::string &file_name, lite::ModelType model_type = lite::MT_TRAIN,\n                     lite::QuantizationType quant_type = lite::QT_DEFAULT, lite::FormatType = lite::FT_FLATBUFFERS) {\n    return mindspore::lite::RET_ERROR;\n }\n```\n\n###### Add GetFeatureMaps and UpdateFeatureMaps interface for Training on device.([!18344](https://gitee.com/mindspore/mindspore/pulls/18344))\n\nWhen Training on the device, we may need to update the model featuremap and get model featuremap.particularly in MindSpore Federated Scenario.\n\n```cpp\nvirtual std::vector<tensor::MSTensor *> GetFeatureMaps() const {\n    std::vector<tensor::MSTensor *> features;\n    return features;\n  }\n  virtual int UpdateFeatureMaps(const std::vector<tensor::MSTensor *> &features) { return mindspore::lite::RET_ERROR; }\n```\n\n#### New features\n\n##### Java API\n\n###### new static method for creating LiteSession by MSConifg in LiteSession.class\n\nPreviously, if we want to create a LiteSession object, we need to call two APIs:\n\n```js\nMSConfig config;\n// config options ...\nLiteSession liteSession = new LiteSession();\nboolean ret = liteSession.init(config);\nif (!ret) {\n  // handle init LiteSession failed ...\n}\n```\n\nnow we can create a LiteSession object with new API just like:\n\n```js\nMSConfig config;\n// config options ...\nLiteSession liteSession = createSession(config);\nif (liteSession == null) {\n  // handle create LiteSession failed ...\n}\n```\n\n###### new static method for creating LiteSession byModelBuffer and MSConfig in LiteSession.class\n\nPreviously, if we want to inference a model, we need to call APIs like:\n\n```js\nMSConfig config;\n// config options ...\nLiteSession liteSession = new LiteSession();\nboolean initSessionRet = liteSession.init(config);\nif (!initSessionRet) {\n  // handle init LiteSession failed and return ...\n}\nModel model = new Model();\nboolean loadModelRet = model.loadModel(modelMappedByteBuffer);\nif (!loadModelRet) {\n  // handle load model failed and return ...\n}\nboolean compileModelRet = liteSession.compileGraph(model);\nif (!loadModelRet) {\n  // handle compile model failed and return ...\n}\nmodel.free();\n// liteSession is ready to inference model, call runGraph in LiteSession.class ...\n```\n\nnow we can use new API just like:\n\n```js\nMSConfig config;\n// config options ...\nLiteSession liteSession = createSession(modelMappedByteBuffer, config);\nif (liteSession == null) {\n  // handle init LiteSession failed and return ...\n}\n// liteSession is ready to inference model, call runGraph in LiteSession.class ...\n```\n\nNew createSession method is an API that integrates four old APIs: LiteSession.init, Model.loadModel, LiteSession.compileGraph and model.free. It is simple and efficient as it reduces one modelBuffer copy operation.\n\n###### new methods getFeaturesMap and updateFeatures for in LiteSession.class\n\nRecently, we add a new C++ api in LiteSession class, Correspondingly we add a new java API in LiteSession.java.\n\n```java\npublic List<MSTensor> getFeaturesMap() {\n         List<Long> ret = this.getFeaturesMap(this.sessionPtr);\n                ArrayList<MSTensor> tensors = new ArrayList<MSTensor>();\n                for (Long msTensorAddr : ret) {\n                    MSTensor msTensor = new MSTensor(msTensorAddr);\n                    tensors.add(msTensor);\n                }\n                return tensors;\n   }\n   public boolean updateFeatures(List<MSTensor> features) {\n            long[] inputsArray = new long[features.size()];\n            for (int i = 0; i < features.size(); i++) {\n                inputsArray[i] = features.get(i).getMSTensorPtr();\n            }\n             return this.updateFeatures(this.sessionPtr, inputsArray);\n   }\n```\n\n###### new methods export to replace saveToFile API in LiteSession.class\n\nRecently, we add a new C++ api in LiteSession class, Correspondingly we add a new java API in LiteSession.java.\n\n```java\npublic boolean export(String modelFileName, int modelType, int quantizationType) {\n        return this.export(this.sessionPtr, modelFileName, modelType, quantizationType);\n    }\n```\n\n###### new train related  API moved to LiteSession.class from TrainSession.class\n\nAlign with update of C++ api in LiteSession class, add new java API to LiteSession.java Correspondingly.\n\n```java\npublic class LiteSession {\n...\npublic static LiteSession createTrainSession(String modelName, final MSConfig config, boolean trainMode){...}\npublic boolean train() {...}\npublic boolean eval() {...}\n...\n```\n\n### Bug fixes\n\n1. Fix the bug that the train session does not release memory cause of refcount bug.\n\n#### Deprecations\n\n### Contributors\n\nThanks goes to these wonderful people:\n\nAdel, AGroupofProbiotocs, anthonyaje, anzhengqi, askmiao, baihuawei, baiyangfan, bai-yangfan, bingyaweng, BowenK, buxue, caifubi, CaoJian, caojian05, caozhou, Cathy, changzherui, chenbo116, chenfei, chengxianbin, chenhaozhe, chenjianping, chenzomi, chenzupeng, chujinjin, cj, cjh9368, Corleone, damon0626, danish, Danish, davidmc, dayschan, doitH, dong-li001, eric, Eric, fary86, fuzhiye, Gaoxiong, GAO_HYP_XYJ, gengdongjie, Gogery, gongdaguo, gray0v0, gukecai, guoqi, gzhcv, hangq, hanhuifeng2020, Harshvardhan, He, heleiwang, hexia, Hoai, HuangBingjian, huangdongrun, huanghui, huangxinjing, huqi, huzhifeng, hwjiaorui, Islam Amin, Jesse, , Jiabin Liu, jianghui58, jiangzhiwen, Jiaqi, jin-xiulang, jinyaohui, jjfeing, John, Jonathan, jonyguo, JulyAi, jzg, kai00, kingfo, kingxian, kpy, kswang, laiyongqiang, leonwanghui, Li, liangchenghui, liangzelang, lichen_101010, lichenever, lihongkang, lilei, limingqi107, ling, linqingke, Lin Xh, liubuyu, liuwenhao4, liuxiao78, liuxiao93, liuyang_655, liuzhongkai, Lixia, lixian, liyanliu, liyong, lizhenyu, luopengting, luoyang, lvchangquan, lvliang, lz, mahdi, Mahdi, maning202007, Margaret_wangrui, mayang, mengyuanli, Ming_blue, nhussain, ougongchang, panfengfeng, panyifeng, Payne, Peilin, peixu_ren, Pengyongrong, qianlong, qianjiahong, r1chardf1d0, riemann_penn, rmdyh, Sheng, shenwei41, simson, Simson, Su, sunsuodong, tao_yunhao, tinazhang, VectorSL, , Wan, wandongdong, wangdongxu, wangmin, wangnan39@huawei.com, wangyue01, wangzhe, wanyiming, Wei, wenchunjiang, wilfChen, WilliamLian, wsc, wudenggang, wukesong, wuweikang, wuxuejian, Xiao Tianci, Xiaoda, xiefangqi, xinyunfan, xuanyue, xulei2020, Xun, xuyongfei, yanghaitao, yanghaitao1, yanghaoran, YangLuo, yangruoqi713, yankai, yanzhenxiang2020, yao_yf, yepei6, yeyunpeng, Yi, yoni, yoonlee666, yuchaojie, yujianfeng, yuximiao, zengzitao, Zhang, zhanghaibo5@huawei.com, zhanghuiyao, zhanghui_china, zhangxinfeng3, zhangyihui, zhangz0911gm, zhanke, zhanyuan, zhaodezan, zhaojichen, zhaoting, zhaozhenlong, zhengjun10, Zhenglong Li, zhiqwang, zhoufeng, zhousiyi, zhouyaqiang, zhouyifengCode, Zichun, Zirui, Ziyan, zjun, ZPaC, wangfengwfwf, zymaa, gerayking.\n\nContributions of any kind are welcome!\n\n# MindSpore 1.2.1\n\n## MindSpore 1.2.1 Release Notes\n\n### Major Features and Improvements\n\n#### FrontEnd\n\n- [STABLE] Add MaskedSelect aicpu operation.(Ascend)\n\n#### Auto Parallel\n\n- [STABLE] Support distributed checkpoint loading.(Ascend/GPU)\n\n# MindSpore 1.2.0\n\n## MindSpore 1.2.0 Release Notes\n\n### Major Features and Improvements\n\n#### NewModels\n\n- [STABLE] Add CV models on Ascend: 3D Unet, Unet++, SSD-Resnet50-fpn, SSD-VGG16, crnn_seq2seq_ocr for BSI, CTPN, resnet18, DPN\n- [STABLE] Add CV models on GPU: Faster-RCNN\n- [STABLE] Add NLP models on Ascend: NAML, Fasttext, GRU, LSTM\n- [BETA] Add TPRR: Thinking Path Re-Ranker, an original ranked-base framework for Multi-Hop Question Answering which has won the first place in HotpotQA leaderboard.(Ascend)\n\n#### FrontEnd\n\n- [STABLE] Support side effects expression to ensure that the perform order of user's semantics is correct.(Ascend/GPU/CPU)\n- [STABLE] Support calculating the gradient for network that contain non-Tensor input parameters（int, float, bool, mstype,int, mstype.float, mstype.uint, mstype.bool_, tuple, list, dict）.(Ascend/GPU/CPU)\n- [STABLE] Support the inverse of a bool Tensor.(Ascend/GPU/CPU)\n- [STABLE] Uniform the interface `isinstance`.(Ascend/GPU/CPU)\n- [STABLE] Support negative indexes.(Ascend/GPU/CPU)\n- [STABLE] Support 110+ Numpy-like interfaces in mindspore.numpy.(Ascend/GPU/CPU)\n- [STABLE] Support export/load mindir model with a size greater than 2 GB.\n- [STABLE] The optimizer supports gradient centralization.(Ascend)\n- [STABLE] Support support auc metric, rou metric, bleu score metric, confusion matrix metric, cosine similarity metric, dice metric, hausdorff distance metric, occlusion sensitivity metric, perplexity metric, mean surface distance metric, root mean surface distance metric.\n- [STABLE] Support use EmbeddingLookup with cache.(Ascend)\n- [STABLE] Add MaskedSelect aicpu operation.(Ascend)\n\n#### Auto Parallel\n\n- [STABLE] Support AllGather and ReduceScatter fusion.(Ascend)\n- [STABLE] Support gradient accumulation feature in auto parallel mode.(Ascend/GPU)\n- [STABLE] Support running parallel optimizer with gradient accumulation.(Ascend)\n- [STABLE] Add the configuration of communication operators' fusion.(Ascend)\n- [STABLE] Support distributed checkpoint loading.(Ascend/GPU)\n\n#### Executor\n\n- [STABLE] Support inference with Nvidia GPU.\n- [STABLE] Support data parallelism in PyNative mode.(Ascend/GPU)\n- [STABLE] Optimize LSTM inference memory consumption in Graph mode with CPU.\n\n#### Sponge\n\n- [STABLE] Add SPONGE modules for molecular dynamics simulation, including Bond, Angle, Dihedral, Non Bond 14, NeighborList, Particle Mesh Ewald, Langevin MD and LIUJIAN MD.(GPU)\n\n#### DataSet\n\n- [STABLE] If the libnuma library is installed in the environment, you can run `export DATASET_ENABLE_NUMA=True` or `export MS_ENABLE_NUMA=True` to configure NUMA binding. In multi-card training scenarios, the training data processing speed can be improved, thereby improving the network training efficiency.\n- [STABLE] Unify API Tensor structure of Training/Inference interfaces in C++ SDK.\n- [STABLE] Optimize duplicated Decode in data preprocess using cache, improve preprocess efficiency.\n- [STABLE] Support eager mode to run data augmentation in Python & C++.\n- [STABLE] Support more data augmentation operators(e.g. Affine, Perspective) in MindSpore-Lite.\n- [STABLE] Support light pipeline to process MindData in MindSpore-Lite training.\n- [STABLE] Support more data preprossing operators based on DVPP hardware module and can be used on on Ascend310 platform.\n- [STABLE] Support copy-free property for data in Ascend310 inference process scenarios.\n\n#### Running Data Recorder\n\n- [STABLE] Support running data recorder (RDR)  for exception demarcation.\n- [STABLE] Provide records of multi-stage computational graphs, memory allocation information, graph execution order, stream execution order and task debug information when a \"run task error\" or \"distribute task failed\" occurs. (Ascend)\n- [STABLE] Provide records of multi-stage computational graphs, memory allocation information and graph execution order when a \"SyncStream error\" occurs. (GPU)\n\n#### 3D Feature\n\n- [STABLE] Support 3D ops: Conv3D, Conv3DBackpropInput, Conv3DBackpropFilter, Conv3DTranspose, BiasAdd, BiasAddGrad, PReLU, Transpose, Reshape, transdata, StrideSlice, MaxPool3D, MaxPool3DGrad, BinaryCrossEntropy, SigmoidCrossEntropyWithLogits, SigmoidCrossEntropyWithLogitsGrad, SoftmaxCrossEntropyWithLogits, SigmoidCrossEntropyWithLogits, SigmoidCrossEntropyWithLogitsGrad, BatchNorm3d, BatchNorm3dGrad, Dropout3d.\n- [STABLE] Support RMSELoss loss function, MAELoss loss function, FocalLoss loss function, DiceLoss binary loss function, and MultiClassDiceLoss multi-type loss function for 2D/3D network.\n- [STABLE] Add optimizer: AdamApplyOne(3D), ApplyMomentum(3D), SGD(3D).\n\n### API Change\n\n#### Backwards Incompatible Change\n\n##### Python API\n\n###### `mindspore.numpy.array()`, `mindspore.numpy.asarray()`, `mindspore.numpy.asfarray()`, `mindspore.numpy.copy()` now support GRAPH mode, but cannot accept `numpy.ndarray` as input arguments anymore([!12726](https://gitee.com/mindspore/mindspore/pulls/12726))\n\nPreviously, these interfaces can accept numpy.ndarray as arguments and convert numpy.ndarray to Tensor, but cannot be used in GRAPH mode.\nHowever, currently MindSpore Parser cannot parse numpy.ndarray in JIT-graph. To support these interfaces in graph mode, we have to remove `numpy.ndarray` support. With that being said, users can still use `Tensor` to convert `numpy.ndarray` to tensors.\n\n<table>\n<tr>\n<td style=\"text-align:center\"> 1.1.1 </td> <td style=\"text-align:center\"> 1.2.0 </td>\n</tr>\n<tr>\n<td>\n\n```python\n>>> import mindspore.numpy as mnp\n>>> import numpy\n>>>\n>>> nd_array = numpy.array([1,2,3])\n>>> tensor = mnp.asarray(nd_array) # this line cannot be parsed in GRAPH mode\n```\n\n</td>\n<td>\n\n```python\n>>> import mindspore.numpy as mnp\n>>> import numpy\n>>>\n>>> tensor = mnp.asarray([1,2,3]) # this line can be parsed in GRAPH mode\n```\n\n</td>\n</tr>\n</table>\n\n###### mindspore.numpy interfaces remove support for keyword arguments `out` and `where`([!12726](https://gitee.com/mindspore/mindspore/pulls/12726))\n\nPreviously, we have incomplete support for keyword arguments `out` and `where` in mindspore.numpy interfaces, however, the `out` argument is only functional when `where` argument is also provided, and `out` cannot be used to pass reference to numpy functions. Therefore, we have removed these two arguments to avoid any confusion users may have. Their original functionality can be found in [np.where](https://www.mindspore.cn/docs/en/master/api_python/numpy/mindspore.numpy.where.html#mindspore.numpy.where)\n\n<table>\n<tr>\n<td style=\"text-align:center\"> 1.1.1 </td> <td style=\"text-align:center\"> 1.2.0 </td>\n</tr>\n<tr>\n<td>\n\n```python\n>>> import mindspore.numpy as np\n>>>\n>>> a = np.ones((3,3))\n>>> b = np.ones((3,3))\n>>> out = np.zeros((3,3))\n>>> where = np.asarray([[True, False, True],[False, False, True],[True, True, True]])\n>>> res = np.add(a, b, out=out, where=where) # `out` cannot be used as a reference, therefore it is misleading\n```\n\n</td>\n<td>\n\n```python\n>>> import mindspore.numpy as np\n>>>\n>>> a = np.ones((3,3))\n>>> b = np.ones((3,3))\n>>> out = np.zeros((3,3))\n>>> where = np.asarray([[True, False, True],[False, False, True],[True, True, True]])\n>>> res = np.add(a, b)\n>>> out = np.where(where, x=res, y=out) # instead of np.add(a, b, out=out, where=where)\n```\n\n</td>\n</tr>\n</table>\n\n###### Turn `ops.MakeRefKey` into an internal interface ([!12010](https://gitee.com/mindspore/mindspore/pulls/12010))\n\nPreviously MakeRefKey is an external interface that is not used, now make it an internal interface with the same usage. We do not recommend users to use this interface, and we will remove the relevant introduction of this interface from the official website.\n\n###### `ops.ApplyFtrl`, `ops.ApplyMomentum`, `ops.ApplyRMSProp`, `ops.ApplyCenteredRMSProp` change the output on Ascend backend from multiple to a single. ([!11895](https://gitee.com/mindspore/mindspore/pulls/11895))\n\nPreviously the number of outputs of these operator is different on different backends. To unify their definition we change their output on Ascend backend from multiple to a single.\n\n##### `P.FusedBatchNorm`, `P.FusedBatchNormEx` deleted ([!12115](https://gitee.com/mindspore/mindspore/pulls/12115))\n\nThe FusedBatchNorm and FusedBatchNormEx interface has been deleted. Please use the batchnorm operator to replace it.\n\n##### `MetaTensor` deleted ([!10325](https://gitee.com/mindspore/mindspore/pulls/10325))\n\nThe MetaTensor interface has been deleted. The function of MetaTensor has been integrated into tensor.\n\n###### `ControlDepend` is deleted, use `Depend` instead. The decorator `@C.add_flags(has_effect=True)` does not work. ([!13793](https://gitee.com/mindspore/mindspore/pulls/13793))\n\nPreviously, we used ControlDepend to control the execution order of multiple operators. In version 1.2.0, mindspore introduces the auto-monad side effects expression to ensure that the perform order of user's semantics is correct. Therefore, ControlDepend is deleted and Depend is recommended.\n\nIn most scenarios, if operators have IO side effects (such as print) or memory side effects (such as assign), they will be executed according to the user's semantics. In some scenarios, if the two operators A and B have no order dependency, and A must be executed before B, we recommend using Depend to specify their execution order. See the API documentation of the Depend operator for specific usage.\n\n<table>\n<tr>\n<td style=\"text-align:center\"> 1.1.1 </td> <td style=\"text-align:center\"> 1.2.0 </td>\n</tr>\n<tr>\n<td>\n\n```python\n    In some side-effect scenarios, we need to ensure the execution order of operators.\n    In order to ensure that operator A is executed before operator B, it is recommended\n    to insert the Depend operator between operators A and B.\n\n    Previously, the ControlDepend operator was used to control the execution order.\n    Since the ControlDepend operator is deprecated from version 1.1, it is recommended\n    to use the Depend operator instead. The replacement method is as follows::\n\n        a = A(x)                --->        a = A(x)\n        b = B(y)                --->        y = Depend(y, a)\n        ControlDepend(a, b)     --->        b = B(y)\n```\n\n</td>\n<td>\n\n```python\n    In most scenarios, if operators have IO side effects or memory side effects,\n    they will be executed according to the user's semantics. In some scenarios,\n    if the two operators A and B have no order dependency, and A must be executed\n    before B, we recommend using Depend to specify their execution order. The\n    usage method is as follows::\n\n        a = A(x)                --->        a = A(x)\n        b = B(y)                --->        y = Depend(y, a)\n                                --->        b = B(y)\n```\n\n</td>\n</tr>\n</table>\n\nAfter the introduction of the auto-monad side effect expression feature, the decorator `@C.add_flags(has_effect=True)` does not work. If the decorator is used in the script, please modify. Take the overflow identification operator (without side effects) as an example, the modification method is as follows:\n\n<table>\n<tr>\n<td style=\"text-align:center\"> 1.1.1 </td> <td style=\"text-align:center\"> 1.2.0 </td>\n</tr>\n<tr>\n<td>\n\n```python\n@C.add_flags(has_effect=True)\ndef construct(self, *inputs):\n    ...\n    loss = self.network(*inputs)\n    init = self.allo_status()\n    self.clear_status(init)\n    ...\n```\n\n</td>\n<td>\n\n```python\ndef construct(self, *inputs):\n    ...\n    loss = self.network(*inputs)\n    init = self.allo_status()\n    init = F.depend(init, loss)\n    clear_status = self.clear_status(init)\n    ...\n```\n\n</td>\n</tr>\n</table>\n\n##### C++ API\n\n###### C++ API support dual ABI now.([!12432](https://gitee.com/mindspore/mindspore/pulls/12432))\n\n1.1.1 supports only the old ABI. Currently, both the new and the old are supported.\n\n<table>\n<tr>\n<td style=\"text-align:center\"> 1.1.1 </td> <td style=\"text-align:center\"> 1.2.0 </td>\n</tr>\n<tr>\n<td>\n\n```cmake\nadd_compile_definitions(_GLIBCXX_USE_CXX11_ABI=0)\n```\n\n</td>\n<td>\n\n```cmake\nadd_compile_definitions(_GLIBCXX_USE_CXX11_ABI=0)  # old ABI are supported\nadd_compile_definitions(_GLIBCXX_USE_CXX11_ABI=1)  # new ABI are supprrted, too\n                                                   # write nothing, use new ABI as default\n```\n\n</td>\n</tr>\n</table>\n\n###### Context refactor.([!13515](https://gitee.com/mindspore/mindspore/pulls/13515))\n\nThe `Context` class is refactored. For details, see the API docs.\n\n<table>\n<tr>\n<td style=\"text-align:center\"> 1.1.1 </td> <td style=\"text-align:center\"> 1.2.0 </td>\n</tr>\n<tr>\n<td>\n\n```cpp\nGlobalContext::SetGlobalDeviceTarget(kDeviceTypeAscend310);       // set device target is ascend310\nGlobalContext::SetGlobalDeviceID(0);                              // set device id is 0\nauto model_context = std::make_shared<ModelContext>();            // create a model context\nModelContext::SetInsertOpConfigPath(model_context, \"./aipp.cfg\")  // set aipp config file is ./aipp.cfg\n```\n\n</td>\n<td>\n\n```cpp\nauto model_context = std::make_shared<Context>();                 // create a model context\nauto ascend310_info = std::make_shared<Ascend310DeviceInfo>();\nmodel_context.MutableDeviceInfo().push_back(ascend310_info );     // set device target is ascend310\nascend310_info->SetDeviceID(0);                                   // set device id is 0\nascend310_info->SetInsertOpConfigPath(\"./aipp.cfg\");              // set aipp config file is ./aipp.cfg\n```\n\n</td>\n</tr>\n</table>\n\n###### LoadModel interface changes.([!13515](https://gitee.com/mindspore/mindspore/pulls/13515))\n\n`LoadModel` is renamed `Load`. No exception is thrown new but the return status should be checked.\n\n<table>\n<tr>\n<td style=\"text-align:center\"> 1.1.1 </td> <td style=\"text-align:center\"> 1.2.0 </td>\n</tr>\n<tr>\n<td>\n\n```cpp\ntry {\n  auto graph = Serialization::LoadModel(model_file_path, kMindIR);\n} catch (...) { ... }\n```\n\n</td>\n<td>\n\n```cpp\nGraph graph;\nauto ret = Serialization::Load(model_file_path, kMindIR, &graph);\nif (ret != kSuccess) { ... }\n```\n\n</td>\n</tr>\n</table>\n\n###### Model ctor changes.([!13515](https://gitee.com/mindspore/mindspore/pulls/13515))\n\n`Model` uses a non-parameter ctor now, and arguments are passed in through `Build`.\n\n<table>\n<tr>\n<td style=\"text-align:center\"> 1.1.1 </td> <td style=\"text-align:center\"> 1.2.0 </td>\n</tr>\n<tr>\n<td>\n\n```cpp\nModel net(net_cell, model_context);\nauto ret = net.Build();\nif (ret != kSuccess) { ... }\n```\n\n</td>\n<td>\n\n```cpp\nModel net;\nauto ret = net.Build(net_cell, model_context);\nif (ret != kSuccess) { ... }\n```\n\n</td>\n</tr>\n</table>\n\n###### MSTensor::CreateTensor returns a native pointer now.([!13515](https://gitee.com/mindspore/mindspore/pulls/13515))\n\n`MSTensor::CreateTensor` and `MSTensor::CreateRefTensor` returns a native pointer now, need to be destroy by `DestroyTensorPtr`.\n\n<table>\n<tr>\n<td style=\"text-align:center\"> 1.1.1 </td> <td style=\"text-align:center\"> 1.2.0 </td>\n</tr>\n<tr>\n<td>\n\n```cpp\nauto tensor = MSTensor::CreateTensor(xxx, xxx, ...);\nauto name = tensor.Name();\n```\n\n</td>\n<td>\n\n```cpp\nauto tensor = MSTensor::CreateTensor(xxx, xxx, ...);\nauto name = tensor->Name();\nMSTensor::DestroyTensorPtr(tensor);\n```\n\n</td>\n</tr>\n</table>\n\n#### New features\n\n##### Python API\n\n- Add SPONGE functions: `mindspore.ops.operations.BondForceWithAtomEnergy`, `mindspore.ops.operations.AngleForceWithAtomEnergy`, `mindspore.ops.operations.DihedralForceWithAtomEnergy`, `mindspore.ops.operations.Dihedral14LJCFForceWithAtomEnergy`, `mindspore.ops.operations.LJForceWithPMEDirectForce`, `mindspore.ops.operations.PMEExcludedForce`, `mindspore.ops.operations.PMEReciprocalForce`,`mindspore.ops.operations.BondEnergy`, `mindspore.ops.operations.AngleEnergy`,`mindspore.ops.operations.DihedralEnergy`, `mindspore.ops.operations.Dihedral14LJEnergy`, `mindspore.ops.operations.Dihedral14CFEnergy`,`mindspore.ops.operations.LJEnergy`, `mindspore.ops.operations.PMEEnergy`. All operators are supported in `GPU`.\n\n#### Deprecations\n\n##### Python API\n\n###### `nn.MatMul` is now deprecated in favor of `ops.matmul` ([!12817](https://gitee.com/mindspore/mindspore/pulls/12817))\n\n[ops.matmul](https://www.mindspore.cn/docs/en/master/api_python/ops/mindspore.ops.matmul.html#mindspore.ops.matmul) follows the API of [numpy.matmul](https://numpy.org/doc/stable/reference/generated/numpy.matmul.html) as closely as possible. As a function interface, [ops.matmul](https://www.mindspore.cn/docs/en/master/api_python/ops/mindspore.ops.matmul.html#mindspore.ops.matmul) is applied without instantiation, as opposed to `nn.MatMul`, which should only be used as a class instance.\n\n<table>\n<tr>\n<td style=\"text-align:center\"> 1.1.1 </td> <td style=\"text-align:center\"> 1.2.0 </td>\n</tr>\n<tr>\n<td>\n\n```python\n>>> import numpy as np\n>>> from mindspore import Tensor, nn\n>>>\n>>> x = Tensor(np.ones((2, 3)).astype(onp.float32)\n>>> y = Tensor(np.ones((3, 4)).astype(onp.float32)\n>>> nn.MatMul()(x, y)\n```\n\n</td>\n<td>\n\n```python\n>>> import numpy as np\n>>> from mindspore import Tensor, ops\n>>>\n>>> x = Tensor(np.ones((2, 3)).astype(onp.float32)\n>>> y = Tensor(np.ones((3, 4)).astype(onp.float32)\n>>> ops.matmul(x, y)\n```\n\n</td>\n</tr>\n</table>\n\n### Bug fixes\n\n#### FrontEnd\n\n- fix the null pointer problem of evaluator in control flow.([!13312](https://gitee.com/mindspore/mindspore/pulls/13312))\n- fix parameter naming conflict bug for CellList and SequentialCell. ([!13260](https://gitee.com/mindspore/mindspore/pulls/13260))\n\n#### Executor\n\n- fix executor pending task not execute in some heterogeneous cases.([!13465](https://gitee.com/mindspore/mindspore/pulls/13465))\n- add passes to support frontend IR unification, including following operations: SliceGrad([!11783](https://gitee.com/mindspore/mindspore/pulls/11783)), ApplyFtrl, ApplyMomentum, ApplyRMSProp, CenteredRMSProp([!11895](https://gitee.com/mindspore/mindspore/pulls/11895)), AvgPoolGrad([!12813](https://gitee.com/mindspore/mindspore/pulls/12813)), BatchNorm([!12115](https://gitee.com/mindspore/mindspore/pulls/12115))\n\n#### Dataset\n\n- Fix getter functions(e.g. GetDatasetSize) terminated abnormally when use python multi-processing. ([!13571](https://gitee.com/mindspore/mindspore/pulls/13571), [!13823](https://gitee.com/mindspore/mindspore/pulls/13823))\n- Fix unclear error log of data augmentation operators. ([!12398](https://gitee.com/mindspore/mindspore/pulls/12398), [!12883](https://gitee.com/mindspore/mindspore/pulls/12883), [!13176](https://gitee.com/mindspore/mindspore/pulls/13176))\n- Fix profiling performs abnormally when sink_size = False, as saving data is later than profiling analysis. ([!13944](https://gitee.com/mindspore/mindspore/pulls/13944))\n\n## MindSpore Lite\n\n### Major Features and Improvements\n\n#### Converter and runtime\n\n1. Support TensorFlow model in Converter except aware-training model.\n2. Add fusion pattern for same horizontal operators in Converter.\n3. Support Jar in x86_64 system for integrating into server with Java backend conveniently.\n4. Provide unified runtime API for developer reusing their code between cloud side and end side.[BETA]\n5. Improve control-flow capabilities continually: Support GRU fusion in Converter; Support weight-quant for control-flow model; Support control-flow model inference with half precision; Support nested control-flow model.[BETA]\n\n#### ARM backend optimization\n\n1. Add NLP dependent float16 operators(like lstm) to enhance inference performance.\n2. Optimize operators: lstm, gru, depthwise.\n3. Add 6 NPU operators(like FullConnection), and fix some bugs about buildIR failed.\n\n#### OpenCL backend\n\n1. Add new ops: add 10+ ops，total 72 ops；\n2. Performance optimization: by memory layout optimize，block tiling，Performance improved by 30% compared to version 1.1 at Adreno GPU.\n3. Initialization time optimization: initialization time improve 100% vs MSLITE Version1.1 by store kernel cache as binary.\n4. Support Java call on Mali or Adreno GPU.\n\n#### Post quantization\n\n1. Support quantization of gather and lstm ops.\n2. Support quantizatizing TF Lite models with sub-graph node.\n3. Add quantiztion strategy to decide quantize ops or not，less accuracy loss and higher compression rate.\n\n#### Training on Device\n\n1. Virtual batching, use mini-batch to minic large batch in theorical with few RAM consumption.\n2. Converter unify, do not compile tod and iod converter separately.\n3. Performance optimization to BWD ops.\n4. TrainLoop with Off-The-Shelf Functionality blocks, like LR scheduler, Loss Monitor, Ckpt Saver, Accuracy Monitor.\n5. Integration of code with Minddata lite.\n6. Support more networks (googlenet, densenet, shufflenetv2, nin, vgg) and operators.\n\n#### Codegen\n\n1. Support 79 ops for the ARM platform and all CMSIS ops for Arm Cortex-M Series.\n2. Multiplatform support, including Android, IoT Devices.\n3. Support offline model weight preprocessing while compiling.\n4. Support offline memory reuse computing for minimum runtime buffer size.\n5. Support kernel register for custom op. Third-party hardware like NNIE can be accessed through it.\n\n### API Change\n\n#### API Incompatible Change\n\n##### C++ API\n\n###### Add header file named lite_types.h for some common data structs. ([!12262](https://gitee.com/mindspore/mindspore/pulls/12262))\n\nPreviously, some common data structs such as `CpuBindMode` and `DeviceType` are in context.h, this may cause cross-dependency between headers. So we create a new header named lite_types.h for some common data structs and move `CpuBindMode` and `DeviceType` from context.h into lite_types.h.\n\n<table>\n<tr>\n<td style=\"text-align:center\"> lite_types.h </td>\n</tr>\n<tr>\n<td>\n\n```cpp\nnamespace mindspore::lite {\n/// \\brief CpuBindMode defined for holding bind cpu strategy argument.\ntypedef enum {\n  NO_BIND,    /**< no bind */\n  HIGHER_CPU, /**< bind higher cpu first */\n  MID_CPU     /**< bind middle cpu first */\n} CpuBindMode;\n\n/// \\brief DeviceType defined for holding user's preferred backend.\ntypedef enum {\n  DT_CPU, /**< CPU device type */\n  DT_GPU, /**< GPU device type */\n  DT_NPU  /**< NPU device type */\n} DeviceType;\n}  // namespace mindspore::lite\n```\n\n</td>\n</tr>\n</table>\n\n###### Add some new interfaces in ms_tensor.h for unified runtime API.([!13515](https://gitee.com/mindspore/mindspore/pulls/13515))\n\nPreviously, users could not create `MSTensor` or modify ``MSTensor, all `MSTensor` are created and managed by framework. However users need to create or modify MSTensor sometimes such as pre-processing input data. So we provide two new interfaces in ms_tensor.h: `CreateTensor` interface for creating `MSTensor` by user and `set_shape` interface for modifying the shape of `MSTensor`.\n\n<table>\n<tr>\n<td style=\"text-align:center\"> CreateTensor </td>\n</tr>\n<tr>\n<td>\n\n```cpp\n/// \\brief Create a MSTensor.\n///\n/// \\return Pointer to an instance of MindSpore Lite MSTensor.\nstatic MSTensor *CreateTensor(const std::string &name, TypeId type, const std::vector<int> &shape, const void *data,\n                                size_t data_len);\n```\n\n</td>\n</tr>\n</table>\n\n<table>\n<tr>\n<td style=\"text-align:center\"> set_shape </td>\n</tr>\n<tr>\n<td>\n\n```cpp\n/// \\brief Set the shape of MSTensor.\nvirtual void set_shape(const std::vector<int> &shape) = 0;\n```\n\n</td>\n</tr>\n</table>\n\nPreviously, users could access to data of `MSTensor` by interface named `MutableData`. However `MutableData` is not only returning data of tensor but also allocating data for tensor if its data is nullptr. So we provide a new interfaces in ms_tensor.h named `data` for returning data of tensor without allocating automatically.\n\n<table>\n<tr>\n<td style=\"text-align:center\"> data </td>\n</tr>\n<tr>\n<td>\n\n```cpp\n/// \\brief Get the pointer of data in MSTensor.\n///\n/// \\note The data pointer can be used to both write and read data in MSTensor. No memory buffer will be\n/// allocated.\n///\n/// \\return the pointer points to data in MSTensor.\nvirtual void *data() = 0;\n```\n\n</td>\n</tr>\n</table>\n\n###### Delete `DimensionSize()` in ms_tensor.h.([!13515](https://gitee.com/mindspore/mindspore/pulls/13515))\n\nThe interface named `DimensionSize` is fuinctionally overlapped with the interface named `shape`. For the simplicity of the interface, we delete `DimensionSize` and recommend users to use the new interface named `shape` instead.\n\n<table>\n<tr>\n<td style=\"text-align:center\"> DimensionSize() </td>\n</tr>\n<tr>\n<td>\n\n```cpp\n/// \\brief Get size of the dimension of the MindSpore Lite MSTensor index by the parameter index.\n///\n/// \\param[in] index Define index of dimension returned.\n///\n/// \\return Size of dimension of the MindSpore Lite MSTensor.\nvirtual int DimensionSize(size_t index) const = 0;\n```\n\n</td>\n</tr>\n</table>\n\n###### Move allocator from namespace mindspore::lite to namespace lite for unified runtime API.([!13515](https://gitee.com/mindspore/mindspore/pulls/13515))\n\nPreviously, class `Allocator` is in namespace mindspore::lite. Considering unified allocator interface for unified runtime API, we move `Allocator` to namespace mindspore.\n\n<table>\n<tr>\n<td style=\"text-align:center\"> 1.1.0 </td> <td style=\"text-align:center\"> 1.2.0 </td>\n</tr>\n<tr>\n<td>\n\n```cpp\nnamespace mindspore::lite {\n/// \\brief Allocator defined a memory pool for malloc memory and free memory dynamically.\n///\n/// \\note List public class and interface for reference.\nclass Allocator;\n}\n```\n\n</td>\n<td>\n\n```cpp\nnamespace mindspore {\n/// \\brief Allocator defined a memory pool for malloc memory and free memory dynamically.\n///\n/// \\note List public class and interface for reference.\nclass Allocator;\n}\n```\n\n</td>\n</tr>\n</table>\n\n### Bug fixes\n\n1. Fix the bug that the array in kernel registrar is not initialized.\n2. Fix segment fault caused by releasing of OpParameter in Crop kernel in mistake.\n3. Fix the bug that the MINDIR aware-training model is finally interpreted as weight-quant model.\n\n## Contributors\n\nThanks goes to these wonderful people:\n\nAdel, AGroupofProbiotocs, anthonyaje, anzhengqi, askmiao, baihuawei, baiyangfan, bai-yangfan, bingyaweng, BowenK, buxue, caifubi, CaoJian, caojian05, caozhou, Cathy, changzherui, chenbo116, chenfei, chengxianbin, chenhaozhe, chenjianping, chenzomi, chenzupeng, chujinjin, cj, cjh9368, Corleone, damon0626, danish, Danish, davidmc, dayschan, doitH, dong-li001, eric, Eric, fary86, fuzhiye, Gaoxiong, GAO_HYP_XYJ, gengdongjie, Gogery, gongdaguo, gray0v0, gukecai, guoqi, gzhcv, hangq, hanhuifeng2020, Harshvardhan, He, heleiwang, hexia, Hoai, HuangBingjian, huangdongrun, huanghui, huangxinjing, huqi, huzhifeng, hwjiaorui, Islam Amin, Jesse, , Jiabin Liu, jianghui58, jiangzhiwen, Jiaqi, jin-xiulang, jinyaohui, jjfeing, John, Jonathan, jonyguo, JulyAi, jzg, kai00, kingfo, kingxian, kpy, kswang, laiyongqiang, leonwanghui, Li, liangchenghui, liangzelang, lichen_101010, lichenever, lihongkang, lilei, limingqi107, ling, linqingke, Lin Xh, liubuyu, liuwenhao4, liuxiao78, liuxiao93, liuyang_655, liuzhongkai, Lixia, lixian, liyanliu, liyong, lizhenyu, luopengting, luoyang, lvchangquan, lvliang, lz, mahdi, Mahdi, maning202007, Margaret_wangrui, mayang, mengyuanli, Ming_blue, nhussain, ougongchang, panfengfeng, panyifeng, Payne, Peilin, peixu_ren, Pengyongrong, qianlong, qianjiahong, r1chardf1d0, riemann_penn, rmdyh, Sheng, shenwei41, simson, Simson, Su, sunsuodong, tao_yunhao, tinazhang, VectorSL, , Wan, wandongdong, wangdongxu, wangmin, wangnan39@huawei.com, wangyue01, wangzhe, wanyiming, Wei, wenchunjiang, wilfChen, WilliamLian, wsc, wudenggang, wukesong, wuweikang, wuxuejian, Xiaoda, xiefangqi, xinyunfan, xuanyue, xulei2020, Xun, xuyongfei, yanghaitao, yanghaitao1, yanghaoran, YangLuo, yangruoqi713, yankai, yanzhenxiang2020, yao_yf, yepei6, yeyunpeng, Yi, yoni, yoonlee666, yuchaojie, yujianfeng, yuximiao, zengzitao, Zhang, zhanghaibo5@huawei.com, zhanghuiyao, zhanghui_china, zhangxinfeng3, zhangyihui, zhangz0911gm, zhanke, zhanyuan, zhaodezan, zhaojichen, zhaoting, zhaozhenlong, zhengjun10, zhiqwang, zhoufeng, zhousiyi, zhouyaqiang, zhouyifengCode, Zichun, Zirui, Ziyan, zjun, ZPaC, zymaa.\n\nContributions of any kind are welcome!\n\n# MindSpore 1.1.1 Release Notes\n\n## MindSpore\n\n### Major Features and Improvements\n\n#### NewModels\n\n- [STABLE] BGCF: a Bayesian Graph Collaborative Filtering(BGCF) framework used to model the uncertainty in the user-item interaction graph and thus recommend accurate and diverse items on Amazon recommendation dataset.(Ascend)\n- [STABLE] GRU: a recurrent neural network architecture like the LSTM(Long-Short Term Memory) on Multi30K dataset.(Ascend)\n- [STABLE] FastText: a simple and efficient text classification algorithm on AG's news topic classification dataset, DBPedia Ontology classification dataset and Yelp Review Polarity dataset.(Ascend)\n- [STABLE] LSTM: a recurrent neural network architecture used to learn word vectors for sentiment analysis on aclImdb_v1 dataset.(Ascend)\n- [STABLE] SimplePoseNet: a convolution-based neural network for the task of human pose estimation and tracking on COCO2017 dataset.(Ascend)\n\n#### FrontEnd\n\n- [BETA] Support Tensor Fancy Index Getitem with tuple and list. (Ascend/GPU/CPU)\n\n### Backwards Incompatible Change\n\n#### Python API\n\n##### `ops.AvgPool`, `ops.MaxPool`, `ops.MaxPoolWithArgmax` change attr name from 'ksize', 'padding' to 'kernel_size', 'pad_mode' ([!11350](https://gitee.com/mindspore/mindspore/pulls/11350))\n\nPreviously the kernel size and pad mode attrs of pooling ops are named \"ksize\" and \"padding\", which is a little puzzling and inconsistent with convolution ops. So they are rename to \"kernel_size\" and \"pad_mode\".\n\n<table>\n<tr>\n<td style=\"text-align:center\"> 1.1.0 </td> <td style=\"text-align:center\"> 1.1.1 </td>\n</tr>\n<tr>\n<td>\n\n```python\n>>> import mindspore.ops as ops\n>>>\n>>> avg_pool = ops.AvgPool(ksize=2, padding='same')\n>>> max_pool = ops.MaxPool(ksize=2, padding='same')\n>>> max_pool_with_argmax = ops.MaxPoolWithArgmax(ksize=2, padding='same')\n```\n\n</td>\n<td>\n\n```python\n>>> import mindspore.ops as ops\n>>>\n>>> avg_pool = ops.AvgPool(kernel_size=2, pad_mode='same')\n>>> max_pool = ops.MaxPool(kernel_size=2, pad_mode='same')\n>>> max_pool_with_argmax = ops.MaxPoolWithArgmax(kernel_size=2, pad_mode='same')\n```\n\n</td>\n</tr>\n</table>\n\n##### `ops.TensorAdd`, change API name to `ops.Add` ([!11568](https://gitee.com/mindspore/mindspore/pulls/11568))\n\nThe operator name TensorAdd is not standardized, it is changed to Add. The old interface can be used continuously, but will be deleted in subsequent versions, it is recommended to use and switch to the latest interface.\n\n<table>\n<tr>\n<td style=\"text-align:center\"> 1.1.0 </td> <td style=\"text-align:center\"> 1.1.1 </td>\n</tr>\n<tr>\n<td>\n\n```python\n>>> import mindspore.ops as ops\n>>>\n>>> add = ops.TensorAdd()\n```\n\n</td>\n<td>\n\n```python\n>>> import mindspore.ops as ops\n>>>\n>>> add = ops.Add()\n```\n\n</td>\n</tr>\n</table>\n\n##### `ops.Gelu`, `ops.GeluGrad`, `ops.FastGelu`, `ops.FastGeluGrad`, change API name to `ops.GeLU`, `ops.GeLUGrad`, `ops.FastGeLU`, `ops.FastGeLUGrad` ([!11603](https://gitee.com/mindspore/mindspore/pulls/11603))\n\nGelu, GeluGrad, FastGelu, and FastGeluGrad names are unified into ReLU naming rules, \"lu\" is changed to the uppercase \"LU\". The old interface can be used continuously, but will be deleted in subsequent versions, it is recommended to use and switch to the latest interface.\n\n<table>\n<tr>\n<td style=\"text-align:center\"> 1.1.0 </td> <td style=\"text-align:center\"> 1.1.1 </td>\n</tr>\n<tr>\n<td>\n\n```python\n>>> import mindspore.ops as ops\n>>>\n>>> gelu = ops.Gelu()\n>>> gelu_grad = ops.GeluGrad()\n>>> fast_gelu = ops.FastGelu()\n>>> fast_gelu_grad = ops.FastGeluGrad()\n```\n\n</td>\n<td>\n\n```python\n>>> import mindspore.ops as ops\n>>>\n>>> gelu = ops.GeLU()\n>>> gelu_grad = ops.GeLUGrad()\n>>> fast_gelu = ops.FastGeLU()\n>>> fast_gelu_grad = ops.FastGeLUGrad()\n```\n\n</td>\n</tr>\n</table>\n\n##### `ops.GatherV2`, change API name to `ops.Gather` ([!11713](https://gitee.com/mindspore/mindspore/pulls/11713))\n\nGatherV2 is changed to Gather. The old interface can be used continuously, but will be deleted in subsequent versions, it is recommended to use and switch to the latest interface.\n\n<table>\n<tr>\n<td style=\"text-align:center\"> 1.1.0 </td> <td style=\"text-align:center\"> 1.1.1 </td>\n</tr>\n<tr>\n<td>\n\n```python\n>>> import mindspore.ops as ops\n>>>\n>>> gather = ops.GatherV2()\n```\n\n</td>\n<td>\n\n```python\n>>> import mindspore.ops as ops\n>>>\n>>> gather = ops.Gather()\n```\n\n</td>\n</tr>\n</table>\n\n##### `ops.Pack`、`ops.Unpack`, change API name to `ops.Stack`、`ops.Unstack` ([!11828](https://gitee.com/mindspore/mindspore/pulls/11828))\n\nPack is changed to Stack, and Unpack is changed to Unstack. The old interface can be used continuously, but will be deleted in subsequent versions, it is recommended to use and switch to the latest interface.\n\n<table>\n<tr>\n<td style=\"text-align:center\"> 1.1.0 </td> <td style=\"text-align:center\"> 1.1.1 </td>\n</tr>\n<tr>\n<td>\n\n```python\n>>> import mindspore.ops as ops\n>>>\n>>> pack= ops.Pack()\n>>> unpack= ops.Unpack()\n```\n\n</td>\n<td>\n\n```python\n>>> import mindspore.ops as ops\n>>>\n>>> stack= ops.Stack()\n>>> unstack= ops.Unstack()\n```\n\n</td>\n</tr>\n</table>\n\n##### `ops.ControlDepend`, add deprecated to ControlDepend ([!11844](https://gitee.com/mindspore/mindspore/pulls/11844))\n\nControlDepend is deprecated and will be removed in a future version, use Depend instead.\n\n<table>\n<tr>\n<td style=\"text-align:center\"> 1.1.0 </td> <td style=\"text-align:center\"> 1.1.1 </td>\n</tr>\n<tr>\n<td>\n\n```pythonNote:\nNote:\n    This operation does not work in `PYNATIVE_MODE`.\n```\n\n</td>\n<td>\n\n```python\nNote:\n        This operation does not work in `PYNATIVE_MODE`.\n        `ControlDepend` is deprecated from version 1.1 and will be removed in a future version, use `Depend` instead.\n```\n\n</td>\n</tr>\n</table>\n\n##### `ops.Depend`, add operator description and use case ([!11815](https://gitee.com/mindspore/mindspore/pulls/11815)), ([!11879](https://gitee.com/mindspore/mindspore/pulls/11879))\n\nSince the ControlDepend operator will be deprecated from version 1.2, it is recommended to use the Depend operator instead.\n\n<table>\n<tr>\n<td style=\"text-align:center\"> 1.1.0 </td> <td style=\"text-align:center\"> 1.1.1 </td>\n</tr>\n<tr>\n<td>\n\n```python\nDepend is used for processing side-effect operations.\n\nInputs:\n    - **value** (Tensor) - the real value to return for depend operator.\n    - **expr** (Expression) - the expression to execute with no outputs.\n\nOutputs:\n    Tensor, the value passed by last operator.\n\nSupported Platforms:\n    ``Ascend`` ``GPU`` ``CPU``\n```\n\n</td>\n<td>\n\n```python\nDepend is used for processing dependency operations.\n\nIn some side-effect scenarios, we need to ensure the execution order of operators.\nIn order to ensure that operator A is executed before operator B, it is recommended\nto insert the Depend operator between operators A and B.\n\nPreviously, the ControlDepend operator was used to control the execution order.\nSince the ControlDepend operator will be deprecated from version 1.2, it is\nrecommended to use the Depend operator instead. The replacement method is as follows::\n\n    a = A(x)                --->        a = A(x)\n    b = B(y)                --->        y = Depend(y, a)\n    ControlDepend(a, b)     --->        b = B(y)\n\nInputs:\n    - **value** (Tensor) - the real value to return for depend operator.\n    - **expr** (Expression) - the expression to execute with no outputs.\n\nOutputs:\n    Tensor, the value passed by last operator.\n\nSupported Platforms:\n    ``Ascend`` ``GPU`` ``CPU``\n\nExamples:\n    >>> import numpy as np\n    >>> import mindspore\n    >>> import mindspore.nn as nn\n    >>> import mindspore.ops.operations as P\n    >>> from mindspore import Tensor\n    >>> class Net(nn.Cell):\n    ...     def __init__(self):\n    ...         super(Net, self).__init__()\n    ...         self.softmax = P.Softmax()\n    ...         self.depend = P.Depend()\n    ...\n    ...     def construct(self, x, y):\n    ...         mul = x - y\n    ...         y = self.depend(y, mul)\n    ...         ret = self.softmax(y)\n    ...         return ret\n    ...\n    >>> x = Tensor(np.ones([4, 5]), dtype=mindspore.float32)\n    >>> y = Tensor(np.ones([4, 5]), dtype=mindspore.float32)\n    >>> net = Net()\n    >>> output = net(x, y)\n    >>> print(output)\n    [[0.2 0.2 0.2 0.2 0.2]\n     [0.2 0.2 0.2 0.2 0.2]\n     [0.2 0.2 0.2 0.2 0.2]\n     [0.2 0.2 0.2 0.2 0.2]]\n```\n\n</td>\n</tr>\n</table>\n\n#### C++ API\n\n##### change namespace from `mindspore::api` to `mindspore` ([!11574](https://gitee.com/mindspore/mindspore/pulls/11574))\n\n<table>\n<tr>\n<td style=\"text-align:center\"> 1.1.0 </td> <td style=\"text-align:center\"> 1.1.1 </td>\n</tr>\n<tr>\n<td>\n\n```c++\nnamespace ms = mindspore::api;\n```\n\n</td>\n<td>\n\n```c++\nnamespace ms = mindspore;\n```\n\n</td>\n</tr>\n</table>\n\n##### `Context` ([!11574](https://gitee.com/mindspore/mindspore/pulls/11574))\n\n<table>\n<tr>\n<td style=\"text-align:center\"> 1.1.0 </td> <td style=\"text-align:center\"> 1.1.1 </td>\n</tr>\n<tr>\n<td>\n\n```c++\nms::Context::Instance().SetDeviceTarget(ms::kDeviceTypeAscend310).SetDeviceID(0);\n```\n\n</td>\n<td>\n\n```c++\nms::GlobalContext::SetGlobalDeviceTarget(ms::kDeviceTypeAscend310);\nms::GlobalContext::SetGlobalDeviceID(0);\n```\n\n</td>\n</tr>\n</table>\n\n##### rename `Tensor` to `MSTensor` ([!11574](https://gitee.com/mindspore/mindspore/pulls/11574))\n\n<table>\n<tr>\n<td style=\"text-align:center\"> 1.1.0 </td> <td style=\"text-align:center\"> 1.1.1 </td>\n</tr>\n<tr>\n<td>\n\n```c++\nms::Tensor a;\n```\n\n</td>\n<td>\n\n```c++\nms::MSTensor a;\n```\n\n</td>\n</tr>\n</table>\n\n##### `Model` move setting of model options from `Build` to ctor `Model` ([!11574](https://gitee.com/mindspore/mindspore/pulls/11574))\n\n<table>\n<tr>\n<td style=\"text-align:center\"> 1.1.0 </td> <td style=\"text-align:center\"> 1.1.1 </td>\n</tr>\n<tr>\n<td>\n\n```c++\nms::Model model(graph_cell);\nmodel.Build(model_options);\n```\n\n</td>\n<td>\n\n```c++\nms::Model model(graph_cell, model_context);\nmodel.Build();\n```\n\n</td>\n</tr>\n</table>\n\n##### `Model` modify `GetInputsInfo`, `GetOutputsInfo` to `GetInputs`, `GetOutputs` ([!11574](https://gitee.com/mindspore/mindspore/pulls/11574))\n\n<table>\n<tr>\n<td style=\"text-align:center\"> 1.1.0 </td> <td style=\"text-align:center\"> 1.1.1 </td>\n</tr>\n<tr>\n<td>\n\n```c++\nstd::vector<std::string> names;\nstd::vector<ms::DataType> types;\nstd::vector<std::vector<int64_t>> shapes;\nstd::vector<size_t> mem_sizes;\nmodel.GetInputsInfo(&names, &types, &shapes, &mem_sizes);\nstd::cout << \"Input 0 name: \" << names[0] << std::endl;\n```\n\n</td>\n<td>\n\n```c++\nauto inputs = model.GetInputs();\nstd::cout << \"Input 0 name: \" << inputs[0].Name() << std::endl;\n```\n\n</td>\n</tr>\n</table>\n\n##### `Model` modify `Predict` parameters type from `Buffer` to `MSTensor` ([!11574](https://gitee.com/mindspore/mindspore/pulls/11574))\n\n<table>\n<tr>\n<td style=\"text-align:center\"> 1.1.0 </td> <td style=\"text-align:center\"> 1.1.1 </td>\n</tr>\n<tr>\n<td>\n\n```c++\nstd::vector<ms::Buffer> inputs;\nstd::vector<ms::Buffer> outputs;\nmodel.Predict(inputs, &outputs);\n```\n\n</td>\n<td>\n\n```c++\nstd::vector<ms::MSTensor> inputs;\nstd::vector<ms::MSTensor> outputs;\nmodel.Predict(inputs, &outputs);\n```\n\n</td>\n</tr>\n</table>\n\n### Deprecations\n\n#### Python API\n\n##### `ops.SpaceToBatch`, `ops.BatchToSpace` are deprecated in favor of `ops.SpaceToBatchND`, `ops.BatchToSpaceND`([!11527](https://gitee.com/mindspore/mindspore/pulls/11527))\n\nThe `ops.SpaceToBatchND`, `ops.BatchToSpaceND` are more general and have same behavior as `ops.SpaceToBatch`, `ops.BatchToSpace` when `block_shape` is a int.\n\n##### `ops.DepthwiseConv2dNative` is deprecated in favor of `nn.Conv2D`([!11702](https://gitee.com/mindspore/mindspore/pulls/11702))\n\nThe `ops.DepthwiseConv2dNative` is only supported by Ascend, it is recommended to directly use `nn.Conv2D`. If `group` is equal to `in_ channels` and `out_channels`, the 2D convolution layer is also a 2D depthwise convolution layer.\n\n## Contributors\n\nThanks goes to these wonderful people:\n\nAdel, AGroupofProbiotocs, anthonyaje, anzhengqi, askmiao, baihuawei, baiyangfan, bai-yangfan, bingyaweng, BowenK, buxue, caifubi, CaoJian, caojian05, caozhou, Cathy, changzherui, chenbo116, chenfei, chengxianbin, chenhaozhe, chenjianping, chenzomi, chenzupeng, chujinjin, cj, cjh9368, Corleone, damon0626, danish, Danish, davidmc, dayschan, doitH, eric, Eric, fary86, fuzhiye, Gaoxiong, gengdongjie, Gogery, gongdaguo, gray0v0, gukecai, guoqi, gzhcv, hangq, hanhuifeng2020, Harshvardhan, He, heleiwang, hexia, Hoai, HuangBingjian, huangdongrun, huanghui, huangxinjing, huqi, huzhifeng, hwjiaorui, Jesse, jianghui58, jiangzhiwen, Jiaqi, jin-xiulang, jinyaohui, jjfeing, John, Jonathan, jonyguo, JulyAi, jzg, kai00, kingfo, kingxian, kpy, kswang, laiyongqiang, leonwanghui, Li, liangchenghui, liangzelang, lichen_101010, lichenever, lihongkang, lilei, limingqi107, ling, linqingke, liubuyu, liuwenhao4, liuxiao78, liuxiao93, liuyang_655, liuzhongkai, Lixia, lixian, liyanliu, liyong, lizhenyu, luoyang, lvchangquan, lvliang, lz, mahdi, Mahdi, maning202007, Margaret_wangrui, mayang, mengyuanli, nhussain, ougongchang, panfengfeng, panyifeng, Payne, Peilin, peixu_ren, Pengyongrong, qianlong, r1chardf1d0, riemann_penn, rmdyh, Sheng, shenwei41, simson, Simson, Su, sunsuodong, tao_yunhao, tinazhang, VectorSL, , Wan, wandongdong, wangdongxu, wangmin, wangnan39@huawei.com, wangyue01, wangzhe, wanyiming, Wei, wenchunjiang, wilfChen, WilliamLian, wsc, wukesong, wuweikang, wuxuejian, Xiaoda, xiefangqi, xinyunfan, xuanyue, xulei2020, Xun, xuyongfei, yanghaitao, yanghaitao1, yanghaoran, YangLuo, yangruoqi713, yankai, yanzhenxiang2020, yao_yf, yepei6, yeyunpeng, Yi, yoni, yoonlee666, yuchaojie, yujianfeng, yuximiao, zengzitao, Zhang, zhanghaibo5@huawei.com, zhanghuiyao, zhangyihui, zhangz0911gm, zhanke, zhanyuan, zhaodezan, zhaojichen, zhaoting, zhaozhenlong, zhengjun10, zhoufeng, zhousiyi, zhouyaqiang, zhouyifengCode, Zichun, Zirui, Ziyan, zjun, ZPaC, zymaa\n\nContributions of any kind are welcome!\n\n# MindSpore 1.1.0 Release Notes\n\n## MindSpore\n\n### Major Features and Improvements\n\n#### NewModels\n\n- [STABLE] GNMT v2: similar to the model described in Google's Neural Machine Translation System: Bridging the Gap between Human and Machine Translation, which is mainly used for corpus translation, on WMT Englis-German dataset.(Ascend)\n- [STABLE] MaskRCNN: a conceptually simple, flexible, and general framework for object instance segmentation on COCO2017 dataset.(Ascend)\n- [STABLE] YOLOv4: a state-of-the-art detector which is faster and more accurate than all available alternative detectors on MS COCO dataset.(Ascend)\n- [STABLE] Openpose: proposes a bottom-up human attitude estimation algorithm using Part Affinity Fields on COCO2017 dataset.(Ascend)\n- [STABLE] CNN-CTC: proposes three major contributions to addresses scene text recognition (STR) on MJSynth and SynthText dataset.(Ascend)\n- [STABLE] CenterFace: a practical anchor-free face detection and alignment method for edge devices on WiderFace dataset.(Ascend)\n- [STABLE] ShuffleNetV2:  a much faster and more accurate network than the previous networks on ImageNet 2012 dataset.(GPU)\n- [STABLE] EfficientNet-B0: a new scaling method that uniformly scales all dimensions of depth/width/resolution using a simple yet highly effective compound coefficient on ImageNet 2012 dataset.(GPU)\n- [BETA] SSD-GhostNet: based on an Ghost module structure which generate more features from cheap operations on Oxford-IIIT Pet dataset.(Ascend)\n- [BETA] DS-CNN:  Depthwise separable convolutional neural network on Speech commands dataset.(Ascend)\n- [BETA] DeepPotentialH2O: A neural network model for molecular dynamics simulations. (Ascend)\n- [BETA] GOMO: A classical numerical method called GOMO for ocean simulation. (GPU)\n\n#### FrontEnd\n\n- [STABLE] Refactor the MINDIR to support 310 inference(Ascend).\n- [STABLE] The execution backend of sparse operations in optimizer can be set through 'target'. (Ascend/GPU/CPU)\n- [STABLE] Support saving specified network to checkpoint and filtering parameters according to prefix when load checkpoint. (Ascend/GPU/CPU)\n- [STABLE] Allow users choose whether to load parameter into network strictly.(Ascend/GPU/CPU)\n- [STABLE] Before training, in graph mode, in order to have the same network initialization parameter values ​​for all devices, broadcast the parameters on device 0 to other devices. (Ascend/GPU)\n- [STABLE] Support if by if of control flow subgraph. (Ascend/GPU)\n- [STABLE] Support the judgment that whether a tensor is in a list. (Ascend/GPU/CPU)\n- [STABLE] Support to get a value by using the corresponding key in a dictionary in the network; Support to get keys and values of a dictionary in the network. (Ascend/GPU/CPU)\n- [STABLE] Support Tensor in enumerate. (Ascend/GPU/CPU)\n- [STABLE] Support multilevel index assignment. (Ascend/GPU/CPU)\n- [STABLE] Support the 'expand_as','view','abs','mean' method of Tensor. (Ascend/GPU/CPU)\n- [STABLE] Support ResizeBilinear operation transfer ratio. (Ascend)\n- [STABLE] nn.Matmul supports matrix-vector product and  batched matrix multiply. (Ascend/GPU)\n- [STABLE] nn.Dense supports input tensor whose dimension can be greater than 2. (Ascend/GPU)\n- [BETA] Support higher order differentiation for partial operators.(CPU/GPU/Ascend)\n- [STABLE] Support Tensor Augassign.(Ascend/GPU)\n- [BETA] Support 22 numpy native interfaces.\n\n#### Auto Parallel\n\n- [STABLE] Support parallel optimizer with weight shard. (Ascend/GPU)\n- [STABLE] Support distributed operators: element-wise series, UnsortedSegmentSum, UnsortedSegmentMin, Split, BroadcastTo and Unique etc. (Ascend/GPU)\n- [STABLE] Support distributed model prediction. (Ascend/GPU)\n- [STABLE] Support auto mixed precision level \"O2\" in auto and semi auto parallel mode. (Ascend/GPU)\n- [STABLE] Add MultiFieldEmbeddingLookup high-level interface. (Ascend/GPU)\n\n#### Executor\n\n- [STABLE] ResNet50 performance optimize. (GPU)\n- [STABLE] Support modelzoo net in PyNative mode(Ascend 29, GPU 23, CPU 2).(Ascend/GPU/CPU)\n- [STABLE] Support PyNative mode on CPU.(CPU)\n- [STABLE] Optimize performance in PyNative mode.(Ascend/GPU/CPU)\n- [STABLE] Support Safe Optimized Memory Allocation Solver (SOMAS) on Ascend to improve the memory-reuse, the batch size of Bert large model (128 sequence length) is increased from 160 to 208.(Ascend)\n- [BETA] Support second order differentiation in PyNative mode.(Ascend/GPU)\n- [DEMO] Add distributed trainning in PyNative mode.(Ascend/GPU)\n\n#### MDP\n\n- [STABLE]  Add new operators for Ascend and GPU: IGamma, LGamma, DiGamma;\n- [STABLE]  Add new distributions for Ascend and GPU: LogNormal, and Logistic;\n- [BETA]  Add new distributions for Ascend only: Gumbel, Cauchy, Gamma, Beta, and Poisson; Add Categorical distribution for GPU;\n- [STABLE]  Add new bijectors for Ascend and GPU: GumbelCDF, Invert;\n- [STABLE]  Add Bayesian layer realized by local reparameterization method for Ascend and GPU;\n- [STABLE]  Add Anomaly Detection Toolbox based on VAE for Ascend and GPU.\n\n#### DataSet\n\n- [STABLE] Support single node multi-p distributed cache data sharing\n- [STABLE] Support GPU profiling with data processing\n- [STABLE] Support YOLOV3 dynamic shape in sink mode with dataset\n- [STABLE] Support unique processing in the data processing pipeline\n- [STABLE] Python layer parameter verification error information unified\n\n### API Change\n\n#### Backwards Incompatible Change\n\n##### Python API\n\n###### Delete shape and dtype of class Initializer ([!7373](https://gitee.com/mindspore/mindspore/pulls/7373/files))\n\nDelete shape and dtype attributes of Initializer class.\n\n###### Modify the return type of initializer ([!7373](https://gitee.com/mindspore/mindspore/pulls/7373/files))\n\nPreviously, the return type of initializer function may be string, number, instance of class Tensor or subclass of class Initializer.\n\nAfter modification, initializer function will return instance of class MetaTensor, class Tensor or subclass of class Initializer.\n\nNoted that the MetaTensor is forbidden to initialize parameters, so we recommend that use str, number or subclass of Initializer for parameters initialization rather than the initializer functions.\n\n<table>\n<tr>\n<td style=\"text-align:center\"> 1.0.1 </td> <td style=\"text-align:center\"> 1.1.0 </td>\n</tr>\n<tr>\n<td>\n\n```python\n>>> import mindspore.nn as nn\n>>> from mindspore.common import initializer\n>>> from mindspore import dtype as mstype\n>>>\n>>> def conv3x3(in_channels, out_channels)\n>>>   weight = initializer('XavierUniform', shape=(3, 2, 32, 32), dtype=mstype.float32)\n>>>   return nn.Conv2d(in_channels, out_channels, weight_init=weight, has_bias=False, pad_mode=\"same\")\n```\n\n</td>\n<td>\n\n```python\n>>> import mindspore.nn as nn\n>>> from mindspore.common.initializer import XavierUniform\n>>>\n>>> #1) using string\n>>> def conv3x3(in_channels, out_channels)\n>>>   return nn.Conv2d(in_channels, out_channels, weight_init='XavierUniform', has_bias=False, pad_mode=\"same\")\n>>>\n>>> #2) using subclass of class Initializer\n>>> def conv3x3(in_channels, out_channels)\n>>>   return nn.Conv2d(in_channels, out_channels, weight_init=XavierUniform(), has_bias=False, pad_mode=\"same\")\n```\n\n</td>\n</tr>\n</table>\n\nAdvantages:\nAfter modification, we can use the same instance of Initializer to initialize parameters of different shapes, which was not allowed before.\n\n<table>\n<tr>\n<td style=\"text-align:center\"> 1.0.1 </td> <td style=\"text-align:center\"> 1.1.0 </td>\n</tr>\n<tr>\n<td>\n\n```python\n>>> import mindspore.nn as nn\n>>> from mindspore.common import initializer\n>>> from mindspore.common.initializer import XavierUniform\n>>>\n>>> weight_init_1 = XavierUniform(gain=1.1)\n>>> conv1 = nn.Conv2d(3, 6, weight_init=weight_init_1)\n>>> weight_init_2 = XavierUniform(gain=1.1)\n>>> conv2 = nn.Conv2d(6, 10, weight_init=weight_init_2)\n```\n\n</td>\n<td>\n\n```python\n>>> import mindspore.nn as nn\n>>> from mindspore.common import initializer\n>>> from mindspore.common.initializer import XavierUniform\n>>>\n>>> weight_init = XavierUniform(gain=1.1)\n>>> conv1 = nn.Conv2d(3, 6, weight_init=weight_init)\n>>> conv2 = nn.Conv2d(6, 10, weight_init=weight_init)\n```\n\n</td>\n</tr>\n</table>\n\n###### Modify get_seed function ([!7429](https://gitee.com/mindspore/mindspore/pulls/7429/files))\n\nModify get_seed function implementation\n\nPreviously, if seed is not set, the value of seed is default, parameters initialized by the normal function are the same every time.\n\nAfter modification, if seed is not set, the value of seed is generated randomly, the initialized parameters change according to the random seed.\n\nIf you want to fix the initial value of parameters, we suggest to set seed.\n\n```python\n>>> from mindspore.common import set_seed\n>>> set_seed(1)\n```\n\n###### `nn.LinSpace` ([!9494](https://gitee.com/mindspore/mindspore/pulls/9494)) has been removed and modify `ops.LinSpace` ([!8920](https://gitee.com/mindspore/mindspore/pulls/8920))\n\nThe `nn.LinSpace` interface only support passing the value by args previously. For the convenience, we provided enhancive `ops.LinSpace` interface, which support passing the value by the inputs at the latest version. So there is no need for `nn.LinSpace`.\n\n<table>\n<tr>\n<td style=\"text-align:center\"> 1.0.1 </td> <td style=\"text-align:center\"> 1.1.0 </td>\n</tr>\n<tr>\n<td>\n\n```python\n>>> from mindspore import nn\n>>>\n>>> start = 1\n>>> stop = 10\n>>> num = 5\n>>> linspace = nn.LinSpace(start, stop, num)\n>>> output = linspace()\n```\n\n</td>\n<td>\n\n```python\n>>> import mindspore\n>>> from mindspore import Tensor\n>>> from mindspore import ops\n>>>\n>>> linspace = ops.LinSpace()\n>>> start = Tensor(1, mindspore.float32)\n>>> stop = Tensor(10, mindspore.float32)\n>>> num = 5\n>>> output = linspace(start, stop, num)\n```\n\n</td>\n</tr>\n</table>\n\n###### Parts of `Optimizer` add target interface ([!6760](https://gitee.com/mindspore/mindspore/pulls/6760/files))\n\nThe usage of the sparse optimizer is changed.\n\nThe target interface is used to set the execution backend of the sparse operator.\n\nThe add_primitive_attr interface is no longer allowed.\n\nThe following optimizers add the target interface:  Adam, FTRL, LazyAdam, ProximalAdagrad\n\n<table>\n<tr>\n<td style=\"text-align:center\"> 1.0.1 </td> <td style=\"text-align:center\"> 1.1.0 </td>\n</tr>\n<tr>\n<td>\n\n```python\n>>> from mindspore.nn import Adam\n>>>\n>>> net = LeNet5()\n>>> optimizer = Adam(filter(lambda x: x.requires_grad, net.get_parameters()))\n>>> optimizer.sparse_opt.set_device(\"CPU\")\n```\n\n</td>\n<td>\n\n```python\n>>> from mindspore.nn import Adam\n>>>\n>>> net = LeNet5()\n>>> optimizer = Adam(filter(lambda x: x.requires_grad, net.get_parameters()))\n>>> optimizer.target = 'CPU'\n```\n\n</td>\n</tr>\n</table>\n\n###### `export` Modify the input parameters and export's file name ([!7385](https://gitee.com/mindspore/mindspore/pulls/7385)， [!9057](https://gitee.com/mindspore/mindspore/pulls/9057/files))\n\nExport the MindSpore prediction model to a file in the specified format.\n\nThe reference includes: `net`, `*inputs`, `file_name`, `file_format`, `**kwargs`.\n\nInput parameters can be input according to specific export requirements.\n\nAdd the file name extension based on the format.\n\n<table>\n<tr>\n<td style=\"text-align:center\"> 1.0.1 </td> <td style=\"text-align:center\"> 1.1.0 </td>\n</tr>\n<tr>\n<td>\n\n```python\n>>> from mindspore.train.quant import quant\n>>>\n>>> network = LeNetQuant()\n>>> inputs = Tensor(np.ones([1, 1, 32, 32]), mindspore.float32)\n>>> quant.export(network, inputs, file_name=\"lenet_quant.mindir\", file_format='MINDIR')\nlenet_quant.mindir\n```\n\n</td>\n<td>\n\n```python\n>>> import mindspore as ms\n>>>\n>>> network = LeNetQuant()\n>>> inputs = Tensor(np.ones([1, 1, 32, 32]), mindspore.float32)\n>>> ms.export(network, inputs, file_name=\"lenet_quant\", file_format='MINDIR', quant_mode='AUTO')\nlenet_quant.mindir\n```\n\n</td>\n</tr>\n</table>\n\n###### `Dense`, `Conv2dBnAct`, `DenseBnAct`, `DenseQuant` support setting the activation attribute as an instance of a class derived from `nn.Cell` or `Primtive` ([!7581](https://gitee.com/mindspore/mindspore/pulls/7581))\n\nactivation (Union[str, Cell, Primitive]): activate function applied to the output of the fully connected layer\n\n<table>\n<tr>\n<td style=\"text-align:center\"> 1.0.1 </td> <td style=\"text-align:center\"> 1.1.0 </td>\n</tr>\n<tr>\n<td>\n\n```python\n>>> import mindspore.nn as nn\n>>>\n>>> dense = nn.Dense(1, 1, activation='relu')\n```\n\n</td>\n<td>\n\n```python\n>>> import mindspore.nn as nn\n>>> import mindspore.ops as ops\n>>>\n>>> dense = nn.Dense(1, 1, activation=nn.ReLU())\n>>> dense = nn.Dense(1, 1, activation=ops.ReLU())\n```\n\n</td>\n</tr>\n</table>\n\n###### `tensor.dim()`, `tensor.size()` has been renamed to `tensor.ndim`, `tensor.size` ([!10175](https://gitee.com/mindspore/mindspore/pulls/10175))\n\nPreviously, tensor.size() and tensor.dim() were used for checking the total number of elements/dimensions in the tensor.\nHowever, from a user's perspective, tensor.size and tensor.ndim (methods -> properties) are better choices, since they follow the numpy naming convention.\n\n<table>\n<tr>\n<td style=\"text-align:center\"> 1.0.1 </td> <td style=\"text-align:center\"> 1.1.0 </td>\n</tr>\n<tr>\n<td>\n\n```python\n>>> from mindspore import Tensor\n>>>\n>>> Tensor((1,2,3)).size()\n>>> Tensor((1,2,3)).dim()\n```\n\n</td>\n<td>\n\n```python\n>>> from mindspore import Tensor\n>>>\n>>> Tensor((1,2,3)).size\n>>> Tensor((1,2,3)).ndim\n```\n\n</td>\n</tr>\n</table>\n\n###### `EmbeddingLookup` add a config in the interface: sparse ([!8202](https://gitee.com/mindspore/mindspore/pulls/8202))\n\nsparse (bool): Using sparse mode. When 'target' is set to 'CPU', 'sparse' has to be true. Default: True.\n\n<table>\n<tr>\n<td style=\"text-align:center\"> 1.0.1 </td> <td style=\"text-align:center\"> 1.1.0 </td>\n</tr>\n<tr>\n<td>\n\n```python\n>>> from mindspore.nn import EmbeddingLookup\n>>>\n>>> input_indices = Tensor(np.array([[1, 0], [3, 2]]), mindspore.int32)\n>>> result = EmbeddingLookup(4,2)(input_indices)\n>>> print(result.shape)\n(2, 2, 2)\n```\n\n</td>\n<td>\n\n```python\n>>> from mindspore.nn import EmbeddingLookup\n>>>\n>>> input_indices = Tensor(np.array([[1, 0], [3, 2]]), mindspore.int32)\n>>> result = EmbeddingLookup(4,2)(input_indices, sparse=False)\n>>> print(result.shape)\n(2, 2, 2)\n```\n\n</td>\n</tr>\n</table>\n\n###### `nn.probability.bijector` change types of attributes from (int, float) to (float, list, numpy.ndarray, Tensor) ([!8191](https://gitee.com/mindspore/mindspore/pulls/8191))\n\nAttributes Type change: (int, float) -> (float, list, numpy.ndarray, Tensor).\nInt type is not supported anymore. Parameters of all bijectors should be type float, list, numpy.ndarray or Tensor.\n\n<table>\n<tr>\n<td style=\"text-align:center\"> 1.0.1 </td> <td style=\"text-align:center\"> 1.1.0 </td>\n</tr>\n<tr>\n<td>\n\n```python\n>>> import mindspore.nn.probability.bijector as msb\n>>>\n>>> power = 2\n>>> bijector = msb.PowerTransform(power=power)\n```\n\n</td>\n<td>\n\n```python\n>>> import mindspore.nn.probability.bijector as msb\n>>>\n>>> power = 2.0\n>>> bijector = msb.PowerTransform(power=power)\n```\n\n</td>\n</tr>\n</table>\n\n###### `nn.probability.bijector.GumbelCDF` remove a attribute in the interface: dtype ([!8191](https://gitee.com/mindspore/mindspore/pulls/8191))\n\ndtype is removed from GumbelCDF and is no longer an argument of the class.\n\n<table>\n<tr>\n<td style=\"text-align:center\"> 1.0.1 </td> <td style=\"text-align:center\"> 1.1.0 </td>\n</tr>\n<tr>\n<td>\n\n```python\n>>> import mindspore.nn.probability.bijector as msb\n>>> from mindspore import dtype as mstype\n>>>\n>>> bijector = msb.GumbelCDF(loc=0.0, scale=1.0, dtype=mstype.float32)\n```\n\n</td>\n<td>\n\n```python\n>>> import mindspore.nn.probability.bijector as msb\n>>>\n>>> bijector = msb.GumbelCDF(loc=0.0, scale=1.0)\n```\n\n</td>\n</tr>\n</table>\n\n###### `nn.layer.combined.Conv2dBnAct`, `nn.layer.combined.DenseBnAct` move from nn.layer.quant to nn.layer.combined ([!8187](https://gitee.com/mindspore/mindspore/pulls/8187))\n\nPreviously Conv2dBnAct and DenseBnAct are in nn.layer.quant, since they are not quant cells, now they are moved to nn.layer.combined. If you import Conv2dBnAct, DenseBnAct from mindspore.nn, then your code doesn't need any change.\n\n<table>\n<tr>\n<td style=\"text-align:center\"> 1.0.1 </td> <td style=\"text-align:center\"> 1.1.0 </td>\n</tr>\n<tr>\n<td>\n\n```python\n>>> from mindspore.nn.layer.quant import Conv2dBnAct, DenseBnAct\n```\n\n</td>\n<td>\n\n```python\n>>> from mindspore.nn import Conv2dBnAct, DenseBnAct\n```\n\n</td>\n</tr>\n</table>\n\n###### `nn.layer.conv.Conv2D`, `nn.layer.quant.Conv2dBnFoldQuant`, `nn.layer.quant.Conv2dBnWithoutFoldQuant` change weight shape when group > 1 in Ascend platform ([!9723](https://gitee.com/mindspore/mindspore/pulls/9723))\n\nIn Ascend platform, if group > 1, the weight shape of Conv2D change from [in_channels//group, out_channels, kernel_size, kernel_size] to [out_channels, in_channels//group, kernel_size, kernel_size]. Previously, checkpoints of the networks are used, which use Conv2D with group > 1, such as MobileNet, can not be directly used now, need to transpose the first and second axis of the weight.\n\n### Bug fixes\n\n#### FrontEnd\n\n- [STABLE] Fix the problem of the cse optimization in the situation of control flow. (Ascend/GPU)\n\n#### Auto Parallel\n\n- [STABLE] Resolve the restriction: input and output layouts of Reshape are restricted in tensor redistribution. (Ascend/GPU)\n- [STABLE] Resolve the restriction: output strategy should be data parallel in model evaluation. (Ascend/GPU)\n\n#### Executor\n\n- [STABLE] Fix fusion operator compilation cache. (Ascend)\n- [STABLE] Fix compilation error of dynamic shape operator. (Ascend)\n- [STABLE] Fix bug of pynative cannot insert transdata of node output when node should be spilted in the backend opt.(Ascend)\n- [STABLE] Fix the bug of TensorMove and memcpy_async merge to one after backend cse pass (Ascend)\n\n#### DataSet\n\n- [STABLE] Fix cache server hang on RequestFreeTag. (Ascend/GPU/CPU)\n- [STABLE] Fix hung when use pyfunc multi-processing. (Ascend/GPU/CPU)\n- [STABLE] Fix add multiple parent nodes to tree node cause core dump. (Ascend/GPU/CPU)\n\n## MindSpore Lite\n\n### Major Features and Improvements\n\n#### Converter and runtime\n\n1. Support dynamic shape in MindSpore Lite Converter.\n2. Optimize sub-graph mechanism by dynamically splitting the entire graph into multiple subgraphs based on the operator supported, backend hardware and user configuration.\n3. Support TensorList and TensorList operators such as TensorListFromTensor, TensorListGetItem and so on.\n4. Support BatchMatMul fusion and LSTM fusion in MindSpore Lite Converter.\n5. Support converting model and run inference on Windows operator system.\n6. Support Model(.ms) visualization on Netron.\n7. Support Tensorflow model in MindSpore Lite Converter\n8. Add 86 converter parsers.\n9. Convert aware training model without user's awareness\n10. Support scalar tensor in MindSpore Lite Converter and Runtime\n11. Support NPU backend on HUAWEI Kirin SoC.[BETA]\n12. Merge timeprofiler into benchmark\n\n#### CPU backend optimization\n\n1. Add 50+ new operators, including new Op type(like Adder, Gru).\n2. Enhanced performance on armv8.2 supported platform. For example, utilizing sdot instruction more efficiently.\n3. Optimize all operators(fp32, fp16, int8) by implementing multi-thread, SIMD tech as much as possible. Model inference time can reduce at least 20% after these optimizations.\n4. Extending to support operators for x86_64 platform based on SSE/AVX instruction set.\n\n#### OpenCL backend\n\n1. Add new ops: add 10+ ops, total 58 ops;\n2. Performance optimization: by memory layout optimize, Winograd Convolution select strategyoptimize, SIMT local size optimize, local cache optimize,  GPU performance improvement up to 20+% vs MSLITE Version1.0\n3. Add Online Graph optimzation: by fusion Convolution/Matmul/Fullconnection and add/mul/pad/reshape, improve performance up to 50+% for some networks;\n4. Add auto tuning: by online tuning in the graph compilation phase, optimize performance up to 10%;\n5. Add weight quant: support weight quant\n6. Add opencl kernel binary cache: improve Initialization time .\n\n#### Post quantization\n\nMindSpore Lite supports both weight quantization and full quantization. Currently, Weights can be quantized into 1 ~ 16 bits according to user configuration. In internal testing, quantization of networks, such as classification, detection, segmentation and transformer are well supported. To ensure high accuracy of quantized models, MindSpore Lite uses a pipeline quantization method. In the first phase, the weight and activation value are quantized using linear quantization methods, such as MIN-MAX. In the second phase, the quantization error is analyzed, and uses statistical methods to compensate loss caused by fp32 quantization to a fixed point such as Int8 to quantized models. The features of Post-training quantization are:\n\n1. perchannel asymmetric quantization for weights, such as MAX_MIN and KMEANS\n2. Perlayer symmetric quantization for activation, such as KL and MAX_MIN.\n3. perlayer asymmetrical quantization for activation, such as, RemoveOutlier.\n4. accuracy loss compensation, such as BiasCorrection\n\n| mobilenet_v2   | ACC (ImageNet)  |\n|---|---|\n| FP32  | 71.56%  |\n|A8W8   | 71.16%  |\n| A8W8(without BiasCorrection)  | 70.74% |\n| A8W7  | 71.06%  |\n| A7W7  | 70.78%  |\n\nThe above table uses the mobilenet_v2 model from TF official website. Using MindSpore Lite quantization, the precision of A8W8 (8-bit activation value quantization and 8-bit weight quantization) decreases from 0.82% to 0.4% after accuracy loss compensation, for 7-bit quantization, the precision loss is still no more than 1%.\n\n#### Training on Device\n\nWithin MindSpore 1.1 release, the MindSpore Lite provides the following Training-on-Device (ToD) capabilities:\n\n1. Learning from scratch and Transfer Learning strategies are supported\n2. MindSpore based models can be converted and used in training on the device. (Third-party models such as TensorFlow and PyTorch for now cannot be directly imported to the framework)\n3. Grad operations are supported for more than 30 operators such as Dense layers, Convolutions and Batch Normalizations. Momentum, SGD, and ADAM optimizers are supported.\n4. Supports networks such as LeNet, Alexnet, Resnet, MobileNetV1/V2/V3, and EffectiveNet, and provides complete model loading, conversion, and Python training scripts on the device side.\n\nThe MindSpore Lite ToD framework is already in use in the newest Huawei Smart TV, providing a unique and personalized user experience as a family entertainment center.\n\n### API Change\n\n#### API Incompatible Change\n\n##### C++ API\n\n- [Modify] Context now support multi-context configuration.(Context.h)\n- [Modify] Callback is move from lite_session.h into ms_tensor.h.\n- [Modify] GetInputsByName in lite_session.h is changed into GetInputsByTensorName\n- [Add] add static LiteSession *CreateSession(const char*model_buf, size_t size, const lite::Context *context) in lite_session.h\n- [Add] add GetErrorInfo interface returning error message in errorcode.h\n- [Delete] Remove model_generated.h, ops_generated.h and headers of FlatBuffers library from interfaces\n\n##### Java API\n\n- [Add] Implement JNI layer and add Java api for CPU and GPU backend\n\n#### Deprecations\n\n##### C++ API\n\nDeprecate Interface GetOutputsByNodeName\n\n### Bug fixes\n\n- [BUGFIX] Fix the bug in sub-graph segmentation\n- [BUGFIX] Fix the bug in Tensor getitem in which the ellipsis matches the wrong dim-size.\n- [BUGFIX] Fix the bug that activation modification after defining Dense will not take effect.\n\n## Contributors\n\nThanks goes to these wonderful people:\n\nzhouyifengCode, huqi, JulyAi, damon0626, chenbo116, rmdyh, davidmc, gray0v0, doitH, Gogery, zymaa, xinyunfan\n\nAdel, AGroupofProbiotocs, anthonyaje, anzhengqi, askmiao, baihuawei, baiyangfan, bai-yangfan, bingyaweng, BowenK, buxue, caifubi, CaoJian, caojian05, caozhou, Cathy, changzherui, chenbo116, chenfei, chengxianbin, chenhaozhe, chenjianping, chenzomi, chenzupeng, chujinjin, cj, cjh9368, Corleone, damon0626, danish, Danish, davidmc, dayschan, doitH, eric, Eric, fary86, fuzhiye, Gaoxiong, gengdongjie, Gogery, gongdaguo, gray0v0, gukecai, guoqi, gzhcv, hangq, hanhuifeng2020, Harshvardhan, He, heleiwang, hexia, Hoai, HuangBingjian, huangdongrun, huanghui, huangxinjing, huqi, huzhifeng, hwjiaorui, Jesse, jianghui58, jiangzhiwen, Jiaqi, jin-xiulang, jinyaohui, jjfeing, John, Jonathan, jonyguo, JulyAi, jzg, kai00, kingfo, kingxian, kpy, kswang, laiyongqiang, leonwanghui, Li, liangchenghui, liangzelang, lichen_101010, lichenever, lihongkang, lilei, limingqi107, ling, linqingke, liubuyu, liuwenhao4, liuxiao78, liuxiao93, liuyang_655, liuzhongkai, Lixia, lixian, liyanliu, liyong, lizhenyu, luoyang, lvchangquan, lvliang, lz, mahdi, Mahdi, maning202007, Margaret_wangrui, mayang, mengyuanli, nhussain, ougongchang, panfengfeng, panyifeng, Payne, Peilin, peixu_ren, Pengyongrong, qianlong, r1chardf1d0, riemann_penn, rmdyh, Sheng, shenwei41, simson, Simson, Su, sunsuodong, tao_yunhao, tinazhang, VectorSL, , Wan, wandongdong, wangdongxu, wangmin, wangnan39@huawei.com, wangyue01, wangzhe, wanyiming, Wei, wenchunjiang, wilfChen, WilliamLian, wsc, wukesong, wuweikang, wuxuejian, Xiaoda, xiefangqi, xinyunfan, xuanyue, xulei2020, Xun, xuyongfei, yanghaitao, yanghaitao1, yanghaoran, YangLuo, yangruoqi713, yankai, yanzhenxiang2020, yao_yf, yepei6, yeyunpeng, Yi, yoni, yoonlee666, yuchaojie, yujianfeng, yuximiao, zengzitao, Zhang, zhanghaibo5@huawei.com, zhanghuiyao, zhangyihui, zhangz0911gm, zhanke, zhanyuan, zhaodezan, zhaojichen, zhaoting, zhaozhenlong, zhengjun10, zhoufeng, zhousiyi, zhouyaqiang, zhouyifengCode, Zichun, Zirui, Ziyan, zjun, ZPaC, zymaa\n\nContributions of any kind are welcome!\n\n# MindSpore 1.0.0 Release Notes\n\n## Major Features and Improvements\n\n### MindSpore Training and Inference Framework\n\n#### Ascend 910\n\n- New models\n    - DenseNet121: a dense convolutional neural network, which connects each layer to every other layer in a feed-forward fashion for object recognition on ImageNet dataset.\n    - UNet2D-Medical: Unet Medical model for 2D image segmentation, Convolutional Networks for Biomedical Image Segmentation on ISBI Challenge database.\n- Frontend and user interface\n    - Second-Order Optimization\n        - Enable second-order optimization for Bert on Ascend 910, which can achieve a masked lm accuracy of 71.3% in 800 seconds using 8 Ascend 910 (Bert-Large @MLPerf v0.7 dataset).\n    - New GNN model BGCF\n        - Bayesian Graph Convolutional Filtering network which naturally incorporate the uncertainty in the user-item interaction graph shows excellent recommendation performance on Amazon-Beauty dataset.\n    - Add append interface for SequentialCell.\n    - Add a level `auto` for AMP.\n- Executor and performance optimization\n    - Support quantitative network (Resnet50 & YoloV3 & MobileNetV2).\n    - Project ease of use optimization: project compilation time optimization, CMakelist regularization, cudnn, cuda independent compilation and installation independent.\n- Data processing, augmentation, and save format\n    - Support GeneratorDataset return string type\n\n#### Other Hardware Support\n\n- GPU platform\n    - Enable second-order optimization for resnet50 on GPU, which achieve 30% improvement on training time compared to SGD with Momentum (Resnet50 @ImageNet).\n\n#### User interfaces change log\n\n- Remove global object GradOperation in Autodiff([!5011](https://gitee.com/mindspore/mindspore/pulls/5011))\n- Remove useless attribute 'name' in Autodiff([!5172](https://gitee.com/mindspore/mindspore/pulls/5172))\n- Rectification distributed init([!5350](https://gitee.com/mindspore/mindspore/pulls/5350))\n- Move the setting of ParalleMode from train.parallel_utils to context([!5351](https://gitee.com/mindspore/mindspore/pulls/5351))\n- Modification of save_checkpoint([!5482](https://gitee.com/mindspore/mindspore/pulls/5482))\n- Wrap numpy random seed into an api([!5634](https://gitee.com/mindspore/mindspore/pulls/5634))\n- Delete enable_fused_layernorm in some modelzoo scripts([!5665](https://gitee.com/mindspore/mindspore/pulls/5665))\n- Move 'multi-subgraphs' interface to internal([!5696](https://gitee.com/mindspore/mindspore/pulls/5696))\n- Rename mirror_mean to gradient_mean([!5700](https://gitee.com/mindspore/mindspore/pulls/5700))\n- Remove default value of 'group' of DepthWiseConv2d([!5865](https://gitee.com/mindspore/mindspore/pulls/5865))\n- Modify interface for function and remove duplicated def([!5958](https://gitee.com/mindspore/mindspore/pulls/5958))\n- Unify Conv2d and DepthwiseConv2d([!5916](https://gitee.com/mindspore/mindspore/pulls/5916))\n- Modification of SoftmaxCrossEntropyWithLogits([!5502](https://gitee.com/mindspore/mindspore/pulls/5502))\n- Change API set_strategy() to shard()([!5991](https://gitee.com/mindspore/mindspore/pulls/5991))\n- Move batch_size from bert_cfg_cfg to cfg([!6233](https://gitee.com/mindspore/mindspore/pulls/6233))\n- Remove unused parameters from SummaryRecord __init__([!5548](https://gitee.com/mindspore/mindspore/pulls/5548))\n- remove sens parameter of TrainOneStepWithLossScaleCell([!5753](https://gitee.com/mindspore/mindspore/pulls/5753))\n- optimize the TrainOneStepCell for user's define([!6159](https://gitee.com/mindspore/mindspore/pulls/6159))\n- delete seed0 and seed1 of nn.Dropout([!5735](https://gitee.com/mindspore/mindspore/pulls/5735))\n- delete DataWrapper([!6101](https://gitee.com/mindspore/mindspore/pulls/6101))\n- LSTM API optimization([!6374](https://gitee.com/mindspore/mindspore/pulls/6374))\n- Merge P\\C\\F of ops([!5645](https://gitee.com/mindspore/mindspore/pulls/5645))\n- delete SoftmaxCrossEntropyExpand interface([!6607](https://gitee.com/mindspore/mindspore/pulls/6607))\n- Adjust GroupNorm interface([!6329](https://gitee.com/mindspore/mindspore/pulls/6329))\n- Modify init interface to internal interface([!6651](https://gitee.com/mindspore/mindspore/pulls/6651))\n- Log optimization([!5842](https://gitee.com/mindspore/mindspore/pulls/5842))\n- Remove useless API dataset.set_dataset_size（[!5806](https://gitee.com/mindspore/mindspore/pulls/5806))\n- Some of Dataset API add usage parameter（[!5605](https://gitee.com/mindspore/mindspore/pulls/5605))\n- Change the import path, such as from mindspore.dataset.transforms.vision to mindspore.dataset.vision.transforms（[!5384](https://gitee.com/mindspore/mindspore/pulls/5384))\n- Rename ImageFolderDatasetV2 to ImageFolderDataset（[!5384](https://gitee.com/mindspore/mindspore/pulls/5384))\n- Dataset.map parameter optimization（[!5384](https://gitee.com/mindspore/mindspore/pulls/5384))\n- Add new api dataset.get_col_names（[!5384](https://gitee.com/mindspore/mindspore/pulls/5384))\n- Add new api dataset.get_col_names（[!5384](https://gitee.com/mindspore/mindspore/pulls/5384))\n- Remove useless API MindRecord finish（[!5580](https://gitee.com/mindspore/mindspore/pulls/5580))\n\n### MindSpore Lite\n\n- Converter\n    - Add 6 TFLite op, 7 Caffe op, 1 ONNX op.\n    - Add support for Windows.\n    - Support parallel inference of multiple sessions to adapt to more scenarios\n    - Support 8bits only weight-quantization, most main-stream models has small accuracy loss (less than 0.5%) when compared to non-qunantized fp32 model.\n\n- CPU & GPU\n    - Add 20 CPU ops，include FP32, int8/uint8, FP16 and int32 ops.\n    - Add supporting FP16 for GPU, add 14 GPU ops include FP32/FP16.\n    - Add Buffer/Image2D transform op for GPU\n    - Performance optimization for CPU ops focus on ARM32.\n    - Performance optimization for GPU Convolution using winograd.\n\n- Tool & example\n    - Add object detection Android Demo.\n\n## Bugfixes\n\n- Models\n    - fix the constant folding problem in multiply.([!6092](https://gitee.com/mindspore/mindspore/pulls/6092))\n    - move batch_size from bert_net_cfg to cfg in bert scripts.([!6233](https://gitee.com/mindspore/mindspore/pulls/6233))\n    - modify the checkpoint file path.([!6137](https://gitee.com/mindspore/mindspore/pulls/6137))\n- Python API\n    - fix semi auto parallel parameter of reshape has another user([!5722](https://gitee.com/mindspore/mindspore/pulls/5722))\n    - raise ValueError when call hook function in graph mode([!5831](https://gitee.com/mindspore/mindspore/pulls/5831))\n- Executor\n    - fix pynative mode to build temporary nn objects.（[!6189](https://gitee.com/mindspore/mindspore/pulls/6189))\n    - fix the accuracy problem of multiple inputs of multi-card communication operator broadcast.([!6522](https://gitee.com/mindspore/mindspore/pulls/5622))\n    - fix the problem that the sample distribution interface categorical does not support graph mode.([!5772](https://gitee.com/mindspore/mindspore/pulls/5772))\n    - fix the random seed failure problem of the polynomial downsampling distribution operator.([!5948](https://gitee.com/mindspore/mindspore/pulls/5948))\n    - fix unnecessary address binding issues in GPU heterogeneous scenarios.([!6232](https://gitee.com/mindspore/mindspore/pulls/6232))\n- GPU platform\n    - fix for kernel resource leak([!5315](https://gitee.com/mindspore/mindspore/pulls/5315))\n    - fix for insufficient memory for continuous unit test running([!5617](https://gitee.com/mindspore/mindspore/pulls/5617))\n    - fix for the memory leak in the sparse slicer([!5578](https://gitee.com/mindspore/mindspore/pulls/5578))\n- Data processing\n    - fix hang when use pyfunc([!6346](https://gitee.com/mindspore/mindspore/pulls/6346))\n    - fix GPU device queue does not release GIL during resource clean up([!5964](https://gitee.com/mindspore/mindspore/pulls/5964))\n    - fix hang if scripte exit unnormally([!6441](https://gitee.com/mindspore/mindspore/pulls/6441))\n- Third party\n    - Sqlite : Update sqlite to 3.32.2 to handle [CVE-2020-11656](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2020-11656), [CVE-2020-13871](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2020-13871), [CVE-2020-11655](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2020-11655), [CVE-2020-9327](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2020-9327), [CVE-2020-13630](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2020-13630), [CVE-2020-15358](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2020-15358), [CVE-2020-13631](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2020-13631), [CVE-2020-13632](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2020-13632), [CVE-2020-13434](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2020-13434), [CVE-2020-13435](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2020-13435), and [CVE-2020-15358](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2020-11655).\n    - Libjpeg-turbo : Update libjpeg-turbo to 2.0.4 to handle [CVE-2020-13790](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2020-13790).\n\n## Contributors\n\nThanks goes to these wonderful people:\n\nAdel, AGroupofProbiotocs, anthonyaje, anzhengqi, askmiao, baihuawei, baiyangfan, bai-yangfan, bingyaweng, BowenK, buxue, caifubi, CaoJian, caojian05, caozhou, Cathy, changzherui, chenfei, chengxianbin, chenhaozhe, chenjianping, chenzomi, chenzupeng, chujinjin, cj, cjh9368, Corleone, danish, Danish, dayschan, eric, Eric, fary86, fuzhiye, Gaoxiong, gengdongjie, gongdaguo, gukecai, guoqi, gzhcv, hangq, hanhuifeng2020, Harshvardhan, He, heleiwang, hexia, Hoai, HuangBingjian, huangdongrun, huanghui, huangxinjing, huzhifeng, hwjiaorui, Jesse, jianghui58, jiangzhiwen, Jiaqi, jin-xiulang, jinyaohui, jjfeing, John, Jonathan, jonyguo, jzg, kai00, kingfo, kingxian, kpy, kswang, laiyongqiang, leonwanghui, Li, liangchenghui, liangzelang, lichen_101010, lichenever, lihongkang, lilei, limingqi107, ling, linqingke, liubuyu, liuwenhao4, liuxiao78, liuxiao93, liuyang_655, liuzhongkai, Lixia, lixian, liyanliu, liyong, lizhenyu, luoyang, lvchangquan, lvliang, lz, mahdi, Mahdi, maning202007, Margaret_wangrui, mayang, mengyuanli, nhussain, ougongchang, panfengfeng, panyifeng, Payne, Peilin, peixu_ren, Pengyongrong, qianlong, r1chardf1d0, riemann_penn, root, Sheng, shenwei41, simson, Simson, Su, sunsuodong, tao_yunhao, tinazhang, VectorSL, , Wan, wandongdong, wangdongxu, wangmin, wangnan39@huawei.com, wangyue01, wangzhe, wanyiming, Wei, wenchunjiang, wilfChen, WilliamLian, wsc, wukesong, wuweikang, wuxuejian, Xiaoda, xiefangqi, xuanyue, xulei2020, Xun, xuyongfei, yanghaitao, yanghaitao1, yanghaoran, YangLuo, yangruoqi713, yankai, yanzhenxiang2020, yao_yf, yepei6, yeyunpeng, Yi, yoni, yoonlee666, yuchaojie, yujianfeng, yuximiao, zengzitao, Zhang, zhanghaibo5@huawei.com, zhanghuiyao, zhangyihui, zhangz0911gm, zhanke, zhanyuan, zhaodezan, zhaojichen, zhaoting, zhaozhenlong, zhengjun10, zhoufeng, zhousiyi, zhouyaqiang, Zichun, Zirui, Ziyan, zjun, ZPaC\n\nContributions of any kind are welcome!\n\n# MindSpore 0.7.0-beta Release Notes\n\n## Major Features and Improvements\n\n### MindSpore Training and Inference Framework\n\n#### Ascend 910\n\n- New models\n    - TinyBert: a smaller and faster version of BERT using transformer distillation for natural language understanding on GLUE benchmark.\n    - SE-ResNet50: add Squeeze-and-Excitation blocks(SE-Blocks) to the resnet50 network to improve channel interdependencies for image classification on ImageNet 2012 dataset.\n    - Inception V3: the third version of Inception convolutional architectures for image classification on ImageNet 2012 dataset.\n- Frontend and user interface\n    - Embedding operator high-level packaging to support segmented by field for Wide&Deep.\n    - Load multi-node checkpoint into single-process to support host-device hybrid inference.\n    - Support Concat/Tile/Strideslice distributed operators.\n    - Support cumulative gradient and batch training split.\n    - Support variable parameter input for Cell object.\n    - Parameter mixed calculation optimization for pynative mode.\n    - Deep Probabilistic Programming\n        - Support statistical distributions classes used to generate stochastic tensors.\n        - Support probabilistic inference algorithms.\n        - Support BNN layers used to construct BNN in Graph mode.\n        - Support interfaces for the transformation between BNN and DNN in Graph mode.\n        - Support uncertainty estimation to estimate epistemic uncertainty and aleatoric uncertainty.\n    - User interfaces change log\n        - change base class of parameter([!3473](https://gitee.com/mindspore/mindspore/pulls/3473))\n        - change binary to mindir([!4258](https://gitee.com/mindspore/mindspore/pulls/4258))\n        - change export from geir to air([!4269](https://gitee.com/mindspore/mindspore/pulls/4269))\n        - Init parameter data by default([!3967](https://gitee.com/mindspore/mindspore/pulls/3967))\n        - change IndexedSlices to RowTensor([!4031](https://gitee.com/mindspore/mindspore/pulls/4031))\n        - Must set or change parallel mode before any Initializer created([!4801](https://gitee.com/mindspore/mindspore/pulls/4801))\n- Executor and performance optimization\n    - MindSpore graph compilation process performance improved by 20%.\n    - Decoupling C++ and Python modules to achieve separate compilation of core modules.\n- Data processing, augmentation, and save format\n    - Support automatic data augmentation\n    - Support GNN distributed cache in single node\n    - Support ConcatDataset using distributed sampler\n\n#### Other Hardware Support\n\n- GPU platform\n    - New model supported: VGG16, ResNet101, DeepFM.\n    - Support some distributed operators in ResNet50 and Wide&Deep.\n    - Support automatic parallel for Wide&Deep.\n    - Support function funcs[i](*inputs) (such as switch-case).\n    - Support distributed training with parameter server.\n    - Support GPU operator profiling.\n    - Performance optimization of the distributed training with allreduce.\n    - Performance optimization of the mixed precision training.\n    - Performance optimization of the pynative mode.\n    - Performance optimization of the convolution operator, batch normalization operator.\n- CPU platform\n    - Support MobileNetV2 Re-Training: Re-train the network with different class number.\n\n### MindSpore Lite\n\n- Converter\n    - Support third-party models, including TFLite/Caffe/ONNX.\n    - Add 93 TFLite op.\n    - Add 24 Caffe op.\n    - Add 62 ONNX op.\n    - Add 11 optimized passes, include fusion/const fold.\n    - Support aware-training and Post-training quantization.\n- CPU\n    - Add 100+ops，support fp32, int8/uint8, FP16 ops\n    - Support fast convolution algorithms: Sliding Window, Img2col + Gemm, Strassen, Winograd\n    - Support assembly/neon instruction.\n    - Support CPU fp16 and sdot on ARM v8.2+.\n- GPU\n    - Add 20+ ops for OpenCL.\n    - Support image2D/buffer format.\n    - Optimize online initialization time.\n    - add optimized convolution1X1/3X3/depthwise/convolution_transposed for OpenCL.\n- Tool & example\n    - Add benchmark and TimeProfile tools.\n    - Add image classification Android Demo.\n\n## Bugfixes\n\n- Models\n    - normalize the readme file([!5410](https://gitee.com/mindspore/mindspore/pulls/5410))\n    - fix a sink_size bug for transformer([!5393](https://gitee.com/mindspore/mindspore/pulls/5393))\n    - fix bool type optional for resnet50([!5363](https://gitee.com/mindspore/mindspore/pulls/5363))\n- Python API\n    - improve interface '__bool__' for tensor([!4000](https://gitee.com/mindspore/mindspore/pulls/4000))\n    - fix GPU-ResizeNearestNeighbor([!3760](https://gitee.com/mindspore/mindspore/pulls/3760))\n    - fix topK multi dimension grad func([!3711](https://gitee.com/mindspore/mindspore/pulls/3711))\n    - fix scatterop error msg([!3699](https://gitee.com/mindspore/mindspore/pulls/3699))\n    - fix bug of cast dtype when using mix_presion in pynative mode([!3730](https://gitee.com/mindspore/mindspore/pulls/3730))\n- Executor\n    - fix etsnet train error when UnsegmentSum's first input shape is (1,) ([!4573](https://gitee.com/mindspore/mindspore/pulls/4573))\n    - fix bug of result error in while control flow because of unsupporting for value reference ([!4103](https://gitee.com/mindspore/mindspore/pulls/4103))\n    - fix bug of the output tensor does not carry device data type ([!3774](https://gitee.com/mindspore/mindspore/pulls/3774))\n    - fix bug of avoiding multi attr value are eliminated in pynative mode ([!4225](https://gitee.com/mindspore/mindspore/pulls/4225))\n    - fix bug of AssignAdd unable to work normally in multi-cases ([!5171](https://gitee.com/mindspore/mindspore/pulls/5171))\n- GPU platform\n    - improve the environment variable checking for nvcc compiler path ([!5140](https://gitee.com/mindspore/mindspore/pulls/5140))\n    - fix bug of error in cast operator conversion from fp16 to fp32 ([!4147](https://gitee.com/mindspore/mindspore/pulls/4147))\n    - fix bug of the array out of bound in case of make_tuple operator ([!5219](https://gitee.com/mindspore/mindspore/pulls/5219))\n- Data processing and Pro\n    - fix GeneratorDataset time out([!3624](https://gitee.com/mindspore/mindspore/pulls/3624))\n    - fix concat operator get_dataset_size error([!4701](https://gitee.com/mindspore/mindspore/pulls/4701))\n    - fixing python validator for Repeat Op([!4366](https://gitee.com/mindspore/mindspore/pulls/4366))\n- Third party\n    - Sqlite : Update sqlite to 3.32.2 to handle [CVE-2020-11656](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2020-11656), [CVE-2020-13871](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2020-13871), [CVE-2020-11655](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2020-11655), [CVE-2020-9327](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2020-9327), [CVE-2020-13630](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2020-13630), [CVE-2020-15358](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2020-15358), [CVE-2020-13631](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2020-13631), [CVE-2020-13632](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2020-13632), [CVE-2020-13434](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2020-13434), [CVE-2020-13435](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2020-13435), and [CVE-2020-15358](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2020-11655).\n    - Libjpeg-turbo : Update libjpeg-turbo to 2.0.4 to handle [CVE-2020-13790](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2020-13790).\n\n## Contributors\n\nThanks goes to these wonderful people:\n\nAdel, Alexey, andy, andy_wangrui, anthonyaje, anzhengqi, askmiao, avakh, baihuawei, bingyaweng, BowenK, buxue, caifubi, CaoJian, caozhou, Cathy, changzherui, chenfei, chengxianbin, chenhaozhe, chenjianping, chentingting, chenzomi, chenzupeng, chujinjin, cjh9368, Corleone, cristoval, danish, dengyutao, eric, Eric, ervinzhang, etone-chan, fangzehua, fary86, fuzhiye, gengdongjie, genglishuai, Giancarlo, gongdaguo, gukecai, guohongzilong, GuoMengHao, hangq, hanhaocheng, hanhuifeng2020, hanjun996, Harshvardhan, He, heleiwang, hesham, hexia, Hoai, hongxing, huangdongrun, huanghui, huangxinjing, islam_amin, Jesse, jianghui58, jiangzhiwen, jin-xiulang, jinyaohui, jjfeing, John, Jonathan, jonyguo, kai00, kingfo, kpy, kswang, laiyongqiang, leilei_snow, leopz, Li, liangzelang, lianliguang, lichen_101010, lichenever, lihongkang, lilei, limingqi107, ling, lingyunli63, linqingke, lirongzhen1, liubuyu, liuwenhao4, liuxiao78, liuxiao93, liuzhongkai, Lixia, lixian, liyong, lizhenyu, looop5, luoyang, lvchangquan, lvliang, lvwenyuan, lyvette, mahdi, Mahdi, mamba_ni, maning202007, Margaret_wangrui, mayang, meixiaowei, meng_chunyang, ms_yan, nhussain, panbingao, panfengfeng, panyifeng, Payne, Peilin, peixu_ren, pengyongrong, Pengyongrong, qianlong, qujianwei, root, shenwei41, shibeiji, simson, songhonglei413, Su, sunsuodong, suteng, tao_yunhao, TFbunny, tinazhang, tom__chen, tony_liu2, tronzhang, VectorSL, wandongdong, wangdongxu, wanghua, wangmin, wangshaocong, wangzhe, wanyiming, Wei, wenchunjiang, wilfChen, WilliamLian, wsc, wukesong, wuweikang, wuxuejian, wuyongkang, xiefangqi, xuanyue, Xun, xutianchun, xuyongfei, yanghaitao, yangjie159, YangLuo, yangruoqi713, yangyongjie, yangzhenzhang, yankai, yao_yf, yelihua, yeyunpeng, Yi, yoni, yoonlee666, yuchaojie, yujianfeng, yuximiao, zhangxuetong, zhaizhiqiang, Zhang, zhangxinfeng3, zhangxuetong, zhangyihui, zhangz0911gm, zhanke, zhanyuan, zhaodezan, zhaoting, zhaozhenlong, zhengjun10, zhongligeng, zhoufeng, zhousiyi, zhouyaqiang, zhouyuanshen, Zichun, Zirui, zjun, zongha, ZPaC, lijiaqi, liangchenghui, wangminggui\n\nContributions of any kind are welcome!\n\n# MindSpore 0.6.0-beta Release Notes\n\n## Major Features and Improvements\n\n### Ascend 910 Training and Inference Framework\n\n- New models\n    - There are official, research and community under modelzoo.\n        - Official is maintained  with the newest APIs by MindSpore team,  MaskRCNN are added.\n        - Research is uploaded by researchers for official review, and APIs may not  be updated in time.\n        - Community reprints the relevant links of partner research results.\n    - Hub added on the same level as modelzoo, synchronous storage of materials needed for official hub web pages which will be launched soon.\n    - Support pre-trained models, few lines of code can be used to download and load pre-trained models, supporting inference or transfer learning.\n- Frontend and user interface\n    - Supports user side operator compilation and graph execution error rendering.\n    - Uniform definition dynamic learning rate behavior in optimizers.\n    - Support IndexSlice in sparse expression.\n    - Support use parent construct method during construct.\n    - Support asynchronous execution save checkpoint file.\n    - Support implicit type conversion in pynative mode.\n    - User interfaces change log\n        - unform learning rate behavior in optimizers([!2755](https://gitee.com/mindspore/mindspore/pulls/2755))\n        - rename operator of sparse optimizer([!3217](https://gitee.com/mindspore/mindspore/pulls/3217))\n        - move profiler module from mindinsight to mindspore([!3075](https://gitee.com/mindspore/mindspore/pulls/3075))\n        - VOCDataset output change to multi-columns([!3093](https://gitee.com/mindspore/mindspore/pulls/3093))\n        - GetDatasize feature([!3212](https://gitee.com/mindspore/mindspore/pulls/3212))\n        - dataset: modify config api([!2936](https://gitee.com/mindspore/mindspore/pulls/2936))\n- Executor and performance optimization\n    - Decouple C++ and python, so make the architecture more extensible.\n    - Parameter Server for distributed deep learning supported.\n    - Serving: a flexible service deployment framework for deep learning models.\n    - Memory reuse is enhanced, and the batch size of Bert large model is increased from 96 to 160 on a single server.\n- Data processing, augmentation, and save format\n    - Support MindRecord save operator after  date processing\n    - Support automatic fusion operator, such as decode/resize/crop\n    - Support CSV dataset loading\n\n### Other Hardware Support\n\n- GPU platform\n    - New model supported: ResNext50, WarpCTC and GoogLeNet.\n    - Support hyperparametric search and data enhanced automl on GPU.\n    - Support Resnet50 automatic parallel in GPU backend.\n\n## Bugfixes\n\n- Models\n    - Improved the performance and accuracy on ResNet50([!3456](https://gitee.com/mindspore/mindspore/pulls/3456))\n    - Fixed the performance test case of bert([!3486](https://gitee.com/mindspore/mindspore/pulls/3486))\n- Python API\n    - Fix assign used in while loop([!2720](https://gitee.com/mindspore/mindspore/pulls/2720))\n    - Revert optimize the graph output of all nop node.([!2857](https://gitee.com/mindspore/mindspore/pulls/2857))\n    - Print tensor as numpy.([!2859](https://gitee.com/mindspore/mindspore/pulls/2859))\n    - Support weight decay for sparse optimizer([!2668](https://gitee.com/mindspore/mindspore/pulls/2668))\n    - Fix BatchToSpaceND([!2741](https://gitee.com/mindspore/mindspore/pulls/2741))\n    - Fixing type check mistakes of InplaceAdd and Inplace Sub ops([!2744](https://gitee.com/mindspore/mindspore/pulls/2744]))\n    - Change order param only equal to group param([!2748](https://gitee.com/mindspore/mindspore/pulls/2748))\n- Executor\n    - The performance of graph with control flow is optimized([!2931](https://gitee.com/mindspore/mindspore/pulls/2931))\n    - Fix bug of wrong number of tuple layers([!3390](https://gitee.com/mindspore/mindspore/pulls/3390))\n    - Fix cpu multi graph memory exception([!3631](https://gitee.com/mindspore/mindspore/pulls/3631))\n    - Enable data sync when calling operator without defining a cell([!3081](https://gitee.com/mindspore/mindspore/pulls/3081))\n    - Fix argmaxwith value error in pynative mode on GPU([!3082](https://gitee.com/mindspore/mindspore/pulls/3082))\n    - Fix precision error with fp16 input on pynative mode([!3196](https://gitee.com/mindspore/mindspore/pulls/3196))\n- Data processing\n    - Fix bug of RandomColor and RandomSharpness default parameter checking  ([!2833](https://gitee.com/mindspore/mindspore/pulls/2833))\n    - Fix process hung when training and eval  ([!3469](https://gitee.com/mindspore/mindspore/pulls/3469))\n- Third party\n    - Sqlite : Update sqlite to 3.32.2 to handle [CVE-2020-11656](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2020-11656), [CVE-2020-13871](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2020-13871), [CVE-2020-11655](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2020-11655), [CVE-2020-9327](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2020-9327), [CVE-2020-13630](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2020-13630), [CVE-2020-15358](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2020-15358), [CVE-2020-13631](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2020-13631), [CVE-2020-13632](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2020-13632), [CVE-2020-13434](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2020-13434), [CVE-2020-13435](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2020-13435), and [CVE-2020-15358](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2020-11655).\n    - Libjpeg-turbo : Update libjpeg-turbo to 2.0.4 to handle [CVE-2020-13790](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2020-13790).\n\n## Contributors\n\nThanks goes to these wonderful people:\n\nAlexey Shevlyakov, avakh, baihuawei, BowenK, buxue, caifubi, caojian05, Cathy Wong, changzherui, chenfei, chengxianbin, chenhaozhe, chenjianping, chentingting, chenzomi, chujinjin, Danish Farid, dayschan, dengwentao, dinghao, etone-chan, fangzehua, fary86, geekun, Giancarlo Colmenares, gong chen, gukecai, guohongzilong, hangangqiang, heleiwang, hesham, He Wei, hexia, hongxing, huangdongrun, huanghui, islam_amin, Jamie Nisbet, Jesse Lee, jiangjinsheng, jiangzhiwen, jinyaohui, jjfeing, jojobugfree, Jonathan Yan, jonyguo, Junhan Hu, Kang, kingfo, kouzhenzhong, kpy, kswang, laiyongqiang, leopz, liangzelang, lichenever, lihongkang, Li Hongzhang, lilei, limingqi107, lirongzhen1, liubuyu, liuchongming74, liuwenhao4, liuxiao, Lixia Chen, liyanliu, liyong, lizhenyu, lvliang, Mahdi, Margaret_wangrui, meixiaowei, ms_yan, nhussain, ougongchang, panfengfeng, panyifeng, peilinwang, Peilin Wang, pkuliuliu, qianlong, rick_sanchez, shibeiji, Shida He, shijianning, simson, sunsuodong, suteng, Tinazhang, Tron Zhang, unknown, VectorSL, wandongdong, wangcong, wangdongxu, wangdongxu6, wanghua, wangnan39, Wei Luning, wenchunjiang, wenkai, wilfChen, WilliamLian, wukesong, Xian Weizhao, Xiaoda Zhang, xiefangqi, xulei2020, xunxue, xutianchun, Yang, yanghaitao, yanghaitao1, yanghaoran, yangjie, yangjie159, YangLuo, Yanjun Peng, yankai, yanzhenxiang2020, yao_yf, Yi Huaijie, yoonlee666, yuchaojie, yujianfeng, zhangzhongpeng, zhangdengcheng, Zhang Qinghua, zhangyinxia, zhangz0911gm, zhaojichen, zhaoting, zhaozhenlong, zhoufeng, zhouneng, zhousiyi, Zirui Wu, Ziyan, zjun, ZPaC, lihongzhang, wangdongxu\n\nContributions of any kind are welcome!\n\n# MindSpore 0.5.2-beta Release Notes\n\n## Major Features and Improvements\n\n### Ascend 910 Training and Inference Framework\n\n- New models\n    - DenseNet121: a convolution based neural network for the task of image classification on ImageNet 2012 dataset.\n\n## Bugfixes\n\n- Models\n    - VGG16,Alexnet,GoogleNet,optimize network for better performance. ([!5539](https://gitee.com/mindspore/mindspore/pulls/5539))\n    - YOLOV3, fix yolov3_darknet53 dataset bug. ([!5658](https://gitee.com/mindspore/mindspore/pulls/5658))\n\n## Contributors\n\nThanks goes to these wonderful people:\n\nAlexey Shevlyakov, avakh, baihuawei, BowenK, buxue, caifubi, caojian05, Cathy Wong, changzherui, chenfei, chengxianbin, chenhaozhe, chenjianping, chentingting, chenzomi, chujinjin, Danish Farid, dayschan, dengwentao, dinghao, etone-chan, fangzehua, fary86, geekun, Giancarlo Colmenares, gong chen, gukecai, guohongzilong, hangangqiang, heleiwang, hesham, He Wei, hexia, hongxing, huangdongrun, huanghui, islam_amin, Jamie Nisbet, Jesse Lee, jiangjinsheng, jiangzhiwen, jinyaohui, jjfeing, jojobugfree, Jonathan Yan, jonyguo, Junhan Hu, Kang, kingfo, kouzhenzhong, kpy, kswang, laiyongqiang, leopz, liangzelang, lichenever, lihongkang, Li Hongzhang, lilei, limingqi107, lirongzhen1, liubuyu, liuchongming74, liuwenhao4, liuxiao, Lixia Chen, liyanliu, liyong, lizhenyu, lvliang, Mahdi, Margaret_wangrui, meixiaowei, ms_yan, nhussain, ougongchang, panfengfeng, panyifeng, peilinwang, Peilin Wang, pkuliuliu, qianlong, rick_sanchez, shibeiji, Shida He, shijianning, simson, sunsuodong, suteng, Tinazhang, Tron Zhang, unknown, VectorSL, wandongdong, wangcong, wangdongxu, wangdongxu6, wanghua, wangnan39, Wei Luning, wenchunjiang, wenkai, wilfChen, WilliamLian, wukesong, Xian Weizhao, Xiaoda Zhang, xiefangqi, xulei2020, xunxue, xutianchun, Yang, yanghaitao, yanghaitao1, yanghaoran, yangjie, yangjie159, YangLuo, Yanjun Peng, yankai, yanzhenxiang2020, yao_yf, Yi Huaijie, yoonlee666, yuchaojie, yujianfeng, zhangzhongpeng, zhangdengcheng, Zhang Qinghua, zhangyinxia, zhangz0911gm, zhaojichen, zhaoting, zhaozhenlong, zhoufeng, zhouneng, zhousiyi, Zirui Wu, Ziyan, zjun, ZPaC, lihongzhang, wangdongxu\n\nContributions of any kind are welcome!\n\n# MindSpore 0.5.0-beta Release Notes\n\n## Major Features and Improvements\n\n### Ascend 910 Training and Inference Framework\n\n- New models\n    - ResNext50: a simple, highly modularized network architecture using aggregated resdiual transformations for image classification on ImageNet 2012 dataset.\n    - MASS: a pre-training method for sequence to sequence based language generation tasks on Text Summarization and Conversational Response Generation using News Crawls 2007-2017 dataset, Gigaword corpus and Cornell movie dialog corpus.\n    - Transformer: a neural network architecture for language understanding on WMT 2014 English-German dataset.\n    - GCN: Graph Convolutional Networks for the task of classification of nodes in a graph on Cora and Citeseer datasets.\n    - GAT: an attention-based graph neural network for node classification on Cora and CiteSeer dataset.\n- Frontend and user interface\n    - Support tensor value and assignment of mixed tensor index in graph mode.\n    - Support tensor comparison, len operator, constexpr syntax, value and assignment of tensor index in pynative mode.\n    - Support converting MindSpore IR to pb format for infer model.\n    - Support print operator to write data directly on the hard disk.\n    - Add the double recursive programming solution for very high speed parallel strategy search in automatic parallel.\n    - User interfaces change log\n        - Allow the learning rate of AdamWeightDecayDynamicLR and Lamb to be 0([!1826](https://gitee.com/mindspore/mindspore/pulls/1826))\n        - Restricting the entire network input parameter is Tensor([!1967](https://gitee.com/mindspore/mindspore/pulls/1967))\n        - Turn shape and dtype into attributes instead of interfaces([!1919](https://gitee.com/mindspore/mindspore/pulls/1919))\n        - Delete multitypefungraph([!2116](https://gitee.com/mindspore/mindspore/pulls/2116))\n        - Refactor the callback module in an encapsulated way, use _CallbackManager instead of_build_callbacks([!2236](https://gitee.com/mindspore/mindspore/pulls/2236))\n        - Delete EmbeddingLookup([!2163](https://gitee.com/mindspore/mindspore/pulls/2163))\n        - Checkpoint add model_type([!2517](https://gitee.com/mindspore/mindspore/pulls/2517))\n- Executor and performance optimization\n    - Heterogeneous execution on CPU and Ascend devices supported, and is verified in Wide&Deep model.\n    - Quantitative training of MobileNetV2, Lenet and Resnet50 on Ascend-910 are supported.\n    - Support new fusion architecture, which can do fusion optimization across graphs and kernels to improve execution speed.\n- Data processing, augmentation, and save format\n    - Support data processing pipeline performance profiling.\n    - Support public dataset loading, such as CLUE and Coco.\n    - Support more text processing, such as more tokenizers and vocab data.\n    - Support MindRecord padded data.\n\n### Other Hardware Support\n\n- GPU platform\n    - New model supported: Bert / Wide&Deep.\n    - Support setting max device memory.\n- CPU platform\n    - New model supported: LSTM.\n\n## Bugfixes\n\n- Models\n    - Bert, Move Bert from `example` to `model_zoo`, optimize network for better performance. ([!1902](https://gitee.com/mindspore/mindspore/pulls/1902))\n    - VGG16, Move VGG16 from `example` to `model_zoo`, optimize network for better accuracy. ([!2645](https://gitee.com/mindspore/mindspore/pulls/2645))\n    - Alexnet, modify parameter setting to improve accuracy ([!1364](https://gitee.com/mindspore/mindspore/pulls/2370))\n    - Wide&Deep, Move Wide&Deep from `example` to `model_zoo`, optimize network for better performance. ([!2221](https://gitee.com/mindspore/mindspore/pulls/2221))\n- Python API\n    - Fix bug in auto cast([!1766](https://gitee.com/mindspore/mindspore/pulls/1766))\n    - Fix bug of register_backward_hook([!2148](https://gitee.com/mindspore/mindspore/pulls/2148))\n    - Fix bug of tuple args in pynative mode([!1878](https://gitee.com/mindspore/mindspore/pulls/1878))\n    - Fix bug of checking numbers of arguments and graph parameters([!1701](https://gitee.com/mindspore/mindspore/pulls/1701))\n- Executor\n    - Fix bug of loading input data repeatedly in pynative mode([!1966](https://gitee.com/mindspore/mindspore/pulls/1966))\n    - Fix bug of list cannot be used as input in pynative mode([!1765](https://gitee.com/mindspore/mindspore/pulls/1765))\n    - Fix bug of kernel select ([!2103](https://gitee.com/mindspore/mindspore/pulls/2103))\n    - Fix bug of pattern matching for batchnorm fusion in the case of auto mix precision.([!1851](https://gitee.com/mindspore/mindspore/pulls/1851))\n    - Fix bug of generate hccl's kernel info.([!2393](https://gitee.com/mindspore/mindspore/pulls/2393))\n- GPU platform\n    - Fix bug of summary feature invalid([!2173](https://gitee.com/mindspore/mindspore/pulls/2173))\n- Data processing\n    - Fix bug of Cifar dataset reading([!2096](https://gitee.com/mindspore/mindspore/pulls/2096))\n    - Fix bug of C++ behavior in RandomCropAndResize([!2026](https://gitee.com/mindspore/mindspore/pulls/2026))\n    - Fix the bug of mindrecord shuffle([!2420](https://gitee.com/mindspore/mindspore/pulls/2420))\n- Third party\n    - Sqlite : Update sqlite to 3.32.2 to handle [CVE-2020-11656](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2020-11656), [CVE-2020-13871](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2020-13871), [CVE-2020-11655](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2020-11655), [CVE-2020-9327](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2020-9327), [CVE-2020-13630](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2020-13630), [CVE-2020-15358](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2020-15358), [CVE-2020-13631](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2020-13631), [CVE-2020-13632](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2020-13632), [CVE-2020-13434](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2020-13434), [CVE-2020-13435](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2020-13435), and [CVE-2020-15358](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2020-11655).\n\n## Contributors\n\nThanks goes to these wonderful people:\n\nAlexey Shevlyakov, avakh, baihuawei, BowenK, buxue, caifubi, caojian05, Cathy Wong, changzherui, chenfei, chengxianbin, chenhaozhe, chenjianping, chentingting, chenzomi, chujinjin, Danish Farid, dayschan, dengwentao, dinghao, etone-chan, fangzehua, fary86, geekun, Giancarlo Colmenares, gong chen, gukecai, guohongzilong, hangangqiang, heleiwang, hesham, He Wei, hexia, hongxing, huangdongrun, huanghui, islam_amin, Jamie Nisbet, Jesse Lee, jiangjinsheng, jiangzhiwen, jinyaohui, jjfeing, jojobugfree, Jonathan Yan, jonyguo, Junhan Hu, Kang, kingfo, kouzhenzhong, kpy, kswang, laiyongqiang, leopz, liangzelang, lichenever, lihongkang, Li Hongzhang, lilei, limingqi107, lirongzhen1, liubuyu, liuchongming74, liuwenhao4, liuxiao, Lixia Chen, liyanliu, liyong, lizhenyu, lvliang, Mahdi, Margaret_wangrui, meixiaowei, ms_yan, nhussain, ougongchang, panfengfeng, panyifeng, peilinwang, Peilin Wang, pkuliuliu, qianlong, rick_sanchez, shibeiji, Shida He, shijianning, simson, sunsuodong, suteng, Tinazhang, Tron Zhang, unknown, VectorSL, wandongdong, wangcong, wangdongxu, wangdongxu6, wanghua, wangnan39, Wei Luning, wenchunjiang, wenkai, wilfChen, WilliamLian, wukesong, Xian Weizhao, Xiaoda Zhang, xiefangqi, xulei2020, xunxue, xutianchun, Yang, yanghaitao, yanghaitao1, yanghaoran, yangjie, yangjie159, YangLuo, Yanjun Peng, yankai, yanzhenxiang2020, yao_yf, Yi Huaijie, yoonlee666, yuchaojie, yujianfeng, zhangzhongpeng, zhangdengcheng, Zhang Qinghua, zhangyinxia, zhangz0911gm, zhaojichen, zhaoting, zhaozhenlong, zhoufeng, zhouneng, zhousiyi, Zirui Wu, Ziyan, zjun, ZPaC, lihongzhang, wangdongxu\n\nContributions of any kind are welcome!\n\n# MindSpore 0.3.1-alpha Release Notes\n\n## Major Features and Improvements\n\n### Ascend 910 Training and Inference Framework\n\n- Frontend and User Interface\n    - Independent model init interface.\n- Data processing, augmentation, and save format\n    - Support sample padding for minddataset.\n\n## Bugfixes\n\n- Python API\n    - Fix bugs in the lars optimizer([!1894](https://gitee.com/mindspore/mindspore/pulls/1894))\n- Data processing\n    - Fix accuracy problem of RandomCropDecodeResize ([!2340](https://gitee.com/mindspore/mindspore/pulls/2340))\n\n# Release 0.3.0-alpha\n\n## Major Features and Improvements\n\n### Ascend 910 Training and Inference Framework\n\n- New models\n    - DeepFM: a factorization-machine based neural network for CTR prediction on Criteo dataset.\n    - DeepLabV3: significantly improves over our previous DeepLab versions without DenseCRF post-processing and attains comparable performance with other state-of-art models on the PASCAL VOC 2007 semantic image segmentation benchmark.\n    - Faster-RCNN: towards real-time object detection with region proposal networks on COCO 2017 dataset.\n    - SSD: a single stage object detection methods on COCO 2017 dataset.\n    - GoogLeNet: a deep convolutional neural network architecture codenamed Inception V1 for classification and detection on CIFAR-10 dataset.\n    - Wide&Deep: jointly trained wide linear models and deep neural networks for recommender systems on Criteo dataset.\n- Frontend and User Interface\n    - Complete numpy advanced indexing method. Supports value and assignment through tensor index.\n    - Some optimizers support separating parameter groups. Different parameter groups can set different `learning_rate` and `weight_decay`.\n    - Support setting submodule's logging level independently, e.g. you can set logging level of module `A` to warning and set logging level of module `B` to info.\n    - Support weights to be compiled according to shape to solve the problem of large memory overhead.\n    - Add some operators implement and grammar support in pynative mode. To be consistent with graph mode.\n    - User interfaces change log\n        - Learning rate and weight decay making group params([!637](https://gitee.com/mindspore/mindspore/pulls/637))\n        - Support weights to be compiled according to shape([!1015](https://gitee.com/mindspore/mindspore/pulls/1015))\n        - delete some context param([!1100](https://gitee.com/mindspore/mindspore/pulls/1100))\n        - ImageSummary/ScalarSummary/TensorSummary/HistogramSummary([!1329](https://gitee.com/mindspore/mindspore/pulls/1329))([!1425](https://gitee.com/mindspore/mindspore/pulls/1425))\n- Executor and Performance Optimization\n    - Support doing evaluation while in training process, so that the accuracy of training can be easily obtained.\n    - Enable second-order optimization for resnet50, which can achieve 75.9% accuracy in 45 epochs (Resnet50 @ImageNet).\n    - Optimize pynative implementation and improve it's execution performance.\n    - Optimize summary record implementation and improve its performance.\n- Data processing, augmentation, and save format\n    - Support simple text processing, such as tokenizer/buildvocab/lookup.\n    - Support padding batch.\n    - Support split or concat dataset.\n    - Support MindDataset reading from file list.\n\n### Other Hardware Support\n\n- GPU platform\n    - New models supported: MobileNetV2, MobileNetV3.\n    - Support mixed precision training.\n    - Support device memory swapping.\n\n## Bugfixes\n\n- Python API\n    - An exception to the broadcast input data type check([!712](https://gitee.com/mindspore/mindspore/pulls/712))\n    - Fix issues assignsub return value 0([!1036](https://gitee.com/mindspore/mindspore/pulls/1036))\n    - Fix issue Conv2dBackpropInput bprop should return 3 instead of 2 items([!1001](https://gitee.com/mindspore/mindspore/pulls/1001))\n    - Fix sens shape error of TrainOneStepWithLossScaleCell([!1050](https://gitee.com/mindspore/mindspore/pulls/1050))\n    - Fix BatchNormGrad operator([!1344](https://gitee.com/mindspore/mindspore/pulls/1344))\n- Executor\n    - Fix dropout，topK and addn errors in PyNative mode ([!1285](https://gitee.com/mindspore/mindspore/pulls/1285), [!1138](https://gitee.com/mindspore/mindspore/pulls/1138), [!1033](https://gitee.com/mindspore/mindspore/pulls/1033)).\n    - Fix memory leaks after execution in PyNatvie mode ([!1201](https://gitee.com/mindspore/mindspore/pulls/1201)).\n    - Fix HCCL failure in some special scenes ([!1204](https://gitee.com/mindspore/mindspore/pulls/1204), [!1252](https://gitee.com/mindspore/mindspore/pulls/1252)).\n    - Fix SSD network when Select failed, can't find kernel info([!1449](https://gitee.com/mindspore/mindspore/pulls/1449)).\n    - Fix Topk operator selection strategy bug between aicore and aicpu([!1367](https://gitee.com/mindspore/mindspore/pulls/1367)).\n    - Fix input memory size of 'assign' op unequal in control sink mode when assigning a data from one child graph to another child graph([!802](https://gitee.com/mindspore/mindspore/pulls/802)).\n    - Fix allreduce ir inconsistency([!989](https://gitee.com/mindspore/mindspore/pulls/989)).\n- GPU platform\n    - Fix summary for gradient collection ([!1364](https://gitee.com/mindspore/mindspore/pulls/1364))\n    - Fix the slice operator ([!1489](https://gitee.com/mindspore/mindspore/pulls/1489))\n- Data processing\n    - Fix memory problems of GeneratorDataset of sub-process ([!907](https://gitee.com/mindspore/mindspore/pulls/907))\n    - Fix getting data timeout when training the cifar10 dataset under the lenet([!1391](https://gitee.com/mindspore/mindspore/pulls/1391))\n\n## Contributors\n\nThanks goes to these wonderful people:\n\nAlexey Shevlyakov, Amir Lashkari, anthony, baihuawei, biffex, buxue, caifubi, candanzg, caojian05, Cathy Wong, changzherui, chenfei, chengxianbin, chenhaozhe, chenzomi, chujinjin, cristoval, dengwentao, eric, etone-chan, fary86, gaojing, gengdongjie, gongchen, guohongzilong, guozhijian, heleiwang, hesham, He Wei, Hoai Linh Tran, hongxing, huangdongrun, huanghui, Jamie Nisbet, Jesse Lee, jiangjinsheng, jiangzhiwen, jinyaohui, jjfeing, jonwe, jonyguo, Junhan Hu, Kang, kingfo, kswang, laiyongqiang, leopz, lichenever, lihongkang, limingqi107, liubuyu, liuliyan2, liuwenhao4, liuxiao, liuxiao, liyong, lizhenyu, lvliang, Margaret_wangrui, meixiaowei, ms_yan, Nat Sutyanyong, ougongchang, panfengfeng, panyifeng, Peilin Wang, peixu_ren, qianlong, rick_sanchez, seatea, sheng, shijianning, simson, sunsuodong, Tinazhang, VectorSL, wandongdong, wangcong, wanghua, wangnan39, Wei Luning, wenchunjiang, wilfChen, WilliamLian, wsc, wukesong, wuxuejian, Xiaoda Zhang, xiefangqi, xulei2020, Yang, yangjie159, yangruoqi713, yangyongjie, yangzhenzhang, Yanjun Peng, yanzhenxiang2020, yao_yf, Yi Huaijie, yoonlee666, yujianfeng, YuJianfeng, yvetteliu, zhangdengcheng, Zhang Qinghua, zhangz0911gm, zhaojichen, zhaoting, zhaozhenlong, zhoufeng, zhouneng, zhousiyi, zhouyuanshen, Zirui Wu, Ziyan, zjun, ZPaC, lihongzhang\n\nContributions of any kind are welcome!\n\n# MindSpore 0.2.0-alpha Release Notes\n\n## Major Features and Improvements\n\n### Ascend 910 Training and Inference Framework\n\n- New models\n    - MobileNetV2: Inverted Residuals and Linear Bottlenecks.\n    - ResNet101: Deep Residual Learning for Image Recognition.\n\n- Frontend and User Interface\n    - Support for all python comparison operators.\n    - Support for math operators **,//,%. Support for other python operators like and/or/not/is/is not/ in/ not in.\n    - Support for the gradients of function with variable arguments.\n    - Support for tensor indexing assignment for certain indexing type.\n    - Support for dynamic learning rate.\n    - User interfaces change log\n        - DepthwiseConv2dNative, DepthwiseConv2dNativeBackpropFilter, DepthwiseConv2dNativeBackpropInput([!424](https://gitee.com/mindspore/mindspore/pulls/424))\n        - ReLU6, ReLU6Grad([!224](https://gitee.com/mindspore/mindspore/pulls/224))\n        - GeneratorDataset([!183](https://gitee.com/mindspore/mindspore/pulls/183))\n        - VOCDataset([!477](https://gitee.com/mindspore/mindspore/pulls/477))\n        - MindDataset, PKSampler([!514](https://gitee.com/mindspore/mindspore/pulls/514))\n        - map([!506](https://gitee.com/mindspore/mindspore/pulls/506))\n        - Conv([!226](https://gitee.com/mindspore/mindspore/pulls/226))\n        - Adam([!253](https://gitee.com/mindspore/mindspore/pulls/253))\n        - _set_fusion_strategy_by_idx,_set_fusion_strategy_by_size([!189](https://gitee.com/mindspore/mindspore/pulls/189))\n        - CheckpointConfig([!122](https://gitee.com/mindspore/mindspore/pulls/122))\n        - Constant([!54](https://gitee.com/mindspore/mindspore/pulls/54))\n- Executor and Performance Optimization\n    - Support parallel execution of data prefetching and forward/backward computing.\n    - Support parallel execution of gradient aggregation and forward/backward computing in distributed training scenarios.\n    - Support operator fusion optimization.\n    - Optimize compilation process and improve the performance.\n- Data processing, augmentation, and save format\n    - Support multi-process of GeneratorDataset/PyFunc for high performance\n    - Support variable batchsize\n    - Support new Dataset operators, such as filter,skip,take,TextLineDataset\n\n### Other Hardware Support\n\n- GPU platform\n    - Use dynamic memory pool by default on GPU.\n    - Support parallel execution of computation and communication.\n    - Support continuous address allocation by memory pool.\n- CPU platform\n    - Support for windows 10 OS.\n\n## Bugfixes\n\n- Models\n    - Fix mixed precision bug for VGG16 model ([!629](https://gitee.com/mindspore/mindspore/pulls/629)).\n- Python API\n    - Fix ControlDepend operator bugs on CPU and GPU ([!396](https://gitee.com/mindspore/mindspore/pulls/396)).\n    - Fix ArgMinWithValue operator bugs ([!338](https://gitee.com/mindspore/mindspore/pulls/338)).\n    - Fix Dense operator bugs on PyNative mode ([!276](https://gitee.com/mindspore/mindspore/pulls/276)).\n    - Fix MatMul operator bugs on PyNative mode ([!288](https://gitee.com/mindspore/mindspore/pulls/288)).\n- Executor\n    - Fix operator selection bugs and make it general ([!300](https://gitee.com/mindspore/mindspore/pulls/300)).\n    - Fix memory reuse bug for GetNext op ([!291](https://gitee.com/mindspore/mindspore/pulls/291)).\n- GPU platform\n    - Fix memory allocation in multi-graph scenarios ([!444](https://gitee.com/mindspore/mindspore/pulls/444)).\n    - Fix bias_add_grad under fp16 precision ([!598](https://gitee.com/mindspore/mindspore/pulls/598)).\n    - Fix support for fp16 kernels on nvidia 1080Ti([!571](https://gitee.com/mindspore/mindspore/pulls/571)).\n    - Fix parsing of tuple type parameters ([!316](https://gitee.com/mindspore/mindspore/pulls/316)).\n- Data processing\n    - Fix TypeErrors about can't pickle mindspore._c_dataengine.DEPipeline objects([!434](https://gitee.com/mindspore/mindspore/pulls/434)).\n    - Add TFRecord file verification([!406](https://gitee.com/mindspore/mindspore/pulls/406)).\n\n## Contributors\n\nThanks goes to these wonderful people:\n\nAlexey_Shevlyakov, Cathy, Chong, Hoai, Jonathan, Junhan, JunhanHu, Peilin, SanjayChan, StrawNoBerry, VectorSL, Wei, WeibiaoYu, Xiaoda, Yanjun, YuJianfeng, ZPaC, Zhang, ZhangQinghua, ZiruiWu, amongo, anthonyaje, anzhengqi, biffex, caifubi, candanzg, caojian05, casgj, cathwong, ch-l, chang, changzherui, chenfei, chengang, chenhaozhe, chenjianping, chentingting, chenzomi, chujinjin, dengwentao, dinghao, fanglei, fary86, flywind, gaojing, geekun, gengdongjie, ghzl, gong, gongchen, gukecai, guohongzilong, guozhijian, gziyan, h.farahat, hesham, huangdongrun, huanghui, jiangzhiwen, jinyaohui, jjfeing, jojobugfree, jonathan_yan, jonyguo, jzw, kingfo, kisnwang, laiyongqiang, leonwanghui, lianliguang, lichen, lichenever, limingqi107, liubuyu, liuxiao, liyong, liyong126, lizhenyu, lupengcheng, lvliang, maoweiyong, ms_yan, mxm, ougongchang, panfengfeng, panyifeng, pengyanjun, penn, qianlong, seatea, simson, suteng, thlinh, vlne-v1, wangchengke, wanghua, wangnan39, wangqiuliang, wenchunjiang, wenkai, wukesong, xiefangqi, xulei, yanghaitao, yanghaoran, yangjie159, yangzhenzhang, yankai10, yanzhenxiang2020, yao_yf, yoonlee666, zhangbuxue, zhangz0911gm, zhangzheng, zhaojichen, zhaoting, zhaozhenlong, zhongligeng, zhoufeng, zhousiyi, zjun, zyli2020, yuhuijun, limingqi107, lizhenyu, chenweifeng.\n\nContributions of any kind are welcome!\n\n# MindSpore 0.1.0-alpha Release Notes\n\n## Main Features\n\n### Ascend 910 Training and Inference Framework\n\n- Recommended OS: Ubuntu 16.04 (or later) or EulerOS 2.5 or EulerOS 2.8\n- Python version: 3.7.5\n- Preset models\n    - ResNet-50: residual structure-based convolutional neural network (CNN) for image classification, which is widely used.\n    - AlexNet: classic CNN for image classification, achieving historical results in ImageNet LSVRC-2012.\n    - LeNet: classic CNN for image classification, which was proposed by Yann LeCun.\n    - VGG16: classic CNN for image classification, which was proposed by Oxford Visual Geometry Group.\n    - YoloV3: real-time object detection network.\n    - NEZHA: BERT-based Chinese pre-training network produced by Huawei Noah's Ark Laboratory.\n- Execution modes\n    - Graph mode: provides graph optimization methods such as memory overcommitment, IR fusion, and buffer fusion to achieve optimal execution performance.\n    - PyNative mode: single-step execution mode, facilitating process debugging.\n- Debugging capability and methods\n    - Save CheckPoints and Summary data during training.\n    - Support asynchronous printing.\n    - Dump the computing data.\n    - Support profiling analysis of the execution process performance.\n- Distributed execution\n    - Support AllReduce, AllGather, and BroadCast collective communication.\n    - AllReduce data parallel: Each device obtains different training data, which accelerates the overall training process.\n    - Collective communication-based layerwise parallel: Models are divided and allocated to different devices to solve the problem of insufficient memory for large model processing and improve the training speed.\n    - Automatic parallel mode: The better data and model parallel mode can be predicted based on the cost model. It is recommended that this mode be used on ResNet series networks.\n- Automatic differentiation\n    - Implement automatic differentiation based on Source to Source.\n    - Support distributed scenarios and automatic insertion of reverse communication operators.\n- Data processing, augmentation, and save format\n    - Load common datasets such as ImageNet, MNIST, CIFAR-10, and CIFAR-100.\n    - Support common data loading pipeline operations, such as shuffle, repeat, batch, map, and sampler.\n    - Provide basic operator libraries to cover common CV scenarios.\n    - Support users to customize Python data augmentation operators through the Pyfunc mechanism.\n    - Support the access of user-defined datasets through the GeneratorDataset mechanism.\n    - Provide the MindSpore data format, data aggregation and storage, random access example, data partition, efficient parallel read, user-defined index, and dataset search.\n    - Convert user datasets to the MindSpore data format.\n    - After data processing and augmentation, provide training applications in feed and graph modes.\n- FP32/16 mixed precision computation, supporting automatic and manual configuration\n- Provide common operators such as nn, math, and array, which can be customized.\n\n### Inference Deployment\n\n- Deploy models in MindSpore format on the Ascend 310 platform for inference.\n- Save models in ONNX format.\n- Support saving models in LITE format and running models based on the lightweight inference framework.\n    - Recommended OS: Android 4.3 or later\n    - Supported network type: LeNet\n    - Provide the generalization operators generated by TVM and operators generated after specific networks are tuned.\n\n### Other Hardware Support\n\n- GPU platform training\n    - Recommended OS: Ubuntu 16.04\n    - CUDA version: 9.2 or 10.1\n    - CuDNN version: 7.6 or later\n    - Python version: 3.7.5\n    - NCCL version: 2.4.8-1\n    - OpenMPI version: 3.1.5\n    - Supported models: AlexNet, LeNet, and LSTM\n    - Supported datasets: MNIST and CIFAR-10\n    - Support data parallel.\n- CPU platform training\n    - Recommended OS: Ubuntu 16.04\n    - Python version: 3.7.5\n    - Supported model: LeNet\n    - Supported dataset: MNIST\n    - Provide only the stand-alone operation version.\n\n## Peripherals and Tools\n\n- [MindSpore Official Website](https://www.mindspore.cn/)\n- [MindInsight Visualization Debugging and Optimization](https://gitee.com/mindspore/mindinsight)\n- [MindArmour Model Security Hardening Package](https://gitee.com/mindspore/mindarmour)\n- [GraphEngine Computational Graph Engine](https://gitee.com/mindspore/graphengine)\n"
        },
        {
          "name": "RELEASE_CN.md",
          "type": "blob",
          "size": 152.6240234375,
          "content": "# MindSpore Release Notes\n\n[View English](./RELEASE.md)\n\n## MindSpore 2.3.0 Release Notes\n\n### 主要特性及增强\n\n#### AutoParallel\n\n- [STABLE] 扩展函数式并行能力，[mindspore.shard](https://www.mindspore.cn/docs/zh-CN/r2.3.0/api_python/mindspore/mindspore.shard.html)新增支持图模式，图模式下以nn.Cell/function为单位设置输入与权重的并行切分策略，未设置的算子将通过\"sharding_propagation\"自动配置并行策略；增加支持手动重排布的[mindspore.reshard](https://www.mindspore.cn/docs/zh-CN/r2.3.0/api_python/mindspore/mindspore.reshard.html)接口，通过[mindspore.Layout](https://www.mindspore.cn/docs/zh-CN/r2.3.0/api_python/mindspore/mindspore.Layout.html)对张量设置精准切分策略。\n- [STABLE] 新增Callback接口[mindspore.train.FlopsUtilizationCollector](https://www.mindspore.cn/docs/zh-CN/r2.3.0/api_python/train/mindspore.train.FlopsUtilizationCollector.html)统计模型算力利用率信息MFU和硬件算力利用率信息HFU 。\n- [STABLE] 新增函数式通信接口[mindspore.communication.comm_func](https://www.mindspore.cn/docs/zh-CN/r2.3.0/api_python/mindspore.communication.comm_func.html)。\n- [BETA] O0和O1模式下，优化interleaved pipeline的内存占用。\n- [BETA] 自动并行模式下支持多机场景自动流水线策略生成（暂不支持单机场景自动流水线策略生成），需要将 `parallel_mode` 设置成自动并行 ``auto_parallel`` 并将 `search_mode` 设置成双递归算法 ``recursive_programming``。\n\n#### PyNative\n\n- [STABLE] 优化动态图的基础数据结构，提升算子API性能。\n- [STABLE] Tensor支持[register_hook](https://www.mindspore.cn/docs/zh-CN/r2.3.0/api_python/mindspore/Tensor/mindspore.Tensor.register_hook.html)功能，以便用户打印或者修改Tensor对应的梯度。\n- [STABLE] PyNative模式支持重计算功能，用户可以通过重计算接口降低网络的显存峰值。\n\n#### FrontEnd\n\n- [STABLE] 优化Checkpoint保存、加载基础流程，提升性能20%。\n- [STABLE] 支持在保存、加载过程中对Checkpoint文件进行CRC校验，提升安全性。\n\n#### Dataset\n\n- [STABLE] 为以下数据增强增加昇腾处理后端支持：Equalize、Rotate、AutoContrast、Posterize、AdjustSharpness、Invert、Solarize、ConvertColor、Erase。\n- [STABLE] 增加视频文件读取、解析功能支持，详见API：[mindspore.dataset.vision.DecodeVideo](https://www.mindspore.cn/docs/zh-CN/r2.3.0/api_python/dataset_vision/mindspore.dataset.vision.DecodeVideo.html)、[mindspore.dataset.vision.read_video](https://www.mindspore.cn/docs/zh-CN/r2.3.0/api_python/dataset_vision/mindspore.dataset.vision.read_video.html#mindspore.dataset.vision.read_video)、[mindspore.dataset.vision.read_video_timestamps](https://www.mindspore.cn/docs/zh-CN/r2.3.0/api_python/dataset_vision/mindspore.dataset.vision.read_video_timestamps.html#mindspore.dataset.vision.read_video_timestamps)。\n- [STABLE] 支持在 `mindspore.dataset.GeneratorDataset`、`mindspore.dataset.Dataset.map` 及 `mindspore.dataset.Dataset.batch` 接口中指定 `max_rowsize` 参数为-1，此时数据多进程所使用的共享内存将随数据大小动态分配并高效运行，无需手动调参。\n\n#### Inference\n\n- [STABLE] 新增LLaMa2、LLaMa3、Qwen1.5等14个大模型支持训推一体架构，实现脚本、分布式策略和运行时的统一，典型大模型训练到推理部署周期下降到天级，通过融合大算子降低推理时延，有效提升网络吞吐量。\n\n#### PIJIT\n\n- [BETA] 支持Python 3.8和Python 3.10的字节码解析，扩大Python版本的支持范围。\n- [BETA] 支持Dynamic Shape、Symbolic Shape作为输入，使能动态输入场景。\n- [BETA] 使能单步构图能力，优化编译时间。\n- [BETA] 通过调整字节码支持了带有副作用的字节码被捕获（STORE_ATTR、STORE_GLOBAL、LIST_APPEND、dict.pop），使能自动混合精度，减少裂图，提升性能。\n\n#### Profiler\n\n- [STABLE] 提供分级Profiler功能，通过profiler_level参数可控制按照不同级别进行性能数据采集。\n- [STABLE] Profiler analyse方法新增mode参数，可配置异步解析模式，性能数据解析与训练并行。\n- [STABLE] Profiler接口新增data_simplification参数，用户可控制性能数据解析完成后是否删除多余数据，节省硬盘空间。\n- [STABLE] Profiler接口增强内存分析功能，用户通过profile_memory参数可采集框架、CANN、硬件的内存申请、释放信息，并可通过[MindStudio工具](https://www.hiascend.com/forum/thread-0230130822583032044-1-1.html)进行可视化分析。\n- [BETA] PyNative模式下Timeline整合host profiling信息，包括任务耗时、用户侧堆栈信息。\n\n#### Dump\n\n- [STABLE] 增强同步和异步Dump功能，统计信息Dump新增L2Norm信息、新增statistic_category字段支持用户自定义需要保存的统计信息，提高Dump易用性。同步和异步Dump支持情况可参考[Dump功能说明](https://www.mindspore.cn/tutorials/experts/zh-CN/r2.3.0/debug/dump.html#dump功能说明)。\n- [STABLE] 完善同步Dump功能，通过配置op_debug_mode字段使能溢出和异常Dump。\n- [STABLE] 增强同步Dump功能，通过配置stat_calc_mode字段可以使能device计算统计信息（默认在host计算），通过配置sample_mode字段可以进行采样Dump，提升Dump性能。\n- [STABLE] 增强异步Dump功能，支持保存complex64和complex128格式。\n\n#### Runtime\n\n- [STABLE] 支持静态图多级编译，配置为[mindspore.set_context(jit_config={\"jit_level\": \"O0/O1/O2\"})](https://www.mindspore.cn/docs/zh-CN/r2.3.0/api_python/mindspore/mindspore.set_context.html)，默认值为空，框架根据产品类别自动选择优化级别，Altas训练产品为O2，其余产品均为O0。\n- [STABLE] 静态图O0/O1下支持通信计算多流并发执行。\n- [STABLE] 新增[内存管理接口](https://www.mindspore.cn/docs/zh-CN/r2.3.0/api_python/mindspore.hal.html#内存管理)。\n- [BETA] 内存池支持虚拟内存碎片整理，在静态图O0/O1下默认使能虚拟内存。\n\n#### Ascend\n\n- [STABLE] 提供昇腾平台上算子内存越界访问检测开关，用户可以通过设置 `mindspore.set_context(ascend_config={\"op_debug_option\": \"oom\"})`来检测昇腾平台上算子内部内存越界问题。\n- [BETA] 环境变量[MS_SIMULATION_LEVEL](https://www.mindspore.cn/docs/zh-CN/r2.3.0/note/env_var_list.html)在昇腾平台上新增支持图编译O0执行模式，并可支持编译性能和运行时内存分析。\n- [BETA] 昇腾平台支持通过AOT接入使用[AscendC自定义算子](https://www.mindspore.cn/tutorials/experts/zh-CN/r2.3.0/operation/op_custom_ascendc.html)。\n\n### API变更\n\n#### 新增API\n\n- [STABLE] 新增[mindspore.mint](https://www.mindspore.cn/docs/zh-CN/r2.3.0/api_python/mindspore.mint.html)API，提供了大量的functional、nn、优化器接口，API用法及功能等与业界主流用法一致，方便用户参考使用。mint接口当前是实验性接口，在图编译模式为O0和PyNative模式下性能比ops更优。当前暂不支持图下沉模式及CPU、GPU后端，后续会逐步完善。\n\n  | mindspore.mint  |  |   | |\n  |:----|:----|:----|:----|\n  | mindspore.mint.eye |mindspore.mint.rand_like|mindspore.mint.isfinite|mindspore.mint.any|\n  | mindspore.mint.ones |mindspore.mint.rand|mindspore.mint.log|mindspore.mint.greater_equal|\n  | mindspore.mint.ones_like |mindspore.mint.gather|mindspore.mint.logical_and|mindspore.mint.all|\n  | mindspore.mint.zeros |mindspore.mint.permute|mindspore.mint.logical_not|mindspore.mint.mean|\n  | mindspore.mint.zeros_like |mindspore.mint.repeat_interleave|mindspore.mint.logical_or|mindspore.mint.prod|\n  | mindspore.mint.arange |mindspore.mint.abs|mindspore.mint.mul|mindspore.mint.sum|\n  | mindspore.mint.broadcast_to |mindspore.mint.add|mindspore.mint.neg|mindspore.mint.eq|\n  | mindspore.mint.cat |mindspore.mint.clamp|mindspore.mint.negative|mindspore.mint.ne|\n  | mindspore.mint.index_select |mindspore.mint.cumsum|mindspore.mint.pow|mindspore.mint.greater|\n  | mindspore.mint.max |mindspore.mint.atan2|mindspore.mint.reciprocal|mindspore.mint.gt|\n  | mindspore.mint.min |mindspore.mint.arctan2|mindspore.mint.rsqrt|mindspore.mint.isclose|\n  | mindspore.mint.scatter_add |mindspore.mint.ceil|mindspore.mint.sigmoid|mindspore.mint.le|\n  | mindspore.mint.narrow |mindspore.mint.unique|mindspore.mint.sin|mindspore.mint.less_equal|\n  | mindspore.mint.nonzero |mindspore.mint.div|mindspore.mint.sqrt|mindspore.mint.lt|\n  | mindspore.mint.normal |mindspore.mint.divide|mindspore.mint.square|mindspore.mint.maximum|\n  | mindspore.mint.tile |mindspore.mint.erf|mindspore.mint.sub|mindspore.mint.minimum|\n  | mindspore.mint.topk |mindspore.mint.erfinv|mindspore.mint.tanh|mindspore.mint.inverse|\n  | mindspore.mint.sort |mindspore.mint.exp|mindspore.mint.bmm|mindspore.mint.searchsorted|\n  | mindspore.mint.stack |mindspore.mint.floor|mindspore.mint.matmul|mindspore.mint.argmax|\n  | mindspore.mint.where |mindspore.mint.flip|mindspore.mint.split|mindspore.mint.cos|\n  | mindspore.mint.less |||\n\n  | mindspore.mint.nn|\n  |:----|\n  | mindspore.mint.nn.Dropout  |\n  | mindspore.mint.nn.Unfold |\n  | mindspore.mint.nn.Fold |\n  | mindspore.mint.nn.Linear|\n  | mindspore.mint.nn.BCEWithLogitsLoss |\n\n  | mindspore.mint.nn.functional||\n  |:----|:----|\n  |mindspore.mint.nn.functional.batch_norm |mindspore.mint.nn.functional.group_norm|\n  |mindspore.mint.nn.functional.fold |mindspore.mint.nn.functional.layer_norm|\n  |mindspore.mint.nn.functional.max_pool2d |mindspore.mint.nn.functional.linear|\n  |mindspore.mint.nn.functional.binary_cross_entropy |mindspore.mint.nn.functional.unfold|\n  |mindspore.mint.nn.functional.sigmoid |mindspore.mint.nn.functional.one_hot|\n  |mindspore.mint.nn.functional.tanh |mindspore.mint.nn.functional.elu|\n  |mindspore.mint.nn.functional.binary_cross_entropy_with_logits |mindspore.mint.nn.functional.gelu|\n  |mindspore.mint.nn.functional.dropout|mindspore.mint.nn.functional.leaky_relu|\n  |mindspore.mint.nn.functional.embedding  |mindspore.mint.nn.functional.silu|\n  |mindspore.mint.nn.functional.grid_sample|mindspore.mint.nn.functional.softplus|\n  |mindspore.mint.nn.functional.relu|mindspore.mint.nn.functional.softmax|\n  |mindspore.mint.nn.functional.pad||\n\n  | mindspore.mint.optim |\n  |:----|\n  | mindspore.mint.optim.AdamW |\n\n  | mindspore.mint.linalg |\n  |:----|\n  | mindspore.mint.linalg.inv |\n\n### 非兼容性接口变更\n\n- 接口名称：性能数据采集接口 `Profiler`\n\n  变更内容：解析生成的性能数据文件进行了精简，将在导出性能数据后删除FRAMEWORK目录数据以及其他多余数据，仅保留profiler的交付件以及PROF_XXX目录下的原始性能数据，以节省空间。通过将 `data_simplification`参数配置为 `False`可关闭精简模式，与历史版本生成的性能数据文件保持一致。\n- 接口名称：Dump功能配置文件中的 `saved_data` 字段为 `\"tensor\"`。\n\n  变更内容：Dump落盘的文件名发生变更，`\"/\"`用 `\"_\"`代替，算子名称变为算子全局名称。\n\n  <table>\n  <tr>\n  <td style=\"text-align:center\"> 原文件名 </td> <td style=\"text-align:center\"> 2.3文件名 </td>\n  </tr>\n  <tr>\n  <td><pre>\n  文件名格式：\n  {op_type}.{op_name}.{task_id}.{stream_id}.\n  {timestamp}.{input_output_index}.{slot}.{format}.npy\n  </br>\n  示例：\n  Conv2D.Conv2D-op12.0.0.1623124369613540.\n  output.0.DefaultFormat.npy\n  </pre>\n  </td>\n  <td><pre>\n  文件名格式：\n  {op_type}.{op_name}.{task_id}.{stream_id}.\n  {timestamp}.{input_output_index}.{slot}.{format}.npy\n  </br>\n  示例：\n  Conv2D.Default_network-WithLossCell__backbone-AlexNet_conv3\n  -Conv2d_Conv2D-op12.0.0.1623124369613540.output.0.DefaultFormat.npy\n  </pre>\n  </td>\n  </tr>\n  </table>\n- 接口名称：Dump功能配置文件中的 `saved_data`字段为 `\"statistic\"`。\n\n  变更内容：原默认保存 `\"max\"`、`\"min\"`、`\"avg\"`、`\"count\"`、`\"negative zero count\"`、`\"positive zero count\"`、`\"nan count\"`、`\"negative inf count\"`、`\"positive inf count\"`、`\"zero count\"`、`md5`统计项，2.3变更为默认保存 `\"max\"`、`\"min\"`、`\"l2norm\"`统计项，可以通过配置 `statistic_category`自定义统计项。\n\n### 贡献者\n\ncaifubi;candanzg;ccsszz;chaiyouheng;changzherui;chenfei_mindspore;chengbin;chengfeng27;Chong;dairenjie;DavidFFFan;DeshiChen;dingjinshan;douzhixing;emmmmtang;Erpim;fary86;fengyixing;fuhouyu;gaoyong10;GuoZhibin;guozhijian;halo;haozhang;hejianheng;Henry Shi;horcham;huandong1;huangbingjian;Jackson_Wong;jiangchenglin3;jiangshanfeng;jiangzhenguang;jiaorui;bantao;jiaxueyu;jijiarong;JuiceZ;jxl;kairui_kou;lanzhineng;LiangZhibo;lichen;limingqi107;linqingke;liubuyu;liujunzhu;liuluobin;liyan2022;liyejun;LLLRT;looop5;lujiale;luochao60;luoyang;lvxudong;machenggui;maning202007;Margaret_wangrui;master_2;mengyuanli;moran;Mrtutu;NaCN;nomindcarry;panzhihui;pengqi;qiuyufeng;qiuzhongya;Renyuan Zhang;shaoshengqi;Shawny;shen_haochen;shenhaojing;shenwei41;shij1anhan;shilishan;shiziyang;shunyuanhan;shuqian0;TAJh;tanghuikang;tan-wei-cheng;Thibaut;tianxiaodong;TronZhang;TuDouNi;VectorSL;wang_ziqi;wanghenchang;wangjie;weiyang;wudawei;wujiangming;wujueying;XianglongZeng;xiaotianci;xiaoxin_zhang;xiaoxiongzhu;xiaoyao;XinDu;xuxinglei;yangchen;yanghaoran;yanglong;yangruoqi713;yangzhenzhang;yangzishuo;Yanzhi_YI;yao_yf;yefeng;yide12;YijieChen;YingLai Lin;yuchaojie;YuJianfeng;zangqx;zhaiyukun;zhangminli;zhangqinghua;ZhangZGC;zhengxinQian;zhengzuohe;zhouyaqiang0;zhuguodong;zhupuxu;zichun_ye;zjun;zlq2020;ZPaC;zuochuanyong;zyli2020;阿琛;狄新凯;范吉斌;冯一航;胡彬;宦晓玲;黄勇;康伟;雷仪婧;李良灿;李林杰;刘崇鸣;刘力力;刘勇琪;刘子涵;吕浩宇;王禹程;熊攀;徐安越;徐永飞;俞涵;张王泽;张栩浩;郑裔;周莉莉;周先琪;朱家兴;邹文祥\n\n欢迎以任何形式对项目提供贡献！\n\n## MindSpore 2.3.0-rc2 Release Notes\n\n### 主要特性和增强\n\n#### AutoParallel\n\n- [STABLE] Transpose/Sub/Add/Mul/Div/ReLU/Softmax/Sigmoid算子支持配置Layout。\n- [STABLE] 集合通信精度会影响网络收敛，在接口mindspore.set_auto_parallel_context提供配置项[force_fp32_communication](https://www.mindspore.cn/docs/zh-CN/r2.3.0rc2/api_python/mindspore/mindspore.set_auto_parallel_context.html)，设为True时可以强制将reduce类通信算子的通信类型转为float32。\n- [BETA] pipeline并行支持Interleave调度，优化micro batch大小受限场景下的模型性能。\n- [BETA] 优化pipeline并行场景下提高模型转换速度，支持单个stage单独转换。\n\n#### PyNative\n\n- [BETA] 动态图下支持[重计算](https://www.mindspore.cn/docs/zh-CN/r2.3.0rc2/api_python/mindspore/mindspore.recompute.html)功能。\n- [STABLE] 动态图下支持[register_hook](https://www.mindspore.cn/docs/zh-CN/r2.3.0rc2/api_python/mindspore/Tensor/mindspore.Tensor.register_hook.html#mindspore.Tensor.register_hook)功能。\n\n### API变更\n\n增加[动态组网](https://www.mindspore.cn/tutorials/experts/zh-CN/r2.3.0rc2/parallel/dynamic_cluster.html)场景下各类超时时间环境变量配置：\n\n- `MS_TOPO_TIMEOUT`： 集群组网阶段超时时间，单位：秒。\n- `MS_NODE_TIMEOUT`：节点心跳超时时间，单位：秒。\n- `MS_RECEIVE_MSG_TIMEOUT`：节点接收消息超时时间，单位：秒。\n\n新增环境变量 `MS_ENABLE_LCCL`，支持昇腾后端单机多卡场景下使用LCCL通信库。\n\n### 问题修复\n\n- [#I9CR96](https://gitee.com/mindspore/mindspore/issues/I9CR96) 修复在大规模集群下，动态组网启动方式的超时时间不足导致集群启动失败的问题。\n- [#I94AQQ](https://gitee.com/mindspore/mindspore/issues/I94AQQ) 修复ops.Addcdiv算子在图模式下输出shape有误问题。\n\n### 贡献者\n\n感谢以下人员做出的贡献:\n\nbantao,caifubi,changzherui,chenfei_mindspore,chenweifeng,dairenjie,dingjinshan,fangzehua,fanyi20,fary86,GuoZhibin,hanhuifeng,haozhang,hedongdong,Henry Shi,huandong1,huangbingjian,huoxinyou,jiangchenglin3,jiangshanfeng,jiaorui,jiaxueyu,jxl,kairui_kou,lichen,limingqi107,liuluobin,LLLRT,looop5,luochao60,luojianing,maning202007,NaCN,niyuxin94520,nomindcarry,shiziyang,tanghuikang,TronZhang,TuDouNi,VectorSL,wang_ziqi,wanghenchang,wudawei,XianglongZeng,xiaoxiongzhu,xiaoyao,yanghaoran,Yanzhi_YI,yao_yf,yide12,YijieChen,YingLai Lin,yuchaojie,YuJianfeng,zangqx,zhanghanLeo,ZhangZGC,zhengzuohe,zhouyaqiang0,zichun_ye,zjun,ZPaC,zyli2020,冯一航,李林杰,刘力力,王禹程,俞涵,张栩浩,朱家兴,邹文祥\n\n欢迎以任何形式对项目提供贡献！\n\n## MindSpore Lite 2.3.0-rc2 Release Notes\n\n### 主要特性和增强\n\n- [STABLE] 支持云侧转换工具所用的配置文件配置FlashAttention相关属性。\n- [STABLE] 支持在多张卡上进行内存共享。\n\n### 贡献者\n\n感谢以下人员做出的贡献:\n\nemmmmtang,熊攀\n\n欢迎以任何形式对项目提供贡献！\n\n## MindSpore 2.3.0-rc1 Release Notes\n\n### 主要特性及增强\n\n#### DataSet\n\n- [STABLE] MindRecord模块增加完整性校验、加解密功能，以此保护用户数据的完整性与安全性。\n- [STABLE] MindRecord接口变更：废弃FileWriter.open_and_set_header接口，因为其功能已内置到FilterWriter类，若使用旧版本代码将报错，删除此调用即可；FileWriter增加写入数据类型校验，以确保Schema定义的数据类型与真实数据类型匹配；Mindrecord组件下所有类方法去除返回值，若处理出错以异常方式提示用户。\n- [STABLE] 为以下数据增强增加Ascend处理后端支持：ResizedCrop、HorizontalFlip、VerticalFlip、Perspective、Crop、Pad、GaussianBlur、Affine。\n- [STABLE] 优化了模型迁移场景中数据迁移部分的指南，提供更多与第三方库框架对比的例子。\n- [STABLE] 优化了TFRecordDataset在多数据列场景下解析效率，提升解析性能 20%。\n\n#### PIJIT\n\n- [BETA] PIJit通过对Python字节码进行分析&调整、执行流进行图捕获&图优化，支持的Python代码做静态图方式执行，不支持的进行子图切分以动态图方式执行，自动地做到动静统一。用户可以通过@jit(mode=\"PIJit\", jit_config={options:value})对函数进行装饰来开启PIJit。\n\n#### Inference\n\n- [DEMO] 大模型推理升级训推一体架构，实现脚本、分布式策略和运行时的统一，典型大模型训练到推理部署周期下降到天级，通过融合大算子降低推理时延，有效提升网络吞吐量。\n\n#### AutoParallel\n\n- [STABLE] 新增msrun启动方式，支持单指令拉起分布式任务。\n- [STABLE] 添加RankTable启动方式即将废弃的提示。\n- [STABLE] 图模式下消除冗余常量，提升编译性能和内存开销。\n- [STABLE] 子图场景优化器并行首个子图inline，使得流水并行下的一些计算和通信掩盖可以进行。\n- [STABLE] 通信信息导出，编译期间导出模型通信信息（通信域、通信量），输入给集群作为通信调度的依据。\n- [STABLE] 流水线并行推理优化，去除共享权重在stage间转发，提升执行性能；支持流水线并行推理结果自动广播，提升自回归推理易用性。\n- [STABLE] 算子级并行切分支持配置MatMul/Add/LayerNorm/GeLU/BiasAdd算子的切分时的设备排布与张量排布的映射关系。\n- [STABLE] 支持数据并行维度的梯度通信与反向计算互相掩盖功能。\n- [STABLE] 单卡模拟编译，用于模拟多卡分布式训练中某张卡的编译流程，辅助分析前后端各编译流程和内存占用。\n- [STABLE] ops.Tril算子支持切分，从而降低对单个device的内存与性能需求。\n- [BETA] 支持通信算子和计算算子融合，掩盖通信开销，提升网络性能。\n- [BETA] 故障恢复时，checkpoint加载与编译并行从而减少故障恢复时间。\n\n#### Runtime\n\n- [BETA] 支持O0/O1/O2多级编译，提升静态图调试调优能力。\n\n#### FrontEnd\n\n- [STABLE] 框架新增对bfloat16数据类型的支持，创建Tensor时可以指定dtype=mindspore.bfloat16。\n- [STABLE] 完善rewrite组件的语法支持能力，新增支持对类变量、函数、控制流等语法的解析。\n- [STABLE] 新增context配置项：debug_level，用户可以使用mindspore.set_context(debug_level=mindspore.DEBUG)来获取更多调试信息。\n\n#### Profiler\n\n- [BETA] 动态启停profiling，用户可以根据训练情况实时采集profiling 数据，减少采集数据量。\n- [BETA] Profiling通信算子耗时矩阵，用户通过分析通信算子耗时矩阵，找出集群通信性能瓶颈。\n- [BETA] 提高昇腾环境解析Profiling数据的性能。\n- [BETA] 支持离线解析Profiling生成的数据，用户可以先采集数据，然后根据需要再解析数据。\n- [BETA] 支持采集HBM、PCIe、l2_cache性能数据，丰富性能分析指标。\n\n#### Dump\n\n- [BETA] Dump保存的统计信息记录MD5值，用户可以通过MD5值确定张量值的微小差异。\n- [BETA] Dump支持bfloat16数据类型，支撑用户定位bfloat16类型的算子精度问题。\n\n#### PyNative\n\n- [STABLE] 重构动态图下单算子调用流程，优化前端算子下发粒度，提升动态图性能。\n\n#### Ascend\n\n- [BETA] 支持用户设置CANN的options配置项，配置项分为global和session二类，用户可以通过mindspore.set_context(ascend_config={\"ge_options\": {\"global\": {\"global_option\": \"option_value\"}, \"session\": {\"session_option\": \"option_value\"}}})进行配置。\n\n#### API变更\n\n- 新增 mindspore.hal接口，开放流、事件以及设备管理能力。\n- 新增 mindspore.multiprocessing 接口，提供了创建多进程的能力。\n\n#### 算子\n\n- [BETA] mindspore.ops.TopK当前支持第二个输入k为Int32类型的张量。\n\n### 问题修复\n\n- [#I92H93] 修复了昇腾平台下使用Print算子打印字符串对象时，Print算子报错Launch kernel failed的问题。\n- [#I8S6LY] 修复了昇腾平台图模式动态shape流程下，变长输入算子（如 AddN、Concat）报错RuntimeError: Attribute dyn_input_sizes of Default/AddN-op1 is [const vector]{}, of which size is less than 0的问题。\n- [#I9ADZS] 修复了故障恢复训练场景中，由于dataset恢复效率低导致网络训练出现数据超时的问题。\n\n### 贡献者\n\n感谢以下人员做出的贡献:\n\nAlanCheng511，AlanCheng712，bantao，Bingliang，BJ-WANG，Bokai Li，Brian-K，caifubi，cao1zhg，CaoWenbin，ccsszz，chaiyouheng，changzherui，chenfei_mindspore，chengbin，chengfeng27，chengxb7532，chenjianping，chenkang，chenweifeng，Chong，chuht，chujinjin，Cynthia叶，dairenjie，DavidFFFan，DeshiChen，douzhixing，emmmmtang，Erpim，fangzhou0329，fary86，fengxun，fengyixing，fuhouyu，gaoshuanglong，gaoyong10，GaoZhenlong，gengdongjie，gent1e，Greatpan，GTT，guoqi，guoxiaokang1，GuoZhibin，guozhijian，hangq，hanhuifeng，haozhang，hedongdong，hejianheng，Henry Shi，heyingjiao，HighCloud，Hongxing，huandong1，huangbingjian，HuangLe02，huangxinjing，huangziling，hujiahui8，huoxinyou，jiangchenglin3，jianghui58，jiangshanfeng，jiaorui，jiaxueyu，JichenZhao，jijiarong，jjfeing，JoeyLin，JuiceZ，jxl，kairui_kou，kate，KevinYi，kisnwang，lanzhineng，liangchenghui，LiangZhibo，lianliguang，lichen，ligan，lihao，limingqi107，ling，linqingke，liruyu，liubuyu，liuchao，liuchengji，liujunzhu，liuluobin，liutongtong9，liuzhuoran2333，liyan2022，liyejun，LLLRT，looop5，luochao60，luojianing，luoyang，LV，machenggui，maning202007，Margaret_wangrui，MaZhiming，mengyuanli，MooYeh，moran，Mrtutu，NaCN，nomindcarry，panshaowu，panzhihui，PingqiLi，qinzheng，qiuzhongya，Rice，shaojunsong，Shawny，shenwei41，shenyaxin，shunyuanhan，silver，Songyuanwei，tangdezhi_123，tanghuikang，tan-wei-cheng，TingWang，TronZhang，TuDouNi，VectorSL，WANG Cong，wang_ziqi，wanghenchang，wangpingan，wangshaocong，wangtongyu6，weiyang，WinXPQAQ，wtcheng，wudawei，wujiangming，wujueying，wuweikang，wwwbby，XianglongZeng，xiaosh，xiaotianci，xiaoxin_zhang，xiaoxiongzhu，xiaoyao，XinDu，xingzhongfan，yanghaoran，yangluhang，yangruoqi713，yangzhenzhang，yangzishuo，yanjiaming，Yanzhi_YI，yao_yf，yefeng，yeyunpeng2020，yide12，YijieChen，YingLai Lin，YingtongHu，youshu，yuchaojie，YuJianfeng，zangqx，zby，zhaiyukun，zhangdanyang，zhanghaibo，zhanghanLeo，zhangminli，zhangqinghua，zhangyanhui，zhangyifan，zhangyinxia，zhangyongxian，ZhangZGC，zhanzhan，zhaoting，zhengyafei，zhengzuohe，ZhihaoLi，zhouyaqiang0，zhuguodong，zhumingming，zhupuxu，zichun_ye，zjun，zlq2020，ZPaC，zuochuanyong，zyli2020，陈宇，代宇鑫，狄新凯，范吉斌，冯一航，胡彬，宦晓玲，黄勇，康伟，李良灿，李林杰，刘崇鸣，刘力力，刘勇琪，吕浩宇，没有窗户的小巷，王禹程，吴蕴溥，熊攀，徐安越，徐永飞，许哲纶，俞涵，张峻源，张树仁，张王泽，张栩浩，郑裔，周莉莉，周先琪，朱家兴，邹文祥\n\n欢迎以任何形式对项目提供贡献！\n\n## MindSpore 2.2.13 Release Notes\n\n### API变更\n\n增加动态组网场景下各类超时时间环境变量配置：\n\n- `MS_TOPO_TIMEOUT`： 集群组网阶段超时时间，单位：秒。\n- `MS_CLUSTER_RETRY_NUM`：集群组网阶段节点重试注册次数。\n- `MS_NODE_TIMEOUT`：节点心跳超时时间，单位：秒。\n- `MS_RECEIVE_MSG_TIMEOUT`：节点接收消息超时时间，单位：秒。\n\n### 问题修复\n\n- [#I9CR96] 修复在大规模集群下，动态组网启动方式的超时时间不足导致集群启动失败的问题。\n\n### 贡献者\n\n感谢以下人员做出的贡献:\n\nZPaC, limingqi107, lizhenyu, jiangshanfeng\n\n欢迎以任何形式对项目提供贡献！\n\n## MindSpore 2.2.12 Release Notes\n\n### 主要特性及增强\n\n- [STABLE] 针对网络参数以fp32初始化以及开启优化器并行的场景，降低Cast算子数目。\n- [STABLE] 增加对静默故障的检测和处理能力；静默故障会导致训练过程异常，该特性帮助用户避免或大幅降低因静默故障导致的集群停机巡检进行故障定位带来的损失。\n\n### 问题修复\n\n- [#I97D1L] 修复 ReduceLROnPlateau、LRScheduler、CosineAnnealingWarmRestarts动态学习率相关接口样例错误。\n- [#I970HV] 修复多卡之间的allgather/reducescatter不保序问题。\n- [#I99JPI] 修复checkpoint在模糊匹配场景下加载类型为bfloat16 parameter的 bug。\n\n### 贡献者\n\n感谢以下人员做出的贡献:\n\nyao_yf, YijieChen, 冯一航, yuchaojie, 李良灿, YuJianfeng, huangxinjing, GuoZhibin, looop5\n\n欢迎以任何形式对项目提供贡献！\n\n## MindSpore 2.2.11 Release Notes\n\n### 主要特性及增强\n\n#### scipy\n\n- [STABLE] 新增scipy模块API mindspore.scipy.optimize.linear_sum_assignment，用于解决线性和分配问题，它可以基于一个给定的成本矩阵，找到一个成本最低的分配方案。\n\n### 问题修复\n\n- [#I8JVRU] 修复bernoulli随机数算子在GPU上跑两次的结果出现概率性一致的问题。\n- [#I8OC32] 修复MatrixSetDiagV3算子未校验异常输入，导致segmentation fault问题。\n\n### 贡献者\n\n感谢以下人员做出的贡献:\n\nfary86, wanghenchang, haozhang, mengyuanli, emmmmtang, luoyang, zhupuxu, zhangyongxian, liuluobin, LLLRT, TuDouNi, hujiahui8, wangtongyu6, ligan, zhuguodong, yanghaoran, YingtongHu, liyejun, zjun, 徐永飞, chuht, 张树仁, 徐安越, DeshiChen, shenyaxin, liujunzhu, shunyuanhan, yuchaojie, yao_yf, 没有窗户的小巷, yeyunpeng2020, weiyang, KevinYi, hedongdong, zhouyaqiang0, Margaret_wangrui, zhanghaibo, moran, huangziling, 朱家兴, GuoZhibin, 李良灿, jiaxueyu, gaoyong10, Greatpan, 宦晓玲, melody, 俞涵, jiangshanfeng, XinDu, ling, caifubi, zhangyinxia, gengdongjie, Erpim, XianglongZeng, zhangminli, fengyixing, 冯一航, 黄勇, panzhihui, 胡彬, linqingke, wangshaocong\n\n欢迎以任何形式对项目提供贡献！\n\n## MindSpore Lite 2.2.11 Release Notes\n\n### 问题修复\n\n- [#I8TPLY] 修复 SSD MobileNetV2 FPN 网络在Atlas 推理系列产品（配置 Ascend 310P AI 处理器）平台上的推理失败问题。\n\n### 贡献者\n\n感谢以下人员做出的贡献:\n\nwangtongyu6, zhuguodong, 徐永飞, 徐安越, yeyunpeng2020, moran, XinDu, gengdongjie.\n\n欢迎以任何形式对项目提供贡献！\n\n## MindSpore 2.2.10 Release Notes\n\n### 主要特性及增强\n\n#### 算子\n\n- [STABLE] FastGelu、BatchMatMul、AllReduce、AllGather、Broadcast、ReduceScatter算子支持bfloat16数据类型\n- [STABLE] AllGather支持uint8数据类型\n\n### 问题修复\n\n- [#I8ALW3]修复Faster R-CNN、DeepTextMask、RCNN-ResNet50等网络在Ascend 910上8卡训练RandomChoiceWithMask算子报错问题\n- [#I8LKG7]修复UNet-2D在Ascend 910 1卡、8卡图编译报错问题\n- [#I8KU3X]修复CRNN-ResNet34在Ascend 910 1卡、8卡PyNative模式下训练进程卡住问题\n- [#I8KTHH]修复在Ascend 910 8卡上使能enable_parallel_optimizer=True，不使用allreduce分组融合时，BERT网络训练报错问题\n\n### 贡献者\n\n感谢以下人员做出的贡献:\n\n李林杰, TuDouNi, chengxb7532, Henry Shi, rms-infer-type, 朱家兴, zhouyaqiang0, tanghuikang, gaoyong10, gengdongjie, yao_yf, hujiahui8, hanhuifeng, shenyaxin, KevinYi, 冯一航, chengfeng27, JuiceZ, zhangyanhui, jijiarong, xiaoxiongzhu, 没有窗户的小巷, ling, liyan2022, haozhang, zangqx, xiaoyao, liujunzhu, 胡彬, panzhihui, wangshaocong, linqingke, jianghui58, qiuzhongya, yangruoqi713, zhangminli, moran, 王禹程, shaojunsong, wangtongyu6, zhupuxu, luoyang, 徐安越, qinzheng, caifubi, 徐永飞, chenkang, youshu, XinDu, liubuyu, jxl, yeyunpeng2020, huoxinyou, yefeng, jiaorui, wangpingan, cao1zhg, zjun, zyli2020, yanjiaming, Cynthia叶, 胡安东, 李良灿, liruyu, liuluobin, lihao, huangbingjian, YijieChen, jjfeing, looop5, 刘力力, xiaoxin_zhang, yangluhang, chenweifeng, jiangshanfeng, zichun_ye, 陈宇, NaCN, ligan, YingLai Lin, huangziling, chenjianping, DeshiChen, chengbin, kairui_kou, ccsszz, yanghaoran, zhangdanyang, Yanzhi_YI, zhengzuohe, hangq, TronZhang, wanghenchang, HighCloud, 吕浩宇, VectorSL, ZPaC, mengyuanli, maning202007, 刘勇琪, r1chardf1d0, fary86, 刘崇鸣, yuchaojie, douzhixing, fengyixing\n\n欢迎以任何形式对项目提供贡献！\n\n## MindSpore Lite 2.2.10 Release Notes\n\n### 问题修复\n\n- [#I8K7CC]优化get_model_info接口传入非str字段的报错\n\n### 贡献者\n\n感谢以下人员做出的贡献:\n\ngengdongjie, zhangyanhui, xiaoxiongzhu, wangshaocong, jianghui58, moran, wangtongyu6, 徐安越, qinzheng, 徐永飞, youshu, XinDu, yeyunpeng2020, yefeng, wangpingan, zjun, 胡安东, 刘力力, 陈宇, chenjianping, kairui_kou, zhangdanyang, hangq, mengyuanli, 刘崇鸣\n\n欢迎以任何形式对项目提供贡献！\n\n## MindSpore 2.2.1 Release Notes\n\n### Bug Fixes\n\n- [#I7R3R5] 修复昇腾平台ResNet-50网络精度劣化问题。\n- [#I8A9RH] 修复昇腾平台DBNet（ResNet-50）网络精度劣化问题。\n- [#I8B8IW] 修复多维Tensor赋值越界导致段错误的问题。\n- [#I8J0F4] 修复多维Tensor扩展维度在动态图执行失败的问题。\n- [#I87P3P] 修复昇腾平台二次训练编译缓存加载失败的问题。\n- [#I86GP9] 修复昇腾平台UNet3D网络推理精度劣化问题。\n- [#I89B4K] 修复Windows平台动态图动态rank执行卡住的问题。\n- [#I8CX0C] 修复昇腾平台上动态图混合精度模式下偶现失败的问题。\n- [#I8BGCF] 修复昇腾平台AIRNet网络动态图模式下执行出现段错误的问题。\n- [#I8L5DS] 修复昇腾平台ResNet-50图像分割网络动态图执行慢的问题。\n\n### 贡献者\n\n感谢以下人员做出的贡献:\n\nyufan, dingcheng, lvzhangcheng, zhunaipan, fangwenyi, weiyang, changzherui, chujinjin, zangqingxiang, yuchaojie, wuweikang, tanghuikang, xiaoyao, huangbinjian, zhoupeichen, chenfei_mindspore, hedongdong, wangnan, zhengzuohe, yanghaoran, zouliqin, luoyang, liuchongmin, lujiale, machenggui, wangcong, lixiangyi, wangting, huangyong\n\n欢迎以任何形式对项目提供贡献！\n\n## MindSpore Lite 2.2.1 Release Notes\n\n### Bug Fixes\n\n- [#I88055] 修复MindSpore Lite推理gridsample算子format设置错误的问题。\n- [#I8D80Y] 修复MindSpore Lite推理单算子调用流程资源释放异常的问题。\n\n### 贡献者\n\n感谢以下人员做出的贡献:\n\nzhanghaibo, wangsiyuan, yefeng, wangshaocong, chenjianping\n\n欢迎以任何形式对项目提供贡献！\n\n## MindSpore 2.2.0 Release Notes\n\n### 主要特性和增强\n\n#### DataSet\n\n- [STABLE] 数据操作map/batch的`row_size`参数扩展支持传入list，代表[输入共享内存, 输出共享内存]，以便在多进程模式时灵活控制共享内存的大小。\n- [STABLE] 为官网API文档页面mindspore.dataset、mindspore.dataset.transforms、mindspore.mindrecord的所有API补充完善样例，方便用户参考。\n- [STABLE] ConcatDataset支持全局采样能力，即使用concat操作组合多来源数据后，可以对数据进行全局随机采样以增强数据多样性。\n- [STABLE] 使用model.train接口训练时，支持通过TimeMonitor(.., data_time=True)实时监控数据处理性能。\n- [STABLE] 引入jemalloc库，解决在极端场景下，因内存碎片回收不及时导致内存缓慢上涨问题。\n\n#### FrontEnd\n\n- [STABLE] 支持添加@lazy_inline装饰器来标注Cell生成的子图延迟inline，从而有效提升编译性能。\n- [STABLE] 新增CellDict数据结构，支持构建Dict类型的Cell对象，完善构建网络能力。\n- [STABLE] 混合精度训练的功能优化，支持通过rewrite自动改写python脚本实现混合精度策略，支持函数、分支语句等多种语法自动解析。\n- [STABLE] 动态学习率功能优化，新增MultiStepLR等API；get_lr方法与global_step解耦，扩展优化器模块功能。\n- [STABLE] 优化API代码样例、API差异表以及高阶函数使用教程。\n\n#### 算子\n\n- [STABLE] 新增算子原语`mindspore.ops.Dense`。\n- [STABLE] 新增随机数算子状态管理功能，使随机数算子可以保存随机数状态，并在模型并行、重计算等场景稳定复现。当前仅支持CPU/GPU平台，涉及的随机数算子包括：`mindspore.ops.Multinomial`、`mindspore.ops.MultinomialWithReplacement`、`mindspore.ops.ParameterizedTruncatedNormal`、`mindspore.ops.StandardLaplace`、`mindspore.ops.StandardLaplace`、`mindspore.ops.Uniform`、`mindspore.ops.UniformInt`、`mindspore.ops.UniformReal`、`mindspore.ops.UniformInt`、`mindspore.ops.Dropout`、`mindspore.ops.RandomChoiceWithMask`、`mindspore.ops.RandomCategorical`、`mindspore.ops.RandomShuffle`、`mindspore.ops.RandamGamma`、`mindspore.ops.RandomPoisson`、`mindspore.ops.TruncatedNormal`。\n- [STABLE] 当GPU算子遇到非法输入场景，支持在算子的CUDA核函数中异步打印报错日志到Host侧，并中断当前CUDA Stream的执行，提高用户算子问题的定位效率。\n\n#### PyNative\n\n- [STABLE] PyNative模式下支持View机制。\n- [STABLE] PyNative模式下功能增强：sens支持dict类型输入。\n\n#### Ascend\n\n- [STABLE] 支持用户可配置算子高精度/高性能模式，用户可以通过`mindspore.set_context(ascend_config={\"op_precision_mode\": \"/path/to/op_precision_config_file\"})`对部分TBE算子配置高精度/高性能模式。\n- [BETA] 支持用户可配置fp16进fp32出的算子，用户可以通过`mindspore.set_context(ascend_config={\"precision_mode\": \"force_fp32\"})`对TBE Cube算子配置fp16进fp32出。\n- [BETA] 去除jit level \"O3\"与GE流程强绑定，用户在执行GE流程时无需再设置`jit_level=\"O3\"`。\n\n#### Parallel\n\n- [STABLE] 支持半自动/全自动模式下，非流水线并行场景的梯度累加特性，用户可以通过`net = GradAccumulationCell(net, micro_size)`方式，对网络使能梯度累加。梯度累加特性同样支持LazyInline编译加速。\n\n#### 推理\n\n自2.2版本起MindSpore主发布包不再提供配套310的推理接口使能，如需使用请切换安装MindSpore Lite发布包或下载MindSpore2.0之前的版本。MindSpore lite的安装部署与用法详见 <https://www.mindspore.cn/lite>。昇腾（Ascend）310是面向边缘场景的高能效高集成度AI处理器，支持对MindIR格式模型进行推理。原先MindSpore提供了两种在Ascend 310硬件上的推理使能用法：\n\n1. 由MindSpore主发布包提供配套Ascend 310的版本，支持C++推理接口。\n2. 由MindSpore Lite发布包提供配套Ascend的版本，支持C++/Java两种语言进行推理。\n\n这两种方案提供的C++ API基本一致，后续不再构建和维护两套接口，而是归一使用MindSpore Lite。原有基于MindSpore主发布包构建的310推理业务，可以少量修改切换到MindSpore Lite，详见 <https://www.mindspore.cn/docs/zh-CN/master/faq/inference.html>。\n\n### Bug fixes\n\n- [I7SDA0] 修复了昇腾平台上CRNN网络精度劣化的问题。\n- [I7T4QK] 修复了昇腾平台上wgan网络推理精度劣化问题。\n- [I7TJ8Z] 修复了昇腾平台上lgtm网络推理精度劣化问题。\n- [I7M58O] 修复了昇腾平台上ASR-dynamic网络训练core-dump的问题\n- [I7L6B6] 修复了dataset多进程模式时，子进程在某些场景不退出的问题。\n- [I7L7AE] 修复了dataset处理中包含repeat操作，且dataset.batch中使用动态batch时，batchinfo.get_epoch_num()计算不正确的问题。\n- [I7UY7G] 修复OBSMindDataset中对于文件权限修改的异常的报错。\n\n### 贡献者\n\n感谢以下人员做出的贡献:\nbantao, Bingliang, BJ-WANG, Brian-K, caifubi, ccsszz, changzherui, chenfei_mindspore, chengfeng27, chenhaozhe, chenjianping, chenkang, chenweifeng, chuht, chujinjin, CShu0507, Cynthia叶, DeshiChen, douzhixing, Erpim, Etienne, fary86, fengxun, fengyixing, gaoshuanglong, Gaoxiong, gaoyong10, GaoZhenlong, Greatpan, GuoZhibin, guozhijian, hangq, hanhuifeng, haozhang, hedongdong, Henry Shi, HighCloud, Hongxing, huangbingjian, huanghui, huangxinjing, huangziling, hujiahui8, huoxinyou, HWalkingMan, jianghui58, jiangshanfeng, jiaorui, jijiarong, jjfeing, JuiceZ, jxl, KevinYi, kisnwang, KXiong, lanzhineng, Li Qingguo, LiangZhibo, lianliguang, ligan, lihao, Lihoon, limingqi107, ling, linqingke, liruyu, liubuyu, liuchao, liujunzhu, liuluobin, liupeng303, liutongtong9, liyan2022, liyejun, looop5, luochao60, luojianing, luoyang, machenggui, maning202007, Margaret_wangrui, MaZhiming, mengyuanli, moran, NaCN, nomindcarry, panshaowu, panzhihui, qinzheng, qiuzhongya, r1chardf1d0, shaojunsong, shenwei41, shenyaxin, shenzhangyi, Shira Zaloshinski, shunyuanhan, tangdezhi_123, tanghuikang, tan-wei-cheng, tan-wei-cheng-3260, TronZhang, TuDouNi, VectorSL, wang_ziqi, wanghenchang, wangpingan, wangshaocong, wangtongyu6, wtcheng, wujueying, XianglongZeng, xiaotianci, xiaoxin_zhang, xiaoxiongzhu, xiaoyao, xiaoyuanyuan, XinDu, xujinliang, xupan, yanghaoran, yangluhang, yangruoqi713, yangsijia, yangzhenzhang, yangzishuo, yanjiaming, Yanzhi_YI, yao_yf, yefeng, yeyunpeng2020, yide12, YijieChen, YingLai Lin, YingtongHu, yonibaehr, youshu, yuchaojie, YuJianfeng, zangqx, zhaizhiqiang, zhangbuxue, zhangchunlei, zhangdanyang, zhangdong, zhanghaibo, zhangminli, zhangqi, zhangqinghua, zhangyanhui, zhangyifan, zhangyongxian, zhangzhen, zhangzheng, zhanzhan, zhengzuohe, ZhihaoLi, zhoufeng, zhouyaqiang0, zhuguodong, zhupuxu, zichun_ye, zjun, ZPaC, zuochuanyong, zyli2020, 陈宇, 程超, 范吉斌, 冯浩, 冯一航, 胡彬, 宦晓玲, 黄勇, 雷元哲, 黎冠新, 李良灿, 李林杰, 刘崇鸣, 刘力力, 刘思铭, 刘勇琪, 吕浩宇, 没有窗户的小巷, 沈竞兴, 王禹程, 王振邦, 徐安越, 徐永飞, 俞涵, 张澍坤, 周超, 朱家兴\n\n欢迎以任何形式对项目提供贡献！\n\n## MindSpore Lite 2.2.0 Release Notes\n\n### 主要特性和增强\n\n#### 支持FlashAttention算子融合\n\n- [STABLE] 在Ascend 910系列硬件上，支持LLAMA、stable diffusion系列模型的FlashAttention大算子融合。\n\n## MindSpore 2.1.1 Release Notes\n\n### Bug fixes\n\n- [I7Q9RX] 昇腾平台支持不同硬件类型自适应识别。\n- [I7SDA0] 修复了昇腾平台上CRNN网络精度劣化的问题。\n- [I7T4QK] 修复了昇腾平台上wgan网络推理精度劣化问题。\n- [I7TJ8Z] 修复了昇腾平台上lgtm网络推理精度劣化问题。\n\n### 贡献者\n\n感谢以下人员做出的贡献:\n\nchangzherui, chenfei_mindspore, chenjianping, chenkang, chenweifeng, chujinjin, fangwenyi, GuoZhibin, guozhijian, hangq, hanhuifeng, haozhang, hedongdong, 尤澍, zhoufeng, 代宇鑫\n\n欢迎以任何形式对项目提供贡献！\n\n## MindSpore Lite 2.1.1 Release Notes\n\n### Major Features and Improvements\n\n- [STABLE] MindSpore Lite Cloud Inference adds support for Python 3.8 and Python 3.9\n\n## MindSpore 2.1.0 Release Notes\n\n### 主要特性和增强\n\n#### FrontEnd\n\n- [BETA] JIT Fallback支持变量场景：静态图模式下，支持返回Dict类型和Scalar类型，支持对非Parameter类型对象进行属性设置， 支持List的部分就地修改操作，完善支持NumPy等第三方库，支持用户自定义类的相关操作，支持Python基础运算符、内置函数使用更多数据类型，兼容控制流、副作用、自动微分等功能。具体用法请参考[静态图语法支持](https://www.mindspore.cn/docs/zh-CN/r2.1/note/static_graph_syntax_support.html)。\n- [BETA] 静态图模式下，优化控制流场景中使用未定义变量的报错。使用if、while、for控制流分支内定义的变量，需在控制流之前初始化定义变量。\n- [STABLE] 新增ReWrite功能，支持基于自定义规则修改网络结构，提供对多个网络进行批量修改的能力。\n- [BETA] 新增optim_ex优化器模块，扩展现有功能，支持全量优化器参数分组策略的设置、支持运行中通过赋值的方式修改参数等功能。\n- [STABLE] 优化MindSpore与PyTorch的API映射表，详细介绍API在功能、参数、输入、输出和特定场景等方面的差异。\n\n#### PyNative\n\n- 优化动态图模式下动态shape场景的性能。\n\n#### DataSet\n\n- [STABLE] 优化MindRecord数据文件的内存结构，加载百TB级别数据训练可降低60%内存占用。\n- [STABLE] 支持单线程执行数据处理Pipeline，以便用户在数据Pipeline中添加代码对数据处理功能进行调试。\n- [STABLE] 优化了TFRecordDataset的性能，对数据集加载性能提升60%+；优化了batch的性能，对于batch数较大的使用场景性能提升30%。\n- [STABLE] 优化API文档[mindspore.dataset](https://www.mindspore.cn/docs/zh-CN/r2.1/api_python/mindspore.dataset.html) 和 [mindspore.dataset.transforms](https://www.mindspore.cn/docs/zh-CN/r2.1/api_python/mindspore.dataset.transforms.html)的Example示例，并新增了四篇样例库展示数据增强的效果，分别是：[使用数据Pipeline加载 & 处理数据集](https://www.mindspore.cn/docs/zh-CN/r2.1/api_python/mindspore.dataset.html#%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86pipeline%E5%BF%AB%E9%80%9F%E4%B8%8A%E6%89%8B)、[视觉变换样例库](https://www.mindspore.cn/docs/zh-CN/r2.1/api_python/mindspore.dataset.transforms.html#%E6%A0%B7%E4%BE%8B%E5%BA%93)、[文本变换样例库](https://www.mindspore.cn/docs/zh-CN/r2.1/api_python/mindspore.dataset.transforms.html#%E6%A0%B7%E4%BE%8B%E5%BA%93-1)、[音频变换样例库](https://www.mindspore.cn/docs/zh-CN/r2.1/api_python/mindspore.dataset.transforms.html#%E6%A0%B7%E4%BE%8B%E5%BA%93-2)\n\n#### AutoParallel\n\n- [STABLE] 支持训练过程将参数或者中间结果offload到CPU或NVMe，用户通过配置context开启自动offload功能，扩大可训练模型规模。\n\n- [STABLE] 自动并行能力增强：\n\n  1. 典型网络自动策略性能不低于默认配置的90%；\n\n  2. 支持3D混合并行训练：自动算子级策略生成结合手动配置pipeline切分。\n\n#### Runtime\n\n- [STABLE] 升级OpenMPI版本至4.1.4。\n- [STABLE] 升级NCCL版本至2.16.5。\n- [STABLE] 动态组网场景下单节点内多卡rank连续分配。\n- [STABLE] 动态组网场景下用户无需在脚本中对Scheduler角色进行适配，Scheduler与Worker脚本可保持完全一致。\n\n#### Ascend\n\n- [STABLE] 算子执行发生AIC Error时日志支持输出辅助AIC Error定位的维测信息，信息包括算子task名字、stream id、输入输出及workspace地址等。\n- [STABLE] 针对算子输出为空Tensor的场景为CANN算子提供默认的处理机制，即跳过其算子执行。\n- [STABLE] 在图模式网络模型执行失败时补充相关定位信息，即在rank_${id}/exec_order/目录下产生csv文件，记录每个task的task id和stream id。\n\n#### Profiler\n\n- [STABLE] Profiler支持收集Host侧各个阶段耗时数据。\n- [BETA] Profiler支持收集Host侧各个阶段内存数据。\n- [BETA] Profiler支持收集数据处理算子耗时。\n\n### API变更\n\n- `mindspore.dataset.GraphData`、`mindspore.dataset.Graph`、`mindspore.dataset.InMemoryGraphDataset`、`mindspore.dataset.ArgoverseDataset`不再进行功能演进并废弃。使用[MindSpore Graph Learning](https://gitee.com/mindspore/graphlearning)进行相关功能替换。对于Model仓库使用到此API的相关网络进行替换时，GCN请参考[Graph Learning GCN](https://gitee.com/mindspore/graphlearning/tree/master/model_zoo/gcn)，GAT请参考[Graph Learning GAT](https://gitee.com/mindspore/graphlearning/tree/master/model_zoo/gat)。\n- `mindspore.set_context`新增`jit_syntax_level`选项，用于设置JIT语法支持级别，请参考[set_context](https://www.mindspore.cn/docs/zh-CN/r2.1/api_python/mindspore/mindspore.set_context.html)。\n- 变更了`model.infer_predict_layout`接口，接口新增参数skip_backend_compile，默认值为False。当用户希望跳过后端编译流程获取参数切分策略时可选择设置为True。\n\n#### 算子\n\n- 新增算子原语`mindspore.ops.ApplyAdamWithAmsgradV2`，推荐通过接口`mindspore.nn.Adam`调用。\n- 新增算子原语`mindspore.ops.UpsampleTrilinear3D`，推荐通过接口`mindspore.ops.interpolate`调用。\n- 新增算子原语`mindspore.ops.UpsampleNearest3D`，推荐通过接口`mindspore.ops.interpolate`调用。\n\n#### 接口弃用\n\n- 弃用算子原语`mindspore.ops.ScatterNonAliasingAdd`，推荐使用算子原语`mindspore.ops.TensorScatterAdd`替换。\n\n#### 非兼容性接口变更\n\n- 接口名称：`mindspore.nn.Dense`、`mindspore.nn.Conv1d`、`mindspore.nn.Conv1dTranspose`、`mindspore.nn.Conv2d`、`mindspore.nn.Conv2dTranspose`、`mindspore.nn.Conv3d`、`mindspore.nn.Conv3dTranspose`\n\n  变更内容：变更了初始化参数策略。weight_init默认值由\"normal\"改为None，bias_init默认值由\"zeros\"改为None。\n\n  说明：权重默认初始化方法由使用\"normal\"改为在内部使用HeUniform初始化。偏差默认初始化方法由\"zeros\"改为在内部使用Uniform初始化。\n\n  <table>\n  <tr>\n  <td style=\"text-align:center\"> 原接口 </td> <td style=\"text-align:center\"> v2.1接口 </td>\n  </tr>\n  <tr>\n  <td><pre>\n  mindspore.nn.Dense(in_channels,\n                     out_channels,\n                     weight_init='normal',\n                     bias_init='zeros',\n                     has_bias=True,\n                     activation=None)\n  </pre>\n  </td>\n  <td><pre>\n  mindspore.nn.Dense(in_channels,\n                     out_channels,\n                     weight_init=None,\n                     bias_init=None,\n                     has_bias=True,\n                     activation=None)\n  </pre>\n  </td>\n  </tr>\n  <tr>\n  <td><pre>\n  mindspore.nn.Conv1d(in_channels,\n                      out_channels,\n                      kernel_size,\n                      stride=1,\n                      pad_mode='same',\n                      padding=0,\n                      dilation=1,\n                      group=1,\n                      has_bias=False,\n                      weight_init='normal',\n                      bias_init='zeros')\n  </pre>\n  </td>\n  <td><pre>\n  mindspore.nn.Conv1d(in_channels,\n                      out_channels,\n                      kernel_size,\n                      stride=1,\n                      pad_mode='same',\n                      padding=0,\n                      dilation=1,\n                      group=1,\n                      has_bias=False,\n                      weight_init=None,\n                      bias_init=None)\n  </pre>\n  </td>\n  </tr>\n  <tr>\n  <td><pre>\n  mindspore.nn.Conv1dTranspose(in_channels,\n                               out_channels,\n                               kernel_size,\n                               stride=1,\n                               pad_mode='same',\n                               padding=0,\n                               dilation=1,\n                               group=1,\n                               has_bias=False,\n                               weight_init='normal',\n                               bias_init='zeros')\n  </pre>\n  </td>\n  <td><pre>\n  mindspore.nn.Conv1dTranspose(in_channels,\n                               out_channels,\n                               kernel_size,\n                               stride=1,\n                               pad_mode='same',\n                               padding=0,\n                               dilation=1,\n                               group=1,\n                               has_bias=False,\n                               weight_init=None,\n                               bias_init=None)\n  </pre>\n  </td>\n  </tr>\n  <tr>\n  <td><pre>\n  mindspore.nn.Conv2d(in_channels,\n                      out_channels, kernel_size,\n                      stride=1,\n                      pad_mode='same',\n                      padding=0,\n                      dilation=1,\n                      group=1,\n                      has_bias=False,\n                      weight_init='normal',\n                      bias_init='zeros',\n                      data_format='NCHW')\n  </pre>\n  </td>\n  <td><pre>\n  mindspore.nn.Conv2d(in_channels,\n                      out_channels,\n                      kernel_size,\n                      stride=1,\n                      pad_mode='same',\n                      padding=0,\n                      dilation=1,\n                      group=1,\n                      has_bias=False,\n                      weight_init=None,\n                      bias_init=None,\n                      data_format='NCHW')\n  </pre>\n  </td>\n  </tr>\n  <tr>\n  <td><pre>\n  mindspore.nn.Conv2dTranspose(in_channels,\n                               out_channels,\n                               kernel_size,\n                               stride=1,\n                               pad_mode='same',\n                               padding=0,\n                               output_padding=0,\n                               dilation=1,\n                               group=1,\n                               has_bias=False,\n                               weight_init='normal',\n                               bias_init='zeros')\n  </pre>\n  </td>\n  <td><pre>\n  mindspore.nn.Conv2dTranspose(in_channels,\n                               out_channels,\n                               kernel_size,\n                               stride=1,\n                               pad_mode='same',\n                               padding=0,\n                               output_padding=0,\n                               dilation=1,\n                               group=1,\n                               has_bias=False,\n                               weight_init=None,\n                               bias_init=None)\n  </pre>\n  </td>\n  </tr>\n  <tr>\n  <td><pre>\n  mindspore.nn.Conv3d(in_channels,\n                      out_channels,\n                      kernel_size,\n                      stride=1,\n                      pad_mode='same',\n                      padding=0,\n                      dilation=1,\n                      group=1,\n                      has_bias=False,\n                      weight_init='normal',\n                      bias_init='zeros',\n                      data_format='NCDHW')\n  </pre>\n  </td>\n  <td><pre>\n  mindspore.nn.Conv3d(in_channels,\n                      out_channels,\n                      kernel_size,\n                      stride=1,\n                      pad_mode='same',\n                      padding=0,\n                      dilation=1,\n                      group=1,\n                      has_bias=False,\n                      weight_init=None,\n                      bias_init=None,\n                      data_format='NCDHW')\n  </pre>\n  </td>\n  </tr>\n  <tr>\n  <td><pre>\n  mindspore.nn.Conv3dTranspose(in_channels,\n                               out_channels,\n                               kernel_size,\n                               stride=1,\n                               pad_mode='same',\n                               padding=0,\n                               dilation=1,\n                               group=1,\n                               output_padding=0,\n                               has_bias=False,\n                               weight_init='normal',\n                               bias_init='zeros',\n                               data_format='NCDHW')\n  </pre>\n  </td>\n  <td><pre>\n  mindspore.nn.Conv3dTranspose(in_channels,\n                               out_channels,\n                               kernel_size,\n                               stride=1,\n                               pad_mode='same',\n                               padding=0,\n                               dilation=1,\n                               group=1,\n                               output_padding=0,\n                               has_bias=False,\n                               weight_init=None,\n                               bias_init=None,\n                               data_format='NCDHW')\n  </pre>\n  </td>\n  </tr>\n  </table>\n\n### Bug fixes\n\n- [I6TKLW] 修复了昇腾平台上MobileNetV2网络性能劣化的问题。\n- [I7CP5H] 修复了昇腾平台上ASR网络训练失败的问题。\n- [I7I3EZ] 修复了由于Pillow 10.0.0版本变更枚举接口导致run_check()失败的问题。若在低版本MindSpore遇到，则安装10.0.0以下版本Pillow避免此问题。\n- [I7IZ8K] 修复了assignsub接口在PyNative下的精度问题。\n- [I7HGY0] 修复了函数式编程，在PyNative模式数据下沉场景，loss不收敛的问题。\n- [I7J4N3] 修复了Profiler动态Shape模式下生成Step Trace失败的问题。\n- [I7J4N3] 修复了MindInsight并行策略视图展示暂无数据的问题。\n- [I79YY4] 修复了PyNative模式下高阶微分时的SiLU算子错误。\n- [I6NQJQ] 修复了PyNative模式下ScatterUpdate算子动态shape场景下执行概率性失败的问题。\n- [I6Y4G5] 修复了Graph模式下Conv3D算子动态Shape场景下执行失败的问题。\n\n### 贡献者\n\n感谢以下人员做出的贡献:\n\nalashkari,anzhengqi,archer2049,B.L.LAN,baihuawei,bichaoyang,BJ-WANG,Bokai Li,Brian-K,caifubi,caiyimeng,cathwong,changzherui,ChenDonYY,chenfei_mindspore,chengang,chengbin,chenhaozhe,chenjianping,chenkang,chenweifeng,chuht,chujinjin,davidanugraha,DavidFFFan,DeshiChen,douzhixing,emmmmtang,Erpim,Ethan,fangwenyi,fangzehua,fangzhou0329,fary86,fengyixing,gaoshuanglong,Gaoxiong,gaoyong10,gengdongjie,gongdaguo1,Greatpan,GuoZhibin,guozhijian,hangq,hanhuifeng,haozhang,hedongdong,Henry Shi,heterogeneous_to_backoff_2_0,huangbingjian,huanghui,huangxinjing,hujiahui8,hujingsong,huoxinyou,jachua,jiahongQian,jianghui58,jiangzhenguang,jiaorui,jiaoy1224,jijiarong,jjfeing,JoeyLin,json,JuiceZ,jxl,kairui_kou,KevinYi,kisnwang,KXiong,laiyongqiang,lanzhineng,liangchenghui,liangzelang,LiangZhibo,lianliguang,lichen,ligan,lijunbin,limingqi107,ling,linqingke,liubuyu,liuchao,liuchuting,liujunzhu,liuluobin,liutongtong9,liuyang811,lixiao,liyan2022,liyejun,liyuxia,looop5,luochao60,luojianing,luoyang,luoyuan,lyqlola,maning202007,maoyaomin,Margaret_wangrui,mayadong,MaZhiming,melody,mengyuanli,michaelzhu_70ab,Mohammad Motallebi,moran,NaCN,nomindcarry,OwenSec,panfengfeng,panshaowu,panzhihui,pkuliuliu,qinzheng,qiuzhongya,qujianwei,r1chardf1d0,Renyuan Zhang,RobinGrosman,shaojunsong,shenwei41,Soaringfish,tangdezhi_123,tanghuikang,tan-wei-cheng,TinaMengtingZhang,TronZhang,TuDouNi,VectorSL,wang_ziqi,wanghenchang,wangnan39,wangpingan,wangshaocong,wangshengnan123,wangtongyu6,weichaoran,wind-zyx,wqx,wtcheng,wujueying,wYann,XianglongZeng,xiaohanzhang,xiaotianci,xiaoyao,XinDu,xulei,xumengjuan1,xupan,xwkgch,yanghaoran,yangluhang,yangruoqi713,yangshuo,yangsijia,yangzhenzhang,yanzhenxiang2020,Yanzhi_YI,yao_yf,yefeng,yeyunpeng2020,Yi_zhang95,yide12,YijieChen,YingLai Lin,YingtongHu,youshu,yuchaojie,yuedongli,YuJianfeng,zangqx,ZengZitao,zhangbuxue,zhangdanyang,zhangdong,zhangfanghe,zhangqi,zhangqinghua,zhangyanhui,zhangyinxia,zhangyongxian,zhangzhaoju,zhanzhan,zhengzuohe,ZhidanLiu,zhixinaa,zhoufeng,zhouyaqiang0,zhuguodong,zhupuxu,zhuyuxiao,zichun_ye,zjun,zlq2020,zong_shuai,ZPaC,zuochuanyong,zyli2020,陈宇,范吉斌,冯一航,胡彬,宦晓玲,黄勇,雷元哲,李良灿,李林杰,刘崇鸣,刘力力,刘勇琪,吕浩宇,吕昱峰（Nate.River）,没有窗户的小巷,沈竞兴,十六夜,王程浩,王禹程,王振邦,徐安越,徐永飞,杨旭华,于振华,俞涵,张清华,张澍坤,张栩浩,张学同,赵英灼,周超,周洪叶,朱家兴\n\n欢迎以任何形式对项目提供贡献！\n\n## MindSpore Lite 2.1.0 Release Notes\n\n### 主要特性和增强\n\n#### MindSpore Lite云侧推理\n\n- [STABLE] 支持Ascend硬件后端单卡大模型以及单机多卡分布式大模型高性能推理。\n- [STABLE] Python API Ascend后端支持多模型共享工作空间（Workspace）内存。\n- [STABLE] [通过ModelGroup新增支持多模型共享权重](https://mindspore.cn/lite/docs/zh-CN/r2.1/use/cloud_infer/runtime_cpp.html#%E5%A4%9A%E6%A8%A1%E5%9E%8B%E5%85%B1%E4%BA%AB%E6%9D%83%E9%87%8D)，比如大模型场景下全量模型和增量模型共享权重。\n\n#### API\n\n新增ModelGroup [Python](https://www.mindspore.cn/lite/api/zh-CN/r2.1/mindspore_lite/mindspore_lite.ModelGroup.html#mindspore_lite.ModelGroup)和[C++](https://mindspore.cn/lite/api/zh-CN/r2.1/api_cpp/mindspore.html#modelgroup)接口，接口定义如下：\n\n```python\nclass ModelGroup\n    def __init__(self, flags=ModelGroupFlag.SHARE_WORKSPACE)\n    def add_model(self, models)\n    def cal_max_size_of_workspace(self, model_type, context)\n```\n\n```C++\n// class ModelGroup\nModelGroup(ModelGroupFlag flags = ModelGroupFlag::kShareWorkspace);\nStatus AddModel(const std::vector<std::string> &model_path_list);\nStatus AddModel(const std::vector<std::pair<const void *, size_t>> &model_buff_list);\nStatus AddModel(const std::vector &model_list);\nStatus AddModel(const std::vector &model_list);\n```\n\n## MindSpore 2.0.0 Release Notes\n\n### 主要特性和增强\n\n#### PyNative\n\n- [Stable] 全面支持动态shape，算子支持度详见[nn接口动态shape支持情况](https://www.mindspore.cn/docs/zh-CN/master/note/dynamic_shape_nn.html)、[ops接口动态shape支持情况](https://www.mindspore.cn/docs/zh-CN/master/note/dynamic_shape_func.html)和[算子动态shape支持情况](https://www.mindspore.cn/docs/zh-CN/master/note/dynamic_shape_primitive.html)。\n\n#### AutoParallel\n\n- [STABLE] 新建MindFormers独立仓，提供分布式并行套件功能，替代mindspore.nn.transformer模块。\n- [DEMO] 分布式Gather算子支持BatchDim属性。\n- [DEMO] 流水线并行支持指定输入数据任意维度作为Batch维。\n\n### API变更\n\n#### 算子\n\n- `mindspore.ops.AdaptiveAvgPool2D` 新增算子原语。\n- `mindspore.ops.BatchToSpaceNDV2` 新增算子原语。\n- `mindspore.ops.CeLU` 新增算子原语。\n- `mindspore.ops.ExtractVolumePatches` 新增算子原语。\n- `mindspore.ops.FFTWithSize` 新增算子原语。\n- `mindspore.ops.FillDiagonal` 新增算子原语。\n- `mindspore.ops.FractionalMaxPool3DWithFixedKsize` 新增算子原语。\n- `mindspore.ops.Im2Col` 新增算子原语。\n- `mindspore.ops.MaskedScatter` 新增算子原语。\n- `mindspore.ops.MatrixBandPart` 新增算子原语。\n- `mindspore.ops.MatrixInverse` 新增算子原语。\n- `mindspore.ops.MaxPoolWithArgmaxV2` 新增算子原语。\n- `mindspore.ops.Ormqr` 新增算子原语。\n- `mindspore.ops.RandpermV2` 新增算子原语。\n- `mindspore.ops.ResizeBicubic` 新增算子原语。\n- `mindspore.ops.Triu` 新增算子原语。\n- `mindspore.ops.Zeta` 新增算子原语。\n\n#### 非兼容性接口变更\n\n- 接口名称：mindspore.ops.MultitypeFuncGraph\n\n  变更内容：该接口参数doc_url在MindSpore 2.0.0.rc1版本作为测试特性，MindSpore 2.0.0版本优化后用户不需要额外配置此参数，故此参数在MindSpore 2.0.0版本删除。\n\n  <table>\n  <tr>\n  <td style=\"text-align:center\"> 原接口 </td> <td style=\"text-align:center\"> v2.0.0 接口</td>\n  </tr>\n  <tr>\n  <td><pre>\n  mindspore.ops.MultitypeFuncGraph（name, read_value=False, doc_url=\"\"）\n  </pre>\n  </td>\n  <td><pre>\n  mindspore.ops.MultitypeFuncGraph（name, read_value=False）\n  </pre>\n  </td>\n  </tr>\n  </table>\n\n- 接口名称：mindspore.set_context(auto_tune_mode=\"GA,RL\")\n\n  变更内容：下线算子AutoTune调优工具，删除auto_tune_mode选项，未来会规划新的调优工具。\n\n- 接口名称：mindspore.set_context(mode=PYNATIVE_MODE)\n\n  变更内容：默认由GRAPH_MODE改为PYNATIVE_MODE。\n\n  说明：原有使用方式若未设置运行模式，该变更会影响性能，需要额外设置图模式，则使用以下方式：\n  mindspore.set_context(mode=GRAPH_MODE)。\n\n  <table>\n  <tr>\n  <td style=\"text-align:center\"> 原接口 </td> <td style=\"text-align:center\"> v2.0.0-rc1接口 </td>\n  </tr>\n  <tr>\n  <td><pre>\n  mindspore.set_context(mode=GRAPH_MODE)\n  </pre>\n  </td>\n  <td><pre>\n  mindspore.set_context(mode=PYNATIVE_MODE)\n  </pre>\n  </td>\n  </tr>\n  </table>\n\n- 接口名称：mindspore.train.Model.train\n\n  变更内容：dataset_sink_mode 默认值由True改为False。\n\n  说明：原有使用方式若未设置dataset_sink_mode，该变更会影响性能，需要额外设置数据下沉运行模式，则使用以下方式：\n  Model.train(dataset_sink_mode=True)。\n\n  <table>\n  <tr>\n  <td style=\"text-align:center\"> 原接口 </td> <td style=\"text-align:center\"> v2.0.0-rc1接口 </td>\n  </tr>\n  <tr>\n  <td><pre>\n  Model.train(dataset_sink_mode=True)\n  </pre>\n  </td>\n  <td><pre>\n  Model.train(dataset_sink_mode=False)\n  </pre>\n  </td>\n  </tr>\n  </table>\n\n- 接口名称：mindspore.export\n\n  变更内容：参数file_format由\"AIR\"改为不指定默认值。\n\n  说明：原有使用方式若未设置file_format，需要额外设置file_format，则使用以下方式：\n  mindspore.export(net, *inputs, file_name, file_format=\"AIR\", **kwargs)。\n\n  <table>\n  <tr>\n  <td style=\"text-align:center\"> 原接口 </td> <td style=\"text-align:center\"> v2.0.0-rc1接口 </td>\n  </tr>\n  <tr>\n  <td><pre>\n  mindspore.export(net, *inputs, file_name,\n                   file_format=\"AIR\", **kwargs)\n  </pre>\n  </td>\n  <td><pre>\n  mindspore.export(net, *inputs, file_name,\n                   file_format, **kwargs)\n  </pre>\n  </td>\n  </tr>\n  </table>\n\n- 接口名称：mindspore.ops.norm\n\n  变更内容：扩展ord参数功能，支持多种形式。\n\n  <table>\n  <tr>\n  <td style=\"text-align:center\"> 原接口 </td> <td style=\"text-align:center\"> v2.0.0-rc1接口 </td>\n  </tr>\n  <tr>\n  <td><pre>\n  ops.norm(input_x, axis, p=2, keep_dims=False, epsilon=1e-12)\n  >>> # 举例:\n  >>> input = Tensor(np.array([[[1.0, 2.0], [3.0, 4.0]],\n  ...                          [[5.0, 6.0], [7.0, 8.0]]]).astype(np.float32))\n  >>> output = ops.norm(input, [0, 1], p=2)\n  </pre></td>\n  <td><pre>\n  ops.norm(A, ord=None, dim=None, keepdim=False, *, dtype=None)\n  >>> # 举例:\n  >>> input = Tensor(np.array([[[1.0, 2.0], [3.0, 4.0]],\n  ...                          [[5.0, 6.0], [7.0, 8.0]]]).astype(np.float32))\n  >>> output = ops.norm(input, ord=2, dim=(0, 1))\n  </pre>\n  </td>\n  </tr>\n  </table>\n\n- 接口名称：mindspore.Tensor.norm\n\n  变更内容：扩展ord参数功能，支持多种形式。\n\n  说明：参考ops.norm例子。\n\n  <table>\n  <tr>\n  <td style=\"text-align:center\"> 原接口 </td> <td style=\"text-align:center\"> v2.0.0-rc1接口 </td>\n  </tr>\n  <tr>\n  <td><pre>\n  Tensor.norm(axis, p=2, keep_dims=False, epsilon=1e-12)\n  </pre>\n  </td>\n  <td><pre>\n  Tensor.norm(ord=None, dim=None, keepdim=False, *, dtype=None)\n  </pre>\n  </td>\n  </tr>\n  </table>\n\n- 接口名称：mindspore.ops.dropout\n\n  变更内容：删除seed0、seed1参数，新增参数seed=None。由返回Tensor和掩码改为只返回Tensor，新增入参training=True。\n\n  <table>\n  <tr>\n  <td style=\"text-align:center\"> 原接口 </td> <td style=\"text-align:center\"> v2.0.0-rc1接口 </td>\n  </tr>\n  <tr>\n  <td><pre>\n  ops.dropout(x, p=0.5, seed0=0, seed1=0)\n  >>> # 举例:\n  >>> input = Tensor(((20, 16), (50, 50)),\n  ...                mindspore.float32)\n  >>> output, mask = dropout(x, p=0.5)\n  </pre>\n  </td>\n  <td><pre>\n  ops.dropout(input, p=0.5, training=True, seed=None)\n  >>> # 举例:\n  >>> input = Tensor(((20, 16), (50, 50)),\n  ...                mindspore.float32)\n  >>> output = ops.dropout(input, p=0.5，training=True)\n  </pre>\n  </td>\n  </tr>\n  </table>\n\n- 接口名称：mindspore.ops.dropout2d\n\n  变更内容：返回值从Tensor和掩码改为只返回Tensor，新增入参training=True。\n\n  <table>\n  <tr>\n  <td style=\"text-align:center\"> 原接口 </td> <td style=\"text-align:center\"> v2.0.0-rc1接口 </td>\n  </tr>\n  <tr>\n  <td>\n  <pre>\n  ops.dropout2d(x, p=0.5)\n  >>> # 举例:\n  >>> input = Tensor(np.ones([2, 1, 2, 3]),\n  ...                mindspore.float32)\n  >>> output, mask = dropout2d(input, 0.5)\n  </pre>\n  </td>\n  <td>\n  <pre>\n  ops.dropout2d(input, p=0.5, training=True)\n  >>> # 举例:\n  >>> input = Tensor(np.ones([2, 1, 2, 3]),\n  ...                mindspore.float32)\n  >>> output = ops.dropout2d(input, 0.5, training=True)\n  </pre>\n  </td>\n  </tr>\n  </table>\n\n- 接口名称：mindspore.ops.dropout3d\n\n  变更内容：返回值从Tensor和掩码改为只返回Tensor，新增入参training=True。\n\n  <table>\n  <tr>\n  <td style=\"text-align:center\"> 原接口 </td> <td style=\"text-align:center\"> v2.0.0-rc1接口 </td>\n  </tr>\n  <tr>\n  <td><pre>\n  ops.dropout3d(x, p=0.5)\n  >>> # 举例:\n  >>> input = Tensor(np.ones([2, 1, 2, 3]),\n  ...                mindspore.float32)\n  >>> output, mask = dropout3d(input, 0.5)\n  </pre>\n  </td>\n  <td><pre>\n  ops.dropout3d(input, p=0.5, training=True)\n  >>> # 举例:\n  >>> input = Tensor(np.ones([2, 1, 2, 3]),\n  ...                mindspore.float32)\n  >>> output = ops.dropout3d(input, 0.5, training=True)\n  </pre>\n  </td>\n  </tr>\n  </table>\n\n- 接口名称：mindspore.ops.std\n\n  变更内容：接口重构，接口使用方式更符合用户使用习惯。\n\n  说明：原有unbiased如果已显示设置，采用以下替代方案：\n  ddof=0替代unbiased=False，ddof=1替代unbiased=True。\n\n  <table>\n  <tr>\n  <td style=\"text-align:center\"> 原接口 </td> <td style=\"text-align:center\"> v2.0.0-rc1接口 </td>\n  </tr>\n  <tr>\n  <td><pre>\n  ops.std(input_x, axis=(), unbiased=True, keep_dims=False)\n  </pre>\n  </td>\n  <td><pre>\n  ops.std(input, axis=None, ddof=0, keepdims=False)\n  </pre>\n  </td>\n  </tr>\n  </table>\n\n- 接口名称：mindspore.load_param_into_net\n\n  变更内容：新增ckpt中未加载的参数作为返回值。\n\n  <table>\n  <tr>\n  <td style=\"text-align:center\"> 原接口 </td> <td style=\"text-align:center\"> v2.0.0-rc1接口 </td>\n  </tr>\n  <tr>\n  <td><pre>\n  net_param = load_param_into_net()\n  </pre>\n  </td>\n  <td><pre>\n  net_param, ckpt_param = load_param_into_net()\n  </pre>\n  </td>\n  </tr>\n  </table>\n\n- 接口名称：mindspore.nn.BCELoss\n\n  变更内容：`reduction` 默认值由'none'变为'mean'。\n\n  <table>\n  <tr>\n  <td style=\"text-align:center\"> 原接口 </td> <td style=\"text-align:center\"> v2.0.0-rc1接口 </td>\n  </tr>\n  <tr>\n  <td><pre>\n  BCELoss(weight=None, reduction='none')\n  >>> # 举例:\n  >>> weight = Tensor(np.array([[1.0, 2.0, 3.0],\n  ...                           [4.0, 3.3, 2.2]]),\n  ...                 mindspore.float32)\n  >>> loss = nn.BCELoss(weight=weight, reduction='mean')\n  >>> logits = Tensor(np.array([[0.1, 0.2, 0.3],\n  ...                           [0.5, 0.7, 0.9]]),\n  ...                 mindspore.float32)\n  >>> labels = Tensor(np.array([[0, 1, 0], [0, 0, 1]]),\n  ...                 mindspore.float32)\n  >>> output = loss(logits, labels)\n  >>> print(output)\n  >>> 1.8952923\n  </pre>\n  </td>\n  <td><pre>\n  BCELoss(weight=None, reduction='mean')\n  >>> # 举例:\n  >>> weight = Tensor(np.array([[1.0, 2.0, 3.0],\n  ...                           [4.0, 3.3, 2.2]]),\n  ...                 mindspore.float32)\n  >>> loss = nn.BCELoss(weight=weight)\n  >>> logits = Tensor(np.array([[0.1, 0.2, 0.3],\n  ...                           [0.5, 0.7, 0.9]]),\n  ...                 mindspore.float32)\n  >>> labels = Tensor(np.array([[0, 1, 0], [0, 0, 1]]),\n  ...                 mindspore.float32)\n  >>> output = loss(logits, labels)\n  >>> print(output)\n  >>> 1.8952923\n  </pre>\n  </td>\n  </tr>\n  </table>\n\n- 接口名称：mindspore.ops.split\n\n  变更内容：接口重构，接口使用方式更符合用户使用习惯，调整第2个和第3个参数的顺序，修改并扩展split_size_or_sections功能。\n\n  <table>\n  <tr>\n  <td style=\"text-align:center\"> 原接口 </td> <td style=\"text-align:center\"> v2.0.0-rc1接口 </td>\n  </tr>\n  <tr>\n  <td><pre>\n  ops.split(input_x, axis=0, output_num=1)\n  >>> # 举例:\n  >>> input = Tensor(np.array([[1, 1, 1, 1], [2, 2, 2, 2]]),\n  ...                mindspore.int32)\n  >>> output = ops.split(input, axis=1, output_num=4)\n  </pre>\n  </td>\n  <td><pre>\n  ops.split(tensor, split_size_or_sections, axis=0)\n  >>> # 举例:\n  >>> input = Tensor(np.array([[1, 1, 1, 1], [2, 2, 2, 2]]),\n  ...                mindspore.int32)\n  >>> output = ops.split(input, split_size_or_sections=1, axis=1)\n  </pre>\n  </td>\n  </tr>\n  </table>\n\n- 接口名称：mindspore.Tensor.split\n\n  变更内容：接口重构，接口使用方式更符合用户使用习惯，调整两个参数的位置，修改并扩展split_size_or_sections功能。\n\n  说明：参考ops.split例子。\n\n  <table>\n  <tr>\n  <td style=\"text-align:center\"> 原接口 </td> <td style=\"text-align:center\"> v2.0.0-rc1接口 </td>\n  </tr>\n  <tr>\n  <td><pre>\n  Tensor.split(axis=0, output_num=1)\n  </pre>\n  </td>\n  <td><pre>\n  Tensor.split(split_size_or_sections, axis=0)\n  </pre>\n  </td>\n  </tr>\n  </table>\n\n- 接口名称：mindspore.ops.pad\n\n  变更内容：修改参数名paddings为padding，添加mode和value功能。\n\n  <table>\n  <tr>\n  <td style=\"text-align:center\"> 原接口 </td> <td style=\"text-align:center\"> v2.0.0-rc1接口 </td>\n  </tr>\n  <tr>\n  <td><pre>\n  ops.pad(input_x, paddings)\n  >>> # 举例:\n  >>> input_x = Tensor(np.array([[-0.1, 0.3, 3.6],\n  ...                            [0.4, 0.5, -3.2]]),\n  ...                  mindspore.float32)\n  >>> paddings = ((1, 2), (2, 1))\n  >>> output = ops.pad(input_x, paddings)\n  </pre>\n  </td>\n  <td><pre>\n  ops.pad(input_x, padding, mode='constant', value=None)\n  >>> # 举例:\n  >>> input_x = Tensor(np.array([[-0.1, 0.3, 3.6],\n  ...                            [0.4, 0.5, -3.2]]),\n  ...                  mindspore.float32)\n  >>> paddings = (2, 1, 1, 2)\n  >>> output = ops.pad(input_x, paddings)\n  </pre>\n  </td>\n  </tr>\n  </table>\n\n- 接口名称：mindspore.ops.meshgrid\n\n  变更内容：入参由inputs改为*input。\n\n  <table>\n  <tr>\n  <td style=\"text-align:center\"> 原接口 </td> <td style=\"text-align:center\"> v2.0.0-rc1接口 </td>\n  </tr>\n  <tr>\n  <td><pre>\n  ops.meshgrid(inputs, indexing='xy')\n  >>> # 举例:\n  >>> x = Tensor(np.array([1, 2, 3, 4]).astype(np.int32))\n  >>> y = Tensor(np.array([5, 6, 7]).astype(np.int32))\n  >>> z = Tensor(np.array([8, 9, 0, 1, 2]).astype(np.int32))\n  >>> output = ops.meshgrid((x, y, z), indexing='xy')\n  </pre>\n  </td>\n  <td><pre>\n  ops.meshgrid(*inputs, indexing='xy')\n  >>> # 举例:\n  >>> x = Tensor(np.array([1, 2, 3, 4]).astype(np.int32))\n  >>> y = Tensor(np.array([5, 6, 7]).astype(np.int32))\n  >>> z = Tensor(np.array([8, 9, 0, 1, 2]).astype(np.int32))\n  >>> output = ops.meshgrid(x, y, z, indexing='xy')\n  </pre>\n  </td>\n  </tr>\n  </table>\n\n- 接口名称：mindspore.ops.max\n\n  变更内容：返回值调换顺序，由：“下标，最大值”改为“最大值，下标”。\n\n  <table>\n  <tr>\n  <td style=\"text-align:center\"> 原接口 </td> <td style=\"text-align:center\"> v2.0.0-rc1接口 </td>\n  </tr>\n  <tr>\n  <td><pre>\n  ops.max(x, axis=0, keep_dims=False)\n  >>> # 举例:\n  >>> input = Tensor(np.array([0.0, 0.4, 0.6, 0.7, 0.1]),\n  ...                mindspore.float32)\n  >>> index, output = ops.max(input)\n  >>> print(index, output)\n  >>> 3 0.7\n  </pre>\n  </td>\n  <td><pre>\n  ops.max(input, axis=None, keepdims=False, *, initial=None, where=True, return_indices=False)\n  >>> # 举例:\n  >>> input = Tensor(np.array([0.0, 0.4, 0.6, 0.7, 0.1]),\n  ...                mindspore.float32)\n  >>> output, index = ops.max(input, axis=0)\n  >>> print(output, index)\n  </pre>\n  </td>\n  </tr>\n  </table>\n\n- 接口名称：mindspore.ops.min\n\n  变更内容：返回值调换顺序，由：“下标，最小值”改为“最小值，下标”。\n\n  <table>\n  <tr>\n  <td style=\"text-align:center\"> 原接口 </td> <td style=\"text-align:center\"> v2.0.0-rc1接口 </td>\n  </tr>\n  <tr>\n  <td><pre>\n  ops.min(x, axis=0, keep_dims=False)\n  >>> # 举例:\n  >>> input = Tensor(np.array([0.0, 0.4, 0.6, 0.7, 0.1]),\n  ...                mindspore.float32)\n  >>> index, output = ops.min(input)\n  >>> 0 0.0\n  </pre>\n  </td>\n  <td><pre>\n  ops.min(input, axis=None, keepdims=False, *, initial=None, where=True, return_indices=False)\n  >>> # 举例:\n  >>> input = Tensor(np.array([0.0, 0.4, 0.6, 0.7, 0.1]),\n  ...                mindspore.float32)\n  >>> output, index = ops.min(input, keepdims=True)\n  >>> 0.0 0\n  </pre>\n  </td>\n  </tr>\n  </table>\n\n- 接口名称：mindspore.ops.random_gamma\n\n  变更内容：删除seed2参数，seed=0改为None。框架行为统一且符合用户实际使用场景及习惯。\n\n  <table>\n  <tr>\n  <td style=\"text-align:center\"> 原接口 </td> <td style=\"text-align:center\"> v2.0.0-rc1接口 </td>\n  </tr>\n  <tr>\n  <td><pre>\n  ops.random_gamma(shape, alpha, seed=0, seed2=0)\n  </pre>\n  </td>\n  <td><pre>\n  ops.random_gamma(shape, alpha, seed=None)\n  </pre>\n  </td>\n  </tr>\n  </table>\n\n- 接口名称：mindspore.ops.standard_laplace\n\n  变更内容：删除seed2参数，seed=0改为None。框架行为统一且符合用户实际使用场景及习惯。\n\n  <table>\n  <tr>\n  <td style=\"text-align:center\"> 原接口 </td> <td style=\"text-align:center\"> v2.0.0-rc1接口 </td>\n  </tr>\n  <tr>\n  <td><pre>\n  ops.standard_laplace(shape, seed=0, seed2=0)\n  </pre>\n  </td>\n  <td><pre>\n  ops.standard_laplace(shape, seed=None)\n  </pre>\n  </td>\n  </tr>\n  </table>\n\n- 接口名称：mindspore.ops.standard_normal\n\n  变更内容：删除seed2参数，seed=0改为None。框架行为统一且符合用户实际使用场景及习惯。\n\n  <table>\n  <tr>\n  <td style=\"text-align:center\"> 原接口 </td> <td style=\"text-align:center\"> v2.0.0-rc1接口 </td>\n  </tr>\n  <tr>\n  <td><pre>\n  ops.standard_normal(shape, seed=0, seed2=0)\n  </pre>\n  </td>\n  <td><pre>\n  ops.standard_normal(shape, seed=None)\n  </pre>\n  </td>\n  </tr>\n  </table>\n\n- 接口名称：mindspore.ops.bernoulli\n\n  变更内容：seed的默认值由-1改为None。符合用户实际使用场景。\n\n  <table>\n  <tr>\n  <td style=\"text-align:center\"> 原接口 </td> <td style=\"text-align:center\"> v2.0.0-rc1接口 </td>\n  </tr>\n  <tr>\n  <td><pre>\n  ops.bernoulli(x, p=0.5, seed=-1)\n  </pre>\n  </td>\n  <td><pre>\n  ops.bernoulli(input, p=0.5, seed=None)\n  </pre>\n  </td>\n  </tr>\n  </table>\n\n- 接口名称：mindspore.data_sink\n\n  变更内容：删除steps参数，jit参数名称修改为jit_config，新增input_signature参数。增加易用性，符合用户实际使用场景。\n\n  <table>\n  <tr>\n  <td style=\"text-align:center\"> 原接口 </td> <td style=\"text-align:center\"> v2.0.0-rc1接口 </td>\n  </tr>\n  <tr>\n  <td><pre>\n  mindspore.data_sink(fn, dataset, steps,\n                      sink_size=1, jit=False)\n  </pre>\n  </td>\n  <td><pre>\n  mindspore.data_sink(fn, dataset, sink_size=1,\n                      jit_config=None, input_signature=None)\n  </pre>\n  </td>\n  </tr>\n  </table>\n\n- 接口名称：mindspore.ops.conv2d\n\n  变更内容：扩展接口功能，添加bias参数，修改参数名及参数顺序。\n\n  <table>\n  <tr>\n  <td style=\"text-align:center\"> 原接口 </td> <td style=\"text-align:center\"> v2.0.0-rc1接口 </td>\n  </tr>\n  <tr>\n  <td><pre>\n  conv2d(inputs, weight, pad_mode=\"valid\",\n         padding=0, stride=1, dilation=1, group=1)\n  </pre>\n  </td>\n  <td><pre>\n  conv2d(input, weight, bias=None, stride=1,\n         pad_mode=\"valid\", padding=0, dilation=1, groups=1)\n  </pre>\n  </td>\n  </tr>\n  </table>\n\n- 接口名称：mindspore.dataset.vision.Pad\n\n  变更内容：调整Pad、RandomCrop、RandomCropWithBbox入参padding，当Padding输入长度为2的序列时，行为将从使用第一个值填充左/上边界，使用第二个值填充右/下边界，变为使用第一个值填充左/右边界，使用第二个值填充上/下边界。\n\n  说明：仅使用size为2的padding参数无法兼容旧版本的效果，需显式表示（左、右、上、下）。\n\n  <table>\n  <tr>\n  <td style=\"text-align:center\"> 原接口 </td> <td style=\"text-align:center\"> v2.0.0-rc1接口 </td>\n  </tr>\n  <tr>\n  <td><pre>\n  mindspore.dataset.vision.Pad(padding=(1,2))\n  代表图片的左/上填充 1像素，右/下填充 2像素\n  </pre>\n  </td>\n  <td><pre>\n  mindspore.dataset.vision.Pad(padding=(1,2,1,2))\n  代表图片的左/上填充 1像素，右/下填充 2像素\n  </pre>\n  </td>\n  </tr>\n  </table>\n\n- 接口名称：mindspore.dataset.Dataset.map\n\n  变更内容：删除column_order参数。因为在绝大部分的情况下，output_columns参数与column_order参数都是同一个值，不需要再传入column_order。若需要调整数据列顺序，使用mindspore.dataset.Dataset.project实现。\n\n  说明：\n\n  1) 在不需要改变列顺序时，直接去掉column_order参数即可。\n  2) 需要指定数据列顺序时，删除column_order参数，并在后面加上一个project方法进行列变换（如下面的例子）。\n\n  <table>\n  <tr>\n  <td style=\"text-align:center\"> 原接口 </td> <td style=\"text-align:center\"> v2.0.0-rc1接口 </td>\n  </tr>\n  <tr>\n  <td><pre>\n  >>> dataset = dataset.map(operations=[transforms],\n  ...                       input_columns=[\"column_a\"],\n  ...                       output_columns=[\"column_b\", \"column_c\"],\n  ...                       column_order=[\"column_c\", \"column_b\"])\n  </pre>\n  </td>\n  <td><pre>\n  >>> dataset = dataset.map(operations=[transforms],\n  ...                       input_columns=[\"column_a\"],\n  ...                       output_columns=[\"column_b\", \"column_c\"])\n  >>> dataset = dataset.project([\"column_c\", column_b\"])\")\n  </pre>\n  </td>\n  </tr>\n  </table>\n\n- 接口名称：mindspore.dataset.Dataset.batch\n\n  变更内容：删除column_order参数。因为在绝大部分的情况下，output_columns参数与column_order参数都是同一个值，不需要再传入column_order。若需要调整数据列顺序，使用mindspore.dataset.Dataset.project实现。\n\n  说明：\n\n  1) 在不需要改变列顺序时，直接去掉column_order参数即可。\n  2) 需要指定数据列顺序时，删除column_order参数，并在后面加上一个project方法进行列变换（如下面的例子）。\n\n  <table>\n  <tr>\n  <td style=\"text-align:center\"> 原接口 </td> <td style=\"text-align:center\"> v2.0.0-rc1接口 </td>\n  </tr>\n  <tr>\n  <td><pre>\n  >>> dataset = dataset.batch(batch_size=4,\n  ...                         input_columns=[\"column_a\"],\n  ...                         output_columns=[\"column_b\", \"column_c\"],\n  ...                         column_order=[\"column_c\", \"column_b\"])\n  </pre>\n  </td>\n  <td><pre>\n  >>> dataset = dataset.batch(batch_size=4, input_columns=[\"column_a\"]\n  ...                         output_columns=[\"column_b\", \"column_c\"])\n  >>> dataset = dataset.project([\"column_c\", column_b\"])\")\n  </pre>\n  </td>\n  </tr>\n  </table>\n\n- 接口名称：mindspore.dataset.Dataset.batch\n\n  变更内容：将batch方法拆分为：batch和padded_batch两个方法。pad_info参数从batch方法移动到padded_batch方法。\n\n  说明：如需使用pad_info参数，改用padded_batch方法。\n\n  <table>\n  <tr>\n  <td style=\"text-align:center\"> 原接口 </td> <td style=\"text-align:center\"> v2.0.0-rc1接口 </td>\n  </tr>\n  <tr>\n  <td><pre>\n  >>> dataset = dataset.batch(batch_size=4,\n  ...                         drop_remainder=True, pad_info=...)\n  </pre>\n  </td>\n  <td><pre>\n  >>> dataset = dataset.padded_batch(batch_size=4,\n  ...                                drop_remainder=True, pad_info=...)\n  </pre>\n  </td>\n  </tr>\n  </table>\n\n### Bug fixes\n\n- [I62I3J] 修复bgcf网络在昇腾310上推理失败的问题\n- [I7C2W3] 修复Pipeline并行场景下多loss打印编译失败问题\n\n### 贡献者\n\n感谢以下人员做出的贡献:\n\nalashkari,anzhengqi,archer2049,B.L.LAN,baihuawei,bichaoyang,BJ-WANG,Bokai Li,Brian-K,caifubi,caiyimeng,cathwong,changzherui,ChenDonYY,chenfei_mindspore,chengang,chengbin,chenhaozhe,chenjianping,chenkang,chenweifeng,chuht,chujinjin,davidanugraha,DavidFFFan,DeshiChen,douzhixing,emmmmtang,Erpim,Ethan,fangwenyi,fangzehua,fangzhou0329,fary86,fengyixing,gaoshuanglong,Gaoxiong,gaoyong10,gengdongjie,gongdaguo1,Greatpan,GuoZhibin,guozhijian,hangq,hanhuifeng,haozhang,hedongdong,Henry Shi,heterogeneous_to_backoff_2_0,huangbingjian,huanghui,huangxinjing,hujiahui8,hujingsong,huoxinyou,jachua,jiahongQian,jianghui58,jiangzhenguang,jiaorui,jiaoy1224,jijiarong,jjfeing,JoeyLin,json,JuiceZ,jxl,kairui_kou,KevinYi,kisnwang,KXiong,laiyongqiang,lanzhineng,liangchenghui,liangzelang,LiangZhibo,lianliguang,lichen,ligan,lijunbin,limingqi107,ling,linqingke,liubuyu,liuchao,liuchuting,liujunzhu,liuluobin,liutongtong9,liuyang811,lixiao,liyan2022,liyejun,liyuxia,looop5,luochao60,luojianing,luoyang,luoyuan,lyqlola,maning202007,maoyaomin,Margaret_wangrui,mayadong,MaZhiming,melody,mengyuanli,michaelzhu_70ab,Mohammad Motallebi,moran,NaCN,nomindcarry,OwenSec,panfengfeng,panshaowu,panzhihui,pkuliuliu,qinzheng,qiuzhongya,qujianwei,r1chardf1d0,Renyuan Zhang,RobinGrosman,shaojunsong,shenwei41,Soaringfish,tangdezhi_123,tanghuikang,tan-wei-cheng,TinaMengtingZhang,TronZhang,TuDouNi,VectorSL,wang_ziqi,wanghenchang,wangnan39,wangpingan,wangshaocong,wangshengnan123,wangtongyu6,weichaoran,wind-zyx,wqx,wtcheng,wujueying,wYann,XianglongZeng,xiaohanzhang,xiaotianci,xiaoyao,XinDu,xulei,xumengjuan1,xupan,xwkgch,yanghaoran,yangluhang,yangruoqi713,yangshuo,yangsijia,yangzhenzhang,yanzhenxiang2020,Yanzhi_YI,yao_yf,yefeng,yeyunpeng2020,Yi_zhang95,yide12,YijieChen,YingLai Lin,YingtongHu,youshu,yuchaojie,yuedongli,YuJianfeng,zangqx,ZengZitao,zhangbuxue,zhangdanyang,zhangdong,zhangfanghe,zhangqi,zhangqinghua,zhangyanhui,zhangyinxia,zhangyongxian,zhangzhaoju,zhanzhan,zhengzuohe,ZhidanLiu,zhixinaa,zhoufeng,zhouyaqiang0,zhuguodong,zhupuxu,zhuyuxiao,zichun_ye,zjun,zlq2020,zong_shuai,ZPaC,zuochuanyong,zyli2020,陈宇,范吉斌,冯一航,胡彬,宦晓玲,黄勇,雷元哲,李良灿,李林杰,刘崇鸣,刘力力,刘勇琪,吕浩宇,吕昱峰（Nate.River）,没有窗户的小巷,沈竞兴,十六夜,王程浩,王禹程,王振邦,徐安越,徐永飞,杨旭华,于振华,俞涵,张清华,张澍坤,张栩浩,张学同,赵英灼,周超,周洪叶,朱家兴\n\n欢迎以任何形式对项目提供贡献！\n\n## MindSpore 2.0.0-rc1 Release Notes\n\n### 主要特性和增强\n\n#### FrontEnd\n\n- [BETA] 静态图模式下，函数及类方法支持\"return None\"、\"return\"、无\"return\"语法。\n- [BETA] 静态图模式下，支持返回list类型对象。\n- [BETA] 静态图模式下，变量条件时，支持\"raise\"语法。\n- [STABLE] 函数式调用支持数据下沉模式。\n- [BETA] nn下新增Transformer层，提供更加易用的Transformer API，无需定义batch_size，支持动态seq_length。\n\n#### DataSet\n\n- [STABLE] Ascend环境下，数据下沉模式超时等待时间调整，默认调整到1900s，以解决数据下沉模式时因环境资源竞争、计算量大等因素容易导致GetNext算子等待超时的问题。\n- [STABLE] MindRecord提供Schema、样本数查询接口，并提供多进程并行写入功能，允许用户更快生成MindRecord数据文件。\n- [STABLE] Dataset流水线支持处理任意Python对象，用法参考[数据pipeline支持Python对象](https://www.mindspore.cn/tutorials/zh-CN/r2.0/advanced/dataset/python_objects.html)。\n\n#### AutoParallel\n\n- [STABLE] 策略保存时支持保存完整策略。\n- [STABLE] 支持Conv3D/MaxPool3D/AvgPool3D分布式算子。\n- [STABLE] 支持PyNative+shard算子级并行+优化器并行：并行表达和Model进行解耦，提供基础的并行表达能力。\n- [STABLE] 支持图模式算子级并行+优化器并行：并行表达和Model进行解耦，提供基础的并行表达能力。\n- [BETA] 支持自定义分布式图切分，提升分布式训练的灵活性。\n\n#### Runtime\n\n- [STABLE] 控制流支持子图下沉。\n- [STABLE] 支持CUDA 11.6。\n- [STABLE] 支持List/Tuple/Scalar类型算子的算子选择和执行，配套Python原生表达。\n- [STABLE] 硬件不支持的算子自动选择CPU算子。\n- [STABLE] 支持子图内部异构执行。\n\n#### Ascend\n\n- [STABLE] 支持CANN溢出检测新方案和HCCL运行态溢出检测。\n- [STABLE] 支持集合通信算子dump功能。\n\n#### Profiler\n\n- [STABLE] 丰富Profiler采集项配置，用户可以更细度地采集性能数据。\n\n#### Dump\n\n- [BETA] 单卡PyNatvie模式支持算子溢出检测。\n- [BETA] Graph模式支持hccl算子dump。\n\n### API变更\n\n- [STABLE] 新增计算类API，如：MaxUnpool、ReplicationPad、GaussianNLLLoss等。\n  详情请参考：<https://www.mindspore.cn/docs/zh-CN/r2.0/api_python/mindspore.html>。\n- [STABLE] 扩展存量API功能，如：AvgPool、pad、norm、interplate等。\n\n#### 算子\n\n- [BETA] `mindspore.ops.AdaptiveAvgPool3D` 新增算子原语。\n- [BETA] `mindspore.ops.AffineGrid` 新增算子原语。\n- [BETA] `mindspore.ops.Angle` 新增算子原语。\n- [BETA] `mindspore.ops.BartlettWindow` 新增算子原语。\n- [BETA] `mindspore.ops.Bernoulli` 新增算子原语。\n- [BETA] `mindspore.ops.BesselI0` 新增算子原语。\n- [BETA] `mindspore.ops.BesselI1` 新增算子原语。\n- [BETA] `mindspore.ops.BesselJ0` 新增算子原语。\n- [BETA] `mindspore.ops.BesselJ1` 新增算子原语。\n- [BETA] `mindspore.ops.BesselK0` 新增算子原语。\n- [BETA] `mindspore.ops.BesselK0e` 新增算子原语。\n- [BETA] `mindspore.ops.BesselK1` 新增算子原语。\n- [BETA] `mindspore.ops.BesselK1e` 新增算子原语。\n- [BETA] `mindspore.ops.BesselY0` 新增算子原语。\n- [BETA] `mindspore.ops.BesselY1` 新增算子原语。\n- [BETA] `mindspore.ops.Bincount` 新增算子原语。\n- [BETA] `mindspore.ops.BlackmanWindow` 新增算子原语。\n- [BETA] `mindspore.ops.ChannelShuffle` 新增算子原语。\n- [BETA] `mindspore.ops.Cholesky` 新增算子原语。\n- [BETA] `mindspore.ops.Col2Im` 新增算子原语。\n- [BETA] `mindspore.ops.Complex` 新增算子原语。\n- [BETA] `mindspore.ops.ComplexAbs` 新增算子原语。\n- [BETA] `mindspore.ops.Cross` 新增算子原语。\n- [BETA] `mindspore.ops.CTCLossV2` 新增算子原语。\n- [BETA] `mindspore.ops.Cummin` 新增算子原语。\n- [BETA] `mindspore.ops.Diag` 新增算子原语。\n- [BETA] `mindspore.ops.Digamma` 新增算子原语。\n- [BETA] `mindspore.ops.Expand` 新增算子原语。\n- [BETA] `mindspore.ops.Fmax` 新增算子原语。\n- [BETA] `mindspore.ops.Gcd` 新增算子原语。\n- [BETA] `mindspore.ops.Geqrf` 新增算子原语。\n- [BETA] `mindspore.ops.GLU` 新增算子原语。\n- [BETA] `mindspore.ops.GridSampler2D` 新增算子原语。\n- [BETA] `mindspore.ops.GridSampler3D` 新增算子原语。\n- [BETA] `mindspore.ops.HammingWindow` 新增算子原语。\n- [BETA] `mindspore.ops.Heaviside` 新增算子原语。\n- [BETA] `mindspore.ops.Hypot` 新增算子原语。\n- [BETA] `mindspore.ops.Igamma` 新增算子原语。\n- [BETA] `mindspore.ops.IndexFill` 新增算子原语。\n- [BETA] `mindspore.ops.InplaceIndexAdd` 新增算子原语。\n- [BETA] `mindspore.ops.InplaceUpdateV2` 新增算子原语。\n- [BETA] `mindspore.ops.Lcm` 新增算子原语。\n- [BETA] `mindspore.ops.LeftShift` 新增算子原语。\n- [BETA] `mindspore.ops.LogicalXor` 新增算子原语。\n- [BETA] `mindspore.ops.Logit` 新增算子原语。\n- [BETA] `mindspore.ops.LogSpace` 新增算子原语。\n- [BETA] `mindspore.ops.LuUnpack` 新增算子原语。\n- [BETA] `mindspore.ops.MatrixDiagPartV3` 新增算子原语。\n- [BETA] `mindspore.ops.MatrixDiagV3` 新增算子原语。\n- [BETA] `mindspore.ops.MatrixSetDiagV3` 新增算子原语。\n- [BETA] `mindspore.ops.MaxPool3DWithArgmax` 新增算子原语。\n- [BETA] `mindspore.ops.MaxUnpool2D` 新增算子原语。\n- [BETA] `mindspore.ops.MaxUnpool3D` 新增算子原语。\n- [BETA] `mindspore.ops.MultiMarginLoss` 新增算子原语。\n- [BETA] `mindspore.ops.MultinomialWithReplacement` 新增算子原语。\n- [BETA] `mindspore.ops.Mvlgamma` 新增算子原语。\n- [BETA] `mindspore.ops.NanToNum` 新增算子原语。\n- [BETA] `mindspore.ops.NextAfter` 新增算子原语。\n- [BETA] `mindspore.ops.Orgqr` 新增算子原语。\n- [BETA] `mindspore.ops.Polygamma` 新增算子原语。\n- [BETA] `mindspore.ops.ResizeBilinearV2` 新增算子原语。\n- [BETA] `mindspore.ops.RightShift` 新增算子原语。\n- [BETA] `mindspore.ops.ScatterNdDiv` 新增算子原语。\n- [BETA] `mindspore.ops.ScatterNdMul` 新增算子原语。\n- [BETA] `mindspore.ops.SearchSorted` 新增算子原语。\n- [BETA] `mindspore.ops.Sinc` 新增算子原语。\n- [BETA] `mindspore.ops.Trace` 新增算子原语。\n- [BETA] `mindspore.ops.Tril` 新增算子原语。\n- [BETA] `mindspore.ops.TrilIndices` 新增算子原语。\n- [BETA] `mindspore.ops.TriuIndices` 新增算子原语。\n- [BETA] `mindspore.ops.UniqueConsecutive` 新增算子原语。\n- [STABLE] `mindspore.ops.Cummax` 新增算子原语。\n- [STABLE] `mindspore.ops.FillV2` 新增算子原语。\n- [STABLE] `mindspore.ops.IsClose` 新增算子原语。\n- [STABLE] `mindspore.ops.MatrixSolve` 新增算子原语。\n- [STABLE] `mindspore.ops.Median` 新增算子原语。\n- [STABLE] `mindspore.ops.MultilabelMarginLoss` 新增算子原语。\n- [STABLE] `mindspore.ops.NonZero` 新增算子原语。\n- [STABLE] `mindspore.ops.Pdist` 新增算子原语。\n- [STABLE] `mindspore.ops.Polar` 新增算子原语。\n- [STABLE] `mindspore.ops.RandomGamma` 新增算子原语。\n- [STABLE] `mindspore.ops.RandomPoisson` 新增算子原语。\n- [STABLE] `mindspore.ops.RandomShuffle` 新增算子原语。\n- [STABLE] `mindspore.ops.Renorm` 新增算子原语。\n- [STABLE] `mindspore.ops.ScatterNdMax` 新增算子原语。\n- [STABLE] `mindspore.ops.ScatterNdMin` 新增算子原语。\n- [STABLE] `mindspore.ops.Svd` 新增算子原语。\n- [STABLE] `mindspore.ops.TripletMarginLoss` 新增算子原语。\n\n#### 删除接口\n\n- `mindspore.compression`特性在MindSpore 1.8版本已经废弃，在当前版本被删除。用户可以使用[昇思金箍棒](https://gitee.com/mindspore/golden-stick)作为`mindspore.compression`的替代品来实现MindSpore中的量化感知训练算法。\n- `mindspore.dataset.close_pool`、`mindspore.dataset.to_device`、`mindspore.dataset.set_dynamic_columns` 接口在之前版本已废弃，当前版本正式删除。\n\n#### 非兼容性接口变更\n\n- 接口名称：mindspore.set_context(mode=PYNATIVE_MODE)\n\n  变更内容：默认由GRAPH_MODE改为PYNATIVE_MODE。\n\n  说明：原有使用方式若未设置运行模式，该变更会影响性能，需要额外设置图模式，则使用以下方式：\n  mindspore.set_context(mode=GRAPH_MODE)。\n\n  <table>\n  <tr>\n  <td style=\"text-align:center\"> 原接口 </td> <td style=\"text-align:center\"> v2.0.0-rc1接口 </td>\n  </tr>\n  <tr>\n  <td><pre>\n  mindspore.set_context(mode=GRAPH_MODE)\n  </pre>\n  </td>\n  <td><pre>\n  mindspore.set_context(mode=PYNATIVE_MODE)\n  </pre>\n  </td>\n  </tr>\n  </table>\n\n- 接口名称：mindspore.train.Model.train\n\n  变更内容：dataset_sink_mode 默认值由True改为False。\n\n  说明：原有使用方式若未设置dataset_sink_mode，该变更会影响性能，需要额外设置数据下沉运行模式，则使用以下方式：\n  Model.train(dataset_sink_mode=True)。\n\n  <table>\n  <tr>\n  <td style=\"text-align:center\"> 原接口 </td> <td style=\"text-align:center\"> v2.0.0-rc1接口 </td>\n  </tr>\n  <tr>\n  <td><pre>\n  Model.train(dataset_sink_mode=True)\n  </pre>\n  </td>\n  <td><pre>\n  Model.train(dataset_sink_mode=False)\n  </pre>\n  </td>\n  </tr>\n  </table>\n\n- 接口名称：mindspore.export\n\n  变更内容：参数file_format由\"AIR\"改为不指定默认值。\n\n  说明：原有使用方式若未设置file_format，需要额外设置file_format，则使用以下方式：\n  mindspore.export(net, *inputs, file_name, file_format=\"AIR\", **kwargs)。\n\n  <table>\n  <tr>\n  <td style=\"text-align:center\"> 原接口 </td> <td style=\"text-align:center\"> v2.0.0-rc1接口 </td>\n  </tr>\n  <tr>\n  <td><pre>\n  mindspore.export(net, *inputs, file_name,\n                   file_format=\"AIR\", **kwargs)\n  </pre>\n  </td>\n  <td><pre>\n  mindspore.export(net, *inputs, file_name,\n                   file_format, **kwargs)\n  </pre>\n  </td>\n  </tr>\n  </table>\n\n- 接口名称：mindspore.ops.norm\n\n  变更内容：扩展ord参数功能，支持多种形式。\n\n  <table>\n  <tr>\n  <td style=\"text-align:center\"> 原接口 </td> <td style=\"text-align:center\"> v2.0.0-rc1接口 </td>\n  </tr>\n  <tr>\n  <td><pre>\n  ops.norm(input_x, axis, p=2, keep_dims=False, epsilon=1e-12)\n  >>> # 举例:\n  >>> input = Tensor(np.array([[[1.0, 2.0], [3.0, 4.0]],\n  ...                          [[5.0, 6.0], [7.0, 8.0]]]).astype(np.float32))\n  >>> output = ops.norm(input, [0, 1], p=2)\n  </pre>\n  </td>\n  <td><pre>\n  ops.norm(A, ord=None, dim=None, keepdim=False, *, dtype=None)\n  >>> # 举例:\n  >>> input = Tensor(np.array([[[1.0, 2.0], [3.0, 4.0]],\n  ...                          [[5.0, 6.0], [7.0, 8.0]]]).astype(np.float32))\n  >>> output = ops.norm(input, ord=2, dim=(0, 1))\n  </pre>\n  </td>\n  </tr>\n  </table>\n\n- 接口名称：mindspore.Tensor.norm\n\n  变更内容：扩展ord参数功能，支持多种形式。\n\n  说明：参考ops.norm例子。\n\n  <table>\n  <tr>\n  <td style=\"text-align:center\"> 原接口 </td> <td style=\"text-align:center\"> v2.0.0-rc1接口 </td>\n  </tr>\n  <tr>\n  <td><pre>\n  Tensor.norm(axis, p=2, keep_dims=False, epsilon=1e-12)\n  </pre>\n  </td>\n  <td><pre>\n  Tensor.norm(ord=None, dim=None, keepdim=False, *, dtype=None)\n  </pre>\n  </td>\n  </tr>\n  </table>\n\n- 接口名称：mindspore.ops.dropout\n\n  变更内容：删除seed0、seed1参数，新增参数seed=None。由返回Tensor和掩码改为只返回Tensor，新增入参training=True。\n\n  <table>\n  <tr>\n  <td style=\"text-align:center\"> 原接口 </td> <td style=\"text-align:center\"> v2.0.0-rc1接口 </td>\n  </tr>\n  <tr>\n  <td>\n  <pre>\n  ops.dropout(x, p=0.5, seed0=0, seed1=0)\n  >>> # 举例:\n  >>> input = Tensor(((20, 16), (50, 50)),\n  ...                mindspore.float32)\n  >>> output, mask = dropout(x, p=0.5)\n  </pre>\n  </td>\n  <td>\n  <pre>\n  ops.dropout(input, p=0.5, training=True, seed=None)\n  >>> # 举例:\n  >>> input = Tensor(((20, 16), (50, 50)),\n  ...                mindspore.float32)\n  >>> output = ops.dropout(input, p=0.5，training=True)\n  </pre>\n  </td>\n  </tr>\n  </table>\n\n- 接口名称：mindspore.ops.dropout2d\n\n  变更内容：返回值从Tensor和掩码改为只返回Tensor，新增入参training=True。\n\n  <table>\n  <tr>\n  <td style=\"text-align:center\"> 原接口 </td> <td style=\"text-align:center\"> v2.0.0-rc1接口 </td>\n  </tr>\n  <tr>\n  <td>\n  <pre>\n  ops.dropout2d(x, p=0.5)\n  >>> # 举例:\n  >>> input = Tensor(np.ones([2, 1, 2, 3]),\n  ...                mindspore.float32)\n  >>> output, mask = dropout2d(input, 0.5)\n  </pre>\n  </td>\n  <td>\n  <pre>\n  ops.dropout2d(input, p=0.5, training=True)\n  >>> # 举例:\n  >>> input = Tensor(np.ones([2, 1, 2, 3]),\n  ...                mindspore.float32)\n  >>> output = ops.dropout2d(input, 0.5, training=True)\n  </pre>\n  </td>\n  </tr>\n  </table>\n\n- 接口名称：mindspore.ops.dropout3d\n\n  变更内容：返回值从Tensor和掩码改为只返回Tensor，新增入参training=True。\n\n  <table>\n  <tr>\n  <td style=\"text-align:center\"> 原接口 </td> <td style=\"text-align:center\"> v2.0.0-rc1接口 </td>\n  </tr>\n  <tr>\n  <td><pre>\n  ops.dropout3d(x, p=0.5)\n  >>> # 举例:\n  >>> input = Tensor(np.ones([2, 1, 2, 3]),\n  ...                mindspore.float32)\n  >>> output, mask = dropout3d(input, 0.5)\n  </pre>\n  </td>\n  <td><pre>\n  ops.dropout3d(input, p=0.5, training=True)\n  >>> # 举例:\n  >>> input = Tensor(np.ones([2, 1, 2, 3]),\n  ...                mindspore.float32)\n  >>> output = ops.dropout3d(input, 0.5, training=True)\n  </pre>\n  </td>\n  </tr>\n  </table>\n\n- 接口名称：mindspore.ops.std\n\n  变更内容：接口重构，接口使用方式更符合用户使用习惯。\n\n  说明：原有unbiased如果已显示设置，采用以下替代方案：\n  ddof=0替代unbiased=False，ddof=1替代unbiased=True。\n\n  <table>\n  <tr>\n  <td style=\"text-align:center\"> 原接口 </td> <td style=\"text-align:center\"> v2.0.0-rc1接口 </td>\n  </tr>\n  <tr>\n  <td><pre>\n  ops.std(input_x, axis=(), unbiased=True, keep_dims=False)\n  </pre>\n  </td>\n  <td><pre>\n  ops.std(input, axis=None, ddof=0, keepdims=False)\n  </pre>\n  </td>\n  </tr>\n  </table>\n\n- 接口名称：mindspore.load_param_into_net\n\n  变更内容：新增ckpt中未加载的参数作为返回值。\n\n  <table>\n  <tr>\n  <td style=\"text-align:center\"> 原接口 </td> <td style=\"text-align:center\"> v2.0.0-rc1接口 </td>\n  </tr>\n  <tr>\n  <td><pre>\n  net_param = load_param_into_net()\n  </pre>\n  </td>\n  <td><pre>\n  net_param, ckpt_param = load_param_into_net()\n  </pre>\n  </td>\n  </tr>\n  </table>\n\n- 接口名称：mindspore.nn.BCELoss\n\n  变更内容：`reduction` 默认值由'none'变为'mean'。\n\n  <table>\n  <tr>\n  <td style=\"text-align:center\"> 原接口 </td> <td style=\"text-align:center\"> v2.0.0-rc1接口 </td>\n  </tr>\n  <tr>\n  <td><pre>\n  BCELoss(weight=None, reduction='none')\n  >>> # 举例:\n  >>> weight = Tensor(np.array([[1.0, 2.0, 3.0],\n  ...                           [4.0, 3.3, 2.2]]),\n  ...                 mindspore.float32)\n  >>> loss = nn.BCELoss(weight=weight, reduction='mean')\n  >>> logits = Tensor(np.array([[0.1, 0.2, 0.3],\n  ...                           [0.5, 0.7, 0.9]]),\n  ...                 mindspore.float32)\n  >>> labels = Tensor(np.array([[0, 1, 0], [0, 0, 1]]),\n  ...                 mindspore.float32)\n  >>> output = loss(logits, labels)\n  >>> print(output)\n  >>> 1.8952923\n  </pre>\n  </td>\n  <td><pre>\n  BCELoss(weight=None, reduction='mean')\n  >>> # 举例:\n  >>> weight = Tensor(np.array([[1.0, 2.0, 3.0],\n  ...                           [4.0, 3.3, 2.2]]),\n  ...                 mindspore.float32)\n  >>> loss = nn.BCELoss(weight=weight)\n  >>> logits = Tensor(np.array([[0.1, 0.2, 0.3],\n  ...                           [0.5, 0.7, 0.9]]),\n  ...                 mindspore.float32)\n  >>> labels = Tensor(np.array([[0, 1, 0], [0, 0, 1]]),\n  ...                 mindspore.float32)\n  >>> output = loss(logits, labels)\n  >>> print(output)\n  >>> 1.8952923\n  </pre>\n  </td>\n  </tr>\n  </table>\n\n- 接口名称：mindspore.ops.split\n\n  变更内容：接口重构，接口使用方式更符合用户使用习惯，调整第2个和第3个参数的顺序，修改并扩展split_size_or_sections功能。\n\n  <table>\n  <tr>\n  <td style=\"text-align:center\"> 原接口 </td> <td style=\"text-align:center\"> v2.0.0-rc1接口 </td>\n  </tr>\n  <tr>\n  <td><pre>\n  ops.split(input_x, axis=0, output_num=1)\n  >>> # 举例:\n  >>> input = Tensor(np.array([[1, 1, 1, 1], [2, 2, 2, 2]]),\n  ...                mindspore.int32)\n  >>> output = ops.split(input, axis=1, output_num=4)\n  </pre>\n  </td>\n  <td><pre>\n  ops.split(tensor, split_size_or_sections, axis=0)\n  >>> # 举例:\n  >>> input = Tensor(np.array([[1, 1, 1, 1], [2, 2, 2, 2]]),\n  ...                mindspore.int32)\n  >>> output = ops.split(input, split_size_or_sections=1, axis=1)\n  </pre>\n  </td>\n  </tr>\n  </table>\n\n- 接口名称：mindspore.Tensor.split\n\n  变更内容：接口重构，接口使用方式更符合用户使用习惯，调整两个参数的位置，修改并扩展split_size_or_sections功能。\n\n  说明：参考ops.split例子。\n\n  <table>\n  <tr>\n  <td style=\"text-align:center\"> 原接口 </td> <td style=\"text-align:center\"> v2.0.0-rc1接口 </td>\n  </tr>\n  <tr>\n  <td><pre>\n  Tensor.split(axis=0, output_num=1)\n  </pre>\n  </td>\n  <td><pre>\n  Tensor.split(split_size_or_sections, axis=0)\n  </pre>\n  </td>\n  </tr>\n  </table>\n\n- 接口名称：mindspore.ops.pad\n\n  变更内容：修改参数名paddings为padding，添加mode和value功能。\n\n  <table>\n  <tr>\n  <td style=\"text-align:center\"> 原接口 </td> <td style=\"text-align:center\"> v2.0.0-rc1接口 </td>\n  </tr>\n  <tr>\n  <td><pre>\n  ops.pad(input_x, paddings)\n  >>> # 举例:\n  >>> input_x = Tensor(np.array([[-0.1, 0.3, 3.6],\n  ...                            [0.4, 0.5, -3.2]]),\n  ...                  mindspore.float32)\n  >>> paddings = ((1, 2), (2, 1))\n  >>> output = ops.pad(input_x, paddings)\n  </pre>\n  </td>\n  <td><pre>\n  ops.pad(input_x, padding, mode='constant', value=None)\n  >>> # 举例:\n  >>> input_x = Tensor(np.array([[-0.1, 0.3, 3.6],\n  ...                            [0.4, 0.5, -3.2]]),\n  ...                  mindspore.float32)\n  >>> paddings = (2, 1, 1, 2)\n  >>> output = ops.pad(input_x, paddings)\n  </pre>\n  </td>\n  </tr>\n  </table>\n\n- 接口名称：mindspore.ops.meshgrid\n\n  变更内容：入参由inputs改为*input。\n\n  <table>\n  <tr>\n  <td style=\"text-align:center\"> 原接口 </td> <td style=\"text-align:center\"> v2.0.0-rc1接口 </td>\n  </tr>\n  <tr>\n  <td><pre>\n  ops.meshgrid(inputs, indexing='xy')\n  >>> # 举例:\n  >>> x = Tensor(np.array([1, 2, 3, 4]).astype(np.int32))\n  >>> y = Tensor(np.array([5, 6, 7]).astype(np.int32))\n  >>> z = Tensor(np.array([8, 9, 0, 1, 2]).astype(np.int32))\n  >>> output = ops.meshgrid((x, y, z), indexing='xy')\n  </pre>\n  </td>\n  <td><pre>\n  ops.meshgrid(*inputs, indexing='xy')\n  >>> # 举例:\n  >>> x = Tensor(np.array([1, 2, 3, 4]).astype(np.int32))\n  >>> y = Tensor(np.array([5, 6, 7]).astype(np.int32))\n  >>> z = Tensor(np.array([8, 9, 0, 1, 2]).astype(np.int32))\n  >>> output = ops.meshgrid(x, y, z, indexing='xy')\n  </pre>\n  </td>\n  </tr>\n  </table>\n\n- 接口名称：mindspore.ops.max\n\n  变更内容：返回值调换顺序，由：“下标，最大值”改为“最大值，下标”。\n\n  <table>\n  <tr>\n  <td style=\"text-align:center\"> 原接口 </td> <td style=\"text-align:center\"> v2.0.0-rc1接口 </td>\n  </tr>\n  <tr>\n  <td><pre>\n  ops.max(x, axis=0, keep_dims=False)\n  >>> # 举例:\n  >>> input = Tensor(np.array([0.0, 0.4, 0.6, 0.7, 0.1]),\n  ...                mindspore.float32)\n  >>> index, output = ops.max(input)\n  >>> print(index, output)\n  >>> 3 0.7\n  </pre>\n  </td>\n  <td><pre>\n  ops.max(input, axis=None, keepdims=False, *, initial=None, where=True, return_indices=False)\n  >>> # 举例:\n  >>> input = Tensor(np.array([0.0, 0.4, 0.6, 0.7, 0.1]),\n  ...                mindspore.float32)\n  >>> output, index = ops.max(input, axis=0)\n  >>> print(output, index)\n  </pre>\n  </td>\n  </tr>\n  </table>\n\n- 接口名称：mindspore.ops.min\n\n  变更内容：返回值调换顺序，由：“下标，最小值”改为“最小值，下标”。\n\n  <table>\n  <tr>\n  <td style=\"text-align:center\"> 原接口 </td> <td style=\"text-align:center\"> v2.0.0-rc1接口 </td>\n  </tr>\n  <tr>\n  <td><pre>\n  ops.min(x, axis=0, keep_dims=False)\n  >>> # 举例:\n  >>> input = Tensor(np.array([0.0, 0.4, 0.6, 0.7, 0.1]),\n  ...                mindspore.float32)\n  >>> index, output = ops.min(input)\n  >>> 0 0.0\n  </pre>\n  </td>\n  <td><pre>\n  ops.min(input, axis=None, keepdims=False, *, initial=None, where=True, return_indices=False)\n  >>> # 举例:\n  >>> input = Tensor(np.array([0.0, 0.4, 0.6, 0.7, 0.1]),\n  ...                mindspore.float32)\n  >>> output, index = ops.min(input, keepdims=True)\n  >>> 0.0 0\n  </pre>\n  </td>\n  </tr>\n  </table>\n\n- 接口名称：mindspore.ops.random_gamma\n\n  变更内容：删除seed2参数，seed=0改为None。框架行为统一且符合用户实际使用场景及习惯。\n\n  <table>\n  <tr>\n  <td style=\"text-align:center\"> 原接口 </td> <td style=\"text-align:center\"> v2.0.0-rc1接口 </td>\n  </tr>\n  <tr>\n  <td><pre>\n  ops.random_gamma(shape, alpha, seed=0, seed2=0)\n  </pre>\n  </td>\n  <td><pre>\n  ops.random_gamma(shape, alpha, seed=None)\n  </pre>\n  </td>\n  </tr>\n  </table>\n\n- 接口名称：mindspore.ops.standard_laplace\n\n  变更内容：删除seed2参数，seed=0改为None。框架行为统一且符合用户实际使用场景及习惯。\n\n  <table>\n  <tr>\n  <td style=\"text-align:center\"> 原接口 </td> <td style=\"text-align:center\"> v2.0.0-rc1接口 </td>\n  </tr>\n  <tr>\n  <td><pre>\n  ops.standard_laplace(shape, seed=0, seed2=0)\n  </pre>\n  </td>\n  <td><pre>\n  ops.standard_laplace(shape, seed=None)\n  </pre>\n  </td>\n  </tr>\n  </table>\n\n- 接口名称：mindspore.ops.standard_normal\n\n  变更内容：删除seed2参数，seed=0改为None。框架行为统一且符合用户实际使用场景及习惯。\n\n  <table>\n  <tr>\n  <td style=\"text-align:center\"> 原接口 </td> <td style=\"text-align:center\"> v2.0.0-rc1接口 </td>\n  </tr>\n  <tr>\n  <td><pre>\n  ops.standard_normal(shape, seed=0, seed2=0)\n  </pre>\n  </td>\n  <td><pre>\n  ops.standard_normal(shape, seed=None)\n  </pre>\n  </td>\n  </tr>\n  </table>\n\n- 接口名称：mindspore.ops.bernoulli\n\n  变更内容：seed的默认值由-1改为None。符合用户实际使用场景。\n\n  <table>\n  <tr>\n  <td style=\"text-align:center\"> 原接口 </td> <td style=\"text-align:center\"> v2.0.0-rc1接口 </td>\n  </tr>\n  <tr>\n  <td><pre>\n  ops.bernoulli(x, p=0.5, seed=-1)\n  </pre>\n  </td>\n  <td><pre>\n  ops.bernoulli(input, p=0.5, seed=None)\n  </pre>\n  </td>\n  </tr>\n  </table>\n\n- 接口名称：mindspore.data_sink\n\n  变更内容：删除steps参数，jit参数名称修改为jit_config，新增input_signature参数。增加易用性，符合用户实际使用场景。\n\n  <table>\n  <tr>\n  <td style=\"text-align:center\"> 原接口 </td> <td style=\"text-align:center\"> v2.0.0-rc1接口 </td>\n  </tr>\n  <tr>\n  <td><pre>\n  mindspore.data_sink(fn, dataset, steps,\n                      sink_size=1, jit=False)\n  </pre>\n  </td>\n  <td><pre>\n  mindspore.data_sink(fn, dataset, sink_size=1,\n                      jit_config=None, input_signature=None)\n  </pre>\n  </td>\n  </tr>\n  </table>\n\n- 接口名称：mindspore.ops.conv2d\n\n  变更内容：扩展接口功能，添加bias参数，修改参数名及参数顺序。\n\n  <table>\n  <tr>\n  <td style=\"text-align:center\"> 原接口 </td> <td style=\"text-align:center\"> v2.0.0-rc1接口 </td>\n  </tr>\n  <tr>\n  <td><pre>\n  conv2d(inputs, weight, pad_mode=\"valid\",\n         padding=0, stride=1, dilation=1, group=1)\n  </pre>\n  </td>\n  <td><pre>\n  conv2d(input, weight, bias=None, stride=1,\n         pad_mode=\"valid\", padding=0, dilation=1, groups=1)\n  </pre>\n  </td>\n  </tr>\n  </table>\n\n- 接口名称：mindspore.dataset.vision.Pad\n\n  变更内容：调整Pad、RandomCrop、RandomCropWithBbox入参padding，当Padding输入长度为2的序列时，行为将从使用第一个值填充左/上边界，使用第二个值填充右/下边界，变为使用第一个值填充左/右边界，使用第二个值填充上/下边界。\n\n  说明：仅使用size为2的padding参数无法兼容旧版本的效果，需显式表示（左、右、上、下）。\n\n  <table>\n  <tr>\n  <td style=\"text-align:center\"> 原接口 </td> <td style=\"text-align:center\"> v2.0.0-rc1接口 </td>\n  </tr>\n  <tr>\n  <td><pre>\n  mindspore.dataset.vision.Pad(padding=(1,2))\n  代表图片的左/上填充 1像素，右/下填充 2像素\n  </pre>\n  </td>\n  <td><pre>\n  mindspore.dataset.vision.Pad(padding=(1,2,1,2))\n  代表图片的左/上填充 1像素，右/下填充 2像素\n  </pre>\n  </td>\n  </tr>\n  </table>\n\n- 接口名称：mindspore.dataset.Dataset.map\n\n  变更内容：删除column_order参数。因为在绝大部分的情况下，output_columns参数与column_order参数都是同一个值，不需要再传入column_order。若需要调整数据列顺序，使用mindspore.dataset.Dataset.project实现。\n\n  说明：\n\n  1) 在不需要改变列顺序时，直接去掉column_order参数即可。\n  2) 需要指定数据列顺序时，删除column_order参数，并在后面加上一个project方法进行列变换（如下面的例子）。\n\n  <table>\n  <tr>\n  <td style=\"text-align:center\"> 原接口 </td> <td style=\"text-align:center\"> v2.0.0-rc1接口 </td>\n  </tr>\n  <tr>\n  <td><pre>\n  >>> dataset = dataset.map(operations=[transforms],\n  ...                       input_columns=[\"column_a\"],\n  ...                       output_columns=[\"column_b\", \"column_c\"],\n  ...                       column_order=[\"column_c\", \"column_b\"])\n  </pre>\n  </td>\n  <td><pre>\n  >>> dataset = dataset.map(operations=[transforms],\n  ...                       input_columns=[\"column_a\"],\n  ...                       output_columns=[\"column_b\", \"column_c\"])\n  >>> dataset = dataset.project([\"column_c\", column_b\"])\")\n  </pre>\n  </td>\n  </tr>\n  </table>\n\n- 接口名称：mindspore.dataset.Dataset.batch\n\n  变更内容：删除column_order参数。因为在绝大部分的情况下，output_columns参数与column_order参数都是同一个值，不需要再传入column_order。若需要调整数据列顺序，使用mindspore.dataset.Dataset.project实现。\n\n  说明：\n\n  1) 在不需要改变列顺序时，直接去掉column_order参数即可。\n  2) 需要指定数据列顺序时，删除column_order参数，并在后面加上一个project方法进行列变换（如下面的例子）。\n\n  <table>\n  <tr>\n  <td style=\"text-align:center\"> 原接口 </td> <td style=\"text-align:center\"> v2.0.0-rc1接口 </td>\n  </tr>\n  <tr>\n  <td><pre>\n  >>> dataset = dataset.batch(batch_size=4,\n  ...                         input_columns=[\"column_a\"],\n  ...                         output_columns=[\"column_b\", \"column_c\"],\n  ...                         column_order=[\"column_c\", \"column_b\"])\n  </pre>\n  </td>\n  <td><pre>\n  >>> dataset = dataset.batch(batch_size=4, input_columns=[\"column_a\"]\n  ...                         output_columns=[\"column_b\", \"column_c\"])\n  >>> dataset = dataset.project([\"column_c\", column_b\"])\")\n  </pre>\n  </td>\n  </tr>\n  </table>\n\n- 接口名称：mindspore.dataset.Dataset.batch\n\n  变更内容：将batch方法拆分为：batch和padded_batch两个方法。pad_info参数从batch方法移动到padded_batch方法。\n\n  说明：如需使用pad_info参数，改用padded_batch方法。\n\n  <table>\n  <tr>\n  <td style=\"text-align:center\"> 原接口 </td> <td style=\"text-align:center\"> v2.0.0-rc1接口 </td>\n  </tr>\n  <tr>\n  <td><pre>\n  >>> dataset = dataset.batch(batch_size=4,\n  ...                         drop_remainder=True, pad_info=...)\n  </pre>\n  </td>\n  <td><pre>\n  >>> dataset = dataset.padded_batch(batch_size=4,\n  ...                                drop_remainder=True, pad_info=...)\n  </pre>\n  </td>\n  </tr>\n  </table>\n\n### Bug fixes\n\n- [I66PE6] 修复 AssignSub算子异常入参导致core dump的问题。\n\n- [I6F5E6] 修复 data_sink 方法在Ascend上执行超时的问题。\n\n### 其它\n\n- Windows系统支持由于还在优化中，rc版本暂不支持，将在2.0正式版本提供下载。\n\n### 贡献者\n\n感谢以下人员做出的贡献：\n\nalashkari,anzhengqi,archer2049,B.L.LAN,baihuawei,bichaoyang,BJ-WANG,Bokai Li,Brian-K,caifubi,caiyimeng,cathwong,changzherui,ChenDonYY,chenfei_mindspore,chengang,chengbin,chenhaozhe,chenjianping,chenkang,chenweifeng,chuht,chujinjin,davidanugraha,DavidFFFan,DeshiChen,douzhixing,emmmmtang,Erpim,Ethan,fangwenyi,fangzehua,fangzhou0329,fary86,fengyixing,gaoshuanglong,Gaoxiong,gaoyong10,gengdongjie,gongdaguo1,Greatpan,GuoZhibin,guozhijian,hangq,hanhuifeng,haozhang,hedongdong,Henry Shi,heterogeneous_to_backoff_2_0,huangbingjian,huanghui,huangxinjing,hujiahui8,hujingsong,huoxinyou,jachua,jiahongQian,jianghui58,jiangzhenguang,jiaorui,jiaoy1224,jijiarong,jjfeing,JoeyLin,json,JuiceZ,jxl,kairui_kou,KevinYi,kisnwang,KXiong,laiyongqiang,lanzhineng,liangchenghui,liangzelang,LiangZhibo,lianliguang,lichen,ligan,lijunbin,limingqi107,ling,linqingke,liubuyu,liuchao,liuchuting,liujunzhu,liuluobin,liutongtong9,liuyang811,lixiao,liyan2022,liyejun,liyuxia,looop5,luochao60,luojianing,luoyang,luoyuan,lyqlola,maning202007,maoyaomin,Margaret_wangrui,mayadong,MaZhiming,melody,mengyuanli,michaelzhu_70ab,Mohammad Motallebi,moran,NaCN,nomindcarry,OwenSec,panfengfeng,panshaowu,panzhihui,pkuliuliu,qinzheng,qiuzhongya,qujianwei,r1chardf1d0,Renyuan Zhang,RobinGrosman,shaojunsong,shenwei41,Soaringfish,tangdezhi_123,tanghuikang,tan-wei-cheng,TinaMengtingZhang,TronZhang,TuDouNi,VectorSL,wang_ziqi,wanghenchang,wangnan39,wangpingan,wangshaocong,wangshengnan123,wangtongyu6,weichaoran,wind-zyx,wqx,wtcheng,wujueying,wYann,XianglongZeng,xiaohanzhang,xiaotianci,xiaoyao,XinDu,xulei,xumengjuan1,xupan,xwkgch,yanghaoran,yangluhang,yangruoqi713,yangshuo,yangsijia,yangzhenzhang,yanzhenxiang2020,Yanzhi_YI,yao_yf,yefeng,yeyunpeng2020,Yi_zhang95,yide12,YijieChen,YingLai Lin,YingtongHu,youshu,yuchaojie,yuedongli,YuJianfeng,zangqx,ZengZitao,zhangbuxue,zhangdanyang,zhangdong,zhangfanghe,zhangqi,zhangqinghua,zhangyanhui,zhangyinxia,zhangyongxian,zhangzhaoju,zhanzhan,zhengzuohe,ZhidanLiu,zhixinaa,zhoufeng,zhouyaqiang0,zhuguodong,zhupuxu,zhuyuxiao,zichun_ye,zjun,zlq2020,zong_shuai,ZPaC,zuochuanyong,zyli2020,陈宇,范吉斌,冯一航,胡彬,宦晓玲,黄勇,雷元哲,李良灿,李林杰,刘崇鸣,刘力力,刘勇琪,吕浩宇,吕昱峰（Nate.River）,没有窗户的小巷,沈竞兴,十六夜,王程浩,王禹程,王振邦,徐安越,徐永飞,杨旭华,于振华,俞涵,张清华,张澍坤,张栩浩,张学同,赵英灼,周超,周洪叶,朱家兴\n\n欢迎以任何形式对项目提供贡献！\n\n## MindSpore Lite 2.0.0-rc1 Release Notes\n\n### 主要特性和增强\n\n#### MindSpore Lite云侧推理\n\n原MindSpore Lite版本主要面向手机、车机等边缘设备，新增云侧推理版本支持云侧多后端硬件资源的场景，支持Ascend及Nvidia GPU推理专用卡，高效利用云侧多核资源。\n\n原通过MindSpore训练版本集成的推理方式可以变更为基于MindSpore Lite进行适配集成，具体可参考[云侧推理快速入门](https://mindspore.cn/lite/docs/zh-CN/r2.0/quick_start/one_hour_introduction_cloud.html)，如果想要保持原始集成方式可以参考[MindSpore推理FAQ](https://mindspore.cn/docs/zh-CN/r2.0/faq/inference.html)。\n\n- [STABLE] 支持MindIR模型文件。\n- [STABLE] 支持将第三方Onnx、Tensorflow、Caffe模型通过MindSpore Lite转换工具转换为MindIR模型文件。\n- [STABLE] 一个发布包支持多种硬件后端：Ascend 310/310P/910、Nvidia GPU、CPU。\n- [STABLE] 支持`Model`接口和`ModelParallelRunner`并行推理接口。\n- [STABLE] 支持C++、Python和Java推理接口。\n\n#### API\n\n- 因原Python API配置参数较多、使用较复杂，因此在2.0版本针对Python API易用性进行优化，包括类构造方法、类属性的调整等，此外2.0及之后的Python API将整合到云侧推理场景，与旧版本不兼容。详细参见[Python API说明文档](https://www.mindspore.cn/lite/api/zh-CN/r2.0/mindspore_lite.html)。\n\n## MindSpore 2.0.0-alpha Release Notes\n\n### 主要特性和增强\n\n#### PyNative\n\n- MindSpore默认模式切换成PyNative模式。需要手动设置模式可以参考文档[计算图](https://www.mindspore.cn/tutorials/zh-CN/r2.0.0-alpha/advanced/compute_graph.html)。\n- 完成动态shape执行方案重构，提升反向构图性能，支持非padding方案的动态shape网络编程，当前主要验证网络Transformer-GPU、YOLOV5-GPU、ASR-Ascend。从[models仓](https://gitee.com/mindspore/models/tree/dynamic_shape)获取Transformer-GPU和YOLOV5-GPU。Ascend后端受算子适配度限制，只支持下列算子：Add、Assign、BatchMatMul、BiasAdd、BiasAddGrad、Cast、Conv2D、Conv2DBackpropFilter、Conv2DBackpropInput、CTCLoss、Div、Dropout、DropoutDoMask、Equal、ExpandDims、Gather、GetNext、LayerNorm、LayerNormGrad、LessEqual、Load、Log、LogicalAnd、LogicalNot、LogicalOr、LogSoftmax、LogSoftmaxGrad、MatMul、Maximum、Mul、Neg、NotEqual、NPUAllocFloatStatus、NPUClearFloatStatus、OneHot、RealDiv、Reciprocal、ReduceMean、ReduceSum、ReLU、ReluGrad、Reshape、Select、Softmax、StridedSlice、Sub、Tile、Transpose、UnsortedSegmentSum、ZerosLike。其余算子未经过完整验证，请酌情使用。\n\n#### DataSet\n\n- TFRecordDataset API支持直接读取通过GZIP或ZLIB压缩后的TFRecord文件。\n- NumpySlicesDataset API支持同时处理不同维度的数据。\n- 优化错误日志信息的结构，展示更清晰的调用栈信息便于调试、定位问题。\n- 修复分布式训练场景下 `mindspore.dataset.config.set_seed` 对随机种子设置不生效的问题。\n\n#### AutoParallel\n\n- 支持更多算子分布式能力。\n\n  Element Wise类算子：AddN、 BitwiseAnd、 BitwiseOr、 BitwiseXor、 CumProd、 HShrink、 HSigmoid、 IsFinite、 Mish、 MulNoNan、 Rint、 SeLU、 SoftShrink、 TruncateDiv、 TruncateMod、 Xdivy Xlogy、 InplaceAdd、 InplacSub、 InplaceUpdate、 Cdist、 L2Loss、 Lerp。\n\n  Math类算子：SquaredDifference、 Erfinv、 MaskedFill、 SplitV、 Gamma、 KLDivLoss、 LinSpace。Scatter类算子：ScatterAdd、ScatterDiv、ScatterMax、ScatterMul、ScatterNdAdd、ScatterNdSub、ScatterNdUpdate、ScatterSub、TensorScatterAdd、TensorScatterDiv、TensorScatterMax、TensorScatterMax、TensorScatterMul、TensorScatterAdd、TensorScatterUpdate。\n\n- 增加`transform_checkpoints`和`transform_checkpoint_by_rank`接口。给定转换前后的策略文件，即可实现对分布式权重转换。详情请参考[分布式弹性训练与推理](https://www.mindspore.cn/tutorials/experts/zh-CN/r2.0.0-alpha/parallel/resilience_train_and_predict.html)。\n\n### API变更\n\n#### 算子\n\n- [STABLE] `mindspore.ops.AdaptiveMaxPool3D` 新增算子原语。\n- [STABLE] `mindspore.ops.AdjustHue` 新增算子原语。\n- [STABLE] `mindspore.ops.BartlettWindow` 新增算子原语。\n- [STABLE] `mindspore.ops.BesselJ0` 新增算子原语。\n- [STABLE] `mindspore.ops.BesselJ1` 新增算子原语。\n- [STABLE] `mindspore.ops.BesselK0` 新增算子原语。\n- [STABLE] `mindspore.ops.BesselK0e` 新增算子原语。\n- [STABLE] `mindspore.ops.BesselK1` 新增算子原语。\n- [STABLE] `mindspore.ops.BesselK1e` 新增算子原语。\n- [STABLE] `mindspore.ops.BesselY0` 新增算子原语。\n- [STABLE] `mindspore.ops.BesselY1` 新增算子原语。\n- [STABLE] `mindspore.ops.Betainc` 新增算子原语。\n- [STABLE] `mindspore.ops.Bincount` 新增算子原语。\n- [STABLE] `mindspore.ops.BlackmanWindow` 新增算子原语。\n- [STABLE] `mindspore.ops.Bucketize` 新增算子原语。\n- [STABLE] `mindspore.ops.CombinedNonMaxSuppression` 新增算子原语。\n- [STABLE] `mindspore.ops.CompareAndBitpack` 新增算子原语。\n- [STABLE] `mindspore.ops.Complex` 新增算子原语。\n- [STABLE] `mindspore.ops.DataFormatVecPermute` 新增算子原语。\n- [STABLE] `mindspore.ops.EuclideanNorm` 新增算子原语。\n- [STABLE] `mindspore.ops.Expand` 新增算子原语。\n- [STABLE] `mindspore.ops.ExtractGlimpse` 新增算子原语。\n- [STABLE] `mindspore.ops.FillDiagonal` 新增算子原语。\n- [STABLE] `mindspore.ops.FractionalAvgPool` 新增算子原语。\n- [STABLE] `mindspore.ops.FractionalMaxPool` 新增算子原语。\n- [STABLE] `mindspore.ops.Gcd` 新增算子原语。\n- [STABLE] `mindspore.ops.HammingWindow` 新增算子原语。\n- [STABLE] `mindspore.ops.Histogram` 新增算子原语。\n- [STABLE] `mindspore.ops.HSVToRGB` 新增算子原语。\n- [STABLE] `mindspore.ops.Lcm` 新增算子原语。\n- [STABLE] `mindspore.ops.LeftShift` 新增算子原语。\n- [STABLE] `mindspore.ops.ListDiff` 新增算子原语。\n- [STABLE] `mindspore.ops.LogSpace` 新增算子原语。\n- [STABLE] `mindspore.ops.Lstsq` 新增算子原语。\n- [STABLE] `mindspore.ops.MatrixDiagPartV3` 新增算子原语。\n- [STABLE] `mindspore.ops.MatrixDiagV3` 新增算子原语。\n- [STABLE] `mindspore.ops.MatrixExp` 新增算子原语。\n- [STABLE] `mindspore.ops.MatrixPower` 新增算子原语。\n- [STABLE] `mindspore.ops.MaxPool3DWithArgmax` 新增算子原语。\n- [STABLE] `mindspore.ops.MaxUnpool2D` 新增算子原语。\n- [STABLE] `mindspore.ops.MultilabelMarginLoss` 新增算子原语。\n- [STABLE] `mindspore.ops.NextAfter` 新增算子原语。\n- [STABLE] `mindspore.ops.Orgqr` 新增算子原语。\n- [STABLE] `mindspore.ops.ReduceStd` 新增算子原语。\n- [STABLE] `mindspore.ops.RGBToHSV` 新增算子原语。\n- [STABLE] `mindspore.ops.RightShift` 新增算子原语。\n- [STABLE] `mindspore.ops.SampleDistortedBoundingBoxV2` 新增算子原语。\n- [STABLE] `mindspore.ops.ScaleAndTranslate` 新增算子原语。\n- [STABLE] `mindspore.ops.ScatterAddWithAxis` 新增算子原语。\n- [STABLE] `mindspore.ops.ScatterNdDiv` 新增算子原语。\n- [STABLE] `mindspore.ops.ScatterNdMax` 新增算子原语。\n- [STABLE] `mindspore.ops.ScatterNdMul` 新增算子原语。\n- [STABLE] `mindspore.ops.STFT` 新增算子原语。\n- [STABLE] `mindspore.ops.Trace` 新增算子原语。\n- [STABLE] `mindspore.ops.UpsampleNearest3D` 新增算子原语。\n- [STABLE] `mindspore.ops.UpsampleTrilinear3D` 新增算子原语。\n- [STABLE] `mindspore.parallel.transform_checkpoints` 新增分布式权重转换接口。\n- [STABLE] `mindspore.parallel.transform_checkpoint_by_rank` 新增分布式权重转换接口。\n\n#### 非兼容性变更\n\n##### Python API\n\n- `mindspore.ms_function`接口名替换为`mindspore.jit`，`mindspore.ms_function` 将在未来版本中弃用并删除。\n- `mindspore.ms_class`接口名替换为`mindspore.jit_class`，`mindspore.ms_class` 将在未来版本中弃用并删除。\n- `mindspore.ops.ms_kernel`接口名替换为`mindspore.ops.kernel`，`mindspore.ops.ms_kernel` 将在未来版本中弃用并删除。\n- `mindspore.dataset.map`接口参数 `column_order` 不再生效，使用`mindspore.dataset.project`替换。\n- `mindspore.dataset.close_pool`、`mindspore.dataset.to_device`、`mindspore.dataset.set_dynamic_columns` 接口在之前版本已废弃，当前版本正式删除。\n\n### Bug fixes\n\n- 修复混合精度函数式接口在图模式下不能修改后端驱动的问题。\n- 修复以下网络在单P场景下用户可自动传入device_id（mobilenetv1/fasterrcnn/yolov3/yolov4/yolov5/unet/openpose/simplepose/crnn/gnmtv2/faceattribute/facequality/facedetection） 。\n\n### 贡献者\n\n感谢以下人员做出的贡献:\n\nAGroupofProbiotocs, anzhengqi, askmiao, baihuawei, baiyangfan, bai-yangfan, bingyaweng, BowenK, buxue, caifubi, CaoJian, caojian05, caozhou, Cathy, changzherui, chenbo116, chenfei, chengxianbin, chenhaozhe, chenjianping, chenzomi, chenzupeng, chujinjin, cj, cjh9368, Corleone, damon0626, danish, Danish, davidmc, dayschan, doitH, dong-li001, fary86, fuzhiye, Gaoxiong, GAO_HYP_XYJ, gengdongjie, Gogery, gongdaguo, gray0v0, gukecai, guoqi, gzhcv, hangq, hanhuifeng2020, Harshvardhan, He, heleiwang, hesham, hexia, Hoai, HuangBingjian, huangdongrun, huanghui, huangxinjing, huqi, huzhifeng, hwjiaorui, Jiabin Liu, jianghui58, Jiaqi, jin-xiulang, jinyaohui, jjfeing, John, jonyguo, JulyAi, jzg, kai00, kingfo, kingxian, kpy, kswang, liuyongqi, laiyongqiang, leonwanghui, liangchenghui, liangzelang, lichen_101010, lichenever, lihongkang, lilei, limingqi107, ling, linqingke, Lin Xh, liubuyu, liuwenhao4, liuxiao78, liuxiao93, liuyang_655, liuzhongkai, Lixia, lixian, liyanliu, liyong, lizhenyu, luopengting, lvchangquan, lvliang, lz, maning202007, Margaret_wangrui, mengyuanli, Ming_blue, ms_yan, ougongchang, panfengfeng, panyifeng, Payne, Peilin, peixu_ren, Pengyongrong, qianlong, qianjiahong, r1chardf1d0, riemann_penn, rmdyh, Sheng, shenwei41, simson, Simson, Su, sunsuodong, tao_yunhao, tinazhang, VectorSL, , Wan, wandongdong, wangdongxu, wangmin,  wangyue01, wangzhe, wanyiming, Wei, wenchunjiang, wilfChen, WilliamLian, wsc, wudenggang, wukesong, wuweikang, wuxuejian, Xiao Tianci, Xiaoda, xiefangqi, xinyunfan, xuanyue, xuyongfei, yanghaitao, yanghaitao1, yanghaoran, YangLuo, yangruoqi713, yankai, yanzhenxiang2020, yao_yf, yepei6, yeyunpeng, Yi, yoni, yoonlee666, yuchaojie, yujianfeng, yuximiao, zengzitao, Zhang,  zhanghuiyao, zhanghui_china, zhangxinfeng3, zhangyihui, zhangz0911gm, zhanke, zhanyuan, zhaodezan, zhaojichen, zhaoting, zhaozhenlong, zhengjun10, zhiqwang, zhoufeng, zhousiyi, zhouyaqiang, zhouyifengCode, Zichun, Ziyan, zjun, ZPaC, wangfengwfwf, zymaa, gerayking, shu-kun-zhang.\n\n欢迎以任何形式对项目提供贡献！\n\n## MindSpore 1.10.1 Release Notes\n\n### 问题修复\n\n- 修复logsumexp防溢出处理中未考虑指定axis的问题\n- 修复proto文件的编译依赖问题\n- 修复print算子打印结果不正常的问题\n- 修复equal算子越界问题\n- 修复函数被@jit修饰后，导致的cell_id解析不正确的问题\n- 修复GNN场景数据类型校验错误\n- 修复Dataset map多进程退化成线程的问题\n\n### 贡献者\n\n感谢以下人员做出的贡献:\n\narcher2049, caifubi, chenfei_mindspore, gaoshuanglong, Greatpan, guozhijian, huoxinyou, Kxiong, lanzhineng, lijunbin, liubuyu, liuchuting, luochao60, lyqlola, nomindcarry, TuDouNi, xiaotianci, xupan, yangshuo, yefeng, YingtongHu, yuchaojie, zhoufeng, ZPaC, 刘勇琪, 吕昱峰, 王禹程, 于振华.\n\n欢迎以任何形式对项目提供贡献！\n\n## MindSpore 1.10.0 Release Notes\n\n### 主要特性和增强\n\n#### DataSet\n\n- [STABLE]下沉模式超时等待时间调整，默认调整到600s，以解决数据下沉模式时因环境资源竞争、计算量大等因素容易导致GetNext算子等待超时的问题。\n\n### Bug fixes\n\n- 修复AMP中部分Primitive算子无法在图模式下实例化导致接口不可用的问题。\n- 修复昇腾平台算力切分场景下LSTM网络中DynamicRNN算子执行失败的问题。\n- 修复mobilenet, fasterrcnn, yolo等网络单卡训练脚本DEVICE_ID在启动脚本中写死的问题。\n\n### 贡献者\n\n感谢以下人员做出的贡献:\n\nAGroupofProbiotocs, anzhengqi, askmiao, baihuawei, baiyangfan, bai-yangfan, bingyaweng, BowenK, buxue, caifubi, CaoJian, caojian05, caozhou, Cathy, changzherui, chenbo116, chenfei, chengxianbin, chenhaozhe, chenjianping, chenzomi, chenzupeng, chujinjin, cj, cjh9368, Corleone, damon0626, danish, Danish, davidmc, dayschan, doitH, dong-li001, fary86, fuzhiye, Gaoxiong, GAO_HYP_XYJ, gengdongjie, Gogery, gongdaguo, gray0v0, gukecai, guoqi, gzhcv, hangq, hanhuifeng2020, Harshvardhan, He, heleiwang, hesham, hexia, Hoai, HuangBingjian, huangdongrun, huanghui, huangxinjing, huqi, huzhifeng, hwjiaorui, Jiabin Liu, jianghui58, Jiaqi, jin-xiulang, jinyaohui, jjfeing, John, jonyguo, JulyAi, jzg, kai00, kingfo, kingxian, kpy, kswang, liuyongqi, laiyongqiang, leonwanghui, liangchenghui, liangzelang, lichen_101010, lichenever, lihongkang, lilei, limingqi107, ling, linqingke, Lin Xh, liubuyu, liuwenhao4, liuxiao78, liuxiao93, liuyang_655, liuzhongkai, Lixia, lixian, liyanliu, liyong, lizhenyu, luopengting, lvchangquan, lvliang, lz, maning202007, Margaret_wangrui, mengyuanli, Ming_blue, ms_yan, ougongchang, panfengfeng, panyifeng, Payne, Peilin, peixu_ren, Pengyongrong, qianlong, qianjiahong, r1chardf1d0, riemann_penn, rmdyh, Sheng, shenwei41, simson, Simson, Su, sunsuodong, tao_yunhao, tinazhang, VectorSL, , Wan, wandongdong, wangdongxu, wangmin,  wangyue01, wangzhe, wanyiming, Wei, wenchunjiang, wilfChen, WilliamLian, wsc, wudenggang, wukesong, wuweikang, wuxuejian, Xiao Tianci, Xiaoda, xiefangqi, xinyunfan, xuanyue, xuyongfei, yanghaitao, yanghaitao1, yanghaoran, YangLuo, yangruoqi713, yankai, yanzhenxiang2020, yao_yf, yepei6, yeyunpeng, Yi, yoni, yoonlee666, yuchaojie, yujianfeng, yuximiao, zengzitao, Zhang,  zhanghuiyao, zhanghui_china, zhangxinfeng3, zhangyihui, zhangz0911gm, zhanke, zhanyuan, zhaodezan, zhaojichen, zhaoting, zhaozhenlong, zhengjun10, zhiqwang, zhoufeng, zhousiyi, zhouyaqiang, zhouyifengCode, Zichun, Ziyan, zjun, ZPaC, wangfengwfwf, zymaa, gerayking, shu-kun-zhang.\n\n欢迎以任何形式对项目提供贡献！\n\n## MindSpore Lite 1.10.0 Release Notes\n\n### Bug fixes\n\n- 修复Arithmetic类CPU算子动态shape场景下可能的计算精度问题。\n- 修复Deconv int8量化算子重量化写入地址错误问题。\n\n## MindSpore 1.9.0 Release Notes\n\n### 主要特性和增强\n\n#### FrontEnd\n\n- [STABLE] 新增面向对象+函数式融合编程范式，提供 `mindspore.amp.LossScaler` 、 `mindspore.amp.DynamicLossScaler` 、 `mindspore.amp.StaticLossScaler` 、 `mindspore.amp.auto_mixed_precision` 、 `mindspore.amp.all_finite` 等融合编程范式下的混合精度接口。\n\n### API变更\n\n#### 算子\n\n- [STABLE] `nn.AdaptiveAvgPool3d` 新增nn接口。\n- [STABLE] `ops.adaptive_avg_pool3d` 新增functional接口。\n- [STABLE] `ops.addcdiv` 新增functional接口。\n- [STABLE] `ops.addcmul` 新增functional接口。\n- [STABLE] `ops.approximate_equal` 新增GPU、CPU支持。\n- [STABLE] `ops.atanh` 新增GPU支持。\n- [STABLE] `ops.bessel_i0` 新增GPU支持。\n- [STABLE] `ops.bessel_i0e` 新增Ascend支持。\n- [STABLE] `ops.bessel_i1` 新增GPU支持。\n- [STABLE] `ops.bessel_i1e` 新增Ascend、GPU支持。\n- [STABLE] `ops.bessel_j0` 新增GPU支持。\n- [STABLE] `ops.bessel_j1` 新增GPU支持。\n- [STABLE] `ops.bessel_k0` 新增GPU支持。\n- [STABLE] `ops.bessel_k0e` 新增GPU支持。\n- [STABLE] `ops.bessel_k1` 新增GPU支持。\n- [STABLE] `ops.bessel_k1e` 新增GPU支持。\n- [STABLE] `ops.bessel_y0` 新增GPU支持。\n- [STABLE] `ops.bessel_y1` 新增GPU支持。\n- [STABLE] `ops.bias_add` 新增functional接口。\n- [STABLE] `ops.bitwise_and` 新增GPU支持。\n- [STABLE] `ops.bitwise_or` 新增GPU支持。\n- [STABLE] `ops.bitwise_xor` 新增GPU支持。\n- [STABLE] `ops.grid_sample` 新增Ascend支持。\n- [STABLE] `ops.inplace_update` 新增CPU支持。\n- [STABLE] `ops.isclose` 新增Ascend、GPU支持。\n- [STABLE] `ops.isnan` 新增Ascend支持。\n- [STABLE] `ops.lerp` 新增GPU支持。\n- [STABLE] `ops.random_poisson` 新增functional接口。\n- [STABLE] `ops.reverse_sequence` 新增functional接口。\n- [STABLE] `ops.scatter_mul` 新增GPU支持。\n- [STABLE] `ops.scatter_nd_max` 新增functional接口。\n- [STABLE] `ops.scatter_nd_min` 新增functional接口。\n- [STABLE] `ops.SparseToDense` 新增GPU支持。\n- [STABLE] `ops.square` 新增functional接口。\n- [STABLE] `ops.standard_laplace` 新增GPU支持。\n- [STABLE] `ops.std` 新增functional接口。\n- [STABLE] `ops.trunc` 新增Ascend、GPU支持。\n- [STABLE] `ops.unsorted_segment_sum` 新增functional接口。\n- [STABLE] `ops.xdivy` 新增functional接口。\n- [STABLE] `ops.xlogy` 新增GPU支持。\n- `ops.poisson` 接口废弃使用，对应新接口为 `ops.random_poisson` 。\n- `ops.SparseApplyAdagrad` 接口废弃使用，可使用 `ops.SparseApplyAdagradV2` 接口替代。\n\n### Bug fixes\n\n- [BUGFIX] 修改混合精度O2 level的判断逻辑，在原来屏蔽 `BatchNorm1d` 、 `BatchNorm2d` 算子的基础上，添加另外两个屏蔽算子`BatchNorm3d`和`LayerNorm`，这4个算子依然用float32数据类型计算。\n\n- [BUGFIX] Dataset处理字符串类型数据时，若调用`create_dict_iterator`或`create_tuple_iterator`接口时指定了`output_numpy=True`，获取到的数据会是`numpy.bytes_`类型。修复此问题后接口会直接返回`numpy.str_`类型数据，用户无需再对其进行字符串解码操作。同样，在使用自定义数据处理函数时，接收到的数据也将直接是`numpy.str_`类型，与原始数据类型相匹配。\n\n### 贡献者\n\n感谢以下人员做出的贡献:\n\nAGroupofProbiotocs, anzhengqi, askmiao, baihuawei, baiyangfan, bai-yangfan, bingyaweng, BowenK, buxue, caifubi, CaoJian, caojian05, caozhou, Cathy, changzherui, chenbo116, chenfei, chengxianbin, chenhaozhe, chenjianping, chenzomi, chenzupeng, chujinjin, cj, cjh9368, Corleone, damon0626, danish, Danish, davidmc, dayschan, doitH, dong-li001, fary86, fuzhiye, Gaoxiong, GAO_HYP_XYJ, gengdongjie, Gogery, gongdaguo, gray0v0, gukecai, guoqi, gzhcv, hangq, hanhuifeng2020, Harshvardhan, He, hesham, hexia, Hoai, HuangBingjian, huangdongrun, huanghui, huangxinjing, huqi, huzhifeng, hwjiaorui, Jiabin Liu, jianghui58, Jiaqi, jin-xiulang, jinyaohui, jjfeing, John, jonyguo, JulyAi, jzg, kai00, kingfo, kingxian, kpy, kswang, liuyongqi, laiyongqiang, leonwanghui, liangchenghui, liangzelang, lichen_101010, lichenever, lihongkang, lilei, limingqi107, ling, linqingke, Lin Xh, liubuyu, liuwenhao4, liuxiao78, liuxiao93, liuyang_655, liuzhongkai, liyanliu, lizhenyu, lvchangquan, lvliang, lz, maning202007, Margaret_wangrui, mengyuanli, Ming_blue, ms_yan, panfengfeng, panyifeng, Payne, peixu_ren, Pengyongrong, qianjiahong, r1chardf1d0, riemann_penn, rmdyh, Sheng, shenwei41, simson, Simson, Su, sunsuodong, tao_yunhao, tinazhang, VectorSL, Wan, wandongdong, wangdongxu, wangmin,  wangyue01, wangzhe, wanyiming, Wei, wenchunjiang, wilfChen, WilliamLian, wsc, wudenggang, wukesong, wuweikang, Xiao Tianci, Xiaoda, xiefangqi, xinyunfan, xuanyue, xuyongfei, yanghaitao, yanghaoran, YangLuo, yangruoqi713, yankai, yanzhenxiang2020, yao_yf, yepei6, yeyunpeng, Yi, yoni, yoonlee666, yuchaojie, yujianfeng, yuximiao, zengzitao, Zhang,  zhanghuiyao, zhanghui_china, zhangxinfeng3, zhangyihui, zhangz0911gm, zhanyuan, zhaojichen, zhaoting, zhaozhenlong, zhengjun10, zhiqwang, zhoufeng, zhousiyi, zhouyaqiang, zhouyifengCode, Zichun, Ziyan, zjun, ZPaC, wangfengwfwf, zymaa, gerayking, shu-kun-zhang.\n\n欢迎以任何形式对项目提供贡献！\n\n## MindSpore 1.8.1 Release Notes\n\n### API变更\n\n#### 算子\n\n- [STABLE] ops.ApplyAdagradDA 新增GPU、CPU支持。\n- [STABLE] ops.ApplyAdagradV2 新增CPU支持。\n- [STABLE] ops.ApplyCenteredRmsProp 新增Ascend动态shape支持。\n- [STABLE] ops.ApplyFtrl 新增CPU支持。\n- [STABLE] ops.ApplyGradientDescent 新增CPU支持。\n- [STABLE] ops.ApplyPowerSign 新增CPU支持。\n- [STABLE] ops.ApplyProximalAdagrad 新增GPU、CPU支持。\n- [STABLE] ops.ApplyRmsProp 新增Ascend动态shape支持。\n- [STABLE] ops.max 新增functional接口。\n- [STABLE] ops.atan2 新增functional接口。\n- [STABLE] ops.cummax 新增GPU支持。\n- [STABLE] ops.cummin 新增GPU、CPU支持。\n- [STABLE] ops.diag 新增GPU支持。\n- [STABLE] ops.expand_dims 新增functional接口。\n- [STABLE] ops.gather_elements 新增functional接口。\n- [STABLE] ops.grid_sample 新增GPU支持。\n- [STABLE] ops.hardswish 新增Ascend支持。\n- [BETA] ops.index_fill 新增GPU支持。\n- [BETA] ops.inplace_update 新增CPU支持。\n- [BETA] nn.InstanceNorm1d 新增GPU支持。\n- [BETA] nn.InstanceNorm2d 新增GPU支持。\n- [BETA] nn.InstanceNorm3d 新增GPU支持。\n- [STABLE] ops.log1p 新增functional接口。\n- [STABLE] ops.masked_fill 新增GPU、CPU支持。\n- [BETA] ops.matrix_diag_part 新增GPU支持。\n- [BETA] ops.matrix_diag 新增GPU支持。\n- [BETA] ops.matrix_set_diag 新增GPU支持。\n- [STABLE] ops.max_pool3d 新增GPU支持。\n- [STABLE] ops.nll_loss 新增functional接口。\n- [STABLE] ops.one_hot 新增functional接口。\n- [STABLE] ops.pad 新增functional接口。\n- [STABLE] ops.random_gamma 新增CPU支持。\n- [STABLE] ops.amax 新增functional接口。\n- [STABLE] ops.mean 新增functional接口。\n- [STABLE] ops.amin 新增functional接口。\n- [STABLE] ops.prod 新增functional接口。\n- [STABLE] ops.renorm 新增Ascend、GPU、CPU支持。\n- [BETA] ops.tensor_scatter_elements 新增Ascend、GPU、CPU支持。\n- [STABLE] ops.scatter_max 新增GPU支持。\n- [STABLE] ops.scatter_min 新增GPU支持。\n- [STABLE] ops.scatter_nd 新增functional接口。\n- [STABLE] ops.scatter_nd_max 新增GPU支持。\n- [STABLE] ops.scatter_update 新增functional接口。\n- [STABLE] ops.binary_cross_entropy_with_logits 新增CPU支持。\n- [STABLE] ops.smooth_l1_loss 新增functional接口。\n- [STABLE] ops.space_to_batch_nd 新增CPU支持。\n- [STABLE] ops.SparseApplyAdagrad 新增GPU、CPU支持。\n- [STABLE] ops.sparse_segment_mean 新增GPU、CPU支持。\n- [STABLE] ops.squeeze 新增functional接口。\n- [STABLE] ops.standard_laplace 新增CPU支持。\n- [BETA] nn.ReflectionPad1d 新增Ascend、GPU、CPU支持。\n- [BETA] nn.ReflectionPad2d 新增Ascend、GPU、CPU支持。\n- [STABLE] nn.SiLU 新增Ascend、GPU、CPU支持。\n- [STABLE] ops.transpose 新增functional接口。\n- [STABLE] ops.uniform_candidate_sampler 新增CPU支持。\n- [STABLE] ops.uniform 新增functional接口。\n- [STABLE] ops.unique_with_pad 新增GPU支持。\n- [STABLE] ops.unstack 新增functional接口。\n- [BETA] ops.interpolate 新增GPU、CPU支持。\n- [STABLE] ops.xdivy 新增CPU支持。\n- [STABLE] ops.xlogy 新增CPU支持。\n\n## MindSpore 1.8.0 Release Notes\n\n### 主要特性和增强\n\n#### FrontEnd\n\n- [BETA]  提供`mindspore.train.Model.fit` API，增加两种callback方法 `mindspore.train.callback.EarlyStopping` 和 `mindspore.train.callback.ReduceLROnPlateau`。\n- [BETA] 自定义算子支持Julia算子。\n- [BETA] 自定义算子支持Hybrid DSL算子。\n- [STABLE] export()接口支持自定义加密算法导出模型，load()接口支持自定义解密算法导入模型。\n- [BETA]   [动静统一] [易用性] 图编译支持常量类型设置可变(1.8版本支持tuple/list/dict)。\n- [BETA]   [动静统一] 常量场景下控制流内支持JIT Fallback功能。\n- [STABLE] [动静统一] 支持图模式常量场景下Python raise语句。\n- [STABLE] [动静统一] 支持图模式常量场景下Python assert语句。\n- [STABLE] [动静统一] 支持图模式常量场景下Python print语句。\n- [STABLE] [动静统一] 支持图模式str.format()方法。\n- [STABLE] [动静统一] 支持图模式用slice方法对list赋值。\n- [STABLE] [动静统一] 图模式支持创建和调用自定义类的实例。\n- [STABLE] [动静统一] 支持从Cell数组/自定义类数组中获取类的属性。\n- [STABLE] [动静统一] 图模式下isinstance支持场景扩展。\n- [STABLE] 自定义算子修饰符'ms_hybrid'重名为'ms_kernel'。\n- [BETA] 自定义算子Hybrid DSL支持CPU后端。\n- [BETA] 自定义算子昇腾后端新增自定义调度原语语法支持。\n\n#### PyNative\n\n- [STABLE] 实现AdamWeightDecay算子，替代原有小算子组合方式。\n- [STABLE] 动态图下使用动静结合的方式执行优化器。\n- [STABLE] 优化PyNative反向图和ms_function的执行性能。\n\n#### Auto Parallel\n\n- [STABLE] 对接AllToAll单算子模式。在图编译等级为O0下，支持AllToAll算子调用。\n- [STABLE] 整图下沉支持MPI启动。整图下沉的模式下，支持使用MPI的方式启动。\n- [STABLE] 模型权重的Seed提供并行接口配置。在用户不通过mindspore.set_seed设置随机数种子时，每个参数初始化的随机数种子为当前分片索引决定。当配置随机数种子之后，相同shape以及相同切分策略的权重，其初始化的结果一致。\n- [STABLE] HCCL屏蔽内部全连接/非全连接。允许一次训练过程中同时有全连接AllToAllv和分级AllToAllv。\n- [BETA] CPU优化器融合。通过优化器跨参数融合，将多个优化器算子按数据类型融合成，带来性能提升。目前已在CPU AdamWeightDecay优化器上做过验证。用户可以通过网络cell类中的flatten_weights方法启用该功能。\n\n#### Executor\n\n- [STABLE] 开放南向芯片对接接口。\n- [STABLE] 使用多Actor融合执行提升运行时的执行性能。\n- [STABLE] NopOp算子(eg. Reshape)执行消除。\n- [STABLE] Embedding Cache架构切换统一分布式运行时。\n- [STABLE] Parameter Server训练切换统一分布式运行时。\n- [STABLE] 支持CPU Parameter Server模式训练。\n\n#### DataSet\n\n- [STABLE] 对于数据集对象使用map操作时，同时num_parallel_workers>1并且python_multiprocessing=True时，进行了多进程的机制优化，使得数据通道与子进程一一映射，避免了过多的文件句柄占用，同时close_pool这个接口也被删除。\n- [STABLE] 新增一批Vision、Text和Audio类数据增强操作。\n- [STABLE] 修复数据集类的flat_map方法未将结果展平的错误。\n- [STABLE] 统一数据集增强API的导入路径，提供更简单的使用方法，请参阅[最新的API用法](https://www.mindspore.cn/docs/zh-CN/r1.8/api_python/mindspore.dataset.vision.html)。\n\n### API变更\n\n#### 算子\n\n- [STABLE] ops.adaptive_avg_pool2d 新增GPU支持。\n- [BETA] ops.adaptive_max_pool2d  新增Ascend、GPU、CPU支持。\n- [BETA] ops.approximate_equal 新增CPU支持。\n- [STABLE] ops.argmin 新增CPU支持。\n- [BETA] ops.assign_sub 新增CPU支持。\n- [STABLE] ops.bernoulli 新增GPU支持。\n- [BETA] ops.bessel_i0 新增CPU支持。\n- [BETA] ops.bessel_i0e 新增CPU支持。\n- [BETA] ops.bessel_i1 新增CPU支持。\n- [BETA] ops.bessel_i1e 新增CPU支持。\n- [STABLE] ops.bessel_j0 新增CPU支持。\n- [STABLE] ops.bessel_j1 新增CPU支持。\n- [STABLE] ops.bessel_k0 新增CPU支持。\n- [STABLE] ops.bessel_k0e 新增CPU支持。\n- [BETA] ops.bessel_k1 新增CPU支持。\n- [BETA] ops.bessel_k1e 新增CPU支持。\n- [STABLE] ops.bessel_y0 新增CPU支持。\n- [STABLE] ops.bessel_y1 新增CPU支持。\n- [STABLE] ops.bitwise_and 新增CPU支持。\n- [STABLE] ops.bitwise_or 新增CPU支持。\n- [STABLE] ops.bitwise_xor 新增CPU支持。\n- [STABLE] ops.broadcast_to 新增functional接口。\n- [BETA] ops.ceil 新增GPU、CPU支持。\n- [BETA] ops.col2im 新增GPU支持。\n- [BETA] ops.concat 新增functional接口。\n- [STABLE] ops.cosh 新增GPU支持。\n- [STABLE] ops.ctc_greedy_decoder 新增Ascend、CPU支持。\n- [BETA] ops.DataFormatDimMap 新增GPU、CPU支持。\n- [BETA] ops.dropout2d 新增GPU、CPU支持。\n- [BETA] ops.dropout3d 新增CPU支持。\n- [BETA] ops.erf 新增CPU支持。\n- [BETA] ops.erfc 新增CPU支持。\n- [STABLE] ops.expand_dims 新增functional接口。\n- [STABLE] ops.fast_gelu 新增GPU、CPU支持。\n- [STABLE] ops.flatten Ascend动态shape支持。\n- [BETA] ops.ger 新增GPU、CPU支持。\n- [STABLE] ops.gumbel_softmax 新增Ascend、GPU、CPU支持。\n- [BETA] ops.hardshrink 新增GPU、CPU支持。\n- [BETA] ops.index_add 新增CPU支持。\n- [BETA] ops.inplace_add 新增CPU支持。\n- [BETA] ops.inplace_sub 新增CPU支持。\n- [STABLE] ops.intopk 新增CPU支持。\n- [STABLE] ops.inv 新增GPU、CPU支持。\n- [STABLE] ops.invert 新增GPU、CPU支持。\n- [BETA] ops.isclose 新增CPU支持。\n- [STABLE] ops.lerp 新增CPU支持。\n- [BETA] ops.linspace 新增CPU支持。\n- [BETA] ops.log_softmax 新增functional接口。\n- [BETA] ops.norm 新增Ascend、GPU、CPU支持。\n- [BETA] ops.lrn 新增CPU支持。\n- [BETA] ops.masked_select 新增GPU支持。\n- [BETA] ops.matrix_band_part 新增GPU、CPU支持。\n- [BETA] ops.matrix_solve 新增GPU、CPU支持。\n- [BETA] ops.meshgrid 新增CPU支持。\n- [STABLE] ops.mish 新增CPU支持。\n- [BETA] ops.nonzero  新增GPU支持。\n- [STABLE] ops.padding 新增GPU、CPU支持。\n- [BETA] ops.pow 新增Ascend动态shape支持。\n- [BETA] ops.range 新增functional接口。\n- [BETA] ops.round 新增Ascend动态shape支持。\n- [STABLE] ops.scatter_add 新增Ascend动态shape支持。\n- [STABLE] ops.scatter_div 新增Ascend动态shape支持。\n- [BETA] ops.scatter_max 新增GPU支持。\n- [BETA] ops.scatter_min 新增GPU支持。\n- [BETA] ops.scatter_nd_add 新增CPU支持。\n- [STABLE] ops.scatter_nd_div 新增GPU、CPU支持。\n- [STABLE] ops.scatter_nd_min 新增GPU、CPU支持。\n- [STABLE] ops.scatter_nd_mul 新增GPU、CPU支持。\n- [BETA] ops.scatter_nd_sub 新增CPU支持。\n- [STABLE] ops.scatter_update 新增Ascend动态shape支持。\n- [BETA] ops.select 新增Ascend动态shape支持。\n- [BETA] ops.selu 新增GPU、CPU支持。\n- [BETA] ops.soft_shrink 新增GPU、CPU支持。\n- [BETA] ops.softsign 新增CPU支持。\n- [STABLE] ops.tan 新增GPU支持。\n- [BETA] ops.tensor_scatter_add 新增Ascend、CPU支持。\n- [STABLE] ops.tensor_scatter_div 新增GPU、CPU支持。\n- [STABLE] ops.tensor_scatter_mul 新增GPU、CPU支持。\n- [BETA] ops.tensor_scatter_sub 新增Ascend、CPU支持。\n- [STABLE] nn.AdaptiveAvgPool1d 新增Ascend、GPU、CPU支持。\n- [STABLE] nn.AdaptiveMaxPool1d 新增Ascend、GPU、CPU支持。\n- [BETA] nn.BiDense 新增Ascend、GPU、CPU支持。\n- [STABLE] nn.ConstantPad1d 新增Ascend、GPU、CPU支持。\n- [STABLE] nn.ConstantPad2d 新增Ascend、GPU、CPU支持。\n- [STABLE] nn.ConstantPad3d 新增Ascend、GPU、CPU支持。\n- [STABLE] nn.Hardtanh 新增Ascend、GPU、CPU支持。\n- [STABLE] nn.HuberLoss 新增Ascend、GPU、CPU支持。\n- [STABLE] nn.RReLU 新增Ascend、GPU、CPU支持。\n- [STABLE] nn.Tanhshrink 新增Ascend、GPU、CPU支持。\n- [STABLE] nn.Threshold 新增Ascend、GPU、CPU支持。\n- [STABLE] nn.ZeroPad2d 新增Ascend、GPU、CPU支持。\n- [BETA] ops.unique_consecutive 新增GPU支持。\n- [STABLE] ops.unsorted_segment_max 新增CPU支持。\n- [STABLE] ops.unsorted_segment_min 新增CPU支持。\n- [STABLE] ops.unsorted_segment_prod 新增GPU支持。\n\n#### 非兼容性变更\n\n##### Python API\n\n- 不再支持DVPP模拟算法，删除 `mindspore.dataset.vision.c_transforms.SoftDvppDecodeRandomCropResizeJpeg` 和 `mindspore.dataset.vision.c_transforms.SoftDvppDecodeResizeJpeg` 接口。\n- LossMonitor中增加`on_train_epoch_end` 方法，实现在 `mindspore.train.Model.fit` 中使用时，打印epoch级别的metric信息。\n- TimeMonitor打印内容变更，打印内容加入\"train\"或\"eval\"用于区分训练和推理阶段。\n- load_checkpoint 接口的`filter_prefix`：不再支持空字符串(\"\")，匹配规则由强匹配修改为模糊匹配。\n\n#### import优化\n\nmindspore.context、mindspore.parallel、mindspore.profiler、mindspore.train模块的接口可直接在mindspore模块使用。原有用法仍可以继续支持。\n\n例如：\n\n- `mindspore.context.set_context`可简化为`mindspore.set_context`。\n- `mindspore.parallel.set_algo_parameters`可简化为`mindspore.set_algo_parameters`。\n- `mindspore.profiler.Profiler`可简化为`mindspore.Profiler`。\n- `mindspore.train.callback.Callback`可简化为`mindspore.train.Callback`。\n\nAPI页面统一汇总至：<https://www.mindspore.cn/docs/zh-CN/r1.8/api_python/mindspore.html>。\n\n### 贡献者\n\n感谢以下人员做出的贡献：\n\nAGroupofProbiotocs, anzhengqi, askmiao, baihuawei, baiyangfan, bai-yangfan, bingyaweng, BowenK, buxue, caifubi, CaoJian, caojian05, caozhou, Cathy, changzherui, chenbo116, chenfei, chengxianbin, chenhaozhe, chenjianping, chenzomi, chenzupeng, chujinjin, cj, cjh9368, Corleone, damon0626, danish, Danish, davidmc, dayschan, doitH, dong-li001, fary86, fuzhiye, Gaoxiong, GAO_HYP_XYJ, gengdongjie, Gogery, gongdaguo, gray0v0, gukecai, guoqi, gzhcv, hangq, hanhuifeng2020, Harshvardhan, He, heleiwang, hesham, hexia, Hoai, HuangBingjian, huangdongrun, huanghui, huangxinjing, huqi, huzhifeng, hwjiaorui, Jiabin Liu, jianghui58, Jiaqi, jin-xiulang, jinyaohui, jjfeing, John, jonyguo, JulyAi, jzg, kai00, kingfo, kingxian, kpy, kswang, liuyongqi, laiyongqiang, leonwanghui, liangchenghui, liangzelang, lichen_101010, lichenever, lihongkang, lilei, limingqi107, ling, linqingke, Lin Xh, liubuyu, liuwenhao4, liuxiao78, liuxiao93, liuyang_655, liuzhongkai, Lixia, lixian, liyanliu, liyong, lizhenyu, luopengting, lvchangquan, lvliang, lz, maning202007, Margaret_wangrui, mengyuanli, Ming_blue, ms_yan, ougongchang, panfengfeng, panyifeng, Payne, Peilin, peixu_ren, Pengyongrong, qianlong, qianjiahong, r1chardf1d0, riemann_penn, rmdyh, Sheng, shenwei41, simson, Simson, Su, sunsuodong, tao_yunhao, tinazhang, VectorSL, , Wan, wandongdong, wangdongxu, wangmin,  wangyue01, wangzhe, wanyiming, Wei, wenchunjiang, wilfChen, WilliamLian, wsc, wudenggang, wukesong, wuweikang, wuxuejian, Xiao Tianci, Xiaoda, xiefangqi, xinyunfan, xuanyue, xuyongfei, yanghaitao, yanghaitao1, yanghaoran, YangLuo, yangruoqi713, yankai, yanzhenxiang2020, yao_yf, yepei6, yeyunpeng, Yi, yoni, yoonlee666, yuchaojie, yujianfeng, yuximiao, zengzitao, Zhang,  zhanghuiyao, zhanghui_china, zhangxinfeng3, zhangyihui, zhangz0911gm, zhanke, zhanyuan, zhaodezan, zhaojichen, zhaoting, zhaozhenlong, zhengjun10, zhiqwang, zhoufeng, zhousiyi, zhouyaqiang, zhouyifengCode, Zichun, Ziyan, zjun, ZPaC, wangfengwfwf, zymaa, gerayking, shu-kun-zhang.\n\n欢迎以任何形式对项目提供贡献！\n\n## MindSpore Lite 1.8.0 Release Notes\n\n### 主要特性和增强\n\n#### API\n\n- [STABLE] 新增模型转换的C++和Python API.\n- [STABLE] 新增模型推理的Python API.\n\n#### 后量化\n\n- [STABLE] 后量化支持PerLayer量化，同时内置CLE算法优化精度。\n\n## MindSpore 1.7.0 Release Notes\n\n### 主要特性和增强\n\n#### OS\n\n- [STABLE] 支持Python 3.8版本（Linux/Windows/Mac）。\n- [STABLE] 简化安装，提供详细安装指南和自动化安装脚本。\n- [STABLE] Windows版本支持算子多线程。\n- [STABLE] GCC兼容7.3到9.x版本。\n\n#### FrontEnd\n\n- [STABLE] 优化器支持动态权重衰减，即训练期间权重衰减值随着step的增加而变化。\n- [STABLE] 增加四种创建Tensor的方法，分别是`mindspore.numpy.rand()`、`mindspore.numpy.randn()`、`mindspore.numpy.randint()`和`mindspore.ops.arange ()`。\n- [STABLE] 增加一种callback方法 `mindspore.train.callback.History`。\n- [BETA] 自定义算子支持Julia算子。\n- [STABLE] 通过 `mindspore.ms_class` 类装饰器，支持获取用户自定义类的属性和方法。\n- [STABLE] 支持同时存在副作用算子和控制流语句的网络的训练。\n- [STABLE] 支持更复杂的控制流语法，比如在while的循环体里使用for语句。\n- [STABLE] 通过减少子图数量，提升包含复杂控制流语法的网络的性能。\n\n#### PyNative\n\n- [STABLE] 在PyNative模式下支持hook函数功能，包括前向hook接口register_forward_pre_hook、register_forward_hook和反向hook接口register_backward_hook。\n- [STABLE] 优化PyNative模式执行性能，并行执行前端Python与后端C++。\n\n#### Auto Parallel\n\n- [STABLE] 在MoE场景中支持TopK的路由、数据并行和优化器切分。\n- [STABLE] 支持AllGather/ReduceScatter通信算子融合，在DATA_PARALLEL模式支持AllReduce按数据量大小编译。\n- [STABLE] 在并行模式下支持ops.clip_by_global_norm。\n- [STABLE] 在并行模式下支持AdaSum优化器。\n- [STABLE] 支持自动优化器切分。\n- [STABLE] 支持AlltoAll可配置开启，支持自动插入VirtualDatasetCell。\n- [STABLE] 在流水线并行训练中，支持自动推断可训练的参数。\n- [STABLE] 支持集群的设备数目不为2的幂次方。\n- [STABLE] 在自动并行模式中支持策略传播。\n- [STABLE] 在统一运行时中支持异构训练。\n- [STABLE] 支持CPU的Adafactor算子。\n- [STABLE] 支持Conv2d/Conv2D的H/W轴切分和Transpose算子。支持ResizeBilinear、ROIAlign、CropAndResize、BoundingBoxEncode、IOU和RandomChoiceWithMask等分布式算子。\n\n#### Executor\n\n- [BETA] [数据并行训练容灾](https://www.mindspore.cn/tutorials/experts/zh-CN/r1.7/parallel/train_gpu.html#%E5%AE%B9%E7%81%BE%E6%81%A2%E5%A4%8D) 支持多卡数据并行训练容灾恢复。\n- [BETA] 支持在CPU下的线程数搜索，获取最优线程数来执行。整个搜索过程需要耗时50个steps，整体的性能会在50个steps后达到稳定的状态。在测试性能的时候，需要以50个steps之后的数据作为标准。\n\n#### DataSet\n\n- [STABLE] 增加了数据处理API的差异文档，比较TensorFlow.data与MindSpore.dataset部分算子的差异，详见 [对比文档](https://www.mindspore.cn/docs/zh-CN/r1.7/note/api_mapping/tensorflow_api_mapping.html#tf-data)。\n- [STABLE] Python多进程逻辑优化，保证不同异常场景的正常退出。\n- [STABLE] 支持[自动数据加速](https://www.mindspore.cn/tutorials/experts/zh-CN/master/dataset/dataset_autotune.html)，可以自适应调节数据处理管道的执行速度。\n- [BETA] [数据处理异构加速](https://www.mindspore.cn/tutorials/experts/zh-CN/master/dataset/dataset_offload.html) 支持了新的数据增强操作: RandomColorAdjust、RandomSharpness和TypeCast。\n- GeneratorDataset加载自定义数据集时，当`__getitem__/__next__`方法返回单个NumPy对象，对应会输出单个数据列。\n- 用户在数据预处理中使用过多的进程数/线程数情况下，会出现错误RuntimeError: can't start new thread，可以通过 `ulimit -u 10240` 增加当前用户可用的线程/进程数解决。\n\n### API变更\n\n#### 非兼容性变更\n\n##### Python API\n\n- 修改register_backward_hook功能对应hook的梯度返回值类型，将梯度返回值统一改成tuple类型。([!31876](https://gitee.com/mindspore/mindspore/pulls/31876))\n- 弃用的import用法： `import mindspore.dataset.engine.datasets as ds` ，因其import目录过深且过度依赖Python目录结构。推荐使用 `import mindspore.dataset as ds` ，更多参考详见 [API文档](https://www.mindspore.cn/docs/zh-CN/r1.7/api_python/mindspore.dataset.html)。\n- 新增`mindspore.ms_class` 接口，作为用户自定义类的类装饰器，使得MindSpore能够识别用户自定义类，并且获取这些类的属性和方法。([!30855](https://gitee.com/mindspore/mindspore/pulls/30855))\n- `mindspore.SparseTensor`接口废弃使用，对应新接口为`mindspore.COOTensor`。 ([!28505](https://gitee.com/mindspore/mindspore/pulls/28505))\n- Tensor新增一个入参`internal`，作为框架内部使用。\n\n### 贡献者\n\n感谢以下人员做出的贡献:\n\nAGroupofProbiotocs, anzhengqi, askmiao, baihuawei, baiyangfan, bai-yangfan, bingyaweng, BowenK, buxue, caifubi, CaoJian, caojian05, caozhou, Cathy, changzherui, chenbo116, chenfei, chengxianbin, chenhaozhe, chenjianping, chenzomi, chenzupeng, chujinjin, cj, cjh9368, Corleone, damon0626, danish, Danish, davidmc, dayschan, doitH, dong-li001, fary86, fuzhiye, Gaoxiong, GAO_HYP_XYJ, gengdongjie, Gogery, gongdaguo, gray0v0, gukecai, guoqi, gzhcv, hangq, hanhuifeng2020, Harshvardhan, He, heleiwang, hesham, hexia, Hoai, HuangBingjian, huangdongrun, huanghui, huangxinjing, huqi, huzhifeng, hwjiaorui, Jiabin Liu, jianghui58, Jiaqi, jin-xiulang, jinyaohui, jjfeing, John, jonyguo, JulyAi, jzg, kai00, kingfo, kingxian, kpy, kswang, liuyongqi, laiyongqiang, leonwanghui, liangchenghui, liangzelang, lichen_101010, lichenever, lihongkang, lilei, limingqi107, ling, linqingke, Lin Xh, liubuyu, liuwenhao4, liuxiao78, liuxiao93, liuyang_655, liuzhongkai, Lixia, lixian, liyanliu, liyong, lizhenyu, luopengting, lvchangquan, lvliang, lz, maning202007, Margaret_wangrui, mengyuanli, Ming_blue, ms_yan, ougongchang, panfengfeng, panyifeng, Payne, Peilin, peixu_ren, Pengyongrong, qianlong, qianjiahong, r1chardf1d0, riemann_penn, rmdyh, Sheng, shenwei41, simson, Simson, Su, sunsuodong, tao_yunhao, tinazhang, VectorSL, , Wan, wandongdong, wangdongxu, wangmin,  wangyue01, wangzhe, wanyiming, Wei, wenchunjiang, wilfChen, WilliamLian, wsc, wudenggang, wukesong, wuweikang, wuxuejian, Xiao Tianci, Xiaoda, xiefangqi, xinyunfan, xuanyue, xuyongfei, yanghaitao, yanghaitao1, yanghaoran, YangLuo, yangruoqi713, yankai, yanzhenxiang2020, yao_yf, yepei6, yeyunpeng, Yi, yoni, yoonlee666, yuchaojie, yujianfeng, yuximiao, zengzitao, Zhang,  zhanghuiyao, zhanghui_china, zhangxinfeng3, zhangyihui, zhangz0911gm, zhanke, zhanyuan, zhaodezan, zhaojichen, zhaoting, zhaozhenlong, zhengjun10, zhiqwang, zhoufeng, zhousiyi, zhouyaqiang, zhouyifengCode, Zichun, Ziyan, zjun, ZPaC, wangfengwfwf, zymaa, gerayking.\n\n欢迎以任何形式对项目提供贡献！\n\n## MindSpore Lite 1.7.0 Release Notes\n\n### 主要特性和增强\n\n#### 后量化\n\n- [STABLE] 后量化支持动态量化算法。\n- [BETA] 后量化模型支持在英伟达GPU上执行推理。\n"
        },
        {
          "name": "SECURITY.md",
          "type": "blob",
          "size": 2.3154296875,
          "content": "# Security for MindSpore training\n\n## Security Risk Description\n\n1. When MindSpore is used for AI model training, if the user-defined computational graph structure (for example, Python code for generating the MindSpore computational graph) is provided by an untrusted third party, malicious code may exist and will be loaded and executed to attack the system.\n2. Model files are stored in binary mode. When MindSpore is used to optimize or infer AI models and the model files are loaded in deserialization mode, once malicious code is written into the model files, the code are loaded and executed, causing attacks on the system.\n3. MindSpore performs only model training and inference based on the data provided by users. Users need to protect data security to avoid privacy leakage.\n4. MindSpore is a distributed training platform. When MindSpore is used for distributed training, if an Ascend chip is used for training, a device provides a secure transmission protocol for gradient fusion. If GPUs or other clusters are used for training, identity authentication and secure transmission are not provided.\n\n## Security Usage Suggestions\n\n1. Run MindSpore in the sandbox.\n2. Run MindSpore as a non-root user.\n3. Ensure that the source of a computational graph structure is trustworthy. Do not write code irrelevant to model training in the network structure definition.\n4. Ensure that the source of a network model is trustworthy or enter secure network model parameters to prevent model parameters from being tampered with.\n5. Ensure that GPU distributed training is performed on an isolated cluster network.\n\n# Security for MindSpore Lite\n\n## Security Risk Description\n\nWhen run a model using MindSpore Lite, the value from the model will be read and used as the parameter or input of a operator, if the value read from the model is invalid, it may cause unexpected result. For example, if the invalid value is used as the offset of a vector, it may cause your app run into segmentation fault issue.\n\n## Security Usage Suggestions\n\n1. Make sure your model is well verified and protected.\n2. The exception catching mechanism of C++ is an effective method to improve robustness of your app, consider adding code to catch exception when calling the MindSpore Lite API, as exception will be raised in some case such as the example mentioned in the risk description above.\n"
        },
        {
          "name": "Third_Party_Open_Source_Software_Notice",
          "type": "blob",
          "size": 587.1650390625,
          "content": "OPEN SOURCE SOFTWARE NOTICE\n\nPlease note we provide an open source software notice along with this product and/or this product firmware (in the following just “this product”). The open source software licenses are granted by the respective right holders. And the open source licenses prevail all other license information with regard to the respective open source software contained in the product, including but not limited to End User Software Licensing Agreement. This notice is provided on behalf of Huawei Technologies Co. Ltd. and any of its local subsidiaries which may have provided this product to you in your local country. \n\nWarranty Disclaimer    \nTHE OPEN SOURCE SOFTWARE IN THIS PRODUCT IS DISTRIBUTED IN THE HOPE THAT IT WILL BE USEFUL, BUT WITHOUT ANY WARRANTY, WITHOUT EVEN THE IMPLIED WARRANTY OF MERCHANTABILITY OR FITNESS FOR A PARTICULAR PURPOSE. SEE THE APPLICABLE LICENSES FOR MORE DETAILS.\n\nCopyright Notice and License Texts \n\nSoftware: asttokens 2.0.4\nCopyright notice: \ncopyright = u'2016, Grist Labs'\nCopyright 2016 Grist Labs, Inc.\n\n                            Apache License\n                       Version 2.0, January 2004\n                     http://www.apache.org/licenses/\n\n   TERMS AND CONDITIONS FOR USE, REPRODUCTION, AND DISTRIBUTION\n\n   1. Definitions.\n\n      \"License\" shall mean the terms and conditions for use, reproduction,\n      and distribution as defined by Sections 1 through 9 of this document.\n\n      \"Licensor\" shall mean the copyright owner or entity authorized by\n      the copyright owner that is granting the License.\n\n      \"Legal Entity\" shall mean the union of the acting entity and all\n      other entities that control, are controlled by, or are under common\n      control with that entity. For the purposes of this definition,\n      \"control\" means (i) the power, direct or indirect, to cause the\n      direction or management of such entity, whether by contract or\n      otherwise, or (ii) ownership of fifty percent (50%) or more of the\n      outstanding shares, or (iii) beneficial ownership of such entity.\n\n      \"You\" (or \"Your\") shall mean an individual or Legal Entity\n      exercising permissions granted by this License.\n\n      \"Source\" form shall mean the preferred form for making modifications,\n      including but not limited to software source code, documentation\n      source, and configuration files.\n\n      \"Object\" form shall mean any form resulting from mechanical\n      transformation or translation of a Source form, including but\n      not limited to compiled object code, generated documentation,\n      and conversions to other media types.\n\n      \"Work\" shall mean the work of authorship, whether in Source or\n      Object form, made available under the License, as indicated by a\n      copyright notice that is included in or attached to the work\n      (an example is provided in the Appendix below).\n\n      \"Derivative Works\" shall mean any work, whether in Source or Object\n      form, that is based on (or derived from) the Work and for which the\n      editorial revisions, annotations, elaborations, or other modifications\n      represent, as a whole, an original work of authorship. For the purposes\n      of this License, Derivative Works shall not include works that remain\n      separable from, or merely link (or bind by name) to the interfaces of,\n      the Work and Derivative Works thereof.\n\n      \"Contribution\" shall mean any work of authorship, including\n      the original version of the Work and any modifications or additions\n      to that Work or Derivative Works thereof, that is intentionally\n      submitted to Licensor for inclusion in the Work by the copyright owner\n      or by an individual or Legal Entity authorized to submit on behalf of\n      the copyright owner. For the purposes of this definition, \"submitted\"\n      means any form of electronic, verbal, or written communication sent\n      to the Licensor or its representatives, including but not limited to\n      communication on electronic mailing lists, source code control systems,\n      and issue tracking systems that are managed by, or on behalf of, the\n      Licensor for the purpose of discussing and improving the Work, but\n      excluding communication that is conspicuously marked or otherwise\n      designated in writing by the copyright owner as \"Not a Contribution.\"\n\n      \"Contributor\" shall mean Licensor and any individual or Legal Entity\n      on behalf of whom a Contribution has been received by Licensor and\n      subsequently incorporated within the Work.\n\n   2. Grant of Copyright License. Subject to the terms and conditions of\n      this License, each Contributor hereby grants to You a perpetual,\n      worldwide, non-exclusive, no-charge, royalty-free, irrevocable\n      copyright license to reproduce, prepare Derivative Works of,\n      publicly display, publicly perform, sublicense, and distribute the\n      Work and such Derivative Works in Source or Object form.\n\n   3. Grant of Patent License. Subject to the terms and conditions of\n      this License, each Contributor hereby grants to You a perpetual,\n      worldwide, non-exclusive, no-charge, royalty-free, irrevocable\n      (except as stated in this section) patent license to make, have made,\n      use, offer to sell, sell, import, and otherwise transfer the Work,\n      where such license applies only to those patent claims licensable\n      by such Contributor that are necessarily infringed by their\n      Contribution(s) alone or by combination of their Contribution(s)\n      with the Work to which such Contribution(s) was submitted. If You\n      institute patent litigation against any entity (including a\n      cross-claim or counterclaim in a lawsuit) alleging that the Work\n      or a Contribution incorporated within the Work constitutes direct\n      or contributory patent infringement, then any patent licenses\n      granted to You under this License for that Work shall terminate\n      as of the date such litigation is filed.\n\n   4. Redistribution. You may reproduce and distribute copies of the\n      Work or Derivative Works thereof in any medium, with or without\n      modifications, and in Source or Object form, provided that You\n      meet the following conditions:\n\n      (a) You must give any other recipients of the Work or\n          Derivative Works a copy of this License; and\n\n      (b) You must cause any modified files to carry prominent notices\n          stating that You changed the files; and\n\n      (c) You must retain, in the Source form of any Derivative Works\n          that You distribute, all copyright, patent, trademark, and\n          attribution notices from the Source form of the Work,\n          excluding those notices that do not pertain to any part of\n          the Derivative Works; and\n\n      (d) If the Work includes a \"NOTICE\" text file as part of its\n          distribution, then any Derivative Works that You distribute must\n          include a readable copy of the attribution notices contained\n          within such NOTICE file, excluding those notices that do not\n          pertain to any part of the Derivative Works, in at least one\n          of the following places: within a NOTICE text file distributed\n          as part of the Derivative Works; within the Source form or\n          documentation, if provided along with the Derivative Works; or,\n          within a display generated by the Derivative Works, if and\n          wherever such third-party notices normally appear. The contents\n          of the NOTICE file are for informational purposes only and\n          do not modify the License. You may add Your own attribution\n          notices within Derivative Works that You distribute, alongside\n          or as an addendum to the NOTICE text from the Work, provided\n          that such additional attribution notices cannot be construed\n          as modifying the License.\n\n      You may add Your own copyright statement to Your modifications and\n      may provide additional or different license terms and conditions\n      for use, reproduction, or distribution of Your modifications, or\n      for any such Derivative Works as a whole, provided Your use,\n      reproduction, and distribution of the Work otherwise complies with\n      the conditions stated in this License.\n\n   5. Submission of Contributions. Unless You explicitly state otherwise,\n      any Contribution intentionally submitted for inclusion in the Work\n      by You to the Licensor shall be under the terms and conditions of\n      this License, without any additional terms or conditions.\n      Notwithstanding the above, nothing herein shall supersede or modify\n      the terms of any separate license agreement you may have executed\n      with Licensor regarding such Contributions.\n\n   6. Trademarks. This License does not grant permission to use the trade\n      names, trademarks, service marks, or product names of the Licensor,\n      except as required for reasonable and customary use in describing the\n      origin of the Work and reproducing the content of the NOTICE file.\n\n   7. Disclaimer of Warranty. Unless required by applicable law or\n      agreed to in writing, Licensor provides the Work (and each\n      Contributor provides its Contributions) on an \"AS IS\" BASIS,\n      WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or\n      implied, including, without limitation, any warranties or conditions\n      of TITLE, NON-INFRINGEMENT, MERCHANTABILITY, or FITNESS FOR A\n      PARTICULAR PURPOSE. You are solely responsible for determining the\n      appropriateness of using or redistributing the Work and assume any\n      risks associated with Your exercise of permissions under this License.\n\n   8. Limitation of Liability. In no event and under no legal theory,\n      whether in tort (including negligence), contract, or otherwise,\n      unless required by applicable law (such as deliberate and grossly\n      negligent acts) or agreed to in writing, shall any Contributor be\n      liable to You for damages, including any direct, indirect, special,\n      incidental, or consequential damages of any character arising as a\n      result of this License or out of the use or inability to use the\n      Work (including but not limited to damages for loss of goodwill,\n      work stoppage, computer failure or malfunction, or any and all\n      other commercial damages or losses), even if such Contributor\n      has been advised of the possibility of such damages.\n\n   9. Accepting Warranty or Additional Liability. While redistributing\n      the Work or Derivative Works thereof, You may choose to offer,\n      and charge a fee for, acceptance of support, warranty, indemnity,\n      or other liability obligations and/or rights consistent with this\n      License. However, in accepting such obligations, You may act only\n      on Your own behalf and on Your sole responsibility, not on behalf\n      of any other Contributor, and only if You agree to indemnify,\n      defend, and hold each Contributor harmless for any liability\n      incurred by, or claims asserted against, such Contributor by reason\n      of your accepting any such warranty or additional liability.\n\n   END OF TERMS AND CONDITIONS\n\n   APPENDIX: How to apply the Apache License to your work.\n\n      To apply the Apache License to your work, attach the following\n      boilerplate notice, with the fields enclosed by brackets \"{}\"\n      replaced with your own identifying information. (Don't include\n      the brackets!)  The text should be enclosed in the appropriate\n      comment syntax for the file format. We also recommend that a\n      file or class name and description of purpose be included on the\n      same \"printed page\" as the copyright notice for easier\n      identification within third-party archives.\n\n   Copyright {yyyy} {name of copyright owner}\n\n   Licensed under the Apache License, Version 2.0 (the \"License\");\n   you may not use this file except in compliance with the License.\n   You may obtain a copy of the License at\n\n       http://www.apache.org/licenses/LICENSE-2.0\n\n   Unless required by applicable law or agreed to in writing, software\n   distributed under the License is distributed on an \"AS IS\" BASIS,\n   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n   See the License for the specific language governing permissions and\n   limitations under the License.\n\nSoftware: easydict 1.9\nCopyright notice:\nCopyright (C) 2007 Free Software Foundation, Inc. <http:fsf.org/>\n\n       GNU LESSER GENERAL PUBLIC LICENSE           \n            Version 3, 29 June 2007\n\n Copyright (C) 2007 Free Software Foundation, Inc. <http://fsf.org/>\n Everyone is permitted to copy and distribute verbatim copies\n of this license document, but changing it is not allowed.\n\n\n  This version of the GNU Lesser General Public License incorporates\nthe terms and conditions of version 3 of the GNU General Public\nLicense, supplemented by the additional permissions listed below.\n\n  0. Additional Definitions.\n\n  As used herein, \"this License\" refers to version 3 of the GNU Lesser\nGeneral Public License, and the \"GNU GPL\" refers to version 3 of the GNU\nGeneral Public License.\n\n  \"The Library\" refers to a covered work governed by this License,\nother than an Application or a Combined Work as defined below.\n\n  An \"Application\" is any work that makes use of an interface provided\nby the Library, but which is not otherwise based on the Library.\nDefining a subclass of a class defined by the Library is deemed a mode\nof using an interface provided by the Library.\n\n  A \"Combined Work\" is a work produced by combining or linking an\nApplication with the Library.  The particular version of the Library\nwith which the Combined Work was made is also called the \"Linked\nVersion\".\n\n  The \"Minimal Corresponding Source\" for a Combined Work means the\nCorresponding Source for the Combined Work, excluding any source code\nfor portions of the Combined Work that, considered in isolation, are\nbased on the Application, and not on the Linked Version.\n\n  The \"Corresponding Application Code\" for a Combined Work means the\nobject code and/or source code for the Application, including any data\nand utility programs needed for reproducing the Combined Work from the\nApplication, but excluding the System Libraries of the Combined Work.\n\n  1. Exception to Section 3 of the GNU GPL.\n\n  You may convey a covered work under sections 3 and 4 of this License\nwithout being bound by section 3 of the GNU GPL.\n\n  2. Conveying Modified Versions.\n\n  If you modify a copy of the Library, and, in your modifications, a\nfacility refers to a function or data to be supplied by an Application\nthat uses the facility (other than as an argument passed when the\nfacility is invoked), then you may convey a copy of the modified\nversion:\n\n   a) under this License, provided that you make a good faith effort to\n   ensure that, in the event an Application does not supply the\n   function or data, the facility still operates, and performs\n   whatever part of its purpose remains meaningful, or\n\n   b) under the GNU GPL, with none of the additional permissions of\n   this License applicable to that copy.\n\n  3. Object Code Incorporating Material from Library Header Files.\n\n  The object code form of an Application may incorporate material from\na header file that is part of the Library.  You may convey such object\ncode under terms of your choice, provided that, if the incorporated\nmaterial is not limited to numerical parameters, data structure\nlayouts and accessors, or small macros, inline functions and templates\n(ten or fewer lines in length), you do both of the following:\n\n   a) Give prominent notice with each copy of the object code that the\n   Library is used in it and that the Library and its use are\n   covered by this License.\n\n   b) Accompany the object code with a copy of the GNU GPL and this license\n   document.\n\n  4. Combined Works.\n\n  You may convey a Combined Work under terms of your choice that,\ntaken together, effectively do not restrict modification of the\nportions of the Library contained in the Combined Work and reverse\nengineering for debugging such modifications, if you also do each of\nthe following:\n\n   a) Give prominent notice with each copy of the Combined Work that\n   the Library is used in it and that the Library and its use are\n   covered by this License.\n\n   b) Accompany the Combined Work with a copy of the GNU GPL and this license\n   document.\n\n   c) For a Combined Work that displays copyright notices during\n   execution, include the copyright notice for the Library among\n   these notices, as well as a reference directing the user to the\n   copies of the GNU GPL and this license document.\n\n   d) Do one of the following:\n\n       0) Convey the Minimal Corresponding Source under the terms of this\n       License, and the Corresponding Application Code in a form\n       suitable for, and under terms that permit, the user to\n       recombine or relink the Application with a modified version of\n       the Linked Version to produce a modified Combined Work, in the\n       manner specified by section 6 of the GNU GPL for conveying\n       Corresponding Source.\n\n       1) Use a suitable shared library mechanism for linking with the\n       Library.  A suitable mechanism is one that (a) uses at run time\n       a copy of the Library already present on the user's computer\n       system, and (b) will operate properly with a modified version\n       of the Library that is interface-compatible with the Linked\n       Version.\n\n   e) Provide Installation Information, but only if you would otherwise\n   be required to provide such information under section 6 of the\n   GNU GPL, and only to the extent that such information is\n   necessary to install and execute a modified version of the\n   Combined Work produced by recombining or relinking the\n   Application with a modified version of the Linked Version. (If\n   you use option 4d0, the Installation Information must accompany\n   the Minimal Corresponding Source and Corresponding Application\n   Code. If you use option 4d1, you must provide the Installation\n   Information in the manner specified by section 6 of the GNU GPL\n   for conveying Corresponding Source.)\n\n  5. Combined Libraries.\n\n  You may place library facilities that are a work based on the\nLibrary side by side in a single library together with other library\nfacilities that are not Applications and are not covered by this\nLicense, and convey such a combined library under terms of your\nchoice, if you do both of the following:\n\n   a) Accompany the combined library with a copy of the same work based\n   on the Library, uncombined with any other library facilities,\n   conveyed under the terms of this License.\n\n   b) Give prominent notice with the combined library that part of it\n   is a work based on the Library, and explaining where to find the\n   accompanying uncombined form of the same work.\n\n  6. Revised Versions of the GNU Lesser General Public License.\n\n  The Free Software Foundation may publish revised and/or new versions\nof the GNU Lesser General Public License from time to time. Such new\nversions will be similar in spirit to the present version, but may\ndiffer in detail to address new problems or concerns.\n\n  Each version is given a distinguishing version number. If the\nLibrary as you received it specifies that a certain numbered version\nof the GNU Lesser General Public License \"or any later version\"\napplies to it, you have the option of following the terms and\nconditions either of that published version or of any later version\npublished by the Free Software Foundation. If the Library as you\nreceived it does not specify a version number of the GNU Lesser\nGeneral Public License, you may choose any version of the GNU Lesser\nGeneral Public License ever published by the Free Software Foundation.\n\n  If the Library as you received it specifies that a proxy can decide\nwhether future versions of the GNU Lesser General Public License shall\napply, that proxy's public statement of acceptance of any version is\npermanent authorization for you to choose that version for the\nLibrary.\n\nSoftware: Eigen 3.4.0\nCopyright notice: \nCopyright (C) 2014 Benoit Steiner <benoit.steiner.goog@gmail.com>\nCopyright (C) 2013 Christian Seiler <christian@iwakd.de>\nCopyright (C) 2015 Eugene Brevdo <ebrevdo@gmail.com>\nCopyright (C) 2014-2015 Benoit Steiner <benoit.steiner.goog@gmail.com>\nCopyright (C) 2015 Navdeep Jaitly <ndjaitly@google.com>\nCopyright (C) 2014 Eric Martin <eric@ericmart.in>\nCopyright (C) 2015 Benoit Steiner <benoit.steiner.goog@gmail.com>\nCopyright (C) 2016 Rasmus Munk Larsen <rmlarsen@google.com>\nCopyright (C) 2016 Benoit Steiner <benoit.steiner.goog@gmail.com>\nCopyright (C) 2015 Jianwei Cui <thucjw@gmail.com>\nCopyright (C) 2016 Eugene Brevdo <ebrevdo@gmail.com>\nCopyright (C) 2015 Ke Yang <yangke@gmail.com>\nCopyright (C) 2016 Mehdi Goli, Codeplay Software Ltd <eigen@codeplay.com>\nCopyright (C) 2014 Navdeep Jaitly <ndjaitly@google.com>\nCopyright (C) 2016 Igor Babuschkin <igor@babuschk.in>\nCopyright (C) 2016 Dmitry Vyukov <dvyukov@google.com>\nCopyright (C) EDF R&D,  lun sep 30 14:23:30 CEST 2002\nCopyright (C) 2008 Gael Guennebaud <gael.guennebaud@inria.fr>\nCopyright (C) EDF R&D,  lun sep 30 14:23:31 CEST 2002\nCopyright (C) 2008-2010 Gael Guennebaud <gael.guennebaud@inria.fr>\nCopyright (C) 2008-2016 Gael Guennebaud <gael.guennebaud@inria.fr>\nCopyright (C) 2009 Mark Borgerding mark a borgerding net\nCopyright (C) 2008-2009 Gael Guennebaud <gael.guennebaud@inria.fr>\nCopyright (C) 2013 Desire Nuentsa <desire.nuentsawakam@inria.fr>\nCopyright (C) 2013 Gael Guennebaud <gael.guennebaud@inria.fr>\nCopyright (C) 2011 Gael Guennebaud <gael.guennebaud@inria.fr>\nCopyright (C) 2012 Desire NUENTSA WAKAM <desire.nuentsawakam@inria.fr>\nCopyright (C) 2009 Benoit Jacob <jacob.benoit.1@gmail.com>\nCopyright (C) 2009 Gael Guennebaud <gael.guennebaud@inria.fr>\nCopyright (C) 2006-2010 Benoit Jacob <jacob.benoit.1@gmail.com>\nCopyright (C) 2006-2008 Benoit Jacob <jacob.benoit.1@gmail.com>\nCopyright (C) EDF R&D,  lun sep 30 14:23:28 CEST 2002\nCopyright (C) 2010 Manuel Yguel <manuel.yguel@gmail.com>\nCopyright (C) 2009 Claire Maurice\nCopyright (C) 2010,2012 Jitse Niesen <jitse@maths.leeds.ac.uk>\nCopyright (c) 2011, Intel Corporation. All rights reserved.\nCopyright (C) 2012-2016 Gael Guennebaud <gael.guennebaud@inria.fr>\nCopyright (C) 2016 Tobias Wood <tobias@spinicist.org.uk>\nCopyright (C) 2010 Jitse Niesen <jitse@maths.leeds.ac.uk>\nCopyright (C) 2012 Alexey Korepanov <kaikaikai@yandex.ru>\nCopyright (C) 2010 Vincent Lejeune\nCopyright (C) 2010 Gael Guennebaud <gael.guennebaud@inria.fr>\nCopyright (C) 2010 Benoit Jacob <jacob.benoit.1@gmail.com>\nCopyright (C) 2017 Gael Guennebaud <gael.guennebaud@inria.fr>\nCopyright (C) 2009-2010 Gael Guennebaud <gael.guennebaud@inria.fr>\nCopyright (C) 2008 Benoit Jacob <jacob.benoit.1@gmail.com>\nCopyright (C) 2009 Mathieu Gautier <mathieu.gautier@cea.fr>\nCopyright (C) 2010 Hauke Heibel <hauke.heibel@gmail.com>\nCopyright (C) 2009 Hauke Heibel <hauke.heibel@gmail.com>\nCopyright (C) 2008-2015 Gael Guennebaud <gael.guennebaud@inria.fr>\nCopyright (C) EDF R&D,  mar déc 3 18:59:36 CET 2002\nCopyright (C) EDF R&D,  lun sep 30 14:23:17 CEST 2002\nCopyright (C) EDF R&D,  mar déc 3 18:59:35 CET 2002\nCopyright (C) 2016 Konstantinos Margaritis <markos@freevec.org>\nCopyright (C) 2007 Julien Pommier\nCopyright (C) 2008-2011 Gael Guennebaud <gael.guennebaud@inria.fr>\nCopyright (C) 2009 Keir Mierle <mierle@gmail.com>\nCopyright (C) 2011 Timothy E. Holy <tim.holy@gmail.com >\nCopyright (C) 2009 Hauke Heibel <hauke.heibel@googlemail.com>\nCopyright (C) 2012 Desire Nuentsa <desire.nuentsawakam@inria.fr>\nCopyright (C) 2014 Gael Guennebaud <gael.guennebaud@inria.fr>\nCopyright (C) 2015 Tal Hadad <talhd@hotmail.com>\n@copyright (c) 2009-2014 The University of Tennessee and The University of Tennessee Research Foundation.\n@copyright (c) 2012-2016 Inria. All rights reserved.\n@copyright (c) 2012-2014 Bordeaux INP, CNRS (LaBRI UMR 5800), Inria, Univ. Bordeaux. All rights reserved.\nCopyright 2007-2009 Kitware, Inc.\nCopyright 2012-2013 Inria\nCopyright 2012-2013 Emmanuel Agullo\nCopyright 2012-2013 Mathieu Faverge\nCopyright 2012      Cedric Castagnede\nCopyright 2013-2016 Florent Pruvost\nCopyright 2016 Codeplay Software Ltd.\nCopyright (c) 2006, 2007 Montel Laurent, <montel@kde.org>\nCopyright (c) 2008, 2009 Gael Guennebaud, <g.gael@free.fr>\nCopyright (c) 2009 Boudewijn Rempt <boud@valdyas.org>\n@copyright (c) 2012-2014 Inria. All rights reserved.\nCopyright 2013      Florent Pruvost\nCopyright (c) 2010 Jitse Niesen, <jitse@maths.leeds.ac.uk>\nCopyright (C) 2009 Benjamin Schindler <bschindler@inf.ethz.ch>\nCopyright (C) 2016 Pedro Gonnet (pedro.gonnet@gmail.com)\nCopyright (C) 2016 Benoit Steiner (benoit.steiner.goog@gmail.com)\nCopyright (C) 2009 Thomas Capricelli <orzel@freehackers.org>\nCopyright (C) 2012-2013 Desire Nuentsa <desire.nuentsawakam@inria.fr>\nCopyright (C) 2012-2014 Gael Guennebaud <gael.guennebaud@inria.fr>\nCopyright Jorge More - Argonne National Laboratory\nCopyright Burt Garbow - Argonne National Laboratory\nCopyright Ken Hillstrom - Argonne National Laboratory\nCopyright (C) 2009 Ilya Baran <ibaran@mit.edu>\nCopyright (c) 2010, Intel Corp.\nCopyright (C) 2009-2010 Benoit Jacob <jacob.benoit.1@gmail.com>\nCopyright (C) 2013-2016 Gael Guennebaud <gael.guennebaud@inria.fr>\nCopyright (C) 2013 Gauthier Brun <brun.gauthier@gmail.com>\nCopyright (C) 2013 Nicolas Carre <nicolas.carre@ensimag.fr>\nCopyright (C) 2013 Jean Ceccato <jean.ceccato@ensimag.fr>\nCopyright (C) 2013 Pierre Zoppitelli <pierre.zoppitelli@ensimag.fr>\nCopyright (C) 2013 Jitse Niesen <jitse@maths.leeds.ac.uk>\nCopyright (C) 2014-2017 Gael Guennebaud <gael.guennebaud@inria.fr>\nCopyright (C) 2013-2014 Gael Guennebaud <gael.guennebaud@inria.fr>\nCopyright (C) 2011-2014 Gael Guennebaud <gael.guennebaud@inria.fr>\nCopyright (C) 2012 Désiré Nuentsa-Wakam <desire.nuentsawakam@inria.fr>\nCopyright (C) 2015 Gael Guennebaud <gael.guennebaud@inria.fr>\nCopyright (C) 2012 Gael Guennebaud <gael.guennebaud@inria.fr>\nCopyright (c) 1994 by Xerox Corporation.  All rights reserved.\nCopyright (C) 2001 Intel Corporation\nCopyright (c) 2001 Intel Corporation.\nCopyright (C) 2009 Gael Guennebaud <g.gael@free.fr>\nCopyright (C) 2013 Christoph Hertzberg <chtz@informatik.uni-bremen.de>\nCopyright (C) 2015 Eugene Brevdo <ebrevdo@google.com>\nCopyright (C) 2016\nMehdi Goli    Codeplay Software Ltd.\nRalph Potter  Codeplay Software Ltd.\nLuke Iwanski  Codeplay Software Ltd.\nCopyright (C) 2014 Jianwei Cui <thucjw@gmail.com>\nCopyright (C) 2015 Vijay Vasudevan <vrv@google.com>\nCopyright (C) 2015\nMehdi Goli    Codeplay Software Ltd.\nRalph Potter  Codeplay Software Ltd.\nLuke Iwanski  Codeplay Software Ltd.\nCopyright (C) 2014 Navdeep Jaitly <ndjaitly@google.com and Benoit Steiner <benoit.steiner.goog@gmail.com>\nCopyright (C) 2011 Gael Guennebaud <g.gael@free.fr>\nCopyright (C) 2012 desire Nuentsa <desire.nuentsawakam@inria.fr\nCopyright (C) 2008 Gael Guennebaud <g.gael@free.fr>\nCopyright (C) 2012 Kolja Brix <brix@igpm.rwth-aaachen.de>\nCopyright (C) 2011 Kolja Brix <brix@igpm.rwth-aachen.de>\nCopyright (C) 2011 Andreas Platen <andiplaten@gmx.de>\nCopyright (C) 2012 Chen-Pang He <jdh8@ms63.hinet.net>\nCopyright (C) 2009 Jitse Niesen <jitse@maths.leeds.ac.uk>\nCopyright (C) 2009-2011 Jitse Niesen <jitse@maths.leeds.ac.uk>\nCopyright (C) 2012, 2013 Chen-Pang He <jdh8@ms63.hinet.net>\nCopyright (C) 2011 Jitse Niesen <jitse@maths.leeds.ac.uk>\nCopyright (C) 2012 Giacomo Po <gpo@ucla.edu>\nCopyright (C) 2008-2010 Gael Guennebaud <g.gael@free.fr>\nCopyright (C) 2016 Gael Guennebaud <gael.guennebaud@inria.fr>\nCopyright (C) 2010-2011 Hauke Heibel <heibel@gmail.com>\nCopyright (C) 2012 David Harmon <dharmon@gmail.com>\nCopyright (C) 2007-2009 Benoit Jacob <jacob.benoit.1@gmail.com>\nCopyright (C) 2007-2010 Benoit Jacob <jacob.benoit.1@gmail.com>\nCopyright (C) 2008-2009 Benoit Jacob <jacob.benoit.1@gmail.com>\nCopyright (C) 2009 Kenneth Riddile <kfriddile@yahoo.com>\nCopyright (C) 2010 Thomas Capricelli <orzel@freehackers.org>\nCopyright (C) 2013 Pavel Holoborodko <pavel@holoborodko.com>\nCopyright (C) EDF R&D,  lun sep 30 14:23:16 CEST 2002\nCopyright (C) EDF R&D,  mar déc 3 18:59:37 CET 2002\nCopyright (C) 2006-2009 Benoit Jacob <jacob.benoit.1@gmail.com>\nCopyright (C) 2008-2010 Benoit Jacob <jacob.benoit.1@gmail.com>\nCopyright (c) 2008-2015 Pavel Holoborodko\nCopyright (C) 20010-2011 Hauke Heibel <hauke.heibel@gmail.com>\nCopyright (c) 2006, Montel Laurent, <montel@kde.org>\nCopyright (c) 2007, Allen Winter, <winter@kde.org>\nCopyright (c) 2007, Alexander Neundorf, <neundorf@kde.org>\nCopyright (C) 2008 Guillaume Saupin <guillaume.saupin@cea.fr>\nCopyright (C) 2008-2009 Guillaume Saupin <guillaume.saupin@cea.fr>\nCopyright (C) 2009 Guillaume Saupin <guillaume.saupin@cea.fr>\nCopyright (C) 2010-2016 Konstantinos Margaritis <markos@freevec.org>\nCopyright (C) 2008-2016 Konstantinos Margaritis <markos@freevec.org>\nCopyright (C) 2014 Benoit Steiner (benoit.steiner.goog@gmail.com)\nCopyright (C) 2014 Pedro Gonnet (pedro.gonnet@gmail.com)\nCopyright (c) Fabian Giesen, 2016\nCopyright (C) 2010 Konstantinos Margaritis <markos@freevec.org>\nCopyright (C) 2007 Michael Olbrich <michael.olbrich@gmx.net>\nCopyright (C) 2011 Benoit Jacob <jacob.benoit.1@gmail.com>\nCopyright (C) 2011-2012 Jitse Niesen <jitse@maths.leeds.ac.uk>\nCopyright (C) 2016 Rasmus Munk Larsen (rmlarsen@google.com)\nCopyright (C) 2008-2014 Gael Guennebaud <gael.guennebaud@inria.fr>\nCopyright (C) 2010-2013 Hauke Heibel <hauke.heibel@gmail.com>\nCopyright (C) 2006-2008, 2010 Benoit Jacob <jacob.benoit.1@gmail.com>\nCopyright (C) 2010-2016 Gael Guennebaud <gael.guennebaud@inria.fr>\nCopyright (C) 2009-2015 Gael Guennebaud <gael.guennebaud@inria.fr>\nCopyright (C) 2009 Ricard Marxer <email@ricardmarxer.com>\nCopyright (C) 2009-2014 Gael Guennebaud <gael.guennebaud@inria.fr>\nCopyright (C) 2010-2011 Gael Guennebaud <gael.guennebaud@inria.fr>\nCopyright (C) 2009 Rohit Garg <rpg.314@gmail.com>\nCopyright (c) 2006, Timothy A. Davis.\nCopyright (c) 1998-2003 by the University of Florida.\nCopyright (C) 2012  Désiré Nuentsa-Wakam <desire.nuentsawakam@inria.fr>\nCopyright (C) 2008-2012 Gael Guennebaud <gael.guennebaud@inria.fr>\nLDL Copyright (c) 2005 by Timothy A. Davis.  All Rights Reserved.\nCopyright (C) 2010 Daniel Lowengrub <lowdanie@gmail.com>\nCopyright (C) EDF R&D,  lun sep 30 14:23:20 CEST 2002\nCopyright (C) EDF R&D,  lun sep 30 14:23:19 CEST 2002\nCopyright (C) 2009, 2010, 2013 Jitse Niesen <jitse@maths.leeds.ac.uk>\nCopyright (C) 2011, 2013 Chen-Pang He <jdh8@ms63.hinet.net>\nCopyright (C) 2009-2011, 2013 Jitse Niesen <jitse@maths.leeds.ac.uk>\nCopyright (C) 2011, 2013 Jitse Niesen <jitse@maths.leeds.ac.uk>\nCopyright (C) 2011 Chen-Pang He <jdh8@ms63.hinet.net>\nCopyright (C) 2010, 2013 Jitse Niesen <jitse@maths.leeds.ac.uk>\nCopyright (C) 2010-2014 Gael Guennebaud <gael.guennebaud@inria.fr>\nCopyright (C) 2012 The Android Open Source Project\n(C) Desire NUENTSA WAKAM, INRIA\nCopyright (C) EDF R&D,  lun sep 30 14:23:18 CEST 2002\nCopyright (C) 2012 Keir Mierle <mierle@gmail.com>\nCopyright (C) 1989, 1991 Free Software Foundation, Inc.\nCopyright (C) EDF R&D,  lun sep 30 14:23:23 CEST 2002\nCopyright (C) EDF R&D,  lun sep 30 14:23:24 CEST 2002\nCopyright (C) EDF R&D,  lun sep 30 14:23:27 CEST 2002\nCopyright (C) 2007 Free Software Foundation, Inc. <http:fsf.org/>\nCopyright (C) 1991, 1999 Free Software Foundation, Inc.\nCopyright (C) 2015 Benoit Jacob <benoitjacob@google.com>\nGeometric Tools, LLC Copyright (c) 1998-2010\nCopyright (C) EDF R&D,  lun sep 30 14:23:15 CEST 2002\nCopyright (C) 2002-2007 Yves Renard\nCopyright (C) 2012, 2014 Kolja Brix <brix@igpm.rwth-aaachen.de>\nCopyright (C) 1997-2001 Andrew Lumsdaine <lums@osl.iu.edu>  Lie-Quan Lee     <llee@osl.iu.edu>\nCopyright (C) 2012 Desire NUENTSA WAKAM <desire.nuentsawakam@inria.fr\nCopyright (C) 2015-2016 Gael Guennebaud <gael.guennebaud@inria.fr>\nCopyright (C) 2013 Hauke Heibel <hauke.heibel@gmail.com>\nCopyright (C) 2010-2011 Jitse Niesen <jitse@maths.leeds.ac.uk>\nIntel Copyright (C) ....\nCopyright (C) 2010-2017 Gael Guennebaud <gael.guennebaud@inria.fr>\nCopyright (C) 20013 Gael Guennebaud <gael.guennebaud@inria.fr>\nCopyright (C) 2008 Daniel Gomez Ferro <dgomezferro@gmail.com>\nCopyright (C) 2013 Désiré Nuentsa-Wakam <desire.nuentsawakam@inria.fr>\nCopyright (C) 2011-2015 Gael Guennebaud <gael.guennebaud@inria.fr>\nCopyright (C) 20015 Gael Guennebaud <gael.guennebaud@inria.fr>\nCopyright (C) 2014-2015 Gael Guennebaud <gael.guennebaud@inria.fr>\n\n\nLicense: Mozilla Public License (MPL) V2.0\n\nMozilla Public License\nVersion 2.0\n1. Definitions\n1.1. “Contributor”\nmeans each individual or legal entity that creates, contributes to the creation of, or owns Covered Software.\n1.2. “Contributor Version”\nmeans the combination of the Contributions of others (if any) used by a Contributor and that particular Contributor’s Contribution.\n1.3. “Contribution”\nmeans Covered Software of a particular Contributor.\n1.4. “Covered Software”\nmeans Source Code Form to which the initial Contributor has attached the notice in Exhibit A, the Executable Form of such Source Code Form, and Modifications of such Source Code Form, in each case including portions thereof.\n1.5. “Incompatible With Secondary Licenses”\nmeans\nthat the initial Contributor has attached the notice described in Exhibit B to the Covered Software; or\nthat the Covered Software was made available under the terms of version 1.1 or earlier of the License, but not also under the terms of a Secondary License.\n1.6. “Executable Form”\nmeans any form of the work other than Source Code Form.\n1.7. “Larger Work”\nmeans a work that combines Covered Software with other material, in a separate file or files, that is not Covered Software.\n1.8. “License”\nmeans this document.\n1.9. “Licensable”\nmeans having the right to grant, to the maximum extent possible, whether at the time of the initial grant or subsequently, any and all of the rights conveyed by this License.\n1.10. “Modifications”\nmeans any of the following:\nany file in Source Code Form that results from an addition to, deletion from, or modification of the contents of Covered Software; or\nany new file in Source Code Form that contains any Covered Software.\n1.11. “Patent Claims” of a Contributor\nmeans any patent claim(s), including without limitation, method, process, and apparatus claims, in any patent Licensable by such Contributor that would be infringed, but for the grant of the License, by the making, using, selling, offering for sale, having made, import, or transfer of either its Contributions or its Contributor Version.\n1.12. “Secondary License”\nmeans either the GNU General Public License, Version 2.0, the GNU Lesser General Public License, Version 2.1, the GNU Affero General Public License, Version 3.0, or any later versions of those licenses.\n1.13. “Source Code Form”\nmeans the form of the work preferred for making modifications.\n1.14. “You” (or “Your”)\nmeans an individual or a legal entity exercising rights under this License. For legal entities, “You” includes any entity that controls, is controlled by, or is under common control with You. For purposes of this definition, “control” means (a) the power, direct or indirect, to cause the direction or management of such entity, whether by contract or otherwise, or (b) ownership of more than fifty percent (50%) of the outstanding shares or beneficial ownership of such entity.\n2. License Grants and Conditions\n2.1. Grants\nEach Contributor hereby grants You a world-wide, royalty-free, non-exclusive license:\nunder intellectual property rights (other than patent or trademark) Licensable by such Contributor to use, reproduce, make available, modify, display, perform, distribute, and otherwise exploit its Contributions, either on an unmodified basis, with Modifications, or as part of a Larger Work; and\nunder Patent Claims of such Contributor to make, use, sell, offer for sale, have made, import, and otherwise transfer either its Contributions or its Contributor Version.\n2.2. Effective Date\nThe licenses granted in Section 2.1 with respect to any Contribution become effective for each Contribution on the date the Contributor first distributes such Contribution.\n2.3. Limitations on Grant Scope\nThe licenses granted in this Section 2 are the only rights granted under this License. No additional rights or licenses will be implied from the distribution or licensing of Covered Software under this License. Notwithstanding Section 2.1(b) above, no patent license is granted by a Contributor:\nfor any code that a Contributor has removed from Covered Software; or\nfor infringements caused by: (i) Your and any other third party’s modifications of Covered Software, or (ii) the combination of its Contributions with other software (except as part of its Contributor Version); or\nunder Patent Claims infringed by Covered Software in the absence of its Contributions.\nThis License does not grant any rights in the trademarks, service marks, or logos of any Contributor (except as may be necessary to comply with the notice requirements in Section 3.4).\n2.4. Subsequent Licenses\nNo Contributor makes additional grants as a result of Your choice to distribute the Covered Software under a subsequent version of this License (see Section 10.2) or under the terms of a Secondary License (if permitted under the terms of Section 3.3).\n2.5. Representation\nEach Contributor represents that the Contributor believes its Contributions are its original creation(s) or it has sufficient rights to grant the rights to its Contributions conveyed by this License.\n2.6. Fair Use\nThis License is not intended to limit any rights You have under applicable copyright doctrines of fair use, fair dealing, or other equivalents.\n2.7. Conditions\nSections 3.1, 3.2, 3.3, and 3.4 are conditions of the licenses granted in Section 2.1.\n3. Responsibilities\n3.1. Distribution of Source Form\nAll distribution of Covered Software in Source Code Form, including any Modifications that You create or to which You contribute, must be under the terms of this License. You must inform recipients that the Source Code Form of the Covered Software is governed by the terms of this License, and how they can obtain a copy of this License. You may not attempt to alter or restrict the recipients’ rights in the Source Code Form.\n3.2. Distribution of Executable Form\nIf You distribute Covered Software in Executable Form then:\nsuch Covered Software must also be made available in Source Code Form, as described in Section 3.1, and You must inform recipients of the Executable Form how they can obtain a copy of such Source Code Form by reasonable means in a timely manner, at a charge no more than the cost of distribution to the recipient; and\nYou may distribute such Executable Form under the terms of this License, or sublicense it under different terms, provided that the license for the Executable Form does not attempt to limit or alter the recipients’ rights in the Source Code Form under this License.\n3.3. Distribution of a Larger Work\nYou may create and distribute a Larger Work under terms of Your choice, provided that You also comply with the requirements of this License for the Covered Software. If the Larger Work is a combination of Covered Software with a work governed by one or more Secondary Licenses, and the Covered Software is not Incompatible With Secondary Licenses, this License permits You to additionally distribute such Covered Software under the terms of such Secondary License(s), so that the recipient of the Larger Work may, at their option, further distribute the Covered Software under the terms of either this License or such Secondary License(s).\n3.4. Notices\nYou may not remove or alter the substance of any license notices (including copyright notices, patent notices, disclaimers of warranty, or limitations of liability) contained within the Source Code Form of the Covered Software, except that You may alter any license notices to the extent required to remedy known factual inaccuracies.\n3.5. Application of Additional Terms\nYou may choose to offer, and to charge a fee for, warranty, support, indemnity or liability obligations to one or more recipients of Covered Software. However, You may do so only on Your own behalf, and not on behalf of any Contributor. You must make it absolutely clear that any such warranty, support, indemnity, or liability obligation is offered by You alone, and You hereby agree to indemnify every Contributor for any liability incurred by such Contributor as a result of warranty, support, indemnity or liability terms You offer. You may include additional disclaimers of warranty and limitations of liability specific to any jurisdiction.\n4. Inability to Comply Due to Statute or Regulation\nIf it is impossible for You to comply with any of the terms of this License with respect to some or all of the Covered Software due to statute, judicial order, or regulation then You must: (a) comply with the terms of this License to the maximum extent possible; and (b) describe the limitations and the code they affect. Such description must be placed in a text file included with all distributions of the Covered Software under this License. Except to the extent prohibited by statute or regulation, such description must be sufficiently detailed for a recipient of ordinary skill to be able to understand it.\n5. Termination\n5.1. The rights granted under this License will terminate automatically if You fail to comply with any of its terms. However, if You become compliant, then the rights granted under this License from a particular Contributor are reinstated (a) provisionally, unless and until such Contributor explicitly and finally terminates Your grants, and (b) on an ongoing basis, if such Contributor fails to notify You of the non-compliance by some reasonable means prior to 60 days after You have come back into compliance. Moreover, Your grants from a particular Contributor are reinstated on an ongoing basis if such Contributor notifies You of the non-compliance by some reasonable means, this is the first time You have received notice of non-compliance with this License from such Contributor, and You become compliant prior to 30 days after Your receipt of the notice.\n5.2. If You initiate litigation against any entity by asserting a patent infringement claim (excluding declaratory judgment actions, counter-claims, and cross-claims) alleging that a Contributor Version directly or indirectly infringes any patent, then the rights granted to You by any and all Contributors for the Covered Software under Section 2.1 of this License shall terminate.\n5.3. In the event of termination under Sections 5.1 or 5.2 above, all end user license agreements (excluding distributors and resellers) which have been validly granted by You or Your distributors under this License prior to termination shall survive termination.\n6. Disclaimer of Warranty\nCovered Software is provided under this License on an “as is” basis, without warranty of any kind, either expressed, implied, or statutory, including, without limitation, warranties that the Covered Software is free of defects, merchantable, fit for a particular purpose or non-infringing. The entire risk as to the quality and performance of the Covered Software is with You. Should any Covered Software prove defective in any respect, You (not any Contributor) assume the cost of any necessary servicing, repair, or correction. This disclaimer of warranty constitutes an essential part of this License. No use of any Covered Software is authorized under this License except under this disclaimer.\n7. Limitation of Liability\nUnder no circumstances and under no legal theory, whether tort (including negligence), contract, or otherwise, shall any Contributor, or anyone who distributes Covered Software as permitted above, be liable to You for any direct, indirect, special, incidental, or consequential damages of any character including, without limitation, damages for lost profits, loss of goodwill, work stoppage, computer failure or malfunction, or any and all other commercial damages or losses, even if such party shall have been informed of the possibility of such damages. This limitation of liability shall not apply to liability for death or personal injury resulting from such party’s negligence to the extent applicable law prohibits such limitation. Some jurisdictions do not allow the exclusion or limitation of incidental or consequential damages, so this exclusion and limitation may not apply to You.\n8. Litigation\nAny litigation relating to this License may be brought only in the courts of a jurisdiction where the defendant maintains its principal place of business and such litigation shall be governed by laws of that jurisdiction, without reference to its conflict-of-law provisions. Nothing in this Section shall prevent a party’s ability to bring cross-claims or counter-claims.\n9. Miscellaneous\nThis License represents the complete agreement concerning the subject matter hereof. If any provision of this License is held to be unenforceable, such provision shall be reformed only to the extent necessary to make it enforceable. Any law or regulation which provides that the language of a contract shall be construed against the drafter shall not be used to construe this License against a Contributor.\n10. Versions of the License\n10.1. New Versions\nMozilla Foundation is the license steward. Except as provided in Section 10.3, no one other than the license steward has the right to modify or publish new versions of this License. Each version will be given a distinguishing version number.\n10.2. Effect of New Versions\nYou may distribute the Covered Software under the terms of the version of the License under which You originally received the Covered Software, or under the terms of any subsequent version published by the license steward.\n10.3. Modified Versions\nIf you create software not governed by this License, and you want to create a new license for such software, you may create and use a modified version of this License if you rename the license and remove any references to the name of the license steward (except to note that such modified license differs from this License).\n10.4. Distributing Source Code Form that is Incompatible With Secondary Licenses\nIf You choose to distribute Source Code Form that is Incompatible With Secondary Licenses under the terms of this version of the License, the notice described in Exhibit B of this License must be attached.\nExhibit A - Source Code Form License Notice\nThis Source Code Form is subject to the terms of the Mozilla Public License, v. 2.0. If a copy of the MPL was not distributed with this file, You can obtain one at https://mozilla.org/MPL/2.0/.\nIf it is not possible or desirable to put the notice in a particular file, then You may include the notice in a location (such as a LICENSE file in a relevant directory) where a recipient would be likely to look for such a notice.\nYou may add additional accurate notices of copyright ownership.\nExhibit B - “Incompatible With Secondary Licenses” Notice\nThis Source Code Form is “Incompatible With Secondary Licenses”, as defined by the Mozilla Public License, v. 2.0.\n\n\nSoftware: JSON for Modern C++ 3.10.1\nCopyright notice: \nCopyright 2015 Google Inc. All rights reserved.\nCopyright 2018 Google Inc. All rights reserved.\nCopyright 2016 Ismael Jimenez Martinez. All rights reserved.\nCopyright 2017 Roman Lebedev. All rights reserved.\nCopyright (c) 2012 Two Blue Cubes Ltd. All rights reserved.\nCopyright (c) 2015 Max Woolf\nCopyright 2014 The Authors\nCopyright (c) 2016 Nicolas Seriot\nCopyright (c) 2015-2017 Niels Lohmann.\nCopyright (c) 2015-2017 Niels Lohmann\nCopyright (c) 2013-2019 Niels Lohmann <http:nlohmann.me>.\nCopyright (c) 2018 Vitaliy Manushkin <agri@akamo.info>.\nCopyright (c) 2012, Erik Edlund <erik.edlund@32767.se>\nCopyright (c) 2013-2019 Niels Lohmann\nCopyright 2013-2019 [Niels Lohmann](http:nlohmann.me)\nCopyright (c) 2009 Google Inc. All rights reserved.\nCopyright (C) 2009 Google Inc.\n\nLicense: MIT License\nThe MIT License\nCopyright (c) <year> <copyright holders>\nPermission is hereby granted, free of charge, to any person obtaining a copy\nof this software and associated documentation files (the \"Software\"), to deal\nin the Software without restriction, including without limitation the rights\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\ncopies of the Software, and to permit persons to whom the Software is\nfurnished to do so, subject to the following conditions:\nThe above copyright notice and this permission notice shall be included in\nall copies or substantial portions of the Software.\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN\nTHE SOFTWARE.\n\n\nSoftware: oneDNN 2.2\nCopyright (c) 2011, Intel Corporation All rights reserved.\nCopyright 2015, Google Inc.\nCopyright 2008, Google Inc.\nCopyright 2016-2020 Intel Corporation\nCopyright 2006, Google Inc.\nCopyright 2018 YANDEX LLC\nCopyright (c) 2005-2014 Intel Corporation. All rights reserved.\nCopyright (c) 2010-2018 The MathJax Consortium\nCopyright (c) 2013, The MathJax Consortium, with Reserved Font Name Asana MathJax.\nCopyright 2018-2020 Intel Corporation\nCopyright 2007, Google Inc.\nCopyright 2008 Google Inc.\nCopyright 2005-2014 Daniel James.\nCopyright 2020 Intel Corporation\nCopyright 2020 Arm Limited and affiliates.\nCopyright (c) 2007, Apostolos Syropoulos (<asyropoulos@yahoo.com), with Reserved Font Name Asana Math.\nCopyright (c) 2009-2018 The MathJax Consortium\nCopyright (c) 2007 MITSUNARI Shigeo All rights reserved.\nCopyright 2019-2020 Intel Corporation\nCopyright 2017-2020 Intel Corporation\nCopyright 2016-2019 Intel Corporation\nCopyright (c) 2011-2015 The MathJax Consortium\nCopyright 2017 - 2020 Intel Corporation Licensed under the Apache License, Version 2.0 (the \"License\");\nCopyright (c) 2015-2017 Martin Hensel\nCopyright 2005, Google Inc.\n\n                                Apache License\n                           Version 2.0, January 2004\n                        http://www.apache.org/licenses/\n\n   TERMS AND CONDITIONS FOR USE, REPRODUCTION, AND DISTRIBUTION\n\n   1. Definitions.\n\n      \"License\" shall mean the terms and conditions for use, reproduction,\n      and distribution as defined by Sections 1 through 9 of this document.\n\n      \"Licensor\" shall mean the copyright owner or entity authorized by\n      the copyright owner that is granting the License.\n\n      \"Legal Entity\" shall mean the union of the acting entity and all\n      other entities that control, are controlled by, or are under common\n      control with that entity. For the purposes of this definition,\n      \"control\" means (i) the power, direct or indirect, to cause the\n      direction or management of such entity, whether by contract or\n      otherwise, or (ii) ownership of fifty percent (50%) or more of the\n      outstanding shares, or (iii) beneficial ownership of such entity.\n\n      \"You\" (or \"Your\") shall mean an individual or Legal Entity\n      exercising permissions granted by this License.\n\n      \"Source\" form shall mean the preferred form for making modifications,\n      including but not limited to software source code, documentation\n      source, and configuration files.\n\n      \"Object\" form shall mean any form resulting from mechanical\n      transformation or translation of a Source form, including but\n      not limited to compiled object code, generated documentation,\n      and conversions to other media types.\n\n      \"Work\" shall mean the work of authorship, whether in Source or\n      Object form, made available under the License, as indicated by a\n      copyright notice that is included in or attached to the work\n      (an example is provided in the Appendix below).\n\n      \"Derivative Works\" shall mean any work, whether in Source or Object\n      form, that is based on (or derived from) the Work and for which the\n      editorial revisions, annotations, elaborations, or other modifications\n      represent, as a whole, an original work of authorship. For the purposes\n      of this License, Derivative Works shall not include works that remain\n      separable from, or merely link (or bind by name) to the interfaces of,\n      the Work and Derivative Works thereof.\n\n      \"Contribution\" shall mean any work of authorship, including\n      the original version of the Work and any modifications or additions\n      to that Work or Derivative Works thereof, that is intentionally\n      submitted to Licensor for inclusion in the Work by the copyright owner\n      or by an individual or Legal Entity authorized to submit on behalf of\n      the copyright owner. For the purposes of this definition, \"submitted\"\n      means any form of electronic, verbal, or written communication sent\n      to the Licensor or its representatives, including but not limited to\n      communication on electronic mailing lists, source code control systems,\n      and issue tracking systems that are managed by, or on behalf of, the\n      Licensor for the purpose of discussing and improving the Work, but\n      excluding communication that is conspicuously marked or otherwise\n      designated in writing by the copyright owner as \"Not a Contribution.\"\n\n      \"Contributor\" shall mean Licensor and any individual or Legal Entity\n      on behalf of whom a Contribution has been received by Licensor and\n      subsequently incorporated within the Work.\n\n   2. Grant of Copyright License. Subject to the terms and conditions of\n      this License, each Contributor hereby grants to You a perpetual,\n      worldwide, non-exclusive, no-charge, royalty-free, irrevocable\n      copyright license to reproduce, prepare Derivative Works of,\n      publicly display, publicly perform, sublicense, and distribute the\n      Work and such Derivative Works in Source or Object form.\n\n   3. Grant of Patent License. Subject to the terms and conditions of\n      this License, each Contributor hereby grants to You a perpetual,\n      worldwide, non-exclusive, no-charge, royalty-free, irrevocable\n      (except as stated in this section) patent license to make, have made,\n      use, offer to sell, sell, import, and otherwise transfer the Work,\n      where such license applies only to those patent claims licensable\n      by such Contributor that are necessarily infringed by their\n      Contribution(s) alone or by combination of their Contribution(s)\n      with the Work to which such Contribution(s) was submitted. If You\n      institute patent litigation against any entity (including a\n      cross-claim or counterclaim in a lawsuit) alleging that the Work\n      or a Contribution incorporated within the Work constitutes direct\n      or contributory patent infringement, then any patent licenses\n      granted to You under this License for that Work shall terminate\n      as of the date such litigation is filed.\n\n   4. Redistribution. You may reproduce and distribute copies of the\n      Work or Derivative Works thereof in any medium, with or without\n      modifications, and in Source or Object form, provided that You\n      meet the following conditions:\n\n      (a) You must give any other recipients of the Work or\n          Derivative Works a copy of this License; and\n\n      (b) You must cause any modified files to carry prominent notices\n          stating that You changed the files; and\n\n      (c) You must retain, in the Source form of any Derivative Works\n          that You distribute, all copyright, patent, trademark, and\n          attribution notices from the Source form of the Work,\n          excluding those notices that do not pertain to any part of\n          the Derivative Works; and\n\n      (d) If the Work includes a \"NOTICE\" text file as part of its\n          distribution, then any Derivative Works that You distribute must\n          include a readable copy of the attribution notices contained\n          within such NOTICE file, excluding those notices that do not\n          pertain to any part of the Derivative Works, in at least one\n          of the following places: within a NOTICE text file distributed\n          as part of the Derivative Works; within the Source form or\n          documentation, if provided along with the Derivative Works; or,\n          within a display generated by the Derivative Works, if and\n          wherever such third-party notices normally appear. The contents\n          of the NOTICE file are for informational purposes only and\n          do not modify the License. You may add Your own attribution\n          notices within Derivative Works that You distribute, alongside\n          or as an addendum to the NOTICE text from the Work, provided\n          that such additional attribution notices cannot be construed\n          as modifying the License.\n\n      You may add Your own copyright statement to Your modifications and\n      may provide additional or different license terms and conditions\n      for use, reproduction, or distribution of Your modifications, or\n      for any such Derivative Works as a whole, provided Your use,\n      reproduction, and distribution of the Work otherwise complies with\n      the conditions stated in this License.\n\n   5. Submission of Contributions. Unless You explicitly state otherwise,\n      any Contribution intentionally submitted for inclusion in the Work\n      by You to the Licensor shall be under the terms and conditions of\n      this License, without any additional terms or conditions.\n      Notwithstanding the above, nothing herein shall supersede or modify\n      the terms of any separate license agreement you may have executed\n      with Licensor regarding such Contributions.\n\n   6. Trademarks. This License does not grant permission to use the trade\n      names, trademarks, service marks, or product names of the Licensor,\n      except as required for reasonable and customary use in describing the\n      origin of the Work and reproducing the content of the NOTICE file.\n\n   7. Disclaimer of Warranty. Unless required by applicable law or\n      agreed to in writing, Licensor provides the Work (and each\n      Contributor provides its Contributions) on an \"AS IS\" BASIS,\n      WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or\n      implied, including, without limitation, any warranties or conditions\n      of TITLE, NON-INFRINGEMENT, MERCHANTABILITY, or FITNESS FOR A\n      PARTICULAR PURPOSE. You are solely responsible for determining the\n      appropriateness of using or redistributing the Work and assume any\n      risks associated with Your exercise of permissions under this License.\n\n   8. Limitation of Liability. In no event and under no legal theory,\n      whether in tort (including negligence), contract, or otherwise,\n      unless required by applicable law (such as deliberate and grossly\n      negligent acts) or agreed to in writing, shall any Contributor be\n      liable to You for damages, including any direct, indirect, special,\n      incidental, or consequential damages of any character arising as a\n      result of this License or out of the use or inability to use the\n      Work (including but not limited to damages for loss of goodwill,\n      work stoppage, computer failure or malfunction, or any and all\n      other commercial damages or losses), even if such Contributor\n      has been advised of the possibility of such damages.\n\n   9. Accepting Warranty or Additional Liability. While redistributing\n      the Work or Derivative Works thereof, You may choose to offer,\n      and charge a fee for, acceptance of support, warranty, indemnity,\n      or other liability obligations and/or rights consistent with this\n      License. However, in accepting such obligations, You may act only\n      on Your own behalf and on Your sole responsibility, not on behalf\n      of any other Contributor, and only if You agree to indemnify,\n      defend, and hold each Contributor harmless for any liability\n      incurred by, or claims asserted against, such Contributor by reason\n      of your accepting any such warranty or additional liability.\n\n   END OF TERMS AND CONDITIONS\n\n   ============================================================================\n\n   Copyright 2016-2019 Intel Corporation\n   Copyright 2018 YANDEX LLC\n\n   Licensed under the Apache License, Version 2.0 (the \"License\");\n   you may not use this file except in compliance with the License.\n   You may obtain a copy of the License at\n\n       http://www.apache.org/licenses/LICENSE-2.0\n\n   Unless required by applicable law or agreed to in writing, software\n   distributed under the License is distributed on an \"AS IS\" BASIS,\n   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n   See the License for the specific language governing permissions and\n   limitations under the License.\n\n   This distribution includes third party software (\"third party programs\").\n   This third party software, even if included with the distribution of\n   the Intel software, may be governed by separate license terms, including\n   without limitation, third party license terms, other Intel software license\n   terms, and open source software license terms. These separate license terms\n   govern your use of the third party programs as set forth in the\n   \"THIRD-PARTY-PROGRAMS\" file.\n\n3-clause BSD license\n====================\n\nXByak (src/cpu/xbyak/)\n----------------------\nCopyright (c) 2007 MITSUNARI Shigeo\nAll rights reserved.\n\nRedistribution and use in source and binary forms, with or without\nmodification, are permitted provided that the following conditions are met:\n\nRedistributions of source code must retain the above copyright notice, this\nlist of conditions and the following disclaimer.\nRedistributions in binary form must reproduce the above copyright notice,\nthis list of conditions and the following disclaimer in the documentation\nand/or other materials provided with the distribution.\nNeither the name of the copyright owner nor the names of its contributors may\nbe used to endorse or promote products derived from this software without\nspecific prior written permission.\n\nTHIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS \"AS IS\"\nAND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE\nIMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE\nARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT OWNER OR CONTRIBUTORS BE\nLIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR\nCONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF\nSUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS\nINTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN\nCONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)\nARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF\nTHE POSSIBILITY OF SUCH DAMAGE.\n-----------------------------------------------------------------------------\nソースコード形式かバイナリ形式か、変更するかしないかを問わず、以下の条件を満た\nす場合に限り、再頒布および使用が許可されます。\n\nソースコードを再頒布する場合、上記の著作権表示、本条件一覧、および下記免責条項\nを含めること。\nバイナリ形式で再頒布する場合、頒布物に付属のドキュメント等の資料に、上記の著作\n権表示、本条件一覧、および下記免責条項を含めること。\n書面による特別の許可なしに、本ソフトウェアから派生した製品の宣伝または販売促進\nに、著作権者の名前またはコントリビューターの名前を使用してはならない。\n本ソフトウェアは、著作権者およびコントリビューターによって「現状のまま」提供さ\nれており、明示黙示を問わず、商業的な使用可能性、および特定の目的に対する適合性\nに関する暗黙の保証も含め、またそれに限定されない、いかなる保証もありません。\n著作権者もコントリビューターも、事由のいかんを問わず、 損害発生の原因いかんを\n問わず、かつ責任の根拠が契約であるか厳格責任であるか（過失その他の）不法行為で\nあるかを問わず、仮にそのような損害が発生する可能性を知らされていたとしても、\n本ソフトウェアの使用によって発生した（代替品または代用サービスの調達、使用の\n喪失、データの喪失、利益の喪失、業務の中断も含め、またそれに限定されない）直接\n損害、間接損害、偶発的な損害、特別損害、懲罰的損害、または結果損害について、\n一切責任を負わないものとします。\n\ngtest (tests/gtests/gtest/)\n---------------------------\nCopyright 2005, Google Inc.\nCopyright 2006, Google Inc.\nCopyright 2007, Google Inc.\nCopyright 2008, Google Inc.\nCopyright 2015, Google Inc.\nAll rights reserved.\n\nRedistribution and use in source and binary forms, with or without\nmodification, are permitted provided that the following conditions are\nmet:\n\n   * Redistributions of source code must retain the above copyright\nnotice, this list of conditions and the following disclaimer.\n   * Redistributions in binary form must reproduce the above\ncopyright notice, this list of conditions and the following disclaimer\nin the documentation and/or other materials provided with the\ndistribution.\n   * Neither the name of Google Inc. nor the names of its\ncontributors may be used to endorse or promote products derived from\nthis software without specific prior written permission.\n\nTHIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS\n\"AS IS\" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT\nLIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR\nA PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT\nOWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,\nSPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT\nLIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,\nDATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY\nTHEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT\n(INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE\nOF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n\nittnotify (src/cpu/jit_utils/jitprofiling/)\n-------------------------------------------\nCopyright (c) 2011, Intel Corporation\nAll rights reserved.\n\nRedistribution and use in source and binary forms, with or without\nmodification, are permitted provided that the following conditions are met:\n\n1. Redistributions of source code must retain the above copyright notice, this\n  list of conditions and the following disclaimer.\n\n2. Redistributions in binary form must reproduce the above copyright notice,\n  this list of conditions and the following disclaimer in the documentation\n  and/or other materials provided with the distribution.\n\n3. Neither the name of the copyright holder nor the names of its\n  contributors may be used to endorse or promote products derived from\n  this software without specific prior written permission.\n\nTHIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS \"AS IS\"\nAND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE\nIMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE\nDISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE\nFOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL\nDAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR\nSERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER\nCAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY,\nOR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE\nOF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n\nCMake (cmake/FindOpenCL.cmake)\n------------------------------\nCMake - Cross Platform Makefile Generator\nCopyright 2000-2019 Kitware, Inc. and Contributors\nAll rights reserved.\n\nRedistribution and use in source and binary forms, with or without\nmodification, are permitted provided that the following conditions\nare met:\n\n* Redistributions of source code must retain the above copyright\n notice, this list of conditions and the following disclaimer.\n\n* Redistributions in binary form must reproduce the above copyright\n notice, this list of conditions and the following disclaimer in the\n documentation and/or other materials provided with the distribution.\n\n* Neither the name of Kitware, Inc. nor the names of Contributors\n may be used to endorse or promote products derived from this\n software without specific prior written permission.\n\nTHIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS\n\"AS IS\" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT\nLIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR\nA PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT\nHOLDER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,\nSPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT\nLIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,\nDATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY\nTHEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT\n(INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE\nOF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n\nApache License, Version 2.0\n===========================\n\nMathJax (doc/assets/mathjax/)\n-----------------------------\nCopyright (c) 2009-2018 The MathJax Consortium\nCopyright (c) 2015-2017 Martin Hensel\nCopyright (c) 2007, Apostolos Syropoulos (<asyropoulos@yahoo.com),\n\nLicensed under the Apache License, Version 2.0 (the \"License\");\nyou may not use this file except in compliance with the License.\nYou may obtain a copy of the License at\n\n   http://www.apache.org/licenses/LICENSE-2.0\n\nUnless required by applicable law or agreed to in writing, software\ndistributed under the License is distributed on an \"AS IS\" BASIS,\nWITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\nSee the License for the specific language governing permissions and\nlimitations under the License.\n\nBoost Software License, Version 1.0\n===================================\n\nBoost C++ Libraries (src/common/primitive_hashing.hpp)\n------------------------------------------------------\nCopyright 2005-2014 Daniel James.\n\nDistributed under the Boost Software License, Version 1.0.\n\nBoost Software License - Version 1.0 - August 17th, 2003\n\nPermission is hereby granted, free of charge, to any person or organization\nobtaining a copy of the software and accompanying documentation covered by\nthis license (the \"Software\") to use, reproduce, display, distribute,\nexecute, and transmit the Software, and to prepare derivative works of the\nSoftware, and to permit third-parties to whom the Software is furnished to\ndo so, all subject to the following:\n\nThe copyright notices in the Software and this entire statement, including\nthe above license grant, this restriction and the following disclaimer,\nmust be included in all copies of the Software, in whole or in part, and\nall derivative works of the Software, unless such copies or derivative\nworks are solely in the form of machine-executable object code generated by\na source language processor.\n\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\nFITNESS FOR A PARTICULAR PURPOSE, TITLE AND NON-INFRINGEMENT. IN NO EVENT\nSHALL THE COPYRIGHT HOLDERS OR ANYONE DISTRIBUTING THE SOFTWARE BE LIABLE\nFOR ANY DAMAGES OR OTHER LIABILITY, WHETHER IN CONTRACT, TORT OR OTHERWISE,\nARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER\nDEALINGS IN THE SOFTWARE.\n\nSoftware: NCCL 2.16.5-1\nCopyright (c) 2016-2019, NVIDIA CORPORATION. All rights reserved.\nCopyright (c) 2015-2019, NVIDIA CORPORATION. All rights reserved.\nCopyright (c) 2017-2019, NVIDIA CORPORATION. All rights reserved.\nCopyright\nCopyright (c) 2019, NVIDIA CORPORATION. All rights reserved.\nCopyright (c) 2018-2019, NVIDIA CORPORATION. All rights reserved.\nCopyright (c) 2015-2017, NVIDIA CORPORATION. All rights reserved.\nCopyright (c) 2004, 2005 Topspin Communications.  All rights reserved.\nCopyright (c) 2004, 2011-2012 Intel Corporation.  All rights reserved.\nCopyright (c) 2005, 2006, 2007 Cisco Systems, Inc.  All rights reserved.\nCopyright (c) 2005 PathScale, Inc.  All rights reserved.\n\nLicense: BSD 3-Clause License \nCopyright (c) 2015-2019, NVIDIA CORPORATION. All rights reserved.\n\n Redistribution and use in source and binary forms, with or without\n modification, are permitted provided that the following conditions\n are met:\n  * Redistributions of source code must retain the above copyright\n    notice, this list of conditions and the following disclaimer.\n  * Redistributions in binary form must reproduce the above copyright\n    notice, this list of conditions and the following disclaimer in the\n    documentation and/or other materials provided with the distribution.\n  * Neither the name of NVIDIA CORPORATION, Lawrence Berkeley National\n    Laboratory, the U.S. Department of Energy, nor the names of their\n    contributors may be used to endorse or promote products derived\n    from this software without specific prior written permission.\n\n THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS ``AS IS'' AND ANY\n EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE\n IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR\n PURPOSE ARE DISCLAIMED.  IN NO EVENT SHALL THE COPYRIGHT OWNER OR\n CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL,\n EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO,\n PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR\n PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY\n OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT\n (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE\n OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n\n The U.S. Department of Energy funded the development of this software\n under subcontract 7078610 with Lawrence Berkeley National Laboratory.\n\nSoftware: OpenMPI 4.1.4\nCopyright (c) 2015 Cisco Systems, Inc.  All rights reserved.\n$COPYRIGHT$\nCopyright (c) 2015      Los Alamos National Security, LLC. All rights\nCopyright (c) 2016      IBM Corporation.  All rights reserved.\nCopyright (c) 2004-2005 The Trustees of Indiana University and Indiana\nCopyright (c) 2004-2006 The University of Tennessee and The University\nCopyright (c) 2004-2005 High Performance Computing Center Stuttgart,\nUniversity of Stuttgart.  All rights reserved.\nCopyright (c) 2004-2005 The Regents of the University of California.\nCopyright (c) 2013-2015 University of Houston. All rights reserved.\nCopyright (c) 2016-2017 IBM Corporation. All rights reserved.\nCopyright (c) 2013-2016 University of Houston. All rights reserved.\nCopyright (c) 2015      Research Organization for Information Science\nCopyright (c) 2004-2017 The University of Tennessee and The University\nCopyright (c) 2004-2005 The University of Tennessee and The University\nCopyright (c) 2013      University of Houston. All rights reserved.\nCopyright (c) 2008      University of Houston. All rights reserved.\nCopyright (c) 2013-2016 Los Alamos National Security, LLC. All rights\nCopyright (c) 2014      Research Organization for Information Science\nCopyright (c) 2013-2014 Los Alamos National Security, LLC. All rights\nCopyright (c) 2014-2015 Intel, Inc. All rights reserved.\nCopyright (c) 2013      Los Alamos National Security, LLC. All rights\nCopyright (c) 2014      Intel, Inc. All rights reserved.\nCopyright (c) 2013-2015 Los Alamos National Security, LLC. All rights\nCopyright (C) 2001 University of Chicago.\nCopyright (C) 1997 University of Chicago.\nCopyright (c) 2013-2015 The University of Tennessee and The University\nCopyright (c) 2013-2017 Inria.  All rights reserved.\nCopyright (c) 2015      Bull SAS.  All rights reserved.\nCopyright (c) 2013-2016 The University of Tennessee and The University\nCopyright (c) 2013-2018 Inria.  All rights reserved.\nCopyright (c) 2004-2008 The Trustees of Indiana University and Indiana\nCopyright (c) 2006-2007 Cisco Systems, Inc.  All rights reserved.\nCopyright (c) 2007-2008 Cisco Systems, Inc. All rights reserved.\nCopyright (c) 2006-2015 Cisco Systems, Inc.  All rights reserved.\nCopyright (c) 2013      Los Alamos National Security, LLC.  All rights reserved.\nCopyright (c) 2013      Intel, Inc.  All rights reserved.\nCopyright (c) 2008-2012 Cisco Systems, Inc.  All rights reserved.\nCopyright (c) 2009      Sun Microsystems, Inc.  All rights reserved.\nCopyright (c) 2015-2017 Intel, Inc. All rights reserved.\nCopyright (c) 2017      IBM Corporation. All rights reserved.\nCopyright (c) 2004-2011 The University of Tennessee and The University\nCopyright (c) 2008-2009 Sun Microsystems, Inc.  All rights reserved.\nCopyright (c) 2016      Los Alamos National Security, LLC. All rights\nCopyright (c) 2016      Research Organization for Information Science\nCopyright (c) 2010      Cisco Systems, Inc.  All rights reserved.\nCopyright (c) 2010      Oracle and/or its affiliates.  All rights reserved.\nCopyright (c) 2004-2006 High Performance Computing Center Stuttgart,\nCopyright (c) 2004-2007 High Performance Computing Center Stuttgart,\nCopyright (c) 2004-2008 The Trustees of Indiana University.\nCopyright (c) 2004-2010 The Trustees of Indiana University.\nCopyright (c) 2014 Cisco Systems, Inc.  All rights reserved.\nCopyright (c) 2004-2007 The Trustees of Indiana University and Indiana\nCopyright (c) 2008      Cisco Systems, Inc.  All rights reserved.\nCopyright (c) 2016-2018 Intel, Inc.  All rights reserved.\nCopyright (c) 2018      Research Organization for Information Science\nCopyright (c)      2010 The Trustees of Indiana University and Indiana\nCopyright (c)      2010 The Trustees of Indiana University.\nCopyright (c) 2012      The University of Wisconsin-La Crosse. All rights\nCopyright (c) 2011      Cisco Systems, Inc.  All rights reserved.\nCopyright (c) 2011      Los Alamos National Security, LLC.\nCopyright (c) 2014-2017 Intel, Inc.  All rights reserved.\nCopyright (c) 2015-2017 Research Organization for Information Science\nCopyright (c) 2011-2017 Cisco Systems, Inc.  All rights reserved\nCopyright (c) 2006-2013 Los Alamos National Security, LLC.  All rights\nCopyright (c) 2007-2010 Cisco Systems, Inc.  All rights reserved.\nCopyright (c) 2010      Sandia National Laboratories. All rights reserved.\nCopyright (c) 2006-2012 Los Alamos National Security, LLC.  All rights\nCopyright (c) 2007      Cisco Systems, Inc.  All rights reserved.\nCopyright (c) 2006-2007 Los Alamos National Security, LLC.  All rights\nCopyright (c) 2007      Sun Microsystem, Inc.  All rights reserved.\nCopyright (c) 2014      Mellanox Technologies, Inc.\nCopyright (c) 2014      Cisco Systems, Inc.  All rights reserved.\nCopyright (c) 2014-2015 Intel, Inc.  All rights reserved.\nCopyright (c) 2004-2006 The Trustees of Indiana University and Indiana\nCopyright (c) 2004-2006 The Regents of the University of California.\nCopyright (c) 2007      Voltaire. All rights reserved.\nCopyright (c) 2012      Los Alamos National Security, LLC. All rights reserved.\nCopyright (c) 2004-2008 High Performance Computing Center Stuttgart,\nCopyright (c) 2007      Los Alamos National Security, LLC.\nCopyright (c) 2009-2014 Cisco Systems, Inc.  All rights reserved.\nCopyright (c) 2014-2015 Research Organization for Information Science\nCopyright (c) 2017      Amazon.com, Inc. or its affiliates.  All Rights\nCopyright (c) 2004-2011 High Performance Computing Center Stuttgart,\nCopyright (c) 2004-2013 The University of Tennessee and The University\nCopyright (c) 2012-2017 Los Alamos National Security, LLC. All rights\nCopyright (c) 2012-2015 Cisco Systems, Inc.  All rights reserved.\nCopyright (c) 2016-2017 Intel, Inc. All rights reserved.\nCopyright (c) 2012      Cisco Systems, Inc.  All rights reserved.\nCopyright (c) 2015-2016 Intel, Inc. All rights reserved.\nCopyright (c) 2016-2017 Los Alamos National Security, LLC. All rights\nCopyright (c) 2009      IBM Corporation.  All rights reserved.\nCopyright (c) 2009      Los Alamos National Security, LLC.  All rights\nCopyright (c) 2007-2015 Los Alamos National Security, LLC. All rights\nCopyright (c) 2017      FUJITSU LIMITED.  All rights reserved.\nCopyright (c) 2016      Karol Mroz.  All rights reserved.\nCopyright (c) 2016      Cisco Systems, Inc.  All rights reserved.\nCopyright (c) 2016 Karol Mroz.  All rights reserved.\nCopyright (c) 2008-2014 Cisco Systems, Inc.  All rights reserved.\nCopyright (c) 2009 Sandia National Laboratories. All rights reserved.\nCopyright (c) 2017      Mellanox Technologies. All rights reserved.\nCopyright (c) 2009 Cisco Systems, Inc.  All rights reserved.\nCopyright (c) 2017      Intel, Inc.  All rights reserved.\nCopyright (c) 2004-2009 High Performance Computing Center Stuttgart,\nCopyright (c) 2008      Sun Microsystems, Inc.  All rights reserved.\nCopyright (c) 2010-2015 Cisco Systems, Inc.  All rights reserved.\nCopyright (c) 2014-2017 Los Alamos National Security, LLC. All rights\nCopyright (c) 2015-2016 Research Organization for Information Science\nCopyright (c) 2007      Los Alamos National Security, LLC.  All rights\nCopyright (c) 2013 Cisco Systems, Inc.  All rights reserved.\nCopyright (c) 2004-2007 The University of Tennessee and The University\nCopyright (c) 2007-2015 Cisco Systems, Inc.  All rights reserved.\nCopyright (c) 2017      Intel, Inc. All rights reserved.\nCopyright (c) 2004-2010 The Trustees of Indiana University and Indiana\nCopyright (c) 2007-2012 Cisco Systems, Inc.  All rights reserved.\nCopyright (c) 2012-2015 Los Alamos National Security, LLC. All rights\nCopyright (c) 2015-2016 Los Alamos National Security, LLC. All rights\nCopyright (c) 2004-2008 The University of Tennessee and The University\nCopyright (c) 2009-2015 Cisco Systems, Inc.  All rights reserved.\nCopyright (c) 2007-2013 Los Alamos National Security, LLC.  All rights\nCopyright (c) 1990, 1993\nCopyright (c) 2007-2008 Cisco Systems, Inc.  All rights reserved.\nCopyright (c) 2017      IBM Corporation.  All rights reserved.\nCopyright (c) 2007-2011 Cisco Systems, Inc.  All rights reserved.\nCopyright (c) 2010      IBM Corporation.  All rights reserved.\nCopyright (c) 2012-2013 Los Alamos National Security, LLC.\nCopyright (c) 2014      Intel, Inc.  All rights reserved.\nCopyright (c) 2016      University of Houston. All rights reserved.\nCopyright (c) 2012      Los Alamos National Security, LLC.\nCopyright (c) 2007-2014 Cisco Systems, Inc.  All rights reserved.\nCopyright (c) 2013      The University of Tennessee and The University\nCopyright (c) 2013      Inria.  All rights reserved.\nCopyright (c) 2014-2017 Research Organization for Information Science\nCopyright (c) 2014-2016 Research Organization for Information Science\nCopyright (c) 2017      Cisco Systems, Inc.  All rights reserved\nCopyright (c) 1992, 1993\nCopyright (c) 2008-2011 Cisco Systems, Inc.  All rights reserved.\nCopyright (c) 2006      Cisco Systems, Inc.  All rights reserved.\nCopyright (c) 2006      Sun Microsystems, Inc.  All rights reserved.\nCopyright (c) 2008-2009 Cisco Systems, Inc.  All rights reserved.\nCopyright (c) 2013      Los Alamos National Security, LLC.\nCopyright (C) 2014      Artem Polyakov <artpol84@gmail.com>\nCopyright (c) 2017      Mellanox Technologies Ltd. All rights reserved.\nCopyright (c) 2014-2017 Intel, Inc. All rights reserved.\nCopyright © 2004-2005 The Trustees of Indiana University and Indiana\nCopyright © 2004-2005 The University of Tennessee and The University\nCopyright © 2004-2005 High Performance Computing Center Stuttgart,\nCopyright © 2004-2005 The Regents of the University of California.\nCopyright © 2010-2014   Inria.  All rights reserved.\nCopyright © 2009-2014 Cisco Systems, Inc.  All rights reserved.\nCopyright © 2004-2006 The Trustees of Indiana University and Indiana\nCopyright © 2008-2014 Cisco Systems, Inc.  All rights reserved.\nCopyright © 2014 Inria.  All rights reserved.\nCopyright (C) 2009. QLogic Corporation.  All rights reserved.\nCopyright (c) 2004-2010 The University of Tennessee and The University\nCopyright (c) 2006      QLogic Corporation. All rights reserved.\nCopyright (c) 2013-2014 Intel, Inc. All rights reserved\nCopyright (c) 2014      Los Alamos National Security, LLC. All rights\nCopyright (c) 2006-2010 QLogic Corporation. All rights reserved.\nCopyright (c) 2012-2015 Los Alamos National Security, LLC.\nCopyright (c) 2014      Intel Corporation. All rights reserved.\nCopyright (c) 2007-2011 University of Houston. All rights reserved.\nCopyright (c) 2011-2013 Inria.  All rights reserved.\nCopyright (c) 2011-2013 Universite Bordeaux 1\nCopyright (c) 2012      Oak Ridge National Labs.  All rights reserved.\nCopyright (c) 2012-2016 Los Alamos National Security, LLC.\nCopyright (c) 2015      Mellanox Technologies. All rights reserved.\nCopyright (c) 2006-2017 Cisco Systems, Inc.  All rights reserved\nCopyright (c) 2006-2017 University of Houston.  All rights reserved.\nCopyright (c) 2009      Sun Microsystems, Inc. All rights reserved.\nCopyright (c) 2012-2013 Los Alamos National Security, LLC.  All rights\nCopyright (c) 2007      Voltaire All rights reserved.\nCopyright (c) 2006-2010 University of Houston.  All rights reserved.\nCopyright (c) 2012-2016 Los Alamos National Security, LLC.  All rights\nCopyright (c) 2013-2016 Intel, Inc.  All rights reserved.\nCopyright (c) 2006-2017 University of Houston. All rights reserved.\nCopyright (c) 2013-2016 Los Alamos National Security, LLC.  All rights\nCopyright (c) 2004-2016 The University of Tennessee and The University\nCopyright (c) 2012-2013 Los Alamos National Security, Inc.  All rights reserved.\nCopyright (c) 2010-2011 Oak Ridge National Labs.  All rights reserved.\nCopyright (c) 2011-2013 Los Alamos National Security, LLC.\nCopyright (c) 2013-2017 Intel, Inc. All rights reserved.\nCopyright (c) 2012-2015 Los Alamos National Security, Inc.  All rights\nCopyright (c) 2004-2010 High Performance Computing Center Stuttgart,\nCopyright (c) 2006-2007 University of Houston. All rights reserved.\nCopyright (c) 2006-2010 University of Houston. All rights reserved.\nCopyright (c) 2013      Cisco Systems, Inc.  All rights reserved.\nCopyright (c) 2006-2008 University of Houston. All rights reserved.\nCopyright (c) 2015      Los Alamos National Security, LLC.  All rights\nCopyright (c) 2004-2005 The Trustees of the University of Tennessee.\nCopyright (c) 2004-2007 The Trustees of Indiana University.\nCopyright (c) 2007      The Trustees of Indiana University.\nCopyright (c) 2011-2016 Cisco Systems, Inc.  All rights reserved.\nCopyright (c) 2011-2017 Los Alamos National Security, LLC. All\nCopyright (c) 2016 Cisco Systems, Inc.  All rights reserved.\nCopyright (c) 2013      Mellanox Technologies, Inc.\nCopyright (c) 2012 Cisco Systems, Inc.  All rights reserved.\nCopyright (c) 2007-2008 Sun Microsystems, Inc.  All rights reserved.\nCopyright (c) 2007-2016 Los Alamos National Security, LLC.  All rights\nCopyright (c) 2011-2013 Cisco Systems, Inc.  All rights reserved.\nCopyright (c) 2017      UT-Battelle, LLC. All rights reserved.\nCopyright (c)      2010-2011 Alex Brick <bricka@ccs.neu.edu>.\nCopyright (c) 2014-2019 Intel, Inc.  All rights reserved.\nCopyright (c) 2015-2018 Cisco Systems, Inc.  All rights reserved\nCopyright (c) 2006-2013 Los Alamos National Security, LLC.\nCopyright (c) 2009-2012 Cisco Systems, Inc.  All rights reserved.\nCopyright (c) 2011      Oak Ridge National Labs.  All rights reserved.\nCopyright (c) 2013-2017 Intel, Inc.  All rights reserved.\nCopyright (c) 2010-2011 Cisco Systems, Inc.  All rights reserved.\nCopyright (c) 2006-2017 Los Alamos National Security, LLC. All rights\nCopyright (c) 2014      NVIDIA Corporation.  All rights reserved.\nCopyright (c) 2016      Mellanox Technologies Ltd. All rights reserved.\nCopyright (c) 2017      Research Organization for Information Science\nCopyright (c) 2013-2019 Intel, Inc.  All rights reserved.\nCopyright (c) 2015-2017 Intel, Inc.  All rights reserved.\nCopyright (c) 2009      Cisco Systems, Inc.  All rights reserved.\nCopyright (c) 2010-2013 Cisco Systems, Inc.  All rights reserved.\nCopyright (c) 2007      Sun Microsystems, Inc.  All rights reserved.\nCopyright (c) 2019      Mellanox Technologies, Inc.\nCopyright (c) 2019      Intel, Inc.  All rights reserved.\nCopyright (c) 2011-2015 Los Alamos National Security, LLC. All\nCopyright (c) 2016      Intel, Inc.  All rights reserved.\nCopyright (c) 2007-2009 Cisco Systems, Inc.  All rights reserved.\nCopyright (c) 2010-2017 IBM Corporation. All rights reserved.\nCopyright (c) 2016      Intel, Inc. All rights reserved.\nCopyright (c) 2013      NVIDIA Corporation.  All rights reserved.\nCopyright (c) 2006-2007 Mellanox Technologies. All rights reserved.\nCopyright (c) 2012-2016 Los Alamos National Security, LLC.  All rights reserved.\nCopyright (c) 2011-2015 Los Alamos National Security, LLC. All rights\nCopyright (c) 2008-2015 University of Houston. All rights reserved.\nCopyright (c) 2008-2016 University of Houston. All rights reserved.\nCopyright (c) 2008-2011 University of Houston. All rights reserved.\nCopyright (c) 2017      University of Houston. All rights reserved.\nCopyright (c) 2008-2017 University of Houston. All rights reserved.\nCopyright 2009 Cisco Systems, Inc.  All rights reserved.\nCopyright (C) Mellanox Technologies Ltd. 2001-2011.  ALL RIGHTS RESERVED.\nCopyright (c) 2016      The University of Tennessee and The University\nCopyright (C) Mellanox Technologies Ltd. 2001-2015.  ALL RIGHTS RESERVED.\nCopyright (c) 2015      Mellanox Technologies, Inc.\nCopyright (c) 2004-2005 The Trustees of Indiana University.\nCopyright (c) 2004-2011 The Trustees of the University of Tennessee.\nCopyright (c) 2007-2015 Los Alamos National Security, LLC.  All rights\nCopyright (c) 2014-2016 Intel, Inc. All rights reserved.\nCopyright (c) 2011-2015 Los Alamos National Security, LLC.\nCopyright (c) 2014-2018 Intel, Inc. All rights reserved.\nCopyright (c) 2014-2015 Mellanox Technologies, Inc.\nCopyright (c) 2016-2017 Research Organization for Information Science\nCopyright (c) 2014-2018 Research Organization for Information Science\nCopyright (c) 2014-2016 Intel, Inc.  All rights reserved.\nCopyright (c) 2014-2017 Mellanox Technologies, Inc.\nCopyright (c) 2010-2017 IBM Corporation.  All rights reserved.\nCopyright (c) 2015-2018 Los Alamos National Security, LLC. All rights\nCopyright (c) 2018-2019 Intel, Inc.  All rights reserved.\nCopyright (c) 2004-2015 The University of Tennessee and The University\nCopyright (c) 2007-2008 UT-Battelle, LLC\nCopyright (c) 2012      Oak Rigde National Laboratory. All rights reserved.\nCopyright (c) 2016-2017 IBM Corporation.  All rights reserved.\nCopyright (c) 2004-2014 The University of Tennessee and The University\nCopyright (c) 2006-2014 Cisco Systems, Inc.  All rights reserved.\nCopyright (c) 2012      Los Alamos National Security, LLC.  All rights\nCopyright (c) 2006      University of Houston. All rights reserved.\nCopyright (C) 2003 University of Chicago, Ohio Supercomputer Center.\n(C) 2008 by Argonne National Laboratory.\nSee COPYRIGHT in top-level directory.\nCopyright (c) 2004-2018 The University of Tennessee and The University\nCopyright (c) 2008      UT-Battelle, LLC. All rights reserved.\nCopyright (c) 2006-2008 University of Houston.  All rights reserved.\nCopyright (c) 2009-2010 Oracle and/or its affiliates.  All rights reserved\nCopyright (c) 2011      Sandia National Laboratories. All rights reserved.\nCopyright (c) 2015      FUJITSU LIMITED.  All rights reserved.\nCopyright (c) 2010      Oracle and/or its affiliates.  All rights reserved\nCopyright (c) 2013-2017 Los Alamos National Security, LLC. All rights\nCopyright (c) 2012-2015 NVIDIA Corporation.  All rights reserved.\nCopyright (c) 2015-2017 Los Alamos National Security, LLC. All rights\nCopyright (c) 2009-2012 Oracle and/or its affiliates.  All rights reserved.\nCopyright (c) 2011-2012 Sandia National Laboratories. All rights reserved.\nCopyright (c) 2010-2012 Oracle and/or its affiliates.  All rights reserved.\nCopyright (c) 2014-2015 Los Alamos National Security, LLC. All rights\nCopyright (c) 2009-2010 Oracle and/or its affiliates.  All rights reserved.\nCopyright (c) 2011-2017 Los Alamos National Security, LLC. All rights\nCopyright (c) 2012      FUJITSU LIMITED.  All rights reserved.\nCopyright (c) 2012      NVIDIA Corporation.  All rights reserved.\nCopyright (c) 2012-2016 Los Alamos National Security, LLC. All rights\nCopyright (c) 2015      Cisco Systems, Inc.  All rights reserved.\nCopyright (c) 2018      FUJITSU LIMITED.  All rights reserved.\nCopyright (c) 2011-2012 NVIDIA Corporation.  All rights reserved.\nCopyright (c) 2011-2016 Los Alamos National Security, LLC. All rights\nCopyright (c) 2007      IBM Corp.,  All rights reserved.\nCopyright (c) 2011-2013 Los Alamos National Security, LLC.  All rights\nCopyright (c) 2012      Los Alamos National Security, LLC\nCopyright (c) 2013-2015 Mellanox Technologies, Inc.\nCopyright (c) 2014-2017 Cisco Systems, Inc.  All rights reserved\nCopyright (c) 2012      Sandia National Laboratories.  All rights reserved.\nCopyright (c) 2014-2016 Los Alamos National Security, LLC. All rights\nCopyright (c) 2014-2017 The University of Tennessee and The University\nCopyright (c) 2011      Sandia National Laboratories.  All rights reserved.\nCopyright (c) 2014-2018 Los Alamos National Security, LLC. All rights\nCopyright (c) 2015-2018 Research Organization for Information Science\nCopyright (c) 2017      The University of Tennessee and The University\nCopyright (c) 2013-2018 Intel, Inc.  All rights reserved.\nCopyright (C) 2012 Cisco Systems, Inc.  All rights reserved.\nCopyright (c) 2006      Voltaire. All rights reserved.\nCopyright (c) 2007      Mellanox Technologies. All rights reserved.\nCopyright (c) 2007-2013 Cisco Systems, Inc.  All rights reserved.\nCopyright (c) 2011      The University of Tennessee and The University\nCopyright (c) 2017-2019 Intel, Inc.  All rights reserved.\nCopyright (c) 2008-2015 Cisco Systems, Inc.  All rights reserved.\nCopyright (c) 2010-2015 Los Alamos National Security, LLC.\nCopyright (c) 2016-2019 Research Organization for Information Science\nCopyright (c) 2009      Oak Ridge National Labs.  All rights reserved.\nCopyright (c) 2006      Los Alamos National Security, LLC.  All rights\nCopyright (c) 2010-2014 Los Alamos National Security, LLC.\nCopyright (c) 2014      Hochschule Esslingen.  All rights reserved.\nCopyright (c) 2015-2018 Mellanox Technologies, Inc.\nCopyright (c) 2016-2019 Intel, Inc.  All rights reserved.\nCopyright (c) 2010-2012 Cisco Systems, Inc.  All rights reserved.\nCopyright (c) 2004-2009 The University of Tennessee and The University\nCopyright (c) 2011-2012 Los Alamos National Security, LLC.\nCopyright (c) 2013      Intel, Inc. All rights reserved\nCopyright (c) 2010 Oracle and/or its affiliates.  All rights reserved.\nCopyright (c) 2009-2011 The Trustees of Indiana University.\nCopyright (c) 2010-2017 Oak Ridge National Labs.  All rights reserved.\nCopyright (c) 2011      Oracle and/or all its affiliates.  All rights reserved.\nCopyright (c) 2014-2018 Intel, Inc.  All rights reserved.\nCopyright (c) 2010      Cisco Systems, Inc. All rights reserved.\nCopyright (c) 2011 Cisco Systems, Inc.  All rights reserved.\nCopyright (c) 2012      Los Alamos National Security, Inc. All rights reserved.\nCopyright (c) 2016      Mellanox Technologies, Inc.\nCopyright (c) 2012-2013 Los Alamos National Security, Inc. All rights reserved.\nCopyright (c) 2017      Amazon.com, Inc. or its affiliates.\nCopyright (c) 2014-2019 Research Organization for Information Science\nCopyright (c) 2017      Los Alamos National Security, LLC. All rights\nCopyright (c) 2018      The University of Tennessee and The University\nCopyright (c) 2006-2019 Cisco Systems, Inc.  All rights reserved\nCopyright (c) 2008 Los Alamos National Security, LLC.  All rights reserved.\nCopyright (c) 2015      Mellanox Technologies, Inc.  All rights reserved.\nCopyright (c) 2010-2012 Oak Ridge National Labs.  All rights reserved.\nCopyright (c) 2011      NVIDIA Corporation.  All rights reserved.\nCopyright (c) 2012-2018 Los Alamos National Security, LLC. All rights\nCopyright (c) 2004-2012 The University of Tennessee and The University\nCopyright (c) 2014-2015 Hewlett-Packard Development Company, LP.\nCopyright (c) 2012-2016 Cisco Systems, Inc.  All rights reserved.\nCopyright (c) 2012      Los Alamos National Security, LLC. All rights reserved\nCopyright (c) 2015      Intel, Inc. All rights reserved\nCopyright (c) 2015      Intel, Inc. All rights reserved.\n(c) Class instantiation: static\nCopyright (c) 2011      Oracle and/or its affiliates.  All rights reserved.\nCopyright (c) 2012      The University of Tennessee and The University\nCopyright (c) 2011-2018 Cisco Systems, Inc.  All rights reserved.\nCopyright (c) 2007-2012 Niels Provos and Nick Mathewson\nCopyright (c) 2000-2007 Niels Provos <provos@citi.umich.edu>\nCopyright (c) 2007-2012 Niels Provos, Nick Mathewson\nCopyright (c) 2009-2012 Niels Provos and Nick Mathewson\nCopyright (c) 2006-2007 Niels Provos <provos@citi.umich.edu>\nCopyright (c) 2008-2012 Niels Provos and Nick Mathewson\nCopyright (c) 2011-2012 Cisco Systems, Inc.  All rights reserved.\nCopyright (c) 2006-2012 Cisco Systems, Inc.  All rights reserved.\nCopyright (c) 2011-2015 Cisco Systems, Inc.  All rights reserved.\nCopyright (c) 2011-2014 Cisco Systems, Inc.  All rights reserved.\nCopyright (c) 2010-2018 Cisco Systems, Inc.  All rights reserved\nCopyright (c) 2012      Sandia National Laboratories. All rights reserved.\nCopyright (c) 2011-2013 The University of Tennessee and The University\nCopyright (c) 2011-2013 Université Bordeaux 1\nCopyright (c) 2013-2014 Cisco Systems, Inc.  All rights reserved.\nCopyright (c) 2012      Oracle and/or its affiliates.  All rights reserved.\nCopyright (c) 2012      University of Oregon.  All rights reserved.\nCopyright (c) 2012      Inria.  All rights reserved.\nCopyright (c) 2004-2014 High Performance Computing Center Stuttgart,\nCopyright (c) 2019      Research Organization for Information Science\nCopyright (c) 2007-2012 Los Alamos National Security, LLC.\nCopyright (c) 2004-2009 The Trustees of Indiana University and Indiana\nCopyright (c) 2013      Intel, Inc. All rights reserved.\nCopyright (c) 2011-2013 INRIA.  All rights reserved.\nCopyright (c) 2015-2019 Intel, Inc.  All rights reserved.\nCopyright (c) 2018      Cisco Systems, Inc.  All rights reserved\nCopyright 2002 Niels Provos <provos@citi.umich.edu>\nCopyright (c) 2010      ARM ltd.  All rights reserved.\nCopyright (c) 2008      The University of Tennessee and The University\nCopyright (c) 2009      Cisco Systems, Inc.  All Rights Reserved.\nCopyright (c) 2006-2016 Cisco Systems, Inc.  All rights reserved.\nCopyright (c) 2006 The Trustees of Indiana University and Indiana\nCopyright (c) 2006 Cisco Systems, Inc.  All rights reserved.\nCopyright (c) 2012-2013 Los Alamos National Security, LLC. All rights\nCopyright (c) 2012-2014 Los Alamos National Security, LLC. All rights\nCopyright (c) 2012-213 Los Alamos National Security, LLC. All rights\nCopyright (c) 2014-2018 Cisco Systems, Inc.  All rights reserved\nCopyright (c) 2011-2013 Los Alamos National Security, LLC. All rights\nCopyright (c) 2011      UT-Battelle, LLC. All rights reserved.\nCopyright (c) 2007-2011 Los Alamos National Security, LLC.\nCopyright (c) 2007-2015 Los Alamos National Security, LLC.\nCopyright (c) 2015-2016 Intel, Inc.  All rights reserved.\nCopyright (c) 2007-2014 Los Alamos National Security, LLC.  All rights\nCopyright (c) 2008-2013 University of Houston. All rights reserved.\nCopyright (c) 2008-2014 University of Houston. All rights reserved.\nCopyright (c) 2017-2018 Intel, Inc.  All rights reserved.\nCopyright (c) 2014-2016 Mellanox Technologies, Inc.\nCopyright (c) 2014      Intel, Inc. All rights reserved\nCopyright (c) 2014      Los Alamos National Security, LLC.  All rights\nCopyright (c) 2009-2012 Mellanox Technologies.  All rights reserved.\nCopyright (c) 2009-2012 Oak Ridge National Laboratory.  All rights reserved.\nCopyright (c) 2012-2014 Cisco Systems, Inc.  All rights reserved.\nCopyright (c) 2014      The University of Tennessee and The University\nCopyright (c) 2015-2018 Los Alamos National Security, LLC.  All rights\nCopyright (c) 2009-2010 Cisco Systems, Inc.  All rights reserved.\nCopyright (c) 2010-2011 Los Alamos National Security, LLC.\nCopyright (c) 2010-2012 Los Alamos National Security, LLC.\nCopyright (c) 2011-2015 Los Alamos National Security, LLC.  All rights\nCopyright (c) 2016-2018 Los Alamos National Security, LLC. All rights\nCopyright (c) 2016      Broadcom Limited. All rights reserved.\nCopyright (c) 2018      Cisco Systems, Inc.  All rights reserved.\nCopyright (c) 2006-2013 Cisco Systems, Inc.  All rights reserved.\nCopyright (c) 2009-2013 Cisco Systems, Inc.  All rights reserved.\nCopyright (c) 2006      Voltaire All rights reserved.\n\"Copyright (c) 2000-2003 The Regents of the University of California.\nCopyright (c) 2004-2006 The Trustees of the University of Tennessee.\nCopyright (c) 2007-2018 Los Alamos National Security, LLC.  All rights\nCopyright (c) 2012-2013 Sandia National Laboratories.  All rights reserved.\nCopyright (c) 2016-2018 Intel, Inc. All rights reserved.\nCopyright (c) 2014-2018 Los Alamos National Security, LLC.  All rights\nCopyright (c) 2014-2016 Los Alamos National Security, LLC.  All rights\nCopyright (c) 2017-2018 Intel, Inc. All rights reserved.\nCopyright (c) 2014-2015 Los Alamos National Security, LLC.  All rights\nCopyright (c) 2012-2015 Sandia National Laboratories.  All rights reserved.\nCopyright (c) 2015      NVIDIA Corporation.  All rights reserved.\nCopyright (c) 2014-2017 Los Alamos National Security, LLC.  All rights\nCopyright (c) 2007-2016 Los Alamos National Security, LLC. All rights\nCopyright (c) 2018      Intel, Inc. All rights reserved.\nCopyright (c) 2011-2012 Sandia National Laboratories.  All rights reserved.\nCopyright (c) 2011 Mellanox Technologies. All rights reserved.\nCopyright (c) 2011      Mellanox Technologies. All rights reserved.\nCopyright (c) 2016-2017 Intel, Inc.  All rights reserved.\nCopyright (c) 2012-2013 Inria.  All rights reserved.\nCopyright (c) 2009-2017 Cisco Systems, Inc.  All rights reserved\nCopyright (c) 2012-2017 Cisco Systems, Inc.  All rights reserved\nCopyright (C) 2003 University of Chicago.\n(C) 2001 by Argonne National Laboratory.\n(C) 2009 UChicago/Argonne LLC\n(C) 2012 by Argonne National Laboratory.\n(C) 2003 by Argonne National Laboratory.\nCopyright (c) 2015-2018 Intel, Inc. All rights reserved.\nCopyright (c) 2013-2015 Sandia National Laboratories. All rights reserved.\nCopyright (c) 2015      Sandia National Laboratories. All rights reserved.\nCopyright (c) 2013      Sandia National Laboratories.  All rights reserved.\nCopyright (c) 2013-2015 Sandia National Laboratories.  All rights reserved.\nCopyright (c) 2011-2018 Cisco Systems, Inc.  All rights reserved\nCopyright (c) 2011-2012 Los Alamos National Security, LLC.  All rights\nCopyright (c) 2013-2018 Intel, Inc. All rights reserved.\nCopyright (c) 2014      Artem Y. Polyakov <artpol84@gmail.com>.\nCopyright (c) 2015-2018 Intel, Inc.  All rights reserved.\nCopyright (c) 2018      Intel, Inc.  All rights reserved.\nCopyright (c) 2015      NVIDIA, Inc. All rights reserved.\nCopyright (c) 2007      Mellanox Technologies, Inc.  All rights reserved.\nCopyright (c) 2012-2015 Los Alamos National Security, LLC.  All rights\nCopyright (c) 2008 Cisco Systems, Inc.  All rights reserved.\nCopyright (c) 2007-2008 Chelsio, Inc. All rights reserved.\nCopyright (c) 2008      Mellanox Technologies. All rights reserved.\nCopyright (c) 2009      Sandia National Laboratories. All rights reserved.\nCopyright (c) 2012-2017 Los Alamos National Security, LLC.  All rights\nCopyright (c) 2011      Mellanox Technologies.  All rights reserved.\nCopyright (c) 2008-2009 Mellanox Technologies. All rights reserved.\nCopyright (c) 2011-2016 Los Alamos National Security, LLC.  All rights\nCopyright (c) 2014      Bull SAS.  All rights reserved.\nCopyright (c) 2016      Mellanox Technologies. All rights reserved.\nCopyright (c) 2011      Los Alamos National Security, LLC.  All\nCopyright (c) 2007-2017 Cisco Systems, Inc.  All rights reserved\nCopyright (c) 2004-2009 The Trustees of Indiana University.\nCopyright (c) 2016-2019 IBM Corporation.  All rights reserved.\nCopyright (c) 2011      Los Alamos National Security, LLC.  All rights\nCopyright (c) 2011      IBM Corporation.  All rights reserved.\nCopyright (c) 2010      Oracle and/or its affiliates.  All rights\nCopyright (c) 2009-2016 Cisco Systems, Inc.  All rights reserved.\nCopyright (c) 2007-2012 Los Alamos National Security, LLC.  All rights\nCopyright (c) 2011-2017 IBM Corporation.  All rights reserved.\nCopyright (c) 2015-2016 Mellanox Technologies, Inc.\nCopyright (c) 2004-2011 The Trustees of Indiana University.\nCopyright (c) 2010-2013 The University of Tennessee and The University\nCopyright (c) 2007      Evergrid, Inc. All rights reserved.\nCopyright (c) 2008      Institut National de Recherche en Informatique\nCopyright (c) 2016      Intel, Inc. All rights reserved\nCopyright (C) 2004 University of Chicago.\nCopyright (c) 2013-2015 Los Alamos National Security, LLC.  All rights\nCopyright (c) 2011-2012 FUJITSU LIMITED.  All rights reserved.\nCopyright (c) 2008      Voltaire. All rights reserved\nCopyright (c) 2015      Los Alamos National Security, LLC.\nCopyright (c) 2014, Cisco Systems, Inc. All rights reserved.\nCopyright (c) 2014-2015 Cisco Systems, Inc. All rights reserved.\nCopyright (c) 2015 Cisco Systems.  All rights reserved.\nCopyright (c) 2017 Amazon.com, Inc. or its affiliates.\nCopyright (c) 2014 Cisco Systems, Inc. All rights reserved.\nCopyright (c) 2017 Amazon.com, Inc. or its affiliates.  All Rights\nCopyright (c) 2017-XXXX Amazon.com, Inc. or its affiliates.\nCopyright (c) 2012      Los Alamos National Security, Inc.  All rights reserved.\nCopyright (c) 2008      UT-Battelle, LLC\nCopyright (c) 2011-2014 Los Alamos National Security, LLC. All rights\nCopyright (c) 2006-2009 Cisco Systems, Inc.  All rights reserved.\nCopyright (c) 2008-2010 Cisco Systems, Inc.  All rights reserved.\nCopyright (c) 2004-2011 The Trustees of Indiana University and Indiana\nCopyright (c) 2011-2014 NVIDIA Corporation.  All rights reserved.\nCopyright (c) 2007-2016 Cisco Systems, Inc.  All rights reserved.\nCopyright (c) 2007      High Performance Computing Center Stuttgart,\nCopyright (c) 2007-2013 The University of Tennessee and The University of\nCopyright (C) 2000-2004 by Etnus, LLC\nCopyright (C) 1999 by Etnus, Inc.\nCopyright (C) 1997-1998 Dolphin Interconnect Solutions Inc.\nCopyright (C) 2000-2004 by Etnus, LLC.\nCopyright (c) 2008 Cisco Systems, Inc.  All rights reserved\nCopyright (c) 2008-2009 Sun Microystems, Inc.  All rights reserved\nCopyright (c) 2017 IBM Corp.  All rights reserved.\nCopyright (c) 2009      Sun Microsystems, Inc  All rights reserved.\nCopyright (c) 2012-2013 The University of Tennessee and The University\nCopyright (c) 2006      The Trustees of Indiana University and Indiana\nCopyright (c) 2006      The Technical University of Chemnitz. All\nCopyright (c) 2006 The Technical University of Chemnitz. All\nCopyright (c) 2015      The University of Tennessee and The University\nCopyright (c) 2008-2019 Cisco Systems, Inc.  All rights reserved\nCopyright (c) 2014-2015 Cisco Systems, Inc.  All rights reserved.\nCopyright (c) 2008-2013 Cisco Systems, Inc.  All rights reserved.\nCopyright (c) 2008-2013  University of Houston. All rights reserved.\nCopyright (c) 2013-2017 University of Houston. All rights reserved.\nCopyright (c) 2010-2014 Cisco Systems, Inc.  All rights reserved.\nCopyright (c) 2011-2012 IBM Corporation.  All rights reserved.\nCopyright (c) 2011-2017 Los Alamos National Security, LLC.  All rights\nCopyright (c) 2013-2014 Intel, Inc. All rights reserved.\nCopyright (c) 2015-2016 Los Alamos National Security, LLC.  All rights\nCopyright (c) 2015-2016 Cisco Systems, Inc.  All rights reserved.\nCopyright (c) 2004-2007 The Trustees of the University of Tennessee.\n(C)Copyright IBM Corp.  2007, 2008\nCopyright (C) 1997-2001 University of Chicago.\nCopyright (c) 2006-2015 Los Alamos National Security, LLC.  All rights\nCopyright (c) 2009      Oak Ridge National Laboratory\nCopyright (c) 2013-2015 NVIDIA Corporation.  All rights reserved.\nCopyright (c) 2008-2010 Oracle and/or its affiliates.  All rights reserved\nCopyright (c) 2015-2017 Cisco Systems, Inc.  All rights reserved\nCopyright (c) 2015-2016 The University of Tennessee and The University\nCopyright (c) 2010-2016 Cisco Systems, Inc.  All rights reserved.\nCopyright (c) 2013-2015 Intel, Inc.  All rights reserved.\nCopyright (c) 2006      High Performance Computing Center Stuttgart,\nCopyright (c) 2010-2015 Los Alamos National Security, LLC. All rights\nCopyright (c) 2018      Mellanox Technologies, Inc.\nCopyright (c) 2011-2012 University of Houston. All rights reserved.\nCopyright (c) 2010-2013 Los Alamos National Security, LLC.\nCopyright (c) 2007      Cisco Systems, Inc.   All rights reserved.\nCopyright (c) 2014-2016 Intel Corporation.  All rights reserved.\nCopyright (c) 2013-2016 Mellanox Technologies, Inc.\nCopyright © 2012 Inria.  All rights reserved.\nCopyright © 2010-2012, 2014 Université Bordeaux\nCopyright © 2010 Cisco Systems, Inc.  All rights reserved.\nCopyright © 2009 CNRS\nCopyright © 2009-2015 Inria.  All rights reserved.\nCopyright © 2009, 2011 Université Bordeaux\nCopyright © 2011 Cisco Systems, Inc.  All rights reserved.\nCopyright © 2009-2016 Inria.  All rights reserved.\nCopyright © 2009-2012 Université Bordeaux\nCopyright © 2009      CNRS\nCopyright © 2009-2017 Inria.  All rights reserved.\nCopyright © 2009-2011 Cisco Systems, Inc.  All rights reserved.\nCopyright © 2009-2010 Oracle and/or its affiliates.  All rights reserved.\nCopyright (c) 2006-2018 Cisco Systems, Inc.  All rights reserved\nCopyright (c) 2009      University of Houston.  All rights reserved.\nCopyright (c) 2006-2014 Los Alamos National Security, LLC.  All rights\nCopyright (c) 2006-2009 University of Houston. All rights reserved.\nCopyright (c) 2016      Mellanox Technologies Ltd.  All rights reserved.\nCopyright (c) 2006-2017 Los Alamos National Security, LLC.\nCopyright (c) 2011-2017 Oak Ridge National Labs.  All rights reserved.\nCopyright (c) 2018      IBM Corporation.  All rights reserved.\nCopyright (c) 2011-2012 Los Alamos National Security, LLC. All rights\nCopyright (c) 2015 Intel, Inc.  All rights reserved.\nCopyright (c) 2015      Intel, Inc.  All rights reserved.\nCopyright (c) 2014 Mellanox Technologies, Inc.\nCopyright (c) 2017      Cisco Systems, Inc. All rights reserved.\nCopyright (c) 2011-2014 Los Alamos National Security, LLC.  All rights\nCopyright (c) 2004-2015 The Trustees of the University of Tennessee.\nCopyright (c) 2011-2015 The University of Tennessee and The University\nCopyright (c) 2011-2015 INRIA.  All rights reserved.\nCopyright (c) 2011-2015 Bordeaux Polytechnic Institute\nCopyright (c) 2011-2015 Université Bordeaux 1\nCopyright (c) 2011-2017 The University of Tennessee and The University\nCopyright (c) 2011-2016 INRIA.  All rights reserved.\nCopyright (c) 2012-2017 Bordeaux Polytechnic Institute\nCopyright (c) 2015-2019 Mellanox Technologies, Inc.\nCopyright (c) 2015-2017 Mellanox Technologies, Inc.  All rights reserved.\nCopyright (c) 2015      Artem Y. Polyakov <artpol84@gmail.com>.\nCopyright (c) 2015-2017 Mellanox Technologies, Inc.\nCopyright (c) 2017      Mellanox Technologies, Inc.\nCopyright (c) 2007-2011 Oracle and/or its affiliates.  All rights reserved.\nCopyright (c) 2009-2011 Cisco Systems, Inc.  All rights reserved.\nCopyright (c) 2011-2012 Universite Bordeaux 1\nCopyright (c) 2012-2015 Mellanox Technologies, Inc.\nCopyright (c) 2004-2005 The University of Tennbfropsee and The University\nCopyright (c) 2007-2010 Oracle and/or its affiliates.  All rights reserved.\nCopyright (c) 2012      Los Alamos National Security, LLC.  All rights reserved.\nCopyright (c) 1991, 1993\nCopyright (c) 2016-2018 Mellanox Technologies, Inc.\nCopyright (c) 2010      The University of Tennessee and The University\nCopyright (c) 2018      Los Alamos National Security, LLC. All rights\nCopyright (c) 2016-2018 IBM Corporation.  All rights reserved.\nCopyright (c) 2017-2018 Mellanox Technologies, Inc.\nCopyright (c) 2009-2010 The Trustees of Indiana University and Indiana\nCopyright (c) 2004-2008 The Regents of the University of California.\nCopyright (c) 2006-2017 Los Alamos National Security, LLC.  All rights\nCopyright (c) 2006-2017 Cisco Systems, Inc.  All rights reserved.\nCopyright (c) 2006-2010 Voltaire, Inc. All rights reserved.\nCopyright (c) 2006-2017 Sandia National Laboratories. All rights reserved.\nCopyright (c) 2006-2010 Sun Microsystems, Inc.  All rights reserved.\nCopyright (c) 2006-2017 The University of Houston. All rights reserved.\nCopyright (c) 2006-2009 Myricom, Inc.  All rights reserved.\nCopyright (c) 2007-2017 UT-Battelle, LLC. All rights reserved.\nCopyright (c) 2007-2017 IBM Corporation.  All rights reserved.\nCopyright (c) 1998-2005 Forschungszentrum Juelich, Juelich Supercomputing\nCopyright (c) 2005-2008 ZIH, TU Dresden, Federal Republic of Germany\nCopyright (c) 2008      Chelsio, Inc.  All rights reserved.\nCopyright (c) 2008-2009 Institut National de Recherche en\nCopyright (c) 2007      Lawrence Livermore National Security, LLC.\nCopyright (c) 2007-2017 Mellanox Technologies.  All rights reserved.\nCopyright (c) 2006-2010 QLogic Corporation.  All rights reserved.\nCopyright (c) 2008-2017 Oak Ridge National Labs.  All rights reserved.\nCopyright (c) 2006-2012 Oracle and/or its affiliates.  All rights reserved.\nCopyright (c) 2009-2015 Bull SAS.  All rights reserved.\nCopyright (c) 2016      ARM, Inc.  All rights reserved.\nCopyright (c) 2010-2011 Alex Brick <bricka@ccs.neu.edu>.  All rights reserved.\nCopyright (c) 2013-2016 Intel, Inc. All rights reserved.\nCopyright (c) 2011-2017 NVIDIA Corporation.  All rights reserved.\nCopyright (c) 2016      Broadcom Limited.  All rights reserved.\nCopyright (c) 2011-2017 Fujitsu Limited.  All rights reserved.\nCopyright (c) 2014-2015 Hewlett-Packard Development Company, LP.  All\nCopyright (c) 2013-2017 Research Organization for Information Science (RIST).\nCopyright (c) 2004-2007 The Regents of the University of California.\nCopyright (c) 2006-2018 Cisco Systems, Inc.  All rights reserved.\nCopyright (c) 2006-2011 Mellanox Technologies. All rights reserved.\nCopyright (c) 2007      Myricom, Inc.  All rights reserved.\nCopyright (c) 2008-2017 IBM Corporation.  All rights reserved.\nCopyright (c) 2010      Oak Ridge National Labs.  All rights reserved.\nCopyright (c) 2011      University of Houston. All rights reserved.\nCopyright (c) 2017-2018 Los Alamos National Security, LLC.  All rights\nCopyright (c) 2013-2017 Intel, Inc. All rights reserved\nCopyright (c) 2013-2015 Intel, Inc. All rights reserved\nCopyright (c) 2013-2016 Intel, Inc. All rights reserved\nCopyright (c) 2012-2017 Los Alamos National Security, LLC.\nCopyright (C) 2018      Mellanox Technologies, Ltd.\nCopyright (c) 2018      Amazon.com, Inc. or its affiliates.  All Rights reserved.\nCopyright (c) 2019 IBM Corporation. All rights reserved.\nCopyright (c) 2012-2015 Los Alamos National Security, LLC.  All rights reserved.\nCopyright (c) 2014-2015 Artem Y. Polyakov <artpol84@gmail.com>.\nCopyright (c) 2010      Oak Ridge National Laboratory.\nCopyright (c) 2010-2017 Cisco Systems, Inc.  All rights reserved\nCopyright (c) 2019      IBM Corporation.  All rights reserved.\nCopyright (c) 2011-2013 UT-Battelle, LLC. All rights reserved.\nCopyright (c) 2008-2018 University of Houston. All rights reserved.\nCopyright (c) 2007      Lawrence Livermore National Security, LLC.  All\nCopyright (c) 2016      ARM, Inc. All rights reserved.\nCopyright (C) 2008 University of Chicago.\nCopyright (c) 2015       Cisco Systems, Inc.  All rights reserved.\nCopyright (c) 2015       Los Alamos National Security, Inc.  All rights\nCopyright (c) 2008-2009 University of Houston. All rights reserved.\nCopyright 2003\nCopyright (c) 2012-2014 The University of Tennessee and The University\nCopyright (c) 2009      Sun Microsystmes, Inc.  All rights reserved.\nCopyright (c) 2013      Los Alamos National Security, LLC.  All rights\nCopyright (C) Mellanox Technologies Ltd. 2001-2017. ALL RIGHTS RESERVED.\nCopyright (c) 2011-2013 Sandia National Laboratories.  All rights reserved.\nCopyright (c) 2017 IBM Corporation.  All rights reserved.\nCopyright (c) 2008-2018 Cisco Systems, Inc.  All rights reserved\nCopyright 2003-2007 Niels Provos <provos@citi.umich.edu>\nCopyright 2007-2012 Niels Provos and Nick Mathewson\nCopyright 2008-2012 Niels Provos and Nick Mathewson\nCopyright 2009-2012 Niels Provos and Nick Mathewson\nCopyright (c) 2003-2007 Niels Provos <provos@citi.umich.edu>\nCopyright (c) 2010-2012 Niels Provos and Nick Mathewson\nCopyright (c) 2009-2012 Nick Mathewson and Niels Provos\nCopyright (c) 2002-2007 Niels Provos <provos@citi.umich.edu>\ntinytest.c -- Copyright 2009-2012 Nick Mathewson\ntinytest.h -- Copyright 2009-2012 Nick Mathewson\ntinytestmacros.h -- Copyright 2009-2012 Nick Mathewson\nCopyright (c) 2008-2019 University of Houston. All rights reserved.\nCopyright (c) 2010-2016 Los Alamos National Security, LLC.\nCopyright (c) 2006-2011 Cisco Systems, Inc.  All rights reserved.\nCopyright (C) 2013 University of Chicago.\nCopyright (c) 2013-2014 Mellanox Technologies, Inc.\nCopyright (c) 2004-2005 The University of Tennptlee and The University\nCopyright (c) 2017-2018 Research Organization for Information Science\nCopyright (c) 2019      Mellanox Technologies, Inc. All rights reserved.\nCopyright (c) 2015-2017 Mellanox Technologies. All rights reserved.\nCopyright (c) 2008-2017 Cisco Systems, Inc.  All rights reserved\nCopyright (c) 2007      Sun Microsystems, Inc.  All rights reserved.\nCopyright (c) 2015      Cisco Systems, Inc.\n(C) 2004 by Argonne National Laboratory.\nCopyright (c) 2011-2013 Los Alamos National Security, LLC. All\nCopyright (C) 2001-2004 Farooq Mela.\nCopyright (C) 2001 Farooq Mela.\nCopyright (c)      2011 The Trustees of Indiana University.\nCopyright (c) 2016      Inria.  All rights reserved.\nCopyright (c) 2016-2018 Inria. All rights reserved.\nCopyright (c) 2016-2017 Inria.  All rights reserved.\nCopyright (c) 2004-201 The University of Tennessee and The University\nCopyright (c) 2010-201 Oak Ridge National Labs.  All rights reserved.\nCopyright (c) 201-2014 Cisco Systems, Inc.  All rights reserved.\nCopyright (c) 201-2013 Los Alamos National Security, LLC.  All rights\nCopyright (c) 2006-2008 Sun Microsystems, Inc.  All rights reserved.\nCopyright (c) 2013      FUJITSU LIMITED.  All rights reserved.\nCopyright (c) 2009 Cisco Systems, Inc. All rights reserved.\nCopyright (c) 2009     Cisco Systems, Inc. All rights reserved.\nCopyright (c) 2009      Cisco Systems, Inc. All rights reserved.\nCopyright (c) 2006-2007 The Trustees of Indiana University and Indiana\nCopyright (c) 2017      Intel, Inc. All rights reserved\nCopyright (c) 2009-2013 The University of Tennessee and The University\nCopyright (c) 2015-2019 Research Organization for Information Science\nCopyright (c) 2019      IBM Corporation. All rights reserved.\nCopyright (c) 2009-2017 The University of Tennessee and The University\nCopyright (c) 2016      FUJITSU LIMITED.  All rights reserved.\nCopyright (c) 2016      Los Alamos National Security, LLC. ALl rights\nCopyright (c) 2014-2015 Intel, Inc. All rights reserved\nCopyright (c) 2007-2009 Sun Microsystems, Inc. All rights reserved.\nCopyright (c) 2012-2015 Los Alamos National Security, Inc.  All rights reserved.\nCopyright (c) 2007      Cisco Systems, Inc. All rights reserved.\nCopyright (c) 2017 Inria.  All rights reserved.\nCopyright (c) 2013-2017 The University of Tennessee and The University\nCopyright (c) 2013-2016 Inria.  All rights reserved.\nCopyright (c) 2017-2018 Los Alamos National Security, LLC. All rights\nCopyright (c) 2016 Broadcom Limited. All rights reserved.\nCopyright (c) 2006-2015 Mellanox Technologies. All rights reserved.\nCopyright (c) 2006-2016 Los Alamos National Security, LLC.  All rights\nCopyright (c) 2006-2007 Voltaire All rights reserved.\nCopyright (c) 2008-2012 Oracle and/or its affiliates.  All rights reserved.\nCopyright (c) 2014      Bull SAS.  All rights reserved\nCopyright (c) 2006-2009 Mellanox Technologies. All rights reserved.\nCopyright (c) 2013-2014 NVIDIA Corporation.  All rights reserved.\nCopyright (c) 2007-2008 Mellanox Technologies. All rights reserved.\nCopyright (c) 2011-2015 NVIDIA Corporation.  All rights reserved.\nCopyright (c) 2012      Oak Ridge National Laboratory.  All rights reserved\nCopyright (c) 2006-2009 Mellanox Technologies, Inc.  All rights reserved.\nCopyright (c) 2010-2011 IBM Corporation.  All rights reserved.\nCopyright (c) 2010-2011 Oracle and/or its affiliates.  All rights reserved\nCopyright (c) 2007-2009 Mellanox Technologies.  All rights reserved.\nCopyright (c) 2008      Chelsio, Inc. All rights reserved.\nCopyright (c) 2017      Los Alamos National Security, LLC.  All rights\nCopyright (c) 2007-2009 Mellanox Technologies. All rights reserved.\nCopyright (c) 2010      University of Houston.  All rights reserved.\nCopyright (c) 2012      Los Alamos Nat Security, LLC. All rights reserved.\nCopyright (c) 2008      University of Houston, Inc.  All rights reserved.\nCopyright (c) 2008      University of Houston.  All rights reserved.\nCopyright (c) 2006-2008 Cisco Systems, Inc.  All rights reserved.\nCopyright (c) 2008      The Trustees of Indiana University and Indiana\nCopyright (c) 2013-2014 Los Alamos National Security, LLC.  All rights\nCopyright (c) 2015      University of Houston.  All rights reserved.\nCopyright (c) 2009      University of Houston. All rights reserved.\nCopyright (c) 2012-2013 Los Alamos Nat Security, LLC. All rights reserved.\nCopyright (c) 2012      Oak Ridge National Laboratory. All rights reserved.\nCopyright (c)      2012 Oak Rigde National Laboratory. All rights reserved.\nCopyright (c) 2007-2018 Cisco Systems, Inc.  All rights reserved\nCopyright (c) 2006-2009 University of Houston.  All rights reserved.\nCopyright (c) 2016      Los Alamos National Security, LLC.  All rights\nCopyright (c) 2012      Oak Ridge National Labs. All rights reserved.\nCopyright (c) 2012-2013 Cisco Systems, Inc.  All rights reserved.\nCopyright (c) 2006-2010 Cisco Systems, Inc.  All rights reserved.\nCopyright (c) 2014-2015 Los Alamos National Security, LLC. ALl rights\nCopyright (c) 2014-2015 Los Alamos National Security, LLC. All right\nCopyright (c) 2006-2009 Sun Microsystems, Inc.  All rights reserved.\nCopyright (c) 2012-2013 Sandia National Laboratories. All rights reserved.\nCopyright (C) 2007 University of Chicago.\nCopyright (c) 2006      Sun Microsystems Inc. All rights reserved.\nCopyright (c) 2019      The University of Tennessee and The University\nCopyright (c) 2009-2014 The University of Tennessee and The University\nCopyright (c) 2009-2010 The Trustees of Indiana University.\nCopyright (c) 2014      Intel Corporation.  All rights reserved.\nCopyright (c) 2008      Sun Microsystems, Inc.  All rights reserved.\nCopyright (c) 2010-2016 Los Alamos National Security, LLC. All rights\nCopyright (c) 2007-2009 Sun Microsystems, Inc.  All rights reserved.\nCopyright (c) 2013      Mellanox Technologies, Inc.  All rights reserved.\nCopyright (c) 2007-2017 Cisco Systems, Inc.  All rights reserved.\nCopyright (c) 2009      Institut National de Recherche en Informatique\nCopyright (c) 2018-2019 Research Organization for Information Science\nCopyright (c) 2016-2017 Mellanox Technologies, Inc.\nCopyright (c) 2008-2013 Los Alamos National Security, LLC.\nCopyright (c) 2010      Los Alamos National Security, LLC.\nCopyright (c) 2006      Sandia National Laboratories. All rights\nCopyright (c) 2013-2017 Cisco Systems, Inc.  All rights reserved.\nCopyright (c) 2014-2016 Cisco Systems, Inc.  All rights reserved.\nCopyright (c) 2013-2016 Cisco Systems, Inc.  All rights reserved.\nCopyright (c) 2008-2017 Cisco Systems, Inc.  All rights reserved.\nCopyright (c) 2012-2014 Los Alamos National Security, LLC.  All rights\nCopyright (c) 2007      The Regents of the University of California.\nCopyright (c) 2013-2015 Cisco Systems, Inc.  All rights reserved.\nCopyright (c) 2008-2016 Cisco Systems, Inc.  All rights reserved.\nCopyright (c) 2009-2017 Cisco Systems, Inc.  All rights reserved.\nCopyright (c) 2011-2017 Cisco Systems, Inc.  All rights reserved.\nCopyright (c) 2013-2017 Cisco Systems, Inc.  All rights reserved\nCopyright (c) 2014      Los Alamos National Security, LLC. All right\nCopyright (c) 2017      IBM Corp.  All rights reserved.\nCopyright (c) 2008 The Trustees of Indiana University and Indiana\nCopyright (c) 2012-2015 Inria.  All rights reserved.\nCopyright (c) 2015 Cisco Systems, Inc.\nCopyright (c) 2017      ARM, Inc. All rights reserved.\nCopyright (C) 2007 Oak Ridge National Laboratory\nCopyright (C) 2008 Sun Microsystems, Lustre group\nCopyright © 2004-2006 The Trustees of Indiana University and Indiana University Research and Technology Corporation.  All rights reserved.\nCopyright © 2004-2005 The University of Tennessee and The University of Tennessee Research Foundation.  All rights reserved.\nCopyright © 2004-2005 High Performance Computing Center Stuttgart, University of Stuttgart.  All rights reserved.\nCopyright © 2004-2005 The Regents of the University of California. All rights reserved.\nCopyright © 2009-2015 Université Bordeaux\nCopyright © 2009-2015 Cisco Systems, Inc.  All rights reserved.\nCopyright © 2009-2012 Oracle and/or its affiliates.  All rights reserved.\nCopyright © 2010      IBM\nCopyright © 2010      Jirka Hladky\nCopyright © 2012      Aleksej Saushev, The NetBSD Foundation\nCopyright © 2012      Blue Brain Project, EPFL. All rights reserved.\nCopyright © 2015      Research Organization for Information Science and Technology (RIST). All rights reserved.\nCopyright © 2015-2016 Intel, Inc.  All rights reserved.\nCopyright (c) 2010-2012 Sandia National Laboratories.  All rights reserved.\nCopyright (c) 2010      Sandia National Laboratories.  All rights reserved.\nCopyright (c) 2007      Sun Microsystems, Inc. All rights reserved.\nCopyright (c) 1996 by Internet Software Consortium.\nCopyright (c) 1995 by International Business Machines, Inc.\nCopyright © 2009-2010, 2012 Université Bordeaux\nCopyright © 2011-2015 Cisco Systems, Inc.  All rights reserved.\nCopyright © 2009-2011 Université Bordeaux\nCopyright © 2012 Université Bordeaux\nCopyright © 2013-2014 Inria.  All rights reserved.\nCopyright © 2010-2016 Inria.  All rights reserved.\nCopyright © 2011-2012 Université Bordeaux\nCopyright © 2009 inria.  All rights reserved.\nCopyright © 2009, 2012 Université Bordeaux\nCopyright © 2009-2014 Inria.  All rights reserved.\nCopyright © 2009-2010 Université Bordeaux\nCopyright © 2009-2011, 2013 Université Bordeaux\nCopyright © 2013-2017 Inria.  All rights reserved.\nCopyright © 2011 Université Bordeaux\nCopyright © 2012-2014 Inria.  All rights reserved.\nCopyright © 2011-2014 Inria.  All rights reserved.\nCopyright © 2009-2013 Université Bordeaux\nCopyright © 2012-2013 Blue Brain Project, BBP/EPFL. All rights reserved.\nCopyright © 2015-2016 Inria.  All rights reserved.\nCopyright © 2009-2010, 2013 Université Bordeaux\nCopyright © 2009-2013, 2015 Université Bordeaux\nCopyright © 2015 Intel, Inc.  All rights reserved.\nCopyright © 2010 IBM\nCopyright © 2012 Aleksej Saushev, The NetBSD Foundation\nCopyright © 2013 Université Bordeaux.  All right reserved.\nCopyright © 2014 Cisco Systems, Inc.  All rights reserved.\nCopyright © 2015      Research Organization for Information Science\nCopyright © 2013 Université Bordeaux.  All rights reserved.\nCopyright © 2016 Inria.  All rights reserved.\nCopyright © 2011      Oracle and/or its affiliates.  All rights reserved.\nCopyright © 2010-2017 Inria.  All rights reserved.\nCopyright © 2010-2013 Université Bordeaux\nCopyright © 2010-2011 Cisco Systems, Inc.  All rights reserved.\nCopyright (c) 2013      Los Alamos National Security, LLC. All Rights\nCopyright (c) 2013-2017 Los Alamos National Security, LLC. All Rights\nCopyright (c) 2013-2016 Los Alamos National Security, LLC. All Rights\nCopyright (c) 2012      Oak Ridge National Laboratory.  All rights reserved.\nCopyright (c) 2012      Oak Rigde National Laboratory.\nCopyright (c) 2007-2017 Los Alamos National Security, LLC.  All rights\nCopyright (c) 2016-2018 Research Organization for Information Science\nCopyright (c) 2012-2013 NVIDIA Corporation.  All rights reserved.\nCopyright (c) 2018      Triad National Security, LLC. All rights\nCopyright (c) 2009-2018 Cisco Systems, Inc.  All rights reserved.\nCopyright (C) 2005 University of Chicago.\nCopyright (C) 2002 University of Chicago.\nCopyright (C) 2007 UChicago/Argonne LLC\nCopyright (C) 2013 UChicago/Argonne, LLC\nCopyright (C) 2007 UChicago/Argonne LLC.\nCopyright (C) 2014 UChicgo/Argonne, LLC.\nCOPYRIGHT\n(C) 2007 by Argonne National Laboratory.\nCopyright (c) 2011      FUJITSU LIMITED.  All rights reserved.\nCopyright (c) 2016-2017 Los Alamos National Security, LLC.  All rights\nCopyright (c) 2006-2007 Sun Microsystems, Inc.  All rights reserved.\nCopyright (c) 2012-2014 Los Alamos National Security, LLC.\nCopyright 2010 IPB, INRIA & CNRS\nCopyright (C) 1997--2004, Makoto Matsumoto, Takuji Nishimura, and\nEric Landry; All rights reserved.\nCopyright (c) 2003-2011, Troy D. Hanson     http:uthash.sourceforge.net\nCopyright (c) 2011-2018 Los Alamos National Security, LLC.  All rights\nCopyright (c) 2017      Rutgers, The State University of New Jersey.\nCopyright (c) 2015      Los Alamos National Security, LLC. All rights reserved.\nCopyright (c) 2006-2007 Voltaire. All rights reserved.\nCopyright (c) 2013-2017 Research Organization for Information Science\nCopyright (c) 2017-2019 Research Organization for Information Science\nCopyright (c) 2004-2019 The University of Tennessee and The University\nCopyright (c) 2004-2017 High Performance Computing Center Stuttgart,\nCopyright (c) 2008-2009 Oak Ridge National Labs.  All rights reserved.\nCopyright (c) 2015      NVIDIA, Inc.  All rights reserved.\nCopyright (c) 2010-2017 Los Alamos National Security, LLC. All rights\nCopyright (c) 2010-2012 IBM Corporation.  All rights reserved.\nCopyright (c) 2012-2014 NVIDIA Corporation.  All rights reserved.\nCopyright (c) 2014-2016 The University of Tennessee and The University\nCopyright (C) 2001-2011 Mellanox Technologies Ltd. ALL RIGHTS RESERVED.\nCopyright (c) 2011-2015 NVIDIA.  All rights reserved.\nCopyright (c) 2016-2018 Inria.  All rights reserved.\nCopyright (c) 2016 Inria.  All rights reserved.\nCopyright (c) 2017      Inria.  All rights reserved.\nCopyright (c) 2006-2010 Oracle and/or its affiliates.  All rights reserved.\nCopyright (c) 2012-2013 Los Alamos National Security, Inc. All rights\nCopyright © 2010-2011 Université Bordeaux\nCopyright © 2009-2010 Cisco Systems, Inc.  All rights reserved.\nCopyright © 2013-2016 Inria.  All rights reserved.\nCopyright © 2012 Blue Brain Project, EPFL. All rights reserved.\nCopyright © 2012-2013 Inria.  All rights reserved.\nCopyright © 2009-2013 inria.  All rights reserved.\nCopyright © 2009-2013 Inria.  All rights reserved.\nCopyright © 2010-2014 Inria.  All rights reserved.\nCopyright © 2012-2016 Inria.  All rights reserved.\nCopyright © 2013-2015 Inria.  All rights reserved.\nCopyright (c) 2006-2015 Los Alamos National Security, LLC.\nCopyright (c) 2010-2015 Sandia National Laboratories.  All rights reserved.\nCopyright (c) 2011-2017 Los Alamos National Security, LLC.\nCopyright (C) 1997 University of Chicago\nCopyright (c) 2006-2010 Oracle and/or its affiliates.  All rights reserved\nCopyright (c) 2011-2016 Los Alamos National Security, LLC. All\nCopyright (c) 2013-2015 Los Alamos National Security, LLC.  All rights reserved.\nCopyright (c) 2013-2015 Bull SAS.  All rights reserved.\nCopyright (c) 2013-2015 Inria.  All rights reserved.\nCopyright (c) 2015      Los Alamos National Security, Inc.  All rights\n(c) 2008-2013 Nathan Hjelm <hjelmn@cs.unm.edu>\n(C) 2013 UChicago/Argonne LLC\n(C) 2011 by Argonne National Laboratory.\nUniversity of Stuttgart. All rights reserved.\nCopyright (c) 2010-2017 The University of Tennessee and The University\nCopyright (c) 2014-2015 NVIDIA Corporation.  All rights reserved.\nCopyright (c) 2010      High Performance Computing Center Stuttgart,\nCopyright (c) 2011-2017 Sandia National Laboratories.  All rights reserved.\nCopyright (C) 2006 University of Chicago.\nCopyright (C) 2006 Unknown (TODO: fix this)\nCopyright (c) 2007-2013 Los Alamos National Security, LLC.\nCopyright (c) 2004-2008 The Trustees of the University of Tennessee.\nCopyright (c) 2010-2011, Siberian State University of Telecommunications\nCopyright (c) 2010-2011, A.V. Rzhanov Institute of Semiconductor Physics SB RAS.\nCopyright (C) 2011 Mikhail Kurnosov <mkurnosov@gmail.com>\nCopyright (c) 2004-2013 The Trustees of the University of Tennessee.\nCopyright (c) 2004-2014 The Trustees of the University of Tennessee.\nCopyright (c) 2006-2010 Los Alamos National Security, LLC.  All rights\nCopyright (c) 2006-2011 Sandia National Laboratories. All rights reserved.\nCopyright (c) 2006-2010 The University of Houston. All rights reserved.\nCopyright (c) 2007-2008 UT-Battelle, LLC. All rights reserved.\nCopyright (c) 2007-2019 IBM Corporation.  All rights reserved.\nCopyright (c) 2007-2019 Mellanox Technologies.  All rights reserved.\nCopyright (c) 2008-2010 Oak Ridge National Labs.  All rights reserved.\nCopyright (c) 2009      Bull SAS.  All rights reserved.\nCopyright (c) 2013-2019 Intel, Inc. All rights reserved.\nCopyright (c) 2019      Amazon.com, Inc. or its affiliates.  All Rights\nCopyright (c) 2008      IBM Corporation.  All rights reserved.\nCopyright (c) 2015      University of Houston. All rights reserved.\nCopyright (c) 2015     Cisco Systems, Inc.  All rights reserved.\nCopyright (c) 2016     Intel, Inc. All rights reserved.\nCopyright (c) 2006-2012 Mellanox Technologies.  All rights reserved.\nCopyright (c) 2010-2017 Los Alamos National Security, LLC.\nCopyright (c) 2011-2018 Los Alamos National Security, LLC. All rights\nCopyright (c) 2010-2018 Los Alamos National Security, LLC.\nCopyright (c) 2010-2014 Los Alamos National Security, LLC. All rights\nCopyright (c) 2010 Chris Davis, Niels Provos, and Nick Mathewson\nCopyright (c) 1996, David Mazieres <dm@uun.org>\nCopyright (c) 2008, Damien Miller <djm@openbsd.org>\nCopyright (c) 2002-2006 Niels Provos <provos@citi.umich.edu>\nCopyright (c) 2009-2012 Niels Provos, Nick Mathewson\nCopyright 2000-2009 Niels Provos <provos@citi.umich.edu>\nCopyright 2000-2007 Niels Provos <provos@citi.umich.edu>\nCopyright 2007-2012 Niels Provos, Nick Mathewson\nCopyright 2003-2009 Niels Provos <provos@citi.umich.edu>\nCopyright 2006-2007 Niels Provos\nCopyright 2007-2012 Nick Mathewson and Niels Provos\nCopyright (c) 2005-2007 Niels Provos <provos@citi.umich.edu>\nCopyright (c) 2003-2009 Niels Provos <provos@citi.umich.edu>\nCopyright (c) 2007 Sun Microsystems. All rights reserved.\nCopyright (c) 2008-2012 Niels Provos, Nick Mathewson\nBased on work Copyright 2002 Christopher Clark\nCopyright 2005-2012 Nick Mathewson\nCopyright 2001-2007 Niels Provos <provos@citi.umich.edu>\nCopyright (c) 2000 Dug Song <dugsong@monkey.org>\nCopyright (c) 1993 The Regents of the University of California.\nCopyright (c) 1998 Todd C. Miller <Todd.Miller@courtesan.com>\nCopyright (c) 2003 Michael A. Davis <mike@datanerds.net>\nCopyright (c) 2007 Sun Microsystems\nCopyright (c) 2002 Christopher Clark\nCopyright (c) 2006 Maxim Yegorushkin <maxim.yegorushkin@gmail.com>\nCopyright (c) 2005-2012 Niels Provos and Nick Mathewson\nCopyright (c) 1993\nCopyright (c) 2012      UT-Battelle, LLC. All rights reserved.\nCopyright 2003 Michael A. Davis <mike@datanerds.net>\nCopyright (c) 2010-2011 Oracle and/or its affiliates.  All rights reserved.\nCopyright (c) 2004-2012 The Trustees of Indiana University.\nCopyright (c) 2017      Los Alamos National Security, LLC. All\nCopyright (c) 2016 Los Alamos National Security, LLC. All rights\nCopyright (c) 2010-2016 IBM Corporation.  All rights reserved.\nCopyright (c) 2009-2011 Oracle and/or its affiliates.  All rights reserved.\n\nSoftware: re2 20191201\nCopyright notice:\nCopyright (C) 2005 Free Software Foundation, Inc.\nCopyright (C) 2007 Free Software Foundation, Inc.\nCopyright (C) 2009 Free Software Foundation, Inc.\nCopyright (C) 2009 The Android Open Source Project\nCopyright (c) 2002 by Lucent Technologies.\nCopyright (c) 2009 The RE2 Authors.\nCopyright 1999-2005 The RE2 Authors.  All Rights Reserved.\nCopyright 2001-2010 The RE2 Authors.  All Rights Reserved.\nCopyright 2002-2009 The RE2 Authors.  All Rights Reserved.\nCopyright 2003-2009 Google Inc.\nCopyright 2003-2009 The RE2 Authors.  All Rights Reserved.\nCopyright 2003-2010 Google Inc.  All Rights Reserved.\nCopyright 2004 The RE2 Authors.  All Rights Reserved.\nCopyright 2005 The RE2 Authors.  All Rights Reserved.\nCopyright 2006 The RE2 Authors.  All Rights Reserved.\nCopyright 2006-2007 The RE2 Authors.  All Rights Reserved.\nCopyright 2006-2008 The RE2 Authors.  All Rights Reserved.\nCopyright 2007 The RE2 Authors.  All Rights Reserved.\nCopyright 2008 The RE2 Authors.  All Rights Reserved.\nCopyright 2009 The RE2 Authors.  All Rights Reserved.\nCopyright 2010 The RE2 Authors.  All Rights Reserved.\nCopyright 2012 The Go Authors.\nCopyright 2015 The RE2 Authors.  All Rights Reserved.\nCopyright 2016 The RE2 Authors.  All Rights Reserved.\nCopyright 2018 The RE2 Authors.  All Rights Reserved.\n\nLicense: BSD-3 with additional clause \nMost files in this release are marked with the copyrights of the\norganizations who have edited them.  The copyrights below are in no\nparticular order and generally reflect members of the Open MPI core\nteam who have contributed code to this release.  The copyrights for\ncode used under license from other parties are included in the\ncorresponding files.\n\nCopyright (c) 2004-2010 The Trustees of Indiana University and Indiana\n                        University Research and Technology\n                        Corporation.  All rights reserved.\nCopyright (c) 2004-2017 The University of Tennessee and The University\n                        of Tennessee Research Foundation.  All rights\n                        reserved.\nCopyright (c) 2004-2010 High Performance Computing Center Stuttgart,\n                        University of Stuttgart.  All rights reserved.\nCopyright (c) 2004-2008 The Regents of the University of California.\n                        All rights reserved.\nCopyright (c) 2006-2017 Los Alamos National Security, LLC.  All rights\n                        reserved.\nCopyright (c) 2006-2017 Cisco Systems, Inc.  All rights reserved.\nCopyright (c) 2006-2010 Voltaire, Inc. All rights reserved.\nCopyright (c) 2006-2017 Sandia National Laboratories. All rights reserved.\nCopyright (c) 2006-2010 Sun Microsystems, Inc.  All rights reserved.\n                        Use is subject to license terms.\nCopyright (c) 2006-2017 The University of Houston. All rights reserved.\nCopyright (c) 2006-2009 Myricom, Inc.  All rights reserved.\nCopyright (c) 2007-2017 UT-Battelle, LLC. All rights reserved.\nCopyright (c) 2007-2017 IBM Corporation.  All rights reserved.\nCopyright (c) 1998-2005 Forschungszentrum Juelich, Juelich Supercomputing\n                        Centre, Federal Republic of Germany\nCopyright (c) 2005-2008 ZIH, TU Dresden, Federal Republic of Germany\nCopyright (c) 2007      Evergrid, Inc. All rights reserved.\nCopyright (c) 2008      Chelsio, Inc.  All rights reserved.\nCopyright (c) 2008-2009 Institut National de Recherche en\n                        Informatique.  All rights reserved.\nCopyright (c) 2007      Lawrence Livermore National Security, LLC.\n                        All rights reserved.\nCopyright (c) 2007-2017 Mellanox Technologies.  All rights reserved.\nCopyright (c) 2006-2010 QLogic Corporation.  All rights reserved.\nCopyright (c) 2008-2017 Oak Ridge National Labs.  All rights reserved.\nCopyright (c) 2006-2012 Oracle and/or its affiliates.  All rights reserved.\nCopyright (c) 2009-2015 Bull SAS.  All rights reserved.\nCopyright (c) 2010      ARM ltd.  All rights reserved.\nCopyright (c) 2016      ARM, Inc.  All rights reserved.\nCopyright (c) 2010-2011 Alex Brick <bricka@ccs.neu.edu>.  All rights reserved.\nCopyright (c) 2012      The University of Wisconsin-La Crosse. All rights\n                        reserved.\nCopyright (c) 2013-2016 Intel, Inc. All rights reserved.\nCopyright (c) 2011-2017 NVIDIA Corporation.  All rights reserved.\nCopyright (c) 2016      Broadcom Limited.  All rights reserved.\nCopyright (c) 2011-2017 Fujitsu Limited.  All rights reserved.\nCopyright (c) 2014-2015 Hewlett-Packard Development Company, LP.  All\n                        rights reserved.\nCopyright (c) 2013-2017 Research Organization for Information Science (RIST).\n                        All rights reserved.\nCopyright (c) 2017      Amazon.com, Inc. or its affiliates.  All Rights\n                        reserved.\n\n$COPYRIGHT$\n\nAdditional copyrights may follow\n\n$HEADER$\n\nRedistribution and use in source and binary forms, with or without\nmodification, are permitted provided that the following conditions are\nmet:\n\n- Redistributions of source code must retain the above copyright\n  notice, this list of conditions and the following disclaimer.\n\n- Redistributions in binary form must reproduce the above copyright\n  notice, this list of conditions and the following disclaimer listed\n  in this license in the documentation and/or other materials\n  provided with the distribution.\n\n- Neither the name of the copyright holders nor the names of its\n  contributors may be used to endorse or promote products derived from\n  this software without specific prior written permission.\n\nThe copyright holders provide no reassurances that the source code\nprovided does not infringe any patent, copyright, or any other\nintellectual property rights of third parties.  The copyright holders\ndisclaim any liability to any recipient for claims brought against\nrecipient by any third party for infringement of that parties\nintellectual property rights.\n\nTHIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS\n\"AS IS\" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT\nLIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR\nA PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT\nOWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,\nSPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT\nLIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,\nDATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY\nTHEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT\n(INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE\nOF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n\nSoftware: pip 20.0.2\nCopyright notice: \nCopyright (c) 2010 ActiveState Software Inc.\nCopyright (c) 1991-2014 Unicode, Inc. All rights reserved.\nCopyright (C) 2013 Vinay Sajip.\nCopyright (C) 2013-2015 Vinay Sajip.\nCopyright 2012 Facebook\nCopyright (c) 2017 Thomas Kluyver\nCopyright (c) 2008-2019 Andrey Petrov and contributors (see CONTRIBUTORS.txt)\nCopyright (c) 2001-2014 Python Software Foundation; All Rights Reserved\nCopyright (C) 2012-2015 Vinay Sajip.\nCopyright (C) 1991, 1999 Free Software Foundation, Inc.\nCopyright (c) 2010-2020 Benjamin Peterson\nCopyright (c) 2010-2019 Benjamin Peterson\nCopyright (C) 2016 Jason R Coombs <jaraco@jaraco.com>\nCopyright (C) 2012 The Python Software Foundation.\ni.e., \"Copyright (c) 2001, 2002, 2003, 2004, 2005, 2006, 2007, 2008, 2009, 2010, 2011, 2012, 2013, 2014 Python Software Foundation; All Rights Reserved\" are retained in Python alone or in any derivative version prepared by Licensee.\nCopyright (c) 2005-2010 ActiveState Software Inc.\nCopyright (c) 2006-2013 James Graham and other contributors\nCopyright (c) 2013 Eddy Petrișor\nCopyright 2015 Eric Larson\nCopyright (c) 2013-2018, Kim Davies. All rights reserved.\nCopyright (C) 2002 Lars Gustaebel <lars@gustaebel.de>\nCopyright (C) 2008-2011 INADA Naoki <songofacandy@gmail.com>\nCopyright (c) 2008-2016 The pip developers (see AUTHORS.txt file)\nCopyright 2018 Kenneth Reitz\ncopyright = '2008-2017, PyPA'\nCopyright (c) Donald Stufft and individual contributors.\nCopyright (C) 2012-2019 Vinay Sajip.\nCopyright 2015,2016,2017 Nir Cohen\nCopyright (c) 2008-2019 The pip developers (see AUTHORS.txt file)\nCopyright (C) 2013-2017 Vinay Sajip.\nCopyright 2007 Google Inc.\nLicense Agreement and CNRI's notice of copyright, i.e., \"Copyright (c) 1995-2001 Corporation for National Research Initiatives; All Rights Reserved\" are retained in Python 1.6.1 alone or in any derivative version prepared by Licensee.  Alternately, in lieu of CNRI's License Agreement, Licensee may substitute the following text (omitting the quotes): \"Python 1.6.1 is made available subject to the terms and conditions in CNRI's License Agreement.  This Agreement together with Python 1.6.1 may be located on the Internet using the following unique, persistent identifier (known as a handle): 1895.22/1013.  This Agreement may also be obtained from a proxy server on the Internet\ncopyright = \"Copyright 2014-2019 %s\" % author\nCopyright (c) 2015-2016 Will Bond <will@wbond.net>\nCopyright (c) 1991 - 1995, Stichting Mathematisch Centrum Amsterdam, The Netherlands.  All rights reserved.\nCopyright (c) 2010 Jonathan Hartley All rights reserved.\ni.e., \"Copyright (c) 2001, 2002, 2003, 2004, 2005, 2006, 2007, 2008, 2009, 2010, 2011 Python Software Foundation; All Rights Reserved\" are retained in Python alone or in any derivative version prepared by Licensee.\nCopyright (C) 2012-2013 Python Software Foundation.\nCopyright 2013-2014 Ray Holder\nCopyright (C) 2012-2017 Vinay Sajip.\ncopyright = 'Copyright 2019 Kenneth Reitz'\nCopyright (c) 2012 by Simon Sapin.\ni.e., \"Copyright (c) 2001, 2002, 2003, 2004, 2005, 2006, 2007, 2008, 2009, 2010 Python Software Foundation; All Rights Reserved\" are retained in Python alone or in any derivative version prepared by Licensee.\nCopyright (c) 2003-2019  Paul T. McGuire\nCopyright (c) 2012 Giorgos Verigakis <verigak@gmail.com>\nCopyright (C) 2012-2017 The Python Software Foundation.\n\nLicense: \nCopyright (c) 2008-2019 The pip developers (see AUTHORS.txt file)\n\nPermission is hereby granted, free of charge, to any person obtaining\na copy of this software and associated documentation files (the\n\"Software\"), to deal in the Software without restriction, including\nwithout limitation the rights to use, copy, modify, merge, publish,\ndistribute, sublicense, and/or sell copies of the Software, and to\npermit persons to whom the Software is furnished to do so, subject to\nthe following conditions:\n\nThe above copyright notice and this permission notice shall be\nincluded in all copies or substantial portions of the Software.\n\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND,\nEXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF\nMERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND\nNONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE\nLIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION\nOF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION\nWITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.\n\nSoftware: pytest 1.6.0\nCopyright notice: \ncopyright = \"2015–2020, holger krekel and pytest-dev team\"\nIf true, \"(C) Copyright ...\" is shown in the HTML footer. Default is True.\nCopyright (c) 2010 by Armin Ronacher.\nCopyright (c) 2004-2020 Holger Krekel and others\nCopyright Holger Krekel and others, 2004-2020.\nepubcopyright = \"2013-2020, holger krekel et alii\"\n\nLicense: The MIT License (MIT)\n\nCopyright (c) 2004-2020 Holger Krekel and others\n\nPermission is hereby granted, free of charge, to any person obtaining a copy of\nthis software and associated documentation files (the \"Software\"), to deal in\nthe Software without restriction, including without limitation the rights to\nuse, copy, modify, merge, publish, distribute, sublicense, and/or sell copies\nof the Software, and to permit persons to whom the Software is furnished to do\nso, subject to the following conditions:\n\nThe above copyright notice and this permission notice shall be included in all\ncopies or substantial portions of the Software.\n\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\nSOFTWARE.\n\nSoftware: Scipy 1.5.4\nCopyright notice: \nJamfile.v2: Copyright Daryle Walker, Hubert Holin, John Maddock 2006 - 2007\nCopyright 2002 Gary Strangman.  All rights reserved\ntestpareto.cpp: Copyright John Maddock 2006.\ntestinstances/realconcepttestinstances1.cpp: Copyright John Maddock 2011.\nCopyright (C)  Tyler Reddy, Ross Hemsley, Edd Edmondson, Nikolai Nowaczyk, Joe Pitt-Francis, 2015.\ntestellint2.cpp:  Copyright John Maddock 2006, 2007\njacobinear1.ipp: Copyright John Maddock 2012.\ncompiletest/sfellintrdincltest.cpp:  Copyright John Maddock 2006.\ntestdigamma.hpp: Copyright John Maddock 2006.\ntestbinomial.cpp: Copyright John Maddock 2006.\ntestinstances/ldoubletestinstances6.cpp: Copyright John Maddock 2011.\nCopyright 2005 Travis Oliphant Permission to use, copy, modify, and distribute this software without fee is granted under the SciPy License.\nlaguerre3.ipp:  (C) Copyright John Maddock 2006-7.\nibetainvdata.ipp:  (C) Copyright John Maddock 2006-7.\ntestconstants.cpp: Copyright John Maddock 2006, 2011.\ntestnegativebinomial.cpp: Copyright John Maddock 2006.\nCopyright (C) 2003, 2007-14 Massachusetts Institute of Technology\ntestbernoulli.cpp: Copyright John Maddock 2006.\nCopyright (c) 2007, Damian Eads. All rights reserved.\ntestremez.cpp:  Copyright John Maddock 2006\ntestibeta.hpp: Copyright Paul A. Bristow 2007, 2009\nCopyright 1984, 1987, 1988, 1992 by Stephen L. Moshier Direct inquiries to 30 Frost Street, Cambridge, MA 02140\nCopyright (c) 2006, Systems Optimization Laboratory All rights reserved.\nbesseljlargedata.ipp:  Copyright (c) 2007 John Maddock\nellintrddata.ipp:  Copyright (c) 2006 John Maddock\ntestellint2.hpp: Copyright Paul A. Bristow 2007, 2009\nlog1pexpm1test.cpp:  Copyright John Maddock 2005.\npch.hpp:  Copyright John Maddock 2008.\ntestlaguerre.hpp: Copyright John Maddock 2006.\ncompiletest/instantiate.hpp:  Copyright John Maddock 2006.\ntestnccshooks.hpp:  (C) Copyright John Maddock 2008.\nLicense: New BSD, (C) 2014\ncompiletest/sfnextincltest.cpp:  Copyright John Maddock 2006.\ntestnonfiniteio.cpp: Copyright 2011 Paul A. Bristow\nacoshtest.hpp:  (C) Copyright Hubert Holin 2003.\ncompiletest/main.cpp:  Copyright John Maddock 2009.\nCopyright 1985 by Stephen L. Moshier Direct inquiries to 30 Frost Street, Cambridge, MA 02140 /\ncompiletest/sfbinomialincltest.cpp:  Copyright John Maddock 2006.\ncompiletest/sfhypotincltest.cpp:  Copyright John Maddock 2006.\nCopyright 2002 Pearu Peterson all rights reserved, Pearu Peterson <pearu@cens.ioc.ee>\ntestinstances/doubletestinstances6.cpp: Copyright John Maddock 2011.\ntestinstances/doubletestinstances2.cpp: Copyright John Maddock 2011.\ncopyright = '2008-%s, The SciPy community' % date.today().year\nCopyright (C) 2014 Eric Moore\nasinhtest.hpp:  (C) Copyright Hubert Holin 2003.\ncomplextest.cpp:  (C) Copyright John Maddock 2005.\ntestbeta.hpp: Copyright Paul A. Bristow 2007, 2009\ntesttr1.cpp:  (C) Copyright John Maddock 2008.\nCopyright (c) Donald Stufft and individual contributors.\ntestigamma.cpp:  (C) Copyright John Maddock 2006.\ntestzeta.cpp:  (C) Copyright John Maddock 2006.\nCopyright (c) 2005-2015, Michele Simionato All rights reserved.\nnctsmalldelta.ipp: Copyright John Maddock 2012.\nntlconceptcheck.cpp:  Copyright Paul A. Bristow 2009, 2011\nspecialfunctionstest.cpp:    BOOSTTESTMESSAGE(\"(C) Copyright Hubert Holin 2003-2005.\");\nCopyright (c) 2010 Thomas P. Robitaille\nCopyright Anne M. Archibald 2008 Released under the scipy license import numpy as np from heapq import heappush, heappop import scipy.sparse\nibetalargedata.ipp:  (C) Copyright John Maddock 2006.\ntestinstances/ldoubletestinstances10.cpp: Copyright John Maddock 2011.\ntestinstances/ldoubletestinstances8.cpp: Copyright John Maddock 2011.\nigammabigdata.ipp:  (C) Copyright John Maddock 2006.\nellinte2data.ipp:  Copyright (c) 2006 John Maddock\ntestexpint.hpp: Copyright Paul A. Bristow 2007, 2009\nCopyright (C)  Tyler Reddy, Richard Gowers, and Max Linked, 2016\ns.ipp: Copyright (c) 2006 Johan Rade\ntestinstances/ldoubletestinstances9.cpp: Copyright John Maddock 2011.\ncompiletest/sfsphharmincltest.cpp:  Copyright John Maddock 2006.\nlog1pexpm1data.ipp:  (C) Copyright John Maddock 2006-7.\njacobiellipticsmall.ipp: Copyright John Maddock 2012.\natanhtest.hpp:  (C) Copyright Hubert Holin 2003.\ncbrtdata.ipp:  (C) Copyright John Maddock 2006-7.\ntestextremevalue.cpp: Copyright John Maddock 2006.\nntlconceptcheck.cpp:  Copyright John Maddock 2007-8.\ncompiletest/sfcospiincltest.cpp:  Copyright John Maddock 2006.\nCopyright (C) 2003-2005 Peter J. Verveer\nCopyright (C) 2013  Pauli Virtanen\ntestskewnormal.cpp: Copyright Benjamin Sobotta 2012\ntestdigamma.hpp: Copyright Paul A. Bristow 2007, 2009\nbinomialquantile.ipp:  (C) Copyright John Maddock 2006-7.\nCopyright (C) 2013 Kenneth L. Ho\nCopyright (c) 1994 by Xerox Corporation.  All rights reserved.\ndigammasmalldata.ipp:  (C) Copyright John Maddock 2006-7.\ntestrationalinstances/testrationaldouble5.cpp:  (C) Copyright John Maddock 2006-7.\ntestrationals.cpp:  (C) Copyright John Maddock 2006.\ntestellint1.cpp:  Copyright Xiaogang Zhang 2006\ngammainvsmalldata.ipp:  (C) Copyright John Maddock 2006-7.\ntestgeometric.cpp: Copyright John Maddock 2010.\ntestbeta.cpp: Copyright John Maddock 2006.\nibetaintdata.ipp:  (C) Copyright John Maddock 2006-7.\ndigammadata.ipp:  (C) Copyright John Maddock 2006-7.\ntestgamma.hpp: Copyright John Maddock 2006.\nlegendreplarge.ipp:  (C) Copyright John Maddock 2006-7.\nCopyright (c) 2006-2008 Alexander Chemeris\ntestbinomialcoeff.hpp: Copyright Paul A. Bristow 2007, 2009\nCopyright (C) 2010 David Fong and Michael Saunders\ntestpareto.cpp: Copyright Paul A. Bristow 2007, 2009.\ntesttgammaratio.hpp: Copyright Paul A. Bristow 2007, 2009\ntestinversegaussian.cpp: Copyright Paul A. Bristow 2010.\ncompiletest/toolstestinctest.cpp:  Copyright John Maddock 2006.\ns.ipp: Copyright (c) 2012 Paul A. Bristow\ntestlaguerre.cpp:  (C) Copyright John Maddock 2006.\ncompiletest/toolsseriesinctest.cpp:  Copyright John Maddock 2006.\ntestbasicnonfinite.cpp: Copyright (c) 2006 Johan Rade\ntestinstances/doubletestinstances3.cpp: Copyright John Maddock 2011.\ncompiletest/complasinincltest.cpp:  Copyright John Maddock 2006.\ntestncf.cpp: Copyright John Maddock 2008.\nellintpi3largedata.ipp:  Copyright (c) 2006 John Maddock\nbetasmalldata.ipp:  (C) Copyright John Maddock 2006.\nCopyright J.S. Roy (js@jeannot.org), 2002-2005 See the LICENSE file for copyright information.\ncompiletest/sfsinpiincltest.cpp:  Copyright John Maddock 2006.\ntestinstances/floattestinstances7.cpp: Copyright John Maddock 2011.\ntestellint1.cpp:  Copyright Paul A. Bristow 2007\nQhull, Copyright (c) 1993-2019\nhandletestresult.hpp:  (C) Copyright John Maddock 2006-7.\ntestnonfinitetrap.cpp: Copyright (c) 2011 Paul A. Bristow To incorporate into Boost.Math\nCopyright 1985, 1987 by Stephen L. Moshier Direct inquiries to 30 Frost Street, Cambridge, MA 02140 /\nteststudentst.cpp: Copyright John Maddock 2006.\ntestarchive.cpp: Copyright (c) 2011 Paul A. Bristow - filename changes for boost-trunk.\nmprealconceptcheck.cpp:  Copyright John Maddock 2007-8.\nsphneumanndata.ipp:  Copyright (c) 2007 John Maddock\nCopyright (C) 2009 Pauli Virtanen Distributed under the same license as Scipy.\nalmostequal.ipp: Copyright (c) 2006 Johan Rade\ntestinstances/floattestinstances3.cpp: Copyright John Maddock 2011.\ntestrationalinstances/testrationalrealconcept3.cpp:  (C) Copyright John Maddock 2006-7.\nCopyright (c) 2004-2005, Jean-Sebastien Roy (js@jeannot.org)\ntgammadeltaratioint.ipp:  (C) Copyright John Maddock 2006-7.\ntestround.cpp:  (C) Copyright John Maddock 2007.\nigammainvadata.ipp:  (C) Copyright John Maddock 2006-7.\ntestnct.cpp: Copyright Paul A. Bristow 2012.\ncompiletest/complatanhincltest.cpp:  Copyright John Maddock 2006.\nerfinvdata.ipp:  (C) Copyright John Maddock 2006-7.\n!   Copyright (C) 2013 Kenneth L. Ho\ntesterf.cpp:  Copyright John Maddock 2006.\nCopyright 1985, 1987, 1989 by Stephen L. Moshier Direct inquiries to 30 Frost Street, Cambridge, MA 02140\ntestinstances/Jamfile.v2: Copyright ohn Maddock 2012\nCopyright (c) 2003-2009, The Regents of the University of California, through Lawrence Berkeley National Laboratory (subject to receipt of any required approvals from U.S. Dept. of Energy) All rights reserved.\ncompiletest/toolsrationalinctest.cpp:  Copyright John Maddock 2006.\ncompiletest/sfellintrjincltest.cpp:  Copyright John Maddock 2006.\nlog1pexpm1test.hpp:  Copyright John Maddock 2005.\ntestexpint.cpp:  (C) Copyright John Maddock 2007.\ntesttriangular.cpp: Copyright Paul Bristow 2006, 2007.\ncompiletest/toolstoms748inctest.cpp:  Copyright John Maddock 2006.\nCopyright (C)  Pauli Virtanen, 2010.\ntestibetainvab.hpp: Copyright Paul A. Bristow 2007, 2009\ncompiletest/constantsincltest.cpp:  Copyright John Maddock 2012.\nlog1pexpm1test.hpp:  Copyright Paul A. Bristow 2010\ncompiletest/sfroundincltest.cpp:  Copyright John Maddock 2006.\nigammameddata.ipp:  (C) Copyright John Maddock 2006.\ntestinstances/testinstances.hpp: Copyright John Maddock 2011.\ntestcbrt.hpp: Copyright Paul A. Bristow 2007, 2009\ntestbesselairyzeros.cpp:  Copyright Paul A. Bristow 2013.\nexpintidatadouble.ipp:  Copyright John Maddock 2008.\ntestsignedzero.cpp: Copyright 2011 Paul A. Bristow  To incorporate into Boost.Math\ntestellint1.cpp:  Copyright John Maddock 2006, 2007\nzeta1belowdata.ipp:  Copyright John Maddock 2008.\ntestgammahooks.hpp:  (C) Copyright John Maddock 2006.\ntestbesselairyzeros.cpp:  Copyright John Maddock 2013\ntestrationalinstances/testrationalfloat2.cpp:  (C) Copyright John Maddock 2006-7.\ncompiletest/stdrealconceptcheck.cpp:  Copyright John Maddock 2006.\nLicense: BSD, (C) 2011\ntestnormal.cpp: Copyright John Maddock 2007.\ntesttriangular.cpp: Copyright John Maddock 2006, 2007.\ntestldoublesimple.cpp: Copyright John Maddock 2013.\ncompiletest/sfexpm1incltest.cpp:  Copyright John Maddock 2006.\ntestinstances/realconcepttestinstances6.cpp: Copyright John Maddock 2011.\nexpintdata.ipp:  Copyright John Maddock 2008.\nCopyright (c) 1998-2003 by the University of Florida.\ntestlegacynonfinite.cpp: Copyright (c) 2011 Paul A. Bristow comments\ntestinstances/ldoubletestinstances2.cpp: Copyright John Maddock 2011.\ntestmathfwd.cpp:  Copyright Paul A. Bristow 2010.\nnccs.ipp:  Copyright John Maddock 2008.\ntestjacobi.cpp:  Copyright John Maddock 2012\nnct.ipp: Copyright John Maddock 2008.\ntestigamma.hpp: Copyright Paul A. Bristow 2007, 2009\nibetainvadata.ipp:  (C) Copyright John Maddock 2006-7.\nCopyright (C) 2015, Pauli Virtanen <pav@iki.fi>\ntestellint3.cpp:  Copyright John Maddock 2006, 2007\nassoclegendrep.ipp:  (C) Copyright John Maddock 2006-7.\ntestibeta.cpp:  (C) Copyright John Maddock 2006.\nbetameddata.ipp:  (C) Copyright John Maddock 2006.\nexpintsmalldata.ipp:  Copyright John Maddock 2008.\nnctasym.ipp: Copyright John Maddock 2012.\nLicense: BSD, (C) 2012\ntestpolicy3.cpp: Copyright John Maddock 2007.\nCopyright (c) 2001-2011 - Scilab Enterprises Updated by Allan Cornet, Sylvestre Ledru.\ntestinstances/doubletestinstances7.cpp: Copyright John Maddock 2011.\ntestinstances/realconcepttestinstances4.cpp: Copyright John Maddock 2011.\ntestinstances/floattestinstances2.cpp: Copyright John Maddock 2011.\ntestbesselj.cpp:  (C) Copyright John Maddock 2007.\ncompiletest/sfsqrt1pm1incltest.cpp:  Copyright John Maddock 2006.\ncompiletest/toolspolynomialinctest.cpp:  Copyright John Maddock 2006.\ntestsign.cpp:#define BOOSTTESTMAIN Copyright John Maddock 2008\ncompiletest/sferfincltest.cpp:  Copyright John Maddock 2006.\npowtest.cpp:  (C) Copyright Bruno Lalande 2008.\nsphericalharmonic.ipp:  (C) Copyright John Maddock 2006-7.\nCopyright (c) 2018 Sylvain Gubian <sylvain.gubian@pmi.com>, Yang Xiang <yang.xiang@pmi.com>\npowm1sqrtp1m1test.hpp:  Copyright John Maddock 2006.\nCopyright (c) 2018, Quansight-Labs All rights reserved.\njacobielliptic.ipp: Copyright John Maddock 2012.\ntestbesselhooks.hpp:  (C) Copyright John Maddock 2007.\ntestrationalinstances/testrationalldouble5.cpp:  (C) Copyright John Maddock 2006-7.\ncompiletest/sfmodfincltest.cpp:  Copyright John Maddock 2006.\nCopyright (c) 1996-2008 Rice University.\nbesseliintdata.ipp:  Copyright (c) 2007 John Maddock\nbetaexpdata.ipp:  (C) Copyright John Maddock 2006.\ntestellint3.hpp: Copyright Paul A. Bristow 2007, 2009\ncompiletest/sfhankelincltest.cpp:  Copyright John Maddock 2012.\ntestskewnormal.cpp: Copyright Paul A. Bristow 2012.\nnegativebinomialquantile.ipp:  (C) Copyright John Maddock 2006-7.\ncompiletest/sfhermiteincltest.cpp:  Copyright John Maddock 2006.\nCopyright (c) 2004 David M. Cooke <cookedm@physics.mcmaster.ca>\ngammainvbigdata.ipp:  (C) Copyright John Maddock 2006-7.\ntestibetainv.cpp:  (C) Copyright John Maddock 2006.\ncompiletest/sfbetaincltest.cpp:  Copyright John Maddock 2006.\ntesterf.hpp: Copyright Paul A. Bristow 2007, 2009\nfunctor.hpp:  (C) Copyright John Maddock 2007.\ntestrationalinstances/testrationalldouble4.cpp:  (C) Copyright John Maddock 2006-7.\ncompiletest/complatanincltest.cpp:  Copyright John Maddock 2006.\nbinomialdata.ipp:  (C) Copyright John Maddock 2006-7.\nerfsmalldata.ipp:  (C) Copyright John Maddock 2006.\ntestigammainva.hpp: Copyright Paul A. Bristow 2007, 2009\ncompiletest/sfdigammaincltest.cpp:  Copyright John Maddock 2006.\nCopyright (c) 2002 Travis Oliphant all rights reserved oliphant.travis@ieee.org Permission to use, modify, and distribute this software is given under the terms of the SciPy (BSD style) license. See LICENSE.txt that came with this distribution for specifics.\ncompiletest/toolsstatsinctest.cpp:  Copyright John Maddock 2006.\ntestgeometric.cpp: Copyright Paul A. Bristow 2010.\ncompiletest/sfzetaincltest.cpp:  Copyright John Maddock 2007.\nCopyright 1984, 1987, 2000 by Stephen L. Moshier\ntestinstances/realconcepttestinstances9.cpp: Copyright John Maddock 2011.\ntestinstances/floattestinstances9.cpp: Copyright John Maddock 2011.\ncompiletest/sfbesselincltest.cpp:  Copyright John Maddock 2006.\ntestrationalinstances/testrationalrealconcept1.cpp:  (C) Copyright John Maddock 2006-7.\nCopyright Anne M. Archibald 2008 Released under the scipy license\ntestinstances/realconcepttestinstances8.cpp: Copyright John Maddock 2011.\nzetanegdata.ipp:  Copyright John Maddock 2008.\ntestnegativebinomial.cpp: Copyright Paul A. Bristow 2007.\nerfdata.ipp:  (C) Copyright John Maddock 2006-7.\nCopyright Anne M. Archibald 2008 Additional contributions by Patrick Varilly and Sturla Molden 2012 Revision by Sturla Molden 2015 Balanced kd-tree construction written by Jake Vanderplas for scikit-learn Released under the scipy license\nhypottest.cpp:  (C) Copyright John Maddock 2005.\n(C) Copyright John Maddock 2006.\ncompiletest/sfpowm1incltest.cpp:  Copyright John Maddock 2006.\ntestinstances/floattestinstances1.cpp: Copyright John Maddock 2011.\ncompiletest/toolssolveinctest.cpp:  Copyright John Maddock 2006.\nigammasmalldata.ipp:  (C) Copyright John Maddock 2006.\ntestrationalinstances/testrationalldouble1.cpp:  (C) Copyright John Maddock 2006-7.\njacobilargephi.ipp: Copyright John Maddock 2012.\ncompiletest/tr1incltest.cpp:  Copyright John Maddock 2008.\nigammaintdata.ipp:  (C) Copyright John Maddock 2006-7.\nellintkdata.ipp:  (C) Copyright John Maddock 2006-7.\ncompiletest/sflanczosincltest.cpp:  Copyright John Maddock 2006.\ntestellint1.hpp: Copyright John Maddock 2006.\nCopyright 1984, 1987, 1989, 2000 by Stephen L. Moshier\ntestlegendre.hpp: Copyright John Maddock 2006.\ntestfindscale.cpp: Copyright Paul A. Bristow 2007.\nibetadata.ipp:  (C) Copyright John Maddock 2006.\ntestbesseli.hpp:  (C) Copyright John Maddock 2007.\nellintfdata.ipp:  Copyright (c) 2006 John Maddock\nCopyright (c) 2000-2015 The University of California Berkeley. All rights reserved.\nsphbesseldata.ipp:  Copyright (c) 2007 John Maddock\nbesselyndata.ipp:  Copyright (c) 2007 John Maddock\ntestrealconceptnegbin.cpp: Copyright John Maddock 2010.\nCopyright 1984, 1987, 1989, 1992, 2000 by Stephen L. Moshier\nerfcinvdata.ipp:  (C) Copyright John Maddock 2006-7.\ncompiletest/sfellint1incltest.cpp:  Copyright John Maddock 2006.\nCopyright (C) 2013 Kenneth L. Ho Redistribution and use in source and binary forms, with or without modification, are permitted provided that the following conditions are met:\ntestlegendrehooks.hpp:  (C) Copyright John Maddock 2006.\ntestlongdoublesupport.cpp: Copyright John Maddock 2009\ncompiletest/sfmathfwdincltest.cpp:  Copyright John Maddock 2006.\ntestibetainv.hpp: Copyright Paul A. Bristow 2007, 2009\ntestbeta.hpp: Copyright John Maddock 2006.\ncompiletest/sfsincincltest.cpp:  Copyright John Maddock 2006.\ncompiletest/instantiate.hpp:  Copyright Paul A. Bristow 2007, 2010.\ncompiletest/toolsminimainctest.cpp:  Copyright John Maddock 2006.\ntestinstantiate2.cpp:  Copyright John Maddock 2006.\ntestibetainv.hpp: Copyright John Maddock 2006.\nstdrealconceptcheck.cpp:  Copyright John Maddock 2006.\nellintpi3data.ipp:  Copyright (c) 2006 John Maddock\ntestpolicysf.cpp:  (C) Copyright John Maddock 2007.\nCopyright 1985, 1987 by Stephen L. Moshier Direct inquiries to 30 Frost Street, Cambridge, MA 02140\nbessely01data.ipp:  Copyright (c) 2007 John Maddock\nteststudentst.cpp: Copyright Paul A. Bristow 2006.\ntestrationalinstances/testrationalldouble3.cpp:  (C) Copyright John Maddock 2006-7.\nCopyright 2002-2016 The SciPy Developers\ncompiletest/toolstestdatainctest.cpp:  Copyright John Maddock 2006.\ntesterf.hpp: Copyright John Maddock 2006.\ntestinstances/realconcepttestinstances5.cpp: Copyright John Maddock 2011.\ntestcommonfactorgmpxx.cpp:  (C) Copyright John Maddock 2010.\ntesttoms748solve.cpp:  (C) Copyright John Maddock 2006.\ntestbesselj.hpp:  (C) Copyright John Maddock 2007.\ntestibetainvab.hpp: Copyright John Maddock 2006.\ntestbasicnonfinite.cpp: Copyright (c) 2011 Paul A. Bristow comments\nbesselyvdata.ipp:  Copyright (c) 2007 John Maddock\ntestconstants.cpp: Copyright Paul Bristow 2007, 2011.\ntesttr1.c:/  (C) Copyright John Maddock 2008.\ntestellint2.hpp: Copyright John Maddock 2006.\ncompiletest/toolsrootsinctest.cpp:  Copyright John Maddock 2006.\ntestcauchy.cpp: Copyright John Maddock 2006, 2007.\ntesterf.cpp:  Copyright Paul A. Bristow 2007\nztestmaxdigits10.cpp:  Copyright 2010 Paul A. Bristow\ntestzeta.hpp: Copyright John Maddock 2006.\ncompiletest/sflog1pincltest.cpp:  Copyright John Maddock 2006.\nCopyright (C) 2008 Damian Eads\ntestpolicy8.cpp: Copyright John Maddock 2007.\ntestcarlson.hpp: Copyright John Maddock 2006.\ntestinstances/floattestinstances5.cpp: Copyright John Maddock 2011.\ntestminima.cpp:  Copyright Paul A. Bristow 2007.\ncompiletest/sfjacobiincltest.cpp:  Copyright John Maddock 2012.\ntgammadeltaratiodata.ipp:  (C) Copyright John Maddock 2006-7.\ntestmathfwd.cpp:  Copyright John Maddock 2010.\ntestconstantgenerate.cpp: Copyright John Maddock 2010.\ntestrayleigh.cpp: Copyright John Maddock 2006.\ndigammanegdata.ipp:  (C) Copyright John Maddock 2006-7.\nsinctest.hpp:  (C) Copyright Hubert Holin 2003.\ntestcarlson.cpp:  Copyright 2006 John Maddock\ntestinstances/longdoubletestinstances1.cpp: Copyright John Maddock 2011.\nCopyright (c) 2006 Xiaogang Zhang Use, modification and distribution are subject to the Boost Software License, Version 1.0.\nibetasmalldata.ipp:  (C) Copyright John Maddock 2006.\ntestcarlson.hpp: Copyright Paul A. Bristow 2007, 2009\nCopyright (c) 2010 - Jordi Gutiérrez Hermoso (Octave patch)\nCopyright 1984, 1996 by Stephen L. Moshier\nncbetabig.ipp:  Copyright John Maddock 2008.\ntestlaplace.cpp:  Copyright Thijs van den Berg, 2008.\ntestarchive.cpp: Copyright (c) 2006 Johan Rade\ntestigammainva.cpp:  (C) Copyright John Maddock 2006.\ntestlaplace.cpp:  Copyright Paul A. Bristow 2008, 2009.\ntestbasicnonfinite.cpp: Copyright (c) 2011 John Maddock\nmultiprcconceptcheck1.cpp:  Copyright John Maddock 2013.\nbesselkdata.ipp:  Copyright (c) 2007 John Maddock\ntestuniform.cpp: Copyright John Maddock 2006.\nCopyright 2013 Andrea Gavana Author: <andrea.gavana@gmail.com>\ntestinstances/floattestinstances10.cpp: Copyright John Maddock 2011.\nhypergeometrictestdata.ipp: Copyright Gautam Sewani 2008\nCopyright (c) 2016--2017 Felix Lenders\npchlight.hpp:  Copyright John Maddock 2008.\nhermite.ipp:  (C) Copyright John Maddock 2006-7.\ntestrationalinstances/testrationalldouble2.cpp:  (C) Copyright John Maddock 2006-7.\nbinomiallargedata.ipp:  (C) Copyright John Maddock 2006-7.\ntestibeta.hpp: Copyright John Maddock 2006.\nCopyright 1984, 1995, 2000 by Stephen L. Moshier\ntestpolicy5.cpp: Copyright John Maddock 2007.\ntestuniform.cpp: Copyright Paul Bristow 2007.\nzetadata.ipp:  Copyright John Maddock 2008.\ntgammaratiodata.ipp:  (C) Copyright John Maddock 2006-7.\nCopyright (c) 2012 Massachusetts Institute of Technology\ntestsign.cpp:  (C) Copyright Paul A. Bristow 2011 (added tests for changesign)\nlaguerre2.ipp:  (C) Copyright John Maddock 2006-7.\nzeta1updata.ipp:  Copyright John Maddock 2008.\ntestlognormal.cpp: Copyright Paul A. Bristow 2007\ntestfindlocation.cpp: Copyright John Maddock 2007.\ncompiletest/sfcbrtincltest.cpp:  Copyright John Maddock 2006.\nCopyright (c) 2006-2015 The University of Colorado Denver.  All rights reserved.\ncompiletest/sfellintrcincltest.cpp:  Copyright John Maddock 2006.\ntestlegendre.cpp:  (C) Copyright John Maddock 2006.\ntestremez.cpp:  Copyright Paul A. Bristow 2007\ntestinstances/doubletestinstances4.cpp: Copyright John Maddock 2011.\ntestclassify.cpp:  Copyright John Maddock 2006.\nCopyright 1984, 1987, 1989 by Stephen L. Moshier Direct inquiries to 30 Frost Street, Cambridge, MA 02140\ncompiletest/complabsincltest.cpp:  Copyright John Maddock 2006.\nCopyright 1984, 1987, 1995 by Stephen L. Moshier\ntestrationalinstances/testrationaldouble1.cpp:  (C) Copyright John Maddock 2006-7.\ntestinstances/realconcepttestinstances7.cpp: Copyright John Maddock 2011.\nbesselidata.ipp:  Copyright (c) 2007 John Maddock\ntestgammadata.ipp:  (C) Copyright John Maddock 2006.\ntgammadeltaratioint2.ipp:  (C) Copyright John Maddock 2006-7.\nspecialfunctionstest.cpp:  (C) Copyright Hubert Holin 2003.\ntestinstances/doubletestinstances10.cpp: Copyright John Maddock 2011.\ntestminima.cpp:  Copyright John Maddock 2006.\nCopyright (c) 2008 Brian M. Clapper <bmc@clapper.org>, Gael Varoquaux Author: Brian M. Clapper, Gael Varoquaux License: 3-clause BSD\nCopyright (C) Damian Eads, 2007-2008. New BSD License.\nCopyright 1999 Travis Oliphant\ntestncbetahooks.hpp:  (C) Copyright John Maddock 2008.\ntestrationalinstances/testrationalfloat3.cpp:  (C) Copyright John Maddock 2006-7.\ncompiletest/sflegendreincltest.cpp:  Copyright John Maddock 2006.\nlog1pexpm1test.cpp:  Copyright Paul A. Bristow 2010\nmultiprcconceptcheck4.cpp:  Copyright John Maddock 2013.\nellintedata.ipp:  Copyright (c) 2006 John Maddock\nCopyright 1985, 1987, 2000 by Stephen L. Moshier\nexpintidata.ipp:  Copyright John Maddock 2008.\nerflargedata.ipp:  (C) Copyright John Maddock 2006-7.\nLicense: BSD, (C) 2011 import warnings\nmpfrconceptcheck.cpp:  Copyright John Maddock 2007-8.\ntestrationalinstances/testrationaldouble4.cpp:  (C) Copyright John Maddock 2006-7.\ntestibetainvab.cpp:  (C) Copyright John Maddock 2006.\ntestbetahooks.hpp:  (C) Copyright John Maddock 2006.\nCopyright (c) 2001-2002 Enthought, Inc.  2003-2019, SciPy Developers.\ncompiletest/sfexpintincltest.cpp:  Copyright John Maddock 2007.\ntestigammainva.hpp: Copyright John Maddock 2006.\ntestzeta.hpp: Copyright Paul A. Bristow 2007, 2009\nellintrjdata.ipp:  Copyright (c) 2006 John Maddock\nerfcinvbigdata.ipp:  (C) Copyright John Maddock 2006-7.\ntestinstances/ldoubletestinstances4.cpp: Copyright John Maddock 2011.\nexpint1data.ipp:  Copyright John Maddock 2008.\ntestigammainv.hpp: Copyright Paul A. Bristow 2007, 2009\nCopyright (C) 2010-2019 Max-Planck-Society\nCopyright (c) 2016 Wenzel Jakob <wenzel.jakob@epfl.ch>, All rights reserved.\ntestrationalinstances/testrationalrealconcept5.cpp:  (C) Copyright John Maddock 2006-7.\ntestcbrt.cpp:  Copyright John Maddock 2006.\ntestpolicy6.cpp: Copyright John Maddock 2007.\ntestsphericalharmonic.cpp:  (C) Copyright John Maddock 2006.\ntestbesselk.cpp:  Copyright John Maddock 2006, 2007\ntestinstances/realconcepttestinstances10.cpp: Copyright John Maddock 2011.\nCopyright (c) 2006-2007, Robert Hetland <hetland@tamu.edu>\ngammainvdata.ipp:  (C) Copyright John Maddock 2006-7.\ntestgamma.cpp:  (C) Copyright John Maddock 2006.\ntestnct.cpp: Copyright John Maddock 2008, 2012.\nnccsbig.ipp: Copyright John Maddock 2008.\natanhdata.ipp: Copyright John Maddock 2008.\ntestzetahooks.hpp:  (C) Copyright John Maddock 2006.\ntestairy.cpp:  Copyright John Maddock 2012\ncompiletest/sfgammaincltest.cpp:  Copyright John Maddock 2006.\ntestlognormal.cpp: Copyright John Maddock 2006.\ntestdigamma.cpp:  (C) Copyright John Maddock 2006.\ntestinstances/floattestinstances6.cpp: Copyright John Maddock 2011.\ntesterrorhandling.cpp: Copyright John Maddock 2006-7.\ntestinstances/pch.hpp:  Copyright John Maddock 2012.\ntestrationalinstances/testrationalfloat4.cpp:  (C) Copyright John Maddock 2006-7.\nCopyright (c) 2007, 2008, Damian Eads\nCopyright 2004-2005 by Enthought, Inc.\nCopyright (C) 2003, 2007-14 Matteo Frigo\ntestpolicy.cpp: Copyright John Maddock 2007.\ntestrationalinstances/testrationalrealconcept4.cpp:  (C) Copyright John Maddock 2006-7.\ntestclassify.cpp:  Copyright Paul A. Bristow 2007\nzztestmaxdigits10.cpp: Copyright 2010 Paul A. Bristow\ntestrationalinstances/testrationalrealconcept2.cpp:  (C) Copyright John Maddock 2006-7.\nCopyright 1984, 1987, 1988, 2000 by Stephen L. Moshier\nCopyright (c) 1993-2019 The Geometry Center.\ntestigammainv.cpp:  (C) Copyright John Maddock 2006.\nexpintidatalong.ipp:  Copyright John Maddock 2008.\ncompiletest/sfsinhcincltest.cpp:  Copyright John Maddock 2006.\ntestroots.cpp:  (C) Copyright John Maddock 2006.\nCopyright (c) 2007, 2008, Damian Eads. All rights reserved.\nefloatconceptcheck.cpp:  Copyright John Maddock 2011.\ntestcauchy.cpp: Copyright Paul A. Bristow 2007\ntesttgammaratio.cpp:  (C) Copyright John Maddock 2006.\ntestellint2.cpp:  Copyright Paul A. Bristow 2007\ntestrationalinstances/testrationaldouble2.cpp:  (C) Copyright John Maddock 2006-7.\ntestcarlson.cpp: Copyright Paul A. Bristow 2007.\nCopyright (C) 2010 David Fong and Michael Saunders Distributed under the same license as SciPy\nCopyright 1984, 1987 by Stephen L. Moshier Direct inquiries to 30 Frost Street, Cambridge, MA 02140\ncompiletest/sfellint2incltest.cpp:  Copyright John Maddock 2006.\ntestigamma.hpp: Copyright John Maddock 2006.\nCopyright (c) 2016 Adrian Veres\ntestoutofrange.hpp: Copyright John Maddock 2012.\nbesselkintdata.ipp:  Copyright (c) 2007 John Maddock\ntestinstances/doubletestinstances8.cpp: Copyright John Maddock 2011.\ntestlexicalcast.cpp: Copyright (c) 2011 Paul A. Bristow incorporated Boost.Math\ncompiletest/sftruncincltest.cpp:  Copyright John Maddock 2006.\nbesseljdata.ipp:  Copyright (c) 2007 John Maddock\nCopyright (c) 2009, Motorola, Inc\ntestlexicalcast.cpp: Copyright (c) 2006 Johan Rade\ncompiletest/toolsfractioninctest.cpp:  Copyright John Maddock 2006.\ncompiletest/sffpclassifyincltest.cpp:  Copyright John Maddock 2006.\nCopyright (c) 2007 - Sébastien Fabbro (gentoo patch)\ntestinstances/doubletestinstances9.cpp: Copyright John Maddock 2011.\ntestbesselk.hpp:  (C) Copyright John Maddock 2007.\ntestrealconcept.cpp: Copyright John Maddock 2010\nCopyright (c) 2003, The Regents of the University of California, through Lawrence Berkeley National Laboratory (subject to receipt of any required approvals from U.S. Dept. of Energy)\ntestbinomialcoeff.cpp:  (C) Copyright John Maddock 2006.\ntestsignedzero.cpp: Copyright 2006 Johan Rade\ntestrationalinstances/testrational.hpp:  (C) Copyright John Maddock 2006-7.\ntestinstantiate1.cpp:  Copyright John Maddock 2006.\ncompiletest/sfellintrfincltest.cpp:  Copyright John Maddock 2006.\ntestellint3.hpp: Copyright John Maddock 2006.\ntestinversegaussian.cpp: Copyright John Maddock 2010.\nacoshdata.ipp: Copyright John Maddock 2008.\nCopyright (c) 2002 Travis Oliphant all rights reserved Oliphant.Travis@altavista.net Permission to use, modify, and distribute this software is given under the terms of the SciPy (BSD style) license.  See LICENSE.txt that came with this distribution for specifics.\ntestjacobi.hpp: Copyright John Maddock 2006.\nCopyright (C) 2019 Peter Bell\ntestbesselk.cpp:  Copyright Paul A. Bristow 2007\nmultiprcconceptcheck3.cpp:  Copyright John Maddock 2013.\nCopyright (C) 2010-2019 Max-Planck-Society All rights reserved.\ntestellint1.hpp: Copyright Paul A. Bristow 2007, 2009\ntabletype.hpp: Copyright John Maddock 2012.\ntestfindscale.cpp: Copyright John Maddock 2007.\ntestinstances/floattestinstances8.cpp: Copyright John Maddock 2011.\ntestskewnormal.cpp: Copyright John Maddock 2012.\ncompiletest/testtraits.cpp:  Copyright John Maddock 2007.\ncompiletest/complacosincltest.cpp:  Copyright John Maddock 2006.\ntestbernoulli.cpp: Copyright  Paul A. Bristow 2007, 2012.\ntestpolicy2.cpp: Copyright John Maddock 2007.\ntestellint3.cpp:  Copyright Xiaogang Zhang 2006\ntestncbeta.cpp: Copyright John Maddock 2008.\ntestsignedzero.cpp: Copyright 2012 Paul A. Bristow with new tests.\nellintrfdata.ipp:  Copyright (c) 2006 John Maddock\ndigammarootdata.ipp:  (C) Copyright John Maddock 2006-7.\nmultiprcconceptcheck2.cpp:  Copyright John Maddock 2013.\ncompiletest/toolsrealcastinctest.cpp:  Copyright John Maddock 2006.\ntestinstances/realconcepttestinstances2.cpp: Copyright John Maddock 2011.\ntestbesselairyzeros.cpp:  Copyright Christopher Kormanyos 2013.\npowm1sqrtp1m1test.cpp:  (C) Copyright John Maddock 2006.\ntestexpinthooks.hpp:  (C) Copyright John Maddock 2006.\nCopyright 1984, 1995 by Stephen L. Moshier\ntestexpint.hpp: Copyright John Maddock 2006.\nCopyright (C) 2009, Pauli Virtanen <pav@iki.fi>\ntestlaguerre.hpp: Copyright Paul A. Bristow 2007, 2009\ntestinstances/ldoubletestinstances7.cpp: Copyright John Maddock 2011.\ntestlegendre.hpp: Copyright Paul A. Bristow 2007, 2009\ntestcbrt.cpp:  Copyright Paul A. Bristow 2010\ntestjacobi.hpp: Copyright Paul A. Bristow 2007, 2009\nCopyright Benjamin Sobotta 2012\ncompiletest/sffactorialsincltest.cpp:  Copyright John Maddock 2006.\ntestlaplace.cpp:  Copyright John Maddock 2008.\ntestbeta.cpp: Copyright Paul A. Bristow 2007, 2009\ntesterrorhandling.cpp: Copyright Paul A. Bristow 2006-7.\ntestrationalinstances/testrationaldouble3.cpp:  (C) Copyright John Maddock 2006-7.\ntestellint2.cpp:  Copyright Xiaogang Zhang 2006\ntestrationalinstances/testrationalfloat1.cpp:  (C) Copyright John Maddock 2006-7.\ncompiletest/complacoshincltest.cpp:  Copyright John Maddock 2006.\nCopyright (c) 2002-2005, Jean-Sebastien Roy (js@jeannot.org)\ntestrealconceptnegbin.cpp: Copyright Paul A. Bristow 2010.\nCopyright 1984, 1987, 1992, 2000 by Stephen L. Moshier\ntestcbrt.hpp: Copyright John Maddock 2006.\ncompiletest/toolsremezinctest.cpp:  Copyright John Maddock 2006.\ncompiletest/sfairyincltest.cpp:  Copyright John Maddock 2012.\nCopyright (c) 2007, John Travers <jtravs@gmail.com>\ncompiletest/sflaguerreincltest.cpp:  Copyright John Maddock 2006.\nCopyright 1984, 1987, 1989, 1995 by Stephen L. Moshier\nCopyright 1984, 1991 by Stephen L. Moshier Direct inquiries to 30 Frost Street, Cambridge, MA 02140\ntesterfhooks.hpp:  (C) Copyright John Maddock 2006.\nCopyright (C) Piers Lawrence.\ntestbessely.cpp:  (C) Copyright John Maddock 2007.\ntestnormal.cpp: Copyright Paul A. Bristow 2010.\ntestbinomialcoeff.hpp: Copyright John Maddock 2006.\nCopyright (C) 2019 Max-Planck-Society\ntestfindlocation.cpp: Copyright Paul A. Bristow 2007.\ntesthankel.cpp:  Copyright John Maddock 2012 testhypergeometricdist.cpp: Copyright Paul A. Bristow testhypergeometricdist.cpp: Copyright Gautam Sewani\ncompiletest/sfsignincltest.cpp:  Copyright John Maddock 2006.\ntestnonfinitetrap.cpp: Copyright (c) 2006 Johan Rade\ntestinstances/ldoubletestinstances5.cpp: Copyright John Maddock 2011.\nasinhdata.ipp: Copyright John Maddock 2008.\ntestlegacynonfinite.cpp: Copyright (c) 2006 Johan Rade\ntestigammainv.hpp: Copyright John Maddock 2006.\nCopyright 1984, 1987, 1988 by Stephen L. Moshier Direct inquiries to 30 Frost Street, Cambridge, MA 02140\ncompiletest/sfellint3incltest.cpp:  Copyright John Maddock 2006.\ntestfactorials.cpp:  Copyright John Maddock 2006.\ntestinstances/doubletestinstances5.cpp: Copyright John Maddock 2011.\nCopyright 2014, Eric W. Moore\ncompiletest/generate.sh:  Copyright John Maddock 2006.\ntestpolicy7.cpp: Copyright John Maddock 2007.\nlegendrep.ipp:  (C) Copyright John Maddock 2006-7.\ntestgamma.hpp: Copyright Paul A. Bristow 2007, 2009\ncompiletest/toolsconfiginctest.cpp:  Copyright John Maddock 2006.\ncompiletest/complasinhincltest.cpp:  Copyright John Maddock 2006.\ntestprintinfoontype.cpp: Copyright John Maddock 2010.\nellintrcdata.ipp:  Copyright (c) 2006 John Maddock\nbesseljintdata.ipp:  Copyright (c) 2007 John Maddock\ncompiletest/testcompileresult.hpp:  Copyright John Maddock 2007.\ntestnext.cpp:  (C) Copyright John Maddock 2008.\ntestinstances/realconcepttestinstances3.cpp: Copyright John Maddock 2011.\ntestinstances/ldoubletestinstances3.cpp: Copyright John Maddock 2011.\ntestinvhyp.cpp:  (C) Copyright John Maddock 2006.\ntestinstances/doubletestinstances1.cpp: Copyright John Maddock 2011.\ntesttgammaratio.hpp: Copyright John Maddock 2006.\nCopyright 1984, 1987, 1993 by Stephen L. Moshier Direct inquiries to 30 Frost Street, Cambridge, MA 02140\ntestbinomial.cpp: Copyright  Paul A. Bristow 2007.\ntestpolicy4.cpp: Copyright John Maddock 2007.\ntestbesseli.cpp:  (C) Copyright John Maddock 2007.\ntestellint3.cpp:  Copyright Paul A. Bristow 2007\nCopyright (C) 2019 Peter Bell \\author Martin Reinecke \\author Peter Bell\nCopyright 1984, 1987, 1989, 1992 by Stephen L. Moshier Direct inquiries to 30 Frost Street, Cambridge, MA 02140\nCopyright (c) 2001, 2002 Enthought, Inc.\nncbeta.ipp:  Copyright John Maddock 2008.\nsinhctest.hpp:  (C) Copyright Hubert Holin 2003.\ntestbessely.hpp:  (C) Copyright John Maddock 2007.\ntestinstances/floattestinstances4.cpp: Copyright John Maddock 2011.\nCopyright (C)  Tyler Reddy, 2016\nCopyright (c) 1993-2019 C.B. Barber.\ncommonfactortest.cpp:  (C) Copyright Daryle Walker 2001, 2006.\nellintpi2data.ipp:  Copyright (c) 2006 John Maddock\nCopyright (c) 1992-2015 The University of Tennessee and The University of Tennessee Research Foundation.  All rights reserved.\n\nLicense: \nCopyright (c) 2001-2002 Enthought, Inc.  2003-2019, SciPy Developers.\nAll rights reserved.\n\nRedistribution and use in source and binary forms, with or without\nmodification, are permitted provided that the following conditions\nare met:\n\n1. Redistributions of source code must retain the above copyright\n   notice, this list of conditions and the following disclaimer.\n\n2. Redistributions in binary form must reproduce the above\n   copyright notice, this list of conditions and the following\n   disclaimer in the documentation and/or other materials provided\n   with the distribution.\n\n3. Neither the name of the copyright holder nor the names of its\n   contributors may be used to endorse or promote products derived\n   from this software without specific prior written permission.\n\nTHIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS\n\"AS IS\" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT\nLIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR\nA PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT\nOWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,\nSPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT\nLIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,\nDATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY\nTHEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT\n(INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE\nOF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\nSoftware: onnx 1.6.0\nCopyright notice: \nCopyright (c) ONNX Project Contributors.\nCopyright (c) Facebook Inc. and Microsoft Corporation.\n\nLicense: MIT License\nPlease see above.\n\nSoftware: onnxruntime 1.6.0\nCopyright notice: \nCopyright (c) ONNX Project Contributors.\nCopyright (c) Facebook Inc. and Microsoft Corporation.\n\nLicense: MIT License\nPlease see above.\n\nSoftware: flatbuffers 2.0.0\nCopyright notice: \nCopyright (c) 2015 Google, Inc.\nCopyright 2014 Google Inc. All rights reserved.\nCopyright 2015 Google Inc. All rights reserved.\nCopyright 2017 Google Inc. All rights reserved.\nCopyright 2008 Google Inc.  All rights reserved.\nCopyright 2014 Google Inc.\nCopyright (c) 2013 Google, Inc.\nCopyright (c) 2014 Google, Inc.\nCopyright 2012, the Dart project authors. All rights reserved.\nCopyright 2018 Google Inc. All rights reserved.\nCopyright 2014 Stefan.Eilemann@epfl.ch\nCopyright 2016 Google Inc. All rights reserved.\nCopyright 2015 The Chromium Authors. All rights reserved.\nCopyright 2015, Google Inc.\nCopyright 2015 Google Inc.\nCopyright 2018 Dan Field. All rights reserved.\nCopyright 2018 Dan Field\n\n\nLicense: Apache License V2.0\n                               Apache License\n                       Version 2.0, January 2004\n                    http://www.apache.org/licenses/\nTERMS AND CONDITIONS FOR USE, REPRODUCTION, AND DISTRIBUTION\n1. Definitions.\n  \"License\" shall mean the terms and conditions for use, reproduction,\n  and distribution as defined by Sections 1 through 9 of this document.\n  \"Licensor\" shall mean the copyright owner or entity authorized by\n  the copyright owner that is granting the License.\n  \"Legal Entity\" shall mean the union of the acting entity and all\n  other entities that control, are controlled by, or are under common\n  control with that entity. For the purposes of this definition,\n  \"control\" means (i) the power, direct or indirect, to cause the\n  direction or management of such entity, whether by contract or\n  otherwise, or (ii) ownership of fifty percent (50%) or more of the\n  outstanding shares, or (iii) beneficial ownership of such entity.\n  \"You\" (or \"Your\") shall mean an individual or Legal Entity\n  exercising permissions granted by this License.\n  \"Source\" form shall mean the preferred form for making modifications,\n  including but not limited to software source code, documentation\n  source, and configuration files.\n  \"Object\" form shall mean any form resulting from mechanical\n  transformation or translation of a Source form, including but\n  not limited to compiled object code, generated documentation,\n  and conversions to other media types.\n  \"Work\" shall mean the work of authorship, whether in Source or\n  Object form, made available under the License, as indicated by a\n  copyright notice that is included in or attached to the work\n  (an example is provided in the Appendix below).\n  \"Derivative Works\" shall mean any work, whether in Source or Object\n  form, that is based on (or derived from) the Work and for which the\n  editorial revisions, annotations, elaborations, or other modifications\n  represent, as a whole, an original work of authorship. For the purposes\n  of this License, Derivative Works shall not include works that remain\n  separable from, or merely link (or bind by name) to the interfaces of,\n  the Work and Derivative Works thereof.\n  \"Contribution\" shall mean any work of authorship, including\n  the original version of the Work and any modifications or additions\n  to that Work or Derivative Works thereof, that is intentionally\n  submitted to Licensor for inclusion in the Work by the copyright owner\n  or by an individual or Legal Entity authorized to submit on behalf of\n  the copyright owner. For the purposes of this definition, \"submitted\"\n  means any form of electronic, verbal, or written communication sent\n  to the Licensor or its representatives, including but not limited to\n  communication on electronic mailing lists, source code control systems,\n  and issue tracking systems that are managed by, or on behalf of, the\n  Licensor for the purpose of discussing and improving the Work, but\n  excluding communication that is conspicuously marked or otherwise\n  designated in writing by the copyright owner as \"Not a Contribution.\"\n  \"Contributor\" shall mean Licensor and any individual or Legal Entity\n  on behalf of whom a Contribution has been received by Licensor and\n  subsequently incorporated within the Work.\n2. Grant of Copyright License. Subject to the terms and conditions of\n  this License, each Contributor hereby grants to You a perpetual,\n  worldwide, non-exclusive, no-charge, royalty-free, irrevocable\n  copyright license to reproduce, prepare Derivative Works of,\n  publicly display, publicly perform, sublicense, and distribute the\n  Work and such Derivative Works in Source or Object form.\n3. Grant of Patent License. Subject to the terms and conditions of\n  this License, each Contributor hereby grants to You a perpetual,\n  worldwide, non-exclusive, no-charge, royalty-free, irrevocable\n  (except as stated in this section) patent license to make, have made,\n  use, offer to sell, sell, import, and otherwise transfer the Work,\n  where such license applies only to those patent claims licensable\n  by such Contributor that are necessarily infringed by their\n  Contribution(s) alone or by combination of their Contribution(s)\n  with the Work to which such Contribution(s) was submitted. If You\n  institute patent litigation against any entity (including a\n  cross-claim or counterclaim in a lawsuit) alleging that the Work\n  or a Contribution incorporated within the Work constitutes direct\n  or contributory patent infringement, then any patent licenses\n  granted to You under this License for that Work shall terminate\n  as of the date such litigation is filed.\n4. Redistribution. You may reproduce and distribute copies of the\n  Work or Derivative Works thereof in any medium, with or without\n  modifications, and in Source or Object form, provided that You\n  meet the following conditions:\n  (a) You must give any other recipients of the Work or\n      Derivative Works a copy of this License; and\n  (b) You must cause any modified files to carry prominent notices\n      stating that You changed the files; and\n  (c) You must retain, in the Source form of any Derivative Works\n      that You distribute, all copyright, patent, trademark, and\n      attribution notices from the Source form of the Work,\n      excluding those notices that do not pertain to any part of\n      the Derivative Works; and\n  (d) If the Work includes a \"NOTICE\" text file as part of its\n      distribution, then any Derivative Works that You distribute must\n      include a readable copy of the attribution notices contained\n      within such NOTICE file, excluding those notices that do not\n      pertain to any part of the Derivative Works, in at least one\n      of the following places: within a NOTICE text file distributed\n      as part of the Derivative Works; within the Source form or\n      documentation, if provided along with the Derivative Works; or,\n      within a display generated by the Derivative Works, if and\n      wherever such third-party notices normally appear. The contents\n      of the NOTICE file are for informational purposes only and\n      do not modify the License. You may add Your own attribution\n      notices within Derivative Works that You distribute, alongside\n      or as an addendum to the NOTICE text from the Work, provided\n      that such additional attribution notices cannot be construed\n      as modifying the License.\n  You may add Your own copyright statement to Your modifications and\n  may provide additional or different license terms and conditions\n  for use, reproduction, or distribution of Your modifications, or\n  for any such Derivative Works as a whole, provided Your use,\n  reproduction, and distribution of the Work otherwise complies with\n  the conditions stated in this License.\n5. Submission of Contributions. Unless You explicitly state otherwise,\n  any Contribution intentionally submitted for inclusion in the Work\n  by You to the Licensor shall be under the terms and conditions of\n  this License, without any additional terms or conditions.\n  Notwithstanding the above, nothing herein shall supersede or modify\n  the terms of any separate license agreement you may have executed\n  with Licensor regarding such Contributions.\n6. Trademarks. This License does not grant permission to use the trade\n  names, trademarks, service marks, or product names of the Licensor,\n  except as required for reasonable and customary use in describing the\n  origin of the Work and reproducing the content of the NOTICE file.\n7. Disclaimer of Warranty. Unless required by applicable law or\n  agreed to in writing, Licensor provides the Work (and each\n  Contributor provides its Contributions) on an \"AS IS\" BASIS,\n  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or\n  implied, including, without limitation, any warranties or conditions\n  of TITLE, NON-INFRINGEMENT, MERCHANTABILITY, or FITNESS FOR A\n  PARTICULAR PURPOSE. You are solely responsible for determining the\n  appropriateness of using or redistributing the Work and assume any\n  risks associated with Your exercise of permissions under this License.\n8. Limitation of Liability. In no event and under no legal theory,\n  whether in tort (including negligence), contract, or otherwise,\n  unless required by applicable law (such as deliberate and grossly\n  negligent acts) or agreed to in writing, shall any Contributor be\n  liable to You for damages, including any direct, indirect, special,\n  incidental, or consequential damages of any character arising as a\n  result of this License or out of the use or inability to use the\n  Work (including but not limited to damages for loss of goodwill,\n  work stoppage, computer failure or malfunction, or any and all\n  other commercial damages or losses), even if such Contributor\n  has been advised of the possibility of such damages.\n9. Accepting Warranty or Additional Liability. While redistributing\n  the Work or Derivative Works thereof, You may choose to offer,\n  and charge a fee for, acceptance of support, warranty, indemnity,\n  or other liability obligations and/or rights consistent with this\n  License. However, in accepting such obligations, You may act only\n  on Your own behalf and on Your sole responsibility, not on behalf\n  of any other Contributor, and only if You agree to indemnify,\n  defend, and hold each Contributor harmless for any liability\n  incurred by, or claims asserted against, such Contributor by reason\n  of your accepting any such warranty or additional liability.\nEND OF TERMS AND CONDITIONS\nAPPENDIX: How to apply the Apache License to your work.\n  To apply the Apache License to your work, attach the following\n  boilerplate notice, with the fields enclosed by brackets \"[]\"\n  replaced with your own identifying information. (Don't include\n  the brackets!)  The text should be enclosed in the appropriate\n  comment syntax for the file format. We also recommend that a\n  file or class name and description of purpose be included on the\n  same \"printed page\" as the copyright notice for easier\n  identification within third-party archives.\nCopyright [yyyy] [name of copyright owner]\nLicensed under the Apache License, Version 2.0 (the \"License\");\nyou may not use this file except in compliance with the License.\nYou may obtain a copy of the License at\n   http://www.apache.org/licenses/LICENSE-2.0\nUnless required by applicable law or agreed to in writing, software\ndistributed under the License is distributed on an \"AS IS\" BASIS,\nWITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\nSee the License for the specific language governing permissions and\nlimitations under the License.\n\nSoftware: googletest 1.8.1\nCopyright notice: \nCopyright 2009, Google Inc.\nCopyright 2008, Google Inc.\nCopyright 2007 Google Inc.\nCopyright 2007, Google Inc.\nCopyright 2013, Google Inc.\nCopyright 2015, Google Inc.\nCopyright 2005, Google Inc.\nCopyright 2008 Google Inc.\nCopyright 2006, Google Inc.\nCopyright 2009 Google Inc. All Rights Reserved.\nCopyright 2013 Google Inc. All Rights Reserved.\nCopyright 2017 Google Inc.\nCopyright 2007 Neal Norwitz\nCopyright 2008 Google Inc.  All Rights Reserved.\nCopyright 2009 Neal Norwitz All Rights Reserved.\nCopyright 2003 Google Inc.\nCopyright 2009 Google Inc.\nCopyright 2008 Google Inc. All Rights Reserved.\nCopyright [2007] Neal Norwitz\nPortions Copyright [2007] Google Inc.\nCopyright 2010 Google Inc.  All Rights Reserved.\nCopyright 2010, Google Inc.\nCopyright 2005 Google Inc. All Rights Reserved.\nCopyright 2018, Google Inc.\nCopyright 2003, Google Inc.\nCopyright 2009 Google Inc. All rights reserved.\nCopyright 2015 Google Inc. All rights reserved.\nCopyright 2009 Google Inc.  All rights reserved.\nCopyright 2018 Google LLC. All rights reserved.\nCopyright 2018, Google LLC.\n\n\nLicense: BSD 3-Clause License\nPlease see above.\n\nSoftware: glog 0.4.0\nCopyright notice:\nCopyright (c) 1999, Google Inc.\nCopyright (c) 2007, Google Inc.\nCopyright (c) 2006, Google Inc.\nCopyright (c) 2003, Google Inc.\nCopyright (c) 1999, 2007, Google Inc.\nCopyright (c) 2008, Google Inc.\nCopyright (c) 2009, Google Inc.\nCopyright (c) 2002, Google Inc.\nCopyright (c) 2000 - 2007, Google Inc.\nCopyright (c) 2005 - 2007, Google Inc.\nCopyright (c) 2004, Google Inc.\nCopyright (c) 2003-2008, Jouni Malinen <j@w1.fi> and contributors\n\n\nLicense: BSD 3-Clause License\nPlease see above.\n\nSoftware: pybind11 2.4.3\nCopyright notice:\nCopyright (c) 2015 Wenzel Jakob <wenzel@inf.ethz.ch>\nCopyright (c) 2016 Wenzel Jakob <wenzel.jakob@epfl.ch>\nCopyright (c) 2016 Trent Houliston <trent@houliston.me> and Wenzel Jakob <wenzel.jakob@epfl.ch>\nCopyright (c) 2017 Wenzel Jakob <wenzel.jakob@epfl.ch>\nCopyright (c) 2017 Jason Rhinelander <jason@imaginary.ca>\nCopyright (c) 2016 Klemens Morgenstern <klemens.morgenstern@ed-chemnitz.de> and\nCopyright (c) 2017 Henry F. Schreiner\nCopyright (c) 2016 Sergey Lyskov and Wenzel Jakob\nCopyright (c) 2016 Wenzel Jakob <wenzel.jakob@epfl.ch>, All rights reserved.\nCopyright (c) 2016 Jason Rhinelander <jason@imaginary.ca>\nCopyright (c) 2019 Google LLC\nCopyright (c) 2019 Google Inc.\nCopyright (c) 2016 Ben North <ben@redfrontdoor.org>\nCopyright (c) 2016 Klemens D. Morgenstern\nCopyright (c) 2016 Pim Schellart <P.Schellart@princeton.edu>\nCopyright (c) 2017 Borja Zarco (Google LLC) <bzarco@google.com>\nCopyright (c) 2016 Ivan Smirnov <i.s.smirnov@gmail.com>\nCopyright (c) 2016 Ivan Smirnov\nCopyright (c) 2016 Sergey Lyskov\nCopyright (c) 2018 Hudson River Trading LLC <opensource@hudson-trading.com>\nCopyright (c) 2019 Roland Dreier <roland.dreier@gmail.com>\nCopyright (c) 2006, 2007 Montel Laurent, <montel@kde.org>\nCopyright (c) 2008, 2009 Gael Guennebaud, <g.gael@free.fr>\nCopyright (c) 2009 Benoit Jacob <jacob.benoit.1@gmail.com>\nCopyright 2001-2009 Kitware, Inc.\nCopyright 2012 Continuum Analytics, Inc.\nCopyright (c) 2007-2012 University of Illinois at Urbana-Champaign.\n\nLicense:BSD 3-Clause License\nCopyright (c) 2016 Wenzel Jakob <wenzel.jakob@epfl.ch>, All rights reserved.\n\nRedistribution and use in source and binary forms, with or without\nmodification, are permitted provided that the following conditions are met:\n\n1. Redistributions of source code must retain the above copyright notice, this\n   list of conditions and the following disclaimer.\n\n2. Redistributions in binary form must reproduce the above copyright notice,\n   this list of conditions and the following disclaimer in the documentation\n   and/or other materials provided with the distribution.\n\n3. Neither the name of the copyright holder nor the names of its contributors\n   may be used to endorse or promote products derived from this software\n   without specific prior written permission.\n\nTHIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS \"AS IS\" AND\nANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED\nWARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE\nDISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE\nFOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL\nDAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR\nSERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER\nCAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY,\nOR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE\nOF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n\nPlease also refer to the file CONTRIBUTING.md, which clarifies licensing of\nexternal contributions to this project including patches, pull requests, etc.\n\nSoftware: SQLite 3.36.0\nCopyright notice:\nCopyright (c) 1991-2011 Unicode, Inc.\nCopyright 2008 D. Richard Hipp and Hipp, Wyrick & Company, Inc.\nCopyright (c) 2002 by David Gravereaux.\nCopyright (c) 2006 by Pat Thoyts\n(c)  The page number is greater than the largest page that existed in\nCopyright (C) 1996, 1997, 1998, 1999, 2000, 2001, 2003, 2004, 2005, 2006, 2007 2008 Free Software Foundation, Inc.\n\nLicense: Public Domain\nAnyone is free to copy, modify, publish, use, compile, sell, or distribute this software, either in source code form or as a compiled binary, for any purpose, commercial or non-commercial, and by any means.\n\nSoftware: pybind11 2.6.1\nCopyright notice:\nCopyright (c) 2016 Wenzel Jakob <wenzel.jakob@epfl.ch>, All rights reserved.\nCopyright (c) 2016 Ben North <ben@redfrontdoor.org>\nCopyright (c) 2017 Wenzel Jakob <wenzel.jakob@epfl.ch>\nCopyright 2012 Continuum Analytics, Inc.\nCopyright 2001-2009 Kitware, Inc.\nCopyright (c) 2016 Ivan Smirnov <i.s.smirnov@gmail.com>\nCopyright (c) 2017 Borja Zarco (Google LLC) <bzarco@google.com>\ncopyright = \"2017, Wenzel Jakob\"\nCopyright (c) 2016 Jason Rhinelander <jason@imaginary.ca>\nCopyright (c) 2016 Trent Houliston <trent@houliston.me> and Wenzel Jakob <wenzel.jakob@epfl.ch>\nCopyright (c) 2016 Wenzel Jakob <wenzel.jakob@epfl.ch>\nCopyright (c) 2017 Jason Rhinelander <jason@imaginary.ca>\nCopyright (c) 2006, 2007 Montel Laurent, <montel@kde.org>\nCopyright (c) 2008, 2009 Gael Guennebaud, <g.gael@free.fr>\nCopyright (c) 2016 Klemens Morgenstern <klemens.morgenstern@ed-chemnitz.de> and Wenzel Jakob <wenzel.jakob@epfl.ch>\nCopyright (c) 2020 Wenzel Jakob <wenzel.jakob@epfl.ch>\nCopyright (c) 2019 Google Inc.\nCopyright (c) 2019 Roland Dreier <roland.dreier@gmail.com>\nCopyright (c) 2018 Hudson River Trading LLC <opensource@hudson-trading.com>\nCopyright (c) 2019 Google LLC\nCopyright (c) 2015 Wenzel Jakob <wenzel@inf.ethz.ch>\nCopyright (c) 2016 Sergey Lyskov and Wenzel Jakob\nCopyright (c) 2016 Ivan Smirnov\nCopyright (c) 2016 Klemens D. Morgenstern\nCopyright (c) 2009 Benoit Jacob <jacob.benoit.1@gmail.com>\nIf true, \"(C) Copyright ...\" is shown in the HTML footer. Default is True.\nCopyright (c) 2016 Pim Schellart <P.Schellart@princeton.edu>\nCopyright (c) 2020 Wenzel Jakob <wenzel@inf.ethz.ch> and Henry Schreiner\nCopyright (c) 2016 Sergey Lyskov\nCopyright (c) 2017 Henry F. Schreiner\n\nCopyright (c) 2016 Wenzel Jakob <wenzel.jakob@epfl.ch>, All rights reserved.\n\nRedistribution and use in source and binary forms, with or without\nmodification, are permitted provided that the following conditions are met:\n\n1. Redistributions of source code must retain the above copyright notice, this\n   list of conditions and the following disclaimer.\n\n2. Redistributions in binary form must reproduce the above copyright notice,\n   this list of conditions and the following disclaimer in the documentation\n   and/or other materials provided with the distribution.\n\n3. Neither the name of the copyright holder nor the names of its contributors\n   may be used to endorse or promote products derived from this software\n   without specific prior written permission.\n\nTHIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS \"AS IS\" AND\nANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED\nWARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE\nDISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE\nFOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL\nDAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR\nSERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER\nCAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY,\nOR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE\nOF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n\nPlease also refer to the file .github/CONTRIBUTING.md, which clarifies licensing of\nexternal contributions to this project including patches, pull requests, etc.\n\nSoftware: incubator-tvm 0.6\nCopyright notice: \nCopyright (c) 2019 by Contributors\nCOPYRIGHT (C) 2017 Institute of Electronics and Computer Science (EDI), Latvia.\nCopyright (c) 2018 by Contributors\nCopyright (c) 2009-2015 by llvm/compiler-rt contributors\nCopyright 2009-2010 Cybozu Labs, Inc.\nCopyright 2011-2014 Kazuho Oku\nCopyright 2019 The Apache Software Foundation\n© Contributors Licensed under an [Apache-2.0](LICENSE) license.\n©2015-2016 Cameron Desrochers.\nCopyright (c) 2015 Jeff Preshing\nCopyright (c) 2009-2019 by the contributors listed in CREDITS.TXT\nCopyright (c) 2009-2015 by the contributors listed in CREDITS.TXT\nCopyright (c) 2013-2016, Cameron Desrochers.\nCopyright 2017 by Contributors\n\nLicense: Apache License V2.0\n\n                             Apache License\n                       Version 2.0, January 2004\n                    http://www.apache.org/licenses/\n\nTERMS AND CONDITIONS FOR USE, REPRODUCTION, AND DISTRIBUTION\n\n1. Definitions.\n\n  \"License\" shall mean the terms and conditions for use, reproduction,\n  and distribution as defined by Sections 1 through 9 of this document.\n\n  \"Licensor\" shall mean the copyright owner or entity authorized by\n  the copyright owner that is granting the License.\n\n  \"Legal Entity\" shall mean the union of the acting entity and all\n  other entities that control, are controlled by, or are under common\n  control with that entity. For the purposes of this definition,\n  \"control\" means (i) the power, direct or indirect, to cause the\n  direction or management of such entity, whether by contract or\n  otherwise, or (ii) ownership of fifty percent (50%) or more of the\n  outstanding shares, or (iii) beneficial ownership of such entity.\n\n  \"You\" (or \"Your\") shall mean an individual or Legal Entity\n  exercising permissions granted by this License.\n\n  \"Source\" form shall mean the preferred form for making modifications,\n  including but not limited to software source code, documentation\n  source, and configuration files.\n\n  \"Object\" form shall mean any form resulting from mechanical\n  transformation or translation of a Source form, including but\n  not limited to compiled object code, generated documentation,\n  and conversions to other media types.\n\n  \"Work\" shall mean the work of authorship, whether in Source or\n  Object form, made available under the License, as indicated by a\n  copyright notice that is included in or attached to the work\n  (an example is provided in the Appendix below).\n\n  \"Derivative Works\" shall mean any work, whether in Source or Object\n  form, that is based on (or derived from) the Work and for which the\n  editorial revisions, annotations, elaborations, or other modifications\n  represent, as a whole, an original work of authorship. For the purposes\n  of this License, Derivative Works shall not include works that remain\n  separable from, or merely link (or bind by name) to the interfaces of,\n  the Work and Derivative Works thereof.\n\n  \"Contribution\" shall mean any work of authorship, including\n  the original version of the Work and any modifications or additions\n  to that Work or Derivative Works thereof, that is intentionally\n  submitted to Licensor for inclusion in the Work by the copyright owner\n  or by an individual or Legal Entity authorized to submit on behalf of\n  the copyright owner. For the purposes of this definition, \"submitted\"\n  means any form of electronic, verbal, or written communication sent\n  to the Licensor or its representatives, including but not limited to\n  communication on electronic mailing lists, source code control systems,\n  and issue tracking systems that are managed by, or on behalf of, the\n  Licensor for the purpose of discussing and improving the Work, but\n  excluding communication that is conspicuously marked or otherwise\n  designated in writing by the copyright owner as \"Not a Contribution.\"\n\n  \"Contributor\" shall mean Licensor and any individual or Legal Entity\n  on behalf of whom a Contribution has been received by Licensor and\n  subsequently incorporated within the Work.\n\n2. Grant of Copyright License. Subject to the terms and conditions of\n  this License, each Contributor hereby grants to You a perpetual,\n  worldwide, non-exclusive, no-charge, royalty-free, irrevocable\n  copyright license to reproduce, prepare Derivative Works of,\n  publicly display, publicly perform, sublicense, and distribute the\n  Work and such Derivative Works in Source or Object form.\n\n3. Grant of Patent License. Subject to the terms and conditions of\n  this License, each Contributor hereby grants to You a perpetual,\n  worldwide, non-exclusive, no-charge, royalty-free, irrevocable\n  (except as stated in this section) patent license to make, have made,\n  use, offer to sell, sell, import, and otherwise transfer the Work,\n  where such license applies only to those patent claims licensable\n  by such Contributor that are necessarily infringed by their\n  Contribution(s) alone or by combination of their Contribution(s)\n  with the Work to which such Contribution(s) was submitted. If You\n  institute patent litigation against any entity (including a\n  cross-claim or counterclaim in a lawsuit) alleging that the Work\n  or a Contribution incorporated within the Work constitutes direct\n  or contributory patent infringement, then any patent licenses\n  granted to You under this License for that Work shall terminate\n  as of the date such litigation is filed.\n\n4. Redistribution. You may reproduce and distribute copies of the\n  Work or Derivative Works thereof in any medium, with or without\n  modifications, and in Source or Object form, provided that You\n  meet the following conditions:\n\n  (a) You must give any other recipients of the Work or\n      Derivative Works a copy of this License; and\n\n  (b) You must cause any modified files to carry prominent notices\n      stating that You changed the files; and\n\n  (c) You must retain, in the Source form of any Derivative Works\n      that You distribute, all copyright, patent, trademark, and\n      attribution notices from the Source form of the Work,\n      excluding those notices that do not pertain to any part of\n      the Derivative Works; and\n\n  (d) If the Work includes a \"NOTICE\" text file as part of its\n      distribution, then any Derivative Works that You distribute must\n      include a readable copy of the attribution notices contained\n      within such NOTICE file, excluding those notices that do not\n      pertain to any part of the Derivative Works, in at least one\n      of the following places: within a NOTICE text file distributed\n      as part of the Derivative Works; within the Source form or\n      documentation, if provided along with the Derivative Works; or,\n      within a display generated by the Derivative Works, if and\n      wherever such third-party notices normally appear. The contents\n      of the NOTICE file are for informational purposes only and\n      do not modify the License. You may add Your own attribution\n      notices within Derivative Works that You distribute, alongside\n      or as an addendum to the NOTICE text from the Work, provided\n      that such additional attribution notices cannot be construed\n      as modifying the License.\n\n  You may add Your own copyright statement to Your modifications and\n  may provide additional or different license terms and conditions\n  for use, reproduction, or distribution of Your modifications, or\n  for any such Derivative Works as a whole, provided Your use,\n  reproduction, and distribution of the Work otherwise complies with\n  the conditions stated in this License.\n\n5. Submission of Contributions. Unless You explicitly state otherwise,\n  any Contribution intentionally submitted for inclusion in the Work\n  by You to the Licensor shall be under the terms and conditions of\n  this License, without any additional terms or conditions.\n  Notwithstanding the above, nothing herein shall supersede or modify\n  the terms of any separate license agreement you may have executed\n  with Licensor regarding such Contributions.\n\n6. Trademarks. This License does not grant permission to use the trade\n  names, trademarks, service marks, or product names of the Licensor,\n  except as required for reasonable and customary use in describing the\n  origin of the Work and reproducing the content of the NOTICE file.\n\n7. Disclaimer of Warranty. Unless required by applicable law or\n  agreed to in writing, Licensor provides the Work (and each\n  Contributor provides its Contributions) on an \"AS IS\" BASIS,\n  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or\n  implied, including, without limitation, any warranties or conditions\n  of TITLE, NON-INFRINGEMENT, MERCHANTABILITY, or FITNESS FOR A\n  PARTICULAR PURPOSE. You are solely responsible for determining the\n  appropriateness of using or redistributing the Work and assume any\n  risks associated with Your exercise of permissions under this License.\n\n8. Limitation of Liability. In no event and under no legal theory,\n  whether in tort (including negligence), contract, or otherwise,\n  unless required by applicable law (such as deliberate and grossly\n  negligent acts) or agreed to in writing, shall any Contributor be\n  liable to You for damages, including any direct, indirect, special,\n  incidental, or consequential damages of any character arising as a\n  result of this License or out of the use or inability to use the\n  Work (including but not limited to damages for loss of goodwill,\n  work stoppage, computer failure or malfunction, or any and all\n  other commercial damages or losses), even if such Contributor\n  has been advised of the possibility of such damages.\n\n9. Accepting Warranty or Additional Liability. While redistributing\n  the Work or Derivative Works thereof, You may choose to offer,\n  and charge a fee for, acceptance of support, warranty, indemnity,\n  or other liability obligations and/or rights consistent with this\n  License. However, in accepting such obligations, You may act only\n  on Your own behalf and on Your sole responsibility, not on behalf\n  of any other Contributor, and only if You agree to indemnify,\n  defend, and hold each Contributor harmless for any liability\n  incurred by, or claims asserted against, such Contributor by reason\n  of your accepting any such warranty or additional liability.\n\nEND OF TERMS AND CONDITIONS\n\nAPPENDIX: How to apply the Apache License to your work.\n\n  To apply the Apache License to your work, attach the following\n  boilerplate notice, with the fields enclosed by brackets \"{}\"\n  replaced with your own identifying information. (Don't include\n  the brackets!)  The text should be enclosed in the appropriate\n  comment syntax for the file format. We also recommend that a\n  file or class name and description of purpose be included on the\n  same \"printed page\" as the copyright notice for easier\n  identification within third-party archives.\n\nCopyright {yyyy} {name of copyright owner}\n\nLicensed under the Apache License, Version 2.0 (the \"License\");\nyou may not use this file except in compliance with the License.\nYou may obtain a copy of the License at\n\n   http://www.apache.org/licenses/LICENSE-2.0\n\nUnless required by applicable law or agreed to in writing, software\ndistributed under the License is distributed on an \"AS IS\" BASIS,\nWITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\nSee the License for the specific language governing permissions and\nlimitations under the License.\n\n------------------------------------------------------------------------------------\nThis product bundles various third-party components under other open source licenses.\nThis section summarizes those components and their licenses. See licenses/\nfor text of these licenses.\n\nApache Software Foundation License 2.0\n--------------------------------------\n\n3rdparty/bfloat16/bfloat16.cc\n3rdparty/dlpack\n3rdparty/dmlc-core\n\n\nBSD 2-clause License\n--------------------\n\n3rdparty/picojson\n3rdparty/dmlc-core/include/dmlc/concurrentqueue.h\n\n\nBSD 2-clause License + zlib License\n-----------------------------------\n\n3rdparty/dmlc-core/include/dmlc/blockingconcurrentqueue.h\n\n\nMIT License\n-----------\n\n3rdparty/cma\n3rdparty/compiler-rt/builtin_fp16.h\n\n\nThe Unlicense\n-------------\n\n3rdparty/rang\n\nSoftware: dlpack 0acb731e0e43d15deee27b66f10e4c5b4e667913\nCopyright notice: \nCopyright by contributors\nCopyright (c) 2017 by  Contributors\n\n\nLicense: Apache License V2.0\n                       Version 2.0, January 2004\n                    http://www.apache.org/licenses/\n\nTERMS AND CONDITIONS FOR USE, REPRODUCTION, AND DISTRIBUTION\n\n1. Definitions.\n\n  \"License\" shall mean the terms and conditions for use, reproduction,\n  and distribution as defined by Sections 1 through 9 of this document.\n\n  \"Licensor\" shall mean the copyright owner or entity authorized by\n  the copyright owner that is granting the License.\n\n  \"Legal Entity\" shall mean the union of the acting entity and all\n  other entities that control, are controlled by, or are under common\n  control with that entity. For the purposes of this definition,\n  \"control\" means (i) the power, direct or indirect, to cause the\n  direction or management of such entity, whether by contract or\n  otherwise, or (ii) ownership of fifty percent (50%) or more of the\n  outstanding shares, or (iii) beneficial ownership of such entity.\n\n  \"You\" (or \"Your\") shall mean an individual or Legal Entity\n  exercising permissions granted by this License.\n\n  \"Source\" form shall mean the preferred form for making modifications,\n  including but not limited to software source code, documentation\n  source, and configuration files.\n\n  \"Object\" form shall mean any form resulting from mechanical\n  transformation or translation of a Source form, including but\n  not limited to compiled object code, generated documentation,\n  and conversions to other media types.\n\n  \"Work\" shall mean the work of authorship, whether in Source or\n  Object form, made available under the License, as indicated by a\n  copyright notice that is included in or attached to the work\n  (an example is provided in the Appendix below).\n\n  \"Derivative Works\" shall mean any work, whether in Source or Object\n  form, that is based on (or derived from) the Work and for which the\n  editorial revisions, annotations, elaborations, or other modifications\n  represent, as a whole, an original work of authorship. For the purposes\n  of this License, Derivative Works shall not include works that remain\n  separable from, or merely link (or bind by name) to the interfaces of,\n  the Work and Derivative Works thereof.\n\n  \"Contribution\" shall mean any work of authorship, including\n  the original version of the Work and any modifications or additions\n  to that Work or Derivative Works thereof, that is intentionally\n  submitted to Licensor for inclusion in the Work by the copyright owner\n  or by an individual or Legal Entity authorized to submit on behalf of\n  the copyright owner. For the purposes of this definition, \"submitted\"\n  means any form of electronic, verbal, or written communication sent\n  to the Licensor or its representatives, including but not limited to\n  communication on electronic mailing lists, source code control systems,\n  and issue tracking systems that are managed by, or on behalf of, the\n  Licensor for the purpose of discussing and improving the Work, but\n  excluding communication that is conspicuously marked or otherwise\n  designated in writing by the copyright owner as \"Not a Contribution.\"\n\n  \"Contributor\" shall mean Licensor and any individual or Legal Entity\n  on behalf of whom a Contribution has been received by Licensor and\n  subsequently incorporated within the Work.\n\n2. Grant of Copyright License. Subject to the terms and conditions of\n  this License, each Contributor hereby grants to You a perpetual,\n  worldwide, non-exclusive, no-charge, royalty-free, irrevocable\n  copyright license to reproduce, prepare Derivative Works of,\n  publicly display, publicly perform, sublicense, and distribute the\n  Work and such Derivative Works in Source or Object form.\n\n3. Grant of Patent License. Subject to the terms and conditions of\n  this License, each Contributor hereby grants to You a perpetual,\n  worldwide, non-exclusive, no-charge, royalty-free, irrevocable\n  (except as stated in this section) patent license to make, have made,\n  use, offer to sell, sell, import, and otherwise transfer the Work,\n  where such license applies only to those patent claims licensable\n  by such Contributor that are necessarily infringed by their\n  Contribution(s) alone or by combination of their Contribution(s)\n  with the Work to which such Contribution(s) was submitted. If You\n  institute patent litigation against any entity (including a\n  cross-claim or counterclaim in a lawsuit) alleging that the Work\n  or a Contribution incorporated within the Work constitutes direct\n  or contributory patent infringement, then any patent licenses\n  granted to You under this License for that Work shall terminate\n  as of the date such litigation is filed.\n\n4. Redistribution. You may reproduce and distribute copies of the\n  Work or Derivative Works thereof in any medium, with or without\n  modifications, and in Source or Object form, provided that You\n  meet the following conditions:\n\n  (a) You must give any other recipients of the Work or\n      Derivative Works a copy of this License; and\n\n  (b) You must cause any modified files to carry prominent notices\n      stating that You changed the files; and\n\n  (c) You must retain, in the Source form of any Derivative Works\n      that You distribute, all copyright, patent, trademark, and\n      attribution notices from the Source form of the Work,\n      excluding those notices that do not pertain to any part of\n      the Derivative Works; and\n\n  (d) If the Work includes a \"NOTICE\" text file as part of its\n      distribution, then any Derivative Works that You distribute must\n      include a readable copy of the attribution notices contained\n      within such NOTICE file, excluding those notices that do not\n      pertain to any part of the Derivative Works, in at least one\n      of the following places: within a NOTICE text file distributed\n      as part of the Derivative Works; within the Source form or\n      documentation, if provided along with the Derivative Works; or,\n      within a display generated by the Derivative Works, if and\n      wherever such third-party notices normally appear. The contents\n      of the NOTICE file are for informational purposes only and\n      do not modify the License. You may add Your own attribution\n      notices within Derivative Works that You distribute, alongside\n      or as an addendum to the NOTICE text from the Work, provided\n      that such additional attribution notices cannot be construed\n      as modifying the License.\n\n  You may add Your own copyright statement to Your modifications and\n  may provide additional or different license terms and conditions\n  for use, reproduction, or distribution of Your modifications, or\n  for any such Derivative Works as a whole, provided Your use,\n  reproduction, and distribution of the Work otherwise complies with\n  the conditions stated in this License.\n\n5. Submission of Contributions. Unless You explicitly state otherwise,\n  any Contribution intentionally submitted for inclusion in the Work\n  by You to the Licensor shall be under the terms and conditions of\n  this License, without any additional terms or conditions.\n  Notwithstanding the above, nothing herein shall supersede or modify\n  the terms of any separate license agreement you may have executed\n  with Licensor regarding such Contributions.\n\n6. Trademarks. This License does not grant permission to use the trade\n  names, trademarks, service marks, or product names of the Licensor,\n  except as required for reasonable and customary use in describing the\n  origin of the Work and reproducing the content of the NOTICE file.\n\n7. Disclaimer of Warranty. Unless required by applicable law or\n  agreed to in writing, Licensor provides the Work (and each\n  Contributor provides its Contributions) on an \"AS IS\" BASIS,\n  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or\n  implied, including, without limitation, any warranties or conditions\n  of TITLE, NON-INFRINGEMENT, MERCHANTABILITY, or FITNESS FOR A\n  PARTICULAR PURPOSE. You are solely responsible for determining the\n  appropriateness of using or redistributing the Work and assume any\n  risks associated with Your exercise of permissions under this License.\n\n8. Limitation of Liability. In no event and under no legal theory,\n  whether in tort (including negligence), contract, or otherwise,\n  unless required by applicable law (such as deliberate and grossly\n  negligent acts) or agreed to in writing, shall any Contributor be\n  liable to You for damages, including any direct, indirect, special,\n  incidental, or consequential damages of any character arising as a\n  result of this License or out of the use or inability to use the\n  Work (including but not limited to damages for loss of goodwill,\n  work stoppage, computer failure or malfunction, or any and all\n  other commercial damages or losses), even if such Contributor\n  has been advised of the possibility of such damages.\n\n9. Accepting Warranty or Additional Liability. While redistributing\n  the Work or Derivative Works thereof, You may choose to offer,\n  and charge a fee for, acceptance of support, warranty, indemnity,\n  or other liability obligations and/or rights consistent with this\n  License. However, in accepting such obligations, You may act only\n  on Your own behalf and on Your sole responsibility, not on behalf\n  of any other Contributor, and only if You agree to indemnify,\n  defend, and hold each Contributor harmless for any liability\n  incurred by, or claims asserted against, such Contributor by reason\n  of your accepting any such warranty or additional liability.\n\nEND OF TERMS AND CONDITIONS\n\nAPPENDIX: How to apply the Apache License to your work.\n\n  To apply the Apache License to your work, attach the following\n  boilerplate notice, with the fields enclosed by brackets \"{}\"\n  replaced with your own identifying information. (Don't include\n  the brackets!)  The text should be enclosed in the appropriate\n  comment syntax for the file format. We also recommend that a\n  file or class name and description of purpose be included on the\n  same \"printed page\" as the copyright notice for easier\n  identification within third-party archives.\n\nCopyright 2017 by Contributors\n\nLicensed under the Apache License, Version 2.0 (the \"License\");\nyou may not use this file except in compliance with the License.\nYou may obtain a copy of the License at\n\n   http://www.apache.org/licenses/LICENSE-2.0\n\nUnless required by applicable law or agreed to in writing, software\ndistributed under the License is distributed on an \"AS IS\" BASIS,\nWITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\nSee the License for the specific language governing permissions and\nlimitations under the License.\n\n\nSoftware: dmlc-core 808f485387f9a03f78fa9f1159f387d0d91b7a28\nCopyright notice: \nCopyright by contributors\nCopyright (c) 2015-2018 by Contributors\nCopyright (c) 2017 by Contributors\nCopyright (c) 2013-2016, Cameron Desrochers.\nCopyright (c) 2018 by Contributors\ncopyright = u'2015, dmlc-core developers'\nCopyright (c) 2015 by Contributors\nCopyright (c) 2016 by Contributors\n©2015-2016 Cameron Desrochers.\n\n\nLicense: Apache License V2.0\nLicensed under the Apache License, Version 2.0 (the \"License\");\nyou may not use this file except in compliance with the License.\nYou may obtain a copy of the License at\n    \n   http://www.apache.org/licenses/LICENSE-2.0\n\nUnless required by applicable law or agreed to in writing, software\ndistributed under the License is distributed on an \"AS IS\" BASIS,\nWITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\nSee the License for the specific language governing permissions and\nlimitations under the License.\n\n\nSoftware: rang cabe04d6d6b05356fa8f9741704924788f0dd762\nCopyright notice: \n\n\nLicense: The Unlicense\nThis is free and unencumbered software released into the public domain.\n\nAnyone is free to copy, modify, publish, use, compile, sell, or\ndistribute this software, either in source code form or as a compiled\nbinary, for any purpose, commercial or non-commercial, and by any\nmeans.\n\nIn jurisdictions that recognize copyright laws, the author or authors\nof this software dedicate any and all copyright interest in the\nsoftware to the public domain. We make this dedication for the benefit\nof the public at large and to the detriment of our heirs and\nsuccessors. We intend this dedication to be an overt act of\nrelinquishment in perpetuity of all present and future rights to this\nsoftware under copyright law.\n\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND,\nEXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF\nMERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT.\nIN NO EVENT SHALL THE AUTHORS BE LIABLE FOR ANY CLAIM, DAMAGES OR\nOTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE,\nARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR\nOTHER DEALINGS IN THE SOFTWARE.\n\nFor more information, please refer to <http://unlicense.org>\n\nSoftware: google/protobuf 3.13.0\nCopyright 2008 Google Inc. All rights reserved.\nCopyright 2008 Google Inc. All rights reserved.\nCopyright 2007-2010 Baptiste Lepilleur Distributed under MIT license, or public domain if desired and recognized in your jurisdiction.\nCopyright 2007 Google Inc. All Rights Reserved.\nCopyright 2012 Google Inc. All rights reserved.\nCopyright 2014 Google Inc. All rights reserved.\nCopyright 2019 Google Inc. All rights reserved.\nCopyright 2008 Google Inc. All Rights Reserved.\ncopyright = u\"2008, Google LLC\"\nCopyright 2017 Google Inc. All rights reserved.\nCopyright 2008 Google Inc.\nCopyright 2015 Google Inc. All rights reserved.\nCopyright 2019 Google Inc. All rights reserved.\nCopyright (c) 2006, Google Inc.\nCopyright (c) 2007-2010 Baptiste Lepilleur\nCopyright 2017 Google Inc. All rights reserved.\nCopyright 2015 Google Inc. All rights reserved.\nCopyright 2018 Google Inc. All rights reserved.\nCopyright 2009 Google Inc. All rights reserved.\nCopyright 2007-2011 Baptiste Lepilleur Distributed under MIT license, or public domain if desired and recognized in your jurisdiction.\nCopyright 2011 Baptiste Lepilleur Distributed under MIT license, or public domain if desired and recognized in your jurisdiction.\n<Copyright>Copyright 2015, Google Inc.</Copyright>\nCopyright 2019 Google LLC. All rights reserved.\nCopyright 2016 Google Inc. All rights reserved.\nCopyright 2005 Google Inc.\nCopyright 2016 Google Inc. All rights reserved.\n\n\nLicense: BSD 3-Clause License\nPlease see above.\n\n\nSoftware: libjpeg-turbo 2.0.4\nCopyright notice:\nCopyright 2009 Pierre Ossman <ossman@cendio.se> for Cendio AB\nCopyright (C) 2011, Nokia Corporation and/or its subsidiary(-ies).\nCopyright (C) 2009-2011, 2013-2014, 2016, 2018, D. R. Commander.\nCopyright (C) 2015-2016, 2018, Matthieu Darbois.\nCopyright (C) 1999-2006, MIYASAKA Masaru.\nCopyright (C) 2014-2015, D. R. Commander.  All Rights Reserved.\nCopyright (C) 2014, Jay Foad.  All Rights Reserved.\nCopyright (C) 2014, D. R. Commander.  All Rights Reserved.\nCopyright (C) 2015, D. R. Commander.  All Rights Reserved.\nCopyright (C) 1991-1996, Thomas G. Lane.\nCopyright (C) 2009-2011, 2014-2016, 2018, D. R. Commander.\nCopyright (C) 2009 by Dimitri van Heesch.\nCopyright (C) 1994-1997, Thomas G. Lane.\nCopyright (C) 1991-1997, Thomas G. Lane.\nCopyright (C) 2017, D. R. Commander.\nCopyright (C) 1991-1998, Thomas G. Lane.\nCopyright (C) 2010, 2013-2014, 2017, D. R. Commander.\nCopyright (C) 2017-2018, D. R. Commander.\nCopyright (C) 2010-2011, 2013-2017, D. R. Commander.\nCopyright (C) 2015, Google, Inc.\nCopyright (C) 2015, 2018, D. R. Commander.\nCopyright (C) 1994-1998, Thomas G. Lane.\nCopyright (C) 1994-1996, Thomas G. Lane.\nCopyright (C) 2009-2012, 2015, D. R. Commander.\nCopyright (C) 2014, MIPS Technologies, Inc., California.\nCopyright (C) 2011, 2014-2015, D. R. Commander.\nCopyright (C) 2009-2011, 2014-2016, 2018-2019, D. R. Commander.\nCopyright (C) 2015, Matthieu Darbois.\nCopyright (C) 1997-1998, Thomas G. Lane, Todd Newman.\nCopyright (C) 2010, D. R. Commander.\nCopyright (C) 2010, 2016, 2018, D. R. Commander.\nCopyright (C) 1991-1994, Thomas G. Lane.\nCopyright (C) 2009-2011, 2018, D. R. Commander.\nCopyright (C) 1995-1997, Thomas G. Lane.\nCopyright (C) 2011, 2015, 2018, D. R. Commander.\nCopyright (C) 2016, 2018, Matthieu Darbois.\nCopyright (C) 2015, D. R. Commander.\nCopyright (C)2011 D. R. Commander.  All Rights Reserved.\nCopyright (C) 1995-1998, Thomas G. Lane.\nCopyright (C) 2016, D. R. Commander.\nCopyright (C) 2010, 2015-2018, D. R. Commander.\nCopyright (C) 2015-2018, D. R. Commander.\nCopyright (C) 2011, 2014, 2016, 2019, D. R. Commander.\nCopyright (C) 2013, 2016, D. R. Commander.\nCopyright (C) 2011, 2016, 2019, D. R. Commander.\nCopyright (C) 2010, 2015-2016, D. R. Commander.\nCopyright (C) 2013, Linaro Limited.\nCopyright (C) 2014-2015, D. R. Commander.\nCopyright (C) 2009, 2011, 2015, D. R. Commander.\nCopyright (C) 2009, 2011-2012, 2014-2015, D. R. Commander.\nCopyright (C) 2010, 2015, D. R. Commander.\nCopyright (C) 2013, MIPS Technologies, Inc., California.\nCopyright (C) 2009-2011, 2016, 2018-2019, D. R. Commander.\nCopyright (C) 2010-2011, 2015-2016, D. R. Commander.\nCopyright (C) 2010, 2016, D. R. Commander.\nCopyright (C) 2012, 2015, D. R. Commander.\nCopyright (C) 2009-2011, 2016, D. R. Commander.\nCopyright (C) 1991-1995, Thomas G. Lane.\nCopyright (C) 2009, 2011, 2014-2015, D. R. Commander.\nCopyright (C) 2014-2015, 2018, D. R. Commander.\nCopyright (C) 2011, 2015, D. R. Commander.\nCopyright (C) 2015-2016, 2018, D. R. Commander.\nCopyright (C) 2019, Arm Limited.\nCopyright (C) 2014, 2017, D. R. Commander.\nCopyright (C) 2014, D. R. Commander.\nCopyright (C) 1992-1996, Thomas G. Lane.\nCopyright (C) 1992-1997, Thomas G. Lane.\nCopyright (C) 2009, 2011, 2014-2015, 2018, D. R. Commander.\nCopyright (C) 2015-2016, D. R. Commander.\nCopyright (C) 2009-2011, 2013-2014, 2016-2017, D. R. Commander.\nCopyright (C) 1995-2010, Thomas G. Lane, Guido Vollbeding.\nCopyright (C) 2010, 2014, 2017, D. R. Commander.\nCopyright (C) 2009, 2015, D. R. Commander.\nCopyright (C) 2009, 2014-2015, D. R. Commander.\nCopyright (C) 2011, 2014, D. R. Commander.\nCopyright (C) 2009-2011, 2014, D. R. Commander.\nCopyright (C) 2013, D. R. Commander.\nCopyright (C) 1991-2012, Thomas G. Lane, Guido Vollbeding.\nCopyright (C) 2010, 2012-2019, D. R. Commander.\ncopyright or license text in that file.\nCopyright (C)2009-2019 D. R. Commander.  All Rights Reserved.\nCopyright (C)2015 Viktor Szathmáry.  All Rights Reserved.\nCopyright (C) 2015, 2017-2018, D. R. Commander.\nCopyright (C) 1988 by Jef Poskanzer.\nCopyright (C) 2015-2017, D. R. Commander.\nCopyright (C) 2010, 2018, D. R. Commander.\nCopyright (C) 2018, D. R. Commander.\nCopyright (C)2011-2012, 2014-2015, 2017, 2019 D. R. Commander.\nCopyright (C)2009-2014, 2017-2019 D. R. Commander.  All Rights Reserved.\nCopyright (C)2011, 2019 D. R. Commander.  All Rights Reserved.\nCopyright (C) 1997-2011, Thomas G. Lane, Guido Vollbeding.\nCopyright (C) 2010, 2017, D. R. Commander.\nCopyright (C)2011-2019 D. R. Commander.  All Rights Reserved.\nCopyright (C)2009-2015, 2017 D. R. Commander.  All Rights Reserved.\nCopyright (C) 2014-2015, 2017, 2019, D. R. Commander.\nCopyright (C) 2015, 2017, D. R. Commander.\nCopyright (C) 1989 by Jef Poskanzer.\nCopyright (C) 2017, 2019, D. R. Commander.\nCopyright (C) 2014-2015, 2019, D. R. Commander.  All Rights Reserved.\nCopyright (C) 2016-2018, Loongson Technology Corporation Limited, BeiJing.\nCopyright (C) 2011, 2014, D. R. Commander.  All Rights Reserved.\nCopyright (C) 2016-2017, Loongson Technology Corporation Limited, BeiJing.\nCopyright (C) 2015, 2018, D. R. Commander.  All Rights Reserved.\nCopyright (C) 2011, 2015, D. R. Commander.  All Rights Reserved.\nCopyright (C) 2014, 2018, D. R. Commander.  All Rights Reserved.\nCopyright (C) 2014-2015, 2018, D. R. Commander.  All Rights Reserved.\nCopyright (C) 2018, D. R. Commander.  All Rights Reserved.\nCopyright (C) 2009-2011, 2014, 2016, 2018, D. R. Commander.\nCopyright (C) 2013-2014, MIPS Technologies, Inc., California.\nCopyright (C) 2015, 2018, Matthieu Darbois.\nCopyright (C) 2019, D. R. Commander.  All Rights Reserved.\nCopyright (C)2018, D. R. Commander.  All Rights Reserved.\nCopyright (C)2018 D. R. Commander.  All Rights Reserved.\nCopyright (C)2013, 2016 D. R. Commander.  All Rights Reserved.\nCopyright (C)2016, 2018-2019 D. R. Commander.  All Rights Reserved.\nCopyright (C) 2019, Google LLC.\nCopyright (C)2011-2013, 2017-2018 D. R. Commander.  All Rights Reserved.\nCopyright (C)2011-2015, 2018 D. R. Commander.  All Rights Reserved.\nCopyright (C)2011, 2013 D. R. Commander.  All Rights Reserved.\nCopyright (C)2017-2018 D. R. Commander.  All Rights Reserved.\nCopyright (C)2011, 2018 D. R. Commander.  All Rights Reserved.\nCopyright (C)2011, 2013, 2018 D. R. Commander.  All Rights Reserved.\nCopyright (C)2011, 2013-2015 D. R. Commander.  All Rights Reserved.\nCopyright (C)2014, 2017 D. R. Commander.  All Rights Reserved.\nCopyright (C)2009-2014, 2016-2019 D. R. Commander.  All Rights Reserved.\nCopyright (C)2011-2012, 2014-2015, 2017-2018 D. R. Commander.\nCopyright (C)2011-2018 D. R. Commander.  All Rights Reserved.\nCopyright (C) 2018, Matthieu Darbois.\nCopyright 2016, 2019 D. R. Commander\nCopyright 2016 Dmitry Marakasov\nCopyright 2016 Roger Leigh\nCopyright 2015 Alex Turbov\nCopyright 2014 Rolf Eike Beer\nCopyright 2014 Daniele E. Domenichelli\nCopyright 2013 Dimitri John Ledkov\nCopyright 2011 Alex Neundorf\nCopyright 2011 Eric NOULARD\nCopyright 2011, 2013-2015 Kitware, Inc.\nCopyright 2011 Nikita Krupen'ko\nCopyright (C) 2011, 2014-2016, 2018, D. R. Commander.\nCopyright (C) 2014, Linaro Limited.\n\nLicense: libjpeg-turbo Licenses \nlibjpeg-turbo is covered by three compatible BSD-style open source licenses:\n\nThe IJG (Independent JPEG Group) License, which is listed in README.ijg\n\nThis license applies to the libjpeg API library and associated programs (any code inherited from libjpeg, and any modifications to that code.)\n\nThe Modified (3-clause) BSD License, which is listed below\n\nThis license covers the TurboJPEG API library and associated programs, as well as the build system.\n\nThe zlib License\n\nThis license is a subset of the other two, and it covers the libjpeg-turbo SIMD extensions.\n\nComplying with the libjpeg-turbo Licenses\nThis section provides a roll-up of the libjpeg-turbo licensing terms, to the best of our understanding.\n\nIf you are distributing a modified version of the libjpeg-turbo source, then:\n\nYou cannot alter or remove any existing copyright or license notices from the source.\n\nOrigin\n\nClause 1 of the IJG License\nClause 1 of the Modified BSD License\nClauses 1 and 3 of the zlib License\nYou must add your own copyright notice to the header of each source file you modified, so others can tell that you modified that file (if there is not an existing copyright header in that file, then you can simply add a notice stating that you modified the file.)\n\nOrigin\n\nClause 1 of the IJG License\nClause 2 of the zlib License\nYou must include the IJG README file, and you must not alter any of the copyright or license text in that file.\n\nOrigin\n\nClause 1 of the IJG License\nIf you are distributing only libjpeg-turbo binaries without the source, or if you are distributing an application that statically links with libjpeg-turbo, then:\n\nYour product documentation must include a message stating:\n\nThis software is based in part on the work of the Independent JPEG Group.\n\nOrigin\n\nClause 2 of the IJG license\nIf your binary distribution includes or uses the TurboJPEG API, then your product documentation must include the text of the Modified BSD License (see below.)\n\nOrigin\n\nClause 2 of the Modified BSD License\nYou cannot use the name of the IJG or The libjpeg-turbo Project or the contributors thereof in advertising, publicity, etc.\n\nOrigin\n\nIJG License\nClause 3 of the Modified BSD License\nThe IJG and The libjpeg-turbo Project do not warrant libjpeg-turbo to be free of defects, nor do we accept any liability for undesirable consequences resulting from your use of the software.\n\nOrigin\n\nIJG License\nModified BSD License\nzlib License\nThe Modified (3-clause) BSD License\nCopyright (C)2009-2019 D. R. Commander. All Rights Reserved. Copyright (C)2015 Viktor Szathmáry. All Rights Reserved.\n\nRedistribution and use in source and binary forms, with or without modification, are permitted provided that the following conditions are met:\n\nRedistributions of source code must retain the above copyright notice, this list of conditions and the following disclaimer.\nRedistributions in binary form must reproduce the above copyright notice, this list of conditions and the following disclaimer in the documentation and/or other materials provided with the distribution.\nNeither the name of the libjpeg-turbo Project nor the names of its contributors may be used to endorse or promote products derived from this software without specific prior written permission.\nTHIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS \"AS IS\", AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDERS OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n\nWhy Three Licenses?\nThe zlib License could have been used instead of the Modified (3-clause) BSD License, and since the IJG License effectively subsumes the distribution conditions of the zlib License, this would have effectively placed libjpeg-turbo binary distributions under the IJG License. However, the IJG License specifically refers to the Independent JPEG Group and does not extend attribution and endorsement protections to other entities. Thus, it was desirable to choose a license that granted us the same protections for new code that were granted to the IJG for code derived from their software.\n\nSoftware: cppjieba 5.0.3\nCopyright notice:\nCopyright 2005, Google Inc.\nCopyright 2008, Google Inc.\nCopyright 2007, Google Inc.\nCopyright 2008 Google Inc.\nCopyright 2006, Google Inc.\nCopyright 2003 Google Inc.\nCopyright 2009 Google Inc.\nCopyright (C) 1991-2, RSA Data Security, Inc. Created 1991. All\n\nSoftware: tinyxml2 8.0.0\nCopyright 2011, John Resig.\nCopyright 2011, The Dojo Foundation.\n\nSoftware: icu 69.1\nCopyright (C) 2000-2004, International Business Machines Corporation\nCopyright (C) 2002-2014, International Business Machines(C) Copyright IBM Corp. 1998-2011 - All Rights Reserved\nCopyright (C) 2003-2008, International Business Machines\nCopyright (C) 2005-2006, International Business Machines\nCopyright (C) 2016 and later: Unicode, Inc. and others.\nCopyright (c) 2001-2010 International Business Machines\nCopyright (C) 2009, International Business Machines\nCopyright (c) 2010-2015 International Business Machines Corporation and others. All rights reserved.\nCopyright (C) 2002-2015, International Business Machines verbatim (minus copyright and #include) and copied together into this file.\nCopyright (c) 1997-2014, International Business Machines Corporation and others. All Rights Reserved.\nCopyright (c) 1997-2008, International Business Machines Corporation and\nCopyright (c) 1997-2003, International Business Machines Corporation and\nCopyright (c) 1996-2012, International Business Machines Corporation and\nCopyright (c) 1997-2016, International Business Machines\nCopyright (c) 1997-2013 International Business Machines\nCopyright (c) 1997-2016, International Business Machines Corporation and\nCopyright (c) 1997-2001, International Business Machines Corporation and\nCopyright (c) 1997-2012, International Business Machines Corporation and\nCopyright (c) 1997-2005, International Business Machines Corporation and\nCopyright (c) 1997-2010, International Business Machines Corporation and\nCopyright (c) 2011-2016, International Business Machines Corporation\nCopyright (c) 1997-2009, International Business Machines Corporation and\nCopyright (c) 1997-2002,2008, International Business Machines Corporation and\nCopyright (c) 1997-2009,2014, International Business Machines\nCopyright (C) 2000-2009, International Business Machines\nCopyright (c) 1997-2015, International Business Machines Corporation and\nCopyright (c) 1997-2013, International Business Machines Corporation and\nCopyright (c) 2001-2016, International Business Machines Corporation and\nCopyright (c) 1997-2016, International Business Machines Corporation\nCopyright (c) 1997-2003, 2007-2009 International Business Machines Corporation and\nCopyright (c) 2011-2014, International Business Machines Corporation\nCopyright (c) 2003-2009, International Business Machines\nCopyright (c) 2016, International Business Machines Corporation\nCopyright (c) 1997-2004, International Business Machines Corporation and\nCopyright (C) 2002-2016, International Business Machines\nCopyright (C) 1998-2014, International Business Machines Corporation\nCopyright (c) 2003-2013, International Business Machines Corporation and\nCopyright (c) 2005-2016, International Business Machines Corporation and\nCopyright (c) 1999-2013, International Business Machines Corporation and\nCopyright (c) 2003-2015, International Business Machines Corporation and\nCopyright (C) 2003-2016, International Business Machines\nCopyright (C) 2003-2014, International Business Machines\nCopyright (C) 2003, International Business Machines\nCopyright (c) 1998-2016, International Business Machines Corporation and\nCopyright (c) 2004-2015, International Business Machines Corporation and\nCopyright (c) 2009-2016, International Business Machines Corporation and\nCopyright (C) 2003-2012, International Business Machines\nCopyright (c) 2000-2016, International Business Machines Corporation and\nCopyright (C) 2001-2014, International Business Machines\nCopyright (C) 2001-2016, International Business Machines\nCopyright (c) 1997-2014, International Business Machines © 2017 and later: Unicode, Inc. and others.\nCopyright (C) 2007-2016, International Business Machines © 2018 and later: Unicode, Inc. and others.\nCopyright (c) 2015, International Business Machines Corporation\nCopyright (c) 2014-2016, International Business Machines Corporation\nCopyright (c) 2002-2016, International Business Machines\nCopyright (c) 2001-2011,2015 International Business Machines\nCopyright (c) 2001-2016 International Business Machines\nCopyright (c) 2005-2013, International Business Machines Corporation and\nCopyright (c) 1998-2014, International Business Machines Corporation and\nCopyright (C) 1997-2016 International Business Machines\nCopyright (C) 2009-2014, International Business Machines Corporation and\nCopyright (c) 2002-2014, International Business Machines Corporation\nCopyright (c) 2002-2007, International Business Machines Corporation\nCopyright (C) 1996-2012, International Business Machines Corporation\nCopyright (C) 1996-2008, International Business Machines Corporation\nCopyright (C) 2007-2013, International Business Machines Corporation and\nCopyright (C) 2008-2015, International Business Machines\nCopyright (C) 2003-2013, International Business Machines Corporation and\nCopyright (C) 2003-2013, International Business Machines Corporation\nCopyright (C) 1997-2016, International Business Machines Corporation and\nCopyright (C) 2001-2011, International Business Machines\nCopyright (C) 2001-2008, International Business Machines\nCopyright (C) 2003 - 2009, International Business Machines Corporation and\nCopyright (C) 2003 - 2008, International Business Machines Corporation and\nCopyright (C) 2007-2014, International Business Machines Corporation\nCopyright (C) 2007-2013, International Business Machines Corporation\nCopyright (C) 1997-2013, International Business Machines Corporation and\nCopyright (C) 1996-2014, International Business Machines Corporation and\nCopyright (C) 2010-2014, International Business Machines\nCopyright (C) 2010-2015, International Business Machines\nCopyright (C) 2013-2014, International Business Machines\nCopyright (C) 1996-2015, International Business Machines\nCopyright (C) 1996-2014, International Business Machines\nCopyright (C) 2012-2015, International Business Machines\nCopyright (C) 2012-2014, International Business Machines\nCopyright (C) 2013-2015, International Business Machines\nCopyright (C) 2013-2016, International Business Machines\nCopyright (C) 1999-2016, International Business Machines\nCopyright (C) 1999-2015, International Business Machines\nCopyright (C) 1999-2014, International Business Machines\nCopyright (C) 2015-2016, International Business Machines Corporation and others.\nCopyright (C) 2003 - 2013, International Business Machines Corporation and\nCopyright (C) 1999-2011, International Business Machines\nCopyright (C) 2005-2016, International Business Machines\nCopyright (C) 2005-2012, International Business Machines\nCopyright (C) 2005-2015, International Business Machines\nCopyright (C) 2005-2013, International Business Machines\nCopyright (C) 2005-2014, International Business Machines\nCopyright (c) 2004, International Business Machines\nCopyright (c) 2004-2014 International Business Machines\nCopyright (c) 2004-2014, International Business Machines\nCopyright (C) 2013, International Business Machines Corporation\nCopyright (C) 1997-2015, International Business Machines Corporation and\nCopyright (C) 2016, International Business Machines\nCopyright (c) IBM Corporation, 2000-2012. All rights reserved.\nCopyright (c) IBM Corporation, 2000-2011. All rights reserved.\nCopyright (c) IBM Corporation, 2000-2014. All rights reserved.\nCopyright (c) IBM Corporation, 2000-2010. All rights reserved.\nCopyright (c) IBM Corporation, 2000-2016. All rights reserved.\nCopyright 2010 the V8 project authors. All rights reserved.\nCopyright 2006-2008 the V8 project authors. All rights reserved.\nCopyright 2012 the V8 project authors. All rights reserved.\nCopyright (C) 2008-2016, International Business Machines Corporation and\nCopyright (C) 2007-2016, International Business Machines Corporation and\nCopyright (C) 2007-2012, International Business Machines Corporation and\nCopyright (c) 2001-2011, International Business Machines\nCopyright (c) 2001-2007, International Business Machines\nCopyright (C) 2010-2014, International Business Machines Corporation and\nCopyright (C) 1997-2010, International Business Machines Corporation and\nCopyright (C) 1997-2012, International Business Machines Corporation and\nCopyright (C) 2009-2015, International Business Machines Corporation and\nCopyright (C) 2009-2012, International Business Machines Corporation and\nCopyright (c) 2002-2012, International Business Machines Corporation\nCopyright (c) 2002-2011, International Business Machines Corporation\nCopyright (C) 2008-2013, International Business Machines Corporation and\nCopyright (c) 2003-2008, International Business Machines\nCopyright (C) 2003-2016, International Business Machines Corporation\nCopyright (C) 2003-2014, International Business Machines Corporation\nCopyright (C) 2003-2008, International Business Machines Corporation\nCopyright (C) 2005-2008, International Business Machines\nCopyright (C) 2003-2015, International Business Machines Corporation\nCopyright (C) 2003-2009,2012,2016 International Business Machines Corporation and\nCopyright (c) 2004-2016, International Business Machines © 2020 and later: Unicode, Inc. and others.\nCopyright (C) 2007-2008, International Business Machines Corporation and\nCopyright (C) 2001-2007, International Business Machines\nCopyright (C) 1997-2012, International Business Machines\nCopyright (C) 1997-2015, International Business Machines\nCopyright (C) 2001-2010, International Business Machines\nCopyright (c) 2000-2005, International Business Machines\nCopyright (c) 2000-2007, International Business Machines © 2019 and later: Unicode, Inc. and others.\nCopyright (C) 2010-2015, International Business Machines Corporation and\nCopyright (C) 2015, International Business Machines Corporation and\nCopyright (c) 2003-2013, International Business Machines\nCopyright (C) 2001-2012, International Business Machines\nCopyright (C) 2001-2011, International Business Machines Corporation\nCopyright (C) 2014-2016, International Business Machines\nCopyright (C) 1997-2015, International Business Machines Corporation\nCopyright (C) 1999-2007, International Business Machines\nCopyright (C) 1999-2007, International Business Machines Corporation\nCopyright (C) 1999-2011, International Business Machines Corporation\nCopyright (C) {1999-2001}, International Business Machines Corporation and others. All Rights Reserved.\nCopyright (C) 2002-2016 International Business Machines Corporation and others.\nCopyright (C) 2002-2016, International Business Machines Corporation and others.\nCopyright (C) 2002-2016 International Business Machines Corporation\nCopyright (C) 2002-2015, International Business Machines Corporation and others.\nCopyright (C) 2012 International Business Machines Corporation\nCopyright (C) 2002-2015 International Business Machines Corporation\nCopyright (C) 2004-2015, International Business Machines Corporation and others.\nCopyright (C) 2003-2010, International Business Machines Corporation and others.\nCopyright (c) 2008-2011, International Business Machines Corporation and\nCopyright (c) 2008-2010, International Business Machines Corporation and\nCopyright (C) 2014-2016, International Business Machines Corporation and\nCopyright (C) 2013, International Business Machines Corporation and\nCopyright (c) 2014, International Business Machines\nCopyright (C) 2014, International Business Machines\nCopyright (C) 2013, International Business Machines\nCopyright (C) 2001-2008,2010 IBM and others. All rights reserved.\nCopyright (C) 2010 , Yahoo! Inc.\nCopyright (c) 1997-2011, International Business Machines Corporation and\nCopyright (C) 2013-2014, International Business Machines Corporation and\nCopyright (C) 2009-2013, International Business Machines Corporation and\nCopyright (C) 1996-2012, International Business Machines Corporation and\nCopyright (C) 2015, International Business Machines Corporation\nCopyright (c) 2001-2012, International Business Machines Corporation\nCopyright (C) 2001-2014 IBM and others. All rights reserved.\nCopyright (C) 2008-2014, Google, International Business Machines Corporation and\nCopyright (C) 2008, Google, International Business Machines Corporation and\nCopyright (C) 2008-2015, Google, International Business Machines Corporation\nCopyright (c) 2001-2014, International Business Machines\nCopyright (c) 2002-2010, International Business Machines Corporation\nCopyright (C) 2011-2015, International Business Machines Corporation and\nCopyright (C) 2011-2016, International Business Machines Corporation and\nCopyright (C) 2011-2012, International Business Machines Corporation and\nCopyright (C) 1996-2016, International Business Machines\nCopyright (C) 1998-2014, International Business Machines\nCopyright (C) 2004-2016, International Business Machines\nCopyright (C) 2010-2011, International Business Machines\nCopyright (C) 2009-2015, International Business Machines\nCopyright (C) 2015, International Business Machines\nCopyright (C) 2012-2016, International Business Machines\nCopyright (C) 1999-2012, International Business Machines\nCopyright (C) 2001, International Business Machines\nCopyright (C) 2013, International Business Machines Corporation and others.\nCopyright (C) 2010-2012, International Business Machines\nCopyright (C) 2004-2015, International Business Machines\nCopyright (C) 2003-2006, International Business Machines\nCopyright (C) 2013-2015, International Business Machines Corporation and others.\nCopyright (C) 2001-2015 IBM and others. All rights reserved.\nCopyright (C) 2008-2015, International Business Machines Corporation\nCopyright (C) 2008-2016, International Business Machines\nCopyright (C) 2008-2013, International Business Machines Corporation\nCopyright (C) 2004-2012, International Business Machines Corporation and\nCopyright (C) 1997-2009,2014 International Business Machines\nCopyright (C) 2009-2011, International Business Machines Corporation and\nCopyright (C) 2009-2016, International Business Machines Corporation and\nCopyright (C) 2009-2013, International Business Machines\nCopyright (C) 2008-2011, International Business Machines\nCopyright (C) 2007-2014, International Business Machines Corporation and\nCopyright (C) 2009-2010, International Business Machines Corporation and\nCopyright (C) 2001-2016 International Business Machines Corporation\nCopyright (c) 2002-2011, International Business Machines\nCopyright (C) 2001-2012 IBM, Inc. All Rights Reserved.\nCopyright (c) 2013-2016 International Business Machines Corporation and others. All rights reserved.\nCopyright (c) 2013-2015 International Business Machines Corporation and others. All rights reserved.\nCopyright (c) 2007-2012, International Business Machines Corporation and\nCopyright (c) 2007-2012, International Business Machines\nCopyright (C) 2010, International Business Machines\nCopyright (C) 1997-2011, International Business Machines\nCopyright (C) 1997-2005, International Business Machines\nCopyright (C) 2009-2011, International Business Machines\nCopyright (C) 2003-2015, International Business Machines\nCopyright (C) 2009-2016, International Business Machines\nCopyright (C) 2008-2012, International Business Machines\nCopyright (C) 2008, International Business Machines\nCopyright (C) 2011-2014, International Business Machines\nCopyright (C) 2011-2013, International Business Machines\nCopyright (C) 2005, International Business Machines\nCopyright (C) 1999-2013, International Business Machines\nCopyright (C) 1998-2016, International Business Machines\nCopyright (c) 2007-2014, International Business Machines Corporation and\nCopyright (C) 2003-2013, International Business Machines\nCopyright (c) 2007-2016, International Business Machines Corporation and\nCopyright (c) 2008-2015, International Business Machines\nCopyright (C) 1999-2010, International Business Machines\nCopyright (C) 2000-2015, International Business Machines\nCopyright (C) 2000-2011, International Business Machines\nCopyright (C) 2000-2012, International Business Machines\nCopyright (C) 2000-2010, International Business Machines\nCopyright (C) 2004-2010, International Business Machines\nCopyright (C) 2004-2005, International Business Machines\nCopyright (c) 2013-2014, International Business Machines\nCopyright (c) 1991-2013 Unicode, Inc. © 2019 Unicode®, Inc.\nCopyright (C) 2018 and later: Unicode, Inc. and others.\nCopyright (c) 2008-2013 International Business Machines\nCopyright (C) 2002-2010, International Business Machines\nCopyright (c) 2012-2015 International Business Machines © 2020 Unicode®, Inc.\nCopyright (c) 2005-2013 IBM Corporation and others. All rights reserved\nCopyright (c) 2011-2012, International Business Machines Corporation and\nCopyright (C) 1998-2000, International Business Machines © 2017 Unicode®, Inc.\nCopyright (c) 2007-2015 International Business Machines\nCopyright (C) 2004-2006, International Business Machines\nCopyright (C) 2003-2005, International Business Machines\nCopyright (c) 1999-2014 International Business Machines\nCopyright (c) 2003, International Business Machines\nCopyright (C) 2014 International Business Machines\nCopyright (c) 2001-2003 International Business Machines\nCopyright (c) 2004-2011 International Business Machines\nCopyright (C) 2015-2016, International Business Machines\nCopyright (c) 2001-2015 International Business Machines\nCopyright (C) 2003-2012, International Business Machines Corporation and COPYRIGHT AND PERMISSION NOTICE\nCopyright (c) 2003 National Electronics and Computer Technology Center and others\nCopyright (C) 2005-2010, International Business Machines\nCopyright (c) 2007-2009 IBM Corporation and others. All rights reserved\nCopyright (C) 2004-2016 International Business Machines\nCopyright (C) 1998-2013, International Business Machines\nCopyright (C) 1998-2010, International Business Machines\nCopyright (c) 1999-2004, International Business Machines\nCopyright (C) 2002-2006 International Business Machines Corporation\nCopyright (C) 1999-2006, International Business Machines\nCopyright (C) 2002-2016 IBM, Inc. All Rights Reserved.\nCopyright (c) 2002-2006, International Business Machines(C) Copyright IBM Corp. 1998-2007 - All Rights Reserved\nCopyright (C) 1999-2003, International Business Machines\nCopyright (C) 1998-2006, International Business Machines Corporation and\nCopyright (C) 1998-2003, International Business Machines Corporation and\nCopyright (C) 2003 - 2008, International Business Machines\nCopyright (C) 1999-2008, International Business Machines\nCopyright (C) 1999-2001, International Business Machines\nCopyright (C) 1999-2005, International Business Machines\nCopyright (C) 2016 and later: Unicode, Inc. and others.\nCopyright (c) 2001-2010 IBM Corporation and others. All Rights Reserved.\nCopyright (C) 1998-2005, International Business Machines Corporation and\nCopyright (C) 1998-2001, International Business Machines Corporation and\nCopyright (c) 2002-2005, International Business Machines Corporation and others. All Rights Reserved.\nCopyright (C) 2000-2014, International Business Machines\nCopyright (C) 1996-2013, International Business Machines\nCopyright (c) 2002-2006, International Business Machines Corporation and\nCopyright (c) 2004-2010, International Business Machines Corporation and\nCopyright (C) 2004-2011, International Business Machines\nCopyright (c) 2002-2005, International Business Machines Corporation and\nCopyright (c) 2002-2014, International Business Machines\nCopyright (c) 1997-2012, International Business Machines\nCopyright (c) 2002-2008, International Business Machines Corporation and others. All Rights Reserved.\nCopyright (C) 2011-2013, Apple Inc.; Unicode, Inc.; and others. All Rights Reserved.\nCopyright (C) 2011-2013, Apple Inc. and others. All Rights Reserved.\nCopyright (c) 2005-2007,2010 Apple Inc., Unicode Inc.,and others. All Rights Reserved.\nCopyright (c) 1999-2003, International Business Machines Corporation and\nCopyright (c) 2003-2014, International Business Machines\nCopyright (c) 2002-2010, International Business Machines Corporation and others. All Rights Reserved.\nCopyright (c) 1999-2010, International Business Machines Corporation and\nCopyright (c) 1999-2002, International Business Machines Corporation and\nCopyright (C) 2002-2003, International Business Machines\nCopyright (C) 2002, International Business Machines\nCopyright (c) 2007, International Business Machines Corporation and\nCopyright (C) 2007, International Business Machines\nCopyright (C) 2001-2006, International Business Machines\nCopyright (C) 2010-2014, International Business Machines Corporation and others.\nCopyright (C) 2005-2016, International Business Machines Corporation and\nCopyright (C) 2015-2016, International Business Machines Corporation and\nCopyright (C) 2008-2012, International Business Machines Corporation\nCopyright (c) 2006-2015 International Business Machines Corporation and others. All rights reserved.\nCopyright (c) 2014-2015 International Business Machines Corporation and others. All rights reserved.\nCopyright (C) 2002-2011, International Business Machines\nCopyright (c) 2003-2010, International Business Machines Corporation and others. All Rights Reserved.\nCopyright (C) 2012 IBM Corporation and Others. All Rights Reserved.\nCopyright (C) 1998-2012, International Business Machines Corporation\nCopyright (c) 2009, International Business Machines Corporation and\nCopyright (C) The Internet Society (2002). All Rights Reserved.\nCopyright (c) 2015, International Business Machines Corporation and\nCopyright (c) 2002, International Business Machines Corporation and others. All Rights Reserved.\nCopyright (C) 1998-2016, International Business Machines Corporation\nCopyright (c) 2011-2016,International Business Machines\nCopyright (C) 2012 International Business Machines Corporation and Others. All Rights Reserved.\nCopyright (C) 2011, International Business Machines Corporation and others. All Rights Reserved.\nCopyright (C) 2011, International Business Machines Corporation and others. All Rights Reserved.\nCopyright (c) 2011-2012,International Business Machines\nCopyright (c) 2007, International Business Machines Corporation and others. All Rights Reserved.\nCopyright (C) 2007-2007, International Business Machines(C) Copyright IBM Corp. 1998-2014 - All Rights Reserved\nCopyright (C) 1998-2002, International Business Machines\nCopyright (c) 2001-2007, International Business Machines Corporation and others. All Rights Reserved.(C) Copyright IBM Corp. 1998-2013 - All Rights Reserved\nCopyright (C) 1998-2015, International Business Machines\nCopyright (C) 2001-2014 International Business Machines\nCopyright (C) 2011-2016, International Business Machines\nCopyright (C) 2011-2015, International Business Machines\nCopyright (c) 1999-2014, International Business Machines Corporation and\nCopyright (c) 1999-2009, International Business Machines Corporation and\nCopyright (c) 2010,International Business Machines\nCopyright (c) 2010-2016,International Business Machines\nCopyright (c) 2002-2005, International Business Machines\nCopyright (C) 2000-2003, International Business Machines\nCopyright (c) 2008-2014, International Business Machines Corporation and\nCopyright (C) 2001 - 2005, International Business Machines\nCopyright (C) 2001-2005, International Business Machines\nCopyright (C) 1995-2014, International Business Machines\nCopyright (c) 2000-2004 IBM, Inc. and Others.\nCopyright (c) 2002-2014, International Business Machines Corporation and\nCopyright (c) 2007-2013, International Business Machines Corporation and\nCopyright (c) 2002-2012, International Business Machines Corporation and\nCopyright (C) 2002-2012, International Business Machines\nCopyright (C) 2009-2011, International Business Machines Corporation, Google and Others.\nCopyright (c) 2002, International Business Machines Corporation and others. All Rights Reserved.\nCopyright (C) 2009-2014, International Business Machines\nCopyright (C) 2008, International Business Machines Corporation and others.\nCopyright (C) 2000-2016, International Business Machines\nCopyright (C) 2011-2014 International Business Machines\nCopyright (C) 1997-2014, International Business Machines\nCopyright (C) 1997-2013, International Business Machines\nCopyright (c) 2004-2006, International Business Machines\nCopyright (C) 1997-2016, International Business Machines\nCopyright (C) 1997-2006, International Business Machines\nCopyright (C) 1997-2011, International Business Machines Corporation and others.\nCopyright (C) 1997-2013, International Business Machines Corporation and others.\nCopyright (c) 2004-2015, International Business Machines\nCopyright (C) 2009-2017, International Business Machines Corporation,Google, and others. All Rights Reserved.\nCopyright (C) 1997-2016, International Business Machines Corporation and others.\nCopyright (C) 2008-2015, International Business Machines Corporation and\nCopyright (C) 1997-2015, International Business Machines Corporation and others.\nCopyright (C) 2014-2016, International Business Machines Corporation and others.\nCopyright (c) 2014-2016, International Business Machines\nCopyright (C) 2001-2011 IBM and others. All rights reserved.\nCopyright (C) 1996-2014, International Business Machines Corporation and others.\nCopyright (C) 1996-2016, International Business Machines Corporation and\nCopyright (C) 2009-2016, International Business Machines Corporation,\nCopyright (C) 2009-2010, Google, International Business Machines Corporation and\nCopyright (C) 2008-2014, Google, International Business Machines Corporation\nCopyright (C) 1996-2015, International Business Machines Corporation and\nCopyright (c) 1996-2015, International Business Machines Corporation and others.\nCopyright (C) 2010-2012,2015 International Business Machines\nCopyright (C) 2007-2015, International Business Machines\nCopyright (C) 2013-2014, International Business Machines Corporation and others.\nCopyright (C) 2010-2013, International Business Machines\nCopyright (c) 2002-2005, International Business Machines Corporation\nCopyright (C) 2001-2011,2014 IBM and others. All rights reserved.\nCopyright (C) 2008-2016, International Business Machines Corporation\nCopyright (C) 2004 - 2008, International Business Machines Corporation and\nCopyright (C) 1997-2011,2014-2015 International Business Machines\nCopyright (C) 2001-2003, International Business Machines\nCopyright (C) 1999-2009, International Business Machines\nCopyright (C) 2020 and later: Unicode, Inc. and others.\nCopyright (c) 2002, International Business Machines Corporation and\nCopyright (C) 2000-2008, International Business Machines\nCopyright (C) 1998-2006, International Business Machines\nCopyright (C) 1998-2001, International Business Machines Corporation\nCopyright (C) 1998-2004, International Business Machines Corporation\nCopyright (C) 2000, International Business Machines\nCopyright (c) 1999-2016, International Business Machines Corporation and\nCopyright (c) 2015, International Business Machines Corporation and others. All Rights Reserved.\nCopyright (c) 1999-2012, International Business Machines Corporation and\nCopyright (C) 1998-2011, International Business Machines\nCopyright (C) 2008-2014, International Business Machines Corporation and\nCopyright (C) 2003-2004, International Business Machines\nCopyright (c) 2003-2005, International Business Machines Corporation and others. All Rights Reserved.\nCopyright (C) 2002-2006 IBM, Inc. All Rights Reserved.\nCopyright (C) 2004-2008, International Business Machines\nCopyright (c) 2002-2016 International Business Machines Corporation and\nCopyright (c) 2002-2015, International Business Machines Corporation and\nCopyright (C) 2002-2016, International Business Machines Corporation\nCopyright (c) 2002-2010,International Business Machines\nCopyright (c) 2002-2014,International Business Machines\nCopyright (c) 2002-2016,International Business Machines\nCopyright (C) 2016 International Business Machines Corporation\nCopyright © 2019 and later: Unicode, Inc. and others.\nCopyright (c) 2016, International Business Machines Corporation and others. All Rights Reserved.\nCopyright (c) 2016 International Business Machines Corporation and others. All Rights Reserved.\nCopyright (c) 2015-2016, International Business Machines Corporation and others. All Rights Reserved.\nCopyright (c) 2005-2006, International Business Machines Corporation and\nCopyright (c) 1997-2004, International Business Machines Corporation\nCopyright (c) 2012-2016, International Business Machines Corporation\nCopyright (c) 2012-2014, International Business Machines Corporation and\nCopyright (c) 1997-2014, International Business Machines Corporation\nCopyright (c) 1996-2016, International Business Machines Corporation and\nCopyright (c) 2003-2013, International Business Machines Corporation\nCopyright (c) 2003-2008, International Business Machines Corporation\nCopyright (c) 1997-2015, International Business Machines Corporation\nCopyright (c) 2002-2016, International Business Machines Corporation and\nCopyright (c) 1997-2002, International Business Machines Corporation and\nCopyright (C) 1996-2012, International Business Machines\nCopyright (c) 1997-2013 International Business Machines Corporation and\nCopyright (c) 2010-2012, International Business Machines Corporation and\nCopyright (c) 1997-2011, International Business Machines Corporation\nCopyright (c) 1997-2006, International Business Machines Corporation and\nCopyright (c) 2008-2016 International Business Machines Corporation and\nCopyright (c) 2008-2016, International Business Machines Corporation and\nCopyright (c) 1997-2016 International Business Machines Corporation and\nCopyright (c) 2007-2011, International Business Machines\nCopyright (c) 2007-2010, International Business Machines\nCopyright (C) 2001-2016, International Business Machines Corporation and\nCopyright (C) 2001-2003, International Business Machines Corporation and\nCopyright (C) 2003-2011, International Business Machines\nCopyright (c) 1997-2007, International Business Machines Corporation and\nCopyright (c) 1997-2015, International Business Machines\nCopyright (C) 2004-2009, International Business Machines Corporation and\nCopyright (C) 2004, International Business Machines Corporation and\nCopyright (C) 1996-2009, International Business Machines Corporation and\nCopyright (C) 1996-2006, International Business Machines Corporation and\nCopyright (C) 2011-2013, International Business Machines Corporation\nCopyright (C) 2000-2007, International Business Machines\nCopyright (c) 2001, International Business Machines Corporation and\nCopyright (C) 2012-2013, International Business Machines\nCopyright (c) 2010-2016, International Business Machines Corporation and\nCopyright (c) 2010-2016, International Business Machines Corporation\nCopyright (c) 1997-2010, International Business Machines Corporation\nCopyright (c) 1997-2003, International Business Machines\nCopyright (C) 2014-2015, International Business Machines Corporation and\nCopyright (c) 1997-2013, International Business Machines Corporation\nCopyright (c) 1999-2016, International Business Machines\nCopyright (c) 1999-2016 International Business Machines Corporation and\nCopyright (c) 2016, International Business Machines Corporation and\nCopyright (c) 2016, International Business Machines\nCopyright (c) 2013-2016, International Business Machines Corporation\nCopyright (c) 2013, International Business Machines Corporation\nCopyright (C) 2013-2016, International Business Machines Corporation and\nCopyright (c) 2001-2010, International Business Machines Corporation and\nCopyright (C) 2014, International Business Machines Corporation and\nCopyright (c) 1999-2015, International Business Machines Corporation and\nCopyright (C) 2001-2016, International Business Machines orporation\nCopyright (c) 2001-2008, International Business Machines Corporation and others\nCopyright (C) 2003-2016, International Business Machines Corporation and\nCopyright (c) 2004, International Business Machines Corporation\nCopyright (C) 2001-2009, International Business Machines\nCopyright (c) 2004,2011 International Business Machines\nCopyright (c) 2004-2011, International Business Machines\nCopyright (c) 2000-2016, International Business Machines Corporation\nCopyright (c) 2001-2005, International Business Machines Corporation and\nCopyright (C) 2001-2004, International Business Machines\nCopyright (c) 2001-2009, International Business Machines\nCopyright (c) 1997-2009, International Business Machines Corporation\nCopyright (c) 1997-2013, International Business Machines\nCopyright (c) 1997-2012, International Business Machines Corporation\nCopyright (C) 2007-2015, International Business Machines Corporation and\nCopyright (C) 2007-2011, International Business Machines Corporation and\nCopyright (C) 2007, International Business Machines Corporation and\nCopyright (c) 1998-2005, International Business Machines Corporation and\nCopyright (c) 2002-2010, International Business Machines Corporation and\nCopyright (C) 1999-2016 International Business Machines Corporation and\nCopyright (c) 2004-2011, International Business Machines Corporation and\nCopyright (c) 2002-2007, International Business Machines Corporation and\nCopyright (C) 2003, International Business Machines Corporation and\nCopyright (C) 2005-2011, International Business Machines\nCopyright (C) 2011-2012, International Business Machines\nCopyright (C) 2007-2012, International Business Machines\nCopyright (C) 2006-2016, International Business Machines Corporation\nCopyright (C) 2006-2012, International Business Machines Corporation and others.\nCopyright 2007 Google Inc. All Rights Reserved.\nCopyright (c) 2001-2015, International Business Machines\nCopyright (C) 2006-2014, International Business Machines Corporation\nCopyright (C) 2008, International Business Machines Corporation and\nCopyright (C) 2009-2012, International Business Machines\nCopyright (C) 2006 International Business Machines Corporation\nCopyright (C) 2010-2016, International Business Machines Corporation and\nCopyright (C) 2002-2014, International Business Machines Corporation and\nCopyright (C) 2002-2005, International Business Machines Corporation and\nCopyright (C) 2011, International Business Machines\nCopyright (c) 2003-2010 International Business Machines\nCopyright (C) 2003-2003, International Business Machines\nCopyright (C) 1999-2016 International Business Machines Corporation\nCopyright (C) 1999-2014 International Business Machines Corporation\nCopyright (C) 1999-2014 International Business Machines\nCopyright (C) 2002-2011, International Business Machines Corporation and others.\nCopyright (C) 2002-2008, International Business Machines Corporation and others.\nCopyright (C) 2002-2008 International Business Machines Corporation\nCopyright (c) 2001-2005, International Business Machines\nCopyright (C) 2002-2014 International Business Machines Corporation\nCopyright (c) 2003-2011, International Business Machines\nCopyright (C) 1998-2012, International Business Machines Corporation and\nCopyright (C) 2001-2014, International Business Machines Corporation.\nCopyright (C) 2001-2011, International Business Machines Corporation.\nCopyright (C) 2001-2014, International Business Machines Corporation and\nCopyright (C) 2001-2011, International Business Machines Corporation and\nCopyright (C) 2001-2012, International Business Machines Corporation and\nCopyright 2004 and onwards Google Inc.\nCopyright (C) 2004-2014, International Business Machines\nCopyright (C) 2006, International Business Machines\nCopyright (C) 2004-2012, International Business Machines\nCopyright (C) 2001-2013, International Business Machines\nCopyright (C) 1998-2004, International Business Machines\nCopyright (C) 2000-2013, International Business Machines\nCopyright (C) 1999-2015 International Business Machines\nCopyright (C) 2000-2006, International Business Machines\nCopyright (C) 1999-2004, International Business Machines\nCopyright (C) 2003-2007, International Business Machines\nCopyright (C) 2002-2006, International Business Machines\nCopyright (C) 2001-2015, International Business Machines\nCopyright (c) 2001-2012, International Business Machines\nCopyright (c) 2002-2004, International Business Machines\nCopyright (C) 1999-2016, International Business Machines Corporation and\nCopyright (c) 1996-2014, International Business Machines\nCopyright (C) 1999-2016, International Business Machines Corporation\nCopyright (C) 2009-2014 International Business Machines\nCopyright (C) 2004-2007, International Business Machines\nCopyright (c) 2001-2016, International Business Machines\nCopyright (C) 2003-2009, International Business Machines\nCopyright (C) 1999-2013, International Business Machines Corporation and\nCopyright (C) 1999-2015, International Business Machines Corporation and\nCopyright (c) 2002-2011, International Business Machines Corporation and others. All Rights Reserved.\nCopyright (C) 2001-2016 IBM, Inc. All Rights Reserved.\nCopyright (C) 1999-2016 International Business Machines\nCopyright (C) 2009-2010 IBM Corporation and Others. All Rights Reserved.\nCopyright (C) 1998-2012, International Business Machines\nCopyright (C) 1991 and later: Unicode, Inc. and others.\nCopyright (C) 1997-2000, International Business Machines\nCopyright (c) 1999-2007, International Business Machines Corporation and\nCopyright (c) 2000 IBM, Inc. and Others.\nCopyright (C) 2008-2013, International Business Machines\nCopyright (C) 1998-2003, 2006, International Business Machines Corporation\nCopyright (c) 2002-2003,International Business Machines\nCopyright (C) 2009 International Business Machines\nCopyright (C) 2010-2016 International Business Machines\nCopyright (C) 2008-2012 IBM, Inc. All Rights Reserved.\nCopyright (C) 1998-2008, International Business Machines\nCopyright (C) 2010-2016, International Business Machines\nCopyright (C) 1999-2006,2013 IBM Corp. All rights reserved.\nCopyright (C) 2008-2009, International Business Machines Corporation and\nCopyright (C) 2012,2014 International Business Machines\nCopyright (c) 1996-2015, International Business Machines Corporation and\nCopyright (C) 1997-2005, International Business Machines Corporation and others. All Rights Reserved.\nCopyright (C) 1999-2012, International Business Machines Corporation and\nCopyright (C) 1996-2013, International Business Machines Corporation\nCopyright (C) 1998-2005, International Business Machines\nCopyright 2001 and onwards Google Inc.\nCopyright (C) 2010-2012,2014, International Business Machines\nCopyright (C) 1996-2015, International Business Machines Corporation and others.\nCopyright (c) 2003-2004, International Business Machines\nCopyright (C) 2000-2004, International Business Machines\nCopyright (C) 2002-2013, International Business Machines\nCopyright (C) 2002-2011 International Business Machines Corporation and others. All Rights Reserved.\nCopyright (C) 1999-2010, International Business Machines Corporation and others.\nCopyright (C) 2001-2005, International Business Machines Corporation and others. All Rights Reserved.\nCopyright (c) 1996-2016, International Business Machines Corporation\nCopyright (C) 1997-2010, International Business Machines\n\nThis software is provided 'as-is', without any express or implied\nwarranty. In no event will the authors be held liable for any\ndamages arising from the use of this software.\n\nPermission is granted to anyone to use this software for any\npurpose, including commercial applications, and to alter it and\nredistribute it freely, subject to the following restrictions:\n\n1. The origin of this software must not be misrepresented; you must\nnot claim that you wrote the original software. If you use this\nsoftware in a product, an acknowledgment in the product documentation\nwould be appreciated but is not required.\n\n2. Altered source versions must be plainly marked as such, and\nmust not be misrepresented as being the original software.\n\n3. This notice may not be removed or altered from any source\ndistribution.\n\nSoftware: libevent 2.1.12\nCopyright notice:\nCopyright (C) 1998 - 2012, Daniel Stenberg, <daniel@haxx.se>, et al.\nCOPYRIGHT AND PERMISSION NOTICE\nCopyright (c) 1996 - 2013, Daniel Stenberg, <daniel@haxx.se>.\nCopyright (C) 2012, iSEC Partners.\nCopyright (c) 1987, 1993, 1994, 1995\nCopyright (c) 1987, 1993, 1994, 1996\nCopyright 2002 Niels Provos <provos@citi.umich.edu>\nCopyright (c) 2007-2012 Niels Provos and Nick Mathewson\nCopyright (c) 2000-2007 Niels Provos <provos@citi.umich.edu>\nCopyright (c) 2007-2012 Niels Provos, Nick Mathewson\nCopyright (c) 2009-2012 Niels Provos and Nick Mathewson\nCopyright (c) 2006-2007 Niels Provos <provos@citi.umich.edu>\nCopyright (c) 2008-2012 Niels Provos and Nick Mathewson\nCopyright (c) 1991, 1993\nCopyright (c) 2009, Michihiro NAKAJIMA\nCopyright 2000-2013 Kitware, Inc.\nCopyright 2000-2011 Insight Software Consortium\nnotices of original copyright by their contributors; see each source\nCopyright (C) 1996-2018 Free Software Foundation, Inc.\nCopyright (c) 2010 Chris Davis, Niels Provos, and Nick Mathewson\nCopyright (c) 2010-2012 Niels Provos and Nick Mathewson\nCopyright (c) 1996, David Mazieres <dm@uun.org>\nCopyright (c) 2008, Damien Miller <djm@openbsd.org>\nCopyright (c) 2002-2007 Niels Provos <provos@citi.umich.edu>\nCopyright (c) 2002-2006 Niels Provos <provos@citi.umich.edu>\nCopyright (c) 2009-2012 Niels Provos, Nick Mathewson\nCopyright 2000-2009 Niels Provos <provos@citi.umich.edu>\nCopyright 2009-2012 Niels Provos and Nick Mathewson\nCopyright 2000-2007 Niels Provos <provos@citi.umich.edu>\nCopyright 2007-2012 Niels Provos, Nick Mathewson\nCopyright 2003-2009 Niels Provos <provos@citi.umich.edu>\nCopyright 2006-2007 Niels Provos\nCopyright 2007-2012 Nick Mathewson and Niels Provos\nCopyright (c) 2005-2007 Niels Provos <provos@citi.umich.edu>\nCopyright (c) 2003-2009 Niels Provos <provos@citi.umich.edu>\nCopyright 2007-2012 Niels Provos and Nick Mathewson\nCopyright (c) 2007 Sun Microsystems. All rights reserved.\nCopyright (c) 2008-2012 Niels Provos, Nick Mathewson\nCopyright 2002 Christopher Clark\nCopyright 2005-2012 Nick Mathewson\nCopyright 2001-2007 Niels Provos <provos@citi.umich.edu>\nCopyright (c) 2012 Niels Provos and Nick Mathewson\nCopyright (c) 2000 Dug Song <dugsong@monkey.org>\nCopyright (c) 1993 The Regents of the University of California.\nCopyright (c) 1998 Todd C. Miller <Todd.Miller@courtesan.com>\nCopyright (c) 2003 Michael A. Davis <mike@datanerds.net>\nCopyright (c) 2007 Sun Microsystems\nCopyright (c) 2002 Christopher Clark\nCopyright (c) 2006 Maxim Yegorushkin <maxim.yegorushkin@gmail.com>\nCopyright (c) 2010 BitTorrent, Inc.\nCopyright (c) 2005-2012 Niels Provos and Nick Mathewson\nCopyright (c) 1993\nCopyright 2003 Michael A. Davis <mike@datanerds.net>\nCopyright 2003-2007 Niels Provos <provos@citi.umich.edu>\nCopyright 2008-2012 Niels Provos and Nick Mathewson\nCopyright (c) 2003-2007 Niels Provos <provos@citi.umich.edu>\nCopyright (c) 2013 Niels Provos and Nick Mathewson\nCopyright (c) 2009-2012 Nick Mathewson and Niels Provos\nCopyright (c) 2007-2013 Niels Provos and Nick Mathewson\nCopyright (c) 2012 Ross Lagerwall <rosslagerwall@gmail.com>\ntinytest.c -- Copyright 2009-2012 Nick Mathewson\ntinytest.h -- Copyright 2009-2012 Nick Mathewson\ntinytestmacros.h -- Copyright 2009-2012 Nick Mathewson\n\nSoftware: grpc 1.36.1\nCopyright notice: \nCopyright 2015 The gRPC Authors\nCopyright 2016 The gRPC Authors\nCopyright 2018 The gRPC Authors\nCopyright 2019 The gRPC Authors\nCopyright 2018 The gRPC Authors\nCopyright © 2018 gRPC.\nCopyright 2016 gRPC authors.\nCopyright 2017 gRPC authors.\nCopyright 2019 gRPC authors.\nCopyright (C) 1995, 1996, 1997, and 1998 WIDE Project.\nCopyright (C) 2009 - 2013 by Daniel Stenberg et al\nCopyright (c) 2004, 2006-2010 Michael Roth <mroth@nessie.de>\nCopyright (c) 2004-2009 Michael Roth <mroth@nessie.de>\nCopyright (c) 2004-2010 Michael Roth <mroth@nessie.de>\nCopyright (c) 2006-2008 Michael Roth <mroth@nessie.de>\nCopyright (c) 2009-2011, Google Inc.\nCopyright (c) 2018, Google Inc.\nCopyright 2007 Google Inc. All Rights Reserved.\nCopyright 2008 Google Inc.\nCopyright 2013 Google Inc.\nCopyright 2014 Google Inc.\nCopyright 2014 gRPC authors.\nCopyright 2014, Google Inc.\nCopyright 2015 The gRPC Authors\nCopyright 2015 gRPC authors.\nCopyright 2015, Google Inc.\nCopyright 2015-2016 gRPC authors.\nCopyright 2015-2017 gRPC authors.\nCopyright 2016 Google Inc.\nCopyright 2016 The Chromium Authors.\nCopyright 2016 gRPC authors.\nCopyright 2016, Google Inc.\nCopyright 2017 The gRPC Authors\nCopyright 2017 gRPC authors.\nCopyright 2018 The Bazel Authors.\nCopyright 2018 The gRPC Authors\nCopyright 2018 The gRPC Authors.\nCopyright 2018 gRPC Authors.\nCopyright 2018 gRPC authors.\nCopyright 2018, gRPC Authors\nCopyright 2019 Istio Authors. All Rights Reserved.\nCopyright 2019 The Bazel Authors.\nCopyright 2019 The gRPC Authors\nCopyright 2019 The gRPC Authors.\nCopyright 2019 The gRPC authors.\nCopyright 2019 gRPC authors.\nCopyright 2019 the gRPC authors.\nCopyright 2019, Google Inc.\nCopyright 2020 The gRPC Authors\nCopyright 2020 The gRPC Authors.\nCopyright 2020 The gRPC authors.\nCopyright 2020 gRPC authors.\nCopyright 2020 the gRPC authors.\nCopyright 2020 王一 Wang Yi <godspeedchina@yeah.net>\nCopyright 2021 The gRPC Authors\nCopyright 2021 The gRPC authors.\nCopyright 2021 gRPC authors.\nCopyright 2021 the gRPC authors.\nCopyright 2015 The gRPC Authors\nCopyright 2017 The gRPC Authors\nCopyright 2015 gRPC authors.\nCopyright 2016 gRPC authors.\nCopyright 2020 The gRPC Authors\n\nSoftware: opencv 4.5.2\nCopyright notice:\nCopyright 2015-2017 Philippe Tillet\nCopyright (C) 1991-2012, Thomas G. Lane, Guido Vollbeding.\n﻿Copyright 2008-2009  Marius Muja (mariusm@cs.ubc.ca). All rights reserved.\n\"Copyright (C) 2009-2011 Nokia Corporation and/or its subsidiary(-ies)\\n\" \\\nCopyright (c) 1991-1996 Silicon Graphics, Inc.\nCopyright (C) 1994-1997, Thomas G. Lane.\nCopyright (C) 2008, 2011, Nils Hasler, all rights reserved.\nCopyright (C) 2010, 2016, 2018, D. R. Commander.\nCopyright (c) 1998-2000 Glenn Randers-Pehrson, are derived from libpng-0.96, and are distributed according to the same disclaimer and license as libpng-0.96, with the following individuals added to the list of Contributing Authors:\nCopyright (c) 1992-1997 Silicon Graphics, Inc.\nCopyright © 2013 Giacomo (Mimmo) Cosenza aka Magomimmo\nCopyright (C) 2017-2018, D. R. Commander.\nCopyright (c) 2015, Matthieu Darbois All rights reserved.\nCopyright (c) 2014,2016 Glenn Randers-Pehrson Written by James Yu <james.yu at linaro.org>, October 2013.\nCopyright (c) 2011-2012, Centre National d'Etudes Spatiales (CNES), France\nCopyright (c) 2014, the respective contributors All rights reserved.\n\"Copyright (C) 2015, 2020 Google, Inc.\\n\" \\\nCopyright (C) 1989, 1991 Free Software Foundation, Inc.\nCopyright (C) 1992-1997, Thomas G. Lane.\nCopyright (C) 1995-2005, 2010 Mark Adler For conditions of distribution and use, see copyright notice in zlib.h\nCopyright (c) Microsoft. All rights reserved.\nCopyright (c) 2011, Intel Corporation All rights reserved.\nCopyright (C) 2016, OpenCV Foundation, all rights reserved.\nc = cv::abs(c)  1000;\nCopyright (c) 2013-2019 Intel Corporation All Rights Reserved.\n==6101== Copyright (C) 2003-2015, and GNU GPL'd, by Nicholas Nethercote ==6101== Using Valgrind-3.11.0 and LibVEX; rerun with -h for copyright info ==6101== Command: ./bin/exampletutorialanisotropicimagesegmentation ==6101==\nCopyright (C) 2008-2012, Willow Garage Inc., all rights reserved.\nCopyright (c) 1998-2002,2004,2006-2014,2016,2018 Glenn Randers-Pehrson\nCopyright (C) 2014, Itseez, Inc, all rights reserved.\nCopyright (C) 2014-2015, D. R. Commander.\nCopyright (c) 2009-2014 DreamWorks Animation LLC.\nCopyright (c) 2014, The Regents of the University of California (Regents)\nCopyright 2015 Google Inc. All Rights Reserved.\nCopyright (c) AWare Systems <http:www.awaresystems.be/>\n\" inflate 1.2.11 Copyright 1995-2017 Mark Adler \";\n\"Copyright (c) 1996-1997 Andreas Dilger\" PNGSTRINGNEWLINE \\\nCopyright (c) 2008, 2011-2012, Centre National d'Etudes Spatiales (CNES), FR\nCopyright (C) 2013, MIPS Technologies, Inc., California.\nCopyright (c) 2008, Industrial Light & Magic, a division of Lucas Digital Ltd. LLC\nCopyright (C) 2012, 2015, D. R. Commander.\nCopyright (C) 2011, 2014-2015, D. R. Commander.\nCopyright (C) 2009-2012, Willow Garage Inc., all rights reserved.\nCopyright (c) 2001-2006 Michael David Adams\nCopyright (c) 2015, Mathieu Malaterre <mathieu.malaterre@gmail.com>\nCopyright (C) 2019 Intel Corporation\nCopyright (c) 2006, Google Inc.\nCopyright (C) 2016, Itseez Inc, all rights reserved.\nCopyright (c) 2010, Andrey Kiselev <dron@ak4719.spb.edu>\nCopyright (c) 2005-2012, Industrial Light & Magic, a division of Lucas Digital Ltd. LLC\nCopyright (c) 2003, Industrial Light & Magic, a division of Lucas Digital Ltd. LLC\nCopyright 2013 Google Inc. All Rights Reserved.\nCopyright (c) 2005, Herve Drolon, FreeImage Team\nCopyright (C) 2013, OpenCV Foundation, all rights reserved.\n﻿Copyright (c) Microsoft Corporation. All rights reserved\nCopyright (C) 2010, 2016, D. R. Commander.\nCopyright (c) 2002-2003 Michael David Adams.\nCopyright 2007, Google Inc.\nCopyright 2013 Red Hat Inc.  All rights reserved.\nCopyright (C) 2016, Intel Corporation, all rights reserved.\nCopyright (C) 2020, Intel Corporation, all rights reserved.\nCopyright (c) 1998-2018 Glenn Randers-Pehrson\nCopyright (c) 2012, Industrial Light & Magic, a division of Lucas Digital Ltd. LLC\nCopyright (C) 2013, Evgeny Toropov, all rights reserved.\nCopyright (C) 2014, Itseez Inc. See the license at http:opencv.org\nCopyright (c) 2017, IntoPIX SA <support@intopix.com>\n\"Copyright (C) 2013-2014 Linaro Limited\\n\" \\\nCopyright (c) 2007, Weta Digital Ltd\nCopyright 2013 Google Inc.  All rights reserved.\nCopyright (C) 1991-1998, Thomas G. Lane.\nCopyright (C) 2010, 2012-2020, D. R. Commander.\nCopyright 2008, Google Inc.\nCopyright (c) 2003-2014, Antonin Descampe\nCopyright( C) 2000, Intel Corporation, all rights reserved.\nCopyright (c) 2000-2002, 2004, 2006-2018 Glenn Randers-Pehrson.\nCopyright (C) 2012-2015, NVIDIA Corporation, all rights reserved.\nCopyright (c) 1996-1997 Andreas Dilger\n﻿[assembly: AssemblyCopyright(\"Copyright ©  2014\")]\nCopyright (C) 1990, 1995  Frank D. Cringle.\nCopyright (C) 2014, MIPS Technologies, Inc., California.\nCopyright (C) 2009, Intel Corporation and others, all rights reserved.\nCopyright (c) 2020, OPEN AI LAB Author: qtang@openailab.com\nCopyright 2005-2008 Google Inc. All Rights Reserved.\nCopyright (c) 2006, 2008 Edward Rosten All rights reserved.\nCopyright (c) 2016-2017 Glenn Randers-Pehrson Written by Mike Klein and Matt Sarett, Google, Inc.\nCopyright (c) 2014-2017 The Khronos Group Inc.\nCopyright (C) 2013, Itseez Inc, all rights reserved.\nCopyright (c) 2008-2011, William Lucas All rights reserved.\nCopyright (c) 1991-1997 Sam Leffler\nCopyright (C) 2010-2011, 2015-2016, D. R. Commander.\nCopyright (C) 2020, Institute of Software, Chinese Academy of Sciences.\nCopyright (c) Microsoft Corporation. All rights reserved.\nCopyright (c) 2002, MD-Mathematische Dienste GmbH Im Defdahl 5-10\nCopyright 2009 Google Inc.\nCopyright (C) 2010-2012, Advanced Micro Devices, Inc., all rights reserved.\nCopyright (c) 2005-2014 Intel Corporation. All rights reserved.\n(C) Copyright Kevlin Henney 2001\nCopyright (c) 2010, Google Inc. All rights reserved.\nCopyright (C) 2000-2020 Intel Corporation, all rights reserved.\nCopyright (c) 2011. Philipp Wagner <bytefish[at]gmx[dot]de>.\nCopyright (C) 2015, 2018, D. R. Commander.\n\"Copyright (c) 2018-2019 Cosmin Truta\" PNGSTRINGNEWLINE \\\nCopyright (C) 2014-2015, NVIDIA Corporation, all rights reserved.\n\"Copyright (C) 2011-2016 Siarhei Siamashka\\n\" \\\nCopyright (c) 2012-2014 Deepmind Technologies (Koray Kavukcuoglu)\nCopyright (c) 2005, Herve Drolon, FreeImage Team All rights reserved.\nCopyright (C) 2019 Czech Technical University.\nCopyright (C) 2011, 2015, 2018, D. R. Commander.\nCopyright (c) 1999-2000 Image Power, Inc.\nCopyright (C) 2017, D. R. Commander.\nCopyright 2011. All rights reserved.\nCopyright (C) 1995-1998, Thomas G. Lane.\n\"Copyright (C) 1999-2006 MIYASAKA Masaru\\n\" \\\nCopyright (c) 1997 Greg Ward Larson\nCopyright (c) 2009, Willow Garage, Inc.\nCopyright (c) 1999-2000 The University of British Columbia\nCopyright (c) 2007, Miroslav Balda All rights reserved.\nCopyright (C) 2009-2011, Willow Garage Inc., all rights reserved.\nCopyright 2011, 2012, 2013, 2014, 2015, 2016, 2017 The Regents of the University of California.  All rights reserved.\nCopyright (c) 1999-2000 Image Power, Inc. and the University of British Columbia.\nCopyright (c) 2008-2009 The Khronos Group Inc.\nCopyright (C) 2015-2016, Itseez Inc., all rights reserved.\nCopyright (c) 2006, Industrial Light & Magic, a division of Lucasfilm Entertainment Company Ltd.  Portions contributed and copyright held by others as indicated.  All rights reserved.\n(builtinmsavshfb(builtinmsaaddvb((v16i8)((v2i64){0x0706050403020100, 0x0F0E0D0C0B0A0908}), builtinmsafillb(c)), b, a))\nCopyright (C) 2019-2020 Intel Corporation\nCopyright (C) 1991, 1999 Free Software Foundation, Inc.\nCopyright (C) 2011, 2014, D. R. Commander.\nCopyright (C) 1995-2003, 2010 Mark Adler For conditions of distribution and use, see copyright notice in zlib.h\nCopyright (C) 2000-2020, Intel Corporation, all rights reserved.\nCopyright (c) 2000-2003 Chih-Chung Chang and Chih-Jen Lin All rights reserved.\nCopyright (C) 2016, Itseez, Inc, all rights reserved.\nCopyright (C) 1995-1997, Thomas G. Lane.\nCopyright (C) 2020, D. R. Commander.\nCopyright (c) 2001-2003, David Janssens\nCopyright (c) 2020, George Terzakis All rights reserved.\nCopyright (C) 2010, 2015, D. R. Commander.\nCopyright (C) 2010, 2015-2018, 2020, D. R. Commander.\nCopyright 2003 Google Inc.\nCopyright (c) Microsoft Corporation. All rights reserved\nCopyright (c) 2006-2007, Parvatha Elangovan All rights reserved.\n| Copyright (c) 2017, Puttemans Steven, Can Ergun and Toon Goedeme | (KU Leuven, EAVISE Research Group, Jan Pieter De Nayerlaan 5, | Sint-Katelijne-Waver, Belgium).\nCopyright (C) 2014, Itseez, Inc., all rights reserved.\nCopyright 2016 Google Inc. All Rights Reserved.\nCopyright (c) 1998-2002,2004,2006-2014,2016 Glenn Randers-Pehrson\nCopyright (c) 2006-2010, Rob Hess <hess@eecs.oregonstate.edu>\nCopyright (c) 2004, Industrial Light & Magic, a division of Lucas Digital Ltd. LLC\nCopyright (C) 1994-1996, Thomas G. Lane.\nCopyright (C) 2000, Intel Corporation, all rights reserved.\n(C) Copyright Christopher Diggins 2005-2011\nCopyright (c) Facebook Inc. and Microsoft Corporation.\nCopyright (c) 2006-2007, Parvatha Elangovan\nCopyright 2011 Google Inc. All Rights Reserved.\nCopyright (C) 2009-2016, NVIDIA Corporation, all rights reserved.\nCopyright (C) 2018 Ya-Chiu Wu, all rights reserved.\nCopyright (c) 2018-2019 Cosmin Truta.\nCopyright (c) 2001-2003 Michael David Adams\nCopyright 2015, Google Inc.\nCopyright 2012 Google Inc.  All rights reserved.\nCopyright (C) 1995-2017 Jean-loup Gailly and Mark Adler\nCopyright (c) 2010-2011, Kaori Hagihara\nCopyright (C) 2009-2011, 2014-2016, 2018-2019, D. R. Commander.\n\"Copyright (C) 1991-2020 The libjpeg-turbo Project and many others\"\nCopyright 2014 Bloomberg Finance LP. All rights reserved.\nCopyright (C) 1995-2017 Mark Adler For conditions of distribution and use, see copyright notice in zlib.h\nCopyright (c) 2001-2004 Idiap Research Institute (Ronan Collobert, Samy Bengio, Johnny Mariethoz)\n\"Copyright (C) 2015-2016, 2018 Matthieu Darbois\\n\" \\\nCopyright (C) 2009-2011, 2013-2014, 2016-2017, 2020, D. R. Commander.\nCopyright (C) 2014, D. R. Commander.\nCopyright (c) 2017 Glenn Randers-Pehrson Written by Vadim Barkov, 2017.\nCopyright (C) 1995-2003, 2010, 2014, 2016 Jean-loup Gailly, Mark Adler For conditions of distribution and use, see copyright notice in zlib.h\nCopyright (C) Microsoft Corporation. All rights reserved.\nCopyright (c) 2002, Industrial Light & Magic, a division of Lucas Digital Ltd. LLC\nCopyright 2014, Google Inc.  All rights reserved.\nCopyright (C) 2017, Intel Corporation, all rights reserved.\nCopyright (C) 2004-2017 Mark Adler For conditions of distribution and use, see copyright notice in zlib.h\nCopyright (C) 2009, Willow Garage Inc., all rights reserved.\nCopyright (C) 2009, 2014-2015, 2020, D. R. Commander.\nCopyright (c) 2002-2014, Professor Benoit Macq\nCopyright (C) 2009-2011, 2016, D. R. Commander.\nCopyright (c) 2007, Jonathan Ballard <dzonatas@dzonux.net>\n\" deflate 1.2.11 Copyright 1995-2017 Jean-loup Gailly and Mark Adler \";\nCopyright (C) 1998 Yossi Rubner Computer Science Department, Stanford University E-Mail: rubner@cs.stanford.edu   URL: http:vision.stanford.edu/rubner\nCopyright (c) 2003-2009, Francois-Olivier Devaux\nCopyright (C) 2015, Matthieu Darbois.\nCopyright (c) 1998-2002,2004,2006-2018 Glenn Randers-Pehrson\nCopyright (c) 1995-1997 Sam Leffler\nCopyright (C) 1997-1998, Thomas G. Lane, Todd Newman.\nCopyright (C) 2000-2015, Intel Corporation, all rights reserved.\nCopyright (C) 2015, NVIDIA Corporation, all rights reserved.\nCopyright (c) 1995-2019 The PNG Reference Library Authors.\nCopyright (C) 2000-2008, 2017, Intel Corporation, all rights reserved.\nCopyright (C) 2018 Intel Corporation\nCopyright (C) 1995-2016 Mark Adler For conditions of distribution and use, see copyright notice in zlib.h\nCopyright (C) 2015, Itseez Inc., all rights reserved.\ndefine TIFFLIBVERSIONSTR \"LIBTIFF, Version 4.0.10\\nCopyright (c) 1988-1996 Sam Leffler\\nCopyright (c) 1991-1996 Silicon Graphics, Inc.\"\nCopyright (C) 2004, 2005, 2010, 2011, 2012, 2013, 2016 Mark Adler For conditions of distribution and use, see copyright notice in zlib.h\nCopyright (C) 2014, 2017, D. R. Commander.\nCopyright (c) 2007, Industrial Light & Magic, a division of Lucas Digital Ltd. LLC\nCopyright (C) 2015, D. R. Commander.\nCopyright (c) 2008-2010 The Khronos Group Inc.\nCopyright (c) 2001 Fabrice Bellard\nCopyright (c) 2002-2014, Professor Benoit Macq All rights reserved.\nCopyright (c) 2008-2015 The Khronos Group Inc.\nCopyright (C) 2015, OpenCV Foundation, all rights reserved.\nCopyright (C) 2012-2014, NVIDIA Corporation, all rights reserved.\nCopyright (c) 2011-2014 Idiap Research Institute (Ronan Collobert)\nCopyright (C) 1991-1995, Thomas G. Lane.\nCopyright (c) 2004-2012, Industrial Light & Magic, a division of Lucas Digital Ltd. LLC\n(builtinmsavshfb(builtinmsasubvb((v16i8)((v2i64){0x1716151413121110, 0x1F1E1D1C1B1A1918}), builtinmsafillb(c)), a, b))\nCopyright (C) 1997 - 2002, Makoto Matsumoto and Takuji Nishimura, All rights reserved.\nCopyright (c) 2007-2009 Scientific Computing and Imaging Institute, University of Utah\n\"Copyright (c) 1995-1996 Guy Eric Schalnat, Group 42, Inc.\" \\\nCopyright (c) 1985, 1986 The Regents of the University of California.\nCopyright (c) 1992-1997 Sam Leffler\nCopyright (c) 2003-2007, Francois-Olivier Devaux\n' Copyright (C) 2018, Intel Corporation, all rights reserved.\\n'\\\n\"Copyright (C) 2009, 2012 Pierre Ossman for Cendio AB\\n\" \\\nsvgfig.py copyright (C) 2008 Jim Pivarski <jpivarski@gmail.com>\nCopyright (C) 1995-2011, 2016 Mark Adler For conditions of distribution and use, see copyright notice in zlib.h\n\"Copyright (C) 2019 Arm Limited\\n\" \\\nCopyright (C) 2020 Intel Corporation\nCopyright (C) 2009-2011, 2014, D. R. Commander.\nCopyright (C) 2010-2012, MulticoreWare Inc., all rights reserved.\n﻿Copyright (c) Microsoft Open Technologies, Inc.\nCopyright (c) 2006-2010 NEC Laboratories America (Ronan Collobert, Leon Bottou, Iain Melvin, Jason Weston)\nCopyright (c) 1998-2002,2004,2006-2016,2018 Glenn Randers-Pehrson\nCopyright (C) 2010, Willow Garage Inc., all rights reserved.\nCopyright (c) 1996 Pixar\nCopyright (c) 2020, OPEN AI LAB\nCopyright (C) 2015-2016, D. R. Commander.\nCopyright (c) 2018, Mapbox Author: <norman.barker at mapbox.com>\nCopyright (C) 2014, Itseez Inc, all rights reserved.\nCopyright 2017 Google Inc. All Rights Reserved.\nCopyright (c) 2016 Glenn Randers-Pehrson Written by Mandar Sahastrabuddhe, 2016.\nCopyright (C) 2010 The Android Open Source Project All rights reserved.\nCopyright (c) 1988-1996 Sam Leffler\nCopyright (C) 2000-2016, Intel Corporation, all rights reserved.\nCopyright (c) 2017, IntoPix SA <contact@intopix.com>\nCopyright (C) 2017-2019, Intel Corporation, all rights reserved.\nCopyright (c) 1990-1997 Sam Leffler\nCopyright (C) 2000-2008, Intel Corporation, all rights reserved.\nCopyright (c) 2020, OPEN AI LAB qli@openailab.com sqfu@openailab.com\nCopyright (c) 2001-2004 Michael David Adams.\nCopyright (C) 2009, 2011, 2014-2015, 2018, 2020, D. R. Commander.\nUpdate copyright year to 2010.\nCopyright (c) 2010-2011, Ethan Rublee\nCopyright (C) 2020, Stefan Brüns <stefan.bruens@rwth-aachen.de>\nCopyright (C) 2013, D. R. Commander.\nCopyright (C) 2013, Ovidiu Parvu, all rights reserved.\nCopyright (c) 2001-2003 Michael David Adams.\nCopyright (c) 1988-1997 Sam Leffler\nCopyright (C) 2008-2016, Itseez Inc., all rights reserved.\nCopyright (c) 2012, Weta Digital Ltd\nCopyright (C) 2004, 2010 Mark Adler For conditions of distribution and use, see copyright notice in zlib.h\nCopyright (C) 2014, NVIDIA Corporation, all rights reserved.\nCopyright (C) 2013-2015, NVIDIA Corporation, all rights reserved.\nCopyright (C) 2010  Elmar Mair All rights reserved.\nCopyright (c) 1995-1996 Guy Eric Schalnat, Group 42, Inc.\nCopyright 2008 Google Inc.\nCopyright (c) Microsoft Open Technologies, Inc.\nCopyright (c) 2008-2020 The Khronos Group Inc.\nCopyright (c) 2005, Industrial Light & Magic, a division of Lucas Digital Ltd. LLC\nCopyright (c) 2014, 2015, The Regents of the University of California (Regents)\nCopyright 2014 Google Inc. All rights reserved.\nCopyright (c) 2007, Callum Lerwick <seg@haxxed.com>\nCopyright (C) 2000-2008, 2018, Intel Corporation, all rights reserved.\nCopyright (c) 2012, CS Systemes d'Information, France\n(C) Copyright Pablo Aguilar 2005\nCopyright 2008 Google Inc.  All rights reserved.\nCopyright (C) 1993 by Sun Microsystems, Inc. All rights reserved.\nCopyright (C) 1995-2017 Jean-loup Gailly and Mark Adler For conditions of distribution and use, see copyright notice in zlib.h\nCopyright (c) 2004, Industrial Light & Magic, a division of Lucasfilm Entertainment Company Ltd.  Portions contributed and copyright held by others as indicated.  All rights reserved.\nCopyright (C) 2009-2011, 2018, D. R. Commander.\nCopyright (c) 1996-1997 Andreas Dilger.\nKAZE Features Copyright 2012, Pablo F. Alcantarilla All Rights Reserved See LICENSE for the license information\nCopyright (C) 2010-2012 Daniel Beer <dlbeer@gmail.com>\nCopyright (C) 2000-2018, Intel Corporation, all rights reserved.\nCopyright (C) 2014, Advanced Micro Devices, Inc., all rights reserved.\nCopyright (C) 2013, 2016, D. R. Commander.\nCopyright (c) 2015, 2015 The Regents of the University of California (Regents)\nCopyright (C) 2018 - 2020 Intel Corporation\nCopyright (C) 2010, D. R. Commander.\nCopyright 2014 Google Inc. All Rights Reserved.\nCopyright (C) 1995-2017 Jean-loup Gailly detectdatatype() function provided freely by Cosmin Truta, 2006 For conditions of distribution and use, see copyright notice in zlib.h\nCopyright (C) 1991-1996, Thomas G. Lane.\nCopyright (C) 1995-2005, 2014, 2016 Jean-loup Gailly, Mark Adler For conditions of distribution and use, see copyright notice in zlib.h\nCopyright (c) 2011, Industrial Light & Magic, a division of Lucas Digital Ltd. LLC\nCopyright (C) 2019 Manolis Lourakis (lourakis at ics forth gr)\nCopyright (C) 2019-2020, Xperience AI, all rights reserved.\nCopyright (C) 1992-1996, Thomas G. Lane.\nCopyright (c) 2011-2013 NYU (Clement Farabet)\nCopyright (c) 1998-2002,2004,2006-2013 Glenn Randers-Pehrson\nCopyright (c) 2018 Cosmin Truta\nCopyright (c) 2017, Planet Labs Author: <even.rouault at spatialys.com>\nCopyright (C) 2009, 2011, 2014-2015, 2020, D. R. Commander.\n\"Copyright (C) 2013-2014 MIPS Technologies, Inc.\\n\" \\\nCopyright (C) 2009-2012, 2015, D. R. Commander.\nCopyright (c) 2006, Industrial Light & Magic, a division of Lucasfilm Entertainment Company Ltd. Portions contributed and copyright held by others as indicated. All rights reserved.\nCopyright (c) 2012, Mathieu Malaterre <mathieu.malaterre@gmail.com>\nCopyright (C) 2010, 2015-2016, D. R. Commander.\nCopyright 2015 Google Inc.  All rights reserved.\n\"Copyright (c) 1998-2002,2004,2006-2018 Glenn Randers-Pehrson\" \\\nCopyright (c) 2018-2019 Cosmin Truta\nCopyright (c) 2016-2017 Glenn Randers-Pehrson Written by Mike Klein and Matt Sarett\nCopyright (c) 1996-1997 Andreas Dilger, are derived from libpng-0.88, and are distributed according to the same disclaimer and license as libpng-0.88, with the following individuals added to the list of Contributing Authors:\n(c) 2012 Weta Digital Ltd\nCopyright (C) 2020, Huawei Technologies Co., Ltd. All rights reserved.\nCopyright (C) 1995-2012 Jean-loup Gailly and Mark Adler.\nCopyright (C) 2014-2015, Itseez Inc., all rights reserved.\n(C) 1995-2017 Jean-loup Gailly and Mark Adler\nCopyright (c) 2013, Bo Li (prclibo@gmail.com), ETH Zurich All rights reserved.\nCopyright (c) 2015 The Regents of the University of California (Regents)\nCopyright 2010 Argus Corp. All rights reserved.\n﻿[assembly: AssemblyCopyright(\"Copyright ©  2013\")]\nCopyright (c) 2008, Jerome Fimes, Communications & Systemes <jerome.fimes@c-s.fr>\nCopyright (C) 1995-2016 Jean-loup Gailly For conditions of distribution and use, see copyright notice in zlib.h\nCopyright (C) 2013, NVIDIA Corporation, all rights reserved.\nCopyright (c) 2006-2012, Industrial Light & Magic, a division of Lucas Digital Ltd. LLC\nCopyright (C) 2009, Liu Liu All rights reserved.\nCopyright (c) 1992, 1993 The Regents of the University of California.  All rights reserved.\nCopyright (c) 2012, Carl Hetherington\nCopyright (c) 2007-2008 Intel Corporation. All Rights Reserved.\nCopyright (C) 2015-2016, 2018, D. R. Commander.\nCopyright (C) 1995-2006, 2010, 2011, 2012, 2016 Mark Adler For conditions of distribution and use, see copyright notice in zlib.h\nCopyright (c) 2013, Industrial Light & Magic, a division of Lucas Digital Ltd. LLC\nCopyright (c) 2008 - 2012 The Khronos Group Inc.\nCopyright (c) 1999-2000, Image Power, Inc. and the University of British Columbia.\nCopyright (c) 1998-2002,2004,2006-2013,2018 Glenn Randers-Pehrson\nCopyright (C)2015 Viktor Szathmáry.  All Rights Reserved.\nCopyright (c) 2015-2018 The Khronos Group Inc.\nCopyright 2009 Pierre Ossman <ossman@cendio.se> for Cendio AB\nCopyright (C) 2013, Linaro Limited.\nCopyright (C) 2016, D. R. Commander.\nCopyright 2008-2011  Marius Muja (mariusm@cs.ubc.ca). All rights reserved.\n\"Copyright (C) 2015 Intel Corporation\\n\" \\\n﻿Copyright (c) Microsoft Corporation. All rights reserved.\n==6117== Copyright (C) 2003-2015, and GNU GPL'd, by Nicholas Nethercote ==6117== Using Valgrind-3.11.0 and LibVEX; rerun with -h for copyright info ==6117== Command: ./bin/exampletutorialportinganisotropicimagesegmentationgapi ==6117==\nCopyright (c) 2002-2012, Industrial Light & Magic, a division of Lucas Digital Ltd. LLC\nAKAZE Features Copyright 2013, Pablo F. Alcantarilla, Jesus Nuevo All Rights Reserved See LICENSE for the license information\nCopyright (c) 2006, Industrial Light & Magic, a division of Lucas Digital Ltd. LLC\nCopyright (C) 2009-2011, 2016, 2018-2019, D. R. Commander.\nCopyright (c) 1995-1997 Silicon Graphics, Inc.\nCopyright (c) 2011-2014, Andrey Kamaev All rights reserved.\nCopyright (C) 2008-2011, Willow Garage Inc., all rights reserved.\nCopyright 2009 Pierre Ossman <ossman@cendio.se> for Cendio AB For conditions of distribution and use, see the accompanying README.ijg file.\nCopyright (C) 2015, 2020, Google, Inc.\nCopyright (C) 2009, 2011-2012, 2014-2015, D. R. Commander.\n| Copyright (c) 2004, Hannes Kruppa and Bernt Schiele (ETH Zurich, Switzerland).\nCopyright (C) 2011, 2015, 2020, D. R. Commander.\nCopyright (c) 1994-1997 Sam Leffler\nCopyright (c) 2016 Glenn Randers-Pehrson Written by Mandar Sahastrabuddhe, August 2016.\nCopyright (C) 2015-2016, OpenCV Foundation, all rights reserved.\nCopyright (C) 2018-2020 Intel Corporation\nCopyright (c) 2009, Industrial Light & Magic, a division of Lucas Digital Ltd. LLC\nCopyright (C) 2010-2012, Institute Of Software Chinese Academy Of Science, all rights reserved.\nCopyright (C) 2016 The Android Open Source Project\nCopyright (c) 2009 Frank Warmerdam\nCopyright (c) 2012, Autodesk, Inc.\nCopyright (c) 2002-2014, Universite catholique de Louvain (UCL), Belgium\nCopyright (c) 2016, Even Rouault All rights reserved.\nCopyright (c) 2014, 2015, the respective contributors All rights reserved.\nCopyright (c) 2017, Intel Corporation\nCopyright (C) 2019-2020, Intel Corporation, all rights reserved.\nCopyright (c) 1997 Silicon Graphics, Inc.\nCopyright (C) 2014, Intel, Inc., all rights reserved.\nCopyright (c) 2002-2003, Yannick Verschueren\nCopyright (c) 2012, CS Systemes d'Information, France All rights reserved.\n\"Copyright (c) 2001-2006 Michael David Adams.\\n\" \\\nCopyright 2005, Google Inc.\nCopyright (c) 2008-2012 The Khronos Group Inc.\nCopyright (c) 2015, Advanced Micro Devices, Inc.\nCopyright (C) 2008-2010, Willow Garage Inc., all rights reserved.\nCopyright (C) 2015-2020, OpenCV Foundation, all rights reserved.\nCopyright 2005 Google Inc.\nCopyright (c) 2017-2018 Arm Holdings. All rights reserved.\nCopyright (c) 1994-1997 Silicon Graphics, Inc.\nCopyright (c) 2015, Piotr Dobrowolski dobrypd[at]gmail[dot]com All rights reserved.\nCopyright (C) 2009, 2015, D. R. Commander.\nCopyright (C)2009-2020 D. R. Commander.  All Rights Reserved.\nCopyright (c) 1998-2002,2004,2006-2017 Glenn Randers-Pehrson\n| Copyright (c) 2011, Modesto Castrillon-Santana (IUSIANI, Universidad de | Las Palmas de Gran Canaria, Spain).\nCopyright (C) 1978-1999 Ken Turkowski. <turk@computer.org>\nCopyright (C) 2014-2016, NVIDIA Corporation, all rights reserved.\nCopyright (C) 2010-2012, Multicoreware, Inc., all rights reserved.\nCopyright (C) 2008, Willow Garage Inc., all rights reserved.\nCopyright (C) 2014, Samson Yilma (samsonyilma@yahoo.com), all rights reserved.\nCopyright (c) 2011-2012 NEC Laboratories America (Koray Kavukcuoglu)\nCopyright &copy; 2016, NVIDIA CORPORATION. All rights reserved.\nCopyright (C) 2015-2018, D. R. Commander.\nCopyright (c) 2014,2016 Glenn Randers-Pehrson Written by Mans Rullgard, 2011.\nCopyright (c) 2011-2012, Industrial Light & Magic, a division of Lucas Digital Ltd. LLC\nCopyright (C) 2019, Arm Limited.\nCopyright (C) 2014, Olexa Bilaniuk, Hamid Bazargani & Robert Laganiere, all rights reserved.\nCopyright 2012. All rights reserved.\nCopyright (C) 2014, Itseez Inc., all rights reserved.\nCopyright (c) 2016-2017 Fabian David Tschopp, all rights reserved.\nCopyright (C) 1991-2020, Thomas G. Lane, Guido Vollbeding.\nCopyright 2012 Google Inc. All Rights Reserved.\n\"Copyright (C) 2009-2020 D. R. Commander\\n\" \\\nCopyright 2008-2011  David G. Lowe (lowe@cs.ubc.ca). All rights reserved.\nCopyright 2014 Google Inc.  All rights reserved.\nCopyright (c) 2008 - 2009 NVIDIA Corporation.  All rights reserved.\nCopyright 2006, Google Inc.\n﻿Copyright (c) Microsoft. All rights reserved.\nCopyright (C) 2001 Fabrice Bellard\nCopyright (C) 2014-2015, 2018, 2020, D. R. Commander.\nCopyright (c) 2014,2017 Glenn Randers-Pehrson Written by Mans Rullgard, 2011.\nCopyright (C) 2010-2013, Advanced Micro Devices, Inc., all rights reserved.\nCopyright (C) 2018-2019, Intel Corporation, all rights reserved.\nCopyright (c) 1991-1997 Silicon Graphics, Inc.\nCopyright (C) 1995-2017 Jean-loup Gailly For conditions of distribution and use, see copyright notice in zlib.h\nCopyright (C) 1991-1994, Thomas G. Lane.\nCopyright (C) 2016, 2018, Matthieu Darbois.\nCopyright 2010 Google Inc. All Rights Reserved.\nCopyright (C) 2009, 2011, 2015, D. R. Commander.\nCopyright 2018 Google Inc. All Rights Reserved.\nCopyright (C) 2015, Google, Inc.\nCopyright (c) 2002-2018, Industrial Light & Magic, a division of Lucas Digital Ltd. LLC\ndefine JCOPYRIGHT \"Copyright (C) 2020, Thomas G. Lane, Guido Vollbeding\"\nCopyright (C) 2018, Intel Corporation, all rights reserved.\nCopyright (C) 2015, 2020, D. R. Commander.\nCopyright 2008-2009  Marius Muja (mariusm@cs.ubc.ca). All rights reserved.\nCopyright (C) 2010, 2020, D. R. Commander.\nCopyright (C) 1999-2006, MIYASAKA Masaru.\nCopyright (C) 2008-2013, Itseez Inc., all rights reserved.\nCopyright (c) 2001-2002 Michael David Adams.\nCopyright (c) 2006      Idiap Research Institute (Samy Bengio)\nCopyright (c) 2000-2002, 2004, 2006-2018 Glenn Randers-Pehrson, are derived from libpng-1.0.6, and are distributed according to the same disclaimer and license as libpng-1.0.6 with the following individuals added to the list of Contributing Authors:\nCopyright (C) 2011  The Autonomous Systems Lab (ASL), ETH Zurich, Stefan Leutenegger, Simon Lynen and Margarita Chli.\nCopyright (c) 1995 Intel Corporation.\nCopyright 2017 Toby Collins Redistribution and use in source and binary forms, with or without modification, are permitted provided that the following conditions are met:\nCopyright (C) 2018-2019 Intel Corporation\nCopyright (C) 2008, Nils Hasler, all rights reserved.\nCopyright (c) 2017 Joseph Redmon\n\"Copyright (c) 1999-2000 Image Power, Inc. and the University of\\n\" \\\nCopyright (C) 2014, Intel Corporation, all rights reserved.\nCopyright (C) 2015-2016, 2018, Matthieu Darbois.\nCopyright (C) 2015, Itseez, Inc., all rights reserved.\nCopyright (C) 1991-1997, Thomas G. Lane.\nCopyright (c) 2008-2013 The Khronos Group Inc.\nCopyright (C) 2008-2013, Willow Garage Inc., all rights reserved.\nCopyright (C) 2004 by Sun Microsystems, Inc. All rights reserved.\nCopyright (C) 2019-2020, Shenzhen Institute of Artificial Intelligence and Robotics for Society, all rights reserved.\n(C) 2006 by Jay Stavinzky.\n\"Copyright (C) 1991-2017 Thomas G. Lane, Guido Vollbeding\"\nCopyright (C) 1995-2016 Jean-loup Gailly, Mark Adler For conditions of distribution and use, see copyright notice in zlib.h\nCopyright (C) 2009-2010, Willow Garage Inc., all rights reserved.\nCopyright (c) 2004 Michael David Adams.\n| Copyright (c) 2014-2016, Joseph Howse (Nummist Media Corporation Limited, | Halifax, Nova Scotia, Canada). All rights reserved.\nCopyright (c) Joris Van Damme <info@awaresystems.be>\nCopyright (c) 2004, Pixar Animation Studios\nCopyright (C) 2006 Simon Perreault\nCopyright (c) 1996-1997 Sam Leffler\nCopyright (C) 1994-1998, Thomas G. Lane.\nCopyright (c) 2013 NVIDIA Corporation. All rights reserved.\nCopyright 2008-2009  David G. Lowe (lowe@cs.ubc.ca). All rights reserved.\nCopyright (C) 2016, NVIDIA Corporation, all rights reserved.\n\nApache License\n                           Version 2.0, January 2004\n                        http://www.apache.org/licenses/\n\n   TERMS AND CONDITIONS FOR USE, REPRODUCTION, AND DISTRIBUTION\n\n   1. Definitions.\n\n      \"License\" shall mean the terms and conditions for use, reproduction,\n      and distribution as defined by Sections 1 through 9 of this document.\n\n      \"Licensor\" shall mean the copyright owner or entity authorized by\n      the copyright owner that is granting the License.\n\n      \"Legal Entity\" shall mean the union of the acting entity and all\n      other entities that control, are controlled by, or are under common\n      control with that entity. For the purposes of this definition,\n      \"control\" means (i) the power, direct or indirect, to cause the\n      direction or management of such entity, whether by contract or\n      otherwise, or (ii) ownership of fifty percent (50%) or more of the\n      outstanding shares, or (iii) beneficial ownership of such entity.\n\n      \"You\" (or \"Your\") shall mean an individual or Legal Entity\n      exercising permissions granted by this License.\n\n      \"Source\" form shall mean the preferred form for making modifications,\n      including but not limited to software source code, documentation\n      source, and configuration files.\n\n      \"Object\" form shall mean any form resulting from mechanical\n      transformation or translation of a Source form, including but\n      not limited to compiled object code, generated documentation,\n      and conversions to other media types.\n\n      \"Work\" shall mean the work of authorship, whether in Source or\n      Object form, made available under the License, as indicated by a\n      copyright notice that is included in or attached to the work\n      (an example is provided in the Appendix below).\n\n      \"Derivative Works\" shall mean any work, whether in Source or Object\n      form, that is based on (or derived from) the Work and for which the\n      editorial revisions, annotations, elaborations, or other modifications\n      represent, as a whole, an original work of authorship. For the purposes\n      of this License, Derivative Works shall not include works that remain\n      separable from, or merely link (or bind by name) to the interfaces of,\n      the Work and Derivative Works thereof.\n\n      \"Contribution\" shall mean any work of authorship, including\n      the original version of the Work and any modifications or additions\n      to that Work or Derivative Works thereof, that is intentionally\n      submitted to Licensor for inclusion in the Work by the copyright owner\n      or by an individual or Legal Entity authorized to submit on behalf of\n      the copyright owner. For the purposes of this definition, \"submitted\"\n      means any form of electronic, verbal, or written communication sent\n      to the Licensor or its representatives, including but not limited to\n      communication on electronic mailing lists, source code control systems,\n      and issue tracking systems that are managed by, or on behalf of, the\n      Licensor for the purpose of discussing and improving the Work, but\n      excluding communication that is conspicuously marked or otherwise\n      designated in writing by the copyright owner as \"Not a Contribution.\"\n\n      \"Contributor\" shall mean Licensor and any individual or Legal Entity\n      on behalf of whom a Contribution has been received by Licensor and\n      subsequently incorporated within the Work.\n\n   2. Grant of Copyright License. Subject to the terms and conditions of\n      this License, each Contributor hereby grants to You a perpetual,\n      worldwide, non-exclusive, no-charge, royalty-free, irrevocable\n      copyright license to reproduce, prepare Derivative Works of,\n      publicly display, publicly perform, sublicense, and distribute the\n      Work and such Derivative Works in Source or Object form.\n\n   3. Grant of Patent License. Subject to the terms and conditions of\n      this License, each Contributor hereby grants to You a perpetual,\n      worldwide, non-exclusive, no-charge, royalty-free, irrevocable\n      (except as stated in this section) patent license to make, have made,\n      use, offer to sell, sell, import, and otherwise transfer the Work,\n      where such license applies only to those patent claims licensable\n      by such Contributor that are necessarily infringed by their\n      Contribution(s) alone or by combination of their Contribution(s)\n      with the Work to which such Contribution(s) was submitted. If You\n      institute patent litigation against any entity (including a\n      cross-claim or counterclaim in a lawsuit) alleging that the Work\n      or a Contribution incorporated within the Work constitutes direct\n      or contributory patent infringement, then any patent licenses\n      granted to You under this License for that Work shall terminate\n      as of the date such litigation is filed.\n\n   4. Redistribution. You may reproduce and distribute copies of the\n      Work or Derivative Works thereof in any medium, with or without\n      modifications, and in Source or Object form, provided that You\n      meet the following conditions:\n\n      (a) You must give any other recipients of the Work or\n          Derivative Works a copy of this License; and\n\n      (b) You must cause any modified files to carry prominent notices\n          stating that You changed the files; and\n\n      (c) You must retain, in the Source form of any Derivative Works\n          that You distribute, all copyright, patent, trademark, and\n          attribution notices from the Source form of the Work,\n          excluding those notices that do not pertain to any part of\n          the Derivative Works; and\n\n      (d) If the Work includes a \"NOTICE\" text file as part of its\n          distribution, then any Derivative Works that You distribute must\n          include a readable copy of the attribution notices contained\n          within such NOTICE file, excluding those notices that do not\n          pertain to any part of the Derivative Works, in at least one\n          of the following places: within a NOTICE text file distributed\n          as part of the Derivative Works; within the Source form or\n          documentation, if provided along with the Derivative Works; or,\n          within a display generated by the Derivative Works, if and\n          wherever such third-party notices normally appear. The contents\n          of the NOTICE file are for informational purposes only and\n          do not modify the License. You may add Your own attribution\n          notices within Derivative Works that You distribute, alongside\n          or as an addendum to the NOTICE text from the Work, provided\n          that such additional attribution notices cannot be construed\n          as modifying the License.\n\n      You may add Your own copyright statement to Your modifications and\n      may provide additional or different license terms and conditions\n      for use, reproduction, or distribution of Your modifications, or\n      for any such Derivative Works as a whole, provided Your use,\n      reproduction, and distribution of the Work otherwise complies with\n      the conditions stated in this License.\n\n   5. Submission of Contributions. Unless You explicitly state otherwise,\n      any Contribution intentionally submitted for inclusion in the Work\n      by You to the Licensor shall be under the terms and conditions of\n      this License, without any additional terms or conditions.\n      Notwithstanding the above, nothing herein shall supersede or modify\n      the terms of any separate license agreement you may have executed\n      with Licensor regarding such Contributions.\n\n   6. Trademarks. This License does not grant permission to use the trade\n      names, trademarks, service marks, or product names of the Licensor,\n      except as required for reasonable and customary use in describing the\n      origin of the Work and reproducing the content of the NOTICE file.\n\n   7. Disclaimer of Warranty. Unless required by applicable law or\n      agreed to in writing, Licensor provides the Work (and each\n      Contributor provides its Contributions) on an \"AS IS\" BASIS,\n      WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or\n      implied, including, without limitation, any warranties or conditions\n      of TITLE, NON-INFRINGEMENT, MERCHANTABILITY, or FITNESS FOR A\n      PARTICULAR PURPOSE. You are solely responsible for determining the\n      appropriateness of using or redistributing the Work and assume any\n      risks associated with Your exercise of permissions under this License.\n\n   8. Limitation of Liability. In no event and under no legal theory,\n      whether in tort (including negligence), contract, or otherwise,\n      unless required by applicable law (such as deliberate and grossly\n      negligent acts) or agreed to in writing, shall any Contributor be\n      liable to You for damages, including any direct, indirect, special,\n      incidental, or consequential damages of any character arising as a\n      result of this License or out of the use or inability to use the\n      Work (including but not limited to damages for loss of goodwill,\n      work stoppage, computer failure or malfunction, or any and all\n      other commercial damages or losses), even if such Contributor\n      has been advised of the possibility of such damages.\n\n   9. Accepting Warranty or Additional Liability. While redistributing\n      the Work or Derivative Works thereof, You may choose to offer,\n      and charge a fee for, acceptance of support, warranty, indemnity,\n      or other liability obligations and/or rights consistent with this\n      License. However, in accepting such obligations, You may act only\n      on Your own behalf and on Your sole responsibility, not on behalf\n      of any other Contributor, and only if You agree to indemnify,\n      defend, and hold each Contributor harmless for any liability\n      incurred by, or claims asserted against, such Contributor by reason\n      of your accepting any such warranty or additional liability.\n\n   END OF TERMS AND CONDITIONS\n\n   APPENDIX: How to apply the Apache License to your work.\n\n      To apply the Apache License to your work, attach the following\n      boilerplate notice, with the fields enclosed by brackets \"[]\"\n      replaced with your own identifying information. (Don't include\n      the brackets!)  The text should be enclosed in the appropriate\n      comment syntax for the file format. We also recommend that a\n      file or class name and description of purpose be included on the\n      same \"printed page\" as the copyright notice for easier\n      identification within third-party archives.\n\n   Copyright [yyyy] [name of copyright owner]\n\n   Licensed under the Apache License, Version 2.0 (the \"License\");\n   you may not use this file except in compliance with the License.\n   You may obtain a copy of the License at\n\n       http://www.apache.org/licenses/LICENSE-2.0\n\n   Unless required by applicable law or agreed to in writing, software\n   distributed under the License is distributed on an \"AS IS\" BASIS,\n   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n   See the License for the specific language governing permissions and\n   limitations under the License.\n\nSoftware: cmake-modules cf2e087039f81d13e687cf6c2b1b382b9c1e756f\nCopyright notice:\nCopyright 2009 Kitware, Inc.\nCopyright 2009 Will Dicharry <wdicharry@stellarscience.com>\nCopyright 2005-2009 Kitware, Inc.\nCopyright Iowa State University 2009-2010.\nCopyright 2006-2009 Kitware, Inc.\nCopyright 2006-2008 Andreas Schneider <mail@cynapses.org>\nCopyright 2007      Wengo\nCopyright 2007      Mike Jackson\nCopyright 2008      Andreas Pakulat <apaku@gmx.de>\nCopyright 2008-2010 Philip Lowman <philip@yhbt.com>\nCopyright 2009 Alexander Neundorf <neundorf@kde.org>\nCopyright (c) 2012 - 2017, Lars Bilke\nCopyright (c) 2012-2016 Sascha Kratky\nCopyright 2012-2018 Sascha Kratky\nCopyright (c) 2012-2018, OpenGeoSys Community (http://www.opengeosys.org)\nCopyright (c) 2012 - 2015, Lars Bilke\nCopyright 2008-2009 Philip Lowman <philip@yhbt.com>\nCopyright 2010      Iowa State University (Ryan Pavlik <abiryan@ryand.net>)\nCopyright 2000-2009 Kitware, Inc., Insight Software Consortium\nCopyright 2010-2011 Kitware, Inc.\nCopyright Iowa State University 2009-2011\n\nBoost Software License - Version 1.0 - August 17th, 2003\n\nPermission is hereby granted, free of charge, to any person or organization\nobtaining a copy of the software and accompanying documentation covered by\nthis license (the \"Software\") to use, reproduce, display, distribute,\nexecute, and transmit the Software, and to prepare derivative works of the\nSoftware, and to permit third-parties to whom the Software is furnished to\ndo so, all subject to the following:\n\nThe copyright notices in the Software and this entire statement, including\nthe above license grant, this restriction and the following disclaimer,\nmust be included in all copies of the Software, in whole or in part, and\nall derivative works of the Software, unless such copies or derivative\nworks are solely in the form of machine-executable object code generated by\na source language processor.\n\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\nFITNESS FOR A PARTICULAR PURPOSE, TITLE AND NON-INFRINGEMENT. IN NO EVENT\nSHALL THE COPYRIGHT HOLDERS OR ANYONE DISTRIBUTING THE SOFTWARE BE LIABLE\nFOR ANY DAMAGES OR OTHER LIABILITY, WHETHER IN CONTRACT, TORT OR OTHERWISE,\nARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER\nDEALINGS IN THE SOFTWARE.\n\n\nSoftware: Myia 395fa4c7beb9479a1d6e323e4cc0ecf25733dfba\nCopyright notice:\nCopyright (c) 2017 MILA\nPlease visit the Myia web site for more information:\n  * https://github.com/mila-iqia/myia/\n\nMIT License\n\nPermission is hereby granted, free of charge, to any person obtaining a copy\nof this software and associated documentation files (the \"Software\"), to deal\nin the Software without restriction, including without limitation the rights\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\ncopies of the Software, and to permit persons to whom the Software is\nfurnished to do so, subject to the following conditions:\n\nThe above copyright notice and this permission notice shall be included in all\ncopies or substantial portions of the Software.\n\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\nSOFTWARE.\n\nSoftware: OpenCL-Headers v2020.12.18\nCopyright notice:\nCopyright (c) 2008-2020 The Khronos Group Inc.\nCopyright (c) 2013-2020 Intel Corporation All Rights Reserved.\nCopyright (c) 2018-2020 The Khronos Group Inc.\nCopyright (c) 2020 The Khronos Group Inc.\nCopyright (c) 2019-2020 The Khronos Group Inc.\nCopyright (c) 2013-2019 Intel Corporation All Rights Reserved.\n\n                              Apache License\n                        Version 2.0, January 2004\n                     http://www.apache.org/licenses/\n\nTERMS AND CONDITIONS FOR USE, REPRODUCTION, AND DISTRIBUTION\n\n1. Definitions.\n\n   \"License\" shall mean the terms and conditions for use, reproduction,\n   and distribution as defined by Sections 1 through 9 of this document.\n\n   \"Licensor\" shall mean the copyright owner or entity authorized by\n   the copyright owner that is granting the License.\n\n   \"Legal Entity\" shall mean the union of the acting entity and all\n   other entities that control, are controlled by, or are under common\n   control with that entity. For the purposes of this definition,\n   \"control\" means (i) the power, direct or indirect, to cause the\n   direction or management of such entity, whether by contract or\n   otherwise, or (ii) ownership of fifty percent (50%) or more of the\n   outstanding shares, or (iii) beneficial ownership of such entity.\n\n   \"You\" (or \"Your\") shall mean an individual or Legal Entity\n   exercising permissions granted by this License.\n\n   \"Source\" form shall mean the preferred form for making modifications,\n   including but not limited to software source code, documentation\n   source, and configuration files.\n\n   \"Object\" form shall mean any form resulting from mechanical\n   transformation or translation of a Source form, including but\n   not limited to compiled object code, generated documentation,\n   and conversions to other media types.\n\n   \"Work\" shall mean the work of authorship, whether in Source or\n   Object form, made available under the License, as indicated by a\n   copyright notice that is included in or attached to the work\n   (an example is provided in the Appendix below).\n\n   \"Derivative Works\" shall mean any work, whether in Source or Object\n   form, that is based on (or derived from) the Work and for which the\n   editorial revisions, annotations, elaborations, or other modifications\n   represent, as a whole, an original work of authorship. For the purposes\n   of this License, Derivative Works shall not include works that remain\n   separable from, or merely link (or bind by name) to the interfaces of,\n   the Work and Derivative Works thereof.\n\n   \"Contribution\" shall mean any work of authorship, including\n   the original version of the Work and any modifications or additions\n   to that Work or Derivative Works thereof, that is intentionally\n   submitted to Licensor for inclusion in the Work by the copyright owner\n   or by an individual or Legal Entity authorized to submit on behalf of\n   the copyright owner. For the purposes of this definition, \"submitted\"\n   means any form of electronic, verbal, or written communication sent\n   to the Licensor or its representatives, including but not limited to\n   communication on electronic mailing lists, source code control systems,\n   and issue tracking systems that are managed by, or on behalf of, the\n   Licensor for the purpose of discussing and improving the Work, but\n   excluding communication that is conspicuously marked or otherwise\n   designated in writing by the copyright owner as \"Not a Contribution.\"\n\n   \"Contributor\" shall mean Licensor and any individual or Legal Entity\n   on behalf of whom a Contribution has been received by Licensor and\n   subsequently incorporated within the Work.\n\n2. Grant of Copyright License. Subject to the terms and conditions of\n   this License, each Contributor hereby grants to You a perpetual,\n   worldwide, non-exclusive, no-charge, royalty-free, irrevocable\n   copyright license to reproduce, prepare Derivative Works of,\n   publicly display, publicly perform, sublicense, and distribute the\n   Work and such Derivative Works in Source or Object form.\n\n3. Grant of Patent License. Subject to the terms and conditions of\n   this License, each Contributor hereby grants to You a perpetual,\n   worldwide, non-exclusive, no-charge, royalty-free, irrevocable\n   (except as stated in this section) patent license to make, have made,\n   use, offer to sell, sell, import, and otherwise transfer the Work,\n   where such license applies only to those patent claims licensable\n   by such Contributor that are necessarily infringed by their\n   Contribution(s) alone or by combination of their Contribution(s)\n   with the Work to which such Contribution(s) was submitted. If You\n   institute patent litigation against any entity (including a\n   cross-claim or counterclaim in a lawsuit) alleging that the Work\n   or a Contribution incorporated within the Work constitutes direct\n   or contributory patent infringement, then any patent licenses\n   granted to You under this License for that Work shall terminate\n   as of the date such litigation is filed.\n\n4. Redistribution. You may reproduce and distribute copies of the\n   Work or Derivative Works thereof in any medium, with or without\n   modifications, and in Source or Object form, provided that You\n   meet the following conditions:\n\n   (a) You must give any other recipients of the Work or\n       Derivative Works a copy of this License; and\n\n   (b) You must cause any modified files to carry prominent notices\n       stating that You changed the files; and\n\n   (c) You must retain, in the Source form of any Derivative Works\n       that You distribute, all copyright, patent, trademark, and\n       attribution notices from the Source form of the Work,\n       excluding those notices that do not pertain to any part of\n       the Derivative Works; and\n\n   (d) If the Work includes a \"NOTICE\" text file as part of its\n       distribution, then any Derivative Works that You distribute must\n       include a readable copy of the attribution notices contained\n       within such NOTICE file, excluding those notices that do not\n       pertain to any part of the Derivative Works, in at least one\n       of the following places: within a NOTICE text file distributed\n       as part of the Derivative Works; within the Source form or\n       documentation, if provided along with the Derivative Works; or,\n       within a display generated by the Derivative Works, if and\n       wherever such third-party notices normally appear. The contents\n       of the NOTICE file are for informational purposes only and\n       do not modify the License. You may add Your own attribution\n       notices within Derivative Works that You distribute, alongside\n       or as an addendum to the NOTICE text from the Work, provided\n       that such additional attribution notices cannot be construed\n       as modifying the License.\n\n   You may add Your own copyright statement to Your modifications and\n   may provide additional or different license terms and conditions\n   for use, reproduction, or distribution of Your modifications, or\n   for any such Derivative Works as a whole, provided Your use,\n   reproduction, and distribution of the Work otherwise complies with\n   the conditions stated in this License.\n\n5. Submission of Contributions. Unless You explicitly state otherwise,\n   any Contribution intentionally submitted for inclusion in the Work\n   by You to the Licensor shall be under the terms and conditions of\n   this License, without any additional terms or conditions.\n   Notwithstanding the above, nothing herein shall supersede or modify\n   the terms of any separate license agreement you may have executed\n   with Licensor regarding such Contributions.\n\n6. Trademarks. This License does not grant permission to use the trade\n   names, trademarks, service marks, or product names of the Licensor,\n   except as required for reasonable and customary use in describing the\n   origin of the Work and reproducing the content of the NOTICE file.\n\n7. Disclaimer of Warranty. Unless required by applicable law or\n   agreed to in writing, Licensor provides the Work (and each\n   Contributor provides its Contributions) on an \"AS IS\" BASIS,\n   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or\n   implied, including, without limitation, any warranties or conditions\n   of TITLE, NON-INFRINGEMENT, MERCHANTABILITY, or FITNESS FOR A\n   PARTICULAR PURPOSE. You are solely responsible for determining the\n   appropriateness of using or redistributing the Work and assume any\n   risks associated with Your exercise of permissions under this License.\n\n8. Limitation of Liability. In no event and under no legal theory,\n   whether in tort (including negligence), contract, or otherwise,\n   unless required by applicable law (such as deliberate and grossly\n   negligent acts) or agreed to in writing, shall any Contributor be\n   liable to You for damages, including any direct, indirect, special,\n   incidental, or consequential damages of any character arising as a\n   result of this License or out of the use or inability to use the\n   Work (including but not limited to damages for loss of goodwill,\n   work stoppage, computer failure or malfunction, or any and all\n   other commercial damages or losses), even if such Contributor\n   has been advised of the possibility of such damages.\n\n9. Accepting Warranty or Additional Liability. While redistributing\n   the Work or Derivative Works thereof, You may choose to offer,\n   and charge a fee for, acceptance of support, warranty, indemnity,\n   or other liability obligations and/or rights consistent with this\n   License. However, in accepting such obligations, You may act only\n   on Your own behalf and on Your sole responsibility, not on behalf\n   of any other Contributor, and only if You agree to indemnify,\n   defend, and hold each Contributor harmless for any liability\n   incurred by, or claims asserted against, such Contributor by reason\n   of your accepting any such warranty or additional liability.\n\nEND OF TERMS AND CONDITIONS\n\nAPPENDIX: How to apply the Apache License to your work.\n\n   To apply the Apache License to your work, attach the following\n   boilerplate notice, with the fields enclosed by brackets \"[]\"\n   replaced with your own identifying information. (Don't include\n   the brackets!)  The text should be enclosed in the appropriate\n   comment syntax for the file format. We also recommend that a\n   file or class name and description of purpose be included on the\n   same \"printed page\" as the copyright notice for easier\n   identification within third-party archives.\n\nCopyright [yyyy] [name of copyright owner]\n\nLicensed under the Apache License, Version 2.0 (the \"License\");\nyou may not use this file except in compliance with the License.\nYou may obtain a copy of the License at\n\n    http://www.apache.org/licenses/LICENSE-2.0\n\nUnless required by applicable law or agreed to in writing, software\ndistributed under the License is distributed on an \"AS IS\" BASIS,\nWITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\nSee the License for the specific language governing permissions and\nlimitations under the License.\n\n\nSoftware: OpenCL-CLHPP v2.0.12\nCopyright notice:\nCopyright (c) 2008-2020 The Khronos Group Inc.\n\n                              Apache License\n                        Version 2.0, January 2004\n                     http://www.apache.org/licenses/\n\nTERMS AND CONDITIONS FOR USE, REPRODUCTION, AND DISTRIBUTION\n\n1. Definitions.\n\n   \"License\" shall mean the terms and conditions for use, reproduction,\n   and distribution as defined by Sections 1 through 9 of this document.\n\n   \"Licensor\" shall mean the copyright owner or entity authorized by\n   the copyright owner that is granting the License.\n\n   \"Legal Entity\" shall mean the union of the acting entity and all\n   other entities that control, are controlled by, or are under common\n   control with that entity. For the purposes of this definition,\n   \"control\" means (i) the power, direct or indirect, to cause the\n   direction or management of such entity, whether by contract or\n   otherwise, or (ii) ownership of fifty percent (50%) or more of the\n   outstanding shares, or (iii) beneficial ownership of such entity.\n\n   \"You\" (or \"Your\") shall mean an individual or Legal Entity\n   exercising permissions granted by this License.\n\n   \"Source\" form shall mean the preferred form for making modifications,\n   including but not limited to software source code, documentation\n   source, and configuration files.\n\n   \"Object\" form shall mean any form resulting from mechanical\n   transformation or translation of a Source form, including but\n   not limited to compiled object code, generated documentation,\n   and conversions to other media types.\n\n   \"Work\" shall mean the work of authorship, whether in Source or\n   Object form, made available under the License, as indicated by a\n   copyright notice that is included in or attached to the work\n   (an example is provided in the Appendix below).\n\n   \"Derivative Works\" shall mean any work, whether in Source or Object\n   form, that is based on (or derived from) the Work and for which the\n   editorial revisions, annotations, elaborations, or other modifications\n   represent, as a whole, an original work of authorship. For the purposes\n   of this License, Derivative Works shall not include works that remain\n   separable from, or merely link (or bind by name) to the interfaces of,\n   the Work and Derivative Works thereof.\n\n   \"Contribution\" shall mean any work of authorship, including\n   the original version of the Work and any modifications or additions\n   to that Work or Derivative Works thereof, that is intentionally\n   submitted to Licensor for inclusion in the Work by the copyright owner\n   or by an individual or Legal Entity authorized to submit on behalf of\n   the copyright owner. For the purposes of this definition, \"submitted\"\n   means any form of electronic, verbal, or written communication sent\n   to the Licensor or its representatives, including but not limited to\n   communication on electronic mailing lists, source code control systems,\n   and issue tracking systems that are managed by, or on behalf of, the\n   Licensor for the purpose of discussing and improving the Work, but\n   excluding communication that is conspicuously marked or otherwise\n   designated in writing by the copyright owner as \"Not a Contribution.\"\n\n   \"Contributor\" shall mean Licensor and any individual or Legal Entity\n   on behalf of whom a Contribution has been received by Licensor and\n   subsequently incorporated within the Work.\n\n2. Grant of Copyright License. Subject to the terms and conditions of\n   this License, each Contributor hereby grants to You a perpetual,\n   worldwide, non-exclusive, no-charge, royalty-free, irrevocable\n   copyright license to reproduce, prepare Derivative Works of,\n   publicly display, publicly perform, sublicense, and distribute the\n   Work and such Derivative Works in Source or Object form.\n\n3. Grant of Patent License. Subject to the terms and conditions of\n   this License, each Contributor hereby grants to You a perpetual,\n   worldwide, non-exclusive, no-charge, royalty-free, irrevocable\n   (except as stated in this section) patent license to make, have made,\n   use, offer to sell, sell, import, and otherwise transfer the Work,\n   where such license applies only to those patent claims licensable\n   by such Contributor that are necessarily infringed by their\n   Contribution(s) alone or by combination of their Contribution(s)\n   with the Work to which such Contribution(s) was submitted. If You\n   institute patent litigation against any entity (including a\n   cross-claim or counterclaim in a lawsuit) alleging that the Work\n   or a Contribution incorporated within the Work constitutes direct\n   or contributory patent infringement, then any patent licenses\n   granted to You under this License for that Work shall terminate\n   as of the date such litigation is filed.\n\n4. Redistribution. You may reproduce and distribute copies of the\n   Work or Derivative Works thereof in any medium, with or without\n   modifications, and in Source or Object form, provided that You\n   meet the following conditions:\n\n   (a) You must give any other recipients of the Work or\n       Derivative Works a copy of this License; and\n\n   (b) You must cause any modified files to carry prominent notices\n       stating that You changed the files; and\n\n   (c) You must retain, in the Source form of any Derivative Works\n       that You distribute, all copyright, patent, trademark, and\n       attribution notices from the Source form of the Work,\n       excluding those notices that do not pertain to any part of\n       the Derivative Works; and\n\n   (d) If the Work includes a \"NOTICE\" text file as part of its\n       distribution, then any Derivative Works that You distribute must\n       include a readable copy of the attribution notices contained\n       within such NOTICE file, excluding those notices that do not\n       pertain to any part of the Derivative Works, in at least one\n       of the following places: within a NOTICE text file distributed\n       as part of the Derivative Works; within the Source form or\n       documentation, if provided along with the Derivative Works; or,\n       within a display generated by the Derivative Works, if and\n       wherever such third-party notices normally appear. The contents\n       of the NOTICE file are for informational purposes only and\n       do not modify the License. You may add Your own attribution\n       notices within Derivative Works that You distribute, alongside\n       or as an addendum to the NOTICE text from the Work, provided\n       that such additional attribution notices cannot be construed\n       as modifying the License.\n\n   You may add Your own copyright statement to Your modifications and\n   may provide additional or different license terms and conditions\n   for use, reproduction, or distribution of Your modifications, or\n   for any such Derivative Works as a whole, provided Your use,\n   reproduction, and distribution of the Work otherwise complies with\n   the conditions stated in this License.\n\n5. Submission of Contributions. Unless You explicitly state otherwise,\n   any Contribution intentionally submitted for inclusion in the Work\n   by You to the Licensor shall be under the terms and conditions of\n   this License, without any additional terms or conditions.\n   Notwithstanding the above, nothing herein shall supersede or modify\n   the terms of any separate license agreement you may have executed\n   with Licensor regarding such Contributions.\n\n6. Trademarks. This License does not grant permission to use the trade\n   names, trademarks, service marks, or product names of the Licensor,\n   except as required for reasonable and customary use in describing the\n   origin of the Work and reproducing the content of the NOTICE file.\n\n7. Disclaimer of Warranty. Unless required by applicable law or\n   agreed to in writing, Licensor provides the Work (and each\n   Contributor provides its Contributions) on an \"AS IS\" BASIS,\n   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or\n   implied, including, without limitation, any warranties or conditions\n   of TITLE, NON-INFRINGEMENT, MERCHANTABILITY, or FITNESS FOR A\n   PARTICULAR PURPOSE. You are solely responsible for determining the\n   appropriateness of using or redistributing the Work and assume any\n   risks associated with Your exercise of permissions under this License.\n\n8. Limitation of Liability. In no event and under no legal theory,\n   whether in tort (including negligence), contract, or otherwise,\n   unless required by applicable law (such as deliberate and grossly\n   negligent acts) or agreed to in writing, shall any Contributor be\n   liable to You for damages, including any direct, indirect, special,\n   incidental, or consequential damages of any character arising as a\n   result of this License or out of the use or inability to use the\n   Work (including but not limited to damages for loss of goodwill,\n   work stoppage, computer failure or malfunction, or any and all\n   other commercial damages or losses), even if such Contributor\n   has been advised of the possibility of such damages.\n\n9. Accepting Warranty or Additional Liability. While redistributing\n   the Work or Derivative Works thereof, You may choose to offer,\n   and charge a fee for, acceptance of support, warranty, indemnity,\n   or other liability obligations and/or rights consistent with this\n   License. However, in accepting such obligations, You may act only\n   on Your own behalf and on Your sole responsibility, not on behalf\n   of any other Contributor, and only if You agree to indemnify,\n   defend, and hold each Contributor harmless for any liability\n   incurred by, or claims asserted against, such Contributor by reason\n   of your accepting any such warranty or additional liability.\n\nEND OF TERMS AND CONDITIONS\n\nAPPENDIX: How to apply the Apache License to your work.\n\n   To apply the Apache License to your work, attach the following\n   boilerplate notice, with the fields enclosed by brackets \"[]\"\n   replaced with your own identifying information. (Don't include\n   the brackets!)  The text should be enclosed in the appropriate\n   comment syntax for the file format. We also recommend that a\n   file or class name and description of purpose be included on the\n   same \"printed page\" as the copyright notice for easier\n   identification within third-party archives.\n\nCopyright [yyyy] [name of copyright owner]\n\nLicensed under the Apache License, Version 2.0 (the \"License\");\nyou may not use this file except in compliance with the License.\nYou may obtain a copy of the License at\n\n    http://www.apache.org/licenses/LICENSE-2.0\n\nUnless required by applicable law or agreed to in writing, software\ndistributed under the License is distributed on an \"AS IS\" BASIS,\nWITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\nSee the License for the specific language governing permissions and\nlimitations under the License.\n\nSoftware: CMSIS v5.7.0\nCopyright notice:\nCopyright (c) 2006-2012 ARM Limited. All rights reserved.\nCopyright (c) 2006-2016 ARM Limited. All rights reserved.\nCopyright (c) 2009-2013 ARM Limited. All rights reserved.\nCopyright (c) 2009-2016 ARM Limited. All rights reserved.\nCopyright (c) 2009-2017 ARM Limited. All rights reserved.\nCopyright (c) 2009-2018 ARM Limited. All rights reserved.\nCopyright (c) 2009-2019 ARM Limited. All rights reserved.\nCopyright (c) 2009-2020 ARM Limited. All rights reserved.\nCopyright (c) 2010 ARM Limited. All rights reserved.\nCopyright (c) 2010-2012 ARM Limited. All rights reserved.\nCopyright (c) 2010-2013 ARM Limited. All rights reserved.\nCopyright (c) 2010-2018 ARM Limited. All rights reserved.\nCopyright (c) 2010-2019 ARM Limited. All rights reserved.\nCopyright (c) 2010-2020 ARM Limited. All rights reserved.\nCopyright (c) 2011 ARM Limited. All rights reserved.\nCopyright (c) 2012-2011 ARM Limited. All rights reserved.\nCopyright (c) 2012-2018 ARM Limited. All rights reserved.\nCopyright (c) 2013-2016 ARM Limited. All rights reserved.\nCopyright (c) 2013-2017 ARM Limited. All rights reserved.\nCopyright (c) 2013-2018 ARM Limited. All rights reserved.\nCopyright (c) 2013-2019 ARM Limited. All rights reserved.\nCopyright (c) 2013-2020 ARM Limited. All rights reserved.\nCopyright (c) 2015-2016 ARM Limited. All rights reserved.\nCopyright (c) 2015-2020 ARM Limited. All rights reserved.\nCopyright (c) 2016 ARM Limited. All rights reserved.\nCopyright (c) 2016-2020 ARM Limited. All rights reserved.\nCopyright (c) 2017 ARM Limited. All rights reserved.\nCopyright (c) 2017-2017 ARM Limited. All rights reserved.\nCopyright (c) 2017-2018 ARM Limited. All rights reserved.\nCopyright (c) 2017-2019 ARM Limited. All rights reserved.\nCopyright (c) 2017-2020 ARM Limited. All rights reserved.\nCopyright (c) 2018-2020 ARM Limited. All rights reserved.\nCopyright (c) 2019-2020 ARM Limited. All rights reserved.\nCopyright (c) 2020 ARM Limited. All rights reserved.\nCopyright (c) 2009 by Dimitri van Heesch.\nCopyright (c) 2010 \"Cowboy\" ben Alman.\nCopyright (c) 1999-2009 KEIL, 2009-2016 ARM Germany GmbH. All rights reserved.\nCopyright (c) 1999-2009 KEIL, 2009-2017 ARM Germany GmbH. All rights reserved.\nCopyright (c) 1999-2009 KEIL, 2009-2018 ARM Germany GmbH. All rights reserved.\nCopyright (c) 1999-2009 KEIL, 2009-2019 ARM Germany GmbH. All rights reserved.\nCopyright (c) 2004-2016 ARM Germany GmbH. All rights reserved.\nCopyright (c) 2005-2014 ARM Germany GmbH. All rights reserved.\nCopyright (c) 2016 ARM Germany GmbH. All rights reserved.\nCopyright (c) 2016-2018 ARM Germany GmbH. All rights reserved.\nCopyright (c) 2005-2014 Keil Software. All rights reserved.\nCopyright (c) 2012-2017 Keil Software. All rights reserved.\nCopyright (c) 2012-2019 Keil Software. All rights reserved.\nCopyright (c) 2006,2007 CodeSourcery Inc\nCopyright (c) 2012 mbed.org\nCopyright (c) 2017-2018 IAR Systems\nCopyright (c) 2017-2019 IAR Systems\n\nApache License\nVersion 2.0, January 2004\nhttp://www.apache.org/licenses/\n\nTERMS AND CONDITIONS FOR USE, REPRODUCTION, AND DISTRIBUTION\n\n1. Definitions.\n\n   \"License\" shall mean the terms and conditions for use, reproduction,\n   and distribution as defined by Sections 1 through 9 of this document.\n\n   \"Licensor\" shall mean the copyright owner or entity authorized by\n   the copyright owner that is granting the License.\n\n   \"Legal Entity\" shall mean the union of the acting entity and all\n   other entities that control, are controlled by, or are under common\n   control with that entity. For the purposes of this definition,\n   \"control\" means (i) the power, direct or indirect, to cause the\n   direction or management of such entity, whether by contract or\n   otherwise, or (ii) ownership of fifty percent (50%) or more of the\n   outstanding shares, or (iii) beneficial ownership of such entity.\n\n   \"You\" (or \"Your\") shall mean an individual or Legal Entity\n   exercising permissions granted by this License.\n\n   \"Source\" form shall mean the preferred form for making modifications,\n   including but not limited to software source code, documentation\n   source, and configuration files.\n\n   \"Object\" form shall mean any form resulting from mechanical\n   transformation or translation of a Source form, including but\n   not limited to compiled object code, generated documentation,\n   and conversions to other media types.\n\n   \"Work\" shall mean the work of authorship, whether in Source or\n   Object form, made available under the License, as indicated by a\n   copyright notice that is included in or attached to the work\n   (an example is provided in the Appendix below).\n\n   \"Derivative Works\" shall mean any work, whether in Source or Object\n   form, that is based on (or derived from) the Work and for which the\n   editorial revisions, annotations, elaborations, or other modifications\n   represent, as a whole, an original work of authorship. For the purposes\n   of this License, Derivative Works shall not include works that remain\n   separable from, or merely link (or bind by name) to the interfaces of,\n   the Work and Derivative Works thereof.\n\n   \"Contribution\" shall mean any work of authorship, including\n   the original version of the Work and any modifications or additions\n   to that Work or Derivative Works thereof, that is intentionally\n   submitted to Licensor for inclusion in the Work by the copyright owner\n   or by an individual or Legal Entity authorized to submit on behalf of\n   the copyright owner. For the purposes of this definition, \"submitted\"\n   means any form of electronic, verbal, or written communication sent\n   to the Licensor or its representatives, including but not limited to\n   communication on electronic mailing lists, source code control systems,\n   and issue tracking systems that are managed by, or on behalf of, the\n   Licensor for the purpose of discussing and improving the Work, but\n   excluding communication that is conspicuously marked or otherwise\n   designated in writing by the copyright owner as \"Not a Contribution.\"\n\n   \"Contributor\" shall mean Licensor and any individual or Legal Entity\n   on behalf of whom a Contribution has been received by Licensor and\n   subsequently incorporated within the Work.\n\n2. Grant of Copyright License. Subject to the terms and conditions of\n   this License, each Contributor hereby grants to You a perpetual,\n   worldwide, non-exclusive, no-charge, royalty-free, irrevocable\n   copyright license to reproduce, prepare Derivative Works of,\n   publicly display, publicly perform, sublicense, and distribute the\n   Work and such Derivative Works in Source or Object form.\n\n3. Grant of Patent License. Subject to the terms and conditions of\n   this License, each Contributor hereby grants to You a perpetual,\n   worldwide, non-exclusive, no-charge, royalty-free, irrevocable\n   (except as stated in this section) patent license to make, have made,\n   use, offer to sell, sell, import, and otherwise transfer the Work,\n   where such license applies only to those patent claims licensable\n   by such Contributor that are necessarily infringed by their\n   Contribution(s) alone or by combination of their Contribution(s)\n   with the Work to which such Contribution(s) was submitted. If You\n   institute patent litigation against any entity (including a\n   cross-claim or counterclaim in a lawsuit) alleging that the Work\n   or a Contribution incorporated within the Work constitutes direct\n   or contributory patent infringement, then any patent licenses\n   granted to You under this License for that Work shall terminate\n   as of the date such litigation is filed.\n\n4. Redistribution. You may reproduce and distribute copies of the\n   Work or Derivative Works thereof in any medium, with or without\n   modifications, and in Source or Object form, provided that You\n   meet the following conditions:\n\n   (a) You must give any other recipients of the Work or\n vative Works a copy of this License; and\n\n   (b) You must cause any modified files to carry prominent notices\n ing that You changed the files; and\n\n   (c) You must retain, in the Source form of any Derivative Works\n  You distribute, all copyright, patent, trademark, and\n ibution notices from the Source form of the Work,\n uding those notices that do not pertain to any part of\n Derivative Works; and\n\n   (d) If the Work includes a \"NOTICE\" text file as part of its\n ribution, then any Derivative Works that You distribute must\n ude a readable copy of the attribution notices contained\n in such NOTICE file, excluding those notices that do not\n ain to any part of the Derivative Works, in at least one\n he following places: within a NOTICE text file distributed\n art of the Derivative Works; within the Source form or\n mentation, if provided along with the Derivative Works; or,\n in a display generated by the Derivative Works, if and\n ever such third-party notices normally appear. The contents\n he NOTICE file are for informational purposes only and\n ot modify the License. You may add Your own attribution\n ces within Derivative Works that You distribute, alongside\n s an addendum to the NOTICE text from the Work, provided\n  such additional attribution notices cannot be construed\n odifying the License.\n\n   You may add Your own copyright statement to Your modifications and\n   may provide additional or different license terms and conditions\n   for use, reproduction, or distribution of Your modifications, or\n   for any such Derivative Works as a whole, provided Your use,\n   reproduction, and distribution of the Work otherwise complies with\n   the conditions stated in this License.\n\n5. Submission of Contributions. Unless You explicitly state otherwise,\n   any Contribution intentionally submitted for inclusion in the Work\n   by You to the Licensor shall be under the terms and conditions of\n   this License, without any additional terms or conditions.\n   Notwithstanding the above, nothing herein shall supersede or modify\n   the terms of any separate license agreement you may have executed\n   with Licensor regarding such Contributions.\n\n6. Trademarks. This License does not grant permission to use the trade\n   names, trademarks, service marks, or product names of the Licensor,\n   except as required for reasonable and customary use in describing the\n   origin of the Work and reproducing the content of the NOTICE file.\n\n7. Disclaimer of Warranty. Unless required by applicable law or\n   agreed to in writing, Licensor provides the Work (and each\n   Contributor provides its Contributions) on an \"AS IS\" BASIS,\n   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or\n   implied, including, without limitation, any warranties or conditions\n   of TITLE, NON-INFRINGEMENT, MERCHANTABILITY, or FITNESS FOR A\n   PARTICULAR PURPOSE. You are solely responsible for determining the\n   appropriateness of using or redistributing the Work and assume any\n   risks associated with Your exercise of permissions under this License.\n\n8. Limitation of Liability. In no event and under no legal theory,\n   whether in tort (including negligence), contract, or otherwise,\n   unless required by applicable law (such as deliberate and grossly\n   negligent acts) or agreed to in writing, shall any Contributor be\n   liable to You for damages, including any direct, indirect, special,\n   incidental, or consequential damages of any character arising as a\n   result of this License or out of the use or inability to use the\n   Work (including but not limited to damages for loss of goodwill,\n   work stoppage, computer failure or malfunction, or any and all\n   other commercial damages or losses), even if such Contributor\n   has been advised of the possibility of such damages.\n\n9. Accepting Warranty or Additional Liability. While redistributing\n   the Work or Derivative Works thereof, You may choose to offer,\n   and charge a fee for, acceptance of support, warranty, indemnity,\n   or other liability obligations and/or rights consistent with this\n   License. However, in accepting such obligations, You may act only\n   on Your own behalf and on Your sole responsibility, not on behalf\n   of any other Contributor, and only if You agree to indemnify,\n   defend, and hold each Contributor harmless for any liability\n   incurred by, or claims asserted against, such Contributor by reason\n   of your accepting any such warranty or additional liability.\n\n   END OF TERMS AND CONDITIONS\n\n   APPENDIX: How to apply the Apache License to your work.\n\n   To apply the Apache License to your work, attach the following\n   boilerplate notice, with the fields enclosed by brackets \"[]\"\n   replaced with your own identifying information. (Don't include\n   the brackets!)  The text should be enclosed in the appropriate\n   comment syntax for the file format. We also recommend that a\n   file or class name and description of purpose be included on the\n   same \"printed page\" as the copyright notice for easier\n   identification within third-party archives.\n\n   Copyright [yyyy] [name of copyright owner]\n\n   Licensed under the Apache License, Version 2.0 (the \"License\");\n   you may not use this file except in compliance with the License.\n   You may obtain a copy of the License at://www.apache.org/licenses/LICENSE-2.0\n\n   Unless required by applicable law or agreed to in writing, software\n   distributed under the License is distributed on an \"AS IS\" BASIS,\n   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n   See the License for the specific language governing permissions and\n   limitations under the License.\n\nSoftware: abseil-cpp 20210324.2\nCopyright notice:\nCopyright 2016 Google Inc. All Rights Reserved.\nCopyright 2017 Google Inc. All Rights Reserved.\nCopyright 2017 The Abseil Authors.\nCopyright 2018 The Abseil Authors.\nCopyright 2019 The Abseil Authors.\nCopyright 2020 The Abseil Authors.\n\nApache License\n                           Version 2.0, January 2004\n                        https://www.apache.org/licenses/\n\n   TERMS AND CONDITIONS FOR USE, REPRODUCTION, AND DISTRIBUTION\n\n   1. Definitions.\n\n      \"License\" shall mean the terms and conditions for use, reproduction,\n      and distribution as defined by Sections 1 through 9 of this document.\n\n      \"Licensor\" shall mean the copyright owner or entity authorized by\n      the copyright owner that is granting the License.\n\n      \"Legal Entity\" shall mean the union of the acting entity and all\n      other entities that control, are controlled by, or are under common\n      control with that entity. For the purposes of this definition,\n      \"control\" means (i) the power, direct or indirect, to cause the\n      direction or management of such entity, whether by contract or\n      otherwise, or (ii) ownership of fifty percent (50%) or more of the\n      outstanding shares, or (iii) beneficial ownership of such entity.\n\n      \"You\" (or \"Your\") shall mean an individual or Legal Entity\n      exercising permissions granted by this License.\n\n      \"Source\" form shall mean the preferred form for making modifications,\n      including but not limited to software source code, documentation\n      source, and configuration files.\n\n      \"Object\" form shall mean any form resulting from mechanical\n      transformation or translation of a Source form, including but\n      not limited to compiled object code, generated documentation,\n      and conversions to other media types.\n\n      \"Work\" shall mean the work of authorship, whether in Source or\n      Object form, made available under the License, as indicated by a\n      copyright notice that is included in or attached to the work\n      (an example is provided in the Appendix below).\n\n      \"Derivative Works\" shall mean any work, whether in Source or Object\n      form, that is based on (or derived from) the Work and for which the\n      editorial revisions, annotations, elaborations, or other modifications\n      represent, as a whole, an original work of authorship. For the purposes\n      of this License, Derivative Works shall not include works that remain\n      separable from, or merely link (or bind by name) to the interfaces of,\n      the Work and Derivative Works thereof.\n\n      \"Contribution\" shall mean any work of authorship, including\n      the original version of the Work and any modifications or additions\n      to that Work or Derivative Works thereof, that is intentionally\n      submitted to Licensor for inclusion in the Work by the copyright owner\n      or by an individual or Legal Entity authorized to submit on behalf of\n      the copyright owner. For the purposes of this definition, \"submitted\"\n      means any form of electronic, verbal, or written communication sent\n      to the Licensor or its representatives, including but not limited to\n      communication on electronic mailing lists, source code control systems,\n      and issue tracking systems that are managed by, or on behalf of, the\n      Licensor for the purpose of discussing and improving the Work, but\n      excluding communication that is conspicuously marked or otherwise\n      designated in writing by the copyright owner as \"Not a Contribution.\"\n\n      \"Contributor\" shall mean Licensor and any individual or Legal Entity\n      on behalf of whom a Contribution has been received by Licensor and\n      subsequently incorporated within the Work.\n\n   2. Grant of Copyright License. Subject to the terms and conditions of\n      this License, each Contributor hereby grants to You a perpetual,\n      worldwide, non-exclusive, no-charge, royalty-free, irrevocable\n      copyright license to reproduce, prepare Derivative Works of,\n      publicly display, publicly perform, sublicense, and distribute the\n      Work and such Derivative Works in Source or Object form.\n\n   3. Grant of Patent License. Subject to the terms and conditions of\n      this License, each Contributor hereby grants to You a perpetual,\n      worldwide, non-exclusive, no-charge, royalty-free, irrevocable\n      (except as stated in this section) patent license to make, have made,\n      use, offer to sell, sell, import, and otherwise transfer the Work,\n      where such license applies only to those patent claims licensable\n      by such Contributor that are necessarily infringed by their\n      Contribution(s) alone or by combination of their Contribution(s)\n      with the Work to which such Contribution(s) was submitted. If You\n      institute patent litigation against any entity (including a\n      cross-claim or counterclaim in a lawsuit) alleging that the Work\n      or a Contribution incorporated within the Work constitutes direct\n      or contributory patent infringement, then any patent licenses\n      granted to You under this License for that Work shall terminate\n      as of the date such litigation is filed.\n\n   4. Redistribution. You may reproduce and distribute copies of the\n      Work or Derivative Works thereof in any medium, with or without\n      modifications, and in Source or Object form, provided that You\n      meet the following conditions:\n\n      (a) You must give any other recipients of the Work or\n          Derivative Works a copy of this License; and\n\n      (b) You must cause any modified files to carry prominent notices\n          stating that You changed the files; and\n\n      (c) You must retain, in the Source form of any Derivative Works\n          that You distribute, all copyright, patent, trademark, and\n          attribution notices from the Source form of the Work,\n          excluding those notices that do not pertain to any part of\n          the Derivative Works; and\n\n      (d) If the Work includes a \"NOTICE\" text file as part of its\n          distribution, then any Derivative Works that You distribute must\n          include a readable copy of the attribution notices contained\n          within such NOTICE file, excluding those notices that do not\n          pertain to any part of the Derivative Works, in at least one\n          of the following places: within a NOTICE text file distributed\n          as part of the Derivative Works; within the Source form or\n          documentation, if provided along with the Derivative Works; or,\n          within a display generated by the Derivative Works, if and\n          wherever such third-party notices normally appear. The contents\n          of the NOTICE file are for informational purposes only and\n          do not modify the License. You may add Your own attribution\n          notices within Derivative Works that You distribute, alongside\n          or as an addendum to the NOTICE text from the Work, provided\n          that such additional attribution notices cannot be construed\n          as modifying the License.\n\n      You may add Your own copyright statement to Your modifications and\n      may provide additional or different license terms and conditions\n      for use, reproduction, or distribution of Your modifications, or\n      for any such Derivative Works as a whole, provided Your use,\n      reproduction, and distribution of the Work otherwise complies with\n      the conditions stated in this License.\n\n   5. Submission of Contributions. Unless You explicitly state otherwise,\n      any Contribution intentionally submitted for inclusion in the Work\n      by You to the Licensor shall be under the terms and conditions of\n      this License, without any additional terms or conditions.\n      Notwithstanding the above, nothing herein shall supersede or modify\n      the terms of any separate license agreement you may have executed\n      with Licensor regarding such Contributions.\n\n   6. Trademarks. This License does not grant permission to use the trade\n      names, trademarks, service marks, or product names of the Licensor,\n      except as required for reasonable and customary use in describing the\n      origin of the Work and reproducing the content of the NOTICE file.\n\n   7. Disclaimer of Warranty. Unless required by applicable law or\n      agreed to in writing, Licensor provides the Work (and each\n      Contributor provides its Contributions) on an \"AS IS\" BASIS,\n      WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or\n      implied, including, without limitation, any warranties or conditions\n      of TITLE, NON-INFRINGEMENT, MERCHANTABILITY, or FITNESS FOR A\n      PARTICULAR PURPOSE. You are solely responsible for determining the\n      appropriateness of using or redistributing the Work and assume any\n      risks associated with Your exercise of permissions under this License.\n\n   8. Limitation of Liability. In no event and under no legal theory,\n      whether in tort (including negligence), contract, or otherwise,\n      unless required by applicable law (such as deliberate and grossly\n      negligent acts) or agreed to in writing, shall any Contributor be\n      liable to You for damages, including any direct, indirect, special,\n      incidental, or consequential damages of any character arising as a\n      result of this License or out of the use or inability to use the\n      Work (including but not limited to damages for loss of goodwill,\n      work stoppage, computer failure or malfunction, or any and all\n      other commercial damages or losses), even if such Contributor\n      has been advised of the possibility of such damages.\n\n   9. Accepting Warranty or Additional Liability. While redistributing\n      the Work or Derivative Works thereof, You may choose to offer,\n      and charge a fee for, acceptance of support, warranty, indemnity,\n      or other liability obligations and/or rights consistent with this\n      License. However, in accepting such obligations, You may act only\n      on Your own behalf and on Your sole responsibility, not on behalf\n      of any other Contributor, and only if You agree to indemnify,\n      defend, and hold each Contributor harmless for any liability\n      incurred by, or claims asserted against, such Contributor by reason\n      of your accepting any such warranty or additional liability.\n\n   END OF TERMS AND CONDITIONS\n\n   APPENDIX: How to apply the Apache License to your work.\n\n      To apply the Apache License to your work, attach the following\n      boilerplate notice, with the fields enclosed by brackets \"[]\"\n      replaced with your own identifying information. (Don't include\n      the brackets!)  The text should be enclosed in the appropriate\n      comment syntax for the file format. We also recommend that a\n      file or class name and description of purpose be included on the\n      same \"printed page\" as the copyright notice for easier\n      identification within third-party archives.\n\n   Copyright [yyyy] [name of copyright owner]\n\n   Licensed under the Apache License, Version 2.0 (the \"License\");\n   you may not use this file except in compliance with the License.\n   You may obtain a copy of the License at\n\n       https://www.apache.org/licenses/LICENSE-2.0\n\n   Unless required by applicable law or agreed to in writing, software\n   distributed under the License is distributed on an \"AS IS\" BASIS,\n   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n   See the License for the specific language governing permissions and\n   limitations under the License.\n\nSoftware: c-ares 1.15.0\nCopyright notice:\nCopyright (c) 2012 Dan Winship\nCopyright (C) 2005 by Dominick Meglio\nCopyright (C) 2009-2013 by Daniel Stenberg\nCopyright (C) 2003-2018 Free Software Foundation, Inc.\nCopyright (c) 2011 Daniel Stenberg <daniel@haxx.se>\nCopyright (c) 1996-1999 by Internet Software Consortium.\nCopyright (C) 2005, 2013 by Dominick Meglio\nCopyright (C) 2017 by John Schember <john@nachtimwald.com>\nCopyright (C) 2008-2013 by Daniel Stenberg\n.\\\" Copyright 2004 by Daniel Stenberg\ndefine ARESCOPYRIGHT \"2004 - 2017 Daniel Stenberg, <daniel@haxx.se>.\"\nCopyright (c) 1996,1999 by Internet Software Consortium.\nCopyright (c) 2013 Roy Stogner <roystgnr@ices.utexas.edu>\nCopyright (C) 2004-2005, 2007-2008, 2011-2015 Free Software Foundation, Inc.\nCopyright (C) 1996-2018 Free Software Foundation, Inc.\nCopyright (C) 2005 - 2010, Daniel Stenberg\nCopyright (c) 2012 Philip Withnall\nCopyright (C) 2004 - 2012 by Daniel Stenberg et al\nCopyright (C) 2004-2010 by Daniel Stenberg.\nCopyright (C) 2004-2009 by Daniel Stenberg.\nCopyright (C) 2004-2009 by Daniel Stenberg\nCopyright 2003 Google Inc.\nCopyright (c) 2008 Steven G. Johnson <stevenj@alum.mit.edu>\n.\\\" Copyright 2005 by Dominick Meglio.\n.\\\" Copyright (C) 2017 by John Schember\nCopyright (C) 2010 Jeremy Lal <kapouer@melix.org>\nCopyright (C) 2009 by Jakub Hrozek <jhrozek@redhat.com>\nCopyright (c) 2012 Christian Persch\n.\\\" Copyright (C) 2013 by Daniel Stenberg\nCopyright 2005, Google Inc.\nCopyright 2013, Google Inc.\nCopyright (C) 2011 Free Software Foundation, Inc.\nCopyright (C) 2018 by John Schember <john@nachtimwald.com>\nCopyright (c) 2008 Benjamin Kosnik <bkoz@redhat.com>\nCopyright 2005 by Dominick Meglio\nCopyright (C) 2004-2005, 2007, 2009, 2011-2015 Free Software Foundation, Inc.\nCopyright (c) 2012 Paolo Borelli\nCopyright (C) 2009 by Daniel Stenberg et al\nCopyright (C) 1996-2001, 2003-2015 Free Software Foundation, Inc.\nCopyright 1998, 2000 by the Massachusetts Institute of Technology.\nCopyright (C) 2004-2005, 2007-2009, 2011-2015 Free Software Foundation, Inc.\nCopyright (C) 2009-2018 Free Software Foundation, Inc.\nCopyright 2005 by Dominick Meglio.\nCopyright (c) 2013 Daniel Stenberg <daniel@haxx.se>\nCopyright (C) 1994 X Consortium\nCopyright 2008 Google Inc.\nCopyright (C) 1999-2018 Free Software Foundation, Inc.\nCopyright 1998, 2011, 2013 by the Massachusetts Institute of Technology.\n.\\\" Copyright 1998 by the Massachusetts Institute of Technology.\n.\\\" Copyright (C) 2004-2010 by Daniel Stenberg\nCopyright (c) 2004 by Internet Systems Consortium, Inc. (\"ISC\")\nCopyright 1992-2018 Free Software Foundation, Inc.\nCopyright 2015, Google Inc.\nCopyright (C) 2004-2018 Free Software Foundation, Inc.\nCopyright (C) 2012 Free Software Foundation, Inc.\nCopyright (C) 2010-2012 by Daniel Stenberg\nCopyright (c) 2012 Xan Lopez\n- aresversion.h: copyright end range year is now 2013\nCopyright (c) 2014, 2015 Google Inc.; contributed by Alexey Sokolov <sokolov@google.com>\nCopyright 2000 by the Massachusetts Institute of Technology.\nCopyright (C) 2009 - 2013 by Daniel Stenberg et al\nCopyright (C) 2004 by Daniel Stenberg et al\nCopyright (C) 2006-2018 Free Software Foundation, Inc.\nCopyright (C) 2008 - 2013 by Daniel Stenberg et al\nCopyright 2006, Google Inc.\nCopyright (C) 2009-2016 by Daniel Stenberg\n.\\\" Copyright (C) 2004-2009 by Daniel Stenberg\nCopyright (C) 2004-2010 by Daniel Stenberg\nCopyright (c) 2007 - 2018, Daniel Stenberg with many contributors, see AUTHORS file.\n.\\\" Copyright 2010 by Ben Greear <greearb@candelatech.com>\nCopyright 2007, Google Inc.\nCopyright (C) 1997-2018 Free Software Foundation, Inc.\nCopyright 1998, 2011 by the Massachusetts Institute of Technology.\n.\\\" Copyright 1998, 2000 by the Massachusetts Institute of Technology.\nCopyright (C) 2004-2011 by Daniel Stenberg\nCopyright (C) 2008 - 2009 by Daniel Stenberg et al\nCopyright (C) 2005-2013 by Daniel Stenberg et al\nCopyright 2008, Google Inc.\nCopyright (C) 2004-2017 by Daniel Stenberg\n.\\\" Copyright (C) 2016 by Daniel Stenberg\nCopyright (C) 2010-2013 by Daniel Stenberg\nCopyright (c) 1987-2001 The Regents of the University of California.\nCopyright (C) 2008 - 2012 by Daniel Stenberg et al\nCopyright (C) 2009-2013 by Daniel Stenberg et al\nCopyright (c) 2015 Bastien ROUCARIES\n.\\\" Copyright 2000 by the Massachusetts Institute of Technology.\nCopyright 2005 Dominick Meglio\n.\\\" Copyright 1998 by Daniel Stenberg\nCopyright (c) 2011 Daniel Richard G. <skunk@iSKUNK.ORG>\nCopyright (C) 2001-2018 Free Software Foundation, Inc.\nCopyright (C) 2004 - 2011 by Daniel Stenberg et al\nCopyright (C) 2004 - 2013 by Daniel Stenberg et al\nCopyright (C) 2012 Marko Kreen <markokr@gmail.com>\n.\\\" Copyright (C) 2008-2010 by Daniel Stenberg\nCopyright (C) 2008 by Daniel Stenberg et al\nCopyright 1998 by the Massachusetts Institute of Technology.\nCopyright (C) 2008-2010 by Daniel Stenberg\nCopyright (C) 2017 by John Schember\nCopyright (C) 2004, 2011-2015 Free Software Foundation, Inc.\nCopyright (C) 2002-2018 Free Software Foundation, Inc.\nCopyright (C) 2007-2013 by Daniel Stenberg\nCopyright 2009 Google Inc.\nCopyright (C) 1994-2018 Free Software Foundation, Inc.\nCopyright (C) 1992-1996, 1998-2012 Free Software Foundation, Inc.\nCopyright (C) 2014 Free Software Foundation, Inc.\nCopyright (c) 2012 Zack Weinberg <zackw@panix.com>\n\nCopyright 1998 by the Massachusetts Institute of Technology.\n\nPermission to use, copy, modify, and distribute this software and its\ndocumentation for any purpose and without fee is hereby granted, provided that\nthe above copyright notice appear in all copies and that both that copyright\nnotice and this permission notice appear in supporting documentation, and that\nthe name of M.I.T. not be used in advertising or publicity pertaining to\ndistribution of the software without specific, written prior permission.\nM.I.T. makes no representations about the suitability of this software for any\npurpose.  It is provided \"as is\" without express or implied warranty.\n\nSoftware: numpy 1.17.0\nCopyright notice:\nCopyright (c) 1995, 1996, 1997 Jim Hugunin, hugunin@mit.edu\nCopyright 2014 Melissa O'Neill <oneill@pcg-random.org>\nCopyright (c) 2006, University of Georgia and Pierre G.F. Gerard-Marchant All rights reserved.\nCopyright 1999-2004 Pearu Peterson all rights reserved, Pearu Peterson <pearu@ioc.ee>\nCopyright (c) 2009-2019: Jeff Bezanson, Stefan Karpinski, Viral B. Shah, and other contributors:\nCopyright (c) 2003-2005, Jean-Sebastien Roy (js@jeannot.org)\ncopyright = '2008-2019, The SciPy community'\nCopyright 2002 Pearu Peterson all rights reserved, Pearu Peterson <pearu@cens.ioc.ee>\nCopyright (c) 2019 NumPy Developers\nCopyright (c) 2005-2017, NumPy Developers.\nCopyright (c) 2018 Melissa E. O'Neill\nCopyright (c) 2008 Ian Bicking and Contributors\nCopyright (c) 1992-2013 The University of Tennessee and The University of Tennessee Research Foundation.  All rights reserved.\nCopyright 1999, 2000, 2001 Regents of the University of California.\nCopyright (c) 2005, NumPy Developers\nCopyright (c) 2019 Kevin Sheppard. All rights reserved.\nCopyright 2010-2012, D. E. Shaw Research.\nCopyright (c) 2011 by Mark Wiebe (mwwiebe@gmail.com)\nCopyright 2006, Dean Edwards\nCopyright (c) 2014 Ryan Juckett\nCopyright 2001-2005 Pearu Peterson all rights reserved, Pearu Peterson <pearu@cens.ioc.ee>\ncopyright = u'2017-2018, NumPy Developers'\nCopyright (C) 2004-2018 Max-Planck-Society \\author Martin Reinecke\nCopyright (c) 2010-2011 by Mark Wiebe (mwwiebe@gmail.com)\nCopyright (c) 2012 Stephen Montgomery-Smith <stephen@FreeBSD.ORG>\nCopyright (c) 2005-2019, NumPy Developers.\nCopyright (c) 2011 Enthought, Inc\nCopyright (c) 2007, 2011 David Schultz <das@FreeBSD.ORG>\nCopyright (c) 2000-2013 The University of California Berkeley. All rights reserved.\nCopyright (c) 2015 Pauli Virtanen All rights reserved.\nCopyright 1999,2000 Pearu Peterson all rights reserved, Pearu Peterson <pearu@ioc.ee>\nCopyright (C) 1997 - 2002, Makoto Matsumoto and Takuji Nishimura, All rights reserved.\nCopyright (c) 2005-2015, NumPy Developers.\nCopyright (c) 2011 by Enthought, Inc.\nCopyright (c) 2010 by Mark Wiebe (mwwiebe@gmail.com)\nCopyright 2000 Pearu Peterson all rights reserved, Pearu Peterson <pearu@ioc.ee>\nf90: Copyright Absoft Corporation 1994-1998 mV2; Cray Research, Inc. 1994-1996 CF90 (2.x.x.x  f36t87) Version 2.3 Wed Apr 19, 2006  13:05:16\nCopyright (c) 2006-2013 The University of Colorado Denver.  All rights reserved.\nf90: Copyright Absoft Corporation 1994-2002; Absoft Pro FORTRAN Version 8.0\nCopyright (C) 1993 by Sun Microsystems, Inc. All rights reserved.\nCopyright 1999--2011 Pearu Peterson all rights reserved, Pearu Peterson <pearu@cens.ioc.ee>\nCopyright 1999 - 2011 Pearu Peterson all rights reserved.\nCopyright 2015 Robert Kern <robert.kern@gmail.com>\nCopyright (c) 2015 Melissa E. O'Neill\n\nCopyright (c) 2005-2019, NumPy Developers.\nAll rights reserved.\n\nRedistribution and use in source and binary forms, with or without\nmodification, are permitted provided that the following conditions are\nmet:\n\n    * Redistributions of source code must retain the above copyright\n       notice, this list of conditions and the following disclaimer.\n\n    * Redistributions in binary form must reproduce the above\n       copyright notice, this list of conditions and the following\n       disclaimer in the documentation and/or other materials provided\n       with the distribution.\n\n    * Neither the name of the NumPy Developers nor the names of any\n       contributors may be used to endorse or promote products derived\n       from this software without specific prior written permission.\n\nTHIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS\n\"AS IS\" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT\nLIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR\nA PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT\nOWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,\nSPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT\nLIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,\nDATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY\nTHEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT\n(INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE\nOF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n\nSoftware: opencv-python 4.1.2.30\nCopyright notice:\nCopyright (C) 2000-2018, Intel Corporation, all rights reserved.\nCopyright (C) 2009-2011, Willow Garage Inc., all rights reserved.\nCopyright (C) 2015-2016, OpenCV Foundation, all rights reserved.\nCopyright (C) 2009-2016, NVIDIA Corporation, all rights reserved.\nCopyright (c) 2010, The WebM Project authors. All rights reserved.\nCopyright (C) 2010-2013, Advanced Micro Devices, Inc., all rights reserved.\nCopyright (C) 2015-2016, Itseez Inc., all rights reserved.\nCopyright (c) 2016-2018 Olli-Pekka Heinisuo and contributors\nCopyright (C) 1991, 1999 Free Software Foundation, Inc.\n\nMIT License\n\nCopyright (c) 2016-2018 Olli-Pekka Heinisuo and contributors\n\nPermission is hereby granted, free of charge, to any person obtaining a copy\nof this software and associated documentation files (the \"Software\"), to deal\nin the Software without restriction, including without limitation the rights\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\ncopies of the Software, and to permit persons to whom the Software is\nfurnished to do so, subject to the following conditions:\n\nThe above copyright notice and this permission notice shall be included in all\ncopies or substantial portions of the Software.\n\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\nSOFTWARE.\n\nSoftware: pandas 1.0.2\nCopyright notice:\nCopyright (c) 2005-2011, NumPy Developers.\nCopyright (c) 2007  Nick Galbreath -- nickg [at] modp [dot] com. All rights reserved.\n(src/search/.c) functions are Copyright © 2011 Szabolcs Nagy and licensed under following terms: \"Permission to use, copy, modify, and/or distribute this code for any purpose with or without fee is hereby granted. There is no warranty.\"\nCopyright (c) 2015-     - Paul Ganssle <paul@ganssle.io>\nCopyright (c) 2003-2012 SciPy Developers.\nCopyright (c) 2012, Lambda Foundry, Inc.\nCopyright © 2003-2009 Steven G. Kargl or\nCopyright © 1994 David Burren. It is licensed under a BSD license.\nCopyright © 2003-2011 David Schultz or\nCopyright (C) 2002 Michael Ringgaard. All rights reserved.\nCopyright (c) 2010, Albert Sweigart All rights reserved.\nCopyright (c) 1991 - 1995, Stichting Mathematisch Centrum Amsterdam, The Netherlands.  All rights reserved.\nCopyright (c) 2006 Alexander Chemeris\nCopyright (c) 2003-2011 - Gustavo Niemeyer <gustavo@niemeyer.net>\naddcopyright = Appender(\"Copyright (c) 2009\", join='\\n')\nCopyright (c) 2015 Jared Hobbs\nCopyright (c) 2005-2011, NumPy Developers All rights reserved.\nCopyright (c) 2001, 2002 Enthought, Inc.\nCopyright (c) 2015-     - dateutil contributors (see AUTHORS file)\nCopyright 2017- Paul Ganssle <paul@ganssle.io>\nCopyright © 2005-2014 Rich Felker, et al.\ncopyright = \"2008-2014, the pandas development team\"\nCopyright (c) 2010-2012 Archipel Asset Management AB.\nCopyright (c) 2008, 2009, 2011 by Attractive Chaos <attractor@live.co.uk>\nCopyright (c) 2011-2012, Lambda Foundry, Inc.\nCopyright (c) 1988-1993 The Regents of the University of California.\nCopyright (c) 2012, PyData Development Team All rights reserved.\nCopyright (C) 2012 Google Inc.\nCopyright (c) 2006-2008 Alexander Chemeris\ncopyright 2013, y-p @ github\nCopyright (c) 2012, Lambda Foundry, Inc., except where noted\nCopyright (c) 1994 Sun Microsystems, Inc.\nCopyright (c) 2011-2013, ESN Social Software AB and Jonas Tarnstrom All rights reserved.\nCopyright (c) 2011 by Enthought, Inc.\nCopyright (c) 2011-2012, PyData Development Team\nCopyright © 1993,2004 Sun Microsystems or\nCopyright (c) 2014-2016 - Yaron de Leeuw <me@jarondl.net>\nCopyright (c) 2008-2012, AQR Capital Management, LLC, Lambda Foundry, Inc. and PyData Development Team All rights reserved.\nLicense Agreement and CNRI's notice of copyright, i.e., \"Copyright (c) 1995-2001 Corporation for National Research Initiatives; All Rights Reserved\" are retained in Python 1.6.1 alone or in any derivative version prepared by Licensee.  Alternately, in lieu of CNRI's License Agreement, Licensee may substitute the following text (omitting the quotes): \"Python 1.6.1 is made available subject to the terms and conditions in CNRI's License Agreement.  This Agreement together with Python 1.6.1 may be located on the Internet using the following unique, persistent identifier (known as a handle): 1895.22/1013.  This Agreement may also be obtained from a proxy server on the Internet\ni.e., \"Copyright (c) 2001, 2002, 2003, 2004, 2005, 2006, 2007, 2008, 2009, 2010 Python Software Foundation; All Rights Reserved\" are retained in Python alone or in any derivative version prepared by Licensee.\nCopyright (c) 2008-2011 AQR Capital Management, LLC\nCopyright 2017- dateutil contributors (see AUTHORS file)\nCopyright (c) 2017 - dateutil contributors class timelex: def init(self, instream): if getattr(instream, 'decode', None) is not None: instream = instream.decode()\nCopyright (c) 2012-2014 - Tomi Pieviläinen <tomi.pievilainen@iki.fi>\nCopyright (c) 2016, PyData Development Team All rights reserved.\nCopyright © 2003-2009 Bruce D. Evans or\nCopyright © 2008 Stephen L. Moshier and labelled as such in comments in the individual source files. All have been licensed under extremely permissive terms.\n\nBSD 3-Clause License\n\nCopyright (c) 2008-2012, AQR Capital Management, LLC, Lambda Foundry, Inc. and PyData Development Team\nAll rights reserved.\n\nRedistribution and use in source and binary forms, with or without\nmodification, are permitted provided that the following conditions are met:\n\n* Redistributions of source code must retain the above copyright notice, this\n  list of conditions and the following disclaimer.\n\n* Redistributions in binary form must reproduce the above copyright notice,\n  this list of conditions and the following disclaimer in the documentation\n  and/or other materials provided with the distribution.\n\n* Neither the name of the copyright holder nor the names of its\n  contributors may be used to endorse or promote products derived from\n  this software without specific prior written permission.\n\nTHIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS \"AS IS\"\nAND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE\nIMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE\nDISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE\nFOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL\nDAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR\nSERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER\nCAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY,\nOR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE\nOF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n\nSoftware: Pillow 6.2.0\nCopyright notice:\nCopyright (c) 2001-2004 by Fredrik Lundh\nCopyright (c) 1997-2001 by Secret Labs AB\nCopyright (c) Fredrik Lundh 1996-2003.\nCopyright (c) 2004 by Secret Labs.\nCopyright (c) Fredrik Lundh 1999.\nCopyright (c) 2016 Marcin Kurczewski <rr-@sakuya.pl>\nCopyright (c) Secret Labs AB 1997-2004.  All rights reserved.\nCopyright (c) 1997-99 by Secret Labs AB.\nCopyright (c) 2014 by Coriolis Systems Limited\nCopyright (c) 2003 by Bitstream, Inc. All Rights Reserved. Bitstream Vera is a trademark of Bitstream, Inc.\nCopyright (c) 2001-2002 by Secret Labs AB\nCopyright (c) 1995-2004 by Fredrik Lundh.\nCopyright (c) 1996 by Fredrik Lundh.\nCopyright (c) Secret Labs AB 1997-2005.  All rights reserved.\nCopyright (c) Fredrik Lundh 1995.\nCOPYRIGHT \"Copyright (c) 1987 Adobe Systems, Inc., Portions Copyright 1988 Digital Equipment Corp.\"\nCopyright (c) 1997-2006 by Secret Labs AB.\nCopyright (c) 1997-2004 by Secret Labs AB.  All rights reserved.\nCopyright (c) 1996-1997 by Fredrik Lundh.\nCopyright (c) 1997-2005 by Secret Labs AB\nCopyright (c) Secret Labs AB 1997-98.\nCopyright (c) 1996-2000 Fredrik Lundh\nCopyright (c) 2008 by Karsten Hiddemann.\nCopyright (c) 1995-2003 by Fredrik Lundh\nCopyright (c) 1996-2006 by Fredrik Lundh\nCopyright (c) Fredrik Lundh 1997-2004.\nCopyright (C) 2002-2003 Kevin Cazabon\nCopyright (c) 1997-2003 by Secret Labs AB.\nCopyright (c) 1998-2005 by Secret Labs AB\nCopyright (c) 2014 Coriolis Systems Limited\nCopyright (c) 1995 by Fredrik Lundh.\nCopyright (c) 1997 by Fredrik Lundh.\nCopyright (c) 2002 by Secret Labs AB\nCopyright (c) 1997-2009 by Secret Labs AB.  All rights reserved.\n== \"Copyright International Color Consortium, 2009\"\nCopyright 2020 Google LLC\nCopyright (c) Fredrik Lundh 1995-97.\nCopyright (c) Secret Labs AB 1997-2002.  All rights reserved.\nCopyright (c) 1997-2002 by Secret Labs AB.\nCopyright (c) 1993-1996 Lucent Technologies.\nCopyright (c) Secret Labs AB 1997-2001.\nCopyright (c) 2004 by Fredrik Lundh.\nCopyright (c) 1995-2001 by Secret Labs AB\nCopyright (c) 2003-2005 by Secret Labs AB\nCopyright (c) Fredrik Lundh 2009.\nCopyright (C) 2020 Free Software Foundation, Inc.\nCopyright (c) 1997-2003 by Secret Labs AB\nCopyright (c) Fredrik Lundh 1997.\nCopyright (c) 2014 by Alastair Houghton\nCopyright (C) 2002-2003 Kevin Cazabon\\n\\\nCopyright (c) 2002-2004 by Fredrik Lundh\nCopyright (c) 1997-98 by Secret Labs AB.\nCopyright (c) 1996-1997 by Fredrik Lundh\nCopyright (c) Secret Labs AB 2002-2004.  All rights reserved.\nCopyright (c) 1995-2009 by Fredrik Lundh.\nCopyright © 2015 Information Technology Authority (ITA) <foss@ita.gov.om>\nCopyright (c) 1997-2001 by Secret Labs AB.\nCopyright © 1995-2011 by Fredrik Lundh\n==51890== Copyright (C) 2002-2017, and GNU GPL'd, by Julian Seward et al.\nCopyright (c) 1998-2000 by Scriptics Corporation.\nCopyright (c) 2002 by Kevin B. Kenny.  All rights reserved.\nCopyright (c) 2004 by Health Research Inc. (HRI) RENSSELAER, NY 12144.\n\"Copyright International Color Consortium, 2009\",\nCopyright © 1997-2011 by Secret Labs AB\nCopyright (c) 1998-2004 by Secret Labs AB.  All rights reserved.\nCopyright (c) 2004 by Bob Ippolito.\nCopyright (c) 1998 by Secret Labs AB\nCopyright © 2016 Khaled Hosny <khaledhosny@eglug.org>\nCopyright (c) 1995-2002 by Fredrik Lundh.\nCopyright (c) 2006 by Fredrik Lundh\nCopyright (c) 1997-1998 by Secret Labs AB\nCopyright (c) 2003-2005 by Fredrik Lundh\nCopyright (c) 1997-2005 by Secret Labs AB.\nCopyright (c) 1995-1997 by Fredrik Lundh\nCopyright (c) 2005 by Fredrik Lundh\nCopyright (c) 2003 by Fredrik Lundh.\nCopyright (c) 1995-2003 by Fredrik Lundh.\nCopyright (c) 1995-2006 by Fredrik Lundh\nCopyright (c) Eric Soroos 2017.\nCopyright (c) 2013 Eric Soroos\nCopyright (c) Mickael Bonfill 2017.\nCopyright (c) 1997-1998 by Fredrik Lundh\nCopyright (c) 1996 by Fredrik Lundh\nCopyright (c) 2006 by Secret Labs AB.\nCopyright (c) 1998 by Toby J Sergeant\nCopyright (c) 1995-2001 by Fredrik Lundh.\nCopyright (c) Secret Labs AB 2002.  All rights reserved.\nCopyright © 2010-2021 by Alex Clark and contributors\nCopyright (c) 1998-2000 Secret Labs AB\nCopyright (c) 1997-2004 by Secret Labs AB.\nCopyright (c) 2003 by Secret Labs AB\nCopyright (c) 1999 by Secret Labs AB.\nCopyright (c) 1997-2004 by Secret Labs AB\nCopyright (c) 1995-1997 by Fredrik Lundh.\nCopyright (c) 2000-2003 by Fredrik Lundh\nCopyright (c) 2012 by Brian Crowell\nCopyright (c) 1999-2005 by Secret Labs AB\nCopyright (c) Fredrik Lundh 1995-2003.\nCopyright (c) 1997 by Secret Labs AB.\nCopyright (c) 1995-2005 by Fredrik Lundh\nCopyright © 2011  Google, Inc.\nCopyright (c) Secret Labs AB 1999.\nCopyright (c) Eric Soroos 2016.\nCopyright (c) 2001-2004 by Secret Labs AB\nCopyright (c) 1995-1996 by Fredrik Lundh\nCopyright (c) 1995-1996 by Fredrik Lundh.\nCopyright (c) Secret Labs AB 1997-99.\nCopyright (C) 2002-2003 Kevin Cazabon kevin@cazabon.com Adapted/reworked for PIL by Fredrik Lundh\nCopyright (c) Secret Labs AB 1998\nCopyright (c) 1997-2005 by Fredrik Lundh\nCopyright (c) Fredrik Lundh 1995-1997.\nassert p.copyright == \"Copyright International Color Consortium, 2009\"\nCopyright (c) 1998-2003 by Fredrik Lundh\nCopyright (c) 1995-2001 by Fredrik Lundh\nCopyright (c) Secret Labs AB 1997-2002.\nCopyright (c) Fredrik Lundh 1994.\nCopyright (c) 1995-96 by Fredrik Lundh.\nCopyright (c) 1996-2004 by Fredrik Lundh.\nCopyright (c) 1997-2006 by Secret Labs AB\nCopyright (c) 1987-1994 The Regents of the University of California.\nCopyright (c) 1994-1998 Sun Microsystems, Inc.\nCopyright (c) 1997-2009 by Secret Labs AB\nCopyright (c) 2002 by Fredrik Lundh\nCopyright (c) 2009 Fredrik Lundh Updated to LCMS2\nCopyright (c) 2006 by Secret Labs AB\nCopyright (c) 1997-2005 by Secret Labs AB.  All rights reserved.\nCopyright (c) Secret Labs AB 1997.\nCopyright (c) 1996-2003 by Fredrik Lundh\nCopyright (c) Fredrik Lundh 1996.\nCopyright (c) 1997-2003 by Fredrik Lundh.\nCopyright (c) 2014 Alastair Houghton\nCopyright (c) 1998-2003 by Secret Labs AB.\nCopyright (c) 2004 by William Baxter.\nCopyright (c) 1997-2000 by Secret Labs AB\nCopyright (c) 2001-2002 by Fredrik Lundh\nCopyright (c) 1996-2000 by Fredrik Lundh\nCopyright (c) 2016 by Mickael Bonfill.\nCopyright (c) 2006 by Fredrik Lundh.\nCopyright (c) 2009 by Fredrik Lundh\nCopyright (c) Secret Labs AB 1997-98.  All rights reserved.\nCOMMENT  Copyright 1984, 1987 Adobe Systems, Inc.\nCopyright (c) 2013 by Eric Soroos\nCopyright (c) 1997-1999 by Secret Labs AB\nCopyright (c) Secret Labs AB 2008.\nBy Kevin Cazabon, copyright 2003 kevincazabon@hotmail.com kevin@cazabon.com /\nCopyright (c) 2014 by Alastair Houghton.\nCopyright (c) 2002-2004 by Secret Labs AB\nCopyright (c) Fredrik Lundh 1996-2001.\nCopyright (c) 1995 by Fredrik Lundh\nCopyright (c) Secret Labs AB 1997-2003.\nCopyright (c) 2006 by Tavmjong Bah. All Rights Reserved.\nCopyright (c) 1995-2004 by Fredrik Lundh\nCopyright (C) 2002-2003 Kevin Cazabon kevin@cazabon.com http:www.cazabon.com\nCopyright (c) 2014 Dov Grobgeld <dov.grobgeld@gmail.com>\nCopyright (c) 1998-2007 by Secret Labs AB\nCopyright (c) Fredrik Lundh 1995-96.\nCopyright (c) Fredrik Lundh 1996-97.\nCopyright (c) 2010 Oliver Tonnhofer <olt@bogosoft.com>, Omniscale\nCopyright (c) 1997-2006 by Secret Labs AB.  All rights reserved.\ncopyright = \"1995-2011 Fredrik Lundh, 2010-2021 Alex Clark and Contributors\"\nCopyright (c) 2004 by Secret Labs AB.\nCOMMENT  Portions Copyright 1988 Digital Equipment Corporation COMMENT COMMENT  Adobe is a registered trademark of Adobe Systems, Inc.  Permission COMMENT  to use these trademarks is hereby granted only in association with the COMMENT  images described in this file.\nIf true, \"(C) Copyright ...\" is shown in the HTML footer. Default is True.\n\nSoftware: Python 3.7.5\nCopyright notice:\nCopyright (c) 1999-2000 by Secret Labs AB\nCopyright (C) 2005-2007   Gregory P. Smith (greg@krypto.org)\nCopyright (c) 2003.\n.  Copyright (C) 2005-2010   Gregory P. Smith (greg@krypto.org)\nCopyright 1996,1997 by Oliver Andrich, Koblenz, Germany.\nCopyright (c) 2001, 2002, 2003, 2004, 2005, 2006 Python Software Foundation.\nCopyright (c) 1995-2001 Corporation for National Research Initiatives.  All rights reserved.\nCopyright 1994 by Lance Ellinghouse Cathedral City, California Republic, United States of America.\nCopyright (C) 2001 Python Software Foundation Barry Warsaw <barry@python.org>, 2000.\nlibffi 2.00-beta - Copyright (c) 1996-2003  Red Hat, Inc.\nCopyright (c) 2008-2012 Stefan Krah. All rights reserved.\n2001-07-01 fl   added BIGCHARSET support (from Martin von Loewis)\n``'Copyright 1991-1995 Stichting Mathematisch Centrum, Amsterdam'``\nCopyright (C) 2003 Python Software Foundation\nCopyright (C) 2001-2016 Vinay Sajip. All Rights Reserved.\nCopyright 1995-1997, Automatrix, Inc., all rights reserved.\nCopyright (c) 2002 MyCompanyName. All rights reserved.\n<string>%version%, (c) 2001-2019 Python Software Foundation.</string>\nCopyright (c) 2004 by Peter Astrand <astrand@lysator.liu.se>\nCopyright (c) 1999-2002 by Fredrik Lundh.\nCopyright (c) 1991-1995 Stichting Mathematisch Centrum, Amsterdam.\\n\\\nAIX ABI support (c) 2002 Free Software Foundation, Inc.\n( Copyright (c) 2011 Stefan Krah. All rights reserved. )\n2013-02-04 mrab added fullmatch primitive\n2003-10-17 gn   implemented non recursive scheme\n2003-04-18 mvl  fully support 4-byte codes\nCopyright (C) 1996-2018 Free Software Foundation, Inc.\nportions copyright 2001, Autonomous Zones Industries, Inc., all rights...\nCopyright (c) 1999-2002 by Secret Labs AB.\nCopyright (C) 1986 Gary S. Brown.  You may use this program, or code or tables extracted from it, as desired without restriction.\n-- Copyright (c) IBM Corporation, 2003, 2008.  All rights reserved.   --\n; Copyright (c) 2008-2016 Stefan Krah. All rights reserved.\nCopyright (c) 2001-2019 Python Software Foundation.\\n\\\nCopyright 2008 Armin Ronacher.\nCopyright © 2000 BeOpen.com. All rights reserved.\n(c) 2005 Ian Bicking and contributors; written for Paste (http://pythonpaste.org)\nCopyright (c) 2005-2006 ActiveState Software Inc.\nCopyright (C) 1994 Steen Lumholt.\nCopyright (c) 1999 by Fredrik Lundh.\nlibffi - Copyright (c) 1996-2003  Red Hat, Inc.\nCopyright (c) 2006-2008 Alexander Chemeris\nCopyright (C) 2002 Lars Gustaebel <lars@gustaebel.de>\nCopyright (c) 1999-2003 Steve Purcell\nDarwin ABI support (c) 2001 John Hornkvist\nCopyright (C) 1995-1998 Eric Young (eay@cryptsoft.com)\nCopyright (c) 1999-2008 by Fredrik Lundh\ni.e., \"Copyright © 1995-2001 Corporation for National Research Initiatives; All Rights Reserved\" are retained in Python 1.6.1 alone or in any derivative version prepared by Licensee.  Alternately, in lieu of CNRI's License Agreement, Licensee may substitute the following text (omitting the quotes): \"Python 1.6.1\n-- Copyright (c) IBM Corporation, 2005, 2009.  All rights reserved.   --\nCopyright (c) 2001-2017 Expat maintainers\nCopyright (c) 2001-2012 Python Software Foundation. All Rights Reserved.\nCopyright (C) 2002-2006 Python Software Foundation Author: Barry Warsaw Contact: email-sig@python.org\n(c) 2002 Gregory P. Ward.  All Rights Reserved.\nCopyright (c) 2000 BeOpen.com.\\n\\\nCopyright (C) 2001-2007 Python Software Foundation Author: Ben Gertzfield, Barry Warsaw Contact: email-sig@python.org\nCopyright (C) 2003-2004 Federico Di Gregorio <fog@debian.org>\n2001-05-14 fl   fixes for 1.5.2 compatibility\nCopyright © 1995-2000 Corporation for National Research Initiatives. All rights reserved.\nCopyright (C) 1995, 1996, 1997, 1998, and 1999 WIDE Project.\ncopyright, i.e., \"Copyright © 2001-2019 Python Software Foundation; All Rights Reserved\" are retained in Python |release| alone or in any derivative version prepared by Licensee.\nCopyright (C) 2001-2007 Python Software Foundation Author: Barry Warsaw, Thomas Wouters, Anthony Baxter Contact: email-sig@python.org\nCopyright (C) 2005-2010   Gregory P. Smith (greg@krypto.org)\nCopyright 2001-2017 by Vinay Sajip. All Rights Reserved.\nCopyright (c) 2000 Doug White, 2006 James Knight, 2007 Christian Heimes All rights reserved.\nCopyright (C) 1999-2001 Gregory P. Ward.\nCopyright (c) 1999-2002 by Fredrik Lundh\n+   Copyright 2007 Python Software Foundation.\nelse if (config == (void )2000 && (c) == 0x9B1D) {                 \\\nCopyright (c) 1999-2002 by Secret Labs AB\n2002-11-09 fl   fixed empty sub/subn return type\nCopyright 2009 Gabriel A. Genellina\nCopyright (c) 2003-2009 by Fredrik Lundh.  All rights reserved.\nCopyright 2004-2005 Elemental Security, Inc. All Rights Reserved.\n(c) Copyright Guido van Rossum, 2000.\nCopyright (C) 1995, 1996, 1997, and 1998 WIDE Project.\nCopyright (C) 2011-2012 Vinay Sajip.\nCopyright 2006 Google, Inc. All Rights Reserved.\n(c) Copyright Marc-Andre Lemburg, 2005.\nCopyright (C) YEAR ORGANIZATION FIRST AUTHOR <EMAIL@ADDRESS>, YEAR.\nCopyright (c) 1999-2000, Marc-Andre Lemburg; mailto:mal@lemburg.com\nCopyright (c) 1995-2000, Corporation for National Research Initiatives.\nCopyright (c) 1999 Toby Dickenson\nCopyright (C) 2001,2002 Python Software Foundation csv package unit tests\nCopyright (C) 2005, 2006 Martin von Löwis Licensed to PSF under a Contributor Agreement.\nCopyright (c) 1997 by Fredrik Lundh\nCopyright (c) 2002-2006 Python Software Foundation.  All rights reserved.\nCopyright (c) 2002  Roger Sayle\nCopyright 1995-1996 by Fred L. Drake, Jr. and Virginia Polytechnic Institute and State University, Blacksburg, Virginia, USA.\ntypes.c - Copyright (c) 1996, 1998  Red Hat, Inc.\nCopyright 2000, Mojam Media, Inc., all rights reserved.\nCopyright (C) 1994 X Consortium\nCopyright (C) 2002-2004 Python Software Foundation\nCopyright (C) 2004-2006 Python Software Foundation Authors: Baxter, Wouters and Warsaw Contact: email-sig@python.org\nCopyright (c) 2002 Jorge Acereda  <jacereda@users.sourceforge.net> &\ndarwin.S - Copyright (c) 1996, 1998, 2001, 2002, 2003  Red Hat, Inc.\nCopyright © 1991 - 1995, Stichting Mathematisch Centrum Amsterdam, The Netherlands.  All rights reserved.\n\"Copyright 1995-1996 by Virginia Polytechnic Institute & State\\n\\\nCopyright 2012, Samuel Neves <sneves@dei.uc.pt>.  You may use this under the terms of the CC0, the OpenSSL Licence, or the Apache Public License 2.0, at your option.  The terms of these licenses can be found at:\nCopyright (C) 1995-2011 Jean-loup Gailly and Mark Adler\nx86-ffitarget.h - Copyright (c) 1996-2003  Red Hat, Inc.\nCopyright 1991-1995, Stichting Mathematisch Centrum, all rights reserved.\ndarwin64.S - Copyright (c) 2006 Free Software Foundation, Inc.\nCopyright (C) 2001-2006 Python Software Foundation Author: Ben Gertzfield Contact: email-sig@python.org\nCopyright (c) 2005 Don Owens All rights reserved.\nwin32.S - Copyright (c) 1996, 1998, 2001, 2002  Red Hat, Inc.\n(c) Copyright 2005, Marc-Andre Lemburg (mal@lemburg.com).\nlibrary/xml.etree.elementtree,,:include,  Copyright (c) <xi:include href=\"year.txt\" parse=\"text\" />.\nffi.c - Copyright (c) 1998 Geoffrey Keating\nCopyright 2006 Georg Brandl.\nCopyright (C) 2005-2010 Gerhard Häring <gh@ghaering.de>\n(c) 2013-2017 Christian Heimes <christian@python.org>\nCopyright 1992-2018 Free Software Foundation, Inc.\nCopyright (c) 1990-1995, Stichting Mathematisch Centrum.\nCopyright (C) 2001-2017 Vinay Sajip. All Rights Reserved.\ni.e., \"Copyright (c) 2001, 2002, 2003, 2004, 2005, 2006, 2007, 2008, 2009, 2010, 2011, 2012, 2013, 2014, 2015, 2016, 2017, 2018, 2019 Python Software Foundation;\n2001-10-24 fl   added finditer primitive (for 2.2 only)\nCopyright (C) 2001-2006 Python Software Foundation Author: Keith Dart Contact: email-sig@python.org\nCopyright (c) 1999-2009 by Fredrik Lundh.\n(c) 2000 Peter Bosch.  All Rights Reserved.\nffitarget.h - Copyright (c) 1996-2003  Red Hat, Inc.\nCopyright (C) 2012 Free Software Foundation, Inc.\nCopyright (C) 2002-2007 Python Software Foundation Author: Ben Gertzfield Contact: email-sig@python.org\nCopyright 1994 by Lance Ellinghouse, Cathedral City, California Republic, United States of America.\nCopyright (C) 1993 by Sun Microsystems, Inc. All rights reserved.\nCopyright (C) 2006 - 2010  Gregor Lingl email: glingl@aon.at\nCopyright © 2001-2019 Python Software Foundation. All rights reserved.\nCopyright (c) 2009,2010 Zmanda Inc. <http://www.zmanda.com/>\nCopyright (c) 1998-2008 The OpenSSL Project.  All rights reserved.\nCopyright 1996 by Sam Rushing\nCopyright (c) 1998-2000 Thai Open Source Software Center Ltd and Clark Cooper\n(c) Craig Reese, Joe Campbell and Jeff Poskanzer 1989 /\nCopyright (c) 1999, 2000, 2001 Steve Purcell This module is free software, and you may redistribute it and/or modify it under the same terms as Python itself, so long as this copyright message and disclaimer are retained in their original form.\n-- Copyright (c) IBM Corporation, 2005, 2008.  All rights reserved.   --\nCopyright (C) 2001-2012 Python Software Foundation. All Rights Reserved.\ndnl Copyright © 2004 Scott James Remnant <scott@netsplit.com>.\nCopyright (C) 2002-2007 Python Software Foundation Contact: email-sig@python.org\nCopyright (c) 1998-2001 by Secret Labs AB.  All rights reserved.\nCopyright (c) 2009,2010 Dustin J. Mitchell <dustin@zmanda.com>\nCopyright (c) 2002  Bo Thorsen\n2001-10-21 fl   added sub/subn primitive\ncopyright, i.e., \"Copyright © 2001-2018 Python Software Foundation; All Rights Reserved\" are retained in Python 3.7 alone or in any derivative version prepared by Licensee.\nCopyright (C) 2011-2013 Vinay Sajip.\nCopyright (c) 1991, 2000, 2001 by Lucent Technologies.\nCopyright (c) 2010 Python Software Foundation. All Rights Reserved.\nCopyright 1992-1994, David Gottner\n\" SRE 2.2.2 Copyright (c) 1997-2002 by Secret Labs AB \";\n;   Copyright (c) 2004, Outercurve Foundation.\nCopyright (c) 2003-2005 by Peter Astrand <astrand@lysator.liu.se>\nCopyright (c) 1999 by Secret Labs AB\nlibffi PyOBJC - Copyright (c) 1996-2003  Red Hat, Inc.\nCopyright (c) 1999-2009 by Fredrik Lundh\nCopyright 2007 Google, Inc. All Rights Reserved.\n-- Copyright (c) IBM Corporation, 2004, 2008.  All rights reserved.   --\nCopyright (c) 2001, 2002, 2003, 2004, 2005, 2006, 2007, 2008, 2009, 2010, 2011, 2012, 2013, 2014, 2015, 2016, 2017, 2018, 2019 Python Software Foundation.  All rights reserved.\nCopyright (C) 2001-2007 Python Software Foundation Author: Barry Warsaw Contact: email-sig@python.org\nCopyright (c) 2000 BeOpen.com.  All rights reserved.\nCopyright © 1991-1995 Stichting Mathematisch Centrum. All rights reserved.\nCopyright (C) 2000  Luke Kenneth Casson Leighton <lkcl@samba.org>\n2001-12-07 fl   fixed memory leak in sub/subn (Guido van Rossum)\n-- Copyright (c) IBM Corporation, 2001, 2008.  All rights reserved.   --\nVirginia, USA.  Portions copyright 1991-1995 by Stichting Mathematisch\\n\\\nCopyright (c) 2004 Free Software Foundation, Inc.\nso portions are Copyright (C) 2001,2002 Python Software Foundation, and were written by Barry Warsaw.\nCopyright (C) 2004-2010 Gerhard Häring <gh@ghaering.de>\nCopyright (c) 2004 Python Software Foundation.\n(c) Copyright 2000 Guido van Rossum.\nCopyright 2007 Georg Brandl.\nCopyright (c) 1999 by Secret Labs AB.\nCopyright (c) 2002 Unicode, Inc.  All Rights reserved.\nCopyright 2009 Brian Quinlan. All Rights Reserved.\nCopyright (c) 2008-2009, Google Inc.\nCopyright (c) 2001-2006 Twisted Matrix Laboratories.\n(c) Copyright CNRI, All Rights Reserved. NO WARRANTY.\nLicense Agreement and CNRI's notice of copyright, i.e., \"Copyright (c) 1995-2001 Corporation for National Research Initiatives; All Rights Reserved\" are retained in Python 1.6.1 alone or in any derivative version prepared by Licensee.  Alternately, in lieu of CNRI's License Agreement, Licensee may substitute the following text (omitting the quotes): \"Python 1.6.1 is made available subject to the terms and conditions in CNRI's License Agreement.  This Agreement together with Python 1.6.1 may be located on the Internet using the following unique, persistent identifier (known as a handle): 1895.22/1013.  This Agreement may also be obtained from a proxy server on the Internet\nCopyright (c) Corporation for National Research Initiatives.\nCopyright (c) 2008-2016 Stefan Krah. All rights reserved.\nCopyright 2001-2016 by Vinay Sajip. All Rights Reserved.\nif (config == (void )2000 && (c) == 0x20B9F) {                     \\\nppc-ffitarget.h - Copyright (c) 1996-2003  Red Hat, Inc.\nCopyright (c) 2001-2006 Gregory P. Ward.  All rights reserved.\nCopyright (c) 1997-2001 by Secret Labs AB.  All rights reserved.\nCopyright 2000 by Timothy O'Malley <timo@alum.mit.edu>\nCopyright (C) 2007-2012 Michael Foord & the mock team E-mail: fuzzyman AT voidspace DOT org DOT uk\nCopyright (C) 2011-2014 Vinay Sajip.\nCopyright (c) 2002  Ranjit Mathew\nppc-darwin.h - Copyright (c) 2002, 2003, 2004, Free Software Foundation, Inc.\nppc64-darwinclosure.S - Copyright (c) 2002, 2003, 2004, Free Software Foundation, Inc. based on ppcclosure.S\nx86-ffi64.c - Copyright (c) 2002  Bo Thorsen <bo@suse.de>\nCopyright (C) 2001-2006 Python Software Foundation Author: Barry Warsaw Contact: email-sig@python.org\n﻿Copyright (c) 2004, Outercurve Foundation.\nCopyright (c) 1995-2001 Corporation for National Research Initiatives.\\n\\\nCopyright 1999, Bioreason, Inc., all rights reserved.\n2001-10-20 fl   added split primitive; re-enable unicode for 1.6/2.0/2.1\nCopyright (C) 2001-2019 Vinay Sajip. All Rights Reserved.\nCopyright (c) 2008 by Christian Heimes <christian@cheimes.de>\nCopyright 2001-2019 by Vinay Sajip. All Rights Reserved.\nCopyright (C) 2005 Martin v. Löwis Licensed to PSF under a contributor agreement.\nppc-darwin.S - Copyright (c) 2000 John Hornkvist\nCopyright (c) 2000, BeOpen.com.\nCopyright (C) 2001-2010 Python Software Foundation Author: Barry Warsaw Contact: email-sig@python.org\nCopyright (C) 2001-2007 Python Software Foundation Author: Anthony Baxter Contact: email-sig@python.org\nCopyright (c) 2004 by Fredrik Lundh <fredrik@pythonware.com>\nCopyright Disney Enterprises, Inc.  All Rights Reserved.\nffi.c - Copyright (c) 1996, 1998, 1999, 2001  Red Hat, Inc.\nCopyright (C) 2003-2013 Python Software Foundation\nCopyright (c) 1991 - 1995, Stichting Mathematisch Centrum Amsterdam, The Netherlands.  All rights reserved.\nCopyright (c) <xi:include href=\"year.txt\" parse=\"text\" />.\nprepcif.c - Copyright (c) 1996, 1998  Red Hat, Inc.\nself.assertEqual(list(c), list(range(2,2000)))\nCopyright (C) 2002-2007 Python Software Foundation Author: Ben Gertzfield, Barry Warsaw Contact: email-sig@python.org\n-- Copyright (c) IBM Corporation, 2000, 2008.  All rights reserved.   --\nCopyright (C) 2012   Christian Heimes (christian@python.org)\nfficommon.h - Copyright (c) 1996  Red Hat, Inc.\nCopyright (C) 2012-2016  Christian Heimes (christian@python.org)\nCopyright (C) 2004-2005 Gerhard Häring <gh@ghaering.de>\n(c) 2002 Python Software Foundation.  All Rights Reserved.\nCopyright (c) 2004 by Secret Labs AB, http://www.pythonware.com\nCopyright (c) 2004, Outercurve Foundation.\nCopyright (c) 2006-2008, R Oudkerk Licensed to PSF under a Contributor Agreement.\n.. Copyright 1995 Virginia Polytechnic Institute and State University and Fred L. Drake, Jr.  This copyright notice must be distributed on all copies, but this document otherwise may be distributed as part of the Python distribution.  No fee may be charged for this document in any representation, either on paper or electronically.  This restriction does not affect other elements in a distributed package in any way.\nCopyright 2012-2013 by Larry Hastings.\nCopyright (C) 2002-2006 Python Software Foundation Contact: email-sig@python.org email package unit tests for (optional) Asian codecs\nCopyright (c) 2002 Peter O'Gorman <ogorman@users.sourceforge.net>\nCopyright 2007 Google Inc.\nCopyright (c) 1999 by Fredrik Lundh\nCopyright (C) 2001-2010 Python Software Foundation Contact: email-sig@python.org email package unit tests\nCopyright (c) 2003-2004 by Fredrik Lundh.  All rights reserved.\nCopyright (c) 1991-1999 Unicode, Inc.  All Rights reserved.\nCopyright (c) 2000-2017 Expat development team Licensed under the MIT license:\nCopyright (c) 1997-2000 Thai Open Source Software Center Ltd\nCopyright (c) 1998 The Open Group\nCopyright (c) 1991 - 1995, Stichting Mathematisch Centrum Amsterdam, The Netherlands. All rights reserved.\\\n<string>%version%, (c) 2001-2016 Python Software Foundation.</string>\nCopyright (c) 2000-2010, eGenix.com Software GmbH; mailto:info@egenix.com\nCopyright (C) 2005 Gerhard Häring <gh@ghaering.de>\ncopyright = '2001-%s, Python Software Foundation' % time.strftime('%Y')\nCopyright (c) 1996-2008  Red Hat, Inc and others.\nCopyright (C) 2005 Martin v. Löwis Licensed to PSF under a Contributor Agreement.\n<string>(c) 2001-2016 Python Software Foundation.</string>\n<string>%VERSION%, (c) 2001-2019 Python Software Foundation.</string>\nCopyright (C) 1997, 2002, 2003, 2007, 2008 Martin von Loewis\nCopyright (c) 2013  Marek Majkowski <marek@popcount.org>\nCopyright (c) 1999-2008 by Fredrik Lundh.  All rights reserved.\nCopyright (C) 1997 - 2002, Makoto Matsumoto and Takuji Nishimura, All rights reserved.\nCopyright (c) 1998, 1999, 2000 Thai Open Source Software Center Ltd and Clark Cooper\n2001-04-15 fl   export copyright as Python attribute, not global 2001-04-28 fl   added copy methods (work in progress)\nCopyright (C) 2002, 2003 Python Software Foundation.\nCopyright (c) 2004, 2005, 2006 Python Software Foundation.\ndnl Copyright © 2012-2015 Dan Nicholson <dbn.lists@gmail.com>\nCopyright (c) 1999-2009 by Secret Labs AB.  All rights reserved.\nCopyright (c) 2003-2010 Python Software Foundation This module is free software, and you may redistribute it and/or modify it under the same terms as Python itself, so long as this copyright message and disclaimer are retained in their original form.\nCopyright (c) 1991-1995 Stichting Mathematisch Centrum.  All rights reserved.\n2001-10-18 fl   fixed group reset issue (from Matthew Mueller)\nCopyright (C) 1992-1996, 1998-2012 Free Software Foundation, Inc.\n-- Copyright (c) IBM Corporation, 1981, 2008.  All rights reserved.   --\nCopyright (C) 2000  Bastian Kleineidam\nppc-darwinclosure.S - Copyright (c) 2002, 2003, 2004, Free Software Foundation, Inc. based on ppcclosure.S\nCopyright (c) 2001  John Beniton\nPortions copyright 1991-1995 by Stichting Mathematisch Centrum, Amsterdam, The Netherlands.  Copying is permitted under the terms associated with the main Python distribution, with the additional restriction that this additional notice be included and maintained on all distributed copies.\n\nA. HISTORY OF THE SOFTWARE\n==========================\n\nPython was created in the early 1990s by Guido van Rossum at Stichting\nMathematisch Centrum (CWI, see http://www.cwi.nl) in the Netherlands\nas a successor of a language called ABC.  Guido remains Python's\nprincipal author, although it includes many contributions from others.\n\nIn 1995, Guido continued his work on Python at the Corporation for\nNational Research Initiatives (CNRI, see http://www.cnri.reston.va.us)\nin Reston, Virginia where he released several versions of the\nsoftware.\n\nIn May 2000, Guido and the Python core development team moved to\nBeOpen.com to form the BeOpen PythonLabs team.  In October of the same\nyear, the PythonLabs team moved to Digital Creations, which became\nZope Corporation.  In 2001, the Python Software Foundation (PSF, see\nhttps://www.python.org/psf/) was formed, a non-profit organization\ncreated specifically to own Python-related Intellectual Property.\nZope Corporation was a sponsoring member of the PSF.\n\nAll Python releases are Open Source (see http://www.opensource.org for\nthe Open Source Definition).  Historically, most, but not all, Python\nreleases have also been GPL-compatible; the table below summarizes\nthe various releases.\n\n    Release         Derived     Year        Owner       GPL-\n                    from                                compatible? (1)\n\n    0.9.0 thru 1.2              1991-1995   CWI         yes\n    1.3 thru 1.5.2  1.2         1995-1999   CNRI        yes\n    1.6             1.5.2       2000        CNRI        no\n    2.0             1.6         2000        BeOpen.com  no\n    1.6.1           1.6         2001        CNRI        yes (2)\n    2.1             2.0+1.6.1   2001        PSF         no\n    2.0.1           2.0+1.6.1   2001        PSF         yes\n    2.1.1           2.1+2.0.1   2001        PSF         yes\n    2.1.2           2.1.1       2002        PSF         yes\n    2.1.3           2.1.2       2002        PSF         yes\n    2.2 and above   2.1.1       2001-now    PSF         yes\n\nFootnotes:\n\n(1) GPL-compatible doesn't mean that we're distributing Python under\n    the GPL.  All Python licenses, unlike the GPL, let you distribute\n    a modified version without making your changes open source.  The\n    GPL-compatible licenses make it possible to combine Python with\n    other software that is released under the GPL; the others don't.\n\n(2) According to Richard Stallman, 1.6.1 is not GPL-compatible,\n    because its license has a choice of law clause.  According to\n    CNRI, however, Stallman's lawyer has told CNRI's lawyer that 1.6.1\n    is \"not incompatible\" with the GPL.\n\nThanks to the many outside volunteers who have worked under Guido's\ndirection to make these releases possible.\n\n\nB. TERMS AND CONDITIONS FOR ACCESSING OR OTHERWISE USING PYTHON\n===============================================================\n\nPYTHON SOFTWARE FOUNDATION LICENSE VERSION 2\n--------------------------------------------\n\n1. This LICENSE AGREEMENT is between the Python Software Foundation\n(\"PSF\"), and the Individual or Organization (\"Licensee\") accessing and\notherwise using this software (\"Python\") in source or binary form and\nits associated documentation.\n\n2. Subject to the terms and conditions of this License Agreement, PSF hereby\ngrants Licensee a nonexclusive, royalty-free, world-wide license to reproduce,\nanalyze, test, perform and/or display publicly, prepare derivative works,\ndistribute, and otherwise use Python alone or in any derivative version,\nprovided, however, that PSF's License Agreement and PSF's notice of copyright,\ni.e., \"Copyright (c) 2001, 2002, 2003, 2004, 2005, 2006, 2007, 2008, 2009, 2010,\n2011, 2012, 2013, 2014, 2015, 2016, 2017, 2018, 2019 Python Software Foundation;\nAll Rights Reserved\" are retained in Python alone or in any derivative version\nprepared by Licensee.\n\n3. In the event Licensee prepares a derivative work that is based on\nor incorporates Python or any part thereof, and wants to make\nthe derivative work available to others as provided herein, then\nLicensee hereby agrees to include in any such work a brief summary of\nthe changes made to Python.\n\n4. PSF is making Python available to Licensee on an \"AS IS\"\nbasis.  PSF MAKES NO REPRESENTATIONS OR WARRANTIES, EXPRESS OR\nIMPLIED.  BY WAY OF EXAMPLE, BUT NOT LIMITATION, PSF MAKES NO AND\nDISCLAIMS ANY REPRESENTATION OR WARRANTY OF MERCHANTABILITY OR FITNESS\nFOR ANY PARTICULAR PURPOSE OR THAT THE USE OF PYTHON WILL NOT\nINFRINGE ANY THIRD PARTY RIGHTS.\n\n5. PSF SHALL NOT BE LIABLE TO LICENSEE OR ANY OTHER USERS OF PYTHON\nFOR ANY INCIDENTAL, SPECIAL, OR CONSEQUENTIAL DAMAGES OR LOSS AS\nA RESULT OF MODIFYING, DISTRIBUTING, OR OTHERWISE USING PYTHON,\nOR ANY DERIVATIVE THEREOF, EVEN IF ADVISED OF THE POSSIBILITY THEREOF.\n\n6. This License Agreement will automatically terminate upon a material\nbreach of its terms and conditions.\n\n7. Nothing in this License Agreement shall be deemed to create any\nrelationship of agency, partnership, or joint venture between PSF and\nLicensee.  This License Agreement does not grant permission to use PSF\ntrademarks or trade name in a trademark sense to endorse or promote\nproducts or services of Licensee, or any third party.\n\n8. By copying, installing or otherwise using Python, Licensee\nagrees to be bound by the terms and conditions of this License\nAgreement.\n\n\nBEOPEN.COM LICENSE AGREEMENT FOR PYTHON 2.0\n-------------------------------------------\n\nBEOPEN PYTHON OPEN SOURCE LICENSE AGREEMENT VERSION 1\n\n1. This LICENSE AGREEMENT is between BeOpen.com (\"BeOpen\"), having an\noffice at 160 Saratoga Avenue, Santa Clara, CA 95051, and the\nIndividual or Organization (\"Licensee\") accessing and otherwise using\nthis software in source or binary form and its associated\ndocumentation (\"the Software\").\n\n2. Subject to the terms and conditions of this BeOpen Python License\nAgreement, BeOpen hereby grants Licensee a non-exclusive,\nroyalty-free, world-wide license to reproduce, analyze, test, perform\nand/or display publicly, prepare derivative works, distribute, and\notherwise use the Software alone or in any derivative version,\nprovided, however, that the BeOpen Python License is retained in the\nSoftware, alone or in any derivative version prepared by Licensee.\n\n3. BeOpen is making the Software available to Licensee on an \"AS IS\"\nbasis.  BEOPEN MAKES NO REPRESENTATIONS OR WARRANTIES, EXPRESS OR\nIMPLIED.  BY WAY OF EXAMPLE, BUT NOT LIMITATION, BEOPEN MAKES NO AND\nDISCLAIMS ANY REPRESENTATION OR WARRANTY OF MERCHANTABILITY OR FITNESS\nFOR ANY PARTICULAR PURPOSE OR THAT THE USE OF THE SOFTWARE WILL NOT\nINFRINGE ANY THIRD PARTY RIGHTS.\n\n4. BEOPEN SHALL NOT BE LIABLE TO LICENSEE OR ANY OTHER USERS OF THE\nSOFTWARE FOR ANY INCIDENTAL, SPECIAL, OR CONSEQUENTIAL DAMAGES OR LOSS\nAS A RESULT OF USING, MODIFYING OR DISTRIBUTING THE SOFTWARE, OR ANY\nDERIVATIVE THEREOF, EVEN IF ADVISED OF THE POSSIBILITY THEREOF.\n\n5. This License Agreement will automatically terminate upon a material\nbreach of its terms and conditions.\n\n6. This License Agreement shall be governed by and interpreted in all\nrespects by the law of the State of California, excluding conflict of\nlaw provisions.  Nothing in this License Agreement shall be deemed to\ncreate any relationship of agency, partnership, or joint venture\nbetween BeOpen and Licensee.  This License Agreement does not grant\npermission to use BeOpen trademarks or trade names in a trademark\nsense to endorse or promote products or services of Licensee, or any\nthird party.  As an exception, the \"BeOpen Python\" logos available at\nhttp://www.pythonlabs.com/logos.html may be used according to the\npermissions granted on that web page.\n\n7. By copying, installing or otherwise using the software, Licensee\nagrees to be bound by the terms and conditions of this License\nAgreement.\n\n\nCNRI LICENSE AGREEMENT FOR PYTHON 1.6.1\n---------------------------------------\n\n1. This LICENSE AGREEMENT is between the Corporation for National\nResearch Initiatives, having an office at 1895 Preston White Drive,\nReston, VA 20191 (\"CNRI\"), and the Individual or Organization\n(\"Licensee\") accessing and otherwise using Python 1.6.1 software in\nsource or binary form and its associated documentation.\n\n2. Subject to the terms and conditions of this License Agreement, CNRI\nhereby grants Licensee a nonexclusive, royalty-free, world-wide\nlicense to reproduce, analyze, test, perform and/or display publicly,\nprepare derivative works, distribute, and otherwise use Python 1.6.1\nalone or in any derivative version, provided, however, that CNRI's\nLicense Agreement and CNRI's notice of copyright, i.e., \"Copyright (c)\n1995-2001 Corporation for National Research Initiatives; All Rights\nReserved\" are retained in Python 1.6.1 alone or in any derivative\nversion prepared by Licensee.  Alternately, in lieu of CNRI's License\nAgreement, Licensee may substitute the following text (omitting the\nquotes): \"Python 1.6.1 is made available subject to the terms and\nconditions in CNRI's License Agreement.  This Agreement together with\nPython 1.6.1 may be located on the Internet using the following\nunique, persistent identifier (known as a handle): 1895.22/1013.  This\nAgreement may also be obtained from a proxy server on the Internet\nusing the following URL: http://hdl.handle.net/1895.22/1013\".\n\n3. In the event Licensee prepares a derivative work that is based on\nor incorporates Python 1.6.1 or any part thereof, and wants to make\nthe derivative work available to others as provided herein, then\nLicensee hereby agrees to include in any such work a brief summary of\nthe changes made to Python 1.6.1.\n\n4. CNRI is making Python 1.6.1 available to Licensee on an \"AS IS\"\nbasis.  CNRI MAKES NO REPRESENTATIONS OR WARRANTIES, EXPRESS OR\nIMPLIED.  BY WAY OF EXAMPLE, BUT NOT LIMITATION, CNRI MAKES NO AND\nDISCLAIMS ANY REPRESENTATION OR WARRANTY OF MERCHANTABILITY OR FITNESS\nFOR ANY PARTICULAR PURPOSE OR THAT THE USE OF PYTHON 1.6.1 WILL NOT\nINFRINGE ANY THIRD PARTY RIGHTS.\n\n5. CNRI SHALL NOT BE LIABLE TO LICENSEE OR ANY OTHER USERS OF PYTHON\n1.6.1 FOR ANY INCIDENTAL, SPECIAL, OR CONSEQUENTIAL DAMAGES OR LOSS AS\nA RESULT OF MODIFYING, DISTRIBUTING, OR OTHERWISE USING PYTHON 1.6.1,\nOR ANY DERIVATIVE THEREOF, EVEN IF ADVISED OF THE POSSIBILITY THEREOF.\n\n6. This License Agreement will automatically terminate upon a material\nbreach of its terms and conditions.\n\n7. This License Agreement shall be governed by the federal\nintellectual property law of the United States, including without\nlimitation the federal copyright law, and, to the extent such\nU.S. federal law does not apply, by the law of the Commonwealth of\nVirginia, excluding Virginia's conflict of law provisions.\nNotwithstanding the foregoing, with regard to derivative works based\non Python 1.6.1 that incorporate non-separable material that was\npreviously distributed under the GNU General Public License (GPL), the\nlaw of the Commonwealth of Virginia shall govern this License\nAgreement only as to issues arising under or with respect to\nParagraphs 4, 5, and 7 of this License Agreement.  Nothing in this\nLicense Agreement shall be deemed to create any relationship of\nagency, partnership, or joint venture between CNRI and Licensee.  This\nLicense Agreement does not grant permission to use CNRI trademarks or\ntrade name in a trademark sense to endorse or promote products or\nservices of Licensee, or any third party.\n\n8. By clicking on the \"ACCEPT\" button where indicated, or by copying,\ninstalling or otherwise using Python 1.6.1, Licensee agrees to be\nbound by the terms and conditions of this License Agreement.\n\n        ACCEPT\n\n\nCWI LICENSE AGREEMENT FOR PYTHON 0.9.0 THROUGH 1.2\n--------------------------------------------------\n\nCopyright (c) 1991 - 1995, Stichting Mathematisch Centrum Amsterdam,\nThe Netherlands.  All rights reserved.\n\nPermission to use, copy, modify, and distribute this software and its\ndocumentation for any purpose and without fee is hereby granted,\nprovided that the above copyright notice appear in all copies and that\nboth that copyright notice and this permission notice appear in\nsupporting documentation, and that the name of Stichting Mathematisch\nCentrum or CWI not be used in advertising or publicity pertaining to\ndistribution of the software without specific, written prior\npermission.\n\nSTICHTING MATHEMATISCH CENTRUM DISCLAIMS ALL WARRANTIES WITH REGARD TO\nTHIS SOFTWARE, INCLUDING ALL IMPLIED WARRANTIES OF MERCHANTABILITY AND\nFITNESS, IN NO EVENT SHALL STICHTING MATHEMATISCH CENTRUM BE LIABLE\nFOR ANY SPECIAL, INDIRECT OR CONSEQUENTIAL DAMAGES OR ANY DAMAGES\nWHATSOEVER RESULTING FROM LOSS OF USE, DATA OR PROFITS, WHETHER IN AN\nACTION OF CONTRACT, NEGLIGENCE OR OTHER TORTIOUS ACTION, ARISING OUT\nOF OR IN CONNECTION WITH THE USE OR PERFORMANCE OF THIS SOFTWARE.\n\nSoftware: Python 3.8.5\nCopyright notice:\ncopyright, i.e., \"Copyright © 2001-2018 Python Software Foundation; All Rights Reserved\" are retained in Python 3.8 alone or in any derivative version prepared by Licensee.\nCopyright (c) 1999-2000 by Secret Labs AB\nCopyright (C) 2005-2007   Gregory P. Smith (greg@krypto.org)\nCopyright (c) 2003.\n.  Copyright (C) 2005-2010   Gregory P. Smith (greg@krypto.org)\nCopyright 1996,1997 by Oliver Andrich, Koblenz, Germany.\nCopyright (c) 2001, 2002, 2003, 2004, 2005, 2006 Python Software Foundation.\nCopyright (c) 1995-2001 Corporation for National Research Initiatives.  All rights reserved.\nCopyright 1994 by Lance Ellinghouse Cathedral City, California Republic, United States of America.\nCopyright (C) 2001 Python Software Foundation Barry Warsaw <barry@python.org>, 2000.\nCopyright (c) 2008-2012 Stefan Krah. All rights reserved.\n2001-07-01 fl   added BIGCHARSET support (from Martin von Loewis)\n``'Copyright 1991-1995 Stichting Mathematisch Centrum, Amsterdam'``\nCopyright (C) 2003 Python Software Foundation\nCopyright (C) 2001-2016 Vinay Sajip. All Rights Reserved.\nCopyright 1995-1997, Automatrix, Inc., all rights reserved.\nCopyright (c) 2002 MyCompanyName. All rights reserved.\nCopyright (c) 2004 by Peter Astrand <astrand@lysator.liu.se>\nCopyright (c) 1999-2002 by Fredrik Lundh.\nCopyright (c) 1991-1995 Stichting Mathematisch Centrum, Amsterdam.\\n\\\nAIX ABI support (c) 2002 Free Software Foundation, Inc.\n( Copyright (c) 2011 Stefan Krah. All rights reserved. )\n2013-02-04 mrab added fullmatch primitive\n2003-10-17 gn   implemented non recursive scheme\n2003-04-18 mvl  fully support 4-byte codes\nCopyright (c) 1999-2002 by Secret Labs AB.\nportions copyright 2001, Autonomous Zones Industries, Inc., all rights...\nCopyright © 2013 W3C® (MIT, ERCIM, Keio, Beihang), All Rights Reserved.\nCopyright (C) 1986 Gary S. Brown.  You may use this program, or code or tables extracted from it, as desired without restriction.\n-- Copyright (c) IBM Corporation, 2003, 2008.  All rights reserved.   --\n; Copyright (c) 2008-2016 Stefan Krah. All rights reserved.\nCopyright (c) 2001-2020 Python Software Foundation.  All rights reserved.\nCopyright 2008 Armin Ronacher.\nCopyright © 2000 BeOpen.com. All rights reserved.\n(c) 2005 Ian Bicking and contributors; written for Paste (http://pythonpaste.org)\nCopyright (c) 2005-2006 ActiveState Software Inc.\nCopyright (C) 1994 Steen Lumholt.\nCopyright (c) 1999 by Fredrik Lundh.\nlibffi - Copyright (c) 1996-2003  Red Hat, Inc.\nCopyright (c) 2006-2008 Alexander Chemeris\nCopyright (C) 2002 Lars Gustaebel <lars@gustaebel.de>\nCopyright (c) 1999-2003 Steve Purcell\nDarwin ABI support (c) 2001 John Hornkvist\nCopyright (C) 1995-1998 Eric Young (eay@cryptsoft.com)\nCopyright (c) 1999-2008 by Fredrik Lundh\ni.e., \"Copyright © 1995-2001 Corporation for National Research Initiatives; All Rights Reserved\" are retained in Python 1.6.1 alone or in any derivative version prepared by Licensee.  Alternately, in lieu of CNRI's License Agreement, Licensee may substitute the following text (omitting the quotes): \"Python 1.6.1\n-- Copyright (c) IBM Corporation, 2005, 2009.  All rights reserved.   --\nCopyright (c) 2001-2017 Expat maintainers\nCopyright (c) 2001-2012 Python Software Foundation. All Rights Reserved.\nCopyright (C) 2002-2006 Python Software Foundation Author: Barry Warsaw Contact: email-sig@python.org\n(c) 2002 Gregory P. Ward.  All Rights Reserved.\nCopyright (c) 2000 BeOpen.com.\\n\\\nCopyright (C) 2001-2007 Python Software Foundation Author: Ben Gertzfield, Barry Warsaw Contact: email-sig@python.org\nCopyright (C) 2003-2004 Federico Di Gregorio <fog@debian.org>\n2001-05-14 fl   fixes for 1.5.2 compatibility\nCopyright © 1995-2000 Corporation for National Research Initiatives. All rights reserved.\nCopyright (c) 2013 W3C(R) (MIT, ERCIM, Keio, Beihang), All Rights Reserved.\nCopyright (C) 1995, 1996, 1997, 1998, and 1999 WIDE Project.\nCopyright (C) 2001-2007 Python Software Foundation Author: Barry Warsaw, Thomas Wouters, Anthony Baxter Contact: email-sig@python.org\nCopyright (C) 2005-2010   Gregory P. Smith (greg@krypto.org)\nCopyright 2001-2017 by Vinay Sajip. All Rights Reserved.\nCopyright (c) 2000 Doug White, 2006 James Knight, 2007 Christian Heimes All rights reserved.\nCopyright (C) 1999-2001 Gregory P. Ward.\nCopyright (c) 1999-2002 by Fredrik Lundh\n+   Copyright 2007 Python Software Foundation.\nelse if (config == (void )2000 && (c) == 0x9B1D) {                 \\\nCopyright (c) 1999-2002 by Secret Labs AB\n2002-11-09 fl   fixed empty sub/subn return type\nCopyright 2009 Gabriel A. Genellina\nCopyright (c) 2003-2009 by Fredrik Lundh.  All rights reserved.\nCopyright 2004-2005 Elemental Security, Inc. All Rights Reserved.\n(c) Copyright Guido van Rossum, 2000.\nCopyright (C) 1995, 1996, 1997, and 1998 WIDE Project.\nCopyright (C) 2011-2012 Vinay Sajip.\nCopyright 2006 Google, Inc. All Rights Reserved.\n(c) Copyright Marc-Andre Lemburg, 2005.\nCopyright (C) 1996-2014 Free Software Foundation, Inc.\nCopyright (C) YEAR ORGANIZATION FIRST AUTHOR <EMAIL@ADDRESS>, YEAR.\nCopyright (c) 1999-2000, Marc-Andre Lemburg; mailto:mal@lemburg.com\nCopyright (c) 1995-2000, Corporation for National Research Initiatives.\nCopyright (c) 1999 Toby Dickenson\nCopyright (C) 2001,2002 Python Software Foundation csv package unit tests\nCopyright (C) 2005, 2006 Martin von Löwis Licensed to PSF under a Contributor Agreement.\nCopyright (c) 1997 by Fredrik Lundh\nCopyright (c) 2002-2006 Python Software Foundation.  All rights reserved.\nCopyright (c) 2002  Roger Sayle\nCopyright 1995-1996 by Fred L. Drake, Jr. and Virginia Polytechnic Institute and State University, Blacksburg, Virginia, USA.\ntypes.c - Copyright (c) 1996, 1998  Red Hat, Inc.\nCopyright 2000, Mojam Media, Inc., all rights reserved.\nCopyright (C) 1994 X Consortium\ncopyright, i.e., \"Copyright © 2001-2020 Python Software Foundation; All Rights Reserved\" are retained in Python |release| alone or in any derivative version prepared by Licensee.\nCopyright (C) 2004-2006 Python Software Foundation Authors: Baxter, Wouters and Warsaw Contact: email-sig@python.org\nCopyright (C) 2002-2004 Python Software Foundation\nCopyright (c) 2002 Jorge Acereda  <jacereda@users.sourceforge.net> &\ndarwin.S - Copyright (c) 1996, 1998, 2001, 2002, 2003  Red Hat, Inc.\nCopyright © 1991 - 1995, Stichting Mathematisch Centrum Amsterdam, The Netherlands.  All rights reserved.\n\"Copyright 1995-1996 by Virginia Polytechnic Institute & State\\n\\\nx86-ffitarget.h - Copyright (c) 1996-2003  Red Hat, Inc.\nCopyright (C) 1995-2011 Jean-loup Gailly and Mark Adler\nCopyright 1991-1995, Stichting Mathematisch Centrum, all rights reserved.\nCopyright © 2001-2020 Python Software Foundation. All rights reserved.\n<string>(c) 2001-2020 Python Software Foundation.</string>\nCopyright (C) 2001-2006 Python Software Foundation Author: Ben Gertzfield Contact: email-sig@python.org\nCopyright (c) 2005 Don Owens All rights reserved.\ndarwin64.S - Copyright (c) 2006 Free Software Foundation, Inc.\n(c) Copyright 2005, Marc-Andre Lemburg (mal@lemburg.com).\nlibrary/xml.etree.elementtree,,:include,  Copyright (c) <xi:include href=\"year.txt\" parse=\"text\" />.\nffi.c - Copyright (c) 1998 Geoffrey Keating\nCopyright 2006 Georg Brandl.\nCopyright (C) 2005-2010 Gerhard Häring <gh@ghaering.de>\n(c) 2013-2017 Christian Heimes <christian@python.org>\nCopyright 1992-2018 Free Software Foundation, Inc.\nCopyright (C) 2003-2013 Python Software Foundation import copy import operator import pickle import unittest import plistlib import os import datetime import codecs import binascii import collections from test import support from io import BytesIO\nCopyright (C) 2001-2017 Vinay Sajip. All Rights Reserved.\nCopyright (c) 1990-1995, Stichting Mathematisch Centrum.\n2001-10-24 fl   added finditer primitive (for 2.2 only)\nCopyright (C) 2001-2006 Python Software Foundation Author: Keith Dart Contact: email-sig@python.org\nCopyright (c) 1999-2009 by Fredrik Lundh.\n(c) 2000 Peter Bosch.  All Rights Reserved.\nCopyright (C) 1993 by Sun Microsystems, Inc. All rights reserved.\nCopyright (C) 2012 Free Software Foundation, Inc.\nCopyright (C) 2002-2007 Python Software Foundation Author: Ben Gertzfield Contact: email-sig@python.org\ni.e., \"Copyright (c) 2001, 2002, 2003, 2004, 2005, 2006, 2007, 2008, 2009, 2010, 2011, 2012, 2013, 2014, 2015, 2016, 2017, 2018, 2019, 2020 Python Software Foundation;\nCopyright 1994 by Lance Ellinghouse, Cathedral City, California Republic, United States of America.\nCopyright (C) 2006 - 2010  Gregor Lingl email: glingl@aon.at\nCopyright (c) 2009,2010 Zmanda Inc. <http://www.zmanda.com/>\nCopyright (c) 1998-2008 The OpenSSL Project.  All rights reserved.\nCopyright 1996 by Sam Rushing\nCopyright (c) 1998-2000 Thai Open Source Software Center Ltd and Clark Cooper\n(c) Craig Reese, Joe Campbell and Jeff Poskanzer 1989 /\nCopyright (c) 1999, 2000, 2001 Steve Purcell This module is free software, and you may redistribute it and/or modify it under the same terms as Python itself, so long as this copyright message and disclaimer are retained in their original form.\n-- Copyright (c) IBM Corporation, 2005, 2008.  All rights reserved.   --\nCopyright (C) 2001-2012 Python Software Foundation. All Rights Reserved.\ndnl Copyright © 2004 Scott James Remnant <scott@netsplit.com>.\nCopyright (C) 2002-2007 Python Software Foundation Contact: email-sig@python.org\nCopyright (c) 1998-2001 by Secret Labs AB.  All rights reserved.\nCopyright (c) 2009,2010 Dustin J. Mitchell <dustin@zmanda.com>\nCopyright (c) 2002  Bo Thorsen\n2001-10-21 fl   added sub/subn primitive\nCopyright 1992-1994, David Gottner\nCopyright (C) 2011-2013 Vinay Sajip.\nCopyright (c) 1991, 2000, 2001 by Lucent Technologies.\nCopyright (c) 2010 Python Software Foundation. All Rights Reserved.\n\" SRE 2.2.2 Copyright (c) 1997-2002 by Secret Labs AB \";\n;   Copyright (c) 2004, Outercurve Foundation.\nCopyright (c) 2003-2005 by Peter Astrand <astrand@lysator.liu.se>\nCopyright (c) 1999 by Secret Labs AB\nlibffi PyOBJC - Copyright (c) 1996-2003  Red Hat, Inc.\nCopyright (c) 1999-2009 by Fredrik Lundh\nCopyright 2007 Google, Inc. All Rights Reserved.\n-- Copyright (c) IBM Corporation, 2004, 2008.  All rights reserved.   --\nCopyright (C) 2001-2007 Python Software Foundation Author: Barry Warsaw Contact: email-sig@python.org\nCopyright (c) 2000 BeOpen.com.  All rights reserved.\n<string>%version%, (c) 2001-2020 Python Software Foundation.</string>\nCopyright © 1991-1995 Stichting Mathematisch Centrum. All rights reserved.\nCopyright (C) 2000  Luke Kenneth Casson Leighton <lkcl@samba.org>\nCopyright (C) 2005-2007 Gerhard Häring <gh@ghaering.de>\n2001-12-07 fl   fixed memory leak in sub/subn (Guido van Rossum)\n-- Copyright (c) IBM Corporation, 2001, 2008.  All rights reserved.   --\nVirginia, USA.  Portions copyright 1991-1995 by Stichting Mathematisch\\n\\\nCopyright (c) 2004 Free Software Foundation, Inc.\nso portions are Copyright (C) 2001,2002 Python Software Foundation, and were written by Barry Warsaw.\nCopyright (C) 2004-2010 Gerhard Häring <gh@ghaering.de>\nCopyright (c) 2004 Python Software Foundation.\n(c) Copyright 2000 Guido van Rossum.\nCopyright 2007 Georg Brandl.\nCopyright (c) 1999 by Secret Labs AB.\nCopyright (c) 2002 Unicode, Inc.  All Rights reserved.\nCopyright 2009 Brian Quinlan. All Rights Reserved.\nCopyright (c) 2008-2009, Google Inc.\nCopyright (c) 2001-2006 Twisted Matrix Laboratories.\n(c) Copyright CNRI, All Rights Reserved. NO WARRANTY.\nLicense Agreement and CNRI's notice of copyright, i.e., \"Copyright (c) 1995-2001 Corporation for National Research Initiatives; All Rights Reserved\" are retained in Python 1.6.1 alone or in any derivative version prepared by Licensee.  Alternately, in lieu of CNRI's License Agreement, Licensee may substitute the following text (omitting the quotes): \"Python 1.6.1 is made available subject to the terms and conditions in CNRI's License Agreement.  This Agreement together with Python 1.6.1 may be located on the Internet using the following unique, persistent identifier (known as a handle): 1895.22/1013.  This Agreement may also be obtained from a proxy server on the Internet\nCopyright (c) Corporation for National Research Initiatives.\nCopyright (c) 2008-2016 Stefan Krah. All rights reserved.\nCopyright 2001-2016 by Vinay Sajip. All Rights Reserved.\nif (config == (void )2000 && (c) == 0x20B9F) {                     \\\nppc-ffitarget.h - Copyright (c) 1996-2003  Red Hat, Inc.\nCopyright (c) 2001-2006 Gregory P. Ward.  All rights reserved.\nCopyright (c) 1997-2001 by Secret Labs AB.  All rights reserved.\nCopyright 2000 by Timothy O'Malley <timo@alum.mit.edu>\nCopyright (C) 2007-2012 Michael Foord & the mock team E-mail: fuzzyman AT voidspace DOT org DOT uk\nCopyright (C) 2011-2014 Vinay Sajip.\nppc-darwin.h - Copyright (c) 2002, 2003, 2004, Free Software Foundation, Inc.\nppc64-darwinclosure.S - Copyright (c) 2002, 2003, 2004, Free Software Foundation, Inc. based on ppcclosure.S\nx86-ffi64.c - Copyright (c) 2002  Bo Thorsen <bo@suse.de>\nCopyright (c) 2002  Ranjit Mathew\nCopyright (C) 2001-2006 Python Software Foundation Author: Barry Warsaw Contact: email-sig@python.org\n﻿Copyright (c) 2004, Outercurve Foundation.\nCopyright (c) 1995-2001 Corporation for National Research Initiatives.\\n\\\nCopyright 1999, Bioreason, Inc., all rights reserved.\n2001-10-20 fl   added split primitive; re-enable unicode for 1.6/2.0/2.1\nCopyright (C) 2001-2019 Vinay Sajip. All Rights Reserved.\nCopyright (c) 2008 by Christian Heimes <christian@cheimes.de>\nCopyright 2001-2019 by Vinay Sajip. All Rights Reserved.\nCopyright (C) 2005 Martin v. Löwis Licensed to PSF under a contributor agreement.\nppc-darwin.S - Copyright (c) 2000 John Hornkvist\nCopyright (c) 2000, BeOpen.com.\nCopyright (C) 2001-2010 Python Software Foundation Author: Barry Warsaw Contact: email-sig@python.org\nCopyright (C) 2001-2007 Python Software Foundation Author: Anthony Baxter Contact: email-sig@python.org\nCopyright (c) 2004 by Fredrik Lundh <fredrik@pythonware.com>\nCopyright Disney Enterprises, Inc.  All Rights Reserved.\nffi.c - Copyright (c) 1996, 1998, 1999, 2001  Red Hat, Inc.\nCopyright (c) 1991 - 1995, Stichting Mathematisch Centrum Amsterdam, The Netherlands.  All rights reserved.\nCopyright (c) <xi:include href=\"year.txt\" parse=\"text\" />.\nprepcif.c - Copyright (c) 1996, 1998  Red Hat, Inc.\nself.assertEqual(list(c), list(range(2,2000)))\nCopyright (C) 2002-2007 Python Software Foundation Author: Ben Gertzfield, Barry Warsaw Contact: email-sig@python.org\n-- Copyright (c) IBM Corporation, 2000, 2008.  All rights reserved.   --\nCopyright (C) 2012   Christian Heimes (christian@python.org)\nfficommon.h - Copyright (c) 1996  Red Hat, Inc.\nCopyright (C) 2012-2016  Christian Heimes (christian@python.org)\nCopyright (C) 2004-2005 Gerhard Häring <gh@ghaering.de>\n(c) 2002 Python Software Foundation.  All Rights Reserved.\nCopyright (c) 2004 by Secret Labs AB, http://www.pythonware.com\nCopyright (c) 2004, Outercurve Foundation.\nCopyright (c) 2006-2008, R Oudkerk Licensed to PSF under a Contributor Agreement.\n.. Copyright 1995 Virginia Polytechnic Institute and State University and Fred L. Drake, Jr.  This copyright notice must be distributed on all copies, but this document otherwise may be distributed as part of the Python distribution.  No fee may be charged for this document in any representation, either on paper or electronically.  This restriction does not affect other elements in a distributed package in any way.\nCopyright 2012-2013 by Larry Hastings.\nCopyright (C) 2002-2006 Python Software Foundation Contact: email-sig@python.org email package unit tests for (optional) Asian codecs\nCopyright (c) 2002 Peter O'Gorman <ogorman@users.sourceforge.net>\nCopyright 2007 Google Inc.\nCopyright (c) 1999 by Fredrik Lundh\nCopyright (C) 2001-2010 Python Software Foundation Contact: email-sig@python.org email package unit tests\nCopyright (c) 2003-2004 by Fredrik Lundh.  All rights reserved.\nCopyright (c) 1991-1999 Unicode, Inc.  All Rights reserved.\nCopyright (c) 2000-2017 Expat development team Licensed under the MIT license:\nCopyright (c) 1997-2000 Thai Open Source Software Center Ltd\nCopyright (c) 2001-2020 Python Software Foundation.\\n\\\nCopyright (c) 1991 - 1995, Stichting Mathematisch Centrum Amsterdam, The Netherlands. All rights reserved.\\\nCopyright (c) 1998 The Open Group\nCopyright (c) 2000-2010, eGenix.com Software GmbH; mailto:info@egenix.com\nCopyright (C) 2005 Gerhard Häring <gh@ghaering.de>\ncopyright = '2001-%s, Python Software Foundation' % time.strftime('%Y')\nCopyright (c) 1996-2008  Red Hat, Inc and others.\nCopyright (C) 2005 Martin v. Löwis Licensed to PSF under a Contributor Agreement.\nCopyright (C) 1997, 2002, 2003, 2007, 2008 Martin von Loewis\n<string>%VERSION%, (c) 2001-2019 Python Software Foundation.</string>\nCopyright (c) 2013  Marek Majkowski <marek@popcount.org>\nCopyright (c) 2008 Daniel Amelang <dan@amelang.net>\nCopyright (c) 1999-2008 by Fredrik Lundh.  All rights reserved.\nCopyright (C) 1997 - 2002, Makoto Matsumoto and Takuji Nishimura, All rights reserved.\nCopyright (c) 1998, 1999, 2000 Thai Open Source Software Center Ltd and Clark Cooper\n2001-04-15 fl   export copyright as Python attribute, not global 2001-04-28 fl   added copy methods (work in progress)\nCopyright (C) 2002, 2003 Python Software Foundation.\nCopyright (c) 2004, 2005, 2006 Python Software Foundation.\ndnl Copyright © 2012-2015 Dan Nicholson <dbn.lists@gmail.com>\nCopyright (c) 1999-2009 by Secret Labs AB.  All rights reserved.\nCopyright (c) 2003-2010 Python Software Foundation This module is free software, and you may redistribute it and/or modify it under the same terms as Python itself, so long as this copyright message and disclaimer are retained in their original form.\nCopyright (c) 1991-1995 Stichting Mathematisch Centrum.  All rights reserved.\n2001-10-18 fl   fixed group reset issue (from Matthew Mueller)\nCopyright (C) 1992-1996, 1998-2012 Free Software Foundation, Inc.\n-- Copyright (c) IBM Corporation, 1981, 2008.  All rights reserved.   --\nCopyright (C) 2000  Bastian Kleineidam\nppc-darwinclosure.S - Copyright (c) 2002, 2003, 2004, Free Software Foundation, Inc. based on ppcclosure.S\nPortions copyright 1991-1995 by Stichting Mathematisch Centrum, Amsterdam, The Netherlands.  Copying is permitted under the terms associated with the main Python distribution, with the additional restriction that this additional notice be included and maintained on all distributed copies.\n\nA. HISTORY OF THE SOFTWARE\n==========================\n\nPython was created in the early 1990s by Guido van Rossum at Stichting\nMathematisch Centrum (CWI, see http://www.cwi.nl) in the Netherlands\nas a successor of a language called ABC.  Guido remains Python's\nprincipal author, although it includes many contributions from others.\n\nIn 1995, Guido continued his work on Python at the Corporation for\nNational Research Initiatives (CNRI, see http://www.cnri.reston.va.us)\nin Reston, Virginia where he released several versions of the\nsoftware.\n\nIn May 2000, Guido and the Python core development team moved to\nBeOpen.com to form the BeOpen PythonLabs team.  In October of the same\nyear, the PythonLabs team moved to Digital Creations, which became\nZope Corporation.  In 2001, the Python Software Foundation (PSF, see\nhttps://www.python.org/psf/) was formed, a non-profit organization\ncreated specifically to own Python-related Intellectual Property.\nZope Corporation was a sponsoring member of the PSF.\n\nAll Python releases are Open Source (see http://www.opensource.org for\nthe Open Source Definition).  Historically, most, but not all, Python\nreleases have also been GPL-compatible; the table below summarizes\nthe various releases.\n\n    Release         Derived     Year        Owner       GPL-\n                    from                                compatible? (1)\n\n    0.9.0 thru 1.2              1991-1995   CWI         yes\n    1.3 thru 1.5.2  1.2         1995-1999   CNRI        yes\n    1.6             1.5.2       2000        CNRI        no\n    2.0             1.6         2000        BeOpen.com  no\n    1.6.1           1.6         2001        CNRI        yes (2)\n    2.1             2.0+1.6.1   2001        PSF         no\n    2.0.1           2.0+1.6.1   2001        PSF         yes\n    2.1.1           2.1+2.0.1   2001        PSF         yes\n    2.1.2           2.1.1       2002        PSF         yes\n    2.1.3           2.1.2       2002        PSF         yes\n    2.2 and above   2.1.1       2001-now    PSF         yes\n\nFootnotes:\n\n(1) GPL-compatible doesn't mean that we're distributing Python under\n    the GPL.  All Python licenses, unlike the GPL, let you distribute\n    a modified version without making your changes open source.  The\n    GPL-compatible licenses make it possible to combine Python with\n    other software that is released under the GPL; the others don't.\n\n(2) According to Richard Stallman, 1.6.1 is not GPL-compatible,\n    because its license has a choice of law clause.  According to\n    CNRI, however, Stallman's lawyer has told CNRI's lawyer that 1.6.1\n    is \"not incompatible\" with the GPL.\n\nThanks to the many outside volunteers who have worked under Guido's\ndirection to make these releases possible.\n\n\nB. TERMS AND CONDITIONS FOR ACCESSING OR OTHERWISE USING PYTHON\n===============================================================\n\nPYTHON SOFTWARE FOUNDATION LICENSE VERSION 2\n--------------------------------------------\n\n1. This LICENSE AGREEMENT is between the Python Software Foundation\n(\"PSF\"), and the Individual or Organization (\"Licensee\") accessing and\notherwise using this software (\"Python\") in source or binary form and\nits associated documentation.\n\n2. Subject to the terms and conditions of this License Agreement, PSF hereby\ngrants Licensee a nonexclusive, royalty-free, world-wide license to reproduce,\nanalyze, test, perform and/or display publicly, prepare derivative works,\ndistribute, and otherwise use Python alone or in any derivative version,\nprovided, however, that PSF's License Agreement and PSF's notice of copyright,\ni.e., \"Copyright (c) 2001, 2002, 2003, 2004, 2005, 2006, 2007, 2008, 2009, 2010,\n2011, 2012, 2013, 2014, 2015, 2016, 2017, 2018, 2019, 2020 Python Software Foundation;\nAll Rights Reserved\" are retained in Python alone or in any derivative version\nprepared by Licensee.\n\n3. In the event Licensee prepares a derivative work that is based on\nor incorporates Python or any part thereof, and wants to make\nthe derivative work available to others as provided herein, then\nLicensee hereby agrees to include in any such work a brief summary of\nthe changes made to Python.\n\n4. PSF is making Python available to Licensee on an \"AS IS\"\nbasis.  PSF MAKES NO REPRESENTATIONS OR WARRANTIES, EXPRESS OR\nIMPLIED.  BY WAY OF EXAMPLE, BUT NOT LIMITATION, PSF MAKES NO AND\nDISCLAIMS ANY REPRESENTATION OR WARRANTY OF MERCHANTABILITY OR FITNESS\nFOR ANY PARTICULAR PURPOSE OR THAT THE USE OF PYTHON WILL NOT\nINFRINGE ANY THIRD PARTY RIGHTS.\n\n5. PSF SHALL NOT BE LIABLE TO LICENSEE OR ANY OTHER USERS OF PYTHON\nFOR ANY INCIDENTAL, SPECIAL, OR CONSEQUENTIAL DAMAGES OR LOSS AS\nA RESULT OF MODIFYING, DISTRIBUTING, OR OTHERWISE USING PYTHON,\nOR ANY DERIVATIVE THEREOF, EVEN IF ADVISED OF THE POSSIBILITY THEREOF.\n\n6. This License Agreement will automatically terminate upon a material\nbreach of its terms and conditions.\n\n7. Nothing in this License Agreement shall be deemed to create any\nrelationship of agency, partnership, or joint venture between PSF and\nLicensee.  This License Agreement does not grant permission to use PSF\ntrademarks or trade name in a trademark sense to endorse or promote\nproducts or services of Licensee, or any third party.\n\n8. By copying, installing or otherwise using Python, Licensee\nagrees to be bound by the terms and conditions of this License\nAgreement.\n\n\nBEOPEN.COM LICENSE AGREEMENT FOR PYTHON 2.0\n-------------------------------------------\n\nBEOPEN PYTHON OPEN SOURCE LICENSE AGREEMENT VERSION 1\n\n1. This LICENSE AGREEMENT is between BeOpen.com (\"BeOpen\"), having an\noffice at 160 Saratoga Avenue, Santa Clara, CA 95051, and the\nIndividual or Organization (\"Licensee\") accessing and otherwise using\nthis software in source or binary form and its associated\ndocumentation (\"the Software\").\n\n2. Subject to the terms and conditions of this BeOpen Python License\nAgreement, BeOpen hereby grants Licensee a non-exclusive,\nroyalty-free, world-wide license to reproduce, analyze, test, perform\nand/or display publicly, prepare derivative works, distribute, and\notherwise use the Software alone or in any derivative version,\nprovided, however, that the BeOpen Python License is retained in the\nSoftware, alone or in any derivative version prepared by Licensee.\n\n3. BeOpen is making the Software available to Licensee on an \"AS IS\"\nbasis.  BEOPEN MAKES NO REPRESENTATIONS OR WARRANTIES, EXPRESS OR\nIMPLIED.  BY WAY OF EXAMPLE, BUT NOT LIMITATION, BEOPEN MAKES NO AND\nDISCLAIMS ANY REPRESENTATION OR WARRANTY OF MERCHANTABILITY OR FITNESS\nFOR ANY PARTICULAR PURPOSE OR THAT THE USE OF THE SOFTWARE WILL NOT\nINFRINGE ANY THIRD PARTY RIGHTS.\n\n4. BEOPEN SHALL NOT BE LIABLE TO LICENSEE OR ANY OTHER USERS OF THE\nSOFTWARE FOR ANY INCIDENTAL, SPECIAL, OR CONSEQUENTIAL DAMAGES OR LOSS\nAS A RESULT OF USING, MODIFYING OR DISTRIBUTING THE SOFTWARE, OR ANY\nDERIVATIVE THEREOF, EVEN IF ADVISED OF THE POSSIBILITY THEREOF.\n\n5. This License Agreement will automatically terminate upon a material\nbreach of its terms and conditions.\n\n6. This License Agreement shall be governed by and interpreted in all\nrespects by the law of the State of California, excluding conflict of\nlaw provisions.  Nothing in this License Agreement shall be deemed to\ncreate any relationship of agency, partnership, or joint venture\nbetween BeOpen and Licensee.  This License Agreement does not grant\npermission to use BeOpen trademarks or trade names in a trademark\nsense to endorse or promote products or services of Licensee, or any\nthird party.  As an exception, the \"BeOpen Python\" logos available at\nhttp://www.pythonlabs.com/logos.html may be used according to the\npermissions granted on that web page.\n\n7. By copying, installing or otherwise using the software, Licensee\nagrees to be bound by the terms and conditions of this License\nAgreement.\n\n\nCNRI LICENSE AGREEMENT FOR PYTHON 1.6.1\n---------------------------------------\n\n1. This LICENSE AGREEMENT is between the Corporation for National\nResearch Initiatives, having an office at 1895 Preston White Drive,\nReston, VA 20191 (\"CNRI\"), and the Individual or Organization\n(\"Licensee\") accessing and otherwise using Python 1.6.1 software in\nsource or binary form and its associated documentation.\n\n2. Subject to the terms and conditions of this License Agreement, CNRI\nhereby grants Licensee a nonexclusive, royalty-free, world-wide\nlicense to reproduce, analyze, test, perform and/or display publicly,\nprepare derivative works, distribute, and otherwise use Python 1.6.1\nalone or in any derivative version, provided, however, that CNRI's\nLicense Agreement and CNRI's notice of copyright, i.e., \"Copyright (c)\n1995-2001 Corporation for National Research Initiatives; All Rights\nReserved\" are retained in Python 1.6.1 alone or in any derivative\nversion prepared by Licensee.  Alternately, in lieu of CNRI's License\nAgreement, Licensee may substitute the following text (omitting the\nquotes): \"Python 1.6.1 is made available subject to the terms and\nconditions in CNRI's License Agreement.  This Agreement together with\nPython 1.6.1 may be located on the Internet using the following\nunique, persistent identifier (known as a handle): 1895.22/1013.  This\nAgreement may also be obtained from a proxy server on the Internet\nusing the following URL: http://hdl.handle.net/1895.22/1013\".\n\n3. In the event Licensee prepares a derivative work that is based on\nor incorporates Python 1.6.1 or any part thereof, and wants to make\nthe derivative work available to others as provided herein, then\nLicensee hereby agrees to include in any such work a brief summary of\nthe changes made to Python 1.6.1.\n\n4. CNRI is making Python 1.6.1 available to Licensee on an \"AS IS\"\nbasis.  CNRI MAKES NO REPRESENTATIONS OR WARRANTIES, EXPRESS OR\nIMPLIED.  BY WAY OF EXAMPLE, BUT NOT LIMITATION, CNRI MAKES NO AND\nDISCLAIMS ANY REPRESENTATION OR WARRANTY OF MERCHANTABILITY OR FITNESS\nFOR ANY PARTICULAR PURPOSE OR THAT THE USE OF PYTHON 1.6.1 WILL NOT\nINFRINGE ANY THIRD PARTY RIGHTS.\n\n5. CNRI SHALL NOT BE LIABLE TO LICENSEE OR ANY OTHER USERS OF PYTHON\n1.6.1 FOR ANY INCIDENTAL, SPECIAL, OR CONSEQUENTIAL DAMAGES OR LOSS AS\nA RESULT OF MODIFYING, DISTRIBUTING, OR OTHERWISE USING PYTHON 1.6.1,\nOR ANY DERIVATIVE THEREOF, EVEN IF ADVISED OF THE POSSIBILITY THEREOF.\n\n6. This License Agreement will automatically terminate upon a material\nbreach of its terms and conditions.\n\n7. This License Agreement shall be governed by the federal\nintellectual property law of the United States, including without\nlimitation the federal copyright law, and, to the extent such\nU.S. federal law does not apply, by the law of the Commonwealth of\nVirginia, excluding Virginia's conflict of law provisions.\nNotwithstanding the foregoing, with regard to derivative works based\non Python 1.6.1 that incorporate non-separable material that was\npreviously distributed under the GNU General Public License (GPL), the\nlaw of the Commonwealth of Virginia shall govern this License\nAgreement only as to issues arising under or with respect to\nParagraphs 4, 5, and 7 of this License Agreement.  Nothing in this\nLicense Agreement shall be deemed to create any relationship of\nagency, partnership, or joint venture between CNRI and Licensee.  This\nLicense Agreement does not grant permission to use CNRI trademarks or\ntrade name in a trademark sense to endorse or promote products or\nservices of Licensee, or any third party.\n\n8. By clicking on the \"ACCEPT\" button where indicated, or by copying,\ninstalling or otherwise using Python 1.6.1, Licensee agrees to be\nbound by the terms and conditions of this License Agreement.\n\n        ACCEPT\n\n\nCWI LICENSE AGREEMENT FOR PYTHON 0.9.0 THROUGH 1.2\n--------------------------------------------------\n\nCopyright (c) 1991 - 1995, Stichting Mathematisch Centrum Amsterdam,\nThe Netherlands.  All rights reserved.\n\nPermission to use, copy, modify, and distribute this software and its\ndocumentation for any purpose and without fee is hereby granted,\nprovided that the above copyright notice appear in all copies and that\nboth that copyright notice and this permission notice appear in\nsupporting documentation, and that the name of Stichting Mathematisch\nCentrum or CWI not be used in advertising or publicity pertaining to\ndistribution of the software without specific, written prior\npermission.\n\nSTICHTING MATHEMATISCH CENTRUM DISCLAIMS ALL WARRANTIES WITH REGARD TO\nTHIS SOFTWARE, INCLUDING ALL IMPLIED WARRANTIES OF MERCHANTABILITY AND\nFITNESS, IN NO EVENT SHALL STICHTING MATHEMATISCH CENTRUM BE LIABLE\nFOR ANY SPECIAL, INDIRECT OR CONSEQUENTIAL DAMAGES OR ANY DAMAGES\nWHATSOEVER RESULTING FROM LOSS OF USE, DATA OR PROFITS, WHETHER IN AN\nACTION OF CONTRACT, NEGLIGENCE OR OTHER TORTIOUS ACTION, ARISING OUT\nOF OR IN CONNECTION WITH THE USE OR PERFORMANCE OF THIS SOFTWARE.\n\nSoftware: Python 3.9.2\nCopyright notice:\nCopyright (c) 1999-2000 by Secret Labs AB\nCopyright (C) 2005-2007   Gregory P. Smith (greg@krypto.org)\nCopyright (c) 2003.\n.  Copyright (C) 2005-2010   Gregory P. Smith (greg@krypto.org)\nCopyright 1996,1997 by Oliver Andrich, Koblenz, Germany.\nCopyright (c) 2008-2020 Stefan Krah. All rights reserved.\nCopyright (c) 2001, 2002, 2003, 2004, 2005, 2006 Python Software Foundation.\nCopyright (c) 1995-2001 Corporation for National Research Initiatives.  All rights reserved.\nCopyright 1994 by Lance Ellinghouse Cathedral City, California Republic, United States of America.\nCopyright (C) 2001 Python Software Foundation Barry Warsaw <barry@python.org>, 2000.\nCopyright (c) 2008-2012 Stefan Krah. All rights reserved.\n2001-07-01 fl   added BIGCHARSET support (from Martin von Loewis)\n``'Copyright 1991-1995 Stichting Mathematisch Centrum, Amsterdam'``\nCopyright (C) 2003 Python Software Foundation\nCopyright (C) 2001-2016 Vinay Sajip. All Rights Reserved.\nCopyright 1995-1997, Automatrix, Inc., all rights reserved.\nCopyright (c) 2002 MyCompanyName. All rights reserved.\nCopyright (c) 2004 by Peter Astrand <astrand@lysator.liu.se>\nCopyright (c) 1999-2002 by Fredrik Lundh.\nCopyright (c) 1991-1995 Stichting Mathematisch Centrum, Amsterdam.\\n\\\nAIX ABI support (c) 2002 Free Software Foundation, Inc.\nCopyright (C) 1996-2020 Free Software Foundation, Inc.\n2013-02-04 mrab added fullmatch primitive\n2003-10-17 gn   implemented non recursive scheme\n2003-04-18 mvl  fully support 4-byte codes\nCopyright (c) 1999-2002 by Secret Labs AB.\nportions copyright 2001, Autonomous Zones Industries, Inc., all rights...\nCopyright © 2013 W3C® (MIT, ERCIM, Keio, Beihang), All Rights Reserved.\nCopyright (C) 1986 Gary S. Brown.  You may use this program, or code or tables extracted from it, as desired without restriction.\n-- Copyright (c) IBM Corporation, 2003, 2008.  All rights reserved.   --\n; Copyright (c) 2008-2020 Stefan Krah. All rights reserved.\nCopyright 2008 Armin Ronacher.\nCopyright © 2000 BeOpen.com. All rights reserved.\n(c) 2005 Ian Bicking and contributors; written for Paste (http://pythonpaste.org)\nCopyright (c) 2005-2006 ActiveState Software Inc.\nCopyright (C) 1994 Steen Lumholt.\nCopyright (c) 1999 by Fredrik Lundh.\nlibffi - Copyright (c) 1996-2003  Red Hat, Inc.\nCopyright (C) 2002 Lars Gustaebel <lars@gustaebel.de>\nCopyright (c) 1999-2003 Steve Purcell\nDarwin ABI support (c) 2001 John Hornkvist\nCopyright (c) 2001-2021 Python Software Foundation.\\n\\\nCopyright (C) 1995-1998 Eric Young (eay@cryptsoft.com)\nCopyright (c) 1999-2008 by Fredrik Lundh\ni.e., \"Copyright © 1995-2001 Corporation for National Research Initiatives; All Rights Reserved\" are retained in Python 1.6.1 alone or in any derivative version prepared by Licensee.  Alternately, in lieu of CNRI's License Agreement, Licensee may substitute the following text (omitting the quotes): \"Python 1.6.1\n-- Copyright (c) IBM Corporation, 2005, 2009.  All rights reserved.   --\nCopyright (c) 2001-2017 Expat maintainers\nCopyright (c) 2001-2012 Python Software Foundation. All Rights Reserved.\nCopyright (C) 2002-2006 Python Software Foundation Author: Barry Warsaw Contact: email-sig@python.org\n(c) 2002 Gregory P. Ward.  All Rights Reserved.\ncopyright, i.e., \"Copyright © 2001-2021 Python Software Foundation; All Rights Reserved\" are retained in Python |release| alone or in any derivative version prepared by Licensee.\nCopyright (c) 2000 BeOpen.com.\\n\\\nCopyright (C) 2001-2007 Python Software Foundation Author: Ben Gertzfield, Barry Warsaw Contact: email-sig@python.org\nCopyright (C) 2003-2004 Federico Di Gregorio <fog@debian.org>\n2001-05-14 fl   fixes for 1.5.2 compatibility\nCopyright (c) 2001-2021 Python Software Foundation.  All rights reserved.\nCopyright © 1995-2000 Corporation for National Research Initiatives. All rights reserved.\nCopyright (c) 2013 W3C(R) (MIT, ERCIM, Keio, Beihang), All Rights Reserved.\nCopyright (C) 1995, 1996, 1997, 1998, and 1999 WIDE Project.\nCopyright (C) 2001-2007 Python Software Foundation Author: Barry Warsaw, Thomas Wouters, Anthony Baxter Contact: email-sig@python.org\nCopyright (C) 2005-2010   Gregory P. Smith (greg@krypto.org)\nCopyright (c) 2000 Doug White, 2006 James Knight, 2007 Christian Heimes All rights reserved.\nCopyright (C) 1999-2001 Gregory P. Ward.\nCopyright (c) 1999-2002 by Fredrik Lundh\n+   Copyright 2007 Python Software Foundation.\nelse if (config == (void )2000 && (c) == 0x9B1D) {                 \\\nCopyright (c) 1999-2002 by Secret Labs AB\n2002-11-09 fl   fixed empty sub/subn return type\nCopyright (C) 2003-2013 Python Software Foundation import copy import operator import pickle import struct import unittest import plistlib import os import datetime import codecs import binascii import collections from test import support from io import BytesIO\nCopyright 2009 Gabriel A. Genellina\nCopyright (c) 2003-2009 by Fredrik Lundh.  All rights reserved.\nCopyright 2004-2005 Elemental Security, Inc. All Rights Reserved.\n(c) Copyright Guido van Rossum, 2000.\nCopyright (C) 1995, 1996, 1997, and 1998 WIDE Project.\nCopyright (C) 2011-2012 Vinay Sajip.\nCopyright 2006 Google, Inc. All Rights Reserved.\n(c) Copyright Marc-Andre Lemburg, 2005.\nCopyright (C) YEAR ORGANIZATION FIRST AUTHOR <EMAIL@ADDRESS>, YEAR.\nCopyright (c) 1999-2000, Marc-Andre Lemburg; mailto:mal@lemburg.com\nCopyright (c) 1995-2000, Corporation for National Research Initiatives.\nCopyright (C) 2001 I'O, All Rights Reserved.\nCopyright (c) 1999 Toby Dickenson\nCopyright (C) 2001,2002 Python Software Foundation csv package unit tests\nCopyright (C) 2005, 2006 Martin von Löwis Licensed to PSF under a Contributor Agreement.\nCopyright (c) 1997 by Fredrik Lundh\nCopyright (c) 2002-2006 Python Software Foundation.  All rights reserved.\nCopyright (c) 2002  Roger Sayle\nCopyright 1995-1996 by Fred L. Drake, Jr. and Virginia Polytechnic Institute and State University, Blacksburg, Virginia, USA.\ntypes.c - Copyright (c) 1996, 1998  Red Hat, Inc.\nCopyright 2000, Mojam Media, Inc., all rights reserved.\nCopyright (C) 1994 X Consortium\nCopyright (C) 2002-2004 Python Software Foundation\nCopyright (C) 2004-2006 Python Software Foundation Authors: Baxter, Wouters and Warsaw Contact: email-sig@python.org\nCopyright (c) 2002 Jorge Acereda  <jacereda@users.sourceforge.net> &\ndarwin.S - Copyright (c) 1996, 1998, 2001, 2002, 2003  Red Hat, Inc.\nCopyright © 1991 - 1995, Stichting Mathematisch Centrum Amsterdam, The Netherlands.  All rights reserved.\n\"Copyright 1995-1996 by Virginia Polytechnic Institute & State\\n\\\nx86-ffitarget.h - Copyright (c) 1996-2003  Red Hat, Inc.\nCopyright (C) 1995-2011 Jean-loup Gailly and Mark Adler\nCopyright 1991-1995, Stichting Mathematisch Centrum, all rights reserved.\n<string>(c) 2001-2020 Python Software Foundation.</string>\ndarwin64.S - Copyright (c) 2006 Free Software Foundation, Inc.\nCopyright (C) 2001-2006 Python Software Foundation Author: Ben Gertzfield Contact: email-sig@python.org\nCopyright (c) 2005 Don Owens All rights reserved.\n(c) Copyright 2005, Marc-Andre Lemburg (mal@lemburg.com).\nlibrary/xml.etree.elementtree,,:include,  Copyright (c) <xi:include href=\"year.txt\" parse=\"text\" />.\nffi.c - Copyright (c) 1998 Geoffrey Keating\nCopyright 2006 Georg Brandl.\nCopyright (C) 2005-2010 Gerhard Häring <gh@ghaering.de>\n(c) 2013-2017 Christian Heimes <christian@python.org>\nCopyright 1992-2018 Free Software Foundation, Inc.\nCopyright (c) 1990-1995, Stichting Mathematisch Centrum.\ni.e., \"Copyright (c) 2001, 2002, 2003, 2004, 2005, 2006, 2007, 2008, 2009, 2010, 2011, 2012, 2013, 2014, 2015, 2016, 2017, 2018, 2019, 2020, 2021 Python Software Foundation;\n2001-10-24 fl   added finditer primitive (for 2.2 only)\nCopyright (C) 2001-2006 Python Software Foundation Author: Keith Dart Contact: email-sig@python.org\nCopyright (c) 1999-2009 by Fredrik Lundh.\n(c) 2000 Peter Bosch.  All Rights Reserved.\n<string>%version%, (c) 2001-2021 Python Software Foundation.</string>\nCopyright (C) 2001 earthian@tama.or.jp, All Rights Reserved.\nCopyright (C) 1993 by Sun Microsystems, Inc. All rights reserved.\nCopyright (C) 2012 Free Software Foundation, Inc.\nCopyright (C) 2002-2007 Python Software Foundation Author: Ben Gertzfield Contact: email-sig@python.org\nCopyright 1994 by Lance Ellinghouse, Cathedral City, California Republic, United States of America.\nCopyright (C) 2006 - 2010  Gregor Lingl email: glingl@aon.at\nCopyright © 2001-2021 Python Software Foundation. All rights reserved.\nCopyright (c) 2009,2010 Zmanda Inc. <http://www.zmanda.com/>\nCopyright (c) 1998-2008 The OpenSSL Project.  All rights reserved.\nCopyright 1996 by Sam Rushing\nCopyright (c) 1998-2000 Thai Open Source Software Center Ltd and Clark Cooper\ncopyright, i.e., \"Copyright © 2001-2018 Python Software Foundation; All Rights Reserved\" are retained in Python 3.9 alone or in any derivative version prepared by Licensee.\n(c) Craig Reese, Joe Campbell and Jeff Poskanzer 1989 /\nCopyright (c) 1999, 2000, 2001 Steve Purcell This module is free software, and you may redistribute it and/or modify it under the same terms as Python itself, so long as this copyright message and disclaimer are retained in their original form.\n-- Copyright (c) IBM Corporation, 2005, 2008.  All rights reserved.   --\nCopyright (C) 2001-2012 Python Software Foundation. All Rights Reserved.\ndnl Copyright © 2004 Scott James Remnant <scott@netsplit.com>.\nCopyright (C) 2002-2007 Python Software Foundation Contact: email-sig@python.org\nCopyright (c) 1998-2001 by Secret Labs AB.  All rights reserved.\nCopyright (c) 2009,2010 Dustin J. Mitchell <dustin@zmanda.com>\nCopyright (c) 2002  Bo Thorsen\n2001-10-21 fl   added sub/subn primitive\nCopyright 1992-1994, David Gottner\nCopyright (C) 2011-2013 Vinay Sajip.\nCopyright (c) 1991, 2000, 2001 by Lucent Technologies.\nCopyright (c) 2010 Python Software Foundation. All Rights Reserved.\n\" SRE 2.2.2 Copyright (c) 1997-2002 by Secret Labs AB \";\n;   Copyright (c) 2004, Outercurve Foundation.\nCopyright (c) 2003-2005 by Peter Astrand <astrand@lysator.liu.se>\nCopyright (c) 1999 by Secret Labs AB\nlibffi PyOBJC - Copyright (c) 1996-2003  Red Hat, Inc.\nCopyright (c) 1999-2009 by Fredrik Lundh\nCopyright 2007 Google, Inc. All Rights Reserved.\n-- Copyright (c) IBM Corporation, 2004, 2008.  All rights reserved.   --\nCopyright (C) 2001-2007 Python Software Foundation Author: Barry Warsaw Contact: email-sig@python.org\nCopyright (c) 2000 BeOpen.com.  All rights reserved.\n3-2926   U+00A9    COPYRIGHT SIGN    [2000]\n<string>%version%, (c) 2001-2020 Python Software Foundation.</string>\nCopyright © 1991-1995 Stichting Mathematisch Centrum. All rights reserved.\nCopyright (C) 2000  Luke Kenneth Casson Leighton <lkcl@samba.org>\nCopyright (C) 2005-2007 Gerhard Häring <gh@ghaering.de>\n2001-12-07 fl   fixed memory leak in sub/subn (Guido van Rossum)\n-- Copyright (c) IBM Corporation, 2001, 2008.  All rights reserved.   --\nVirginia, USA.  Portions copyright 1991-1995 by Stichting Mathematisch\\n\\\nCopyright (c) 2004 Free Software Foundation, Inc.\nso portions are Copyright (C) 2001,2002 Python Software Foundation, and were written by Barry Warsaw.\nCopyright (C) 2004-2010 Gerhard Häring <gh@ghaering.de>\nCopyright (c) 2004 Python Software Foundation.\n(c) Copyright 2000 Guido van Rossum.\nCopyright 2007 Georg Brandl.\nCopyright (c) 1999 by Secret Labs AB.\nCopyright (c) 2002 Unicode, Inc.  All Rights reserved.\nCopyright 2009 Brian Quinlan. All Rights Reserved.\nCopyright (c) 2008-2009, Google Inc.\nCopyright (c) 2001-2006 Twisted Matrix Laboratories.\n(c) Copyright CNRI, All Rights Reserved. NO WARRANTY.\nLicense Agreement and CNRI's notice of copyright, i.e., \"Copyright (c) 1995-2001 Corporation for National Research Initiatives; All Rights Reserved\" are retained in Python 1.6.1 alone or in any derivative version prepared by Licensee.  Alternately, in lieu of CNRI's License Agreement, Licensee may substitute the following text (omitting the quotes): \"Python 1.6.1 is made available subject to the terms and conditions in CNRI's License Agreement.  This Agreement together with Python 1.6.1 may be located on the Internet using the following unique, persistent identifier (known as a handle): 1895.22/1013.  This Agreement may also be obtained from a proxy server on the Internet\nCopyright (c) Corporation for National Research Initiatives.\nif (config == (void )2000 && (c) == 0x20B9F) {                     \\\nCopyright 2001-2016 by Vinay Sajip. All Rights Reserved.\nppc-ffitarget.h - Copyright (c) 1996-2003  Red Hat, Inc.\nppc-darwin.h - Copyright (c) 2002, 2003, 2004, Free Software Foundation, Inc.\nCopyright (c) 2001-2006 Gregory P. Ward.  All rights reserved.\nCopyright (c) 1997-2001 by Secret Labs AB.  All rights reserved.\nCopyright 2000 by Timothy O'Malley <timo@alum.mit.edu>\nCopyright (C) 2007-2012 Michael Foord & the mock team E-mail: fuzzyman AT voidspace DOT org DOT uk\nCopyright (C) 2011-2014 Vinay Sajip.\nx86-ffi64.c - Copyright (c) 2002  Bo Thorsen <bo@suse.de>\nppc64-darwinclosure.S - Copyright (c) 2002, 2003, 2004, Free Software Foundation, Inc. based on ppcclosure.S\nCopyright (c) 2002  Ranjit Mathew\nCopyright (C) 2001-2006 Python Software Foundation Author: Barry Warsaw Contact: email-sig@python.org\n﻿Copyright (c) 2004, Outercurve Foundation.\nCopyright (c) 1995-2001 Corporation for National Research Initiatives.\\n\\\nCopyright 1999, Bioreason, Inc., all rights reserved.\n2001-10-20 fl   added split primitive; re-enable unicode for 1.6/2.0/2.1\nCopyright (C) 2001-2019 Vinay Sajip. All Rights Reserved.\nCopyright (c) 2008 by Christian Heimes <christian@cheimes.de>\nCopyright 2001-2019 by Vinay Sajip. All Rights Reserved.\nCopyright (C) 2005 Martin v. Löwis Licensed to PSF under a contributor agreement.\nppc-darwin.S - Copyright (c) 2000 John Hornkvist\nCopyright (c) 2000, BeOpen.com.\nCopyright (C) 2001-2010 Python Software Foundation Author: Barry Warsaw Contact: email-sig@python.org\nCopyright (C) 2001-2007 Python Software Foundation Author: Anthony Baxter Contact: email-sig@python.org\nCopyright (c) 2004 by Fredrik Lundh <fredrik@pythonware.com>\nCopyright Disney Enterprises, Inc.  All Rights Reserved.\nffi.c - Copyright (c) 1996, 1998, 1999, 2001  Red Hat, Inc.\nCopyright (c) 1991 - 1995, Stichting Mathematisch Centrum Amsterdam, The Netherlands.  All rights reserved.\nCopyright (c) <xi:include href=\"year.txt\" parse=\"text\" />.\nprepcif.c - Copyright (c) 1996, 1998  Red Hat, Inc.\nself.assertEqual(list(c), list(range(2,2000)))\nCopyright (C) 2002-2007 Python Software Foundation Author: Ben Gertzfield, Barry Warsaw Contact: email-sig@python.org\n-- Copyright (c) IBM Corporation, 2000, 2008.  All rights reserved.   --\nCopyright (C) 2012   Christian Heimes (christian@python.org)\nfficommon.h - Copyright (c) 1996  Red Hat, Inc.\nCopyright (C) 2012-2016  Christian Heimes (christian@python.org)\nCopyright (C) 2004-2005 Gerhard Häring <gh@ghaering.de>\n(c) 2002 Python Software Foundation.  All Rights Reserved.\nCopyright (c) 2004 by Secret Labs AB, http://www.pythonware.com\nCopyright (c) 2004, Outercurve Foundation.\nCopyright (c) 2006-2008, R Oudkerk Licensed to PSF under a Contributor Agreement.\n.. Copyright 1995 Virginia Polytechnic Institute and State University and Fred L. Drake, Jr.  This copyright notice must be distributed on all copies, but this document otherwise may be distributed as part of the Python distribution.  No fee may be charged for this document in any representation, either on paper or electronically.  This restriction does not affect other elements in a distributed package in any way.\nCopyright 2012-2013 by Larry Hastings.\nCopyright (C) 2002-2006 Python Software Foundation Contact: email-sig@python.org email package unit tests for (optional) Asian codecs\nCopyright (c) 2002 Peter O'Gorman <ogorman@users.sourceforge.net>\nCopyright 2007 Google Inc.\nCopyright (c) 1999 by Fredrik Lundh\nCopyright (C) 2001-2010 Python Software Foundation Contact: email-sig@python.org email package unit tests\nCopyright (c) 2003-2004 by Fredrik Lundh.  All rights reserved.\nCopyright (c) 1991-1999 Unicode, Inc.  All Rights reserved.\nCopyright (c) 2000-2017 Expat development team Licensed under the MIT license:\nCopyright (c) 1997-2000 Thai Open Source Software Center Ltd\nCopyright (c) 1998 The Open Group\nCopyright (c) 1991 - 1995, Stichting Mathematisch Centrum Amsterdam, The Netherlands. All rights reserved.\\\nCopyright (c) 2000-2010, eGenix.com Software GmbH; mailto:info@egenix.com\nCopyright (C) 2005 Gerhard Häring <gh@ghaering.de>\ncopyright = '2001-%s, Python Software Foundation' % time.strftime('%Y')\nCopyright (c) 1996-2008  Red Hat, Inc and others.\nCopyright (C) 2005 Martin v. Löwis Licensed to PSF under a Contributor Agreement.\nCopyright (C) 1997, 2002, 2003, 2007, 2008 Martin von Loewis\n<string>%VERSION%, (c) 2001-2019 Python Software Foundation.</string>\n( Copyright (c) 2011-2020 Stefan Krah. All rights reserved. )\nCopyright (c) 2013  Marek Majkowski <marek@popcount.org>\nCopyright (c) 2008 Daniel Amelang <dan@amelang.net>\nCopyright (c) 1999-2008 by Fredrik Lundh.  All rights reserved.\nCopyright (C) 1997 - 2002, Makoto Matsumoto and Takuji Nishimura, All rights reserved.\nCopyright (c) 1998, 1999, 2000 Thai Open Source Software Center Ltd and Clark Cooper\n2001-04-15 fl   export copyright as Python attribute, not global 2001-04-28 fl   added copy methods (work in progress)\nCopyright (C) 2002, 2003 Python Software Foundation.\nCopyright (c) 2004, 2005, 2006 Python Software Foundation.\ndnl Copyright © 2012-2015 Dan Nicholson <dbn.lists@gmail.com>\nCopyright (c) 1999-2009 by Secret Labs AB.  All rights reserved.\nCopyright (c) 2003-2010 Python Software Foundation This module is free software, and you may redistribute it and/or modify it under the same terms as Python itself, so long as this copyright message and disclaimer are retained in their original form.\nCopyright (c) 1991-1995 Stichting Mathematisch Centrum.  All rights reserved.\n2001-10-18 fl   fixed group reset issue (from Matthew Mueller)\nCopyright (C) 1992-1996, 1998-2012 Free Software Foundation, Inc.\n-- Copyright (c) IBM Corporation, 1981, 2008.  All rights reserved.   --\nCopyright (C) 2000  Bastian Kleineidam\nppc-darwinclosure.S - Copyright (c) 2002, 2003, 2004, Free Software Foundation, Inc. based on ppcclosure.S\nPortions copyright 1991-1995 by Stichting Mathematisch Centrum, Amsterdam, The Netherlands.  Copying is permitted under the terms associated with the main Python distribution, with the additional restriction that this additional notice be included and maintained on all distributed copies.\n\nA. HISTORY OF THE SOFTWARE\n==========================\n\nPython was created in the early 1990s by Guido van Rossum at Stichting\nMathematisch Centrum (CWI, see http://www.cwi.nl) in the Netherlands\nas a successor of a language called ABC.  Guido remains Python's\nprincipal author, although it includes many contributions from others.\n\nIn 1995, Guido continued his work on Python at the Corporation for\nNational Research Initiatives (CNRI, see http://www.cnri.reston.va.us)\nin Reston, Virginia where he released several versions of the\nsoftware.\n\nIn May 2000, Guido and the Python core development team moved to\nBeOpen.com to form the BeOpen PythonLabs team.  In October of the same\nyear, the PythonLabs team moved to Digital Creations, which became\nZope Corporation.  In 2001, the Python Software Foundation (PSF, see\nhttps://www.python.org/psf/) was formed, a non-profit organization\ncreated specifically to own Python-related Intellectual Property.\nZope Corporation was a sponsoring member of the PSF.\n\nAll Python releases are Open Source (see http://www.opensource.org for\nthe Open Source Definition).  Historically, most, but not all, Python\nreleases have also been GPL-compatible; the table below summarizes\nthe various releases.\n\n    Release         Derived     Year        Owner       GPL-\n                    from                                compatible? (1)\n\n    0.9.0 thru 1.2              1991-1995   CWI         yes\n    1.3 thru 1.5.2  1.2         1995-1999   CNRI        yes\n    1.6             1.5.2       2000        CNRI        no\n    2.0             1.6         2000        BeOpen.com  no\n    1.6.1           1.6         2001        CNRI        yes (2)\n    2.1             2.0+1.6.1   2001        PSF         no\n    2.0.1           2.0+1.6.1   2001        PSF         yes\n    2.1.1           2.1+2.0.1   2001        PSF         yes\n    2.1.2           2.1.1       2002        PSF         yes\n    2.1.3           2.1.2       2002        PSF         yes\n    2.2 and above   2.1.1       2001-now    PSF         yes\n\nFootnotes:\n\n(1) GPL-compatible doesn't mean that we're distributing Python under\n    the GPL.  All Python licenses, unlike the GPL, let you distribute\n    a modified version without making your changes open source.  The\n    GPL-compatible licenses make it possible to combine Python with\n    other software that is released under the GPL; the others don't.\n\n(2) According to Richard Stallman, 1.6.1 is not GPL-compatible,\n    because its license has a choice of law clause.  According to\n    CNRI, however, Stallman's lawyer has told CNRI's lawyer that 1.6.1\n    is \"not incompatible\" with the GPL.\n\nThanks to the many outside volunteers who have worked under Guido's\ndirection to make these releases possible.\n\n\nB. TERMS AND CONDITIONS FOR ACCESSING OR OTHERWISE USING PYTHON\n===============================================================\n\nPython software and documentation are licensed under the\nPython Software Foundation License Version 2.\n\nStarting with Python 3.8.6, examples, recipes, and other code in\nthe documentation are dual licensed under the PSF License Version 2\nand the Zero-Clause BSD license.\n\nSome software incorporated into Python is under different licenses.\nThe licenses are listed with code falling under that license.\n\n\nPYTHON SOFTWARE FOUNDATION LICENSE VERSION 2\n--------------------------------------------\n\n1. This LICENSE AGREEMENT is between the Python Software Foundation\n(\"PSF\"), and the Individual or Organization (\"Licensee\") accessing and\notherwise using this software (\"Python\") in source or binary form and\nits associated documentation.\n\n2. Subject to the terms and conditions of this License Agreement, PSF hereby\ngrants Licensee a nonexclusive, royalty-free, world-wide license to reproduce,\nanalyze, test, perform and/or display publicly, prepare derivative works,\ndistribute, and otherwise use Python alone or in any derivative version,\nprovided, however, that PSF's License Agreement and PSF's notice of copyright,\ni.e., \"Copyright (c) 2001, 2002, 2003, 2004, 2005, 2006, 2007, 2008, 2009, 2010,\n2011, 2012, 2013, 2014, 2015, 2016, 2017, 2018, 2019, 2020, 2021 Python Software Foundation;\nAll Rights Reserved\" are retained in Python alone or in any derivative version\nprepared by Licensee.\n\n3. In the event Licensee prepares a derivative work that is based on\nor incorporates Python or any part thereof, and wants to make\nthe derivative work available to others as provided herein, then\nLicensee hereby agrees to include in any such work a brief summary of\nthe changes made to Python.\n\n4. PSF is making Python available to Licensee on an \"AS IS\"\nbasis.  PSF MAKES NO REPRESENTATIONS OR WARRANTIES, EXPRESS OR\nIMPLIED.  BY WAY OF EXAMPLE, BUT NOT LIMITATION, PSF MAKES NO AND\nDISCLAIMS ANY REPRESENTATION OR WARRANTY OF MERCHANTABILITY OR FITNESS\nFOR ANY PARTICULAR PURPOSE OR THAT THE USE OF PYTHON WILL NOT\nINFRINGE ANY THIRD PARTY RIGHTS.\n\n5. PSF SHALL NOT BE LIABLE TO LICENSEE OR ANY OTHER USERS OF PYTHON\nFOR ANY INCIDENTAL, SPECIAL, OR CONSEQUENTIAL DAMAGES OR LOSS AS\nA RESULT OF MODIFYING, DISTRIBUTING, OR OTHERWISE USING PYTHON,\nOR ANY DERIVATIVE THEREOF, EVEN IF ADVISED OF THE POSSIBILITY THEREOF.\n\n6. This License Agreement will automatically terminate upon a material\nbreach of its terms and conditions.\n\n7. Nothing in this License Agreement shall be deemed to create any\nrelationship of agency, partnership, or joint venture between PSF and\nLicensee.  This License Agreement does not grant permission to use PSF\ntrademarks or trade name in a trademark sense to endorse or promote\nproducts or services of Licensee, or any third party.\n\n8. By copying, installing or otherwise using Python, Licensee\nagrees to be bound by the terms and conditions of this License\nAgreement.\n\n\nBEOPEN.COM LICENSE AGREEMENT FOR PYTHON 2.0\n-------------------------------------------\n\nBEOPEN PYTHON OPEN SOURCE LICENSE AGREEMENT VERSION 1\n\n1. This LICENSE AGREEMENT is between BeOpen.com (\"BeOpen\"), having an\noffice at 160 Saratoga Avenue, Santa Clara, CA 95051, and the\nIndividual or Organization (\"Licensee\") accessing and otherwise using\nthis software in source or binary form and its associated\ndocumentation (\"the Software\").\n\n2. Subject to the terms and conditions of this BeOpen Python License\nAgreement, BeOpen hereby grants Licensee a non-exclusive,\nroyalty-free, world-wide license to reproduce, analyze, test, perform\nand/or display publicly, prepare derivative works, distribute, and\notherwise use the Software alone or in any derivative version,\nprovided, however, that the BeOpen Python License is retained in the\nSoftware, alone or in any derivative version prepared by Licensee.\n\n3. BeOpen is making the Software available to Licensee on an \"AS IS\"\nbasis.  BEOPEN MAKES NO REPRESENTATIONS OR WARRANTIES, EXPRESS OR\nIMPLIED.  BY WAY OF EXAMPLE, BUT NOT LIMITATION, BEOPEN MAKES NO AND\nDISCLAIMS ANY REPRESENTATION OR WARRANTY OF MERCHANTABILITY OR FITNESS\nFOR ANY PARTICULAR PURPOSE OR THAT THE USE OF THE SOFTWARE WILL NOT\nINFRINGE ANY THIRD PARTY RIGHTS.\n\n4. BEOPEN SHALL NOT BE LIABLE TO LICENSEE OR ANY OTHER USERS OF THE\nSOFTWARE FOR ANY INCIDENTAL, SPECIAL, OR CONSEQUENTIAL DAMAGES OR LOSS\nAS A RESULT OF USING, MODIFYING OR DISTRIBUTING THE SOFTWARE, OR ANY\nDERIVATIVE THEREOF, EVEN IF ADVISED OF THE POSSIBILITY THEREOF.\n\n5. This License Agreement will automatically terminate upon a material\nbreach of its terms and conditions.\n\n6. This License Agreement shall be governed by and interpreted in all\nrespects by the law of the State of California, excluding conflict of\nlaw provisions.  Nothing in this License Agreement shall be deemed to\ncreate any relationship of agency, partnership, or joint venture\nbetween BeOpen and Licensee.  This License Agreement does not grant\npermission to use BeOpen trademarks or trade names in a trademark\nsense to endorse or promote products or services of Licensee, or any\nthird party.  As an exception, the \"BeOpen Python\" logos available at\nhttp://www.pythonlabs.com/logos.html may be used according to the\npermissions granted on that web page.\n\n7. By copying, installing or otherwise using the software, Licensee\nagrees to be bound by the terms and conditions of this License\nAgreement.\n\n\nCNRI LICENSE AGREEMENT FOR PYTHON 1.6.1\n---------------------------------------\n\n1. This LICENSE AGREEMENT is between the Corporation for National\nResearch Initiatives, having an office at 1895 Preston White Drive,\nReston, VA 20191 (\"CNRI\"), and the Individual or Organization\n(\"Licensee\") accessing and otherwise using Python 1.6.1 software in\nsource or binary form and its associated documentation.\n\n2. Subject to the terms and conditions of this License Agreement, CNRI\nhereby grants Licensee a nonexclusive, royalty-free, world-wide\nlicense to reproduce, analyze, test, perform and/or display publicly,\nprepare derivative works, distribute, and otherwise use Python 1.6.1\nalone or in any derivative version, provided, however, that CNRI's\nLicense Agreement and CNRI's notice of copyright, i.e., \"Copyright (c)\n1995-2001 Corporation for National Research Initiatives; All Rights\nReserved\" are retained in Python 1.6.1 alone or in any derivative\nversion prepared by Licensee.  Alternately, in lieu of CNRI's License\nAgreement, Licensee may substitute the following text (omitting the\nquotes): \"Python 1.6.1 is made available subject to the terms and\nconditions in CNRI's License Agreement.  This Agreement together with\nPython 1.6.1 may be located on the Internet using the following\nunique, persistent identifier (known as a handle): 1895.22/1013.  This\nAgreement may also be obtained from a proxy server on the Internet\nusing the following URL: http://hdl.handle.net/1895.22/1013\".\n\n3. In the event Licensee prepares a derivative work that is based on\nor incorporates Python 1.6.1 or any part thereof, and wants to make\nthe derivative work available to others as provided herein, then\nLicensee hereby agrees to include in any such work a brief summary of\nthe changes made to Python 1.6.1.\n\n4. CNRI is making Python 1.6.1 available to Licensee on an \"AS IS\"\nbasis.  CNRI MAKES NO REPRESENTATIONS OR WARRANTIES, EXPRESS OR\nIMPLIED.  BY WAY OF EXAMPLE, BUT NOT LIMITATION, CNRI MAKES NO AND\nDISCLAIMS ANY REPRESENTATION OR WARRANTY OF MERCHANTABILITY OR FITNESS\nFOR ANY PARTICULAR PURPOSE OR THAT THE USE OF PYTHON 1.6.1 WILL NOT\nINFRINGE ANY THIRD PARTY RIGHTS.\n\n5. CNRI SHALL NOT BE LIABLE TO LICENSEE OR ANY OTHER USERS OF PYTHON\n1.6.1 FOR ANY INCIDENTAL, SPECIAL, OR CONSEQUENTIAL DAMAGES OR LOSS AS\nA RESULT OF MODIFYING, DISTRIBUTING, OR OTHERWISE USING PYTHON 1.6.1,\nOR ANY DERIVATIVE THEREOF, EVEN IF ADVISED OF THE POSSIBILITY THEREOF.\n\n6. This License Agreement will automatically terminate upon a material\nbreach of its terms and conditions.\n\n7. This License Agreement shall be governed by the federal\nintellectual property law of the United States, including without\nlimitation the federal copyright law, and, to the extent such\nU.S. federal law does not apply, by the law of the Commonwealth of\nVirginia, excluding Virginia's conflict of law provisions.\nNotwithstanding the foregoing, with regard to derivative works based\non Python 1.6.1 that incorporate non-separable material that was\npreviously distributed under the GNU General Public License (GPL), the\nlaw of the Commonwealth of Virginia shall govern this License\nAgreement only as to issues arising under or with respect to\nParagraphs 4, 5, and 7 of this License Agreement.  Nothing in this\nLicense Agreement shall be deemed to create any relationship of\nagency, partnership, or joint venture between CNRI and Licensee.  This\nLicense Agreement does not grant permission to use CNRI trademarks or\ntrade name in a trademark sense to endorse or promote products or\nservices of Licensee, or any third party.\n\n8. By clicking on the \"ACCEPT\" button where indicated, or by copying,\ninstalling or otherwise using Python 1.6.1, Licensee agrees to be\nbound by the terms and conditions of this License Agreement.\n\n        ACCEPT\n\n\nCWI LICENSE AGREEMENT FOR PYTHON 0.9.0 THROUGH 1.2\n--------------------------------------------------\n\nCopyright (c) 1991 - 1995, Stichting Mathematisch Centrum Amsterdam,\nThe Netherlands.  All rights reserved.\n\nPermission to use, copy, modify, and distribute this software and its\ndocumentation for any purpose and without fee is hereby granted,\nprovided that the above copyright notice appear in all copies and that\nboth that copyright notice and this permission notice appear in\nsupporting documentation, and that the name of Stichting Mathematisch\nCentrum or CWI not be used in advertising or publicity pertaining to\ndistribution of the software without specific, written prior\npermission.\n\nSTICHTING MATHEMATISCH CENTRUM DISCLAIMS ALL WARRANTIES WITH REGARD TO\nTHIS SOFTWARE, INCLUDING ALL IMPLIED WARRANTIES OF MERCHANTABILITY AND\nFITNESS, IN NO EVENT SHALL STICHTING MATHEMATISCH CENTRUM BE LIABLE\nFOR ANY SPECIAL, INDIRECT OR CONSEQUENTIAL DAMAGES OR ANY DAMAGES\nWHATSOEVER RESULTING FROM LOSS OF USE, DATA OR PROFITS, WHETHER IN AN\nACTION OF CONTRACT, NEGLIGENCE OR OTHER TORTIOUS ACTION, ARISING OUT\nOF OR IN CONNECTION WITH THE USE OR PERFORMANCE OF THIS SOFTWARE.\n\nZERO-CLAUSE BSD LICENSE FOR CODE IN THE PYTHON DOCUMENTATION\n----------------------------------------------------------------------\n\nPermission to use, copy, modify, and/or distribute this software for any\npurpose with or without fee is hereby granted.\n\nTHE SOFTWARE IS PROVIDED \"AS IS\" AND THE AUTHOR DISCLAIMS ALL WARRANTIES WITH\nREGARD TO THIS SOFTWARE INCLUDING ALL IMPLIED WARRANTIES OF MERCHANTABILITY\nAND FITNESS. IN NO EVENT SHALL THE AUTHOR BE LIABLE FOR ANY SPECIAL, DIRECT,\nINDIRECT, OR CONSEQUENTIAL DAMAGES OR ANY DAMAGES WHATSOEVER RESULTING FROM\nLOSS OF USE, DATA OR PROFITS, WHETHER IN AN ACTION OF CONTRACT, NEGLIGENCE OR\nOTHER TORTIOUS ACTION, ARISING OUT OF OR IN CONNECTION WITH THE USE OR\nPERFORMANCE OF THIS SOFTWARE.\n\nSoftware: sentencepiece v0.1.92\nCopyright notice:\nCopyright 2008 Google Inc.  All rights reserved.\nCopyright 2018 Google Inc.\nCopyright 2014 Google Inc.  All rights reserved.\nCopyright 2012 Google Inc.  All rights reserved.\nCopyright 2016 Google Inc.\nCopyright (c) 2006, Google Inc.\nCopyright (c) 2008-2009 Yuta Mori All Rights Reserved.\n© 2016 Unicode®, Inc.\nCopyright (c) 2010 Daisuke Okanohara All Rights Reserved.\nCopyright 2017 The Abseil Authors.\nCopyright (c) 2008-2011, Susumu Yata All rights reserved.\nCopyright 2016 Google LLC.\n\nApache License\n                           Version 2.0, January 2004\n                        http://www.apache.org/licenses/\n\n   TERMS AND CONDITIONS FOR USE, REPRODUCTION, AND DISTRIBUTION\n\n   1. Definitions.\n\n      \"License\" shall mean the terms and conditions for use, reproduction,\n      and distribution as defined by Sections 1 through 9 of this document.\n\n      \"Licensor\" shall mean the copyright owner or entity authorized by\n      the copyright owner that is granting the License.\n\n      \"Legal Entity\" shall mean the union of the acting entity and all\n      other entities that control, are controlled by, or are under common\n      control with that entity. For the purposes of this definition,\n      \"control\" means (i) the power, direct or indirect, to cause the\n      direction or management of such entity, whether by contract or\n      otherwise, or (ii) ownership of fifty percent (50%) or more of the\n      outstanding shares, or (iii) beneficial ownership of such entity.\n\n      \"You\" (or \"Your\") shall mean an individual or Legal Entity\n      exercising permissions granted by this License.\n\n      \"Source\" form shall mean the preferred form for making modifications,\n      including but not limited to software source code, documentation\n      source, and configuration files.\n\n      \"Object\" form shall mean any form resulting from mechanical\n      transformation or translation of a Source form, including but\n      not limited to compiled object code, generated documentation,\n      and conversions to other media types.\n\n      \"Work\" shall mean the work of authorship, whether in Source or\n      Object form, made available under the License, as indicated by a\n      copyright notice that is included in or attached to the work\n      (an example is provided in the Appendix below).\n\n      \"Derivative Works\" shall mean any work, whether in Source or Object\n      form, that is based on (or derived from) the Work and for which the\n      editorial revisions, annotations, elaborations, or other modifications\n      represent, as a whole, an original work of authorship. For the purposes\n      of this License, Derivative Works shall not include works that remain\n      separable from, or merely link (or bind by name) to the interfaces of,\n      the Work and Derivative Works thereof.\n\n      \"Contribution\" shall mean any work of authorship, including\n      the original version of the Work and any modifications or additions\n      to that Work or Derivative Works thereof, that is intentionally\n      submitted to Licensor for inclusion in the Work by the copyright owner\n      or by an individual or Legal Entity authorized to submit on behalf of\n      the copyright owner. For the purposes of this definition, \"submitted\"\n      means any form of electronic, verbal, or written communication sent\n      to the Licensor or its representatives, including but not limited to\n      communication on electronic mailing lists, source code control systems,\n      and issue tracking systems that are managed by, or on behalf of, the\n      Licensor for the purpose of discussing and improving the Work, but\n      excluding communication that is conspicuously marked or otherwise\n      designated in writing by the copyright owner as \"Not a Contribution.\"\n\n      \"Contributor\" shall mean Licensor and any individual or Legal Entity\n      on behalf of whom a Contribution has been received by Licensor and\n      subsequently incorporated within the Work.\n\n   2. Grant of Copyright License. Subject to the terms and conditions of\n      this License, each Contributor hereby grants to You a perpetual,\n      worldwide, non-exclusive, no-charge, royalty-free, irrevocable\n      copyright license to reproduce, prepare Derivative Works of,\n      publicly display, publicly perform, sublicense, and distribute the\n      Work and such Derivative Works in Source or Object form.\n\n   3. Grant of Patent License. Subject to the terms and conditions of\n      this License, each Contributor hereby grants to You a perpetual,\n      worldwide, non-exclusive, no-charge, royalty-free, irrevocable\n      (except as stated in this section) patent license to make, have made,\n      use, offer to sell, sell, import, and otherwise transfer the Work,\n      where such license applies only to those patent claims licensable\n      by such Contributor that are necessarily infringed by their\n      Contribution(s) alone or by combination of their Contribution(s)\n      with the Work to which such Contribution(s) was submitted. If You\n      institute patent litigation against any entity (including a\n      cross-claim or counterclaim in a lawsuit) alleging that the Work\n      or a Contribution incorporated within the Work constitutes direct\n      or contributory patent infringement, then any patent licenses\n      granted to You under this License for that Work shall terminate\n      as of the date such litigation is filed.\n\n   4. Redistribution. You may reproduce and distribute copies of the\n      Work or Derivative Works thereof in any medium, with or without\n      modifications, and in Source or Object form, provided that You\n      meet the following conditions:\n\n      (a) You must give any other recipients of the Work or\n          Derivative Works a copy of this License; and\n\n      (b) You must cause any modified files to carry prominent notices\n          stating that You changed the files; and\n\n      (c) You must retain, in the Source form of any Derivative Works\n          that You distribute, all copyright, patent, trademark, and\n          attribution notices from the Source form of the Work,\n          excluding those notices that do not pertain to any part of\n          the Derivative Works; and\n\n      (d) If the Work includes a \"NOTICE\" text file as part of its\n          distribution, then any Derivative Works that You distribute must\n          include a readable copy of the attribution notices contained\n          within such NOTICE file, excluding those notices that do not\n          pertain to any part of the Derivative Works, in at least one\n          of the following places: within a NOTICE text file distributed\n          as part of the Derivative Works; within the Source form or\n          documentation, if provided along with the Derivative Works; or,\n          within a display generated by the Derivative Works, if and\n          wherever such third-party notices normally appear. The contents\n          of the NOTICE file are for informational purposes only and\n          do not modify the License. You may add Your own attribution\n          notices within Derivative Works that You distribute, alongside\n          or as an addendum to the NOTICE text from the Work, provided\n          that such additional attribution notices cannot be construed\n          as modifying the License.\n\n      You may add Your own copyright statement to Your modifications and\n      may provide additional or different license terms and conditions\n      for use, reproduction, or distribution of Your modifications, or\n      for any such Derivative Works as a whole, provided Your use,\n      reproduction, and distribution of the Work otherwise complies with\n      the conditions stated in this License.\n\n   5. Submission of Contributions. Unless You explicitly state otherwise,\n      any Contribution intentionally submitted for inclusion in the Work\n      by You to the Licensor shall be under the terms and conditions of\n      this License, without any additional terms or conditions.\n      Notwithstanding the above, nothing herein shall supersede or modify\n      the terms of any separate license agreement you may have executed\n      with Licensor regarding such Contributions.\n\n   6. Trademarks. This License does not grant permission to use the trade\n      names, trademarks, service marks, or product names of the Licensor,\n      except as required for reasonable and customary use in describing the\n      origin of the Work and reproducing the content of the NOTICE file.\n\n   7. Disclaimer of Warranty. Unless required by applicable law or\n      agreed to in writing, Licensor provides the Work (and each\n      Contributor provides its Contributions) on an \"AS IS\" BASIS,\n      WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or\n      implied, including, without limitation, any warranties or conditions\n      of TITLE, NON-INFRINGEMENT, MERCHANTABILITY, or FITNESS FOR A\n      PARTICULAR PURPOSE. You are solely responsible for determining the\n      appropriateness of using or redistributing the Work and assume any\n      risks associated with Your exercise of permissions under this License.\n\n   8. Limitation of Liability. In no event and under no legal theory,\n      whether in tort (including negligence), contract, or otherwise,\n      unless required by applicable law (such as deliberate and grossly\n      negligent acts) or agreed to in writing, shall any Contributor be\n      liable to You for damages, including any direct, indirect, special,\n      incidental, or consequential damages of any character arising as a\n      result of this License or out of the use or inability to use the\n      Work (including but not limited to damages for loss of goodwill,\n      work stoppage, computer failure or malfunction, or any and all\n      other commercial damages or losses), even if such Contributor\n      has been advised of the possibility of such damages.\n\n   9. Accepting Warranty or Additional Liability. While redistributing\n      the Work or Derivative Works thereof, You may choose to offer,\n      and charge a fee for, acceptance of support, warranty, indemnity,\n      or other liability obligations and/or rights consistent with this\n      License. However, in accepting such obligations, You may act only\n      on Your own behalf and on Your sole responsibility, not on behalf\n      of any other Contributor, and only if You agree to indemnify,\n      defend, and hold each Contributor harmless for any liability\n      incurred by, or claims asserted against, such Contributor by reason\n      of yo"
        },
        {
          "name": "akg",
          "type": "commit",
          "content": null
        },
        {
          "name": "build.bat",
          "type": "blob",
          "size": 4.55078125,
          "content": "@rem Copyright 2020 Huawei Technologies Co., Ltd\n@rem\n@rem Licensed under the Apache License, Version 2.0 (the \"License\");\n@rem you may not use this file except in compliance with the License.\n@rem You may obtain a copy of the License at\n@rem\n@rem http://www.apache.org/licenses/LICENSE-2.0\n@rem\n@rem Unless required by applicable law or agreed to in writing, software\n@rem distributed under the License is distributed on an \"AS IS\" BASIS,\n@rem WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n@rem See the License for the specific language governing permissions and\n@rem limitations under the License.\n@rem ============================================================================\n@echo off\n@title mindspore_build\n\nsetlocal EnableDelayedExpansion\n\n@echo off\necho Start build at: %date% %time%\n\nSET BASE_PATH=%CD%\nSET BUILD_PATH=%BASE_PATH%/build\nSET FFMPEG_DLL_PATH=%BASE_PATH%\\build\\mindspore\\ffmpeg_lib\n\nSET threads=8\nSET ENABLE_GITEE=OFF\nSET ENABLE_MSVC=OFF\nset BUILD_TYPE=Release\nset VERSION_STR=''\nset ENABLE_AKG=OFF\nset ENABLE_FFMPEG=ON\nset ENABLE_FFMPEG_DOWNLOAD=OFF\nfor /f \"tokens=1\" %%a in (version.txt) do (set VERSION_STR=%%a)\n\nECHO %2%|FINDSTR \"^[0-9][0-9]*$\"\nIF %errorlevel% == 0 (\n    SET threads=%2%\n)\n\nIF \"%FROM_GITEE%\" == \"1\" (\n    echo \"DownLoad from gitee\"\n    SET ENABLE_GITEE=ON\n)\n\nIF \"%MSLIBS_SERVER%\" == \"tools.mindspore.cn\" (\n    SET ENABLE_FFMPEG_DOWNLOAD=ON\n)\n\nECHO %1%|FINDSTR \"^ms_vs\"\nIF %errorlevel% == 0 (\n    echo \"use msvc compiler\"\n    SET ENABLE_MSVC=ON\n) else (\n    echo \"use mingw compiler\"\n)\n\nIF NOT EXIST \"%BUILD_PATH%\" (\n    md \"build\"\n)\ncd %BUILD_PATH%\nIF NOT EXIST \"%BUILD_PATH%/mindspore\" (\n    md \"mindspore\"\n)\n\ncd %BUILD_PATH%/mindspore\nIF \"%1%\" == \"lite\" (\n    echo \"======Start building MindSpore Lite %VERSION_STR%======\"\n    rd /s /q \"%BASE_PATH%\\output\"\n    (git log -1 | findstr \"^commit\") > %BUILD_PATH%\\.commit_id\n    IF defined VisualStudioVersion (\n        cmake -DMSLITE_MINDDATA_IMPLEMENT=off -DMSLITE_ENABLE_TRAIN=off -DVERSION_STR=%VERSION_STR% ^\n            -DCMAKE_BUILD_TYPE=Release -G \"Ninja\" \"%BASE_PATH%/mindspore/lite\"\n    ) ELSE (\n        cmake -DMSLITE_MINDDATA_IMPLEMENT=off -DMSLITE_ENABLE_TRAIN=off -DVERSION_STR=%VERSION_STR% ^\n            -DCMAKE_BUILD_TYPE=Release -G \"CodeBlocks - MinGW Makefiles\" \"%BASE_PATH%/mindspore/lite\"\n    )\n) ELSE (\n    for /f \"delims=\" %%i in ('powershell.exe -ExecutionPolicy Bypass -Command \"Get-ChildItem HKLM:\\SOFTWARE\\Wow6432Node\\Microsoft\\Windows\\CurrentVersion\\Uninstall | foreach { Get-ItemProperty $_.PsPath } | where { $_.DisplayName -like '*Visual Studio*' -and $_.InstallLocation.Length -gt 0 } | sort InstallDate -Descending | foreach { Join-Path $_.InstallLocation 'VC\\Auxiliary\\Build'}\"') do (call \"%%i\\vcvars64.bat\")\n    SET CMAKE_ARGS=-DENABLE_CPU=ON -DENABLE_MINDDATA=ON -DUSE_GLOG=ON -DENABLE_GITEE=%ENABLE_GITEE%\n    where ccache\n    IF !errorlevel! == 0 (\n        echo \"use ccache to speed up compile\"\n        SET CMAKE_ARGS=!CMAKE_ARGS! -DCMAKE_C_COMPILER_LAUNCHER=ccache -DCMAKE_CXX_COMPILER_LAUNCHER=ccache \n    )\n    IF \"%1%\" == \"ms_vs_gpu\" (\n        echo \"======Start gen VS2019 Project for MS gpu ======\"\n        SET CMAKE_ARGS=!CMAKE_ARGS! -DCMAKE_BUILD_TYPE=Release  -DENABLE_GPU=ON -DGPU_BACKEND_CUDA=ON -DMS_REQUIRE_CUDA_VERSION=11.1 \n    ) ELSE IF \"%1%\" == \"ms_vs_cpu\" (\n        echo \"======Start gen VS2019 Project for MS cpu ======\"\n        SET CMAKE_ARGS=!CMAKE_ARGS! -DCMAKE_BUILD_TYPE=Release\n    ) ELSE IF \"%1%\" == \"ms_vs_cpu_debug\" (\n        echo \"======Start gen VS2019 Project for MS cpu debug======\"\n        SET CMAKE_ARGS=!CMAKE_ARGS! -DCMAKE_BUILD_TYPE=Debug -DDEBUG_MODE=ON\n        set BUILD_TYPE=Debug\n    )\n    IF ON == %ENABLE_FFMPEG% (\n        call %BASE_PATH%\\cmake\\external_libs\\ffmpeg.bat\n        IF errorlevel 1 (\n            echo \"cmake fail.\"\n            call :clean\n            EXIT /b 1\n        )\n    )\n    cmake !CMAKE_ARGS! -G Ninja ../..\n)\n\nIF NOT %errorlevel% == 0 (\n    echo \"cmake fail.\"\n    call :clean\n    EXIT /b 1\n)\n\nIF ON == %ENABLE_MSVC% (\n    cmake --build . --config %BUILD_TYPE% --target package\n) ELSE (\n    cmake --build . --target package -- -j%threads%\n)\n\nIF NOT %errorlevel% == 0 (\n    echo \"build fail.\"\n    call :clean\n    EXIT /b 1\n)\n\ncall :clean\nEXIT /b 0\n\n:clean\n    IF EXIST \"%BASE_PATH%/output\" (\n        cd %BASE_PATH%/output\n        if EXIST \"%BASE_PATH%/output/_CPack_Packages\" (\n             rd /s /q _CPack_Packages\n        )\n    )\n    IF EXIST \"%FFMPEG_DLL_PATH%\" (\n        rd /s /q %FFMPEG_DLL_PATH%\n    )\n    cd %BASE_PATH%\n\n@echo off\nIF EXIST \"%FFMPEG_DLL_PATH%\" (\n        rd /s /q %FFMPEG_DLL_PATH%\n    )\necho End build at: %date% %time%"
        },
        {
          "name": "build.sh",
          "type": "blob",
          "size": 2.9462890625,
          "content": "#!/bin/bash\n# Copyright 2019-2021 Huawei Technologies Co., Ltd\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n# http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n# ============================================================================\n\nset -e\nBASEPATH=$(cd \"$(dirname $0)\"; pwd)\nexport CUDA_PATH=\"\"\nexport BUILD_PATH=\"${BASEPATH}/build/\"\n\nsource ./scripts/build/usage.sh\nsource ./scripts/build/default_options.sh\nsource ./scripts/build/option_proc_debug.sh\nsource ./scripts/build/option_proc_mindspore.sh\nsource ./scripts/build/option_proc_lite.sh\nsource ./scripts/build/process_options.sh\nsource ./scripts/build/parse_device.sh\nsource ./scripts/build/build_mindspore.sh\n\n# check value of input is 'on' or 'off'\n# usage: check_on_off arg_value arg_name\ncheck_on_off()\n{\n  if [[ \"X$1\" != \"Xon\" && \"X$1\" != \"Xoff\" ]]; then\n    echo \"Invalid value $1 for option -$2\"\n    usage\n    exit 1\n  fi\n}\n\nupdate_submodule()\n{\n  git submodule update --init graphengine\n  cd \"${BASEPATH}/graphengine\"\n  GRAPHENGINE_SUBMODULE=\"910/metadef\"\n  git submodule update --init ${GRAPHENGINE_SUBMODULE}\n  cd \"${BASEPATH}\"\n  if [[ \"X$ENABLE_AKG\" = \"Xon\" ]]; then\n    if [[ \"X$ENABLE_D\" == \"Xon\" ]]; then\n      git submodule update --init akg\n    else\n      GIT_LFS_SKIP_SMUDGE=1 git submodule update --init akg\n    fi\n  fi\n}\n\nbuild_exit()\n{\n    echo \"$@\" >&2\n    stty echo\n    exit 1\n}\n\nmake_clean()\n{\n  echo \"enable make clean\"\n  cd \"${BUILD_PATH}/mindspore\"\n  cmake --build . --target clean\n}\n\necho \"---------------- MindSpore: build start ----------------\"\ninit_default_options\nprocess_options \"$@\"\nparse_device\n\nif [[ \"X$COMPILE_LITE\" = \"Xon\" ]]; then\n  export COMPILE_MINDDATA_LITE\n  export ENABLE_VERBOSE\n  export LITE_PLATFORM\n  export LITE_ENABLE_AAR\n  source mindspore/lite/build_lite.sh\nelse\n  mkdir -pv \"${BUILD_PATH}/package/mindspore/lib\"\n  mkdir -pv \"${BUILD_PATH}/package/mindspore/lib/plugin\"\n  update_submodule\n\n  build_mindspore\n\n  if [[ \"X$ENABLE_MAKE_CLEAN\" = \"Xon\" ]]; then\n    make_clean\n  fi\n  if [[ \"X$ENABLE_ACL\" == \"Xon\" ]] && [[ \"X$ENABLE_D\" == \"Xoff\" ]]; then\n      echo \"acl mode, skipping deploy phase\"\n      rm -rf ${BASEPATH}/output/_CPack_Packages/\n  elif [[ \"X$FASTER_BUILD_FOR_PLUGINS\" == \"Xon\" ]]; then\n      echo \"plugin mode, skipping deploy phase\"\n      rm -rf ${BASEPATH}/output/_CPack_Packages/\n  else\n      cp -rf ${BUILD_PATH}/package/mindspore/lib ${BASEPATH}/mindspore/python/mindspore\n      cp -rf ${BUILD_PATH}/package/mindspore/*.so ${BASEPATH}/mindspore/python/mindspore\n  fi\nfi\necho \"---------------- MindSpore: build end   ----------------\"\n"
        },
        {
          "name": "cmake",
          "type": "tree",
          "content": null
        },
        {
          "name": "config",
          "type": "tree",
          "content": null
        },
        {
          "name": "docs",
          "type": "tree",
          "content": null
        },
        {
          "name": "graphengine",
          "type": "commit",
          "content": null
        },
        {
          "name": "include",
          "type": "tree",
          "content": null
        },
        {
          "name": "mindspore",
          "type": "tree",
          "content": null
        },
        {
          "name": "requirements.txt",
          "type": "blob",
          "size": 0.541015625,
          "content": "numpy >= 1.20.0,<2.0.0\nprotobuf >= 3.13.0\nasttokens >= 2.0.4          # asttokens >= 2.0.6 requires six >= 1.12.0\npillow >= 6.2.0\nscipy >= 1.5.4\ndecorator >= 4.4.0\nmatplotlib >= 3.1.3         # for ut test\nopencv-python >= 4.1.2.30   # for ut test\nscikit-learn >= 0.14,<1.3.0 # for st test\npandas >= 1.0.2             # for ut test\npackaging >= 20.0\npycocotools >= 2.0.2        # for st test\ntables >= 3.6.1             # for st test\neasydict >= 1.9             # for st test\nonnxruntime >= 1.6.0        # for st test\npsutil >= 5.7.0\nastunparse >= 1.6.3\n"
        },
        {
          "name": "scripts",
          "type": "tree",
          "content": null
        },
        {
          "name": "setup.py",
          "type": "blob",
          "size": 6.7880859375,
          "content": "#!/usr/bin/env python3\n# encoding: utf-8\n# Copyright 2020 Huawei Technologies Co., Ltd\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n# http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n# ============================================================================\n\"\"\"setup package.\"\"\"\nimport os\nimport stat\nimport platform\n\nfrom setuptools import setup, find_packages\nfrom setuptools.command.egg_info import egg_info\nfrom setuptools.command.build_py import build_py\n\nbackend_policy = os.getenv('BACKEND_POLICY')\ncommit_id = os.getenv('COMMIT_ID').replace(\"\\n\", \"\")\npackage_name = os.getenv('MS_PACKAGE_NAME').replace(\"\\n\", \"\")\nbuild_path = os.getenv('BUILD_PATH')\n\npwd = os.path.dirname(os.path.realpath(__file__))\npkg_dir = os.path.join(build_path, 'package')\n\n\ndef _read_file(filename):\n    with open(os.path.join(pwd, filename), encoding='UTF-8') as f:\n        return f.read()\n\n\nversion = _read_file('version.txt').replace(\"\\n\", \"\")\nreadme = _read_file('README.md')\n\n\ndef _write_version(file):\n    file.write(\"__version__ = '{}'\\n\".format(version))\n\n\ndef _write_config(file):\n    file.write(\"__backend__ = '{}'\\n\".format(backend_policy))\n\n\ndef _write_commit_file(file):\n    file.write(\"__commit_id__ = '{}'\\n\".format(commit_id))\n\n\ndef _write_package_name(file):\n    file.write(\"__package_name__ = '{}'\\n\".format(package_name))\n\n\ndef build_dependencies():\n    \"\"\"generate python file\"\"\"\n    version_file = os.path.join(pkg_dir, 'mindspore', 'version.py')\n    with open(version_file, 'w') as f:\n        _write_version(f)\n\n    version_file = os.path.join(pwd, 'mindspore/python/mindspore', 'version.py')\n    with open(version_file, 'w') as f:\n        _write_version(f)\n\n    config_file = os.path.join(pkg_dir, 'mindspore', 'default_config.py')\n    with open(config_file, 'w') as f:\n        _write_config(f)\n\n    config_file = os.path.join(pwd, 'mindspore/python/mindspore', 'default_config.py')\n    with open(config_file, 'w') as f:\n        _write_config(f)\n\n    package_info = os.path.join(pkg_dir, 'mindspore', 'default_config.py')\n    with open(package_info, 'a') as f:\n        _write_package_name(f)\n\n    package_info = os.path.join(pwd, 'mindspore/python/mindspore', 'default_config.py')\n    with open(package_info, 'a') as f:\n        _write_package_name(f)\n\n    commit_file = os.path.join(pkg_dir, 'mindspore', '.commit_id')\n    with open(commit_file, 'w') as f:\n        _write_commit_file(f)\n\n    commit_file = os.path.join(pwd, 'mindspore/python/mindspore', '.commit_id')\n    with open(commit_file, 'w') as f:\n        _write_commit_file(f)\n\n\nbuild_dependencies()\n\nrequired_package = [\n    'numpy >= 1.20.0,<2.0.0',\n    'protobuf >= 3.13.0',\n    'asttokens >= 2.0.4',\n    'pillow >= 6.2.0',\n    'scipy >= 1.5.4',\n    'packaging >= 20.0',\n    'psutil >= 5.6.1',\n    'astunparse >= 1.6.3'\n]\n\npackage_data = {\n    '': [\n        '*.so*',\n        '*.pyd',\n        '*.dll',\n        '*.pdb',\n        'bin/*',\n        'lib/plugin/*',\n        'lib/plugin/*/*',\n        'lib/plugin/*/*/*',\n        'lib/plugin/*/*/*/*',\n        'lib/plugin/*/*/*/*/*',\n        'lib/plugin/*/*/*/*/*/*',\n        'lib/plugin/*/*/*/*/*/*/*',\n        'lib/plugin/*/*/*/*/*/*/*/*',\n        'lib/plugin/*/*/*/*/*/*/*/*/*',\n        'lib/plugin/*/*/*/*/*/*/*/*/*/*',\n        'lib/*.so*',\n        'lib/*.a',\n        'lib/*.dylib*',\n        '.commit_id',\n        'config/*',\n        'include/*',\n        'include/*/*',\n        'include/*/*/*',\n        'include/*/*/*/*',\n        'Third_Party_Open_Source_Software_Notice'\n    ]\n}\n\n\ndef update_permissions(path):\n    \"\"\"\n    Update permissions.\n\n    Args:\n        path (str): Target directory path.\n    \"\"\"\n    if platform.system() == \"Windows\":\n        return\n\n    for dirpath, dirnames, filenames in os.walk(path):\n        for dirname in dirnames:\n            dir_fullpath = os.path.join(dirpath, dirname)\n            os.chmod(dir_fullpath, stat.S_IREAD | stat.S_IWRITE |\n                     stat.S_IEXEC | stat.S_IRGRP | stat.S_IXGRP)\n        for filename in filenames:\n            file_fullpath = os.path.join(dirpath, filename)\n            os.chmod(file_fullpath, stat.S_IREAD)\n\n\nclass EggInfo(egg_info):\n    \"\"\"Egg info.\"\"\"\n\n    def run(self):\n        super().run()\n        egg_info_dir = os.path.join(pkg_dir, 'mindspore.egg-info')\n        update_permissions(egg_info_dir)\n\n\nclass BuildPy(build_py):\n    \"\"\"BuildPy.\"\"\"\n\n    def run(self):\n        super().run()\n        mindspore_dir = os.path.join(pkg_dir, 'build', 'lib', 'mindspore')\n        update_permissions(mindspore_dir)\n        mindspore_dir = os.path.join(pkg_dir, 'build', 'lib', 'mindspore', '_akg')\n        update_permissions(mindspore_dir)\n\n\nsetup(\n    name=package_name,\n    version=version,\n    author='The MindSpore Authors',\n    author_email='contact@mindspore.cn',\n    url='https://www.mindspore.cn',\n    download_url='https://github.com/mindspore-ai/mindspore/tags',\n    project_urls={\n        'Sources': 'https://github.com/mindspore-ai/mindspore',\n        'Issue Tracker': 'https://github.com/mindspore-ai/mindspore/issues',\n    },\n    description='MindSpore is a new open source deep learning training/inference '\n                'framework that could be used for mobile, edge and cloud scenarios.',\n    long_description=readme,\n    long_description_content_type=\"text/markdown\",\n    packages=find_packages(),\n    package_data=package_data,\n    include_package_data=True,\n    cmdclass={\n        'egg_info': EggInfo,\n        'build_py': BuildPy,\n    },\n    entry_points={\n        'console_scripts': [\n            'cache_admin=mindspore.dataset.engine.cache_admin:main',\n            'msrun=mindspore.parallel.cluster.run:main'\n        ],\n    },\n    python_requires='>=3.7',\n    install_requires=required_package,\n    classifiers=[\n        'Development Status :: 4 - Beta',\n        'Environment :: Console',\n        'Intended Audience :: Science/Research',\n        'Intended Audience :: Developers',\n        'License :: OSI Approved :: Apache Software License',\n        'Programming Language :: Python :: 3 :: Only',\n        'Programming Language :: Python :: 3.7',\n        'Programming Language :: Python :: 3.8',\n        'Programming Language :: C++',\n        'Topic :: Scientific/Engineering',\n        'Topic :: Scientific/Engineering :: Artificial Intelligence',\n        'Topic :: Software Development',\n        'Topic :: Software Development :: Libraries',\n        'Topic :: Software Development :: Libraries :: Python Modules',\n    ],\n    license='Apache 2.0',\n    keywords='mindspore machine learning',\n)\n"
        },
        {
          "name": "tests",
          "type": "tree",
          "content": null
        },
        {
          "name": "third_party",
          "type": "tree",
          "content": null
        },
        {
          "name": "version.txt",
          "type": "blob",
          "size": 0.0078125,
          "content": "2.4.0rc1"
        }
      ]
    }
  ]
}