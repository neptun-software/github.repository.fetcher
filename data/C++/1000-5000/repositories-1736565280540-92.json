{
  "metadata": {
    "timestamp": 1736565280540,
    "page": 92,
    "hasNextPage": true,
    "endCursor": "Y3Vyc29yOjEwMA==",
    "completionStatus": "IN_PROGRESS"
  },
  "repositories": [
    {
      "nameWithOwner": "rapidsai/cuml",
      "stars": 4336,
      "defaultBranch": "branch-25.02",
      "files": [
        {
          "name": ".devcontainer",
          "type": "tree",
          "content": null
        },
        {
          "name": ".github",
          "type": "tree",
          "content": null
        },
        {
          "name": ".gitignore",
          "type": "blob",
          "size": 0.9658203125,
          "content": "## python raft symlink\npython/cuml/raft\n\n## common\n__pycache__\n*.pyc\n*~\n\\#*\n.#*\n*.o\n*.so\n*.dylib\n.cache\n.coverage*\n.vscode\n*.swp\n*.pytest_cache\nhtmlcov\nbuild/\nbuild_prims/\ncmake-build*\ncuml.egg-info/\ndist/\npython/cuml/**/*.cpp\npython/_external_repositories\npython/record.txt\nlog\n.ipynb_checkpoints\n.DS_Store\ndask-worker-space/\ntmp/\n.hypothesis\nwheels/\nwheelhouse/\n_skbuild/\n\n## files pickled in notebook when ran during python docstring generation\ndocs/source/*.model\ndocs/source/*.pkl\ndocs/source/*.tl\n\n## eclipse\n.project\n.cproject\n.settings\n.ptp-sync-folder\n\n## Pycharm\n.idea\n\n## ccls\n.ccls-cache\n.ccls\n\n## profiling\n*.qdrep\n*.qdrep.cache\n*.qdstrm\n*.nvprof\n\n## doxygen build check inside ci/checks/style.sh\ndoxygen_check/\n\n## Doxygen\ncpp/html\ncpp/Doxyfile\n\n# clang tooling\ncompile_commands.json\n.clangd/\n\n# generally prefer 'pyproject.toml' to 'pytest.ini' for pytest options\n# ref: https://github.com/rapidsai/cuml/pull/6201\npytest.ini\n!python/cuml/cuml/benchmark/automated/pytest.ini\n"
        },
        {
          "name": ".pre-commit-config.yaml",
          "type": "blob",
          "size": 2.728515625,
          "content": "---\n# Copyright (c) 2023, NVIDIA CORPORATION.\n\nrepos:\n    - repo: https://github.com/psf/black\n      rev: 22.10.0\n      hooks:\n          - id: black\n            files: python/.*\n            args: [--config, python/cuml/pyproject.toml]\n    - repo: https://github.com/PyCQA/flake8\n      rev: 7.1.1\n      hooks:\n          - id: flake8\n            args: [--config=python/cuml/.flake8]\n            files: python/.*$\n            types: [file]\n            types_or: [python, cython]\n            exclude: thirdparty\n            additional_dependencies: [flake8-force]\n    - repo: https://github.com/MarcoGorelli/cython-lint\n      rev: v0.15.0\n      hooks:\n          - id: cython-lint\n    - repo: https://github.com/pre-commit/mirrors-clang-format\n      rev: v16.0.6\n      hooks:\n          - id: clang-format\n            types_or: [c, c++, cuda]\n            args: [\"-fallback-style=none\", \"-style=file\", \"-i\"]\n    - repo: https://github.com/codespell-project/codespell\n      rev: v2.2.2\n      hooks:\n          - id: codespell\n            additional_dependencies: [tomli]\n            args: [\"--toml\", \"pyproject.toml\"]\n            exclude: (?x)^(.*stemmer.*|.*stop_words.*|^CHANGELOG.md$)\n    - repo: local\n      hooks:\n          - id: no-deprecationwarning\n            name: no-deprecationwarning\n            description: 'Enforce that DeprecationWarning is not introduced (use FutureWarning instead)'\n            entry: '(category=|\\s)DeprecationWarning[,)]'\n            language: pygrep\n            types_or: [python, cython]\n          - id: include-check\n            name: include-check\n            entry: python cpp/scripts/include_checker.py\n            args:\n                - cpp/bench\n                - cpp/comms/mpi/include\n                - cpp/comms/mpi/src\n                - cpp/comms/std/include\n                - cpp/comms/std/src\n                - cpp/include\n                - cpp/examples\n                - cpp/src\n                - cpp/src_prims\n                - cpp/test\n            pass_filenames: false\n            language: python\n    - repo: https://github.com/rapidsai/pre-commit-hooks\n      rev: v0.4.0\n      hooks:\n        - id: verify-copyright\n          files: |\n            (?x)\n                [.](cmake|cpp|cu|cuh|h|hpp|sh|pxd|py|pyx)$|\n                CMakeLists[.]txt$|\n                CMakeLists_standalone[.]txt$|\n                [.]flake8[.]cython$|\n                meta[.]yaml$\n          exclude: |\n            (?x)\n                cpp/src/tsne/cannylab/bh[.]cu$|\n                python/cuml/cuml/_thirdparty\n        - id: verify-alpha-spec\n    - repo: https://github.com/rapidsai/dependency-file-generator\n      rev: v1.17.0\n      hooks:\n          - id: rapids-dependency-file-generator\n            args: [\"--clean\"]\n\ndefault_language_version:\n    python: python3\n"
        },
        {
          "name": "BUILD.md",
          "type": "blob",
          "size": 10.7353515625,
          "content": "# cuML Build From Source Guide\n\n## Setting Up Your Build Environment\n\nTo install cuML from source, ensure the following dependencies are met:\n\n1. [cuDF](https://github.com/rapidsai/cudf) (Same as cuML Version)\n2. zlib\n3. cmake (>= 3.26.4)\n4. CUDA (>= 11+)\n5. Cython (>= 0.29)\n6. gcc (>= 9.0)\n7. BLAS - Any BLAS compatible with cmake's [FindBLAS](https://cmake.org/cmake/help/v3.14/module/FindBLAS.html). Note that the blas has to be installed to the same folder system as cmake, for example if using conda installed cmake, the blas implementation should also be installed in the conda environment.\n8. clang-format (= 16.0.6) - enforces uniform C++ coding style; required to build cuML from source. The packages `clang=16` and `clang-tools=16` from the conda-forge channel should be sufficient, if you are on conda. If not using conda, install the right version using your OS package manager.\n9. NCCL (>=2.4)\n10. UCX [optional] (>= 1.7) - enables point-to-point messaging in the cuML standard communicator. This is necessary for many multi-node multi-GPU cuML algorithms to function.\n\nIt is recommended to use conda for environment/package management. If doing so, development environment .yaml files are located in `conda/environments/all_*.yaml`. These files contains most of the dependencies mentioned above (notable exceptions are `gcc` and `zlib`). To create a development environment named `cuml_dev`, you can use the follow commands:\n\n```bash\nconda create -n cuml_dev python=3.12\nconda env update -n cuml_dev --file=conda/environments/all_cuda-118_arch-x86_64.yaml\nconda activate cuml_dev\n```\n\n## Installing from Source:\n\n### Recommended process\n\nAs a convenience, a `build.sh` script is provided which can be used to execute the same build commands above.  Note that the libraries will be installed to the location set in `$INSTALL_PREFIX` if set (i.e. `export INSTALL_PREFIX=/install/path`), otherwise to `$CONDA_PREFIX`.\n```bash\n$ ./build.sh                           # build the cuML libraries, tests, and python package, then\n                                       # install them to $INSTALL_PREFIX if set, otherwise $CONDA_PREFIX\n```\nFor workflows that involve frequent switching among branches or between debug and release builds, it is recommended that you install [ccache](https://ccache.dev/) and make use of it by passing the `--ccache` flag to `build.sh`.\n\nTo build individual components, specify them as arguments to `build.sh`\n```bash\n$ ./build.sh libcuml                   # build and install the cuML C++ and C-wrapper libraries\n$ ./build.sh cuml                      # build and install the cuML python package\n$ ./build.sh prims                     # build the ml-prims tests\n$ ./build.sh bench                     # build the cuML c++ benchmark\n$ ./build.sh prims-bench               # build the ml-prims c++ benchmark\n```\n\nOther `build.sh` options:\n```bash\n$ ./build.sh clean                     # remove any prior build artifacts and configuration (start over)\n$ ./build.sh libcuml -v                # build and install libcuml with verbose output\n$ ./build.sh libcuml -g                # build and install libcuml for debug\n$ PARALLEL_LEVEL=8 ./build.sh libcuml  # build and install libcuml limiting parallel build jobs to 8 (ninja -j8)\n$ ./build.sh libcuml -n                # build libcuml but do not install\n$ ./build.sh prims --allgpuarch        # build the ML prims tests for all supported GPU architectures\n$ ./build.sh cuml --singlegpu          # build the cuML python package without MNMG algorithms\n$ ./build.sh --ccache                  # use ccache to cache compilations, speeding up subsequent builds\n```\n\nBy default, Ninja is used as the cmake generator. To override this and use (e.g.) `make`, define the `CMAKE_GENERATOR` environment variable accordingly:\n```bash\nCMAKE_GENERATOR='Unix Makefiles' ./build.sh\n```\n\nTo run the C++ unit tests (optional), from the repo root:\n\n```bash\n$ cd cpp/build\n$ ./test/ml # Single GPU algorithm tests\n$ ./test/ml_mg # Multi GPU algorithm tests, if --singlegpu was not used\n$ ./test/prims # ML Primitive function tests\n```\n\nIf you want a list of the available C++ tests:\n```bash\n$ ./test/ml --gtest_list_tests # Single GPU algorithm tests\n$ ./test/ml_mg --gtest_list_tests # Multi GPU algorithm tests\n$ ./test/prims --gtest_list_tests # ML Primitive function tests\n```\n\n\nTo run all Python tests, including multiGPU algorithms, from the repo root:\n```bash\n$ cd python\n$ pytest -v\n```\n\nIf only the single GPU algos want to be run, then:\n\n```bash\n$ pytest --ignore=cuml/tests/dask --ignore=cuml/tests/test_nccl.py\n```\n\nIf you want a list of the available Python tests:\n```bash\n$ pytest cuML/tests --collect-only\n```\n\n### Manual Process\n\nOnce dependencies are present, follow the steps below:\n\n1. Clone the repository.\n```bash\n$ git clone https://github.com/rapidsai/cuml.git\n```\n\n2. Build and install `libcuml++` (C++/CUDA library containing the cuML algorithms), starting from the repository root folder:\n```bash\n$ cd cpp\n$ mkdir build && cd build\n$ export CUDA_BIN_PATH=$CUDA_HOME # (optional env variable if cuda binary is not in the PATH. Default CUDA_HOME=/path/to/cuda/)\n$ cmake ..\n```\n\nIf using a conda environment (recommended), then cmake can be configured appropriately for `libcuml++` via:\n\n```bash\n$ cmake .. -DCMAKE_INSTALL_PREFIX=$CONDA_PREFIX\n```\n\nNote: The following warning message is dependent upon the version of cmake and the `CMAKE_INSTALL_PREFIX` used. If this warning is displayed, the build should still run successfully. We are currently working to resolve this open issue. You can silence this warning by adding `-DCMAKE_IGNORE_PATH=$CONDA_PREFIX/lib` to your `cmake` command.\n```\nCannot generate a safe runtime search path for target ml_test because files\nin some directories may conflict with libraries in implicit directories:\n```\n\nThe configuration script will print the BLAS found on the search path. If the version found does not match the version intended, use the flag `-DBLAS_LIBRARIES=/path/to/blas.so` with the `cmake` command to force your own version.\n\nIf using conda and a conda installed cmake, the `openblas` conda package is recommended and can be explicitly specified for `blas` and `lapack`:\n\n```bash\ncmake .. -DCMAKE_INSTALL_PREFIX=$CONDA_PREFIX -DBLAS_LIBRARIES=$CONDA_PREFIX/lib/libopenblas.so\n```\n\nAdditionally, to reduce compile times, you can specify a GPU compute capability to compile for, for example for Volta GPUs:\n\n```bash\n$ cmake .. -DCMAKE_INSTALL_PREFIX=$CONDA_PREFIX -DGPU_ARCHS=\"70\"\n```\n\nYou may also wish to make use of `ccache` to reduce build times when switching among branches or between debug and release builds:\n\n```bash\n$ cmake .. -DUSE_CCACHE=ON\n```\n\nThere are many options to configure the build process, see the [customizing build section](#libcuml-&-libcumlc++).\n\n3. Build `libcuml++` and `libcuml`:\n\n```bash\n$ make -j\n$ make install\n```\n\nTo run tests (optional):\n```bash\n$ ./test/ml # Single GPU algorithm tests\n$ ./test/ml_mg # Multi GPU algorithm tests\n$ ./test/prims # ML Primitive function tests\n```\n\nIf you want a list of the available tests:\n```bash\n$ ./test/ml --gtest_list_tests # Single GPU algorithm tests\n$ ./test/ml_mg --gtest_list_tests # Multi GPU algorithm tests\n$ ./test/prims --gtest_list_tests # ML Primitive function tests\n```\n\nTo run cuML c++ benchmarks (optional):\n```bash\n$ ./bench/sg_benchmark  # Single GPU benchmarks\n```\nRefer to `--help` option to know more on its usage\n\nTo run ml-prims C++ benchmarks (optional):\n```bash\n$ ./bench/prims_benchmark  # ml-prims benchmarks\n```\nRefer to `--help` option to know more on its uage\n\nTo build doxygen docs for all C/C++ source files\n```bash\n$ make doc\n```\n\n5. Build the `cuml` python package:\n\n```bash\n$ cd ../../python\n$ python setup.py build_ext --inplace\n```\n\nTo run Python tests (optional):\n\n```bash\n$ pytest -v\n```\n\n\nIf only the single GPU algos want to be run, then:\n\n```bash\n$ pytest --ignore=cuml/tests/dask --ignore=cuml/tests/test_nccl.py\n```\n\n\nIf you want a list of the available tests:\n```bash\n$ pytest cuML/tests --collect-only\n```\n\n5. Finally, install the Python package to your Python path:\n\n```bash\n$ python setup.py install\n```\n\n### Custom Build Options\n\n#### libcuml & libcuml++\n\ncuML's cmake has the following configurable flags available:\n\n| Flag | Possible Values | Default Value | Behavior |\n| --- | --- | --- | --- |\n| BLAS_LIBRARIES | path/to/blas_lib | \"\" | Optional variable allowing to manually specify location of BLAS library. |\n| BUILD_CUML_CPP_LIBRARY | [ON, OFF]  | ON  | Enable/disable building libcuml++ shared library. Setting this variable to `OFF` sets the variables BUILD_CUML_C_LIBRARY, BUILD_CUML_TESTS, BUILD_CUML_MG_TESTS and BUILD_CUML_EXAMPLES to `OFF` |\n| BUILD_CUML_C_LIBRARY | [ON, OFF]  | ON  | Enable/disable building libcuml shared library. Setting this variable to `ON` will set the variable BUILD_CUML_CPP_LIBRARY to `ON` |\n| BUILD_CUML_STD_COMMS | [ON, OFF] | ON | Enable/disable building cuML NCCL+UCX communicator for running multi-node multi-GPU algorithms. Note that UCX support can also be enabled/disabled (see below). Note that BUILD_CUML_STD_COMMS and BUILD_CUML_MPI_COMMS are not mutually exclusive and can both be installed simultaneously. |\n| WITH_UCX | [ON, OFF] | OFF | Enable/disable UCX support for the standard cuML communicator. Algorithms requiring point-to-point messaging will not work when this is disabled. This has no effect on the MPI communicator. |\n| BUILD_CUML_MPI_COMMS | [ON, OFF] | OFF | Enable/disable building cuML MPI+NCCL communicator for running multi-node multi-GPU C++ tests. Note that BUILD_CUML_STD_COMMS and BUILD_CUML_MPI_COMMS are not mutually exclusive, and can both be installed simultaneously. |\n| BUILD_CUML_TESTS | [ON, OFF]  | ON  |  Enable/disable building cuML algorithm test executable `ml_test`.  |\n| BUILD_CUML_MG_TESTS | [ON, OFF]  | ON  |  Enable/disable building cuML algorithm test executable `ml_mg_test`. |\n| BUILD_PRIMS_TESTS | [ON, OFF]  | ON  | Enable/disable building cuML algorithm test executable `prims_test`.  |\n| BUILD_CUML_EXAMPLES | [ON, OFF]  | ON  | Enable/disable building cuML C++ API usage examples.  |\n| BUILD_CUML_BENCH | [ON, OFF] | ON | Enable/disable building of cuML C++ benchark.  |\n| CMAKE_CXX11_ABI | [ON, OFF]  | ON  | Enable/disable the GLIBCXX11 ABI  |\n| DETECT_CONDA_ENV | [ON, OFF] | ON | Use detection of conda environment for dependencies. If set to ON, and no value for CMAKE_INSTALL_PREFIX is passed, then it'll assign it to $CONDA_PREFIX (to install in the active environment).  |\n| DISABLE_OPENMP | [ON, OFF]  | OFF  | Set to `ON` to disable OpenMP  |\n| GPU_ARCHS |  List of GPU architectures, semicolon-separated | 60;70;75  | List of GPU architectures that all artifacts are compiled for.  |\n| KERNEL_INFO | [ON, OFF]  | OFF  | Enable/disable kernel resource usage info in nvcc. |\n| LINE_INFO | [ON, OFF]  | OFF  | Enable/disable lineinfo in nvcc.  |\n| NVTX | [ON, OFF]  | OFF  | Enable/disable nvtx markers in libcuml++.  |\n"
        },
        {
          "name": "CHANGELOG.md",
          "type": "blob",
          "size": 226.6904296875,
          "content": "# cuml 24.12.00 (11 Dec 2024)\n\n## 🚨 Breaking Changes\n\n- Forward merge Branch 24.10 into 24.12 ([#6106](https://github.com/rapidsai/cuml/pull/6106)) [@divyegala](https://github.com/divyegala)\n\n## 🐛 Bug Fixes\n\n- Fix `scikit-learn` version specifier ([#6158](https://github.com/rapidsai/cuml/pull/6158)) [@trxcllnt](https://github.com/trxcllnt)\n- Correctly handle missing categorical data in experimental FIL ([#6132](https://github.com/rapidsai/cuml/pull/6132)) [@wphicks](https://github.com/wphicks)\n- Put a ceiling on cuda-python ([#6131](https://github.com/rapidsai/cuml/pull/6131)) [@bdice](https://github.com/bdice)\n- Don&#39;t presume pointers are mutually exclusive for device/host. ([#6128](https://github.com/rapidsai/cuml/pull/6128)) [@robertmaynard](https://github.com/robertmaynard)\n- cuml SINGLEGPU now tells cuvs to not build with nccl/mg support ([#6127](https://github.com/rapidsai/cuml/pull/6127)) [@robertmaynard](https://github.com/robertmaynard)\n- Remove type from pickle header for CumlArray ([#6120](https://github.com/rapidsai/cuml/pull/6120)) [@wphicks](https://github.com/wphicks)\n- Forward merge Branch 24.10 into 24.12 ([#6106](https://github.com/rapidsai/cuml/pull/6106)) [@divyegala](https://github.com/divyegala)\n- Fix Dask estimators serialization prior to training ([#6065](https://github.com/rapidsai/cuml/pull/6065)) [@viclafargue](https://github.com/viclafargue)\n\n## 🚀 New Features\n\n- Enable HDBSCAN `gpu` training and `cpu` inference ([#6108](https://github.com/rapidsai/cuml/pull/6108)) [@divyegala](https://github.com/divyegala)\n\n## 🛠️ Improvements\n\n- Update FIL tests to use XGBoost UBJSON instead of binary ([#6153](https://github.com/rapidsai/cuml/pull/6153)) [@hcho3](https://github.com/hcho3)\n- Use sparse knn / distances from cuvs ([#6143](https://github.com/rapidsai/cuml/pull/6143)) [@benfred](https://github.com/benfred)\n- Ensure MG to have the same number of allreduce calls in mean_stddev for sparse matrix to avoid hanging ([#6141](https://github.com/rapidsai/cuml/pull/6141)) [@lijinf2](https://github.com/lijinf2)\n- Stop excluding cutlass from symbol exclusion check ([#6140](https://github.com/rapidsai/cuml/pull/6140)) [@vyasr](https://github.com/vyasr)\n- Optimize MG variance calculation for dataset standardization for logistic regression ([#6138](https://github.com/rapidsai/cuml/pull/6138)) [@lijinf2](https://github.com/lijinf2)\n- enforce wheel size limits, README formatting in CI ([#6136](https://github.com/rapidsai/cuml/pull/6136)) [@jameslamb](https://github.com/jameslamb)\n- Experimental command line interface UX ([#6135](https://github.com/rapidsai/cuml/pull/6135)) [@dantegd](https://github.com/dantegd)\n- add telemetry ([#6126](https://github.com/rapidsai/cuml/pull/6126)) [@msarahan](https://github.com/msarahan)\n- Make cuVS optional if CUML_ALGORITHMS is set ([#6125](https://github.com/rapidsai/cuml/pull/6125)) [@hcho3](https://github.com/hcho3)\n- devcontainer: replace `VAULT_HOST` with `AWS_ROLE_ARN` ([#6118](https://github.com/rapidsai/cuml/pull/6118)) [@jjacobelli](https://github.com/jjacobelli)\n- print sccache stats in builds ([#6111](https://github.com/rapidsai/cuml/pull/6111)) [@jameslamb](https://github.com/jameslamb)\n- fix version in Doxygen docs ([#6104](https://github.com/rapidsai/cuml/pull/6104)) [@jameslamb](https://github.com/jameslamb)\n- make conda installs in CI stricter ([#6103](https://github.com/rapidsai/cuml/pull/6103)) [@jameslamb](https://github.com/jameslamb)\n- Make `get_param_names` a class method on single GPU estimators to match Scikit-learn closer ([#6101](https://github.com/rapidsai/cuml/pull/6101)) [@dantegd](https://github.com/dantegd)\n- Prune workflows based on changed files ([#6094](https://github.com/rapidsai/cuml/pull/6094)) [@KyleFromNVIDIA](https://github.com/KyleFromNVIDIA)\n- Update all rmm imports to use pylibrmm/librmm ([#6084](https://github.com/rapidsai/cuml/pull/6084)) [@Matt711](https://github.com/Matt711)\n- Merge branch 24.10 into branch 24.12 ([#6083](https://github.com/rapidsai/cuml/pull/6083)) [@jameslamb](https://github.com/jameslamb)\n\n# cuml 24.10.00 (9 Oct 2024)\n\n## 🚨 Breaking Changes\n\n- Remove old dask-glm based logistic regression ([#6028](https://github.com/rapidsai/cuml/pull/6028)) [@dantegd](https://github.com/dantegd)\n\n## 🐛 Bug Fixes\n\n- Fix train_test_split for string columns ([#6088](https://github.com/rapidsai/cuml/pull/6088)) [@dantegd](https://github.com/dantegd)\n- Stop shadowing free function ([#6076](https://github.com/rapidsai/cuml/pull/6076)) [@vyasr](https://github.com/vyasr)\n- Set default values for conftest options. ([#6067](https://github.com/rapidsai/cuml/pull/6067)) [@bdice](https://github.com/bdice)\n- Add license file to conda packages ([#6061](https://github.com/rapidsai/cuml/pull/6061)) [@raydouglass](https://github.com/raydouglass)\n- Fix np.NAN to np.nan. ([#6056](https://github.com/rapidsai/cuml/pull/6056)) [@bdice](https://github.com/bdice)\n- Reenable `pytest cuml-dask` for CUDA 12.5 wheel CI tests ([#6051](https://github.com/rapidsai/cuml/pull/6051)) [@divyegala](https://github.com/divyegala)\n- Fix for `simplicial_set_embedding` ([#6043](https://github.com/rapidsai/cuml/pull/6043)) [@viclafargue](https://github.com/viclafargue)\n- MAINT: Allow for error message to contain ``np.float32(1.0)`` ([#6030](https://github.com/rapidsai/cuml/pull/6030)) [@seberg](https://github.com/seberg)\n- Stop exporting fill_k kernel as that causes ODR violations ([#6021](https://github.com/rapidsai/cuml/pull/6021)) [@robertmaynard](https://github.com/robertmaynard)\n- Avoid cudf column APIs after cudf.Series disallows column inputs ([#6019](https://github.com/rapidsai/cuml/pull/6019)) [@mroeschke](https://github.com/mroeschke)\n- Use HDBSCAN package pin to `0.8.38` ([#5906](https://github.com/rapidsai/cuml/pull/5906)) [@divyegala](https://github.com/divyegala)\n\n## 📖 Documentation\n\n- Update UMAP doc ([#6064](https://github.com/rapidsai/cuml/pull/6064)) [@viclafargue](https://github.com/viclafargue)\n- Update README in experimental FIL ([#6052](https://github.com/rapidsai/cuml/pull/6052)) [@hcho3](https://github.com/hcho3)\n- add docs for simplicial_set ([#6042](https://github.com/rapidsai/cuml/pull/6042)) [@Intron7](https://github.com/Intron7)\n\n## 🚀 New Features\n\n- TSNE CPU/GPU Interop ([#6063](https://github.com/rapidsai/cuml/pull/6063)) [@divyegala](https://github.com/divyegala)\n- Enable GPU `fit` and CPU `transform` in UMAP ([#6032](https://github.com/rapidsai/cuml/pull/6032)) [@divyegala](https://github.com/divyegala)\n\n## 🛠️ Improvements\n\n- Migrate to use cuVS for vector search ([#6085](https://github.com/rapidsai/cuml/pull/6085)) [@benfred](https://github.com/benfred)\n- Support all-zeroes feature vectors for MG sparse logistic regression ([#6082](https://github.com/rapidsai/cuml/pull/6082)) [@lijinf2](https://github.com/lijinf2)\n- Update update-version.sh to use packaging lib ([#6081](https://github.com/rapidsai/cuml/pull/6081)) [@AyodeAwe](https://github.com/AyodeAwe)\n- Use CI workflow branch &#39;branch-24.10&#39; again ([#6072](https://github.com/rapidsai/cuml/pull/6072)) [@jameslamb](https://github.com/jameslamb)\n- Update fmt (to 11.0.2) and spdlog (to 1.14.1), add those libraries to libcuml conda host dependencies ([#6071](https://github.com/rapidsai/cuml/pull/6071)) [@jameslamb](https://github.com/jameslamb)\n- Update flake8 to 7.1.1. ([#6070](https://github.com/rapidsai/cuml/pull/6070)) [@bdice](https://github.com/bdice)\n- Add support for Python 3.12, update to umap-learn==0.5.6 ([#6060](https://github.com/rapidsai/cuml/pull/6060)) [@jameslamb](https://github.com/jameslamb)\n- Fix compiler warning about signed vs unsigned ints ([#6053](https://github.com/rapidsai/cuml/pull/6053)) [@hcho3](https://github.com/hcho3)\n- Update rapidsai/pre-commit-hooks ([#6048](https://github.com/rapidsai/cuml/pull/6048)) [@KyleFromNVIDIA](https://github.com/KyleFromNVIDIA)\n- Drop Python 3.9 support ([#6040](https://github.com/rapidsai/cuml/pull/6040)) [@jameslamb](https://github.com/jameslamb)\n- Add use_cuda_wheels matrix entry ([#6038](https://github.com/rapidsai/cuml/pull/6038)) [@KyleFromNVIDIA](https://github.com/KyleFromNVIDIA)\n- Switch debug build to RelWithDebInfo ([#6033](https://github.com/rapidsai/cuml/pull/6033)) [@rongou](https://github.com/rongou)\n- Remove NumPy &lt;2 pin ([#6031](https://github.com/rapidsai/cuml/pull/6031)) [@seberg](https://github.com/seberg)\n- Remove old dask-glm based logistic regression ([#6028](https://github.com/rapidsai/cuml/pull/6028)) [@dantegd](https://github.com/dantegd)\n- [FEA] UMAP API for building with batched NN Descent ([#6022](https://github.com/rapidsai/cuml/pull/6022)) [@jinsolp](https://github.com/jinsolp)\n- Enabling CPU/GPU interop for SVM, DBSCAN and KMeans ([#6020](https://github.com/rapidsai/cuml/pull/6020)) [@viclafargue](https://github.com/viclafargue)\n- Update pre-commit hooks ([#6016](https://github.com/rapidsai/cuml/pull/6016)) [@KyleFromNVIDIA](https://github.com/KyleFromNVIDIA)\n- Improve update-version.sh ([#6014](https://github.com/rapidsai/cuml/pull/6014)) [@bdice](https://github.com/bdice)\n- Use tool.scikit-build.cmake.version, set scikit-build-core minimum-version ([#6012](https://github.com/rapidsai/cuml/pull/6012)) [@jameslamb](https://github.com/jameslamb)\n- Merge branch-24.08 into branch-24.10 ([#5981](https://github.com/rapidsai/cuml/pull/5981)) [@jameslamb](https://github.com/jameslamb)\n- Use CUDA math wheels ([#5966](https://github.com/rapidsai/cuml/pull/5966)) [@KyleFromNVIDIA](https://github.com/KyleFromNVIDIA)\n\n# cuml 24.08.00 (7 Aug 2024)\n\n## 🐛 Bug Fixes\n\n- Fixes for encoders/transformers for cudf.pandas ([#5990](https://github.com/rapidsai/cuml/pull/5990)) [@dantegd](https://github.com/dantegd)\n- BUG: remove sample parameter from pca call to mean ([#5980](https://github.com/rapidsai/cuml/pull/5980)) [@mfoerste4](https://github.com/mfoerste4)\n- Fix segfault and other errors in ForestInference.load_from_sklearn ([#5973](https://github.com/rapidsai/cuml/pull/5973)) [@hcho3](https://github.com/hcho3)\n- Rename `.devcontainer`s for CUDA 12.5 ([#5967](https://github.com/rapidsai/cuml/pull/5967)) [@jakirkham](https://github.com/jakirkham)\n- [MNT] Small NumPy 2 related fixes ([#5954](https://github.com/rapidsai/cuml/pull/5954)) [@seberg](https://github.com/seberg)\n- CI Fix: use ld_preload to avoid libgomp issue on ARM jobs ([#5949](https://github.com/rapidsai/cuml/pull/5949)) [@dantegd](https://github.com/dantegd)\n- Fix for benchmark runner to handle parameter sweeps of multiple data types ([#5938](https://github.com/rapidsai/cuml/pull/5938)) [@dantegd](https://github.com/dantegd)\n- Avoid extra memory copy when using cp.concatenate in cuml.dask kmeans ([#5937](https://github.com/rapidsai/cuml/pull/5937)) [@dantegd](https://github.com/dantegd)\n- Assign correct `labels_` in `cuml.dask.kmeans` ([#5931](https://github.com/rapidsai/cuml/pull/5931)) [@dantegd](https://github.com/dantegd)\n- Fix nightly jobs by updating hypothesis strategies to account for sklearn change ([#5925](https://github.com/rapidsai/cuml/pull/5925)) [@dantegd](https://github.com/dantegd)\n- Fix for SVC fit_proba not using class weights ([#5912](https://github.com/rapidsai/cuml/pull/5912)) [@pablotanner](https://github.com/pablotanner)\n- Fix `cudf.pandas` failure on `test_convert_input_dtype` ([#5885](https://github.com/rapidsai/cuml/pull/5885)) [@dantegd](https://github.com/dantegd)\n- Fix `cudf.pandas` failure on  `test_convert_matrix_order_cuml_array` ([#5882](https://github.com/rapidsai/cuml/pull/5882)) [@dantegd](https://github.com/dantegd)\n- Simplify cuml array ([#5166](https://github.com/rapidsai/cuml/pull/5166)) [@wence-](https://github.com/wence-)\n\n## 🚀 New Features\n\n- [FEA] Enable UMAP to build knn graph using NN Descent ([#5910](https://github.com/rapidsai/cuml/pull/5910)) [@jinsolp](https://github.com/jinsolp)\n- Allow estimators to accept any dtype ([#5888](https://github.com/rapidsai/cuml/pull/5888)) [@dantegd](https://github.com/dantegd)\n\n## 🛠️ Improvements\n\n- Add support for XGBoost UBJSON in FIL ([#6009](https://github.com/rapidsai/cuml/pull/6009)) [@hcho3](https://github.com/hcho3)\n- split up CUDA-suffixed dependencies in dependencies.yaml ([#5974](https://github.com/rapidsai/cuml/pull/5974)) [@jameslamb](https://github.com/jameslamb)\n- Use workflow branch 24.08 again ([#5970](https://github.com/rapidsai/cuml/pull/5970)) [@KyleFromNVIDIA](https://github.com/KyleFromNVIDIA)\n- Bump Treelite to 4.3.0 ([#5968](https://github.com/rapidsai/cuml/pull/5968)) [@hcho3](https://github.com/hcho3)\n- reduce memory_footprint for sparse PCA transform ([#5964](https://github.com/rapidsai/cuml/pull/5964)) [@Intron7](https://github.com/Intron7)\n- Build and test with CUDA 12.5.1 ([#5963](https://github.com/rapidsai/cuml/pull/5963)) [@KyleFromNVIDIA](https://github.com/KyleFromNVIDIA)\n- Support int64 index type in MG sparse LogisticRegression ([#5962](https://github.com/rapidsai/cuml/pull/5962)) [@lijinf2](https://github.com/lijinf2)\n- Add CUDA_STATIC_MATH_LIBRARIES ([#5959](https://github.com/rapidsai/cuml/pull/5959)) [@KyleFromNVIDIA](https://github.com/KyleFromNVIDIA)\n- skip CMake 3.30.0 ([#5956](https://github.com/rapidsai/cuml/pull/5956)) [@jameslamb](https://github.com/jameslamb)\n- Make `ci/run_cuml_dask_pytests.sh` environment-agnostic again ([#5950](https://github.com/rapidsai/cuml/pull/5950)) [@trxcllnt](https://github.com/trxcllnt)\n- Use verify-alpha-spec hook ([#5948](https://github.com/rapidsai/cuml/pull/5948)) [@KyleFromNVIDIA](https://github.com/KyleFromNVIDIA)\n- nest cuml one level deeper in python ([#5944](https://github.com/rapidsai/cuml/pull/5944)) [@msarahan](https://github.com/msarahan)\n- resolve dependency-file-generator warning, other rapids-build-backend followup ([#5928](https://github.com/rapidsai/cuml/pull/5928)) [@jameslamb](https://github.com/jameslamb)\n- Adopt CI/packaging codeowners ([#5923](https://github.com/rapidsai/cuml/pull/5923)) [@bdice](https://github.com/bdice)\n- Remove text builds of documentation ([#5921](https://github.com/rapidsai/cuml/pull/5921)) [@vyasr](https://github.com/vyasr)\n- Fix conflict of forward-merge #5905 of branch-24.06 into branch-24.08 ([#5911](https://github.com/rapidsai/cuml/pull/5911)) [@dantegd](https://github.com/dantegd)\n- Bump Treelite to 4.2.1 ([#5908](https://github.com/rapidsai/cuml/pull/5908)) [@hcho3](https://github.com/hcho3)\n- remove unnecessary &#39;setuptools&#39; dependency ([#5901](https://github.com/rapidsai/cuml/pull/5901)) [@jameslamb](https://github.com/jameslamb)\n- [FEA] PCA Initialization for TSNE ([#5897](https://github.com/rapidsai/cuml/pull/5897)) [@aamijar](https://github.com/aamijar)\n- Use rapids-build-backend ([#5804](https://github.com/rapidsai/cuml/pull/5804)) [@KyleFromNVIDIA](https://github.com/KyleFromNVIDIA)\n\n# cuml 24.06.00 (5 Jun 2024)\n\n## 🐛 Bug Fixes\n\n- [HOTFIX] Fix import of sklearn by using cpu_only_import ([#5914](https://github.com/rapidsai/cuml/pull/5914)) [@dantegd](https://github.com/dantegd)\n- Fix label binarize for binary class ([#5900](https://github.com/rapidsai/cuml/pull/5900)) [@jinsolp](https://github.com/jinsolp)\n- Fix RandomForestClassifier return type ([#5896](https://github.com/rapidsai/cuml/pull/5896)) [@jinsolp](https://github.com/jinsolp)\n- Fix nightly CI: remove deprecated creation of columns by using explicit dtype ([#5880](https://github.com/rapidsai/cuml/pull/5880)) [@dantegd](https://github.com/dantegd)\n- Fix DBSCAN allocates rbc index even if deactivated ([#5859](https://github.com/rapidsai/cuml/pull/5859)) [@mfoerste4](https://github.com/mfoerste4)\n- Remove gtest from dependencies.yaml ([#5854](https://github.com/rapidsai/cuml/pull/5854)) [@robertmaynard](https://github.com/robertmaynard)\n- Support expression-based Dask Dataframe API ([#5835](https://github.com/rapidsai/cuml/pull/5835)) [@rjzamora](https://github.com/rjzamora)\n- Mark all kernels with internal linkage ([#5764](https://github.com/rapidsai/cuml/pull/5764)) [@robertmaynard](https://github.com/robertmaynard)\n- Fix build.sh clean command ([#5730](https://github.com/rapidsai/cuml/pull/5730)) [@csadorf](https://github.com/csadorf)\n\n## 📖 Documentation\n\n- Update the developer&#39;s guide with new copyright hook ([#5848](https://github.com/rapidsai/cuml/pull/5848)) [@KyleFromNVIDIA](https://github.com/KyleFromNVIDIA)\n\n## 🚀 New Features\n\n- Always use a static gtest and gbench ([#5847](https://github.com/rapidsai/cuml/pull/5847)) [@robertmaynard](https://github.com/robertmaynard)\n\n## 🛠️ Improvements\n\n- Support double precision in MNMG Logistic Regression ([#5898](https://github.com/rapidsai/cuml/pull/5898)) [@lijinf2](https://github.com/lijinf2)\n- Reduce and rename cudf.pandas integrations jobs ([#5890](https://github.com/rapidsai/cuml/pull/5890)) [@dantegd](https://github.com/dantegd)\n- Fix building cuml with CCCL main ([#5886](https://github.com/rapidsai/cuml/pull/5886)) [@trxcllnt](https://github.com/trxcllnt)\n- Add optional CI job for integration tests with cudf.pandas ([#5881](https://github.com/rapidsai/cuml/pull/5881)) [@dantegd](https://github.com/dantegd)\n- Enable pytest failures on FutureWarnings/DeprecationWarnings ([#5877](https://github.com/rapidsai/cuml/pull/5877)) [@mroeschke](https://github.com/mroeschke)\n- Remove return in test_lbfgs ([#5875](https://github.com/rapidsai/cuml/pull/5875)) [@mroeschke](https://github.com/mroeschke)\n- Avoid dask_cudf.core imports ([#5874](https://github.com/rapidsai/cuml/pull/5874)) [@bdice](https://github.com/bdice)\n- Support CPU object for `train_test_split` ([#5873](https://github.com/rapidsai/cuml/pull/5873)) [@isVoid](https://github.com/isVoid)\n- Only use functions in the limited API ([#5871](https://github.com/rapidsai/cuml/pull/5871)) [@vyasr](https://github.com/vyasr)\n- Replace deprecated disutils.version with packaging.version ([#5868](https://github.com/rapidsai/cuml/pull/5868)) [@mroeschke](https://github.com/mroeschke)\n- Adjust deprecated cupy.sparse usage ([#5867](https://github.com/rapidsai/cuml/pull/5867)) [@mroeschke](https://github.com/mroeschke)\n- Fix numpy 2.0 deprecations ([#5866](https://github.com/rapidsai/cuml/pull/5866)) [@mroeschke](https://github.com/mroeschke)\n- Fix deprecated positional arg usage ([#5865](https://github.com/rapidsai/cuml/pull/5865)) [@mroeschke](https://github.com/mroeschke)\n- Use int instead of float in random.randint ([#5864](https://github.com/rapidsai/cuml/pull/5864)) [@mroeschke](https://github.com/mroeschke)\n- Migrate to `{{ stdlib(&quot;c&quot;) }}` ([#5863](https://github.com/rapidsai/cuml/pull/5863)) [@hcho3](https://github.com/hcho3)\n- Avoid deprecated API in notebook ([#5862](https://github.com/rapidsai/cuml/pull/5862)) [@rjzamora](https://github.com/rjzamora)\n- Add dedicated handling for cudf.pandas wrapped Numpy arrays ([#5861](https://github.com/rapidsai/cuml/pull/5861)) [@betatim](https://github.com/betatim)\n- Prepend devcontainer name with the username ([#5860](https://github.com/rapidsai/cuml/pull/5860)) [@trxcllnt](https://github.com/trxcllnt)\n- add --rm and --name to devcontainer run args ([#5857](https://github.com/rapidsai/cuml/pull/5857)) [@trxcllnt](https://github.com/trxcllnt)\n- Update pip devcontainers to UCX v1.15.0 ([#5856](https://github.com/rapidsai/cuml/pull/5856)) [@trxcllnt](https://github.com/trxcllnt)\n- Replace rmm::mr::device_memory_resource* with rmm::device_async_resource_ref ([#5853](https://github.com/rapidsai/cuml/pull/5853)) [@harrism](https://github.com/harrism)\n- Update scikit-learn to 1.4 ([#5851](https://github.com/rapidsai/cuml/pull/5851)) [@betatim](https://github.com/betatim)\n- Prevent undefined behavior when passing handle from Treelite to cuML FIL ([#5849](https://github.com/rapidsai/cuml/pull/5849)) [@hcho3](https://github.com/hcho3)\n- Adds missing files to `update-version.sh` ([#5830](https://github.com/rapidsai/cuml/pull/5830)) [@AyodeAwe](https://github.com/AyodeAwe)\n- Enable all tests for `arm` arch ([#5824](https://github.com/rapidsai/cuml/pull/5824)) [@galipremsagar](https://github.com/galipremsagar)\n- Address PytestReturnNotNoneWarning in cuml tests ([#5819](https://github.com/rapidsai/cuml/pull/5819)) [@mroeschke](https://github.com/mroeschke)\n- Handle binary classifier with all-0 labels ([#5810](https://github.com/rapidsai/cuml/pull/5810)) [@hcho3](https://github.com/hcho3)\n- Use pytest_cases.fixture to fix warnings. ([#5798](https://github.com/rapidsai/cuml/pull/5798)) [@bdice](https://github.com/bdice)\n- Enable Dask tests with UCX-Py/UCXX in CI ([#5697](https://github.com/rapidsai/cuml/pull/5697)) [@pentschev](https://github.com/pentschev)\n\n# cuML 24.04.00 (10 Apr 2024)\n\n## 🐛 Bug Fixes\n\n- Update pre-commit-hooks to v0.0.3 ([#5816](https://github.com/rapidsai/cuml/pull/5816)) [@KyleFromNVIDIA](https://github.com/KyleFromNVIDIA)\n- Correct and adjust tolerances of mnmg logreg pytests ([#5812](https://github.com/rapidsai/cuml/pull/5812)) [@dantegd](https://github.com/dantegd)\n- Remove use of cudf.core.column.full. ([#5794](https://github.com/rapidsai/cuml/pull/5794)) [@bdice](https://github.com/bdice)\n- Suppress all HealthChecks on test_split_datasets. ([#5791](https://github.com/rapidsai/cuml/pull/5791)) [@bdice](https://github.com/bdice)\n- Suppress a hypothesis HealthCheck on test_split_datasets that fails in nightly CI. ([#5790](https://github.com/rapidsai/cuml/pull/5790)) [@bdice](https://github.com/bdice)\n- [BUG] Fix `MAX_THREADS_PER_SM` on sm 89. ([#5785](https://github.com/rapidsai/cuml/pull/5785)) [@trivialfis](https://github.com/trivialfis)\n- fix device to host copy not sync stream in logistic regression mg ([#5766](https://github.com/rapidsai/cuml/pull/5766)) [@lijinf2](https://github.com/lijinf2)\n- Use cudf.Index instead of cudf.GenericIndex. ([#5738](https://github.com/rapidsai/cuml/pull/5738)) [@bdice](https://github.com/bdice)\n- update RAPIDS dependencies to 24.4, refactor dependencies.yaml ([#5726](https://github.com/rapidsai/cuml/pull/5726)) [@jameslamb](https://github.com/jameslamb)\n\n## 🚀 New Features\n\n- Support CUDA 12.2 ([#5711](https://github.com/rapidsai/cuml/pull/5711)) [@jameslamb](https://github.com/jameslamb)\n\n## 🛠️ Improvements\n\n- Use `conda env create --yes` instead of `--force` ([#5822](https://github.com/rapidsai/cuml/pull/5822)) [@bdice](https://github.com/bdice)\n- Bump Treelite to 4.1.2 ([#5814](https://github.com/rapidsai/cuml/pull/5814)) [@hcho3](https://github.com/hcho3)\n- Support standardization for sparse vectors in logistic regression MG ([#5806](https://github.com/rapidsai/cuml/pull/5806)) [@lijinf2](https://github.com/lijinf2)\n- Update script input name ([#5802](https://github.com/rapidsai/cuml/pull/5802)) [@AyodeAwe](https://github.com/AyodeAwe)\n- Add upper bound to prevent usage of NumPy 2 ([#5797](https://github.com/rapidsai/cuml/pull/5797)) [@bdice](https://github.com/bdice)\n- Enable pytest failures on warnings from cudf ([#5796](https://github.com/rapidsai/cuml/pull/5796)) [@mroeschke](https://github.com/mroeschke)\n- Use public cudf APIs where possible ([#5795](https://github.com/rapidsai/cuml/pull/5795)) [@mroeschke](https://github.com/mroeschke)\n- Remove hard-coding of RAPIDS version where possible ([#5793](https://github.com/rapidsai/cuml/pull/5793)) [@KyleFromNVIDIA](https://github.com/KyleFromNVIDIA)\n- Switch `pytest-xdist` algorithm to `worksteal` ([#5792](https://github.com/rapidsai/cuml/pull/5792)) [@bdice](https://github.com/bdice)\n- Automate C++ include file grouping and ordering using clang-format ([#5787](https://github.com/rapidsai/cuml/pull/5787)) [@harrism](https://github.com/harrism)\n- Add support for Python 3.11, require NumPy 1.23+ ([#5786](https://github.com/rapidsai/cuml/pull/5786)) [@jameslamb](https://github.com/jameslamb)\n- [ENH] Let cuDF handle input types for label encoder. ([#5783](https://github.com/rapidsai/cuml/pull/5783)) [@trivialfis](https://github.com/trivialfis)\n- Install test dependencies at the same time as cuml packages. ([#5781](https://github.com/rapidsai/cuml/pull/5781)) [@bdice](https://github.com/bdice)\n- Update devcontainers to CUDA Toolkit 12.2 ([#5778](https://github.com/rapidsai/cuml/pull/5778)) [@trxcllnt](https://github.com/trxcllnt)\n- target branch-24.04 for GitHub Actions workflows ([#5776](https://github.com/rapidsai/cuml/pull/5776)) [@jameslamb](https://github.com/jameslamb)\n- Add environment-agnostic scripts for running ctests and pytests ([#5761](https://github.com/rapidsai/cuml/pull/5761)) [@trxcllnt](https://github.com/trxcllnt)\n- Pandas 2.x support ([#5758](https://github.com/rapidsai/cuml/pull/5758)) [@dantegd](https://github.com/dantegd)\n- Update ops-bot.yaml ([#5752](https://github.com/rapidsai/cuml/pull/5752)) [@AyodeAwe](https://github.com/AyodeAwe)\n- Forward-merge branch-24.02 to branch-24.04 ([#5735](https://github.com/rapidsai/cuml/pull/5735)) [@bdice](https://github.com/bdice)\n- Replace local copyright check with pre-commit-hooks verify-copyright ([#5732](https://github.com/rapidsai/cuml/pull/5732)) [@KyleFromNVIDIA](https://github.com/KyleFromNVIDIA)\n- DBSCAN utilize rbc eps_neighbors ([#5728](https://github.com/rapidsai/cuml/pull/5728)) [@mfoerste4](https://github.com/mfoerste4)\n\n# cuML 24.02.00 (12 Feb 2024)\n\n## 🚨 Breaking Changes\n\n- Update to CCCL 2.2.0. ([#5702](https://github.com/rapidsai/cuml/pull/5702)) [@bdice](https://github.com/bdice)\n- Switch to scikit-build-core ([#5693](https://github.com/rapidsai/cuml/pull/5693)) [@vyasr](https://github.com/vyasr)\n\n## 🐛 Bug Fixes\n\n- [Hotfix] Fix FIL gtest ([#5755](https://github.com/rapidsai/cuml/pull/5755)) [@hcho3](https://github.com/hcho3)\n- Exclude tests from builds ([#5754](https://github.com/rapidsai/cuml/pull/5754)) [@vyasr](https://github.com/vyasr)\n- Fix ctest directory to ensure tests are executed ([#5753](https://github.com/rapidsai/cuml/pull/5753)) [@bdice](https://github.com/bdice)\n- Synchronize stream in SVC memory test ([#5729](https://github.com/rapidsai/cuml/pull/5729)) [@wphicks](https://github.com/wphicks)\n- Fix shared-workflows repo name ([#5723](https://github.com/rapidsai/cuml/pull/5723)) [@raydouglass](https://github.com/raydouglass)\n- Fix cupy dependency in pyproject.toml ([#5705](https://github.com/rapidsai/cuml/pull/5705)) [@vyasr](https://github.com/vyasr)\n- Only cufft offers a static_nocallback version of the library ([#5703](https://github.com/rapidsai/cuml/pull/5703)) [@robertmaynard](https://github.com/robertmaynard)\n\n## 🛠️ Improvements\n\n- [Hotfix] Update GPUTreeSHAP to fix ARM build ([#5747](https://github.com/rapidsai/cuml/pull/5747)) [@hcho3](https://github.com/hcho3)\n- Disable HistGradientBoosting support for now ([#5744](https://github.com/rapidsai/cuml/pull/5744)) [@hcho3](https://github.com/hcho3)\n- Disable hnswlib feature in RAFT; pin pytest ([#5733](https://github.com/rapidsai/cuml/pull/5733)) [@hcho3](https://github.com/hcho3)\n- [LogisticRegressionMG] Support standardization with no data modification ([#5724](https://github.com/rapidsai/cuml/pull/5724)) [@lijinf2](https://github.com/lijinf2)\n- Remove usages of rapids-env-update ([#5716](https://github.com/rapidsai/cuml/pull/5716)) [@KyleFromNVIDIA](https://github.com/KyleFromNVIDIA)\n- Remove extraneous SKBUILD_BUILD_OPTIONS ([#5714](https://github.com/rapidsai/cuml/pull/5714)) [@vyasr](https://github.com/vyasr)\n- refactor CUDA versions in dependencies.yaml ([#5712](https://github.com/rapidsai/cuml/pull/5712)) [@jameslamb](https://github.com/jameslamb)\n- Update to CCCL 2.2.0. ([#5702](https://github.com/rapidsai/cuml/pull/5702)) [@bdice](https://github.com/bdice)\n- Migrate to Treelite 4.0 ([#5701](https://github.com/rapidsai/cuml/pull/5701)) [@hcho3](https://github.com/hcho3)\n- Use cuda::proclaim_return_type on device lambdas. ([#5696](https://github.com/rapidsai/cuml/pull/5696)) [@bdice](https://github.com/bdice)\n- move _process_generic to base_return_types, avoid circular import ([#5695](https://github.com/rapidsai/cuml/pull/5695)) [@dcolinmorgan](https://github.com/dcolinmorgan)\n- Switch to scikit-build-core ([#5693](https://github.com/rapidsai/cuml/pull/5693)) [@vyasr](https://github.com/vyasr)\n- Fix all deprecated function calls in TUs where warnings are errors ([#5692](https://github.com/rapidsai/cuml/pull/5692)) [@vyasr](https://github.com/vyasr)\n- Remove CUML_BUILD_WHEELS and standardize Python builds ([#5689](https://github.com/rapidsai/cuml/pull/5689)) [@vyasr](https://github.com/vyasr)\n- Forward-merge branch-23.12 to branch-24.02 ([#5657](https://github.com/rapidsai/cuml/pull/5657)) [@bdice](https://github.com/bdice)\n- Add cuML devcontainers ([#5568](https://github.com/rapidsai/cuml/pull/5568)) [@trxcllnt](https://github.com/trxcllnt)\n\n# cuML 23.12.00 (6 Dec 2023)\n\n## 🚨 Breaking Changes\n\n- [LogisticRegressionMG] Support sparse vectors ([#5632](https://github.com/rapidsai/cuml/pull/5632)) [@lijinf2](https://github.com/lijinf2)\n\n## 🐛 Bug Fixes\n\n- Update actions/labeler to v4 ([#5686](https://github.com/rapidsai/cuml/pull/5686)) [@raydouglass](https://github.com/raydouglass)\n- updated docs around `make_column_transformer` change from `.preprocessing` to `.compose` ([#5680](https://github.com/rapidsai/cuml/pull/5680)) [@taureandyernv](https://github.com/taureandyernv)\n- Skip dask pytest NN hang in CUDA 11.4 CI ([#5665](https://github.com/rapidsai/cuml/pull/5665)) [@dantegd](https://github.com/dantegd)\n- Avoid hard import of sklearn in base module. ([#5663](https://github.com/rapidsai/cuml/pull/5663)) [@csadorf](https://github.com/csadorf)\n- CI: Pin clang-tidy to 15.0.7. ([#5661](https://github.com/rapidsai/cuml/pull/5661)) [@csadorf](https://github.com/csadorf)\n- Adjust assumption regarding valid cudf.Series dimensional input. ([#5654](https://github.com/rapidsai/cuml/pull/5654)) [@csadorf](https://github.com/csadorf)\n- Flatten cupy array before feeding to cudf.Series ([#5651](https://github.com/rapidsai/cuml/pull/5651)) [@vyasr](https://github.com/vyasr)\n- CI: Fix expected ValueError and dask-glm incompatibility ([#5644](https://github.com/rapidsai/cuml/pull/5644)) [@csadorf](https://github.com/csadorf)\n- Use drop_duplicates instead of unique for cudf&#39;s pandas compatibility mode ([#5639](https://github.com/rapidsai/cuml/pull/5639)) [@vyasr](https://github.com/vyasr)\n- Temporarily avoid pydata-sphinx-theme version 0.14.2. ([#5629](https://github.com/rapidsai/cuml/pull/5629)) [@csadorf](https://github.com/csadorf)\n- Fix type hint in split function. ([#5625](https://github.com/rapidsai/cuml/pull/5625)) [@trivialfis](https://github.com/trivialfis)\n- Fix trying to get pointer to None in svm/linear.pyx ([#5615](https://github.com/rapidsai/cuml/pull/5615)) [@yosider](https://github.com/yosider)\n- Reduce parallelism to avoid OOMs in wheel tests ([#5611](https://github.com/rapidsai/cuml/pull/5611)) [@vyasr](https://github.com/vyasr)\n\n## 📖 Documentation\n\n- Update interoperability docs ([#5633](https://github.com/rapidsai/cuml/pull/5633)) [@beckernick](https://github.com/beckernick)\n- Update instructions for creating a conda build environment ([#5628](https://github.com/rapidsai/cuml/pull/5628)) [@csadorf](https://github.com/csadorf)\n\n## 🚀 New Features\n\n- Basic implementation of `OrdinalEncoder`. ([#5646](https://github.com/rapidsai/cuml/pull/5646)) [@trivialfis](https://github.com/trivialfis)\n\n## 🛠️ Improvements\n\n- Build concurrency for nightly and merge triggers ([#5658](https://github.com/rapidsai/cuml/pull/5658)) [@bdice](https://github.com/bdice)\n- [LogisticRegressionMG][FEA] Support training when dataset contains only one class ([#5655](https://github.com/rapidsai/cuml/pull/5655)) [@lijinf2](https://github.com/lijinf2)\n- Use new `rapids-dask-dependency` metapackage for managing `dask` versions ([#5649](https://github.com/rapidsai/cuml/pull/5649)) [@galipremsagar](https://github.com/galipremsagar)\n- Simplify some logic in LabelEncoder ([#5648](https://github.com/rapidsai/cuml/pull/5648)) [@vyasr](https://github.com/vyasr)\n- Increase `Nanny` close timeout in `LocalCUDACluster` tests ([#5636](https://github.com/rapidsai/cuml/pull/5636)) [@pentschev](https://github.com/pentschev)\n- [LogisticRegressionMG] Support sparse vectors ([#5632](https://github.com/rapidsai/cuml/pull/5632)) [@lijinf2](https://github.com/lijinf2)\n- Add rich HTML representation to estimators ([#5630](https://github.com/rapidsai/cuml/pull/5630)) [@betatim](https://github.com/betatim)\n- Unpin `dask` and `distributed` for `23.12` development ([#5627](https://github.com/rapidsai/cuml/pull/5627)) [@galipremsagar](https://github.com/galipremsagar)\n- Update `shared-action-workflows` references ([#5621](https://github.com/rapidsai/cuml/pull/5621)) [@AyodeAwe](https://github.com/AyodeAwe)\n- Use branch-23.12 workflows. ([#5618](https://github.com/rapidsai/cuml/pull/5618)) [@bdice](https://github.com/bdice)\n- Update rapids-cmake functions to non-deprecated signatures ([#5616](https://github.com/rapidsai/cuml/pull/5616)) [@robertmaynard](https://github.com/robertmaynard)\n- Allow nightly dependencies and set up consistent nightly versions for conda and pip packages ([#5607](https://github.com/rapidsai/cuml/pull/5607)) [@vyasr](https://github.com/vyasr)\n- Forward-merge branch-23.10 to branch-23.12 ([#5596](https://github.com/rapidsai/cuml/pull/5596)) [@bdice](https://github.com/bdice)\n- Build CUDA 12.0 ARM conda packages. ([#5595](https://github.com/rapidsai/cuml/pull/5595)) [@bdice](https://github.com/bdice)\n- Enable multiclass svm for sparse input ([#5588](https://github.com/rapidsai/cuml/pull/5588)) [@mfoerste4](https://github.com/mfoerste4)\n\n# cuML 23.10.00 (11 Oct 2023)\n\n## 🚨 Breaking Changes\n\n- add sample_weight parameter to dbscan.fit ([#5574](https://github.com/rapidsai/cuml/pull/5574)) [@mfoerste4](https://github.com/mfoerste4)\n- Update to Cython 3.0.0 ([#5506](https://github.com/rapidsai/cuml/pull/5506)) [@vyasr](https://github.com/vyasr)\n\n## 🐛 Bug Fixes\n\n- Fix accidental unsafe cupy import ([#5613](https://github.com/rapidsai/cuml/pull/5613)) [@dantegd](https://github.com/dantegd)\n- Fixes for CPU package ([#5599](https://github.com/rapidsai/cuml/pull/5599)) [@dantegd](https://github.com/dantegd)\n- Fixes for timeouts in tests ([#5598](https://github.com/rapidsai/cuml/pull/5598)) [@dantegd](https://github.com/dantegd)\n\n## 🚀 New Features\n\n- Enable cuml-cpu nightly ([#5585](https://github.com/rapidsai/cuml/pull/5585)) [@dantegd](https://github.com/dantegd)\n- add sample_weight parameter to dbscan.fit ([#5574](https://github.com/rapidsai/cuml/pull/5574)) [@mfoerste4](https://github.com/mfoerste4)\n\n## 🛠️ Improvements\n\n- cuml-cpu notebook, docs and cluster models ([#5597](https://github.com/rapidsai/cuml/pull/5597)) [@dantegd](https://github.com/dantegd)\n- Pin `dask` and `distributed` for `23.10` release ([#5592](https://github.com/rapidsai/cuml/pull/5592)) [@galipremsagar](https://github.com/galipremsagar)\n- Add changes for early experimental support for dataframe interchange protocol API ([#5591](https://github.com/rapidsai/cuml/pull/5591)) [@dantegd](https://github.com/dantegd)\n- [FEA] Support L1 regularization and ElasticNet in MNMG Dask LogisticRegression ([#5587](https://github.com/rapidsai/cuml/pull/5587)) [@lijinf2](https://github.com/lijinf2)\n- Update image names ([#5586](https://github.com/rapidsai/cuml/pull/5586)) [@AyodeAwe](https://github.com/AyodeAwe)\n- Update to clang 16.0.6. ([#5583](https://github.com/rapidsai/cuml/pull/5583)) [@bdice](https://github.com/bdice)\n- Upgrade to Treelite 3.9.1 ([#5581](https://github.com/rapidsai/cuml/pull/5581)) [@hcho3](https://github.com/hcho3)\n- Update to doxygen 1.9.1. ([#5580](https://github.com/rapidsai/cuml/pull/5580)) [@bdice](https://github.com/bdice)\n- [REVIEW] Adding a few of datasets for benchmarking ([#5573](https://github.com/rapidsai/cuml/pull/5573)) [@vinaydes](https://github.com/vinaydes)\n- Allow cuML MNMG estimators to be serialized ([#5571](https://github.com/rapidsai/cuml/pull/5571)) [@viclafargue](https://github.com/viclafargue)\n- [FEA] Support multiple classes in multi-node-multi-gpu logistic regression, from C++, Cython, to Dask Python class ([#5565](https://github.com/rapidsai/cuml/pull/5565)) [@lijinf2](https://github.com/lijinf2)\n- Use `copy-pr-bot` ([#5563](https://github.com/rapidsai/cuml/pull/5563)) [@ajschmidt8](https://github.com/ajschmidt8)\n- Unblock CI for branch-23.10 ([#5561](https://github.com/rapidsai/cuml/pull/5561)) [@csadorf](https://github.com/csadorf)\n- Fix CPU-only build for new FIL ([#5559](https://github.com/rapidsai/cuml/pull/5559)) [@hcho3](https://github.com/hcho3)\n- [FEA] Support no regularization in MNMG LogisticRegression ([#5558](https://github.com/rapidsai/cuml/pull/5558)) [@lijinf2](https://github.com/lijinf2)\n- Unpin `dask` and `distributed` for `23.10` development ([#5557](https://github.com/rapidsai/cuml/pull/5557)) [@galipremsagar](https://github.com/galipremsagar)\n- Branch 23.10 merge 23.08 ([#5547](https://github.com/rapidsai/cuml/pull/5547)) [@vyasr](https://github.com/vyasr)\n- Use Python builtins to prep benchmark `tmp_dir` ([#5537](https://github.com/rapidsai/cuml/pull/5537)) [@jakirkham](https://github.com/jakirkham)\n- Branch 23.10 merge 23.08 ([#5522](https://github.com/rapidsai/cuml/pull/5522)) [@vyasr](https://github.com/vyasr)\n- Update to Cython 3.0.0 ([#5506](https://github.com/rapidsai/cuml/pull/5506)) [@vyasr](https://github.com/vyasr)\n\n# cuML 23.08.00 (9 Aug 2023)\n\n## 🚨 Breaking Changes\n\n- Stop using setup.py in build.sh ([#5500](https://github.com/rapidsai/cuml/pull/5500)) [@vyasr](https://github.com/vyasr)\n- Add `copy_X` parameter to `LinearRegression` ([#5495](https://github.com/rapidsai/cuml/pull/5495)) [@viclafargue](https://github.com/viclafargue)\n\n## 🐛 Bug Fixes\n\n- Update dependencies.yaml test_notebooks to include dask_ml ([#5545](https://github.com/rapidsai/cuml/pull/5545)) [@taureandyernv](https://github.com/taureandyernv)\n- Fix cython-lint issues. ([#5536](https://github.com/rapidsai/cuml/pull/5536)) [@bdice](https://github.com/bdice)\n- Skip rf_memleak tests ([#5529](https://github.com/rapidsai/cuml/pull/5529)) [@dantegd](https://github.com/dantegd)\n- Pin hdbscan to fix pytests in CI ([#5515](https://github.com/rapidsai/cuml/pull/5515)) [@dantegd](https://github.com/dantegd)\n- Fix UMAP and simplicial set functions metric ([#5490](https://github.com/rapidsai/cuml/pull/5490)) [@viclafargue](https://github.com/viclafargue)\n- Fix test_masked_column_mode ([#5480](https://github.com/rapidsai/cuml/pull/5480)) [@viclafargue](https://github.com/viclafargue)\n- Use fit_predict rather than fit for KNeighborsClassifier and KNeighborsRegressor in benchmark utility ([#5460](https://github.com/rapidsai/cuml/pull/5460)) [@beckernick](https://github.com/beckernick)\n- Modify HDBSCAN membership_vector batch_size check ([#5455](https://github.com/rapidsai/cuml/pull/5455)) [@tarang-jain](https://github.com/tarang-jain)\n\n## 🚀 New Features\n\n- Use rapids-cmake testing to run tests in parallel ([#5487](https://github.com/rapidsai/cuml/pull/5487)) [@robertmaynard](https://github.com/robertmaynard)\n- [FEA] Update MST Reduction Op ([#5386](https://github.com/rapidsai/cuml/pull/5386)) [@tarang-jain](https://github.com/tarang-jain)\n- cuml: Build CUDA 12 packages ([#5318](https://github.com/rapidsai/cuml/pull/5318)) [@vyasr](https://github.com/vyasr)\n- CI: Add custom GitHub Actions job to run clang-tidy ([#5235](https://github.com/rapidsai/cuml/pull/5235)) [@csadorf](https://github.com/csadorf)\n\n## 🛠️ Improvements\n\n- Pin `dask` and `distributed` for `23.08` release ([#5541](https://github.com/rapidsai/cuml/pull/5541)) [@galipremsagar](https://github.com/galipremsagar)\n- Remove Dockerfile. ([#5534](https://github.com/rapidsai/cuml/pull/5534)) [@bdice](https://github.com/bdice)\n- Improve temporary directory handling in cuML ([#5527](https://github.com/rapidsai/cuml/pull/5527)) [@jakirkham](https://github.com/jakirkham)\n- Support init arguments in MNMG LogisticRegression ([#5519](https://github.com/rapidsai/cuml/pull/5519)) [@lijinf2](https://github.com/lijinf2)\n- Support predict in MNMG Logistic Regression ([#5516](https://github.com/rapidsai/cuml/pull/5516)) [@lijinf2](https://github.com/lijinf2)\n- Remove unused matrix.cuh and math.cuh headers to eliminate deprecation warnings. ([#5513](https://github.com/rapidsai/cuml/pull/5513)) [@bdice](https://github.com/bdice)\n- Update gputreeshap to use rapids-cmake. ([#5512](https://github.com/rapidsai/cuml/pull/5512)) [@bdice](https://github.com/bdice)\n- Remove raft specializations includes. ([#5509](https://github.com/rapidsai/cuml/pull/5509)) [@bdice](https://github.com/bdice)\n- Revert CUDA 12.0 CI workflows to branch-23.08. ([#5508](https://github.com/rapidsai/cuml/pull/5508)) [@bdice](https://github.com/bdice)\n- Enable wheels CI scripts to run locally ([#5507](https://github.com/rapidsai/cuml/pull/5507)) [@divyegala](https://github.com/divyegala)\n- Default to nproc for PARALLEL_LEVEL in build.sh. ([#5505](https://github.com/rapidsai/cuml/pull/5505)) [@csadorf](https://github.com/csadorf)\n- Fixed potential overflows in SVM, minor adjustments to nvtx ranges ([#5504](https://github.com/rapidsai/cuml/pull/5504)) [@mfoerste4](https://github.com/mfoerste4)\n- Stop using setup.py in build.sh ([#5500](https://github.com/rapidsai/cuml/pull/5500)) [@vyasr](https://github.com/vyasr)\n- Fix PCA test ([#5498](https://github.com/rapidsai/cuml/pull/5498)) [@viclafargue](https://github.com/viclafargue)\n- Update build dependencies ([#5496](https://github.com/rapidsai/cuml/pull/5496)) [@csadorf](https://github.com/csadorf)\n- Add `copy_X` parameter to `LinearRegression` ([#5495](https://github.com/rapidsai/cuml/pull/5495)) [@viclafargue](https://github.com/viclafargue)\n- Sparse pca patch ([#5493](https://github.com/rapidsai/cuml/pull/5493)) [@Intron7](https://github.com/Intron7)\n- Restrict HDBSCAN metric options to L2 #5415 ([#5492](https://github.com/rapidsai/cuml/pull/5492)) [@Rvch7](https://github.com/Rvch7)\n- Fix typos. ([#5481](https://github.com/rapidsai/cuml/pull/5481)) [@bdice](https://github.com/bdice)\n- Add multi-node-multi-gpu Logistic Regression in C++ ([#5477](https://github.com/rapidsai/cuml/pull/5477)) [@lijinf2](https://github.com/lijinf2)\n- Add missing stream argument to cub calls in workingset ([#5476](https://github.com/rapidsai/cuml/pull/5476)) [@mfoerste4](https://github.com/mfoerste4)\n- Update to CMake 3.26.4 ([#5464](https://github.com/rapidsai/cuml/pull/5464)) [@vyasr](https://github.com/vyasr)\n- use rapids-upload-docs script ([#5457](https://github.com/rapidsai/cuml/pull/5457)) [@AyodeAwe](https://github.com/AyodeAwe)\n- Unpin `dask` and `distributed` for development ([#5452](https://github.com/rapidsai/cuml/pull/5452)) [@galipremsagar](https://github.com/galipremsagar)\n- Remove documentation build scripts for Jenkins ([#5450](https://github.com/rapidsai/cuml/pull/5450)) [@ajschmidt8](https://github.com/ajschmidt8)\n- Fix update version and pinnings for 23.08. ([#5440](https://github.com/rapidsai/cuml/pull/5440)) [@bdice](https://github.com/bdice)\n- Add cython-lint configuration. ([#5439](https://github.com/rapidsai/cuml/pull/5439)) [@bdice](https://github.com/bdice)\n- Unpin scikit-build upper bound ([#5438](https://github.com/rapidsai/cuml/pull/5438)) [@vyasr](https://github.com/vyasr)\n- Fix some deprecation warnings in tests. ([#5436](https://github.com/rapidsai/cuml/pull/5436)) [@bdice](https://github.com/bdice)\n- Update `raft::sparse::distance::pairwise_distance` to new API ([#5428](https://github.com/rapidsai/cuml/pull/5428)) [@divyegala](https://github.com/divyegala)\n\n# cuML 23.06.00 (7 Jun 2023)\n\n## 🚨 Breaking Changes\n\n- Dropping Python 3.8 ([#5385](https://github.com/rapidsai/cuml/pull/5385)) [@divyegala](https://github.com/divyegala)\n- Support sparse input for SVC and SVR ([#5273](https://github.com/rapidsai/cuml/pull/5273)) [@mfoerste4](https://github.com/mfoerste4)\n\n## 🐛 Bug Fixes\n\n- Fixes for nightly GHA runs ([#5446](https://github.com/rapidsai/cuml/pull/5446)) [@dantegd](https://github.com/dantegd)\n- Add missing RAFT cusolver_macros import and changes for recent cuDF updates ([#5434](https://github.com/rapidsai/cuml/pull/5434)) [@dantegd](https://github.com/dantegd)\n- Fix kmeans pytest to correctly compute fp output error ([#5426](https://github.com/rapidsai/cuml/pull/5426)) [@mdoijade](https://github.com/mdoijade)\n- Add missing `raft/matrix/matrix.cuh` include ([#5411](https://github.com/rapidsai/cuml/pull/5411)) [@benfred](https://github.com/benfred)\n- Fix path to cumlprims_mg in build workflow ([#5406](https://github.com/rapidsai/cuml/pull/5406)) [@divyegala](https://github.com/divyegala)\n- Fix path to cumlprims in build workflow ([#5405](https://github.com/rapidsai/cuml/pull/5405)) [@vyasr](https://github.com/vyasr)\n- Pin to scikit-build&lt;17.2 ([#5400](https://github.com/rapidsai/cuml/pull/5400)) [@vyasr](https://github.com/vyasr)\n- Fix forward merge #5383 ([#5384](https://github.com/rapidsai/cuml/pull/5384)) [@dantegd](https://github.com/dantegd)\n- Correct buffer move assignment in experimental FIL ([#5372](https://github.com/rapidsai/cuml/pull/5372)) [@wphicks](https://github.com/wphicks)\n- Avoid invalid memory access in experimental FIL for large output size ([#5365](https://github.com/rapidsai/cuml/pull/5365)) [@wphicks](https://github.com/wphicks)\n- Fix forward merge #5336 ([#5345](https://github.com/rapidsai/cuml/pull/5345)) [@dantegd](https://github.com/dantegd)\n\n## 📖 Documentation\n\n- Fix HDBSCAN docs and add membership_vector to cuml.cluster.hdbscan namespace ([#5378](https://github.com/rapidsai/cuml/pull/5378)) [@beckernick](https://github.com/beckernick)\n- Small doc fix ([#5375](https://github.com/rapidsai/cuml/pull/5375)) [@tarang-jain](https://github.com/tarang-jain)\n\n## 🚀 New Features\n\n- Provide method for auto-optimization of FIL parameters ([#5368](https://github.com/rapidsai/cuml/pull/5368)) [@wphicks](https://github.com/wphicks)\n\n## 🛠️ Improvements\n\n- Fix documentation source code links ([#5449](https://github.com/rapidsai/cuml/pull/5449)) [@ajschmidt8](https://github.com/ajschmidt8)\n- Drop seaborn dependency. ([#5437](https://github.com/rapidsai/cuml/pull/5437)) [@bdice](https://github.com/bdice)\n- Make all nvtx usage go through safe imports ([#5424](https://github.com/rapidsai/cuml/pull/5424)) [@dantegd](https://github.com/dantegd)\n- run docs nightly too ([#5423](https://github.com/rapidsai/cuml/pull/5423)) [@AyodeAwe](https://github.com/AyodeAwe)\n- Switch back to using primary shared-action-workflows branch ([#5420](https://github.com/rapidsai/cuml/pull/5420)) [@vyasr](https://github.com/vyasr)\n- Add librmm to libcuml dependencies. ([#5410](https://github.com/rapidsai/cuml/pull/5410)) [@bdice](https://github.com/bdice)\n- Update recipes to GTest version &gt;=1.13.0 ([#5408](https://github.com/rapidsai/cuml/pull/5408)) [@bdice](https://github.com/bdice)\n- Remove cudf from libcuml `meta.yaml` ([#5407](https://github.com/rapidsai/cuml/pull/5407)) [@divyegala](https://github.com/divyegala)\n- Support CUDA 12.0 for pip wheels ([#5404](https://github.com/rapidsai/cuml/pull/5404)) [@divyegala](https://github.com/divyegala)\n- Support for gtest 1.11+ changes ([#5403](https://github.com/rapidsai/cuml/pull/5403)) [@dantegd](https://github.com/dantegd)\n- Update cupy dependency ([#5401](https://github.com/rapidsai/cuml/pull/5401)) [@vyasr](https://github.com/vyasr)\n- Build wheels using new single image workflow ([#5394](https://github.com/rapidsai/cuml/pull/5394)) [@vyasr](https://github.com/vyasr)\n- Revert shared-action-workflows pin ([#5391](https://github.com/rapidsai/cuml/pull/5391)) [@divyegala](https://github.com/divyegala)\n- Fix logic for concatenating Treelite objects ([#5387](https://github.com/rapidsai/cuml/pull/5387)) [@hcho3](https://github.com/hcho3)\n- Dropping Python 3.8 ([#5385](https://github.com/rapidsai/cuml/pull/5385)) [@divyegala](https://github.com/divyegala)\n- Remove usage of rapids-get-rapids-version-from-git ([#5379](https://github.com/rapidsai/cuml/pull/5379)) [@jjacobelli](https://github.com/jjacobelli)\n- [ENH] Add missing includes of rmm/mr/device/per_device_resource.hpp ([#5369](https://github.com/rapidsai/cuml/pull/5369)) [@ahendriksen](https://github.com/ahendriksen)\n- Remove wheel pytest verbosity ([#5367](https://github.com/rapidsai/cuml/pull/5367)) [@sevagh](https://github.com/sevagh)\n- support parameter &#39;class_weight&#39; and method &#39;decision_function&#39; in LinearSVC ([#5364](https://github.com/rapidsai/cuml/pull/5364)) [@mfoerste4](https://github.com/mfoerste4)\n- Update clang-format to 16.0.1. ([#5361](https://github.com/rapidsai/cuml/pull/5361)) [@bdice](https://github.com/bdice)\n- Implement apply() in FIL ([#5358](https://github.com/rapidsai/cuml/pull/5358)) [@hcho3](https://github.com/hcho3)\n- Use ARC V2 self-hosted runners for GPU jobs ([#5356](https://github.com/rapidsai/cuml/pull/5356)) [@jjacobelli](https://github.com/jjacobelli)\n- Try running silhouette test ([#5353](https://github.com/rapidsai/cuml/pull/5353)) [@vyasr](https://github.com/vyasr)\n- Remove uses-setup-env-vars ([#5344](https://github.com/rapidsai/cuml/pull/5344)) [@vyasr](https://github.com/vyasr)\n- Resolve auto-merger conflicts between `branch-23.04` &amp; `branch-23.06` ([#5340](https://github.com/rapidsai/cuml/pull/5340)) [@galipremsagar](https://github.com/galipremsagar)\n- Solve merge conflict of PR #5327 ([#5329](https://github.com/rapidsai/cuml/pull/5329)) [@dantegd](https://github.com/dantegd)\n- Branch 23.06 merge 23.04 ([#5315](https://github.com/rapidsai/cuml/pull/5315)) [@vyasr](https://github.com/vyasr)\n- Support sparse input for SVC and SVR ([#5273](https://github.com/rapidsai/cuml/pull/5273)) [@mfoerste4](https://github.com/mfoerste4)\n- Delete outdated versions.json. ([#5229](https://github.com/rapidsai/cuml/pull/5229)) [@bdice](https://github.com/bdice)\n\n# cuML 23.04.00 (6 Apr 2023)\n\n## 🚨 Breaking Changes\n\n- Pin `dask` and `distributed` for release ([#5333](https://github.com/rapidsai/cuml/pull/5333)) [@galipremsagar](https://github.com/galipremsagar)\n\n## 🐛 Bug Fixes\n\n- Skip pickle notebook during nbsphinx ([#5342](https://github.com/rapidsai/cuml/pull/5342)) [@dantegd](https://github.com/dantegd)\n- Avoid race condition in FIL predict_per_tree ([#5334](https://github.com/rapidsai/cuml/pull/5334)) [@wphicks](https://github.com/wphicks)\n- Ensure experimental FIL shmem usage is below device limits ([#5326](https://github.com/rapidsai/cuml/pull/5326)) [@wphicks](https://github.com/wphicks)\n- Update cuda architectures for threads per sm restriction ([#5323](https://github.com/rapidsai/cuml/pull/5323)) [@wphicks](https://github.com/wphicks)\n- Run experimental FIL tests in CI ([#5316](https://github.com/rapidsai/cuml/pull/5316)) [@wphicks](https://github.com/wphicks)\n- Run memory leak pytests without parallelism to avoid sporadic test failures ([#5313](https://github.com/rapidsai/cuml/pull/5313)) [@dantegd](https://github.com/dantegd)\n- Update cupy version for pip wheels ([#5311](https://github.com/rapidsai/cuml/pull/5311)) [@dantegd](https://github.com/dantegd)\n- Fix for raising attributeerors erroneously for ipython methods ([#5299](https://github.com/rapidsai/cuml/pull/5299)) [@dantegd](https://github.com/dantegd)\n- Fix cuml local cpp docs build ([#5297](https://github.com/rapidsai/cuml/pull/5297)) [@galipremsagar](https://github.com/galipremsagar)\n- Don&#39;t run dask tests twice when testing wheels ([#5279](https://github.com/rapidsai/cuml/pull/5279)) [@benfred](https://github.com/benfred)\n- Remove MANIFEST.in use auto-generated one for sdists and package_data for wheels ([#5278](https://github.com/rapidsai/cuml/pull/5278)) [@vyasr](https://github.com/vyasr)\n- Removing remaining include of `raft/distance/distance_type.hpp` ([#5264](https://github.com/rapidsai/cuml/pull/5264)) [@cjnolet](https://github.com/cjnolet)\n- Enable hypothesis testing for nightly test runs. ([#5244](https://github.com/rapidsai/cuml/pull/5244)) [@csadorf](https://github.com/csadorf)\n- Support numeric, boolean, and string keyword arguments to class methods during CPU dispatching ([#5236](https://github.com/rapidsai/cuml/pull/5236)) [@beckernick](https://github.com/beckernick)\n- Allowing large data in kmeans ([#5228](https://github.com/rapidsai/cuml/pull/5228)) [@cjnolet](https://github.com/cjnolet)\n\n## 📖 Documentation\n\n- Fix docs build to be `pydata-sphinx-theme=0.13.0` compatible ([#5259](https://github.com/rapidsai/cuml/pull/5259)) [@galipremsagar](https://github.com/galipremsagar)\n- Add supported CPU/GPU operators to API docs and update docstrings ([#5239](https://github.com/rapidsai/cuml/pull/5239)) [@beckernick](https://github.com/beckernick)\n- Fix documentation author ([#5126](https://github.com/rapidsai/cuml/pull/5126)) [@bdice](https://github.com/bdice)\n\n## 🚀 New Features\n\n- Modify default batch size in HDBSCAN soft clustering ([#5335](https://github.com/rapidsai/cuml/pull/5335)) [@tarang-jain](https://github.com/tarang-jain)\n- reduce memory pressure in membership vector computation ([#5268](https://github.com/rapidsai/cuml/pull/5268)) [@tarang-jain](https://github.com/tarang-jain)\n- membership_vector for HDBSCAN ([#5247](https://github.com/rapidsai/cuml/pull/5247)) [@tarang-jain](https://github.com/tarang-jain)\n- Provide FIL implementation for both CPU and GPU ([#4890](https://github.com/rapidsai/cuml/pull/4890)) [@wphicks](https://github.com/wphicks)\n\n## 🛠️ Improvements\n\n- Remove deprecated Treelite CI API from FIL ([#5348](https://github.com/rapidsai/cuml/pull/5348)) [@hcho3](https://github.com/hcho3)\n- Updated forest inference to new dask worker api for 23.04 ([#5347](https://github.com/rapidsai/cuml/pull/5347)) [@taureandyernv](https://github.com/taureandyernv)\n- Pin `dask` and `distributed` for release ([#5333](https://github.com/rapidsai/cuml/pull/5333)) [@galipremsagar](https://github.com/galipremsagar)\n- Pin cupy in wheel tests to supported versions ([#5312](https://github.com/rapidsai/cuml/pull/5312)) [@vyasr](https://github.com/vyasr)\n- Drop `pickle5` ([#5310](https://github.com/rapidsai/cuml/pull/5310)) [@jakirkham](https://github.com/jakirkham)\n- Remove CUDA_CHECK macro ([#5308](https://github.com/rapidsai/cuml/pull/5308)) [@hcho3](https://github.com/hcho3)\n- Revert faiss removal pinned tag ([#5306](https://github.com/rapidsai/cuml/pull/5306)) [@cjnolet](https://github.com/cjnolet)\n- Upgrade to Treelite 3.2.0 ([#5304](https://github.com/rapidsai/cuml/pull/5304)) [@hcho3](https://github.com/hcho3)\n- Implement predict_per_tree() in FIL ([#5303](https://github.com/rapidsai/cuml/pull/5303)) [@hcho3](https://github.com/hcho3)\n- remove faiss from cuml ([#5293](https://github.com/rapidsai/cuml/pull/5293)) [@benfred](https://github.com/benfred)\n- Stop setting package version attribute in wheels ([#5285](https://github.com/rapidsai/cuml/pull/5285)) [@vyasr](https://github.com/vyasr)\n- Add libfaiss runtime dependency to libcuml. ([#5284](https://github.com/rapidsai/cuml/pull/5284)) [@bdice](https://github.com/bdice)\n- Move faiss_mr from raft ([#5281](https://github.com/rapidsai/cuml/pull/5281)) [@benfred](https://github.com/benfred)\n- Generate pyproject dependencies with dfg ([#5275](https://github.com/rapidsai/cuml/pull/5275)) [@vyasr](https://github.com/vyasr)\n- Updating cuML to use consolidated RAFT libs ([#5272](https://github.com/rapidsai/cuml/pull/5272)) [@cjnolet](https://github.com/cjnolet)\n- Add codespell as a linter ([#5265](https://github.com/rapidsai/cuml/pull/5265)) [@benfred](https://github.com/benfred)\n- Pass `AWS_SESSION_TOKEN` and `SCCACHE_S3_USE_SSL` vars to conda build ([#5263](https://github.com/rapidsai/cuml/pull/5263)) [@ajschmidt8](https://github.com/ajschmidt8)\n- Update to GCC 11 ([#5258](https://github.com/rapidsai/cuml/pull/5258)) [@bdice](https://github.com/bdice)\n- Drop Python 3.7 handling for pickle protocol 4 ([#5256](https://github.com/rapidsai/cuml/pull/5256)) [@jakirkham](https://github.com/jakirkham)\n- Migrate as much as possible to pyproject.toml ([#5251](https://github.com/rapidsai/cuml/pull/5251)) [@vyasr](https://github.com/vyasr)\n- Adapt to rapidsai/rmm#1221 which moves allocator callbacks ([#5249](https://github.com/rapidsai/cuml/pull/5249)) [@wence-](https://github.com/wence-)\n- Add dfg as a pre-commit hook. ([#5246](https://github.com/rapidsai/cuml/pull/5246)) [@vyasr](https://github.com/vyasr)\n- Stop using versioneer to manage versions ([#5245](https://github.com/rapidsai/cuml/pull/5245)) [@vyasr](https://github.com/vyasr)\n- Enhance cuML benchmark utility and refactor hdbscan import utilities ([#5242](https://github.com/rapidsai/cuml/pull/5242)) [@beckernick](https://github.com/beckernick)\n- Fix GHA build workflow ([#5241](https://github.com/rapidsai/cuml/pull/5241)) [@AjayThorve](https://github.com/AjayThorve)\n- Support innerproduct distance in the pairwise_distance API ([#5230](https://github.com/rapidsai/cuml/pull/5230)) [@benfred](https://github.com/benfred)\n- Enable hypothesis for 23.04 ([#5221](https://github.com/rapidsai/cuml/pull/5221)) [@csadorf](https://github.com/csadorf)\n- Reduce error handling verbosity in CI tests scripts ([#5219](https://github.com/rapidsai/cuml/pull/5219)) [@AjayThorve](https://github.com/AjayThorve)\n- Bump pinned pip wheel deps to 23.4 ([#5217](https://github.com/rapidsai/cuml/pull/5217)) [@sevagh](https://github.com/sevagh)\n- Update shared workflow branches ([#5215](https://github.com/rapidsai/cuml/pull/5215)) [@ajschmidt8](https://github.com/ajschmidt8)\n- Unpin `dask` and `distributed` for development ([#5209](https://github.com/rapidsai/cuml/pull/5209)) [@galipremsagar](https://github.com/galipremsagar)\n- Remove gpuCI scripts. ([#5208](https://github.com/rapidsai/cuml/pull/5208)) [@bdice](https://github.com/bdice)\n- Move date to build string in `conda` recipe ([#5190](https://github.com/rapidsai/cuml/pull/5190)) [@ajschmidt8](https://github.com/ajschmidt8)\n- Kernel shap improvements ([#5187](https://github.com/rapidsai/cuml/pull/5187)) [@vinaydes](https://github.com/vinaydes)\n- test out the raft bfknn replacement ([#5186](https://github.com/rapidsai/cuml/pull/5186)) [@benfred](https://github.com/benfred)\n- Forward merge 23.02 into 23.04 ([#5182](https://github.com/rapidsai/cuml/pull/5182)) [@vyasr](https://github.com/vyasr)\n- Add `detail` namespace for linear models ([#5107](https://github.com/rapidsai/cuml/pull/5107)) [@lowener](https://github.com/lowener)\n- Add pre-commit configuration ([#4983](https://github.com/rapidsai/cuml/pull/4983)) [@csadorf](https://github.com/csadorf)\n\n# cuML 23.02.00 (9 Feb 2023)\n\n## 🚨 Breaking Changes\n\n- Use ivf_pq and ivf_flat from raft ([#5119](https://github.com/rapidsai/cuml/pull/5119)) [@benfred](https://github.com/benfred)\n- Estimators adaptation toward CPU/GPU interoperability ([#4918](https://github.com/rapidsai/cuml/pull/4918)) [@viclafargue](https://github.com/viclafargue)\n- Provide host CumlArray and associated infrastructure ([#4908](https://github.com/rapidsai/cuml/pull/4908)) [@wphicks](https://github.com/wphicks)\n- Improvements of UMAP/TSNE precomputed KNN feature ([#4865](https://github.com/rapidsai/cuml/pull/4865)) [@viclafargue](https://github.com/viclafargue)\n\n## 🐛 Bug Fixes\n\n- Fix for creation of CUDA context at import time ([#5211](https://github.com/rapidsai/cuml/pull/5211)) [@dantegd](https://github.com/dantegd)\n- Correct arguments to load_from_treelite_model after classmethod conversion ([#5210](https://github.com/rapidsai/cuml/pull/5210)) [@wphicks](https://github.com/wphicks)\n- Use workaround to avoid staticmethod 3.10/Cython issue ([#5202](https://github.com/rapidsai/cuml/pull/5202)) [@wphicks](https://github.com/wphicks)\n- Increase margin for flaky FIL test ([#5194](https://github.com/rapidsai/cuml/pull/5194)) [@wphicks](https://github.com/wphicks)\n- Increase margin for flaky FIL test ([#5174](https://github.com/rapidsai/cuml/pull/5174)) [@wphicks](https://github.com/wphicks)\n- Fix gather_if raft update ([#5149](https://github.com/rapidsai/cuml/pull/5149)) [@lowener](https://github.com/lowener)\n- Add `_predict_model_on_cpu` for `RandomForestClassifier` ([#5148](https://github.com/rapidsai/cuml/pull/5148)) [@lowener](https://github.com/lowener)\n- Fix for hdbscan model serialization ([#5128](https://github.com/rapidsai/cuml/pull/5128)) [@cjnolet](https://github.com/cjnolet)\n- build.sh switch to use `RAPIDS` magic value ([#5124](https://github.com/rapidsai/cuml/pull/5124)) [@robertmaynard](https://github.com/robertmaynard)\n- Fix `Lasso` interop issue ([#5116](https://github.com/rapidsai/cuml/pull/5116)) [@viclafargue](https://github.com/viclafargue)\n- Remove nvcc conda package and add compiler/ninja to dev envs ([#5113](https://github.com/rapidsai/cuml/pull/5113)) [@dantegd](https://github.com/dantegd)\n- Add missing job dependency for new PR jobs check ([#5112](https://github.com/rapidsai/cuml/pull/5112)) [@dantegd](https://github.com/dantegd)\n- Skip RAFT docstring test in cuML ([#5088](https://github.com/rapidsai/cuml/pull/5088)) [@dantegd](https://github.com/dantegd)\n- Restore KNN metric attribute ([#5087](https://github.com/rapidsai/cuml/pull/5087)) [@viclafargue](https://github.com/viclafargue)\n- Check `sklearn` presence before importing the `Pipeline` ([#5072](https://github.com/rapidsai/cuml/pull/5072)) [@viclafargue](https://github.com/viclafargue)\n- Provide workaround for kernel ridge solver ([#5064](https://github.com/rapidsai/cuml/pull/5064)) [@wphicks](https://github.com/wphicks)\n- Keep verbosity level in KMeans OPG ([#5063](https://github.com/rapidsai/cuml/pull/5063)) [@viclafargue](https://github.com/viclafargue)\n- Transmit verbosity level to Dask workers ([#5062](https://github.com/rapidsai/cuml/pull/5062)) [@viclafargue](https://github.com/viclafargue)\n- Ensure consistent order for nearest neighbor tests ([#5059](https://github.com/rapidsai/cuml/pull/5059)) [@wphicks](https://github.com/wphicks)\n- Add `workers` argument to dask `make_blobs` ([#5057](https://github.com/rapidsai/cuml/pull/5057)) [@viclafargue](https://github.com/viclafargue)\n- Fix indexing type for ridge and linear models ([#4996](https://github.com/rapidsai/cuml/pull/4996)) [@lowener](https://github.com/lowener)\n\n## 📖 Documentation\n\n- Adding benchmark notebook for hdbscan soft clustering ([#5103](https://github.com/rapidsai/cuml/pull/5103)) [@cjnolet](https://github.com/cjnolet)\n- Fix doc for solver in LogisticRegression ([#5097](https://github.com/rapidsai/cuml/pull/5097)) [@viclafargue](https://github.com/viclafargue)\n- Fix docstring of `HashingVectorizer` ([#5041](https://github.com/rapidsai/cuml/pull/5041)) [@lowener](https://github.com/lowener)\n- expose text, text.{CountVectorizer,HashingVectorizer,Tfidf{Transformer,Vectorizer}} from feature_extraction&#39;s public api ([#5028](https://github.com/rapidsai/cuml/pull/5028)) [@mattf](https://github.com/mattf)\n- Add Dask LabelEncoder to the documentation ([#5023](https://github.com/rapidsai/cuml/pull/5023)) [@beckernick](https://github.com/beckernick)\n\n## 🚀 New Features\n\n- HDBSCAN CPU/GPU Interop ([#5137](https://github.com/rapidsai/cuml/pull/5137)) [@divyegala](https://github.com/divyegala)\n- Make all CPU/GPU only imports &quot;safe&quot; for respective package ([#5117](https://github.com/rapidsai/cuml/pull/5117)) [@wphicks](https://github.com/wphicks)\n- Pickling for HBDSCAN ([#5102](https://github.com/rapidsai/cuml/pull/5102)) [@divyegala](https://github.com/divyegala)\n- Break up silhouette score into 3 units to improve compilation time ([#5061](https://github.com/rapidsai/cuml/pull/5061)) [@wphicks](https://github.com/wphicks)\n- Provide host CumlArray and associated infrastructure ([#4908](https://github.com/rapidsai/cuml/pull/4908)) [@wphicks](https://github.com/wphicks)\n\n## 🛠️ Improvements\n\n- Pin `dask` and `distributed` for release ([#5198](https://github.com/rapidsai/cuml/pull/5198)) [@galipremsagar](https://github.com/galipremsagar)\n- Update shared workflow branches ([#5197](https://github.com/rapidsai/cuml/pull/5197)) [@ajschmidt8](https://github.com/ajschmidt8)\n- Pin wheel dependencies to same RAPIDS release ([#5183](https://github.com/rapidsai/cuml/pull/5183)) [@sevagh](https://github.com/sevagh)\n- Reverting RAFT pin ([#5178](https://github.com/rapidsai/cuml/pull/5178)) [@cjnolet](https://github.com/cjnolet)\n- Remove `faiss` from `libcuml` ([#5175](https://github.com/rapidsai/cuml/pull/5175)) [@ajschmidt8](https://github.com/ajschmidt8)\n- Update location of `import_utils` from `common` to `internals` for Forest notebook ([#5171](https://github.com/rapidsai/cuml/pull/5171)) [@taureandyernv](https://github.com/taureandyernv)\n- Disable hypothesis tests for 23.02 burndown. ([#5168](https://github.com/rapidsai/cuml/pull/5168)) [@csadorf](https://github.com/csadorf)\n- Use CTK 118/cp310 branch of wheel workflows ([#5163](https://github.com/rapidsai/cuml/pull/5163)) [@sevagh](https://github.com/sevagh)\n- Add docs build GH ([#5155](https://github.com/rapidsai/cuml/pull/5155)) [@AjayThorve](https://github.com/AjayThorve)\n- Adapt to changes in `cudf.core.buffer.Buffer` ([#5154](https://github.com/rapidsai/cuml/pull/5154)) [@galipremsagar](https://github.com/galipremsagar)\n- Upgrade Treelite to 3.1.0 ([#5146](https://github.com/rapidsai/cuml/pull/5146)) [@hcho3](https://github.com/hcho3)\n- Replace cpdef variables with cdef variables. ([#5145](https://github.com/rapidsai/cuml/pull/5145)) [@bdice](https://github.com/bdice)\n- Update Scikit-learn compatibility to 1.2 ([#5141](https://github.com/rapidsai/cuml/pull/5141)) [@dantegd](https://github.com/dantegd)\n- Replace deprecated raft headers ([#5134](https://github.com/rapidsai/cuml/pull/5134)) [@lowener](https://github.com/lowener)\n- Execution device interoperability documentation ([#5130](https://github.com/rapidsai/cuml/pull/5130)) [@viclafargue](https://github.com/viclafargue)\n- Remove outdated macOS deployment target from build script. ([#5125](https://github.com/rapidsai/cuml/pull/5125)) [@bdice](https://github.com/bdice)\n- Build CUDA 11.8 and Python 3.10 Packages ([#5120](https://github.com/rapidsai/cuml/pull/5120)) [@bdice](https://github.com/bdice)\n- Use ivf_pq and ivf_flat from raft ([#5119](https://github.com/rapidsai/cuml/pull/5119)) [@benfred](https://github.com/benfred)\n- Update workflows for nightly tests ([#5110](https://github.com/rapidsai/cuml/pull/5110)) [@ajschmidt8](https://github.com/ajschmidt8)\n- Build pip wheels alongside conda CI ([#5109](https://github.com/rapidsai/cuml/pull/5109)) [@sevagh](https://github.com/sevagh)\n- Remove PROJECT_FLASH from libcuml conda build environment. ([#5108](https://github.com/rapidsai/cuml/pull/5108)) [@bdice](https://github.com/bdice)\n- Enable `Recently Updated` Check ([#5105](https://github.com/rapidsai/cuml/pull/5105)) [@ajschmidt8](https://github.com/ajschmidt8)\n- Ensure `pytest` is run from relevant directories in GH Actions ([#5101](https://github.com/rapidsai/cuml/pull/5101)) [@ajschmidt8](https://github.com/ajschmidt8)\n- Remove C++ Kmeans test ([#5098](https://github.com/rapidsai/cuml/pull/5098)) [@lowener](https://github.com/lowener)\n- Slightly lower the test_mbsgd_regressor expected min score. ([#5092](https://github.com/rapidsai/cuml/pull/5092)) [@csadorf](https://github.com/csadorf)\n- Skip all hypothesis health checks by default in CI runs. ([#5090](https://github.com/rapidsai/cuml/pull/5090)) [@csadorf](https://github.com/csadorf)\n- Reduce Naive Bayes test time ([#5082](https://github.com/rapidsai/cuml/pull/5082)) [@lowener](https://github.com/lowener)\n- Remove unused `.conda` folder ([#5078](https://github.com/rapidsai/cuml/pull/5078)) [@ajschmidt8](https://github.com/ajschmidt8)\n- Fix conflicts in #5045 ([#5077](https://github.com/rapidsai/cuml/pull/5077)) [@ajschmidt8](https://github.com/ajschmidt8)\n- Add GitHub Actions Workflows ([#5075](https://github.com/rapidsai/cuml/pull/5075)) [@csadorf](https://github.com/csadorf)\n- Skip test_linear_regression_model_default test. ([#5074](https://github.com/rapidsai/cuml/pull/5074)) [@csadorf](https://github.com/csadorf)\n- Fix link. ([#5067](https://github.com/rapidsai/cuml/pull/5067)) [@bdice](https://github.com/bdice)\n- Expand hypothesis testing for linear models ([#5065](https://github.com/rapidsai/cuml/pull/5065)) [@csadorf](https://github.com/csadorf)\n- Update xgb version in GPU CI 23.02 to 1.7.1 and unblocking CI ([#5051](https://github.com/rapidsai/cuml/pull/5051)) [@dantegd](https://github.com/dantegd)\n- Remove direct UCX and NCCL dependencies ([#5038](https://github.com/rapidsai/cuml/pull/5038)) [@vyasr](https://github.com/vyasr)\n- Move single test from `test` to `tests` ([#5037](https://github.com/rapidsai/cuml/pull/5037)) [@vyasr](https://github.com/vyasr)\n- Support using `CountVectorizer` &amp; `TfidVectorizer` in `cuml.pipeline.Pipeline` ([#5034](https://github.com/rapidsai/cuml/pull/5034)) [@lasse-it](https://github.com/lasse-it)\n- Refactor API decorators ([#5026](https://github.com/rapidsai/cuml/pull/5026)) [@csadorf](https://github.com/csadorf)\n- Implement hypothesis strategies and tests for arrays ([#5017](https://github.com/rapidsai/cuml/pull/5017)) [@csadorf](https://github.com/csadorf)\n- Add dependencies.yaml for rapids-dependency-file-generator ([#5003](https://github.com/rapidsai/cuml/pull/5003)) [@beckernick](https://github.com/beckernick)\n- Improved CPU/GPU interoperability ([#5001](https://github.com/rapidsai/cuml/pull/5001)) [@viclafargue](https://github.com/viclafargue)\n- Estimators adaptation toward CPU/GPU interoperability ([#4918](https://github.com/rapidsai/cuml/pull/4918)) [@viclafargue](https://github.com/viclafargue)\n- Improvements of UMAP/TSNE precomputed KNN feature ([#4865](https://github.com/rapidsai/cuml/pull/4865)) [@viclafargue](https://github.com/viclafargue)\n\n# cuML 22.12.00 (8 Dec 2022)\n\n## 🚨 Breaking Changes\n\n- Change docs theme to `pydata-sphinx` theme ([#4985](https://github.com/rapidsai/cuml/pull/4985)) [@galipremsagar](https://github.com/galipremsagar)\n- Remove &quot;Open In Colab&quot; link from Estimator Intro notebook. ([#4980](https://github.com/rapidsai/cuml/pull/4980)) [@bdice](https://github.com/bdice)\n- Remove `CumlArray.copy()` ([#4958](https://github.com/rapidsai/cuml/pull/4958)) [@madsbk](https://github.com/madsbk)\n\n## 🐛 Bug Fixes\n\n- Remove cupy.cusparse custom serialization ([#5024](https://github.com/rapidsai/cuml/pull/5024)) [@dantegd](https://github.com/dantegd)\n- Restore `LinearRegression` documentation ([#5020](https://github.com/rapidsai/cuml/pull/5020)) [@viclafargue](https://github.com/viclafargue)\n- Don&#39;t use CMake 3.25.0 as it has a FindCUDAToolkit show stopping bug ([#5007](https://github.com/rapidsai/cuml/pull/5007)) [@robertmaynard](https://github.com/robertmaynard)\n- verifying cusparse wrapper revert passes CI ([#4990](https://github.com/rapidsai/cuml/pull/4990)) [@cjnolet](https://github.com/cjnolet)\n- Use rapdsi_cpm_find(COMPONENTS ) for proper component tracking ([#4989](https://github.com/rapidsai/cuml/pull/4989)) [@robertmaynard](https://github.com/robertmaynard)\n- Fix integer overflow in AutoARIMA due to bool-to-int cub scan ([#4971](https://github.com/rapidsai/cuml/pull/4971)) [@Nyrio](https://github.com/Nyrio)\n- Add missing includes ([#4947](https://github.com/rapidsai/cuml/pull/4947)) [@vyasr](https://github.com/vyasr)\n- Fix the CMake option for disabling deprecation warnings. ([#4946](https://github.com/rapidsai/cuml/pull/4946)) [@vyasr](https://github.com/vyasr)\n- Make doctest resilient to changes in cupy reprs ([#4945](https://github.com/rapidsai/cuml/pull/4945)) [@vyasr](https://github.com/vyasr)\n- Assign python/ sub-directory to python-codeowners ([#4940](https://github.com/rapidsai/cuml/pull/4940)) [@csadorf](https://github.com/csadorf)\n- Fix for non-contiguous strides ([#4736](https://github.com/rapidsai/cuml/pull/4736)) [@viclafargue](https://github.com/viclafargue)\n\n## 📖 Documentation\n\n- Change docs theme to `pydata-sphinx` theme ([#4985](https://github.com/rapidsai/cuml/pull/4985)) [@galipremsagar](https://github.com/galipremsagar)\n- Remove &quot;Open In Colab&quot; link from Estimator Intro notebook. ([#4980](https://github.com/rapidsai/cuml/pull/4980)) [@bdice](https://github.com/bdice)\n- Updating build instructions ([#4979](https://github.com/rapidsai/cuml/pull/4979)) [@cjnolet](https://github.com/cjnolet)\n\n## 🚀 New Features\n\n- Reenable copy_prs. ([#5010](https://github.com/rapidsai/cuml/pull/5010)) [@vyasr](https://github.com/vyasr)\n- Add wheel builds ([#5009](https://github.com/rapidsai/cuml/pull/5009)) [@vyasr](https://github.com/vyasr)\n- LinearRegression: add support for multiple targets ([#4988](https://github.com/rapidsai/cuml/pull/4988)) [@ahendriksen](https://github.com/ahendriksen)\n- CPU/GPU interoperability POC ([#4874](https://github.com/rapidsai/cuml/pull/4874)) [@viclafargue](https://github.com/viclafargue)\n\n## 🛠️ Improvements\n\n- Upgrade Treelite to 3.0.1 ([#5018](https://github.com/rapidsai/cuml/pull/5018)) [@hcho3](https://github.com/hcho3)\n- fix addition of nan_euclidean_distances to public api ([#5015](https://github.com/rapidsai/cuml/pull/5015)) [@mattf](https://github.com/mattf)\n- Fixing raft pin to 22.12 ([#5000](https://github.com/rapidsai/cuml/pull/5000)) [@cjnolet](https://github.com/cjnolet)\n- Pin `dask` and `distributed` for release ([#4999](https://github.com/rapidsai/cuml/pull/4999)) [@galipremsagar](https://github.com/galipremsagar)\n- Update `dask` nightly install command in CI ([#4978](https://github.com/rapidsai/cuml/pull/4978)) [@galipremsagar](https://github.com/galipremsagar)\n- Improve error message for array_equal asserts. ([#4973](https://github.com/rapidsai/cuml/pull/4973)) [@csadorf](https://github.com/csadorf)\n- Use new rapids-cmake functionality for rpath handling. ([#4966](https://github.com/rapidsai/cuml/pull/4966)) [@vyasr](https://github.com/vyasr)\n- Impl. `CumlArray.deserialize()` ([#4965](https://github.com/rapidsai/cuml/pull/4965)) [@madsbk](https://github.com/madsbk)\n- Update `cuda-python` dependency to 11.7.1 ([#4961](https://github.com/rapidsai/cuml/pull/4961)) [@galipremsagar](https://github.com/galipremsagar)\n- Add check for nsys utility version in the `nvtx_benchmarks.py` script ([#4959](https://github.com/rapidsai/cuml/pull/4959)) [@viclafargue](https://github.com/viclafargue)\n- Remove `CumlArray.copy()` ([#4958](https://github.com/rapidsai/cuml/pull/4958)) [@madsbk](https://github.com/madsbk)\n- Implement hypothesis-based tests for linear models ([#4952](https://github.com/rapidsai/cuml/pull/4952)) [@csadorf](https://github.com/csadorf)\n- Switch to using rapids-cmake for gbench. ([#4950](https://github.com/rapidsai/cuml/pull/4950)) [@vyasr](https://github.com/vyasr)\n- Remove stale labeler ([#4949](https://github.com/rapidsai/cuml/pull/4949)) [@raydouglass](https://github.com/raydouglass)\n- Fix url in python/setup.py setuptools metadata. ([#4937](https://github.com/rapidsai/cuml/pull/4937)) [@csadorf](https://github.com/csadorf)\n- Updates to fix cuml build ([#4928](https://github.com/rapidsai/cuml/pull/4928)) [@cjnolet](https://github.com/cjnolet)\n- Documenting hdbscan module to add prediction functions ([#4925](https://github.com/rapidsai/cuml/pull/4925)) [@cjnolet](https://github.com/cjnolet)\n- Unpin `dask` and `distributed` for development ([#4912](https://github.com/rapidsai/cuml/pull/4912)) [@galipremsagar](https://github.com/galipremsagar)\n- Use KMeans from Raft ([#4713](https://github.com/rapidsai/cuml/pull/4713)) [@lowener](https://github.com/lowener)\n- Update cuml raft header extensions ([#4599](https://github.com/rapidsai/cuml/pull/4599)) [@cjnolet](https://github.com/cjnolet)\n- Reconciling primitives moved to RAFT ([#4583](https://github.com/rapidsai/cuml/pull/4583)) [@cjnolet](https://github.com/cjnolet)\n\n# cuML 22.10.00 (12 Oct 2022)\n\n## 🐛 Bug Fixes\n\n- Skipping some hdbscan tests when cuda version is &lt;= 11.2. ([#4916](https://github.com/rapidsai/cuml/pull/4916)) [@cjnolet](https://github.com/cjnolet)\n- Fix HDBSCAN python namespace ([#4895](https://github.com/rapidsai/cuml/pull/4895)) [@cjnolet](https://github.com/cjnolet)\n- Cupy 11 fixes ([#4889](https://github.com/rapidsai/cuml/pull/4889)) [@dantegd](https://github.com/dantegd)\n- Fix small fp precision failure in linear regression doctest test ([#4884](https://github.com/rapidsai/cuml/pull/4884)) [@lowener](https://github.com/lowener)\n- Remove unused cuDF imports ([#4873](https://github.com/rapidsai/cuml/pull/4873)) [@beckernick](https://github.com/beckernick)\n- Update for thrust 1.17 and fixes to accommodate for cuDF Buffer refactor ([#4871](https://github.com/rapidsai/cuml/pull/4871)) [@dantegd](https://github.com/dantegd)\n- Use rapids-cmake 22.10 best practice for RAPIDS.cmake location ([#4862](https://github.com/rapidsai/cuml/pull/4862)) [@robertmaynard](https://github.com/robertmaynard)\n- Patch for nightly test&amp;bench ([#4840](https://github.com/rapidsai/cuml/pull/4840)) [@viclafargue](https://github.com/viclafargue)\n- Fixed Large memory requirements for SimpleImputer strategy median #4794 ([#4817](https://github.com/rapidsai/cuml/pull/4817)) [@erikrene](https://github.com/erikrene)\n- Transforms RandomForest estimators non-consecutive labels to consecutive labels where appropriate ([#4780](https://github.com/rapidsai/cuml/pull/4780)) [@VamsiTallam95](https://github.com/VamsiTallam95)\n\n## 📖 Documentation\n\n- Document that minimum required CMake version is now 3.23.1 ([#4899](https://github.com/rapidsai/cuml/pull/4899)) [@robertmaynard](https://github.com/robertmaynard)\n- Update KMeans notebook for clarity ([#4886](https://github.com/rapidsai/cuml/pull/4886)) [@beckernick](https://github.com/beckernick)\n\n## 🚀 New Features\n\n- Allow cupy 11 ([#4880](https://github.com/rapidsai/cuml/pull/4880)) [@galipremsagar](https://github.com/galipremsagar)\n- Add `sample_weight` to Coordinate Descent solver (Lasso and ElasticNet) ([#4867](https://github.com/rapidsai/cuml/pull/4867)) [@lowener](https://github.com/lowener)\n- Import treelite models into FIL in a different precision ([#4839](https://github.com/rapidsai/cuml/pull/4839)) [@canonizer](https://github.com/canonizer)\n- #4783 Added nan_euclidean distance metric to pairwise_distances ([#4797](https://github.com/rapidsai/cuml/pull/4797)) [@Sreekiran096](https://github.com/Sreekiran096)\n- `PowerTransformer`, `QuantileTransformer` and `KernelCenterer` ([#4755](https://github.com/rapidsai/cuml/pull/4755)) [@viclafargue](https://github.com/viclafargue)\n- Add &quot;median&quot; to TargetEncoder ([#4722](https://github.com/rapidsai/cuml/pull/4722)) [@daxiongshu](https://github.com/daxiongshu)\n- New Feature StratifiedKFold ([#3109](https://github.com/rapidsai/cuml/pull/3109)) [@daxiongshu](https://github.com/daxiongshu)\n\n## 🛠️ Improvements\n\n- Updating python to use pylibraft ([#4887](https://github.com/rapidsai/cuml/pull/4887)) [@cjnolet](https://github.com/cjnolet)\n- Upgrade Treelite to 3.0.0 ([#4885](https://github.com/rapidsai/cuml/pull/4885)) [@hcho3](https://github.com/hcho3)\n- Statically link all CUDA toolkit libraries ([#4881](https://github.com/rapidsai/cuml/pull/4881)) [@trxcllnt](https://github.com/trxcllnt)\n- approximate_predict function for HDBSCAN ([#4872](https://github.com/rapidsai/cuml/pull/4872)) [@tarang-jain](https://github.com/tarang-jain)\n- Pin `dask` and `distributed` for release ([#4859](https://github.com/rapidsai/cuml/pull/4859)) [@galipremsagar](https://github.com/galipremsagar)\n- Remove Raft deprecated headers ([#4858](https://github.com/rapidsai/cuml/pull/4858)) [@lowener](https://github.com/lowener)\n- Fix forward-merge conflicts ([#4857](https://github.com/rapidsai/cuml/pull/4857)) [@ajschmidt8](https://github.com/ajschmidt8)\n- Update the NVTX bench helper for the new nsys utility ([#4826](https://github.com/rapidsai/cuml/pull/4826)) [@viclafargue](https://github.com/viclafargue)\n- All points membership vector for HDBSCAN ([#4800](https://github.com/rapidsai/cuml/pull/4800)) [@tarang-jain](https://github.com/tarang-jain)\n- TSNE and UMAP allow several distance types ([#4779](https://github.com/rapidsai/cuml/pull/4779)) [@tarang-jain](https://github.com/tarang-jain)\n- Convert fp32 datasets to fp64 in ARIMA and AutoARIMA + update notebook to avoid deprecation warnings with positional parameters ([#4195](https://github.com/rapidsai/cuml/pull/4195)) [@Nyrio](https://github.com/Nyrio)\n\n# cuML 22.08.00 (17 Aug 2022)\n\n## 🚨 Breaking Changes\n\n- Update Python build to scikit-build ([#4818](https://github.com/rapidsai/cuml/pull/4818)) [@dantegd](https://github.com/dantegd)\n- Bump `xgboost` to `1.6.0` from `1.5.2` ([#4777](https://github.com/rapidsai/cuml/pull/4777)) [@galipremsagar](https://github.com/galipremsagar)\n\n## 🐛 Bug Fixes\n\n- Revert &quot;Allow CuPy 11&quot; ([#4847](https://github.com/rapidsai/cuml/pull/4847)) [@galipremsagar](https://github.com/galipremsagar)\n- Fix RAFT_NVTX option not set ([#4825](https://github.com/rapidsai/cuml/pull/4825)) [@achirkin](https://github.com/achirkin)\n- Fix KNN error message. ([#4782](https://github.com/rapidsai/cuml/pull/4782)) [@trivialfis](https://github.com/trivialfis)\n- Update raft pinnings in dev yml files ([#4778](https://github.com/rapidsai/cuml/pull/4778)) [@galipremsagar](https://github.com/galipremsagar)\n- Bump `xgboost` to `1.6.0` from `1.5.2` ([#4777](https://github.com/rapidsai/cuml/pull/4777)) [@galipremsagar](https://github.com/galipremsagar)\n- Fixes exception when using predict_proba on fitted Pipeline object with a ColumnTransformer step ([#4774](https://github.com/rapidsai/cuml/pull/4774)) [@VamsiTallam95](https://github.com/VamsiTallam95)\n- Regression errors failing with mixed data type combinations ([#4770](https://github.com/rapidsai/cuml/pull/4770)) [@shaswat-indian](https://github.com/shaswat-indian)\n\n## 📖 Documentation\n\n- Use common code in python docs and defer `js` loading ([#4852](https://github.com/rapidsai/cuml/pull/4852)) [@galipremsagar](https://github.com/galipremsagar)\n- Centralize common css &amp; js code in docs ([#4844](https://github.com/rapidsai/cuml/pull/4844)) [@galipremsagar](https://github.com/galipremsagar)\n- Add ComplementNB to the documentation ([#4805](https://github.com/rapidsai/cuml/pull/4805)) [@lowener](https://github.com/lowener)\n- Fix forward-merge branch-22.06 to branch-22.08 ([#4789](https://github.com/rapidsai/cuml/pull/4789)) [@divyegala](https://github.com/divyegala)\n\n## 🚀 New Features\n\n- Update Python build to scikit-build ([#4818](https://github.com/rapidsai/cuml/pull/4818)) [@dantegd](https://github.com/dantegd)\n- Vectorizers to accept Pandas Series as input ([#4811](https://github.com/rapidsai/cuml/pull/4811)) [@shaswat-indian](https://github.com/shaswat-indian)\n- Cython wrapper for v-measure ([#4785](https://github.com/rapidsai/cuml/pull/4785)) [@shaswat-indian](https://github.com/shaswat-indian)\n\n## 🛠️ Improvements\n\n- Pin `dask` &amp; `distributed` for release ([#4850](https://github.com/rapidsai/cuml/pull/4850)) [@galipremsagar](https://github.com/galipremsagar)\n- Allow CuPy 11 ([#4837](https://github.com/rapidsai/cuml/pull/4837)) [@jakirkham](https://github.com/jakirkham)\n- Remove duplicate adj_to_csr implementation ([#4829](https://github.com/rapidsai/cuml/pull/4829)) [@ahendriksen](https://github.com/ahendriksen)\n- Update conda environment files to UCX 1.13.0 ([#4813](https://github.com/rapidsai/cuml/pull/4813)) [@pentschev](https://github.com/pentschev)\n- Update conda recipes to UCX 1.13.0 ([#4809](https://github.com/rapidsai/cuml/pull/4809)) [@pentschev](https://github.com/pentschev)\n- Fix #3414: remove naive versions dbscan algorithms ([#4804](https://github.com/rapidsai/cuml/pull/4804)) [@ahendriksen](https://github.com/ahendriksen)\n- Accelerate adjacency matrix to CSR conversion for DBSCAN ([#4803](https://github.com/rapidsai/cuml/pull/4803)) [@ahendriksen](https://github.com/ahendriksen)\n- Pin max version of `cuda-python` to `11.7.0` ([#4793](https://github.com/rapidsai/cuml/pull/4793)) [@Ethyling](https://github.com/Ethyling)\n- Allow cosine distance metric in dbscan ([#4776](https://github.com/rapidsai/cuml/pull/4776)) [@tarang-jain](https://github.com/tarang-jain)\n- Unpin `dask` &amp; `distributed` for development ([#4771](https://github.com/rapidsai/cuml/pull/4771)) [@galipremsagar](https://github.com/galipremsagar)\n- Clean up Thrust includes. ([#4675](https://github.com/rapidsai/cuml/pull/4675)) [@bdice](https://github.com/bdice)\n- Improvements in feature sampling ([#4278](https://github.com/rapidsai/cuml/pull/4278)) [@vinaydes](https://github.com/vinaydes)\n\n# cuML 22.06.00 (7 Jun 2022)\n\n## 🐛 Bug Fixes\n\n- Fix sg benchmark build. ([#4766](https://github.com/rapidsai/cuml/pull/4766)) [@trivialfis](https://github.com/trivialfis)\n- Resolve KRR hypothesis test failure ([#4761](https://github.com/rapidsai/cuml/pull/4761)) [@RAMitchell](https://github.com/RAMitchell)\n- Fix `KBinsDiscretizer` `bin_edges_` ([#4735](https://github.com/rapidsai/cuml/pull/4735)) [@viclafargue](https://github.com/viclafargue)\n- FIX Accept small floats in RandomForest ([#4717](https://github.com/rapidsai/cuml/pull/4717)) [@thomasjpfan](https://github.com/thomasjpfan)\n- Remove import of `scalar_broadcast_to` from stemmer ([#4706](https://github.com/rapidsai/cuml/pull/4706)) [@viclafargue](https://github.com/viclafargue)\n- Replace 22.04.x with 22.06.x in yaml files ([#4692](https://github.com/rapidsai/cuml/pull/4692)) [@daxiongshu](https://github.com/daxiongshu)\n- Replace cudf.logical_not with ~ ([#4669](https://github.com/rapidsai/cuml/pull/4669)) [@canonizer](https://github.com/canonizer)\n\n## 📖 Documentation\n\n- Fix docs builds ([#4733](https://github.com/rapidsai/cuml/pull/4733)) [@ajschmidt8](https://github.com/ajschmidt8)\n- Change &quot;principals&quot; to &quot;principles&quot; ([#4695](https://github.com/rapidsai/cuml/pull/4695)) [@cakiki](https://github.com/cakiki)\n- Update pydoc and promote `ColumnTransformer` out of experimental ([#4509](https://github.com/rapidsai/cuml/pull/4509)) [@viclafargue](https://github.com/viclafargue)\n\n## 🚀 New Features\n\n- float64 support in FIL functions ([#4655](https://github.com/rapidsai/cuml/pull/4655)) [@canonizer](https://github.com/canonizer)\n- float64 support in FIL core ([#4646](https://github.com/rapidsai/cuml/pull/4646)) [@canonizer](https://github.com/canonizer)\n- Allow &quot;LabelEncoder&quot; to accept cupy and numpy arrays as input. ([#4620](https://github.com/rapidsai/cuml/pull/4620)) [@daxiongshu](https://github.com/daxiongshu)\n- MNMG Logistic Regression (dask-glm wrapper) ([#3512](https://github.com/rapidsai/cuml/pull/3512)) [@daxiongshu](https://github.com/daxiongshu)\n\n## 🛠️ Improvements\n\n- Pin `dask` &amp; `distributed` for release ([#4758](https://github.com/rapidsai/cuml/pull/4758)) [@galipremsagar](https://github.com/galipremsagar)\n- Simplicial set functions ([#4756](https://github.com/rapidsai/cuml/pull/4756)) [@viclafargue](https://github.com/viclafargue)\n- Upgrade Treelite to 2.4.0 ([#4752](https://github.com/rapidsai/cuml/pull/4752)) [@hcho3](https://github.com/hcho3)\n- Simplify recipes ([#4749](https://github.com/rapidsai/cuml/pull/4749)) [@Ethyling](https://github.com/Ethyling)\n- Inference for float64 random forests using FIL ([#4739](https://github.com/rapidsai/cuml/pull/4739)) [@canonizer](https://github.com/canonizer)\n- MNT Removes unused optim_batch_size from UMAP&#39;s docstring ([#4732](https://github.com/rapidsai/cuml/pull/4732)) [@thomasjpfan](https://github.com/thomasjpfan)\n- Require UCX 1.12.1+ ([#4720](https://github.com/rapidsai/cuml/pull/4720)) [@jakirkham](https://github.com/jakirkham)\n- Allow enabling raft NVTX markers when raft is installed ([#4718](https://github.com/rapidsai/cuml/pull/4718)) [@achirkin](https://github.com/achirkin)\n- Fix identifier collision ([#4716](https://github.com/rapidsai/cuml/pull/4716)) [@viclafargue](https://github.com/viclafargue)\n- Use raft::span in TreeExplainer ([#4714](https://github.com/rapidsai/cuml/pull/4714)) [@hcho3](https://github.com/hcho3)\n- Expose simplicial set functions ([#4711](https://github.com/rapidsai/cuml/pull/4711)) [@viclafargue](https://github.com/viclafargue)\n- Refactor `tests` in `cuml` ([#4703](https://github.com/rapidsai/cuml/pull/4703)) [@galipremsagar](https://github.com/galipremsagar)\n- Use conda to build python packages during GPU tests ([#4702](https://github.com/rapidsai/cuml/pull/4702)) [@Ethyling](https://github.com/Ethyling)\n- Update pinning to allow newer CMake versions. ([#4698](https://github.com/rapidsai/cuml/pull/4698)) [@vyasr](https://github.com/vyasr)\n- TreeExplainer extensions ([#4697](https://github.com/rapidsai/cuml/pull/4697)) [@RAMitchell](https://github.com/RAMitchell)\n- Add sample_weight for Ridge ([#4696](https://github.com/rapidsai/cuml/pull/4696)) [@lowener](https://github.com/lowener)\n- Unpin `dask` &amp; `distributed` for development ([#4693](https://github.com/rapidsai/cuml/pull/4693)) [@galipremsagar](https://github.com/galipremsagar)\n- float64 support in treelite-&gt;FIL import and Python layer ([#4690](https://github.com/rapidsai/cuml/pull/4690)) [@canonizer](https://github.com/canonizer)\n- Enable building static libs ([#4673](https://github.com/rapidsai/cuml/pull/4673)) [@trxcllnt](https://github.com/trxcllnt)\n- Treeshap hypothesis tests ([#4671](https://github.com/rapidsai/cuml/pull/4671)) [@RAMitchell](https://github.com/RAMitchell)\n- float64 support in multi-sum and child_index() ([#4648](https://github.com/rapidsai/cuml/pull/4648)) [@canonizer](https://github.com/canonizer)\n- Add libcuml-tests package ([#4635](https://github.com/rapidsai/cuml/pull/4635)) [@Ethyling](https://github.com/Ethyling)\n- Random ball cover algorithm for 3D data ([#4582](https://github.com/rapidsai/cuml/pull/4582)) [@cjnolet](https://github.com/cjnolet)\n- Use conda compilers ([#4577](https://github.com/rapidsai/cuml/pull/4577)) [@Ethyling](https://github.com/Ethyling)\n- Build packages using mambabuild ([#4542](https://github.com/rapidsai/cuml/pull/4542)) [@Ethyling](https://github.com/Ethyling)\n\n# cuML 22.04.00 (6 Apr 2022)\n\n## 🚨 Breaking Changes\n\n- Moving more ling prims to raft ([#4567](https://github.com/rapidsai/cuml/pull/4567)) [@cjnolet](https://github.com/cjnolet)\n- Refactor QN solver: pass parameters via a POD struct ([#4511](https://github.com/rapidsai/cuml/pull/4511)) [@achirkin](https://github.com/achirkin)\n\n## 🐛 Bug Fixes\n\n- Fix single-GPU build by separating multi-GPU decomposition utils from single GPU ([#4645](https://github.com/rapidsai/cuml/pull/4645)) [@dantegd](https://github.com/dantegd)\n- RF: fix stream bug causing performance regressions ([#4644](https://github.com/rapidsai/cuml/pull/4644)) [@venkywonka](https://github.com/venkywonka)\n- XFail test_hinge_loss temporarily ([#4621](https://github.com/rapidsai/cuml/pull/4621)) [@lowener](https://github.com/lowener)\n- cuml now supports building non static treelite ([#4598](https://github.com/rapidsai/cuml/pull/4598)) [@robertmaynard](https://github.com/robertmaynard)\n- Fix mean_squared_error with cudf series ([#4584](https://github.com/rapidsai/cuml/pull/4584)) [@daxiongshu](https://github.com/daxiongshu)\n- Fix for nightly CI tests: Use CUDA_REL variable in gpu build.sh script ([#4581](https://github.com/rapidsai/cuml/pull/4581)) [@dantegd](https://github.com/dantegd)\n- Fix the TargetEncoder when transforming dataframe/series with custom index ([#4578](https://github.com/rapidsai/cuml/pull/4578)) [@daxiongshu](https://github.com/daxiongshu)\n- Removing sign from pca assertions for now. ([#4559](https://github.com/rapidsai/cuml/pull/4559)) [@cjnolet](https://github.com/cjnolet)\n- Fix compatibility of OneHotEncoder fit ([#4544](https://github.com/rapidsai/cuml/pull/4544)) [@lowener](https://github.com/lowener)\n- Fix worker streams in OLS-eig executing in an unsafe order ([#4539](https://github.com/rapidsai/cuml/pull/4539)) [@achirkin](https://github.com/achirkin)\n- Remove xfail from test_hinge_loss ([#4504](https://github.com/rapidsai/cuml/pull/4504)) [@Nanthini10](https://github.com/Nanthini10)\n- Fix automerge #4501 ([#4502](https://github.com/rapidsai/cuml/pull/4502)) [@dantegd](https://github.com/dantegd)\n- Remove classmethod of SimpleImputer ([#4439](https://github.com/rapidsai/cuml/pull/4439)) [@lowener](https://github.com/lowener)\n\n## 📖 Documentation\n\n- RF: Fix improper documentation in dask-RF ([#4666](https://github.com/rapidsai/cuml/pull/4666)) [@venkywonka](https://github.com/venkywonka)\n- Add doctest ([#4618](https://github.com/rapidsai/cuml/pull/4618)) [@lowener](https://github.com/lowener)\n- Fix document layouts in Parameters sections ([#4609](https://github.com/rapidsai/cuml/pull/4609)) [@Yosshi999](https://github.com/Yosshi999)\n- Updates to consistency of MNMG PCA/TSVD solvers (docs + code consolidation) ([#4556](https://github.com/rapidsai/cuml/pull/4556)) [@cjnolet](https://github.com/cjnolet)\n\n## 🚀 New Features\n\n- Add a dummy argument `deep` to `TargetEncoder.get_params()` ([#4601](https://github.com/rapidsai/cuml/pull/4601)) [@daxiongshu](https://github.com/daxiongshu)\n- Add Complement Naive Bayes ([#4595](https://github.com/rapidsai/cuml/pull/4595)) [@lowener](https://github.com/lowener)\n- Add get_params() to TargetEncoder ([#4588](https://github.com/rapidsai/cuml/pull/4588)) [@daxiongshu](https://github.com/daxiongshu)\n- Target Encoder with variance statistics ([#4483](https://github.com/rapidsai/cuml/pull/4483)) [@daxiongshu](https://github.com/daxiongshu)\n- Interruptible execution ([#4463](https://github.com/rapidsai/cuml/pull/4463)) [@achirkin](https://github.com/achirkin)\n- Configurable libcuml++ per algorithm ([#4296](https://github.com/rapidsai/cuml/pull/4296)) [@dantegd](https://github.com/dantegd)\n\n## 🛠️ Improvements\n\n- Adding some prints when hdbscan assertion fails ([#4656](https://github.com/rapidsai/cuml/pull/4656)) [@cjnolet](https://github.com/cjnolet)\n- Temporarily disable new `ops-bot` functionality ([#4652](https://github.com/rapidsai/cuml/pull/4652)) [@ajschmidt8](https://github.com/ajschmidt8)\n- Use CPMFindPackage to retrieve `cumlprims_mg` ([#4649](https://github.com/rapidsai/cuml/pull/4649)) [@trxcllnt](https://github.com/trxcllnt)\n- Pin `dask` &amp; `distributed` versions ([#4647](https://github.com/rapidsai/cuml/pull/4647)) [@galipremsagar](https://github.com/galipremsagar)\n- Remove RAFT MM includes ([#4637](https://github.com/rapidsai/cuml/pull/4637)) [@viclafargue](https://github.com/viclafargue)\n- Add option to build RAFT artifacts statically into libcuml++ ([#4633](https://github.com/rapidsai/cuml/pull/4633)) [@dantegd](https://github.com/dantegd)\n- Upgrade `dask` &amp; `distributed` minimum version ([#4632](https://github.com/rapidsai/cuml/pull/4632)) [@galipremsagar](https://github.com/galipremsagar)\n- Add `.github/ops-bot.yaml` config file ([#4630](https://github.com/rapidsai/cuml/pull/4630)) [@ajschmidt8](https://github.com/ajschmidt8)\n- Small fixes for certain test failures ([#4628](https://github.com/rapidsai/cuml/pull/4628)) [@vinaydes](https://github.com/vinaydes)\n- Templatizing FIL types to add float64 support ([#4625](https://github.com/rapidsai/cuml/pull/4625)) [@canonizer](https://github.com/canonizer)\n- Fitsne as default tsne method ([#4597](https://github.com/rapidsai/cuml/pull/4597)) [@lowener](https://github.com/lowener)\n- Add `get_feature_names` to OneHotEncoder ([#4596](https://github.com/rapidsai/cuml/pull/4596)) [@viclafargue](https://github.com/viclafargue)\n- Fix OOM and cudaContext crash in C++ benchmarks ([#4594](https://github.com/rapidsai/cuml/pull/4594)) [@RAMitchell](https://github.com/RAMitchell)\n- Using Pyraft and automatically cloning when raft pin changes ([#4593](https://github.com/rapidsai/cuml/pull/4593)) [@cjnolet](https://github.com/cjnolet)\n- Upgrade Treelite to 2.3.0 ([#4590](https://github.com/rapidsai/cuml/pull/4590)) [@hcho3](https://github.com/hcho3)\n- Sphinx warnings as errors ([#4585](https://github.com/rapidsai/cuml/pull/4585)) [@RAMitchell](https://github.com/RAMitchell)\n- Adding missing FAISS license ([#4579](https://github.com/rapidsai/cuml/pull/4579)) [@cjnolet](https://github.com/cjnolet)\n- Add QN solver to ElasticNet and Lasso models ([#4576](https://github.com/rapidsai/cuml/pull/4576)) [@achirkin](https://github.com/achirkin)\n- Move remaining stats prims to raft ([#4568](https://github.com/rapidsai/cuml/pull/4568)) [@cjnolet](https://github.com/cjnolet)\n- Moving more ling prims to raft ([#4567](https://github.com/rapidsai/cuml/pull/4567)) [@cjnolet](https://github.com/cjnolet)\n- Adding libraft conda dependencies ([#4564](https://github.com/rapidsai/cuml/pull/4564)) [@cjnolet](https://github.com/cjnolet)\n- Fix RF integer overflow ([#4563](https://github.com/rapidsai/cuml/pull/4563)) [@RAMitchell](https://github.com/RAMitchell)\n- Add CMake `install` rules for tests ([#4551](https://github.com/rapidsai/cuml/pull/4551)) [@ajschmidt8](https://github.com/ajschmidt8)\n- Faster GLM preprocessing by fusing kernels ([#4549](https://github.com/rapidsai/cuml/pull/4549)) [@achirkin](https://github.com/achirkin)\n- RAFT API updates for lap, label, cluster, and spectral apis ([#4548](https://github.com/rapidsai/cuml/pull/4548)) [@cjnolet](https://github.com/cjnolet)\n- Moving cusparse wrappers to detail API in RAFT. ([#4547](https://github.com/rapidsai/cuml/pull/4547)) [@cjnolet](https://github.com/cjnolet)\n- Unpin max `dask` and `distributed` versions ([#4546](https://github.com/rapidsai/cuml/pull/4546)) [@galipremsagar](https://github.com/galipremsagar)\n- Kernel density estimation ([#4545](https://github.com/rapidsai/cuml/pull/4545)) [@RAMitchell](https://github.com/RAMitchell)\n- Update `xgboost` version in CI ([#4541](https://github.com/rapidsai/cuml/pull/4541)) [@ajschmidt8](https://github.com/ajschmidt8)\n- replaces `ccache` with `sccache` ([#4534](https://github.com/rapidsai/cuml/pull/4534)) [@AyodeAwe](https://github.com/AyodeAwe)\n- Remove RAFT memory management (2/2) ([#4526](https://github.com/rapidsai/cuml/pull/4526)) [@viclafargue](https://github.com/viclafargue)\n- Updating RAFT linalg headers ([#4515](https://github.com/rapidsai/cuml/pull/4515)) [@divyegala](https://github.com/divyegala)\n- Refactor QN solver: pass parameters via a POD struct ([#4511](https://github.com/rapidsai/cuml/pull/4511)) [@achirkin](https://github.com/achirkin)\n- Kernel ridge regression ([#4492](https://github.com/rapidsai/cuml/pull/4492)) [@RAMitchell](https://github.com/RAMitchell)\n- QN solvers: Use different gradient norms for different for different loss functions. ([#4491](https://github.com/rapidsai/cuml/pull/4491)) [@achirkin](https://github.com/achirkin)\n- RF: Variable binning and other minor refactoring ([#4479](https://github.com/rapidsai/cuml/pull/4479)) [@venkywonka](https://github.com/venkywonka)\n- Rewrite CD solver using more BLAS ([#4446](https://github.com/rapidsai/cuml/pull/4446)) [@achirkin](https://github.com/achirkin)\n- Add support for sample_weights in LinearRegression ([#4428](https://github.com/rapidsai/cuml/pull/4428)) [@lowener](https://github.com/lowener)\n- Nightly automated benchmark ([#4414](https://github.com/rapidsai/cuml/pull/4414)) [@viclafargue](https://github.com/viclafargue)\n- Use FAISS with RMM ([#4297](https://github.com/rapidsai/cuml/pull/4297)) [@viclafargue](https://github.com/viclafargue)\n- Split C++ tests into separate binaries ([#4295](https://github.com/rapidsai/cuml/pull/4295)) [@dantegd](https://github.com/dantegd)\n\n# cuML 22.02.00 (2 Feb 2022)\n\n## 🚨 Breaking Changes\n\n- Move NVTX range helpers to raft ([#4445](https://github.com/rapidsai/cuml/pull/4445)) [@achirkin](https://github.com/achirkin)\n\n## 🐛 Bug Fixes\n\n- Always upload libcuml ([#4530](https://github.com/rapidsai/cuml/pull/4530)) [@raydouglass](https://github.com/raydouglass)\n- Fix RAFT pin to main branch ([#4508](https://github.com/rapidsai/cuml/pull/4508)) [@dantegd](https://github.com/dantegd)\n- Pin `dask` &amp; `distributed` ([#4505](https://github.com/rapidsai/cuml/pull/4505)) [@galipremsagar](https://github.com/galipremsagar)\n- Replace use of RMM provided CUDA bindings with CUDA Python ([#4499](https://github.com/rapidsai/cuml/pull/4499)) [@shwina](https://github.com/shwina)\n- Dataframe Index as columns in ColumnTransformer ([#4481](https://github.com/rapidsai/cuml/pull/4481)) [@viclafargue](https://github.com/viclafargue)\n- Support compilation with Thrust 1.15 ([#4469](https://github.com/rapidsai/cuml/pull/4469)) [@robertmaynard](https://github.com/robertmaynard)\n- fix minor ASAN issues in UMAPAlgo::Optimize::find_params_ab() ([#4405](https://github.com/rapidsai/cuml/pull/4405)) [@yitao-li](https://github.com/yitao-li)\n\n## 📖 Documentation\n\n- Remove comment numerical warning ([#4408](https://github.com/rapidsai/cuml/pull/4408)) [@viclafargue](https://github.com/viclafargue)\n- Fix docstring for npermutations in PermutationExplainer ([#4402](https://github.com/rapidsai/cuml/pull/4402)) [@hcho3](https://github.com/hcho3)\n\n## 🚀 New Features\n\n- Combine and expose SVC&#39;s support vectors when fitting multi-class data ([#4454](https://github.com/rapidsai/cuml/pull/4454)) [@NV-jpt](https://github.com/NV-jpt)\n- Accept fold index for TargetEncoder ([#4453](https://github.com/rapidsai/cuml/pull/4453)) [@daxiongshu](https://github.com/daxiongshu)\n- Move NVTX range helpers to raft ([#4445](https://github.com/rapidsai/cuml/pull/4445)) [@achirkin](https://github.com/achirkin)\n\n## 🛠️ Improvements\n\n- Fix packages upload ([#4517](https://github.com/rapidsai/cuml/pull/4517)) [@Ethyling](https://github.com/Ethyling)\n- Testing split fused l2 knn compilation units ([#4514](https://github.com/rapidsai/cuml/pull/4514)) [@cjnolet](https://github.com/cjnolet)\n- Prepare upload scripts for Python 3.7 removal ([#4500](https://github.com/rapidsai/cuml/pull/4500)) [@Ethyling](https://github.com/Ethyling)\n- Renaming macros with their RAFT counterparts ([#4496](https://github.com/rapidsai/cuml/pull/4496)) [@divyegala](https://github.com/divyegala)\n- Allow CuPy 10 ([#4487](https://github.com/rapidsai/cuml/pull/4487)) [@jakirkham](https://github.com/jakirkham)\n- Upgrade Treelite to 2.2.1 ([#4484](https://github.com/rapidsai/cuml/pull/4484)) [@hcho3](https://github.com/hcho3)\n- Unpin `dask` and `distributed` ([#4482](https://github.com/rapidsai/cuml/pull/4482)) [@galipremsagar](https://github.com/galipremsagar)\n- Support categorical splits in in TreeExplainer ([#4473](https://github.com/rapidsai/cuml/pull/4473)) [@hcho3](https://github.com/hcho3)\n- Remove RAFT memory management ([#4468](https://github.com/rapidsai/cuml/pull/4468)) [@viclafargue](https://github.com/viclafargue)\n- Add missing imports tests ([#4452](https://github.com/rapidsai/cuml/pull/4452)) [@Ethyling](https://github.com/Ethyling)\n- Update CUDA 11.5 conda environment to use 22.02 pinnings. ([#4450](https://github.com/rapidsai/cuml/pull/4450)) [@bdice](https://github.com/bdice)\n- Support cuML / scikit-learn RF classifiers in TreeExplainer ([#4447](https://github.com/rapidsai/cuml/pull/4447)) [@hcho3](https://github.com/hcho3)\n- Remove `IncludeCategories` from `.clang-format` ([#4438](https://github.com/rapidsai/cuml/pull/4438)) [@codereport](https://github.com/codereport)\n- Simplify perplexity normalization in t-SNE ([#4425](https://github.com/rapidsai/cuml/pull/4425)) [@zbjornson](https://github.com/zbjornson)\n- Unify dense and sparse tests ([#4417](https://github.com/rapidsai/cuml/pull/4417)) [@levsnv](https://github.com/levsnv)\n- Update ucx-py version on release using rvc ([#4411](https://github.com/rapidsai/cuml/pull/4411)) [@Ethyling](https://github.com/Ethyling)\n- Universal Treelite tree walk function for FIL ([#4407](https://github.com/rapidsai/cuml/pull/4407)) [@levsnv](https://github.com/levsnv)\n- Update to UCX-Py 0.24 ([#4396](https://github.com/rapidsai/cuml/pull/4396)) [@pentschev](https://github.com/pentschev)\n- Using sparse public API functions from RAFT ([#4389](https://github.com/rapidsai/cuml/pull/4389)) [@cjnolet](https://github.com/cjnolet)\n- Add a warning to prefer LinearSVM over SVM(kernel=&#39;linear&#39;) ([#4382](https://github.com/rapidsai/cuml/pull/4382)) [@achirkin](https://github.com/achirkin)\n- Hiding cusparse deprecation warnings ([#4373](https://github.com/rapidsai/cuml/pull/4373)) [@cjnolet](https://github.com/cjnolet)\n- Unify dense and sparse import in FIL ([#4328](https://github.com/rapidsai/cuml/pull/4328)) [@levsnv](https://github.com/levsnv)\n- Integrating RAFT handle updates ([#4313](https://github.com/rapidsai/cuml/pull/4313)) [@divyegala](https://github.com/divyegala)\n- Use RAFT template instantations for distances ([#4302](https://github.com/rapidsai/cuml/pull/4302)) [@cjnolet](https://github.com/cjnolet)\n- RF: code re-organization to enhance build parallelism ([#4299](https://github.com/rapidsai/cuml/pull/4299)) [@venkywonka](https://github.com/venkywonka)\n- Add option to build faiss and treelite shared libs, inherit common dependencies from raft ([#4256](https://github.com/rapidsai/cuml/pull/4256)) [@trxcllnt](https://github.com/trxcllnt)\n\n# cuML 21.12.00 (9 Dec 2021)\n\n## 🚨 Breaking Changes\n\n- Fix indexing of PCA to use safer types ([#4255](https://github.com/rapidsai/cuml/pull/4255)) [@lowener](https://github.com/lowener)\n- RF: Add Gamma and Inverse Gaussian loss criteria ([#4216](https://github.com/rapidsai/cuml/pull/4216)) [@venkywonka](https://github.com/venkywonka)\n- update RF docs ([#4138](https://github.com/rapidsai/cuml/pull/4138)) [@venkywonka](https://github.com/venkywonka)\n\n## 🐛 Bug Fixes\n\n- Update conda recipe to have explicit libcusolver ([#4392](https://github.com/rapidsai/cuml/pull/4392)) [@dantegd](https://github.com/dantegd)\n- Restore FIL convention of inlining code ([#4366](https://github.com/rapidsai/cuml/pull/4366)) [@levsnv](https://github.com/levsnv)\n- Fix SVR intercept AttributeError ([#4358](https://github.com/rapidsai/cuml/pull/4358)) [@lowener](https://github.com/lowener)\n- Fix `is_stable_build` logic for CI scripts ([#4350](https://github.com/rapidsai/cuml/pull/4350)) [@ajschmidt8](https://github.com/ajschmidt8)\n- Temporarily disable rmm devicebuffer in array.py ([#4333](https://github.com/rapidsai/cuml/pull/4333)) [@dantegd](https://github.com/dantegd)\n- Fix categorical test in python ([#4326](https://github.com/rapidsai/cuml/pull/4326)) [@levsnv](https://github.com/levsnv)\n- Revert &quot;Merge pull request #4319 from AyodeAwe/branch-21.12&quot; ([#4325](https://github.com/rapidsai/cuml/pull/4325)) [@ajschmidt8](https://github.com/ajschmidt8)\n- Preserve indexing in methods when applied to DataFrame and Series objects ([#4317](https://github.com/rapidsai/cuml/pull/4317)) [@dantegd](https://github.com/dantegd)\n- Fix potential CUDA context poison when negative (invalid) categories provided to FIL model ([#4314](https://github.com/rapidsai/cuml/pull/4314)) [@levsnv](https://github.com/levsnv)\n- Using sparse expanded distances where possible ([#4310](https://github.com/rapidsai/cuml/pull/4310)) [@cjnolet](https://github.com/cjnolet)\n- Fix for `mean_squared_error` ([#4287](https://github.com/rapidsai/cuml/pull/4287)) [@viclafargue](https://github.com/viclafargue)\n- Fix for Categorical Naive Bayes sparse handling ([#4277](https://github.com/rapidsai/cuml/pull/4277)) [@lowener](https://github.com/lowener)\n- Throw an explicit excpetion if the input array is empty in DBSCAN.fit #4273 ([#4275](https://github.com/rapidsai/cuml/pull/4275)) [@viktorkovesd](https://github.com/viktorkovesd)\n- Fix KernelExplainer returning TypeError for certain input ([#4272](https://github.com/rapidsai/cuml/pull/4272)) [@Nanthini10](https://github.com/Nanthini10)\n- Remove most warnings from pytest suite ([#4196](https://github.com/rapidsai/cuml/pull/4196)) [@dantegd](https://github.com/dantegd)\n\n## 📖 Documentation\n\n- Add experimental GPUTreeSHAP to API doc ([#4398](https://github.com/rapidsai/cuml/pull/4398)) [@hcho3](https://github.com/hcho3)\n- Fix GLM typo on device/host pointer ([#4320](https://github.com/rapidsai/cuml/pull/4320)) [@lowener](https://github.com/lowener)\n- update RF docs ([#4138](https://github.com/rapidsai/cuml/pull/4138)) [@venkywonka](https://github.com/venkywonka)\n\n## 🚀 New Features\n\n- Add GPUTreeSHAP to cuML explainer module (experimental) ([#4351](https://github.com/rapidsai/cuml/pull/4351)) [@hcho3](https://github.com/hcho3)\n- Enable training single GPU cuML models using Dask DataFrames and Series ([#4300](https://github.com/rapidsai/cuml/pull/4300)) [@ChrisJar](https://github.com/ChrisJar)\n- LinearSVM using QN solvers ([#4268](https://github.com/rapidsai/cuml/pull/4268)) [@achirkin](https://github.com/achirkin)\n- Add support for exogenous variables to ARIMA ([#4221](https://github.com/rapidsai/cuml/pull/4221)) [@Nyrio](https://github.com/Nyrio)\n- Use opt-in shared memory carveout for FIL ([#3759](https://github.com/rapidsai/cuml/pull/3759)) [@levsnv](https://github.com/levsnv)\n- Symbolic Regression/Classification C/C++ ([#3638](https://github.com/rapidsai/cuml/pull/3638)) [@vimarsh6739](https://github.com/vimarsh6739)\n\n## 🛠️ Improvements\n\n- Fix Changelog Merge Conflicts for `branch-21.12` ([#4393](https://github.com/rapidsai/cuml/pull/4393)) [@ajschmidt8](https://github.com/ajschmidt8)\n- Pin max `dask` and `distributed` to `2012.11.2` ([#4390](https://github.com/rapidsai/cuml/pull/4390)) [@galipremsagar](https://github.com/galipremsagar)\n- Fix forward merge #4349 ([#4374](https://github.com/rapidsai/cuml/pull/4374)) [@dantegd](https://github.com/dantegd)\n- Upgrade `clang` to `11.1.0` ([#4372](https://github.com/rapidsai/cuml/pull/4372)) [@galipremsagar](https://github.com/galipremsagar)\n- Update clang-format version in docs; allow unanchored version string ([#4365](https://github.com/rapidsai/cuml/pull/4365)) [@zbjornson](https://github.com/zbjornson)\n- Add CUDA 11.5 developer environment ([#4364](https://github.com/rapidsai/cuml/pull/4364)) [@dantegd](https://github.com/dantegd)\n- Fix aliasing violation in t-SNE ([#4363](https://github.com/rapidsai/cuml/pull/4363)) [@zbjornson](https://github.com/zbjornson)\n- Promote FITSNE from experimental ([#4361](https://github.com/rapidsai/cuml/pull/4361)) [@lowener](https://github.com/lowener)\n- Fix unnecessary f32/f64 conversions in t-SNE KL calc ([#4331](https://github.com/rapidsai/cuml/pull/4331)) [@zbjornson](https://github.com/zbjornson)\n- Update rapids-cmake version ([#4330](https://github.com/rapidsai/cuml/pull/4330)) [@dantegd](https://github.com/dantegd)\n- rapids-cmake version update to 21.12 ([#4327](https://github.com/rapidsai/cuml/pull/4327)) [@dantegd](https://github.com/dantegd)\n- Use compute-sanitizer instead of cuda-memcheck ([#4324](https://github.com/rapidsai/cuml/pull/4324)) [@teju85](https://github.com/teju85)\n- Ability to pass fp64 type to cuml benchmarks ([#4323](https://github.com/rapidsai/cuml/pull/4323)) [@teju85](https://github.com/teju85)\n- Split treelite fil import from `forest` object definition ([#4306](https://github.com/rapidsai/cuml/pull/4306)) [@levsnv](https://github.com/levsnv)\n- update xgboost version ([#4301](https://github.com/rapidsai/cuml/pull/4301)) [@msadang](https://github.com/msadang)\n- Accounting for RAFT updates to matrix, stats, and random implementations in detail ([#4294](https://github.com/rapidsai/cuml/pull/4294)) [@divyegala](https://github.com/divyegala)\n- Update cudf matrix calls for to_numpy and to_cupy ([#4293](https://github.com/rapidsai/cuml/pull/4293)) [@dantegd](https://github.com/dantegd)\n- Update `conda` recipes for Enhanced Compatibility effort ([#4288](https://github.com/rapidsai/cuml/pull/4288)) [@ajschmidt8](https://github.com/ajschmidt8)\n- Increase parallelism from 4 to 8 jobs in CI ([#4286](https://github.com/rapidsai/cuml/pull/4286)) [@dantegd](https://github.com/dantegd)\n- RAFT distance prims public API update ([#4280](https://github.com/rapidsai/cuml/pull/4280)) [@cjnolet](https://github.com/cjnolet)\n- Update to UCX-Py 0.23 ([#4274](https://github.com/rapidsai/cuml/pull/4274)) [@pentschev](https://github.com/pentschev)\n- In FIL, clip blocks_per_sm to one wave instead of asserting ([#4271](https://github.com/rapidsai/cuml/pull/4271)) [@levsnv](https://github.com/levsnv)\n- Update of &quot;Gracefully accept &#39;n_jobs&#39;, a common sklearn parameter, in NearestNeighbors Estimator&quot; ([#4267](https://github.com/rapidsai/cuml/pull/4267)) [@NV-jpt](https://github.com/NV-jpt)\n- Improve numerical stability of the Kalman filter for ARIMA ([#4259](https://github.com/rapidsai/cuml/pull/4259)) [@Nyrio](https://github.com/Nyrio)\n- Fix indexing of PCA to use safer types ([#4255](https://github.com/rapidsai/cuml/pull/4255)) [@lowener](https://github.com/lowener)\n- Change calculation of ARIMA confidence intervals ([#4248](https://github.com/rapidsai/cuml/pull/4248)) [@Nyrio](https://github.com/Nyrio)\n- Unpin `dask` &amp; `distributed` in CI ([#4235](https://github.com/rapidsai/cuml/pull/4235)) [@galipremsagar](https://github.com/galipremsagar)\n- RF: Add Gamma and Inverse Gaussian loss criteria ([#4216](https://github.com/rapidsai/cuml/pull/4216)) [@venkywonka](https://github.com/venkywonka)\n- Exposing KL divergence in TSNE ([#4208](https://github.com/rapidsai/cuml/pull/4208)) [@viclafargue](https://github.com/viclafargue)\n- Unify template parameter dispatch for FIL inference and shared memory footprint estimation ([#4013](https://github.com/rapidsai/cuml/pull/4013)) [@levsnv](https://github.com/levsnv)\n\n# cuML 21.10.00 (7 Oct 2021)\n\n## 🚨 Breaking Changes\n\n- RF: python api behaviour refactor ([#4207](https://github.com/rapidsai/cuml/pull/4207)) [@venkywonka](https://github.com/venkywonka)\n- Implement vector leaf for random forest ([#4191](https://github.com/rapidsai/cuml/pull/4191)) [@RAMitchell](https://github.com/RAMitchell)\n- Random forest refactoring ([#4166](https://github.com/rapidsai/cuml/pull/4166)) [@RAMitchell](https://github.com/RAMitchell)\n- RF: Add Poisson deviance impurity criterion ([#4156](https://github.com/rapidsai/cuml/pull/4156)) [@venkywonka](https://github.com/venkywonka)\n- avoid paramsSolver::{n_rows,n_cols} shadowing their base class counterparts ([#4130](https://github.com/rapidsai/cuml/pull/4130)) [@yitao-li](https://github.com/yitao-li)\n- Apply modifications to account for RAFT changes ([#4077](https://github.com/rapidsai/cuml/pull/4077)) [@viclafargue](https://github.com/viclafargue)\n\n## 🐛 Bug Fixes\n\n- Update scikit-learn version in conda dev envs to 0.24 ([#4241](https://github.com/rapidsai/cuml/pull/4241)) [@dantegd](https://github.com/dantegd)\n- Using pinned host memory for Random Forest and DBSCAN ([#4215](https://github.com/rapidsai/cuml/pull/4215)) [@divyegala](https://github.com/divyegala)\n- Make sure we keep the rapids-cmake and cuml cal version in sync ([#4213](https://github.com/rapidsai/cuml/pull/4213)) [@robertmaynard](https://github.com/robertmaynard)\n- Add thrust_create_target to install export in CMakeLists ([#4209](https://github.com/rapidsai/cuml/pull/4209)) [@dantegd](https://github.com/dantegd)\n- Change the error type to match sklearn. ([#4198](https://github.com/rapidsai/cuml/pull/4198)) [@achirkin](https://github.com/achirkin)\n- Fixing remaining hdbscan bug ([#4179](https://github.com/rapidsai/cuml/pull/4179)) [@cjnolet](https://github.com/cjnolet)\n- Fix for cuDF changes to cudf.core ([#4168](https://github.com/rapidsai/cuml/pull/4168)) [@dantegd](https://github.com/dantegd)\n- Fixing UMAP reproducibility pytest failures in 11.4 by using random init for now ([#4152](https://github.com/rapidsai/cuml/pull/4152)) [@cjnolet](https://github.com/cjnolet)\n- avoid paramsSolver::{n_rows,n_cols} shadowing their base class counterparts ([#4130](https://github.com/rapidsai/cuml/pull/4130)) [@yitao-li](https://github.com/yitao-li)\n- Use the new RAPIDS.cmake to fetch rapids-cmake ([#4102](https://github.com/rapidsai/cuml/pull/4102)) [@robertmaynard](https://github.com/robertmaynard)\n\n## 📖 Documentation\n\n- Expose train_test_split in API doc ([#4234](https://github.com/rapidsai/cuml/pull/4234)) [@hcho3](https://github.com/hcho3)\n- Adding docs for `.get_feature_names()` inside `TfidfVectorizer` ([#4226](https://github.com/rapidsai/cuml/pull/4226)) [@mayankanand007](https://github.com/mayankanand007)\n- Removing experimental flag from hdbscan description in docs ([#4211](https://github.com/rapidsai/cuml/pull/4211)) [@cjnolet](https://github.com/cjnolet)\n- updated build instructions ([#4200](https://github.com/rapidsai/cuml/pull/4200)) [@shaneding](https://github.com/shaneding)\n- Forward-merge branch-21.08 to branch-21.10 ([#4171](https://github.com/rapidsai/cuml/pull/4171)) [@jakirkham](https://github.com/jakirkham)\n\n## 🚀 New Features\n\n- Experimental option to build libcuml++ only with FIL ([#4225](https://github.com/rapidsai/cuml/pull/4225)) [@dantegd](https://github.com/dantegd)\n- FIL to import categorical models from treelite ([#4173](https://github.com/rapidsai/cuml/pull/4173)) [@levsnv](https://github.com/levsnv)\n- Add hamming, jensen-shannon, kl-divergence, correlation and russellrao distance metrics ([#4155](https://github.com/rapidsai/cuml/pull/4155)) [@mdoijade](https://github.com/mdoijade)\n- Add Categorical Naive Bayes ([#4150](https://github.com/rapidsai/cuml/pull/4150)) [@lowener](https://github.com/lowener)\n- FIL to infer categorical forests and generate them in C++ tests ([#4092](https://github.com/rapidsai/cuml/pull/4092)) [@levsnv](https://github.com/levsnv)\n- Add Gaussian Naive Bayes ([#4079](https://github.com/rapidsai/cuml/pull/4079)) [@lowener](https://github.com/lowener)\n- ARIMA - Add support for missing observations and padding ([#4058](https://github.com/rapidsai/cuml/pull/4058)) [@Nyrio](https://github.com/Nyrio)\n\n## 🛠️ Improvements\n\n- Pin max `dask` and `distributed` versions to 2021.09.1 ([#4229](https://github.com/rapidsai/cuml/pull/4229)) [@galipremsagar](https://github.com/galipremsagar)\n- Fea/umap refine ([#4228](https://github.com/rapidsai/cuml/pull/4228)) [@AjayThorve](https://github.com/AjayThorve)\n- Upgrade Treelite to 2.1.0 ([#4220](https://github.com/rapidsai/cuml/pull/4220)) [@hcho3](https://github.com/hcho3)\n- Add option to clone RAFT even if it is in the environment ([#4217](https://github.com/rapidsai/cuml/pull/4217)) [@dantegd](https://github.com/dantegd)\n- RF: python api behaviour refactor ([#4207](https://github.com/rapidsai/cuml/pull/4207)) [@venkywonka](https://github.com/venkywonka)\n- Pytest updates for Scikit-learn 0.24 ([#4205](https://github.com/rapidsai/cuml/pull/4205)) [@dantegd](https://github.com/dantegd)\n- Faster glm ols-via-eigendecomposition algorithm ([#4201](https://github.com/rapidsai/cuml/pull/4201)) [@achirkin](https://github.com/achirkin)\n- Implement vector leaf for random forest ([#4191](https://github.com/rapidsai/cuml/pull/4191)) [@RAMitchell](https://github.com/RAMitchell)\n- Refactor kmeans sampling code ([#4190](https://github.com/rapidsai/cuml/pull/4190)) [@Nanthini10](https://github.com/Nanthini10)\n- Gracefully accept &#39;n_jobs&#39;, a common sklearn parameter, in NearestNeighbors Estimator ([#4178](https://github.com/rapidsai/cuml/pull/4178)) [@NV-jpt](https://github.com/NV-jpt)\n- Update with rapids cmake new features ([#4175](https://github.com/rapidsai/cuml/pull/4175)) [@robertmaynard](https://github.com/robertmaynard)\n- Update to UCX-Py 0.22 ([#4174](https://github.com/rapidsai/cuml/pull/4174)) [@pentschev](https://github.com/pentschev)\n- Random forest refactoring ([#4166](https://github.com/rapidsai/cuml/pull/4166)) [@RAMitchell](https://github.com/RAMitchell)\n- Fix log level for dask tree_reduce ([#4163](https://github.com/rapidsai/cuml/pull/4163)) [@lowener](https://github.com/lowener)\n- Add CUDA 11.4 development environment ([#4160](https://github.com/rapidsai/cuml/pull/4160)) [@dantegd](https://github.com/dantegd)\n- RF: Add Poisson deviance impurity criterion ([#4156](https://github.com/rapidsai/cuml/pull/4156)) [@venkywonka](https://github.com/venkywonka)\n- Split FIL infer_k into phases to speed up compilation (when a patch is applied) ([#4148](https://github.com/rapidsai/cuml/pull/4148)) [@levsnv](https://github.com/levsnv)\n- RF node queue rewrite ([#4125](https://github.com/rapidsai/cuml/pull/4125)) [@RAMitchell](https://github.com/RAMitchell)\n- Remove max version pin for `dask` &amp; `distributed` on development branch ([#4118](https://github.com/rapidsai/cuml/pull/4118)) [@galipremsagar](https://github.com/galipremsagar)\n- Correct name of a cmake function in get_spdlog.cmake ([#4106](https://github.com/rapidsai/cuml/pull/4106)) [@robertmaynard](https://github.com/robertmaynard)\n- Apply modifications to account for RAFT changes ([#4077](https://github.com/rapidsai/cuml/pull/4077)) [@viclafargue](https://github.com/viclafargue)\n- Warnings are errors ([#4075](https://github.com/rapidsai/cuml/pull/4075)) [@harrism](https://github.com/harrism)\n- ENH Replace gpuci_conda_retry with gpuci_mamba_retry ([#4065](https://github.com/rapidsai/cuml/pull/4065)) [@dillon-cullinan](https://github.com/dillon-cullinan)\n- Changes to NearestNeighbors to call 2d random ball cover ([#4003](https://github.com/rapidsai/cuml/pull/4003)) [@cjnolet](https://github.com/cjnolet)\n- support space in workspace ([#3752](https://github.com/rapidsai/cuml/pull/3752)) [@jolorunyomi](https://github.com/jolorunyomi)\n\n# cuML 21.08.00 (4 Aug 2021)\n\n## 🚨 Breaking Changes\n\n- Remove deprecated target_weights in UMAP ([#4081](https://github.com/rapidsai/cuml/pull/4081)) [@lowener](https://github.com/lowener)\n- Upgrade Treelite to 2.0.0 ([#4072](https://github.com/rapidsai/cuml/pull/4072)) [@hcho3](https://github.com/hcho3)\n- RF/DT cleanup ([#4005](https://github.com/rapidsai/cuml/pull/4005)) [@venkywonka](https://github.com/venkywonka)\n- RF: memset and batch size optimization for computing splits ([#4001](https://github.com/rapidsai/cuml/pull/4001)) [@venkywonka](https://github.com/venkywonka)\n- Remove old RF backend ([#3868](https://github.com/rapidsai/cuml/pull/3868)) [@RAMitchell](https://github.com/RAMitchell)\n- Enable warp-per-tree inference in FIL for regression and binary classification ([#3760](https://github.com/rapidsai/cuml/pull/3760)) [@levsnv](https://github.com/levsnv)\n\n## 🐛 Bug Fixes\n\n- Disabling umap reproducibility tests for cuda 11.4 ([#4128](https://github.com/rapidsai/cuml/pull/4128)) [@cjnolet](https://github.com/cjnolet)\n- Fix for crash in RF when `max_leaves` parameter is specified ([#4126](https://github.com/rapidsai/cuml/pull/4126)) [@vinaydes](https://github.com/vinaydes)\n- Running umap mnmg test twice ([#4112](https://github.com/rapidsai/cuml/pull/4112)) [@cjnolet](https://github.com/cjnolet)\n- Minimal fix for `SparseRandomProjection` ([#4100](https://github.com/rapidsai/cuml/pull/4100)) [@viclafargue](https://github.com/viclafargue)\n- Creating copy of `components` in PCA transform and inverse transform ([#4099](https://github.com/rapidsai/cuml/pull/4099)) [@divyegala](https://github.com/divyegala)\n- Fix SVM model parameter handling in case n_support=0 ([#4097](https://github.com/rapidsai/cuml/pull/4097)) [@tfeher](https://github.com/tfeher)\n- Fix set_params for linear models ([#4096](https://github.com/rapidsai/cuml/pull/4096)) [@lowener](https://github.com/lowener)\n- Fix train test split pytest comparison ([#4062](https://github.com/rapidsai/cuml/pull/4062)) [@dantegd](https://github.com/dantegd)\n- Fix fit_transform on KMeans ([#4055](https://github.com/rapidsai/cuml/pull/4055)) [@lowener](https://github.com/lowener)\n- Fixing -1 key access in 1nn reduce op in HDBSCAN ([#4052](https://github.com/rapidsai/cuml/pull/4052)) [@divyegala](https://github.com/divyegala)\n- Disable installing gbench to avoid container permission issues ([#4049](https://github.com/rapidsai/cuml/pull/4049)) [@dantegd](https://github.com/dantegd)\n- Fix double fit crash in preprocessing models ([#4040](https://github.com/rapidsai/cuml/pull/4040)) [@viclafargue](https://github.com/viclafargue)\n- Always add `faiss` library alias if it&#39;s missing ([#4028](https://github.com/rapidsai/cuml/pull/4028)) [@trxcllnt](https://github.com/trxcllnt)\n- Fixing intermittent HBDSCAN pytest failure in CI ([#4025](https://github.com/rapidsai/cuml/pull/4025)) [@divyegala](https://github.com/divyegala)\n- HDBSCAN bug on A100 ([#4024](https://github.com/rapidsai/cuml/pull/4024)) [@divyegala](https://github.com/divyegala)\n- Add treelite include paths to treelite targets ([#4023](https://github.com/rapidsai/cuml/pull/4023)) [@trxcllnt](https://github.com/trxcllnt)\n- Add Treelite_BINARY_DIR include to `cuml++` build interface include paths ([#4018](https://github.com/rapidsai/cuml/pull/4018)) [@trxcllnt](https://github.com/trxcllnt)\n- Small ARIMA-related bug fixes in Hessenberg reduction and make_arima ([#4017](https://github.com/rapidsai/cuml/pull/4017)) [@Nyrio](https://github.com/Nyrio)\n- Update setup.py ([#4015](https://github.com/rapidsai/cuml/pull/4015)) [@ajschmidt8](https://github.com/ajschmidt8)\n- Update `treelite` version in `get_treelite.cmake` ([#4014](https://github.com/rapidsai/cuml/pull/4014)) [@ajschmidt8](https://github.com/ajschmidt8)\n- Fix build with latest RAFT branch-21.08 ([#4012](https://github.com/rapidsai/cuml/pull/4012)) [@trxcllnt](https://github.com/trxcllnt)\n- Skipping hdbscan pytests when gpu is a100 ([#4007](https://github.com/rapidsai/cuml/pull/4007)) [@cjnolet](https://github.com/cjnolet)\n- Using 64-bit array lengths to increase scale of pca &amp; tsvd ([#3983](https://github.com/rapidsai/cuml/pull/3983)) [@cjnolet](https://github.com/cjnolet)\n- Fix MNMG test in Dask RF ([#3964](https://github.com/rapidsai/cuml/pull/3964)) [@hcho3](https://github.com/hcho3)\n- Use nested include in destination of install headers to avoid docker permission issues ([#3962](https://github.com/rapidsai/cuml/pull/3962)) [@dantegd](https://github.com/dantegd)\n- Fix automerge #3939 ([#3952](https://github.com/rapidsai/cuml/pull/3952)) [@dantegd](https://github.com/dantegd)\n- Update UCX-Py version to 0.21 ([#3950](https://github.com/rapidsai/cuml/pull/3950)) [@pentschev](https://github.com/pentschev)\n- Fix kernel and line info in cmake ([#3941](https://github.com/rapidsai/cuml/pull/3941)) [@dantegd](https://github.com/dantegd)\n- Fix for multi GPU PCA compute failing bug after transform and added error handling when n_components is not passed ([#3912](https://github.com/rapidsai/cuml/pull/3912)) [@akaanirban](https://github.com/akaanirban)\n- Tolerate QN linesearch failures when it&#39;s harmless ([#3791](https://github.com/rapidsai/cuml/pull/3791)) [@achirkin](https://github.com/achirkin)\n\n## 📖 Documentation\n\n- Improve docstrings for silhouette score metrics. ([#4026](https://github.com/rapidsai/cuml/pull/4026)) [@bdice](https://github.com/bdice)\n- Update CHANGELOG.md link ([#3956](https://github.com/rapidsai/cuml/pull/3956)) [@Salonijain27](https://github.com/Salonijain27)\n- Update documentation build examples to be generator agnostic ([#3909](https://github.com/rapidsai/cuml/pull/3909)) [@robertmaynard](https://github.com/robertmaynard)\n- Improve FIL code readability and documentation ([#3056](https://github.com/rapidsai/cuml/pull/3056)) [@levsnv](https://github.com/levsnv)\n\n## 🚀 New Features\n\n- Add Multinomial and Bernoulli Naive Bayes variants ([#4053](https://github.com/rapidsai/cuml/pull/4053)) [@lowener](https://github.com/lowener)\n- Add weighted K-Means sampling for SHAP ([#4051](https://github.com/rapidsai/cuml/pull/4051)) [@Nanthini10](https://github.com/Nanthini10)\n- Use chebyshev, canberra, hellinger and minkowski distance metrics ([#3990](https://github.com/rapidsai/cuml/pull/3990)) [@mdoijade](https://github.com/mdoijade)\n- Implement vector leaf prediction for fil. ([#3917](https://github.com/rapidsai/cuml/pull/3917)) [@RAMitchell](https://github.com/RAMitchell)\n- change TargetEncoder&#39;s smooth argument from ratio to count ([#3876](https://github.com/rapidsai/cuml/pull/3876)) [@daxiongshu](https://github.com/daxiongshu)\n- Enable warp-per-tree inference in FIL for regression and binary classification ([#3760](https://github.com/rapidsai/cuml/pull/3760)) [@levsnv](https://github.com/levsnv)\n\n## 🛠️ Improvements\n\n- Remove clang/clang-tools from conda recipe ([#4109](https://github.com/rapidsai/cuml/pull/4109)) [@dantegd](https://github.com/dantegd)\n- Pin dask version ([#4108](https://github.com/rapidsai/cuml/pull/4108)) [@galipremsagar](https://github.com/galipremsagar)\n- ANN warnings/tests updates ([#4101](https://github.com/rapidsai/cuml/pull/4101)) [@viclafargue](https://github.com/viclafargue)\n- Removing local memory operations from computeSplitKernel and other optimizations ([#4083](https://github.com/rapidsai/cuml/pull/4083)) [@vinaydes](https://github.com/vinaydes)\n- Fix libfaiss dependency to not expressly depend on conda-forge ([#4082](https://github.com/rapidsai/cuml/pull/4082)) [@Ethyling](https://github.com/Ethyling)\n- Remove deprecated target_weights in UMAP ([#4081](https://github.com/rapidsai/cuml/pull/4081)) [@lowener](https://github.com/lowener)\n- Upgrade Treelite to 2.0.0 ([#4072](https://github.com/rapidsai/cuml/pull/4072)) [@hcho3](https://github.com/hcho3)\n- Optimize dtype conversion for FIL ([#4070](https://github.com/rapidsai/cuml/pull/4070)) [@dantegd](https://github.com/dantegd)\n- Adding quick notes to HDBSCAN public API docs as to why discrepancies may occur between cpu and gpu impls. ([#4061](https://github.com/rapidsai/cuml/pull/4061)) [@cjnolet](https://github.com/cjnolet)\n- Update `conda` environment name for CI ([#4039](https://github.com/rapidsai/cuml/pull/4039)) [@ajschmidt8](https://github.com/ajschmidt8)\n- Rewrite random forest gtests ([#4038](https://github.com/rapidsai/cuml/pull/4038)) [@RAMitchell](https://github.com/RAMitchell)\n- Updating Clang Version to 11.0.0 ([#4029](https://github.com/rapidsai/cuml/pull/4029)) [@codereport](https://github.com/codereport)\n- Raise ARIMA parameter limits from 4 to 8 ([#4022](https://github.com/rapidsai/cuml/pull/4022)) [@Nyrio](https://github.com/Nyrio)\n- Testing extract clusters in HDBSCAN ([#4009](https://github.com/rapidsai/cuml/pull/4009)) [@divyegala](https://github.com/divyegala)\n- ARIMA - Kalman loop rewrite: single megakernel instead of host loop ([#4006](https://github.com/rapidsai/cuml/pull/4006)) [@Nyrio](https://github.com/Nyrio)\n- RF/DT cleanup ([#4005](https://github.com/rapidsai/cuml/pull/4005)) [@venkywonka](https://github.com/venkywonka)\n- Exposing condensed hierarchy through cython for easier unit-level testing ([#4004](https://github.com/rapidsai/cuml/pull/4004)) [@cjnolet](https://github.com/cjnolet)\n- Use the 21.08 branch of rapids-cmake as rmm requires it ([#4002](https://github.com/rapidsai/cuml/pull/4002)) [@robertmaynard](https://github.com/robertmaynard)\n- RF: memset and batch size optimization for computing splits ([#4001](https://github.com/rapidsai/cuml/pull/4001)) [@venkywonka](https://github.com/venkywonka)\n- Reducing cluster size to number of selected clusters. Returning stability scores ([#3987](https://github.com/rapidsai/cuml/pull/3987)) [@cjnolet](https://github.com/cjnolet)\n- HDBSCAN: Lazy-loading (and caching) condensed &amp; single-linkage tree objects ([#3986](https://github.com/rapidsai/cuml/pull/3986)) [@cjnolet](https://github.com/cjnolet)\n- Fix `21.08` forward-merge conflicts ([#3982](https://github.com/rapidsai/cuml/pull/3982)) [@ajschmidt8](https://github.com/ajschmidt8)\n- Update Dask/Distributed version ([#3978](https://github.com/rapidsai/cuml/pull/3978)) [@pentschev](https://github.com/pentschev)\n- Use clang-tools on x86 only ([#3969](https://github.com/rapidsai/cuml/pull/3969)) [@jakirkham](https://github.com/jakirkham)\n- Promote `trustworthiness_score` to public header, add missing includes, update dependencies ([#3968](https://github.com/rapidsai/cuml/pull/3968)) [@trxcllnt](https://github.com/trxcllnt)\n- Moving FAISS ANN wrapper to raft ([#3963](https://github.com/rapidsai/cuml/pull/3963)) [@cjnolet](https://github.com/cjnolet)\n- Add MG weighted k-means ([#3959](https://github.com/rapidsai/cuml/pull/3959)) [@lowener](https://github.com/lowener)\n- Remove unused code in UMAP. ([#3931](https://github.com/rapidsai/cuml/pull/3931)) [@trivialfis](https://github.com/trivialfis)\n- Fix automerge #3900 and correct package versions in meta packages ([#3918](https://github.com/rapidsai/cuml/pull/3918)) [@dantegd](https://github.com/dantegd)\n- Adaptive stress tests when GPU memory capacity is insufficient ([#3916](https://github.com/rapidsai/cuml/pull/3916)) [@lowener](https://github.com/lowener)\n- Fix merge conflicts ([#3892](https://github.com/rapidsai/cuml/pull/3892)) [@ajschmidt8](https://github.com/ajschmidt8)\n- Remove old RF backend ([#3868](https://github.com/rapidsai/cuml/pull/3868)) [@RAMitchell](https://github.com/RAMitchell)\n- Refactor to extract random forest objectives ([#3854](https://github.com/rapidsai/cuml/pull/3854)) [@RAMitchell](https://github.com/RAMitchell)\n\n# cuML 21.06.00 (9 Jun 2021)\n\n## 🚨 Breaking Changes\n\n- Remove Base.enable_rmm_pool method as it is no longer needed ([#3875](https://github.com/rapidsai/cuml/pull/3875)) [@teju85](https://github.com/teju85)\n- RF: Make experimental-backend default for regression tasks and deprecate old-backend. ([#3872](https://github.com/rapidsai/cuml/pull/3872)) [@venkywonka](https://github.com/venkywonka)\n- Deterministic UMAP with floating point rounding. ([#3848](https://github.com/rapidsai/cuml/pull/3848)) [@trivialfis](https://github.com/trivialfis)\n- Fix RF regression performance ([#3845](https://github.com/rapidsai/cuml/pull/3845)) [@RAMitchell](https://github.com/RAMitchell)\n- Add feature to print forest shape in FIL upon importing ([#3763](https://github.com/rapidsai/cuml/pull/3763)) [@levsnv](https://github.com/levsnv)\n- Remove &#39;seed&#39; and &#39;output_type&#39; deprecated features ([#3739](https://github.com/rapidsai/cuml/pull/3739)) [@lowener](https://github.com/lowener)\n\n## 🐛 Bug Fixes\n\n- Disable UMAP deterministic test on CTK11.2 ([#3942](https://github.com/rapidsai/cuml/pull/3942)) [@trivialfis](https://github.com/trivialfis)\n- Revert #3869 ([#3933](https://github.com/rapidsai/cuml/pull/3933)) [@hcho3](https://github.com/hcho3)\n- RF: fix the bug in `pdf_to_cdf` device function that causes hang when `n_bins &gt; TPB &amp;&amp; n_bins % TPB != 0` ([#3921](https://github.com/rapidsai/cuml/pull/3921)) [@venkywonka](https://github.com/venkywonka)\n- Fix number of permutations in pytest and getting handle for cuml models ([#3920](https://github.com/rapidsai/cuml/pull/3920)) [@dantegd](https://github.com/dantegd)\n- Fix typo in umap `target_weight` parameter ([#3914](https://github.com/rapidsai/cuml/pull/3914)) [@lowener](https://github.com/lowener)\n- correct compliation of cuml c library ([#3908](https://github.com/rapidsai/cuml/pull/3908)) [@robertmaynard](https://github.com/robertmaynard)\n- Correct install path for include folder to avoid double nesting ([#3901](https://github.com/rapidsai/cuml/pull/3901)) [@dantegd](https://github.com/dantegd)\n- Add type check for y in train_test_split ([#3886](https://github.com/rapidsai/cuml/pull/3886)) [@Nanthini10](https://github.com/Nanthini10)\n- Fix for MNMG test_rf_classification_dask_fil_predict_proba ([#3831](https://github.com/rapidsai/cuml/pull/3831)) [@lowener](https://github.com/lowener)\n- Fix MNMG test test_rf_regression_dask_fil ([#3830](https://github.com/rapidsai/cuml/pull/3830)) [@hcho3](https://github.com/hcho3)\n- AgglomerativeClustering support single cluster and ignore only zero distances from self-loops ([#3824](https://github.com/rapidsai/cuml/pull/3824)) [@cjnolet](https://github.com/cjnolet)\n\n## 📖 Documentation\n\n- Small doc fixes for 21.06 release ([#3936](https://github.com/rapidsai/cuml/pull/3936)) [@dantegd](https://github.com/dantegd)\n- Document ability to export cuML RF to predict on other machines ([#3890](https://github.com/rapidsai/cuml/pull/3890)) [@hcho3](https://github.com/hcho3)\n\n## 🚀 New Features\n\n- Deterministic UMAP with floating point rounding. ([#3848](https://github.com/rapidsai/cuml/pull/3848)) [@trivialfis](https://github.com/trivialfis)\n- HDBSCAN ([#3821](https://github.com/rapidsai/cuml/pull/3821)) [@cjnolet](https://github.com/cjnolet)\n- Add feature to print forest shape in FIL upon importing ([#3763](https://github.com/rapidsai/cuml/pull/3763)) [@levsnv](https://github.com/levsnv)\n\n## 🛠️ Improvements\n\n- Pin dask ot 2021.5.1 for 21.06 release ([#3937](https://github.com/rapidsai/cuml/pull/3937)) [@dantegd](https://github.com/dantegd)\n- Upgrade xgboost to 1.4.2 ([#3925](https://github.com/rapidsai/cuml/pull/3925)) [@dantegd](https://github.com/dantegd)\n- Use UCX-Py 0.20 ([#3911](https://github.com/rapidsai/cuml/pull/3911)) [@jakirkham](https://github.com/jakirkham)\n- Upgrade NCCL to 2.9.9 ([#3902](https://github.com/rapidsai/cuml/pull/3902)) [@dantegd](https://github.com/dantegd)\n- Update conda developer environments ([#3898](https://github.com/rapidsai/cuml/pull/3898)) [@viclafargue](https://github.com/viclafargue)\n- ARIMA: pre-allocation of temporary memory to reduce latencies ([#3895](https://github.com/rapidsai/cuml/pull/3895)) [@Nyrio](https://github.com/Nyrio)\n- Condense TSNE parameters into a struct ([#3884](https://github.com/rapidsai/cuml/pull/3884)) [@lowener](https://github.com/lowener)\n- Update `CHANGELOG.md` links for calver ([#3883](https://github.com/rapidsai/cuml/pull/3883)) [@ajschmidt8](https://github.com/ajschmidt8)\n- Make sure `__init__` is called in graph callback. ([#3881](https://github.com/rapidsai/cuml/pull/3881)) [@trivialfis](https://github.com/trivialfis)\n- Update docs build script ([#3877](https://github.com/rapidsai/cuml/pull/3877)) [@ajschmidt8](https://github.com/ajschmidt8)\n- Remove Base.enable_rmm_pool method as it is no longer needed ([#3875](https://github.com/rapidsai/cuml/pull/3875)) [@teju85](https://github.com/teju85)\n- RF: Make experimental-backend default for regression tasks and deprecate old-backend. ([#3872](https://github.com/rapidsai/cuml/pull/3872)) [@venkywonka](https://github.com/venkywonka)\n- Enable probability output from RF binary classifier (alternative implementaton) ([#3869](https://github.com/rapidsai/cuml/pull/3869)) [@hcho3](https://github.com/hcho3)\n- CI test speed improvement ([#3851](https://github.com/rapidsai/cuml/pull/3851)) [@lowener](https://github.com/lowener)\n- Fix RF regression performance ([#3845](https://github.com/rapidsai/cuml/pull/3845)) [@RAMitchell](https://github.com/RAMitchell)\n- Update to CMake 3.20 features, `rapids-cmake` and `CPM` ([#3844](https://github.com/rapidsai/cuml/pull/3844)) [@dantegd](https://github.com/dantegd)\n- Support sparse input features in QN solvers and Logistic Regression ([#3827](https://github.com/rapidsai/cuml/pull/3827)) [@achirkin](https://github.com/achirkin)\n- Trustworthiness score improvements ([#3826](https://github.com/rapidsai/cuml/pull/3826)) [@viclafargue](https://github.com/viclafargue)\n- Performance optimization of RF split kernels by removing empty cycles ([#3818](https://github.com/rapidsai/cuml/pull/3818)) [@vinaydes](https://github.com/vinaydes)\n- Correct deprecate positional args decorator for CalVer ([#3784](https://github.com/rapidsai/cuml/pull/3784)) [@lowener](https://github.com/lowener)\n- ColumnTransformer &amp; FunctionTransformer ([#3745](https://github.com/rapidsai/cuml/pull/3745)) [@viclafargue](https://github.com/viclafargue)\n- Remove &#39;seed&#39; and &#39;output_type&#39; deprecated features ([#3739](https://github.com/rapidsai/cuml/pull/3739)) [@lowener](https://github.com/lowener)\n\n# cuML 0.19.0 (21 Apr 2021)\n\n## 🚨 Breaking Changes\n\n- Use the new RF backend by default for classification ([#3686](https://github.com//rapidsai/cuml/pull/3686)) [@hcho3](https://github.com/hcho3)\n- Deprecating quantile-per-tree and removing three previously deprecated Random Forest parameters ([#3667](https://github.com//rapidsai/cuml/pull/3667)) [@vinaydes](https://github.com/vinaydes)\n- Update predict() / predict_proba() of RF to match sklearn ([#3609](https://github.com//rapidsai/cuml/pull/3609)) [@hcho3](https://github.com/hcho3)\n- Upgrade FAISS to 1.7.x ([#3509](https://github.com//rapidsai/cuml/pull/3509)) [@viclafargue](https://github.com/viclafargue)\n- cuML&#39;s estimator Base class for preprocessing models ([#3270](https://github.com//rapidsai/cuml/pull/3270)) [@viclafargue](https://github.com/viclafargue)\n\n## 🐛 Bug Fixes\n\n- Fix brute force KNN distance metric issue ([#3755](https://github.com//rapidsai/cuml/pull/3755)) [@viclafargue](https://github.com/viclafargue)\n- Fix min_max_axis ([#3735](https://github.com//rapidsai/cuml/pull/3735)) [@viclafargue](https://github.com/viclafargue)\n- Fix NaN errors observed with ARIMA in CUDA 11.2 builds ([#3730](https://github.com//rapidsai/cuml/pull/3730)) [@Nyrio](https://github.com/Nyrio)\n- Fix random state generator ([#3716](https://github.com//rapidsai/cuml/pull/3716)) [@viclafargue](https://github.com/viclafargue)\n- Fixes the out of memory access issue for computeSplit kernels ([#3715](https://github.com//rapidsai/cuml/pull/3715)) [@vinaydes](https://github.com/vinaydes)\n- Fixing umap gtest failure under cuda 11.2. ([#3696](https://github.com//rapidsai/cuml/pull/3696)) [@cjnolet](https://github.com/cjnolet)\n- Fix irreproducibility issue in RF classification ([#3693](https://github.com//rapidsai/cuml/pull/3693)) [@vinaydes](https://github.com/vinaydes)\n- BUG fix BatchedLevelAlgo DtClsTest &amp; DtRegTest failing tests ([#3690](https://github.com//rapidsai/cuml/pull/3690)) [@venkywonka](https://github.com/venkywonka)\n- Restore the functionality of RF score() ([#3685](https://github.com//rapidsai/cuml/pull/3685)) [@hcho3](https://github.com/hcho3)\n- Use main build.sh to build docs in docs CI ([#3681](https://github.com//rapidsai/cuml/pull/3681)) [@dantegd](https://github.com/dantegd)\n- Revert &quot;Update conda recipes pinning of repo dependencies&quot; ([#3680](https://github.com//rapidsai/cuml/pull/3680)) [@raydouglass](https://github.com/raydouglass)\n- Skip tests that fail on CUDA 11.2 ([#3679](https://github.com//rapidsai/cuml/pull/3679)) [@dantegd](https://github.com/dantegd)\n- Dask KNN Cl&amp;Re 1D labels ([#3668](https://github.com//rapidsai/cuml/pull/3668)) [@viclafargue](https://github.com/viclafargue)\n- Update conda recipes pinning of repo dependencies ([#3666](https://github.com//rapidsai/cuml/pull/3666)) [@mike-wendt](https://github.com/mike-wendt)\n- OOB access in GLM SoftMax ([#3642](https://github.com//rapidsai/cuml/pull/3642)) [@divyegala](https://github.com/divyegala)\n- SilhouetteScore C++ tests seed ([#3640](https://github.com//rapidsai/cuml/pull/3640)) [@divyegala](https://github.com/divyegala)\n- SimpleImputer fix ([#3624](https://github.com//rapidsai/cuml/pull/3624)) [@viclafargue](https://github.com/viclafargue)\n- Silhouette Score `make_monotonic` for non-monotonic label set ([#3619](https://github.com//rapidsai/cuml/pull/3619)) [@divyegala](https://github.com/divyegala)\n- Fixing support for empty rows in sparse Jaccard / Cosine ([#3612](https://github.com//rapidsai/cuml/pull/3612)) [@cjnolet](https://github.com/cjnolet)\n- Fix train_test_split with stratify option ([#3611](https://github.com//rapidsai/cuml/pull/3611)) [@Nanthini10](https://github.com/Nanthini10)\n- Update predict() / predict_proba() of RF to match sklearn ([#3609](https://github.com//rapidsai/cuml/pull/3609)) [@hcho3](https://github.com/hcho3)\n- Change dask and distributed branch to main ([#3593](https://github.com//rapidsai/cuml/pull/3593)) [@dantegd](https://github.com/dantegd)\n- Fixes memory allocation for experimental backend and improves quantile computations ([#3586](https://github.com//rapidsai/cuml/pull/3586)) [@vinaydes](https://github.com/vinaydes)\n- Add ucx-proc package back that got lost during an auto merge conflict ([#3550](https://github.com//rapidsai/cuml/pull/3550)) [@dantegd](https://github.com/dantegd)\n- Fix failing Hellinger gtest ([#3549](https://github.com//rapidsai/cuml/pull/3549)) [@cjnolet](https://github.com/cjnolet)\n- Directly invoke make for non-CMake docs target ([#3534](https://github.com//rapidsai/cuml/pull/3534)) [@wphicks](https://github.com/wphicks)\n- Fix Codecov.io Coverage Upload for Branch Builds ([#3524](https://github.com//rapidsai/cuml/pull/3524)) [@mdemoret-nv](https://github.com/mdemoret-nv)\n- Ensure global_output_type is thread-safe ([#3497](https://github.com//rapidsai/cuml/pull/3497)) [@wphicks](https://github.com/wphicks)\n- List as input for SimpleImputer ([#3489](https://github.com//rapidsai/cuml/pull/3489)) [@viclafargue](https://github.com/viclafargue)\n\n## 📖 Documentation\n\n- Add sparse docstring comments ([#3712](https://github.com//rapidsai/cuml/pull/3712)) [@JohnZed](https://github.com/JohnZed)\n- FIL and Dask demo ([#3698](https://github.com//rapidsai/cuml/pull/3698)) [@miroenev](https://github.com/miroenev)\n- Deprecating quantile-per-tree and removing three previously deprecated Random Forest parameters ([#3667](https://github.com//rapidsai/cuml/pull/3667)) [@vinaydes](https://github.com/vinaydes)\n- Fixing Indentation for Docstring Generators ([#3650](https://github.com//rapidsai/cuml/pull/3650)) [@mdemoret-nv](https://github.com/mdemoret-nv)\n- Update doc to indicate ExtraTree support ([#3635](https://github.com//rapidsai/cuml/pull/3635)) [@hcho3](https://github.com/hcho3)\n- Update doc, now that FIL supports multi-class classification ([#3634](https://github.com//rapidsai/cuml/pull/3634)) [@hcho3](https://github.com/hcho3)\n- Document model_type=&#39;xgboost_json&#39; in FIL ([#3633](https://github.com//rapidsai/cuml/pull/3633)) [@hcho3](https://github.com/hcho3)\n- Including log loss metric to the documentation website ([#3617](https://github.com//rapidsai/cuml/pull/3617)) [@lowener](https://github.com/lowener)\n- Update the build doc regarding the use of GCC 7.5 ([#3605](https://github.com//rapidsai/cuml/pull/3605)) [@hcho3](https://github.com/hcho3)\n- Update One-Hot Encoder doc ([#3600](https://github.com//rapidsai/cuml/pull/3600)) [@lowener](https://github.com/lowener)\n- Fix documentation of KMeans ([#3595](https://github.com//rapidsai/cuml/pull/3595)) [@lowener](https://github.com/lowener)\n\n## 🚀 New Features\n\n- Reduce the size of the cuml libraries ([#3702](https://github.com//rapidsai/cuml/pull/3702)) [@robertmaynard](https://github.com/robertmaynard)\n- Use ninja as default CMake generator ([#3664](https://github.com//rapidsai/cuml/pull/3664)) [@wphicks](https://github.com/wphicks)\n- Single-Linkage Hierarchical Clustering Python Wrapper ([#3631](https://github.com//rapidsai/cuml/pull/3631)) [@cjnolet](https://github.com/cjnolet)\n- Support for precomputed distance matrix in DBSCAN ([#3585](https://github.com//rapidsai/cuml/pull/3585)) [@Nyrio](https://github.com/Nyrio)\n- Adding haversine to brute force knn ([#3579](https://github.com//rapidsai/cuml/pull/3579)) [@cjnolet](https://github.com/cjnolet)\n- Support for sample_weight parameter in LogisticRegression ([#3572](https://github.com//rapidsai/cuml/pull/3572)) [@viclafargue](https://github.com/viclafargue)\n- Provide &quot;--ccache&quot; flag for build.sh ([#3566](https://github.com//rapidsai/cuml/pull/3566)) [@wphicks](https://github.com/wphicks)\n- Eliminate unnecessary includes discovered by cppclean ([#3564](https://github.com//rapidsai/cuml/pull/3564)) [@wphicks](https://github.com/wphicks)\n- Single-linkage Hierarchical Clustering C++ ([#3545](https://github.com//rapidsai/cuml/pull/3545)) [@cjnolet](https://github.com/cjnolet)\n- Expose sparse distances via semiring to Python API ([#3516](https://github.com//rapidsai/cuml/pull/3516)) [@lowener](https://github.com/lowener)\n- Use cmake --build in build.sh to facilitate switching build tools ([#3487](https://github.com//rapidsai/cuml/pull/3487)) [@wphicks](https://github.com/wphicks)\n- Add cython hinge_loss ([#3409](https://github.com//rapidsai/cuml/pull/3409)) [@Nanthini10](https://github.com/Nanthini10)\n- Adding CodeCov Info for Dask Tests ([#3338](https://github.com//rapidsai/cuml/pull/3338)) [@mdemoret-nv](https://github.com/mdemoret-nv)\n- Add predict_proba() to XGBoost-style models in FIL C++ ([#2894](https://github.com//rapidsai/cuml/pull/2894)) [@levsnv](https://github.com/levsnv)\n\n## 🛠️ Improvements\n\n- Updating docs, readme, and umap param tests for 0.19 ([#3731](https://github.com//rapidsai/cuml/pull/3731)) [@cjnolet](https://github.com/cjnolet)\n- Locking RAFT hash for 0.19 ([#3721](https://github.com//rapidsai/cuml/pull/3721)) [@cjnolet](https://github.com/cjnolet)\n- Upgrade to Treelite 1.1.0 ([#3708](https://github.com//rapidsai/cuml/pull/3708)) [@hcho3](https://github.com/hcho3)\n- Update to XGBoost 1.4.0rc1 ([#3699](https://github.com//rapidsai/cuml/pull/3699)) [@hcho3](https://github.com/hcho3)\n- Use the new RF backend by default for classification ([#3686](https://github.com//rapidsai/cuml/pull/3686)) [@hcho3](https://github.com/hcho3)\n- Update LogisticRegression documentation ([#3677](https://github.com//rapidsai/cuml/pull/3677)) [@viclafargue](https://github.com/viclafargue)\n- Preprocessing out of experimental ([#3676](https://github.com//rapidsai/cuml/pull/3676)) [@viclafargue](https://github.com/viclafargue)\n- ENH Decision Tree new backend `computeSplit*Kernel` histogram calculation optimization ([#3674](https://github.com//rapidsai/cuml/pull/3674)) [@venkywonka](https://github.com/venkywonka)\n- Remove `check_cupy8` ([#3669](https://github.com//rapidsai/cuml/pull/3669)) [@viclafargue](https://github.com/viclafargue)\n- Use custom conda build directory for ccache integration ([#3658](https://github.com//rapidsai/cuml/pull/3658)) [@dillon-cullinan](https://github.com/dillon-cullinan)\n- Disable three flaky tests ([#3657](https://github.com//rapidsai/cuml/pull/3657)) [@hcho3](https://github.com/hcho3)\n- CUDA 11.2 developer environment ([#3648](https://github.com//rapidsai/cuml/pull/3648)) [@dantegd](https://github.com/dantegd)\n- Store data frequencies in tree nodes of RF ([#3647](https://github.com//rapidsai/cuml/pull/3647)) [@hcho3](https://github.com/hcho3)\n- Row major Gram matrices ([#3639](https://github.com//rapidsai/cuml/pull/3639)) [@tfeher](https://github.com/tfeher)\n- Converting all Estimator Constructors to Keyword Arguments ([#3636](https://github.com//rapidsai/cuml/pull/3636)) [@mdemoret-nv](https://github.com/mdemoret-nv)\n- Adding make_pipeline + test score with pipeline ([#3632](https://github.com//rapidsai/cuml/pull/3632)) [@viclafargue](https://github.com/viclafargue)\n- ENH Decision Tree new backend `computeSplitClassificationKernel` histogram calculation and occupancy optimization ([#3616](https://github.com//rapidsai/cuml/pull/3616)) [@venkywonka](https://github.com/venkywonka)\n- Revert &quot;ENH Fix stale GHA and prevent duplicates &quot; ([#3614](https://github.com//rapidsai/cuml/pull/3614)) [@mike-wendt](https://github.com/mike-wendt)\n- ENH Fix stale GHA and prevent duplicates ([#3613](https://github.com//rapidsai/cuml/pull/3613)) [@mike-wendt](https://github.com/mike-wendt)\n- KNN from RAFT ([#3603](https://github.com//rapidsai/cuml/pull/3603)) [@viclafargue](https://github.com/viclafargue)\n- Update Changelog Link ([#3601](https://github.com//rapidsai/cuml/pull/3601)) [@ajschmidt8](https://github.com/ajschmidt8)\n- Move SHAP explainers out of experimental ([#3596](https://github.com//rapidsai/cuml/pull/3596)) [@dantegd](https://github.com/dantegd)\n- Fixing compatibility issue with CUDA array interface ([#3594](https://github.com//rapidsai/cuml/pull/3594)) [@lowener](https://github.com/lowener)\n- Remove cutlass usage in row major input for euclidean exp/unexp, cosine and L1 distance matrix ([#3589](https://github.com//rapidsai/cuml/pull/3589)) [@mdoijade](https://github.com/mdoijade)\n- Test FIL probabilities with absolute error thresholds in python ([#3582](https://github.com//rapidsai/cuml/pull/3582)) [@levsnv](https://github.com/levsnv)\n- Removing sparse prims and fused l2 nn prim from cuml ([#3578](https://github.com//rapidsai/cuml/pull/3578)) [@cjnolet](https://github.com/cjnolet)\n- Prepare Changelog for Automation ([#3570](https://github.com//rapidsai/cuml/pull/3570)) [@ajschmidt8](https://github.com/ajschmidt8)\n- Print debug message if SVM convergence is poor ([#3562](https://github.com//rapidsai/cuml/pull/3562)) [@tfeher](https://github.com/tfeher)\n- Fix merge conflicts in 3552 ([#3557](https://github.com//rapidsai/cuml/pull/3557)) [@ajschmidt8](https://github.com/ajschmidt8)\n- Additional distance metrics for ANN ([#3533](https://github.com//rapidsai/cuml/pull/3533)) [@viclafargue](https://github.com/viclafargue)\n- Improve warning message when QN solver reaches max_iter ([#3515](https://github.com//rapidsai/cuml/pull/3515)) [@tfeher](https://github.com/tfeher)\n- Fix merge conflicts in 3502 ([#3513](https://github.com//rapidsai/cuml/pull/3513)) [@ajschmidt8](https://github.com/ajschmidt8)\n- Upgrade FAISS to 1.7.x ([#3509](https://github.com//rapidsai/cuml/pull/3509)) [@viclafargue](https://github.com/viclafargue)\n- ENH Pass ccache variables to conda recipe &amp; use Ninja in CI ([#3508](https://github.com//rapidsai/cuml/pull/3508)) [@Ethyling](https://github.com/Ethyling)\n- Fix forward-merger conflicts in #3502 ([#3506](https://github.com//rapidsai/cuml/pull/3506)) [@dantegd](https://github.com/dantegd)\n- Sklearn meta-estimators into namespace ([#3493](https://github.com//rapidsai/cuml/pull/3493)) [@viclafargue](https://github.com/viclafargue)\n- Add flexibility to copyright checker ([#3466](https://github.com//rapidsai/cuml/pull/3466)) [@lowener](https://github.com/lowener)\n- Update sparse KNN to use rmm device buffer ([#3460](https://github.com//rapidsai/cuml/pull/3460)) [@lowener](https://github.com/lowener)\n- Fix forward-merger conflicts in #3444 ([#3455](https://github.com//rapidsai/cuml/pull/3455)) [@ajschmidt8](https://github.com/ajschmidt8)\n- Replace ML::MetricType with raft::distance::DistanceType ([#3389](https://github.com//rapidsai/cuml/pull/3389)) [@lowener](https://github.com/lowener)\n- RF param initialization cython and C++ layer cleanup ([#3358](https://github.com//rapidsai/cuml/pull/3358)) [@venkywonka](https://github.com/venkywonka)\n- MNMG RF broadcast feature ([#3349](https://github.com//rapidsai/cuml/pull/3349)) [@viclafargue](https://github.com/viclafargue)\n- cuML&#39;s estimator Base class for preprocessing models ([#3270](https://github.com//rapidsai/cuml/pull/3270)) [@viclafargue](https://github.com/viclafargue)\n- Make `_get_tags` a class/static method ([#3257](https://github.com//rapidsai/cuml/pull/3257)) [@dantegd](https://github.com/dantegd)\n- NVTX Markers for RF and RF-backend ([#3014](https://github.com//rapidsai/cuml/pull/3014)) [@venkywonka](https://github.com/venkywonka)\n\n# cuML 0.18.0 (24 Feb 2021)\n\n## Breaking Changes 🚨\n\n- cuml.experimental SHAP improvements (#3433) @dantegd\n- Enable feature sampling for the experimental backend of Random Forest (#3364) @vinaydes\n- re-enable cuML&#39;s copyright checker script (#3363) @teju85\n- Batched Silhouette Score (#3362) @divyegala\n- Update failing MNMG tests (#3348) @viclafargue\n- Rename print_summary() of Dask RF to get_summary_text(); it now returns string to the client (#3341) @hcho3\n- Rename dump_as_json() -&gt; get_json(); expose it from Dask RF (#3340) @hcho3\n- MNMG KNN consolidation (#3307) @viclafargue\n- Return confusion matrix as int unless float weights are used (#3275) @lowener\n- Approximate Nearest Neighbors (#2780) @viclafargue\n\n## Bug Fixes 🐛\n\n- HOTFIX Add ucx-proc package back that got lost during an auto merge conflict (#3551) @dantegd\n- Non project-flash CI ml test 18.04 issue debugging and bugfixing (#3495) @dantegd\n- Temporarily xfail KBinsDiscretizer uniform tests (#3494) @wphicks\n- Fix illegal memory accesses when NITEMS &gt; 1, and nrows % NITEMS != 0. (#3480) @canonizer\n- Update call to dask client persist (#3474) @dantegd\n- Adding warning for IVFPQ (#3472) @viclafargue\n- Fix failing sparse NN test in CI by allowing small number of index discrepancies (#3454) @cjnolet\n- Exempting thirdparty code from copyright checks (#3453) @lowener\n- Relaxing Batched SilhouetteScore Test Constraint (#3452) @divyegala\n- Mark kbinsdiscretizer quantile tests as xfail (#3450) @wphicks\n- Fixing documentation on SimpleImputer (#3447) @lowener\n- Skipping IVFPQ (#3429) @viclafargue\n- Adding tol to dask test_kmeans (#3426) @lowener\n- Fix memory bug for SVM with large n_rows (#3420) @tfeher\n- Allow linear regression for  with CUDA &gt;=11.0 (#3417) @wphicks\n- Fix vectorizer tests by restoring sort behavior in groupby (#3416) @JohnZed\n- Ensure make_classification respects output type (#3415) @wphicks\n- Clean Up `#include` Dependencies (#3402) @mdemoret-nv\n- Fix Nearest Neighbor Stress Test (#3401) @lowener\n- Fix array_equal in tests (#3400) @viclafargue\n- Improving Copyright Check When Not Running in CI (#3398) @mdemoret-nv\n- Also xfail zlib errors when downloading newsgroups data (#3393) @JohnZed\n- Fix for ANN memory release bug (#3391) @viclafargue\n- XFail Holt Winters test where statsmodels has known issues with gcc 9.3.0 (#3385) @JohnZed\n- FIX Update cupy to &gt;= 7.8 and remove unused build.sh script (#3378) @dantegd\n- re-enable cuML&#39;s copyright checker script (#3363) @teju85\n- Update failing MNMG tests (#3348) @viclafargue\n- Rename print_summary() of Dask RF to get_summary_text(); it now returns string to the client (#3341) @hcho3\n- Fixing `make_blobs` to Respect the Global Output Type (#3339) @mdemoret-nv\n- Fix permutation explainer (#3332) @RAMitchell\n- k-means bug fix in debug build (#3321) @akkamesh\n- Fix for default arguments of PCA (#3320) @lowener\n- Provide workaround for cupy.percentile bug (#3315) @wphicks\n- Fix SVR unit test parameter (#3294) @tfeher\n- Add xfail on fetching 20newsgroup dataset (test_naive_bayes) (#3291) @lowener\n- Remove unused keyword in PorterStemmer code (#3289) @wphicks\n- Remove static specifier in DecisionTree unit test for C++14 compliance (#3281) @wphicks\n- Correct pure virtual declaration in manifold_inputs_t (#3279) @wphicks\n\n## Documentation 📖\n\n- Correct import path in docs for experimental preprocessing features (#3488) @wphicks\n- Minor doc updates for 0.18 (#3475) @JohnZed\n- Improve Python Docs with Default Role (#3445) @mdemoret-nv\n- Fixing Python Documentation Errors and Warnings (#3428) @mdemoret-nv\n- Remove outdated references to changelog in CONTRIBUTING.md (#3328) @wphicks\n- Adding highlighting to bibtex in readme (#3296) @cjnolet\n\n## New Features 🚀\n\n- Improve runtime performance of RF to Treelite conversion (#3410) @wphicks\n- Parallelize Treelite to FIL conversion over trees (#3396) @wphicks\n- Parallelize RF to Treelite conversion over trees (#3395) @wphicks\n- Allow saving Dask RandomForest models immediately after training (fixes #3331) (#3388) @jameslamb\n- genetic programming initial structures (#3387) @teju85\n- MNMG DBSCAN (#3382) @Nyrio\n- FIL to use L1 cache when input columns don&#39;t fit into shared memory (#3370) @levsnv\n- Enable feature sampling for the experimental backend of Random Forest (#3364) @vinaydes\n- Batched Silhouette Score (#3362) @divyegala\n- Rename dump_as_json() -&gt; get_json(); expose it from Dask RF (#3340) @hcho3\n- Exposing model_selection in a similar way to scikit-learn (#3329) @ptartan21\n- Promote IncrementalPCA from experimental in 0.18 release (#3327) @lowener\n- Create labeler.yml (#3324) @jolorunyomi\n- Add slow high-precision mode to KNN (#3304) @wphicks\n- Sparse TSNE (#3293) @divyegala\n- Sparse Generalized SPMV (semiring) Primitive (#3146) @cjnolet\n- Multiclass meta estimator wrappers and multiclass SVC (#3092) @tfeher\n- Approximate Nearest Neighbors (#2780) @viclafargue\n- Add KNN parameter to t-SNE (#2592) @aleksficek\n\n## Improvements 🛠️\n\n- Update stale GHA with exemptions &amp; new labels (#3507) @mike-wendt\n- Add GHA to mark issues/prs as stale/rotten (#3500) @Ethyling\n- Fix naive bayes inputs (#3448) @cjnolet\n- Prepare Changelog for Automation (#3442) @ajschmidt8\n- cuml.experimental SHAP improvements (#3433) @dantegd\n- Speed up knn tests (#3411) @JohnZed\n- Replacing sklearn functions with cuml in RF MNMG notebook (#3408) @lowener\n- Auto-label PRs based on their content (#3407) @jolorunyomi\n- Use stable 1.0.0 version of Treelite (#3394) @hcho3\n- API update to match RAFT PR #120 (#3386) @drobison00\n- Update linear models to use RMM memory allocation (#3365) @lowener\n- Updating dense pairwise distance enum names (#3352) @cjnolet\n- Upgrade Treelite module (#3316) @hcho3\n- Removed FIL node types with `_t` suffix (#3314) @canonizer\n- MNMG KNN consolidation (#3307) @viclafargue\n- Updating PyTests to Stay Below 4 Gb Limit (#3306) @mdemoret-nv\n- Refactoring: move internal FIL interface to a separate file (#3292) @canonizer\n- Return confusion matrix as int unless float weights are used (#3275) @lowener\n- 018 add unfitted error pca &amp; tests on IPCA (#3272) @lowener\n- Linear models predict function consolidation (#3256) @dantegd\n- Preparing sparse primitives for movement to RAFT (#3157) @cjnolet\n\n# cuML 0.17.0 (10 Dec 2020)\n\n## New Features\n- PR #3164: Expose silhouette score in Python\n- PR #3160: Least Angle Regression (experimental)\n- PR #2659: Add initial max inner product sparse knn\n- PR #3092: Multiclass meta estimator wrappers and multiclass SVC\n- PR #2836: Refactor UMAP to accept sparse inputs\n- PR #2894: predict_proba in FIL C++ for XGBoost-style multi-class models\n- PR #3126: Experimental versions of GPU accelerated Kernel and Permutation SHAP\n\n## Improvements\n- PR #3077: Improve runtime for test_kmeans\n- PR #3070: Speed up dask/test_datasets tests\n- PR #3075: Speed up test_linear_model tests\n- PR #3078: Speed up test_incremental_pca tests\n- PR #2902: `matrix/matrix.cuh` in RAFT namespacing\n- PR #2903: Moving linalg's gemm, gemv, transpose to RAFT namespaces\n- PR #2905: `stats` prims `mean_center`, `sum` to RAFT namespaces\n- PR #2904: Moving `linalg` basic math ops to RAFT namespaces\n- PR #2956: Follow cuML array conventions in ARIMA and remove redundancy\n- PR #3000: Pin cmake policies to cmake 3.17 version, bump project version to 0.17\n- PR #3083: Improving test_make_blobs testing time\n- PR #3223: Increase default SVM kernel cache to 2000 MiB\n- PR #2906: Moving `linalg` decomp to RAFT namespaces\n- PR #2988: FIL: use tree-per-class reduction for GROVE_PER_CLASS_FEW_CLASSES\n- PR #2996: Removing the max_depth restriction for switching to the batched backend\n- PR #3004: Remove Single Process Multi GPU (SPMG) code\n- PR #3032: FIL: Add optimization parameter `blocks_per_sm` that will help all but tiniest models\n- PR #3044: Move leftover `linalg` and `stats` to RAFT namespaces\n- PR #3067: Deleting prims moved to RAFT and updating header paths\n- PR #3074: Reducing dask coordinate descent test runtime\n- PR #3096: Avoid memory transfers in CSR WeakCC for DBSCAN\n- PR #3088: More readable and robust FIL C++ test management\n- PR #3052: Speeding up MNMG KNN Cl&Re testing\n- PR #3115: Speeding up MNMG UMAP testing\n- PR #3112: Speed test_array\n- PR #3111: Adding Cython to Code Coverage\n- PR #3129: Update notebooks README\n- PR #3002: Update flake8 Config To With Per File Settings\n- PR #3135: Add QuasiNewton tests\n- PR #3040: Improved Array Conversion with CumlArrayDescriptor and Decorators\n- PR #3134: Improving the Deprecation Message Formatting in Documentation\n- PR #3154: Adding estimator pickling demo notebooks (and docs)\n- PR #3151: MNMG Logistic Regression via dask-glm\n- PR #3113: Add tags and prefered memory order tags to estimators\n- PR #3137: Reorganize Pytest Config and Add Quick Run Option\n- PR #3144: Adding Ability to Set Arbitrary Cmake Flags in ./build.sh\n- PR #3155: Eliminate unnecessary warnings from random projection test\n- PR #3176: Add probabilistic SVM tests with various input array types\n- PR #3180: FIL: `blocks_per_sm` support in Python\n- PR #3186: Add gain to RF JSON dump\n- PR #3219: Update CI to use XGBoost 1.3.0 RCs\n- PR #3221: Update contributing doc for label support\n- PR #3177: Make Multinomial Naive Bayes inherit from `ClassifierMixin` and use it for score\n- PR #3241: Updating RAFT to latest\n- PR #3240: Minor doc updates\n- PR #3275: Return confusion matrix as int unless float weights are used\n\n## Bug Fixes\n- PR #3218: Specify dependency branches in conda dev environment to avoid pip resolver issue\n- PR #3196: Disable ascending=false path for sortColumnsPerRow\n- PR #3051: MNMG KNN Cl&Re fix + multiple improvements\n- PR #3179: Remove unused metrics.cu file\n- PR #3069: Prevent conversion of DataFrames to Series in preprocessing\n- PR #3065: Refactoring prims metrics function names from camelcase to underscore format\n- PR #3033: Splitting ml metrics to individual files\n- PR #3072: Fusing metrics and score directories in src_prims\n- PR #3037: Avoid logging deadlock in multi-threaded C code\n- PR #2983: Fix seeding of KISS99 RNG\n- PR #3011: Fix unused initialize_embeddings parameter in Barnes-Hut t-SNE\n- PR #3008: Check number of columns in check_array validator\n- PR #3012: Increasing learning rate for SGD log loss and invscaling pytests\n- PR #2950: Fix includes in UMAP\n- PR #3194: Fix cuDF to cuPy conversion (missing value)\n- PR #3021: Fix a hang in cuML RF experimental backend\n- PR #3039: Update RF and decision tree parameter initializations in benchmark codes\n- PR #3060: Speed up test suite `test_fil`\n- PR #3061: Handle C++ exception thrown from FIL predict\n- PR #3073: Update mathjax CDN URL for documentation\n- PR #3062: Bumping xgboost version to match cuml version\n- PR #3084: Fix artifacts in t-SNE results\n- PR #3086: Reverting FIL Notebook Testing\n- PR #3192: Enable pipeline usage for OneHotEncoder and LabelEncoder\n- PR #3114: Fixed a typo in SVC's predict_proba AttributeError\n- PR #3117: Fix two crashes in experimental RF backend\n- PR #3119: Fix memset args for benchmark\n- PR #3130: Return Python string from `dump_as_json()` of RF\n- PR #3132: Add `min_samples_split` + Rename `min_rows_per_node` -> `min_samples_leaf`\n- PR #3136: Fix stochastic gradient descent example\n- PR #3152: Fix access to attributes of individual NB objects in dask NB\n- PR #3156: Force local conda artifact install\n- PR #3162: Removing accidentally checked in debug file\n- PR #3191: Fix __repr__ function for preprocessing models\n- PR #3175: Fix gtest pinned cmake version for build from source option\n- PR #3182: Fix a bug in MSE metric calculation\n- PR #3187: Update docstring to document behavior of `bootstrap=False`\n- PR #3215: Add a missing `__syncthreads()`\n- PR #3246: Fix MNMG KNN doc (adding batch_size)\n- PR #3185: Add documentation for Distributed TFIDF Transformer\n- PR #3190: Fix Attribute error on ICPA #3183 and PCA input type\n- PR #3208: Fix EXITCODE override in notebook test script\n- PR #3250: Fixing label binarizer bug with multiple partitions\n- PR #3214: Correct flaky silhouette score test by setting atol\n- PR #3216: Ignore splits that do not satisfy constraints\n- PR #3239: Fix intermittent dask random forest failure\n- PR #3243: Avoid unnecessary split for degenerate case where all labels are identical\n- PR #3245: Rename `rows_sample` -> `max_samples` to be consistent with sklearn's RF\n- PR #3282: Add secondary test to kernel explainer pytests for stability in Volta\n\n# cuML 0.16.0 (23 Oct 2020)\n\n## New Features\n- PR #2922: Install RAFT headers with cuML\n- PR #2909: Update allgatherv for compatibility with latest RAFT\n- PR #2677: Ability to export RF trees as JSON\n- PR #2698: Distributed TF-IDF transformer\n- PR #2476: Porter Stemmer\n- PR #2789: Dask LabelEncoder\n- PR #2152: add FIL C++ benchmark\n- PR #2638: Improve cython build with custom `build_ext`\n- PR #2866: Support XGBoost-style multiclass models (gradient boosted decision trees) in FIL C++\n- PR #2874: Issue warning for degraded accuracy with float64 models in Treelite\n- PR #2881: Introduces experimental batched backend for random forest\n- PR #2916: Add SKLearn multi-class GBDT model support in FIL\n\n## Improvements\n- PR #2947: Add more warnings for accuracy degradation with 64-bit models\n- PR #2873: Remove empty marker kernel code for NVTX markers\n- PR #2796: Remove tokens of length 1 by default for text vectorizers\n- PR #2741: Use rapids build packages in conda environments\n- PR #2735: Update seed to random_state in random forest and associated tests\n- PR #2739: Use cusparse_wrappers.h from RAFT\n- PR #2729: Replace `cupy.sparse` with `cupyx.scipy.sparse`\n- PR #2749: Correct docs for python version used in cuml_dev conda environment\n- PR #2747: Adopting raft::handle_t and raft::comms::comms_t in cuML\n- PR #2762: Fix broken links and provide minor edits to docs\n- PR #2723: Support and enable convert_dtype in estimator predict\n- PR #2758: Match sklearn's default n_components behavior for PCA\n- PR #2770: Fix doxygen version during cmake\n- PR #2766: Update default RandomForestRegressor score function to use r2\n- PR #2775: Enablinbg mg gtests w/ raft mpi comms\n- PR #2783: Add pytest that will fail when GPU IDs in Dask cluster are not unique\n- PR #2784: Add SparseCumlArray container for sparse index/data arrays\n- PR #2785: Add in cuML-specific dev conda dependencies\n- PR #2778: Add README for FIL\n- PR #2799: Reenable lightgbm test with lower (1%) proba accuracy\n- PR #2800: Align cuML's spdlog version with RMM's\n- PR #2824: Make data conversions warnings be debug level\n- PR #2835: Rng prims, utils, and dependencies in RAFT\n- PR #2541: Improve Documentation Examples and Source Linking\n- PR #2837: Make the FIL node reorder loop more obvious\n- PR #2849: make num_classes significant in FLOAT_SCALAR case\n- PR #2792: Project flash (new build process) script changes\n- PR #2850: Clean up unused params in paramsPCA\n- PR #2871: Add timing function to utils\n- PR #2863: in FIL, rename leaf_value_t enums to more descriptive\n- PR #2867: improve stability of FIL benchmark measurements\n- PR #2798: Add python tests for FIL multiclass classification of lightgbm models\n- PR #2892: Update ci/local/README.md\n- PR #2910: Adding Support for CuPy 8.x\n- PR #2914: Add tests for XGBoost multi-class models in FIL\n- PR #2622: Simplify tSNE perplexity search\n- PR #2930: Pin libfaiss to <=1.6.3\n- PR #2928: Updating Estimators Derived from Base for Consistency\n- PR #2942: Adding `cuml.experimental` to the Docs\n- PR #3010: Improve gpuCI Scripts\n- PR #3141: Move DistanceType enum to RAFT\n\n## Bug Fixes\n- PR #2973: Allow data imputation for nan values\n- PR #2982: Adjust kneighbors classifier test threshold to avoid intermittent failure\n- PR #2885: Changing test target for NVTX wrapper test\n- PR #2882: Allow import on machines without GPUs\n- PR #2875: Bug fix to enable colorful NVTX markers\n- PR #2744: Supporting larger number of classes in KNeighborsClassifier\n- PR #2769: Remove outdated doxygen options for 1.8.20\n- PR #2787: Skip lightgbm test for version 3 and above temporarily\n- PR #2805: Retain index in stratified splitting for dataframes\n- PR #2781: Use Python print to correctly redirect spdlogs when sys.stdout is changed\n- PR #2787: Skip lightgbm test for version 3 and above temporarily\n- PR #2813: Fix memory access in generation of non-row-major random blobs\n- PR #2810: Update Rf MNMG threshold to prevent sporadic test failure\n- PR #2808: Relax Doxygen version required in CMake to coincide with integration repo\n- PR #2818: Fix parsing of singlegpu option in build command\n- PR #2827: Force use of whole dataset when sample bootstrapping is disabled\n- PR #2829: Fixing description for labels in docs and removing row number constraint from PCA xform/inverse_xform\n- PR #2832: Updating stress tests that fail with OOM\n- PR #2831: Removing repeated capture and parameter in lambda function\n- PR #2847: Workaround for TSNE lockup, change caching preference.\n- PR #2842: KNN index preprocessors were using incorrect n_samples\n- PR #2848: Fix typo in Python docstring for UMAP\n- PR #2856: Fix LabelEncoder for filtered input\n- PR #2855: Updates for RMM being header only\n- PR #2844: Fix for OPG KNN Classifier & Regressor\n- PR #2880: Fix bugs in Auto-ARIMA when s==None\n- PR #2877: TSNE exception for n_components > 2\n- PR #2879: Update unit test for LabelEncoder on filtered input\n- PR #2932: Marking KBinsDiscretizer pytests as xfail\n- PR #2925: Fixing Owner Bug When Slicing CumlArray Objects\n- PR #2931: Fix notebook error handling in gpuCI\n- PR #2941: Fixing dask tsvd stress test failure\n- PR #2943: Remove unused shuffle_features parameter\n- PR #2940: Correcting labels meta dtype for `cuml.dask.make_classification`\n- PR #2965: Notebooks update\n- PR #2955: Fix for conftest for singlegpu build\n- PR #2968: Remove shuffle_features from RF param names\n- PR #2957: Fix ols test size for stability\n- PR #2972: Upgrade Treelite to 0.93\n- PR #2981: Prevent unguarded import of sklearn in SVC\n- PR #2984: Fix GPU test scripts gcov error\n- PR #2990: Reduce MNMG kneighbors regressor test threshold\n- PR #2997: Changing ARIMA `get/set_params` to `get/set_fit_params`\n\n# cuML 0.15.0 (26 Aug 2020)\n\n## New Features\n- PR #2581: Added model persistence via joblib in each section of estimator_intro.ipynb\n- PR #2554: Hashing Vectorizer and general vectorizer improvements\n- PR #2240: Making Dask models pickleable\n- PR #2267: CountVectorizer estimator\n- PR #2261: Exposing new FAISS metrics through Python API\n- PR #2287: Single-GPU TfidfTransformer implementation\n- PR #2289: QR SVD solver for MNMG PCA\n- PR #2312: column-major support for make_blobs\n- PR #2172: Initial support for auto-ARIMA\n- PR #2394: Adding cosine & correlation distance for KNN\n- PR #2392: PCA can accept sparse inputs, and sparse prim for computing covariance\n- PR #2465: Support pandas 1.0+\n- PR #2550: Single GPU Target Encoder\n- PR #2519: Precision recall curve using cupy\n- PR #2500: Replace UMAP functionality dependency on nvgraph with RAFT Spectral Clustering\n- PR #2502: cuML Implementation of `sklearn.metrics.pairwise_distances`\n- PR #2520: TfidfVectorizer estimator\n- PR #2211: MNMG KNN Classifier & Regressor\n- PR #2461: Add KNN Sparse Output Functionality\n- PR #2615: Incremental PCA\n- PR #2594: Confidence intervals for ARIMA forecasts\n- PR #2607: Add support for probability estimates in SVC\n- PR #2618: SVM class and sample weights\n- PR #2635: Decorator to generate docstrings with autodetection of parameters\n- PR #2270: Multi class MNMG RF\n- PR #2661: CUDA-11 support for single-gpu code\n- PR #2322: Sparse FIL forests with 8-byte nodes\n- PR #2675: Update conda recipes to support CUDA 11\n- PR #2645: Add experimental, sklearn-based preprocessing\n\n## Improvements\n- PR #2336: Eliminate `rmm.device_array` usage\n- PR #2262: Using fully shared PartDescriptor in MNMG decomposiition, linear models, and solvers\n- PR #2310: Pinning ucx-py to 0.14 to make 0.15 CI pass\n- PR #1945: enable clang tidy\n- PR #2339: umap performance improvements\n- PR #2308: Using fixture for Dask client to eliminate possibility of not closing\n- PR #2345: make C++ logger level definition to be the same as python layer\n- PR #2329: Add short commit hash to conda package name\n- PR #2362: Implement binary/multi-classification log loss with cupy\n- PR #2363: Update threshold and make other changes for stress tests\n- PR #2371: Updating MBSGD tests to use larger batches\n- PR #2380: Pinning libcumlprims version to ease future updates\n- PR #2405: Remove references to deprecated RMM headers.\n- PR #2340: Import ARIMA in the root init file and fix the `test_fit_function` test\n- PR #2408: Install meta packages for dependencies\n- PR #2417: Move doc customization scripts to Jenkins\n- PR #2427: Moving MNMG decomposition to cuml\n- PR #2433: Add libcumlprims_mg to CMake\n- PR #2420: Add and set convert_dtype default to True in estimator fit methods\n- PR #2411: Refactor Mixin classes and use in classifier/regressor estimators\n- PR #2442: fix setting RAFT_DIR from the RAFT_PATH env var\n- PR #2469: Updating KNN c-api to document all arguments\n- PR #2453: Add CumlArray to API doc\n- PR #2440: Use Treelite Conda package\n- PR #2403: Support for input and output type consistency in logistic regression predict_proba\n- PR #2473: Add metrics.roc_auc_score to API docs. Additional readability and minor docs bug fixes\n- PR #2468: Add `_n_features_in_` attribute to all single GPU estimators that implement fit\n- PR #2489: Removing explicit FAISS build and adding dependency on libfaiss conda package\n- PR #2480: Moving MNMG glm and solvers to cuml\n- PR #2490: Moving MNMG KMeans to cuml\n- PR #2483: Moving MNMG KNN to cuml\n- PR #2492: Adding additional assertions to mnmg nearest neighbors pytests\n- PR #2439: Update dask RF code to have print_detailed function\n- PR #2431: Match output of classifier predict with target dtype\n- PR #2237: Refactor RF cython code\n- PR #2513: Fixing LGTM Analysis Issues\n- PR #2099: Raise an error when float64 data is used with dask RF\n- PR #2522: Renaming a few arguments in KNeighbors* to be more readable\n- PR #2499: Provide access to `cuml.DBSCAN` core samples\n- PR #2526: Removing PCA TSQR as a solver due to scalability issues\n- PR #2536: Update conda upload versions for new supported CUDA/Python\n- PR #2538: Remove Protobuf dependency\n- PR #2553: Test pickle protocol 5 support\n- PR #2570: Accepting single df or array input in train_test_split\n- PR #2566: Remove deprecated cuDF from_gpu_matrix calls\n- PR #2583: findpackage.cmake.in template for cmake dependencies\n- PR #2577: Fully removing NVGraph dependency for CUDA 11 compatibility\n- PR #2575: Speed up TfidfTransformer\n- PR #2584: Removing dependency on sklearn's NotFittedError\n- PR #2591: Generate benchmark datsets using `cuml.datasets`\n- PR #2548: Fix limitation on number of rows usable with tSNE and refactor memory allocation\n- PR #2589: including cuda-11 build fixes into raft\n- PR #2599: Add Stratified train_test_split\n- PR #2487: Set classes_ attribute during classifier fit\n- PR #2605: Reduce memory usage in tSNE\n- PR #2611: Adding building doxygen docs to gpu ci\n- PR #2631: Enabling use of gtest conda package for build\n- PR #2623: Fixing kmeans score() API to be compatible with Scikit-learn\n- PR #2629: Add naive_bayes api docs\n- PR #2643: 'dense' and 'sparse' values of `storage_type` for FIL\n- PR #2691: Generic Base class attribute setter\n- PR #2666: Update MBSGD documentation to mention that the model is experimental\n- PR #2687: Update xgboost version to 1.2.0dev.rapidsai0.15\n- PR #2684: CUDA 11 conda development environment yml and faiss patch\n- PR #2648: Replace CNMeM with `rmm::mr::pool_memory_resource`.\n- PR #2686: Improve SVM tests\n- PR #2692: Changin LBFGS log level\n- PR #2705: Add sum operator and base operator overloader functions to cumlarray\n- PR #2701: Updating README + Adding ref to UMAP paper\n- PR #2721: Update API docs\n- PR #2730: Unpin cumlprims in conda recipes for release\n\n## Bug Fixes\n- PR #2369: Update RF code to fix set_params memory leak\n- PR #2364: Fix for random projection\n- PR #2373: Use Treelite Pip package in GPU testing\n- PR #2376: Update documentation Links\n- PR #2407: fixed batch count in DBScan for integer overflow case\n- PR #2413: CumlArray and related methods updates to account for cuDF.Buffer contiguity update\n- PR #2424: --singlegpu flag fix on build.sh script\n- PR #2432: Using correct algo_name for UMAP in benchmark tests\n- PR #2445: Restore access to coef_ property of Lasso\n- PR #2441: Change p2p_enabled definition to work without ucx\n- PR #2447: Drop `nvstrings`\n- PR #2450: Update local build to use new gpuCI image\n- PR #2454: Mark RF memleak test as XFAIL, because we can't detect memleak reliably\n- PR #2455: Use correct field to store data type in `LabelEncoder.fit_transform`\n- PR #2475: Fix typo in build.sh\n- PR #2496: Fixing indentation for simulate_data in test_fil.py\n- PR #2494: Set QN regularization strength consistent with scikit-learn\n- PR #2486: Fix cupy input to kmeans init\n- PR #2497: Changes to accommodate cuDF unsigned categorical changes\n- PR #2209: Fix FIL benchmark for gpuarray-c input\n- PR #2507: Import `treelite.sklearn`\n- PR #2521: Fixing invalid smem calculation in KNeighborsCLassifier\n- PR #2515: Increase tolerance for LogisticRegression test\n- PR #2532: Updating doxygen in new MG headers\n- PR #2521: Fixing invalid smem calculation in KNeighborsCLassifier\n- PR #2515: Increase tolerance for LogisticRegression test\n- PR #2545: Fix documentation of n_iter_without_progress in tSNE Python bindings\n- PR #2543: Improve numerical stability of QN solver\n- PR #2544: Fix Barnes-Hut tSNE not using specified post_learning_rate\n- PR #2558: Disabled a long-running FIL test\n- PR #2540: Update default value for n_epochs in UMAP to match documentation & sklearn API\n- PR #2535: Fix issue with incorrect docker image being used in local build script\n- PR #2542: Fix small memory leak in TSNE\n- PR #2552: Fixed the length argument of updateDevice calls in RF test\n- PR #2565: Fix cell allocation code to avoid loops in quad-tree. Prevent NaNs causing infinite descent\n- PR #2563: Update scipy call for arima gradient test\n- PR #2569: Fix for cuDF update\n- PR #2508: Use keyword parameters in sklearn.datasets.make_* functions\n- PR #2587: Attributes for estimators relying on solvers\n- PR #2586: Fix SVC decision function data type\n- PR #2573: Considering managed memory as device type on checking for KMeans\n- PR #2574: Fixing include path in `tsvd_mg.pyx`\n- PR #2506: Fix usage of CumlArray attributes on `cuml.common.base.Base`\n- PR #2593: Fix inconsistency in train_test_split\n- PR #2609: Fix small doxygen issues\n- PR #2610: Remove cuDF tolist call\n- PR #2613: Removing thresholds from kmeans score tests (SG+MG)\n- PR #2616: Small test code fix for pandas dtype tests\n- PR #2617: Fix floating point precision error in tSNE\n- PR #2625: Update Estimator notebook to resolve errors\n- PR #2634: singlegpu build option fixes\n- PR #2641: [Breaking] Make `max_depth` in RF compatible with scikit-learn\n- PR #2650: Make max_depth behave consistently for max_depth > 14\n- PR #2651: AutoARIMA Python bug fix\n- PR #2654: Fix for vectorizer concatenations\n- PR #2655: Fix C++ RF predict function access of rows/samples array\n- PR #2649: Cleanup sphinx doc warnings for 0.15\n- PR #2668: Order conversion improvements to account for cupy behavior changes\n- PR #2669: Revert PR 2655 Revert \"Fixes C++ RF predict function\"\n- PR #2683: Fix incorrect \"Bad CumlArray Use\" error messages on test failures\n- PR #2695: Fix debug build issue due to incorrect host/device method setup\n- PR #2709: Fixing OneHotEncoder Overflow Error\n- PR #2710: Fix SVC doc statement about predic_proba\n- PR #2726: Return correct output type in QN\n- PR #2711: Fix Dask RF failure intermittently\n- PR #2718: Fix temp directory for py.test\n- PR #2719: Set KNeighborsRegressor output dtype according to training target dtype\n- PR #2720: Updates to outdated links\n- PR #2722: Getting cuML covariance test passing w/ Cupy 7.8 & CUDA 11\n\n# cuML 0.14.0 (03 Jun 2020)\n\n## New Features\n- PR #1994: Support for distributed OneHotEncoder\n- PR #1892: One hot encoder implementation with cupy\n- PR #1655: Adds python bindings for homogeneity score\n- PR #1704: Adds python bindings for completeness score\n- PR #1687: Adds python bindings for mutual info score\n- PR #1980: prim: added a new write-only unary op prim\n- PR #1867: C++: add logging interface support in cuML based spdlog\n- PR #1902: Multi class inference in FIL C++ and importing multi-class forests from treelite\n- PR #1906: UMAP MNMG\n- PR #2067: python: wrap logging interface in cython\n- PR #2083: Added dtype, order, and use_full_low_rank to MNMG `make_regression`\n- PR #2074: SG and MNMG `make_classification`\n- PR #2127: Added order to SG `make_blobs`, and switch from C++ to cupy based implementation\n- PR #2057: Weighted k-means\n- PR #2256: Add a `make_arima` generator\n- PR #2245: ElasticNet, Lasso and Coordinate Descent MNMG\n- PR #2242: Pandas input support with output as NumPy arrays by default\n- PR #2551: Add cuML RF multiclass prediction using FIL from python\n- PR #1728: Added notebook testing to gpuCI gpu build\n\n## Improvements\n- PR #1931: C++: enabled doxygen docs for all of the C++ codebase\n- PR #1944: Support for dask_cudf.core.Series in _extract_partitions\n- PR #1947: Cleaning up cmake\n- PR #1927: Use Cython's `new_build_ext` (if available)\n- PR #1946: Removed zlib dependency from cmake\n- PR #1988: C++: cpp bench refactor\n- PR #1873: Remove usage of nvstring and nvcat from LabelEncoder\n- PR #1968: Update SVC SVR with cuML Array\n- PR #1972: updates to our flow to use conda-forge's clang and clang-tools packages\n- PR #1974: Reduce ARIMA testing time\n- PR #1984: Enable Ninja build\n- PR #1985: C++ UMAP parametrizable tests\n- PR #2005: Adding missing algorithms to cuml benchmarks and notebook\n- PR #2016: Add capability to setup.py and build.sh to fully clean all cython build files and artifacts\n- PR #2044: A cuda-memcheck helper wrapper for devs\n- PR #2018: Using `cuml.dask.part_utils.extract_partitions` and removing similar, duplicated code\n- PR #2019: Enable doxygen build in our nightly doc build CI script\n- PR #1996: Cythonize in parallel\n- PR #2032: Reduce number of tests for MBSGD to improve CI running time\n- PR #2031: Encapsulating UCX-py interactions in singleton\n- PR #2029: Add C++ ARIMA log-likelihood benchmark\n- PR #2085: Convert TSNE to use CumlArray\n- PR #2051: Reduce the time required to run dask pca and dask tsvd tests\n- PR #1981: Using CumlArray in kNN and DistributedDataHandler in dask kNN\n- PR #2053: Introduce verbosity level in C++ layer instead of boolean `verbose` flag\n- PR #2047: Make internal streams non-blocking w.r.t. NULL stream\n- PR #2048: Random forest testing speedup\n- PR #2058: Use CumlArray in Random Projection\n- PR #2068: Updating knn class probabilities to use make_monotonic instead of binary search\n- PR #2062: Adding random state to UMAP mnmg tests\n- PR #2064: Speed-up K-Means test\n- PR #2015: Renaming .h to .cuh in solver, dbscan and svm\n- PR #2080: Improved import of sparse FIL forests from treelite\n- PR #2090: Upgrade C++ build to C++14 standard\n- PR #2089: CI: enabled cuda-memcheck on ml-prims unit-tests during nightly build\n- PR #2128: Update Dask RF code to reduce the time required for GPU predict to run\n- PR #2125: Build infrastructure to use RAFT\n- PR #2131: Update Dask RF fit to use DistributedDataHandler\n- PR #2055: Update the metrics notebook to use important cuML models\n- PR #2095: Improved import of src_prims/utils.h, making it less ambiguous\n- PR #2118: Updating SGD & mini-batch estimators to use CumlArray\n- PR #2120: Speeding up dask RandomForest tests\n- PR #1883: Use CumlArray in ARIMA\n- PR #877: Adding definition of done criteria to wiki\n- PR #2135: A few optimizations to UMAP fuzzy simplicial set\n- PR #1914: Change the meaning of ARIMA's intercept to match the literature\n- PR #2098: Renaming .h to .cuh in decision_tree, glm, pca\n- PR #2150: Remove deprecated RMM calls in RMM allocator adapter\n- PR #2146: Remove deprecated kalman filter\n- PR #2151: Add pytest duration and pytest timeout\n- PR #2156: Add Docker 19 support to local gpuci build\n- PR #2178: Reduce duplicated code in RF\n- PR #2124: Expand tutorial docs and sample notebook\n- PR #2175: Allow CPU-only and dataset params for benchmark sweeps\n- PR #2186: Refactor cython code to build OPG structs in common utils file\n- PR #2180: Add fully single GPU singlegpu python build\n- PR #2187: CMake improvements to manage conda environment dependencies\n- PR #2185: Add has_sklearn function and use it in datasets/classification.\n- PR #2193: Order-independent local shuffle in `cuml.dask.make_regression`\n- PR #2204: Update python layer to use the logger interface\n- PR #2184: Refoctor headers for holtwinters, rproj, tsvd, tsne, umap\n- PR #2199: Remove unncessary notebooks\n- PR #2195: Separating fit and transform calls in SG, MNMG PCA to save transform array memory consumption\n- PR #2201: Re-enabling UMAP repro tests\n- PR #2132: Add SVM C++ benchmarks\n- PR #2196: Updates to benchmarks. Moving notebook\n- PR #2208: Coordinate Descent, Lasso and ElasticNet CumlArray updates\n- PR #2210: Updating KNN tests to evaluate multiple index partitions\n- PR #2205: Use timeout to add 2 hour hard limit to dask tests\n- PR #2212: Improve DBScan batch count / memory estimation\n- PR #2213: Standardized include statements across all cpp source files, updated copyright on all modified files\n- PR #2214: Remove utils folder and refactor to common folder\n- PR #2220: Final refactoring of all src_prims header files following rules as specified in #1675\n- PR #2225: input_to_cuml_array keep order option, test updates and cleanup\n- PR #2244: Re-enable slow ARIMA tests as stress tests\n- PR #2231: Using OPG structs from `cuml.common` in decomposition algorithms\n- PR #2257: Update QN and LogisticRegression to use CumlArray\n- PR #2259: Add CumlArray support to Naive Bayes\n- PR #2252: Add benchmark for the Gram matrix prims\n- PR #2263: Faster serialization for Treelite objects with RF\n- PR #2264: Reduce build time for cuML by using make_blobs from libcuml++ interface\n- PR #2269: Add docs targets to build.sh and fix python cuml.common docs\n- PR #2271: Clarify doc for `_unique` default implementation in OneHotEncoder\n- PR #2272: Add docs build.sh script to repository\n- PR #2276: Ensure `CumlArray` provided `dtype` conforms\n- PR #2281: Rely on cuDF's `Serializable` in `CumlArray`\n- PR #2284: Reduce dataset size in SG RF notebook to reduce run time of sklearn\n- PR #2285: Increase the threshold for elastic_net test in dask/test_coordinate_descent\n- PR #2314: Update FIL default values, documentation and test\n- PR #2316: 0.14 release docs additions and fixes\n- PR #2320: Add prediction notes to RF docs\n- PR #2323: Change verbose levels and parameter name to match Scikit-learn API\n- PR #2324: Raise an error if n_bins > number of training samples in RF\n- PR #2335: Throw a warning if treelite cannot be imported and `load_from_sklearn` is used\n\n## Bug Fixes\n- PR #1939: Fix syntax error in cuml.common.array\n- PR #1941: Remove c++ cuda flag that was getting duplicated in CMake\n- PR #1971: python: Correctly honor --singlegpu option and CUML_BUILD_PATH env variable\n- PR #1969: Update libcumlprims to 0.14\n- PR #1973: Add missing mg files for setup.py --singlegpu flag\n- PR #1993: Set `umap_transform_reproducibility` tests to xfail\n- PR #2004: Refactoring the arguments to `plant()` call\n- PR #2017: Fixing memory issue in weak cc prim\n- PR #2028: Skipping UMAP knn reproducibility tests until we figure out why its failing in CUDA 10.2\n- PR #2024: Fixed cuda-memcheck errors with sample-without-replacement prim\n- PR #1540: prims: support for custom math-type used for computation inside adjusted rand index prim\n- PR #2077: dask-make blobs arguments to match sklearn\n- PR #2059: Make all Scipy imports conditional\n- PR #2078: Ignore negative cache indices in get_vecs\n- PR #2084: Fixed cuda-memcheck errors with COO unit-tests\n- PR #2087: Fixed cuda-memcheck errors with dispersion prim\n- PR #2096: Fixed syntax error with nightly build command for memcheck unit-tests\n- PR #2115: Fixed contingency matrix prim unit-tests for computing correct golden values\n- PR #2107: Fix PCA transform\n- PR #2109: input_to_cuml_array __cuda_array_interface__ bugfix\n- PR #2117: cuDF __array__ exception small fixes\n- PR #2139: CumlArray for adjusted_rand_score\n- PR #2140: Returning self in fit model functions\n- PR #2144: Remove GPU arch < 60 from CMake build\n- PR #2153: Added missing namespaces to some Decision Tree files\n- PR #2155: C++: fix doxygen build break\n- PR #2161: Replacing depreciated bruteForceKnn\n- PR #2162: Use stream in transpose prim\n- PR #2165: Fit function test correction\n- PR #2166: Fix handling of temp file in RF pickling\n- PR #2176: C++: fix for adjusted rand index when input array is all zeros\n- PR #2179: Fix clang tools version in libcuml recipe\n- PR #2183: Fix RAFT in nightly package\n- PR #2191: Fix placement of SVM parameter documentation and add examples\n- PR #2212: Fix DBScan results (no propagation of labels through border points)\n- PR #2215: Fix the printing of forest object\n- PR #2217: Fix opg_utils naming to fix singlegpu build\n- PR #2223: Fix bug in ARIMA C++ benchmark\n- PR #2224: Temporary fix for CI until new Dask version is released\n- PR #2228: Update to use __reduce_ex__ in CumlArray to override cudf.Buffer\n- PR #2249: Fix bug in UMAP continuous target metrics\n- PR #2258: Fix doxygen build break\n- PR #2255: Set random_state for train_test_split function in dask RF\n- PR #2275: Fix RF fit memory leak\n- PR #2274: Fix parameter name verbose to verbosity in mnmg OneHotEncoder\n- PR #2277: Updated cub repo path and branch name\n- PR #2282: Fix memory leak in Dask RF concatenation\n- PR #2301: Scaling KNN dask tests sample size with n GPUs\n- PR #2293: Contiguity fixes for input_to_cuml_array and train_test_split\n- PR #2295: Fix convert_to_dtype copy even with same dtype\n- PR #2305: Fixed race condition in DBScan\n- PR #2354: Fix broken links in README\n- PR #2619: Explicitly skip raft test folder for pytest 6.0.0\n- PR #2788: Set the minimum number of columns that can be sampled to 1 to fix 0 mem allocation error\n\n# cuML 0.13.0 (31 Mar 2020)\n\n## New Features\n- PR #1777: Python bindings for entropy\n- PR #1742: Mean squared error implementation with cupy\n- PR #1817: Confusion matrix implementation with cupy (SNSG and MNMG)\n- PR #1766: Mean absolute error implementation with cupy\n- PR #1766: Mean squared log error implementation with cupy\n- PR #1635: cuML Array shim and configurable output added to cluster methods\n- PR #1586: Seasonal ARIMA\n- PR #1683: cuml.dask make_regression\n- PR #1689: Add framework for cuML Dask serializers\n- PR #1709: Add `decision_function()` and `predict_proba()` for LogisticRegression\n- PR #1714: Add `print_env.sh` file to gather important environment details\n- PR #1750: LinearRegression CumlArray for configurable output\n- PR #1814: ROC AUC score implementation with cupy\n- PR #1767: Single GPU decomposition models configurable output\n- PR #1646: Using FIL to predict in MNMG RF\n- PR #1778: Make cuML Handle picklable\n- PR #1738: cuml.dask refactor beginning and dask array input option for OLS, Ridge and KMeans\n- PR #1874: Add predict_proba function to RF classifier\n- PR #1815: Adding KNN parameter to UMAP\n- PR #1978: Adding `predict_proba` function to dask RF\n\n## Improvements\n- PR #1644: Add `predict_proba()` for FIL binary classifier\n- PR #1620: Pickling tests now automatically finds all model classes inheriting from cuml.Base\n- PR #1637: Update to newer treelite version with XGBoost 1.0 compatibility\n- PR #1632: Fix MBSGD models inheritance, they now inherits from cuml.Base\n- PR #1628: Remove submodules from cuML\n- PR #1755: Expose the build_treelite function for python\n- PR #1649: Add the fil_sparse_format variable option to RF API\n- PR #1647: storage_type=AUTO uses SPARSE for large models\n- PR #1668: Update the warning statement thrown in RF when the seed is set but n_streams is not 1\n- PR #1662: use of direct cusparse calls for coo2csr, instead of depending on nvgraph\n- PR #1747: C++: dbscan performance improvements and cleanup\n- PR #1697: Making trustworthiness batchable and using proper workspace\n- PR #1721: Improving UMAP pytests\n- PR #1717: Call `rmm_cupy_allocator` for CuPy allocations\n- PR #1718: Import `using_allocator` from `cupy.cuda`\n- PR #1723: Update RF Classifier to throw an exception for multi-class pickling\n- PR #1726: Decorator to allocate CuPy arrays with RMM\n- PR #1719: UMAP random seed reproducibility\n- PR #1748: Test serializing `CumlArray` objects\n- PR #1776: Refactoring pca/tsvd distributed\n- PR #1762: Update CuPy requirement to 7\n- PR #1768: C++: Different input and output types for add and subtract prims\n- PR #1790: Add support for multiple seeding in k-means++\n- PR #1805: Adding new Dask cuda serializers to naive bayes + a trivial perf update\n- PR #1812: C++: bench: UMAP benchmark cases added\n- PR #1795: Add capability to build CumlArray from bytearray/memoryview objects\n- PR #1824: C++: improving the performance of UMAP algo\n- PR #1816: Add ARIMA notebook\n- PR #1856: Update docs for 0.13\n- PR #1827: Add HPO demo Notebook\n- PR #1825: `--nvtx` option in `build.sh`\n- PR #1847: Update XGBoost version for CI\n- PR #1837: Simplify cuML Array construction\n- PR #1848: Rely on subclassing for cuML Array serialization\n- PR #1866: Minimizing client memory pressure on Naive Bayes\n- PR #1788: Removing complexity bottleneck in S-ARIMA\n- PR #1873: Remove usage of nvstring and nvcat from LabelEncoder\n- PR #1891: Additional improvements to naive bayes tree reduction\n\n## Bug Fixes\n- PR #1835 : Fix calling default RF Classification always\n- PT #1904: replace cub sort\n- PR #1833: Fix depth issue in shallow RF regression estimators\n- PR #1770: Warn that KalmanFilter is deprecated\n- PR #1775: Allow CumlArray to work with inputs that have no 'strides' in array interface\n- PR #1594: Train-test split is now reproducible\n- PR #1590: Fix destination directory structure for run-clang-format.py\n- PR #1611: Fixing pickling errors for KNN classifier and regressor\n- PR #1617: Fixing pickling issues for SVC and SVR\n- PR #1634: Fix title in KNN docs\n- PR #1627: Adding a check for multi-class data in RF classification\n- PR #1654: Skip treelite patch if its already been applied\n- PR #1661: Fix nvstring variable name\n- PR #1673: Using struct for caching dlsym state in communicator\n- PR #1659: TSNE - introduce 'convert_dtype' and refactor class attr 'Y' to 'embedding_'\n- PR #1672: Solver 'svd' in Linear and Ridge Regressors when n_cols=1\n- PR #1670: Lasso & ElasticNet - cuml Handle added\n- PR #1671: Update for accessing cuDF Series pointer\n- PR #1652: Support XGBoost 1.0+ models in FIL\n- PR #1702: Fix LightGBM-FIL validation test\n- PR #1701: test_score kmeans test passing with newer cupy version\n- PR #1706: Remove multi-class bug from QuasiNewton\n- PR #1699: Limit CuPy to <7.2 temporarily\n- PR #1708: Correctly deallocate cuML handles in Cython\n- PR #1730: Fixes to KF for test stability (mainly in CUDA 10.2)\n- PR #1729: Fixing naive bayes UCX serialization problem in fit()\n- PR #1749: bug fix rf classifier/regressor on seg fault in bench\n- PR #1751: Updated RF documentation\n- PR #1765: Update the checks for using RF GPU predict\n- PR #1787: C++: unit-tests to check for RF accuracy. As well as a bug fix to improve RF accuracy\n- PR #1793: Updated fil pyx to solve memory leakage issue\n- PR #1810: Quickfix - chunkage in dask make_regression\n- PR #1842: DistributedDataHandler not properly setting 'multiple'\n- PR #1849: Critical fix in ARIMA initial estimate\n- PR #1851: Fix for cuDF behavior change for multidimensional arrays\n- PR #1852: Remove Thrust warnings\n- PR #1868: Turning off IPC caching until it is fixed in UCX-py/UCX\n- PR #1876: UMAP exponential decay parameters fix\n- PR #1887: Fix hasattr for missing attributes on base models\n- PR #1877: Remove resetting index in shuffling in train_test_split\n- PR #1893: Updating UCX in comms to match current UCX-py\n- PR #1888: Small train_test_split test fix\n- PR #1899: Fix dask `extract_partitions()`, remove transformation as instance variable in PCA and TSVD and match sklearn APIs\n- PR #1920: Temporarily raising threshold for UMAP reproducibility tests\n- PR #1918: Create memleak fixture to skip memleak tests in CI for now\n- PR #1926: Update batch matrix test margins\n- PR #1925: Fix failing dask tests\n- PR #1936: Update DaskRF regression test to xfail\n- PR #1932: Isolating cause of make_blobs failure\n- PR #1951: Dask Random forest regression CPU predict bug fix\n- PR #1948: Adjust BatchedMargin margin and disable tests temporarily\n- PR #1950: Fix UMAP test failure\n\n\n# cuML 0.12.0 (04 Feb 2020)\n\n## New Features\n- PR #1483: prims: Fused L2 distance and nearest-neighbor prim\n- PR #1494: bench: ml-prims benchmark\n- PR #1514: bench: Fused L2 NN prim benchmark\n- PR #1411: Cython side of MNMG OLS\n- PR #1520: Cython side of MNMG Ridge Regression\n- PR #1516: Suppor Vector Regression (epsilon-SVR)\n\n## Improvements\n- PR #1638: Update cuml/docs/README.md\n- PR #1468: C++: updates to clang format flow to make it more usable among devs\n- PR #1473: C++: lazy initialization of \"costly\" resources inside cumlHandle\n- PR #1443: Added a new overloaded GEMM primitive\n- PR #1489: Enabling deep trees using Gather tree builder\n- PR #1463: Update FAISS submodule to 1.6.1\n- PR #1488: Add codeowners\n- PR #1432: Row-major (C-style) GPU arrays for benchmarks\n- PR #1490: Use dask master instead of conda package for testing\n- PR #1375: Naive Bayes & Distributed Naive Bayes\n- PR #1377: Add GPU array support for FIL benchmarking\n- PR #1493: kmeans: add tiling support for 1-NN computation and use fusedL2-1NN prim for L2 distance metric\n- PR #1532: Update CuPy to >= 6.6 and allow 7.0\n- PR #1528: Re-enabling KNN using dynamic library loading for UCX in communicator\n- PR #1545: Add conda environment version updates to ci script\n- PR #1541: Updates for libcudf++ Python refactor\n- PR #1555: FIL-SKL, an SKLearn-based benchmark for FIL\n- PR #1537: Improve pickling and scoring suppport for many models to support hyperopt\n- PR #1551: Change custom kernel to cupy for col/row order transform\n- PR #1533: C++: interface header file separation for SVM\n- PR #1560: Helper function to allocate all new CuPy arrays with RMM memory management\n- PR #1570: Relax nccl in conda recipes to >=2.4 (matching CI)\n- PR #1578: Add missing function information to the cuML documenataion\n- PR #1584: Add has_scipy utility function for runtime check\n- PR #1583: API docs updates for 0.12\n- PR #1591: Updated FIL documentation\n\n## Bug Fixes\n- PR #1470: Documentation: add make_regression, fix ARIMA section\n- PR #1482: Updated the code to remove sklearn from the mbsgd stress test\n- PR #1491: Update dev environments for 0.12\n- PR #1512: Updating setup_cpu() in SpeedupComparisonRunner\n- PR #1498: Add build.sh to code owners\n- PR #1505: cmake: added correct dependencies for prims-bench build\n- PR #1534: Removed TODO comment in create_ucp_listeners()\n- PR #1548: Fixing umap extra unary op in knn graph\n- PR #1547: Fixing MNMG kmeans score. Fixing UMAP pickling before fit(). Fixing UMAP test failures.\n- PR #1557: Increasing threshold for kmeans score\n- PR #1562: Increasing threshold even higher\n- PR #1564: Fixed a typo in function cumlMPICommunicator_impl::syncStream\n- PR #1569: Remove Scikit-learn exception and depedenncy in SVM\n- PR #1575: Add missing dtype parameter in call to strides to order for CuPy 6.6 code path\n- PR #1574: Updated the init file to include SVM\n- PR #1589: Fixing the default value for RF and updating mnmg predict to accept cudf\n- PR #1601: Fixed wrong datatype used in knn voting kernel\n\n# cuML 0.11.0 (11 Dec 2019)\n\n## New Features\n\n- PR #1295: Cython side of MNMG PCA\n- PR #1218: prims: histogram prim\n- PR #1129: C++: Separate include folder for C++ API distribution\n- PR #1282: OPG KNN MNMG Code (disabled for 0.11)\n- PR #1242: Initial implementation of FIL sparse forests\n- PR #1194: Initial ARIMA time-series modeling support.\n- PR #1286: Importing treelite models as FIL sparse forests\n- PR #1285: Fea minimum impurity decrease RF param\n- PR #1301: Add make_regression to generate regression datasets\n- PR #1322: RF pickling using treelite, protobuf and FIL\n- PR #1332: Add option to cuml.dask make_blobs to produce dask array\n- PR #1307: Add RF regression benchmark\n- PR #1327: Update the code to build treelite with protobuf\n- PR #1289: Add Python benchmarking support for FIL\n- PR #1371: Cython side of MNMG tSVD\n- PR #1386: Expose SVC decision function value\n\n## Improvements\n- PR #1170: Use git to clone subprojects instead of git submodules\n- PR #1239: Updated the treelite version\n- PR #1225: setup.py clone dependencies like cmake and correct include paths\n- PR #1224: Refactored FIL to prepare for sparse trees\n- PR #1249: Include libcuml.so C API in installed targets\n- PR #1259: Conda dev environment updates and use libcumlprims current version in CI\n- PR #1277: Change dependency order in cmake for better printing at compile time\n- PR #1264: Add -s flag to GPU CI pytest for better error printing\n- PR #1271: Updated the Ridge regression documentation\n- PR #1283: Updated the cuMl docs to include MBSGD and adjusted_rand_score\n- PR #1300: Lowercase parameter versions for FIL algorithms\n- PR #1312: Update CuPy to version 6.5 and use conda-forge channel\n- PR #1336: Import SciKit-Learn models into FIL\n- PR #1314: Added options needed for ASVDb output (CUDA ver, etc.), added option\n  to select algos\n- PR #1335: Options to print available algorithms and datasets\n  in the Python benchmark\n- PR #1338: Remove BUILD_ABI references in CI scripts\n- PR #1340: Updated unit tests to uses larger dataset\n- PR #1351: Build treelite temporarily for GPU CI testing of FIL Scikit-learn\n  model importing\n- PR #1367: --test-split benchmark parameter for train-test split\n- PR #1360: Improved tests for importing SciKit-Learn models into FIL\n- PR #1368: Add --num-rows benchmark command line argument\n- PR #1351: Build treelite temporarily for GPU CI testing of FIL Scikit-learn model importing\n- PR #1366: Modify train_test_split to use CuPy and accept device arrays\n- PR #1258: Documenting new MPI communicator for multi-node multi-GPU testing\n- PR #1345: Removing deprecated should_downcast argument\n- PR #1362: device_buffer in UMAP + Sparse prims\n- PR #1376: AUTO value for FIL algorithm\n- PR #1408: Updated pickle tests to delete the pre-pickled model to prevent pointer leakage\n- PR #1357: Run benchmarks multiple times for CI\n- PR #1382: ARIMA optimization: move functions to C++ side\n- PR #1392: Updated RF code to reduce duplication of the code\n- PR #1444: UCX listener running in its own isolated thread\n- PR #1445: Improved performance of FIL sparse trees\n- PR #1431: Updated API docs\n- PR #1441: Remove unused CUDA conda labels\n- PR #1439: Match sklearn 0.22 default n_estimators for RF and fix test errors\n- PR #1461: Add kneighbors to API docs\n\n## Bug Fixes\n- PR #1281: Making rng.h threadsafe\n- PR #1212: Fix cmake git cloning always running configure in subprojects\n- PR #1261: Fix comms build errors due to cuml++ include folder changes\n- PR #1267: Update build.sh for recent change of building comms in main CMakeLists\n- PR #1278: Removed incorrect overloaded instance of eigJacobi\n- PR #1302: Updates for numba 0.46\n- PR #1313: Updated the RF tests to set the seed and n_streams\n- PR #1319: Using machineName arg passed in instead of default for ASV reporting\n- PR #1326: Fix illegal memory access in make_regression (bounds issue)\n- PR #1330: Fix C++ unit test utils for better handling of differences near zero\n- PR #1342: Fix to prevent memory leakage in Lasso and ElasticNet\n- PR #1337: Fix k-means init from preset cluster centers\n- PR #1354: Fix SVM gamma=scale implementation\n- PR #1344: Change other solver based methods to create solver object in init\n- PR #1373: Fixing a few small bugs in make_blobs and adding asserts to pytests\n- PR #1361: Improve SMO error handling\n- PR #1384: Lower expectations on batched matrix tests to prevent CI failures\n- PR #1380: Fix memory leaks in ARIMA\n- PR #1391: Lower expectations on batched matrix tests even more\n- PR #1394: Warning added in svd for cuda version 10.1\n- PR #1407: Resolved RF predict issues and updated RF docstring\n- PR #1401: Patch for lbfgs solver for logistic regression with no l1 penalty\n- PR #1416: train_test_split numba and rmm device_array output bugfix\n- PR #1419: UMAP pickle tests are using wrong n_neighbors value for trustworthiness\n- PR #1438: KNN Classifier to properly return Dataframe with Dataframe input\n- PR #1425: Deprecate seed and use random_state similar to Scikit-learn in train_test_split\n- PR #1458: Add joblib as an explicit requirement\n- PR #1474: Defer knn mnmg to 0.12 nightly builds and disable ucx-py dependency\n\n# cuML 0.10.0 (16 Oct 2019)\n\n## New Features\n- PR #1148: C++ benchmark tool for c++/CUDA code inside cuML\n- PR #1071: Selective eigen solver of cuSolver\n- PR #1073: Updating RF wrappers to use FIL for GPU accelerated prediction\n- PR #1104: CUDA 10.1 support\n- PR #1113: prims: new batched make-symmetric-matrix primitive\n- PR #1112: prims: new batched-gemv primitive\n- PR #855: Added benchmark tools\n- PR #1149 Add YYMMDD to version tag for nightly conda packages\n- PR #892: General Gram matrices prim\n- PR #912: Support Vector Machine\n- PR #1274: Updated the RF score function to use GPU predict\n\n## Improvements\n- PR #961: High Peformance RF; HIST algo\n- PR #1028: Dockerfile updates after dir restructure. Conda env yaml to add statsmodels as a dependency\n- PR #1047: Consistent OPG interface for kmeans, based on internal libcumlprims update\n- PR #763: Add examples to train_test_split documentation\n- PR #1093: Unified inference kernels for different FIL algorithms\n- PR #1076: Paying off some UMAP / Spectral tech debt.\n- PR #1086: Ensure RegressorMixin scorer uses device arrays\n- PR #1110: Adding tests to use default values of parameters of the models\n- PR #1108: input_to_host_array function in input_utils for input processing to host arrays\n- PR #1114: K-means: Exposing useful params, removing unused params, proxying params in Dask\n- PR #1138: Implementing ANY_RANK semantics on irecv\n- PR #1142: prims: expose separate InType and OutType for unaryOp and binaryOp\n- PR #1115: Moving dask_make_blobs to cuml.dask.datasets. Adding conversion to dask.DataFrame\n- PR #1136: CUDA 10.1 CI updates\n- PR #1135: K-means: add boundary cases for kmeans||, support finer control with convergence\n- PR #1163: Some more correctness improvements. Better verbose printing\n- PR #1165: Adding except + in all remaining cython\n- PR #1186: Using LocalCUDACluster Pytest fixture\n- PR #1173: Docs: Barnes Hut TSNE documentation\n- PR #1176: Use new RMM API based on Cython\n- PR #1219: Adding custom bench_func and verbose logging to cuml.benchmark\n- PR #1247: Improved MNMG RF error checking\n\n## Bug Fixes\n\n- PR #1231: RF respect number of cuda streams from cuml handle\n- PR #1230: Rf bugfix memleak in regression\n- PR #1208: compile dbscan bug\n- PR #1016: Use correct libcumlprims version in GPU CI\n- PR #1040: Update version of numba in development conda yaml files\n- PR #1043: Updates to accommodate cuDF python code reorganization\n- PR #1044: Remove nvidia driver installation from ci/cpu/build.sh\n- PR #991: Barnes Hut TSNE Memory Issue Fixes\n- PR #1075: Pinning Dask version for consistent CI results\n- PR #990: Barnes Hut TSNE Memory Issue Fixes\n- PR #1066: Using proper set of workers to destroy nccl comms\n- PR #1072: Remove pip requirements and setup\n- PR #1074: Fix flake8 CI style check\n- PR #1087: Accuracy improvement for sqrt/log in RF max_feature\n- PR #1088: Change straggling numba python allocations to use RMM\n- PR #1106: Pinning Distributed version to match Dask for consistent CI results\n- PR #1116: TSNE CUDA 10.1 Bug Fixes\n- PR #1132: DBSCAN Batching Bug Fix\n- PR #1162: DASK RF random seed bug fix\n- PR #1164: Fix check_dtype arg handling for input_to_dev_array\n- PR #1171: SVM prediction bug fix\n- PR #1177: Update dask and distributed to 2.5\n- PR #1204: Fix SVM crash on Turing\n- PR #1199: Replaced sprintf() with snprintf() in THROW()\n- PR #1205: Update dask-cuda in yml envs\n- PR #1211: Fixing Dask k-means transform bug and adding test\n- PR #1236: Improve fix for SMO solvers potential crash on Turing\n- PR #1251: Disable compiler optimization for CUDA 10.1 for distance prims\n- PR #1260: Small bugfix for major conversion in input_utils\n- PR #1276: Fix float64 prediction crash in test_random_forest\n\n# cuML 0.9.0 (21 Aug 2019)\n\n## New Features\n\n- PR #894: Convert RF to treelite format\n- PR #826: Jones transformation of params for ARIMA models timeSeries ml-prim\n- PR #697: Silhouette Score metric ml-prim\n- PR #674: KL Divergence metric ml-prim\n- PR #787: homogeneity, completeness and v-measure metrics ml-prim\n- PR #711: Mutual Information metric ml-prim\n- PR #724: Entropy metric ml-prim\n- PR #766: Expose score method based on inertia for KMeans\n- PR #823: prims: cluster dispersion metric\n- PR #816: Added inverse_transform() for LabelEncoder\n- PR #789: prims: sampling without replacement\n- PR #813: prims: Col major istance prim\n- PR #635: Random Forest & Decision Tree Regression (Single-GPU)\n- PR #819: Forest Inferencing Library (FIL)\n- PR #829: C++: enable nvtx ranges\n- PR #835: Holt-Winters algorithm\n- PR #837: treelite for decision forest exchange format\n- PR #871: Wrapper for FIL\n- PR #870: make_blobs python function\n- PR #881: wrappers for accuracy_score and adjusted_rand_score functions\n- PR #840: Dask RF classification and regression\n- PR #870: make_blobs python function\n- PR #879: import of treelite models to FIL\n- PR #892: General Gram matrices prim\n- PR #883: Adding MNMG Kmeans\n- PR #930: Dask RF\n- PR #882: TSNE - T-Distributed Stochastic Neighbourhood Embedding\n- PR #624: Internals API & Graph Based Dimensionality Reductions Callback\n- PR #926: Wrapper for FIL\n- PR #994: Adding MPI comm impl for testing / benchmarking MNMG CUDA\n- PR #960: Enable using libcumlprims for MG algorithms/prims\n\n## Improvements\n- PR #822: build: build.sh update to club all make targets together\n- PR #807: Added development conda yml files\n- PR #840: Require cmake >= 3.14\n- PR #832: Stateless Decision Tree and Random Forest API\n- PR #857: Small modifications to comms for utilizing IB w/ Dask\n- PR #851: Random forest Stateless API wrappers\n- PR #865: High Performance RF\n- PR #895: Pretty prints arguments!\n- PR #920: Add an empty marker kernel for tracing purposes\n- PR #915: syncStream added to cumlCommunicator\n- PR #922: Random Forest support in FIL\n- PR #911: Update headers to credit CannyLabs BH TSNE implementation\n- PR #918: Streamline CUDA_REL environment variable\n- PR #924: kmeans: updated APIs to be stateless, refactored code for mnmg support\n- PR #950: global_bias support in FIL\n- PR #773: Significant improvements to input checking of all classes and common input API for Python\n- PR #957: Adding docs to RF & KMeans MNMG. Small fixes for release\n- PR #965: Making dask-ml a hard dependency\n- PR #976: Update api.rst for new 0.9 classes\n- PR #973: Use cudaDeviceGetAttribute instead of relying on cudaDeviceProp object being passed\n- PR #978: Update README for 0.9\n- PR #1009: Fix references to notebooks-contrib\n- PR #1015: Ability to control the number of internal streams in cumlHandle_impl via cumlHandle\n- PR #1175: Add more modules to docs ToC\n\n## Bug Fixes\n\n- PR #923: Fix misshapen level/trend/season HoltWinters output\n- PR #831: Update conda package dependencies to cudf 0.9\n- PR #772: Add missing cython headers to SGD and CD\n- PR #849: PCA no attribute trans_input_ transform bug fix\n- PR #869: Removing incorrect information from KNN Docs\n- PR #885: libclang installation fix for GPUCI\n- PR #896: Fix typo in comms build instructions\n- PR #921: Fix build scripts using incorrect cudf version\n- PR #928: TSNE Stability Adjustments\n- PR #934: Cache cudaDeviceProp in cumlHandle for perf reasons\n- PR #932: Change default param value for RF classifier\n- PR #949: Fix dtype conversion tests for unsupported cudf dtypes\n- PR #908: Fix local build generated file ownerships\n- PR #983: Change RF max_depth default to 16\n- PR #987: Change default values for knn\n- PR #988: Switch to exact tsne\n- PR #991: Cleanup python code in cuml.dask.cluster\n- PR #996: ucx_initialized being properly set in CommsContext\n- PR #1007: Throws a well defined error when mutigpu is not enabled\n- PR #1018: Hint location of nccl in build.sh for CI\n- PR #1022: Using random_state to make K-Means MNMG tests deterministic\n- PR #1034: Fix typos and formatting issues in RF docs\n- PR #1052: Fix the rows_sample dtype to float\n\n# cuML 0.8.0 (27 June 2019)\n\n## New Features\n\n- PR #652: Adjusted Rand Index metric ml-prim\n- PR #679: Class label manipulation ml-prim\n- PR #636: Rand Index metric ml-prim\n- PR #515: Added Random Projection feature\n- PR #504: Contingency matrix ml-prim\n- PR #644: Add train_test_split utility for cuDF dataframes\n- PR #612: Allow Cuda Array Interface, Numba inputs and input code refactor\n- PR #641: C: Separate C-wrapper library build to generate libcuml.so\n- PR #631: Add nvcategory based ordinal label encoder\n- PR #681: Add MBSGDClassifier and MBSGDRegressor classes around SGD\n- PR #705: Quasi Newton solver and LogisticRegression Python classes\n- PR #670: Add test skipping functionality to build.sh\n- PR #678: Random Forest Python class\n- PR #684: prims: make_blobs primitive\n- PR #673: prims: reduce cols by key primitive\n- PR #812: Add cuML Communications API & consolidate Dask cuML\n\n## Improvements\n\n- PR #597: C++ cuML and ml-prims folder refactor\n- PR #590: QN Recover from numeric errors\n- PR #482: Introduce cumlHandle for pca and tsvd\n- PR #573: Remove use of unnecessary cuDF column and series copies\n- PR #601: Cython PEP8 cleanup and CI integration\n- PR #596: Introduce cumlHandle for ols and ridge\n- PR #579: Introduce cumlHandle for cd and sgd, and propagate C++ errors in cython level for cd and sgd\n- PR #604: Adding cumlHandle to kNN, spectral methods, and UMAP\n- PR #616: Enable clang-format for enforcing coding style\n- PR #618: CI: Enable copyright header checks\n- PR #622: Updated to use 0.8 dependencies\n- PR #626: Added build.sh script, updated CI scripts and documentation\n- PR #633: build: Auto-detection of GPU_ARCHS during cmake\n- PR #650: Moving brute force kNN to prims. Creating stateless kNN API.\n- PR #662: C++: Bulk clang-format updates\n- PR #671: Added pickle pytests and correct pickling of Base class\n- PR #675: atomicMin/Max(float, double) with integer atomics and bit flipping\n- PR #677: build: 'deep-clean' to build.sh to clean faiss build as well\n- PR #683: Use stateless c++ API in KNN so that it can be pickled properly\n- PR #686: Use stateless c++ API in UMAP so that it can be pickled properly\n- PR #695: prims: Refactor pairwise distance\n- PR #707: Added stress test and updated documentation for RF\n- PR #701: Added emacs temporary file patterns to .gitignore\n- PR #606: C++: Added tests for host_buffer and improved device_buffer and host_buffer implementation\n- PR #726: Updated RF docs and stress test\n- PR #730: Update README and RF docs for 0.8\n- PR #744: Random projections generating binomial on device. Fixing tests.\n- PR #741: Update API docs for 0.8\n- PR #754: Pickling of UMAP/KNN\n- PR #753: Made PCA and TSVD picklable\n- PR #746: LogisticRegression and QN API docstrings\n- PR #820: Updating DEVELOPER GUIDE threading guidelines\n\n## Bug Fixes\n- PR #584: Added missing virtual destructor to deviceAllocator and hostAllocator\n- PR #620: C++: Removed old unit-test files in ml-prims\n- PR #627: C++: Fixed dbscan crash issue filed in 613\n- PR #640: Remove setuptools from conda run dependency\n- PR #646: Update link in contributing.md\n- PR #649: Bug fix to LinAlg::reduce_rows_by_key prim filed in issue #648\n- PR #666: fixes to gitutils.py to resolve both string decode and handling of uncommitted files\n- PR #676: Fix template parameters in `bernoulli()` implementation.\n- PR #685: Make CuPy optional to avoid nccl conda package conflicts\n- PR #687: prims: updated tolerance for reduce_cols_by_key unit-tests\n- PR #689: Removing extra prints from NearestNeighbors cython\n- PR #718: Bug fix for DBSCAN and increasing batch size of sgd\n- PR #719: Adding additional checks for dtype of the data\n- PR #736: Bug fix for RF wrapper and .cu print function\n- PR #547: Fixed issue if C++ compiler is specified via CXX during configure.\n- PR #759: Configure Sphinx to render params correctly\n- PR #762: Apply threshold to remove flakiness of UMAP tests.\n- PR #768: Fixing memory bug from stateless refactor\n- PR #782: Nearest neighbors checking properly whether memory should be freed\n- PR #783: UMAP was using wrong size for knn computation\n- PR #776: Hotfix for self.variables in RF\n- PR #777: Fix numpy input bug\n- PR #784: Fix jit of shuffle_idx python function\n- PR #790: Fix rows_sample input type for RF\n- PR #793: Fix for dtype conversion utility for numba arrays without cupy installed\n- PR #806: Add a seed for sklearn model in RF test file\n- PR #843: Rf quantile fix\n\n# cuML 0.7.0 (10 May 2019)\n\n## New Features\n\n- PR #405: Quasi-Newton GLM Solvers\n- PR #277: Add row- and column-wise weighted mean primitive\n- PR #424: Add a grid-sync struct for inter-block synchronization\n- PR #430: Add R-Squared Score to ml primitives\n- PR #463: Add matrix gather to ml primitives\n- PR #435: Expose cumlhandle in cython + developer guide\n- PR #455: Remove default-stream argument across ml-prims and cuML\n- PR #375: cuml cpp shared library renamed to libcuml++.so\n- PR #460: Random Forest & Decision Trees (Single-GPU, Classification)\n- PR #491: Add doxygen build target for ml-prims\n- PR #505: Add R-Squared Score to python interface\n- PR #507: Add coordinate descent for lasso and elastic-net\n- PR #511: Add a minmax ml-prim\n- PR #516: Added Trustworthiness score feature\n- PR #520: Add local build script to mimic gpuCI\n- PR #503: Add column-wise matrix sort primitive\n- PR #525: Add docs build script to cuML\n- PR #528: Remove current KMeans and replace it with a new single GPU implementation built using ML primitives\n\n## Improvements\n\n- PR #481: Refactoring Quasi-Newton to use cumlHandle\n- PR #467: Added validity check on cumlHandle_t\n- PR #461: Rewrote permute and added column major version\n- PR #440: README updates\n- PR #295: Improve build-time and the interface e.g., enable bool-OutType, for distance()\n- PR #390: Update docs version\n- PR #272: Add stream parameters to cublas and cusolver wrapper functions\n- PR #447: Added building and running mlprims tests to CI\n- PR #445: Lower dbscan memory usage by computing adjacency matrix directly\n- PR #431: Add support for fancy iterator input types to LinAlg::reduce_rows_by_key\n- PR #394: Introducing cumlHandle API to dbscan and add example\n- PR #500: Added CI check for black listed CUDA Runtime API calls\n- PR #475: exposing cumlHandle for dbscan from python-side\n- PR #395: Edited the CONTRIBUTING.md file\n- PR #407: Test files to run stress, correctness and unit tests for cuml algos\n- PR #512: generic copy method for copying buffers between device/host\n- PR #533: Add cudatoolkit conda dependency\n- PR #524: Use cmake find blas and find lapack to pass configure options to faiss\n- PR #527: Added notes on UMAP differences from reference implementation\n- PR #540: Use latest release version in update-version CI script\n- PR #552: Re-enable assert in kmeans tests with xfail as needed\n- PR #581: Add shared memory fast col major to row major function back with bound checks\n- PR #592: More efficient matrix copy/reverse methods\n- PR #721: Added pickle tests for DBSCAN and Random Projections\n\n## Bug Fixes\n\n- PR #334: Fixed segfault in `ML::cumlHandle_impl::destroyResources`\n- PR #349: Developer guide clarifications for cumlHandle and cumlHandle_impl\n- PR #398: Fix CI scripts to allow nightlies to be uploaded\n- PR #399: Skip PCA tests to allow CI to run with driver 418\n- PR #422: Issue in the PCA tests was solved and CI can run with driver 418\n- PR #409: Add entry to gitmodules to ignore build artifacts\n- PR #412: Fix for svdQR function in ml-prims\n- PR #438: Code that depended on FAISS was building everytime.\n- PR #358: Fixed an issue when switching streams on MLCommon::device_buffer and MLCommon::host_buffer\n- PR #434: Fixing bug in CSR tests\n- PR #443: Remove defaults channel from ci scripts\n- PR #384: 64b index arithmetic updates to the kernels inside ml-prims\n- PR #459: Fix for runtime library path of pip package\n- PR #464: Fix for C++11 destructor warning in qn\n- PR #466: Add support for column-major in LinAlg::*Norm methods\n- PR #465: Fixing deadlock issue in GridSync due to consecutive sync calls\n- PR #468: Fix dbscan example build failure\n- PR #470: Fix resource leakage in Kalman filter python wrapper\n- PR #473: Fix gather ml-prim test for change in rng uniform API\n- PR #477: Fixes default stream initialization in cumlHandle\n- PR #480: Replaced qn_fit() declaration with #include of file containing definition to fix linker error\n- PR #495: Update cuDF and RMM versions in GPU ci test scripts\n- PR #499: DEVELOPER_GUIDE.md: fixed links and clarified ML::detail::streamSyncer example\n- PR #506: Re enable ml-prim tests in CI\n- PR #508: Fix for an error with default argument in LinAlg::meanSquaredError\n- PR #519: README.md Updates and adding BUILD.md back\n- PR #526: Fix the issue of wrong results when fit and transform of PCA are called separately\n- PR #531: Fixing missing arguments in updateDevice() for RF\n- PR #543: Exposing dbscan batch size through cython API and fixing broken batching\n- PR #551: Made use of ZLIB_LIBRARIES consistent between ml_test and ml_mg_test\n- PR #557: Modified CI script to run cuML tests before building mlprims and removed lapack flag\n- PR #578: Updated Readme.md to add lasso and elastic-net\n- PR #580: Fixing cython garbage collection bug in KNN\n- PR #577: Use find libz in prims cmake\n- PR #594: fixed cuda-memcheck mean_center test failures\n\n\n# cuML 0.6.1 (09 Apr 2019)\n\n## Bug Fixes\n\n- PR #462 Runtime library path fix for cuML pip package\n\n\n# cuML 0.6.0 (22 Mar 2019)\n\n## New Features\n\n- PR #249: Single GPU Stochastic Gradient Descent for linear regression, logistic regression, and linear svm with L1, L2, and elastic-net penalties.\n- PR #247: Added \"proper\" CUDA API to cuML\n- PR #235: NearestNeighbors MG Support\n- PR #261: UMAP Algorithm\n- PR #290: NearestNeighbors numpy MG Support\n- PR #303: Reusable spectral embedding / clustering\n- PR #325: Initial support for single process multi-GPU OLS and tSVD\n- PR #271: Initial support for hyperparameter optimization with dask for many models\n\n## Improvements\n\n- PR #144: Dockerfile update and docs for LinearRegression and Kalman Filter.\n- PR #168: Add /ci/gpu/build.sh file to cuML\n- PR #167: Integrating full-n-final ml-prims repo inside cuml\n- PR #198: (ml-prims) Removal of *MG calls + fixed a bug in permute method\n- PR #194: Added new ml-prims for supporting LASSO regression.\n- PR #114: Building faiss C++ api into libcuml\n- PR #64: Using FAISS C++ API in cuML and exposing bindings through cython\n- PR #208: Issue ml-common-3: Math.h: swap thrust::for_each with binaryOp,unaryOp\n- PR #224: Improve doc strings for readable rendering with readthedocs\n- PR #209: Simplify README.md, move build instructions to BUILD.md\n- PR #218: Fix RNG to use given seed and adjust RNG test tolerances.\n- PR #225: Support for generating random integers\n- PR #215: Refactored LinAlg::norm to Stats::rowNorm and added Stats::colNorm\n- PR #234: Support for custom output type and passing index value to main_op in *Reduction kernels\n- PR #230: Refactored the cuda_utils header\n- PR #236: Refactored cuml python package structure to be more sklearn like\n- PR #232: Added reduce_rows_by_key\n- PR #246: Support for 2 vectors in the matrix vector operator\n- PR #244: Fix for single GPU OLS and Ridge to support one column training data\n- PR #271: Added get_params and set_params functions for linear and ridge regression\n- PR #253: Fix for issue #250-reduce_rows_by_key failed memcheck for small nkeys\n- PR #269: LinearRegression, Ridge Python docs update and cleaning\n- PR #322: set_params updated\n- PR #237: Update build instructions\n- PR #275: Kmeans use of faster gpu_matrix\n- PR #288: Add n_neighbors to NearestNeighbors constructor\n- PR #302: Added FutureWarning for deprecation of current kmeans algorithm\n- PR #312: Last minute cleanup before release\n- PR #315: Documentation updating and enhancements\n- PR #330: Added ignored argument to pca.fit_transform to map to sklearn's implemenation\n- PR #342: Change default ABI to ON\n- PR #572: Pulling DBSCAN components into reusable primitives\n\n\n## Bug Fixes\n\n- PR #193: Fix AttributeError in PCA and TSVD\n- PR #211: Fixing inconsistent use of proper batch size calculation in DBSCAN\n- PR #202: Adding back ability for users to define their own BLAS\n- PR #201: Pass CMAKE CUDA path to faiss/configure script\n- PR #200 Avoid using numpy via cimport in KNN\n- PR #228: Bug fix: LinAlg::unaryOp with 0-length input\n- PR #279: Removing faiss-gpu references in README\n- PR #321: Fix release script typo\n- PR #327: Update conda requirements for version 0.6 requirements\n- PR #352: Correctly calculating numpy chunk sizing for kNN\n- PR #345: Run python import as part of package build to trigger compilation\n- PR #347: Lowering memory usage of kNN.\n- PR #355: Fixing issues with very large numpy inputs to SPMG OLS and tSVD.\n- PR #357: Removing FAISS requirement from README\n- PR #362: Fix for matVecOp crashing on large input sizes\n- PR #366: Index arithmetic issue fix with TxN_t class\n- PR #376: Disabled kmeans tests since they are currently too sensitive (see #71)\n- PR #380: Allow arbitrary data size on ingress for numba_utils.row_matrix\n- PR #385: Fix for long import cuml time in containers and fix for setup_pip\n- PR #630: Fixing a missing kneighbors in nearest neighbors python proxy\n\n# cuML 0.5.1 (05 Feb 2019)\n\n## Bug Fixes\n\n- PR #189 Avoid using numpy via cimport to prevent ABI issues in Cython compilation\n\n\n# cuML 0.5.0 (28 Jan 2019)\n\n## New Features\n\n- PR #66: OLS Linear Regression\n- PR #44: Distance calculation ML primitives\n- PR #69: Ridge (L2 Regularized) Linear Regression\n- PR #103: Linear Kalman Filter\n- PR #117: Pip install support\n- PR #64: Device to device support from cuML device pointers into FAISS\n\n## Improvements\n\n- PR #56: Make OpenMP optional for building\n- PR #67: Github issue templates\n- PR #44: Refactored DBSCAN to use ML primitives\n- PR #91: Pytest cleanup and sklearn toyset datasets based pytests for kmeans and dbscan\n- PR #75: C++ example to use kmeans\n- PR #117: Use cmake extension to find any zlib installed in system\n- PR #94: Add cmake flag to set ABI compatibility\n- PR #139: Move thirdparty submodules to root and add symlinks to new locations\n- PR #151: Replace TravisCI testing and conda pkg builds with gpuCI\n- PR #164: Add numba kernel for faster column to row major transform\n- PR #114: Adding FAISS to cuml build\n\n## Bug Fixes\n\n- PR #48: CUDA 10 compilation warnings fix\n- PR #51: Fixes to Dockerfile and docs for new build system\n- PR #72: Fixes for GCC 7\n- PR #96: Fix for kmeans stack overflow with high number of clusters\n- PR #105: Fix for AttributeError in kmeans fit method\n- PR #113: Removed old  glm python/cython files\n- PR #118: Fix for AttributeError in kmeans predict method\n- PR #125: Remove randomized solver option from PCA python bindings\n\n\n# cuML 0.4.0 (05 Dec 2018)\n\n## New Features\n\n## Improvements\n\n- PR #42: New build system: separation of libcuml.so and cuml python package\n- PR #43: Added changelog.md\n\n## Bug Fixes\n\n\n# cuML 0.3.0 (30 Nov 2018)\n\n## New Features\n\n- PR #33: Added ability to call cuML algorithms using numpy arrays\n\n## Improvements\n\n- PR #24: Fix references of python package from cuML to cuml and start using versioneer for better versioning\n- PR #40: Added support for refactored cuDF 0.3.0, updated Conda files\n- PR #33: Major python test cleaning, all tests pass with cuDF 0.2.0 and 0.3.0. Preparation for new build system\n- PR #34: Updated batch count calculation logic in DBSCAN\n- PR #35: Beginning of DBSCAN refactor to use cuML mlprims and general improvements\n\n## Bug Fixes\n\n- PR #30: Fixed batch size bug in DBSCAN that caused crash. Also fixed various locations for potential integer overflows\n- PR #28: Fix readthedocs build documentation\n- PR #29: Fix pytests for cuml name change from cuML\n- PR #33: Fixed memory bug that would cause segmentation faults due to numba releasing memory before it was used. Also fixed row major/column major bugs for different algorithms\n- PR #36: Fix kmeans gtest to use device data\n- PR #38: cuda\\_free bug removed that caused google tests to sometimes pass and sometimes fail randomly\n- PR #39: Updated cmake to correctly link with CUDA libraries, add CUDA runtime linking and include source files in compile target\n\n# cuML 0.2.0 (02 Nov 2018)\n\n## New Features\n\n- PR #11: Kmeans algorithm added\n- PR #7: FAISS KNN wrapper added\n- PR #21: Added Conda install support\n\n## Improvements\n\n- PR #15: Added compatibility with cuDF (from prior pyGDF)\n- PR #13: Added FAISS to Dockerfile\n- PR #21: Added TravisCI build system for CI and Conda builds\n\n## Bug Fixes\n\n- PR #4: Fixed explained variance bug in TSVD\n- PR #5: Notebook bug fixes and updated results\n\n\n# cuML 0.1.0\n\nInitial release including PCA, TSVD, DBSCAN, ml-prims and cython wrappers\n"
        },
        {
          "name": "CONTRIBUTING.md",
          "type": "blob",
          "size": 10.416015625,
          "content": "# Contributing to cuML\n\nIf you are interested in contributing to cuML, your contributions will fall\ninto three categories:\n1. You want to report a bug, feature request, or documentation issue\n    - File an [issue](https://github.com/rapidsai/cuml/issues/new/choose)\n    describing what you encountered or what you want to see changed.\n    - Please run and paste the output of the `cuml/print_env.sh` script while\n    reporting a bug to gather and report relevant environment details.\n    - The RAPIDS team will evaluate the issues and triage them, scheduling\n    them for a release. If you believe the issue needs priority attention\n    comment on the issue to notify the team.\n2. You want to propose a new Feature and implement it\n    - Post about your intended feature, and we shall discuss the design and\n    implementation.\n    - Once we agree that the plan looks good, go ahead and implement it, using\n    the [code contributions](#code-contributions) guide below.\n3. You want to implement a feature or bug-fix for an outstanding issue\n    - Follow the [code contributions](#code-contributions) guide below.\n    - If you need more context on a particular issue, please ask and we shall\n    provide.\n\n## Code contributions\n\n### Your first issue\n\n1. Read the project's [README.md](https://github.com/rapidsai/cuml/blob/main/README.md)\n    to learn how to setup the development environment.\n2. Find an issue to work on. The best way is to look for the [good first issue](https://github.com/rapidsai/cuml/issues?q=is%3Aissue+is%3Aopen+label%3A%22good+first+issue%22)\n    or [help wanted](https://github.com/rapidsai/cuml/issues?q=is%3Aissue+is%3Aopen+label%3A%22help+wanted%22) labels\n3. Comment on the issue saying you are going to work on it.\n4. Get familiar with the developer guide relevant for you:\n    * For C++ developers it is available here [DEVELOPER_GUIDE.md](wiki/cpp/DEVELOPER_GUIDE.md)\n    * For Python developers, a [Python DEVELOPER_GUIDE.md](wiki/python/DEVELOPER_GUIDE.md) is available as well.\n5. Code! Make sure to update unit tests!\n6. When done, [create your pull request](https://github.com/rapidsai/cuml/compare).\n7. Verify that CI passes all [status checks](https://help.github.com/articles/about-status-checks/), or fix if needed.\n8. Wait for other developers to review your code and update code as needed.\n9. Once reviewed and approved, a RAPIDS developer will merge your pull request.\n\nRemember, if you are unsure about anything, don't hesitate to comment on issues and ask for clarifications!\n\n\n## Code Formatting\n\nConsistent code formatting is important in the cuML project to ensure\nreadability, maintainability, and thus simplifies collaboration.\n\n### Using pre-commit hooks\n\ncuML uses [pre-commit](https://pre-commit.com) to execute code linters and\nformatters that check the code for common issues, such as syntax errors, code\nstyle violations, and help to detect bugs. Using pre-commit ensures that linter\nversions and options are aligned for all developers. The same hooks are executed\nas part of the CI checks. This means running pre-commit checks locally avoids\nunnecessary CI iterations.\n\nTo use `pre-commit`, install the tool via `conda` or `pip` into your development\nenvironment:\n\n```console\nconda install -c conda-forge pre-commit\n```\nAlternatively:\n```console\npip install pre-commit\n```\n\nAfter installing pre-commit, it is recommended to install pre-commit hooks to\nrun automatically before creating a git commit. In this way, it is less likely\nthat style checks will fail as part of CI checks. To install pre-commit hooks,\nsimply run the following command within the repository root directory:\n\n```console\npre-commit install\n```\n\nBy default, pre-commit runs on staged files only, meaning only on changes that\nare about to be committed. To run pre-commit checks on all files, execute:\n\n```bash\npre-commit run --all-files\n```\n\nTo skip the checks temporarily, use `git commit --no-verify` or its short form\n`-n`.\n\n_Note_: If the auto-formatters' changes affect each other, you may need to go\nthrough multiple iterations of `git commit` and `git add -u`.\n\ncuML also uses [codespell](https://github.com/codespell-project/codespell) to find spelling\nmistakes, and this check is run as part of the pre-commit hook. To apply the suggested spelling\nfixes, you can run  `codespell -i 3 -w .` from the command-line in the cuML root directory.\nThis will bring up an interactive prompt to select which spelling fixes to apply.\n\nIf you want to ignore errors highlighted by codespell you can:\n * Add the word to the ignore-words-list in pyproject.toml, to exclude for all of cuML\n * Exclude the entire file from spellchecking, by adding to the `exclude` regex in .pre-commit-config.yaml\n * Ignore only specific lines as shown in https://github.com/codespell-project/codespell/issues/1212#issuecomment-654191881\n\n### Summary of pre-commit hooks\n\nThe pre-commit hooks configured for this repository consist of a number of\nlinters and auto-formatters that we summarize here. For a full and current list,\nplease see the `.pre-commit-config.yaml` file.\n\n- `clang-format`: Formats C++ and CUDA code for consistency and readability.\n- `black`: Auto-formats Python code to conform to the PEP 8 style guide.\n- `flake8`: Lints Python code for syntax errors and common code style issues.\n- `cython-lint`: Lints Cython code for syntax errors and common code style issues.\n- _`DeprecationWarning` checker_: Checks for new `DeprecationWarning` being\n  introduced in Python code, and instead `FutureWarning` should be used.\n- _`#include` syntax checker_: Ensures consistent syntax for C++ `#include` statements.\n- _Copyright header checker and auto-formatter_: Ensures the copyright headers\n  of files are up-to-date and in the correct format.\n- `codespell`: Checks for spelling mistakes\n\n### Clang-tidy\n\nIn order to maintain high-quality code, cuML uses not only pre-commit hooks\nfeaturing various formatters and linters but also the clang-tidy tool.\nClang-tidy is designed to detect potential issues within the C and C++ code. It\nis typically run as part of our continuous integration (CI) process.\n\nWhile it's generally unnecessary for contributors to run clang-tidy locally,\nthere might be cases where you would want to do so. There are two primary\nmethods to run clang-tidy on your local machine: using Docker or Conda.\n\n* **Docker**\n\n    1. Navigate to the repository root directory.\n    2. Run the following Docker command:\n\n        ```bash\n        docker run --rm --pull always \\\n            --mount type=bind,source=\"$(pwd)\",target=/opt/repo --workdir /opt/repo \\\n            -e SCCACHE_S3_NO_CREDENTIALS=1 \\\n            rapidsai/ci-conda:latest /opt/repo/ci/run_clang_tidy.sh\n        ```\n\n\n* **Conda**\n\n    1. Navigate to the repository root directory.\n    2. Create and activate the needed conda environment:\n        ```bash\n        conda env create --yes -n cuml-clang-tidy -f conda/environments/clang_tidy_cuda-118_arch-x86_64.yaml\n        conda activate cuml-clang-tidy\n        ```\n    3. Generate the compile command database with\n        ```bash\n        ./build.sh --configure-only libcuml\n        ```\n    3. Run clang-tidy with the following command:\n        ```bash\n        python cpp/scripts/run-clang-tidy.py --config pyproject.toml\n        ```\n\n### Managing PR labels\n\nEach PR must be labeled according to whether it is a \"breaking\" or \"non-breaking\" change (using Github labels). This is used to highlight changes that users should know about when upgrading.\n\nFor cuML, a \"breaking\" change is one that modifies the public, non-experimental, Python API in a\nnon-backward-compatible way. The C++ API does not have an expectation of backward compatibility at this\ntime, so changes to it are not typically considered breaking. Backward-compatible API changes to the Python\nAPI (such as adding a new keyword argument to a function) do not need to be labeled.\n\nAdditional labels must be applied to indicate whether the change is a feature, improvement, bugfix, or documentation change. See the shared RAPIDS documentation for these labels: https://github.com/rapidsai/kb/issues/42.\n\n### Seasoned developers\n\nOnce you have gotten your feet wet and are more comfortable with the code, you\ncan look at the prioritized issues of our next release in our [project boards](https://github.com/rapidsai/cuml/projects).\n\n> **Pro Tip:** Always look at the release board with the highest number for\nissues to work on. This is where RAPIDS developers also focus their efforts.\n\nLook at the unassigned issues, and find an issue you are comfortable with\ncontributing to. Start with _Step 3_ from above, commenting on the issue to let\nothers know you are working on it. If you have any questions related to the\nimplementation of the issue, ask them in the issue instead of the PR.\n\n### Branches and Versions\n\nThe cuML repository has two main branches:\n\n1. `main` branch: it contains the last released version. Only hotfixes are targeted and merged into it.\n2. `branch-x.y`: it is the development branch which contains the upcoming release. All the new features should be based on this branch and Merge/Pull request should target this branch (with the exception of hotfixes).\n\n### Additional details\n\nFor every new version `x.y` of cuML there is a corresponding branch called `branch-x.y`, from where new feature development starts and PRs will be targeted and merged before its release. The exceptions to this are the 'hotfixes' that target the `main` branch, which target critical issues raised by Github users and are directly merged to `main` branch, and create a new subversion of the project. While trying to patch an issue which requires a 'hotfix', please state the intent in the PR.\n\nFor all development, your changes should be pushed into a branch (created using the naming instructions below) in your own fork of cuML and then create a pull request when the code is ready.\n\nA few days before releasing version `x.y` the code of the current development branch (`branch-x.y`) will be frozen and a new branch, 'branch-x+1.y' will be created to continue development.\n\n### Branch naming\n\nBranches used to create PRs should have a name of the form `<type>-<name>`\nwhich conforms to the following conventions:\n- Type:\n    - fea - For if the branch is for a new feature(s)\n    - enh - For if the branch is an enhancement of an existing feature(s)\n    - bug - For if the branch is for fixing a bug(s) or regression(s)\n- Name:\n    - A name to convey what is being worked on\n    - Please use dashes or underscores between words as opposed to spaces.\n\n## Attribution\nPortions adopted from https://github.com/pytorch/pytorch/blob/master/CONTRIBUTING.md\n"
        },
        {
          "name": "LICENSE",
          "type": "blob",
          "size": 11.0849609375,
          "content": "                                 Apache License\n                           Version 2.0, January 2004\n                        http://www.apache.org/licenses/\n\n   TERMS AND CONDITIONS FOR USE, REPRODUCTION, AND DISTRIBUTION\n\n   1. Definitions.\n\n      \"License\" shall mean the terms and conditions for use, reproduction,\n      and distribution as defined by Sections 1 through 9 of this document.\n\n      \"Licensor\" shall mean the copyright owner or entity authorized by\n      the copyright owner that is granting the License.\n\n      \"Legal Entity\" shall mean the union of the acting entity and all\n      other entities that control, are controlled by, or are under common\n      control with that entity. For the purposes of this definition,\n      \"control\" means (i) the power, direct or indirect, to cause the\n      direction or management of such entity, whether by contract or\n      otherwise, or (ii) ownership of fifty percent (50%) or more of the\n      outstanding shares, or (iii) beneficial ownership of such entity.\n\n      \"You\" (or \"Your\") shall mean an individual or Legal Entity\n      exercising permissions granted by this License.\n\n      \"Source\" form shall mean the preferred form for making modifications,\n      including but not limited to software source code, documentation\n      source, and configuration files.\n\n      \"Object\" form shall mean any form resulting from mechanical\n      transformation or translation of a Source form, including but\n      not limited to compiled object code, generated documentation,\n      and conversions to other media types.\n\n      \"Work\" shall mean the work of authorship, whether in Source or\n      Object form, made available under the License, as indicated by a\n      copyright notice that is included in or attached to the work\n      (an example is provided in the Appendix below).\n\n      \"Derivative Works\" shall mean any work, whether in Source or Object\n      form, that is based on (or derived from) the Work and for which the\n      editorial revisions, annotations, elaborations, or other modifications\n      represent, as a whole, an original work of authorship. For the purposes\n      of this License, Derivative Works shall not include works that remain\n      separable from, or merely link (or bind by name) to the interfaces of,\n      the Work and Derivative Works thereof.\n\n      \"Contribution\" shall mean any work of authorship, including\n      the original version of the Work and any modifications or additions\n      to that Work or Derivative Works thereof, that is intentionally\n      submitted to Licensor for inclusion in the Work by the copyright owner\n      or by an individual or Legal Entity authorized to submit on behalf of\n      the copyright owner. For the purposes of this definition, \"submitted\"\n      means any form of electronic, verbal, or written communication sent\n      to the Licensor or its representatives, including but not limited to\n      communication on electronic mailing lists, source code control systems,\n      and issue tracking systems that are managed by, or on behalf of, the\n      Licensor for the purpose of discussing and improving the Work, but\n      excluding communication that is conspicuously marked or otherwise\n      designated in writing by the copyright owner as \"Not a Contribution.\"\n\n      \"Contributor\" shall mean Licensor and any individual or Legal Entity\n      on behalf of whom a Contribution has been received by Licensor and\n      subsequently incorporated within the Work.\n\n   2. Grant of Copyright License. Subject to the terms and conditions of\n      this License, each Contributor hereby grants to You a perpetual,\n      worldwide, non-exclusive, no-charge, royalty-free, irrevocable\n      copyright license to reproduce, prepare Derivative Works of,\n      publicly display, publicly perform, sublicense, and distribute the\n      Work and such Derivative Works in Source or Object form.\n\n   3. Grant of Patent License. Subject to the terms and conditions of\n      this License, each Contributor hereby grants to You a perpetual,\n      worldwide, non-exclusive, no-charge, royalty-free, irrevocable\n      (except as stated in this section) patent license to make, have made,\n      use, offer to sell, sell, import, and otherwise transfer the Work,\n      where such license applies only to those patent claims licensable\n      by such Contributor that are necessarily infringed by their\n      Contribution(s) alone or by combination of their Contribution(s)\n      with the Work to which such Contribution(s) was submitted. If You\n      institute patent litigation against any entity (including a\n      cross-claim or counterclaim in a lawsuit) alleging that the Work\n      or a Contribution incorporated within the Work constitutes direct\n      or contributory patent infringement, then any patent licenses\n      granted to You under this License for that Work shall terminate\n      as of the date such litigation is filed.\n\n   4. Redistribution. You may reproduce and distribute copies of the\n      Work or Derivative Works thereof in any medium, with or without\n      modifications, and in Source or Object form, provided that You\n      meet the following conditions:\n\n      (a) You must give any other recipients of the Work or\n          Derivative Works a copy of this License; and\n\n      (b) You must cause any modified files to carry prominent notices\n          stating that You changed the files; and\n\n      (c) You must retain, in the Source form of any Derivative Works\n          that You distribute, all copyright, patent, trademark, and\n          attribution notices from the Source form of the Work,\n          excluding those notices that do not pertain to any part of\n          the Derivative Works; and\n\n      (d) If the Work includes a \"NOTICE\" text file as part of its\n          distribution, then any Derivative Works that You distribute must\n          include a readable copy of the attribution notices contained\n          within such NOTICE file, excluding those notices that do not\n          pertain to any part of the Derivative Works, in at least one\n          of the following places: within a NOTICE text file distributed\n          as part of the Derivative Works; within the Source form or\n          documentation, if provided along with the Derivative Works; or,\n          within a display generated by the Derivative Works, if and\n          wherever such third-party notices normally appear. The contents\n          of the NOTICE file are for informational purposes only and\n          do not modify the License. You may add Your own attribution\n          notices within Derivative Works that You distribute, alongside\n          or as an addendum to the NOTICE text from the Work, provided\n          that such additional attribution notices cannot be construed\n          as modifying the License.\n\n      You may add Your own copyright statement to Your modifications and\n      may provide additional or different license terms and conditions\n      for use, reproduction, or distribution of Your modifications, or\n      for any such Derivative Works as a whole, provided Your use,\n      reproduction, and distribution of the Work otherwise complies with\n      the conditions stated in this License.\n\n   5. Submission of Contributions. Unless You explicitly state otherwise,\n      any Contribution intentionally submitted for inclusion in the Work\n      by You to the Licensor shall be under the terms and conditions of\n      this License, without any additional terms or conditions.\n      Notwithstanding the above, nothing herein shall supersede or modify\n      the terms of any separate license agreement you may have executed\n      with Licensor regarding such Contributions.\n\n   6. Trademarks. This License does not grant permission to use the trade\n      names, trademarks, service marks, or product names of the Licensor,\n      except as required for reasonable and customary use in describing the\n      origin of the Work and reproducing the content of the NOTICE file.\n\n   7. Disclaimer of Warranty. Unless required by applicable law or\n      agreed to in writing, Licensor provides the Work (and each\n      Contributor provides its Contributions) on an \"AS IS\" BASIS,\n      WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or\n      implied, including, without limitation, any warranties or conditions\n      of TITLE, NON-INFRINGEMENT, MERCHANTABILITY, or FITNESS FOR A\n      PARTICULAR PURPOSE. You are solely responsible for determining the\n      appropriateness of using or redistributing the Work and assume any\n      risks associated with Your exercise of permissions under this License.\n\n   8. Limitation of Liability. In no event and under no legal theory,\n      whether in tort (including negligence), contract, or otherwise,\n      unless required by applicable law (such as deliberate and grossly\n      negligent acts) or agreed to in writing, shall any Contributor be\n      liable to You for damages, including any direct, indirect, special,\n      incidental, or consequential damages of any character arising as a\n      result of this License or out of the use or inability to use the\n      Work (including but not limited to damages for loss of goodwill,\n      work stoppage, computer failure or malfunction, or any and all\n      other commercial damages or losses), even if such Contributor\n      has been advised of the possibility of such damages.\n\n   9. Accepting Warranty or Additional Liability. While redistributing\n      the Work or Derivative Works thereof, You may choose to offer,\n      and charge a fee for, acceptance of support, warranty, indemnity,\n      or other liability obligations and/or rights consistent with this\n      License. However, in accepting such obligations, You may act only\n      on Your own behalf and on Your sole responsibility, not on behalf\n      of any other Contributor, and only if You agree to indemnify,\n      defend, and hold each Contributor harmless for any liability\n      incurred by, or claims asserted against, such Contributor by reason\n      of your accepting any such warranty or additional liability.\n\n   END OF TERMS AND CONDITIONS\n\n   APPENDIX: How to apply the Apache License to your work.\n\n      To apply the Apache License to your work, attach the following\n      boilerplate notice, with the fields enclosed by brackets \"{}\"\n      replaced with your own identifying information. (Don't include\n      the brackets!)  The text should be enclosed in the appropriate\n      comment syntax for the file format. We also recommend that a\n      file or class name and description of purpose be included on the\n      same \"printed page\" as the copyright notice for easier\n      identification within third-party archives.\n\n   Copyright 2018 NVIDIA CORPORATION\n   \n   Licensed under the Apache License, Version 2.0 (the \"License\");\n   you may not use this file except in compliance with the License.\n   You may obtain a copy of the License at\n\n       http://www.apache.org/licenses/LICENSE-2.0\n\n   Unless required by applicable law or agreed to in writing, software\n   distributed under the License is distributed on an \"AS IS\" BASIS,\n   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n   See the License for the specific language governing permissions and\n   limitations under the License.\n"
        },
        {
          "name": "README.md",
          "type": "blob",
          "size": 8.421875,
          "content": "# <div align=\"left\"><img src=\"img/rapids_logo.png\" width=\"90px\"/>&nbsp;cuML - GPU Machine Learning Algorithms</div>\n\ncuML is a suite of libraries that implement machine learning algorithms and mathematical primitives functions that share compatible APIs with other [RAPIDS](https://rapids.ai/) projects.\n\ncuML enables data scientists, researchers, and software engineers to run\ntraditional tabular ML tasks on GPUs without going into the details of CUDA\nprogramming. In most cases, cuML's Python API matches the API from\n[scikit-learn](https://scikit-learn.org).\n\nFor large datasets, these GPU-based implementations can complete 10-50x faster\nthan their CPU equivalents. For details on performance, see the [cuML Benchmarks\nNotebook](https://github.com/rapidsai/cuml/tree/branch-25.02/notebooks/tools).\n\nAs an example, the following Python snippet loads input and computes DBSCAN clusters, all on GPU, using cuDF:\n```python\nimport cudf\nfrom cuml.cluster import DBSCAN\n\n# Create and populate a GPU DataFrame\ngdf_float = cudf.DataFrame()\ngdf_float['0'] = [1.0, 2.0, 5.0]\ngdf_float['1'] = [4.0, 2.0, 1.0]\ngdf_float['2'] = [4.0, 2.0, 1.0]\n\n# Setup and fit clusters\ndbscan_float = DBSCAN(eps=1.0, min_samples=1)\ndbscan_float.fit(gdf_float)\n\nprint(dbscan_float.labels_)\n```\n\nOutput:\n```\n0    0\n1    1\n2    2\ndtype: int32\n```\n\ncuML also features multi-GPU and multi-node-multi-GPU operation, using [Dask](https://www.dask.org), for a\ngrowing list of algorithms. The following Python snippet reads input from a CSV file and performs\na NearestNeighbors query across a cluster of Dask workers, using multiple GPUs on a single node:\n\n\nInitialize a `LocalCUDACluster` configured with [UCX](https://github.com/rapidsai/ucx-py) for fast transport of CUDA arrays\n```python\n# Initialize UCX for high-speed transport of CUDA arrays\nfrom dask_cuda import LocalCUDACluster\n\n# Create a Dask single-node CUDA cluster w/ one worker per device\ncluster = LocalCUDACluster(protocol=\"ucx\",\n                           enable_tcp_over_ucx=True,\n                           enable_nvlink=True,\n                           enable_infiniband=False)\n```\n\nLoad data and perform `k-Nearest Neighbors` search. `cuml.dask` estimators also support `Dask.Array` as input:\n```python\n\nfrom dask.distributed import Client\nclient = Client(cluster)\n\n# Read CSV file in parallel across workers\nimport dask_cudf\ndf = dask_cudf.read_csv(\"/path/to/csv\")\n\n# Fit a NearestNeighbors model and query it\nfrom cuml.dask.neighbors import NearestNeighbors\nnn = NearestNeighbors(n_neighbors = 10, client=client)\nnn.fit(df)\nneighbors = nn.kneighbors(df)\n```\n\nFor additional examples, browse our complete [API\ndocumentation](https://docs.rapids.ai/api/cuml/stable/), or check out our\nexample [walkthrough\nnotebooks](https://github.com/rapidsai/cuml/tree/branch-25.02/notebooks). Finally, you\ncan find complete end-to-end examples in the [notebooks-contrib\nrepo](https://github.com/rapidsai/notebooks-contrib).\n\n\n### Supported Algorithms\n| Category | Algorithm | Notes |\n| --- | --- | --- |\n| **Clustering** |  Density-Based Spatial Clustering of Applications with Noise (DBSCAN) | Multi-node multi-GPU via Dask |\n|  | Hierarchical Density-Based Spatial Clustering of Applications with Noise (HDBSCAN)  | |\n|  | K-Means | Multi-node multi-GPU via Dask |\n|  | Single-Linkage Agglomerative Clustering | |\n| **Dimensionality Reduction** | Principal Components Analysis (PCA) | Multi-node multi-GPU via Dask|\n| | Incremental PCA | |\n| | Truncated Singular Value Decomposition (tSVD) | Multi-node multi-GPU via Dask |\n| | Uniform Manifold Approximation and Projection (UMAP) | Multi-node multi-GPU Inference via Dask |\n| | Random Projection | |\n| | t-Distributed Stochastic Neighbor Embedding (TSNE) | |\n| **Linear Models for Regression or Classification** | Linear Regression (OLS) | Multi-node multi-GPU via Dask |\n| | Linear Regression with Lasso or Ridge Regularization | Multi-node multi-GPU via Dask |\n| | ElasticNet Regression | |\n| | LARS Regression | (experimental) |\n| | Logistic Regression | Multi-node multi-GPU via Dask-GLM [demo](https://github.com/daxiongshu/rapids-demos) |\n| | Naive Bayes | Multi-node multi-GPU via Dask |\n| | Stochastic Gradient Descent (SGD), Coordinate Descent (CD), and Quasi-Newton (QN) (including L-BFGS and OWL-QN) solvers for linear models  | |\n| **Nonlinear Models for Regression or Classification** | Random Forest (RF) Classification | Experimental multi-node multi-GPU via Dask |\n| | Random Forest (RF) Regression | Experimental multi-node multi-GPU via Dask |\n| | Inference for decision tree-based models | Forest Inference Library (FIL) |\n|  | K-Nearest Neighbors (KNN) Classification | Multi-node multi-GPU via Dask+[UCX](https://github.com/rapidsai/ucx-py), uses [Faiss](https://github.com/facebookresearch/faiss) for Nearest Neighbors Query. |\n|  | K-Nearest Neighbors (KNN) Regression | Multi-node multi-GPU via Dask+[UCX](https://github.com/rapidsai/ucx-py), uses [Faiss](https://github.com/facebookresearch/faiss) for Nearest Neighbors Query. |\n|  | Support Vector Machine Classifier (SVC) | |\n|  | Epsilon-Support Vector Regression (SVR) | |\n| **Preprocessing** | Standardization, or mean removal and variance scaling / Normalization / Encoding categorical features / Discretization / Imputation of missing values / Polynomial features generation / and coming soon custom transformers and non-linear transformation | Based on Scikit-Learn preprocessing\n| **Time Series** | Holt-Winters Exponential Smoothing | |\n|  | Auto-regressive Integrated Moving Average (ARIMA) | Supports seasonality (SARIMA) |\n| **Model Explanation**                                 | SHAP Kernel Explainer\n| [Based on SHAP](https://shap.readthedocs.io/en/latest/)                                                                                                                                              |\n|                                                       | SHAP Permutation Explainer\n| [Based on SHAP](https://shap.readthedocs.io/en/latest/)                                                                                                                                               |\n| **Execution device interoperability** | | Run estimators interchangeably from host/cpu or device/gpu with minimal code change [demo](https://docs.rapids.ai/api/cuml/stable/execution_device_interoperability.html) |\n| **Other**                                             | K-Nearest Neighbors (KNN) Search                                                                                                          | Multi-node multi-GPU via Dask+[UCX](https://github.com/rapidsai/ucx-py), uses [Faiss](https://github.com/facebookresearch/faiss) for Nearest Neighbors Query. |\n\n---\n\n## Installation\n\nSee [the RAPIDS Release Selector](https://docs.rapids.ai/install#selector) for\nthe command line to install either nightly or official release cuML packages\nvia Conda or Docker.\n\n## Build/Install from Source\nSee the build [guide](BUILD.md).\n\n## Contributing\n\nPlease see our [guide for contributing to cuML](CONTRIBUTING.md).\n\n## References\n\nThe RAPIDS team has a number of blogs with deeper technical dives and examples. [You can find them here on Medium.](https://medium.com/rapids-ai/tagged/machine-learning)\n\nFor additional details on the technologies behind cuML, as well as a broader overview of the Python Machine Learning landscape, see [_Machine Learning in Python: Main developments and technology trends in data science, machine learning, and artificial intelligence_ (2020)](https://arxiv.org/abs/2002.04803) by Sebastian Raschka, Joshua Patterson, and Corey Nolet.\n\nPlease consider citing this when using cuML in a project. You can use the citation BibTeX:\n\n```bibtex\n@article{raschka2020machine,\n  title={Machine Learning in Python: Main developments and technology trends in data science, machine learning, and artificial intelligence},\n  author={Raschka, Sebastian and Patterson, Joshua and Nolet, Corey},\n  journal={arXiv preprint arXiv:2002.04803},\n  year={2020}\n}\n```\n\n## Contact\n\nFind out more details on the [RAPIDS site](https://rapids.ai/community.html)\n\n## <div align=\"left\"><img src=\"img/rapids_logo.png\" width=\"265px\"/></div> Open GPU Data Science\n\nThe RAPIDS suite of open source software libraries aim to enable execution of end-to-end data science and analytics pipelines entirely on GPUs. It relies on NVIDIA® CUDA® primitives for low-level compute optimization, but exposing that GPU parallelism and high-bandwidth memory speed through user-friendly Python interfaces.\n\n<p align=\"center\"><img src=\"img/rapids_arrow.png\" width=\"80%\"/></p>\n"
        },
        {
          "name": "VERSION",
          "type": "blob",
          "size": 0.0087890625,
          "content": "25.02.00\n"
        },
        {
          "name": "build.sh",
          "type": "blob",
          "size": 10.4365234375,
          "content": "#!/bin/bash\n\n# Copyright (c) 2019-2024, NVIDIA CORPORATION.\n\n# cuml build script\n\n# This script is used to build the component(s) in this repo from\n# source, and can be called with various options to customize the\n# build as needed (see the help output for details)\n\n# Abort script on first error\nset -e\n\nNUMARGS=$#\nARGS=$*\n\n# NOTE: ensure all dir changes are relative to the location of this\n# script, and that this script resides in the repo dir!\nREPODIR=$(cd $(dirname $0); pwd)\n\nVALIDTARGETS=\"clean libcuml cuml cuml-cpu cpp-mgtests prims bench prims-bench cppdocs pydocs\"\nVALIDFLAGS=\"-v -g -n --allgpuarch --singlegpu --nolibcumltest --nvtx --show_depr_warn --codecov --ccache --configure-only -h --help \"\nVALIDARGS=\"${VALIDTARGETS} ${VALIDFLAGS}\"\nHELP=\"$0 [<target> ...] [<flag> ...]\n where <target> is:\n   clean             - remove all existing build artifacts and configuration (start over)\n   libcuml           - build the cuml C++ code only. Also builds the C-wrapper library\n                       around the C++ code.\n   cuml              - build the cuml Python package\n   cuml-cpu          - build the cuml CPU Python package\n   cpp-mgtests       - build libcuml mnmg tests. Builds MPI communicator, adding MPI as dependency.\n   prims             - build the ml-prims tests\n   bench             - build the libcuml C++ benchmark\n   prims-bench       - build the ml-prims C++ benchmark\n   cppdocs           - build the C++ API doxygen documentation\n   pydocs            - build the general and Python API documentation\n and <flag> is:\n   -v                - verbose build mode\n   -g                - build for debug\n   -n                - no install step\n   -h                - print this text\n   --allgpuarch      - build for all supported GPU architectures\n   --singlegpu       - Build libcuml and cuml without multigpu components\n   --nolibcumltest   - disable building libcuml C++ tests for a faster build\n   --nvtx            - Enable nvtx for profiling support\n   --show_depr_warn  - show cmake deprecation warnings\n   --codecov         - Enable code coverage support by compiling with Cython linetracing\n                       and profiling enabled (WARNING: Impacts performance)\n   --ccache          - Use ccache to cache previous compilations\n   --configure-only  - Invoke CMake without actually building\n   --nocloneraft     - CMake will clone RAFT even if it is in the environment, use this flag to disable that behavior\n   --static-treelite - Force CMake to use the Treelite static libs, cloning and building them if necessary\n\n default action (no args) is to build and install 'libcuml', 'cuml', and 'prims' targets only for the detected GPU arch\n\n The following environment variables are also accepted to allow further customization:\n   PARALLEL_LEVEL         - Number of parallel threads to use in compilation.\n   CUML_EXTRA_CMAKE_ARGS  - Extra arguments to pass directly to cmake. Values listed in environment\n                            variable will override existing arguments. Example:\n                            CUML_EXTRA_CMAKE_ARGS=\\\"-DBUILD_CUML_C_LIBRARY=OFF\\\" ./build.sh\n   CUML_EXTRA_PYTHON_ARGS - Extra arguments to pass directly to pip install\n\"\nLIBCUML_BUILD_DIR=${LIBCUML_BUILD_DIR:=${REPODIR}/cpp/build}\nCUML_BUILD_DIR=${REPODIR}/python/cuml/build\nPYTHON_DEPS_CLONE=${REPODIR}/python/external_repositories\nBUILD_DIRS=\"${LIBCUML_BUILD_DIR} ${CUML_BUILD_DIR} ${PYTHON_DEPS_CLONE}\"\n\n# Set defaults for vars modified by flags to this script\nVERBOSE=\"\"\nBUILD_TYPE=Release\nINSTALL_TARGET=install\nBUILD_ALL_GPU_ARCH=0\nSINGLEGPU_CPP_FLAG=\"\"\nCUML_EXTRA_PYTHON_ARGS=${CUML_EXTRA_PYTHON_ARGS:=\"\"}\nNVTX=OFF\nCCACHE=OFF\nCLEAN=0\nBUILD_DISABLE_DEPRECATION_WARNINGS=ON\nBUILD_CUML_STD_COMMS=ON\nBUILD_CUML_TESTS=ON\nBUILD_CUML_MG_TESTS=OFF\nBUILD_STATIC_TREELITE=OFF\nCMAKE_LOG_LEVEL=WARNING\n\n# Set defaults for vars that may not have been defined externally\nINSTALL_PREFIX=${INSTALL_PREFIX:=${PREFIX:=${CONDA_PREFIX:=$LIBCUML_BUILD_DIR/install}}}\nPARALLEL_LEVEL=${PARALLEL_LEVEL:=`nproc`}\n\n# Default to Ninja if generator is not specified\nexport CMAKE_GENERATOR=\"${CMAKE_GENERATOR:=Ninja}\"\n\n# Allow setting arbitrary cmake args via the $CUML_ADDL_CMAKE_ARGS variable. Any\n# values listed here will override existing arguments. For example:\n# CUML_EXTRA_CMAKE_ARGS=\"-DBUILD_CUML_C_LIBRARY=OFF\" ./build.sh\n# Will disable building the C library even though it is hard coded to ON\nCUML_EXTRA_CMAKE_ARGS=${CUML_EXTRA_CMAKE_ARGS:=\"\"}\n\nfunction hasArg {\n    (( ${NUMARGS} != 0 )) && (echo \" ${ARGS} \" | grep -q \" $1 \")\n}\n\nfunction completeBuild {\n    (( ${NUMARGS} == 0 )) && return\n    for a in ${ARGS}; do\n        if (echo \" ${VALIDTARGETS} \" | grep -q \" ${a} \"); then\n          false; return\n        fi\n    done\n    true\n}\n\nif hasArg -h || hasArg --help; then\n    echo \"${HELP}\"\n    exit 0\nfi\n\nif hasArg clean; then\n    CLEAN=1\nfi\n\nif hasArg cpp-mgtests; then\n    BUILD_CUML_MG_TESTS=ON\nfi\n\n# Long arguments\nLONG_ARGUMENT_LIST=(\n    \"verbose\"\n    \"debug\"\n    \"no-install\"\n    \"allgpuarch\"\n    \"singlegpu\"\n    \"nvtx\"\n    \"show_depr_warn\"\n    \"codecov\"\n    \"ccache\"\n    \"nolibcumltest\"\n    \"nocloneraft\"\n    \"configure-only\"\n)\n\n# Short arguments\nARGUMENT_LIST=(\n    \"v\"\n    \"g\"\n    \"n\"\n)\n\n# read arguments\nopts=$(getopt \\\n    --longoptions \"$(printf \"%s,\" \"${LONG_ARGUMENT_LIST[@]}\")\" \\\n    --name \"$(basename \"$0\")\" \\\n    --options \"$(printf \"%s\" \"${ARGUMENT_LIST[@]}\")\" \\\n    -- \"$@\"\n)\n\nif [ $? != 0 ] ; then echo \"Terminating...\" >&2 ; exit 1 ; fi\n\neval set -- \"$opts\"\n\nwhile true; do\n    case \"$1\" in\n        -h)\n            show_help\n            exit 0\n            ;;\n        -v | --verbose )\n            VERBOSE_FLAG=\"-v\"\n            CMAKE_LOG_LEVEL=VERBOSE\n            ;;\n        -g | --debug )\n            BUILD_TYPE=RelWithDebInfo\n            ;;\n        -n | --no-install )\n            INSTALL_TARGET=\"\"\n            ;;\n        --allgpuarch )\n            BUILD_ALL_GPU_ARCH=1\n            ;;\n        --singlegpu )\n            CUML_EXTRA_PYTHON_ARGS=\"${CUML_EXTRA_PYTHON_ARGS} --singlegpu\"\n            SINGLEGPU_CPP_FLAG=ON\n            ;;\n        --nvtx )\n            NVTX=ON\n            ;;\n        --show_depr_warn )\n            BUILD_DISABLE_DEPRECATION_WARNINGS=OFF\n            ;;\n        --codecov )\n            CUML_EXTRA_PYTHON_ARGS=\"${CUML_EXTRA_PYTHON_ARGS} --linetrace=1 --profile\"\n            ;;\n        --ccache )\n            CCACHE=ON\n            ;;\n        --nolibcumltest )\n            BUILD_CUML_TESTS=OFF\n            ;;\n        --nocloneraft )\n            DISABLE_FORCE_CLONE_RAFT=ON\n            ;;\n        --static-treelite )\n            BUILD_STATIC_TREELITE=ON\n            ;;\n        --)\n            shift\n            break\n            ;;\n    esac\n    shift\ndone\n\n\n# If clean given, run it prior to any other steps\nif (( ${CLEAN} == 1 )); then\n    # If the dirs to clean are mounted dirs in a container, the\n    # contents should be removed but the mounted dirs will remain.\n    # The find removes all contents but leaves the dirs, the rmdir\n    # attempts to remove the dirs but can fail safely.\n    for bd in ${BUILD_DIRS}; do\n        if [ -d ${bd} ]; then\n            find ${bd} -mindepth 1 -delete\n            rmdir ${bd} || true\n        fi\n    done\n\n    # Clean up python artifacts\n    find ${REPODIR}/python/ | grep -E \"(__pycache__|\\.pyc|\\.pyo|\\.so|\\_skbuild)$\"  | xargs rm -rf\n\n    # Remove Doxyfile\n    rm -rf ${REPODIR}/cpp/Doxyfile\n\n    # Remove .benchmark dirs and .pytest_cache\n    find ${REPODIR}/ | grep -E \"(\\.pytest_cache|\\.benchmarks)$\"  | xargs rm -rf\nfi\n\n\n################################################################################\n# Configure for building all C++ targets\nif completeBuild || hasArg libcuml || hasArg prims || hasArg bench || hasArg prims-bench || hasArg cppdocs || hasArg cpp-mgtests; then\n    if (( ${BUILD_ALL_GPU_ARCH} == 0 )); then\n        CUML_CMAKE_CUDA_ARCHITECTURES=\"NATIVE\"\n        echo \"Building for the architecture of the GPU in the system...\"\n    else\n        CUML_CMAKE_CUDA_ARCHITECTURES=\"RAPIDS\"\n        echo \"Building for *ALL* supported GPU architectures...\"\n    fi\n\n    mkdir -p ${LIBCUML_BUILD_DIR}\n    cd ${LIBCUML_BUILD_DIR}\n\n    cmake -DCMAKE_INSTALL_PREFIX=${INSTALL_PREFIX} \\\n          -DCMAKE_CUDA_ARCHITECTURES=${CUML_CMAKE_CUDA_ARCHITECTURES} \\\n          -DCMAKE_BUILD_TYPE=${BUILD_TYPE} \\\n          -DBUILD_CUML_C_LIBRARY=ON \\\n          -DSINGLEGPU=${SINGLEGPU_CPP_FLAG} \\\n          -DCUML_ALGORITHMS=\"ALL\" \\\n          -DBUILD_CUML_TESTS=${BUILD_CUML_TESTS} \\\n          -DBUILD_CUML_MPI_COMMS=${BUILD_CUML_MG_TESTS} \\\n          -DBUILD_CUML_MG_TESTS=${BUILD_CUML_MG_TESTS} \\\n          -DCUML_USE_TREELITE_STATIC=${BUILD_STATIC_TREELITE} \\\n          -DNVTX=${NVTX} \\\n          -DUSE_CCACHE=${CCACHE} \\\n          -DDISABLE_DEPRECATION_WARNINGS=${BUILD_DISABLE_DEPRECATION_WARNINGS} \\\n          -DCMAKE_PREFIX_PATH=${INSTALL_PREFIX} \\\n          -DCMAKE_MESSAGE_LOG_LEVEL=${CMAKE_LOG_LEVEL} \\\n          ${CUML_EXTRA_CMAKE_ARGS} \\\n          ..\nfi\n\n# If `./build.sh cuml` is called, don't build C/C++ components\nif (! hasArg --configure-only) && (completeBuild || hasArg libcuml || hasArg prims || hasArg bench || hasArg cpp-mgtests); then\n    cd ${LIBCUML_BUILD_DIR}\n    if [ -n \"${INSTALL_TARGET}\" ]; then\n      cmake --build ${LIBCUML_BUILD_DIR} -j${PARALLEL_LEVEL} ${build_args} --target ${INSTALL_TARGET} ${VERBOSE_FLAG}\n    else\n      cmake --build ${LIBCUML_BUILD_DIR} -j${PARALLEL_LEVEL} ${build_args} ${VERBOSE_FLAG}\n    fi\nfi\n\nif (! hasArg --configure-only) && hasArg cppdocs; then\n    cd ${LIBCUML_BUILD_DIR}\n    cmake --build ${LIBCUML_BUILD_DIR} --target docs_cuml\nfi\n\n\n# Build and (optionally) install the cuml Python package\nif (! hasArg --configure-only) && (completeBuild || hasArg cuml || hasArg pydocs); then\n    # Replace spaces with semicolons in SKBUILD_EXTRA_CMAKE_ARGS\n    SKBUILD_EXTRA_CMAKE_ARGS=$(echo ${SKBUILD_EXTRA_CMAKE_ARGS} | sed 's/ /;/g')\n\n    # Append `-DFIND_CUML_CPP=ON` to CUML_EXTRA_CMAKE_ARGS unless a user specified the option.\n    if [[ \"${SKBUILD_EXTRA_CMAKE_ARGS}\" != *\"DFIND_CUML_CPP\"* ]]; then\n        SKBUILD_EXTRA_CMAKE_ARGS=\"${SKBUILD_EXTRA_CMAKE_ARGS};-DFIND_CUML_CPP=ON\"\n    fi\n\n    SKBUILD_CMAKE_ARGS=\"-DCMAKE_MESSAGE_LOG_LEVEL=${CMAKE_LOG_LEVEL};${SKBUILD_EXTRA_CMAKE_ARGS}\" \\\n        python -m pip install --no-build-isolation --no-deps --config-settings rapidsai.disable-cuda=true ${REPODIR}/python/cuml\n\n    if hasArg pydocs; then\n        cd ${REPODIR}/docs\n        make html\n    fi\nfi\n\nif hasArg cuml-cpu; then\n    SKBUILD_CMAKE_ARGS=\"-DCUML_CPU=ON;-DCMAKE_MESSAGE_LOG_LEVEL=VERBOSE\" \\\n        python -m pip install --no-build-isolation --no-deps --config-settings rapidsai.disable-cuda=true ${REPODIR}/python/cuml\nfi\n"
        },
        {
          "name": "ci",
          "type": "tree",
          "content": null
        },
        {
          "name": "codecov.yml",
          "type": "blob",
          "size": 0.4521484375,
          "content": "#Configuration File for CodeCov\ncoverage:\n  status:\n    project: off\n    patch: off\ncomment:\n  behavior: new\n\n# Suggested workaround to fix \"missing base report\" issue when using Squash and\n# Merge Strategy in GitHub. See this comment from CodeCov support about this\n# undocumented option:\n# https://community.codecov.io/t/unable-to-determine-a-parent-commit-to-compare-against-in-base-branch-after-squash-and-merge/2480/15\ncodecov:\n  allow_coverage_offsets: true"
        },
        {
          "name": "conda",
          "type": "tree",
          "content": null
        },
        {
          "name": "cpp",
          "type": "tree",
          "content": null
        },
        {
          "name": "dependencies.yaml",
          "type": "blob",
          "size": 18.9560546875,
          "content": "# Dependency list for https://github.com/rapidsai/dependency-file-generator\nfiles:\n  all:\n    output: conda\n    matrix:\n      cuda: [\"11.8\", \"12.5\"]\n      arch: [x86_64]\n    includes:\n      - common_build\n      - cuda\n      - cuda_version\n      - depends_on_cudf\n      - depends_on_cupy\n      - depends_on_cuvs\n      - depends_on_dask_cudf\n      - depends_on_libcumlprims\n      - depends_on_libcuvs\n      - depends_on_libraft_headers\n      - depends_on_librmm\n      - depends_on_pylibraft\n      - depends_on_raft_dask\n      - depends_on_rmm\n      - docs\n      - py_build\n      - py_run\n      - py_version\n      - rapids_build_backend\n      - test_python\n  cpp_all:\n    output: conda\n    matrix:\n      cuda: [\"11.8\", \"12.5\"]\n      arch: [x86_64]\n    includes:\n      - common_build\n      - cuda\n      - cuda_version\n      - depends_on_libcumlprims\n      - depends_on_libcuvs\n      - depends_on_libraft_headers\n      - depends_on_librmm\n  checks:\n    output: none\n    includes:\n      - checks\n      - py_version\n  clang_tidy:\n    output: conda\n    matrix:\n      cuda: [\"11.8\"]\n      arch: [x86_64]\n    includes:\n      - clang_tidy\n      - common_build\n      - cuda\n      - cuda_version\n      - depends_on_libcumlprims\n      - depends_on_libcuvs\n      - depends_on_libraft_headers\n      - depends_on_librmm\n  docs:\n    output: none\n    includes:\n      - cuda_version\n      - docs\n      - py_version\n  test_cpp:\n    output: none\n    includes:\n      - cuda_version\n      - depends_on_libcuml\n      - test_libcuml\n      - test_cpp\n  test_python:\n    output: none\n    includes:\n      - cuda_version\n      - depends_on_cuml\n      - depends_on_libcuml\n      - py_version\n      - test_python\n  test_notebooks:\n    output: none\n    includes:\n      - cuda_version\n      - depends_on_cuml\n      - depends_on_cupy\n      - depends_on_cuvs\n      - depends_on_dask_cudf\n      - depends_on_pylibraft\n      - depends_on_raft_dask\n      - depends_on_rmm\n      - py_run\n      - py_version\n      - test_notebooks\n  py_build_cuml:\n    output: pyproject\n    pyproject_dir: python/cuml\n    extras:\n      table: build-system\n    includes:\n      - rapids_build_backend\n  py_rapids_build_cuml:\n    output: pyproject\n    pyproject_dir: python/cuml\n    extras:\n      table: tool.rapids-build-backend\n      key: requires\n    includes:\n      - common_build\n      - depends_on_cuvs\n      - depends_on_libcumlprims\n      - depends_on_libraft_headers\n      - depends_on_pylibraft\n      - depends_on_rmm\n      - py_build\n  py_run_cuml:\n    output: pyproject\n    pyproject_dir: python/cuml\n    extras:\n      table: project\n    includes:\n      - cuda_wheels\n      - depends_on_cudf\n      - depends_on_cupy\n      - depends_on_cuvs\n      - depends_on_dask_cudf\n      - depends_on_pylibraft\n      - depends_on_raft_dask\n      - depends_on_rmm\n      - py_run\n  py_test_cuml:\n    output: pyproject\n    pyproject_dir: python/cuml\n    extras:\n      table: project.optional-dependencies\n      key: test\n    includes:\n      - test_python\nchannels:\n  - rapidsai\n  - rapidsai-nightly\n  - dask/label/dev\n  - conda-forge\n  - nvidia\ndependencies:\n  rapids_build_backend:\n    common:\n      - output_types: [conda, requirements, pyproject]\n        packages:\n          - rapids-build-backend>=0.3.0,<0.4.0.dev0\n      - output_types: [conda]\n        packages:\n          - scikit-build-core>=0.10.0\n      - output_types: [requirements, pyproject]\n        packages:\n          - scikit-build-core[pyproject]>=0.10.0\n  checks:\n    common:\n      - output_types: [conda, requirements]\n        packages:\n          - pre-commit\n  clang_tidy:\n    common:\n      - output_types: [conda, requirements]\n        packages:\n          # clang 15 required by libcudacxx.\n          - clang==15.0.7\n          - clang-tools==15.0.7\n          - ninja\n          - tomli\n  common_build:\n    common:\n      - output_types: [conda, requirements, pyproject]\n        packages:\n          - &cmake_ver cmake>=3.26.4,!=3.30.0\n          - ninja\n      - output_types: conda\n        packages:\n          - c-compiler\n          - cxx-compiler\n          - fmt>=11.0.2,<12\n          - spdlog>=1.14.1,<1.15\n    specific:\n      - output_types: conda\n        matrices:\n          - matrix:\n              arch: x86_64\n            packages:\n              - gcc_linux-64=11.*\n              - sysroot_linux-64==2.17\n          - matrix:\n              arch: aarch64\n            packages:\n              - gcc_linux-aarch64=11.*\n              - sysroot_linux-aarch64==2.17\n      - output_types: conda\n        matrices:\n          - matrix:\n              arch: x86_64\n              cuda: \"11.8\"\n            packages:\n              - nvcc_linux-64=11.8\n          - matrix:\n              arch: aarch64\n              cuda: \"11.8\"\n            packages:\n              - nvcc_linux-aarch64=11.8\n          - matrix:\n              cuda: \"12.*\"\n            packages:\n              - cuda-nvcc\n  py_build:\n    common:\n      - output_types: [conda, requirements, pyproject]\n        packages:\n          - &cython cython>=3.0.0\n          - &treelite treelite==4.3.0\n    specific:\n      - output_types: [conda, requirements, pyproject]\n        matrices:\n          - matrix:\n              cuda: \"12.*\"\n            packages:\n              - cuda-python>=12.6.2,<13.0a0\n          - matrix:\n              cuda: \"11.*\"\n            packages:\n              - cuda-python>=11.8.5,<12.0a0\n          - matrix:\n            packages:\n              - cuda-python\n\n  py_run:\n    common:\n      - output_types: [conda, requirements, pyproject]\n        packages:\n          - dask-cuda==25.2.*,>=0.0.0a0\n          - joblib>=0.11\n          - numba>=0.57\n          - numpy>=1.23,<3.0a0\n            # TODO: Is scipy really a hard dependency, or should\n            # we make it optional (i.e. an extra for pip\n            # installation/run_constrained for conda)?\n          - scipy>=1.8.0\n          - packaging\n          - rapids-dask-dependency==25.2.*,>=0.0.0a0\n          - *treelite\n      - output_types: requirements\n        packages:\n          # pip recognizes the index as a global option for the requirements.txt file\n          - --extra-index-url=https://pypi.nvidia.com\n          - --extra-index-url=https://pypi.anaconda.org/rapidsai-wheels-nightly/simple\n  cuda_version:\n    specific:\n      - output_types: conda\n        matrices:\n          - matrix:\n              cuda: \"11.2\"\n            packages:\n              - cuda-version=11.2\n          - matrix:\n              cuda: \"11.4\"\n            packages:\n              - cuda-version=11.4\n          - matrix:\n              cuda: \"11.5\"\n            packages:\n              - cuda-version=11.5\n          - matrix:\n              cuda: \"11.8\"\n            packages:\n              - cuda-version=11.8\n          - matrix:\n              cuda: \"12.0\"\n            packages:\n              - cuda-version=12.0\n          - matrix:\n              cuda: \"12.2\"\n            packages:\n              - cuda-version=12.2\n          - matrix:\n              cuda: \"12.5\"\n            packages:\n              - cuda-version=12.5\n  cuda:\n    specific:\n      - output_types: conda\n        matrices:\n          - matrix:\n              cuda: \"12.*\"\n            packages:\n              - cuda-cudart-dev\n              - cuda-profiler-api\n              - libcublas-dev\n              - libcufft-dev\n              - libcurand-dev\n              - libcusolver-dev\n              - libcusparse-dev\n          - matrix:\n              cuda: \"11.8\"\n            packages:\n              - cudatoolkit\n              - libcublas-dev=11.11.3.6\n              - libcublas=11.11.3.6\n              - libcufft-dev=10.9.0.58\n              - libcufft=10.9.0.58\n              - libcurand-dev=10.3.0.86\n              - libcurand=10.3.0.86\n              - libcusolver-dev=11.4.1.48\n              - libcusolver=11.4.1.48\n              - libcusparse-dev=11.7.5.86\n              - libcusparse=11.7.5.86\n          - matrix:\n              cuda: \"11.5\"\n            packages:\n              - cudatoolkit\n              - libcublas-dev>=11.7.3.1,<=11.7.4.6\n              - libcublas>=11.7.3.1,<=11.7.4.6\n              - libcufft-dev>=10.6.0.54,<=10.6.0.107\n              - libcufft>=10.6.0.54,<=10.6.0.107\n              - libcurand-dev>=10.2.6.48,<=10.2.7.107\n              - libcurand>=10.2.6.48,<=10.2.7.107\n              - libcusolver-dev>=11.2.1.48,<=11.3.2.107\n              - libcusolver>=11.2.1.48,<=11.3.2.107\n              - libcusparse-dev>=11.7.0.31,<=11.7.0.107\n              - libcusparse>=11.7.0.31,<=11.7.0.107\n          - matrix:\n              cuda: \"11.4\"\n            packages:\n              - cudatoolkit\n              - &libcublas_dev114 libcublas-dev>=11.5.2.43,<=11.6.5.2\n              - &libcublas114 libcublas>=11.5.2.43,<=11.6.5.2\n              - &libcufft_dev114 libcufft-dev>=10.5.0.43,<=10.5.2.100\n              - &libcufft114 libcufft>=10.5.0.43,<=10.5.2.100\n              - &libcurand_dev114 libcurand-dev>=10.2.5.43,<=10.2.5.120\n              - &libcurand114 libcurand>=10.2.5.43,<=10.2.5.120\n              - &libcusolver_dev114 libcusolver-dev>=11.2.0.43,<=11.2.0.120\n              - &libcusolver114 libcusolver>=11.2.0.43,<=11.2.0.120\n              - &libcusparse_dev114 libcusparse-dev>=11.6.0.43,<=11.6.0.120\n              - &libcusparse114 libcusparse>=11.6.0.43,<=11.6.0.120\n          - matrix:\n              cuda: \"11.2\"\n            packages:\n              - cudatoolkit\n              # The NVIDIA channel doesn't publish pkgs older than 11.4 for these libs,\n              # so 11.2 uses 11.4 packages (the oldest available).\n              - *libcublas_dev114\n              - *libcublas114\n              - *libcufft_dev114\n              - *libcufft114\n              - *libcurand_dev114\n              - *libcurand114\n              - *libcusolver_dev114\n              - *libcusolver114\n              - *libcusparse_dev114\n              - *libcusparse114\n  cuda_wheels:\n    specific:\n      - output_types: pyproject\n        matrices:\n          - matrix:\n              cuda: \"12.*\"\n              use_cuda_wheels: \"true\"\n            packages:\n              - nvidia-cublas-cu12\n              - nvidia-cufft-cu12\n              - nvidia-curand-cu12\n              - nvidia-cusparse-cu12\n              - nvidia-cusolver-cu12\n          # CUDA 11 does not provide wheels, so use the system libraries instead\n          - matrix:\n              cuda: \"11.*\"\n              use_cuda_wheels: \"true\"\n            packages:\n          # if use_cuda_wheels=false is provided, do not add dependencies on any CUDA wheels\n          # (e.g. for DLFW and pip devcontainers)\n          - matrix:\n              use_cuda_wheels: \"false\"\n            packages:\n          # if no matching matrix selectors passed, list the unsuffixed packages\n          # (just as a source of documentation, as this populates pyproject.toml in source control)\n          - matrix:\n            packages:\n              - nvidia-cublas\n              - nvidia-cufft\n              - nvidia-curand\n              - nvidia-cusparse\n              - nvidia-cusolver\n  docs:\n    common:\n      - output_types: [conda, requirements]\n        packages:\n          - graphviz\n          - ipython\n          - ipykernel\n          - nbsphinx\n          - numpydoc\n          # https://github.com/pydata/pydata-sphinx-theme/issues/1539\n          - pydata-sphinx-theme!=0.14.2\n          - recommonmark\n          - &scikit_learn scikit-learn==1.5.*\n          - sphinx\n          - sphinx-copybutton\n          - sphinx-markdown-tables\n      - output_types: conda\n        packages:\n          - doxygen=1.9.1\n  py_version:\n    specific:\n      - output_types: conda\n        matrices:\n          - matrix:\n              py: \"3.10\"\n            packages:\n              - python=3.10\n          - matrix:\n              py: \"3.11\"\n            packages:\n              - python=3.11\n          - matrix:\n              py: \"3.12\"\n            packages:\n              - python=3.12\n          - matrix:\n            packages:\n              - python>=3.10,<3.13\n  test_libcuml:\n    common:\n      - output_types: conda\n        packages:\n          - libcuml-tests==25.2.*,>=0.0.0a0\n  test_cpp:\n    common:\n      - output_types: conda\n        packages:\n          - *cmake_ver\n  test_python:\n    common:\n      - output_types: [conda, requirements, pyproject]\n        packages:\n          - certifi\n          - *cython\n          - dask-ml\n          - hdbscan>=0.8.39,<0.8.40\n          - hypothesis>=6.0,<7\n          - nltk\n          - numpydoc\n          - pytest==7.*\n          - pytest-benchmark\n          - pytest-cases\n          - pytest-cov\n          - pytest-xdist\n          - seaborn\n          - *scikit_learn\n          - &xgboost xgboost>=2.1.0\n          - statsmodels\n          - umap-learn==0.5.6\n          - pynndescent\n  test_notebooks:\n    common:\n      - output_types: [conda, requirements]\n        packages:\n          - dask-ml==2023.3.24\n          - jupyter\n          - matplotlib\n          - numpy\n          - pandas\n          - *scikit_learn\n          - seaborn\n          - *xgboost\n  depends_on_cudf:\n    common:\n      - output_types: conda\n        packages:\n          - &cudf_unsuffixed cudf==25.2.*,>=0.0.0a0\n      - output_types: requirements\n        packages:\n          # pip recognizes the index as a global option for the requirements.txt file\n          - --extra-index-url=https://pypi.nvidia.com\n          - --extra-index-url=https://pypi.anaconda.org/rapidsai-wheels-nightly/simple\n    specific:\n      - output_types: [requirements, pyproject]\n        matrices:\n          - matrix:\n              cuda: \"12.*\"\n              cuda_suffixed: \"true\"\n            packages:\n              - cudf-cu12==25.2.*,>=0.0.0a0\n          - matrix:\n              cuda: \"11.*\"\n              cuda_suffixed: \"true\"\n            packages:\n              - cudf-cu11==25.2.*,>=0.0.0a0\n          - matrix:\n            packages:\n              - *cudf_unsuffixed\n  depends_on_cuml:\n    common:\n      - output_types: conda\n        packages:\n          - cuml==25.2.*,>=0.0.0a0\n  depends_on_cupy:\n    common:\n      - output_types: conda\n        packages:\n          - cupy>=12.0.0\n    specific:\n      - output_types: [requirements, pyproject]\n        matrices:\n          - matrix: {cuda: \"12.*\"}\n            packages:\n              - cupy-cuda12x>=12.0.0\n          - matrix: {cuda: \"11.*\"}\n            packages: &cupy_packages_cu11\n              - cupy-cuda11x>=12.0.0\n          - {matrix: null, packages: *cupy_packages_cu11}\n  depends_on_cuvs:\n    common:\n      - output_types: conda\n        packages:\n          - &cuvs_unsuffixed cuvs==25.2.*,>=0.0.0a0\n      - output_types: requirements\n        packages:\n          # pip recognizes the index as a global option for the requirements.txt file\n          - --extra-index-url=https://pypi.nvidia.com\n          - --extra-index-url=https://pypi.anaconda.org/rapidsai-wheels-nightly/simple\n    specific:\n      - output_types: [requirements, pyproject]\n        matrices:\n          - matrix:\n              cuda: \"12.*\"\n              cuda_suffixed: \"true\"\n            packages:\n              - cuvs-cu12==25.2.*,>=0.0.0a0\n          - matrix:\n              cuda: \"11.*\"\n              cuda_suffixed: \"true\"\n            packages:\n              - cuvs-cu11==25.2.*,>=0.0.0a0\n          - matrix:\n            packages:\n              - *cuvs_unsuffixed\n  depends_on_dask_cudf:\n    common:\n      - output_types: conda\n        packages:\n          - &dask_cudf_unsuffixed dask-cudf==25.2.*,>=0.0.0a0\n      - output_types: requirements\n        packages:\n          # pip recognizes the index as a global option for the requirements.txt file\n          - --extra-index-url=https://pypi.nvidia.com\n          - --extra-index-url=https://pypi.anaconda.org/rapidsai-wheels-nightly/simple\n    specific:\n      - output_types: [requirements, pyproject]\n        matrices:\n          - matrix:\n              cuda: \"12.*\"\n              cuda_suffixed: \"true\"\n            packages:\n              - dask-cudf-cu12==25.2.*,>=0.0.0a0\n          - matrix:\n              cuda: \"11.*\"\n              cuda_suffixed: \"true\"\n            packages:\n              - dask-cudf-cu11==25.2.*,>=0.0.0a0\n          - matrix:\n            packages:\n              - *dask_cudf_unsuffixed\n  depends_on_libcuml:\n    common:\n      - output_types: conda\n        packages:\n          - libcuml==25.2.*,>=0.0.0a0\n  depends_on_libcumlprims:\n    common:\n      - output_types: conda\n        packages:\n          - libcumlprims==25.2.*,>=0.0.0a0\n  depends_on_libcuvs:\n    common:\n      - output_types: conda\n        packages:\n          - libcuvs==25.2.*,>=0.0.0a0\n  depends_on_libraft_headers:\n    common:\n      - output_types: conda\n        packages:\n          - libraft-headers==25.2.*,>=0.0.0a0\n  depends_on_librmm:\n    common:\n      - output_types: conda\n        packages:\n          - librmm==25.2.*,>=0.0.0a0\n  depends_on_pylibraft:\n    common:\n      - output_types: conda\n        packages:\n          - &pylibraft_unsuffixed pylibraft==25.2.*,>=0.0.0a0\n      - output_types: requirements\n        packages:\n          # pip recognizes the index as a global option for the requirements.txt file\n          - --extra-index-url=https://pypi.nvidia.com\n          - --extra-index-url=https://pypi.anaconda.org/rapidsai-wheels-nightly/simple\n    specific:\n      - output_types: [requirements, pyproject]\n        matrices:\n          - matrix:\n              cuda: \"12.*\"\n              cuda_suffixed: \"true\"\n            packages:\n              - pylibraft-cu12==25.2.*,>=0.0.0a0\n          - matrix:\n              cuda: \"11.*\"\n              cuda_suffixed: \"true\"\n            packages:\n              - pylibraft-cu11==25.2.*,>=0.0.0a0\n          - matrix:\n            packages:\n              - *pylibraft_unsuffixed\n  depends_on_raft_dask:\n    common:\n      - output_types: conda\n        packages:\n          - &raft_dask_unsuffixed raft-dask==25.2.*,>=0.0.0a0\n      - output_types: requirements\n        packages:\n          # pip recognizes the index as a global option for the requirements.txt file\n          - --extra-index-url=https://pypi.nvidia.com\n          - --extra-index-url=https://pypi.anaconda.org/rapidsai-wheels-nightly/simple\n    specific:\n      - output_types: [requirements, pyproject]\n        matrices:\n          - matrix:\n              cuda: \"12.*\"\n              cuda_suffixed: \"true\"\n            packages:\n              - raft-dask-cu12==25.2.*,>=0.0.0a0\n          - matrix:\n              cuda: \"11.*\"\n              cuda_suffixed: \"true\"\n            packages:\n              - raft-dask-cu11==25.2.*,>=0.0.0a0\n          - matrix:\n            packages:\n              - *raft_dask_unsuffixed\n  depends_on_rmm:\n    common:\n      - output_types: conda\n        packages:\n          - &rmm_unsuffixed rmm==25.2.*,>=0.0.0a0\n      - output_types: requirements\n        packages:\n          # pip recognizes the index as a global option for the requirements.txt file\n          - --extra-index-url=https://pypi.nvidia.com\n          - --extra-index-url=https://pypi.anaconda.org/rapidsai-wheels-nightly/simple\n    specific:\n      - output_types: [requirements, pyproject]\n        matrices:\n          - matrix:\n              cuda: \"12.*\"\n              cuda_suffixed: \"true\"\n            packages:\n              - rmm-cu12==25.2.*,>=0.0.0a0\n          - matrix:\n              cuda: \"11.*\"\n              cuda_suffixed: \"true\"\n            packages:\n              - rmm-cu11==25.2.*,>=0.0.0a0\n          - matrix:\n            packages:\n              - *rmm_unsuffixed\n"
        },
        {
          "name": "docs",
          "type": "tree",
          "content": null
        },
        {
          "name": "img",
          "type": "tree",
          "content": null
        },
        {
          "name": "notebooks",
          "type": "tree",
          "content": null
        },
        {
          "name": "print_env.sh",
          "type": "blob",
          "size": 1.732421875,
          "content": "#!/usr/bin/env bash\n# Reports relevant environment information useful for diagnosing and\n# debugging cuML issues.\n# Usage: \n# \"./print_env.sh\" - prints to stdout\n# \"./print_env.sh > env.txt\" - prints to file \"env.txt\"\n\nprint_env() {\necho \"**git***\"\nif [ \"$(git rev-parse --is-inside-work-tree 2>/dev/null)\" == \"true\" ]; then\ngit log --decorate -n 1\necho \"**git submodules***\"\ngit submodule status --recursive\nelse\necho \"Not inside a git repository\"\nfi\necho \n\necho \"***OS Information***\"\ncat /etc/*-release\nuname -a\necho \n\necho \"***GPU Information***\"\nnvidia-smi\necho \n\necho \"***CPU***\"\nlscpu\necho\n\necho \"***CMake***\"\nwhich cmake && cmake --version\necho \n\necho \"***g++***\"\nwhich g++ && g++ --version\necho \n\necho \"***nvcc***\"\nwhich nvcc && nvcc --version\necho \n\necho \"***Python***\"\nwhich python && python -c \"import sys; print('Python {0}.{1}.{2}'.format(sys.version_info[0], sys.version_info[1], sys.version_info[2]))\"\necho\n\necho \"***Environment Variables***\"\n\nprintf '%-32s: %s\\n' PATH $PATH\n\nprintf '%-32s: %s\\n' LD_LIBRARY_PATH $LD_LIBRARY_PATH\n\nprintf '%-32s: %s\\n' NUMBAPRO_NVVM $NUMBAPRO_NVVM\n\nprintf '%-32s: %s\\n' NUMBAPRO_LIBDEVICE $NUMBAPRO_LIBDEVICE\n\nprintf '%-32s: %s\\n' CONDA_PREFIX $CONDA_PREFIX\n\nprintf '%-32s: %s\\n' PYTHON_PATH $PYTHON_PATH\n\necho\n\n\n# Print conda packages if conda exists\nif type \"conda\" &> /dev/null; then\necho '***conda packages***'\nwhich conda && conda list\necho\n# Print pip packages if pip exists\nelif type \"pip\" &> /dev/null; then\necho \"conda not found\"\necho \"***pip packages***\"\nwhich pip && pip list\necho\nelse\necho \"conda not found\"\necho \"pip not found\"\nfi\n}\n\necho \"<details><summary>Click here to see environment details</summary><pre>\"\necho \"     \"\nprint_env | while read -r line; do\n    echo \"     $line\"\ndone\necho \"</pre></details>\"\n"
        },
        {
          "name": "pyproject.toml",
          "type": "blob",
          "size": 0.763671875,
          "content": "[tool.codespell]\n# note: pre-commit passes explicit lists of files here, which this skip file list doesn't override -\n# this is only to allow you to run codespell interactively\nskip = \"./.git,./.github,./cpp/build,.*egg-info.*,./.mypy_cache,.*_skbuild,CHANGELOG.md,_stop_words.py,,*stemmer.*\"\n# ignore short words, and typename parameters like OffsetT\nignore-regex = \"\\\\b(.{1,4}|[A-Z]\\\\w*T)\\\\b\"\nignore-words-list = \"inout,numer,startd,couldn,referr\"\n# use the 'clear' dictionary for unambiguous spelling mistakes\nbuiltin = \"clear\"\n# disable warnings about binary files and wrong encoding\nquiet-level = 3\n\n[tool.cython-lint]\n# TODO: Re-enable E501 with a reasonable line length\nmax-line-length = 999\nignore = ['E501']\n\n\n[tool.run-clang-tidy]\nignore = \"[.]cu$|_deps|examples/kmeans/\"\n"
        },
        {
          "name": "python",
          "type": "tree",
          "content": null
        },
        {
          "name": "rapids_config.cmake",
          "type": "blob",
          "size": 1.79296875,
          "content": "# =============================================================================\n# Copyright (c) 2018-2024, NVIDIA CORPORATION.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\"); you may not use this file except\n# in compliance with the License. You may obtain a copy of the License at\n#\n# http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software distributed under the License\n# is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express\n# or implied. See the License for the specific language governing permissions and limitations under\n# the License.\n# =============================================================================\nfile(READ \"${CMAKE_CURRENT_LIST_DIR}/VERSION\" _rapids_version)\nif(_rapids_version MATCHES [[^([0-9][0-9])\\.([0-9][0-9])\\.([0-9][0-9])]])\n  set(RAPIDS_VERSION_MAJOR \"${CMAKE_MATCH_1}\")\n  set(RAPIDS_VERSION_MINOR \"${CMAKE_MATCH_2}\")\n  set(RAPIDS_VERSION_PATCH \"${CMAKE_MATCH_3}\")\n  set(RAPIDS_VERSION_MAJOR_MINOR \"${RAPIDS_VERSION_MAJOR}.${RAPIDS_VERSION_MINOR}\")\n  set(RAPIDS_VERSION \"${RAPIDS_VERSION_MAJOR}.${RAPIDS_VERSION_MINOR}.${RAPIDS_VERSION_PATCH}\")\nelse()\n  string(REPLACE \"\\n\" \"\\n  \" _rapids_version_formatted \"  ${_rapids_version}\")\n  message(\n    FATAL_ERROR\n      \"Could not determine RAPIDS version. Contents of VERSION file:\\n${_rapids_version_formatted}\"\n  )\nendif()\n\nif(NOT EXISTS \"${CMAKE_CURRENT_BINARY_DIR}/CUML_RAPIDS-${RAPIDS_VERSION_MAJOR_MINOR}.cmake\")\n  file(\n    DOWNLOAD\n    \"https://raw.githubusercontent.com/rapidsai/rapids-cmake/branch-${RAPIDS_VERSION_MAJOR_MINOR}/RAPIDS.cmake\"\n    \"${CMAKE_CURRENT_BINARY_DIR}/CUML_RAPIDS-${RAPIDS_VERSION_MAJOR_MINOR}.cmake\"\n  )\nendif()\ninclude(\"${CMAKE_CURRENT_BINARY_DIR}/CUML_RAPIDS-${RAPIDS_VERSION_MAJOR_MINOR}.cmake\")\n"
        },
        {
          "name": "thirdparty",
          "type": "tree",
          "content": null
        },
        {
          "name": "wiki",
          "type": "tree",
          "content": null
        }
      ]
    }
  ]
}