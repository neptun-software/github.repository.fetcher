{
  "metadata": {
    "timestamp": 1736565373271,
    "page": 207,
    "hasNextPage": true,
    "endCursor": "Y3Vyc29yOjIxMA==",
    "completionStatus": "IN_PROGRESS"
  },
  "repositories": [
    {
      "nameWithOwner": "lightvector/KataGo",
      "stars": 3655,
      "defaultBranch": "master",
      "files": [
        {
          "name": ".clang-format",
          "type": "blob",
          "size": 3.94921875,
          "content": "---\nLanguage:        Cpp\n# BasedOnStyle:  Chromium\nAccessModifierOffset: -1\nAlignAfterOpenBracket: AlwaysBreak\nAlignConsecutiveAssignments: false\nAlignConsecutiveDeclarations: false\nAlignEscapedNewlines: DontAlign\nAlignOperands:   true\nAlignTrailingComments: true\nAllowAllParametersOfDeclarationOnNextLine: false\nAllowShortBlocksOnASingleLine: false\nAllowShortCaseLabelsOnASingleLine: false\nAllowShortFunctionsOnASingleLine: Inline\nAllowShortIfStatementsOnASingleLine: false\nAllowShortLoopsOnASingleLine: false\nAlwaysBreakAfterDefinitionReturnType: None\nAlwaysBreakAfterReturnType: None\nAlwaysBreakBeforeMultilineStrings: true\nAlwaysBreakTemplateDeclarations: Yes\nBinPackArguments: false\nBinPackParameters: false\nBraceWrapping:\n  AfterClass:      false\n  AfterControlStatement: false\n  AfterEnum:       false\n  AfterFunction:   false\n  AfterNamespace:  false\n  AfterObjCDeclaration: false\n  AfterStruct:     false\n  AfterUnion:      false\n  AfterExternBlock: false\n  BeforeCatch:     false\n  BeforeElse:      false\n  IndentBraces:    false\n  SplitEmptyFunction: true\n  SplitEmptyRecord: true\n  SplitEmptyNamespace: true\nBreakBeforeBinaryOperators: None\nBreakBeforeBraces: Attach\nBreakBeforeInheritanceComma: false\nBreakInheritanceList: BeforeColon\nBreakBeforeTernaryOperators: true\nBreakConstructorInitializersBeforeComma: false\nBreakConstructorInitializers: BeforeColon\nBreakAfterJavaFieldAnnotations: false\nBreakStringLiterals: true\nColumnLimit:     120\nCommentPragmas:  '^ IWYU pragma:'\nCompactNamespaces: false\nConstructorInitializerAllOnOneLineOrOnePerLine: true\nConstructorInitializerIndentWidth: 2\nContinuationIndentWidth: 2\nCpp11BracedListStyle: true\nDerivePointerAlignment: false\nDisableFormat:   false\nExperimentalAutoDetectBinPacking: false\nFixNamespaceComments: true\nForEachMacros:\n  - foreach\n  - Q_FOREACH\n  - BOOST_FOREACH\nIncludeBlocks:   Preserve\nIncludeCategories:\n  - Regex:           '^<ext/.*\\.h>'\n    Priority:        2\n  - Regex:           '^<.*\\.h>'\n    Priority:        1\n  - Regex:           '^<.*'\n    Priority:        2\n  - Regex:           '.*'\n    Priority:        3\nIncludeIsMainRegex: '([-_](test|unittest))?$'\nIndentCaseLabels: true\nIndentPPDirectives: None\nIndentWidth:     2\nIndentWrappedFunctionNames: false\nJavaScriptQuotes: Leave\nJavaScriptWrapImports: true\nKeepEmptyLinesAtTheStartOfBlocks: false\nMacroBlockBegin: ''\nMacroBlockEnd:   ''\nMaxEmptyLinesToKeep: 1\nNamespaceIndentation: All\nObjCBinPackProtocolList: Never\nObjCBlockIndentWidth: 2\nObjCSpaceAfterProperty: false\nObjCSpaceBeforeProtocolList: true\nPenaltyBreakAssignment: 1\nPenaltyBreakBeforeFirstCallParameter: 2\nPenaltyBreakComment: 300\nPenaltyBreakFirstLessLess: 120\nPenaltyBreakString: 500000\nPenaltyBreakTemplateDeclaration: 10\nPenaltyExcessCharacter: 10000\nPenaltyReturnTypeOnItsOwnLine: 200\nPointerAlignment: Left\nRawStringFormats:\n  - Language:        Cpp\n    Delimiters:\n      - cc\n      - CC\n      - cpp\n      - Cpp\n      - CPP\n      - 'c++'\n      - 'C++'\n    CanonicalDelimiter: ''\n    BasedOnStyle:    google\n  - Language:        TextProto\n    Delimiters:\n      - pb\n      - PB\n      - proto\n      - PROTO\n    EnclosingFunctions:\n      - EqualsProto\n      - EquivToProto\n      - PARSE_PARTIAL_TEXT_PROTO\n      - PARSE_TEST_PROTO\n      - PARSE_TEXT_PROTO\n      - ParseTextOrDie\n      - ParseTextProtoOrDie\n    CanonicalDelimiter: ''\n    BasedOnStyle:    google\nReflowComments:  true\nSortIncludes:    true\nSortUsingDeclarations: true\nSpaceAfterCStyleCast: false\nSpaceAfterTemplateKeyword: false\nSpaceBeforeAssignmentOperators: true\nSpaceBeforeCpp11BracedList: false\nSpaceBeforeCtorInitializerColon: true\nSpaceBeforeInheritanceColon: true\nSpaceBeforeParens: Never\nSpaceBeforeRangeBasedForLoopColon: false\nSpaceInEmptyParentheses: false\nSpacesBeforeTrailingComments: 2\nSpacesInAngles:  false\nSpacesInContainerLiterals: false\nSpacesInCStyleCastParentheses: false\nSpacesInParentheses: false\nSpacesInSquareBrackets: false\nStandard:        Auto\nStatementMacros:\n  - Q_UNUSED\n  - QT_REQUIRE_VERSION\nTabWidth:        4\nUseTab:          Never\n...\n"
        },
        {
          "name": ".gitattributes",
          "type": "blob",
          "size": 0.044921875,
          "content": "cpp/external/mozilla-cacerts/cacert.pem binary"
        },
        {
          "name": ".gitignore",
          "type": "blob",
          "size": 0.95703125,
          "content": "*.[oa]\n*.exe\n*~\n__pycache__\n*.h5\n*.log\n*.cbp\n\ntmp*.txt\n\ncpp/write\ncpp/runtests\ncpp/example\ncpp/gtp\ncpp/gtp.log\ncpp/match\ncpp/matchcuda\ncpp/matchtensorflow\ncpp/match.log\ncpp/main\ncpp/maincuda\ncpp/mainopencl\ncpp/katago\ncpp/configs\ncpp/evalsgf\ncpp/run*.sh\ncpp/tests/scratch\ncpp/program/gitinfo.h\n\ncpp/tests/results/matchsgfs/games.sgfs\ncpp/tests/results/matchsgfs2/games.sgfs\n\ncpp/data/\nversions/\ncpp/build\ncpp/out\n\nexport_model_cuda.sh\nmixmodels.sh\nrunfindposes.sh\nruntraining.sh\nrunlztest*.sh\n\npython/upload_all*.sh\npython/count_all*.sh\n\ntmp\ntmp.txt\ntest.txt\ncpp/tmp\nout.txt\n\n# For clion IDE\n.idea\n\n# For vscode\n.vscode\n\n# For VS\n.vs\ncpp/CMakeSettings.json\n\n# For cmake\nCMakeCache.txt\nCMakeFiles/\nMakefile\ncmake_install.cmake\n\n.DS_Store\nGPATH\nGRTAGS\nGTAGS\n\ncpp/external/httplib/cpp-httplib/\ncpp/external/nlohmann_json/nlohmann_json\ngtp.cfg\nkatago_contribute/\ntmpsgf/\nwatchgame.txt\nmodels/\npython/startposesupload.txt\nfor_release/\n\ntests/results/matchsgfs/\ntests/results/matchsgfs2/"
        },
        {
          "name": "CONTRIBUTORS",
          "type": "blob",
          "size": 3.259765625,
          "content": "\nPrimary author and project maintainer (https://github.com/lightvector/KataGo):\nDavid J Wu (\"lightvector\")\n\nMany thanks to these additional authors:\nTycho Tatitscheff (\"tychota\") - for documentation and build improvements\nBernd Schmidt (\"bernds\") - for minor build improvements\nLoren Puchalla Fiore (\"lpuchallafiore\") - for a wide variety of code refactors and fixes\n\"TFiFiE\" - for minor build improvements\n\"iopq\" - for a fix to python script imports\nBrett Harrison - coauthor of part of the original game board code\nAnnie Wagner (\"featurecat\") - slight readme edits\nMartin HÃ¤cker (\"dwt\") - minor bugfix, MacOS support, commandline improvements\n\"yenw\" - simple compile fix on MacOS.\nAdrian Petrescu (\"apetresc\") - MacOS support\nAnson Hu (\"farmersrice\") - frontend features and logic\nSander Land (\"sanderland\") - many options for analysis engine, various bugfixes and other work\nAlexander Noack (\"shammyx\") - minor customization for resign logic\n\"yffbit\" - minor optimization for benson's algorithm\nMichael Reilly (\"OmnipotentEntity\") - workaround for CUDA on some cmake versions and other work\nHiraoka (\"kaorahi\") - for help optimizing Eigen backend and other work\nAkita Noek (\"anoek\") - for some minor performance and api suggestions, minor cuda work\nHarald Han - for some work on CUDNN8 support\n\"inbae\" - for removing boost filesystem dependencies, major contributions to pytorch training\n\"rimathia\" - for a minor bugfix\n\"Jonathan_Go\" - for help with client proxy support\nJonathan Roy (\"roy7\") - for various search refactors\nKensuke Matsuzaki (\"zakki\") - catching a buffer overrun bug\nKuang-che Wu (\"kcwu\") - minor improvement to distributed logging\n\"yzyray\" - minor bugfix, improvements to gtp extensions\n\"fuhaoda\" - code optimizations, testing, and other improvements\n\"y-ich\" - for GPU optimization suggestions and other minor features\nYule Hou (\"hyln9\") - For implementing TensorRT backend and various testing and work.\n\"rooklift\" - various documentation improvements\nViktor Pogrebniak (\"avtomaton\") - for improvements on the config system\nAdam Gleave - for improvements on the config system\nEmanuel-de-Jong - For minor improvement to GTP command.\n\"simon300000\" - For minor update to .gitignore.\nDave Jarvis - For improved inline documentation for GTP example config.\nYuji Ichikiwa - For a minor fix to include paths.\n\"hzyhhzy\" - For a minor fix for rules parsing.\nThaddee Tyl (\"espadrine\") - Reporting and fixing of issue with half library intrinsics.\nSebastian H (\"nerai\") - Minor code cleanup\nJochen Voss (\"seehuhn\") - Typo fix in doc\n\"kinfkong\" - Added trt build configuration option\n\"TTXS123OK\" - Minor code style improvement.\nChin-Chang Yang - For a very useful GPU backend error testing command.\n\nSeparately from the authors of the content in this repo, additional special thanks to:\nJunyan Xu (\"alreadydone\") - for much testing and troubleshooting for Windows support\n\"petgo3\" - for bugfinding and advice on supporting KGS api\n\"sbbdms\" - for much testing of cpuct and uncertainty parameters\n\"Medwin\", \"shengke\" and others - for many tests and ideas and parameters\n\"lionfenfen\", and Yi XiaoTian - For major ideas and techniques for improving neural net training in KataGo.\nReid McIlroy-Young (\"reidmcy\") - for discussion of AlphaZero and policy conditioning and optimism\n\"jaysephjw\", and \"gcmutator\" - for finding some typos."
        },
        {
          "name": "Compiling.md",
          "type": "blob",
          "size": 11.126953125,
          "content": "\n# Compiling KataGo\nKataGo is written in C++. It should compile on Linux or OSX via g++ that supports at least C++14, or on Windows via MSVC 15 (2017) and later. Other compilers and systems have not been tested yet. This is recommended if you want to run the full KataGo self-play training loop on your own and/or do your own research and experimentation, or if you want to run KataGo on an operating system for which there is no precompiled executable available.\n\n### Building for Distributed\nAs also mentioned in the instructions below but repeated here for visibility, if you also are building KataGo with the intent to use it in distributed training on https://katagotraining.org, then keep in mind:\n* You'll need to specify `-DBUILD_DISTRIBUTED=1` or `BUILD_DISTRIBUTED` and have OpenSSL installed.\n* Building will need to happen within a Git clone of the KataGo repo, rather than a zipped copy of the source (such as what you might download from a packaged release).\n* The version will need to be supported for distributed training. **The `master` branch will NOT work** - instead please use the either latest release tag or the tip of the `stable` branch, these should both work.\n* Please do NOT attempt to bypass any versioning or safety checks - if you feel you need to do so, please first reach out by opening an issue or messaging in [discord](https://discord.gg/bqkZAz3). There is an alternate site [test.katagodistributed.org](test.katagodistributed.org) you can use if you are working on KataGo development or want to test things more freely, ask in the KataGo channel of discord to set up a test account.\n\n## Linux\n   * TLDR (if you have a working GPU):\n     ```\n     git clone https://github.com/lightvector/KataGo.git\n     cd KataGo/cpp\n     # If you get missing library errors, install the appropriate packages using your system package manager and try again.\n     # -DBUILD_DISTRIBUTED=1 is only needed if you want to contribute back to public training.\n     cmake . -DUSE_BACKEND=OPENCL -DBUILD_DISTRIBUTED=1\n     make -j 4\n     ```\n   * TLDR (building the slow pure-CPU version):\n     ```\n     git clone https://github.com/lightvector/KataGo.git\n     cd KataGo/cpp\n     # If you get missing library errors, install the appropriate packages using your system package manager and try again.\n     cmake . -DUSE_BACKEND=EIGEN -DUSE_AVX2=1\n     make -j 4\n     ```\n   * Requirements\n      * CMake with a minimum version of 3.18.2 - for example `sudo apt install cmake` on Debian, or download from https://cmake.org/download/ if that doesn't give you a recent-enough version.\n      * Some version of g++ that supports at least C++14.\n      * If using the OpenCL backend, a modern GPU that supports OpenCL 1.2 or greater, or else something like [this](https://software.intel.com/en-us/opencl-sdk) for CPU. But if using CPU, Eigen should be better.\n      * If using the CUDA backend, CUDA 11 or later and a compatible version of CUDNN based on your CUDA version (https://developer.nvidia.com/cuda-toolkit) (https://developer.nvidia.com/cudnn) and a GPU capable of supporting them.\n      * If using the TensorRT backend, in addition to a compatible CUDA Toolkit (https://developer.nvidia.com/cuda-toolkit), you also need TensorRT (https://developer.nvidia.com/tensorrt) that is at least version 8.5.\n      * If using the Eigen backend, Eigen3. With Debian packages, (i.e. apt or apt-get), this should be `libeigen3-dev`.\n      * zlib, libzip. With Debian packages (i.e. apt or apt-get), these should be `zlib1g-dev`, `libzip-dev`.\n      * If you want to do self-play training and research, probably Google perftools `libgoogle-perftools-dev` for TCMalloc or some other better malloc implementation. For unknown reasons, the allocation pattern in self-play with large numbers of threads and parallel games causes a lot of memory fragmentation under glibc malloc that will eventually run your machine out of memory, but better mallocs handle it fine.\n      * If compiling to contribute to public distributed training runs, OpenSSL is required (`libssl-dev`).\n   * Clone this repo:\n      * `git clone https://github.com/lightvector/KataGo.git`\n   * Compile using CMake and make in the cpp directory:\n      * `cd KataGo/cpp`\n      * `cmake . -DUSE_BACKEND=OPENCL` or `cmake . -DUSE_BACKEND=CUDA` or `cmake . -DUSE_BACKEND=TENSORRT` or `cmake . -DUSE_BACKEND=EIGEN` depending on which backend you want.\n         * Specify also `-DUSE_TCMALLOC=1` if using TCMalloc.\n         * Compiling will also call git commands to embed the git hash into the compiled executable, specify also `-DNO_GIT_REVISION=1` to disable it if this is causing issues for you.\n         * Specify `-DUSE_AVX2=1` to also compile Eigen with AVX2 and FMA support, which will make it incompatible with old CPUs but much faster. (If you want to go further, you can also add `-DCMAKE_CXX_FLAGS='-march=native'` which will specialize to precisely your machine's CPU, but the exe might not run on other machines at all).\n         * Specify `-DBUILD_DISTRIBUTED=1` to compile with support for contributing data to public distributed training runs.\n            * If building distributed, you will also need to build with Git revision support, including building within a clone of the repo, as opposed to merely an unzipped copy of its source.\n            * Only builds from specific tagged versions or branches can contribute, in particular, instead of the `master` branch, use either the latest [release](https://github.com/lightvector/KataGo/releases) tag or the tip of the `stable` branch. To minimize the chance of any data incompatibilities or bugs, please do NOT attempt to contribute with custom changes or circumvent these limitations.\n      * `make`\n   * Done! You should now have a compiled `katago` executable in your working directory.\n   * Pre-trained neural nets are available at [the main training website](https://katagotraining.org/).\n   * You will probably want to edit `configs/gtp_example.cfg` (see \"Tuning for Performance\" above).\n   * If using OpenCL, you will want to verify that KataGo is picking up the correct device when you run it (e.g. some systems may have both an Intel CPU OpenCL and GPU OpenCL, if KataGo appears to pick the wrong one, you can correct this by specifying `openclGpuToUse` in `configs/gtp_example.cfg`).\n\n## Windows\n   * TLDR:\n      * Building from source on Windows is actually a bit tricky, depending on what version you're building, there's not necessarily a super-fast way.\n   * Requirements\n      * CMake with a minimum version of 3.18.2, GUI version strongly recommended (https://cmake.org/download/)\n      * Microsoft Visual Studio for C++. Version 15 (2017) has been tested and should work, other versions might work as well.\n      * If using the OpenCL backend, a modern GPU that supports OpenCL 1.2 or greater, or else something like [this](https://software.intel.com/en-us/opencl-sdk) for CPU. But if using CPU, Eigen should be better.\n      * If using the CUDA backend, CUDA 11 or later and a compatible version of CUDNN based on your CUDA version (https://developer.nvidia.com/cuda-toolkit) (https://developer.nvidia.com/cudnn) and a GPU capable of supporting them. I'm unsure how version compatibility works with CUDA, there's a good chance that later versions than these work just as well, but they have not been tested.\n      * If using the TensorRT backend, in addition to a compatible CUDA Toolkit (https://developer.nvidia.com/cuda-toolkit), you also need TensorRT (https://developer.nvidia.com/tensorrt) that is at least version 8.5.\n      * If using the Eigen backend, Eigen3, version 3.3.x. (http://eigen.tuxfamily.org/index.php?title=Main_Page#Download).\n      * zlib. The following package might work, https://www.nuget.org/packages/zlib-vc140-static-64/, or alternatively you can build it yourself via something like: https://github.com/kiyolee/zlib-win-build\n      * libzip (optional, needed only for self-play training) - for example https://github.com/kiyolee/libzip-win-build\n      * If compiling to contribute to public distributed training runs, OpenSSL is required (https://www.openssl.org/, https://wiki.openssl.org/index.php/Compilation_and_Installation).\n   * Download/clone this repo to some folder `KataGo`.\n   * Configure using CMake GUI and compile in MSVC:\n      * Select `KataGo/cpp` as the source code directory in [CMake GUI](https://cmake.org/runningcmake/).\n      * Set the build directory to wherever you would like the built executable to be produced.\n      * Click \"Configure\". For the generator select your MSVC version, and also select \"x64\" for the optional platform if you're on 64-bit windows, don't use win32.\n      * If you get errors where CMake has not automatically found ZLib, point it to the appropriate places according to the error messages:\n        * `ZLIB_INCLUDE_DIR` - point this to the directory containing `zlib.h` and other headers\n        * `ZLIB_LIBRARY` - point this to the `libz.lib` resulting from building zlib. Note that \"*_LIBRARY\" expects to be pointed to the \".lib\" file, whereas the \".dll\" file is the file that needs to be included with KataGo at runtime.\n      * Also set `USE_BACKEND` to `OPENCL`, or `CUDA`, or `TENSORRT`, or `EIGEN` depending on what backend you want to use.\n      * Set any other options you want and re-run \"Configure\" again as needed after setting them. Such as:\n         * `NO_GIT_REVISION` if you don't have Git or if cmake is not finding it.\n         * `NO_LIBZIP` if you don't care about running self-play training and you don't have libzip.\n         * `USE_AVX2` if you want to compile with AVX2 and FMA instructions, which will fail on some CPUs but speed up Eigen greatly on CPUs that support them.\n         * `BUILD_DISTRIBUTED` to compile with support for contributing data to public distributed training runs.\n            * If building distributed, you will also need to build with Git revision support, including building within a clone of the repo, as opposed to merely an unzipped copy of its source.\n            * Only builds from specific tagged versions or branches can contribute, in particular, instead of the `master` branch, use either the latest [release](https://github.com/lightvector/KataGo/releases) tag or the tip of the `stable` branch. To minimize the chance of any data incompatibilities or bugs, please do NOT attempt to contribute with custom changes or circumvent these limitations.\n      * Once running \"Configure\" looks good, run \"Generate\" and then open MSVC and build as normal in MSVC.\n   * Done! You should now have a compiled `katago.exe` executable in your working directory.\n   * Note: You may need to copy the \".dll\" files corresponding to the various \".lib\" files you compiled with into the directory containing katago.exe.\n   * Note: If you had to update or install CUDA or GPU drivers, you will likely need to reboot before they will work.\n   * Pre-trained neural nets are available at [the main training website](https://katagotraining.org/).\n   * You will probably want to edit `configs/gtp_example.cfg` (see \"Tuning for Performance\" above).\n   * If using OpenCL, you will want to verify that KataGo is picking up the correct device (e.g. some systems may have both an Intel CPU OpenCL and GPU OpenCL, if KataGo appears to pick the wrong one, you can correct this by specifying `openclGpuToUse` in `configs/gtp_example.cfg`).\n"
        },
        {
          "name": "LICENSE",
          "type": "blob",
          "size": 2.1796875,
          "content": "The code in this repository currently relies on several other libraries, parts of libraries,\nor external files: clblast, filesystem-1.5.8, half-2.1.0, httplib, mozilla-cacerts,\nnlohmann_json, sgfmill, and tclap-1.2.2. For the licenses for those libraries and/or files, see the\nindividual readmes and/or license files for each one within their respective subdirectories within\ncpp/external. Additionally, cpp/core/sha2.cpp derives from another piece of external code\nand embeds its own license within that file.\n\nAside from the above, the license for all OTHER content in this repo is as follows:\n\n----------------------------------------\n\nCopyright 2019 David J Wu (\"lightvector\") and/or other authors of the content in this repository.\n(See 'CONTRIBUTORS' file for a list of authors as well as other indirect contributors).\n\nPermission is hereby granted, free of charge, to any person obtaining a copy of this software and\nassociated documentation files (the \"Software\"), to deal in the Software without restriction,\nincluding without limitation the rights to use, copy, modify, merge, publish, distribute,\nsublicense, and/or sell copies of the Software, and to permit persons to whom the Software is\nfurnished to do so, subject to the following conditions:\n\nThe above copyright notice and this permission notice shall be included in all copies or\nsubstantial portions of the Software.\n\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT\nNOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND\nNONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM,\nDAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.\n\n----------------------------------------\n\nAdditional disclaimer from David J Wu (\"lightvector\") regarding the above license and KataGo's\nrepository (https://github.com/lightvector/KataGo):\nI am providing code in the repository to you under an open source license. Because this is my\npersonal repository, the license you receive to my code is from me, and not my employer (Facebook)."
        },
        {
          "name": "README.md",
          "type": "blob",
          "size": 27.9169921875,
          "content": "# KataGo\n\n* [Overview](#overview)\n* [Training History and Research](#training-history-and-research)\n* [Where To Download Stuff](#where-to-download-stuff)\n* [Setting Up and Running KataGo](#setting-up-and-running-katago)\n  * [GUIs](#guis)\n  * [Windows and Linux](#windows-and-linux)\n  * [MacOS](#macos)\n  * [OpenCL vs CUDA vs TensorRT vs Eigen](#opencl-vs-cuda-vs-tensorrt-vs-eigen)\n  * [How To Use](#how-to-use)\n  * [Tuning for Performance](#tuning-for-performance)\n  * [Common Questions and Issues](#common-questions-and-issues)\n    * [Issues with specific GPUs or GPU drivers](#issues-with-specific-gpus-or-gpu-drivers)\n    * [Common Problems](#common-problems)\n    * [Other Questions](#other-questions)\n* [Features for Developers](#features-for-developers)\n  * [GTP Extensions](#gtp-extensions)\n  * [Analysis Engine](#analysis-engine)\n* [Compiling KataGo](#compiling-katago)\n* [Source Code Overview](#source-code-overview)\n* [Selfplay Training](#selfplay-training)\n* [Contributors](#contributors)\n* [License](#license)\n\n## Overview\n\nKataGo's public distributed training run is ongoing! See https://katagotraining.org/ for more details, to download the latest and strongest neural nets, or to learn how to contribute if you want to help KataGo improve further! Also check out the computer Go [discord channel](https://discord.gg/bqkZAz3)!\n\nAs of 2024, KataGo remains one of the strongest open source Go bots available online. KataGo was trained using an AlphaZero-like process with many enhancements and improvements, and is capable of reaching top levels rapidly and entirely from scratch with no outside data, improving only via self-play. Some of these improvements take advantage of game-specific features and training targets, but also many of the techniques are general and could be applied in other games. As a result, early training is immensely faster than in other self-play-trained bots - with only a few strong GPUs for a few days, any researcher/enthusiast should be able to train a neural net from nothing to high amateur dan strength on the full 19x19 board. If tuned well, a training run using only a *single* top-end consumer GPU could possibly train a bot from scratch to superhuman strength within a few months.\n\nExperimentally, KataGo did also try some limited ways of using external data at the end of its June 2020 run, and has continued to do so into its most recent public distributed run, \"kata1\" at https://katagotraining.org/. External data is not necessary for reaching top levels of play, but still appears to provide some mild benefits against some opponents, and noticeable benefits in a useful analysis tool for a variety of kinds of situations that don't occur in self-play but that do occur in human games and  games that users wish to analyze.\n\nKataGo's engine aims to be a useful tool for Go players and developers, and supports the following features:\n* Estimates territory and score, rather than only \"winrate\", helping analyze kyu and amateur dan games besides only on moves that actually would swing the game outcome at pro/superhuman-levels of play.\n* Cares about maximizing score, enabling strong play in handicap games when far behind, and reducing slack play in the endgame when winning.\n* Supports alternative values of komi (including integer values) and good high-handicap game play.\n* Supports board sizes ranging from 7x7 to 19x19, and as of May 2020 may be the strongest open-source bot on both 9x9 and 13x13 as well.\n* Supports a wide variety of [rules](https://lightvector.github.io/KataGo/rules.html), including rules that match Japanese rules in almost all common cases, and ancient stone-counting-like rules.\n* For tool/back-end developers - supports a JSON-based analysis engine that can batch multiple-game evaluations efficiently and be easier to use than GTP.\n\n## Training History and Research and Docs\n\nHere are some links to some docs/papers/posts about KataGo's research and training!\n\n* Paper about the major new ideas and techniques used in KataGo: [Accelerating Self-Play Learning in Go (arXiv)](https://arxiv.org/abs/1902.10565). Many of the specific parameters are outdated, but the general methods continue to be used.\n\n* Many major further improvements have been found since then, which have been incorporated into KataGo's more recent runs and are documented here: [KataGoMethods.md](docs/KataGoMethods.md).\n\n* KataGo has a fully working implementation of Monte-Carlo Graph Search, extending MCTS to operate on graphs instead of just trees! An explanation can be found here [Monte-Carlo Graph Search from First Principles](docs/GraphSearch.md). This explanation is written to be general (not specific to KataGo) and to fill a big gap in explanatory material in the academic literature and hopefully it can be useful to others!\n\n* Many thanks to [Jane Street](https://www.janestreet.com/) for supporting the training of KataGo's major earlier published runs, as well as numerous many smaller testing runs and experiments. Blog posts about the initial release and some interesting subsequent experiments:\n    * [Accelerating Self-Play Learning in Go](https://blog.janestreet.com/accelerating-self-play-learning-in-go/)\n    * [Deep-Learning the Hardest Go Problem in the World](https://blog.janestreet.com/deep-learning-the-hardest-go-problem-in-the-world/).\n\nFor more details about KataGo's older training runs, including comparisons to other bots, see [Older Training History and Research](TrainingHistory.md)!\n\nAlso if you're looking to ask about general information about KataGo or how it works, or about some past Go bots besides KataGo, consider the computer Go [discord channel](https://discord.gg/bqkZAz3).\n\n## Where To Download Stuff\nPrecompiled executables for KataGo can be found at the [releases page](https://github.com/lightvector/KataGo/releases) for Windows and Linux.\n\nAnd the latest neural nets are available at [https://katagotraining.org/](https://katagotraining.org/).\n\n## Setting Up and Running KataGo\nKataGo implements just a GTP engine, which is a simple text protocol that Go software uses. It does NOT have a graphical interface on its own. So generally, you will want to use KataGo along with a GUI or analysis program. A few of them bundle KataGo in their download so that you can get everything from one place rather than downloading separately and managing the file paths and commands.\n\n### GUIs\nThis is by no means a complete list - there are lots of things out there. But, writing as of 2020, a few of the easier and/or popular ones might be:\n\n* [KaTrain](https://github.com/sanderland/katrain) - KaTrain might be the easiest to set up for non-technical users, offering an all-in-one package (no need to download KataGo separately!), modified-strength bots for weaker players, and good analysis features.\n* [Lizzie](https://github.com/featurecat/lizzie) - Lizzie is very popular for running long interactive analyses and visualizing them as they happen. Lizzie also offers an all-in-one package. However keep mind that KataGo's OpenCL version may take quite a while to tune and load on the very first startup as described [here](#opencl-vs-cuda), and Lizzie does a poor job of displaying this progress as it happens. And in case of an actual error or failure, Lizzie's interface is not the best at explaining these errors and will appear to hang forever. The version of KataGo packaged with Lizzie is quite strong but might not always be the newest or strongest, so once you have it working, you may want to download KataGo and a newer network from [releases page](https://github.com/lightvector/KataGo/releases) and replace Lizzie's versions with them.\n* [Ogatak](https://github.com/rooklift/ogatak) is a KataGo-specific GUI with an emphasis on displaying the basics in a snappy, responsive fashion. It does not come with KataGo included.\n* [q5Go](https://github.com/bernds/q5Go) and [Sabaki](https://sabaki.yichuanshen.de/) are general SGF editors and GUIs that support KataGo, including KataGo's score estimation, and many high-quality features.\n\nGenerally, for GUIs that don't offer an all-in-one package, you will need to download KataGo (or any other Go engine of your choice!) and tell the GUI the proper command line to run to invoke your engine, with the proper file paths involved. See [How To Use](#how-to-use) below for details on KataGo's command line interface.\n\n### Windows and Linux\n\nKataGo currently officially supports both Windows and Linux, with [precompiled executables provided each release](https://github.com/lightvector/KataGo/releases). On Windows, the executables should generally work out of the box, on Linux if you encounter issues with system library versions, as an alternative [building from source](Compiling.md) is usually straightforward. Not all different OS versions and compilers have been tested, so if you encounter problems, feel free to open an issue. KataGo can also of course be compiled from source on Windows via MSVC on Windows or on Linux via usual compilers like g++, documented further down.\n\n### MacOS\nThe community also provides KataGo packages for [Homebrew](https://brew.sh) on MacOS - releases there may lag behind official releases slightly.\n\nUse `brew install katago`. The latest config files and networks are installed in KataGo's `share` directory. Find them via `brew list --verbose katago`. A basic way to run katago will be `katago gtp -config $(brew list --verbose katago | grep 'gtp.*\\.cfg') -model $(brew list --verbose katago | grep .gz | head -1)`. You should choose the Network according to the release notes here and customize the provided example config as with every other way of installing KataGo.\n\n### OpenCL vs CUDA vs TensorRT vs Eigen\nKataGo has four backends, OpenCL (GPU), CUDA (GPU), TensorRT (GPU), and Eigen (CPU).\n\nThe quick summary is:\n  * **To easily get something working, try OpenCL if you have any good or decent GPU.**\n  * **For often much better performance on NVIDIA GPUs, try TensorRT**, but you may need to install TensorRT from Nvidia.\n  * Use Eigen with AVX2 if you don't have a GPU or if your GPU is too old/weak to work with OpenCL, and you just want a plain CPU KataGo.\n  * Use Eigen without AVX2 if your CPU is old or on a low-end device that doesn't support AVX2.\n  * The CUDA backend can work for NVIDIA GPUs with CUDA+CUDNN installed but is likely worse than TensorRT.\n\nMore in detail:\n  * OpenCL is a general GPU backend should be able to run with any GPUs or accelerators that support [OpenCL](https://en.wikipedia.org/wiki/OpenCL), including NVIDIA GPUs, AMD GPUs, as well CPU-based OpenCL implementations or things like Intel Integrated Graphics. This is the most general GPU version of KataGo and doesn't require a complicated install like CUDA does, so is most likely to work out of the box as long as you have a fairly modern GPU. **However, it also need to take some time when run for the very first time to tune itself.** For many systems, this will take 5-30 seconds, but on a few older/slower systems, may take many minutes or longer. Also, the quality of OpenCL implementations is sometimes inconsistent, particularly for Intel Integrated Graphics and for AMD GPUs that are older than several years, so it might not work for very old machines, as well as specific buggy newer AMD GPUs, see also [Issues with specific GPUs or GPU drivers](#issues-with-specific-gpus-or-gpu-drivers).\n  * CUDA is a GPU backend specific to NVIDIA GPUs (it will not work with AMD or Intel or any other GPUs) and requires installing [CUDA](https://developer.nvidia.com/cuda-zone) and [CUDNN](https://developer.nvidia.com/cudnn) and a modern NVIDIA GPU. On most GPUs, the OpenCL implementation will actually beat NVIDIA's own CUDA/CUDNN at performance. The exception is for top-end NVIDIA GPUs that support FP16 and tensor cores, in which case sometimes one is better and sometimes the other is better.\n  * TensorRT is similar to CUDA, but only uses NVIDIA's TensorRT framework to run the neural network with more optimized kernels. For modern NVIDIA GPUs, it should work whenever CUDA does and will usually be faster than CUDA or any other backend.\n  * Eigen is a *CPU* backend that should work widely *without* needing a GPU or fancy drivers. Use this if you don't have a good GPU or really any GPU at all. It will be quite significantly slower than OpenCL or CUDA, but on a good CPU can still often get 10 to 20 playouts per second if using the smaller (15 or 20) block neural nets. Eigen can also be compiled with AVX2 and FMA support, which can provide a big performance boost for Intel and AMD CPUs from the last few years. However, it will not run at all on older CPUs (and possibly even some recent but low-power modern CPUs) that don't support these fancy vector instructions.\n\nFor **any** implementation, it's recommended that you also tune the number of threads used if you care about optimal performance, as it can make a factor of 2-3 difference in the speed. See \"Tuning for Performance\" below. However, if you mostly just want to get it working, then the default untuned settings should also be still reasonable.\n\n### How To Use\nKataGo is just an engine and does not have its own graphical interface. So generally you will want to use KataGo along with a [GUI or analysis program](#guis).\nIf you encounter any problems while setting this up, check out [Common Questions and Issues](#common-questions-and-issues).\n\n**First**: Run a command like this to make sure KataGo is working, with the neural net file you [downloaded](https://github.com/lightvector/KataGo/releases/tag/v1.4.5). On OpenCL, it will also tune for your GPU.\n```\n./katago.exe benchmark                                                   # if you have default_gtp.cfg and default_model.bin.gz\n./katago.exe benchmark -model <NEURALNET>.bin.gz                         # if you have default_gtp.cfg\n./katago.exe benchmark -model <NEURALNET>.bin.gz -config gtp_custom.cfg  # use this .bin.gz neural net and this .cfg file\n```\nIt will tell you a good number of threads. Edit your .cfg file and set \"numSearchThreads\" to that many to get best performance.\n\n**Or**: Run this command to have KataGo generate a custom gtp config for you based on answering some questions:\n```\n./katago.exe genconfig -model <NEURALNET>.bin.gz -output gtp_custom.cfg\n```\n\n**Next**: A command like this will run KataGo's engine. This is the command to give to your [GUI or analysis program](#guis) so that it can run KataGo.\n```\n./katago.exe gtp                                                   # if you have default_gtp.cfg and default_model.bin.gz\n./katago.exe gtp -model <NEURALNET>.bin.gz                         # if you have default_gtp.cfg\n./katago.exe gtp -model <NEURALNET>.bin.gz -config gtp_custom.cfg  # use this .bin.gz neural net and this .cfg file\n```\n\nYou may need to specify different paths when entering KataGo's command for a GUI program, e.g.:\n```\npath/to/katago.exe gtp -model path/to/<NEURALNET>.bin.gz\npath/to/katago.exe gtp -model path/to/<NEURALNET>.bin.gz -config path/to/gtp_custom.cfg\n```\n\n#### Human-style Play and Analysis\n\nYou can also have KataGo imitate human play if you download the human SL model b18c384nbt-humanv0.bin.gz from https://github.com/lightvector/KataGo/releases/tag/v1.15.0, and run a command like the following, providing both the normal model and the human SL model:\n```\n./katago.exe gtp -model <NEURALNET>.bin.gz -human-model b18c384nbt-humanv0.bin.gz -config gtp_human5k_example.cfg\n```\n\nThe [gtp_human5k_example.cfg](cpp/configs/gtp_human5k_example.cfg) configures KataGo to imitate 5-kyu-level players. You can change it to imitate other ranks too, as well as to do many more things, including making KataGo play in a human style but still at a strong level or analyze in interesting ways. Read the config file itself for documentation on some of these possibilities!\n\nAnd see also [this guide](https://github.com/lightvector/KataGo/blob/master/docs/Analysis_Engine.md#human-sl-analysis-guide) to using the human SL model, which is written from the perspective of the JSON-based analysis engine mentioned below, but is also applicable to gtp as well.\n\n#### Other Commands:\n\nRun a JSON-based [analysis engine](docs/Analysis_Engine.md) that can do efficient batched evaluations for a backend Go service:\n\n   * `./katago analysis -model <NEURALNET>.gz -config <ANALYSIS_CONFIG>.cfg`\n\nRun a high-performance match engine that will play a pool of bots against each other sharing the same GPU batches and CPUs with each other:\n\n   * `./katago match -config <MATCH_CONFIG>.cfg -log-file match.log -sgf-output-dir <DIR TO WRITE THE SGFS>`\n\nForce OpenCL tuner to re-tune:\n\n   * `./katago tuner -config <GTP_CONFIG>.cfg`\n\nPrint version:\n\n   * `./katago version`\n\n\n### Tuning for Performance\n\nThe most important parameter to optimize for KataGo's performance is the number of threads to use - this can easily make a factor of 2 or 3 difference.\n\nSecondarily, you can also read over the parameters in your GTP config (`default_gtp.cfg` or `gtp_example.cfg` or `configs/gtp_example.cfg`, etc). A lot of other settings are described in there that you can set to adjust KataGo's resource usage, or choose which GPUs to use. You can also adjust things like KataGo's resign threshold, pondering behavior or utility function. Most parameters are documented directly inline in the [example config file](cpp/configs/gtp_example.cfg). Many can also be interactively set when generating a config via the `genconfig` command described above.\n\n\n### Common Questions and Issues\nThis section summarizes a number of common questions and issues when running KataGo.\n\n#### Issues with specific GPUs or GPU drivers\nIf you are observing any crashes in KataGo while attempting to run the benchmark or the program itself, and you have one of the below GPUs, then this is likely the reason.\n\n* **AMD Radeon RX 5700** - AMD's drivers for OpenCL for this GPU have been buggy ever since this GPU was released, and as of May 2020 AMD has still never released a fix. If you are using this GPU, you will just not be able to run KataGo (Leela Zero and other Go engines will probably fail too) and will probably also obtain incorrect calculations or crash if doing anything else scientific or mathematical that uses OpenCL. See for example these reddit threads: [[1]](https://www.reddit.com/r/Amd/comments/ebso1x/its_not_just_setihome_any_mathematic_or/) or [[2]](https://www.reddit.com/r/BOINC/comments/ebiz18/psa_please_remove_your_amd_rx5700xt_from_setihome/) or this [L19 thread](https://lifein19x19.com/viewtopic.php?f=18&t=17093).\n* **OpenCL Mesa** - These drivers for OpenCL are buggy. Particularly if on startup before crashing you see KataGo printing something like\n`Found OpenCL Platform 0: ... (Mesa) (OpenCL 1.1 Mesa ...) ...`\nthen you are using the Mesa drivers. You will need to change your drivers, see for example this [KataGo issue](https://github.com/lightvector/KataGo/issues/182#issuecomment-607943405) which links to [this thread](https://bbs.archlinux.org/viewtopic.php?pid=1895516#p1895516).\n* **Intel Integrated Graphics** - For weaker/older machines or laptops or devices that don't have a dedicated GPU, KataGo might end up using the weak \"Intel Integrated Graphics\" that is built in with the CPU. Often this will work fine (although KataGo will be slow and only get a tiny number of playouts compared to using a real GPU), but various versions of Intel Integrated Graphics can also be buggy and not work at all. If a driver update doesn't work for you, then the only solution is to upgrade to a better GPU. See for example this [issue](https://github.com/lightvector/KataGo/issues/54) or this [issue](https://github.com/lightvector/KataGo/issues/78), or this [other Github's issue](https://github.com/CNugteren/CLBlast/issues/280).\n\n#### Common Problems\n* **KataGo seems to hang or is \"loading\" forever on startup in Lizzie/Sabaki/q5go/GoReviewPartner/etc.**\n   * Likely either you have some misconfiguration, have specified file paths incorrectly, a bad GPU, etc. Many of these GUIs do a poor job of reporting errors and may completely swallow the error message from KataGo that would have told you what was wrong. Try running KataGo's `benchmark` or `gtp` directly on the command line, as described [above](#how-to-use).\n   * Sometimes there is no error at all, it is merely that the *first* time KataGo runs on a given network size, it needs to do some expensive tuning, which may take a few minutes. Again this is clearer if you run the `benchmark` command directly in the command line. After tuning, then subsequent runs will be faster.\n\n* **KataGo works on the command line but having trouble specifying the right file paths for the GUI.**\n   * As described [above](#how-to-use), you can name your config `default_gtp.cfg` and name whichever network file you've downloaded to `default_model.bin.gz` (for newer `.bin.gz` models) or `default_model.txt.gz` (for older `.txt.gz` models). Stick those into the same directory as KataGo's executable, and then you don't need to specify `-config` or `-model` paths at all.\n\n* **KataGo gives an error like `Could not create file` when trying to run the initial tuning.**\n   * KataGo probably does not have access permissions to write files in the directory where you placed it.\n   * On Windows for example, the `Program Files` directory and its subdirectories are often restricted to only allow writes with admin-level permissions. Try placing KataGo somewhere else.\n\n* **I'm new to the command line and still having trouble knowing what to tell Lizzie/q5go/Sabaki/whatever to make it run KataGo**.\n   * Again, make sure you have your directory paths right.\n   * A common issue: AVOID having any spaces in any file or directory names anywhere, since depending on the GUI, this may require you to have to quote or character-escape the paths or arguments in various ways.\n   * If you don't understand command line arguments and flags, relative vs absolute file paths, etc, search online. Try pages like https://superuser.com/questions/1270591/how-to-use-relative-paths-on-windows-cmd or https://www.bleepingcomputer.com/tutorials/understanding-command-line-arguments-and-how-to-use-them/ or other pages you find, or get someone tech-savvy to help you in a chat or even in-person if you can.\n   * Consider using https://github.com/sanderland/katrain instead - this is an excellent GUI written by someone else for KataGo that usually automates all of the technical setup for you.\n\n* **I'm getting a different error or still want further help.**\n   * Check out [the discord chat where Leela Zero, KataGo, and other bots hang out](https://discord.gg/bqkZAz3) and ask in the \"#help\" channel.\n   * If you think you've found a bug in KataGo itself, feel free also to [open an issue](https://github.com/lightvector/KataGo/issues). Please provide as much detail as possible about the exact commands you ran, the full error message and output (if you're in a GUI, please make sure to check that GUI's raw GTP console or log), the things you've tried, your config file and network, your GPU and operating system, etc.\n\n#### Other Questions\n* **How do I make KataGo use Japanese rules or other rules?**\n   * KataGo supports some [GTP extensions](docs/GTP_Extensions.md) for developers of GUIs to set the rules, but unfortunately as of June 2020, only a few of them make use of this. So as a workaround, there are a few ways:\n     * Edit KataGo's config (`default_gtp.cfg` or `gtp_example.cfg` or `gtp.cfg`, or whatever you've named it) to use `rules=japanese` or `rules=chinese` or whatever you need, or set the individual rules `koRule`,`scoringRule`,`taxRule`, etc. to what they should be. See [here](https://github.com/lightvector/KataGo/blob/master/cpp/configs/gtp_example.cfg#L91) for where this is in the config, or and see [this webpage](https://lightvector.github.io/KataGo/rules.html) for the full description of KataGo's ruleset.\n     * Use the `genconfig` command (`./katago genconfig -model <NEURALNET>.gz -output <PATH_TO_SAVE_GTP_CONFIG>.cfg`) to generate a config, and it will interactively help you, including asking you for what default rules you want.\n     * If your GUI allows access directly to the GTP console (for example, press `E` in Lizzie), then you can run `kata-set-rules japanese` or similar for other rules directly in the GTP console, to change the rules dynamically in the middle of a game or an analysis session.\n\n* **Which model/network should I use?**\n   * Generally, use the strongest or most recent b18-sized net (b18c384nbt) from [the main training site](https://katagotraining.org/). This will be the best neural net even for weaker machines, since despite being a bit slower than old smaller nets, it is much stronger and more accurate per evaluation.\n   * If you care a lot about theoretical purity - no outside data, bot learns strictly on its own - use the 20 or 40 block nets from [this release](https://github.com/lightvector/KataGo/releases/tag/v1.4.0), which are pure in this way and still much stronger than Leela Zero, but also much weaker than more recent nets.\n   * If you want some nets that are much faster to run, and each with their own interesting style of play due to their unique stages of learning, try any of the \"b10c128\" or \"b15c192\" Extended Training Nets [here](https://katagoarchive.org/g170/neuralnets/index.html) which are 10 block and 15 block networks from earlier in the run that are much weaker but still pro-level-and-beyond.\n\n\n## Features for Developers\n\n#### GTP Extensions:\nIn addition to a basic set of [GTP commands](https://www.lysator.liu.se/~gunnar/gtp/), KataGo supports a few additional commands, for use with analysis tools and other programs.\n\nKataGo's GTP extensions are documented **[here](docs/GTP_Extensions.md)**.\n\n   * Notably: KataGo exposes a GTP command `kata-analyze` that in addition to policy and winrate, also reports an estimate of the *expected score* and a heatmap of the predicted territory ownership of every location of the board. Expected score should be particularly useful for reviewing handicap games or games of weaker players. Whereas the winrate for black will often remain pinned at nearly 100% in a handicap game even as black makes major mistakes (until finally the game becomes very close), expected score should make it more clear which earlier moves are losing points that allow white to catch up, and exactly how much or little those mistakes lose. If you're interested in adding support for this to any analysis tool, feel free to reach out, I'd be happy to answer questions and help.\n\n   * KataGo also exposes a few GTP extensions that allow setting what rules are in effect (Chinese, AGA, Japanese, etc). See again [here](docs/GTP_Extensions.md) for details.\n\n#### Analysis Engine:\nKataGo also implements a separate engine that can evaluate much faster due to batching if you want to analyze whole games at once and might be much less of a hassle than GTP if you are working in an environment where JSON parsing is easy. See [here](docs/Analysis_Engine.md) for details.\n\nKataGo also includes example code demonstrating how you can invoke the analysis engine from Python, see [here](python/query_analysis_engine_example.py)!\n\n## Compiling KataGo\nKataGo is written in C++. It should compile on Linux or OSX via g++ that supports at least C++14, or on Windows via MSVC 15 (2017) and later. Instructions may be found at [Compiling KataGo](Compiling.md).\n\n## Source Code Overview:\nSee the [cpp readme](cpp/README.md) or the [python readme](python/README.md) for some high-level overviews of the source code in this repo, if you want to get a sense of what is where and how it fits together.\n\n## Selfplay Training:\nIf you'd also like to run the full self-play loop and train your own neural nets using the code here, see [Selfplay Training](SelfplayTraining.md).\n\n## Contributors\n\nMany thanks to the various people who have contributed to this project! See [CONTRIBUTORS](CONTRIBUTORS) for a list of contributors.\n\n## License\n\nExcept for several external libraries that have been included together in this repo under `cpp/external/` as well as the single file `cpp/core/sha2.cpp`, which all have their own individual licenses, all code and other content in this repo is released for free use or modification under the license in the following file: [LICENSE](LICENSE).\n\nLicense aside, if you end up using any of the code in this repo to do any of your own cool new self-play or neural net training experiments, I (lightvector) would to love hear about it.\n"
        },
        {
          "name": "SelfplayTraining.md",
          "type": "blob",
          "size": 15.25390625,
          "content": "\n## Selfplay Training:\nIf you'd also like to run the full self-play loop and train your own neural nets, in addition to probably wanting to [compile KataGo yourself](https://github.com/lightvector/KataGo#compiling-katago), you must have [Python3](https://www.python.org/) and [Pytorch](https://pytorch.org/) installed. You'll also probably need a decent amount of GPU power.\n\nThere are 5 things that need to all run to form a closed self-play training loop.\n   * Selfplay engine (C++ - `cpp/katago selfplay`) - continuously plays games using the latest neural net in some directory of accepted models, writing the data to some directory.\n   * Shuffler (python - `python/shuffle.py`) - scans directories of data from selfplay and shuffles it to produce TFRecord files to write to some directory.\n   * Training (python - `python/train.py`) - continuously trains a neural net using TFRecord files from some directory, saving models periodically to some directory.\n   * Exporter (python - `python/export_model.py`) - scans a directory of saved models and converts from Tensorflow's format to the format that all the C++ uses, exporting to some directory.\n   * Gatekeeper (C++ - `cpp/katago gatekeeper`) - polls a directory of newly exported models, plays games against the latest model in an accepted models directory, and if the new model passes, moves it to the accepted models directory. OPTIONAL, it is also possible to train just accepting every new model.\n\n### Simple One-Machine Synchronous Training\nAlthough for large-scale runs, KataGo is designed to run asynchronously across many machines for smaller runs it's also possible to run KataGo synchronously on a single machine. An example script is provided in [python/selfplay/synchronous_loop.sh](python/selfplay/synchronous_loop.sh) for how to do this. It loops around, running each of the 5 above steps sequentially. Notably, it passes some extra arguments to each different piece so that it quits rather than runs indefinitely as in asynchronous training:\n\n  * Selfplay engine - Sets `-max-games-total` to the selfplay so it terminates after a certain number of games.\n  * Shuffler - Sets smaller values of `-keep-target-rows` for the shuffler to reduce the data per cycle.\n  * Training - Sets `-stop-when-train-bucket-limited` for the training to terminate if it has taken too many steps given the amount of new data instead of waiting for more data.\n  * Exporter - Only runs it one-shot each cycle of the loop rather than polling forever as in the asynchronous script `python/selfplay/shuffle_and_export_loop.sh`.\n  * Gatekeeper - If being used at all, has `-quit-if-no-nets-to-test` so that it terminates after gatekeeping any nets produced by training.\n\n**You probably want to read the comments and edit the parameters in python/selfplay/synchronous_loop.sh and in the selfplay and gatekeeper .cfg files that it points to, to set the board size, the number of parallel threads or other computational parameters, etc.**\n\nNote that not using gating (passing in 0 for `USEGATING` on `python/selfplay/synchronous_loop.sh`) will be faster and will save compute power, and the whole loop works perfectly fine without it, but having it at first can be nice to help debugging and make sure that things are working and that the net is actually getting stronger.\n\nThe default parameters in the example synchronous loop script are NOT heavily tested, and unlike the asynchronous setup, have NOT been used for KataGo's primary training runs, so it is quite possible that they are suboptimal, and will need some experimentation. The right parameters may also vary depending on what you're training - for example a 9x9-only run may prefer a different number of samples and windowing policy than 19x19, etc.\n\nThe default parameters are also deliberately set to be probably suboptimally/inefficiently small in terms of the amount of work done each cycle of the loop, so as to make cycles of the loop faster while you're trying to get set up and make sure everything is working. You may want to increase these values once things are working and/or a run is mature and successive models are changing by less, depending on what you're doing.\n\n### Asynchronous training\nFor KataGo's official runs, normally all 5 steps above run simultaneously and _asynchronously_ without ever stopping. Selfplay continuously produces data and polls for new nets, shuffle repeatedly takes the data and shuffles it, training continuously uses the data to produce new nets, etc. This is the most efficient method if using more than one machine in the training loop, since different processes can simply just keep running on their own machine without waiting for steps on any other. To do so, simply just start up each separate process as described above, each one on an appropriate machine, each one using the same base directory. It's expected that this base directory resides on a fast networked file system shared between all machines.\n\nIt's recommended to be spending anywhere from 4x to 40x more GPU power on the selfplay than on the training. For the normal asynchronous setup, this is done by simply using more and/or stronger GPUs on the selfplay processes than on training. For synchronous, this can be done by playing around with the various parameters (number of games, visits per move, samples per epoch, etc) and seeing how long each step takes, to find a good balance for your hardware. Note however that very early in a run may be misleading for timing these steps though, since with early barely-better-than-random nets games will last a lot longer than a little further into a run.\n\nOn the cloud, a reasonable small-scale setup for all these things might be:\n   * A machine with a decent amount of cores and memory to run the shuffler and exporter.\n   * A machine with one or two powerful GPUs and a lot of cpus and memory to run the selfplay engine.\n   * A machine with a medium GPU and a lot of cpus and memory to run the gatekeeper. (optional, useful for early testing but not needed)\n   * A machine with a modest GPU to run the training.\n   * A well-performing shared filesystem accessible by all four of these machines.\n\nYou may need to play with learning rates, batch sizes, and the balance between training and self-play. If you allocate too much GPU power to training, it will end up waiting a lot of the time for more data to fill the train bucket so it can resume training. Overshooting the other way and having too much GPU power on self-play will result in training being unable to keep up with your configured `-max-train-bucket-per-new-data`, which is fine, but probably means that you should switch more GPU power to training so that it can keep up.\n\nExample instructions to start up these things (assuming you have appropriate machines set up), with some base directory $BASEDIR to hold the all the models and training data generated with a few hundred GB of disk space. The below commands assume you're running from the root of the repo and that you can run bash scripts.\n   * **Selfplay engine:** `cpp/katago selfplay -output-dir $BASEDIR/selfplay -models-dir $BASEDIR/models -config cpp/configs/training/SELFPLAYCONFIG.cfg >> log.txt 2>&1 & disown`\n     * Some example configs for different numbers of GPUs are: cpp/configs/training/selfplay*.cfg. See [cpp/configs/training/README.md](cpp/configs/training/README.md) for some notes about what the configs are. You may want to copy and edit them depending on your specs - for example to change the sizes of various tables depending on how much memory you have, or to specify gpu indices if you're doing things like putting some mix of training, gatekeeper, and self-play on the same machines or GPUs instead of on separate ones. Note that the number of game threads in these configs is very large, probably far larger than the number of cores on your machine. This is intentional, as each thread only currently runs synchronously with respect to neural net queries, so a large number of parallel games is needed to take advantage of batching.\n     * Take a look at the generated `log.txt` for any errors and/or for running stats on started games and occasional neural net query stats.\n     * Edit the config to change the number of playouts used or other parameters, or to set a cap on the number of games generated after which selfplay should terminate.\n     * If `models-dir` is empty, selfplay will use a random number generator instead to produce data, so selfplay is the **starting point** of setting up the full closed loop.\n     * Multiple selfplays across many machines can coexist using the same output dirs on a shared filesystem. Having multiple instances running all pointing to the same directory, ne per machine, is the intended way to run selfplay across a cluster and make use of multiple machines.\n   * **Shuffler and exporter:** `cd python; ./selfplay/shuffle_and_export_loop.sh $NAMEOFRUN $BASEDIR/ $SCRATCH_DIRECTORY $NUM_THREADS $BATCH_SIZE $USE_GATING`\n     * `$NAMEOFRUN` should be a short alphanumeric string that ideally should be globally unique, to distinguish models from your run if you choose to share your results with others. It will get prefixed on to the internal names of exported models, which will appear in log messages when KataGo loads the model.\n     * This starts both the shuffler and exporter. The shuffler will use the scratch directory with the specified number of threads to shuffle in parallel. Make sure you have some disk space. You probably want as many threads as you have cores. If not using the gatekeeper, specify `0` for `$USE_GATING`, else specify `1`.\n     * KataGo uses a batch size of 256, but you might have to use a smaller batch size if your GPU has less memory or you are training a very big net.\n     * Also, if you're low on disk space, take a look also at the `./selfplay/shuffle.sh` script (which is called by `shuffle_and_export_loop.sh`). Right now it's *very* conservative about cleaning up old shuffles so that it doesn't accidentally delete a shuffle that the training is still reading from, but you could tweak it to be a bit more aggressive.\n     * You can also edit `./selfplay/shuffle.sh` if you want to change any details about the lookback window for training data, see `shuffle.py` for more possible arguments.\n     * The loop script will output `$BASEDIR/logs/outshuffle.txt` and `$BASEDIR/logs/outexport.txt`, take a look at these to see the output of the shuffle program and/or any errors it encountered.\n     * Run `python ./shuffle.py -help` to for information about how the window size is computed, if you want to adjust window size parameters.\n   * **Training:** `cd python; ./selfplay/train.sh $BASEDIR/ $TRAININGNAME b6c96 $BATCH_SIZE main -lr-scale 1.0 -max-train-bucket-per-new-data 4 -max-train-bucket-size 5000000 -no-repeat-files >> log.txt 2>&1 & disown`\n     * This starts the training. You may want to look at or edit the train.sh script, it also snapshots the state of the repo for logging, as well as contains some training parameters that can be tweaked.\n     * `$TRAININGNAME` is a name prefix for the neural net, whose name will follow the convention `$NAMEOFRUN-$TRAININGNAME-s(# of samples trained on)-d(# of data samples generated)`.\n     * The batch size specified here MUST match the batch size given to the shuffle script.\n     * The fourth argument controls some export behavior:\n        * `main` - this is the main net for selfplay, save it regularly to `$BASEDIR/tfsavedmodels_toexport` which the export loop will export regularly for gating.\n        * `extra` - save models to `$BASEDIR/tfsavedmodels_toexport_extra`, which the export loop will then export to `$BASEDIR/models_extra`, a directory that does not feed into gating or selfplay.\n        * `trainonly` - the neural net without exporting anything. This is useful for when you are trying to jointly train additional models of different sizes and there's no point to have them export anything yet (maybe they're too weak to bother testing).\n     * Any additional arguments, like \"-lr-scale 1.0\" to adjust learning rate will simply get forwarded on to train.py. The argument `-max-epochs-this-instance` can be used to make training terminate after a few epochs, instead of running forever. Run train.py with -help for other arguments.\n     * The arguments `-max-train-bucket-per-new-data 4 -max-train-bucket-size 10000000` instruct the training script that it is allowed to perform 4 training steps (measured in rows or samples, not batches) per data row generated by selfplay, the total of which is reported by the shuffler to the training whenever the shuffler outputs a new sampling of rows from the data. However, if more than 2.5M training rows are added at a time, the training will cap out at doing 10M steps at once rather than more. The value of \"4\" is conservative, you can increase it to train more/faster, but too large will risk problems from overfitting.\n     * The argument `-no-repeat-files` makes the training script wait for the shuffler to rerandomize a new sampling of rows if it's already made a full pass over all the shuffled data files from the current shuffle.\n     * Take a look at the generated `log.txt` for any possible errors, as well as running stats on training and loss statistics.\n     * You can choose a different size than b6c96 if desired. Configuration is in `python/modelconfigs.py`, which you can also edit to add other sizes.\n     * If you have a GPU that supports FP16, some other arguments like `-use-fp16` may make the training faster.\n     * If you want to export models less frequently, particularly later in a run to reduce model-switching overhead for selfplay, you can also set `-epochs-per-export`.\n     * There are many other options, see `--help` and/or look at the source code of `python/train.py` and `python/selfplay/train.sh`.\n   * **Gatekeeper:** `cpp/katago gatekeeper -rejected-models-dir $BASEDIR/rejectedmodels -accepted-models-dir $BASEDIR/models/ -sgf-output-dir $BASEDIR/gatekeepersgf/ -test-models-dir $BASEDIR/modelstobetested/ -selfplay-dir $BASEDIR/selfplay/ -config cpp/configs/training/GATEKEEPERCONFIG.cfg >> log.txt 2>&1 & disown`\n     * This starts the gatekeeper. Some example configs for different numbers of GPUs are: configs/training/gatekeeper{1,2a,2b,2c}.cfg. Again, you may want to edit these. The number of simultaneous game threads here is also large for the same reasons as for selfplay. No need to start this if specifying `0` for `$USE_GATING`.\n     * Take a look at the generated `log.txt` for any errors and/or for the game-by-game progress of each testing match that the gatekeeper runs.\n     * The argument `-quit-if-no-nets-to-test` can make gatekeeper terminate after testing all nets queued for testing, instead of running forever and waiting for more. Run with -help to see other arguments as well.\n     * Gatekeeper takes `-selfplay-dir` as an argument so as to pre-create the directory so that if there are multiple self-play machines, they don't corrupt a shared filesystem in a race to create the dir.\n\nTo manually pause a run, sending `SIGINT` or `SIGKILL` to all the relevant processes is the recommended method. The selfplay and gatekeeper processes will terminate gracefully when receiving such a signal and finish writing all pending data (this may take a minute or two), and any python or bash scripts will be terminated abruptly but are all implemented to write to disk in a way that is safe if killed at any point. To resume the run, just restart everything again with the same `$BASEDIR` and everything will continue where it left off.\n"
        },
        {
          "name": "TrainingHistory.md",
          "type": "blob",
          "size": 15.6240234375,
          "content": "# KataGo Older Training History and Research\n\n* [Current Status](#current-status)\n* [History](#history)\n  * [Third Major Run](#third-major-run)\n    * [Comparisons to Other Bots](#comparisons-to-other-bots)\n  * [First and Second Major Runs](#first-and-second-major-runs)\n  * [GoNN](#gonn)\n\n## Current Status\n\nAs of 2024, KataGo's is currently continuing its public distributed run, \"kata1\"! The website, where you can download the latest networks and find instructions to contribute if you wish, is here:\n\nhttps://katagotraining.org/\n\nThis run, continuing from the peak of KataGo's g170 run, has already improved in strength a bit, with hopefully much further room to improve. KataGo is able to win variously more than 80% or 90% of games against various classic and benchmark opponents even with a large handicap in computation power allowed, as well as performing favorably against the peak of its older 170 run. See [here](https://lifein19x19.com/viewtopic.php?p=262982#p262982) for some results.\n\n## Older History\n\nPrior to opening up its first public distributed run, KataGo ran three major runs on cloud machines or clusters privately or with the help of sponsors (many thanks to [Jane Street](https://www.janestreet.com/) for supporting and making some of these earlier runs and the necessary experiments and testing possible!). The full history of networks and generated training data for all three of these runs is available [here](https://katagoarchive.org/g170/index.html).\n\nIn reverse-chronological order:\n\n### Third Major Run\n\nKataGo's third major official run \"g170\" lasted from December 2019 to June 2020 for about 5 months (KataGo did not run entirely continuously during those 7 months) and reached significantly stronger than its competitors, including Leela Zero's using its strongest official 40-block nets. KataGo also took only 12-14 days to surpass its earlier 19-day \"g104\" run from June 2019. This is due to various training improvements which were not present in prior runs. By the end of the 5 months, it reached more than 700 Elo stronger than it. In addition to reaching stronger faster and running longer, this third run added major new features: support for Japanese rules, stronger handicap play, and more accurate score estimation.\n\nNetworks for g170 were released concurrently with major releases and development on the engine and analysis side, which can be seen in the history of the [releases page](https://github.com/lightvector/KataGo/releases). The training for g170 also included a variety of alternative and extendedly-trained neural nets which can be found [here](https://katagoarchive.org/g170/index.html), including some smaller nets that are *very* strong given their size. These include a fast 10-block network that nearly matches the strength of many earlier 15 block nets, including KataGo best 15-block net from last year and Leela Zero's LZ150. And a very strong 15-block network that almost matches the strength of ELFv2, a 20-block network.\n\nFor particularly limited hardware, these small nets may be of interest to users! But note that KataGo's later networks are so vastly stronger (hundreds or even thousands of Elo) that even on weak hardware, so long as the later and larger nets are runnable at all, they likely dominate the smaller ones, even taking into account how much slower they are to evaluate.\n\nHere is a graph of the improvement so over the course of the 157 training days of the run:\n\n<table class=\"image\">\n<tr><td><img src=\"https://raw.githubusercontent.com/lightvector/KataGo/master/images/readme/jan2020vsjune2019.png\" height=\"350\"/></td></tr>\n<tr><td><sub>X axis is days of training, log scale. (note: hardware is not entirely consistent during this time but most of the time was 44 V100 GPUs). Y axis is relative Elo rating based on some 1200-visit test matches. The abrupt jumps at the ends of each run are due to learning rate drops at the ends of those runs. The instability just before the jump in the June 2020 run, visible particularly in the 40-block Elo, is due to the last 40 days of that run being used to play with experimental changes, not all of which were improvements. 117 days is the last \"clean\" point prior to these changes.</sub></tr></td>\n</table>\n\nThe first 117 days of the run were clean and adhered to \"semi-zero\" standards. In particular, game-specific input features and auxiliary training targets were used, most of which are described in KataGo's [paper](https://arxiv.org/abs/1902.10565), and a few more [here](docs/KataGoMethods.md). However there was no use of outside data nor any special heuristics or expert logic encoded into the search for biasing or selecting moves, beyond some minor optimizations to end finished games a little faster. Only minimal adjustments were made to the ongoing training, via high-level hyperparameters (e.g. decaying the learning rate, the schedule for enlarging the neural net, etc). The last 40 days of the run then began to experiment with some limited ways of using external data to see the effects.\n\nThe run used about 46 GPUs for most of its duration. Of these, 40 were for self-play data generation, and up to 4 for training the main neural nets for the run, and 2 for gating games. Only 28 GPUs were used to surpass last year's run in the first 14 days. For days 14 to 38 this was increased to 36 GPUs, then from day 38 onward increased again to the current 46 GPUs, which was the number used for the rest of the run. One extra 47th GPU was used sometimes during the experimental changes in the last 40 days. Additionally, at times up to 3 more GPUs were used for training some extra networks such as extended smaller networks for end-users with weaker hardware, but these played no role in the run proper.\n\nJust for fun, are tables of the Elo strength of selected versions, based on a few tens of thousands of games between these and other versions in a pool (1200 visits). These are based on fixed search tree size, NOT fixed computation time. For the first 117 days:\n\n| Neural Net | Note | Approx Days Selfplay | Elo |\n|-------------|-------|---------------|------|\n| g170-b6c96-s175395328-d26788732 | (last selfplay 6 block)   | 0.75    |      -1184 |\n| g170-b10c128-s197428736-d67404019 |  (last selfplay 10 block)  | 1.75  |      -280 |\n| g170e-b10c128-s1141046784-d204142634  | (extended training 10 block)  | -  |   300 |\n| g170-b15c192-s497233664-d149638345 |   (last selfplay 15 block) | 7.5  |      512 |\n| g170e-b15c192-s1305382144-d335919935  | (extended training 15 block)  | -  |   876 |\n| g170e-b15c192-s1672170752-d466197061  | (extended training 15 block)  | -  |   935 |\n| g170-b20c256x2-s668214784-d222255714  | (20 block)  |  15.5 |   959 |\n| g170-b20c256x2-s1039565568-d285739972  | (20 block)   | 21.5 |    1073 |\n| g170-b20c256x2-s1420141824-d350969033  | (20 block)   | 27.5 |    1176 |\n| g170-b20c256x2-s1913382912-d435450331  | (20 block)  | 35.5 |    1269 |\n| g170-b20c256x2-s2107843328-d468617949  | (last selfplay 20 block)  | 38.5 |    1293 |\n| g170e-b20c256x2-s2430231552-d525879064 | (extended training 20 block)  | 47.5  | 1346  |\n| g170-b30c320x2-s1287828224-d525929064  | (30 block more channels)  | 47.5 |    1412 |\n| g170-b40c256x2-s1349368064-d524332537  | (40 block less channels)  | 47   |    1406 |\n| g170e-b20c256x2-s2971705856-d633407024 | (extended training 20 block)  | 64.5  | 1413  |\n| g170-b30c320x2-s1840604672-d633482024  | (30 block more channels)  | 64.5 |    1524 |\n| g170-b40c256x2-s1929311744-d633132024  | (40 block less channels)  | 64.5   |    1510 |\n| g170e-b20c256x2-s3354994176-d716845198 | (extended training 20 block)  | 78  | 1455  |\n| g170-b30c320x2-s2271129088-d716970897  | (30 block more channels)  | 78   |    1551 |\n| g170-b40c256x2-s2383550464-d716628997  | (40 block less channels)  | 78   |    1554 |\n| g170e-b20c256x2-s3761649408-d809581368 | (extended training 20 block) | 92  |  1513 |\n| g170-b30c320x2-s2846858752-d829865719  | (30 block more channels)  | 96   |  1619 |\n| g170-b40c256x2-s2990766336-d830712531  | (40 block less channels)  | 96   |  1613 |\n| g170e-b20c256x2-s4384473088-d968438914 | (extended training 20 block) | 117 |  1529 |\n| g170-b30c320x2-s3530176512-d968463914  | (30 block more channels)  | 117  | 1643 |\n| g170-b40c256x2-s3708042240-d967973220  | (40 block less channels)  | 117  | 1687 |\n\nNeural nets following some of the more experimental training changes in the last 40 days, where various changes to the training involving external data were tried, with mixed results:\n\n| Neural Net | Note | Approx Days Selfplay | Elo |\n|-------------|-------|---------------|------|\n| g170-b30c320x2-s3910534144-d1045712926  | (30 block more channels)  | 129 |     1651 |\n| g170-b40c256x2-s4120339456-d1045882697  | (40 block less channels)  | 129 |   1698 |\n| g170e-b20c256x2-s4667204096-d1045479207 | (extended training 20 block) | 129 |     1561 |\n| g170-b30c320x2-s4141693952-d1091071549  | (30 block more channels)  | 136.5 |   1653 |\n| g170-b40c256x2-s4368856832-d1091190099  | (40 block less channels)  | 136.5 |   1680 |\n| g170e-b20c256x2-s4842585088-d1091433838 | (extended training 20 block) | 136.5 |     1547 |\n| g170-b30c320x2-s4432082944-d1149895217  | (30 block more channels)  | 145.5 |   1648 |\n| g170-b40c256x2-s4679779328-d1149909226  | (40 block less channels)  | 145.5  |  1690 |\n| g170e-b20c256x2-s5055114240-d1149032340 | (extended training 20 block) | 145.5 |     1539 |\n\nNeural nets resulting from final learning rate drops. Some of the experimental uses of external data were continued here, but the large gains are most definitely due to learning rate drops rather than those uses. **The last three nets in this table are KataGo's final nets from this run!**\n\n| Neural Net | Note | Approx Days Selfplay | Elo |\n|-------------|-------|---------------|------|\n| g170-b30c320x2-s4574191104-d1178681586  | (learning rate drop by 3.5x)  | 150 |   1759   |\n| g170-b40c256x2-s4833666560-d1179059206  | (learning rate drop by 3.5x)  | 150 |   1788 |\n| g170e-b20c256x2-s5132547840-d1177695086 | (learning rate drop by 2x) | 150 |     1577 |\n| **g170-b30c320x2-s4824661760-d122953669**   | **(learning rate drop by another 2x)**  | **157** |   **1908** |\n| **g170-b40c256x2-s5095420928-d1229425124**  | **(learning rate drop by another 2x)**  | **157** |   **1919** |\n| **g170e-b20c256x2-s5303129600-d1228401921** | **(learning rate drop by another 2x)** | **157** |    **1645** |\n\n\nAnd for comparison to the old 2019 June official run: (these Elos are directly measured rather than inferred, as these older networks competed directly in the same pool of test games):\n\n| Neural Net | Note | Approx Days Selfplay |  Elo |\n|-------------|-------|---------------|------|\n| g104-b6c96-s97778688-d23397744 | (last selfplay 6 block)   |  0.75 |    -1146 |\n| g104-b10c128-s110887936-d54937276  | (last selfplay 10 block)     |  1.75 |    -476 |\n| g104-b15c192-s297383936-d140330251  | (last selfplay 15 block)    |  7.5 |    327 |\n| g104-b20c256-s447913472-d241840887  | (last selfplay 20 block)   |  19 |    908 |\n\n#### Comparisons to Other Bots\nKataGo's g170 run as of June 2020 ended up significantly stronger than other major open-source bots in a variety of tests and conditions.\n\nFor some tests versus Leela Zero and ELF, see https://github.com/lightvector/KataGo/issues/254, as well as #test-results in https://discord.gg/bqkZAz3 and various casual tests run by various users in https://lifein19x19.com/viewtopic.php?f=18&t=17195 and https://lifein19x19.com/viewtopic.php?f=18&t=17474 at various points in KataGo's progression. See also the [paper](https://arxiv.org/abs/1902.10565) for test results regarding KataGo's June 2019 run (\"g104\") against some opponents. As a result of some further improvements, the most notable of which are documented [here](docs/KataGoMethods.md) along with other research notes, KataGo's June 2019 run learned somewhere between 1.5x and 2x less efficiently than more recent and much better June 2020 run (\"g170\").\n\nBased on some of these tests, although most of these used all different parameters and match conditions and hardware, **if one were to try to put Leela Zero on the same Elo scale as in the above tables, one could maybe guess LZ272 to be very roughly somewhere between 1250 and 1450 Elo**. But note also that the above Elos, due to being computed primarily by match games with earlier networks in the same run (although selected with high variety to avoid \"rock-paper-scissors\" issues) are likely to *not* be fully linear/transitive to other bots. Or even to other KataGo networks, particularly for larger differences. For example, it would not be surprising if one were to take two networks that were a large 400 Elo apart, and discover that in a direct test that the stronger one did not win quite precisely win 10 games per 1 lost game as the Elo model would predict, although one might expect still something close.\n\nOn 9x9 (KataGo's same networks can handle all common board sizes), KataGo topped the CGOS ladder in May 2020 using one V100 GPU, [playing more than 100 games](http://www.yss-aya.com/cgos/9x9/cross/katab40s37-awsp3.html) against other top bots including many specially-trained 9x9 bots, as well as many games against moderately weaker 9x9 bots. Against the strongest several opponents, it won close to half of these games, while losing only one game ever (the rest of the games were draws). An [alternate version](http://www.yss-aya.com/cgos/9x9/cross/katab40s37-pda1.html) configured to be more aggressive and/or even to deliberately overplay won more than half of its games against the strongest opponents, drawing slightly less often at the cost of losing a few additional games.\n\n### First and Second Major Runs\n\nThe first serious run of KataGo, \"g65\", ran for 7 days in February 2019 on up to 35 V100 GPUs. This is the run featured the [early versions](https://arxiv.org/abs/1902.10565v2) of KataGo's research paper. It achieved close to LZ130 strength before it was halted, or up to just barely superhuman.\n\nFollowing some further improvements and much-improved hyperparameters, KataGo performed a second serious run, \"g104\", in May-June 2019 with a max of 28 V100 GPUs, surpassing the February run after just three and a half days. The run was halted after 19 days, with the final 20-block networks reaching a final strength slightly stronger than LZ-ELFv2! (This is Facebook's very strong 20-block ELF network, running on Leela Zero's search architecture). Comparing to the yet larger Leela Zero 40-block networks, KataGo's network falls somewhere around LZ200 at visit parity, despite only itself being 20 blocks. [Recent versions](https://arxiv.org/abs/1902.10565) of the paper have been updated to reflect this run. Here is a graph of Elo ratings of KataGo's June run compared to Leela Zero and ELF based on a set of test games, where the X axis is an approximate measure of self-play computation required (note: log scale).\n\n<table class=\"image\">\n<tr><td><img src=\"https://raw.githubusercontent.com/lightvector/KataGo/master/images/readme/katajunevslz.png\" height=\"350\"/></td></tr>\n<tr><td><sub>June run of KataGo vs LZ and ELF. X axis is approx selfplay compute spent, log scale. Y axis is relative Elo rating. Leela Zero goes up to LZ225 on this graph. KataGo trains efficiently compared to other bots. See paper for details.</sub></tr></td>\n</table>\n\n### GoNN\n\nSee also https://github.com/lightvector/GoNN for some earlier research, mostly involving supervised neural net training on professional Go games. KataGo is essentially a continuation of that research, but that old repo has been preserved since the changes in this repo are not backwards compatible, and to leave the old repo intact to continue as a showcase of the many earlier experiments performed there. Several of KataGo's major improvements over AlphaZero, such as global pooling and ownership auxiliary prediction, came directly out of these experiments in neural net training and architecture.\n"
        },
        {
          "name": "cpp",
          "type": "tree",
          "content": null
        },
        {
          "name": "docs",
          "type": "tree",
          "content": null
        },
        {
          "name": "images",
          "type": "tree",
          "content": null
        },
        {
          "name": "misc",
          "type": "tree",
          "content": null
        },
        {
          "name": "python",
          "type": "tree",
          "content": null
        }
      ]
    }
  ]
}