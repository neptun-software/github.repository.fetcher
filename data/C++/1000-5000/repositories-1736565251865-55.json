{
  "metadata": {
    "timestamp": 1736565251865,
    "page": 55,
    "hasNextPage": true,
    "endCursor": "Y3Vyc29yOjYw",
    "completionStatus": "IN_PROGRESS"
  },
  "repositories": [
    {
      "nameWithOwner": "arrayfire/arrayfire",
      "stars": 4600,
      "defaultBranch": "master",
      "files": [
        {
          "name": ".coveralls.yml",
          "type": "blob",
          "size": 0.1298828125,
          "content": "service_name: jenkins-ci\ninclude: [src,include]\nexclude: [src/backend/opencl/cl.hpp, test, include/af/version.h]\ngcov_options: '-lp'\n"
        },
        {
          "name": ".github",
          "type": "tree",
          "content": null
        },
        {
          "name": ".gitignore",
          "type": "blob",
          "size": 0.31640625,
          "content": "#CMakeCache.txt\n#./CMakeFiles/\nCMakeUserPresets.json\nbuild*/\nRelease/\n#Makefile\n#cmake_install.cmake\nGTAGS\nGRTAGS\nGPATH\n.dir-locals.el\n#docs/details/examples.dox\n/TAGS\nexternal/\nextern/\ncompile_commands.json\nvenv\ntest/gtest\n#src/backend/cuda/cub\nconanbuildinfo*\nconaninfo*\nconan.lock\ngraph_info.json\n.ccls-cache\n.projectile\n"
        },
        {
          "name": ".gitmodules",
          "type": "blob",
          "size": 0,
          "content": ""
        },
        {
          "name": "ACKNOWLEDGEMENTS.md",
          "type": "blob",
          "size": 1.25,
          "content": "Acknowledgements\n=====\n\nThe ArrayFire library is written by developers at [ArrayFire](http://arrayfire.com) LLC\nwith [contributions from several individuals](https://github.com/arrayfire/arrayfire/graphs/contributors).\nThe developers at ArrayFire LLC have received partial financial support\nfrom several grants and institutions. Those that wish to receive public\nacknowledgement are listed below:\n\n<!--\nThe following section contains acknowledgements for grant funding. In most\ncircumstances, the specific phrasing of the text is mandated by the grant\nprovider. Thus these acknowledgements must remain intact without modification.\n-->\n\n### Grants\n\nThis material is based upon work supported by the DARPA SBIR Program Office\nunder Contract Numbers W31P4Q-14-C-0012 and W31P4Q-15-C-0008.\nAny opinions, findings and conclusions or recommendations expressed in this\nmaterial are those of the author(s) and do not necessarily reflect the views of\nthe DARPA SBIR Program Office.\n\nResearch reported in this publication is supported by the National Library of\nMedicine of the National Institutes of Health under award number\nR43LM012359. The content is solely the responsibility of the author(s) and\ndoes not necessarily represent the official views of the National Institutes\nof Health.\n"
        },
        {
          "name": "CMakeLists.txt",
          "type": "blob",
          "size": 23.556640625,
          "content": "# Copyright (c) 2021, ArrayFire\n# All rights reserved.\n#\n# This file is distributed under 3-clause BSD license.\n# The complete license agreement can be obtained at:\n# http://arrayfire.com/licenses/BSD-3-Clause\n\nif(AF_BUILD_ONEAPI)\n  cmake_minimum_required(VERSION 3.20)\nelse()\n  cmake_minimum_required(VERSION 3.16.3)\nendif()\ninclude(CheckLanguage)\n\ninclude(CMakeModules/AF_vcpkg_options.cmake)\n\nset(CMAKE_MODULE_PATH ${CMAKE_MODULE_PATH} \"${CMAKE_CURRENT_SOURCE_DIR}/CMakeModules\")\nproject(ArrayFire VERSION 3.9.0 LANGUAGES C CXX)\n\ninclude(AFconfigure_deps_vars)\ninclude(AFBuildConfigurations)\ninclude(AFInstallDirs)\ninclude(CMakeDependentOption)\ninclude(InternalUtils)\ninclude(Version)\ninclude(platform)\ninclude(GetPrerequisites)\ninclude(CheckCXXCompilerFlag)\ninclude(CheckSymbolExists)\ninclude(SplitDebugInfo)\n\n# Use the function generate_product_version on Windows\n# to attach version info in dll file attributes.\n# Make sure to pass appropriate arguments for each backend\n# to generate the correct resource file\ninclude(generate_product_version)\n\nset_policies(\n  TYPE NEW\n  POLICIES CMP0073\n           CMP0074\n           CMP0077\n           CMP0079)\narrayfire_set_cmake_default_variables()\n\noption(AF_WITH_EXTERNAL_PACKAGES_ONLY \"Build ArrayFire with External packages only\" OFF)\nif(AF_WITH_EXTERNAL_PACKAGES_ONLY)\n  set(AF_REQUIRED REQUIRED)\nendif()\nif(CMAKE_SYCL_COMPILER)\n  get_filename_component(SYCL_COMPILER_NAME ${CMAKE_SYCL_COMPILER} NAME)\nendif()\nif(SYCL_COMPILER_NAME STREQUAL \"dpcpp\" OR SYCL_COMPILER_NAME STREQUAL \"dpcpp.exe\"\n   OR SYCL_COMPILER_NAME STREQUAL \"icpx\" OR SYCL_COMPILER_NAME STREQUAL \"icx.exe\")\n  set(MKL_THREAD_LAYER \"TBB\" CACHE STRING \"The thread layer to choose for MKL\")\n  set(MKL_INTERFACE \"ilp64\")\n  set(MKL_INTERFACE_INTEGER_SIZE 8)\nelse()\n  set(MKL_THREAD_LAYER \"Intel OpenMP\" CACHE STRING \"The thread layer to choose for MKL\")\n  set(MKL_INTERFACE \"lp64\")\n  set(MKL_INTERFACE_INTEGER_SIZE 4)\nendif()\n\nfind_package(CUDA 10.2)\nfind_package(cuDNN 4.0)\nfind_package(OpenCL 1.2)\nfind_package(OpenGL)\nfind_package(glad CONFIG QUIET)\nfind_package(FreeImage)\nfind_package(Threads)\nfind_package(FFTW)\nfind_package(CBLAS)\nfind_package(LAPACKE)\nfind_package(Doxygen)\nfind_package(AF_MKL)\nfind_package(spdlog QUIET ${AF_REQUIRED} NO_CMAKE_PACKAGE_REGISTRY)\nfind_package(fmt QUIET ${AF_REQUIRED})\nfind_package(span-lite QUIET)\nfind_package(GTest)\nfind_package(CLBlast QUIET)\nfind_package(Boost 1.70 ${AF_REQUIRED})\n\n# CLFFT used in ArrayFire requires a specific fork\n#find_package(clFFT QUIET)\n\ninclude(boost_package)\ninclude(config_ccache)\n\noption(AF_BUILD_CPU      \"Build ArrayFire with a CPU backend\"        ON)\noption(AF_BUILD_CUDA     \"Build ArrayFire with a CUDA backend\"       ${CUDA_FOUND})\noption(AF_BUILD_OPENCL   \"Build ArrayFire with a OpenCL backend\"     ${OpenCL_FOUND})\noption(AF_BUILD_ONEAPI   \"Build ArrayFire with a oneAPI backend\"     OFF)\noption(AF_BUILD_UNIFIED  \"Build Backend-Independent ArrayFire API\"   ON)\noption(AF_BUILD_DOCS     \"Create ArrayFire Documentation\"            ${DOXYGEN_FOUND})\noption(AF_BUILD_EXAMPLES \"Build Examples\"                            ON)\noption(AF_WITH_CUDNN     \"Use cuDNN for convolveNN functions\"        ${cuDNN_FOUND})\noption(AF_BUILD_FORGE\n    \"Forge libs are not built by default as it is not link time dependency\" OFF)\n\noption(AF_WITH_NONFREE  \"Build ArrayFire nonfree algorithms\"   OFF)\noption(AF_WITH_LOGGING  \"Build ArrayFire with logging support\" ON)\noption(AF_WITH_STACKTRACE  \"Add stacktraces to the error messages.\" ON)\noption(AF_CACHE_KERNELS_TO_DISK \"Enable caching kernels to disk\" ON)\noption(AF_WITH_STATIC_MKL \"Link against static Intel MKL libraries\" OFF)\noption(AF_WITH_STATIC_CUDA_NUMERIC_LIBS \"Link libafcuda with static numeric libraries(cublas, cufft, etc.)\" OFF)\noption(AF_WITH_SPDLOG_HEADER_ONLY \"Build ArrayFire with header only version of spdlog\" OFF)\noption(AF_WITH_FMT_HEADER_ONLY \"Build ArrayFire with header only version of fmt\" OFF)\noption(AF_WITH_FAST_MATH \"Use lower precision but high performance numeric optimizations\" OFF)\noption(AF_CTEST_SEPARATED \"Run tests separately when called from ctest(increases test times)\" OFF)\n\nif(AF_WITH_STATIC_CUDA_NUMERIC_LIBS)\n  option(AF_WITH_PRUNE_STATIC_CUDA_NUMERIC_LIBS \"Prune CUDA static libraries to reduce binary size.(WARNING: May break some libs on older CUDA toolkits for some compute arch)\" OFF)\nendif()\n\nset(default_compute_library \"FFTW/LAPACK/BLAS\")\nif(MKL_FOUND)\n  set(default_compute_library \"Intel-MKL\")\nendif()\n\nif(AF_WITH_STATIC_MKL)\n  set(MKL_LINK static)\nendif()\nif(MKL_THREAD_LAYER STREQUAL \"Sequential\")\n  set(MKL_THREADING \"sequential\")\nelseif(MKL_THREAD_LAYER STREQUAL \"GNU OpenMP\")\n  set(MKL_THREADING \"gnu_thread\")\nelseif(MKL_THREAD_LAYER STREQUAL \"Intel OpenMP\")\n  set(MKL_THREADING \"intel_thread\")\nelseif(MKL_THREAD_LAYER STREQUAL \"TBB\")\n  set(MKL_THREADING \"tbb_thread\")\nelse()\nendif()\n\nif(CMAKE_VERSION VERSION_GREATER_EQUAL 3.13)\n  # VCPKG overrides the find_package command and the PATH parameter is currently\n  # broken with the current version of VCPKG so we are setting the MKL_ROOT\n  # directory to the MKLROOT environment variable.\n  if(DEFINED ENV{MKLROOT} AND NOT DEFINED MKL_ROOT)\n    set(MKL_ROOT \"$ENV{MKLROOT}\")\n  endif()\n  set(DPCPP_COMPILER ON)\n  set(MKL_THREADING \"tbb_thread\")\n  set(MKL_INTERFACE \"ilp64\")\n  find_package(MKL 2023.1)\nendif()\n\naf_multiple_option(NAME        AF_COMPUTE_LIBRARY\n                   DEFAULT     ${default_compute_library}\n                   DESCRIPTION \"Compute library for signal processing and linear algebra routines\"\n                   OPTIONS     \"Intel-MKL\" \"FFTW/LAPACK/BLAS\")\n\nif(WIN32)\n  af_multiple_option(NAME         AF_STACKTRACE_TYPE\n                     DEFAULT      \"Windbg\"\n                     DESCRIPTION  \"The type of backtrace features. Windbg(simple), None\"\n                     OPTIONS       \"Windbg\" \"None\")\nelse()\n  af_multiple_option(NAME         AF_STACKTRACE_TYPE\n                     DEFAULT      \"Basic\"\n                     DESCRIPTION  \"The type of backtrace features. Basic(simple), libbacktrace(fancy), addr2line(fancy), None\"\n                     OPTIONS       \"Basic\" \"libbacktrace\" \"addr2line\" \"None\")\nendif()\n\noption(AF_INSTALL_STANDALONE \"Build installers that include all dependencies\" OFF)\n\ncmake_dependent_option(AF_WITH_RELATIVE_TEST_DIR \"Use relative paths for the test data directory(For continious integration(CI) purposes only)\" OFF\n  \"BUILD_TESTING\" OFF)\n\ncmake_dependent_option(AF_WITH_IMAGEIO \"Build ArrayFire with Image IO support\" ${FreeImage_FOUND}\n                       \"FreeImage_FOUND\" OFF)\ncmake_dependent_option(AF_BUILD_FRAMEWORK \"Build an ArrayFire framework for Apple platforms.(Experimental)\" OFF\n                       \"APPLE\" OFF)\n\noption(AF_WITH_STATIC_FREEIMAGE \"Use Static FreeImage Lib\" OFF)\n\nset(AF_WITH_CPUID ON CACHE BOOL \"Build with CPUID integration\")\n\nif(AF_BUILD_CUDA)\n  check_language(CUDA)\n  if(CMAKE_CUDA_COMPILER)\n    enable_language(CUDA)\n  elseif(CUDA_NVCC_EXECUTABLE)\n    message(STATUS \"Using the FindCUDA script to search for the CUDA compiler\")\n    set(CMAKE_CUDA_COMPILER ${CUDA_NVCC_EXECUTABLE} CACHE INTERNAL \"CUDA compiler executable\")\n    enable_language(CUDA)\n  else()\n    message(WARNING \"No CUDA support\")\n  endif()\nendif()\n\naf_deprecate(BUILD_CPU             AF_BUILD_CPU)\naf_deprecate(BUILD_CUDA            AF_BUILD_CUDA)\naf_deprecate(BUILD_OPENCL          AF_BUILD_OPENCL)\naf_deprecate(BUILD_UNIFIED         AF_BUILD_UNIFIED)\naf_deprecate(BUILD_DOCS            AF_BUILD_DOCS)\naf_deprecate(BUILD_NONFREE         AF_WITH_NONFREE)\naf_deprecate(BUILD_EXAMPLES        AF_BUILD_EXAMPLES)\naf_deprecate(USE_RELATIVE_TEST_DIR AF_WITH_RELATIVE_TEST_DIR)\naf_deprecate(USE_FREEIMAGE_STATIC  AF_WITH_STATIC_FREEIMAGE)\naf_deprecate(USE_CPUID             AF_WITH_CPUID)\nif(DEFINED USE_CPU_MKL OR DEFINED USE_OPENCL_MKL)\n  # Cannot use af_deprecated as it expects the new and old variables to store values of\n  # same type. In this case, USE_*_MKL variables are BOOLs and AF_COMPUTE_LIBRARY is a STRING\n  message(DEPRECATION\n    \"Variables USE_CPU_MKL/USE_OPENCL_MKL are deprecated. Use AF_COMPUTE_LIBRARY instead.\")\n  message(WARNING\n    \"USE_CPU_MKL/USE_OPENCL_MKL defined. These values take precendence over the value of\n    AF_COMPUTE_LIBRARY until they are removed to preserve existing build behavior.\")\n  # Until USE_CPU_MKL and USE_OPENCL_MKL are removed, if they are defined, they take\n  # precendence and cmake will check and report error if Intel-MKL is not found\n  if(USE_CPU_MKL OR USE_OPENCL_MKL)\n    get_property(doc CACHE AF_COMPUTE_LIBRARY PROPERTY HELPSTRING)\n    set(AF_COMPUTE_LIBRARY \"Intel-MKL\" CACHE STRING \"${doc}\" FORCE)\n  endif()\nendif()\n\nif(AF_COMPUTE_LIBRARY STREQUAL \"Intel-MKL\")\n  set(BLA_VENDOR \"Intel10_64lp\")\n  if(MKL_THREAD_LAYER STREQUAL \"Sequential\")\n    set(BLA_VENDOR \"${BLA_VENDOR}_seq\")\n  endif()\nendif()\nfind_package(BLAS)\nfind_package(LAPACK)\n\n# IF: the old USE_CPU_MKL/USE_OPENCL_MKL flags are present,\n# THEN Irrespective of AF_COMPUTE_LIBRARY value, continue with MKL to preserve old\n#      behavior. Once the deprecated USE_CPU_MKL/USE_OPENCL_MKL are removed in later\n#      versions AF_COMPUTE_LIBRARY will take over total control of selecting CPU\n#      compute backend.\n#\n# Note that the default value of AF_COMPUTE_LIBRARY is Intel-MKL.\n# Also, cmake doesn't have short-circuit of OR/AND conditions in if\nif(${AF_BUILD_CPU} OR ${AF_BUILD_OPENCL})\n  if(\"${AF_COMPUTE_LIBRARY}\" STREQUAL \"Intel-MKL\"\n      OR \"${AF_COMPUTE_LIBRARY}\" STREQUAL \"MKL\")\n    af_mkl_batch_check()\n    dependency_check(MKL_Shared_FOUND \"Please ensure Intel-MKL / oneAPI-oneMKL is installed\")\n    set(BUILD_WITH_MKL ON)\n  elseif(\"${AF_COMPUTE_LIBRARY}\" STREQUAL \"FFTW/LAPACK/BLAS\")\n    dependency_check(FFTW_FOUND \"FFTW not found\")\n    dependency_check(CBLAS_FOUND \"CBLAS not found\")\n    if(UNIX AND NOT APPLE)\n      dependency_check(LAPACK_FOUND \"LAPACK not found\")\n    endif()\n  endif()\nendif()\n\n#Configure forge submodule\n#forge is included in ALL target if AF_BUILD_FORGE is ON\n#otherwise, forge is not built at all\ninclude(AFconfigure_forge_dep)\n\nif(TARGET fmt::fmt AND AF_WITH_FMT_HEADER_ONLY)\n  set_target_properties(fmt::fmt\n    PROPERTIES\n      INTERFACE_COMPILE_DEFINITIONS \"FMT_HEADER_ONLY=1\")\nendif()\n\nif(TARGET spdlog::spdlog OR AF_WITH_EXTERNAL_PACKAGES_ONLY)\n  if(AF_WITH_SPDLOG_HEADER_ONLY)\n    add_library(af_spdlog ALIAS spdlog::spdlog_header_only)\n  else()\n    add_library(af_spdlog ALIAS spdlog::spdlog)\n  endif()\nelse()\n  add_library(af_spdlog INTERFACE)\n  af_dep_check_and_populate(${spdlog_prefix}\n    URI https://github.com/gabime/spdlog.git\n    REF v1.9.2\n  )\n\n  if(TARGET fmt::fmt)\n    set(SPDLOG_FMT_EXTERNAL ON)\n  endif()\n\n  add_subdirectory(${${spdlog_prefix}_SOURCE_DIR} ${${spdlog_prefix}_BINARY_DIR} EXCLUDE_FROM_ALL)\n\n  if(AF_WITH_SPDLOG_HEADER_ONLY)\n    set_target_properties(af_spdlog\n      PROPERTIES\n        INTERFACE_COMPILE_DEFINITIONS \"FMT_HEADER_ONLY=1\"\n        INTERFACE_LINK_LIBRARIES \"spdlog_header_only\")\n  else()\n    target_compile_options(spdlog\n      PRIVATE\n        $<$<BOOL:${has_cxx_fp_model}>:-fp-model precise>)\n    install(TARGETS spdlog\n      COMPONENT common_backend_dependencies\n      DESTINATION ${AF_INSTALL_BIN_DIR})\n    set_target_properties(af_spdlog\n      PROPERTIES\n        INTERFACE_LINK_LIBRARIES \"spdlog\")\n  endif()\nendif()\n\nif(NOT TARGET glad::glad)\n  af_dep_check_and_populate(${glad_prefix}\n    URI https://github.com/arrayfire/glad.git\n    REF main\n  )\n  add_subdirectory(${${glad_prefix}_SOURCE_DIR} ${${glad_prefix}_BINARY_DIR})\n\n  add_library(af_glad STATIC $<TARGET_OBJECTS:af_glad_obj_lib>)\n  target_link_libraries(af_glad PUBLIC ${CMAKE_DL_LIBS})\n  target_include_directories(af_glad\n    SYSTEM PUBLIC\n      $<BUILD_INTERFACE:$<TARGET_PROPERTY:af_glad_obj_lib,INTERFACE_INCLUDE_DIRECTORIES>>)\nendif()\n\nif(NOT TARGET nonstd::span-lite)\n  af_dep_check_and_populate(span-lite\n    URI https://github.com/martinmoene/span-lite\n    REF \"ccf2351\"\n    )\n  add_subdirectory(${span-lite_SOURCE_DIR} EXCLUDE_FROM_ALL)\n  get_property(span_include_dir\n    TARGET span-lite\n    PROPERTY INTERFACE_INCLUDE_DIRECTORIES)\n  set_target_properties(span-lite\n    PROPERTIES INTERFACE_SYSTEM_INCLUDE_DIRECTORIES \"${span_include_dir}\")\n  set_target_properties(span-lite\n    PROPERTIES INTERFACE_COMPILE_DEFINITIONS \"span_FEATURE_WITH_INITIALIZER_LIST_P2447=1\")\n\nendif()\n\naf_dep_check_and_populate(${assets_prefix}\n  URI https://github.com/arrayfire/assets.git\n  REF master\n)\nset(ASSETS_DIR ${${assets_prefix}_SOURCE_DIR})\n\n# when crosscompiling use the bin2cpp file from the native bin directory\nif(CMAKE_CROSSCOMPILING)\n  set(NATIVE_BIN_DIR \"NATIVE_BIN_DIR-NOTFOUND\"\n    CACHE FILEPATH \"Path to the Native build directory.\")\n  if(NATIVE_BIN_DIR)\n    include(${NATIVE_BIN_DIR}/ImportExecutables.cmake)\n  else()\n    message(SEND_ERROR \"Native Directory not found. Run cmake in a separate\"\n                       \"directory and build the bin2cpp target.\")\n  endif()\nelse()\n  add_executable(bin2cpp CMakeModules/bin2cpp.cpp\n                         src/backend/common/deterministicHash.cpp\n                         src/backend/common/deterministicHash.hpp\n                         src/backend/common/Source.hpp)\n  set_target_properties(bin2cpp\n    PROPERTIES\n      CXX_STANDARD 17)\n  target_link_libraries(bin2cpp PRIVATE nonstd::span-lite)\n\n  if(WIN32)\n    target_compile_definitions(bin2cpp PRIVATE OS_WIN)\n  elseif(APPLE)\n    target_compile_definitions(bin2cpp PRIVATE OS_MAC)\n  elseif(UNIX)\n    target_compile_definitions(bin2cpp PRIVATE OS_LNX)\n  endif()\n  target_include_directories(bin2cpp PRIVATE\n                             ${ArrayFire_SOURCE_DIR}/include\n                             ${ArrayFire_BINARY_DIR}/include\n                             ${ArrayFire_SOURCE_DIR}/src/backend)\n  export(TARGETS bin2cpp FILE ${CMAKE_BINARY_DIR}/ImportExecutables.cmake)\nendif()\n\n\nif(NOT LAPACK_FOUND)\n    if(APPLE)\n        # UNSET THE VARIABLES FROM LAPACKE\n        unset(LAPACKE_LIB CACHE)\n        unset(LAPACK_LIB CACHE)\n        unset(LAPACKE_INCLUDES CACHE)\n        unset(LAPACKE_ROOT_DIR CACHE)\n    endif()\nendif()\n\nadd_subdirectory(src/backend/common)\nadd_subdirectory(src/api/c)\nadd_subdirectory(src/api/cpp)\n\nconditional_directory(AF_BUILD_CPU     src/backend/cpu)\nconditional_directory(AF_BUILD_CUDA    src/backend/cuda)\nconditional_directory(AF_BUILD_ONEAPI  src/backend/oneapi)\nconditional_directory(AF_BUILD_OPENCL  src/backend/opencl)\nconditional_directory(AF_BUILD_UNIFIED src/api/unified)\n\nif(TARGET af)\n  list(APPEND built_backends af)\nendif()\n\nif(TARGET afcpu)\n  list(APPEND built_backends afcpu)\nendif()\n\nif(TARGET afcuda)\n  list(APPEND built_backends afcuda)\nendif()\n\nif(TARGET afoneapi)\n  list(APPEND built_backends afoneapi)\nendif()\n\nif(TARGET afopencl)\n  list(APPEND built_backends afopencl)\nendif()\n\nset_target_properties(${built_backends} PROPERTIES\n                      CXX_STANDARD 17\n                      CXX_EXTENSIONS OFF\n                      CXX_VISIBILITY_PRESET hidden\n                      VERSION \"${ArrayFire_VERSION}\"\n                      SOVERSION \"${ArrayFire_VERSION_MAJOR}\")\n\nif(AF_INSTALL_STANDALONE)\n\n  # This flag enables the use of RUNPATH instead of RPATH which is the\n  # preferred method to set the runtime lookup. Only doind this for\n  # standalone builds because we include all libraries with the installers\n  # and they are included in the same directory so the RUNPATH is set to\n  # $ORIGIN. This avoid setting the linker path in ld.so.conf.d\n  check_cxx_compiler_flag(\"-Wl,--enable-new-dtags\" HAS_RUNPATH_FLAG)\n  if(HAS_RUNPATH_FLAG)\n    set_target_properties(${built_backends} PROPERTIES\n      INSTALL_RPATH \"$ORIGIN\"\n      LINK_OPTIONS \"-Wl,--enable-new-dtags\")\n  endif()\nendif()\n\n# On some distributions the linker will not add a library to the ELF header if\n# the symbols are not needed when the library was first parsed by the linker.\n# This causes undefined references issues when linking with libraries which have\n# circular dependencies.\nif(UNIX AND NOT APPLE AND CMAKE_CXX_COMPILER_ID MATCHES \"GNU\")\n  set_target_properties(${built_backends} PROPERTIES\n                        LINK_FLAGS \"-Wl,--no-as-needed\")\nendif()\n\n\nfind_library(Backtrace_LIBRARY backtrace\n  DOC \"libbacktrace.so file for more informative stacktraces. https://github.com/ianlancetaylor/libbacktrace\")\nfind_program(ADDR2LINE_PROGRAM addr2line\n  DOC \"The path to the addr2line program for informative stacktraces\")\n\ncheck_cxx_compiler_flag(-Wno-ignored-attributes has_ignored_attributes_flag)\ncheck_cxx_compiler_flag(-Wall has_all_warnings_flag)\n\nforeach(backend ${built_backends})\n  arrayfire_set_default_cxx_flags(${backend})\nendforeach()\n\nif(AF_BUILD_FRAMEWORK)\n  set_target_properties(${built_backends}\n    PROPERTIES\n      FRAMEWORK TRUE\n      FRAMEWORK_VERSION A\n      MACOSX_FRAMEWORK_IDENTIFIER com.arrayfire.arrayfireFramework\n      #MACOSX_FRAMEWORK_INFO_PLIST Info.plist\n      #PUBLIC_HEADER \"${CMAKE_CURRENT_SOURCE_DIR}/include/arrayfire.h;${af_headers}\"\n      #XCODE_ATTRIBUTE_CODE_SIGN_IDENTITY \"iPhone Developer\"\n    )\nendif()\n\ninstall(DIRECTORY include/ DESTINATION ${AF_INSTALL_INC_DIR}\n    COMPONENT headers\n    FILES_MATCHING\n    PATTERN \"*.h\"\n    PATTERN \"*.hpp\"\n    PATTERN \".gitignore\" EXCLUDE\n)\n\n## The ArrayFire version file is generated and won't be included above, install\n## it separately.\ninstall(FILES ${ArrayFire_BINARY_DIR}/include/af/version.h\n              ${ArrayFire_BINARY_DIR}/include/af/compilers.h\n        DESTINATION \"${AF_INSTALL_INC_DIR}/af/\"\n        COMPONENT headers)\n\n# install the examples irrespective of the AF_BUILD_EXAMPLES value\n# only the examples source files are installed, so the installation of these\n# source files does not depend on AF_BUILD_EXAMPLES\n# when AF_BUILD_EXAMPLES is OFF, the examples source is installed without\n# building the example executables\ninstall(DIRECTORY examples/ #NOTE The slash at the end is important\n    DESTINATION ${AF_INSTALL_EXAMPLE_DIR}\n    COMPONENT examples)\n\ninstall(DIRECTORY ${ASSETS_DIR}/examples/ #NOTE The slash at the end is important\n    DESTINATION ${AF_INSTALL_EXAMPLE_DIR}\n    COMPONENT examples)\n\ninstall(DIRECTORY \"${ArrayFire_SOURCE_DIR}/LICENSES/\"\n    DESTINATION LICENSES\n    COMPONENT licenses)\n\nforeach(backend CPU CUDA OpenCL oneAPI Unified)\n  string(TOUPPER ${backend} upper_backend)\n  string(TOLOWER ${backend} lower_backend)\n  if(AF_BUILD_${upper_backend})\n    install(EXPORT ArrayFire${backend}Targets\n            NAMESPACE ArrayFire::\n            DESTINATION ${AF_INSTALL_CMAKE_DIR}\n            COMPONENT ${lower_backend}_dev)\n\n    export( EXPORT ArrayFire${backend}Targets\n            NAMESPACE ArrayFire::\n            FILE cmake/ArrayFire${backend}Targets.cmake)\n  endif()\nendforeach()\n\ninclude(CMakePackageConfigHelpers)\nwrite_basic_package_version_file(\n  \"${ArrayFire_BINARY_DIR}/ArrayFireConfigVersion.cmake\"\n  COMPATIBILITY SameMajorVersion\n)\n\n# This config file will be installed so we need to set the install_destination\n# path relitive to the install path\nset(INCLUDE_DIRS include)\nset(CMAKE_DIR ${AF_INSTALL_CMAKE_DIR})\nconfigure_package_config_file(\n  ${ArrayFire_SOURCE_DIR}/CMakeModules/ArrayFireConfig.cmake.in\n  cmake/install/ArrayFireConfig.cmake\n  INSTALL_DESTINATION \"${AF_INSTALL_CMAKE_DIR}\"\n  PATH_VARS INCLUDE_DIRS CMAKE_DIR\n  )\n\ninstall(FILES ${ArrayFire_BINARY_DIR}/cmake/install/ArrayFireConfig.cmake\n              ${ArrayFire_BINARY_DIR}/ArrayFireConfigVersion.cmake\n              DESTINATION ${AF_INSTALL_CMAKE_DIR}\n              COMPONENT cmake)\n\nif(BUILD_WITH_MKL AND AF_INSTALL_STANDALONE)\n  if(TARGET MKL::ThreadingLibrary)\n    get_filename_component(mkl_tl ${MKL_ThreadingLibrary_LINK_LIBRARY} REALPATH)\n    install(FILES\n      $<TARGET_FILE:MKL::ThreadingLibrary>\n      ${mkl_tl}\n      DESTINATION ${AF_INSTALL_LIB_DIR}\n      COMPONENT mkl_dependencies)\n  endif()\n\n  if(NOT AF_WITH_STATIC_MKL AND TARGET MKL::Shared)\n    if(NOT WIN32)\n      get_filename_component(mkl_int ${MKL_Interface_LINK_LIBRARY} REALPATH)\n      install(FILES\n        $<TARGET_FILE:MKL::Interface>\n        ${mkl_int}\n        DESTINATION ${AF_INSTALL_LIB_DIR}\n        COMPONENT mkl_dependencies)\n    endif()\n\n    get_filename_component(mkl_rnt ${MKL_RT_LINK_LIBRARY} REALPATH)\n    get_filename_component(mkl_shd ${MKL_Core_LINK_LIBRARY} REALPATH)\n    get_filename_component(mkl_tly ${MKL_ThreadLayer_LINK_LIBRARY} REALPATH)\n    install(FILES\n      ${mkl_rnt}\n      ${mkl_shd}\n      ${mkl_tly}\n      $<TARGET_FILE:MKL::RT>\n      $<TARGET_FILE:MKL::Shared>\n      $<TARGET_FILE:MKL::ThreadLayer>\n      ${MKL_RUNTIME_KERNEL_LIBRARIES}\n\n      # This variable is used to add tbb.so.2 library because the main lib\n      # is a linker script and not a symlink so it cant be resolved using\n      # get_filename_component\n      ${AF_ADDITIONAL_MKL_LIBRARIES}\n      DESTINATION ${AF_INSTALL_LIB_DIR}\n      COMPONENT mkl_dependencies)\n  endif()\nendif()\n\n# This file will be used to create the config file for the build directory.\n# These config files will be used by the examples to find the ArrayFire\n# libraries\nset(INCLUDE_DIRS \"${ArrayFire_SOURCE_DIR}/include\" \"${ArrayFire_BINARY_DIR}/include\")\nset(CMAKE_DIR \"${ArrayFire_BINARY_DIR}/cmake\")\nconfigure_package_config_file(\n  ${ArrayFire_SOURCE_DIR}/CMakeModules/ArrayFireConfig.cmake.in\n  ArrayFireConfig.cmake\n  INSTALL_DESTINATION \"${ArrayFire_BINARY_DIR}\"\n  PATH_VARS INCLUDE_DIRS CMAKE_DIR\n  INSTALL_PREFIX \"${ArrayFire_BINARY_DIR}\"\n  )\n\n# Registers the current build directory with the user's cmake config. This will\n# create a file at $HOME/.cmake/packages/ArrayFire which will point to this source\n# build directory.\n# TODO(umar): Disable for now. Causing issues with builds on windows.\n#export(PACKAGE ArrayFire)\n\n# Unset the visibility to avoid setting policy commands for older versions of\n# CMake for examples and tests.\nunset(CMAKE_CXX_VISIBILITY_PRESET)\n\nconfigure_file(\n  ${ArrayFire_SOURCE_DIR}/CMakeModules/CTestCustom.cmake\n  ${ArrayFire_BINARY_DIR}/CTestCustom.cmake)\n\ninclude(CTest)\n\n# Handle depricated BUILD_TEST variable if found.\nif(BUILD_TEST)\n  set(BUILD_TESTING ${BUILD_TEST})\nendif()\n\nconditional_directory(BUILD_TESTING test)\n\nconditional_directory(AF_BUILD_EXAMPLES examples)\nconditional_directory(AF_BUILD_DOCS docs)\n\ninclude(CPackConfig)\n\n# VCPKG variables that aren't necessarily important\n# for ArrayFire Development. They are marked hidden.\n# If VCPKG is not used, marking them is not harmful\nmark_as_advanced(\n  AF_BUILD_FRAMEWORK\n  AF_CACHE_KERNELS_TO_DISK\n  AF_INSTALL_STANDALONE\n  AF_WITH_CPUID\n  AF_WITH_LOGGING\n  AF_WITH_STACKTRACE\n  AF_WITH_STATIC_FREEIMAGE\n  AF_WITH_NONFREE\n  AF_WITH_IMAGEIO\n  AF_WITH_RELATIVE_TEST_DIR\n  AF_TEST_WITH_MTX_FILES\n  ArrayFire_DIR\n\n  VCPKG_APPLOCAL_DEPS\n  VCPKG_BOOTSTRAP_OPTIONS\n  VCPKG_INSTALL_OPTIONS\n  VCPKG_MANIFEST_DIR\n  VCPKG_MANIFEST_INSTALL\n  VCPKG_MANIFEST_MODE\n  VCPKG_OVERLAY_PORTS\n  VCPKG_OVERLAY_TRIPLETS\n  VCPKG_TARGET_TRIPLET\n  X_VCPKG_APPLOCAL_DEPS_INSTALL\n  X_VCPKG_APPLOCAL_DEPS_SERIALIZED\n  Z_VCPKG_BUILTIN_POWERSHELL_PATH\n  Z_VCPKG_PWSH_PATH\n  Z_VCPKG_CL\n  _VCPKG_INSTALLED_DIR\n\n  Boost_INCLUDE_DIR\n  CLEAR CUDA_VERSION\n  CUDA_HOST_COMPILER\n  CUDA_SDK_ROOT_DIR\n  CUDA_USE_STATIC_CUDA_RUNTIME\n  CUDA_rt_LIBRARY\n  SPDLOG_BUILD_EXAMPLES\n  SPDLOG_BUILD_TESTING\n  ADDR2LINE_PROGRAM\n  Backtrace_LIBRARY\n  AF_WITH_STATIC_MKL\n  GIT\n  Forge_DIR\n  glad_DIR\n  spdlog_DIR\n  FG_BUILD_OFFLINE\n  SPAN_LITE_COLOURISE_TEST\n  SPAN_LITE_EXPORT_PACKAGE\n  SPAN_LITE_OPT_BUILD_EXAMPLES\n  SPAN_LITE_OPT_BUILD_TESTS\n  SPAN_LITE_OPT_SELECT_NONSTD\n  SPAN_LITE_OPT_SELECT_STD\n  FETCHCONTENT_SOURCE_DIR_SPAN-LITE\n  SPDLOG_BUILD_ALL\n  SPDLOG_BUILD_BENCH\n  SPDLOG_BUILD_EXAMPLE\n  SPDLOG_BUILD_EXAMPLE_HO\n  SPDLOG_BUILD_SHARED\n  SPDLOG_BUILD_TESTS\n  SPDLOG_BUILD_TESTS_HO\n  SPDLOG_BUILD_WARNINGS\n  SPDLOG_CLOCK_COARSE\n  SPDLOG_DISABLE_DEFAULT_LOGGER\n  SPDLOG_ENABLE_PCH\n  SPDLOG_FMT_EXTERNAL\n  SPDLOG_FMT_EXTERNAL_HO\n  SPDLOG_INSTALL\n  SPDLOG_NO_ATOMIC_LEVELS\n  SPDLOG_NO_EXCEPTIONS\n  SPDLOG_NO_THREAD_ID\n  SPDLOG_NO_TLS\n  SPDLOG_PREVENT_CHILD_FD\n  SPDLOG_SANITIZE_ADDRESS\n  SPDLOG_TIDY\n  SPDLOG_WCHAR_FILENAMES\n  SPDLOG_WCHAR_SUPPORT\n  cub_include_dir\n  fmt_DIR\n  span-lite_DIR\n  )\n"
        },
        {
          "name": "CMakeModules",
          "type": "tree",
          "content": null
        },
        {
          "name": "CMakePresets.json",
          "type": "blob",
          "size": 8.5810546875,
          "content": "{\r\n  \"version\": 2,\r\n  \"cmakeMinimumRequired\": {\r\n    \"major\": 3,\r\n    \"minor\": 20,\r\n    \"patch\": 0\r\n  },\r\n  \"configurePresets\": [\r\n    {\r\n      \"name\": \"ninja-all-off-debug\",\r\n      \"hidden\": true,\r\n      \"description\": \"Base preset with all backends off with Debug build configuration\",\r\n      \"binaryDir\": \"${sourceDir}/build/${presetName}\",\r\n      \"generator\": \"Ninja\",\r\n      \"cacheVariables\": {\r\n        \"CMAKE_BUILD_TYPE\": {\r\n          \"type\": \"String\",\r\n          \"value\": \"Debug\"\r\n        },\r\n        \"AF_COMPUTE_LIBRARY\": {\r\n          \"type\": \"String\",\r\n          \"value\": \"Intel-MKL\"\r\n        },\r\n        \"AF_BUILD_CPU\": {\r\n          \"type\": \"BOOL\",\r\n          \"value\": \"OFF\"\r\n        },\r\n        \"AF_BUILD_CUDA\": {\r\n          \"type\": \"BOOL\",\r\n          \"value\": \"OFF\"\r\n        },\r\n        \"AF_BUILD_OPENCL\": {\r\n          \"type\": \"BOOL\",\r\n          \"value\": \"OFF\"\r\n        },\r\n        \"AF_BUILD_UNIFIED\": {\r\n          \"type\": \"BOOL\",\r\n          \"value\": \"OFF\"\r\n        },\r\n        \"AF_BUILD_FORGE\": {\r\n          \"type\": \"BOOL\",\r\n          \"value\": \"ON\"\r\n        },\r\n        \"AF_BUILD_DOCS\": {\r\n          \"type\": \"BOOL\",\r\n          \"value\": \"OFF\"\r\n        },\r\n        \"AF_BUILD_EXAMPLES\": {\r\n          \"type\": \"BOOL\",\r\n          \"value\": \"OFF\"\r\n        },\r\n        \"AF_TEST_WITH_MTX_FILES\": {\r\n          \"type\": \"BOOL\",\r\n          \"value\": \"OFF\"\r\n        },\r\n        \"CMAKE_INSTALL_PREFIX\": {\r\n          \"type\": \"PATH\",\r\n          \"value\": \"${sourceDir}/build/${presetName}/pkg\"\r\n        }\r\n      }\r\n    },\r\n    {\r\n      \"name\": \"ninja-cpu-mkl-debug\",\r\n      \"description\": \"Build CPU Backend using Intel MKL in Debug Configuration with Ninja Generator\",\r\n      \"inherits\": \"ninja-all-off-debug\",\r\n      \"cacheVariables\": {\r\n        \"AF_BUILD_CPU\": \"ON\"\r\n      }\r\n    },\r\n    {\r\n      \"name\": \"ninja-cpu-mkl-relwithdebinfo\",\r\n      \"description\": \"Build CPU Backend using Intel MKL in RelWithDebInfo Configuration with Ninja Generator\",\r\n      \"inherits\": \"ninja-cpu-mkl-debug\",\r\n      \"cacheVariables\": {\r\n        \"CMAKE_BUILD_TYPE\": \"RelWithDebInfo\"\r\n      }\r\n    },\r\n    {\r\n      \"name\": \"ninja-cpu-debug\",\r\n      \"description\": \"Build CPU Backend with FFTW and a BLAS library using Ninja Generator in Debug Configuration\",\r\n      \"inherits\": \"ninja-cpu-mkl-debug\",\r\n      \"cacheVariables\": {\r\n        \"AF_COMPUTE_LIBRARY\": \"FFTW/LAPCK/BLAS\"\r\n      }\r\n    },\r\n    {\r\n      \"name\": \"ninja-cpu-relwithdebinfo\",\r\n      \"description\": \"Build CPU Backend with FFTW and a BLAS library using Ninja Generator in RelWithDebInfo Configuration\",\r\n      \"inherits\": \"ninja-cpu-debug\",\r\n      \"cacheVariables\": {\r\n        \"CMAKE_BUILD_TYPE\": \"RelWithDebInfo\"\r\n      }\r\n    },\r\n    {\r\n      \"name\": \"ninja-cuda-debug\",\r\n      \"description\": \"Build CUDA Backend in debug configuration using Ninja Generator\",\r\n      \"inherits\": \"ninja-all-off-debug\",\r\n      \"cacheVariables\": {\r\n        \"AF_BUILD_CUDA\": \"ON\"\r\n      }\r\n    },\r\n    {\r\n      \"name\": \"ninja-cuda-relwithdebinfo\",\r\n      \"description\": \"Build CUDA Backend in RelWithDebInfo configuration using Ninja Generator\",\r\n      \"inherits\": \"ninja-cuda-debug\",\r\n      \"cacheVariables\": {\r\n        \"CMAKE_BUILD_TYPE\": \"RelWithDebInfo\"\r\n      }\r\n    },\r\n    {\r\n      \"name\": \"ninja-opencl-mkl-debug\",\r\n      \"description\": \"Build OpenCL Backend in debug configuration using Ninja Generator\",\r\n      \"inherits\": \"ninja-all-off-debug\",\r\n      \"cacheVariables\": {\r\n        \"AF_BUILD_OPENCL\": \"ON\"\r\n      }\r\n    },\r\n    {\r\n      \"name\": \"ninja-opencl-mkl-relwithdebinfo\",\r\n      \"description\": \"Build OpenCL Backend in RelWithDebInfo configuration using Ninja Generator. This preset uses Intel MKL for CPU fallback code.\",\r\n      \"inherits\": \"ninja-opencl-mkl-debug\",\r\n      \"cacheVariables\": {\r\n        \"CMAKE_BUILD_TYPE\": \"RelWithDebInfo\"\r\n      }\r\n    },\r\n    {\r\n      \"name\": \"ninja-opencl-debug\",\r\n      \"description\": \"Build OpenCL Backend in debug configuration using Ninja Generator\",\r\n      \"inherits\": \"ninja-opencl-mkl-debug\",\r\n      \"cacheVariables\": {\r\n        \"AF_COMPUTE_LIBRARY\": \"FFTW/LAPCK/BLAS\"\r\n      }\r\n    },\r\n    {\r\n      \"name\": \"ninja-opencl-relwithdebinfo\",\r\n      \"description\": \"Build OpenCL Backend in RelWithDebInfo configuration using Ninja Generator\",\r\n      \"inherits\": \"ninja-opencl-debug\",\r\n      \"cacheVariables\": {\r\n        \"CMAKE_BUILD_TYPE\": \"RelWithDebInfo\"\r\n      }\r\n    },\r\n    {\r\n        \"name\": \"ninja-all-mkl-debug\",\r\n        \"description\": \"Build all feasible backends using Ninja Generator in Debug Configuraiton\",\r\n        \"inherits\": \"ninja-all-off-debug\",\r\n        \"cacheVariables\": {\r\n            \"AF_BUILD_CPU\": \"ON\",\r\n            \"AF_BUILD_CUDA\": \"ON\",\r\n            \"AF_BUILD_OPENCL\": \"ON\",\r\n            \"AF_BUILD_UNIFIED\": \"ON\"\r\n        }\r\n    },\r\n    {\r\n        \"name\": \"ninja-all-mkl-relwithdebinfo\",\r\n        \"description\": \"Build all feasible backends using Ninja Generator in RelWithDebInfo Configuraiton\",\r\n        \"inherits\": \"ninja-all-mkl-debug\",\r\n        \"cacheVariables\": {\r\n            \"CMAKE_BUILD_TYPE\": \"RelWithDebInfo\"\r\n        }\r\n    },\r\n    {\r\n        \"name\": \"ninja-all-debug\",\r\n        \"description\": \"Build all feasible backends using Ninja Generator in Debug Configuraiton\",\r\n        \"inherits\": \"ninja-all-mkl-debug\",\r\n        \"cacheVariables\": {\r\n            \"AF_COMPUTE_LIBRARY\": \"FFTW/LAPCK/BLAS\"\r\n        }\r\n    },\r\n    {\r\n        \"name\": \"ninja-all-relwithdebinfo\",\r\n        \"description\": \"Build all feasible backends using Ninja Generator in RelWithDebInfo Configuraiton\",\r\n        \"inherits\": \"ninja-all-debug\",\r\n        \"cacheVariables\": {\r\n            \"CMAKE_BUILD_TYPE\": \"RelWithDebInfo\"\r\n        }\r\n    },\r\n    {\r\n        \"name\": \"ninja-all-mkl-local-install\",\r\n        \"description\": \"Build all feasible backends using Ninja Generator in RelWithDebInfo Configuraiton\",\r\n        \"inherits\": \"ninja-all-mkl-relwithdebinfo\",\r\n        \"cacheVariables\": {\r\n            \"BUILD_TESTING\": \"OFF\"\r\n        }\r\n    },\r\n    {\r\n        \"name\": \"ninja-all-mkl-standalone-install\",\r\n        \"description\": \"Build all feasible backends using Ninja Generator in RelWithDebInfo Configuraiton\",\r\n        \"inherits\": \"ninja-all-mkl-local-install\",\r\n        \"cacheVariables\": {\r\n            \"AF_INSTALL_STANDALONE\": \"ON\"\r\n        }\r\n    },\r\n    {\r\n      \"name\": \"ninja-docs\",\r\n      \"description\": \"Build ArrayFire Documentation, needs doxygen installed\",\r\n      \"inherits\": \"ninja-all-off-debug\",\r\n      \"cacheVariables\": {\r\n          \"BUILD_TESTING\": \"OFF\",\r\n          \"AF_BUILD_FORGE\": \"OFF\",\r\n          \"AF_BUILD_DOCS\": \"ON\"\r\n      }\r\n    },\r\n    {\r\n        \"name\": \"ninja-any-debug\",\r\n        \"description\": \"Build available backends in Debug configuration using Ninja Generator\",\r\n        \"binaryDir\": \"${sourceDir}/build/${presetName}\",\r\n        \"generator\": \"Ninja\",\r\n        \"cacheVariables\": {\r\n            \"CMAKE_BUILD_TYPE\": \"Debug\",\r\n            \"CMAKE_INSTALL_PREFIX\": \"${sourceDir}/build/${presetName}/pkg\"\r\n        }\r\n    },\r\n    {\r\n        \"name\": \"ninja-any-relwithdebinfo\",\r\n        \"description\": \"Build available backends in RelWithDebInfo configuration using Ninja Generator\",\r\n        \"inherits\": \"ninja-any-debug\",\r\n        \"cacheVariables\": {\r\n            \"CMAKE_BUILD_TYPE\": \"RelWithDebInfo\"\r\n        }\r\n    },\r\n    {\r\n      \"name\": \"msvc2019\",\r\n      \"hidden\": true,\r\n      \"description\": \"Base preset for Visual Studio 16 2019 generator.\",\r\n      \"generator\": \"Visual Studio 16 2019\",\r\n      \"architecture\": \"x64\"\r\n    },\r\n    {\r\n      \"name\": \"msvc2019-cpu-mkl\",\r\n      \"description\": \"Build CPU Backend using Intel MKL with MSVC 2019 Generator\",\r\n      \"inherits\": [ \"msvc2019\", \"ninja-cpu-mkl-debug\" ]\r\n    },\r\n    {\r\n      \"name\": \"msvc2019-cuda\",\r\n      \"description\": \"Build CUDA Backend with MSVC 2019 Generator\",\r\n      \"inherits\": [ \"msvc2019\", \"ninja-cuda-debug\" ]\r\n    },\r\n    {\r\n      \"name\": \"msvc2019-opencl-mkl\",\r\n      \"description\": \"Build OpenCL Backend with MSVC 2019 Generator. Uses MKL for CPU fallback.\",\r\n      \"inherits\": [ \"msvc2019\", \"ninja-opencl-mkl-debug\" ]\r\n    },\r\n    {\r\n      \"name\": \"msvc2019-all-mkl\",\r\n      \"description\": \"Build all feasible Backends with MSVC 2019 Generator. Uses MKL for CPU fallback.\",\r\n      \"inherits\": [ \"msvc2019\", \"ninja-all-mkl-debug\" ]\r\n    },\r\n    {\r\n      \"name\": \"msvc2019-all-mkl-local-install\",\r\n      \"description\": \"Build all feasible Backends with MSVC 2019 Generator. Installs to specified path prefix.\",\r\n      \"inherits\": [ \"msvc2019\", \"ninja-all-mkl-local-install\" ]\r\n    },\r\n    {\r\n      \"name\": \"msvc2019-all-mkl-standalone-install\",\r\n      \"description\": \"Build all feasible Backends with MSVC 2019 Generator. Also packages dependencies while installing to specified path prefix.\",\r\n      \"inherits\": [ \"msvc2019\", \"ninja-all-mkl-standalone-install\" ]\r\n    }\r\n  ]\r\n}\r\n"
        },
        {
          "name": "CONTRIBUTING.md",
          "type": "blob",
          "size": 2.134765625,
          "content": "# Contributing to ArrayFire #\n\n## Reporting Issues ##\n\nWe both value and encourage the community to provide feedback about using ArrayFire and the issues they are facing.\nThe more detailed the information, the easier it is for the developers to resolve the issue.\n\nIssues can span a variety of topics including:\n- Feature requests\n- Bug reports\n- Build Issues\n- Performance improvements\n- New hardware / backend support\n\nWe use the github [issue tracker](https://github.com/arrayfire/arrayfire/issues?state=open) to track our issues. Technical issues can also be discussed on our [user forum](https://groups.google.com/forum/#!forum/arrayfire-users).\n\n## Contributing Code ##\n\nIf you want to contribute code, we suggest you use the one of the following methods.\n\n- [Using Github](https://github.com/arrayfire/arrayfire/wiki/Contribute-code-using-github)\n- [Using Email](https://github.com/arrayfire/arrayfire/wiki/Contribute-code-using-email)\n\nKey areas of code contributions include:\n- [New features](https://github.com/arrayfire/arrayfire/issues?q=is%3Aopen+is%3Aissue+label%3Afeature)\n    - You can refer to [this](https://github.com/arrayfire/arrayfire/wiki/How-to-Add-a-New-Function-to-ArrayFire) wiki page to get started on how to add a new function to the library.\n- [Bug fixes](https://github.com/arrayfire/arrayfire/labels/bug)\n- [Style changes](https://github.com/arrayfire/arrayfire/labels/style)\n- [Performance improvements](https://github.com/arrayfire/arrayfire/labels/style)\n- [New tests](https://github.com/arrayfire/arrayfire/labels/test)\n- New examples!\n\n##ArrayFire Based Projects##\n\nYou can also contribute to ArrayFire by helping out projects that use ArrayFire! For our part, in addition to the ArrayFire library we are also in the process of adding native bindings for numerous language. We currently support\n\n- [Java](https://github.com/arrayfire/arrayfire_java)\n- [R](https://github.com/arrayfire/arrayfire_r)\n- [Fortran](https://github.com/arrayfire/arrayfire_fortran)\n\nIf you are experienced in any of these languages, you can help us improve these language bindings. If you prefer a different language that is not in the list, dive in and create a new repo!\n"
        },
        {
          "name": "COPYRIGHT.md",
          "type": "blob",
          "size": 5.88671875,
          "content": "Copyrights\n==========================================\n##Index\n* [ArrayFire](#arrayfire)\n* [ArrayFire: SIFT](#arrayfire-sift)\n* [FreeImage](#freeimage)\n* [clBLAS](#clblas)\n* [clFFT](#clfft)\n* [Random123](#random123)\n* [Boost Compute](#boost-compute)\n* [Thrust](#thrust)\n* [Magma](#magma)\n* [glbinding](#glbinding)\n\n### Introduction\nArrayFire uses software written by the following parties. Each software is listed with its copyright, license and home page.\n\nAll the licenses can be found in the LICENSES directory.\n\n### ArrayFire\nCopyright (C) 2014-2015, ArrayFire.\n\nArrayFire is distributed under the BSD 3-Clause License. A copy of this license is present in the LICENSES directory.\n\nSee ArrayFire home page https://github.com/arrayfire/arrayfire for details and links to the source code.\n\n### ArrayFire: SIFT\nCopyright (C) 2014-2015, ArrayFire.\n\nCopyright (c) 2006-2012, Rob Hess <rob@iqengines.com>\n\nArrayFire SIFT is based on the OpenSIFT project by Rob Hess, licensed and distributed under the BSD 3-Clause License. A full copy of the license is present in the LICENSES directory.\n\nSIFT is an algorithm patented and protected by US Law under the US Patent 6,711,293 (March 23, 2004) assigned to the University of British Columbia. before using this code or any binary forms generated from it, please verify that you have permission to do so.\n\n### FreeImage\nCopyright (C) 2014-2015, FreeImage.\n\nFreeImage is distributed under the FreeImage Public License (FIPL) version 1.0. A copy of this license is present in the LICENSES directory.\n\nSee FreeImage home page http://freeimage.sourceforge.net/ for details and links to the source code.\n\n**How ArrayFire uses FreeImage:** The ArrayFire source code does not contain any source code from FreeImage. FreeImage can be optionally linked with or disabled during build time. The binary installers of ArrayFire may come packaged with FreeImage.\n\n### clBLAS\nCopyright (C) 2013-2015 Advanced Micro Devices, Inc.\nThis product includes software developed at Advanced Micro Devices, Inc. (http://www.amd.com).\n\nclBLAS is distributed under the Apache License Version 2.0 License. A copy of this license is present in the LICENSES directory.\n\nSee clBLAS home page https://github.com/clMathLibraries/clBLAS for details and links to the source code.\n\n**How ArrayFire uses clBLAS:** The ArrayFire source code does not contain any source code from clBLAS. clBLAS is statically linked during build time when building OpenCL backend.\n\n### clFFT\nCopyright (C) 2013-2015 Advanced Micro Devices, Inc.\nThis product includes software developed at Advanced Micro Devices, Inc. (http://www.amd.com).\n\nclFFT is distributed under the Apache License Version 2.0 License. A copy of this license is present in the LICENSES directory.\n\nSee clFFT home page https://github.com/clMathLibraries/clBLAS for details and links to the source code.\n\n**How ArrayFire uses clFFT:** The ArrayFire source code does not contain any source code from clFFT. clFFT is statically linked during build time when building OpenCL backend.\n\n### Random123\nCopyright (C) 2010-2015, D. E. Shaw Research.\n\nRandom123 is distributed under the BSD 3-Clause License. A copy of this license is present in the LICENSES directory.\n\nSee Random123 home page https://www.deshawresearch.com/resources_random123.html for details and links to the source code.\n\n**How ArrayFire uses Random123:** ArrayFire uses a modified and stripped down version of Random123 in all backends. Each of the source files using the modified version of Random123 contain the original copyright.\n\n### Boost Compute\nCopyright (C) 2013-2015 Kyle Lutz\n\nBoost Compute is distributed under the Boost Software License, Version 1.0 License. A copy of this license is present in the LICENSES directory.\n\nSee Boost Compute home page https://github.com/boostorg/compute for details and links to the source code.\n\n**How ArrayFire uses Boost Compute:** The ArrayFire source code does not contain any source code from Boost Compute. Boost Compute header files are optionally required to build the OpenCL backend.\n\n### Thrust\nCopyright (C) 2011-2015 NVIDIA Corporation.\n\nThrust is distributed under the Apache License Version 2.0 License. A copy of this license is present in the LICENSES directory.\n\nSee Thrust home page https://github.com/thrust/thrust for details and links to the source code.\n\n**How ArrayFire uses Thrust:** The ArrayFire source code does not contain any source code from Thrust. Thrust header files are optionally required to build the CUDA backend.\n\n### clMagma\nCopyright (C) 2015 The University of Tennessee.\n\nclMagma is distributed under the BSD 3-Clause License. A copy of this license is present in the LICENSES directory.\n\nSee clMagma home page http://icl.cs.utk.edu/magma/index.html for details and links to the source code.\n\n**How ArrayFire uses clMagma:** ArrayFire uses a modified and stripped down version of clMagma in the OpenCL backend. Each of the source files using the modified version of clMagma contain the original copyright.\n\n### GLFW\nCopyright (C) 2002-2006 Marcus Geelnard\nCopyright (C) 2006-2011 Camilla Berglund\n\nGLFW is distributed under the zlib/libpng License. A copy of this license is present in the LICENSES directory.\n\nSee GLFW home page http://www.glfw.org for details and links to the source code.\n\n**How ArrayFire uses GLFW:** The ArrayFire source code does not contain any source code from GLFW. GLFW can be optionally linked with or disabled during build time. The binary installers of ArrayFire may come packaged with GLFW.\n\n### glbinding\n\nCopyright (c) 2014-2015 Computer Graphics Systems Group at the Hasso-Plattner-Institute and CG Internals GmbH, Germany.\n\nglbinding is distributed under the MIT License. A copy of this license is present in the LICENSES directory.\n\nSee glbinding home page http://www.glbinding.org for details and links to the source code.\n\n**How ArrayFire uses glbinding:** The ArrayFire source code does not contain any source code from glbinding. glbinding is statically linked during build time.\n\n\n"
        },
        {
          "name": "CTestConfig.cmake",
          "type": "blob",
          "size": 0.52734375,
          "content": "## This file should be placed in the root directory of your project.\n## Then modify the CMakeLists.txt file in the root directory of your\n## project to incorporate the testing dashboard.\n## # The following are required to uses Dart and the Cdash dashboard\n##   ENABLE_TESTING()\n##   INCLUDE(CTest)\nset(CTEST_PROJECT_NAME \"ArrayFire\")\nset(CTEST_NIGHTLY_START_TIME \"01:00:00 UTC\")\n\nset(CTEST_DROP_METHOD \"https\")\nset(CTEST_DROP_SITE \"ci.arrayfire.org\")\nset(CTEST_DROP_LOCATION \"/submit.php?project=ArrayFire\")\nset(CTEST_DROP_SITE_CDASH TRUE)\n"
        },
        {
          "name": "LICENSE",
          "type": "blob",
          "size": 1.43359375,
          "content": "Copyright (c) 2014-2022, ArrayFire\nAll rights reserved.\n\nRedistribution and use in source and binary forms, with or without modification, are permitted provided that the following conditions are met:\n\n* Redistributions of source code must retain the above copyright notice, this list of conditions and the following disclaimer.\n\n* Redistributions in binary form must reproduce the above copyright notice, this list of conditions and the following disclaimer in the documentation and/or other materials provided with the distribution.\n\n* Neither the name ArrayFire nor the names of its contributors may be used to endorse or promote products derived from this software without specific prior written permission.\n\nTHIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS \"AS IS\" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n"
        },
        {
          "name": "LICENSES",
          "type": "tree",
          "content": null
        },
        {
          "name": "README.md",
          "type": "blob",
          "size": 8.7509765625,
          "content": "<p align=\"center\"><a href=\"http://arrayfire.com/\"><img src=\"http://arrayfire.com/logos/arrayfire_logo_whitebkgnd.png\" width=\"800\"></a></p>\n\nArrayFire is a general-purpose tensor library that simplifies the software\ndevelopment process for the parallel architectures found in CPUs, GPUs, and\nother hardware acceleration devices. The library serves users in every\ntechnical computing market.\n\nSeveral of ArrayFire's benefits include:\n\n* Hundreds of accelerated [tensor computing\n  functions](https://arrayfire.org/docs/group__arrayfire__func.htm), in the\n  following areas:\n    * Array handling\n    * Computer vision\n    * Image processing\n    * Linear algebra\n    * Machine learning\n    * Standard math\n    * Signal Processing\n    * Statistics\n    * Vector algorithms\n* [Easy to use](http://arrayfire.org/docs/gettingstarted.htm), stable,\n  [well-documented](http://arrayfire.org/docs) API\n* Rigorous benchmarks and tests ensuring top performance and numerical accuracy\n* Cross-platform compatibility with support for CUDA, oneAPI, OpenCL, and\n  native CPU on Windows, Mac, and Linux\n* Built-in visualization functions through\n  [Forge](https://github.com/arrayfire/forge)\n* Commercially friendly open-source licensing\n* Enterprise support from [ArrayFire](http://arrayfire.com)\n\nArrayFire provides software developers with a high-level abstraction of data\nthat resides on the accelerator, the `af::array` object. Developers write code\nthat performs operations on ArrayFire arrays, which, in turn, are automatically\ntranslated into near-optimal kernels that execute on the computational device.\n\nArrayFire runs on devices ranging from low-power mobile phones to high-power\nGPU-enabled supercomputers. ArrayFire runs on CPUs from all major vendors\n(Intel, AMD, ARM), GPUs from the prominent manufacturers (AMD, Intel, NVIDIA,\nand Qualcomm), as well as a variety of other accelerator devices on Windows,\nMac, and Linux.\n\n# Getting ArrayFire\n\nInstructions to [install][32] or to build ArrayFire from source can be found on\nthe [wiki][1].\n\n### Conway's Game of Life Using ArrayFire\n\nVisit the [Wikipedia page][2] for a description of Conway's Game of Life.\n\n<img align=\"left\"\nsrc=\"https://github.com/arrayfire/assets/blob/master/gifs/conway.gif\"\nalt=\"Conway's Game of Life\" height=\"256\" width=\"256\">\n\n```cpp\nstatic const float h_kernel[] = { 1, 1, 1, 1, 0, 1, 1, 1, 1 };\nstatic const array kernel(3, 3, h_kernel, afHost);\n\narray state = (randu(128, 128, f32) > 0.5).as(f32); // Init state\nWindow myWindow(256, 256);\nwhile(!myWindow.close()) {\n    array nHood = convolve(state, kernel); // Obtain neighbors\n    array C0 = (nHood == 2);  // Generate conditions for life\n    array C1 = (nHood == 3);\n    state = state * C0 + C1;  // Update state\n    myWindow.image(state);    // Display\n}\n```\nThe complete source code can be found [here][3].\n\n### Perceptron\n\n<img align=\"left\"\nsrc=\"https://github.com/arrayfire/assets/blob/imgs_readme_improv/gifs/perceptron.gif\"\nalt=\"Perceptron\" height=\"400\" width=\"300\">\n\n```cpp\narray predict(const array &X, const array &W) {\n    return sigmoid(matmul(X, W));\n}\n\narray train(const array &X, const array &Y,\n        double alpha = 0.1, double maxerr = 0.05,\n        int maxiter = 1000, bool verbose = false) {\n    array Weights = constant(0, X.dims(1), Y.dims(1));\n\n    for (int i = 0; i < maxiter; i++) {\n        array P   = predict(X, Weights);\n        array err = Y - P;\n        if (mean<float>(abs(err) < maxerr) break;\n        Weights += alpha * matmulTN(X, err);\n    }\n    return Weights;\n}\n...\n\narray Weights = train(train_feats, train_targets);\narray test_outputs  = predict(test_feats, Weights);\ndisplay_results<true>(test_images, test_outputs,\n                      test_targets, 20);\n```\n\nThe complete source code can be found [here][31].\n\nFor more code examples, visit the [`examples/`][4] directory.\n\n# Documentation\n\nYou can find the complete documentation [here](http://www.arrayfire.com/docs/index.htm).\n\nQuick links:\n\n* [List of functions](http://www.arrayfire.org/docs/group__arrayfire__func.htm)\n* [Tutorials](http://arrayfire.org/docs/tutorials.htm)\n* [Examples](http://www.arrayfire.org/docs/examples.htm)\n* [Blog](http://arrayfire.com/blog/)\n\n# Language support\n\nArrayFire has several official and community maintained language API's:\n\n[![C++][5]][6] [![Python][7]][8] [![Rust][9]][10] [![Julia][27]][28]<sub><span>&#8224;</span></sub>\n[![Nim][29]][30]<sub><span>&#8224;</span></sub>\n\n<sup><span>&#8224;</span></sup>&nbsp; Community maintained wrappers\n\n__In-Progress Wrappers__\n\n[![.NET][11]][12] [![Fortran][13]][14] [![Go][15]][16]\n[![Java][17]][18] [![Lua][19]][20] [![NodeJS][21]][22] [![R][23]][24] [![Ruby][25]][26]\n\n# Contributing\n\nThe community of ArrayFire developers invites you to build with us if you are\ninterested and able to write top-performing tensor functions. Together we can\nfulfill [The ArrayFire\nMission](https://github.com/arrayfire/arrayfire/wiki/The-ArrayFire-Mission-Statement)\nfor fast scientific computing for all.\n\nContributions of any kind are welcome! Please refer to [the\nwiki](https://github.com/arrayfire/arrayfire/wiki) and our [Code of\nConduct](33) to learn more about how you can get involved with the ArrayFire\nCommunity through\n[Sponsorship](https://github.com/arrayfire/arrayfire/wiki/Sponsorship),\n[Developer\nCommits](https://github.com/arrayfire/arrayfire/wiki/Contributing-Code-to-ArrayFire),\nor [Governance](https://github.com/arrayfire/arrayfire/wiki/Governance).\n\n# Citations and Acknowledgements\n\nIf you redistribute ArrayFire, please follow the terms established in [the\nlicense](LICENSE). If you wish to cite ArrayFire in an academic publication,\nplease use the following [citation document](.github/CITATION.md).\n\nArrayFire development is funded by AccelerEyes LLC and several third parties,\nplease see the list of [acknowledgements](ACKNOWLEDGEMENTS.md) for an\nexpression of our gratitude.\n\n# Support and Contact Info\n\n* [Slack Chat](https://join.slack.com/t/arrayfire-org/shared_invite/MjI4MjIzMDMzMTczLTE1MDI5ODg4NzYtN2QwNGE3ODA5OQ)\n* [Google Groups](https://groups.google.com/forum/#!forum/arrayfire-users)\n* ArrayFire Services:  [Consulting](http://arrayfire.com/consulting)  |  [Support](http://arrayfire.com/download)   |  [Training](http://arrayfire.com/training)\n\n# Trademark Policy\n\nThe literal mark \"ArrayFire\" and ArrayFire logos are trademarks of AccelerEyes\nLLC (dba ArrayFire). If you wish to use either of these marks in your own\nproject, please consult [ArrayFire's Trademark\nPolicy](http://arrayfire.com/trademark-policy/)\n\n[1]: https://github.com/arrayfire/arrayfire/wiki\n[2]: https://en.wikipedia.org/wiki/Conway%27s_Game_of_Life\n[3]: https://github.com/arrayfire/arrayfire/blob/master/examples/graphics/conway_pretty.cpp\n[4]: https://github.com/arrayfire/arrayfire/blob/master/examples/\n[5]: https://img.shields.io/badge/c++-%2300599C.svg?style=for-the-badge&logo=c%2B%2B&logoColor=white\n[6]: http://arrayfire.org/docs/gettingstarted.htm#gettingstarted_api_usage\n[7]: https://img.shields.io/badge/python-%2314354C.svg?style=for-the-badge&logo=python&logoColor=white\n[8]: https://github.com/arrayfire/arrayfire-python\n[9]: https://img.shields.io/badge/rust-%23000000.svg?style=for-the-badge&logo=rust&logoColor=white\n[10]: https://github.com/arrayfire/arrayfire-rust\n[11]: https://img.shields.io/badge/.NET-5C2D91?style=for-the-badge&logo=.net&logoColor=white\n[12]: https://github.com/arrayfire/arrayfire-dotnet\n[13]: https://img.shields.io/badge/F-Fortran-734f96?style=for-the-badge\n[14]: https://github.com/arrayfire/arrayfire-fortran\n[15]: https://img.shields.io/badge/go-%2300ADD8.svg?style=for-the-badge&logo=go&logoColor=white\n[16]: https://github.com/arrayfire/arrayfire-go\n[17]: https://img.shields.io/badge/java-%23ED8B00.svg?style=for-the-badge&logo=java&logoColor=white\n[18]: https://github.com/arrayfire/arrayfire-java\n[19]: https://img.shields.io/badge/lua-%232C2D72.svg?style=for-the-badge&logo=lua&logoColor=white\n[20]: https://github.com/arrayfire/arrayfire-lua\n[21]: https://img.shields.io/badge/javascript-%23323330.svg?style=for-the-badge&logo=javascript&logoColor=%23F7DF1E\n[22]: https://github.com/arrayfire/arrayfire-js\n[23]: https://img.shields.io/badge/r-%23276DC3.svg?style=for-the-badge&logo=r&logoColor=white\n[24]: https://github.com/arrayfire/arrayfire-r\n[25]: https://img.shields.io/badge/ruby-%23CC342D.svg?style=for-the-badge&logo=ruby&logoColor=white\n[26]: https://github.com/arrayfire/arrayfire-rb\n[27]: https://img.shields.io/badge/j-Julia-cb3c33?style=for-the-badge&labelColor=4063d8\n[28]: https://github.com/JuliaComputing/ArrayFire.jl\n[29]: https://img.shields.io/badge/n-Nim-000000?style=for-the-badge&labelColor=efc743\n[30]: https://github.com/bitstormGER/ArrayFire-Nim\n[31]: https://github.com/arrayfire/arrayfire/blob/master/examples/machine_learning/perceptron.cpp\n[32]: https://github.com/arrayfire/arrayfire/wiki/Getting-ArrayFire\n[33]: https://github.com/arrayfire/arrayfire/wiki/Code-Of-Conduct\n"
        },
        {
          "name": "conanfile.py",
          "type": "blob",
          "size": 4.73828125,
          "content": "from conans import ConanFile, CMake, tools\nimport os\n\n\nARRAYFIRE_VERSION = \"3.7.1\"\nBINARY_INSTALLER_NAME_SUFFIX = \"-1\"\nBINARY_INSTALLER_NAME = f\"ArrayFire-v{ARRAYFIRE_VERSION}{BINARY_INSTALLER_NAME_SUFFIX}_Linux_x86_64.sh\"\nCUDA_TOOLKIT_VERSION = \"10.0\"\n\nclass ArrayFireConan(ConanFile):\n    name = \"arrayfire\"\n    version = ARRAYFIRE_VERSION\n    license = \"BSD\"\n    author = \"jacobkahn jacobkahn1@gmail.com\"\n    url = \"https://github.com/arrayfire/arrayfire\"\n    requires = []\n    description = \"ArrayFire: a general purpose GPU library\"\n    topics = (\"arrayfire\", \"gpu\", \"cuda\", \"opencl\", \"gpgpu\",\n              \"hpc\", \"performance\", \"scientific-computing\")\n    settings = \"os\", \"compiler\", \"build_type\", \"arch\"\n    options = {\n        \"cpu_backend\": [True, False],\n        \"cuda_backend\": [True, False],\n        \"opencl_backend\": [True, False],\n        \"unified_backend\": [True, False],\n        \"graphics\": [True, False],\n    }\n    generators = \"cmake\"  # unused\n\n    def configure(self):\n        if self.settings.os == \"Windows\":\n            raise ConanInvalidConfiguration(\n                \"Linux binary installer not compaible with Windows.\")\n\n    def requirements(self):\n        if self.options.graphics:\n            self.requires('glfw/3.3.2@bincrafters/stable')\n\n    def _download_arrayfire(self):\n        self.af_installer_local_path = BINARY_INSTALLER_NAME\n        if not os.path.exists(self.af_installer_local_path):\n            self.output.info(\n                f\"Downloading the ArrayFire {ARRAYFIRE_VERSION} binary installer...\")\n            tools.download(\n                f\"https://arrayfire.s3.amazonaws.com/{ARRAYFIRE_VERSION}/{BINARY_INSTALLER_NAME}\", self.af_installer_local_path)\n            self.output.success(\n                f\"ArrayFire {ARRAYFIRE_VERSION} binary installer successfully downloaded to {self.af_installer_local_path}\")\n        else:\n            self.output.info(\n                f\"ArrayFire {ARRAYFIRE_VERSION} binary installer already exists - skipping download.\")\n\n    def _unpack_arrayfire(self):\n        if not os.path.exists(self.af_unpack_path):\n            os.mkdir(self.af_unpack_path)\n        self.output.info(\n            f\"Unpacking ArrayFire {ARRAYFIRE_VERSION} binary installer...\")\n        cmd = f\"bash {self.af_installer_local_path} --prefix={self.af_unpack_path} --skip-license\"\n        self.run(cmd)\n        self.output.success(\n            f\"ArrayFire {ARRAYFIRE_VERSION} successfully unpacked.\")\n\n    def _process_arrayfire(self):\n        # Install ArrayFire to requisite path\n        self.af_unpack_path = os.path.join(self.source_folder, 'arrayfire')\n\n        # Only proceed if missing\n        if os.path.exists(os.path.join(self.af_unpack_path, 'include', 'arrayfire.h')):\n            self.output.info(\n                f\"ArrayFire {ARRAYFIRE_VERSION} already unpacked - skipping.\")\n        else:\n            self._download_arrayfire()\n            self._unpack_arrayfire()\n\n    def build(self):\n        self._process_arrayfire()\n\n    def package(self):\n        # libs\n        self.copy(\"*.so\", dst=\"lib\", keep_path=False, symlinks=True)\n        self.copy(\"*.so.*\", dst=\"lib\", keep_path=False, symlinks=True)\n\n        # headers\n        self.copy(\"*.h\", dst=\"include\", src=\"arrayfire/include\")\n        self.copy(\"*.hpp\", dst=\"include\", src=\"arrayfire/include\")\n\n    def package_info(self):\n        self.cpp_info.libs = []\n        if self.options.unified_backend:\n            self.cpp_info.libs.extend([\n                f\"libaf.so.{ARRAYFIRE_VERSION}\",\n            ])\n        if self.options.graphics:\n            self.cpp_info.libs.extend([\n                \"libforge.so.1.0.5\",\n            ])\n        if self.options.cuda_backend:\n            self.cpp_info.libs.extend([\n                f\"libafcuda.so.{ARRAYFIRE_VERSION}\",\n                \"libnvrtc-builtins.so\",\n                f\"libcudnn.so.{CUDA_TOOLKIT_VERSION}\",\n                f\"libcusparse.so.{CUDA_TOOLKIT_VERSION}\",\n                f\"libcublas.so.{CUDA_TOOLKIT_VERSION}\",\n                f\"libcusolver.so.{CUDA_TOOLKIT_VERSION}\",\n                f\"libnvrtc.so.{CUDA_TOOLKIT_VERSION}\",\n                f\"libcufft.so.{CUDA_TOOLKIT_VERSION}\",\n            ])\n        if self.options.cpu_backend:\n            self.cpp_info.libs.extend([\n                f\"libafcpu.so.{ARRAYFIRE_VERSION}\",\n                \"libmkl_avx2.so\",\n                \"libmkl_mc.so\",\n                \"libmkl_intel_lp64.so\",\n                \"libmkl_core.so\",\n                \"libmkl_avx.so\",\n                \"libmkl_def.so\",\n                \"libiomp5.so\",\n                \"libmkl_avx512.so\",\n                \"libmkl_intel_thread.so\",\n                \"libmkl_mc3.so\",\n\n            ])\n        if self.options.opencl_backend:\n            self.cpp_info.libs.extend([\n                f\"libafopencl.so.{ARRAYFIRE_VERSION}\",\n                \"libOpenCL.so.1\",\n            ])\n"
        },
        {
          "name": "docs",
          "type": "tree",
          "content": null
        },
        {
          "name": "examples",
          "type": "tree",
          "content": null
        },
        {
          "name": "extern",
          "type": "tree",
          "content": null
        },
        {
          "name": "include",
          "type": "tree",
          "content": null
        },
        {
          "name": "src",
          "type": "tree",
          "content": null
        },
        {
          "name": "test",
          "type": "tree",
          "content": null
        },
        {
          "name": "vcpkg.json",
          "type": "blob",
          "size": 2.41796875,
          "content": "{\n    \"name\": \"arrayfire\",\n    \"version\": \"3.9.0\",\n    \"homepage\": \"https://github.com/arrayfire/arrayfire\",\n    \"description\": \"ArrayFire is a HPC general-purpose library targeting parallel and massively-parallel architectures such as CPUs, GPUs, etc.\",\n    \"supports\": \"x64\",\n    \"dependencies\": [\n        \"boost-math\",\n        \"boost-stacktrace\",\n        \"spdlog\",\n        \"freeimage\",\n        \"span-lite\"\n    ],\n    \"overrides\": [\n        {\n            \"name\": \"fmt\",\n            \"version\": \"8.1.1\"\n        },\n        {\n            \"name\": \"spdlog\",\n            \"version\": \"1.9.2\"\n        },\n        {\n            \"name\": \"jasper\",\n            \"version\": \"4.2.0\"\n        },\n        {\n            \"name\": \"boost-modular-build-helper\",\n            \"version\": \"1.84.0#3\"\n        }\n    ],\n    \"features\": {\n        \"tests\": {\n            \"description\": \"Build with tests\",\n            \"dependencies\": [\n                \"gtest\"\n            ]\n        },\n        \"forge\": {\n            \"description\": \"Build Forge\",\n            \"dependencies\": [\n                {\n                    \"name\": \"freetype\",\n                    \"default-features\": false\n                },\n                {\n                    \"name\": \"fontconfig\",\n                    \"platform\": \"!windows\"\n                },\n                \"glfw3\",\n                \"glad\"\n            ]\n        },\n        \"openblasfftw\": {\n            \"description\": \"Build with OpenBLAS/FFTW\",\n            \"dependencies\": [\n                {\n                    \"name\": \"fftw3\",\n                    \"features\": [ \"threads\" ]\n                },\n                {\n                    \"name\": \"openblas\",\n                    \"features\": [ \"threads\" ]\n                },\n                \"lapack\"\n            ]\n        },\n        \"cuda\": {\n            \"description\": \"Build CUDA backend\",\n            \"dependencies\": [\n                \"cuda\"\n            ]\n        },\n        \"opencl\": {\n            \"description\": \"Build OpenCL backend\",\n            \"dependencies\": [\n                \"boost-compute\",\n                \"opencl\"\n            ]\n        },\n        \"mkl\": {\n            \"description\": \"Build with MKL\",\n            \"dependencies\": [\n                \"intel-mkl\"\n            ]\n        },\n        \"cudnn\": {\n            \"description\": \"Build CUDA with support for cuDNN\",\n            \"dependencies\": [\n                \"cudnn\"\n            ]\n        }\n    },\n    \"builtin-baseline\": \"9d47b24eacbd1cd94f139457ef6cd35e5d92cc84\"\n}\n"
        }
      ]
    }
  ]
}