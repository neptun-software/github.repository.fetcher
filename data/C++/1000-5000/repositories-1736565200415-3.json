{
  "metadata": {
    "timestamp": 1736565200415,
    "page": 3,
    "hasNextPage": true,
    "endCursor": "Y3Vyc29yOjEw",
    "completionStatus": "IN_PROGRESS"
  },
  "repositories": [
    {
      "nameWithOwner": "XiaoMi/mace",
      "stars": 4985,
      "defaultBranch": "master",
      "files": [
        {
          "name": ".bazelrc",
          "type": "blob",
          "size": 0.1181640625,
          "content": "# To support new bazelrc file list:\n# https://github.com/bazelbuild/bazel/issues/4502 \nimport %workspace%/tools/bazel.rc\n"
        },
        {
          "name": ".bazelversion",
          "type": "blob",
          "size": 0.005859375,
          "content": "0.13.0"
        },
        {
          "name": ".clang-format",
          "type": "blob",
          "size": 0.1201171875,
          "content": "BasedOnStyle: google\nMaxEmptyLinesToKeep: 3\nDerivePointerAlignment: false\nPointerAlignment: Right\nBinPackParameters: false\n"
        },
        {
          "name": ".gitignore",
          "type": "blob",
          "size": 0.611328125,
          "content": "bazel-*\nbuild/*\ncmake-build/\ncmake-build-debug/\ndocs/_build/\n\n.idea/\n.vscode/\ntags\n\n\\.project/\n*swp\n*~\n*.pyc\n.python-version\n\nmace/codegen/models/\nmace/codegen/opencl/\nmace/codegen/opencl_bin/\nmace/codegen/tuning/\nmace/codegen/version/\nmace/codegen/engine/\nmace/codegen/lib/\n\nexamples/android/macelibrary/src/main/cpp/mace/\nexamples/android/macelibrary/src/main/cpp/include/\nexamples/android/macelibrary/src/main/cpp/lib/arm64-v8a/\nexamples/android/macelibrary/src/main/jniLibs/arm64-v8a/\n\ntools/python/py_proto/*_pb2.py\n\nmicro/codegen/**\nmicro/examples/micro\nmicro/build\n\nmace-models\n\n__pycache__\n*.egg-info\n.mace_run\n.model\n"
        },
        {
          "name": ".gitlab-ci-new.yml",
          "type": "blob",
          "size": 9.021484375,
          "content": "stages:\n  - .pre\n  - linting\n  - build\n  - test\n  - benchmark\n  - model_validate\n  - .post\n\nvariables:\n  MI_9_SE: 22927ca0\n  REDMI_K30_PRO:  1a6be0d8\n  MI_NOTE_3: f13dacf7\n  SIRIUS: aa52c843\n  ANDROID_NDK_HOME: /opt/android-ndk-r17b\n  IMAGE_TAG_VERSION: tmp\n\nclean-device-workspace:\n  stage: .pre\n  tags:\n     - mace-host\n  image: cr.d.xiaomi.net/zhangzhimin1/mace-dev2:$IMAGE_TAG_VERSION\n  only:\n    - schedule\n  script:\n    - adb -s $REDMI_K30_PRO shell \"rm -rf /data/local/tmp/*\"\n\ncheck-env:\n  stage: .pre\n  tags:\n    - mace-host\n  image: cr.d.xiaomi.net/zhangzhimin1/mace-dev2:$IMAGE_TAG_VERSION\n  script:\n    - adb devices\n    - ls -lh ~/.ssh\n    - ssh pi@10.221.225.200 echo \"Hi, This is raspberrypi\"\n\ncpplint:\n  stage: linting\n  image: cr.d.xiaomi.net/zhangzhimin1/mace-dev2:$IMAGE_TAG_VERSION\n  script:\n    - sh tools/cpplint.sh\n\npylint:\n  stage: linting\n  image: cr.d.xiaomi.net/zhangzhimin1/mace-dev2:$IMAGE_TAG_VERSION\n  script:\n    - pycodestyle . --filename=*.py --exclude=examples,third_party\n\nbuild_docs:\n  stage: build\n  image: cr.d.xiaomi.net/zhangzhimin1/mace-dev2:$IMAGE_TAG_VERSION\n  when: manual\n  script:\n    - cd docs && make html\n  artifacts:\n    paths:\n      - docs/_build\n\nlinux-x64:build:\n  image: cr.d.xiaomi.net/zhangzhimin1/mace-dev2:$IMAGE_TAG_VERSION\n  stage: build\n  artifacts:\n    paths:\n      - build/cmake-build/host/install\n  script:\n    - RUNTIME=CPU QUANTIZE=ON tools/cmake/cmake-build-host.sh\n\nlinux-x64:test:\n  image: cr.d.xiaomi.net/zhangzhimin1/mace-dev2:$IMAGE_TAG_VERSION\n  stage: test\n  needs:\n    - \"linux-x64:build\"\n  dependencies:\n    - \"linux-x64:build\"\n  script:\n    - ls build -lh\n    - ./build/cmake-build/host/install/bin/mace_cc_test host/install/bin/mace_cc_test  --gtest_filter=*:-*GPU*:*OPENCL*:*Quant*:*OpenCL*:*DepthwiseDeconv2dOpTest*:*EltwiseOpTest*:*FullyConnectedOpTest*:*Gather*:*CPUFall*:*PadTest*:*QUANT*:*SpaceToBatchTest*:*BiasAddSimple2DCPU*:*Conv2dOpTest*\n\nlinux-x64:model_validate:\n  stage: model_validate\n  image: cr.d.xiaomi.net/zhangzhimin1/mace-dev2:$IMAGE_TAG_VERSION\n  needs:\n    - \"linux-x64:build\"\n  dependencies:\n    - \"linux-x64:build\"\n  before_script:\n    - echo \"git clone mace-models\"\n    - rm -rf mace-models\n    - git clone https://github.com/XiaoMi/mace-models.git\n  script:\n    - TARGET_SOCS=random\n    - CONF_FILE=mace-models/mobilenet-v1/mobilenet-v1.yml\n    - python tools/python/convert.py --config=${CONF_FILE}\n    - python tools/python/run_model.py --config=${CONF_FILE} --target_socs=$TARGET_SOCS --target_abi=host --validate --benchmark --runtime=cpu\n\nlinux-arm-quant:build:\n  stage: build\n  image: cr.d.xiaomi.net/zhangzhimin1/mace-dev2:$IMAGE_TAG_VERSION\n  script:\n    - LINARO_ARM_LINUX_GNUEABIHF=/usr RUNTIME=CPU QUANTIZE=ON ./tools/cmake/cmake-build-arm-linux-gnueabihf.sh\n\nandroid-aarch64-gpu&quant:build:\n  stage: build\n  image: cr.d.xiaomi.net/zhangzhimin1/mace-dev2:$IMAGE_TAG_VERSION\n  artifacts:\n    paths:\n      - build/cmake-build/arm64-v8a/install\n  script:\n    - RUNTIME=GPU QUANTIZE=ON tools/cmake/cmake-build-arm64-v8a.sh\n    - LIBMACE64_FULL_SIZE=`stat -c%s build/cmake-build/arm64-v8a/install/lib/libmace.so`\n    - if (( LIBMACE64_FULL_SIZE > 2500000 )) ; then echo \"The libmace.so size too large\"; exit 1; fi\n\nandroid-aarch64-gpu&quant:test:\n  stage: test\n  image: cr.d.xiaomi.net/zhangzhimin1/mace-dev2:$IMAGE_TAG_VERSION\n  needs:\n    - android-aarch64-gpu&quant:build\n  dependencies:\n    - android-aarch64-gpu&quant:build\n  tags:\n    - mace-host\n  script:\n    - adb -s $REDMI_K30_PRO shell rm -rf /data/local/$IMAGE_TAG_VERSION/${CI_JOB_ID}_install\n    - adb -s $REDMI_K30_PRO push build/cmake-build/arm64-v8a/install /data/local/$IMAGE_TAG_VERSION/${CI_JOB_ID}_install\n    - adb -s $REDMI_K30_PRO shell /data/local/$IMAGE_TAG_VERSION/${CI_JOB_ID}_install/bin/mace_cc_test\n    - adb -s $REDMI_K30_PRO shell rm -rf /data/local/$IMAGE_TAG_VERSION/${CI_JOB_ID}_install\n\nandroid-aarch64-gpu&quant:benchmark:\n  stage: benchmark\n  when: manual\n  needs:\n    - android-aarch64-gpu&quant:build\n  dependencies:\n    - android-aarch64-gpu&quant:build\n  tags:\n    - mace-host\n  image: cr.d.xiaomi.net/zhangzhimin1/mace-dev2:$IMAGE_TAG_VERSION\n  script:\n    - adb -s $REDMI_K30_PRO shell rm -rf /data/local/$IMAGE_TAG_VERSION/${CI_JOB_ID}_install\n    - adb -s $REDMI_K30_PRO push build/cmake-build/arm64-v8a/install /data/local/$IMAGE_TAG_VERSION/${CI_JOB_ID}_install\n    - adb -s $REDMI_K30_PRO shell /data/local/$IMAGE_TAG_VERSION/${CI_JOB_ID}_install/bin/mace_cc_benchmark\n    - adb -s $REDMI_K30_PRO shell rm -rf /data/local/$IMAGE_TAG_VERSION/${CI_JOB_ID}_install\n\nandroid-aarch64-gpu:model_validate:\n  stage: model_validate\n  tags:\n    - mace-host\n  image: cr.d.xiaomi.net/zhangzhimin1/mace-dev2:$IMAGE_TAG_VERSION\n  needs:\n    - \"android-aarch64-gpu&quant:build\"\n  dependencies:\n    - \"android-aarch64-gpu&quant:build\"\n  before_script:\n    - echo \"git clone mace-models\"\n    - rm -rf mace-models\n    - git clone https://github.com/XiaoMi/mace-models.git\n  script:\n    - CONF_FILE=mace-models/mobilenet-v1/mobilenet-v1.yml\n    - python tools/python/convert.py --config=${CONF_FILE}\n    - python tools/python/run_model.py --config=${CONF_FILE} --target_socs=random --target_abi=arm64-v8a --validate --benchmark --runtime=gpu\n\nandroid-aarch64-hexagon_dsp:build:\n  stage: build\n  image: cr.d.xiaomi.net/zhangzhimin1/mace-dev2:$IMAGE_TAG_VERSION\n  artifacts:\n    paths:\n      - build/cmake-build/arm64-v8a/install\n  script:\n    - RUNTIME=HEXAGON QUANTIZE=ON tools/cmake/cmake-build-arm64-v8a.sh\n\nandroid-aarch64-hexagon_dsp:model_validate:\n  stage: model_validate\n  tags:\n    - mace-host\n  image: cr.d.xiaomi.net/zhangzhimin1/mace-dev2:$IMAGE_TAG_VERSION\n  needs:\n    - \"android-aarch64-hexagon_dsp:build\"\n  dependencies:\n    - \"android-aarch64-hexagon_dsp:build\"\n  before_script:\n    - echo \"git clone mace-models\"\n    - rm -rf mace-models\n    - git clone https://github.com/XiaoMi/mace-models.git\n  script:\n    - CONF_FILE=mace-models/mobilenet-v1/mobilenet-v1-quantize-retrain-dsp.yml\n    - python tools/python/convert.py --config=${CONF_FILE}\n    - python tools/python/run_model.py --config=${CONF_FILE} --target_socs=sdm660 --target_abi=arm64-v8a --validate --benchmark --runtime=dsp\n\nandroid-aarch64-hexagon_hta:build:\n  stage: build\n  image: cr.d.xiaomi.net/zhangzhimin1/mace-dev2:$IMAGE_TAG_VERSION\n  artifacts:\n    paths:\n      - build/cmake-build/arm64-v8a/install\n  script:\n    - git reset origin/hta third_party/hta && git checkout third_party/hta\n    - RUNTIME=HTA QUANTIZE=ON tools/cmake/cmake-build-arm64-v8a.sh\n\nandroid-aarch64-hexagon_hta:model_validate:\n  stage: model_validate\n  tags:\n    - mace-host\n  image: cr.d.xiaomi.net/zhangzhimin1/mace-dev2:$IMAGE_TAG_VERSION\n  needs:\n    - \"android-aarch64-hexagon_hta:build\"\n  dependencies:\n    - \"android-aarch64-hexagon_hta:build\"\n  before_script:\n    - echo \"git clone mace-models\"\n    - rm -rf mace-models\n    - git clone https://github.com/XiaoMi/mace-models.git\n  script:\n    - CONF_FILE=mace-models/mobilenet-v1/mobilenet-v1-quantize-retrain-hta.yml\n    - python tools/python/convert.py --config=${CONF_FILE}\n    - python tools/python/run_model.py --config=${CONF_FILE} --target_socs=REDMI_K30_PRO --target_abi=arm64-v8a --validate --benchmark --runtime=hta\n\nandroid-aarch64-cpu/uint8:model_validate:\n  stage: model_validate\n  tags:\n    - mace-host\n  image: cr.d.xiaomi.net/zhangzhimin1/mace-dev2:$IMAGE_TAG_VERSION\n  needs:\n    - \"android-aarch64-gpu&quant:build\"\n  dependencies:\n    - \"android-aarch64-gpu&quant:build\"\n  before_script:\n    - echo \"git clone mace-models\"\n    - rm -rf mace-models\n    - git clone https://github.com/XiaoMi/mace-models.git\n  script:\n    - TARGET_SOCS=random\n    - CONF_FILE=mace-models/mobilenet-v1/mobilenet-v1-quantize-friendly.yml\n    - python tools/python/convert.py --config=${CONF_FILE}\n    - python tools/python/run_model.py --config=${CONF_FILE} --target_socs=random --target_abi=arm64-v8a --validate --benchmark --runtime=cpu\n\nhost-micro-cmsis:build:\n  variables:\n    GIT_SUBMODULE_STRATEGY: recursive\n  stage: build\n  tags:\n    - mace-host\n  image: cr.d.xiaomi.net/zhangzhimin1/mace-dev2:$IMAGE_TAG_VERSION\n  artifacts:\n    paths:\n      - build/micro\n  script:\n    - ./micro/tools/cmake/cmake-build-host.sh -DMACE_MICRO_ENABLE_TESTS=ON -DMACE_MICRO_ENABLE_CMSIS=ON\n\nhost-micro-cmsis:test:\n  stage: test\n  tags:\n    - mace-host\n  image: cr.d.xiaomi.net/zhangzhimin1/mace-dev2:$IMAGE_TAG_VERSION\n  needs:\n   - \"host-micro-cmsis:build\"\n  dependencies:\n   - \"host-micro-cmsis:build\"\n  script:\n    - build/micro/host/test/ccunit/micro_ops_test\n\nhost-micro-cmsis:benchmark:\n  stage: benchmark\n  tags:\n    - mace-host\n  image: cr.d.xiaomi.net/zhangzhimin1/mace-dev2:$IMAGE_TAG_VERSION\n  needs:\n   - \"host-micro-cmsis:build\"\n  dependencies:\n   - \"host-micro-cmsis:build\"\n  script:\n    - build/micro/host/test/ccbenchmark/micro_cc_benchmark\n\nnone-micro-m4:build:\n  stage: build\n  variables:\n    GIT_SUBMODULE_STRATEGY: recursive\n  stage: build\n  tags:\n    - mace-host\n  image: cr.d.xiaomi.net/zhangzhimin1/mace-dev2:$IMAGE_TAG_VERSION\n  artifacts:\n    paths:\n      - build/micro/\n  script:\n    - ./micro/tools/cmake/cmake-build-gcc-arm-none-eabi.sh -DARM_CPU=cortex-m7 -DMACE_MICRO_ENABLE_CMSIS=ON -DMACE_MICRO_ENABLE_TESTS=OFF"
        },
        {
          "name": ".gitlab-ci.yml",
          "type": "blob",
          "size": 11.8642578125,
          "content": "stages:\n  - prepare\n  - linting\n  - build\n  - test\n  - extra\n\nsetenv:\n  stage: prepare\n  script:\n    - export CCACHE_NOHASHDIR=1\n    - export CCACHE_BASEDIR=${CI_PROJECT_DIR}\n\ncpplint:\n  stage: linting\n  script:\n    - sh tools/cpplint.sh\n\npylint:\n  stage: linting\n  script:\n    - pycodestyle . --filename=*.py --exclude=examples,third_party,tools/python/py_proto --max-line-length=120\n\nbuild_docs:\n  stage: build\n  script:\n    - pwd\n    - set +x\n    - cd docs\n    - pyenv local 3.6.3 && make html\n    - CI_LATEST_OUTPUT_PATH=/mace-build-output/$CI_PROJECT_NAME/latest\n    - CI_JOB_OUTPUT_PATH=/mace-build-output/$CI_PROJECT_NAME/$CI_PIPELINE_ID\n    - rm -rf $CI_JOB_OUTPUT_PATH\n    - mkdir -p $CI_JOB_OUTPUT_PATH\n    - cp -r _build/html $CI_JOB_OUTPUT_PATH/docs\n    - rm -rf $CI_LATEST_OUTPUT_PATH\n    - mkdir -p $CI_LATEST_OUTPUT_PATH\n    - cp -r _build/html $CI_LATEST_OUTPUT_PATH/docs\n\n  artifacts:\n    paths:\n      - docs/_build\n\ncmake_build_android-armeabi-v7a:\n  stage: build\n  script:\n    - pwd\n    - set +x\n    - RUNTIME=GPU QUANTIZE=OFF bash tools/cmake/cmake-build-armeabi-v7a.sh\n    - LIBMACE32_FULL_SIZE=`stat -c%s build/cmake-build/armeabi-v7a/install/lib/libmace.so`\n    - if (( LIBMACE32_FULL_SIZE > 1600000 )) ; then echo \"The libmace.so size too large($LIBMACE32_FULL_SIZE)\"; exit 1; fi\n\ncmake_build_android-arm64-v8:\n  stage: build\n  script:\n    - pwd\n    - set +x\n    - RUNTIME=GPU QUANTIZE=OFF bash tools/cmake/cmake-build-arm64-v8a.sh\n    - LIBMACE64_FULL_SIZE=`stat -c%s build/cmake-build/arm64-v8a/install/lib/libmace.so`\n    - if (( LIBMACE64_FULL_SIZE > 2400000 )) ; then echo \"The libmace.so size too large($LIBMACE64_FULL_SIZE)\"; exit 1; fi\n\ncmake_build_host:\n  stage: build\n  script:\n    - pwd\n    - set +x\n    - RUNTIME=GPU QUANTIZE=OFF bash tools/cmake/cmake-build-host.sh\n    - LIBMACE_HOST_FULL_SIZE=`stat -c%s build/cmake-build/host/install/lib/libmace.so`\n    - if (( LIBMACE_HOST_FULL_SIZE > 2600000 )) ; then echo \"The libmace.so size too large($LIBMACE_HOST_FULL_SIZE)\"; exit 1; fi\n\nbazel_build:\n  stage: build\n  script:\n    - pwd\n    - set +x\n    - bash tools/bazel_build_standalone_lib.sh\n    - bash tools/bazel_build_standalone_lib.sh --abi=armeabi-v7a --runtimes=cpu\n    - bash tools/bazel_build_standalone_lib.sh --abi=armeabi-v7a --runtimes=cpu,gpu\n    - LIBMACE32_FULL_SIZE=`stat -c%s build/lib/armeabi-v7a/libmace.so`\n    - if (( LIBMACE32_FULL_SIZE > 1500000 )) ; then echo \"The libmace.so size too large(LIBMACE32_FULL_SIZE)\"; exit 1; fi\n    - bash tools/bazel_build_standalone_lib.sh --abi=armeabi-v7a --runtimes=cpu,gpu,dsp\n    - bash tools/bazel_build_standalone_lib.sh --abi=armeabi-v7a --runtimes=cpu,gpu,dsp --debug --asan\n    - bash tools/bazel_build_standalone_lib.sh --abi=arm64-v8a --runtimes=cpu\n    - bash tools/bazel_build_standalone_lib.sh --abi=arm64-v8a --runtimes=cpu,gpu\n    - LIBMACE64_FULL_SIZE=`stat -c%s build/lib/arm64-v8a/libmace.so`\n      - if (( LIBMACE64_FULL_SIZE > 2300000 )) ; then echo \"The libmace.so size too large(LIBMACE64_FULL_SIZE)\"; exit 1; fi\n    - bash tools/bazel_build_standalone_lib.sh --abi=arm64-v8a --runtimes=cpu,gpu,dsp\n    - bash tools/bazel_build_standalone_lib.sh --abi=arm64-v8a --runtimes=cpu,gpu,apu\n    - bash tools/bazel_build_standalone_lib.sh --abi=arm64-v8a --runtimes=cpu,gpu,dsp --debug --asan\n    - bash tools/bazel_build_standalone_lib.sh --abi=arm64-v8a --runtimes=cpu,gpu,apu --debug --asan\n    - bash tools/bazel_build_standalone_lib.sh --abi=arm_linux_gnueabihf --runtimes=cpu\n    - bash tools/bazel_build_standalone_lib.sh --abi=arm_linux_gnueabihf --runtimes=cpu,gpu\n    - bash tools/bazel_build_standalone_lib.sh --abi=aarch64_linux_gnu --runtimes=cpu\n    - bash tools/bazel_build_standalone_lib.sh --abi=aarch64_linux_gnu --runtimes=cpu,gpu\n    - bash tools/bazel_build_standalone_lib.sh --abi=host\n    - bash tools/bazel_build_standalone_lib.sh --static\n    - bash tools/bazel_build_standalone_lib.sh --abi=armeabi-v7a --runtimes=cpu --static\n    - bash tools/bazel_build_standalone_lib.sh --abi=armeabi-v7a --runtimes=cpu,gpu --static\n    - bash tools/bazel_build_standalone_lib.sh --abi=armeabi-v7a --runtimes=cpu,gpu,dsp --static\n    - bash tools/bazel_build_standalone_lib.sh --abi=armeabi-v7a --runtimes=cpu,gpu,dsp --static --debug --asan\n    - bash tools/bazel_build_standalone_lib.sh --abi=arm64-v8a --runtimes=cpu --static\n    - bash tools/bazel_build_standalone_lib.sh --abi=arm64-v8a --runtimes=cpu,gpu --static\n    - bash tools/bazel_build_standalone_lib.sh --abi=arm64-v8a --runtimes=cpu,gpu,dsp --static\n    - bash tools/bazel_build_standalone_lib.sh --abi=arm64-v8a --runtimes=cpu,gpu,dsp --static --debug --asan\n    - bash tools/bazel_build_standalone_lib.sh --abi=arm64-v8a --runtimes=cpu,gpu,apu --static\n    - bash tools/bazel_build_standalone_lib.sh --abi=arm64-v8a --runtimes=cpu,gpu,apu --static --debug --asan\n    - bash tools/bazel_build_standalone_lib.sh --abi=arm_linux_gnueabihf --runtimes=cpu --static\n    - bash tools/bazel_build_standalone_lib.sh --abi=arm_linux_gnueabihf --runtimes=cpu,gpu --static\n    - bash tools/bazel_build_standalone_lib.sh --abi=aarch64_linux_gnu --runtimes=cpu --static\n    - bash tools/bazel_build_standalone_lib.sh --abi=aarch64_linux_gnu --runtimes=cpu,gpu --static\n    - bash tools/bazel_build_standalone_lib.sh --abi=host --static\n  only:\n    - triggers\n\nbuild_android_demo:\n  stage: build\n  script:\n    - pwd\n    - set +x\n    - ANDROID_NDK_HOME_SAVED=${ANDROID_NDK_HOME}\n    - export ANDROID_NDK_HOME=/opt/android-ndk-r17b\n    - pushd examples/android/ && bash build.sh static && bash build.sh dynamic && popd\n    - export ANDROID_NDK_HOME=${ANDROID_NDK_HOME_SAVED}\n  only:\n    - triggers\n\nmace_cc_test:\n  stage: test\n  script:\n    - pwd\n    - set +x\n    - if [ -z \"$TARGET_SOCS\" ]; then TARGET_SOCS=random; fi\n    - >\n      if ping -c 1 v9.git.n.xiaomi.com 1>/dev/null 2>&1; then\n        GIT_SSH_COMMAND=\"ssh -o UserKnownHostsFile=/dev/null -o StrictHostKeyChecking=no\" git clone git@v9.git.n.xiaomi.com:deep-computing/generic-mobile-devices.git\n        DEVICE_CONF_FILE=generic-mobile-devices/devices.yml\n      fi\n    - python tools/bazel_adb_run.py --target=\"//test/ccunit:mace_cc_test\" --device_yml=${DEVICE_CONF_FILE} --run_target=True --stdout_processor=unittest_stdout_processor --target_abis=armeabi-v7a,arm64-v8a --target_socs=$TARGET_SOCS\n\nmace_cc_benchmark:\n  stage: test\n  script:\n    - pwd\n    - set +x\n    - if [ -z \"$TARGET_SOCS\" ]; then TARGET_SOCS=random; fi\n    - python tools/bazel_adb_run.py --target=\"//test/ccbenchmark:mace_cc_benchmark\" --run_target=True --stdout_processor=ops_benchmark_stdout_processor --target_abis=armeabi-v7a,arm64-v8a --target_socs=$TARGET_SOCS --args=\"--filter=.*SIGMOID.*\"\n  only:\n    - triggers\n\nmodel_tests:\n  stage: test\n  script:\n    - pwd\n    - set +x\n    - rm -rf mace-models\n    - rm -rf generic-mobile-devices\n    - GIT_SSH_COMMAND=\"ssh -o UserKnownHostsFile=/dev/null -o StrictHostKeyChecking=no\" git clone https://github.com/XiaoMi/mace-models.git\n    - CONF_FILE=mace-models/mobilenet-v1/mobilenet-v1.yml\n    - >\n      if ping -c 1 v9.git.n.xiaomi.com 1>/dev/null 2>&1; then\n        GIT_SSH_COMMAND=\"ssh -o UserKnownHostsFile=/dev/null -o StrictHostKeyChecking=no\" git clone git@v9.git.n.xiaomi.com:deep-computing/generic-mobile-devices.git\n        DEVICE_CONF_FILE=generic-mobile-devices/devices.yml\n      fi\n    - if [ -z \"$TARGET_SOCS\" ]; then TARGET_SOCS=random; fi\n    - python tools/converter.py convert --config=${CONF_FILE}  --target_socs=$TARGET_SOCS --model_graph_format=file --model_data_format=file --cl_mem_type=buffer\n    - python tools/converter.py run --config=${CONF_FILE} --target_socs=$TARGET_SOCS --device_yml=${DEVICE_CONF_FILE} --round=1 --target_abis=armeabi-v7a --validate --model_graph_format=file --model_data_format=file\n    - bash test/ci-mace-models/run-ci-test-model.sh\n    - CONF_FILE=mace-models/mobilenet-v2/mobilenet-v2-host.yml\n    - python tools/converter.py convert --config=${CONF_FILE} --target_socs=$TARGET_SOCS --model_graph_format=file --model_data_format=file\n    - python tools/converter.py run --config=${CONF_FILE} --target_socs=$TARGET_SOCS --round=1 --validate --model_graph_format=file --model_data_format=file --address_sanitizer\n    - python tools/converter.py run --config=${CONF_FILE} --target_socs=$TARGET_SOCS --round=5 --model_graph_format=file --model_data_format=file --benchmark\n    - python tools/converter.py convert --config=${CONF_FILE} --target_socs=$TARGET_SOCS --model_graph_format=code --model_data_format=file\n    - python tools/converter.py run --config=${CONF_FILE} --target_socs=$TARGET_SOCS --round=1 --validate --model_graph_format=code --model_data_format=file\n    - python tools/converter.py run --config=${CONF_FILE} --target_socs=$TARGET_SOCS --round=5 --model_graph_format=code --model_data_format=file --benchmark\n\nquantization_tests:\n  stage: test\n  script:\n    - pwd\n    - set +x\n    - rm -rf mace-models\n    - GIT_SSH_COMMAND=\"ssh -o UserKnownHostsFile=/dev/null -o StrictHostKeyChecking=no\" git clone https://github.com/XiaoMi/mace-models.git\n    - >\n      if ping -c 1 v9.git.n.xiaomi.com 1>/dev/null 2>&1; then\n        GIT_SSH_COMMAND=\"ssh -o UserKnownHostsFile=/dev/null -o StrictHostKeyChecking=no\" git clone git@v9.git.n.xiaomi.com:deep-computing/generic-mobile-devices.git\n        DEVICE_CONF_FILE=generic-mobile-devices/devices.yml\n      fi\n    - >\n      CONF_FILE=mace-models/mobilenet-v1/mobilenet-v1-quantize-retrain-dsp.yml;\n      python tools/converter.py convert --config=${CONF_FILE} --target_socs=$TARGET_SOCS --model_graph_format=file --model_data_format=file || exit 1;\n      python tools/converter.py run --config=${CONF_FILE} --target_socs=$TARGET_SOCS --device_yml=${DEVICE_CONF_FILE} --round=1 --validate --model_graph_format=file --model_data_format=file --use_system_libhexagon_nn || exit 1;\n    - >\n      CONF_FILE=mace-models/mobilenet-v1/mobilenet-v1-quantize-retrain-hta.yml;\n      GIT_SSH_COMMAND=\"ssh -o UserKnownHostsFile=/dev/null -o StrictHostKeyChecking=no\" git clone --single-branch --branch hta git@v9.git.n.xiaomi.com:deep-computing/mace.git mace_hta --depth 1;\n      mv mace_hta/third_party/hta/ third_party/;\n      python tools/converter.py convert --config=${CONF_FILE} --model_graph_format=file --model_data_format=file || exit 1;\n      python tools/converter.py run --config=${CONF_FILE} --round=1 --validate --model_graph_format=file --model_data_format=file || exit 1;\n      rm -rf mace_hta third_party/hta;\n    - rm -rf mace-models\n\ndynamic_linking_test:\n  stage: extra\n  script:\n    - pwd\n    - set +x\n    - export ANDROID_NDK_HOME=/opt/android-ndk-r17b\n    - rm -rf mace-models\n    - rm -rf generic-mobile-devices\n    - GIT_SSH_COMMAND=\"ssh -o UserKnownHostsFile=/dev/null -o StrictHostKeyChecking=no\" git clone https://github.com/XiaoMi/mace-models.git\n    - CONF_FILE=mace-models/mobilenet-v1/mobilenet-v1.yml\n    - >\n      if ping -c 1 v9.git.n.xiaomi.com 1>/dev/null 2>&1; then\n        GIT_SSH_COMMAND=\"ssh -o UserKnownHostsFile=/dev/null -o StrictHostKeyChecking=no\" git clone git@v9.git.n.xiaomi.com:deep-computing/generic-mobile-devices.git\n        DEVICE_CONF_FILE=generic-mobile-devices/devices.yml\n      fi\n    - if [ -z \"$TARGET_SOCS\" ]; then TARGET_SOCS=random; fi\n    - python tools/converter.py convert --config=${CONF_FILE}  --target_socs=$TARGET_SOCS --model_graph_format=file --model_data_format=file --cl_mem_type=buffer || exit 1;\n    - python tools/converter.py run --config=${CONF_FILE} --target_socs=$TARGET_SOCS --device_yml=${DEVICE_CONF_FILE} --round=1 --validate --model_graph_format=file --model_data_format=file --mace_lib_type=dynamic || exit 1;\n    - rm -rf mace-models\n  only:\n    - triggers\n\nmicro:\n  stage: test\n  tags:\n    - mace-micro\n  image: mace-micro-dev\n  before_script:\n    - git submodule deinit -f .\n    - git submodule sync\n    - git submodule update --init .\n  script:\n    - pwd\n    - set +x\n    - bash micro/tools/ci/model_convert.sh\n    - bash micro/tools/ci/cross_build.sh\n    - bash micro/tools/ci/host_build_and_run_examples.sh\n    - bash micro/tools/ci/host_build_and_run_tests.sh\n    - bash micro/tools/ci/build_mbed_example.sh\n"
        },
        {
          "name": ".gitmodules",
          "type": "blob",
          "size": 0.4072265625,
          "content": "[submodule \"micro/third_party/CMSIS_5\"]\n\tpath = micro/third_party/CMSIS_5\n\turl = https://github.com/ARM-software/CMSIS_5.git\n\tshallow = true\n[submodule \"micro/third_party/googletest\"]\n\tpath = micro/third_party/googletest\n\turl = https://github.com/google/googletest.git\n\tshallow = true\n[submodule \"micro/third_party/gflags\"]\n\tpath = micro/third_party/gflags\n\turl = https://github.com/gflags/gflags.git\n\tshallow = true\n"
        },
        {
          "name": ".travis.yml",
          "type": "blob",
          "size": 6.3134765625,
          "content": "language: cpp\n\nbefore_install:\n  - echo \"Start to test on $TRAVIS_OS_NAME\";\n  - if [[ \"$TRAVIS_OS_NAME\" == \"osx\" ]]; then export PIP=pip2; else export PIP=pip; fi\n  - if [[ \"$TRAVIS_OS_NAME\" == \"osx\" ]]; then export OS=darwin; else export OS=linux; fi\n  - if [[ \"$TRAVIS_OS_NAME\" == \"osx\" ]]; then export PYTHONPATH=\"/usr/local/lib/python2.7/site-packages:$PYTHONPATH\"; fi\n  - sudo $PIP install pycodestyle\n  - export BAZEL_VERSION=0.16.0\n  - wget https://github.com/bazelbuild/bazel/releases/download/$BAZEL_VERSION/bazel-$BAZEL_VERSION-installer-$OS-x86_64.sh\n  - chmod +x bazel-*.sh\n  - sudo ./bazel-$BAZEL_VERSION-installer-$OS-x86_64.sh\n  - rm -f bazel-$BAZEL_VERSION-installer-$OS-x86_64.sh\n  - pushd /opt/\n  - sudo wget -q https://dl.google.com/android/repository/android-ndk-r15c-$OS-x86_64.zip\n  - sudo unzip -q android-ndk-r15c-$OS-x86_64.zip\n  - sudo rm -f android-ndk-r15c-$OS-x86_64.zip\n  - export ANDROID_NDK_VERSION=r15c\n  - export ANDROID_NDK=/opt/android-ndk-${ANDROID_NDK_VERSION}\n  - export ANDROID_NDK_HOME=${ANDROID_NDK}\n  - export PATH=${PATH}:${ANDROID_NDK_HOME}\n  - popd\n  - if [[ \"$TRAVIS_OS_NAME\" == \"osx\" ]]; then brew update; brew cask install android-platform-tools; fi\n  - if [[ \"$TRAVIS_OS_NAME\" == \"linux\" ]]; then sudo apt-get update; sudo apt-get install -y --no-install-recommends android-tools-adb; fi\n  - sudo $PIP install setuptools\n  - sudo $PIP install -I \"tensorflow==1.8.0\" \"numpy==1.15.4\" \"sh==1.12.14\" \"pycodestyle==2.4.0\" \"pyyaml==3.13\" \"jinja2==2.10\" \"filelock==3.0.10\" \"scipy==1.2.0\" \"PTable==0.9.2\"\n\njobs:\n  include:\n    - stage: Check Code Style\n      script:\n        - echo 'Check Code Style'\n        - curl -o cpplint.py https://raw.githubusercontent.com/google/styleguide/gh-pages/cpplint/cpplint.py && python cpplint.py --linelength=80 --counting=detailed $(find mace -name \"*.h\" -or -name \"*.cc\") && rm -f cpplint.py || exit 1;\n        - pycodestyle $(find . -name \"*.py\") || exit 1;\n      env: TYPE=Check-Code-Stype\n      os: linux\n      dist: xenial\n      sudo: required\n    - stage: Check Code Style\n      script:\n        - echo 'Check Code Style'\n        - curl -o cpplint.py https://raw.githubusercontent.com/google/styleguide/gh-pages/cpplint/cpplint.py && python cpplint.py --linelength=80 --counting=detailed $(find mace -name \"*.h\" -or -name \"*.cc\") && rm -f cpplint.py || exit 1;\n        - pycodestyle $(find . -name \"*.py\") || exit 1;\n      env: TYPE=Check-Code-Stype\n      os: osx\n      osx_image: xcode7.2\n    - stage: Unit Test\n      script:\n        - echo \"Ops Test\"\n        - python tools/bazel_adb_run.py --target=\"//test/ccunit:mace_cc_test\" --run_target=False --target_abis=armeabi-v7a,arm64-v8a,arm64 || exit 1;\n      env: TYPE=Ops-Test\n      os: linux\n      dist: xenial\n      sudo: required\n    - stage: Unit Test\n      script:\n        - echo \"Ops Test\"\n        - python tools/bazel_adb_run.py --target=\"//test/ccunit:mace_cc_test\" --run_target=False --target_abis=armeabi-v7a,arm64-v8a,arm64 || exit 1;\n      env: TYPE=Ops-Test\n      os: osx\n      osx_image: xcode7.2\n    - stage: Unit Test\n      script:\n        - echo \"Ops Test On Darwin\"\n        - python tools/bazel_adb_run.py --target=\"//test/ccunit:mace_cc_test\" --run_target=False --target_abis=host || exit 1;\n        - bazel build \"//test/ccunit:mace_cc_test\" --config=ios --config=optimization_darwin --define quantize=true --define neon=true --config symbol_hidden || exit 1;\n      env: TYPE=Ops-Test\n      os: osx\n      osx_image: xcode7.2\n    - stage: Unit Test\n      script:\n        - echo \"Ops Test Without NEON\"\n        - python tools/bazel_adb_run.py --target=\"//test/ccunit:mace_cc_test\" --run_target=False --target_abis=armeabi-v7a,arm64-v8a,arm64 --enable_neon=false --enable_quantize=false || exit 1\n      env: TYPE=Ops-Test-Without-NEON\n      os: linux\n      dist: xenial\n      sudo: required\n    - stage: Unit Test\n      script:\n        - python tools/bazel_adb_run.py --target=\"//test/ccbenchmark:mace_cc_benchmark\" --run_target=False --target_abis=armeabi-v7a,arm64-v8a,arm64 || exit 1;\n      env: TYPE=Ops-Benchmark\n      os: linux\n      dist: xenial\n      sudo: required\n    - stage: Unit Test\n      script:\n        - python tools/bazel_adb_run.py --target=\"//test/ccbenchmark:mace_cc_benchmark\" --run_target=False --target_abis=armeabi-v7a,arm64-v8a,arm64 || exit 1;\n      env: TYPE=Ops-Benchmark\n      os: osx\n      osx_image: xcode7.2\n    - stage: Unit Test\n      script:\n        - python tools/bazel_adb_run.py --target=\"//test/ccbenchmark:mace_cc_benchmark\" --run_target=False --target_abis=host || exit 1;\n        - bazel build \"//test/ccbenchmark:mace_cc_benchmark\" --config=ios --config=optimization_darwin --define quantize=true --define neon=true --config symbol_hidden || exit 1;\n      env: TYPE=Ops-Benchmark\n      os: osx\n      osx_image: xcode7.2\n    - stage: Extra Test\n      script:\n        - sh tools/cmake-build-android-armeabi-v7a-full.sh\n        - LIBMACE32_FULL_SIZE=`stat -c%s cmake-build/android-armeabi-v7a-full/install/lib/libmace.so`\n        - if (( LIBMACE32_FULL_SIZE > 2200000 )) ; then echo \"The libmace.so size too large\"; exit 1; fi\n      env: TYPE=Build-Library\n      os: linux\n      dist: xenial\n      sudo: required\n    - stage: Extra Test\n      script:\n        - sh tools/cmake-build-android-arm64-v8a-full.sh\n        - LIBMACE64_FULL_SIZE=`stat -c%s cmake-build/android-arm64-v8a-full/install/lib/libmace.so`\n        - if (( LIBMACE64_FULL_SIZE > 3100000 )) ; then echo \"The libmace.so size too large\"; exit 1; fi\n      env: TYPE=Build-Library\n      os: linux\n      dist: xenial\n      sudo: required\n    - stage: Extra Test\n      script:\n        - bazel build \"//mace/libmace:libmace_static\" --config=darwin --config=optimization_darwin --define quantize=true --config symbol_hidden || exit 1;\n        - bazel build \"//mace/libmace:libmace_dynamic\" --config=darwin --config=optimization_darwin --define quantize=true --config symbol_hidden || exit 1;\n      env: TYPE=Build-Library\n      os: osx\n      osx_image: xcode7.2\n    - stage: Extra Test\n      script:\n        - bazel build \"//mace/libmace:libmace_static\" --config=ios --config=optimization_darwin --define quantize=true --define neon=true --config symbol_hidden || exit 1;\n        - bazel build \"//mace/libmace:libmace_dynamic\" --config=ios --config=optimization_darwin --define quantize=true --define neon=true --config symbol_hidden || exit 1;\n      env: TYPE=Build-Library\n      os: osx\n      osx_image: xcode7.2\n"
        },
        {
          "name": "BUILD.bazel",
          "type": "blob",
          "size": 0,
          "content": ""
        },
        {
          "name": "CMakeLists.txt",
          "type": "blob",
          "size": 6.5029296875,
          "content": "# new CUDA support requires 3.8 for Linux/Mac, and 3.9 for Windows\ncmake_minimum_required(VERSION 3.2 FATAL_ERROR)\nmessage(\"CMAKE_VERSION: ${CMAKE_VERSION}\")\nproject(mace C CXX)\n\noption(MACE_ENABLE_CPU         \"whether to enable CPU support\"              OFF)\noption(MACE_ENABLE_NEON        \"whether to enable NEON support\"             OFF)\noption(MACE_ENABLE_QUANTIZE    \"whether to enable NEON int8 support\"        OFF)\noption(MACE_ENABLE_OPENCL      \"whether to enable OpenCL support\"           OFF)\noption(MACE_ENABLE_CUDA        \"whether to enable CUDA support\"             OFF)\noption(MACE_ENABLE_HEXAGON_DSP \"whether to enable Hexagon DSP support\"      OFF)\noption(MACE_ENABLE_HEXAGON_HTA \"whether to enable Hexagon HTA support\"      OFF)\noption(MACE_ENABLE_MTK_APU     \"whether to enable MTK APU support\"          OFF)\noption(MACE_ENABLE_BFLOAT16    \"whether to enable bfloat16 support\"         OFF)\noption(MACE_ENABLE_FP16        \"whether to enable armv8.2 fp16 support\"     OFF)\noption(MACE_ENABLE_TESTS       \"whether to build c++ unit tests\"            OFF)\noption(MACE_ENABLE_BENCHMARKS  \"whether to build c++ micro benchmarks\"      OFF)\noption(MACE_ENABLE_OPT_SIZE    \"whether to build with optimized binary size\" ON)\noption(MACE_ENABLE_OBFUSCATE   \"whether to build with code obfuscation\"      ON)\noption(MACE_ENABLE_CCACHE      \"whether to build with ccache\"                ON)\noption(MACE_ENABLE_CODE_MODE   \"whether to use code mode\"                   OFF)\n\nmessage(\"CMAKE_INSTALL_PREFIX: ${CMAKE_INSTALL_PREFIX}\")\n\nstring(TOLOWER ${CMAKE_SYSTEM_NAME} MACE_OS)\nstring(TOLOWER ${CMAKE_SYSTEM_PROCESSOR} MACE_TARGET)\n\nif(MACE_ENABLE_CCACHE)\n  find_program(CCACHE_FOUND ccache)\n  if(CCACHE_FOUND)\n    set(CMAKE_CXX_COMPILER_LAUNCHER ccache)\n    set(CMAKE_C_COMPILER_LAUNCHER   ccache)\n  endif(CCACHE_FOUND)\nendif(MACE_ENABLE_CCACHE)\n\n# TODO make these flags well defined and organized\n# TODO enable sanitizer\nset(MACE_CC_FLAGS \"${MACE_CC_FLAGS} -fPIC\")\nif(MACE_ENABLE_OPT_SIZE)\n  if(APPLE)\n    set(MACE_LINKER_FLAGS \"${MACE_LINKER_FLAGS} -Wl,-dead_strip -Wl,-dead_strip_dylibs\")\n  else(APPLE)\n    set(MACE_LINKER_FLAGS \"${MACE_LINKER_FLAGS} -Wl,--strip-all -Wl,--gc-sections\")\n    set(MACE_CC_FLAGS \"${MACE_CC_FLAGS} -ffunction-sections -fdata-sections\")\n  endif(APPLE)\n  set(MACE_CC_FLAGS \"${MACE_CC_FLAGS} -fvisibility=hidden -fvisibility-inlines-hidden\")\n  set(MACE_CODE_CC_FLAGS \"${MACE_CODE_CC_FLAGS} -fno-rtti -fno-exceptions -DGOOGLE_PROTOBUF_NO_RTTI -DPROTOBUF_USE_EXCEPTIONS=0\")\nendif(MACE_ENABLE_OPT_SIZE)\n\nif(MACE_ENABLE_CODE_MODE)\n  set(MACE_CODE_CC_FLAGS \"${MACE_CODE_CC_FLAGS} -DMODEL_GRAPH_FORMAT_CODE\")\nendif(MACE_ENABLE_CODE_MODE)\n\n# flags apply only to mace code (third_party excluded)\n# -Wno-error=unused-command-line-argument: official Android toolchain contains\n# unsupported argument and will break ccache preprocessor\nif(ANDROID)\n  set(MACE_CODE_CC_FLAGS \"${MACE_CODE_CC_FLAGS} -Wall -Werror -Wno-error=unused-command-line-argument -Wno-error=unevaluated-expression -Wno-error=tautological-compare\")\nelse(ANDROID)\n  set(MACE_CODE_CC_FLAGS \"${MACE_CODE_CC_FLAGS} -Wall -Werror\")\nendif(ANDROID)\nset(MACE_CODE_CC_FLAGS \"${MACE_CODE_CC_FLAGS} -std=c++11 -D_GLIBCXX_USE_C99_MATH_TR1\")\n\nif(IOS)\n  # TODO correct the code\n  set(MACE_CODE_CC_FLAGS \"${MACE_CODE_CC_FLAGS} -Wno-error=shorten-64-to-32\")\nendif(IOS)\n\nif(MACE_ENABLE_NEON)\n  add_definitions(-DMACE_ENABLE_NEON)\n  if(ANDROID_ABI STREQUAL \"armeabi-v7a\")\n    # Enable NEON fp16 support\n    string(REPLACE \"-mfpu=neon \" \"-mfpu=neon-fp16 \" CMAKE_CXX_FLAGS ${CMAKE_CXX_FLAGS})\n  endif(ANDROID_ABI STREQUAL \"armeabi-v7a\")\nendif(MACE_ENABLE_NEON)\n\nif(MACE_ENABLE_QUANTIZE)\n  add_definitions(-DMACE_ENABLE_QUANTIZE)\n  add_definitions(-DGEMMLOWP_USE_MACE_THREAD_POOL)\n  add_definitions(-DMACE_DEPTHWISE_U8_USE_MULTI_THREAD)\nendif(MACE_ENABLE_QUANTIZE)\n\nif(MACE_ENABLE_CPU OR MACE_ENABLE_OPENCL)\n  add_definitions(-DMACE_ENABLE_CPU)\nendif(MACE_ENABLE_CPU OR MACE_ENABLE_OPENCL)\n\nif(MACE_ENABLE_OPENCL)\n  if(IOS)\n    message(FATAL_ERROR \"OpenCL is not supported for iOS\")\n  endif(IOS)\n  add_definitions(-DMACE_ENABLE_OPENCL)\nendif(MACE_ENABLE_OPENCL)\n\nif(MACE_ENABLE_CUDA)\n  # new CUDA support requires 3.8 for Linux/Mac, and 3.9 for Windows\n  cmake_minimum_required(VERSION 3.8 FATAL_ERROR)\n  enable_language(CUDA)\nendif(MACE_ENABLE_CUDA)\n\nif(MACE_ENABLE_RPCMEM)\n  add_definitions(-DMACE_ENABLE_RPCMEM)\nendif(MACE_ENABLE_RPCMEM)\n\nif(MACE_ENABLE_HEXAGON_DSP OR MACE_ENABLE_HEXAGON_HTA)\n  if(ANDROID_ABI STREQUAL \"arm64-v8a\")\n    # Use gold linker to avoid linking check of libcdsprpc.so\n    set(MACE_LINKER_FLAGS \"${MACE_LINKER_FLAGS} -fuse-ld=gold\")\n  endif(ANDROID_ABI STREQUAL \"arm64-v8a\")\nendif(MACE_ENABLE_HEXAGON_DSP OR MACE_ENABLE_HEXAGON_HTA)\n\nif(MACE_ENABLE_HEXAGON_DSP)\n  if(NOT ANDROID)\n    message(FATAL_ERROR \"Hexagon DSP is only supported on Android\")\n  endif(NOT ANDROID)\n  # TODO => -DMACE_ENABLE_HEXAGON_DSP\n  add_definitions(-DMACE_ENABLE_HEXAGON)\nendif(MACE_ENABLE_HEXAGON_DSP)\n\nif(MACE_ENABLE_RPCMEM)\n  add_definitions(-DMACE_ENABLE_RPCMEM)\nendif(MACE_ENABLE_RPCMEM)\n\nif(MACE_ENABLE_HEXAGON_HTA)\n  if(NOT ANDROID)\n    message(FATAL_ERROR \"Hexagon HTA is only supported on Android\")\n  endif(NOT ANDROID)\n  add_definitions(-DMACE_ENABLE_HEXAGON_HTA)\n  add_definitions(-DMACE_ENABLE_HTA)\nendif(MACE_ENABLE_HEXAGON_HTA)\n\nif(MACE_ENABLE_MTK_APU)\n  if(NOT ANDROID)\n    message(FATAL_ERROR \"MTK APU is only supported on Android\")\n  endif(NOT ANDROID)\n  add_definitions(-DMACE_ENABLE_MTK_APU)\n  # Use gold linker to avoid linking check of libapu-platform.so\n  set(MACE_LINKER_FLAGS \"${MACE_LINKER_FLAGS} -fuse-ld=gold\")\nendif(MACE_ENABLE_MTK_APU)\n\nif(MACE_ENABLE_BFLOAT16)\n  add_definitions(-DMACE_ENABLE_BFLOAT16)\nendif(MACE_ENABLE_BFLOAT16)\n\nif(MACE_ENABLE_FP16)\n  add_definitions(-DMACE_ENABLE_FP16)\nendif(MACE_ENABLE_FP16)\n\nif(MACE_ENABLE_OBFUSCATE)\n  add_definitions(-DMACE_OBFUSCATE_LITERALS)\nendif(MACE_ENABLE_OBFUSCATE)\n\nif(NOT MSVC)\n  set(CMAKE_CXX_FLAGS \"${CMAKE_CXX_FLAGS} ${MACE_CODE_CC_FLAGS} ${MACE_CC_FLAGS}\")\n  set(CMAKE_SHARED_LINKER_FLAGS \"${CMAKE_SHARED_LINKER_FLAGS} ${MACE_LINKER_FLAGS}\")\n  set(CMAKE_EXE_LINKER_FLAGS \"${CMAKE_EXE_LINKER_FLAGS} ${MACE_LINKER_FLAGS}\")\nendif(NOT MSVC)\n\ninclude(${PROJECT_SOURCE_DIR}/third_party/third_party.cmake)\n\ninclude_directories(\"${PROJECT_SOURCE_DIR}\")\ninclude_directories(\"${PROJECT_SOURCE_DIR}/include\")\ninclude_directories(\"${PROJECT_BINARY_DIR}\") # proto\n\nadd_subdirectory(include)\nadd_subdirectory(mace)\n\nif(MACE_ENABLE_TESTS OR MACE_ENABLE_BENCHMARKS)\n  add_subdirectory(test)\nendif(MACE_ENABLE_TESTS OR MACE_ENABLE_BENCHMARKS)\n\nif(MACE_ENABLE_MICRO)\n  add_subdirectory(micro)\nendif(MACE_ENABLE_MICRO)\n"
        },
        {
          "name": "ISSUE_TEMPLATE.md",
          "type": "blob",
          "size": 1.337890625,
          "content": "---\nname: ISSUE TEMPLATE\nabout: Bug and Feature Report\n\n---\n\nBefore you open an issue, please make sure you have tried the following steps:\n\n1. Make sure your **environment** is the same with (https://mace.readthedocs.io/en/latest/installation/env_requirement.html).\n2. Have you ever read the document for your usage?\n3. Check if your issue appears in [HOW-TO-DEBUG](https://mace.readthedocs.io/en/latest/development/how_to_debug.html) or [FAQ](https://mace.readthedocs.io/en/latest/faq.html).\n4. The form below must be filled.\n\n------------------------\n\n### System information\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:\n- **NDK version(e.g., 15c)**:\n- **GCC version(if compiling for host, e.g., 5.4.0)**:\n- **MACE version (Use the command: git describe --long --tags)**:\n- **Python version(2.7)**: \n- **Bazel version (e.g., 0.13.0)**:\n\n### Model deploy file (*.yml)\n```yaml\n......\n```\n\n### Describe the problem\nA clear and concise description of what the bug is.\n\n### To Reproduce\nSteps to reproduce the problem:\n```bash\n1. cd /path/to/mace\n2. python tools/converter.py convert --config_file=/path/to/your/model_deployment_file\n```\n\n### Error information / logs\nPlease include the **full** log and/or traceback here.\n```bash\nLOGs\n```\n\n### Additional context\nAdd any other context about the problem here, e.g., what you have modified about the code.\n"
        },
        {
          "name": "JOBS.md",
          "type": "blob",
          "size": 0.677734375,
          "content": "## Join Us\nWe are hiring talents (full-time or interns) with the following skills:\n\n* Solid C++ skills (required)\n* Heterogeneous computing (NEON, OpenCL, CUDA, HVX, TVM, MLIR etc.)\n* Model compression and quantization\n* Large scale distributed system\n* Computer vision, image processing and/or autonomous driving\n\nContacts: please find email from the commit log.\n\n## 加入我们\n欢迎加入我们 (全职或实习生)：\n\n* 扎实的C++编程基础与良好的工程习惯 (必须)\n* 异构计算 (NEON, OpenCL, CUDA, HVX, TVM, MLIR等)\n* 神经网络模型压缩与量化\n* 大规模分布式系统\n* 计算机视觉，图像处理，自动驾驶\n\n联系方式：提交记录中的email。\n"
        },
        {
          "name": "LICENSE",
          "type": "blob",
          "size": 11.091796875,
          "content": "\n                                 Apache License\n                           Version 2.0, January 2004\n                        http://www.apache.org/licenses/\n\n   TERMS AND CONDITIONS FOR USE, REPRODUCTION, AND DISTRIBUTION\n\n   1. Definitions.\n\n      \"License\" shall mean the terms and conditions for use, reproduction,\n      and distribution as defined by Sections 1 through 9 of this document.\n\n      \"Licensor\" shall mean the copyright owner or entity authorized by\n      the copyright owner that is granting the License.\n\n      \"Legal Entity\" shall mean the union of the acting entity and all\n      other entities that control, are controlled by, or are under common\n      control with that entity. For the purposes of this definition,\n      \"control\" means (i) the power, direct or indirect, to cause the\n      direction or management of such entity, whether by contract or\n      otherwise, or (ii) ownership of fifty percent (50%) or more of the\n      outstanding shares, or (iii) beneficial ownership of such entity.\n\n      \"You\" (or \"Your\") shall mean an individual or Legal Entity\n      exercising permissions granted by this License.\n\n      \"Source\" form shall mean the preferred form for making modifications,\n      including but not limited to software source code, documentation\n      source, and configuration files.\n\n      \"Object\" form shall mean any form resulting from mechanical\n      transformation or translation of a Source form, including but\n      not limited to compiled object code, generated documentation,\n      and conversions to other media types.\n\n      \"Work\" shall mean the work of authorship, whether in Source or\n      Object form, made available under the License, as indicated by a\n      copyright notice that is included in or attached to the work\n      (an example is provided in the Appendix below).\n\n      \"Derivative Works\" shall mean any work, whether in Source or Object\n      form, that is based on (or derived from) the Work and for which the\n      editorial revisions, annotations, elaborations, or other modifications\n      represent, as a whole, an original work of authorship. For the purposes\n      of this License, Derivative Works shall not include works that remain\n      separable from, or merely link (or bind by name) to the interfaces of,\n      the Work and Derivative Works thereof.\n\n      \"Contribution\" shall mean any work of authorship, including\n      the original version of the Work and any modifications or additions\n      to that Work or Derivative Works thereof, that is intentionally\n      submitted to Licensor for inclusion in the Work by the copyright owner\n      or by an individual or Legal Entity authorized to submit on behalf of\n      the copyright owner. For the purposes of this definition, \"submitted\"\n      means any form of electronic, verbal, or written communication sent\n      to the Licensor or its representatives, including but not limited to\n      communication on electronic mailing lists, source code control systems,\n      and issue tracking systems that are managed by, or on behalf of, the\n      Licensor for the purpose of discussing and improving the Work, but\n      excluding communication that is conspicuously marked or otherwise\n      designated in writing by the copyright owner as \"Not a Contribution.\"\n\n      \"Contributor\" shall mean Licensor and any individual or Legal Entity\n      on behalf of whom a Contribution has been received by Licensor and\n      subsequently incorporated within the Work.\n\n   2. Grant of Copyright License. Subject to the terms and conditions of\n      this License, each Contributor hereby grants to You a perpetual,\n      worldwide, non-exclusive, no-charge, royalty-free, irrevocable\n      copyright license to reproduce, prepare Derivative Works of,\n      publicly display, publicly perform, sublicense, and distribute the\n      Work and such Derivative Works in Source or Object form.\n\n   3. Grant of Patent License. Subject to the terms and conditions of\n      this License, each Contributor hereby grants to You a perpetual,\n      worldwide, non-exclusive, no-charge, royalty-free, irrevocable\n      (except as stated in this section) patent license to make, have made,\n      use, offer to sell, sell, import, and otherwise transfer the Work,\n      where such license applies only to those patent claims licensable\n      by such Contributor that are necessarily infringed by their\n      Contribution(s) alone or by combination of their Contribution(s)\n      with the Work to which such Contribution(s) was submitted. If You\n      institute patent litigation against any entity (including a\n      cross-claim or counterclaim in a lawsuit) alleging that the Work\n      or a Contribution incorporated within the Work constitutes direct\n      or contributory patent infringement, then any patent licenses\n      granted to You under this License for that Work shall terminate\n      as of the date such litigation is filed.\n\n   4. Redistribution. You may reproduce and distribute copies of the\n      Work or Derivative Works thereof in any medium, with or without\n      modifications, and in Source or Object form, provided that You\n      meet the following conditions:\n\n      (a) You must give any other recipients of the Work or\n          Derivative Works a copy of this License; and\n\n      (b) You must cause any modified files to carry prominent notices\n          stating that You changed the files; and\n\n      (c) You must retain, in the Source form of any Derivative Works\n          that You distribute, all copyright, patent, trademark, and\n          attribution notices from the Source form of the Work,\n          excluding those notices that do not pertain to any part of\n          the Derivative Works; and\n\n      (d) If the Work includes a \"NOTICE\" text file as part of its\n          distribution, then any Derivative Works that You distribute must\n          include a readable copy of the attribution notices contained\n          within such NOTICE file, excluding those notices that do not\n          pertain to any part of the Derivative Works, in at least one\n          of the following places: within a NOTICE text file distributed\n          as part of the Derivative Works; within the Source form or\n          documentation, if provided along with the Derivative Works; or,\n          within a display generated by the Derivative Works, if and\n          wherever such third-party notices normally appear. The contents\n          of the NOTICE file are for informational purposes only and\n          do not modify the License. You may add Your own attribution\n          notices within Derivative Works that You distribute, alongside\n          or as an addendum to the NOTICE text from the Work, provided\n          that such additional attribution notices cannot be construed\n          as modifying the License.\n\n      You may add Your own copyright statement to Your modifications and\n      may provide additional or different license terms and conditions\n      for use, reproduction, or distribution of Your modifications, or\n      for any such Derivative Works as a whole, provided Your use,\n      reproduction, and distribution of the Work otherwise complies with\n      the conditions stated in this License.\n\n   5. Submission of Contributions. Unless You explicitly state otherwise,\n      any Contribution intentionally submitted for inclusion in the Work\n      by You to the Licensor shall be under the terms and conditions of\n      this License, without any additional terms or conditions.\n      Notwithstanding the above, nothing herein shall supersede or modify\n      the terms of any separate license agreement you may have executed\n      with Licensor regarding such Contributions.\n\n   6. Trademarks. This License does not grant permission to use the trade\n      names, trademarks, service marks, or product names of the Licensor,\n      except as required for reasonable and customary use in describing the\n      origin of the Work and reproducing the content of the NOTICE file.\n\n   7. Disclaimer of Warranty. Unless required by applicable law or\n      agreed to in writing, Licensor provides the Work (and each\n      Contributor provides its Contributions) on an \"AS IS\" BASIS,\n      WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or\n      implied, including, without limitation, any warranties or conditions\n      of TITLE, NON-INFRINGEMENT, MERCHANTABILITY, or FITNESS FOR A\n      PARTICULAR PURPOSE. You are solely responsible for determining the\n      appropriateness of using or redistributing the Work and assume any\n      risks associated with Your exercise of permissions under this License.\n\n   8. Limitation of Liability. In no event and under no legal theory,\n      whether in tort (including negligence), contract, or otherwise,\n      unless required by applicable law (such as deliberate and grossly\n      negligent acts) or agreed to in writing, shall any Contributor be\n      liable to You for damages, including any direct, indirect, special,\n      incidental, or consequential damages of any character arising as a\n      result of this License or out of the use or inability to use the\n      Work (including but not limited to damages for loss of goodwill,\n      work stoppage, computer failure or malfunction, or any and all\n      other commercial damages or losses), even if such Contributor\n      has been advised of the possibility of such damages.\n\n   9. Accepting Warranty or Additional Liability. While redistributing\n      the Work or Derivative Works thereof, You may choose to offer,\n      and charge a fee for, acceptance of support, warranty, indemnity,\n      or other liability obligations and/or rights consistent with this\n      License. However, in accepting such obligations, You may act only\n      on Your own behalf and on Your sole responsibility, not on behalf\n      of any other Contributor, and only if You agree to indemnify,\n      defend, and hold each Contributor harmless for any liability\n      incurred by, or claims asserted against, such Contributor by reason\n      of your accepting any such warranty or additional liability.\n\n   END OF TERMS AND CONDITIONS\n\n   APPENDIX: How to apply the Apache License to your work.\n\n      To apply the Apache License to your work, attach the following\n      boilerplate notice, with the fields enclosed by brackets \"[]\"\n      replaced with your own identifying information. (Don't include\n      the brackets!)  The text should be enclosed in the appropriate\n      comment syntax for the file format. We also recommend that a\n      file or class name and description of purpose be included on the\n      same \"printed page\" as the copyright notice for easier\n      identification within third-party archives.\n\n   Copyright [yyyy] [name of copyright owner]\n\n   Licensed under the Apache License, Version 2.0 (the \"License\");\n   you may not use this file except in compliance with the License.\n   You may obtain a copy of the License at\n\n       http://www.apache.org/licenses/LICENSE-2.0\n\n   Unless required by applicable law or agreed to in writing, software\n   distributed under the License is distributed on an \"AS IS\" BASIS,\n   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n   See the License for the specific language governing permissions and\n   limitations under the License.\n"
        },
        {
          "name": "README.md",
          "type": "blob",
          "size": 4.7705078125,
          "content": "<div align=\"center\">\n<img src=\"docs/mace-logo.png\" width=\"400\" alt=\"MACE\" />\n</div>\n\n\n[![License](https://img.shields.io/badge/License-Apache%202.0-blue.svg)](LICENSE)\n[![Build Status](https://travis-ci.org/XiaoMi/mace.svg?branch=master)](https://travis-ci.org/XiaoMi/mace)\n[![pipeline status](https://gitlab.com/llhe/mace/badges/master/pipeline.svg)](https://gitlab.com/llhe/mace/pipelines)\n[![doc build status](https://readthedocs.org/projects/mace/badge/?version=latest)](https://readthedocs.org/projects/mace/badge/?version=latest)\n\n[Documentation](https://mace.readthedocs.io) |\n[FAQ](https://mace.readthedocs.io/en/latest/faq.html) |\n[Release Notes](RELEASE.md) |\n[Roadmap](ROADMAP.md) |\n[MACE Model Zoo](https://github.com/XiaoMi/mace-models) |\n[Demo](examples/android) |\n[Join Us](JOBS.md) |\n[中文](README_zh.md)\n\n**Mobile AI Compute Engine** (or **MACE** for short) is a deep learning inference framework optimized for\nmobile heterogeneous computing on Android, iOS, Linux and Windows devices. The design focuses on the following\ntargets:\n* Performance\n  * Runtime is optimized with NEON, OpenCL and Hexagon, and\n    [Winograd algorithm](https://arxiv.org/abs/1509.09308) is introduced to\n    speed up convolution operations. The initialization is also optimized to be faster.\n* Power consumption\n  * Chip dependent power options like big.LITTLE scheduling, Adreno GPU hints are\n    included as advanced APIs.\n* Responsiveness\n  * UI responsiveness guarantee is sometimes obligatory when running a model.\n    Mechanism like automatically breaking OpenCL kernel into small units is\n    introduced to allow better preemption for the UI rendering task.\n* Memory usage and library footprint\n  * Graph level memory allocation optimization and buffer reuse are supported.\n    The core library tries to keep minimum external dependencies to keep the\n    library footprint small.\n* Model protection\n  * Model protection has been the highest priority since the beginning of \n    the design. Various techniques are introduced like converting models to C++\n    code and literal obfuscations.\n* Platform coverage\n  * Good coverage of recent Qualcomm, MediaTek, Pinecone and other ARM based\n    chips. CPU runtime supports Android, iOS and Linux.\n* Rich model formats support\n  * [TensorFlow](https://github.com/tensorflow/tensorflow),\n    [Caffe](https://github.com/BVLC/caffe) and\n    [ONNX](https://github.com/onnx/onnx) model formats are supported.\n\n## Getting Started\n* [Introduction](https://mace.readthedocs.io/en/latest/introduction.html)\n* [Installation](https://mace.readthedocs.io/en/latest/installation/env_requirement.html)\n* [Basic Usage](https://mace.readthedocs.io/en/latest/user_guide/basic_usage.html)\n* [Advanced Usage](https://mace.readthedocs.io/en/latest/user_guide/advanced_usage.html)\n\n## Performance\n[MACE Model Zoo](https://github.com/XiaoMi/mace-models) contains\nseveral common neural networks and models which will be built daily against a list of mobile\nphones. The benchmark results can be found in [the CI result page](https://gitlab.com/llhe/mace-models/pipelines)\n(choose the latest passed pipeline, click *release* step and you will see the benchmark results).\nTo get the comparison results with other frameworks, you can take a look at\n[MobileAIBench](https://github.com/XiaoMi/mobile-ai-bench) project.\n\n## Communication\n* GitHub issues: bug reports, usage issues, feature requests\n* Slack: [mace-users.slack.com](https://join.slack.com/t/mace-users/shared_invite/enQtMzkzNjM3MzMxODYwLTAyZTAzMzQyNjc0ZGI5YjU3MjI1N2Q2OWI1ODgwZjAwOWVlNzFlMjFmMTgwYzhjNzU4MDMwZWQ1MjhiM2Y4OTE)\n* QQ群: 756046893\n\n## Contributing\nAny kind of contribution is welcome. For bug reports, feature requests,\nplease just open an issue without any hesitation. For code contributions, it's\nstrongly suggested to open an issue for discussion first. For more details,\nplease refer to [the contribution guide](https://mace.readthedocs.io/en/latest/development/contributing.html).\n\n## License\n[Apache License 2.0](LICENSE).\n\n## Acknowledgement\nMACE depends on several open source projects located in the\n[third_party](third_party) directory. Particularly, we learned a lot from\nthe following projects during the development:\n* [Qualcomm Hexagon NN Offload Framework](https://developer.qualcomm.com/software/hexagon-dsp-sdk): the Hexagon DSP runtime\n  depends on this library.\n* [TensorFlow](https://github.com/tensorflow/tensorflow),\n  [Caffe](https://github.com/BVLC/caffe),\n  [SNPE](https://developer.qualcomm.com/software/snapdragon-neural-processing-engine-ai),\n  [ARM ComputeLibrary](https://github.com/ARM-software/ComputeLibrary),\n  [ncnn](https://github.com/Tencent/ncnn),\n  [ONNX](https://github.com/onnx/onnx) and many others: we learned many best\n  practices from these projects.\n\nFinally, we also thank the Qualcomm, Pinecone and MediaTek engineering teams for\ntheir help.\n"
        },
        {
          "name": "README_zh.md",
          "type": "blob",
          "size": 3.27734375,
          "content": "<div  align=\"center\">\n<img src=\"docs/mace-logo.png\" width = \"400\" alt=\"MACE\" />\n</div>\n\n[![License](https://img.shields.io/badge/License-Apache%202.0-blue.svg)](LICENSE)\n[![pipeline status](https://gitlab.com/llhe/mace/badges/master/pipeline.svg)](https://gitlab.com/llhe/mace/pipelines)\n[![doc build status](https://readthedocs.org/projects/mace/badge/?version=latest)](https://readthedocs.org/projects/mace/badge/?version=latest)\n\n[文档](https://mace.readthedocs.io) |\n[FAQ](https://mace.readthedocs.io/en/latest/faq.html) |\n[发布记录](RELEASE.md) |\n[路线图](ROADMAP.md) |\n[MACE Model Zoo](https://github.com/XiaoMi/mace-models) |\n[Demo](mace/examples/android) |\n[加入我们](JOBS.md) |\n[English](README.md)\n\n**Mobile AI Compute Engine (MACE)** 是一个专为移动端异构计算平台(支持Android, iOS, Linux, Windows)优化的神经网络计算框架。\n主要从以下的角度做了专门的优化：\n* 性能\n  * 代码经过NEON指令，OpenCL以及Hexagon HVX专门优化，并且采用\n  [Winograd算法](https://arxiv.org/abs/1509.09308)来进行卷积操作的加速。\n  此外，还对启动速度进行了专门的优化。\n* 功耗\n  * 支持芯片的功耗管理，例如ARM的big.LITTLE调度，以及高通Adreno GPU功耗选项。\n* 系统响应\n  * 支持自动拆解长时间的OpenCL计算任务，来保证UI渲染任务能够做到较好的抢占调度，\n  从而保证系统UI的相应和用户体验。\n* 内存占用\n  * 通过运用内存依赖分析技术，以及内存复用，减少内存的占用。另外，保持尽量少的外部\n  依赖，保证代码尺寸精简。\n* 模型加密与保护\n  * 模型保护是重要设计目标之一。支持将模型转换成C++代码，以及关键常量字符混淆，增加逆向的难度。\n* 硬件支持范围\n  * 支持高通，联发科，以及松果等系列芯片的CPU，GPU与DSP(目前仅支持Hexagon)计算加速。CPU模式支持Android, iOS, Linux等系统。\n* 模型格式支持\n  * 支持[TensorFlow](https://github.com/tensorflow/tensorflow)，\n  [Caffe](https://github.com/BVLC/caffe)和[ONNX](https://github.com/onnx/onnx)等模型格式。\n\n## 开始使用\n* [简介](https://mace.readthedocs.io/en/latest/introduction.html)\n* [安装](https://mace.readthedocs.io/en/latest/installation/env_requirement.html)\n* [基本用法](https://mace.readthedocs.io/en/latest/user_guide/basic_usage.html)\n* [高级用法](https://mace.readthedocs.io/en/latest/user_guide/advanced_usage.html)\n\n## 性能评测\n[MACE Model Zoo](https://github.com/XiaoMi/mace-models)\n包含若干常用模型，并且会对一组手机进行每日构建。最新的性能评测结果可以从项目的[持续集成页面获取](https://gitlab.com/llhe/mace-models/pipelines)\n(选择最新的成功的Pipeline，点击*release*可以看到最新的评测结果)。\n同时，可以参考[MobileAIBench](https://github.com/XiaoMi/mobile-ai-bench)项目\n获取MACE与其他框架的对比结果。\n\n## 交流与反馈\n* 欢迎通过Github Issues提交问题报告与建议\n* QQ群: 756046893\n* Slack: [mace-users.slack.com](https://join.slack.com/t/mace-users/shared_invite/enQtMzkzNjM3MzMxODYwLTAyZTAzMzQyNjc0ZGI5YjU3MjI1N2Q2OWI1ODgwZjAwOWVlNzFlMjFmMTgwYzhjNzU4MDMwZWQ1MjhiM2Y4OTE)\n\n## License\n[Apache License 2.0](LICENSE)\n\n## 加入我们\n[欢迎加入我们](JOBS.md)。\n"
        },
        {
          "name": "RELEASE.md",
          "type": "blob",
          "size": 7.1357421875,
          "content": "# v1.0.0 (2020-11-04)\n## Support Quantization For MACE Micro\nAt the beginning of this year, we released MACE Micro to fully support ultra-low-power inference scenarios of mobile phones and IoT devices. In this version, we support quantization for MACE Micro and integrate CMSIS5 to support Cortex-M chips better.\n\n## Support More Model Formats\nWe find more and more R&D engineers are using the PyTorch framework to train their models. In previous versions, MACE transformed the PyTorch model by using ONNX format as a bridge. In order to serve PyTorch developers better, we support direct transformation for PyTorch models in this version, which improves the performance of the model inference.\nAt the same time, we cooperated with [MEGVII](URL 'https://www.megvii.com/') company and support its [MegEngine](URL 'https://github.com/MegEngine/MegEngine') model format. If you trained your models by [MegEngine](URL 'https://github.com/MegEngine/MegEngine') framework, now you can use MACE to deploy the models on mobile phones or IoT devices.\n\n## Support More Data Precision\nArmv8.2 provides support for half-precision floating-point data processing instructions, in this version we support the fp16 precision computation by Armv8.2 fp16 instructions, which increases inference speed by roughly 40% for models such as mobilenet-v1 model.\nThe bfloat16 (Brain Floating Point) floating-point format is a computer number format occupying 16 bits in computer memory, we also support bfloat16 precision in this version, which increases inference speed by roughly 40% for models such as mobilenet-v1/2 model on some low-end chips.\n\n## Others\nIn this version, we also add the following features:\n1. Support more operators, such as `GroupNorm`, `ExtractImagePatches`, `Elu`, etc.\n2. Optimize the performance of the framework and operators, such as the `Reduce` operator.\n3. Support dynamic filter of conv2d/deconv2d.\n4. Integrate MediaTek APU support on mt6873, mt6885, and mt6853.\n\n## Acknowledgement\nThanks to the following guys who contribute code which makes MACE better.\n\n@ZhangZhijing1, who contributed the bf16 code which was then committed by someone else.\n@yungchienhsu, @Yi-Kai-Chen, @Eric-YK-Chen, @yzchen, @gasgallo, @lq, @huahang, @elswork, @LovelyBuggies, @freewym.\n\n# v0.13.0 (2020-04-03)\n## Support for MACE Micro\nCompared with mobile devices such as mobile phones, micro-controllers are small, low-energy computing devices, which are often embedded in hardware that only needs basic computing, including household appliances and IoT devices. Billions of microcontrollers are produced every year. MACE adds micro-controller support to fully support ultra-low-power inference scenarios of mobile phones and IoT devices. MACE's micro-controller engine does not rely on any OS, heap memory allocation, C++ library or other third-party libraries except the math library. \n\n## Further Support For Quantization\nMACE supports two kinds of quantization mechanisms: quantization-aware training and post-training quantization. In this version, we add a mixed-use of them. Furthermore, we support Armv8.2 dot product instruction for CPU quantization.\n\n## Performance Optimization\nMACE is continuously optimizing the performance. This time, we add ION buffer support for Qualcomm socs, which greatly improves the inference performance of models that need to switch between GPU and CPU. Moreover, we optimize the operators' performance such as `ResizeNearestNeighbor`, `Deconv`.\n\n## Others\nIn this version, We support many new operators, `BatchMatMulV2` and `Select` operators for TensorFlow, `Deconv2d`, `Strided-Slice`, `Sigmoid` for Hexagon DSP and fix some bugs on validation and tuning.\n\n## Acknowledgement\nThanks for the following guys who contribute code which makes MACE better.\ngasgallo\n\n# v0.12.0 (2019-11-17)\n------\n## Performance Optimization\nWe found that the lack of OP implementations on devices(GPU, Hexagon DSP, etc.) would lead to inefficient model execution, for  the memory synchronization between the device and the CPU consumed much time, so we added and enhanced some operators on the GPU( reshape, lpnorm, mvnorm, etc.) and Hexagon DSP (s2d, d2s, sub, etc.) to improve the efficiency of model execution.\n\n## Further Support For Speech Recognition\nIn the last version, we supported the Kaldi framework. In Xiaomi we did a lot of work to support the speech recognition model,  including the support of flatten, unsample and other operators in onnx, as well as some bug fixes.\n\n## CMake Support\nMACE is continuously optimizing our compilation tools. This time, we support cmake compilation. Because of the use of ccache for acceleration, the compilation speed of cmake is much faster than the original bazel.\nRelated Docs: https://mace.readthedocs.io/en/latest/user_guide/basic_usage_cmake.html\n\n## Others\nIn this version, We supported detection of perfomance regression by dana , and  “ gpu_queue_window” parameter is added to yml file,  to solve the UI jam problem caused by GPU task execution.\nRelated Docs: https://mace.readthedocs.io/en/latest/faq.html\n\n## Acknowledgement\nThanks for the following guys who contribute code which make MACE better.\n\nyungchienhsu, gasgallo, albu, yunikkk\n\n# v0.10.0 (2019-01-03)\n------\n## Improvements\n1. Support mixing usage of CPU and GPU.\n2. Support ONNX format.\n3. Support ARM Linux development board.\n4. Support CPU quantization.\n5. Update DSP library.\n6. Add `Depthwise Deconvolution` of Caffe.\n7. Add documents about debug and benchmark.\n8. Bug fixed.\n\n## Incompatible Changes\n1. Remove all APIs in mace_runtime.h\n\n## New APIs\n1. Add OpenclContext and GPUContextBuilder API.\n2. Add MaceEngineConfig API.\n3. Add MaceStatus API.\n4. MaceTensor support data format.\n\n## Acknowledgement\nThanks for the following guys who contribute code which make MACE better.\n\nByronHsu, conansherry, jackwish, herbakamil, tomaszkaliciak, oneTaken,\nmadhavajay, wayen820, idstein, newway1995.\n\n# v0.9.0 (2018-07-20)\n------\n## Improvements\n1. New work flow and documents.\n2. Separate the model library from MACE library.\n3. Reduce the size of static and dynamic library.\n4. Support `ArgMax` Operations.\n5. Support `Deconvolution` of Caffe.\n6. Support NDK-17b.\n\n## Incompatible Changes\n1. Use file to store OpenCL tuned parameters and Add `SetOpenCLParameterPath` API.\n\n## New APIs\n1. Add a new `MaceEngine::Init` API with model data file.\n\n## Bug Fixed\n1. Not unmap the model data file when load model from files with CPU runtime.\n2. 2D LWS tuning does not work.\n3. Winograd convolution of GPU failed when open tuning.\n4. Incorrect dynamic library of host.\n\n## Acknowledgement\nThanks for the following guys who contribute code which make MACE better.\n\nZero King(@l2dy), James Bie(@JamesBie), Sun Aries(@SunAriesCN), Allen(@allen0125),\nconansherry(@conansherry), 黎明灰烬(@jackwish)\n\n\n# v0.8.0 (2018-05-31)\n------\n1. Change build and run tools\n2. Handle runtime failure\n\n# v0.7.0 (2018-05-18)\n------\n1. Change interface that report error type\n2. Improve CPU performance\n3. Merge CPU/GPU engine to on\n\n# v0.6.3 (2018-05-21)\n------\n1. support `float` `data_type` when running in GPU\n\n\n# v0.6.2 (2018-05-17)\n------\n* Return status instead of abort when allocate failed\n\n\n# v0.6.0 (2018-04-04)\n------\n1. Change mace header interfaces, only including necessary methods.\n\n"
        },
        {
          "name": "ROADMAP.md",
          "type": "blob",
          "size": 0.12109375,
          "content": "Roadmap\n=======\n\n* CUDA support\n* Mixed-precision inference\n* Improved host/x86 performance\n\n*Last updated: April 15, 2019*\n"
        },
        {
          "name": "WORKSPACE",
          "type": "blob",
          "size": 6.0859375,
          "content": "workspace(name = \"mace\")\n\n# generate version and opencl kernel code.\nload(\"//repository/git:git_configure.bzl\", \"git_version_repository\")\nload(\"//repository/opencl-kernel:opencl_kernel_configure.bzl\", \"encrypt_opencl_kernel_repository\")\n\ngit_version_repository(name = \"local_version_config\")\n\nencrypt_opencl_kernel_repository(name = \"local_opencl_kernel_encrypt\")\n\n# proto_library rules implicitly depend on @com_google_protobuf//:protoc,\n# which is the proto-compiler.\n# This statement defines the @com_google_protobuf repo.\nhttp_archive(\n    name = \"com_google_protobuf\",\n    sha256 = \"d7a221b3d4fb4f05b7473795ccea9e05dab3b8721f6286a95fffbffc2d926f8b\",\n    strip_prefix = \"protobuf-3.6.1\",\n    urls = [\n        \"https://cnbj1.fds.api.xiaomi.com/mace/third-party/protobuf/protobuf-3.6.1.zip\",\n        \"https://github.com/google/protobuf/archive/v3.6.1.zip\",\n    ],\n)\n\nnew_http_archive(\n    name = \"gtest\",\n    build_file = \"third_party/googletest/googletest.BUILD\",\n    sha256 = \"f3ed3b58511efd272eb074a3a6d6fb79d7c2e6a0e374323d1e6bcbcc1ef141bf\",\n    strip_prefix = \"googletest-release-1.8.0\",\n    urls = [\n        \"https://cnbj1.fds.api.xiaomi.com/mace/third-party/googletest/googletest-release-1.8.0.zip\",\n        \"https://github.com/google/googletest/archive/release-1.8.0.zip\",\n    ],\n)\n\nnew_http_archive(\n    name = \"opencl_headers\",\n    build_file = \"third_party/opencl-headers/opencl-headers.BUILD\",\n    sha256 = \"e08f3c77a76f0e3d9ef886c7a7245757a831fdf5bc2c554587f57adb9226f53a\",\n    strip_prefix = \"OpenCL-Headers-2021.06.30\",\n    urls = [\n        \"https://cnbj1.fds.api.xiaomi.com/mace/third-party/OpenCL-Headers/OpenCL-Headers-2021.06.30.zip\",\n        \"https://github.com/KhronosGroup/OpenCL-Headers/archive/refs/tags/v2021.06.30.zip\",\n    ],\n)\n\nnew_http_archive(\n    name = \"opencl_clhpp\",\n    build_file = \"third_party/opencl-clhpp/opencl-clhpp.BUILD\",\n    sha256 = \"767c2e9589739cfca814cbb94c57bcbb3112d94f1a8cafffa8a5cc3a5de00d12\",\n    strip_prefix = \"OpenCL-CLHPP-2.0.15\",\n    urls = [\n        \"https://cnbj1.fds.api.xiaomi.com/mace/third-party/OpenCL-CLHPP/OpenCL-CLHPP-2.0.15.zip\",\n        \"https://github.com/KhronosGroup/OpenCL-CLHPP/archive/refs/tags/v2.0.15.zip\",\n    ],\n)\n\nnew_http_archive(\n    name = \"half\",\n    build_file = \"third_party/half/half.BUILD\",\n    sha256 = \"0f514a1e877932b21dc5edc26a148ddc700b6af2facfed4c030ca72f74d0219e\",\n    strip_prefix = \"half-code-356-trunk\",\n    urls = [\n        \"https://cnbj1.fds.api.xiaomi.com/mace/third-party/half/half-code-356-trunk.zip\",\n    ],\n)\n\nnew_http_archive(\n    name = \"eigen\",\n    build_file = \"third_party/eigen3/eigen.BUILD\",\n    sha256 = \"ca7beac153d4059c02c8fc59816c82d54ea47fe58365e8aded4082ded0b820c4\",\n    strip_prefix = \"eigen-eigen-f3a22f35b044\",\n    urls = [\n        \"http://cnbj1.fds.api.xiaomi.com/mace/third-party/eigen/f3a22f35b044.tar.gz\",\n        \"http://mirror.bazel.build/bitbucket.org/eigen/eigen/get/f3a22f35b044.tar.gz\",\n        \"https://bitbucket.org/eigen/eigen/get/f3a22f35b044.tar.gz\",\n    ],\n)\n\nhttp_archive(\n    name = \"gemmlowp\",\n    sha256 = \"d445e5a0ef6ae18dcb68adb3c38245708cb357c0e1e51cb752dd933b7c975314\",\n    strip_prefix = \"gemmlowp-76272a197495297154e97cdcb624a52581165497\",\n    urls = [\n        \"http://cnbj1.fds.api.xiaomi.com/mace/third-party/gemmlowp/gemmlowp-76272a197495297154e97cdcb624a52581165497.zip\",\n    ],\n)\n\nhttp_archive(\n    name = \"tflite\",\n    sha256 = \"6f2671a02fe635a82c289c8c40a6e5bc24670ff1d4c3c2ab4a7aa9b825256a18\",\n    strip_prefix = \"tensorflow-mace-d73e88fc830320d3818ac24e57cd441820a85cc9\",\n    urls = [\n        \"http://cnbj1.fds.api.xiaomi.com/mace/third-party/tflite/tensorflow-mace-d73e88fc830320d3818ac24e57cd441820a85cc9.zip\",\n    ],\n)\n\nnew_http_archive(\n    name = \"six_archive\",\n    build_file = \"third_party/six/six.BUILD\",\n    sha256 = \"105f8d68616f8248e24bf0e9372ef04d3cc10104f1980f54d57b2ce73a5ad56a\",\n    strip_prefix = \"six-1.10.0\",\n    urls = [\n        \"https://cnbj1.fds.api.xiaomi.com/mace/third-party/six/six-1.10.0.tar.gz\",\n        \"http://mirror.bazel.build/pypi.python.org/packages/source/s/six/six-1.10.0.tar.gz\",\n        \"https://pypi.python.org/packages/source/s/six/six-1.10.0.tar.gz\",\n    ],\n)\n\nbind(\n    name = \"six\",\n    actual = \"@six_archive//:six\",\n)\n\nhttp_archive(\n    # v2.2.0 + fix of include path\n    name = \"com_github_gflags_gflags\",\n    sha256 = \"16903f6bb63c00689eee3bf7fb4b8f242934f6c839ce3afc5690f71b712187f9\",\n    strip_prefix = \"gflags-30dbc81fb5ffdc98ea9b14b1918bfe4e8779b26e\",\n    urls = [\n        \"https://cnbj1.fds.api.xiaomi.com/mace/third-party/gflags/gflags-30dbc81fb5ffdc98ea9b14b1918bfe4e8779b26e.zip\",\n        \"https://github.com/gflags/gflags/archive/30dbc81fb5ffdc98ea9b14b1918bfe4e8779b26e.zip\",\n    ],\n)\n\nbind(\n    name = \"gflags\",\n    actual = \"@com_github_gflags_gflags//:gflags\",\n)\n\nbind(\n    name = \"gflags_nothreads\",\n    actual = \"@com_github_gflags_gflags//:gflags_nothreads\",\n)\n\n# Set up Android NDK\nandroid_ndk_repository(\n    name = \"androidndk\",\n    # Android 5.0\n    api_level = 21,\n)\n\n# Set up default cross compilers for arm linux\nnew_http_archive(\n    name = \"gcc_linaro_7_3_1_arm_linux_gnueabihf\",\n    build_file = \"third_party/compilers/arm_compiler.BUILD\",\n    sha256 = \"7248bf105d0d468887a9b8a7120bb281ac8ad0223d9cb3d00dc7c2d498485d91\",\n    strip_prefix = \"gcc-linaro-7.3.1-2018.05-x86_64_arm-linux-gnueabihf\",\n    urls = [\n        \"https://cnbj1.fds.api.xiaomi.com/mace/third-party/gcc-linaro/gcc-linaro-7.3.1-2018.05-x86_64_arm-linux-gnueabihf.tar.xz\",\n        \"https://releases.linaro.org/components/toolchain/binaries/7.3-2018.05/arm-linux-gnueabihf/gcc-linaro-7.3.1-2018.05-x86_64_arm-linux-gnueabihf.tar.xz\",\n    ],\n)\n\nnew_http_archive(\n    name = \"gcc_linaro_7_3_1_aarch64_linux_gnu\",\n    build_file = \"third_party/compilers/aarch64_compiler.BUILD\",\n    sha256 = \"73eed74e593e2267504efbcf3678918bb22409ab7afa3dc7c135d2c6790c2345\",\n    strip_prefix = \"gcc-linaro-7.3.1-2018.05-x86_64_aarch64-linux-gnu\",\n    urls = [\n        \"https://cnbj1.fds.api.xiaomi.com/mace/third-party/gcc-linaro/gcc-linaro-7.3.1-2018.05-x86_64_aarch64-linux-gnu.tar.xz\",\n        \"https://releases.linaro.org/components/toolchain/binaries/7.3-2018.05/aarch64-linux-gnu/gcc-linaro-7.3.1-2018.05-x86_64_aarch64-linux-gnu.tar.xz\",\n    ],\n)\n"
        },
        {
          "name": "cmake",
          "type": "tree",
          "content": null
        },
        {
          "name": "docker",
          "type": "tree",
          "content": null
        },
        {
          "name": "docs",
          "type": "tree",
          "content": null
        },
        {
          "name": "examples",
          "type": "tree",
          "content": null
        },
        {
          "name": "include",
          "type": "tree",
          "content": null
        },
        {
          "name": "mace",
          "type": "tree",
          "content": null
        },
        {
          "name": "micro",
          "type": "tree",
          "content": null
        },
        {
          "name": "repository",
          "type": "tree",
          "content": null
        },
        {
          "name": "setup",
          "type": "tree",
          "content": null
        },
        {
          "name": "test",
          "type": "tree",
          "content": null
        },
        {
          "name": "third_party",
          "type": "tree",
          "content": null
        },
        {
          "name": "tools",
          "type": "tree",
          "content": null
        }
      ]
    }
  ]
}