{
  "metadata": {
    "timestamp": 1736565604482,
    "page": 484,
    "hasNextPage": true,
    "endCursor": "Y3Vyc29yOjQ5MA==",
    "completionStatus": "IN_PROGRESS"
  },
  "repositories": [
    {
      "nameWithOwner": "facebookresearch/habitat-sim",
      "stars": 2734,
      "defaultBranch": "main",
      "files": [
        {
          "name": ".clang-format",
          "type": "blob",
          "size": 3.6162109375,
          "content": "---\n# clang-format v8\nLanguage:        Cpp\n# BasedOnStyle:  Chromium\nAccessModifierOffset: -1\nAlignAfterOpenBracket: Align\nAlignConsecutiveAssignments: false\nAlignConsecutiveDeclarations: false\nAlignEscapedNewlines: Left\nAlignOperands:   true\nAlignTrailingComments: true\nAllowAllParametersOfDeclarationOnNextLine: false\nAllowShortBlocksOnASingleLine: false\nAllowShortCaseLabelsOnASingleLine: false\nAllowShortFunctionsOnASingleLine: Inline\nAllowShortIfStatementsOnASingleLine: false\nAllowShortLoopsOnASingleLine: false\nAlwaysBreakAfterDefinitionReturnType: None\nAlwaysBreakAfterReturnType: None\nAlwaysBreakBeforeMultilineStrings: true\nAlwaysBreakTemplateDeclarations: true\nBinPackArguments: true\nBinPackParameters: false\nBraceWrapping:\n  AfterClass:      false\n  AfterControlStatement: false\n  AfterEnum:       false\n  AfterFunction:   false\n  AfterNamespace:  false\n  AfterObjCDeclaration: false\n  AfterStruct:     false\n  AfterUnion:      false\n  AfterExternBlock: false\n  BeforeCatch:     false\n  BeforeElse:      false\n  IndentBraces:    false\n  SplitEmptyFunction: true\n  SplitEmptyRecord: true\n  SplitEmptyNamespace: true\nBreakBeforeBinaryOperators: None\nBreakBeforeBraces: Attach\nBreakBeforeInheritanceComma: false\nBreakBeforeTernaryOperators: true\nBreakConstructorInitializersBeforeComma: false\nBreakConstructorInitializers: BeforeColon\nBreakAfterJavaFieldAnnotations: false\nBreakStringLiterals: true\nColumnLimit:     80\n# Doc block @ref and @section commands often cause Doxygen parsing bugs if\n# wrapped on multiple lines. If a comment contains them, it's not formatted in\n# any way.\nCommentPragmas:  '(^ IWYU pragma:|@ref|@section)'\nCompactNamespaces: false\nConstructorInitializerAllOnOneLineOrOnePerLine: true\nConstructorInitializerIndentWidth: 4\nContinuationIndentWidth: 4\nCpp11BracedListStyle: true\nDerivePointerAlignment: false\nDisableFormat:   false\nExperimentalAutoDetectBinPacking: false\nFixNamespaceComments: true\nForEachMacros:\n  - foreach\n  - Q_FOREACH\n  - BOOST_FOREACH\nIncludeBlocks:   Preserve\nIncludeCategories:\n  - Regex:           '^<ext/.*\\.h>'\n    Priority:        2\n  - Regex:           '^<.*\\.h>'\n    Priority:        1\n  - Regex:           '^<.*'\n    Priority:        2\n  - Regex:           '.*'\n    Priority:        3\nIncludeIsMainRegex: '([-_](test|unittest))?$'\nIndentCaseLabels: true\nIndentPPDirectives: None\nIndentWidth:     2\nIndentWrappedFunctionNames: false\nJavaScriptQuotes: Leave\nJavaScriptWrapImports: true\nKeepEmptyLinesAtTheStartOfBlocks: false\nMacroBlockBegin: ''\nMacroBlockEnd:   ''\nMaxEmptyLinesToKeep: 1\nNamespaceIndentation: None\nObjCBinPackProtocolList: Never\nObjCBlockIndentWidth: 2\nObjCSpaceAfterProperty: false\nObjCSpaceBeforeProtocolList: true\nPenaltyBreakAssignment: 2\nPenaltyBreakBeforeFirstCallParameter: 1\nPenaltyBreakComment: 300\nPenaltyBreakFirstLessLess: 120\nPenaltyBreakString: 1000\nPenaltyExcessCharacter: 1000000\nPenaltyReturnTypeOnItsOwnLine: 200\nPointerAlignment: Left\nRawStringFormats:\n  - Language:        TextProto\n    Delimiters:\n      - pb\n      - PB\n      - proto\n      - PROTO\n    CanonicalDelimiter: ''\n    BasedOnStyle:    google\nReflowComments:  true\nSortIncludes:    true\nSortUsingDeclarations: true\nSpaceAfterCStyleCast: false\nSpaceAfterTemplateKeyword: true\nSpaceBeforeAssignmentOperators: true\nSpaceBeforeCtorInitializerColon: true\nSpaceBeforeInheritanceColon: true\nSpaceBeforeParens: ControlStatements\nSpaceBeforeRangeBasedForLoopColon: true\nSpaceInEmptyParentheses: false\nSpacesBeforeTrailingComments: 2\nSpacesInAngles:  false\nSpacesInContainerLiterals: true\nSpacesInCStyleCastParentheses: false\nSpacesInParentheses: false\nSpacesInSquareBrackets: false\nStandard:        Auto\nTabWidth:        8\nUseTab:          Never\n...\n"
        },
        {
          "name": ".clang-tidy",
          "type": "blob",
          "size": 4.8779296875,
          "content": "Checks: '\nbugprone-*,\nclang-analyzer-cplusplus-*,\nclang-analyzer-optin.performance.*,\ncppcoreguidelines-init-variables,\ncppcoreguidelines-pro-type-member-init,\ngoogle-*,\nmisc-definitions-in-headers,\nmisc-static-assert,\nmisc-unconventional-assign-operator,\nmisc-uniqueptr-reset-release,\nmisc-unused-parameters,\nmodernize-avoid-bind,\nmodernize-deprecated-headers,\nmodernize-make-shared,\nmodernize-make-unique,\nmodernize-pass-by-value,\nmodernize-redundant-void-arg,\nmodernize-replace-disallow-copy-and-assign-macro,\nmodernize-replace-random-shuffle,\nmodernize-shrink-to-fit,\nmodernize-unary-static-assert,\nmodernize-use-bool-literals,\nmodernize-use-default-member-init,\nmodernize-use-emplace,\nmodernize-use-equals-default,\nmodernize-use-equals-delete,\nmodernize-use-noexcept,\nmodernize-use-nullptr,\nmodernize-use-override,\nmodernize-use-transparent-functors,\nperformance-*,\nreadability-avoid-const-params-in-decls,\nreadability-const-return-type,\nreadability-delete-null-pointer,\nreadability-implicit-bool-conversion,\nreadability-make-member-function-const,\nreadability-misplaced-array-index,\nreadability-non-const-parameter,\nreadability-qualified-auto,\nreadability-redundant-declaration,\nreadability-redundant-function-ptr-dereference,\nreadability-redundant-preprocessor,\nreadability-redundant-smartptr-get,\nreadability-redundant-string-cstr,\nreadability-simplify-boolean-expr,\nreadability-simplify-subscript-expr,\nreadability-static-accessed-through-instance,\nreadability-static-definition-in-anonymous-namespace,\nreadability-string-compare,\nreadability-uniqueptr-delete-release,\n-*-objc-*,\n-*.cocoa.*,\n-clang-analyzer-core.NullDereference,\n-clang-analyzer-security.insecureAPI.rand,\n-google-build-explicit-make-pair,\n-google-default-arguments,\n-google-readability-braces-around-statements,\n-google-readability-todo,\n-google-runtime-references,\n-modernize-avoid-c-arrays,\n-modernize-use-auto,\n-modernize-use-trailing-return-type,\n-bugprone-easily-swappable-parameters,\n-bugprone-forward-declaration-namespace,\n-performance-no-int-to-ptr,\n'\n\nCheckOptions:\n- key:             cppcoreguidelines-pro-type-member-init.IgnoreArrays\n  value:           true\n- key:             modernize-pass-by-value.ValuesOnly\n  value:           true\n- key:             performance-for-range-copy.WarnOnAllAutoCopies\n  value:           true\n- key:             readability-implicit-bool-conversion.AllowPointerConditions\n  value:           true\n\nWarningsAsErrors: '\n*,\n-bugprone-narrowing-conversions,\n-bugprone-reserved-identifier,\n-bugprone-unused-raii,\n-clang-diagnostic-deprecated-declarations,\n-clang-analyzer-cplusplus.PlacementNew,\n-cppcoreguidelines-pro-type-member-init,\n-optin.cplusplus.UninitializedObject,\n-readability-implicit-bool-conversion,\n'\n\nHeaderFilterRegex: \"src/esp/\"\n\n# Comments for particular disabled checks:\n#\n# bugprone-forward-declaration-namespace\n#   This check would make forward declarations work only if each class name is\n#   unique across all namespaces, otherwise it would complain that e.g. Buffer\n#   is defined in Magnum::GL but a forward declaration appears in Magnum::Vk.\n#   Which is just useless, and goes against the point of namespaces.\n# clang-diagnostic-deprecated-declarations\n#   From time to time, Magnum annotates APIs with deprecation warnings,\n#   suggesting people to upgrade to newer / better designed / more flexible\n#   APIs. Treating such warnings as error is counterproductive, since the first\n#   thing you want to do after an upgrade is compiling existing *unchanged*\n#   code and ensuring all tests pass, and only then start updating the code.\n# readability-implicit-bool-conversion\n#   There's many cases of checking counts in if statements, such as\n#   `if(!importer->sceneCount())` for Magnum importers. For those there are no\n#   corresponding `hasScenes()` or such, and having to write `== 0` doesn't\n#   really improve readability in any way. Keeping this as a warning tho, as it\n#   *might* actually be useful in certain cases, just not treating it as an\n#   error.\n# performance-no-int-to-ptr\n#   \"error: integer to pointer cast pessimizes optimization opportunities\"\n#   triggered by gfx::replay::NodeHandle, which can be either a pointer (for\n#   the SceneGraph backend) or an arbitrary integer value (for the new\n#   data-oriented backend). Clang Tidy, tell me, how else am I supposed to\n#   implement type-safe handles?!\n# misc-misplaced-const\n#   \"'node' declared with a const-qualified typedef; results in the type being\n#   'esp::gfx::replay::NodeHandle_ *const' instead of 'const\n#   esp::gfx::replay::NodeHandle_ *'\". Same problem, how else am I supposed to\n#   implement type-safe handles? If the handle represents an integer, it's also\n#   not really \"const\" because I can use it to index a mutable array (which I\n#   regularly do). \"Fixing\" this warning would mean adding a const to the\n#   typedef AND THEN a const_cast to each and every reinterpret_cast that turns\n#   it into a SceneNode*. Which is way worse than the original problem.\n"
        },
        {
          "name": ".cmake-format.py",
          "type": "blob",
          "size": 0.4814453125,
          "content": "# flake8: noqa\nwith section(\"format\"):\n    line_width = 88  # Give a little more length\n    max_pargs_hwrap = 5\n    max_subgroups_hwrap = 3  # So set commands dont get wrapped\n    min_prefix_chars = 2\n    dangle_parens = True  # Dangle Parens to make diffs cleaner\n    always_wrap = [\n        \"add_library\",\n        \"target_link_libraries\",\n    ]  # Always wrap these ones\n    autosort = True  # Try to autosort lists\nwith section(\"markup\"):\n    enable_markup = False  # Don't format comments\n"
        },
        {
          "name": ".coveragerc",
          "type": "blob",
          "size": 0.0390625,
          "content": "[run]\nomit =\n    */tests/*\n    setup.py\n"
        },
        {
          "name": ".editorconfig",
          "type": "blob",
          "size": 0.322265625,
          "content": "# See https://editorconfig.org/ for more info :)\n\n[*]\ncharset = utf-8\nindent_style = space\nindent_size = 2\ntrim_trailing_whitespace = true\ninsert_final_newline = true\n\n# isort can't parse [*.{py,rst}], so specifying it separately\n# https://github.com/timothycrosley/isort/issues/830\n[*.py]\nindent_size = 4\n[*.rst]\nindent_size = 4\n"
        },
        {
          "name": ".eslintrc.json",
          "type": "blob",
          "size": 2.505859375,
          "content": "{\n  \"extends\": [\n    \"eslint:recommended\",\n    \"plugin:prettier/recommended\",\n    \"prettier/@typescript-eslint\"\n  ],\n  \"plugins\": [\n    \"html\"\n  ],\n  \"env\": {\n    \"browser\": true,\n    \"commonjs\": true,\n    \"node\": true,\n    \"es6\": true,\n    \"jest\": true\n  },\n  \"parserOptions\": {\n    \"ecmaVersion\": 2018,\n    \"sourceType\": \"module\"\n  },\n  \"rules\": {\n    \"no-console\": \"off\",\n    \"strict\": [\"error\", \"global\"],\n    \"curly\": \"warn\",\n    \"prettier/prettier\": \"error\"\n  },\n  \"parser\": \"babel-eslint\",\n  // Taken from create-react-app's eslint configuration\n  \"overrides\": [\n    {\n      \"files\": [\"**/*.ts?(x)\"],\n      \"parser\": \"@typescript-eslint/parser\",\n      \"parserOptions\": {\n        \"ecmaVersion\": 2018,\n        \"sourceType\": \"module\",\n        \"ecmaFeatures\": {\n          \"jsx\": true\n        },\n\n        // typescript-eslint specific options\n        \"warnOnUnsupportedTypeScriptVersion\": true\n      },\n      \"plugins\": [\"@typescript-eslint\"],\n      // If adding a typescript-eslint version of an existing ESLint rule,\n      // make sure to disable the ESLint rule here.\n      \"rules\": {\n        // TypeScript\"s `noFallthroughCasesInSwitch` option is more robust\n        \"default-case\": \"off\",\n        // \"tsc\" already handles this (https://github.com/typescript-eslint/typescript-eslint/issues/291)\n        \"no-dupe-class-members\": \"off\",\n        // \"tsc\" already handles this (https://github.com/typescript-eslint/typescript-eslint/issues/477)\n        \"no-undef\": \"off\",\n\n        // Add TypeScript specific rules (and turn off ESLint equivalents)\n        \"@typescript-eslint/consistent-type-assertions\": \"warn\",\n        \"no-array-constructor\": \"off\",\n        \"@typescript-eslint/no-array-constructor\": \"warn\",\n        \"no-use-before-define\": \"off\",\n        \"@typescript-eslint/no-use-before-define\": [\n          \"warn\",\n          {\n            \"functions\": false,\n            \"classes\": false,\n            \"variables\": false,\n            \"typedefs\": false\n          }\n        ],\n        \"no-unused-expressions\": \"off\",\n        \"@typescript-eslint/no-unused-expressions\": [\n          \"error\",\n          {\n            \"allowShortCircuit\": true,\n            \"allowTernary\": true,\n            \"allowTaggedTemplates\": true\n          }\n        ],\n        \"no-unused-vars\": \"off\",\n        \"@typescript-eslint/no-unused-vars\": [\n          \"warn\",\n          {\n            \"args\": \"none\",\n            \"ignoreRestSiblings\": true\n          }\n        ],\n        \"no-useless-constructor\": \"off\",\n        \"@typescript-eslint/no-useless-constructor\": \"warn\"\n      }\n    }\n  ]\n}\n"
        },
        {
          "name": ".github",
          "type": "tree",
          "content": null
        },
        {
          "name": ".gitignore",
          "type": "blob",
          "size": 2.09375,
          "content": "## c++\n\n# Prerequisites\n*.d\n\n# Compiled Object files\n*.slo\n*.lo\n*.o\n*.obj\n\n# Precompiled Headers\n*.gch\n*.pch\n\n# Compiled Dynamic libraries\n*.so\n*.dylib\n*.dll\n\n# Fortran module files\n*.mod\n*.smod\n\n# Compiled Static libraries\n*.lai\n*.la\n*.a\n*.lib\n\n# Executables\n*.exe\n*.out\n*.app\n\n## python\n\n# Byte-compiled / optimized / DLL files\n__pycache__/\n*.py[cod]\n*$py.class\n\n# C extensions\n*.so\n\n# Distribution / packaging\n.Python\nbuild*/\ndevelop-eggs/\ndist/\ndownloads/\neggs/\n.eggs/\nlib/\nlib64/\nparts/\nsdist/\nvar/\nwheels/\n*.egg-info/\n.installed.cfg\n*.egg\nMANIFEST\n\n# PyInstaller\n#  Usually these files are written by a python script from a template\n#  before PyInstaller builds the exe, so as to inject date/other infos into it.\n*.manifest\n*.spec\n\n# Installer logs\npip-log.txt\npip-delete-this-directory.txt\n\n# Unit test / coverage reports\nhtmlcov/\n.tox/\n.coverage\n.coverage.*\n.cache\nnosetests.xml\ncoverage.xml\n*.cover\n.hypothesis/\n.pytest_cache/\n\n# Translations\n*.mo\n*.pot\n\n# Django stuff:\n*.log\nlocal_settings.py\ndb.sqlite3\n\n# Flask stuff:\ninstance/\n.webassets-cache\n\n# Scrapy stuff:\n.scrapy\n\n# Sphinx documentation\ndocs/_build/\n\n# PyBuilder\ntarget/\n\n# Jupyter Notebook\n.ipynb_checkpoints\n\n# pyenv\n.python-version\n\n# celery beat schedule file\ncelerybeat-schedule\n\n# SageMath parsed files\n*.sage.py\n\n# Environments\n.env\n.venv\nenv/\nvenv/\nENV/\nenv.bak/\nvenv.bak/\n\n# Spyder project settings\n.spyderproject\n.spyproject\n\n# Rope project settings\n.ropeproject\n\n# mkdocs documentation\n/site\n\n# mypy\n.mypy_cache/\n\n# PyCharm\n.idea\n\n# vscode\n.vscode/\n\n.DS_Store\n\ncompile_commands.json\n.vimtags\n.ycm*\n.clangd\n\n.autoenv*\n\nbuild_with_utils.sh\nrun_example\n.lvimrc\n.ccls-cache/\n\n*.zip\n*.mp4\n\n.setuppy_args_cache.json\n\npre-commit-deps.txt\n\n# Vim swap files\n*.swp\n\n# Ignore all in data directory\n/data/*\n# ...except these necessary subdirectories...\n!/data/fonts/\n!/data/hm3d_semantics/\n!/data/matterport_semantics/\n!/data/pbr/\n!/data/test_assets/\n# ...and files\n!/data/default.pbr_config.json\n!/data/default.physics_config.json\n\n# ignore shortcut to build/tests/configure.h for ccls\n/src/tests/configure.h\n\n/src_python/habitat_sim/_ext\n/tools/qa_scenes/qa_scenes_output/\n"
        },
        {
          "name": ".gitmodules",
          "type": "blob",
          "size": 1.8125,
          "content": "[submodule \"src/deps/rapidjson\"]\n\tpath = src/deps/rapidjson\n\turl = https://github.com/Tencent/rapidjson.git\n[submodule \"src/deps/magnum\"]\n\tpath = src/deps/magnum\n\turl = https://github.com/mosra/magnum.git\n[submodule \"src/deps/corrade\"]\n\tpath = src/deps/corrade\n\turl = https://github.com/mosra/corrade.git\n[submodule \"src/deps/magnum-plugins\"]\n\tpath = src/deps/magnum-plugins\n\turl = https://github.com/mosra/magnum-plugins.git\n[submodule \"src/deps/pybind11\"]\n\tpath = src/deps/pybind11\n\turl = https://github.com/pybind/pybind11.git\n[submodule \"src/deps/eigen\"]\n\tpath = src/deps/eigen\n\turl = https://gitlab.com/libeigen/eigen.git\n[submodule \"src/deps/assimp\"]\n\tpath = src/deps/assimp\n\turl = https://github.com/assimp/assimp\n[submodule \"src/deps/glfw\"]\n\tpath = src/deps/glfw\n\turl = https://github.com/glfw/glfw\n[submodule \"src/deps/recastnavigation\"]\n\tpath = src/deps/recastnavigation\n\turl = https://github.com/erikwijmans/recastnavigation.git\n[submodule \"src/deps/magnum-integration\"]\n\tpath = src/deps/magnum-integration\n\turl = https://github.com/mosra/magnum-integration.git\n[submodule \"src/deps/magnum-bindings\"]\n\tpath = src/deps/magnum-bindings\n\turl = https://github.com/mosra/magnum-bindings.git\n[submodule \"docs/m.css\"]\n\tpath = docs/m.css\n\turl = https://github.com/mosra/m.css\n[submodule \"src/deps/tinyobjloader\"]\n\tpath = src/deps/tinyobjloader\n\turl = https://github.com/syoyo/tinyobjloader.git\n[submodule \"src/deps/bullet3\"]\n\tpath = src/deps/bullet3\n\turl = https://github.com/bulletphysics/bullet3\n[submodule \"src/deps/openexr\"]\n\tpath = src/deps/openexr\n\turl = https://github.com/AcademySoftwareFoundation/openexr\n[submodule \"src/deps/rlr-audio-propagation\"]\n\tpath = src/deps/rlr-audio-propagation\n\turl = https://github.com/facebookresearch/rlr-audio-propagation\n[submodule \"src/deps/zstd\"]\n\tpath = src/deps/zstd\n\turl = https://github.com/facebook/zstd\n"
        },
        {
          "name": ".lgtm.yml",
          "type": "blob",
          "size": 0.599609375,
          "content": "extraction:\n  cpp:\n    index: # Builds the project\n      build_command: \"python3 setup.py build_ext --inplace --headless --bullet\"\n    prepare:\n      packages: # required apt-get packages\n        - libbullet-dev\n        - libegl1-mesa-dev\n        - libglm-dev\n        - libgl1-mesa-glx\n        - libjpeg-dev\n        - mesa-utils\n  python:\n    index: #don't scan notebooks\n      exclude: examples/tutorials/nb_python/\n    python_setup:\n      version: \"3\"\npath_classifiers:\n  docs:\n    - \"docs\"\n  library:\n    - \"src/deps\"\n  tests:\n    - \"tests\"\nqueries: # remove useless alerts\n  exclude: py/import-and-import-from\n"
        },
        {
          "name": ".pre-commit-config.yaml",
          "type": "blob",
          "size": 4.294921875,
          "content": "exclude: '^(build|data/datasets|data/scene_datasets|node_modules/|src/deps|src/obsolete)'\n\ndefault_language_version:\n    python: python3\n\nrepos:\n-   repo: https://github.com/pre-commit/pre-commit-hooks\n    rev: v4.1.0\n    hooks:\n    -   id: trailing-whitespace\n    -   id: check-added-large-files\n        args: ['--maxkb=2000']\n    -   id: end-of-file-fixer\n    -   id: check-case-conflict\n    -   id: check-docstring-first\n    -   id: check-executables-have-shebangs\n    -   id: check-json\n        # The JSONs below support comments (against spec)\n        exclude: ^(.eslintrc.json|tsconfig.json)\n    -   id: check-merge-conflict\n    -   id: check-toml\n    -   id: check-xml\n    -   id: check-yaml\n        exclude: ^conda-build/.*/meta.yaml\n    -   id: debug-statements\n    -   id: mixed-line-ending\n        args: ['--fix=lf']\n    -   id: requirements-txt-fixer\n\n    # Changes tabs to spaces\n-   repo: https://github.com/Lucas-C/pre-commit-hooks\n    rev: v1.1.13\n    hooks:\n    -   id: remove-tabs\n        exclude: \"(^(.git|setup.cfg))|(.(json|scn|tsv)$)\"\n\n-   repo: https://github.com/macisamuele/language-formatters-pre-commit-hooks\n    rev: v2.3.0\n    hooks:\n    -   id: pretty-format-ini\n        args: [--autofix]\n    -   id: pretty-format-toml\n        args: [--autofix]\n        additional_dependencies:\n         - toml-sort==0.21.0\n\n-   repo: https://github.com/pre-commit/pygrep-hooks\n    rev: v1.9.0  # Use the ref you want to point at\n    hooks:\n    -   id: python-check-blanket-noqa\n    -   id: python-check-blanket-type-ignore\n\n-   repo: https://github.com/timothycrosley/isort\n    rev: 5.12.0\n    hooks:\n    -   id: isort\n        exclude: docs/\n\n-   repo: https://github.com/ambv/black\n    rev: 23.1.0\n    hooks:\n    -   id: black\n        exclude: ^examples/tutorials/(nb_python|notebooks)\n\n-   repo: https://github.com/astral-sh/ruff-pre-commit\n    # Ruff version.\n    rev: v0.0.277\n    hooks:\n    -   id: ruff\n        args: [--fix]\n        exclude: ^examples/tutorials/(nb_python|notebooks)\n\n-   repo: https://github.com/pycqa/flake8\n    rev: 5.0.4\n    hooks:\n    -   id: flake8\n        exclude: docs/\n        additional_dependencies: &flake8_dependencies\n        - flake8-bugbear==22.1.11\n        - flake8-builtins==1.5.3\n        - flake8-comprehensions==3.10.0\n        - flake8-return==1.2.0\n        - flake8-simplify==0.17.0\n\n-   repo: https://github.com/asottile/yesqa\n    rev: v1.3.0\n    hooks:\n    -   id: yesqa\n        additional_dependencies: *flake8_dependencies\n\n-   repo: https://github.com/pre-commit/mirrors-mypy\n    rev: 'v1.9.0'\n    hooks:\n    -   id: mypy\n        pass_filenames: false\n        additional_dependencies:\n        - attrs\n\n-   repo: https://github.com/seddonym/import-linter\n    rev: v1.2.6\n    hooks:\n    -   id: import-linter\n        entry: env PYTHONPATH=src_python lint-imports\n\n-   repo: https://github.com/kynan/nbstripout\n    rev: 0.5.0\n    hooks:\n    -   id: nbstripout\n\n-   repo: https://github.com/mwouts/jupytext\n    rev: v1.13.7\n    hooks:\n    -   id: jupytext\n        files: '^examples/tutorials/(notebooks|nb_python)/(.*\\.py|.*\\.ipynb)$'\n        args: [--update-metadata, '{\"jupytext\":{\"notebook_metadata_filter\":\"all\", \"cell_metadata_filter\":\"-all\"}, \"accelerator\":\"GPU\"}', --set-formats, 'nb_python//py:percent,notebooks//ipynb,', --pipe, black, --pipe, 'isort - --treat-comment-as-code \"# %%\"', --pipe-fmt, 'py:percent', --sync]\n        additional_dependencies:\n            - 'nbformat<=5.0.8'\n            - black==23.1.0\n            - isort==5.12.0\n\n-   repo: https://github.com/pre-commit/mirrors-clang-format\n    rev: v13.0.1\n    hooks:\n    -   id: clang-format\n        types_or: [c++, c, c#, cuda] # also run on CUDA\n        additional_dependencies:\n            - pip>=21\n\n-   repo: https://github.com/cheshirekow/cmake-format-precommit\n    rev: v0.6.13\n    hooks:\n    -   id: cmake-format\n        exclude: (^src/(cmake/Find|deps)|configure\\.h\\.cmake$)\n\n-   repo: https://github.com/pre-commit/mirrors-eslint\n    rev: v8.12.0\n    hooks:\n    -   id: eslint\n        args: [--fix, --ext .html,.js]\n        language_version: 14.21.3\n        additional_dependencies:\n        - eslint@6.4.0\n        - eslint-config-prettier@6.3.0\n        - eslint-plugin-prettier@3.1.0\n        - eslint-plugin-html@6.0.0\n        - prettier@1.18.2\n\n-   repo: https://github.com/shellcheck-py/shellcheck-py\n    rev: v0.8.0.4\n    hooks:\n    -   id: shellcheck\n"
        },
        {
          "name": "BUILD_FROM_SOURCE.md",
          "type": "blob",
          "size": 5.685546875,
          "content": "## [Experimental] PIP install\n\n- This is an automated way for building the necessary habitat binaries. For better support please skip to the Build from Source section.\n- The build files are not cached and therefore this build method is slow and not recommended for active development.\n\n```bash\n   git clone --branch stable https://github.com/facebookresearch/habitat-sim.git\n   cd habitat-sim\n   pip install . -v\n```\n\n- You can also allow pip to compile a specific version of Habitat. First clone the repo, then `pip install .` in the current git root directory\n  to start the compilation process. To quickly compile the latest main, run `pip install git+https://github.com/facebookresearch/habitat-sim`.\n\n- Since pip out of tree by default, this process will copy quite a lot of data to your TMPDIR. You can change this location by modifying the TMPDIR env variable.\n  It will also not cache previous builds effectively and therefore will be slow. For active development, building using `python setup.py install...` is recommended.\n\n- Most compilation options can be accessed by either modifying the relevant ENV\\_VARS (WITH\\_BULLET, WITH\\_CUDA, HEADLESS) etc or by passing the args through pip's `--global-option` and `--build-option` arguments.\n\n- By default, we build a headless version with bullet enabled.\n\n\n## Build from Source\n\nWe highly recommend installing a [miniconda](https://docs.conda.io/en/latest/miniconda.html) or [Anaconda](https://www.anaconda.com/distribution/#download-section) environment (note: python>=3.9 is required). Once you have Anaconda installed, here are the instructions.\n\n\n1. Clone this github repository.\n\n   ```bash\n   # Checkout the latest stable release\n   git clone --branch stable https://github.com/facebookresearch/habitat-sim.git\n   cd habitat-sim\n   ```\n\n   List of stable releases is [available here](https://github.com/facebookresearch/habitat-sim/releases). Main branch contains 'bleeding edge' code and under active development.\n\n1. Install Dependencies\n\n    Common\n\n   ```bash\n   # We require python>=3.9 and cmake>=3.10\n   conda create -n habitat python=3.9 cmake=3.14.0\n   conda activate habitat\n   pip install -r requirements.txt\n   ```\n\n    Linux (Tested with Ubuntu 18.04 with gcc 7.4.0)\n\n   ```bash\n   sudo apt-get update || true\n   # These are fairly ubiquitous packages and your system likely has them already,\n   # but if not, let's get the essentials for EGL support:\n   sudo apt-get install -y --no-install-recommends \\\n        libjpeg-dev libglm-dev libgl1-mesa-glx libegl1-mesa-dev mesa-utils xorg-dev freeglut3-dev\n   ```\n\n   See the github actions and workflow [configs for a full list of dependencies](https://github.com/facebookresearch/habitat-sim/blob/main/.github) that our CI installs on a clean Ubuntu VM. If you run into build errors later, this is a good place to check if all dependencies are installed.\n\n1. Build Habitat-Sim\n\n    Default build (for machines with a display attached)\n\n   ```bash\n   # Assuming we're still within habitat conda environment\n   python setup.py install\n   ```\n\n    For headless systems (i.e. without an attached display, e.g. in a cluster) and multiple GPU systems\n\n   ```bash\n   python setup.py install --headless\n   ```\n\n    For systems with CUDA (to build CUDA features)\n\n   ```bash\n   python setup.py install --with-cuda\n   ```\n\n   With physics simulation via [Bullet Physics SDK](https://github.com/bulletphysics/bullet3/):\n   To use Bullet, enable bullet physics build via:\n\n   ```bash\n   python setup.py install --bullet    # build habitat with bullet physics\n   ```\n\n   With audio sensor via [rlr-audio-propagation](https://github.com/facebookresearch/rlr-audio-propagation/):\n   To use Audio sensors (Linux only), enable the audio flag via:\n\n   ```bash\n   python setup.py install --audio    # build habitat with audio sensor\n   ```\n\n   Note1: Build flags stack, *e.g.* to build in headless mode, with CUDA, and bullet, one would use `--headless --with-cuda --bullet`.\n\n   Note2: some Linux distributions might require an additional `--user` flag to deal with permission issues.\n\n   Note3: for active development in Habitat, you might find `./build.sh` instead of `python setup.py install` more useful.\n\n   Note4: Audio sensor is only available on Linux.\n\n1. [Only if using `build.sh`] For use with [Habitat Lab](https://github.com/facebookresearch/habitat-lab) and your own python code, add habitat-sim to your `PYTHONPATH`. For example modify your `.bashrc` (or `.bash_profile` in Mac OS X) file by adding the line:\n   ```bash\n   export PYTHONPATH=$PYTHONPATH:/path/to/habitat-sim/\n   ```\n\n## Common build issues\n\n- If your machine has a custom installation location for the nvidia OpenGL and EGL drivers, you may need to manually provide the `EGL_LIBRARY` path to cmake as follows.  Add `-DEGL_LIBRARY=/usr/lib/x86_64-linux-gnu/nvidia-opengl/libEGL.so` to the `build.sh` command line invoking cmake. When running any executable adjust the environment as follows: `LD_LIBRARY_PATH=/usr/lib/x86_64-linux-gnu/nvidia-opengl:${LD_LIBRARY_PATH} examples/example.py`.\n\n- By default, the build process uses all cores available on the system to parallelize. On some virtual machines, this might result in running out of memory. You can serialize the build process via:\n   ```bash\n   python setup.py build_ext --parallel 1 install\n   ```\n\n- Build is tested on Tested with Ubuntu 18.04 with gcc 7.4.0 and MacOS 10.13.6 with Xcode 10 and clang-1000.10.25.5. If you experience compilation issues, please open an issue with the details of your OS and compiler versions.\n\n  We also have a dev slack channel, please follow this [link](https://join.slack.com/t/ai-habitat/shared_invite/enQtNjY1MzM1NDE4MTk2LTZhMzdmYWMwODZlNjg5MjZiZjExOTBjOTg5MmRiZTVhOWQyNzk0OTMyN2E1ZTEzZTNjMWM0MjBkN2VhMjQxMDI) to get added to the channel.\n"
        },
        {
          "name": "CODE_OF_CONDUCT.md",
          "type": "blob",
          "size": 0.244140625,
          "content": "# Code of Conduct\n\nMeta Platforms has adopted a Code of Conduct that we expect project participants to adhere to.\nPlease read the [full text](https://code.fb.com/codeofconduct/)\nso that you can understand what actions will and will not be tolerated.\n"
        },
        {
          "name": "CONTRIBUTING.md",
          "type": "blob",
          "size": 4.6533203125,
          "content": "# Contributing to Habitat-Sim\nWe want to make contributing to this project as easy and transparent as\npossible.\n\n## Developer Workflow\n- Active development should happen on your fork of the repositories.\n- Name your PR in a way that unambiguously identifies the feature or fix.\n- Follow the contribution guide to ensure your code is conformant to the conventions and style.\n- Try to make small, logically independent, self-documenting commits (and reflect this in the commit messages by providing brief rationale/change summary).\n- We encourage creating draft PRs to gather early feedback.\n- Request reviews from at least one Habitat core team member (if the scope of changes necessitates, request from two or more reviewers).\n- We have adopted squash-and-merge as the policy for incorporating PRs into the main branch.  We encourage more smaller/focused PRs rather than big PRs with many independent changes.  This also enables faster development by merging PRs into main quickly and reducing the need to rebase due to changes on main.\n- While working on a PR, try to religiously keep your fork up-to-date with main by rebasing as necessary.  Note that the above recommendation for smaller and more frequent PRs reduces the burden of rebasing.\n- We expect PR ready for final review only if Continuous Integration tests are passing.\n- Recommended: after getting a PR through reviews/feedback and is merged into main, delete the branch to de-clutter noise.\n- Reach out to us with questions or suggestions on our Slack channel.\n\n## Contributor License Agreement (\"CLA\")\nIn order to accept your pull request, we need you to submit a CLA. You only need\nto do this once to work on any of Facebook's open source projects. Complete your CLA [here](https://code.facebook.com/cla).\n\nBy contributing to habitat-sim, you agree that your contributions will be licensed\nunder [the LICENSE file](https://github.com/facebookresearch/habitat-sim/blob/main/LICENSE).\n\n## Versioning / release workflow\nWe use [semantic versioning](https://semver.org/). To prepare a release:\n1. Update version numbers.\n2. Update the change log.\n3. Make sure all tests are passing.\n4. Create a release tag with change log summary using the github release interface (release tag should follow semantic versioning as described above)\n\nStable versions are regularly assigned by Habitat core team after rigorous testing.\n\n## Issues\nWe use [GitHub issues](https://github.com/facebookresearch/habitat-sim/issues) to track public bugs. Please ensure your description is\nclear and has sufficient instructions to be able to reproduce the issue.\n\n\n## Coding Style\n\n- C++\n  - In general, we follow [C++ Core Guidelines](https://isocpp.github.io/CppCoreGuidelines/CppCoreGuidelines) and [Google C++ guidelines](https://google.github.io/styleguide/cppguide.html)\n  - Use `clang-format-12` for style enforcement and linting.\n  Install `clang-format-12` through `brew install clang-format` on macOS. For other systems, `clang-format-12` can be installed via `conda install clangdev -c conda-forge` or by downloading binaries or sources from [releases.llvm.org/download](http://releases.llvm.org/download.html).\n  For vim integration add to your .vimrc file `map <C-K> :%!clang-format<cr>` and use Ctrl+K to format entire file. Integration plugin for [vscode](https://marketplace.visualstudio.com/items?itemName=xaver.clang-format)..\n- Python\n  - We follow PEP8 and use [typing](https://docs.python.org/3/library/typing.html).\n  - We use `black` and `isort` for linting and code style of python code.\n  Install `black` and `isort` through `pip install -U black isort`. They can then be ran via `black .` and `isort`.\n\nWe also use pre-commit hooks to ensure linting and style enforcement. Install the pre-commit hooks with `pip install pre-commit && pre-commit install`.\n\n## Documentation\n- Our documentation style is based on Magnum / Corrade and uses [a similar build system](https://mcss.mosra.cz/documentation/doxygen/).\n- The gfx_batch library is a good example of the documentation style.\n- Documentation of PRs is highly encouraged!\n\n## Development Tips\n\n1. Install `ninja` (`sudo apt install ninja-build` on Linux, or `brew install ninja` on macOS) for significantly faster incremental builds\n1. Install `ccache` (`sudo apt install ccache` on Linux, or `brew install ccache` on macOS) for significantly faster clean re-builds and builds with slightly different settings\n1. You can skip reinstalling magnum every time by adding the argument of `--skip-install-magnum` to either `build.sh` or `setup.py`.  Note that you will still need to install magnum bindings once.\n1. Arguments to `build.sh` and `setup.py` can be cached between subsequent invocations with the flag `--cache-args` on the _first_ invocation.\n"
        },
        {
          "name": "DATASETS.md",
          "type": "blob",
          "size": 13.923828125,
          "content": "# HowTo Use Common Supported Datasets with Habitat-Sim\n\nðŸ¤— View the open-source collection of Habitat-ready datasets and test assets on Hugging Face at https://huggingface.co/ai-habitat!\n\n## Table of contents\n   1. [Habitat test scenes](#habitat-test-scenes)\n   1. [Habitat-Matterport 3D Research Dataset (HM3D)](#habitat-matterport-3d-research-dataset-hm3d)\n   1. [Habitat Synthetic Scenes Dataset (HSSD)](#habitat-synthetic-scene-dataset-hssd)\n   1. [AI2-THOR (Habitat)](#ai2-thor-habitat)\n   1. [Matterport3D (MP3D) dataset](#matterport3d-mp3d-dataset)\n   1. [Gibson and 3DSceneGraph datasets](#gibson-and-3dscenegraph-datasets)\n   1. [Replica Dataset](#replica-dataset)\n   1. [ReplicaCAD](#replicacad)\n   1. [ScanNet](#scannet)\n   1. [YCB Benchmarks - Object and Model Set](#ycb-benchmarks---object-and-model-set)\n   1. [Previewing dataset assets using Habitat-Sim's viewers](#previewing-dataset-assets-using-habitat-sims-viewers)\n\n___\n\n## Habitat test scenes\n[ðŸ¤— Browse on Hugging Face ðŸ¤—](https://huggingface.co/datasets/ai-habitat/habitat_test_scenes)\n\nWe provide 3 example scenes for performing unit tests in habitat-sim. These can be programmatically downloaded via Habitat's data download utility.\n\n```\npython -m habitat_sim.utils.datasets_download --uids habitat_test_scenes --data-path data/\n```\n\nWe also provide PointNav episodes sampled from these scenes for performing unit tests in habitat-lab. These can also be downloaded using Habitat's data download utility.\n\n```\npython -m habitat_sim.utils.datasets_download --uids habitat_test_pointnav_dataset --data-path data/\n```\n\n___\n\n## Habitat-Matterport 3D Research Dataset (HM3D)\n\nDetails: [https://aihabitat.org/datasets/hm3d/](https://aihabitat.org/datasets/hm3d/).\n\nGetting access: [https://matterport.com/habitat-matterport-3d-research-dataset](https://matterport.com/habitat-matterport-3d-research-dataset)\n\nGithub page with download links: [https://github.com/matterport/habitat-matterport-3dresearch](https://github.com/matterport/habitat-matterport-3dresearch)\n\nAfter getting access to the dataset, you can download manually or programmatically via Habitat's data download utility.\n\n### Downloading HM3D with the download utility\n\nFirst, you will need to generate a matterport API Token:\n\n1. Navigate to https://my.matterport.com/settings/account/devtools\n1. Generate an API token\n1. Your API token ID then functions as your username, passed to the download script with `--username`,\n and your API token secret functions as your password,\n passed to the download script with `--password`.\n Note: Make sure to write your API token secret down, you can't reveal it again!\n\nNow, you are ready to download. For example, to download the minival split, use:\n```\npython -m habitat_sim.utils.datasets_download --username <api-token-id> --password <api-token-secret> --uids hm3d_minival_v0.2\n```\n\nBy default, downloading the data for train/val/example scenes also pulls in the semantic annotations and configs for [HM3D-Semantics v0.2](https://aihabitat.org/datasets/hm3d-semantics/). To download only the semantic files for these splits, use the uid `hm3d_semantics`.\n\n\nBy default the download script will only download what is needed for Habitat-Sim. You can add `_full` to the uid to download the raw glbs in addition to what is needed for use with Habitat-Sim.\n\n### Loading semantics for HM3D\n\nFirst, ensure that the corresponding file structure exists (see minival example below):\n\n```\n> ls <PATH TO HM3D>\nhm3d_annotated_basis.scene_dataset_config.json    train/\nhm3d_basis.scene_dataset_config.json              val/\nminival/\n\n> ls <PATH TO HM3D>/minival\n00800-TEEsavR23oF/    00806-tQ5s4ShP627/\n00801-HaxA7YrQdEC/    00807-rsggHU7g7dh/\n00802-wcojb4TFT35/    00808-y9hTuugGdiq/\n00803-k1cupFYWXJ6/    00809-Qpor2mEya8F/\n00804-BHXhpBwSMLh/    hm3d_annotated_minival_basis.scene_dataset_config.json\n00805-SUHsP6z2gcJ/    hm3d_minival_basis.scene_dataset_config.json\n\n> ls <PATH TO HM3D>/minival/00800-TEEsavR23oF/\nTEEsavR23oF.basis.glb       TEEsavR23oF.basis.navmesh\nTEEsavR23oF.semantic.glb    TEEsavR23oF.semantic.txt\n```\nNote that there may be more files in `<PATH TO HM3D>/minival/00800-TEEsavR23oF/` if the full HM3D dataset is downloaded. Most importantly, ensure that the `hm3d_annotated_*`, `*.semantic.glb`, and `*.semantic.txt` files are present.\n\nTo load semantic annotations in Habitat-Sim:\n* Enable the semantic sensor\n* Set the `scene_dataset_config_file` configuration variable\n\nA simple example below:\n```\nimport habitat_sim\n\nbackend_cfg = habitat_sim.SimulatorConfiguration()\nbackend_cfg.scene_id = \"<PATH TO HM3D>/minival/00800-TEEsavR23oF/TEEsavR23oF.basis.glb\"\nbackend_cfg.scene_dataset_config_file = \"<PATH TO HM3D>/hm3d_annotated_basis.scene_dataset_config.json\"\n\nsem_cfg = habitat_sim.CameraSensorSpec()\nsem_cfg.uuid = \"semantic\"\nsem_cfg.sensor_type = habitat_sim.SensorType.SEMANTIC\n\nagent_cfg = habitat_sim.agent.AgentConfiguration()\nagent_cfg.sensor_specifications = [sem_cfg]\n\nsim_cfg = habitat_sim.Configuration(backend_cfg, [agent_cfg])\nsim = habitat_sim.Simulator(sim_cfg)\n```\n\nTo view the semantic annotations in the C++ viewer, install the latest `main` branch of Habitat-Sim and run the following command:\n```\n# ./build/viewer if compiled locally\nhabitat-viewer --dataset '<PATH TO HM3D>/hm3d_annotated_basis.scene_dataset_config.json' TEEsavR23oF\n```\n\n\nTo load semantic annotations in habitat-lab:\n\n* Add the semantic sensor to the list of agent sensors:\n\n    ```\n    SIMULATOR.AGENT_0.SENSORS = [\"RGB_SENSOR\", \"SEMANTIC_SENSOR\"]\n    ```\n* Set the `SIMULATOR.SCENE_DATASET` configuration variable:\n\n    ```\n    SIMULATOR.SCENE_DATASET = \"<PATH TO HM3D>/hm3d_annotated_basis.scene_dataset_config.json\"\n    ```\n\nNote that if you are using the RL environment from habitat-lab, `SIMULATOR.SCENE_DATASET` is overridden by the episode dataset (see [here](https://github.com/facebookresearch/habitat-lab/blob/e934b15c35233457cc3cb9c90ba0e207610dbd19/habitat/core/env.py#L94-L96)). Each episode in the episode dataset must point to the annotation config file (as done in the HM3D ObjectNav dataset [here](https://github.com/facebookresearch/habitat-lab)).\n\n___\n\n## Habitat Synthetic Scene Dataset (HSSD)\n\nDetails: [https://3dlg-hcvc.github.io/hssd/](https://3dlg-hcvc.github.io/hssd/).\n\nYou can browse and download the HSSD dataset from instructions provided in the above website.\n\nFor quick setup and use with habitat-sim and habitat-lab, register for access [on the huggingface hssd-hab repo page](https://huggingface.co/datasets/hssd/hssd-hab) and then use the `datasets_download.py` script as follows:\n\n```\npython -m habitat_sim.utils.datasets_download --username <huggingface-username> --password <huggingface-password> --uids hssd-hab --data-path data/\n```\n\n___\n\n## AI2-THOR (Habitat)\n\nDetails: [https://huggingface.co/datasets/hssd/ai2thor-hab](https://huggingface.co/datasets/hssd/ai2thor-hab).\n\nYou can download Habitat-compatible versions of the iTHOR, RoboTHOR, and ProcTHOR scene datasets from instructions provided in the above website.\n\n___\n\n## Matterport3D (MP3D) dataset\n\n\nDetails: [https://niessner.github.io/Matterport/](https://niessner.github.io/Matterport/).\nGithub: [https://github.com/niessner/Matterport](https://github.com/niessner/Matterport)\n\nWe provide 1 example scene from MP3D for performing unit tests in habitat-sim. This can be programmatically downloaded via Habitat's data download utility.\n\n```\npython -m habitat_sim.utils.datasets_download --uids mp3d_example_scene --data-path data/\n```\n\n\nThe full MP3D dataset for use with Habitat can be downloaded using the official [Matterport3D](https://niessner.github.io/Matterport/) download script as follows: `python download_mp.py --task habitat -o path/to/download/`. Note that this download script requires python 2.7 to run.\n\nYou only need the habitat zip archive and not the entire Matterport3D dataset.\n\nOnce you have the habitat zip archive, you should download [this SceneDatasetConfig file](http://dl.fbaipublicfiles.com/habitat/mp3d/config_v1/mp3d.scene_dataset_config.json) and place it in the root directory for the Matterport3D dataset (e.g. Habitat-Sim/data/scene_datasets/mp3d/). This file should then be specified as [the scene dataset config in the SimulatorConfiguration structure](/examples/tutorials/nb_python/ReplicaCAD_quickstart.py#L145) like this example for the ReplicaCAD dataset.\n\n___\n\n## Gibson and 3DSceneGraph datasets\n\nThe Gibson dataset for use with Habitat can be downloaded by agreeing to the terms of use in the [Gibson](https://github.com/StanfordVL/GibsonEnv#database) repository.\n\nSemantic information for Gibson is available from the [3DSceneGraph](https://3dscenegraph.stanford.edu/) dataset. The semantic data will need to be converted before it can be used within Habitat:\n   ```bash\n   tools/gen_gibson_semantics.sh /path/to/3DSceneGraph_medium/automated_graph /path/to/GibsonDataset /path/to/output\n   ```\n   To use semantics, you will need to enable the semantic sensor.\n\n   Once you have downloaded the Gibson dataset and converted the semantic data, you should download [this SceneDatasetConfig file](http://dl.fbaipublicfiles.com/habitat/gibson/config_v1/gibson_semantic.scene_dataset_config.json) and place it in the root directory for the Gibson dataset (e.g. Habitat-Sim/data/scene_datasets/gibson/). This file should then be specified as [the scene dataset config in the SimulatorConfiguration structure](/examples/tutorials/nb_python/ReplicaCAD_quickstart.py#L145) like this example for the ReplicaCAD dataset.\n\n___\n\n## Replica Dataset\n\nDetails and download instructions: [https://github.com/facebookresearch/Replica-Dataset](https://github.com/facebookresearch/Replica-Dataset).\n\n___\n\n## ReplicaCAD\nðŸ¤— Browse on Hugging Face ([interactive](https://huggingface.co/datasets/ai-habitat/ReplicaCAD_dataset), [baked_lighting](https://huggingface.co/datasets/ai-habitat/ReplicaCAD_baked_lighting)) ðŸ¤—\n\nDetails and instructions: [https://aihabitat.org/datasets/replica_cad/](https://aihabitat.org/datasets/replica_cad/).\n\n___\n\n## ScanNet\n\nThe official ScanNet data can be downloaded here: [http://www.scan-net.org/](http://www.scan-net.org/). To use ScanNet scans with Habitat-Sim, the `scene_*.ply` files need to be converted to glTF format (`*.glb`). For example, using [assimp](https://github.com/assimp/assimp):\n\n```\nassimp export <PLY FILE> <GLB PATH>\n```\n\nThe exported `*.glb` files can directly be used with Habitat-Sim versions >= 2.0.\n\nNote: Depending on the configured radius and height of the agent, certain scans may have no navigable locations on the navmesh (~200). These scenes can be filtered out by checking if `sim.pathfinder.is_loaded` is False.\n\n___\n\n## YCB Benchmarks - Object and Model Set\n[ðŸ¤— Browse Habitat-ready asset dataset on Hugging Face ðŸ¤—](https://huggingface.co/datasets/ai-habitat/ycb)\n\nDetails: [https://www.ycbbenchmarks.com/](https://www.ycbbenchmarks.com/).\n\n> YCB Object and Model Set is designed for facilitating benchmarking in robotic manipulation... The set is associated with a [model database](http://www.ycbbenchmarks.com/object-models/) which provides mesh models and high-resolution RGB-D scans of the objects for easy incorporation into manipulation and planning software platforms.\n\nQuick-start with the dataset_downloader utility:\n\n```\n# with conda install\npython -m habitat_sim.utils.datasets_download --uids ycb --data-path /path/to/data/\n\n# with source\npython /path/to/habitat_sim/src_python/habitat_sim/utils/datasets_download.py --uids ycb --data-path /path/to/data/\n```\n\nLoad the assets in python by setting [MetadataMediator.active_dataset](https://aihabitat.org/docs/habitat-sim/habitat_sim.metadata.MetadataMediator.html#active_dataset):\n```\n#load the full YCB dataset into the MetadataMediator\nsim.metadata_mediator.active_dataset = \"/path/to/data/objects/ycb/ycb.scene_dataset_config.json\"\n\n#then instance objects from the ObjectAttributesManager:\nchef_can_key = sim.get_object_template_manager().get_file_template_handles(\"002_master_chef_can\")[0]\nchef_can_object = sim.get_rigid_object_manager().add_object_by_template_handle(chef_can_key)\n```\nFor more information on using objects in habitat-sim, see the \"Habitat-Sim for Interaction\" and \"Habitat-Sim Advanced Topics\" sections of our [ECCV tutorial series](https://aihabitat.org/tutorial/2020/).\n\nTo quickly test in the viewer application:\n```\n#from the habitat-sim directory\n# C++\n# ./build/viewer if compiling locally\nhabitat-viewer --use-default-lighting --enable-physics --object-dir \"\"  --dataset data/objects/ycb/ycb.scene_dataset_config.json -- data/test_assets/scenes/simple_room.glb\n```\nThen press `'o'` key to add random objects from the dataset.\n\n___\n\n# Previewing dataset assets using  Habitat-Sim's viewers\n\nFor datasets with scene dataset configuration support (such as HM3D, ReplicaCAD, MP3D, Gibson, etc) you can preview the assets using one of Habitat's command-line driven viewers, either in c++ or python. When launching the viewer, you should specify not only the desired scene to load, but also the specifying the scene dataset configuration file, to guarantee the assets load and display correctly.  This has the added benefit of providing quick access to other scenes in the same dataset, without requiring a reload of the entire simulation environment from the command line.\n\nIf you are using the python [viewer](/examples/viewer.py), the command line parameters to load a scene dataset configuration and a scene file would be (run from the Habitat-Sim source directory):\n\n```\npython examples/viewer.py --dataset '<path to desired dataset config>/<desired dataset>.scene_dataset_config.json' --scene '<scene to show>'\n```\n\nIf you are using the c++ [viewer](/src/utils/viewer/viewer.cpp), the command line parameters to load a scene dataset configuration and a scene file would be (run from the Habitat-Sim source directory):\n\n```\n# ./build/viewer if compiled locally\nhabitat-viewer --dataset '<path to desired dataset config>/<desired dataset>.scene_dataset_config.json' '<scene to show>'\n```\n\nTo preview other scenes in the same scene dataset in either viewer, use `TAB`/`SHIFT-TAB` to cycle forward/backward through the list of scenes referenced by the loaded scene dataset config.\n"
        },
        {
          "name": "DETAILS.md",
          "type": "blob",
          "size": 4.091796875,
          "content": "## Details\n\nThe Habitat-Sim backend module is implemented in C++ and leverages the [magnum](https://github.com/mosra/magnum) graphics middleware library to support cross-platform deployment on a broad variety of hardware configurations. The architecture of the main abstraction classes is shown below. The design of this module ensures a few key properties:\n* Memory-efficient management of 3D environment resources (triangle mesh geometry, textures, shaders) ensuring shared resources are cached and re-used\n* Flexible, structured representation of 3D environments using SceneGraphs, allowing for programmatic manipulation of object state, and combination of objects from different environments\n* High-efficiency rendering engine with multi-attachment render passes for reduced overhead when multiple sensors are active\n* Arbitrary numbers of Agents and corresponding Sensors that can be linked to a 3D environment by attachment to a SceneGraph.\n\n<p align=\"center\">\n <img src='docs/images/habitat_architecture.png' width=\"800\" />\n <p align=\"center\"><i>Architecture of <code>Habitat-Sim</code> main classes</i></p>\n</p>\n\nThe Simulator delegates management of all resources related to 3D environments to a ResourceManager that is responsible for loading and caching 3D environment data from a variety of on-disk formats. These resources are used within SceneGraphs at the level of individual SceneNodes that represent distinct objects or regions in a particular Scene. Agents and their Sensors are instantiated by being attached to SceneNodes in a particular SceneGraph.\n\n<p align=\"center\">\n <img src='docs/images/sensor-data.png' width=\"600\" />\n <p align=\"center\"><i>Example rendered sensor observations</i></p>\n</p>\n\n## Performance\nThe table below reports performance statistics for a test scene from the Matterport3D dataset (id `17DRP5sb8fy`) on a `Xeon E5-2690 v4 CPU` and `Nvidia Titan Xp`. Single-thread performance reaches several thousand frames per second, while multi-process operation with several independent simulation backends can reach more than 10,000 frames per second on a single GPU!\n<table class=\"table\" id=\"fps_table\">\n <tr>\n   <td></td>\n   <th colspan=\"3\"> 1 proc </th>\n   <th colspan=\"3\"> 3 procs </th>\n   <th colspan=\"3\"> 5 procs </th>\n </tr>\n <tr>\n   <th>Sensors / Resolution</th>\n   <th>128</th>\n   <th>256</th>\n   <th>512</th>\n   <th>128</th>\n   <th>256</th>\n   <th>512</th>\n   <th>128</th>\n   <th>256</th>\n   <th>512</th>\n </tr>\n <tr>\n   <td>RGB</td>\n   <td>4093</td>\n   <td>1987</td>\n   <td>848</td>\n   <td>10638</td>\n   <td>3428</td>\n   <td>2068</td>\n   <td>10592</td>\n   <td>3574</td>\n   <td>2629</td>\n </tr>\n <tr>\n   <td>RGB + depth</td>\n   <td>2050</td>\n   <td>1042</td>\n   <td>423</td>\n   <td>5024</td>\n   <td>1715</td>\n   <td>1042</td>\n   <td>5223</td>\n   <td>1774</td>\n   <td>1348</td>\n </tr>\n <tr>\n   <td>RGB + depth + semantics*</td>\n   <td>709</td>\n   <td>596</td>\n   <td>394</td>\n   <td>1312</td>\n   <td>1219</td>\n   <td>979</td>\n   <td>1521</td>\n   <td>1429</td>\n   <td>1291</td>\n </tr>\n</table>\n\nPrevious simulation platforms that have operated on similar datasets typically produce on the order of a couple hundred frames per second. For example [Gibson](https://github.com/StanfordVL/GibsonEnv#gibson-framerate) reports up to about 150 fps with 8 processes, and [MINOS](https://github.com/minosworld/minos#benchmarking) reports up to about 167 fps with 4 threads.\n\n*Note: The semantic sensor in MP3D houses currently requires the use of additional house 3D meshes with orders of magnitude more geometric complexity leading to reduced performance. We expect this to be addressed in future versions leading to speeds comparable to RGB + depth; stay tuned.\n\n## Rendering to GPU Tensors\n\nWe support transferring rendering results directly to a [PyTorch](https://pytorch.org/) tensor via CUDA-GL Interop.\nThis feature is built by when Habitat-Sim is compiled with CUDA, i.e. built with `--with-cuda`.  To enable it, set the\n`gpu2gpu_transfer` flag of the sensor specification(s) to `True`\n\nThis is implemented in a way that is reasonably agnostic to the exact GPU-Tensor library being used, but we currently have only implemented support for PyTorch.\n"
        },
        {
          "name": "LICENSE",
          "type": "blob",
          "size": 1.06640625,
          "content": "MIT License\n\nCopyright (c) Meta Platforms, Inc. and its affiliates.\n\nPermission is hereby granted, free of charge, to any person obtaining a copy\nof this software and associated documentation files (the \"Software\"), to deal\nin the Software without restriction, including without limitation the rights\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\ncopies of the Software, and to permit persons to whom the Software is\nfurnished to do so, subject to the following conditions:\n\nThe above copyright notice and this permission notice shall be included in all\ncopies or substantial portions of the Software.\n\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\nSOFTWARE.\n"
        },
        {
          "name": "MANIFEST.in",
          "type": "blob",
          "size": 0.0537109375,
          "content": "graft src_python/habitat_sim/sensors/noise_models/data\n"
        },
        {
          "name": "README.md",
          "type": "blob",
          "size": 16.26171875,
          "content": "[![codecov](https://codecov.io/gh/facebookresearch/habitat-sim/branch/main/graph/badge.svg)](https://codecov.io/gh/facebookresearch/habitat-sim)\n[![GitHub license](https://img.shields.io/badge/license-MIT-blue.svg)](https://github.com/facebookresearch/habitat-sim/blob/main/LICENSE)\n[![Conda Version Badge](https://img.shields.io/conda/vn/aihabitat/habitat-sim?color=blue&label=conda%20version)](https://anaconda.org/aihabitat/habitat-sim)\n[![Conda Platforms support Badge](https://img.shields.io/conda/pn/aihabitat/habitat-sim?color=orange&label=platforms)](https://anaconda.org/aihabitat/habitat-sim)\n[![Documentation](https://img.shields.io/badge/docs-automated-green.svg)](https://aihabitat.org/docs/habitat-sim/)\n[![pre-commit](https://img.shields.io/badge/pre--commit-enabled-brightgreen?logo=pre-commit&logoColor=white)](https://github.com/pre-commit/pre-commit)\n[![Python 3.9](https://img.shields.io/badge/python-3.9.svg)](https://www.python.org/downloads/release/)\n[![Supports Bullet](https://img.shields.io/static/v1?label=supports&message=Bullet%20Physics&color=informational&link=https://opensource.google/projects/bullet3)](https://opensource.google/projects/bullet3)\n[![Twitter Follow](https://img.shields.io/twitter/follow/ai_habitat?style=social)](https://twitter.com/ai_habitat)\n\n# Habitat-Sim\n\nA high-performance physics-enabled 3D simulator with support for:\n- 3D scans of indoor/outdoor spaces (with built-in support for [HM3D](https://aihabitat.org/datasets/hm3d/), [MatterPort3D](https://niessner.github.io/Matterport/), [Gibson](http://gibsonenv.stanford.edu/database/), [Replica](https://github.com/facebookresearch/Replica-Dataset), and other datasets)\n- CAD models of spaces and piecewise-rigid objects (e.g. [ReplicaCAD](https://aihabitat.org/datasets/replica_cad/), [YCB](https://www.ycbbenchmarks.com/), [Google Scanned Objects](https://app.ignitionrobotics.org/GoogleResearch/fuel/collections/Google%20Scanned%20Objects)),\n- Configurable sensors (RGB-D cameras, egomotion sensing)\n- Robots described via URDF (mobile manipulators like [Fetch](http://docs.fetchrobotics.com/), fixed-base arms like [Franka](https://www.franka.de/), quadrupeds like [AlienGo](https://www.unitree.com/products/aliengo/)),\n- Rigid-body mechanics (via [Bullet](https://github.com/bulletphysics/bullet3)).\n\nThe design philosophy of Habitat is to prioritize simulation speed over the breadth of simulation capabilities. When rendering a scene from the Matterport3D dataset, Habitat-Sim achieves several thousand frames per second (FPS) running single-threaded and reaches over 10,000 FPS multi-process on a single GPU. Habitat-Sim simulates a Fetch robot interacting in ReplicaCAD scenes at over 8,000 steps per second (SPS), where each â€˜stepâ€™ involves rendering 1 RGBD observation (128Ã—128 pixels) and rigid-body dynamics for 1/30sec.\n\n\nHabitat-Sim is typically used with\n[Habitat-Lab](https://github.com/facebookresearch/habitat-lab), a modular high-level library for end-to-end experiments in embodied AI -- defining embodied AI tasks (e.g. navigation, instruction following, question answering), training agents (via imitation or reinforcement learning, or no learning at all as in classical SensePlanAct pipelines), and benchmarking their performance on the defined tasks using standard metrics.\n\n## [Questions or Comments? Join the AI Habitat community discussions forum.](https://github.com/facebookresearch/habitat-lab/discussions)\n\n[![Habitat Demo](https://img.shields.io/static/v1?label=WebGL&message=Try%20AI%20Habitat%20In%20Your%20Browser%20&color=blue&logo=webgl&labelColor=%23990000&style=for-the-badge&link=https://aihabitat.org/demo)](https://aihabitat.org/demo)\n\nhttps://user-images.githubusercontent.com/2941091/126080914-36dc8045-01d4-4a68-8c2e-74d0bca1b9b8.mp4\n\n---\n\n## Table of contents\n   1. [Citing Habitat](#citing-habitat)\n   1. [Installation](#installation)\n   1. [Testing](#testing)\n   1. [Documentation](#documentation)\n   1. [Datasets](#datasets)\n   1. [External Contributions](#external-contributions)\n   1. [License](#license)\n\n\n## Citing Habitat\nIf you use the Habitat platform in your research, please cite the [Habitat 1.0](https://arxiv.org/abs/1904.01201), [Habitat 2.0](https://arxiv.org/abs/2106.14405), and [Habitat 3.0](https://arxiv.org/abs/2310.13724) papers:\n\n```\n@misc{puig2023habitat3,\n      title  = {Habitat 3.0: A Co-Habitat for Humans, Avatars and Robots},\n      author = {Xavi Puig and Eric Undersander and Andrew Szot and Mikael Dallaire Cote and Ruslan Partsey and Jimmy Yang and Ruta Desai and Alexander William Clegg and Michal Hlavac and Tiffany Min and Theo Gervet and VladimiÌr VondrusÌŒ and Vincent-Pierre Berges and John Turner and Oleksandr Maksymets and Zsolt Kira and Mrinal Kalakrishnan and Jitendra Malik and Devendra Singh Chaplot and Unnat Jain and Dhruv Batra and Akshara Rai and Roozbeh Mottaghi},\n      year={2023},\n      archivePrefix={arXiv},\n}\n\n@inproceedings{szot2021habitat,\n  title     =     {Habitat 2.0: Training Home Assistants to Rearrange their Habitat},\n  author    =     {Andrew Szot and Alex Clegg and Eric Undersander and Erik Wijmans and Yili Zhao and John Turner and Noah Maestre and Mustafa Mukadam and Devendra Chaplot and Oleksandr Maksymets and Aaron Gokaslan and Vladimir Vondrus and Sameer Dharur and Franziska Meier and Wojciech Galuba and Angel Chang and Zsolt Kira and Vladlen Koltun and Jitendra Malik and Manolis Savva and Dhruv Batra},\n  booktitle =     {Advances in Neural Information Processing Systems (NeurIPS)},\n  year      =     {2021}\n}\n\n@inproceedings{habitat19iccv,\n  title     =     {Habitat: {A} {P}latform for {E}mbodied {AI} {R}esearch},\n  author    =     {Manolis Savva and Abhishek Kadian and Oleksandr Maksymets and Yili Zhao and Erik Wijmans and Bhavana Jain and Julian Straub and Jia Liu and Vladlen Koltun and Jitendra Malik and Devi Parikh and Dhruv Batra},\n  booktitle =     {Proceedings of the IEEE/CVF International Conference on Computer Vision (ICCV)},\n  year      =     {2019}\n}\n```\n\nHabitat-Sim also builds on work contributed by others.  If you use contributed methods/models, please cite their works.  See the [External Contributions](#external-contributions) section\nfor a list of what was externally contributed and the corresponding work/citation.\n\n\n## Installation\n\nHabitat-Sim can be installed in 3 ways:\n1. Via Conda - Recommended method for most users. Stable release and nightly builds.\n1. [Experimental] Via PIP - `pip install .` to compile the latest headless build with Bullet. Read [build instructions and common build issues](BUILD_FROM_SOURCE.md).\n1. Via Docker - Updated approximately once per year for the [Habitat Challenge](https://aihabitat.org/challenge/). Read [habitat-docker-setup](https://github.com/facebookresearch/habitat-lab#docker-setup).\n1. Via Source - For active development. Read [build instructions and common build issues](BUILD_FROM_SOURCE.md).\n\n### [Recommended] Conda Packages\n\nHabitat is under active development, and we advise users to restrict themselves to [stable releases](https://github.com/facebookresearch/habitat-sim/releases). Starting with v0.1.4, we provide [conda packages for each release](https://anaconda.org/aihabitat).\n\n1. **Preparing conda env**\n\n   Assuming you have [conda](https://docs.conda.io/projects/conda/en/latest/user-guide/install/) installed, let's prepare a conda env:\n   ```bash\n   # We require python>=3.9 and cmake>=3.10\n   conda create -n habitat python=3.9 cmake=3.14.0\n   conda activate habitat\n   ```\n\n1. **conda install habitat-sim**\n\n   Pick one of the options below depending on your system/needs:\n\n   - To install on machines with an attached display:\n      ```bash\n      conda install habitat-sim -c conda-forge -c aihabitat\n      ```\n   - To install on headless machines (i.e. without an attached display, e.g. in a cluster) and machines with multiple GPUs (this parameter relies on EGL and thus does *not* work on MacOS):\n      ```\n      conda install habitat-sim headless -c conda-forge -c aihabitat\n      ```\n   - [**Most common scenario**] To install habitat-sim with bullet physics\n      ```\n      conda install habitat-sim withbullet -c conda-forge -c aihabitat\n      ```\n\n   - Note: Build parameters can be chained together. For instance, to install habitat-sim with physics on headless machines:\n      ```\n      conda install habitat-sim withbullet headless -c conda-forge -c aihabitat\n      ```\n\nConda packages for older versions can installed by explicitly specifying the version, e.g. `conda install habitat-sim=0.1.6 -c conda-forge -c aihabitat`.\n\nWe also provide a [nightly conda build for the main branch](https://anaconda.org/aihabitat-nightly). However, this should only be used if you need a specific feature not yet in the latest release version. To get the nightly build of the latest main, simply swap `-c aihabitat` for `-c aihabitat-nightly`.\n\n## Testing\n\n1. Let's download some 3D assets using our python data download utility:\n   - Download (testing) 3D scenes\n      ```bash\n      python -m habitat_sim.utils.datasets_download --uids habitat_test_scenes --data-path /path/to/data/\n      ```\n      Note that these testing scenes do not provide semantic annotations.\n      If you would like to test the semantic sensors via `example.py`, please use the data from the Matterport3D dataset (see [Datasets](DATASETS.md)).\n\n   - Download example objects\n      ```bash\n      python -m habitat_sim.utils.datasets_download --uids habitat_example_objects --data-path /path/to/data/\n      ```\n\n1. **Interactive testing**: Use the interactive viewer included with Habitat-Sim in either C++ or python:\n   ```bash\n   #C++\n   # ./build/viewer if compiling locally\n   habitat-viewer /path/to/data/scene_datasets/habitat-test-scenes/skokloster-castle.glb\n\n   #Python\n   #NOTE: depending on your choice of installation, you may need to add '/path/to/habitat-sim' to your PYTHONPATH.\n   #e.g. from 'habitat-sim/' directory run 'export PYTHONPATH=$(pwd)'\n   python examples/viewer.py --scene /path/to/data/scene_datasets/habitat-test-scenes/skokloster-castle.glb\n   ```\n   You should be able to control an agent in this test scene.\n   Use W/A/S/D keys to move forward/left/backward/right and arrow keys or mouse (LEFT click) to control gaze direction (look up/down/left/right).\n   Try to find the picture of a woman surrounded by a wreath.\n   Have fun!\n\n1. **Physical interactions**: Habitat-sim provides rigid and articulated dynamics simulation via integration with [Bullet physics](https://pybullet.org/).\n   Try it out now with our interactive viewer functionality in C++ or python.\n\n   First, download our fully interactive [ReplicaCAD apartment dataset](https://aihabitat.org/datasets/replica_cad/) (140 MB):\n\n   ```bash\n   #NOTE: by default, data will be downloaded into habitat-sim/data/. Optionally modify the data path by adding:  `--data-path /path/to/data/`\n   # with conda install\n   python -m habitat_sim.utils.datasets_download --uids replica_cad_dataset\n\n   # with source (from inside habitat_sim/)\n   python src_python/habitat_sim/utils/datasets_download.py --uids replica_cad_dataset\n   ```\n   - Alternatively, 105 scene variations with pre-baked lighting are available via `--uids replica_cad_baked_lighting` (480 MB).\n\n   Then load a ReplicaCAD scene in the viewer application with physics enabled. If you modified the data path above, also modify it in viewer calls below.\n\n   ```bash\n   #C++\n   # ./build/viewer if compiling locally\n   habitat-viewer --enable-physics --dataset data/replica_cad/replicaCAD.scene_dataset_config.json -- apt_1\n\n   #python\n   #NOTE: habitat-sim/ directory must be on your `PYTHONPATH`\n   python examples/viewer.py --dataset data/replica_cad/replicaCAD.scene_dataset_config.json --scene apt_1\n   ```\n   - Using scenes with pre-baked lighting instead? Use `--dataset data/replica_cad_baked_lighting/replicaCAD_baked.scene_dataset_config.json --scene Baked_sc1_staging_00`\n\n   The viewer application outputs the full list of keyboard and mouse interface options to the console at runtime.\n\n   Quickstart Example:\n   - `WASD` to move\n   - `LEFT` click and drag the mouse to look around\n   - press `SPACE` to toggle simulation off/on (default on)\n   - press `'m'` to switch to \"GRAB\" mouse mode\n    - now `LEFT` or `RIGHT` click and drag to move objects or open doors/drawers and release to drop the object\n    - with an object gripped, scroll the mouse wheel to:\n      - (default): move it closer or farther away\n      - (+`ALT`): rotate object fixed constraint frame (yaw)\n      - (+`CTRL`): rotate object fixed constraint frame (pitch)\n      - (+`ALT`+`CTRL`): rotate object fixed constraint frame (roll)\n\n1. **Non-interactive testing** (e.g. for headless systems): Run the example script:\n   ```bash\n   python /path/to/habitat-sim/examples/example.py --scene /path/to/data/scene_datasets/habitat-test-scenes/skokloster-castle.glb\n   ```\n   The agent will traverse a particular path and you should see the performance stats at the very end, something like this:\n  `640 x 480, total time: 3.208 sec. FPS: 311.7`.\n\n   To reproduce the benchmark table from [Habitat ICCV'19](https://arxiv.org/abs/1904.01201) run `examples/benchmark.py --scene /path/to/mp3d_example/17DRP5sb8fy/17DRP5sb8fy.glb`.\n\n   Additional arguments to `example.py` are provided to change the sensor configuration, print statistics of the semantic annotations in a scene, compute action-space shortest path trajectories, and set other useful functionality. Refer to the `example.py` and `demo_runner.py` source files for an overview.\n\n   Load a specific MP3D or Gibson house: `examples/example.py --scene path/to/mp3d/house_id.glb`.\n\n\n   We have also provided an [example demo](https://aihabitat.org/docs/habitat-lab/habitat-lab-demo.html) for reference.\n\n   To run a physics example in python (after building with \"Physics simulation via Bullet\"):\n   ```bash\n   python examples/example.py --scene /path/to/data/scene_datasets/habitat-test-scenes/skokloster-castle.glb --enable_physics\n   ```\n   Note that in this mode the agent will be frozen and oriented toward the spawned physical objects. Additionally, `--save_png` can be used to output agent visual observation frames of the physical scene to the current directory.\n\n\n### Common testing issues\n\n- If you are running on a remote machine and experience display errors when initializing the simulator, e.g.\n   ```bash\n    X11: The DISPLAY environment variable is missing\n    Could not initialize GLFW\n   ```\n\n  ensure you do not have `DISPLAY` defined in your environment (run `unset DISPLAY` to undefine the variable)\n\n- If you see libGL errors like:\n\n   ```bash\n    X11: The DISPLAY environment variable is missing\n    Could not initialize GLFW\n   ```\n\n    chances are your libGL is located at a non-standard location. See e.g. [this issue](https://askubuntu.com/questions/541343/problems-with-libgl-fbconfigs-swrast-through-each-update).\n\n## Documentation\n\nBrowse the online [Habitat-Sim documentation](https://aihabitat.org/docs/habitat-sim/index.html).\n\nCheck out our [ECCV tutorial series](https://aihabitat.org/tutorial/2020/) for a hands-on quickstart experience.\n\nCan't find the answer to your question? Try asking the developers and community on our [Discussions forum](https://github.com/facebookresearch/habitat-lab/discussions).\n\n## Datasets\n\n[HowTo use common supported datasets with Habitat-Sim](DATASETS.md).\n\n\n## External Contributions\n\n* If you use the noise model from PyRobot, please cite the their [technical report](https://github.com/facebookresearch/pyrobot#citation).\n\n\n    Specifically, the noise model used for the noisy control functions named `pyrobot_*` and defined in `src_python/habitat_sim/agent/controls/pyrobot_noisy_controls.py`\n\n\n* If you use the Redwood Depth Noise Model, please cite their [paper](http://redwood-data.org/indoor/)\n\n    Specifically, the noise model defined in `src_python/habitat_sim/sensors/noise_models/redwood_depth_noise_model.py` and `src/esp/sensor/RedwoodNoiseModel.*`\n\n\n## License\n\nHabitat-Sim is MIT licensed. See the [LICENSE](LICENSE) for details.\n\nThe demo scripts use:\n- [The KingÂ´s Hall](https://sketchfab.com/3d-models/the-king-s-hall-d18155613363445b9b68c0c67196d98d) by [Skokloster Castle (Skoklosters slott)](https://sketchfab.com/SkoklosterCastle) licensed under [Creative Commons Attribution](http://creativecommons.org/licenses/by/4.0/)\n- [Van Gogh Room](https://sketchfab.com/3d-models/van-gogh-room-311d052a9f034ba8bce55a1a8296b6f9) by [ruslans3d](https://sketchfab.com/ruslans3d) licensed under [Creative Commons Attribution](http://creativecommons.org/licenses/by/4.0/)\n"
        },
        {
          "name": "build.sh",
          "type": "blob",
          "size": 1.17578125,
          "content": "#!/usr/bin/env bash\n\n# Copyright (c) Meta Platforms, Inc. and its affiliates.\n# This source code is licensed under the MIT license found in the\n# LICENSE file in the root directory of this source tree.\n\n# Propagate failures properly\nset -e\n\nbuilder_args=()\nwhile [[ $# -gt 0 ]]\ndo\nkey=\"$1\"\n\ncase $key in\n    --run-tests)\n      shift\n      RUN_TESTS=true\n      builder_args+=(\"--build-tests\")\n      ;;\n    *)    # Forward unknown args to builder\n      shift\n      builder_args+=(\"$key\")\n      ;;\nesac\ndone\n\n\n# devfair/learnfair custom stuff: EGL path, and module loads\nmy_hostname=$(hostname)\nif [[ $my_hostname =~ \"fair\" ]]; then\n  module purge\n  module load cuda/10.0\n  module load cudnn/v7.4-cuda.10.0\n  module load cmake/3.15.3/gcc.7.3.0\nfi\n\npython setup.py build_ext --inplace \"${builder_args[@]}\"\n\nhere=$(pwd)\nif [ \"$RUN_TESTS\" = true ] ; then\n  cd build\n  PYTHONPATH=${here}/src_python ctest -V\nfi\n\n# Check if src_python has been added to python path, otherwise remind user\nif [[ \"$PYTHONPATH\" == *\"src_python\"* ]]; then\n  echo \"\\`src_python\\` subdir found in PYTHONPATH : \\`$PYTHONPATH\\`\"\nelse\n  echo \"Add src_python to PYTHONPATH, i.e. \\`export PYTHONPATH=${here}/src_python:\\${PYTHONPATH}\\`\"\nfi\n"
        },
        {
          "name": "codecov.yml",
          "type": "blob",
          "size": 0.0888671875,
          "content": "ignore:\n  - \"build/**\"\n  - \"src/deps/**\"\n  - \"src/tests/**\"\n  - \"test/**\"\n  - \"**/test/**\"\n"
        },
        {
          "name": "conda-build",
          "type": "tree",
          "content": null
        },
        {
          "name": "data",
          "type": "tree",
          "content": null
        },
        {
          "name": "docs",
          "type": "tree",
          "content": null
        },
        {
          "name": "examples",
          "type": "tree",
          "content": null
        },
        {
          "name": "install_deps.sh",
          "type": "blob",
          "size": 0.48046875,
          "content": "#!/usr/bin/env bash\n\n# Copyright (c) Meta Platforms, Inc. and its affiliates.\n# This source code is licensed under the MIT license found in the\n# LICENSE file in the root directory of this source tree.\n\n# Detect the platform\necho \"Installing dependencies. You might be prompted for your sudo password.\"\nOS=\"$(uname)\"\ncase $OS in\n  'Linux')\n    sudo apt-get install -y libomp-dev libx11-dev\n    ;;\n  'WindowsNT')\n    OS='Windows'\n    ;;\n  'Darwin')\n    brew install libomp\n    ;;\n  *) ;;\nesac\n"
        },
        {
          "name": "mypy.ini",
          "type": "blob",
          "size": 0.64453125,
          "content": "[mypy]\n# do not follow imports (except for ones found in typeshed)\nignore_missing_imports = True\n\nfollow_imports = silent\n\nno_implicit_optional = True\n# treat Optional per PEP 484\nstrict_optional = False\n\nwarn_unused_configs = True\nwarn_redundant_casts = True\n# ensure all execution paths are returning\nwarn_no_return = True\n# Re-enable https://github.com/python/mypy/issues/11839 fixed\nwarn_unreachable = False\n# Enables redefinitions of types in same proper scopes\nallow_redefinition = True\nshow_error_codes = True\ncheck_untyped_defs = True\n\nfiles=\n    src_python/habitat_sim,\n    tests\npython_version = 3.9\n\n[mypy-habitat_sim.bindings]\nignore_errors = True\n"
        },
        {
          "name": "package.json",
          "type": "blob",
          "size": 2.5517578125,
          "content": "{\n  \"name\": \"habitat-sim\",\n  \"version\": \"0.3.2\",\n  \"description\": \"A high performance simulator for training embodied agents\",\n  \"devDependencies\": {\n    \"@babel/core\": \"^7.6.0\",\n    \"@babel/node\": \"^7.7.7\",\n    \"@babel/plugin-proposal-class-properties\": \"^7.5.5\",\n    \"@babel/plugin-transform-runtime\": \"^7.7.6\",\n    \"@babel/preset-env\": \"^7.6.0\",\n    \"@babel/preset-typescript\": \"^7.7.7\",\n    \"@babel/runtime\": \"^7.7.6\",\n    \"@typescript-eslint/eslint-plugin\": \"^2.14.0\",\n    \"@typescript-eslint/parser\": \"^2.14.0\",\n    \"babel-eslint\": \"^10.0.3\",\n    \"babel-loader\": \"^8.0.6\",\n    \"babel-plugin-transform-es2015-modules-commonjs\": \"^6.26.2\",\n    \"css-loader\": \"^3.2.0\",\n    \"eslint\": \"^6.8.0\",\n    \"eslint-config-prettier\": \"^6.3.0\",\n    \"eslint-loader\": \"^3.0.0\",\n    \"eslint-plugin-html\": \"^6.0.0\",\n    \"eslint-plugin-prettier\": \"^3.1.0\",\n    \"finalhandler\": \"^1.1.2\",\n    \"html-webpack-plugin\": \"^3.2.0\",\n    \"jest\": \"^24.9.0\",\n    \"jest-image-snapshot\": \"^2.11.1\",\n    \"minimist\": \"^1.2.0\",\n    \"prettier\": \"^1.18.2\",\n    \"puppeteer\": \"^2.0.0\",\n    \"serve-static\": \"^1.14.1\",\n    \"style-loader\": \"^1.0.0\",\n    \"typescript\": \"^3.7.4\",\n    \"webpack\": \"^4.40.2\",\n    \"webpack-cli\": \"^3.3.9\"\n  },\n  \"scripts\": {\n    \"test\": \"jest ./src/esp/bindings_js/tests/\",\n    \"test_with_coverage\": \"jest ./src/esp/bindings_js/tests/ --collectCoverage\",\n    \"format\": \"prettier --trailing-comma es5 --single-quote './src/esp/bindings_js/**/*{.js,.ts}'\",\n    \"build\": \"webpack --config ./src/esp/bindings_js/webpack.config.js\",\n    \"lint\": \"eslint --ext .html,.js,.ts ./src/esp/bindings_js\",\n    \"lint-fix\": \"eslint --ext .html,.js,.ts --fix ./src/esp/bindings_js\"\n  },\n  \"repository\": {\n    \"type\": \"git\",\n    \"url\": \"git+https://github.com/facebookresearch/habitat-sim.git\"\n  },\n  \"jest\": {\n    \"collectCoverage\": false,\n    \"collectCoverageFrom\": [\n      \"./src/esp/bindings_js/**/*.{js,jsx,.ts}\",\n      \"!**/node_modules/**\",\n      \"!**/webpack.config.js\"\n    ],\n    \"coverageDirectory\": \"./coverage_js\"\n  },\n  \"babel\": {\n    \"presets\": [\n      \"@babel/preset-env\",\n      \"@babel/preset-typescript\"\n    ],\n    \"plugins\": [\n      \"@babel/plugin-proposal-class-properties\",\n      \"@babel/plugin-transform-runtime\"\n    ],\n    \"env\": {\n      \"test\": {\n        \"plugins\": [\n          \"transform-es2015-modules-commonjs\"\n        ]\n      }\n    }\n  },\n  \"keywords\": [\n    \"embodied\",\n    \"sim\",\n    \"ai\",\n    \"agents\"\n  ],\n  \"author\": \"FAIR A-STAR\",\n  \"license\": \"MIT\",\n  \"bugs\": {\n    \"url\": \"https://github.com/facebookresearch/habitat-sim/issues\"\n  },\n  \"homepage\": \"https://github.com/facebookresearch/habitat-sim#readme\"\n}\n"
        },
        {
          "name": "pyproject.toml",
          "type": "blob",
          "size": 1.2080078125,
          "content": "[build-system]\nbuild-backend = \"setuptools.build_meta\"\nrequires = [\n            \"cmake\",\n            \"ninja\",\n            \"pip\",\n            \"setuptools\",\n            \"wheel\",\n           ]\n\n[tool.black]\nexclude = '''\n(\n  /(\n      \\.eggs         # exclude a few common directories in the\n    | \\.git          # root of the project\n    | \\.hg\n    | \\.mypy_cache\n    | \\.tox\n    | \\.venv\n    | _build\n    | buck-out\n    | ^examples/tutorials/notebooks\n    | ^examples/tutorials/nb_python\n    | build\n    | dist\n    | obselete\n    | deps\n  )/\n)\n'''\n\n[tool.isort]\nskip_glob = [\"*/deps/*\", \"*/build/*\", \"*/obselete/*\"]\nknown_first_party = [\"habitat_sim\"]\nprofile = 'black'\ntreat_comments_as_code = \"# %%\"\n\n[tool.ruff]\nexclude = [\n    \".git\",\n    \"__pycache__\",\n    \"build\",\n    \"data\",\n    \"dist\",\n    \"docs\",\n    \"src/deps\",\n    \"tools/run-clang-tidy.py\",\n]\nignore = [\n    \"A003\",\n    \"B018\",\n    \"B9\",\n    \"C401\",\n    \"C402\",\n    \"C408\",\n    \"RET504\",\n    \"RET505\",\n    \"SIM105\",\n    \"PERF2\",\n    \"PERF4\",\n]\nline-length = 88\nselect = [\n    \"A\",\n    \"B\",\n    \"C4\",\n    \"F\",\n    \"RET\",\n    \"SIM\",\n    \"W\",\n    \"PERF\",\n]\n\n[tool.ruff.per-file-ignores]\n\"*/__init__.py\" = [\"F401\"]\n\"examples/tutorials/nb_python/*.py\" = [\n    \"B008\",\n    \"F841\",\n]\n"
        },
        {
          "name": "requirements.txt",
          "type": "blob",
          "size": 0.1259765625,
          "content": "attrs>=19.1.0\ngitpython\nimageio\nimageio-ffmpeg\nmatplotlib\nnumba\nnumpy==1.26.4\nnumpy-quaternion\npillow==10.4.0\nscipy>=1.10.1\ntqdm\n"
        },
        {
          "name": "setup.cfg",
          "type": "blob",
          "size": 1.1708984375,
          "content": "[aliases]\ntest = pytest\n\n[build_ext]\nbuild_temp = build\n\n[flake8]\nselect = A,B,C,F,R,W,SIM\nexclude =\n\t.git,\n\t__pycache__,\n\tbuild,\n\tdata,\n\tdist,\n\tdocs,\n\tsrc/deps,\n\ttools/run-clang-tidy.py\nmax-line-length = 88\n# A003 prevents class attrs from having builtin name properties\n# C401, and C402 are ignored to make scanning between dict and set easy\n# C408 ignored because we like the dict keyword argument syntax\n# R504 has some false positives since it doesn't care about side effects\n# W503 is incompatible with Black\n# SIM105 is a nice suggestion but except: ImportError is also really readable\n# SIM9 rules are experimental\nignore =\n\tA003,\n\tC401,C402,C408,\n\tSIM105,SIM113,SIM9\n\tR504,R505,\n\tW503\nper-file-ignores =\n\t*/__init__.py:F401\n\texamples/tutorials/nb_python/*.py:B008,F841\n\n[importlinter]\nroot_packages=\n\texamples\n\thabitat_sim\n\ttests\n\n[importlinter:contract:1]\nname = examples and tests do not import habitat_sim.bindings directly\ntype = forbidden\nsource_modules=\n\texamples\n\ttests\nforbidden_modules=\n\thabitat_sim.bindings\nallow_indirect_imports=True\n\n[tool:pytest]\naddopts = --verbose -rsxX -q\ntestpaths = tests\nmarkers =\n\tgfxtest: marks a test as needing to render\nnorecursedirs=tests/helpers\n"
        },
        {
          "name": "setup.py",
          "type": "blob",
          "size": 15.9228515625,
          "content": "#!/usr/bin/env python3\n\n# Copyright (c) Meta Platforms, Inc. and its affiliates.\n# This source code is licensed under the MIT license found in the\n# LICENSE file in the root directory of this source tree.\n\n\"\"\"\nAdapted from: https://www.benjack.io/building-and-testing-a-hybrid-python/c-package/\n\"\"\"\n\nimport argparse\nimport builtins\nimport glob\nimport json\nimport os\nimport os.path as osp\nimport re\nimport shlex\nimport shutil\nimport subprocess\nimport sys\nfrom distutils.util import strtobool\nfrom distutils.version import StrictVersion\n\nfrom setuptools import Extension, find_packages, setup\nfrom setuptools.command.build_ext import build_ext\n\ntry:\n    import cmake\n\n    # If the cmake python package is installed, use that exe\n    CMAKE_BIN_DIR = cmake.CMAKE_BIN_DIR\nexcept ImportError:\n    CMAKE_BIN_DIR = \"\"\n\nsys.path.insert(0, osp.join(osp.dirname(__file__), \"src_python\"))\n\nARG_CACHE_BLACKLIST = {\"force_cmake\", \"cache_args\", \"inplace\"}\n\n\ndef str2bool(input_str: str) -> bool:\n    return bool(strtobool(input_str.lower()))\n\n\ndef is_pip() -> bool:\n    # This will end with python if driven with python setup.py or PEP517_BUILD_BACKEND will be set\n    return (\n        osp.basename(os.environ.get(\"_\", \"/pip/no\")).startswith(\"pip\")\n        or os.environ.get(\"PEP517_BUILD_BACKEND\") is not None\n    )\n\n\n# TODO refactor to the proper way to pass options to setup.py so pip can do so.\ndef build_parser():\n    parser = argparse.ArgumentParser(\n        formatter_class=argparse.ArgumentDefaultsHelpFormatter\n    )\n    parser.add_argument(\n        \"--headless\",\n        dest=\"headless\",\n        default=str2bool(os.environ.get(\"HEADLESS\", str(is_pip()))),\n        action=\"store_true\",\n        help=\"\"\"Build in headless mode.\nUse \"HEADLESS=True pip install .\" to build in headless mode with pip\"\"\",\n    )\n    parser.add_argument(\n        \"--with-cuda\",\n        action=\"store_true\",\n        default=str2bool(os.environ.get(\"WITH_CUDA\", \"False\")),\n        dest=\"with_cuda\",\n        help=\"Build CUDA enabled features.  Requires CUDA to be installed\",\n    )\n    parser.add_argument(\n        \"--bullet\",\n        \"--with-bullet\",\n        dest=\"with_bullet\",\n        default=str2bool(os.environ.get(\"WITH_BULLET\", str(is_pip()))),\n        action=\"store_true\",\n        help=\"\"\"Build with Bullet simulation engine. Default to True when pip installing.\n Default value is otherwise false or provided  WITH_BULLET=ON or WITH_BULLET_OFF when doing pip install.\"\"\",\n    )\n    parser.add_argument(\"--no-bullet\", dest=\"with_bullet\", action=\"store_false\")\n    parser.add_argument(\n        \"--cmake\",\n        \"--force-cmake\",\n        dest=\"force_cmake\",\n        action=\"store_true\",\n        help=\"Forces cmake to be rerun.  This argument is not cached\",\n    )\n    parser.add_argument(\n        \"--build-tests\", dest=\"build_tests\", action=\"store_true\", help=\"Build tests\"\n    )\n    parser.add_argument(\n        \"--cmake-args\",\n        type=str,\n        default=os.environ.get(\"CMAKE_ARGS\", \"\"),\n        help=\"\"\"Additional arguments to be passed to cmake.\nNote that you will need to do `--cmake-args=\"...\"` as `--cmake-args \"...\"`\nwill generally not be parsed correctly\nYou may need to use --force-cmake to ensure cmake is rerun with new args.\nUse \"CMAKE_ARGS=\"...\" pip install .\" to set cmake args with pip\"\"\",\n    )\n    parser.add_argument(\n        \"--no-update-submodules\",\n        dest=\"no_update_submodules\",\n        action=\"store_true\",\n        help=\"Don't update git submodules\",\n    )\n    parser.add_argument(\n        \"--build-type\",\n        dest=\"build_type\",\n        default=None,\n        help=\"CMake configuration to build with (Release, Debug, etc...)\",\n    )\n    parser.add_argument(\n        \"--no-lto\",\n        dest=\"lto\",\n        default=None,\n        action=\"store_false\",\n        help=\"Disables Link Time Optimization: faster compile times but worse performance.\",\n    )\n    parser.add_argument(\n        \"--lto\",\n        dest=\"lto\",\n        action=\"store_true\",\n        help=\"Enables Link Time Optimization: better performance but longer compile time\",\n    )\n\n    parser.add_argument(\n        \"--cache-args\",\n        dest=\"cache_args\",\n        action=\"store_true\",\n        help=\"\"\"Caches the arguments sent to setup.py\n        and reloads them on the next invocation.  This argument is not cached\"\"\",\n    )\n\n    parser.add_argument(\n        \"--skip-install-magnum\",\n        dest=\"skip_install_magnum\",\n        action=\"store_true\",\n        help=\"Don't install magnum.  \"\n        \"This is nice for incrementally building for development but \"\n        \"can cause install magnum bindings to fall out-of-sync\",\n    )\n\n    parser.add_argument(\n        \"--build-basis-compressor\",\n        \"--basis-compressor\",\n        dest=\"build_basis_compressor\",\n        action=\"store_true\",\n        help=\"Wether or not to build the basis compressor.\"\n        \"  Loading basis compressed meshes does NOT require this.\",\n    )\n\n    parser.add_argument(\n        \"--audio\",\n        action=\"store_true\",\n        default=str2bool(os.environ.get(\"WITH_AUDIO\", \"False\")),\n        dest=\"with_audio\",\n        help=\"Build with audio features enabled.\",\n    )\n\n    return parser\n\n\nparseable_args = []\nunparseable_args = []\nfor i, arg in enumerate(sys.argv):\n    if arg == \"--\":\n        unparseable_args = sys.argv[i:]\n        break\n\n    parseable_args.append(arg)\n\n\nparser = build_parser()\nargs, filtered_args = parser.parse_known_args(args=parseable_args)\n\nsys.argv = filtered_args + unparseable_args\n\n\ndef in_git():\n    try:\n        subprocess.check_output([\"git\", \"rev-parse\", \"--is-inside-work-tree\"])\n        return True\n    except (OSError, subprocess.SubprocessError):\n        return False\n\n\ndef has_ninja():\n    try:\n        subprocess.check_output([\"ninja\", \"--version\"])\n        return True\n    except (OSError, subprocess.SubprocessError):\n        return False\n\n\nclass CMakeExtension(Extension):\n    def __init__(self, name, sourcedir=\"\"):\n        Extension.__init__(self, name, sources=[])\n        self.sourcedir = os.path.abspath(sourcedir)\n\n\n# populated in CMakeBuild.build_extension()\n_cmake_build_dir = None\n\n\nclass CMakeBuild(build_ext):\n    def finalize_options(self):\n        super().finalize_options()\n\n        cacheable_params = [\n            opt[0].replace(\"=\", \"\").replace(\"-\", \"_\") for opt in self.user_options\n        ]\n\n        args_cache_file = \".setuppy_args_cache.json\"\n\n        if not args.cache_args and osp.exists(args_cache_file):\n            with open(args_cache_file, \"r\") as f:\n                cached_args = json.load(f)\n\n            for k, v in cached_args[\"args\"].items():\n                setattr(args, k, v)\n\n            for k, v in cached_args[\"build_ext\"].items():\n                setattr(self, k, v)\n\n        elif args.cache_args:\n            cache = dict(\n                args={\n                    k: v for k, v in vars(args).items() if k not in ARG_CACHE_BLACKLIST\n                },\n                build_ext={\n                    k: getattr(self, k)\n                    for k in cacheable_params\n                    if k not in ARG_CACHE_BLACKLIST\n                },\n            )\n            with open(args_cache_file, \"w\") as f:\n                json.dump(cache, f, indent=4, sort_keys=True)\n\n        if not os.path.exists(self.build_temp):\n            os.makedirs(self.build_temp)\n        # Save the CMake build directory -- that's where the generated setup.py\n        # for magnum-bindings will appear which we need to run later\n        global _cmake_build_dir\n        _cmake_build_dir = self.build_temp\n\n    def run(self):\n        try:\n            subprocess.check_output([osp.join(CMAKE_BIN_DIR, \"cmake\"), \"--version\"])\n        except (OSError, subprocess.SubprocessError):\n            raise RuntimeError(\n                \"CMake must be installed to build the following extensions: \"\n                + \", \".join(e.name for e in self.extensions)\n            )\n\n        for ext in self.extensions:\n            self.build_extension(ext)\n\n    def build_extension(self, ext):\n        extdir = os.path.abspath(os.path.dirname(self.get_ext_fullpath(ext.name)))\n\n        # Init & update all submodules if not already (the user might be pinned\n        # on some particular commit or have working tree changes, don't destroy\n        # those)\n        if in_git() and not args.no_update_submodules:\n            subprocess.check_call(\n                [\"git\", \"submodule\", \"update\", \"--init\", \"--recursive\"]\n            )\n\n        cmake_args = [\n            \"-DBUILD_PYTHON_BINDINGS=ON\",\n            \"-DCMAKE_LIBRARY_OUTPUT_DIRECTORY=\" + extdir,\n            \"-DPYTHON_EXECUTABLE=\" + sys.executable,\n            \"-DCMAKE_EXPORT_COMPILE_COMMANDS={}\".format(\"OFF\" if is_pip() else \"ON\"),\n            \"-DREL_BUILD_RPATH={}\".format(\"OFF\" if self.inplace else \"ON\"),\n        ]\n        if args.lto is not None:\n            cmake_args += [\n                \"-DCMAKE_INTERPROCEDURAL_OPTIMIZATION={}\".format(\n                    \"ON\" if args.lto else \"OFF\"\n                )\n            ]\n        cmake_args += shlex.split(args.cmake_args)\n\n        build_type = args.build_type\n        assert not (\n            build_type is not None and self.debug\n        ), f\"Debug and Build-Type flags conflict: {self.debug}, {build_type}\"\n        if build_type is None:\n            build_type = \"Debug\" if self.debug else \"RelWithDebInfo\"\n        build_args = [\"--config\", build_type]\n\n        cmake_args += [\"-DCMAKE_BUILD_TYPE=\" + build_type]\n\n        build_args += [\"--\"]\n\n        if has_ninja():\n            cmake_args += [\"-GNinja\"]\n        # Make it possible to *reduce* the number of jobs. Ninja requires a\n        # number passed to -j (and builds on all cores by default), while make\n        # doesn't require a number (but builds sequentially by default), so we\n        # add the argument only when it's not ninja or the number of jobs is\n        # specified.\n        if not has_ninja() or self.parallel:\n            build_args += [\"-j{}\".format(self.parallel) if self.parallel else \"-j\"]\n\n        cmake_args += [\n            \"-DBUILD_GUI_VIEWERS={}\".format(\"ON\" if not args.headless else \"OFF\")\n        ]\n\n        cmake_args += [\"-DBUILD_TEST={}\".format(\"ON\" if args.build_tests else \"OFF\")]\n        cmake_args += [\n            \"-DBUILD_WITH_BULLET={}\".format(\"ON\" if args.with_bullet else \"OFF\")\n        ]\n        cmake_args += [\"-DBUILD_WITH_CUDA={}\".format(\"ON\" if args.with_cuda else \"OFF\")]\n        cmake_args += [\n            \"-DBUILD_BASIS_COMPRESSOR={}\".format(\n                \"ON\" if args.build_basis_compressor else \"OFF\"\n            )\n        ]\n        cmake_args += [\n            \"-DBUILD_WITH_AUDIO={}\".format(\"ON\" if args.with_audio else \"OFF\")\n        ]\n\n        env = os.environ.copy()\n        env[\"CXXFLAGS\"] = '{} -DVERSION_INFO=\\\\\"{}\\\\\"'.format(\n            env.get(\"CXXFLAGS\", \"\"), self.distribution.get_version()\n        )\n\n        if is_pip() or self.run_cmake(cmake_args):\n            os.makedirs(self.build_temp, exist_ok=True)\n            # Remove invalid cmakefiles if is is_pip()\n            for cmake_cache_f in [\n                \"CMakeFiles\",\n                \"CMakeCache.txt\",\n                \"cmake_install.cmake\",\n            ]:\n                cmake_cache_f = osp.join(self.build_temp, cmake_cache_f)\n                if is_pip() and osp.exists(cmake_cache_f):\n                    if osp.isdir(cmake_cache_f):\n                        shutil.rmtree(cmake_cache_f)\n                    else:\n                        os.remove(cmake_cache_f)\n            subprocess.check_call(\n                [osp.join(CMAKE_BIN_DIR, \"cmake\")]\n                + cmake_args\n                + [osp.realpath(ext.sourcedir)],\n                env=env,\n                cwd=self.build_temp,\n            )\n\n        if not is_pip():\n            self.create_compile_commands()\n\n        subprocess.check_call(\n            [osp.join(CMAKE_BIN_DIR, \"cmake\"), \"--build\", self.build_temp] + build_args\n        )\n        print()  # Add an empty line for cleaner output\n\n        # The things following this don't work with pip\n        if is_pip():\n            return\n\n        if not args.headless:\n            link_dst = osp.join(self.build_temp, \"viewer\")\n            if not osp.islink(link_dst):\n                os.symlink(\n                    osp.abspath(osp.join(self.build_temp, \"utils/viewer/viewer\")),\n                    link_dst,\n                )\n\n    def run_cmake(self, cmake_args):\n        if args.force_cmake:\n            return True\n\n        cache_parser = re.compile(r\"(?P<K>\\w+?)(:\\w+?|)=(?P<V>.*?)$\")\n\n        cmake_cache = osp.join(self.build_temp, \"CMakeCache.txt\")\n        if osp.exists(cmake_cache):\n            with open(cmake_cache, \"r\") as f:\n                cache_contents = f.readlines()\n\n            for arg in cmake_args:\n                if arg[0:2] == \"-G\":\n                    continue\n\n                k, v = arg.split(\"=\", 1)\n                # Strip +D\n                k = k[2:]\n                for l in cache_contents:\n                    match = cache_parser.match(l)\n                    if match is None:\n                        continue\n\n                    if match.group(\"K\") == k and match.group(\"V\") != v:\n                        return True\n\n            return False\n\n        return True\n\n    def create_compile_commands(self):\n        def load(filename):\n            with open(filename) as f:\n                return json.load(f)\n\n        command_files = [osp.join(self.build_temp, \"compile_commands.json\")]\n        command_files += glob.glob(\"{}/*/compile_commands.json\".format(self.build_temp))\n        all_commands = [entry for f in command_files for entry in load(f)]\n\n        # cquery does not like c++ compiles that start with gcc.\n        # It forgets to include the c++ header directories.\n        # We can work around this by replacing the gcc calls that python\n        # setup.py generates with g++ calls instead\n        for command in all_commands:\n            if command[\"command\"].startswith(\"gcc \"):\n                command[\"command\"] = \"g++ \" + command[\"command\"][4:]\n\n        new_contents = json.dumps(all_commands, indent=2)\n        contents = \"\"\n        if os.path.exists(\"compile_commands.json\"):\n            with open(\"compile_commands.json\", \"r\") as f:\n                contents = f.read()\n        if contents != new_contents:\n            with open(\"compile_commands.json\", \"w\") as f:\n                f.write(new_contents)\n\n\nif __name__ == \"__main__\":\n    assert StrictVersion(\n        \"{}.{}\".format(sys.version_info[0], sys.version_info[1])\n    ) >= StrictVersion(\"3.9\"), \"Must use python 3.9 or newer\"\n    with open(\"./requirements.txt\", \"r\") as f:\n        requirements = [l.strip() for l in f.readlines() if len(l.strip()) > 0]\n\n    builtins.__HSIM_SETUP__ = True\n    import habitat_sim\n\n    setup(\n        name=\"habitat_sim\",\n        version=habitat_sim.__version__,\n        author=\"FAIR A-STAR\",\n        description=\"A high performance simulator for training embodied agents\",\n        long_description=\"\",\n        packages=find_packages(where=\"src_python\"),\n        package_dir={\"\": \"src_python\"},\n        install_requires=requirements,\n        tests_require=[\"hypothesis\", \"pytest-benchmark\", \"pytest\"],\n        python_requires=\">=3.9\",\n        # add extension module\n        ext_modules=[CMakeExtension(\"habitat_sim._ext.habitat_sim_bindings\", \"src\")],\n        # add custom build_ext command\n        cmdclass=dict(build_ext=CMakeBuild),\n        zip_safe=False,\n        include_package_data=True,\n    )\n    pymagnum_build_dir = osp.join(\n        _cmake_build_dir, \"deps\", \"magnum-bindings\", \"src\", \"python\"\n    )\n\n    if (\n        not args.skip_install_magnum\n        and \"sdist\" not in sys.argv\n        and os.path.exists(pymagnum_build_dir)\n    ):\n        subprocess.check_call(\n            [sys.executable, \"-m\", \"pip\", \"install\", pymagnum_build_dir]\n        )\n    else:\n        if not os.path.exists(pymagnum_build_dir) and \"sdist\" not in sys.argv:\n            print(\n                f\"{pymagnum_build_dir} does not exist and therefore we cannot install magnum-bindings directly.\"\n            )\n        print(\n            \"Assuming magnum bindings are already installed (or we're inside pip and *\\\\_('-')_/*)\"\n        )\n        print(\n            f\"Run '{sys.executable} -m pip install {pymagnum_build_dir}' if this assumption is incorrect\"\n        )\n"
        },
        {
          "name": "src",
          "type": "tree",
          "content": null
        },
        {
          "name": "src_python",
          "type": "tree",
          "content": null
        },
        {
          "name": "tests",
          "type": "tree",
          "content": null
        },
        {
          "name": "tools",
          "type": "tree",
          "content": null
        },
        {
          "name": "tsconfig.json",
          "type": "blob",
          "size": 0.7802734375,
          "content": "{\n  \"compilerOptions\": {\n    \"noEmit\": true,\n    \"module\": \"esnext\",\n    \"target\": \"esnext\",\n    \"lib\": [\n      \"es6\",\n      \"dom\"\n    ],\n    \"esModuleInterop\": true,\n    \"sourceMap\": true,\n    \"allowJs\": true,\n    \"jsx\": \"react\",\n    \"moduleResolution\": \"node\",\n    \"rootDir\": \"./src/esp/bindings_js\",\n    \"forceConsistentCasingInFileNames\": true,\n    \"noImplicitReturns\": true,\n    \"noImplicitThis\": true,\n    \"noImplicitAny\": false,\n    \"strictNullChecks\": true,\n    \"suppressImplicitAnyIndexErrors\": true,\n    \"noUnusedLocals\": true,\n    \"typeRoots\": [\n      \"./node_modules/@types\", /// - here - types are pointing to this @types folder inside node_modules.\n      \"typings/typings.d.ts\"\n    ]\n  },\n  \"exclude\": [\n    \"node_modules\",\n    \"build\",\n    \"scripts\",\n    \"webpack\",\n    \"jest\",\n  ]\n}\n"
        }
      ]
    }
  ]
}