{
  "metadata": {
    "timestamp": 1736565577791,
    "page": 451,
    "hasNextPage": true,
    "endCursor": "Y3Vyc29yOjQ2MA==",
    "completionStatus": "IN_PROGRESS"
  },
  "repositories": [
    {
      "nameWithOwner": "openxla/xla",
      "stars": 2833,
      "defaultBranch": "main",
      "files": [
        {
          "name": ".bazelrc",
          "type": "blob",
          "size": 51.8046875,
          "content": "# TensorFlow Bazel configuration file.\n# This file tries to group and simplify build options for TensorFlow\n#\n# ----CONFIG OPTIONS----\n# Android options:\n#    android:\n#    android_arm:\n#    android_arm64:\n#    android_x86:\n#    android_x86_64:\n#\n# iOS options:\n#     ios:\n#     ios_armv7:\n#     ios_arm64:\n#     ios_x86_64:\n#     ios_fat:\n#\n# Macosx options\n#     darwin_arm64:\n#\n# Compiler options:\n#     cuda_clang:             Use Clang when building CUDA code.\n#     avx_linux:              Build with avx instruction set on linux.\n#     avx_win:                Build with avx instruction set on windows\n#\n# Other build options:\n#     short_logs:       Only log errors during build, skip warnings.\n#     verbose_logs:     Show all compiler warnings during build.\n#     monolithic:       Build all TF C++ code into a single shared object.\n#     dynamic_kernels:  Try to link all kernels dynamically (experimental).\n#     dbg:              Build with debug info\n#\n# TF version options;\n#     v2: Build TF v2\n#\n# Feature and Third party library support options:\n#     xla:          Build TF with XLA\n#     tpu:          Build TF with TPU support\n#     cuda:         Build with CUDA support.\n#     cuda_clang    Build with CUDA Clang support.\n#     rocm:         Build with AMD GPU support (rocm)\n#     mkl:          Enable full mkl support.\n#     nogcp:        Disable GCS support.\n#     nonccl:       Disable nccl support.\n#\n#\n# Remote build execution options (only configured to work with TF team projects for now.)\n#     rbe_base:  General RBE options shared by all flavors.\n#     rbe_linux: General RBE options used on all linux builds.\n#     rbe_win_base:   General RBE options used on all Windows builds. Not to be used standalone.\n#     rbe_win_clang:  Options specific to compiling using Clang.\n#\n#     rbe_linux_cpu:                  RBE options to build with only CPU support.\n#     rbe_linux_cuda:                 RBE options to build with GPU support using clang.\n#     rbe_linux_cuda_nvcc:            RBE options to build with GPU support using nvcc.\n#\n# Embedded Linux options (experimental and only tested with TFLite build yet)\n#     elinux:          General Embedded Linux options shared by all flavors.\n#     elinux_aarch64:  Embedded Linux options for aarch64 (ARM64) CPU support.\n#     elinux_armhf:    Embedded Linux options for armhf (ARMv7) CPU support.\n#\n# Release build options (for all operating systems)\n#     release_base:                    Common options for all builds on all operating systems.\n#     release_cpu_linux:               Toolchain and CUDA options for Linux CPU builds.\n#     release_gpu_linux:               Toolchain and CUDA options for Linux GPU builds.\n#     release_cpu_macos:               Toolchain and CUDA options for MacOS CPU builds.\n#     release_cpu_windows:             Toolchain and CUDA options for Windows CPU builds.\n\n# Default build options. These are applied first and unconditionally.\n\n# For projects which use TensorFlow as part of a Bazel build process, putting\n# nothing in a bazelrc will default to a monolithic build. The following line\n# opts in to modular op registration support by default.\nbuild --define framework_shared_object=true\nbuild --define tsl_protobuf_header_only=true\n\nbuild --define=use_fast_cpp_protos=true\nbuild --define=allow_oversize_protos=true\n\nbuild --spawn_strategy=standalone\nbuild -c opt\n\n# Make Bazel print out all options from rc files.\nbuild --announce_rc\n\n# TODO(mihaimaruseac): Document this option or remove if no longer needed\nbuild --define=grpc_no_ares=true\n\n# See https://github.com/bazelbuild/bazel/issues/7362 for information on what\n# --incompatible_remove_legacy_whole_archive flag does.\n# This flag is set to true in Bazel 1.0 and newer versions. We tried to migrate\n# Tensorflow to the default, however test coverage wasn't enough to catch the\n# errors.\n# There is ongoing work on Bazel team's side to provide support for transitive\n# shared libraries. As part of migrating to transitive shared libraries, we\n# hope to provide a better mechanism for control over symbol exporting, and\n# then tackle this issue again.\n#\n# TODO: Remove the following two lines once TF doesn't depend on Bazel wrapping\n# all library archives in -whole_archive -no_whole_archive.\nbuild --noincompatible_remove_legacy_whole_archive\nbuild --features=-force_no_whole_archive\n\n# TODO(mihaimaruseac): Document this option or remove if no longer needed\nbuild --enable_platform_specific_config\n\n# Enable XLA support by default.\nbuild --define=with_xla_support=true\n\n# TODO(mihaimaruseac): Document this option or remove if no longer needed\nbuild --config=short_logs\n\n# TODO(mihaimaruseac): Document this option or remove if no longer needed\nbuild --config=v2\n\n# TF now has `cc_shared_library` targets, so it needs the experimental flag\n# TODO(rostam): Remove when `cc_shared_library` is enabled by default\nbuild --experimental_cc_shared_library\n\n# cc_shared_library ensures no library is linked statically more than once.\nbuild --experimental_link_static_libraries_once=false\n\n# Prevent regressions on those two incompatible changes\n# TODO: remove those flags when they are flipped in the default Bazel version TF uses.\nbuild --incompatible_enforce_config_setting_visibility\n# TODO: also enable this flag after fixing the visibility violations\n# build --incompatible_config_setting_private_default_visibility\n\n# Default options should come above this line.\n\n# Android configs. Bazel needs to have --cpu and --fat_apk_cpu both set to the\n# target CPU to build transient dependencies correctly. See\n# https://docs.bazel.build/versions/master/user-manual.html#flag--fat_apk_cpu\nbuild:android --crosstool_top=//external:android/crosstool\nbuild:android --host_crosstool_top=@bazel_tools//tools/cpp:toolchain\nbuild:android_arm --config=android\nbuild:android_arm --cpu=armeabi-v7a\nbuild:android_arm --fat_apk_cpu=armeabi-v7a\nbuild:android_arm64 --config=android\nbuild:android_arm64 --cpu=arm64-v8a\nbuild:android_arm64 --fat_apk_cpu=arm64-v8a\nbuild:android_x86 --config=android\nbuild:android_x86 --cpu=x86\nbuild:android_x86 --fat_apk_cpu=x86\nbuild:android_x86_64 --config=android\nbuild:android_x86_64 --cpu=x86_64\nbuild:android_x86_64 --fat_apk_cpu=x86_64\n\n# Build everything statically for Android since all static libs are later\n# bundled together into a single .so for deployment.\nbuild:android --dynamic_mode=off\n# TODO(belitskiy): Remove once on Clang 20.\nbuild:android --define=xnn_enable_avxvnniint8=false\n\n# Sets the default Apple platform to macOS.\nbuild:macos --apple_platform_type=macos\n\n# gRPC on MacOS requires this #define\nbuild:macos --copt=-DGRPC_BAZEL_BUILD\n\n# Avoid hitting command line argument limit\nbuild:macos --features=archive_param_file\n\n# Settings for MacOS on ARM CPUs.\nbuild:macos_arm64 --cpu=darwin_arm64\nbuild:macos_arm64 --macos_minimum_os=11.0\n\n# iOS configs for each architecture and the fat binary builds.\nbuild:ios --apple_platform_type=ios\nbuild:ios --apple_bitcode=embedded --copt=-fembed-bitcode\nbuild:ios --copt=-Wno-c++11-narrowing\nbuild:ios_armv7 --config=ios\nbuild:ios_armv7 --cpu=ios_armv7\nbuild:ios_arm64 --config=ios\nbuild:ios_arm64 --cpu=ios_arm64\nbuild:ios_arm64e --config=ios\nbuild:ios_arm64e --cpu=ios_arm64e\nbuild:ios_sim_arm64 --config=ios\nbuild:ios_sim_arm64 --cpu=ios_sim_arm64\nbuild:ios_x86_64 --config=ios\nbuild:ios_x86_64 --cpu=ios_x86_64\nbuild:ios_fat --config=ios\nbuild:ios_fat --ios_multi_cpus=armv7,arm64,i386,x86_64\n\n# Config to use a mostly-static build and disable modular op registration\n# support (this will revert to loading TensorFlow with RTLD_GLOBAL in Python).\n# By default, TensorFlow will build with a dependence on\n# //tensorflow:libtensorflow_framework.so.\nbuild:monolithic --define framework_shared_object=false\nbuild:monolithic --define tsl_protobuf_header_only=false\nbuild:monolithic --experimental_link_static_libraries_once=false  # b/229868128\n\n# Please note that MKL on MacOS is still not supported.\n# If you would like to use a local MKL instead of downloading, please set the\n# environment variable \"TF_MKL_ROOT\" every time before build.\nbuild:mkl --define=build_with_mkl=true --define=enable_mkl=true\nbuild:mkl --define=tensorflow_mkldnn_contraction_kernel=0\nbuild:mkl --define=build_with_openmp=true\nbuild:mkl -c opt\n\n# config to build OneDNN backend with a user specified threadpool.\nbuild:mkl_threadpool --define=build_with_mkl=true --define=enable_mkl=true\nbuild:mkl_threadpool --define=tensorflow_mkldnn_contraction_kernel=0\nbuild:mkl_threadpool --define=build_with_mkl_opensource=true\nbuild:mkl_threadpool -c opt\n\n# Config setting to build oneDNN with Compute Library for the Arm Architecture (ACL).\nbuild:mkl_aarch64 --define=build_with_mkl_aarch64=true\nbuild:mkl_aarch64 --define=build_with_openmp=true\nbuild:mkl_aarch64 --define=build_with_acl=true\nbuild:mkl_aarch64 -c opt\n\n# Config setting to build oneDNN with Compute Library for the Arm Architecture (ACL).\n# with Eigen threadpool support\nbuild:mkl_aarch64_threadpool --define=build_with_mkl_aarch64=true\nbuild:mkl_aarch64_threadpool -c opt\n\n# CUDA: This config refers to building CUDA op kernels with nvcc.\nbuild:cuda --repo_env TF_NEED_CUDA=1\nbuild:cuda --crosstool_top=@local_config_cuda//crosstool:toolchain\nbuild:cuda --@local_config_cuda//:enable_cuda\n# Default CUDA and CUDNN versions.\nbuild:cuda --repo_env=HERMETIC_CUDA_VERSION=\"12.5.1\"\nbuild:cuda --repo_env=HERMETIC_CUDNN_VERSION=\"9.3.0\"\n# This flag is needed to include CUDA libraries.\nbuild:cuda --@local_config_cuda//cuda:include_cuda_libs=true\n\n# This configuration is used for building the wheels.\nbuild:cuda_wheel --@local_config_cuda//cuda:include_cuda_libs=false\n\n# CUDA: This config refers to building CUDA op kernels with clang.\nbuild:cuda_clang --config=cuda\nbuild:cuda_clang --@local_config_cuda//:cuda_compiler=clang\nbuild:cuda_clang --copt=-Qunused-arguments\n# Select supported compute capabilities (supported graphics cards).\n# This is the same as the official TensorFlow builds.\n# See https://developer.nvidia.com/cuda-gpus#compute\n# `compute_XY` enables PTX embedding in addition to SASS. PTX\n# is forward compatible beyond the current compute capability major\n# release while SASS is only forward compatible inside the current\n# major release. Example: sm_80 kernels can run on sm_89 GPUs but\n# not on sm_90 GPUs. compute_80 kernels though can also run on sm_90 GPUs.\nbuild:cuda_clang --repo_env=HERMETIC_CUDA_COMPUTE_CAPABILITIES=\"sm_60,sm_70,sm_80,sm_89,compute_90\"\n# Permit newer CUDA versions than Clang is aware of\nbuild:cuda_clang --copt=\"-Wno-unknown-cuda-version\"\n# Set lld as the linker.\nbuild:cuda_clang --host_linkopt=\"-fuse-ld=lld\"\nbuild:cuda_clang --host_linkopt=\"-lm\"\nbuild:cuda_clang --linkopt=\"-fuse-ld=lld\"\nbuild:cuda_clang --linkopt=\"-lm\"\n\n# Set up compilation CUDA version and paths and use the CUDA Clang toolchain.\nbuild:cuda_clang_official --config=cuda_clang\nbuild:cuda_clang_official --repo_env=HERMETIC_CUDA_VERSION=\"12.5.1\"\nbuild:cuda_clang_official --repo_env=HERMETIC_CUDNN_VERSION=\"9.3.0\"\nbuild:cuda_clang_official --action_env=CLANG_CUDA_COMPILER_PATH=\"/usr/lib/llvm-18/bin/clang\"\nbuild:cuda_clang_official --crosstool_top=\"@local_config_cuda//crosstool:toolchain\"\n\n# Build with nvcc for CUDA and clang for host\nbuild:cuda_nvcc --config=cuda\nbuild:cuda_nvcc --action_env=TF_NVCC_CLANG=\"1\"\nbuild:cuda_nvcc --@local_config_cuda//:cuda_compiler=nvcc\n# Old config for backward compatibility\nbuild:nvcc_clang --config=cuda_nvcc\n\n# Debug config\nbuild:dbg -c dbg\n# Only include debug info for files under tensorflow/, excluding kernels, to\n# reduce the size of the debug info in the binary. This is because if the debug\n# sections in the ELF binary are too large, errors can occur. See\n# https://github.com/tensorflow/tensorflow/issues/48919.\n# Users can still include debug info for a specific kernel, e.g. with:\n#     --config=dbg --per_file_copt=+tensorflow/core/kernels/identity_op.*@-g\n# Since this .bazelrc file is synced between the tensorflow/tensorflow repo and\n# the openxla/xla repo, also include debug info for files under xla/.\nbuild:dbg --per_file_copt=+.*,-tensorflow.*,-xla.*@-g0\nbuild:dbg --per_file_copt=+tensorflow/core/kernels.*@-g0\n# for now, disable arm_neon. see: https://github.com/tensorflow/tensorflow/issues/33360\nbuild:dbg --cxxopt -DTF_LITE_DISABLE_X86_NEON\n# AWS SDK must be compiled in release mode. see: https://github.com/tensorflow/tensorflow/issues/37498\nbuild:dbg --copt -DDEBUG_BUILD\n\n# Config to build TF TPU\nbuild:tpu --define=with_tpu_support=true\nbuild:tpu --define=framework_shared_object=true\nbuild:tpu --copt=-DLIBTPU_ON_GCE\nbuild:tpu --define=enable_mlir_bridge=true\n\nbuild:rocm --crosstool_top=@local_config_rocm//crosstool:toolchain\nbuild:rocm --define=using_rocm_hipcc=true\nbuild:rocm --define=tensorflow_mkldnn_contraction_kernel=0\nbuild:rocm --repo_env TF_NEED_ROCM=1\n\nbuild:rocm_clang_official --config=rocm\nbuild:rocm_clang_official --action_env=CLANG_COMPILER_PATH=\"/usr/lib/llvm-18/bin/clang\"\nbuild:rocm_clang_official --action_env=TF_ROCM_CLANG=\"1\"\nbuild:rocm_clang_official --linkopt=\"-fuse-ld=lld\"\nbuild:rocm_clang_official --host_linkopt=\"-fuse-ld=lld\"\n\nbuild:rocm_ci --config=rocm_clang_official\n\nbuild:sycl --crosstool_top=@local_config_sycl//crosstool:toolchain\nbuild:sycl --define=using_sycl=true\nbuild:sycl --define=tensorflow_mkldnn_contraction_kernel=0\nbuild:sycl --repo_env TF_NEED_SYCL=1\n\n# Options to disable default on features\nbuild:nogcp --define=no_gcp_support=true\nbuild:nonccl --define=no_nccl_support=true\n\n# Modular TF build options\nbuild:dynamic_kernels --define=dynamic_loaded_kernels=true\nbuild:dynamic_kernels --copt=-DAUTOLOAD_DYNAMIC_KERNELS\n\n# Don't trigger --config=<host platform> when cross-compiling.\nbuild:android --noenable_platform_specific_config\nbuild:ios --noenable_platform_specific_config\n\n# Suppress all C++ compiler warnings, otherwise build logs become 10s of MBs.\nbuild:android --copt=-w\nbuild:ios --copt=-w\nbuild:linux --host_copt=-w\nbuild:macos --copt=-w\nbuild:windows --copt=/W0\nbuild:windows --host_copt=/W0\n\n# Suppress most C++ compiler warnings to reduce log size but allow\n# for specific warnings to still be present.\nbuild:linux --copt=\"-Wno-all\"\nbuild:linux --copt=\"-Wno-extra\"\nbuild:linux --copt=\"-Wno-deprecated\"\nbuild:linux --copt=\"-Wno-deprecated-declarations\"\nbuild:linux --copt=\"-Wno-ignored-attributes\"\nbuild:linux --copt=\"-Wno-array-bounds\"\n\n# Add unused-result as an error on Linux.\nbuild:linux --copt=\"-Wunused-result\"\nbuild:linux --copt=\"-Werror=unused-result\"\n# Add switch as an error on Linux.\nbuild:linux --copt=\"-Wswitch\"\nbuild:linux --copt=\"-Werror=switch\"\n\n# Linux ARM64 specific options\nbuild:linux_arm64 --copt=\"-mtune=generic\" --copt=\"-march=armv8-a\" --copt=\"-O3\"\n\n\n# On Windows, `__cplusplus` is wrongly defined without this switch\n# See https://devblogs.microsoft.com/cppblog/msvc-now-correctly-reports-__cplusplus/\nbuild:windows --copt=/Zc:__cplusplus\nbuild:windows --host_copt=/Zc:__cplusplus\n\n# Tensorflow uses M_* math constants that only get defined by MSVC headers if\n# _USE_MATH_DEFINES is defined.\nbuild:windows --copt=/D_USE_MATH_DEFINES\nbuild:windows --host_copt=/D_USE_MATH_DEFINES\n\n# Windows has a relatively short command line limit, which TF has begun to hit.\n# See https://docs.bazel.build/versions/main/windows.html\nbuild:windows --features=compiler_param_file\nbuild:windows --features=archive_param_file\n\n# Speed Windows compile times. Available in VS 16.4 (we are on 16.11). See\n# https://groups.google.com/a/tensorflow.org/d/topic/build/SsW98Eo7l3o/discussion\nbuild:windows --copt=/d2ReducedOptimizeHugeFunctions\nbuild:windows --host_copt=/d2ReducedOptimizeHugeFunctions\n\n# Before VS 2017 15.8, the member \"type\" would non-conformingly have an\n# alignment of only alignof(max_align_t). VS 2017 15.8 was fixed to handle this\n# correctly, but the fix inherently changes layout and breaks binary\n# compatibility (*only* for uses of aligned_storage with extended alignments).\nbuild:windows --copt=-D_ENABLE_EXTENDED_ALIGNED_STORAGE\nbuild:windows --host_copt=-D_ENABLE_EXTENDED_ALIGNED_STORAGE\n\n# Enable the runfiles symlink tree on Windows. This makes it possible to build\n# the pip package on Windows without an intermediate data-file archive, as the\n# build_pip_package script in its current form (as of Aug 2023) uses the\n# runfiles symlink tree to decide what to put into the Python wheel.\nstartup --windows_enable_symlinks\nbuild:windows --enable_runfiles\nbuild:windows --nobuild_python_zip\nbuild:windows --dynamic_mode=off\n\n# Default paths for TF_SYSTEM_LIBS\nbuild:linux --define=PREFIX=/usr\nbuild:linux --define=LIBDIR=$(PREFIX)/lib\nbuild:linux --define=INCLUDEDIR=$(PREFIX)/include\nbuild:linux --define=PROTOBUF_INCLUDE_PATH=$(PREFIX)/include\nbuild:macos --define=PREFIX=/usr\nbuild:macos --define=LIBDIR=$(PREFIX)/lib\nbuild:macos --define=INCLUDEDIR=$(PREFIX)/include\nbuild:macos --define=PROTOBUF_INCLUDE_PATH=$(PREFIX)/include\n# TF_SYSTEM_LIBS do not work on windows.\n\n# By default, build TF in C++ 17 mode.\nbuild:android --cxxopt=-std=c++17\nbuild:android --host_cxxopt=-std=c++17\nbuild:ios --cxxopt=-std=c++17\nbuild:ios --host_cxxopt=-std=c++17\nbuild:linux --cxxopt=-std=c++17\nbuild:linux --host_cxxopt=-std=c++17\nbuild:macos --cxxopt=-std=c++17\nbuild:macos --host_cxxopt=-std=c++17\nbuild:windows --cxxopt=/std:c++17\nbuild:windows --host_cxxopt=/std:c++17\n\n# On windows, we still link everything into a single DLL.\nbuild:windows --config=monolithic\n\n# On linux, we dynamically link small amount of kernels\nbuild:linux --config=dynamic_kernels\n\n# Make sure to include as little of windows.h as possible\nbuild:windows --copt=-DWIN32_LEAN_AND_MEAN\nbuild:windows --host_copt=-DWIN32_LEAN_AND_MEAN\nbuild:windows --copt=-DNOGDI\nbuild:windows --host_copt=-DNOGDI\n\n# MSVC (Windows): Standards-conformant preprocessor mode\n# See https://docs.microsoft.com/en-us/cpp/preprocessor/preprocessor-experimental-overview\nbuild:windows --copt=/Zc:preprocessor\nbuild:windows --host_copt=/Zc:preprocessor\n\n# Misc build options we need for windows.\nbuild:windows --linkopt=/DEBUG\nbuild:windows --host_linkopt=/DEBUG\nbuild:windows --linkopt=/OPT:REF\nbuild:windows --host_linkopt=/OPT:REF\nbuild:windows --linkopt=/OPT:ICF\nbuild:windows --host_linkopt=/OPT:ICF\n\n# Verbose failure logs when something goes wrong\nbuild:windows --verbose_failures\n\n# Work around potential issues with large command lines on windows.\n# See: https://github.com/bazelbuild/bazel/issues/5163\nbuild:windows --features=compiler_param_file\n\n# Do not risk cache corruption. See:\n# https://github.com/bazelbuild/bazel/issues/3360\nbuild:linux --experimental_guard_against_concurrent_changes\n\n# Configure short or long logs\nbuild:short_logs --output_filter=DONT_MATCH_ANYTHING\nbuild:verbose_logs --output_filter=\n\n# Instruction set optimizations\n# TODO(gunan): Create a feature in toolchains for avx/avx2 to\n#   avoid having to define linux/win separately.\nbuild:avx_linux --copt=-mavx\nbuild:avx_linux --host_copt=-mavx\nbuild:avx_win --copt=/arch:AVX\n\n# TODO(belitskiy): Remove once Win2019 is gone.\n# Use Clang-cl compiler on Windows\nbuild:win_clang --extra_toolchains=@local_config_cc//:cc-toolchain-x64_windows-clang-cl\nbuild:win_clang --extra_execution_platforms=//tools/toolchains/win:x64_windows-clang-cl\nbuild:win_clang --host_platform=//tools/toolchains/win:x64_windows-clang-cl\nbuild:win_clang --copt=/clang:-Weverything\nbuild:win_clang --host_copt=/clang:-Weverything\nbuild:win_clang --compiler=clang-cl\nbuild:win_clang --linkopt=/FORCE:MULTIPLE\nbuild:win_clang --host_linkopt=/FORCE:MULTIPLE\ntest:win_clang --linkopt=/FORCE:MULTIPLE\ntest:win_clang --host_linkopt=/FORCE:MULTIPLE\ntest:win_clang --action_env=PATHEXT=.COM;.EXE;.BAT;.CMD;.VBS;.VBE;.JS;.JSE;.WSF;.WSH;.MSC;.PY;.PYW\n\n# build:windows_x86_cpu --extra_toolchains=\"//tools/toolchains/win2022/20241118:cc-toolchain-x64_windows-clang-cl\"\n# build:windows_x86_cpu --extra_execution_platforms=\"//tools/toolchains/win2022:windows_ltsc2022_clang\"\n# build:windows_x86_cpu --host_platform=\"//tools/toolchains/win2022:windows_ltsc2022_clang\"\nbuild:windows_x86_cpu --crosstool_top=\"//tools/toolchains/win2022/20241118:toolchain\"\nbuild:windows_x86_cpu --extra_toolchains=\"//tools/toolchains/win2022/20241118:cc-toolchain-x64_windows-clang-cl\"\nbuild:windows_x86_cpu --extra_execution_platforms=\"//tools/toolchains/win2022:windows_ltsc2022_clang\"\nbuild:windows_x86_cpu --host_platform=\"//tools/toolchains/win2022:windows_ltsc2022_clang\"\nbuild:windows_x86_cpu --platforms=\"//tools/toolchains/win2022:windows_ltsc2022_clang\"\nbuild:windows_x86_cpu --copt=/clang:-Weverything\nbuild:windows_x86_cpu --host_copt=/clang:-Weverything\nbuild:windows_x86_cpu --compiler=clang-cl\nbuild:windows_x86_cpu --linkopt=/FORCE:MULTIPLE\nbuild:windows_x86_cpu --host_linkopt=/FORCE:MULTIPLE\ntest:windows_x86_cpu --linkopt=/FORCE:MULTIPLE\ntest:windows_x86_cpu --host_linkopt=/FORCE:MULTIPLE\ntest:windows_x86_cpu --action_env=PATHEXT=.COM;.EXE;.BAT;.CMD;.VBS;.VBE;.JS;.JSE;.WSF;.WSH;.MSC;.PY;.PYW\n\n# Options to build TensorFlow 1.x or 2.x.\n# TODO(kanglan): Change v2's define to default behavior\nbuild:v2 --define=tf_api_version=2 --action_env=TF2_BEHAVIOR=1\n\n# Enable all targets in XLA\nbuild:cpu_cross --define=with_cross_compiler_support=true\n\n# Disable XLA on mobile.\nbuild:xla     --define=with_xla_support=true # TODO: remove, it's on by default.\nbuild:android --define=with_xla_support=false\nbuild:ios     --define=with_xla_support=false\n\n# BEGIN TF REMOTE BUILD EXECUTION OPTIONS\n# Options when using remote execution\n# WARNING: THESE OPTIONS WONT WORK IF YOU DO NOT HAVE PROPER AUTHENTICATION AND PERMISSIONS\n\n# Allow creation of resultstore URLs for any bazel invocation\nbuild:resultstore --google_default_credentials\nbuild:resultstore --bes_backend=buildeventservice.googleapis.com\nbuild:resultstore --bes_instance_name=\"tensorflow-testing\"\nbuild:resultstore --bes_results_url=\"https://source.cloud.google.com/results/invocations\"\nbuild:resultstore --bes_timeout=600s\n\n# Flag to enable remote config\ncommon --experimental_repo_remote_exec\n\n# Make Bazel not try to probe the host system for a C++ toolchain.\nbuild:rbe_base --config=resultstore\nbuild:rbe_base --repo_env=BAZEL_DO_NOT_DETECT_CPP_TOOLCHAIN=1\nbuild:rbe_base --define=EXECUTOR=remote\nbuild:rbe_base --jobs=800\nbuild:rbe_base --remote_executor=grpcs://remotebuildexecution.googleapis.com\nbuild:rbe_base --remote_timeout=3600\nbuild:rbe_base --spawn_strategy=remote,worker,standalone,local\n# Attempt to minimize the amount of data transfer between bazel and the remote\n# workers:\nbuild:rbe_base --remote_download_toplevel\ntest:rbe_base --test_env=USER=anon\n\n# TODO(kanglan): Check if we want to merge rbe_linux into rbe_linux_cpu.\nbuild:rbe_linux --config=rbe_base\nbuild:rbe_linux --action_env=PATH=\"/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/local/go/bin\"\n# Non-rbe settings we should include because we do not run configure\nbuild:rbe_linux --config=avx_linux\n# TODO(gunan): Check why we need this specified in rbe, but not in other builds.\nbuild:rbe_linux --linkopt=-lrt\nbuild:rbe_linux --host_linkopt=-lrt\nbuild:rbe_linux --linkopt=-lm\nbuild:rbe_linux --host_linkopt=-lm\n\nbuild:rbe_linux_cpu --config=rbe_linux\n# Linux cpu and cuda builds share the same toolchain now.\nbuild:rbe_linux_cpu --host_crosstool_top=\"@local_config_cuda//crosstool:toolchain\"\nbuild:rbe_linux_cpu --crosstool_top=\"@local_config_cuda//crosstool:toolchain\"\nbuild:rbe_linux_cpu --extra_toolchains=\"@local_config_cuda//crosstool:toolchain-linux-x86_64\"\nbuild:rbe_linux_cpu --repo_env=CC=\"/usr/lib/llvm-18/bin/clang\"\nbuild:rbe_linux_cpu --repo_env=TF_SYSROOT=\"/dt9\"\nbuild:rbe_linux_cpu --extra_execution_platforms=\"@ml_build_config_platform//:platform\"\nbuild:rbe_linux_cpu --host_platform=\"@ml_build_config_platform//:platform\"\nbuild:rbe_linux_cpu --platforms=\"@ml_build_config_platform//:platform\"\n# This is needed for all Clang17 builds but must not be present in GCC builds.\nbuild:rbe_linux_cpu --copt=-Wno-error=unused-command-line-argument\n# This was added in clang-16 by https://reviews.llvm.org/D133574.\n# Can be removed once upb is updated, since a type definition is used within\n# offset of in the current version of ubp.\n# See https://github.com/protocolbuffers/upb/blob/9effcbcb27f0a665f9f345030188c0b291e32482/upb/upb.c#L183.\nbuild:rbe_linux_cpu --copt=-Wno-gnu-offsetof-extensions\n# Python config is the same across all containers because the binary is the same\nbuild:rbe_linux_cpu --python_path=\"/usr/bin/python3\"\n# These you may need to change for your own GCP project.\ncommon:rbe_linux_cpu --remote_instance_name=projects/tensorflow-testing/instances/default_instance\n\n# TODO(kanglan): Remove it after toolchain update is complete.\nbuild:rbe_linux_cpu_old --config=rbe_linux\nbuild:rbe_linux_cpu_old --host_crosstool_top=\"@ubuntu20.04-gcc9_manylinux2014-cuda11.2-cudnn8.1-tensorrt7.2_config_cuda//crosstool:toolchain\"\nbuild:rbe_linux_cpu_old --crosstool_top=\"@ubuntu20.04-gcc9_manylinux2014-cuda11.2-cudnn8.1-tensorrt7.2_config_cuda//crosstool:toolchain\"\nbuild:rbe_linux_cpu_old --extra_toolchains=\"@ubuntu20.04-gcc9_manylinux2014-cuda11.2-cudnn8.1-tensorrt7.2_config_cuda//crosstool:toolchain-linux-x86_64\"\nbuild:rbe_linux_cpu_old --extra_execution_platforms=\"@ubuntu20.04-gcc9_manylinux2014-cuda11.2-cudnn8.1-tensorrt7.2_config_platform//:platform\"\nbuild:rbe_linux_cpu_old --host_platform=\"@ubuntu20.04-gcc9_manylinux2014-cuda11.2-cudnn8.1-tensorrt7.2_config_platform//:platform\"\nbuild:rbe_linux_cpu_old --platforms=\"@ubuntu20.04-gcc9_manylinux2014-cuda11.2-cudnn8.1-tensorrt7.2_config_platform//:platform\"\nbuild:rbe_linux_cpu_old --python_path=\"/usr/local/bin/python3.9\"\ncommon:rbe_linux_cpu_old --remote_instance_name=projects/tensorflow-testing/instances/default_instance\n\nbuild:rbe_linux_cuda --config=cuda_clang_official\nbuild:rbe_linux_cuda --config=rbe_linux_cpu\n# For Remote build execution -- GPU configuration\nbuild:rbe_linux_cuda --repo_env=REMOTE_GPU_TESTING=1\n\nbuild:rbe_linux_cuda_nvcc --config=rbe_linux_cuda\nbuild:rbe_linux_cuda_nvcc --config=cuda_nvcc\nbuild:rbe_linux_cuda_nvcc --repo_env TF_NCCL_USE_STUB=1\n\nbuild:rbe_win_base --config=rbe_base\nbuild:rbe_win_base --shell_executable=C:\\\\tools\\\\msys64\\\\usr\\\\bin\\\\bash.exe\nbuild:rbe_win_base --remote_instance_name=projects/tensorflow-testing/instances/windows\n# Don't build the python zip archive in the RBE build.\nbuild:rbe_win_base --remote_download_minimal\nbuild:rbe_win_base --enable_runfiles\nbuild:rbe_win_base --nobuild_python_zip\nbuild:rbe_win_base --define=override_eigen_strong_inline=true\n\nbuild:rbe_win_clang --config=rbe_win_base\nbuild:rbe_win_clang --crosstool_top=\"//tools/toolchains/win/20240424:toolchain\"\nbuild:rbe_win_clang --extra_toolchains=\"//tools/toolchains/win/20240424:cc-toolchain-x64_windows-clang-cl\"\nbuild:rbe_win_clang --extra_execution_platforms=\"//tools/toolchains/win:x64_windows-clang-cl\"\nbuild:rbe_win_clang --host_platform=\"//tools/toolchains/win:x64_windows-clang-cl\"\nbuild:rbe_win_clang --platforms=\"//tools/toolchains/win:x64_windows-clang-cl\"\nbuild:rbe_win_clang --compiler=clang-cl\nbuild:rbe_win_clang --linkopt=/FORCE:MULTIPLE\nbuild:rbe_win_clang --host_linkopt=/FORCE:MULTIPLE\n\n# TODO(belitskiy): Rename `rbe_win_clang` to this, once done switching presubmits.\nbuild:rbe_windows_x86_cpu --config=rbe_win_clang\n\n# END TF REMOTE BUILD EXECUTION OPTIONS\n\n# TFLite build configs for generic embedded Linux\nbuild:elinux --crosstool_top=@local_config_embedded_arm//:toolchain\nbuild:elinux --host_crosstool_top=@bazel_tools//tools/cpp:toolchain\nbuild:elinux_aarch64 --config=elinux\nbuild:elinux_aarch64 --cpu=aarch64\nbuild:elinux_armhf --config=elinux\nbuild:elinux_armhf --cpu=armhf\nbuild:elinux_armhf --copt -mfp16-format=ieee\n\n# Config-specific options should come above this line.\n\n# Load rc file written by ./configure.\ntry-import %workspace%/.tf_configure.bazelrc\ntry-import %workspace%/xla_configure.bazelrc\n\n# Load rc file with user-specific options.\ntry-import %workspace%/.bazelrc.user\n\n# Here are bazelrc configs for release builds\n# Build TensorFlow v2.\ntest:release_base --test_size_filters=small,medium\n\n# Enable support for all targets\nbuild:release_base --config=cpu_cross\n\n# Ensure release_base is set on linux\nbuild:release_linux_base --config=release_base\n\n# Disable clang extension that rejects type definitions within offsetof.\n# This was added in clang-16 by https://reviews.llvm.org/D133574.\n# Can be removed once upb is updated, since a type definition is used within\n# offset of in the current version of ubp.\n# See https://github.com/protocolbuffers/upb/blob/9effcbcb27f0a665f9f345030188c0b291e32482/upb/upb.c#L183.\nbuild:release_linux_base --copt=-Wno-gnu-offsetof-extensions\nbuild:release_linux_base --copt=-Wno-error=array-parameter\nbuild:release_linux_base --copt=-Wno-error=unused-command-line-argument\n# Set lld as the linker.\nbuild:release_linux_base --linkopt=\"-fuse-ld=lld\"\nbuild:release_linux_base --linkopt=\"-lm\"\n\n# We have some invalid linker scripts in the build,\n# so we need to disable this check\nbuild:release_linux_base --linkopt=-Wl,--undefined-version\n\n# Container environment settings below this point.\n# Use Python 3.X as installed in container image\nbuild:release_linux_base --action_env PYTHON_BIN_PATH=\"/usr/bin/python3\"\nbuild:release_linux_base --action_env PYTHON_LIB_PATH=\"/usr/lib/tf_python\"\nbuild:release_linux_base --python_path=\"/usr/bin/python3\"\n# Set Clang as compiler. Use the actual path to clang installed in container.\nbuild:release_linux_base --repo_env=CC=\"/usr/lib/llvm-18/bin/clang\"\nbuild:release_linux_base --repo_env=BAZEL_COMPILER=\"/usr/lib/llvm-18/bin/clang\"\n# Test-related settings below this point.\ntest:release_linux_base --build_tests_only --keep_going --test_output=errors --verbose_failures=true\ntest:release_linux_base --local_test_jobs=HOST_CPUS\n# Give only the list of failed tests at the end of the log\ntest:release_linux_base --test_summary=short\n\n# Use the Clang toolchain to compile\nbuild:release_cpu_linux --config=release_linux_base\nbuild:release_cpu_linux --crosstool_top=\"@local_config_cuda//crosstool:toolchain\"\nbuild:release_cpu_linux --repo_env=TF_SYSROOT=\"/dt9\"\n# Target the AVX instruction set\nbuild:release_cpu_linux --config=avx_linux\n\nbuild:release_gpu_linux --config=release_cpu_linux\n# Set up compilation CUDA version and paths and use the CUDA Clang toolchain.\n# Note that linux cpu and cuda builds share the same toolchain now.\nbuild:release_gpu_linux --config=cuda_clang_official\n# Local test jobs has to be 4 because parallel_gpu_execute is fragile, I think\ntest:release_gpu_linux --test_timeout=300,450,1200,3600 --local_test_jobs=4 --run_under=//tensorflow/tools/ci_build/gpu_build:parallel_gpu_execute\n\nbuild:release_arm64_linux --config=release_linux_base\nbuild:release_arm64_linux --config=linux_arm64\nbuild:release_arm64_linux --crosstool_top=\"@ml2014_clang_aarch64_config_aarch64//crosstool:toolchain\"\nbuild:release_arm64_linux --config=mkl_aarch64_threadpool\nbuild:release_arm64_linux --copt=-flax-vector-conversions\ntest:release_arm64_linux --flaky_test_attempts=3\n\nbuild:release_cpu_macos --config=avx_linux\n\n# Base build configs for macOS\nbuild:release_macos_base --action_env  DEVELOPER_DIR=/Applications/Xcode.app/Contents/Developer\nbuild:release_macos_base --define=no_nccl_support=true --output_filter=^$\n\n# Ensure release_base is set on mac\nbuild:release_macos_base --config=release_base\n\n# Build configs for macOS x86\nbuild:release_macos_x86 --config=release_macos_base\n# Build with the AVX instruction set when on macOS x86\nbuild:release_macos_x86 --config=avx_linux\nbuild:release_macos_x86 --cpu=darwin\n# Target Catalina as the minimum compatible OS version\nbuild:release_macos_x86 --macos_minimum_os=10.15\nbuild:release_macos_x86 --action_env MACOSX_DEPLOYMENT_TARGET=10.15\n\n# Build configs for macOS Arm64\nbuild:release_macos_arm64 --config=release_macos_base\nbuild:release_macos_arm64 --cpu=darwin_arm64\nbuild:release_macos_arm64 --define=tensorflow_mkldnn_contraction_kernel=0\n# Target Moneterey as the minimum compatible OS version\nbuild:release_macos_arm64 --macos_minimum_os=12.0\nbuild:release_macos_arm64 --action_env MACOSX_DEPLOYMENT_TARGET=12.0\n\n# Base test configs for macOS\ntest:release_macos_base --verbose_failures=true --local_test_jobs=HOST_CPUS\ntest:release_macos_base --test_timeout=300,450,1200,3600 --test_output=errors\ntest:release_macos_base --build_tests_only --keep_going\ntest:release_macos_base --flaky_test_attempts=3\n\n# Test configs for macOS x86\ntest:release_macos_x86 --config=release_macos_base\n\n# Test configs for macOS Arm64\ntest:release_macos_arm64 --config=release_macos_base\n\n# Ensure release_base is set on windows\nbuild:release_cpu_windows --config=release_base\n\n# TODO(kanglan): Update windows configs after b/289091160 is fixed\nbuild:release_cpu_windows --config=avx_win\nbuild:release_cpu_windows --define=no_tensorflow_py_deps=true\n\n# Exclude TFRT integration for anything but Linux.\nbuild:android --config=no_tfrt\nbuild:macos   --config=no_tfrt\nbuild:windows --config=no_tfrt\nbuild:rocm --config=no_tfrt\nbuild:no_tfrt --deleted_packages=tensorflow/compiler/mlir/tfrt,tensorflow/compiler/mlir/tfrt/benchmarks,tensorflow/compiler/mlir/tfrt/ir,tensorflow/compiler/mlir/tfrt/ir/mlrt,tensorflow/compiler/mlir/tfrt/jit/python_binding,tensorflow/compiler/mlir/tfrt/jit/transforms,tensorflow/compiler/mlir/tfrt/python_tests,tensorflow/compiler/mlir/tfrt/tests,tensorflow/compiler/mlir/tfrt/tests/ifrt,tensorflow/compiler/mlir/tfrt/tests/mlrt,tensorflow/compiler/mlir/tfrt/tests/ir,tensorflow/compiler/mlir/tfrt/tests/analysis,tensorflow/compiler/mlir/tfrt/tests/jit,tensorflow/compiler/mlir/tfrt/tests/lhlo_to_tfrt,tensorflow/compiler/mlir/tfrt/tests/lhlo_to_jitrt,tensorflow/compiler/mlir/tfrt/tests/tf_to_corert,tensorflow/compiler/mlir/tfrt/tests/tf_to_tfrt_data,tensorflow/compiler/mlir/tfrt/tests/saved_model,tensorflow/compiler/mlir/tfrt/transforms/lhlo_gpu_to_tfrt_gpu,tensorflow/compiler/mlir/tfrt/transforms/mlrt,tensorflow/core/runtime_fallback,tensorflow/core/runtime_fallback/conversion,tensorflow/core/runtime_fallback/kernel,tensorflow/core/runtime_fallback/opdefs,tensorflow/core/runtime_fallback/runtime,tensorflow/core/runtime_fallback/util,tensorflow/core/runtime_fallback/test,tensorflow/core/runtime_fallback/test/gpu,tensorflow/core/runtime_fallback/test/saved_model,tensorflow/core/runtime_fallback/test/testdata,tensorflow/core/tfrt/stubs,tensorflow/core/tfrt/tfrt_session,tensorflow/core/tfrt/mlrt,tensorflow/core/tfrt/mlrt/attribute,tensorflow/core/tfrt/mlrt/kernel,tensorflow/core/tfrt/mlrt/bytecode,tensorflow/core/tfrt/mlrt/interpreter,tensorflow/compiler/mlir/tfrt/translate/mlrt,tensorflow/compiler/mlir/tfrt/translate/mlrt/testdata,tensorflow/core/tfrt/gpu,tensorflow/core/tfrt/run_handler_thread_pool,tensorflow/core/tfrt/runtime,tensorflow/core/tfrt/saved_model,tensorflow/core/tfrt/graph_executor,tensorflow/core/tfrt/saved_model/tests,tensorflow/core/tfrt/tpu,tensorflow/core/tfrt/utils,tensorflow/core/tfrt/utils/debug,tensorflow/core/tfrt/saved_model/python,tensorflow/core/tfrt/graph_executor/python,tensorflow/core/tfrt/saved_model/utils\n\n# BEGIN TF CACHE HELPER OPTIONS\n# Options when using remote execution\n# WARNING: THESE OPTIONS WONT WORK IF YOU DO NOT HAVE PROPER AUTHENTICATION AND PERMISSIONS\n\n# Use --config=tf_public_cache to try and use the TensorFlow public build cache\n# to build TensorFlow. Look at ci/official/envs to find which types of jobs\n# push to the cache.  For macOS, use --config=tf_public_macos_cache\nbuild:tf_public_cache --remote_cache=\"https://storage.googleapis.com/tensorflow-devinfra-bazel-cache/january2024\" --remote_upload_local_results=false\n# Cache pushes are limited to TF's CI system.\nbuild:tf_public_cache_push --config=tf_public_cache --remote_upload_local_results=true --google_default_credentials\n# Public cache for macOS builds\nbuild:tf_public_macos_cache --remote_cache=\"https://storage.googleapis.com/tensorflow-macos-bazel-cache/oct2023\" --remote_upload_local_results=false\n# Cache pushes are limited to TF's CI system.\nbuild:tf_public_macos_cache_push --config=tf_public_macos_cache --remote_upload_local_results=true --google_default_credentials\n\n# END TF CACHE HELPER OPTIONS\n# BEGIN TF TEST SUITE OPTIONS\n# These are convenience config options that effectively declare TF's CI test suites. Look\n# at the scripts of ci/official/ to see how TF's CI uses them.\n\n# LIBTENSORFLOW TESTS are for building Libtensorflow archives. These are CUDA/CPU-agnostic.\ntest:linux_libtensorflow_test --config=cuda_wheel -- //tensorflow/tools/lib_package:libtensorflow_test //tensorflow/tools/lib_package:libtensorflow_java_test\nbuild:linux_libtensorflow_build --config=cuda_wheel -- //tensorflow/tools/lib_package:libtensorflow.tar.gz //tensorflow/tools/lib_package:libtensorflow_jni.tar.gz //tensorflow/java:libtensorflow.jar //tensorflow/java:libtensorflow-src.jar //tensorflow/tools/lib_package:libtensorflow_proto.zip\nbuild:windows_libtensorflow_build --config=cuda_wheel --config=windows_x86_cpu -- //:LICENSE //tensorflow:tensorflow.dll //tensorflow:tensorflow_dll_import_lib //tensorflow/tools/lib_package:clicenses_generate //tensorflow/java:tensorflow_jni.dll //tensorflow/tools/lib_package:jnilicenses_generate\n\n# PYTHON TESTS run a suite of Python tests intended for verifying that the Python wheel\n# will work properly. These are usually run Nightly or upon Release.\n# CPU WHEEL\ntest:linux_cpu_wheel_test_filters --test_tag_filters=-no_oss,-tf_tosa,-oss_excluded,-oss_serial,-gpu,-tpu,-benchmark-test,-v1only,-no_oss_py38,-no_oss_py39,-no_oss_py310\ntest:linux_cpu_wheel_test_filters --build_tag_filters=-no_oss,-tf_tosa,-oss_excluded,-oss_serial,-gpu,-tpu,-benchmark-test,-v1only,-no_oss_py38,-no_oss_py39,-no_oss_py310\ntest:linux_cpu_wheel_test_filters --test_lang_filters=py --test_size_filters=small,medium\ntest:linux_cpu_wheel_test --@tsl//third_party/py:wheel_dependency=true --config=linux_cpu_wheel_test_filters -- //tensorflow/... //tensorflow/tools/pip_package:prebuilt_wheel_import_api_packages_test_cpu -//tensorflow/compiler/tf2tensorrt/... -//tensorflow/core/tpu/... -//tensorflow/lite/... -//tools/toolchains/...\n# CUDA WHEEL\ntest:linux_cuda_wheel_test_filters --test_tag_filters=gpu,requires-gpu,-no_gpu,-no_oss,-tf_tosa,-oss_excluded,-oss_serial,-benchmark-test,-no_cuda11,-no_oss_py38,-no_oss_py39,-no_oss_py310\ntest:linux_cuda_wheel_test_filters --build_tag_filters=gpu,requires-gpu,-no_gpu,-no_oss,-tf_tosa,-oss_excluded,-oss_serial,-benchmark-test,-no_cuda11,-no_oss_py38,-no_oss_py39,-no_oss_py310\ntest:linux_cuda_wheel_test_filters --test_lang_filters=py --test_size_filters=small,medium\ntest:linux_cuda_wheel_test --@tsl//third_party/py:wheel_dependency=true --config=linux_cuda_wheel_test_filters -- //tensorflow/... //tensorflow/tools/pip_package:prebuilt_wheel_import_api_packages_test_gpu -//tensorflow/compiler/tf2tensorrt/... -//tensorflow/core/tpu/... -//tensorflow/lite/... -//tools/toolchains/...\n# ARM64 WHEEL\ntest:linux_arm64_wheel_test_filters --test_tag_filters=-no_oss,-tf_tosa,-no_aarch64,-oss_excluded,-oss_serial,-gpu,-tpu,-benchmark-test,-v1only,-no_oss_py38,-no_oss_py39,-no_oss_py310\ntest:linux_arm64_wheel_test_filters --build_tag_filters=-no_oss,-tf_tosa,-no_aarch64,-oss_excluded,-oss_serial,-gpu,-tpu,-benchmark-test,-v1only,-no_oss_py38,-no_oss_py39,-no_oss_py310\ntest:linux_arm64_wheel_test_filters --test_lang_filters=py --test_size_filters=small,medium\ntest:linux_arm64_wheel_test --@tsl//third_party/py:wheel_dependency=true --config=linux_arm64_wheel_test_filters -- //tensorflow/... //tensorflow/tools/pip_package:prebuilt_wheel_import_api_packages_test_cpu -//tensorflow/compiler/tf2tensorrt/... -//tensorflow/core/tpu/... -//tensorflow/lite/... -//tools/toolchains/...  -//tensorflow/go/... -//tensorflow/java/... -//tensorflow/core/grappler/optimizers:auto_mixed_precision_test_cpu -//tensorflow/core/grappler/optimizers:remapper_test_cpu -//tensorflow/core/kernels/image:resize_bicubic_op_test\n# MACOS ARM64 WHEEL\ntest:macos_arm64_wheel_test_filters --test_tag_filters=-no_oss,-tf_tosa,-oss_excluded,-oss_serial,-no_oss_py39,-no_oss_py310,-nomac,-no_mac,-mac_excluded,-v1only,-gpu,-tpu,-benchmark-test,-no_mac_arm64,-no_aarch64\ntest:macos_arm64_wheel_test_filters --build_tag_filters=-no_oss,-tf_tosa,-oss_excluded,-oss_serial,-no_oss_py39,-no_oss_py310,-nomac,-no_mac,-mac_excluded,-v1only,-gpu,-tpu,-benchmark-test,-no_mac_arm64,-no_aarch64\ntest:macos_arm64_wheel_test_filters --test_lang_filters=py --test_size_filters=small,medium\ntest:macos_arm64_wheel_test --@tsl//third_party/py:wheel_dependency=true --config=macos_arm64_wheel_test_filters -- //tensorflow/... //tensorflow/tools/pip_package:prebuilt_wheel_import_api_packages_test_cpu -//tensorflow/compiler/tf2tensorrt/... -//tensorflow/core/tpu/... -//tensorflow/lite/... -//tools/toolchains/... -//tensorflow/go/... -//tensorflow/java/... -//tensorflow/compiler/aot/...\n# MACOS X86 WHEEL\ntest:macos_x86_wheel_test_filters --test_tag_filters=-no_oss,-tf_tosa,-oss_excluded,-oss_serial,-no_oss_py38,-no_oss_py39,-no_oss_py310,-nomac,-no_mac,-mac_excluded,-v1only,-gpu,-tpu,-benchmark-test\ntest:macos_x86_wheel_test_filters --build_tag_filters=-no_oss,-tf_tosa,-oss_excluded,-oss_serial,-no_oss_py38,-no_oss_py39,-no_oss_py310,-nomac,-no_mac,-mac_excluded,-v1only,-gpu,-tpu,-benchmark-test\ntest:macos_x86_wheel_test_filters --test_lang_filters=py --test_size_filters=small,medium\ntest:macos_x86_wheel_test --@tsl//third_party/py:wheel_dependency=true --config=macos_x86_wheel_test_filters -- //tensorflow/... //tensorflow/tools/pip_package:prebuilt_wheel_import_api_packages_test_cpu -//tensorflow/compiler/tf2tensorrt/... -//tensorflow/core/tpu/... -//tensorflow/lite/... -//tools/toolchains/... -//tensorflow/go/... -//tensorflow/java/... -//tensorflow/compiler/aot/...\n# WINDOWS X86 WHEEL\ntest:windows_x86_cpu_wheel_test_filters --test_tag_filters=-no_windows,-windows_excluded,-no_oss,-oss_excluded,-gpu,-tpu,-benchmark-test\ntest:windows_x86_cpu_wheel_test_filters --build_tag_filters=-no_windows,-windows_excluded,-no_oss,-oss_excluded,-benchmark-test\ntest:windows_x86_cpu_wheel_test_filters --test_lang_filters=cc,py --test_size_filters=small,medium --test_timeout=\"300,450,1200,3600\"\ntest:windows_x86_cpu_wheel_test --build_tests_only --config=windows_x86_cpu_pycpp_test_filters -- //tensorflow/... -//tensorflow/java/... -//tensorflow/lite/... -//tensorflow/compiler/...\n\n# PYCPP TESTS run a suite of Python and C++ tests to verify general correctness over\n# the whole TF code base. These are usually run continuously or upon presubmit.\n# LINUX CPU PYCPP:\ntest:linux_cpu_pycpp_test_filters --test_tag_filters=-no_oss,-tf_tosa,-oss_excluded,-oss_serial,-gpu,-tpu,-benchmark-test,-v1only\ntest:linux_cpu_pycpp_test_filters --build_tag_filters=-no_oss,-tf_tosa,-oss_excluded,-oss_serial,-gpu,-tpu,-benchmark-test,-v1only\ntest:linux_cpu_pycpp_test_filters --test_lang_filters=cc,py --test_size_filters=small,medium\ntest:linux_cpu_pycpp_test --config=linux_cpu_pycpp_test_filters -- //tensorflow/... //tensorflow/tools/pip_package:import_api_packages_test_cpu -//tensorflow/compiler/tf2tensorrt/... -//tensorflow/core/tpu/... -//tensorflow/lite/... -//tools/toolchains/...\n\n# LINUX CUDA PYCPP:\ntest:linux_cuda_pycpp_test_filters --test_tag_filters=-no_oss,-tf_tosa,-oss_excluded,-oss_serial,-benchmark-test,-v1only,gpu,-no_gpu,-no_gpu_presubmit,-no_cuda11\ntest:linux_cuda_pycpp_test_filters --build_tag_filters=-no_oss,-tf_tosa,-oss_excluded,-oss_serial,-benchmark-test,-v1only,gpu,-no_gpu,-no_gpu_presubmit,-no_cuda11\ntest:linux_cuda_pycpp_test_filters --test_lang_filters=cc,py --test_size_filters=small,medium\ntest:linux_cuda_pycpp_test --config=linux_cuda_pycpp_test_filters -- //tensorflow/... //tensorflow/tools/pip_package:import_api_packages_test_gpu -//tensorflow/compiler/tf2tensorrt/... -//tensorflow/core/tpu/... -//tensorflow/lite/... -//tools/toolchains/...\n\n# LINUX ARM64 PYCPP\n# In Linux Arm64 presubmit/continuous build, we cross-compile the binaries on\n# Linux x86 so that we can use RBE. Since tests still need to run on the single\n# host Arm64 machine, the build becomes too slow (~30 min) to be a presubmit.\n# For testing purposes, we want to see the runtime performance of an\n# experimental job that is build-only, i.e, we only build the test targets and\n# do not run them. By prefixing the configs with \"build\", we can run both\n# `bazel build` and `bazel test` commands with the same config as test configs\n# inherit from build.\nbuild:linux_arm64_pycpp_test_filters --test_tag_filters=-no_oss,-tf_tosa,-no_aarch64,-oss_excluded,-oss_serial,-gpu,-tpu,-benchmark-test,-v1only\nbuild:linux_arm64_pycpp_test_filters --build_tag_filters=-no_oss,-tf_tosa,-no_aarch64,-oss_excluded,-oss_serial,-gpu,-tpu,-benchmark-test,-v1only\nbuild:linux_arm64_pycpp_test_filters --test_lang_filters=cc,py --test_size_filters=small,medium --flaky_test_attempts=3\n# TODO(michaelhudgins): Why do we need to specifically omit go and java here?\nbuild:linux_arm64_pycpp_test --config=linux_arm64_pycpp_test_filters -- //tensorflow/... //tensorflow/tools/pip_package:import_api_packages_test_cpu -//tensorflow/compiler/tf2tensorrt/... -//tensorflow/core/tpu/... -//tensorflow/lite/... -//tools/toolchains/... -//tensorflow/go/... -//tensorflow/java/... -//tensorflow/core/grappler/optimizers:auto_mixed_precision_test_cpu -//tensorflow/core/grappler/optimizers:remapper_test_cpu -//tensorflow/core/kernels/image:resize_bicubic_op_test -//tensorflow/python/tools:aot_compiled_test\n# CROSS-COMPILE ARM64 PYCPP\nbuild:cross_compile_linux_arm64_pycpp_test --config=linux_arm64_pycpp_test\n# Tests that fail only when cross-compiled\nbuild:cross_compile_linux_arm64_pycpp_test -//tensorflow/compiler/mlir/quantization/stablehlo:convert_tf_quant_to_mhlo_int_test\n# MACOS ARM64 PYCPP\ntest:macos_arm64_pycpp_test_filters --test_tag_filters=-no_oss,-tf_tosa,-oss_excluded,-oss_serial,-no_oss_py39,-no_oss_py310,-nomac,-no_mac,-mac_excluded,-v1only,-gpu,-tpu,-benchmark-test,-no_mac_arm64,-no_aarch64\ntest:macos_arm64_pycpp_test_filters --build_tag_filters=-no_oss,-tf_tosa,-oss_excluded,-oss_serial,-no_oss_py39,-no_oss_py310,-nomac,-no_mac,-mac_excluded,-v1only,-gpu,-tpu,-benchmark-test,-no_mac_arm64,-no_aarch64\ntest:macos_arm64_pycpp_test_filters --test_lang_filters=cc,py --test_size_filters=small,medium\ntest:macos_arm64_pycpp_test --config=macos_arm64_pycpp_test_filters -- //tensorflow/... //tensorflow/tools/pip_package:import_api_packages_test_cpu -//tensorflow/compiler/tf2tensorrt/... -//tensorflow/core/tpu/... -//tensorflow/lite/... -//tools/toolchains/... -//tensorflow/go/... -//tensorflow/java/... -//tensorflow/compiler/aot/... -//tensorflow/core/kernels/image:resize_bicubic_op_test\n# MACOS X86 PYCPP\n# These are defined as build configs so that we can run a build only job. See\n# the note under \"ARM64 PYCPP\" for more details.\nbuild:macos_x86_pycpp_test_filters --test_tag_filters=-no_oss,-tf_tosa,-oss_excluded,-oss_serial,-no_oss_py38,-no_oss_py39,-no_oss_py310,-nomac,-no_mac,-mac_excluded,-v1only,-gpu,-tpu,-benchmark-test\nbuild:macos_x86_pycpp_test_filters --build_tag_filters=-no_oss,-tf_tosa,-oss_excluded,-oss_serial,-no_oss_py38,-no_oss_py39,-no_oss_py310,-nomac,-no_mac,-mac_excluded,-v1only,-gpu,-tpu,-benchmark-test\nbuild:macos_x86_pycpp_test_filters --keep_going --test_lang_filters=cc,py --test_size_filters=small,medium\nbuild:macos_x86_pycpp_test --config=macos_x86_pycpp_test_filters -- //tensorflow/... //tensorflow/tools/pip_package:import_api_packages_test_cpu -//tensorflow/compiler/tf2tensorrt/... -//tensorflow/core/tpu/... -//tensorflow/go/... -//tensorflow/java/... -//tools/toolchains/... -//tensorflow/lite/... -//tensorflow/compiler/aot/...\n# CROSS-COMPILE MACOS X86 PYCPP\nbuild:cross_compile_macos_x86_pycpp_test --config=macos_x86_pycpp_test\nbuild:cross_compile_macos_x86_pycpp_test -//tensorflow/core/kernels:quantized_conv_ops_test -//tensorflow/core/kernels:quantized_matmul_op_test -//tensorflow/python/ops:quantized_conv_ops_test -//tensorflow/tools/graph_transforms:transforms_test -//tensorflow/python/tools:aot_compiled_test\n# WINDOWS X86-64 CPU PYCPP\nbuild:windows_x86_cpu_pycpp_test_build_opts --copt=/d2ReducedOptimizeHugeFunctions --host_copt=/d2ReducedOptimizeHugeFunctions --dynamic_mode=off\nbuild:windows_x86_cpu_pycpp_test_build_opts_debug --config=windows_x86_cpu_pycpp_test_build_opts --linkopt=/demangle:no --host_linkopt=/demangle:no --linkopt=/errorlimit:0 --host_linkopt=/errorlimit:0\ntest:windows_x86_cpu_pycpp_test_filters --test_tag_filters=-no_windows,-windows_excluded,-no_oss,-tf_tosa,-oss_excluded,-gpu,-tpu,-benchmark-test\ntest:windows_x86_cpu_pycpp_test_filters --build_tag_filters=-no_windows,-windows_excluded,-no_oss,-tf_tosa,-oss_excluded,-benchmark-test\ntest:windows_x86_cpu_pycpp_test_filters --test_lang_filters=cc,py --test_size_filters=small,medium --test_timeout=\"300,450,1200,3600\"\ntest:windows_x86_cpu_pycpp_test_opts --config=windows_x86_cpu_pycpp_test_build_opts --build_tests_only\ntest:windows_x86_cpu_pycpp_test --config=windows_x86_cpu_pycpp_test_opts --config=windows_x86_cpu_pycpp_test_filters -- //tensorflow/... -//tensorflow/java/... -//tensorflow/lite/... -//tensorflow/compiler/...\n\n# END TF TEST SUITE OPTIONS\n\n# START CROSS-COMPILE CONFIGS\n# Set execution platform to Linux x86\n# Note: Lot of the \"host_\" flags such as \"host_cpu\" and \"host_crosstool_top\"\n# flags seem to be actually used to specify the execution platform details. It\n# seems it is this way because these flags are old and predate the distinction\n# between host and execution platform.\nbuild:cross_compile_base --host_cpu=k8\nbuild:cross_compile_base --host_crosstool_top=//tools/toolchains/cross_compile/cc:cross_compile_toolchain_suite\nbuild:cross_compile_base --extra_execution_platforms=//tools/toolchains/cross_compile/config:linux_x86_64\n\nbuild:rbe_cross_compile_base --config=rbe_base\nbuild:rbe_cross_compile_base --remote_instance_name=projects/tensorflow-testing/instances/default_instance\n\n# Test-related settings below this point\n# We cannot run cross-compiled tests on the remote Linux x86 VMs so we need to\n# force all tests to run locally on the Aarch64 host.\ntest:rbe_cross_compile_base --strategy=TestRunner=local --build_tests_only\ntest:rbe_cross_compile_base --verbose_failures=true --local_test_jobs=HOST_CPUS --test_output=errors\n\n# START LINUX AARCH64 CROSS-COMPILE CONFIGS\nbuild:cross_compile_linux_arm64 --config=cross_compile_base\n\n# Set the target CPU to Aarch64\nbuild:cross_compile_linux_arm64 --platforms=//tools/toolchains/cross_compile/config:linux_aarch64\nbuild:cross_compile_linux_arm64 --cpu=aarch64\nbuild:cross_compile_linux_arm64 --crosstool_top=//tools/toolchains/cross_compile/cc:cross_compile_toolchain_suite\n\n# RBE cross-compile configs for Linux Aarch64\nbuild:rbe_cross_compile_linux_arm64 --config=cross_compile_linux_arm64\nbuild:rbe_cross_compile_linux_arm64 --config=rbe_cross_compile_base\ntest:rbe_cross_compile_linux_arm64 --config=rbe_cross_compile_base\n\n# END LINUX AARCH64 CROSS-COMPILE CONFIGS\n\n# START MACOS CROSS-COMPILE CONFIGS\nbuild:cross_compile_macos_x86 --config=cross_compile_base\nbuild:cross_compile_macos_x86 --config=nonccl\n# Target Catalina (10.15) as the minimum supported OS\nbuild:cross_compile_macos_x86 --action_env  MACOSX_DEPLOYMENT_TARGET=10.15\n\n# Set the target CPU to Darwin x86\nbuild:cross_compile_macos_x86 --platforms=//tools/toolchains/cross_compile/config:darwin_x86_64\nbuild:cross_compile_macos_x86 --cpu=darwin\nbuild:cross_compile_macos_x86 --crosstool_top=//tools/toolchains/cross_compile/cc:cross_compile_toolchain_suite\n# When RBE cross-compiling for macOS, we need to explicitly register the\n# toolchain. Otherwise, oddly, RBE complains that a \"docker container must be\n# specified\".\nbuild:cross_compile_macos_x86 --extra_toolchains=//tools/toolchains/cross_compile/config:macos-x86-cross-compile-cc-toolchain\n# Map --platforms=darwin_x86_64 to --cpu=darwin and vice-versa to make selects()\n# and transistions that use these flags work.\nbuild:cross_compile_macos_x86 --platform_mappings=tools/toolchains/cross_compile/config/platform_mappings\n\n# RBE cross-compile configs for Darwin x86\nbuild:rbe_cross_compile_macos_x86 --config=cross_compile_macos_x86 --remote_download_minimal\nbuild:rbe_cross_compile_macos_x86 --bes_backend=\"\" --bes_results_url=\"\" --bes_timeout=\"0s\"\nbuild:rbe_cross_compile_macos_x86 --experimental_remote_build_event_upload=\"minimal\"\nbuild:rbe_cross_compile_macos_x86 --config=rbe_cross_compile_base\nbuild:rbe_cross_compile_macos_x86 --bes_upload_mode=nowait_for_upload_complete\ntest:rbe_cross_compile_macos_x86 --config=rbe_cross_compile_base\n# Increase the test timeout as tests often take longer on mac.\ntest:rbe_cross_compile_macos_x86 --test_timeout=300,450,1200,3600\n# Limit jobs to 100 to avoid running into \"out of memory\" issues (b/316266643)\nbuild:rbe_cross_compile_macos_x86 --jobs=100\ntest:rbe_cross_compile_macos_x86 --jobs=100\n# END MACOS CROSS-COMPILE CONFIGS\n# END CROSS-COMPILE CONFIGS\n\n# Try to load the XLA warnings config if available\ntry-import %workspace%/warnings.bazelrc\n"
        },
        {
          "name": ".bazelversion",
          "type": "blob",
          "size": 0.005859375,
          "content": "6.5.0\n"
        },
        {
          "name": ".clang-format",
          "type": "blob",
          "size": 0.115234375,
          "content": "BasedOnStyle: Google\nLanguage: Cpp\nPointerBindsToType: true\nSortIncludes: Never\nAlignTrailingComments:\n  Kind: Always\n"
        },
        {
          "name": ".clang-tidy",
          "type": "blob",
          "size": 5.7705078125,
          "content": "ExtraArgs: [\n  \"-Wno-everything\",\n  \"-Wno-error\",\n  \"-Wdeprecated-declarations\",\n  \"-D_LIBCPP_DISABLE_DEPRECATION_WARNINGS\",\n  \"-Wdeprecated-register\",\n  \"-Wexpansion-to-defined\",\n  \"-Wignored-attributes\",\n  \"-Wnon-pod-varargs\",\n  \"-Wshadow-field\",\n  \"-Wshift-sign-overflow\",\n  \"-Wtautological-undefined-compare\",\n  \"-Wthread-safety-analysis\",\n  \"-Wthread-safety-beta\",\n  \"-Wthread-safety-reference\",\n  \"-Wundefined-bool-conversion\",\n  \"-Wunreachable-code\",\n  \"-Wunused-const-variable\",\n  \"-Wunused-function\",\n  \"-Wunused-lambda-capture\",\n  \"-Wunused-local-typedef\",\n  \"-Wunused-private-field\",\n  \"-Wuser-defined-warnings\",\n]\nChecks: \"-*,\n  abseil-duration-addition,\n  abseil-duration-addition,\n  abseil-duration-comparison,\n  abseil-duration-conversion-cast,\n  abseil-duration-division,\n  abseil-duration-factory-float,\n  abseil-duration-factory-scale,\n  abseil-duration-subtraction,\n  abseil-duration-unnecessary-conversion,\n  abseil-faster-strsplit-delimiter,\n  abseil-no-internal-dependencies,\n  abseil-redundant-strcat-calls,\n  abseil-str-cat-append,\n  abseil-string-find-startswith,\n  abseil-string-find-str-contains,\n  abseil-time-comparison,\n  abseil-time-subtraction,\n  bugprone-argument-comment,\n  bugprone-assert-side-effect,\n  bugprone-bool-pointer-implicit-conversion,\n  bugprone-dangling-handle,\n  bugprone-fold-init-type,\n  bugprone-forward-declaration-namespace,\n  bugprone-inaccurate-erase,\n  bugprone-macro-repeated-side-effects,\n  bugprone-move-forwarding-reference,\n  bugprone-multiple-statement-macro,\n  bugprone-string-constructor,\n  bugprone-stringview-nullptr,\n  bugprone-suspicious-memset-usage,\n  bugprone-undefined-memory-manipulation,\n  bugprone-undelegated-constructor,\n  bugprone-unused-raii,\n  bugprone-use-after-move,\n  clang-diagnostic-deprecated-declarations,\n  clang-diagnostic-deprecated-register,\n  clang-diagnostic-expansion-to-defined,\n  clang-diagnostic-ignored-attributes,\n  clang-diagnostic-non-pod-varargs,\n  clang-diagnostic-shadow-field,\n  clang-diagnostic-shift-sign-overflow,\n  clang-diagnostic-tautological-undefined-compare,\n  clang-diagnostic-thread-safety*,\n  clang-diagnostic-undefined-bool-conversion,\n  clang-diagnostic-unreachable-code,\n  clang-diagnostic-unreachable-code-loop-increment,\n  clang-diagnostic-unused-const-variable,\n  clang-diagnostic-unused-function,\n  clang-diagnostic-unused-lambda-capture,\n  clang-diagnostic-unused-local-typedef,\n  clang-diagnostic-unused-private-field,\n  clang-diagnostic-user-defined-warnings,\n  darwin-avoid-spinlock,\n  google-build-explicit-make-pair,\n  google-build-namespaces,\n  google-build-using-namespace,\n  google-default-arguments,\n  google-explicit-constructor,\n  google-global-names-in-headers,\n  google-objc-avoid-nsobject-new,\n  google-objc-function-naming,\n  google-objc-global-variable-declaration,\n  google-readability-function-size,\n  google-readability-namespace-comments,\n  google-runtime-int,\n  google-runtime-memset,\n  google-runtime-operator,\n  misc-definitions-in-headers,\n  misc-static-assert,\n  misc-unconventional-assign-operator,\n  misc-uniqueptr-reset-release,\n  misc-unused-alias-decls,\n  misc-unused-using-decls,\n  modernize-make-unique,\n  modernize-redundant-void-arg,\n  modernize-replace-auto-ptr,\n  modernize-shrink-to-fit,\n  modernize-use-bool-literals,\n  modernize-use-equals-default,\n  modernize-use-nullptr,\n  modernize-use-override,\n  objc-avoid-nserror-init,\n  objc-dealloc-in-category,\n  objc-forbidden-subclassing,\n  objc-nsinvocation-argument-lifetime,\n  objc-property-declaration,\n  objc-super-self,\n  performance-faster-string-find,\n  performance-for-range-copy,\n  performance-implicit-conversion-in-loop,\n  performance-inefficient-algorithm,\n  performance-inefficient-vector-operation,\n  performance-move-constructor-init,\n  portability-std-allocator-const,\n  readability-avoid-const-params-in-decls,\n  readability-const-return-type,\n  readability-container-size-empty,\n  readability-deleted-default,\n  readability-inconsistent-declaration-parameter-name,\n  readability-misleading-indentation,\n  readability-redundant-control-flow,\n  readability-redundant-smartptr-get,\n  readability-string-compare,\"\nCheckOptions:\n  - key: 'bugprone-assert-side-effect.AssertMacros'\n    value: assert,DCHECK\n  - key: 'bugprone-string-constructor.WarnOnLargeLength'\n    value: 0\n  - key: 'bugprone-dangling-handle.HandleClasses'\n    value: '::std::string_view;::std::experimental::string_view;::absl::string_view;::absl::Span;::absl::FunctionRef;::llvm::StringRef;::llvm::ArrayRef;::absl::BitGenRef;::mlir::BlockRange;::mlir::OperandRange;::mlir::RegionRange;::mlir::ResultRange;::mlir::SuccessorRange;::mlir::TypeRange;::mlir::ValueRange'\n  - key: 'google-readability-function-size.ParameterThreshold'\n    value: 100\n  - key: 'modernize-make-unique.IncludeStyle'\n    value: 'google'\n  - key: 'performance-inefficient-vector-operation.VectorLikeClasses'\n    value: '::std::vector;::absl::InlinedVector'\n  - key: 'performance-inefficient-vector-operation.EnableProto'\n    value: 1\n  - key: 'abseil-string-find-startswith.IncludeStyle'\n    value: 'google'\n  - key: 'abseil-string-find-startswith.AbseilStringsMatchHeader'\n    value: 'absl/strings/match.h'\n  - key: 'abseil-string-find-startswith.StringLikeClasses'\n    value: '::std::string_view;::absl::string_view;::basic_string;::std::basic_string;'\n  - key: 'abseil-string-find-str-contains.IncludeStyle'\n    value: 'google'\n  - key: 'abseil-string-find-str-contains.AbseilStringsMatchHeader'\n    value: 'absl/strings/match.h'\n  - key: 'abseil-string-find-str-contains.StringLikeClasses'\n    value: '::std::basic_string_view;::absl::string_view;::basic_string;::std::basic_string;'\n  - key: 'readability-function-cognitive-complexity.Threshold'\n    value: 15\n  - key: 'readability-function-cognitive-complexity.DescribeBasicIncrements'\n    value: false\n  - key: 'readability-function-cognitive-complexity.IgnoreMacros'\n    value: true\n"
        },
        {
          "name": ".github",
          "type": "tree",
          "content": null
        },
        {
          "name": ".gitignore",
          "type": "blob",
          "size": 0.3720703125,
          "content": "# Copyright 2023 The OpenXLA Authors\n#\n\n\n# Ignore the bazel directories when this directory is used as a local repository.\nbazel-*\nbazel-bin\nbazel-out\nbazel-testlogs\n\n# Ignore files produced by `configure`\n.tf_configure.bazelrc\nxla_configure.bazelrc\ntools/python_bin_path.sh\n\n# Emacs autosaves\n*~\n\\#*\\#\n\n# Visual Studio files\n.vs/\n.vscode/\n*.sdf\n*.opensdf\n*.VC.opendb\n*.suo\n*.user\n"
        },
        {
          "name": ".kokoro",
          "type": "tree",
          "content": null
        },
        {
          "name": "BUILD.bazel",
          "type": "blob",
          "size": 0.3037109375,
          "content": "load(\"@rules_license//rules:license.bzl\", \"license\")\n\npackage(\n    default_applicable_licenses = [\":license\"],\n    default_visibility = [\"//visibility:public\"],\n)\n\nlicenses([\"notice\"])\n\nlicense(\n    name = \"license\",\n    package_name = \"xla\",\n    license_kinds = [\"@rules_license//licenses/spdx:Apache-2.0\"],\n)\n"
        },
        {
          "name": "CONTRIBUTING.md",
          "type": "blob",
          "size": 0.125,
          "content": "# Contributing to OpenXLA\n\nFor information on how to contribute to OpenXLA, see\n[Contributing to OpenXLA](docs/contributing.md)\n"
        },
        {
          "name": "LICENSE",
          "type": "blob",
          "size": 11.08984375,
          "content": "                                 Apache License\n                           Version 2.0, January 2004\n                        http://www.apache.org/licenses/\n\n   TERMS AND CONDITIONS FOR USE, REPRODUCTION, AND DISTRIBUTION\n\n   1. Definitions.\n\n      \"License\" shall mean the terms and conditions for use, reproduction,\n      and distribution as defined by Sections 1 through 9 of this document.\n\n      \"Licensor\" shall mean the copyright owner or entity authorized by\n      the copyright owner that is granting the License.\n\n      \"Legal Entity\" shall mean the union of the acting entity and all\n      other entities that control, are controlled by, or are under common\n      control with that entity. For the purposes of this definition,\n      \"control\" means (i) the power, direct or indirect, to cause the\n      direction or management of such entity, whether by contract or\n      otherwise, or (ii) ownership of fifty percent (50%) or more of the\n      outstanding shares, or (iii) beneficial ownership of such entity.\n\n      \"You\" (or \"Your\") shall mean an individual or Legal Entity\n      exercising permissions granted by this License.\n\n      \"Source\" form shall mean the preferred form for making modifications,\n      including but not limited to software source code, documentation\n      source, and configuration files.\n\n      \"Object\" form shall mean any form resulting from mechanical\n      transformation or translation of a Source form, including but\n      not limited to compiled object code, generated documentation,\n      and conversions to other media types.\n\n      \"Work\" shall mean the work of authorship, whether in Source or\n      Object form, made available under the License, as indicated by a\n      copyright notice that is included in or attached to the work\n      (an example is provided in the Appendix below).\n\n      \"Derivative Works\" shall mean any work, whether in Source or Object\n      form, that is based on (or derived from) the Work and for which the\n      editorial revisions, annotations, elaborations, or other modifications\n      represent, as a whole, an original work of authorship. For the purposes\n      of this License, Derivative Works shall not include works that remain\n      separable from, or merely link (or bind by name) to the interfaces of,\n      the Work and Derivative Works thereof.\n\n      \"Contribution\" shall mean any work of authorship, including\n      the original version of the Work and any modifications or additions\n      to that Work or Derivative Works thereof, that is intentionally\n      submitted to Licensor for inclusion in the Work by the copyright owner\n      or by an individual or Legal Entity authorized to submit on behalf of\n      the copyright owner. For the purposes of this definition, \"submitted\"\n      means any form of electronic, verbal, or written communication sent\n      to the Licensor or its representatives, including but not limited to\n      communication on electronic mailing lists, source code control systems,\n      and issue tracking systems that are managed by, or on behalf of, the\n      Licensor for the purpose of discussing and improving the Work, but\n      excluding communication that is conspicuously marked or otherwise\n      designated in writing by the copyright owner as \"Not a Contribution.\"\n\n      \"Contributor\" shall mean Licensor and any individual or Legal Entity\n      on behalf of whom a Contribution has been received by Licensor and\n      subsequently incorporated within the Work.\n\n   2. Grant of Copyright License. Subject to the terms and conditions of\n      this License, each Contributor hereby grants to You a perpetual,\n      worldwide, non-exclusive, no-charge, royalty-free, irrevocable\n      copyright license to reproduce, prepare Derivative Works of,\n      publicly display, publicly perform, sublicense, and distribute the\n      Work and such Derivative Works in Source or Object form.\n\n   3. Grant of Patent License. Subject to the terms and conditions of\n      this License, each Contributor hereby grants to You a perpetual,\n      worldwide, non-exclusive, no-charge, royalty-free, irrevocable\n      (except as stated in this section) patent license to make, have made,\n      use, offer to sell, sell, import, and otherwise transfer the Work,\n      where such license applies only to those patent claims licensable\n      by such Contributor that are necessarily infringed by their\n      Contribution(s) alone or by combination of their Contribution(s)\n      with the Work to which such Contribution(s) was submitted. If You\n      institute patent litigation against any entity (including a\n      cross-claim or counterclaim in a lawsuit) alleging that the Work\n      or a Contribution incorporated within the Work constitutes direct\n      or contributory patent infringement, then any patent licenses\n      granted to You under this License for that Work shall terminate\n      as of the date such litigation is filed.\n\n   4. Redistribution. You may reproduce and distribute copies of the\n      Work or Derivative Works thereof in any medium, with or without\n      modifications, and in Source or Object form, provided that You\n      meet the following conditions:\n\n      (a) You must give any other recipients of the Work or\n          Derivative Works a copy of this License; and\n\n      (b) You must cause any modified files to carry prominent notices\n          stating that You changed the files; and\n\n      (c) You must retain, in the Source form of any Derivative Works\n          that You distribute, all copyright, patent, trademark, and\n          attribution notices from the Source form of the Work,\n          excluding those notices that do not pertain to any part of\n          the Derivative Works; and\n\n      (d) If the Work includes a \"NOTICE\" text file as part of its\n          distribution, then any Derivative Works that You distribute must\n          include a readable copy of the attribution notices contained\n          within such NOTICE file, excluding those notices that do not\n          pertain to any part of the Derivative Works, in at least one\n          of the following places: within a NOTICE text file distributed\n          as part of the Derivative Works; within the Source form or\n          documentation, if provided along with the Derivative Works; or,\n          within a display generated by the Derivative Works, if and\n          wherever such third-party notices normally appear. The contents\n          of the NOTICE file are for informational purposes only and\n          do not modify the License. You may add Your own attribution\n          notices within Derivative Works that You distribute, alongside\n          or as an addendum to the NOTICE text from the Work, provided\n          that such additional attribution notices cannot be construed\n          as modifying the License.\n\n      You may add Your own copyright statement to Your modifications and\n      may provide additional or different license terms and conditions\n      for use, reproduction, or distribution of Your modifications, or\n      for any such Derivative Works as a whole, provided Your use,\n      reproduction, and distribution of the Work otherwise complies with\n      the conditions stated in this License.\n\n   5. Submission of Contributions. Unless You explicitly state otherwise,\n      any Contribution intentionally submitted for inclusion in the Work\n      by You to the Licensor shall be under the terms and conditions of\n      this License, without any additional terms or conditions.\n      Notwithstanding the above, nothing herein shall supersede or modify\n      the terms of any separate license agreement you may have executed\n      with Licensor regarding such Contributions.\n\n   6. Trademarks. This License does not grant permission to use the trade\n      names, trademarks, service marks, or product names of the Licensor,\n      except as required for reasonable and customary use in describing the\n      origin of the Work and reproducing the content of the NOTICE file.\n\n   7. Disclaimer of Warranty. Unless required by applicable law or\n      agreed to in writing, Licensor provides the Work (and each\n      Contributor provides its Contributions) on an \"AS IS\" BASIS,\n      WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or\n      implied, including, without limitation, any warranties or conditions\n      of TITLE, NON-INFRINGEMENT, MERCHANTABILITY, or FITNESS FOR A\n      PARTICULAR PURPOSE. You are solely responsible for determining the\n      appropriateness of using or redistributing the Work and assume any\n      risks associated with Your exercise of permissions under this License.\n\n   8. Limitation of Liability. In no event and under no legal theory,\n      whether in tort (including negligence), contract, or otherwise,\n      unless required by applicable law (such as deliberate and grossly\n      negligent acts) or agreed to in writing, shall any Contributor be\n      liable to You for damages, including any direct, indirect, special,\n      incidental, or consequential damages of any character arising as a\n      result of this License or out of the use or inability to use the\n      Work (including but not limited to damages for loss of goodwill,\n      work stoppage, computer failure or malfunction, or any and all\n      other commercial damages or losses), even if such Contributor\n      has been advised of the possibility of such damages.\n\n   9. Accepting Warranty or Additional Liability. While redistributing\n      the Work or Derivative Works thereof, You may choose to offer,\n      and charge a fee for, acceptance of support, warranty, indemnity,\n      or other liability obligations and/or rights consistent with this\n      License. However, in accepting such obligations, You may act only\n      on Your own behalf and on Your sole responsibility, not on behalf\n      of any other Contributor, and only if You agree to indemnify,\n      defend, and hold each Contributor harmless for any liability\n      incurred by, or claims asserted against, such Contributor by reason\n      of your accepting any such warranty or additional liability.\n\n   END OF TERMS AND CONDITIONS\n\n   APPENDIX: How to apply the Apache License to your work.\n\n      To apply the Apache License to your work, attach the following\n      boilerplate notice, with the fields enclosed by brackets \"[]\"\n      replaced with your own identifying information. (Don't include\n      the brackets!)  The text should be enclosed in the appropriate\n      comment syntax for the file format. We also recommend that a\n      file or class name and description of purpose be included on the\n      same \"printed page\" as the copyright notice for easier\n      identification within third-party archives.\n\n   Copyright [yyyy] [name of copyright owner]\n\n   Licensed under the Apache License, Version 2.0 (the \"License\");\n   you may not use this file except in compliance with the License.\n   You may obtain a copy of the License at\n\n       http://www.apache.org/licenses/LICENSE-2.0\n\n   Unless required by applicable law or agreed to in writing, software\n   distributed under the License is distributed on an \"AS IS\" BASIS,\n   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n   See the License for the specific language governing permissions and\n   limitations under the License."
        },
        {
          "name": "README.md",
          "type": "blob",
          "size": 1.587890625,
          "content": "# XLA\n\nXLA (Accelerated Linear Algebra) is an open-source machine learning (ML)\ncompiler for GPUs, CPUs, and ML accelerators.\n\n<picture>\n  <source media=\"(prefers-color-scheme: dark)\" srcset=\"docs/images/openxla_dark.svg\">\n  <img alt=\"OpenXLA Ecosystem\" src=\"docs/images/openxla.svg\">\n</picture>\n\nThe XLA compiler takes models from popular ML frameworks such as PyTorch,\nTensorFlow, and JAX, and optimizes them for high-performance execution across\ndifferent hardware platforms including GPUs, CPUs, and ML accelerators.\n\n## Get started\n\nIf you want to use XLA to compile your ML project, refer to the corresponding\ndocumentation for your ML framework:\n\n* [PyTorch](https://pytorch.org/xla)\n* [TensorFlow](https://www.tensorflow.org/xla)\n* [JAX](https://jax.readthedocs.io/en/latest/notebooks/quickstart.html)\n\nIf you're not contributing code to the XLA compiler, you don't need to clone and\nbuild this repo. Everything here is intended for XLA contributors who want to\ndevelop the compiler and XLA integrators who want to debug or add support for ML\nfrontends and hardware backends.\n\n## Contribute\n\nIf you'd like to contribute to XLA, review\n[How to Contribute](docs/contributing.md) and then see the\n[developer guide](docs/developer_guide.md).\n\n## Contacts\n\n*   For questions, contact the maintainers - maintainers at openxla.org\n\n## Resources\n\n*   [Community Resources](https://github.com/openxla/community)\n\n## Code of Conduct\n\nWhile under TensorFlow governance, all community spaces for SIG OpenXLA are\nsubject to the\n[TensorFlow Code of Conduct](https://github.com/tensorflow/tensorflow/blob/master/CODE_OF_CONDUCT.md).\n"
        },
        {
          "name": "WORKSPACE",
          "type": "blob",
          "size": 2.208984375,
          "content": "# buildifier: disable=load-on-top\nworkspace(name = \"xla\")\n\n# Initialize the XLA repository and all dependencies.\n#\n# The cascade of load() statements and xla_workspace?() calls works around the\n# restriction that load() statements need to be at the top of .bzl files.\n# E.g. we can not retrieve a new repository with http_archive and then load()\n# a macro from that repository in the same file.\n\n# Initialize hermetic Python\nload(\"//third_party/py:python_init_rules.bzl\", \"python_init_rules\")\n\npython_init_rules()\n\nload(\"//third_party/py:python_init_repositories.bzl\", \"python_init_repositories\")\n\npython_init_repositories(\n    requirements = {\n        \"3.11\": \"//:requirements_lock_3_11.txt\",\n    },\n)\n\nload(\"//third_party/py:python_init_toolchains.bzl\", \"python_init_toolchains\")\n\npython_init_toolchains()\n\nload(\"//third_party/py:python_init_pip.bzl\", \"python_init_pip\")\n\npython_init_pip()\n\nload(\"@pypi//:requirements.bzl\", \"install_deps\")\n\ninstall_deps()\n\nload(\":workspace4.bzl\", \"xla_workspace4\")\n\nxla_workspace4()\n\nload(\":workspace3.bzl\", \"xla_workspace3\")\n\nxla_workspace3()\n\nload(\":workspace2.bzl\", \"xla_workspace2\")\n\nxla_workspace2()\n\nload(\":workspace1.bzl\", \"xla_workspace1\")\n\nxla_workspace1()\n\nload(\":workspace0.bzl\", \"xla_workspace0\")\n\nxla_workspace0()\n\nload(\n    \"@tsl//third_party/gpus/cuda/hermetic:cuda_json_init_repository.bzl\",\n    \"cuda_json_init_repository\",\n)\n\ncuda_json_init_repository()\n\nload(\n    \"@cuda_redist_json//:distributions.bzl\",\n    \"CUDA_REDISTRIBUTIONS\",\n    \"CUDNN_REDISTRIBUTIONS\",\n)\nload(\n    \"@tsl//third_party/gpus/cuda/hermetic:cuda_redist_init_repositories.bzl\",\n    \"cuda_redist_init_repositories\",\n    \"cudnn_redist_init_repository\",\n)\n\ncuda_redist_init_repositories(\n    cuda_redistributions = CUDA_REDISTRIBUTIONS,\n)\n\ncudnn_redist_init_repository(\n    cudnn_redistributions = CUDNN_REDISTRIBUTIONS,\n)\n\nload(\n    \"@tsl//third_party/gpus/cuda/hermetic:cuda_configure.bzl\",\n    \"cuda_configure\",\n)\n\ncuda_configure(name = \"local_config_cuda\")\n\nload(\n    \"@tsl//third_party/nccl/hermetic:nccl_redist_init_repository.bzl\",\n    \"nccl_redist_init_repository\",\n)\n\nnccl_redist_init_repository()\n\nload(\n    \"@tsl//third_party/nccl/hermetic:nccl_configure.bzl\",\n    \"nccl_configure\",\n)\n\nnccl_configure(name = \"local_config_nccl\")\n"
        },
        {
          "name": "build_tools",
          "type": "tree",
          "content": null
        },
        {
          "name": "configure.py",
          "type": "blob",
          "size": 0.033203125,
          "content": "build_tools/configure/configure.py"
        },
        {
          "name": "docs",
          "type": "tree",
          "content": null
        },
        {
          "name": "opensource_only.files",
          "type": "blob",
          "size": 2.1826171875,
          "content": "compiler/xla/backends/cpu/nanort/package_groups.bzl:\ncompiler/xla/backends/cpu/package_groups.bzl:\ncompiler/xla/internal/package_groups.bzl:\ncompiler/xla/mlir_hlo/WORKSPACE:\ncompiler/xla/package_groups.bzl:\ncompiler/xla/pjrt/cpu/package_groups.bzl:\ncompiler/xla/pjrt/gpu/package_groups.bzl:\ncompiler/xla/stream_executor/build_defs.bzl:\ncompiler/xla/tsl/cuda/stub.bzl:\ncompiler/xla/tsl/mkl/BUILD:\ncompiler/xla/tsl/mkl/LICENSE:\ncompiler/xla/tsl/mkl/MKL_LICENSE:\ncompiler/xla/tsl/mkl/build_defs.bzl:\ncompiler/xla/tsl/package_groups.bzl:\ncompiler/xla/tsl/profiler/BUILD:\nthird_party/BUILD:\nthird_party/__init__:.py\nthird_party/compute_library/BUILD:\nthird_party/compute_library/build_defs.bzl:\nthird_party/implib_so/BUILD:\nthird_party/implib_so/get_symbols.py:\nthird_party/implib_so/make_stub.py:\nthird_party/llvm_openmp/BUILD:\nthird_party/llvm_openmp/cmake_vars.bzl:\nthird_party/llvm_openmp/expand_cmake_vars:.py\nthird_party/llvm_openmp/openmp.bzl:\nthird_party/ortools/BUILD:\nthird_party/ortools/glpk.BUILD:\nthird_party/ortools/ortools.patch:\nthird_party/py/BUILD.tpl:\nthird_party/py/BUILD:\nthird_party/py/ml_dtypes/BUILD:\nthird_party/py/ml_dtypes/LICENSE:\nthird_party/py/numpy/BUILD:\nthird_party/py/python_configure.bzl:\nthird_party/py/python_init_pip.bzl:\nthird_party/py/python_init_repositories.bzl:\nthird_party/py/python_init_rules.bzl:\nthird_party/py/python_init_toolchains.bzl:\nthird_party/py/python_repo.bzl:\nthird_party/python_runtime/BUILD:\nthird_party/repo.bzl:\nthird_party/spirv_llvm_translator/spirv_llvm_translator.BUILD:\nthird_party/stablehlo/BUILD:\ntools/toolchains/BUILD:\ntools/toolchains/clang6/BUILD:\ntools/toolchains/cpus/py/BUILD:\ntools/toolchains/cpus/py3/BUILD:\ntools/toolchains/cross_compile/cc/BUILD:\ntools/toolchains/cross_compile/config/BUILD:\ntools/toolchains/embedded/arm-linux/BUILD:\ntools/toolchains/java/BUILD:\ntools/toolchains/python/BUILD:\ntools/toolchains/remote/BUILD:\ntools/toolchains/remote_config/BUILD:\ntools/toolchains/win/20240424/BUILD:\ntools/toolchains/win/BUILD:\ntools/toolchains/win/bazel_211/BUILD:\ntools/toolchains/win/tf_win_05022023/BUILD:\ntools/toolchains/win2022/20241118/BUILD:\ntools/toolchains/win2022/BUILD:\ntools/toolchains/win_1803/py38/BUILD:\ntools/toolchains/win_1803/py39/BUILD:\n"
        },
        {
          "name": "requirements_lock_3_11.txt",
          "type": "blob",
          "size": 3.859375,
          "content": "numpy==1.24.3 \\\n    --hash=sha256:0ec87a7084caa559c36e0a2309e4ecb1baa03b687201d0a847c8b0ed476a7187 \\\n    --hash=sha256:1a7d6acc2e7524c9955e5c903160aa4ea083736fde7e91276b0e5d98e6332812 \\\n    --hash=sha256:202de8f38fc4a45a3eea4b63e2f376e5f2dc64ef0fa692838e31a808520efaf7 \\\n    --hash=sha256:210461d87fb02a84ef243cac5e814aad2b7f4be953b32cb53327bb49fd77fbb4 \\\n    --hash=sha256:2d926b52ba1367f9acb76b0df6ed21f0b16a1ad87c6720a1121674e5cf63e2b6 \\\n    --hash=sha256:352ee00c7f8387b44d19f4cada524586f07379c0d49270f87233983bc5087ca0 \\\n    --hash=sha256:35400e6a8d102fd07c71ed7dcadd9eb62ee9a6e84ec159bd48c28235bbb0f8e4 \\\n    --hash=sha256:3c1104d3c036fb81ab923f507536daedc718d0ad5a8707c6061cdfd6d184e570 \\\n    --hash=sha256:4719d5aefb5189f50887773699eaf94e7d1e02bf36c1a9d353d9f46703758ca4 \\\n    --hash=sha256:4749e053a29364d3452c034827102ee100986903263e89884922ef01a0a6fd2f \\\n    --hash=sha256:5342cf6aad47943286afa6f1609cad9b4266a05e7f2ec408e2cf7aea7ff69d80 \\\n    --hash=sha256:56e48aec79ae238f6e4395886b5eaed058abb7231fb3361ddd7bfdf4eed54289 \\\n    --hash=sha256:76e3f4e85fc5d4fd311f6e9b794d0c00e7002ec122be271f2019d63376f1d385 \\\n    --hash=sha256:7776ea65423ca6a15255ba1872d82d207bd1e09f6d0894ee4a64678dd2204078 \\\n    --hash=sha256:784c6da1a07818491b0ffd63c6bbe5a33deaa0e25a20e1b3ea20cf0e43f8046c \\\n    --hash=sha256:8535303847b89aa6b0f00aa1dc62867b5a32923e4d1681a35b5eef2d9591a463 \\\n    --hash=sha256:9a7721ec204d3a237225db3e194c25268faf92e19338a35f3a224469cb6039a3 \\\n    --hash=sha256:a1d3c026f57ceaad42f8231305d4653d5f05dc6332a730ae5c0bea3513de0950 \\\n    --hash=sha256:ab344f1bf21f140adab8e47fdbc7c35a477dc01408791f8ba00d018dd0bc5155 \\\n    --hash=sha256:ab5f23af8c16022663a652d3b25dcdc272ac3f83c3af4c02eb8b824e6b3ab9d7 \\\n    --hash=sha256:ae8d0be48d1b6ed82588934aaaa179875e7dc4f3d84da18d7eae6eb3f06c242c \\\n    --hash=sha256:c91c4afd8abc3908e00a44b2672718905b8611503f7ff87390cc0ac3423fb096 \\\n    --hash=sha256:d5036197ecae68d7f491fcdb4df90082b0d4960ca6599ba2659957aafced7c17 \\\n    --hash=sha256:d6cc757de514c00b24ae8cf5c876af2a7c3df189028d68c0cb4eaa9cd5afc2bf \\\n    --hash=sha256:d933fabd8f6a319e8530d0de4fcc2e6a61917e0b0c271fded460032db42a0fe4 \\\n    --hash=sha256:ea8282b9bcfe2b5e7d491d0bf7f3e2da29700cec05b49e64d6246923329f2b02 \\\n    --hash=sha256:ecde0f8adef7dfdec993fd54b0f78183051b6580f606111a6d789cd14c61ea0c \\\n    --hash=sha256:f21c442fdd2805e91799fbe044a7b999b8571bb0ab0f7850d0cb9641a687092b\nlit==17.0.6 \\\n    --hash=sha256:dfa9af9b55fc4509a56be7bf2346f079d7f4a242d583b9f2e0b078fd0abae31b\nml-dtypes==0.3.2 \\\n    --hash=sha256:2c34f2ba9660b21fe1034b608308a01be82bbef2a92fb8199f24dc6bad0d5226 \\\n    --hash=sha256:3a17ef2322e60858d93584e9c52a5be7dd6236b056b7fa1ec57f1bb6ba043e33 \\\n    --hash=sha256:533059bc5f1764fac071ef54598db358c167c51a718f68f5bb55e3dee79d2967 \\\n    --hash=sha256:6604877d567a29bfe7cc02969ae0f2425260e5335505cf5e7fefc3e5465f5655 \\\n    --hash=sha256:6b35c4e8ca957c877ac35c79ffa77724ecc3702a1e4b18b08306c03feae597bb \\\n    --hash=sha256:763697ab8a88d47443997a7cdf3aac7340049aed45f7521f6b0ec8a0594821fe \\\n    --hash=sha256:7a4c3fcbf86fa52d0204f07cfd23947ef05b4ad743a1a988e163caa34a201e5e \\\n    --hash=sha256:7afde548890a92b41c0fed3a6c525f1200a5727205f73dc21181a2726571bb53 \\\n    --hash=sha256:7ba8e1fafc7fff3e643f453bffa7d082df1678a73286ce8187d3e825e776eb94 \\\n    --hash=sha256:91f8783fd1f2c23fd3b9ee5ad66b785dafa58ba3cdb050c4458021fa4d1eb226 \\\n    --hash=sha256:93b78f53431c93953f7850bb1b925a17f0ab5d97527e38a7e865b5b4bc5cfc18 \\\n    --hash=sha256:961134ea44c7b8ca63eda902a44b58cd8bd670e21d62e255c81fba0a8e70d9b7 \\\n    --hash=sha256:b89b194e9501a92d289c1ffd411380baf5daafb9818109a4f49b0a1b6dce4462 \\\n    --hash=sha256:c7b3fb3d4f6b39bcd4f6c4b98f406291f0d681a895490ee29a0f95bab850d53c \\\n    --hash=sha256:d1a746fe5fb9cd974a91070174258f0be129c592b93f9ce7df6cc336416c3fbd \\\n    --hash=sha256:e8505946df1665db01332d885c2020b4cb9e84a8b1241eb4ba69d59591f65855 \\\n    --hash=sha256:f47619d978ab1ae7dfdc4052ea97c636c6263e1f19bd1be0e42c346b98d15ff4"
        },
        {
          "name": "third_party",
          "type": "tree",
          "content": null
        },
        {
          "name": "tools",
          "type": "tree",
          "content": null
        },
        {
          "name": "warnings.bazelrc",
          "type": "blob",
          "size": 4.2099609375,
          "content": "# This file is autogenerated! Do not edit!\n\n# Treat warnings as errors...\nbuild:warnings --copt=-Werror --host_copt=-Werror\n# ...and silence them outside of the workspace.\nbuild:warnings --per_file_copt=external/.*@-w\n# ...and silence them on host builds.\nbuild:warnings --host_per_file_copt=external/.*@-w\n\nbuild:warnings --copt=-Wall\nbuild:warnings --copt=-Werror\nbuild:warnings --copt=-Wno-address-of-packed-member\nbuild:warnings --copt=-Wno-defaulted-function-deleted\nbuild:warnings --copt=-Wno-enum-compare-switch\nbuild:warnings --copt=-Wno-expansion-to-defined\nbuild:warnings --copt=-Wno-ignored-attributes\nbuild:warnings --copt=-Wno-ignored-qualifiers\nbuild:warnings --copt=-Wno-inconsistent-missing-override\nbuild:warnings --copt=-Wno-potentially-evaluated-expression\nbuild:warnings --copt=-Wno-range-loop-analysis\nbuild:warnings --copt=-Wno-strict-prototypes\nbuild:warnings --copt=-Wno-tautological-type-limit-compare\nbuild:warnings --copt=-Wno-tautological-undefined-compare\nbuild:warnings --copt=-Wno-tautological-unsigned-zero-compare\nbuild:warnings --copt=-Wno-tautological-unsigned-enum-zero-compare\nbuild:warnings --copt=-Wno-undefined-func-template\nbuild:warnings --copt=-Wno-unused-but-set-variable\nbuild:warnings --copt=-Wno-unused-lambda-capture\nbuild:warnings --copt=-Wno-unused-local-typedef\nbuild:warnings --copt=-Wno-deprecated-builtins\nbuild:warnings --copt=-Wno-deprecated-volatile\nbuild:warnings --copt=-Wno-deprecated-anon-enum-enum-conversion\nbuild:warnings --copt=-Wno-deprecated-enum-compare\nbuild:warnings --copt=-Wno-deprecated-enum-enum-conversion\nbuild:warnings --copt=-Wno-deprecated-enum-compare-conditional\nbuild:warnings --copt=-Wno-deprecated-enum-float-conversion\nbuild:warnings --copt=-Wno-deprecated-this-capture\nbuild:warnings --copt=-Wno-return-type-c-linkage\nbuild:warnings --copt=-Wno-nullability-completeness\nbuild:warnings --copt=-Wno-bitfield-constant-conversion\nbuild:warnings --copt=-Wno-bitwise-instead-of-logical\nbuild:warnings --copt=-Wno-comment\nbuild:warnings --copt=-Wno-compound-token-split\nbuild:warnings --copt=-Wno-deprecated-non-prototype\nbuild:warnings --copt=-Wno-misleading-indentation\nbuild:warnings --copt=-Wno-psabi\nbuild:warnings --copt=-Wno-unqualified-std-cast-call\nbuild:warnings --copt=-Wno-deprecated-literal-operator\nbuild:warnings --copt=-Wno-nontrivial-memaccess\nbuild:warnings --copt=-Wno-ambiguous-member-template\nbuild:warnings --copt=-Wno-char-subscripts\nbuild:warnings --copt=-Wno-deprecated-declarations\nbuild:warnings --copt=-Wno-deprecated-pragma\nbuild:warnings --copt=-Wno-extern-c-compat\nbuild:warnings --copt=-Wno-gnu-alignof-expression\nbuild:warnings --copt=-Wno-gnu-variable-sized-type-not-at-end\nbuild:warnings --copt=-Wno-implicit-int-float-conversion\nbuild:warnings --copt=-Wno-invalid-source-encoding\nbuild:warnings --copt=-Wno-mismatched-tags\nbuild:warnings --copt=-Wno-pointer-sign\nbuild:warnings --copt=-Wno-private-header\nbuild:warnings --copt=-Wno-sign-compare\nbuild:warnings --copt=-Wno-strict-overflow\nbuild:warnings --copt=-Wno-unknown-pragmas\nbuild:warnings --copt=-Wno-unused-command-line-argument\nbuild:warnings --copt=-Wno-unused-const-variable\nbuild:warnings --copt=-Wno-unused-function\nbuild:warnings --copt=-Wno-unused-private-field\nbuild:warnings --copt=-Wno-user-defined-warnings\nbuild:warnings --copt=-Wfloat-overflow-conversion\nbuild:warnings --copt=-Wfloat-zero-conversion\nbuild:warnings --copt=-Wfor-loop-analysis\nbuild:warnings --copt=-Wgnu-redeclared-enum\nbuild:warnings --copt=-Winfinite-recursion\nbuild:warnings --copt=-Wself-assign\nbuild:warnings --copt=-Wno-self-assign-overloaded\nbuild:warnings --copt=-Wstring-conversion\nbuild:warnings --copt=-Wtautological-overlap-compare\nbuild:warnings --copt=-Wunused-but-set-parameter\nbuild:warnings --copt=-Wunused-comparison\nbuild:warnings --copt=-Wvla\nbuild:warnings --copt=-Wctad-maybe-unsupported\nbuild:warnings --copt=-Wthread-safety-beta\nbuild:warnings --copt=-Wno-trigraphs\nbuild:warnings --copt=-Woverloaded-virtual\nbuild:warnings --copt=-Wno-invalid-offsetof\nbuild:warnings --copt=-Wno-final-dtor-non-final-class\nbuild:warnings --copt=-Wnon-virtual-dtor\nbuild:warnings --copt=-Wimplicit-fallthrough\nbuild:warnings --copt=-Wthread-safety-analysis\nbuild:warnings --copt=-Wno-builtin-macro-redefined\nbuild:warnings --copt=-Wno-macro-redefined\n"
        },
        {
          "name": "workspace0.bzl",
          "type": "blob",
          "size": 4.9658203125,
          "content": "\"\"\"TensorFlow workspace initialization. Consult the WORKSPACE on how to use it.\"\"\"\n\nload(\"@bazel_toolchains//repositories:repositories.bzl\", bazel_toolchains_repositories = \"repositories\")\nload(\"@bazel_tools//tools/build_defs/repo:http.bzl\", \"http_archive\")\nload(\"@build_bazel_apple_support//lib:repositories.bzl\", \"apple_support_dependencies\")\nload(\"@build_bazel_rules_apple//apple:repositories.bzl\", \"apple_rules_dependencies\")\nload(\"@build_bazel_rules_swift//swift:repositories.bzl\", \"swift_rules_dependencies\")\nload(\"@com_google_benchmark//:bazel/benchmark_deps.bzl\", \"benchmark_deps\")\nload(\"@tsl//:workspace0.bzl\", \"tsl_workspace0\")\n\ndef _tf_bind():\n    \"\"\"Bind targets for some external repositories\"\"\"\n    ##############################################################################\n    # BIND DEFINITIONS\n    #\n    # Please do not add bind() definitions unless we have no other choice.\n    # If that ends up being the case, please leave a comment explaining\n    # why we can't depend on the canonical build target.\n\n    # Needed by Protobuf\n    native.bind(\n        name = \"grpc_cpp_plugin\",\n        actual = \"@com_github_grpc_grpc//src/compiler:grpc_cpp_plugin\",\n    )\n    native.bind(\n        name = \"grpc_python_plugin\",\n        actual = \"@com_github_grpc_grpc//src/compiler:grpc_python_plugin\",\n    )\n\n    native.bind(\n        name = \"grpc_lib\",\n        actual = \"@com_github_grpc_grpc//:grpc++\",\n    )\n\n    native.bind(\n        name = \"grpc_lib_unsecure\",\n        actual = \"@com_github_grpc_grpc//:grpc++_unsecure\",\n    )\n\n    # Needed by Protobuf\n    native.bind(\n        name = \"python_headers\",\n        actual = str(Label(\"//third_party/python_runtime:headers\")),\n    )\n\n    # Needed by Protobuf\n    native.bind(\n        name = \"six\",\n        actual = \"@six_archive//:six\",\n    )\n\ndef workspace():\n    tsl_workspace0()\n\n    http_archive(\n        name = \"inception_v1\",\n        build_file = \"//:models.BUILD\",\n        sha256 = \"7efe12a8363f09bc24d7b7a450304a15655a57a7751929b2c1593a71183bb105\",\n        urls = [\n            \"https://storage.googleapis.com/download.tensorflow.org/models/inception_v1.zip\",\n        ],\n    )\n\n    http_archive(\n        name = \"mobile_ssd\",\n        build_file = \"//:models.BUILD\",\n        sha256 = \"bddd81ea5c80a97adfac1c9f770e6f55cbafd7cce4d3bbe15fbeb041e6b8f3e8\",\n        urls = [\n            \"https://storage.googleapis.com/download.tensorflow.org/models/object_detection/ssd_mobilenet_v1_android_export.zip\",\n        ],\n    )\n\n    http_archive(\n        name = \"mobile_multibox\",\n        build_file = \"//:models.BUILD\",\n        sha256 = \"859edcddf84dddb974c36c36cfc1f74555148e9c9213dedacf1d6b613ad52b96\",\n        urls = [\n            \"https://storage.googleapis.com/download.tensorflow.org/models/mobile_multibox_v1a.zip\",\n        ],\n    )\n\n    http_archive(\n        name = \"stylize\",\n        build_file = \"//:models.BUILD\",\n        sha256 = \"3d374a730aef330424a356a8d4f04d8a54277c425e274ecb7d9c83aa912c6bfa\",\n        urls = [\n            \"https://storage.googleapis.com/download.tensorflow.org/models/stylize_v1.zip\",\n        ],\n    )\n\n    http_archive(\n        name = \"speech_commands\",\n        build_file = \"//:models.BUILD\",\n        sha256 = \"c3ec4fea3158eb111f1d932336351edfe8bd515bb6e87aad4f25dbad0a600d0c\",\n        urls = [\n            \"https://storage.googleapis.com/download.tensorflow.org/models/speech_commands_v0.01.zip\",\n        ],\n    )\n\n    http_archive(\n        name = \"person_detect_data\",\n        sha256 = \"170542270da256994ce24d1e357f6e84a54fdaf7d28ff2b74725a40b70b082cf\",\n        urls = [\n            \"https://storage.googleapis.com/download.tensorflow.org/data/tf_lite_micro_person_data_grayscale_2020_05_24.zip\",\n        ],\n    )\n\n    bazel_toolchains_repositories()\n\n    # Apple rules for Bazel. https://github.com/bazelbuild/rules_apple.\n    # Note: We add this to fix Kokoro builds.\n    # The rules below call into `rules_proto` but the hash has changed and\n    # Bazel refuses to continue. So, we add our own mirror.\n    http_archive(\n        name = \"rules_proto\",\n        sha256 = \"20b240eba17a36be4b0b22635aca63053913d5c1ee36e16be36499d167a2f533\",\n        strip_prefix = \"rules_proto-11bf7c25e666dd7ddacbcd4d4c4a9de7a25175f8\",\n        urls = [\n            \"https://storage.googleapis.com/mirror.tensorflow.org/github.com/bazelbuild/rules_proto/archive/11bf7c25e666dd7ddacbcd4d4c4a9de7a25175f8.tar.gz\",\n            \"https://github.com/bazelbuild/rules_proto/archive/11bf7c25e666dd7ddacbcd4d4c4a9de7a25175f8.tar.gz\",\n        ],\n    )\n\n    # Now, finally use the rules\n    apple_rules_dependencies()\n    swift_rules_dependencies()\n    apple_support_dependencies()\n\n    # We only need `benchmark_deps` to be able to have bazel query to work and not complain about missing `@libpfm`.\n    benchmark_deps()\n\n    # If a target is bound twice, the later one wins, so we have to do tf bindings\n    # at the end of the WORKSPACE file.\n    _tf_bind()\n\n# Alias so it can be loaded without assigning to a different symbol to prevent\n# shadowing previous loads and trigger a buildifier warning.\nxla_workspace0 = workspace\n"
        },
        {
          "name": "workspace1.bzl",
          "type": "blob",
          "size": 1.3349609375,
          "content": "\"\"\"TensorFlow workspace initialization. Consult the WORKSPACE on how to use it.\"\"\"\n\nload(\"@bazel_tools//tools/build_defs/repo:http.bzl\", \"http_archive\")\nload(\"@com_github_grpc_grpc//bazel:grpc_deps.bzl\", \"grpc_deps\")\nload(\"@io_bazel_rules_closure//closure:defs.bzl\", \"closure_repositories\")\nload(\"@rules_pkg//:deps.bzl\", \"rules_pkg_dependencies\")\nload(\"@tsl//:workspace1.bzl\", \"tsl_workspace1\")\n\n# buildifier: disable=unnamed-macro\ndef workspace():\n    \"\"\"Loads a set of TensorFlow dependencies in a WORKSPACE file.\"\"\"\n    tsl_workspace1()\n\n    native.register_toolchains(\"@local_config_python//:py_toolchain\")\n    rules_pkg_dependencies()\n\n    closure_repositories()\n\n    http_archive(\n        name = \"bazel_toolchains\",\n        sha256 = \"294cdd859e57fcaf101d4301978c408c88683fbc46fbc1a3829da92afbea55fb\",\n        strip_prefix = \"bazel-toolchains-8c717f8258cd5f6c7a45b97d974292755852b658\",\n        urls = [\n            \"http://mirror.tensorflow.org/github.com/bazelbuild/bazel-toolchains/archive/8c717f8258cd5f6c7a45b97d974292755852b658.tar.gz\",\n            \"https://github.com/bazelbuild/bazel-toolchains/archive/8c717f8258cd5f6c7a45b97d974292755852b658.tar.gz\",\n        ],\n    )\n\n    grpc_deps()\n\n# Alias so it can be loaded without assigning to a different symbol to prevent\n# shadowing previous loads and trigger a buildifier warning.\nxla_workspace1 = workspace\n"
        },
        {
          "name": "workspace2.bzl",
          "type": "blob",
          "size": 7.8076171875,
          "content": "\"\"\"TensorFlow workspace initialization. Consult the WORKSPACE on how to use it.\"\"\"\n\n# Import third party config rules.\nload(\"@bazel_skylib//lib:versions.bzl\", \"versions\")\n\n# Import TSL Workspaces\nload(\"@tsl//:workspace2.bzl\", \"tsl_workspace2\")\nload(\"//third_party:repo.bzl\", \"tf_http_archive\", \"tf_mirror_urls\")\nload(\"//third_party/dlpack:workspace.bzl\", dlpack = \"repo\")\n\n# Import third party repository rules. See go/tfbr-thirdparty.\nload(\"//third_party/FP16:workspace.bzl\", FP16 = \"repo\")\nload(\"//third_party/gloo:workspace.bzl\", gloo = \"repo\")\nload(\"//third_party/mpitrampoline:workspace.bzl\", mpitrampoline = \"repo\")\nload(\"//third_party/nanobind:workspace.bzl\", nanobind = \"repo\")\nload(\"//third_party/robin_map:workspace.bzl\", robin_map = \"repo\")\nload(\"//third_party/shardy:workspace.bzl\", shardy = \"repo\")\nload(\"//third_party/stablehlo:workspace.bzl\", stablehlo = \"repo\")\nload(\"//third_party/triton:workspace.bzl\", triton = \"repo\")\nload(\"//third_party/uv:workspace.bzl\", uv = \"repo\")\n\ndef _initialize_third_party():\n    \"\"\" Load third party repositories.  See above load() statements. \"\"\"\n    FP16()\n    dlpack()\n    gloo()\n    mpitrampoline()\n    nanobind()\n    robin_map()\n    shardy()\n    stablehlo()\n    triton()\n    uv()\n\n# Define all external repositories required by TensorFlow\ndef _tf_repositories():\n    \"\"\"All external dependencies for TF builds.\"\"\"\n\n    # To update any of the dependencies below:\n    # a) update URL and strip_prefix to the new git commit hash\n    # b) get the sha256 hash of the commit by running:\n    #    curl -L <url> | sha256sum\n    # and update the sha256 with the result.\n\n    # LINT.IfChange\n    tf_http_archive(\n        name = \"XNNPACK\",\n        sha256 = \"3306f4178c8594b689165d385e644f03a3154c3be044f6ae36dd170fbf182cf5\",\n        strip_prefix = \"XNNPACK-983d013300f19fd3f4e33220b6401408e97a8d12\",\n        urls = tf_mirror_urls(\"https://github.com/google/XNNPACK/archive/983d013300f19fd3f4e33220b6401408e97a8d12.zip\"),\n    )\n    # LINT.ThenChange(//tensorflow/lite/tools/cmake/modules/xnnpack.cmake)\n\n    tf_http_archive(\n        name = \"KleidiAI\",\n        sha256 = \"ad37707084a6d4ff41be10cbe8540c75bea057ba79d0de6c367c1bfac6ba0852\",\n        strip_prefix = \"kleidiai-40a926833857fb64786e02f97703e42b1537cb57\",\n        urls = tf_mirror_urls(\"https://gitlab.arm.com/kleidi/kleidiai/-/archive/40a926833857fb64786e02f97703e42b1537cb57/kleidiai-40a926833857fb64786e02f97703e42b1537cb57.zip\"),\n    )\n\n    tf_http_archive(\n        name = \"FXdiv\",\n        sha256 = \"3d7b0e9c4c658a84376a1086126be02f9b7f753caa95e009d9ac38d11da444db\",\n        strip_prefix = \"FXdiv-63058eff77e11aa15bf531df5dd34395ec3017c8\",\n        urls = tf_mirror_urls(\"https://github.com/Maratyszcza/FXdiv/archive/63058eff77e11aa15bf531df5dd34395ec3017c8.zip\"),\n    )\n\n    tf_http_archive(\n        name = \"cpuinfo\",\n        sha256 = \"52e0ffd7998d8cb3a927d8a6e1145763744d866d2be09c4eccea27fc157b6bb0\",\n        strip_prefix = \"cpuinfo-cebb0933058d7f181c979afd50601dc311e1bf8c\",\n        urls = tf_mirror_urls(\"https://github.com/pytorch/cpuinfo/archive/cebb0933058d7f181c979afd50601dc311e1bf8c.zip\"),\n    )\n\n    tf_http_archive(\n        name = \"pthreadpool\",\n        sha256 = \"a4cf06de57bfdf8d7b537c61f1c3071bce74e57524fe053e0bbd2332feca7f95\",\n        strip_prefix = \"pthreadpool-4fe0e1e183925bf8cfa6aae24237e724a96479b8\",\n        urls = tf_mirror_urls(\"https://github.com/Maratyszcza/pthreadpool/archive/4fe0e1e183925bf8cfa6aae24237e724a96479b8.zip\"),\n    )\n\n    tf_http_archive(\n        name = \"jsoncpp_git\",\n        sha256 = \"f409856e5920c18d0c2fb85276e24ee607d2a09b5e7d5f0a371368903c275da2\",\n        strip_prefix = \"jsoncpp-1.9.5\",\n        system_build_file = \"//third_party/systemlibs:jsoncpp.BUILD\",\n        urls = tf_mirror_urls(\"https://github.com/open-source-parsers/jsoncpp/archive/1.9.5.tar.gz\"),\n    )\n\n    tf_http_archive(\n        name = \"cudnn_frontend_archive\",\n        build_file = \"//third_party:cudnn_frontend.BUILD\",\n        patch_file = [\"//third_party:cudnn_frontend_header_fix.patch\"],\n        sha256 = \"7be8afebc693f0ef75bbc673ce5c1cf422673e84ea7d53e488201756c046496e\",\n        strip_prefix = \"cudnn-frontend-1.9.0\",\n        urls = tf_mirror_urls(\"https://github.com/NVIDIA/cudnn-frontend/archive/refs/tags/v1.9.0.zip\"),\n    )\n\n    tf_http_archive(\n        name = \"cutlass_archive\",\n        build_file = \"//third_party:cutlass.BUILD\",\n        sha256 = \"84cf3fcc47c440a8dde016eb458f8d6b93b3335d9c3a7a16f388333823f1eae0\",\n        strip_prefix = \"cutlass-afa7b7241aabe598b725c65480bd9fa71121732c\",\n        urls = tf_mirror_urls(\"https://github.com/chsigg/cutlass/archive/afa7b7241aabe598b725c65480bd9fa71121732c.tar.gz\"),\n    )\n\n    tf_http_archive(\n        name = \"boringssl\",\n        sha256 = \"9dc53f851107eaf87b391136d13b815df97ec8f76dadb487b58b2fc45e624d2c\",\n        strip_prefix = \"boringssl-c00d7ca810e93780bd0c8ee4eea28f4f2ea4bcdc\",\n        system_build_file = \"//third_party/systemlibs:boringssl.BUILD\",\n        urls = tf_mirror_urls(\"https://github.com/google/boringssl/archive/c00d7ca810e93780bd0c8ee4eea28f4f2ea4bcdc.tar.gz\"),\n    )\n\n    tf_http_archive(\n        name = \"com_google_ortools\",\n        sha256 = \"bc4b07dc9c23f0cca43b1f5c889f08a59c8f2515836b03d4cc7e0f8f2c879234\",\n        strip_prefix = \"or-tools-9.6\",\n        patch_file = [\"//third_party/ortools:ortools.patch\"],\n        urls = tf_mirror_urls(\"https://github.com/google/or-tools/archive/v9.6.tar.gz\"),\n        repo_mapping = {\n            \"@com_google_protobuf_cc\": \"@com_google_protobuf\",\n            \"@eigen\": \"@eigen_archive\",\n        },\n    )\n\n    tf_http_archive(\n        name = \"glpk\",\n        sha256 = \"9a5dab356268b4f177c33e00ddf8164496dc2434e83bd1114147024df983a3bb\",\n        build_file = \"//third_party/ortools:glpk.BUILD\",\n        urls = [\n            \"https://storage.googleapis.com/mirror.tensorflow.org/ftp.gnu.org/gnu/glpk/glpk-4.52.tar.gz\",\n            \"http://ftp.gnu.org/gnu/glpk/glpk-4.52.tar.gz\",\n        ],\n    )\n\n    tf_http_archive(\n        name = \"scip\",\n        sha256 = \"fe7636f8165a8c9298ff55ed3220d084d4ea31ba9b69d2733beec53e0e4335d6\",\n        strip_prefix = \"scip-803\",\n        build_file = \"//third_party/ortools:scip.BUILD\",\n        patch_file = [\"//third_party/ortools:scip.patch\"],\n        urls = tf_mirror_urls(\"https://github.com/scipopt/scip/archive/refs/tags/v803.tar.gz\"),\n    )\n\n    tf_http_archive(\n        name = \"bliss\",\n        build_file = \"//third_party/ortools:bliss.BUILD\",\n        sha256 = \"f57bf32804140cad58b1240b804e0dbd68f7e6bf67eba8e0c0fa3a62fd7f0f84\",\n        urls = tf_mirror_urls(\"https://github.com/google/or-tools/releases/download/v9.0/bliss-0.73.zip\"),\n        #url = \"http://www.tcs.hut.fi/Software/bliss/bliss-0.73.zip\",\n    )\n\n    tf_http_archive(\n        name = \"pybind11_protobuf\",\n        urls = tf_mirror_urls(\"https://github.com/pybind/pybind11_protobuf/archive/80f3440cd8fee124e077e2e47a8a17b78b451363.zip\"),\n        sha256 = \"c7ab64b1ccf9a678694a89035a8c865a693e4e872803778f91f0965c2f281d78\",\n        strip_prefix = \"pybind11_protobuf-80f3440cd8fee124e077e2e47a8a17b78b451363\",\n    )\n\n# buildifier: disable=function-docstring\n# buildifier: disable=unnamed-macro\ndef workspace():\n    tsl_workspace2()\n\n    # Check the bazel version before executing any repository rules, in case\n    # those rules rely on the version we require here.\n    versions.check(\"1.0.0\")\n\n    # Import third party repositories according to go/tfbr-thirdparty.\n    _initialize_third_party()\n\n    # Import all other repositories. This should happen before initializing\n    # any external repositories, because those come with their own\n    # dependencies. Those recursive dependencies will only be imported if they\n    # don't already exist (at least if the external repository macros were\n    # written according to common practice to query native.existing_rule()).\n    _tf_repositories()\n\n# Alias so it can be loaded without assigning to a different symbol to prevent\n# shadowing previous loads and trigger a buildifier warning.\nxla_workspace2 = workspace\n"
        },
        {
          "name": "workspace3.bzl",
          "type": "blob",
          "size": 2.4697265625,
          "content": "\"\"\"TensorFlow workspace initialization. Consult the WORKSPACE on how to use it.\"\"\"\n\nload(\"@bazel_tools//tools/build_defs/repo:http.bzl\", \"http_archive\")\nload(\"@tsl//:workspace3.bzl\", \"tsl_workspace3\")\nload(\"//third_party/llvm:workspace.bzl\", llvm = \"repo\")\n\n# buildifier: disable=function-docstring\n# buildifier: disable=unnamed-macro\ndef workspace():\n    tsl_workspace3()\n\n    http_archive(\n        name = \"io_bazel_rules_closure\",\n        sha256 = \"5b00383d08dd71f28503736db0500b6fb4dda47489ff5fc6bed42557c07c6ba9\",\n        strip_prefix = \"rules_closure-308b05b2419edb5c8ee0471b67a40403df940149\",\n        urls = [\n            \"https://storage.googleapis.com/mirror.tensorflow.org/github.com/bazelbuild/rules_closure/archive/308b05b2419edb5c8ee0471b67a40403df940149.tar.gz\",\n            \"https://github.com/bazelbuild/rules_closure/archive/308b05b2419edb5c8ee0471b67a40403df940149.tar.gz\",  # 2019-06-13\n        ],\n    )\n\n    # https://github.com/bazelbuild/bazel-skylib/releases\n    http_archive(\n        name = \"bazel_skylib\",\n        sha256 = \"74d544d96f4a5bb630d465ca8bbcfe231e3594e5aae57e1edbf17a6eb3ca2506\",\n        urls = [\n            \"https://storage.googleapis.com/mirror.tensorflow.org/github.com/bazelbuild/bazel-skylib/releases/download/1.3.0/bazel-skylib-1.3.0.tar.gz\",\n            \"https://github.com/bazelbuild/bazel-skylib/releases/download/1.3.0/bazel-skylib-1.3.0.tar.gz\",\n        ],\n    )\n\n    http_archive(\n        name = \"rules_pkg\",\n        urls = [\n            \"https://mirror.bazel.build/github.com/bazelbuild/rules_pkg/releases/download/0.7.1/rules_pkg-0.7.1.tar.gz\",\n            \"https://github.com/bazelbuild/rules_pkg/releases/download/0.7.1/rules_pkg-0.7.1.tar.gz\",\n        ],\n        sha256 = \"451e08a4d78988c06fa3f9306ec813b836b1d076d0f055595444ba4ff22b867f\",\n    )\n\n    # Maven dependencies.\n    RULES_JVM_EXTERNAL_TAG = \"4.3\"\n    http_archive(\n        name = \"rules_jvm_external\",\n        strip_prefix = \"rules_jvm_external-%s\" % RULES_JVM_EXTERNAL_TAG,\n        sha256 = \"6274687f6fc5783b589f56a2f1ed60de3ce1f99bc4e8f9edef3de43bdf7c6e74\",\n        url = \"https://github.com/bazelbuild/rules_jvm_external/archive/%s.zip\" % RULES_JVM_EXTERNAL_TAG,\n    )\n\n    # Load the raw llvm-project.  llvm does not have build rules set up by default,\n    # but provides a script for setting up build rules via overlays.\n    llvm(\"llvm-raw\")\n\n# Alias so it can be loaded without assigning to a different symbol to prevent\n# shadowing previous loads and trigger a buildifier warning.\nxla_workspace3 = workspace\n"
        },
        {
          "name": "workspace4.bzl",
          "type": "blob",
          "size": 0.4609375,
          "content": "\"\"\"TensorFlow workspace initialization. Consult the WORKSPACE on how to use it.\"\"\"\n\nload(\"//third_party:repo.bzl\", \"tf_vendored\")\n\n# buildifier: disable=function-docstring\n# buildifier: disable=unnamed-macro\ndef workspace():\n    # Declares @tsl\n    tf_vendored(name = \"tsl\", relpath = \"third_party/tsl\")\n\n# Alias so it can be loaded without assigning to a different symbol to prevent\n# shadowing previous loads and trigger a buildifier warning.\nxla_workspace4 = workspace\n"
        },
        {
          "name": "xla",
          "type": "tree",
          "content": null
        }
      ]
    }
  ]
}