{
  "metadata": {
    "timestamp": 1736565502675,
    "page": 369,
    "hasNextPage": true,
    "endCursor": "Y3Vyc29yOjM3MA==",
    "completionStatus": "IN_PROGRESS"
  },
  "repositories": [
    {
      "nameWithOwner": "facebook/wangle",
      "stars": 3059,
      "defaultBranch": "main",
      "files": [
        {
          "name": ".buckconfig.d",
          "type": "tree",
          "content": null
        },
        {
          "name": ".github",
          "type": "tree",
          "content": null
        },
        {
          "name": "CONTRIBUTING.md",
          "type": "blob",
          "size": 1.466796875,
          "content": "# Contributing to wangle\nWe want to make contributing to this project as easy and transparent as\npossible.\n\n## Our Development Process\nExternal pull requests are first applied to facebook's internal\nbranch, then synced with wangle github repository.\n\n## Pull Requests\nWe actively welcome your pull requests.\n1. Fork the repo and create your branch from `master`.\n2. If you've added code that should be tested, add tests\n3. If you've changed APIs, update the documentation.\n4. Ensure the test suite passes.\n5. Make sure your code lints.\n6. If you haven't already, complete the Contributor License Agreement (\"CLA\").\n\n## Contributor License Agreement (\"CLA\")\nIn order to accept your pull request, we need you to submit a CLA. You only need\nto do this once to work on any of Facebook's open source projects.\n\nComplete your CLA here: <https://developers.facebook.com/opensource/cla>\n\n## Issues\nWe use GitHub issues to track public bugs. Please ensure your description is\nclear and has sufficient instructions to be able to reproduce the issue.\n\nFacebook has a [bounty program](https://www.facebook.com/whitehat/) for the safe\ndisclosure of security bugs. In those cases, please go through the process\noutlined on that page and do not file a public issue.\n\n## Coding Style\n* 80 character line length\n* 2 spaces for indentation rather than tabs\n* Match existing style as much as possible\n\n## License\nBy contributing to wangle, you agree that your contributions will be licensed\nunder its Apache 2.0 license.\n"
        },
        {
          "name": "LICENSE",
          "type": "blob",
          "size": 9.935546875,
          "content": "\n                                 Apache License\n                           Version 2.0, January 2004\n                        http://www.apache.org/licenses/\n\n   TERMS AND CONDITIONS FOR USE, REPRODUCTION, AND DISTRIBUTION\n\n   1. Definitions.\n\n      \"License\" shall mean the terms and conditions for use, reproduction,\n      and distribution as defined by Sections 1 through 9 of this document.\n\n      \"Licensor\" shall mean the copyright owner or entity authorized by\n      the copyright owner that is granting the License.\n\n      \"Legal Entity\" shall mean the union of the acting entity and all\n      other entities that control, are controlled by, or are under common\n      control with that entity. For the purposes of this definition,\n      \"control\" means (i) the power, direct or indirect, to cause the\n      direction or management of such entity, whether by contract or\n      otherwise, or (ii) ownership of fifty percent (50%) or more of the\n      outstanding shares, or (iii) beneficial ownership of such entity.\n\n      \"You\" (or \"Your\") shall mean an individual or Legal Entity\n      exercising permissions granted by this License.\n\n      \"Source\" form shall mean the preferred form for making modifications,\n      including but not limited to software source code, documentation\n      source, and configuration files.\n\n      \"Object\" form shall mean any form resulting from mechanical\n      transformation or translation of a Source form, including but\n      not limited to compiled object code, generated documentation,\n      and conversions to other media types.\n\n      \"Work\" shall mean the work of authorship, whether in Source or\n      Object form, made available under the License, as indicated by a\n      copyright notice that is included in or attached to the work\n      (an example is provided in the Appendix below).\n\n      \"Derivative Works\" shall mean any work, whether in Source or Object\n      form, that is based on (or derived from) the Work and for which the\n      editorial revisions, annotations, elaborations, or other modifications\n      represent, as a whole, an original work of authorship. For the purposes\n      of this License, Derivative Works shall not include works that remain\n      separable from, or merely link (or bind by name) to the interfaces of,\n      the Work and Derivative Works thereof.\n\n      \"Contribution\" shall mean any work of authorship, including\n      the original version of the Work and any modifications or additions\n      to that Work or Derivative Works thereof, that is intentionally\n      submitted to Licensor for inclusion in the Work by the copyright owner\n      or by an individual or Legal Entity authorized to submit on behalf of\n      the copyright owner. For the purposes of this definition, \"submitted\"\n      means any form of electronic, verbal, or written communication sent\n      to the Licensor or its representatives, including but not limited to\n      communication on electronic mailing lists, source code control systems,\n      and issue tracking systems that are managed by, or on behalf of, the\n      Licensor for the purpose of discussing and improving the Work, but\n      excluding communication that is conspicuously marked or otherwise\n      designated in writing by the copyright owner as \"Not a Contribution.\"\n\n      \"Contributor\" shall mean Licensor and any individual or Legal Entity\n      on behalf of whom a Contribution has been received by Licensor and\n      subsequently incorporated within the Work.\n\n   2. Grant of Copyright License. Subject to the terms and conditions of\n      this License, each Contributor hereby grants to You a perpetual,\n      worldwide, non-exclusive, no-charge, royalty-free, irrevocable\n      copyright license to reproduce, prepare Derivative Works of,\n      publicly display, publicly perform, sublicense, and distribute the\n      Work and such Derivative Works in Source or Object form.\n\n   3. Grant of Patent License. Subject to the terms and conditions of\n      this License, each Contributor hereby grants to You a perpetual,\n      worldwide, non-exclusive, no-charge, royalty-free, irrevocable\n      (except as stated in this section) patent license to make, have made,\n      use, offer to sell, sell, import, and otherwise transfer the Work,\n      where such license applies only to those patent claims licensable\n      by such Contributor that are necessarily infringed by their\n      Contribution(s) alone or by combination of their Contribution(s)\n      with the Work to which such Contribution(s) was submitted. If You\n      institute patent litigation against any entity (including a\n      cross-claim or counterclaim in a lawsuit) alleging that the Work\n      or a Contribution incorporated within the Work constitutes direct\n      or contributory patent infringement, then any patent licenses\n      granted to You under this License for that Work shall terminate\n      as of the date such litigation is filed.\n\n   4. Redistribution. You may reproduce and distribute copies of the\n      Work or Derivative Works thereof in any medium, with or without\n      modifications, and in Source or Object form, provided that You\n      meet the following conditions:\n\n      (a) You must give any other recipients of the Work or\n          Derivative Works a copy of this License; and\n\n      (b) You must cause any modified files to carry prominent notices\n          stating that You changed the files; and\n\n      (c) You must retain, in the Source form of any Derivative Works\n          that You distribute, all copyright, patent, trademark, and\n          attribution notices from the Source form of the Work,\n          excluding those notices that do not pertain to any part of\n          the Derivative Works; and\n\n      (d) If the Work includes a \"NOTICE\" text file as part of its\n          distribution, then any Derivative Works that You distribute must\n          include a readable copy of the attribution notices contained\n          within such NOTICE file, excluding those notices that do not\n          pertain to any part of the Derivative Works, in at least one\n          of the following places: within a NOTICE text file distributed\n          as part of the Derivative Works; within the Source form or\n          documentation, if provided along with the Derivative Works; or,\n          within a display generated by the Derivative Works, if and\n          wherever such third-party notices normally appear. The contents\n          of the NOTICE file are for informational purposes only and\n          do not modify the License. You may add Your own attribution\n          notices within Derivative Works that You distribute, alongside\n          or as an addendum to the NOTICE text from the Work, provided\n          that such additional attribution notices cannot be construed\n          as modifying the License.\n\n      You may add Your own copyright statement to Your modifications and\n      may provide additional or different license terms and conditions\n      for use, reproduction, or distribution of Your modifications, or\n      for any such Derivative Works as a whole, provided Your use,\n      reproduction, and distribution of the Work otherwise complies with\n      the conditions stated in this License.\n\n   5. Submission of Contributions. Unless You explicitly state otherwise,\n      any Contribution intentionally submitted for inclusion in the Work\n      by You to the Licensor shall be under the terms and conditions of\n      this License, without any additional terms or conditions.\n      Notwithstanding the above, nothing herein shall supersede or modify\n      the terms of any separate license agreement you may have executed\n      with Licensor regarding such Contributions.\n\n   6. Trademarks. This License does not grant permission to use the trade\n      names, trademarks, service marks, or product names of the Licensor,\n      except as required for reasonable and customary use in describing the\n      origin of the Work and reproducing the content of the NOTICE file.\n\n   7. Disclaimer of Warranty. Unless required by applicable law or\n      agreed to in writing, Licensor provides the Work (and each\n      Contributor provides its Contributions) on an \"AS IS\" BASIS,\n      WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or\n      implied, including, without limitation, any warranties or conditions\n      of TITLE, NON-INFRINGEMENT, MERCHANTABILITY, or FITNESS FOR A\n      PARTICULAR PURPOSE. You are solely responsible for determining the\n      appropriateness of using or redistributing the Work and assume any\n      risks associated with Your exercise of permissions under this License.\n\n   8. Limitation of Liability. In no event and under no legal theory,\n      whether in tort (including negligence), contract, or otherwise,\n      unless required by applicable law (such as deliberate and grossly\n      negligent acts) or agreed to in writing, shall any Contributor be\n      liable to You for damages, including any direct, indirect, special,\n      incidental, or consequential damages of any character arising as a\n      result of this License or out of the use or inability to use the\n      Work (including but not limited to damages for loss of goodwill,\n      work stoppage, computer failure or malfunction, or any and all\n      other commercial damages or losses), even if such Contributor\n      has been advised of the possibility of such damages.\n\n   9. Accepting Warranty or Additional Liability. While redistributing\n      the Work or Derivative Works thereof, You may choose to offer,\n      and charge a fee for, acceptance of support, warranty, indemnity,\n      or other liability obligations and/or rights consistent with this\n      License. However, in accepting such obligations, You may act only\n      on Your own behalf and on Your sole responsibility, not on behalf\n      of any other Contributor, and only if You agree to indemnify,\n      defend, and hold each Contributor harmless for any liability\n      incurred by, or claims asserted against, such Contributor by reason\n      of your accepting any such warranty or additional liability.\n\n   END OF TERMS AND CONDITIONS\n"
        },
        {
          "name": "README.md",
          "type": "blob",
          "size": 22.041015625,
          "content": "[![Support Ukraine](https://img.shields.io/badge/Support-Ukraine-FFD500?style=flat&labelColor=005BBB)](https://opensource.fb.com/support-ukraine) [![Travis Build Status](https://api.travis-ci.com/facebook/wangle.svg?branch=master)](https://travis-ci.com/facebook/wangle)\n[![CI Status](https://github.com/facebook/wangle/workflows/CI/badge.svg?branch=master)](https://github.com/facebook/wangle/actions?workflow=CI)\n<section class=\"dex_guide\"><h1 class=\"dex_title\">Wangle</h1><section class=\"dex_document\"><h1></h1><p class=\"dex_introduction\">C++ networking library</p><p>Wangle is a library that makes it easy to build protocols, application clients, and application servers.</p>\n\n<p>It&#039;s like Netty + Finagle smooshed together, but in C++</p>\n\n## Building and Installing\n\nThe main dependencies are:\n* The folly library from https://github.com/facebook/folly\n* The fizz library from https://github.com/facebookincubator/fizz\n* CMake\n* OpenSSL, at least version 1.0.2+, preferably with TLS extension support.\n\nOnce folly is installed, run the following inside the wangle directory to build, test, and install wangle:\n```\ncmake .\nmake\nctest\nsudo make install\n```\n\n## Tutorial\n\nThere is a tutorial [here](tutorial.md) that explains the basics of Wangle and shows how to build an echo server/client.\n\n## Examples\n\nSee the examples/ directory for some example Wangle servers and clients\n\n## License\nWangle is Apache 2.0-licensed.\n\n## Contributing\nSee the CONTRIBUTING file for how to help out.\n\n## Documentation\n\n<p>Wangle interfaces are asynchronous.  Interfaces are currently based on <a href=\"https://github.com/facebook/folly/tree/master/folly/futures\">Futures</a>, but we&#039;re also exploring how to support fibers</p>\n\n<h2 id=\"client-server-abstractio\">Client / Server abstraction <a href=\"#client-server-abstractio\" class=\"headerLink\">#</a></h2>\n\n<p>You&#039;re probably familiar with Java&#039;s Netty, or Python&#039;s twisted, or similar libraries.</p>\n\n<p>It is built on top of folly/async/io, so it&#039;s one level up the stack from that (or similar abstractions like boost::asio)</p>\n\n<p>ServerBootstrap - easily manage creation of threadpools and pipelines</p>\n\n<p>ClientBootstrap - the same for clients</p>\n\n<p>Pipeline - set up a series of handlers that modify your socket data</p>\n\n<h2 id=\"request-response-abstrac\">Request / Response abstraction <a href=\"#request-response-abstrac\" class=\"headerLink\">#</a></h2>\n\n<p>This is roughly equivalent to the <a href=\"https://twitter.github.io/finagle/\" target=\"_blank\">Finagle</a> library.</p>\n\n<p>Aims to provide easy testing, load balancing, client pooling, retry logic, etc.  for any request/response type service - i.e. thrift, http, etc.</p>\n\n<p>Service - a matched interface between client/server.  A server will implement this interface, and a client will call in to it.  These are protocol-specific</p>\n\n<p>ServiceFilter - a generic filter on a service. Examples: stats, request timeouts, rate limiting</p>\n\n<p>ServiceFactory - A factory that creates client connections.  Any protocol specific setup code goes here</p>\n\n<p>ServiceFactoryFilter - Generic filters that control how connections are created.  Client examples: load balancing, pooling,  idle timeouts, markdowns, etc.</p></section><section class=\"dex_document\"><h1>ServerBootstrap</h1><p class=\"dex_introduction\">Easily create a new server</p><p>ServerBootstrap does the work to set up one or multiple acceptor threads, and one or multiple sets of IO threads.  The thread pools can be the same.  SO_REUSEPORT is automatically supported for multiple accept threads. tcp is most common, although udp is also supported.</p>\n\n<h2 id=\"methods\">Methods <a href=\"#methods\" class=\"headerLink\">#</a></h2>\n\n<p><strong>childPipeline(PipelineFactory&lt;Pipeline&gt;)</strong></p>\n\n<p>Sets the pipeline factory for each new connection.  One pipeline per connection will be created.</p>\n\n<p><strong>group(IOThreadPoolExecutor accept, IOThreadPoolExecutor io)</strong></p>\n\n<p>Sets the thread pools for accept and io thread pools.  If more than one thread is in the accept group, SO_REUSEPORT is used.  Defaults to a single accept thread, and one io thread per core.</p>\n\n<p><strong>bind(SocketAddress),bind(port)</strong></p>\n\n<p>Binds to a port. Automatically starts to accept after bind.</p>\n\n<p><strong>stop()</strong></p>\n\n<p>Stops listening on all sockets.</p>\n\n<p><strong>join()</strong></p>\n\n<p>Joins all threadpools - all current reads and writes will be completed before this method returns.</p>\n\n<div class=\"remarkup-note\"><span class=\"remarkup-note-word\">NOTE:</span> however that both accept and io thread pools will be stopped using this method, so the thread pools can&#039;t be shared, or care must be taken using shared pools during shutdown.</div>\n\n<p><strong>waitForStop()</strong></p>\n\n<p>Waits for stop() to be called from another thread.</p>\n\n<h2 id=\"other-methods\">Other methods <a href=\"#other-methods\" class=\"headerLink\">#</a></h2>\n\n<p><strong>channelFactory(ServerSocketFactory)</strong></p>\n\n<p>Sets up the type of server.  Defaults to TCP AsyncServerSocket, but AsyncUDPServerSocket is also supported to receive udp messages.  In practice, ServerBootstrap is only useful for udp if you need to multiplex the messages across many threads, or have TCP connections going on at the same time, etc.  Simple usages of AsyncUDPSocket probably don&#039;t need the complexity of ServerBootstrap.</p>\n\n<p><strong>pipeline(PipelineFactory&lt;AcceptPipeline&gt;)</strong></p>\n\n<p>This pipeline method is used to get the accepted socket (or udp message) <strong>before</strong> it has been handed off to an IO thread.  This can be used to steer the accept thread to a particular thread, or for logging.</p>\n\n<p>See also AcceptRoutingHandler and RoutingDataHandler for additional help in reading data off of the accepted socket <strong>before</strong> it gets attached to an IO thread.  These can be used to hash incoming sockets to specific threads.</p>\n\n<p><strong>childHandler(AcceptorFactory)</strong></p>\n\n<p>Previously facebook had lots of code that used AcceptorFactories instead of Pipelines, this is a method to support this code and be backwards compatible.  The AcceptorFactory is responsible for creating acceptors, setting up pipelines, setting up AsyncSocket read callbacks, etc.</p>\n\n<h2 id=\"examples\">Examples <a href=\"#examples\" class=\"headerLink\">#</a></h2>\n\n<p>A simple example:</p>\n\n<div class=\"remarkup-code-block\" data-code-lang=\"php\"><pre class=\"remarkup-code\"><span class=\"no\">ServerBootstrap</span><span class=\"o\">&lt;</span><span class=\"no\">TelnetPipeline</span><span class=\"o\">&gt;</span> <span class=\"no\">server</span><span class=\"o\">;</span>                                                                                                      \n<span class=\"no\">server</span><span class=\"o\">.</span><span class=\"nf\" data-symbol-name=\"childPipeline\">childPipeline</span><span class=\"o\">(</span><span class=\"nc\" data-symbol-name=\"std\">std</span><span class=\"o\">::</span><span class=\"na\" data-symbol-context=\"std\" data-symbol-name=\"make_shared\">make_shared</span><span class=\"o\">&lt;</span><span class=\"no\">TelnetPipelineFactory</span><span class=\"o\">&gt;());</span>                                                                             \n<span class=\"no\">server</span><span class=\"o\">.</span><span class=\"nf\" data-symbol-name=\"bind\">bind</span><span class=\"o\">(</span><span class=\"no\">FLAGS_port</span><span class=\"o\">);</span>                                                                                                                     \n<span class=\"no\">server</span><span class=\"o\">.</span><span class=\"nf\" data-symbol-name=\"waitForStop\">waitForStop</span><span class=\"o\">();</span></pre></div></section><section class=\"dex_document\"><h1>ClientBootstrap</h1><p class=\"dex_introduction\">Create clients easily</p><p>ClientBootstrap is a thin wrapper around AsyncSocket that provides a future interface to the connect callback, and a Pipeline interface to the read callback.</p>\n\n<h2 id=\"methods\">Methods <a href=\"#methods\" class=\"headerLink\">#</a></h2>\n\n<p><strong>group(IOThreadPoolExecutor)</strong></p>\n\n<p>Sets the thread or group of threads where the IO will take place.  Callbacks are also made on this thread.</p>\n\n<p><strong>bind(port)</strong></p>\n\n<p>Optionally bind to a specific port</p>\n\n<p><strong>Future&lt;Pipeline*&gt; connect(SocketAddress)</strong></p>\n\n<p>Connect to the selected address.  When the future is complete, the initialized pipeline will be returned.</p>\n\n<div class=\"remarkup-note\"><span class=\"remarkup-note-word\">NOTE:</span> future.cancel() can be called to cancel an outstanding connection attempt.</div>\n\n<p><strong>pipelineFactory(PipelineFactory&lt;Pipeline&gt;)</strong></p>\n\n<p>Set the pipeline factory to use after a connection is successful.</p>\n\n<h2 id=\"example\">Example <a href=\"#example\" class=\"headerLink\">#</a></h2>\n\n<div class=\"remarkup-code-block\" data-code-lang=\"php\"><pre class=\"remarkup-code\"><span class=\"no\">ClientBootstrap</span><span class=\"o\">&lt;</span><span class=\"no\">TelnetPipeline</span><span class=\"o\">&gt;</span> <span class=\"no\">client</span><span class=\"o\">;</span>\n<span class=\"no\">client</span><span class=\"o\">.</span><span class=\"nf\" data-symbol-name=\"group\">group</span><span class=\"o\">(</span><span class=\"nc\" data-symbol-name=\"std\">std</span><span class=\"o\">::</span><span class=\"na\" data-symbol-context=\"std\" data-symbol-name=\"make_shared\">make_shared</span><span class=\"o\">&lt;</span><span class=\"nc\" data-symbol-name=\"folly\">folly</span><span class=\"o\">::</span><span class=\"na\" data-symbol-context=\"folly\" data-symbol-name=\"wangle\">wangle</span><span class=\"o\">::</span><span class=\"na\" data-symbol-name=\"IOThreadPoolExecutor\">IOThreadPoolExecutor</span><span class=\"o\">&gt;(</span><span class=\"mi\">1</span><span class=\"o\">));</span>\n<span class=\"no\">client</span><span class=\"o\">.</span><span class=\"nf\" data-symbol-name=\"pipelineFactory\">pipelineFactory</span><span class=\"o\">(</span><span class=\"nc\" data-symbol-name=\"std\">std</span><span class=\"o\">::</span><span class=\"na\" data-symbol-context=\"std\" data-symbol-name=\"make_shared\">make_shared</span><span class=\"o\">&lt;</span><span class=\"no\">TelnetPipelineFactory</span><span class=\"o\">&gt;());</span>\n<span class=\"c\">// synchronously wait for the connect to finish</span>\n<span class=\"no\">auto</span> <span class=\"no\">pipeline</span> <span class=\"o\">=</span> <span class=\"no\">client</span><span class=\"o\">.</span><span class=\"nf\" data-symbol-name=\"connect\">connect</span><span class=\"o\">(</span><span class=\"nf\" data-symbol-name=\"SocketAddress\">SocketAddress</span><span class=\"o\">(</span><span class=\"no\">FLAGS_host</span><span class=\"o\">,</span><span class=\"no\">FLAGS_port</span><span class=\"o\">)).</span><span class=\"nf\" data-symbol-name=\"get\">get</span><span class=\"o\">();</span>\n\n<span class=\"c\">// close the pipeline when finished</span>\n<span class=\"no\">pipeline</span><span class=\"o\">-&gt;</span><span class=\"na\" data-symbol-name=\"close\">close</span><span class=\"o\">();</span></pre></div></section><section class=\"dex_document\"><h1>Pipeline</h1><p class=\"dex_introduction\">Send your socket data through a series of tubes</p><p>A Pipeline is a series of Handlers that intercept inbound or outbound events, giving full control over how events are handled.  Handlers can be added dynamically to the pipeline.</p>\n\n<p>When events are called, a Context* object is passed to the Handler - this means state can be stored in the context object, and a single instantiation of any individual Handler can be used for the entire program.</p>\n\n<p>Netty&#039;s documentation: <a href=\"http://netty.io/4.0/api/io/netty/channel/ChannelPipeline.html\" target=\"_blank\">ChannelHandler</a></p>\n\n<p>Usually, the bottom of the Pipeline is a wangle::AsyncSocketHandler to read/write to a socket, but this isn&#039;t a requirement.</p>\n\n<p>A pipeline is templated on the input and output types:</p>\n\n<div class=\"remarkup-code-block\" data-code-lang=\"php\"><pre class=\"remarkup-code\"><span class=\"no\">EventBase</span> <span class=\"no\">base_</span><span class=\"o\">;</span>\n<span class=\"no\">Pipeline</span><span class=\"o\">&lt;</span><span class=\"no\">IOBufQueue</span><span class=\"o\">&amp;,</span> <span class=\"nc\" data-symbol-name=\"std\">std</span><span class=\"o\">::</span><span class=\"na\" data-symbol-context=\"std\" data-symbol-name=\"unique_ptr\">unique_ptr</span><span class=\"o\">&lt;</span><span class=\"no\">IOBuf</span><span class=\"o\">&gt;&gt;</span> <span class=\"no\">pipeline</span><span class=\"o\">;</span>\n<span class=\"no\">pipeline</span><span class=\"o\">.</span><span class=\"nf\" data-symbol-name=\"addBack\">addBack</span><span class=\"o\">(</span><span class=\"nf\" data-symbol-name=\"AsyncSocketHandler\">AsyncSocketHandler</span><span class=\"o\">(</span><span class=\"nc\" data-symbol-name=\"AsyncSocket\">AsyncSocket</span><span class=\"o\">::</span><span class=\"nf\" data-symbol-context=\"AsyncSocket\" data-symbol-name=\"newSocket\">newSocket</span><span class=\"o\">(</span><span class=\"no\">eventBase</span><span class=\"o\">)));</span></pre></div>\n\n<p>The above creates a pipeline and adds a single AsyncSocket handler, that will push read events through the pipeline when the socket gets bytes.  Let&#039;s try handling some socket events:</p>\n\n<div class=\"remarkup-code-block\" data-code-lang=\"php\"><pre class=\"remarkup-code\"><span class=\"k\">class</span> <span class=\"no\">MyHandler</span> <span class=\"o\">:</span> <span class=\"k\">public</span> <span class=\"no\">InboundHandler</span><span class=\"o\">&lt;</span><span class=\"nc\" data-symbol-name=\"folly\">folly</span><span class=\"o\">::</span><span class=\"na\" data-symbol-context=\"folly\" data-symbol-name=\"IOBufQueue\">IOBufQueue</span><span class=\"o\">&amp;&gt;</span> <span class=\"o\">&#123;</span>\n <span class=\"k\">public</span><span class=\"o\">:</span>\n\n  <span class=\"no\">void</span> <span class=\"nf\" data-symbol-name=\"read\">read</span><span class=\"o\">(</span><span class=\"no\">Context</span><span class=\"o\">*</span> <span class=\"no\">ctx</span><span class=\"o\">,</span> <span class=\"nc\" data-symbol-name=\"folly\">folly</span><span class=\"o\">::</span><span class=\"na\" data-symbol-context=\"folly\" data-symbol-name=\"IOBufQueue\">IOBufQueue</span><span class=\"o\">&amp;</span> <span class=\"no\">q</span><span class=\"o\">)</span> <span class=\"no\">override</span> <span class=\"o\">&#123;</span>\n    <span class=\"no\">IOBufQueue</span> <span class=\"no\">data</span><span class=\"o\">;</span>   \n    <span class=\"k\">if</span> <span class=\"o\">(</span><span class=\"no\">q</span><span class=\"o\">.</span><span class=\"nf\" data-symbol-name=\"chainLength\">chainLength</span><span class=\"o\">()</span> <span class=\"o\">&gt;=</span> <span class=\"mi\">4</span><span class=\"o\">)</span> <span class=\"o\">&#123;</span>\n       <span class=\"no\">data</span><span class=\"o\">.</span><span class=\"nf\" data-symbol-name=\"append\">append</span><span class=\"o\">(</span><span class=\"no\">q</span><span class=\"o\">.</span><span class=\"nf\" data-symbol-name=\"split\">split</span><span class=\"o\">(</span><span class=\"mi\">4</span><span class=\"o\">));</span>\n       <span class=\"no\">ctx</span><span class=\"o\">-&gt;</span><span class=\"na\" data-symbol-name=\"fireRead\">fireRead</span><span class=\"o\">(</span><span class=\"no\">data</span><span class=\"o\">);</span>\n    <span class=\"o\">&#125;</span> \n  <span class=\"o\">&#125;</span>\n<span class=\"o\">&#125;;</span></pre></div>\n\n<p>This handler only handles read (inbound) data, so we can inherit from InboundHandler, and ignore the outbound type (so the ordering of inbound/outbound handlers in your pipeline doesn&#039;t matter).   It checks if there are at least 4 bytes of data available, and if so, passes them on to the next handler.  If there aren&#039;t yet four bytes of data available, it does nothing, and waits for more data.</p>\n\n<p>We can add this handler to our pipeline like so:</p>\n\n<div class=\"remarkup-code-block\" data-code-lang=\"php\"><pre class=\"remarkup-code\"><span class=\"nx\">pipeline</span><span class=\"k\">.</span><span data-symbol-name=\"addBack\" class=\"nf\">addBack</span><span class=\"k\">(</span><span data-symbol-name=\"MyHandler\" class=\"nf\">MyHandler</span><span class=\"k\">(</span><span class=\"k\">)</span><span class=\"k\">)</span><span class=\"k\">;</span></pre></div>\n\n<p>and remove it just as easily:</p>\n\n<div class=\"remarkup-code-block\" data-code-lang=\"php\"><pre class=\"remarkup-code\"><span class=\"no\">pipeline</span><span class=\"o\">.</span><span class=\"no\">remove</span><span class=\"o\">&lt;</span><span class=\"no\">MyHandler</span><span class=\"o\">&gt;();</span></pre></div>\n\n<h3 id=\"staticpipeline\">StaticPipeline <a href=\"#staticpipeline\" class=\"headerLink\">#</a></h3>\n\n<p>Instantiating all these handlers and pipelines can hit the allocator pretty hard.  There are two ways to try to do fewer allocations.  StaticPipeline allows <strong>all</strong> the handlers, and the pipeline, to be instantiated all in the same memory block, so we only hit the allocator once.</p>\n\n<p>The other option is to allocate the handlers once at startup, and reuse them in many pipelines.  This means all state has to be saved in the HandlerContext object instead of the Handler itself, since each handler can be in multiple pipelines.  There is one context per pipeline to get around this limitation.</p></section><section class=\"dex_document\"><h1>Built-in handlers</h1><p class=\"dex_introduction\">The stuff that comes with the box</p><h2 id=\"byte-to-byte-handlers\">Byte to byte handlers <a href=\"#byte-to-byte-handlers\" class=\"headerLink\">#</a></h2>\n\n<h3 id=\"asyncsockethandler\">AsyncSocketHandler <a href=\"#asyncsockethandler\" class=\"headerLink\">#</a></h3>\n\n<p>This is almost always the first handler in the pipeline for clients and servers - it connects an AsyncSocket to the pipeline.  Having it as a handler is nice, because mocking it out for tests becomes trivial.</p>\n\n<h3 id=\"outputbufferinghandler\">OutputBufferingHandler <a href=\"#outputbufferinghandler\" class=\"headerLink\">#</a></h3>\n\n<p>Output is buffered and only sent once per event loop.  This logic is exactly what is in ThriftServer, and very similar to what exists in proxygen - it can improve throughput for small writes by up to 300%.</p>\n\n<h3 id=\"eventbasehandler\">EventBaseHandler <a href=\"#eventbasehandler\" class=\"headerLink\">#</a></h3>\n\n<p>Putting this right after an AsyncSocketHandler means that writes can happen from any thread, and eventBase-&gt;runInEventBaseThread() will automatically be called to put them in the correct thread.  It doesn&#039;t intrinsically make the pipeline thread-safe though, writes from different threads may be interleaved, other handler stages must be only used from one thread or be thread safe, etc.</p>\n\n<p>In addition, reads are still always called on the eventBase thread.</p>\n\n<h2 id=\"codecs\">Codecs <a href=\"#codecs\" class=\"headerLink\">#</a></h2>\n\n<h3 id=\"fixedlengthframedecoder\">FixedLengthFrameDecoder <a href=\"#fixedlengthframedecoder\" class=\"headerLink\">#</a></h3>\n\n<p>A decoder that splits received IOBufs by a fixed number of bytes.  Used for fixed-length protocols</p>\n\n<h3 id=\"lengthfieldprepender\">LengthFieldPrepender <a href=\"#lengthfieldprepender\" class=\"headerLink\">#</a></h3>\n\n<p>Prepends a fixed-length field length.  Field length is configurable.</p>\n\n<h3 id=\"lengthfieldbasedframedec\">LengthFieldBasedFrameDecoder <a href=\"#lengthfieldbasedframedec\" class=\"headerLink\">#</a></h3>\n\n<p>The receiving portion of LengthFieldPrepender - decodes based on a fixed frame length, with optional header/tailer data sections.</p>\n\n<h3 id=\"linebasedframedecoder\">LineBasedFrameDecoder <a href=\"#linebasedframedecoder\" class=\"headerLink\">#</a></h3>\n\n<p>Decodes by line (with optional ending detection types), to be used for text-based protocols</p>\n\n<h3 id=\"stringcodec\">StringCodec <a href=\"#stringcodec\" class=\"headerLink\">#</a></h3>\n\n<p>Converts from IOBufs to std::strings and back for text-based protocols.  Must be used after one of the above frame decoders</p></section><section class=\"dex_document\"><h1>Services</h1><p class=\"dex_introduction\">How to add a new protocol</p><p><a href=\"https://twitter.github.io/finagle/guide/ServicesAndFilters.html\" target=\"_blank\">Finagle&#039;s documentation</a> on Services is highly recommended</p>\n\n<h2 id=\"services\">Services <a href=\"#services\" class=\"headerLink\">#</a></h2>\n\n<p>A Pipeline was read() and write() methods - it streams bytes in one or both directions.  write() returns a future, but the future is set when the bytes are successfully written.   Using pipeline there is no easy way to match up requests and responses for RPC.</p>\n\n<p>A Service is an RPC abstraction - Both clients and servers implement the interface.   Servers implement it by handling the request.  Clients implement it by sending the request to the server to complete.</p>\n\n<p>A Dispatcher is the adapter between the Pipeline and Service that matches up the requests and responses.  There are several built in Dispatchers, however if you are doing anything advanced, you may need to write your own.</p>\n\n<p>Because both clients and servers implement the same interface, mocking either clients or servers is trivially easy.</p>\n\n<h2 id=\"servicefilters\">ServiceFilters <a href=\"#servicefilters\" class=\"headerLink\">#</a></h2>\n\n<p>ServiceFilters provide a way to wrap filters around every request and response.  Things like logging, timeouts, retrying requests, etc. can be implemented as ServiceFilters.</p>\n\n<p>Existing ServiceFilters include:</p>\n\n<ul>\n<li>CloseOnReleaseFilter - rejects requests after connection is closed.  Often used in conjunction with</li>\n<li>ExpiringFilter - idle timeout and max connection time (usually used for clients)</li>\n<li>TimeoutFilter - request timeout time.  Usually used on servers.  Clients can use future.within to specify timeouts individually.</li>\n<li>ExecutorFilter - move requests to a different executor.</li>\n</ul>\n\n<h2 id=\"servicefactories\">ServiceFactories <a href=\"#servicefactories\" class=\"headerLink\">#</a></h2>\n\n<p>For some services, a Factory can help instantiate clients.   In Finagle, these are frequently provided for easy use with specific protocols, i.e. http, memcache, etc.</p>\n\n<h2 id=\"servicefactoryfilters\">ServiceFactoryFilters <a href=\"#servicefactoryfilters\" class=\"headerLink\">#</a></h2>\n\n<p>ServiceFactoryFilters provide filters for getting clients.  These include most connection-oriented things, like connection pooling, selection, dispatch, load balancing, etc.</p>\n\n<p>Existing ServiceFactoryFilters:</p>\n\n<ul>\n<li></li>\n<li></li>\n</ul></section>\n"
        },
        {
          "name": "buck2",
          "type": "blob",
          "size": 2.005859375,
          "content": "#!/usr/bin/env dotslash\n\n{\n  \"name\": \"buck2\",\n  \"platforms\": {\n    \"macos-aarch64\": {\n      \"size\": 26678080,\n      \"hash\": \"blake3\",\n      \"digest\": \"77a33acb816af93dc9a38d0bf26a1c0d044ede1d1e9bf80e68bd2c692e9b15b3\",\n      \"format\": \"zst\",\n      \"path\": \"buck2-aarch64-apple-darwin\",\n      \"providers\": [\n        {\n          \"url\": \"https://github.com/facebook/buck2/releases/download/2025-01-02/buck2-aarch64-apple-darwin.zst\"\n        }\n      ]\n    },\n    \"linux-aarch64\": {\n      \"size\": 28584872,\n      \"hash\": \"blake3\",\n      \"digest\": \"718ab212768932fa261284629b0c679639d06e7bff2d659f33eb1922121c4a9c\",\n      \"format\": \"zst\",\n      \"path\": \"buck2-aarch64-unknown-linux-musl\",\n      \"providers\": [\n        {\n          \"url\": \"https://github.com/facebook/buck2/releases/download/2025-01-02/buck2-aarch64-unknown-linux-musl.zst\"\n        }\n      ]\n    },\n    \"macos-x86_64\": {\n      \"size\": 28411693,\n      \"hash\": \"blake3\",\n      \"digest\": \"c70e6b0a7d35ada00dbb0a6af45c9032322c8d6bb5da9ade57813db8fec9cfd1\",\n      \"format\": \"zst\",\n      \"path\": \"buck2-x86_64-apple-darwin\",\n      \"providers\": [\n        {\n          \"url\": \"https://github.com/facebook/buck2/releases/download/2025-01-02/buck2-x86_64-apple-darwin.zst\"\n        }\n      ]\n    },\n    \"windows-x86_64\": {\n      \"size\": 23990882,\n      \"hash\": \"blake3\",\n      \"digest\": \"7dbef62c82d63a80c3a331b2455afce365c2a34c81a17533937f80989bc1f1dd\",\n      \"format\": \"zst\",\n      \"path\": \"buck2-x86_64-pc-windows-msvc.exe\",\n      \"providers\": [\n        {\n          \"url\": \"https://github.com/facebook/buck2/releases/download/2025-01-02/buck2-x86_64-pc-windows-msvc.exe.zst\"\n        }\n      ]\n    },\n    \"linux-x86_64\": {\n      \"size\": 30052738,\n      \"hash\": \"blake3\",\n      \"digest\": \"6a4e4f1e4c27fafa799fd64b258b00d405344e3e9e8fab0ab0cc88477bcf9947\",\n      \"format\": \"zst\",\n      \"path\": \"buck2-x86_64-unknown-linux-musl\",\n      \"providers\": [\n        {\n          \"url\": \"https://github.com/facebook/buck2/releases/download/2025-01-02/buck2-x86_64-unknown-linux-musl.zst\"\n        }\n      ]\n    }\n  }\n}\n"
        },
        {
          "name": "build",
          "type": "tree",
          "content": null
        },
        {
          "name": "tutorial.md",
          "type": "blob",
          "size": 9.974609375,
          "content": "# Wangle Tutorial\n\n## Introduction\n\nThe tutorial assumes that you have installed Wangle and its dependencies. The tutorial will demonstrate how to build an echo server - the \"hello world\" of distributed systems.\n\n## What is Wangle?\n\nWangle is a client/server application framework to build asynchronous, event-driven modern C++ services. The fundamental abstraction of Wangle is the Pipeline. Once you have fully understood this abstraction, you will be able to write all sorts of sophisticated modern C++ services. Another important abstraction is Service, which is an advanced version of a pipeline but it’s out of scope for this post.\n\n## What is a Pipeline?\n\nThe pipeline is the most important and powerful abstraction of Wangle. It offers immense flexibility to customize how requests and responses are handled by your service.\n\nA pipeline is a chain of request/response handlers that handle upstream (handling request) and downstream (handling response). Once you chain handlers together, it provides an agile way to convert a raw data stream into the desired message type (class) and the inverse -- desired message type to raw data stream.\n\nA handler should do one and only one function - just like the UNIX philosophy. If you have a handler that is doing more than one function than you should split it into individual handlers. This is really important for maintainability and flexibility as its common to change your protocol for one reason or the other.\n\nAll shared state within handlers are not thread-safe. Only use shared state that is guarded by a mutex, atomic lock, etc. If you want to use a thread-safe container then it is recommended to use Folly's lock-free data structures, which can be easily imported because they are a dependency of Wangle and are blazing fast.\n\n## Echo Server\n\nNow onto writing our first service with Wangle: the Echo Server. \n\nHere's the main piece of code in our echo server; it receives a string, prints it to stdout and sends it back downstream in the pipeline. It's really important to add the line delimiter because our pipeline will use a line decoder.\n\n``` cpp\n// the main logic of our echo server; receives a string and writes it straight\n// back\nclass EchoHandler : public HandlerAdapter<std::string> {\n public:\n  virtual void read(Context* ctx, std::string msg) override {\n    std::cout << \"handling \" << msg << std::endl;\n    write(ctx, msg + \"\\r\\n\");\n  }\n};\n```\n\nThis needs to be the final handler in the pipeline. Now the definition of the pipeline is needed to handle the requests and responses.\n\n```cpp\n// where we define the chain of handlers for each messeage received\nclass EchoPipelineFactory : public PipelineFactory<EchoPipeline> {\n public:\n  EchoPipeline::Ptr newPipeline(std::shared_ptr<AsyncTransport> sock) {\n    auto pipeline = EchoPipeline::create();\n    pipeline->addBack(AsyncSocketHandler(sock));\n    pipeline->addBack(LineBasedFrameDecoder(8192));\n    pipeline->addBack(StringCodec());\n    pipeline->addBack(EchoHandler());\n    pipeline->finalize();\n    return pipeline;\n  }\n };\n```\n\nIt is **very** important to be strict in the order of insertion as they are ordered by insertion. The pipeline has 4 handlers:\n\n  - **AsyncSocketHandler**\n    - Upstream: Reads a raw data stream from the socket and converts it into a zero-copy byte buffer.\n    - Downstream: Writes the contents of a zero-copy byte buffer to the underlying socket.\n  - **LineBasedFrameDecoder**\n    - Upstream: receives a zero-copy byte buffer and splits on line-endings\n    - Downstream: just passes the byte buffer to AsyncSocketHandler\n  - **StringCodec**\n    - Upstream: receives a byte buffer and decodes it into a std::string and pass up to the EchoHandler.\n    - Downstream: receives a std::string and encodes it into a byte buffer and pass down to the LineBasedFrameDecoder.\n  - **EchoHandler**\n    - Upstream: receives a std::string and writes it to the pipeline — which will send the message downstream.\n    - Downstream: receives a std::string and forwards it to StringCodec.\n\nNow that all needs to be done is plug the pipeline factory into a ServerBootstrap and that’s pretty much it. Bind a port and wait for it to stop.\n\n```cpp\n#include <folly/portability/GFlags.h>\n\n#include <wangle/bootstrap/ServerBootstrap.h>\n#include <wangle/channel/AsyncSocketHandler.h>\n#include <wangle/codec/LineBasedFrameDecoder.h>\n#include <wangle/codec/StringCodec.h>\n\nusing namespace folly;\nusing namespace wangle;\n\nDEFINE_int32(port, 8080, \"echo server port\");\n\ntypedef Pipeline<IOBufQueue&, std::string> EchoPipeline;\n\n// the main logic of our echo server; receives a string and writes it straight\n// back\nclass EchoHandler : public HandlerAdapter<std::string> {\n public:\n  virtual void read(Context* ctx, std::string msg) override {\n    std::cout << \"handling \" << msg << std::endl;\n    write(ctx, msg + \"\\r\\n\");\n  }\n};\n\n// where we define the chain of handlers for each message received\nclass EchoPipelineFactory : public PipelineFactory<EchoPipeline> {\n public:\n  EchoPipeline::Ptr newPipeline(std::shared_ptr<AsyncTransport> sock) {\n    auto pipeline = EchoPipeline::create();\n    pipeline->addBack(AsyncSocketHandler(sock));\n    pipeline->addBack(LineBasedFrameDecoder(8192));\n    pipeline->addBack(StringCodec());\n    pipeline->addBack(EchoHandler());\n    pipeline->finalize();\n    return pipeline;\n  }\n};\n\nint main(int argc, char** argv) {\n  gflags::ParseCommandLineFlags(&argc, &argv, true);\n\n  ServerBootstrap<EchoPipeline> server;\n  server.childPipeline(std::make_shared<EchoPipelineFactory>());\n  server.bind(FLAGS_port);\n  server.waitForStop();\n\n  return 0;\n}\n```\n\nWe've written an asynchronous C++ server in under 48 LOC.\n\n## Echo Client\n\nThe code for the echo client is very similar to the Echo Server. Here is the main echo handler.\n\n```cpp\n// the handler for receiving messages back from the server\nclass EchoHandler : public HandlerAdapter<std::string> {\n public:\n  virtual void read(Context* ctx, std::string msg) override {\n    std::cout << \"received back: \" << msg;\n  }\n  virtual void readException(Context* ctx, exception_wrapper e) override {\n    std::cout << exceptionStr(e) << std::endl;\n    close(ctx);\n  }\n  virtual void readEOF(Context* ctx) override {\n    std::cout << \"EOF received :(\" << std::endl;\n    close(ctx);\n  }\n};\n```\n\nNotice that we override other methods — readException and readEOF. There are few other methods that can be overriden. If you need to handle a particular event, just override the corresponding virtual method.\n\nNow onto the client’s pipeline factory. It is identical the server’s pipeline factory apart from _EventBaseHandler_ — which handles writing data from an event loop thread.\n\n```cpp\n// chains the handlers together to define the response pipeline\nclass EchoPipelineFactory : public PipelineFactory<EchoPipeline> {\n public:\n  EchoPipeline::Ptr newPipeline(std::shared_ptr<AsyncTransport> sock) {\n    auto pipeline = EchoPipeline::create();\n    pipeline->addBack(AsyncSocketHandler(sock));\n    pipeline->addBack(\n       EventBaseHandler()); // ensure we can write from any thread\n    pipeline->addBack(LineBasedFrameDecoder(8192, false));\n    pipeline->addBack(StringCodec());\n    pipeline->addBack(EchoHandler());\n    pipeline->finalize();\n    return pipeline;\n  }\n};\n```\n\nWhat does it looks like when it is all put together for the client?\n\n```cpp\n#include <folly/portability/GFlags.h>\n#include <iostream>\n\n#include <wangle/bootstrap/ClientBootstrap.h>\n#include <wangle/channel/AsyncSocketHandler.h>\n#include <wangle/channel/EventBaseHandler.h>\n#include <wangle/codec/LineBasedFrameDecoder.h>\n#include <wangle/codec/StringCodec.h>\n\nusing namespace folly;\nusing namespace wangle;\n\nDEFINE_int32(port, 8080, \"echo server port\");\nDEFINE_string(host, \"::1\", \"echo server address\");\n\ntypedef Pipeline<folly::IOBufQueue&, std::string> EchoPipeline;\n\n// the handler for receiving messages back from the server\nclass EchoHandler : public HandlerAdapter<std::string> {\n public:\n  virtual void read(Context* ctx, std::string msg) override {\n    std::cout << \"received back: \" << msg;\n  }\n  virtual void readException(Context* ctx, exception_wrapper e) override {\n    std::cout << exceptionStr(e) << std::endl;\n    close(ctx);\n  }\n  virtual void readEOF(Context* ctx) override {\n    std::cout << \"EOF received :(\" << std::endl;\n    close(ctx);\n  }\n};\n\n// chains the handlers together to define the response pipeline\nclass EchoPipelineFactory : public PipelineFactory<EchoPipeline> {\n public:\n  EchoPipeline::Ptr newPipeline(std::shared_ptr<AsyncTransport> sock) {\n    auto pipeline = EchoPipeline::create();\n    pipeline->addBack(AsyncSocketHandler(sock));\n    pipeline->addBack(\n        EventBaseHandler()); // ensure we can write from any thread\n    pipeline->addBack(LineBasedFrameDecoder(8192, false));\n    pipeline->addBack(StringCodec());\n    pipeline->addBack(EchoHandler());\n    pipeline->finalize();\n    return pipeline;\n  }\n};\n\nint main(int argc, char** argv) {\n  gflags::ParseCommandLineFlags(&argc, &argv, true);\n\n  ClientBootstrap<EchoPipeline> client;\n  client.group(std::make_shared<folly::IOThreadPoolExecutor>(1));\n  client.pipelineFactory(std::make_shared<EchoPipelineFactory>());\n  auto pipeline = client.connect(SocketAddress(FLAGS_host, FLAGS_port)).get();\n\n  try {\n    while (true) {\n      std::string line;\n      std::getline(std::cin, line);\n      if (line == \"\") {\n        break;\n      }\n\n      pipeline->write(line + \"\\r\\n\").get();\n      if (line == \"bye\") {\n        pipeline->close();\n        break;\n      }\n    }\n  } catch (const std::exception& e) {\n    std::cout << exceptionStr(e) << std::endl;\n  }\n\n  return 0;\n}\n```\n\nIt reads input from stdin in a loop and writes it to the pipeline and it blocks until the response is processed. It blocks by calling .get() from the returned future.\n\n## Summary\n\nThis quick tutorial has shown how to quickly write a basic service in modern C++ using Wangle. You should now know the fundamentals of Wangle and it should give you confidence to write your own service in C++. It is strongly recommend to understand the Service abstraction once you are comfortable with using the Pipeline as you can build sophisticated servers with it.\n"
        },
        {
          "name": "wangle",
          "type": "tree",
          "content": null
        }
      ]
    }
  ]
}