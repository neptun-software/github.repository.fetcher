{
  "metadata": {
    "timestamp": 1736565693574,
    "page": 594,
    "hasNextPage": true,
    "endCursor": "Y3Vyc29yOjYwMA==",
    "completionStatus": "IN_PROGRESS"
  },
  "repositories": [
    {
      "nameWithOwner": "LeelaChessZero/lc0",
      "stars": 2506,
      "defaultBranch": "master",
      "files": [
        {
          "name": ".circleci",
          "type": "tree",
          "content": null
        },
        {
          "name": ".clang-format",
          "type": "blob",
          "size": 0.0869140625,
          "content": "---\nLanguage: Cpp\nBasedOnStyle: Google\nDerivePointerAlignment: false\n---\nLanguage: Proto\n"
        },
        {
          "name": ".github",
          "type": "tree",
          "content": null
        },
        {
          "name": ".gitignore",
          "type": "blob",
          "size": 0.2314453125,
          "content": "!subprojects/*.wrap\n*.swp\n.clang_complete\n.DS_Store\n.cache/\n.clangd/\nbuild/\n__pycache__/\ncompile_commands.json\nCUDA_NN/\nlc0.xcodeproj/\nLC0VSProj/\nsrc/.vs/\nsubprojects/*\ntestdata/\nxcuserdata\n.clang-tidy\ncompile_flags.txt\n.vscode\n.mesonpy*"
        },
        {
          "name": ".gitmodules",
          "type": "blob",
          "size": 0.1162109375,
          "content": "[submodule \"libs/lczero-common\"]\n\tpath = libs/lczero-common\n\turl = https://github.com/LeelaChessZero/lczero-common.git\n"
        },
        {
          "name": "CITATION.cff",
          "type": "blob",
          "size": 0.48046875,
          "content": "cff-version: 1.2.0\ntitle: LeelaChessZero\ntype: software\nauthors:\n  - name: The LCZero Authors\nrepository-code: 'https://github.com/LeelaChessZero/lc0'\nurl: 'https://lczero.org/'\nrepository-artifact: 'https://github.com/LeelaChessZero/lc0/releases/'\nabstract: >-\n  Lc0 is a UCI-compliant chess engine designed to play chess\n  via neural network, specifically those of the\n  LeelaChessZero project.\nkeywords:\n  - chess\n  - neural networks (NN)\n  - artificial intelligence (AI)\nlicense: GPL-3.0\n"
        },
        {
          "name": "CONTRIBUTING.md",
          "type": "blob",
          "size": 4.798828125,
          "content": "# Contributing to lc0\n\nThese are the guidelines and standards followed by this codebase.\n\nThe language is C++, specifically C++17. As such, manual `new` and `delete` memory mangement is strongly discouraged; use the standard library tools for managing memory (such as `unique_ptr`, `shared_ptr` etc.).\n\nThis codebase uses semantic versioning. A release is the final commit for that version number, and all subsequent commits are development for the next version. `master` is the default branch, and the active development branch (as such, all Pull Requests go here); it always targets a minor (or major) version which succeeds the current relase. `release` is always equivalent to the latest tag.\n\n\n### Style\n\nStyle is of course the first guideline on every new contributor's mind :)\n\nThis codebase largely complies with the [Google C++ style guide](https://google.github.io/styleguide/cppguide.html). The maintainers recommend the use of [Clang's auto formatter](https://clang.llvm.org/docs/ClangFormatStyleOptions.html).\n\nNotable exceptions:\n 1. C++ exceptions are allowed (in fact, only `lczero::Exception`, defined in `utils/exception.h`, is allowed)\n 2. We use `#pragma once` instead of header guards.\n 3. Default function parameters are sometimes allowed.\n 4. Rvalue reference function params are sometimes allowed, not only for constructors and assignment operators.\n\nFor items (3) and (4), usage of those are discouraged, only use them if they benefit readability or have significant performance gain. It's possible that those exceptions (3) and (4) will be disallowed in future.\n\nThe most important rule to follow is consistency: look at the surrounding code when doing changes and follow similar style.\n\nThese are the most important parts of the codebase style (as a sort of tl;dr):\n\n * Comments must be full sentences, i.e. capitalized and ending in a period. (Sentences with elided subjects are fine.) Only `//` style comments are allowed, `/* */` style comments aren't.\n\n * Braces are a variant of K&R style, as can be gleaned from existing code. All `if` statements must use braces, with the possible exception of single statement `if`s, which *may* omit if the braces *if* the conditional and following statement are on the same line. Again, see surrounding code for examples.\n\n * Indentation is two spaces; \\t characters are disallowed.\n\n * Code line length is strictly capped at 80 characters.\n\n * Using non-`const` references as function parameters is disallowed; use pointers instead. (Using `const` references as parameters is fine.)\n\n * Identifier style:\n   - `kLikeThis` for constants and enum values\n   - `like_this` for variables\n   - `like_this_` for member variables\n   - `LikeThis` for function and class names\n\n * All code should be inside `namespace lczero`\n\nThe internal code dependency structure looks like this:\n\n * Code in `src/utils` is not allowed to depend on any other code.\n\n * Code in `src/chess` only depends on `src/utils`\n\n * Code in `src/neural` only depends on `src/utils` and `src/chess`\n\n * Code in `src/mcts` only depends on `src/utils`, `src/chess` and `src/neural`\n\n\n### Git history\n\nPull Requests are squashed when merged. This means all commits in the branch will be squashed into one commit applied onto master, so branches and their PRs should stick to *one* topic only. If you think changes deserve separate commits, make separate PRs for each commit.\n\nThis also means it's not possible to reuse one branch for multiple PRs; new PRs must either use entirely new branches, or else you could use `git reset --hard` on the current branch.\n\n\n### Allowed features\n\nLc0 is still in early stages of development, and has not yet reached the point where we are ready to add small tweaks to add few points of a rating. Large code changes still happen, and having lots of small optimizations adds overhead to larger changes, slowing development.\n\nTherefore, as a rule, search algorithm tweaks that give a gain of less than ~20 Elo points are discouraged at this point. (This limit will gradually be lowered as Lc0 code matures, eventually to 0.0 Elo).\n\n\n#### Adding new command line flags/UCI parameters\n\nOnly add new parameters if users can significantly (>20 Elo) benefit by tweaking it. We don't want to make every single constant configurable (or rather, users don't want to see hundreds of parameters which don't do anything).\n\nTry to minimize number of parameters that your feature introduces. If your feature introduces several parameters, every individual parameter should be significant (i.e. tweaking it with other fixes will give >20 Elo).\n\n\n#### Adding features for testing\n\nIt is fine to temporarily commit a feature of unknown Elo gain so that people may test it. It's also fine to expose many parameters for the feature initially so that people can tune them. However, if the tweak doesn't prove to be significant, it should be removed after a few weeks.\n\n"
        },
        {
          "name": "COPYING",
          "type": "blob",
          "size": 34.32421875,
          "content": "                    GNU GENERAL PUBLIC LICENSE\n                       Version 3, 29 June 2007\n\n Copyright (C) 2007 Free Software Foundation, Inc. <https://fsf.org/>\n Everyone is permitted to copy and distribute verbatim copies\n of this license document, but changing it is not allowed.\n\n                            Preamble\n\n  The GNU General Public License is a free, copyleft license for\nsoftware and other kinds of works.\n\n  The licenses for most software and other practical works are designed\nto take away your freedom to share and change the works.  By contrast,\nthe GNU General Public License is intended to guarantee your freedom to\nshare and change all versions of a program--to make sure it remains free\nsoftware for all its users.  We, the Free Software Foundation, use the\nGNU General Public License for most of our software; it applies also to\nany other work released this way by its authors.  You can apply it to\nyour programs, too.\n\n  When we speak of free software, we are referring to freedom, not\nprice.  Our General Public Licenses are designed to make sure that you\nhave the freedom to distribute copies of free software (and charge for\nthem if you wish), that you receive source code or can get it if you\nwant it, that you can change the software or use pieces of it in new\nfree programs, and that you know you can do these things.\n\n  To protect your rights, we need to prevent others from denying you\nthese rights or asking you to surrender the rights.  Therefore, you have\ncertain responsibilities if you distribute copies of the software, or if\nyou modify it: responsibilities to respect the freedom of others.\n\n  For example, if you distribute copies of such a program, whether\ngratis or for a fee, you must pass on to the recipients the same\nfreedoms that you received.  You must make sure that they, too, receive\nor can get the source code.  And you must show them these terms so they\nknow their rights.\n\n  Developers that use the GNU GPL protect your rights with two steps:\n(1) assert copyright on the software, and (2) offer you this License\ngiving you legal permission to copy, distribute and/or modify it.\n\n  For the developers' and authors' protection, the GPL clearly explains\nthat there is no warranty for this free software.  For both users' and\nauthors' sake, the GPL requires that modified versions be marked as\nchanged, so that their problems will not be attributed erroneously to\nauthors of previous versions.\n\n  Some devices are designed to deny users access to install or run\nmodified versions of the software inside them, although the manufacturer\ncan do so.  This is fundamentally incompatible with the aim of\nprotecting users' freedom to change the software.  The systematic\npattern of such abuse occurs in the area of products for individuals to\nuse, which is precisely where it is most unacceptable.  Therefore, we\nhave designed this version of the GPL to prohibit the practice for those\nproducts.  If such problems arise substantially in other domains, we\nstand ready to extend this provision to those domains in future versions\nof the GPL, as needed to protect the freedom of users.\n\n  Finally, every program is threatened constantly by software patents.\nStates should not allow patents to restrict development and use of\nsoftware on general-purpose computers, but in those that do, we wish to\navoid the special danger that patents applied to a free program could\nmake it effectively proprietary.  To prevent this, the GPL assures that\npatents cannot be used to render the program non-free.\n\n  The precise terms and conditions for copying, distribution and\nmodification follow.\n\n                       TERMS AND CONDITIONS\n\n  0. Definitions.\n\n  \"This License\" refers to version 3 of the GNU General Public License.\n\n  \"Copyright\" also means copyright-like laws that apply to other kinds of\nworks, such as semiconductor masks.\n\n  \"The Program\" refers to any copyrightable work licensed under this\nLicense.  Each licensee is addressed as \"you\".  \"Licensees\" and\n\"recipients\" may be individuals or organizations.\n\n  To \"modify\" a work means to copy from or adapt all or part of the work\nin a fashion requiring copyright permission, other than the making of an\nexact copy.  The resulting work is called a \"modified version\" of the\nearlier work or a work \"based on\" the earlier work.\n\n  A \"covered work\" means either the unmodified Program or a work based\non the Program.\n\n  To \"propagate\" a work means to do anything with it that, without\npermission, would make you directly or secondarily liable for\ninfringement under applicable copyright law, except executing it on a\ncomputer or modifying a private copy.  Propagation includes copying,\ndistribution (with or without modification), making available to the\npublic, and in some countries other activities as well.\n\n  To \"convey\" a work means any kind of propagation that enables other\nparties to make or receive copies.  Mere interaction with a user through\na computer network, with no transfer of a copy, is not conveying.\n\n  An interactive user interface displays \"Appropriate Legal Notices\"\nto the extent that it includes a convenient and prominently visible\nfeature that (1) displays an appropriate copyright notice, and (2)\ntells the user that there is no warranty for the work (except to the\nextent that warranties are provided), that licensees may convey the\nwork under this License, and how to view a copy of this License.  If\nthe interface presents a list of user commands or options, such as a\nmenu, a prominent item in the list meets this criterion.\n\n  1. Source Code.\n\n  The \"source code\" for a work means the preferred form of the work\nfor making modifications to it.  \"Object code\" means any non-source\nform of a work.\n\n  A \"Standard Interface\" means an interface that either is an official\nstandard defined by a recognized standards body, or, in the case of\ninterfaces specified for a particular programming language, one that\nis widely used among developers working in that language.\n\n  The \"System Libraries\" of an executable work include anything, other\nthan the work as a whole, that (a) is included in the normal form of\npackaging a Major Component, but which is not part of that Major\nComponent, and (b) serves only to enable use of the work with that\nMajor Component, or to implement a Standard Interface for which an\nimplementation is available to the public in source code form.  A\n\"Major Component\", in this context, means a major essential component\n(kernel, window system, and so on) of the specific operating system\n(if any) on which the executable work runs, or a compiler used to\nproduce the work, or an object code interpreter used to run it.\n\n  The \"Corresponding Source\" for a work in object code form means all\nthe source code needed to generate, install, and (for an executable\nwork) run the object code and to modify the work, including scripts to\ncontrol those activities.  However, it does not include the work's\nSystem Libraries, or general-purpose tools or generally available free\nprograms which are used unmodified in performing those activities but\nwhich are not part of the work.  For example, Corresponding Source\nincludes interface definition files associated with source files for\nthe work, and the source code for shared libraries and dynamically\nlinked subprograms that the work is specifically designed to require,\nsuch as by intimate data communication or control flow between those\nsubprograms and other parts of the work.\n\n  The Corresponding Source need not include anything that users\ncan regenerate automatically from other parts of the Corresponding\nSource.\n\n  The Corresponding Source for a work in source code form is that\nsame work.\n\n  2. Basic Permissions.\n\n  All rights granted under this License are granted for the term of\ncopyright on the Program, and are irrevocable provided the stated\nconditions are met.  This License explicitly affirms your unlimited\npermission to run the unmodified Program.  The output from running a\ncovered work is covered by this License only if the output, given its\ncontent, constitutes a covered work.  This License acknowledges your\nrights of fair use or other equivalent, as provided by copyright law.\n\n  You may make, run and propagate covered works that you do not\nconvey, without conditions so long as your license otherwise remains\nin force.  You may convey covered works to others for the sole purpose\nof having them make modifications exclusively for you, or provide you\nwith facilities for running those works, provided that you comply with\nthe terms of this License in conveying all material for which you do\nnot control copyright.  Those thus making or running the covered works\nfor you must do so exclusively on your behalf, under your direction\nand control, on terms that prohibit them from making any copies of\nyour copyrighted material outside their relationship with you.\n\n  Conveying under any other circumstances is permitted solely under\nthe conditions stated below.  Sublicensing is not allowed; section 10\nmakes it unnecessary.\n\n  3. Protecting Users' Legal Rights From Anti-Circumvention Law.\n\n  No covered work shall be deemed part of an effective technological\nmeasure under any applicable law fulfilling obligations under article\n11 of the WIPO copyright treaty adopted on 20 December 1996, or\nsimilar laws prohibiting or restricting circumvention of such\nmeasures.\n\n  When you convey a covered work, you waive any legal power to forbid\ncircumvention of technological measures to the extent such circumvention\nis effected by exercising rights under this License with respect to\nthe covered work, and you disclaim any intention to limit operation or\nmodification of the work as a means of enforcing, against the work's\nusers, your or third parties' legal rights to forbid circumvention of\ntechnological measures.\n\n  4. Conveying Verbatim Copies.\n\n  You may convey verbatim copies of the Program's source code as you\nreceive it, in any medium, provided that you conspicuously and\nappropriately publish on each copy an appropriate copyright notice;\nkeep intact all notices stating that this License and any\nnon-permissive terms added in accord with section 7 apply to the code;\nkeep intact all notices of the absence of any warranty; and give all\nrecipients a copy of this License along with the Program.\n\n  You may charge any price or no price for each copy that you convey,\nand you may offer support or warranty protection for a fee.\n\n  5. Conveying Modified Source Versions.\n\n  You may convey a work based on the Program, or the modifications to\nproduce it from the Program, in the form of source code under the\nterms of section 4, provided that you also meet all of these conditions:\n\n    a) The work must carry prominent notices stating that you modified\n    it, and giving a relevant date.\n\n    b) The work must carry prominent notices stating that it is\n    released under this License and any conditions added under section\n    7.  This requirement modifies the requirement in section 4 to\n    \"keep intact all notices\".\n\n    c) You must license the entire work, as a whole, under this\n    License to anyone who comes into possession of a copy.  This\n    License will therefore apply, along with any applicable section 7\n    additional terms, to the whole of the work, and all its parts,\n    regardless of how they are packaged.  This License gives no\n    permission to license the work in any other way, but it does not\n    invalidate such permission if you have separately received it.\n\n    d) If the work has interactive user interfaces, each must display\n    Appropriate Legal Notices; however, if the Program has interactive\n    interfaces that do not display Appropriate Legal Notices, your\n    work need not make them do so.\n\n  A compilation of a covered work with other separate and independent\nworks, which are not by their nature extensions of the covered work,\nand which are not combined with it such as to form a larger program,\nin or on a volume of a storage or distribution medium, is called an\n\"aggregate\" if the compilation and its resulting copyright are not\nused to limit the access or legal rights of the compilation's users\nbeyond what the individual works permit.  Inclusion of a covered work\nin an aggregate does not cause this License to apply to the other\nparts of the aggregate.\n\n  6. Conveying Non-Source Forms.\n\n  You may convey a covered work in object code form under the terms\nof sections 4 and 5, provided that you also convey the\nmachine-readable Corresponding Source under the terms of this License,\nin one of these ways:\n\n    a) Convey the object code in, or embodied in, a physical product\n    (including a physical distribution medium), accompanied by the\n    Corresponding Source fixed on a durable physical medium\n    customarily used for software interchange.\n\n    b) Convey the object code in, or embodied in, a physical product\n    (including a physical distribution medium), accompanied by a\n    written offer, valid for at least three years and valid for as\n    long as you offer spare parts or customer support for that product\n    model, to give anyone who possesses the object code either (1) a\n    copy of the Corresponding Source for all the software in the\n    product that is covered by this License, on a durable physical\n    medium customarily used for software interchange, for a price no\n    more than your reasonable cost of physically performing this\n    conveying of source, or (2) access to copy the\n    Corresponding Source from a network server at no charge.\n\n    c) Convey individual copies of the object code with a copy of the\n    written offer to provide the Corresponding Source.  This\n    alternative is allowed only occasionally and noncommercially, and\n    only if you received the object code with such an offer, in accord\n    with subsection 6b.\n\n    d) Convey the object code by offering access from a designated\n    place (gratis or for a charge), and offer equivalent access to the\n    Corresponding Source in the same way through the same place at no\n    further charge.  You need not require recipients to copy the\n    Corresponding Source along with the object code.  If the place to\n    copy the object code is a network server, the Corresponding Source\n    may be on a different server (operated by you or a third party)\n    that supports equivalent copying facilities, provided you maintain\n    clear directions next to the object code saying where to find the\n    Corresponding Source.  Regardless of what server hosts the\n    Corresponding Source, you remain obligated to ensure that it is\n    available for as long as needed to satisfy these requirements.\n\n    e) Convey the object code using peer-to-peer transmission, provided\n    you inform other peers where the object code and Corresponding\n    Source of the work are being offered to the general public at no\n    charge under subsection 6d.\n\n  A separable portion of the object code, whose source code is excluded\nfrom the Corresponding Source as a System Library, need not be\nincluded in conveying the object code work.\n\n  A \"User Product\" is either (1) a \"consumer product\", which means any\ntangible personal property which is normally used for personal, family,\nor household purposes, or (2) anything designed or sold for incorporation\ninto a dwelling.  In determining whether a product is a consumer product,\ndoubtful cases shall be resolved in favor of coverage.  For a particular\nproduct received by a particular user, \"normally used\" refers to a\ntypical or common use of that class of product, regardless of the status\nof the particular user or of the way in which the particular user\nactually uses, or expects or is expected to use, the product.  A product\nis a consumer product regardless of whether the product has substantial\ncommercial, industrial or non-consumer uses, unless such uses represent\nthe only significant mode of use of the product.\n\n  \"Installation Information\" for a User Product means any methods,\nprocedures, authorization keys, or other information required to install\nand execute modified versions of a covered work in that User Product from\na modified version of its Corresponding Source.  The information must\nsuffice to ensure that the continued functioning of the modified object\ncode is in no case prevented or interfered with solely because\nmodification has been made.\n\n  If you convey an object code work under this section in, or with, or\nspecifically for use in, a User Product, and the conveying occurs as\npart of a transaction in which the right of possession and use of the\nUser Product is transferred to the recipient in perpetuity or for a\nfixed term (regardless of how the transaction is characterized), the\nCorresponding Source conveyed under this section must be accompanied\nby the Installation Information.  But this requirement does not apply\nif neither you nor any third party retains the ability to install\nmodified object code on the User Product (for example, the work has\nbeen installed in ROM).\n\n  The requirement to provide Installation Information does not include a\nrequirement to continue to provide support service, warranty, or updates\nfor a work that has been modified or installed by the recipient, or for\nthe User Product in which it has been modified or installed.  Access to a\nnetwork may be denied when the modification itself materially and\nadversely affects the operation of the network or violates the rules and\nprotocols for communication across the network.\n\n  Corresponding Source conveyed, and Installation Information provided,\nin accord with this section must be in a format that is publicly\ndocumented (and with an implementation available to the public in\nsource code form), and must require no special password or key for\nunpacking, reading or copying.\n\n  7. Additional Terms.\n\n  \"Additional permissions\" are terms that supplement the terms of this\nLicense by making exceptions from one or more of its conditions.\nAdditional permissions that are applicable to the entire Program shall\nbe treated as though they were included in this License, to the extent\nthat they are valid under applicable law.  If additional permissions\napply only to part of the Program, that part may be used separately\nunder those permissions, but the entire Program remains governed by\nthis License without regard to the additional permissions.\n\n  When you convey a copy of a covered work, you may at your option\nremove any additional permissions from that copy, or from any part of\nit.  (Additional permissions may be written to require their own\nremoval in certain cases when you modify the work.)  You may place\nadditional permissions on material, added by you to a covered work,\nfor which you have or can give appropriate copyright permission.\n\n  Notwithstanding any other provision of this License, for material you\nadd to a covered work, you may (if authorized by the copyright holders of\nthat material) supplement the terms of this License with terms:\n\n    a) Disclaiming warranty or limiting liability differently from the\n    terms of sections 15 and 16 of this License; or\n\n    b) Requiring preservation of specified reasonable legal notices or\n    author attributions in that material or in the Appropriate Legal\n    Notices displayed by works containing it; or\n\n    c) Prohibiting misrepresentation of the origin of that material, or\n    requiring that modified versions of such material be marked in\n    reasonable ways as different from the original version; or\n\n    d) Limiting the use for publicity purposes of names of licensors or\n    authors of the material; or\n\n    e) Declining to grant rights under trademark law for use of some\n    trade names, trademarks, or service marks; or\n\n    f) Requiring indemnification of licensors and authors of that\n    material by anyone who conveys the material (or modified versions of\n    it) with contractual assumptions of liability to the recipient, for\n    any liability that these contractual assumptions directly impose on\n    those licensors and authors.\n\n  All other non-permissive additional terms are considered \"further\nrestrictions\" within the meaning of section 10.  If the Program as you\nreceived it, or any part of it, contains a notice stating that it is\ngoverned by this License along with a term that is a further\nrestriction, you may remove that term.  If a license document contains\na further restriction but permits relicensing or conveying under this\nLicense, you may add to a covered work material governed by the terms\nof that license document, provided that the further restriction does\nnot survive such relicensing or conveying.\n\n  If you add terms to a covered work in accord with this section, you\nmust place, in the relevant source files, a statement of the\nadditional terms that apply to those files, or a notice indicating\nwhere to find the applicable terms.\n\n  Additional terms, permissive or non-permissive, may be stated in the\nform of a separately written license, or stated as exceptions;\nthe above requirements apply either way.\n\n  8. Termination.\n\n  You may not propagate or modify a covered work except as expressly\nprovided under this License.  Any attempt otherwise to propagate or\nmodify it is void, and will automatically terminate your rights under\nthis License (including any patent licenses granted under the third\nparagraph of section 11).\n\n  However, if you cease all violation of this License, then your\nlicense from a particular copyright holder is reinstated (a)\nprovisionally, unless and until the copyright holder explicitly and\nfinally terminates your license, and (b) permanently, if the copyright\nholder fails to notify you of the violation by some reasonable means\nprior to 60 days after the cessation.\n\n  Moreover, your license from a particular copyright holder is\nreinstated permanently if the copyright holder notifies you of the\nviolation by some reasonable means, this is the first time you have\nreceived notice of violation of this License (for any work) from that\ncopyright holder, and you cure the violation prior to 30 days after\nyour receipt of the notice.\n\n  Termination of your rights under this section does not terminate the\nlicenses of parties who have received copies or rights from you under\nthis License.  If your rights have been terminated and not permanently\nreinstated, you do not qualify to receive new licenses for the same\nmaterial under section 10.\n\n  9. Acceptance Not Required for Having Copies.\n\n  You are not required to accept this License in order to receive or\nrun a copy of the Program.  Ancillary propagation of a covered work\noccurring solely as a consequence of using peer-to-peer transmission\nto receive a copy likewise does not require acceptance.  However,\nnothing other than this License grants you permission to propagate or\nmodify any covered work.  These actions infringe copyright if you do\nnot accept this License.  Therefore, by modifying or propagating a\ncovered work, you indicate your acceptance of this License to do so.\n\n  10. Automatic Licensing of Downstream Recipients.\n\n  Each time you convey a covered work, the recipient automatically\nreceives a license from the original licensors, to run, modify and\npropagate that work, subject to this License.  You are not responsible\nfor enforcing compliance by third parties with this License.\n\n  An \"entity transaction\" is a transaction transferring control of an\norganization, or substantially all assets of one, or subdividing an\norganization, or merging organizations.  If propagation of a covered\nwork results from an entity transaction, each party to that\ntransaction who receives a copy of the work also receives whatever\nlicenses to the work the party's predecessor in interest had or could\ngive under the previous paragraph, plus a right to possession of the\nCorresponding Source of the work from the predecessor in interest, if\nthe predecessor has it or can get it with reasonable efforts.\n\n  You may not impose any further restrictions on the exercise of the\nrights granted or affirmed under this License.  For example, you may\nnot impose a license fee, royalty, or other charge for exercise of\nrights granted under this License, and you may not initiate litigation\n(including a cross-claim or counterclaim in a lawsuit) alleging that\nany patent claim is infringed by making, using, selling, offering for\nsale, or importing the Program or any portion of it.\n\n  11. Patents.\n\n  A \"contributor\" is a copyright holder who authorizes use under this\nLicense of the Program or a work on which the Program is based.  The\nwork thus licensed is called the contributor's \"contributor version\".\n\n  A contributor's \"essential patent claims\" are all patent claims\nowned or controlled by the contributor, whether already acquired or\nhereafter acquired, that would be infringed by some manner, permitted\nby this License, of making, using, or selling its contributor version,\nbut do not include claims that would be infringed only as a\nconsequence of further modification of the contributor version.  For\npurposes of this definition, \"control\" includes the right to grant\npatent sublicenses in a manner consistent with the requirements of\nthis License.\n\n  Each contributor grants you a non-exclusive, worldwide, royalty-free\npatent license under the contributor's essential patent claims, to\nmake, use, sell, offer for sale, import and otherwise run, modify and\npropagate the contents of its contributor version.\n\n  In the following three paragraphs, a \"patent license\" is any express\nagreement or commitment, however denominated, not to enforce a patent\n(such as an express permission to practice a patent or covenant not to\nsue for patent infringement).  To \"grant\" such a patent license to a\nparty means to make such an agreement or commitment not to enforce a\npatent against the party.\n\n  If you convey a covered work, knowingly relying on a patent license,\nand the Corresponding Source of the work is not available for anyone\nto copy, free of charge and under the terms of this License, through a\npublicly available network server or other readily accessible means,\nthen you must either (1) cause the Corresponding Source to be so\navailable, or (2) arrange to deprive yourself of the benefit of the\npatent license for this particular work, or (3) arrange, in a manner\nconsistent with the requirements of this License, to extend the patent\nlicense to downstream recipients.  \"Knowingly relying\" means you have\nactual knowledge that, but for the patent license, your conveying the\ncovered work in a country, or your recipient's use of the covered work\nin a country, would infringe one or more identifiable patents in that\ncountry that you have reason to believe are valid.\n\n  If, pursuant to or in connection with a single transaction or\narrangement, you convey, or propagate by procuring conveyance of, a\ncovered work, and grant a patent license to some of the parties\nreceiving the covered work authorizing them to use, propagate, modify\nor convey a specific copy of the covered work, then the patent license\nyou grant is automatically extended to all recipients of the covered\nwork and works based on it.\n\n  A patent license is \"discriminatory\" if it does not include within\nthe scope of its coverage, prohibits the exercise of, or is\nconditioned on the non-exercise of one or more of the rights that are\nspecifically granted under this License.  You may not convey a covered\nwork if you are a party to an arrangement with a third party that is\nin the business of distributing software, under which you make payment\nto the third party based on the extent of your activity of conveying\nthe work, and under which the third party grants, to any of the\nparties who would receive the covered work from you, a discriminatory\npatent license (a) in connection with copies of the covered work\nconveyed by you (or copies made from those copies), or (b) primarily\nfor and in connection with specific products or compilations that\ncontain the covered work, unless you entered into that arrangement,\nor that patent license was granted, prior to 28 March 2007.\n\n  Nothing in this License shall be construed as excluding or limiting\nany implied license or other defenses to infringement that may\notherwise be available to you under applicable patent law.\n\n  12. No Surrender of Others' Freedom.\n\n  If conditions are imposed on you (whether by court order, agreement or\notherwise) that contradict the conditions of this License, they do not\nexcuse you from the conditions of this License.  If you cannot convey a\ncovered work so as to satisfy simultaneously your obligations under this\nLicense and any other pertinent obligations, then as a consequence you may\nnot convey it at all.  For example, if you agree to terms that obligate you\nto collect a royalty for further conveying from those to whom you convey\nthe Program, the only way you could satisfy both those terms and this\nLicense would be to refrain entirely from conveying the Program.\n\n  13. Use with the GNU Affero General Public License.\n\n  Notwithstanding any other provision of this License, you have\npermission to link or combine any covered work with a work licensed\nunder version 3 of the GNU Affero General Public License into a single\ncombined work, and to convey the resulting work.  The terms of this\nLicense will continue to apply to the part which is the covered work,\nbut the special requirements of the GNU Affero General Public License,\nsection 13, concerning interaction through a network will apply to the\ncombination as such.\n\n  14. Revised Versions of this License.\n\n  The Free Software Foundation may publish revised and/or new versions of\nthe GNU General Public License from time to time.  Such new versions will\nbe similar in spirit to the present version, but may differ in detail to\naddress new problems or concerns.\n\n  Each version is given a distinguishing version number.  If the\nProgram specifies that a certain numbered version of the GNU General\nPublic License \"or any later version\" applies to it, you have the\noption of following the terms and conditions either of that numbered\nversion or of any later version published by the Free Software\nFoundation.  If the Program does not specify a version number of the\nGNU General Public License, you may choose any version ever published\nby the Free Software Foundation.\n\n  If the Program specifies that a proxy can decide which future\nversions of the GNU General Public License can be used, that proxy's\npublic statement of acceptance of a version permanently authorizes you\nto choose that version for the Program.\n\n  Later license versions may give you additional or different\npermissions.  However, no additional obligations are imposed on any\nauthor or copyright holder as a result of your choosing to follow a\nlater version.\n\n  15. Disclaimer of Warranty.\n\n  THERE IS NO WARRANTY FOR THE PROGRAM, TO THE EXTENT PERMITTED BY\nAPPLICABLE LAW.  EXCEPT WHEN OTHERWISE STATED IN WRITING THE COPYRIGHT\nHOLDERS AND/OR OTHER PARTIES PROVIDE THE PROGRAM \"AS IS\" WITHOUT WARRANTY\nOF ANY KIND, EITHER EXPRESSED OR IMPLIED, INCLUDING, BUT NOT LIMITED TO,\nTHE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR\nPURPOSE.  THE ENTIRE RISK AS TO THE QUALITY AND PERFORMANCE OF THE PROGRAM\nIS WITH YOU.  SHOULD THE PROGRAM PROVE DEFECTIVE, YOU ASSUME THE COST OF\nALL NECESSARY SERVICING, REPAIR OR CORRECTION.\n\n  16. Limitation of Liability.\n\n  IN NO EVENT UNLESS REQUIRED BY APPLICABLE LAW OR AGREED TO IN WRITING\nWILL ANY COPYRIGHT HOLDER, OR ANY OTHER PARTY WHO MODIFIES AND/OR CONVEYS\nTHE PROGRAM AS PERMITTED ABOVE, BE LIABLE TO YOU FOR DAMAGES, INCLUDING ANY\nGENERAL, SPECIAL, INCIDENTAL OR CONSEQUENTIAL DAMAGES ARISING OUT OF THE\nUSE OR INABILITY TO USE THE PROGRAM (INCLUDING BUT NOT LIMITED TO LOSS OF\nDATA OR DATA BEING RENDERED INACCURATE OR LOSSES SUSTAINED BY YOU OR THIRD\nPARTIES OR A FAILURE OF THE PROGRAM TO OPERATE WITH ANY OTHER PROGRAMS),\nEVEN IF SUCH HOLDER OR OTHER PARTY HAS BEEN ADVISED OF THE POSSIBILITY OF\nSUCH DAMAGES.\n\n  17. Interpretation of Sections 15 and 16.\n\n  If the disclaimer of warranty and limitation of liability provided\nabove cannot be given local legal effect according to their terms,\nreviewing courts shall apply local law that most closely approximates\nan absolute waiver of all civil liability in connection with the\nProgram, unless a warranty or assumption of liability accompanies a\ncopy of the Program in return for a fee.\n\n                     END OF TERMS AND CONDITIONS\n\n            How to Apply These Terms to Your New Programs\n\n  If you develop a new program, and you want it to be of the greatest\npossible use to the public, the best way to achieve this is to make it\nfree software which everyone can redistribute and change under these terms.\n\n  To do so, attach the following notices to the program.  It is safest\nto attach them to the start of each source file to most effectively\nstate the exclusion of warranty; and each file should have at least\nthe \"copyright\" line and a pointer to where the full notice is found.\n\n    <one line to give the program's name and a brief idea of what it does.>\n    Copyright (C) <year>  <name of author>\n\n    This program is free software: you can redistribute it and/or modify\n    it under the terms of the GNU General Public License as published by\n    the Free Software Foundation, either version 3 of the License, or\n    (at your option) any later version.\n\n    This program is distributed in the hope that it will be useful,\n    but WITHOUT ANY WARRANTY; without even the implied warranty of\n    MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n    GNU General Public License for more details.\n\n    You should have received a copy of the GNU General Public License\n    along with this program.  If not, see <https://www.gnu.org/licenses/>.\n\nAlso add information on how to contact you by electronic and paper mail.\n\n  If the program does terminal interaction, make it output a short\nnotice like this when it starts in an interactive mode:\n\n    <program>  Copyright (C) <year>  <name of author>\n    This program comes with ABSOLUTELY NO WARRANTY; for details type `show w'.\n    This is free software, and you are welcome to redistribute it\n    under certain conditions; type `show c' for details.\n\nThe hypothetical commands `show w' and `show c' should show the appropriate\nparts of the General Public License.  Of course, your program's commands\nmight be different; for a GUI interface, you would use an \"about box\".\n\n  You should also get your employer (if you work as a programmer) or school,\nif any, to sign a \"copyright disclaimer\" for the program, if necessary.\nFor more information on this, and how to apply and follow the GNU GPL, see\n<https://www.gnu.org/licenses/>.\n\n  The GNU General Public License does not permit incorporating your program\ninto proprietary programs.  If your program is a subroutine library, you\nmay consider it more useful to permit linking proprietary applications with\nthe library.  If this is what you want to do, use the GNU Lesser General\nPublic License instead of this License.  But first, please read\n<https://www.gnu.org/licenses/why-not-lgpl.html>."
        },
        {
          "name": "FLAGS.md",
          "type": "blob",
          "size": 5.455078125,
          "content": "# Modes\n\n`lc0` supports several operating modes, each of which has a different set of \ncommand line flags (although there are common ones).\n\nCurrently, `lc0` has the following modes:\n\n| Mode |   Description |\n|------|---------------|\n| uci (*default*) | Acts as a UCI chess engine |\n| selfplay | Plays one or multiple games with itself and optionally generates training data |\n| debug | Generates debug data for a position |\n\nTo run `lc0` in any of those modes, specify a mode name as the first argument (`uci` may be omitted).\nFor example:\n\n```bash\n$ ./lc0 selfplay ...    # For selfplay mode\n$ ./lc0 ...             # For UCI mode\n```\n\nIn any of those modes, it's possible to get help using the `--help` command line argument:\n\n```bash\n$ ./lc0 --help            # Help for UCI mode\n$ ./lc0 selfplay --help   # Help for selfplay mode\n```\n\n## UCI Mode\n\nIn UCI engine mode, all of command line parameters can also be changed using a UCI parameter.\n\nList of command line flags:\n\n| Flag | UCI Parameter | Description |\n|------|---------------|-------------|\n| -w PATH,<br>--weights=PATH | Network weights file path | Path to load network weights from.<br>Default is `<autodiscover>`, which makes it search for the latest (by file date) file in ./ and ./weights/ subdirectories which look like weights. |\n| -t NUM,<br>--threads=NUM | Number of worker threads | Number of (CPU) threads to use.<br> Default is `2`. There's currently no use of making it more than 3 as it's limited by mutex contention which is yet to be optimized. |\n| --nncache=SIZE | NNCache size | Number of positions to store in cache.<br>Default: `2000000` |\n| <nobr>--backend=BACKEND</nobr><br><nobr>--backend-opts=OPTS</nobr> | NN backend to use<br>NN backend parameters | Configuration of backend parameters. Described in details [here](#backendconfiguration).<br>Default depends on particular build type (cuDNN, tensorflow, etc.). |\n| --slowmover=NUM | Scale thinking time | Parameter value `X` means that the whole remaining time is split in such a way that the current move gets `X × Y` seconds, and next moves will get `1 × Y` seconds. However, due to smart pruning, the engine usually doesn't use all allocated time.<br>Default: `2.2`|\n| <nobr>--move-overhead=NUM</nobr> | Move time overhead in milliseconds | How much overhead should the engine allocate for every move (to counteract things like slow connection, interprocess communication, etc.).<br>Default: `100` ms. |\n| <nobr>--minibatch-size=NUM</nobr> | Minibatch size for NN inference | How many positions the engine tries to batch together for computation. Theoretically larger batches may reduce strengths a bit, especially on a small number of playouts.<br>Default is `256`. Every backend/hardware has different optimal value (e.g., `1` if batching is not supported). |\n| <nobr>--max-prefetch=NUM</nobr> | Maximum prefetch nodes per NN call | When the engine can't gather a large enough batch for immediate use, try to prefetch up to `X` positions, which are likely to be useful soon, and put them in the cache.<br>Default: `32`. |\n| <nobr>--cpuct=NUM</nobr> | Cpuct MCTS option | C_puct constant from Upper Confidence Tree search algorithm. Higher values promote more exploration/wider search, lower values promote more confidence/deeper search.<br>Default: `1.2`. |\n| <nobr>--temperature=NUM</nobr> | Initial temperature | Tau value from softmax formula. If equal to 0, the engine also picks the best move to make. Larger values increase randomness while making the move.<br>Default: `0` |\n| <nobr>--tempdecay-moves=NUM</nobr> | Moves with temperature decay | Reduce temperature for every move linearly from initial temperature to `0`, during this number of moves since the game started. `0` disables temperature decay.<br>Default: `0` |\n| -n,<br>--[no-]noise | Add Dirichlet noise to root node | Add noise to root node prior probabilities. This allows the engine to explore moves which are known to be very bad, and this is useful to discover new ideas during training.<br>Default: `false` |\n| <nobr>--[no-]verbose-move-stats | Display verbose move stats | Display `Q`, `V`, `N`, `U` and `P` values of every move candidate after each move.<br>Default: `false` |\n| --[no-]smart-pruning  | Enable smart pruning | Default: `true` |\n| --virtual-loss-bug=NUM | Virtual loss bug | Default: `0` |\n| --fpu-reduction=NUM | First Play Urgency reduction | Default: `0.2` |\n| --cache-history-length=NUM | The length of history to include in the cache | Default: `7` |\n| --extra-virtual-loss=NUM | Extra virtual loss | Default: `0` |\n| -l,<br>--logfile=FILENAME | Do debug logging into a file | Default is off (empty string) |\n\n\n## Configuration Files\n`lc0` supports using a configuration file instead of passing flags on the command line.  The default configuration file is `lc0.config`, but it can be changed with the `--config` command line flag.  `lc0` configuration files only support the long flags that begin with `--`, and there must only be 1 flag per line.  For example:\n```\n# Lines beginning with a # is a comment\n--threads=1\n--minibatch-size=32\n--sticky-checkmate\n# The -- is optional.  The following flags will work as well:\nweights=10445.txt.gz\nsyzygy-paths=syzygy\nlogfile=lc0.log\n```\nYou can tell `lc0` to ignore the default configuration file by passing `--config=` on the command line.  Command line arguments will override any arguments that also exist in the configuration file.\n\n\n## Backend Configuration\n\nTo be explained. That's the most interesting and undocumented!\n\n\n## Selfplay Mode\n\nTo be explained.\n\n\n## Debug Mode\n\nTo be explained.\n"
        },
        {
          "name": "README.md",
          "type": "blob",
          "size": 11.2177734375,
          "content": "[![CircleCI](https://circleci.com/gh/LeelaChessZero/lc0.svg?style=shield)](https://circleci.com/gh/LeelaChessZero/lc0)\n[![AppVeyor](https://ci.appveyor.com/api/projects/status/3245b83otdee7oj7?svg=true)](https://ci.appveyor.com/project/leelachesszero/lc0)\n\n# Lc0\n\nLc0 is a UCI-compliant chess engine designed to play chess via neural network, specifically those of the [LeelaChessZero project](https://lczero.org).\n\n## Downloading source\n\nLc0 can be acquired either via a git clone or an archive download from GitHub. Be aware that there is a required submodule which isn't included in source archives.\n\nFor essentially all purposes, including selfplay game generation and match play, we highly recommend using the latest `release/version` branch (for example `release/0.31`), which is equivalent to using the latest version tag.\n\nVersioning follows the Semantic Versioning guidelines, with major, minor and patch sections. The training server enforces game quality using the versions output by the client and engine.\n\n\nDownload using git:\n\n```shell\ngit clone -b release/0.31 --recurse-submodules https://github.com/LeelaChessZero/lc0.git\n```\n\nIf you have cloned already an old version, fetch, view and checkout a new branch:\n```shell\ngit fetch --all\ngit branch --all\ngit checkout -t remotes/origin/release/0.31\n```\n\n\nIf you prefer to download an archive, you need to also download and place the submodule:\n * Download the [.zip](https://api.github.com/repos/LeelaChessZero/lc0/zipball/release/0.31) file ([.tar.gz](https://api.github.com/repos/LeelaChessZero/lc0/tarball/release/0.31) archive is also available)\n * Extract\n * Download https://github.com/LeelaChessZero/lczero-common/archive/master.zip (also available as [.tar.gz](https://github.com/LeelaChessZero/lczero-common/archive/master.tar.gz))\n * Move the second archive into the first archive's `libs/lczero-common/` folder and extract\n * The final form should look like `<TOP>/libs/lczero-common/proto/`\n\nHaving successfully acquired Lc0 via either of these methods, proceed to the build section below and follow the instructions for your OS.\n\n\n## Building and running Lc0\n\nBuilding should be easier now than it was in the past. Please report any problems you have.\n\nAside from the git submodule, lc0 requires the Meson build system and at least one backend library for evaluating the neural network, as well as the required `zlib`. (`gtest` is optionally used for the test suite.) If your system already has this library installed, they will be used; otherwise Meson will generate its own copy of the two (a \"subproject\"), which in turn requires that git is installed (yes, separately from cloning the actual lc0 repository). Meson also requires python and Ninja.\n\nBackend support includes (in theory) any CBLAS-compatible library for CPU usage, such as OpenBLAS or Intel's DNNL or MKL. For GPUs, OpenCL and CUDA+cudnn are supported, while DX-12 can be used in Windows 10 with latest drivers.\n\nFinally, lc0 requires a compiler supporting C++17. Minimal versions seem to be g++ v8.0, clang v5.0 (with C++17 stdlib) or Visual Studio 2017.\n\n*Note* that cuda checks the compiler version and stops even with newer compilers, and to work around this we have added the `nvcc_ccbin` build option. This is more of an issue with new Linux versions, but you can get around it by using an earlier version of gcc just for cuda. As an example, adding `-Dnvcc_ccbin=g++-9` to the `build.sh` command line will use g++-9 with cuda instead of the system compiler.\n\nGiven those basics, the OS and backend specific instructions are below.\n\n### Linux\n\n#### Generic\n\n1. Install backend:\n    - If you want to use NVidia graphics cards Install [CUDA](https://developer.nvidia.com/cuda-zone) and [cuDNN](https://developer.nvidia.com/cudnn).\n    - If you want to use AMD graphics cards install OpenCL.\n    - if you want OpenBLAS version Install OpenBLAS (`libopenblas-dev`).\n2. Install ninja build (`ninja-build`), meson, and (optionally) gtest (`libgtest-dev`).\n3. Go to `lc0/`\n4. Run `./build.sh`\n5. `lc0` will be in `lc0/build/release/` directory\n6. Unzip a [neural network](https://lczero.org/play/networks/bestnets/) in the same directory as the binary.\n\nIf you want to build with a different compiler, pass the `CC` and `CXX` environment variables:\n\n    CC=clang-6.0 CXX=clang++-6.0 ./build.sh\n\n#### Note on installing CUDA on Ubuntu\n\nNvidia provides .deb packages. CUDA will be installed in `/usr/local/cuda-10.0` and requires 3GB of diskspace.\nIf your `/usr/local` partition doesn't have that much space left you can create a symbolic link before\ndoing the install; for example: `sudo ln -s /opt/cuda-10.0 /usr/local/cuda-10.0`\n\nThe instructions given on the nvidia website tell you to finish with `apt install cuda`. However, this\nmight not work (missing dependencies). In that case use `apt install cuda-10-0`. Afterwards you can\ninstall the meta package `cuda` which will cause an automatic upgrade to a newer version when that\ncomes available (assuming you use `Installer Type deb (network)`, if you'd want that (just cuda-10-0 will\nstay at version 10). If you don't know what to do, only install cuda-10-0.\n\ncuDNN exists of two packages, the Runtime Library and the Developer Library (both a .deb package).\n\nBefore you can download the latter you need to create a (free) \"developer\" account with nvidia for\nwhich at least a legit email address is required (their website says: The e-mail address is not made public\nand will only be used if you wish to receive a new password or wish to receive certain news or notifications\nby e-mail.). Further they ask for a name, date of birth (not visible later on), country, organisation (\"LeelaZero\"\nif you have none), primary industry segment (\"Other\"/none) and which development areas you are interested\nin (\"Deep Learning\").\n\n#### Ubuntu 18.04\n\nFor Ubuntu 18.04 you need the latest version of meson, libstdc++-8-dev, and clang-6.0 before performing the steps above:\n\n    sudo apt-get install libstdc++-8-dev clang-6.0 ninja-build pkg-config\n    pip3 install meson --user\n    CC=clang-6.0 CXX=clang++-6.0 INSTALL_PREFIX=~/.local ./build.sh\n\nMake sure that `~/.local/bin` is in your `PATH` environment variable. You can now type `lc0 --help` and start.\n\n#### Ubuntu 16.04\n\nFor Ubuntu 16.04 you need the latest version of meson, ninja, clang-6.0, and libstdc++-8:\n\n    wget -O - https://apt.llvm.org/llvm-snapshot.gpg.key | sudo apt-key add -\n    sudo apt-add-repository 'deb http://apt.llvm.org/xenial/ llvm-toolchain-xenial-6.0 main'\n    sudo add-apt-repository ppa:ubuntu-toolchain-r/test\n    sudo apt-get update\n    sudo apt-get install clang-6.0 libstdc++-8-dev\n    pip3 install meson ninja --user\n    CC=clang-6.0 CXX=clang++-6.0 INSTALL_PREFIX=~/.local ./build.sh\n\nMake sure that `~/.local/bin` is in your `PATH` environment variable. You can now type `lc0 --help` and start.\n\n#### openSUSE (all versions)\n\nInstructions, packages and tools for building on openSUSE are at [openSUSE_install.md](openSUSE_install.md)\n\n#### Docker\n\nUse https://github.com/vochicong/lc0-docker\nto run latest releases of lc0 and the client inside a Docker container.\n\n\n### Windows\n\nHere are the brief instructions for CUDA/CuDNN, for details and other options see `windows-build.md`.\n\n0. Install Microsoft Visual Studio (2017 or later)\n1. Install [CUDA](https://developer.nvidia.com/cuda-zone)\n2. Install [cuDNN](https://developer.nvidia.com/cudnn).\n3. Install Python3\n4. Install Meson: `pip3 install --upgrade meson`\n5. Edit `build.cmd`:\n\n* Set `CUDA_PATH` with your CUDA directory\n* Set `CUDNN_PATH` with your cuDNN directory (may be the same with CUDA_PATH)\n\n6. Run `build.cmd`. It will ask permission to delete the build directory, then generate MSVS project and pause.\n\nThen either:\n\n7. Hit `Enter` to build it.\n8. Resulting binary will be `build/lc0.exe`\n\nOr.\n\n7. Open generated solution `build/lc0.sln` in Visual Studio and build yourself.\n\n### Mac\n\nFirst you need to install some required packages through Terminal:\n1. Install brew as per the instructions at https://brew.sh/\n2. Install python3: `brew install python3`\n3. Install meson: `brew install meson`\n4. Install ninja: `brew install ninja`\n5. (For Mac OS 10.14 Mojave, or if the other step 5 fails):\n * Install developer tools: ``xcode-select --install``\n * When using Mojave install SDK headers: `installer -pkg /Library/Developer/CommandLineTools/Packages/macOS_SDK_headers_for_macOS_10.14.pkg -target /` (if this doesn't work, use `sudo installer` instead of just `installer`.)\n\nOr.\n\n5. (For MacOS 10.15 Catalina, or if the other step 5 fails): \n * Install Xcode command-line tools: ``xcode-select --install``\n * Install \"XCode Developer Tools\" through the app store. (First one on the list of Apps if searched.)\n * Associate the SDK headers in XCode with a command: export CPATH=\\`xcrun --show-sdk-path\\`/usr/include\n \nNow download the lc0 source, if you haven't already done so, following the instructions earlier in the page.\n\n6. Go to the lc0 directory.\n7. Run `./build.sh -Dgtest=false` (needs step 5)\n\n### Raspberry Pi\n\nYou'll need to be running the latest Raspberry Pi OS \"buster\".\n\n1. Install OpenBLAS\n\n```shell\ngit clone https://github.com/xianyi/OpenBLAS.git\ncd OpenBLAS/\nmake\nsudo make PREFIX=/usr install\ncd ..\n```\n\n2. Install Meson\n\n```shell\npip install meson\npip install ninja\n```\n\n3. Install compiler and standard libraries\n\n```shell\nsudo apt install clang-6.0 libstdc++-8-dev\n```\n\n4. Clone lc0 and compile\n\n```shell\ngit clone https://github.com/LeelaChessZero/lc0.git\ncd lc0\ngit submodule update --init --recursive\nCC=clang-6.0 CXX=clang++-6.0 ./build.sh -Ddefault_library=static\n```\n\n5. The resulting binary will be in build/release\n\n## Python bindings\n\nPython bindings can be built and installed as follows.\n\n```shell\npip install --user git+https://github.com/LeelaChessZero/lc0.git\n```\n\nThis will build the package `lczero-bindings` and install it to your Python user install directory.\nAll the `lc0` functionality related to position evaluation is now available in the module `lczero.backends`.\nAn example interactive session can be found [here](https://github.com/LeelaChessZero/lc0/pull/1261#issuecomment-622951248).\n\n## License\n\nLeela Chess is free software: you can redistribute it and/or modify\nit under the terms of the GNU General Public License as published by\nthe Free Software Foundation, either version 3 of the License, or\n(at your option) any later version.\n\nLeela Chess is distributed in the hope that it will be useful,\nbut WITHOUT ANY WARRANTY; without even the implied warranty of\nMERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\nGNU General Public License for more details.\n\nYou should have received a copy of the GNU General Public License\nalong with Leela Chess.  If not, see <http://www.gnu.org/licenses/>.\n\n### Additional permission under GNU GPL version 3 section 7\n\n_The source files of Lc0 with the exception of the BLAS and OpenCL\nbackends (all files in the `blas` and `opencl` sub-directories) have\nthe following additional permission, as allowed under GNU GPL version 3\nsection 7:_\n\nIf you modify this Program, or any covered work, by linking or\ncombining it with NVIDIA Corporation's libraries from the NVIDIA CUDA\nToolkit and the NVIDIA CUDA Deep Neural Network library (or a\nmodified version of those libraries), containing parts covered by the\nterms of the respective license agreement, the licensors of this\nProgram grant you additional permission to convey the resulting work.\n\n"
        },
        {
          "name": "appveyor.yml",
          "type": "blob",
          "size": 11.16796875,
          "content": "version: '{build}'\nconfiguration: Release\nplatform: x64\nimage:\n- Visual Studio 2019\nenvironment:\n  matrix:\n  - NAME: gpu-nvidia-cudnn\n  - NAME: gpu-nvidia-cuda\n#  - NAME: gpu-dx12\n#  - NAME: gpu-opencl\n  - NAME: cpu-dnnl\n  - NAME: cpu-openblas\n#  - NAME: onednn\n  - NAME: onnx-dml\n  - NAME: android\nfor:\n-\n  matrix:\n    only:\n#    - NAME: gpu-opencl\n    - NAME: cpu-dnnl\n  skip_non_tags: true\nclone_folder: c:\\projects\\lc0\ninstall:\n- cmd: set CUDA=false\n- cmd: set CUDNN=false\n- cmd: set DX=false\n- cmd: set OPENCL=false\n- cmd: set BLAS=false\n- cmd: set ONEDNN=false\n- cmd: set ONNX_DML=false\n- cmd: set GTEST=false\n- cmd: set ANDROID=false\n- cmd: IF %NAME%==android set ANDROID=true\n- cmd: IF %NAME%==gpu-nvidia-cudnn set CUDNN=true\n- cmd: IF %NAME%==gpu-nvidia-cudnn set CUDA=true\n- cmd: IF %NAME%==gpu-nvidia-cuda set CUDA=true\n- cmd: IF %NAME%==gpu-dx12 set DX=true\n- cmd: IF %NAME%==gpu-opencl set OPENCL=true\n- cmd: IF %NAME%==cpu-dnnl set BLAS=true\n- cmd: IF %NAME%==cpu-openblas set BLAS=true\n- cmd: IF %NAME%==cpu-openblas set GTEST=true\n- cmd: IF %NAME%==onednn set ONEDNN=true\n- cmd: IF %NAME%==onnx-dml set ONNX_DML=true\n- cmd: set NET=753723\n- cmd: set NET_HASH=3e3444370b9fe413244fdc79671a490e19b93d3cca1669710ffeac890493d198\n- cmd: IF NOT %OPENCL%==true IF NOT %DX%==true set NET=791556\n- cmd: IF NOT %OPENCL%==true IF NOT %DX%==true set NET_HASH=f404e156ceb2882470fd8c032b8754af0fa0b71168328912eaef14671a256e34\n- cmd: call \"C:\\Program Files (x86)\\Microsoft Visual Studio\\2019\\Community\\VC\\Auxiliary\\Build\\vcvarsall.bat\" amd64\n- cmd: set DNNL_NAME=dnnl_win_1.5.0_cpu_vcomp\n- cmd: IF %NAME%==cpu-dnnl IF NOT EXIST C:\\cache\\%DNNL_NAME% appveyor DownloadFile https://github.com/oneapi-src/oneDNN/releases/download/v1.5/dnnl_win_1.5.0_cpu_vcomp.zip\n- cmd: IF %NAME%==cpu-dnnl IF NOT EXIST C:\\cache\\%DNNL_NAME% 7z x dnnl_win_1.5.0_cpu_vcomp.zip -oC:\\cache\n- cmd: IF %NAME%==onednn set DNNL_NAME=dnnl_win_2.7.2_cpu_vcomp_gpu_vcomp\n- cmd: IF %NAME%==onednn IF NOT EXIST C:\\cache\\%DNNL_NAME% appveyor DownloadFile https://github.com/borg323/oneDNN/releases/download/v2.7.2/dnnl_win_2.7.2_cpu_vcomp_gpu_vcomp.zip\n- cmd: IF %NAME%==onednn IF NOT EXIST C:\\cache\\%DNNL_NAME% 7z x dnnl_win_2.7.2_cpu_vcomp_gpu_vcomp.zip -oC:\\cache\n- cmd: IF %NAME%==onnx-dml IF NOT EXIST C:\\cache\\onnxruntime-win-x64-dml-1.13.1 appveyor DownloadFile https://github.com/borg323/onnxruntime/releases/download/v1.13.1/onnxruntime-win-x64-dml-1.13.1.zip\n- cmd: IF %NAME%==onnx-dml IF NOT EXIST C:\\cache\\onnxruntime-win-x64-dml-1.13.1 7z x onnxruntime-win-x64-dml-1.13.1.zip -oC:\\cache\n- cmd: IF %NAME%==onnx-dml set ONNX_NAME=onnxruntime-win-x64-dml-1.13.1\n- cmd: IF %NAME%==cpu-openblas IF NOT EXIST C:\\cache\\OpenBLAS appveyor DownloadFile https://sjeng.org/ftp/OpenBLAS-0.3.3-win-oldthread.zip\n- cmd: IF %NAME%==cpu-openblas IF NOT EXIST C:\\cache\\OpenBLAS 7z x OpenBLAS-0.3.3-win-oldthread.zip -oC:\\cache\\OpenBLAS\n- cmd: IF %OPENCL%==true nuget install opencl-nug -Version 0.777.77 -OutputDirectory C:\\cache\n- cmd: set ISPC=%BLAS%\n- cmd: IF %NAME%==android set ISPC=true\n- cmd: IF %ISPC%==true IF NOT EXIST C:\\cache\\ispc-v1.13.0-windows appveyor DownloadFile https://github.com/ispc/ispc/releases/download/v1.13.0/ispc-v1.13.0-windows.zip\n- cmd: IF %ISPC%==true IF NOT EXIST C:\\cache\\ispc-v1.13.0-windows 7z x ispc-v1.13.0-windows.zip -oC:\\cache\\ispc-v1.13.0-windows\n- cmd: IF %ISPC%==true set PATH=C:\\cache\\ispc-v1.13.0-windows\\bin;%PATH%\n- cmd: set \"CUDA_PATH=C:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v10.1\"\n- cmd: IF %CUDNN%==true IF NOT EXIST \"%CUDA_PATH%\\cuda\" set CUDNN_INSTALL=1\n- cmd: IF DEFINED CUDNN_INSTALL appveyor DownloadFile https://developer.download.nvidia.com/compute/cuda/10.1/Prod/network_installers/cuda_10.1.243_win10_network.exe\n- cmd: IF DEFINED CUDNN_INSTALL cuda_10.1.243_win10_network -s nvcc_10.1 cublas_dev_10.1 cublas_10.1 cudart_10.1\n- cmd: IF DEFINED CUDNN_INSTALL appveyor DownloadFile https://developer.download.nvidia.com/compute/redist/cudnn/v7.5.1/cudnn-10.1-windows10-x64-v7.5.1.10.zip\n- cmd: IF DEFINED CUDNN_INSTALL 7z x cudnn-10.1-windows10-x64-v7.5.1.10.zip -o\"%CUDA_PATH%\"\n- cmd: IF %CUDNN%==false set \"CUDA_PATH=C:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v11.1\"\n- cmd: IF %CUDA%==true IF NOT EXIST \"%CUDA_PATH%\" set CUDA_INSTALL=1\n- cmd: IF DEFINED CUDA_INSTALL appveyor DownloadFile https://developer.download.nvidia.com/compute/cuda/11.1.0/network_installers/cuda_11.1.0_win10_network.exe\n- cmd: IF DEFINED CUDA_INSTALL cuda_11.1.0_win10_network.exe -s nvcc_11.1 cublas_dev_11.1 cublas_11.1 cudart_11.1 documentation_11.1\n- cmd: IF %CUDA%==true set PATH=%CUDA_PATH%\\bin;%PATH%\n- cmd: set PATH=C:\\Python310;C:\\Python310\\scripts;%PATH%\n#- cmd: pip3 install --upgrade meson==0.55.3\n- cmd: set MIMALLOC_PATH=C:\\cache\\mimalloc-1.8.7\n- cmd: IF %ANDROID%==false IF NOT EXIST \"%MIMALLOC_PATH%\" appveyor DownloadFile https://github.com/microsoft/mimalloc/archive/refs/tags/v1.8.7.zip\n- cmd: IF %ANDROID%==false IF NOT EXIST \"%MIMALLOC_PATH%\" 7z x v1.8.7.zip -oC:\\cache\\\n- cmd: IF %ANDROID%==false IF NOT EXIST \"%MIMALLOC_PATH%\"\\out msbuild \"%MIMALLOC_PATH%\"\\ide\\vs2019\\mimalloc-override.vcxproj /p:Configuration=Release /m\n- cmd: IF %NAME%==android IF NOT EXIST C:\\ndk\\android-ndk-r27c\\toolchains\\llvm\\prebuilt\\windows-x86_64 appveyor DownloadFile https://dl.google.com/android/repository/android-ndk-r27c-windows.zip\n- cmd: IF %NAME%==android IF NOT EXIST C:\\ndk\\android-ndk-r27c\\toolchains\\llvm\\prebuilt\\windows-x86_64 7z x android-ndk-r27c-windows.zip -oC:\\ndk\n- cmd: IF %NAME%==android set PATH=C:\\ndk\\android-ndk-r27c\\toolchains\\llvm\\prebuilt\\windows-x86_64\\bin;%PATH%\n- cmd: IF %NAME%==android sed \"s/clang+*/&.cmd/\" cross-files/aarch64-linux-android >crossfile-aarch64\n- cmd: IF %NAME%==android IF NOT EXIST C:\\cache\\OpenBLAS\\android-aarch64 appveyor DownloadFile https://github.com/borg323/OpenBLAS/releases/download/android-0.3.27/openblas-android-aarch64.zip\n- cmd: IF %NAME%==android IF NOT EXIST C:\\cache\\OpenBLAS\\android-aarch64 7z x openblas-android-aarch64.zip -oC:\\cache\\OpenBLAS\n- cmd: IF %NAME%==android sed \"s/clang+*/&.cmd/\" cross-files/armv7a-linux-android >crossfile-armv7a\n- cmd: IF %NAME%==android IF NOT EXIST C:\\cache\\OpenBLAS\\android-armv7a appveyor DownloadFile https://github.com/borg323/OpenBLAS/releases/download/android-0.3.27/openblas-android-armv7a.zip\n- cmd: IF %NAME%==android IF NOT EXIST C:\\cache\\OpenBLAS\\android-armv7a 7z x openblas-android-armv7a.zip -oC:\\cache\\OpenBLAS\n- cmd: set PKG_FOLDER=\"C:\\cache\"\n- cmd: IF NOT EXIST c:\\cache mkdir c:\\cache\n- cmd: IF NOT EXIST c:\\cache\\%NET%.pb.gz appveyor DownloadFile http://training.lczero.org/get_network?sha=%NET_HASH% -Filename c:\\cache\\%NET%.pb.gz\n- cmd: touch -t 201801010000.00 c:\\cache\\%NET%.pb.gz\n- cmd: IF %GTEST%==true IF NOT EXIST C:\\cache\\syzygy mkdir C:\\cache\\syzygy\n- cmd: IF %GTEST%==true cd C:\\cache\\syzygy\n- cmd: IF %GTEST%==true IF NOT EXIST KQvK.rtbz curl --remote-name-all https://tablebase.lichess.ovh/tables/standard/3-4-5/K{P,N,R,B,Q}vK.rtb{w,z}\n- cmd: IF %GTEST%==true IF NOT EXIST KQQvK.rtbz curl --remote-name-all https://tablebase.lichess.ovh/tables/standard/3-4-5/K{P,N,R,B,Q}{P,N,R,B,Q}vK.rtb{w,z}\n- cmd: IF %GTEST%==true IF NOT EXIST KQvKQ.rtbz curl --remote-name-all https://tablebase.lichess.ovh/tables/standard/3-4-5/K{P,N,R,B,Q}vK{P,N,R,B,Q}.rtb{w,z}\n- cmd: cd C:\\projects\\lc0\ncache:\n  - C:\\cache\n  - 'C:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v10.1'\n  - 'C:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v11.1'\n  - C:\\projects\\lc0\\subprojects\\packagecache\n  - C:\\ndk\\android-ndk-r27c\\toolchains\\llvm\\prebuilt\\windows-x86_64\nbefore_build:\n- cmd: git submodule update --init --recursive\n- cmd: IF %BLAS%==true (echo.#define DEFAULT_MAX_PREFETCH 0 & echo.#define DEFAULT_TASK_WORKERS 0) > params_override.h\n- cmd: IF %ANDROID%==true (echo.#define DEFAULT_MAX_PREFETCH 0 & echo.#define DEFAULT_TASK_WORKERS 0) > params_override.h\n- cmd: SET BUILD_BLAS=%BLAS%\n- cmd: IF %OPENCL%==true SET BUILD_BLAS=true\n- cmd: IF %DX%==true SET BUILD_BLAS=true\n- cmd: SET EMBED=false\n- cmd: IF %APPVEYOR_REPO_TAG%==true IF %ANDROID%==true SET EMBED=true\n- cmd: SET POPCNT=true\n- cmd: IF %NAME%==cpu-openblas SET POPCNT=false\n- cmd: SET F16C=true\n- cmd: IF %NAME%==cpu-openblas SET F16C=false\n- cmd: IF %CUDA%==true SET F16C=false\n- cmd: SET EXTRA=\n- cmd: IF %ANDROID%==false SET EXTRA=-Db_vscrt=md\n- cmd: IF %ONNX_DML%==true SET EXTRA=-Db_vscrt=md -Donnx_libdir=C:\\cache\\%ONNX_NAME%\\lib -Donnx_include=C:\\cache\\%ONNX_NAME%\\include\n- cmd: IF %ANDROID%==false meson build --backend vs2019 --buildtype release -Dgtest=%GTEST% -Dopencl=%OPENCL% -Dblas=%BUILD_BLAS% -Ddnnl=true -Ddx=%DX% -Dcudnn=%CUDNN% -Donednn=%ONEDNN% -Dispc_native_only=false -Dnative_cuda=false -Dpopcnt=%POPCNT% -Df16c=%F16C% -Dcudnn_include=\"%CUDA_PATH%\\include\",\"%CUDA_PATH%\\cuda\\include\" -Dcudnn_libdirs=\"%CUDA_PATH%\\lib\\x64\",\"%CUDA_PATH%\\cuda\\lib\\x64\" -Dopenblas_include=\"%PKG_FOLDER%\\OpenBLAS\\dist64\\include\" -Dopenblas_libdirs=\"%PKG_FOLDER%\\OpenBLAS\\dist64\\lib\" -Ddnnl_dir=\"%PKG_FOLDER%\\%DNNL_NAME%\" -Dopencl_include=\"%PKG_FOLDER%\\opencl-nug.0.777.77\\build\\native\\include\" -Dopencl_libdirs=\"%PKG_FOLDER%\\opencl-nug.0.777.77\\build\\native\\lib\\x64\" -Ddefault_library=static -Dmalloc=mimalloc -Dmimalloc_libdir=\"%MIMALLOC_PATH%\"\\out\\msvc-x64\\Release %EXTRA%\n- cmd: IF %ANDROID%==true meson arm64-v8a --buildtype release -Dgtest=false -Dopenblas_include=\"%PKG_FOLDER%\\OpenBLAS\\android-aarch64\\include\" -Dopenblas_libdirs=\"%PKG_FOLDER%\\OpenBLAS\\android-aarch64\\lib\" -Dembed=%EMBED% -Ddefault_library=static --cross-file crossfile-aarch64\n- cmd: IF %ANDROID%==true meson armeabi-v7a --buildtype release -Dgtest=false -Dopenblas_include=\"%PKG_FOLDER%\\OpenBLAS\\android-armv7a\\include\" -Dopenblas_libdirs=\"%PKG_FOLDER%\\OpenBLAS\\android-armv7a\\lib\" -Dembed=%EMBED% -Ddefault_library=static --cross-file crossfile-armv7a -Dispc=false -Dneon=false\nbuild_script:\n- cmd: IF %ANDROID%==false call scripts\\appveyor_win_build.cmd\n- cmd: IF %ANDROID%==true call scripts\\appveyor_android_build.cmd\n- cmd: cd C:\\projects\\lc0\nafter_build:\n- cmd: IF %APPVEYOR_REPO_TAG%==true IF %ANDROID%==false call scripts\\appveyor_win_package.cmd\n- cmd: IF %APPVEYOR_REPO_TAG%==true IF %ANDROID%==true call scripts\\appveyor_android_package.cmd\n- cmd: cd C:\\projects\\lc0\nartifacts:\n  - path: build/lc0.exe\n    name: lc0-$(NAME)\n  - path: arm64-v8a/lc0\n    name: lc0-android-arm64-v8a\n  - path: armeabi-v7a/lc0\n    name: lc0-android-armeabi-v7a\n  - path: /lc0*.zip/\n    name: lc0-$(APPVEYOR_REPO_TAG_NAME)-windows-$(NAME)-zip\n  - path: build/lc0.pdb\n    name: lc0-debug-symbols\n  - path: /lc0*.apk/\n    name: lc0-$(APPVEYOR_REPO_TAG_NAME)-android-apk\n  - path: dnnl.dll\n    name: dnnl-dll\ndeploy:\n  - provider: GitHub\n    artifact: /.*\\.zip/\n    auth_token:\n      secure: USFAdwQKTXqOXQjCYQfzWvzRpUhvqJLBkN4hbOg+j876vDxGZHt9bMYayb5evePp\n    on:\n      appveyor_repo_tag: true\n  - provider: GitHub\n    artifact: /.*\\.apk/\n    auth_token:\n      secure: USFAdwQKTXqOXQjCYQfzWvzRpUhvqJLBkN4hbOg+j876vDxGZHt9bMYayb5evePp\n    on:\n      appveyor_repo_tag: true\ntest_script:\n- cmd: IF %GTEST%==true cd build\n- cmd: IF %GTEST%==true xcopy /s /i C:\\cache\\syzygy syzygy\n- cmd: IF %GTEST%==true meson test --print-errorlogs\n- cmd: cd C:\\projects\\lc0\non_finish:\n- cmd: IF %GTEST%==true cd C:\\projects\\lc0\\build\n- cmd: IF %GTEST%==true for %%a in (*.xml) do curl -F file=@%%a https://ci.appveyor.com/api/testresults/junit/%APPVEYOR_JOB_ID%\n- cmd: cd C:\\projects\\lc0\n"
        },
        {
          "name": "build.cmd",
          "type": "blob",
          "size": 2.509765625,
          "content": "@echo off\nsetlocal\n\nrem 1. Set the following for the options you want to build.\nset CUDNN=true\nset CUDA=true\nset DX12=false\nset OPENCL=false\nset MKL=false\nset DNNL=false\nset OPENBLAS=false\nset EIGEN=false\nset TEST=false\n\nrem 2. Edit the paths for the build dependencies.\nset CUDA_PATH=C:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v10.0\nset CUDNN_PATH=%CUDA_PATH%\nset OPENBLAS_PATH=C:\\OpenBLAS\nset MKL_PATH=C:\\Program Files (x86)\\IntelSWTools\\compilers_and_libraries\\windows\\mkl\nset DNNL_PATH=C:\\dnnl_win_1.1.1_cpu_vcomp\nset OPENCL_LIB_PATH=%CUDA_PATH%\\lib\\x64\nset OPENCL_INCLUDE_PATH=%CUDA_PATH%\\include\n\nrem 3. In most cases you won't need to change anything further down.\necho Deleting build directory:\nrd /s build\n\nset CC=cl\nset CXX=cl\nset CC_LD=link\nset CXX_LD=link\n\nif exist \"C:\\Program Files\\Microsoft Visual Studio\\2022\" (\n  where /q cl\n  if errorlevel 1 call \"C:\\Program Files\\Microsoft Visual Studio\\2022\\Community\\VC\\Auxiliary\\Build\\vcvarsall.bat\" amd64\n  set backend=vs2022\n) else if exist \"C:\\Program Files (x86)\\Microsoft Visual Studio\\2019\" (\n  where /q cl\n  if errorlevel 1 call \"C:\\Program Files (x86)\\Microsoft Visual Studio\\2019\\Community\\VC\\Auxiliary\\Build\\vcvarsall.bat\" amd64\n  set backend=vs2019\n) else (\n  where /q cl\n  if errorlevel 1 call \"C:\\Program Files (x86)\\Microsoft Visual Studio\\2017\\Community\\VC\\Auxiliary\\Build\\vcvarsall.bat\" amd64\n  set backend=vs2017\n)\n\nset BLAS=true\nif %MKL%==false if %DNNL%==false if %OPENBLAS%==false if %EIGEN%==false set BLAS=false\n\nif \"%CUDA_PATH%\"==\"%CUDNN_PATH%\" (\n  set CUDNN_LIB_PATH=%CUDNN_PATH%\\lib\\x64\n  set CUDNN_INCLUDE_PATH=%CUDNN_PATH%\\include\n) else (\n  set CUDNN_LIB_PATH=%CUDA_PATH%\\lib\\x64,%CUDNN_PATH%\\lib\\x64\n  set CUDNN_INCLUDE_PATH=%CUDA_PATH%\\include,%CUDNN_PATH%\\include\n)\n\nif %CUDNN%==true set PATH=%CUDA_PATH%\\bin;%PATH%\n\nmeson setup build --backend %backend% --buildtype release -Ddx=%DX12% -Dcudnn=%CUDNN% -Dplain_cuda=%CUDA% ^\n-Dopencl=%OPENCL% -Dblas=%BLAS% -Dmkl=%MKL% -Dopenblas=%OPENBLAS% -Ddnnl=%DNNL% -Dgtest=%TEST% ^\n-Dcudnn_include=\"%CUDNN_INCLUDE_PATH%\" -Dcudnn_libdirs=\"%CUDNN_LIB_PATH%\" ^\n-Dmkl_include=\"%MKL_PATH%\\include\" -Dmkl_libdirs=\"%MKL_PATH%\\lib\\intel64\" -Ddnnl_dir=\"%DNNL_PATH%\" ^\n-Dopencl_libdirs=\"%OPENCL_LIB_PATH%\" -Dopencl_include=\"%OPENCL_INCLUDE_PATH%\" ^\n-Dopenblas_include=\"%OPENBLAS_PATH%\\include\" -Dopenblas_libdirs=\"%OPENBLAS_PATH%\\lib\" ^\n-Ddefault_library=static\n\nif errorlevel 1 exit /b\n\npause\n\ncd build\n\nmsbuild /m /p:Configuration=Release /p:Platform=x64 /p:WholeProgramOptimization=true ^\n/p:PreferredToolArchitecture=x64 lc0.sln /filelogger\n"
        },
        {
          "name": "build.sh",
          "type": "blob",
          "size": 0.75,
          "content": "#!/usr/bin/env bash\n\nset -e\n\n# Move to this script's directory.\nCDPATH= cd -- \"$(dirname -- \"$0\")\"\n\ncase $1 in\n  plain|debug|debugoptimized|release|minsize)\n    BUILDTYPE=$1\n    shift\n    ;;\n  *)\n    BUILDTYPE=release\n    ;;\nesac\n\nBUILDDIR=build/${BUILDTYPE}\n\nMESON=$(PATH=\"${PATH}:${HOME}/.local/bin\" command -v meson || :)\nMESON=${MESON:?\"Could not find meson. Is it installed and in PATH?\"}\n\nif [ -f \"${BUILDDIR}/build.ninja\" ]\nthen\n  \"${MESON}\" configure \"${BUILDDIR}\" -Dbuildtype=\"${BUILDTYPE}\" -Dprefix=\"${INSTALL_PREFIX:-/usr/local}\" \"$@\"\nelse\n  \"${MESON}\" \"${BUILDDIR}\" --buildtype \"${BUILDTYPE}\" --prefix \"${INSTALL_PREFIX:-/usr/local}\" \"$@\"\nfi\n\n\"${MESON}\" compile -C \"${BUILDDIR}\"\n\nif [ -n \"${INSTALL_PREFIX}\" ]\nthen\n  \"${MESON}\" install -C \"${BUILDDIR}\"\nfi\n"
        },
        {
          "name": "build_rescorer.cmd",
          "type": "blob",
          "size": 1.01953125,
          "content": "@echo off\nsetlocal\n\necho Deleting build directory:\nrd /s build\n\nset CC=cl\nset CXX=cl\nset CC_LD=link\nset CXX_LD=link\n\nif exist \"C:\\Program Files\\Microsoft Visual Studio\\2022\" (\n  where /q cl\n  if errorlevel 1 call \"C:\\Program Files\\Microsoft Visual Studio\\2022\\Community\\VC\\Auxiliary\\Build\\vcvarsall.bat\" amd64\n  set backend=vs2022\n) else if exist \"C:\\Program Files (x86)\\Microsoft Visual Studio\\2019\" (\n  where /q cl\n  if errorlevel 1 call \"C:\\Program Files (x86)\\Microsoft Visual Studio\\2019\\Community\\VC\\Auxiliary\\Build\\vcvarsall.bat\" amd64\n  set backend=vs2019\n) else (\n  where /q cl\n  if errorlevel 1 call \"C:\\Program Files (x86)\\Microsoft Visual Studio\\2017\\Community\\VC\\Auxiliary\\Build\\vcvarsall.bat\" amd64\n  set backend=vs2017\n)\n\nmeson build --backend %backend% --buildtype release -Drescorer=true -Dlc0=false -Dgtest=false -Ddefault_library=static\n\nif errorlevel 1 exit /b\n\npause\n\ncd build\n\nmsbuild /m /p:Configuration=Release /p:Platform=x64 /p:WholeProgramOptimization=true ^\n/p:PreferredToolArchitecture=x64 rescorer.sln /filelogger\n"
        },
        {
          "name": "changelog.txt",
          "type": "blob",
          "size": 48.30859375,
          "content": "﻿v0.31.0-rc1 (2024-03-25)\n~~~~~~~\n* The blas, cuda, eigen, metal and onnx backends now have support for multihead\n  network architecture and can run BT3/BT4 nets.\n* Updated the internal Elo model to better align with regular Elo for human\n  players.\n* There is a new XLA backend that uses OpenXLA compiler to produce code to\n  execute the neural network. See\n  <https://github.com/LeelaChessZero/lc0/wiki/XLA-backend> for details. Related\n  are new leela2onnx options to output the HLO format that XLA understands.\n* There is a vastly simplified lc0 interface available by renaming the\n  executable to `lc0simple`.\n* The backends can now suggest a minibatch size to the search, this is enabled\n  by `--minibatch-size=0` (the new default).\n* If the cudnn backend detected an unsupported network architecture it will\n  switch to the cuda backend.\n* Two new selfplay options enable value and policy tournaments. A policy\n  tournament is using a single node policy to select the move to play, while a\n  value tournament searches all possible moves at depth 1 to select the one with\n  the best q.\n* While it is easy to get a single node policy evaluation (`go nodes 1` using\n  uci), there was no simple way to get the effect of a value only evalaution, so\n  the `--value-only` option was added.\n* Button uci options were implemented and a button to clear the tree was added\n  (as hidden option).\n* Support for the uci `go mate` option was added.\n* The rescorer can now be built from the lc0 code base instead of a separate\n  branch.\n* A dicrete onnx layernorm implementation was added to get around a onnxruntime\n  bug with directml - this has some overhead so it is only enabled for onnx-dml\n  and can be switched off with the `alt_layernorm=false` backend option.\n* The `--onnx2pytoch` option was added to leela2onnx to generate pytorch\n  compatible models.\n* There is a cuda `min_batch` backend option to reduce non-determinism with\n  small batches.\n* New options were added to onnx2leela to fix tf exported onnx models.\n* The onnx backend can now be built for amd's rocm.\n* Fixed a bug where the Contempt effect on eval was too low for nets with\n  natively higher draw rates.\n* Made the WDL Rescale sharpness limit configurable via the `--wdl-max-s` hidden\n  option.\n* Several assorted fixes and code cleanups.\n\nv0.30.0 (2023-07-21)\n~~~~~~~\n* WDL_mu score type is now the default and the mlh-threshold default was\n  changed from 0 to 0.8.\n* Fixes for contempt with infinite search and pondering and for the wdl display\n  when pondering.\n\nv0.30.0-rc2 (2023-06-15)\n~~~~~~~\n* WDL conversion for more realistic WDL score and contempt. Adds an Elo based\n  WDL transformation of the NN value head output. Helps with more accurate play\n  at high level (WDL sharpening), more aggressive play against weaker opponents\n  and draw avoiding openings (contempt), piece odds play. There will be a blog\n  post soon explaining in detail how it works.\n* A new score type `WDL_mu` which follows the new eval convention, where +1.00\n  means 50% white win chance.\n* Simplified to a single `--draw-score` parameter, adjusting the draw score from\n  white's perspective: 0 gives standard scoring, -1 gives Armageddon scoring.\n* Updated describenet for new net architectures.\n* Added a `first-move-bonus` option to the legacy time manager, to accompany\n  `book-ply-bonus` for shallow openings.\n* Changed mlh threshold effect to create a smooth transition.\n* Revised 'simple' time manager.\n* A new spinlock implementation (selected with `--search-spin-backoff`) to help\n  with many cpu threads (e.g. 128 threads), obviously for cpu backends only.\n* Some assorted fixes and code cleanups.\n\nv0.30.0-rc1 (2023-04-24)\n~~~~~~~\n* Support for networks with attention body and smolgen added to blas, cuda,\n  metal and onnx backends.\n* Persistent L2 cache optimization for the cuda backend. Use the\n  `cache_opt=true` backend option to turn it on.\n* Some performance improvements for the cuda, onnx and blas backends.\n* Added the `threads` backend option to onnx, defaults to 0 (let the\n  onnxruntime decide) except for onnx-cpu that defaults to 1.\n* The onnx-dml package now includes a `directml.dll` installation script.\n* Some users experienced memory issues with onnx-dml, so the defaults were\n  changed. This may affect performance, in which case you can use the `steps=8`\n  backend option to get the old behavior.\n* The Python bindings are available as a package, see the README for\n  instructions.\n* Some assorted fixes and code cleanups.\n\nv0.29.0 (2022-12-13)\n~~~~~~~\n* Updated onednn version to the latest one.\n\nv0.29.0-rc1 (2022-12-09)\n~~~~~~~\n* New metal backend for apple systems. This is now the default backend for\n  macos builds.\n* New onnx-dml backend to use DirectML under windows, has better net\n  compatibility than dx12 and is faster than opencl. See the README for use\n  instructions, a separate download of the DirectML dll is required.\n* Full attention policy support in cuda, cudnn, metal, onnx, blas, dnnl, and\n  eigen backends.\n* Partial attention policy support in onednn backend (good enough for T79).\n* Now the onnx backends can use fp16 when running with a network file (not with\n  .onnx model files). This is the default for onnx-cuda and onnx-dml, can be\n  switched on or off with by setting the `fp16` backend option to `true` or\n  `false` respectively.\n* The onednn package comes with a dnnl compiled to allow running on an intel gpu\n  by adding `gpu=0` to the backend options.\n* The default net is now 791556 for most backends except opencl and dx12 that\n  get 753723 (as they lack attention policy support).\n* Support for using pgn book with long lines in training: selfplay can start at\n  a random point in the book.\n* New \"simple\" time manager.\n* Support for double Fischer random chess (dfrc).\n* Added TC-dependent output to the backendbench assistant.\n* Starting with this version, the check backend compares policy for valid moves\n  after softmax.\n* Some assorted fixes and code cleanups.\n\nv0.29.0-rc0 (2022-04-03)\n~~~~~~~\n* Initial support for attention policy, only cuda backend and partially in\n  blas/dnnl/eigen (good enough for T79).\n* Non multigather (legacy) search code and `--multigather` option are removed.\n* 15b default net is now 753723.\n* The onnx backend now allows selecting gpu to use.\n* Improved error messages for unsupported network files.\n* Some assorted fixes.\n\nv0.28.2 (2021-12-13)\n~~~~~~~\n* No changes from v0.28.1-rc1 as the v0.28.1 release was botched.\n\nv0.28.1 (2021-12-12)\n~~~~~~~\n* No changes from rc1.\n\nv0.28.1-rc1 (2021-12-05)\n~~~~~~~\n* Improved cuda performance for 512 filter networks on Amprere GPUs.\n* Several fixes for the onnx backend.\n* Command line options for network file conversion to/from onnx.\n* Documentation updates.\n* Correctness fixes for rescorer support functions.\n\nv0.28.0 (2021-08-25)\n~~~~~~~\n* Fixed an issue with small third-party nets on the cuda/cudnn backends.\n* Minor tweak to the default task-workers for the cpu packages.\n\nv0.28.0-rc2 (2021-08-20)\n~~~~~~~\n* The cuda backend option multi_stream is now off by default. You should\n  consider setting it to on if you have a recent gpu with a lot of vram.\n* The default time manager is back to \"legacy\".\n* Updated default parameters.\n* Newer and stronger nets are included in the release packages.\n* Added support for onnx network files and runtime with the \"onnx\" backend.\n* Several bug and stability fixes.\n\nv0.28.0-rc1 (2021-06-16)\n~~~~~~~\n* Multigather is now made the default (and also improved). Some search settings\n  have changed meaning, so if you have modified values please discard them.\n  Specifically, `max-collision-events`, `max-collision-visits` and\n `max-out-of-order-evals-factor` have changed default values, but other options\n  also affect the search. Similarly, check that your gui is not caching the old\n  values.\n* Performance improvements for the cuda/cudnn backends.\n* Support for policy focus during training.\n* Larger/stronger 15b default net for all packages except android, blas and dnnl\n  that get a new 10b network.\n* The distributed binaries come with the mimalloc memory allocator for better\n  performance when a large tree has to be destroyed (e.g. after an unexpected\n  move).\n* The `legacy` time manager will use more time for the first move after a long\n  book line.\n* The `--preload` command line flag will initialize the backend and load the\n  network during startup.\n* A 'fen' command was added as a UCI extension to print the current position.\n* Experimental onednn backend for recent intel cpus and gpus.\n\nv0.27.0 (2021-02-21)\n~~~~~~~\n* A better value for the backendbench Clippy threshold.\n\nv0.27.0-rc2 (2021-02-18)\n~~~~~~~\n* Fix additional cases where 'invalid move' could be incorrectly reported.\n* Replace WDL softmax in cudnn backend with same implementation as cuda\n  backend. This fixes some inaccuracy issues that were causing training\n  data to be rejected at a fairly low frequency.\n* Ensure that training data Q/D pairs form valid WDL targets even if there\n  is accumulated drift in calculation.\n* Fix for the calculation of the 'best q is proven' bit in training data.\n* Multiple fixes for timelosses and infinite instamoving in smooth time\n  manager. Smooth time manager now made default after these fixes.\n\nv0.27.0-rc1 (2021-02-06)\n~~~~~~~\n* Fix a bug which meant `position ... moves ...` didn't work if the moves \n  went off the end of the existing tree. \n\nv0.27.0-rc0 (2021-02-06)\n~~~~~~~\n* Multigather search inspired by Ceres.\n* V6 training format with additional info for training experiments.\n* Updated default search parameters.\n* A better algorithm for the backendbench assistant.\n* Terminate search early if only 1 move isn't a proven loss.\n* Various build system changes.\n\nv0.26.3 (2020-10-10)\n~~~~~~~\n* Increased maximum value of TempDecayMoves.\n\nv0.26.3-rc2 (2020-10-03)\n~~~~~~~\n* Fix for uninitialized variable that led to crashes with the cudnn backend.\n* Correct windows support for systems with more than 64 threads.\n* A new package is built for the `cuda` backend with cuda 11.1. The old cuda\n  package is renamed to `cudnn`.\n\nv0.26.3-rc1 (2020-09-28)\n~~~~~~~\n* Residual block fusion optimization for cudnn backend, that depends on\n  `custom_winograd=true`. Enabled by default only for networks with up to 384\n  filters in fp16 mode and never in fp32 mode. Default can be overridden with\n  `--backend-opts=res_block_fusing=false` to disable (or `=true` to enable).\n* New experimental cuda backend without cudnn dependency (`cuda-auto`, `cuda`\n  and `cuda-fp16` are available).\n\nv0.26.2 (2020-08-31)\n~~~~~~~\n* No changes from rc1.\n\nv0.26.2-rc1 (2020-08-28)\n~~~~~~~~~~~\n* Repetitions in the search tree are marked as draws, to explore more promising\n  lines. Enabled by default (except in selfplay mode) use\n  `--two-fold-draws=false` to disable.\n* Syzygy tablebase files can now be used in selfplay. Still need to add\n  adjudication support before we can consider using this for training.\n* Default net updated to 703810.\n* Fix for book with CR/LF line endings.\n* Updated Eigen wrap to use new download link.\n\nv0.26.1 (2020-07-15)\n~~~~~~~\n* Fix a bug where invalid openings-pgn settings would result in the book\n  being ignored rather than used.\n* Add support for compressed book files.\n\nv0.26.0 (2020-07-03)\n~~~~~~~\n* No changes from rc1.\n\nv0.26.0-rc1 (2020-06-29)\n~~~~~~~~~~~\n\n* Verbose move stats now includes a line for the root node itself.\n* Added optional `alphazero` time manager type for fixed fraction of \n  remaining time per move. \n* The WL score is now tracked with double pecision to improve accuracy\n  during very long search.\n* Fix for a performance bug when playing from tablebase position with\n  tablebases enabled and the PV move was changing frequently.\n* Illegal searchmove restrictions will now be ignored rather than crash.\n* Policy is cleared for terminal losses to encourage better quality MLH\n  estimates by reducing how many visits a move that will not be selected\n  (unless all other options are equally bad) receives.\n* Smart pruning will now cause leela to play immediately once mate score has\n  been declared.\n* Fix an issue where sometimes the pv reported wouldn't match the move that\n  would be selected at that moment.\n* Improvement for logic for when to disable custom_winograd optimization to\n  avoid running out of video ram.\n* `--show-hidden` can now be specified after `--help` and still work.\n* Performance tuning for populating the policy into nodes after nn eval\n  completes.\n* Enable custom optimized SE paths for nets with 384 filters when using the\n  custom_winograd=false path.\n* Updates to zlib/gtest/eigen when included via meson wrap.\n* Added build option to build python bindings to the lc0 engine.\n* Only show the git hash in uci name if not a release tag build.\n* Add `--nps-limit` option to artificially reduce nps to make for easier\n  opponent or whatever other reason you want.\n* Fixed a bug where search tree shape could be affected even when the\n  `--smart-pruning-factor` setting was 0.\n* Changed the search logic to find the lc0.config file if left on the default\n  value.\n* Changed the search logic to find network files in autodiscover mode.\n* Changed the logic to determine the default location for training games\n  generated by selfplay in training mode.\n* Changed the logic to decide where to look for the opencl backend tuning\n  settings file.\n* Android binaries published by appveyor are now stripped.\n* Build can now use system installed eigen if available.\n* When nodes in the tree get proven terminal, parents are updated as if they\n  had always been terminal. This allows for faster convergence on more\n  accurate MLH estimates amongst other details.\n* Removed shortsightedness and logit-q options that have not found a reliable\n  use case.\n* Fixed a bug where m_effect calculated as part of S in verbose move stats was\n  not consistent with the value used in search itself.\n* Added 'pro' mode as an alternative to `--show-hidden` for UCI hosts that do\n  not support command line arguments. Simply rename the lc0 binary to include\n  'pro' in order to enable.\n* `backendbench` now has a `--clippy` option to try and auto suggest which\n  batch size is a good idea.\n* The demux backend now splits the batch into equal sizes based on the number\n  of threads that demux is using rather than number of backends. By default\n  this is no change as usually there is 1 thread per backend. But it allows\n  to more easily use demux against a blas backend sending one chunk per core.\n* Added support for new training input variants canonical_hectoplies and \n  canonical_hectoplies_armageddon.\n* Fixed a bug where if the network search paths for autodiscover contain files\n  which lc0 cannot open it would error out rather than continuing on to other\n  files.\n* Blas backends no longer have a `blas_cores` option, as it never seemed useful\n  compared to running more threads at a higher level.\n* `--help-md` option removed as it was deemed not very useful.\n* Updated to the latest version of dnnl for the dnnl build.\n* Selfplay mode now supports per color settings in addition to per player\n  settings. Per player settings have higher priority if there is a conflict.\n  This will be used as part of armageddon training.\n* Added a new experimental backend type: `recordreplay`. This allows to\n  record the output of a backend under a particular search and then replay it\n  back again later. Theoretically this lets you simulate a CPU bottlenecked\n  environment but still use a search tree that is a match for what might be a\n  GPU bottlenecked environment. In practice there are a lot of corner cases\n  where replay is not reliable yet.  At a minimum you must disable prefetch.\n* During search the node tree is occasionally compacted to reduce cache misses\n  during the search tree walk. New option `--solid-tree-threshold` can be used\n  to adjust how aggressive this optimization is.  Note that very small values\n  can cause very large growth in ram usage and are not a good idea. The default\n  value is a little conservative, if you have plenty of spare ram it can be\n  good to decrease it a bit.\n* Small performance optimization for windows build with MLH enabled.\n* Meson configuration changed to build with LTO by default. Note that meson\n  does not always configure visual studio project files to apply this\n  correctly on windows.\n* The included net in appveyor builds is now 703350. This network supports MLH\n  although the default MLH parameters are still threshold 1.0 which means it\n  will not trigger without parameter adjustment.\n* New backend option to explicitly override the net details and force MLH\n  disabled. If you weren't going to use MLH anyway, this may give a tiny nps\n  increase.\n* New flag `--show-movesleft` (or `UCI_ShowMovesLeft` for UCI hosts that\n  support it) will cause movesleft (in moves) to be reported in the uci info\n  messages. Only works with networks that have MLH enabled.\n* More sensible default values for MLH are in. Note that threshold is still\n  1.0 by default, so that will still need to be configured to enable it.\n* The `smooth-experimental` time manager has been renamed `smooth` and support\n  added to increase search time whenever the best N does not correspond with\n  the move with best utility estimate. `legacy` remains the default for now\n  as `smooth` has only been tuned for short time controls and evidence suggests\n  it doesn't scale with these defaults.\n* Selfplay mode now supports a logfile parameter just like normal mode.\n* Reinstated the 4 billion visit limit on search to avoid overflowing counters\n  and causing very strange behavior to occur.\n* Performance optimization to make tree walk faster by ensuring that node\n  edges are always sorted by policy. This has some very small side effects to\n  do with tiebreaks in search no longer always being dominated by movegen\n  order.\n* Appveyor built blas and Android binaries now default to minibatch size 1\n  and prefetch 0, which should be much better than the normal GPU optimized\n  defaults. Note this *only* affects Appveyor built binaries.\n* The included client in Windows Appveyor releases is now v27 and is named\n  `lc0-training-client.exe` instead of `client.exe`.\n\nv0.25.1 (2020-04-30)\n~~~~~~~\n\n* Fixed some issues with cudnn backend on the 16xx GTX models and also for \n  low memory devices with large network files where the new optimizations\n  could result in out of memory errors.\n* Added a workaround for a cutechess issue where reporting depth 0 during\n  instamoves causes it to ignore our info message.\n\nv0.25.0 (2020-04-28)\n~~~~~~~\n\n* Relax strictness for complete standard fens in uci and opening books. Fen\n  must still be standard, but default values will be substituted for sections\n  that are missing.\n* Restore some backwards compatibility in cudnn backends that was lost with\n  the addition of the new convolution implementation. It is also on by default\n  for more scenarios, although still off for fp16 on RTX gpus.\n* Small logic fix for nps smoothing in the new optional experimental time \n  manager.\n\nv0.25.0-rc2 (2020-04-23)\n~~~~~~~~~~~\n\n* Increased upper limit for maximum collision events.\n* Allow negative values for some of the extended moves left head parameters.\n* Fix a critical bug in training data generation for input type 3.\n* Fix for switching between positions in uci mode that only differ by 50 move\n  rule in initial fen.\n* Some refinements of certainty propagation.\n* Better support for c++17 implementations that are missing charconv.\n* Option to more accurately apply time management for uci hosts using \n  cuteseal or similar timing techniques.\n* Fix for selfplay mode to allow exactly book length total games.\n* Fix for selfplay opening books with castling moves starting from chess960 fens.\n* Add build option to override nvcc compiler.\n* Improved validity checking for some uci input parameters.\n* Updated the Q to CP conversion formula to better fit recent T60 net outputs to\n  expectations.\n* Add a new experimental time manager.\n* Bug fix for the Q+U in verbose move stats. It is now called S: and contains\n  the total score, including any moves left based effect if applicable.\n* New temperature decay option to allow to delay the start of decay.\n* All temperature options have been hidden by default.\n* New optional cuda backend convolution implementation. Off by default for \n  cudnn-fp16 until an issue with cublas performance on some gpus is resolved.\n\nv0.25.0-rc1 (2020-04-09)\n~~~~~~~~~~~\n\n* Now requires a c++17 supporting compilation environment to build.\n* Support for Moves Left Head based networks. Includes options to adjust search\n  to favour shorter/longer wins/losses based on the moves left head output.\n* Mate score reporting is now possible, and move selection will prefer shorter\n  mates over longer ones when they are proven.\n* Training now outputs v5 format data. This passes the moves left information\n  back to training. This also includes support for multiple sub formats, \n  including the existing standard, a new variant which can encode FRC960\n  castling, and also a further extension of that which tries to make training\n  data cannonical, so there aren't multiple positions that are trivially\n  equivalent with different network inputs.\n* Benchmark now includes a suite of 34 positions to test by default instead of\n  just start position.\n* Tensorflow backend works once more, almost just as hard to compile as it used\n  to be though.\n* `--noise` flag is gone, use `--noise-epsilon=0.25` to get the old behavior.\n* Some bug fixes related to drawscore.\n* Selfplay mode now defaults to the same value as match play for \n  `--root-has-own-cpuct-params` (true).\n* Some advanced time management parameters are now accessed via the new \n  `--time-manager` parameter instead of individual parameters.\n* Windows build script has been modernized.\n* Separate Eigen backend option for CPU.\n* Random backend no longer requires a network.\n* Random backend supports producing training data of any input format sub type.\n* Integer parameters now give better error messages when given invalid values.\n\nv0.24.1 (2020-03-15)\n~~~~~~~\n\n* Fix issues where logitq was being passed as drawscore and logitq wasn't \n  passed to some GetQ calls. Causing major performance issues when either \n  setting was non-default.\n\nv0.24.0 (2020-03-11)\n~~~~~~~\n\n* New parameter `--max-out-of-order-evals-factor` replaces \n  `--max-out-of-order-evals` that was introduced in v0.24.0-rc3 and provides\n  the factor to multiply the maximum batch size to set maximum number\n  out-of-order evals per batch. The default value of 1.0 keeps the behavior\n  of previous releases.\n* Bug fix for hangs with very early stop command from non-conforming UCI hosts.\n\nv0.24.0-rc3 (2020-03-08)\n~~~~~~~~~~~\n\n* New parameter `--max-out-of-order-evals` to set maximum number out-of-order\n  evals per batch (was equal to the batch size before).\n* It's now possible to embed networks into the binary. It allows easier builds\n  of .apk for Android.\n* New parameter `--smart-pruning-minimum-batches` to only allow smart pruning\n  to stop after at least k batches, preventing insta-moves on slow backends.\n\nv0.24.0-rc2 (2020-03-01)\n~~~~~~~~~~~\n\n* All releases are now bundled with network id591226 (and the file date is old \n  enough so it has a lower priority than networks that you already may have\n  in your directory).\n* Added a 'backendbench' mode to benchmark NN evaluation performance without\n  search.\n* Android builds are added to the official releases.\n\nv0.24.0-rc1 (2020-02-23)\n~~~~~~~~~~~\n\n* Introduced DirectX12 backend.\n* Optimized Cpuct/FPU parameters are now default.\n* There is now a separate set of CPuct parameters for the root node.\n* Support of running selfplay games from an opening book.\n* It's possible to adjust draw score from 0 to something else.\n* There is a new --max-concurrent-seachers parameter (default is 1) which\n  helps with thread congestion at the beginning of the search.\n* Cache fullness is not reported in UCI info line by default anymore.\n* Removed libproto dependency.\n\nv0.23.3 (2020-02-18)\n~~~~~~~\n\n* Fix a bug in time management which sometimes led to insta-moves in long time\n  control.\n\nv0.23.2 (2019-12-31)\n~~~~~~~\n\n* Fixed a bug where odd length openings had reversed training data results in\n  selfplay.\n* Fixed a bug where zero length training games could be generated due to\n  discard pile containing positions that were already considered end of game.\n* Add cudnn-auto backend.\n\nv0.23.1 (2019-12-03)\n~~~~~~~\n\n* Fixed a bug with Lc0 crashing sometimes during match phase of training game\n  generation.\n* Release packages now include CUDNN version without DLLs bundled.\n\nv0.23.0 (2019-12-01)\n~~~~~~~\n\n* Fixed the order of BLAS options so that Eigen is lower priority, to match\n  assumption in check_opencl patch introduced in v0.23.0-rc2.\n\nv0.23.0-rc2 (2019-11-27)\n~~~~~~~~~~~\n\n* Fixes in nps and time reporting during search.\n* Introduced DNNL BLAS build for modern CPUs in addition to OpenBLAS.\n* Build fixes on MacOS without OpenCL.\n* Fixed smart pruning and KLDGain trying to stop search in `go infinite` mode.\n* OpenCL package now has check_opencl tool to find computation behaves sanely.\n* Fixed a bug in interoperation of shortsighteness and certainty propagation.\n\nv0.23.0-rc1 (2019-11-21)\n~~~~~~~~~~~\n\n* Support for Fischer Random Chess (`UCI_Chess960` option to enable FRC-style\n  castling). Also added support for FRC-compatible weight files, but no training\n  code yet.\n* New option `--logit-q` (UCI: `LogitQ`). Changes subtree selection algorithm a\n  bit, possibly making it stronger (experimental, default off).\n* Lc0 now reports WDL score. To enable it, use `--show-wdl` command-line\n  argument or `UCI_ShowWdl` UCI option.\n* Added \"Badgame split\" mode during the training. After the engine makes\n  inferior move due to temperature, the game is branched and later the game is\n  replayed from the position of the branch.\n* Added experimental `--short-sightedness` (UCI: `ShortSightedness`) parameter.\n  Treats longer variations as more \"drawish\".\n* Lc0 can now open Fat Fritz weight files.\n* Time management code refactoring. No functional changes, but will make time\n  management changes easier.\n* Lc0 logo is now printed in red! \\o/\n* Command line argument `-v` is now short for `--verbose-move-stats`.\n* Errors in `--backend-opts` parameter syntax are now reported.\n* The most basic version of \"certainty propagation\" feature (actually without\n  \"propagation\"). If the engine sees checkmate, it plays it!\n  (before it could play other good move).\n* Benchmark mode no longer supports smart pruning.\n* Various small changes: hidden options to control Dirichlet noise, floating\n  point optimizations, Better error reporting if there is exception in worker\n  thread, better error messages in CUDA backend.\n\nv0.22.0 (2019-08-05)\n~~~~~~~\n\n(no changes)\n\nv0.22.0-rc1 (2019-08-03)\n~~~~~~~~~~~\n\n* Remove softmax calculation from backends and apply it after filtering for\n  illegal moves to ensure spurious outputs on illegal moves don't reduce (or\n  entirely remove) the quality of the policy values on the legal moves.\n* Fix for blas backend allocation bug with small network sizes.\n* The blas backend can be built with eigen - the result is reasonably optimized\n  for the build machine.\n* Other small tweaks piled up in master branch.\n\n\nv0.21.4 (2019-07-28)\n~~~~~~~~~~~~~~~~~~~~\n\n* A fix for crashes that can occur during use of sticky-endgames.\n* Change the false positive value reported when in wdl style resign and display\n  average nodes per move as part of tournament stats in selfplay mode.\n\nv0.21.3 (2019-07-21)\n~~~~~~~\n\n* Fix for potential memory corruption/crash in using small networks or using the\n  wdl head with cuda backends. (#892)\n* Fix for building with newer versions of meson. (#904)\n\nv0.21.2 (2019-06-09)\n~~~~~~~\n\n* Divide by a slightly smaller divisor to truncate to +/-12800. (#880)\n\nv0.21.2-rc3 (2019-06-08)\n~~~~~~~~~~~\n\n* Centipawn conversion (#860)\n\nv0.21.2-rc2 (2019-05-22)\n~~~~~~~~~~~\n\n* Add 320 and 352 channel support for fused SE layer (#855)\n* SE layer fix when not using fused kernel (#852)\n* Fp16 nchw for cudnn-fp16 backend (support GTX 16xx GPUs) (#849)\n\nv0.21.2-rc1 (2019-05-05)\n~~~~~~~~~~~\n\n* Make --sticky-endgames on by default (still off in training) (#844)\n* update download links in README (#842)\n* Recalibrate centipawn formula (#841)\n* Also make parents Terminal if any move is a win or all moves are loss or draw. (#822)\n* Use parent Q as a default score instead of 0 for unvisited pv. (#828)\n* Add stop command to selfplay interactive mode to allow for graceful exit. (#810)\n* Increased hard limit on batch size in opencl backend to 32 (#807)\n\nv0.21.0-rc2 (2019-03-06)\n~~~~~~~~~~~\n\n* Add support for cudnn7.0 (#717)\n* Informative Tournament Stats (#698)\n* Memory leak fix cuda backend (#747)\n* cudnn-fp16 fallback path for unusual se-ratios. (#739)\n* Cudnn 7.4.2 in packaged binary and warning for using old cudnn with new gpu (#741)\n* Move mode specific options to end of help. (#745)\n* LogLiveStats hidden option (#754)\n* Optional markdown support for help output (#769)\n* Improved folding of batch norm into weights and biases - fixes negative gamma bug. (#779)\n\nv0.21.0-rc1 (2019-02-16)\n~~~~~~~~~~~\n\n* Check Syzygy tablebase file sizes for corruption (#690)\n* search for nvcc on the path first (#709)\n* AZ-style policy head support (#712) \n* Implement V4TrainingData (#722)\n* WDL value head support (#635)\n* Add option for doing kldgain thresholding rather than absolute visit\n  limiting (#721)\n* Easily run latest releases of lc0 and client using NVIDIA docker (#621)\n* Add WDL style resign option. (#724)\n* Add a uniform output option for random backend to support a0 seed data\n  style (#725)\n* Fix c hw switching in cudnn-fp16 mode with convolution policy head.\n  (#729)\n* misc (non-functional) changes to cudnn backend (#731)\n* handle 64 filter SE networks (#624)\n\nv0.20.2 (2019-02-01)\n~~~~~~~~~~~\n\n* Favor winning moves that minimize DTZ to reduce shuffling by assuming\n  repeated position by default (#708)\n* Print cuda and gpu info, warn if mismatches are noticed (#711)\n\nv0.20.2-rc1 (2019-01-27)\n~~~~~~~~~~~\n\n* no terminal multivisits (#683)\n* better fix for issue 651 (#693)\n* Changed output of --help flag to stdout rather than stderr (#687)\n* Movegen speedup via magic bitboards (#640)\n* modify default benchmark setting to run for 10 seconds (#681)\n* Fix incorrect index in OpenCL Winograd output transform (#676)\n* Update OpenCL (#655)\n\nv0.20.1 (2019-01-07)\n~~~~~~~~~~~\n\n* Change to atomic for cache capacity. (#665)\n\nv0.20.1-rc3 (2019-01-07)\n~~~~~~~~~~~\n\n* Remove ffast-math from the default flags (#661)\n\nv0.20.1-rc2 (2019-01-05)\n~~~~~~~~~~~\n\n* Don't use Winograd for 1x1 conv. (#659)\n* Fix issues with pondering and search limits. (#658)\n* Check for zero capacity in cache (#648)\n* fix undefined behavior in DiscoverWeightsFile() (#650)\n* fix fastmath.h undefined behavior and clean it up (#643)\n\nv0.20.1-rc1 (2019-01-01)\n~~~~~~~~~~~\n\n* Simplify movestogo approximator to use median residual time. (#634)\n* Replace time curve logic with movestogo approximator. (#271)\n* Cache best edge to improve PickNodeToExtend performance. (#619)\n* fix building with tensorflow 1.12 (#626)\n* Minor changes to `src/chess` (#606)\n* make uci search parameters the defaults ones (#609)\n* Preallocate nodes in advance of their need to avoid the allocation being\n  behind a mutex. (#613)\n* imrpove meson error when no backends enabled (#614)\n* allow building with the mklml library as an mkl alternative (#612)\n* Only build the history up if we are actually going to extend the position.\n  (#607)\n* fix warning (#604)\n\nv0.20.0 (2019-01-01)\n~~~~~~~~~~~\n\n* no lto builds by default (#625)\n\nv0.20.0-rc2 (2018-12-24)\n~~~~~~~~~~~\n\n* Fix for demux backend to match cuda expected threading model for \n  computations. (#605)\n\nv0.20.0-rc1 (2018-12-22)\n~~~~~~~~~~~\n\n* Squeeze-and-Excitation Networks are now supported! (lc0.org/se)\n* Older text network files are no longer supported.\n* Various performance fixes (most major being having fast approximate math\n  functions).\n* For systems with multiple GPUs, in addition to \"multiplexing\" backend\n  we now also have \"demux\" backend and \"roundrobin\" backend.\n* Compiler settings tweaks (use VS2017 for windows builds, always have LTO\n  enabled, windows releases have PGO enabled).\n* Benchmark mode has more options now (e.g. movetime) and saner defaults.\n* Added an option to prevent engine to resign too early (used in training).\n* Fixed a bug when number of visits could be too high in collision nodes.\n  The fix is pretty hacky, there will be better fix later.\n* 32-bit version compiles again.\n\nv0.19.1 (2018-12-10)\n~~~~~~~\n\n(no changes relative to v0.19.1-rc2)\n\nv0.19.1-rc2 (2018-12-07)\n~~~~~~~~~~~\n\n* Temperature and FPU related params. (#568)\n* Rework Cpuct related params. (#567)\n\nv0.19.1-rc1 (2018-12-06)\n~~~~~~~~~~~\n\n* Updated cpuct formula from alphazero paper. (#563)\n* remove UpdateFromUciOptions() from EnsureReady() (#558)\n* revert IsSearchActive() and better fix for one of #500 crashes (#555)\n\nv0.19.0 (2018-11-19)\n~~~~~~~\n\n* remove Wait() from EngineController::Stop() (#522)\n\nv0.19.0-rc5 (2018-11-17)\n~~~~~~~~~~~\n\n* OpenCL: replace thread_local with a resource pool. (#516)\n* optional wtime and btime (#515)\n* Make convolve1 work with workgroup size of 128 (#514)\n* adjust average depth calculation for multivisits (#510)\n\nv0.19.0-rc4 (2018-11-12)\n~~~~~~~~~~~\n\n* Microseconds have 6 digits, not 3! (#505)\n* use bestmove_is_sent_ for Search::IsSearchActive() (#502)\n\nv0.19.0-rc3 (2018-11-07)\n~~~~~~~~~~~\n\n* Fix OpenCL tuner always loading the first saved tuning (#491)\n* Do not show warning when ComputeBlocking() takes too much time. (#494)\n* Output microseconds in log rather than milliseconds. (#495)\n* Add benchmark features (#483)\n* Fix EncodePositionForNN test failure (#490)\n\nv0.19.0-rc2 (2018-11-03)\n~~~~~~~~~~~\n\n* Version v0.19.0-rc1 reported it's version as v0.19.0-dev\n  Therefore v0.19.0-rc2 is released with this issue fixed.\n\nv0.19.0-rc1 (2018-11-03)\n~~~~~~~~~~~\n\n* Search algorithm changes\n\n  When visiting terminal nodes and collisions, instead of counting that as one\n  visit, estimate how many subsequent visits will also go to the same node, and\n  do a batch update.\n\n  That should slightly improve nps near terminal nodes and in multithread\n  configurations. Command line parameters that control that:\n\n  --max-collision-events – number of collision events allowed per batch.\n    Default is 32. This parameter is roughly equivalent to\n    --allowed-node-collisions in v0.18.\n  \n  --max-collision-visits – total number of estimated collisions per NN batch.\n    Default is 9999.\n\n* Time management\n\n  Multiple changes have been done to make Leela track used time more precisely\n  (particularly, the moment when to start timer is now much closer to the moment\n  GUIs start timer).\n\n  For smart pruning, Leela's timer only starts when the first batch comes from\n  NN eval. That should help against instamoves, especially on non-even GPUs.\n\n  Also Leela stops the search quicker now when it sees that time is up (it could\n  continue the search for hundreds of milliseconds after that, which caused time\n  trouble if opponent moves very fast).\n\n  Those changes should help a lot in ultra-bullet configurations.\n\n* Better logging\n\n  Much more information is outputted now to the log file. That will allow us to\n  easier diagnose problems if they occur. To have debug file written, add a\n  command line option:\n\n  --logfile=/path/to/logfile\n\n  (or short option \"-l /path/to/logfile\", or corresponding UCI option \"LogFile\")\n\n  It's recommended to always have logging on, to make it easier to report bugs\n  when it happens.\n\n* Configuration parameters change\n\n  Large part of parameter handling has been reworked. As the result:\n\n  All UCI parameters have been changed to have more \"classical\" look.\n    E.g. was \"Network weights file path\", became \"WeightsFile\".\n\n  Much more detailed help is shown than before when you run\n    ./lc0 --help\n\n  Some flags have been renamed, e.g.\n    --futile-move-aversion\n    is renamed back to\n    --smart-pruning-factor.\n\n  After setting a parameter (using command line parameter or uci setoption\n    command), uci command \"uci\" shows updated result. That way you can check the\n    current option values.\n\n  Some command-line and UCI options are hidden now. Use --show-hidden command\n    line parameter to unhide them. E.g.\n    ./lc0 --show-hidden --help\n\n  Also, in selfplay mode the per player configuration format has been changed\n  (although probably noone knew that anyway):\n    Was: ./lc0 selfplay player1: --movetime=14\n    Became: ./lc0 selfplay --player1.movetime=14\n\n* Other\n\n  \"go depth X\" uci command now causes search to stop when depth information in\n  uci info line reaches X. Not that it makes much sense for it to work this way,\n  but at least it's better than noting.\n\n  Network file size can now be larger than 64MB.\n\n  There is now an experimental flag --ramlimit-mb. The engine tries to estimate\n  how much memory it uses and stops search when tree size (plus cache size)\n  reaches RAM limit. The estimation is very rough. We'll see how it performs and\n  improve estimation later.  \n  In situations when search cannot be stopped (`go infinite` or ponder),\n  `bestmove` is not automatically outputted. Instead, search stops progress and\n  outputs warning.\n  \n  Benchmark mode has been implemented. Run run, use the following command line:\n    ./lc0 benchmark\n  This feature is pretty basic in the current version, but will be expanded later.\n\n  As Leela plays much weaker in positions without history, it now is able to\n  synthesize it and do not blunder in custom FEN positions. There is a\n  --history-fill flag for it. Setting it to \"no\" disables the feature, setting\n  to \"fen_only\" (default) enables it for all positions except chess start\n  position, and setting it to \"always\" enables it even for startpos.\n\n  Instead of output current win estimation as centipawn score approximation,\n  Leela can how show it's raw score. A flag that controls that is --score-type.\n  Possible values:\n    - centipawn (default) – approximate the win rate in centipawns, like Leela\n      always did.\n    - win_percentage – value from 0 to 100.0 which represents expected score in\n      percents.\n    - Q – the same, but scales from -100.0 to 100.0 rather than from 0 to 100.0\n\nv0.18.1 (2018-10-02)\n~~~~~~~\n\n* Fix for falling into threefold repetition in a winning endgame tablebase position.\n\n\nv0.18.0 (2018-09-30)\n~~~~~~~\n\n* No changes from rc2 except the version.\n\n\nv0.18.0-rc2 (2018-09-26)\n~~~~~~~~~~~\n\n* Severe bug fixed: Race condition when out-of-order-eval was enabled (and it\n  was enabled by default)\n\n* Windows 32-bit builds are now possible (CPU only for now)\n\n\nv0.18.0-rc1 (2018-09-24)\n~~~~~~~~~~~\n\nKNOWN BUG!\n\n* We have credible reports that in some rare cases Lc0 crashes!\n  However, we were not able to reproduce it reliably. If you see the crash,\n  please report to devs! What seems to increase crash probability:\n  - Very short move time (milliseconds)\n  - Proximity to a checkmate (happens 1-3 moves before the checkmate)\n\n\nNew features:\n\n* Endgame tablebases support! Both WDL and DTZ now.\n\n* Added MultiPv support.\n\n\nTime management changes:\n\n* Introduced --immediate-time-use flag. Yes, yet another time management\n  flag. Posible values are between 0.0 and 1.0. Setting it closer to \n  1.0 makes Leela use time saved from futile search aversion earlier.\n\n* Some time management parameters were changed:\n  - Slowmover is 1.0 now (was 2.4)\n  - Immediate-time-use is 0.6 now (didn't exist before, so was 0.0)\n\n* Fixed a bug, because of which futile search aversion tolerance was incorrectly\n  applied, which resulted in instamoves.\n\n* Now search stops immediately when it runs out of budgeted time.\n  Should help against timeouts, especially on slow backends (e.g. BLAS).\n\n* Move overhead now is a fixed time, doesn't depend on number of remaining\n  moves.\n\n\nOther:\n\n* Out of order eval is on by default. That brings slight nps improvement.\n\n* Default FPU reduction is 1.2 now (was 0.9)\n\n* Cudnn backend now has max_batch parameter.\n  (can be set for example like this --backend-opts=max_batch=100).\n  This is needed for lower end GPUs that didn't have enough VRAM for a buffer\n  of size 1024. Make sure that this setting is not lower than --minibatch-size.\n\n* Small memory usage optimizations.\n\n* Engine name in UCI response is shorter now. Fritz chess UI should be able\n  to work with Leela now\n\n* Added flag --temp-visit-offset, will allow to offset temperature during\n  training.\n\n* Command line and UCI parameter values are now checked for validity.\n\n* You can now build for older processors that don't support the popcnt\n  instruction by passing -Dpopcnt=false to meson when building.\n\n* 32-bit build is possible now. CPU only and we were only able to build it \n  in Linux for now, including Raspberry Pi.\n\n* Threading issue which caused crash in heavily multithreaded environment\n  with slow backends was fixed.\n\n\nv0.17.0 (2018-08-27)\n~~~~~~~\n\nNo changes from rc2 except the version.\n\n\nv0.17.0-rc2 (2018-08-21)\n~~~~~~~~~~~\n\n* Fixed a bug, that rule50 value was located in wrong place in a training data.\n* OpenCL uses much less VRAM now.\n* Default OpenCL batch size is 16 now (was 1).\n* Default time management related configuration was tweaked:\n  --futile-move-aversion is 1.33 now (was 1.47)\n  --slowmover is 2.4 now (was 2.6)\n\n\nv0.17.0-rc1 (2018-08-19)\n~~~~~~~~~~~\n\nNew visible features:\n* Implemented ponder support.\n* Tablebases are supported now (only WDL probe for now).\n  Command line parameter is\n  --syzygy-paths=/path/to/syzygy/\n* Old smart pruning flag is gone. Instead there is\n  --futile-search-aversion flag.\n  --futile-search-aversion=0 is equivalent to old --no-smart-pruning.\n  --futile-search-aversion=1 is equivalent to old --smart-pruning.\n  Now default is 1.47, which means that engine will sometimes decide to\n  stop search earlier even when there is theoretical chance (but not very\n  probable) that best move decision could be changed if allowed to think more.\n* Lc0 now supports configuration files. Options can be listed there instead of\n  command line flags / uci params.\n  Config should be named lc0.config and located in the same directory as lc0.\n  Should list one command line option per line, with '--' in the beginning\n  being optional, for example:\n\n     syzygy-paths=/path/to/syzygy/\n\n* In uci info, \"depth\" is now average depth rather than full depth\n  (which was 4 all the time).\n  Also, depth values do not include reused tree, only nodes visited during the\n  current search session.\n* --sticky-checkmates experimental flag (default off), supposed to find shorter\n  checkmate sequences.\n* More features in backend \"check\".\n\n\nPerformance optimizations:\n* Release windows executables are built with \"whole program optimization\".\n* Added --out-of-order-eval flag (default is off).\n  Switching it on makes cached/terminal nodes higher priority, which increases\n  nps.\n* OpenCL backend now supports batches (up to 5x speedup!)\n* Performance optimizations for BLAS backend.\n* Total visited policy (for FPU reduction) is now cached.\n* Values of priors (P) are stored now as 16-bit float rather than 32-bit float,\n  that saves considerable amount of RAM.\n\n\nBugfixes:\n* Fixed en passant detection bug which caused the position after pawn moving by\n  two squares not counted towards threefold repetition even if en passant was\n  not possible.\n* Fixed the bug which caused --cache-history-length for values 2..7 work the\n  same as --cache-history-length=1.\n  This is fixed, but default is temporarily changed to --cache-history-length=1\n  during play. (For training games, it's 7)\n\n\nRemoved features:\n* Backpropagation beta / backpropagation gamma parameters have been removed.\n\n\nOther changes:\n* Release lc0-windows-cuda.zip package now contains NVdia CUDA and cuDNN .dlls.\n\n\nv0.16.0 (2018-07-20)\n~~~~~~~\n\n* Fully switched to official releases! No more https://crem.xyz/lc0/\n* Fixed a bug when pv display and smart pruning didn't sometimes work properly\n  after tree reuse.\n* Format of protobuf network files was changed.\n* Autodiscovery of protobuf based network files works now.\n\n\nlc0-win-20180715-cuda92-cudnn714\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n\n* Support of new format of network files (needed for lc0 launch on main\n  training server)\n* Fixed hang/poor performance in the beginning of search when there are many\n  threads. (Happened on linux only though).\n* Memory footprint is reduced a bit. (~-60 bytes per node)\n\nlc0-win-20180711-cuda92-cudnn714\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n\n* Edge-node separation introduced a bug that smart pruning didn't work. That's\n  fixed.\n* Changed options parsing so that --backend-opts=cudnn-fp16 is now possible.\n* Performance fixes (mostly for slowness introduced by edge-node separation).\n\nlc0-win-20180708-cuda92-cudnn714\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n\n* Mutex contention has been reduced (but locking mutex more rarely).\n  Helps a lot with many threads running. Especially recommended to check with\n  multi-GPU configuration.\n* Memory usage reduced at least 2x (probably more).\n* cudnn backend crashed on large batches (>800) that's fixed.\n  There is still a limit of batch size 1024 though.\n* (not in cudnn build, but for completeness)\n  Fixed NN computation with BLAS backend, it had up to 5% error before that.\n* Default time budgeting params have been changed again! (not by mach this time)\n  --slowmover=1.95\n  --time-curve-peak=26.2\n  --time-curve-left-width=82\n  --time-curve-right-width=74\n\nlc0-win-20180701-cuda92-cudnn714\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n\n* fp16-based computation for very modern NVidia GPUs!\n  May reduce precision a bit, but should be compensated by nps boost.\n  Enable with --backend=cudnn-fp16 flag\n* V is now not stored in nodes (a bit less RAM used while thinking)\n* (not in cudnn build, but listing for completeness) blas batching support.\n\nlc0-win-20180629-cuda92-cudnn714\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n\n* Default time budgeting parameters have been changed (again!):\n  --slowmover=1.93\n  --time-curve-peak=26\n  --time-curve-left-width=67\n  --time-curve-right-width=76\n* When generating training games, the engine could confuse client by sending\n  corrupted output. That's fixed.\n\nlc0-win-20180624-cuda92-cudnn714\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n\n* Default time budgeting parameters have been changed:\n  --slowmover=2.13  (was 1.8)\n  --time-curve-peak=22.0  (was 41.0)\n  --time-curve-left-width=450.0  (was 1000.0)\n  --time-curve-right-width=30.0  (was 39.5)\n* During training game generation, the engine is able to send resign statistics.\n\n\nlc0-win-20180622-cuda92-cudnn714\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n\n* Time budged allocation has been changed, it allocates more time to early\n  stages of the game.\n  Graphs are here: https://github.com/LeelaChessZero/lc0/pull/59\n  Slowmover value has so be recalibrated, and default value was changed from 2.2 to 1.8.\n* Fixed a race condition in cache prefetch code. Realistically it hardly every\n  occured before though.\n\nlc0-win-20180619-cuda92-cudnn714-00\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n\n* Fix a bug instroduced in version 20180609 which caused the engine to miss checkmates sometimes.\n\nlc0-win-20180614-cuda92-cudnn714\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n\n* \"go searchmoves\" uci command is now supported\n* It's possible now to disable tree reuse in training games\n* Few improvements for random backend\n* Lc0 now shows version in uci response\n* Analyzer mode has been removed\n* extra-virtual-loss has been removed\n* Implemented resign (for training games)\n\nlc0-win-20180609-cuda92-cudnn714-01\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n\n* In addition to --backpropagate-gamma, there is also --backpropagate-beta!\n  Default is 1.0.\n\nlc0-win-20180609-cuda92-cudnn714-00\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n\nVisible changes:\n* Experimental changes from 20180604 are now default.\n* Memory footprint is reduced by 8 bytes per visible node (+ ~240 bytes in\n  invisible nodes per visible)\n* Introduced --backpropagate-gamma flag.\n  Default is 1.0. There are rumours that reducing it to 0.75 improves play.\n* Extra-virtual-loss parameter has been removed.\n* Quotes in backend-opts parameter were not parsed properly, that's fixed.\n\n\nlc0-win-20180604-cuda92-cudnn714-experimental\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n\nVisible changes:\n* Experimental default settings:\n  cPUCT: 3.4\n  FPU reduction: 0.9\n  policy Softmax: 2.2\n\n* Fix memory leak when GUI doesn't ever issue `isready` uci command.\n\n\nlc0-win-20180602-cuda92-cudnn714-00\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n\nVisible changes:\n* cPUCT is now 3.1 by default instead of 1.2 (or what it was before)\n* Fixed Batch normalization epsilon in tensorflow backend (but noone uses tensorflow anyway)\n* Periodically (every 5 seconds) output \"uci info\" even if bestmove/depth doesn't change.\n* Memory management is redone so that node release happens after \"bestmove\" and \"isready\", rather than after \"position\" uci command.\n  That garbage collection could take tens of milliseconds and chess GUI already started timer at that point.\n  Memory management is always fragile, so fresh crashes and memory leaks are possible.\n\nInvisible changes:\n* Store castlings again as e1g1 and not e1h1. Fixes a bug that tree was not reused after castling.\n"
        },
        {
          "name": "cross-files",
          "type": "tree",
          "content": null
        },
        {
          "name": "dist",
          "type": "tree",
          "content": null
        },
        {
          "name": "install_openSUSE_lc0.sh",
          "type": "blob",
          "size": 3.6083984375,
          "content": "#!/bin/bash\n\n\n# This script can be run from any location, but must be run in a root console.\n\n# Start OS detection and setting variables\nID=$(grep -w ID= /etc/os-release | sed -e 's/ID=//')\nVERSION_ID=$(grep -w VERSION_ID= /etc/os-release | sed -e 's/VERSION_ID=//' | sed -e 's/\"//g')\n\n#If Tumbleweed is detected, the Tumbleweed install\nif [ \"$ID\" = '\"opensuse-tumbleweed\"' ]; then\n\n# Update system, always a good idea before a major install\nzypper dup -y\n\necho \"No repositories will be added\"\n# Tumbleweed repositories are currently disabled because of a Tumbleweed bug, but may not be significant due to the bleeding edge and rolling release nature of Tumbleweed. Currently, lc0 builds fine without these repos\t\n# zypper -n ar -f https://download.opensuse.org/repositories/devel:/gcc/openSUSE_Factory/ Tumbleweed:devel:gcc \n# zypper -n ar -f\thttps://download.opensuse.org/repositories/devel:/languages:/python:/Factory/openSUSE_Tumbleweed/ Tumbleweed:devel:languages:python\n# zypper -n ar -f\thttp://download.opensuse.org/repositories/science/openSUSE_Tumbleweed/ openSUSE_Tumbleweed:science \n\n#Enable to access Tensorflow packages\n# zypper -n ar -f https://download.opensuse.org/repositories/science:/machinelearning/openSUSE_Leap_$VERSION_ID/ Tumbleweed::science:machinelearning\n\n\nelse\n#If LEAP is detected, then the LEAP install for that specific version of LEAP\nif [ \"$ID\" = '\"opensuse-leap\"' ]; then\n\n# Update system, always a good idea before a major install\nzypper up -y\n\nzypper -n ar -f https://download.opensuse.org/repositories/devel:/gcc/openSUSE_Leap_\"$VERSION_ID\"/ LEAP:devel:gcc \nzypper -n ar -f\thttps://download.opensuse.org/repositories/devel:/languages:/python:/backports/openSUSE_Leap_\"$VERSION_ID\"/ LEAP:devel:languages:python:backports\nzypper -n ar -f\thttp://download.opensuse.org/repositories/science/openSUSE_Leap_\"$VERSION_ID\"/ LEAP:science \n\n#Enable to access Tensorflow packages\n#zypper -n ar -f https://download.opensuse.org/repositories/science:/machinelearning/openSUSE_Leap_$VERSION_ID/ Tumbleweed::science:machinelearning\n\nfi\n# Package repositories are activated\nzypper --gpg-auto-import-keys ref\nfi\n\n\n# install dependencies\n# If any build dependencies aren't met, enable the following which installs the complete C/C++ Development environment\n# zypper in -y -t pattern devel_C_C++ \n\n# The following dependencies are sometimes found, sometimes not found by the lc0 meson build, so are not installed by default\n# When the following are not found already on the system, the lc0 build towards the end of this script will do its own install\n# zypper in -y python3-protobuf libprotoc17 libprotobuf17 \n\nzypper in -y --allow-vendor-change --allow-downgrade git gcc-c++ gcc7-c++ meson ninja python3-abseil openblas_pthreads-devel-static libz1\n\n\n\n# Clone lc0 github repo\n# The following clones the development branch.\n# If you want to instead clone a stable release branch, visit the following URL in a web browser, select and copy the release you want, replacing the URL that follows \"git clone\" 5 lines below, but leaving the \"/opt/lc0\" at the end of the line untouched(In other words, everything between \"https\" and \"git\" inclusively)\n# https://github.com/LeelaChessZero/lc0\n\n# Note following installs into /opt. Modify location as desired\nmkdir /opt/lc0\ngit clone https://github.com/LeelaChessZero/lc0.git /opt/lc0\ncd /opt/lc0/ || exit\n\n\n# Execute\n./build.sh\n\n# Final Message\necho \"Completed. If you see no errors above, you can attach your chessboard to the lc0 binary at /opt/lc0/build/release/lc0\"\necho \"Or, follow the instructions for your specific chessboard frontend at\"\necho \"https://github.com/LeelaChessZero/lc0/wiki/Running-Leela-Chess-Zero-in-a-Chess-GUI\"\n\n\n"
        },
        {
          "name": "libs",
          "type": "tree",
          "content": null
        },
        {
          "name": "meson.build",
          "type": "blob",
          "size": 27.1044921875,
          "content": "# This file is part of Leela Chess Zero.\n# Copyright (C) 2018-2022 The LCZero Authors\n#\n# Leela Chess is free software: you can redistribute it and/or modify\n# it under the terms of the GNU General Public License as published by\n# the Free Software Foundation, either version 3 of the License, or\n# (at your option) any later version.\n#\n# Leela Chess is distributed in the hope that it will be useful,\n# but WITHOUT ANY WARRANTY; without even the implied warranty of\n# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n# GNU General Public License for more details.\n#\n# You should have received a copy of the GNU General Public License\n# along with Leela Chess.  If not, see <http://www.gnu.org/licenses/>.\n\nproject('lc0', 'cpp',\n        default_options : ['cpp_std=c++20', 'b_ndebug=if-release', 'warning_level=3', 'b_lto=true', 'b_vscrt=mt'],\n        meson_version: '>=0.55')\n\ncc = meson.get_compiler('cpp')\n\nif not cc.has_header('optional') or not cc.has_header('string_view')\n    error('Lc0 requires a compiler supporting C++17, for example g++ v8.0, ' +\n          'clang v5.0 or later (with C++17 stdlib) and Visual Studio 2017 or ' +\n          'later.')\nendif\n\nif not cc.has_header('charconv')\n    warning('Your compiler or library does not have full C++17 support. ' +\n            'See the README for compilers that are known to be working. ' +\n            'This will become an error in the future.')\nendif\n\nif cc.get_id() == 'clang'\n  # Thread safety annotation\n  add_project_arguments('-Wthread-safety', language : 'cpp')\nendif\nif cc.get_id() == 'clang' or cc.get_id() == 'gcc'\n  if get_option('buildtype') == 'release'\n    add_project_arguments(cc.get_supported_arguments(['-march=native']), language : 'cpp')\n  endif\nendif\nif cc.get_id() == 'msvc'\n  # Silence some zlib warnings.\n  add_global_arguments('/wd4131', '/wd4267', '/wd4127', '/wd4244', '/wd4245', language : 'c')\nendif\nif host_machine.system() == 'windows'\n  add_project_arguments('-DNOMINMAX', language : 'cpp')\nendif\nif ['arm', 'aarch64'].contains(host_machine.cpu_family())\n  if get_option('neon')\n    add_project_arguments(cc.get_supported_arguments(['-mfpu=neon']), language : 'cpp')\n    add_project_link_arguments(cc.get_supported_arguments(['-mfpu=neon']), language : 'cpp')\n  endif\nendif\n\n# Files to compile.\ndeps = []\ncommon_files = []\nfiles = []\nincludes = []\nhas_backends = false\n\n# Third party files.\nincludes += include_directories('third_party', is_system: true)\n\n# Compiling protobufs.\ncompile_proto = find_program('scripts/compile_proto.py')\ngen = generator(compile_proto, output: ['@BASENAME@.pb.h'],\n  arguments : [\n    '--proto_path=@CURRENT_SOURCE_DIR@/libs/lczero-common',\n    '--cpp_out=@BUILD_DIR@',\n    '@INPUT@'])\n\n# Handle submodules.\ngit = find_program('git', required: false)\nif run_command('scripts/checkdir.py', 'libs/lczero-common/proto', check : false).returncode() != 0\n  if git.found()\n    if run_command(git, 'status', check : false).returncode() == 0\n      message('updating git submodule libs/lczero-common')\n      run_command(git, 'submodule', 'update', '--init', '--recursive', check : false)\n    else\n      message('cloning lczero-common.git into libs/lczero-common')\n      run_command(git, 'clone', '--depth=1',\n                  'https://github.com/LeelaChessZero/lczero-common.git',\n                  'libs/lczero-common/', check : false)\n    endif\n  else\n    error('Please install git to automatically fetch submodules or download the archives manually from GitHub.')\n  endif\nendif\n\npb_files = [\n  'src/utils/protomessage.cc',\n  gen.process('libs/lczero-common/proto/net.proto',\n    preserve_path_from : meson.current_source_dir() + '/libs/lczero-common/')\n]\ncommon_files += pb_files\n\n# Extract git short revision.\nshort_rev = 'unknown'\nif git.found()\n  r = run_command(git, 'rev-parse', '--short', 'HEAD', check : false)\n  if r.returncode() == 0\n    # Now let's check if the working directory is clean.\n    if run_command(git, 'diff-index', '--quiet', 'HEAD', check : false).returncode() == 0\n      short_rev = r.stdout().strip()\n      if run_command(git, 'describe', '--exact-match', '--tags', check : false).returncode() == 0\n        short_rev = ''\n      endif\n    else\n      short_rev = 'dirty'\n      warning('Cannot extract valid git short revision from dirty working directory.')\n    endif\n  else\n    warning('Failed to parse short revision. Use git clone instead of downloading the archive from GitHub.')\n  endif\nendif\n\n# Construct build identifier.\nbuild_identifier = ''\nif short_rev != ''\n  build_identifier = 'git.' + short_rev\n  message('Using build identifier \"' + build_identifier + '\".')\nendif\n\nconf_data = configuration_data()\nconf_data.set_quoted('BUILD_IDENTIFIER', build_identifier)\nconfigure_file(output: 'build_id.h', configuration: conf_data)\n\n# Some malloc libraries require to be linked first.\nif get_option('malloc') == 'mimalloc' and cc.get_id() == 'msvc'\n  if get_option('b_vscrt') != 'md' and get_option('b_vscrt') != 'mdd'\n    error('You need -Db_vscrt=md (or mdd)')\n  endif\n  add_project_link_arguments('/INCLUDE:mi_version', language : 'cpp')\n  deps += cc.find_library('mimalloc-override', dirs: get_option('mimalloc_libdir'), required: true)\nelif get_option('malloc') != ''\n  deps += cc.find_library(get_option('malloc'), required: true)\nendif\n\n# ONNX and HLO protobufs.\ngen_proto_src = generator(compile_proto, output: ['@BASENAME@.pb.h'],\n  arguments : [\n    '--proto_path=@CURRENT_SOURCE_DIR@/src',\n    '--cpp_out=@BUILD_DIR@',\n    '@INPUT@'])\n\nfiles += gen_proto_src.process('src/neural/onnx/onnx.proto',\n  preserve_path_from : meson.current_source_dir() + '/src/')\n\nfiles += gen_proto_src.process('src/neural/xla/hlo.proto',\n  preserve_path_from : meson.current_source_dir() + '/src/')\n\n#############################################################################\n## Main files\n#############################################################################\ncommon_files += [\n  'src/chess/bitboard.cc',\n  'src/chess/board.cc',\n  'src/chess/gamestate.cc',\n  'src/chess/position.cc',\n  'src/chess/uciloop.cc',\n  'src/neural/backend.cc',\n  'src/neural/decoder.cc',\n  'src/neural/encoder.cc',\n  'src/neural/register.cc',\n  'src/neural/shared_params.cc',\n  'src/neural/wrapper.cc',\n  'src/search/classic/node.cc',\n  'src/syzygy/syzygy.cc',\n  'src/trainingdata/reader.cc',\n  'src/trainingdata/trainingdata.cc',\n  'src/trainingdata/writer.cc',\n  'src/utils/commandline.cc',\n  'src/utils/configfile.cc',\n  'src/utils/esc_codes.cc',\n  'src/utils/files.cc',\n  'src/utils/logging.cc',\n  'src/utils/optionsdict.cc',\n  'src/utils/optionsparser.cc',\n  'src/utils/random.cc',\n  'src/utils/string.cc',\n  'src/version.cc',\n]\n\nfiles += [\n  'src/engine_classic.cc',\n  'src/engine_loop.cc',\n  'src/engine.cc',\n  'src/neural/backends/network_check.cc',\n  'src/neural/backends/network_demux.cc',\n  'src/neural/backends/network_mux.cc',\n  'src/neural/backends/network_random.cc',\n  'src/neural/backends/network_record.cc',\n  'src/neural/backends/network_rr.cc',\n  'src/neural/backends/network_trivial.cc',\n  'src/neural/cache.cc',\n  'src/neural/factory.cc',\n  'src/neural/loader.cc',\n  'src/neural/memcache.cc',\n  'src/neural/network_legacy.cc',\n  'src/neural/onnx/adapters.cc',\n  'src/neural/onnx/builder.cc',\n  'src/neural/onnx/converter.cc',\n  'src/neural/xla/hlo_builder.cc',\n  'src/neural/xla/onnx2hlo.cc',\n  'src/neural/xla/print_hlo.cc',\n  'src/neural/xla/xla_tensor.cc',\n  'src/search/classic/params.cc',\n  'src/search/classic/search.cc',\n  'src/search/classic/stoppers/alphazero.cc',\n  'src/search/classic/stoppers/common.cc',\n  'src/search/classic/stoppers/factory.cc',\n  'src/search/classic/stoppers/legacy.cc',\n  'src/search/classic/stoppers/simple.cc',\n  'src/search/classic/stoppers/smooth.cc',\n  'src/search/classic/stoppers/stoppers.cc',\n  'src/search/classic/stoppers/timemgr.cc',\n  'src/search/register.cc',\n  'src/selfplay/game.cc',\n  'src/selfplay/loop.cc',\n  'src/selfplay/multigame.cc',\n  'src/selfplay/tournament.cc',\n  'src/tools/backendbench.cc',\n  'src/tools/benchmark.cc',\n  'src/tools/describenet.cc',\n  'src/tools/leela2onnx.cc',\n  'src/tools/onnx2leela.cc',\n  'src/utils/histogram.cc',\n  'src/utils/numa.cc',\n  'src/utils/weights_adapter.cc',\n]\n\nfiles += [\n  'src/search/instamove/instamove.cc',\n]\nincludes += include_directories('src')\n\ndeps += dependency('threads')\n\n#############################################################################\n## Platform specific files\n############################################################################\nif host_machine.system() == 'windows'\n  common_files += 'src/utils/filesystem.win32.cc'\nelse\n  common_files += 'src/utils/filesystem.posix.cc'\nendif\n\n#############################################################################\n## BACKENDS\n#############################################################################\n\nif get_option('build_backends')\n  ## ~~~~~~~~~~\n  ## Tensorflow\n  ## ~~~~~~~~~~\n  tf_dl_lib = cc.find_library('dl', required: false)\n  # We had `is_system: true` to reduce warnings, but meson > 0.56.0 breaks.\n  tf_tensorflow_cc_lib = dependency('tensorflow_cc', required: false)\n  if get_option('tensorflow') and tf_dl_lib.found() and tf_tensorflow_cc_lib.found()\n    deps += [tf_dl_lib, tf_tensorflow_cc_lib]\n    files += 'src/neural/backends/network_tf_cc.cc'\n    has_backends = true\n  endif\n\n  ## ~~~~~\n  ## Blas\n  ## ~~~~~\n\n  shared_files = []\n\n  accelerate_lib = dependency('Accelerate', required: false)\n\n  mkl_libdirs = get_option('mkl_libdirs')\n  mkl_lib = cc.find_library('mkl_rt', dirs: mkl_libdirs, required: false)\n  if not mkl_lib.found()\n    mkl_lib = cc.find_library('mklml', dirs: mkl_libdirs, required: false)\n  endif\n\n  dnnl_libdirs = [get_option('dnnl_dir') + '/lib64', get_option('dnnl_dir') + '/lib']\n  dnnl_lib = cc.find_library('dnnl', dirs: dnnl_libdirs, required: false)\n\n  openblas_libdirs = get_option('openblas_libdirs')\n  openblas_lib = cc.find_library('openblas.dll', dirs: openblas_libdirs, required: false)\n  if not openblas_lib.found()\n    openblas_lib = cc.find_library('openblas', dirs: openblas_libdirs, required: false)\n  endif\n\n  if get_option('blas')\n    if get_option('mkl') and mkl_lib.found()\n      mkl_inc = get_option('mkl_include')\n      if run_command('scripts/checkdir.py', mkl_inc, check : false).returncode() == 0\n        includes += include_directories(mkl_inc)\n      endif\n      if cc.has_header('mkl.h')\n        add_project_arguments(['-DUSE_MKL', '-DUSE_BLAS'], language : 'cpp')\n        deps += [ mkl_lib ]\n      endif\n\n    elif get_option('dnnl') and dnnl_lib.found()\n      add_project_arguments(['-DUSE_DNNL', '-DUSE_BLAS'], language : 'cpp')\n      includes += include_directories(get_option('dnnl_dir') + '/include')\n      deps += [ dnnl_lib, dependency('openmp', required:true) ]\n\n    elif get_option('accelerate') and accelerate_lib.found()\n      deps += [ accelerate_lib ]\n      add_project_arguments('-DUSE_BLAS', language : 'cpp')\n\n    elif get_option('openblas') and openblas_lib.found()\n      add_project_arguments(['-DUSE_OPENBLAS', '-DUSE_BLAS'], language : 'cpp')\n\n      required_openblas_header = 'openblas_config.h'\n      if not cc.has_header(required_openblas_header)\n        openblas_headers_found = false\n\n        # add the first valid include directory\n        foreach d : get_option('openblas_include')\n          if not openblas_headers_found and cc.has_header(required_openblas_header, args: '-I' + d)\n            includes += include_directories(d)\n            openblas_headers_found = true\n          endif\n        endforeach\n\n        if not openblas_headers_found\n          error('Failed to detect OpenBLAS headers. Did you install libopenblas-dev?')\n        endif\n      endif\n\n      deps += [ openblas_lib ]\n\n    endif\n\n    deps += dependency('eigen3', fallback: ['eigen', 'eigen_dep']).as_system()\n\n    ispc = find_program('ispc', required: false)\n    ispc_arch = 'x86-64'\n    ispc_extra_args = []\n    if get_option('ispc') and ispc.found()\n      ispc_native_only = get_option('ispc_native_only') and not meson.is_cross_build()  \n      if host_machine.system() == 'windows'\n        outputnames = [ '@BASENAME@.obj']\n        if not ispc_native_only\n          outputnames += ['@BASENAME@_sse2.obj', '@BASENAME@_sse4.obj',\n                          '@BASENAME@_avx.obj', '@BASENAME@_avx2.obj',\n                          '@BASENAME@_avx512knl.obj', '@BASENAME@_avx512skx.obj' ]\n        endif\n      else\n        ispc_extra_args += ['--pic']\n        outputnames = [ '@BASENAME@.o']\n        if not ispc_native_only\n          outputnames += ['@BASENAME@_sse2.o', '@BASENAME@_sse4.o',\n                          '@BASENAME@_avx.o', '@BASENAME@_avx2.o',\n                          '@BASENAME@_avx512knl.o', '@BASENAME@_avx512skx.o' ]\n        endif\n      endif\n      ispc_target = 'sse2-i32x8,sse4-i32x8,avx1-i32x8,avx2-i32x8,avx512knl-i32x16,avx512skx-i32x16'\n\n      if host_machine.system() == 'android'\n        ispc_extra_args += ['--target-os=android']\n      endif\n\n      if ['arm', 'aarch64'].contains(host_machine.cpu_family())\n        outputnames = [ '@BASENAME@.o']\n        if host_machine.cpu_family() == 'aarch64'\n          ispc_target = 'neon-i32x8'\n          ispc_arch = 'aarch64'\n        else\n          ispc_target = 'neon-i32x4'\n          ispc_arch = 'arm'\n        endif\n      endif\n\n      if ispc_native_only\n        ispc_target = 'host'\n      endif\n\n      iscp_gen = generator(ispc,\n        output: [ '@BASENAME@_ispc.h', outputnames ],\n        arguments: [ '-O2', '--wno-perf', '--arch=' + ispc_arch,\n                     '--target=' + ispc_target,\n                     '@INPUT@', '-o', '@OUTPUT1@' ,'-h', '@OUTPUT0@' ]\n                     + ispc_extra_args\n      )\n    endif\n\n    blas_files = [\n    'src/neural/backends/blas/convolution1.cc',\n    'src/neural/backends/blas/fully_connected_layer.cc',\n    'src/neural/backends/blas/se_unit.cc',\n    'src/neural/backends/blas/network_blas.cc',\n    'src/neural/backends/blas/winograd_convolution3.cc'\n    ]\n\n    shared_files = [\n    'src/neural/backends/shared/activation.cc',\n    'src/neural/backends/shared/winograd_filter.cc',\n    ]\n\n    files += blas_files\n    has_backends = true\n\n    if get_option('ispc') and ispc.found()\n      files += iscp_gen.process('src/neural/backends/blas/winograd_transform.ispc')\n      files += iscp_gen.process('src/neural/backends/blas/layer_norm.ispc')\n      files += iscp_gen.process('src/neural/backends/shared/activation.ispc')\n      add_project_arguments('-DUSE_ISPC', language : 'cpp')\n    endif\n\n  endif\n\n\n  ## ~~~~~\n  ## OpenCL\n  ## ~~~~~\n\n  has_opencl = false\n\n  opencl_libdirs = get_option('opencl_libdirs')\n  opencl_lib=cc.find_library('OpenCL', dirs: opencl_libdirs, required: false)\n\n  opencl_framework=dependency('OpenCL', method: 'extraframework', required: false)\n  if opencl_framework.found()\n      opencl_dep = [ opencl_framework ]\n      has_opencl = true\n\n  elif opencl_lib.found() and cc.has_header('CL/opencl.h', args: '-I' + get_option('opencl_include'))\n      opencl_dep = [ opencl_lib ]\n      has_opencl = true\n\n  endif\n\n  if get_option('opencl') and has_opencl\n\n    opencl_files = [\n      'src/neural/backends/opencl/network_opencl.cc',\n      'src/neural/backends/opencl/OpenCL.cc',\n      'src/neural/backends/opencl/OpenCLTuner.cc',\n      'src/neural/backends/opencl/OpenCLBuffers.cc',\n    ]\n\n    shared_files = [\n    'src/neural/backends/shared/activation.cc',\n    'src/neural/backends/shared/winograd_filter.cc',\n    ]\n\n    if not opencl_framework.found()\n      includes += include_directories(get_option('opencl_include'))\n    endif\n    deps += opencl_dep\n    files += opencl_files\n    has_backends = true\n\n  endif\n\n  files += shared_files\n\n  ## ~~~~~\n  ## cuDNN\n  ## ~~~~~\n  cudnn_libdirs = get_option('cudnn_libdirs')\n  cu_blas = cc.find_library('cublas', dirs: cudnn_libdirs, required: false)\n  cu_dnn = cc.find_library('cudnn', dirs: cudnn_libdirs, required: false)\n  cu_dart = cc.find_library('cudart', dirs: cudnn_libdirs, required: false)\n  nvcc = find_program('nvcc', '/usr/local/cuda/bin/nvcc', '/opt/cuda/bin/nvcc',\n                      required: false)\n\n  if (get_option('cudnn') or get_option('plain_cuda')) and cu_blas.found() and cu_dart.found() and nvcc.found()\n    deps += [cu_blas, cu_dart]\n    cuda_files = ['src/neural/backends/cuda/layers.cc']\n    if get_option('cudnn') and cu_dnn.found()\n      deps += cu_dnn\n      cuda_files += 'src/neural/backends/cuda/network_cudnn.cc'\n      cuda_files += 'src/neural/backends/cuda/network_cuda.cc' # To support newer nets.\n      add_project_arguments('-DUSE_CUDNN', language : 'cpp')\n    elif get_option('plain_cuda')\n      cuda_files += 'src/neural/backends/cuda/network_cuda.cc'\n    endif\n    foreach d : get_option('cudnn_include')\n      if run_command('scripts/checkdir.py', d, check : false).returncode() == 0\n        includes += include_directories(d, is_system: true)\n      endif\n    endforeach\n    includes += include_directories('src/neural/backends/cuda/')\n\n    cuda_arguments = ['-c', '@INPUT@', '-o', '@OUTPUT@',\n                      '-I', meson.current_source_dir() + '/src']\n    nvcc_help = run_command(nvcc, '-h', check : false).stdout()\n    if host_machine.system() == 'windows'\n      if get_option('b_vscrt') == 'mt'\n        cuda_arguments += ['-Xcompiler', '-MT']\n      elif get_option('b_vscrt') == 'mtd'\n        cuda_arguments += ['-Xcompiler', '-MTd']\n      elif get_option('b_vscrt') == 'mdd' or (get_option('b_vscrt') == 'from_buildtype' and get_option('buildtype') == 'debug')\n        cuda_arguments += ['-Xcompiler', '-MDd']\n      elif get_option('b_vscrt') != 'none'\n        cuda_arguments += ['-Xcompiler', '-MD']\n      endif\n    else\n      cuda_arguments += ['--std=c++14', '-Xcompiler', '-fPIC']\n    endif\n    if get_option('nvcc_ccbin') != ''\n      cuda_arguments += ['-ccbin=' + get_option('nvcc_ccbin')]\n    endif\n    cuda_cc = get_option('cc_cuda') # Unfortunately option cuda_cc is reserved.\n    nvcc_extra_args = []\n    if cuda_cc != ''\n      nvcc_extra_args = ['-arch=compute_' + cuda_cc, '-code=sm_' + cuda_cc]\n    elif get_option('native_cuda') and nvcc_help.contains('-arch=native')\n      nvcc_extra_args = ['-arch=native']\n    elif nvcc_help.contains('-arch=all-major')\n      nvcc_extra_args = ['-arch=all-major', '-Wno-deprecated-gpu-targets']\n    else\n      nvcc_extra_args = ['-Wno-deprecated-gpu-targets']\n      # Fallback for cuda versions without -arch=all-major.\n      foreach x : ['35', '50', '60', '70', '80']\n        if nvcc_help.contains('sm_' + x)\n          nvcc_extra_args += '-gencode=arch=compute_' + x + ',code=sm_' + x\n        endif\n      endforeach\n      # For forward compatibility.\n      if nvcc_help.contains('sm_80') # Cuda 11+\n        nvcc_extra_args += '-gencode=arch=compute_80,code=compute_80'\n      elif nvcc_help.contains('sm_75') # Cuda 10+\n        nvcc_extra_args += '-gencode=arch=compute_75,code=compute_75'\n      endif\n    endif\n    foreach x : get_option('cudnn_include')\n      cuda_arguments += ['-I', x]\n    endforeach\n    if host_machine.system() == 'windows'\n      outputname = '@BASENAME@.obj'\n    else\n      outputname = '@BASENAME@.o'\n    endif\n\t files += cuda_files\n    files += custom_target('cuda fp32 code',\n      input : 'src/neural/backends/cuda/common_kernels.cu',\n      output : outputname,\n      depend_files: 'src/neural/backends/cuda/winograd_helper.inc',\n      command : [nvcc, nvcc_extra_args, cuda_arguments]\n    )\n\n    files += custom_target('cuda fp16 code',\n      input : 'src/neural/backends/cuda/fp16_kernels.cu',\n      output : outputname,\n      depend_files: 'src/neural/backends/cuda/winograd_helper.inc',\n      command : [nvcc, nvcc_extra_args, cuda_arguments]\n    )\n    has_backends = true\n  endif\n\n  ## ~~~~~~~~\n  ## DirectX\n  ## ~~~~~~~~\n\n  # we should always be able to build DirectX12 backend on windows platform\n  if host_machine.system() == 'windows' and get_option('dx')\n    dx_d3d12 = cc.find_library('d3d12')\n    dx_dxgi = cc.find_library('dxgi')\n\n    dx_files = [\n      'src/neural/backends/dx/network_dx.cc',\n      'src/neural/backends/dx/shader_wrapper.cc',\n      'src/neural/backends/dx/layers_dx.cc',\n    ]\n    files += dx_files\n    deps += [dx_d3d12, dx_dxgi]\n\n    subdir('src/neural/backends/dx/shaders')\n\n    has_backends = true\n  endif\n\n  if get_option('onednn') and dnnl_lib.found()\n    includes += include_directories(get_option('dnnl_dir') + '/include')\n    deps += [ dnnl_lib, dependency('openmp', required:true) ]\n    files += [\n      'src/neural/backends/onednn/network_onednn.cc',\n      'src/neural/backends/onednn/layers.cc',\n    ]\n    has_backends = true\n  endif\n\n  ## ~~~~~~~~~~\n  ## ONNX\n  ## ~~~~~~~~~~\n  if get_option('onnx_libdir') != '' and get_option('onnx_include') != ''\n    deps += cc.find_library('onnxruntime', dirs: get_option('onnx_libdir'),\n                            required: true)\n    includes += include_directories(get_option('onnx_include'), is_system: true)\n    cc.has_header('onnxruntime_cxx_api.h', required: true,\n                  args: '-I' + get_option('onnx_include'))\n    if not cc.has_header('cpu_provider_factory.h',\n                         args: '-I' + get_option('onnx_include'))\n      cc.has_header('../providers/cpu/cpu_provider_factory.h', required: true,\n                    args: '-I' + get_option('onnx_include'))\n      includes += include_directories(get_option('onnx_include') + '/../providers/cpu',\n                                      is_system: true)\n    endif\n    files += 'src/neural/backends/network_onnx.cc'\n    if cc.find_library('onnxruntime_providers_rocm',\n                       dirs: get_option('onnx_libdir'), required: false).found()\n      add_project_arguments('-DUSE_ROCM', language : 'cpp')\n    endif\n    has_backends = true\n  endif\n\n  ## ~~~~~~~~\n  ## Metal\n  ## ~~~~~~~~\n  # Metal backend only available on MacOS.\n  # Check for required frameworks - Foundation, Metal and MPS.\n  metal_frameworks = dependency('appleframeworks',\n                                modules : ['Foundation', 'Metal', 'MetalPerformanceShaders', 'MetalPerformanceShadersGraph'],\n                                required: get_option('metal'))\n\n  if (metal_frameworks.found() and add_languages('objc', 'objcpp'))\n    deps += metal_frameworks\n\n    files += [\n      'src/neural/backends/metal/network_metal.cc',\n      'src/neural/backends/metal/mps/NetworkGraph.mm',\n      'src/neural/backends/metal/mps/MetalNetworkBuilder.mm',\n    ]\n\n    has_backends = true\n    add_project_arguments('-fobjc-arc', language : 'objc')\n    add_project_arguments('-fobjc-arc', language : 'objcpp')\n  endif\n\n\n  ## ~~~~~~~~\n  ## XLA\n  ## ~~~~~~~~\n  if get_option('xla')\n      files += [\n        'src/neural/backends/xla/network_xla.cc',\n        'src/neural/backends/xla/pjrt.cc',\n        'src/neural/backends/xla/xla_runner.cc',\n      ]\n      deps += cc.find_library('dl', required: false)\n      has_backends = true\n  endif\n\nendif # if get_option('build_backends')\n\nif not has_backends and get_option('lc0') and get_option('build_backends')\n  error('''\n\n        No usable computation backends (cudnn/opencl/blas/etc) enabled.\n        If you want to build with the random backend only, add\n        -Dbuild_backends=false to the build command line.''')\nendif\n\n\n#############################################################################\n## Dependencies\n#############################################################################\n  ## ~~~~\n  ## zlib\n  ## ~~~~\n  # Pick latest from https://wrapdb.mesonbuild.com/zlib and put into\n  # subprojects/zlib.wrap\n  if host_machine.system() == 'windows'\n    # In several cases where a zlib dependency was detected on windows, it\n    # caused trouble (crashes or failed builds). Better safe than sorry.\n    deps += subproject('zlib').get_variable('zlib_dep')\n  else\n    deps += dependency('zlib', fallback: ['zlib', 'zlib_dep'])\n  endif\n\n  ## ~~~~~~~~\n  ## Profiler\n  ## ~~~~~~~~\n  if get_option('buildtype') != 'release'\n    deps += cc.find_library('libprofiler',\n      dirs: ['/usr/local/lib'], required: false)\n  endif\n\n  deps += cc.find_library('libatomic', required: false)\n\n#############################################################################\n## Main Executable\n#############################################################################\n\nif not get_option('popcnt')\n  add_project_arguments('-DNO_POPCNT', language : 'cpp')\nendif\n\nif not get_option('f16c')\n  add_project_arguments('-DNO_F16C', language : 'cpp')\nendif\n\nif not get_option('pext')\n  add_project_arguments('-DNO_PEXT', language : 'cpp')\nendif\n\nif get_option('embed')\n  add_project_arguments('-DEMBED', language : 'cpp')\nendif\n\nif get_option('lc0')\n  files += common_files\n  executable('lc0', 'src/main.cc',\n       files, include_directories: includes, dependencies: deps, install: true)\nendif\n\n#############################################################################\n## Rescorer Executable\n#############################################################################\n\nif get_option('rescorer')\n  deps += subproject('gaviotatb').get_variable('gaviotatb_dep')\n  executable('rescorer', 'src/rescorer_main.cc',\n       [common_files, 'src/trainingdata/rescoreloop.cc'],\n       include_directories: includes, dependencies: deps, install: true)\nendif\n\n#############################################################################\n## Tests\n#############################################################################\n\nif get_option('gtest')\n  gtest = dependency('gtest', fallback: ['gtest', 'gtest_dep'])\n  lc0_lib = library('lc0_lib', files, include_directories: includes, dependencies: deps)\n\n  test('ChessBoard',\n    executable('chessboard_test', 'src/chess/board_test.cc',\n    include_directories: includes, link_with: lc0_lib, dependencies: gtest\n  ), args: '--gtest_output=xml:chessboard.xml', timeout: 90)\n\n  test('HashCat',\n    executable('hashcat_test', 'src/utils/hashcat_test.cc',\n    include_directories: includes, link_with: lc0_lib, dependencies: gtest\n  ), args: '--gtest_output=xml:hashcat.xml', timeout: 90)\n\n  test('PositionTest',\n    executable('position_test', 'src/chess/position_test.cc',\n    include_directories: includes, link_with: lc0_lib, dependencies: gtest\n  ), args: '--gtest_output=xml:position.xml', timeout: 90)\n\n  test('OptionsParserTest',\n    executable('optionsparser_test', 'src/utils/optionsparser_test.cc',\n    include_directories: includes, link_with: lc0_lib, dependencies: gtest\n  ), args: '--gtest_output=xml:optionsparser.xml', timeout: 90)\n\n  test('SyzygyTest',\n    executable('syzygy_test', 'src/syzygy/syzygy_test.cc',\n    include_directories: includes, link_with: lc0_lib, dependencies: gtest\n  ), args: '--gtest_output=xml:syzygy.xml', timeout: 90)\n\n  test('EncodePositionForNN',\n    executable('encoder_test', 'src/neural/encoder_test.cc', pb_files,\n    include_directories: includes, link_with: lc0_lib,\n    dependencies: [gtest]\n  ), args: '--gtest_output=xml:encoder.xml', timeout: 90)\nendif\n\n\n#############################################################################\n## Python bindings\n#############################################################################\n\nif get_option('python_bindings')\n  pymod = import('python')\n  python = pymod.find_installation('python3')\n  if not python.language_version().version_compare('>3.7')\n    error('You need python 3.7 or newer')\n  endif\n  py_bindings_generator = find_program('scripts/gen_py_bindings.py')\n\n  gen_py_bindings = custom_target('backends', input:[], output:['backends.cc'],\n    command : [py_bindings_generator, '@OUTPUT0@'])\n\n  py_files = [ gen_py_bindings ]\n\n  cpython = dependency('python3')\n  python.extension_module('backends',\n    [py_files + files],\n    include_directories: [includes],\n    dependencies: [cpython] + deps,\n    subdir: 'lczero',\n    install: true)\nendif\n"
        },
        {
          "name": "meson_options.txt",
          "type": "blob",
          "size": 4.97265625,
          "content": "option('openblas_include',\n       type: 'array',\n       value: ['/usr/include/openblas/'],\n       description: 'Paths to openblas include directories')\n\noption('opencl_include',\n       type: 'string',\n       value: '/usr/include/',\n       description: 'Path to OpenCL include directory')\n\noption('openblas_libdirs',\n       type: 'array',\n       value: ['/usr/lib/'],\n       description: 'Paths to OpenBLAS libraries')\n\noption('opencl_libdirs',\n       type: 'array',\n       value: ['/opt/cuda/lib64/', '/usr/local/cuda/lib64/'],\n       description: 'Paths to OpenCL libraries')\n\noption('cudnn_libdirs',\n       type: 'array',\n       value: ['/opt/cuda/lib64/', '/usr/local/cuda/lib64/', '/usr/lib/cuda/lib64/'],\n       description: 'Paths to Cuda/cudnn libraries')\n\noption('mkl_libdirs',\n       type: 'array',\n       value: ['/opt/intel/lib/intel64', '/opt/intel/mkl/lib/intel64', '/opt/intel/mkl/lib'],\n       description: 'Paths to MKL libraries')\n\noption('mkl_include',\n       type: 'array',\n       value: ['/opt/intel/mkl/include'],\n       description: 'Paths to MKL libraries')\n\noption('dnnl_dir',\n       type: 'string',\n       value: '/usr',\n       description: 'Paths to DNNL install directory')\n\noption('cudnn_include',\n       type: 'array',\n       value: ['/opt/cuda/include/', '/usr/local/cuda/include/', '/usr/lib/cuda/include/'],\n       description: 'Paths to cudnn include directory')\n\noption('build_backends',\n       type: 'boolean',\n       value: true,\n       description: 'Build backends for NN computation')\n\noption('blas',\n       type: 'boolean',\n       value: true,\n       description: 'Enable BLAS backend')\n\noption('ispc',\n       type: 'boolean',\n       value: true,\n       description: 'use ispc')\n\noption('ispc_native_only',\n       type: 'boolean',\n       value: true,\n       description: 'use ispc and enable native arch only')\n\noption('native_cuda',\n       type: 'boolean',\n       value: true,\n       description: 'build cuda code for native arch only (if supported)')\n\noption('cudnn',\n       type: 'boolean',\n       value: true,\n       description: 'Enable cuDNN backend')\n\noption('plain_cuda',\n       type: 'boolean',\n       value: true,\n       description: 'Enable CUDA backend')\n\noption('opencl',\n       type: 'boolean',\n       value: true,\n       description: 'Enable OpenCL backend')\n\noption('dx',\n       type: 'boolean',\n       value: true,\n       description: 'Enable DirectX12 backend')\n\noption('tensorflow',\n       type: 'boolean',\n       value: false,\n       description: 'Enable TensorFlow backend')\n\noption('onednn',\n       type: 'boolean',\n       value: false,\n       description: 'Enable oneDNN backend')\n\noption('openblas',\n       type: 'boolean',\n       value: true,\n       description: 'Enable OpenBLAS support')\n\noption('mkl',\n       type: 'boolean',\n       value: true,\n       description: 'Enable MKL BLAS support')\n\noption('dnnl',\n       type: 'boolean',\n       value: false,\n       description: 'Enable DNNL BLAS support')\n\noption('accelerate',\n       type: 'boolean',\n       value: true,\n       description: 'Enable Accelerate BLAS support')\n\noption('metal',\n       type: 'feature',\n       value: 'auto',\n       description: 'Enable Metal backend')\n\noption('malloc',\n       type : 'string',\n       value: '',\n       description: 'Use alternative memory allocator, e.g. tcmalloc/jemalloc')\n\noption('mimalloc_libdir',\n       type : 'string',\n       value: '',\n       description: 'Library directory for malloc=mimalloc')\n\noption('popcnt',\n       type: 'boolean',\n       value: true,\n       description: 'Use the popcnt instruction')\n\noption('f16c',\n       type: 'boolean',\n       value: true,\n       description: 'Use natice fp16 conversion instructions')\n\noption('pext',\n       type: 'boolean',\n       value: false,\n       description: 'Use the pext instruction')\n\noption('neon',\n       type: 'boolean',\n       value: true,\n       description: 'Use neon instructions on arm processors')\n\noption('gtest',\n       type: 'boolean',\n       value: true,\n       description: 'Build gtest tests')\n\noption('embed',\n       type: 'boolean',\n       value: false,\n       description: 'Use embedded net by default')\n\noption('nvcc_ccbin',\n       type: 'string',\n       value: '',\n       description: 'Override C++ compiler used by cuda nvcc')\n\noption('python_bindings',\n       type: 'boolean',\n       value: false,\n       description: 'Build Python bindings for the python to bind.')\n\noption('cc_cuda',\n       type: 'string',\n       value: '',\n       description: 'Build for a specific cuda CC, e.g. -Dcc_cuda=35 for CC 3.5')\n\noption('onnx_libdir',\n       type: 'string',\n       value: '',\n       description: 'Paths to ONNX runtime libraries')\n\noption('onnx_include',\n       type: 'string',\n       value: '',\n       description: 'Paths to ONNX runtime includes')\n\noption('xla',\n       type: 'boolean',\n       value: false,\n       description: 'Enable XLA backend')\n\noption('lc0',\n       type: 'boolean',\n       value: true,\n       description: 'Build Lc0')\n\noption('rescorer',\n       type: 'boolean',\n       value: false,\n       description: 'Build rescorer')\n"
        },
        {
          "name": "openSUSE_install.md",
          "type": "blob",
          "size": 11.02734375,
          "content": "![openSUSE Logo](https://github.com/openSUSE/artwork/blob/master/logos/official/logo-color.png?style=centerme)\n# lc0 on openSUSE \n\nopenSUSE is a popular RPM based Linux distro, the install sources can be downloaded from [https://software.opensuse.org](https://software.opensuse.org) .\n\nThe steps described here are minimal, enough to install and run lc0 on openSUSE. The reader is encouraged to skim the Supplementary Information after completing the Install where additional information can be found to download an icon to beautify and enter complete information about the lc0 engine into Arena. I doubt anyone would want to run on a 32-bit machine, but for these kinds of oddball installs, modifying the script should be next to trivial.\n\nIf the User finds anything in this guide unclear, the original documentation is linked under \"Supplemental Information\" in the last section. And, don't forget to recommend(as an Issue) or submit a change (as a Pull).\n\n## RPM packages vs Building from Source\n\nAn extremely versatile Build script that makes building from source simple and trivial is provided below which should run on practically any version of openSUSE but supports only the openBLAS backend, which means it can be run on any openSUSE without any hardware dependencies, and supports any version of openSUSE LEAP(ie 42.x, 15.1, etc, possibly ARM) or Tumbleweed. Most of the procedure after starting the script is just waiting to finish, no technical knowledge is required.\n\nFor those who instead prefer to not install the many files to build lc0, experimental packages (as of this writing) are available for LEAP 15 and Tumbleweed only (as of this writing). Currently the RPM supports OpenCL(AMD GPU only) and BLAS (which can be installed on any hardware). For Users who wish to use a pre-built binary from a package, skip down to [\"RPM packages\"](https://github.com/putztzu/lc0/blob/master/openSUSE_install.md#rpm-packages)\n\nIf someone wishes to do the work to investigate the procedures to install other backends (As of this writing, Tensorflow and CUDA are possible) findings and updates to this guide are welcomed.\n\n## Supported openSUSE versions\n\nThe following until the \"RPM Packages\" section describes running the build script which would be the more flexible and versativle option today, which creates a binary for more than just the LEAP 15.0 and Tumbleweed x64 platforms\n\nThese build script instructions have been tested on current versions of LEAP 15.0 (The stable release) and Tumbleweed (The Development Rolling Release) on 64-bit machines but these instructions and the build script should work with all versions of LEAP and Tumbleweed both past and into the forseeable future provided the repositories and packages are available..\n\n## Supported lc0 Backends\n\nAlthough lc0 supports many backends including GPU computing, this guide currently describes using only the openBLAS backend for its lack of hardware dependencies. This means that this guide can be used to install on any openSUSE regardless of CPU or GPU, on physical or virtual machines. Anyone who wishes to build CUDA, OpenCL or Tensorflow backends are invited to contribute and modify this page.\n\n## For Players who don't want to know the details, Just set up and Go!\n\nNot all Players are Tech-heads, they just want something that will work ASAP without knowing the details. An Install Script is provided for you, which should have you playing in a very short period of time.\n\nSummary of steps\n\n* Compile the lc0 Engine\n* Download the Networks file and place in the same folder as the compiled lc0 binary\n* Move or Copy the folder containing the lc0 binary to a convenient location for setting up the graphical chessboard\n* Configure the graphical chessboard pointing to the lc0 binary\n\n#### Compile the lc0 Engine\n\nDownload and save the following file to your machine by clicking on the following link\n\n[install_openSUSE_lc0.sh](install_openSUSE_lc0.sh)\n\nThe file you just downloaded can be run from any location, but must be executed in a root console.\n\nOpen a root console by first opening whatever terminal or console was installed in your Desktop, examples might be Xterm, Konsole, Qterminal, Gnome Terminal.\nThen in your console type\n\n`\nsu\n`\n\nFor the following two commands and elsewhere below, the User can either copy the text into an open console or type the commands by hand.<br>\n\nChange directory to where your downloaded script is (most likely your Downloads folder) and execute.\nIf necessary, modify the execute permission of the script with \"chmod+x install_openSUSE_lc0.sh\"\n\n```\n\ncd ~/Downloads\n./install_openSUSE_lc0.sh\n```\n\n\n## RPM Packages\n\nIf you ran the script that builds from source, you can ignore this section and skip to the next section which describes installing a networks file. \n\nOtherwise, if you skipped most of what is described above because you want to use pre-built packages, this is where you should start!\n1. Using an openSUSE provided Web browser (recommend Firefox), find the package for your version of openSUSE and download and/or install the package. The actual location of packages may change depending on project status, so you may also want to use the web package search at https://software.opensuse.org/package/lc0 and click on the \"One-click install for your version of openSUSE.\n2. Once the RPM file has been downloaded, you can install using YaST, zypper or RPM by simply pointing the install command to the file.\n3. If successfully installed, you will find the lc0 binary at the following location and you can now proceed to the next section.\n```\n\n/usr/bin/lco\n```\n\n\n\n## The One Thing you must do Manually\n\n#### Download and install the Networks file\n\nThe Install script automates practically everything needed for the lc0 Engine to run when hooked up to a graphical chessboard. The one thing missing that you, the User has to do on your own is to select a \"Networks\" file which contains the game data for its thinking. New data is generated continuously and players may want to try different files so this can't be automated. You need to select a file from the following page (usually under 50MBytes) and drop the file into the same folder as your lc0 binary.\n\n[https://lczero.org/play/networks/bestnets/](https://lczero.org/play/networks/bestnets/)\n\n## An example setup with the Arena graphical chessboard\n\nThe following applies if you compiled your own lc0 binary or if you are using the pre-built lc0 binary on a machine with an AMD processor. Special instructions to use Arena with the RPM is provided below, otherwise if you built from source Arena should \"just work.\" An alternative is to use another graphical chessboard, [Cute Chess](https://cutechess.com/) has been tested and verified to work. Setting up Cute Chess is generally similar to setting up on Arena, with fewer options but generally the same major steps. If Users are unable to figure out how to set up with Cute Chess, a section will be added later.\n\nDownload the Arena Linux app from [Download Arena for Linux](http://www.playwitharena.com/?Download:Arena_for_Linux)\n\nIf your web browser offers to extract the archive, you should decline. Perform the following which installs in your User's Home Directory\n\n```\n\nmkdir ~/Arena\nmv arenalinux_64bit_1.1.tar.gz ~/Arena/\ncd ~/Arena/\ntar -xf arenalinux_64bit_1.1.tar.gz\n```\nNow, a special command to reset permissions on ~/.configure/ so that a regular User account can write to this directory. After you run the following command as root, you will be able to run Arena as a regular User.\n\n\n```\n\nchown -R $USER:$(id -gn $USER) ~/.config\n```\n\n\n\nNow you can execute Arena as a normal, non-root User with the following command.\n\n```\n\n./Arena_x86_64_linux\n```\n\n#### Copying the lc0 binary to a location for Arena access\n\nThe above completes the installation of Arena, but does not hook it up to any Chess Engines. You can set up the Chess Engines that come with Arena, but the following describes how to set up lc0.\nAssuming that your command console is still open and at the root of the Arena application, the next steps set up lc0 to connect to Arena\n\nThe \"network file\" in the following is the file you should have downloaded in the above section \"The One thing you must do Manually\"\n\nIf you built using the \"install_openSUSE_lc0.sh\" script, run the following\n```\n\nmkdir Engines/lc0\ncp -r /opt/lc0/build/release/* Engines/lc0/\ncp \"network file\" Engines/lc0/\n```\nIf you installed using a RPM, run the following\n```\n\nmkdir Engines/lc0\ncp /usr/bin/lc0 Engines/lc0/\ncp \"network file\" Engines/lc0/\n```\n\n\n\n#### Configure Arena to point to the lc0 binary\n\nYour files are now pre-positioned and ready for Arena.\n\nLaunch the Arena Engine Install Wizard with the F11 key. Or, if that doesn't work, then from the Arena menubar, \nEngines > Manage > Details tab > Installation Wizard button\n\nEnter the information as required, pointing to your lc0 binary at\n\n```\n\n[Arena_root]/Engines/lc0/lc0\n```\n\n__RPM Package installs only__:\n\n* In Arena, \"Load\" the lc0 engine\n* In Arena, Press Ctl-1 or \n   Engines > Engine 1 > Configure\n   Find the \"backend\" setting and select your preference, currently should be either opencl or blas\n* While still in \"Engine 1\" start the engine\n\nYou should now be able to play!\n\n\n\n\n## Removal / Uninstall\n\nIf RPMs were used to install lc0, you can remove using ordinary package management commands, eg the YaST Software Manager or the following command line\n...\n\n\nzypper rm lc0\n...\n\nThe following describes removing files manually, either to verify total removal or if installed from source\n\nThe following commands remove parts of the install, the User can decide which to implement\n\nThe script installs lc0 files in /opt/lc0\nSo the following removes these files\n\n```\n\nrm -r /opt/lc0/\n```\n\nThe script adds the following repositories. If you don't have something else using these repositories, they can be removed with the following command\n\n```\n\nzypper rr LEAP:devel:gcc LEAP:devel:languages:python:backports LEAP:science\n```\n\nThe following packages were installed by the script and can be uninstalled. Note that uninstalling packages doesn't remove any dependencies of these packages, and libzl is excluded from the list because it's commonly used for other things.\n\n```\n\nzypper rm git gcc-c++ gcc7-c++ meson ninja python3-abseil openblas_pthreads-devel-static\n```\n\n## Re-install\n\nUnless the Install script is interrupted, it's unlikely that the script has to be run again. If the script is run on a system more than once, non-critical errors (might look ugly, but will not harm a system) will be seen. Depending on the reason to run the Install script more than once, the User should consider either removing what has been installed (see Uninstall section) or commenting the lines in the Install script that would cause errors (primarily the Add Repo lines).\n\n## Supplementary Information\n\nFull Instructions connecting lc0 to graphical chessboards including Arena\n\n[Running Leela Chess Zero in a Chess GUI\"](https://github.com/LeelaChessZero/lc0/wiki/Running-Leela-Chess-Zero-in-a-Chess-GUI)\n\nOriginal instructions for setting up lc0 on all platforms\n\n[Getting Started](https://github.com/LeelaChessZero/lc0/wiki/Getting-Started)\n\nOriginal compilation Instructions\n\n[Build Instructions](https://github.com/LeelaChessZero/lc0)\n"
        },
        {
          "name": "pyproject.toml",
          "type": "blob",
          "size": 0.642578125,
          "content": "[build-system]\nrequires = [\"meson-python\"]\nbuild-backend = \"mesonpy\"\n\n[project]\nname = \"lczero_bindings\"\nversion = \"0.1.0\"\ndescription = \"Leela Chess Zero Python bindings\"\nauthors = [{ name = \"The LCZero Authors\" }]\nlicense = {file = \"COPYING\"}\nreadme = \"README.md\"\nrequires-python = \">=3.7\"\nclassifiers = [\n    \"Programming Language :: Python :: 3\",\n    \"Topic :: Games/Entertainment :: Board Games\",\n    \"Topic :: Scientific/Engineering :: Artificial Intelligence\",\n    \"Environment :: GPU\"\n]\n\n[project.urls]\nhomepage = \"https://github.com/LeelaChessZero/lc0\"\n\n[tool.meson-python.args]\ndist = []\nsetup = [\"-Dpython_bindings=true\"]\ncompile = []\ninstall = []"
        },
        {
          "name": "scripts",
          "type": "tree",
          "content": null
        },
        {
          "name": "src",
          "type": "tree",
          "content": null
        },
        {
          "name": "subprojects",
          "type": "tree",
          "content": null
        },
        {
          "name": "tensorflow.md",
          "type": "blob",
          "size": 0.8525390625,
          "content": "To build with tensorflow under linux you need to install Tensorflow_cc from\n<https://github.com/FloopCZ/tensorflow_cc>. Either release v1.9.0, v1.12.0 or\nv1.13.0. Tensorflow_cc requires a specific version of protobuf, which constrains\nthe build. Release v1.9.0 works out of the box, since the default protobuf\nsubproject (v3.5.1) is compatible and is used instead of a system installed\nversion. In contrast release v1.12.0 needs protobuf v3.6.0 and release v1.13.0\nis built with protobuf 3.6.1 but also works with 3.6.0. For those versions\n`-Dprotobuf-3-6-0=true` should be added to the build command line. Note that\nthis protobuf version has issues with static builds and crashes so is not\nrecommended for normal use. The crashes look very similar to:\n* <https://github.com/protocolbuffers/protobuf/issues/5107>\n* <https://github.com/protocolbuffers/protobuf/issues/5353>\n"
        },
        {
          "name": "third_party",
          "type": "tree",
          "content": null
        },
        {
          "name": "windows_build.md",
          "type": "blob",
          "size": 4.08984375,
          "content": "## Windows build\n\n0. [Install Microsoft Visual Studio](https://visualstudio.microsoft.com/) (2017 or later). Make sure\n   the option \"Desktop development with C++\" is selected (you can add it later if not).\n\n1. [Install git for windows](https://git-scm.com/download/win) - this can be used to get lc0 but is also\n   needed for meson. If you haven't downloaded lc0, you can do it now following the instructions in\n   the `README`(https://github.com/LeelaChessZero/lc0/blob/master/README.md).\n\n2. GPU users with nVIDIA cards (and \"compute capability\" 3.0 or higher) can build with CUDA/CuDNN.\n*  Install [CUDA](https://developer.nvidia.com/cuda-zone) (v10.0 is fine for Visual Studio 2017, newer is\n   needed for Visual Studio 2019) and then\n*  install the appropriate [cuDNN](https://developer.nvidia.com/cudnn).\n\n3. GPU users with recent Windows 10 installations can build with DirectX 12, this only requires updated\n   SDK headers (that may already be available in Visual Studio).\n\n4. CPU users may want to install a BLAS library. This can be either OpenBLAS, Intel MKL or Intel DNNL.\n   This is optional since the Eigen library can be used without installing anything, but probably with\n   worse performance.\n*  For [OpenBLAS go here](http://www.openblas.net/), you need a binary package with a filename of the\n   form `OpenBLAS-version-Win64-int32.zip`, they are not available for all versions, which you just unpack\n   at a location of your choise (but not inside the lc0 directory).\n*  For [Intel MKL go here](https://software.intel.com/en-us/mkl), where you need to register. After\n   installation don't forget to run `mklvars.bat intel64` to set up the paths to the dlls.\n*  For [Intel DNNL go here](https://github.com/intel/mkl-dnn/releases). Note that not all releases have\n   binaries available, you want `dnnl_win_*_cpu_vcomp.zip`.\n\n5. For OpenCL you also need to install OpenCL developer libraries.\n*  For AMD cards the AMD APP SDK 3.0 seems to be the appropriate one, to be installed after the card drivers.\n   This is not currently available on the AMD website, but links to a signed installer are available in the\n   [AMD community forum](https://community.amd.com/thread/222855).\n*  For nVIDIA cards it is included in the [CUDA toolkit](https://developer.nvidia.com/cuda-downloads).\n\n6. [Install Python3](https://www.python.org/) - be sure to check the box to add python to the path.\n\n7. Install Meson: `pip3 install --upgrade meson`\n\n8. Edit `build.cmd`:\n*  At the top, set to `true` and `false` the variables for the backends you want to build.\n*  Then set the paths for the build dependencies.\n    - Note: for `OPENCL_INCLUDE_PATH` you don't want the directory containing `opencl.h`, but one level higher\n    (the one containing `CL`).\n\n9. Run `build.cmd`. It will ask permission to delete the build directory, then generate MSVS project and\n   pause.\n\n10. Hit `Enter` to build it.\n\n11. Resulting binary will be `build/lc0.exe`\n\nAlternatively you can\n\n10. open generated solution `build/lc0.sln` in Visual Studio and build yourself.\n\n\n### Troubleshooting\n\nIf you get something like\n\n   Downloading zlib patch from https://wrapdb.mesonbuild.com/v1/projects/zlib/1.2.11/4/get_zip\n   A fallback URL could be specified using patch_fallback_url key in the wrap file\n\n   meson.build:604:4: ERROR: WrapDB connection failed to https://wrapdb.mesonbuild.com/v1/projects/zlib/1.2.11/4/get_zip with error <urlopen error [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: certificate has expired (_ssl.c:1108)>\n\nwhen you run build.cmd, it may be that your machine does not trust the Let's Encrypt R3 intermediate certificate. To fix this, download https://letsencrypt.org/certs/lets-encrypt-r3.pem, run Windows PowerShell as administrator, and run the following command:\n\n`Import-Certificate -FilePath *path to file* -CertStoreLocation Cert:\\LocalMachine\\CA`\n\nIf things still aren't working after that, you can instead manually download the\n\n\n   https://wrapdb.mesonbuild.com/v1/projects/zlib/1.2.11/4/get_zip\n\nfile in your browser and place the file in the lc0\\subprojects\\packagecache folder. Then remove the\n\n   lc0\\subprojects\\zlib-1.2.11\n\nfolder and run build again.\n"
        }
      ]
    }
  ]
}