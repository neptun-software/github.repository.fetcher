{
  "metadata": {
    "timestamp": 1736565266548,
    "page": 74,
    "hasNextPage": true,
    "endCursor": "Y3Vyc29yOjgw",
    "completionStatus": "IN_PROGRESS"
  },
  "repositories": [
    {
      "nameWithOwner": "nmslib/hnswlib",
      "stars": 4479,
      "defaultBranch": "master",
      "files": [
        {
          "name": ".github",
          "type": "tree",
          "content": null
        },
        {
          "name": ".gitignore",
          "type": "blob",
          "size": 0.1376953125,
          "content": "hnswlib.egg-info/\nbuild/\ndist/\ntmp/\npython_bindings/tests/__pycache__/\n*.pyd\nhnswlib.cpython*.so\nvar/\n.idea/\n.vscode/\n.vs/\n**.DS_Store\n*.pyc\n"
        },
        {
          "name": "ALGO_PARAMS.md",
          "type": "blob",
          "size": 2.5244140625,
          "content": "# HNSW algorithm parameters\n\n## Search parameters:\n* ```ef``` - the size of the dynamic list for the nearest neighbors (used during the search). Higher ```ef```\nleads to more accurate but slower search. ```ef``` cannot be set lower than the number of queried nearest neighbors\n```k```. The value ```ef``` of can be anything between ```k``` and the size of the dataset.\n* ```k``` number of nearest neighbors to be returned as the result.\nThe ```knn_query``` function returns two numpy arrays, containing labels and distances to the k found nearest \nelements for the queries. Note that in case the algorithm is not be able to find ```k``` neighbors to all of the queries,\n(this can be due to problems with graph or ```k```>size of the dataset) an exception is thrown.\n\nAn example of tuning the parameters can be found in [TESTING_RECALL.md](TESTING_RECALL.md)\n\n## Construction parameters:\n* ```M``` - the number of bi-directional links created for every new element during construction. Reasonable range for ```M``` \nis 2-100. Higher ```M``` work better on datasets with high intrinsic dimensionality and/or high recall, while low ```M``` work \nbetter for datasets with low intrinsic dimensionality and/or low recalls. The parameter also determines the algorithm's memory \nconsumption, which is roughly ```M * 8-10``` bytes per stored element.  \nAs an example for ```dim```=4 random vectors optimal ```M``` for search is somewhere around 6, while for high dimensional datasets \n(word embeddings, good face descriptors), higher ```M``` are required (e.g. ```M```=48-64) for optimal performance at high recall. \nThe range ```M```=12-48 is ok for the most of the use cases. When ```M``` is changed one has to update the other parameters. \nNonetheless, ef and ef_construction parameters can be roughly estimated by assuming that ```M```*```ef_{construction}``` is \na constant.\n\n* ```ef_construction``` - the parameter has the same meaning as ```ef```, but controls the index_time/index_accuracy. Bigger \nef_construction leads to longer construction, but better index quality. At some point, increasing ef_construction does\nnot improve the quality of the index. One way to check if the selection of ef_construction was ok is to measure a recall \nfor M nearest neighbor search when ```ef``` =```ef_construction```: if the recall is lower than 0.9, than there is room \nfor improvement.\n* ```num_elements``` - defines the maximum number of elements in the index. The index can be extended by saving/loading (load_index\nfunction has a parameter which defines the new maximum number of elements).\n"
        },
        {
          "name": "CMakeLists.txt",
          "type": "blob",
          "size": 3.9599609375,
          "content": "cmake_minimum_required(VERSION 3.0...3.26)\n\nproject(hnswlib\n    LANGUAGES CXX)\n\ninclude(GNUInstallDirs)\ninclude(CheckCXXCompilerFlag)\n\nadd_library(hnswlib INTERFACE)\nadd_library(hnswlib::hnswlib ALIAS hnswlib)\n\ntarget_include_directories(hnswlib INTERFACE\n    $<BUILD_INTERFACE:${CMAKE_CURRENT_SOURCE_DIR}>\n    $<INSTALL_INTERFACE:${CMAKE_INSTALL_INCLUDEDIR}>)\n\n# Install\ninstall(DIRECTORY ${CMAKE_CURRENT_SOURCE_DIR}/hnswlib\n    DESTINATION ${CMAKE_INSTALL_INCLUDEDIR})\n\ninstall(TARGETS hnswlib\n    EXPORT hnswlibTargets)\n\ninstall(EXPORT hnswlibTargets\n    FILE hnswlibConfig.cmake\n    NAMESPACE hnswlib::\n    DESTINATION ${CMAKE_INSTALL_LIBDIR}/cmake/hnswlib)\n\n# Examples and tests\nif(CMAKE_PROJECT_NAME STREQUAL PROJECT_NAME)\n    option(HNSWLIB_EXAMPLES \"Build examples and tests.\" ON)\nelse()\n    option(HNSWLIB_EXAMPLES \"Build examples and tests.\" OFF)\nendif()\nif(HNSWLIB_EXAMPLES)\n    set(CMAKE_CXX_STANDARD 11)\n\n    if (CMAKE_CXX_COMPILER_ID MATCHES \"Clang\")\n      SET( CMAKE_CXX_FLAGS  \"-Ofast -std=c++11 -DHAVE_CXX0X -openmp -fpic -ftree-vectorize\" )\n      check_cxx_compiler_flag(\"-march=native\" COMPILER_SUPPORT_NATIVE_FLAG)\n      if(COMPILER_SUPPORT_NATIVE_FLAG)\n        SET( CMAKE_CXX_FLAGS \"${CMAKE_CXX_FLAGS} -march=native\" )\n        message(\"set -march=native flag\")\n      else()\n        check_cxx_compiler_flag(\"-mcpu=apple-m1\" COMPILER_SUPPORT_M1_FLAG)\n        if(COMPILER_SUPPORT_M1_FLAG)\n          SET( CMAKE_CXX_FLAGS \"${CMAKE_CXX_FLAGS} -mcpu=apple-m1\" )\n          message(\"set -mcpu=apple-m1 flag\")\n        endif()\n      endif()\n    elseif (CMAKE_CXX_COMPILER_ID STREQUAL \"GNU\")\n      SET( CMAKE_CXX_FLAGS  \"-Ofast -lrt -std=c++11 -DHAVE_CXX0X -march=native -fpic -w -fopenmp -ftree-vectorize -ftree-vectorizer-verbose=0\" )\n    elseif (CMAKE_CXX_COMPILER_ID STREQUAL \"MSVC\")\n      SET( CMAKE_CXX_FLAGS  \"/O2 -DHAVE_CXX0X /W1 /openmp /EHsc\" )\n    endif()\n\n    # examples\n    add_executable(example_search examples/cpp/example_search.cpp)\n    target_link_libraries(example_search hnswlib)\n\n    add_executable(example_epsilon_search examples/cpp/example_epsilon_search.cpp)\n    target_link_libraries(example_epsilon_search hnswlib)\n\n    add_executable(example_multivector_search examples/cpp/example_multivector_search.cpp)\n    target_link_libraries(example_multivector_search hnswlib)\n\n    add_executable(example_filter examples/cpp/example_filter.cpp)\n    target_link_libraries(example_filter hnswlib)\n\n    add_executable(example_replace_deleted examples/cpp/example_replace_deleted.cpp)\n    target_link_libraries(example_replace_deleted hnswlib)\n\n    add_executable(example_mt_search examples/cpp/example_mt_search.cpp)\n    target_link_libraries(example_mt_search hnswlib)\n\n    add_executable(example_mt_filter examples/cpp/example_mt_filter.cpp)\n    target_link_libraries(example_mt_filter hnswlib)\n\n    add_executable(example_mt_replace_deleted examples/cpp/example_mt_replace_deleted.cpp)\n    target_link_libraries(example_mt_replace_deleted hnswlib)\n\n    # tests\n    add_executable(multivector_search_test tests/cpp/multivector_search_test.cpp)\n    target_link_libraries(multivector_search_test hnswlib)\n\n    add_executable(epsilon_search_test tests/cpp/epsilon_search_test.cpp)\n    target_link_libraries(epsilon_search_test hnswlib)\n\n    add_executable(test_updates tests/cpp/updates_test.cpp)\n    target_link_libraries(test_updates hnswlib)\n\n    add_executable(searchKnnCloserFirst_test tests/cpp/searchKnnCloserFirst_test.cpp)\n    target_link_libraries(searchKnnCloserFirst_test hnswlib)\n\n    add_executable(searchKnnWithFilter_test tests/cpp/searchKnnWithFilter_test.cpp)\n    target_link_libraries(searchKnnWithFilter_test hnswlib)\n\n    add_executable(multiThreadLoad_test tests/cpp/multiThreadLoad_test.cpp)\n    target_link_libraries(multiThreadLoad_test hnswlib)\n\n    add_executable(multiThread_replace_test tests/cpp/multiThread_replace_test.cpp)\n    target_link_libraries(multiThread_replace_test hnswlib)\n\n    add_executable(main tests/cpp/main.cpp tests/cpp/sift_1b.cpp)\n    target_link_libraries(main hnswlib)\nendif()\n"
        },
        {
          "name": "LICENSE",
          "type": "blob",
          "size": 11.0908203125,
          "content": "                                 Apache License\n                           Version 2.0, January 2004\n                        http://www.apache.org/licenses/\n\n   TERMS AND CONDITIONS FOR USE, REPRODUCTION, AND DISTRIBUTION\n\n   1. Definitions.\n\n      \"License\" shall mean the terms and conditions for use, reproduction,\n      and distribution as defined by Sections 1 through 9 of this document.\n\n      \"Licensor\" shall mean the copyright owner or entity authorized by\n      the copyright owner that is granting the License.\n\n      \"Legal Entity\" shall mean the union of the acting entity and all\n      other entities that control, are controlled by, or are under common\n      control with that entity. For the purposes of this definition,\n      \"control\" means (i) the power, direct or indirect, to cause the\n      direction or management of such entity, whether by contract or\n      otherwise, or (ii) ownership of fifty percent (50%) or more of the\n      outstanding shares, or (iii) beneficial ownership of such entity.\n\n      \"You\" (or \"Your\") shall mean an individual or Legal Entity\n      exercising permissions granted by this License.\n\n      \"Source\" form shall mean the preferred form for making modifications,\n      including but not limited to software source code, documentation\n      source, and configuration files.\n\n      \"Object\" form shall mean any form resulting from mechanical\n      transformation or translation of a Source form, including but\n      not limited to compiled object code, generated documentation,\n      and conversions to other media types.\n\n      \"Work\" shall mean the work of authorship, whether in Source or\n      Object form, made available under the License, as indicated by a\n      copyright notice that is included in or attached to the work\n      (an example is provided in the Appendix below).\n\n      \"Derivative Works\" shall mean any work, whether in Source or Object\n      form, that is based on (or derived from) the Work and for which the\n      editorial revisions, annotations, elaborations, or other modifications\n      represent, as a whole, an original work of authorship. For the purposes\n      of this License, Derivative Works shall not include works that remain\n      separable from, or merely link (or bind by name) to the interfaces of,\n      the Work and Derivative Works thereof.\n\n      \"Contribution\" shall mean any work of authorship, including\n      the original version of the Work and any modifications or additions\n      to that Work or Derivative Works thereof, that is intentionally\n      submitted to Licensor for inclusion in the Work by the copyright owner\n      or by an individual or Legal Entity authorized to submit on behalf of\n      the copyright owner. For the purposes of this definition, \"submitted\"\n      means any form of electronic, verbal, or written communication sent\n      to the Licensor or its representatives, including but not limited to\n      communication on electronic mailing lists, source code control systems,\n      and issue tracking systems that are managed by, or on behalf of, the\n      Licensor for the purpose of discussing and improving the Work, but\n      excluding communication that is conspicuously marked or otherwise\n      designated in writing by the copyright owner as \"Not a Contribution.\"\n\n      \"Contributor\" shall mean Licensor and any individual or Legal Entity\n      on behalf of whom a Contribution has been received by Licensor and\n      subsequently incorporated within the Work.\n\n   2. Grant of Copyright License. Subject to the terms and conditions of\n      this License, each Contributor hereby grants to You a perpetual,\n      worldwide, non-exclusive, no-charge, royalty-free, irrevocable\n      copyright license to reproduce, prepare Derivative Works of,\n      publicly display, publicly perform, sublicense, and distribute the\n      Work and such Derivative Works in Source or Object form.\n\n   3. Grant of Patent License. Subject to the terms and conditions of\n      this License, each Contributor hereby grants to You a perpetual,\n      worldwide, non-exclusive, no-charge, royalty-free, irrevocable\n      (except as stated in this section) patent license to make, have made,\n      use, offer to sell, sell, import, and otherwise transfer the Work,\n      where such license applies only to those patent claims licensable\n      by such Contributor that are necessarily infringed by their\n      Contribution(s) alone or by combination of their Contribution(s)\n      with the Work to which such Contribution(s) was submitted. If You\n      institute patent litigation against any entity (including a\n      cross-claim or counterclaim in a lawsuit) alleging that the Work\n      or a Contribution incorporated within the Work constitutes direct\n      or contributory patent infringement, then any patent licenses\n      granted to You under this License for that Work shall terminate\n      as of the date such litigation is filed.\n\n   4. Redistribution. You may reproduce and distribute copies of the\n      Work or Derivative Works thereof in any medium, with or without\n      modifications, and in Source or Object form, provided that You\n      meet the following conditions:\n\n      (a) You must give any other recipients of the Work or\n          Derivative Works a copy of this License; and\n\n      (b) You must cause any modified files to carry prominent notices\n          stating that You changed the files; and\n\n      (c) You must retain, in the Source form of any Derivative Works\n          that You distribute, all copyright, patent, trademark, and\n          attribution notices from the Source form of the Work,\n          excluding those notices that do not pertain to any part of\n          the Derivative Works; and\n\n      (d) If the Work includes a \"NOTICE\" text file as part of its\n          distribution, then any Derivative Works that You distribute must\n          include a readable copy of the attribution notices contained\n          within such NOTICE file, excluding those notices that do not\n          pertain to any part of the Derivative Works, in at least one\n          of the following places: within a NOTICE text file distributed\n          as part of the Derivative Works; within the Source form or\n          documentation, if provided along with the Derivative Works; or,\n          within a display generated by the Derivative Works, if and\n          wherever such third-party notices normally appear. The contents\n          of the NOTICE file are for informational purposes only and\n          do not modify the License. You may add Your own attribution\n          notices within Derivative Works that You distribute, alongside\n          or as an addendum to the NOTICE text from the Work, provided\n          that such additional attribution notices cannot be construed\n          as modifying the License.\n\n      You may add Your own copyright statement to Your modifications and\n      may provide additional or different license terms and conditions\n      for use, reproduction, or distribution of Your modifications, or\n      for any such Derivative Works as a whole, provided Your use,\n      reproduction, and distribution of the Work otherwise complies with\n      the conditions stated in this License.\n\n   5. Submission of Contributions. Unless You explicitly state otherwise,\n      any Contribution intentionally submitted for inclusion in the Work\n      by You to the Licensor shall be under the terms and conditions of\n      this License, without any additional terms or conditions.\n      Notwithstanding the above, nothing herein shall supersede or modify\n      the terms of any separate license agreement you may have executed\n      with Licensor regarding such Contributions.\n\n   6. Trademarks. This License does not grant permission to use the trade\n      names, trademarks, service marks, or product names of the Licensor,\n      except as required for reasonable and customary use in describing the\n      origin of the Work and reproducing the content of the NOTICE file.\n\n   7. Disclaimer of Warranty. Unless required by applicable law or\n      agreed to in writing, Licensor provides the Work (and each\n      Contributor provides its Contributions) on an \"AS IS\" BASIS,\n      WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or\n      implied, including, without limitation, any warranties or conditions\n      of TITLE, NON-INFRINGEMENT, MERCHANTABILITY, or FITNESS FOR A\n      PARTICULAR PURPOSE. You are solely responsible for determining the\n      appropriateness of using or redistributing the Work and assume any\n      risks associated with Your exercise of permissions under this License.\n\n   8. Limitation of Liability. In no event and under no legal theory,\n      whether in tort (including negligence), contract, or otherwise,\n      unless required by applicable law (such as deliberate and grossly\n      negligent acts) or agreed to in writing, shall any Contributor be\n      liable to You for damages, including any direct, indirect, special,\n      incidental, or consequential damages of any character arising as a\n      result of this License or out of the use or inability to use the\n      Work (including but not limited to damages for loss of goodwill,\n      work stoppage, computer failure or malfunction, or any and all\n      other commercial damages or losses), even if such Contributor\n      has been advised of the possibility of such damages.\n\n   9. Accepting Warranty or Additional Liability. While redistributing\n      the Work or Derivative Works thereof, You may choose to offer,\n      and charge a fee for, acceptance of support, warranty, indemnity,\n      or other liability obligations and/or rights consistent with this\n      License. However, in accepting such obligations, You may act only\n      on Your own behalf and on Your sole responsibility, not on behalf\n      of any other Contributor, and only if You agree to indemnify,\n      defend, and hold each Contributor harmless for any liability\n      incurred by, or claims asserted against, such Contributor by reason\n      of your accepting any such warranty or additional liability.\n\n   END OF TERMS AND CONDITIONS\n\n   APPENDIX: How to apply the Apache License to your work.\n\n      To apply the Apache License to your work, attach the following\n      boilerplate notice, with the fields enclosed by brackets \"{}\"\n      replaced with your own identifying information. (Don't include\n      the brackets!)  The text should be enclosed in the appropriate\n      comment syntax for the file format. We also recommend that a\n      file or class name and description of purpose be included on the\n      same \"printed page\" as the copyright notice for easier\n      identification within third-party archives.\n\n   Copyright {yyyy} {name of copyright owner}\n\n   Licensed under the Apache License, Version 2.0 (the \"License\");\n   you may not use this file except in compliance with the License.\n   You may obtain a copy of the License at\n\n       http://www.apache.org/licenses/LICENSE-2.0\n\n   Unless required by applicable law or agreed to in writing, software\n   distributed under the License is distributed on an \"AS IS\" BASIS,\n   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n   See the License for the specific language governing permissions and\n   limitations under the License.\n"
        },
        {
          "name": "MANIFEST.in",
          "type": "blob",
          "size": 0.03515625,
          "content": "include hnswlib/*.h\ninclude LICENSE\n"
        },
        {
          "name": "Makefile",
          "type": "blob",
          "size": 0.28515625,
          "content": "pypi: dist\n\ttwine upload dist/*\n\ndist:\n\t-rm dist/*\n\tpip install build\n\tpython3 -m build --sdist\n\ntest:\n\tpython3 -m unittest discover --start-directory tests/python --pattern \"bindings_test*.py\"\n\nclean:\n\trm -rf *.egg-info build dist tmp var tests/__pycache__ hnswlib.cpython*.so\n\n.PHONY: dist\n"
        },
        {
          "name": "README.md",
          "type": "blob",
          "size": 15.6572265625,
          "content": "# Hnswlib - fast approximate nearest neighbor search\nHeader-only C++ HNSW implementation with python bindings, insertions and updates.\n\n**NEWS:**\n\n**version 0.8.0** \n\n* Multi-vector document search and epsilon search (for now, only in C++)\n* By default, there is no statistic aggregation, which speeds up the multi-threaded search (it does not seem like people are using it anyway: [Issue #495](https://github.com/nmslib/hnswlib/issues/495)). \n* Various bugfixes and improvements\n* `get_items` now have `return_type` parameter, which can be either 'numpy' or 'list'\n\nFull list of changes: https://github.com/nmslib/hnswlib/pull/523\n\n**version 0.7.0** \n\n* Added support to filtering (#402, #430) by [@kishorenc](https://github.com/kishorenc)\n* Added python interface for filtering (though note its performance is limited by GIL) (#417) by [@gtsoukas](https://github.com/gtsoukas)\n* Added support for replacing the elements that were marked as delete with newly inserted elements (to control the size of the index, #418) by [@dyashuni](https://github.com/dyashuni)\n* Fixed data races/deadlocks in updates/insertion, added stress test for multithreaded operation (#418) by [@dyashuni](https://github.com/dyashuni)\n* Documentation, tests, exception handling, refactoring (#375, #379, #380, #395, #396, #401, #406, #404, #409, #410, #416, #415, #431, #432, #433) by [@jlmelville](https://github.com/jlmelville), [@dyashuni](https://github.com/dyashuni), [@kishorenc](https://github.com/kishorenc), [@korzhenevski](https://github.com/korzhenevski), [@yoshoku](https://github.com/yoshoku), [@jianshu93](https://github.com/jianshu93), [@PLNech](https://github.com/PLNech)\n* global linkages (#383) by [@MasterAler](https://github.com/MasterAler), USE_SSE usage in MSVC (#408) by [@alxvth](https://github.com/alxvth)\n\n\n### Highlights:\n1) Lightweight, header-only, no dependencies other than C++ 11\n2) Interfaces for C++, Python, external support for Java and R (https://github.com/jlmelville/rcpphnsw).\n3) Has full support for incremental index construction and updating the elements (thanks to the contribution by Apoorv Sharma). Has support for element deletions \n(by marking them in index, later can be replaced with other elements). Python index is picklable.\n4) Can work with custom user defined distances (C++).\n5) Significantly less memory footprint and faster build time compared to current nmslib's implementation.\n\nDescription of the algorithm parameters can be found in [ALGO_PARAMS.md](ALGO_PARAMS.md).\n\n\n### Python bindings\n\n#### Supported distances:\n\n| Distance         | parameter       | Equation                |\n| -------------    |:---------------:| -----------------------:|\n|Squared L2        |'l2'             | d = sum((Ai-Bi)^2)      |\n|Inner product     |'ip'             | d = 1.0 - sum(Ai\\*Bi)   |\n|Cosine similarity |'cosine'         | d = 1.0 - sum(Ai\\*Bi) / sqrt(sum(Ai\\*Ai) * sum(Bi\\*Bi))|\n\nNote that inner product is not an actual metric. An element can be closer to some other element than to itself. That allows some speedup if you remove all elements that are not the closest to themselves from the index.\n\nFor other spaces use the nmslib library https://github.com/nmslib/nmslib. \n\n#### API description\n* `hnswlib.Index(space, dim)` creates a non-initialized index an HNSW in space `space` with integer dimension `dim`.\n\n`hnswlib.Index` methods:\n* `init_index(max_elements, M = 16, ef_construction = 200, random_seed = 100, allow_replace_deleted = False)` initializes the index from with no elements. \n    * `max_elements` defines the maximum number of elements that can be stored in the structure(can be increased/shrunk).\n    * `ef_construction` defines a construction time/accuracy trade-off (see [ALGO_PARAMS.md](ALGO_PARAMS.md)).\n    * `M` defines tha maximum number of outgoing connections in the graph ([ALGO_PARAMS.md](ALGO_PARAMS.md)).\n    * `allow_replace_deleted` enables replacing of deleted elements with new added ones.\n    \n* `add_items(data, ids, num_threads = -1, replace_deleted = False)` - inserts the `data`(numpy array of vectors, shape:`N*dim`) into the structure. \n    * `num_threads` sets the number of cpu threads to use (-1 means use default).\n    * `ids` are optional N-size numpy array of integer labels for all elements in `data`. \n      - If index already has the elements with the same labels, their features will be updated. Note that update procedure is slower than insertion of a new element, but more memory- and query-efficient.\n    * `replace_deleted` replaces deleted elements. Note it allows to save memory.\n      - to use it `init_index` should be called with `allow_replace_deleted=True`\n    * Thread-safe with other `add_items` calls, but not with `knn_query`.\n    \n* `mark_deleted(label)`  - marks the element as deleted, so it will be omitted from search results. Throws an exception if it is already deleted.\n\n* `unmark_deleted(label)`  - unmarks the element as deleted, so it will be not be omitted from search results.\n\n* `resize_index(new_size)` - changes the maximum capacity of the index. Not thread safe with `add_items` and `knn_query`.\n\n* `set_ef(ef)` - sets the query time accuracy/speed trade-off, defined by the `ef` parameter (\n[ALGO_PARAMS.md](ALGO_PARAMS.md)). Note that the parameter is currently not saved along with the index, so you need to set it manually after loading.\n\n* `knn_query(data, k = 1, num_threads = -1, filter = None)` make a batch query for `k` closest elements for each element of the \n    * `data` (shape:`N*dim`). Returns a numpy array of (shape:`N*k`).\n    * `num_threads` sets the number of cpu threads to use (-1 means use default).\n    * `filter` filters elements by its labels, returns elements with allowed ids. Note that search with a filter works slow in python in multithreaded mode. It is recommended to set `num_threads=1`\n    * Thread-safe with other `knn_query` calls, but not with `add_items`.\n    \n* `load_index(path_to_index, max_elements = 0, allow_replace_deleted = False)` loads the index from persistence to the uninitialized index.\n    * `max_elements`(optional) resets the maximum number of elements in the structure.\n    * `allow_replace_deleted` specifies whether the index being loaded has enabled replacing of deleted elements.\n      \n* `save_index(path_to_index)` saves the index from persistence.\n\n* `set_num_threads(num_threads)` set the default number of cpu threads used during data insertion/querying.\n  \n* `get_items(ids, return_type = 'numpy')` - returns a numpy array (shape:`N*dim`) of vectors that have integer identifiers specified in `ids` numpy vector (shape:`N`) if `return_type` is `list` return list of lists. Note that for cosine similarity it currently returns **normalized** vectors.\n  \n* `get_ids_list()`  - returns a list of all elements' ids.\n\n* `get_max_elements()` - returns the current capacity of the index\n\n* `get_current_count()` - returns the current number of element stored in the index\n\nRead-only properties of `hnswlib.Index` class:\n\n* `space` - name of the space (can be one of \"l2\", \"ip\", or \"cosine\"). \n\n* `dim`   - dimensionality of the space. \n\n* `M` - parameter that defines the maximum number of outgoing connections in the graph. \n\n* `ef_construction` - parameter that controls speed/accuracy trade-off during the index construction. \n\n* `max_elements` - current capacity of the index. Equivalent to `p.get_max_elements()`. \n\n* `element_count` - number of items in the index. Equivalent to `p.get_current_count()`. \n\nProperties of `hnswlib.Index` that support reading and writing:\n\n* `ef` - parameter controlling query time/accuracy trade-off.\n\n* `num_threads` - default number of threads to use in `add_items` or `knn_query`. Note that calling `p.set_num_threads(3)` is equivalent to `p.num_threads=3`.\n\n  \n        \n  \n#### Python bindings examples\n[See more examples here](examples/python/EXAMPLES.md):\n* Creating index, inserting elements, searching, serialization/deserialization\n* Filtering during the search with a boolean function\n* Deleting the elements and reusing the memory of the deleted elements for newly added elements\n\nAn example of creating index, inserting elements, searching and pickle serialization:\n```python\nimport hnswlib\nimport numpy as np\nimport pickle\n\ndim = 128\nnum_elements = 10000\n\n# Generating sample data\ndata = np.float32(np.random.random((num_elements, dim)))\nids = np.arange(num_elements)\n\n# Declaring index\np = hnswlib.Index(space = 'l2', dim = dim) # possible options are l2, cosine or ip\n\n# Initializing index - the maximum number of elements should be known beforehand\np.init_index(max_elements = num_elements, ef_construction = 200, M = 16)\n\n# Element insertion (can be called several times):\np.add_items(data, ids)\n\n# Controlling the recall by setting ef:\np.set_ef(50) # ef should always be > k\n\n# Query dataset, k - number of the closest elements (returns 2 numpy arrays)\nlabels, distances = p.knn_query(data, k = 1)\n\n# Index objects support pickling\n# WARNING: serialization via pickle.dumps(p) or p.__getstate__() is NOT thread-safe with p.add_items method!\n# Note: ef parameter is included in serialization; random number generator is initialized with random_seed on Index load\np_copy = pickle.loads(pickle.dumps(p)) # creates a copy of index p using pickle round-trip\n\n### Index parameters are exposed as class properties:\nprint(f\"Parameters passed to constructor:  space={p_copy.space}, dim={p_copy.dim}\") \nprint(f\"Index construction: M={p_copy.M}, ef_construction={p_copy.ef_construction}\")\nprint(f\"Index size is {p_copy.element_count} and index capacity is {p_copy.max_elements}\")\nprint(f\"Search speed/quality trade-off parameter: ef={p_copy.ef}\")\n```\n\nAn example with updates after serialization/deserialization:\n```python\nimport hnswlib\nimport numpy as np\n\ndim = 16\nnum_elements = 10000\n\n# Generating sample data\ndata = np.float32(np.random.random((num_elements, dim)))\n\n# We split the data in two batches:\ndata1 = data[:num_elements // 2]\ndata2 = data[num_elements // 2:]\n\n# Declaring index\np = hnswlib.Index(space='l2', dim=dim)  # possible options are l2, cosine or ip\n\n# Initializing index\n# max_elements - the maximum number of elements (capacity). Will throw an exception if exceeded\n# during insertion of an element.\n# The capacity can be increased by saving/loading the index, see below.\n#\n# ef_construction - controls index search speed/build speed tradeoff\n#\n# M - is tightly connected with internal dimensionality of the data. Strongly affects memory consumption (~M)\n# Higher M leads to higher accuracy/run_time at fixed ef/efConstruction\n\np.init_index(max_elements=num_elements//2, ef_construction=100, M=16)\n\n# Controlling the recall by setting ef:\n# higher ef leads to better accuracy, but slower search\np.set_ef(10)\n\n# Set number of threads used during batch search/construction\n# By default using all available cores\np.set_num_threads(4)\n\nprint(\"Adding first batch of %d elements\" % (len(data1)))\np.add_items(data1)\n\n# Query the elements for themselves and measure recall:\nlabels, distances = p.knn_query(data1, k=1)\nprint(\"Recall for the first batch:\", np.mean(labels.reshape(-1) == np.arange(len(data1))), \"\\n\")\n\n# Serializing and deleting the index:\nindex_path='first_half.bin'\nprint(\"Saving index to '%s'\" % index_path)\np.save_index(\"first_half.bin\")\ndel p\n\n# Re-initializing, loading the index\np = hnswlib.Index(space='l2', dim=dim)  # the space can be changed - keeps the data, alters the distance function.\n\nprint(\"\\nLoading index from 'first_half.bin'\\n\")\n\n# Increase the total capacity (max_elements), so that it will handle the new data\np.load_index(\"first_half.bin\", max_elements = num_elements)\n\nprint(\"Adding the second batch of %d elements\" % (len(data2)))\np.add_items(data2)\n\n# Query the elements for themselves and measure recall:\nlabels, distances = p.knn_query(data, k=1)\nprint(\"Recall for two batches:\", np.mean(labels.reshape(-1) == np.arange(len(data))), \"\\n\")\n```\n\n#### C++ examples\n[See examples here](examples/cpp/EXAMPLES.md):\n* creating index, inserting elements, searching, serialization/deserialization\n* filtering during the search with a boolean function\n* deleting the elements and reusing the memory of the deleted elements for newly added elements\n* multithreaded usage\n* multivector search\n* epsilon search\n\n\n### Bindings installation\n\nYou can install from sources:\n```bash\napt-get install -y python-setuptools python-pip\ngit clone https://github.com/nmslib/hnswlib.git\ncd hnswlib\npip install .\n```\n\nor you can install via pip:\n`pip install hnswlib`\n\n\n### For developers \nContributions are highly welcome!\n\nPlease make pull requests against the `develop` branch.\n\nWhen making changes please run tests (and please add a test to `tests/python` in case there is new functionality):\n```bash\npython -m unittest discover --start-directory tests/python --pattern \"bindings_test*.py\"\n```\n\n\n### Other implementations\n* Non-metric space library (nmslib) - main library(python, C++), supports exotic distances: https://github.com/nmslib/nmslib\n* Faiss library by facebook, uses own HNSW  implementation for coarse quantization (python, C++):\nhttps://github.com/facebookresearch/faiss\n* Code for the paper \n[\"Revisiting the Inverted Indices for Billion-Scale Approximate Nearest Neighbors\"](https://arxiv.org/abs/1802.02422) \n(current state-of-the-art in compressed indexes, C++):\nhttps://github.com/dbaranchuk/ivf-hnsw\n* Amazon PECOS https://github.com/amzn/pecos \n* TOROS N2 (python, C++): https://github.com/kakao/n2 \n* Online HNSW (C++): https://github.com/andrusha97/online-hnsw) \n* Go implementation: https://github.com/Bithack/go-hnsw\n* Python implementation (as a part of the clustering code by by Matteo Dell'Amico): https://github.com/matteodellamico/flexible-clustering\n* Julia implmentation https://github.com/JuliaNeighbors/HNSW.jl\n* Java implementation: https://github.com/jelmerk/hnswlib\n* Java bindings using Java Native Access: https://github.com/stepstone-tech/hnswlib-jna\n* .Net implementation: https://github.com/curiosity-ai/hnsw-sharp\n* CUDA implementation: https://github.com/js1010/cuhnsw\n* Rust implementation https://github.com/rust-cv/hnsw\n* Rust implementation for memory and thread safety purposes and There is  A Trait to enable the user to implement its own distances. It takes as data slices of types T satisfying T:Serialize+Clone+Send+Sync.: https://github.com/jean-pierreBoth/hnswlib-rs\n\n### 200M SIFT test reproduction \nTo download and extract the bigann dataset (from root directory):\n```bash\npython tests/cpp/download_bigann.py\n```\nTo compile:\n```bash\nmkdir build\ncd build\ncmake ..\nmake all\n```\n\nTo run the test on 200M SIFT subset:\n```bash\n./main\n```\n\nThe size of the BigANN subset (in millions) is controlled by the variable **subset_size_millions** hardcoded in **sift_1b.cpp**.\n\n### Updates test\nTo generate testing data (from root directory):\n```bash\ncd tests/cpp\npython update_gen_data.py\n```\nTo compile (from root directory):\n```bash\nmkdir build\ncd build\ncmake ..\nmake \n```\nTo run test **without** updates (from `build` directory)\n```bash\n./test_updates\n```\n\nTo run test **with** updates (from `build` directory)\n```bash\n./test_updates update\n```\n\n### HNSW example demos\n\n- Visual search engine for 1M amazon products (MXNet + HNSW): [website](https://thomasdelteil.github.io/VisualSearch_MXNet/), [code](https://github.com/ThomasDelteil/VisualSearch_MXNet), demo by [@ThomasDelteil](https://github.com/ThomasDelteil)\n\n### References\nHNSW paper:\n```\n@article{malkov2018efficient,\n  title={Efficient and robust approximate nearest neighbor search using hierarchical navigable small world graphs},\n  author={Malkov, Yu A and Yashunin, Dmitry A},\n  journal={IEEE transactions on pattern analysis and machine intelligence},\n  volume={42},\n  number={4},\n  pages={824--836},\n  year={2018},\n  publisher={IEEE}\n}\n```\n\nThe update algorithm supported in this repository is to be published in \"Dynamic Updates For HNSW, Hierarchical Navigable Small World Graphs\" US Patent 15/929,802 by Apoorv Sharma, Abhishek Tayal and Yury Malkov.\n"
        },
        {
          "name": "TESTING_RECALL.md",
          "type": "blob",
          "size": 3.474609375,
          "content": "# Testing recall\n\nSelecting HNSW parameters for a specific use case highly impacts the search quality. One way to test the quality of the constructed index is to compare the HNSW search results to the actual results (i.e., the actual `k` nearest neighbors).\nFor that cause, the API enables creating a simple \"brute-force\" index in which vectors are stored as is, and searching for the `k` nearest neighbors to a query vector requires going over the entire index.  \nComparing between HNSW and brute-force results may help with finding the desired HNSW parameters for achieving a satisfying recall, based on the index size and data dimension.\n\n### Brute force index API\n`hnswlib.BFIndex(space, dim)` creates a non-initialized index in space `space` with integer dimension `dim`.\n\n`hnswlib.BFIndex` methods:\n\n`init_index(max_elements)` initializes the index with no elements.\n\nmax_elements defines the maximum number of elements that can be stored in the structure.\n\n`add_items(data, ids)` inserts the data (numpy array of vectors, shape:`N*dim`) into the structure.\n`ids` are optional N-size numpy array of integer labels for all elements in data.\n\n`delete_vector(label)` delete the element associated with the given `label` so it will be omitted from search results.\n\n`knn_query(data, k = 1)` make a batch query for `k `closest elements for each element of the\n`data` (shape:`N*dim`). Returns a numpy array of (shape:`N*k`).\n\n`load_index(path_to_index, max_elements = 0)` loads the index from persistence to the uninitialized index.\n\n`save_index(path_to_index)` saves the index from persistence.\n\n### measuring recall example\n\n```python\nimport hnswlib\nimport numpy as np\n\ndim = 32\nnum_elements = 100000\nk = 10\nnun_queries = 10\n\n# Generating sample data\ndata = np.float32(np.random.random((num_elements, dim)))\n\n# Declaring index\nhnsw_index = hnswlib.Index(space='l2', dim=dim)  # possible options are l2, cosine or ip\nbf_index = hnswlib.BFIndex(space='l2', dim=dim)\n\n# Initing both hnsw and brute force indices\n# max_elements - the maximum number of elements (capacity). Will throw an exception if exceeded\n# during insertion of an element.\n# The capacity can be increased by saving/loading the index, see below.\n#\n# hnsw construction params:\n# ef_construction - controls index search speed/build speed tradeoff\n#\n# M - is tightly connected with internal dimensionality of the data. Strongly affects the memory consumption (~M)\n# Higher M leads to higher accuracy/run_time at fixed ef/efConstruction\n\nhnsw_index.init_index(max_elements=num_elements, ef_construction=200, M=16)\nbf_index.init_index(max_elements=num_elements)\n\n# Controlling the recall for hnsw by setting ef:\n# higher ef leads to better accuracy, but slower search\nhnsw_index.set_ef(200)\n\n# Set number of threads used during batch search/construction in hnsw\n# By default using all available cores\nhnsw_index.set_num_threads(1)\n\nprint(\"Adding batch of %d elements\" % (len(data)))\nhnsw_index.add_items(data)\nbf_index.add_items(data)\n\nprint(\"Indices built\")\n\n# Generating query data\nquery_data = np.float32(np.random.random((nun_queries, dim)))\n\n# Query the elements and measure recall:\nlabels_hnsw, distances_hnsw = hnsw_index.knn_query(query_data, k)\nlabels_bf, distances_bf = bf_index.knn_query(query_data, k)\n\n# Measure recall\ncorrect = 0\nfor i in range(nun_queries):\n    for label in labels_hnsw[i]:\n        for correct_label in labels_bf[i]:\n            if label == correct_label:\n                correct += 1\n                break\n\nprint(\"recall is :\", float(correct)/(k*nun_queries))\n```\n"
        },
        {
          "name": "examples",
          "type": "tree",
          "content": null
        },
        {
          "name": "hnswlib",
          "type": "tree",
          "content": null
        },
        {
          "name": "pyproject.toml",
          "type": "blob",
          "size": 0.14453125,
          "content": "[build-system]\nrequires = [\n    \"setuptools>=42\",\n    \"wheel\",\n    \"numpy>=1.10.0\",\n    \"pybind11>=2.0\",\n]\n\nbuild-backend = \"setuptools.build_meta\"\n"
        },
        {
          "name": "python_bindings",
          "type": "tree",
          "content": null
        },
        {
          "name": "setup.py",
          "type": "blob",
          "size": 4.48046875,
          "content": "import os\nimport sys\nimport platform\n\nimport numpy as np\nimport pybind11\nimport setuptools\nfrom setuptools import Extension, setup\nfrom setuptools.command.build_ext import build_ext\n\n__version__ = '0.8.0'\n\n\ninclude_dirs = [\n    pybind11.get_include(),\n    np.get_include(),\n]\n\n# compatibility when run in python_bindings\nbindings_dir = 'python_bindings'\nif bindings_dir in os.path.basename(os.getcwd()):\n    source_files = ['./bindings.cpp']\n    include_dirs.extend(['../hnswlib/'])\nelse:\n    source_files = ['./python_bindings/bindings.cpp']\n    include_dirs.extend(['./hnswlib/'])\n\n\nlibraries = []\nextra_objects = []\n\n\next_modules = [\n    Extension(\n        'hnswlib',\n        source_files,\n        include_dirs=include_dirs,\n        libraries=libraries,\n        language='c++',\n        extra_objects=extra_objects,\n    ),\n]\n\n\n# As of Python 3.6, CCompiler has a `has_flag` method.\n# cf http://bugs.python.org/issue26689\ndef has_flag(compiler, flagname):\n    \"\"\"Return a boolean indicating whether a flag name is supported on\n    the specified compiler.\n    \"\"\"\n    import tempfile\n    with tempfile.NamedTemporaryFile('w', suffix='.cpp') as f:\n        f.write('int main (int argc, char **argv) { return 0; }')\n        try:\n            compiler.compile([f.name], extra_postargs=[flagname])\n        except setuptools.distutils.errors.CompileError:\n            return False\n    return True\n\n\ndef cpp_flag(compiler):\n    \"\"\"Return the -std=c++[11/14] compiler flag.\n    The c++14 is prefered over c++11 (when it is available).\n    \"\"\"\n    if has_flag(compiler, '-std=c++14'):\n        return '-std=c++14'\n    elif has_flag(compiler, '-std=c++11'):\n        return '-std=c++11'\n    else:\n        raise RuntimeError('Unsupported compiler -- at least C++11 support '\n                           'is needed!')\n\n\nclass BuildExt(build_ext):\n    \"\"\"A custom build extension for adding compiler-specific options.\"\"\"\n    compiler_flag_native = '-march=native'\n    c_opts = {\n        'msvc': ['/EHsc', '/openmp', '/O2'],\n        'unix': ['-O3', compiler_flag_native],  # , '-w'\n    }\n    link_opts = {\n        'unix': [],\n        'msvc': [],\n    }\n\n    if os.environ.get(\"HNSWLIB_NO_NATIVE\"):\n        c_opts['unix'].remove(compiler_flag_native)\n\n    if sys.platform == 'darwin':\n        c_opts['unix'] += ['-stdlib=libc++', '-mmacosx-version-min=10.7']\n        link_opts['unix'] += ['-stdlib=libc++', '-mmacosx-version-min=10.7']\n    else:\n        c_opts['unix'].append(\"-fopenmp\")\n        link_opts['unix'].extend(['-fopenmp', '-pthread'])\n\n    def build_extensions(self):\n        ct = self.compiler.compiler_type\n        opts = BuildExt.c_opts.get(ct, [])\n        if ct == 'unix':\n            opts.append('-DVERSION_INFO=\"%s\"' % self.distribution.get_version())\n            opts.append(cpp_flag(self.compiler))\n            if has_flag(self.compiler, '-fvisibility=hidden'):\n                opts.append('-fvisibility=hidden')\n            if not os.environ.get(\"HNSWLIB_NO_NATIVE\"):\n                # check that native flag is available\n                print('checking avalability of flag:', BuildExt.compiler_flag_native)\n                if not has_flag(self.compiler, BuildExt.compiler_flag_native):\n                    print('removing unsupported compiler flag:', BuildExt.compiler_flag_native)\n                    opts.remove(BuildExt.compiler_flag_native)\n                    # for macos add apple-m1 flag if it's available\n                    if sys.platform == 'darwin':\n                        m1_flag = '-mcpu=apple-m1'\n                        print('checking avalability of flag:', m1_flag)\n                        if has_flag(self.compiler, m1_flag):\n                            print('adding flag:', m1_flag)\n                            opts.append(m1_flag)\n                        else:\n                            print(f'flag: {m1_flag} is not available')\n                else:\n                    print(f'flag: {BuildExt.compiler_flag_native} is available')\n        elif ct == 'msvc':\n            opts.append('/DVERSION_INFO=\\\\\"%s\\\\\"' % self.distribution.get_version())\n\n        for ext in self.extensions:\n            ext.extra_compile_args.extend(opts)\n            ext.extra_link_args.extend(BuildExt.link_opts.get(ct, []))\n\n        build_ext.build_extensions(self)\n\n\nsetup(\n    name='hnswlib',\n    version=__version__,\n    description='hnswlib',\n    author='Yury Malkov and others',\n    url='https://github.com/yurymalkov/hnsw',\n    long_description=\"\"\"hnsw\"\"\",\n    ext_modules=ext_modules,\n    install_requires=['numpy'],\n    cmdclass={'build_ext': BuildExt},\n    zip_safe=False,\n)\n"
        },
        {
          "name": "tests",
          "type": "tree",
          "content": null
        }
      ]
    }
  ]
}