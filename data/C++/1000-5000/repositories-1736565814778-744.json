{
  "metadata": {
    "timestamp": 1736565814778,
    "page": 744,
    "hasNextPage": true,
    "endCursor": "Y3Vyc29yOjc1MA==",
    "completionStatus": "IN_PROGRESS"
  },
  "repositories": [
    {
      "nameWithOwner": "chdb-io/chdb",
      "stars": 2224,
      "defaultBranch": "main",
      "files": [
        {
          "name": ".clang-format",
          "type": "blob",
          "size": 2.69140625,
          "content": "BasedOnStyle: WebKit\nLanguage: Cpp\nAlignAfterOpenBracket: AlwaysBreak\nBreakBeforeBraces: Custom\nBraceWrapping:\n    AfterClass: true\n    AfterControlStatement: true\n    AfterEnum: true\n    AfterFunction: true\n    AfterNamespace: true\n    AfterStruct: true\n    AfterUnion: true\n    BeforeCatch: true\n    BeforeElse: true\n    BeforeLambdaBody: true\n    IndentBraces: false\nBreakConstructorInitializersBeforeComma: false\nCpp11BracedListStyle: true\nColumnLimit: 140\nConstructorInitializerAllOnOneLineOrOnePerLine: true\nExperimentalAutoDetectBinPacking: true\nUseTab: Never\nTabWidth: 4\nStandard: Cpp11\nPointerAlignment: Middle\nMaxEmptyLinesToKeep: 2\nKeepEmptyLinesAtTheStartOfBlocks: false\nAllowShortFunctionsOnASingleLine: InlineOnly\nAlwaysBreakTemplateDeclarations: true\nIndentCaseLabels: true\nSpaceAfterTemplateKeyword: true\nSpaceBeforeCpp11BracedList: false\nSortIncludes: true\nIndentPPDirectives: AfterHash\nIncludeCategories:\n  - Regex: '^<[a-z_]+>'\n    Priority: 1\n  - Regex: '^<[a-z_]+.h>'\n    Priority: 2\n  - Regex: '^[\"<](common|ext|mysqlxx|daemon|zkutil)/'\n    Priority: 90\n  - Regex: '^[\"<](DB)/'\n    Priority: 100\n  - Regex: '^[\"<](Poco)/'\n    Priority: 50\n  - Regex: '^\"'\n    Priority: 110\n  - Regex: '/'\n    Priority: 30\n  - Regex: '.*'\n    Priority: 40\nReflowComments: false\nAlignEscapedNewlinesLeft: false\nAlignEscapedNewlines: DontAlign\nAlignTrailingComments: false\n\n# Not changed:\nAccessModifierOffset: -4\nAlignConsecutiveAssignments: false\nAlignOperands: false\nAllowAllParametersOfDeclarationOnNextLine: true\nAllowShortBlocksOnASingleLine: false\nAllowShortCaseLabelsOnASingleLine: false\nAllowShortIfStatementsOnASingleLine: false\nAllowShortLoopsOnASingleLine: false\nAlwaysBreakAfterDefinitionReturnType: None\nAlwaysBreakBeforeMultilineStrings: false\nBinPackArguments: false\nBinPackParameters: false\nBreakBeforeBinaryOperators: All\nBreakBeforeTernaryOperators: true\nCommentPragmas: '^ IWYU pragma:'\nConstructorInitializerIndentWidth: 4\nContinuationIndentWidth: 4\nDerivePointerAlignment: false\nDisableFormat: false\nIndentRequiresClause: false\nIndentWidth: 4\nIndentWrappedFunctionNames: false\nMacroBlockBegin: ''\nMacroBlockEnd: ''\nNamespaceIndentation: None\nObjCBlockIndentWidth: 4\nObjCSpaceAfterProperty: true\nObjCSpaceBeforeProtocolList: true\nPenaltyBreakBeforeFirstCallParameter: 19\nPenaltyBreakComment: 300\nPenaltyBreakFirstLessLess: 120\nPenaltyBreakString: 1000\nPenaltyExcessCharacter: 1000000\nPenaltyReturnTypeOnItsOwnLine: 60\nRemoveBracesLLVM: false\nSpaceAfterCStyleCast: false\nSpaceBeforeAssignmentOperators: true\nSpaceBeforeParens: ControlStatements\nSpaceInEmptyParentheses: false\nSpacesBeforeTrailingComments: 1\nSpacesInContainerLiterals: true\nSpacesInCStyleCastParentheses: false\nSpacesInParentheses: false\nSpacesInSquareBrackets: false\n"
        },
        {
          "name": ".clang-tidy",
          "type": "blob",
          "size": 7.078125,
          "content": "# To run clang-tidy from CMake, build ClickHouse with -DENABLE_CLANG_TIDY=1. To show all warnings, it is\n# recommended to pass \"-k0\" to Ninja.\n\n# Enable all checks + disable selected checks. Feel free to remove disabled checks from below list if\n# a) the new check is not controversial (this includes many checks in readability-* and google-*) or\n# b) too noisy (checks with > 100 new warnings are considered noisy, this includes e.g. cppcoreguidelines-*).\n\nHeaderFilterRegex: '^.*/(base|src|programs|utils)/.*(h|hpp)$'\n\nChecks: [\n  '*',\n\n  '-abseil-*',\n\n  '-altera-*',\n\n  '-android-*',\n\n  '-bugprone-assignment-in-if-condition',\n  '-bugprone-branch-clone',\n  '-bugprone-easily-swappable-parameters',\n  '-bugprone-exception-escape',\n  '-bugprone-forward-declaration-namespace',\n  '-bugprone-implicit-widening-of-multiplication-result',\n  '-bugprone-multi-level-implicit-pointer-conversion',\n  '-bugprone-narrowing-conversions',\n  '-bugprone-not-null-terminated-result',\n  '-bugprone-reserved-identifier', # useful but too slow, TODO retry when https://reviews.llvm.org/rG1c282052624f9d0bd273bde0b47b30c96699c6c7 is merged\n  '-bugprone-unchecked-optional-access',\n  '-bugprone-crtp-constructor-accessibility',\n  '-bugprone-suspicious-stringview-data-usage',\n\n  '-cert-dcl16-c',\n  '-cert-dcl37-c',\n  '-cert-dcl51-cpp',\n  '-cert-err58-cpp',\n  '-cert-msc32-c',\n  '-cert-msc51-cpp',\n  '-cert-oop54-cpp',\n  '-cert-oop57-cpp',\n  '-cert-err33-c', # Misreports on clang-19: it warns about all functions containing 'remove' in the name, not only about the standard library.\n\n  '-clang-analyzer-optin.performance.Padding',\n\n  '-clang-analyzer-unix.Malloc',\n\n  '-cppcoreguidelines-*', # impractical in a codebase as large as ClickHouse, also slow\n\n  '-darwin-*',\n\n  '-fuchsia-*',\n\n  '-google-build-using-namespace',\n  '-google-readability-braces-around-statements',\n  '-google-readability-casting',\n  '-google-readability-function-size',\n  '-google-readability-namespace-comments',\n  '-google-readability-todo',\n\n  '-hicpp-avoid-c-arrays',\n  '-hicpp-avoid-goto',\n  '-hicpp-braces-around-statements',\n  '-hicpp-explicit-conversions',\n  '-hicpp-function-size',\n  '-hicpp-member-init',\n  '-hicpp-move-const-arg',\n  '-hicpp-multiway-paths-covered',\n  '-hicpp-named-parameter',\n  '-hicpp-no-array-decay',\n  '-hicpp-no-assembler',\n  '-hicpp-no-malloc',\n  '-hicpp-signed-bitwise',\n  '-hicpp-special-member-functions',\n  '-hicpp-uppercase-literal-suffix',\n  '-hicpp-use-auto',\n  '-hicpp-use-emplace',\n  '-hicpp-vararg',\n\n  '-linuxkernel-*',\n\n  '-llvm-*',\n\n  '-llvmlibc-*',\n\n  '-openmp-*',\n\n  '-misc-const-correctness',\n  '-misc-include-cleaner', # useful but far too many occurrences\n  '-misc-no-recursion',\n  '-misc-non-private-member-variables-in-classes',\n  '-misc-confusable-identifiers', # useful but slooo\n  '-misc-use-anonymous-namespace',\n\n  '-modernize-avoid-c-arrays',\n  '-modernize-concat-nested-namespaces',\n  '-modernize-macro-to-enum',\n  '-modernize-pass-by-value',\n  '-modernize-return-braced-init-list',\n  '-modernize-use-auto',\n  '-modernize-use-constraints', # This is a good check, but clang-tidy crashes, see https://github.com/llvm/llvm-project/issues/91872\n  '-modernize-use-default-member-init',\n  '-modernize-use-emplace',\n  '-modernize-use-nodiscard',\n  '-modernize-use-trailing-return-type',\n  '-modernize-use-designated-initializers',\n\n  '-performance-enum-size',\n  '-performance-inefficient-string-concatenation',\n  '-performance-no-int-to-ptr',\n  '-performance-avoid-endl',\n  '-performance-unnecessary-value-param',\n\n  '-portability-simd-intrinsics',\n\n  '-readability-avoid-nested-conditional-operator',\n  '-readability-avoid-unconditional-preprocessor-if',\n  '-readability-braces-around-statements',\n  '-readability-convert-member-functions-to-static',\n  '-readability-else-after-return',\n  '-readability-function-cognitive-complexity',\n  '-readability-function-size',\n  '-readability-identifier-length',\n  '-readability-identifier-naming', # useful but too slow\n  '-readability-implicit-bool-conversion',\n  '-readability-isolate-declaration',\n  '-readability-magic-numbers',\n  '-readability-named-parameter',\n  '-readability-redundant-declaration',\n  '-readability-redundant-inline-specifier', # useful but incompatible with __attribute((always_inline))__ (aka. ALWAYS_INLINE, base/base/defines.h).\n        # ALWAYS_INLINE only has an effect if combined with `inline`: https://godbolt.org/z/Eefd74qdM\n  '-readability-redundant-member-init', # Useful but triggers another problem. Imagine a struct S with multiple String members. Structs are often instantiated via designated\n        # initializer S s{.s1 = [...], .s2 = [...], [...]}. In this case, compiler warning `missing-field-initializers` requires to specify all members which are not in-struct\n        # initialized (example: s1 in struct S { String s1; String s2{};}; is not in-struct initialized, therefore it must be specified at instantiation time). As explicitly\n        # specifying all members is tedious for large structs, `missing-field-initializers` makes programmers initialize as many members as possible in-struct. Clang-tidy\n        # warning `readability-redundant-member-init` does the opposite thing, both are not compatible with each other.\n  '-readability-simplify-boolean-expr',\n  '-readability-suspicious-call-argument',\n  '-readability-uppercase-literal-suffix',\n  '-readability-use-anyofallof',\n\n  '-zircon-*'\n]\n\nWarningsAsErrors: '*'\n\nExtraArgs:\n# clang-tidy 17 started to complain (for unknown reasons) that various pragmas are unknown (\"clang-diagnostic-unknown-pragmas\").\n# This is technically a compiler error, not a clang-tidy error. We could litter the code base with more pragmas that suppress\n# this error but it is better to pass the following flag to the compiler:\n- '-Wno-unknown-pragmas'\n- '-Wno-unused-command-line-argument' # similar issue\n\nCheckOptions:\n  readability-identifier-naming.ClassCase: CamelCase\n  readability-identifier-naming.EnumCase: CamelCase\n  readability-identifier-naming.LocalVariableCase: lower_case\n  readability-identifier-naming.StaticConstantCase: aNy_CasE\n  readability-identifier-naming.MemberCase: lower_case\n  readability-identifier-naming.PrivateMemberPrefix: ''\n  readability-identifier-naming.ProtectedMemberPrefix: ''\n  readability-identifier-naming.PublicMemberCase: lower_case\n  readability-identifier-naming.MethodCase: camelBack\n  readability-identifier-naming.PrivateMethodPrefix: ''\n  readability-identifier-naming.ProtectedMethodPrefix: ''\n  readability-identifier-naming.ParameterPackCase: lower_case\n  readability-identifier-naming.StructCase: CamelCase\n  readability-identifier-naming.TemplateTemplateParameterCase: CamelCase\n  readability-identifier-naming.TemplateParameterCase: lower_case\n  readability-identifier-naming.TypeTemplateParameterCase: CamelCase\n  readability-identifier-naming.TypedefCase: CamelCase\n  readability-identifier-naming.UnionCase: CamelCase\n  modernize-loop-convert.UseCxx20ReverseRanges: false\n  performance-move-const-arg.CheckTriviallyCopyableMove: false\n  # Workaround clang-tidy bug: https://github.com/llvm/llvm-project/issues/46097\n  readability-identifier-naming.TypeTemplateParameterIgnoredRegexp: expr-type\n  cppcoreguidelines-avoid-do-while.IgnoreMacros: true"
        },
        {
          "name": ".clangd",
          "type": "blob",
          "size": 0.6611328125,
          "content": "Diagnostics:\n    # clangd does parse .clang-tidy, but some checks are too slow to run in\n    # clang-tidy build, so let's enable them explicitly for clangd at least.\n    ClangTidy:\n        # The following checks had been disabled due to slowliness with C++23,\n        # for more details see [1].\n        #\n        #   [1]: https://github.com/llvm/llvm-project/issues/61418\n        #\n        # But the code base had been written in a style that had been checked\n        # by this check, so at least, let's enable it for clangd.\n        Add: [\n            # configured in .clang-tidy\n            readability-identifier-naming,\n            bugprone-reserved-identifier,\n        ]\n"
        },
        {
          "name": ".coveragerc",
          "type": "blob",
          "size": 0.5732421875,
          "content": "# .coveragerc to control coverage.py\n[run]\nbranch = True\nsource = chdb\n# omit = bad_file.py\n\n[paths]\nsource =\n    src/\n    */site-packages/\n\n[report]\n# Regexes for lines to exclude from consideration\nexclude_lines =\n    # Have to re-enable the standard pragma\n    pragma: no cover\n\n    # Don't complain about missing debug-only code:\n    def __repr__\n    if self\\.debug\n\n    # Don't complain if tests don't hit defensive assertion code:\n    raise AssertionError\n    raise NotImplementedError\n\n    # Don't complain if non-runnable code isn't run:\n    if 0:\n    if __name__ == .__main__.:\n"
        },
        {
          "name": ".cursorignore",
          "type": "blob",
          "size": 0.0087890625,
          "content": "contrib/\n"
        },
        {
          "name": ".editorconfig",
          "type": "blob",
          "size": 0.4091796875,
          "content": "root = true\n\n# Unix-style newlines with a newline ending every file\n[*]\nend_of_line = lf\ninsert_final_newline = true\n\n\n# Matches multiple files with brace expansion notation\n# Set default charset\n[*.{c,cpp,cxx,h,hpp,hxx,py,cmake}]\ncharset = utf-8\nindent_style = space\nindent_size = 4\ntrim_trailing_whitespace = true\n\n[CMakeLists.txt]\ncharset = utf-8\nindent_style = space\nindent_size = 4\ntrim_trailing_whitespace = true\n"
        },
        {
          "name": ".exrc",
          "type": "blob",
          "size": 0.099609375,
          "content": "au BufRead,BufNewFile * set tabstop=4 softtabstop=0 expandtab shiftwidth=4 smarttab tags=tags,../tags\n"
        },
        {
          "name": ".git-blame-ignore-revs",
          "type": "blob",
          "size": 0.46875,
          "content": "# This is a file that can be used by git-blame to ignore some revisions.\n# (git 2.23+, released in August 2019)\n#\n# Can be configured as follow:\n#\n#     $ git config blame.ignoreRevsFile .git-blame-ignore-revs\n#\n# For more information you can look at git-blame(1) man page.\n\n# Changed tabs to spaces in code [#CLICKHOUSE-3]\n137ad95929ee016cc6d3c03bccb5586941c163ff\n\n# dbms/ → src/\n# (though it is unlikely that you will see it in blame)\n06446b4f08a142d6f1bc30664c47ded88ab51782\n"
        },
        {
          "name": ".gitattributes",
          "type": "blob",
          "size": 0.1396484375,
          "content": "contrib/* linguist-vendored\n*.h linguist-language=C++\ntests/queries/0_stateless/data_json/* binary\ntests/queries/0_stateless/*.reference -crlf\n"
        },
        {
          "name": ".github",
          "type": "tree",
          "content": null
        },
        {
          "name": ".gitignore",
          "type": "blob",
          "size": 2.91796875,
          "content": "# emacs files\n*~\n*\\#\n.tramp_history\n*.parquet\n*.arrow\n\n# vim cache files\n*.swp\n\n# auto generated files\n*.logrt\n\n/python_pkg/\nminitest/\n/tmps\n/bak\n*state_tmp_*\n/chdb-0.*/\n*.strings\n/arrow1100\ntest_main\n/build*\n/bench\n/tests/venv\n/tests/data\n/obj-x86_64-linux-gnu/\n\n/examples/chdbStub\n/examples/chdbSimple\n/examples/chdbDlopen\nlibchdb.so\n\n# logs\n*.log\n*.debuglog\n*.stderr\n*.stdout\n\n/docs/build\n/docs/publish\n/docs/edit\n/docs/website\n/docs/venv\n/docs/tools/venv\n/docs/tools/translate/venv\n/docs/tools/translate/output.md\n/docs/en/single.md\n/docs/ru/single.md\n/docs/zh/single.md\n/docs/ja/single.md\n/docs/fa/single.md\n\n# callgrind files\ncallgrind.out.*\n\n# ignore kdevelop files\n*.kdev4\n*.kdev_include_paths\n\n# ignore sublime project files\n*.sublime-*\n\n# Qt Creator files\n*.user\n\n# ignore perf output\n*/perf.data\n\n# ignore build files\nCMakeCache.txt\nCMakeFiles\nMakefile\ncmake_install.cmake\nCTestTestfile.cmake\n*.a\n*.o\n*.so\n*.dll\n*.lib\n*.dylib\ncmake-build-*\n\n# Python cache\n*.pyc\n__pycache__\n*.pytest_cache\n.mypy_cache\n\ntest.cpp\nCPackConfig.cmake\nCPackSourceConfig.cmake\n\n*-preprocessed.xml\n\ncore\n!core/\nvgcore*\n\n*.deb\n*.tar.zst\n*.gz\n*.bz2\n*.tgz\n*.build\n*.upload\n*.changes\nbuild-stamp\nconfigure-stamp\n\n*.bin\n*.mrk\n*.mrk2\n*.mrk3\n\n.dupload.conf\n\n# Netbeans project files\nnbproject/*\n\n# JetBrains project files\n.idea\n\n# Microsoft Visual Studio Code\n.vscode\n\nconfig-preprocessed.xml\n\n# Protobuf\n*.pb.cpp\n*.pb.h\n\n# Ignore symlink to private repository\n/private\n\n# Gulp dependencies used to minify website\nnode_modules\npublic\nwebsite/docs\nwebsite/presentations\nwebsite/package-lock.json\n.DS_Store\n*/.DS_Store\n\n# cquery cache\n/.cquery-cache\n\n# ccls cache\n/.ccls-cache\n\n# clangd cache\n/.cache\n\n/compile_commands.json\n\n# Toolchains\n/cmake/toolchain/*\n\n# ANTLR extension cache\n.antlr\n\n# ANTLR generated files\n/src/Parsers/New/*.interp\n/src/Parsers/New/*.tokens\n/src/Parsers/New/ClickHouseParserBaseVisitor.*\n\n# pytest-profiling\n/prof\n\n*.iml\n\n# data store\n/programs/server/data\n/programs/server/metadata\n/programs/server/store\n/programs/server/uuid\n/programs/server/coordination\n\n# temporary test files\ntests/queries/0_stateless/test_*\ntests/queries/0_stateless/*.binary\ntests/queries/0_stateless/*.generated-expect\ntests/queries/0_stateless/*.expect.history\ntests/integration/**/_gen\n\n# pytest --pdb history\n.pdb_history\n\n/examples/ml-25m\n# rust\n/rust/**/target*\n# It is autogenerated from *.in\n/rust/**/.cargo/config.toml\n/rust/**/vendor\n# Temporary and binary files\n*~\n*.py[cod]\n*.so\n*.cfg\n!.isort.cfg\n!setup.cfg\n*.orig\n*.log\n*.pot\n__pycache__/*\n.cache/*\n.*.swp\n*/.ipynb_checkpoints/*\n.DS_Store\n\n# Project files\n.ropeproject\n.project\n.pydevproject\n.settings\n.idea\n.vscode\ntags\n\n# Package files\n*.egg\n*.eggs/\n.installed.cfg\n*.egg-info\n\n# Unittest and coverage\nhtmlcov/*\n.coverage\n.coverage.*\n.tox\njunit*.xml\ncoverage.xml\n.pytest_cache/\n\n# Build and docs folder/files\nbuild/*\ndist/*\nsdist/*\ndocs/api/*\ndocs/_rst/*\ndocs/_build/*\ncover/*\nMANIFEST\n\n# Per-project virtualenvs\n.venv*/\n.conda*/\n.python-version\n"
        },
        {
          "name": ".gitmodules",
          "type": "blob",
          "size": 12.857421875,
          "content": "# Please do not use 'branch = ...' tags with submodule entries. Such tags make updating submodules a\n# little bit more convenient but they do *not* specify the tracked submodule branch. Thus, they are\n# more confusing than useful.\n[submodule \"contrib/zstd\"]\n\tpath = contrib/zstd\n\turl = https://github.com/facebook/zstd\n[submodule \"contrib/lz4\"]\n\tpath = contrib/lz4\n\turl = https://github.com/lz4/lz4\n[submodule \"contrib/librdkafka\"]\n\tpath = contrib/librdkafka\n\turl = https://github.com/ClickHouse/librdkafka\n[submodule \"contrib/cctz\"]\n\tpath = contrib/cctz\n\turl = https://github.com/ClickHouse/cctz\n[submodule \"contrib/zlib-ng\"]\n\tpath = contrib/zlib-ng\n\turl = https://github.com/ClickHouse/zlib-ng\n[submodule \"contrib/googletest\"]\n\tpath = contrib/googletest\n\turl = https://github.com/google/googletest\n[submodule \"contrib/capnproto\"]\n\tpath = contrib/capnproto\n\turl = https://github.com/ClickHouse/capnproto\n[submodule \"contrib/re2\"]\n\tpath = contrib/re2\n\turl = https://github.com/google/re2\n[submodule \"contrib/mariadb-connector-c\"]\n\tpath = contrib/mariadb-connector-c\n\turl = https://github.com/ClickHouse/mariadb-connector-c\n[submodule \"contrib/jemalloc\"]\n\tpath = contrib/jemalloc\n\turl = https://github.com/jemalloc/jemalloc\n[submodule \"contrib/unixodbc\"]\n\tpath = contrib/unixodbc\n\turl = https://github.com/ClickHouse/UnixODBC\n[submodule \"contrib/google-protobuf\"]\n\tpath = contrib/google-protobuf\n\turl = https://github.com/ClickHouse/google-protobuf.git\n[submodule \"contrib/boost\"]\n\tpath = contrib/boost\n\turl = https://github.com/ClickHouse/boost\n[submodule \"contrib/thrift\"]\n\tpath = contrib/thrift\n\turl = https://github.com/apache/thrift\n[submodule \"contrib/libhdfs3\"]\n\tpath = contrib/libhdfs3\n\turl = https://github.com/ClickHouse/libhdfs3\n[submodule \"contrib/libxml2\"]\n\tpath = contrib/libxml2\n\turl = https://github.com/GNOME/libxml2\n[submodule \"contrib/libgsasl\"]\n\tpath = contrib/libgsasl\n\turl = https://github.com/ClickHouse/libgsasl\n[submodule \"contrib/snappy\"]\n\tpath = contrib/snappy\n\turl = https://github.com/ClickHouse/snappy\n[submodule \"contrib/cppkafka\"]\n\tpath = contrib/cppkafka\n\turl = https://github.com/mfontanini/cppkafka\n[submodule \"contrib/brotli\"]\n\tpath = contrib/brotli\n\turl = https://github.com/google/brotli\n[submodule \"contrib/h3\"]\n\tpath = contrib/h3\n\turl = https://github.com/ClickHouse/h3\n[submodule \"contrib/libunwind\"]\n\tpath = contrib/libunwind\n\turl = https://github.com/ClickHouse/libunwind\n[submodule \"contrib/simdjson\"]\n\tpath = contrib/simdjson\n\turl = https://github.com/simdjson/simdjson\n[submodule \"contrib/rapidjson\"]\n\tpath = contrib/rapidjson\n\turl = https://github.com/ClickHouse/rapidjson\n[submodule \"contrib/fastops\"]\n\tpath = contrib/fastops\n\turl = https://github.com/ClickHouse/fastops\n[submodule \"contrib/orc\"]\n\tpath = contrib/orc\n\turl = https://github.com/ClickHouse/orc\n[submodule \"contrib/sparsehash-c11\"]\n\tpath = contrib/sparsehash-c11\n\turl = https://github.com/sparsehash/sparsehash-c11\n[submodule \"contrib/grpc\"]\n\tpath = contrib/grpc\n\turl = https://github.com/ClickHouse/grpc\n[submodule \"contrib/aws\"]\n\tpath = contrib/aws\n\turl = https://github.com/ClickHouse/aws-sdk-cpp\n[submodule \"aws-c-event-stream\"]\n\tpath = contrib/aws-c-event-stream\n\turl = https://github.com/awslabs/aws-c-event-stream\n[submodule \"aws-c-common\"]\n\tpath = contrib/aws-c-common\n\turl = https://github.com/awslabs/aws-c-common.git\n[submodule \"aws-checksums\"]\n\tpath = contrib/aws-checksums\n\turl = https://github.com/awslabs/aws-checksums\n[submodule \"contrib/curl\"]\n\tpath = contrib/curl\n\turl = https://github.com/curl/curl\n[submodule \"contrib/icudata\"]\n\tpath = contrib/icudata\n\turl = https://github.com/ClickHouse/icudata\n[submodule \"contrib/icu\"]\n\tpath = contrib/icu\n\turl = https://github.com/unicode-org/icu\n[submodule \"contrib/flatbuffers\"]\n\tpath = contrib/flatbuffers\n\turl = https://github.com/ClickHouse/flatbuffers\n[submodule \"contrib/replxx\"]\n\tpath = contrib/replxx\n\turl = https://github.com/ClickHouse/replxx\n[submodule \"contrib/avro\"]\n\tpath = contrib/avro\n\turl = https://github.com/ClickHouse/avro\n\tignore = untracked\n[submodule \"contrib/msgpack-c\"]\n\tpath = contrib/msgpack-c\n\turl = https://github.com/msgpack/msgpack-c\n[submodule \"contrib/libcpuid\"]\n\tpath = contrib/libcpuid\n\turl = https://github.com/ClickHouse/libcpuid\n[submodule \"contrib/openldap\"]\n\tpath = contrib/openldap\n\turl = https://github.com/ClickHouse/openldap\n[submodule \"contrib/AMQP-CPP\"]\n\tpath = contrib/AMQP-CPP\n\turl = https://github.com/ClickHouse/AMQP-CPP\n[submodule \"contrib/cassandra\"]\n\tpath = contrib/cassandra\n\turl = https://github.com/ClickHouse/cpp-driver\n[submodule \"contrib/libuv\"]\n\tpath = contrib/libuv\n\turl = https://github.com/ClickHouse/libuv\n[submodule \"contrib/fmtlib\"]\n\tpath = contrib/fmtlib\n\turl = https://github.com/fmtlib/fmt\n[submodule \"contrib/sentry-native\"]\n\tpath = contrib/sentry-native\n\turl = https://github.com/ClickHouse/sentry-native\n[submodule \"contrib/krb5\"]\n\tpath = contrib/krb5\n\turl = https://github.com/ClickHouse/krb5\n[submodule \"contrib/cyrus-sasl\"]\n\tpath = contrib/cyrus-sasl\n\turl = https://github.com/ClickHouse/cyrus-sasl\n[submodule \"contrib/croaring\"]\n\tpath = contrib/croaring\n\turl = https://github.com/RoaringBitmap/CRoaring\n[submodule \"contrib/miniselect\"]\n\tpath = contrib/miniselect\n\turl = https://github.com/danlark1/miniselect\n[submodule \"contrib/rocksdb\"]\n\tpath = contrib/rocksdb\n\turl = https://github.com/ClickHouse/rocksdb\n[submodule \"contrib/xz\"]\n\tpath = contrib/xz\n\turl = https://github.com/xz-mirror/xz\n[submodule \"contrib/abseil-cpp\"]\n\tpath = contrib/abseil-cpp\n\turl = https://github.com/abseil/abseil-cpp\n[submodule \"contrib/dragonbox\"]\n\tpath = contrib/dragonbox\n\turl = https://github.com/ClickHouse/dragonbox\n[submodule \"contrib/fast_float\"]\n\tpath = contrib/fast_float\n\turl = https://github.com/fastfloat/fast_float\n[submodule \"contrib/NuRaft\"]\n\tpath = contrib/NuRaft\n\turl = https://github.com/ClickHouse/NuRaft\n[submodule \"contrib/nanodbc\"]\n\tpath = contrib/nanodbc\n\turl = https://github.com/ClickHouse/nanodbc\n[submodule \"contrib/datasketches-cpp\"]\n\tpath = contrib/datasketches-cpp\n\turl = https://github.com/apache/datasketches-cpp\n[submodule \"contrib/yaml-cpp\"]\n\tpath = contrib/yaml-cpp\n\turl = https://github.com/ClickHouse/yaml-cpp\n[submodule \"contrib/cld2\"]\n\tpath = contrib/cld2\n\turl = https://github.com/ClickHouse/cld2\n[submodule \"contrib/libstemmer_c\"]\n\tpath = contrib/libstemmer_c\n\turl = https://github.com/ClickHouse/libstemmer_c\n[submodule \"contrib/wordnet-blast\"]\n\tpath = contrib/wordnet-blast\n\turl = https://github.com/ClickHouse/wordnet-blast\n[submodule \"contrib/lemmagen-c\"]\n\tpath = contrib/lemmagen-c\n\turl = https://github.com/ClickHouse/lemmagen-c\n[submodule \"contrib/libpqxx\"]\n\tpath = contrib/libpqxx\n\turl = https://github.com/ClickHouse/libpqxx\n[submodule \"contrib/sqlite-amalgamation\"]\n\tpath = contrib/sqlite-amalgamation\n\turl = https://github.com/ClickHouse/sqlite-amalgamation\n[submodule \"contrib/s2geometry\"]\n\tpath = contrib/s2geometry\n\turl = https://github.com/ClickHouse/s2geometry\n[submodule \"contrib/bzip2\"]\n\tpath = contrib/bzip2\n\turl = https://github.com/ClickHouse/bzip2\n[submodule \"contrib/magic_enum\"]\n\tpath = contrib/magic_enum\n\turl = https://github.com/Neargye/magic_enum\n[submodule \"contrib/libprotobuf-mutator\"]\n\tpath = contrib/libprotobuf-mutator\n\turl = https://github.com/google/libprotobuf-mutator\n[submodule \"contrib/sysroot\"]\n\tpath = contrib/sysroot\n\turl = https://github.com/ClickHouse/sysroot\n[submodule \"contrib/nlp-data\"]\n\tpath = contrib/nlp-data\n\turl = https://github.com/ClickHouse/nlp-data\n[submodule \"contrib/hive-metastore\"]\n\tpath = contrib/hive-metastore\n\turl = https://github.com/ClickHouse/hive-metastore\n[submodule \"contrib/azure\"]\n\tpath = contrib/azure\n\turl = https://github.com/ClickHouse/azure-sdk-for-cpp\n[submodule \"contrib/minizip-ng\"]\n\tpath = contrib/minizip-ng\n\turl = https://github.com/zlib-ng/minizip-ng\n[submodule \"contrib/annoy\"]\n\tpath = contrib/annoy\n\turl = https://github.com/ClickHouse/annoy\n[submodule \"contrib/qpl\"]\n\tpath = contrib/qpl\n\turl = https://github.com/intel/qpl\n[submodule \"contrib/idxd-config\"]\n\tpath = contrib/idxd-config\n\turl = https://github.com/intel/idxd-config\n[submodule \"contrib/QAT-ZSTD-Plugin\"]\n\tpath = contrib/QAT-ZSTD-Plugin\n\turl = https://github.com/intel/QAT-ZSTD-Plugin\n[submodule \"contrib/qatlib\"]\n\tpath = contrib/qatlib\n\turl = https://github.com/intel/qatlib\n[submodule \"contrib/wyhash\"]\n\tpath = contrib/wyhash\n\turl = https://github.com/wangyi-fudan/wyhash\n[submodule \"contrib/nats-io\"]\n\tpath = contrib/nats-io\n\turl = https://github.com/ClickHouse/nats.c\n[submodule \"contrib/vectorscan\"]\n\tpath = contrib/vectorscan\n\turl = https://github.com/VectorCamp/vectorscan.git\n[submodule \"contrib/llvm-project\"]\n\tpath = contrib/llvm-project\n\turl = https://github.com/ClickHouse/llvm-project\n[submodule \"contrib/corrosion\"]\n\tpath = contrib/corrosion\n\turl = https://github.com/corrosion-rs/corrosion\n[submodule \"contrib/libssh\"]\n\tpath = contrib/libssh\n\turl = https://github.com/ClickHouse/libssh.git\n[submodule \"contrib/morton-nd\"]\n\tpath = contrib/morton-nd\n\turl = https://github.com/morton-nd/morton-nd\n[submodule \"contrib/xxHash\"]\n\tpath = contrib/xxHash\n\turl = https://github.com/Cyan4973/xxHash\n[submodule \"contrib/crc32-s390x\"]\n\tpath = contrib/crc32-s390x\n\turl = https://github.com/linux-on-ibm-z/crc32-s390x\n[submodule \"contrib/google-benchmark\"]\n\tpath = contrib/google-benchmark\n\turl = https://github.com/google/benchmark\n[submodule \"contrib/libdivide\"]\n\tpath = contrib/libdivide\n\turl = https://github.com/ridiculousfish/libdivide\n[submodule \"contrib/libbcrypt\"]\n\tpath = contrib/libbcrypt\n\turl = https://github.com/rg3/libbcrypt.git\n[submodule \"contrib/ulid-c\"]\n\tpath = contrib/ulid-c\n\turl = https://github.com/ClickHouse/ulid-c.git\n[submodule \"contrib/aws-crt-cpp\"]\n\tpath = contrib/aws-crt-cpp\n\turl = https://github.com/ClickHouse/aws-crt-cpp\n[submodule \"contrib/aws-c-io\"]\n\tpath = contrib/aws-c-io\n\turl = https://github.com/ClickHouse/aws-c-io\n[submodule \"contrib/aws-c-mqtt\"]\n\tpath = contrib/aws-c-mqtt\n\turl = https://github.com/awslabs/aws-c-mqtt\n[submodule \"contrib/aws-c-auth\"]\n\tpath = contrib/aws-c-auth\n\turl = https://github.com/awslabs/aws-c-auth\n[submodule \"contrib/aws-c-cal\"]\n\tpath = contrib/aws-c-cal\n\turl = https://github.com/ClickHouse/aws-c-cal\n[submodule \"contrib/aws-c-sdkutils\"]\n\tpath = contrib/aws-c-sdkutils\n\turl = https://github.com/awslabs/aws-c-sdkutils\n[submodule \"contrib/aws-c-http\"]\n\tpath = contrib/aws-c-http\n\turl = https://github.com/awslabs/aws-c-http\n[submodule \"contrib/aws-c-s3\"]\n\tpath = contrib/aws-c-s3\n\turl = https://github.com/awslabs/aws-c-s3\n[submodule \"contrib/aws-c-compression\"]\n\tpath = contrib/aws-c-compression\n\turl = https://github.com/awslabs/aws-c-compression\n[submodule \"contrib/aws-s2n-tls\"]\n\tpath = contrib/aws-s2n-tls\n\turl = https://github.com/ClickHouse/s2n-tls\n[submodule \"contrib/crc32-vpmsum\"]\n\tpath = contrib/crc32-vpmsum\n\turl = https://github.com/antonblanchard/crc32-vpmsum.git\n[submodule \"contrib/expected\"]\n\tpath = contrib/expected\n\turl = https://github.com/TartanLlama/expected\n[submodule \"contrib/liburing\"]\n\tpath = contrib/liburing\n\turl = https://github.com/axboe/liburing\n[submodule \"contrib/libarchive\"]\n\tpath = contrib/libarchive\n\turl = https://github.com/libarchive/libarchive.git\n\tignore = dirty\n[submodule \"contrib/libfiu\"]\n\tpath = contrib/libfiu\n\turl = https://github.com/ClickHouse/libfiu.git\n[submodule \"contrib/isa-l\"]\n\tpath = contrib/isa-l\n\turl = https://github.com/ClickHouse/isa-l.git\n[submodule \"contrib/c-ares\"]\n\tpath = contrib/c-ares\n\turl = https://github.com/c-ares/c-ares.git\n[submodule \"contrib/incbin\"]\n\tpath = contrib/incbin\n\turl = https://github.com/graphitemaster/incbin.git\n[submodule \"contrib/usearch\"]\n\tpath = contrib/usearch\n\turl = https://github.com/unum-cloud/usearch.git\n[submodule \"contrib/SimSIMD\"]\n\tpath = contrib/SimSIMD\n\turl = https://github.com/ashvardanian/SimSIMD.git\n[submodule \"contrib/FP16\"]\n\tpath = contrib/FP16\n\turl = https://github.com/Maratyszcza/FP16.git\n[submodule \"contrib/robin-map\"]\n\tpath = contrib/robin-map\n\turl = https://github.com/Tessil/robin-map.git\n[submodule \"contrib/aklomp-base64\"]\n\tpath = contrib/aklomp-base64\n\turl = https://github.com/aklomp/base64.git\n[submodule \"contrib/pocketfft\"]\n\tpath = contrib/pocketfft\n\turl = https://github.com/mreineck/pocketfft.git\n[submodule \"contrib/sqids-cpp\"]\n\tpath = contrib/sqids-cpp\n\turl = https://github.com/sqids/sqids-cpp.git\n[submodule \"contrib/idna\"]\n\tpath = contrib/idna\n\turl = https://github.com/ada-url/idna.git\n[submodule \"contrib/rust_vendor\"]\n\tpath = contrib/rust_vendor\n\turl = https://github.com/ClickHouse/rust_vendor.git\n[submodule \"contrib/openssl\"]\n\tpath = contrib/openssl\n\turl = https://github.com/ClickHouse/openssl.git\n[submodule \"contrib/double-conversion\"]\n\tpath = contrib/double-conversion\n\turl = https://github.com/ClickHouse/double-conversion.git\n[submodule \"contrib/arrow\"]\n\tpath = contrib/arrow\n\turl = https://github.com/auxten/arrow\n[submodule \"contrib/utf8proc\"]\n\tpath = contrib/utf8proc\n\turl = https://github.com/JuliaStrings/utf8proc.git\n[submodule \"contrib/numactl\"]\n\tpath = contrib/numactl\n\turl = https://github.com/ClickHouse/numactl.git\n[submodule \"contrib/postgres\"]\n\tpath = contrib/postgres\n\turl = https://github.com/ClickHouse/postgres.git\n"
        },
        {
          "name": ".readthedocs.yml",
          "type": "blob",
          "size": 0.517578125,
          "content": "# Read the Docs configuration file\n# See https://docs.readthedocs.io/en/stable/config-file/v2.html for details\n\n# Required\nversion: 2\n\n# Build documentation in the docs/ directory with Sphinx\nsphinx:\n  configuration: docs/conf.py\n\n# Build documentation with MkDocs\n#mkdocs:\n#  configuration: mkdocs.yml\n\n# Optionally build your docs in additional formats such as PDF\nformats:\n  - pdf\n\nbuild:\n  os: ubuntu-22.04\n  tools:\n    python: \"3.11\"\n\npython:\n  install:\n    - requirements: docs/requirements.txt\n    - {path: ., method: pip}\n"
        },
        {
          "name": ".snyk",
          "type": "blob",
          "size": 0.0693359375,
          "content": "# Snyk (https://snyk.io) policy file\nexclude:\n  global:\n    - tests/**\n"
        },
        {
          "name": ".yamllint",
          "type": "blob",
          "size": 0.3427734375,
          "content": "# vi: ft=yaml\nextends: default\n\nrules:\n    indentation:\n        level: warning\n        indent-sequences: consistent\n    line-length:\n        # there are:\n        # - bash -c \"\", so this is OK\n        # - yaml in tests\n        max: 1000\n        level: warning\n    comments:\n        min-spaces-from-content: 1\n    document-start:\n        present: false\n"
        },
        {
          "name": "AUTHORS.md",
          "type": "blob",
          "size": 0.2763671875,
          "content": "# Contributors\n\n* auxten [auxten@clickhouse.com](mailto:auxten@clickhouse.com)\n\nTo see the list of authors who created the source code of ClickHouse, published and distributed by ClickHouse, Inc. as the owner,\nrun \"SELECT * FROM system.contributors;\" query on any ClickHouse server.\n"
        },
        {
          "name": "CHANGELOG.md",
          "type": "blob",
          "size": 0,
          "content": ""
        },
        {
          "name": "CITATION.cff",
          "type": "blob",
          "size": 0.822265625,
          "content": "# This CITATION.cff file was generated with cffinit.\n\ncff-version: 1.2.0\ntitle: \"ClickHouse\"\nmessage: \"If you use this software, please cite it as below.\"\ntype: software\nauthors:\n  - family-names: \"Milovidov\"\n    given-names: \"Alexey\"\nrepository-code: 'https://github.com/ClickHouse/ClickHouse'\nurl: 'https://clickhouse.com'\nlicense: Apache-2.0\npreferred-citation:\n  type: article\n  authors:\n  - family-names: \"Schulze\"\n    given-names: \"Robert\"\n  - family-names: \"Schreiber\"\n    given-names: \"Tom\"\n  - family-names: \"Yatsishin\"\n    given-names: \"Ilya\"\n  - family-names: \"Dahimene\"\n    given-names: \"Ryadh\"\n  - family-names: \"Milovidov\"\n    given-names: \"Alexey\"\n  journal: \"Proceedings of the VLDB Endowment\"\n  title: \"ClickHouse - Lightning Fast Analytics for Everyone\"\n  year: 2024\n  volume: 17\n  issue: 12\n  doi: 10.14778/3685800.3685802\n"
        },
        {
          "name": "CMakeLists.txt",
          "type": "blob",
          "size": 27.5244140625,
          "content": "cmake_minimum_required(VERSION 3.20)\n\nproject(ClickHouse LANGUAGES C CXX ASM)\n\n# If turned off (e.g. when ENABLE_FOO is ON, but FOO tool was not found) the CMake will continue.\noption(FAIL_ON_UNSUPPORTED_OPTIONS_COMBINATION\n   \"Stop/Fail CMake configuration if some ENABLE_XXX option is defined (either ON or OFF)\n   but is not possible to satisfy\" ON)\n\nif(FAIL_ON_UNSUPPORTED_OPTIONS_COMBINATION)\n    set(RECONFIGURE_MESSAGE_LEVEL FATAL_ERROR)\nelse()\n    set(RECONFIGURE_MESSAGE_LEVEL WARNING)\nendif()\n\ninclude (cmake/arch.cmake)\ninclude (cmake/target.cmake)\ninclude (cmake/tools.cmake)\ninclude (cmake/ccache.cmake)\ninclude (cmake/clang_tidy.cmake)\ninclude (cmake/git.cmake)\ninclude (cmake/utils.cmake)\n\n# This is needed to set up the CMAKE_INSTALL_BINDIR variable.\ninclude (GNUInstallDirs)\n\n# Ignore export() since we don't use it,\n# but it gets broken with global targets via link_libraries()\nmacro (export)\nendmacro ()\n\nset(CMAKE_EXPORT_COMPILE_COMMANDS 1) # Write compile_commands.json\nset(CMAKE_LINK_DEPENDS_NO_SHARED 1) # Do not relink all depended targets on .so\nset(CMAKE_CONFIGURATION_TYPES \"RelWithDebInfo;Debug;Release;MinSizeRel\" CACHE STRING \"\" FORCE)\nset(CMAKE_DEBUG_POSTFIX \"d\" CACHE STRING \"Generate debug library name with a postfix.\")    # To be consistent with CMakeLists from contrib libs.\n\n# Enable the ability to organize targets into hierarchies of \"folders\" for capable GUI-based IDEs.\n# For more info see https://cmake.org/cmake/help/latest/prop_gbl/USE_FOLDERS.html\nset_property(GLOBAL PROPERTY USE_FOLDERS ON)\n\n# Check that submodules are present\nif (NOT EXISTS \"${ClickHouse_SOURCE_DIR}/contrib/sysroot/README.md\")\n    message (FATAL_ERROR \"Submodules are not initialized. Run\\n\\tgit submodule update --init\")\nendif ()\n\n# Take care to add prlimit in command line before ccache, or else ccache thinks that\n# prlimit is compiler, and clang++ is its input file, and refuses to work  with\n# multiple inputs, e.g in ccache log:\n# [2021-03-31T18:06:32.655327 36900] Command line: /usr/bin/ccache prlimit --as=10000000000 --data=5000000000 --cpu=600 /usr/bin/clang++-11 - ...... std=gnu++2a -MD -MT src/CMakeFiles/dbms.dir/Storages/MergeTree/IMergeTreeDataPart.cpp.o -MF src/CMakeFiles/dbms.dir/Storages/MergeTree/IMergeTreeDataPart.cpp.o.d -o src/CMakeFiles/dbms.dir/Storages/MergeTree/IMergeTreeDataPart.cpp.o -c ../src/Storages/MergeTree/IMergeTreeDataPart.cpp\n#\n# [2021-03-31T18:06:32.656704 36900] Multiple input files: /usr/bin/clang++-11 and ../src/Storages/MergeTree/IMergeTreeDataPart.cpp\n#\n# Another way would be to use --ccache-skip option before clang++-11 to make\n# ccache ignore it.\noption(ENABLE_CHECK_HEAVY_BUILDS \"Don't allow C++ translation units to compile too long or to take too much memory while compiling.\" OFF)\nif (ENABLE_CHECK_HEAVY_BUILDS)\n    # set DATA (since RSS does not work since 2.6.x+) to 5G\n    set (RLIMIT_DATA 5000000000)\n    # set VIRT (RLIMIT_AS) to 10G (DATA*2)\n    set (RLIMIT_AS 10000000000)\n    # set CPU time limit to 1000 seconds\n    set (RLIMIT_CPU 1000)\n\n    # Sanitizers are too heavy. Some architectures too.\n    if (SANITIZE OR SANITIZE_COVERAGE OR WITH_COVERAGE OR ARCH_RISCV64 OR ARCH_LOONGARCH64)\n        # Twice as large\n        set (RLIMIT_DATA 10000000000)\n        set (RLIMIT_AS 20000000000)\n    endif()\n\n    # For some files currently building RISCV64/LOONGARCH64 might be too slow.\n    # TODO: Improve compilation times per file\n    if (ARCH_RISCV64 OR ARCH_LOONGARCH64)\n        set (RLIMIT_CPU 1800)\n    endif()\n\n    set (CMAKE_CXX_COMPILER_LAUNCHER prlimit --as=${RLIMIT_AS} --data=${RLIMIT_DATA} --cpu=${RLIMIT_CPU} ${CMAKE_CXX_COMPILER_LAUNCHER})\nendif ()\n\nif (NOT CMAKE_BUILD_TYPE OR CMAKE_BUILD_TYPE STREQUAL \"None\")\n    set (CMAKE_BUILD_TYPE \"RelWithDebInfo\")\n    message (STATUS \"CMAKE_BUILD_TYPE is not set, set to default = ${CMAKE_BUILD_TYPE}\")\nendif ()\nmessage (STATUS \"CMAKE_BUILD_TYPE: ${CMAKE_BUILD_TYPE}\")\n\nstring (TOUPPER ${CMAKE_BUILD_TYPE} CMAKE_BUILD_TYPE_UC)\n\nlist(REVERSE CMAKE_FIND_LIBRARY_SUFFIXES)\n\noption (ENABLE_FUZZING \"Fuzzy testing using libfuzzer\" OFF)\n\nif (ENABLE_FUZZING)\n    # Also set WITH_COVERAGE=1 for better fuzzing process\n    # By default this is disabled, because fuzzers are built in CI with the clickhouse itself.\n    # And we don't want to enable coverage for it.\n    message (STATUS \"Fuzzing instrumentation enabled\")\n    set (FUZZER \"libfuzzer\")\n    set (CMAKE_CXX_FLAGS \"${CMAKE_CXX_FLAGS} -nostdlib++\")\n    set (ENABLE_CLICKHOUSE_ODBC_BRIDGE OFF)\n    set (ENABLE_LIBRARIES 0)\n    set (ENABLE_SSL 1)\n    set (ENABLE_EXAMPLES 0)\n    set (ENABLE_UTILS 0)\n    set (ENABLE_THINLTO 0)\n    set (ENABLE_TCMALLOC 0)\n    set (ENABLE_JEMALLOC 0)\n    set (ENABLE_CHECK_HEAVY_BUILDS 1)\n    set (GLIBC_COMPATIBILITY OFF)\n    set (ENABLE_BENCHMARKS 0)\n\n    # For codegen_select_fuzzer\n    set (ENABLE_PROTOBUF 1)\n\n    add_compile_definitions(FUZZING_MODE=1)\nendif()\n\nif (ENABLE_PYTHON)\n    set(USE_PYTHON 1)\n    set(USE_UTF8PROC 1)\nendif()\n\n# Global libraries\n# See:\n# - default_libs.cmake\n# - sanitize.cmake\nadd_library(global-libs INTERFACE)\n\ninclude (cmake/sanitize.cmake)\n\noption(ENABLE_COLORED_BUILD \"Enable colors in compiler output\" ON)\n\nset (CMAKE_COLOR_MAKEFILE ${ENABLE_COLORED_BUILD}) # works only for the makefile generator\n\nif (ENABLE_COLORED_BUILD AND CMAKE_GENERATOR STREQUAL \"Ninja\")\n    # Turn on colored output. https://github.com/ninja-build/ninja/wiki/FAQ\n    set (CMAKE_CXX_FLAGS \"${CMAKE_CXX_FLAGS} -fdiagnostics-color=always\")\n    set (CMAKE_C_FLAGS \"${CMAKE_C_FLAGS} -fdiagnostics-color=always\")\n    # ... such manually setting of flags can be removed once CMake supports a variable to\n    # activate colors in *all* build systems: https://gitlab.kitware.com/cmake/cmake/-/issues/15502\n    # --> available since CMake 3.24: https://stackoverflow.com/a/73349744\nendif ()\n\ninclude (cmake/check_flags.cmake)\ninclude (cmake/add_warning.cmake)\n\n# generate ranges for fast \"addr2line\" search\nif (NOT CMAKE_BUILD_TYPE_UC STREQUAL \"RELEASE\")\n    # NOTE: that clang has a bug because of it does not emit .debug_aranges\n    # with ThinLTO, so custom ld.lld wrapper is shipped in docker images.\n    set(COMPILER_FLAGS \"${COMPILER_FLAGS} -gdwarf-aranges\")\nendif ()\n\n# See https://blog.llvm.org/posts/2021-04-05-constructor-homing-for-debug-info/\nif (CMAKE_BUILD_TYPE_UC STREQUAL \"DEBUG\" OR CMAKE_BUILD_TYPE_UC STREQUAL \"RELWITHDEBINFO\")\n    set (CMAKE_CXX_FLAGS \"${CMAKE_CXX_FLAGS} -Xclang -fuse-ctor-homing\")\n    set (CMAKE_C_FLAGS \"${CMAKE_C_FLAGS} -Xclang -fuse-ctor-homing\")\nendif()\n\nno_warning(enum-constexpr-conversion) # breaks Protobuf in clang-16\n\noption(ENABLE_TESTS \"Provide unit_test_dbms target with Google.Test unit tests\" ON)\noption(ENABLE_EXAMPLES \"Build all example programs in 'examples' subdirectories\" OFF)\noption(ENABLE_BENCHMARKS \"Build all benchmark programs in 'benchmarks' subdirectories\" OFF)\n\nif (OS_LINUX AND (ARCH_AMD64 OR ARCH_AARCH64) AND NOT USE_MUSL)\n    # Only for Linux, x86_64 or aarch64.\n    option(GLIBC_COMPATIBILITY \"Enable compatibility with older glibc libraries.\" ON)\nelseif(GLIBC_COMPATIBILITY)\n    message (${RECONFIGURE_MESSAGE_LEVEL} \"Glibc compatibility cannot be enabled in current configuration\")\nendif ()\n\nif (OS_LINUX)\n    # We should not export dynamic symbols, because:\n    # - The main clickhouse binary does not use dlopen,\n    #   and whatever is poisoning it by LD_PRELOAD should not link to our symbols.\n    # - The clickhouse-odbc-bridge and clickhouse-library-bridge binaries\n    #   should not expose their symbols to ODBC drivers and libraries.\n    set (CMAKE_EXE_LINKER_FLAGS \"${CMAKE_EXE_LINKER_FLAGS} -Wl,--no-export-dynamic -Wl,--gc-sections\")\nendif ()\n\nif (OS_DARWIN)\n    # The `-all_load` flag forces loading of all symbols from all libraries,\n    # and leads to multiply-defined symbols. This flag allows force loading\n    # from a _specific_ library, which is what we need.\n    set(WHOLE_ARCHIVE -force_load)\n    # The `-noall_load` flag is the default and now obsolete.\n    set(NO_WHOLE_ARCHIVE \"-undefined,error\") # Effectively, a no-op. Here to avoid empty \"-Wl, \" sequence to be generated in the command line.\nelse ()\n    set(WHOLE_ARCHIVE --whole-archive)\n    set(NO_WHOLE_ARCHIVE --no-whole-archive)\nendif ()\n\nif (NOT CMAKE_BUILD_TYPE_UC STREQUAL \"RELEASE\")\n    # Can be lld or ld-lld or lld-13 or /path/to/lld.\n    if (LINKER_NAME MATCHES \"lld\")\n        set (CMAKE_EXE_LINKER_FLAGS \"${CMAKE_EXE_LINKER_FLAGS} -Wl,--gdb-index\")\n        message (STATUS \"Adding .gdb-index via --gdb-index linker option.\")\n    endif ()\nendif()\n\nif (NOT (SANITIZE_COVERAGE OR WITH_COVERAGE)\n    AND (CMAKE_BUILD_TYPE_UC STREQUAL \"RELEASE\"\n        OR CMAKE_BUILD_TYPE_UC STREQUAL \"RELWITHDEBINFO\"\n        OR CMAKE_BUILD_TYPE_UC STREQUAL \"MINSIZEREL\"))\n    set (OMIT_HEAVY_DEBUG_SYMBOLS_DEFAULT ON)\nelse()\n    set (OMIT_HEAVY_DEBUG_SYMBOLS_DEFAULT OFF)\nendif()\n# Provides faster linking and lower binary size.\n# Tradeoff is the inability to debug some source files with e.g. gdb\n# (empty stack frames and no local variables).\"\noption(OMIT_HEAVY_DEBUG_SYMBOLS\n    \"Do not generate debugger info for heavy modules (ClickHouse functions and dictionaries, some contrib)\"\n    ${OMIT_HEAVY_DEBUG_SYMBOLS_DEFAULT})\n\noption(USE_DEBUG_HELPERS \"Enable debug helpers\" ${USE_DEBUG_HELPERS})\n\noption(BUILD_STANDALONE_KEEPER \"Build keeper as small standalone binary\" OFF)\nif (NOT BUILD_STANDALONE_KEEPER)\n    option(CREATE_KEEPER_SYMLINK \"Create symlink for clickhouse-keeper to main server binary\" ON)\nelse ()\n    option(CREATE_KEEPER_SYMLINK \"Create symlink for clickhouse-keeper to main server binary\" OFF)\nendif ()\n\n# Create BuildID when using lld. For other linkers it is created by default.\n# (NOTE: LINKER_NAME can be either path or name, and in different variants)\nif (LINKER_NAME MATCHES \"lld\")\n    # SHA1 is not cryptographically secure but it is the best what lld is offering.\n    set (CMAKE_EXE_LINKER_FLAGS \"${CMAKE_EXE_LINKER_FLAGS} -Wl,--build-id=sha1\")\nendif ()\n\n# Add a section with the hash of the compiled machine code for integrity checks.\n# Only for official builds, because adding a section can be time consuming (rewrite of several GB).\n# And cross compiled binaries are not supported (since you cannot execute clickhouse hash-binary)\nif (CLICKHOUSE_OFFICIAL_BUILD AND (NOT CMAKE_TOOLCHAIN_FILE OR CMAKE_TOOLCHAIN_FILE MATCHES \"linux/toolchain-x86_64.cmake$\"))\n    message(STATUS \"Official build: A checksum hash will be added to the clickhouse executable\")\n    set (USE_BINARY_HASH 1 CACHE STRING \"Calculate binary hash and store it in the separate section\")\nelse ()\n    message(STATUS \"No official build: A checksum hash will not be added to the clickhouse executable\")\nendif ()\n\n# Optionally split binaries and debug symbols.\noption(SPLIT_DEBUG_SYMBOLS \"Split binaries and debug symbols\" OFF)\nif (SPLIT_DEBUG_SYMBOLS)\n    message(STATUS \"Will split binaries and debug symbols\")\n    set(SPLITTED_DEBUG_SYMBOLS_DIR \"stripped\" CACHE STRING \"A separate directory for stripped information\")\nendif()\n\ncmake_host_system_information(RESULT AVAILABLE_PHYSICAL_MEMORY QUERY AVAILABLE_PHYSICAL_MEMORY) # Not available under freebsd\n\n\nif(NOT AVAILABLE_PHYSICAL_MEMORY OR AVAILABLE_PHYSICAL_MEMORY GREATER 8000)\n    # Less `/tmp` usage, more RAM usage.\n    option(COMPILER_PIPE \"-pipe compiler option\" ON)\nendif()\n\nif(COMPILER_PIPE)\n    set(COMPILER_FLAGS \"${COMPILER_FLAGS} -pipe\")\nelse()\n    message(STATUS \"Disabling compiler -pipe option (have only ${AVAILABLE_PHYSICAL_MEMORY} mb of memory)\")\nendif()\n\ninclude(cmake/cpu_features.cmake)\n\n\n# Query Profiler doesn't work on MacOS for several reasons\n# - PHDR cache is not available\n# - We use native functionality to get stacktraces which is not async signal safe\n# and thus we don't need to generate asynchronous unwind tables\nif (NOT OS_DARWIN)\n    # Asynchronous unwind tables are needed for Query Profiler.\n    # They are already by default on some platforms but possibly not on all platforms.\n    # Enable it explicitly.\n    set (COMPILER_FLAGS \"${COMPILER_FLAGS} -fasynchronous-unwind-tables\")\nendif()\n\n# Reproducible builds.\nif (CMAKE_BUILD_TYPE_UC STREQUAL \"DEBUG\")\n    set (ENABLE_BUILD_PATH_MAPPING_DEFAULT OFF)\nelse ()\n    set (ENABLE_BUILD_PATH_MAPPING_DEFAULT ON)\nendif ()\n\noption (ENABLE_BUILD_PATH_MAPPING \"Enable remapping of file source paths in debug info, predefined preprocessor macros, and __builtin_FILE(). It's used to generate reproducible builds. See https://reproducible-builds.org/docs/build-path\" ${ENABLE_BUILD_PATH_MAPPING_DEFAULT})\n\nif (ENABLE_BUILD_PATH_MAPPING)\n    set (COMPILER_FLAGS \"${COMPILER_FLAGS} -ffile-prefix-map=${PROJECT_SOURCE_DIR}=.\")\n    set (CMAKE_ASM_FLAGS \"${CMAKE_ASM_FLAGS} -ffile-prefix-map=${PROJECT_SOURCE_DIR}=.\")\nendif ()\n\noption (ENABLE_BUILD_PROFILING \"Enable profiling of build time\" OFF)\nif (ENABLE_BUILD_PROFILING)\n    set (COMPILER_FLAGS \"${COMPILER_FLAGS} -ftime-trace\")\n\n    if (LINKER_NAME MATCHES \"lld\")\n        set (CMAKE_EXE_LINKER_FLAGS \"${CMAKE_EXE_LINKER_FLAGS} -Wl,--time-trace\")\n        set (CMAKE_MODULE_LINKER_FLAGS \"${CMAKE_MODULE_LINKER_FLAGS} -Wl,--time-trace\")\n    endif ()\nendif ()\n\nset (CMAKE_CXX_STANDARD 23)\nset (CMAKE_CXX_EXTENSIONS OFF)\nset (CMAKE_CXX_STANDARD_REQUIRED ON)\n\nset (CMAKE_C_STANDARD 11)\nset (CMAKE_C_EXTENSIONS ON) # required by most contribs written in C\nset (CMAKE_C_STANDARD_REQUIRED ON)\n\n# Enable C++14 sized global deallocation functions. It should be enabled by setting -std=c++14 but I'm not sure.\n# See https://reviews.llvm.org/D112921\nset(CMAKE_CXX_FLAGS \"${CMAKE_CXX_FLAGS} -fsized-deallocation\")\n\n# falign-functions=32 prevents from random performance regressions with the code change. Thus, providing more stable\n# benchmarks.\nset(COMPILER_FLAGS \"${COMPILER_FLAGS} -falign-functions=32\")\n\nif (ARCH_AMD64)\n    # align branches within a 32-Byte boundary to avoid the potential performance loss when code layout change,\n    # which makes benchmark results more stable.\n    set(BRANCHES_WITHIN_32B_BOUNDARIES \"-mbranches-within-32B-boundaries\")\n    set(COMPILER_FLAGS \"${COMPILER_FLAGS} ${BRANCHES_WITHIN_32B_BOUNDARIES}\")\nendif()\n\n# Disable floating-point expression contraction in order to get consistent floating point calculation results across platforms\nset (COMPILER_FLAGS \"${COMPILER_FLAGS} -ffp-contract=off\")\n\nset (COMPILER_FLAGS \"${COMPILER_FLAGS} -fPIC\")\n\n# Our built-in unwinder only supports DWARF version up to 4.\nset (DEBUG_INFO_FLAGS \"-g\")\n\n# Disable omit frame pointer compiler optimization using -fno-omit-frame-pointer\noption(DISABLE_OMIT_FRAME_POINTER \"Disable omit frame pointer compiler optimization\" OFF)\n\nif (DISABLE_OMIT_FRAME_POINTER)\n    set (CMAKE_CXX_FLAGS_ADD \"${CMAKE_CXX_FLAGS_ADD} -fno-omit-frame-pointer -mno-omit-leaf-frame-pointer\")\n    set (CMAKE_C_FLAGS_ADD \"${CMAKE_C_FLAGS_ADD} -fno-omit-frame-pointer -mno-omit-leaf-frame-pointer\")\n    set (CMAKE_ASM_FLAGS_ADD \"${CMAKE_ASM_FLAGS_ADD} -fno-omit-frame-pointer -mno-omit-leaf-frame-pointer\")\nendif()\n\nset (CMAKE_CXX_FLAGS                     \"${CMAKE_CXX_FLAGS} ${COMPILER_FLAGS}\")\nset (CMAKE_CXX_FLAGS_RELWITHDEBINFO      \"${CMAKE_CXX_FLAGS_RELWITHDEBINFO} -fPIC -O3 ${DEBUG_INFO_FLAGS} ${CMAKE_CXX_FLAGS_ADD}\")\nset (CMAKE_CXX_FLAGS_DEBUG               \"${CMAKE_CXX_FLAGS_DEBUG} -O0 ${DEBUG_INFO_FLAGS} ${CMAKE_CXX_FLAGS_ADD}\")\n\nset (CMAKE_C_FLAGS                       \"${CMAKE_C_FLAGS} ${COMPILER_FLAGS} ${CMAKE_C_FLAGS_ADD}\")\nset (CMAKE_C_FLAGS_RELWITHDEBINFO        \"${CMAKE_C_FLAGS_RELWITHDEBINFO} -fPIC -O3 ${DEBUG_INFO_FLAGS} ${CMAKE_C_FLAGS_ADD}\")\nset (CMAKE_C_FLAGS_DEBUG                 \"${CMAKE_C_FLAGS_DEBUG} -O0 ${DEBUG_INFO_FLAGS} ${CMAKE_C_FLAGS_ADD}\")\n\nset (CMAKE_ASM_FLAGS                     \"${CMAKE_ASM_FLAGS} ${COMPILER_FLAGS} ${CMAKE_ASM_FLAGS_ADD}\")\nset (CMAKE_ASM_FLAGS_RELWITHDEBINFO      \"${CMAKE_ASM_FLAGS_RELWITHDEBINFO} -fPIC -O3 ${DEBUG_INFO_FLAGS} ${CMAKE_ASM_FLAGS_ADD}\")\nset (CMAKE_ASM_FLAGS_DEBUG               \"${CMAKE_ASM_FLAGS_DEBUG} -O0 ${DEBUG_INFO_FLAGS} ${CMAKE_ASM_FLAGS_ADD}\")\n\nif (OS_DARWIN)\n    set(CMAKE_CXX_FLAGS \"${CMAKE_CXX_FLAGS} -stdlib=libc++\")\n    set(CMAKE_EXE_LINKER_FLAGS \"${CMAKE_EXE_LINKER_FLAGS} -Wl,-U,_inside_main\")\nendif()\n\n# Display absolute paths in error messages. Otherwise KDevelop fails to navigate to correct file and opens a new file instead.\nset(CMAKE_CXX_FLAGS \"${CMAKE_CXX_FLAGS} -fdiagnostics-absolute-paths\")\nset(CMAKE_C_FLAGS \"${CMAKE_C_FLAGS} -fdiagnostics-absolute-paths\")\n\nif (NOT ENABLE_TESTS AND NOT SANITIZE AND NOT SANITIZE_COVERAGE AND OS_LINUX)\n    # https://clang.llvm.org/docs/ThinLTO.html\n    # Applies to clang and linux only.\n    # Disabled when building with tests or sanitizers.\n    option(ENABLE_THINLTO \"Clang-specific link time optimization\" ON)\nendif()\n\nset(CMAKE_CXX_FLAGS \"${CMAKE_CXX_FLAGS} -fstrict-vtable-pointers\")\n\n# We cannot afford to use LTO when compiling unit tests, and it's not enough\n# to only supply -fno-lto at the final linking stage. So we disable it\n# completely.\nif (ENABLE_THINLTO AND NOT ENABLE_TESTS AND NOT SANITIZE)\n    # Link time optimization\n    set (CMAKE_C_FLAGS_RELWITHDEBINFO \"${CMAKE_C_FLAGS_RELWITHDEBINFO} -flto=thin -fwhole-program-vtables\")\n    set (CMAKE_CXX_FLAGS_RELWITHDEBINFO \"${CMAKE_CXX_FLAGS_RELWITHDEBINFO} -flto=thin -fwhole-program-vtables\")\n    set (CMAKE_EXE_LINKER_FLAGS_RELWITHDEBINFO \"${CMAKE_EXE_LINKER_FLAGS_RELWITHDEBINFO} -flto=thin -fwhole-program-vtables\")\nelseif (ENABLE_THINLTO)\n    message (${RECONFIGURE_MESSAGE_LEVEL} \"Cannot enable ThinLTO\")\nendif ()\n\n# Turns on all external libs like s3, kafka, ODBC, ...\noption(ENABLE_LIBRARIES \"Enable all external libraries by default\" ON)\n\n# Increase stack size on Musl. We need big stack for our recursive-descend parser.\nif (USE_MUSL)\n    set (CMAKE_EXE_LINKER_FLAGS \"${CMAKE_EXE_LINKER_FLAGS} -Wl,-stack_size,2097152\")\nendif ()\n\ninclude(cmake/dbms_glob_sources.cmake)\n\nadd_library(global-group INTERFACE)\nif (OS_LINUX OR OS_ANDROID)\n    include(cmake/linux/default_libs.cmake)\nelseif (OS_DARWIN)\n    include(cmake/darwin/default_libs.cmake)\nelseif (OS_FREEBSD)\n    include(cmake/freebsd/default_libs.cmake)\nelse()\n    link_libraries(global-group)\nendif ()\n\noption (ENABLE_GWP_ASAN \"Enable Gwp-Asan\" OFF)\n# We use mmap for allocations more heavily in debug builds,\n# but GWP-ASan also wants to use mmap frequently,\n# and due to a large number of memory mappings,\n# it does not work together well.\n# if ((NOT OS_LINUX AND NOT OS_ANDROID) OR (CMAKE_BUILD_TYPE_UC STREQUAL \"DEBUG\"))\n#     set(ENABLE_GWP_ASAN OFF)\n# endif ()\n\noption (ENABLE_FIU \"Enable Fiu\" ON)\n\noption(WERROR \"Enable -Werror compiler option\" ON)\n\nif (WERROR)\n    # Don't pollute CMAKE_CXX_FLAGS with -Werror as it will break some CMake checks.\n    # Instead, adopt modern cmake usage requirement.\n    # TODO: Set CMAKE_COMPILE_WARNING_AS_ERROR (cmake 3.24)\n    target_compile_options(global-group INTERFACE \"-Werror\")\nendif ()\n\n# Make this extra-checks for correct library dependencies.\nif (OS_LINUX AND NOT SANITIZE)\n    target_link_options(global-group INTERFACE \"LINKER:--no-undefined\")\nendif ()\n\n######################################\n### Add targets below this comment ###\n######################################\n\nset (CMAKE_POSTFIX_VARIABLE \"CMAKE_${CMAKE_BUILD_TYPE_UC}_POSTFIX\")\n\n# if (NOT SANITIZE)\n#     set (CMAKE_POSITION_INDEPENDENT_CODE OFF)\n# endif()\nset (CMAKE_POSITION_INDEPENDENT_CODE ON)\n\n# if (OS_LINUX AND NOT (ARCH_AARCH64 OR ARCH_S390X) AND NOT SANITIZE)\n#     # Slightly more efficient code can be generated\n#     # It's disabled for ARM because otherwise ClickHouse cannot run on Android.\n#     set (CMAKE_CXX_FLAGS_RELWITHDEBINFO \"${CMAKE_CXX_FLAGS_RELWITHDEBINFO} -fno-pie\")\n#     set (CMAKE_C_FLAGS_RELWITHDEBINFO \"${CMAKE_C_FLAGS_RELWITHDEBINFO} -fno-pie\")\n#     set (CMAKE_EXE_LINKER_FLAGS \"${CMAKE_EXE_LINKER_FLAGS} -no-pie -Wl,-no-pie\")\n# endif ()\n\nif (ENABLE_TESTS)\n    message (STATUS \"Unit tests are enabled\")\nelse()\n    message(STATUS \"Unit tests are disabled\")\nendif ()\n\nenable_testing() # Enable for tests without binary\n\nif (ARCH_S390X)\n    set(ENABLE_OPENSSL_DYNAMIC_DEFAULT ON)\nelse ()\n    set(ENABLE_OPENSSL_DYNAMIC_DEFAULT OFF)\nendif ()\noption(ENABLE_OPENSSL_DYNAMIC \"This option removes SSL from ClickHouse and will link to the OpenSSL version supplied by OS.\" ${ENABLE_OPENSSL_DYNAMIC_DEFAULT})\n\n# when installing to /usr - place configs to /etc but for /usr/local place to /usr/local/etc\nif (CMAKE_INSTALL_PREFIX STREQUAL \"/usr\")\n    set (CLICKHOUSE_ETC_DIR \"/etc\")\nelse ()\n    set (CLICKHOUSE_ETC_DIR \"${CMAKE_INSTALL_PREFIX}/etc\")\nendif ()\n\nmessage (STATUS \"Building for: ${CMAKE_SYSTEM} ${CMAKE_SYSTEM_PROCESSOR} ${CMAKE_LIBRARY_ARCHITECTURE}\")\n\nadd_subdirectory (contrib EXCLUDE_FROM_ALL)\n\nif (NOT ENABLE_JEMALLOC)\n    set(CMAKE_CXX_FLAGS \"${CMAKE_CXX_FLAGS} -DUSE_JEMALLOC=0\")\n    set(CMAKE_C_FLAGS \"${CMAKE_C_FLAGS} -DUSE_JEMALLOC=0\")\n    message (WARNING \"Non default allocator is disabled. This is not recommended for production builds.\")\nelse ()\n    set(CMAKE_CXX_FLAGS \"${CMAKE_CXX_FLAGS} -DUSE_JEMALLOC=1 -DJEMALLOC_NO_RENAME=1 -DARROW_JEMALLOC=1\")\n    set(CMAKE_C_FLAGS \"${CMAKE_C_FLAGS} -DUSE_JEMALLOC=1 -DJEMALLOC_NO_RENAME=1 -DARROW_JEMALLOC=1\")\nendif ()\n\nmacro (clickhouse_add_executable target)\n    # invoke built-in add_executable\n    # explicitly acquire and interpose malloc symbols by clickhouse_malloc\n    # if GLIBC_COMPATIBILITY is ON and ENABLE_THINLTO is on than provide memcpy symbol explicitly to neutrialize thinlto's libcall generation.\n    if (ARCH_AMD64 AND GLIBC_COMPATIBILITY AND ENABLE_THINLTO)\n        add_executable (${ARGV} $<TARGET_OBJECTS:clickhouse_malloc> $<TARGET_OBJECTS:memcpy>)\n    else ()\n        add_executable (${ARGV} $<TARGET_OBJECTS:clickhouse_malloc>)\n    endif ()\n\n    get_target_property (type ${target} TYPE)\n    if (${type} STREQUAL EXECUTABLE)\n        # disabled for TSAN and gcc since libtsan.a provides overrides too\n        if (TARGET clickhouse_new_delete)\n            # operator::new/delete for executables (MemoryTracker stuff)\n            target_link_libraries (${target} PRIVATE clickhouse_new_delete)\n        endif()\n\n        # In case of static jemalloc, because zone_register() is located in zone.c and\n        # is never used outside (it is declared as constructor) it is omitted\n        # by the linker, and so jemalloc will not be registered as system\n        # allocator under osx [1], and clickhouse will SIGSEGV.\n        #\n        #   [1]: https://github.com/jemalloc/jemalloc/issues/708\n        #\n        # About symbol name:\n        # - _zone_register not zone_register due to Mach-O binary format,\n        # - _je_zone_register due to JEMALLOC_PRIVATE_NAMESPACE=je_ under OS X.\n        # - but jemalloc-cmake does not run private_namespace.sh\n        #   so symbol name should be _zone_register\n        if (ENABLE_JEMALLOC AND OS_DARWIN)\n            set_property(TARGET ${target} APPEND PROPERTY LINK_OPTIONS -u_zone_register)\n        endif()\n    endif()\nendmacro()\n\n# With cross-compiling, all targets are built for the target platform which usually different from the host\n# platform. This is problematic if a build artifact X (e.g. a file or an executable) is generated by running\n# another executable Y previously produced in the build. This is solved by compiling and running Y for/on\n# the host platform. Add target to the list:\n#    add_native_target(<target> ...)\nset_property (GLOBAL PROPERTY NATIVE_BUILD_TARGETS)\nfunction (add_native_target)\n    set_property (GLOBAL APPEND PROPERTY NATIVE_BUILD_TARGETS ${ARGV})\nendfunction (add_native_target)\n\nset(CONFIG_INCLUDE_PATH ${CMAKE_CURRENT_BINARY_DIR}/includes/configs CACHE INTERNAL \"Path to generated configuration files.\")\ninclude_directories(${CONFIG_INCLUDE_PATH})\n\n# Add as many warnings as possible for our own code.\ninclude (cmake/warnings.cmake)\ninclude (cmake/print_flags.cmake)\n\nif (ENABLE_RUST)\n    add_subdirectory (rust)\n\n    # With LTO Rust adds few symbols with global visiblity, the most common is\n    # rust_eh_personality. And this leads to linking errors because multiple\n    # Rust libraries contains the same symbol.\n    #\n    # If it was shared library, that we could use version script for linker to\n    # hide this symbols, but libraries are static.\n    #\n    # we could in theory compile everything to one library but this will be a\n    # mess\n    #\n    # But this should be OK since CI has lots of other builds that are done\n    # without LTO and it will find multiple definitions if there will be any.\n    #\n    # More information about this behaviour in Rust can be found here\n    # - https://github.com/rust-lang/rust/issues/44322\n    # - https://alanwu.space/post/symbol-hygiene/\n    if (ENABLE_THINLTO)\n        set (CMAKE_EXE_LINKER_FLAGS \"${CMAKE_EXE_LINKER_FLAGS} -Wl,--allow-multiple-definition\")\n    endif()\nendif()\n\nif (CMAKE_BUILD_TYPE_UC STREQUAL \"RELWITHDEBINFO\"\n    AND NOT SANITIZE AND NOT SANITIZE_COVERAGE AND NOT ENABLE_FUZZING\n    AND OS_LINUX AND (ARCH_AMD64 OR ARCH_AARCH64))\n    set(CHECK_LARGE_OBJECT_SIZES_DEFAULT ON)\nelse ()\n    set(CHECK_LARGE_OBJECT_SIZES_DEFAULT OFF)\nendif ()\noption(CHECK_LARGE_OBJECT_SIZES \"Check that there are no large object files after build.\" ${CHECK_LARGE_OBJECT_SIZES_DEFAULT})\n\nadd_subdirectory (base)\nadd_subdirectory (src)\nadd_subdirectory (programs)\nadd_subdirectory (utils)\n\nif (FUZZER)\n    # Bundle fuzzers target\n    add_custom_target(fuzzers)\n    # Instrument all targets fuzzer and link with libfuzzer\n    get_all_targets(all_targets)\n    foreach(target ${all_targets})\n        if (NOT(target STREQUAL \"_fuzzer\" OR target STREQUAL \"_fuzzer_no_main\"))\n            get_target_property(target_type ${target} TYPE)\n            if (NOT(target_type STREQUAL \"INTERFACE_LIBRARY\" OR target_type STREQUAL \"UTILITY\"))\n                target_compile_options(${target} PRIVATE \"-fsanitize=fuzzer-no-link\")\n            endif()\n            if (target_type STREQUAL \"EXECUTABLE\" AND target MATCHES \".+_fuzzer\")\n                message(STATUS \"${target} instrumented with fuzzer\")\n                target_link_libraries(${target} PUBLIC ch_contrib::fuzzer)\n                # Add to fuzzers bundle\n                add_dependencies(fuzzers ${target})\n                get_target_filename(${target} target_bin_name)\n                get_target_property(target_bin_dir ${target} BINARY_DIR)\n                add_custom_command(TARGET fuzzers POST_BUILD COMMAND mv \"${target_bin_dir}/${target_bin_name}\" \"${CMAKE_CURRENT_BINARY_DIR}/programs/\" VERBATIM)\n            endif()\n            if (target STREQUAL \"clickhouse\")\n                message(STATUS \"${target} instrumented with fuzzer\")\n                target_link_libraries(${target} PUBLIC ch_contrib::fuzzer_no_main)\n                # Add to fuzzers bundle\n                add_dependencies(fuzzers ${target})\n            endif()\n        endif()\n    endforeach()\n    add_custom_command(TARGET fuzzers POST_BUILD COMMAND SRC=${CMAKE_SOURCE_DIR} BIN=${CMAKE_BINARY_DIR} OUT=${CMAKE_BINARY_DIR}/programs ${CMAKE_SOURCE_DIR}/tests/fuzz/build.sh VERBATIM)\nendif()\n\ninclude (cmake/sanitize_targets.cmake)\n\n# Build native targets if necessary\nget_property(NATIVE_BUILD_TARGETS GLOBAL PROPERTY NATIVE_BUILD_TARGETS)\nif (NATIVE_BUILD_TARGETS\n    AND NOT(\n        CMAKE_HOST_SYSTEM_NAME STREQUAL CMAKE_SYSTEM_NAME\n        AND CMAKE_HOST_SYSTEM_PROCESSOR STREQUAL CMAKE_SYSTEM_PROCESSOR\n    )\n)\n    message (STATUS \"Building native targets...\")\n\n    set (NATIVE_BUILD_DIR \"${PROJECT_BINARY_DIR}/native\")\n\n    execute_process(\n        COMMAND ${CMAKE_COMMAND} -E make_directory \"${NATIVE_BUILD_DIR}\"\n        COMMAND_ECHO STDOUT)\n\n    execute_process(\n        COMMAND ${CMAKE_COMMAND}\n            \"-DCMAKE_C_COMPILER=${CMAKE_C_COMPILER}\"\n            \"-DCMAKE_CXX_COMPILER=${CMAKE_CXX_COMPILER}\"\n            \"-DCOMPILER_CACHE=${COMPILER_CACHE}\"\n            # Avoid overriding .cargo/config.toml with native toolchain.\n            \"-DENABLE_RUST=OFF\"\n            \"-DENABLE_CLICKHOUSE_SELF_EXTRACTING=${ENABLE_CLICKHOUSE_SELF_EXTRACTING}\"\n        ${PROJECT_SOURCE_DIR}\n        WORKING_DIRECTORY \"${NATIVE_BUILD_DIR}\"\n        COMMAND_ECHO STDOUT)\n\n    execute_process(\n        COMMAND ${CMAKE_COMMAND} --build \"${NATIVE_BUILD_DIR}\" --target ${NATIVE_BUILD_TARGETS}\n        COMMAND_ECHO STDOUT)\nendif ()\n"
        },
        {
          "name": "CODE_OF_CONDUCT.md",
          "type": "blob",
          "size": 0.0693359375,
          "content": "We welcome everyone to contribute to our product, see CONTRIBUTING.md.\n"
        },
        {
          "name": "CONTRIBUTING.md",
          "type": "blob",
          "size": 12.03125,
          "content": "# Contributing\n\nWelcome to `chdb` contributor's guide.\n\nThis document focuses on getting any potential contributor familiarized with\nthe development processes, but [other kinds of contributions] are also appreciated.\n\nIf you are new to using [git] or have never collaborated in a project previously,\nplease have a look at [contribution-guide.org]. Other resources are also\nlisted in the excellent [guide created by FreeCodeCamp] [^contrib1].\n\nPlease notice, all users and contributors are expected to be **open,\nconsiderate, reasonable, and respectful**. When in doubt,\n[Python Software Foundation's Code of Conduct] is a good reference in terms of\nbehavior guidelines.\n\n## Issue Reports\n\nIf you experience bugs or general issues with `chdb`, please have a look\non the [issue tracker].\nIf you don't see anything useful there, please feel free to fire an issue report.\n\n:::{tip}\nPlease don't forget to include the closed issues in your search.\nSometimes a solution was already reported, and the problem is considered\n**solved**.\n:::\n\nNew issue reports should include information about your programming environment\n(e.g., operating system, Python version) and steps to reproduce the problem.\nPlease try also to simplify the reproduction steps to a very minimal example\nthat still illustrates the problem you are facing. By removing other factors,\nyou help us to identify the root cause of the issue.\n\n## Documentation Improvements\n\nYou can help improve `chdb` docs by making them more readable and coherent, or\nby adding missing information and correcting mistakes.\n\n`chdb` documentation uses [Sphinx] as its main documentation compiler.\nThis means that the docs are kept in the same repository as the project code, and\nthat any documentation update is done in the same way was a code contribution.\n\n```{todo} Don't forget to mention which markup language you are using.\n\n    e.g.,  [reStructuredText] or [CommonMark] with [MyST] extensions.\n```\n\n```{todo} If your project is hosted on GitHub, you can also mention the following tip:\n\n   :::{tip}\n      Please notice that the [GitHub web interface] provides a quick way of\n      propose changes in `chdb`'s files. While this mechanism can\n      be tricky for normal code contributions, it works perfectly fine for\n      contributing to the docs, and can be quite handy.\n\n      If you are interested in trying this method out, please navigate to\n      the `docs` folder in the source [repository], find which file you\n      would like to propose changes and click in the little pencil icon at the\n      top, to open [GitHub's code editor]. Once you finish editing the file,\n      please write a message in the form at the bottom of the page describing\n      which changes have you made and what are the motivations behind them and\n      submit your proposal.\n   :::\n```\n\nWhen working on documentation changes in your local machine, you can\ncompile them using [tox] :\n\n```\ntox -e docs\n```\n\nand use Python's built-in web server for a preview in your web browser\n(`http://localhost:8000`):\n\n```\npython3 -m http.server --directory 'docs/_build/html'\n```\n\n## Code Contributions\n\n```{todo} Please include a reference or explanation about the internals of the project.\n\n   An architecture description, design principles or at least a summary of the\n   main concepts will make it easy for potential contributors to get started\n   quickly.\n```\n\n### Submit an issue\n\nBefore you work on any non-trivial code contribution it's best to first create\na report in the [issue tracker] to start a discussion on the subject.\nThis often provides additional considerations and avoids unnecessary work.\n\n### Create an environment\n\nBefore you start coding, we recommend creating an isolated [virtual environment]\nto avoid any problems with your installed Python packages.\nThis can easily be done via either [virtualenv]:\n\n```\nvirtualenv <PATH TO VENV>\nsource <PATH TO VENV>/bin/activate\n```\n\nor [Miniconda]:\n\n```\nconda create -n chdb python=3 six virtualenv pytest pytest-cov\nconda activate chdb\n```\n\n### Clone the repository\n\n1. Create an user account on GitHub if you do not already have one.\n\n2. Fork the project [repository]: click on the *Fork* button near the top of the\n   page. This creates a copy of the code under your account on GitHub.\n\n3. Clone this copy to your local disk:\n\n   ```\n   git clone git@github.com:YourLogin/chdb.git\n   cd chdb\n   ```\n\n4. You should run:\n\n   ```\n   pip install -U pip setuptools -e .\n   ```\n\n   to be able to import the package under development in the Python REPL.\n\n   ```{todo} if you are not using pre-commit, please remove the following item:\n   ```\n\n5. Install [pre-commit]:\n\n   ```\n   pip install pre-commit\n   pre-commit install\n   ```\n\n   `chdb` comes with a lot of hooks configured to automatically help the\n   developer to check the code being written.\n\n### Implement your changes\n\n1. Create a branch to hold your changes:\n\n   ```\n   git checkout -b my-feature\n   ```\n\n   and start making changes. Never work on the main branch!\n\n2. Start your work on this branch. Don't forget to add [docstrings] to new\n   functions, modules and classes, especially if they are part of public APIs.\n\n3. Add yourself to the list of contributors in `AUTHORS.rst`.\n\n4. When you’re done editing, do:\n\n   ```\n   git add <MODIFIED FILES>\n   git commit\n   ```\n\n   to record your changes in [git].\n\n   ```{todo} if you are not using pre-commit, please remove the following item:\n   ```\n\n   Please make sure to see the validation messages from [pre-commit] and fix\n   any eventual issues.\n   This should automatically use [flake8]/[black] to check/fix the code style\n   in a way that is compatible with the project.\n\n   :::{important}\n   Don't forget to add unit tests and documentation in case your\n   contribution adds an additional feature and is not just a bugfix.\n\n   Moreover, writing a [descriptive commit message] is highly recommended.\n   In case of doubt, you can check the commit history with:\n\n   ```\n   git log --graph --decorate --pretty=oneline --abbrev-commit --all\n   ```\n\n   to look for recurring communication patterns.\n   :::\n\n5. Please check that your changes don't break any unit tests with:\n\n   ```\n   tox\n   ```\n\n   (after having installed [tox] with `pip install tox` or `pipx`).\n\n   You can also use [tox] to run several other pre-configured tasks in the\n   repository. Try `tox -av` to see a list of the available checks.\n\n### Submit your contribution\n\n1. If everything works fine, push your local branch to the remote server with:\n\n   ```\n   git push -u origin my-feature\n   ```\n\n2. Go to the web page of your fork and click \"Create pull request\"\n   to send your changes for review.\n\n   ```{todo} if you are using GitHub, you can uncomment the following paragraph\n\n      Find more detailed information in [creating a PR]. You might also want to open\n      the PR as a draft first and mark it as ready for review after the feedbacks\n      from the continuous integration (CI) system or any required fixes.\n\n   ```\n\n### Troubleshooting\n\nThe following tips can be used when facing problems to build or test the\npackage:\n\n1. Make sure to fetch all the tags from the upstream [repository].\n   The command `git describe --abbrev=0 --tags` should return the version you\n   are expecting. If you are trying to run CI scripts in a fork repository,\n   make sure to push all the tags.\n   You can also try to remove all the egg files or the complete egg folder, i.e.,\n   `.eggs`, as well as the `*.egg-info` folders in the `src` folder or\n   potentially in the root of your project.\n\n2. Sometimes [tox] misses out when new dependencies are added, especially to\n   `setup.cfg` and `docs/requirements.txt`. If you find any problems with\n   missing dependencies when running a command with [tox], try to recreate the\n   `tox` environment using the `-r` flag. For example, instead of:\n\n   ```\n   tox -e docs\n   ```\n\n   Try running:\n\n   ```\n   tox -r -e docs\n   ```\n\n3. Make sure to have a reliable [tox] installation that uses the correct\n   Python version (e.g., 3.7+). When in doubt you can run:\n\n   ```\n   tox --version\n   # OR\n   which tox\n   ```\n\n   If you have trouble and are seeing weird errors upon running [tox], you can\n   also try to create a dedicated [virtual environment] with a [tox] binary\n   freshly installed. For example:\n\n   ```\n   virtualenv .venv\n   source .venv/bin/activate\n   .venv/bin/pip install tox\n   .venv/bin/tox -e all\n   ```\n\n4. [Pytest can drop you] in an interactive session in the case an error occurs.\n   In order to do that you need to pass a `--pdb` option (for example by\n   running `tox -- -k <NAME OF THE FALLING TEST> --pdb`).\n   You can also setup breakpoints manually instead of using the `--pdb` option.\n\n## Maintainer tasks\n\n### Releases\n\n```{todo} This section assumes you are using PyPI to publicly release your package.\n\n   If instead you are using a different/private package index, please update\n   the instructions accordingly.\n```\n\nIf you are part of the group of maintainers and have correct user permissions\non [PyPI], the following steps can be used to release a new version for\n`chdb`:\n\n1. Make sure all unit tests are successful.\n2. Tag the current commit on the main branch with a release tag, e.g., `v1.2.3`.\n3. Push the new tag to the upstream [repository],\n   e.g., `git push upstream v1.2.3`\n4. Clean up the `dist` and `build` folders with `tox -e clean`\n   (or `rm -rf dist build`)\n   to avoid confusion with old builds and Sphinx docs.\n5. Run `tox -e build` and check that the files in `dist` have\n   the correct version (no `.dirty` or [git] hash) according to the [git] tag.\n   Also check the sizes of the distributions, if they are too big (e.g., >\n   500KB), unwanted clutter may have been accidentally included.\n6. Run `tox -e publish -- --repository pypi` and check that everything was\n   uploaded to [PyPI] correctly.\n\n[^contrib1]: Even though, these resources focus on open source projects and\n    communities, the general ideas behind collaborating with other developers\n    to collectively create software are general and can be applied to all sorts\n    of environments, including private companies and proprietary code bases.\n\n\n[black]: https://pypi.org/project/black/\n[commonmark]: https://commonmark.org/\n[contribution-guide.org]: http://www.contribution-guide.org/\n[creating a pr]: https://docs.github.com/en/pull-requests/collaborating-with-pull-requests/proposing-changes-to-your-work-with-pull-requests/creating-a-pull-request\n[descriptive commit message]: https://chris.beams.io/posts/git-commit\n[docstrings]: https://www.sphinx-doc.org/en/master/usage/extensions/napoleon.html\n[first-contributions tutorial]: https://github.com/firstcontributions/first-contributions\n[flake8]: https://flake8.pycqa.org/en/stable/\n[git]: https://git-scm.com\n[github web interface]: https://docs.github.com/en/github/managing-files-in-a-repository/managing-files-on-github/editing-files-in-your-repository\n[github's code editor]: https://docs.github.com/en/github/managing-files-in-a-repository/managing-files-on-github/editing-files-in-your-repository\n[github's fork and pull request workflow]: https://guides.github.com/activities/forking/\n[guide created by freecodecamp]: https://github.com/freecodecamp/how-to-contribute-to-open-source\n[miniconda]: https://docs.conda.io/en/latest/miniconda.html\n[myst]: https://myst-parser.readthedocs.io/en/latest/syntax/syntax.html\n[other kinds of contributions]: https://opensource.guide/how-to-contribute\n[pre-commit]: https://pre-commit.com/\n[pypi]: https://pypi.org/\n[pyscaffold's contributor's guide]: https://pyscaffold.org/en/stable/contributing.html\n[pytest can drop you]: https://docs.pytest.org/en/stable/usage.html#dropping-to-pdb-python-debugger-at-the-start-of-a-test\n[python software foundation's code of conduct]: https://www.python.org/psf/conduct/\n[restructuredtext]: https://www.sphinx-doc.org/en/master/usage/restructuredtext/\n[sphinx]: https://www.sphinx-doc.org/en/master/\n[tox]: https://tox.readthedocs.io/en/stable/\n[virtual environment]: https://realpython.com/python-virtual-environments-a-primer/\n[virtualenv]: https://virtualenv.pypa.io/en/stable/\n\n\n```{todo} Please review and change the following definitions:\n```\n\n[repository]: https://github.com/chdb-io/chdb\n[issue tracker]: https://github.com/chdb-io/chdb/issues\n"
        },
        {
          "name": "LICENSE.txt",
          "type": "blob",
          "size": 11.099609375,
          "content": "Copyright 2023 chDB, Inc.\n\n                                 Apache License\n                           Version 2.0, January 2004\n                        http://www.apache.org/licenses/\n\n   TERMS AND CONDITIONS FOR USE, REPRODUCTION, AND DISTRIBUTION\n\n   1. Definitions.\n\n      \"License\" shall mean the terms and conditions for use, reproduction,\n      and distribution as defined by Sections 1 through 9 of this document.\n\n      \"Licensor\" shall mean the copyright owner or entity authorized by\n      the copyright owner that is granting the License.\n\n      \"Legal Entity\" shall mean the union of the acting entity and all\n      other entities that control, are controlled by, or are under common\n      control with that entity. For the purposes of this definition,\n      \"control\" means (i) the power, direct or indirect, to cause the\n      direction or management of such entity, whether by contract or\n      otherwise, or (ii) ownership of fifty percent (50%) or more of the\n      outstanding shares, or (iii) beneficial ownership of such entity.\n\n      \"You\" (or \"Your\") shall mean an individual or Legal Entity\n      exercising permissions granted by this License.\n\n      \"Source\" form shall mean the preferred form for making modifications,\n      including but not limited to software source code, documentation\n      source, and configuration files.\n\n      \"Object\" form shall mean any form resulting from mechanical\n      transformation or translation of a Source form, including but\n      not limited to compiled object code, generated documentation,\n      and conversions to other media types.\n\n      \"Work\" shall mean the work of authorship, whether in Source or\n      Object form, made available under the License, as indicated by a\n      copyright notice that is included in or attached to the work\n      (an example is provided in the Appendix below).\n\n      \"Derivative Works\" shall mean any work, whether in Source or Object\n      form, that is based on (or derived from) the Work and for which the\n      editorial revisions, annotations, elaborations, or other modifications\n      represent, as a whole, an original work of authorship. For the purposes\n      of this License, Derivative Works shall not include works that remain\n      separable from, or merely link (or bind by name) to the interfaces of,\n      the Work and Derivative Works thereof.\n\n      \"Contribution\" shall mean any work of authorship, including\n      the original version of the Work and any modifications or additions\n      to that Work or Derivative Works thereof, that is intentionally\n      submitted to Licensor for inclusion in the Work by the copyright owner\n      or by an individual or Legal Entity authorized to submit on behalf of\n      the copyright owner. For the purposes of this definition, \"submitted\"\n      means any form of electronic, verbal, or written communication sent\n      to the Licensor or its representatives, including but not limited to\n      communication on electronic mailing lists, source code control systems,\n      and issue tracking systems that are managed by, or on behalf of, the\n      Licensor for the purpose of discussing and improving the Work, but\n      excluding communication that is conspicuously marked or otherwise\n      designated in writing by the copyright owner as \"Not a Contribution.\"\n\n      \"Contributor\" shall mean Licensor and any individual or Legal Entity\n      on behalf of whom a Contribution has been received by Licensor and\n      subsequently incorporated within the Work.\n\n   2. Grant of Copyright License. Subject to the terms and conditions of\n      this License, each Contributor hereby grants to You a perpetual,\n      worldwide, non-exclusive, no-charge, royalty-free, irrevocable\n      copyright license to reproduce, prepare Derivative Works of,\n      publicly display, publicly perform, sublicense, and distribute the\n      Work and such Derivative Works in Source or Object form.\n\n   3. Grant of Patent License. Subject to the terms and conditions of\n      this License, each Contributor hereby grants to You a perpetual,\n      worldwide, non-exclusive, no-charge, royalty-free, irrevocable\n      (except as stated in this section) patent license to make, have made,\n      use, offer to sell, sell, import, and otherwise transfer the Work,\n      where such license applies only to those patent claims licensable\n      by such Contributor that are necessarily infringed by their\n      Contribution(s) alone or by combination of their Contribution(s)\n      with the Work to which such Contribution(s) was submitted. If You\n      institute patent litigation against any entity (including a\n      cross-claim or counterclaim in a lawsuit) alleging that the Work\n      or a Contribution incorporated within the Work constitutes direct\n      or contributory patent infringement, then any patent licenses\n      granted to You under this License for that Work shall terminate\n      as of the date such litigation is filed.\n\n   4. Redistribution. You may reproduce and distribute copies of the\n      Work or Derivative Works thereof in any medium, with or without\n      modifications, and in Source or Object form, provided that You\n      meet the following conditions:\n\n      (a) You must give any other recipients of the Work or\n          Derivative Works a copy of this License; and\n\n      (b) You must cause any modified files to carry prominent notices\n          stating that You changed the files; and\n\n      (c) You must retain, in the Source form of any Derivative Works\n          that You distribute, all copyright, patent, trademark, and\n          attribution notices from the Source form of the Work,\n          excluding those notices that do not pertain to any part of\n          the Derivative Works; and\n\n      (d) If the Work includes a \"NOTICE\" text file as part of its\n          distribution, then any Derivative Works that You distribute must\n          include a readable copy of the attribution notices contained\n          within such NOTICE file, excluding those notices that do not\n          pertain to any part of the Derivative Works, in at least one\n          of the following places: within a NOTICE text file distributed\n          as part of the Derivative Works; within the Source form or\n          documentation, if provided along with the Derivative Works; or,\n          within a display generated by the Derivative Works, if and\n          wherever such third-party notices normally appear. The contents\n          of the NOTICE file are for informational purposes only and\n          do not modify the License. You may add Your own attribution\n          notices within Derivative Works that You distribute, alongside\n          or as an addendum to the NOTICE text from the Work, provided\n          that such additional attribution notices cannot be construed\n          as modifying the License.\n\n      You may add Your own copyright statement to Your modifications and\n      may provide additional or different license terms and conditions\n      for use, reproduction, or distribution of Your modifications, or\n      for any such Derivative Works as a whole, provided Your use,\n      reproduction, and distribution of the Work otherwise complies with\n      the conditions stated in this License.\n\n   5. Submission of Contributions. Unless You explicitly state otherwise,\n      any Contribution intentionally submitted for inclusion in the Work\n      by You to the Licensor shall be under the terms and conditions of\n      this License, without any additional terms or conditions.\n      Notwithstanding the above, nothing herein shall supersede or modify\n      the terms of any separate license agreement you may have executed\n      with Licensor regarding such Contributions.\n\n   6. Trademarks. This License does not grant permission to use the trade\n      names, trademarks, service marks, or product names of the Licensor,\n      except as required for reasonable and customary use in describing the\n      origin of the Work and reproducing the content of the NOTICE file.\n\n   7. Disclaimer of Warranty. Unless required by applicable law or\n      agreed to in writing, Licensor provides the Work (and each\n      Contributor provides its Contributions) on an \"AS IS\" BASIS,\n      WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or\n      implied, including, without limitation, any warranties or conditions\n      of TITLE, NON-INFRINGEMENT, MERCHANTABILITY, or FITNESS FOR A\n      PARTICULAR PURPOSE. You are solely responsible for determining the\n      appropriateness of using or redistributing the Work and assume any\n      risks associated with Your exercise of permissions under this License.\n\n   8. Limitation of Liability. In no event and under no legal theory,\n      whether in tort (including negligence), contract, or otherwise,\n      unless required by applicable law (such as deliberate and grossly\n      negligent acts) or agreed to in writing, shall any Contributor be\n      liable to You for damages, including any direct, indirect, special,\n      incidental, or consequential damages of any character arising as a\n      result of this License or out of the use or inability to use the\n      Work (including but not limited to damages for loss of goodwill,\n      work stoppage, computer failure or malfunction, or any and all\n      other commercial damages or losses), even if such Contributor\n      has been advised of the possibility of such damages.\n\n   9. Accepting Warranty or Additional Liability. While redistributing\n      the Work or Derivative Works thereof, You may choose to offer,\n      and charge a fee for, acceptance of support, warranty, indemnity,\n      or other liability obligations and/or rights consistent with this\n      License. However, in accepting such obligations, You may act only\n      on Your own behalf and on Your sole responsibility, not on behalf\n      of any other Contributor, and only if You agree to indemnify,\n      defend, and hold each Contributor harmless for any liability\n      incurred by, or claims asserted against, such Contributor by reason\n      of your accepting any such warranty or additional liability.\n\n   END OF TERMS AND CONDITIONS\n\n   APPENDIX: How to apply the Apache License to your work.\n\n      To apply the Apache License to your work, attach the following\n      boilerplate notice, with the fields enclosed by brackets \"[]\"\n      replaced with your own identifying information. (Don't include\n      the brackets!)  The text should be enclosed in the appropriate\n      comment syntax for the file format. We also recommend that a\n      file or class name and description of purpose be included on the\n      same \"printed page\" as the copyright notice for easier\n      identification within third-party archives.\n\n   Copyright 2023 chDB, Inc.\n\n   Licensed under the Apache License, Version 2.0 (the \"License\");\n   you may not use this file except in compliance with the License.\n   You may obtain a copy of the License at\n\n       http://www.apache.org/licenses/LICENSE-2.0\n\n   Unless required by applicable law or agreed to in writing, software\n   distributed under the License is distributed on an \"AS IS\" BASIS,\n   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n   See the License for the specific language governing permissions and\n   limitations under the License."
        },
        {
          "name": "Makefile",
          "type": "blob",
          "size": 0.5703125,
          "content": ".PHONY: all clean buildlib wheel pub mac-arm64\n\nbuildlib:\n\t@echo \"Building library...\"\n\t@cd chdb && bash build.sh\n\t@echo \"Done.\"\n\nwheel:\n\t@echo \"Building wheel...\"\n\ttox -e build -- --wheel\n\t@echo \"Done.\"\n\ntest:\n\t@echo \"Testing...\"\n\tcd tests && python3 run_all.py\n\npub:\n\t@echo \"Publishing wheel...\"\n\ttox -e publish\n\t@echo \"Done.\"\n\nclean:\n\t@echo \"Cleaning...\"\n\ttox -e clean\n\t@echo \"Done.\"\n\nmac-arm64:\n\t@echo \"Make macOS arm64 whl\"\n\tchdb/build_mac_arm64.sh\n\t@echo \"Done.\"\n\nlinux-arm64:\n\t@echo \"Make linux arm64 whl\"\n\tchdb/build_linux_arm64.sh\n\t@echo \"Done.\"\n\nbuild: clean buildlib wheel\n"
        },
        {
          "name": "PreLoad.cmake",
          "type": "blob",
          "size": 4.2080078125,
          "content": "# Use Ninja instead of Unix Makefiles by default.\n# https://stackoverflow.com/questions/11269833/cmake-selecting-a-generator-within-cmakelists-txt\n#\n# Reason: it has better startup time than make and it parallelizes jobs more uniformly.\n# (when comparing to make with Makefiles that was generated by CMake)\n#\n# How to install Ninja on Ubuntu:\n#  sudo apt-get install ninja-build\n\n\nif (NOT DEFINED ENV{XCODE_IDE})\n    find_program(NINJA_PATH ninja)\n    if (NINJA_PATH)\n        set(CMAKE_GENERATOR \"Ninja\" CACHE INTERNAL \"\")\n    endif ()\nendif()\n\n# Check if environment is polluted.\nif (NOT \"$ENV{CFLAGS}\" STREQUAL \"\"\n    OR NOT \"$ENV{CXXFLAGS}\" STREQUAL \"\"\n    OR NOT \"$ENV{LDFLAGS}\" STREQUAL \"\"\n    OR CMAKE_C_FLAGS OR CMAKE_CXX_FLAGS OR CMAKE_EXE_LINKER_FLAGS OR CMAKE_MODULE_LINKER_FLAGS\n    OR CMAKE_C_FLAGS_INIT OR CMAKE_CXX_FLAGS_INIT OR CMAKE_EXE_LINKER_FLAGS_INIT OR CMAKE_MODULE_LINKER_FLAGS_INIT)\n\n    # if $ENV\n    message(\"CFLAGS: $ENV{CFLAGS}\")\n    message(\"CXXFLAGS: $ENV{CXXFLAGS}\")\n    message(\"LDFLAGS: $ENV{LDFLAGS}\")\n    # if *_FLAGS\n    message(\"CMAKE_C_FLAGS: ${CMAKE_C_FLAGS}\")\n    message(\"CMAKE_CXX_FLAGS: ${CMAKE_CXX_FLAGS}\")\n    message(\"CMAKE_EXE_LINKER_FLAGS: ${CMAKE_EXE_LINKER_FLAGS}\")\n    message(\"CMAKE_SHARED_LINKER_FLAGS: ${CMAKE_SHARED_LINKER_FLAGS}\")\n    message(\"CMAKE_MODULE_LINKER_FLAGS: ${CMAKE_MODULE_LINKER_FLAGS}\")\n    # if *_FLAGS_INIT\n    message(\"CMAKE_C_FLAGS_INIT: ${CMAKE_C_FLAGS_INIT}\")\n    message(\"CMAKE_CXX_FLAGS_INIT: ${CMAKE_CXX_FLAGS_INIT}\")\n    message(\"CMAKE_EXE_LINKER_FLAGS_INIT: ${CMAKE_EXE_LINKER_FLAGS_INIT}\")\n    message(\"CMAKE_MODULE_LINKER_FLAGS_INIT: ${CMAKE_MODULE_LINKER_FLAGS_INIT}\")\n\n    message(FATAL_ERROR \"\n        Some of the variables like CFLAGS, CXXFLAGS, LDFLAGS are not empty.\n        It is not possible to build ClickHouse with custom flags.\n        These variables can be set up by previous invocation of some other build tools.\n        You should cleanup these variables and start over again.\n\n        Run the `env` command to check the details.\n        You will also need to remove the contents of the build directory.\n\n        Note: if you don't like this behavior, you can manually edit the cmake files, but please don't complain to developers.\")\nendif()\n\n# Default toolchain - this is needed to avoid dependency on OS files.\nexecute_process(COMMAND uname -s OUTPUT_VARIABLE OS)\nexecute_process(COMMAND uname -m OUTPUT_VARIABLE ARCH)\n\n# By default, prefer clang on Linux\n# But note, that you still may change the compiler with -DCMAKE_C_COMPILER/-DCMAKE_CXX_COMPILER.\nif (OS MATCHES \"Linux\"\n    AND \"$ENV{CC}\" STREQUAL \"\"\n    AND \"$ENV{CXX}\" STREQUAL \"\"\n    AND NOT DEFINED CMAKE_C_COMPILER\n    AND NOT DEFINED CMAKE_CXX_COMPILER)\n    find_program(CLANG_PATH clang)\n    if (CLANG_PATH)\n        set(CMAKE_C_COMPILER \"clang\" CACHE INTERNAL \"\")\n    endif()\n\n    find_program(CLANG_CXX_PATH clang++)\n    if (CLANG_CXX_PATH)\n        set(CMAKE_CXX_COMPILER \"clang++\" CACHE INTERNAL \"\")\n    endif()\nendif()\n\nif (OS MATCHES \"Linux\"\n    AND NOT DEFINED CMAKE_TOOLCHAIN_FILE\n    AND NOT DISABLE_HERMETIC_BUILD\n    AND (\"$ENV{CC}\" MATCHES \".*clang.*\" OR CMAKE_C_COMPILER MATCHES \".*clang.*\"))\n\n    if (ARCH MATCHES \"amd64|x86_64\")\n        # NOTE: right now musl is not ready, since unwind is too slow with it\n        #\n        # FWIW the following had been tried:\n        # - update musl\n        # - compile musl with debug\n        # - compile musl with debug and -fasynchronous-unwind-tables\n        #\n        # But none of this changes anything so far.\n        set (CMAKE_TOOLCHAIN_FILE \"cmake/linux/toolchain-x86_64.cmake\" CACHE INTERNAL \"\")\n    elseif (ARCH MATCHES \"^(aarch64.*|AARCH64.*|arm64.*|ARM64.*)\")\n        set (CMAKE_TOOLCHAIN_FILE \"cmake/linux/toolchain-aarch64.cmake\" CACHE INTERNAL \"\")\n    elseif (ARCH MATCHES \"^(ppc64le.*|PPC64LE.*)\")\n        set (CMAKE_TOOLCHAIN_FILE \"cmake/linux/toolchain-ppc64le.cmake\" CACHE INTERNAL \"\")\n    elseif (ARCH MATCHES \"^(s390x.*|S390X.*)\")\n        set (CMAKE_TOOLCHAIN_FILE \"cmake/linux/toolchain-s390x.cmake\" CACHE INTERNAL \"\")\n    elseif (ARCH MATCHES \"^(loongarch64.*|LOONGARCH64.*)\")\n        set (CMAKE_TOOLCHAIN_FILE \"cmake/linux/toolchain-loongarch64.cmake\" CACHE INTERNAL \"\")\n    else ()\n        message (FATAL_ERROR \"Unsupported architecture: ${ARCH}\")\n    endif ()\n\nendif()\n"
        },
        {
          "name": "README-zh.md",
          "type": "blob",
          "size": 13.283203125,
          "content": "<div align=\"center\">\n   <a href=\"https://clickhouse.com/blog/chdb-joins-clickhouse-family\">📢 chDB joins the ClickHouse family 🐍+🚀</a>\n</div>\n<div align=\"center\">\n<picture>\n  <source media=\"(prefers-color-scheme: dark)\" srcset=\"docs/_static/snake-chdb-dark.png\" height=\"130\">\n  <img src=\"docs/_static/snake-chdb.png\" height=\"130\">\n</picture>\n\n[![构建状态](https://github.com/chdb-io/chdb/actions/workflows/build_linux_x86_wheels.yml/badge.svg?branch=main)](https://github.com/chdb-io/chdb/actions/workflows/build_linux_x86_wheels.yml)\n[![PyPI](https://img.shields.io/pypi/v/chdb.svg)](https://pypi.org/project/chdb/)\n[![Downloads](https://static.pepy.tech/badge/chdb)](https://pepy.tech/project/chdb)\n[![Discord](https://img.shields.io/discord/1098133460310294528?logo=Discord)](https://discord.gg/D2Daa2fM5K)\n[![Twitter](https://img.shields.io/twitter/url/http/shields.io.svg?style=social&label=Twitter)](https://twitter.com/chdb_io)\n</div>\n\n# chDB\n\n[English](README.md)\n\n> chDB 是一个由 ClickHouse 驱动的嵌入式 SQL OLAP 引擎。更多细节：[chDB: ClickHouse as a Function](https://zhuanlan.zhihu.com/p/642345300)\n\n\n## 特点\n     \n* 嵌入在 Python 中的 SQL OLAP 引擎，由 ClickHouse 驱动\n* 不需要安装 ClickHouse\n* 支持 Parquet、CSV、JSON、Arrow、ORC 和其他 60 多种格式的[输入输出](https://clickhouse.com/docs/en/interfaces/formats)，[示例](tests/format_output.py)。\n* 支持 Python DB API 2.0 标准, [example](examples/dbapi.py)\n\n## 架构\n<div align=\"center\">\n  <img src=\"docs/_static/arch-chdb3.png\" width=\"450\">\n</div>\n\n## 安装方式\n目前，chDB 只支持在 macOS（x86_64 和 ARM64）和 Linux 上的 Python 3.8+。\n```bash\npip install chdb\n```\n\n## 用法\n\n### 在命令行中运行\n> `python3 -m chdb SQL [OutputFormat]`\n```bash\npython3 -m chdb \"SELECT 1,'abc'\" Pretty\n```\n\n\n有三种使用 chdb 的方法：“原始文件查询（性能）”、“高级查询（推荐）”和“DB-API”：\n<details>\n    <summary><h4>🗂️ 原始文件查询</h4>（Parquet、CSV、JSON、Arrow、ORC 等 60 多种格式）</summary>\n\n您可以执行 SQL 并返回所需格式的数据。\n\n```python\nimport chdb\nres = chdb.query('select version()', 'Pretty'); print(res)\n```\n\n### 使用 Parquet 或 CSV\n```python\n# 查看更多数据类型格式，请参见 tests/format_output.py\nres = chdb.query('select * from file(\"data.parquet\", Parquet)', 'JSON'); print(res)\nres = chdb.query('select * from file(\"data.csv\", CSV)', 'CSV');  print(res)\nprint(f\"SQL read {res.rows_read()} rows, {res.bytes_read()} bytes, elapsed {res.elapsed()} seconds\")\n```\n\n### Pandas DataFrame 输出\n```python\n# 更多内容请参见 https://clickhouse.com/docs/en/interfaces/formats\nchdb.query('select * from file(\"data.parquet\", Parquet)', 'Dataframe')\n```\n</details>\n\n<details>\n    <summary><h4>🗂️ 高级查询</h4>（Pandas DataFrame、Parquet 文件/字节、Arrow 文件/字节）</summary>\n\n### 查询 Pandas DataFrame\n```python\nimport chdb.dataframe as cdf\nimport pandas as pd\n# Join 2 DataFrames\ndf1 = pd.DataFrame({'a': [1, 2, 3], 'b': [\"one\", \"two\", \"three\"]})\ndf2 = pd.DataFrame({'c': [1, 2, 3], 'd': [\"①\", \"②\", \"③\"]})\nret_tbl = cdf.query(sql=\"select * from __tbl1__ t1 join __tbl2__ t2 on t1.a = t2.c\",\n                  tbl1=df1, tbl2=df2)\nprint(ret_tbl)\n# Query on the DataFrame Table\nprint(ret_tbl.query('select b, sum(a) from __table__ group by b'))\n```\n</details>\n\n<details>\n  <summary><h4>🗂️ 基于有状态会话 Session 查询</h4></summary>\n\n```python\nfrom chdb import session as chs\n\n## 在临时会话中创建DB, Table, View，当会话被删除时自动清除。\nsess = chs.Session()\nsess.query(\"CREATE DATABASE IF NOT EXISTS db_xxx ENGINE = Atomic\")\nsess.query(\"CREATE TABLE IF NOT EXISTS db_xxx.log_table_xxx (x String, y Int) ENGINE = Log;\")\nsess.query(\"INSERT INTO db_xxx.log_table_xxx VALUES ('a', 1), ('b', 3), ('c', 2), ('d', 5);\")\nsess.query(\n    \"CREATE VIEW db_xxx.view_xxx AS SELECT * FROM db_xxx.log_table_xxx LIMIT 4;\"\n)\nprint(\"Select from view:\\n\")\nprint(sess.query(\"SELECT * FROM db_xxx.view_xxx\", \"Pretty\"))\n```\n\n参见: [test_stateful.py](tests/test_stateful.py)\n</details>\n\n<details>\n    <summary><h4>🗂️ Python DB-API 2.0</h4></summary>\n\n```python\nimport chdb.dbapi as dbapi\nprint(\"chdb driver version: {0}\".format(dbapi.get_client_info()))\n\nconn1 = dbapi.connect()\ncur1 = conn1.cursor()\ncur1.execute('select version()')\nprint(\"description: \", cur1.description)\nprint(\"data: \", cur1.fetchone())\ncur1.close()\nconn1.close()\n```\n</details>\n\n<details>\n    <summary><h4>🗂️ Query with UDF(User Defined Functions)</h4></summary>\n\n```python\nfrom chdb.udf import chdb_udf\nfrom chdb import query\n\n@chdb_udf()\ndef sum_udf(lhs, rhs):\n    return int(lhs) + int(rhs)\n\nprint(query(\"select sum_udf(12,22)\"))\n```\n\n参见: [test_udf.py](tests/test_udf.py).\n</details>\n\n更多示例，请参见 [examples](examples) 和 [tests](tests)。\n\n## 演示和示例\n\n- [Colab Notebook](https://colab.research.google.com/drive/1-zKB6oKfXeptggXi0kUX87iR8ZTSr4P3?usp=sharing) 和更多 [示例](examples)\n\n## 基准测试\n\n- [ClickBench of embedded engines](https://benchmark.clickhouse.com/#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)\n\n- [chDB vs Pandas](https://colab.research.google.com/drive/1FogLujJ_-ds7RGurDrUnK-U0IW8a8Qd0)\n\n- [Benchmark on DataFrame: chDB Pandas DuckDB Polars](https://benchmark.clickhouse.com/#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)\n\n\n<div align=\"center\">\n    <img src=\"https://github.com/chdb-io/chdb/raw/main/docs/_static/df_bench.png\" width=\"800\">\n</div>\n\n## 文档\n- 关于 SQL 语法，请参考 [ClickHouse SQL 参考](https://clickhouse.com/docs/en/sql-reference/syntax)\n\n\n## 贡献\n贡献是使开源社区成为一个学习、激励和创造的绝佳场所的原因。您做出的任何贡献都将受到**高度赞赏**。\n以下是您可以提供帮助的事项：\n- 「Star」和「分享」\n- [ ] 帮助测试和报告错误\n- [ ] 帮助改进文档\n- [ ] 帮助提高代码质量和性能\n\n## 事件\n\n- Demo chDB at [ClickHouse v23.7 livehouse!](https://t.co/todc13Kn19) and [Slides](https://docs.google.com/presentation/d/1ikqjOlimRa7QAg588TAB_Fna-Tad2WMg7_4AgnbQbFA/edit?usp=sharing)\n\n## 相关论文\n\n- [ClickHouse - Lightning Fast Analytics for Everyone](https://www.vldb.org/pvldb/vol17/p3731-schulze.pdf)\n\n## 版权信息\nApache 2.0，请查看 [LICENSE](LICENSE.txt) 获取更多信息。\n\n## 鸣谢\nchDB 主要基于 [ClickHouse](https://github.com/ClickHouse/ClickHouse)。由于商标和其他原因，我将其命名为 chDB。\n\n## 联系方式\n- 知乎: [@auxten](https://www.zhihu.com/people/auxten)\n- Discord：[https://discord.gg/D2Daa2fM5K](https://discord.gg/D2Daa2fM5K)\n- 电子邮件：auxten@clickhouse.com\n- Twitter：[@chdb](https://twitter.com/chdb_io)\n"
        },
        {
          "name": "README.md",
          "type": "blob",
          "size": 17.7119140625,
          "content": "<div align=\"center\">\n   <a href=\"https://clickhouse.com/blog/chdb-joins-clickhouse-family\">📢 chDB joins the ClickHouse family 🐍+🚀</a>\n</div>\n<div align=\"center\">\n<picture>\n  <source media=\"(prefers-color-scheme: dark)\" srcset=\"https://github.com/chdb-io/chdb/raw/main/docs/_static/snake-chdb-dark.png\" height=\"130\">\n  <img src=\"https://github.com/chdb-io/chdb/raw/main/docs/_static/snake-chdb.png\" height=\"130\">\n</picture>\n\n[![Build X86](https://github.com/chdb-io/chdb/actions/workflows/build_linux_x86_wheels.yml/badge.svg?event=release)](https://github.com/chdb-io/chdb/actions/workflows/build_linux_x86_wheels.yml)\n[![PyPI](https://img.shields.io/pypi/v/chdb.svg)](https://pypi.org/project/chdb/)\n[![Downloads](https://static.pepy.tech/badge/chdb)](https://pepy.tech/project/chdb)\n[![Discord](https://img.shields.io/discord/1098133460310294528?logo=Discord)](https://discord.gg/D2Daa2fM5K)\n[![Twitter](https://img.shields.io/twitter/url/http/shields.io.svg?style=social&label=Twitter)](https://twitter.com/chdb_io)\n</div>\n\n# chDB\n\n\n> chDB is an in-process SQL OLAP Engine powered by ClickHouse  [^1]\n> For more details: [The birth of chDB](https://auxten.com/the-birth-of-chdb/) \n\n\n## Features\n     \n* In-process SQL OLAP Engine, powered by ClickHouse\n* No need to install ClickHouse\n* Minimized data copy from C++ to Python with [python memoryview](https://docs.python.org/3/c-api/memoryview.html)\n* Input&Output support Parquet, CSV, JSON, Arrow, ORC and 60+[more](https://clickhouse.com/docs/en/interfaces/formats) formats, [samples](tests/format_output.py)\n* Support Python DB API 2.0, [example](examples/dbapi.py)\n\n\n\n## Arch\n<div align=\"center\">\n  <img src=\"https://github.com/chdb-io/chdb/raw/main/docs/_static/arch-chdb3.png\" width=\"450\">\n</div>\n\n## Get Started\nGet started with **chdb** using our [Installation and Usage Examples](https://clickhouse.com/docs/en/chdb)\n\n<br>\n\n## Installation\nCurrently, chDB supports Python 3.8+ on macOS and Linux (x86_64 and ARM64).\n```bash\npip install chdb\n```\n\n## Usage\n\n### Run in command line\n> `python3 -m chdb SQL [OutputFormat]`\n```bash\npython3 -m chdb \"SELECT 1,'abc'\" Pretty\n```\n\n<br>\n\n### Data Input\nThe following methods are available to access on-disk and in-memory data formats:\n\n<details>\n    <summary><h4>🗂️ Query On File</h4> (Parquet, CSV, JSON, Arrow, ORC and 60+)</summary>\n\nYou can execute SQL and return desired format data.\n\n```python\nimport chdb\nres = chdb.query('select version()', 'Pretty'); print(res)\n```\n\n### Work with Parquet or CSV\n```python\n# See more data type format in tests/format_output.py\nres = chdb.query('select * from file(\"data.parquet\", Parquet)', 'JSON'); print(res)\nres = chdb.query('select * from file(\"data.csv\", CSV)', 'CSV');  print(res)\nprint(f\"SQL read {res.rows_read()} rows, {res.bytes_read()} bytes, elapsed {res.elapsed()} seconds\")\n```\n\n### Pandas dataframe output\n```python\n# See more in https://clickhouse.com/docs/en/interfaces/formats\nchdb.query('select * from file(\"data.parquet\", Parquet)', 'Dataframe')\n```\n</details>\n\n<details>\n    <summary><h4>🗂️ Query On Table</h4> (Pandas DataFrame, Parquet file/bytes, Arrow bytes) </summary>\n\n### Query On Pandas DataFrame\n```python\nimport chdb.dataframe as cdf\nimport pandas as pd\n# Join 2 DataFrames\ndf1 = pd.DataFrame({'a': [1, 2, 3], 'b': [\"one\", \"two\", \"three\"]})\ndf2 = pd.DataFrame({'c': [1, 2, 3], 'd': [\"①\", \"②\", \"③\"]})\nret_tbl = cdf.query(sql=\"select * from __tbl1__ t1 join __tbl2__ t2 on t1.a = t2.c\",\n                  tbl1=df1, tbl2=df2)\nprint(ret_tbl)\n# Query on the DataFrame Table\nprint(ret_tbl.query('select b, sum(a) from __table__ group by b'))\n```\n</details>\n\n<details>\n  <summary><h4>🗂️ Query with Stateful Session</h4></summary>\n\n```python\nfrom chdb import session as chs\n\n## Create DB, Table, View in temp session, auto cleanup when session is deleted.\nsess = chs.Session()\nsess.query(\"CREATE DATABASE IF NOT EXISTS db_xxx ENGINE = Atomic\")\nsess.query(\"CREATE TABLE IF NOT EXISTS db_xxx.log_table_xxx (x String, y Int) ENGINE = Log;\")\nsess.query(\"INSERT INTO db_xxx.log_table_xxx VALUES ('a', 1), ('b', 3), ('c', 2), ('d', 5);\")\nsess.query(\n    \"CREATE VIEW db_xxx.view_xxx AS SELECT * FROM db_xxx.log_table_xxx LIMIT 4;\"\n)\nprint(\"Select from view:\\n\")\nprint(sess.query(\"SELECT * FROM db_xxx.view_xxx\", \"Pretty\"))\n```\n\nsee also: [test_stateful.py](tests/test_stateful.py).\n</details>\n\n<details>\n    <summary><h4>🗂️ Query with Python DB-API 2.0</h4></summary>\n\n```python\nimport chdb.dbapi as dbapi\nprint(\"chdb driver version: {0}\".format(dbapi.get_client_info()))\n\nconn1 = dbapi.connect()\ncur1 = conn1.cursor()\ncur1.execute('select version()')\nprint(\"description: \", cur1.description)\nprint(\"data: \", cur1.fetchone())\ncur1.close()\nconn1.close()\n```\n</details>\n\n\n<details>\n    <summary><h4>🗂️ Query with UDF (User Defined Functions)</h4></summary>\n\n```python\nfrom chdb.udf import chdb_udf\nfrom chdb import query\n\n@chdb_udf()\ndef sum_udf(lhs, rhs):\n    return int(lhs) + int(rhs)\n\nprint(query(\"select sum_udf(12,22)\"))\n```\n\nSome notes on chDB Python UDF(User Defined Function) decorator.\n1. The function should be stateless. So, only UDFs are supported, not UDAFs(User Defined Aggregation Function).\n2. Default return type is String. If you want to change the return type, you can pass in the return type as an argument.\n    The return type should be one of the following: https://clickhouse.com/docs/en/sql-reference/data-types\n3. The function should take in arguments of type String. As the input is TabSeparated, all arguments are strings.\n4. The function will be called for each line of input. Something like this:\n    ```\n    def sum_udf(lhs, rhs):\n        return int(lhs) + int(rhs)\n\n    for line in sys.stdin:\n        args = line.strip().split('\\t')\n        lhs = args[0]\n        rhs = args[1]\n        print(sum_udf(lhs, rhs))\n        sys.stdout.flush()\n    ```\n5. The function should be pure python function. You SHOULD import all python modules used IN THE FUNCTION.\n    ```\n    def func_use_json(arg):\n        import json\n        ...\n    ```\n6. Python interpertor used is the same as the one used to run the script. Get from `sys.executable`\n\nsee also: [test_udf.py](tests/test_udf.py).\n</details>\n\n\n<details>\n    <summary><h4>🗂️ Python Table Engine</h4></summary>\n\n### Query on Pandas DataFrame\n\n```python\nimport chdb\nimport pandas as pd\ndf = pd.DataFrame(\n    {\n        \"a\": [1, 2, 3, 4, 5, 6],\n        \"b\": [\"tom\", \"jerry\", \"auxten\", \"tom\", \"jerry\", \"auxten\"],\n    }\n)\n\nchdb.query(\"SELECT b, sum(a) FROM Python(df) GROUP BY b ORDER BY b\").show()\n```\n\n### Query on Arrow Table\n\n```python\nimport chdb\nimport pyarrow as pa\narrow_table = pa.table(\n    {\n        \"a\": [1, 2, 3, 4, 5, 6],\n        \"b\": [\"tom\", \"jerry\", \"auxten\", \"tom\", \"jerry\", \"auxten\"],\n    }\n)\n\nchdb.query(\n    \"SELECT b, sum(a) FROM Python(arrow_table) GROUP BY b ORDER BY b\", \"debug\"\n).show()\n```\n\n### Query on chdb.PyReader class instance\n\n1. You must inherit from chdb.PyReader class and implement the `read` method.\n2. The `read` method should:\n    1. return a list of lists, the first demension is the column, the second dimension is the row, the columns order should be the same as the first arg `col_names` of `read`.\n    1. return an empty list when there is no more data to read.\n    1. be stateful, the cursor should be updated in the `read` method.\n3. An optional `get_schema` method can be implemented to return the schema of the table. The prototype is `def get_schema(self) -> List[Tuple[str, str]]:`, the return value is a list of tuples, each tuple contains the column name and the column type. The column type should be one of the following: https://clickhouse.com/docs/en/sql-reference/data-types\n\n```python\nimport chdb\n\nclass myReader(chdb.PyReader):\n    def __init__(self, data):\n        self.data = data\n        self.cursor = 0\n        super().__init__(data)\n\n    def read(self, col_names, count):\n        print(\"Python func read\", col_names, count, self.cursor)\n        if self.cursor >= len(self.data[\"a\"]):\n            return []\n        block = [self.data[col] for col in col_names]\n        self.cursor += len(block[0])\n        return block\n\nreader = myReader(\n    {\n        \"a\": [1, 2, 3, 4, 5, 6],\n        \"b\": [\"tom\", \"jerry\", \"auxten\", \"tom\", \"jerry\", \"auxten\"],\n    }\n)\n\nchdb.query(\n    \"SELECT b, sum(a) FROM Python(reader) GROUP BY b ORDER BY b\"\n).show()\n```\n\nsee also: [test_query_py.py](tests/test_query_py.py).\n\n### Limitations\n\n1. Column types supported: pandas.Series, pyarrow.array, chdb.PyReader\n1. Data types supported: Int, UInt, Float, String, Date, DateTime, Decimal\n1. Python Object type will be converted to String\n1. Pandas DataFrame performance is all of the best, Arrow Table is better than PyReader\n\n\n</details>\n\nFor more examples, see [examples](examples) and [tests](tests).\n\n<br>\n\n## Demos and Examples\n\n- [Project Documentation](https://clickhouse.com/docs/en/chdb) and [Usage Examples](https://clickhouse.com/docs/en/chdb/install/python)\n- [Colab Notebooks](https://colab.research.google.com/drive/1-zKB6oKfXeptggXi0kUX87iR8ZTSr4P3?usp=sharing) and other [Script Examples](examples)\n\n## Benchmark\n\n- [ClickBench of embedded engines](https://benchmark.clickhouse.com/#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)\n\n- [chDB vs Pandas](https://colab.research.google.com/drive/1FogLujJ_-ds7RGurDrUnK-U0IW8a8Qd0)\n\n- [Benchmark on DataFrame: chDB Pandas DuckDB Polars](https://benchmark.clickhouse.com/#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)\n\n\n<div align=\"center\">\n    <img src=\"https://github.com/chdb-io/chdb/raw/main/docs/_static/df_bench.png\" width=\"800\">\n</div>\n\n\n## Documentation\n- For chdb specific examples and documentation refer to [chDB docs](https://clickhouse.com/docs/en/chdb)\n- For SQL syntax, please refer to [ClickHouse SQL Reference](https://clickhouse.com/docs/en/sql-reference/syntax)\n\n\n## Events\n\n- Demo chDB at [ClickHouse v23.7 livehouse!](https://t.co/todc13Kn19) and [Slides](https://docs.google.com/presentation/d/1ikqjOlimRa7QAg588TAB_Fna-Tad2WMg7_4AgnbQbFA/edit?usp=sharing)\n\n## Contributing\nContributions are what make the open source community such an amazing place to be learn, inspire, and create. Any contributions you make are **greatly appreciated**.\nThere are something you can help:\n- [ ] Help test and report bugs\n- [ ] Help improve documentation\n- [ ] Help improve code quality and performance\n\n### Bindings\n\nWe welcome bindings for other languages, please refer to [bindings](bindings.md) for more details.\n\n## Paper\n\n- [ClickHouse - Lightning Fast Analytics for Everyone](https://www.vldb.org/pvldb/vol17/p3731-schulze.pdf)\n\n## License\nApache 2.0, see [LICENSE](LICENSE.txt) for more information.\n\n## Acknowledgments\nchDB is mainly based on [ClickHouse](https://github.com/ClickHouse/ClickHouse) [^1]\nfor trade mark and other reasons, I named it chDB.\n\n## Contact\n- Discord: [https://discord.gg/D2Daa2fM5K](https://discord.gg/D2Daa2fM5K)\n- Email: auxten@clickhouse.com\n- Twitter: [@chdb](https://twitter.com/chdb_io)\n\n\n<br>\n\n[^1]: ClickHouse® is a trademark of ClickHouse Inc. All trademarks, service marks, and logos mentioned or depicted are the property of their respective owners. The use of any third-party trademarks, brand names, product names, and company names does not imply endorsement, affiliation, or association with the respective owners.\n"
        },
        {
          "name": "SECURITY.md",
          "type": "blob",
          "size": 2.5390625,
          "content": "<!--\nthe file is autogenerated by utils/security-generator/generate_security.py\n-->\n\n# Security Policy\n\n## Security Announcements\nSecurity fixes will be announced by posting them in the [security changelog](https://clickhouse.com/docs/en/whats-new/security-changelog/).\n\n## Scope and Supported Versions\n\nThe following versions of ClickHouse server are currently being supported with security updates:\n\n| Version | Supported |\n|:-|:-|\n| 24.4 | ✔️ |\n| 24.3 | ✔️ |\n| 24.2 | ✔️ |\n| 24.1 | ❌ |\n| 23.* | ❌ |\n| 23.8 | ✔️ |\n| 23.7 | ❌ |\n| 23.6 | ❌ |\n| 23.5 | ❌ |\n| 23.4 | ❌ |\n| 23.3 | ❌ |\n| 23.2 | ❌ |\n| 23.1 | ❌ |\n| 22.* | ❌ |\n| 21.* | ❌ |\n| 20.* | ❌ |\n| 19.* | ❌ |\n| 18.* | ❌ |\n| 1.* | ❌ |\n\n## Reporting a Vulnerability\n\nWe're extremely grateful for security researchers and users that report vulnerabilities to the ClickHouse Open Source Community. All reports are thoroughly investigated by developers.\n\nTo report a potential vulnerability in ClickHouse please send the details about it to [security@clickhouse.com](mailto:security@clickhouse.com). We do not offer any financial rewards for reporting issues to us using this method. Alternatively, you can also submit your findings through our public bug bounty program hosted by [Bugcrowd](https://bugcrowd.com/clickhouse) and be rewarded for it as per the program scope and rules of engagement.\n\n### When Should I Report a Vulnerability?\n\n- You think you discovered a potential security vulnerability in ClickHouse\n- You are unsure how a vulnerability affects ClickHouse\n\n### When Should I NOT Report a Vulnerability?\n\n- You need help tuning ClickHouse components for security\n- You need help applying security related updates\n- Your issue is not security related\n\n## Security Vulnerability Response\n\nEach report is acknowledged and analyzed by ClickHouse maintainers within 5 working days.\nAs the security issue moves from triage, to identified fix, to release planning we will keep the reporter updated.\n\n## Public Disclosure Timing\n\nA public disclosure date is negotiated by the ClickHouse maintainers and the bug submitter. We prefer to fully disclose the bug as soon as possible once a user mitigation is available. It is reasonable to delay disclosure when the bug or the fix is not yet fully understood, the solution is not well-tested, or for vendor coordination. The timeframe for disclosure is from immediate (especially if it's already publicly known) to 90 days. For a vulnerability with a straightforward mitigation, we expect the report date to disclosure date to be on the order of 7 days.\n\n"
        },
        {
          "name": "base",
          "type": "tree",
          "content": null
        },
        {
          "name": "benchmark",
          "type": "tree",
          "content": null
        },
        {
          "name": "bindings.md",
          "type": "blob",
          "size": 3.11328125,
          "content": "## Welcome to the Bindings Contributors\n\nWelcome to the community of bindings contributors! chDB offers a Stable C ABI, which facilitates the development of bindings in various languages. For a C language calling demo, please refer to the examples in the `/examples` directory, such as `chdbDlopen.c`, `chdbSimple.c`, and `chdbStub.c`.\n\n### chDB Language Bindings Status\n\nHere is a table outlining the current status of language bindings for chDB:\n\n| Language | Repository | Status |\n| --- | --- | --- |\n| Python | [chdb](https://github.com/chdb-io/chdb) | Production Ready |\n| Golang | [chdb-go](https://github.com/chdb-io/chdb-go) | General Available |\n| Bun | [chdb-bun](https://github.com/chdb-io/chdb-bun) | General Available |\n| Node | [chdb-node](https://github.com/chdb-io/chdb-node) | General Available |\n| Rust | [chdb-rust](https://github.com/chdb-io/chdb-rust) | In Development (Contributors Needed) |\n| Java | n/a | Contributors Needed |\n| PHP | n/a | Contributors Needed |\n| Ruby | n/a | Contributors Needed |\n| R | n/a | Contributors Needed |\n\n\n\n### chDB stable ABI\n\nchDB provides several stable ABIs for other language bindings.\n\n\n\nThe following is the definition of the `local_result` and `local_result_v2` structure:\n\n```c\nstruct local_result\n{\n    char * buf;\n    size_t len;\n    void * _vec; // std::vector<char> *, for freeing\n    double elapsed;\n    uint64_t rows_read;\n    uint64_t bytes_read;\n};\n\nstruct local_result_v2\n{\n    char * buf;\n    size_t len;\n    void * _vec; // std::vector<char> *, for freeing\n    double elapsed;\n    uint64_t rows_read;\n    uint64_t bytes_read;\n    char * error_message;\n};\n```\n\nThe following is the definition of the `query_stable`, `free_result` and `query_stable_v2`, `free_result_v2` functions.\n\n```c\n// v1 API\nstruct local_result * query_stable(int argc, char ** argv);\nvoid free_result(struct local_result * result);\n\n// v2 API added `char * error_message`.\nstruct local_result_v2 * query_stable_v2(int argc, char ** argv);\nvoid free_result_v2(struct local_result_v2 * result);\n```\n\n#### Query\n`query_stable` and `query_stable_v2` accept the same parameters just like the `clickhouse-local` command line tool. You can check `queryToBuffer` function in [LocalChdb.cpp](programs/local/LocalChdb.cpp) as an example.\n\nThe difference is that `query_stable_v2` adds the `char * error_message` field.\nYou can check if the `error_message` field is `NULL` to determine if an error occurred.\n\n#### Free Result\n`free_result` and `free_result_v2` are used to free the `local_result` and `local_result_v2` memory. For GC languages, you can call `free_result` or `free_result_v2` in the destructor of the object.\n\n#### Known Issues\n\n- By chDB v1.2.0, the `query_stable_v2``\n returns nil if the query(eg. CREATE TABLE) successes but returns no data. We will change this behavior in the future.\n\n\n### Need Help?\nIf you have already developed bindings for a language not listed above, \n\nIf you are interested in contributing to the development of bindings for a language not listed above, please contact us at:\n\n- Discord: [bindings](https://discord.gg/uUk6AKf7yM)\n- Email: auxten@clickhouse.com\n- Twitter: [@chdb](https://twitter.com/chdb_io)\n"
        },
        {
          "name": "chdb",
          "type": "tree",
          "content": null
        },
        {
          "name": "cmake",
          "type": "tree",
          "content": null
        },
        {
          "name": "contrib",
          "type": "tree",
          "content": null
        },
        {
          "name": "docker",
          "type": "tree",
          "content": null
        },
        {
          "name": "docs",
          "type": "tree",
          "content": null
        },
        {
          "name": "examples",
          "type": "tree",
          "content": null
        },
        {
          "name": "format_sources",
          "type": "blob",
          "size": 0.2548828125,
          "content": "# Settings -> Configure KDevelop -> Source Formatter -> [C++, C] ; Custom Script Formatter ; Kdevelop: kdev_format_source\n*.c *.cpp *.h *.hpp: mv $TMPFILE $TMPFILE.tmp; cat $TMPFILE.tmp | clang-format -style=file -assume-filename=`pwd`/.clang-format > $TMPFILE\n"
        },
        {
          "name": "gen_manifest.sh",
          "type": "blob",
          "size": 0.599609375,
          "content": "#!/bin/bash\n\nset -e\n\nDIR=\"$( cd \"$( dirname \"${BASH_SOURCE[0]}\" )\" >/dev/null 2>&1 && pwd )\"\n\ncd ${DIR}\n\nrm -f MANIFEST.in\n\necho \"include README.md\" >> MANIFEST.in\necho \"include LICENSE.txt\" >> MANIFEST.in\necho \"graft chdb\" >> MANIFEST.in\necho \"global-exclude *.py[cod]\" >> MANIFEST.in\necho \"global-exclude __pycache__\" >> MANIFEST.in\necho \"global-exclude .DS_Store\" >> MANIFEST.in\necho \"global-exclude .git*\" >> MANIFEST.in\necho \"global-exclude ~*\" >> MANIFEST.in\nexport SO_SUFFIX=$(python3 -c \"import sysconfig; print(sysconfig.get_config_var('EXT_SUFFIX'))\")\necho \"include chdb/_chdb${SO_SUFFIX}\" >> MANIFEST.in"
        },
        {
          "name": "packages",
          "type": "tree",
          "content": null
        },
        {
          "name": "programs",
          "type": "tree",
          "content": null
        },
        {
          "name": "pybind",
          "type": "tree",
          "content": null
        },
        {
          "name": "pyproject.toml",
          "type": "blob",
          "size": 0.330078125,
          "content": "[build-system]\nrequires = [\"setuptools>=46.1.0\", \"pybind11>=2.6\"]\nbuild-backend = \"setuptools.build_meta\"\n\n[tool.cibuildwheel]\nbuild-frontend = \"pip\"\n\n[tool.pyright]\ninclude = [\"chdb\"]\nexclude = [\"src\", \"contrib\", \"programs\", \"build\", \"buildlib\", \"dist\", \"venv\", \".venv\", \".vscode\", \".git\", \"__pycache__\", \".mypy_cache\", \".pytest_cache\"]\n"
        },
        {
          "name": "rust",
          "type": "tree",
          "content": null
        },
        {
          "name": "setup.cfg",
          "type": "blob",
          "size": 2.1455078125,
          "content": "# This file is used to configure your project.\n# Read more about the various options under:\n# https://setuptools.pypa.io/en/latest/userguide/declarative_config.html\n# https://setuptools.pypa.io/en/latest/references/keywords.html\n\n[metadata]\nname = chdb\ndescription = chDB is an in-process SQL OLAP Engine powered by ClickHouse\nauthor = auxten\nauthor_email = auxten@clickhouse.com\nlicense = Apache-2.0\nlicense_files = LICENSE.txt\nlong_description = file: README.md\nlong_description_content_type = text/markdown; charset=UTF-8; variant=GFM\nurl = https://github.com/chdb-io/chdb\n# Add here related links, for example:\nproject_urls =\n    Homepage = https://clickhouse.com/chdb\n    Documentation = https://clickhouse.com/docs/en/chdb\n    Source = https://github.com/chdb-io/chdb\n    Download = https://pypi.org/project/chdb/#files\n    Twitter = https://twitter.com/chdb_io\n\n# Change if running only on Windows, Mac or Linux (comma-separated)\nplatforms = Mac, Linux\n\n# Add here all kinds of additional classifiers as defined under\n# https://pypi.org/classifiers/\nclassifiers =\n    Development Status :: 4 - Beta\n    Intended Audience :: Developers\n    License :: OSI Approved :: Apache Software License\n    Operating System :: MacOS :: MacOS X\n    Operating System :: POSIX\n    Programming Language :: Python :: 3.8\n    Programming Language :: Python :: 3.9\n    Programming Language :: Python :: 3.10\n    Programming Language :: Python :: 3.11\n    Programming Language :: Python :: 3.12\n    Topic :: Database\n    Topic :: Scientific/Engineering :: Information Analysis\n\n[devpi:upload]\n# Options for the devpi: PyPI server and packaging tool\n# VCS export must be deactivated since we are using setuptools-scm\nno_vcs = 1\nformats = bdist_wheel\n\n[flake8]\n# Some sane defaults for the code style checker flake8\nmax_line_length = 88\nextend_ignore = E203, W503\n# ^  Black-compatible\n#    E203 and W503 have edge cases handled by black\nexclude =\n    .tox\n    build\n    dist\n    .eggs\n    docs/conf.py\n\n[pyscaffold]\n# PyScaffold's parameters when the project was created.\n# This will be used when updating. Do not change!\nversion = 4.4\npackage = chdb\nextensions =\n    markdown\n\n[options]\npython_requires = >=3.8\n"
        },
        {
          "name": "setup.py",
          "type": "blob",
          "size": 7.4619140625,
          "content": "import os\nimport sys\nimport re\nimport subprocess\nimport sysconfig\nfrom setuptools import setup, Extension\nfrom setuptools.command.build_ext import build_ext\nimport setuptools\nfrom distutils import log\n\nlog.set_verbosity(log.DEBUG)\n\n\ndef get_python_ext_suffix():\n    internal_ext_suffix = sysconfig.get_config_var(\"EXT_SUFFIX\")\n    p = subprocess.run(\n        [\n            \"python3\",\n            \"-c\",\n            \"import sysconfig; print(sysconfig.get_config_var('EXT_SUFFIX'))\",\n        ],\n        capture_output=True,\n        text=True,\n    )\n    if p.returncode != 0:\n        print(\"Failed to get EXT_SUFFIX via python3\")\n        return internal_ext_suffix\n    py_ext_suffix = p.stdout.strip()\n    if py_ext_suffix != internal_ext_suffix:\n        print(\"EXT_SUFFIX mismatch\")\n        print(\"Internal EXT_SUFFIX: \" + internal_ext_suffix)\n        print(\"Python3 EXT_SUFFIX: \" + py_ext_suffix)\n        print(\"Current Python Path: \" + sys.executable)\n        print(\"Current Python Version: \" + sys.version)\n        print(\n            \"Outside Python Path: \"\n            + subprocess.check_output([\"which\", \"python3\"]).decode(\"utf-8\").strip()\n        )\n        print(\n            \"Outside Python Version: \"\n            + subprocess.check_output([\"python3\", \"--version\"]).decode(\"utf-8\").strip()\n        )\n    return py_ext_suffix\n\n\n# get the path of the current file\nscript_dir = os.path.dirname(os.path.abspath(__file__))\nlibdir = os.path.join(script_dir, \"chdb\")\n\n\ndef get_latest_git_tag(minor_ver_auto=False):\n    try:\n        # get latest tag commit\n        completed_process = subprocess.run(\n            [\"git\", \"rev-list\", \"--tags\", \"--max-count=1\"],\n            capture_output=True,\n            text=True,\n        )\n        if completed_process.returncode != 0:\n            print(completed_process.stdout)\n            print(completed_process.stderr)\n            # get git version\n            raise RuntimeError(\"Failed to get git latest tag commit \")\n        output = completed_process.stdout.strip()\n        # get latest tag name by commit\n        completed_process = subprocess.run(\n            [\"git\", \"describe\", \"--tags\", f\"{output}\"], capture_output=True, text=True\n        )\n        if completed_process.returncode != 0:\n            print(completed_process.stdout)\n            print(completed_process.stderr)\n            # get git version\n            raise RuntimeError(\"Failed to get git tag\")\n        output = completed_process.stdout.strip()\n        # strip the v from the tag\n        output = output[1:]\n        parts = output.split(\".\")\n        if len(parts) == 3:\n            if minor_ver_auto:\n                completed_process = subprocess.run(\n                    [\"git\", \"rev-list\", \"--count\", f\"v{output}..HEAD\"],\n                    capture_output=True,\n                    text=True,\n                )\n                if completed_process.returncode != 0:\n                    print(completed_process.stdout)\n                    print(completed_process.stderr)\n                    raise RuntimeError(\"Failed to get git rev-list\")\n                n = completed_process.stdout.strip()\n                parts[2] = int(parts[2]) + int(n)\n            return f\"{parts[0]}.{parts[1]}.{parts[2]}\"\n    except Exception as e:\n        print(\"Failed to get git tag. Error: \")\n        print(e)\n        raise\n\n\n# replace the version in chdb/__init__.py, which is `chdb_version = ('0', '1', '0')` by default\n# regex replace the version string `chdb_version = ('0', '1', '0')` with version parts\ndef fix_version_init(version):\n    # split version string into parts\n    p1, p2, p3 = version.split(\".\")\n    init_file = os.path.join(script_dir, \"chdb\", \"__init__.py\")\n    with open(init_file, \"r+\") as f:\n        init_content = f.read()\n        # regex replace the version string `chdb_version = ('0', '1', '0')`\n        regPattern = r\"chdb_version = \\(\\'\\d+\\', \\'\\d+\\', \\'\\d+\\'\\)\"\n        init_content = re.sub(\n            regPattern, f\"chdb_version = ('{p1}', '{p2}', '{p3}')\", init_content\n        )\n        f.seek(0)\n        f.write(init_content)\n        f.truncate()\n\n\n# Update version in pyproject.toml\ndef update_pyproject_version(version):\n    pyproject_file = os.path.join(script_dir, \"pyproject.toml\")\n    with open(pyproject_file, \"r\") as f:\n        content = f.read()\n\n    # Use regex to replace the version\n    updated_content = re.sub(\n        r'version\\s*=\\s*\"[^\"]*\"', f'version = \"{version}\"', content\n    )\n\n    with open(pyproject_file, \"w\") as f:\n        f.write(updated_content)\n\n\n# As of Python 3.6, CCompiler has a `has_flag` method.\n# cf http://bugs.python.org/issue26689\ndef has_flag(compiler, flagname):\n    \"\"\"Return a boolean indicating whether a flag name is supported on\n    the specified compiler.\n    \"\"\"\n    import tempfile\n\n    with tempfile.NamedTemporaryFile(\"w\", suffix=\".cpp\") as f:\n        f.write(\"int main (int argc, char **argv) { return 0; }\")\n        try:\n            compiler.compile([f.name], extra_postargs=[flagname])\n        except setuptools.distutils.errors.CompileError:\n            return False\n    return True\n\n\ndef cpp_flag(compiler):\n    \"\"\"Return the -std=c++[11/2a] compiler flag.\n    The c++2a is prefered over c++11 (when it is available).\n    \"\"\"\n    if has_flag(compiler, \"-std=c++2a\"):\n        return \"-std=c++2a\"\n    elif has_flag(compiler, \"-std=c++17\"):\n        return \"-std=c++17\"\n    elif has_flag(compiler, \"-std=c++14\"):\n        return \"-std=c++14\"\n    elif has_flag(compiler, \"-std=c++11\"):\n        return \"-std=c++11\"\n    else:\n        raise RuntimeError(\n            \"Unsupported compiler -- at least C++11 support \" \"is needed!\"\n        )\n\n\nclass BuildExt(build_ext):\n    \"\"\"A custom build extension for adding compiler-specific options.\"\"\"\n\n    def build_extensions(self):\n        # add the _chdb.cpython-37m-darwin.so or _chdb.cpython-39-x86_64-linux.so to the chdb package\n        self.distribution.package_data[\"chdb\"] = [\n            \"chdb/_chdb\" + get_python_ext_suffix()\n        ]\n        # super().build_extensions()\n\n\n# this will be executed by python setup.py bdist_wheel\nif __name__ == \"__main__\":\n    try:\n        # get python extension file name\n        chdb_so = libdir + \"/_chdb\" + get_python_ext_suffix()\n        ext_modules = [\n            Extension(\n                \"_chdb\",\n                sources=[\"programs/local/LocalChdb.cpp\"],\n                language=\"c++\",\n                libraries=[],\n                library_dirs=[libdir],\n                extra_objects=[chdb_so],\n            ),\n        ]\n        # fix the version in chdb/__init__.py\n        versionStr = get_latest_git_tag()\n        fix_version_init(versionStr)\n        # Call the function to update pyproject.toml\n        # update_pyproject_version(versionStr)\n\n        # scan the chdb directory and add all the .py files to the package\n        pkg_files = []\n        for root, dirs, files in os.walk(libdir):\n            for file in files:\n                if file.endswith(\".py\"):\n                    pkg_files.append(os.path.join(root, file))\n        pkg_files.append(chdb_so)\n\n        setup(\n            packages=[\"chdb\"],\n            version=versionStr,\n            package_data={\"chdb\": pkg_files},\n            exclude_package_data={\"\": [\"*.pyc\", \"src/**\"]},\n            ext_modules=ext_modules,\n            python_requires=\">=3.8\",\n            install_requires=[\n                \"pyarrow>=13.0.0\",\n                \"pandas>=2.0.0\",\n            ],\n            cmdclass={\"build_ext\": BuildExt},\n            test_suite=\"tests\",\n            zip_safe=False,\n        )\n    except Exception as e:\n        print(\"Build from setup.py failed. Error: \")\n        print(e)\n        raise\n"
        },
        {
          "name": "src",
          "type": "tree",
          "content": null
        },
        {
          "name": "tests",
          "type": "tree",
          "content": null
        },
        {
          "name": "tox.ini",
          "type": "blob",
          "size": 3.091796875,
          "content": "# Tox configuration file\n# Read more under https://tox.wiki/\n# THIS SCRIPT IS SUPPOSED TO BE AN EXAMPLE. MODIFY IT ACCORDING TO YOUR NEEDS!\n\n[tox]\nminversion = 3.24\nenvlist = py38, py39, py310, py311, py312\nisolated_build = True\n\n[testenv]\ndescription = Build and test the package\nsetenv =\n    TOXINIDIR = {toxinidir}\npassenv =\n    HOME\n    SETUPTOOLS_*\ncommands =\n    {envpython} setup.py test\n\n\n# # To run `tox -e lint` you need to make sure you have a\n# # `.pre-commit-config.yaml` file. See https://pre-commit.com\n# [testenv:lint]\n# description = Perform static analysis and style checks\n# skip_install = True\n# deps = pre-commit\n# passenv =\n#     HOMEPATH\n#     PROGRAMDATA\n#     SETUPTOOLS_*\n# commands =\n#     pre-commit run --all-files {posargs:--show-diff-on-failure}\n\n\n[testenv:{build,clean}]\ndescription =\n    build: Build the package in isolation according to PEP517, see https://github.com/pypa/build\n    clean: Remove old distribution files and temporary build artifacts (./buildlib and ./dist)\n# https://setuptools.pypa.io/en/stable/build_meta.html#how-to-use-it\nskip_install = True\nchangedir = {toxinidir}\nexclude = src/**/*.py, tests/**/*py\ndeps =\n    build: build[virtualenv]\npassenv =\n    SETUPTOOLS_*\ncommands =\n    clean: python -c 'import shutil; [shutil.rmtree(p, True) for p in (\"chdb/build\", \"chdb/__pycache__\", \"dist\", \"docs/_build\", \"chdb.egg-info\")]'\n    clean: python -c 'import pathlib, shutil; [shutil.rmtree(p, True) for p in pathlib.Path(\"chdb\").glob(\"*.egg-info\")]'\n    clean: python -c 'import pathlib, shutil; [shutil.rmtree(p, True) for p in pathlib.Path(\"build\").glob(\"lib.*\")]'\n    clean: python -c 'import pathlib, shutil; [shutil.rmtree(p, True) for p in pathlib.Path(\"build\").glob(\"bdist.*\")]'\n    build: python -m build {posargs}\n# By default, both `sdist` and `wheel` are built. If your sdist is too big or you don't want\n# to make it available, consider running: `tox -e build -- --wheel`\n\n\n[testenv:{docs,doctests,linkcheck}]\ndescription =\n    docs: Invoke sphinx-build to build the docs\n    doctests: Invoke sphinx-build to run doctests\n    linkcheck: Check for broken links in the documentation\npassenv =\n    SETUPTOOLS_*\nsetenv =\n    DOCSDIR = {toxinidir}/docs\n    BUILDDIR = {toxinidir}/docs/_build\n    docs: BUILD = html\n    doctests: BUILD = doctest\n    linkcheck: BUILD = linkcheck\ndeps =\n    -r {toxinidir}/docs/requirements.txt\n    # ^  requirements.txt shared with Read The Docs\ncommands =\n    sphinx-build --color -b {env:BUILD} -d \"{env:BUILDDIR}/doctrees\" \"{env:DOCSDIR}\" \"{env:BUILDDIR}/{env:BUILD}\" {posargs}\n\n\n[testenv:publish]\ndescription =\n    Publish the package you have been developing to a package index server.\n    By default, it uses testpypi. If you really want to publish your package\n    to be publicly accessible in PyPI, use the `-- --repository pypi` option.\nskip_install = True\nchangedir = {toxinidir}\npassenv =\n    # See: https://twine.readthedocs.io/en/latest/\n    TWINE_USERNAME\n    TWINE_PASSWORD\n    TWINE_REPOSITORY\n    TWINE_REPOSITORY_URL\ndeps = twine\ncommands =\n    python -m twine check dist/*\n    python -m twine upload {posargs:--repository {env:TWINE_REPOSITORY:pypi}} dist/*\n"
        },
        {
          "name": "utils",
          "type": "tree",
          "content": null
        }
      ]
    }
  ]
}