{
  "metadata": {
    "timestamp": 1736565579118,
    "page": 454,
    "hasNextPage": true,
    "endCursor": "Y3Vyc29yOjQ2MA==",
    "completionStatus": "IN_PROGRESS"
  },
  "repositories": [
    {
      "nameWithOwner": "rapidfuzz/RapidFuzz",
      "stars": 2819,
      "defaultBranch": "main",
      "files": [
        {
          "name": ".clang-format",
          "type": "blob",
          "size": 0.7451171875,
          "content": "ColumnLimit: 110\nIndentWidth: 4\nAccessModifierOffset: -4\n\nAllowShortIfStatementsOnASingleLine: true\nPointerAlignment: Left\nAllowShortBlocksOnASingleLine: Always\nAllowShortFunctionsOnASingleLine: None\nAllowShortLambdasOnASingleLine: None\nBreakBeforeBraces: Custom\nAlwaysBreakTemplateDeclarations: true\nBraceWrapping:\n  SplitEmptyFunction: false\n  AfterCaseLabel: true\n  AfterClass: false\n  AfterControlStatement: MultiLine\n  AfterEnum: false\n  AfterFunction: true\n  AfterNamespace: false\n  AfterStruct: false\n  AfterUnion: false\n  BeforeCatch: true\n  BeforeElse: true\n  SplitEmptyRecord: false\n  SplitEmptyNamespace: false\nAllowAllConstructorInitializersOnNextLine: true\nConstructorInitializerAllOnOneLineOrOnePerLine: true\nAllowShortCaseLabelsOnASingleLine: true\n"
        },
        {
          "name": ".codespell-ignore-lines",
          "type": "blob",
          "size": 0.021484375,
          "content": "    >>> s2 = \"cetain\"\n"
        },
        {
          "name": ".coveragerc",
          "type": "blob",
          "size": 0.115234375,
          "content": "[run]\nplugins = Cython.Coverage\nsource = src\nomit =\n    src/rapidfuzz/cpp_common.pxd\n\n[precision]\nshow_missing = true\n"
        },
        {
          "name": ".gitattributes",
          "type": "blob",
          "size": 0.1181640625,
          "content": "bench/results/* linguist-vendored\ndocs/img/* linguist-vendored\n*.impl linguist-language=C++\n*.incl linguist-language=C++\n"
        },
        {
          "name": ".github",
          "type": "tree",
          "content": null
        },
        {
          "name": ".gitignore",
          "type": "blob",
          "size": 0.3154296875,
          "content": ".vscode/\n__pycache__/\n.idea/\n.venv/\nbuild/\n_skbuild/\nrapidfuzz.egg-info/\ndist/\n*.data\n*.so\n*.o\n*.out\ntest.py\nsrc/*.html\n.coverage\ncoverage.xml\nsde/\n\n# Sphinx documentation\nsite/\n\n# benchmark results\nbench_results/\n\n# Hypothesis results\n.hypothesis/\n\n# Cython generated files\n*.cxx\n\n# temp files from benchmarks\nbench/temp/\n"
        },
        {
          "name": ".gitmodules",
          "type": "blob",
          "size": 0.21484375,
          "content": "[submodule \"extern/rapidfuzz-cpp\"]\n\tpath = extern/rapidfuzz-cpp\n\turl = https://github.com/rapidfuzz/rapidfuzz-cpp.git\n[submodule \"extern/taskflow\"]\n\tpath = extern/taskflow\n\turl = https://github.com/taskflow/taskflow.git\n"
        },
        {
          "name": ".pre-commit-config.yaml",
          "type": "blob",
          "size": 3.1591796875,
          "content": "# To use:\n#\n#     pre-commit run -a\n#\n# Or:\n#\n#     pre-commit install  # (runs every time you commit in git)\n#\n# To update this file:\n#\n#     pre-commit autoupdate\n#\n# See https://github.com/pre-commit/pre-commit\n\nrepos:\n# Standard hooks\n- repo: https://github.com/pre-commit/pre-commit-hooks\n  rev: \"v4.5.0\"\n  hooks:\n  - id: check-added-large-files\n  - id: check-case-conflict\n  - id: check-docstring-first\n  - id: check-merge-conflict\n  - id: check-symlinks\n  - id: check-toml\n  - id: check-yaml\n  - id: debug-statements\n  - id: end-of-file-fixer\n  - id: mixed-line-ending\n  - id: requirements-txt-fixer\n  - id: trailing-whitespace\n\n# Black, the code formatter, natively supports pre-commit\n- repo: https://github.com/psf/black-pre-commit-mirror\n  rev: \"24.2.0\" # Keep in sync with blacken-docs\n  hooks:\n  - id: black\n\n# Also code format the docs\n- repo: https://github.com/asottile/blacken-docs\n  rev: \"1.16.0\"\n  hooks:\n  - id: blacken-docs\n    additional_dependencies:\n    - black==24.2.0 # keep in sync with black hook\n\n# Changes tabs to spaces\n- repo: https://github.com/Lucas-C/pre-commit-hooks\n  rev: \"v1.5.5\"\n  hooks:\n  - id: remove-tabs\n\n- repo: https://github.com/sirosen/texthooks\n  rev: \"0.6.4\"\n  hooks:\n  - id: fix-ligatures\n  - id: fix-smartquotes\n\n\n# Checking for common mistakes\n- repo: https://github.com/pre-commit/pygrep-hooks\n  rev: \"v1.10.0\"\n  hooks:\n  - id: rst-backticks\n  - id: rst-directive-colons\n  - id: rst-inline-touching-normal\n\n\n# PyLint has native support - not always usable, but works for us\n- repo: https://github.com/PyCQA/pylint\n  rev: \"v3.1.0\"\n  hooks:\n  - id: pylint\n    files: ^pybind11\n\n# CMake formatting\n- repo: https://github.com/cheshirekow/cmake-format-precommit\n  rev: \"v0.6.13\"\n  hooks:\n  - id: cmake-format\n    additional_dependencies: [pyyaml]\n    types: [file]\n    files: (\\.cmake|CMakeLists.txt)(.in)?$\n\n# Check static types with mypy\n#- repo: https://github.com/pre-commit/mirrors-mypy\n#  rev: \"v0.971\"\n#  hooks:\n#  - id: mypy\n#    args: []\n#    exclude: ^(tests|docs)/\n#    additional_dependencies: [nox, rich]\n\n# Checks the manifest for missing files (native support)\n- repo: https://github.com/mgedmin/check-manifest\n  rev: \"0.49\"\n  hooks:\n  - id: check-manifest\n    # This is a slow hook, so only run this if --hook-stage manual is passed\n    stages: [manual]\n    additional_dependencies: [cmake, ninja]\n\n- repo: https://github.com/charliermarsh/ruff-pre-commit\n  rev: v0.3.0\n  hooks:\n  - id: ruff\n    args: [\"--fix\", \"--show-fixes\"]\n\n# Check for spelling\n- repo: https://github.com/codespell-project/codespell\n  rev: \"v2.2.6\"\n  hooks:\n  - id: codespell\n    exclude: \".*/test_.*.py\"\n    args: [\"-x\", \".codespell-ignore-lines\"]\n\n# Check for common shell mistakes\n- repo: https://github.com/shellcheck-py/shellcheck-py\n  rev: \"v0.9.0.6\"\n  hooks:\n  - id: shellcheck\n\n# Disallow some common capitalization mistakes\n- repo: local\n  hooks:\n  - id: disallow-caps\n    name: Disallow improper capitalization\n    language: pygrep\n    entry: PyBind|Numpy|Cmake|CCache|PyTest\n    exclude: ^\\.pre-commit-config.yaml$\n\n# Clang format the codebase automatically\n- repo: https://github.com/pre-commit/mirrors-clang-format\n  rev: \"v17.0.6\"\n  hooks:\n  - id: clang-format\n    types_or: [c++, c]\n"
        },
        {
          "name": "CHANGELOG.rst",
          "type": "blob",
          "size": 32.28125,
          "content": "Changelog\n---------\n\n[3.11.0] - 2024-12-17\n^^^^^^^^^^^^^^^^^^^^^\nPerformance\n~~~~~~~~~~~\n- improve calculation of min score inside partial_ratio so it can skip more alignments\n\nAdded\n~~~~~\n- added build support for emscripten\n\n[3.10.1] - 2024-10-24\n^^^^^^^^^^^^^^^^^^^^^\nFixed\n~~~~~\n- fix compilation on clang-19\n- fix incorrect results in simd optimized implementation of Levenshtein and OSA on 32bit targets\n\nAdded\n~~~~~\n* added support for taskflow 3.8.0\n\n[3.10.0] - 2024-09-21\n^^^^^^^^^^^^^^^^^^^^^\nFixed\n~~~~~\n- drop support for Python 3.8\n- switch build system to `scikit-build-core`\n\n[3.9.7] - 2024-09-02\n^^^^^^^^^^^^^^^^^^^^\nFixed\n~~~~~\n* fix crash in ``cdist`` due to Visual Studio upgrade\n\n[3.9.6] - 2024-08-06\n^^^^^^^^^^^^^^^^^^^^\nChanged\n~~~~~~~\n* upgrade to ``Cython==3.0.11``\n* add python 3.13 wheels\n\n[3.9.5] - 2024-07-29\n^^^^^^^^^^^^^^^^^^^^\nFixed\n~~~~~\n* include simd binaries in pyinstaller builds\n* fix builds with setuptools 72 by upgrading `scikit-build`\n\n[3.9.4] - 2024-07-02\n^^^^^^^^^^^^^^^^^^^^\nFixed\n~~~~~\n* fix bug in ``Levenshtein.editops`` and ``Levenshtein.opcodes`` which could lead\n  to incorrect results and crashes for some inputs\n\n[3.9.3] - 2024-05-31\n^^^^^^^^^^^^^^^^^^^^\nFixed\n~~~~~\n* fix None handling for queries in ``process.cdist`` for scorers not supporting SIMD\n\n[3.9.2] - 2024-05-28\n^^^^^^^^^^^^^^^^^^^^\nFixed\n~~~~~\n* fix supported versions of taskflow in cmake to be in the range v3.3 - v3.7\n\n[3.9.1] - 2024-05-19\n^^^^^^^^^^^^^^^^^^^^\nFixed\n~~~~~\n* disable AVX2 on MacOS since it did lead to illegal instructions being generated\n\n[3.9.0] - 2024-05-02\n^^^^^^^^^^^^^^^^^^^^\nChanged\n~~~~~~~\n* significantly improve type hints for the library\n\nFixed\n~~~~~\n* fix cmake version parsing\n\n[3.8.1] - 2024-04-07\n^^^^^^^^^^^^^^^^^^^^\nFixed\n~~~~~\n* use the correct version of ``rapidfuzz-cpp`` when building against a system installed version\n\n[3.8.0] - 2024-04-06\n^^^^^^^^^^^^^^^^^^^^\nAdded\n~~~~~\n* added ``process.cpdist`` which allows pairwise comparison of two collection of inputs\n\nFixed\n~~~~~\n- fix some minor errors in the type hints\n- fix potentially incorrect results of JaroWinkler when using high prefix weights\n\n[3.7.0] - 2024-03-21\n^^^^^^^^^^^^^^^^^^^^\nChanged\n~~~~~~~\n* reduce importtime\n\n[3.6.2] - 2024-03-05\n^^^^^^^^^^^^^^^^^^^^\n\nChanged\n~~~~~~~\n* upgrade to ``Cython==3.0.9``\n\nFixed\n~~~~~\n* upgrade ``rapidfuzz-cpp`` which includes a fix for build issues on some compilers\n* fix some issues with the sphinx config\n\n[3.6.1] - 2023-12-28\n^^^^^^^^^^^^^^^^^^^^\nFixed\n~~~~~\n* fix overflow error on systems with ``sizeof(size_t) < 8``\n\n[3.6.0] - 2023-12-26\n^^^^^^^^^^^^^^^^^^^^\nFixed\n~~~~~\n* fix pure python fallback implementation of ``fuzz.token_set_ratio``\n* properly link with ``-latomic`` if ``std::atomic<uint64_t>`` is not natively supported\n\nPerformance\n~~~~~~~~~~~\n* add banded implementation of LCS / Indel. This improves the runtime from ``O((|s1|/64) * |s2|)`` to ``O((score_cutoff/64) * |s2|)``\n\nChanged\n~~~~~~~\n* upgrade to ``Cython==3.0.7``\n* cdist for many metrics now returns a matrix of ``uint32`` instead of ``int32`` by default\n\n[3.5.2] - 2023-11-02\n^^^^^^^^^^^^^^^^^^^^\nFixed\n~~~~~\n* use _mm_malloc/_mm_free on macOS if aligned_alloc is unsupported\n\n[3.5.1] - 2023-10-31\n^^^^^^^^^^^^^^^^^^^^\nFixed\n~~~~~\n* fix compilation failure on macOS\n\n[3.5.0] - 2023-10-31\n^^^^^^^^^^^^^^^^^^^^\nChanged\n~~~~~~~\n* skip pandas ``pd.NA`` similar to ``None``\n* add ``score_multiplier`` argument to ``process.cdist`` which allows multiplying the end result scores\n  with a constant factor.\n* drop support for Python 3.7\n\nPerformance\n~~~~~~~~~~~\n* improve performance of simd implementation for ``LCS`` / ``Indel`` / ``Jaro`` / ``JaroWinkler``\n* improve performance of Jaro and Jaro Winkler for long sequences\n* implement ``process.extract`` with ``limit=1`` using ``process.extractOne`` which can be faster\n\nFixed\n~~~~~\n* the preprocessing function was always called through Python due to a broken C-API version check\n* fix wraparound issue in simd implementation of Jaro and Jaro Winkler\n\n[3.4.0] - 2023-10-09\n^^^^^^^^^^^^^^^^^^^^\nChanged\n~~~~~~~\n* upgrade to ``Cython==3.0.3``\n* add simd implementation for Jaro and Jaro Winkler\n\n[3.3.1] - 2023-09-25\n^^^^^^^^^^^^^^^^^^^^\nAdded\n~~~~~\n* add missing tag for python 3.12 support\n\n[3.3.0] - 2023-09-11\n^^^^^^^^^^^^^^^^^^^^\nChanged\n~~~~~~~\n* upgrade to ``Cython==3.0.2``\n* implement the remaining missing features from the C++ implementation in the pure Python implementation\n\nAdded\n~~~~~\n* added support for Python 3.12\n\n[3.2.0] - 2023-08-02\n^^^^^^^^^^^^^^^^^^^^\nChanged\n~~~~~~~\n* build x86 with sse2/avx2 runtime detection\n\n[3.1.2] - 2023-07-19\n^^^^^^^^^^^^^^^^^^^^\nChanged\n~~~~~~~\n* upgrade to ``Cython==3.0.0``\n\n[3.1.1] - 2023-06-06\n^^^^^^^^^^^^^^^^^^^^\nChanged\n~~~~~~~\n* upgrade to ``taskflow==3.6``\n\nFixed\n~~~~~\n* replace usage of ``isnan`` with ``std::isnan`` which fixes the build on NetBSD\n\n[3.1.0] - 2023-06-02\n^^^^^^^^^^^^^^^^^^^^\nChanged\n~~~~~~~\n* added keyword argument ``pad`` to Hamming distance. This controls whether sequences of different\n  length should be padded or lead to a ``ValueError``\n* improve consistency of exception messages between the C++ and pure Python implementation\n* upgrade required Cython version to ``Cython==3.0.0b3``\n\nFixed\n~~~~~\n* fix missing GIL restore when an exception is thrown inside ``process.cdist``\n* fix incorrect type hints for the ``process`` module\n\n[3.0.0] - 2023-04-16\n^^^^^^^^^^^^^^^^^^^^\nChanged\n~~~~~~~\n* allow the usage of ``Hamming`` for different string lengths. Length differences are handled as\n  insertions / deletions\n* remove support for boolean preprocessor functions in ``rapidfuzz.fuzz`` and ``rapidfuzz.process``.\n  The processor argument is now always a callable or ``None``.\n* update defaults of the processor argument to be ``None`` everywhere. For affected functions this can change results, since strings are no longer preprocessed.\n  To get back the old behaviour pass ``processor=utils.default_process`` to these functions.\n  The following functions are affected by this:\n\n  * ``process.extract``, ``process.extract_iter``, ``process.extractOne``\n  * ``fuzz.token_sort_ratio``, ``fuzz.token_set_ratio``, ``fuzz.token_ratio``, ``fuzz.partial_token_sort_ratio``, ``fuzz.partial_token_set_ratio``, ``fuzz.partial_token_ratio``, ``fuzz.WRatio``, ``fuzz.QRatio``\n\n* ``rapidfuzz.process`` no longer calls scorers with ``processor=None``. For this reason user provided scorers no longer require this argument.\n* remove option to pass keyword arguments to scorer via ``**kwargs`` in ``rapidfuzz.process``. They can be passed\n  via a ``scorer_kwargs`` argument now. This ensures this does not break when extending function parameters and\n  prevents naming clashes.\n* remove ``rapidfuzz.string_metric`` module. Replacements for all functions are available in ``rapidfuzz.distance``\n\nAdded\n~~~~~\n* added support for arbitrary hashable sequence in the pure Python fallback implementation of all functions in ``rapidfuzz.distance``\n* added support for ``None`` and ``float(\"nan\")`` in ``process.cdist`` as long as the underlying scorer supports it.\n  This is the case for all scorers returning normalized results.\n\nFixed\n~~~~~\n* fix division by zero in simd implementation of normalized metrics leading to incorrect results\n\n[2.15.1] - 2023-04-11\n^^^^^^^^^^^^^^^^^^^^^\nFixed\n~~~~~\n* fix incorrect tag dispatching implementation leading to AVX2 instructions in the SSE2 code path\n\nAdded\n~~~~~\n* add wheels for windows arm64\n\n[2.15.0] - 2023-04-01\n^^^^^^^^^^^^^^^^^^^^^\nChanged\n~~~~~~~\n* allow the usage of finite generators as choices in ``process.extract``\n\n[2.14.0] - 2023-03-31\n^^^^^^^^^^^^^^^^^^^^^\nChanged\n~~~~~~~\n* upgrade required Cython version to ``Cython==3.0.0b2``\n\nFixed\n~~~~~\n* fix handling of non symmetric scorers in pure python version of ``process.cdist``\n* fix default dtype handling when using ``process.cdist`` with pure python scorers\n\n[2.13.7] - 2022-12-20\n^^^^^^^^^^^^^^^^^^^^^\nFixed\n~~~~~~~\n* fix function signature of ``get_requires_for_build_wheel``\n\n[2.13.6] - 2022-12-11\n^^^^^^^^^^^^^^^^^^^^^\nChanged\n~~~~~~~\n* reformat changelog as restructured text to get rig of ``m2r2`` dependency\n\n\n[2.13.5] - 2022-12-11\n^^^^^^^^^^^^^^^^^^^^^\nAdded\n~~~~~\n* added docs to sdist\n\nFixed\n~~~~~\n* fix two cases of undefined behavior in ``process.cdist``\n\n[2.13.4] - 2022-12-08\n^^^^^^^^^^^^^^^^^^^^^\nChanged\n~~~~~~~\n* handle ``float(\"nan\")`` similar to ``None`` for query / choice, since this is common for\n  non-existent data in tools like numpy\n\nFixed\n~~~~~\n* fix handling on ``None``\\ /\\ ``float(\"nan\")`` in ``process.distance``\n* use absolute imports inside tests\n\n[2.13.3] - 2022-12-03\n^^^^^^^^^^^^^^^^^^^^^\nFixed\n~~~~~\n* improve handling of functions wrapped using ``functools.wraps``\n* fix broken fallback to Python implementation when the a ``ImportError`` occurs on import.\n  This can e.g. occur when the binary has a dependency on libatomic, but it is unavailable on\n  the system\n* define ``CMAKE_C_COMPILER_AR``\\ /\\ ``CMAKE_CXX_COMPILER_AR``\\ /\\ ``CMAKE_C_COMPILER_RANLIB``\\ /\\ ``CMAKE_CXX_COMPILER_RANLIB``\n  if they are not defined yet\n\n[2.13.2] - 2022-11-05\n^^^^^^^^^^^^^^^^^^^^^\nFixed\n~~~~~\n* fix incorrect results in ``Hamming.normalized_similarity``\n* fix incorrect score_cutoff handling in pure python implementation of\n  ``Postfix.normalized_distance`` and ``Prefix.normalized_distance``\n* fix ``Levenshtein.normalized_similarity`` and ``Levenshtein.normalized_distance``\n  when used in combination with the process module\n* ``fuzz.partial_ratio`` was not always symmetric when ``len(s1) == len(s2)``\n\n[2.13.1] - 2022-11-02\n^^^^^^^^^^^^^^^^^^^^^\nFixed\n~~~~~\n* fix bug in ``normalized_similarity`` of most scorers,\n  leading to incorrect results when used in combination with the process module\n* fix sse2 support\n* fix bug in ``JaroWinkler`` and ``Jaro`` when used in the pure python process module\n* forward kwargs in pure Python implementation of ``process.extract``\n\n[2.13.0] - 2022-10-30\n^^^^^^^^^^^^^^^^^^^^^\nFixed\n~~~~~\n* fix bug in ``Levenshtein.editops`` leading to crashes when used with ``score_hint``\n\nChanged\n~~~~~~~\n* moved capi from ``rapidfuzz_capi`` into ``rapidfuzz``\\ , since it will always\n  succeed the installation now that there is a pure Python mode\n* add ``score_hint`` argument to process module\n* add ``score_hint`` argument to Levenshtein module\n\n[2.12.0] - 2022-10-24\n^^^^^^^^^^^^^^^^^^^^^\nChanged\n~~~~~~~\n* drop support for Python 3.6\n\nAdded\n~~~~~\n* added ``Prefix``\\ /\\ ``Suffix`` similarity\n\nFixed\n~~~~~\n* fixed packaging with pyinstaller\n\n[2.11.1] - 2022-10-05\n^^^^^^^^^^^^^^^^^^^^^\nFixed\n~~~~~\n* Fix segmentation fault in ``process.cdist`` when used with an empty query sequence\n\n[2.11.0] - 2022-10-02\n^^^^^^^^^^^^^^^^^^^^^\nChanges\n~~~~~~~\n* move jarowinkler dependency into rapidfuzz to simplify maintenance\n\nPerformance\n~~~~~~~~~~~\n* add SIMD implementation for ``fuzz.ratio``\\ /\\ ``fuzz.QRatio``\\ /\\ ``Levenshtein``\\ /\\ ``Indel``\\ /\\ ``LCSseq``\\ /\\ ``OSA`` to improve\n  performance for short strings in cdist\n\n[2.10.3] - 2022-09-30\n^^^^^^^^^^^^^^^^^^^^^\nFixed\n~~~~~\n* use ``scikit-build=0.14.1`` on Linux, since ``scikit-build=0.15.0`` fails to find the Python Interpreter\n* workaround gcc in bug in template type deduction\n\n[2.10.2] - 2022-09-27\n^^^^^^^^^^^^^^^^^^^^^\nFixed\n~~~~~\n* fix support for cmake versions below 3.17\n\n[2.10.1] - 2022-09-25\n^^^^^^^^^^^^^^^^^^^^^\nChanged\n~~~~~~~\n* modernize cmake build to fix most conda-forge builds\n\n[2.10.0] - 2022-09-18\n^^^^^^^^^^^^^^^^^^^^^\nAdded\n~~~~~\n* add editops to hamming distance\n\nPerformance\n~~~~~~~~~~~\n* strip common affix in osa distance\n\nFixed\n~~~~~\n* ignore missing pandas in Python 3.11 tests\n\n[2.9.0] - 2022-09-16\n^^^^^^^^^^^^^^^^^^^^\nAdded\n~~~~~\n* add optimal string alignment (OSA)\n\n[2.8.0] - 2022-09-11\n^^^^^^^^^^^^^^^^^^^^\nFixed\n~~~~~\n* ``fuzz.partial_ratio`` did not find the optimal alignment in some edge cases (#219)\n\nPerformance\n~~~~~~~~~~~\n* improve performance of ``fuzz.partial_ratio``\n\nChanged\n~~~~~~~\n* increased minimum C++ version to C++17 (see #255)\n\n[2.7.0] - 2022-09-11\n^^^^^^^^^^^^^^^^^^^^\nPerformance\n~~~~~~~~~~~\n* improve performance of ``Levenshtein.distance``\\ /\\ ``Levenshtein.editops`` for\n  long sequences.\n\nAdded\n~~~~~\n* add ``score_hint`` parameter to ``Levenshtein.editops`` which allows the use of a\n  faster implementation\n\nChanged\n~~~~~~~\n* all functions in the ``string_metric`` module do now raise a deprecation warning.\n  They are now only wrappers for their replacement functions, which makes them slower\n  when used with the process module\n\n[2.6.1] - 2022-09-03\n^^^^^^^^^^^^^^^^^^^^\nFixed\n~~~~~\n* fix incorrect results of partial_ratio for long needles (#257)\n\n[2.6.0] - 2022-08-20\n^^^^^^^^^^^^^^^^^^^^\nFixed\n~~~~~\n* fix hashing for custom classes\n\nAdded\n~~~~~\n* add support for slicing in ``Editops.__getitem__``\\ /\\ ``Editops.__delitem__``\n* add ``DamerauLevenshtein`` module\n\n[2.5.0] - 2022-08-14\n^^^^^^^^^^^^^^^^^^^^\nAdded\n~~~~~\n* added support for KeyboardInterrupt in processor module\n  It might still take a bit until the KeyboardInterrupt is registered, but\n  no longer runs all text comparisons after pressing ``Ctrl + C``\n\nFixed\n~~~~~\n* fix default scorer used by cdist to use C++ implementation if possible\n\n[2.4.4] - 2022-08-12\n^^^^^^^^^^^^^^^^^^^^\nChanged\n~~~~~~~\n* Added support for Python 3.11\n\n[2.4.3] - 2022-08-08\n^^^^^^^^^^^^^^^^^^^^\nFixed\n~~~~~\n* fix value range of ``jaro_similarity``\\ /\\ ``jaro_winkler_similarity`` in the pure Python mode\n  for the string_metric module\n* fix missing atomix symbol on arm 32 bit\n\n[2.4.2] - 2022-07-30\n^^^^^^^^^^^^^^^^^^^^\nFixed\n~~~~~\n* add missing symbol to pure Python which made the usage impossible\n\n[2.4.1] - 2022-07-29\n^^^^^^^^^^^^^^^^^^^^\nFixed\n~~~~~\n* fix version number\n\n[2.4.0] - 2022-07-29\n^^^^^^^^^^^^^^^^^^^^\nFixed\n~~~~~\n* fix banded Levenshtein implementation\n\nPerformance\n~~~~~~~~~~~\n* improve performance and memory usage of ``Levenshtein.editops``\n\n  * memory usage is reduced from O(NM) to O(N)\n  * performance is improved for long sequences\n\n[2.3.0] - 2022-07-23\n^^^^^^^^^^^^^^^^^^^^\nAdded\n~~~~~\n* add ``as_matching_blocks`` to ``Editops``\\ /\\ ``Opcodes``\n* add support for deletions from ``Editops``\n* add ``Editops.apply``\\ /\\ ``Opcodes.apply``\n* add ``Editops.remove_subsequence``\n\nChanged\n~~~~~~~\n* merge adjacent similar blocks in ``Opcodes``\n\nFixed\n~~~~~\n* fix usage of ``eval(repr(Editop))``\\ , ``eval(repr(Editops))``\\ , ``eval(repr(Opcode))`` and ``eval(repr(Opcodes))``\n* fix opcode conversion for empty source sequence\n* fix validation for empty Opcode list passed into ``Opcodes.__init__``\n\n[2.2.0] - 2022-07-19\n^^^^^^^^^^^^^^^^^^^^\nChanged\n~~~~~~~\n* added in-tree build backend to install cmake and ninja only when it is not installed yet\n  and only when wheels are available\n\n[2.1.4] - 2022-07-17\n^^^^^^^^^^^^^^^^^^^^\nChanged\n~~~~~~~\n* changed internal implementation of cdist to remove build dependency to numpy\n\nAdded\n~~~~~\n* added wheels for musllinux and manylinux ppc64le, s390x\n\n[2.1.3] - 2022-07-09\n^^^^^^^^^^^^^^^^^^^^\nFixed\n~~~~~\n* fix missing type stubs\n\n[2.1.2] - 2022-07-04\n^^^^^^^^^^^^^^^^^^^^\nChanged\n~~~~~~~\n* change src layout to make package import from root directory possible\n\n[2.1.1] - 2022-06-30\n^^^^^^^^^^^^^^^^^^^^\nChanged\n~~~~~~~\n* allow installation without the C++ extension if it fails to compile\n* allow selection of implementation via the environment variable ``RAPIDFUZZ_IMPLEMENTATION``\n  which can be set to \"cpp\" or \"python\"\n\n[2.1.0] - 2022-06-29\n^^^^^^^^^^^^^^^^^^^^\nAdded\n~~~~~\n* added pure python fallback for all implementations with the following exceptions:\n\n  * no support for sequences of hashables. Only strings supported so far\n  * ``\\*.editops`` / ``\\*.opcodes`` functions not implemented yet\n  * process.cdist does not support multithreading\n\nFixed\n~~~~~\n* fuzz.partial_ratio_alignment ignored the score_cutoff\n* fix implementation of Hamming.normalized_similarity\n* fix default score_cutoff of Hamming.similarity\n* fix implementation of LCSseq.distance when used in the process module\n* treat hash for -1 and -2 as different\n\n[2.0.15] - 2022-06-24\n^^^^^^^^^^^^^^^^^^^^^\nFixed\n~~~~~\n* fix integer wraparound in partial_ratio/partial_ratio_alignment\n\n[2.0.14] - 2022-06-23\n^^^^^^^^^^^^^^^^^^^^^\nFixed\n~~~~~\n* fix unlimited recursion in LCSseq when used in combination with the process module\n\nChanged\n~~~~~~~\n* add fallback implementations of ``taskflow``\\ , ``rapidfuzz-cpp`` and ``jarowinkler-cpp``\n  back to wheel, since some package building systems like piwheels can't clone sources\n\n[2.0.13] - 2022-06-22\n^^^^^^^^^^^^^^^^^^^^^\nChanged\n~~~~~~~\n* use system version of cmake on arm platforms, since the cmake package fails to compile\n\n[2.0.12] - 2022-06-22\n^^^^^^^^^^^^^^^^^^^^^\nChanged\n~~~~~~~\n* add tests to sdist\n* remove cython dependency for sdist\n\n[2.0.11] - 2022-04-23\n^^^^^^^^^^^^^^^^^^^^^\nChanged\n~~~~~~~\n* relax version requirements of dependencies to simplify packaging\n\n[2.0.10] - 2022-04-17\n^^^^^^^^^^^^^^^^^^^^^\nFixed\n~~~~~\n* Do not include installations of jaro_winkler in wheels (regression from 2.0.7)\n\nChanged\n~~~~~~~\n* Allow installation from system installed versions of ``rapidfuzz-cpp``\\ , ``jarowinkler-cpp``\n  and ``taskflow``\n\nAdded\n~~~~~\n* Added PyPy3.9 wheels on Linux\n\n[2.0.9] - 2022-04-07\n^^^^^^^^^^^^^^^^^^^^\nFixed\n~~~~~\n* Add missing Cython code in sdist\n* consider float imprecision in score_cutoff (see #210)\n\n[2.0.8] - 2022-04-07\n^^^^^^^^^^^^^^^^^^^^\nFixed\n~~~~~\n* fix incorrect score_cutoff handling in token_set_ratio and token_ratio\n\nAdded\n~~~~~\n* add longest common subsequence\n\n[2.0.7] - 2022-03-13\n^^^^^^^^^^^^^^^^^^^^\nFixed\n~~~~~\n* Do not include installations of jaro_winkler and taskflow in wheels\n\n[2.0.6] - 2022-03-06\n^^^^^^^^^^^^^^^^^^^^\nFixed\n~~~~~\n* fix incorrect population of sys.modules which lead to submodules overshadowing\n  other imports\n\nChanged\n~~~~~~~\n* moved JaroWinkler and Jaro into a separate package\n\n[2.0.5] - 2022-02-25\n^^^^^^^^^^^^^^^^^^^^\nFixed\n~~~~~\n* fix signed integer overflow inside hashmap implementation\n\n[2.0.4] - 2022-02-21\n^^^^^^^^^^^^^^^^^^^^\nFixed\n~~~~~\n* fix binary size increase due to debug symbols\n* fix segmentation fault in ``Levenshtein.editops``\n\n[2.0.3] - 2022-02-18\n^^^^^^^^^^^^^^^^^^^^\nAdded\n~~~~~\n* Added fuzz.partial_ratio_alignment, which returns the result of fuzz.partial_ratio\n  combined with the alignment this result stems from\n\nFixed\n~~~~~\n* Fix Indel distance returning incorrect result when using score_cutoff=1, when the strings\n  are not equal. This affected other scorers like fuzz.WRatio, which use the Indel distance\n  as well.\n\n[2.0.2] - 2022-02-12\n^^^^^^^^^^^^^^^^^^^^\nFixed\n~~~~~\n* fix type hints\n* Add back transpiled cython files to the sdist to simplify builds in package builders\n  like FreeBSD port build or conda-forge\n\n[2.0.1] - 2022-02-11\n^^^^^^^^^^^^^^^^^^^^\nFixed\n~~~~~\n* fix type hints\n* Indel.normalized_similarity mistakenly used the implementation of Indel.normalized_distance\n\n[2.0.0] - 2022-02-09\n^^^^^^^^^^^^^^^^^^^^\nAdded\n~~~~~\n* added C-Api which can be used to extend RapidFuzz from different Python modules using any\n  programming language which allows the usage of C-Apis (C/C++/Rust)\n* added new scorers in ``rapidfuzz.distance.*``\n\n  * port existing distances to this new api\n  * add Indel distance along with the corresponding editops function\n\nChanged\n~~~~~~~\n* when the result of ``string_metric.levenshtein`` or ``string_metric.hamming`` is below max\n  they do now return ``max + 1`` instead of -1\n* Build system moved from setuptools to scikit-build\n* Stop including all modules in __init__.py, since they significantly slowed down import time\n\nRemoved\n~~~~~~~\n* remove the ``rapidfuzz.levenshtein`` module which was deprecated in v1.0.0 and scheduled for removal in v2.0.0\n* dropped support for Python2.7 and Python3.5\n\nDeprecated\n~~~~~~~~~~\n* deprecate support to specify processor in form of a boolean (will be removed in v3.0.0)\n\n  * new functions will not get support for this in the first place\n\n* deprecate ``rapidfuzz.string_metric`` (will be removed in v3.0.0). Similar scorers are available\n  in ``rapidfuzz.distance.*``\n\nFixed\n~~~~~\n* process.cdist did raise an exception when used with a pure python scorer\n\nPerformance\n~~~~~~~~~~~\n* improve performance and memory usage of ``rapidfuzz.string_metric.levenshtein_editops``\n\n  * memory usage is reduced by 33%\n  * performance is improved by around 10%-20%\n\n* significantly improve performance of  ``rapidfuzz.string_metric.levenshtein`` for ``max <= 31``\n  using a banded implementation\n\n[1.9.1] - 2021-12-13\n^^^^^^^^^^^^^^^^^^^^\nFixed\n~~~~~\n* fix bug in new editops implementation, causing it to SegFault on some inputs (see qurator-spk/dinglehopper#64)\n\n[1.9.0] - 2021-12-11\n^^^^^^^^^^^^^^^^^^^^\nFixed\n~~~~~\n* Fix some issues in the type annotations (see #163)\n\nPerformance\n~~~~~~~~~~~\n* improve performance and memory usage of ``rapidfuzz.string_metric.levenshtein_editops``\n\n  * memory usage is reduced by 10x\n  * performance is improved from ``O(N * M)`` to ``O([N / 64] * M)``\n\n[1.8.3] - 2021-11-19\n^^^^^^^^^^^^^^^^^^^^\nAdded\n~~~~~\n* Added missing wheels for Python3.6 on MacOs and Windows (see #159)\n\n[1.8.2] - 2021-10-27\n^^^^^^^^^^^^^^^^^^^^\nAdded\n~~~~~\n* Add wheels for Python 3.10 on MacOs\n\n[1.8.1] - 2021-10-22\n^^^^^^^^^^^^^^^^^^^^\nFixed\n~~~~~\n* Fix incorrect editops results (See #148)\n\n[1.8.0] - 2021-10-20\n^^^^^^^^^^^^^^^^^^^^\nChanged\n~~~~~~~\n* Add Wheels for Python3.10 on all platforms except MacOs (see #141)\n* Improve performance of ``string_metric.jaro_similarity`` and  ``string_metric.jaro_winkler_similarity`` for strings with a length <= 64\n\n[1.7.1] - 2021-10-02\n^^^^^^^^^^^^^^^^^^^^\nFixed\n~~~~~\n* fixed incorrect results of fuzz.partial_ratio for long needles (see #138)\n\n[1.7.0] - 2021-09-27\n^^^^^^^^^^^^^^^^^^^^\nChanged\n~~~~~~~\n* Added typing for process.cdist\n* Added multithreading support to cdist using the argument ``process.cdist``\n* Add dtype argument to ``process.cdist`` to set the dtype of the result numpy array (see #132)\n* Use a better hash collision strategy in the internal hashmap, which improves the worst case performance\n\n[1.6.2] - 2021-09-15\n^^^^^^^^^^^^^^^^^^^^\nChanged\n~~~~~~~\n* improved performance of fuzz.ratio\n* only import process.cdist when numpy is available\n\n[1.6.1] - 2021-09-11\n^^^^^^^^^^^^^^^^^^^^\nChanged\n~~~~~~~\n* Add back wheels for Python2.7\n\n[1.6.0] - 2021-09-10\n^^^^^^^^^^^^^^^^^^^^\nChanged\n~~~~~~~\n* fuzz.partial_ratio uses a new implementation for short needles (<= 64). This implementation is\n\n  * more accurate than the current implementation (it is guaranteed to find the optimal alignment)\n  * it is significantly faster\n\n* Add process.cdist to compare all elements of two lists (see #51)\n\n[1.5.1] - 2021-09-01\n^^^^^^^^^^^^^^^^^^^^\nFixed\n~~~~~\n* Fix out of bounds access in levenshtein_editops\n\n[1.5.0] - 2021-08-21\n^^^^^^^^^^^^^^^^^^^^\nChanged\n~~~~~~~\n* all scorers do now support similarity/distance calculations between any sequence of hashables. So it is possible to calculate e.g. the WER as:\n  .. code-block::\n\n     >>> string_metric.levenshtein([\"word1\", \"word2\"], [\"word1\", \"word3\"])\n     1\n\nAdded\n~~~~~\n* Added type stub files for all functions\n* added jaro similarity in ``string_metric.jaro_similarity``\n* added jaro winkler similarity in ``string_metric.jaro_winkler_similarity``\n* added Levenshtein editops in ``string_metric.levenshtein_editops``\n\nFixed\n~~~~~\n* Fixed support for set objects in ``process.extract``\n* Fixed inconsistent handling of empty strings\n\n[1.4.1] - 2021-03-30\n^^^^^^^^^^^^^^^^^^^^\nPerformance\n~~~~~~~~~~~\n* improved performance of result creation in process.extract\n\nFixed\n~~~~~\n* Cython ABI stability issue (#95)\n* fix missing decref in case of exceptions in process.extract\n\n[1.4.0] - 2021-03-29\n^^^^^^^^^^^^^^^^^^^^\nChanged\n~~~~~~~\n* added processor support to ``levenshtein`` and ``hamming``\n* added distance support to extract/extractOne/extract_iter\n\nFixed\n~~~~~\n* incorrect results of ``normalized_hamming`` and ``normalized_levenshtein`` when used with ``utils.default_process`` as processor\n\n[1.3.3] - 2021-03-20\n^^^^^^^^^^^^^^^^^^^^\nFixed\n~~~~~\n* Fix a bug in the mbleven implementation of the uniform Levenshtein distance and cover it with fuzz tests\n\n[1.3.2] - 2021-03-20\n^^^^^^^^^^^^^^^^^^^^\nFixed\n~~~~~\n* some of the newly activated warnings caused build failures in the conda-forge build\n\n[1.3.1] - 2021-03-20\n^^^^^^^^^^^^^^^^^^^^\nFixed\n~~~~~\n* Fixed issue in LCS calculation for partial_ratio (see #90)\n* Fixed incorrect results for normalized_hamming and normalized_levenshtein when the processor ``utils.default_process`` is used\n* Fix many compiler warnings\n\n[1.3.0] - 2021-03-16\n^^^^^^^^^^^^^^^^^^^^\nChanged\n~~~~~~~\n* add wheels for a lot of new platforms\n* drop support for Python 2.7\n\nPerformance\n~~~~~~~~~~~\n* use ``is`` instead of ``==`` to compare functions directly by address\n\nFixed\n~~~~~\n* Fix another ref counting issue\n* Fix some issues in the Levenshtein distance algorithm (see #92)\n\n[1.2.1] - 2021-03-08\n^^^^^^^^^^^^^^^^^^^^\nPerformance\n~~~~~~~~~~~\n* further improve bitparallel implementation of uniform Levenshtein distance for strings with a length > 64 (in many cases more than 50% faster)\n\n[1.2.0] - 2021-03-07\n^^^^^^^^^^^^^^^^^^^^\nChanged\n~~~~~~~\n* add more benchmarks to documentation\n\nPerformance\n~~~~~~~~~~~\n* add bitparallel implementation to InDel Distance (Levenshtein with the weights 1,1,2) for strings with a length > 64\n* improve bitparallel implementation of uniform Levenshtein distance for strings with a length > 64\n* use the InDel Distance and uniform Levenshtein distance in more cases instead of the generic implementation\n* Directly use the Levenshtein implementation in C++ instead of using it through Python in process.*\n\n[1.1.2] - 2021-03-03\n^^^^^^^^^^^^^^^^^^^^\nFixed\n~~~~~\n* Fix reference counting in process.extract (see #81)\n\n[1.1.1] - 2021-02-23\n^^^^^^^^^^^^^^^^^^^^\nFixed\n~~~~~\n* Fix result conversion in process.extract (see #79)\n\n[1.1.0] - 2021-02-21\n^^^^^^^^^^^^^^^^^^^^\nChanged\n~~~~~~~\n* string_metric.normalized_levenshtein supports now all weights\n* when different weights are used for Insertion and Deletion the strings are not swapped inside the Levenshtein implementation anymore. So different weights for Insertion and Deletion are now supported.\n* replace C++ implementation with a Cython implementation. This has the following advantages:\n\n  * The implementation is less error prone, since a lot of the complex things are done by Cython\n  * slightly faster than the current implementation (up to 10% for some parts)\n  * about 33% smaller binary size\n  * reduced compile time\n\n* Added \\*\\*kwargs argument to process.extract/extractOne/extract_iter that is passed to the scorer\n* Add max argument to hamming distance\n* Add support for whole Unicode range to utils.default_process\n\nPerformance\n~~~~~~~~~~~\n* replaced Wagner Fischer usage in the normal Levenshtein distance with a bitparallel implementation\n\n[1.0.2] - 2021-02-19\n^^^^^^^^^^^^^^^^^^^^\nFixed\n~~~~~\n* The bitparallel LCS algorithm in fuzz.partial_ratio did not find the longest common substring properly in some cases.\n  The old algorithm is used again until this bug is fixed.\n\n[1.0.1] - 2021-02-17\n^^^^^^^^^^^^^^^^^^^^\nChanged\n~~~~~~~\n* string_metric.normalized_levenshtein supports now the weights (1, 1, N) with N >= 1\n\nPerformance\n~~~~~~~~~~~\n* The Levenshtein distance with the weights (1, 1, >2) do now use the same implementation as the weight (1, 1, 2), since\n  ``Substitution > Insertion + Deletion`` has no effect\n\nFixed\n~~~~~\n* fix uninitialized variable in bitparallel Levenshtein distance with the weight (1, 1, 1)\n\n[1.0.0] - 2021-02-12\n^^^^^^^^^^^^^^^^^^^^\nChanged\n~~~~~~~\n* all normalized string_metrics can now be used as scorer for process.extract/extractOne\n* Implementation of the C++ Wrapper completely refactored to make it easier to add more scorers, processors and string matching algorithms in the future.\n* increased test coverage, that already helped to fix some bugs and help to prevent regressions in the future\n* improved docstrings of functions\n\nPerformance\n~~~~~~~~~~~\n* Added bit-parallel implementation of the Levenshtein distance for the weights (1,1,1) and (1,1,2).\n* Added specialized implementation of the Levenshtein distance for cases with a small maximum edit distance, that is even faster, than the bit-parallel implementation.\n* Improved performance of ``fuzz.partial_ratio``\n  -> Since ``fuzz.ratio`` and ``fuzz.partial_ratio`` are used in most scorers, this improves the overall performance.\n* Improved performance of ``process.extract`` and ``process.extractOne``\n\nDeprecated\n~~~~~~~~~~\n* the ``rapidfuzz.levenshtein`` module is now deprecated and will be removed in v2.0.0\n  These functions are now placed in ``rapidfuzz.string_metric``. ``distance``\\ , ``normalized_distance``\\ , ``weighted_distance`` and ``weighted_normalized_distance`` are combined into ``levenshtein`` and ``normalized_levenshtein``.\n\nAdded\n~~~~~\n* added normalized version of the hamming distance in ``string_metric.normalized_hamming``\n* process.extract_iter as a generator, that yields the similarity of all elements, that have a similarity >= score_cutoff\n\nFixed\n~~~~~\n* multiple bugs in extractOne when used with a scorer, that's not from RapidFuzz\n* fixed bug in ``token_ratio``\n* fixed bug in result normalization causing zero division\n\n[0.14.2] - 2020-12-31\n^^^^^^^^^^^^^^^^^^^^^\nFixed\n~~~~~\n* utf8 usage in the copyright header caused problems with python2.7 on some platforms (see #70)\n\n[0.14.1] - 2020-12-13\n^^^^^^^^^^^^^^^^^^^^^\nFixed\n~~~~~\n* when a custom processor like ``lambda s: s`` was used with any of the methods inside fuzz.* it always returned a score of 100. This release fixes this and adds a better test coverage to prevent this bug in the future.\n\n[0.14.0] - 2020-12-09\n^^^^^^^^^^^^^^^^^^^^^\nAdded\n~~~~~\n* added hamming distance metric in the levenshtein module\n\nPerformance\n~~~~~~~~~~~\n* improved performance of default_process by using lookup table\n\n[0.13.4] - 2020-11-30\n^^^^^^^^^^^^^^^^^^^^^\nFixed\n~~~~~\n* Add missing virtual destructor that caused a segmentation fault on Mac Os\n\n[0.13.3] - 2020-11-21\n^^^^^^^^^^^^^^^^^^^^^\nAdded\n~~~~~\n* C++11 Support\n* manylinux wheels\n\n[0.13.2] - 2020-11-21\n^^^^^^^^^^^^^^^^^^^^^\nFixed\n~~~~~\n* Levenshtein was not imported from __init__\n* The reference count of a Python Object inside process.extractOne was decremented to early\n\n[0.13.1] - 2020-11-17\n^^^^^^^^^^^^^^^^^^^^^\nPerformance\n~~~~~~~~~~~\n* process.extractOne  exits early when a score of 100 is found. This way the other strings do not have to be preprocessed anymore.\n\n[0.13.0] - 2020-11-16\n^^^^^^^^^^^^^^^^^^^^^\nFixed\n~~~~~\n* string objects passed to scorers had to be strings even before preprocessing them. This was changed, so they only have to be strings after preprocessing similar to process.extract/process.extractOne\n\nPerformance\n~~~~~~~~~~~\n* process.extractOne is now implemented in C++ making it a lot faster\n* When token_sort_ratio or partial_token_sort ratio is used inprocess.extractOne the words in the query are only sorted once to improve the runtime\n\nChanged\n~~~~~~~\n* process.extractOne/process.extract do now return the index of the match, when the choices are a list.\n\nRemoved\n~~~~~~~\n* process.extractIndices got removed, since the indices are now already returned by process.extractOne/process.extract\n\n[0.12.5] - 2020-10-26\n^^^^^^^^^^^^^^^^^^^^^\nFixed\n~~~~~\n* fix documentation of process.extractOne (see #48)\n\n[0.12.4] - 2020-10-22\n^^^^^^^^^^^^^^^^^^^^^\nAdded\n~~~~~\n* Added wheels for\n\n  * CPython 2.7 on windows 64 bit\n  * CPython 2.7 on windows 32 bit\n  * PyPy 2.7 on windows 32 bit\n\n[0.12.3] - 2020-10-09\n^^^^^^^^^^^^^^^^^^^^^\nFixed\n~~~~~\n* fix bug in partial_ratio (see #43)\n\n[0.12.2] - 2020-10-01\n^^^^^^^^^^^^^^^^^^^^^\nFixed\n~~~~~\n* fix inconsistency with fuzzywuzzy in partial_ratio when using strings of equal length\n\n[0.12.1] - 2020-09-30\n^^^^^^^^^^^^^^^^^^^^^\nFixed\n~~~~~\n* MSVC has a bug and therefore crashed on some of the templates used. This Release simplifies the templates so compiling on msvc works again\n\n[0.12.0] - 2020-09-30\n^^^^^^^^^^^^^^^^^^^^^\nPerformance\n~~~~~~~~~~~\n* partial_ratio is using the Levenshtein distance now, which is a lot faster. Since many of the other algorithms use partial_ratio, this helps to improve the overall performance\n\n[0.11.3] - 2020-09-22\n^^^^^^^^^^^^^^^^^^^^^\nFixed\n~~~~~\n* fix partial_token_set_ratio returning 100 all the time\n\n[0.11.2] - 2020-09-12\n^^^^^^^^^^^^^^^^^^^^^\nAdded\n~~~~~\n* added rapidfuzz.__author__, rapidfuzz.__license__ and rapidfuzz.__version__\n\n[0.11.1] - 2020-09-01\n^^^^^^^^^^^^^^^^^^^^^\nFixed\n~~~~~\n* do not use auto junk when searching the optimal alignment for partial_ratio\n\n[0.11.0] - 2020-08-22\n^^^^^^^^^^^^^^^^^^^^^\nChanged\n~~~~~~~\n* support for python 2.7 added #40\n* add wheels for python2.7 (both pypy and cpython) on MacOS and Linux\n\n[0.10.0] - 2020-08-17\n^^^^^^^^^^^^^^^^^^^^^\nChanged\n~~~~~~~\n* added wheels for Python3.9\n\nFixed\n~~~~~\n* tuple scores in process.extractOne are now supported #39\n"
        },
        {
          "name": "CITATION.bib",
          "type": "blob",
          "size": 0.322265625,
          "content": "@software{max_bachmann_2024_10938887,\n  author       = {Max Bachmann},\n  title        = {rapidfuzz/RapidFuzz: Release 3.8.1},\n  month        = apr,\n  year         = 2024,\n  publisher    = {Zenodo},\n  version      = {v3.8.1},\n  doi          = {10.5281/zenodo.10938887},\n  url          = {https://doi.org/10.5281/zenodo.10938887}\n}\n"
        },
        {
          "name": "CMakeLists.txt",
          "type": "blob",
          "size": 3.6025390625,
          "content": "cmake_minimum_required(VERSION 3.15...3.30)\n\nset(CMAKE_INTERPROCEDURAL_OPTIMIZATION TRUE)\nset(CMAKE_POSITION_INDEPENDENT_CODE ON)\nset(SKBUILD_LINK_LIBRARIES_KEYWORD PRIVATE)\nset(THREADS_PREFER_PTHREAD_FLAG ON)\n\nlist(APPEND CMAKE_MODULE_PATH \"${CMAKE_CURRENT_SOURCE_DIR}/cmake\")\n\nproject(rapidfuzz LANGUAGES C CXX)\n\ninclude(CMakePrintHelpers)\ncmake_print_variables(CMAKE_AR CMAKE_C_COMPILER_AR CMAKE_CXX_COMPILER_AR)\ncmake_print_variables(CMAKE_RANLIB CMAKE_C_COMPILER_RANLIB\n                      CMAKE_CXX_COMPILER_RANLIB)\n\nif(\"${CMAKE_C_COMPILER_AR}\" STREQUAL \"\")\n  set(CMAKE_C_COMPILER_AR \"${CMAKE_AR}\")\nendif()\nif(\"${CMAKE_CXX_COMPILER_AR}\" STREQUAL \"\")\n  set(CMAKE_CXX_COMPILER_AR \"${CMAKE_AR}\")\nendif()\nif(\"${CMAKE_C_COMPILER_RANLIB}\" STREQUAL \"\")\n  set(CMAKE_C_COMPILER_RANLIB \"${CMAKE_RANLIB}\")\nendif()\nif(\"${CMAKE_CXX_COMPILER_RANLIB}\" STREQUAL \"\")\n  set(CMAKE_CXX_COMPILER_RANLIB \"${CMAKE_RANLIB}\")\nendif()\n\nif(MSVC)\n  add_compile_options(/W4 /bigobj /wd4127)\n\n  # NOTE: _DISABLE_CONSTEXPR_MUTEX_CONSTRUCTOR is temporary. When building on\n  # VS 2022 17.10 or newer, but using an older runtime, mutexes can crash\n  add_compile_options(/D_DISABLE_CONSTEXPR_MUTEX_CONSTRUCTOR)\nelse()\n  add_compile_options(-Wall -Wextra -pedantic -Wno-psabi)\nendif()\n\nif(EMSCRIPTEN)\n  add_compile_options(-fexceptions)\n  add_link_options(-fexceptions)\nendif()\n\nif(CMAKE_VERSION VERSION_LESS 3.18)\n  find_package(\n    Python\n    COMPONENTS Interpreter Development\n    REQUIRED)\nelse()\n  set(Python_ARTIFACTS_INTERACTIVE TRUE)\n  find_package(\n    Python\n    COMPONENTS Interpreter Development.Module\n    REQUIRED)\nendif()\n\nif(CMAKE_VERSION VERSION_LESS 3.17)\n  execute_process(\n    COMMAND\n      \"${Python_EXECUTABLE}\" -c\n      \"import sysconfig; print(sysconfig.get_config_var('EXT_SUFFIX').split('.')[1])\"\n    OUTPUT_VARIABLE Python_SOABI\n    OUTPUT_STRIP_TRAILING_WHITESPACE COMMAND_ECHO STDOUT)\n  message(STATUS \"Corrected SOABI: ${Python_SOABI}\")\nelseif(\"${Python_INTERPRETER_ID}\" STREQUAL \"PyPy\")\n  message(STATUS \"PyPy SOABI: ${Python_SOABI}\")\n  execute_process(\n    COMMAND\n      \"${Python_EXECUTABLE}\" -c\n      \"import sysconfig; print(sysconfig.get_config_var('EXT_SUFFIX').split('.')[1])\"\n    OUTPUT_VARIABLE Python_SOABI\n    OUTPUT_STRIP_TRAILING_WHITESPACE COMMAND_ECHO STDOUT)\n  message(STATUS \"Corrected SOABI: ${Python_SOABI}\")\nendif()\n\ninclude(FetchContent)\ninclude(CheckCPUArch)\n\ncheck_cpu_arch_x64(RAPIDFUZZ_ARCH_X64)\ncheck_cpu_arch_x86(RAPIDFUZZ_ARCH_X86)\n\nset(RF_BASE_DIR ${CMAKE_CURRENT_SOURCE_DIR}/src)\n\nfind_package(Taskflow 3.8.0 QUIET)\nif(NOT Taskflow_FOUND)\n  find_package(Taskflow 3.7.0 QUIET)\nendif()\nif(NOT Taskflow_FOUND)\n  find_package(Taskflow 3.6.0 QUIET)\nendif()\nif(NOT Taskflow_FOUND)\n  find_package(Taskflow 3.5.0 QUIET)\nendif()\nif(NOT Taskflow_FOUND)\n  find_package(Taskflow 3.4.0 QUIET)\nendif()\nif(NOT Taskflow_FOUND)\n  find_package(Taskflow 3.3.0 QUIET)\nendif()\nif(Taskflow_FOUND)\n  message(STATUS \"Using system supplied version of Taskflow\")\nelse()\n  message(STATUS \"Using packaged version of Taskflow\")\n  set(TF_BUILD_CUDA\n      OFF\n      CACHE BOOL \"Enables build of CUDA code\")\n  set(TF_BUILD_TESTS\n      OFF\n      CACHE BOOL \"Enables build of tests\")\n  set(TF_BUILD_EXAMPLES\n      OFF\n      CACHE BOOL \"Enables build of examples\")\n  add_subdirectory(extern/taskflow EXCLUDE_FROM_ALL)\n  add_library(Taskflow::Taskflow ALIAS Taskflow)\nendif()\n\nfind_package(rapidfuzz 3.2.0 QUIET)\nif(rapidfuzz_FOUND)\n  message(STATUS \"Using system supplied version of rapidfuzz-cpp\")\nelse()\n  message(STATUS \"Using packaged version of rapidfuzz-cpp\")\n  add_subdirectory(extern/rapidfuzz-cpp)\nendif()\n\nadd_subdirectory(src/rapidfuzz)\nadd_subdirectory(src/rapidfuzz/distance)\n"
        },
        {
          "name": "CODE_OF_CONDUCT.md",
          "type": "blob",
          "size": 5.359375,
          "content": "\n# Contributor Covenant Code of Conduct\n\n## Our Pledge\n\nWe as members, contributors, and leaders pledge to make participation in our\ncommunity a harassment-free experience for everyone, regardless of age, body\nsize, visible or invisible disability, ethnicity, sex characteristics, gender\nidentity and expression, level of experience, education, socio-economic status,\nnationality, personal appearance, race, caste, color, religion, or sexual\nidentity and orientation.\n\nWe pledge to act and interact in ways that contribute to an open, welcoming,\ndiverse, inclusive, and healthy community.\n\n## Our Standards\n\nExamples of behavior that contributes to a positive environment for our\ncommunity include:\n\n* Demonstrating empathy and kindness toward other people\n* Being respectful of differing opinions, viewpoints, and experiences\n* Giving and gracefully accepting constructive feedback\n* Accepting responsibility and apologizing to those affected by our mistakes,\n  and learning from the experience\n* Focusing on what is best not just for us as individuals, but for the overall\n  community\n\nExamples of unacceptable behavior include:\n\n* The use of sexualized language or imagery, and sexual attention or advances of\n  any kind\n* Trolling, insulting or derogatory comments, and personal or political attacks\n* Public or private harassment\n* Publishing others' private information, such as a physical or email address,\n  without their explicit permission\n* Other conduct which could reasonably be considered inappropriate in a\n  professional setting\n\n## Enforcement Responsibilities\n\nCommunity leaders are responsible for clarifying and enforcing our standards of\nacceptable behavior and will take appropriate and fair corrective action in\nresponse to any behavior that they deem inappropriate, threatening, offensive,\nor harmful.\n\nCommunity leaders have the right and responsibility to remove, edit, or reject\ncomments, commits, code, wiki edits, issues, and other contributions that are\nnot aligned to this Code of Conduct, and will communicate reasons for moderation\ndecisions when appropriate.\n\n## Scope\n\nThis Code of Conduct applies within all community spaces, and also applies when\nan individual is officially representing the community in public spaces.\nExamples of representing our community include using an official e-mail address,\nposting via an official social media account, or acting as an appointed\nrepresentative at an online or offline event.\n\n## Enforcement\n\nInstances of abusive, harassing, or otherwise unacceptable behavior may be\nreported to the community leaders responsible for enforcement at conduct@maxbachmann.de.\nAll complaints will be reviewed and investigated promptly and fairly.\n\nAll community leaders are obligated to respect the privacy and security of the\nreporter of any incident.\n\n## Enforcement Guidelines\n\nCommunity leaders will follow these Community Impact Guidelines in determining\nthe consequences for any action they deem in violation of this Code of Conduct:\n\n### 1. Correction\n\n**Community Impact**: Use of inappropriate language or other behavior deemed\nunprofessional or unwelcome in the community.\n\n**Consequence**: A private, written warning from community leaders, providing\nclarity around the nature of the violation and an explanation of why the\nbehavior was inappropriate. A public apology may be requested.\n\n### 2. Warning\n\n**Community Impact**: A violation through a single incident or series of\nactions.\n\n**Consequence**: A warning with consequences for continued behavior. No\ninteraction with the people involved, including unsolicited interaction with\nthose enforcing the Code of Conduct, for a specified period of time. This\nincludes avoiding interactions in community spaces as well as external channels\nlike social media. Violating these terms may lead to a temporary or permanent\nban.\n\n### 3. Temporary Ban\n\n**Community Impact**: A serious violation of community standards, including\nsustained inappropriate behavior.\n\n**Consequence**: A temporary ban from any sort of interaction or public\ncommunication with the community for a specified period of time. No public or\nprivate interaction with the people involved, including unsolicited interaction\nwith those enforcing the Code of Conduct, is allowed during this period.\nViolating these terms may lead to a permanent ban.\n\n### 4. Permanent Ban\n\n**Community Impact**: Demonstrating a pattern of violation of community\nstandards, including sustained inappropriate behavior, harassment of an\nindividual, or aggression toward or disparagement of classes of individuals.\n\n**Consequence**: A permanent ban from any sort of public interaction within the\ncommunity.\n\n## Attribution\n\nThis Code of Conduct is adapted from the [Contributor Covenant][homepage],\nversion 2.1, available at\n[https://www.contributor-covenant.org/version/2/1/code_of_conduct.html][v2.1].\n\nCommunity Impact Guidelines were inspired by\n[Mozilla's code of conduct enforcement ladder][Mozilla CoC].\n\nFor answers to common questions about this code of conduct, see the FAQ at\n[https://www.contributor-covenant.org/faq][FAQ]. Translations are available at\n[https://www.contributor-covenant.org/translations][translations].\n\n[homepage]: https://www.contributor-covenant.org\n[v2.1]: https://www.contributor-covenant.org/version/2/1/code_of_conduct.html\n[Mozilla CoC]: https://github.com/mozilla/diversity\n[FAQ]: https://www.contributor-covenant.org/faq\n[translations]: https://www.contributor-covenant.org/translations\n"
        },
        {
          "name": "LICENSE",
          "type": "blob",
          "size": 1.06640625,
          "content": "Copyright © 2020-present Max Bachmann\nCopyright © 2011 Adam Cohen\n\nPermission is hereby granted, free of charge, to any person obtaining\na copy of this software and associated documentation files (the\n\"Software\"), to deal in the Software without restriction, including\nwithout limitation the rights to use, copy, modify, merge, publish,\ndistribute, sublicense, and/or sell copies of the Software, and to\npermit persons to whom the Software is furnished to do so, subject to\nthe following conditions:\n\nThe above copyright notice and this permission notice shall be\nincluded in all copies or substantial portions of the Software.\n\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND,\nEXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF\nMERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND\nNONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE\nLIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION\nOF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION\nWITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.\n"
        },
        {
          "name": "README.md",
          "type": "blob",
          "size": 11.0810546875,
          "content": "<h1 align=\"center\">\n<img src=\"https://raw.githubusercontent.com/rapidfuzz/RapidFuzz/main/docs/img/RapidFuzz.svg?sanitize=true\" alt=\"RapidFuzz\" width=\"400\">\n</h1>\n<h4 align=\"center\">Rapid fuzzy string matching in Python and C++ using the Levenshtein Distance</h4>\n\n<p align=\"center\">\n  <a href=\"https://github.com/rapidfuzz/RapidFuzz/actions\">\n    <img src=\"https://github.com/rapidfuzz/RapidFuzz/workflows/Test%20Build/badge.svg\"\n         alt=\"Continuous Integration\">\n  </a>\n  <a href=\"https://pypi.org/project/rapidfuzz/\">\n    <img src=\"https://img.shields.io/pypi/v/rapidfuzz\"\n         alt=\"PyPI package version\">\n  </a>\n  <a href=\"https://anaconda.org/conda-forge/rapidfuzz\">\n    <img src=\"https://img.shields.io/conda/vn/conda-forge/rapidfuzz.svg\"\n         alt=\"Conda Version\">\n  </a>\n  <a href=\"https://www.python.org\">\n    <img src=\"https://img.shields.io/pypi/pyversions/rapidfuzz\"\n         alt=\"Python versions\">\n  </a><br/>\n  <a href=\"https://rapidfuzz.github.io/RapidFuzz\">\n    <img src=\"https://img.shields.io/badge/-documentation-blue\"\n         alt=\"Documentation\">\n  </a>\n  <a href=\"https://codecov.io/gh/rapidfuzz/RapidFuzz\">\n    <img src=\"https://codecov.io/gh/rapidfuzz/RapidFuzz/branch/main/graph/badge.svg?token=1IJLT65K8B\"\n         alt=\"Code Coverage\">\n  </a>\n  <a href=\"https://github.com/rapidfuzz/RapidFuzz/blob/main/LICENSE\">\n    <img src=\"https://img.shields.io/github/license/rapidfuzz/rapidfuzz\"\n         alt=\"GitHub license\">\n  </a>\n</p>\n\n<p align=\"center\">\n  <a href=\"#description\">Description</a> •\n  <a href=\"#installation\">Installation</a> •\n  <a href=\"#usage\">Usage</a> •\n  <a href=\"#license\">License</a>\n</p>\n\n---\n\n## Description\nRapidFuzz is a fast string matching library for Python and C++, which is using the string similarity calculations from [FuzzyWuzzy](https://github.com/seatgeek/fuzzywuzzy). However there are a couple of aspects that set RapidFuzz apart from FuzzyWuzzy:\n1) It is MIT licensed so it can be used whichever License you might want to choose for your project, while you're forced to adopt the GPL license when using FuzzyWuzzy\n2) It provides many string_metrics like hamming or jaro_winkler, which are not included in FuzzyWuzzy\n3) It is mostly written in C++ and on top of this comes with a lot of Algorithmic improvements to make string matching even faster, while still providing the same results. For detailed benchmarks check the [documentation](https://rapidfuzz.github.io/RapidFuzz)\n4) Fixes multiple bugs in the `partial_ratio` implementation\n5) It can be largely used as a drop in replacement for `fuzzywuzzy`. However there are a couple API differences described [here](https://github.com/rapidfuzz/RapidFuzz/blob/main/api_differences.md)\n\n## Requirements\n\n- Python 3.9 or later\n- On Windows the [Visual C++ 2019 redistributable](https://support.microsoft.com/en-us/help/2977003/the-latest-supported-visual-c-downloads) is required\n\n## Installation\n\nThere are several ways to install RapidFuzz, the recommended methods\nare to either use `pip`(the Python package manager) or\n`conda` (an open-source, cross-platform, package manager)\n\n### with pip\n\nRapidFuzz can be installed with `pip` the following way:\n\n```bash\npip install rapidfuzz\n```\n\nThere are pre-built binaries (wheels) of RapidFuzz for MacOS (10.9 and later), Linux x86_64 and Windows. Wheels for armv6l (Raspberry Pi Zero) and armv7l (Raspberry Pi) are available on [piwheels](https://www.piwheels.org/project/rapidfuzz/).\n\n> :heavy_multiplication_x: &nbsp;&nbsp;**failure \"ImportError: DLL load failed\"**\n>\n> If you run into this error on Windows the reason is most likely, that the [Visual C++ 2019 redistributable](https://support.microsoft.com/en-us/help/2977003/the-latest-supported-visual-c-downloads) is not installed, which is required to find C++ Libraries (The C++ 2019 version includes the 2015, 2017 and 2019 version).\n\n### with conda\n\nRapidFuzz can be installed with `conda`:\n\n```bash\nconda install -c conda-forge rapidfuzz\n```\n\n### from git\nRapidFuzz can be installed directly from the source distribution by cloning the repository. This requires a C++17 capable compiler.\n\n```bash\ngit clone --recursive https://github.com/rapidfuzz/rapidfuzz.git\ncd rapidfuzz\npip install .\n```\n\n## Usage\nSome simple functions are shown below. A complete documentation of all functions can be found [here](https://rapidfuzz.github.io/RapidFuzz/Usage/index.html).<br>\nNote that from RapidFuzz 3.0.0, strings are not preprocessed(removing all non alphanumeric characters, trimming whitespaces, converting all characters to lower case) by default. Which means that when comparing two strings that have the same characters but different cases(\"this is a word\", \"THIS IS A WORD\") their similarity score value might be different, so when comparing such strings you might see a difference in score value compared to previous versions. Some examples of string matching with preprocessing can be found [here](#weighted-ratio).\n\n### Scorers\nScorers in RapidFuzz can be found in the modules `fuzz` and `distance`.\n\n#### Simple Ratio\n```console\n> from rapidfuzz import fuzz\n> fuzz.ratio(\"this is a test\", \"this is a test!\")\n96.55172413793103\n```\n\n#### Partial Ratio\n```console\n> from rapidfuzz import fuzz\n> fuzz.partial_ratio(\"this is a test\", \"this is a test!\")\n100.0\n```\n\n#### Token Sort Ratio\n```console\n> from rapidfuzz import fuzz\n> fuzz.ratio(\"fuzzy wuzzy was a bear\", \"wuzzy fuzzy was a bear\")\n90.9090909090909\n> fuzz.token_sort_ratio(\"fuzzy wuzzy was a bear\", \"wuzzy fuzzy was a bear\")\n100.0\n```\n\n#### Token Set Ratio\n```console\n> from rapidfuzz import fuzz\n> fuzz.token_sort_ratio(\"fuzzy was a bear\", \"fuzzy fuzzy was a bear\")\n84.21052631578947\n> fuzz.token_set_ratio(\"fuzzy was a bear\", \"fuzzy fuzzy was a bear\")\n100.0\n# Returns 100.0 if one string is a subset of the other, regardless of extra content in the longer string\n> fuzz.token_set_ratio(\"fuzzy was a bear but not a dog\", \"fuzzy was a bear\")\n100.0\n# Score is reduced only when there is explicit disagreement in the two strings\n> fuzz.token_set_ratio(\"fuzzy was a bear but not a dog\", \"fuzzy was a bear but not a cat\")\n92.3076923076923\n```\n\n#### Weighted Ratio\n```console\n> from rapidfuzz import fuzz\n> fuzz.WRatio(\"this is a test\", \"this is a new test!!!\")\n85.5\n\n> from rapidfuzz import fuzz, utils\n> # Removing non alpha numeric characters(\"!\") from the string\n> fuzz.WRatio(\"this is a test\", \"this is a new test!!!\", processor=utils.default_process) # here \"this is a new test!!!\" is converted to \"this is a new test\"\n95.0\n> fuzz.WRatio(\"this is a test\", \"this is a new test\")\n95.0\n\n> # Converting string to lower case\n> fuzz.WRatio(\"this is a word\", \"THIS IS A WORD\")\n21.42857142857143\n> fuzz.WRatio(\"this is a word\", \"THIS IS A WORD\", processor=utils.default_process) # here \"THIS IS A WORD\" is converted to \"this is a word\"\n100.0\n```\n\n#### Quick Ratio\n```console\n> from rapidfuzz import fuzz\n> fuzz.QRatio(\"this is a test\", \"this is a new test!!!\")\n80.0\n\n> from rapidfuzz import fuzz, utils\n> # Removing non alpha numeric characters(\"!\") from the string\n> fuzz.QRatio(\"this is a test\", \"this is a new test!!!\", processor=utils.default_process)\n87.5\n> fuzz.QRatio(\"this is a test\", \"this is a new test\")\n87.5\n\n> # Converting string to lower case\n> fuzz.QRatio(\"this is a word\", \"THIS IS A WORD\")\n21.42857142857143\n> fuzz.QRatio(\"this is a word\", \"THIS IS A WORD\", processor=utils.default_process)\n100.0\n```\n\n### Process\nThe process module makes it compare strings to lists of strings. This is generally more\nperformant than using the scorers directly from Python.\nHere are some examples on the usage of processors in RapidFuzz:\n\n```console\n> from rapidfuzz import process, fuzz\n> choices = [\"Atlanta Falcons\", \"New York Jets\", \"New York Giants\", \"Dallas Cowboys\"]\n> process.extract(\"new york jets\", choices, scorer=fuzz.WRatio, limit=2)\n[('New York Jets', 76.92307692307692, 1), ('New York Giants', 64.28571428571428, 2)]\n> process.extractOne(\"cowboys\", choices, scorer=fuzz.WRatio)\n('Dallas Cowboys', 83.07692307692308, 3)\n\n> # With preprocessing\n> from rapidfuzz import process, fuzz, utils\n> process.extract(\"new york jets\", choices, scorer=fuzz.WRatio, limit=2, processor=utils.default_process)\n[('New York Jets', 100.0, 1), ('New York Giants', 78.57142857142857, 2)]\n> process.extractOne(\"cowboys\", choices, scorer=fuzz.WRatio, processor=utils.default_process)\n('Dallas Cowboys', 90.0, 3)\n```\n\nThe full documentation of processors can be found [here](https://rapidfuzz.github.io/RapidFuzz/Usage/process.html)\n\n## Benchmark\n\nThe following benchmark gives a quick performance comparison between RapidFuzz and FuzzyWuzzy.\nMore detailed benchmarks for the string metrics can be found in the [documentation](https://rapidfuzz.github.io/RapidFuzz). For this simple comparison I generated a list of 10.000 strings with length 10, that is compared to a sample of 100 elements from this list:\n```python\nwords = [\n    \"\".join(random.choice(string.ascii_letters + string.digits) for _ in range(10))\n    for _ in range(10_000)\n]\nsamples = words[:: len(words) // 100]\n```\n\nThe first benchmark compares the performance of the scorers in FuzzyWuzzy and RapidFuzz when they are used directly\nfrom Python in the following way:\n```python3\nfor sample in samples:\n    for word in words:\n        scorer(sample, word)\n```\nThe following graph shows how many elements are processed per second with each of the scorers. There are big performance differences between the different scorers. However each of the scorers is faster in RapidFuzz\n\n<img src=\"https://raw.githubusercontent.com/rapidfuzz/RapidFuzz/main/docs/img/scorer.svg?sanitize=true\" alt=\"Benchmark Scorer\">\n\nThe second benchmark compares the performance when the scorers are used in combination with cdist in the following\nway:\n```python3\ncdist(samples, words, scorer=scorer)\n```\nThe following graph shows how many elements are processed per second with each of the scorers. In RapidFuzz the usage of scorers through processors like `cdist` is a lot faster than directly using it. That's why they should be used whenever possible.\n\n<img src=\"https://raw.githubusercontent.com/rapidfuzz/RapidFuzz/main/docs/img/cdist.svg?sanitize=true\" alt=\"Benchmark cdist\">\n\n\n## Support the project\n\nIf you are using RapidFuzz for your work and feel like giving a bit of your own benefit back to support the project, consider sending us money through GitHub Sponsors or PayPal that we can use to buy us free time for the maintenance of this great library, to fix bugs in the software, review and integrate code contributions, to improve its features and documentation, or to just take a deep breath and have a cup of tea every once in a while. Thank you for your support.\n\nSupport the project through [GitHub Sponsors]() or via [PayPal](https://www.paypal.com/donate/?hosted_button_id=VGWQBBD5CTWJU):\n\n[![](https://www.paypalobjects.com/en_US/i/btn/btn_donateCC_LG.gif)](https://www.paypal.com/donate/?hosted_button_id=VGWQBBD5CTWJU).\n\n## License\nRapidFuzz is licensed under the MIT license since I believe that everyone should be able to use it without being forced to adopt the GPL license. That's why the library is based on an older version of fuzzywuzzy that was MIT licensed as well.\nThis old version of fuzzywuzzy can be found [here](https://github.com/seatgeek/fuzzywuzzy/tree/4bf28161f7005f3aa9d4d931455ac55126918df7).\n"
        },
        {
          "name": "SECURITY.md",
          "type": "blob",
          "size": 0.9638671875,
          "content": "## Reporting Security Issues\n\nIf you believe you have found a security vulnerability in the project, please report it to us through coordinated disclosure.\n\n**Please do not report security vulnerabilities through public GitHub issues, discussions, or pull requests.**\n\nInstead, please send an email to oss@maxbachmann.de.\n\nPlease include as much of the information listed below as you can to help us better understand and resolve the issue:\n\n  * The type of issue (e.g., buffer overflow, SQL injection, or cross-site scripting)\n  * Full paths of source file(s) related to the manifestation of the issue\n  * The location of the affected source code (tag/branch/commit or direct URL)\n  * Any special configuration required to reproduce the issue\n  * Step-by-step instructions to reproduce the issue\n  * Proof-of-concept or exploit code (if possible)\n  * Impact of the issue, including how an attacker might exploit the issue\n\nThis information will help us triage your report more quickly.\n"
        },
        {
          "name": "api_differences.md",
          "type": "blob",
          "size": 3.869140625,
          "content": "# API differences to `fuzzywuzzy`\n\n`Rapidfuzz` does provide a very similar API to `fuzzywuzzy`/`thefuzz` making it a drop in replacement for a large amount of projects.\nHowever there are some differences which are listed below:\n\n## ratio implementation\n\n`fuzzywuzzy` provides two implementations of the algorithm:\n1) a pure Python version implemented using difflib (Ratcliff and Obershelp algorithm)\n2) an accelerated version using the Indel similarity (similar to the Levenshtein distance but only allows for Insertions / Deletions)\n\nThis leads to different results depending on the version in use. `RapidFuzz` always uses the Indel similarity both in the pure Python\nfallback implementation and the C++ based implementation to provide consistent matching results.\n\n## partial_ratio implementation\n`fuzzywuzzy` searches for the optimal matching substring and then calculates the similarity using `ratio`. This substring is searches using either:\n1) `difflib.SequenceMatcher.get_matching_blocks` (based on Ratcliff and Obershelp algorithm)\n2) `Levenshtein.matching_blocks` (backtracks Levenshtein matrix)\n\nThis implementation has a couple of issues:\n1) in the pure Python implementation the automatic junk heuristic of difflib is not deactivated. This heuristic improves the performance for long strings,\nbut can lead to completely incorrect results.\n2) the accelerated version backtracks the Levenshtein matrix to find the same alignment found by the Python implementation. However the algorithm just uses\none of multiple optimal alignment. There is no guarantee for this alignment to include the longest common substring.\n3) the optimal substring is assumed to start at one of these `matching_blocks`. However this is not guaranteed.\n\n`RapidFuzz` uses a sliding window approach (with some optimizations to skip impossible alignments) to find the optimal alignment. This approach is guaranteed\nto find the optimal alignment.\n\n## differences in preprocessing\n\n`fuzzywuzzy` provides the function `utils.full_process` to preprocess strings. This function is called `utils.default_process` in `RapidFuzz`. It behaves similar with the only exception\nthat it does not provide the optional argument `force_ascii` which removes any non ascii characters from a string.\n\n## differences in scorers\n\n`fuzzywuzzy` has the following scorers which preprocess strings by default:\n- `fuzz.token_sort_ratio`\n- `fuzz.token_set_ratio`\n- `fuzz.partial_token_sort_ratio`\n- `fuzz.partial_token_set_ratio`\n- `fuzz.WRatio`\n- `fuzz.QRatio`\n- `fuzz.UWRatio`\n- `fuzz.UQRatio`\n\nWith the exception `fuzz.UWRatio` and `fuzz.UQRatio` of all have `force_ascii` enabled forthe peprocessing function by default.\n\nIn `RapidFuzz` no scorer preprocesses strings by default to keep the interface consistent. However a preprocessing function can be provided using the `processor` argument. In addition the functions `fuzz.UWRatio` and `fuzz.UQRatio` do not exist, since they are the same as  `fuzz.WRatio` / `fuzz.QRatio` with `force_ascii` disabled. Since in `RapidFuzz` the `force_ascii` argument does not exist these functions do not provide any value.\n\n## differences in processor functions\n\nIn `fuzzywuzzy` the process module includes the following functions:\n- `extractWithoutOrder` (generator over unsorted results)\n- `extract` (find the N best matches in a sorted list)\n- `extractBests` (same as extract but with an addition score_cutoff parameter to filter bad matches)\n- `extractOne` (find best match)\n- `dedupe` (deduplicate list)\n\nIn `RapidFuzz` these functions are sometimes available under different names:\n- `extractWithoutOrder` is called `extract_iter`\n- `extract` / `extractBests` are a single function called `extract` which povides the optional `score_cutoff` argument\n- `extractOne` is available under the same name\n- `dedupe` is not available\n\nIn addition these functions do not preprocess strings by default. However preprocessing can be enabled using the `processor` argument.\n"
        },
        {
          "name": "bench",
          "type": "tree",
          "content": null
        },
        {
          "name": "cmake",
          "type": "tree",
          "content": null
        },
        {
          "name": "docs",
          "type": "tree",
          "content": null
        },
        {
          "name": "extern",
          "type": "tree",
          "content": null
        },
        {
          "name": "pyproject.toml",
          "type": "blob",
          "size": 4.7001953125,
          "content": "[build-system]\nrequires = [\n    \"scikit-build-core>=0.10.7\",\n    \"Cython >=3.0.11, <3.1.0\"\n]\nbuild-backend = \"scikit_build_core.build\"\n\n[project]\nname = \"RapidFuzz\"\ndynamic = [\"version\"]\nrequires-python = \">= 3.9\"\nauthors = [\n  {name = \"Max Bachmann\", email = \"pypi@maxbachmann.de\"},\n]\ndescription = \"rapid fuzzy string matching\"\nreadme = \"README.md\"\nclassifiers=[\n  \"Programming Language :: Python :: 3\",\n  \"Programming Language :: Python :: 3.9\",\n  \"Programming Language :: Python :: 3.10\",\n  \"Programming Language :: Python :: 3.11\",\n  \"Programming Language :: Python :: 3.12\",\n  \"Programming Language :: Python :: 3.13\",\n  \"License :: OSI Approved :: MIT License\",\n]\nHomepage = \"https://github.com/rapidfuzz/RapidFuzz\"\nDocumentation = \"https://rapidfuzz.github.io/RapidFuzz/\"\nRepository = \"https://github.com/rapidfuzz/RapidFuzz.git\"\nIssues = \"https://github.com/rapidfuzz/RapidFuzz/issues\"\nChangelog = \"https://github.com/rapidfuzz/RapidFuzz/blob/main/CHANGELOG.rst\"\n\n[project.optional-dependencies]\nall = [\n  \"numpy\"\n]\n\n[project.entry-points.pyinstaller40]\nhook-dirs = \"rapidfuzz.__pyinstaller:get_hook_dirs\"\ntests = \"rapidfuzz.__pyinstaller:get_PyInstaller_tests\"\n\n[tool.scikit-build]\nminimum-version = \"build-system.requires\"\nsdist.include = [\n  \"src/rapidfuzz/*.cxx\",\n  \"src/rapidfuzz/distance/*.cxx\",\n]\nsdist.exclude = [\n  \".github\"\n]\nwheel.exclude = [\n  \"**.pyx\",\n  \"**.cxx\",\n  \"**.pxd\",\n  \"**.cpp\",\n  \"**.hpp\",\n  \"**.h\",\n  \"CMakeLists.txt\",\n  \"generate.sh\"\n]\nwheel.packages = [\"src/rapidfuzz\"]\nwheel.cmake = false\nmessages.after-success = \"{yellow}CMake unavailable, falling back to pure Python Extension\"\n\n[[tool.scikit-build.overrides]]\nif.any.system-cmake = \">=3.15\"\nif.any.cmake-wheel = true\nwheel.cmake = true\nmessages.after-success = \"{green}C++ Extension built successfully\"\n\n[[tool.scikit-build.overrides]]\nif.failed = true\nif.env.CIBUILDWHEEL = false\nif.env.CONDA_BUILD = false\nif.env.PIWHEELS_BUILD = false\nif.env.RAPIDFUZZ_BUILD_EXTENSION = false\nwheel.cmake = false\nmessages.after-success = \"{yellow}Failed to build C++ Extension, falling back to pure Python Extension\"\n\n[[tool.scikit-build.overrides]]\nif.any.env.CIBUILDWHEEL = true\nif.any.env.CONDA_BUILD = true\nif.any.env.PIWHEELS_BUILD = true\nif.any.env.RAPIDFUZZ_BUILD_EXTENSION = true\nwheel.cmake = true\nmessages.after-success = \"{green}C++ Extension built successfully\"\nmessages.after-failure = \"{red}Failed to build C++ Extension in a packaged build\"\n\n[tool.scikit-build.metadata.version]\nprovider = \"scikit_build_core.metadata.regex\"\ninput = \"src/rapidfuzz/__init__.py\"\n\n\n[tool.black]\nline-length = 120\n\n[tool.mypy]\nfiles = [\"src\"]\npython_version = \"3.9\"\nwarn_unused_configs = true\nshow_error_codes = true\nenable_error_code = [\"ignore-without-code\", \"redundant-expr\", \"truthy-bool\"]\nstrict = true\ndisallow_untyped_defs = false\n\n[tool.pytest.ini_options]\nminversion = \"6.0\"\ntestpaths = [\"tests\"]\naddopts = [\"-ra\", \"--showlocals\", \"--strict-markers\", \"--strict-config\"]\nnorecursedirs = [\"_skbuild\"]\nxfail_strict = true\nlog_cli_level = \"info\"\n\n[tool.pylint]\npy-version = \"3.9\"\n\n[tool.pylint.reports]\noutput-format = \"colorized\"\n\n[tool.pylint.messages_control]\ndisable = [\n  \"design\",\n  \"fixme\",\n  \"imports\",\n  \"line-too-long\",\n  \"imports\",\n  \"invalid-name\",\n  \"protected-access\",\n  \"missing-module-docstring\",\n]\n\n[tool.ruff]\ntarget-version = \"py39\"\nsrc = [\"src\"]\nexclude = []\n\n[tool.ruff.lint]\nselect = [\n  \"E\", \"F\", \"W\", # flake8\n  \"B\",           # flake8-bugbear\n  \"I\",           # isort\n  \"ARG\",         # flake8-unused-arguments\n  \"C4\",          # flake8-comprehensions\n  \"EM\",          # flake8-errmsg\n  \"ICN\",         # flake8-import-conventions\n  \"ISC\",         # flake8-implicit-str-concat\n  \"G\",           # flake8-logging-format\n  \"PGH\",         # pygrep-hooks\n  \"PIE\",         # flake8-pie\n  \"PL\",          # pylint\n  \"PT\",          # flake8-pytest-style\n  \"PTH\",         # flake8-use-pathlib\n  \"RET\",         # flake8-return\n  \"RUF\",         # Ruff-specific\n  \"SIM\",         # flake8-simplify\n  \"T20\",         # flake8-print\n  \"UP\",          # pyupgrade\n  \"YTT\",         # flake8-2020\n  \"EXE\",         # flake8-executable\n  \"NPY\",         # NumPy specific rules\n  \"PD\",          # pandas-vet\n]\nextend-ignore = [\n  \"PLR\",    # Design related pylint codes\n  \"E501\",   # Line too long\n  \"PT004\",  # Use underscore for non-returning fixture (use usefixture instead)\n  \"PTH123\", # use pathlib instead of builtin open\n]\nunfixable = [\n  \"T20\",  # Removes print statements\n  \"F841\", # Removes unused variables\n]\nflake8-unused-arguments.ignore-variadic-names = true\nisort.required-imports = [\"from __future__ import annotations\"]\n\n[tool.ruff.lint.per-file-ignores]\n\"tests/**\" = [\"T20\"]\n\"bench/**\" = [\"T20\"]\n\"tools/**\" = [\"T20\"]\n\"tools/test_process_typing.py\" = [\"ARG001\"]\n\"_custom_build/backend.py\" = [\"T20\"]\n\"setup.py\" = [\"T20\"]\n"
        },
        {
          "name": "src",
          "type": "tree",
          "content": null
        },
        {
          "name": "tests",
          "type": "tree",
          "content": null
        },
        {
          "name": "tools",
          "type": "tree",
          "content": null
        }
      ]
    }
  ]
}