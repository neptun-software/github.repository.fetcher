{
  "metadata": {
    "timestamp": 1736565992230,
    "page": 968,
    "hasNextPage": true,
    "endCursor": "Y3Vyc29yOjk3MA==",
    "completionStatus": "IN_PROGRESS"
  },
  "repositories": [
    {
      "nameWithOwner": "logcabin/logcabin",
      "stars": 1890,
      "defaultBranch": "master",
      "files": [
        {
          "name": ".gitignore",
          "type": "blob",
          "size": 0.1572265625,
          "content": "*.pyc\n/.sconsign.dblite\n/Local.sc\n/Local.sc.bck\n/build\n/debug\n/docs/doxygen/\n/logcabin*.conf\n/scripts/localconfig.py\n/smoketest*.conf\n/smoketeststorage\n/storage\n"
        },
        {
          "name": ".gitmodules",
          "type": "blob",
          "size": 0.1220703125,
          "content": "[submodule \"gtest\"]\n\tpath = gtest\n\t# relative URL, usually goes to https://github.com/logcabin/gtest.git\n\turl = ../gtest.git\n"
        },
        {
          "name": ".travis.yml",
          "type": "blob",
          "size": 1.1845703125,
          "content": "language: cpp\ncompiler:\n- gcc\nbefore_install:\n- echo \"TRAVIS_BRANCH=$TRAVIS_BRANCH\"\n- echo \"TRAVIS_PULL_REQUEST=$TRAVIS_PULL_REQUEST\"\n- openssl aes-256-cbc\n  -K $encrypted_74e7c0811ff1_key\n  -iv $encrypted_74e7c0811ff1_iv\n  -in travisci_rsa.enc\n  -out travisci_rsa -d &&\n  chmod 0600 travisci_rsa &&\n  mv travisci_rsa ~/.ssh/id_rsa ||\n  echo \"Failed to set up SSH key for doxygen output\"\n- sudo apt-get update -qq\n- sudo apt-get install -y protobuf-compiler libprotobuf-dev\n- sudo apt-get install -y libcrypto++-dev\n- sudo apt-get --no-install-recommends install -y doxygen\n- sudo apt-get install -y rpm\n- echo \"HTML_TIMESTAMP = no\" >> docs/Doxyfile\nscript:\n- scons NUMCPUS=2\n- VERBOSE=1 build/test/test --gtest_filter='-*TimingSensitive*:*IPv6*'\n- VERBOSE=1 build/test/test --gtest_filter='*TimingSensitive*:*IPv6*' || true\n- ./build/Examples/SmokeTest --mock\n- scons check\n- scons docs; DOCS_STATUS=$?; (exit $DOCS_STATUS)\n- if [ $DOCS_STATUS -eq 0 -a \"$TRAVIS_BRANCH\" = \"master\" -a \"$TRAVIS_PULL_REQUEST\" = \"false\" ]; then\n      ./scripts/publish-doxygen;\n  else\n      echo \"Not pushing doxygen, sons docs=$DOCS_STATUS, TRAVIS_BRANCH=$TRAVIS_BRANCH, TRAVIS_PULL_REQUEST=$TRAVIS_PULL_REQUEST\";\n  fi\n- scons rpm\n"
        },
        {
          "name": "CLANG.md",
          "type": "blob",
          "size": 1.78125,
          "content": "This file describes how to build LogCabin under Clang with libstdc++ (GNU) or\nlibc++.\n\nDiego used the following as a `Local.sc` file to build with clang 3.5 and\nlibc++ 3.5.\n\n```python\nCXX='clang++-3.5'\nCXXFLAGS=['-Werror', '-stdlib=libc++', '-DGTEST_USE_OWN_TR1_TUPLE']\nPROTOCXXFLAGS=['-stdlib=libc++']\nGTESTCXXFLAGS=['-stdlib=libc++', '-DGTEST_USE_OWN_TR1_TUPLE']\nBUILDTYPE='DEBUG'\nPROTOINSTALLPATH='/home/ongardie/local/protobuf-2.6.1/clang-3.5-libc++'\nLINKFLAGS='-lc++ -L%s/lib -Wl,-rpath,%s/lib' % (PROTOINSTALLPATH,\n                                                PROTOINSTALLPATH)\n```\n\nTo use libstdc++ instead:\n```python\nCXX='clang++-3.5'\nCXXFLAGS=['-Werror']\nBUILDTYPE='DEBUG'\nPROTOINSTALLPATH='/home/ongardie/local/protobuf-2.6.1/clang-3.5-libstdc++'\nLINKFLAGS='-L%s/lib -Wl,-rpath,%s/lib' % (PROTOINSTALLPATH,\n                                          PROTOINSTALLPATH)\n```\n\nNote that earlier versions of libstdc++ do not seem to work. For example, Diego wasn't\nable to even build ```#include <thread>``` using clang++ 3.4 and libstdc++ 4.6\n(due to std::chrono::duration issues as in\nhttps://github.com/Andersbakken/rct/issues/17).\n\n\nThe ProtoBuf library was built as follows (using v2.6.1, git hash bba83652):\n\n```shell\n./autogen.sh\n./configure \\\n    CC=clang-3.5 \\\n    CXX=clang++-3.5  \\\n    CPPFLAGS=\"-stdlib=libc++ -DGTEST_USE_OWN_TR1_TUPLE\" \\\n    LIBS=\"-lc++ -lc++abi\" \\\n    --prefix=$HOME/local/protobuf-2.6.1/clang-3.5-libc++\nmake -j4\nmake -j4 check\nmake install\n```\n\nThe `GTEST_USE_OWN_TR1_TUPLE` flag works around gtest's attempt to include the\n`<tr1/tuple>` header.\n\nTo build the ProtoBuf library against libstdc++ instead:\n\n```shell\n./autogen.sh\n./configure \\\n    CC=clang-3.5 \\\n    CXX=clang++-3.5  \\\n    --prefix=$HOME/local/protobuf-2.6.1/clang-3.5-libstdc++\nmake -j4\nmake -j4 check\nmake install\n```\n"
        },
        {
          "name": "Client",
          "type": "tree",
          "content": null
        },
        {
          "name": "Core",
          "type": "tree",
          "content": null
        },
        {
          "name": "Event",
          "type": "tree",
          "content": null
        },
        {
          "name": "Examples",
          "type": "tree",
          "content": null
        },
        {
          "name": "LICENSE",
          "type": "blob",
          "size": 0.734375,
          "content": "ISC License\n\nCopyright (c) 2011, 2012 Stanford University\n\nPermission to use, copy, modify, and distribute this software for any\npurpose with or without fee is hereby granted, provided that the above\ncopyright notice and this permission notice appear in all copies.\n\nTHE SOFTWARE IS PROVIDED \"AS IS\" AND THE AUTHOR(S) DISCLAIM ALL WARRANTIES\nWITH REGARD TO THIS SOFTWARE INCLUDING ALL IMPLIED WARRANTIES OF\nMERCHANTABILITY AND FITNESS. IN NO EVENT SHALL AUTHORS BE LIABLE FOR\nANY SPECIAL, DIRECT, INDIRECT, OR CONSEQUENTIAL DAMAGES OR ANY DAMAGES\nWHATSOEVER RESULTING FROM LOSS OF USE, DATA OR PROFITS, WHETHER IN AN\nACTION OF CONTRACT, NEGLIGENCE OR OTHER TORTIOUS ACTION, ARISING OUT OF\nOR IN CONNECTION WITH THE USE OR PERFORMANCE OF THIS SOFTWARE.\n"
        },
        {
          "name": "Protocol",
          "type": "tree",
          "content": null
        },
        {
          "name": "README.md",
          "type": "blob",
          "size": 10.2236328125,
          "content": "[![logo](logo/500px.png?raw=true)](logo/logo.svg)\n\nOverview\n========\n\nLogCabin is a distributed system that provides a small amount of highly\nreplicated, consistent storage. It is a reliable place for other distributed\nsystems to store their core metadata and is helpful in solving cluster\nmanagement issues. LogCabin uses the\n[Raft consensus algorithm](https://raft.github.io) internally and is actually\nthe very first implementation of Raft. It's released under the\n[ISC license](https://en.wikipedia.org/wiki/ISC_license) (equivalent to BSD).\n\nExternal resources:\n- [Slide deck](https://logcabin.github.io/talk/)\n  on LogCabin's usage, operations, and internals\n- [Code-level documentation](https://logcabin.github.io/doxygen/annotated.html)\n  built with Doxygen\n- Recent updates on LogCabin's development on\n  [Diego's blog](http://ongardie.net/blog/+logcabin/)\n\nInformation about releases is in [RELEASES.md](RELEASES.md).\n\nThis README will walk you through how to compile and run LogCabin.\n\nQuestions\n=========\n\nThe best place to ask questions about the LogCabin implementation is on the\n[logcabin-dev](https://groups.google.com/forum/#!forum/logcabin-dev) mailing\nlist. You might also try `#logcabin` on the freenode IRC network, although\nthere aren't always people around. Use GitHub Issues to report problems or\nsuggest features.\n\nFor questions and discussion about the Raft consensus algorithm, which LogCabin\nimplements, use the\n[raft-dev](https://groups.google.com/forum/#!forum/raft-dev) mailing list.\n\nBuilding\n========\n\n[![Build Status](https://travis-ci.org/logcabin/logcabin.svg?branch=master)](https://travis-ci.org/logcabin/logcabin)\n\nPre-requisites:\n\n- Linux x86-64 (v2.6.32 and up should work)\n- git (v1.7 and up should work)\n- scons (v2.0 and v2.3 are known to work)\n- g++ (v4.4 through v4.9 and v5.1 are known to work) or\n  clang (v3.4 through v3.7 are known to work with libstdc++ 4.9, and libc++ is\n  also supported; see [CLANG.md](CLANG.md) for more info)\n- protobuf (v2.6.x suggested, v2.5.x should work, v2.3.x is not supported)\n- crypto++ (v5.6.1 is known to work)\n- doxygen (optional; v1.8.8 is known to work)\n\nIn short, RHEL/CentOS 6 should work, as well as anything more recent.\n\nGet the source code:\n\n    git clone git://github.com/logcabin/logcabin.git\n    cd logcabin\n    git submodule update --init\n\n\nBuild the client library, server binary, and unit tests:\n\n    scons\n\nFor custom build environments, you can place your configuration variables in\n`Local.sc`. For example, that file might look like:\n\n    BUILDTYPE='DEBUG'\n    CXXFLAGS=['-Wno-error']\n\nTo see which configuration parameters are available, run:\n\n    scons --help\n\nRunning basic tests\n===================\n\nIt's a good idea to run the included unit tests before proceeding:\n\n    build/test/test\n\nYou can also run some system-wide tests. This first command runs the smoke\ntests against an in-memory database that is embedded into the LogCabin client\n(no servers are involved):\n\n    build/Examples/SmokeTest --mock && echo 'Smoke test completed successfully'\n\nTo run the same smoke test against a real LogCabin cluster will take some more\nsetup.\n\nRunning a real cluster\n======================\n\nThis section shows you how to run the `HelloWorld` example program against a\nthree-server LogCabin cluster. We'll run all the servers on localhost for now:\n\n - Server 1 will listen on 127.0.0.1:5254\n - Server 2 will listen on 127.0.0.1:5255\n - Server 3 will listen on 127.0.0.1:5256\n\nPort 5254 is LogCabin's default port and is reserved by IANA for LogCabin. The\nother two belong to others and are hopefully not in use on your network.\n\nWe'll first need to create three configuration files. You can base yours off of\nsample.conf, or the following will work for now:\n\nFile `logcabin-1.conf`:\n\n    serverId = 1\n    listenAddresses = 127.0.0.1:5254\n\nFile `logcabin-2.conf`:\n\n    serverId = 2\n    listenAddresses = 127.0.0.1:5255\n\nFile `logcabin-3.conf`:\n\n    serverId = 3\n    listenAddresses = 127.0.0.1:5256\n\nNow you're almost ready to start the servers. First, initialize one of the\nserver's logs with a cluster membership configuration that contains just\nitself:\n\n    build/LogCabin --config logcabin-1.conf --bootstrap\n\nThe server with ID 1 will now have a valid cluster membership configuration in\nits log. At this point, there's only 1 server in the cluster, so only 1 vote is\nneeded: it'll be able to elect itself leader and commit new entries. We can now\nstart this server (leave it running):\n\n    build/LogCabin --config logcabin-1.conf\n\nWe don't want to stop here, though, because the cluster isn't fault-tolerant\nwith just one server! We're going to start two more servers and then add them\nboth to the first server's cluster.\n\nLet's start up the second server in another terminal (leave it running):\n\n    build/LogCabin --config logcabin-2.conf\n\nNote how this server is just idling, awaiting a cluster membership\nconfiguration. It's still not part of the cluster.\n\nStart the third server also (LogCabin checks to make sure all the servers in\nyour new configuration are available before committing to switch to it, just to\nkeep you from doing anything stupid):\n\n    build/LogCabin --config logcabin-3.conf\n\nNow use the reconfiguration command to add the second and third servers to the\ncluster:\n\n    ALLSERVERS=127.0.0.1:5254,127.0.0.1:5255,127.0.0.1:5256\n    build/Examples/Reconfigure --cluster=$ALLSERVERS set 127.0.0.1:5254 127.0.0.1:5255 127.0.0.1:5256\n\nThis `Reconfigure` command is a special LogCabin client. It first queries each\nof the servers given in its positional command line arguments (space-delimited\nafter the command \"set\") to retrieve their server IDs and listening addresses\n(as set in their configuration files). Then, it connects to the cluster given\nby the `--cluster` option (comma-delimited) and asks the leader to set the\ncluster membership to consist of those servers. Note that the existing cluster\nmembers should be included in the positional arguments if they are to remain in\nthe cluster; otherwise, they will be evicted from the cluster.\n\nIf this succeeded, you should see that the first server has added the others to\nthe cluster, and the second and third servers are now participating. It should\nhave output something like:\n\n    Current configuration:\n    Configuration 1:\n    - 1: 127.0.0.1:5254\n\n    Attempting to change cluster membership to the following:\n    1: 127.0.0.1:5254 (given as 127.0.0.1:5254)\n    2: 127.0.0.1:5255 (given as 127.0.0.1:5255)\n    3: 127.0.0.1:5256 (given as 127.0.0.1:5256)\n\n    Membership change result: OK\n\n    Current configuration:\n    Configuration 4:\n    - 1: 127.0.0.1:5254\n    - 2: 127.0.0.1:5255\n    - 3: 127.0.0.1:5256\n\nNote: If you're sharing a single magnetic disk under heavy load for all the\nservers, the cluster may have trouble maintaining a leader. See\n[issue 57](https://github.com/logcabin/logcabin/issues/57) for more details on\nsymptoms and a workaround.\n\nFinally, you can run a LogCabin client to exercise the cluster:\n\n    build/Examples/HelloWorld --cluster=$ALLSERVERS\n\nThat program doesn't do anything very interesting. Another tool called\nTreeOps exposes LogCabin's data structure on the command line:\n\n    echo -n hello | build/Examples/TreeOps --cluster=$ALLSERVERS write /world\n    build/Examples/TreeOps --cluster=$ALLSERVERS dump\n\nSee the --help for a complete listing of the available commands.\n\nYou should be able to kill one server at a time and maintain availability, or\nkill more and restart them and maintain safety (with an availability hiccup).\n\nIf you find it annoying to pass --cluster=$ALLSERVERS everywhere, you can also\nuse a DNS name to return all the IP addresses. However, you will need distinct\nIP addresses for each server, not just distinct ports.\n\nIf you have your own application, you can link it against\n`build/liblogcabin.a`. You'll also need to link against the following\nlibraries:\n\n- pthread\n- protobuf\n- cryptopp\n\nRunning cluster-wide tests\n==========================\n\nThe procedure described above for running a cluster is fairly tedious when you\njust want to run some tests and tear everything down again. Thus,\n`scripts/smoketest.py` automates it. Create a file called `scripts/localconfig.py`\nto override the `smokehosts` and `hosts` variables found in `scripts/config.py`:\n\n    smokehosts = hosts = [\n      ('192.168.2.1', '192.168.2.1', 1),\n      ('192.168.2.2', '192.168.2.2', 2),\n      ('192.168.2.3', '192.168.2.3', 3),\n    ]\n\nThe scripts use this file to when launching servers using SSH. Each tuple in\nthe (smoke)hosts list represents one server, containing:\n\n 1. the address to use for SSH,\n 2. the address to use for LogCabin TCP connections, and\n 3. a unique ID.\n\nEach of these servers should be accessible over SSH without a password and\nshould have the LogCabin directory available in the same filesystem location.\nThe script currently assumes this directory to be on a shared filesystem, such\nas an NFS mount or localhost.\n\nYou may optionally create a `smoketest.conf` file, which can define\nvarious options that apply to all the servers. The servers' listen addresses\nwill be merged with your `smoketest.conf` automatically.\n\nNow you're ready to run:\n\n    scripts/smoketest.py && echo 'Smoke test completed successfully'\n\nThis script can also be hijacked/included to run other test programs.\n\nDocumentation\n=============\n\nTo build the documentation from the source code, run:\n\n    scons docs\n\nThe resulting HTML files will be placed in `docs/doxygen`.\n\nYou can also find this documentation at <https://logcabin.github.io>.\n\nInstallation\n============\n\nTo install a bunch of things on your filesystem, run:\n\n    scons install\n\nAlong with the binaries, this installs a RHEL 6-compatible init script.\n\nIf you don't want these files to pollute your filesystem, you can install the files\nto any given directory as follows (replace `pathtoinstallprefix` in both places\nwith wherever you'd like the files to go):\n\n    scons --install-sandbox=pathtoinstallprefix pathtoinstallprefix\n\nFinally, you can build a binary RPM as follows:\n\n    scons rpm\n\nThis creates a file called `build/logcabin-0.0.1-0.1.alpha.0.x86_64.rpm` or\nsimilar that you can then install using RPM, with the same effect as `scons\ninstall`.\n\nContributing\n============\n\nPlease use GitHub to report issues and send pull requests.\n\nAll commits should pass the pre-commit hooks. Enable them to run before each\ncommit:\n\n    ln -s ../../hooks/pre-commit .git/hooks/pre-commit\n"
        },
        {
          "name": "RELEASE-PROCESS.md",
          "type": "blob",
          "size": 2.7890625,
          "content": "This file describes the procedure for creating a new release of LogCabin. For\nrelease notes, see [RELEASES.md](RELEASES.md).\n\n\nRelease Process\n===============\n\n- Run pre-commit hooks on all supported compilers (use `scripts/hookmatrix.sh`)\n  in both DEBUG and RELEASE mode\n  - All hooks should pass, except for possibly spurious timing-sensitive failures\n\n- Run unit tests under valgrind:\n  - TimingSensitive tests may fail but all others should pass.\n  - The main process heap should have 0 bytes in use at exit and no other\n    valgrind errors shown.\n  - Death tests may leak memory.\n\n- Run smoke test with servers under valgrind:\n  - `./scripts/smoketest.py --binary='valgrind build/LogCabin'`\n  - Increase election timeout in `smoketest.conf` as needed to 5 seconds or so.\n  - Bootstrap heap should have 0 bytes in use at exit and no other valgrind\n    errors shown.\n  - All servers' main process heaps should have 0 bytes in use at exit and no\n    other valgrind errors shown.\n  - Child processes (for snapshots) may leak memory.\n\n- Run smoke test client under valgrind:\n  - `./scripts/smoketest.py --client='valgrind build/Examples/SmokeTest'`\n  - Heap should have 0 bytes in use at exit and no other valgrind errors shown.\n\n- Run smoke test using g++ 4.9 ThreadSanitizer:\n  - Here's a `Local.sc`:\n```\nCXX='g++-4.9'\nCXXFLAGS=['-Werror', '-fsanitize=thread']\nLINKFLAGS=['-fsanitize=thread', '-pie']\nBUILDTYPE='DEBUG'\n```\n  - This may print warnings, but look through them.\n  - As of 1.0 release, see one warning about a read of 8 bytes in\n    LogCabin::Storage::FilesystemUtil::write called from\n    LogCabin::Storage::SegmentedLog::segmentPreparerMain().\n    This might be a false alarm.\n\n- Run build, unit tests, readme.sh, and `scons rpm` on RHEL/CentOS 6.\n  - All should pass.\n\n- Run `scripts/failovertest.py` and\n  `scripts/failovertest.py --client=build/Examples/ReconfigureTest`.\n  - Should reach the timeout with no errors.\n\n- Run `./scripts/smoketest.py --client='build/Examples/Benchmark\n  --writes=1000000 --thread=16' --timeout=45`\n  - Should reach timeout with no errors.\n  - No performance targets at the moment, but 1.0 on /dev/shm on Diego's laptop\n    wrote 3850 objects per second with the default settings (1.1 did the same\n    under g++-4.4-release build).\n\n- In `SConstruct`, update the version number and RPM version number and set the\n  RPM release string to '1'.\n\n- Run `scons rpm` to verify the RPM version number\n\n- Update `RELEASES.md` to describe the released version\n\n- Create a git commit\n\n- Create a signed git tag named vMAJOR.MINOR.PATCH\n\n- In `SConstruct`, update the version number to MAJOR.MINOR.(PATCH+1)-alpha.0,\n  set the RPM version number to MAJOR.MINOR.(PATCH+1), and set the RPM release\n  string to '0.1.alpha.0'.\n\n- Update `RELEASES.md` to include a header for the next version\n\n- Create another git commit\n"
        },
        {
          "name": "RELEASES.md",
          "type": "blob",
          "size": 9.572265625,
          "content": "Versioning\n==========\n\nLogCabin uses [SemVer](http://semver.org) for its version numbers. Its \"public\nAPI\" consists of many components, including its network and disk formats, its\nclient library, and the command line arguments for various executables. These\ncomponents are all released together under a single version number, and the\nrelease notes below describe which components have actually changed.\n\nRelease Process\n===============\n\nSee [RELEASE-PROCESS.md](RELEASE-PROCESS.md).\n\nVersion 1.2.0-alpha.0 (In Development)\n======================================\n\nInternal improvements:\n\n- #200: reset leader election timeout in follower after disk io completes\n\nNew backwards-compatible changes:\n\n- Added new API getConfiguration2, which behaves as getConfiguration\n  but allows a timeout. The API returns a the configuration plus a\n  status code to allow for a TIMEOUT response.\n- Added companion getConfiguration2Ex that behaves as\n  getConfiguration2 but throws exceptions.\n- Added setConfiguration2 which behaves as setConfiguration but allows\n  a timeout.\n- Added companion setConfiguration2Ex that behaves as\n  setConfiguration2 throws exceptions.\n- See https://github.com/logcabin/logcabin/pull/184 for details\n\n\nVersion 1.1.0 (2015-07-26)\n==========================\n\nThis release brings many bug fixes and improvements since v1.0.0. All users are\nstrongly encouraged to upgrade.\n\nBug fixes (high severity):\n\n- Fixes packaging up very large AppendEntries requests. Before, it was possible\n  for a leader to send a non-contiguous list of entries to the follower, and\n  the follower would end up with a corrupt log (issue #160). Before, it was\n  also possible for packing up the requests to take so long as to cause\n  availability and performance problems (issue #161).\n- Fixes occasional hang when exiting due to unsafe access of a boolean flag\n  (issue #144).\n- Fixes hang when exiting while removing servers from the cluster configuration\n  (issue #183).\n- Fixes client waiting past its timeout on another client's connection attempt\n  (issue #173).\n\nBug fixes (low severity):\n\n- Fixes `Core::Debug::DebugMessage` move constructor, where `processName` and\n  `threadName` were not moved over as they should have been (git 77d7f6b).\n- Fixes signed integer overflow bug under aggressive optimizing compilers\n  affecting `SteadyTimeConverter`, which is only used in producing ServerStats\n  (git 6473400). Turns on `-fno-strict-overflow` compiler setting.\n- Fixes repeated PANIC in InstallSnapshot RPC after a server restarts while\n  receiving a snapshot (issue #174). This could result in a temporary\n  availability issue that would resolve itself on the next term change.\n- Fixes failing conditional tree operations after setting a condition with a\n  relative path (issue #177).\n- Fixes event loop thread dumping server stats to the debug log, which had the\n  potential for delays and deadlock (we never saw deadlock occur in practice,\n  however). Now the stats are dumped from a separate thread (issue #159).\n- Fixes PANIC due to \"No route to host\" error after many minutes of the network\n  interface going down (issue #154). This is considered low severity as it was\n  unlikely to affect overall cluster availability.\n\nInternal improvements:\n\n- Adds gcc 5.1 (which required no changes; issue #141) and clang 3.4, 3.5, 3.6,\n  and 3.7 (issue #9) as supported compilers.\n- `liblogcabin.a` is now compiled with `-fPIC`, so it can be linked into shared\n  object (.so) files (git 1ca169c).\n- Optimizes setting `nextIndex` on leaders by capping it to just past the\n  follower's last log index. This helps with followers that are new or have\n  fallen far behind (git fcbacbb).\n- Clients now make a best effort attempt to close their sessions when they shut\n  down gracefully (issue #116). Before, client sessions were only ever expired\n  after a timeout. This state could accumulate quickly when running short-lived\n  clients in a tight loop. Enabling this change requires all servers to be\n  updated (so that the state machine is updated); new clients talking to old\n  clusters will issue a warning that they are unable to close their sessions.\n- SegmentedLog now coalesces back-to-back fdatasync calls, making batch log\n  appends much more efficient (issue #165).\n- Leaders will now limit the amount of data they send to a follower when their\n  connection to that follower is lost, which reduces wasted bandwidth\n  (git e238fa6).\n\nNew backwards-compatible changes:\n\n- `LogLevel`, `getLogFilename`, `setLogFilename`, `reopenLogFromFilename`,\n  `getLogPolicy`, `logPolicyFromString`, `logPolicyToString` were introduced in\n  `include/LogCabin/Debug.h`.\n- The LogCabin daemon will now reopen its log file on `SIGUSR2` (useful for log\n  rotation; issue #150). Signal handling was not listed as part of LogCabin's\n  public API until now; signals listed in `--help` messages are now subject to\n  semantic versioning.\n- The `build/Examples/ServerControl` or `/usr/bin/logcabinctl` program can be\n  used to inspect and manipulate an individual server's state (issue #151). Its\n  command line is now part of LogCabin's public API.\n- All clients now have `--verbose` and `--verbosity` to control the debug log\n  level and policy (issue #153). The server's config file now has a new option\n  `logPolicy` to control the same.\n- Exceptions due to bad user input are now caught by broad exception handlers.\n  They were uncaught before, causing the process to abort() and create\n  unnecessary core files (issue #166).\n- Adds several new ServerStats metrics.\n\nChanges to unstable APIs:\n\n- `build/Examples/ServerStats` or `/usr/bin/logcabin-serverstats` along with\n  `scripts/serverstats.py` have been removed. The `logcabinctl` program can now\n  be used to fetch the stats instead, and the Python wrapper wasn't kept\n  up-to-date anyhow. External clients linked to old versions of\n  `LogCabin::Client::Cluster::getServerStats()` will not work with new servers,\n  and `logcabinctl stats get` and other clients linked to the same function will\n  not work with old servers.\n- `Examples/HelloWorld` is no longer installed to\n  `/usr/bin/logcabin-helloworld`.\n- Fixes RPM build on Scons 2.3.0 (git e77d217).\n- Removes the 'reload' command from the Red Hat init script, which would\n  previously kill the server (git 28044cb).\n- Changes the log path in the Red Hat init script to\n  `/var/log/logcabin/logcabin.log` (git e9e466f).\n- Changes the RPM package and Red Hat init script to launch the LogCabin server\n  as user `logcabin` instead of `root` (issue #178). Changes the storage path.\n- The client library in testing mode (`MockClientImpl`) will now return obvious\n  timeout errors, making it easier to unit test client code (git a8b22be).\n\nVersion 1.0.0 (2015-04-29)\n==========================\n\nThis is the first stable release of LogCabin. We encourage others to try this\nrelease out, and we believe it to be ready for production use. As it is the\nvery first release, users are advised to check back frequently in case serious\nbugs are found.\n\nThe public API with respect to versioning consists of the following:\n\n- `include/LogCabin/Client.h`: API\n- `include/LogCabin/Debug.h`: API\n- `build/LogCabin` or `/usr/bin/logcabind`: command line\n- `build/Examples/Reconfigure` or `/usr/bin/logcabin-reconfigure`: command line\n- `build/Examples/TreeOps` or `/usr/bin/logcabin`: command line\n- config file format and options: defined by `sample.conf`\n- client-to-server network protocol: compatibility\n- server-to-server network protocol: compatibility\n- replicated state machine behavior: compatibility\n- storage layout on disk: compatibility\n- snapshot format on disk: compatibility\n- log format on disk of `Segmented` storage module: compatibility\n\nCommand line APIs consist of argv, zero vs nonzero exit statuses, and side\neffects, but not necessarily stdout and stderr. These are documented with `-h`\nand `--help` flags.\n\nThe interfaces/protocols indicating \"compatibility\" are not documented\npublicly, but interoperability with different versions of the code is\nmaintained. Interoperability with third-party implementations is not\nguaranteed, as there is no explicit protocol specification.\n\n- Network protocols indicating \"compatibility\" provide forwards and backwards\n  compatibility: older code and newer code must be able to interoperate within\n  a MAJOR release. This is desirable in the network protocols to allow\n  non-disruptive rolling upgrades.\n\n- Disk formats indicating \"compatibility\" provide backwards compatibility:\n  newer code must be able to accept formats produced by older code within a\n  MAJOR release. However, older code may not be able to accept disk formats\n  produced by newer code. This reflects the expectation that servers will be\n  upgraded monotonically from older to newer versions but never back.\n\n- The replicated state machine (which contains the core Tree data structure\n  that clients interact with, among other things) provides backwards\n  compatibility for a limited window of time. LogCabin will only update the\n  externally visible behavior of its replicated state machine when all\n  currently known servers support the new version. At that point, servers\n  running the old version of the code may not be able to participate in the\n  cluster (they will most likely PANIC repeatedly until their code is\n  upgraded).\n\n\nThe following are specifically excluded from the public API and are not subject\nto semantic versioning (they may be added to the public API in future\nreleases):\n\n- client library ABI\n- `scripts/logcabin-init-redhat` command line\n- various other scripts\n- `build/Examples/ServerStats` command line\n- various other `build/Examples` executables\n- `build/Storage/Tool` command line\n- `ServerStats` ProtoBuf fields\n- log format on disk of `SimpleFile` storage module\n"
        },
        {
          "name": "RPC",
          "type": "tree",
          "content": null
        },
        {
          "name": "SConstruct",
          "type": "blob",
          "size": 15.7919921875,
          "content": "from distutils.version import LooseVersion as Version\nimport re\nimport sys\nimport os\nimport subprocess\n\n# Python 2.6 doesn't have subprocess.check_output\ntry:\n    subprocess.check_output\nexcept AttributeError:\n    def check_output_compat(*popenargs, **kwargs):\n        # This function was copied from Python 2.7's subprocess module.\n        # This function only is:\n        # Copyright (c) 2003-2005 by Peter Astrand <astrand@lysator.liu.se>\n        # Licensed to PSF under a Contributor Agreement.\n        # See http://www.python.org/2.4/license for licensing details.\n        if 'stdout' in kwargs:\n            raise ValueError('stdout argument not allowed, it will be overridden.')\n        process = subprocess.Popen(stdout=subprocess.PIPE, *popenargs, **kwargs)\n        output, unused_err = process.communicate()\n        retcode = process.poll()\n        if retcode:\n            cmd = kwargs.get(\"args\")\n            if cmd is None:\n                cmd = popenargs[0]\n            raise subprocess.CalledProcessError(retcode, cmd, output=output)\n        return output\n    subprocess.check_output = check_output_compat\n\n# Access through env['VERSION'], env['RPM_VERSION'], and env['RPM_RELEASE'] to\n# allow users to override these. RPM versioning is explained here:\n# https://fedoraproject.org/wiki/Packaging:NamingGuidelines#NonNumericRelease\n_VERSION = '1.2.0-alpha.0'\n_RPM_VERSION = '1.2.0'\n_RPM_RELEASE = '0.1.alpha.0'\n\nopts = Variables('Local.sc')\n\nopts.AddVariables(\n    (\"CC\", \"C Compiler\"),\n    (\"CPPPATH\", \"The list of directories that the C preprocessor \"\n                \"will search for include directories\", []),\n    (\"CXX\", \"C++ Compiler\"),\n    (\"CXX_FAMILY\", \"C++ compiler family (gcc or clang)\", \"auto\"),\n    (\"CXX_VERSION\", \"C++ compiler version\", \"auto\"),\n    (\"CXXFLAGS\", \"Options that are passed to the C++ compiler\", []),\n    (\"PROTOCXXFLAGS\", \"Options that are passed to the C++ compiler \"\n                      \"for ProtoBuf files\", []),\n    (\"GTESTCXXFLAGS\", \"Options that are passed to the C++ compiler \"\n                      \"for compiling gtest\", []),\n    (\"LINKFLAGS\", \"Options that are passed to the linker\", []),\n    (\"AS\", \"Assembler\"),\n    (\"LIBPATH\", \"Library paths that are passed to the linker\", []),\n    (\"LINK\", \"Linker\"),\n    (\"BUILDTYPE\", \"Build type (RELEASE or DEBUG)\", \"DEBUG\"),\n    (\"VERBOSE\", \"Show full build information (0 or 1)\", \"0\"),\n    (\"NUMCPUS\", \"Number of CPUs to use for build (0 means auto).\", \"0\"),\n    (\"VERSION\", \"Override version string\", _VERSION),\n    (\"RPM_VERSION\", \"Override version number for rpm\", _RPM_VERSION),\n    (\"RPM_RELEASE\", \"Override release string for rpm\", _RPM_RELEASE),\n)\n\nenv = Environment(options = opts,\n                  tools = ['default', 'protoc', 'packaging'],\n                  ENV = os.environ)\nHelp(opts.GenerateHelpText(env))\n\n# Needed for Clang Static Analyzer's scan-build tool\nenv[\"CC\"] = os.getenv(\"CC\") or env[\"CC\"]\nenv[\"CXX\"] = os.getenv(\"CXX\") or env[\"CXX\"]\nfor k, v in os.environ.items():\n    if k.startswith(\"CCC_\"):\n        env[\"ENV\"][k] = v\n\ndef detect_compiler():\n    reflags = re.IGNORECASE|re.MULTILINE\n    output = subprocess.check_output([env['CXX'], '-v'],\n                                     stderr=subprocess.STDOUT)\n    m = re.search(r'gcc version (\\d+\\.\\d+\\.\\d+)',\n                  output, reflags)\n    if m is not None:\n        env['CXX_FAMILY'] = 'gcc'\n        env['CXX_VERSION'] = m.group(1)\n        return\n    m = re.search(r'clang version (\\d+\\.\\d+\\.\\d+)',\n                  output, reflags)\n    if m is not None:\n        env['CXX_FAMILY'] = 'clang'\n        env['CXX_VERSION'] = m.group(1)\n        return\n\nif env['CXX_FAMILY'].lower() == 'auto':\n    try:\n        detect_compiler()\n        print 'Detected compiler %s %s' % (env['CXX_FAMILY'],\n                                           env['CXX_VERSION'])\n    except BaseException as e:\n        print 'Could not detect compiler: %s' % e\n        pass\n\nCXX_STANDARD = 'c++11'\n\nif (env['CXX_FAMILY'] == 'gcc' and\n    Version(env['CXX_VERSION']) < Version('4.7')):\n    CXX_STANDARD = 'c++0x'\n\nif env['CXX_FAMILY'] == 'gcc':\n    env.Prepend(CXXFLAGS = [\n        \"-Wall\",\n        \"-Wextra\",\n        \"-Wcast-align\",\n        \"-Wcast-qual\",\n        \"-Wconversion\",\n        \"-Weffc++\",\n        \"-Wformat=2\",\n        \"-Wmissing-format-attribute\",\n        \"-Wno-non-template-friend\",\n        \"-Wno-unused-parameter\",\n        \"-Woverloaded-virtual\",\n        \"-Wwrite-strings\",\n        \"-DSWIG\", # For some unknown reason, this suppresses some definitions\n                  # in headers generated by protobuf 2.6 (but not 2.5) that we\n                  # don't use and that cause warnings with -Weffc++.\n    ])\nelif env['CXX_FAMILY'] == 'clang':\n    # I couldn't find a descriptive list of warnings for clang, so it's easier\n    # to enable them all with -Weverything and then disable the problematic\n    # ones.\n    env.Prepend(CXXFLAGS = [\n        '-Wno-c++98-compat-pedantic',\n        '-Wno-covered-switch-default',\n        '-Wno-deprecated',\n        '-Wno-disabled-macro-expansion',\n        '-Wno-documentation-unknown-command',\n        '-Wno-exit-time-destructors',\n        '-Wno-float-equal',\n        '-Wno-global-constructors',\n        '-Wno-gnu-zero-variadic-macro-arguments',\n        '-Wno-missing-noreturn',\n        '-Wno-missing-prototypes',\n        '-Wno-missing-variable-declarations',\n        '-Wno-packed',\n        '-Wno-padded',\n        '-Wno-reserved-id-macro',\n        '-Wno-shadow',\n        '-Wno-shift-sign-overflow',\n        '-Wno-switch-enum',\n        '-Wno-undef',\n        '-Wno-unknown-warning-option',\n        '-Wno-unused-macros',\n        '-Wno-unused-member-function',\n        \"-Wno-unused-parameter\",\n        '-Wno-used-but-marked-unused',\n        '-Wno-vla',\n        '-Wno-vla-extension',\n        '-Wno-weak-vtables',\n    ])\n\n    # Clang 3.4 is known to emit warnings without -Wno-unreachable-code:\n    if Version(env['CXX_VERSION']) < Version('3.5'):\n        env.Prepend(CXXFLAGS = ['-Wno-unreachable-code'])\n\n    env.Prepend(CXXFLAGS = ['-Weverything'])\n\nenv.Prepend(CXXFLAGS = [\n    \"-std=%s\" % CXX_STANDARD,\n    \"-fno-strict-overflow\",\n    \"-fPIC\",\n])\nenv.Prepend(PROTOCXXFLAGS = [\n    \"-std=%s\" % CXX_STANDARD,\n    \"-fno-strict-overflow\",\n    \"-fPIC\",\n])\nenv.Prepend(GTESTCXXFLAGS = [\n    \"-std=%s\" % CXX_STANDARD,\n    \"-fno-strict-overflow\",\n    \"-fPIC\",\n])\n\nif env[\"BUILDTYPE\"] == \"DEBUG\":\n    env.Append(CPPFLAGS = [ \"-g\", \"-DDEBUG\" ])\nelif env[\"BUILDTYPE\"] == \"RELEASE\":\n    env.Append(CPPFLAGS = [ \"-DNDEBUG\", \"-O2\" ])\nelse:\n    print \"Error BUILDTYPE must be RELEASE or DEBUG\"\n    sys.exit(-1)\n\nif env[\"VERBOSE\"] == \"0\":\n    env[\"CCCOMSTR\"] = \"Compiling $SOURCE\"\n    env[\"CXXCOMSTR\"] = \"Compiling $SOURCE\"\n    env[\"SHCCCOMSTR\"] = \"Compiling $SOURCE\"\n    env[\"SHCXXCOMSTR\"] = \"Compiling $SOURCE\"\n    env[\"ARCOMSTR\"] = \"Creating library $TARGET\"\n    env[\"LINKCOMSTR\"] = \"Linking $TARGET\"\n\nenv.Append(CPPPATH = '#')\nenv.Append(CPPPATH = '#/include')\n\n# Define protocol buffers builder to simplify SConstruct files\ndef Protobuf(env, source):\n    # First build the proto file\n    cc = env.Protoc(os.path.splitext(source)[0] + '.pb.cc',\n                    source,\n                    PROTOCPROTOPATH = [\".\"],\n                    PROTOCPYTHONOUTDIR = \".\",\n                    PROTOCOUTDIR = \".\")[1]\n    # Then build the resulting C++ file with no warnings\n    return env.StaticObject(cc,\n                            CXXFLAGS = env['PROTOCXXFLAGS'] + ['-Ibuild'])\nenv.AddMethod(Protobuf)\n\ndef GetNumCPUs():\n    if env[\"NUMCPUS\"] != \"0\":\n        return int(env[\"NUMCPUS\"])\n    if os.sysconf_names.has_key(\"SC_NPROCESSORS_ONLN\"):\n        cpus = os.sysconf(\"SC_NPROCESSORS_ONLN\")\n        if isinstance(cpus, int) and cpus > 0:\n            return 2*cpus\n        else:\n            return 2\n    return 2*int(os.popen2(\"sysctl -n hw.ncpu\")[1].read())\n\nenv.SetOption('num_jobs', GetNumCPUs())\n\nobject_files = {}\nExport('object_files')\n\nExport('env')\nSConscript('Core/SConscript', variant_dir='build/Core')\nSConscript('Event/SConscript', variant_dir='build/Event')\nSConscript('RPC/SConscript', variant_dir='build/RPC')\nSConscript('Protocol/SConscript', variant_dir='build/Protocol')\nSConscript('Tree/SConscript', variant_dir='build/Tree')\nSConscript('Client/SConscript', variant_dir='build/Client')\nSConscript('Storage/SConscript', variant_dir='build/Storage')\nSConscript('Server/SConscript', variant_dir='build/Server')\nSConscript('Examples/SConscript', variant_dir='build/Examples')\nSConscript('test/SConscript', variant_dir='build/test')\n\n# This function is taken from http://www.scons.org/wiki/PhonyTargets\ndef PhonyTargets(env = None, **kw):\n    if not env: env = DefaultEnvironment()\n    for target,action in kw.items():\n        env.AlwaysBuild(env.Alias(target, [], action))\n\nPhonyTargets(check = \"scripts/cpplint.py\")\nPhonyTargets(lint = \"scripts/cpplint.py\")\nPhonyTargets(doc = \"doxygen docs/Doxyfile\")\nPhonyTargets(docs = \"doxygen docs/Doxyfile\")\nPhonyTargets(tags = \"ctags -R --exclude=build --exclude=docs .\")\n\nclientlib = env.StaticLibrary(\"build/logcabin\",\n                  (object_files['Client'] +\n                   object_files['Tree'] +\n                   object_files['Protocol'] +\n                   object_files['RPC'] +\n                   object_files['Event'] +\n                   object_files['Core']))\nenv.Default(clientlib)\n\ndaemon = env.Program(\"build/LogCabin\",\n            ([\"build/Server/Main.cc\"] +\n             object_files['Server'] +\n             object_files['Storage'] +\n             object_files['Tree'] +\n             object_files['Client'] +\n             object_files['Protocol'] +\n             object_files['RPC'] +\n             object_files['Event'] +\n             object_files['Core']),\n            LIBS = [ \"pthread\", \"protobuf\", \"rt\", \"cryptopp\" ])\nenv.Default(daemon)\n\nstorageTool = env.Program(\"build/Storage/Tool\",\n            ([\"build/Storage/Tool.cc\"] +\n             [ # these proto files should maybe move into Protocol\n                \"build/Server/SnapshotMetadata.pb.o\",\n                \"build/Server/SnapshotStateMachine.pb.o\",\n             ] +\n             object_files['Storage'] +\n             object_files['Tree'] +\n             object_files['Protocol'] +\n             object_files['Core']),\n            LIBS = [ \"pthread\", \"protobuf\", \"rt\", \"cryptopp\" ])\nenv.Default(storageTool)\n\n# Create empty directory so that it can be installed to /var/log/logcabin\ntry:\n    os.mkdir(\"build/emptydir\")\nexcept OSError:\n    pass # directory exists\n\n### scons install target\n\nenv.InstallAs('/etc/init.d/logcabin',           'scripts/logcabin-init-redhat')\nenv.InstallAs('/usr/bin/logcabinctl',           'build/Client/ServerControl')\nenv.InstallAs('/usr/bin/logcabind',             'build/LogCabin')\nenv.InstallAs('/usr/bin/logcabin',              'build/Examples/TreeOps')\nenv.InstallAs('/usr/bin/logcabin-benchmark',    'build/Examples/Benchmark')\nenv.InstallAs('/usr/bin/logcabin-reconfigure',  'build/Examples/Reconfigure')\nenv.InstallAs('/usr/bin/logcabin-smoketest',    'build/Examples/SmokeTest')\nenv.InstallAs('/usr/bin/logcabin-storage',      'build/Storage/Tool')\nenv.InstallAs('/var/log/logcabin',              'build/emptydir')\nenv.Alias('install', ['/etc', '/usr', '/var'])\n\n\n#### 'scons rpm' target\n\n# Work-around for older versions of SCons (2.3.0) that had LC_ALL set to\n# lowercase c instead of uppercase C. SCons hg changeset 2943:8e42d865bdda in\n# Nov 3, 2013 fixed this upstream in SCons. Without this workaround, building\n# the RPM with 2.3.0 would sometimes fail.\nenv['RPM'] = 'LC_ALL=C rpmbuild'\n\n# monkey-patch for SCons.Tool.packaging.rpm.collectintargz, which tries to put\n# way too many files into the source tarball (the source tarball should only\n# contain the installed files, since we're not building it)\ndef decent_collectintargz(target, source, env):\n    tarball = env['SOURCE_URL'].split('/')[-1]\n    from SCons.Tool.packaging import src_targz\n    tarball = src_targz.package(env, source=source, target=tarball,\n                                PACKAGEROOT=env['PACKAGEROOT'])\n    return target, tarball\nimport SCons.Tool.packaging.rpm as RPMPackager\nRPMPackager.collectintargz = decent_collectintargz\n\n# set the install target in the .spec file to just copy over the files that\n# 'scons install' would install. Default scons behavior is to invoke scons in\n# the source tarball, which doesn't make a ton of sense unless you're doing the\n# build in there.\ninstall_commands = []\nfor target in env.FindInstalledFiles():\n    parent = target.get_dir()\n    source = target.sources[0]\n    install_commands.append('mkdir -p $RPM_BUILD_ROOT%s' % parent)\n    install_commands.append('cp -r %s $RPM_BUILD_ROOT%s' % (source, target))\n\npre_commands = [\n    ('/usr/bin/getent group logcabin ||' +\n     '/usr/sbin/groupadd -r logcabin'),\n    ('/usr/bin/getent passwd logcabin ||' +\n     '/usr/sbin/useradd -r -g logcabin -d / -s /sbin/nologin logcabin'),\n]\n\npost_commands = [\n    'chown -R logcabin:logcabin /var/log/logcabin',\n    'mkdir -p /var/lib/logcabin',\n    'chown logcabin:logcabin /var/lib/logcabin',\n]\n\n# We probably don't want rpm to strip binaries.\n# This is kludged into the spec file.\nskip_stripping_binaries_commands = [\n    # The normal __os_install_post consists of:\n    #    %{_rpmconfigdir}/brp-compress\n    #    %{_rpmconfigdir}/brp-strip %{__strip}\n    #    %{_rpmconfigdir}/brp-strip-static-archive %{__strip}\n    #    %{_rpmconfigdir}/brp-strip-comment-note %{__strip} %{__objdump}\n    # as shown by: rpm --showrc | grep ' __os_install_post' -A10\n    #\n    # brp-compress just gzips manpages, which is fine. The others are probably\n    # undesirable.\n    #\n    # This can go anywhere in the spec file.\n    '%define __os_install_post /usr/lib/rpm/brp-compress',\n\n    # Your distro may also be configured to build -debuginfo packages by default,\n    # stripping the binaries and placing their symbols there. Let's not do that\n    # either.\n    #\n    # This has to go at the top of the spec file.\n    '%global _enable_debug_package 0',\n    '%global debug_package %{nil}',\n]\n\nPACKAGEROOT = 'logcabin-%s' % env['RPM_VERSION']\n\nrpms=RPMPackager.package(env,\n    target            = ['logcabin-%s' % env['RPM_VERSION']],\n    source            = env.FindInstalledFiles(),\n    X_RPM_INSTALL     = '\\n'.join(install_commands),\n    X_RPM_PREINSTALL  = '\\n'.join(pre_commands),\n    X_RPM_POSTINSTALL = '\\n'.join(post_commands),\n    PACKAGEROOT       = PACKAGEROOT,\n    NAME              = 'logcabin',\n    VERSION           = env['RPM_VERSION'],\n    PACKAGEVERSION    = env['RPM_RELEASE'],\n    LICENSE           = 'ISC',\n    SUMMARY           = 'LogCabin is clustered consensus deamon',\n    X_RPM_GROUP       = ('Application/logcabin' + '\\n' +\n                         '\\n'.join(skip_stripping_binaries_commands)),\n    DESCRIPTION       =\n    'LogCabin is a distributed system that provides a small amount of\\n'\n    'highly replicated, consistent storage. It is a reliable place for\\n'\n    'other distributed systems to store their core metadata and\\n'\n    'is helpful in solving cluster management issues.',\n)\n\n# Rename .rpm files into build/\ndef rename(env, target, source):\n    for (t, s) in zip(target, source):\n        os.rename(str(s), str(t))\n\n# Rename files used to build .rpm files\ndef remove_sources(env, target, source):\n    garbage = set()\n    for s in source:\n        garbage.update(s.sources)\n        for s2 in s.sources:\n            garbage.update(s2.sources)\n    for g in list(garbage):\n        if str(g).endswith('.spec'):\n            garbage.update(g.sources)\n    for g in garbage:\n        if env['VERBOSE'] == '1':\n            print 'rm %s' % g\n        try:\n            os.remove(str(g))\n        except OSError:\n            os.rmdir(str(g))\n\n# Rename PACKAGEROOT directory and subdirectories (should be empty)\ndef remove_packageroot(env, target, source):\n    if env['VERBOSE'] == '1':\n        print 'rm -r %s' % PACKAGEROOT\n    import shutil\n    shutil.rmtree(str(PACKAGEROOT))\n\n# Wrap cleanup around (moved) RPM targets\nrpms = env.Command(['build/%s' % str(rpm) for rpm in rpms],\n                   rpms,\n                   [rename, remove_sources, remove_packageroot])\n\nenv.Alias('rpm', rpms)\n"
        },
        {
          "name": "Server",
          "type": "tree",
          "content": null
        },
        {
          "name": "Storage",
          "type": "tree",
          "content": null
        },
        {
          "name": "Tree",
          "type": "tree",
          "content": null
        },
        {
          "name": "docs",
          "type": "tree",
          "content": null
        },
        {
          "name": "gtest",
          "type": "commit",
          "content": null
        },
        {
          "name": "hookmatrix.sample",
          "type": "tree",
          "content": null
        },
        {
          "name": "hooks",
          "type": "tree",
          "content": null
        },
        {
          "name": "include",
          "type": "tree",
          "content": null
        },
        {
          "name": "logo",
          "type": "tree",
          "content": null
        },
        {
          "name": "sample.conf",
          "type": "blob",
          "size": 9.7177734375,
          "content": "# This is a sample configuration file for LogCabin.\n\n\n\n### Server ###\n\n# Each server needs a unique ID. Server IDs are used to tell if two servers are\n# the same, so they must be unique across the cluster. There is no default\n# value. There are two reasonable ways to generate IDs: one is to assign them\n# by incrementing a counter somewhere; another is to create random IDs. This is\n# meant to be an unsigned 64-bit integer, but you might want to stick to the\n# range 1 through (2^63 - 1).\n#\n# serverId = -REQUIRED-\n\n# This server will bind to and listen on all of the following addresses. These\n# addresses are given to clients and other servers to connect to this one, so\n# they must be routable from both clients and servers. As a result, 0.0.0.0\n# (all available addresses) and 127.0.0.1 are probably not going to work.\n# To provide more than one address, separate them with commas.\n#\n# listenAddresses = -REQUIRED-\n\n# An opaque string used to prevent accidental communication across LogCabin\n# clusters. If set, this string will be checked when creating each\n# client-to-server and server-to-server session. If the recipient's has a cluster\n# UUID that does not match the UUID in the request, the connection will be\n# closed with an error.\n#\n# The default (empty string) allows communication with any client and server of\n# any cluster initially. Once this process discovers a cluster UUID, it will\n# insist on using it when creating future sessions.\n#\n# Set this to a unique string for each cluster to avoid accidental\n# communication across LogCabin clusters (which could have disastrous effects\n# on your data).\n#\n# clusterUUID =\n\n\n\n### Misc ###\n\n# Controls the verbosity of the server's debug logs. The format is a\n# comma-separated list of LEVEL or PATTERN@LEVEL rules. The available levels\n# are: SILENT, ERROR, WARNING, NOTICE, and VERBOSE. A pattern matches a\n# filename prefix or suffix (from the root directory of the LogCabin\n# repository). Example: Client@NOTICE,Test.cc@SILENT,VERBOSE.\n# This setting was added in LogCabin v1.1.0.\n#\n# logPolicy = NOTICE\n\n# The maximum number of threads to launch for each RPC service (default: 16).\n#\n# maxThreads = 16\n\n# Each servers will dump a bunch of information about itself periodically in\n# its debug log at the NOTICE level. This is the number of milliseconds between\n# state dumps. A value of 0 means to never print these messages to the log.\n# Note: you can also request a server to dump its information by sending it the\n# signal SIGUSR1.\n#\n# statsDumpIntervalMilliseconds = 60000\n\n# The connect() call to initiate a TCP connection can take ages to time out on\n# Linux in some circumstances, especially if the remote host is not responding.\n# To avoid waiting so long, LogCabin clients and servers give up on a connect()\n# call after this many milliseconds. This applies to server-to-server\n# connections (which this config file will affect). It may also be set for the\n# client library in the map of options passed to the Cluster constructor.\n#\n# tcpConnectTimeoutMilliseconds = 1000\n\n# The client side of a TCP connection will actively send out pings when it has\n# an outstanding RPC but suspects the server of being down. It will send out a\n# ping after tcpHeartbeatTimeoutMilliseconds, and if it doesn't get a response\n# after another tcpHeartbeatTimeoutMilliseconds, it will close the session.\n# This applies to server-to-server connections (which this config file will\n# affect). It may also be set for the client library in the map of options\n# passed to the Cluster constructor.\n#\n# tcpHeartbeatTimeoutMilliseconds = 500\n\n\n\n### Raft ###\n\n# The number of milliseconds that a follower waits without hearing from a\n# current leader or granting its vote, before it becomes a candidate and starts\n# a new election. Until we understand how Raft would behave, it's strongly\n# recommended that you use the same election timeout setting on every server.\n#\n# electionTimeoutMilliseconds = 500\n\n# A leader sends RPCs at least this often, even if there is no data to\n# send. Default and sane value: electionTimeoutMilliseconds / 2.\n#\n# heartbeatPeriodMilliseconds = 250\n\n# A candidate or leader waits this long after an RPC fails before sending\n# another one, so as to not overwhelm the network with retries.\n# Default value: electionTimeoutMilliseconds / 2.\n#\n# rpcFailureBackoffMilliseconds = 250\n\n# If true and compiled with BUILDTYPE=DEBUG mode, runs through some additional\n# checks inside the Raft module. These are very costly, especially if you have\n# a large number of entries.\n#\n# raftDebug = no\n\n\n\n### Storage Module ###\n\n# You need to specify the storage module to use.\n# Different storage modules require different additional options.\n#\n# WARNING: it is unsafe to change this setting once the server has participated\n# in a cluster, since the server would come online with an empty log. The safe\n# way to change this is to first remove the server from the cluster through a\n# cluster membership change, then clear out the storage, and add the server\n# to the cluster again.\n#\n# Default: Segmented\n\n# The Memory storage module will store all data in memory only. It will\n# probably eat your data, and it's impossible to bootstrap. This is\n# experimental and is not part of the public API.\n#\n# storageModule = Memory\n\n# The SimpleFile storage module stores each log entry in a separate file. It's\n# fairly easy to see what the server is storing, but it's not efficient. This\n# is untested and is not part of the public API.\n#\n# storageModule = SimpleFile\n#\n# A filesystem path for this storage module to operate in. Its parent directory\n# must exist.\n#\n# storagePath = storage\n\n# The Segmented storage module writes log entries sequentially into large files\n# called segments, typically 8 MB in size. This should make efficient use the\n# disk while still working atop the filesystem.\n#\n# The Segmented-Text module is similar to Segmented but uses a slow,\n# human-readable record format. While this may be useful for development, it is\n# not part of the public API.\n#\n# storageModule = Segmented\n#\n# A filesystem path for this storage module to operate in. Its parent directory\n# must exist.\n#\n# storagePath = storage\n#\n# The checksum algorithm to use for records on disk. Most of the crypto++\n# algorithms are available, but only CRC32 is part of the public API.\n#\n# storageChecksum = CRC32\n#\n# The number of segment files that the Segmented storage module will try to open\n# ahead of time. Once Log::append() fills up the head of the log, it will grab\n# one of these files to use for the next entry. If there are no files\n# available, the append will be blocked temporarily, and you'll see a WARNING\n# in the server's debug logs.\n#\n# storageOpenSegments = 3\n#\n# The maximum size for each segment that this storage module will create. Note\n# that the server will happily read in segments of any size at boot time; this\n# option only applies to newly written segments. If an entry is appended to the\n# log that is larger than this value, it will be written to its own segment,\n# regardless of the size. Default: 8 MB.\n#\n# storageSegmentBytes = 8388608\n#\n# If true and compiled with BUILDTYPE=DEBUG mode, runs through some additional\n# checks inside the Segmented storage module. These may be costly, especially\n# if you have a large number of entries.\n#\n# storageDebug = no\n\n\n\n### Snapshotting ###\n\n# Each server takes a snapshot once the following conditions are met:\n#   log size > snapshotMinLogSize, AND\n#   log size > snapshotRatio * last snapshot size\n#\n# Size in bytes of smallest log to snapshot. Default: 64 MB.\n#\n# snapshotMinLogSize = 67108864\n#\n# Maximum log size as multiple of last snapshot size until server should\n# snapshot.\n#\n# snapshotRatio = 4\n#\n# Snapshotting is done in a separate child process, and if there was a bug in\n# LogCabin or its libraries, this child might be prone to deadlock (see\n# https://github.com/logcabin/logcabin/issues/121). To detect this deadlock,\n# the parent process includes a watchdog thread that makes sure the child\n# writes something into the snapshot file during each interval; the length of\n# the interval is given by this setting. If the interval elapses with no\n# progress made, the child is killed, and another one is started shortly\n# thereafter. A value of 0 disables this functionality altogether.\n#\n# snapshotWatchdogMilliseconds = 10000\n\n\n\n### Advanced ###\n\n# If true, this server as leader will not cause the replicated state machine to\n# update to a new version. This could potentially be used in the future to test\n# a new code release without irreversibly changing the state machine state.\n# This behavior is subject to change and is not part of the public API.\n#\n# disableStateMachineUpdates = false\n\n# Controls how long Raft waits after failing to advance the state machine to\n# a new version. This can happen when:\n# - The servers do not currently support a common version, or\n# - This server has not yet received version information from all other\n#   servers, or\n# - An advance state machine log entry failed to commit (probably due to lost\n#   leadership).\n# The system shouldn't be very sensitive to changes in this setting, and you\n# shouldn't need to change this unless you're encountering problems with it.\n#\n# stateMachineUpdaterBackoffMilliseconds = 10000\n\n# The state machine logs messages when it receives a command or query that is\n# not understood in the current running version. This controls the minimum\n# interval between such messages to prevent spamming the debug log. You\n# shouldn't need to change this unless you're encountering problems with it.\n#\n# stateMachineUnknownRequestMessageBackoffMilliseconds = 10000\n\n\n# A leader will pack at most this many entries into an AppendEntries request\n# message. This helps bound processing time when entries are very small in\n# size. You shouldn't need to change this unless you're encountering problems\n# with it.\n#\n# maxLogEntriesPerRequest = 5000\n"
        },
        {
          "name": "scripts",
          "type": "tree",
          "content": null
        },
        {
          "name": "site_scons",
          "type": "tree",
          "content": null
        },
        {
          "name": "test",
          "type": "tree",
          "content": null
        },
        {
          "name": "travisci_rsa.enc",
          "type": "blob",
          "size": 1.640625,
          "content": null
        }
      ]
    }
  ]
}