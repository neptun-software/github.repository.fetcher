{
  "metadata": {
    "timestamp": 1736565822014,
    "page": 754,
    "hasNextPage": true,
    "endCursor": "Y3Vyc29yOjc2MA==",
    "completionStatus": "IN_PROGRESS"
  },
  "repositories": [
    {
      "nameWithOwner": "ggerganov/wave-share",
      "stars": 2206,
      "defaultBranch": "master",
      "files": [
        {
          "name": ".gitignore",
          "type": "blob",
          "size": 0.044921875,
          "content": "build\nbuild_timestamp.h\ncompile_*\n*.js\n*.wasm\n"
        },
        {
          "name": "CMakeLists.txt",
          "type": "blob",
          "size": 0.9345703125,
          "content": "cmake_minimum_required (VERSION 2.8)\nproject (wave-share)\n\noption(USE_FINDSDL2 \"Use the FindSDL2.cmake script\" OFF)\n\nif (NOT CMAKE_BUILD_TYPE)\n    set(CMAKE_BUILD_TYPE Release)\nendif()\n\nset(CMAKE_MODULE_PATH ${CMAKE_CURRENT_SOURCE_DIR}/cmake)\nset(CMAKE_CXX_FLAGS \"${CMAKE_CXX_FLAGS} -std=c++11 -W -Wall -Wno-long-long -pedantic\")\n\n#\n## Dependencies\nfind_package(Threads REQUIRED)\nfind_package(SDL2)\n\nif (NOT USE_FINDSDL2 AND NOT SDL2_FOUND)\n    message(WARNING \"Unable to find SDL2 library. It is either not installed or CMake cannot find it.\"\n        \" In the latter case, setting the USE_FINDSDL2 variable might help:\\n\"\n        \"   $ cmake -D USE_FINDSDL2 ..\"\n        )\n\n    message(FATAL_ERROR \"Aborting\")\nendif()\n\nstring(STRIP \"${SDL2_LIBRARIES}\" SDL2_LIBRARIES)\n\nadd_executable(wave-share main.cpp)\ntarget_include_directories(wave-share PUBLIC ${SDL2_INCLUDE_DIRS})\ntarget_link_libraries(wave-share PUBLIC ${CMAKE_THREAD_LIBS_INIT} ${SDL2_LIBRARIES})\n"
        },
        {
          "name": "LICENSE",
          "type": "blob",
          "size": 1.046875,
          "content": "MIT License\n\nCopyright (c) 2018 Georgi Gerganov\n\nPermission is hereby granted, free of charge, to any person obtaining a copy\nof this software and associated documentation files (the \"Software\"), to deal\nin the Software without restriction, including without limitation the rights\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\ncopies of the Software, and to permit persons to whom the Software is\nfurnished to do so, subject to the following conditions:\n\nThe above copyright notice and this permission notice shall be included in all\ncopies or substantial portions of the Software.\n\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\nSOFTWARE.\n"
        },
        {
          "name": "README.md",
          "type": "blob",
          "size": 7.51953125,
          "content": "# wave-share\n\nA proof-of-concept for WebRTC signaling using sound. Works with all devices that have microphone + speakers. Runs in the\nbrowser.\n\nNearby devices negotiate the WebRTC connection by exchanging the necessary Session Description Protocol (SDP) data via\na sequence of audio tones. Upon successful negotiation, a local WebRTC connection is established between the browsers allowing data to be exchanged via LAN.\n\nSee it in action (2min video):\n\n<a href=\"http://www.youtube.com/watch?feature=player_embedded&v=d30QDrKyQkg\" target=\"_blank\"><img src=\"http://img.youtube.com/vi/d30QDrKyQkg/0.jpg\" alt=\"CG++ Data over sound\" width=\"360\" height=\"270\" border=\"10\" /></a>\n\nTry it yourself: [ggerganov.github.io/wave-share](https://ggerganov.github.io/wave-share)\n\n**Latest news:** \\\nI've extracted the data-over-sound algorithm into a standalone library called [ggwave](https://github.com/ggerganov/ggwave).\\\nIt can be embedded easily into other projects.\n\n## How it works\n\nThe [WebRTC](https://en.wikipedia.org/wiki/WebRTC) technology allows two browsers running on different devices to connect with each other and exchange data. There is no need to install plugins or download applications. To initiate the connection, the peers exchange contact information (ip address, network ports, session id, etc.). This process is called \"signaling\". The WebRTC specification does not define any standard for signaling - the contact exchange can be achieved by any protocol or technology.\n\nIn this project the signaling is performed via sound. The signaling sequence looks like this:\n\n  - Peer A broadcasts an offer for a WebRTC connection by encoding the session data into audio tones\n  - Nearby peer(s) capture the sound emitted by peer A and decode the WebRTC session data\n  - Peer B, who wants to establish connection with peer A, responds with an audio answer. The answer has peer B's contact information encoded in it. Additionally, peer B starts trying to connect to peer A\n  - Peer A receives the answer from peer B, decodes the transmitted contact data and allows peer B to connect\n  - Connection is established\n  \n<p align=\"center\"><img src=\"media/wave-share-scheme2.png\"></p>\n  \nThe described signaling sequence does not involve a signaling server. Therefore, an application using signaling through sound can be, for example, served by a static web page. The only requirement is to have control over the audio output/capture devices.\n\nAn obvious limitation (feature) of the current approach is that only nearby devices (e.g. within the same room) can establish connection with each other. Moreover, the devices have to be connected in the same local network, because NAT is not available.\n\n## Sound Tx/Rx\n\nThe data communicated through sound contains the contact information required to initialize the WebRTC connection. This data is stored in the [Session Description Protocol (SDP)](https://en.wikipedia.org/wiki/Session_Description_Protocol) format. Since data-over-sound has significant limitations in terms of bandwidth and robustness it is desirable to transmit as few data as possible. Therefore, the SDP is stripped from all irrelevant information and only the essential data needed to establish the connection is transmitted. Currently, the sound packet containing the minimum required SDP data has the following format:\n\n| Size, [B] | Description |\n| --------- | ----------- |\n| 1         | Type of the SDP - Offer or Answer |\n| 1         | Packet size in bytes (not including ECC bytes) |\n| 4         | IP address of the transmitting peer |\n| 2         | Network port that will be used for the communication |\n| 32        | SHA-256 fingerprint of the session data |\n| 40        | ICE Credentials - 16 bytes username + 24 bytes password |\n| 32        | ECC correction bytes used to correct errors during Tx |\n\nThe total size of the audio packet is 112 bytes. With the current audio encoding algorithm, the SDP packet can be transmitted in 5-10 seconds (depending on the Tx protocol used). Using slower protocols provides more reliable transmission in noisy environments or if the communicating devices are far from each other.\n\n### Data-to-sound encoding\n\nThe current approach uses a multi-frequency [Frequency-Shift Keying (FSK)](https://en.wikipedia.org/wiki/Frequency-shift_keying) modulation scheme. The data to be transmitted is first split into 4-bit chunks. At each moment of time, 3 bytes are transmitted using 6 tones - one tone for each 4-bit chunk. The 6 tones are emitted in a 4.5kHz range divided in 96 equally-spaced frequencies:\n\n| Freq, [Hz]   | Value, [bits]   | Freq, [Hz]   | Value, [bits]   | ... | Freq, [Hz]   | Value, [bits]   |\n| ------------ | --------------- | ------------ | --------------- | --- | ------------ | --------------- |\n| `F0 + 00*dF` | Chunk 0: `0000` | `F0 + 16*dF` | Chunk 1: `0000` | ... | `F0 + 80*dF` | Chunk 5: `0000` |\n| `F0 + 01*dF` | Chunk 0: `0001` | `F0 + 17*dF` | Chunk 1: `0001` | ... | `F0 + 81*dF` | Chunk 5: `0001` |\n| `F0 + 02*dF` | Chunk 0: `0010` | `F0 + 18*dF` | Chunk 1: `0010` | ... | `F0 + 82*dF` | Chunk 5: `0010` |\n| ...          | ...             | ...          | ...             | ... | ...          | ...             |\n| `F0 + 14*dF` | Chunk 0: `1110` | `F0 + 30*dF` | Chunk 1: `1110` | ... | `F0 + 94*dF` | Chunk 5: `1110` |\n| `F0 + 15*dF` | Chunk 0: `1111` | `F0 + 31*dF` | Chunk 1: `1111` | ... | `F0 + 95*dF` | Chunk 5: `1111` |\n\nFor all protocols: `dF = 46.875 Hz`. For non-ultrasonic protocols: `F0 = 1875.000 Hz`. For ultrasonic protocols: `F0 = 15000.000 Hz`.\n\n## Getting the local IP address\n\nFor convenience, a [simple WebRTC hack](https://github.com/diafygi/webrtc-ips) is used to automatically detect the local IP address of your machine, so you don't have to provide it manually. However, the latest WebRTC spec prevents this from being possible for security reasons, so at some point this \"feature\" will stop working in all browsers. For example, [it no longer works on Safari](https://stackoverflow.com/questions/46925857/get-the-client-ip-address-with-javascript-on-safari).\n\n## Build\n\n### Web Assembly module `wave.wasm`\n\nYou will need an Emscripten compiler. Run the ``compile.sh`` script.\n\n### CLI tool `wave-share`\n\n---\n\n**Important:** This CLI tool was the prototype for the now standalone library [ggwave](https://github.com/ggerganov/ggwave). Make sure to check it out, as it has more up-to-date examples for the application of this data-over-sound type of communication.\n\n---\n\nThis is a simple tool that receives and sends data using the explained `wave-share` sound tx/rx protocol. Type some text on the standard input and press Enter to transmit.\n\n```bash\n# build\ngit clone https://github.com/ggerganov/wave-share\ncd wave-share && mkdir build && cd build\ncmake ..\nmake\n\n# running\n./wave-share\n```\n\nHere is a short video demonstrating how to use the CLI tool:\n\n<a href=\"http://www.youtube.com/watch?feature=player_embedded&v=TcfjCMCyqF0\" target=\"_blank\"><img src=\"http://img.youtube.com/vi/TcfjCMCyqF0/0.jpg\" alt=\"Wave-share: command line tool\" width=\"360\" height=\"270\" border=\"10\" /></a>\n\n## Known problems / stuff to improve\n\n  - Does not work with: IE, IE Edge, Chrome/Firefox on iOS, Safari on macOS\n  - Ultrasonic sound transmission does not work on most devices. Probably hardware limitations?\n  - In presence of multiple local networks, cannot currently select which one to use. Always the first one is used\n  - There is occasionally sound cracking during transmission. Need to optimize the Tx code\n  - The size of the emscripten generated .js is too big (~1MB). Rewrite in pure JS?\n  - On mobile, using Firefox, the page can remain running in the background even after closing the tab\n"
        },
        {
          "name": "cmake",
          "type": "tree",
          "content": null
        },
        {
          "name": "compile.sh",
          "type": "blob",
          "size": 0.6630859375,
          "content": "#!/bin/bash\n\necho \"static const char * BUILD_TIMESTAMP=\\\"`date`\\\";\" > build_timestamp.h\n\nem++ -Wall -Wextra -O3 -std=c++11 -s USE_SDL=2 -s WASM=1 ./main.cpp -o wave.js \\\n    -s EXPORTED_FUNCTIONS='[\"_getText\", \"_getSampleRate\", \"_setText\", \"_getAverageRxTime_ms\", \"_setParameters\",\n                            \"_getFramesLeftToRecord\", \"_getFramesToRecord\",\n                            \"_getFramesLeftToAnalyze\", \"_getFramesToAnalyze\",\n                            \"_hasDeviceOutput\", \"_hasDeviceCapture\", \"_doInit\",\n                            \"_setTxMode\",\n                            \"_main\"]' \\\n    -s EXTRA_EXPORTED_RUNTIME_METHODS='[\"ccall\", \"cwrap\", \"writeArrayToMemory\"]'\n"
        },
        {
          "name": "main.cpp",
          "type": "blob",
          "size": 39.0859375,
          "content": "/*! \\file main.cpp\n *  \\brief Send/Receive data through sound\n *  \\author Georgi Gerganov\n */\n\n#include \"reed-solomon/rs.hpp\"\n\n#include <SDL2/SDL.h>\n#include <SDL2/SDL_audio.h>\n\n#include <cmath>\n#include <cstdio>\n#include <array>\n#include <string>\n#include <chrono>\n#include <ctime>\n#include <algorithm>\n#include <map>\n#include <complex>\n\n#ifndef M_PI\n#define M_PI 3.14159265358979323846f\n#endif\n\n#ifdef __EMSCRIPTEN__\n#include \"build_timestamp.h\"\n#include \"emscripten/emscripten.h\"\n#else\n#include <thread>\n#include <iostream>\n#endif\n\n#ifdef main\n#undef main\n#endif\n\nstatic char *g_captureDeviceName = nullptr;\nstatic int g_captureId = -1;\nstatic int g_playbackId = -1;\n\nstatic bool g_isInitialized = false;\nstatic int g_totalBytesCaptured = 0;\n\nstatic SDL_AudioDeviceID devid_in = 0;\nstatic SDL_AudioDeviceID devid_out = 0;\n\nstruct DataRxTx;\nstatic DataRxTx *g_data = nullptr;\n\nnamespace {\n\nconstexpr double kBaseSampleRate = 48000.0;\nconstexpr auto kMaxSamplesPerFrame = 1024;\nconstexpr auto kMaxDataBits = 256;\nconstexpr auto kMaxDataSize = 256;\nconstexpr auto kMaxLength = 140;\nconstexpr auto kMaxSpectrumHistory = 4;\nconstexpr auto kMaxRecordedFrames = 64*10;\nconstexpr auto kDefaultFixedLength = 82;\n\n// FFT routines taken from https://stackoverflow.com/a/37729648/4039976\n\nint log2(int N) {\n    int k = N, i = 0;\n    while(k) {\n        k >>= 1;\n        i++;\n    }\n    return i - 1;\n}\n\nint check(int n) {\n    return n > 0 && (n & (n - 1)) == 0;\n}\n\nint reverse(int N, int n) {\n    int j, p = 0;\n    for(j = 1; j <= log2(N); j++) {\n        if(n & (1 << (log2(N) - j)))\n            p |= 1 << (j - 1);\n    }\n    return p;\n}\n\nvoid ordina(std::complex<float>* f1, int N) {\n    std::complex<float> f2[kMaxSamplesPerFrame];\n    for(int i = 0; i < N; i++)\n        f2[i] = f1[reverse(N, i)];\n    for(int j = 0; j < N; j++)\n        f1[j] = f2[j];\n}\n\nvoid transform(std::complex<float>* f, int N) {\n    ordina(f, N);    //first: reverse order\n    std::complex<float> *W;\n    W = (std::complex<float> *)malloc(N / 2 * sizeof(std::complex<float>));\n    W[1] = std::polar(1., -2. * M_PI / N);\n    W[0] = 1;\n    for(int i = 2; i < N / 2; i++)\n        W[i] = pow(W[1], i);\n    int n = 1;\n    int a = N / 2;\n    for(int j = 0; j < log2(N); j++) {\n        for(int i = 0; i < N; i++) {\n            if(!(i & n)) {\n                std::complex<float> temp = f[i];\n                std::complex<float> Temp = W[(i * a) % (n * a)] * f[i + n];\n                f[i] = temp + Temp;\n                f[i + n] = temp - Temp;\n            }\n        }\n        n *= 2;\n        a = a / 2;\n    }\n    free(W);\n}\n\nvoid FFT(std::complex<float>* f, int N, float d) {\n    transform(f, N);\n    for(int i = 0; i < N; i++)\n        f[i] *= d; //multiplying by step\n}\n\nvoid FFT(float * src, std::complex<float>* dst, int N, float d) {\n    for (int i = 0; i < N; ++i) {\n        dst[i].real(src[i]);\n        dst[i].imag(0);\n    }\n    FFT(dst, N, d);\n}\n\nenum TxMode {\n    FixedLength = 0,\n    VariableLength,\n};\n\nusing AmplitudeData   = std::array<float, kMaxSamplesPerFrame>;\nusing AmplitudeData16 = std::array<int16_t, kMaxRecordedFrames*kMaxSamplesPerFrame>;\nusing SpectrumData    = std::array<float, kMaxSamplesPerFrame>;\nusing RecordedData    = std::array<float, kMaxRecordedFrames*kMaxSamplesPerFrame>;\n\ninline void addAmplitudeSmooth(const AmplitudeData & src, AmplitudeData & dst, float scalar, int startId, int finalId, int cycleMod, int nPerCycle) {\n    int nTotal = nPerCycle*finalId;\n    float frac = 0.15f;\n    float ds = frac*nTotal;\n    float ids = 1.0f/ds;\n    int nBegin = frac*nTotal;\n    int nEnd = (1.0f - frac)*nTotal;\n    for (int i = startId; i < finalId; i++) {\n        float k = cycleMod*finalId + i;\n        if (k < nBegin) {\n            dst[i] += scalar*src[i]*(k*ids);\n        } else if (k > nEnd) {\n            dst[i] += scalar*src[i]*(((float)(nTotal) - k)*ids);\n        } else {\n            dst[i] += scalar*src[i];\n        }\n    }\n}\n\ntemplate <class T>\nfloat getTime_ms(const T & tStart, const T & tEnd) {\n    return ((float)(std::chrono::duration_cast<std::chrono::microseconds>(tEnd - tStart).count()))/1000.0;\n}\n\nint getECCBytesForLength(int len) {\n    return std::max(4, 2*(len/5));\n}\n}\n\nstruct DataRxTx {\n    DataRxTx(int aSampleRateOut, int aSampleRate, int aSamplesPerFrame, int aSampleSizeB, const char * text) {\n        sampleSizeBytes = aSampleSizeB;\n        sampleRate = aSampleRate;\n        sampleRateOut = aSampleRateOut;\n        samplesPerFrame = aSamplesPerFrame;\n\n        init(strlen(text), text);\n    }\n\n    void init(int textLength, const char * stext) {\n        if (textLength > ::kMaxLength) {\n            printf(\"Truncating data from %d to 140 bytes\\n\", textLength);\n            textLength = ::kMaxLength;\n        }\n\n        const uint8_t * text = reinterpret_cast<const uint8_t *>(stext);\n        frameId = 0;\n        nIterations = 0;\n        hasData = false;\n\n        isamplesPerFrame = 1.0f/samplesPerFrame;\n        sendVolume = ((double)(paramVolume))/100.0f;\n        hzPerFrame = sampleRate/samplesPerFrame;\n        ihzPerFrame = 1.0/hzPerFrame;\n        framesPerTx = paramFramesPerTx;\n\n        nDataBitsPerTx = paramBytesPerTx*8;\n        nECCBytesPerTx = (txMode == ::TxMode::FixedLength) ? paramECCBytesPerTx : getECCBytesForLength(textLength);\n\n        framesToAnalyze = 0;\n        framesLeftToAnalyze = 0;\n        framesToRecord = 0;\n        framesLeftToRecord = 0;\n        nBitsInMarker = 16;\n        nMarkerFrames = 16;\n        nPostMarkerFrames = 0;\n        sendDataLength = (txMode == ::TxMode::FixedLength) ? ::kDefaultFixedLength : textLength + 3;\n\n        d0 = paramFreqDelta/2;\n        freqDelta_hz = hzPerFrame*paramFreqDelta;\n        freqStart_hz = hzPerFrame*paramFreqStart;\n        if (paramFreqDelta == 1) {\n            d0 = 1;\n            freqDelta_hz *= 2;\n        }\n\n        outputBlock.fill(0);\n        encodedData.fill(0);\n\n        for (int k = 0; k < (int) phaseOffsets.size(); ++k) {\n            phaseOffsets[k] = (M_PI*k)/(nDataBitsPerTx);\n        }\n#ifdef __EMSCRIPTEN__\n        std::random_shuffle(phaseOffsets.begin(), phaseOffsets.end());\n#endif\n\n        for (int k = 0; k < (int) dataBits.size(); ++k) {\n            double freq = freqStart_hz + freqDelta_hz*k;\n            dataFreqs_hz[k] = freq;\n\n            double phaseOffset = phaseOffsets[k];\n            double curHzPerFrame = sampleRateOut/samplesPerFrame;\n            double curIHzPerFrame = 1.0/curHzPerFrame;\n            for (int i = 0; i < samplesPerFrame; i++) {\n                double curi = i;\n                bit1Amplitude[k][i] = std::sin((2.0*M_PI)*(curi*isamplesPerFrame)*(freq*curIHzPerFrame) + phaseOffset);\n            }\n            for (int i = 0; i < samplesPerFrame; i++) {\n                double curi = i;\n                bit0Amplitude[k][i] = std::sin((2.0*M_PI)*(curi*isamplesPerFrame)*((freq + hzPerFrame*d0)*curIHzPerFrame) + phaseOffset);\n            }\n        }\n\n        if (rsData) delete rsData;\n        if (rsLength) delete rsLength;\n\n        if (txMode == ::TxMode::FixedLength) {\n            rsData = new RS::ReedSolomon(kDefaultFixedLength, nECCBytesPerTx);\n        } else {\n            rsData = new RS::ReedSolomon(textLength, nECCBytesPerTx);\n            rsLength = new RS::ReedSolomon(1, 2);\n        }\n\n        if (textLength > 0) {\n            static std::array<char, ::kMaxDataSize> theData;\n            theData.fill(0);\n\n            if (txMode == ::TxMode::FixedLength) {\n                for (int i = 0; i < textLength; ++i) theData[i] = text[i];\n                rsData->Encode(theData.data(), encodedData.data());\n            } else {\n                theData[0] = textLength;\n                for (int i = 0; i < textLength; ++i) theData[i + 1] = text[i];\n                rsData->Encode(theData.data() + 1, encodedData.data() + 3);\n                rsLength->Encode(theData.data(), encodedData.data());\n            }\n\n            hasData = true;\n        }\n\n        // Rx\n        receivingData = false;\n        analyzingData = false;\n\n        sampleAmplitude.fill(0);\n\n        sampleSpectrum.fill(0);\n        for (auto & s : sampleAmplitudeHistory) {\n            s.fill(0);\n        }\n\n        rxData.fill(0);\n\n        for (int i = 0; i < samplesPerFrame; ++i) {\n            fftOut[i].real(0.0f);\n            fftOut[i].imag(0.0f);\n        }\n    }\n\n    void send() {\n        int samplesPerFrameOut = (sampleRateOut/sampleRate)*samplesPerFrame;\n        if (sampleRateOut != sampleRate) {\n            printf(\"Resampling from %d Hz to %d Hz\\n\", (int) sampleRate, (int) sampleRateOut);\n        }\n\n        while(hasData) {\n            int nBytesPerTx = nDataBitsPerTx/8;\n            std::fill(outputBlock.begin(), outputBlock.end(), 0.0f);\n            std::uint16_t nFreq = 0;\n\n            if (sampleRateOut != sampleRate) {\n                for (int k = 0; k < nDataBitsPerTx; ++k) {\n                    double freq = freqStart_hz + freqDelta_hz*k;\n\n                    double phaseOffset = phaseOffsets[k];\n                    double curHzPerFrame = sampleRateOut/samplesPerFrame;\n                    double curIHzPerFrame = 1.0/curHzPerFrame;\n                    for (int i = 0; i < samplesPerFrameOut; i++) {\n                        double curi = (i + frameId*samplesPerFrameOut);\n                        bit1Amplitude[k][i] = std::sin((2.0*M_PI)*(curi*isamplesPerFrame)*(freq*curIHzPerFrame) + phaseOffset);\n                    }\n                    for (int i = 0; i < samplesPerFrameOut; i++) {\n                        double curi = (i + frameId*samplesPerFrameOut);\n                        bit0Amplitude[k][i] = std::sin((2.0*M_PI)*(curi*isamplesPerFrame)*((freq + hzPerFrame*d0)*curIHzPerFrame) + phaseOffset);\n                    }\n                }\n            }\n\n            if (frameId < nMarkerFrames) {\n                nFreq = nBitsInMarker;\n\n                for (int i = 0; i < nBitsInMarker; ++i) {\n                    if (i%2 == 0) {\n                        ::addAmplitudeSmooth(bit1Amplitude[i], outputBlock, sendVolume, 0, samplesPerFrameOut, frameId, nMarkerFrames);\n                    } else {\n                        ::addAmplitudeSmooth(bit0Amplitude[i], outputBlock, sendVolume, 0, samplesPerFrameOut, frameId, nMarkerFrames);\n                    }\n                }\n            } else if (frameId < nMarkerFrames + nPostMarkerFrames) {\n                nFreq = nBitsInMarker;\n\n                for (int i = 0; i < nBitsInMarker; ++i) {\n                    if (i%2 == 0) {\n                        ::addAmplitudeSmooth(bit0Amplitude[i], outputBlock, sendVolume, 0, samplesPerFrameOut, frameId - nMarkerFrames, nPostMarkerFrames);\n                    } else {\n                        ::addAmplitudeSmooth(bit1Amplitude[i], outputBlock, sendVolume, 0, samplesPerFrameOut, frameId - nMarkerFrames, nPostMarkerFrames);\n                    }\n                }\n            } else if (frameId <\n                       (nMarkerFrames + nPostMarkerFrames) +\n                       ((sendDataLength + nECCBytesPerTx)/nBytesPerTx + 2)*framesPerTx) {\n                int dataOffset = frameId - nMarkerFrames - nPostMarkerFrames;\n                int cycleModMain = dataOffset%framesPerTx;\n                dataOffset /= framesPerTx;\n                dataOffset *= nBytesPerTx;\n\n                dataBits.fill(0);\n\n                if (paramFreqDelta > 1) {\n                    for (int j = 0; j < nBytesPerTx; ++j) {\n                        for (int i = 0; i < 8; ++i) {\n                            dataBits[j*8 + i] = encodedData[dataOffset + j] & (1 << i);\n                        }\n                    }\n\n                    for (int k = 0; k < nDataBitsPerTx; ++k) {\n                        ++nFreq;\n                        if (dataBits[k] == false) {\n                            ::addAmplitudeSmooth(bit0Amplitude[k], outputBlock, sendVolume, 0, samplesPerFrameOut, cycleModMain, framesPerTx);\n                            continue;\n                        }\n                        ::addAmplitudeSmooth(bit1Amplitude[k], outputBlock, sendVolume, 0, samplesPerFrameOut, cycleModMain, framesPerTx);\n                    }\n                } else {\n                    for (int j = 0; j < nBytesPerTx; ++j) {\n                        {\n                            uint8_t d = encodedData[dataOffset + j] & 15;\n                            dataBits[(2*j + 0)*16 + d] = 1;\n                        }\n                        {\n                            uint8_t d = encodedData[dataOffset + j] & 240;\n                            dataBits[(2*j + 1)*16 + (d >> 4)] = 1;\n                        }\n                    }\n\n                    for (int k = 0; k < 2*nBytesPerTx*16; ++k) {\n                        if (dataBits[k] == 0) continue;\n\n                        ++nFreq;\n                        if (k%2) {\n                            ::addAmplitudeSmooth(bit0Amplitude[k/2], outputBlock, sendVolume, 0, samplesPerFrameOut, cycleModMain, framesPerTx);\n                        } else {\n                            ::addAmplitudeSmooth(bit1Amplitude[k/2], outputBlock, sendVolume, 0, samplesPerFrameOut, cycleModMain, framesPerTx);\n                        }\n                    }\n                }\n            } else if (txMode == ::TxMode::VariableLength && frameId <\n                       (nMarkerFrames + nPostMarkerFrames) +\n                       ((sendDataLength + nECCBytesPerTx)/nBytesPerTx + 2)*framesPerTx +\n                       (nMarkerFrames)) {\n                nFreq = nBitsInMarker;\n\n                int fId = frameId - ((nMarkerFrames + nPostMarkerFrames) + ((sendDataLength + nECCBytesPerTx)/nBytesPerTx + 2)*framesPerTx);\n                for (int i = 0; i < nBitsInMarker; ++i) {\n                    if (i%2 == 0) {\n                        ::addAmplitudeSmooth(bit0Amplitude[i], outputBlock, sendVolume, 0, samplesPerFrameOut, fId, nMarkerFrames);\n                    } else {\n                        ::addAmplitudeSmooth(bit1Amplitude[i], outputBlock, sendVolume, 0, samplesPerFrameOut, fId, nMarkerFrames);\n                    }\n                }\n            } else {\n                textToSend = \"\";\n                hasData = false;\n            }\n\n            if (nFreq == 0) nFreq = 1;\n            float scale = 1.0f/nFreq;\n            for (int i = 0; i < samplesPerFrameOut; ++i) {\n                outputBlock[i] *= scale;\n            }\n\n            for (int i = 0; i < samplesPerFrameOut; ++i) {\n                outputBlock16[frameId*samplesPerFrameOut + i] = std::round(32000.0*outputBlock[i]);\n            }\n            ++frameId;\n        }\n        SDL_QueueAudio(devid_out, outputBlock16.data(), 2*frameId*samplesPerFrameOut);\n    }\n\n    void receive() {\n        static int nCalls = 0;\n        static float tSum_ms = 0.0f;\n        auto tCallStart = std::chrono::high_resolution_clock::now();\n\n        if (needUpdate) {\n            init(0, \"\");\n            needUpdate = false;\n        }\n\n        while (hasData == false) {\n            // read capture data\n            int nBytesRecorded = SDL_DequeueAudio(devid_in, sampleAmplitude.data(), samplesPerFrame*sampleSizeBytes);\n            if (nBytesRecorded != 0) {\n                {\n                    sampleAmplitudeHistory[historyId] = sampleAmplitude;\n\n                    if (++historyId >= ::kMaxSpectrumHistory) {\n                        historyId = 0;\n                    }\n\n                    if (historyId == 0 && (receivingData == false || (receivingData && txMode == ::TxMode::VariableLength))) {\n                        std::fill(sampleAmplitudeAverage.begin(), sampleAmplitudeAverage.end(), 0.0f);\n                        for (auto & s : sampleAmplitudeHistory) {\n                            for (int i = 0; i < samplesPerFrame; ++i) {\n                                sampleAmplitudeAverage[i] += s[i];\n                            }\n                        }\n                        float norm = 1.0f/::kMaxSpectrumHistory;\n                        for (int i = 0; i < samplesPerFrame; ++i) {\n                            sampleAmplitudeAverage[i] *= norm;\n                        }\n\n                        // calculate spectrum\n                        std::copy(sampleAmplitudeAverage.begin(), sampleAmplitudeAverage.begin() + samplesPerFrame, fftIn.data());\n\n                        FFT(fftIn.data(), fftOut.data(), samplesPerFrame, 1.0);\n\n                        double fsum = 0.0;\n                        for (int i = 0; i < samplesPerFrame; ++i) {\n                            sampleSpectrum[i] = (fftOut[i].real()*fftOut[i].real() + fftOut[i].imag()*fftOut[i].imag());\n                            fsum += sampleSpectrum[i];\n                        }\n                        for (int i = 1; i < samplesPerFrame/2; ++i) {\n                            sampleSpectrum[i] += sampleSpectrum[samplesPerFrame - i];\n                        }\n\n                        if (fsum < 1e-10) {\n                            g_totalBytesCaptured = 0;\n                        } else {\n                            g_totalBytesCaptured += nBytesRecorded;\n                        }\n                    }\n\n                    if (framesLeftToRecord > 0) {\n                        std::copy(sampleAmplitude.begin(),\n                                  sampleAmplitude.begin() + samplesPerFrame,\n                                  recordedAmplitude.data() + (framesToRecord - framesLeftToRecord)*samplesPerFrame);\n\n                        if (--framesLeftToRecord <= 0) {\n                            std::fill(sampleSpectrum.begin(), sampleSpectrum.end(), 0.0f);\n                            analyzingData = true;\n                        }\n                    }\n                }\n\n                if (analyzingData) {\n                    int nBytesPerTx = nDataBitsPerTx/8;\n                    int stepsPerFrame = 16;\n                    int step = samplesPerFrame/stepsPerFrame;\n\n                    int offsetStart = 0;\n\n                    framesToAnalyze = nMarkerFrames*stepsPerFrame;\n                    framesLeftToAnalyze = framesToAnalyze;\n\n                    bool isValid = false;\n                    //for (int ii = nMarkerFrames*stepsPerFrame/2; ii < (nMarkerFrames + nPostMarkerFrames)*stepsPerFrame; ++ii) {\n                    for (int ii = nMarkerFrames*stepsPerFrame - 1; ii >= nMarkerFrames*stepsPerFrame/2; --ii) {\n                        offsetStart = ii;\n                        bool knownLength = txMode == ::TxMode::FixedLength;\n                        int encodedOffset = (txMode == ::TxMode::FixedLength) ? 0 : 3;\n\n                        for (int itx = 0; itx < 1024; ++itx) {\n                            int offsetTx = offsetStart + itx*framesPerTx*stepsPerFrame;\n                            if (offsetTx >= recvDuration_frames*stepsPerFrame) {\n                                break;\n                            }\n\n                            std::copy(\n                                recordedAmplitude.begin() + offsetTx*step,\n                                recordedAmplitude.begin() + offsetTx*step + samplesPerFrame, fftIn.data());\n\n                            for (int k = 1; k < framesPerTx-1; ++k) {\n                                for (int i = 0; i < samplesPerFrame; ++i) {\n                                    fftIn[i] += recordedAmplitude[(offsetTx + k*stepsPerFrame)*step + i];\n                                }\n                            }\n\n                            FFT(fftIn.data(), fftOut.data(), samplesPerFrame, 1.0);\n\n                            for (int i = 0; i < samplesPerFrame; ++i) {\n                                sampleSpectrum[i] = (fftOut[i].real()*fftOut[i].real() + fftOut[i].imag()*fftOut[i].imag());\n                            }\n                            for (int i = 1; i < samplesPerFrame/2; ++i) {\n                                sampleSpectrum[i] += sampleSpectrum[samplesPerFrame - i];\n                            }\n\n                            uint8_t curByte = 0;\n                            if (paramFreqDelta > 1) {\n                                for (int i = 0; i < nDataBitsPerTx; ++i) {\n                                    int k = i%8;\n                                    int bin = std::round(dataFreqs_hz[i]*ihzPerFrame);\n                                    if (sampleSpectrum[bin] > 1*sampleSpectrum[bin + d0]) {\n                                        curByte += 1 << k;\n                                    } else if (sampleSpectrum[bin + d0] > 1*sampleSpectrum[bin]) {\n                                    } else {\n                                    }\n                                    if (k == 7) {\n                                        encodedData[itx*nBytesPerTx + i/8] = curByte;\n                                        curByte = 0;\n                                    }\n                                }\n                            } else {\n                                for (int i = 0; i < 2*nBytesPerTx; ++i) {\n                                    int bin = std::round(dataFreqs_hz[0]*ihzPerFrame) + i*16;\n\n                                    int kmax = 0;\n                                    double amax = 0.0;\n                                    for (int k = 0; k < 16; ++k) {\n                                        if (sampleSpectrum[bin + k] > amax) {\n                                            kmax = k;\n                                            amax = sampleSpectrum[bin + k];\n                                        }\n                                    }\n\n                                    if (i%2) {\n                                        curByte += (kmax << 4);\n                                        encodedData[itx*nBytesPerTx + i/2] = curByte;\n                                        curByte = 0;\n                                    } else {\n                                        curByte = kmax;\n                                    }\n                                }\n                            }\n\n                            if (txMode == ::TxMode::VariableLength) {\n                                if (itx*nBytesPerTx > 3 && knownLength == false) {\n                                    if ((rsLength->Decode(encodedData.data(), rxData.data()) == 0) && (rxData[0] <= 140)) {\n                                        knownLength = true;\n                                    } else {\n                                        break;\n                                    }\n                                }\n                            }\n                        }\n\n                        if (txMode == ::TxMode::VariableLength && knownLength) {\n                            if (rsData) delete rsData;\n                            rsData = new RS::ReedSolomon(rxData[0], ::getECCBytesForLength(rxData[0]));\n                        }\n\n                        if (knownLength) {\n                            int decodedLength = rxData[0];\n                            if (rsData->Decode(encodedData.data() + encodedOffset, rxData.data()) == 0) {\n                                printf(\"Decoded length = %d\\n\", decodedLength);\n                                if (txMode == ::TxMode::FixedLength && rxData[0] == 'A') {\n                                    printf(\"[ANSWER] Received sound data successfully!\\n\");\n                                } else if (txMode == ::TxMode::FixedLength && rxData[0] == 'O') {\n                                    printf(\"[OFFER]  Received sound data successfully!\\n\");\n                                } else {\n                                    std::string s((char *) rxData.data(), decodedLength);\n                                    printf(\"Received sound data successfully: '%s'\\n\", s.c_str());\n                                }\n                                framesToRecord = 0;\n                                isValid = true;\n                            }\n                        }\n\n                        if (isValid) {\n                            break;\n                        }\n                        --framesLeftToAnalyze;\n                    }\n\n                    if (isValid == false) {\n                        printf(\"Failed to capture sound data. Please try again\\n\");\n                        framesToRecord = -1;\n                    }\n\n                    receivingData = false;\n                    analyzingData = false;\n\n                    std::fill(sampleSpectrum.begin(), sampleSpectrum.end(), 0.0f);\n\n                    framesToAnalyze = 0;\n                    framesLeftToAnalyze = 0;\n                }\n\n                // check if receiving data\n                if (receivingData == false) {\n                    bool isReceiving = true;\n\n                    for (int i = 0; i < nBitsInMarker; ++i) {\n                        int bin = std::round(dataFreqs_hz[i]*ihzPerFrame);\n\n                        if (i%2 == 0) {\n                            if (sampleSpectrum[bin] <= 3.0f*sampleSpectrum[bin + d0]) isReceiving = false;\n                        } else {\n                            if (sampleSpectrum[bin] >= 3.0f*sampleSpectrum[bin + d0]) isReceiving = false;\n                        }\n                    }\n\n                    if (isReceiving) {\n                        std::time_t timestamp = std::time(nullptr);\n                        printf(\"%sReceiving sound data ...\\n\", std::asctime(std::localtime(&timestamp)));\n                        rxData.fill(0);\n                        receivingData = true;\n                        if (txMode == ::TxMode::FixedLength) {\n                            recvDuration_frames = nMarkerFrames + nPostMarkerFrames + framesPerTx*((::kDefaultFixedLength + paramECCBytesPerTx)/paramBytesPerTx + 1);\n                        } else {\n                            recvDuration_frames = nMarkerFrames + nPostMarkerFrames + framesPerTx*((::kMaxLength + ::getECCBytesForLength(::kMaxLength))/paramBytesPerTx + 1);\n                        }\n                        framesToRecord = recvDuration_frames;\n                        framesLeftToRecord = recvDuration_frames;\n                    }\n                } else if (txMode == ::TxMode::VariableLength) {\n                    bool isEnded = true;\n\n                    for (int i = 0; i < nBitsInMarker; ++i) {\n                        int bin = std::round(dataFreqs_hz[i]*ihzPerFrame);\n\n                        if (i%2 == 0) {\n                            if (sampleSpectrum[bin] >= 3.0f*sampleSpectrum[bin + d0]) isEnded = false;\n                        } else {\n                            if (sampleSpectrum[bin] <= 3.0f*sampleSpectrum[bin + d0]) isEnded = false;\n                        }\n                    }\n\n                    if (isEnded && framesToRecord > 1) {\n                        std::time_t timestamp = std::time(nullptr);\n                        printf(\"%sReceived end marker\\n\", std::asctime(std::localtime(&timestamp)));\n                        recvDuration_frames -= framesLeftToRecord - 1;\n                        framesLeftToRecord = 1;\n                    }\n                }\n            } else {\n                break;\n            }\n\n            ++nIterations;\n        }\n\n        auto tCallEnd = std::chrono::high_resolution_clock::now();\n        tSum_ms += getTime_ms(tCallStart, tCallEnd);\n        if (++nCalls == 10) {\n            averageRxTime_ms = tSum_ms/nCalls;\n            tSum_ms = 0.0f;\n            nCalls = 0;\n        }\n\n        if ((int) SDL_GetQueuedAudioSize(devid_in) > 32*sampleSizeBytes*samplesPerFrame) {\n            printf(\"nIter = %d, Queue size: %d\\n\", nIterations, SDL_GetQueuedAudioSize(devid_in));\n            SDL_ClearQueuedAudio(devid_in);\n        }\n    }\n\n    int nIterations;\n    bool needUpdate = false;\n\n    int paramFreqDelta = 6;\n    int paramFreqStart = 40;\n    int paramFramesPerTx = 6;\n    int paramBytesPerTx = 2;\n    int paramECCBytesPerTx = 32;\n    int paramVolume = 10;\n\n    // Rx\n    bool receivingData;\n    bool analyzingData;\n\n    std::array<float, kMaxSamplesPerFrame> fftIn;\n    std::array<std::complex<float>, kMaxSamplesPerFrame> fftOut;\n\n    ::AmplitudeData sampleAmplitude;\n    ::SpectrumData sampleSpectrum;\n\n    std::array<std::uint8_t, ::kMaxDataSize> rxData;\n    std::array<std::uint8_t, ::kMaxDataSize> encodedData;\n\n    int historyId = 0;\n    ::AmplitudeData sampleAmplitudeAverage;\n    std::array<::AmplitudeData, ::kMaxSpectrumHistory> sampleAmplitudeHistory;\n\n    ::RecordedData recordedAmplitude;\n\n    // Tx\n    bool hasData;\n    int sampleSizeBytes;\n    float sampleRate;\n    float sampleRateOut;\n    int samplesPerFrame;\n    float isamplesPerFrame;\n\n    ::AmplitudeData outputBlock;\n    ::AmplitudeData16 outputBlock16;\n\n    std::array<::AmplitudeData, ::kMaxDataBits> bit1Amplitude;\n    std::array<::AmplitudeData, ::kMaxDataBits> bit0Amplitude;\n\n    float sendVolume;\n    float hzPerFrame;\n    float ihzPerFrame;\n\n    int d0 = 1;\n    float freqStart_hz;\n    float freqDelta_hz;\n\n    int frameId;\n    int nRampFrames;\n    int nRampFramesBegin;\n    int nRampFramesEnd;\n    int nRampFramesBlend;\n    int dataId;\n    int framesPerTx;\n    int framesToAnalyze;\n    int framesLeftToAnalyze;\n    int framesToRecord;\n    int framesLeftToRecord;\n    int nBitsInMarker;\n    int nMarkerFrames;\n    int nPostMarkerFrames;\n    int recvDuration_frames;\n\n    ::TxMode txMode = ::TxMode::FixedLength;\n\n    std::array<bool, ::kMaxDataBits> dataBits;\n    std::array<double, ::kMaxDataBits> phaseOffsets;\n    std::array<double, ::kMaxDataBits> dataFreqs_hz;\n\n    int nDataBitsPerTx;\n    int nECCBytesPerTx;\n    int sendDataLength;\n\n    RS::ReedSolomon * rsData = nullptr;\n    RS::ReedSolomon * rsLength = nullptr;\n\n    float averageRxTime_ms = 0.0;\n\n    std::string textToSend;\n};\n\nint init() {\n    if (g_isInitialized) return 0;\n\n    printf(\"Initializing ...\\n\");\n\n    SDL_LogSetPriority(SDL_LOG_CATEGORY_APPLICATION, SDL_LOG_PRIORITY_INFO);\n\n    if (SDL_Init(SDL_INIT_AUDIO) < 0) {\n        SDL_LogError(SDL_LOG_CATEGORY_APPLICATION, \"Couldn't initialize SDL: %s\\n\", SDL_GetError());\n        return (1);\n    }\n\n    SDL_SetHintWithPriority(SDL_HINT_AUDIO_RESAMPLING_MODE, \"medium\", SDL_HINT_OVERRIDE);\n\n    {\n        int nDevices = SDL_GetNumAudioDevices(SDL_FALSE);\n        printf(\"Found %d playback devices:\\n\", nDevices);\n        for (int i = 0; i < nDevices; i++) {\n            printf(\"    - Playback device #%d: '%s'\\n\", i, SDL_GetAudioDeviceName(i, SDL_FALSE));\n        }\n    }\n    {\n        int nDevices = SDL_GetNumAudioDevices(SDL_TRUE);\n        printf(\"Found %d capture devices:\\n\", nDevices);\n        for (int i = 0; i < nDevices; i++) {\n            printf(\"    - Capture device #%d: '%s'\\n\", i, SDL_GetAudioDeviceName(i, SDL_TRUE));\n        }\n    }\n\n    SDL_AudioSpec desiredSpec;\n    SDL_zero(desiredSpec);\n\n    desiredSpec.freq = ::kBaseSampleRate;\n    desiredSpec.format = AUDIO_S16SYS;\n    desiredSpec.channels = 1;\n    desiredSpec.samples = 16*1024;\n    desiredSpec.callback = NULL;\n\n    SDL_AudioSpec obtainedSpec;\n    SDL_zero(obtainedSpec);\n\n    if (g_playbackId >= 0) {\n        printf(\"Attempt to open playback device %d : '%s' ...\\n\", g_playbackId, SDL_GetAudioDeviceName(g_playbackId, SDL_FALSE));\n        devid_out = SDL_OpenAudioDevice(SDL_GetAudioDeviceName(g_playbackId, SDL_FALSE), SDL_FALSE, &desiredSpec, &obtainedSpec, 0);\n    } else {\n        printf(\"Attempt to open default playback device ...\\n\");\n        devid_out = SDL_OpenAudioDevice(NULL, SDL_FALSE, &desiredSpec, &obtainedSpec, 0);\n    }\n\n    if (!devid_out) {\n        printf(\"Couldn't open an audio device for playback: %s!\\n\", SDL_GetError());\n        devid_out = 0;\n    } else {\n        printf(\"Obtained spec for output device (SDL Id = %d):\\n\", devid_out);\n        printf(\"    - Sample rate:       %d (required: %d)\\n\", obtainedSpec.freq, desiredSpec.freq);\n        printf(\"    - Format:            %d (required: %d)\\n\", obtainedSpec.format, desiredSpec.format);\n        printf(\"    - Channels:          %d (required: %d)\\n\", obtainedSpec.channels, desiredSpec.channels);\n        printf(\"    - Samples per frame: %d (required: %d)\\n\", obtainedSpec.samples, desiredSpec.samples);\n\n        if (obtainedSpec.format != desiredSpec.format ||\n            obtainedSpec.channels != desiredSpec.channels ||\n            obtainedSpec.samples != desiredSpec.samples) {\n            SDL_CloseAudio();\n            throw std::runtime_error(\"Failed to initialize desired SDL_OpenAudio!\");\n        }\n    }\n\n    SDL_AudioSpec captureSpec;\n    captureSpec = obtainedSpec;\n    captureSpec.freq = ::kBaseSampleRate;\n    captureSpec.format = AUDIO_F32SYS;\n    captureSpec.samples = 1024;\n\n    if (g_playbackId >= 0) {\n        printf(\"Attempt to open capture device %d : '%s' ...\\n\", g_captureId, SDL_GetAudioDeviceName(g_captureId, SDL_FALSE));\n        devid_in = SDL_OpenAudioDevice(SDL_GetAudioDeviceName(g_captureId, SDL_TRUE), SDL_TRUE, &captureSpec, &captureSpec, 0);\n    } else {\n        printf(\"Attempt to open default capture device ...\\n\");\n        devid_in = SDL_OpenAudioDevice(g_captureDeviceName, SDL_TRUE, &captureSpec, &captureSpec, 0);\n    }\n    if (!devid_in) {\n        printf(\"Couldn't open an audio device for capture: %s!\\n\", SDL_GetError());\n        devid_in = 0;\n    } else {\n\n        printf(\"Obtained spec for input device (SDL Id = %d):\\n\", devid_in);\n        printf(\"    - Sample rate:       %d\\n\", captureSpec.freq);\n        printf(\"    - Format:            %d (required: %d)\\n\", captureSpec.format, desiredSpec.format);\n        printf(\"    - Channels:          %d (required: %d)\\n\", captureSpec.channels, desiredSpec.channels);\n        printf(\"    - Samples per frame: %d\\n\", captureSpec.samples);\n    }\n\n    int sampleSizeBytes = 4;\n    //switch (obtainedSpec.format) {\n    //    case AUDIO_U8:\n    //    case AUDIO_S8:\n    //        sampleSizeBytes = 1;\n    //        break;\n    //    case AUDIO_U16SYS:\n    //    case AUDIO_S16SYS:\n    //        sampleSizeBytes = 2;\n    //        break;\n    //    case AUDIO_S32SYS:\n    //    case AUDIO_F32SYS:\n    //        sampleSizeBytes = 4;\n    //        break;\n    //}\n\n    g_data = new DataRxTx(obtainedSpec.freq, ::kBaseSampleRate, captureSpec.samples, sampleSizeBytes, \"\");\n\n    g_isInitialized = true;\n    return 0;\n}\n\n// JS interface\nextern \"C\" {\n    int setText(int textLength, const char * text) {\n        g_data->init(textLength, text);\n        return 0;\n    }\n\n    int getText(char * text) {\n        std::copy(g_data->rxData.begin(), g_data->rxData.end(), text);\n        return 0;\n    }\n\n    int getSampleRate() { return g_data->sampleRate; }\n    float getAverageRxTime_ms() { return g_data->averageRxTime_ms; }\n    int getFramesToRecord() { return g_data->framesToRecord; }\n    int getFramesLeftToRecord() { return g_data->framesLeftToRecord; }\n    int getFramesToAnalyze() { return g_data->framesToAnalyze; }\n    int getFramesLeftToAnalyze() { return g_data->framesLeftToAnalyze; }\n    int hasDeviceOutput() { return devid_out; }\n    int hasDeviceCapture() { return (g_totalBytesCaptured > 0) ? devid_in : 0; }\n    int doInit() { return init(); }\n    int setTxMode(int txMode) { g_data->txMode = (::TxMode)(txMode); return 0; }\n\n    void setParameters(\n        int paramFreqDelta,\n        int paramFreqStart,\n        int paramFramesPerTx,\n        int paramBytesPerTx,\n        int /*paramECCBytesPerTx*/,\n        int paramVolume) {\n        if (g_data == nullptr) return;\n\n        g_data->paramFreqDelta = paramFreqDelta;\n        g_data->paramFreqStart = paramFreqStart;\n        g_data->paramFramesPerTx = paramFramesPerTx;\n        g_data->paramBytesPerTx = paramBytesPerTx;\n        g_data->paramVolume = paramVolume;\n\n        g_data->needUpdate = true;\n    }\n}\n\n// main loop\nvoid update() {\n    if (g_isInitialized == false) return;\n\n    SDL_Event e;\n    SDL_bool shouldTerminate = SDL_FALSE;\n    while (SDL_PollEvent(&e)) {\n        if (e.type == SDL_QUIT) {\n            shouldTerminate = SDL_TRUE;\n        }\n    }\n\n    if (g_data->hasData == false) {\n        SDL_PauseAudioDevice(devid_out, SDL_FALSE);\n\n        static auto tLastNoData = std::chrono::high_resolution_clock::now();\n        auto tNow = std::chrono::high_resolution_clock::now();\n\n        if ((int) SDL_GetQueuedAudioSize(devid_out) < g_data->samplesPerFrame*g_data->sampleSizeBytes) {\n            SDL_PauseAudioDevice(devid_in, SDL_FALSE);\n            if (::getTime_ms(tLastNoData, tNow) > 500.0f) {\n                g_data->receive();\n            } else {\n                SDL_ClearQueuedAudio(devid_in);\n            }\n        } else {\n            tLastNoData = tNow;\n            //SDL_ClearQueuedAudio(devid_in);\n            //SDL_Delay(10);\n        }\n    } else {\n        SDL_PauseAudioDevice(devid_out, SDL_TRUE);\n        SDL_PauseAudioDevice(devid_in, SDL_TRUE);\n\n        g_data->send();\n    }\n\n    if (shouldTerminate) {\n        SDL_PauseAudioDevice(devid_in, 1);\n        SDL_CloseAudioDevice(devid_in);\n        SDL_PauseAudioDevice(devid_out, 1);\n        SDL_CloseAudioDevice(devid_out);\n        SDL_CloseAudio();\n        SDL_Quit();\n        #ifdef __EMSCRIPTEN__\n        emscripten_cancel_main_loop();\n        #endif\n    }\n}\n\nstatic std::map<std::string, std::string> parseCmdArguments(int argc, char ** argv) {\n    int last = argc;\n    std::map<std::string, std::string> res;\n    for (int i = 1; i < last; ++i) {\n        if (argv[i][0] == '-') {\n            if (strlen(argv[i]) > 1) {\n                res[std::string(1, argv[i][1])] = strlen(argv[i]) > 2 ? argv[i] + 2 : \"\";\n            }\n        }\n    }\n\n    return res;\n}\n\nint main(int argc, char** argv) {\n#ifdef __EMSCRIPTEN__\n    printf(\"Build time: %s\\n\", BUILD_TIMESTAMP);\n    printf(\"Press the Init button to start\\n\");\n\n    g_captureDeviceName = argv[1];\n#else\n    printf(\"Usage: %s [-cN] [-pN] [-tN]\\n\", argv[0]);\n    printf(\"    -cN - select capture device N\\n\");\n    printf(\"    -pN - select playback device N\\n\");\n    printf(\"    -tN - transmission protocol:\\n\");\n    printf(\"          -t0 : Normal\\n\");\n    printf(\"          -t1 : Fast (default)\\n\");\n    printf(\"          -t2 : Fastest\\n\");\n    printf(\"          -t3 : Ultrasonic\\n\");\n    printf(\"\\n\");\n\n    g_captureDeviceName = nullptr;\n\n    auto argm = parseCmdArguments(argc, argv);\n    g_captureId = argm[\"c\"].empty() ? 0 : std::stoi(argm[\"c\"]);\n    g_playbackId = argm[\"p\"].empty() ? 0 : std::stoi(argm[\"p\"]);\n    int txProtocol = argm[\"t\"].empty() ? 1 : std::stoi(argm[\"t\"]);\n#endif\n\n#ifdef __EMSCRIPTEN__\n    emscripten_set_main_loop(update, 60, 1);\n#else\n    init();\n    setTxMode(1);\n    printf(\"Selecting Tx protocol %d\\n\", txProtocol);\n    switch (txProtocol) {\n        case 0:\n            {\n                printf(\"Using 'Normal' Tx Protocol\\n\");\n                setParameters(1, 40, 9, 3, 0, 50);\n            }\n            break;\n        case 1:\n            {\n                printf(\"Using 'Fast' Tx Protocol\\n\");\n                setParameters(1, 40, 6, 3, 0, 50);\n            }\n            break;\n        case 2:\n            {\n                printf(\"Using 'Fastest' Tx Protocol\\n\");\n                setParameters(1, 40, 3, 3, 0, 50);\n            }\n            break;\n        case 3:\n            {\n                printf(\"Using 'Ultrasonic' Tx Protocol\\n\");\n                setParameters(1, 320, 9, 3, 0, 50);\n            }\n            break;\n        default:\n            {\n                printf(\"Using 'Fast' Tx Protocol\\n\");\n                setParameters(1, 40, 6, 3, 0, 50);\n            }\n    };\n    printf(\"\\n\");\n    std::thread inputThread([]() {\n        std::string inputOld = \"\";\n        while (true) {\n            std::string input;\n            std::cout << \"Enter text: \";\n            getline(std::cin, input);\n            if (input.empty()) {\n                std::cout << \"Re-sending ... \" << std::endl;\n                input = inputOld;\n            } else {\n                std::cout << \"Sending ... \" << std::endl;\n            }\n            setText(input.size(), input.data());\n            inputOld = input;\n        }\n    });\n\n    while (true) {\n        SDL_Delay(1);\n        update();\n    }\n\n    inputThread.join();\n#endif\n\n    delete g_data;\n\n    SDL_PauseAudioDevice(devid_in, 1);\n    SDL_CloseAudioDevice(devid_in);\n    SDL_PauseAudioDevice(devid_out, 1);\n    SDL_CloseAudioDevice(devid_out);\n    SDL_CloseAudio();\n    SDL_Quit();\n\n    return 0;\n}\n"
        },
        {
          "name": "main.js",
          "type": "blob",
          "size": 24.69921875,
          "content": "/*! \\file main.js\n *  \\brief File transfer with WebRTC. Signaling is done through sound\n *  \\author Georgi Gerganov\n */\n\nvar kOfferNumCandidates         = 5;\nvar kOfferName                  = '-';\nvar kOfferUsername              = '-';\nvar kOfferSessionId             = '1337';\nvar kOfferSessionVersion        = '0';\nvar kOfferLocalhost             = '0.0.0.0';\nvar kOfferBundle                = 'sdparta_0';\nvar kOfferPort                  = '5400';\nvar kOfferCandidateFoundation   = '0';\nvar kOfferCandidateComponent    = '1';\nvar kOfferCandidatePriority     = '2122252543';\nvar kOfferUfrag                 = 'bc105aa9';\nvar kOfferPwd                   = '52f0a329e7fd93662f50828f617b408d';\nvar kOfferFingerprint           = '00:00:00:00:00:00:00:00:00:00:00:00:00:00:00:00:00:00:00:00:00:00:00:00:00:00:00:00:00:00:00:00';\n\nvar kAnswerNumCandidates        = 5;\nvar kAnswerName                 = '-';\nvar kAnswerUsername             = '-';\nvar kAnswerSessionId            = '1338';\nvar kAnswerSessionVersion       = '0';\nvar kAnswerLocalhost            = '0.0.0.0';\nvar kAnswerBundle               = 'sdparta_0';\nvar kAnswerPort                 = '5400';\nvar kAnswerCandidateFoundation  = '0';\nvar kAnswerCandidateComponent   = '1';\nvar kAnswerCandidatePriority    = '2122252543';\nvar kAnswerUfrag                = 'c417de3e';\nvar kAnswerPwd                  = '1aa0e1241c16687064c4fd31b8fc367a';\nvar kAnswerFingerprint          = '00:00:00:00:00:00:00:00:00:00:00:00:00:00:00:00:00:00:00:00:00:00:00:00:00:00:00:00:00:00:00:00';\n\nfunction getOfferTemplate() {\n    return \"v=0\\r\\n\" +\n        \"o=\"+kOfferUsername+\" \"+kOfferSessionId+\" \"+kOfferSessionVersion+\" IN IP4 \"+kOfferLocalhost+\"\\r\\n\" +\n        \"s=\"+kOfferName+\"\\r\\n\" +\n        \"t=0 0\\r\\n\" +\n        \"a=sendrecv\\r\\n\" +\n        \"a=fingerprint:sha-256 \"+kOfferFingerprint+\"\\r\\n\" +\n        \"a=group:BUNDLE \"+kOfferBundle+\"\\r\\n\" +\n        \"a=ice-options:trickle\\r\\n\" +\n        \"a=msid-semantic:WMS *\\r\\n\" +\n        \"m=application \"+kOfferPort+\" DTLS/SCTP 5000\\r\\n\" +\n        \"c=IN IP4 \"+kOfferLocalhost+\"\\r\\n\" +\n        \"a=candidate:0 \"+kOfferCandidateComponent+\" UDP \"+kOfferCandidatePriority+\" \"+kOfferLocalhost+\" \"+kOfferPort+\" typ host\\r\\n\" +\n        \"a=candidate:1 \"+kOfferCandidateComponent+\" UDP \"+kOfferCandidatePriority+\" \"+kOfferLocalhost+\" \"+kOfferPort+\" typ host\\r\\n\" +\n        \"a=candidate:2 \"+kOfferCandidateComponent+\" UDP \"+kOfferCandidatePriority+\" \"+kOfferLocalhost+\" \"+kOfferPort+\" typ host\\r\\n\" +\n        \"a=candidate:3 \"+kOfferCandidateComponent+\" UDP \"+kOfferCandidatePriority+\" \"+kOfferLocalhost+\" \"+kOfferPort+\" typ host\\r\\n\" +\n        \"a=candidate:4 \"+kOfferCandidateComponent+\" UDP \"+kOfferCandidatePriority+\" \"+kOfferLocalhost+\" \"+kOfferPort+\" typ host\\r\\n\" +\n        \"a=sendrecv\\r\\n\" +\n        \"a=end-of-candidates\\r\\n\" +\n        \"a=ice-pwd:\"+kOfferPwd+\"\\r\\n\" +\n        \"a=ice-ufrag:\"+kOfferUfrag+\"\\r\\n\" +\n        \"a=mid:\"+kOfferBundle+\"\\r\\n\" +\n        \"a=sctpmap:5000 webrtc-datachannel 256\\r\\n\" +\n        \"a=setup:actpass\\r\\n\" +\n        \"a=max-message-size:1073741823\\r\\n\";\n}\n\nfunction getAnswerTemplate() {\n    return \"v=0\\r\\n\" +\n        \"o=\"+kAnswerUsername+\" \"+kAnswerSessionId+\" \"+kAnswerSessionVersion+\" IN IP4 \"+kAnswerLocalhost+\"\\r\\n\" +\n        \"s=\"+kAnswerName+\"\\r\\n\" +\n        \"t=0 0\\r\\n\" +\n        \"a=sendrecv\\r\\n\" +\n        \"a=fingerprint:sha-256 \"+kAnswerFingerprint+\"\\r\\n\" +\n        \"a=group:BUNDLE \"+kAnswerBundle+\"\\r\\n\" +\n        \"a=ice-options:trickle\\r\\n\" +\n        \"a=msid-semantic:WMS *\\r\\n\" +\n        \"m=application \"+kAnswerPort+\" DTLS/SCTP 5000\\r\\n\" +\n        \"c=IN IP4 \"+kAnswerLocalhost+\"\\r\\n\" +\n        \"a=candidate:0 \"+kAnswerCandidateComponent+\" UDP \"+kAnswerCandidatePriority+\" \"+kAnswerLocalhost+\" \"+kAnswerPort+\" typ host\\r\\n\" +\n        \"a=candidate:1 \"+kAnswerCandidateComponent+\" UDP \"+kAnswerCandidatePriority+\" \"+kAnswerLocalhost+\" \"+kAnswerPort+\" typ host\\r\\n\" +\n        \"a=candidate:2 \"+kAnswerCandidateComponent+\" UDP \"+kAnswerCandidatePriority+\" \"+kAnswerLocalhost+\" \"+kAnswerPort+\" typ host\\r\\n\" +\n        \"a=candidate:3 \"+kAnswerCandidateComponent+\" UDP \"+kAnswerCandidatePriority+\" \"+kAnswerLocalhost+\" \"+kAnswerPort+\" typ host\\r\\n\" +\n        \"a=candidate:4 \"+kAnswerCandidateComponent+\" UDP \"+kAnswerCandidatePriority+\" \"+kAnswerLocalhost+\" \"+kAnswerPort+\" typ host\\r\\n\" +\n        \"a=sendrecv\\r\\n\" +\n        \"a=end-of-candidates\\r\\n\" +\n        \"a=ice-pwd:\"+kAnswerPwd+\"\\r\\n\" +\n        \"a=ice-ufrag:\"+kAnswerUfrag+\"\\r\\n\" +\n        \"a=mid:\"+kAnswerBundle+\"\\r\\n\" +\n        \"a=sctpmap:5000 webrtc-datachannel 256\\r\\n\" +\n        \"a=setup:active\\r\\n\" +\n        \"a=max-message-size:1073741823\\r\\n\";\n}\n\n// Taken from: https://github.com/diafygi/webrtc-ips\n// get the IP addresses associated with an account\nfunction getIPs(callback){\n    var ip_dups = {};\n\n    //compatibility for firefox and chrome\n    var RTCPeerConnection = window.RTCPeerConnection\n        || window.mozRTCPeerConnection\n        || window.webkitRTCPeerConnection;\n    var useWebKit = !!window.webkitRTCPeerConnection;\n\n    //bypass naive webrtc blocking using an iframe\n    if(!RTCPeerConnection){\n        //NOTE: you need to have an iframe in the page right above the script tag\n        //\n        //<iframe id=\"iframe\" sandbox=\"allow-same-origin\" style=\"display: none\"></iframe>\n        //<script>...getIPs called in here...\n        //\n        var win = iframe.contentWindow;\n        RTCPeerConnection = win.RTCPeerConnection\n            || win.mozRTCPeerConnection\n            || win.webkitRTCPeerConnection;\n        useWebKit = !!win.webkitRTCPeerConnection;\n    }\n\n    //construct a new RTCPeerConnection\n    var pc = new RTCPeerConnection(null);\n\n    function handleCandidate(candidate){\n        //match just the IP address\n        //console.log(candidate);\n        var ip_regex = /([0-9]{1,3}(\\.[0-9]{1,3}){3}|[a-f0-9]{1,4}(:[a-f0-9]{1,4}){7})/\n        var regex_res = ip_regex.exec(candidate);\n        if (regex_res == null) return;\n        var ip_addr = ip_regex.exec(candidate)[1];\n\n        //remove duplicates\n        if(ip_dups[ip_addr] === undefined)\n            callback(ip_addr);\n\n        ip_dups[ip_addr] = true;\n    }\n\n    //listen for candidate events\n    pc.onicecandidate = function(ice){\n\n        //skip non-candidate events\n        if(ice.candidate)\n            handleCandidate(ice.candidate.candidate);\n    };\n\n    //create a bogus data channel\n    pc.createDataChannel(\"\");\n\n    //create an offer sdp\n    pc.createOffer(function(result){\n\n        //trigger the stun server request\n        pc.setLocalDescription(result, function(){}, function(){});\n\n    }, function(){});\n\n    //wait for a while to let everything done\n    setTimeout(function(){\n        //read candidate info from local description\n        var lines = pc.localDescription.sdp.split('\\n');\n\n        lines.forEach(function(line){\n            if(line.indexOf('a=candidate:') === 0)\n                handleCandidate(line);\n        });\n    }, 1000);\n}\n\nfunction transmitRelevantData(sdp, dataType) {\n    var res = parseSDP(sdp);\n    var hashparts = null;\n    if (typeof res.fingerprint === 'undefined') {\n        hashparts = res.media[0].fingerprint.hash.split(\":\");\n    } else {\n        hashparts = res.fingerprint.hash.split(\":\");\n    }\n\n    var r = new Uint8Array(256);\n    r[0] = dataType.charCodeAt(0);\n\n    var ip = document.getElementById('available-networks').value;\n    r[2] = parseInt(ip.split(\".\")[0]);\n    r[3] = parseInt(ip.split(\".\")[1]);\n    r[4] = parseInt(ip.split(\".\")[2]);\n    r[5] = parseInt(ip.split(\".\")[3]);\n\n    for (var m in res.media[0].candidates) {\n        if (res.media[0].candidates[m].ip != ip) continue;\n        //if (res.media[0].candidate[m].transport != \"UDP\") continue;\n        var port = res.media[0].candidates[m].port;\n        r[6] = parseInt(port & 0xFF00) >> 8\n        r[7] = parseInt(port & 0x00FF);\n        break;\n    }\n\n    for (var i = 0; i < 32; ++i) {\n        r[8+i] = parseInt(hashparts[i], 16);\n    }\n\n    var credentials = \"\";\n    credentials += res.media[0].iceUfrag;\n    credentials += \" \";\n    credentials += res.media[0].icePwd;\n    for (var i = 0; i < credentials.length; ++i) {\n        r[40 + i] = credentials.charCodeAt(i);\n    }\n\n    r[1] = 40 + credentials.length;\n\n    var buffer = Module._malloc(256);\n    Module.writeArrayToMemory(r, buffer, 256);\n    Module.cwrap('setText', 'number', ['number', 'buffer'])(r[1], buffer);\n    Module._free(buffer);\n}\n\n//\n// Web RTC, Common\n//\n\nvar sdpConstraints = { optional: [{RtpDataChannels: true}] };\n\nvar oldRxData = null;\nvar lastSenderRequest = null\nvar lastSenderRequestSDP = null\nvar lastSenderRequestTimestamp = null\nvar lastReceiverAnswer = null\nvar lastReceiverAnswerSDP = null\nvar lastReceiverAnswerTimestamp = null\n\nvar bitrateDiv = document.querySelector('div#bitrate');\nvar fileInput = document.querySelector('input#fileInput');\nvar downloadAnchor = document.querySelector('a#download');\nvar sendProgress = document.querySelector('progress#sendProgress');\nvar receiveProgress = document.querySelector('progress#receiveProgress');\nvar statusMessage = document.querySelector('span#status');\nvar peerInfo = document.querySelector('a#peer-info');\nvar peerReceive = document.querySelector('a#peer-receive');\n\nvar receiveBuffer = [];\nvar receivedSize = 0;\n\nvar bytesPrev = 0;\nvar timestampPrev = 0;\nvar timestampStart;\nvar statsInterval = null;\nvar bitrateMax = 0;\n\n//\n// Web RTC, Sender\n//\n\nvar senderPC;\nvar senderDC;\n\nfunction onAddIceCandidateSuccess() {\n    console.log('AddIceCandidate success.');\n}\n\nfunction onAddIceCandidateError(error) {\n    console.log('Failed to add Ice Candidate: ' + error.toString());\n}\n\nfunction createOfferSDP() {\n    lastReceiverAnswerSDP = null;\n\n    senderDC = senderPC.createDataChannel(\"fileTransfer\");\n    senderDC.binaryType = 'arraybuffer';\n    senderDC.onopen = onSendChannelStateChange;\n    senderDC.onclose = onSendChannelStateChange;\n    senderPC.createOffer().then(function(e) {\n        var res = parseSDP(e.sdp);\n\n        res.name                    = kOfferName;\n        res.origin.username         = kOfferUsername;\n        res.origin.sessionId        = kOfferSessionId;\n        res.origin.sessionVersion   = kOfferSessionVersion;\n        res.groups[0].mids          = kOfferBundle;\n        res.media[0].mid            = kOfferBundle;\n        res.media[0].connection.ip  = document.getElementById('available-networks').value;\n\n        e.sdp = writeSDP(res);\n        senderPC.setLocalDescription(e);\n    });\n};\n\nfunction senderInit() {\n    senderPC = new RTCPeerConnection(null);\n\n    senderPC.oniceconnectionstatechange = function(e) {\n        //var state = senderPC.iceConnectionState;\n    };\n\n    senderPC.onicecandidate = function(e) {\n        if (e.candidate) return;\n        // send offer using sound\n        transmitRelevantData(senderPC.localDescription.sdp, \"O\");\n    }\n\n    createOfferSDP();\n}\n\nfunction senderSend() {\n    if (lastReceiverAnswerSDP == null) return;\n    var answerDesc = new RTCSessionDescription(JSON.parse(lastReceiverAnswerSDP));\n    if (senderPC) {\n        senderPC.setRemoteDescription(answerDesc);\n    }\n}\n\n//\n// Web RTC, Receiver\n//\n\nvar receiverPC;\nvar receiverDC;\nvar firstTimeFail = false;\n\nfunction updatePeerInfo() {\n    if (typeof Module === 'undefined') return;\n    var framesLeftToRecord = Module.cwrap('getFramesLeftToRecord', 'number', [])();\n    var framesToRecord = Module.cwrap('getFramesToRecord', 'number', [])();\n    var framesLeftToAnalyze = Module.cwrap('getFramesLeftToAnalyze', 'number', [])();\n    var framesToAnalyze = Module.cwrap('getFramesToAnalyze', 'number', [])();\n\n    if (framesToAnalyze > 0) {\n        peerInfo.innerHTML=\n            \"Analyzing Rx data: <progress value=\" + (framesToAnalyze - framesLeftToAnalyze) +\n            \" max=\" + (framesToRecord) + \"></progress>\";\n        peerReceive.innerHTML= \"\";\n    } else if (framesLeftToRecord > Math.max(0, 0.05*framesToRecord)) {\n        firstTimeFail = true;\n        peerInfo.innerHTML=\n            \"Sound handshake in progress: <progress value=\" + (framesToRecord - framesLeftToRecord) +\n            \" max=\" + (framesToRecord) + \"></progress>\";\n        peerReceive.innerHTML= \"\";\n    } else if (framesToRecord > 0) {\n        peerInfo.innerHTML= \"Analyzing Rx data ...\";\n    } else if (framesToRecord == -1) {\n        if (firstTimeFail) {\n            playSound(\"/media/case-closed\");\n            firstTimeFail = false;\n        }\n        peerInfo.innerHTML= \"<p style=\\\"color:red\\\">Failed to decode Rx data</p>\";\n    }\n}\n\nfunction parseRxData(brx) {\n    var vals = Array();\n    vals[0] = \"\";\n    vals[0] += String(brx[2]) + \".\";\n    vals[0] += String(brx[3]) + \".\";\n    vals[0] += String(brx[4]) + \".\";\n    vals[0] += String(brx[5]);\n\n    vals[1] = String(brx[6]*256 + brx[7]);\n\n    vals[2] = \"\";\n    for (var i = 0; i < 32; ++i) {\n        if (brx[8+i] == 0) {\n            vals[2] += '00';\n        } else if (brx[8+i] < 16) {\n            vals[2] += '0'+brx[8+i].toString(16).toUpperCase();\n        } else {\n            vals[2] += brx[8+i].toString(16).toUpperCase();\n        }\n        if (i < 31) vals[2] += ':';\n    }\n\n    var credentials = \"\";\n    for (var i = 40; i < brx[1]; ++i) {\n        credentials += String.fromCharCode(brx[i]);\n    }\n    vals[3] = credentials.split(\" \")[0];\n    vals[4] = credentials.split(\" \")[1];\n\n    return vals;\n}\n\nfunction checkRxForPeerData() {\n    if (typeof Module === 'undefined') return;\n    Module.cwrap('getText', 'number', ['buffer'])(bufferRx);\n    var result = \"\";\n    for(var i = 0; i < 82; ++i){\n        result += (String.fromCharCode((Module.HEAPU8)[bufferRx + i]));\n        brx[i] = (Module.HEAPU8)[bufferRx + i];\n    }\n\n    if (String.fromCharCode(brx[0]) == \"O\") {\n        var lastSenderRequestTmp = brx;\n        if (lastSenderRequestTmp == lastSenderRequest) return;\n\n        console.log(\"Received Offer\");\n        lastSenderRequest = lastSenderRequestTmp;\n\n        var vals = parseRxData(brx);\n        var res = parseSDP(getOfferTemplate());\n\n        res.origin.username             = kOfferUsername;\n        res.origin.sessionId            = kOfferSessionId;\n        res.media[0].iceUfrag           = vals[3];\n        res.media[0].icePwd             = vals[4];\n        res.media[0].connection.ip      = vals[0];\n        res.media[0].port               = vals[1];\n        if (typeof res.fingerprint === 'undefined') {\n            res.media[0].fingerprint.hash   = vals[2];\n        } else {\n            res.fingerprint.hash   = vals[2];\n        }\n        if (typeof res.candidates === 'undefined') {\n            for (var i = 0; i < kOfferNumCandidates; ++i) {\n                res.media[0].candidates[i].ip       = vals[0];\n                res.media[0].candidates[i].port     = vals[1];\n                res.media[0].candidates[i].priority = kOfferCandidatePriority;\n            }\n        } else {\n            for (var i = 0; i < kOfferNumCandidates; ++i) {\n                res.candidates[i].ip       = vals[0];\n                res.candidates[i].port     = vals[1];\n                res.candidates[i].priority = kOfferCandidatePriority;\n            }\n        }\n\n        //console.log(writeSDP(res));\n        lastSenderRequestSDP = '{\"type\":\"offer\",\"sdp\":'+JSON.stringify(writeSDP(res))+'}';\n        peerInfo.innerHTML= \"Receive file from \" + vals[0] + \" ?\";\n        peerReceive.innerHTML= \"<button onClick=\\\"lockoutSubmit(this); receiverInit();\\\">Receive</button>\";\n        playSound(\"/media/open-ended\");\n\n        return;\n    } else {\n        lastSenderRequest = null;\n    }\n\n    if (String.fromCharCode(brx[0]) == \"A\") {\n        var lastReceiverAnswerTmp = brx;\n        if (lastReceiverAnswerTmp == lastReceiverAnswer) return;\n\n        console.log(\"Received Answer\");\n        lastReceiverAnswer = lastReceiverAnswerTmp;\n\n        var vals = parseRxData(brx);\n        var res = parseSDP(getAnswerTemplate());\n\n        res.origin.username             = kAnswerUsername;\n        res.origin.sessionId            = kAnswerSessionId;\n        res.media[0].iceUfrag           = vals[3];\n        res.media[0].icePwd             = vals[4];\n        res.media[0].connection.ip      = vals[0];\n        res.media[0].port               = vals[1];\n        if (typeof res.fingerprint === 'undefined') {\n            res.media[0].fingerprint.hash   = vals[2];\n        } else {\n            res.fingerprint.hash   = vals[2];\n        }\n        if (typeof res.candidates === 'undefined') {\n            for (var i = 0; i < kAnswerNumCandidates; ++i) {\n                res.media[0].candidates[i].ip       = vals[0];\n                res.media[0].candidates[i].port     = vals[1];\n                res.media[0].candidates[i].priority = kAnswerCandidatePriority;\n            }\n        } else {\n            for (var i = 0; i < kAnswerNumCandidates; ++i) {\n                res.candidates[i].ip       = vals[0];\n                res.candidates[i].port     = vals[1];\n                res.candidates[i].priority = kAnswerCandidatePriority;\n            }\n        }\n\n        lastReceiverAnswerSDP = '{\"type\":\"answer\",\"sdp\":'+JSON.stringify(writeSDP(res))+'}';\n        playSound(\"/media/open-ended\");\n\n        if (senderPC) {\n            peerInfo.innerHTML= \"Trying to connect with \" + vals[0] + \" ...\";\n            senderSend();\n        } else {\n            peerInfo.innerHTML= \"Received answer not meant for us (\" + vals[0] + \")\";\n        }\n\n        return;\n    } else {\n        lastReceiverAnswer = null;\n    }\n}\n\nfunction createAnswerSDP() {\n    if (lastSenderRequestSDP == null) return;\n    var offerDesc = new RTCSessionDescription(JSON.parse(lastSenderRequestSDP));\n    receiverPC.setRemoteDescription(offerDesc,\n        function() {\n            receiverPC.createAnswer(\n                function (e) {\n                    var res = parseSDP(e.sdp);\n\n                    res.name                    = kAnswerName;\n                    res.origin.username         = kAnswerUsername;\n                    res.origin.sessionId        = kAnswerSessionId;\n                    res.origin.sessionVersion   = kAnswerSessionVersion;\n                    res.media[0].mid            = kAnswerBundle;\n                    res.media[0].connection.ip  = document.getElementById('available-networks').value;\n\n                    e.sdp = writeSDP(res);\n                    receiverPC.setLocalDescription(e);\n                },\n                function () { console.warn(\"Couldn't create offer\") },\n                sdpConstraints\n            );\n        }, function(e) {\n            console.log(\"Could not set remote description. Reason: \" + e);\n        });\n};\n\nfunction receiverInit() {\n    receiverPC = new RTCPeerConnection(null);\n\n    receiverPC.ondatachannel = receiveChannelCallback;\n    receiverPC.onicecandidate = function(e) {\n        if (e.candidate) return;\n        // send answer using sound\n        transmitRelevantData(receiverPC.localDescription.sdp, \"A\");\n    };\n    receiverPC.oniceconnectionstatechange = function(e) {};\n\n    createAnswerSDP();\n}\n\n//\n// File sutff\n//\n\nfunction ab2str(buf) {\n    return String.fromCharCode.apply(null, new Uint16Array(buf));\n}\n\nfunction str2ab(str) {\n    var buf = new ArrayBuffer(str.length*2); // 2 bytes for each char\n    var bufView = new Uint16Array(buf);\n    for (var i=0, strLen=str.length; i<strLen; i++) {\n        bufView[i] = str.charCodeAt(i);\n    }\n    return buf;\n}\n\nfileInput.addEventListener('change', handleFileInputChange, false);\n\nfunction handleFileInputChange() {\n    var file = fileInput.files[0];\n    if (!file) {\n        console.log('No file chosen');\n    }\n}\n\nfunction sendData() {\n    var file = fileInput.files[0];\n    if (file == null) {\n        peerInfo.innerHTML = \"Connection established, but no file selected\";\n        return;\n    }\n    peerInfo.innerHTML = \"Sending selected file to peer ...\";\n    console.log('File is ' + [file.name, file.size, file.type, file.lastModifiedDate ].join(' '));\n\n    // Handle 0 size files.\n    statusMessage.textContent = '';\n    downloadAnchor.textContent = '';\n    if (file.size === 0) {\n        bitrateDiv.innerHTML = '';\n        statusMessage.textContent = 'File is empty, please select a non-empty file';\n        closeDataChannels();\n        return;\n    }\n    senderDC.send(str2ab(file.name));\n    senderDC.send(str2ab(String(file.size)));\n    sendProgress.max = file.size;\n    receiveProgress.max = file.size;\n    var chunkSize = 16384;\n    var sliceFile = function(offset) {\n        var reader = new window.FileReader();\n        reader.onload = (function() {\n            return function(e) {\n                if (senderDC.bufferedAmount > 4*1024*1024) {\n                    window.setTimeout(sliceFile, 100, offset);\n                } else {\n                    senderDC.send(e.target.result);\n                    if (file.size > offset + e.target.result.byteLength) {\n                        window.setTimeout(sliceFile, 0, offset + chunkSize);\n                    }\n                    sendProgress.value = offset + e.target.result.byteLength;\n                }\n            };\n        })(file);\n        var slice = file.slice(offset, offset + chunkSize);\n        reader.readAsArrayBuffer(slice);\n    };\n    sliceFile(0);\n}\n\nfunction closeDataChannels() {\n    console.log('Closing data channels');\n    if (senderDC) {\n        senderDC.close();\n        console.log('Closed data channel with label: ' + senderDC.label);\n    }\n    if (receiverDC) {\n        receiverDC.close();\n        console.log('Closed data channel with label: ' + receiverDC.label);\n    }\n\n    if (senderPC) senderPC.close();\n    if (receiverPC) receiverPC.close();\n\n    senderPC = null;\n    receiverPC = null;\n    console.log('Closed peer connections');\n\n    // re-enable the file select\n    fileInput.disabled = false;\n}\n\nfunction onSendChannelStateChange() {\n    var readyState = senderDC.readyState;\n    console.log('Send channel state is: ' + readyState);\n    if (readyState === 'open') {\n        sendData();\n    }\n}\n\nfunction receiveChannelCallback(event) {\n    console.log('Receive Channel Callback');\n    receiverDC = event.channel;\n    receiverDC.binaryType = 'arraybuffer';\n    receiverDC.onmessage = onReceiveMessageCallback;\n    receiverDC.onopen = onReceiveChannelStateChange;\n    receiverDC.onclose = onReceiveChannelStateChange;\n\n    receivedSize = 0;\n    recvFileName = '';\n    recvFileSize = 0;\n    bitrateMax = 0;\n    downloadAnchor.textContent = '';\n    downloadAnchor.removeAttribute('download');\n    if (downloadAnchor.href) {\n        URL.revokeObjectURL(downloadAnchor.href);\n        downloadAnchor.removeAttribute('href');\n    }\n}\n\nvar recvFileName = '';\nvar recvFileSize = 0;\n\nfunction onReceiveMessageCallback(event) {\n    //console.log('Received Message ' + event.data.byteLength);\n    if (recvFileName == '') {\n        recvFileName = ab2str(event.data);\n        return;\n    }\n    if (recvFileSize == 0) {\n        recvFileSize = parseInt(ab2str(event.data));\n        peerInfo.innerHTML = \"Receiving file '\" + recvFileName + \"' (\" + recvFileSize + \" bytes) ...\";\n        receiveProgress.max = recvFileSize;\n        return;\n    }\n\n    receiveBuffer.push(event.data);\n    receivedSize += event.data.byteLength;\n\n    receiveProgress.value = receivedSize;\n\n    // we are assuming that our signaling protocol told\n    // about the expected file size (and name, hash, etc).\n    //var file = fileInput.files[0];\n    if (receivedSize === recvFileSize) {\n        var received = new window.Blob(receiveBuffer);\n        receiveBuffer = [];\n\n        downloadAnchor.href = URL.createObjectURL(received);\n        downloadAnchor.download = recvFileName;\n        downloadAnchor.textContent = 'Click to download \\'' + recvFileName + '\\' (' + recvFileSize + ' bytes)';\n        downloadAnchor.style.display = 'block';\n\n        var bitrate = Math.round(8*receivedSize/((new Date()).getTime() - timestampStart));\n        bitrateDiv.innerHTML = 'Average Bitrate: ' + bitrate + ' kbits/sec (max: ' + bitrateMax + ' kbits/sec)';\n\n        if (statsInterval) {\n            window.clearInterval(statsInterval);\n            statsInterval = null;\n        }\n\n        closeDataChannels();\n    }\n}\n\nfunction onReceiveChannelStateChange() {\n    var readyState = receiverDC.readyState;\n    console.log('Receive channel state is: ' + readyState);\n    if (readyState === 'open') {\n        timestampStart = (new Date()).getTime();\n        timestampPrev = timestampStart;\n        statsInterval = window.setInterval(displayStats, 500);\n        window.setTimeout(displayStats, 100);\n        window.setTimeout(displayStats, 300);\n    }\n}\n\n// display bitrate statistics.\nfunction displayStats() {\n    var display = function(bitrate) {\n        bitrateDiv.innerHTML = '<strong>Current Bitrate:</strong> ' +\n            bitrate + ' kbits/sec';\n    };\n\n    if (receiverPC && receiverPC.iceConnectionState === 'connected') {\n        // Firefox currently does not have data channel stats. See\n        // https://bugzilla.mozilla.org/show_bug.cgi?id=1136832\n        // Instead, the bitrate is calculated based on the number of\n        // bytes received.\n        var bytesNow = receivedSize;\n        var now = (new Date()).getTime();\n        var bitrate = Math.round(8*(bytesNow - bytesPrev)/(now - timestampPrev));\n        display(bitrate);\n        timestampPrev = now;\n        bytesPrev = bytesNow;\n        if (bitrate > bitrateMax) {\n            bitrateMax = bitrate;\n        }\n    }\n}\n"
        },
        {
          "name": "media",
          "type": "tree",
          "content": null
        },
        {
          "name": "reed-solomon",
          "type": "tree",
          "content": null
        },
        {
          "name": "sdp-transform",
          "type": "tree",
          "content": null
        }
      ]
    }
  ]
}