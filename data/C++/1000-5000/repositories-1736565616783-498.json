{
  "metadata": {
    "timestamp": 1736565616783,
    "page": 498,
    "hasNextPage": true,
    "endCursor": "Y3Vyc29yOjUwMA==",
    "completionStatus": "IN_PROGRESS"
  },
  "repositories": [
    {
      "nameWithOwner": "greg7mdp/parallel-hashmap",
      "stars": 2710,
      "defaultBranch": "master",
      "files": [
        {
          "name": ".gitattributes",
          "type": "blob",
          "size": 0.048828125,
          "content": "* linguist-vendored \n*.cc linguist-vendored=false\n"
        },
        {
          "name": ".github",
          "type": "tree",
          "content": null
        },
        {
          "name": ".gitignore",
          "type": "blob",
          "size": 0.1767578125,
          "content": "VagrantFile\nbenchmark/build\nbenchmark/output\nbenchmark/charts.html\nexamples/llil_utils/tmp\nbuild*\n.vagrant\n.cache\n.gdb_history\ncompile_commands.json\n.emacs.desktop*\n**/.vscode\nTAGS\n"
        },
        {
          "name": "CITATION.cff",
          "type": "blob",
          "size": 0.2880859375,
          "content": "cff-version: 1.2.0\nmessage: \"If you use this software, please cite it as below.\"\nauthors:\n  - family-names: Popovitch\n    given-names: Gregory\n    orcid: https://orcid.org/0009-0005-7245-5930\ntitle: \"The Parallel Hashmap C++ library\"\nlicense: Apache-2.0\nversion: 1.4.1\ndate-released: 2024-10-27\n"
        },
        {
          "name": "CMakeLists.txt",
          "type": "blob",
          "size": 9.5546875,
          "content": "#[===================================================================[\n    parallel-hashmap library by Gregory Popovitch\n\n    CMake projects that wish to use this library may do\n    something like :\n\n    include(FetchContent)\n    FetchContent_Declare(\n        parallel-hashmap\n        GIT_REPOSITORY https://github.com/greg7mdp/parallel-hashmap.git\n        GIT_TAG        v1.4.1 # adjust tag/branch/commit as needed\n    )\n    FetchContent_MakeAvailable(parallel-hashmap)\n\n    ...\n    include_directories(${parallel-hashmap_SOURCE_DIR})\n\n#]===================================================================]\n\ncmake_minimum_required(VERSION 3.13)\n\nlist (APPEND CMAKE_MODULE_PATH \"${CMAKE_CURRENT_SOURCE_DIR}/cmake\")\n\ninclude(DetectVersion)\n\nif(NOT CMAKE_CXX_STANDARD)\n    set(CMAKE_CXX_STANDARD 11)            ## compile with C++11 support\nendif()\n\nif(NOT CMAKE_CXX_STANDARD_REQUIRED)\n    set(CMAKE_CXX_STANDARD_REQUIRED ON)\nendif()\n\nif(NOT DEFINED PHMAP_MASTER_PROJECT)\n    set(PHMAP_MASTER_PROJECT OFF)\n    if(CMAKE_CURRENT_SOURCE_DIR STREQUAL CMAKE_SOURCE_DIR)\n        set(PHMAP_MASTER_PROJECT ON)\n    endif()\nendif()\n\nproject(phmap VERSION ${DETECTED_PHMAP_VERSION} LANGUAGES CXX)\n\n## ----------------------------- options -----------------------------\noption(PHMAP_INSTALL \"Enable installation\" ${PHMAP_MASTER_PROJECT})\n\n\nset(PHMAP_DIR parallel_hashmap)\nset(PHMAP_HEADERS ${CMAKE_CURRENT_SOURCE_DIR}/${PHMAP_DIR}/phmap.h\n                  ${CMAKE_CURRENT_SOURCE_DIR}/${PHMAP_DIR}/phmap_base.h\n                  ${CMAKE_CURRENT_SOURCE_DIR}/${PHMAP_DIR}/phmap_bits.h\n                  ${CMAKE_CURRENT_SOURCE_DIR}/${PHMAP_DIR}/phmap_config.h\n                  ${CMAKE_CURRENT_SOURCE_DIR}/${PHMAP_DIR}/phmap_dump.h\n                  ${CMAKE_CURRENT_SOURCE_DIR}/${PHMAP_DIR}/phmap_fwd_decl.h\n                  ${CMAKE_CURRENT_SOURCE_DIR}/${PHMAP_DIR}/phmap_utils.h\n                  ${CMAKE_CURRENT_SOURCE_DIR}/${PHMAP_DIR}/meminfo.h\n                  ${CMAKE_CURRENT_SOURCE_DIR}/${PHMAP_DIR}/btree.h)\n\ninclude(helpers)\n\nadd_library(${PROJECT_NAME} INTERFACE)\n\ntarget_sources(${PROJECT_NAME} INTERFACE ${PHMAP_HEADERS})\n\ntarget_include_directories(\n     ${PROJECT_NAME} INTERFACE\n     $<BUILD_INTERFACE:${PROJECT_SOURCE_DIR}>\n     $<INSTALL_INTERFACE:include>)\n\nif(PHMAP_INSTALL)\n    include(GNUInstallDirs)\n    include(CMakePackageConfigHelpers)\n\n    install(\n        DIRECTORY ${PROJECT_SOURCE_DIR}/${PHMAP_DIR}/\n        DESTINATION ${CMAKE_INSTALL_INCLUDEDIR}/${PHMAP_DIR})\n\n    install(TARGETS ${PROJECT_NAME}\n            EXPORT ${PROJECT_NAME}-targets)\n\n    export(EXPORT ${PROJECT_NAME}-targets\n           FILE \"${CMAKE_CURRENT_BINARY_DIR}/${PROJECT_NAME}Targets.cmake\")\nendif()\n\n## ------------------------- building tests and examples -------------\noption(PHMAP_BUILD_TESTS    \"Whether or not to build the tests\"    ${PHMAP_MASTER_PROJECT})\noption(PHMAP_BUILD_EXAMPLES \"Whether or not to build the examples\" ${PHMAP_MASTER_PROJECT})\n\nif(MSVC)\n    add_compile_options(\"$<$<COMPILE_LANGUAGE:CXX>:/bigobj>\")\nendif()\n\nif (PHMAP_BUILD_TESTS OR PHMAP_BUILD_EXAMPLES)\n    include_directories(${PROJECT_SOURCE_DIR})\nendif()\n\nif (PHMAP_BUILD_TESTS)\n\n    if (NOT PHMAP_GTEST_LIBS)\n        include(cmake/DownloadGTest.cmake)\n\n        check_target(gtest)\n        check_target(gtest_main)\n        check_target(gmock)\n        set(PHMAP_GTEST_LIBS gmock_main)\n    endif()\n\n    enable_testing()\n\n    ## ---------------- regular hash maps ----------------------------\n    phmap_cc_test(NAME container_memory SRCS \"tests/container_memory_test.cc\"\n                  DEPS ${PHMAP_GTEST_LIBS})\n\n    phmap_cc_test(NAME hash_policy_testing SRCS \"tests/hash_policy_testing_test.cc\"\n                  DEPS ${PHMAP_GTEST_LIBS})\n\n    phmap_cc_test(NAME node_hash_policy SRCS \"tests/node_hash_policy_test.cc\"\n                  DEPS ${PHMAP_GTEST_LIBS})\n\n    phmap_cc_test(NAME raw_hash_set SRCS \"tests/raw_hash_set_test.cc\"\n                  DEPS ${PHMAP_GTEST_LIBS})\n\n    phmap_cc_test(NAME raw_hash_set_allocator SRCS \"tests/raw_hash_set_allocator_test.cc\"\n                  DEPS ${PHMAP_GTEST_LIBS})\n\n    ## ---------------- regular hash maps ----------------------------\n    phmap_cc_test(NAME flat_hash_set SRCS \"tests/flat_hash_set_test.cc\"\n                  COPTS \"-DUNORDERED_SET_CXX17\" DEPS ${PHMAP_GTEST_LIBS})\n\n    phmap_cc_test(NAME flat_hash_map SRCS \"tests/flat_hash_map_test.cc\"\n                  DEPS ${PHMAP_GTEST_LIBS})\n\n    phmap_cc_test(NAME node_hash_map SRCS \"tests/node_hash_map_test.cc\"\n                  DEPS ${PHMAP_GTEST_LIBS})\n\n    phmap_cc_test(NAME node_hash_set SRCS \"tests/node_hash_set_test.cc\"\n                  COPTS \"-DUNORDERED_SET_CXX17\" DEPS  ${PHMAP_GTEST_LIBS})\n\n    ## --------------- parallel hash maps -----------------------------------------------\n    phmap_cc_test(NAME parallel_flat_hash_map SRCS \"tests/parallel_flat_hash_map_test.cc\"\n                  COPTS \"-DUNORDERED_MAP_CXX17\" DEPS ${PHMAP_GTEST_LIBS})\n\n    phmap_cc_test(NAME parallel_flat_hash_set SRCS \"tests/parallel_flat_hash_set_test.cc\"\n                  COPTS \"-DUNORDERED_SET_CXX17\" DEPS ${PHMAP_GTEST_LIBS})\n\n    phmap_cc_test(NAME parallel_node_hash_map SRCS \"tests/parallel_node_hash_map_test.cc\"\n                  DEPS ${PHMAP_GTEST_LIBS})\n\n    phmap_cc_test(NAME parallel_node_hash_set SRCS \"tests/parallel_node_hash_set_test.cc\"\n                  COPTS \"-DUNORDERED_SET_CXX17\" DEPS  ${PHMAP_GTEST_LIBS})\n\n    phmap_cc_test(NAME parallel_flat_hash_map_mutex SRCS \"tests/parallel_flat_hash_map_mutex_test.cc\"\n                  COPTS \"-DUNORDERED_MAP_CXX17\" DEPS ${PHMAP_GTEST_LIBS})\n\n    phmap_cc_test(NAME dump_load SRCS \"tests/dump_load_test.cc\"\n                  COPTS \"-DUNORDERED_MAP_CXX17\" DEPS ${PHMAP_GTEST_LIBS})\n\n    phmap_cc_test(NAME erase_if SRCS \"tests/erase_if_test.cc\"\n                  COPTS \"-DUNORDERED_MAP_CXX17\" DEPS ${PHMAP_GTEST_LIBS})\n\n    ## --------------- btree -----------------------------------------------\n    phmap_cc_test(NAME btree SRCS \"tests/btree_test.cc\"\n                  DEPS ${PHMAP_GTEST_LIBS})\n\n\nendif()\n\nif (PHMAP_BUILD_EXAMPLES)\n    if(NOT MSVC)\n        add_compile_options(\"$<$<COMPILE_LANGUAGE:CXX>:-pedantic;-Wall;-Wextra;-Wcast-align;-Wcast-qual;-Wdisabled-optimization;-Winit-self;-Wlogical-op;-Wmissing-include-dirs;-Woverloaded-virtual;-Wredundant-decls;-Wshadow;-Wstrict-null-sentinel;-Wswitch-default;-Wno-unused>\")\n        if (NOT CMAKE_COMPILER_IS_GNUCC OR CMAKE_CXX_COMPILER_VERSION VERSION_GREATER 5.0)\n            add_compile_options(\"$<$<COMPILE_LANGUAGE:CXX>:-Wno-unknown-warning-option;-Wno-gnu-zero-variadic-macro-arguments>\")\n        endif()\n    else()\n        add_compile_options(\"$<$<COMPILE_LANGUAGE:CXX>:/W4;/Zc:__cplusplus>\")\n    endif()\n\n    set(THREADS_PREFER_PTHREAD_FLAG ON)\n    find_package(Threads REQUIRED)\n\n    add_executable(ex_allmaps examples/allmaps.cc phmap.natvis)\n    add_executable(ex_basic examples/basic.cc phmap.natvis)\n    add_executable(ex_bench examples/bench.cc phmap.natvis)\n    add_executable(ex_emplace examples/emplace.cc phmap.natvis)\n    if (MSVC)\n        add_executable(ex_lazy_emplace_l examples/lazy_emplace_l.cc phmap.natvis)\n    endif()\n    add_executable(ex_serialize examples/serialize.cc phmap.natvis)\n    #target_include_directories(ex_serialize PUBLIC $<BUILD_INTERFACE:${CMAKE_CURRENT_SOURCE_DIR}/../cereal/include>)\n    add_executable(ex_hash_std examples/hash_std.cc phmap.natvis)\n    add_executable(ex_hash_value examples/hash_value.cc phmap.natvis)\n    add_executable(ex_hash examples/hash.cc phmap.natvis)\n    add_executable(ex_two_files examples/f1.cc examples/f2.cc phmap.natvis)\n    add_executable(ex_insert_bench examples/insert_bench.cc phmap.natvis)\n    add_executable(ex_knucleotide examples/knucleotide.cc phmap.natvis)\n    add_executable(ex_dump_load examples/dump_load.cc phmap.natvis)\n    add_executable(ex_btree examples/btree.cc phmap.natvis)\n    add_executable(ex_hash_bench examples/hash_bench.cc phmap.natvis)\n    add_executable(ex_matt examples/matt.cc phmap.natvis)\n    add_executable(ex_mt_word_counter examples/mt_word_counter.cc phmap.natvis)\n    add_executable(ex_p_bench examples/p_bench.cc phmap.natvis)\n\n    #set(Boost_INCLUDE_DIR /home/greg/dev/boost_1_82_0) # if boost installed in non-standard location\n    set(Boost_USE_STATIC_LIBS OFF)\n    set(Boost_USE_MULTITHREADED ON)\n    set(Boost_USE_STATIC_RUNTIME OFF)\n\n    # llil4map.cc - see https://www.perlmonks.com/?node_id=11149643\n    # -------------------------------------------------------------\n    find_package(OpenMP)\n    find_package(Boost 1.70.0)\n    if (OpenMP_FOUND AND Boost_FOUND AND \"cxx_std_20\" IN_LIST CMAKE_CXX_COMPILE_FEATURES)\n       add_executable(ex_llil4map examples/llil4map.cc phmap.natvis)\n       target_include_directories(ex_llil4map PRIVATE ${Boost_INCLUDE_DIRS})\n       target_compile_features(ex_llil4map PUBLIC cxx_std_20)\n       find_package(TBB COMPONENTS tbb)\n       if (TBB_FOUND)\n           target_link_libraries(ex_llil4map PRIVATE TBB::tbb)\n       endif()\n       target_link_libraries(ex_llil4map PRIVATE OpenMP::OpenMP_CXX)\n       target_compile_options(ex_llil4map PRIVATE \"${OpenMP_CXX_FLAGS}\")\n\n       file(COPY examples/llil_utils DESTINATION \"${CMAKE_CURRENT_BINARY_DIR}\")\n    endif()\n\n    if (Boost_FOUND)\n       add_executable(ex_custom_pointer examples/custom_pointer.cc phmap.natvis)\n       target_include_directories(ex_custom_pointer PRIVATE ${Boost_INCLUDE_DIRS})\n\n       add_executable(ex_llil examples/llil.cc phmap.natvis)\n       target_include_directories(ex_llil PRIVATE ${Boost_INCLUDE_DIRS})\n       target_compile_features(ex_llil PUBLIC cxx_std_20)\n       target_link_libraries(ex_llil Threads::Threads)\n    endif()\n\n    target_link_libraries(ex_knucleotide Threads::Threads)\n    target_link_libraries(ex_bench Threads::Threads)\nendif()\n"
        },
        {
          "name": "LICENSE",
          "type": "blob",
          "size": 11.09375,
          "content": "\n                                 Apache License\n                           Version 2.0, January 2004\n                        https://www.apache.org/licenses/\n\n   TERMS AND CONDITIONS FOR USE, REPRODUCTION, AND DISTRIBUTION\n\n   1. Definitions.\n\n      \"License\" shall mean the terms and conditions for use, reproduction,\n      and distribution as defined by Sections 1 through 9 of this document.\n\n      \"Licensor\" shall mean the copyright owner or entity authorized by\n      the copyright owner that is granting the License.\n\n      \"Legal Entity\" shall mean the union of the acting entity and all\n      other entities that control, are controlled by, or are under common\n      control with that entity. For the purposes of this definition,\n      \"control\" means (i) the power, direct or indirect, to cause the\n      direction or management of such entity, whether by contract or\n      otherwise, or (ii) ownership of fifty percent (50%) or more of the\n      outstanding shares, or (iii) beneficial ownership of such entity.\n\n      \"You\" (or \"Your\") shall mean an individual or Legal Entity\n      exercising permissions granted by this License.\n\n      \"Source\" form shall mean the preferred form for making modifications,\n      including but not limited to software source code, documentation\n      source, and configuration files.\n\n      \"Object\" form shall mean any form resulting from mechanical\n      transformation or translation of a Source form, including but\n      not limited to compiled object code, generated documentation,\n      and conversions to other media types.\n\n      \"Work\" shall mean the work of authorship, whether in Source or\n      Object form, made available under the License, as indicated by a\n      copyright notice that is included in or attached to the work\n      (an example is provided in the Appendix below).\n\n      \"Derivative Works\" shall mean any work, whether in Source or Object\n      form, that is based on (or derived from) the Work and for which the\n      editorial revisions, annotations, elaborations, or other modifications\n      represent, as a whole, an original work of authorship. For the purposes\n      of this License, Derivative Works shall not include works that remain\n      separable from, or merely link (or bind by name) to the interfaces of,\n      the Work and Derivative Works thereof.\n\n      \"Contribution\" shall mean any work of authorship, including\n      the original version of the Work and any modifications or additions\n      to that Work or Derivative Works thereof, that is intentionally\n      submitted to Licensor for inclusion in the Work by the copyright owner\n      or by an individual or Legal Entity authorized to submit on behalf of\n      the copyright owner. For the purposes of this definition, \"submitted\"\n      means any form of electronic, verbal, or written communication sent\n      to the Licensor or its representatives, including but not limited to\n      communication on electronic mailing lists, source code control systems,\n      and issue tracking systems that are managed by, or on behalf of, the\n      Licensor for the purpose of discussing and improving the Work, but\n      excluding communication that is conspicuously marked or otherwise\n      designated in writing by the copyright owner as \"Not a Contribution.\"\n\n      \"Contributor\" shall mean Licensor and any individual or Legal Entity\n      on behalf of whom a Contribution has been received by Licensor and\n      subsequently incorporated within the Work.\n\n   2. Grant of Copyright License. Subject to the terms and conditions of\n      this License, each Contributor hereby grants to You a perpetual,\n      worldwide, non-exclusive, no-charge, royalty-free, irrevocable\n      copyright license to reproduce, prepare Derivative Works of,\n      publicly display, publicly perform, sublicense, and distribute the\n      Work and such Derivative Works in Source or Object form.\n\n   3. Grant of Patent License. Subject to the terms and conditions of\n      this License, each Contributor hereby grants to You a perpetual,\n      worldwide, non-exclusive, no-charge, royalty-free, irrevocable\n      (except as stated in this section) patent license to make, have made,\n      use, offer to sell, sell, import, and otherwise transfer the Work,\n      where such license applies only to those patent claims licensable\n      by such Contributor that are necessarily infringed by their\n      Contribution(s) alone or by combination of their Contribution(s)\n      with the Work to which such Contribution(s) was submitted. If You\n      institute patent litigation against any entity (including a\n      cross-claim or counterclaim in a lawsuit) alleging that the Work\n      or a Contribution incorporated within the Work constitutes direct\n      or contributory patent infringement, then any patent licenses\n      granted to You under this License for that Work shall terminate\n      as of the date such litigation is filed.\n\n   4. Redistribution. You may reproduce and distribute copies of the\n      Work or Derivative Works thereof in any medium, with or without\n      modifications, and in Source or Object form, provided that You\n      meet the following conditions:\n\n      (a) You must give any other recipients of the Work or\n          Derivative Works a copy of this License; and\n\n      (b) You must cause any modified files to carry prominent notices\n          stating that You changed the files; and\n\n      (c) You must retain, in the Source form of any Derivative Works\n          that You distribute, all copyright, patent, trademark, and\n          attribution notices from the Source form of the Work,\n          excluding those notices that do not pertain to any part of\n          the Derivative Works; and\n\n      (d) If the Work includes a \"NOTICE\" text file as part of its\n          distribution, then any Derivative Works that You distribute must\n          include a readable copy of the attribution notices contained\n          within such NOTICE file, excluding those notices that do not\n          pertain to any part of the Derivative Works, in at least one\n          of the following places: within a NOTICE text file distributed\n          as part of the Derivative Works; within the Source form or\n          documentation, if provided along with the Derivative Works; or,\n          within a display generated by the Derivative Works, if and\n          wherever such third-party notices normally appear. The contents\n          of the NOTICE file are for informational purposes only and\n          do not modify the License. You may add Your own attribution\n          notices within Derivative Works that You distribute, alongside\n          or as an addendum to the NOTICE text from the Work, provided\n          that such additional attribution notices cannot be construed\n          as modifying the License.\n\n      You may add Your own copyright statement to Your modifications and\n      may provide additional or different license terms and conditions\n      for use, reproduction, or distribution of Your modifications, or\n      for any such Derivative Works as a whole, provided Your use,\n      reproduction, and distribution of the Work otherwise complies with\n      the conditions stated in this License.\n\n   5. Submission of Contributions. Unless You explicitly state otherwise,\n      any Contribution intentionally submitted for inclusion in the Work\n      by You to the Licensor shall be under the terms and conditions of\n      this License, without any additional terms or conditions.\n      Notwithstanding the above, nothing herein shall supersede or modify\n      the terms of any separate license agreement you may have executed\n      with Licensor regarding such Contributions.\n\n   6. Trademarks. This License does not grant permission to use the trade\n      names, trademarks, service marks, or product names of the Licensor,\n      except as required for reasonable and customary use in describing the\n      origin of the Work and reproducing the content of the NOTICE file.\n\n   7. Disclaimer of Warranty. Unless required by applicable law or\n      agreed to in writing, Licensor provides the Work (and each\n      Contributor provides its Contributions) on an \"AS IS\" BASIS,\n      WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or\n      implied, including, without limitation, any warranties or conditions\n      of TITLE, NON-INFRINGEMENT, MERCHANTABILITY, or FITNESS FOR A\n      PARTICULAR PURPOSE. You are solely responsible for determining the\n      appropriateness of using or redistributing the Work and assume any\n      risks associated with Your exercise of permissions under this License.\n\n   8. Limitation of Liability. In no event and under no legal theory,\n      whether in tort (including negligence), contract, or otherwise,\n      unless required by applicable law (such as deliberate and grossly\n      negligent acts) or agreed to in writing, shall any Contributor be\n      liable to You for damages, including any direct, indirect, special,\n      incidental, or consequential damages of any character arising as a\n      result of this License or out of the use or inability to use the\n      Work (including but not limited to damages for loss of goodwill,\n      work stoppage, computer failure or malfunction, or any and all\n      other commercial damages or losses), even if such Contributor\n      has been advised of the possibility of such damages.\n\n   9. Accepting Warranty or Additional Liability. While redistributing\n      the Work or Derivative Works thereof, You may choose to offer,\n      and charge a fee for, acceptance of support, warranty, indemnity,\n      or other liability obligations and/or rights consistent with this\n      License. However, in accepting such obligations, You may act only\n      on Your own behalf and on Your sole responsibility, not on behalf\n      of any other Contributor, and only if You agree to indemnify,\n      defend, and hold each Contributor harmless for any liability\n      incurred by, or claims asserted against, such Contributor by reason\n      of your accepting any such warranty or additional liability.\n\n   END OF TERMS AND CONDITIONS\n\n   APPENDIX: How to apply the Apache License to your work.\n\n      To apply the Apache License to your work, attach the following\n      boilerplate notice, with the fields enclosed by brackets \"[]\"\n      replaced with your own identifying information. (Don't include\n      the brackets!)  The text should be enclosed in the appropriate\n      comment syntax for the file format. We also recommend that a\n      file or class name and description of purpose be included on the\n      same \"printed page\" as the copyright notice for easier\n      identification within third-party archives.\n\n   Copyright [yyyy] [name of copyright owner]\n\n   Licensed under the Apache License, Version 2.0 (the \"License\");\n   you may not use this file except in compliance with the License.\n   You may obtain a copy of the License at\n\n       https://www.apache.org/licenses/LICENSE-2.0\n\n   Unless required by applicable law or agreed to in writing, software\n   distributed under the License is distributed on an \"AS IS\" BASIS,\n   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n   See the License for the specific language governing permissions and\n   limitations under the License.\n"
        },
        {
          "name": "README.md",
          "type": "blob",
          "size": 19.3505859375,
          "content": "\n<img src=\"https://github.com/greg7mdp/parallel-hashmap/blob/master/html/img/phash.png?raw=true\" width=\"120\" align=\"middle\">\n\n# The Parallel Hashmap\n\n[![License: Apache-2.0](https://img.shields.io/badge/License-Apache-yellow.svg)](https://opensource.org/licenses/Apache-2.0) [![Linux](https://github.com/greg7mdp/parallel-hashmap/actions/workflows/linux.yml/badge.svg)](https://github.com/greg7mdp/parallel-hashmap/actions/workflows/linux.yml)  [![MacOS](https://github.com/greg7mdp/parallel-hashmap/actions/workflows/macos.yml/badge.svg)](https://github.com/greg7mdp/parallel-hashmap/actions/workflows/macos.yml) [![Windows](https://github.com/greg7mdp/parallel-hashmap/actions/workflows/windows.yml/badge.svg)](https://github.com/greg7mdp/parallel-hashmap/actions/workflows/windows.yml)\n\n## Overview\n\nThis repository aims to provide a set of excellent **hash map** implementations, as well as a **btree** alternative to std::map and std::set, with the following characteristics:\n\n- **Header only**: nothing to build, just copy the `parallel_hashmap` directory to your project and you are good to go.\n\n- **drop-in replacement** for `std::unordered_map`, `std::unordered_set`, `std::map` and `std::set`\n\n- Compiler with **C++11 support** required, **C++14 and C++17 APIs are provided (such as `try_emplace`)**\n\n- **Very efficient**, significantly faster than your compiler's unordered map/set or Boost's, or than [sparsepp](https://github.com/greg7mdp/sparsepp)\n\n- **Memory friendly**: low memory usage, although a little higher than [sparsepp](https://github.com/greg7mdp/sparsepp)\n\n- Supports **heterogeneous lookup**\n\n- Easy to **forward declare**: just include `phmap_fwd_decl.h` in your header files to forward declare Parallel Hashmap containers [note: this does not work currently for hash maps with pointer keys]\n\n- **Dump/load** feature: when a `flat` hash map stores data that is `std::trivially_copyable`, the table can be dumped to disk and restored as a single array, very efficiently, and without requiring any hash computation. This is typically about 10 times faster than doing element-wise serialization to disk, but it will use 10% to 60% extra disk space. See `examples/serialize.cc`. _(flat hash map/set only)_\n\n- **Tested** on Windows (vs2015 & vs2017, vs2019, vs2022, Intel compiler 18 and 19), linux (g++ 4.8, 5, 6, 7, 8, 9, 10, 11, 12, clang++ 3.9 to 16) and MacOS (g++ and clang++) - click on travis and appveyor icons above for detailed test status.\n\n- Automatic support for **boost's hash_value()** method for providing the hash function (see `examples/hash_value.h`). Also default hash support for `std::pair` and `std::tuple`.\n\n- **natvis** visualization support in Visual Studio _(hash map/set only)_\n\n@byronhe kindly provided this [Chinese translation](https://byronhe.com/post/2020/11/10/parallel-hashmap-btree-fast-multi-thread-intro/) of the README.md.\n\n\n## Parallel-hashmap or GTL?\n\nThe observant among us may have noticed that I have two github repos, [parallel-hashmap](https://github.com/greg7mdp/parallel-hashmap) and [gtl](https://github.com/greg7mdp/gtl), which both provide very similar functionality. Indeed the hash tables in both are equivalent and the code mostly the same. The main difference is that  [parallel-hashmap](https://github.com/greg7mdp/parallel-hashmap) only requires a C++11 compiler, while  [gtl](https://github.com/greg7mdp/gtl) requires a C++20 compiler.\n\nMy recommendation would be to use [gtl](https://github.com/greg7mdp/gtl) if you are compiling with C++20 or higher, and  [parallel-hashmap](https://github.com/greg7mdp/parallel-hashmap) otherwise. While the included hash maps are equivalent, [gtl](https://github.com/greg7mdp/gtl) is where new development occurs, and it will include useful new classes.\n\n## Fast *and*  memory friendly\n\nClick here [For a full writeup explaining the design and benefits of the Parallel Hashmap](https://greg7mdp.github.io/parallel-hashmap/).\n\nThe hashmaps and btree provided here are built upon those open sourced by Google in the Abseil library. The hashmaps use closed hashing, where values are stored directly into a memory array, avoiding memory indirections. By using parallel SSE2 instructions, these hashmaps are able to look up items by checking 16 slots in parallel,  allowing the implementation to remain fast even when the table is filled up to 87.5% capacity.\n\n> **IMPORTANT:** This repository borrows code from the [abseil-cpp](https://github.com/abseil/abseil-cpp) repository, with modifications, and may behave differently from the original. This repository is an independent work, with no guarantees implied or provided by the authors. Please visit [abseil-cpp](https://github.com/abseil/abseil-cpp) for the official Abseil libraries.\n\n## Installation\n\nCopy the parallel_hashmap directory to your project. Update your include path. That's all.\n\nIf you are using Visual Studio, you probably want to add `phmap.natvis` to your projects. This will allow for a clear display of the hash table contents in the debugger.\n\n> A cmake configuration files (CMakeLists.txt) is provided for building the tests and examples. Command for building and running the tests is:\n\n```sh\ncmake -DPHMAP_BUILD_TESTS=ON -DPHMAP_BUILD_EXAMPLES=ON -B build\n\ncmake --build build\n\nctest --test-dir build\n```\n\n## Example\n\n```c++\n#include <iostream>\n#include <string>\n#include <parallel_hashmap/phmap.h>\n\nusing phmap::flat_hash_map;\n\nint main()\n{\n    // Create an unordered_map of three strings (that map to strings)\n    flat_hash_map<std::string, std::string> email =\n    {\n        { \"tom\",  \"tom@gmail.com\"},\n        { \"jeff\", \"jk@gmail.com\"},\n        { \"jim\",  \"jimg@microsoft.com\"}\n    };\n\n    // Iterate and print keys and values\n    for (const auto& n : email)\n        std::cout << n.first << \"'s email is: \" << n.second << \"\\n\";\n\n    // Add a new entry\n    email[\"bill\"] = \"bg@whatever.com\";\n\n    // and print it\n    std::cout << \"bill's email is: \" << email[\"bill\"] << \"\\n\";\n\n    return 0;\n}\n```\n\n## Various hash maps and their pros and cons\n\nThe header `parallel_hashmap/phmap.h` provides the implementation for the following eight hash tables:\n- phmap::flat_hash_set\n- phmap::flat_hash_map\n- phmap::node_hash_set\n- phmap::node_hash_map\n- phmap::parallel_flat_hash_set\n- phmap::parallel_flat_hash_map\n- phmap::parallel_node_hash_set\n- phmap::parallel_node_hash_map\n\nThe header `parallel_hashmap/btree.h` provides the implementation for the following btree-based ordered containers:\n- phmap::btree_set\n- phmap::btree_map\n- phmap::btree_multiset\n- phmap::btree_multimap\n\nThe btree containers are direct ports from Abseil, and should behave exactly the same as the Abseil ones, modulo small differences (such as supporting std::string_view instead of absl::string_view, and being forward declarable).\n\nWhen btrees are mutated, values stored within can be moved in memory. This means that pointers or iterators to values stored in btree containers can be invalidated when that btree is modified. This is a significant difference with `std::map` and `std::set`, as the std containers do offer a guarantee of pointer stability. The same is true for the 'flat' hash maps and sets.\n\nThe full types with template parameters can be found in the [parallel_hashmap/phmap_fwd_decl.h](https://raw.githubusercontent.com/greg7mdp/parallel-hashmap/master/parallel_hashmap/phmap_fwd_decl.h) header, which is useful for forward declaring the Parallel Hashmaps when necessary.\n\n**Key decision points for hash containers:**\n\n- The `flat` hash maps will move the keys and values in memory. So if you keep a pointer to something inside a `flat` hash map, this pointer may become invalid when the map is mutated. The `node` hash maps don't, and should be used instead if this is a problem.\n\n- The `flat` hash maps will use less memory, and usually be faster than the `node` hash maps, so use them if you can. the exception is when the values inserted in the hash map are large (say more than 100 bytes [*needs testing*]) and costly to move.\n\n- The `parallel` hash maps are preferred when you have a few hash maps that will store a very large number of values. The `non-parallel` hash maps are preferred if you have a large number of hash maps, each storing a relatively small number of values.\n\n- The benefits of the `parallel` hash maps are:\n   a. reduced peak memory usage (when resizing), and\n   b. multithreading support (and inherent internal parallelism)\n\n**Key decision points for btree containers:**\n\nBtree containers are ordered containers, which can be used as alternatives to `std::map` and `std::set`. They store multiple values in each tree node, and are therefore more cache friendly and use significantly less memory.\n\nBtree containers will usually be preferable to the default red-black trees of the STL, except when:\n- pointer stability or iterator stability is required\n- the value_type is large and expensive to move\n\nWhen an ordering is not needed, a hash container is typically a better choice than a btree one.\n\n## Changes to Abseil's hashmaps\n\n- The default hash framework is std::hash, not absl::Hash. However, if you prefer the default to be the Abseil hash framework, include the Abseil headers before `phmap.h` and define the preprocessor macro `PHMAP_USE_ABSL_HASH`.\n\n- The `erase(iterator)` and `erase(const_iterator)` both return an iterator to the element following the removed element, as does the std::unordered_map. A non-standard `void _erase(iterator)` is provided in case the return value is not needed.\n\n- No new types, such as `absl::string_view`, are provided. All types with a `std::hash<>` implementation are supported by phmap tables (including `std::string_view` of course if your compiler provides it).\n\n- The Abseil hash tables internally randomize a hash seed, so that the table iteration order is non-deterministic. This can be useful to prevent *Denial Of Service*  attacks when a hash table is used for a customer facing web service, but it can make debugging more difficult. The *phmap* hashmaps by default do **not** implement this randomization, but it can be enabled by adding `#define PHMAP_NON_DETERMINISTIC 1` before including the header `phmap.h` (as is done in raw_hash_set_test.cc).\n\n- Unlike the Abseil hash maps, we do an internal mixing of the hash value provided. This prevents serious degradation of the hash table performance when the hash function provided by the user has poor entropy distribution. The cost in performance is very minimal, and this helps provide reliable performance even with *imperfect* hash functions. Disabling this mixing is possible by defining the preprocessor macro `PHMAP_DISABLE_MIX=1` before `phmap.h` is included, but it is not recommended.\n\n\n## Memory usage\n\n|  type                 |    memory usage   | additional *peak* memory usage when resizing  |\n|-----------------------|-------------------|-----------------------------------------------|\n| flat tables           | ![flat_mem_usage](https://github.com/greg7mdp/parallel-hashmap/blob/master/html/img/flat_mem_usage.png?raw=true) | ![flat_peak_usage](https://github.com/greg7mdp/parallel-hashmap/blob/master/html/img/flat_peak.png?raw=true) |\n| node tables           | ![node_mem_usage](https://github.com/greg7mdp/parallel-hashmap/blob/master/html/img/node_mem_usage.png?raw=true) | ![node_peak_usage](https://github.com/greg7mdp/parallel-hashmap/blob/master/html/img/node_peak.png?raw=true) |\n| parallel flat tables  | ![flat_mem_usage](https://github.com/greg7mdp/parallel-hashmap/blob/master/html/img/flat_mem_usage.png?raw=true) | ![parallel_flat_peak](https://github.com/greg7mdp/parallel-hashmap/blob/master/html/img/parallel_flat_peak.png?raw=true) |\n| parallel node tables  | ![node_mem_usage](https://github.com/greg7mdp/parallel-hashmap/blob/master/html/img/node_mem_usage.png?raw=true) | ![parallel_node_peak](https://github.com/greg7mdp/parallel-hashmap/blob/master/html/img/parallel_node_peak.png?raw=true) |\n\n\n- *size()* is the number of values in the container, as returned by the size() method\n- *load_factor()* is the ratio: `size() / bucket_count()`. It varies between 0.4375 (just after the resize) to 0.875 (just before the resize). The size of the bucket array doubles at each resize.\n- the value 9 comes from `sizeof(void *) + 1`, as the *node* hash maps store one pointer plus one byte of metadata for each entry in the bucket array.\n- flat tables store the values, plus one byte of metadata per value), directly into the bucket array, hence the `sizeof(C::value_type) + 1`.\n- the additional peak memory usage (when resizing) corresponds the the old bucket array (half the size of the new one, hence the 0.5), which contains the values to be copied to the new bucket array, and which is freed when the values have been copied.\n- the *parallel* hashmaps, when created with a template parameter N=4, create 16 submaps. When the hash values are well distributed, and in single threaded mode, only one of these 16 submaps resizes at any given time, hence the factor `0.03` roughly equal to `0.5 / 16`\n\n## Iterator invalidation for hash containers\n\nThe rules are the same as for `std::unordered_map`, and are valid for all the phmap hash containers:\n\n\n|    Operations\t                            | Invalidated                |\n|-------------------------------------------|----------------------------|\n| All read only operations, swap, std::swap | Never                      |\n| clear, rehash, reserve, operator=         | Always                     |\n| insert, emplace, emplace_hint, operator[] | Only if rehash triggered   |\n| erase                                     | Only to the element erased |\n\n## Iterator invalidation for btree containers\n\nUnlike for `std::map` and `std::set`, any mutating operation may invalidate existing iterators to btree containers.\n\n\n|    Operations\t                            | Invalidated                |\n|-------------------------------------------|----------------------------|\n| All read only operations, swap, std::swap | Never                      |\n| clear, operator=                          | Always                     |\n| insert, emplace, emplace_hint, operator[] | Yes                        |\n| erase                                     | Yes                        |\n\n## Example 2 - providing a hash function for a user-defined class\n\nIn order to use a flat_hash_set or flat_hash_map, a hash function should be provided. This can be done with one of the following methods:\n\n- Provide a hash functor via the HashFcn template parameter\n\n- As with boost, you may add a `hash_value()` friend function in your class.\n\nFor example:\n\n```c++\n#include <parallel_hashmap/phmap_utils.h> // minimal header providing phmap::HashState()\n#include <string>\nusing std::string;\n\nstruct Person\n{\n    bool operator==(const Person &o) const\n    {\n        return _first == o._first && _last == o._last && _age == o._age;\n    }\n\n    friend size_t hash_value(const Person &p)\n    {\n        return phmap::HashState().combine(0, p._first, p._last, p._age);\n    }\n\n    string _first;\n    string _last;\n    int    _age;\n};\n```\n\n- Inject a specialization of `std::hash` for the class into the \"std\" namespace. We provide a convenient and small header `phmap_utils.h` which allows to easily add such specializations.\n\nFor example:\n\n### file \"Person.h\"\n\n```c++\n#include <parallel_hashmap/phmap_utils.h> // minimal header providing phmap::HashState()\n#include <string>\nusing std::string;\n\nstruct Person\n{\n    bool operator==(const Person &o) const\n    {\n        return _first == o._first && _last == o._last && _age == o._age;\n    }\n\n    string _first;\n    string _last;\n    int    _age;\n};\n\nnamespace std\n{\n    // inject specialization of std::hash for Person into namespace std\n    // ----------------------------------------------------------------\n    template<> struct hash<Person>\n    {\n        std::size_t operator()(Person const &p) const\n        {\n            return phmap::HashState().combine(0, p._first, p._last, p._age);\n        }\n    };\n}\n```\n\nThe `std::hash` specialization for `Person` combines the hash values for both first and last name and age, using the convenient phmap::HashState() function, and returns the combined hash value.\n\n### file \"main.cpp\"\n\n```c++\n#include \"Person.h\"   // defines Person  with std::hash specialization\n\n#include <iostream>\n#include <parallel_hashmap/phmap.h>\n\nint main()\n{\n    // As we have defined a specialization of std::hash() for Person,\n    // we can now create sparse_hash_set or sparse_hash_map of Persons\n    // ----------------------------------------------------------------\n    phmap::flat_hash_set<Person> persons =\n        { { \"John\", \"Mitchell\", 35 },\n          { \"Jane\", \"Smith\",    32 },\n          { \"Jane\", \"Smith\",    30 },\n        };\n\n    for (auto& p: persons)\n        std::cout << p._first << ' ' << p._last << \" (\" << p._age << \")\" << '\\n';\n\n}\n```\n\n\n## Thread safety\n\nParallel Hashmap containers follow the thread safety rules of the Standard C++ library. In Particular:\n\n- A single phmap hash table is thread safe for reading from multiple threads. For example, given a hash table A, it is safe to read A from thread 1 and from thread 2 simultaneously.\n\n- If a single hash table is being written to by one thread, then all reads and writes to that hash table on the same or other threads must be protected. For example, given a hash table A, if thread 1 is writing to A, then thread 2 must be prevented from reading from or writing to A.\n\n- It is safe to read and write to one instance of a type even if another thread is reading or writing to a different instance of the same type. For example, given hash tables A and B of the same type, it is safe if A is being written in thread 1 and B is being read in thread 2.\n\n- The *parallel* tables can be made internally thread-safe for concurrent read and write access, by providing a synchronization type (for example [std::mutex](https://en.cppreference.com/w/cpp/thread/mutex)) as the last template argument. Because locking is performed at the *submap* level, a high level of concurrency can still be achieved. Read access can be done safely using `if_contains()`, which passes a reference value to the callback while holding the *submap* lock. Similarly, write access can be done safely using `modify_if`, `try_emplace_l` or `lazy_emplace_l`. However, please be aware that iterators or references returned by standard APIs are not protected by the mutex, so they cannot be used reliably on a hash map which can be changed by another thread.\n\n- Examples on how to use various mutex types, including boost::mutex, boost::shared_mutex and absl::Mutex can be found in `examples/bench.cc`\n\n\n## Using the Parallel Hashmap from languages other than C++\n\nWhile C++ is the native language of the Parallel Hashmap, we welcome bindings making it available for other languages. One such implementation has been created for Python and is described below:\n\n- [GetPy - A Simple, Fast, and Small Hash Map for Python](https://github.com/atom-moyer/getpy): GetPy is a thin and robust binding to The Parallel Hashmap (https://github.com/greg7mdp/parallel-hashmap.git) which is the current state of the art for minimal memory overhead and fast runtime speed. The binding layer is supported by PyBind11 (https://github.com/pybind/pybind11.git) which is fast to compile and simple to extend. Serialization is handled by Cereal (https://github.com/USCiLab/cereal.git) which supports streaming binary serialization, a critical feature for the large hash maps this package is designed to support.\n\n## Acknowledgements\n\nMany thanks to the Abseil developers for implementing the swiss table and btree data structures (see [abseil-cpp](https://github.com/abseil/abseil-cpp)) upon which this work is based, and to Google for releasing it as open-source.\n"
        },
        {
          "name": "benchmark",
          "type": "tree",
          "content": null
        },
        {
          "name": "cmake",
          "type": "tree",
          "content": null
        },
        {
          "name": "css",
          "type": "tree",
          "content": null
        },
        {
          "name": "doc",
          "type": "tree",
          "content": null
        },
        {
          "name": "examples",
          "type": "tree",
          "content": null
        },
        {
          "name": "html",
          "type": "tree",
          "content": null
        },
        {
          "name": "index.html",
          "type": "blob",
          "size": 33.67578125,
          "content": "<!DOCTYPE html>\n<html lang=\"en\">\n  <head>\n    <meta charset=\"utf-8\">\n    <title>The Parallel Hashmap (Gregory Popovitch)</title>\n    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\">\n    <meta name=\"description\" content=\"\">\n    <meta name=\"author\" content=\"\">\n\n    <link href=\"http://fonts.googleapis.com/css?family=Inconsolata\" rel=\"stylesheet\">\n    \n    <link href=\"css/bootstrap-responsive.min.css\" rel=\"stylesheet\">\n    <link href=\"css/colors.css\" rel=\"stylesheet\">\n    <link rel=\"alternate\" type=\"application/atom+xml\" title=\"The Parallel Hashmap\" href=\"rss/atom.xml\" />\n\n          <style type=\"text/css\">\n    a.sourceLine { display: inline-block; line-height: 1.25; }\n    a.sourceLine { pointer-events: none; color: inherit; text-decoration: inherit; }\n    a.sourceLine:empty { height: 1.2em; }\n    .sourceCode { overflow: visible; }\n    code.sourceCode { white-space: pre; position: relative; }\n    div.sourceCode { margin: 1em 0; }\n    pre.sourceCode { margin: 0; }\n    @media screen {\n    div.sourceCode { overflow: auto; }\n    }\n    @media print {\n    code.sourceCode { white-space: pre-wrap; }\n    a.sourceLine { text-indent: -1em; padding-left: 1em; }\n    }\n    pre.numberSource a.sourceLine\n      { position: relative; left: -4em; }\n    pre.numberSource a.sourceLine::before\n      { content: attr(title);\n        position: relative; left: -1em; text-align: right; vertical-align: baseline;\n        border: none; pointer-events: all; display: inline-block;\n        -webkit-touch-callout: none; -webkit-user-select: none;\n        -khtml-user-select: none; -moz-user-select: none;\n        -ms-user-select: none; user-select: none;\n        padding: 0 4px; width: 4em;\n        color: #aaaaaa;\n      }\n    pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }\n    div.sourceCode\n      {  }\n    @media screen {\n    a.sourceLine::before { text-decoration: underline; }\n    }\n    code span.al { color: #ff0000; font-weight: bold; } /* Alert */\n    code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */\n    code span.at { color: #7d9029; } /* Attribute */\n    code span.bn { color: #40a070; } /* BaseN */\n    code span.bu { } /* BuiltIn */\n    code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */\n    code span.ch { color: #4070a0; } /* Char */\n    code span.cn { color: #880000; } /* Constant */\n    code span.co { color: #60a0b0; font-style: italic; } /* Comment */\n    code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */\n    code span.do { color: #ba2121; font-style: italic; } /* Documentation */\n    code span.dt { color: #902000; } /* DataType */\n    code span.dv { color: #40a070; } /* DecVal */\n    code span.er { color: #ff0000; font-weight: bold; } /* Error */\n    code span.ex { } /* Extension */\n    code span.fl { color: #40a070; } /* Float */\n    code span.fu { color: #06287e; } /* Function */\n    code span.im { } /* Import */\n    code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */\n    code span.kw { color: #007020; font-weight: bold; } /* Keyword */\n    code span.op { color: #666666; } /* Operator */\n    code span.ot { color: #007020; } /* Other */\n    code span.pp { color: #bc7a00; } /* Preprocessor */\n    code span.sc { color: #4070a0; } /* SpecialChar */\n    code span.ss { color: #bb6688; } /* SpecialString */\n    code span.st { color: #4070a0; } /* String */\n    code span.va { color: #19177c; } /* Variable */\n    code span.vs { color: #4070a0; } /* VerbatimString */\n    code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */\n      </style>\n            <link rel=\"stylesheet\" href=\"css/style.css\" />\n                          </head>\n\n  <body>\n\n    <div>\n\n        <div class=\"row\">\n\n          <div class=\"span9 body\">\n<!--<h1>article</h1>--!>\n<div style=\"display:none\">\n<p><span class=\"math display\">\\[\\newcommand{\\andalso}{\\quad\\quad}\n\\newcommand{\\infabbrev}[2]{\\infax{#1 \\quad\\eqdef\\quad #2}}\n\\newcommand{\\infrule}[2]{\\displaystyle \\dfrac{#1}{#2}}\n\\newcommand{\\ar}{\\rightarrow}\n\\newcommand{\\Int}{\\mathtt{Int}}\n\\newcommand{\\Bool}{\\mathtt{Bool}}\n\\newcommand{\\becomes}{\\Downarrow}\n\\newcommand{\\trule}[1]{(\\textbf{#1})}\n\\newcommand{\\FV}[1]{\\mathtt{fv}(#1)}\n\\newcommand{\\FTV}[1]{\\mathtt{ftv}(#1)}\n\\newcommand{\\BV}[1]{\\mathtt{bv}(#1)}\n\\newcommand{\\compiles}[1]{\\text{C}\\llbracket{#1}\\rrbracket}\n\\newcommand{\\exec}[1]{\\text{E}\\llbracket{#1}\\rrbracket}\n\\renewcommand{\\t}[1]{\\mathtt{#1}}\n\\newcommand{\\ite}[3]{\\text{if }#1\\text{ then }#2\\text{ else }#3}\n\\]</span></p>\n</div>\n<h1 id=\"the-parallel-hashmap\">The Parallel Hashmap</h1>\n<p>or Abseiling from the shoulders of giants - © Gregory Popovitch - March 10, 2019</p>\n<p>[tl;dr] We present a novel hashmap design, the Parallel Hashmap. Built on a modified version of Abseil's <em>flat_hash_map</em>, the Parallel Hashmap has lower space requirements, is nearly as fast as the underlying <em>flat_hash_map</em>, and can be used from multiple threads with high levels of concurrency. The <a href=\"https://github.com/greg7mdp/parallel-hashmap\">parallel hashmap</a> repository provides header-only version of the flat and node hashmaps, and their parallel versions as well.</p>\n<h3 id=\"a-quick-look-at-the-current-state-of-the-art\">A quick look at the current state of the art</h3>\n<p>If you haven't been living under a rock, you know that Google open sourced late last year their Abseil library, which includes a very efficient flat hash table implementation. The <em>absl::flat_hash_map</em> stores the values directly in a memory array, which avoids memory indirections (this is referred to as closed hashing).</p>\n<p><img src=\"https://github.com/greg7mdp/parallel-hashmap/blob/master/html/img/closed_hashing.png?raw=true\" alt=\"closed_hashing\" /></p>\n<p>Using parallel SSE2 instructions, the flat hash table is able to look up items by checking 16 slots in parallel, which allows the implementation to remain fast even when the table is filled to 87.5% capacity.</p>\n<p>The graphs below show a comparison of time and memory usage necessary to insert up to 100 million values (each value is composed of two 8-byte integers), between the default hashmap of Visual Studio 2017 (std::unordered_map), and Abseil's flat_hash_map:</p>\n<p><img src=\"https://github.com/greg7mdp/parallel-hashmap/blob/master/html/img/stl_flat_both.PNG?raw=true\" alt=\"stl_flat comparison\" /></p>\n<p>On the bottom graph, we can see that, as expected, the Abseil <em>flat_hash_map</em> is significantly faster that the default stl implementation, typically about three times faster.</p>\n<h3 id=\"the-peak-memory-usage-issue\">The peak memory usage issue</h3>\n<p>The top graph shown the memory usage for both tables.</p>\n<p>I used a separate thread to monitor the memory usage, which allows to track the increased memory usage when the table resizes. Indeed, both tables have a peak memory usage that is significantly higher than the memory usage seen between insertions.</p>\n<p>In the case of Abseil's <em>flat_hash_map</em>, the values are stored directly in a memory array. The memory usage is constant until the table needs to resize, which is why we see these horizontal sections of memory usage.</p>\n<p>When the <em>flat_hash_map</em> reaches 87.5% occupancy, a new array of twice the size is allocated, the values are moved (rehashed) from the smaller to the larger array, and then the smaller array, now empty, is freed. So we see that during the resize, the occupancy is only one third of 87.5%, or 29.1%, and when the smaller array is released, occupancy is half of 87.5% or 43.75%.</p>\n<p>The default STL implementation is also subject to this higher peak memory usage, since it typically is implemented with an array of buckets, each bucket having a pointer to a linked list of nodes containing the values. In order to maintain O(1) lookups, the array of buckets also needs to be resized as the table size grows, requiring a 3x temporary memory requirement for moving the old bucket array (1x) to the newly allocated, larger (2x) array. In between the bucket array resizes, the default STL implementation memory usage grows at a constant rate as new values are added to the linked lists.</p>\n<blockquote>\n<p>Instead of having a separate linked list for each bucket, <em>std::unordered_map</em> implementations often use a single linked list (making iteration faster), with buckets pointing to locations within the single linked list. <em>absl::node_hash_map</em>, on the other hand, has each bucket pointing to a single value, and collisions are handled with open addressing like for the <em>absl::flat_hash_map</em>.</p>\n</blockquote>\n<p>This peak memory usage can be the limiting factor for large tables. Suppose you are on a machine with 32 GB of ram, and the <em>flat_hash_map</em> needs to resize when you inserted 10 GB of values in it. 10 GB of values means the array size is 11.42 GB (resizing at 87.5% occupancy), and we need to allocate a new array of double size (22.85 GB), which obviously will not be possible on our 32 GB machine.</p>\n<p>For my work developing mechanical engineering software, this has kept me from using flat hash maps, as the high peak memory usage was the limiting factor for the size of FE models which could be loaded on a given machine. So I used other types of maps, such as <a href=\"https://github.com/greg7mdp/sparsepp\">sparsepp</a> or Google's <a href=\"https://code.google.com/archive/p/cpp-btree/\">cpp-btree</a>.</p>\n<p>When the Abseil library was open sourced, I started pondering the issue again. Compared to Google's old dense_hash_map which resized at 50% capacity, the new <em>absl::flat_hash_map</em> resizing at 87.5% capacity was more memory friendly, but it still had these significant peaks of memory usage when resizing.</p>\n<p>If only there was a way to eliminate those peaks, the <em>flat_hash_map</em> would be close to perfect. But how?</p>\n<h3 id=\"the-peak-memory-usage-solution\">The peak memory usage solution</h3>\n<p>Suddenly, it hit me. I had a solution. I would create a hash table that internally is made of an array of 16 hash tables (the submaps). When inserting or looking up an item, the index of the target submap would be decided by the hash of the value to insert. For example, if for a given <code>size_t hashval</code>, the index for the internal submap would be computed with:</p>\n<p><code>submap_index = (hashval ^ (hashval &gt;&gt; 4)) &amp; 0xF;</code></p>\n<p>providing an index between 0 and 15.</p>\n<blockquote>\n<p>In the actual implementation, the size of the array of hash tables is configurable to a power of two, so it can be 2, 4, 8, 16, 32, ... The following illustration shows a parallel_hash_map with 8 submaps.</p>\n</blockquote>\n<p><img src=\"https://github.com/greg7mdp/parallel-hashmap/blob/master/html/img/index_computation.png?raw=true\" alt=\"index_computation\" /></p>\n<p>The benefit of this approach would be that the internal tables would each resize on its own when they reach 87.5% capacity, and since each table contains approximately one sixteenth of the values, the memory usage peak would be only one sixteenth of the size we saw for the single <em>flat_hash_map</em>.</p>\n<p>The rest of this article describes my implementation of this concept that I have done in my <a href=\"https://github.com/greg7mdp/parallel-hashmap\">parallel hashmap</a> repository. This is a header only library, which provides the following eight hashmaps:</p>\n<ul>\n<li>phmap::flat_hash_set</li>\n<li>phmap::flat_hash_map</li>\n<li>phmap::node_hash_set</li>\n<li>phmap::node_hash_map</li>\n<li>phmap::parallel_flat_hash_set</li>\n<li>phmap::parallel_flat_hash_map</li>\n<li>phmap::parallel_node_hash_set</li>\n<li>phmap::parallel_node_hash_map</li>\n</ul>\n<p>This implementation requires a C++11 compatible compiler, and provides full compatibility with the std::unordered_map (with the exception of <em>pointer stability</em> for the <code>flat</code> versions. C++14 and C++17 methods, like <code>try-emplace</code>, are provided as well. The names for it are <em>parallel_flat_hash_map</em> or <em>parallel_flat_hash_set</em>, and the <em>node</em> equivalents. These hashmaps provide the same external API as the <em>flat_hash_map</em>, and internally use a std::array of 2**N <em>flat_hash_maps</em>.</p>\n<p>I was delighted to find out that not only the <em>parallel_flat_hash_map</em> has significant memory usage benefits compared to the <em>flat_hash_map</em>, but it also has significant advantages for concurrent programming as I will show later. In the rest of this article, we will focus on the <em>parallel_flat_hash_map</em>, but similar results are seen for the <em>parallel_node_hash_map</em>, and the <em>set</em> versions of course.</p>\n<h3 id=\"the-parallel-hashmap-memory-usage\">The Parallel Hashmap: memory usage</h3>\n<p>So, without further ado, let's see the same graphs graphs as above, with the addition of the <em>parallel_flat_hash_map</em>. Let us first look at memory usage (the second graph provides a \"zoomed-in\" view of the location where resizing occurs):</p>\n<p><img src=\"https://github.com/greg7mdp/parallel-hashmap/blob/master/html/img/stl_flat_par_mem.PNG?raw=true\" alt=\"stl_flat_par comparison\" /></p>\n<p><img src=\"https://github.com/greg7mdp/parallel-hashmap/blob/master/html/img/stl_flat_par_mem_zoomed.PNG?raw=true\" alt=\"stl_flat_par_zoomed comparison\" /></p>\n<p>We see that the <em>parallel_flat_hash_map</em> behaves as expected. The memory usage matches exactly the memory usage of its base <em>flat_hash_map</em>, except that the peaks of memory usage which occur when the table resizes are drastically reduced, to the point that they are not objectionable anymore. In the \"zoomed-in\" view, we can see the sixteen dots corresponding to each of the individual submaps resizing. The fact that those resizes are occuring at roughly the same x location in the graph shows that we have a good hash function distribution, distributing the values evenly between the sixteen individual submaps.</p>\n<h3 id=\"the-parallel-hashmap-speed\">The Parallel Hashmap: speed</h3>\n<p>But what about the speed? After all, for each value inserted into the parallel hashmap, we have to do some extra work (steps 1 and 2 below):</p>\n<ol>\n<li>compute the hash for the value to insert</li>\n<li>compute the index of the target submap from the hash)</li>\n<li>insert the value into the submap</li>\n</ol>\n<p>The first step (compute the hash) is the most problematic one, as it can potentially be costly. As we mentioned above, the second step (computing the index from the hash) is very simple and its cost in minimal (3 processor instruction as shown below in <em>Matt Godbolt</em>'s compiler explorer):</p>\n<p><img src=\"https://github.com/greg7mdp/parallel-hashmap/blob/master/html/img/idx_computation_cost.PNG?raw=true\" alt=\"index computation cost\" /></p>\n<p>As for the hash value computation, fortunately we can eliminate this cost by providing the computed hash to the submap functions, so that it is computed only once. This is exactly what I have done in my implementation of the <em>parallel_flat_hash_map</em>, adding a few extra APIs to the internal raw_hash_map.h header, which allow the <em>parallel_flat_hash_map</em> to pass the precomputed hash value to the underlying submaps.</p>\n<p>So we have all but eliminated the cost of the first step, and seen that the cost of the second step is very minimal. At this point we expect that the <em>parallel_flat_hash_map</em> performance will be close to the one of its underlying <em>flat_hash_map</em>, and this is confirmed by the chart below:</p>\n<p><img src=\"https://github.com/greg7mdp/parallel-hashmap/blob/master/html/img/stl_flat_par_speed.PNG?raw=true\" alt=\"stl_flat_par comparison\" /></p>\n<p>Indeed, because of the scale is somewhat compressed due to the longer times of the std::unordered_map, we can barely distinguish between the blue curve of the <em>flat_hash_map</em> and the red curve of the <em>parallel_flat_hash_map</em>. So let's look at a graph without the std::unordered_map:</p>\n<p><img src=\"https://github.com/greg7mdp/parallel-hashmap/blob/master/html/img/flat_par_speed.PNG?raw=true\" alt=\"flat_par comparison\" /></p>\n<p>This last graph shows that the <em>parallel_flat_hash_map</em> is slightly slower especially for smaller table sizes. For a reason not obvious to me (maybe better memory locality), the speeds of the <em>parallel_flat_hash_map</em> and <em>flat_hash_map</em> are essentially undistinguishable for larger map sizes (&gt; 80 million values).</p>\n<h3 id=\"are-we-done-yet\">Are we done yet?</h3>\n<p>This is already looking pretty good. For large hash_maps, the <em>parallel_flat_hash_map</em> is a very appealing solution, as it provides essentially the excellent performance of the <em>flat_hash_map</em>, while virtually eliminating the peaks of memory usage which occur when the hash table resizes.</p>\n<p>But there is another aspect of the inherent parallelism of the <em>parallel_flat_hash_map</em> which is interesting to explore. As we know, typical hashmaps cannot be modified from multiple threads without explicit synchronization. And bracketing write accesses to a shared hash_map with synchronization primitives, such as mutexes, can reduce the concurrency of our program, and even cause deadlocks.</p>\n<p>Because the <em>parallel_flat_hash_map</em> is made of sixteen separate submaps, it posesses some intrinsic parallelism. Indeed, suppose you can make sure that different threads will use different submaps, you would be able to insert into the same <em>parallel_flat_hash_map</em> at the same time from the different threads without any locking.</p>\n<h3 id=\"using-the-intrinsic-parallelism-of-the-parallel_flat_hash_map-to-insert-values-from-multiple-threads-lock-free\">Using the intrinsic parallelism of the <em>parallel_flat_hash_map</em> to insert values from multiple threads, lock free.</h3>\n<p>So, if you can iterate over the values you want to insert into the hash table, the idea is that each thread will iterate over all values, and then for each value:</p>\n<ol>\n<li>compute the hash for that value</li>\n<li>compute the submap index for that hash</li>\n<li>if the submap index is one assigned to this thread, then insert the value, otherwise do nothing and continue to the next value</li>\n</ol>\n<p>Here is the code for the single-threaded insert:</p>\n<div class=\"sourceCode\" id=\"cb1\"><pre class=\"sourceCode c++\"><code class=\"sourceCode cpp\"><a class=\"sourceLine\" id=\"cb1-1\" title=\"1\"><span class=\"kw\">template</span> &lt;<span class=\"kw\">class</span> HT&gt;</a>\n<a class=\"sourceLine\" id=\"cb1-2\" title=\"2\"><span class=\"dt\">void</span> _fill_random_inner(<span class=\"dt\">int64_t</span> cnt, HT &amp;hash, RSU &amp;rsu)</a>\n<a class=\"sourceLine\" id=\"cb1-3\" title=\"3\">{</a>\n<a class=\"sourceLine\" id=\"cb1-4\" title=\"4\">    <span class=\"cf\">for</span> (<span class=\"dt\">int64_t</span> i=<span class=\"dv\">0</span>; i&lt;cnt; ++i)</a>\n<a class=\"sourceLine\" id=\"cb1-5\" title=\"5\">    {</a>\n<a class=\"sourceLine\" id=\"cb1-6\" title=\"6\">        hash.insert(<span class=\"kw\">typename</span> HT::<span class=\"dt\">value_type</span>(rsu.next(), <span class=\"dv\">0</span>));</a>\n<a class=\"sourceLine\" id=\"cb1-7\" title=\"7\">        ++num_keys[<span class=\"dv\">0</span>];</a>\n<a class=\"sourceLine\" id=\"cb1-8\" title=\"8\">    }</a>\n<a class=\"sourceLine\" id=\"cb1-9\" title=\"9\">}</a></code></pre></div>\n<p>and here is the code for the multi-threaded insert:</p>\n<div class=\"sourceCode\" id=\"cb2\"><pre class=\"sourceCode c++\"><code class=\"sourceCode cpp\"><a class=\"sourceLine\" id=\"cb2-1\" title=\"1\"><span class=\"kw\">template</span> &lt;<span class=\"kw\">class</span> HT&gt;</a>\n<a class=\"sourceLine\" id=\"cb2-2\" title=\"2\"><span class=\"dt\">void</span> _fill_random_inner_mt(<span class=\"dt\">int64_t</span> cnt, HT &amp;hash, RSU &amp;rsu)</a>\n<a class=\"sourceLine\" id=\"cb2-3\" title=\"3\">{</a>\n<a class=\"sourceLine\" id=\"cb2-4\" title=\"4\">    <span class=\"kw\">constexpr</span> <span class=\"dt\">int64_t</span> num_threads = <span class=\"dv\">8</span>;   <span class=\"co\">// has to be a power of two</span></a>\n<a class=\"sourceLine\" id=\"cb2-5\" title=\"5\">    <span class=\"bu\">std::</span>unique_ptr&lt;<span class=\"bu\">std::</span>thread&gt; threads[num_threads];</a>\n<a class=\"sourceLine\" id=\"cb2-6\" title=\"6\"></a>\n<a class=\"sourceLine\" id=\"cb2-7\" title=\"7\">    <span class=\"kw\">auto</span> thread_fn = [&amp;hash, cnt, num_threads](<span class=\"dt\">int64_t</span> thread_idx, RSU rsu) {</a>\n<a class=\"sourceLine\" id=\"cb2-9\" title=\"9\">        <span class=\"dt\">size_t</span> modulo = hash.subcnt() / num_threads;        <span class=\"co\">// subcnt() returns the number of submaps</span></a>\n<a class=\"sourceLine\" id=\"cb2-10\" title=\"10\"></a>\n<a class=\"sourceLine\" id=\"cb2-11\" title=\"11\">        <span class=\"cf\">for</span> (<span class=\"dt\">int64_t</span> i=<span class=\"dv\">0</span>; i&lt;cnt; ++i)                       <span class=\"co\">// iterate over all values</span></a>\n<a class=\"sourceLine\" id=\"cb2-12\" title=\"12\">        {</a>\n<a class=\"sourceLine\" id=\"cb2-13\" title=\"13\">            <span class=\"dt\">unsigned</span> <span class=\"dt\">int</span> key = rsu.next();                  <span class=\"co\">// get next key to insert</span></a>\n<a class=\"sourceLine\" id=\"cb2-14\" title=\"14\">            <span class=\"dt\">size_t</span> hashval = hash.hash(key);                <span class=\"co\">// compute its hash</span></a>\n<a class=\"sourceLine\" id=\"cb2-15\" title=\"15\">            <span class=\"dt\">size_t</span> idx  = hash.subidx(hashval);             <span class=\"co\">// compute the submap index for this hash</span></a>\n<a class=\"sourceLine\" id=\"cb2-16\" title=\"16\">            <span class=\"cf\">if</span> (idx / modulo == thread_idx)                 <span class=\"co\">// if the submap is suitable for this thread</span></a>\n<a class=\"sourceLine\" id=\"cb2-17\" title=\"17\">            {</a>\n<a class=\"sourceLine\" id=\"cb2-18\" title=\"18\">                hash.insert(<span class=\"kw\">typename</span> HT::<span class=\"dt\">value_type</span>(key, <span class=\"dv\">0</span>)); <span class=\"co\">// insert the value</span></a>\n<a class=\"sourceLine\" id=\"cb2-19\" title=\"19\">                ++(num_keys[thread_idx]);                     <span class=\"co\">// increment count of inserted values</span></a>\n<a class=\"sourceLine\" id=\"cb2-20\" title=\"20\">            }</a>\n<a class=\"sourceLine\" id=\"cb2-21\" title=\"21\">        }</a>\n<a class=\"sourceLine\" id=\"cb2-22\" title=\"22\">    };</a>\n<a class=\"sourceLine\" id=\"cb2-23\" title=\"23\"></a>\n<a class=\"sourceLine\" id=\"cb2-24\" title=\"24\">    <span class=\"co\">// create and start 8 threads - each will insert in their own submaps</span></a>\n<a class=\"sourceLine\" id=\"cb2-25\" title=\"25\">    <span class=\"co\">// thread 0 will insert the keys whose hash direct them to submap0 or submap1</span></a>\n<a class=\"sourceLine\" id=\"cb2-26\" title=\"26\">    <span class=\"co\">// thread 1 will insert the keys whose hash direct them to submap2 or submap3</span></a>\n<a class=\"sourceLine\" id=\"cb2-27\" title=\"27\">    <span class=\"co\">// --------------------------------------------------------------------------</span></a>\n<a class=\"sourceLine\" id=\"cb2-28\" title=\"28\">    <span class=\"cf\">for</span> (<span class=\"dt\">int64_t</span> i=<span class=\"dv\">0</span>; i&lt;num_threads; ++i)</a>\n<a class=\"sourceLine\" id=\"cb2-29\" title=\"29\">        threads[i].reset(<span class=\"kw\">new</span> <span class=\"bu\">std::</span>thread(thread_fn, i, rsu));</a>\n<a class=\"sourceLine\" id=\"cb2-30\" title=\"30\"></a>\n<a class=\"sourceLine\" id=\"cb2-31\" title=\"31\">    <span class=\"co\">// rsu passed by value to threads... we need to increment the reference object</span></a>\n<a class=\"sourceLine\" id=\"cb2-32\" title=\"32\">    <span class=\"cf\">for</span> (<span class=\"dt\">int64_t</span> i=<span class=\"dv\">0</span>; i&lt;cnt; ++i)</a>\n<a class=\"sourceLine\" id=\"cb2-33\" title=\"33\">        rsu.next();</a>\n<a class=\"sourceLine\" id=\"cb2-34\" title=\"34\">    </a>\n<a class=\"sourceLine\" id=\"cb2-35\" title=\"35\">    <span class=\"co\">// wait for the threads to finish their work and exit</span></a>\n<a class=\"sourceLine\" id=\"cb2-36\" title=\"36\">    <span class=\"cf\">for</span> (<span class=\"dt\">int64_t</span> i=<span class=\"dv\">0</span>; i&lt;num_threads; ++i)</a>\n<a class=\"sourceLine\" id=\"cb2-37\" title=\"37\">        threads[i]-&gt;join();</a>\n<a class=\"sourceLine\" id=\"cb2-38\" title=\"38\">}</a></code></pre></div>\n<p>Using multiple threads, we are able to populate the <em>parallel_flat_hash_map</em> (inserting 100 million values) three times faster than the standard <em>flat_hash_map</em> (which we could not have populated from multiple threads without explicit locks, which would have prevented performance improvements).</p>\n<p>And the graphical visualization of the results:</p>\n<p><img src=\"https://github.com/greg7mdp/parallel-hashmap/blob/master/html/img/mt_stl_flat_par_both_run2.PNG?raw=true\" alt=\"mt_stl_flat_par comparison\" /></p>\n<p>We notice in this last graph that the memory usage peaks, while still smaller than those of the <em>flat_hash_map</em>, are larger that those we saw when populating the <em>parallel_flat_hash_map</em> using a single thread. The obvious reason is that, when using a single thread, only one of the submaps would resize at a time, ensuring that the peak would only be 1/16th of the one for the <em>flat_hash_map</em> (provided of course that the hash function distributes the values somewhat evenly between the submaps).</p>\n<p>When running in multi-threaded mode (in this case eight threads), potentially as many as eight submaps can resize simultaneaously, so for a <em>parallel_flat_hash_map</em> with sixteen submaps the memory peak size can be half as large as the one for the <em>flat_hash_map</em>.</p>\n<p>Still, this is a pretty good result, we are now inserting values into our <em>parallel_flat_hash_map</em> three times faster than we were able to do using the <em>flat_hash_map</em>, while using a lower memory ceiling.</p>\n<p>This is significant, as the speed of insertion into a hash map is important in many algorithms, for example removing duplicates in a collection of values.</p>\n<h3 id=\"using-the-intrinsic-parallelism-of-the-parallel_flat_hash_map-with-internal-mutexes\">Using the intrinsic parallelism of the <em>parallel_flat_hash_map</em> with internal mutexes</h3>\n<p>It may not be practical to add logic into your program to ensure you use different internal submaps from each thread. Still, locking the whole <em>parallel_flat_hash_map</em> for each access would forego taking advantage of its intrinsic parallelism.</p>\n<p>For that reason, the <em>parallel_flat_hash_map</em> can provide internal locking using the <code>std::mutex</code> (the default template parameter is <code>phmap::NullMutex</code>, which does no locking and has no size cost). When selecting <code>std::mutex</code>, one mutex is created for each internal submap at a cost of 8 bytes per submap, and the <em>parallel_flat_hash_map</em> internally protects each submap access with its associated mutex.</p>\n<table>\n<thead>\n<tr class=\"header\">\n<th style=\"text-align: left;\">map</th>\n<th style=\"text-align: center;\">Number of submaps</th>\n<th style=\"text-align: right;\">sizeof(map)</th>\n</tr>\n</thead>\n<tbody>\n<tr class=\"odd\">\n<td style=\"text-align: left;\">std::unordered_map (vs2017)</td>\n<td style=\"text-align: center;\">-</td>\n<td style=\"text-align: right;\">64</td>\n</tr>\n<tr class=\"even\">\n<td style=\"text-align: left;\">phmap::flat_hash_map</td>\n<td style=\"text-align: center;\">-</td>\n<td style=\"text-align: right;\">48</td>\n</tr>\n<tr class=\"odd\">\n<td style=\"text-align: left;\">phmap::parallel_flat_hash_map, N=4, phmap::NullMutex</td>\n<td style=\"text-align: center;\">16</td>\n<td style=\"text-align: right;\">768</td>\n</tr>\n<tr class=\"even\">\n<td style=\"text-align: left;\">phmap::parallel_flat_hash_map, N=4, phmap::Mutex</td>\n<td style=\"text-align: center;\">16</td>\n<td style=\"text-align: right;\">896</td>\n</tr>\n</tbody>\n</table>\n<p>It is about time we provide the complete parallel_flat_hash_map class declaration (the declaration for parallel_flat_hash_set is similar):</p>\n<pre><code>template &lt;class K, class V,\n          class Hash      = phmap::priv::hash_default_hash&lt;K&gt;,\n          class Eq        = phmap::priv::hash_default_eq&lt;K&gt;,\n          class Allocator = phmap::priv::Allocator&lt;std::pair&lt;const K, V&gt;&gt;, // alias for std::allocator\n          size_t N        = 4,                 // 2**N submaps\n          class Mutex     = phmap::NullMutex&gt;   // use std::mutex to enable internal locks\nclass parallel_flat_hash_map;\n</code></pre>\n<p>Let's see what result we get for the insertion of random values from multiple threads, however this time we create a <em>parallel_flat_hash_map</em> with internal locking (by providing std::mutex as the last template argument), and modify the code so that each thread inserts values in any submap (no pre-selection).</p>\n<p><img src=\"https://github.com/greg7mdp/parallel-hashmap/blob/master/html/img/no_preselection.PNG?raw=true\" alt=\"no_preselection\" /></p>\n<p>If we were to do a intensive insertion test into a hash map from multiple threads, where we lock the whole hash table for each insertion, we would be likely to get even worse results than for a single threaded insert, because of heavy lock contention.</p>\n<p>In this case, our expectation is that the finer grained locking of the <em>parallel_flat_hash_map</em> (separate locks for each internal submap) will provide a speed benefit when compared to the single threaded insertion, and this is indeed what the benchmarks show:</p>\n<p><img src=\"https://github.com/greg7mdp/parallel-hashmap/blob/master/html/img/flat_par_mutex_4.PNG?raw=true\" alt=\"flat_par_mutex_4\" /></p>\n<p>Interestingly, we notice that the memory peaks (when resizing occur) are again very small, in the order of 1/16th of those for the <em>flat_hash_map</em>. This is likely because, as soon as one of the submaps resizes (which takes much longer than a regular insertion), the other threads very soon have to wait on the resizing submap's mutex for an insertion, before they reach their own resizing threashold.</p>\n<p>Since threads statistically will insert on a different submap for each value, it would be a surprising coincidence indeed if two submaps reached their resizing threshold without the resizing of the first submap blocking all the other threads first.</p>\n<p>If we increase the number of submaps, we should see more parallelism (less lock contention across threads, as the odds of two separate threads inserting in the same subhash is lower), but with diminishing returns as every submap resize will quickly block the other threads until the resize is completed.</p>\n<p>This is indeed what we see:</p>\n<p><img src=\"https://github.com/greg7mdp/parallel-hashmap/blob/master/html/img/lock_various_sizes.PNG?raw=true\" alt=\"lock_various_sizes\" /></p>\n<table>\n<thead>\n<tr class=\"header\">\n<th style=\"text-align: left;\">map</th>\n<th style=\"text-align: center;\">Number of submaps</th>\n<th style=\"text-align: right;\">sizeof(map)</th>\n<th style=\"text-align: right;\">time 100M insertions</th>\n</tr>\n</thead>\n<tbody>\n<tr class=\"odd\">\n<td style=\"text-align: left;\">phmap::flat_hash_map</td>\n<td style=\"text-align: center;\">-</td>\n<td style=\"text-align: right;\">48</td>\n<td style=\"text-align: right;\">14.77s</td>\n</tr>\n<tr class=\"even\">\n<td style=\"text-align: left;\">phmap::parallel_flat_hash_map, N=4, std::mutex</td>\n<td style=\"text-align: center;\">16</td>\n<td style=\"text-align: right;\">896</td>\n<td style=\"text-align: right;\">8.36s</td>\n</tr>\n<tr class=\"odd\">\n<td style=\"text-align: left;\">phmap::parallel_flat_hash_map, N=5, std::mutex</td>\n<td style=\"text-align: center;\">32</td>\n<td style=\"text-align: right;\">1792</td>\n<td style=\"text-align: right;\">7.14s</td>\n</tr>\n<tr class=\"even\">\n<td style=\"text-align: left;\">phmap::parallel_flat_hash_map, N=6, std::mutex</td>\n<td style=\"text-align: center;\">64</td>\n<td style=\"text-align: right;\">3584</td>\n<td style=\"text-align: right;\">6.61s</td>\n</tr>\n</tbody>\n</table>\n<p>There is still some overhead from the mutex lock/unlock, and the occasional lock contention, which prevents us from reaching the performance of the previous multithreaded lock-free insertion (5.12s for inserting 100M elements).</p>\n<h3 id=\"in-conclusion\">In Conclusion</h3>\n<p>We have seen that the novel parallel hashmap approach, used within a single thread, provides significant space advantages, with a very minimal time penalty. When used in a multi-thread context, the parallel hashmap still provides a significant space benefit, in addition to a consequential time benefit by reducing (or even eliminating) lock contention when accessing the parallel hashmap.</p>\n<h3 id=\"future-work\">Future work</h3>\n<ol>\n<li>It would be beneficial to provide additional APIs for the <em>parallel_flat_hash_map</em> and <em>parallel_flat_hash_set</em> taking a precomputed hash value. This would enable the lock-free usage of the <em>parallel_flat_hash_map</em>, described above for multi-threaded environments, without requiring a double hash computation.</li>\n</ol>\n<h3 id=\"thanks\">Thanks</h3>\n<p>I would like to thank Google's <em>Matt Kulukundis</em> for his eye-opening presentation of the <em>flat_hash_map</em> design at CPPCON 2017 - my frustration with not being able to use it helped trigger my insight into the <em>parallel_flat_hash_map</em>. Also many thanks to the Abseil container developers - I believe the main contributors are <em>Alkis Evlogimenos</em> and <em>Roman Perepelitsa</em> - who created an excellent codebase into which the graft of this new hashmap took easily, and finally to Google for open-sourcing Abseil. Thanks also to my son <em>Andre</em> for reviewing this paper, and for his patience when I was rambling about the <em>parallel_flat_hash_map</em> and its benefits.</p>\n<h3 id=\"links\">Links</h3>\n<p><a href=\"https://github.com/greg7mdp/parallel-hashmap\">Repository for the Parallel Hashmap, including the benchmark code used in this paper</a></p>\n<p><a href=\"https://abseil.io/blog/20180927-swisstables\">Swiss Tables doc</a></p>\n<p><a href=\"https://github.com/abseil/abseil-cpp\">Google Abseil repository</a></p>\n<p><a href=\"https://www.youtube.com/watch?v=ncHmEUmJZf4\">Matt Kulukindis: Designing a Fast, Efficient, Cache-friendly Hash Table, Step by Step</a></p>\n          </div>\n        </div>\n\n    </div>\n    <script src=\"https://code.jquery.com/jquery.js\"></script>\n  </body>\n</html>\n"
        },
        {
          "name": "parallel_hashmap",
          "type": "tree",
          "content": null
        },
        {
          "name": "phmap.natvis",
          "type": "blob",
          "size": 6.228515625,
          "content": "<?xml version=\"1.0\" encoding=\"utf-8\"?>  \n\n<AutoVisualizer xmlns=\"http://schemas.microsoft.com/vstudio/debugger/natvis/2010\">  \n  <!-- flat map/set  -->\n  <Type            Name=\"phmap::flat_hash_set&lt;*,*,*,*&gt;\">  \n  <AlternativeType Name=\"phmap::flat_hash_map&lt;*,*,*,*,*&gt;\" />  \n      <DisplayString>{{size = {size_}}}</DisplayString>  \n      <Expand>  \n        <CustomListItems MaxItemsPerView=\"1000\" ExcludeView=\"Test\">  \n          <Variable Name=\"ctrl\" InitialValue=\"ctrl_\" />  \n          <Variable Name=\"slot\" InitialValue=\"slots_\" />  \n          <Variable Name=\"ctrl_end\" InitialValue=\"ctrl_ + capacity_\" />  \n          <Variable Name=\"slot_end\" InitialValue=\"slots_ + capacity_\" />  \n    \n          <Size>size_</Size>  \n          <Loop>  \n              <Break Condition=\"slot == slot_end\" />  \n              <If Condition=\"*ctrl >= -1\">\n                <Item>*slot,na</Item>  \n              </If>  \n              <Exec>++slot</Exec>  \n              <Exec>++ctrl</Exec>  \n          </Loop>\n        </CustomListItems>  \n      </Expand>  \n  </Type>  \n\n  <!-- node map/set - only difference is the **slot instead of *slot -->\n  <Type            Name=\"phmap::node_hash_set&lt;*,*,*,*&gt;\">  \n  <AlternativeType Name=\"phmap::node_hash_map&lt;*,*,*,*,*&gt;\" />  \n      <DisplayString>{{size = {size_}}}</DisplayString>  \n      <Expand>  \n        <CustomListItems MaxItemsPerView=\"1000\" ExcludeView=\"Test\">  \n          <Variable Name=\"ctrl\" InitialValue=\"ctrl_\" />  \n          <Variable Name=\"slot\" InitialValue=\"slots_\" />  \n          <Variable Name=\"ctrl_end\" InitialValue=\"ctrl_ + capacity_\" />  \n          <Variable Name=\"slot_end\" InitialValue=\"slots_ + capacity_\" />  \n    \n          <Size>size_</Size>  \n          <Loop>  \n              <Break Condition=\"slot == slot_end\" />  \n              <If Condition=\"*ctrl >= -1\">\n                <Item>**slot,na</Item>  \n              </If>  \n              <Exec>++slot</Exec>  \n              <Exec>++ctrl</Exec>  \n          </Loop>\n        </CustomListItems>  \n      </Expand>  \n  </Type>  \n    \n  <Type Name=\"phmap::priv::map_slot_type&lt;*,*&gt;\">\n    <DisplayString>{value}</DisplayString>\n  </Type>\n\n  <!-- flat map iterators -->\n  <Type Name=\"phmap::priv::raw_hash_set&lt;*,*,*,*&gt;::iterator\">\n       <DisplayString Condition=\"ctrl_ == 0\">unset</DisplayString>\n       <DisplayString Condition=\"!(*ctrl_ >= 0)\">end()</DisplayString>\n       <DisplayString>{*slot_,na}</DisplayString>\n  </Type>\n\n  <!-- node map iterators  - only difference is the **slot_ instead of * -->\n  <Type Name=\"phmap::priv::raw_hash_set&lt;phmap::priv::NodeHashSetPolicy&lt;*&gt;,*,*,*&gt;::iterator\">\n       <DisplayString Condition=\"ctrl_ == 0\">unset</DisplayString>\n       <DisplayString Condition=\"!(*ctrl_ >= 0)\">end()</DisplayString>\n       <DisplayString>{**slot_,na}</DisplayString>\n  </Type>\n\n  <!-- parallel flat/node set -->\n  <Type            Name=\"phmap::parallel_flat_hash_set&lt;*,*,*,*,*,*&gt;\">  \n  <AlternativeType Name=\"phmap::parallel_node_hash_set&lt;*,*,*,*,*,*&gt;\" />  \n      <DisplayString>{{size = ?}}</DisplayString>  \n      <Expand>  \n        <CustomListItems MaxItemsPerView=\"1000\" ExcludeView=\"Test\">  \n          <Variable Name=\"idx\" InitialValue=\"0\" />  \n          <Variable Name=\"maxidx\" InitialValue=\"$T5\" />  \n          <Variable Name=\"ctrl\" InitialValue=\"sets_._Elems[0].set_.ctrl_\" />  \n          <Variable Name=\"slot\" InitialValue=\"sets_._Elems[0].set_.slots_\" />  \n          <Variable Name=\"ctrl_end\" InitialValue=\"sets_._Elems[0].set_.ctrl_\" />  \n          <Variable Name=\"slot_end\" InitialValue=\"sets_._Elems[0].set_.slots_\" />  \n          <Exec>maxidx = 2 &lt;&lt; maxidx</Exec>\n          <Loop>  \n                <Break Condition=\"idx == maxidx\" />  \n                <Exec>ctrl = sets_._Elems[idx].set_.ctrl_</Exec>  \n                <Exec>slot = sets_._Elems[idx].set_.slots_</Exec>  \n                <Exec>ctrl_end = sets_._Elems[idx].set_.ctrl_ + sets_._Elems[idx].set_.capacity_</Exec>  \n                <Exec>slot_end = sets_._Elems[idx].set_.slots_ + sets_._Elems[idx].set_.capacity_</Exec>  \n                <Loop>  \n                    <Break Condition=\"slot == slot_end\" />  \n                    <If Condition=\"*ctrl >= -1\">\n                      <Item>*slot,na</Item>  \n                    </If>  \n                    <Exec>++slot</Exec>  \n                    <Exec>++ctrl</Exec>  \n                </Loop>\n                <Exec>++idx</Exec>  \n          </Loop>\n        </CustomListItems>  \n      </Expand>  \n  </Type>  \n\n  <!-- parallel flat/node map - only difference is $T6 instead of $T5 -->\n  <Type            Name=\"phmap::parallel_flat_hash_map&lt;*,*,*,*,*,*,*&gt;\">  \n  <AlternativeType Name=\"phmap::parallel_node_hash_map&lt;*,*,*,*,*,*,*&gt;\" /> \n      <DisplayString>{{size = ?}}</DisplayString>  \n      <Expand>  \n        <CustomListItems MaxItemsPerView=\"1000\" ExcludeView=\"Test\">  \n          <Variable Name=\"idx\" InitialValue=\"0\" />  \n          <Variable Name=\"maxidx\" InitialValue=\"$T6\" />  \n          <Variable Name=\"ctrl\" InitialValue=\"sets_._Elems[0].set_.ctrl_\" />  \n          <Variable Name=\"slot\" InitialValue=\"sets_._Elems[0].set_.slots_\" />  \n          <Variable Name=\"ctrl_end\" InitialValue=\"sets_._Elems[0].set_.ctrl_\" />  \n          <Variable Name=\"slot_end\" InitialValue=\"sets_._Elems[0].set_.slots_\" />  \n          <Exec>maxidx = 2 &lt;&lt; maxidx</Exec>\n          <Loop>  \n                <Break Condition=\"idx == maxidx\" />  \n                <Exec>ctrl = sets_._Elems[idx].set_.ctrl_</Exec>  \n                <Exec>slot = sets_._Elems[idx].set_.slots_</Exec>  \n                <Exec>ctrl_end = sets_._Elems[idx].set_.ctrl_ + sets_._Elems[idx].set_.capacity_</Exec>  \n                <Exec>slot_end = sets_._Elems[idx].set_.slots_ + sets_._Elems[idx].set_.capacity_</Exec>  \n                <Loop>  \n                    <Break Condition=\"slot == slot_end\" />  \n                    <If Condition=\"*ctrl >= -1\">\n                      <Item>*slot,na</Item>  \n                    </If>  \n                    <Exec>++slot</Exec>  \n                    <Exec>++ctrl</Exec>  \n                </Loop>\n                <Exec>++idx</Exec>  \n          </Loop>\n        </CustomListItems>  \n      </Expand>  \n  </Type>  \n\n  <Type Name=\"phmap::priv::parallel_hash_set&lt;*,*,*,*,*,*,*&gt;::iterator\">\n       <DisplayString>{it_,na}</DisplayString>\n  </Type>\n\n</AutoVisualizer>  \n\n"
        },
        {
          "name": "phmap_gdb.py",
          "type": "blob",
          "size": 5.2021484375,
          "content": "# Python GDB formatters for parallel-hashmap\n# tested with GCC 10.2 / GDB 9.2\n# to install it, ensure the script location is in the Python path\n# and type the following command (or put it in $HOME/.gdbinit):\n\n# python\n# import phmap_gdb\n# end\n\n\nimport gdb.printing\n\n\ndef counter():\n    i = 0\n    while(True):\n        yield str(i)\n        i += 1\n\n\ndef slot_iterator(base_obj):\n    index = -1\n    n_items = 0\n    size = int(base_obj[\"size_\"])\n    while n_items < size:\n        index += 1\n        if int(base_obj[\"ctrl_\"][index]) < 0:\n            continue\n\n        n_items += 1\n        yield base_obj[\"slots_\"][index]\n\n\ndef parallel_slot_iterator(base_obj):\n    array = base_obj[\"sets_\"]\n    array_len = int(array.type.template_argument(1))\n    for index in range(array_len):\n        obj = array[\"_M_elems\"][index][\"set_\"]\n        yield from slot_iterator(obj)\n\n\ndef flat_map_iterator(name, item):\n    yield (next(name), item[\"value\"][\"first\"])\n    yield (next(name), item[\"value\"][\"second\"])\n\n\ndef flat_set_iterator(name, item):\n    yield (next(name), item)\n\n\ndef node_map_iterator(name, item):\n    yield (next(name), item.dereference()[\"first\"])\n    yield (next(name), item.dereference()[\"second\"])\n\n\ndef node_set_iterator(name, item):\n    yield (next(name), item.dereference())\n\n\ndef traverse(iterator, slot_type_iterator):\n    name = counter()\n    for item in iterator:\n        yield from slot_type_iterator(name, item)\n\n\ndef parallel_size(parallel_hash_obj):\n    array = parallel_hash_obj[\"sets_\"]\n    array_len = int(array.type.template_argument(1))\n    size = 0\n    for index in range(array_len):\n        size += array[\"_M_elems\"][index][\"set_\"][\"size_\"]\n\n    return size\n\n\nclass FlatMapPrinter:\n    def __init__(self, val):\n        self.val = val\n\n    def children(self):\n        return traverse(slot_iterator(self.val), flat_map_iterator)\n\n    def to_string(self):\n        return f\"phmap::flat_hash_map with {int(self.val['size_'])} elements\"\n\n    def display_hint(self):\n        return \"map\"\n\n\nclass FlatSetPrinter:\n    def __init__(self, val):\n        self.val = val\n\n    def children(self):\n        return traverse(slot_iterator(self.val), flat_set_iterator)\n\n    def to_string(self):\n        return f\"phmap::flat_hash_set with {int(self.val['size_'])} elements\"\n\n    def display_hint(self):\n        return \"array\"\n\n\nclass NodeMapPrinter:\n    def __init__(self, val):\n        self.val = val\n\n    def children(self):\n        return traverse(slot_iterator(self.val), node_map_iterator)\n\n    def to_string(self):\n        return f\"phmap::node_hash_map with {int(self.val['size_'])} elements\"\n\n    def display_hint(self):\n        return \"map\"\n\n\nclass NodeSetPrinter:\n    def __init__(self, val):\n        self.val = val\n\n    def children(self):\n        return traverse(slot_iterator(self.val), node_set_iterator)\n\n    def to_string(self):\n        return f\"phmap::node_hash_set with {int(self.val['size_'])} elements\"\n\n    def display_hint(self):\n        return \"array\"\n\n\nclass ParallelFlatMapPrinter:\n    def __init__(self, val):\n        self.val = val\n\n    def children(self):\n        return traverse(parallel_slot_iterator(self.val), flat_map_iterator)\n\n    def to_string(self):\n        return f\"phmap::parallel_flat_hash_map with {parallel_size(self.val)} elements\"\n\n    def display_hint(self):\n        return \"map\"\n\n\nclass ParallelFlatSetPrinter:\n    def __init__(self, val):\n        self.val = val\n\n    def children(self):\n        return traverse(parallel_slot_iterator(self.val), flat_set_iterator)\n\n    def to_string(self):\n        return f\"phmap::parallel_flat_hash_set with {parallel_size(self.val)} elements\"\n\n    def display_hint(self):\n        return \"array\"\n\n\nclass ParallelNodeMapPrinter:\n    def __init__(self, val):\n        self.val = val\n\n    def children(self):\n        return traverse(parallel_slot_iterator(self.val), node_map_iterator)\n\n    def to_string(self):\n        return f\"phmap::parallel_node_hash_map with {parallel_size(self.val)} elements\"\n\n    def display_hint(self):\n        return \"map\"\n\n\nclass ParallelNodeSetPrinter:\n    def __init__(self, val):\n        self.val = val\n\n    def children(self):\n        return traverse(parallel_slot_iterator(self.val), node_set_iterator)\n\n    def to_string(self):\n        return f\"phmap::parallel_node_hash_set with {parallel_size(self.val)} elements\"\n\n    def display_hint(self):\n        return \"array\"\n\n\ndef build_pretty_printer():\n    pp = gdb.printing.RegexpCollectionPrettyPrinter(\"phmap\")\n    pp.add_printer('flat_hash_map', '^phmap::flat_hash_map<.*>$', FlatMapPrinter)\n    pp.add_printer('flat_hash_set', '^phmap::flat_hash_set<.*>$', FlatSetPrinter)\n    pp.add_printer('node_hash_map', '^phmap::node_hash_map<.*>$', NodeMapPrinter)\n    pp.add_printer('node_hash_set', '^phmap::node_hash_set<.*>$', NodeSetPrinter)\n    pp.add_printer('parallel_flat_hash_map', '^phmap::parallel_flat_hash_map<.*>$', ParallelFlatMapPrinter)\n    pp.add_printer('parallel_flat_hash_set', '^phmap::parallel_flat_hash_set<.*>$', ParallelFlatSetPrinter)\n    pp.add_printer('parallel_node_hash_map', '^phmap::parallel_node_hash_map<.*>$', ParallelNodeMapPrinter)\n    pp.add_printer('parallel_node_hash_set', '^phmap::parallel_node_hash_set<.*>$', ParallelNodeSetPrinter)\n    return pp\n\n\ngdb.printing.register_pretty_printer(gdb.current_objfile(), build_pretty_printer())\n"
        },
        {
          "name": "phmap_lldb.py",
          "type": "blob",
          "size": 10.2158203125,
          "content": "# Python lldb formatters for parallel-hashmap\r\n# tested witch clang10 / lldb9 & 10\r\n\r\n# to install it, type the following command or put it in $HOME/.lldbinit:\r\n# command script import \"PATH_TO_SCRIPT/lldb_phmap.py\"\r\n\r\n\r\nimport lldb\r\nimport os\r\nimport sys\r\nimport re\r\n\r\n_MAX_CHILDREN = 250\r\n_MAX_CTRL_INDEX = 1_000\r\n_MODULE_NAME = os.path.basename(__file__).split(\".\")[0]\r\n\r\n\r\ndef _get_function_name(instance=None):\r\n    \"\"\"Return the name of the calling function\"\"\"\r\n    class_name = f\"{type(instance).__name__}.\" if instance else \"\"\r\n    return class_name + sys._getframe(1).f_code.co_name\r\n\r\n\r\nclass flat_map_slot_type:\r\n    CLASS_PATTERN = \"^phmap::priv::raw_hash_set<phmap::priv::FlatHashMapPolicy.*>::slot_type$\"\r\n    HAS_SUMMARY = True\r\n    IS_SYNTHETIC_PROVIDER = False\r\n\r\n    @staticmethod\r\n    def summary(valobj, _):\r\n        try:\r\n            valobj = valobj.GetChildMemberWithName('value')\r\n            first = valobj.GetChildMemberWithName('first').GetSummary()\r\n            if not first: first = \"{...}\"\r\n            second = valobj.GetChildMemberWithName('second').GetSummary()\r\n            if not second: second = \"{...}\"\r\n            return f\"{{{first}, {second}}}\"\r\n        except BaseException as ex:\r\n            print(f\"{_get_function_name()} -> {ex}\")\r\n        return \"\"\r\n\r\n\r\nclass node_map_slot_type:\r\n    CLASS_PATTERN = r\"phmap::priv::raw_hash_set<phmap::priv::NodeHashMapPolicy.*>::slot_type$\"\r\n    HAS_SUMMARY = True\r\n    IS_SYNTHETIC_PROVIDER = False\r\n\r\n    @staticmethod\r\n    def summary(valobj, _):\r\n        try:\r\n            valobj = valobj.Dereference()\r\n            first = valobj.GetChildMemberWithName('first').GetSummary()\r\n            if not first: first = \"{...}\"\r\n            second = valobj.GetChildMemberWithName('second').GetSummary()\r\n            if not second: second = \"{...}\"\r\n            return f\"{{{first}, {second}}}\"\r\n        except BaseException as ex:\r\n            print(f\"{_get_function_name()} -> {ex}\")\r\n        return \"{?}\"\r\n\r\n\r\nclass node_set_slot_type:\r\n    CLASS_PATTERN = r\"phmap::priv::raw_hash_set<phmap::priv::NodeHashSetPolicy.*>::slot_type$\"\r\n    HAS_SUMMARY = True\r\n    IS_SYNTHETIC_PROVIDER = False\r\n\r\n    @staticmethod\r\n    def summary(valobj, _):\r\n        try:\r\n            summary = valobj.Dereference().GetSummary()\r\n            if not summary: summary = \"{...}\"\r\n            return summary\r\n        except BaseException as ex:\r\n            print(f\"{_get_function_name()} -> {ex}\")\r\n        return \"{?}\"\r\n\r\n\r\nclass flat_hash_map_or_set:\r\n    CLASS_PATTERN = \"^phmap::flat_hash_(map|set)<.*>$\"\r\n    HAS_SUMMARY = True\r\n    IS_SYNTHETIC_PROVIDER = True\r\n\r\n    @staticmethod\r\n    def summary(valobj, _):\r\n        try:\r\n            valobj = valobj.GetNonSyntheticValue()\r\n            size = valobj.GetChildMemberWithName('size_').GetValueAsUnsigned()\r\n            capacity = valobj.GetChildMemberWithName('capacity_').GetValueAsUnsigned()\r\n            return f\"size = {size} (capacity = {capacity})\"\r\n        except BaseException as ex:\r\n            print(f\"{_get_function_name()} -> {ex}\")\r\n        return \"{?}\"\r\n\r\n    def __init__(self, valobj, _):\r\n        self.valobj = valobj\r\n        self.slots_ = self.slot_type = self.ctrl_ = None\r\n        self.size_ = self.capacity_ = self.slot_size = 0\r\n\r\n    def num_children(self):\r\n        return min(self.size_, _MAX_CHILDREN)\r\n\r\n    def has_children(self):\r\n        return True\r\n\r\n    def update(self):\r\n        try:\r\n            self.size_ = self.valobj.GetChildMemberWithName('size_').GetValueAsUnsigned()\r\n            self.capacity_ = self.valobj.GetChildMemberWithName('capacity_').GetValueAsUnsigned()\r\n            self.slots_ = self.valobj.GetChildMemberWithName(\"slots_\")\r\n            self.slot_type = self.slots_.GetType().GetPointeeType()\r\n            self.slot_size = self.slot_type.GetByteSize()\r\n            self.ctrl_ = self.valobj.GetChildMemberWithName(\"ctrl_\")\r\n        except BaseException as ex:\r\n            print(f\"{_get_function_name(self)} -> {ex}\")\r\n\r\n    def get_child_index(self, name):\r\n        try:\r\n            if name in ('size_', 'capacity_'):\r\n                return -1\r\n            return int(name.lstrip('[').rstrip(']'))\r\n        except:\r\n            return -1\r\n\r\n    def get_child_at_index(self, index):\r\n        try:\r\n            if index < 0:\r\n                return None\r\n            if index >= self.size_ or index >= _MAX_CHILDREN:\r\n                return None\r\n            real_idx = -1\r\n            for idx in range(min(self.capacity_ + 3, _MAX_CTRL_INDEX)):\r\n                ctrl = self.ctrl_.GetChildAtIndex(idx, True, True).GetValueAsSigned()\r\n                if ctrl >= -1:\r\n                    real_idx += 1\r\n                    if real_idx == index:\r\n                        slot = self.slots_.CreateChildAtOffset(f'', idx * self.slot_size, self.slot_type)\r\n                        print(slot.type.name)\r\n                        if \"MapPolicy\" in slot.type.name:\r\n                            val = slot.GetChildAtIndex(0, True, True)\r\n                        else:\r\n                            val = slot\r\n                        return val.CreateChildAtOffset(f'[{index}]', 0, val.type)\r\n        except BaseException as ex:\r\n            print(f\"{_get_function_name(self)} -> {ex}\")\r\n        return None\r\n\r\n\r\nclass parallel_flat_or_node_map_or_set:\r\n    CLASS_PATTERN = \"^phmap::parallel_(flat|node)_hash_(map|set)<.*>$\"\r\n    HAS_SUMMARY = True\r\n    IS_SYNTHETIC_PROVIDER = True\r\n    REGEX_EXTRACT_ARRAY_SIZE = re.compile(r\"std::array\\s*<.*,\\s*(\\d+)\\s*>\")\r\n\r\n    @staticmethod\r\n    def _get_size_and_capacity(valobj):\r\n        try:\r\n            valobj = valobj.GetNonSyntheticValue()\r\n            sets = valobj.GetChildMemberWithName('sets_')\r\n            # sets is an std::array<T, SIZE>.\r\n            # It's not possible to get the size of the array with templates parameters\r\n            # \"set.GetType().GetTemplateArgumentType(1)\" returns an \"unsigned long\" type but not the value\r\n            # so we must extract it with a regex\r\n            m = parallel_flat_or_node_map_or_set.REGEX_EXTRACT_ARRAY_SIZE.match(sets.GetType().GetName())\r\n            n_buckets = int(m.group(1))\r\n            # this is dependent on the implementation of the standard library\r\n            buckets = sets.GetChildMemberWithName('_M_elems')\r\n            size = capacity = 0\r\n            for idx in range(n_buckets):\r\n                bucket = buckets.GetChildAtIndex(idx, True, True).GetChildMemberWithName('set_')\r\n                size += bucket.GetChildMemberWithName('size_').GetValueAsUnsigned()\r\n                capacity += bucket.GetChildMemberWithName('capacity_').GetValueAsUnsigned()\r\n            return size, capacity, n_buckets\r\n        except:\r\n            return '?', '?', 0\r\n\r\n    @staticmethod\r\n    def summary(valobj, _):\r\n        size, capacity, _ = parallel_flat_or_node_map_or_set._get_size_and_capacity(valobj)\r\n        return f\"size = {size} (capacity = {capacity})\"\r\n\r\n    def __init__(self, valobj, _):\r\n        self.valobj = valobj\r\n        self.buckets = self.slot_type = None\r\n        self.size_ = self.capacity_ = self.n_buckets_ = self.slot_type = self.ctrl_size = 0\r\n\r\n    def num_children(self):\r\n        return min(self.size_, _MAX_CHILDREN)\r\n\r\n    def has_children(self):\r\n        return True\r\n\r\n    def update(self):\r\n        try:\r\n            self.size_, self.capacity_, self.n_buckets_ = self._get_size_and_capacity(self.valobj)\r\n            self.buckets = self.valobj.GetChildMemberWithName('sets_').GetChildMemberWithName('_M_elems')\r\n            bucket0 = self.buckets.GetChildAtIndex(0).GetChildMemberWithName('set_')\r\n            self.slot_type = bucket0.GetChildMemberWithName('slots_').GetType().GetPointeeType()\r\n            self.slot_size = self.slot_type.GetByteSize()\r\n        except BaseException as ex:\r\n            print(f\"{_get_function_name(self)} -> {ex}\")\r\n\r\n    def get_child_index(self, name):\r\n        try:\r\n            if name in ('sets_'):\r\n                return -1\r\n            return int(name.lstrip('[').rstrip(']'))\r\n        except:\r\n            return -1\r\n\r\n    def get_child_at_index(self, index):\r\n        try:\r\n            if index < 0:\r\n                return None\r\n            if index >= self.size_ or index >= _MAX_CHILDREN:\r\n                return None\r\n            real_idx = -1\r\n            total_idx = 0\r\n            for idx in range(self.n_buckets_):\r\n                bucket = self.buckets.GetChildAtIndex(idx, True, True).GetChildMemberWithName('set_')\r\n                size = bucket.GetChildMemberWithName(\"size_\").GetValueAsUnsigned()\r\n                if size:\r\n                    slots_ = bucket.GetChildMemberWithName(\"slots_\")\r\n                    ctrl_ = bucket.GetChildMemberWithName(\"ctrl_\")\r\n                    for jdx in range(size):\r\n                        ctrl = ctrl_.GetChildAtIndex(jdx, True, True).GetValueAsSigned()\r\n                        if ctrl >= -1:\r\n                            real_idx += 1\r\n                            if real_idx == index:\r\n                                slot = slots_.CreateChildAtOffset(f'[{index}]', jdx * self.slot_size, self.slot_type)\r\n                                if \"MapPolicy\" in slot.type.name:\r\n                                    val = slot.GetChildAtIndex(0, True, True)\r\n                                else:\r\n                                    val = slot\r\n                                return val.CreateChildAtOffset(f'[{index}]', 0, val.type)\r\n                    total_idx += size\r\n                    if total_idx > _MAX_CHILDREN:\r\n                        return None\r\n        except BaseException as ex:\r\n            print(f\"{_get_function_name(self)} -> {ex}\")\r\n        return None\r\n\r\n\r\ndef __lldb_init_module(debugger, internal_dict):\r\n    for sp in (\r\n            flat_map_slot_type,\r\n            node_map_slot_type,\r\n            node_set_slot_type,\r\n            flat_hash_map_or_set,\r\n            parallel_flat_or_node_map_or_set,\r\n    ):\r\n        if sp.HAS_SUMMARY:\r\n            debugger.HandleCommand(\r\n                f'type summary add --regex \"{sp.CLASS_PATTERN}\" --python-function {_MODULE_NAME}.{sp.__name__}.summary '\r\n                f'--category phmap --expand')\r\n        if sp.IS_SYNTHETIC_PROVIDER:\r\n            debugger.HandleCommand(\r\n                f'type synthetic add --regex \"{sp.CLASS_PATTERN}\" --python-class {_MODULE_NAME}.{sp.__name__} '\r\n                f'--category phmap')\r\n    debugger.HandleCommand('type category enable phmap')\r\n"
        },
        {
          "name": "tests",
          "type": "tree",
          "content": null
        }
      ]
    }
  ]
}