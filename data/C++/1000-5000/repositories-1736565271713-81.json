{
  "metadata": {
    "timestamp": 1736565271713,
    "page": 81,
    "hasNextPage": true,
    "endCursor": "Y3Vyc29yOjkw",
    "completionStatus": "IN_PROGRESS"
  },
  "repositories": [
    {
      "nameWithOwner": "amazon-archives/amazon-dsstne",
      "stars": 4405,
      "defaultBranch": "master",
      "files": [
        {
          "name": ".dockerignore",
          "type": "blob",
          "size": 0.0048828125,
          "content": ".git\n"
        },
        {
          "name": ".github",
          "type": "tree",
          "content": null
        },
        {
          "name": ".gitignore",
          "type": "blob",
          "size": 0.3115234375,
          "content": "*.swp\n*.o\n/src/amazon/dsstne/bin/\n/src/amazon/dsstne/lib/\n/src/amazon/dsstne/utils/encoder\n/src/amazon/dsstne/utils/generateNetCDF\n/src/amazon/dsstne/utils/predict\n/src/amazon/dsstne/utils/train\n/src/amazon/dsstne/utils/TestGPU\n/src/amazon/dsstne/include/\n/build/\n/amazon-dsstne/\njava/target\njava/target/**\n.gitignore\n\n"
        },
        {
          "name": ".travis.yml",
          "type": "blob",
          "size": 1.96875,
          "content": "language: cpp\nsudo: required\ndist: trusty\n\nmatrix:\n  include:\n    - os: linux\n      compiler: gcc\n      addons:\n        apt:\n          sources: ['ubuntu-toolchain-r-test']\n          packages: ['g++-4.8']\n      env:\n        - NETCDF_CXX4_CXXFLAGS=-Wno-write-strings\n        - OUR_CXX=g++-4.8\n        - OUR_CC=gcc-4.8\n\n    - os: linux\n      compiler: gcc\n      addons:\n        apt:\n          sources: ['ubuntu-toolchain-r-test']\n          packages: ['g++-4.9']\n      env:\n        - NETCDF_CXX4_CXXFLAGS=-Wno-write-strings\n        - OUR_CXX=g++-4.9\n        - OUR_CC=gcc-4.9\n\n    - os: linux\n      compiler: gcc\n      addons:\n        apt:\n          sources: ['ubuntu-toolchain-r-test']\n          packages: ['g++-5']\n      env:\n        - NETCDF_CXX4_CXXFLAGS=-Wno-write-strings\n        - OUR_CXX=g++-5\n        - OUR_CC=gcc-5\n\n    - os: linux\n      compiler: clang\n      addons:\n        apt:\n          sources: ['ubuntu-toolchain-r-test', 'llvm-toolchain-precise-3.7']\n          packages: ['clang-3.7']\n      env:\n        - NETCDF_CXX4_CXXFLAGS=-Wno-c++11-compat-deprecated-writable-strings\n        - OUR_CXX=clang++-3.7\n        - OUR_CC=clang-3.7\n\n    - os: linux\n      compiler: clang\n      addons:\n        apt:\n          sources: ['ubuntu-toolchain-r-test', 'llvm-toolchain-precise-3.8']\n          packages: ['clang-3.8']\n      env:\n        - NETCDF_CXX4_CXXFLAGS=-Wno-c++11-compat-deprecated-writable-strings\n        - OUR_CXX=clang++-3.8\n        - OUR_CC=clang-3.8\n\nbefore_install:\n  - sudo apt-get update -qq\n  - sudo apt-get install -qq libcppunit-dev libnetcdf-dev\n\ninstall:\n  - wget http://www.unidata.ucar.edu/downloads/netcdf/ftp/netcdf-cxx4-4.2.tar.gz\n  - tar xvf netcdf-cxx4-4.2.tar.gz\n  - pushd netcdf-cxx4-4.2\n  - export CC=$OUR_CC\n  - export CXX=$OUR_CXX\n  - CXXFLAGS=$NETCDF_CXX4_CXXFLAGS ./configure --prefix=/usr/local\n  - make\n  - sudo make install\n  - popd\n\nscript:\n  - cd tst/unittests\n  - mkdir build && cd build\n  - cmake ..\n  - make\n  - LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/usr/local/lib ./unittests\n"
        },
        {
          "name": "CODE_OF_CONDUCT.md",
          "type": "blob",
          "size": 0.3037109375,
          "content": "## Code of Conduct\nThis project has adopted the [Amazon Open Source Code of Conduct](https://aws.github.io/code-of-conduct). \nFor more information see the [Code of Conduct FAQ](https://aws.github.io/code-of-conduct-faq) or contact \nopensource-codeofconduct@amazon.com with any additional questions or comments.\n"
        },
        {
          "name": "CONTRIBUTING.md",
          "type": "blob",
          "size": 3.4833984375,
          "content": "# Contributing Guidelines\n\nThank you for your interest in contributing to our project. Whether it's a bug report, new feature, correction, or additional \ndocumentation, we greatly value feedback and contributions from our community.\n\nPlease read through this document before submitting any issues or pull requests to ensure we have all the necessary \ninformation to effectively respond to your bug report or contribution.\n\n\n## Reporting Bugs/Feature Requests\n\nWe welcome you to use the GitHub issue tracker to report bugs or suggest features.\n\nWhen filing an issue, please check [existing open](https://github.com/amzn/amazon-dsstne/issues), or [recently closed](https://github.com/amzn/amazon-dsstne/issues?utf8=%E2%9C%93&q=is%3Aissue%20is%3Aclosed%20), issues to make sure somebody else hasn't already \nreported the issue. Please try to include as much information as you can. Details like these are incredibly useful:\n\n* A reproducible test case or series of steps\n* The version of our code being used\n* Any modifications you've made relevant to the bug\n* Anything unusual about your environment or deployment\n\n\n## Contributing via Pull Requests\nContributions via pull requests are much appreciated. Before sending us a pull request, please ensure that:\n\n1. You are working against the latest source on the *master* branch.\n2. You check existing open, and recently merged, pull requests to make sure someone else hasn't addressed the problem already.\n3. You open an issue to discuss any significant work - we would hate for your time to be wasted.\n\nTo send us a pull request, please:\n\n1. Fork the repository.\n2. Modify the source; please focus on the specific change you are contributing. If you also reformat all the code, it will be hard for us to focus on your change.\n3. Ensure local tests pass.\n4. Commit to your fork using clear commit messages.\n5. Send us a pull request, answering any default questions in the pull request interface.\n6. Pay attention to any automated CI failures reported in the pull request, and stay involved in the conversation.\n\nGitHub provides additional document on [forking a repository](https://help.github.com/articles/fork-a-repo/) and \n[creating a pull request](https://help.github.com/articles/creating-a-pull-request/).\n\n\n## Finding contributions to work on\nLooking at the existing issues is a great way to find something to contribute on. As our projects, by default, use the default GitHub issue labels ((enhancement/bug/duplicate/help wanted/invalid/question/wontfix), looking at any ['help wanted'](https://github.com/amzn/amazon-dsstne/labels/help%20wanted) issues is a great place to start. \n\n\n## Code of Conduct\nThis project has adopted the [Amazon Open Source Code of Conduct](https://aws.github.io/code-of-conduct). \nFor more information see the [Code of Conduct FAQ](https://aws.github.io/code-of-conduct-faq) or contact \nopensource-codeofconduct@amazon.com with any additional questions or comments.\n\n\n## Security issue notifications\nIf you discover a potential security issue in this project we ask that you notify AWS/Amazon Security via our [vulnerability reporting page](http://aws.amazon.com/security/vulnerability-reporting/). Please do **not** create a public github issue.\n\n\n## Licensing\n\nSee the [LICENSE](https://github.com/amzn/amazon-dsstne/blob/master/LICENSE) file for our project's licensing. We will ask you to confirm the licensing of your contribution.\n\nWe may ask you to sign a [Contributor License Agreement (CLA)](http://en.wikipedia.org/wiki/Contributor_License_Agreement) for larger changes.\n"
        },
        {
          "name": "Dockerfile",
          "type": "blob",
          "size": 1.517578125,
          "content": "# VERSION 0.3\n# AUTHOR:         DSSTNE Docker <dsstne-docker@amazon.com>\n# DESCRIPTION:    Docker image for Amazon DSSTNE\n\nFROM nvidia/cuda:9.1-cudnn7-devel-ubuntu16.04\n\n# Suppress interactive prompts while installing base packages\nENV DEBIAN_FRONTEND=noninteractive\n\n# Add repositories and install base packages\nRUN apt-get update && \\\n    apt-get install -y build-essential libcppunit-dev libatlas-base-dev pkg-config python \\\n        software-properties-common unzip wget && \\\n    add-apt-repository ppa:george-edison55/cmake-3.x && \\\n    apt-get update && \\\n    apt-get install -y cmake && \\\n    apt-get clean\n\n# Install OpenMPI\nRUN apt-get install -y libopenmpi-dev\n\n# Install JSONCPP\nRUN apt-get install -y libjsoncpp-dev\n\n# Install hdf5\nRUN apt-get install -y libhdf5-dev\n\n# Install zlib\nRUN apt-get install -y zlib1g-dev\n\n# Install netcdf\nRUN apt-get install -y libnetcdf-dev\n\n# Install netcdf-c++\nRUN apt-get install -y libnetcdf-c++4-dev\n\n# Installing CUBG\nRUN cd /tmp && \\\n    wget https://github.com/NVlabs/cub/archive/1.5.2.zip && \\\n    unzip 1.5.2.zip && \\\n    cp -rf cub-1.5.2/cub/ /usr/local/include/ && \\\n    rm -rf /tmp/*\n\n# Ensure OpenMPI is available on path\nENV PATH=/usr/local/openmpi/bin/:${PATH} \\\n    LD_LIBRARY_PATH=/usr/local/lib/:/usr/local/openmpi/lib/:${LD_LIBRARY_PATH}\n\n# Build latest version of DSSTNE from source\nCOPY . /opt/amazon/dsstne\nRUN cd /opt/amazon/dsstne && \\\n    make install\n\n# Cleanup\nRUN rm -rf /var/lib/apt/lists/* /tmp/* /var/tmp/*\n\n# Add DSSTNE binaries to PATH\nENV PATH=/opt/amazon/dsstne/bin/:${PATH}\n"
        },
        {
          "name": "FAQ.md",
          "type": "blob",
          "size": 6.853515625,
          "content": "# Amazon DSSTNE: Q&A\n\n## What is DSSTNE?\nDeep Scalable Sparse Tensor Network Engine, (DSSTNE), pronounced “Destiny”, is an Amazon developed library for building Deep Learning (DL) machine learning (ML) models for recommendations. DSSTNE significantly outperforms current open source DL libraries on certain tasks where training data is sparse (where almost all the values are zero), common in recommendation problems.\n\n## Why is Amazon open sourcing DSSTNE?\nWe are releasing DSSTNE as open source software so that the promise of deep learning can extend beyond speech and language understanding and object recognition to other areas such as search and recommendations. We hope that researchers around the world can collaborate to improve it. But more importantly, we hope that it spurs innovation in many more areas.\n\n## Why did Amazon write this library?\nEvery day, hundreds of millions of customers shop on Amazon. We help them discover the right product from an immense catalog of products. Making good recommendations requires neural networks. Even a simple 3-layer autoencoder with an input layer of hundreds of million nodes (one for every product), a hidden layer of 1000 nodes, and an output layer mirroring the input layer has upwards of a trillion parameters to learn. Once again, this is hard to solve with today’s hardware. Reducing the size of the network by limiting it to a single product category and to users in the United States also pushes the boundaries of present day GPUs. For example, the weight matrices of a 3-layer autoencoder with 8 million nodes in the input and output layer and 256 nodes in the hidden layer consumes 8GB of memory in single precision arithmetic. Even training such a network using open source software with shopping data from tens of millions of users would take weeks on the fastest GPUs available on the market.\nA few weeks into this endeavor we realized that we couldn’t make meaningful progress without writing software that parallelized backpropagation by distributing the computation across multiple GPUs. So we built our own deep learning package.\n\n## What makes DSSTNE different/differentiated from other deep learning libraries/offerings?\nDSSTNE has been built from the ground up to support use cases where training data is sparse, while other libraries such as Caffe, TensorFlow, Theano and Torch have a larger feature set and network support. DSSTNE resembles Caffe in spirit, emphasizing performance for production applications. DSSTNE is much faster than any other DL package (2.1x compared to TensorFlow in 1 g2.8xlarge) for problems involving sparse data, which includes recommendations problems and many natural language understanding (NLU) tasks. DSSTNE is also significantly better than other packages at using multiple GPUs in a single server. DSSTNE can automatically distribute each computation across all available GPUs, speeding up all computations, and also enabling larger models than other packages can build without heroic effort. Practically, this means being able to build recommendations systems that can model ten million unique products instead of hundreds of thousands, or NLU tasks with very large vocabularies. For problems of this size, other packages would need to revert to CPU computation for the sparse data, decreasing performance by about an order of magnitude. Also, DSSTNE’s network definition language is much simpler than Caffe’s, as it would require only 33 lines of code to express the popular AlexNet image recognition model, whereas Caffe’s language requires over 300 lines of code. DSSTNE does not yet support the convolutional layers needed for image processing, and has only limited support for recurrent layers needed for many NLU and speech recognition tasks, but both of these features are on its immediate roadmap.\n\n## What are the new and innovative capabilities?\n1. 2.1x Speedup vs TensorFlow in a g2.8xlarge for MovieLens recommendations.\n2. Multi-GPU capability of model-parallelism, increasing the speed of training by automatically distributing the computation between multiple interconnected GPUs in the same host. DSSTNE makes it easy to take advantage of servers with multiple GPUs by automatically distributing the computations across GPUs. Scaling out deep neural network training jobs is important because these jobs can take a very long time to run, limiting experimentation. The most common pattern is to split the training data across GPUs, have each GPU train its own model on a part of the data and then keep those models in sync somehow. This pattern, called “data-parallel training”, generally requires making trade-offs between speed and accuracy.\nDSSTNE instead uses “model-parallel training”, where each layer of the network is split across the available GPUs so each operation just runs faster. Model-parallel training is harder to implement, but it doesn’t come with the same speed/accuracy trade-offs of data-parallel training. Other neural network libraries offer a version of model-parallel training where each layer or operation can be assigned to a different GPU. While this approach works for some problems, it doesn’t work in situations where the weight matrices just don’t fit in the memory of a single GPU – like the recommendations problem at Amazon.\n\n## What is the license associated with DSSTNE? Restrictions? Attributions? Requirements?\nDSSTNE is licensed with the business-friendly Apache 2.0 license\n\n\n## Can DSSTNE be run on multiple instances working on the same data set?\nYes, it can be run on cluster with multiple instances (like EMR). If a MPI cluster is set up, the framework detects the lack of Peer-to-Peer connectivity between the GPUs in play and automagically switches to MPI system memory collectives. That being said, please ensure that all your nodes are in the same placement group connected by Elastic File System, so that you can share the data across the instances\n\n## Is there a way to run this on multiple instances working on the same data set? like EMR?\nYes, if you set up an MPI cluster, it should work. The framework detects the lack of P2P connectivity between the GPUs in play and automagically switches to MPI system memory collectives (distributed enabled from day 1).\nHowever, at 10 Gb/s between g2.8xlarge instances plus ~2-3 GB/s upload/download because virtualization, you will need a rather large layer to get efficient scaling. That said, if you just want to run large models, it should just work. It has, of course, never been tried beyond a single instance to my knowledge.\nWhat will be interesting down the road is running this on RDMA-enabled servers that allow inter-system P2P copies. That will need a few more lines of code, but it also ought to work.\nIf you are using Multiple Instance please ensure that all your nodes are in the same placement group.\nI would try Multiple EC2 instances on the same Placement group connected by Elastic File System so that you can share the data across the instances\n"
        },
        {
          "name": "LICENSE",
          "type": "blob",
          "size": 11.1201171875,
          "content": "                                 Apache License\n                           Version 2.0, January 2004\n                        http://www.apache.org/licenses/\n\n   TERMS AND CONDITIONS FOR USE, REPRODUCTION, AND DISTRIBUTION\n\n   1. Definitions.\n\n      \"License\" shall mean the terms and conditions for use, reproduction,\n      and distribution as defined by Sections 1 through 9 of this document.\n\n      \"Licensor\" shall mean the copyright owner or entity authorized by\n      the copyright owner that is granting the License.\n\n      \"Legal Entity\" shall mean the union of the acting entity and all\n      other entities that control, are controlled by, or are under common\n      control with that entity. For the purposes of this definition,\n      \"control\" means (i) the power, direct or indirect, to cause the\n      direction or management of such entity, whether by contract or\n      otherwise, or (ii) ownership of fifty percent (50%) or more of the\n      outstanding shares, or (iii) beneficial ownership of such entity.\n\n      \"You\" (or \"Your\") shall mean an individual or Legal Entity\n      exercising permissions granted by this License.\n\n      \"Source\" form shall mean the preferred form for making modifications,\n      including but not limited to software source code, documentation\n      source, and configuration files.\n\n      \"Object\" form shall mean any form resulting from mechanical\n      transformation or translation of a Source form, including but\n      not limited to compiled object code, generated documentation,\n      and conversions to other media types.\n\n      \"Work\" shall mean the work of authorship, whether in Source or\n      Object form, made available under the License, as indicated by a\n      copyright notice that is included in or attached to the work\n      (an example is provided in the Appendix below).\n\n      \"Derivative Works\" shall mean any work, whether in Source or Object\n      form, that is based on (or derived from) the Work and for which the\n      editorial revisions, annotations, elaborations, or other modifications\n      represent, as a whole, an original work of authorship. For the purposes\n      of this License, Derivative Works shall not include works that remain\n      separable from, or merely link (or bind by name) to the interfaces of,\n      the Work and Derivative Works thereof.\n\n      \"Contribution\" shall mean any work of authorship, including\n      the original version of the Work and any modifications or additions\n      to that Work or Derivative Works thereof, that is intentionally\n      submitted to Licensor for inclusion in the Work by the copyright owner\n      or by an individual or Legal Entity authorized to submit on behalf of\n      the copyright owner. For the purposes of this definition, \"submitted\"\n      means any form of electronic, verbal, or written communication sent\n      to the Licensor or its representatives, including but not limited to\n      communication on electronic mailing lists, source code control systems,\n      and issue tracking systems that are managed by, or on behalf of, the\n      Licensor for the purpose of discussing and improving the Work, but\n      excluding communication that is conspicuously marked or otherwise\n      designated in writing by the copyright owner as \"Not a Contribution.\"\n\n      \"Contributor\" shall mean Licensor and any individual or Legal Entity\n      on behalf of whom a Contribution has been received by Licensor and\n      subsequently incorporated within the Work.\n\n   2. Grant of Copyright License. Subject to the terms and conditions of\n      this License, each Contributor hereby grants to You a perpetual,\n      worldwide, non-exclusive, no-charge, royalty-free, irrevocable\n      copyright license to reproduce, prepare Derivative Works of,\n      publicly display, publicly perform, sublicense, and distribute the\n      Work and such Derivative Works in Source or Object form.\n\n   3. Grant of Patent License. Subject to the terms and conditions of\n      this License, each Contributor hereby grants to You a perpetual,\n      worldwide, non-exclusive, no-charge, royalty-free, irrevocable\n      (except as stated in this section) patent license to make, have made,\n      use, offer to sell, sell, import, and otherwise transfer the Work,\n      where such license applies only to those patent claims licensable\n      by such Contributor that are necessarily infringed by their\n      Contribution(s) alone or by combination of their Contribution(s)\n      with the Work to which such Contribution(s) was submitted. If You\n      institute patent litigation against any entity (including a\n      cross-claim or counterclaim in a lawsuit) alleging that the Work\n      or a Contribution incorporated within the Work constitutes direct\n      or contributory patent infringement, then any patent licenses\n      granted to You under this License for that Work shall terminate\n      as of the date such litigation is filed.\n\n   4. Redistribution. You may reproduce and distribute copies of the\n      Work or Derivative Works thereof in any medium, with or without\n      modifications, and in Source or Object form, provided that You\n      meet the following conditions:\n\n      (a) You must give any other recipients of the Work or\n          Derivative Works a copy of this License; and\n\n      (b) You must cause any modified files to carry prominent notices\n          stating that You changed the files; and\n\n      (c) You must retain, in the Source form of any Derivative Works\n          that You distribute, all copyright, patent, trademark, and\n          attribution notices from the Source form of the Work,\n          excluding those notices that do not pertain to any part of\n          the Derivative Works; and\n\n      (d) If the Work includes a \"NOTICE\" text file as part of its\n          distribution, then any Derivative Works that You distribute must\n          include a readable copy of the attribution notices contained\n          within such NOTICE file, excluding those notices that do not\n          pertain to any part of the Derivative Works, in at least one\n          of the following places: within a NOTICE text file distributed\n          as part of the Derivative Works; within the Source form or\n          documentation, if provided along with the Derivative Works; or,\n          within a display generated by the Derivative Works, if and\n          wherever such third-party notices normally appear. The contents\n          of the NOTICE file are for informational purposes only and\n          do not modify the License. You may add Your own attribution\n          notices within Derivative Works that You distribute, alongside\n          or as an addendum to the NOTICE text from the Work, provided\n          that such additional attribution notices cannot be construed\n          as modifying the License.\n\n      You may add Your own copyright statement to Your modifications and\n      may provide additional or different license terms and conditions\n      for use, reproduction, or distribution of Your modifications, or\n      for any such Derivative Works as a whole, provided Your use,\n      reproduction, and distribution of the Work otherwise complies with\n      the conditions stated in this License.\n\n   5. Submission of Contributions. Unless You explicitly state otherwise,\n      any Contribution intentionally submitted for inclusion in the Work\n      by You to the Licensor shall be under the terms and conditions of\n      this License, without any additional terms or conditions.\n      Notwithstanding the above, nothing herein shall supersede or modify\n      the terms of any separate license agreement you may have executed\n      with Licensor regarding such Contributions.\n\n   6. Trademarks. This License does not grant permission to use the trade\n      names, trademarks, service marks, or product names of the Licensor,\n      except as required for reasonable and customary use in describing the\n      origin of the Work and reproducing the content of the NOTICE file.\n\n   7. Disclaimer of Warranty. Unless required by applicable law or\n      agreed to in writing, Licensor provides the Work (and each\n      Contributor provides its Contributions) on an \"AS IS\" BASIS,\n      WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or\n      implied, including, without limitation, any warranties or conditions\n      of TITLE, NON-INFRINGEMENT, MERCHANTABILITY, or FITNESS FOR A\n      PARTICULAR PURPOSE. You are solely responsible for determining the\n      appropriateness of using or redistributing the Work and assume any\n      risks associated with Your exercise of permissions under this License.\n\n   8. Limitation of Liability. In no event and under no legal theory,\n      whether in tort (including negligence), contract, or otherwise,\n      unless required by applicable law (such as deliberate and grossly\n      negligent acts) or agreed to in writing, shall any Contributor be\n      liable to You for damages, including any direct, indirect, special,\n      incidental, or consequential damages of any character arising as a\n      result of this License or out of the use or inability to use the\n      Work (including but not limited to damages for loss of goodwill,\n      work stoppage, computer failure or malfunction, or any and all\n      other commercial damages or losses), even if such Contributor\n      has been advised of the possibility of such damages.\n\n   9. Accepting Warranty or Additional Liability. While redistributing\n      the Work or Derivative Works thereof, You may choose to offer,\n      and charge a fee for, acceptance of support, warranty, indemnity,\n      or other liability obligations and/or rights consistent with this\n      License. However, in accepting such obligations, You may act only\n      on Your own behalf and on Your sole responsibility, not on behalf\n      of any other Contributor, and only if You agree to indemnify,\n      defend, and hold each Contributor harmless for any liability\n      incurred by, or claims asserted against, such Contributor by reason\n      of your accepting any such warranty or additional liability.\n\n   END OF TERMS AND CONDITIONS\n\n   APPENDIX: How to apply the Apache License to your work.\n\n      To apply the Apache License to your work, attach the following\n      boilerplate notice, with the fields enclosed by brackets \"{}\"\n      replaced with your own identifying information. (Don't include\n      the brackets!)  The text should be enclosed in the appropriate\n      comment syntax for the file format. We also recommend that a\n      file or class name and description of purpose be included on the\n      same \"printed page\" as the copyright notice for easier\n      identification within third-party archives.\n\n   Copyright 2016 Amazon.com, Inc. or its affiliates. All Rights Reserved. \n\n   Licensed under the Apache License, Version 2.0 (the \"License\");\n   you may not use this file except in compliance with the License.\n   You may obtain a copy of the License at\n\n       http://www.apache.org/licenses/LICENSE-2.0\n\n   Unless required by applicable law or agreed to in writing, software\n   distributed under the License is distributed on an \"AS IS\" BASIS,\n   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n   See the License for the specific language governing permissions and\n   limitations under the License.\n"
        },
        {
          "name": "Makefile",
          "type": "blob",
          "size": 0.775390625,
          "content": "SHELL=/bin/sh\nVPATH=\n\n# Prefix of the directory to install dsstne.\nPREFIX ?= $(shell pwd)/amazon-dsstne\n\n# Build directory. Export it for sub-makefiles to use it\nexport BUILD_DIR ?= $(shell pwd)/build\n\nall: | engine runtime utils tests java\n\nengine:\n\tcd src/amazon/dsstne/engine && make\n\nutils:\n\tcd src/amazon/dsstne/utils && make\n\nruntime:\n\tcd src/amazon/dsstne/runtime && make\n\ntests:\n\tcd tst && make\n\n#java: | engine runtime tests\n#\tcd java && make\n\ninstall: all\n\tmkdir -p $(PREFIX)\n\tcp -rfp $(BUILD_DIR)/lib $(PREFIX)\n\tcp -rfp $(BUILD_DIR)/bin $(PREFIX)\n\tcp -rfp $(BUILD_DIR)/include $(PREFIX)\n\nrun-tests:\n\tcd tst && make run-tests\n\nclean:\n\tcd src/amazon/dsstne/engine && make clean\n\tcd src/amazon/dsstne/utils && make clean\n\tcd tst && make clean\n\n#.PHONY: engine runtime tests java clean \n"
        },
        {
          "name": "NOTICE",
          "type": "blob",
          "size": 0.0888671875,
          "content": "Amazon DSSTNE\nCopyright 2015-2016 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n"
        },
        {
          "name": "README.md",
          "type": "blob",
          "size": 2.0986328125,
          "content": "\n\n# Amazon DSSTNE: Deep Scalable Sparse Tensor Network Engine\n\nDSSTNE (pronounced \"Destiny\") is an open source software library for training and deploying recommendation\nmodels with sparse inputs, fully connected hidden layers, and sparse outputs. Models with weight matrices\nthat are too large for a single GPU can still be trained on a single host. DSSTNE has been used at Amazon\nto generate personalized product recommendations for our customers at Amazon's scale. It is designed for\nproduction deployment of real-world applications which need to emphasize speed and scale over experimental \nflexibility.\n\nDSSTNE was built with a number of features for production recommendation workloads:\n\n* **Multi-GPU Scale**: Training and prediction\nboth scale out to use multiple GPUs, spreading out computation\nand storage in a model-parallel fashion for each layer.\n* **Large Layers**: Model-parallel scaling enables larger networks than\nare possible with a single GPU.\n* **Sparse Data**: DSSTNE is optimized for fast performance on sparse datasets, common in recommendation \nproblems. Custom GPU kernels perform sparse computation on the GPU, without filling in lots of zeroes.\n\n## Benchmarks\n* scottlegrand@ reported [near-linear scaling with multiple GPUs] on the MovieLens recommendation problem \n(https://medium.com/@scottlegrand/first-dsstne-benchmarks-tldr-almost-15x-faster-than-tensorflow-393dbeb80c0f#.ghe74fu1q)\n* Directions on how to run a benchmark can be found in [here](benchmarks/Benchmark.md)\n\n## Scaling up\n* [Using Spark in AWS EMR and Dockers in AWS ECS ](http://blogs.aws.amazon.com/bigdata/post/TxGEL8IJ0CAXTK/Generating-Recommendations-at-Amazon-Scale-with-Apache-Spark-and-Amazon-DSSTNE)\n    \n\n## License\n[License](LICENSE)\n\n\n \n \n\n## Setup\n* Follow [Setup](docs/getting_started/setup.md) for step by step instructions on installing and setting up DSSTNE\n\n## User Guide\n* Check [User Guide](docs/getting_started/userguide.md) for detailed information about the features in DSSTNE\n\n## Examples\n* Check [Examples](docs/getting_started/examples.md) to start trying your first Neural Network Modeling using DSSTNE\n\n## Q&A\n[FAQ](FAQ.md)\n"
        },
        {
          "name": "Singularity",
          "type": "blob",
          "size": 2.9384765625,
          "content": "Bootstrap: docker\nFrom: nvidia/cuda:7.5-cudnn5-devel-ubuntu14.04\n\n%environment\n    DEBIAN_FRONTEND=noninteractive\n    LD_LIBRARY_PATH=/usr/local/lib/:/usr/local/openmpi/lib/\n    PATH=/amazon-dsstne/src/amazon/dsstne/bin/:/usr/local/openmpi/bin/:${PATH}\n    export DEBIAN_FRONTEND LD_LIBRARY_PATH PATH\n\n%setup\n    echo $SINGULARITY_ROOTFS\n    echo \"cp -r . $SINGULARITY_ROOTFS/\"\n    cp Singularity $SINGULARITY_ROOTFS/\n    cp -r ./amazon-dsstne/ $SINGULARITY_ROOTFS/\n\n%post\n    apt-get update && \\\n    apt-get install -y build-essential libcppunit-dev libatlas-base-dev pkg-config python \\\n        software-properties-common unzip wget && \\\n    add-apt-repository ppa:george-edison55/cmake-3.x && \\\n    apt-get update && \\\n    apt-get install -y cmake && \\\n    apt-get clean && \\\n    rm -rf /var/lib/apt/lists/* /tmp/* /var/tmp/*\n\n    cd /tmp  &&  \\\n    wget https://www.open-mpi.org/software/ompi/v2.1/downloads/openmpi-2.1.1.tar.gz && \\\n    tar xvfz openmpi-2.1.1.tar.gz && \\\n    cd openmpi-2.1.1 && \\\n    ./configure CC=gcc CXX=g++ --enable-mpi-cxx --prefix=/usr/local/openmpi && \\\n    make -j 8 && \\\n    sudo make install && rm -rf /tmp/*\n\n    cd /tmp  && \\\n    wget https://github.com/open-source-parsers/jsoncpp/archive/svn-import.tar.gz && \\\n    tar xvfz svn-import.tar.gz && \\\n    cd jsoncpp-svn-import && \\\n    mkdir -p build/release && \\\n    cd build/release && \\\n    cmake -DCMAKE_BUILD_TYPE=release -DJSONCPP_LIB_BUILD_SHARED=OFF -G \"Unix Makefiles\" ../.. && \\\n    make -j 8 && \\\n    make install && rm -rf /tmp/*\n\n    cd /tmp && \\\n    wget ftp://ftp.unidata.ucar.edu/pub/netcdf/netcdf-4/hdf5-1.8.9.tar.gz && \\\n    tar xvfz hdf5-1.8.9.tar.gz && \\\n    cd hdf5-1.8.9 && \\\n    ./configure --prefix=/usr/local &&\\\n    make -j 8 && \\\n    make install && rm -rf /tmp/*\n\n    cd /tmp && \\\n    wget https://www.unidata.ucar.edu/downloads/netcdf/ftp/netcdf-4/zlib-1.2.8.tar.gz && \\\n    tar xvf zlib-1.2.8.tar.gz && \\\n    cd zlib-1.2.8 && \\\n    ./configure && \\\n    make -j 8 && \\\n    make install && rm -rf /tmp/*\n\n    cd /tmp && \\\n    wget https://www.unidata.ucar.edu/downloads/netcdf/ftp/netcdf-4.1.3.tar.gz && \\\n    tar xvf netcdf-4.1.3.tar.gz && \\\n    cd netcdf-4.1.3 && \\\n    ./configure --prefix=/usr/local && \\\n    make -j 8 && \\\n    make install && rm -rf /tmp/*\n\n    cd /tmp && \\\n    wget https://www.unidata.ucar.edu/downloads/netcdf/ftp/netcdf-cxx4-4.2.tar.gz && \\\n    tar xvf netcdf-cxx4-4.2.tar.gz && \\\n    cd netcdf-cxx4-4.2 && \\\n    ./configure --prefix=/usr/local && \\\n    make -j 8 && \\\n    make install && rm -rf /tmp/*\n\n    cd /tmp && \\\n    wget https://github.com/NVlabs/cub/archive/1.5.2.zip && \\\n    unzip 1.5.2.zip && \\\n    cp -rf cub-1.5.2/cub/ /usr/local/include/ && \\\n    rm -rf /tmp/*\n\n    export LD_LIBRARY_PATH=/usr/local/lib/:/usr/local/openmpi/lib/:${LD_LIBRARY_PATH}\n    export PATH=/amazon-dsstne/src/amazon/dsstne/bin:/usr/local/openmpi/bin:/usr/local/bin:/usr/local/include/bin:/usr/local/cuda-7.5/bin:${PATH}\n    cd /amazon-dsstne/src/amazon/dsstne && \\\n    make install\n"
        },
        {
          "name": "amazon-dsstne",
          "type": "tree",
          "content": null
        },
        {
          "name": "benchmarks",
          "type": "tree",
          "content": null
        },
        {
          "name": "docs",
          "type": "tree",
          "content": null
        },
        {
          "name": "java",
          "type": "tree",
          "content": null
        },
        {
          "name": "python",
          "type": "tree",
          "content": null
        },
        {
          "name": "samples",
          "type": "tree",
          "content": null
        },
        {
          "name": "src",
          "type": "tree",
          "content": null
        },
        {
          "name": "talks",
          "type": "tree",
          "content": null
        },
        {
          "name": "tst",
          "type": "tree",
          "content": null
        }
      ]
    }
  ]
}