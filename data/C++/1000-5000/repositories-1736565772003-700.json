{
  "metadata": {
    "timestamp": 1736565772003,
    "page": 700,
    "hasNextPage": true,
    "endCursor": "Y3Vyc29yOjcwMA==",
    "completionStatus": "IN_PROGRESS"
  },
  "repositories": [
    {
      "nameWithOwner": "bshoshany/thread-pool",
      "stars": 2297,
      "defaultBranch": "master",
      "files": [
        {
          "name": ".clang-format",
          "type": "blob",
          "size": 4.5,
          "content": "AccessModifierOffset: -4\nAlignAfterOpenBracket: DontAlign\nAlignArrayOfStructures: None\nAlignConsecutiveAssignments: None\nAlignConsecutiveBitFields: None\nAlignConsecutiveDeclarations: None\nAlignConsecutiveMacros: None\nAlignConsecutiveShortCaseStatements:\n  Enabled: false\nAlignEscapedNewlines: Left\nAlignOperands: DontAlign\nAlignTrailingComments:\n  Kind: Always\n  OverEmptyLines: 0\nAllowAllArgumentsOnNextLine: false\nAllowAllParametersOfDeclarationOnNextLine: false\nAllowBreakBeforeNoexceptSpecifier: Never\nAllowShortBlocksOnASingleLine: Empty\nAllowShortCaseLabelsOnASingleLine: false\nAllowShortCompoundRequirementOnASingleLine: true\nAllowShortEnumsOnASingleLine: false\nAllowShortFunctionsOnASingleLine: Empty\nAllowShortIfStatementsOnASingleLine: Never\nAllowShortLambdasOnASingleLine: Empty\nAllowShortLoopsOnASingleLine: false\nAlwaysBreakAfterReturnType: None\nAlwaysBreakBeforeMultilineStrings: false\nAlwaysBreakTemplateDeclarations: Yes\nAttributeMacros: []\nBinPackArguments: true\nBinPackParameters: true\nBitFieldColonSpacing: Both\nBraceWrapping:\n  AfterCaseLabel: true\n  AfterClass: true\n  AfterControlStatement: Always\n  AfterEnum: true\n  AfterExternBlock: true\n  AfterFunction: true\n  AfterNamespace: false\n  AfterStruct: true\n  AfterUnion: true\n  BeforeCatch: true\n  BeforeElse: true\n  BeforeLambdaBody: true\n  BeforeWhile: false\n  IndentBraces: false\n  SplitEmptyFunction: true\n  SplitEmptyNamespace: true\n  SplitEmptyRecord: true\nBracedInitializerIndentWidth: 4\nBreakAdjacentStringLiterals: false\nBreakAfterAttributes: Never\nBreakBeforeBinaryOperators: None\nBreakBeforeBraces: Custom\nBreakBeforeConceptDeclarations: true\nBreakBeforeInheritanceComma: false\nBreakBeforeTernaryOperators: true\nBreakConstructorInitializers: BeforeColon\nBreakConstructorInitializersBeforeComma: false\nBreakInheritanceList: BeforeColon\nBreakStringLiterals: true\nColumnLimit: 1024\nCompactNamespaces: false\nConstructorInitializerAllOnOneLineOrOnePerLine: false\nConstructorInitializerIndentWidth: 4\nContinuationIndentWidth: 4\nCpp11BracedListStyle: true\nDeriveLineEnding: true\nDerivePointerAlignment: false\nDisableFormat: false\nEmptyLineAfterAccessModifier: Never\nEmptyLineBeforeAccessModifier: LogicalBlock\nExperimentalAutoDetectBinPacking: false\nFixNamespaceComments: true\nIncludeBlocks: Preserve\nIncludeIsMainSourceRegex: ''\nIndentAccessModifiers: false\nIndentCaseBlocks: false\nIndentCaseLabels: false\nIndentExternBlock: AfterExternBlock\nIndentGotoLabels: true\nIndentPPDirectives: BeforeHash\nIndentRequires: false\nIndentWidth: 4\nIndentWrappedFunctionNames: false\nJavaScriptQuotes: Leave\nJavaScriptWrapImports: true\nKeepEmptyLinesAtTheStartOfBlocks: true\nLambdaBodyIndentation: Signature\nLanguage: Cpp\nMacroBlockBegin: ''\nMacroBlockEnd: ''\nMaxEmptyLinesToKeep: 1\nNamespaceIndentation: Inner\nObjCBinPackProtocolList: Auto\nObjCBlockIndentWidth: 4\nObjCBreakBeforeNestedBlockParam: true\nObjCSpaceAfterProperty: false\nObjCSpaceBeforeProtocolList: true\nPPIndentWidth: -1\nPackConstructorInitializers: BinPack\nPenaltyBreakAssignment: 0\nPenaltyBreakBeforeFirstCallParameter: 0\nPenaltyBreakComment: 0\nPenaltyBreakFirstLessLess: 0\nPenaltyBreakOpenParenthesis: 0\nPenaltyBreakString: 0\nPenaltyBreakTemplateDeclaration: 0\nPenaltyExcessCharacter: 0\nPenaltyIndentedWhitespace: 0\nPenaltyReturnTypeOnItsOwnLine: 0\nPointerAlignment: Left\nQualifierAlignment: Leave\nReferenceAlignment: Pointer\nReflowComments: true\nRemoveBracesLLVM: false\nSeparateDefinitionBlocks: Always\nShortNamespaceLines: 1\nSkipMacroDefinitionBody: true\nSortIncludes: CaseSensitive\nSortJavaStaticImport: Before\nSortUsingDeclarations: true\nSpaceAfterCStyleCast: false\nSpaceAfterLogicalNot: false\nSpaceAfterTemplateKeyword: true\nSpaceAroundPointerQualifiers: Default\nSpaceBeforeAssignmentOperators: true\nSpaceBeforeCaseColon: false\nSpaceBeforeCpp11BracedList: false\nSpaceBeforeCtorInitializerColon: true\nSpaceBeforeInheritanceColon: true\nSpaceBeforeParens: ControlStatements\nSpaceBeforeParensOptions:\n  AfterControlStatements: true\n  AfterForeachMacros: true\n  AfterFunctionDeclarationName: false\n  AfterFunctionDefinitionName: false\n  AfterIfMacros: true\n  AfterOverloadedOperator: false\n  BeforeNonEmptyParentheses: false\nSpaceBeforeRangeBasedForLoopColon: true\nSpaceBeforeSquareBrackets: false\nSpaceInEmptyBlock: false\nSpaceInEmptyParentheses: false\nSpacesBeforeTrailingComments: 1\nSpacesInAngles: Never\nSpacesInCStyleCastParentheses: false\nSpacesInConditionalStatement: false\nSpacesInContainerLiterals: true\nSpacesInLineCommentPrefix:\n  Maximum: 1\n  Minimum: 1\nSpacesInParentheses: false\nSpacesInSquareBrackets: false\nStandard: Latest\nTabWidth: 4\nUseCRLF: false\nUseTab: Never\n"
        },
        {
          "name": ".clang-tidy",
          "type": "blob",
          "size": 1.748046875,
          "content": "CheckOptions:\n  misc-const-correctness.WarnPointersAsValues: true\n  misc-non-private-member-variables-in-classes.IgnoreClassesWithAllMemberVariablesBeingPublic: true\n  readability-magic-numbers.IgnoredIntegerValues: 0; 1; 2; 3; 4; 5; 6; 7; 8; 9; 10\nChecks: >\n    *,\n    -abseil-*,\n    -altera-*,\n    -android-*,\n    -boost-*,\n    -bugprone-easily-swappable-parameters,\n    -bugprone-empty-catch,\n    -cert-err58-cpp,\n    -cppcoreguidelines-avoid-c-arrays,\n    -cppcoreguidelines-avoid-do-while,\n    -cppcoreguidelines-avoid-magic-numbers,\n    -cppcoreguidelines-avoid-non-const-global-variables,\n    -cppcoreguidelines-macro-usage,\n    -cppcoreguidelines-pro-bounds-array-to-pointer-decay,\n    -cppcoreguidelines-pro-bounds-constant-array-index,\n    -cppcoreguidelines-pro-bounds-pointer-arithmetic,\n    -cppcoreguidelines-pro-type-reinterpret-cast,\n    -cppcoreguidelines-pro-type-vararg,\n    -darwin-*,\n    -fuchsia-*,\n    -google-*,\n    -hicpp-avoid-c-arrays,\n    -hicpp-braces-around-statements,\n    -hicpp-no-array-decay,\n    -hicpp-signed-bitwise,\n    -hicpp-use-auto,\n    -hicpp-vararg,\n    -linuxkernel-*,\n    -llvm-*,\n    -llvmlibc-*,\n    -misc-definitions-in-headers,\n    -misc-use-internal-linkage,\n    -modernize-avoid-bind,\n    -modernize-avoid-c-arrays,\n    -modernize-use-auto,\n    -modernize-use-constraints,\n    -modernize-use-designated-initializers,\n    -modernize-use-ranges,\n    -modernize-use-std-numbers,\n    -modernize-use-trailing-return-type,\n    -mpi-*,\n    -objc-*,\n    -openmp-*,\n    -performance-enum-size,\n    -readability-avoid-nested-conditional-operator,\n    -readability-braces-around-statements,\n    -readability-function-cognitive-complexity,\n    -readability-identifier-length,\n    -zircon-*,\nHeaderFileExtensions: [h, hpp, cppm]\nHeaderFilterRegex: .*\n"
        },
        {
          "name": ".github",
          "type": "tree",
          "content": null
        },
        {
          "name": ".gitignore",
          "type": "blob",
          "size": 0.0107421875,
          "content": "build\ntemp\n"
        },
        {
          "name": ".vscode-linux",
          "type": "tree",
          "content": null
        },
        {
          "name": ".vscode-macos",
          "type": "tree",
          "content": null
        },
        {
          "name": ".vscode-windows",
          "type": "tree",
          "content": null
        },
        {
          "name": "CHANGELOG.md",
          "type": "blob",
          "size": 97.5283203125,
          "content": "# `BS::thread_pool`: a fast, lightweight, modern, and easy-to-use C++17 / C++20 / C++23 thread pool library\n\nBy **Barak Shoshany**\\\nEmail: <baraksh@gmail.com>\\\nWebsite: <https://baraksh.com/>\\\nGitHub: <https://github.com/bshoshany>\n\n* [Version history](#version-history)\n    * [v5.0.0 (2024-12-19)](#v500-2024-12-19)\n    * [v4.1.0 (2024-03-22)](#v410-2024-03-22)\n    * [v4.0.1 (2023-12-28)](#v401-2023-12-28)\n    * [v4.0.0 (2023-12-27)](#v400-2023-12-27)\n    * [v3.5.0 (2023-05-25)](#v350-2023-05-25)\n    * [v3.4.0 (2023-05-12)](#v340-2023-05-12)\n    * [v3.3.0 (2022-08-03)](#v330-2022-08-03)\n    * [v3.2.0 (2022-07-28)](#v320-2022-07-28)\n    * [v3.1.0 (2022-07-13)](#v310-2022-07-13)\n    * [v3.0.0 (2022-05-30)](#v300-2022-05-30)\n    * [v2.0.0 (2021-08-14)](#v200-2021-08-14)\n    * [v1.9 (2021-07-29)](#v19-2021-07-29)\n    * [v1.8 (2021-07-28)](#v18-2021-07-28)\n    * [v1.7 (2021-06-02)](#v17-2021-06-02)\n    * [v1.6 (2021-05-26)](#v16-2021-05-26)\n    * [v1.5 (2021-05-07)](#v15-2021-05-07)\n    * [v1.4 (2021-05-05)](#v14-2021-05-05)\n    * [v1.3 (2021-05-03)](#v13-2021-05-03)\n    * [v1.2 (2021-04-29)](#v12-2021-04-29)\n    * [v1.1 (2021-04-24)](#v11-2021-04-24)\n    * [v1.0 (2021-01-15)](#v10-2021-01-15)\n\n## Version history\n\n### v5.0.0 (2024-12-19)\n\n* A major new release with many new features, improvements, bug fixes, and performance optimizations! Please note that code written using previous releases may need to be modified to work with the new release. The changes needed to migrate to the new API are explicitly indicated below for your convenience.\n* **Highlights:**\n    * Added support for C++20 and C++23, while maintaining full C++17 compatibility. In C++20, the library can now optionally be imported as a module using `import BS.thread_pool` on Clang, GCC, and MSVC. In C++23, both the library itself and the test program can now optionally import the C++ Standard Library as a module using `import std` on supported compilers and platforms. Extensive documentation has been added to `README.md` on how to use these features, to ease the transition.\n    * Optional features are now enabled via a bitmask template parameter instead of macros, using the flags `BS::tp::priority`, `BS::tp::pause`, and `BS::tp::wait_deadlock_checks`. This makes the optional features easier to use, allows multiple thread pools with different features to coexist, and makes the library compatible with C++20 modules. Exception handling is now disabled automatically if exceptions are disabled, instead of using a macro.\n    * Added optional native extensions for non-portable features using the operating system's native API: setting the priority and affinity for processes and threads, and setting thread names. These have been tested on the latest versions of Windows, Ubuntu, and macOS.\n    * This library is now back to being a true single-header library, with a single header file `BS_thread_pool.hpp`. The utility classes have been combined into the main header file. `BS::timer` has been removed, `BS::signaller` has been replaced with `BS::binary_semaphore` and `BS::counting_semaphore` (in C++17 mode only), and `BS::synced_stream` now supports multiple output streams.\n    * Cleanup functions can now be defined to complement the initialization functions. Both initialization and cleanup functions can now optionally take the index of the thread as an argument.\n    * Parallelization member functions no longer need type casting or template parameters if the start and end indices are of different types.\n    * The worker function no longer incorrectly reads shared variables while the mutex is unlocked.\n    * The type aliases `BS::this_thread::optional_index` and `BS::this_thread::optional_pool` have been removed. Instead, `BS::this_thread::get_index()` returns `std::optional<std::size_t>`, and `BS::this_thread::get_pool()` returns `std::optional<void*>`. The latter must be cast to the correct instantiation of the `BS::thread_pool` class template before using any member functions.\n    * The thread pool version is now accessible using the object `BS::thread_pool_version`, a `constexpr struct` of type `BS::version` with the members `major`, `minor`, and `patch`. This works even if importing the library as a C++20 module, unlike the version macros.\n    * The type `priority_t`, used to set priorities, is now defined as `std::int8_t`, which means it takes values from -128 to +127. The pre-defined priorities in `BS::pr`, such as `BS::pr::highest` or `BS::pr::lowest`, have been updated accordingly.\n    * Exceptions thrown by detached tasks are now caught and prevented from propagating, so that they do not terminate the program. Exceptions thrown by submitted tasks are still rethrown when calling `get()` on the future, as before.\n    * Parallelization member functions no longer destruct objects prematurely under certain circumstances.\n    * The test program has been expanded with many new tests for both old and new features. It can also import both the thread pool module using `import BS.thread_pool` (in C++20 and later) and the C++ Standard Library module using `import std` (in C++23) if the appropriate macros are defined, and read default command line arguments from a `default_args.txt` file for debugging purposes.\n    * Added new and improved benchmarks using a highly-optimized multithreaded algorithm which generates a plot of the Mandelbrot set, utilizing a normalized iteration count algorithm and linear interpolation to create smooth coloring.\n    * The type `BS::concurrency_t` has been removed; use `std::size_t` instead.\n* **C++20 and C++23 support:**\n    * This library now officially supports C++20 and C++23 in addition to C++17. If compiled with C++20 and/or C++23 support (e.g. using the compiler flag `-std=c++23` in Clang/GCC or `/std:c++latest` on MSVC), the library will make use of newly available features for maximum performance, reliability, and usability.\n        * To be clear, the library is still fully compatible with any C++17 standard-compliant compiler. I have no plans to remove C++17 support at the moment, as it is still [the most widely used C++ standard](https://www.jetbrains.com/lp/devecosystem-2023/cpp/) among developers, but that might change in the future.\n    * If C++20 features are available, the library can be imported as a module using `import BS.thread_pool`. This is now the officially recommended way to use the library, as it has many benefits, such as faster compilation times, better encapsulation, no namespace pollution, no include order issues, easier maintainability, simpler dependency management, and more.\n        * The module file itself is `BS.thread_pool.cppm`, located in the `modules` folder, and it is just a thin wrapper around the header file `BS_thread_pool.hpp`.\n        * The `constexpr` flag `BS::thread_pool_module` indicates whether the thread pool library was compiled as a module.\n        * To my knowledge, `BS::thread_pool` is one of the only popular C++ libraries that are [currently available as a C++20 module](https://arewemodulesyet.org/) (and certainly the only thread pool library). This feature has been tested with the latest versions of Clang, GCC, and MSVC. Unfortunately, C++20 modules are still (4 years later!) not fully implemented in all compilers, and each compiler implements them differently; for instructions on how to compile and import the `BS.thread_pool` module in each compiler, please see `README.md`.\n        * Known issues:\n            * GCC v14.2.0 (latest version at the time of writing) appears to have an internal compiler error when compiling programs containing modules (or at least, this particular module) with any optimization flags other than `-Og` enabled. Until this is fixed, if you wish to use compiler optimizations, please either include the library as a header file or use a different compiler.\n            * On macOS, Apple Clang v16.0.0 (latest version at the time of writing) does not support C++20 modules. Please either install the latest version of LLVM Clang using [Homebrew](https://formulae.brew.sh/formula/llvm), or include the library as a header file.\n            * Visual Studio Code's C/C++ extension v1.23.2 (latest version at the time of writing) does not yet support modules. My temporary solution for that, as demonstrated in the test program, is to define the macro `BS_THREAD_POOL_TEST_IMPORT_MODULE` (see below) when compiling the test program, but not when editing in the IDE. If the macro is enabled, the module is imported via `import BS.thread_pool`, otherwise the header file is included using `#include \"BS_thread_pool.hpp\"` as usual.\n    * If C++23 features are available, both the library and the test program can now import the C++ Standard Library as a module using `import std`. To enable this, define the macro `BS_THREAD_POOL_IMPORT_STD` at compilation time. This is currently only officially supported by recent versions of MSVC with Microsoft STL or LLVM Clang (**not** Apple Clang) with LLVM libc++. It is not supported by GCC with any standard library, Clang with any standard library other than libc++, any compiler with GNU libstdc++, or any other compiler.\n        * If `BS_THREAD_POOL_IMPORT_STD` is defined, then you must also import the library itself as a module. If the library is included as a header file, this will force the program that included the header file to also import `std`, which is not desirable and can lead to compilation errors if the program `#include`s any Standard Library header files.\n        * Defining the macro before importing the module will not work, as modules cannot access macros defined in the program that imported them. Instead, define the macro as a compiler flag, e.g. `-D BS_THREAD_POOL_IMPORT_STD` (or `/D` for MSVC).\n        * The `constexpr` flag `BS::thread_pool_import_std` indicates whether the thread pool library was compiled with `import std`. Note that the flag will be `false` if `BS_THREAD_POOL_IMPORT_STD` is defined but the compiler or standard library does not support importing the C++ Standard Library as a module.\n    * If C++20 features are available, the pool will use `std::jthread` instead of `std::thread`. This allows considerable simplification and added safety, since the threads no longer need to be manually joined, and `std::stop_token` is used to stop the workers automatically when destructing the threads. This eliminates the need for the `destroy_threads()` member function, as well as the `workers_running` flag, which are now only used in C++17 mode.\n    * If C++20 features are available, the library will use concepts to enforce the signature of the initialization function and to selectively enable member functions related to pausing only if pausing is enabled. In C++17 mode, the library will use SFINAE to achieve essentially the same effect.\n    * If C++23 features are available, the task queue will use `std::move_only_function<void()>` instead of `std::function<void()>`. This allows `submit_task()` to work without using a shared pointer, which should increase performance.\n    * **API migration:** All of the C++20/C++23 features listed above are either automatically applied based on compiler settings or optional. If you are still using C++17, or if you are using C++20 or C++23 but do not wish to import the thread pool library and/or the C++ Standard Library as a module, no changes are needed.\n* **Optional features overhaul:**\n    * All optional features are now enabled via a bitmask template parameter instead of macros. This works using `if constexpr`, `std::conditional_t`, and concepts (in C++20 and later) or SFINAE (in C++17).\n        * This change makes the optional features much easier and more intuitive to use, as you no longer need to define any macros before including the header file.\n        * Additionally, it allows you to have multiple thread pools in the same program with different optional features enabled or disabled. For example, you can have one pool with task priority enabled and another without.\n        * Most importantly, this makes it possible to import the library as a C++20 module, as macros cannot be read by imported modules.\n    * The bitmask flags are members of the `BS::tp` enumeration:\n        * `BS::tp::priority` enables task priority (previously enabled via the macro `BS_THREAD_POOL_ENABLE_PRIORITY`, which has been removed).\n        * `BS::tp::pause` enables pausing the pool (previously enabled via the macro `BS_THREAD_POOL_ENABLE_PAUSE`, which has been removed).\n        * `BS::tp::wait_deadlock_checks` enables deadlock checks in `wait()`/`wait_for()`/`wait_until()` (previously enabled via the macro `BS_THREAD_POOL_ENABLE_WAIT_DEADLOCK_CHECK`, which has been removed).\n        * The default is `BS::tp::none`, which disables all optional features.\n    * Convenience aliases are defined as follows:\n        * `BS::light_thread_pool` disables all optional features (equivalent to `BS::thread_pool` with the default template parameter, that is, `BS::thread_pool<BS::tp::none>`).\n        * `BS::priority_thread_pool` enables task priority (equivalent to `BS::thread_pool<BS::tp::priority>`).\n        * `BS::pause_thread_pool` enables pausing the pool (equivalent to `BS::thread_pool<BS::tp::pause>`).\n        * `BS::wdc_thread_pool` enables wait deadlock checks (equivalent to `BS::thread_pool<BS::tp::wait_deadlock_checks>`).\n        * There are no aliases with multiple features enabled; if this is desired, you must either pass the template parameter explicitly or define your own alias. Note that the parameter is a bitmask, so to enable multiple features, you need to use the bitwise OR operator `|`, e.g. `BS::thread_pool<BS::tp::priority | BS::tp::pause>` to enable both task priority and pausing.\n    * The macro `BS_THREAD_POOL_DISABLE_EXCEPTION_HANDLING` has been removed. Exception handling is disabled automatically if exceptions are disabled, based on whether the feature-test macro `__cpp_exceptions` is defined.\n    * The exception thrown by wait deadlock checks is now `BS::wait_deadlock` instead of `BS::thread_pool::wait_deadlock`, to avoid having to deal with different template parameters.\n    * The macro `BS_THREAD_POOL_LIGHT_TEST` has been removed from the test program, as all optional features are now tested by enabling them selectively via the template parameter, so there is no need to compile with different macros.\n    * If for some reason you forgot which options you enabled when creating the pool, the `static constexpr` members `priority_enabled`, `pause_enabled`, and `wait_deadlock_checks_enabled` can be used to check if the corresponding features are enabled.\n    * **API migration:**\n        * `BS::thread_pool` can still be used without the template parameter, for backwards compatibility; this will create a thread pool with all optional features disabled. Therefore, if you did not use any of the optional features in existing code, no changes are needed.\n        * If your code uses any of the optional features by defining macros before including the header file, please remove these macros, and instead either use one of the convenience aliases above or define the template parameter explicitly using the `BS::tp` enumeration when creating the pool.\n        * If you use wait deadlock checks, you must now catch the exception `BS::wait_deadlock` instead of `BS::thread_pool::wait_deadlock`.\n* **Native extensions:**\n    * While portability is one of my guiding principle when developing this library, non-portable features such as setting the thread priority using the operating system's native API are frequently requested by users. Starting with this release, the library includes native extensions, which are disabled by default.\n    * Currently, the extensions provide the following functions (please see `README.md` for details on how to use them):\n        * `BS::get_os_process_affinity()` and `BS::set_os_process_affinity()` to get and set the CPU affinity of the current process in a portable way. Should work on Windows and Linux, but not on macOS, as the native API does not allow it.\n        * `BS::get_os_process_priority()` and `BS::set_os_process_priority()` to get and set the priority of the current process in a portable way. Should work on Windows, Linux, and macOS.\n        * `BS::this_thread::get_os_thread_affinity()` and `BS::this_thread::set_os_thread_affinity()` to get and set the CPU affinity of the current thread in a portable way. Should work on Windows and Linux, but not on macOS, as the native API does not allow it.\n        * `BS::this_thread::get_os_thread_priority()` and `BS::this_thread::set_os_thread_priority()` to get and set the priority of the current thread in a portable way. Should work on Windows, Linux, and macOS.\n        * `BS::this_thread::get_os_thread_name()` and `BS::this_thread::set_os_thread_name()` to get and set the name of the current thread in a portable way, for debugging purposes. Should work on Windows, Linux, and macOS.\n    * The native extensions may be enabled by defining the macro `BS_THREAD_POOL_NATIVE_EXTENSIONS` at compilation time.\n        * Even if the macro is defined, the extensions are disabled automatically if a supported operating system (Windows, Linux, or macOS) is not detected.\n        * Note that if you are using the library as a C++20 module, defining the macro before importing the module will not work, as modules cannot access macros defined in the program that imported them. Instead, define the macro as a compiler flag, e.g. `-D BS_THREAD_POOL_NATIVE_EXTENSIONS` (or `/D` for MSVC).\n    * The macro `BS_THREAD_POOL_ENABLE_NATIVE_HANDLES` has been removed. The thread pool member function `get_native_handles()` is now part of the native extensions, so it is enabled using the macro `BS_THREAD_POOL_NATIVE_EXTENSIONS`.\n    * Please note that the native extensions have only been tested on Windows 11 23H2, Ubuntu 24.10, and macOS 15.1. They have not been tested on older versions of these operating systems, other Linux distributions, or any other operating systems, and are therefore not guaranteed to work on every system. If you encounter any issues, please report them on the GitHub repository.\n    * The test program only tests the native extensions if the macro `BS_THREAD_POOL_NATIVE_EXTENSIONS` is defined at compilation time. If importing the library as a module, please ensure that the macro is also enabled when compiling the module.\n    * The `constexpr` flag `BS::thread_pool_native_extensions` indicates whether the thread pool library was compiled with native extensions enabled. Note that the flag will be `false` if `BS_THREAD_POOL_NATIVE_EXTENSIONS` is defined but the operating system is unsupported.\n    * **API migration:** The native extensions are a brand new optional feature and do not require any changes to existing code.\n* **Utility classes:**\n    * This library is now back to being a true single-header library, with a single header file `BS_thread_pool.hpp`. The utility classes (previously in a separate header `BS_thread_pool_utils.hpp`, which has been removed) have been combined into the main header file.\n    * The `BS::timer` class has been removed from the library, since it doesn't really have anything to do with multithreading directly. However, it is still available in the test program if you want to use it.\n    * The `BS::signaller` class has been removed from the library, and replaced with `BS::binary_semaphore` and `BS::counting_semaphore`, which are C++17 polyfills for the C++20 classes `std::binary_semaphore` and `std::counting_semaphore`. If C++20 features are available, the polyfills are not used, and instead are just aliases for the standard library classes. The reason is that semaphores can do the same thing that the signaller class was previously used for, but are much more versatile.\n    * The `BS::synced_stream` class now supports printing to more than one output stream.\n    * **API migration:**\n        * If you previously included the `BS_thread_pool_utils.hpp` header file, this is no longer needed. Only include the header `BS_thread_pool.hpp`, or better yet, in C++20 or later, import the library as a module using `import BS.thread_pool`.\n        * If you previously used the `BS::timer` class, it is no longer available in the header file, but if you still need it you can copy it into your program directly from the test program `BS_thread_pool_test.cpp`.\n        * If you previously used the `BS::signaller` class, you can replace it with `BS::binary_semaphore` or `BS::counting_semaphore`. Previously, you defined an object `BS::signaller signal`, and then used `signal.wait()` to wait for the signal, and `signal.ready()` to unblock all waiting threads. Now, you can define an object `BS::counting_semaphore signal(0)`, and use `signal.acquire()` to wait for the signal, and `signal.release(num_threads)` to unblock waiting threads; note that the number of threads to release must be passed explicitly, as the semaphore also allows you to unblock only some of them. Use `BS::binary_semaphore` if only one thread will be waiting at any given time.\n        * If you previously used the `BS::synced_stream` class, no changes are needed.\n* **Cleanup and initialization functions:**\n    * Using the new `set_cleanup_func()` member function, it is now possible to provide the pool with a cleanup function to run in each thread right before it is destroyed, which will happen when the pool is destructed or reset. See [#152](https://github.com/bshoshany/thread-pool/issues/152).\n    * Both initialization and cleanup functions can now optionally take the index of the thread as an argument.\n    * Added a warning in the documentation that both initialization and cleanup functions must not throw any exceptions, as that will result in program termination. Any exceptions must be handled explicitly within the function.\n    * **API migration:** No changes to existing code are needed.\n* **Parallelization index types:**\n    * All member functions which parallelize collections of tasks, namely `detach_blocks()`, `detach_loop()`, `detach_sequence()`, `submit_blocks()`, `submit_loop()`, and `submit_sequence()`, can now be called with start and end indices of different types.\n    * Previously, the indices had to be of the same type, or the template parameter had to be explicitly specified; this is no longer needed, as the library will automatically cast the indices to a suitable common type.\n    * This was already possible in v2.X.X and v3.X.X, where it was done using [`std::common_type`](https://en.cppreference.com/w/cpp/types/common_type), but I removed it in v4.X.X because `std::common_type` sometimes completely messed up the range of the loop. For example, the `std::common_type` of `int` and `unsigned int` is `unsigned int`, which means the loop will only use non-negative indices even if the `int` start index was negative, resulting in an integer overflow.\n    * Starting with v5.0.0, the library uses a custom type trait `BS::common_index_type` to determine the common type of the indices. The common type of two signed integers or two unsigned integers is the larger of the integers, while the common type of a signed and an unsigned integer is a signed integer that can hold the full ranges of both integers. This avoids messing up the indices, except in the case of `std::uint64_t`, where there is no fundamental signed type that can hold its entire range. In this case, we choose `std::uint64_t` as the common type, since the most common use case is where the indices go from 0 to `x` where `x` has been previously defined as `std::size_t`. This will fail if the first index is negative; in that case, the user must cast the indices explicitly.\n    * **API migration:** Existing code which uses type casting or explicit template parameters in parallelization functions does not need to be changed, but it can be simplified by removing the casting or template parameters. However, if one index is negative and the other is an unsigned 64-bit integer, casting is still needed (although you should probably not be doing this in the first place, as casting to either of the two types will result in potential narrowing or overflow).\n* **`BS::this_thread`:**\n    * `BS::this_thread` is now a class instead of a namespace, since defining it as a namespace proved to be incompatible with C++20 modules (at least in some compilers). Defining it as a class also results in a simpler implementation. However, the functionality remains the same, and since it only has static methods, the call syntax for `BS::this_thread::get_index()` and `BS::this_thread::get_pool()` is unchanged.\n    * The type aliases `BS::this_thread::optional_index` and `BS::this_thread::optional_pool` have been removed. Instead, `BS::this_thread::get_index()` now returns the explicit type `std::optional<std::size_t>`, and `BS::this_thread::get_pool()` returns `std::optional<void*>`.\n        * The rationale for this removal is that using `std::optional` explicitly provides more information about the type that is being returned, and most users are probably not using the explicit types anyway (either by using `auto` or by invoking the `std::optional` member functions directly on the returned object).\n    * Note that `BS::this_thread::get_pool()` now returns an optional `void*` instead of `BS::thread_pool*`. The reason for that is that `BS::thread_pool` is now a template. Once you obtain the pool pointer, you must cast it to the desired instantiation of the template if you want to use any member functions. Note that you have to cast it to the correct type; if you cast a pointer to a `BS::light_thread_pool` into a pointer to a `BS::priority_thread_pool`, for example, your program will have undefined behavior.\n    * **API migration:**\n        * If your code uses the type aliases, please replace `BS::this_thread::optional_index` with `std::optional<std::size_t>` and `BS::this_thread::optional_pool` with `std::optional<void*>`.\n        * If your code uses `BS::this_thread::get_pool()`, you must now cast the returned pointer to the correct instantiation of the `BS::thread_pool` class template before using any member functions.\n* **Determining the library version:**\n    * The library now defines the `constexpr` object `BS::thread_pool_version`, which can be used to check the version of the library at compilation time. This object is of type `BS::version`, with members `major`, `minor`, and `patch`, and all comparison operators defined as `constexpr`. It also has a `to_string()` member function and an `operator<<` overload for easy printing at runtime. For example, you can do `static_assert(BS::thread_pool_version == BS::version(5, 0, 0))`, or you can use it in `if constexpr` for conditional compilation.\n    * The version macros `BS_THREAD_POOL_VERSION_MAJOR`, `BS_THREAD_POOL_VERSION_MINOR`, and `BS_THREAD_POOL_VERSION_PATCH` are still defined, since they can be used in conditional code inclusion, and for backwards compatibility. However, since C++20 modules cannot export macros, `BS::thread_pool_version` is the only way to check the version of the thread pool library if you are importing it as a module.\n    * **API migration:** No changes needed in existing code; if you previously used the macros `BS_THREAD_POOL_VERSION_MAJOR`, `BS_THREAD_POOL_VERSION_MINOR`, and `BS_THREAD_POOL_VERSION_PATCH` to determine the version of the library when including it as a header file, you can still do so. However, if you wish to import the library as a C++20 module, you must use the object `BS::thread_pool_version` instead.\n* **Task priority:**\n    * The type `priority_t`, used to set priorities, is now defined as `std::int8_t`, which means it takes values from -128 to +127. The pre-defined priorities in `BS::pr`, such as `BS::pr::highest` or `BS::pr::lowest`, have been updated accordingly (also, it is now an `enum` instead of a namespace). The old priority type `std::int16_t` was unnecessarily large; having fewer priority values means less bookkeeping in the priority queue, which should also improve performance.\n    * **API migration:** If you used the pre-defined priorities in `BS::pr`, no changes are needed. If you specified numerical priorities directly, you may need to adjust them to the new range of -128 to +127.\n* **Miscellaneous:**\n    * Exceptions thrown by detached tasks are now caught and prevented from propagating, so that they do not terminate the program. Exceptions thrown by submitted tasks are still rethrown when calling `get()` on the future, as before.\n    * All member functions which parallelize collections of tasks, namely `detach_blocks()`, `detach_loop()`, `detach_sequence()`, `submit_blocks()`, `submit_loop()`, and `submit_sequence()`, now store the callable object inside an `std::shared_ptr`, and then pass that shared pointer to each subtask. Previously, the callable was passed using perfect forwarding, which under some circumstances resulted in mistakenly moving the callable during the first iteration of the loop, thus potentially destructing captured objects prematurely. The new shared pointer method resolves this issue, while also avoiding making copies of the callable. See [#149](https://github.com/bshoshany/thread-pool/issues/149).\n    * Fixed incorrect reading of shared variables while the mutex is unlocked in the worker function. See [#159](https://github.com/bshoshany/thread-pool/issues/159).\n    * Added documentation to `README.md` for all the new features. In addition, fixed some typos and other minor issues in the existing documentation.\n    * Added instructions in `README.md` for installing the library using CMake with `FetchContent` instead of CPM. See [#155](https://github.com/bshoshany/thread-pool/pull/155).\n    * The type `BS::concurrency_t` has been removed. In previous versions this type was defined to be the type of the value returned by `std::thread::hardware_concurrency()` (which is supposed to be `unsigned int`), for maximum portability. However, in practice this value is only used to indicate the size of arrays, so `std::size_t` is more appropriate, and this simplifies the code.\n    * **API migration:** If you used `BS::concurrency_t` in your code, please replace it with `std::size_t`. If you previously cast to/from these two types, you can now remove the cast.\n* **Tests:**\n    * The test program `BS_thread_pool_test.cpp` will import the library as a C++20 module via `import BS.thread_pool` if the macro `BS_THREAD_POOL_TEST_IMPORT_MODULE` is defined, C++20 or later is detected, and a supported compiler is used.\n    * The test program will also import the C++ Standard Library as a module using `import std` if the macro `BS_THREAD_POOL_IMPORT_STD` is defined during compilation, on supported compilers and platforms.\n    * The new test `check_copy()` checks that the callable object does not get copied when parallelized into multiple tasks. It will succeed on previous versions of the library, but not if perfect forwarding is removed.\n    * The new test `check_shared_ptr()` checks that captured shared pointers do not prematurely destruct. It will fail on previous versions.\n    * The new test `check_task_destruct()` checks that a task is destructed immediately after it executes, and therefore does not artificially extend the lifetime of any captured objects.\n    * The new test `check_common_index_type()` checks that the type trait `BS::common_index_type` (see above) works as expected.\n    * The new tests `check_os_process_priorities()`, `check_os_thread_priorities()`, `check_os_process_affinity()`, `check_os_thread_affinity()`, and `check_os_thread_names()` check the corresponding features of the native extensions.\n    * The new test `check_callables()` checks that different callable types are accepted by the thread pool.\n    * New command line argument: `stdout`, to print to the standard output, enabled by default.\n    * If the file `default_args.txt` exists in the same folder, the test program reads the default arguments from it (space separated in a single line). Command line arguments can still override these defaults. This is useful when debugging.\n    * The test program will now detect and log the OS, compiler, standard library, C++ standard, available C++ features, whether the thread pool was imported as a C++20 module, and whether the standard library was imported as a module.\n* **Benchmarks:**\n    * Added new and improved benchmarks using a highly-optimized multithreaded algorithm which generates a plot of the Mandelbrot set, utilizing a normalized iteration count algorithm and linear interpolation to create smooth coloring.\n    * These benchmarks are heavily CPU-intensive, and much less limited by memory and cache compared to the benchmarks in previous versions (which used vector or matrix operations). This results in a much higher speedup factor due to multithreading, utilizing every core and thread to their fullest extent. This makes these benchmarks more useful for optimizing the library, since they are more sensitive to the thread pool's own performance.\n    * The full benchmarks are enabled using the command line argument `benchmarks`, which is enabled by default. The command line argument `plot` can be used to just plot the Mandelbrot set once, either instead of or in addition to doing the full benchmarks. This will plot the largest possible image that can be plotted in 5 seconds, and only measure the performance in pixels/ms for the entire plot.\n    * If you want to see the actual plot, pass the `save` command line argument. The plot is saved to a BMP file, since I didn't want to depend on any 3rd-party libraries. This is off by default, since that file can get quite large.\n* **Development:**\n    * A Python script `compile_cpp.py` has been added to the repository, in the `scripts` folder. It can be used to compile any C++ source file with different compilers on different platforms. The compilation parameters can be configured using command line arguments and/or via an optional YAML configuration file `compile_cpp.yaml` which specifies defined macros, extra compiler flags (per compiler), include folders, modules, and the output folder.\n    * I wrote this script to make it easier for me to test the library with different combinations of compilers, standards, and platforms using the built-in Visual Studio Code tasks. I also included three `.vscode` folders (one for each OS) in the repository, with appropriate `c_cpp_properties.json`, `launch.json`, and `tasks.json` files that utilize this script, in case you want to use it in your own projects. However, note that this script is not meant to replace CMake or any full-fledged build system, it's just a convenient script for developing single-header libraries like this one or other small projects.\n    * The `compile_cpp.py` script also transparently handles C++20 modules and importing the C++ Standard Library as a module in C++23. Therefore, users of this library who wish to import it as a C+20 module may find this script particularly useful.\n    * Another Python script `test_all.py` in the `scripts` folder replaces the old PowerShell test script. Tests are now performed in C++17, C++20, and C++23 modes, using all compilers available in the system (Clang, GCC, and/or MSVC). Since there are so many tests, the test script now no longer performs the benchmarks, as that would take too long.\n    * A final Python script `clear_folder.py` in the `scripts` folder is used to clean up output and temporary folders, and integrates with VS Code tasks.\n\n### v4.1.0 (2024-03-22)\n\n* This library is now published in [SoftwareX](https://www.sciencedirect.com/journal/softwarex)! If you use it in published research, please cite it as follows: Barak Shoshany, *\"A C++17 Thread Pool for High-Performance Scientific Computing\"*, [doi:10.1016/j.softx.2024.101687](https://doi.org/10.1016/j.softx.2024.101687), [SoftwareX 26 (2024) 101687](https://www.sciencedirect.com/science/article/pii/S235271102400058X), [arXiv:2105.00613](https://arxiv.org/abs/2105.00613)\n    * Updated the source files, as well as `README.md`, `CITATION.bib`, and `CITATION.cff` with the new citation.\n* A new macro, `BS_THREAD_POOL_DISABLE_EXCEPTION_HANDLING`, allows the user to disable exception handling in `submit_task()` if it is not needed, or if exceptions are explicitly disabled in the codebase. See [#139](https://github.com/bshoshany/thread-pool/issues/139).\n    * Note that this macro can be defined independently of `BS_THREAD_POOL_ENABLE_WAIT_DEADLOCK_CHECK`. Disabling exception handling removes the `try`-`catch` block from `submit_task()`, while enabling wait deadlock checks adds a `throw` expression to `wait()`, `wait_for()`, and `wait_until()`.\n    * If the feature-test macro `__cpp_exceptions` is undefined, `BS_THREAD_POOL_DISABLE_EXCEPTION_HANDLING` is automatically defined, and `BS_THREAD_POOL_ENABLE_WAIT_DEADLOCK_CHECK` is automatically undefined.\n* Replaced `#pragma once` with old-school include guards using the macros `BS_THREAD_POOL_HPP` and `BS_THREAD_POOL_UTILS_HPP`. There are two main reasons for this:\n    1. Even though `#pragma once` is supported by the vast majority of modern compilers, it is still a non-standard feature, so using it technically made the library not standards compliant.\n    2. Include guards make it possible to include the library twice in the same project (for example, once with priority enabled and once without) by undefining the include guard and putting the second include in its own namespace.\n* Included a description of the destructor behavior for the `BS::thread_pool` class in `README.md`, in the library reference section. See [#143](https://github.com/bshoshany/thread-pool/issues/143).\n* Removed unnecessary locking in `reset()` if pausing is not enabled.\n\n### v4.0.1 (2023-12-28)\n\n* Fixed linkage issue caused by the global variables `BS::this_thread::get_index` and `BS::this_thread::get_pool` not being defined as `inline`. See [#134](https://github.com/bshoshany/thread-pool/issues/134) and [137](https://github.com/bshoshany/thread-pool/issues/137).\n* Fixed redundant cast in the `BS::thread_pool::blocks` class, and added `-Wuseless-cast` to the GCC warning flags in `BS_thread_pool_test.ps1` to catch similar issues in the future. See [#133](https://github.com/bshoshany/thread-pool/pull/133).\n* Each of the three files `BS_thread_pool_test.cpp`, `BS_thread_pool.hpp`, and `BS_thread_pool_utils.hpp` now contains three macros indicating the major, minor, and patch version of the file. In addition, `BS_thread_pool_test.cpp` now checks whether the versions of all three files match, and aborts compilation if they do not.\n\n### v4.0.0 (2023-12-27)\n\n* A major new release with numerous changes, additions, fixes, and improvements. Many frequently requested features have been added, and performance has been optimized. Please note that code written using previous releases will need to be modified to work with the new release. The changes needed to migrate to the new API are explicitly indicated below for your convenience.\n* Highlights:\n    * The light thread pool has been removed. However, by default, the thread pool is in \"light mode\". Optional features that may affect performance must be enabled by defining suitable macros.\n    * This library now ships with two stand-alone header files:\n        * `BS_thread_pool.hpp` contains the main `BS::thread_pool` class and the `BS::multi_future` helper classes, and is the only file needed to use the thread pool itself.\n        * `BS_thread_pool_utils.hpp` contains the additional utility classes `BS::signaller`, `BS::synced_stream`, and `BS::timer`, which are fully independent of the thread pool itself and can be used either with or without it.\n    * It is now possible to assign priorities to tasks. Tasks with higher priorities will be executed first.\n    * Member functions for submitting tasks and loops have been renamed for consistency, e.g. `detach_task()` and `submit_task()`, where the prefix `detach` means no future will be returned and `submit` means a future or `BS::multi_future` will be returned.\n    * There are now two ways to parallelize loops into blocks:\n        * `detach_blocks()` and `submit_blocks()` behave the same as loop parallelization in previous releases, running the loop function once per block.\n        * `detach_loop()` and `submit_loop()` have a simpler syntax, where the loop function is run once per index, so the user doesn't have to manually run the internal loop for each block.\n    * The new member functions `detach_sequence()` and `submit_sequence()` allow submitting a sequence of tasks enumerated by indices.\n    * It is now possible to run an initialization function in each thread before it starts to execute any submitted tasks.\n    * Tasks submitted with `detach_task()` or `submit_task()` can no longer have arguments. Task with arguments must be enclosed inside lambda expressions. This simplifies the API and provides better readability. Tasks can still have return values.\n    * Various ways to obtain information about the threads in the pool have been introduced:\n        * The member function `get_thread_ids()` obtains the unique thread identifiers, and `get_native_handles()` obtains the underlying implementation-defined thread handles.\n        * The new namespace `BS::this_thread` allows obtaining the thread's index in the pool using `BS::this_thread::get_index()` and a pointer to the pool that owns the thread using `BS::this_thread::get_pool()`.\n    * Member functions for waiting for tasks have been renamed for brevity: `wait()`/`wait_for()`/`wait_until()`. In addition, these functions can now optionally throw an exception if the user tries to call them from within a thread of the same pool, which would result in a deadlock.\n    * The first index must now be specified explicitly when parallelizing blocks, loops, and sequences, and it must not be greater than the last index. Also, both indices must now have the same type, or the template parameter should be explicitly specified.\n    * Optimized the way `detach_blocks()`, `submit_blocks()`, `detach_loop()`, and `submit_loop()` split the range of the loop into blocks.\n    * Added a utility class `BS::signaller` to allow simple signalling between threads.\n    * `BS::multi_future<T>` is now a specialization of `std::vector<std::future<T>>` with additional member functions.\n* Breaking changes:\n    * The light thread pool has been removed. The original idea was that the light thread pool will allow the user to sacrifice functionality for increased performance. However, in my testing I found that there was no actual performance benefit to the light thread pool. Therefore, there is no reason to keep it.\n        * However, by default, the thread pool is in \"light mode\". Optional features that may affect performance due to additional checks or more complicated algorithms must be enabled by defining suitable macros before including the library:\n            * `BS_THREAD_POOL_ENABLE_PAUSE` to enable pausing.\n            * `BS_THREAD_POOL_ENABLE_PRIORITY` to enable task priority.\n            * `BS_THREAD_POOL_ENABLE_WAIT_DEADLOCK_CHECK` to enable wait deadlock checks.\n        * **API migration:**\n            * If you previously used `BS_thread_pool_light.hpp`, simply use `BS_thread_pool.hpp` instead.\n            * If you previously used the pausing feature, define the macro `BS_THREAD_POOL_ENABLE_PAUSE` before including `BS_thread_pool.hpp` to enable it.\n    * Member functions have been renamed for better consistency. Each function has a `detach` variant which does not return a future, and a `submit` variant which does return a future (or a `BS::multi_future`):\n        * `detach_task()` and `submit_task()` for single tasks.\n        * `detach_blocks()` and `submit_blocks()` for loops to be split into blocks, where the loop function is executed once per block and must have an internal loop, as in previous releases.\n        * `detach_loop()` and `submit_loop()` for loops to be split into blocks, where the loop function is executed once per index and the pool takes care of the internal loop.\n        * `detach_sequence()` and `submit_sequence()` for sequences of enumerated tasks.\n        * **API migration:** Use the new names of the functions:\n            * `push_task()` -> `detach_task()`\n            * `submit()` -> `submit_task()`\n            * `push_loop()` -> `detach_blocks()`\n            * `parallelize_loop()` -> `submit_blocks()`\n    * `wait_for_tasks()`, `wait_for_tasks_duration()`, and `wait_for_tasks_until()` have been renamed to `wait()`, `wait_for()`, and `wait_until()` respectively.\n        * **API migration:** Use the new names of the functions:\n            * `wait_for_tasks()` -> `wait()`\n            * `wait_for_tasks_duration()` -> `wait_for()`\n            * `wait_for_tasks_until()` -> `wait_until()`\n    * Functions for parallelizing loops no longer have dedicated overloads for the special case where the first index is 0. These overloads essentially amount to giving the first function argument a default value, which is not allowed in C++, and can be confusing. In addition, indicating the first index explicitly is better for readability.\n        * **API migration:** Add the first index 0 manually as the first argument if it was omitted.\n    * Functions for parallelizing loops no longer allow the last index to be smaller than the first index. Previously, e.g. `detach_blocks(5, 0, ...)` was equivalent to `detach_blocks(0, 5, ...)`. However, this led to confusing results. Since the first argument is the first index and the second argument is the index *after* the last index (i.e. 0 to 5 actually means 0, 1, 2, 3, 4), the user might get the wrong impression that `detach_blocks(5, 0, ...)` will count 5, 4, 3, 2, 1 instead. This option was removed to avoid this confusion.\n        * Sometimes the user might actually want to make a loop that counts down instead of up. This cannot be done by flipping the order of the arguments to e.g. `detach_blocks()` (nor could it be done in previous releases). However, it can be done by simply defining a suitable loop function. For example, if you call `detach_blocks(0, 10, loop, 2)` and define the loop function as `for (T i = 9 - start; i > 9 - end; --i)`, then the first block will count 9, 8, 7, 6, 5 and the second block will count 4, 3, 2, 1, 0.\n        * `detach_loop()`, `submit_loop()`, `detach_sequence()`, and `submit_sequence()` work the same way. The first index must be smaller than the last index, but you can count down by writing a suitable loop or sequence function.\n        * **API migration:** Any loop parallelization that used a first index greater than the last index will work exactly the same after switching the first and second arguments so that the smaller index appears first.\n    * Functions for parallelizing loops no longer accept first and last indices of different types. The reason for allowing this previously was that otherwise, writing something like `detach_blocks(0, x, ...)` where `x` is not an `int` would result in a compilation error, since `0` is by default an `int` and therefore the arguments `0` and `x` have different types. However, this behavior, which used [`std::common_type`](https://en.cppreference.com/w/cpp/types/common_type) to determine the common type of the two indices, sometimes completely messed up the range of the loop. For example, the `std::common_type` of `int` and `unsigned int` is `unsigned int`, which means the loop will only use non-negative indices even if the `int` start index was negative, resulting in an integer overflow.\n        * **API migration:** If you want to invoke e.g. `detach_blocks(0, x, ...)` where `x` is not an `int`, you can either:\n            * Make the `0` have the desired type using a cast or a suffix. For example, if `x` is an `unsigned int`, write `(unsigned int)0` or `0U` instead of `0`.\n            * Specify the template parameter explicitly. For example, if `x` is a `size_t`, write `detach_blocks<size_t>(0, x, ...)`.\n    * `detach_task()` and `submit_task()` no longer accept arguments for the submitted task. Instead, you must enclose the function in a [lambda expression](https://en.cppreference.com/w/cpp/language/lambda). In other words, instead of `detach_task(task, args...)` you should write `detach_task([] { task(args...); })`, indicating in the capture list `[]` whether to capture the task itself, and each of the arguments, by value or reference. Please see `README.md` for examples. This was changed for the following reasons:\n        1. Consistency with `detach_blocks()` and `submit_blocks()`, as well as the new `detach_loop()`, `submit_loop()`, `detach_sequence()`, and `submit_sequence()`, which do not accept function arguments either.\n        2. In my own multithreaded projects, I find that I almost always need the task to have access to variables in the local scope. This is much simpler, easier, and more concise to do with a lambda capture list, especially an implicit capture `[=]` or `[&]`, than by defining a function that takes arguments and then passing these arguments.\n        3. Similarly, I find that I mostly submit tasks defined as a lambda on the spot, rather than creating them as separate functions, because it's faster to code and makes it clear exactly what the task does without having to look elsewhere.\n        4. When users post issues to this repository asking for help with their own code that uses the thread pool, the solution often turns out to be \"just wrap that in a lambda\". Such issues can be avoided if lambdas must be used to begin with.\n        5. Submitting member functions, which previously required the awkward syntax `detach_task(&class::function, &object, args...)`, can now be achieved with the much simpler and more readable syntax `detach_task([] { object.function(args...); })` with the appropriate captures.\n        6. Passing arguments by reference, which previously required using [`std::ref`](https://en.cppreference.com/w/cpp/utility/functional/ref), e.g. `detach_task(task, std::ref(arg))`, can now be achieved with the much simpler and more readable syntax `detach_task([&arg] { task(arg); })`.\n        7. The new syntax allows specifying the priority of the task easily, as the second argument - otherwise, it would have been hard to distinguish the priority from a task argument, making the API more complicated and confusing. This syntax will also permit adding additional arguments to the member functions as needed in the future.\n        * **API migration:** Enclose all tasks with arguments inside a lambda expression. All submitted tasks must have no arguments, but they can still have return values.\n            * Alternatively, [`std::bind`](https://en.cppreference.com/w/cpp/utility/functional/bind) can also be used, if the old syntax is preferred to a lambda. Just wrap it around the task and its arguments: instead of `detach_task(task, args...)`, write `detach_task(std::bind(task, args...))`. This achieves the same effect, and can be used to easily convert v3.x.x code to v4.0.0 using a simple regular expression search and replace:\n                * `push_task\\((.*?)\\)` -> `detach_task(std::bind($1))`\n                * `submit\\((.*?)\\)` -> `submit_task(std::bind($1))`\n    * `BS::synced_stream` and `BS::timer` have been moved to `BS_thread_pool_utils.hpp`.\n        * **API migration:** Include the new header file if either of these utility classes are used.\n* `BS_thread_pool.hpp` new features:\n    * A new optional feature, enabled by defining the macro `BS_THREAD_POOL_ENABLE_PRIORITY`, allows assigning priority to tasks. The priority is a number of type `BS::priority_t`, which is a signed 16-bit integer, so it can have any value between -32,768 and 32,767. The tasks will be executed in priority order from highest to lowest.\n        * To assign a priority to a task, add the priority as the last argument to any of the `detach` or `submit` functions. If the priority is not specified, the default value will be 0.\n        * The namespace `BS::pr` contains some pre-defined priorities for users who wish to avoid magic numbers and enjoy better future-proofing. In order of decreasing priority, the pre-defined priorities are: `BS::pr::highest`, `BS::pr::high`, `BS::pr::normal`, `BS::pr::low`, and `BS::pr::lowest`.\n        * Please see `README.md` for more information, including performance considerations.\n    * The new member functions `detach_loop()` and `submit_loop()` facilitate loop parallelization without having to worry about internal loops in the loop function. In previous releases, the loop function had to be of the form `[](T start, T end) { for (T i = start; i < end; ++i) loop(i); }`. This behavior has been preserved in `detach_blocks()` and `submit_blocks()`. However, the new `detach_loop()` and `submit_loop()` allow much simpler loop functions of the form `[](T i) { loop(i) }`, greatly simplifying the interface.\n        * Performance-wise, due to fewer function calls, `detach_blocks()` and `submit_blocks()` are generally faster. However, the difference is usually not significant, and with compiler optimizations there may be no difference at all. In any case, `detach_loop()` and `submit_loop()` are provided as convenience functions, but performance-critical applications can stick with `detach_blocks()` and `submit_blocks()`.\n    * The new member functions `detach_sequence()` and `submit_sequence()` facilitate submitting a sequence of tasks enumerated by indices. This is a bit similar to `detach_loop()` and `submit_loop()`, except that the range of indices is not split into blocks with each block containing a smaller range of indices. Instead, there is exactly one task per index. This can be used, for example, to submit a sequence of tasks with each one independently processing a single array element. `detach_sequence()` does not return a future, while `submit_sequence()` returns a `BS::multi_future`.\n    * It is now possible to run an initialization function in each thread before it starts to execute any submitted tasks. The function must take no arguments and have no return value. It will only be executed exactly once, when the thread is first constructed. It can be passed as an argument to the constructor or to `reset()`. See [#104](https://github.com/bshoshany/thread-pool/issues/104), [#105](https://github.com/bshoshany/thread-pool/pull/105), [#113](https://github.com/bshoshany/thread-pool/issues/113), and [#119](https://github.com/bshoshany/thread-pool/issues/119).\n    * Added a member function `get_thread_ids()` which returns a vector containing the unique identifiers for each of the pool's threads, as obtained by [`std::thread::get_id()`](https://en.cppreference.com/w/cpp/thread/get_id). See [#126](https://github.com/bshoshany/thread-pool/issues/126).\n    * A new optional feature, enabled by defining the macro `BS_THREAD_POOL_ENABLE_NATIVE_HANDLES`, adds a member function `get_native_handles()` which returns a vector containing the underlying implementation-defined thread handles for each of the pool's threads. These can then be used in an implementation-specific way to manage the threads at the OS level; however, note that this will generally **not** be portable code. See [#122](https://github.com/bshoshany/thread-pool/issues/122).\n        * This feature is disabled by default since it uses [std::thread::native_handle()](https://en.cppreference.com/w/cpp/thread/thread/native_handle), which is in the C++ standard library, but is **not** guaranteed to be present on all systems.\n    * A new namespace `BS::this_thread` was created to provide functionality similar to `std::this_thread`.\n        * `BS::this_thread::get_index()` can be used to get the index of the current thread. If this thread belongs to a `BS::thread_pool` object, it will have an index from 0 to `BS::thread_pool::get_thread_count() - 1`. Otherwise, for example if this thread is the main thread or an independent [`std::thread`](https://en.cppreference.com/w/cpp/thread/thread), [`std::nullopt`](https://en.cppreference.com/w/cpp/utility/optional/nullopt) will be returned.\n        * `BS::this_thread::get_pool()` can be used to get the pointer to the thread pool that owns the current thread. If this thread belongs to a `BS::thread_pool` object, a pointer to that object will be returned. Otherwise, `std::nullopt` will be returned.\n        * Note that both functions return an [`std::optional`](https://en.cppreference.com/w/cpp/utility/optional) object.\n    * `BS::multi_future<T>` is now defined as a specialization of `std::vector<std::future<T>>`. This means that all of the member functions that can be used on an [`std::vector`](https://en.cppreference.com/w/cpp/container/vector) can also be used on a `BS::multi_future`. For example, it is now possible to use a range-based `for` loop with a `BS::multi_future` object, since it has iterators.\n        * In addition to inherited member functions, `BS::multi_future` has the following specialized member functions, most of which are new in this release: `get()`, `ready_count()`, `valid()`, `wait()`, `wait_for()`, and `wait_until()`. Please see `README.md` for more information. See also [#128](https://github.com/bshoshany/thread-pool/issues/128).\n    * A new optional feature, enabled by defining the macro `BS_THREAD_POOL_ENABLE_WAIT_DEADLOCK_CHECK`, allows `wait()`, `wait_for()`, and `wait_until()` to check whether the user tried to call them from within a thread of the same pool, which would result in a deadlock. If so, they will throw the exception `BS::thread_pool::wait_deadlock` instead of waiting.\n* `BS_thread_pool_utils.hpp`:\n    * The utility classes `BS::synced_stream` and `BS::timer` now reside in this header file instead of the main one.\n    * `BS::timer` has a new member function, `current_ms()`, which can be used to obtain the number of milliseconds that have elapsed so far, but keep the timer ticking.\n    * The new utility class `BS::signaller` allows simple signalling between threads. It can be used to make one or more threads wait, using the `wait()` member function. When another thread uses the `ready()` member function, all waiting threads stop waiting. This class is really just a convenient wrapper around [`std::promise`](https://en.cppreference.com/w/cpp/thread/promise), which contains both the promise and its future.\n* `BS_thread_pool.hpp` bug fixes and minor changes:\n    * Optimized locking in the worker function. This should result in increased performance.\n    * Optimized the way `detach_blocks()`, `submit_blocks()`, `detach_loop()`, and `submit_loop()` split the range of the loop into blocks. All blocks are now guaranteed to have one of two sizes, differing by 1, with the larger blocks always first. See [#96](https://github.com/bshoshany/thread-pool/issues/96).\n        * For example, in previous releases, 100 indices were split into 15 blocks as 14 blocks of size 6 and one additional block of size 16, which was suboptimal. Now they are split into 10 blocks of size 7 and 5 blocks of size 6, which means the tasks are as evenly distributed as possible.\n    * Fixed a bug that caused paused pools to have high idle CPU usage if pausing was used. See [#120](https://github.com/bshoshany/thread-pool/issues/120).\n    * The worker now destructs the task object as soon as it finishes executing. See [#124](https://github.com/bshoshany/thread-pool/issues/124) and [#129](https://github.com/bshoshany/thread-pool/pull/129).\n    * Added Markdown inline code formatting in all comments whenever applicable, which makes the comments look nicer when displayed as a tooltip in [Visual Studio Code](https://code.visualstudio.com/) or other supporting IDEs.\n    * The `BS::thread_pool::blocks` helper class has been moved into the main thread pool class, and now returns a degenerate object (zero blocks) if `index_after_last <= first_index`.\n* `BS_thread_pool_test.cpp`:\n    * Removed tests for the light thread pool.\n    * Added/modified tests for all new/changed features.\n    * Many of the previous tests have been simplified and optimized.\n    * The program now takes command line arguments:\n        * `help`: Show a help message and exit.\n        * `log`: Create a log file.\n        * `tests`: Perform standard tests.\n        * `deadlock` Perform long deadlock tests.\n        * `benchmarks`: Perform benchmarks.\n        * If no options are entered, the default is: `log tests benchmarks`.\n    * By default, the test program enables all the optional features by defining the suitable macros, so it can test them. However, if the macro `BS_THREAD_POOL_LIGHT_TEST` is defined during compilation, the optional features will not be tested.\n    * Instead of using a pre-defined list to specify the number of loop blocks to try in the benchmarks, the program now simply keeps increasing the number of blocks until it finds the optimal value. Often, the optimal number of blocks is much higher than the number of hardware threads, but if the number is too high it will result in diminishing returns.\n    * `check_loop_no_return()` now checks that the loop modifies all the indices exactly once, to detect cases where an index has been modified more than once, e.g. if the same loop index was erroneously placed in more than one block.\n    * Instead of defining `_CRT_SECURE_NO_WARNINGS`, the program now uses [`localtime_s`](https://learn.microsoft.com/en-us/cpp/c-runtime-library/reference/localtime-s-localtime32-s-localtime64-s) instead of [`std::localtime`](https://en.cppreference.com/w/cpp/chrono/c/localtime) if MSVC is detected to avoid generating a warning.\n    * On macOS, the test program will exit with [`std::terminate()`](https://en.cppreference.com/w/cpp/error/terminate) instead of [`std::quick_exit()`](https://en.cppreference.com/w/cpp/utility/program/quick_exit) if any tests failed. This is because macOS does not implement `std::quick_exit()` for some reason. Note that as a result, the number of failed tests cannot be returned by the program on macOS. Unfortunately, [`std::exit()`](https://en.cppreference.com/w/cpp/utility/program/exit) cannot be used here, as it might get stuck if a deadlock occurs. See [#106](https://github.com/bshoshany/thread-pool/pull/106)\n    * The log file now uses the name of the executable file, followed by the date and time, so it's easy to distinguish between log files generated by different builds of the test (since the test script names them based on the compiler used). Also, the program now checks if the log file failed to open for some reason, and writes only to the standard output in that case.\n    * The benchmarks now display a progress bar.\n    * The test program will now detect the OS and compiler used.\n* `BS_thread_pool_test.ps1`:\n    * The script will compile and run a light version of the test, with no optional features enabled, in addition to the main test, for each compiler.\n    * The source and build folders will now be determined relative to the script folder, to ensure that the script works no matter which folder it is executed from.\n    * The script now checks that the include files `BS_thread_pool.hpp` and `BS_thread_pool_utils.hpp` are present before attempting to compile the test program.\n* `README.md`:\n    * Added/modified documentation for all new/changed features.\n    * Revised many of the existing examples and explanations.\n    * Added a complete library reference at the end of the documentation.\n    * Added instructions for installing the package using Meson and CMake with CPM. The installation instructions with various package managers and build systems were moved to the end, before the reference.\n* Miscellaneous:\n    * A `.clang-tidy` file is now included, with all the checks that are enabled in this project. The pull request template has been updated to suggest that authors lint their code using this file before submitting the pull request.\n* This release is dedicated to my wife (since December 1, 2023), Pauline. Her endless love, support, and encouragement have been a great source of motivation for working on this and other projects. I am so lucky and honored to [`my_future.share()`](https://en.cppreference.com/w/cpp/thread/future/share) with her \n\n### v3.5.0 (2023-05-25)\n\n* `BS_thread_pool.hpp` and `BS_thread_pool_light.hpp`:\n    * Added a new member function, `purge()`, to the full (non-light) thread pool. This function purges all the tasks waiting in the queue. Tasks that are currently running will not be affected, but any tasks still waiting in the queue will be removed and will never be executed by the threads. Please note that there is no way to restore the purged tasks.\n    * Fixed a bug which caused `wait_for_tasks()` to only block the first thread that called it. Now it blocks every thread that calls it, which is the expected behavior. In addition, all related deadlock have now been completely resolved. This also applies to the variants `wait_for_tasks_duration()` and `wait_for_tasks_until()` in the non-light version. See [#110](https://github.com/bshoshany/thread-pool/pull/110).\n        * Note: You should never call `wait_for_tasks()` from within a thread of the same thread pool, as that will cause it to wait forever! This fix is relevant for situations when `wait_for_tasks()` is called from an auxiliary `std::thread` or a separate thread pool.\n    * `push_task()` and `submit()` now avoid creating unnecessary copies of the function object. This should improve performance, especially if large objects are involved. See [#90](https://github.com/bshoshany/thread-pool/pull/90).\n    * Optimized the way condition variables are used by the thread pool class. Shared variables are now modified while owning the mutex, but condition variables are notified after the mutex is released, if possible. See [#84](https://github.com/bshoshany/thread-pool/pull/84).\n    * Instead of a variable `tasks_total` to keep track of the total number of tasks (queued + running), the thread pool class now uses a variable `tasks_running` to keep track only of the number of running tasks, with the number of tasks in the queue obtained via `tasks.size()`. This makes more sense in terms of the internal logic of the class.\n    * All atomic variables have been converted to non-atomic. They are now all governed by `tasks_mutex`, so they do not need to be atomic. This eliminates redundant locking, and may improve performance a bit.\n    * `running` has been renamed to `workers_running` and `task_done_cv` has been renamed to `tasks_done_cv`.\n    * The worker now only notifies thi condition variable `tasks_done_cv` if all the tasks are done, not just a single task. Checking if the tasks are done is cheaper than notifying the condition variable, so since the worker no longer notifies the condition variable every single time it finishes a task, this should improve performance a bit if `wait_for_tasks()` is used.\n* `BS_thread_pool_test.cpp`:\n    * Combined the tests for the full and light versions into one program. The file `BS_thread_pool_light_test.cpp` has been removed.\n    * The tests for the light version are now much more comprehensive. The only features that are not tested in the light version are those that do not exist in it.\n    * Added a test for the new `purge()` member function.\n    * Added a test to ensure that `push_task()` and `submit()` do not create unnecessary copies of the function object.\n    * Added a test to ensure that `push_task()` and `submit()` correctly accept arguments passed by value, reference, and constant reference.\n    * Added a test to ensure that `wait_for_tasks()` blocks all external threads that call it.\n    * `_CRT_SECURE_NO_WARNINGS` is now set only if it has not already been defined, to prevent errors in MSVC projects which already have it set as part of the default build settings. See [#72](https://github.com/bshoshany/thread-pool/pull/72).\n* `README.md`:\n    * Added documentation for the new `purge()` member function.\n    * Added an explanation for how to pass arguments by reference or constant reference when submitting functions to the queue, using the wrappers `std::ref()` and `std::cref()` respectively. See [#83](https://github.com/bshoshany/thread-pool/issues/83).\n    * Added a link to [my lecture notes](https://baraksh.com/CSE701/notes.php) for a course taught at McMaster University, for the benefit of beginner C++ programmers who wish to learn some of the advanced techniques and programming practices used in developing this library.\n    * Removed the sample test results, since the complete log file (including the deadlock tests) is now over 500 lines long.\n* Other:\n    * A `.clang-format` file with the project's formatting conventions is now included in the GitHub repository. The pull request template now asks to format any new code using this file, so that it is consistent with the rest of the library.\n    * A PowerShell script, `BS_thread_pool_test.ps1`, is now provided in the GitHub repository to make running the test on multiple compilers and operating systems easier. Since it is written in PowerShell, it is fully portable and works on Windows, Linux, and macOS. The script will automatically detect if Clang, GCC, and/or MSVC are available, compile the test program using each available compiler, and then run each compiled test program 5 times and report on any errors. The pull request template now recommends using this script for testing.\n    * Since the root folder has become a bit crowded, the header files `BS_thread_pool.hpp` and `BS_thread_pool_light.hpp` have been moved to the `include` subfolder, and the test file `BS_thread_pool_test.cpp` has been moved to the `tests` subfolder, which also contains the new test script `BS_thread_pool_test.ps1`.\n\n### v3.4.0 (2023-05-12)\n\n* `BS_thread_pool.hpp` and `BS_thread_pool_light.hpp`:\n    * Resolved an issue which could have caused `tasks_total` to not be synchronized in some cases. See [#70](https://github.com/bshoshany/thread-pool/pull/70).\n    * Resolved a deadlock which could rarely be caused when the pool was destructed or reset. See [#93](https://github.com/bshoshany/thread-pool/pull/93), [#100](https://github.com/bshoshany/thread-pool/pull/100), [#107](https://github.com/bshoshany/thread-pool/pull/107), and [#108](https://github.com/bshoshany/thread-pool/pull/108).\n    * Resolved a deadlock which could be caused when `wait_for_tasks()` was called more than once.\n    * Two new member functions have been added to the non-light version: `wait_for_tasks_duration()` and `wait_for_tasks_until()`. They allow waiting for the tasks to complete, but with a timeout. `wait_for_tasks_duration()` will stop waiting after the specified duration has passed, and `wait_for_tasks_until()` will stop waiting after the specified time point has been reached.\n    * Renamed `BS_THREAD_POOL_VERSION` in `BS_thread_pool_light.hpp` to `BS_THREAD_POOL_LIGHT_VERSION` and removed the `[light]` tag. This allows including both header files in the same program in case we want to use both the light and non-light thread pools simultaneously.\n* `BS_thread_pool_test.cpp` and `BS_thread_pool_light_test.cpp`:\n    * Fixed an issue that caused a compilation error when using MSVC and including `windows.h`. See [#72](https://github.com/bshoshany/thread-pool/pull/72).\n    * The number and size of the vectors in the performance test (`BS_thread_pool_test.cpp` only) are now guaranteed to be multiples of the number of threads, for optimal performance.\n    * In `count_unique_threads()`, moved the condition variables and mutexes to the function scope to prevent cluttering the global scope.\n    * Three new tests have been added to `BS_thread_pool_test.cpp` to check the deadlocks issue that were resolved in this release (see above). The tests rely on the new wait for tasks with timeout feature, so they are not available in the light version.\n        * One test checks for deadlocks when calling `wait_for_tasks()` more than once.\n        * Two tests check for deadlocks when destructing and resetting the pool respectively. They are turned off by default, since they take a long time to complete, but can be turned on by setting `enable_long_deadlock_tests` to `true`.\n    * Two new tests have been added to the non-light version to check the new member functions `wait_for_tasks_duration()` and `wait_for_tasks_until()`.\n    * The test programs now return the number of failed tests upon exit, instead of just 1 if any number of tests failed, which was the case in previous versions. Also, if any tests failed, `std::quick_exit()` is invoked instead of `return`, to avoid getting stuck due to any lingering tasks or deadlocks.\n* `README.md`:\n    * Added documentation for the two new member functions, `wait_for_tasks_duration()` and `wait_for_tasks_until()`.\n    * Fixed Markdown rendering incorrectly on Visual Studio. See [#77](https://github.com/bshoshany/thread-pool/pull/77).\n    * The sample performance tests are now taken from a 40-core / 80-thread dual-CPU computing node, which is a more typical use case for high-performance scientific software.\n\n### v3.3.0 (2022-08-03)\n\n* `BS_thread_pool.hpp`:\n    * The public member variable `paused` of `BS::thread_pool` has been made private for future-proofing (in case future versions implement a more involved pausing mechanism) and better encapsulation. It is now accessible only via the `pause()`, `unpause()`, and `is_paused()` member functions. In other words:\n        * Replace `pool.paused = true` with `pool.pause()`.\n        * Replace `pool.paused = false` with `pool.unpause()`.\n        * Replace `if (pool.paused)` (or similar) with `if (pool.is_paused())`.\n    * The public member variable `f` of `BS::multi_future` has been renamed to `futures` for clarity, and has been made private for encapsulation and simplification purposes. Instead of operating on the vector `futures` itself, you can now use the `[]` operator of the `BS::multi_future` to access the future at a specific index directly, or the `push_back()` member function to append a new future to the list. The `size()` member function tells you how many futures are currently stored in the object.\n    * The explicit casts of `std::endl` and `std::flush`, added in v3.2.0 to enable flushing a `BS::synced_stream`, caused ODR (One Definition Rule) violations if `BS_thread_pool.hpp` was included in two different translation units, since they were mistakenly not defined as `inline`. To fix this, I decided to make them static members of `BS::synced_stream` instead of global variables, which also makes the code better organized in my opinion. These objects can now be accessed as `BS::synced_stream::endl` and `BS::synced_stream::flush`. I also added an example for how to use them in `README.md`. See [#64](https://github.com/bshoshany/thread-pool/issues/64).\n* `BS_thread_pool_light.hpp`:\n    * This package started out as a very lightweight thread pool, but over time has expanded to include many additional features, and at the time of writing it has a total of 340 lines of code, including all the helper classes. Therefore, I have decided to bundle a light version of the thread pool in a separate and stand-alone header file, `BS_thread_pool_light.hpp`, with only 170 lines of code (half the size of the full package). This file does not contain any of the helper classes, only a new `BS::thread_pool_light` class, which is a minimal thread pool with only the 5 most basic member functions:\n        * `get_thread_count()`\n        * `push_loop()`\n        * `push_task()`\n        * `submit()`\n        * `wait_for_tasks()`\n    * A separate test program `BS_thread_pool_light_test.cpp` tests only the features of the lightweight `BS::thread_pool_light` class. In the spirit of minimalism, it does not generate a log file and does not do any benchmarks.\n    * To be perfectly clear, each header file is 100% stand-alone. If you wish to use the full package, you only need `BS_thread_pool.hpp`, and if you wish to use the light version, you only need `BS_thread_pool_light.hpp`. Only a single header file needs to be included in your project.\n\n### v3.2.0 (2022-07-28)\n\n* `BS_thread_pool.hpp`:\n    * Main `BS::thread_pool` class:\n        * Added a new member function, `push_loop()`, which does the same thing as `parallelize_loop()`, except that it does not return a `BS::multi_future` with the futures for each block. Just like `push_task()` vs. `submit()`, this avoids the overhead of creating the futures, but the user must use `wait_for_tasks()` or some other method to ensure that the loop finishes executing, otherwise bad things will happen.\n        * `push_task()` and `submit()` now utilize perfect forwarding in order to support more types of tasks - in particular member functions, which in previous versions could not be submitted unless wrapped in a lambda. To submit a member function, use the syntax `submit(&class::function, &object, args)`. More information can be found in `README.md`. See [#9](https://github.com/bshoshany/thread-pool/issues/9).\n        * `push_loop()` and `parallelize_loop()` now have overloads where the first argument (the first index in the loop) is omitted, in which case it is assumed to be 0. This is for convenience, as the case where the first index is 0 is very common.\n    * Helper classes:\n        * `BS::synced_stream` now utilizes perfect forwarding in the member functions `print()` and `println()`.\n        * Previously, it was impossible to pass the flushing manipulators `std::endl` and `std::flush` to `print()` and `println()`, since the compiler could not figure out which template specializations to use. The new objects `BS::endl` and `BS::flush` are explicit casts of these manipulators, whose sole purpose is to enable passing them to `print()` and `println()`.\n        * `BS::multi_future::get()` now rethrows exceptions generated by the futures, even if the futures return `void`. See [#62](https://github.com/bshoshany/thread-pool/pull/62).\n        * Added a new helper class, `BS::blocks`, which is used by `parallelize_loop()` and `push_loop()` to divide a range into blocks. This class is not documented in `README.md`, as it most likely will not be of interest to most users, but it is still publicly available, in case you want to parallelize something manually but still benefit from the built-in algorithm for splitting a range into blocks.\n* `BS_thread_pool_test.cpp`:\n    * Added plenty of new tests for the new features described above.\n    * Fixed a bug in `count_unique_threads()` that caused it to get stuck on certain systems.\n    * `dual_println()` now also flushes the stream using `BS::endl`, so that if the test gets stuck, the log file will still contain everything up to that point. (Note: It is a common misconception that `std::endl` and `'\\n'` are interchangeable. `std::endl` not only prints a newline character, it also flushes the stream, which is not always desirable, as it may reduce performance.)\n    * The performance test has been modified as follows:\n        * Instead of generating random vectors using `std::mersenne_twister_engine`, which proved to be inconsistent across different compilers and systems, the test now generates each element via an arbitrarily-chosen numerical operation. In my testing, this provided much more consistent results.\n        * Instead of using a hard-coded vector size, a suitable vector size is now determined dynamically at runtime.\n        * Instead of using `parallelize_loop()`, the test now uses the new `push_loop()` function to squeeze out a bit more performance.\n        * Instead of setting the test parameters to achieve a fixed single-threaded mean execution time of 300 ms, the test now aims to achieve a fixed multithreaded mean execution time of 50 ms when the number of blocks is equal to the number of threads. This allows for more reliable results on very fast CPUs with a very large number of threads, where the mean execution time when using all the threads could previously be below a statistically significant value.\n        * The number of vectors is now restricted to be a multiple of the number of threads, so that the blocks are always all of the same size.\n* `README.md`:\n    * Added instructions and examples for the new features described above.\n    * Rewrote the documentation for `parallelize_loop()` to make it clearer.\n\n### v3.1.0 (2022-07-13)\n\n* `BS_thread_pool.hpp`:\n    * Fixed an issue where `wait_for_tasks()` would sometimes get stuck if `push_task()` was executed immediately before `wait_for_tasks()`.\n    * Both the thread pool constructor and the `reset()` member function now determine the number of threads to use in the pool as follows. If the parameter is a positive number, then the pool will be created with this number of threads. If the parameter is non-positive, or a parameter was not supplied, then the pool will be created with the total number of hardware threads available, as obtained from `std::thread::hardware_concurrency()`. If the latter returns a non-positive number for some reason, then the pool will be created with just one thread. See [#51](https://github.com/bshoshany/thread-pool/issues/51) and [#52](https://github.com/bshoshany/thread-pool/issues/52).\n    * Added the `[[nodiscard]]` attribute to classes and class members, in order to warn the user when accidentally discarding an important return value, such as a future or the return value of a function with no useful side-effects. For example, if you use `submit()` and don't save the future it returns, the compiler will now generate a warning. (If a future is not needed, then you should use `push_task()` instead.)\n    * Removed the `explicit` specifier from all constructors, as it prevented the default constructor from being used with static class members. See [#48](https://github.com/bshoshany/thread-pool/issues/48).\n* `BS_thread_pool_test.cpp`:\n    * Improved `count_unique_threads()` using condition variables, to ensure that each thread in the pool runs at least one task regardless of how fast it takes to run the tasks.\n    * When appropriate, `check()` now explicitly reports what the obtained result was and what it was expected to be.\n    * `check_task_monitoring()` and `check_pausing()` now explicitly report the results of the monitoring at each step.\n    * Changed all instances of `std::vector<std::atomic<bool>>` to `std::unique_ptr<std::atomic<bool>[]>`. See [#44](https://github.com/bshoshany/thread-pool/issues/44).\n    * Converted a few more C-style casts to C++ cast expressions.\n* `README.md`:\n    * Added instructions for using this package with the [Conan](https://conan.io/) C/C++ package manager. Please refer to [this package's page on ConanCenter](https://conan.io/center/bshoshany-thread-pool) to learn how to use Conan to include this package in your project with various build systems.\n* If you found this project useful, please consider [starring it on GitHub](https://github.com/bshoshany/thread-pool/stargazers)! This allows me to see how many people are using my code, and motivates me to keep working to improve it.\n\n### v3.0.0 (2022-05-30)\n\n* This is a major new release with many changes and improvements! Please note that code written using previous releases will need to be slightly modified to work with the new release. The changes needed to migrate to the new API are explicitly indicated below for your convenience.\n* Breaking changes to the library header file:\n    * The header file has been renamed to `BS_thread_pool.hpp` to avoid potential conflict with other thread pool libraries.\n        * **API migration:** The library must now be included by invoking `#include \"BS_thread_pool.hpp\"`.\n    * All the definitions in the library, including the `thread_pool` class and the helper classes, are now located in the namespace `BS`. This namespace will also be used for my other C++ projects, and is intended to ensure consistency between my projects while avoiding potential name conflicts with other libraries.\n        * **API migration:** The thread pool class should now be invoked as `BS::thread_pool`. Alternatively, it is possible to employ `using BS::thread_pool` or even `using namespace BS` and then invoke `thread_pool` directly. Same for the `BS::synced_stream` and `BS::timer` helper classes.\n    * The macro `THREAD_POOL_VERSION`, which contains the version number and release date of the library, has been renamed to `BS_THREAD_POOL_VERSION` to avoid potential conflicts.\n        * **API migration:** The version must now be read from the macro `BS_THREAD_POOL_VERSION`.\n    * The public member `sleep_duration` has been removed. The thread pool now uses condition variables instead of sleep to facilitate waiting. This significantly improves performance (by 10%-50% in my testing), drastically decreases idle CPU utilization, and eliminates the need to set an optimal sleep time. This was a highly-requested change; see [issue #1](https://github.com/bshoshany/thread-pool/issues/1), [issue #12](https://github.com/bshoshany/thread-pool/issues/12), and [pull request #23](https://github.com/bshoshany/thread-pool/pull/23).\n        * **API migration:** Remove any code that relates to the public member `sleep_duration`.\n    * The template specializations for `submit()` have been merged. Now instead of two versions, one for functions with a return value and one for functions without a return value, there is just one version, which can accept any function. This makes the code more compact (and elegant). If a function with no return value is submitted, an `std::future<void>` is returned (the previous version returned an `std::future<bool>`)\n        * **API migration:** To wait for a task with no return value, simply call `wait()` or `get()` on the corresponding `std::future<void>`.\n    * `parallelize_loop()` now returns a future in the form of a new `BS::multi_future` helper class template. The member function `wait()` of this future allows waiting until all of the loop's blocks finish executing. In previous versions, calling `parallelize_loop()` both parallelized the loop and waited for the blocks to finish; now it is possible to do other stuff while the loop executes.\n        * **API migration:** Since `parallelize_loop()` no longer automatically blocks, you should either store the result in a `BS::multi_future` object and call its `wait()` member function, or simply call `parallelize_loop().wait()` to reproduce the old behavior.\n* Non-breaking changes to the library header file:\n    * It is now possible to use `parallelize_loop()` with functions that have return values and get these values from all blocks at once through the `get()` member function of the `BS::multi_future`.\n    * The template specializations for `push_task()` have been merged. Now instead of two versions, one for functions with arguments and one for functions without arguments, there is just one version, which can accept any function.\n    * Constructors have been made `explicit`. See [issue #28](https://github.com/bshoshany/thread-pool/issues/28).\n    * `submit()` now uses `std::make_shared` instead of `new` to create the shared pointer. This means only one memory allocation is performed instead of two, which should improve performance. In addition, all unique pointers are now created using `std::make_unique`.\n    * A new helper class template, `BS::multi_future`, has been added. It's basically just a wrapper around `std::vector<std::future<T>>`. This class is used by the new implementation of `parallelize_loop()` to allow waiting for the entire loop, consisting of multiple tasks with their corresponding futures, to finish executing.\n    * `BS::multi_future` can also be used independently to handle multiple futures at once. For example, you can now keep track of several groups of tasks by storing their futures inside separate `BS::multi_future` objects and use either `wait()` to wait for all tasks in a specific group to finish or `get()` to get an `std::vector` with the return values of every task in the group.\n    * Integer types are now chosen in a smarter way to improve portability, allow for better compatibility with 32-bit systems, and prevent potential conversion errors.\n    * Added a new type, `BS::concurrency_t`, equal to the return type of `std::thread::hardware_concurrency()`. This is probably pointless, since the C++ standard requires this to be `unsigned int`, but it seems to me to make the code slightly more portable, in case some non-conforming compiler chooses to use a different integer type.\n    * C-style casts have been converted to C++ cast expressions for added clarity.\n    * Miscellaneous minor optimizations and style improvements.\n* Changes to the test program:\n    * The program has been renamed to `BS_thread_pool_test.cpp` to avoid potential conflict with other thread pool libraries.\n    * The program now returns `EXIT_FAILURE` if any of the tests failed, for automation purposes. See [pull request #42](https://github.com/bshoshany/thread-pool/pull/42).\n    * Fixed incorrect check order in `check_task_monitoring()`. See [pull request #43](https://github.com/bshoshany/thread-pool/pull/43).\n    * Added a new test for `parallelize_loop()` with a return value.\n    * Improved some of the tests to make them more reliable. For example, `count_unique_threads()` now uses futures (stored in a `BS::multi_future<void>` object).\n    * The program now uses `std::vector` instead of matrices, for both consistency checks and benchmarks, in order to simplify the code and considerably reduce its length.\n    * The benchmarks have been simplified. There's now only one test: filling a specific number of vectors of fixed size with random values. This may be replaced with something more practical in a future released, but at least on the systems I've tested on, it does demonstrate a very significant multithreading speedup.\n    * In addition to multithreaded tests with different numbers of tasks, the benchmark now also includes a single-threaded test. This allows for more accurate benchmarks compared to previous versions, as the (slight) parallelization overhead is now taken into account when calculating the maximum speedup.\n    * The program decides how many vectors to use for benchmarking by testing how many are needed to reach a target duration in the single-threaded test. This ensures that the test takes approximately the same amount of time on different systems, and is thus more consistent and portable.\n    * Miscellaneous minor optimizations and style improvements.\n* Changes to `README.md`:\n    * Many sections have been rewritten and/or polished.\n    * Explanations and examples of all the new features have been added.\n    * Added an acknowledgements section.\n* Miscellaneous changes:\n    * Added a `CITATION.bib` file (in BibTeX format) to the GitHub repository. You can use it to easily cite this package if you use it in any research papers.\n    * Added a `CITATION.cff` file (in YAML format) to the GitHub repository. This should add [an option to get a citation in different formats](https://docs.github.com/en/github/creating-cloning-and-archiving-repositories/creating-a-repository-on-github/about-citation-files) directly from GitHub repository by clicking on \"cite this repository\" on the sidebar to the right.\n    * Added templates for GitHub issues and pull requests.\n\n### v2.0.0 (2021-08-14)\n\n* From now on, version numbers will adhere to the [Semantic Versioning](https://semver.org/) specification in the format **major.minor.patch**.\n* A file named `thread_pool_test.cpp` has been added to the package. It will perform automated tests of all aspects of the package, and benchmark some multithreaded matrix operations. Please run it on your system and [submit a bug report](https://github.com/bshoshany/thread-pool/issues) if any of the tests fail. In addition, the code is thoroughly documented, and is meant to serve as an extensive example of how to properly use the package.\n* The package is now available through [vcpkg](https://github.com/microsoft/vcpkg). Instructions for how to install it have been added to `README.md`. See [this pull request](https://github.com/bshoshany/thread-pool/pull/18).\n* The package now defines a macro `THREAD_POOL_VERSION`, which returns the version number and release date of the thread pool library as a string.\n* `parallelize_loop()` has undergone some major changes (and is now incompatible with v1.x):\n    * The second argument is now the index **after** the last index, instead of the last index itself. This is more consistent with C++ conventions (e.g. standard library algorithms) where the range is always `[first, last)`. For example, for an array with `n` indices, instead of `parallelize_loop(0, n - 1, ...)` you should now write `parallelize_loop(0, n, ...)`.\n    * The `loop` function is now only called once per block, instead of once per index, as was the case before. This should provide a performance boost due to significantly reducing the number of function calls, and it also allows you to conserve resources by using them only once per block instead of once per index (an example can be found in the `random_matrix_generator` class in `thread_pool_test.cpp`). It also means that `loop` now takes two arguments: the first index in the block and the index after the last index in the block. Thus, `loop(start, end)` should typically involve a loop of the form `for (T i = start; i < end; i++)`.\n    * The first and last indices can now be of two different integer types. Previously, `parallelize_loop(0, i, ...)` did not work if `i` was not an `int`, because `0` was interpreted as `int`, and the two arguments had to be of the same type. Therefore, one had to use casting, e.g. `parallelize_loop((size_t)0, i)`, to make it work. Now this is no longer necessary; the common type is inferred automatically using `std::common_type_t`.\n\n### v1.9 (2021-07-29)\n\n* Fixed a bug in `reset()` which caused it to create the wrong number of threads.\n\n### v1.8 (2021-07-28)\n\n* The version history has become too long to be included in `README.md`, so I moved it to a separate file, `CHANGELOG.md`.\n* A button to open this repository directly in Visual Studio Code has been added to the badges in `README.md`.\n* An internal variable named `promise` has been renamed to `task_promise` to avoid any potential errors in case the user invokes `using namespace std`.\n* `submit()` now catches exceptions thrown by the submitted task and forwards them to the future. See [this issue](https://github.com/bshoshany/thread-pool/issues/14).\n* Eliminated compiler warnings that appeared when using the `-Weffc++` flag in GCC. See [this pull request](https://github.com/bshoshany/thread-pool/pull/17).\n\n### v1.7 (2021-06-02)\n\n* Fixed a bug in `parallelize_loop()` which prevented it from actually running loops in parallel, see [this issue](https://github.com/bshoshany/thread-pool/issues/11).\n\n### v1.6 (2021-05-26)\n\n* Since MSVC does not interpret `and` as `&&` by default, the previous release did not compile with MSVC unless the `/permissive-` or `/Za` compiler flags were used. This has been fixed in this version, and the code now successfully compiles with GCC, Clang, and MSVC. See [this pull request](https://github.com/bshoshany/thread-pool/pull/10).\n\n### v1.5 (2021-05-07)\n\n* This library now has a DOI for citation purposes. Information on how to cite it in publications has been added to the source code and to `README.md`.\n* Added GitHub badges to `README.md`.\n\n### v1.4 (2021-05-05)\n\n* Added three new public member functions to monitor the tasks submitted to the pool:\n    * `get_tasks_queued()` gets the number of tasks currently waiting in the queue to be executed by the threads.\n    * `get_tasks_running()` gets the number of tasks currently being executed by the threads.\n    * `get_tasks_total()` gets the total number of unfinished tasks - either still in the queue, or running in a thread.\n    * Note that `get_tasks_running() == get_tasks_total() - get_tasks_queued()`.\n    * Renamed the private member variable `tasks_waiting` to `tasks_total` to make its purpose clearer.\n* Added an option to temporarily pause the workers:\n    * When public member variable `paused` is set to `true`, the workers temporarily stop popping new tasks out of the queue, although any tasks already executed will keep running until they are done. Set to `false` again to resume popping tasks.\n    * While the workers are paused, `wait_for_tasks()` will wait for the running tasks instead of all tasks (otherwise it would wait forever).\n    * By utilizing the new pausing mechanism, `reset()` can now change the number of threads on-the-fly while there are still tasks waiting in the queue. The new thread pool will resume executing tasks from the queue once it is created.\n* `parallelize_loop()` and `wait_for_tasks()` now have the same behavior as the worker function with regards to waiting for tasks to complete. If the relevant tasks are not yet complete, then before checking again, they will sleep for `sleep_duration` microseconds, unless that variable is set to zero, in which case they will call `std::this_thread::yield()`. This should improve performance and reduce CPU usage.\n* Merged [this commit](https://github.com/bshoshany/thread-pool/pull/8): Fixed weird error when using MSVC and including `windows.h`.\n* The `README.md` file has been reorganized and expanded.\n\n### v1.3 (2021-05-03)\n\n* Fixed [this issue](https://github.com/bshoshany/thread-pool/issues/3): Removed `std::move` from the `return` statement in `push_task()`. This previously generated a `-Wpessimizing-move` warning in Clang. The assembly code generated by the compiler seems to be the same before and after this change, presumably because the compiler eliminates the `std::move` automatically, but this change gets rid of the Clang warning.\n* Fixed [this issue](https://github.com/bshoshany/thread-pool/issues/5): Removed a debugging message printed to `std::cout`, which was left in the code by mistake.\n* Fixed [this issue](https://github.com/bshoshany/thread-pool/issues/6): `parallelize_loop()` no longer sends references for the variables `start` and `stop` when calling `push_task()`, which may lead to undefined behavior.\n* A companion paper is now published at <a href=\"https://arxiv.org/abs/2105.00613\">arXiv:2105.00613</a>, including additional information such as performance tests on systems with up to 80 hardware threads. The `README.md` has been updated, and it is now roughly identical in content to the paper.\n\n### v1.2 (2021-04-29)\n\n* The worker function, which controls the execution of tasks by each thread, now sleeps by default instead of yielding. Previously, when the worker could not find any tasks in the queue, it called `std::this_thread::yield()` and then tried again. However, this caused the workers to have high CPU usage when idle, [as reported by some users](https://github.com/bshoshany/thread-pool/issues/1). Now, when the worker function cannot find a task to run, it instead sleeps for a duration given by the public member variable `sleep_duration` (in microseconds) before checking the queue again. The default value is `1000` microseconds, which I found to be optimal in terms of both CPU usage and performance, but your own optimal value may be different.\n* If the constructor is called with an argument of zero for the number of threads, then the default value, `std::thread::hardware_concurrency()`, is used instead.\n* Added a simple helper class, `timer`, which can be used to measure execution time for benchmarking purposes.\n* Improved and expanded the documentation.\n\n### v1.1 (2021-04-24)\n\n* Cosmetic changes only. Fixed a typo in the Doxygen comments and added a link to the GitHub repository.\n\n### v1.0 (2021-01-15)\n\n* Initial release.\n"
        },
        {
          "name": "CITATION.bib",
          "type": "blob",
          "size": 0.470703125,
          "content": "@article{Shoshany2024_ThreadPool,\n    archiveprefix = {arXiv},\n    author        = {Barak Shoshany},\n    doi           = {10.1016/j.softx.2024.101687},\n    eprint        = {2105.00613},\n    journal       = {SoftwareX},\n    pages         = {101687},\n    title         = {{A C++17 Thread Pool for High-Performance Scientific Computing}},\n    url           = {https://www.sciencedirect.com/science/article/pii/S235271102400058X},\n    volume        = {26},\n    year          = {2024}\n}\n"
        },
        {
          "name": "CITATION.cff",
          "type": "blob",
          "size": 0.798828125,
          "content": "authors:\n  - email: baraksh@gmail.com\n    family-names: Shoshany\n    given-names: Barak\n    orcid: https://orcid.org/0000-0003-2222-127X\ncff-version: 1.2.0\ndoi: 10.1016/j.softx.2024.101687\nlicense: MIT\nmessage: If you use this library in published research, please cite it as follows.\npreferred-citation:\n  authors:\n    - family-names: Shoshany\n      given-names: Barak\n  doi: 10.1016/j.softx.2024.101687\n  journal: SoftwareX\n  start: 101687\n  title: A C++17 Thread Pool for High-Performance Scientific Computing\n  type: article\n  url: https://www.sciencedirect.com/science/article/pii/S235271102400058X\n  volume: 26\n  year: 2024\nrepository-code: https://github.com/bshoshany/thread-pool\ntitle: A C++17 Thread Pool for High-Performance Scientific Computing\ntype: software\nurl: https://github.com/bshoshany/thread-pool\n"
        },
        {
          "name": "LICENSE.txt",
          "type": "blob",
          "size": 1.0458984375,
          "content": "MIT License\n\nCopyright (c) 2024 Barak Shoshany\n\nPermission is hereby granted, free of charge, to any person obtaining a copy\nof this software and associated documentation files (the \"Software\"), to deal\nin the Software without restriction, including without limitation the rights\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\ncopies of the Software, and to permit persons to whom the Software is\nfurnished to do so, subject to the following conditions:\n\nThe above copyright notice and this permission notice shall be included in all\ncopies or substantial portions of the Software.\n\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\nSOFTWARE.\n"
        },
        {
          "name": "README.md",
          "type": "blob",
          "size": 220.4775390625,
          "content": "[![Author: Barak Shoshany](https://img.shields.io/badge/author-Barak_Shoshany-009933)](https://baraksh.com/)\n[![DOI: 10.1016/j.softx.2024.101687](https://img.shields.io/badge/DOI-10.1016%2Fj.softx.2024.101687-b31b1b)](https://doi.org/10.1016/j.softx.2024.101687)\n[![arXiv:2105.00613](https://img.shields.io/badge/arXiv-2105.00613-b31b1b)](https://arxiv.org/abs/2105.00613)\n[![License: MIT](https://img.shields.io/github/license/bshoshany/thread-pool)](https://github.com/bshoshany/thread-pool/blob/master/LICENSE.txt)\n[![Language: C++17 / C++20 / C++23](https://img.shields.io/badge/Language-C%2B%2B17%20%2F%20C%2B%2B20%20%2F%20C%2B%2B23-yellow)](https://cppreference.com/)\n[![GitHub stars](https://img.shields.io/github/stars/bshoshany/thread-pool?style=flat&color=009999)](https://github.com/bshoshany/thread-pool/stargazers)\n[![GitHub forks](https://img.shields.io/github/forks/bshoshany/thread-pool?style=flat&color=009999)](https://github.com/bshoshany/thread-pool/forks)\n[![GitHub release](https://img.shields.io/github/v/release/bshoshany/thread-pool?color=660099)](https://github.com/bshoshany/thread-pool/releases)\n[![Vcpkg version](https://img.shields.io/vcpkg/v/bshoshany-thread-pool?color=6600ff)](https://vcpkg.io/)\n[![Meson WrapDB](https://img.shields.io/badge/dynamic/json?url=https%3A%2F%2Fraw.githubusercontent.com%2Fmesonbuild%2Fwrapdb%2Fmaster%2Freleases.json&query=%24%5B%22bshoshany-thread-pool%22%5D.versions%5B0%5D&label=wrapdb&color=6600ff)](https://mesonbuild.com/Wrapdb-projects.html)\n[![Conan version](https://img.shields.io/conan/v/bshoshany-thread-pool?color=6600ff)](https://conan.io/center/recipes/bshoshany-thread-pool)\n[![Open in Visual Studio Code](https://img.shields.io/badge/Open_in_Visual_Studio_Code-007acc)](https://vscode.dev/github/bshoshany/thread-pool)\n\n# `BS::thread_pool`: a fast, lightweight, modern, and easy-to-use C&plus;&plus;17 / C&plus;&plus;20 / C&plus;&plus;23 thread pool library\n\nBy **Barak Shoshany**\\\nEmail: <baraksh@gmail.com>\\\nWebsite: <https://baraksh.com/>\\\nGitHub: <https://github.com/bshoshany>\n\nThis is the complete documentation for **v5.0.0** of the library, released on **2024-12-19**.\n\n* [Introduction](#introduction)\n    * [Motivation](#motivation)\n    * [Overview of features](#overview-of-features)\n* [Getting started](#getting-started)\n    * [Installing the library](#installing-the-library)\n    * [Compiling and compatibility](#compiling-and-compatibility)\n    * [Constructors](#constructors)\n    * [Getting and resetting the number of threads in the pool](#getting-and-resetting-the-number-of-threads-in-the-pool)\n* [Submitting tasks to the queue](#submitting-tasks-to-the-queue)\n    * [Submitting tasks with no arguments and receiving a future](#submitting-tasks-with-no-arguments-and-receiving-a-future)\n    * [Submitting tasks with arguments and receiving a future](#submitting-tasks-with-arguments-and-receiving-a-future)\n    * [Detaching and waiting for tasks](#detaching-and-waiting-for-tasks)\n    * [Waiting for submitted or detached tasks with a timeout](#waiting-for-submitted-or-detached-tasks-with-a-timeout)\n    * [Class member functions as tasks](#class-member-functions-as-tasks)\n* [Parallelizing loops](#parallelizing-loops)\n    * [Automatic parallelization of loops](#automatic-parallelization-of-loops)\n    * [Optimizing the number of blocks](#optimizing-the-number-of-blocks)\n    * [Common index types](#common-index-types)\n    * [Parallelizing loops without futures](#parallelizing-loops-without-futures)\n    * [Parallelizing individual indices vs. blocks](#parallelizing-individual-indices-vs-blocks)\n    * [Loops with return values](#loops-with-return-values)\n    * [Parallelizing sequences](#parallelizing-sequences)\n    * [More about `BS::multi_future`](#more-about-bsmulti_future)\n* [Utility classes](#utility-classes)\n    * [Synchronizing printing to a stream with `BS::synced_stream`](#synchronizing-printing-to-a-stream-with-bssynced_stream)\n    * [Synchronizing tasks with `BS::counting_semaphore` and `BS::binary_semaphore`](#synchronizing-tasks-with-bscounting_semaphore-and-bsbinary_semaphore)\n* [Managing tasks](#managing-tasks)\n    * [Monitoring the tasks](#monitoring-the-tasks)\n    * [Purging tasks](#purging-tasks)\n    * [Exception handling](#exception-handling)\n    * [Getting information about the current thread](#getting-information-about-the-current-thread)\n    * [Thread initialization functions](#thread-initialization-functions)\n    * [Thread cleanup functions](#thread-cleanup-functions)\n    * [Passing task arguments by constant reference](#passing-task-arguments-by-constant-reference)\n* [Optional features](#optional-features)\n    * [Enabling features](#enabling-features)\n    * [Setting task priority](#setting-task-priority)\n    * [Pausing the pool](#pausing-the-pool)\n    * [Avoiding wait deadlocks](#avoiding-wait-deadlocks)\n* [Native extensions](#native-extensions)\n    * [Enabling the native extensions](#enabling-the-native-extensions)\n    * [Setting thread priority](#setting-thread-priority)\n    * [Setting thread affinity](#setting-thread-affinity)\n    * [Setting thread names](#setting-thread-names)\n    * [Setting process priority](#setting-process-priority)\n    * [Setting process affinity](#setting-process-affinity)\n    * [Accessing native thread handles](#accessing-native-thread-handles)\n* [Testing the library](#testing-the-library)\n    * [Automated tests](#automated-tests)\n    * [Performance tests](#performance-tests)\n    * [Finding the version of the library](#finding-the-version-of-the-library)\n* [Importing the library as a C++20 module](#importing-the-library-as-a-c20-module)\n    * [Compiling the module](#compiling-the-module)\n    * [Compiling with `compile_cpp.py` using `import BS.thread_pool`](#compiling-with-compile_cpppy-using-import-bsthread_pool)\n    * [Compiling with Clang using `import BS.thread_pool`](#compiling-with-clang-using-import-bsthread_pool)\n    * [Compiling with GCC using `import BS.thread_pool`](#compiling-with-gcc-using-import-bsthread_pool)\n    * [Compiling with MSVC using `import BS.thread_pool`](#compiling-with-msvc-using-import-bsthread_pool)\n    * [Compiling with CMake using `import BS.thread_pool`](#compiling-with-cmake-using-import-bsthread_pool)\n* [Importing the C++23 Standard Library as a module](#importing-the-c23-standard-library-as-a-module)\n    * [Enabling `import std`](#enabling-import-std)\n    * [Compiling with `compile_cpp.py` using `import std`](#compiling-with-compile_cpppy-using-import-std)\n    * [Compiling with Clang and LLVM libc++ using `import std`](#compiling-with-clang-and-llvm-libc-using-import-std)\n    * [Compiling with MSVC and Microsoft STL using `import std`](#compiling-with-msvc-and-microsoft-stl-using-import-std)\n    * [Compiling with CMake using `import std`](#compiling-with-cmake-using-import-std)\n* [Installing the library using package managers](#installing-the-library-using-package-managers)\n    * [Installing using vcpkg](#installing-using-vcpkg)\n    * [Installing using Conan](#installing-using-conan)\n    * [Installing using Meson](#installing-using-meson)\n    * [Installing using CMake with CPM](#installing-using-cmake-with-cpm)\n    * [Installing using CMake with `FetchContent`](#installing-using-cmake-with-fetchcontent)\n* [Complete library reference](#complete-library-reference)\n    * [The `BS::thread_pool` class template](#the-bsthread_pool-class-template)\n    * [Optional features and the template parameter](#optional-features-and-the-template-parameter)\n    * [The `BS::this_thread` class](#the-bsthis_thread-class)\n    * [The native extensions](#the-native-extensions)\n    * [The `BS::multi_future` class](#the-bsmulti_future-class)\n    * [The `BS::synced_stream` class](#the-bssynced_stream-class)\n    * [The `BS::version` class](#the-bsversion-class)\n    * [Diagnostic variables](#diagnostic-variables)\n    * [All names exported by the C++20 module](#all-names-exported-by-the-c20-module)\n* [Development tools](#development-tools)\n    * [The `compile_cpp.py` script](#the-compile_cpppy-script)\n    * [Other included tools](#other-included-tools)\n* [About the project](#about-the-project)\n    * [Bug reports and feature requests](#bug-reports-and-feature-requests)\n    * [Contribution and pull request policy](#contribution-and-pull-request-policy)\n    * [Starring the repository](#starring-the-repository)\n    * [Acknowledgements](#acknowledgements)\n    * [Copyright and citing](#copyright-and-citing)\n    * [About the author](#about-the-author)\n    * [Learning more about C++](#learning-more-about-c)\n    * [Other projects to check out](#other-projects-to-check-out)\n\n## Introduction\n\n### Motivation\n\nMultithreading is essential for modern high-performance computing. Since C&plus;&plus;11, the C&plus;&plus; standard library has included built-in low-level multithreading support using constructs such as `std::thread`. However, `std::thread` creates a new thread each time it is called, which can have a significant performance overhead. Furthermore, it is possible to create more threads than the hardware can handle simultaneously, potentially resulting in a substantial slowdown.\n\nThe library presented here contains a C&plus;&plus; thread pool class, `BS::thread_pool`, which avoids these issues by creating a fixed pool of threads once and for all, and then continuously reusing the same threads to perform different tasks throughout the lifetime of the program. By default, the number of threads in the pool is equal to the maximum number of threads that the hardware can run in parallel.\n\nThe user submits tasks to be executed into a queue. Whenever a thread becomes available, it retrieves the next task from the queue and executes it. The pool optionally produces an `std::future` for each task, which allows the user to wait for the task to finish executing and/or obtain its eventual return value, if applicable. Threads and tasks are autonomously managed by the pool in the background, without requiring any input from the user aside from submitting the desired tasks.\n\nThe design of this library is guided by four important principles. First, *compactness*: the entire library consists of just one self-contained header file, with no other components or dependencies. Second, *portability*: the library only utilizes the C&plus;&plus; standard library, without relying on any compiler extensions or 3rd-party libraries, and is therefore compatible with any modern standards-conforming C&plus;&plus; compiler on any platform, as long as it supports C&plus;&plus;17 or later. Third, *ease of use*: the library is extensively documented, and programmers of any level should be able to use it right out of the box.\n\nThe fourth and final guiding principle is *performance*: each and every line of code in this library was carefully designed with maximum performance in mind, and performance was tested and verified on a variety of compilers and platforms. Indeed, the library was originally designed for use in the author's own computationally-intensive scientific computing projects, running both on high-end desktop/laptop computers and high-performance computing nodes.\n\nAmong the available C&plus;&plus; thread pool libraries, `BS::thread_pool` occupies the crucial middle ground between small bare-bones thread pool classes that offer rudimentary functionality and are only suitable for simple programs, and very large libraries that offer many advanced features but consist of multiple components and dependencies and involve complex APIs that require a substantial time investment to learn. `BS::thread_pool` was designed for users who want a simple and lightweight header-only library that is easy to learn and use, and can be readily incorporated into existing or new projects, but do not want to compromise on performance or functionality.\n\nObtaining the library is quick and easy; it can be downloaded manually from [the GitHub repository](https://github.com/bshoshany/thread-pool), or installed automatically using a variety of package managers and build systems. The library can be imported either as a traditional [header-only library](#installing-the-library), or as a modern [C&plus;&plus;20 module](#importing-the-library-as-a-c20-module). `BS::thread_pool` has undergone extensive testing on multiple platforms and is actively used by thousands of C&plus;&plus; developers worldwide for a wide range of applications, from scientific computing to game development.\n\n### Overview of features\n\n* **Fast:**\n    * Built from scratch with [maximum performance](#performance-tests) in mind.\n    * Suitable for use in high-performance computing nodes with a very large number of CPU cores.\n    * Reusing threads avoids the overhead of creating and destroying them for individual tasks.\n    * A task queue ensures that there are never more tasks running in parallel than is allowed by the hardware.\n    * All optional features can be selectively turned on to ensure minimal overhead.\n* **Lightweight:**\n    * Single header file: simply [`#include \"BS_thread_pool.hpp\"`](#installing-the-library) and you're all set!\n    * Header-only: no need to install or build the library.\n    * Self-contained: no external requirements or dependencies.\n    * Portable: uses only the C&plus;&plus; standard library, and works with any C&plus;&plus;17-compliant compiler on any platform.\n    * Only 487 lines of code, including all optional features and utility classes (excluding comments, blank lines, lines containing only a single brace, C&plus;&plus;17 polyfills, and native extensions).\n* **Modern:**\n    * Fully supports C&plus;&plus;17, C&plus;&plus;20, and C&plus;&plus;23, taking advantage of the latest language features when available for maximum performance, reliability, and usability.\n    * In C&plus;&plus;20, the library can an be imported as a C&plus;&plus;20 module using [`import BS.thread_pool`](#importing-the-library-as-a-c20-module), with many benefits, such as faster compilation times and avoiding namespace pollution.\n    * In C&plus;&plus;23, the library can import the C&plus;&plus; Standard Library as a module using [`import std`](#importing-the-c23-standard-library-as-a-module) on supported compilers and platforms.\n    * Makes use of modern C&plus;&plus; programming practices for readability, maintainability, performance, safety, portability, and reliability.\n* **Easy to use:**\n    * Very simple operation, using only a handful of member functions for basic use, with many additional member functions, classes, and functions for more advanced use.\n    * Every task submitted to the queue using [`submit_task()`](#submitting-tasks-to-the-queue) automatically generates an `std::future`, which can be used to wait for the task to finish executing, obtain its eventual return value, and/or catch any thrown exceptions.\n    * Loops can be automatically parallelized into any number of tasks using [`submit_loop()`](#parallelizing-loops), which returns a [`BS::multi_future`](#more-about-bsmulti_future) that can be used to track the execution of all parallel tasks at once.\n    * If futures are not needed, tasks may be submitted using [`detach_task()`](#detaching-and-waiting-for-tasks), and loops can be parallelized using [`detach_loop()`](#parallelizing-loops-without-futures) - sacrificing convenience for even greater performance. In that case, `wait()`, `wait_for()`, and `wait_until()` can be used to wait for all the tasks in the queue to complete.\n    * Extremely thorough and detailed documentation, with numerous examples, is available in the library's [`README.md` file](https://github.com/bshoshany/thread-pool/blob/master/README.md), with a total of 3,359 lines and 25,506 words!\n    * The code is thoroughly documented using Doxygen comments - not only the interface, but also the implementation, in case the user would like to make modifications.\n    * Optionally, the included Python script [`compile_cpp.py`](#the-compile_cpppy-script) can be used to easily compile any programs that are using the library, with full support for C&plus;&plus;20 modules and C&plus;&plus;23 Standard Library modules where applicable.\n* **Additional features:**\n    * Get the current thread count of the pool using [`get_thread_count()`](#getting-and-resetting-the-number-of-threads-in-the-pool).\n    * Change the number of threads in the pool safely and on-the-fly as needed using [`reset()`](#getting-and-resetting-the-number-of-threads-in-the-pool).\n    * Monitor the number of queued and/or running tasks using [`get_tasks_queued()`, `get_tasks_running()`, and `get_tasks_total()`](#monitoring-the-tasks).\n    * Purge all tasks currently waiting in the queue with [`purge()`](#purging-tasks).\n    * Run an [initialization function](#thread-initialization-functions) in each thread before it starts to execute any submitted tasks, by passing it to the `BS::thread_pool` constructor.\n    * Run a cleanup function in each thread right before it is destroyed, using [`set_cleanup_func()`](#thread-cleanup-functions).\n    * Assume lower-level control of parallelized loops using [`detach_blocks()` and `submit_blocks()`](#parallelizing-individual-indices-vs-blocks).\n    * Parallelize a sequence of tasks enumerated by indices to the queue using [`detach_sequence()` and `submit_sequence()`](#parallelizing-sequences).\n    * Get [information about the current thread](#getting-information-about-the-current-thread): the pool index using `BS::this_thread::get_index()` and a pointer to the owning pool using `BS::this_thread::get_pool()`.\n    * Get the unique thread IDs for all threads in the pool using [`get_thread_ids()`](#getting-and-resetting-the-number-of-threads-in-the-pool).\n    * Synchronize output to one or more streams from multiple threads in parallel using the [`BS::synced_stream`](#synchronizing-printing-to-a-stream-with-bssynced_stream) utility class.\n    * Access C&plus;&plus;20 semaphores in C&plus;&plus;17 using the [`BS::binary_semaphore` and `BS::counting_semaphore`](#synchronizing-tasks-with-bscounting_semaphore-and-bsbinary_semaphore) polyfill classes.\n* **Optional features:**\n    * [Optional features](#enabling-features) can be enabled by passing a bitmask template parameter to the `BS::thread_pool` class template.\n    * Assign a priority to each task using the optional [task priority](#setting-task-priority) feature. The priority, in the range -128 to +127, is passed as the last argument to all `submit` and `detach` member functions. Tasks with higher priorities will be executed first.\n    * Freely pause and resume the pool using `pause()`, `unpause()`, and `is_paused()` with the optional [pausing](#pausing-the-pool) feature. When paused, threads do not retrieve new tasks out of the queue.\n    * Avoid deadlocks using the optional [wait deadlock checks](#avoiding-wait-deadlocks) feature. If a deadlock is detected while waiting for tasks, the pool will throw the exception `BS::wait_deadlock`.\n* **Native extensions:**\n    * The library includes optional [native extensions](#native-extensions), which contain non-portable features using the operating system's native API, enabled by defining the macro `BS_THREAD_POOL_NATIVE_EXTENSIONS` at compilation time. This feature should work on most Windows, Linux, and macOS systems.\n    * Use [`BS::this_thread::get_os_thread_priority()` and `BS::this_thread::set_os_thread_priority()`](#setting-thread-priority) to get and set the priority of the current thread.\n    * Use [`BS::this_thread::get_os_thread_affinity()` and `BS::this_thread::set_os_thread_affinity()`](#setting-thread-affinity) to get and set the processor affinity of the current thread.\n    * Use [`BS::this_thread::get_os_thread_name()` and `BS::this_thread::set_os_thread_name()`](#setting-thread-names) to get and set the name of the current thread.\n    * Use [`BS::get_os_process_priority()` and `BS::set_os_process_priority()`](#setting-process-priority) to get and set the priority of the current process.\n    * Use [`BS::get_os_process_affinity()` and `BS::set_os_process_affinity()`](#setting-process-affinity) to get and set the processor affinity of the current process.\n    * Get the implementation-defined thread handles for all threads in the pool using [`get_native_handles()`](#accessing-native-thread-handles).\n* **Well-tested:**\n    * The included test program [`BS_thread_pool_test.cpp`](#automated-tests) performs hundreds of automated tests, and also serves as a comprehensive example of how to properly use the library.\n    * The test program also performs [benchmarks](#performance-tests) using a highly-optimized multithreaded algorithm which generates a plot of the Mandelbrot set.\n    * The included Python script `test_all.py` provides a portable way to easily run the tests with multiple compilers.\n    * [Compatibility](#compiling-and-compatibility) is comprehensively tested on the latest versions of Windows, Ubuntu, and macOS, using Clang, GCC, and MSVC.\n    * Under continuous and active development. Bug reports and feature requests are welcome, and should be made via [GitHub issues](https://github.com/bshoshany/thread-pool/issues).\n\n## Getting started\n\n### Installing the library\n\nTo install `BS::thread_pool`, simply download the [latest release](https://github.com/bshoshany/thread-pool/releases) from [the GitHub repository](https://github.com/bshoshany/thread-pool), place the header file `BS_thread_pool.hpp` from the `include` folder in the desired folder, and include it in your program:\n\n```cpp\n#include \"BS_thread_pool.hpp\"\n```\n\nThe thread pool will now be accessible via the `BS::thread_pool` class. For an even quicker installation, you can download the header file itself directly [at this URL](https://raw.githubusercontent.com/bshoshany/thread-pool/master/include/BS_thread_pool.hpp); no additional files are required, as the library is a single-header library.\n\nThis library is also available on various package managers and build system, including [vcpkg](https://vcpkg.io/), [Conan](https://conan.io/), [Meson](https://mesonbuild.com/), and [CMake](https://cmake.org/). Please [see below](#installing-the-library-using-package-managers) for more details.\n\nIf C&plus;&plus;20 features are available, the library can also be imported as a C&plus;&plus;20 module, in which case `#include \"BS_thread_pool.hpp\"` should be replaced with `import BS.thread_pool;`. This requires one additional file, and the module must be compiled before it can be used; please see detailed instructions [below](#importing-the-library-as-a-c20-module).\n\n### Compiling and compatibility\n\nThis library officially supports C&plus;&plus;17, C&plus;&plus;20, and C&plus;&plus;23. If compiled with C&plus;&plus;20 and/or C&plus;&plus;23 support, the library will make use of newly available features for maximum performance and usability. However, the library is fully compatible with C&plus;&plus;17, and should successfully compile on any C&plus;&plus;17 standard-compliant compiler, on all operating systems and architectures for which such a compiler is available.\n\nCompatibility was verified using the bundled test program `BS_thread_pool_test.cpp`, compiled using the bundled Python scripts `test_all.py` and `compile_cpp.py` with native extensions enabled, importing the library [as a C&plus;&plus;20 module](#importing-the-library-as-a-c20-module) where applicable, and importing the [C&plus;&plus;23 Standard Library as a module](#importing-the-c23-standard-library-as-a-module) where applicable, on a 24-core (8P+16E) / 32-thread Intel i9-13900K CPU, using the following compilers, C&plus;&plus; standard libraries, and platforms:\n\n* Windows 11 23H2 build 22631.4602:\n    * [Clang](https://clang.llvm.org/) v19.1.4 with LLVM libc&plus;&plus; v19.1.4 ([MSYS2 build](https://www.msys2.org/))\n    * [GCC](https://gcc.gnu.org/) v14.2.0 with GNU libstdc&plus;&plus; v14 (20240801) ([MSYS2 build](https://www.msys2.org/))\n    * [MSVC](https://docs.microsoft.com/en-us/cpp/) v19.42.34435 with Microsoft STL v143 (202408).\n* Ubuntu 24.10:\n    * [Clang](https://clang.llvm.org/) v19.1.6 with LLVM libc&plus;&plus; v19.1.6\n    * [GCC](https://gcc.gnu.org/) v14.2.0 with GNU libstdc&plus;&plus; v14 (20240908)\n* macOS 15.1 build 24B83:\n    * [Clang](https://clang.llvm.org/) v19.1.6 with LLVM libc&plus;&plus; v19.1.6 ([Homebrew build](https://formulae.brew.sh/formula/llvm))\n    * Note: Apple Clang is currently not officially supported, as it does not support C&plus;&plus;20 modules.\n\nAs this library requires C&plus;&plus;17 features, the code must be compiled with C&plus;&plus;17 support:\n\n* For Clang or GCC, use the `-std=c++17` flag. On Linux, you will also need to use the `-pthread` flag to enable the POSIX threads library.\n* For MSVC, use `/std:c++17`, and also `/permissive-` to ensure standards conformance.\n\nFor maximum performance, it is recommended to compile with all available compiler optimizations:\n\n* For Clang or GCC, use the `-O3` flag.\n* For MSVC, use `/O2`.\n\nAs an example, to compile the test program `BS_thread_pool_test.cpp` with compiler optimizations, it is recommended to use the following commands:\n\n* Windows:\n    * GCC: `g++ BS_thread_pool_test.cpp -std=c++17 -O3 -o BS_thread_pool_test.exe`\n    * Clang: `clang++ BS_thread_pool_test.cpp -std=c++17 -O3 -o BS_thread_pool_test.exe`\n    * MSVC: `cl BS_thread_pool_test.cpp /std:c++17 /permissive- /O2 /EHsc /Fo:BS_thread_pool_test.obj /Fe:BS_thread_pool_test.exe`\n* Linux/macOS:\n    * GCC: `g++ BS_thread_pool_test.cpp -std=c++17 -O3 -pthread -o BS_thread_pool_test`\n    * Clang: `clang++ BS_thread_pool_test.cpp -std=c++17 -O3 -pthread -o BS_thread_pool_test`\n\nIf your compiler and codebase support C&plus;&plus;20 and/or C&plus;&plus;23, it is recommended to enable them in order to allow the library access to the latest features:\n\n* For Clang or GCC, use the `-std=c++20` or `-std=c++23` flag.\n* For MSVC, use `/std:c++20` for C&plus;&plus;20 or `/std:c++latest` for C&plus;&plus;23.\n\nIn addition, if C&plus;&plus;20 features are available, the library can be imported as a module; instructions for doing so are provided [below](#importing-the-library-as-a-c20-module).\n\n### Constructors\n\nThe default constructor creates a thread pool with as many threads as the hardware can handle concurrently, as reported by the implementation via `std::thread::hardware_concurrency()`. This is usually determined by the number of cores in the CPU. If a core is hyperthreaded, it will count as two threads. For example:\n\n```cpp\n// Constructs a thread pool with as many threads as are available in the hardware.\nBS::thread_pool pool;\n```\n\nOptionally, a number of threads different from the hardware concurrency can be specified as an argument to the constructor. However, note that adding more threads than the hardware can handle will **not** improve performance, and in fact will most likely hinder it. This option exists in order to allow using **fewer** threads than the hardware concurrency, in cases where you wish to leave some threads available for other processes. For example:\n\n```cpp\n// Constructs a thread pool with only 12 threads.\nBS::thread_pool pool(12);\n```\n\nUsually, when the thread pool is used, a program's main thread should only submit tasks to the thread pool and wait for them to finish, and should not perform any computationally intensive tasks on its own. If this is the case, it is recommended to use the default value for the number of threads. This ensures that all the threads available in the hardware will be put to work while the main thread waits.\n\nHowever, if the main thread also performs computationally intensive tasks, it may be beneficial to use one fewer thread than the hardware concurrency, leaving one hardware thread available for the main thread. Furthermore, if more than one thread pool is used in the program simultaneously, the total number of thread across all pools should not exceed the hardware concurrency.\n\n### Getting and resetting the number of threads in the pool\n\nThe member function `get_thread_count()` returns the number of threads in the pool. This will be equal to `std::thread::hardware_concurrency()` if the default constructor was used.\n\nIt is generally unnecessary to change the number of threads in the pool after it has been created, since the whole point of a thread pool is that you only create the threads once. However, if needed, this can be done, safely and on-the-fly, using the `reset()` member function.\n\n`reset()` will wait for all currently running tasks to be completed, but will leave the rest of the tasks in the queue. Then it will destroy the thread pool and create a new one with the desired new number of threads, as specified in the function's argument (or the hardware concurrency if no argument is given). The new thread pool will then resume executing the tasks that remained in the queue and any newly submitted tasks.\n\nThe member function `get_thread_ids()` returns a vector containing the unique identifiers for each of the pool's threads, as obtained by `std::thread::get_id()`. These values are not so useful on their own, but can be used to identify and distinguish between threads, or for allocating resources.\n\n## Submitting tasks to the queue\n\n### Submitting tasks with no arguments and receiving a future\n\nIn this section we will learn how to submit a task with no arguments, but potentially with a return value, to the queue. Once a task has been submitted, it will be executed as soon as a thread becomes available. Tasks are executed in the order that they were submitted (first-in, first-out), unless task priority is enabled ([see below](#setting-task-priority)).\n\nFor example, if the pool has 8 threads and an empty queue, and we submitted 16 tasks, then we should expect the first 8 tasks to be executed in parallel, with the remaining tasks being picked up by the threads one by one as each thread finishes executing its first task, until no tasks are left in the queue.\n\nThe member function `submit_task()` is used to submit tasks to the queue. It takes exactly one input, the task to submit. This task must be a function with no arguments, but it can have a return value.\n\n`submit_task()` returns an `std::future` associated to the task. If the submitted task has a return value of type `T`, then the future will be of type `std::future<T>`, and will be set to the task's return value when the task finishes its execution. If the submitted task does not have a return value, then the future will be an `std::future<void>`, which will not contain any value, but may still be used to wait for the task to finish.\n\nTo wait until the task finishes, use the member function `wait()` of the future. To obtain the return value, use the member function `get()`, which will also automatically wait for the task to finish if it hasn't yet. Here is a simple example:\n\n```cpp\n#include \"BS_thread_pool.hpp\" // BS::thread_pool\n#include <future>             // std::future\n#include <iostream>           // std::cout\n\nint the_answer()\n{\n    return 42;\n}\n\nint main()\n{\n    BS::thread_pool pool;\n    std::future<int> my_future = pool.submit_task(the_answer);\n    std::cout << my_future.get() << '\\n';\n}\n```\n\nIn this example we submitted the function `the_answer()`, which returns an `int`. The member function `submit_task()` of the pool therefore returned an `std::future<int>`. We then used used the `get()` member function of the future to get the return value, and printed it out.\n\nIn addition to submitting a pre-defined function, we can also use a [lambda expression](https://en.cppreference.com/w/cpp/language/lambda) to quickly define the task on-the-fly. Rewriting the previous example in terms of a lambda expression, we get:\n\n```cpp\n#include \"BS_thread_pool.hpp\" // BS::thread_pool\n#include <future>             // std::future\n#include <iostream>           // std::cout\n\nint main()\n{\n    BS::thread_pool pool;\n    std::future<int> my_future = pool.submit_task([]{ return 42; });\n    std::cout << my_future.get() << '\\n';\n}\n```\n\nHere, the lambda expression `[]{ return 42; }` has two parts:\n\n1. An empty capture clause, denoted by `[]`. This signifies to the compiler that a lambda expression is being defined.\n2. A code block `{ return 42; }` that simply returns the value `42`.\n\nIt is generally simpler and faster to submit lambda expressions rather than pre-defined functions, especially due to the ability to capture local variables, which we will discuss in the next section.\n\nOf course, tasks do not have to return values. In the following example, we submit a function with no return value and then using the future to wait for it to finish executing:\n\n```cpp\n#include \"BS_thread_pool.hpp\" // BS::thread_pool\n#include <chrono>             // std::chrono\n#include <future>             // std::future\n#include <iostream>           // std::cout\n#include <thread>             // std::this_thread\n\nint main()\n{\n    BS::thread_pool pool;\n    const std::future<void> my_future = pool.submit_task(\n        []\n        {\n            std::this_thread::sleep_for(std::chrono::milliseconds(500));\n        });\n    std::cout << \"Waiting for the task to complete... \";\n    my_future.wait();\n    std::cout << \"Done.\" << '\\n';\n}\n```\n\nHere we split the lambda into multiple lines to make it more readable. The command `std::this_thread::sleep_for(std::chrono::milliseconds(500))` instructs the task to simply sleep for 500 milliseconds, simulating a computationally-intensive task.\n\n### Submitting tasks with arguments and receiving a future\n\nAs stated in the previous section, tasks submitted using `submit_task()` cannot have any arguments. However, it is easy to submit tasks with argument either by wrapping the function in a lambda or using lambda captures directly. The following is an example of submitting a pre-defined function with arguments by wrapping it in a lambda:\n\n```cpp\n#include \"BS_thread_pool.hpp\" // BS::thread_pool\n#include <future>             // std::future\n#include <iostream>           // std::cout\n\ndouble multiply(const double lhs, const double rhs)\n{\n    return lhs * rhs;\n}\n\nint main()\n{\n    BS::thread_pool pool;\n    std::future<double> my_future = pool.submit_task(\n        []\n        {\n            return multiply(6, 7);\n        });\n    std::cout << my_future.get() << '\\n';\n}\n```\n\nAs you can see, to pass the arguments to `multiply()` we simply called `multiply(6, 7)` explicitly inside a lambda. If the arguments are not literals, we can use the lambda capture clause to capture the arguments from the local scope:\n\n```cpp\n#include \"BS_thread_pool.hpp\" // BS::thread_pool\n#include <future>             // std::future\n#include <iostream>           // std::cout\n\ndouble multiply(const double lhs, const double rhs)\n{\n    return lhs * rhs;\n}\n\nint main()\n{\n    BS::thread_pool pool;\n    constexpr double first = 6;\n    constexpr double second = 7;\n    std::future<double> my_future = pool.submit_task(\n        [first, second]\n        {\n            return multiply(first, second);\n        });\n    std::cout << my_future.get() << '\\n';\n}\n```\n\nWe could even get rid of the `multiply()` function entirely and just put everything inside a lambda, if desired:\n\n```cpp\n#include \"BS_thread_pool.hpp\" // BS::thread_pool\n#include <future>             // std::future\n#include <iostream>           // std::cout\n\nint main()\n{\n    BS::thread_pool pool;\n    constexpr double first = 6;\n    constexpr double second = 7;\n    std::future<double> my_future = pool.submit_task(\n        [first, second]\n        {\n            return first * second;\n        });\n    std::cout << my_future.get() << '\\n';\n}\n```\n\n### Detaching and waiting for tasks\n\nUsually, it is best to submit a task to the queue using `submit_task()`. This allows you to wait for the task to finish and/or get its return value later. However, sometimes a future is not needed, for example when you just want to \"set and forget\" a certain task, or if the task already communicates with the main thread or with other tasks without using futures, such as via condition variables.\n\nIn such cases, you may wish to avoid the overhead involved in assigning a future to the task, in order to increase performance. This is called \"detaching\" the task, as the task detaches from the main thread and runs independently.\n\nDetaching tasks is done using the `detach_task()` member function, which allows you to detach a task to the queue without generating a future for it. As with `submit_task()`, the task must have no arguments, but you can pass arguments by wrapping it in a lambda, as shown in the previous section. However, tasks executed via `detach_task()` cannot have a return value, as there would be no way for the main thread to retrieve that value.\n\nSince `detach_task()` does not return a future, there is no built-in way for the user to know when the task finishes executing. You must manually ensure that the task finishes executing before trying to use anything that depends on its output. Otherwise, bad things will happen!\n\n`BS::thread_pool` provides the member function `wait()` to facilitate waiting for all the tasks in the queue to complete, whether they were detached or submitted with a future. The `wait()` member function works similarly to the `wait()` member function of `std::future`. Consider, for example, the following code:\n\n```cpp\n#include \"BS_thread_pool.hpp\" // BS::thread_pool\n#include <chrono>             // std::chrono\n#include <iostream>           // std::cout\n#include <thread>             // std::this_thread\n\nint main()\n{\n    BS::thread_pool pool;\n    int result = 0;\n    pool.detach_task(\n        [&result]\n        {\n            std::this_thread::sleep_for(std::chrono::milliseconds(100));\n            result = 42;\n        });\n    std::cout << result << '\\n';\n}\n```\n\nThis program first defines a local variable named `result` and initializes it to `0`. It then detaches a task in the form of a lambda expression. Note that the lambda captures `result` **by reference**, as indicated by the `&` in front of it. This means that the task can modify `result`, and any such modification will be reflected in the main thread.\n\nThe task changes `result` to `42`, but it first sleeps for 100 milliseconds. When the main thread prints out the value of `result`, the task has not yet had time to modify its value, since it is still sleeping. Therefore, the program will actually print out the initial value `0`, which is not what we want.\n\nTo wait for the task to complete, we must use the `wait()` member function after detaching it:\n\n```cpp\n#include \"BS_thread_pool.hpp\" // BS::thread_pool\n#include <chrono>             // std::chrono\n#include <iostream>           // std::cout\n#include <thread>             // std::this_thread\n\nint main()\n{\n    BS::thread_pool pool;\n    int result = 0;\n    pool.detach_task(\n        [&result]\n        {\n            std::this_thread::sleep_for(std::chrono::milliseconds(100));\n            result = 42;\n        });\n    pool.wait();\n    std::cout << result << '\\n';\n}\n```\n\nNow the program will print out the value `42`, as expected. Note, however, that `wait()` will wait for **all** the tasks in the queue, including any other tasks that were potentially submitted before or after the one we care about. If we want to wait just for **one** task, `submit_task()` would be a better choice.\n\n### Waiting for submitted or detached tasks with a timeout\n\nSometimes you may wish to wait for the tasks to complete, but only for a certain amount of time, or until a specific point in time. For example, if the tasks have not yet completed after some time, you may wish to let the user know that there is a delay.\n\nFor tasks submitted with futures using `submit_task()`, this can be achieved using two member functions of `std::future`:\n\n* `wait_for()` waits for the task to be completed, but stops waiting after the specified duration, given as an argument of type `std::chrono::duration`, has passed.\n* `wait_until()` waits for the task to be completed, but stops waiting after the specified time point, given as an argument of type `std::chrono::time_point`, has been reached.\n\nIn both cases, the functions will return `std::future_status::ready` if the future is ready, meaning the task is finished and its return value, if any, has been obtained. However, they will return `std::future_status::timeout` if the future is not yet ready when the timeout has expired.\n\nHere is an example:\n\n```cpp\n#include \"BS_thread_pool.hpp\" // BS::thread_pool\n#include <chrono>             // std::chrono\n#include <future>             // std::future\n#include <iostream>           // std::cout\n#include <thread>             // std::this_thread\n\nint main()\n{\n    BS::thread_pool pool;\n    const std::future<void> my_future = pool.submit_task(\n        []\n        {\n            std::this_thread::sleep_for(std::chrono::milliseconds(1000));\n            std::cout << \"Task done!\\n\";\n        });\n    while (true)\n    {\n        if (my_future.wait_for(std::chrono::milliseconds(200)) != std::future_status::ready)\n            std::cout << \"Sorry, the task is not done yet.\\n\";\n        else\n            break;\n    }\n}\n```\n\nThe output should look similar to this:\n\n```none\nSorry, the task is not done yet.\nSorry, the task is not done yet.\nSorry, the task is not done yet.\nSorry, the task is not done yet.\nTask done!\n```\n\nFor detached tasks, since we do not have futures for them, we cannot use this method. However, `BS::thread_pool` has two member functions, also named `wait_for()` and `wait_until()`, which similarly wait for a specified duration or until a specified time point, but do so for **all** tasks (whether submitted or detached). Instead of an `std::future_status`, the thread pool's wait functions returns `true` if all tasks finished running, or `false` if the duration expired or the time point was reached but some tasks are still running.\n\nHere is the same example as above, using `detach_task()` and `pool.wait_for()`:\n\n```cpp\n#include \"BS_thread_pool.hpp\" // BS::thread_pool\n#include <chrono>             // std::chrono\n#include <iostream>           // std::cout\n#include <thread>             // std::this_thread\n\nint main()\n{\n    BS::thread_pool pool;\n    pool.detach_task(\n        []\n        {\n            std::this_thread::sleep_for(std::chrono::milliseconds(1000));\n            std::cout << \"Task done!\\n\";\n        });\n    while (true)\n    {\n        if (!pool.wait_for(std::chrono::milliseconds(200)))\n            std::cout << \"Sorry, the task is not done yet.\\n\";\n        else\n            break;\n    }\n}\n```\n\n### Class member functions as tasks\n\nLet us consider the following program:\n\n```cpp\n#include <iostream> // std::boolalpha, std::cout\n\nclass flag_class\n{\npublic:\n    [[nodiscard]] bool get_flag() const\n    {\n        return flag;\n    }\n\n    void set_flag(const bool arg)\n    {\n        flag = arg;\n    }\n\nprivate:\n    bool flag = false;\n};\n\nint main()\n{\n    flag_class flag_object;\n    flag_object.set_flag(true);\n    std::cout << std::boolalpha << flag_object.get_flag() << '\\n';\n}\n```\n\nThis program creates a new object `flag_object` of the class `flag_class`, sets the flag to `true` using the setter member function `set_flag()`, and then prints out the flag's value using the getter member function `get_flag()`.\n\nWhat if we want to submit the member function `set_flag()` as a task to the thread pool? We can simply wrap the entire statement `flag_object.set_flag(true);` in a lambda, and pass `flag_object` to the lambda by reference, as in the following example:\n\n```cpp\n#include \"BS_thread_pool.hpp\" // BS::thread_pool\n#include <iostream>           // std::boolalpha, std::cout\n\nclass flag_class\n{\npublic:\n    [[nodiscard]] bool get_flag() const\n    {\n        return flag;\n    }\n\n    void set_flag(const bool arg)\n    {\n        flag = arg;\n    }\n\nprivate:\n    bool flag = false;\n};\n\nint main()\n{\n    BS::thread_pool pool;\n    flag_class flag_object;\n    pool.submit_task(\n            [&flag_object]\n            {\n                flag_object.set_flag(true);\n            })\n        .wait();\n    std::cout << std::boolalpha << flag_object.get_flag() << '\\n';\n}\n```\n\nOf course, this will also work with `detach_task()`, if we call `wait()` on the pool itself instead of on the returned future.\n\nNote that in this example, instead of getting a future from `submit_task()` and then waiting for that future, we simply called `wait()` on that future straight away. This is a common way of waiting for a task to complete if we have nothing else to do in the meantime. Note also that we passed `flag_object` by reference to the lambda, since we want to set the flag on that same object, not a copy of it.\n\nAnother thing you might want to do is call a member function from within the object itself, that is, from another member function. This follows a similar syntax, except that you must also capture `this` (i.e. a pointer to the current object) in the lambda. Here is an example:\n\n```cpp\n#include \"BS_thread_pool.hpp\" // BS::thread_pool\n#include <iostream>           // std::boolalpha, std::cout\n\nBS::thread_pool pool;\n\nclass flag_class\n{\npublic:\n    [[nodiscard]] bool get_flag() const\n    {\n        return flag;\n    }\n\n    void set_flag(const bool arg)\n    {\n        flag = arg;\n    }\n\n    void set_flag_to_true()\n    {\n        pool.submit_task(\n                [this]\n                {\n                    set_flag(true);\n                })\n            .wait();\n    }\n\nprivate:\n    bool flag = false;\n};\n\nint main()\n{\n    flag_class flag_object;\n    flag_object.set_flag_to_true();\n    std::cout << std::boolalpha << flag_object.get_flag() << '\\n';\n}\n```\n\nNote that in this example we defined the thread pool as a global object, so that it is accessible outside the `main()` function. Although we could have, in theory, passed a reference to the thread pool in our call to `set_flag_to_true()`, that would be very cumbersome to do if multiple different functions need to use the same thread pool. Defining the thread pool as a global object is common practice, as it allows all functions to access the same thread pool without having to pass it around as an argument.\n\n## Parallelizing loops\n\n### Automatic parallelization of loops\n\nOne of the most common and effective methods of parallelization is splitting a loop into smaller sub-loops and running them in parallel. It is most effective in \"embarrassingly parallel\" computations, such as vector or matrix operations, where each iteration of the loop is completely independent of every other iteration.\n\nFor example, if we are summing up two vectors of 1000 elements each, and we have 10 threads, we could split the summation into 10 blocks of 100 elements each, and run all the blocks in parallel, potentially increasing performance by up to a factor of 10.\n\n`BS::thread_pool` can automatically parallelize loops, making it very easy to implement many parallel algorithms without having to worry about the details. To see how this works, consider the following generic loop:\n\n```cpp\nfor (T i = start; i < end; ++i)\n    loop(i);\n```\n\nwhere:\n\n* `T` is any signed or unsigned integer type.\n* The loop is over the range `[start, end)`, i.e. inclusive of `start` but exclusive of `end`.\n* `loop()` is an operation performed for each loop index `i`, such as modifying an array with `end - start` elements.\n\nThis loop may be automatically parallelized and submitted to the thread pool's queue using the member function `submit_loop()`, which has the follows syntax:\n\n```cpp\npool.submit_loop(start, end, loop, num_blocks);\n```\n\nwhere:\n\n* `start` is the first index in the range.\n* `end` is the index after the last index in the range, such that the full range is `[start, end)`. In other words, the loop will be equivalent to the generic loop above, but parallelized. Note that if `end <= start`, nothing will happen; the loop cannot go backwards.\n* `loop()` is the function that should run in every iteration of the loop. It must take exactly one argument, the loop index. It cannot have a return value, as it will be executed multiple times by each task, so a return value would not make sense.\n* `num_blocks` is the number of blocks of the form `[a, b)` to split the loop into. For example, if the range is `[0, 9)` and there are 3 blocks, then the blocks will be the ranges `[0, 3)`, `[3, 6)`, and `[6, 9)`. This argument can be omitted, in which case the number of blocks will be the number of threads in the pool.\n\nThe thread pool's internal algorithm ensures that each of the blocks has one of two sizes, differing by 1, with the larger blocks always first, so that the tasks are as evenly distributed as possible, to optimize performance. For example, if the range `[0, 100)` is split into 15 blocks, the result will be 10 blocks of size 7, which will be submitted first, and 5 blocks of size 6.\n\nEach block will be submitted to the thread pool's queue as a separate task. Therefore, a loop that is split into 3 blocks will be split into 3 individual tasks, which may run in parallel. If there is only one block, then the entire loop will run as one task, and no parallelization will take place.\n\nTo parallelize the generic loop above, we use the following commands:\n\n```cpp\nBS::multi_future<void> loop_future = pool.submit_loop(start, end, loop, num_blocks);\nloop_future.wait();\n```\n\n`submit_loop()` returns an object of the helper class [`BS::multi_future<T>`](#more-about-bsmulti_future). This is essentially a specialization of `std::vector<std::future<T>>` with additional member functions. Each of the `num_blocks` blocks will have an `std::future<T>` assigned to it, and all these futures will be stored inside the returned `BS::multi_future<T>`. When `loop_future.wait()` is called, the main thread will wait until **all** tasks generated by `submit_loop()` finish executing, and **only** those tasks - not any other tasks that also happen to be in the queue. This is essentially the role of the `BS::multi_future<T>` class: to wait for a specific **group of tasks**, in this case the tasks running the loop blocks.\n\nAs a simple example, the following code calculates and prints a table of squares of all integers from 0 to 99:\n\n```cpp\n#include <cstddef>  // std::size_t\n#include <iomanip>  // std::setw\n#include <iostream> // std::cout\n\nint main()\n{\n    constexpr std::size_t max = 100;\n    std::size_t squares[max];\n    for (std::size_t i = 0; i < max; ++i)\n        squares[i] = i * i;\n    for (std::size_t i = 0; i < max; ++i)\n        std::cout << std::setw(2) << i << \"^2 = \" << std::setw(4) << squares[i] << ((i % 5 != 4) ? \" | \" : \"\\n\");\n}\n```\n\nWe can parallelize it as follows:\n\n```cpp\n#include \"BS_thread_pool.hpp\" // BS::multi_future, BS::thread_pool\n#include <cstddef>            // std::size_t\n#include <iomanip>            // std::setw\n#include <iostream>           // std::cout\n\nint main()\n{\n    BS::thread_pool pool(10);\n    constexpr std::size_t max = 100;\n    std::size_t squares[max];\n    const BS::multi_future<void> loop_future = pool.submit_loop(0, max,\n        [&squares](const std::size_t i)\n        {\n            squares[i] = i * i;\n        });\n    loop_future.wait();\n    for (std::size_t i = 0; i < max; ++i)\n        std::cout << std::setw(2) << i << \"^2 = \" << std::setw(4) << squares[i] << ((i % 5 != 4) ? \" | \" : \"\\n\");\n}\n```\n\nSince there are 10 threads, and we omitted the `num_blocks` argument, the loop will be divided into 10 blocks, each calculating 10 squares.\n\nAs a side note, notice that here we parallelized the calculation of the squares, but we did not parallelize printing the results. This is for two reasons:\n\n1. We want to print out the squares in ascending order, and we have no guarantee that the blocks will be executed in the correct order. This is very important; you must never expect that the parallelized loop will execute at the same order as the non-parallelized loop.\n2. If we did print out the squares from within the parallel tasks, we would get a huge mess, since all 10 blocks would print to the standard output at once. [Later](#synchronizing-printing-to-a-stream-with-bssynced_stream) we will see how to synchronize printing to a stream from multiple tasks at the same time.\n\n### Optimizing the number of blocks\n\nThe most important factor to consider when parallelizing loops is the number of blocks `num_blocks` to split the loop into. Naively, it may seem that the number of blocks should simply be equal to the number of threads in the pool, but that is usually **not** the optimal choice. Inevitably, some blocks will finish before other blocks; if there is only one block per thread, then any threads that have already finished executing their blocks will remain idle until the rest of the blocks are done, wasting many CPU cycles.\n\nIt is therefore generally better to use a larger number of blocks than the number of threads, to ensure that all threads work at maximum capacity. On the other hand, parallelization with too many blocks will eventually suffer from diminishing returns due to increased overhead. A good rule of thumb is to use a number of blocks equal to the square of the number of threads, but this is not necessarily the optimal number in all cases.\n\nIn the end, the optimal number of blocks will always depend on the specific algorithm being parallelized and the total number of indices in the loop, and may differ between different compilers, operating systems, and hardware configurations. For best performance, it is strongly recommended to do your own benchmarks to find the optimal number of blocks for your particular use case; see the [benchmarks code in the bundled test program](#performance-tests) for an example of how to do this.\n\nFinally, note that the discussion here only pertains to situations where the parallelized loop is the only thing running in the pool. If there are many other tasks running in parallel from other sources, then you probably do not need to worry about idle time, since the threads will be kept busy by the other tasks anyway.\n\n### Common index types\n\nLet us now consider a subtlety regarding the types of the start and end indices. In the example [above](#automatic-parallelization-of-loops), the start index is `0`, which is of type `int`, while the end index is `max`, which is of type `std::size_t`. These two types are not compatible, as they are both of different signedness and (on a 64-bit system) of different bit width. In such cases, `submit_loop()` uses a custom type trait `BS::common_index_type` to determine the common type of the indices.\n\nThe common index type of two signed integers or two unsigned integers is the larger of the integers, while the common index type of a signed and an unsigned integer is a signed integer that can hold the full ranges of both integers. (This is in contrast to [`std::common_type`](https://en.cppreference.com/w/cpp/types/common_type), which would choose the unsigned integer in the latter case, causing a loop with a negative start index and an unsigned end index to fail due to integer overflow.)\n\nThe exception to this rule is when one of the integers is a 64-bit unsigned integer, and the other is a signed integer (of any bit width), since there is no fundamental signed type that can hold the full ranges of both integers. In this case, we choose a 64-bit unsigned integer as the common index type, since the most common scenario where this might happen is when the indices go from `0` to an index of type `std::size_t` - as in our example in the previous section.\n\nHowever, it is important to note that this will fail if the first index is in fact negative. Therefore, **only** in the edge case where one index is a negative integer and the other is of an unsigned 64-bit integer type such as `std::size_t`, the user must cast both indices explicitly to the desired common type. In all other cases, this is handled automatically behind the scenes using `BS::common_index_type`.\n\n### Parallelizing loops without futures\n\nJust as in the case of [`detach_task()`](#detaching-and-waiting-for-tasks) vs. [`submit_task()`](#submitting-tasks-with-no-arguments-and-receiving-a-future), sometimes you may want to parallelize a loop, but you don't need it to return a `BS::multi_future`. In this case, you can save the overhead of generating the futures (which can be significant, depending on the number of blocks) by using `detach_loop()` instead of `submit_loop()`, with the same arguments.\n\nFor example, we could detach the loop of squares example above as follows:\n\n```cpp\n#include \"BS_thread_pool.hpp\" // BS::thread_pool\n#include <cstddef>            // std::size_t\n#include <iomanip>            // std::setw\n#include <iostream>           // std::cout\n\nint main()\n{\n    BS::thread_pool pool(10);\n    constexpr std::size_t max = 100;\n    std::size_t squares[max];\n    pool.detach_loop(0, max,\n        [&squares](const std::size_t i)\n        {\n            squares[i] = i * i;\n        });\n    pool.wait();\n    for (std::size_t i = 0; i < max; ++i)\n        std::cout << std::setw(2) << i << \"^2 = \" << std::setw(4) << squares[i] << ((i % 5 != 4) ? \" | \" : \"\\n\");\n}\n```\n\n**Warning:** Since `detach_loop()` does not return a `BS::multi_future`, there is no built-in way for the user to know when the loop finishes executing. You must use either [`wait()`](#detaching-and-waiting-for-tasks) as we did here, or some other method such as condition variables, to ensure that the loop finishes executing before trying to use anything that depends on its output. Otherwise, bad things will happen! If the loop is the only thing running in the pool, then generally `detach_loop()` followed by `wait()` is the optimal choice in terms of performance.\n\n### Parallelizing individual indices vs. blocks\n\nWe have seen that `detach_loop()` and `submit_loop()` execute the function `loop(i)` for each index `i` in the loop. However, behind the scenes, the loop is split into blocks, and each block executes the `loop()` function multiple times. Each block has an internal loop of the form (where `T` is the type of the indices):\n\n```cpp\nfor (T i = start; i < end; ++i)\n    loop(i);\n```\n\nThe `start` and `end` indices of each block are determined automatically by the pool. For example, in the previous section, the loop from 0 to 100 was split into 10 blocks of 10 indices each: `start = 0` to `end = 10`, `start = 10` to `end = 20`, and so on; the blocks are not inclusive of the last index, since the `for` loop has the condition `i < end` and not `i <= end`.\n\nHowever, this also means that the `loop()` function is executed multiple times per block. This generates additional overhead due to the multiple function calls. For short loops, this should not affect performance. However, for very long loops, with millions of indices, the performance cost may be significant.\n\nFor this reason, the thread pool library provides two additional member functions for parallelizing loops: `detach_blocks()` and `submit_blocks()`. While `detach_loop()` and `submit_loop()` execute a function `loop(i)` once per index but multiple times per block, `detach_blocks()` and `submit_blocks()` execute a function `block(start, end)` only once per block.\n\nThe main advantage of this method is increased performance, but the main disadvantage is slightly more complicated code. In particular, the user must define the loop from `start` to `end` manually within each block, ensuring that all the indices in the block are handled. Here is the previous example again, this time using `detach_blocks()`:\n\n```cpp\n#include \"BS_thread_pool.hpp\" // BS::thread_pool\n#include <cstddef>            // std::size_t\n#include <iomanip>            // std::setw\n#include <iostream>           // std::cout\n\nint main()\n{\n    BS::thread_pool pool(10);\n    constexpr std::size_t max = 100;\n    std::size_t squares[max];\n    pool.detach_blocks(0, max,\n        [&squares](const std::size_t start, const std::size_t end)\n        {\n            for (std::size_t i = start; i < end; ++i)\n                squares[i] = i * i;\n        });\n    pool.wait();\n    for (std::size_t i = 0; i < max; ++i)\n        std::cout << std::setw(2) << i << \"^2 = \" << std::setw(4) << squares[i] << ((i % 5 != 4) ? \" | \" : \"\\n\");\n}\n```\n\nNote how the block function takes two arguments, and includes the internal loop. Also, since we are using `detach_blocks()`, we must wait for the loop to finish executing using `wait()`. Alternatively, we could have used `submit_blocks()` and waited on the returned `BS::multi_future<void>` object.\n\nGenerally, compiler optimizations should be able to make `detach_loop()` and `submit_loop()` perform roughly the same as `detach_blocks()` and `submit_blocks()`. However, `detach_blocks()` and `submit_blocks()` are always going to be inherently faster, at the cost of being slightly more complicated to use. In addition, having low-level control of each block can allow for further optimizations, such as allocating resources per block instead of per index. As usual, you should perform your own benchmarks to see which option works best for your particular use case.\n\n### Loops with return values\n\nAs mentioned above, unlike `submit_task()`, the member function `submit_loop()` only takes loop functions with no return value. The reason is that each block is running the loop function multiple times, so a return value would not make sense. In contrast, `submit_blocks()` allows the block function to have a return value, as each block can return a unique value.\n\nThe block function will be executed once for each block, but the blocks are managed by the thread pool, with the user only able to select the number of blocks, but not the range of each block. Therefore, there is limited usability in returning one value per block. However, for cases where this is desired, such as for summation or some sorting algorithms, `submit_blocks()` does accept functions with return values, in which case it returns a `BS::multi_future<T>` object where `T` is the type of the return value.\n\nHere's an example of a function template summing all elements of type `T` in a given range:\n\n```cpp\n#include \"BS_thread_pool.hpp\" // BS::multi_future, BS::thread_pool\n#include <cstdint>            // std::uint64_t\n#include <future>             // std::future\n#include <iostream>           // std::cout\n\nBS::thread_pool pool;\n\ntemplate <typename T>\nT sum(T min, T max)\n{\n    BS::multi_future<T> loop_future = pool.submit_blocks(\n        min, max + 1,\n        [](const T start, const T end)\n        {\n            T block_total = 0;\n            for (T i = start; i < end; ++i)\n                block_total += i;\n            return block_total;\n        },\n        100);\n    T result = 0;\n    for (std::future<T>& future : loop_future)\n        result += future.get();\n    return result;\n}\n\nint main()\n{\n    std::cout << sum<std::uint64_t>(1, 1'000'000);\n}\n```\n\nNote that we needed to specify the type `T` explicitly as `std::uint64_t`, that is, an unsigned 64-bit integer, as the result, 500,000,500,000, would not fit in a 32-bit integer.\n\nHere we used the fact that `BS::multi_future<T>` is a specialization of `std::vector<std::future<T>>`, so we can use a range-based `for` loop to iterate over the futures, and use the `get()` member function of each future to get its value. The values of the futures will be the partial sums from each block, so when we add them up, we will get the total sum. Note that we divided the loop into 100 blocks, so there will be 100 futures in total, each with the partial sum of 10,000 numbers.\n\nThe range-based `for` loop will likely start before the loop finished executing, and each time it calls a future, it will get the value of that future if it is ready, or it will wait until the future is ready and then get the value. This increases performance, since we can start summing the results without waiting for the entire loop to finish executing first - we only need to wait for individual blocks.\n\nIf we did want to wait until the entire loop finishes before summing the results, we could have used the `get()` member function of the `BS::multi_future<T>` object itself, which returns an `std::vector<T>` with the values obtained from each future. In that case, the sum could be obtained after calling `submit_blocks()`, for example using `std::reduce`, as follows:\n\n```cpp\n#include \"BS_thread_pool.hpp\" // BS::multi_future, BS::thread_pool\n#include <cstdint>            // std::uint64_t\n#include <iostream>           // std::cout\n#include <numeric>            // std::reduce\n#include <vector>             // std::vector\n\nBS::thread_pool pool;\n\ntemplate <typename T>\nT sum(T min, T max)\n{\n    BS::multi_future<T> loop_future = pool.submit_blocks(\n        min, max + 1,\n        [](const T start, const T end)\n        {\n            T block_total = 0;\n            for (T i = start; i < end; ++i)\n                block_total += i;\n            return block_total;\n        },\n        100);\n    std::vector<T> partial_sums = loop_future.get();\n    T result = std::reduce(partial_sums.begin(), partial_sums.end());\n    return result;\n}\n\nint main()\n{\n    std::cout << sum<std::uint64_t>(1, 1'000'000);\n}\n```\n\n### Parallelizing sequences\n\nThe member functions `detach_loop()`, `submit_loop()`, `detach_blocks()`, and `submit_blocks()` parallelize a loop by splitting it into blocks, and submitting each block as an individual task to the queue, with each such task iterating over all the indices in the corresponding block's range, which can be numerous. However, sometimes we have a loop with a small number of indices, or more generally, a sequence of tasks enumerated by some index. In such cases, we can avoid the overhead of splitting into blocks and simply submit each individual index as its own independent task to the pool's queue.\n\nThis can be done with `detach_sequence()` and `submit_sequence()`. The syntax of these functions is similar to `detach_loop()` and `submit_loop()`, except that they don't have the `num_blocks` argument at the end. The sequence function must take only one argument, the index.\n\nAs usual, `detach_sequence()` detaches the tasks and does not return a future, so you must use `wait()` if you need to wait for the entire sequence to finish executing, while `submit_sequence()` returns a `BS::multi_future`. If the tasks in the sequence return values, then the futures will contain those values, otherwise they will be `void` futures.\n\nHere is a simple example, where each task in the sequence calculates the factorial of its index:\n\n```cpp\n#include \"BS_thread_pool.hpp\" // BS::multi_future, BS::thread_pool\n#include <cstdint>            // std::uint64_t\n#include <iostream>           // std::cout\n#include <vector>             // std::vector\n\nstd::uint64_t factorial(const std::uint64_t n)\n{\n    std::uint64_t result = 1;\n    for (std::uint64_t i = 2; i <= n; ++i)\n        result *= i;\n    return result;\n}\n\nint main()\n{\n    BS::thread_pool pool;\n    constexpr std::uint64_t max = 20;\n    BS::multi_future<std::uint64_t> sequence_future = pool.submit_sequence(0, max + 1, factorial);\n    std::vector<std::uint64_t> factorials = sequence_future.get();\n    for (std::uint64_t i = 0; i < max + 1; ++i)\n        std::cout << i << \"! = \" << factorials[i] << '\\n';\n}\n```\n\nNote how the factorials of each index are stored in the `BS::multi_future`, and can be obtained as a vector using `get()`; each element of the vector is equal to the factorial of the element's index, calculated by its own individual task in the sequence.\n\n**Warning:** Since each index in the sequence will be submitted as a separate task, `detach_sequence()` and `submit_sequence()` should only be used if the number of indices is small (say, within 1-2 orders of magnitude of the number of threads), and each index performs a substantial computation on its own. If you submit a sequence of 1 million indices, each performing a 1 ms calculation, the overhead of submitting each index as a separate task would far outweigh the benefits of parallelization.\n\n### More about `BS::multi_future`\n\nThe helper class `BS::multi_future<T>`, which we have been using throughout this section, provides a convenient way to collect and access groups of futures. While a `BS::multi_future<T>` object is created automatically by the pool when parallelizing loops, you can also use it to store futures manually, such as those obtained from `submit_task()` or by other means. `BS::multi_future<T>` is a specialization of `std::vector<std::future<T>>`, so it should be used in a similar way:\n\n* When you create a new `BS::multi_future<T>` object, either use the default constructor to create an empty object and add futures to it later, or pass the desired number of futures to the constructor in advance.\n* Use the `[]` operator to access the future at a specific index, or the `push_back()` member function to append a new future to the list. (If the number of futures is known in advance, you should use `reserve()` to allocate memory for all of them first, and only then `push_back()` the individual futures, otherwise memory will have to be reallocated multiple times, which is very inefficient.)\n* The `size()` member function tells you how many futures are currently stored in the object.\n\nHowever, `BS::multi_future<T>` also has additional member functions that are aimed specifically at handling futures:\n\n* Once all the futures are stored, you can use `wait()` to wait for all of them at once or `get()` to get an `std::vector<T>` with the results from all of them.\n* You can check how many futures are ready using `ready_count()`.\n* You can check if all the stored futures are valid using `valid()`.\n* You can wait for all the stored futures for a specific duration with `wait_for()` or wait until a specific time with `wait_until()`. These functions return `true` if all futures have been waited for before the duration expired or the time point was reached, and `false` otherwise.\n\nAside from using `BS::multi_future<T>` to track the execution of parallelized loops, it can also be used, for example, whenever you have several different groups of tasks and you want to track the execution of each group individually.\n\n## Utility classes\n\n### Synchronizing printing to a stream with `BS::synced_stream`\n\nWhen printing to an output stream from multiple threads in parallel, the output may become garbled. For example, try running this code:\n\n```cpp\n#include \"BS_thread_pool.hpp\" // BS::thread_pool\n#include <iostream>           // std::cout\n\nBS::thread_pool pool;\n\nint main()\n{\n    pool.submit_sequence(0, 5,\n            [](const unsigned int i)\n            {\n                std::cout << \"Task no. \" << i << \" executing.\\n\";\n            })\n        .wait();\n}\n```\n\nThe output will be a mess similar to this:\n\n```none\nTask no. Task no. Task no. 3 executing.\n0 executing.\nTask no. 41 executing.\nTask no. 2 executing.\n executing.\n```\n\nThe reason is that, although each **individual** insertion to `std::cout` is thread-safe, there is no mechanism in place to ensure subsequent insertions from the same thread are printed contiguously.\n\nThe thread pool utility class `BS::synced_stream` is designed to eliminate such synchronization issues. The stream to print to should be passed as a constructor argument. If no argument is supplied, `std::cout` will be used:\n\n```cpp\n// Construct a synced stream that will print to std::cout.\nBS::synced_stream sync_out;\n// Construct a synced stream that will print to the output stream my_stream.\nBS::synced_stream sync_out(my_stream);\n```\n\nThe member function `print()` takes an arbitrary number of arguments, which are inserted into the stream one by one, in the order they were given. `println()` does the same, but also prints a newline character `\\n` at the end, for convenience. A mutex is used to synchronize this process, so that any other calls to `print()` or `println()` using the same `BS::synced_stream` object must wait until the previous call has finished.\n\nAs an example, this code:\n\n```cpp\n#include \"BS_thread_pool.hpp\" // BS::synced_stream, BS::thread_pool\n\nBS::synced_stream sync_out;\nBS::thread_pool pool;\n\nint main()\n{\n    pool.submit_sequence(0, 5,\n            [](const unsigned int i)\n            {\n                sync_out.println(\"Task no. \", i, \" executing.\");\n            })\n        .wait();\n}\n```\n\nWill print out:\n\n```none\nTask no. 0 executing.\nTask no. 1 executing.\nTask no. 2 executing.\nTask no. 3 executing.\nTask no. 4 executing.\n```\n\n**Warning:** Always create the `BS::synced_stream` object **before** the `BS::thread_pool` object, as we did in this example. When the `BS::thread_pool` object goes out of scope, it waits for the remaining tasks to be executed. If the `BS::synced_stream` object goes out of scope before the `BS::thread_pool` object, then any tasks using the `BS::synced_stream` will crash. Since objects are destructed in the opposite order of construction, creating the `BS::synced_stream` object before the `BS::thread_pool` object ensures that the `BS::synced_stream` is always available to the tasks, even while the pool is destructing.\n\nMost stream manipulators defined in the headers `<ios>` and `<iomanip>`, such as `std::setw` (set the character width of the next output), `std::setprecision` (set the precision of floating point numbers), and `std::fixed` (display floating point numbers with a fixed number of digits), can be passed as arguments to `print()` and `println()`, and will have the same effect as inserting them to the associated stream.\n\nThe only exceptions are the flushing manipulators `std::endl` and `std::flush`, which will not work because the compiler will not be able to figure out which template specializations to use. Instead, use `BS::synced_stream::endl` and `BS::synced_stream::flush`. Here is an example:\n\n```cpp\n#include \"BS_thread_pool.hpp\" // BS::synced_stream, BS::thread_pool\n#include <cmath>              // std::sqrt\n#include <iomanip>            // std::setprecision, std::setw\n#include <ios>                // std::fixed\n\nBS::synced_stream sync_out;\nBS::thread_pool pool;\n\nint main()\n{\n    sync_out.print(std::setprecision(10), std::fixed);\n    pool.submit_sequence(0, 16,\n            [](const unsigned int i)\n            {\n                sync_out.print(\"The square root of \", std::setw(2), i, \" is \", std::sqrt(i), \".\", BS::synced_stream::endl);\n            })\n        .wait();\n}\n```\n\nNote, however, that `BS::synced_stream::endl` should only be used if flushing is desired; otherwise, a newline character should be used instead. As with `std::endl`, using `BS::synced_stream::endl` too often will cause a performance hit, as it will force the stream to flush the buffer every time it is called.\n\nIf desired, `BS::synced_stream` can also synchronize printing into more than one stream at a time. To facilitate this, we can pass a list of output streams to the constructor. For example, the following program will print the same output to both `std::cout` and a log file:\n\n```cpp\n#include \"BS_thread_pool.hpp\" // BS::synced_stream, BS::thread_pool\n#include <fstream>            // std::ofstream\n#include <iostream>           // std::cout\n\nBS::thread_pool pool;\n\nint main()\n{\n    std::ofstream log_file(\"task.log\");\n    BS::synced_stream sync_out(std::cout, log_file);\n    pool.submit_sequence(0, 5,\n            [&sync_out](const unsigned int i)\n            {\n                sync_out.println(\"Task no. \", i, \" executing.\");\n            })\n        .wait();\n}\n```\n\nNote that we must wait on the future before the `main()` function ends, as otherwise the log file may be destructed before the tasks finish executing. If we used `detach_sequence()`, which does not return a future, we would have to call `pool.wait()` in the last line.\n\nIn this example we did not create the `BS::synced_stream` as a global object, since we wanted to pass the log file as a stream to the constructor. However, it is also possible to add streams to or remove streams from an existing `BS::synced_stream` object using the member functions `add_stream()` and `remove_stream()`. For example, in the following program, we create a `BS::synced_stream` global object with the default constructor, so that it prints to `std::cout`, but then we change out minds, remove `std::cout` from the list of streams, and add a log file instead:\n\n```cpp\n#include \"BS_thread_pool.hpp\" // BS::synced_stream, BS::thread_pool\n#include <fstream>            // std::ofstream\n#include <iostream>           // std::cout\n\nBS::synced_stream sync_out;\nBS::thread_pool pool;\n\nint main()\n{\n    std::ofstream log_file(\"task.log\");\n    sync_out.remove_stream(std::cout);\n    sync_out.add_stream(log_file);\n    pool.submit_sequence(0, 5,\n            [](const unsigned int i)\n            {\n                sync_out.println(\"Task no. \", i, \" executing.\");\n            })\n        .wait();\n}\n```\n\nIt is common practice to create a global `BS::synced_stream` object, so that it can be accessed from anywhere in the program, without having to pass it to every function that might want to print something to the stream. However, if you also have a global `BS::thread_pool` object, you must always make sure to define the global `BS::synced_stream` object **before** the global `BS::thread_pool` object, for the reasons explained in the warning above.\n\nInternally, `BS::synced_stream` keeps the streams in an `std::vector<std::ostream*>`. The order in which the streams are added is also the order in which they will be printed to. For more precise control, you can use the member function `get_streams()` to get a reference to this vector, and manipulate it directly as you see fit.\n\n### Synchronizing tasks with `BS::counting_semaphore` and `BS::binary_semaphore`\n\nThe thread pool library provides two utility classes, `BS::counting_semaphore` and `BS::binary_semaphore`, which offer versatile synchronization primitives that can be used to synchronize tasks in a variety of ways. These classes are equivalent to the C&plus;&plus;20 `std::counting_semaphore` and `std::binary_semaphore`, respectively, but are offered in the library as convenience polyfills for projects based on C&plus;&plus;17. If C&plus;&plus;20 features are available, the polyfills are not used, and instead are just aliases for the standard library classes.\n\nSince `BS::counting_semaphore` and `BS::binary_semaphore` are identical in functionality to their standard library counterparts, we will not explain how to use them here. Instead, the user is referred to [cppreference.com](https://en.cppreference.com/w/cpp/thread/counting_semaphore).\n\n## Managing tasks\n\n### Monitoring the tasks\n\nSometimes you may wish to monitor what is happening with the tasks you submitted to the pool. This may be done using these three member functions:\n\n* `get_tasks_queued()` gets the number of tasks currently waiting in the queue to be executed.\n* `get_tasks_running()` gets the number of tasks currently being executed by the threads.\n* `get_tasks_total()` gets the total number of unfinished tasks: either still in the queue, or being executed by a thread.\n\nNote that `get_tasks_total() == get_tasks_queued() + get_tasks_running()`. These functions are demonstrated in the following program:\n\n```cpp\n#include \"BS_thread_pool.hpp\" // BS::synced_stream, BS::thread_pool\n#include <chrono>             // std::chrono\n#include <thread>             // std::this_thread\n\nBS::synced_stream sync_out;\nBS::thread_pool pool(4);\n\nvoid sleep_half_second(const unsigned int i)\n{\n    std::this_thread::sleep_for(std::chrono::milliseconds(500));\n    sync_out.println(\"Task \", i, \" done.\");\n}\n\nvoid monitor_tasks()\n{\n    sync_out.println(pool.get_tasks_total(), \" tasks total, \", pool.get_tasks_running(), \" tasks running, \", pool.get_tasks_queued(), \" tasks queued.\");\n}\n\nint main()\n{\n    pool.wait();\n    pool.detach_sequence(0, 12, sleep_half_second);\n    monitor_tasks();\n    std::this_thread::sleep_for(std::chrono::milliseconds(750));\n    monitor_tasks();\n    std::this_thread::sleep_for(std::chrono::milliseconds(500));\n    monitor_tasks();\n    std::this_thread::sleep_for(std::chrono::milliseconds(500));\n    monitor_tasks();\n    pool.wait();\n}\n```\n\nAssuming you have at least 4 hardware threads (so that 4 tasks can run concurrently), the output should be similar to:\n\n```none\n12 tasks total, 0 tasks running, 12 tasks queued.\nTask 0 done.\nTask 1 done.\nTask 2 done.\nTask 3 done.\n8 tasks total, 4 tasks running, 4 tasks queued.\nTask 4 done.\nTask 5 done.\nTask 6 done.\nTask 7 done.\n4 tasks total, 4 tasks running, 0 tasks queued.\nTask 8 done.\nTask 9 done.\nTask 10 done.\nTask 11 done.\n0 tasks total, 0 tasks running, 0 tasks queued.\n```\n\nThe reason we called `pool.wait()` in the beginning is that when the thread pool is created, an initialization task runs in each thread, so if we don't wait, the first line would say there are 16 tasks in total, including the 4 initialization tasks. See [below](#thread-initialization-functions) for more details. Of course, we also called `pool.wait()` at the end to ensure that all tasks have finished executing before the program ends.\n\n### Purging tasks\n\nConsider a situation where the user cancels a multithreaded operation while it is still ongoing. Perhaps the operation was split into multiple tasks, and half of the tasks are currently being executed by the pool's threads, but the other half are still waiting in the queue.\n\nThe thread pool cannot terminate the tasks that are already running, as C&plus;&plus; does not provide that functionality (and in any case, abruptly terminating a task while it's running could have extremely bad consequences, such as memory leaks and data corruption). However, the tasks that are still waiting in the queue can be purged using the `purge()` member function.\n\nOnce `purge()` is called, any tasks still waiting in the queue will be discarded, and will never be executed by the threads. Please note that there is no way to restore the purged tasks; they are gone forever!\n\nConsider for example the following program:\n\n```cpp\n#include \"BS_thread_pool.hpp\" // BS::synced_stream, BS::thread_pool\n#include <chrono>             // std::chrono\n#include <thread>             // std::this_thread\n\nBS::synced_stream sync_out;\nBS::thread_pool pool(4);\n\nint main()\n{\n    pool.detach_sequence(0, 8,\n        [](const unsigned int i)\n        {\n            std::this_thread::sleep_for(std::chrono::milliseconds(100));\n            sync_out.println(\"Task \", i, \" done.\");\n        });\n    std::this_thread::sleep_for(std::chrono::milliseconds(50));\n    pool.purge();\n    pool.wait();\n}\n```\n\nThe program submit 8 tasks to the queue. Each task waits 100 milliseconds and then prints a message. The thread pool has 4 threads, so it will execute the first 4 tasks in parallel, and then the remaining 4. We wait 50 milliseconds, to ensure that the first 4 tasks have all started running. Then we call `purge()` to purge the remaining 4 tasks. As a result, these tasks never get executed. However, since the first 4 tasks are still running when `purge()` is called, they will finish uninterrupted; `purge()` only discards tasks that have not yet started running. The output of the program therefore only contains the messages from the first 4 tasks:\n\n```none\nTask 0 done.\nTask 1 done.\nTask 2 done.\nTask 3 done.\n```\n\nPlease note that, as explained above, the thread pool cannot terminate running tasks on its own. If you need to do that, you must incorporate a mechanism into the task itself that will terminate the task safely. For example, you could create an atomic flag that the task checks periodically, terminating itself if the flag is set. Here is a simple example:\n\n```cpp\n#include \"BS_thread_pool.hpp\" // BS::synced_stream, BS::thread_pool\n#include <chrono>             // std::chrono\n#include <thread>             // std::this_thread\n\nBS::synced_stream sync_out;\nBS::thread_pool pool(4);\n\nint main()\n{\n    std::atomic<bool> stop_flag = false;\n    pool.detach_sequence(0, 8,\n        [&stop_flag](const unsigned int i)\n        {\n            std::this_thread::sleep_for(std::chrono::milliseconds(100));\n            if (stop_flag)\n                return;\n            sync_out.println(\"Task \", i, \" done.\");\n        });\n    std::this_thread::sleep_for(std::chrono::milliseconds(50));\n    stop_flag = true;\n    pool.purge();\n    pool.wait();\n}\n```\n\nThis program will not print out any output, as the tasks will terminate themselves prematurely when `stop_flag` is set to `true`. In this case, we did not have to call `purge()`, but by doing so we prevented the other 4 tasks from being executed for no reason.\n\n### Exception handling\n\n`submit_task()` catches any exceptions thrown by the submitted task and forwards them to the corresponding future. They can then be caught when invoking the `get()` member function of the future. For example:\n\n```cpp\n#include \"BS_thread_pool.hpp\" // BS::synced_stream, BS::thread_pool\n#include <exception>          // std::exception\n#include <future>             // std::future\n#include <stdexcept>          // std::runtime_error\n\nBS::synced_stream sync_out;\nBS::thread_pool pool;\n\ndouble inverse(const double x)\n{\n    if (x == 0)\n        throw std::runtime_error(\"Division by zero!\");\n    return 1 / x;\n}\n\nint main()\n{\n    constexpr double num = 0;\n    std::future<double> my_future = pool.submit_task(\n        [num]\n        {\n            return inverse(num);\n        });\n    try\n    {\n        const double result = my_future.get();\n        sync_out.println(\"The inverse of \", num, \" is \", result, \".\");\n    }\n    catch (const std::exception& e)\n    {\n        sync_out.println(\"Caught exception: \", e.what());\n    }\n}\n```\n\nThe output will be:\n\n```none\nCaught exception: Division by zero!\n```\n\nHowever, if you change `num` to any non-zero number, no exceptions will be thrown and the inverse will be printed.\n\nIt is important to note that `wait()` does not throw any exceptions; only `get()` does. Therefore, even if your task does not return anything, i.e. your future is an `std::future<void>`, you must still use `get()` on the future obtained from it if you want to catch exceptions thrown by it. Here is an example:\n\n```cpp\n#include \"BS_thread_pool.hpp\" // BS::synced_stream, BS::thread_pool\n#include <exception>          // std::exception\n#include <future>             // std::future\n#include <stdexcept>          // std::runtime_error\n\nBS::synced_stream sync_out;\nBS::thread_pool pool;\n\nvoid print_inverse(const double x)\n{\n    if (x == 0)\n        throw std::runtime_error(\"Division by zero!\");\n    sync_out.println(\"The inverse of \", x, \" is \", 1 / x, \".\");\n}\n\nint main()\n{\n    constexpr double num = 0;\n    std::future<void> my_future = pool.submit_task(\n        [num]\n        {\n            print_inverse(num);\n        });\n    try\n    {\n        my_future.get();\n    }\n    catch (const std::exception& e)\n    {\n        sync_out.println(\"Caught exception: \", e.what());\n    }\n}\n```\n\nWhen using `BS::multi_future<T>` to handle multiple futures at once, exception handling works the same way: if any of the futures may throw exceptions, you may catch these exceptions when calling `get()`, even in the case of `BS::multi_future<void>`.\n\nNote that if you use `detach_task()`, or any other `detach` member function, there is no way to catch exceptions thrown by the task, as a future will not be returned. In such cases, all exceptions thrown by the task will be silently ignored, to prevent program termination. If you need to catch exceptions in a detached task, you must do so within the task itself, as in this example:\n\n```cpp\n#include \"BS_thread_pool.hpp\" // BS::synced_stream, BS::thread_pool\n#include <exception>          // std::exception\n#include <stdexcept>          // std::runtime_error\n\nBS::synced_stream sync_out;\nBS::thread_pool pool;\n\ndouble inverse(const double x)\n{\n    if (x == 0)\n        throw std::runtime_error(\"Division by zero!\");\n    return 1 / x;\n}\n\nint main()\n{\n    constexpr double num = 0;\n    pool.detach_task(\n        [num]\n        {\n            try\n            {\n                const double result = inverse(num);\n                sync_out.println(\"The inverse of \", num, \" is \", result, \".\");\n            }\n            catch (const std::exception& e)\n            {\n                sync_out.println(\"Caught exception: \", e.what());\n            }\n        });\n    pool.wait();\n}\n```\n\nIf exceptions are explicitly disabled in your codebase, or if the feature-test macro `__cpp_exceptions` is undefined for any other reason, exception handling will be automatically disabled in the thread pool.\n\n### Getting information about the current thread\n\nThe class `BS::this_thread` provides functionality analogous to `std::this_thread`, that is, it allows a thread to reference itself. It contains the following static member functions:\n\n* `BS::this_thread::get_index()` can be used to get the index of the current thread as an `std::optional<std::size_t>` object.\n    * If this thread belongs to a `BS::thread_pool` object, the return value will be an index in the range `[0, N)` where `N == BS::thread_pool::get_thread_count()`.\n    * Otherwise, for example if this thread is the main thread or an independent thread not in any pools, `std::nullopt` will be returned.\n* `BS::this_thread::get_pool()` can be used to get a pointer to the thread pool that owns the current thread as an `std::optional<void*>` object.\n    * If this thread belongs to a `BS::thread_pool` object, the return value will be a `void` pointer to that object.\n    * Otherwise, `std::nullopt` will be returned.\n\nAn [`std::optional`](https://en.cppreference.com/w/cpp/utility/optional) is an object that may or may not have a value. [`std::nullopt`](https://en.cppreference.com/w/cpp/utility/optional/nullopt) is a placeholder which indicates that the object does not have a value. To access an `std::optional`, you should first use [`std::optional::has_value()`](https://en.cppreference.com/w/cpp/utility/optional/operator_bool) to check if it contains a value, and if so, use [`std::optional::value()`](https://en.cppreference.com/w/cpp/utility/optional/value) to obtain that value. A shortcut for `if (x.has_value())` is `if (x)`, and a shortcut for `x.value()` is `*x`.\n\nThe reason that `BS::this_thread::get_pool()` returns a `void*` is that `BS::thread_pool` is a template. Once you obtain the pool pointer, you must cast it to the desired instantiation of the template if you want to use any member functions. Note that you have to cast it to the correct type; if you cast a pointer to a `BS::light_thread_pool` into a pointer to a `BS::priority_thread_pool`, for example, your program will have undefined behavior. (Please see the [optional features](#optional-features) section for more information about the template parameters and aliases.)\n\nHere is an example illustrating all of the above:\n\n```cpp\n#include \"BS_thread_pool.hpp\" // BS::light_thread_pool, BS::synced_stream, BS::this_thread\n#include <atomic>             // std::atomic\n#include <cstddef>            // std::size_t\n#include <optional>           // std::optional\n#include <thread>             // std::thread\n\nBS::synced_stream sync_out;\nBS::light_thread_pool p1;\nBS::light_thread_pool p2;\nstd::atomic<char> ltr = 'A';\n\nvoid check_this_thread(const char letter)\n{\n    const std::optional<void*> my_pool = BS::this_thread::get_pool();\n    const std::optional<std::size_t> my_index = BS::this_thread::get_index();\n\n    if (my_pool && my_index)\n    {\n        const std::size_t pool_number = *my_pool == &p1 ? 1 : 2;\n        sync_out.println(\"Task \", letter, \" is being executed by thread #\", *my_index, \" of pool #\", pool_number, '.');\n        static_cast<BS::light_thread_pool*>(*my_pool)->detach_task(\n            [letter]\n            {\n                sync_out.println(\"-> Task \", ltr++, \" was submitted by task \", letter, \" using detach_task().\");\n            });\n    }\n    else\n    {\n        sync_out.println(\"Task \", letter, \" is being executed by an independent thread, not in any thread pools.\");\n        std::thread(\n            [letter]\n            {\n                sync_out.println(\"-> Task \", ltr++, \" was submitted by task \", letter, \" using a detached std::thread.\");\n            })\n            .detach();\n    }\n}\n\nint main()\n{\n    p1.submit_task(\n          []\n          {\n              check_this_thread(ltr++);\n          })\n        .wait();\n    p2.submit_task(\n          []\n          {\n              check_this_thread(ltr++);\n          })\n        .wait();\n    std::thread(\n        []\n        {\n            check_this_thread(ltr++);\n        })\n        .join();\n}\n```\n\nThe output of this program will be similar to:\n\n```none\nTask A is being executed by thread #3 of pool #1.\n-> Task B was submitted by task A using detach_task().\nTask C is being executed by thread #7 of pool #2.\n-> Task D was submitted by task C using detach_task().\nTask E is being executed by an independent thread, not in any thread pools.\n-> Task F was submitted by task E using a detached std::thread.\n```\n\nIn this example, we execute the task `check_this_thread()` in three different ways:\n\n1. By submitting it from the thread pool `p1`.\n2. By submitting it from the thread pool `p2`.\n3. By submitting it from an independent `std::thread`.\n\nThe task calls `BS::this_thread::get_pool()` and `BS::this_thread::get_index()` and receives two `std::optional` objects, `my_pool` and `my_index`. If both have a value (that is, evaluate to `true`), then the task knows it is running in a thread pool. The actual values are then obtained by \"dereferencing\" them: the pool pointer is `*my_pool`, and the thread index is `*my_index`.\n\nThe task deduces which pool it is running in by comparing the pointer `*my_pool` to the addresses of the pools `p1` and `p2`. It also gets the index of the thread from `*my_index`. Finally, it detaches an additional task (without waiting for it, as that might cause a deadlock!) from its own pool by first casting the `void*` pointer to the correct type, which in this case is `BS::light_thread_pool*`, and then calling the `detach_task()` member function of that specific pool.\n\nIf `my_pool` and `my_index` do not have values (that is, evaluate to `false`), then the task knows it is running in an independent thread. In this case, it detaches the additional task using another independent thread.\n\n### Thread initialization functions\n\nSometimes, it is necessary to initialize the threads before they run any tasks. This can be done by submitting a proper initialization function to the `BS::thread_pool` constructor or to `reset()`, either as the only argument or as the second argument after the desired number of threads.\n\nThe thread initialization function must have no return value. It can either take one argument, the thread index of type `std::size_t`, or zero arguments. In the latter case, the function can use `BS::this_thread::get_index()` to find the thread index. In addition, the function can use `BS::this_thread::get_pool()` to find which pool its thread belongs to.\n\nThe initialization functions are effectively submitted as a set of special tasks, one per thread, which bypass the queue, but still count towards the number of running tasks. This means `get_tasks_total()` and `get_tasks_running()` will report that these tasks are running if they are checked immediately after the pool is initialized.\n\nThis is done so that the user has the option to either wait for the initialization functions to finish, by calling `wait()` on the pool, or just keep going. In either case, the initialization functions will always finish running before any tasks are executed by the corresponding thread, so there is no reason to wait for them to finish unless they have some side-effects that affect the main thread, or if they must finish running on **all** the threads before the pool starts executing any tasks.\n\nHere is a simple example:\n\n```cpp\n#include \"BS_thread_pool.hpp\" // BS::synced_stream, BS::thread_pool\n#include <random>             // std::mt19937_64, std::random_device\n\nBS::synced_stream sync_out;\nthread_local std::mt19937_64 twister;\n\nint main()\n{\n    BS::thread_pool pool(\n        []\n        {\n            twister.seed(std::random_device()());\n        });\n    pool.submit_sequence(0, 4,\n            [](int)\n            {\n                sync_out.println(\"I generated a random number: \", twister());\n            })\n        .wait();\n}\n```\n\nIn this example, we create a `thread_local` Mersenne twister engine, meaning that each thread has its own independent engine. However, if we do not seed the engine, each thread would generate the exact same sequence of pseudo-random numbers. To remedy this, we pass an initialization function to the `BS::thread_pool` constructor which seeds the twister in each thread with the (hopefully) non-deterministic random number generator `std::random_device`.\n\nNote that the lambda function we passed to `submit_sequence()` has the signature `[](int)`, with an unnamed `int` argument, as it does not make use of the sequence index, which will be a number in the range `[0, 4)`. This is an easy way to simply submit the same task multiple times.\n\n**Warning:** Exceptions thrown by thread initialization functions must not throw any exceptions, as that will result in program termination. Any exceptions must be handled explicitly within the function.\n\n### Thread cleanup functions\n\nSimilarly to the thread initialization function, it is also possible to provide the pool with a cleanup function to run in each thread right before it is destroyed, which will happen when the pool is destructed or reset. Like the initialization function, the cleanup function must have no return value, and can either take one argument, the thread index of type `std::size_t`, or zero arguments. Each pool can have its own cleanup function, which is specified using the member function `set_cleanup_func()`. Here is an example:\n\n```cpp\n#include \"BS_thread_pool.hpp\" // BS::synced_stream, BS::this_thread, BS::thread_pool\n#include <chrono>             // std::chrono\n#include <cstddef>            // std::size_t\n#include <fstream>            // std::ofstream\n#include <string>             // std::to_string\n#include <thread>             // std::this_thread\n\nthread_local std::ofstream log_file;\nthread_local BS::synced_stream sync_out(log_file);\nconstexpr std::size_t threads = 4;\n\nint main()\n{\n    BS::thread_pool pool(threads,\n        [](const std::size_t idx)\n        {\n            log_file.open(\"thread_\" + std::to_string(idx) + \".log\");\n        });\n    pool.set_cleanup_func(\n        []\n        {\n            log_file.close();\n        });\n    pool.submit_sequence(0, threads * 10,\n            [](const std::size_t idx)\n            {\n                std::this_thread::sleep_for(std::chrono::milliseconds(50));\n                sync_out.println(\"Task \", idx, \" is running on thread \", *BS::this_thread::get_index(), '.');\n            })\n        .wait();\n}\n```\n\nIn this example, we create 4 threads, each of which has a separate thread-local `BS::synced_stream` object writing to its own log file of the form `thread_N.log` where `N` is the thread index. The initialization function, passed as an argument to the constructor, opens the log file. The cleanup function, set using `set_cleanup_func()`, closes the log file.\n\nWe submit 40 tasks to the queue using `submit_sequence()`, each of which prints a message to the log file indicating which thread it is running on. When the `main()` function exits and `pool` is destroyed, the cleanup function is called for each thread, ensuring that the log files are closed properly.\n\n**Warning:** As with initialization functions, exceptions thrown by thread cleanup functions must not throw any exceptions, as that will result in program termination. Any exceptions must be handled explicitly within the function.\n\n### Passing task arguments by constant reference\n\nIn C&plus;&plus;, it is often crucial to pass function arguments by reference or constant reference, instead of by value. This allows the function to access the object being passed directly, rather than creating a new copy of the object. We have already seen [above](#detaching-and-waiting-for-tasks) that submitting an argument by reference is a simple matter of capturing it with a `&` in the lambda capture list. To submit by **constant** reference, we can use `std::as_const()` as in the following example:\n\n```cpp\n#include \"BS_thread_pool.hpp\" // BS::synced_stream, BS::thread_pool\n#include <utility>            // std::as_const\n\nBS::synced_stream sync_out;\n\nvoid increment(int& x)\n{\n    ++x;\n}\n\nvoid print(const int& x)\n{\n    sync_out.println(x);\n}\n\nint main()\n{\n    BS::thread_pool pool;\n    int n = 0;\n    pool.submit_task(\n            [&n]\n            {\n                increment(n);\n            })\n        .wait();\n    pool.submit_task(\n            [&n = std::as_const(n)]\n            {\n                print(n);\n            })\n        .wait();\n}\n```\n\nThe `increment()` function takes a **reference** to an integer, and increments that integer. Passing the argument by reference guarantees that `n` itself, in the scope of `main()`, will be incremented - rather than a copy of it in the scope of `increment()`.\n\nSimilarly, the `print()` function takes a **constant reference** to an integer, and prints that integer. Passing the argument by constant reference guarantees that the variable will not be accidentally modified by the function, even though we are accessing `n` itself, rather than a copy. If we replace `print()` with `increment()`, the program won't compile, as `increment()` cannot take constant references.\n\nGenerally, it is not really necessary to pass arguments by constant reference, but it is more \"correct\" to do so, if we would like to guarantee that the variable being referenced is indeed never modified.\n\n## Optional features\n\n### Enabling features\n\nThe thread pool has some optional features, which are disabled by default to minimize overhead. They can be enabled by passing the appropriate template parameter to the `BS::thread_pool` class when creating the pool. The template parameter is a bitmask, so you can enable several features at once by combining them with the bitwise OR operator `|`. The bitmask flags are members of the `BS::tp` enumeration:\n\n* `BS::tp::priority` enables [task priority](#setting-task-priority).\n* `BS::tp::pause` enables [pausing the pool](#pausing-the-pool).\n* `BS::tp::wait_deadlock_checks` enables [wait deadlock checks](#avoiding-wait-deadlocks).\n* The default is `BS::tp::none`, which disables all optional features.\n\nFor example, to enable both task priority and pausing the pool, the thread pool object should be created like this:\n\n```cpp\nBS::thread_pool<BS::tp::priority | BS::tp::pause> pool;\n```\n\nConvenience aliases are defined as follows:\n\n* `BS::light_thread_pool` disables all optional features (equivalent to `BS::thread_pool` with the default template parameter, that is, `BS::thread_pool<BS::tp::none>`).\n* `BS::priority_thread_pool` enables task priority (equivalent to `BS::thread_pool<BS::tp::priority>`).\n* `BS::pause_thread_pool` enables pausing the pool (equivalent to `BS::thread_pool<BS::tp::pause>`).\n* `BS::wdc_thread_pool` enables wait deadlock checks (equivalent to `BS::thread_pool<BS::tp::wait_deadlock_checks>`).\n\nThere are no aliases with multiple features enabled; if this is desired, you must either pass the template parameter explicitly or define your own alias, and use the bitwise OR operator as shown above.\n\nNote that, since optional features are enabled separately for each `BS::thread_pool` object, you can have multiple pools with different features enabled in the same program. For example, you can have one `BS::light_thread_pool` for tasks that do not need to be prioritized, and a separate `BS::priority_thread_pool` for tasks that do.\n\n### Setting task priority\n\nTurning on the `BS::tp::priority` flag in the template parameter to `BS::thread_pool` enables task priority. In addition, the library defines the convenience alias `BS::priority_thread_pool`, which is equivalent to `BS::thread_pool<BS::tp::priority>`. When this feature is enabled, the static member `priority_enabled` will be set to `true`.\n\nThe priority of a task or group of tasks may then be specified as an additional argument (at the end of the argument list) to `detach_task()`, `submit_task()`, `detach_blocks()`, `submit_blocks()`, `detach_loop()`, `submit_loop()`, `detach_sequence()`, and `submit_sequence()`. If the priority is not specified, the default value will be 0.\n\nThe priority is a number of type `BS::priority_t`, which is a signed 8-bit integer, so it can have any value between -128 and +127. The tasks will be executed in priority order from highest to lowest. If priority is assigned to the block/loop/sequence parallelization functions, which submit multiple tasks, then all of these tasks will have the same priority.\n\nThe enumeration `BS::pr` contains some pre-defined priorities for users who wish to avoid magic numbers and enjoy better future-proofing. In order of decreasing priority, the pre-defined priorities are: `BS::pr::highest`, `BS::pr::high`, `BS::pr::normal`, `BS::pr::low`, and `BS::pr::lowest`.\n\nHere is a simple example:\n\n```cpp\n#include \"BS_thread_pool.hpp\" // BS::priority_thread_pool, BS::synced_stream\n\nBS::synced_stream sync_out;\nBS::priority_thread_pool pool(1);\n\nint main()\n{\n    pool.detach_task(\n        []\n        {\n            sync_out.println(\"This task will execute third.\");\n        },\n        BS::pr::normal);\n    pool.detach_task(\n        []\n        {\n            sync_out.println(\"This task will execute fifth.\");\n        },\n        BS::pr::lowest);\n    pool.detach_task(\n        []\n        {\n            sync_out.println(\"This task will execute second.\");\n        },\n        BS::pr::high);\n    pool.detach_task(\n        []\n        {\n            sync_out.println(\"This task will execute first.\");\n        },\n        BS::pr::highest);\n    pool.detach_task(\n        []\n        {\n            sync_out.println(\"This task will execute fourth.\");\n        },\n        BS::pr::low);\n}\n```\n\nThis program will print out the tasks in the correct priority order. Note that for simplicity, we used a pool with just one thread, so the tasks will run one at a time. In a pool with 5 or more threads, all 5 tasks will actually run more or less at the same time, because, for example, the task with the second-highest priority will be picked up by another thread while the task with the highest priority is still running.\n\nOf course, this is just a pedagogical example. In a realistic use case we may want, for example, to submit tasks that must be completed immediately with high priority so they skip over other tasks already in the queue, or background non-urgent tasks with low priority so they evaluate only after higher-priority tasks are done.\n\nTask priority is facilitated using [`std::priority_queue`](https://en.cppreference.com/w/cpp/container/priority_queue), which has O(log n) complexity for storing new tasks, but only O(1) complexity for retrieving the next (i.e. highest-priority) task. This is in contrast with [`std::queue`](https://en.cppreference.com/w/cpp/container/queue), used if priority is disabled, which both stores and retrieves with O(1) complexity.\n\nDue to this, enabling the priority queue can incur a very slight decrease in performance, depending on the specific use case, which is why this feature is disabled by default. In other words, you gain functionality, but pay for it in performance. However, the difference in performance is never substantial, and compiler optimizations can often reduce it to a negligible amount.\n\nLastly, please note that when using the priority queue, tasks will not necessarily be executed in the same order they were submitted, **even if they all have the same priority**. This is due to the implementation of `std::priority_queue` as a [binary heap](https://en.wikipedia.org/wiki/Binary_heap), which means tasks are stored as a binary tree instead of sequentially.\n\n### Pausing the pool\n\nTurning on the `BS::tp::pause` flag in the template parameter to `BS::thread_pool` enables pausing the pool. In addition, the library defines the convenience alias `BS::pause_thread_pool`, which is equivalent to `BS::thread_pool<BS::tp::pause>`. When this feature is enabled, the static member `pause_enabled` will be set to `true`.\n\nThis feature enables the member functions `pause()`, `unpause()`, and `is_paused()`. When you call `pause()`, the workers will temporarily stop retrieving new tasks out of the queue. However, any tasks already executed will keep running until they are done, since the thread pool has no control over the internal code of your tasks. If you need to pause a task in the middle of its execution, you must do that manually by programming your own pause mechanism into the task itself. To resume retrieving tasks, call `unpause()`. To check whether the pool is currently paused, call `is_paused()`.\n\nHere is an example:\n\n```cpp\n#include \"BS_thread_pool.hpp\" // BS::pause_thread_pool, BS::synced_stream\n#include <chrono>             // std::chrono\n#include <thread>             // std::this_thread\n\nBS::synced_stream sync_out;\nBS::pause_thread_pool pool(4);\n\nvoid sleep_half_second(const unsigned int i)\n{\n    std::this_thread::sleep_for(std::chrono::milliseconds(500));\n    sync_out.println(\"Task \", i, \" done.\");\n}\n\nvoid check_if_paused()\n{\n    if (pool.is_paused())\n        sync_out.println(\"Pool paused.\");\n    else\n        sync_out.println(\"Pool unpaused.\");\n}\n\nint main()\n{\n    pool.detach_sequence(0, 8, sleep_half_second);\n    sync_out.println(\"Submitted 8 tasks.\");\n    std::this_thread::sleep_for(std::chrono::milliseconds(250));\n    pool.pause();\n    check_if_paused();\n    std::this_thread::sleep_for(std::chrono::milliseconds(1000));\n    sync_out.println(\"Still paused...\");\n    std::this_thread::sleep_for(std::chrono::milliseconds(1000));\n    pool.detach_sequence(8, 12, sleep_half_second);\n    sync_out.println(\"Submitted 4 more tasks.\");\n    sync_out.println(\"Still paused...\");\n    std::this_thread::sleep_for(std::chrono::milliseconds(1000));\n    pool.unpause();\n    check_if_paused();\n}\n```\n\nAssuming you have at least 4 hardware threads, the output should be similar to:\n\n```none\nSubmitted 8 tasks.\nPool paused.\nTask 0 done.\nTask 1 done.\nTask 2 done.\nTask 3 done.\nStill paused...\nSubmitted 4 more tasks.\nStill paused...\nPool unpaused.\nTask 4 done.\nTask 5 done.\nTask 6 done.\nTask 7 done.\nTask 8 done.\nTask 9 done.\nTask 10 done.\nTask 11 done.\n```\n\nIn this example, we initially submit a total of 8 tasks to the queue. The first 4 tasks start running immediately (only 4, since the pool has 4 threads). We wait for 250ms, and then pause. The tasks that are already running (for 500ms) will keep running until they finished; pausing has no effect on currently running tasks. However, the other 4 tasks will not be executed yet. While the pool is paused, we submit 4 more tasks to the queue, but they just wait at the end of the queue. When we unpause, the remaining 4 initial tasks are executed, followed by the 4 new tasks.\n\nWhile the workers are paused, `wait()` will wait only for the running tasks instead of all tasks (otherwise it would wait forever). This is demonstrated by the following program:\n\n```cpp\n#include \"BS_thread_pool.hpp\" // BS::pause_thread_pool, BS::synced_stream\n#include <chrono>             // std::chrono\n#include <thread>             // std::this_thread\n\nBS::synced_stream sync_out;\nBS::pause_thread_pool pool(4);\n\nvoid sleep_half_second(const unsigned int i)\n{\n    std::this_thread::sleep_for(std::chrono::milliseconds(500));\n    sync_out.println(\"Task \", i, \" done.\");\n}\n\nvoid check_if_paused()\n{\n    if (pool.is_paused())\n        sync_out.println(\"Pool paused.\");\n    else\n        sync_out.println(\"Pool unpaused.\");\n}\n\nint main()\n{\n    pool.detach_sequence(0, 8, sleep_half_second);\n    sync_out.println(\"Submitted 8 tasks. Waiting for them to complete.\");\n    pool.wait();\n    pool.detach_sequence(8, 20, sleep_half_second);\n    sync_out.println(\"Submitted 12 more tasks.\");\n    std::this_thread::sleep_for(std::chrono::milliseconds(250));\n    pool.pause();\n    check_if_paused();\n    sync_out.println(\"Waiting for the \", pool.get_tasks_running(), \" running tasks to complete.\");\n    pool.wait();\n    sync_out.println(\"All running tasks completed. \", pool.get_tasks_queued(), \" tasks still queued.\");\n    std::this_thread::sleep_for(std::chrono::milliseconds(1000));\n    sync_out.println(\"Still paused...\");\n    std::this_thread::sleep_for(std::chrono::milliseconds(1000));\n    sync_out.println(\"Still paused...\");\n    std::this_thread::sleep_for(std::chrono::milliseconds(1000));\n    pool.unpause();\n    check_if_paused();\n    std::this_thread::sleep_for(std::chrono::milliseconds(250));\n    sync_out.println(\"Waiting for the remaining \", pool.get_tasks_total(), \" tasks (\", pool.get_tasks_running(), \" running and \", pool.get_tasks_queued(), \" queued) to complete.\");\n    pool.wait();\n    sync_out.println(\"All tasks completed.\");\n}\n```\n\nThe output should be similar to:\n\n```none\nSubmitted 8 tasks. Waiting for them to complete.\nTask 0 done.\nTask 1 done.\nTask 2 done.\nTask 3 done.\nTask 4 done.\nTask 5 done.\nTask 6 done.\nTask 7 done.\nSubmitted 12 more tasks.\nPool paused.\nWaiting for the 4 running tasks to complete.\nTask 8 done.\nTask 9 done.\nTask 10 done.\nTask 11 done.\nAll running tasks completed. 8 tasks still queued.\nStill paused...\nStill paused...\nPool unpaused.\nWaiting for the remaining 8 tasks (4 running and 4 queued) to complete.\nTask 12 done.\nTask 13 done.\nTask 14 done.\nTask 15 done.\nTask 16 done.\nTask 17 done.\nTask 18 done.\nTask 19 done.\nAll tasks completed.\n```\n\nThe first `wait()`, which was called while the pool was not paused, waited for all 8 tasks, both running and queued. The second `wait()`, which was called after pausing the pool, only waited for the 4 running tasks, while the other 8 tasks remained queued, and were not executed since the pool was paused. Finally, the third `wait()`, which was called after unpausing the pool, waited for the remaining 8 tasks, both running and queued.\n\nNote that pausing the pool adds additional checks to the waiting and worker functions, which have a very small but non-zero overhead. This is why this feature is disabled by default.\n\n**Warning:** If the thread pool is destroyed while paused, any tasks still in the queue will never be executed!\n\n### Avoiding wait deadlocks\n\nTurning on the `BS::tp::wait_deadlock_checks` flag in the template parameter to `BS::thread_pool` enables wait deadlock checks. In addition, the library defines the convenience alias `BS::wdc_thread_pool`, which is equivalent to `BS::thread_pool<BS::tp::wait_deadlock_checks>`. When this feature is enabled, the static member `wait_deadlock_checks_enabled` will be set to `true`.\n\nTo understand why this feature is useful, consider the following program:\n\n```cpp\n#include \"BS_thread_pool.hpp\" // BS::synced_stream, BS::thread_pool\n\nBS::synced_stream sync_out;\nBS::thread_pool pool;\n\nint main()\n{\n    pool.detach_task(\n        []\n        {\n            pool.wait();\n            sync_out.println(\"Done waiting.\");\n        });\n}\n```\n\nThis program creates a thread pool, and then detaches a task that waits for tasks in the same thread pool to complete. If you run this program, it will never print the message \"Done waiting\", because the task will wait for **itself** to complete. This causes a **deadlock**, and the program will wait forever.\n\nUsually, in simple programs, this will never happen. However, in more complicated programs, perhaps ones running multiple thread pools in parallel, wait deadlocks could potentially occur. In such cases, wait deadlock checks may be useful. If enabled, `wait()`, `wait_for()`, and `wait_until()` will check whether the user tried to call them from within a thread of the same pool, and if so, they will throw the exception `BS::wait_deadlock` instead of waiting.\n\nHere is an example:\n\n```cpp\n#include \"BS_thread_pool.hpp\" // BS::synced_stream, BS::wdc_thread_pool\n\nBS::synced_stream sync_out;\nBS::wdc_thread_pool pool;\n\nint main()\n{\n    pool.detach_task(\n        []\n        {\n            try\n            {\n                pool.wait();\n                sync_out.println(\"Done waiting.\");\n            }\n            catch (const BS::wait_deadlock&)\n            {\n                sync_out.println(\"Error: Deadlock!\");\n            }\n        });\n}\n```\n\nThis time, `wait()` will detect the deadlock, and will throw an exception, causing the output to be \"Error: Deadlock!\".\n\nWait deadlock checks are disabled by default because wait deadlocks are not something that happens often, and the check adds a small but non-zero overhead every time `wait()`, `wait_for()`, or `wait_until()` is called. Note that if the feature-test macro `__cpp_exceptions` is undefined, wait deadlock checks will be automatically disabled, and trying to compile a program which creates a pool with the `BS::tp::wait_deadlock_checks` flag enabled will result in a compilation error.\n\n## Native extensions\n\n### Enabling the native extensions\n\nWhile portability is one of the guiding principle for developing this library, non-portable features such as setting the thread priority using the operating system's native API can be very useful. Therefore, the library includes native extensions - which are disabled by default, as they are not portable.\n\nThe native extensions may be enabled by defining the macro `BS_THREAD_POOL_NATIVE_EXTENSIONS` at compilation time. If including the library as a header file, the macro must be defined before `#include \"BS_thread_pool.hpp\"`. Note that even if the macro is defined, the native extensions are disabled automatically if a supported operating system (Windows, Linux, or macOS) is not detected.\n\nIf importing the library [as a C&plus;&plus;20 module](#importing-the-library-as-a-c20-module), defining the macro before importing the module will not work, as modules cannot access macros defined in the program that imported them. Instead, you must define the macro as a compiler flag: `-D BS_THREAD_POOL_NATIVE_EXTENSIONS` for Clang and GCC or `/D BS_THREAD_POOL_NATIVE_EXTENSIONS` for MSVC.\n\n[The test program](#testing-the-library) only tests the native extensions if the macro `BS_THREAD_POOL_NATIVE_EXTENSIONS` is defined at compilation time. If importing the library [as a C&plus;&plus;20 module](#importing-the-library-as-a-c20-module), please ensure that the macro is also enabled when compiling the module.\n\nThe `constexpr` flag `BS::thread_pool_native_extensions` indicates whether the thread pool library was compiled with native extensions enabled. Note that the flag will be `false` if `BS_THREAD_POOL_NATIVE_EXTENSIONS` is defined but the operating system is unsupported.\n\n**Warning:** Please note that, as of v5.0.0 of the thread pool library, the native extensions have only been tested on **Windows 11 23H2, Ubuntu 24.10, and macOS 15.1**. They have not been tested on older versions of these operating systems, other Linux distributions, or any other operating systems, and are therefore not guaranteed to work on every system. If you encounter any issues, please report them on [the GitHub repository](https://github.com/bshoshany/thread-pool).\n\n### Setting thread priority\n\nThe thread pool's native extensions provide the ability to set a thread's priority using the operating system's native API. Please note that this is **not** the same as [setting a task's priority](#setting-task-priority), which is a feature of the thread pool's queue, unrelated to the pool's threads themselves. Task priority controls which tasks are executed first, while thread priority (roughly) controls how much CPU time a thread gets compared to other threads. In addition, you can use the native extensions to set the priority of any thread (such as a thread created using `std::thread`), not just a pool thread.\n\nFor performance-critical applications, you may wish to increase the thread priority, while for applications that should run in the background, you may wish to decrease it. As priority is handled very differently on different operating systems, the thread pool library provides an abstraction layer over the native APIs, in the form of the enumeration class `BS::os_thread_priority`, which has the following 7 members:\n\n* `BS::os_thread_priority::idle`\n* `BS::os_thread_priority::lowest`\n* `BS::os_thread_priority::below_normal`\n* `BS::os_thread_priority::normal`\n* `BS::os_thread_priority::above_normal`\n* `BS::os_thread_priority::highest`\n* `BS::os_thread_priority::realtime`\n\nOn Windows, these pre-defined priorities map 1-to-1 with [the thread priority values defined by the Windows API](https://learn.microsoft.com/en-us/windows/win32/api/processthreadsapi/nf-processthreadsapi-setthreadpriority) (with `realtime` mapping to time critical priority). On Linux and macOS, thread priorities are a lot more complicated, so these pre-defined priorities are mapped to the parameters available in the native API.\n\nOn Linux (with POSIX threads), thread priority is determined by three factors: [scheduling policy](https://www.man7.org/linux/man-pages/man3/pthread_setschedparam.3.html), priority value, and [\"nice\" value](https://www.man7.org/linux/man-pages/man2/setpriority.2.html). The thread pool library's abstraction layer distills these factors into the above pre-defined levels, for simplicity and portability. The total number of possible combinations of parameters is much larger, but allowing more fine-grained control would not be portable, and in any case it would have limited use. For the precise mapping, please refer to the source code itself (in the header file `BS_thread_pool.hpp`).\n\nOn macOS, the thread pool library will also use POSIX threads, but unlike Linux, the \"nice\" value is per-process, not per-thread (in compliance with the POSIX standard). However, macOS does allow more freedom with respect to the available range of priorities. Again, for the precise details of the mapping, please refer to the source code itself.\n\nMost users do not need to worry about the specifics of how thread priority is handled on different operating systems. The abstraction layer provided by the thread pool library is meant to make everything as simple and portable as possible. However, it is important to note that only Windows allows a non-privileged user to set a thread's priority to a higher value. On Linux and macOS, a non-privileged user can only set a thread's priority to a lower value, and only root can set a higher value; also, confusingly, if a user decreased the priority of their thread from normal to a lower priority, they cannot increase it back to normal without root privileges, even though normal was the thread's initial priority.\n\nThread priority is managed using two static member functions of the `BS::this_thread` class:\n\n* `BS::this_thread::get_os_thread_priority()` gets the current thread's priority. It returns an object of type `std::optional<BS::os_thread_priority>`. If the returned object does not contain a value, then either the priority could not be determined, or it is not one of the pre-defined values listed above.\n* `BS::this_thread::set_os_thread_priority()` sets the current thread's priority. It returns `true` if the priority was set successfully, or `false` otherwise. Usually, `false` means that the user does not have the necessary permissions to set the desired priority.\n\nIncreasing or decreasing the priority of all the threads in a pool can be done most easily using an [initialization function](#thread-initialization-functions). Here is an example:\n\n```cpp\n#define BS_THREAD_POOL_NATIVE_EXTENSIONS\n#include \"BS_thread_pool.hpp\" // BS::os_thread_priority, BS::synced_stream, BS::this_thread, BS::thread_pool\n#include <cstddef>            // std::size_t\n#include <map>                // std::map\n#include <optional>           // std::optional\n#include <string>             // std::string\n\nBS::synced_stream sync_out;\nBS::os_thread_priority target = BS::os_thread_priority::highest;\n\nconst std::map<BS::os_thread_priority, std::string> os_thread_priority_map = {{BS::os_thread_priority::idle, \"idle\"}, {BS::os_thread_priority::lowest, \"lowest\"}, {BS::os_thread_priority::below_normal, \"below_normal\"}, {BS::os_thread_priority::normal, \"normal\"}, {BS::os_thread_priority::above_normal, \"above_normal\"}, {BS::os_thread_priority::highest, \"highest\"}, {BS::os_thread_priority::realtime, \"realtime\"}};\n\nstd::string os_thread_priority_name(const BS::os_thread_priority priority)\n{\n    const std::map<BS::os_thread_priority, std::string>::const_iterator it = os_thread_priority_map.find(priority);\n    return (it != os_thread_priority_map.end()) ? it->second : \"unknown\";\n}\n\nvoid set_priority(const std::size_t idx)\n{\n    const std::optional<BS::os_thread_priority> get_result = BS::this_thread::get_os_thread_priority();\n    if (get_result)\n        sync_out.println(\"The OS thread priority of thread \", idx, \" is currently set to '\", os_thread_priority_name(*get_result), \"'.\");\n    else\n        sync_out.println(\"Error: Failed to get the OS thread priority of thread \", idx, '!');\n    const bool set_result = BS::this_thread::set_os_thread_priority(target);\n    sync_out.println(set_result ? \"Successfully\" : \"Error: Failed to\", \" set the OS priority of thread \", idx, \" to '\", os_thread_priority_name(target), \"'.\");\n}\n\nint main()\n{\n    BS::thread_pool pool(4, set_priority);\n}\n```\n\nOn Linux or macOS, please ensure that you run this example as root using `sudo`, otherwise it will fail. In this example we used an initialization function `set_priority()` to first print the initial priority of each thread (which should be \"normal\") and then set the priority of each thread to \"highest\". `os_thread_priority_name()` is a helper function to convert a `BS::os_thread_priority` value to a human-readable string.\n\n### Setting thread affinity\n\nThe thread pool's native extensions allow the user to set a thread's processor affinity using the operating system's native API. Processor affinity, sometimes called \"pinning\", controls which logical processors a thread is allowed to run on. Generally, a non-hyperthreaded core corresponds to one logical processor, and a hyperthreaded core corresponds to two logical processors.\n\nThis can be useful for performance optimization, as it can reduce cache misses. However, it can also degrade performance, sometimes severely, since the thread will not run at all until its assigned cores are available. Therefore, it is usually better to let the operating system's scheduler manage thread affinities on its own, except in very specific cases.\n\nPlease note that setting thread affinity works on Windows and Linux, but not on macOS, as the native API does not allow it. As affinity is handled differently on different operating systems, the thread pool library provides an abstraction layer over the native APIs. In this abstraction layer, affinity is controlled using an `std::vector<bool>` where each element corresponds to a logical processor.\n\nThread affinity is managed using two static member functions of the `BS::this_thread` class:\n\n* `BS::this_thread::get_os_thread_affinity()` gets the current thread's affinity. It returns an object of type `std::optional<std::vector<bool>>`. If the returned object does not contain a value, then the affinity could not be determined. On macOS, this function always returns `std::nullopt`.\n* `BS::this_thread::set_os_thread_affinity()` sets the current thread's affinity. It returns `true` if the affinity was set successfully, or `false` otherwise. On macOS, this function always returns `false`.\n\nNote that the thread affinity must be a subset of the process affinity (as obtained using [`BS::get_os_process_affinity()`](#setting-process-affinity)) for the containing process of a thread.\n\nSetting thread affinity can significantly increase performance if multiple threads are accessing the same data, as the data can be kept in the local cache of the specific core that the threads are running on. This is illustrated in the following program:\n\n```cpp\n#define BS_THREAD_POOL_NATIVE_EXTENSIONS\n#include \"BS_thread_pool.hpp\" // BS::synced_stream, BS::this_thread\n#include <atomic>             // std::atomic\n#include <chrono>             // std::chrono\n#include <cstdint>            // std::uint64_t\n#include <thread>             // std::thread\n#include <vector>             // std::vector\n\nvoid do_test(const bool pin_threads)\n{\n    BS::synced_stream sync_out;\n    constexpr std::uint64_t num_increments = 10'000'000;\n    sync_out.println(pin_threads ? \"With   \" : \"Without\", \" thread pinning:\");\n    std::atomic<std::uint64_t> counter = 0;\n    auto worker = [&counter, pin_threads]\n    {\n        if (pin_threads)\n        {\n            std::vector<bool> affinity(std::thread::hardware_concurrency(), false);\n            affinity[0] = true;\n            BS::this_thread::set_os_thread_affinity(affinity);\n        }\n        for (std::uint64_t i = 0; i < num_increments; ++i)\n            ++counter;\n    };\n    const std::chrono::steady_clock::time_point start = std::chrono::steady_clock::now();\n    std::thread thread1(worker);\n    std::thread thread2(worker);\n    thread1.join();\n    thread2.join();\n    const std::chrono::steady_clock::time_point end = std::chrono::steady_clock::now();\n    sync_out.println(\"Final count: \", counter, \", execution time: \", (std::chrono::duration_cast<std::chrono::milliseconds>(end - start)).count(), \" ms.\");\n}\n\nint main()\n{\n    do_test(false);\n    do_test(true);\n}\n```\n\nThe output should be similar to:\n\n```none\nWithout thread pinning:\nFinal count: 20000000, execution time: 160 ms.\nWith thread pinning:\nFinal count: 20000000, execution time: 68 ms.\n```\n\nIn this program, we create two threads, each of which increments an atomic counter 10 million times. First, we do this without thread pinning; in this case, since the OS will most likely run the threads on two different cores, the state of the atomic variable will need to be synchronized between the two cores, which will incur a performance penalty. Then, we do this with thread pinning, using `BS::this_thread::set_os_thread_affinity()` to set the affinity of each thread to core 0 by passing a vector with `true` at index 0 and `false` at all other indices. In this case, the atomic variable will be kept in the local cache of core 0, which will increase performance.\n\n**Warning:** Setting the affinity of threads in a pool is almost never a good idea! When you submit a task to a thread pool, you have no control over which thread it will actually run in. The main benefit of thread affinity is to reduce cache misses, but there is no way to guarantee that tasks accessing the same data will run on the same core if they are submitted to a pool. In fact, setting the affinity of the pool threads will almost certainly decrease performance, sometimes substantially, as the operating system's scheduler will be prevented from assigning threads to cores in the most optimal way. The most common use case for `BS::this_thread::set_os_thread_affinity()` is to set the affinity of individual threads created independently of any pool, for example using `std::thread`.\n\n### Setting thread names\n\nThe thread pool's native extensions permit setting a thread's name using the operating system's native API. This can be useful for debugging, as the names of the threads will be visible in the debugger (for example, in the Call Stack on Visual Studio Code).\n\nAs with other features of the native extensions, the thread pool library provides an abstraction layer over the native APIs, consisting of the following two static member functions of the `BS::this_thread` class:\n\n* `BS::this_thread::get_os_thread_name()` gets the current thread's name. It returns an object of type `std::optional<std::string>`. If the returned object does not contain a value, then the name could not be determined.\n* `BS::this_thread::set_os_thread_name()` sets the current thread's name. It returns `true` if the name was set successfully, or `false` otherwise. Note that on Linux thread names are limited to 16 characters, including the null terminator.\n\nThis feature is illustrated by the following program:\n\n```cpp\n#define BS_THREAD_POOL_NATIVE_EXTENSIONS\n#include \"BS_thread_pool.hpp\" // BS::synced_stream, BS::this_thread, BS::thread_pool\n#include <cstddef>            // std::size_t\n#include <optional>           // std::optional\n#include <string>             // std::string, std::to_string\n\nBS::synced_stream sync_out;\n\nvoid set_name(const std::size_t idx)\n{\n    const std::string name = \"Thread \" + std::to_string(idx);\n    const bool result = BS::this_thread::set_os_thread_name(name);\n    sync_out.println(result ? \"Successfully\" : \"Error: Failed to\", \" set the name of thread \", idx, \" to '\", name, \"'.\");\n}\n\nvoid get_name()\n{\n    const std::optional<std::string> result = BS::this_thread::get_os_thread_name();\n    if (result)\n        sync_out.println(\"This thread's name is set to '\", *result, \"'.\");\n    else\n        sync_out.println(\"Error: Failed to get this thread's name!\");\n}\n\nint main()\n{\n    const bool result = BS::this_thread::set_os_thread_name(\"Main Thread\");\n    sync_out.println(result ? \"Successfully\" : \"Error: Failed to\", \" set the name of the main thread.\");\n    BS::thread_pool pool(4, set_name);\n    pool.wait();\n    // Place a breakpoint here to see the thread names in the debugger.\n    pool.submit_task(get_name).wait();\n}\n```\n\nIf you place a breakpoint on the indicated line, you will be able to see the names of the threads in the debugger. The main thread will be named \"Main Thread\", while the 4 pool threads will be named \"Thread 0\" to \"Thread 3\". In the last line, a random thread's name will be read and printed out.\n\n### Setting process priority\n\nAlthough not directly related to multithreading, `BS::thread_pool`'s native extensions also provide the ability to set the entire process's priority using the operating system's native API. As with thread priority, the thread pool library provides an abstraction layer over the native APIs, in the form of the enumeration class `BS::os_process_priority`, which has the following 6 members:\n\n* `BS::os_process_priority::idle`\n* `BS::os_process_priority::below_normal`\n* `BS::os_process_priority::normal`\n* `BS::os_process_priority::above_normal`\n* `BS::os_process_priority::high`\n* `BS::os_process_priority::realtime`\n\nOn Windows, these pre-defined priorities map 1-to-1 with [the process priority classes defined by the Windows API](https://learn.microsoft.com/en-us/windows/win32/api/processthreadsapi/nf-processthreadsapi-setpriorityclass). On Linux and macOS, process priorities are mapped to [\"nice\" values](https://www.man7.org/linux/man-pages/man2/setpriority.2.html), as given by the actual values of the enumeration members (note that lower numbers correspond to higher priorities).\n\nProcess priority is managed using two functions:\n\n* `BS::get_os_process_priority()` gets the process's priority. It returns an object of type `std::optional<BS::os_process_priority>`. If the returned object does not contain a value, then either the priority could not be determined, or it is not one of the pre-defined values listed above.\n* `BS::set_os_process_priority()` sets the process's priority. It returns `true` if the priority was set successfully, or `false` otherwise. Usually, `false` means that the user does not have the necessary permissions to set the desired priority.\n\nThis is demonstrated by the following program:\n\n```cpp\n#define BS_THREAD_POOL_NATIVE_EXTENSIONS\n#include \"BS_thread_pool.hpp\" // BS::get_os_process_priority, BS::os_process_priority, BS::set_os_process_priority, BS::synced_stream\n#include <map>                // std::map\n#include <optional>           // std::optional\n#include <string>             // std::string\n\nBS::synced_stream sync_out;\nBS::os_process_priority target = BS::os_process_priority::high;\n\nconst std::map<BS::os_process_priority, std::string> os_process_priority_map = {{BS::os_process_priority::idle, \"idle\"}, {BS::os_process_priority::below_normal, \"below_normal\"}, {BS::os_process_priority::normal, \"normal\"}, {BS::os_process_priority::above_normal, \"above_normal\"}, {BS::os_process_priority::high, \"high\"}, {BS::os_process_priority::realtime, \"realtime\"}};\n\nstd::string os_process_priority_name(const BS::os_process_priority priority)\n{\n    const std::map<BS::os_process_priority, std::string>::const_iterator it = os_process_priority_map.find(priority);\n    return (it != os_process_priority_map.end()) ? it->second : \"unknown\";\n}\n\nint main()\n{\n    const std::optional<BS::os_process_priority> get_result = BS::get_os_process_priority();\n    if (get_result)\n        sync_out.println(\"The OS process priority is currently set to '\", os_process_priority_name(*get_result), \"'.\");\n    else\n        sync_out.println(\"Error: Failed to get the OS process priority!\");\n    const bool set_result = BS::set_os_process_priority(target);\n    sync_out.println(set_result ? \"Successfully\" : \"Error: Failed to\", \" set the OS process priority to '\", os_process_priority_name(target), \"'.\");\n}\n```\n\nOn Linux or macOS, please ensure that you run this example as root using `sudo`, otherwise it will fail. (Note that here we didn't actually need to use `BS::synced_stream`, since we are not using the thread pool, and only the main thread prints to the stream; we used it only for consistency with other examples.)\n\n### Setting process affinity\n\nThe thread pool's native extensions also allow the user to set the entire process's processor affinity using the operating system's native API. This works on Windows and Linux, but not on macOS, as the native API does not allow it. As with thread affinity, the thread pool library provides an abstraction layer over the native APIs, in the form of an `std::vector<bool>` where each element corresponds to a logical processor.\n\nProcess affinity is managed using two functions:\n\n* `BS::this_thread::get_os_process_affinity()` gets the process's affinity. It returns an object of type `std::optional<std::vector<bool>>`. If the returned object does not contain a value, then the affinity could not be determined. On macOS, this function always returns `std::nullopt`.\n* `BS::this_thread::set_os_process_affinity()` sets the process's affinity. It returns `true` if the affinity was set successfully, or `false` otherwise. On macOS, this function always returns `false`.\n\n### Accessing native thread handles\n\nIf the native extensions are enabled, the `BS::thread_pool` class gains the member function `get_native_handles()`, which returns a vector containing the underlying implementation-defined thread handles for each of the pool's threads. These can then be used in an implementation-specific way to manage the threads at the OS level.\n\nHere is a quick example:\n\n```cpp\n#define BS_THREAD_POOL_NATIVE_EXTENSIONS\n#include \"BS_thread_pool.hpp\" // BS::synced_stream, BS::thread_pool\n#include <thread>             // std::thread\n#include <vector>             // std::vector\n\nBS::synced_stream sync_out;\nBS::thread_pool pool(4);\n\nint main()\n{\n    std::vector<std::thread::native_handle_type> handles = pool.get_native_handles();\n    for (std::size_t i = 0; i < handles.size(); ++i)\n        sync_out.println(\"Thread \", i, \" native handle: \", handles[i]);\n}\n```\n\nThe output will depend on your compiler and operating system. Here is an example:\n\n```none\nThread 0 native handle: 00000000000000AC\nThread 1 native handle: 00000000000000B0\nThread 2 native handle: 00000000000000B4\nThread 3 native handle: 00000000000000B8\n```\n\n**Warning:** Please note that any code written using the native handles directly will **not** be portable. As detailed above, the thread pool's native extensions define abstraction layers for several commonly used thread operations, which are portable on supported platforms, and are therefore strongly preferred over non-portable operations. The native handles are made available for users who need to perform operations that are not covered by these abstraction layers.\n\n## Testing the library\n\n### Automated tests\n\nThe file `BS_thread_pool_test.cpp` in the `tests` folder of [the GitHub repository](https://github.com/bshoshany/thread-pool) will perform automated tests of all aspects of the library. In addition, the code is meant to serve as an extensive example of how to properly use the library.\n\nThe test program also takes the following command line arguments:\n\n* `help`: Show a help message and exit. Any other arguments will be ignored.\n* `stdout`: Print to the standard output.\n* `log`: Print to a log file. It will have the same name as the executable, with a suffix `-yyyy-mm-dd_hh.mm.ss.log` based on the current date and time.\n* `tests`: Perform standard tests.\n* `deadlock`: Perform long deadlock tests.\n* `benchmarks`: Perform full Mandelbrot plot benchmarks.\n* `plot`: Perform quick Mandelbrot plot benchmarks.\n* `save`: Save the Mandelbrot plot to a file.\n\nIf no options are entered, the default is `benchmarks log stdout tests`. If the file `default_args.txt` exists in the same folder, the test program reads the default arguments from it (space separated in a single line). Command line arguments can still override these defaults. This is useful when debugging.\n\nThe following macros can be defined during compilation (using the `-D` flag in Clang and GCC or `/D` in MSVC) to enable additional features:\n\n* `BS_THREAD_POOL_TEST_IMPORT_MODULE`: Import the thread pool library [as a C&plus;&plus;20 module](#importing-the-library-as-a-c20-module). Note that the module must be compiled beforehand, as explained in the relevant section.\n* `BS_THREAD_POOL_NATIVE_EXTENSIONS`: Test the [native extensions](#native-extensions). If importing the library as a C&plus;&plus;20 module, ensure that the library was compiled with the same macro.\n\nA Python script, `test_all.py`, is provided for convenience in the `scripts` folder. This script makes use of the bundled [`compile_cpp.py` script](#the-compile_cpppy-script), and requires Python 3.12 or later. The script will automatically detect if Clang, GCC, and/or MSVC are available, and compile and run the test program using each available compiler 3 times:\n\n1. With C&plus;&plus;17 support.\n2. With C&plus;&plus;20 support, using `import BS.thread_pool`.\n3. With C&plus;&plus;23 support, using `import BS.thread_pool`, and using `import std` on supported compilers.\n\nIf any of the tests fail, please [submit a bug report](https://github.com/bshoshany/thread-pool/issues) including the exact specifications of your system (OS, CPU, compiler, etc.) and the generated log file. However, please note that only the latest versions of each compiler are supported.\n\n### Performance tests\n\n`BS_thread_pool_test.cpp` also performs benchmarks, using a highly-optimized multithreaded algorithm which generates a plot of the [Mandelbrot set](https://en.wikipedia.org/wiki/Mandelbrot_set), utilizing a normalized iteration count algorithm and linear interpolation to create smooth coloring. If tests are enabled, the benchmarks will only be performed if all of the tests pass.\n\nThese benchmarks are heavily CPU-intensive, which results in a high speedup factor due to multithreading, ideally utilizing every core and thread to their fullest extent. This makes them useful for optimizing the library, since they are more sensitive to the thread pool's own performance than to other factors such as memory or cache.\n\nThe full benchmarks are enabled using the command line argument `benchmarks`, which is enabled by default. The command line argument `plot` can be used to just plot the Mandelbrot set once, either instead of or in addition to doing the full benchmarks. This will plot the largest possible image that can be plotted in 5 seconds, and only measure the performance in pixels/ms for the entire plot.\n\nIf you want to see the actual plot, pass the `save` command line argument. The plot is saved to a BMP file, to avoid having to depend on 3rd-party libraries. This is off by default, since that file can get quite large.\n\nThe program determines the optimal resolution of the Mandelbrot plot by testing how many pixels are needed to reach a certain target duration when parallelizing the loop using a number of tasks equal to the number of threads. This ensures that the benchmarks take approximately the same amount of time (per thread) on all systems, and are thus more consistent and portable.\n\nOnce the appropriate resolution has been determined, the program plots the Mandelbrot set. For more details about the algorithm used, please see the source code for `BS_thread_pool_test.cpp`. This operation is performed both single-threaded and multithreaded, with the multithreaded computation spread across multiple tasks submitted to the pool.\n\nMultithreaded tests are performed with increasingly higher task counts, while keeping the number of threads in the pool equal to the hardware concurrency for optimal performance. Each test is repeated multiple times, with the run times averaged over all runs of the same test. The program keeps increasing the number of tasks by a factor of 2 until diminishing returns are encountered. The run times of the tests are compared, and the maximum speedup obtained compared to the single-threaded test is calculated.\n\nIf the [native extensions](#native-extensions) are enabled, the program will try to increase the priority of both the process itself and all the threads in the pool to the highest possible value, to prevent other processes from interfering with the benchmarks. Therefore, to obtain the most reliable benchmarks, it is recommended to run the tests as a privileged user, especially on Linux or macOS where only root can increase the priority.\n\nAs an example, here are the results of the benchmarks running on a 24-core (8P+16E) / 32-thread Intel i9-13900K CPU. The tests were compiled using MSVC in C&plus;&plus;23 mode, to obtain maximum performance using the latest C&plus;&plus;23 features. Compiler optimizations were enabled using the `/O2` flag. The benchmarks were run 5 times, and the result with the median speedup was as follows:\n\n```none\nGenerating a 3965x3965 plot of the Mandelbrot set...\nEach test will be repeated 30 times to collect reliable statistics.\n   1 task:  [..............................]  (single-threaded)\n-> Mean:  510.5 ms, standard deviation:  0.5 ms, speed:  1026.5 pixels/ms.\n   8 tasks: [..............................]\n-> Mean:  149.1 ms, standard deviation:  0.6 ms, speed:  3514.7 pixels/ms.\n  16 tasks: [..............................]\n-> Mean:   85.4 ms, standard deviation:  2.5 ms, speed:  6133.9 pixels/ms.\n  32 tasks: [..............................]\n-> Mean:   48.3 ms, standard deviation:  1.8 ms, speed: 10849.7 pixels/ms.\n  64 tasks: [..............................]\n-> Mean:   29.1 ms, standard deviation:  1.0 ms, speed: 17987.7 pixels/ms.\n 128 tasks: [..............................]\n-> Mean:   23.6 ms, standard deviation:  0.7 ms, speed: 22173.8 pixels/ms.\n 256 tasks: [..............................]\n-> Mean:   22.5 ms, standard deviation:  0.6 ms, speed: 23325.3 pixels/ms.\n 512 tasks: [..............................]\n-> Mean:   21.8 ms, standard deviation:  0.5 ms, speed: 24075.4 pixels/ms.\n1024 tasks: [..............................]\n-> Mean:   21.9 ms, standard deviation:  0.7 ms, speed: 23892.4 pixels/ms.\nMaximum speedup obtained by multithreading vs. single-threading: 23.5x, using 512 tasks.\n```\n\nThis CPU has 24 cores, of which 8 are fast (5.40 GHz max) performance cores with hyperthreading (thus providing 16 threads in total), and 16 are slower (4.30 GHz max) efficiency cores without hyperthreading, for a total of 32 threads.\n\nDue to the hybrid architecture, it is not trivial to calculate the theoretical maximum speedup. However, we can get a rough estimate by noticing that the E-cores are about 20% slower than the P-cores, and that hyperthreading is generally known to provide around a 30% speedup. Thus, the estimated theoretical speedup (compared to a single P-core) is 8 &times; 1.3 + 16 &times; 0.8 = 23.2x.\n\nThe actual median speedup obtained, 23.5x, is slightly above this estimate, which indicates that the thread pool provides optimal performance and allows the Mandelbrot plot algorithm to take full advantage of the CPU's capabilities.\n\nIt should also be noted that even though the available number of hardware threads is 32, the maximum possible speedup is achieved not with 32 tasks, but with 512 tasks - half the square of the number of hardware threads. The reason for this is that splitting the job into more tasks than threads eliminates thread idle time, as explained [above](#optimizing-the-number-of-blocks). However, at 1024 tasks we encounter diminishing returns, as the overhead of submitting the tasks to the pool starts to outweigh the benefits of parallelization.\n\n### Finding the version of the library\n\nStarting with v5.0.0, the thread pool library defines the `constexpr` object `BS::thread_pool_version`, which can be used to check the version of the library at compilation time. This object is of type `BS::version`, with members `major`, `minor`, and `patch`, and all comparison operators defined as `constexpr`. It also has a `to_string()` member function and an `operator<<` overload for easy printing at runtime.\n\nSince `BS::thread_pool_version` is a `constexpr` object, it can be used in any context where a `constexpr` object is allowed, such as `static_assert()` and `if constexpr`. For example, the following program will fail to compile if the version is not 5.1.0 or higher:\n\n```cpp\n#include \"BS_thread_pool.hpp\"\n\nstatic_assert(BS::thread_pool_version >= BS::version(5, 1, 0), \"This program requires version 5.1.0 or later of the BS::thread_pool library.\");\n\nint main()\n{\n    // ...\n}\n```\n\nAs another example, the following program will print the version of the library (this will implicitly use the `<<` operator of `BS::version`) and then conditionally compile one of two branches of code depending on the version of the library:\n\n```cpp\n#include \"BS_thread_pool.hpp\" // BS::synced_stream, BS::thread_pool\n\nBS::synced_stream sync_out;\nBS::thread_pool pool;\n\nint main()\n{\n    sync_out.println(\"Detected BS::thread_pool v\", BS::thread_pool_version, '.');\n    if constexpr (BS::thread_pool_version <= BS::version(5, 1, 0))\n    {\n        // Do something supported by BS::thread_pool v5.1.0 or earlier.\n    }\n    else\n    {\n        // Do something supported by newer versions of BS::thread_pool after v5.1.0.\n    }\n}\n```\n\nCurrently, both the examples above are of pedagogical value only, because `BS::thread_pool_version` was only introduced in v5.0.0, and that is also the latest version at the time of writing, so there are no other versions to compare to. However, once future versions of the library are released, this object will be the preferred way to do version checking.\n\nFor backwards compatibility, if you are not sure if you are going to get v4 or v5 of the library, you can check the version using the following preprocessor macros, which were introduced in v4.0.1:\n\n* `BS_THREAD_POOL_VERSION_MAJOR` - indicates the major version.\n* `BS_THREAD_POOL_VERSION_MINOR` - indicates the minor version.\n* `BS_THREAD_POOL_VERSION_PATCH` - indicates the patch version.\n\nThese macros allow for conditional inclusion of code using `#if` directives. As an example, the member function [`set_cleanup_func()`](#thread-cleanup-functions) was introduced in v5.0.0. Therefore, if the major version number is 5 or higher, we can use this function; otherwise, we must find some other way to do the cleanup:\n\n ```cpp\n#include \"BS_thread_pool.hpp\" // BS::synced_stream, BS::thread_pool\n\nBS::synced_stream sync_out;\nBS::thread_pool pool;\n\nint main()\n{\n#if BS_THREAD_POOL_VERSION_MAJOR >= 5\n    pool.set_cleanup_func(\n        []\n        {\n            sync_out.println(\"Doing cleanup...\");\n        });\n#else\n    // Do the cleanup in some other way.\n#endif\n}\n```\n\nHowever, please note that if the library is imported [as a C&plus;&plus;20 module](#importing-the-library-as-a-c20-module), these macros will not be available, since macros cannot be exported from a module. In this case, you must use `BS::thread_pool_version` instead. (Indeed, this is exactly why it was introduced in the first place.)\n\n## Importing the library as a C&plus;&plus;20 module\n\n### Compiling the module\n\nIf C&plus;&plus;20 features are available, the library can be imported as a C&plus;&plus;20 module using `import BS.thread_pool`. This is the officially recommended way to use the library, as it has many benefits, such as faster compilation times, better encapsulation, no namespace pollution, no include order issues, easier maintainability, simpler dependency management, and more. The `constexpr` flag `BS::thread_pool_module` indicates whether the thread pool library was compiled as a module. For more information on C&plus;&plus;20 modules, please see [cppreference.com](https://en.cppreference.com/w/cpp/language/modules).\n\nThe module file itself is `BS.thread_pool.cppm`, located in the `modules` folder, and it is just a thin wrapper around the header file `BS_thread_pool.hpp`. The C&plus;&plus;20 standard does not provide a way for one file to be used as both a module and a header file, so both files are needed in order to compile the library as a module. (However, to use the library as a header file, only `BS_thread_pool.hpp` is needed.)\n\nNote that the header file `BS_thread_pool.hpp` has an underscore `_` following `BS`, for backwards compatibility with older versions of the library. However, the module file `BS.thread_pool.cppm` has a dot `.` following `BS`, to conform with the C&plus;&plus;20 module naming convention, where dots represent hierarchy; all modules written by the author of this library will use the `BS.` prefix.\n\nThis feature has been tested with the latest versions of Clang, GCC, and MSVC. Unfortunately, at the time of writing, C&plus;&plus;20 modules are still not fully implemented in all compilers, and each compiler implements them differently.\n\nThe easiest way to compile the module itself, as well as any programs that import it, is using the `compile_cpp.py` Python script provided in [the GitHub repository](https://github.com/bshoshany/thread-pool), which will automatically figure out the appropriate flags for each compiler. Please see the [next section](#compiling-with-compile_cpppy-using-import-bsthread_pool) for more information.\n\nHowever, if you prefer to compile manually, the module must first be compiled into a binary file, in a format specific to each compiler, as described in the following sections. Once it is compiled once and for all, this binary file (plus an object file, in MSVC) is the only file needed to import the library; the `.cppm` and `.hpp` files are no longer needed. However, any program using the module must be compiled with a flag indicating to the compiler where to find that binary file.\n\nOnce the module is compiled, it can be imported using `import BS.thread_pool`. In all the examples above, you can simply replace `#include \"BS_thread_pool.hpp\"` with `import BS.thread_pool;` in order to import the library as a module. The only exception is the [native extensions](#native-extensions), which are enabled in the examples using a macro; as explained in that section, the macro must be defined as a compiler flag, as modules cannot access macros defined in the program that imported them.\n\nHere is a quick example:\n\n```cpp\nimport BS.thread_pool;\n\nBS::synced_stream sync_out;\nBS::thread_pool pool;\n\nint main()\n{\n    pool.submit_task(\n            []\n            {\n                sync_out.println(\"Thread pool library successfully imported using C++20 modules!\");\n            })\n        .wait();\n}\n```\n\nBelow we will provide the commands for compiling the library as a module and then compiling [the test program](#testing-the-library) `BS_thread_pool_test.cpp` using this module, with Clang, GCC, and MSVC, as well as with CMake. In [the GitHub repository](https://github.com/bshoshany/thread-pool), the relevant files are organized as follows:\n\n```\n README.md                     <- this documentation file\n include\n    BS_thread_pool.hpp        <- the header file\n modules\n    BS.thread_pool.cppm       <- the module file\n tasks\n    compile_cpp.py            <- the compile script (optional)\n tests\n     BS_thread_pool_test.cpp   <- the test program\n```\n\nIn the following examples, it is assumed that the commands are executed in the root directory of the repository (the one that contains `README.md`). The compiled files will be placed in a `build` subdirectory, which should be created beforehand.\n\n### Compiling with `compile_cpp.py` using `import BS.thread_pool`\n\nThe bundled Python script [`compile_cpp.py`](#the-compile_cpppy-script) can be used to easily compile any programs that import the library as a module. The script will automatically figure out the appropriate flags for each compiler, so you do not have to worry about the details. For example, to compile the test program `BS_thread_pool_test.cpp` and have it import the `BS.thread_pool` module, simply run the following command in the root folder of the repository:\n\n```bash\npython scripts/compile_cpp.py tests/BS_thread_pool_test.cpp -s=c++20 -i=include -t=release -m=\"BS.thread_pool=modules/BS.thread_pool.cppm,include/BS_thread_pool.hpp\" -o=build/BS_thread_pool_test -d=BS_THREAD_POOL_TEST_IMPORT_MODULE -v\n```\n\nPlease see [below](#the-compile_cpppy-script) for an explanation of the command line arguments. The `-d` argument defines the macro `BS_THREAD_POOL_TEST_IMPORT_MODULE`, which is used to indicate to the test program that it needs to import the library as a module instead of including the header file. **Note that this macro is only used by the test program; it is not needed when you compile your own programs.** To enable the [native extensions](#native-extensions), you should also add `-d=BS_THREAD_POOL_NATIVE_EXTENSIONS` to define the required macro. To use C&plus;&plus;23, replace `-s=c++20` with `-s=c++23`.\n\nSince we used `-t=release`, optimization flags will be added automatically. If you now type `build/BS_thread_pool_test`, the test program will run; you can also add the argument `-r` to run it automatically after compilation. If the module was successfully imported, the test program will print the message:\n\n```none\nThread pool library imported using: import BS.thread_pool (C++20 modules).\n```\n\nFor further customization, it is recommend to create a `compile_cpp.yaml` file as explained [below](#the-compile_cpppy-script).\n\n### Compiling with Clang using `import BS.thread_pool`\n\nNote: The following instructions have only been tested using Clang v19.1.6, the latest version at the time of writing, and may not work with older versions of the compiler.\n\nTo compile the module file `BS.thread_pool.cppm` with Clang, first create the `build` folder using `mkdir build`, and then run the following command in the root folder of the repository:\n\n```bash\nclang++ modules/BS.thread_pool.cppm --precompile -std=c++20 -I include -o build/BS.thread_pool.pcm\n```\n\nHere is a breakdown of the compiler arguments:\n\n* `modules/BS.thread_pool.cppm`: The module file to compile. Note that it will include the file `include/BS_thread_pool.hpp` automatically.\n* `--precompile`: Do not run the linker, only compile the module.\n* `-std=c++20`: Use the C&plus;&plus;20 standard. For C&plus;&plus;23, use `-std=c++23`.\n* `-I include`: Add the `include` folder to the include path, so that the module can find the header file `BS_thread_pool.hpp`.\n* `-o build/BS.thread_pool.pcm`: Output the compiled module to `build/BS.thread_pool.pcm`. The extension `.pcm` is used by Clang for precompiled modules.\n\nNote that to enable the [native extensions](#native-extensions), you should add `-D BS_THREAD_POOL_NATIVE_EXTENSIONS` to define the required macro.\n\nOnce the module is compiled, you can compile the test program as follows:\n\n```bash\nclang++ tests/BS_thread_pool_test.cpp -fmodule-file=\"BS.thread_pool=build/BS.thread_pool.pcm\" -std=c++20 -o build/BS_thread_pool_test -D BS_THREAD_POOL_TEST_IMPORT_MODULE\n```\n\nHere is a breakdown of the compiler arguments:\n\n* `tests/BS_thread_pool_test.cpp`: The program to compile.\n* `-fmodule-file=\"BS.thread_pool=build/BS.thread_pool.pcm\"`: Specify that the module `BS.thread_pool` is located in the file `build/BS.thread_pool.pcm`.\n* `-std=c++20`: Same as above.\n* `-o build/BS_thread_pool_test`: Output the compiled program to `build/BS_thread_pool_test` (or `build/BS_thread_pool_test.exe` on Windows).\n* `-D BS_THREAD_POOL_TEST_IMPORT_MODULE`: Define the macro `BS_THREAD_POOL_TEST_IMPORT_MODULE`, which is used to indicate to the test program that it needs to import the library as a module instead of including the header file. **Note that this macro is only used by the test program; it is not needed when you compile your own programs.**\n\nAgain, you should add `-D BS_THREAD_POOL_NATIVE_EXTENSIONS` if you wish to test the native extensions. You do not need to use the `-I` flag, since the header file is not needed, only the `.pcm` file. If you now type `build/BS_thread_pool_test`, the test program will run. If the module was successfully imported, the test program will print the message:\n\n```none\nThread pool library imported using: import BS.thread_pool (C++20 modules).\n```\n\nOf course, you should add warning, debugging, optimization, and other compiler flags to the commands above as needed. For more information about using C&plus;&plus;20 modules with Clang, please see [the official documentation](https://clang.llvm.org/docs/StandardCPlusPlusModules.html).\n\n**Note:** On macOS, Apple Clang v16.0.0 (the latest version at the time of writing) does not support C&plus;&plus;20 modules. Please either install the latest version of LLVM Clang using [Homebrew](https://formulae.brew.sh/formula/llvm), or include the library as a header file.\n\n### Compiling with GCC using `import BS.thread_pool`\n\nNote: The following instructions have only been tested using GCC v14.2.0, the latest version at the time of writing, and may not work with older versions of the compiler.\n\nTo compile the module file `BS.thread_pool.cppm` with GCC, first create the `build` folder using `mkdir build`, and then run the following command in the root folder of the repository:\n\n```bash\ng++ -x c++ modules/BS.thread_pool.cppm -c \"-fmodule-mapper=|@g++-mapper-server -r build\" -fmodule-only -fmodules-ts -std=c++20 -I include\n```\n\nHere is a breakdown of the compiler arguments:\n\n* `-x c++`: Treat the input file as a C&plus;&plus; file. This is necessary because the file has the `.cppm` extension, which is not recognized by GCC.\n* `modules/BS.thread_pool.cppm`: The module file to compile. Note that it will include the file `include/BS_thread_pool.hpp` automatically.\n* `-c`: Do not run the linker, only compile the module.\n* `\"-fmodule-mapper=|@g++-mapper-server -r build\"`: Specify to the module mapper that the compiled module should be placed in the `build` folder. This will create a file `build/BS.thread_pool.gcm`. The extension `.gcm` is used by GCC for compiled modules.\n* `-fmodule-only`: Do not create an object file for the module.\n* `-fmodules-ts`: Enable C&plus;&plus;20 modules.\n* `-std=c++20`: Use the C&plus;&plus;20 standard. For C&plus;&plus;23, use `-std=c++23`.\n* `-I include`: Add the `include` folder to the include path, so that the module can find the header file `BS_thread_pool.hpp`.\n\nNote that to enable the [native extensions](#native-extensions), you should add `-D BS_THREAD_POOL_NATIVE_EXTENSIONS` to define the required macro.\n\nOnce the module is compiled, you can compile the test program as follows:\n\n```bash\ng++ tests/BS_thread_pool_test.cpp \"-fmodule-mapper=|@g++-mapper-server -r build\" -fmodules-ts -std=c++20 -o build/BS_thread_pool_test -D BS_THREAD_POOL_TEST_IMPORT_MODULE\n```\n\nHere is a breakdown of the compiler arguments:\n\n* `tests/BS_thread_pool_test.cpp`: The program to compile.\n* `\"-fmodule-mapper=|@g++-mapper-server -r build\"`: Specify to the module mapper that the compiled module can be found in the `build` folder. It will look for the file `build/BS.thread_pool.gcm`.\n* `-fmodules-ts`, `-std=c++20`: Same as above.\n* `-o build/BS_thread_pool_test`: Output the compiled program to `build/BS_thread_pool_test` (or `build/BS_thread_pool_test.exe` on Windows).\n* `-D BS_THREAD_POOL_TEST_IMPORT_MODULE`: Define the macro `BS_THREAD_POOL_TEST_IMPORT_MODULE`, which is used to indicate to the test program that it needs to import the library as a module instead of including the header file. **Note that this macro is only used by the test program; it is not needed when you compile your own programs.**\n\nAgain, you should add `-D BS_THREAD_POOL_NATIVE_EXTENSIONS` if you wish to test the native extensions. You do not need to use the `-I` flag, since the header file is not needed, only the `.gcm` file. If you now type `build/BS_thread_pool_test`, the test program will run. If the module was successfully imported, the test program will print the message:\n\n```none\nThread pool library imported using: import BS.thread_pool (C++20 modules).\n```\n\nOf course, you should add warning, debugging, optimization, and other compiler flags to the commands above as needed. For more information about using C&plus;&plus;20 modules with GCC, please see [the official documentation](https://gcc.gnu.org/onlinedocs/gcc/C_002b_002b-Modules.html).\n\n**Note:** GCC v14.2.0 (latest version at the time of writing) appears to have an internal compiler error when compiling programs containing modules (or at least, this particular module) with any optimization flags other than `-Og` enabled. Until this is fixed, if you wish to use compiler optimizations, please either include the library as a header file or use a different compiler.\n\n### Compiling with MSVC using `import BS.thread_pool`\n\nNote: The following instructions have only been tested using MSVC v19.42.34435, the latest version at the time of writing, and may not work with older versions of the compiler.\n\nTo compile the module file `BS.thread_pool.cppm` with MSVC, first open the Visual Studio Developer PowerShell for the appropriate CPU architecture. For example, for x64, execute the following command in PowerShell:\n\n```pwsh\n& 'C:\\Program Files\\Microsoft Visual Studio\\2022\\Community\\Common7\\Tools\\Launch-VsDevShell.ps1' -Arch amd64 -HostArch amd64\n```\n\nFor ARM64, replace `amd64` with `arm64`. (Do not use the \"Developer PowerShell for VS 2022\" Start Menu shortcut, as it may not use the correct CPU architecture by default.)\n\nNavigate to the repository folder, create the `build` folder using `mkdir build`, and then run the following command in the root folder of the repository:\n\n```pwsh\ncl modules/BS.thread_pool.cppm /c /EHsc /interface /nologo /permissive- /std:c++20 /TP /Zc:__cplusplus /I include /ifcOutput build/BS.thread_pool.ifc /Fo:build/BS.thread_pool.obj\n```\n\nHere is a breakdown of the compiler arguments:\n\n* `modules/BS.thread_pool.cppm`: The module file to compile. Note that it will include the file `include/BS_thread_pool.hpp` automatically.\n* `/c`: Do not run the linker, only compile the module.\n* `/EHsc`: Enable C&plus;&plus; exceptions.\n* `/interface`: Treat the input file as a module interface unit. This is needed because MSVC expects the `.ixx` extension for the module file, but this library uses the `.cppm` extension.\n* `/nologo`: Do not display the compiler's banner.\n* `/permissive-`: Disable permissive behaviors, that is, enforce strict C&plus;&plus; standard conformance.\n* `/std:c++20`: Use the C&plus;&plus;20 standard. For C&plus;&plus;23, use `/std:c++latest`.\n* `/TP`: Treat the input file as a C&plus;&plus; file. This is necessary because the file has the `.cppm` extension, which is not recognized by MSVC.\n* `/Zc:__cplusplus`: Make the `__cplusplus` preprocessor macro correctly reflect the C&plus;&plus; standard being used.\n* `/I include`: Add the `include` folder to the include path, so that the module can find the header file `BS_thread_pool.hpp`.\n* `/ifcOutput build/BS.thread_pool.ifc`: Output the compiled module to `build/BS.thread_pool.ifc`. The extension `.ifc` is used by MSVC for module interface files.\n* `/Fo:build/BS.thread_pool.obj`: Output the compiled object file to `build/BS.thread_pool.obj`.\n\nNote that to enable the [native extensions](#native-extensions), you should add `/D BS_THREAD_POOL_NATIVE_EXTENSIONS` to define the required macro.\n\nOnce the module is compiled, you can compile the test program as follows:\n\n```pwsh\ncl tests/BS_thread_pool_test.cpp build/BS.thread_pool.obj /reference BS.thread_pool=build/BS.thread_pool.ifc /EHsc /nologo /permissive- /std:c++20 /Zc:__cplusplus /Fo:build/BS_thread_pool_test.obj /Fe:build/BS_thread_pool_test.exe /D BS_THREAD_POOL_TEST_IMPORT_MODULE\n```\n\nHere is a breakdown of the compiler arguments:\n\n* `tests/BS_thread_pool_test.cpp`: The program to compile.\n* `build/BS.thread_pool.obj`: The module object file to link to the program.\n* `/reference BS.thread_pool=build/BS.thread_pool.ifc`: Specify that the module `BS.thread_pool` is located in the file `build/BS.thread_pool.ifc`.\n* `/EHsc`, `/nologo`, `/permissive-`, `/std:c++20`, `/Zc:__cplusplus`: Same as above.\n* `/Fo:build/BS_thread_pool_test.obj`: Output the compiled object file to `build/BS_thread_pool_test.obj`.\n* `/Fe:build/BS_thread_pool_test.exe`: Output the compiled program to `build/BS_thread_pool_test.exe`.\n* `/D BS_THREAD_POOL_TEST_IMPORT_MODULE`: Define the macro `BS_THREAD_POOL_TEST_IMPORT_MODULE`, which is used to indicate to the test program that it needs to import the library as a module instead of including the header file. **Note that this macro is only used by the test program; it is not needed when you compile your own programs.**\n\nAgain, you should add `/D BS_THREAD_POOL_NATIVE_EXTENSIONS` if you wish to test the native extensions. You do not need to use the `/I` flag, since the header file is not needed, only the `.obj` and `.ifc` files. If you now type `build/BS_thread_pool_test`, the test program will run. If the module was successfully imported, the test program will print the message:\n\n```none\nThread pool library imported using: import BS.thread_pool (C++20 modules).\n```\n\nOf course, you should add warning, debugging, optimization, and other compiler flags to the commands above as needed. For more information about using C&plus;&plus;20 modules with MSVC, please see [this blog post](https://devblogs.microsoft.com/cppblog/using-cpp-modules-in-msvc-from-the-command-line-part-1/).\n\n### Compiling with CMake using `import BS.thread_pool`\n\nNote: The following instructions have only been tested using CMake v3.31.2, the latest version at the time of writing, and may not work with older versions. Also, modules are currently only supported by CMake with the [`Ninja`](https://ninja-build.org/) and `Visual Studio 17 2022` generators.\n\nIf you are using [CMake](https://cmake.org/), you can use `target_sources()` with `CXX_MODULES` to include the module file `BS.thread_pool.cppm`. CMake will then automatically compile the module and link it to your program. Here is an example of a `CMakeLists.txt` file that can be used to build the test program and import the thread pool library as a module:\n\n```cmake\ncmake_minimum_required(VERSION 3.31)\nproject(BS_thread_pool_test LANGUAGES CXX)\nset(CMAKE_CXX_STANDARD 20)\nset(CMAKE_CXX_STANDARD_REQUIRED ON)\nset(CMAKE_CXX_EXTENSIONS OFF)\n\nif(MSVC)\n    add_compile_options(/permissive- /Zc:__cplusplus)\nendif()\n\nadd_library(BS_thread_pool)\ntarget_sources(BS_thread_pool PRIVATE FILE_SET CXX_MODULES FILES modules/BS.thread_pool.cppm)\ntarget_include_directories(BS_thread_pool PRIVATE include)\n\nadd_executable(${PROJECT_NAME} tests/BS_thread_pool_test.cpp)\ntarget_link_libraries(${PROJECT_NAME} PRIVATE BS_thread_pool)\ntarget_compile_definitions(${PROJECT_NAME} PRIVATE BS_THREAD_POOL_TEST_IMPORT_MODULE)\n```\n\nNote that for MSVC we have to add the `/permissive-` flag to enforce strict C&plus;&plus; standard conformance, otherwise the test program will not compile, and `/Zc:__cplusplus`, otherwise the test program cannot detect the correct C&plus;&plus; version. This is handled automatically by the `if(MSVC)` block.\n\nTo enable the [native extensions](#native-extensions), add the line `add_compile_definitions(BS_THREAD_POOL_NATIVE_EXTENSIONS)`. Replace `CMAKE_CXX_STANDARD 20` with `23` if you wish to use C&plus;&plus;23 features.\n\nPlace this file in the root folder of the repository, and then run the following commands:\n\n```bash\ncmake -B build\ncmake --build build\nbuild/BS_thread_pool_test\n```\n\nFor MSVC, replace the last command with `build/Debug/BS_thread_pool_test`. If the module was successfully imported, the test program will print the message:\n\n```none\nThread pool library imported using: import BS.thread_pool (C++20 modules).\n```\n\nOf course, you should add warning, debugging, optimization, and other compiler flags to the configuration above as needed. For more information about using C&plus;&plus;20 modules with CMake, please see [the official documentation](https://cmake.org/cmake/help/latest/manual/cmake-cxxmodules.7.html).\n\nYou can also instruct CMake to download the library automatically from the GitHub repository, as explained below, either using [CPM](#installing-using-cmake-with-cpm) or [`FetchContent`](#installing-using-cmake-with-fetchcontent).\n\n## Importing the C&plus;&plus;23 Standard Library as a module\n\n### Enabling `import std`\n\nIf C&plus;&plus;23 features are available, the thread pool library can import the C&plus;&plus; Standard Library as a module using `import std`. This has the same benefits described [above](#importing-the-library-as-a-c20-module) for importing the library as a module, such as faster compilation times. To enable this feature, define the macro `BS_THREAD_POOL_IMPORT_STD` at compilation time.\n\nAt the time of writing, importing the C&plus;&plus; Standard Library as a module is only officially supported by the following combinations of compilers and standard libraries:\n\n* Recent versions of MSVC with Microsoft STL.\n* Recent versions of LLVM Clang (**not** Apple Clang) with LLVM libc&plus;&plus;.\n\nIt is not supported by GCC with any standard library, Clang with any standard library other than libc&plus;&plus;, any compiler with GNU libstdc&plus;&plus;, or any other compiler or standard library.\n\nIf `BS_THREAD_POOL_IMPORT_STD` is defined, then you must also import the thread pool library itself as a module. If the library is included as a header file, this will force the program that included the header file to also import `std`, which is not desirable and can lead to compilation errors if the program `#include`s any Standard Library header files.\n\nDefining the macro before importing the module will not work, as modules cannot access macros defined in the program that imported them. Instead, you must define the macro as a compiler flag: `-D BS_THREAD_POOL_IMPORT_STD` for Clang and GCC or `/D BS_THREAD_POOL_IMPORT_STD` for MSVC.\n\n[The test program](#testing-the-library) will also import the `std` module if the macro `BS_THREAD_POOL_IMPORT_STD` is defined at compilation time. In that case, you should also enable the macro `BS_THREAD_POOL_TEST_IMPORT_MODULE` to import the thread pool library as a module.\n\nThe `constexpr` flag `BS::thread_pool_import_std` indicates whether the thread pool library was compiled with `import std`. Note that the flag will be `false` if `BS_THREAD_POOL_IMPORT_STD` is defined but the compiler or standard library does not support importing the C&plus;&plus; Standard Library as a module.\n\nAt the time of writing, importing the `std` module requires compiling it first. As explained in the [previous section](#importing-the-library-as-a-c20-module), using the bundled `compile_cpp.py` script is the easiest way to do this, as we show in the [next section](#compiling-with-compile_cpppy-using-import-std). However, for those who wish to compile manually, in the following sections we will explain how to do it with both Clang and MSVC, as well as with CMake. It is assumed that the reader has already read the section about importing the `BS.thread_pool` library as a module, so we omit some details here.\n\n### Compiling with `compile_cpp.py` using `import std`\n\nThe bundled Python script [`compile_cpp.py`](#the-compile_cpppy-script) can be used to easily compile any programs that import the C&plus;&plus; Standard Library as a module. The script will automatically figure out the appropriate flags for each compiler, so you do not have to worry about the details. For example, to compile the test program `BS_thread_pool_test.cpp` and have it import both the `BS.thread_pool` module and the `std` module, simply run the following command in the root folder of the repository:\n\n```bash\npython scripts/compile_cpp.py tests/BS_thread_pool_test.cpp -s=c++23 -i=include -t=release -m=\"BS.thread_pool=modules/BS.thread_pool.cppm,include/BS_thread_pool.hpp\" -o=build/BS_thread_pool_test -d=BS_THREAD_POOL_TEST_IMPORT_MODULE -d=BS_THREAD_POOL_IMPORT_STD -u=auto -v\n```\n\nPlease see [below](#the-compile_cpppy-script) for an explanation of the command line arguments. The differences between this command and the one we used for [importing the thread pool library as a module](#compiling-with-compile_cpppy-using-import-bsthread_pool) are:\n\n* Changed `-s=c++20` to `-s=c++23` so we can use the C&plus;&plus;23 standard.\n* Added `-d=BS_THREAD_POOL_IMPORT_STD` to define the required macro.\n* Added `-u=auto` to automatically detect the location of the `std` module. If this doesn't work, you will need to specify the path manually.\n\nTo enable the [native extensions](#native-extensions), you should also add `-d=BS_THREAD_POOL_NATIVE_EXTENSIONS` to define the required macro. If you now type `build/BS_thread_pool_test`, the test program will run. If the `std` module was successfully imported, the test program will print the message:\n\n```none\nC++ Standard Library imported using:\n* Thread pool library: import std (C++23 std module).\n* Test program: import std (C++23 std module).\n```\n\nFor further customization, it is recommend to create a `compile_cpp.yaml` file as explained [below](#the-compile_cpppy-script).\n\n### Compiling with Clang and LLVM libc&plus;&plus; using `import std`\n\nNote: The following instructions have only been tested using Clang v19.1.6 and LLVM libc&plus;&plus; v19.1.6, the latest versions at the time of writing, and may not work with older versions.\n\nBefore compiling the `std` module, you must find the file `std.cppm`:\n\n* On Windows, libc&plus;&plus; is most likely installed via [MSYS2](https://www.msys2.org/), so the `std` module should be at `C:\\msys64\\clang64\\share\\libc&plus;&plus;\\v1\\std.cppm`. If you did not install MSYS2 in `C:\\msys64`, replace that with the correct path. If you installed libc&plus;&plus; without MSYS2, locate `std.cppm` manually in the installation folder.\n* On Linux, the `std` module should be at `/usr/lib/llvm-<LLVM major version>/share/libc&plus;&plus;/v1/std.cppm`. Replace `<LLVM major version>` with the major version number of libc&plus;&plus;, e.g. `19`. If you installed libc&plus;&plus; in a different folder, locate `std.cppm` manually in that folder.\n* On macOS, the `std` module should be at `/usr/local/Cellar/llvm/<LLVM full version>/share/libc&plus;&plus;/v1/std.cppm`. Replace `<LLVM full version>` with the full version number of libc&plus;&plus;, e.g. `19.1.6`. If you installed libc&plus;&plus; in a different folder, locate `std.cppm` manually in that folder.\n\nTo compile the module file `std.cppm` with Clang, first create the `build` folder using `mkdir build`, and then run the following command in the root folder of the repository:\n\n```bash\nclang++ \"path to std.cppm\" --precompile -std=c++23 -o build/std.pcm -Wno-reserved-module-identifier\n```\n\nOf course, you should replace `\"path to std.cppm\"` with the actual path. The compiler arguments are explained [above](#compiling-with-clang-using-import-bsthread_pool). The additional argument `-Wno-reserved-module-identifier` is needed to silence a false-positive warning.\n\nNext, compile the `BS.thread_pool` module as [above](#compiling-with-clang-using-import-bsthread_pool), but with the following additional flags:\n\n* `-fmodule-file=\"std=build/std.pcm\"`: Specify that the module `std` is located in the file `build/std.pcm`.\n* `-D BS_THREAD_POOL_IMPORT_STD`: Instruct the library to import the `std` module.\n\n```bash\nclang++ modules/BS.thread_pool.cppm --precompile -fmodule-file=\"std=build/std.pcm\" -std=c++23 -I include -o build/BS.thread_pool.pcm -D BS_THREAD_POOL_IMPORT_STD\n```\n\nAdd `-D BS_THREAD_POOL_NATIVE_EXTENSIONS` if you wish to enable the [native extensions](#native-extensions). Once the module is compiled, you can compile the test program as follows:\n\n```bash\nclang++ tests/BS_thread_pool_test.cpp -fmodule-file=\"std=build/std.pcm\" -fmodule-file=\"BS.thread_pool=build/BS.thread_pool.pcm\" -std=c++23 -o build/BS_thread_pool_test -D BS_THREAD_POOL_TEST_IMPORT_MODULE -D BS_THREAD_POOL_IMPORT_STD\n```\n\nAgain, you should add `-D BS_THREAD_POOL_NATIVE_EXTENSIONS` if you wish to test the native extensions. If you now type `build/BS_thread_pool_test`, the test program will run. If the `std` module was successfully imported, the test program will print the message:\n\n```none\nC++ Standard Library imported using:\n* Thread pool library: import std (C++23 std module).\n* Test program: import std (C++23 std module).\n```\n\n### Compiling with MSVC and Microsoft STL using `import std`\n\nNote: The following instructions have only been tested using MSVC v19.42.34435 and Microsoft STL v143 (202408), the latest versions at the time of writing, and may not work with older versions.\n\nBefore compiling the `std` module, you must find the file `std.ixx`. It should be located in the folder `C:\\Program Files\\Microsoft Visual Studio\\2022\\Community\\VC\\Tools\\MSVC\\<MSVC runtime version>\\modules`. Replace `<MSVC runtime version>` with the full version number of the MSVC runtime library, e.g. `14.42.34433`. If you installed Visual Studio in a different folder, locate `std.ixx` manually in that folder.\n\nTo compile the module file `std.ixx` with MSVC, first open the Visual Studio Developer PowerShell for the appropriate CPU architecture as explained [above](#compiling-with-msvc-using-import-bsthread_pool). Navigate to the repository folder, create the `build` folder using `mkdir build`, and then run the following command in the root folder of the repository:\n\n```pwsh\ncl \"path to std.ixx\" /c /EHsc /nologo /permissive- /std:c++latest /Zc:__cplusplus /ifcOutput build/std.ifc /Fo:build/std.obj\n```\n\nOf course, you should replace `\"path to std.ixx\"` with the actual path. The compiler arguments are explained [above](#compiling-with-msvc-using-import-bsthread_pool).\n\nNext, compile the `BS.thread_pool` module as [above](#compiling-with-msvc-using-import-bsthread_pool), but with the following additional flags:\n\n* `/reference std=build/std.ifc`: Specify that the module `std` is located in the file `build/std.ifc`.\n* `/D BS_THREAD_POOL_IMPORT_STD`: Instruct the library to import the `std` module.\n\n```pwsh\ncl modules/BS.thread_pool.cppm /reference std=build/std.ifc /c /EHsc /interface /nologo /permissive- /std:c++latest /TP /Zc:__cplusplus /I include /ifcOutput build/BS.thread_pool.ifc /Fo:build/BS.thread_pool.obj /D BS_THREAD_POOL_IMPORT_STD\n```\n\nAdd `/D BS_THREAD_POOL_NATIVE_EXTENSIONS` if you wish to enable the [native extensions](#native-extensions). Once the module is compiled, you can compile the test program as follows (note that we added `build/std.obj` to link with the `std` module):\n\n```pwsh\ncl tests/BS_thread_pool_test.cpp build/std.obj build/BS.thread_pool.obj /reference std=build/std.ifc /reference BS.thread_pool=build/BS.thread_pool.ifc /EHsc /nologo /permissive- /std:c++latest /Zc:__cplusplus /Fo:build/BS_thread_pool_test.obj /Fe:build/BS_thread_pool_test.exe /D BS_THREAD_POOL_TEST_IMPORT_MODULE /D BS_THREAD_POOL_IMPORT_STD\n```\n\nAgain, you should add `/D BS_THREAD_POOL_NATIVE_EXTENSIONS` if you wish to test the native extensions. If you now type `build/BS_thread_pool_test`, the test program will run. If the `std` module was successfully imported, the test program will print the message:\n\n```none\nC++ Standard Library imported using:\n* Thread pool library: import std (C++23 std module).\n* Test program: import std (C++23 std module).\n```\n\n### Compiling with CMake using `import std`\n\nNote: The following instructions have only been tested using CMake v3.31.2, the latest version at the time of writing, and may not work with older versions. Also, modules are currently only supported by CMake with the [`Ninja`](https://ninja-build.org/) and `Visual Studio 17 2022` generators.\n\nIf you are using [CMake](https://cmake.org/), you can enable `CMAKE_EXPERIMENTAL_CXX_IMPORT_STD` to automatically compile the `std` module, provided the compiler and standard library support it. Here is an example of a `CMakeLists.txt` file that can be used to build the test program, import the thread pool library as a module, and import the C&plus;&plus; Standard Library as a module:\n\n```cmake\ncmake_minimum_required(VERSION 3.31)\nproject(BS_thread_pool_test LANGUAGES CXX)\nset(CMAKE_CXX_STANDARD 23)\nset(CMAKE_CXX_STANDARD_REQUIRED ON)\nset(CMAKE_CXX_EXTENSIONS OFF)\nset(CMAKE_EXPERIMENTAL_CXX_IMPORT_STD ON)\n\nadd_compile_definitions(BS_THREAD_POOL_IMPORT_STD)\n\nif(MSVC)\n    add_compile_options(/permissive- /Zc:__cplusplus)\nendif()\n\nadd_library(BS_thread_pool)\ntarget_sources(BS_thread_pool PRIVATE FILE_SET CXX_MODULES FILES modules/BS.thread_pool.cppm)\ntarget_include_directories(BS_thread_pool PRIVATE include)\n\nadd_executable(${PROJECT_NAME} tests/BS_thread_pool_test.cpp)\ntarget_link_libraries(${PROJECT_NAME} PRIVATE BS_thread_pool)\ntarget_compile_definitions(${PROJECT_NAME} PRIVATE BS_THREAD_POOL_TEST_IMPORT_MODULE)\n```\n\nThe `if(MSVC)` block is explained [above](#compiling-with-msvc-using-import-bsthread_pool). To enable the [native extensions](#native-extensions), add the macro `BS_THREAD_POOL_NATIVE_EXTENSIONS` to `add_compile_definitions()`.\n\nPlace this file in the root folder of the repository, and then run the following commands:\n\n```bash\ncmake -B build\ncmake --build build\nbuild/BS_thread_pool_test\n```\n\nFor MSVC, replace the last command with `build/Debug/BS_thread_pool_test`. If the `std` module was successfully imported, the test program will print the message:\n\n```none\nC++ Standard Library imported using:\n* Thread pool library: import std (C++23 std module).\n* Test program: import std (C++23 std module).\n```\n\nYou can also instruct CMake to download the library automatically from the GitHub repository, as explained below, either using [CPM](#installing-using-cmake-with-cpm) or [`FetchContent`](#installing-using-cmake-with-fetchcontent).\n\n## Installing the library using package managers\n\n### Installing using vcpkg\n\nIf you are using the [vcpkg](https://vcpkg.io/) C/C&plus;&plus; package manager, you can easily install `BS::thread_pool` with the following command:\n\n```bash\nvcpkg install bshoshany-thread-pool\n```\n\nTo update the package to the latest version, run:\n\n```bash\nvcpkg upgrade\n```\n\nPlease refer to [this package's page on vcpkg.io](https://vcpkg.io/en/package/bshoshany-thread-pool) for more information.\n\n### Installing using Conan\n\nIf you are using the [Conan](https://conan.io/) C/C&plus;&plus; package manager, you can easily integrate `BS::thread_pool` into your project by adding the following lines to your `conanfile.txt`:\n\n```ini\n[requires]\nbshoshany-thread-pool/5.0.0\n```\n\nTo update the package to the latest version, simply change the version number. Please refer to [this package's page on ConanCenter](https://conan.io/center/recipes/bshoshany-thread-pool) for more information.\n\n### Installing using Meson\n\nIf you are using the [Meson](https://mesonbuild.com/) build system, you can install `BS::thread_pool` from [WrapDB](https://mesonbuild.com/Wrapdb-projects.html). To do so, create a `subprojects` folder in your project (if it does not already exist) and run the following command:\n\n```bash\nmeson wrap install bshoshany-thread-pool\n```\n\nThen, use `dependency('bshoshany-thread-pool')` in your `meson.build` file to include the package. To update the package to the latest version, run:\n\n```bash\nmeson wrap update bshoshany-thread-pool\n```\n\n### Installing using CMake with CPM\n\nNote: The following instructions have only been tested using CMake v3.31.2 and CPM v0.40.2, the latest versions at the time of writing, and may not work with older versions.\n\nIf you are using [CMake](https://cmake.org/), you can install `BS::thread_pool` most easily with [CPM](https://github.com/cpm-cmake/CPM.cmake). If CPM is already installed, simply add the following to your project's `CMakeLists.txt`:\n\n```cmake\nCPMAddPackage(\n    NAME BS_thread_pool\n    GITHUB_REPOSITORY bshoshany/thread-pool\n    VERSION 5.0.0\n    EXCLUDE_FROM_ALL\n    SYSTEM\n)\nadd_library(BS_thread_pool INTERFACE)\ntarget_include_directories(BS_thread_pool INTERFACE ${BS_thread_pool_SOURCE_DIR}/include)\n```\n\nThis will automatically download the indicated version of the package from [the GitHub repository](https://github.com/bshoshany/thread-pool) and include it in your project.\n\nA convenient shorthand for GitHub packages also exists, in which case `CPMAddPackage()` can be called with a single argument of the form `\"gh:user/name@version\"`. After that, `CPM_LAST_PACKAGE_NAME` will be set to the name of the package, so we need to use this variable to define the include folder. This results in a more compact configuration:\n\n```cmake\nCPMAddPackage(\"gh:bshoshany/thread-pool@5.0.0\")\nadd_library(BS_thread_pool INTERFACE)\ntarget_include_directories(BS_thread_pool INTERFACE ${${CPM_LAST_PACKAGE_NAME}_SOURCE_DIR}/include)\n```\n\nIt is also possible to use CPM without installing it first, by adding the following lines to `CMakeLists.txt` before `CPMAddPackage()`:\n\n```cmake\nset(CPM_DOWNLOAD_LOCATION ${CMAKE_BINARY_DIR}/CPM.cmake)\nif(NOT(EXISTS ${CPM_DOWNLOAD_LOCATION}))\n    file(DOWNLOAD https://github.com/cpm-cmake/CPM.cmake/releases/latest/download/CPM.cmake ${CPM_DOWNLOAD_LOCATION})\nendif()\ninclude(${CPM_DOWNLOAD_LOCATION})\n```\n\nHere is an example of a complete `CMakeLists.txt` which automatically downloads and compiles the test program [`BS_thread_pool_test.cpp`](#automated-tests):\n\n```cmake\ncmake_minimum_required(VERSION 3.31)\nproject(BS_thread_pool_test LANGUAGES CXX)\nset(CMAKE_CXX_STANDARD 17)\nset(CMAKE_CXX_STANDARD_REQUIRED ON)\nset(CMAKE_CXX_EXTENSIONS OFF)\n\nif(MSVC)\n    add_compile_options(/permissive- /Zc:__cplusplus)\nendif()\n\nset(CPM_DOWNLOAD_LOCATION ${CMAKE_BINARY_DIR}/CPM.cmake)\nif(NOT(EXISTS ${CPM_DOWNLOAD_LOCATION}))\n    file(DOWNLOAD https://github.com/cpm-cmake/CPM.cmake/releases/latest/download/CPM.cmake ${CPM_DOWNLOAD_LOCATION})\nendif()\ninclude(${CPM_DOWNLOAD_LOCATION})\n\nCPMAddPackage(\"gh:bshoshany/thread-pool@5.0.0\")\nadd_library(BS_thread_pool INTERFACE)\ntarget_include_directories(BS_thread_pool INTERFACE ${${CPM_LAST_PACKAGE_NAME}_SOURCE_DIR}/include)\n\nadd_executable(${PROJECT_NAME} ${${CPM_LAST_PACKAGE_NAME}_SOURCE_DIR}/tests/BS_thread_pool_test.cpp)\ntarget_link_libraries(${PROJECT_NAME} PRIVATE BS_thread_pool)\n```\n\nNote that for MSVC we have to add the `/permissive-` flag to enforce strict C&plus;&plus; standard conformance, otherwise the test program will not compile, and `/Zc:__cplusplus`, otherwise the test program cannot detect the correct C&plus;&plus; version. This is handled automatically by the `if(MSVC)` block.\n\nTo enable the [native extensions](#native-extensions), add the line `add_compile_definitions(BS_THREAD_POOL_NATIVE_EXTENSIONS)`. Replace `CMAKE_CXX_STANDARD 17` with `20` or `23` if you wish to use C&plus;&plus;20 or C&plus;&plus;23 features, respectively. Of course, you should add warning, debugging, optimization, and other compiler flags to the configuration above as needed.\n\nWith this `CMakeLists.txt` in an empty folder, type the following commands to build and run the project:\n\n```bash\ncmake -B build\ncmake --build build\nbuild/BS_thread_pool_test\n```\n\nFor MSVC, replace the last command with `build/Debug/BS_thread_pool_test`. Please see [here](#compiling-with-cmake-using-import-bsthread_pool) for instructions on how to import the library as a C&plus;&plus;20 module with CMake, and [here](#compiling-with-cmake-using-import-std) for instructions on how to import the C&plus;&plus; Standard Library as a module with CMake.\n\n### Installing using CMake with `FetchContent`\n\nNote: The following instructions have only been tested using CMake v3.31.2, the latest version at the time of writing, and may not work with older versions.\n\nIf you are using [CMake](https://cmake.org/) but do not wish to use 3rd-party tools, you can also install `BS::thread_pool` using the built-in [`FetchContent`](https://cmake.org/cmake/help/latest/module/FetchContent.html) module. Here is an example of a complete `CMakeLists.txt` which automatically downloads and compiles the test program, as in the previous section, but this time using `FetchContent` directly:\n\n```cmake\ncmake_minimum_required(VERSION 3.31)\nproject(BS_thread_pool_test LANGUAGES CXX)\nset(CMAKE_CXX_STANDARD 17)\nset(CMAKE_CXX_STANDARD_REQUIRED ON)\nset(CMAKE_CXX_EXTENSIONS OFF)\n\nif(MSVC)\n    add_compile_options(/permissive- /Zc:__cplusplus)\nendif()\n\ninclude(FetchContent)\nset(FETCHCONTENT_UPDATES_DISCONNECTED ON)\nFetchContent_Declare(\n    bshoshany_thread_pool\n    GIT_REPOSITORY https://github.com/bshoshany/thread-pool.git\n    GIT_TAG v5.0.0\n    DOWNLOAD_EXTRACT_TIMESTAMP TRUE\n    EXCLUDE_FROM_ALL\n    SYSTEM\n)\nFetchContent_MakeAvailable(bshoshany_thread_pool)\nadd_library(BS_thread_pool INTERFACE)\ntarget_include_directories(BS_thread_pool INTERFACE ${bshoshany_thread_pool_SOURCE_DIR}/include)\n\nadd_executable(${PROJECT_NAME} ${bshoshany_thread_pool_SOURCE_DIR}/tests/BS_thread_pool_test.cpp)\ntarget_link_libraries(${PROJECT_NAME} PRIVATE BS_thread_pool)\n```\n\n## Complete library reference\n\nThis section provides a complete reference for all classes and functions available in this library, along with other important information. Functions are given with simplified prototypes (e.g. removing `const`) for ease of reading. Explanations are kept brief, as the purpose of this section is only to provide a quick reference; for more detailed information and usage examples, please refer to the full documentation above.\n\nDescriptions of each item can also be found in the [Doxygen](https://www.doxygen.nl/) comments embedded in the source code. Any modern IDE, such as [Visual Studio Code](https://code.visualstudio.com/), can use these Doxygen comments to provide automatic documentation for any class and member function in this library when hovering over code with the mouse or using auto-complete.\n\n### The `BS::thread_pool` class template\n\n`BS::thread_pool` is the main thread pool class. It is used to create a pool of threads that continuously execute tasks submitted to a queue. It can take template parameters, which enable optional features as described [below](#optional-features-and-the-template-parameter). The member functions that are available by default, when no template parameters are used, are:\n\n* Constructors:\n    * `thread_pool()`: Construct a new thread pool with a number of threads equal to `std::thread::hardware_concurrency()`.\n    * `thread_pool(std::size_t num_threads)`: Construct a new thread pool with the specified number of threads.\n    * `thread_pool(F&& init)`: Construct a new thread pool with a number of threads equal to `std::thread::hardware_concurrency()` and the specified initialization function. `F` is a template parameter.\n    * `thread_pool(std::size_t num_threads, F&& init)`: Construct a new thread pool with the specified number of threads and the specified initialization function.\n* Resetters:\n    * `void reset()`: Reset the pool with a number of threads equal to `std::thread::hardware_concurrency()`, waiting for running tasks first, and preserving submitted tasks after the reset.\n    * `void reset(std::size_t num_threads)`: Reset the pool with a new number of threads.\n    * `void reset(F&& init)` Reset the pool with a number of threads equal to `std::thread::hardware_concurrency()` and a new initialization function. `F` is a template parameter.\n    * `void reset(std::size_t num_threads, F&& init)`: Reset the pool with a new number of threads and a new initialization function.\n* Setters:\n    * `void set_cleanup_func(F&& cleanup)`: Set the thread pool's cleanup function. `F` is a template parameter.\n* Getters:\n    * `std::size_t get_tasks_queued()`: Get the number of tasks currently waiting in the queue to be executed by the threads.\n    * `std::size_t get_tasks_running()`: Get the number of tasks currently being executed by the threads.\n    * `std::size_t get_tasks_total()`: Get the total number of unfinished tasks: either still waiting in the queue, or running in a thread. Note that `get_tasks_total() == get_tasks_queued() + get_tasks_running()`.\n    * `std::size_t get_thread_count()`: Get the number of threads in the pool.\n    * `std::vector<std::thread::id> get_thread_ids()`: Get a vector containing the unique identifiers for each of the pool's threads, as obtained by `std::thread::get_id()` (or `std::jthread::get_id()` in C&plus;&plus;20 and later).\n* Task submission without futures (`T1`, `T2`, and `F` are template parameters):\n    * `void detach_task(F&& task)`: Submit a function with no arguments and no return value into the task queue. To submit a function with arguments, enclose it in a lambda expression.\n    * `void detach_blocks(T1 first_index, T2 index_after_last, F&& block, std::size_t num_blocks = 0)`: Parallelize a loop by automatically splitting it into blocks. The block function takes two arguments, the start and end of the block, so that it is only called once per block, but it is up to the user make sure the block function correctly deals with all the indices in each block.\n    * `void detach_loop(T1 first_index, T2 index_after_last, F&& loop, std::size_t num_blocks = 0)`: Parallelize a loop by automatically splitting it into blocks. The loop function takes one argument, the loop index, so that it is called many times per block.\n    * `void detach_sequence(1T first_index, T2 index_after_last, F&& sequence)`: Submit a sequence of tasks enumerated by indices to the queue. The sequence function takes one argument, the task index, and will be called once per index.\n* Task submission with futures (`T1`, `T2`, `F`, and `R` are template parameters):\n    * `std::future<R> submit_task(F&& task)`: Submit a function with no arguments into the task queue. To submit a function with arguments, enclose it in a lambda expression.\n    * `BS::multi_future<R> submit_blocks(T1 first_index, T2 index_after_last, F&& block, std::size_t num_blocks = 0)`: Parallelize a loop by automatically splitting it into blocks. The block function takes two arguments, the start and end of the block, so that it is only called once per block, but it is up to the user make sure the block function correctly deals with all the indices in each block. Returns a `BS::multi_future` that contains the futures for all of the blocks.\n    * `BS::multi_future<void> submit_loop(T1 first_index, T2 index_after_last, F&& loop, std::size_t num_blocks = 0)`: Parallelize a loop by automatically splitting it into blocks. The loop function takes one argument, the loop index, so that it is called many times per block. It must have no return value. Returns a `BS::multi_future` that contains the futures for all of the blocks.\n    * `BS::multi_future<R> submit_sequence(T1 first_index, T2 index_after_last, F&& sequence)`: Submit a sequence of tasks enumerated by indices to the queue. The sequence function takes one argument, the task index, and will be called once per index. Returns a `BS::multi_future` that contains the futures for all of the tasks.\n* Task management:\n    * `void purge()`: Purge all the tasks waiting in the queue. Please note that there is no way to restore the purged tasks.\n* Waiting for tasks (`R`, `P`, `C`, and `D` are template parameters):\n    * `void wait()`: Wait for all tasks to be completed, both those that are currently running in the threads and those that are still waiting in the queue.\n    * `bool wait_for(std::chrono::duration<R, P>& duration)`: Wait for tasks to be completed, but stop waiting after the specified duration has passed. Returns `true` if all tasks finished running, `false` if the duration expired but some tasks are still running.\n    * `bool wait_until(std::chrono::time_point<C, D>& timeout_time)`: Wait for tasks to be completed, but stop waiting after the specified time point has been reached. Returns `true` if all tasks finished running, `false` if the time point was reached but some tasks are still running.\n* Destructor:\n    * `~thread_pool()`: Wait for all tasks to complete, then destroy all threads. If a cleanup function was set, it will run in each thread right before it is destroyed.\n\n### Optional features and the template parameter\n\nThe thread pool has several optional features that must be explicitly enabled by passing a template parameter. The template parameter is a bitmask, so you can enable several features at once by combining them with the bitwise OR operator `|`. The bitmask flags are members of the `BS::tp` enumeration.\n\n* **Task priority:** Enabled by turning on the `BS::tp::priority` flag in the template parameter. When enabled, the static member `priority_enabled` will be set to `true`.\n    * When enabled, the priority of a task or group of tasks may be specified as an additional argument (at the end of the argument list) to all detach and submit functions. If the priority is not specified, the default value will be 0.\n    * The priority is of type `BS::priority_t`, a signed 8-bit integer, with values between -128 and +127. The tasks will be executed in priority order from highest to lowest. Groups of parallelized tasks will all have the same priority.\n    * The enumeration `BS::pr` contains some pre-defined priorities: `BS::pr::highest`, `BS::pr::high`, `BS::pr::normal`, `BS::pr::low`, and `BS::pr::lowest`.\n* **Pausing:** Enabled by turning on the `BS::tp::pause` flag in the template parameter. When enabled, the static member `pause_enabled` will be set to `true`. Adds the following member functions:\n    * `void pause()`: Pause the pool. The workers will temporarily stop retrieving new tasks out of the queue, although any tasks already executed will keep running until they are finished.\n    * `void unpause()`: Unpause the pool. The workers will resume retrieving new tasks out of the queue.\n    * `bool is_paused()`: Check whether the pool is currently paused.\n* **Wait deadlock checks:** Enabled by turning on the `BS::tp::wait_deadlock_checks` flag in the template parameter. When enabled, the static member `wait_deadlock_checks_enabled` will be set to `true`.\n    * When enabled, `wait()`, `wait_for()`, and `wait_until()` will check whether the user tried to call them from within a thread of the same pool, which would result in a deadlock. If so, they will throw the exception `BS::wait_deadlock` instead of waiting.\n    * If the feature-test macro `__cpp_exceptions` is undefined, wait deadlock checks will be automatically disabled, and trying to enable this feature will result in a compilation error.\n\nConvenience aliases are defined as follows:\n\n* `BS::light_thread_pool` disables all optional features (equivalent to `BS::thread_pool` with the default template parameter, that is, `BS::thread_pool<BS::tp::none>`).\n* `BS::priority_thread_pool` enables task priority (equivalent to `BS::thread_pool<BS::tp::priority>`).\n* `BS::pause_thread_pool` enables pausing the pool (equivalent to `BS::thread_pool<BS::tp::pause>`).\n* `BS::wdc_thread_pool` enables wait deadlock checks (equivalent to `BS::thread_pool<BS::tp::wait_deadlock_checks>`).\n\n### The `BS::this_thread` class\n\nThe class `BS::this_thread` provides functionality analogous to `std::this_thread`. It contains the following static member functions:\n\n* `static std::optional<std::size_t> get_index()`: Get the index of the current thread. The optional object will not have a value if the thread is not in a pool.\n* `static std::optional<void*> get_pool()`: Get a pointer to the thread pool that owns the current thread. The optional object will not have a value if the thread is not in a pool.\n\nIf the [native extensions](#the-native-extensions) are enabled, the class will contain additional static member functions. Please see the relevant section for more information.\n\n### The native extensions\n\nThe native extensions may be enabled by defining the macro `BS_THREAD_POOL_NATIVE_EXTENSIONS` at compilation time. If including the library as a header file, the macro must be defined before `#include \"BS_thread_pool.hpp\"`. If importing the library as a C&plus;&plus;20 module, the macro must be defined as a compiler flag. The native extensions use the operating system's native API, and are thus not portable; however, they should work on Windows, Linux, and macOS.\n\nThe native extensions add the following functions to the `BS` namespace:\n\n* `bool set_os_process_affinity(std::vector<bool>& affinity)`: Set the processor affinity of the current process. The argument is an `std::vector<bool>` where each element corresponds to a logical processor. Returns `true` if the affinity was set successfully, `false` otherwise. Does not work on macOS.\n* `std::optional<std::vector<bool>> BS::get_os_process_affinity()`: Get the processor affinity of the current process. The optional object will not have a value if the affinity could not be determined. Does not work on macOS.\n* `bool BS::set_os_process_priority(BS::os_process_priority priority)`: Set the priority of the current process. The argument must be a member of the `BS::os_process_priority` enumeration, which contains the options `idle`, `below_normal`, `normal`, `above_normal`, `high`, and `realtime`. Returns `true` if the priority was set successfully, or `false` otherwise.\n* `std::optional<BS::os_process_priority> BS::get_os_process_priority()`: Get the priority of the current process. The optional object will not have a value if the priority could not be determined, or it is not one of the pre-defined values in the `BS::os_process_priority` enumeration.\n\nThe native extensions also add the following static member functions to `BS::this_thread`:\n\n* `bool set_os_thread_affinity(std::vector<bool>& affinity)`: Set the processor affinity of the current thread. The argument is an `std::vector<bool>` where each element corresponds to a logical processor. Note that the thread affinity must be a subset of the process affinity for the containing process of a thread. Does not work on macOS.\n* `std::optional<std::vector<bool>> get_os_thread_affinity()`: Get the processor affinity of the current thread. The optional object will not have a value if the affinity could not be determined. Does not work on macOS.\n* `bool set_os_thread_name(std::string& name)`: Set the name of the current thread. Note that on Linux thread names are limited to 16 characters, including the null terminator. Returns `true` if the name was set successfully, `false` otherwise.\n* `std::optional<std::string> get_os_thread_name()`: Get the name of the current thread. The optional object will not have a value if the name could not be determined.\n* `bool set_os_thread_priority(BS::os_thread_priority priority)`: Set the priority of the current thread. The argument must be a member of the `BS::os_thread_priority` enumeration, which contains the options `idle`, `lowest`, `below_normal`, `normal`, `above_normal`, `highest`, and `realtime`. Returns `true` if the priority was set successfully, or `false` otherwise.\n* `std::optional<os_thread_priority> get_os_thread_priority()`: Get the priority of the current thread. The optional object will not have a value if the priority could not be determined, or it is not one of the pre-defined values in the `BS::os_thread_priority` enumeration.\n\nFinally, the native extensions add the following member function to `BS::thread_pool`:\n\n* `std::vector<std::thread::native_handle_type> get_native_handles()`: Get a vector containing the underlying implementation-defined thread handles for each of the pool's threads.\n\n### The `BS::multi_future` class\n\n`BS::multi_future<T>` is a helper class used to facilitate waiting for and/or getting the results of multiple futures at once. It is defined as a specialization of `std::vector<std::future<T>>`. This means that all of the member functions that can be used on an [`std::vector<std::future<T>>`](https://en.cppreference.com/w/cpp/container/vector) can also be used on a `BS::multi_future<T>`. For example, you may use a range-based for loop with a `BS::multi_future<T>`, since it has iterators.\n\nIn addition to inherited member functions, `BS::multi_future<T>` has the following specialized member functions (`R` and `P`, `C`, and `D` are template parameters):\n\n* `[void or std::vector<T>] get()`: Get the results from all the futures stored in this `BS::multi_future`, rethrowing any stored exceptions. If the futures return `void`, this function returns `void` as well. If the futures return a type `T`, this function returns a vector containing the results.\n* `std::size_t ready_count()`: Check how many of the futures stored in this `BS::multi_future` are ready.\n* `bool valid()`: Check if all the futures stored in this `BS::multi_future` are valid.\n* `void wait()`: Wait for all the futures stored in this `BS::multi_future`.\n* `bool wait_for(std::chrono::duration<R, P>& duration)`: Wait for all the futures stored in this `BS::multi_future`, but stop waiting after the specified duration has passed. Returns `true` if all futures have been waited for before the duration expired, `false` otherwise.\n* `bool wait_until(std::chrono::time_point<C, D>& timeout_time)`: Wait for all the futures stored in this `BS::multi_future` object, but stop waiting after the specified time point has been reached. Returns `true` if all futures have been waited for before the time point was reached, `false` otherwise.\n\n### The `BS::synced_stream` class\n\n`BS::synced_stream` is a utility class which can be used to synchronize printing to one or more output streams by different threads. It has the following member functions (`T` is a template parameter pack):\n\n* `synced_stream()`: Construct a new synced stream which prints to `std::cout`.\n* `synced_stream(T&... streams)`: Construct a new synced stream which prints to the given output streams.\n* `void add_stream(std::ostream& stream)`: Add a stream to the list of output streams.\n* `std::vector<std::ostream*>& get_streams()`: Get a reference to a vector containing pointers to the output streams to print to.\n* `void print(T&... items)`: Print any number of items into the output streams. Ensures that no other threads print to the streams simultaneously, as long as they all exclusively use the same `BS::synced_stream` object to print.\n* `void println(T&&... items)`: Print any number of items into the output streams, followed by a newline character.\n* `void remove_stream(std::ostream& stream)`: Remove a stream from the list of output streams.\n\nIn addition, the class comes with two stream manipulators, which are meant to help the compiler figure out which template specializations to use with the class:\n\n* `BS::synced_stream::endl`: An explicit cast of `std::endl`. Prints a newline character to the stream, and then flushes it. Should only be used if flushing is desired, otherwise a newline character should be used instead.\n* `BS::synced_stream::flush`: An explicit cast of `std::flush`. Used to flush the stream.\n\n### The `BS::version` class\n\n`BS::version` is a utility class used to represent a version number. It has public members `major`, `minor`, and `patch`, as well as the following member functions:\n\n* `constexpr version(std::uint64_t major, std::uint64_t minor, std::uint64_t patch)`: Construct a new version object with the specified major, minor, and patch numbers.\n* `std::strong_ordering operator<=>(version&)`: 3-way comparison operator for two version numbers, in C&plus;&plus;20 and later. In C&plus;&plus;17, the operators `==`, `!=`, `<`, `<=`, `>`, `>=` are instead defined explicitly.\n* `std::string to_string()`: Convert the version number to a string in the format `\"major.minor.patch\"`.\n* `std::ostream& operator<<(std::ostream& stream, version& ver)`: Output the version string to a stream.\n\nIn addition, the library defines a `constexpr` object `BS::thread_pool_version` of type `BS::version`, which can be used to check the version of the library at compilation time.\n\nNote that this feature is only available starting with v5.0.0 of the library; previous versions used the macros `BS_THREAD_POOL_VERSION_MAJOR`, `BS_THREAD_POOL_VERSION_MINOR`, and `BS_THREAD_POOL_VERSION_PATCH`, which are still defined for compatibility purposes, but are not accessible if the library is imported as a C&plus;&plus;20 module.\n\n### Diagnostic variables\n\nThe library defines the following `constexpr` variables:\n\n* `bool thread_pool_import_std`: Indicates whether the library imported the C&plus;&plus;23 Standard Library module using `import std`.\n* `bool thread_pool_module`: Indicates whether the library was compiled as a C&plus;&plus;20 module.\n* `bool thread_pool_native_extensions`: Indicates whether the native extensions are enabled.\n\n### All names exported by the C&plus;&plus;20 module\n\nWhen the library is imported as a C&plus;&plus;20 module using `import BS.thread_pool`, it exports the following names, in alphabetical order:\n\n* `BS::binary_semaphore`\n* `BS::common_index_type_t`\n* `BS::counting_semaphore`\n* `BS::light_thread_pool`\n* `BS::multi_future`\n* `BS::pause_thread_pool`\n* `BS::pr`\n* `BS::priority_t`\n* `BS::priority_thread_pool`\n* `BS::synced_stream`\n* `BS::this_thread`\n* `BS::thread_pool`\n* `BS::thread_pool_import_std`\n* `BS::thread_pool_module`\n* `BS::thread_pool_native_extensions`\n* `BS::thread_pool_version`\n* `BS::tp`\n* `BS::version`\n* `BS::wait_deadlock`\n* `BS::wdc_thread_pool`\n\nIf the native extensions are enabled, the following names are also exported:\n\n* `BS::get_os_process_affinity`\n* `BS::get_os_process_priority`\n* `BS::os_process_priority`\n* `BS::os_thread_priority`\n* `BS::set_os_process_affinity`\n* `BS::set_os_process_priority`\n\n## Development tools\n\n### The `compile_cpp.py` script\n\nThe Python script `compile_cpp.py`, in the `scripts` folder of [the GitHub repository](https://github.com/bshoshany/thread-pool), can be used to compile any C&plus;&plus; source file with different compilers on different platforms. It requires Python 3.12 or later.\n\nThe script was written by the author of the library to make it easier to test the library with different combinations of compilers, standards, and platforms using the built-in Visual Studio Code tasks. However, note that this script is not meant to replace CMake or any full-fledged build system, it's just a convenient script for developing single-header libraries like this one or other small projects.\n\nThe `compile_cpp.py` script also transparently handles C&plus;&plus;20 modules and importing the C&plus;&plus; Standard Library as a module in C&plus;&plus;23. Therefore, users of this library who wish to import it as a C&plus;&plus;20 module may find this script particularly useful.\n\nThe compilation parameters can be configured using the command line arguments and/or via an optional YAML configuration file `compile_cpp.yaml`. The command line arguments are as follows:\n\n* Positional argument(s): the source file(s) to compile.\n* `-h` or `--help`: Show the help message and exit.\n* `-a` or `--arch`: The target architecture (MSVC only). Must be one of `[amd64, arm64]`, default is `amd64`.\n* `-c` or `--compiler`: Which compiler to use. Must be one of `[cl, clang++, g++]`. The default is to determine it automatically based on the platform.\n* `-d` or `--define`: Macros to define. Use this argument multiple times to define more than one macro. Additional macros can be defined in `compile_cpp.yaml`.\n* `-f` or `--flag`: Extra compiler flags to add. Use this argument multiple times to add more than one flag. Additional flags can be specified in `compile_cpp.yaml`.\n* `-i` or `--include`: The include folder to use. Use this argument multiple times to use more than one include folder. Additional include folders can be specified in `compile_cpp.yaml`.\n* `-l` or `--as-module`: Enable this flag to compile the file as a C&plus;&plus;20 module.\n* `-m` or `--module`: C&plus;&plus;20 module files to use if desired, in the format `module_name=module_file,dependent_files,...`. Use this argument multiple times to use more than one module. Additional modules can be specified in `compile_cpp.yaml`. The dependent files are only used to determine whether the module needs to be recompiled.\n* `-o` or `--output`: The output folder and/or executable name. End with `/` to create the folder if it doesn't already exist. If not specified, the folder defined in `compile_cpp.yaml` will be used. If the executable name is not specified, it will be determined automatically in the format `source_[module_]type-compiler-standard` where:\n    * `source` is the name of the first source file (without the extension).\n    * `module_`, if present, indicates that the file is a C&plus;&plus;20 module.\n    * `type` is one of `[debug, release]`.\n    * `compiler` is one of `[clang, gcc, msvc]`.\n    * `standard` is one of `[c++17, c++20, c++23]`.\n* `-p` or `--pass`: Pass command line arguments to the compiled program when running it, if `-r` is specified. Use this argument multiple times to pass more than one argument to the program. Additional arguments can be specified in `compile_cpp.yaml`.\n* `-r` or `--run`: Enable this flag to run the program after compiling it.\n* `-s` or `--std`: Which C&plus;&plus; standard to use. Must be one of `[c++17, c++20, c++23]`. The default is `c++23`.\n* `-t` or `--type`: Which mode to compile in. Must be one of `[debug, release]`. The default is `debug`.\n* `-u` or `--std-module`: Specify the path to the standard library module (C&plus;&plus;23 only). Taken from `compile_cpp.yaml` if not specified. Use `auto` to auto-detect or `disable` to explicitly disable.\n* `-v` or `--verbose`: Enable this flag to print the script's diagnostic messages.\n\nThe `compile_cpp.yaml` file includes the following fields:\n\n* `defines`: A list of macros to define when compiling the source files.\n* `flags`: A map of flags to pass to each compiler. The compiler should be one of `[cl, clang++, g++]`. The flags should be a list of strings.\n* `includes`: A list of include folders.\n* `modules`: A map of C&plus;&plus;20 modules in the format `module_name: [module_path, dependent files, ...]`. Will only be used in C&plus;&plus;20 or C&plus;&plus;23 mode. The dependent files are only used to determine whether the module needs to be recompiled.\n* `output`: The output folder for the compiled files.\n* `pass_args`: A list of arguments to pass to the program if running it after compilation.\n* `std_module`: A map of paths to the standard library modules for each OS and compiler combination (C&plus;&plus;23 only). The OS should be one of `[Windows, Linux, Darwin]`. Use `Automatic` to determine the path automatically if possible.\n\nPlease see the `compile_cpp.yaml` file in the GitHub repository for an example of how to use it.\n\n### Other included tools\n\nThe `scripts` folder of [the GitHub repository](https://github.com/bshoshany/thread-pool) contains two other Python scripts that are used in the development of the library:\n\n* `test_all.py` performs the [automated tests](#automated-tests) in C&plus;&plus;17, C&plus;&plus;20, and C&plus;&plus;23 modes, using all compilers available in the system (Clang, GCC, and/or MSVC). Since there are so many tests, the test script does not perform the benchmarks, as that would take too long. Pass the optional argument `--compile-only` to only check that the program compiles successfully with all compilers, without running it.\n* `clear_folder.py` is used to clean up output and temporary folders. It will create the folder if it does not already exist, so the outcome is always an empty folder.\n\nIn addition, for Visual Studio Code users, the GitHub repository includes three `.vscode` folders:\n\n* `.vscode-windows`, to be used in Windows with Clang, GCC, and MSVC.\n* `.vscode-linux`, to be used in Linux with Clang and GCC.\n* `.vscode-macos`, to be used in macOS with LLVM Clang (not Apple Clang).\n\nEach folder contains appropriate `c_cpp_properties.json`, `launch.json`, and `tasks.json` files that utilize the included Python scripts. Users are welcome to use these files in their own projects, but they may require some modifications to work on specific systems.\n\n## About the project\n\n### Bug reports and feature requests\n\nThis library is under continuous and active development. If you encounter any bugs, or if you would like to request any additional features, please feel free to [open a new issue on GitHub](https://github.com/bshoshany/thread-pool/issues) and I will look into it as soon as I can.\n\n### Contribution and pull request policy\n\nContributions are always welcome. However, I release my projects in cumulative updates after editing and testing them locally on my system, so **my policy is to never accept any pull requests**. If you open a pull request, and I decide to incorporate your suggestion into the project, I will first modify your code to comply with the project's coding conventions (formatting, syntax, naming, comments, programming practices, etc.), and perform some tests to ensure that the change doesn't break anything. I will then merge it into the next release of the project, possibly together with some other changes. The new release will also include a note in `CHANGELOG.md` with a link to your pull request, and modifications to the documentation in `README.md` as needed.\n\n### Starring the repository\n\nIf you found this project useful, please consider [starring it on GitHub](https://github.com/bshoshany/thread-pool/stargazers)! This allows me to see how many people are using my code, and motivates me to keep working to improve it.\n\n### Acknowledgements\n\nMany GitHub users have helped improve this project, directly or indirectly, via issues, pull requests, comments, and/or personal correspondence. Please see `CHANGELOG.md` for links to specific issues and pull requests that have been the most helpful. Thank you all for your contribution! \n\n### Copyright and citing\n\nCopyright (c) 2024 [Barak Shoshany](https://baraksh.com/). Licensed under the [MIT license](https://github.com/bshoshany/thread-pool/blob/master/LICENSE.txt).\n\nIf you use this library in software of any kind, please provide a link to [the GitHub repository](https://github.com/bshoshany/thread-pool) in the source code and documentation.\n\nIf you use this library in published research, please cite it as follows:\n\n* Barak Shoshany, *\"A C++17 Thread Pool for High-Performance Scientific Computing\"*, [doi:10.1016/j.softx.2024.101687](https://doi.org/10.1016/j.softx.2024.101687), [SoftwareX 26 (2024) 101687](https://www.sciencedirect.com/science/article/pii/S235271102400058X), [arXiv:2105.00613](https://arxiv.org/abs/2105.00613)\n\nYou can use the following BibTeX entry:\n\n```bibtex\n@article{Shoshany2024_ThreadPool,\n    archiveprefix = {arXiv},\n    author        = {Barak Shoshany},\n    doi           = {10.1016/j.softx.2024.101687},\n    eprint        = {2105.00613},\n    journal       = {SoftwareX},\n    pages         = {101687},\n    title         = {{A C++17 Thread Pool for High-Performance Scientific Computing}},\n    url           = {https://www.sciencedirect.com/science/article/pii/S235271102400058X},\n    volume        = {26},\n    year          = {2024}\n}\n```\n\nPlease note that the papers on [SoftwareX](https://www.sciencedirect.com/science/article/pii/S235271102400058X) and [arXiv](https://arxiv.org/abs/2105.00613) are not up to date with the latest version of the library. These publications are only intended to facilitate discovery of this library by scientists, and to enable citing it in scientific research. Documentation for the latest version is provided only by the `README.md` file in [the GitHub repository](https://github.com/bshoshany/thread-pool).\n\n### About the author\n\nMy name is Barak Shoshany and I am a theoretical, mathematical, and computational physicist. I work as an Assistant Professor of Physics at Brock University in Ontario, Canada, and I am also a Sessional Lecturer at McMaster University. My research focuses on the nature of time and causality in general relativity and quantum mechanics, as well as symbolic and high-performance scientific computing. For more about me, please see [my personal website](https://baraksh.com/).\n\n### Learning more about C&plus;&plus;\n\nBeginner C&plus;&plus; programmers may be interested in [my lecture notes](https://baraksh.com/CSE701/notes/) for a graduate-level course taught at McMaster University, which teach modern C and C&plus;&plus; from scratch, including some of the advanced techniques and programming practices used in developing this library. I have been teaching this course every year since 2020, and the notes are continuously updated and improved based on student feedback.\n\n### Other projects to check out\n\nIf you are a physicist or astronomer, you may be interested in my project [OGRe](https://github.com/bshoshany/OGRe): An Object-Oriented General Relativity Package for Mathematica, or its Python port [OGRePy](https://github.com/bshoshany/OGRePy): An Object-Oriented General Relativity Package for Python.\n"
        },
        {
          "name": "compile_cpp.yaml",
          "type": "blob",
          "size": 1.6494140625,
          "content": "# A list of macros to define when compiling the source files.\ndefines: [BS_THREAD_POOL_TEST_IMPORT_MODULE, BS_THREAD_POOL_IMPORT_STD, BS_THREAD_POOL_NATIVE_EXTENSIONS]\n# A map of flags to pass to each compiler. The compiler should be one of [cl, clang++, g++]. The flags should be a list of strings.\nflags:\n  cl: [/W4]\n  clang++: [-Wall, -Wextra, -Wconversion, -Wsign-conversion, -Wpedantic, -Wshadow, -Weffc++, -march=native, -fcolor-diagnostics, -fansi-escape-codes, -stdlib=libc++]\n  g++: [-Wall, -Wextra, -Wconversion, -Wpedantic, -Wshadow, -Wuseless-cast, -march=native, -fdiagnostics-color=always]\n# A list of include folders.\nincludes: [include]\n# A map of C++20 modules in the format \"module_name: [module_path, dependent files, ...]\". Will only be used in C++20 or C++23 mode. The dependent files are any files that the module depends on, and are only used to determine whether the module needs to be recompiled.\nmodules:\n  BS.thread_pool: [modules/BS.thread_pool.cppm, include/BS_thread_pool.hpp]\n# The output folder for the compiled files.\noutput: build/\n# A list of arguments to pass to the program if running it after compilation.\npass_args: []\n# A map of paths to the standard library modules for each OS and compiler combination (C++23 only). The OS should be one of [Darwin, Linux, Windows]. This is currently only officially supported by MSVC with Microsoft STL and LLVM Clang (NOT Apple Clang) with LLVM libc++. It is not supported by GCC with any standard library, or any compiler with GNU libstdc++. Use \"auto\" to determine the path automatically if possible.\nstd_module:\n  Darwin:\n    clang++: auto\n  Linux:\n    clang++: auto\n  Windows:\n    cl: auto\n    clang++: auto\n"
        },
        {
          "name": "include",
          "type": "tree",
          "content": null
        },
        {
          "name": "modules",
          "type": "tree",
          "content": null
        },
        {
          "name": "pyproject.toml",
          "type": "blob",
          "size": 9.37109375,
          "content": "[tool.pyright]\nanalyzeUnannotatedFunctions = true\ndeprecateTypingAliases = true\ndisableBytesTypePromotions = true\nenableExperimentalFeatures = false\nenableReachabilityAnalysis = true\nenableTypeIgnoreComments = true\nextraPaths = [\".\"]\npythonPlatform = \"All\"\npythonVersion = \"3.13\"\nreportAbstractUsage = \"error\"\nreportArgumentType = \"error\"\nreportAssertAlwaysTrue = \"error\"\nreportAssertTypeFailure = \"error\"\nreportAssignmentType = \"error\"\nreportAttributeAccessIssue = \"error\"\nreportCallInDefaultInitializer = \"error\"\nreportCallIssue = \"error\"\nreportConstantRedefinition = \"error\"\nreportDeprecated = \"error\"\nreportDuplicateImport = \"error\"\nreportFunctionMemberAccess = \"error\"\nreportGeneralTypeIssues = \"error\"\nreportImplicitOverride = \"error\"\nreportImplicitStringConcatenation = \"error\"\nreportImportCycles = \"error\"\nreportIncompatibleMethodOverride = \"error\"\nreportIncompatibleVariableOverride = \"error\"\nreportIncompleteStub = \"error\"\nreportInconsistentConstructor = \"error\"\nreportInconsistentOverload = \"error\"\nreportIndexIssue = \"error\"\nreportInvalidStringEscapeSequence = \"error\"\nreportInvalidStubStatement = \"error\"\nreportInvalidTypeArguments = \"error\"\nreportInvalidTypeForm = \"error\"\nreportInvalidTypeVarUse = \"error\"\nreportMatchNotExhaustive = \"error\"\nreportMissingImports = \"error\"\nreportMissingModuleSource = \"error\"\nreportMissingParameterType = \"error\"\nreportMissingTypeArgument = \"error\"\nreportMissingTypeStubs = \"error\"\nreportNoOverloadImplementation = \"error\"\nreportOperatorIssue = \"none\"\nreportOptionalCall = \"error\"\nreportOptionalContextManager = \"error\"\nreportOptionalIterable = \"error\"\nreportOptionalMemberAccess = \"error\"\nreportOptionalOperand = \"error\"\nreportOptionalSubscript = \"error\"\nreportOverlappingOverload = \"error\"\nreportPossiblyUnboundVariable = \"error\"\nreportPrivateImportUsage = \"error\"\nreportPrivateUsage = \"error\"\nreportPropertyTypeMismatch = \"none\"\nreportRedeclaration = \"error\"\nreportReturnType = \"error\"\nreportSelfClsParameterName = \"error\"\nreportShadowedImports = \"error\"\nreportTypeCommentUsage = \"error\"\nreportTypedDictNotRequiredAccess = \"error\"\nreportUnboundVariable = \"error\"\nreportUndefinedVariable = \"error\"\nreportUnhashable = \"error\"\nreportUninitializedInstanceVariable = \"error\"\nreportUnknownArgumentType = \"error\"\nreportUnknownLambdaType = \"error\"\nreportUnknownMemberType = \"none\"\nreportUnknownParameterType = \"error\"\nreportUnknownVariableType = \"error\"\nreportUnnecessaryCast = \"error\"\nreportUnnecessaryComparison = \"error\"\nreportUnnecessaryContains = \"error\"\nreportUnnecessaryIsInstance = \"error\"\nreportUnnecessaryTypeIgnoreComment = \"error\"\nreportUnsupportedDunderAll = \"error\"\nreportUntypedBaseClass = \"error\"\nreportUntypedClassDecorator = \"error\"\nreportUntypedFunctionDecorator = \"error\"\nreportUntypedNamedTuple = \"error\"\nreportUnusedCallResult = \"error\"\nreportUnusedClass = \"warning\"\nreportUnusedCoroutine = \"error\"\nreportUnusedExcept = \"error\"\nreportUnusedExpression = \"error\"\nreportUnusedFunction = \"warning\"\nreportUnusedImport = \"warning\"\nreportUnusedVariable = \"warning\"\nreportWildcardImportFromLibrary = \"error\"\nstrictDictionaryInference = true\nstrictListInference = true\nstrictParameterNoneValue = true\nstrictSetInference = true\ntypeCheckingMode = \"strict\"\nuseLibraryCodeForTypes = true\n\n[tool.ruff]\nindent-width = 4\nline-length = 320\ntarget-version = \"py313\"\n\n[tool.ruff.format]\ndocstring-code-format = false\ndocstring-code-line-length = \"dynamic\"\nindent-style = \"space\"\nline-ending = \"lf\"\nquote-style = \"double\"\nskip-magic-trailing-comma = false\n\n[tool.ruff.lint]\ndummy-variable-rgx = \"^(_+|(_+[a-zA-Z0-9_]*[a-zA-Z0-9]+?))$\"\nfixable = [\"ALL\"]\nignore = [\n    \"BLE001\",\n    \"C901\",\n    \"D200\",\n    \"D203\",\n    \"D205\",\n    \"D212\",\n    \"D400\",\n    \"D402\",\n    \"D415\",\n    \"E501\",\n    \"INP001\",\n    \"N814\",\n    \"N999\",\n    \"PLR0912\",\n    \"PLR0913\",\n    \"PLR2004\",\n    \"RUF009\",\n    \"S310\",\n    \"S602\",\n    \"S603\",\n    \"S607\",\n    \"SIM108\",\n    \"SLF001\",\n    \"T201\",\n    \"TCH003\",\n    \"TD002\",\n    \"TD003\",\n    \"UP015\",\n]\nselect = [\"ALL\"]\nunfixable = []\n\n[tool.ruff.lint.per-file-ignores]\n\"Interactive*\" = [\"ALL\"]\n\n[tool.pylint.main]\nanalyse-fallback-blocks = false\nclear-cache-post-run = false\nexit-zero = false\nextension-pkg-allow-list = []\nextension-pkg-whitelist = []\nfail-on = \"\"\nfail-under = 10\nfrom-stdin = false\nignore-paths = []\nignore-patterns = []\nignored-modules = []\ninit-hook = \"\"\njobs = 0\nlimit-inference-results = 100\nload-plugins = []\npersistent = true\nprefer-stubs = true\npy-version = \"3.13\"\nrecursive = false\nsource-roots = []\nsuggestion-mode = true\nunsafe-load-any-extension = false\n\n[tool.pylint.basic]\nargument-naming-style = \"snake_case\"\nargument-rgx = \"\"\nattr-naming-style = \"snake_case\"\nattr-rgx = \"\"\nbad-names = []\nbad-names-rgxs = \"\"\nclass-attribute-naming-style = \"any\"\nclass-attribute-rgx = \"\"\nclass-const-naming-style = \"UPPER_CASE\"\nclass-const-rgx = \"\"\nclass-naming-style = \"PascalCase\"\nclass-rgx = \"\"\nconst-naming-style = \"UPPER_CASE\"\nconst-rgx = \"\"\ndocstring-min-length = -1\nfunction-naming-style = \"snake_case\"\nfunction-rgx = \"\"\ngood-names = [\"_\"]\ngood-names-rgxs = \"\"\ninclude-naming-hint = true\ninlinevar-naming-style = \"any\"\ninlinevar-rgx = \"\"\nmethod-naming-style = \"snake_case\"\nmethod-rgx = \"\"\nmodule-naming-style = \"snake_case\"\nmodule-rgx = \"\"\nname-group = []\nno-docstring-rgx = \"\"\nproperty-classes = [\"abc.abstractproperty\"]\ntypealias-rgx = \"\"\ntypevar-rgx = \"\"\nvariable-naming-style = \"snake_case\"\nvariable-rgx = \"\"\n\n[tool.pylint.classes]\ncheck-protected-access-in-special-methods = true\ndefining-attr-methods = [\n    \"__init__\",\n    \"__new__\",\n    \"__post_init__\",\n    \"asyncSetUp\",\n    \"setUp\",\n]\nexclude-protected = [\n    \"_asdict\",\n    \"_fields\",\n    \"_make\",\n    \"_replace\",\n    \"_source\",\n    \"os._exit\",\n]\nvalid-classmethod-first-arg = [\"cls\"]\nvalid-metaclass-classmethod-first-arg = [\"mcs\"]\n\n[tool.pylint.design]\nexclude-too-few-public-methods = []\nignored-parents = []\nmax-args = 5\nmax-attributes = 7\nmax-bool-expr = 5\nmax-branches = 12\nmax-locals = 15\nmax-parents = 7\nmax-public-methods = 20\nmax-returns = 6\nmax-statements = 50\nmin-public-methods = 2\n\n[tool.pylint.exceptions]\novergeneral-exceptions = [\"builtins.BaseException\", \"builtins.Exception\"]\n\n[tool.pylint.format]\nexpected-line-ending-format = \"LF\"\nignore-long-lines = \"^\\\\s*(# )?<?https?://\\\\S+>?$\"\nindent-after-paren = 4\nindent-string = \"    \"\nmax-line-length = 1024\nmax-module-lines = 8192\nsingle-line-class-stmt = false\nsingle-line-if-stmt = false\n\n[tool.pylint.imports]\nallow-any-import-level = []\nallow-reexport-from-package = false\nallow-wildcard-with-all = false\ndeprecated-modules = []\next-import-graph = \"\"\nimport-graph = \"\"\nint-import-graph = \"\"\nknown-standard-library = []\nknown-third-party = []\npreferred-modules = []\n\n[tool.pylint.logging]\nlogging-format-style = \"new\"\nlogging-modules = [\"logging\"]\n\n[tool.pylint.\"messages control\"]\nconfidence = []\ndisable = [\n    \"broad-exception-caught\",\n    \"consider-using-enumerate\",\n    \"expression-not-assigned\",\n    \"import-error\",\n    \"invalid-unary-operand-type\",\n    \"missing-module-docstring\",\n    \"named-expr-without-context\",\n    \"not-callable\",\n    \"pointless-statement\",\n    \"protected-access\",\n    \"too-few-public-methods\",\n    \"too-many-arguments\",\n    \"too-many-boolean-expressions\",\n    \"too-many-branches\",\n    \"too-many-instance-attributes\",\n    \"too-many-locals\",\n    \"too-many-nested-blocks\",\n    \"too-many-public-methods\",\n    \"ungrouped-imports\",\n    \"use-implicit-booleaness-not-comparison-to-string\",\n    \"use-implicit-booleaness-not-comparison-to-zero\",\n    \"wrong-import-order\",\n    \"wrong-import-position\",\n]\nenable = [\"all\"]\n\n[tool.pylint.method_args]\ntimeout-methods = [\n    \"requests.api.delete\",\n    \"requests.api.get\",\n    \"requests.api.head\",\n    \"requests.api.options\",\n    \"requests.api.patch\",\n    \"requests.api.post\",\n    \"requests.api.put\",\n    \"requests.api.request\",\n]\n\n[tool.pylint.miscellaneous]\nnotes = [\"TODO\"]\nnotes-rgx = \"\"\n\n[tool.pylint.refactoring]\nmax-nested-blocks = 5\nnever-returning-functions = [\"argparse.parse_error\", \"sys.exit\"]\nsuggest-join-with-non-empty-separator = true\n\n[tool.pylint.reports]\nevaluation = \"max(0, 0 if fatal else 10.0 - ((float(5 * error + warning + refactor + convention) / statement) * 10))\"\nmsg-template = \"\"\noutput-format = \"text\"\nreports = true\nscore = true\n\n[tool.pylint.similarities]\nignore-comments = true\nignore-docstrings = true\nignore-imports = true\nignore-signatures = true\nmin-similarity-lines = 4\n\n[tool.pylint.spelling]\nmax-spelling-suggestions = 4\nspelling-dict = \"\"\nspelling-ignore-comment-directives = \"fmt: on,fmt: off,noqa:,noqa,nosec,isort:skip,mypy:\"\nspelling-ignore-words = \"\"\nspelling-private-dict-file = \"\"\nspelling-store-unknown-words = false\n\n[tool.pylint.typecheck]\ncontextmanager-decorators = [\"contextlib.contextmanager\"]\ngenerated-members = []\nignore-mixin-members = true\nignore-none = true\nignore-on-opaque-inference = false\nignored-checks-for-mixins = [\n    \"attribute-defined-outside-init\",\n    \"no-member\",\n    \"not-async-context-manager\",\n    \"not-context-manager\",\n]\nignored-classes = [\n    \"_thread._local\",\n    \"argparse.Namespace\",\n    \"optparse.Values\",\n    \"thread._local\",\n]\nmissing-member-hint = true\nmissing-member-hint-distance = 1\nmissing-member-max-choices = 1\nmixin-class-rgx = \".*[Mm]ixin\"\nsignature-mutators = []\n\n[tool.pylint.variables]\nadditional-builtins = []\nallow-global-unused-variables = true\nallowed-redefined-builtins = []\ncallbacks = [\"_cb\", \"cb_\"]\ndummy-variables-rgx = \"^_.*\"\nignored-argument-names = \"^_.*\"\ninit-import = true\nredefining-builtins-modules = [\n    \"builtins\",\n    \"future.builtins\",\n    \"io\",\n    \"past.builtins\",\n    \"six.moves\",\n]\n"
        },
        {
          "name": "scripts",
          "type": "tree",
          "content": null
        },
        {
          "name": "tests",
          "type": "tree",
          "content": null
        }
      ]
    }
  ]
}