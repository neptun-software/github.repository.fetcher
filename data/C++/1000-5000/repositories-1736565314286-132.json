{
  "metadata": {
    "timestamp": 1736565314286,
    "page": 132,
    "hasNextPage": true,
    "endCursor": "Y3Vyc29yOjE0MA==",
    "completionStatus": "IN_PROGRESS"
  },
  "repositories": [
    {
      "nameWithOwner": "k2-fsa/sherpa-onnx",
      "stars": 4051,
      "defaultBranch": "master",
      "files": [
        {
          "name": ".clang-format",
          "type": "blob",
          "size": 3.0625,
          "content": "---\nBasedOnStyle: Google\n---\nLanguage:               Cpp\nCpp11BracedListStyle:   true\nStandard:               Cpp11\nDerivePointerAlignment: false\nPointerAlignment:       Right\n---\nLanguage: Java\nJavaImportGroups: [ 'java', 'javax', 'javafx', 'org', 'io', 'com', 'de.gsi' ]\nAccessModifierOffset: -4\nAlignAfterOpenBracket: DontAlign\nAlignConsecutiveAssignments: false\nAlignConsecutiveDeclarations: false\nAlignEscapedNewlines: DontAlign\nAlignTrailingComments: false\nAllowAllParametersOfDeclarationOnNextLine: true\nAllowShortLambdasOnASingleLine: None\nAllowShortCaseLabelsOnASingleLine: false\nAllowShortFunctionsOnASingleLine: None\nAllowShortIfStatementsOnASingleLine: Never\nAllowShortLoopsOnASingleLine: false\nAlwaysBreakAfterReturnType: None\nAlwaysBreakBeforeMultilineStrings: false\nAlwaysBreakTemplateDeclarations: Yes\nBinPackArguments: true\nBinPackParameters: true\nBraceWrapping:\n  AfterClass: false\n  AfterControlStatement: Never\n  AfterEnum: false\n  AfterFunction: false\n  AfterNamespace: false\n  AfterObjCDeclaration: false\n  AfterStruct: false\n  AfterUnion: false\n  BeforeCatch: false\n  BeforeElse: false\n  IndentBraces: false\n  SplitEmptyFunction: true\n  SplitEmptyRecord: true\n  SplitEmptyNamespace: true\nBreakBeforeBinaryOperators: All\nBreakBeforeBraces: Custom\nBreakBeforeInheritanceComma: false\nBreakBeforeTernaryOperators: true\nBreakConstructorInitializersBeforeComma: false\nBreakConstructorInitializers: BeforeComma\nBreakAfterJavaFieldAnnotations: true\nBreakStringLiterals: true\nColumnLimit: 0\nCommentPragmas: '^ IWYU pragma:'\nCompactNamespaces: false\nConstructorInitializerAllOnOneLineOrOnePerLine: false\nConstructorInitializerIndentWidth: 4\nContinuationIndentWidth: 8\nCpp11BracedListStyle: false\nDerivePointerAlignment: false\nDisableFormat: false\nExperimentalAutoDetectBinPacking: false\nFixNamespaceComments: true\nForEachMacros:\n  - forever # avoids { wrapped to next line\n  - foreach\n  - Q_FOREACH\n  - BOOST_FOREACH\nIncludeCategories:\n  - Regex: '^<Q.*'\n    Priority: 200\nIncludeIsMainRegex: '(Test)?$'\nIndentCaseLabels: false\nIndentWidth: 4\nIndentWrappedFunctionNames: false\nJavaScriptQuotes: Leave\nJavaScriptWrapImports: true\nKeepEmptyLinesAtTheStartOfBlocks: false\n# Do not add QT_BEGIN_NAMESPACE/QT_END_NAMESPACE as this will indent lines in between.\nMacroBlockBegin: \"\"\nMacroBlockEnd: \"\"\nMaxEmptyLinesToKeep: 1\nNamespaceIndentation: None\nObjCBlockIndentWidth: 4\nObjCSpaceAfterProperty: false\nObjCSpaceBeforeProtocolList: true\nPenaltyBreakAssignment: 150\nPenaltyBreakBeforeFirstCallParameter: 300\nPenaltyBreakComment: 500\nPenaltyBreakFirstLessLess: 400\nPenaltyBreakString: 600\nPenaltyExcessCharacter: 50\nPenaltyReturnTypeOnItsOwnLine: 300\nPointerAlignment: Right\nReflowComments: true\nSortIncludes: true\nSortUsingDeclarations: true\nSpaceAfterCStyleCast: true\nSpaceAfterTemplateKeyword: false\nSpaceBeforeAssignmentOperators: true\nSpaceBeforeParens: ControlStatements\nSpaceInEmptyParentheses: false\nSpacesBeforeTrailingComments: 1\nSpacesInAngles: false\nSpacesInContainerLiterals: false\nSpacesInCStyleCastParentheses: false\nSpacesInParentheses: false\nSpacesInSquareBrackets: false\nStandard: c++17\nTabWidth: 4\nUseTab: Never"
        },
        {
          "name": ".clang-tidy",
          "type": "blob",
          "size": 2.4296875,
          "content": "---\n# NOTE there must be no spaces before the '-', so put the comma last.\n# The check bugprone-unchecked-optional-access is also turned off atm\n# because it causes clang-tidy to hang randomly. The tracking issue\n# can be found at https://github.com/llvm/llvm-project/issues/69369.\n#\n# Modified from\n# https://github.com/pytorch/pytorch/blob/main/.clang-tidy\nInheritParentConfig: true\nChecks: '\nbugprone-*,\n-bugprone-easily-swappable-parameters,\n-bugprone-forward-declaration-namespace,\n-bugprone-implicit-widening-of-multiplication-result,\n-bugprone-macro-parentheses,\n-bugprone-lambda-function-name,\n-bugprone-narrowing-conversions,\n-bugprone-reserved-identifier,\n-bugprone-swapped-arguments,\n-bugprone-unchecked-optional-access,\nclang-diagnostic-missing-prototypes,\ncppcoreguidelines-*,\n-cppcoreguidelines-avoid-const-or-ref-data-members,\n-cppcoreguidelines-avoid-do-while,\n-cppcoreguidelines-avoid-magic-numbers,\n-cppcoreguidelines-avoid-non-const-global-variables,\n-cppcoreguidelines-interfaces-global-init,\n-cppcoreguidelines-macro-usage,\n-cppcoreguidelines-narrowing-conversions,\n-cppcoreguidelines-owning-memory,\n-cppcoreguidelines-pro-bounds-array-to-pointer-decay,\n-cppcoreguidelines-pro-bounds-constant-array-index,\n-cppcoreguidelines-pro-bounds-pointer-arithmetic,\n-cppcoreguidelines-pro-type-const-cast,\n-cppcoreguidelines-pro-type-cstyle-cast,\n-cppcoreguidelines-pro-type-reinterpret-cast,\n-cppcoreguidelines-pro-type-static-cast-downcast,\n-cppcoreguidelines-pro-type-union-access,\n-cppcoreguidelines-pro-type-vararg,\n-cppcoreguidelines-special-member-functions,\n-cppcoreguidelines-non-private-member-variables-in-classes,\n-facebook-hte-RelativeInclude,\nhicpp-exception-baseclass,\nhicpp-avoid-goto,\nmisc-*,\n-misc-const-correctness,\n-misc-include-cleaner,\n-misc-use-anonymous-namespace,\n-misc-unused-parameters,\n-misc-no-recursion,\n-misc-non-private-member-variables-in-classes,\n-misc-confusable-identifiers,\nmodernize-*,\n-modernize-macro-to-enum,\n-modernize-pass-by-value,\n-modernize-return-braced-init-list,\n-modernize-use-auto,\n-modernize-use-default-member-init,\n-modernize-use-using,\n-modernize-use-trailing-return-type,\n-modernize-use-nodiscard,\nperformance-*,\nreadability-container-size-empty,\nreadability-delete-null-pointer,\nreadability-duplicate-include\nreadability-misplaced-array-index,\nreadability-redundant-function-ptr-dereference,\nreadability-redundant-smartptr-get,\nreadability-simplify-subscript-expr,\nreadability-string-compare,\n'\nWarningsAsErrors: '*'\n...\n"
        },
        {
          "name": ".flake8",
          "type": "blob",
          "size": 0.091796875,
          "content": "[flake8]\nshow-source=true\nstatistics=true\nmax-line-length = 120\n\nexclude =\n  .git,\n  ./cmake,\n"
        },
        {
          "name": ".github",
          "type": "tree",
          "content": null
        },
        {
          "name": ".gitignore",
          "type": "blob",
          "size": 2.5205078125,
          "content": "build\n*.zip\n*.tgz\n*.sw?\nonnxruntime-*\nicefall-*\nrun.sh\n__pycache__\ndist/\nsherpa_onnx.egg-info/\n.DS_Store\nbuild-aarch64-linux-gnu\nbuild-arm-linux-gnueabihf\nsherpa-onnx-streaming-zipformer-*\nsherpa-onnx-lstm-en-*\nsherpa-onnx-lstm-zh-*\nbuild-android-arm64-v8a/\nbuild-android-armv7-eabi/\nbuild-android-x86-64/\na.txt\nrun-bilingual*.sh\nrun-*-zipformer.sh\nrun-zh.sh\ndecode-file-c-api\noffline-tts-c-api\nrun-decode-file-c-api.sh\nsherpa-onnx-ffmpeg\nbuild-ios\nbuild-swift-macos\naa.sh\nclient-2.sh\nffmpeg-examples/run-3.sh\npython-api-examples/decode-file-multiple-bak-2.py\nrun-en-zipformer-microphone*\nrun-websocket-server*\ndecode-file\n*.dylib\ntokens.txt\n*.onnx\nlog.txt\ntags\nrun-decode-file-python.sh\nandroid/SherpaOnnx/app/src/main/assets/\n*.ncnn.*\nrun-sherpa-onnx-offline.sh\nsherpa-onnx-conformer-en-2023-03-18\nparaformer-onnxruntime-python-example\nrun-sherpa-onnx-offline-paraformer.sh\nrun-sherpa-onnx-offline-transducer.sh\nsherpa-onnx-paraformer-zh-2023-03-28\nsherpa-onnx-paraformer-zh-2023-09-14\nrun-offline-websocket-server-paraformer.sh\nrun-*int8.sh\na.sh\nrun-offline-websocket-client-*.sh\nrun-sherpa-onnx-*.sh\nsherpa-onnx-zipformer-en-2023-03-30\nsherpa-onnx-zipformer-en-2023-04-01\nrun-offline-decode-files.sh\nsherpa-onnx-nemo-ctc-en-citrinet-512\nsherpa-onnx-streaming-paraformer-bilingual-zh-en\nrun-offline-decode-files-nemo-ctc.sh\nsherpa-onnx-nemo-ctc-*\n*.wav\nsherpa-onnx-zipformer-*\nsherpa-onnx-conformer-*\nsherpa-onnx-whisper-*\nswift-api-examples/k2fsa-*\nrun-*.sh\ntwo-pass-*.sh\nbuild-*\n\n## User settings\nxcuserdata/\n\n## Xcode 8 and earlier\n*.xcscmblueprint\n*.xccheckout\nvits-vctk\nvits-zh-aishell3\njslint.mjs\nvits-piper-en_US-amy-low\nvits-piper-*-*-*\nlog\n*.exe\nvits-piper-*\nvits-coqui-*\nvits-mms-*\n*.tar.bz2\nsherpa-onnx-paraformer-trilingual-zh-cantonese-en\nsr-data\n*xcworkspace/xcuserdata/*\n\nvits-icefall-*\nsherpa-onnx-punct-ct-transformer-zh-en-vocab272727-2024-04-12\nspoken-language-identification-test-wavs\nmy-release-key*\nvits-zh-hf-fanchen-C\nsherpa-onnx-kws-zipformer-wenetspeech-3.3M-2024-01-01\n*.dll\n*.lib\n*.tar.gz\n*.tar.bz2\n*.zip\nsherpa-onnx-ced-*\nnode_modules\npackage-lock.json\npubspec.lock\nsherpa-onnx-nemo-*\nsherpa-onnx-vits-*\nsherpa-onnx-telespeech-ctc-*\n*.fst\n.ccache\nlib*.a\nsherpa-onnx-sense-voice-zh-en-ja-ko-yue-2024-07-17\n*.bak\nvits-melo-tts-zh_en\n*.o\n*.ppu\nsherpa-onnx-online-punct-en-2024-08-06\n*.mp4\n*.mp3\nsherpa-onnx-pyannote-segmentation-3-0\nsherpa-onnx-moonshine-tiny-en-int8\nsherpa-onnx-moonshine-base-en-int8\nharmony-os/SherpaOnnxHar/sherpa_onnx/LICENSE\nharmony-os/SherpaOnnxHar/sherpa_onnx/CHANGELOG.md\nmatcha-icefall-zh-baker\nmatcha-icefall-en_US-ljspeech\n"
        },
        {
          "name": "CHANGELOG.md",
          "type": "blob",
          "size": 12.09375,
          "content": "## 1.10.38\n\n* Fix initializing TTS in Python. (#1664)\n* Remove spaces after punctuations for TTS (#1666)\n* Add constructor fromPtr() for all flutter class with factory ctor. (#1667)\n* Add Kotlin API for Matcha-TTS models. (#1668)\n* Support Matcha-TTS models using espeak-ng (#1672)\n* Add Java API for Matcha-TTS models. (#1673)\n* Avoid adding tail padding for VAD in generate-subtitles.py (#1674)\n* Add C API for MatchaTTS models (#1675)\n* Add CXX API for MatchaTTS models (#1676)\n* Add JavaScript API (node-addon-api) for MatchaTTS models. (#1677)\n* Add HarmonyOS examples for MatchaTTS. (#1678)\n* Upgraded to .NET 8 and made code style a little more internally consistent. (#1680)\n* Update workflows to use .NET 8.0 also. (#1681)\n* Add C# and JavaScript (wasm) API for MatchaTTS models (#1682)\n* Add Android demo for MatchaTTS models. (#1683)\n* Add Swift API for MatchaTTS models. (#1684)\n* Add Go API for MatchaTTS models (#1685)\n* Add Pascal API for MatchaTTS models. (#1686)\n* Add Dart API for MatchaTTS models (#1687)\n\n## 1.10.37\n\n* Add new tts models for Latvia and Persian+English (#1644)\n* Add a byte-level BPE Chinese+English non-streaming zipformer model (#1645)\n* Support removing invalid utf-8 sequences. (#1648)\n* Add TeleSpeech CTC to non_streaming_server.py (#1649)\n* Fix building macOS libs (#1656)\n* Add Go API for Keyword spotting (#1662)\n* Add Swift online punctuation (#1661)\n* Add C++ runtime for Matcha-TTS (#1627)\n\n## 1.10.36\n\n* Update AAR version in Android Java demo (#1618)\n* Support linking onnxruntime statically for Android (#1619)\n* Update readme to include Open-LLM-VTuber (#1622)\n* Rename maxNumStences to maxNumSentences (#1625)\n* Support using onnxruntime 1.16.0 with CUDA 11.4 on Jetson Orin NX (Linux arm64 GPU). (#1630)\n* Update readme to include jetson orin nx and nano b01 (#1631)\n* feat: add checksum action (#1632)\n* Support decoding with byte-level BPE (bbpe) models. (#1633)\n* feat: enable c api for android ci (#1635)\n* Update README.md (#1640)\n* SherpaOnnxVadAsr: Offload runSecondPass to background thread for improved real-time audio processing (#1638)\n* Fix GitHub actions. (#1642)\n\n\n## 1.10.35\n\n* Add missing changes about speaker identfication demo for HarmonyOS (#1612)\n* Provide sherpa-onnx.aar for Android (#1615)\n* Use aar in Android Java demo. (#1616)\n\n## 1.10.34\n\n* Fix building node-addon package (#1598)\n* Update doc links for HarmonyOS (#1601)\n* Add on-device real-time ASR demo for HarmonyOS (#1606)\n* Add speaker identification APIs for HarmonyOS (#1607)\n* Add speaker identification demo for HarmonyOS (#1608)\n* Add speaker diarization API for HarmonyOS. (#1609)\n* Add speaker diarization demo for HarmonyOS (#1610)\n\n## 1.10.33\n\n* Add non-streaming ASR support for HarmonyOS. (#1564)\n* Add streaming ASR support for HarmonyOS. (#1565)\n* Fix building for Android (#1568)\n* Publish `sherpa_onnx.har` for HarmonyOS (#1572)\n* Add VAD+ASR demo for HarmonyOS (#1573)\n* Fix publishing har packages for HarmonyOS (#1576)\n* Add CI to build HAPs for HarmonyOS (#1578)\n* Add microphone demo about VAD+ASR for HarmonyOS (#1581)\n* Fix getting microphone permission for HarmonyOS VAD+ASR example (#1582)\n* Add HarmonyOS support for text-to-speech. (#1584)\n* Fix: support both old and new websockets request headers format (#1588)\n* Add on-device tex-to-speech (TTS) demo for HarmonyOS (#1590)\n\n## 1.10.32\n\n* Support cross-compiling for HarmonyOS (#1553)\n* HarmonyOS support for VAD. (#1561)\n* Fix publishing flutter iOS app to appstore (#1563).\n\n## 1.10.31\n\n* Publish pre-built wheels for Python 3.13 (#1485)\n* Publish pre-built macos xcframework (#1490)\n* Fix reading tokens.txt on Windows. (#1497)\n* Add two-pass ASR Android APKs for Moonshine models. (#1499)\n* Support building GPU-capable sherpa-onnx on Linux aarch64. (#1500)\n* Publish pre-built wheels with CUDA support for Linux aarch64. (#1507)\n* Export the English TTS model from MeloTTS (#1509)\n* Add Lazarus example for Moonshine models. (#1532)\n* Add isolate_tts demo (#1529)\n* Add WebAssembly example for VAD + Moonshine models. (#1535)\n* Add Android APK for streaming Paraformer ASR (#1538)\n* Support static build for windows arm64. (#1539)\n* Use xcframework for Flutter iOS plugin to support iOS simulators.\n\n## 1.10.30\n\n* Fix building node-addon for Windows x86. (#1469)\n* Begin to support https://github.com/usefulsensors/moonshine (#1470)\n* Publish pre-built JNI libs for Linux aarch64 (#1472)\n* Add C++ runtime and Python APIs for Moonshine models (#1473)\n* Add Kotlin and Java API for Moonshine models (#1474)\n* Add C and C++ API for Moonshine models (#1476)\n* Add Swift API for Moonshine models. (#1477)\n* Add Go API examples for adding punctuations to text. (#1478)\n* Add Go API for Moonshine models (#1479)\n* Add JavaScript API for Moonshine models (#1480)\n* Add Dart API for Moonshine models. (#1481)\n* Add Pascal API for Moonshine models (#1482)\n* Add C# API for Moonshine models. (#1483)\n\n## 1.10.29\n\n* Add Go API for offline punctuation models (#1434)\n* Support https://huggingface.co/Revai/reverb-diarization-v1 (#1437)\n* Add more models for speaker diarization (#1440)\n* Add Java API example for hotwords. (#1442)\n* Add java android demo (#1454)\n* Add C++ API for streaming ASR. (#1455)\n* Add C++ API for non-streaming ASR (#1456)\n* Handle NaN embeddings in speaker diarization. (#1461)\n* Add speaker identification with VAD and non-streaming ASR using ALSA (#1463)\n* Support GigaAM CTC models for Russian ASR (#1464)\n* Add GigaAM NeMo transducer model for Russian ASR (#1467)\n\n## 1.10.28\n\n* Fix swift example for generating subtitles. (#1362)\n* Allow more online models to load tokens file from the memory (#1352)\n* Fix CI errors introduced by supporting loading keywords from buffers (#1366)\n* Fix running MeloTTS models on GPU. (#1379)\n* Support Parakeet models from NeMo (#1381)\n* Export Pyannote speaker segmentation models to onnx (#1382)\n* Support Agglomerative clustering. (#1384)\n* Add Python API for clustering (#1385)\n* support whisper turbo (#1390)\n* context_state is not set correctly when previous context is passed after reset (#1393)\n* Speaker diarization example with onnxruntime Python API (#1395)\n* C++ API for speaker diarization (#1396)\n* Python API for speaker diarization. (#1400)\n* C API for speaker diarization (#1402)\n* docs(nodejs-addon-examples): add guide for pnpm user (#1401)\n* Go API for speaker diarization (#1403)\n* Swift API for speaker diarization (#1404)\n* Update readme to include more external projects using sherpa-onnx (#1405)\n* C# API for speaker diarization (#1407)\n* JavaScript API (node-addon) for speaker diarization (#1408)\n* WebAssembly exmaple for speaker diarization (#1411)\n* Handle audio files less than 10s long for speaker diarization. (#1412)\n* JavaScript API with WebAssembly for speaker diarization (#1414)\n* Kotlin API for speaker diarization (#1415)\n* Java API for speaker diarization (#1416)\n* Dart API for speaker diarization (#1418)\n* Pascal API for speaker diarization (#1420)\n* Android JNI support for speaker diarization (#1421)\n* Android demo for speaker diarization (#1423)\n\n## 1.10.27\n\n* Add non-streaming ONNX models for Russian ASR (#1358)\n* Fix building Flutter TTS examples for Linux (#1356)\n* Support passing utf-8 strings from JavaScript to C++. (#1355)\n* Fix sherpa_onnx.go to support returning empty recognition results (#1353)\n\n## 1.10.26\n\n* Add links to projects using sherpa-onnx. (#1345)\n* Support lang/emotion/event results from SenseVoice in Swift API. (#1346)\n* Support specifying max speech duration for VAD. (#1348)\n* Add APIs about max speech duration in VAD for various programming languages (#1349)\n\n## 1.10.25\n\n* Allow tokens and hotwords to be loaded from buffered string driectly (#1339)\n* Fix computing features for CED audio tagging models. (#1341)\n* Preserve previous result as context for next segment (#1335)\n* Add Python binding for online punctuation models (#1312)\n* Fix vad.Flush(). (#1329)\n* Fix wasm app for streaming paraformer (#1328)\n* Build websocket related binaries for embedded systems. (#1327)\n* Fixed the C api calls and created the TTS project file (#1324)\n* Re-implement LM rescore for online transducer (#1231)\n\n## 1.10.24\n\n* Add VAD and keyword spotting for the Node package with WebAssembly (#1286)\n* Fix releasing npm package and fix building Android VAD+ASR example (#1288)\n* add Tokens []string, Timestamps []float32, Lang string, Emotion string, Event string (#1277)\n* add vad+sense voice example for C API (#1291)\n* ADD VAD+ASR example for dart with CircularBuffer. (#1293)\n* Fix VAD+ASR example for Dart API. (#1294)\n* Avoid SherpaOnnxSpeakerEmbeddingManagerFreeBestMatches freeing null. (#1296)\n* Fix releasing wasm app for vad+asr (#1300)\n* remove extra files from linux/macos/windows jni libs (#1301)\n* two-pass Android APK for SenseVoice (#1302)\n* Downgrade flutter sdk versions. (#1305)\n* Reduce onnxruntime log output. (#1306)\n* Provide prebuilt .jar files for different java versions. (#1307)\n\n\n## 1.10.23\n\n* flutter: add lang, emotion, event to OfflineRecognizerResult (#1268)\n* Use a separate thread to initialize models for lazarus examples. (#1270)\n* Object pascal examples for recording and playing audio with portaudio. (#1271)\n* Text to speech API for Object Pascal. (#1273)\n* update kotlin api for better release native object and add user-friendly apis. (#1275)\n* Update wave-reader.cc to support 8/16/32-bit waves (#1278)\n* Add WebAssembly for VAD (#1281)\n* WebAssembly example for VAD + Non-streaming ASR (#1284)\n\n## 1.10.22\n\n* Add Pascal API for reading wave files (#1243)\n* Pascal API for streaming ASR (#1246)\n* Pascal API for non-streaming ASR (#1247)\n* Pascal API for VAD (#1249)\n* Add more C API examples (#1255)\n* Add emotion, event of SenseVoice. (#1257)\n* Support reading multi-channel wave files with 8/16/32-bit encoded samples (#1258)\n* Enable IPO only for Release build. (#1261)\n* Add Lazarus example for generating subtitles using Silero VAD with non-streaming ASR (#1251)\n* Fix looking up OOVs in lexicon.txt for MeloTTS models. (#1266)\n\n\n## 1.10.21\n\n* Fix ffmpeg c api example (#1185)\n* Fix splitting sentences for MeloTTS (#1186)\n* Non-streaming WebSocket client for Java. (#1190)\n* Fix copying asset files for flutter examples. (#1191)\n* Add Chinese+English tts example for flutter (#1192)\n* Add speaker identification and verification exmaple for Dart API (#1194)\n* Fix reading non-standard wav files. (#1199)\n* Add ReazonSpeech Japanese pre-trained model (#1203)\n* Describe how to add new words for MeloTTS models (#1209)\n* Remove libonnxruntime_providers_cuda.so as a dependency. (#1210)\n* Fix setting SenseVoice language. (#1214)\n* Support passing TTS callback in Swift API (#1218)\n* Add MeloTTS example for ios (#1223)\n* Add online punctuation and casing prediction model for English language (#1224)\n* Fix python two pass ASR examples (#1230)\n* Add blank penalty for various language bindings\n\n## 1.10.20\n\n* Add Dart API for audio tagging\n* Add Dart API for adding punctuations to text\n\n## 1.10.19\n\n* Prefix all C API functions with SherpaOnnx\n\n## 1.10.18\n\n* Fix the case when recognition results contain the symbol `\"`. It caused\n  issues when converting results to a json string.\n\n## 1.10.17\n\n* Support SenseVoice CTC models.\n* Add Dart API for keyword spotter.\n\n## 1.10.16\n\n* Support zh-en TTS model from MeloTTS.\n\n## 1.10.15\n\n* Downgrade onnxruntime from v1.18.1 to v1.17.1\n\n## 1.10.14\n\n* Support whisper large v3\n* Update onnxruntime from v1.18.0 to v1.18.1\n* Fix invalid utf8 sequence from Whisper for Dart API.\n\n## 1.10.13\n\n* Update onnxruntime from 1.17.1 to 1.18.0\n* Add C# API for Keyword spotting\n\n## 1.10.12\n\n* Add Flush to VAD so that the last speech segment can be detected. See also\n  https://github.com/k2-fsa/sherpa-onnx/discussions/1077#discussioncomment-9979740\n\n## 1.10.11\n\n* Support the iOS platform for Flutter.\n\n## 1.10.10\n\n* Build sherpa-onnx into a single shared library.\n\n## 1.10.9\n\n* Fix released packages. piper-phonemize was not included in v1.10.8.\n\n## 1.10.8\n\n* Fix released packages. There should be a lib directory.\n\n## 1.10.7\n\n* Support Android for Flutter.\n\n## 1.10.2\n\n* Fix passing C# string to C++\n\n## 1.10.1\n\n* Enable to stop TTS generation\n\n## 1.10.0\n\n* Add inverse text normalization\n\n## 1.9.30\n\n* Add TTS\n\n## 1.9.29\n\n* Publish with CI\n\n## 0.0.3\n\n* Fix path separator on Windows.\n\n## 0.0.2\n\n* Support specifying lib path.\n\n## 0.0.1\n\n* Initial release.\n"
        },
        {
          "name": "CMakeLists.txt",
          "type": "blob",
          "size": 16.3203125,
          "content": "cmake_minimum_required(VERSION 3.13 FATAL_ERROR)\n\nset(CMAKE_OSX_DEPLOYMENT_TARGET \"10.14\" CACHE STRING \"Minimum OS X deployment version. Used only for macOS\")\n\nset(CMAKE_POLICY_DEFAULT_CMP0063 NEW)\nset(CMAKE_POLICY_DEFAULT_CMP0069 NEW)\n\nproject(sherpa-onnx)\n\n# Remember to update\n# ./CHANGELOG.md\n# ./new-release.sh\nset(SHERPA_ONNX_VERSION \"1.10.38\")\n\n# Disable warning about\n#\n# \"The DOWNLOAD_EXTRACT_TIMESTAMP option was not given and policy CMP0135 is\n#  not set.\nif (CMAKE_VERSION VERSION_GREATER_EQUAL \"3.24.0\")\n  cmake_policy(SET CMP0135 NEW)\nendif()\n\noption(SHERPA_ONNX_ENABLE_PYTHON \"Whether to build Python\" OFF)\noption(SHERPA_ONNX_ENABLE_TESTS \"Whether to build tests\" OFF)\noption(SHERPA_ONNX_ENABLE_CHECK \"Whether to build with assert\" OFF)\noption(BUILD_SHARED_LIBS \"Whether to build shared libraries\" OFF)\noption(SHERPA_ONNX_ENABLE_PORTAUDIO \"Whether to build with portaudio\" ON)\noption(SHERPA_ONNX_ENABLE_JNI \"Whether to build JNI internface\" OFF)\noption(SHERPA_ONNX_ENABLE_C_API \"Whether to build C API\" ON)\noption(SHERPA_ONNX_ENABLE_WEBSOCKET \"Whether to build webscoket server/client\" ON)\noption(SHERPA_ONNX_ENABLE_GPU \"Enable ONNX Runtime GPU support\" OFF)\noption(SHERPA_ONNX_ENABLE_DIRECTML \"Enable ONNX Runtime DirectML support\" OFF)\noption(SHERPA_ONNX_ENABLE_WASM \"Whether to enable WASM\" OFF)\noption(SHERPA_ONNX_ENABLE_WASM_SPEAKER_DIARIZATION \"Whether to enable WASM for speaker diarization\" OFF)\noption(SHERPA_ONNX_ENABLE_WASM_TTS \"Whether to enable WASM for TTS\" OFF)\noption(SHERPA_ONNX_ENABLE_WASM_ASR \"Whether to enable WASM for ASR\" OFF)\noption(SHERPA_ONNX_ENABLE_WASM_KWS \"Whether to enable WASM for KWS\" OFF)\noption(SHERPA_ONNX_ENABLE_WASM_VAD \"Whether to enable WASM for VAD\" OFF)\noption(SHERPA_ONNX_ENABLE_WASM_VAD_ASR \"Whether to enable WASM for VAD+ASR\" OFF)\noption(SHERPA_ONNX_ENABLE_WASM_NODEJS \"Whether to enable WASM for NodeJS\" OFF)\noption(SHERPA_ONNX_ENABLE_BINARY \"Whether to build binaries\" ON)\noption(SHERPA_ONNX_ENABLE_TTS \"Whether to build TTS related code\" ON)\noption(SHERPA_ONNX_ENABLE_SPEAKER_DIARIZATION \"Whether to build speaker diarization related code\" ON)\noption(SHERPA_ONNX_LINK_LIBSTDCPP_STATICALLY \"True to link libstdc++ statically. Used only when BUILD_SHARED_LIBS is OFF on Linux\" ON)\noption(SHERPA_ONNX_USE_PRE_INSTALLED_ONNXRUNTIME_IF_AVAILABLE \"True to use pre-installed onnxruntime if available\" ON)\noption(SHERPA_ONNX_ENABLE_SANITIZER \"Whether to enable ubsan and asan\" OFF)\noption(SHERPA_ONNX_BUILD_C_API_EXAMPLES \"Whether to enable C API examples\" ON)\n\nset(SHERPA_ONNX_LINUX_ARM64_GPU_ONNXRUNTIME_VERSION \"1.11.0\" CACHE STRING \"Used only for Linux ARM64 GPU. If you use Jetson nano b01, then please set it to 1.11.0. If you use Jetson Orin NX, then set it to 1.16.0\")\n\n\nset(CMAKE_ARCHIVE_OUTPUT_DIRECTORY \"${CMAKE_BINARY_DIR}/lib\")\nset(CMAKE_LIBRARY_OUTPUT_DIRECTORY \"${CMAKE_BINARY_DIR}/lib\")\nset(CMAKE_RUNTIME_OUTPUT_DIRECTORY \"${CMAKE_BINARY_DIR}/bin\")\n\nif(NOT WIN32)\n  set(CMAKE_SKIP_BUILD_RPATH FALSE)\n  set(BUILD_RPATH_USE_ORIGIN TRUE)\n  set(CMAKE_INSTALL_RPATH_USE_LINK_PATH TRUE)\nendif()\n\nif(NOT APPLE)\n  set(SHERPA_ONNX_RPATH_ORIGIN \"$ORIGIN\")\nelse()\n  set(SHERPA_ONNX_RPATH_ORIGIN \"@loader_path\")\nendif()\n\nif(NOT WIN32)\n  set(CMAKE_INSTALL_RPATH ${SHERPA_ONNX_RPATH_ORIGIN})\n  set(CMAKE_BUILD_RPATH ${SHERPA_ONNX_RPATH_ORIGIN})\nendif()\n\nif(NOT CMAKE_BUILD_TYPE)\n  message(STATUS \"No CMAKE_BUILD_TYPE given, default to Release\")\n  set(CMAKE_BUILD_TYPE Release)\nendif()\n\nif(DEFINED ANDROID_ABI AND NOT SHERPA_ONNX_ENABLE_JNI AND NOT SHERPA_ONNX_ENABLE_C_API)\n  message(STATUS \"Set SHERPA_ONNX_ENABLE_JNI to ON for Android\")\n  set(SHERPA_ONNX_ENABLE_JNI ON CACHE BOOL \"\" FORCE)\nendif()\n\nif(SHERPA_ONNX_ENABLE_PYTHON AND NOT BUILD_SHARED_LIBS)\n  message(STATUS \"Set BUILD_SHARED_LIBS to ON since SHERPA_ONNX_ENABLE_PYTHON is ON\")\n  set(BUILD_SHARED_LIBS ON CACHE BOOL \"\" FORCE)\nendif()\n\nif(SHERPA_ONNX_ENABLE_GPU)\n  message(WARNING \"\\\nCompiling for NVIDIA GPU is enabled. Please make sure cudatoolkit\nis installed on your system. Otherwise, you will get errors at runtime.\nHint: You don't need sudo permission to install CUDA toolkit. Please refer to\n  https://k2-fsa.github.io/k2/installation/cuda-cudnn.html\nto install CUDA toolkit if you have not installed it.\")\n  if(NOT BUILD_SHARED_LIBS)\n    message(STATUS \"Set BUILD_SHARED_LIBS to ON since SHERPA_ONNX_ENABLE_GPU is ON\")\n    set(BUILD_SHARED_LIBS ON CACHE BOOL \"\" FORCE)\n  endif()\nendif()\n\nif(SHERPA_ONNX_ENABLE_DIRECTML)\n  message(WARNING \"\\\nCompiling with DirectML enabled. Please make sure Windows 10 SDK\nis installed on your system. Otherwise, you will get errors at runtime.\nPlease refer to\n  https://onnxruntime.ai/docs/execution-providers/DirectML-ExecutionProvider.html#requirements\nto install Windows 10 SDK if you have not installed it.\")\n  if(NOT BUILD_SHARED_LIBS)\n    message(STATUS \"Set BUILD_SHARED_LIBS to ON since SHERPA_ONNX_ENABLE_DIRECTML is ON\")\n    set(BUILD_SHARED_LIBS ON CACHE BOOL \"\" FORCE)\n  endif()\nendif()\n\n# see https://cmake.org/cmake/help/latest/prop_tgt/MSVC_RUNTIME_LIBRARY.html\n# https://stackoverflow.com/questions/14172856/compile-with-mt-instead-of-md-using-cmake\nif(MSVC)\n  add_compile_options(\n      $<$<CONFIG:>:/MT> #---------|\n      $<$<CONFIG:Debug>:/MTd> #---|-- Statically link the runtime libraries\n      $<$<CONFIG:Release>:/MT> #--|\n      $<$<CONFIG:RelWithDebInfo>:/MT>\n      $<$<CONFIG:MinSizeRel>:/MT>\n  )\nendif()\n\nif(CMAKE_SYSTEM_NAME STREQUAL OHOS)\n  set(CMAKE_CXX_FLAGS \"-Wno-unused-command-line-argument ${CMAKE_CXX_FLAGS}\")\n  set(CMAKE_C_FLAGS \"-Wno-unused-command-line-argument ${CMAKE_C_FLAGS}\")\nendif()\n\nmessage(STATUS \"CMAKE_BUILD_TYPE: ${CMAKE_BUILD_TYPE}\")\nmessage(STATUS \"CMAKE_INSTALL_PREFIX: ${CMAKE_INSTALL_PREFIX}\")\nmessage(STATUS \"BUILD_SHARED_LIBS ${BUILD_SHARED_LIBS}\")\nmessage(STATUS \"SHERPA_ONNX_ENABLE_PYTHON ${SHERPA_ONNX_ENABLE_PYTHON}\")\nmessage(STATUS \"SHERPA_ONNX_ENABLE_TESTS ${SHERPA_ONNX_ENABLE_TESTS}\")\nmessage(STATUS \"SHERPA_ONNX_ENABLE_CHECK ${SHERPA_ONNX_ENABLE_CHECK}\")\nmessage(STATUS \"SHERPA_ONNX_ENABLE_PORTAUDIO ${SHERPA_ONNX_ENABLE_PORTAUDIO}\")\nmessage(STATUS \"SHERPA_ONNX_ENABLE_JNI ${SHERPA_ONNX_ENABLE_JNI}\")\nmessage(STATUS \"SHERPA_ONNX_ENABLE_C_API ${SHERPA_ONNX_ENABLE_C_API}\")\nmessage(STATUS \"SHERPA_ONNX_ENABLE_WEBSOCKET ${SHERPA_ONNX_ENABLE_WEBSOCKET}\")\nmessage(STATUS \"SHERPA_ONNX_ENABLE_GPU ${SHERPA_ONNX_ENABLE_GPU}\")\nmessage(STATUS \"SHERPA_ONNX_ENABLE_WASM ${SHERPA_ONNX_ENABLE_WASM}\")\nmessage(STATUS \"SHERPA_ONNX_ENABLE_WASM_SPEAKER_DIARIZATION ${SHERPA_ONNX_ENABLE_WASM_SPEAKER_DIARIZATION}\")\nmessage(STATUS \"SHERPA_ONNX_ENABLE_WASM_TTS ${SHERPA_ONNX_ENABLE_WASM_TTS}\")\nmessage(STATUS \"SHERPA_ONNX_ENABLE_WASM_ASR ${SHERPA_ONNX_ENABLE_WASM_ASR}\")\nmessage(STATUS \"SHERPA_ONNX_ENABLE_WASM_KWS ${SHERPA_ONNX_ENABLE_WASM_KWS}\")\nmessage(STATUS \"SHERPA_ONNX_ENABLE_WASM_VAD ${SHERPA_ONNX_ENABLE_WASM_VAD}\")\nmessage(STATUS \"SHERPA_ONNX_ENABLE_WASM_VAD_ASR ${SHERPA_ONNX_ENABLE_WASM_VAD_ASR}\")\nmessage(STATUS \"SHERPA_ONNX_ENABLE_WASM_NODEJS ${SHERPA_ONNX_ENABLE_WASM_NODEJS}\")\nmessage(STATUS \"SHERPA_ONNX_ENABLE_BINARY ${SHERPA_ONNX_ENABLE_BINARY}\")\nmessage(STATUS \"SHERPA_ONNX_ENABLE_TTS ${SHERPA_ONNX_ENABLE_TTS}\")\nmessage(STATUS \"SHERPA_ONNX_ENABLE_SPEAKER_DIARIZATION ${SHERPA_ONNX_ENABLE_SPEAKER_DIARIZATION}\")\nmessage(STATUS \"SHERPA_ONNX_LINK_LIBSTDCPP_STATICALLY ${SHERPA_ONNX_LINK_LIBSTDCPP_STATICALLY}\")\nmessage(STATUS \"SHERPA_ONNX_USE_PRE_INSTALLED_ONNXRUNTIME_IF_AVAILABLE ${SHERPA_ONNX_USE_PRE_INSTALLED_ONNXRUNTIME_IF_AVAILABLE}\")\nmessage(STATUS \"SHERPA_ONNX_ENABLE_SANITIZER: ${SHERPA_ONNX_ENABLE_SANITIZER}\")\nmessage(STATUS \"SHERPA_ONNX_BUILD_C_API_EXAMPLES: ${SHERPA_ONNX_BUILD_C_API_EXAMPLES}\")\n\nif(BUILD_SHARED_LIBS OR SHERPA_ONNX_ENABLE_JNI)\n  set(CMAKE_CXX_VISIBILITY_PRESET hidden)\n  set(CMAKE_VISIBILITY_INLINES_HIDDEN 1)\n  set(CMAKE_POSITION_INDEPENDENT_CODE ON)\nendif()\n\nif(BUILD_SHARED_LIBS AND NOT CMAKE_SYSTEM_NAME STREQUAL iOS AND CMAKE_BUILD_TYPE STREQUAL Release)\n  # Don't use LTO for iOS since it causes the following error\n  # error: unable to find any architecture information in the binary\n  # at '/Users/fangjun/open-source/sherpa-onnx/build-ios/build/os64/sherpa-onnx.a':\n  # Unknown header: 0xb17c0de\n  # See also https://forums.developer.apple.com/forums/thread/714324\n\n  include(CheckIPOSupported)\n  check_ipo_supported(RESULT ipo)\n  if(ipo)\n    message(STATUS \"IPO is enabled\")\n    set(CMAKE_INTERPROCEDURAL_OPTIMIZATION ON)\n  else()\n    message(STATUS \"IPO is not available\")\n  endif()\nendif()\n\nif(SHERPA_ONNX_ENABLE_TTS)\n  message(STATUS \"TTS is enabled\")\n  add_definitions(-DSHERPA_ONNX_ENABLE_TTS=1)\nelse()\n  message(WARNING \"TTS is disabled\")\n  add_definitions(-DSHERPA_ONNX_ENABLE_TTS=0)\nendif()\n\nif(SHERPA_ONNX_ENABLE_SPEAKER_DIARIZATION)\n  message(STATUS \"speaker diarization is enabled\")\n  add_definitions(-DSHERPA_ONNX_ENABLE_SPEAKER_DIARIZATION=1)\nelse()\n  message(WARNING \"speaker diarization is disabled\")\n  add_definitions(-DSHERPA_ONNX_ENABLE_SPEAKER_DIARIZATION=0)\nendif()\n\nif(SHERPA_ONNX_ENABLE_DIRECTML)\n  message(STATUS \"DirectML is enabled\")\n  add_definitions(-DSHERPA_ONNX_ENABLE_DIRECTML=1)\nelse()\n  message(WARNING \"DirectML is disabled\")\n  add_definitions(-DSHERPA_ONNX_ENABLE_DIRECTML=0)\nendif()\n\nif(SHERPA_ONNX_ENABLE_WASM_SPEAKER_DIARIZATION)\n  if(NOT SHERPA_ONNX_ENABLE_SPEAKER_DIARIZATION)\n    message(FATAL_ERROR \"Please set SHERPA_ONNX_ENABLE_SPEAKER_DIARIZATION to ON if you want to build WASM for speaker diarization\")\n  endif()\n\n  if(NOT SHERPA_ONNX_ENABLE_WASM)\n    message(FATAL_ERROR \"Please set SHERPA_ONNX_ENABLE_WASM to ON if you enable WASM for speaker diarization\")\n  endif()\nendif()\n\nif(SHERPA_ONNX_ENABLE_WASM_TTS)\n  if(NOT SHERPA_ONNX_ENABLE_TTS)\n    message(FATAL_ERROR \"Please set SHERPA_ONNX_ENABLE_TTS to ON if you want to build WASM for TTS\")\n  endif()\n\n  if(NOT SHERPA_ONNX_ENABLE_WASM)\n    message(FATAL_ERROR \"Please set SHERPA_ONNX_ENABLE_WASM to ON if you enable WASM for TTS\")\n  endif()\nendif()\n\nif(SHERPA_ONNX_ENABLE_WASM_ASR)\n  if(NOT SHERPA_ONNX_ENABLE_WASM)\n    message(FATAL_ERROR \"Please set SHERPA_ONNX_ENABLE_WASM to ON if you enable WASM for ASR\")\n  endif()\nendif()\n\nif(SHERPA_ONNX_ENABLE_WASM_NODEJS)\n  if(NOT SHERPA_ONNX_ENABLE_WASM)\n    message(FATAL_ERROR \"Please set SHERPA_ONNX_ENABLE_WASM to ON if you enable WASM for NodeJS\")\n  endif()\n  add_definitions(-DSHERPA_ONNX_ENABLE_WASM_KWS=1)\nendif()\n\nif(SHERPA_ONNX_ENABLE_WASM)\n  add_definitions(-DSHERPA_ONNX_ENABLE_WASM=1)\nendif()\n\nif(SHERPA_ONNX_ENABLE_WASM_KWS)\n  if(NOT SHERPA_ONNX_ENABLE_WASM)\n    message(FATAL_ERROR \"Please set SHERPA_ONNX_ENABLE_WASM to ON if you enable WASM for KWS\")\n  endif()\n  add_definitions(-DSHERPA_ONNX_ENABLE_WASM_KWS=1)\nendif()\n\nif(SHERPA_ONNX_ENABLE_WASM_VAD)\n  if(NOT SHERPA_ONNX_ENABLE_WASM)\n    message(FATAL_ERROR \"Please set SHERPA_ONNX_ENABLE_WASM to ON if you enable WASM for VAD\")\n  endif()\nendif()\n\nif(SHERPA_ONNX_ENABLE_WASM_VAD_ASR)\n  if(NOT SHERPA_ONNX_ENABLE_WASM)\n    message(FATAL_ERROR \"Please set SHERPA_ONNX_ENABLE_WASM to ON if you enable WASM for VAD+ASR\")\n  endif()\nendif()\n\nif(NOT CMAKE_CXX_STANDARD)\n  set(CMAKE_CXX_STANDARD 17 CACHE STRING \"The C++ version to be used.\")\nendif()\nset(CMAKE_CXX_EXTENSIONS OFF)\nmessage(STATUS \"C++ Standard version: ${CMAKE_CXX_STANDARD}\")\n\ninclude(CheckIncludeFileCXX)\n\nif(UNIX AND NOT APPLE AND NOT SHERPA_ONNX_ENABLE_WASM AND NOT CMAKE_SYSTEM_NAME STREQUAL Android AND NOT CMAKE_SYSTEM_NAME STREQUAL OHOS)\n  check_include_file_cxx(alsa/asoundlib.h SHERPA_ONNX_HAS_ALSA)\n  if(SHERPA_ONNX_HAS_ALSA)\n    message(STATUS \"With Alsa\")\n    add_definitions(-DSHERPA_ONNX_ENABLE_ALSA=1)\n  else()\n    message(WARNING \"\\\nCould not find alsa/asoundlib.h !\nWe won't build sherpa-onnx-alsa\nTo fix that, please do:\n  (1) sudo apt-get install alsa-utils libasound2-dev\n  (2) rm -rf build\n  (3) re-try\n  \")\n  endif()\nendif()\n\ncheck_include_file_cxx(cxxabi.h SHERPA_ONNX_HAVE_CXXABI_H)\ncheck_include_file_cxx(execinfo.h SHERPA_ONNX_HAVE_EXECINFO_H)\n\nif(WIN32)\n  add_definitions(-DNOMINMAX) # Otherwise, std::max() and std::min() won't work\nendif()\n\nif(WIN32 AND MSVC)\n  # disable various warnings for MSVC\n  # 4244: 'return': conversion from 'unsigned __int64' to 'int', possible loss of data\n  # 4267: 'initializing': conversion from 'size_t' to 'int', possible loss of data\n  # 4305: 'argument': truncation from 'double' to 'const float'\n  # 4334: '<<': result of 32-bit shift implicitly converted to 64 bits\n  # 4800: 'int': forcing value to bool 'true' or 'false'\n  # 4996: 'fopen': This function or variable may be unsafe\n  set(disabled_warnings\n      /wd4244\n      /wd4267\n      /wd4305\n      /wd4334\n      /wd4800\n      /wd4996\n  )\n  message(STATUS \"Disabled warnings: ${disabled_warnings}\")\n  foreach(w IN LISTS disabled_warnings)\n    string(APPEND CMAKE_CXX_FLAGS \" ${w} \")\n  endforeach()\n\n  add_compile_options(\"$<$<C_COMPILER_ID:MSVC>:/utf-8>\")\n  add_compile_options(\"$<$<CXX_COMPILER_ID:MSVC>:/utf-8>\")\nendif()\n\nlist(APPEND CMAKE_MODULE_PATH ${CMAKE_SOURCE_DIR}/cmake/Modules)\nlist(APPEND CMAKE_MODULE_PATH ${CMAKE_SOURCE_DIR}/cmake)\n\nif(SHERPA_ONNX_ENABLE_WASM)\n  # Enable it for debugging in case there is something wrong.\n  # string(APPEND CMAKE_CXX_FLAGS \" -g4 -s ASSERTIONS=2 -s SAFE_HEAP=1 -s STACK_OVERFLOW_CHECK=1 \")\nendif()\n\nif(NOT BUILD_SHARED_LIBS AND CMAKE_SYSTEM_NAME STREQUAL Linux)\n  if(SHERPA_ONNX_LINK_LIBSTDCPP_STATICALLY)\n    message(STATUS \"Link libstdc++ statically\")\n    set(CMAKE_CXX_FLAGS \" ${CMAKE_CXX_FLAGS} -static-libstdc++ -static-libgcc \")\n  else()\n    message(STATUS \"Link libstdc++ dynamically\")\n  endif()\nendif()\n\ninclude(kaldi-native-fbank)\ninclude(kaldi-decoder)\ninclude(onnxruntime)\ninclude(simple-sentencepiece)\nset(ONNXRUNTIME_DIR ${onnxruntime_SOURCE_DIR})\nmessage(STATUS \"ONNXRUNTIME_DIR: ${ONNXRUNTIME_DIR}\")\n\nif(SHERPA_ONNX_ENABLE_PORTAUDIO AND SHERPA_ONNX_ENABLE_BINARY)\n  # portaudio is used only in building demo binaries and the sherpa-onnx-core\n  # library does not depend on it.\n  include(portaudio)\nendif()\n\nif(SHERPA_ONNX_ENABLE_PYTHON)\n  include(pybind11)\nendif()\n\nif(SHERPA_ONNX_ENABLE_TESTS)\n  enable_testing()\n  include(googletest)\nendif()\n\nif(SHERPA_ONNX_ENABLE_WEBSOCKET)\n  include(websocketpp)\n  include(asio)\nendif()\n\nif(SHERPA_ONNX_ENABLE_TTS)\n  include(espeak-ng-for-piper)\n  set(ESPEAK_NG_DIR ${espeak_ng_SOURCE_DIR})\n  message(STATUS \"ESPEAK_NG_DIR: ${ESPEAK_NG_DIR}\")\n  include(piper-phonemize)\n  include(cppjieba) # For Chinese TTS. It is a header-only C++ library\nendif()\n\nif(SHERPA_ONNX_ENABLE_SPEAKER_DIARIZATION)\n  include(hclust-cpp)\nendif()\n\n# if(NOT MSVC AND CMAKE_BUILD_TYPE STREQUAL Debug AND (CMAKE_CXX_COMPILER_ID STREQUAL \"Clang\" OR CMAKE_CXX_COMPILER_ID STREQUAL \"AppleClang\"))\nif(SHERPA_ONNX_ENABLE_SANITIZER)\n  message(WARNING \"enable ubsan and asan\")\n  set(CMAKE_REQUIRED_LIBRARIES -lubsan -lasan)\n  include(CheckCCompilerFlag)\n\n  set(flags -fsanitize=undefined )\n  string(APPEND flags \" -fno-sanitize-recover=undefined \")\n  string(APPEND flags \" -fsanitize=integer \")\n  string(APPEND flags \" -fsanitize=nullability \")\n  string(APPEND flags \" -fsanitize=implicit-conversion \")\n  string(APPEND flags \" -fsanitize=bounds \")\n  string(APPEND flags \" -fsanitize=address \")\n\n  if(OFF)\n    set(CMAKE_C_FLAGS \"${CMAKE_C_FLAGS} ${flags} -Wall -Wextra\")\n    set(CMAKE_CXX_FLAGS \"${CMAKE_CXX_FLAGS} ${flags} -Wall -Wextra\")\n  else()\n    set(CMAKE_C_FLAGS \"${CMAKE_C_FLAGS} ${flags}\")\n    set(CMAKE_CXX_FLAGS \"${CMAKE_CXX_FLAGS} ${flags}\")\n  endif()\n\n  set(CMAKE_EXECUTBLE_LINKER_FLAGS \"${CMAKE_EXECUTBLE_LINKER_FLAGS} ${flags}\")\n\n  add_compile_options(-fno-omit-frame-pointer)\nendif()\n\nadd_subdirectory(sherpa-onnx)\n\nif(SHERPA_ONNX_ENABLE_C_API AND SHERPA_ONNX_ENABLE_BINARY AND SHERPA_ONNX_BUILD_C_API_EXAMPLES)\n  set(SHERPA_ONNX_PKG_WITH_CARGS \"-lcargs\")\n  add_subdirectory(c-api-examples)\n  add_subdirectory(cxx-api-examples)\nendif()\n\nif(SHERPA_ONNX_ENABLE_WASM)\n  add_subdirectory(wasm)\nendif()\n\nmessage(STATUS \"CMAKE_CXX_FLAGS: ${CMAKE_CXX_FLAGS}\")\n\nif(NOT BUILD_SHARED_LIBS)\n  if(APPLE)\n    set(SHERPA_ONNX_PKG_CONFIG_EXTRA_LIBS \"-lc++ -framework Foundation\")\n  endif()\n\n  if(UNIX AND NOT APPLE)\n    set(SHERPA_ONNX_PKG_CONFIG_EXTRA_LIBS \"-lstdc++ -lm -pthread -ldl\")\n  endif()\nendif()\n\nif(NOT BUILD_SHARED_LIBS)\n# See https://people.freedesktop.org/~dbn/pkg-config-guide.html\n  if(SHERPA_ONNX_ENABLE_TTS)\n    configure_file(cmake/sherpa-onnx-static.pc.in ${PROJECT_BINARY_DIR}/sherpa-onnx.pc @ONLY)\n  else()\n    configure_file(cmake/sherpa-onnx-static-no-tts.pc.in ${PROJECT_BINARY_DIR}/sherpa-onnx.pc @ONLY)\n  endif()\nelse()\n  configure_file(cmake/sherpa-onnx-shared.pc.in ${PROJECT_BINARY_DIR}/sherpa-onnx.pc @ONLY)\nendif()\n\ninstall(\n  FILES\n    ${PROJECT_BINARY_DIR}/sherpa-onnx.pc\n  DESTINATION\n    ./\n)\nmessage(STATUS \"CMAKE_CXX_FLAGS: ${CMAKE_CXX_FLAGS}\")\n"
        },
        {
          "name": "CPPLINT.cfg",
          "type": "blob",
          "size": 0.0224609375,
          "content": "filter=-./mfc-examples\n"
        },
        {
          "name": "LICENSE",
          "type": "blob",
          "size": 11.091796875,
          "content": "\n                                 Apache License\n                           Version 2.0, January 2004\n                        http://www.apache.org/licenses/\n\n   TERMS AND CONDITIONS FOR USE, REPRODUCTION, AND DISTRIBUTION\n\n   1. Definitions.\n\n      \"License\" shall mean the terms and conditions for use, reproduction,\n      and distribution as defined by Sections 1 through 9 of this document.\n\n      \"Licensor\" shall mean the copyright owner or entity authorized by\n      the copyright owner that is granting the License.\n\n      \"Legal Entity\" shall mean the union of the acting entity and all\n      other entities that control, are controlled by, or are under common\n      control with that entity. For the purposes of this definition,\n      \"control\" means (i) the power, direct or indirect, to cause the\n      direction or management of such entity, whether by contract or\n      otherwise, or (ii) ownership of fifty percent (50%) or more of the\n      outstanding shares, or (iii) beneficial ownership of such entity.\n\n      \"You\" (or \"Your\") shall mean an individual or Legal Entity\n      exercising permissions granted by this License.\n\n      \"Source\" form shall mean the preferred form for making modifications,\n      including but not limited to software source code, documentation\n      source, and configuration files.\n\n      \"Object\" form shall mean any form resulting from mechanical\n      transformation or translation of a Source form, including but\n      not limited to compiled object code, generated documentation,\n      and conversions to other media types.\n\n      \"Work\" shall mean the work of authorship, whether in Source or\n      Object form, made available under the License, as indicated by a\n      copyright notice that is included in or attached to the work\n      (an example is provided in the Appendix below).\n\n      \"Derivative Works\" shall mean any work, whether in Source or Object\n      form, that is based on (or derived from) the Work and for which the\n      editorial revisions, annotations, elaborations, or other modifications\n      represent, as a whole, an original work of authorship. For the purposes\n      of this License, Derivative Works shall not include works that remain\n      separable from, or merely link (or bind by name) to the interfaces of,\n      the Work and Derivative Works thereof.\n\n      \"Contribution\" shall mean any work of authorship, including\n      the original version of the Work and any modifications or additions\n      to that Work or Derivative Works thereof, that is intentionally\n      submitted to Licensor for inclusion in the Work by the copyright owner\n      or by an individual or Legal Entity authorized to submit on behalf of\n      the copyright owner. For the purposes of this definition, \"submitted\"\n      means any form of electronic, verbal, or written communication sent\n      to the Licensor or its representatives, including but not limited to\n      communication on electronic mailing lists, source code control systems,\n      and issue tracking systems that are managed by, or on behalf of, the\n      Licensor for the purpose of discussing and improving the Work, but\n      excluding communication that is conspicuously marked or otherwise\n      designated in writing by the copyright owner as \"Not a Contribution.\"\n\n      \"Contributor\" shall mean Licensor and any individual or Legal Entity\n      on behalf of whom a Contribution has been received by Licensor and\n      subsequently incorporated within the Work.\n\n   2. Grant of Copyright License. Subject to the terms and conditions of\n      this License, each Contributor hereby grants to You a perpetual,\n      worldwide, non-exclusive, no-charge, royalty-free, irrevocable\n      copyright license to reproduce, prepare Derivative Works of,\n      publicly display, publicly perform, sublicense, and distribute the\n      Work and such Derivative Works in Source or Object form.\n\n   3. Grant of Patent License. Subject to the terms and conditions of\n      this License, each Contributor hereby grants to You a perpetual,\n      worldwide, non-exclusive, no-charge, royalty-free, irrevocable\n      (except as stated in this section) patent license to make, have made,\n      use, offer to sell, sell, import, and otherwise transfer the Work,\n      where such license applies only to those patent claims licensable\n      by such Contributor that are necessarily infringed by their\n      Contribution(s) alone or by combination of their Contribution(s)\n      with the Work to which such Contribution(s) was submitted. If You\n      institute patent litigation against any entity (including a\n      cross-claim or counterclaim in a lawsuit) alleging that the Work\n      or a Contribution incorporated within the Work constitutes direct\n      or contributory patent infringement, then any patent licenses\n      granted to You under this License for that Work shall terminate\n      as of the date such litigation is filed.\n\n   4. Redistribution. You may reproduce and distribute copies of the\n      Work or Derivative Works thereof in any medium, with or without\n      modifications, and in Source or Object form, provided that You\n      meet the following conditions:\n\n      (a) You must give any other recipients of the Work or\n          Derivative Works a copy of this License; and\n\n      (b) You must cause any modified files to carry prominent notices\n          stating that You changed the files; and\n\n      (c) You must retain, in the Source form of any Derivative Works\n          that You distribute, all copyright, patent, trademark, and\n          attribution notices from the Source form of the Work,\n          excluding those notices that do not pertain to any part of\n          the Derivative Works; and\n\n      (d) If the Work includes a \"NOTICE\" text file as part of its\n          distribution, then any Derivative Works that You distribute must\n          include a readable copy of the attribution notices contained\n          within such NOTICE file, excluding those notices that do not\n          pertain to any part of the Derivative Works, in at least one\n          of the following places: within a NOTICE text file distributed\n          as part of the Derivative Works; within the Source form or\n          documentation, if provided along with the Derivative Works; or,\n          within a display generated by the Derivative Works, if and\n          wherever such third-party notices normally appear. The contents\n          of the NOTICE file are for informational purposes only and\n          do not modify the License. You may add Your own attribution\n          notices within Derivative Works that You distribute, alongside\n          or as an addendum to the NOTICE text from the Work, provided\n          that such additional attribution notices cannot be construed\n          as modifying the License.\n\n      You may add Your own copyright statement to Your modifications and\n      may provide additional or different license terms and conditions\n      for use, reproduction, or distribution of Your modifications, or\n      for any such Derivative Works as a whole, provided Your use,\n      reproduction, and distribution of the Work otherwise complies with\n      the conditions stated in this License.\n\n   5. Submission of Contributions. Unless You explicitly state otherwise,\n      any Contribution intentionally submitted for inclusion in the Work\n      by You to the Licensor shall be under the terms and conditions of\n      this License, without any additional terms or conditions.\n      Notwithstanding the above, nothing herein shall supersede or modify\n      the terms of any separate license agreement you may have executed\n      with Licensor regarding such Contributions.\n\n   6. Trademarks. This License does not grant permission to use the trade\n      names, trademarks, service marks, or product names of the Licensor,\n      except as required for reasonable and customary use in describing the\n      origin of the Work and reproducing the content of the NOTICE file.\n\n   7. Disclaimer of Warranty. Unless required by applicable law or\n      agreed to in writing, Licensor provides the Work (and each\n      Contributor provides its Contributions) on an \"AS IS\" BASIS,\n      WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or\n      implied, including, without limitation, any warranties or conditions\n      of TITLE, NON-INFRINGEMENT, MERCHANTABILITY, or FITNESS FOR A\n      PARTICULAR PURPOSE. You are solely responsible for determining the\n      appropriateness of using or redistributing the Work and assume any\n      risks associated with Your exercise of permissions under this License.\n\n   8. Limitation of Liability. In no event and under no legal theory,\n      whether in tort (including negligence), contract, or otherwise,\n      unless required by applicable law (such as deliberate and grossly\n      negligent acts) or agreed to in writing, shall any Contributor be\n      liable to You for damages, including any direct, indirect, special,\n      incidental, or consequential damages of any character arising as a\n      result of this License or out of the use or inability to use the\n      Work (including but not limited to damages for loss of goodwill,\n      work stoppage, computer failure or malfunction, or any and all\n      other commercial damages or losses), even if such Contributor\n      has been advised of the possibility of such damages.\n\n   9. Accepting Warranty or Additional Liability. While redistributing\n      the Work or Derivative Works thereof, You may choose to offer,\n      and charge a fee for, acceptance of support, warranty, indemnity,\n      or other liability obligations and/or rights consistent with this\n      License. However, in accepting such obligations, You may act only\n      on Your own behalf and on Your sole responsibility, not on behalf\n      of any other Contributor, and only if You agree to indemnify,\n      defend, and hold each Contributor harmless for any liability\n      incurred by, or claims asserted against, such Contributor by reason\n      of your accepting any such warranty or additional liability.\n\n   END OF TERMS AND CONDITIONS\n\n   APPENDIX: How to apply the Apache License to your work.\n\n      To apply the Apache License to your work, attach the following\n      boilerplate notice, with the fields enclosed by brackets \"[]\"\n      replaced with your own identifying information. (Don't include\n      the brackets!)  The text should be enclosed in the appropriate\n      comment syntax for the file format. We also recommend that a\n      file or class name and description of purpose be included on the\n      same \"printed page\" as the copyright notice for easier\n      identification within third-party archives.\n\n   Copyright [yyyy] [name of copyright owner]\n\n   Licensed under the Apache License, Version 2.0 (the \"License\");\n   you may not use this file except in compliance with the License.\n   You may obtain a copy of the License at\n\n       http://www.apache.org/licenses/LICENSE-2.0\n\n   Unless required by applicable law or agreed to in writing, software\n   distributed under the License is distributed on an \"AS IS\" BASIS,\n   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n   See the License for the specific language governing permissions and\n   limitations under the License.\n"
        },
        {
          "name": "MANIFEST.in",
          "type": "blob",
          "size": 0.24609375,
          "content": "include LICENSE\ninclude README.md\ninclude CMakeLists.txt\nrecursive-include c-api-examples *.*\nrecursive-include sherpa-onnx *.*\nrecursive-include cmake *.*\nprune */__pycache__\nprune android\nprune sherpa-onnx/java-api\nprune ios-swift\nprune ios-swiftui\n\n"
        },
        {
          "name": "README.md",
          "type": "blob",
          "size": 32.4091796875,
          "content": "### Supported functions\n\n|Speech recognition| Speech synthesis |\n|------------------|------------------|\n|   ✔️              |         ✔️        |\n\n|Speaker identification| Speaker diarization | Speaker verification |\n|----------------------|-------------------- |------------------------|\n|   ✔️                  |         ✔️           |            ✔️           |\n\n| Spoken Language identification | Audio tagging | Voice activity detection |\n|--------------------------------|---------------|--------------------------|\n|                 ✔️              |          ✔️    |                ✔️         |\n\n| Keyword spotting | Add punctuation |\n|------------------|-----------------|\n|     ✔️            |       ✔️         |\n\n### Supported platforms\n\n|Architecture| Android | iOS     | Windows    | macOS | linux | HarmonyOS |\n|------------|---------|---------|------------|-------|-------|-----------|\n|   x64      |  ✔️      |         |   ✔️        | ✔️     |  ✔️    |   ✔️       |\n|   x86      |  ✔️      |         |   ✔️        |       |       |           |\n|   arm64    |  ✔️      | ✔️       |   ✔️        | ✔️     |  ✔️    |   ✔️       |\n|   arm32    |  ✔️      |         |            |       |  ✔️    |   ✔️       |\n|   riscv64  |         |         |            |       |  ✔️    |           |\n\n### Supported programming languages\n\n| 1. C++ | 2. C  | 3. Python | 4. JavaScript |\n|--------|-------|-----------|---------------|\n|   ✔️    | ✔️     | ✔️         |    ✔️          |\n\n|5. Java | 6. C# | 7. Kotlin | 8. Swift |\n|--------|-------|-----------|----------|\n| ✔️      |  ✔️    | ✔️         |  ✔️       |\n\n| 9. Go | 10. Dart | 11. Rust | 12. Pascal |\n|-------|----------|----------|------------|\n| ✔️     |  ✔️       |   ✔️      |    ✔️       |\n\nFor Rust support, please see [sherpa-rs][sherpa-rs]\n\nIt also supports WebAssembly.\n\n## Introduction\n\nThis repository supports running the following functions **locally**\n\n  - Speech-to-text (i.e., ASR); both streaming and non-streaming are supported\n  - Text-to-speech (i.e., TTS)\n  - Speaker diarization\n  - Speaker identification\n  - Speaker verification\n  - Spoken language identification\n  - Audio tagging\n  - VAD (e.g., [silero-vad][silero-vad])\n  - Keyword spotting\n\non the following platforms and operating systems:\n\n  - x86, ``x86_64``, 32-bit ARM, 64-bit ARM (arm64, aarch64), RISC-V (riscv64)\n  - Linux, macOS, Windows, openKylin\n  - Android, WearOS\n  - iOS\n  - HarmonyOS\n  - NodeJS\n  - WebAssembly\n  - [NVIDIA Jetson Orin NX][NVIDIA Jetson Orin NX] (Support running on both CPU and GPU)\n  - [NVIDIA Jetson Nano B01][NVIDIA Jetson Nano B01] (Support running on both CPU and GPU)\n  - [Raspberry Pi][Raspberry Pi]\n  - [RV1126][RV1126]\n  - [LicheePi4A][LicheePi4A]\n  - [VisionFive 2][VisionFive 2]\n  - [旭日X3派][旭日X3派]\n  - [爱芯派][爱芯派]\n  - etc\n\nwith the following APIs\n\n  - C++, C, Python, Go, ``C#``\n  - Java, Kotlin, JavaScript\n  - Swift, Rust\n  - Dart, Object Pascal\n\n### Links for Huggingface Spaces\n\n<details>\n<summary>You can visit the following Huggingface spaces to try sherpa-onnx without\ninstalling anything. All you need is a browser.</summary>\n\n| Description                                           | URL                                     |\n|-------------------------------------------------------|-----------------------------------------|\n| Speaker diarization                                   | [Click me][hf-space-speaker-diarization]|\n| Speech recognition                                    | [Click me][hf-space-asr]                |\n| Speech recognition with [Whisper][Whisper]            | [Click me][hf-space-asr-whisper]        |\n| Speech synthesis                                      | [Click me][hf-space-tts]                |\n| Generate subtitles                                    | [Click me][hf-space-subtitle]           |\n| Audio tagging                                         | [Click me][hf-space-audio-tagging]      |\n| Spoken language identification with [Whisper][Whisper]| [Click me][hf-space-slid-whisper]       |\n\nWe also have spaces built using WebAssembly. They are listed below:\n\n| Description                                                                              | Huggingface space| ModelScope space|\n|------------------------------------------------------------------------------------------|------------------|-----------------|\n|Voice activity detection with [silero-vad][silero-vad]                                    | [Click me][wasm-hf-vad]|[地址][wasm-ms-vad]|\n|Real-time speech recognition (Chinese + English) with Zipformer                           | [Click me][wasm-hf-streaming-asr-zh-en-zipformer]|[地址][wasm-hf-streaming-asr-zh-en-zipformer]|\n|Real-time speech recognition (Chinese + English) with Paraformer                          |[Click me][wasm-hf-streaming-asr-zh-en-paraformer]| [地址][wasm-ms-streaming-asr-zh-en-paraformer]|\n|Real-time speech recognition (Chinese + English + Cantonese) with [Paraformer-large][Paraformer-large]|[Click me][wasm-hf-streaming-asr-zh-en-yue-paraformer]| [地址][wasm-ms-streaming-asr-zh-en-yue-paraformer]|\n|Real-time speech recognition (English) |[Click me][wasm-hf-streaming-asr-en-zipformer]    |[地址][wasm-ms-streaming-asr-en-zipformer]|\n|VAD + speech recognition (Chinese + English + Korean + Japanese + Cantonese) with [SenseVoice][SenseVoice]|[Click me][wasm-hf-vad-asr-zh-en-ko-ja-yue-sense-voice]| [地址][wasm-ms-vad-asr-zh-en-ko-ja-yue-sense-voice]|\n|VAD + speech recognition (English) with [Whisper][Whisper] tiny.en|[Click me][wasm-hf-vad-asr-en-whisper-tiny-en]| [地址][wasm-ms-vad-asr-en-whisper-tiny-en]|\n|VAD + speech recognition (English) with [Moonshine tiny][Moonshine tiny]|[Click me][wasm-hf-vad-asr-en-moonshine-tiny-en]| [地址][wasm-ms-vad-asr-en-moonshine-tiny-en]|\n|VAD + speech recognition (English) with Zipformer trained with [GigaSpeech][GigaSpeech]    |[Click me][wasm-hf-vad-asr-en-zipformer-gigaspeech]| [地址][wasm-ms-vad-asr-en-zipformer-gigaspeech]|\n|VAD + speech recognition (Chinese) with Zipformer trained with [WenetSpeech][WenetSpeech]  |[Click me][wasm-hf-vad-asr-zh-zipformer-wenetspeech]| [地址][wasm-ms-vad-asr-zh-zipformer-wenetspeech]|\n|VAD + speech recognition (Japanese) with Zipformer trained with [ReazonSpeech][ReazonSpeech]|[Click me][wasm-hf-vad-asr-ja-zipformer-reazonspeech]| [地址][wasm-ms-vad-asr-ja-zipformer-reazonspeech]|\n|VAD + speech recognition (Thai) with Zipformer trained with [GigaSpeech2][GigaSpeech2]      |[Click me][wasm-hf-vad-asr-th-zipformer-gigaspeech2]| [地址][wasm-ms-vad-asr-th-zipformer-gigaspeech2]|\n|VAD + speech recognition (Chinese 多种方言) with a [TeleSpeech-ASR][TeleSpeech-ASR] CTC model|[Click me][wasm-hf-vad-asr-zh-telespeech]| [地址][wasm-ms-vad-asr-zh-telespeech]|\n|VAD + speech recognition (English + Chinese, 及多种中文方言) with Paraformer-large          |[Click me][wasm-hf-vad-asr-zh-en-paraformer-large]| [地址][wasm-ms-vad-asr-zh-en-paraformer-large]|\n|VAD + speech recognition (English + Chinese, 及多种中文方言) with Paraformer-small          |[Click me][wasm-hf-vad-asr-zh-en-paraformer-small]| [地址][wasm-ms-vad-asr-zh-en-paraformer-small]|\n|Speech synthesis (English)                                                                  |[Click me][wasm-hf-tts-piper-en]| [地址][wasm-ms-tts-piper-en]|\n|Speech synthesis (German)                                                                   |[Click me][wasm-hf-tts-piper-de]| [地址][wasm-ms-tts-piper-de]|\n|Speaker diarization                                                                         |[Click me][wasm-hf-speaker-diarization]|[地址][wasm-ms-speaker-diarization]|\n\n</details>\n\n### Links for pre-built Android APKs\n\n<details>\n\n<summary>You can find pre-built Android APKs for this repository in the following table</summary>\n\n| Description                            | URL                                | 中国用户                          |\n|----------------------------------------|------------------------------------|-----------------------------------|\n| Speaker diarization                    | [Address][apk-speaker-diarization] | [点此][apk-speaker-diarization-cn]|\n| Streaming speech recognition           | [Address][apk-streaming-asr]       | [点此][apk-streaming-asr-cn]      |\n| Text-to-speech                         | [Address][apk-tts]                 | [点此][apk-tts-cn]                |\n| Voice activity detection (VAD)         | [Address][apk-vad]                 | [点此][apk-vad-cn]                |\n| VAD + non-streaming speech recognition | [Address][apk-vad-asr]             | [点此][apk-vad-asr-cn]            |\n| Two-pass speech recognition            | [Address][apk-2pass]               | [点此][apk-2pass-cn]              |\n| Audio tagging                          | [Address][apk-at]                  | [点此][apk-at-cn]                 |\n| Audio tagging (WearOS)                 | [Address][apk-at-wearos]           | [点此][apk-at-wearos-cn]          |\n| Speaker identification                 | [Address][apk-sid]                 | [点此][apk-sid-cn]                |\n| Spoken language identification         | [Address][apk-slid]                | [点此][apk-slid-cn]               |\n| Keyword spotting                       | [Address][apk-kws]                 | [点此][apk-kws-cn]                |\n\n</details>\n\n### Links for pre-built Flutter APPs\n\n<details>\n\n#### Real-time speech recognition\n\n| Description                    | URL                                 | 中国用户                            |\n|--------------------------------|-------------------------------------|-------------------------------------|\n| Streaming speech recognition   | [Address][apk-flutter-streaming-asr]| [点此][apk-flutter-streaming-asr-cn]|\n\n#### Text-to-speech\n\n| Description                              | URL                                | 中国用户                           |\n|------------------------------------------|------------------------------------|------------------------------------|\n| Android (arm64-v8a, armeabi-v7a, x86_64) | [Address][flutter-tts-android]     | [点此][flutter-tts-android-cn]     |\n| Linux (x64)                              | [Address][flutter-tts-linux]       | [点此][flutter-tts-linux-cn]       |\n| macOS (x64)                              | [Address][flutter-tts-macos-x64]   | [点此][flutter-tts-macos-arm64-cn] |\n| macOS (arm64)                            | [Address][flutter-tts-macos-arm64] | [点此][flutter-tts-macos-x64-cn]   |\n| Windows (x64)                            | [Address][flutter-tts-win-x64]     | [点此][flutter-tts-win-x64-cn]     |\n\n> Note: You need to build from source for iOS.\n\n</details>\n\n### Links for pre-built Lazarus APPs\n\n<details>\n\n#### Generating subtitles\n\n| Description                    | URL                        | 中国用户                   |\n|--------------------------------|----------------------------|----------------------------|\n| Generate subtitles (生成字幕)  | [Address][lazarus-subtitle]| [点此][lazarus-subtitle-cn]|\n\n</details>\n\n### Links for pre-trained models\n\n<details>\n\n| Description                                 | URL                                                                                   |\n|---------------------------------------------|---------------------------------------------------------------------------------------|\n| Speech recognition (speech to text, ASR)    | [Address][asr-models]                                                                 |\n| Text-to-speech (TTS)                        | [Address][tts-models]                                                                 |\n| VAD                                         | [Address][vad-models]                                                                 |\n| Keyword spotting                            | [Address][kws-models]                                                                 |\n| Audio tagging                               | [Address][at-models]                                                                  |\n| Speaker identification (Speaker ID)         | [Address][sid-models]                                                                 |\n| Spoken language identification (Language ID)| See multi-lingual [Whisper][Whisper] ASR models from  [Speech recognition][asr-models]|\n| Punctuation                                 | [Address][punct-models]                                                               |\n| Speaker segmentation                        | [Address][speaker-segmentation-models]                                                |\n\n</details>\n\n#### Some pre-trained ASR models (Streaming)\n\n<details>\n\nPlease see\n\n  - <https://k2-fsa.github.io/sherpa/onnx/pretrained_models/online-transducer/index.html>\n  - <https://k2-fsa.github.io/sherpa/onnx/pretrained_models/online-paraformer/index.html>\n  - <https://k2-fsa.github.io/sherpa/onnx/pretrained_models/online-ctc/index.html>\n\nfor more models. The following table lists only **SOME** of them.\n\n\n|Name | Supported Languages| Description|\n|-----|-----|----|\n|[sherpa-onnx-streaming-zipformer-bilingual-zh-en-2023-02-20][sherpa-onnx-streaming-zipformer-bilingual-zh-en-2023-02-20]| Chinese, English| See [also](https://k2-fsa.github.io/sherpa/onnx/pretrained_models/online-transducer/zipformer-transducer-models.html#csukuangfj-sherpa-onnx-streaming-zipformer-bilingual-zh-en-2023-02-20-bilingual-chinese-english)|\n|[sherpa-onnx-streaming-zipformer-small-bilingual-zh-en-2023-02-16][sherpa-onnx-streaming-zipformer-small-bilingual-zh-en-2023-02-16]| Chinese, English| See [also](https://k2-fsa.github.io/sherpa/onnx/pretrained_models/online-transducer/zipformer-transducer-models.html#sherpa-onnx-streaming-zipformer-small-bilingual-zh-en-2023-02-16-bilingual-chinese-english)|\n|[sherpa-onnx-streaming-zipformer-zh-14M-2023-02-23][sherpa-onnx-streaming-zipformer-zh-14M-2023-02-23]|Chinese| Suitable for Cortex A7 CPU. See [also](https://k2-fsa.github.io/sherpa/onnx/pretrained_models/online-transducer/zipformer-transducer-models.html#sherpa-onnx-streaming-zipformer-zh-14m-2023-02-23)|\n|[sherpa-onnx-streaming-zipformer-en-20M-2023-02-17][sherpa-onnx-streaming-zipformer-en-20M-2023-02-17]|English|Suitable for Cortex A7 CPU. See [also](https://k2-fsa.github.io/sherpa/onnx/pretrained_models/online-transducer/zipformer-transducer-models.html#sherpa-onnx-streaming-zipformer-en-20m-2023-02-17)|\n|[sherpa-onnx-streaming-zipformer-korean-2024-06-16][sherpa-onnx-streaming-zipformer-korean-2024-06-16]|Korean| See [also](https://k2-fsa.github.io/sherpa/onnx/pretrained_models/online-transducer/zipformer-transducer-models.html#sherpa-onnx-streaming-zipformer-korean-2024-06-16-korean)|\n|[sherpa-onnx-streaming-zipformer-fr-2023-04-14][sherpa-onnx-streaming-zipformer-fr-2023-04-14]|French| See [also](https://k2-fsa.github.io/sherpa/onnx/pretrained_models/online-transducer/zipformer-transducer-models.html#shaojieli-sherpa-onnx-streaming-zipformer-fr-2023-04-14-french)|\n\n</details>\n\n\n#### Some pre-trained ASR models (Non-Streaming)\n\n<details>\n\nPlease see\n\n  - <https://k2-fsa.github.io/sherpa/onnx/pretrained_models/offline-transducer/index.html>\n  - <https://k2-fsa.github.io/sherpa/onnx/pretrained_models/offline-paraformer/index.html>\n  - <https://k2-fsa.github.io/sherpa/onnx/pretrained_models/offline-ctc/index.html>\n  - <https://k2-fsa.github.io/sherpa/onnx/pretrained_models/telespeech/index.html>\n  - <https://k2-fsa.github.io/sherpa/onnx/pretrained_models/whisper/index.html>\n\nfor more models. The following table lists only **SOME** of them.\n\n|Name | Supported Languages| Description|\n|-----|-----|----|\n|[Whisper tiny.en](https://github.com/k2-fsa/sherpa-onnx/releases/download/asr-models/sherpa-onnx-whisper-tiny.en.tar.bz2)|English| See [also](https://k2-fsa.github.io/sherpa/onnx/pretrained_models/whisper/tiny.en.html)|\n|[Moonshine tiny][Moonshine tiny]|English|See [also](https://github.com/usefulsensors/moonshine)|\n|[sherpa-onnx-sense-voice-zh-en-ja-ko-yue-2024-07-17][sherpa-onnx-sense-voice-zh-en-ja-ko-yue-2024-07-17]|Chinese, Cantonese, English, Korean, Japanese| 支持多种中文方言. See [also](https://k2-fsa.github.io/sherpa/onnx/sense-voice/index.html)|\n|[sherpa-onnx-paraformer-zh-2024-03-09][sherpa-onnx-paraformer-zh-2024-03-09]|Chinese, English| 也支持多种中文方言. See [also](https://k2-fsa.github.io/sherpa/onnx/pretrained_models/offline-paraformer/paraformer-models.html#csukuangfj-sherpa-onnx-paraformer-zh-2024-03-09-chinese-english)|\n|[sherpa-onnx-zipformer-ja-reazonspeech-2024-08-01][sherpa-onnx-zipformer-ja-reazonspeech-2024-08-01]|Japanese|See [also](https://k2-fsa.github.io/sherpa/onnx/pretrained_models/offline-transducer/zipformer-transducer-models.html#sherpa-onnx-zipformer-ja-reazonspeech-2024-08-01-japanese)|\n|[sherpa-onnx-nemo-transducer-giga-am-russian-2024-10-24][sherpa-onnx-nemo-transducer-giga-am-russian-2024-10-24]|Russian|See [also](https://k2-fsa.github.io/sherpa/onnx/pretrained_models/offline-transducer/nemo-transducer-models.html#sherpa-onnx-nemo-transducer-giga-am-russian-2024-10-24-russian)|\n|[sherpa-onnx-nemo-ctc-giga-am-russian-2024-10-24][sherpa-onnx-nemo-ctc-giga-am-russian-2024-10-24]|Russian| See [also](https://k2-fsa.github.io/sherpa/onnx/pretrained_models/offline-ctc/nemo/russian.html#sherpa-onnx-nemo-ctc-giga-am-russian-2024-10-24)|\n|[sherpa-onnx-zipformer-ru-2024-09-18][sherpa-onnx-zipformer-ru-2024-09-18]|Russian|See [also](https://k2-fsa.github.io/sherpa/onnx/pretrained_models/offline-transducer/zipformer-transducer-models.html#sherpa-onnx-zipformer-ru-2024-09-18-russian)|\n|[sherpa-onnx-zipformer-korean-2024-06-24][sherpa-onnx-zipformer-korean-2024-06-24]|Korean|See [also](https://k2-fsa.github.io/sherpa/onnx/pretrained_models/offline-transducer/zipformer-transducer-models.html#sherpa-onnx-zipformer-korean-2024-06-24-korean)|\n|[sherpa-onnx-zipformer-thai-2024-06-20][sherpa-onnx-zipformer-thai-2024-06-20]|Thai| See [also](https://k2-fsa.github.io/sherpa/onnx/pretrained_models/offline-transducer/zipformer-transducer-models.html#sherpa-onnx-zipformer-thai-2024-06-20-thai)|\n|[sherpa-onnx-telespeech-ctc-int8-zh-2024-06-04][sherpa-onnx-telespeech-ctc-int8-zh-2024-06-04]|Chinese| 支持多种方言. See [also](https://k2-fsa.github.io/sherpa/onnx/pretrained_models/telespeech/models.html#sherpa-onnx-telespeech-ctc-int8-zh-2024-06-04)|\n\n</details>\n\n### Useful links\n\n- Documentation: https://k2-fsa.github.io/sherpa/onnx/\n- Bilibili 演示视频: https://search.bilibili.com/all?keyword=%E6%96%B0%E4%B8%80%E4%BB%A3Kaldi\n\n### How to reach us\n\nPlease see\nhttps://k2-fsa.github.io/sherpa/social-groups.html\nfor 新一代 Kaldi **微信交流群** and **QQ 交流群**.\n\n## Projects using sherpa-onnx\n\n### [Open-LLM-VTuber](https://github.com/t41372/Open-LLM-VTuber)\n\nTalk to any LLM with hands-free voice interaction, voice interruption, and Live2D taking\nface running locally across platforms\n\nSee also <https://github.com/t41372/Open-LLM-VTuber/pull/50>\n\n### [voiceapi](https://github.com/ruzhila/voiceapi)\n\n<details>\n  <summary>Streaming ASR and TTS based on FastAPI</summary>\n\n\nIt shows how to use the ASR and TTS Python APIs with FastAPI.\n</details>\n\n### [腾讯会议摸鱼工具 TMSpeech](https://github.com/jxlpzqc/TMSpeech)\n\nUses streaming ASR in C# with graphical user interface.\n\nVideo demo in Chinese: [【开源】Windows实时字幕软件（网课/开会必备）](https://www.bilibili.com/video/BV1rX4y1p7Nx)\n\n### [lol互动助手](https://github.com/l1veIn/lol-wom-electron)\n\nIt uses the JavaScript API of sherpa-onnx along with [Electron](https://electronjs.org/)\n\nVideo demo in Chinese: [爆了！炫神教你开打字挂！真正影响胜率的英雄联盟工具！英雄联盟的最后一块拼图！和游戏中的每个人无障碍沟通！](https://www.bilibili.com/video/BV142tje9E74)\n\n\n[sherpa-rs]: https://github.com/thewh1teagle/sherpa-rs\n[silero-vad]: https://github.com/snakers4/silero-vad\n[Raspberry Pi]: https://www.raspberrypi.com/\n[RV1126]: https://www.rock-chips.com/uploads/pdf/2022.8.26/191/RV1126%20Brief%20Datasheet.pdf\n[LicheePi4A]: https://sipeed.com/licheepi4a\n[VisionFive 2]: https://www.starfivetech.com/en/site/boards\n[旭日X3派]: https://developer.horizon.ai/api/v1/fileData/documents_pi/index.html\n[爱芯派]: https://wiki.sipeed.com/hardware/zh/maixIII/ax-pi/axpi.html\n[hf-space-speaker-diarization]: https://huggingface.co/spaces/k2-fsa/speaker-diarization\n[hf-space-asr]: https://huggingface.co/spaces/k2-fsa/automatic-speech-recognition\n[Whisper]: https://github.com/openai/whisper\n[hf-space-asr-whisper]: https://huggingface.co/spaces/k2-fsa/automatic-speech-recognition-with-whisper\n[hf-space-tts]: https://huggingface.co/spaces/k2-fsa/text-to-speech\n[hf-space-subtitle]: https://huggingface.co/spaces/k2-fsa/generate-subtitles-for-videos\n[hf-space-audio-tagging]: https://huggingface.co/spaces/k2-fsa/audio-tagging\n[hf-space-slid-whisper]: https://huggingface.co/spaces/k2-fsa/spoken-language-identification\n[wasm-hf-vad]: https://huggingface.co/spaces/k2-fsa/web-assembly-vad-sherpa-onnx\n[wasm-ms-vad]: https://modelscope.cn/studios/csukuangfj/web-assembly-vad-sherpa-onnx\n[wasm-hf-streaming-asr-zh-en-zipformer]: https://huggingface.co/spaces/k2-fsa/web-assembly-asr-sherpa-onnx-zh-en\n[wasm-ms-streaming-asr-zh-en-zipformer]: https://modelscope.cn/studios/k2-fsa/web-assembly-asr-sherpa-onnx-zh-en\n[wasm-hf-streaming-asr-zh-en-paraformer]: https://huggingface.co/spaces/k2-fsa/web-assembly-asr-sherpa-onnx-zh-en-paraformer\n[wasm-ms-streaming-asr-zh-en-paraformer]: https://modelscope.cn/studios/k2-fsa/web-assembly-asr-sherpa-onnx-zh-en-paraformer\n[Paraformer-large]: https://www.modelscope.cn/models/damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch/summary\n[wasm-hf-streaming-asr-zh-en-yue-paraformer]: https://huggingface.co/spaces/k2-fsa/web-assembly-asr-sherpa-onnx-zh-cantonese-en-paraformer\n[wasm-ms-streaming-asr-zh-en-yue-paraformer]: https://modelscope.cn/studios/k2-fsa/web-assembly-asr-sherpa-onnx-zh-cantonese-en-paraformer\n[wasm-hf-streaming-asr-en-zipformer]: https://huggingface.co/spaces/k2-fsa/web-assembly-asr-sherpa-onnx-en\n[wasm-ms-streaming-asr-en-zipformer]: https://modelscope.cn/studios/k2-fsa/web-assembly-asr-sherpa-onnx-en\n[SenseVoice]: https://github.com/FunAudioLLM/SenseVoice\n[wasm-hf-vad-asr-zh-en-ko-ja-yue-sense-voice]: https://huggingface.co/spaces/k2-fsa/web-assembly-vad-asr-sherpa-onnx-zh-en-ja-ko-cantonese-sense-voice\n[wasm-ms-vad-asr-zh-en-ko-ja-yue-sense-voice]: https://www.modelscope.cn/studios/csukuangfj/web-assembly-vad-asr-sherpa-onnx-zh-en-jp-ko-cantonese-sense-voice\n[wasm-hf-vad-asr-en-whisper-tiny-en]: https://huggingface.co/spaces/k2-fsa/web-assembly-vad-asr-sherpa-onnx-en-whisper-tiny\n[wasm-ms-vad-asr-en-whisper-tiny-en]: https://www.modelscope.cn/studios/csukuangfj/web-assembly-vad-asr-sherpa-onnx-en-whisper-tiny\n[wasm-hf-vad-asr-en-moonshine-tiny-en]: https://huggingface.co/spaces/k2-fsa/web-assembly-vad-asr-sherpa-onnx-en-moonshine-tiny\n[wasm-ms-vad-asr-en-moonshine-tiny-en]: https://www.modelscope.cn/studios/csukuangfj/web-assembly-vad-asr-sherpa-onnx-en-moonshine-tiny\n[wasm-hf-vad-asr-en-zipformer-gigaspeech]: https://huggingface.co/spaces/k2-fsa/web-assembly-vad-asr-sherpa-onnx-en-zipformer-gigaspeech\n[wasm-ms-vad-asr-en-zipformer-gigaspeech]: https://www.modelscope.cn/studios/k2-fsa/web-assembly-vad-asr-sherpa-onnx-en-zipformer-gigaspeech\n[wasm-hf-vad-asr-zh-zipformer-wenetspeech]: https://huggingface.co/spaces/k2-fsa/web-assembly-vad-asr-sherpa-onnx-zh-zipformer-wenetspeech\n[wasm-ms-vad-asr-zh-zipformer-wenetspeech]: https://www.modelscope.cn/studios/k2-fsa/web-assembly-vad-asr-sherpa-onnx-zh-zipformer-wenetspeech\n[ReazonSpeech]: https://research.reazon.jp/_static/reazonspeech_nlp2023.pdf\n[wasm-hf-vad-asr-ja-zipformer-reazonspeech]: https://huggingface.co/spaces/k2-fsa/web-assembly-vad-asr-sherpa-onnx-ja-zipformer\n[wasm-ms-vad-asr-ja-zipformer-reazonspeech]: https://www.modelscope.cn/studios/csukuangfj/web-assembly-vad-asr-sherpa-onnx-ja-zipformer\n[GigaSpeech2]: https://github.com/SpeechColab/GigaSpeech2\n[wasm-hf-vad-asr-th-zipformer-gigaspeech2]: https://huggingface.co/spaces/k2-fsa/web-assembly-vad-asr-sherpa-onnx-th-zipformer\n[wasm-ms-vad-asr-th-zipformer-gigaspeech2]: https://www.modelscope.cn/studios/csukuangfj/web-assembly-vad-asr-sherpa-onnx-th-zipformer\n[TeleSpeech-ASR]: https://github.com/Tele-AI/TeleSpeech-ASR\n[wasm-hf-vad-asr-zh-telespeech]: https://huggingface.co/spaces/k2-fsa/web-assembly-vad-asr-sherpa-onnx-zh-telespeech\n[wasm-ms-vad-asr-zh-telespeech]: https://www.modelscope.cn/studios/k2-fsa/web-assembly-vad-asr-sherpa-onnx-zh-telespeech\n[wasm-hf-vad-asr-zh-en-paraformer-large]: https://huggingface.co/spaces/k2-fsa/web-assembly-vad-asr-sherpa-onnx-zh-en-paraformer\n[wasm-ms-vad-asr-zh-en-paraformer-large]: https://www.modelscope.cn/studios/k2-fsa/web-assembly-vad-asr-sherpa-onnx-zh-en-paraformer\n[wasm-hf-vad-asr-zh-en-paraformer-small]: https://huggingface.co/spaces/k2-fsa/web-assembly-vad-asr-sherpa-onnx-zh-en-paraformer-small\n[wasm-ms-vad-asr-zh-en-paraformer-small]: https://www.modelscope.cn/studios/k2-fsa/web-assembly-vad-asr-sherpa-onnx-zh-en-paraformer-small\n[wasm-hf-tts-piper-en]: https://huggingface.co/spaces/k2-fsa/web-assembly-tts-sherpa-onnx-en\n[wasm-ms-tts-piper-en]: https://modelscope.cn/studios/k2-fsa/web-assembly-tts-sherpa-onnx-en\n[wasm-hf-tts-piper-de]: https://huggingface.co/spaces/k2-fsa/web-assembly-tts-sherpa-onnx-de\n[wasm-ms-tts-piper-de]: https://modelscope.cn/studios/k2-fsa/web-assembly-tts-sherpa-onnx-de\n[wasm-hf-speaker-diarization]: https://huggingface.co/spaces/k2-fsa/web-assembly-speaker-diarization-sherpa-onnx\n[wasm-ms-speaker-diarization]: https://www.modelscope.cn/studios/csukuangfj/web-assembly-speaker-diarization-sherpa-onnx\n[apk-speaker-diarization]: https://k2-fsa.github.io/sherpa/onnx/speaker-diarization/apk.html\n[apk-speaker-diarization-cn]: https://k2-fsa.github.io/sherpa/onnx/speaker-diarization/apk-cn.html\n[apk-streaming-asr]: https://k2-fsa.github.io/sherpa/onnx/android/apk.html\n[apk-streaming-asr-cn]: https://k2-fsa.github.io/sherpa/onnx/android/apk-cn.html\n[apk-tts]: https://k2-fsa.github.io/sherpa/onnx/tts/apk-engine.html\n[apk-tts-cn]: https://k2-fsa.github.io/sherpa/onnx/tts/apk-engine-cn.html\n[apk-vad]: https://k2-fsa.github.io/sherpa/onnx/vad/apk.html\n[apk-vad-cn]: https://k2-fsa.github.io/sherpa/onnx/vad/apk-cn.html\n[apk-vad-asr]: https://k2-fsa.github.io/sherpa/onnx/vad/apk-asr.html\n[apk-vad-asr-cn]: https://k2-fsa.github.io/sherpa/onnx/vad/apk-asr-cn.html\n[apk-2pass]: https://k2-fsa.github.io/sherpa/onnx/android/apk-2pass.html\n[apk-2pass-cn]: https://k2-fsa.github.io/sherpa/onnx/android/apk-2pass-cn.html\n[apk-at]: https://k2-fsa.github.io/sherpa/onnx/audio-tagging/apk.html\n[apk-at-cn]: https://k2-fsa.github.io/sherpa/onnx/audio-tagging/apk-cn.html\n[apk-at-wearos]: https://k2-fsa.github.io/sherpa/onnx/audio-tagging/apk-wearos.html\n[apk-at-wearos-cn]: https://k2-fsa.github.io/sherpa/onnx/audio-tagging/apk-wearos-cn.html\n[apk-sid]: https://k2-fsa.github.io/sherpa/onnx/speaker-identification/apk.html\n[apk-sid-cn]: https://k2-fsa.github.io/sherpa/onnx/speaker-identification/apk-cn.html\n[apk-slid]: https://k2-fsa.github.io/sherpa/onnx/spoken-language-identification/apk.html\n[apk-slid-cn]: https://k2-fsa.github.io/sherpa/onnx/spoken-language-identification/apk-cn.html\n[apk-kws]: https://k2-fsa.github.io/sherpa/onnx/kws/apk.html\n[apk-kws-cn]: https://k2-fsa.github.io/sherpa/onnx/kws/apk-cn.html\n[apk-flutter-streaming-asr]: https://k2-fsa.github.io/sherpa/onnx/flutter/asr/app.html\n[apk-flutter-streaming-asr-cn]: https://k2-fsa.github.io/sherpa/onnx/flutter/asr/app-cn.html\n[flutter-tts-android]: https://k2-fsa.github.io/sherpa/onnx/flutter/tts-android.html\n[flutter-tts-android-cn]: https://k2-fsa.github.io/sherpa/onnx/flutter/tts-android-cn.html\n[flutter-tts-linux]: https://k2-fsa.github.io/sherpa/onnx/flutter/tts-linux.html\n[flutter-tts-linux-cn]: https://k2-fsa.github.io/sherpa/onnx/flutter/tts-linux-cn.html\n[flutter-tts-macos-x64]: https://k2-fsa.github.io/sherpa/onnx/flutter/tts-macos-x64.html\n[flutter-tts-macos-arm64-cn]: https://k2-fsa.github.io/sherpa/onnx/flutter/tts-macos-x64-cn.html\n[flutter-tts-macos-arm64]: https://k2-fsa.github.io/sherpa/onnx/flutter/tts-macos-arm64.html\n[flutter-tts-macos-x64-cn]: https://k2-fsa.github.io/sherpa/onnx/flutter/tts-macos-arm64-cn.html\n[flutter-tts-win-x64]: https://k2-fsa.github.io/sherpa/onnx/flutter/tts-win.html\n[flutter-tts-win-x64-cn]: https://k2-fsa.github.io/sherpa/onnx/flutter/tts-win-cn.html\n[lazarus-subtitle]: https://k2-fsa.github.io/sherpa/onnx/lazarus/download-generated-subtitles.html\n[lazarus-subtitle-cn]: https://k2-fsa.github.io/sherpa/onnx/lazarus/download-generated-subtitles-cn.html\n[asr-models]: https://github.com/k2-fsa/sherpa-onnx/releases/tag/asr-models\n[tts-models]: https://github.com/k2-fsa/sherpa-onnx/releases/tag/tts-models\n[vad-models]: https://github.com/k2-fsa/sherpa-onnx/releases/download/asr-models/silero_vad.onnx\n[kws-models]: https://github.com/k2-fsa/sherpa-onnx/releases/tag/kws-models\n[at-models]: https://github.com/k2-fsa/sherpa-onnx/releases/tag/audio-tagging-models\n[sid-models]: https://github.com/k2-fsa/sherpa-onnx/releases/tag/speaker-recongition-models\n[slid-models]: https://github.com/k2-fsa/sherpa-onnx/releases/tag/speaker-recongition-models\n[punct-models]: https://github.com/k2-fsa/sherpa-onnx/releases/tag/punctuation-models\n[speaker-segmentation-models]: https://github.com/k2-fsa/sherpa-onnx/releases/tag/speaker-segmentation-models\n[GigaSpeech]: https://github.com/SpeechColab/GigaSpeech\n[WenetSpeech]: https://github.com/wenet-e2e/WenetSpeech\n[sherpa-onnx-streaming-zipformer-bilingual-zh-en-2023-02-20]: https://github.com/k2-fsa/sherpa-onnx/releases/download/asr-models/sherpa-onnx-streaming-zipformer-bilingual-zh-en-2023-02-20.tar.bz2\n[sherpa-onnx-streaming-zipformer-small-bilingual-zh-en-2023-02-16]: https://github.com/k2-fsa/sherpa-onnx/releases/download/asr-models/sherpa-onnx-streaming-zipformer-small-bilingual-zh-en-2023-02-16.tar.bz2\n[sherpa-onnx-streaming-zipformer-korean-2024-06-16]: https://github.com/k2-fsa/sherpa-onnx/releases/download/asr-models/sherpa-onnx-streaming-zipformer-korean-2024-06-16.tar.bz2\n[sherpa-onnx-streaming-zipformer-zh-14M-2023-02-23]: https://github.com/k2-fsa/sherpa-onnx/releases/download/asr-models/sherpa-onnx-streaming-zipformer-zh-14M-2023-02-23.tar.bz2\n[sherpa-onnx-streaming-zipformer-en-20M-2023-02-17]: https://github.com/k2-fsa/sherpa-onnx/releases/download/asr-models/sherpa-onnx-streaming-zipformer-en-20M-2023-02-17.tar.bz2\n[sherpa-onnx-zipformer-ja-reazonspeech-2024-08-01]: https://github.com/k2-fsa/sherpa-onnx/releases/download/asr-models/sherpa-onnx-zipformer-ja-reazonspeech-2024-08-01.tar.bz2\n[sherpa-onnx-zipformer-ru-2024-09-18]: https://github.com/k2-fsa/sherpa-onnx/releases/download/asr-models/sherpa-onnx-zipformer-ru-2024-09-18.tar.bz2\n[sherpa-onnx-zipformer-korean-2024-06-24]: https://github.com/k2-fsa/sherpa-onnx/releases/download/asr-models/sherpa-onnx-zipformer-korean-2024-06-24.tar.bz2\n[sherpa-onnx-zipformer-thai-2024-06-20]: https://github.com/k2-fsa/sherpa-onnx/releases/download/asr-models/sherpa-onnx-zipformer-thai-2024-06-20.tar.bz2\n[sherpa-onnx-nemo-transducer-giga-am-russian-2024-10-24]: https://github.com/k2-fsa/sherpa-onnx/releases/download/asr-models/sherpa-onnx-nemo-transducer-giga-am-russian-2024-10-24.tar.bz2\n[sherpa-onnx-paraformer-zh-2024-03-09]: https://github.com/k2-fsa/sherpa-onnx/releases/download/asr-models/sherpa-onnx-paraformer-zh-2024-03-09.tar.bz2\n[sherpa-onnx-nemo-ctc-giga-am-russian-2024-10-24]: https://github.com/k2-fsa/sherpa-onnx/releases/download/asr-models/sherpa-onnx-nemo-ctc-giga-am-russian-2024-10-24.tar.bz2\n[sherpa-onnx-telespeech-ctc-int8-zh-2024-06-04]: https://github.com/k2-fsa/sherpa-onnx/releases/download/asr-models/sherpa-onnx-telespeech-ctc-int8-zh-2024-06-04.tar.bz2\n[sherpa-onnx-sense-voice-zh-en-ja-ko-yue-2024-07-17]: https://github.com/k2-fsa/sherpa-onnx/releases/download/asr-models/sherpa-onnx-sense-voice-zh-en-ja-ko-yue-2024-07-17.tar.bz2\n[sherpa-onnx-streaming-zipformer-fr-2023-04-14]: https://github.com/k2-fsa/sherpa-onnx/releases/download/asr-models/sherpa-onnx-streaming-zipformer-fr-2023-04-14.tar.bz2\n[Moonshine tiny]: https://github.com/k2-fsa/sherpa-onnx/releases/download/asr-models/sherpa-onnx-moonshine-tiny-en-int8.tar.bz2\n[NVIDIA Jetson Orin NX]: https://developer.download.nvidia.com/assets/embedded/secure/jetson/orin_nx/docs/Jetson_Orin_NX_DS-10712-001_v0.5.pdf?RCPGu9Q6OVAOv7a7vgtwc9-BLScXRIWq6cSLuditMALECJ_dOj27DgnqAPGVnT2VpiNpQan9SyFy-9zRykR58CokzbXwjSA7Gj819e91AXPrWkGZR3oS1VLxiDEpJa_Y0lr7UT-N4GnXtb8NlUkP4GkCkkF_FQivGPrAucCUywL481GH_WpP_p7ziHU1Wg==&t=eyJscyI6ImdzZW8iLCJsc2QiOiJodHRwczovL3d3dy5nb29nbGUuY29tLmhrLyJ9\n[NVIDIA Jetson Nano B01]: https://www.seeedstudio.com/blog/2020/01/16/new-revision-of-jetson-nano-dev-kit-now-supports-new-jetson-nano-module/\n"
        },
        {
          "name": "android",
          "type": "tree",
          "content": null
        },
        {
          "name": "build-aarch64-linux-gnu.sh",
          "type": "blob",
          "size": 3.078125,
          "content": "#!/usr/bin/env bash\n#\n# Usage of this file\n#\n# (1) Build CPU version of sherpa-onnx\n#    ./build-aarch64-linux-gnu.sh\n#\n# (2) Build GPU version of sherpa-onnx\n#\n#   (a) Make sure your board has NVIDIA GPU(s)\n#\n#   (b) For Jetson Nano B01 (using CUDA 10.2)\n#\n#       export SHERPA_ONNX_ENABLE_GPU=ON\n#       export SHERPA_ONNX_LINUX_ARM64_GPU_ONNXRUNTIME_VERSION=1.11.0\n#       ./build-aarch64-linux-gnu.sh\n#\n#   (c) For Jetson Orin NX (using CUDA 11.4)\n#\n#       export SHERPA_ONNX_ENABLE_GPU=ON\n#       export SHERPA_ONNX_LINUX_ARM64_GPU_ONNXRUNTIME_VERSION=1.16.0\n#       ./build-aarch64-linux-gnu.sh\n\nif command -v aarch64-none-linux-gnu-gcc  &> /dev/null; then\n  ln -svf $(which aarch64-none-linux-gnu-gcc) ./aarch64-linux-gnu-gcc\n  ln -svf $(which aarch64-none-linux-gnu-g++) ./aarch64-linux-gnu-g++\n  export PATH=$PWD:$PATH\nfi\n\nif ! command -v aarch64-linux-gnu-gcc  &> /dev/null; then\n  echo \"Please install a toolchain for cross-compiling.\"\n  echo \"You can refer to: \"\n  echo \"  https://k2-fsa.github.io/sherpa/onnx/install/aarch64-embedded-linux.html\"\n  echo \"for help.\"\n  exit 1\nfi\n\nset -ex\n\ndir=build-aarch64-linux-gnu\nmkdir -p $dir\ncd $dir\n\nif [ ! -f alsa-lib/src/.libs/libasound.so ]; then\n  echo \"Start to cross-compile alsa-lib\"\n  if [ ! -d alsa-lib ]; then\n    git clone --depth 1 --branch v1.2.12 https://github.com/alsa-project/alsa-lib\n  fi\n  # If it shows:\n  #  ./gitcompile: line 79: libtoolize: command not found\n  # Please use:\n  #  sudo apt-get install libtool m4 automake\n  #\n  pushd alsa-lib\n  CC=aarch64-linux-gnu-gcc ./gitcompile --host=aarch64-linux-gnu\n  popd\n  echo \"Finish cross-compiling alsa-lib\"\nfi\n\nexport CPLUS_INCLUDE_PATH=$PWD/alsa-lib/include:$CPLUS_INCLUDE_PATH\nexport SHERPA_ONNX_ALSA_LIB_DIR=$PWD/alsa-lib/src/.libs\n\nif [[ x\"$BUILD_SHARED_LIBS\" == x\"\" ]]; then\n  # By default, use static link\n  BUILD_SHARED_LIBS=OFF\nfi\n\nif [[ x\"$SHERPA_ONNX_ENABLE_GPU\" == x\"\" ]]; then\n  # By default, use CPU\n  SHERPA_ONNX_ENABLE_GPU=OFF\nfi\n\nif [[ x\"$SHERPA_ONNX_ENABLE_GPU\" == x\"ON\" ]]; then\n  # Build shared libs if building GPU is enabled.\n  BUILD_SHARED_LIBS=ON\nfi\n\nif [[ x\"$SHERPA_ONNX_LINUX_ARM64_GPU_ONNXRUNTIME_VERSION\" == x\"\" ]]; then\n  # Used only when SHERPA_ONNX_ENABLE_GPU is ON\n  SHERPA_ONNX_LINUX_ARM64_GPU_ONNXRUNTIME_VERSION=\"1.11.0\"\nfi\n\ncmake \\\n  -DBUILD_PIPER_PHONMIZE_EXE=OFF \\\n  -DBUILD_PIPER_PHONMIZE_TESTS=OFF \\\n  -DBUILD_ESPEAK_NG_EXE=OFF \\\n  -DBUILD_ESPEAK_NG_TESTS=OFF \\\n  -DCMAKE_INSTALL_PREFIX=./install \\\n  -DCMAKE_BUILD_TYPE=Release \\\n  -DSHERPA_ONNX_ENABLE_GPU=$SHERPA_ONNX_ENABLE_GPU \\\n  -DBUILD_SHARED_LIBS=$BUILD_SHARED_LIBS \\\n  -DSHERPA_ONNX_ENABLE_TESTS=OFF \\\n  -DSHERPA_ONNX_ENABLE_PYTHON=OFF \\\n  -DSHERPA_ONNX_ENABLE_CHECK=OFF \\\n  -DSHERPA_ONNX_ENABLE_PORTAUDIO=OFF \\\n  -DSHERPA_ONNX_ENABLE_JNI=OFF \\\n  -DSHERPA_ONNX_ENABLE_C_API=ON \\\n  -DSHERPA_ONNX_ENABLE_WEBSOCKET=ON \\\n  -DSHERPA_ONNX_LINUX_ARM64_GPU_ONNXRUNTIME_VERSION=$SHERPA_ONNX_LINUX_ARM64_GPU_ONNXRUNTIME_VERSION \\\n  -DCMAKE_TOOLCHAIN_FILE=../toolchains/aarch64-linux-gnu.toolchain.cmake \\\n  ..\n\nmake VERBOSE=1 -j4\nmake install/strip\n\n# Enable it if only needed\n# cp -v $SHERPA_ONNX_ALSA_LIB_DIR/libasound.so* ./install/lib/\n"
        },
        {
          "name": "build-android-arm64-v8a.sh",
          "type": "blob",
          "size": 6.1533203125,
          "content": "#!/usr/bin/env bash\nset -ex\n\n# If BUILD_SHARED_LIBS is ON, we use libonnxruntime.so\n# If BUILD_SHARED_LIBS is OFF, we use libonnxruntime.a\n#\n# In any case, we will have libsherpa-onnx-jni.so\n#\n# If BUILD_SHARED_LIBS is OFF, then libonnxruntime.a is linked into libsherpa-onnx-jni.so\n# and you only need to copy libsherpa-onnx-jni.so to your Android projects.\n#\n# If BUILD_SHARED_LIBS is ON, then you need to copy both libsherpa-onnx-jni.so\n# and libonnxruntime.so to your Android projects\n#\nif [ -z $BUILD_SHARED_LIBS ]; then\n  BUILD_SHARED_LIBS=ON\nfi\n\nif [ $BUILD_SHARED_LIBS == ON ]; then\n  dir=$PWD/build-android-arm64-v8a\nelse\n  dir=$PWD/build-android-arm64-v8a-static\nfi\n\nmkdir -p $dir\ncd $dir\n\n# Note from https://github.com/Tencent/ncnn/wiki/how-to-build#build-for-android\n# (optional) remove the hardcoded debug flag in Android NDK android-ndk\n# issue: https://github.com/android/ndk/issues/243\n#\n# open $ANDROID_NDK/build/cmake/android.toolchain.cmake for ndk < r23\n# or $ANDROID_NDK/build/cmake/android-legacy.toolchain.cmake for ndk >= r23\n#\n# delete \"-g\" line\n#\n# list(APPEND ANDROID_COMPILER_FLAGS\n#   -g\n#   -DANDROID\n\nif [ -z $ANDROID_NDK ]; then\n  ANDROID_NDK=/star-fj/fangjun/software/android-sdk/ndk/22.1.7171670\n  if [ $BUILD_SHARED_LIBS == OFF ]; then\n    ANDROID_NDK=/star-fj/fangjun/software/android-sdk/ndk/27.0.11718014\n  fi\n  # or use\n  # ANDROID_NDK=/star-fj/fangjun/software/android-ndk\n  #\n  # Inside the $ANDROID_NDK directory, you can find a binary ndk-build\n  # and some other files like the file \"build/cmake/android.toolchain.cmake\"\n\n  if [ ! -d $ANDROID_NDK ]; then\n    # For macOS, I have installed Android Studio, select the menu\n    # Tools -> SDK manager -> Android SDK\n    # and set \"Android SDK location\" to /Users/fangjun/software/my-android\n    ANDROID_NDK=/Users/fangjun/software/my-android/ndk/22.1.7171670\n\n    if [ $BUILD_SHARED_LIBS == OFF ]; then\n      ANDROID_NDK=/Users/fangjun/software/my-android/ndk/27.0.11718014\n    fi\n  fi\nfi\n\nif [ ! -d $ANDROID_NDK ]; then\n  echo Please set the environment variable ANDROID_NDK before you run this script\n  exit 1\nfi\n\necho \"ANDROID_NDK: $ANDROID_NDK\"\nsleep 1\nonnxruntime_version=1.17.1\n\nif [ $BUILD_SHARED_LIBS == ON ]; then\n  if [ ! -f $onnxruntime_version/jni/arm64-v8a/libonnxruntime.so ]; then\n    mkdir -p $onnxruntime_version\n    pushd $onnxruntime_version\n    wget -c -q https://github.com/csukuangfj/onnxruntime-libs/releases/download/v${onnxruntime_version}/onnxruntime-android-${onnxruntime_version}.zip\n    unzip onnxruntime-android-${onnxruntime_version}.zip\n    rm onnxruntime-android-${onnxruntime_version}.zip\n    popd\n  fi\n\n  export SHERPA_ONNXRUNTIME_LIB_DIR=$dir/$onnxruntime_version/jni/arm64-v8a/\n  export SHERPA_ONNXRUNTIME_INCLUDE_DIR=$dir/$onnxruntime_version/headers/\nelse\n  if [ ! -f ${onnxruntime_version}-static/lib/libonnxruntime.a ]; then\n    wget -c -q https://github.com/csukuangfj/onnxruntime-libs/releases/download/v${onnxruntime_version}/onnxruntime-android-arm64-v8a-static_lib-${onnxruntime_version}.zip\n    unzip onnxruntime-android-arm64-v8a-static_lib-${onnxruntime_version}.zip\n    rm onnxruntime-android-arm64-v8a-static_lib-${onnxruntime_version}.zip\n    mv onnxruntime-android-arm64-v8a-static_lib-${onnxruntime_version} ${onnxruntime_version}-static\n  fi\n\n  export SHERPA_ONNXRUNTIME_LIB_DIR=$dir/$onnxruntime_version-static/lib/\n  export SHERPA_ONNXRUNTIME_INCLUDE_DIR=$dir/$onnxruntime_version-static/include/\nfi\n\necho \"SHERPA_ONNXRUNTIME_LIB_DIR: $SHERPA_ONNXRUNTIME_LIB_DIR\"\necho \"SHERPA_ONNXRUNTIME_INCLUDE_DIR $SHERPA_ONNXRUNTIME_INCLUDE_DIR\"\n\nif [ -z $SHERPA_ONNX_ENABLE_TTS ]; then\n  SHERPA_ONNX_ENABLE_TTS=ON\nfi\n\nif [ -z $SHERPA_ONNX_ENABLE_SPEAKER_DIARIZATION ]; then\n  SHERPA_ONNX_ENABLE_SPEAKER_DIARIZATION=ON\nfi\n\nif [ -z $SHERPA_ONNX_ENABLE_BINARY ]; then\n  SHERPA_ONNX_ENABLE_BINARY=OFF\nfi\n\nif [ -z $SHERPA_ONNX_ENABLE_C_API ]; then\n  SHERPA_ONNX_ENABLE_C_API=OFF\nfi\n\nif [ -z $SHERPA_ONNX_ENABLE_JNI ]; then\n  SHERPA_ONNX_ENABLE_JNI=ON\nfi\n\ncmake -DCMAKE_TOOLCHAIN_FILE=\"$ANDROID_NDK/build/cmake/android.toolchain.cmake\" \\\n    -DSHERPA_ONNX_ENABLE_TTS=$SHERPA_ONNX_ENABLE_TTS \\\n    -DSHERPA_ONNX_ENABLE_SPEAKER_DIARIZATION=$SHERPA_ONNX_ENABLE_SPEAKER_DIARIZATION \\\n    -DSHERPA_ONNX_ENABLE_BINARY=$SHERPA_ONNX_ENABLE_BINARY \\\n    -DBUILD_PIPER_PHONMIZE_EXE=OFF \\\n    -DBUILD_PIPER_PHONMIZE_TESTS=OFF \\\n    -DBUILD_ESPEAK_NG_EXE=OFF \\\n    -DBUILD_ESPEAK_NG_TESTS=OFF \\\n    -DCMAKE_BUILD_TYPE=Release \\\n    -DBUILD_SHARED_LIBS=$BUILD_SHARED_LIBS \\\n    -DSHERPA_ONNX_ENABLE_PYTHON=OFF \\\n    -DSHERPA_ONNX_ENABLE_TESTS=OFF \\\n    -DSHERPA_ONNX_ENABLE_CHECK=OFF \\\n    -DSHERPA_ONNX_ENABLE_PORTAUDIO=OFF \\\n    -DSHERPA_ONNX_ENABLE_JNI=$SHERPA_ONNX_ENABLE_JNI \\\n    -DSHERPA_ONNX_LINK_LIBSTDCPP_STATICALLY=OFF \\\n    -DSHERPA_ONNX_ENABLE_C_API=$SHERPA_ONNX_ENABLE_C_API \\\n    -DCMAKE_INSTALL_PREFIX=./install \\\n    -DANDROID_ABI=\"arm64-v8a\" \\\n    -DANDROID_PLATFORM=android-21 ..\n\n    # By default, it links to libc++_static.a\n    # -DANDROID_STL=c++_shared \\\n\n# Please use -DANDROID_PLATFORM=android-27 if you want to use Android NNAPI\n\n# make VERBOSE=1 -j4\nmake -j4\nmake install/strip\ncp -fv $onnxruntime_version/jni/arm64-v8a/libonnxruntime.so install/lib 2>/dev/null || true\nrm -rf install/share\nrm -rf install/lib/pkgconfig\nrm -rf install/lib/lib*.a\nif [ -f install/lib/libsherpa-onnx-c-api.so ]; then\n  cat >install/lib/README.md <<EOF\n# Introduction\n\nNote that if you use Android Studio, then you only need to\ncopy libonnxruntime.so and libsherpa-onnx-jni.so\nto your jniLibs, and you don't need libsherpa-onnx-c-api.so or\nlibsherpa-onnx-cxx-api.so.\n\nlibsherpa-onnx-c-api.so and libsherpa-onnx-cxx-api.so are for users\nwho don't use JNI. In that case, libsherpa-onnx-jni.so is not needed.\n\nIn any case, libonnxruntime.is is always needed.\nEOF\n  ls -lh install/lib/README.md\nfi\n\n# To run the generated binaries on Android, please use the following steps.\n#\n#\n# 1. Copy sherpa-onnx and its dependencies to Android\n#\n#   cd build-android-arm64-v8a/install/lib\n#   adb push ./lib*.so /data/local/tmp\n#   cd ../bin\n#   adb push ./sherpa-onnx /data/local/tmp\n#\n# 2. Login into Android\n#\n#   adb shell\n#   cd /data/local/tmp\n#   ./sherpa-onnx\n#\n# It should show the help message of sherpa-onnx.\n#\n# Please use the above approach to copy model files to your phone.\n"
        },
        {
          "name": "build-android-armv7-eabi.sh",
          "type": "blob",
          "size": 5.650390625,
          "content": "#!/usr/bin/env bash\nset -ex\n\n# If BUILD_SHARED_LIBS is ON, we use libonnxruntime.so\n# If BUILD_SHARED_LIBS is OFF, we use libonnxruntime.a\n#\n# In any case, we will have libsherpa-onnx-jni.so\n#\n# If BUILD_SHARED_LIBS is OFF, then libonnxruntime.a is linked into libsherpa-onnx-jni.so\n# and you only need to copy libsherpa-onnx-jni.so to your Android projects.\n#\n# If BUILD_SHARED_LIBS is ON, then you need to copy both libsherpa-onnx-jni.so\n# and libonnxruntime.so to your Android projects\n#\nif [ -z $BUILD_SHARED_LIBS ]; then\n  BUILD_SHARED_LIBS=ON\nfi\n\nif [ $BUILD_SHARED_LIBS == ON ]; then\n  dir=$PWD/build-android-armv7-eabi\nelse\n  dir=$PWD/build-android-armv7-eabi-static\nfi\n\nmkdir -p $dir\ncd $dir\n\n# Note from https://github.com/Tencent/ncnn/wiki/how-to-build#build-for-android\n# (optional) remove the hardcoded debug flag in Android NDK android-ndk\n# issue: https://github.com/android/ndk/issues/243\n#\n# open $ANDROID_NDK/build/cmake/android.toolchain.cmake for ndk < r23\n# or $ANDROID_NDK/build/cmake/android-legacy.toolchain.cmake for ndk >= r23\n#\n# delete \"-g\" line\n#\n# list(APPEND ANDROID_COMPILER_FLAGS\n#   -g\n#   -DANDROID\n\nif [ -z $ANDROID_NDK ]; then\n  ANDROID_NDK=/star-fj/fangjun/software/android-sdk/ndk/22.1.7171670\n  if [ $BUILD_SHARED_LIBS == OFF ]; then\n    ANDROID_NDK=/star-fj/fangjun/software/android-sdk/ndk/27.0.11718014\n  fi\n  # or use\n  # ANDROID_NDK=/star-fj/fangjun/software/android-ndk\n  #\n  # Inside the $ANDROID_NDK directory, you can find a binary ndk-build\n  # and some other files like the file \"build/cmake/android.toolchain.cmake\"\n\n  if [ ! -d $ANDROID_NDK ]; then\n    # For macOS, I have installed Android Studio, select the menu\n    # Tools -> SDK manager -> Android SDK\n    # and set \"Android SDK location\" to /Users/fangjun/software/my-android\n    ANDROID_NDK=/Users/fangjun/software/my-android/ndk/22.1.7171670\n\n    if [ $BUILD_SHARED_LIBS == OFF ]; then\n      ANDROID_NDK=/Users/fangjun/software/my-android/ndk/27.0.11718014\n    fi\n  fi\nfi\n\nif [ ! -d $ANDROID_NDK ]; then\n  echo Please set the environment variable ANDROID_NDK before you run this script\n  exit 1\nfi\n\necho \"ANDROID_NDK: $ANDROID_NDK\"\nsleep 1\n\nonnxruntime_version=1.17.1\n\nif [ $BUILD_SHARED_LIBS == ON ]; then\n  if [ ! -f $onnxruntime_version/jni/armeabi-v7a/libonnxruntime.so ]; then\n    mkdir -p $onnxruntime_version\n    pushd $onnxruntime_version\n    wget -c -q https://github.com/csukuangfj/onnxruntime-libs/releases/download/v${onnxruntime_version}/onnxruntime-android-${onnxruntime_version}.zip\n    unzip onnxruntime-android-${onnxruntime_version}.zip\n    rm onnxruntime-android-${onnxruntime_version}.zip\n    popd\n  fi\n\n  export SHERPA_ONNXRUNTIME_LIB_DIR=$dir/$onnxruntime_version/jni/armeabi-v7a/\n  export SHERPA_ONNXRUNTIME_INCLUDE_DIR=$dir/$onnxruntime_version/headers/\nelse\n  if [ ! -f ${onnxruntime_version}-static/lib/libonnxruntime.a ]; then\n    wget -c -q https://github.com/csukuangfj/onnxruntime-libs/releases/download/v${onnxruntime_version}/onnxruntime-android-armeabi-v7a-static_lib-${onnxruntime_version}.zip\n    unzip onnxruntime-android-armeabi-v7a-static_lib-${onnxruntime_version}.zip\n    rm onnxruntime-android-armeabi-v7a-static_lib-${onnxruntime_version}.zip\n    mv onnxruntime-android-armeabi-v7a-static_lib-${onnxruntime_version} ${onnxruntime_version}-static\n  fi\n\n  export SHERPA_ONNXRUNTIME_LIB_DIR=$dir/$onnxruntime_version-static/lib/\n  export SHERPA_ONNXRUNTIME_INCLUDE_DIR=$dir/$onnxruntime_version-static/include/\nfi\n\necho \"SHERPA_ONNXRUNTIME_LIB_DIR: $SHERPA_ONNXRUNTIME_LIB_DIR\"\necho \"SHERPA_ONNXRUNTIME_INCLUDE_DIR $SHERPA_ONNXRUNTIME_INCLUDE_DIR\"\n\nif [ -z $SHERPA_ONNX_ENABLE_TTS ]; then\n  SHERPA_ONNX_ENABLE_TTS=ON\nfi\n\nif [ -z $SHERPA_ONNX_ENABLE_SPEAKER_DIARIZATION ]; then\n  SHERPA_ONNX_ENABLE_SPEAKER_DIARIZATION=ON\nfi\n\nif [ -z $SHERPA_ONNX_ENABLE_BINARY ]; then\n  SHERPA_ONNX_ENABLE_BINARY=OFF\nfi\n\nif [ -z $SHERPA_ONNX_ENABLE_C_API ]; then\n  SHERPA_ONNX_ENABLE_C_API=OFF\nfi\n\nif [ -z $SHERPA_ONNX_ENABLE_JNI ]; then\n  SHERPA_ONNX_ENABLE_JNI=ON\nfi\n\ncmake -DCMAKE_TOOLCHAIN_FILE=\"$ANDROID_NDK/build/cmake/android.toolchain.cmake\" \\\n    -DSHERPA_ONNX_ENABLE_TTS=$SHERPA_ONNX_ENABLE_TTS \\\n    -DSHERPA_ONNX_ENABLE_SPEAKER_DIARIZATION=$SHERPA_ONNX_ENABLE_SPEAKER_DIARIZATION \\\n    -DSHERPA_ONNX_ENABLE_BINARY=$SHERPA_ONNX_ENABLE_BINARY \\\n    -DBUILD_PIPER_PHONMIZE_EXE=OFF \\\n    -DBUILD_PIPER_PHONMIZE_TESTS=OFF \\\n    -DBUILD_ESPEAK_NG_EXE=OFF \\\n    -DBUILD_ESPEAK_NG_TESTS=OFF \\\n    -DCMAKE_BUILD_TYPE=Release \\\n    -DBUILD_SHARED_LIBS=$BUILD_SHARED_LIBS \\\n    -DSHERPA_ONNX_ENABLE_PYTHON=OFF \\\n    -DSHERPA_ONNX_ENABLE_TESTS=OFF \\\n    -DSHERPA_ONNX_ENABLE_CHECK=OFF \\\n    -DSHERPA_ONNX_ENABLE_PORTAUDIO=OFF \\\n    -DSHERPA_ONNX_ENABLE_JNI=$SHERPA_ONNX_ENABLE_JNI \\\n    -DSHERPA_ONNX_LINK_LIBSTDCPP_STATICALLY=OFF \\\n    -DSHERPA_ONNX_ENABLE_C_API=$SHERPA_ONNX_ENABLE_C_API \\\n    -DCMAKE_INSTALL_PREFIX=./install \\\n    -DANDROID_ABI=\"armeabi-v7a\" -DANDROID_ARM_NEON=ON \\\n    -DANDROID_PLATFORM=android-21 ..\n\n    # By default, it links to libc++_static.a\n    # -DANDROID_STL=c++_shared \\\n\n# make VERBOSE=1 -j4\nmake -j4\nmake install/strip\ncp -fv $onnxruntime_version/jni/armeabi-v7a/libonnxruntime.so install/lib 2>/dev/null || true\nrm -rf install/share\nrm -rf install/lib/pkgconfig\nrm -rf install/lib/lib*.a\n\nif [ -f install/lib/libsherpa-onnx-c-api.so ]; then\n  cat >install/lib/README.md <<EOF\n# Introduction\n\nNote that if you use Android Studio, then you only need to\ncopy libonnxruntime.so and libsherpa-onnx-jni.so\nto your jniLibs, and you don't need libsherpa-onnx-c-api.so or\nlibsherpa-onnx-cxx-api.so.\n\nlibsherpa-onnx-c-api.so and libsherpa-onnx-cxx-api.so are for users\nwho don't use JNI. In that case, libsherpa-onnx-jni.so is not needed.\n\nIn any case, libonnxruntime.is is always needed.\nEOF\n  ls -lh install/lib/README.md\nfi\n"
        },
        {
          "name": "build-android-x86-64.sh",
          "type": "blob",
          "size": 5.623046875,
          "content": "#!/usr/bin/env bash\nset -ex\n\n# If BUILD_SHARED_LIBS is ON, we use libonnxruntime.so\n# If BUILD_SHARED_LIBS is OFF, we use libonnxruntime.a\n#\n# In any case, we will have libsherpa-onnx-jni.so\n#\n# If BUILD_SHARED_LIBS is OFF, then libonnxruntime.a is linked into libsherpa-onnx-jni.so\n# and you only need to copy libsherpa-onnx-jni.so to your Android projects.\n#\n# If BUILD_SHARED_LIBS is ON, then you need to copy both libsherpa-onnx-jni.so\n# and libonnxruntime.so to your Android projects\n#\nif [ -z $BUILD_SHARED_LIBS ]; then\n  BUILD_SHARED_LIBS=ON\nfi\n\nif [ $BUILD_SHARED_LIBS == ON ]; then\n  dir=$PWD/build-android-x86-64\nelse\n  dir=$PWD/build-android-x86-64-static\nfi\n\nmkdir -p $dir\ncd $dir\n\n# Note from https://github.com/Tencent/ncnn/wiki/how-to-build#build-for-android\n# (optional) remove the hardcoded debug flag in Android NDK android-ndk\n# issue: https://github.com/android/ndk/issues/243\n#\n# open $ANDROID_NDK/build/cmake/android.toolchain.cmake for ndk < r23\n# or $ANDROID_NDK/build/cmake/android-legacy.toolchain.cmake for ndk >= r23\n#\n# delete \"-g\" line\n#\n# list(APPEND ANDROID_COMPILER_FLAGS\n#   -g\n#   -DANDROID\n\nif [ -z $ANDROID_NDK ]; then\n  ANDROID_NDK=/star-fj/fangjun/software/android-sdk/ndk/22.1.7171670\n  if [ $BUILD_SHARED_LIBS == OFF ]; then\n    ANDROID_NDK=/star-fj/fangjun/software/android-sdk/ndk/27.0.11718014\n  fi\n  # or use\n  # ANDROID_NDK=/star-fj/fangjun/software/android-ndk\n  #\n  # Inside the $ANDROID_NDK directory, you can find a binary ndk-build\n  # and some other files like the file \"build/cmake/android.toolchain.cmake\"\n\n  if [ ! -d $ANDROID_NDK ]; then\n    # For macOS, I have installed Android Studio, select the menu\n    # Tools -> SDK manager -> Android SDK\n    # and set \"Android SDK location\" to /Users/fangjun/software/my-android\n    ANDROID_NDK=/Users/fangjun/software/my-android/ndk/22.1.7171670\n\n    if [ $BUILD_SHARED_LIBS == OFF ]; then\n      ANDROID_NDK=/Users/fangjun/software/my-android/ndk/27.0.11718014\n    fi\n  fi\nfi\n\nif [ ! -d $ANDROID_NDK ]; then\n  echo Please set the environment variable ANDROID_NDK before you run this script\n  exit 1\nfi\n\necho \"ANDROID_NDK: $ANDROID_NDK\"\nsleep 1\n\nonnxruntime_version=1.17.1\n\nif [ $BUILD_SHARED_LIBS == ON ]; then\n  if [ ! -f $onnxruntime_version/jni/x86_64/libonnxruntime.so ]; then\n    mkdir -p $onnxruntime_version\n    pushd $onnxruntime_version\n    wget -c -q https://github.com/csukuangfj/onnxruntime-libs/releases/download/v${onnxruntime_version}/onnxruntime-android-${onnxruntime_version}.zip\n    unzip onnxruntime-android-${onnxruntime_version}.zip\n    rm onnxruntime-android-${onnxruntime_version}.zip\n    popd\n  fi\n\n  export SHERPA_ONNXRUNTIME_LIB_DIR=$dir/$onnxruntime_version/jni/x86_64/\n  export SHERPA_ONNXRUNTIME_INCLUDE_DIR=$dir/$onnxruntime_version/headers/\nelse\n  if [ ! -f ${onnxruntime_version}-static/lib/libonnxruntime.a ]; then\n    wget -c -q https://github.com/csukuangfj/onnxruntime-libs/releases/download/v${onnxruntime_version}/onnxruntime-android-x86_64-static_lib-${onnxruntime_version}.zip\n    unzip onnxruntime-android-x86_64-static_lib-${onnxruntime_version}.zip\n    rm onnxruntime-android-x86_64-static_lib-${onnxruntime_version}.zip\n    mv onnxruntime-android-x86_64-static_lib-${onnxruntime_version} ${onnxruntime_version}-static\n  fi\n\n  export SHERPA_ONNXRUNTIME_LIB_DIR=$dir/$onnxruntime_version-static/lib/\n  export SHERPA_ONNXRUNTIME_INCLUDE_DIR=$dir/$onnxruntime_version-static/include/\nfi\n\necho \"SHERPA_ONNXRUNTIME_LIB_DIR: $SHERPA_ONNXRUNTIME_LIB_DIR\"\necho \"SHERPA_ONNXRUNTIME_INCLUDE_DIR $SHERPA_ONNXRUNTIME_INCLUDE_DIR\"\n\nif [ -z $SHERPA_ONNX_ENABLE_TTS ]; then\n  SHERPA_ONNX_ENABLE_TTS=ON\nfi\n\nif [ -z $SHERPA_ONNX_ENABLE_SPEAKER_DIARIZATION ]; then\n  SHERPA_ONNX_ENABLE_SPEAKER_DIARIZATION=ON\nfi\n\nif [ -z $SHERPA_ONNX_ENABLE_BINARY ]; then\n  SHERPA_ONNX_ENABLE_BINARY=OFF\nfi\n\nif [ -z $SHERPA_ONNX_ENABLE_C_API ]; then\n  SHERPA_ONNX_ENABLE_C_API=OFF\nfi\n\nif [ -z $SHERPA_ONNX_ENABLE_JNI ]; then\n  SHERPA_ONNX_ENABLE_JNI=ON\nfi\n\ncmake -DCMAKE_TOOLCHAIN_FILE=\"$ANDROID_NDK/build/cmake/android.toolchain.cmake\" \\\n    -DSHERPA_ONNX_ENABLE_TTS=$SHERPA_ONNX_ENABLE_TTS \\\n    -DSHERPA_ONNX_ENABLE_SPEAKER_DIARIZATION=$SHERPA_ONNX_ENABLE_SPEAKER_DIARIZATION \\\n    -DSHERPA_ONNX_ENABLE_BINARY=$SHERPA_ONNX_ENABLE_BINARY \\\n    -DBUILD_PIPER_PHONMIZE_EXE=OFF \\\n    -DBUILD_PIPER_PHONMIZE_TESTS=OFF \\\n    -DBUILD_ESPEAK_NG_EXE=OFF \\\n    -DBUILD_ESPEAK_NG_TESTS=OFF \\\n    -DCMAKE_BUILD_TYPE=Release \\\n    -DBUILD_SHARED_LIBS=$BUILD_SHARED_LIBS \\\n    -DSHERPA_ONNX_ENABLE_PYTHON=OFF \\\n    -DSHERPA_ONNX_ENABLE_TESTS=OFF \\\n    -DSHERPA_ONNX_ENABLE_CHECK=OFF \\\n    -DSHERPA_ONNX_ENABLE_PORTAUDIO=OFF \\\n    -DSHERPA_ONNX_ENABLE_JNI=$SHERPA_ONNX_ENABLE_JNI \\\n    -DSHERPA_ONNX_LINK_LIBSTDCPP_STATICALLY=OFF \\\n    -DCMAKE_INSTALL_PREFIX=./install \\\n    -DANDROID_ABI=\"x86_64\" \\\n    -DSHERPA_ONNX_ENABLE_C_API=$SHERPA_ONNX_ENABLE_C_API \\\n    -DSHERPA_ONNX_ENABLE_WEBSOCKET=OFF \\\n    -DANDROID_PLATFORM=android-21 ..\n\n    # By default, it links to libc++_static.a\n    # -DANDROID_STL=c++_shared \\\n\n# make VERBOSE=1 -j4\nmake -j4\nmake install/strip\n\ncp -fv $onnxruntime_version/jni/x86_64/libonnxruntime.so install/lib 2>/dev/null || true\nrm -rf install/share\nrm -rf install/lib/pkgconfig\nrm -rf install/lib/lib*.a\n\nif [ -f install/lib/libsherpa-onnx-c-api.so ]; then\n  cat >install/lib/README.md <<EOF\n# Introduction\n\nNote that if you use Android Studio, then you only need to\ncopy libonnxruntime.so and libsherpa-onnx-jni.so\nto your jniLibs, and you don't need libsherpa-onnx-c-api.so or\nlibsherpa-onnx-cxx-api.so.\n\nlibsherpa-onnx-c-api.so and libsherpa-onnx-cxx-api.so are for users\nwho don't use JNI. In that case, libsherpa-onnx-jni.so is not needed.\n\nIn any case, libonnxruntime.is is always needed.\nEOF\n  ls -lh install/lib/README.md\nfi\n"
        },
        {
          "name": "build-android-x86.sh",
          "type": "blob",
          "size": 4.0263671875,
          "content": "#!/usr/bin/env bash\nset -ex\n\nif [ x$BUILD_SHARED_LIBS == xOFF ]; then\n  echo \"BUILD_SHARED_LIBS=OFF is ignored for Android x86.\"\n  echo \"Always link with libonnxruntime.so\"\n  sleep 2\nfi\n\ndir=$PWD/build-android-x86\n\nmkdir -p $dir\ncd $dir\n\n# Note from https://github.com/Tencent/ncnn/wiki/how-to-build#build-for-android\n# (optional) remove the hardcoded debug flag in Android NDK android-ndk\n# issue: https://github.com/android/ndk/issues/243\n#\n# open $ANDROID_NDK/build/cmake/android.toolchain.cmake for ndk < r23\n# or $ANDROID_NDK/build/cmake/android-legacy.toolchain.cmake for ndk >= r23\n#\n# delete \"-g\" line\n#\n# list(APPEND ANDROID_COMPILER_FLAGS\n#   -g\n#   -DANDROID\n\nif [ -z $ANDROID_NDK ]; then\n  ANDROID_NDK=/star-fj/fangjun/software/android-sdk/ndk/22.1.7171670\n  # or use\n  # ANDROID_NDK=/star-fj/fangjun/software/android-ndk\n  #\n  # Inside the $ANDROID_NDK directory, you can find a binary ndk-build\n  # and some other files like the file \"build/cmake/android.toolchain.cmake\"\n\n  if [ ! -d $ANDROID_NDK ]; then\n    # For macOS, I have installed Android Studio, select the menu\n    # Tools -> SDK manager -> Android SDK\n    # and set \"Android SDK location\" to /Users/fangjun/software/my-android\n    ANDROID_NDK=/Users/fangjun/software/my-android/ndk/22.1.7171670\n  fi\nfi\n\nif [ ! -d $ANDROID_NDK ]; then\n  echo Please set the environment variable ANDROID_NDK before you run this script\n  exit 1\nfi\n\necho \"ANDROID_NDK: $ANDROID_NDK\"\nsleep 1\n\nonnxruntime_version=1.17.1\n\nif [ ! -f $onnxruntime_version/jni/x86/libonnxruntime.so ]; then\n  mkdir -p $onnxruntime_version\n  pushd $onnxruntime_version\n  wget -c -q https://github.com/csukuangfj/onnxruntime-libs/releases/download/v${onnxruntime_version}/onnxruntime-android-${onnxruntime_version}.zip\n  unzip onnxruntime-android-${onnxruntime_version}.zip\n  rm onnxruntime-android-${onnxruntime_version}.zip\n  popd\nfi\n\nexport SHERPA_ONNXRUNTIME_LIB_DIR=$dir/$onnxruntime_version/jni/x86/\nexport SHERPA_ONNXRUNTIME_INCLUDE_DIR=$dir/$onnxruntime_version/headers/\n\necho \"SHERPA_ONNXRUNTIME_LIB_DIR: $SHERPA_ONNXRUNTIME_LIB_DIR\"\necho \"SHERPA_ONNXRUNTIME_INCLUDE_DIR $SHERPA_ONNXRUNTIME_INCLUDE_DIR\"\n\nif [ -z $SHERPA_ONNX_ENABLE_TTS ]; then\n  SHERPA_ONNX_ENABLE_TTS=ON\nfi\n\nif [ -z $SHERPA_ONNX_ENABLE_SPEAKER_DIARIZATION ]; then\n  SHERPA_ONNX_ENABLE_SPEAKER_DIARIZATION=ON\nfi\n\nif [ -z $SHERPA_ONNX_ENABLE_BINARY ]; then\n  SHERPA_ONNX_ENABLE_BINARY=OFF\nfi\n\nif [ -z $SHERPA_ONNX_ENABLE_C_API ]; then\n  SHERPA_ONNX_ENABLE_C_API=OFF\nfi\n\nif [ -z $SHERPA_ONNX_ENABLE_JNI ]; then\n  SHERPA_ONNX_ENABLE_JNI=ON\nfi\n\ncmake -DCMAKE_TOOLCHAIN_FILE=\"$ANDROID_NDK/build/cmake/android.toolchain.cmake\" \\\n    -DSHERPA_ONNX_ENABLE_TTS=$SHERPA_ONNX_ENABLE_TTS \\\n    -DSHERPA_ONNX_ENABLE_SPEAKER_DIARIZATION=$SHERPA_ONNX_ENABLE_SPEAKER_DIARIZATION \\\n    -DSHERPA_ONNX_ENABLE_BINARY=$SHERPA_ONNX_ENABLE_BINARY \\\n    -DBUILD_PIPER_PHONMIZE_EXE=OFF \\\n    -DBUILD_PIPER_PHONMIZE_TESTS=OFF \\\n    -DBUILD_ESPEAK_NG_EXE=OFF \\\n    -DBUILD_ESPEAK_NG_TESTS=OFF \\\n    -DCMAKE_BUILD_TYPE=Release \\\n    -DBUILD_SHARED_LIBS=ON \\\n    -DSHERPA_ONNX_ENABLE_PYTHON=OFF \\\n    -DSHERPA_ONNX_ENABLE_TESTS=OFF \\\n    -DSHERPA_ONNX_ENABLE_CHECK=OFF \\\n    -DSHERPA_ONNX_ENABLE_PORTAUDIO=OFF \\\n    -DSHERPA_ONNX_ENABLE_JNI=$SHERPA_ONNX_ENABLE_JNI \\\n    -DCMAKE_INSTALL_PREFIX=./install \\\n    -DANDROID_ABI=\"x86\" \\\n    -DSHERPA_ONNX_ENABLE_C_API=$SHERPA_ONNX_ENABLE_C_API \\\n    -DSHERPA_ONNX_ENABLE_WEBSOCKET=OFF \\\n    -DANDROID_PLATFORM=android-21 ..\n\n# make VERBOSE=1 -j4\nmake -j4\nmake install/strip\ncp -fv $onnxruntime_version/jni/x86/libonnxruntime.so install/lib\nrm -rf install/lib/pkgconfig\n\nif [ -f install/lib/libsherpa-onnx-c-api.so ]; then\n  cat >install/lib/README.md <<EOF\n# Introduction\n\nNote that if you use Android Studio, then you only need to\ncopy libonnxruntime.so and libsherpa-onnx-jni.so\nto your jniLibs, and you don't need libsherpa-onnx-c-api.so or\nlibsherpa-onnx-cxx-api.so.\n\nlibsherpa-onnx-c-api.so and libsherpa-onnx-cxx-api.so are for users\nwho don't use JNI. In that case, libsherpa-onnx-jni.so is not needed.\n\nIn any case, libonnxruntime.is is always needed.\nEOF\n  ls -lh install/lib/README.md\nfi\n"
        },
        {
          "name": "build-arm-linux-gnueabihf.sh",
          "type": "blob",
          "size": 1.796875,
          "content": "#!/usr/bin/env bash\n\nif command -v arm-none-linux-gnueabihf-gcc  &> /dev/null; then\n  ln -svf $(which arm-none-linux-gnueabihf-gcc) ./arm-linux-gnueabihf-gcc\n  ln -svf $(which arm-none-linux-gnueabihf-g++) ./arm-linux-gnueabihf-g++\n  export PATH=$PWD:$PATH\nfi\n\nif ! command -v arm-linux-gnueabihf-gcc  &> /dev/null; then\n  echo \"Please install a toolchain for cross-compiling.\"\n  echo \"You can refer to: \"\n  echo \"  https://k2-fsa.github.io/sherpa/onnx/install/arm-embedded-linux.html\"\n  echo \"for help.\"\n  exit 1\nfi\n\nset -ex\n\ndir=build-arm-linux-gnueabihf\nmkdir -p $dir\ncd $dir\n\nif [ ! -f alsa-lib/src/.libs/libasound.so ]; then\n  echo \"Start to cross-compile alsa-lib\"\n  if [ ! -d alsa-lib ]; then\n    git clone --depth 1 --branch v1.2.12 https://github.com/alsa-project/alsa-lib\n  fi\n  pushd alsa-lib\n  CC=arm-linux-gnueabihf-gcc ./gitcompile --host=arm-linux-gnueabihf\n  popd\n  echo \"Finish cross-compiling alsa-lib\"\nfi\n\nexport CPLUS_INCLUDE_PATH=$PWD/alsa-lib/include:$CPLUS_INCLUDE_PATH\nexport SHERPA_ONNX_ALSA_LIB_DIR=$PWD/alsa-lib/src/.libs\n\nif [[ x\"$BUILD_SHARED_LIBS\" == x\"\" ]]; then\n  # By default, use static link\n  BUILD_SHARED_LIBS=OFF\nfi\n\ncmake \\\n  -DBUILD_PIPER_PHONMIZE_EXE=OFF \\\n  -DBUILD_PIPER_PHONMIZE_TESTS=OFF \\\n  -DBUILD_ESPEAK_NG_EXE=OFF \\\n  -DBUILD_ESPEAK_NG_TESTS=OFF \\\n  -DCMAKE_INSTALL_PREFIX=./install \\\n  -DCMAKE_BUILD_TYPE=Release \\\n  -DBUILD_SHARED_LIBS=$BUILD_SHARED_LIBS \\\n  -DSHERPA_ONNX_ENABLE_TESTS=OFF \\\n  -DSHERPA_ONNX_ENABLE_PYTHON=OFF \\\n  -DSHERPA_ONNX_ENABLE_CHECK=OFF \\\n  -DSHERPA_ONNX_ENABLE_PORTAUDIO=OFF \\\n  -DSHERPA_ONNX_ENABLE_JNI=OFF \\\n  -DSHERPA_ONNX_ENABLE_C_API=ON \\\n  -DSHERPA_ONNX_ENABLE_WEBSOCKET=ON \\\n  -DCMAKE_TOOLCHAIN_FILE=../toolchains/arm-linux-gnueabihf.toolchain.cmake \\\n  ..\n\nmake VERBOSE=1 -j4\nmake install/strip\n\ncp -v $SHERPA_ONNX_ALSA_LIB_DIR/libasound.so* ./install/lib/\n"
        },
        {
          "name": "build-ios-no-tts.sh",
          "type": "blob",
          "size": 5.46484375,
          "content": "#!/usr/bin/env  bash\n\nset -e\n\ndir=build-ios-no-tts\nmkdir -p $dir\ncd $dir\nonnxruntime_version=1.17.1\nonnxruntime_dir=ios-onnxruntime/$onnxruntime_version\n\nif [ ! -f $onnxruntime_dir/onnxruntime.xcframework/ios-arm64/onnxruntime.a ]; then\n  mkdir -p $onnxruntime_dir\n  pushd $onnxruntime_dir\n  wget -c https://github.com/csukuangfj/onnxruntime-libs/releases/download/v${onnxruntime_version}/onnxruntime.xcframework-${onnxruntime_version}.tar.bz2\n  tar xvf onnxruntime.xcframework-${onnxruntime_version}.tar.bz2\n  rm onnxruntime.xcframework-${onnxruntime_version}.tar.bz2\n  cd ..\n  ln -sf $onnxruntime_version/onnxruntime.xcframework .\n  popd\nfi\n\n# First, for simulator\necho \"Building for simulator (x86_64)\"\n\nexport SHERPA_ONNXRUNTIME_LIB_DIR=$PWD/ios-onnxruntime/onnxruntime.xcframework/ios-arm64_x86_64-simulator\nexport SHERPA_ONNXRUNTIME_INCLUDE_DIR=$PWD/ios-onnxruntime/onnxruntime.xcframework/Headers\n\necho \"SHERPA_ONNXRUNTIME_LIB_DIR: $SHERPA_ONNXRUNTIME_LIB_DIR\"\necho \"SHERPA_ONNXRUNTIME_INCLUDE_DIR $SHERPA_ONNXRUNTIME_INCLUDE_DIR\"\n\n# Note: We use -DENABLE_ARC=1 here to fix the linking error:\n#\n# The symbol _NSLog is not defined\n#\n\ncmake \\\n  -DSHERPA_ONNX_ENABLE_TTS=OFF \\\n  -DBUILD_PIPER_PHONMIZE_EXE=OFF \\\n  -DBUILD_PIPER_PHONMIZE_TESTS=OFF \\\n  -DBUILD_ESPEAK_NG_EXE=OFF \\\n  -DBUILD_ESPEAK_NG_TESTS=OFF \\\n  -S .. \\\n  -DCMAKE_TOOLCHAIN_FILE=./toolchains/ios.toolchain.cmake \\\n  -DPLATFORM=SIMULATOR64 \\\n  -DENABLE_BITCODE=0 \\\n  -DENABLE_ARC=1 \\\n  -DENABLE_VISIBILITY=0 \\\n  -DCMAKE_BUILD_TYPE=Release \\\n  -DBUILD_SHARED_LIBS=OFF \\\n  -DSHERPA_ONNX_ENABLE_PYTHON=OFF \\\n  -DSHERPA_ONNX_ENABLE_TESTS=OFF \\\n  -DSHERPA_ONNX_ENABLE_CHECK=OFF \\\n  -DSHERPA_ONNX_ENABLE_PORTAUDIO=OFF \\\n  -DSHERPA_ONNX_ENABLE_JNI=OFF \\\n  -DSHERPA_ONNX_ENABLE_C_API=ON \\\n  -DSHERPA_ONNX_ENABLE_WEBSOCKET=OFF \\\n  -DDEPLOYMENT_TARGET=13.0 \\\n  -B build/simulator_x86_64\n\ncmake --build build/simulator_x86_64 -j 4 --verbose\n\necho \"Building for simulator (arm64)\"\n\ncmake \\\n  -DSHERPA_ONNX_ENABLE_TTS=OFF \\\n  -DBUILD_PIPER_PHONMIZE_EXE=OFF \\\n  -DBUILD_PIPER_PHONMIZE_TESTS=OFF \\\n  -DBUILD_ESPEAK_NG_EXE=OFF \\\n  -DBUILD_ESPEAK_NG_TESTS=OFF \\\n  -S .. \\\n  -DCMAKE_TOOLCHAIN_FILE=./toolchains/ios.toolchain.cmake \\\n  -DPLATFORM=SIMULATORARM64 \\\n  -DENABLE_BITCODE=0 \\\n  -DENABLE_ARC=1 \\\n  -DENABLE_VISIBILITY=0 \\\n  -DCMAKE_BUILD_TYPE=Release \\\n  -DCMAKE_INSTALL_PREFIX=./install \\\n  -DBUILD_SHARED_LIBS=OFF \\\n  -DSHERPA_ONNX_ENABLE_PYTHON=OFF \\\n  -DSHERPA_ONNX_ENABLE_TESTS=OFF \\\n  -DSHERPA_ONNX_ENABLE_CHECK=OFF \\\n  -DSHERPA_ONNX_ENABLE_PORTAUDIO=OFF \\\n  -DSHERPA_ONNX_ENABLE_JNI=OFF \\\n  -DSHERPA_ONNX_ENABLE_C_API=ON \\\n  -DSHERPA_ONNX_ENABLE_WEBSOCKET=OFF \\\n  -DDEPLOYMENT_TARGET=13.0 \\\n  -B build/simulator_arm64\n\ncmake --build build/simulator_arm64 -j 4 --verbose\n\necho \"Building for arm64\"\n\nexport SHERPA_ONNXRUNTIME_LIB_DIR=$PWD/ios-onnxruntime/onnxruntime.xcframework/ios-arm64\n\n\ncmake \\\n  -DSHERPA_ONNX_ENABLE_TTS=OFF \\\n  -DBUILD_PIPER_PHONMIZE_EXE=OFF \\\n  -DBUILD_PIPER_PHONMIZE_TESTS=OFF \\\n  -DBUILD_ESPEAK_NG_EXE=OFF \\\n  -DBUILD_ESPEAK_NG_TESTS=OFF \\\n  -S .. \\\n  -DCMAKE_TOOLCHAIN_FILE=./toolchains/ios.toolchain.cmake \\\n  -DPLATFORM=OS64 \\\n  -DENABLE_BITCODE=0 \\\n  -DENABLE_ARC=1 \\\n  -DENABLE_VISIBILITY=0 \\\n  -DCMAKE_INSTALL_PREFIX=./install \\\n  -DCMAKE_BUILD_TYPE=Release \\\n  -DBUILD_SHARED_LIBS=OFF \\\n  -DSHERPA_ONNX_ENABLE_PYTHON=OFF \\\n  -DSHERPA_ONNX_ENABLE_TESTS=OFF \\\n  -DSHERPA_ONNX_ENABLE_CHECK=OFF \\\n  -DSHERPA_ONNX_ENABLE_PORTAUDIO=OFF \\\n  -DSHERPA_ONNX_ENABLE_JNI=OFF \\\n  -DSHERPA_ONNX_ENABLE_C_API=ON \\\n  -DSHERPA_ONNX_ENABLE_WEBSOCKET=OFF \\\n  -DDEPLOYMENT_TARGET=13.0 \\\n  -B build/os64\n\ncmake --build build/os64 -j 4\n# Generate headers for sherpa-onnx.xcframework\ncmake --build build/os64 --target install\n\necho \"Generate xcframework\"\n\nmkdir -p \"build/simulator/lib\"\nfor f in libkaldi-native-fbank-core.a libsherpa-onnx-c-api.a libsherpa-onnx-core.a \\\n         libsherpa-onnx-fst.a libsherpa-onnx-fstfar.a libsherpa-onnx-kaldifst-core.a libkaldi-decoder-core.a libssentencepiece_core.a; do\n  lipo -create build/simulator_arm64/lib/${f} \\\n               build/simulator_x86_64/lib/${f} \\\n       -output build/simulator/lib/${f}\ndone\n\n# Merge archive first, because the following xcodebuild create xcframework\n# cannot accept multi archive with the same architecture.\nlibtool -static -o build/simulator/sherpa-onnx.a \\\n  build/simulator/lib/libkaldi-native-fbank-core.a \\\n  build/simulator/lib/libsherpa-onnx-c-api.a \\\n  build/simulator/lib/libsherpa-onnx-core.a  \\\n  build/simulator/lib/libsherpa-onnx-fst.a   \\\n  build/simulator/lib/libsherpa-onnx-fstfar.a   \\\n  build/simulator/lib/libsherpa-onnx-kaldifst-core.a \\\n  build/simulator/lib/libkaldi-decoder-core.a \\\n  build/simulator/lib/libssentencepiece_core.a\n\nlibtool -static -o build/os64/sherpa-onnx.a \\\n  build/os64/lib/libkaldi-native-fbank-core.a \\\n  build/os64/lib/libsherpa-onnx-c-api.a \\\n  build/os64/lib/libsherpa-onnx-core.a \\\n  build/os64/lib/libsherpa-onnx-fst.a   \\\n  build/os64/lib/libsherpa-onnx-fstfar.a   \\\n  build/os64/lib/libsherpa-onnx-kaldifst-core.a \\\n  build/os64/lib/libkaldi-decoder-core.a \\\n  build/os64/lib/libssentencepiece_core.a\n\nrm -rf sherpa-onnx.xcframework\n\nxcodebuild -create-xcframework \\\n      -library \"build/os64/sherpa-onnx.a\" \\\n      -library \"build/simulator/sherpa-onnx.a\" \\\n      -output sherpa-onnx.xcframework\n\n# Copy Headers\nmkdir -p sherpa-onnx.xcframework/Headers\ncp -av install/include/* sherpa-onnx.xcframework/Headers\n\npushd sherpa-onnx.xcframework/ios-arm64_x86_64-simulator\nln -s sherpa-onnx.a libsherpa-onnx.a\npopd\n\npushd sherpa-onnx.xcframework/ios-arm64\nln -s sherpa-onnx.a libsherpa-onnx.a\n"
        },
        {
          "name": "build-ios-shared.sh",
          "type": "blob",
          "size": 8.4794921875,
          "content": "#!/usr/bin/env  bash\n#\n# Note: This script is to build sherpa-onnx for flutter/dart, which requires\n# us to use shared libraries for sherpa-onnx.\n#\n# Note: We still use static libraries for onnxruntime.\n\nset -e\n\ndir=build-ios-shared\nmkdir -p $dir\ncd $dir\nonnxruntime_version=1.17.1\nonnxruntime_dir=ios-onnxruntime/$onnxruntime_version\n\nSHERPA_ONNX_GITHUB=github.com\n\nif [ \"$SHERPA_ONNX_GITHUB_MIRROW\" == true ]; then\n    SHERPA_ONNX_GITHUB=hub.nuaa.cf\nfi\n\nif [ ! -z CMAKE_VERBOSE_MAKEFILE ]; then\n  CMAKE_VERBOSE_MAKEFILE=ON\nelse\n  CMAKE_VERBOSE_MAKEFILE=OFF\nfi\n\nif [ ! -f $onnxruntime_dir/onnxruntime.xcframework/ios-arm64/onnxruntime.a ]; then\n  mkdir -p $onnxruntime_dir\n  pushd $onnxruntime_dir\n  wget -c https://${SHERPA_ONNX_GITHUB}/csukuangfj/onnxruntime-libs/releases/download/v${onnxruntime_version}/onnxruntime.xcframework-${onnxruntime_version}.tar.bz2\n  tar xvf onnxruntime.xcframework-${onnxruntime_version}.tar.bz2\n  rm onnxruntime.xcframework-${onnxruntime_version}.tar.bz2\n  cd ..\n  ln -sf $onnxruntime_version/onnxruntime.xcframework .\n  popd\nfi\n\n# First, for simulator\necho \"Building for simulator (x86_64)\"\n\nexport SHERPA_ONNXRUNTIME_LIB_DIR=$PWD/ios-onnxruntime/onnxruntime.xcframework/ios-arm64_x86_64-simulator\nexport SHERPA_ONNXRUNTIME_INCLUDE_DIR=$PWD/ios-onnxruntime/onnxruntime.xcframework/Headers\n\necho \"SHERPA_ONNXRUNTIME_LIB_DIR: $SHERPA_ONNXRUNTIME_LIB_DIR\"\necho \"SHERPA_ONNXRUNTIME_INCLUDE_DIR $SHERPA_ONNXRUNTIME_INCLUDE_DIR\"\n\n# Note: We use -DENABLE_ARC=1 here to fix the linking error:\n#\n# The symbol _NSLog is not defined\n#\nif [[ ! -f build/simulator_x86_64/install/lib/libsherpa-onnx-c-api.dylib ]]; then\n  cmake \\\n    -DSHERPA_ONNX_ENABLE_BINARY=OFF \\\n    -DBUILD_PIPER_PHONMIZE_EXE=OFF \\\n    -DBUILD_PIPER_PHONMIZE_TESTS=OFF \\\n    -DBUILD_ESPEAK_NG_EXE=OFF \\\n    -DBUILD_ESPEAK_NG_TESTS=OFF \\\n    -S .. -D CMAKE_VERBOSE_MAKEFILE=$CMAKE_VERBOSE_MAKEFILE \\\n    -DCMAKE_TOOLCHAIN_FILE=./toolchains/ios.toolchain.cmake \\\n    -DPLATFORM=SIMULATOR64 \\\n    -DENABLE_BITCODE=0 \\\n    -DENABLE_ARC=1 \\\n    -DENABLE_VISIBILITY=1 \\\n    -DCMAKE_BUILD_TYPE=Release \\\n    -DCMAKE_INSTALL_PREFIX=./build/simulator_x86_64/install \\\n    -DBUILD_SHARED_LIBS=ON \\\n    -DSHERPA_ONNX_ENABLE_PYTHON=OFF \\\n    -DSHERPA_ONNX_ENABLE_TESTS=OFF \\\n    -DSHERPA_ONNX_ENABLE_CHECK=OFF \\\n    -DSHERPA_ONNX_ENABLE_PORTAUDIO=OFF \\\n    -DSHERPA_ONNX_ENABLE_JNI=OFF \\\n    -DSHERPA_ONNX_ENABLE_C_API=ON \\\n    -DSHERPA_ONNX_ENABLE_WEBSOCKET=OFF \\\n    -DDEPLOYMENT_TARGET=13.0 \\\n    -B build/simulator_x86_64\n\n  cmake --build build/simulator_x86_64 -j 4 --target install\nelse\n  echo \"Skip building for simulator (x86_64)\"\nfi\n\necho \"Building for simulator (arm64)\"\n\nif [[ ! -f build/simulator_arm64/install/lib/libsherpa-onnx-c-api.dylib ]]; then\n  cmake \\\n    -DSHERPA_ONNX_ENABLE_BINARY=OFF \\\n    -DBUILD_PIPER_PHONMIZE_EXE=OFF \\\n    -DBUILD_PIPER_PHONMIZE_TESTS=OFF \\\n    -DBUILD_ESPEAK_NG_EXE=OFF \\\n    -DBUILD_ESPEAK_NG_TESTS=OFF \\\n    -S .. -D CMAKE_VERBOSE_MAKEFILE=$CMAKE_VERBOSE_MAKEFILE \\\n    -DCMAKE_TOOLCHAIN_FILE=./toolchains/ios.toolchain.cmake \\\n    -DPLATFORM=SIMULATORARM64 \\\n    -DENABLE_BITCODE=0 \\\n    -DENABLE_ARC=1 \\\n    -DENABLE_VISIBILITY=1 \\\n    -DCMAKE_BUILD_TYPE=Release \\\n    -DCMAKE_INSTALL_PREFIX=./build/simulator_arm64/install \\\n    -DBUILD_SHARED_LIBS=ON \\\n    -DSHERPA_ONNX_ENABLE_PYTHON=OFF \\\n    -DSHERPA_ONNX_ENABLE_TESTS=OFF \\\n    -DSHERPA_ONNX_ENABLE_CHECK=OFF \\\n    -DSHERPA_ONNX_ENABLE_PORTAUDIO=OFF \\\n    -DSHERPA_ONNX_ENABLE_JNI=OFF \\\n    -DSHERPA_ONNX_ENABLE_C_API=ON \\\n    -DSHERPA_ONNX_ENABLE_WEBSOCKET=OFF \\\n    -DDEPLOYMENT_TARGET=13.0 \\\n    -B build/simulator_arm64\n\n  cmake --build build/simulator_arm64 -j 4 --target install\nelse\n  echo \"Skip building for simulator (arm64)\"\nfi\n\necho \"Building for arm64\"\n\nif [[ ! -f build/os64/install/lib/libsherpa-onnx-c-api.dylib ]]; then\n  export SHERPA_ONNXRUNTIME_LIB_DIR=$PWD/ios-onnxruntime/onnxruntime.xcframework/ios-arm64\n\n  cmake \\\n    -DSHERPA_ONNX_ENABLE_BINARY=OFF \\\n    -DBUILD_PIPER_PHONMIZE_EXE=OFF \\\n    -DBUILD_PIPER_PHONMIZE_TESTS=OFF \\\n    -DBUILD_ESPEAK_NG_EXE=OFF \\\n    -DBUILD_ESPEAK_NG_TESTS=OFF \\\n    -S .. -D CMAKE_VERBOSE_MAKEFILE=$CMAKE_VERBOSE_MAKEFILE \\\n    -DCMAKE_TOOLCHAIN_FILE=./toolchains/ios.toolchain.cmake \\\n    -DPLATFORM=OS64 \\\n    -DENABLE_BITCODE=0 \\\n    -DENABLE_ARC=1 \\\n    -DENABLE_VISIBILITY=1 \\\n    -DCMAKE_BUILD_TYPE=Release \\\n    -DCMAKE_INSTALL_PREFIX=./build/os64/install \\\n    -DBUILD_SHARED_LIBS=ON \\\n    -DSHERPA_ONNX_ENABLE_PYTHON=OFF \\\n    -DSHERPA_ONNX_ENABLE_TESTS=OFF \\\n    -DSHERPA_ONNX_ENABLE_CHECK=OFF \\\n    -DSHERPA_ONNX_ENABLE_PORTAUDIO=OFF \\\n    -DSHERPA_ONNX_ENABLE_JNI=OFF \\\n    -DSHERPA_ONNX_ENABLE_C_API=ON \\\n    -DSHERPA_ONNX_ENABLE_WEBSOCKET=OFF \\\n    -DDEPLOYMENT_TARGET=13.0 \\\n    -B build/os64\n\n  cmake --build build/os64 -j 4 --target install\nelse\n  echo \"Skip building for arm64\"\nfi\n\necho \"Collect dynamic libraries \"\nmkdir -p ios-arm64 ios-arm64-simulator ios-x86_64-simulator\n\ncp -v ./build/os64/install/lib/libsherpa-onnx-c-api.dylib ios-arm64/\ncp -v ./build/simulator_arm64/install/lib/libsherpa-onnx-c-api.dylib ios-arm64-simulator/\ncp -v .//build/simulator_x86_64/install/lib/libsherpa-onnx-c-api.dylib ios-x86_64-simulator/\n\n# see https://github.com/k2-fsa/sherpa-onnx/issues/1172#issuecomment-2439662662\nrm -rf ios-arm64_x86_64-simulator\nmkdir ios-arm64_x86_64-simulator\n\nlipo \\\n  -create \\\n    ios-arm64-simulator/libsherpa-onnx-c-api.dylib \\\n    ios-x86_64-simulator/libsherpa-onnx-c-api.dylib \\\n  -output \\\n    ios-arm64_x86_64-simulator/libsherpa-onnx-c-api.dylib\n\npushd ios-arm64\nrm -rf sherpa_onnx.framework\nmkdir sherpa_onnx.framework\n\nlipo \\\n  -create \\\n    libsherpa-onnx-c-api.dylib \\\n  -output \\\n    sherpa_onnx\n\nmv sherpa_onnx sherpa_onnx.framework/\ncd sherpa_onnx.framework\n\ninstall_name_tool \\\n  -change @rpath/libsherpa-onnx-c-api.dylib @rpath/sherpa_onnx.framework/sherpa_onnx \\\n  sherpa_onnx\n\ninstall_name_tool \\\n  -id \"@rpath/sherpa_onnx.framework/sherpa_onnx\" \\\n  sherpa_onnx\n\nchmod +x sherpa_onnx\npopd\n\npushd ios-arm64_x86_64-simulator\nrm -rf sherpa_onnx.framework\nmkdir sherpa_onnx.framework\n\nlipo \\\n  -create \\\n    libsherpa-onnx-c-api.dylib \\\n  -output \\\n    sherpa_onnx\n\nmv sherpa_onnx sherpa_onnx.framework/\ncd sherpa_onnx.framework\ninstall_name_tool \\\n  -change @rpath/libsherpa-onnx-c-api.dylib @rpath/sherpa_onnx.framework/sherpa_onnx \\\n  sherpa_onnx\n\ninstall_name_tool \\\n  -id \"@rpath/sherpa_onnx.framework/sherpa_onnx\" \\\n  sherpa_onnx\n\nchmod +x sherpa_onnx\npopd\n\nfor d in ios-arm64_x86_64-simulator ios-arm64; do\n  dst=$d/sherpa_onnx.framework\n\n  # The Info.plist is modified from\n  # https://github.com/Spicely/flutter_openim_sdk_ffi/blob/main/ios/openim_sdk_ffi.framework/Info.plist\n  cat >$dst/Info.plist <<EOF\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<!DOCTYPE plist PUBLIC \"-//Apple//DTD PLIST 1.0//EN\" \"http://www.apple.com/DTDs/PropertyList-1.0.dtd\">\n<plist version=\"1.0\">\n<dict>\n\t<key>CFBundleName</key>\n\t<string>sherpa_onnx</string>\n\t<key>DTSDKName</key>\n\t<string>iphoneos17.0</string>\n\t<key>DTXcode</key>\n\t<string>1501</string>\n\t<key>DTSDKBuild</key>\n\t<string>21A326</string>\n\t<key>CFBundleDevelopmentRegion</key>\n\t<string>en</string>\n\t<key>CFBundleVersion</key>\n\t<string>1</string>\n\t<key>BuildMachineOSBuild</key>\n\t<string>23B81</string>\n\t<key>DTPlatformName</key>\n\t<string>iphoneos</string>\n\t<key>CFBundlePackageType</key>\n\t<string>FMWK</string>\n\t<key>CFBundleShortVersionString</key>\n\t<string>1.10.38</string>\n\t<key>CFBundleSupportedPlatforms</key>\n\t<array>\n\t\t<string>iPhoneOS</string>\n\t</array>\n\t<key>CFBundleInfoDictionaryVersion</key>\n\t<string>6.0</string>\n\t<key>CFBundleExecutable</key>\n\t<string>sherpa_onnx</string>\n\t<key>DTCompiler</key>\n\t<string>com.apple.compilers.llvm.clang.1_0</string>\n\t<key>UIRequiredDeviceCapabilities</key>\n\t<array>\n\t\t<string>arm64</string>\n\t</array>\n\t<key>MinimumOSVersion</key>\n\t<string>13.0</string>\n\t<key>CFBundleIdentifier</key>\n\t<string>com.k2fsa.sherpa.onnx</string>\n\t<key>UIDeviceFamily</key>\n\t<array>\n\t\t<integer>1</integer>\n\t\t<integer>2</integer>\n\t</array>\n\t<key>CFBundleSignature</key>\n\t<string>????</string>\n\t<key>DTPlatformVersion</key>\n\t<string>17.0</string>\n\t<key>DTXcodeBuild</key>\n\t<string>15A507</string>\n\t<key>DTPlatformBuild</key>\n\t<string>21A326</string>\n\t<key>SupportedArchitectures</key>\n\t<array>\n\t\t<string>arm64</string>\n\t\t<string>x86_64</string>\n\t</array>\n\t<key>SupportedPlatform</key>\n\t<string>ios</string>\n</dict>\n</plist>\nEOF\ndone\n\nrm -rf sherpa_onnx.xcframework\nxcodebuild -create-xcframework \\\n  -framework ios-arm64/sherpa_onnx.framework \\\n  -framework ios-arm64_x86_64-simulator/sherpa_onnx.framework \\\n  -output sherpa_onnx.xcframework\n\ncd sherpa_onnx.xcframework\necho \"PWD: $PWD\"\nls -lh\necho \"---\"\nls -lh */*\n"
        },
        {
          "name": "build-ios.sh",
          "type": "blob",
          "size": 5.767578125,
          "content": "#!/usr/bin/env  bash\n\nset -e\n\ndir=build-ios\nmkdir -p $dir\ncd $dir\nonnxruntime_version=1.17.1\nonnxruntime_dir=ios-onnxruntime/$onnxruntime_version\n\nSHERPA_ONNX_GITHUB=github.com\n\nif [ \"$SHERPA_ONNX_GITHUB_MIRROW\" == true ]; then\n    SHERPA_ONNX_GITHUB=hub.nuaa.cf\nfi\n\nif [ ! -f $onnxruntime_dir/onnxruntime.xcframework/ios-arm64/onnxruntime.a ]; then\n  mkdir -p $onnxruntime_dir\n  pushd $onnxruntime_dir\n  wget -c https://${SHERPA_ONNX_GITHUB}/csukuangfj/onnxruntime-libs/releases/download/v${onnxruntime_version}/onnxruntime.xcframework-${onnxruntime_version}.tar.bz2\n  tar xvf onnxruntime.xcframework-${onnxruntime_version}.tar.bz2\n  rm onnxruntime.xcframework-${onnxruntime_version}.tar.bz2\n  cd ..\n  ln -sf $onnxruntime_version/onnxruntime.xcframework .\n  popd\nfi\n\n# First, for simulator\necho \"Building for simulator (x86_64)\"\n\nexport SHERPA_ONNXRUNTIME_LIB_DIR=$PWD/ios-onnxruntime/onnxruntime.xcframework/ios-arm64_x86_64-simulator\nexport SHERPA_ONNXRUNTIME_INCLUDE_DIR=$PWD/ios-onnxruntime/onnxruntime.xcframework/Headers\n\necho \"SHERPA_ONNXRUNTIME_LIB_DIR: $SHERPA_ONNXRUNTIME_LIB_DIR\"\necho \"SHERPA_ONNXRUNTIME_INCLUDE_DIR $SHERPA_ONNXRUNTIME_INCLUDE_DIR\"\n\n# Note: We use -DENABLE_ARC=1 here to fix the linking error:\n#\n# The symbol _NSLog is not defined\n#\n\ncmake \\\n  -DBUILD_PIPER_PHONMIZE_EXE=OFF \\\n  -DBUILD_PIPER_PHONMIZE_TESTS=OFF \\\n  -DBUILD_ESPEAK_NG_EXE=OFF \\\n  -DBUILD_ESPEAK_NG_TESTS=OFF \\\n  -S .. \\\n  -DCMAKE_TOOLCHAIN_FILE=./toolchains/ios.toolchain.cmake \\\n  -DPLATFORM=SIMULATOR64 \\\n  -DENABLE_BITCODE=0 \\\n  -DENABLE_ARC=1 \\\n  -DENABLE_VISIBILITY=0 \\\n  -DCMAKE_BUILD_TYPE=Release \\\n  -DBUILD_SHARED_LIBS=OFF \\\n  -DSHERPA_ONNX_ENABLE_PYTHON=OFF \\\n  -DSHERPA_ONNX_ENABLE_TESTS=OFF \\\n  -DSHERPA_ONNX_ENABLE_CHECK=OFF \\\n  -DSHERPA_ONNX_ENABLE_PORTAUDIO=OFF \\\n  -DSHERPA_ONNX_ENABLE_JNI=OFF \\\n  -DSHERPA_ONNX_ENABLE_C_API=ON \\\n  -DSHERPA_ONNX_ENABLE_WEBSOCKET=OFF \\\n  -DDEPLOYMENT_TARGET=13.0 \\\n  -B build/simulator_x86_64\n\ncmake --build build/simulator_x86_64 -j 4 --verbose\n\necho \"Building for simulator (arm64)\"\n\ncmake \\\n  -DBUILD_PIPER_PHONMIZE_EXE=OFF \\\n  -DBUILD_PIPER_PHONMIZE_TESTS=OFF \\\n  -DBUILD_ESPEAK_NG_EXE=OFF \\\n  -DBUILD_ESPEAK_NG_TESTS=OFF \\\n  -S .. \\\n  -DCMAKE_TOOLCHAIN_FILE=./toolchains/ios.toolchain.cmake \\\n  -DPLATFORM=SIMULATORARM64 \\\n  -DENABLE_BITCODE=0 \\\n  -DENABLE_ARC=1 \\\n  -DENABLE_VISIBILITY=0 \\\n  -DCMAKE_BUILD_TYPE=Release \\\n  -DCMAKE_INSTALL_PREFIX=./install \\\n  -DBUILD_SHARED_LIBS=OFF \\\n  -DSHERPA_ONNX_ENABLE_PYTHON=OFF \\\n  -DSHERPA_ONNX_ENABLE_TESTS=OFF \\\n  -DSHERPA_ONNX_ENABLE_CHECK=OFF \\\n  -DSHERPA_ONNX_ENABLE_PORTAUDIO=OFF \\\n  -DSHERPA_ONNX_ENABLE_JNI=OFF \\\n  -DSHERPA_ONNX_ENABLE_C_API=ON \\\n  -DSHERPA_ONNX_ENABLE_WEBSOCKET=OFF \\\n  -DDEPLOYMENT_TARGET=13.0 \\\n  -B build/simulator_arm64\n\ncmake --build build/simulator_arm64 -j 4 --verbose\n\necho \"Building for arm64\"\n\nexport SHERPA_ONNXRUNTIME_LIB_DIR=$PWD/ios-onnxruntime/onnxruntime.xcframework/ios-arm64\n\ncmake \\\n  -DBUILD_PIPER_PHONMIZE_EXE=OFF \\\n  -DBUILD_PIPER_PHONMIZE_TESTS=OFF \\\n  -DBUILD_ESPEAK_NG_EXE=OFF \\\n  -DBUILD_ESPEAK_NG_TESTS=OFF \\\n  -S .. \\\n  -DCMAKE_TOOLCHAIN_FILE=./toolchains/ios.toolchain.cmake \\\n  -DPLATFORM=OS64 \\\n  -DENABLE_BITCODE=0 \\\n  -DENABLE_ARC=1 \\\n  -DENABLE_VISIBILITY=0 \\\n  -DCMAKE_INSTALL_PREFIX=./install \\\n  -DCMAKE_BUILD_TYPE=Release \\\n  -DBUILD_SHARED_LIBS=OFF \\\n  -DSHERPA_ONNX_ENABLE_PYTHON=OFF \\\n  -DSHERPA_ONNX_ENABLE_TESTS=OFF \\\n  -DSHERPA_ONNX_ENABLE_CHECK=OFF \\\n  -DSHERPA_ONNX_ENABLE_PORTAUDIO=OFF \\\n  -DSHERPA_ONNX_ENABLE_JNI=OFF \\\n  -DSHERPA_ONNX_ENABLE_C_API=ON \\\n  -DSHERPA_ONNX_ENABLE_WEBSOCKET=OFF \\\n  -DDEPLOYMENT_TARGET=13.0 \\\n  -B build/os64\n\ncmake --build build/os64 -j 4\n# Generate headers for sherpa-onnx.xcframework\ncmake --build build/os64 --target install\n\necho \"Generate xcframework\"\n\nmkdir -p \"build/simulator/lib\"\nfor f in libkaldi-native-fbank-core.a libsherpa-onnx-c-api.a libsherpa-onnx-core.a \\\n         libsherpa-onnx-fstfar.a libssentencepiece_core.a \\\n         libsherpa-onnx-fst.a libsherpa-onnx-kaldifst-core.a libkaldi-decoder-core.a \\\n         libucd.a libpiper_phonemize.a libespeak-ng.a; do\n  lipo -create build/simulator_arm64/lib/${f} \\\n               build/simulator_x86_64/lib/${f} \\\n       -output build/simulator/lib/${f}\ndone\n\n# Merge archive first, because the following xcodebuild create xcframework\n# cannot accept multi archive with the same architecture.\nlibtool -static -o build/simulator/sherpa-onnx.a \\\n  build/simulator/lib/libkaldi-native-fbank-core.a \\\n  build/simulator/lib/libsherpa-onnx-c-api.a \\\n  build/simulator/lib/libsherpa-onnx-core.a  \\\n  build/simulator/lib/libsherpa-onnx-fstfar.a   \\\n  build/simulator/lib/libsherpa-onnx-fst.a   \\\n  build/simulator/lib/libsherpa-onnx-kaldifst-core.a \\\n  build/simulator/lib/libkaldi-decoder-core.a \\\n  build/simulator/lib/libucd.a \\\n  build/simulator/lib/libpiper_phonemize.a \\\n  build/simulator/lib/libespeak-ng.a \\\n  build/simulator/lib/libssentencepiece_core.a\n\nlibtool -static -o build/os64/sherpa-onnx.a \\\n  build/os64/lib/libkaldi-native-fbank-core.a \\\n  build/os64/lib/libsherpa-onnx-c-api.a \\\n  build/os64/lib/libsherpa-onnx-core.a \\\n  build/os64/lib/libsherpa-onnx-fstfar.a   \\\n  build/os64/lib/libsherpa-onnx-fst.a   \\\n  build/os64/lib/libsherpa-onnx-kaldifst-core.a \\\n  build/os64/lib/libkaldi-decoder-core.a \\\n  build/os64/lib/libucd.a \\\n  build/os64/lib/libpiper_phonemize.a \\\n  build/os64/lib/libespeak-ng.a \\\n  build/os64/lib/libssentencepiece_core.a\n\nrm -rf sherpa-onnx.xcframework\n\nxcodebuild -create-xcframework \\\n      -library \"build/os64/sherpa-onnx.a\" \\\n      -library \"build/simulator/sherpa-onnx.a\" \\\n      -output sherpa-onnx.xcframework\n\n# Copy Headers\nmkdir -p sherpa-onnx.xcframework/Headers\ncp -av install/include/* sherpa-onnx.xcframework/Headers\n\npushd sherpa-onnx.xcframework/ios-arm64_x86_64-simulator\nln -s sherpa-onnx.a libsherpa-onnx.a\npopd\n\npushd sherpa-onnx.xcframework/ios-arm64\nln -s sherpa-onnx.a libsherpa-onnx.a\n"
        },
        {
          "name": "build-ohos-arm64-v8a.sh",
          "type": "blob",
          "size": 5.5029296875,
          "content": "#!/usr/bin/env bash\nset -ex\n\ndir=$PWD/build-ohos-arm64-v8a\n\nmkdir -p $dir\ncd $dir\n\n# Please first download the commandline tools from\n# https://developer.huawei.com/consumer/cn/download/\n#\n# Example filename on Linux: commandline-tools-linux-x64-5.0.5.200.zip\n# You can also download it from https://hf-mirror.com/csukuangfj/harmonyos-commandline-tools/tree/main\n\n# mkdir /star-fj/fangjun/software/huawei\n# cd /star-fj/fangjun/software/huawei\n# wget https://hf-mirror.com/csukuangfj/harmonyos-commandline-tools/resolve/main/commandline-tools-linux-x64-5.0.5.200.zip\n# unzip commandline-tools-linux-x64-5.0.5.200.zip\n# rm commandline-tools-linux-x64-5.0.5.200.zip\nif [ -z $OHOS_SDK_NATIVE_DIR ]; then\n  OHOS_SDK_NATIVE_DIR=/star-fj/fangjun/software/huawei/command-line-tools/sdk/default/openharmony/native/\n  # You can find the following content inside OHOS_SDK_NATIVE_DIR\n  # ls -lh /star-fj/fangjun/software/huawei/command-line-tools/sdk/default/openharmony/native/\n  # total 524K\n  # -rw-r--r--  1 kuangfangjun root 501K Jan  1  2001 NOTICE.txt\n  # drwxr-xr-x  3 kuangfangjun root    0 Nov  6 22:36 build\n  # drwxr-xr-x  3 kuangfangjun root    0 Nov  6 22:36 build-tools\n  # -rw-r--r--  1 kuangfangjun root  371 Jan  1  2001 compatible_config.json\n  # drwxr-xr-x  4 kuangfangjun root    0 Nov  6 22:36 docs\n  # drwxr-xr-x 10 kuangfangjun root    0 Nov  6 22:36 llvm\n  # -rw-r--r--  1 kuangfangjun root  16K Jan  1  2001 nativeapi_syscap_config.json\n  # -rw-r--r--  1 kuangfangjun root 5.9K Jan  1  2001 ndk_system_capability.json\n  # -rw-r--r--  1 kuangfangjun root  167 Jan  1  2001 oh-uni-package.json\n  # drwxr-xr-x  3 kuangfangjun root    0 Nov  6 22:36 sysroot\nfi\n\nif [ ! -d $OHOS_SDK_NATIVE_DIR ]; then\n  OHOS_SDK_NATIVE_DIR=/Users/fangjun/software/command-line-tools/sdk/default/openharmony/native\n  # (py38) fangjuns-MacBook-Pro:software fangjun$ ls -lh command-line-tools/sdk/default/openharmony/native/\n  # total 752\n  # -rw-r--r--   1 fangjun  staff   341K Jan  1  2001 NOTICE.txt\n  # drwxr-xr-x   3 fangjun  staff    96B Nov  6 21:17 build\n  # drwxr-xr-x   3 fangjun  staff    96B Nov  6 21:18 build-tools\n  # -rw-r--r--   1 fangjun  staff   371B Jan  1  2001 compatible_config.json\n  # drwxr-xr-x  10 fangjun  staff   320B Nov  6 21:18 llvm\n  # -rw-r--r--   1 fangjun  staff    16K Jan  1  2001 nativeapi_syscap_config.json\n  # -rw-r--r--   1 fangjun  staff   5.9K Jan  1  2001 ndk_system_capability.json\n  # -rw-r--r--   1 fangjun  staff   167B Jan  1  2001 oh-uni-package.json\n  # drwxr-xr-x   3 fangjun  staff    96B Nov  6 21:17 sysroot\nfi\n\nif [ ! -d $OHOS_SDK_NATIVE_DIR ]; then\n  echo \"Please first download Command Line Tools for HarmonyOS\"\n  echo \"See https://developer.huawei.com/consumer/cn/download/\"\n  echo \"or\"\n  echo \"https://hf-mirror.com/csukuangfj/harmonyos-commandline-tools/tree/main\"\n  exit 1\nfi\n\nif [ ! -f $OHOS_SDK_NATIVE_DIR/llvm/bin/aarch64-unknown-linux-ohos-clang ]; then\n  echo \"$OHOS_SDK_NATIVE_DIR/llvm/bin/aarch64-unknown-linux-ohos-clang does not exist\"\n  echo \"Please first download Command Line Tools for HarmonyOS\"\n  echo \"See https://developer.huawei.com/consumer/cn/download/\"\n  echo \"or\"\n  echo \"https://hf-mirror.com/csukuangfj/harmonyos-commandline-tools/tree/main\"\n  exit 1\nfi\n\nexport PATH=$OHOS_SDK_NATIVE_DIR/build-tools/cmake/bin:$PATH\nexport PATH=$OHOS_SDK_NATIVE_DIR/llvm/bin:$PATH\n\nOHOS_TOOLCHAIN_FILE=$OHOS_SDK_NATIVE_DIR/build/cmake/ohos.toolchain.cmake\n\nif [ ! -f $OHOS_TOOLCHAIN_FILE ]; then\n  echo \"$OHOS_TOOLCHAIN_FILE does not exist\"\n  echo \"Please first download Command Line Tools for HarmonyOS\"\n  exit 1\nfi\n\nsleep 1\nonnxruntime_version=1.16.3\nonnxruntime_dir=onnxruntime-ohos-arm64-v8a-$onnxruntime_version\n\nif [ ! -f $onnxruntime_dir/lib/libonnxruntime.so ]; then\n  # wget -c  https://github.com/csukuangfj/onnxruntime-libs/releases/download/v${onnxruntime_version}/$onnxruntime_dir.zip\n  wget -c https://hf-mirror.com/csukuangfj/onnxruntime-libs/resolve/main/$onnxruntime_dir.zip\n  unzip $onnxruntime_dir.zip\n  rm $onnxruntime_dir.zip\nfi\n\nexport SHERPA_ONNXRUNTIME_LIB_DIR=$dir/$onnxruntime_dir/lib\nexport SHERPA_ONNXRUNTIME_INCLUDE_DIR=$dir/$onnxruntime_dir/include\n\necho \"SHERPA_ONNXRUNTIME_LIB_DIR: $SHERPA_ONNXRUNTIME_LIB_DIR\"\necho \"SHERPA_ONNXRUNTIME_INCLUDE_DIR $SHERPA_ONNXRUNTIME_INCLUDE_DIR\"\n\nif [ -z $SHERPA_ONNX_ENABLE_TTS ]; then\n  SHERPA_ONNX_ENABLE_TTS=ON\nfi\n\nif [ -z $SHERPA_ONNX_ENABLE_SPEAKER_DIARIZATION ]; then\n  SHERPA_ONNX_ENABLE_SPEAKER_DIARIZATION=ON\nfi\n\nif [ -z $SHERPA_ONNX_ENABLE_BINARY ]; then\n  SHERPA_ONNX_ENABLE_BINARY=OFF\nfi\n\ncmake \\\n    -DOHOS_ARCH=arm64-v8a \\\n    -DCMAKE_TOOLCHAIN_FILE=$OHOS_TOOLCHAIN_FILE \\\n    -DSHERPA_ONNX_ENABLE_TTS=$SHERPA_ONNX_ENABLE_TTS \\\n    -DSHERPA_ONNX_ENABLE_SPEAKER_DIARIZATION=$SHERPA_ONNX_ENABLE_SPEAKER_DIARIZATION \\\n    -DSHERPA_ONNX_ENABLE_BINARY=$SHERPA_ONNX_ENABLE_BINARY \\\n    -DBUILD_PIPER_PHONMIZE_EXE=OFF \\\n    -DBUILD_PIPER_PHONMIZE_TESTS=OFF \\\n    -DBUILD_ESPEAK_NG_EXE=OFF \\\n    -DBUILD_ESPEAK_NG_TESTS=OFF \\\n    -DCMAKE_BUILD_TYPE=Release \\\n    -DBUILD_SHARED_LIBS=ON \\\n    -DSHERPA_ONNX_ENABLE_PYTHON=OFF \\\n    -DSHERPA_ONNX_ENABLE_TESTS=OFF \\\n    -DSHERPA_ONNX_ENABLE_CHECK=OFF \\\n    -DSHERPA_ONNX_ENABLE_PORTAUDIO=OFF \\\n    -DSHERPA_ONNX_ENABLE_JNI=OFF \\\n    -DSHERPA_ONNX_ENABLE_C_API=ON \\\n    -DCMAKE_INSTALL_PREFIX=./install \\\n    ..\n\n# make VERBOSE=1 -j4\nmake -j2\nmake install/strip\ncp -fv $onnxruntime_dir/lib/libonnxruntime.so install/lib\n\nrm -rf install/share\nrm -rf install/lib/pkgconfig\n\nd=../harmony-os/SherpaOnnxHar/sherpa_onnx/src/main/cpp/libs/arm64-v8a\nif [ -d $d ]; then\n  cp -v install/lib/libsherpa-onnx-c-api.so $d/\n  cp -v install/lib/libonnxruntime.so $d/\nfi\n"
        },
        {
          "name": "build-ohos-armeabi-v7a.sh",
          "type": "blob",
          "size": 4.689453125,
          "content": "#!/usr/bin/env bash\nset -ex\n\ndir=$PWD/build-ohos-armeabi-v7a\n\nmkdir -p $dir\ncd $dir\n\n# Please first download the commandline tools from\n# https://developer.huawei.com/consumer/cn/download/\n#\n# Example filename on Linux: commandline-tools-linux-x64-5.0.5.200.zip\n# You can also download it from https://hf-mirror.com/csukuangfj/harmonyos-commandline-tools/tree/main\n\n# mkdir /star-fj/fangjun/software/huawei\n# cd /star-fj/fangjun/software/huawei\n# wget https://hf-mirror.com/csukuangfj/harmonyos-commandline-tools/resolve/main/commandline-tools-linux-x64-5.0.5.200.zip\n# unzip commandline-tools-linux-x64-5.0.5.200.zip\n# rm commandline-tools-linux-x64-5.0.5.200.zip\nif [ -z $OHOS_SDK_NATIVE_DIR ]; then\n  OHOS_SDK_NATIVE_DIR=/star-fj/fangjun/software/huawei/command-line-tools/sdk/default/openharmony/native/\n  export PATH=$OHOS_SDK_NATIVE_DIR/build-tools/cmake/bin:$PATH\n  # You can find the following content inside OHOS_SDK_NATIVE_DIR\n  # ls -lh /star-fj/fangjun/software/huawei/command-line-tools/sdk/default/openharmony/native/\n  # total 524K\n  # -rw-r--r--  1 kuangfangjun root 501K Jan  1  2001 NOTICE.txt\n  # drwxr-xr-x  3 kuangfangjun root    0 Nov  6 22:36 build\n  # drwxr-xr-x  3 kuangfangjun root    0 Nov  6 22:36 build-tools\n  # -rw-r--r--  1 kuangfangjun root  371 Jan  1  2001 compatible_config.json\n  # drwxr-xr-x  4 kuangfangjun root    0 Nov  6 22:36 docs\n  # drwxr-xr-x 10 kuangfangjun root    0 Nov  6 22:36 llvm\n  # -rw-r--r--  1 kuangfangjun root  16K Jan  1  2001 nativeapi_syscap_config.json\n  # -rw-r--r--  1 kuangfangjun root 5.9K Jan  1  2001 ndk_system_capability.json\n  # -rw-r--r--  1 kuangfangjun root  167 Jan  1  2001 oh-uni-package.json\n  # drwxr-xr-x  3 kuangfangjun root    0 Nov  6 22:36 sysroot\nfi\n\nif [ ! -d $OHOS_SDK_NATIVE_DIR ]; then\n  echo \"Please first download Command Line Tools for HarmonyOS\"\n  echo \"See https://developer.huawei.com/consumer/cn/download/\"\n  echo \"or\"\n  echo \"https://hf-mirror.com/csukuangfj/harmonyos-commandline-tools/tree/main\"\n  exit 1\nfi\n\nif [ ! -f $OHOS_SDK_NATIVE_DIR/llvm/bin/armv7-unknown-linux-ohos-clang ]; then\n  echo \"$OHOS_SDK_NATIVE_DIR/llvm/bin/armv7-unknown-linux-ohos-clang does not exist\"\n  echo \"Please first download Command Line Tools for HarmonyOS\"\n  echo \"See https://developer.huawei.com/consumer/cn/download/\"\n  echo \"or\"\n  echo \"https://hf-mirror.com/csukuangfj/harmonyos-commandline-tools/tree/main\"\n  exit 1\nfi\n\nexport PATH=$OHOS_SDK_NATIVE_DIR/build-tools/cmake/bin:$PATH\nexport PATH=$OHOS_SDK_NATIVE_DIR/llvm/bin:$PATH\n\nOHOS_TOOLCHAIN_FILE=$OHOS_SDK_NATIVE_DIR/build/cmake/ohos.toolchain.cmake\n\nif [ ! -f $OHOS_TOOLCHAIN_FILE ]; then\n  echo \"$OHOS_TOOLCHAIN_FILE does not exist\"\n  echo \"Please first download Command Line Tools for HarmonyOS\"\n  exit 1\nfi\n\nsleep 1\nonnxruntime_version=1.16.3\nonnxruntime_dir=onnxruntime-ohos-armeabi-v7a-$onnxruntime_version\n\nif [ ! -f $onnxruntime_dir/lib/libonnxruntime.so ]; then\n  # wget -c https://github.com/csukuangfj/onnxruntime-libs/releases/download/v${onnxruntime_version}/$onnxruntime_dir.zip\n  wget -c https://hf-mirror.com/csukuangfj/onnxruntime-libs/resolve/main/$onnxruntime_dir.zip\n  unzip $onnxruntime_dir.zip\n  rm $onnxruntime_dir.zip\nfi\n\nexport SHERPA_ONNXRUNTIME_LIB_DIR=$dir/$onnxruntime_dir/lib\nexport SHERPA_ONNXRUNTIME_INCLUDE_DIR=$dir/$onnxruntime_dir/include\n\necho \"SHERPA_ONNXRUNTIME_LIB_DIR: $SHERPA_ONNXRUNTIME_LIB_DIR\"\necho \"SHERPA_ONNXRUNTIME_INCLUDE_DIR $SHERPA_ONNXRUNTIME_INCLUDE_DIR\"\n\nif [ -z $SHERPA_ONNX_ENABLE_TTS ]; then\n  SHERPA_ONNX_ENABLE_TTS=ON\nfi\n\nif [ -z $SHERPA_ONNX_ENABLE_SPEAKER_DIARIZATION ]; then\n  SHERPA_ONNX_ENABLE_SPEAKER_DIARIZATION=ON\nfi\n\nif [ -z $SHERPA_ONNX_ENABLE_BINARY ]; then\n  SHERPA_ONNX_ENABLE_BINARY=OFF\nfi\n\n# See https://github.com/llvm/llvm-project/issues/57732\n# we need to use -mfloat-abi=hard\ncmake \\\n    -DOHOS_ARCH=armeabi-v7a \\\n    -DCMAKE_CXX_FLAGS=\"-mfloat-abi=hard\" \\\n    -DCMAKE_C_FLAGS=\"-mfloat-abi=hard\" \\\n    -DCMAKE_TOOLCHAIN_FILE=$OHOS_TOOLCHAIN_FILE \\\n    -DSHERPA_ONNX_ENABLE_TTS=$SHERPA_ONNX_ENABLE_TTS \\\n    -DSHERPA_ONNX_ENABLE_SPEAKER_DIARIZATION=$SHERPA_ONNX_ENABLE_SPEAKER_DIARIZATION \\\n    -DSHERPA_ONNX_ENABLE_BINARY=$SHERPA_ONNX_ENABLE_BINARY \\\n    -DBUILD_PIPER_PHONMIZE_EXE=OFF \\\n    -DBUILD_PIPER_PHONMIZE_TESTS=OFF \\\n    -DBUILD_ESPEAK_NG_EXE=OFF \\\n    -DBUILD_ESPEAK_NG_TESTS=OFF \\\n    -DCMAKE_BUILD_TYPE=Release \\\n    -DBUILD_SHARED_LIBS=ON \\\n    -DSHERPA_ONNX_ENABLE_PYTHON=OFF \\\n    -DSHERPA_ONNX_ENABLE_TESTS=OFF \\\n    -DSHERPA_ONNX_ENABLE_CHECK=OFF \\\n    -DSHERPA_ONNX_ENABLE_PORTAUDIO=OFF \\\n    -DSHERPA_ONNX_ENABLE_JNI=OFF \\\n    -DSHERPA_ONNX_ENABLE_C_API=ON \\\n    -DCMAKE_INSTALL_PREFIX=./install \\\n    ..\n\n# make VERBOSE=1 -j4\nmake -j2\nmake install/strip\ncp -fv $onnxruntime_dir/lib/libonnxruntime.so install/lib\n\nrm -rf install/share\nrm -rf install/lib/pkgconfig\n"
        },
        {
          "name": "build-ohos-x86-64.sh",
          "type": "blob",
          "size": 5.48828125,
          "content": "#!/usr/bin/env bash\nset -ex\n\ndir=$PWD/build-ohos-x86-64\n\nmkdir -p $dir\ncd $dir\n\n# Please first download the commandline tools from\n# https://developer.huawei.com/consumer/cn/download/\n#\n# Example filename on Linux: commandline-tools-linux-x64-5.0.5.200.zip\n# You can also download it from https://hf-mirror.com/csukuangfj/harmonyos-commandline-tools/tree/main\n\n# mkdir /star-fj/fangjun/software/huawei\n# cd /star-fj/fangjun/software/huawei\n# wget https://hf-mirror.com/csukuangfj/harmonyos-commandline-tools/resolve/main/commandline-tools-linux-x64-5.0.5.200.zip\n# unzip commandline-tools-linux-x64-5.0.5.200.zip\n# rm commandline-tools-linux-x64-5.0.5.200.zip\nif [ -z $OHOS_SDK_NATIVE_DIR ]; then\n  OHOS_SDK_NATIVE_DIR=/star-fj/fangjun/software/huawei/command-line-tools/sdk/default/openharmony/native/\n  # You can find the following content inside OHOS_SDK_NATIVE_DIR\n  # ls -lh /star-fj/fangjun/software/huawei/command-line-tools/sdk/default/openharmony/native/\n  # total 524K\n  # -rw-r--r--  1 kuangfangjun root 501K Jan  1  2001 NOTICE.txt\n  # drwxr-xr-x  3 kuangfangjun root    0 Nov  6 22:36 build\n  # drwxr-xr-x  3 kuangfangjun root    0 Nov  6 22:36 build-tools\n  # -rw-r--r--  1 kuangfangjun root  371 Jan  1  2001 compatible_config.json\n  # drwxr-xr-x  4 kuangfangjun root    0 Nov  6 22:36 docs\n  # drwxr-xr-x 10 kuangfangjun root    0 Nov  6 22:36 llvm\n  # -rw-r--r--  1 kuangfangjun root  16K Jan  1  2001 nativeapi_syscap_config.json\n  # -rw-r--r--  1 kuangfangjun root 5.9K Jan  1  2001 ndk_system_capability.json\n  # -rw-r--r--  1 kuangfangjun root  167 Jan  1  2001 oh-uni-package.json\n  # drwxr-xr-x  3 kuangfangjun root    0 Nov  6 22:36 sysroot\nfi\n\nif [ ! -d $OHOS_SDK_NATIVE_DIR ]; then\n  OHOS_SDK_NATIVE_DIR=/Users/fangjun/software/command-line-tools/sdk/default/openharmony/native\n  # (py38) fangjuns-MacBook-Pro:software fangjun$ ls -lh command-line-tools/sdk/default/openharmony/native/\n  # total 752\n  # -rw-r--r--   1 fangjun  staff   341K Jan  1  2001 NOTICE.txt\n  # drwxr-xr-x   3 fangjun  staff    96B Nov  6 21:17 build\n  # drwxr-xr-x   3 fangjun  staff    96B Nov  6 21:18 build-tools\n  # -rw-r--r--   1 fangjun  staff   371B Jan  1  2001 compatible_config.json\n  # drwxr-xr-x  10 fangjun  staff   320B Nov  6 21:18 llvm\n  # -rw-r--r--   1 fangjun  staff    16K Jan  1  2001 nativeapi_syscap_config.json\n  # -rw-r--r--   1 fangjun  staff   5.9K Jan  1  2001 ndk_system_capability.json\n  # -rw-r--r--   1 fangjun  staff   167B Jan  1  2001 oh-uni-package.json\n  # drwxr-xr-x   3 fangjun  staff    96B Nov  6 21:17 sysroot\nfi\n\nif [ ! -d $OHOS_SDK_NATIVE_DIR ]; then\n  echo \"Please first download Command Line Tools for HarmonyOS\"\n  echo \"See https://developer.huawei.com/consumer/cn/download/\"\n  echo \"or\"\n  echo \"https://hf-mirror.com/csukuangfj/harmonyos-commandline-tools/tree/main\"\n  exit 1\nfi\n\nif [ ! -f $OHOS_SDK_NATIVE_DIR/llvm/bin/x86_64-unknown-linux-ohos-clang ]; then\n  echo \"$OHOS_SDK_NATIVE_DIR/llvm/bin/x86_64-unknown-linux-ohos-clang does not exist\"\n  echo \"Please first download Command Line Tools for HarmonyOS\"\n  echo \"See https://developer.huawei.com/consumer/cn/download/\"\n  echo \"or\"\n  echo \"https://hf-mirror.com/csukuangfj/harmonyos-commandline-tools/tree/main\"\n  exit 1\nfi\n\nexport PATH=$OHOS_SDK_NATIVE_DIR/build-tools/cmake/bin:$PATH\nexport PATH=$OHOS_SDK_NATIVE_DIR/llvm/bin:$PATH\n\nOHOS_TOOLCHAIN_FILE=$OHOS_SDK_NATIVE_DIR/build/cmake/ohos.toolchain.cmake\n\nif [ ! -f $OHOS_TOOLCHAIN_FILE ]; then\n  echo \"$OHOS_TOOLCHAIN_FILE does not exist\"\n  echo \"Please first download Command Line Tools for HarmonyOS\"\n  exit 1\nfi\n\nsleep 1\nonnxruntime_version=1.16.3\nonnxruntime_dir=onnxruntime-ohos-x86_64-$onnxruntime_version\n\nif [ ! -f $onnxruntime_dir/lib/libonnxruntime.so ]; then\n  # wget -c https://github.com/csukuangfj/onnxruntime-libs/releases/download/v${onnxruntime_version}/$onnxruntime_dir.zip\n  wget -c https://hf-mirror.com/csukuangfj/onnxruntime-libs/resolve/main/$onnxruntime_dir.zip\n  unzip $onnxruntime_dir.zip\n  rm $onnxruntime_dir.zip\nfi\n\nexport SHERPA_ONNXRUNTIME_LIB_DIR=$dir/$onnxruntime_dir/lib\nexport SHERPA_ONNXRUNTIME_INCLUDE_DIR=$dir/$onnxruntime_dir/include\n\necho \"SHERPA_ONNXRUNTIME_LIB_DIR: $SHERPA_ONNXRUNTIME_LIB_DIR\"\necho \"SHERPA_ONNXRUNTIME_INCLUDE_DIR $SHERPA_ONNXRUNTIME_INCLUDE_DIR\"\n\nif [ -z $SHERPA_ONNX_ENABLE_TTS ]; then\n  SHERPA_ONNX_ENABLE_TTS=ON\nfi\n\nif [ -z $SHERPA_ONNX_ENABLE_SPEAKER_DIARIZATION ]; then\n  SHERPA_ONNX_ENABLE_SPEAKER_DIARIZATION=ON\nfi\n\nif [ -z $SHERPA_ONNX_ENABLE_BINARY ]; then\n  SHERPA_ONNX_ENABLE_BINARY=OFF\nfi\n\ncmake \\\n    -DOHOS_ARCH=x86_64 \\\n    -DCMAKE_TOOLCHAIN_FILE=$OHOS_TOOLCHAIN_FILE \\\n    -DSHERPA_ONNX_ENABLE_TTS=$SHERPA_ONNX_ENABLE_TTS \\\n    -DSHERPA_ONNX_ENABLE_SPEAKER_DIARIZATION=$SHERPA_ONNX_ENABLE_SPEAKER_DIARIZATION \\\n    -DSHERPA_ONNX_ENABLE_BINARY=$SHERPA_ONNX_ENABLE_BINARY \\\n    -DBUILD_PIPER_PHONMIZE_EXE=OFF \\\n    -DBUILD_PIPER_PHONMIZE_TESTS=OFF \\\n    -DBUILD_ESPEAK_NG_EXE=OFF \\\n    -DBUILD_ESPEAK_NG_TESTS=OFF \\\n    -DCMAKE_BUILD_TYPE=Release \\\n    -DBUILD_SHARED_LIBS=ON \\\n    -DSHERPA_ONNX_ENABLE_PYTHON=OFF \\\n    -DSHERPA_ONNX_ENABLE_TESTS=OFF \\\n    -DSHERPA_ONNX_ENABLE_CHECK=OFF \\\n    -DSHERPA_ONNX_ENABLE_PORTAUDIO=OFF \\\n    -DSHERPA_ONNX_ENABLE_JNI=OFF \\\n    -DSHERPA_ONNX_ENABLE_C_API=ON \\\n    -DCMAKE_INSTALL_PREFIX=./install \\\n    ..\n\n# make VERBOSE=1 -j4\nmake -j2\nmake install/strip\ncp -fv $onnxruntime_dir/lib/libonnxruntime.so install/lib\n\nrm -rf install/share\nrm -rf install/lib/pkgconfig\n\nd=../harmony-os/SherpaOnnxHar/sherpa_onnx/src/main/cpp/libs/x86_64\nif [ -d $d ]; then\n  cp -v install/lib/libsherpa-onnx-c-api.so $d/\n  cp -v install/lib/libonnxruntime.so $d/\nfi\n"
        },
        {
          "name": "build-riscv64-linux-gnu.sh",
          "type": "blob",
          "size": 2.2724609375,
          "content": "#!/usr/bin/env bash\nset -ex\n\nif ! command -v riscv64-unknown-linux-gnu-g++  &> /dev/null; then\n  echo \"Please install the toolchain first.\"\n  echo\n  echo \"You can use the following command to install the toolchain:\"\n  echo\n  echo \"  mkdir -p $HOME/software\"\n  echo \"  cd $HOME/software\"\n  echo \"  mkdir riscv64-glibc-ubuntu-18.04-nightly-2022.11.12-nightly\"\n  echo \"  cd riscv64-glibc-ubuntu-18.04-nightly-2022.11.12-nightly\"\n  echo \"  wget https://github.com/riscv-collab/riscv-gnu-toolchain/releases/download/2022.11.12/riscv64-glibc-ubuntu-18.04-nightly-2022.11.12-nightly.tar.gz\"\n  echo \"  tar xvf riscv64-glibc-ubuntu-18.04-nightly-2022.11.12-nightly.tar.gz --strip-components=1\"\n  echo \"  export PATH=$HOME/software/riscv64-glibc-ubuntu-18.04-nightly-2022.11.12-nightly/bin\"\n  echo\n  exit 1\nfi\n\nif [ x$dir = x\"\" ]; then\n  dir=build-riscv64-linux-gnu\nfi\nmkdir -p $dir\ncd $dir\n\nif [ ! -f alsa-lib/src/.libs/libasound.so ]; then\n  echo \"Start to cross-compile alsa-lib\"\n  if [ ! -d alsa-lib ]; then\n    git clone --depth 1 --branch v1.2.12 https://github.com/alsa-project/alsa-lib\n  fi\n  # If it shows:\n  #  ./gitcompile: line 79: libtoolize: command not found\n  # Please use:\n  #  sudo apt-get install libtool m4 automake\n  #\n  pushd alsa-lib\n  CC=riscv64-unknown-linux-gnu-gcc ./gitcompile --host=riscv64-unknown-linux-gnu\n  popd\n  echo \"Finish cross-compiling alsa-lib\"\nfi\n\nexport CPLUS_INCLUDE_PATH=$PWD/alsa-lib/include:$CPLUS_INCLUDE_PATH\nexport SHERPA_ONNX_ALSA_LIB_DIR=$PWD/alsa-lib/src/.libs\n\nif [[ x\"$BUILD_SHARED_LIBS\" == x\"\" ]]; then\n  # By default, use shared libraries\n  BUILD_SHARED_LIBS=ON\nfi\n\ncmake \\\n  -DBUILD_PIPER_PHONMIZE_EXE=OFF \\\n  -DBUILD_PIPER_PHONMIZE_TESTS=OFF \\\n  -DBUILD_ESPEAK_NG_EXE=OFF \\\n  -DBUILD_ESPEAK_NG_TESTS=OFF \\\n  -DCMAKE_INSTALL_PREFIX=./install \\\n  -DCMAKE_BUILD_TYPE=Release \\\n  -DBUILD_SHARED_LIBS=$BUILD_SHARED_LIBS \\\n  -DSHERPA_ONNX_ENABLE_TESTS=OFF \\\n  -DSHERPA_ONNX_ENABLE_PYTHON=OFF \\\n  -DSHERPA_ONNX_ENABLE_CHECK=OFF \\\n  -DSHERPA_ONNX_ENABLE_PORTAUDIO=OFF \\\n  -DSHERPA_ONNX_ENABLE_JNI=OFF \\\n  -DSHERPA_ONNX_ENABLE_C_API=OFF \\\n  -DSHERPA_ONNX_ENABLE_WEBSOCKET=ON \\\n  -DCMAKE_TOOLCHAIN_FILE=../toolchains/riscv64-linux-gnu.toolchain.cmake \\\n  ..\n\nmake VERBOSE=1 -j4\nmake install/strip\n\n# Enable it if only needed\n# cp -v $SHERPA_ONNX_ALSA_LIB_DIR/libasound.so* ./install/lib/\n"
        },
        {
          "name": "build-swift-macos.sh",
          "type": "blob",
          "size": 1.2294921875,
          "content": "#!/usr/bin/env  bash\n\nset -ex\n\ndir=build-swift-macos\nmkdir -p $dir\ncd $dir\n\ncmake \\\n  -DSHERPA_ONNX_ENABLE_BINARY=OFF \\\n  -DSHERPA_ONNX_BUILD_C_API_EXAMPLES=OFF \\\n  -DCMAKE_OSX_ARCHITECTURES=\"arm64;x86_64\" \\\n  -DCMAKE_INSTALL_PREFIX=./install \\\n  -DCMAKE_BUILD_TYPE=Release \\\n  -DBUILD_SHARED_LIBS=OFF \\\n  -DSHERPA_ONNX_ENABLE_PYTHON=OFF \\\n  -DSHERPA_ONNX_ENABLE_TESTS=OFF \\\n  -DSHERPA_ONNX_ENABLE_CHECK=OFF \\\n  -DSHERPA_ONNX_ENABLE_PORTAUDIO=OFF \\\n  -DSHERPA_ONNX_ENABLE_JNI=OFF \\\n  -DSHERPA_ONNX_ENABLE_C_API=ON \\\n  -DSHERPA_ONNX_ENABLE_WEBSOCKET=OFF \\\n  ../\n\nmake VERBOSE=1 -j4\nmake install\nrm -fv ./install/include/cargs.h\n\nlibtool -static -o ./install/lib/libsherpa-onnx.a \\\n  ./install/lib/libsherpa-onnx-c-api.a \\\n  ./install/lib/libsherpa-onnx-core.a \\\n  ./install/lib/libkaldi-native-fbank-core.a \\\n  ./install/lib/libsherpa-onnx-fstfar.a \\\n  ./install/lib/libsherpa-onnx-fst.a \\\n  ./install/lib/libsherpa-onnx-kaldifst-core.a \\\n  ./install/lib/libkaldi-decoder-core.a \\\n  ./install/lib/libucd.a \\\n  ./install/lib/libpiper_phonemize.a \\\n  ./install/lib/libespeak-ng.a \\\n  ./install/lib/libssentencepiece_core.a\n\nxcodebuild -create-xcframework \\\n  -library install/lib/libsherpa-onnx.a \\\n  -headers install/include \\\n  -output sherpa-onnx.xcframework\n"
        },
        {
          "name": "build-wasm-simd-asr.sh",
          "type": "blob",
          "size": 1.6982421875,
          "content": "#!/usr/bin/env bash\n# Copyright (c)  2024  Xiaomi Corporation\n#\n# This script is to build sherpa-onnx for WebAssembly (ASR)\n\nset -ex\n\nif [ x\"$EMSCRIPTEN\" == x\"\" ]; then\n  if ! command -v emcc &> /dev/null; then\n    echo \"Please install emscripten first\"\n    echo \"\"\n    echo \"You can use the following commands to install it:\"\n    echo \"\"\n    echo \"git clone https://github.com/emscripten-core/emsdk.git\"\n    echo \"cd emsdk\"\n    echo \"git pull\"\n    echo \"./emsdk install 3.1.53\"\n    echo \"./emsdk activate 3.1.53\"\n    echo \"source ./emsdk_env.sh\"\n    exit 1\n  else\n    EMSCRIPTEN=$(dirname $(realpath $(which emcc)))\n    emcc --version\n  fi\nfi\n\nexport EMSCRIPTEN=$EMSCRIPTEN\necho \"EMSCRIPTEN: $EMSCRIPTEN\"\nif [ ! -f $EMSCRIPTEN/cmake/Modules/Platform/Emscripten.cmake ]; then\n  echo \"Cannot find $EMSCRIPTEN/cmake/Modules/Platform/Emscripten.cmake\"\n  echo \"Please make sure you have installed emsdk correctly\"\n  exit 1\nfi\n\nmkdir -p build-wasm-simd-asr\npushd build-wasm-simd-asr\n\nexport SHERPA_ONNX_IS_USING_BUILD_WASM_SH=ON\n\ncmake \\\n  -DCMAKE_INSTALL_PREFIX=./install \\\n  -DCMAKE_BUILD_TYPE=Release \\\n  -DCMAKE_TOOLCHAIN_FILE=$EMSCRIPTEN/cmake/Modules/Platform/Emscripten.cmake \\\n  \\\n  -DSHERPA_ONNX_ENABLE_PYTHON=OFF \\\n  -DSHERPA_ONNX_ENABLE_TESTS=OFF \\\n  -DSHERPA_ONNX_ENABLE_CHECK=OFF \\\n  -DBUILD_SHARED_LIBS=OFF \\\n  -DSHERPA_ONNX_ENABLE_PORTAUDIO=OFF \\\n  -DSHERPA_ONNX_ENABLE_JNI=OFF \\\n  -DSHERPA_ONNX_ENABLE_C_API=ON \\\n  -DSHERPA_ONNX_ENABLE_TTS=OFF \\\n  -DSHERPA_ONNX_ENABLE_WEBSOCKET=OFF \\\n  -DSHERPA_ONNX_ENABLE_GPU=OFF \\\n  -DSHERPA_ONNX_ENABLE_WASM=ON \\\n  -DSHERPA_ONNX_ENABLE_WASM_ASR=ON \\\n  -DSHERPA_ONNX_ENABLE_BINARY=OFF \\\n  -DSHERPA_ONNX_LINK_LIBSTDCPP_STATICALLY=OFF \\\n  ..\nmake -j2\nmake install\n\nls -lh install/bin/wasm/asr\n"
        },
        {
          "name": "build-wasm-simd-kws.sh",
          "type": "blob",
          "size": 1.5849609375,
          "content": "#!/usr/bin/env  bash\n\nif [ x\"$EMSCRIPTEN\" == x\"\" ]; then\n  if ! command -v emcc &> /dev/null; then\n    echo \"Please install emscripten first\"\n    echo \"\"\n    echo \"You can use the following commands to install it:\"\n    echo \"\"\n    echo \"git clone https://github.com/emscripten-core/emsdk.git\"\n    echo \"cd emsdk\"\n    echo \"git pull\"\n    echo \"./emsdk install 3.1.53\"\n    echo \"./emsdk activate 3.1.53\"\n    echo \"source ./emsdk_env.sh\"\n    exit 1\n  else\n    EMSCRIPTEN=$(dirname $(realpath $(which emcc)))\n    emcc --version\n  fi\nfi\n\nexport EMSCRIPTEN=$EMSCRIPTEN\necho \"EMSCRIPTEN: $EMSCRIPTEN\"\nif [ ! -f $EMSCRIPTEN/cmake/Modules/Platform/Emscripten.cmake ]; then\n  echo \"Cannot find $EMSCRIPTEN/cmake/Modules/Platform/Emscripten.cmake\"\n  echo \"Please make sure you have installed emsdk correctly\"\n  exit 1\nfi\n\nmkdir -p build-wasm-simd-kws\npushd build-wasm-simd-kws\n\nexport SHERPA_ONNX_IS_USING_BUILD_WASM_SH=ON\n\ncmake \\\n  -DCMAKE_INSTALL_PREFIX=./install \\\n  -DCMAKE_BUILD_TYPE=Release \\\n  -DCMAKE_TOOLCHAIN_FILE=$EMSCRIPTEN/cmake/Modules/Platform/Emscripten.cmake \\\n  \\\n  -DSHERPA_ONNX_ENABLE_PYTHON=OFF \\\n  -DSHERPA_ONNX_ENABLE_TESTS=OFF \\\n  -DSHERPA_ONNX_ENABLE_CHECK=OFF \\\n  -DBUILD_SHARED_LIBS=OFF \\\n  -DSHERPA_ONNX_ENABLE_PORTAUDIO=OFF \\\n  -DSHERPA_ONNX_ENABLE_JNI=OFF \\\n  -DSHERPA_ONNX_ENABLE_C_API=ON \\\n  -DSHERPA_ONNX_ENABLE_TTS=OFF \\\n  -DSHERPA_ONNX_ENABLE_WEBSOCKET=OFF \\\n  -DSHERPA_ONNX_ENABLE_GPU=OFF \\\n  -DSHERPA_ONNX_ENABLE_WASM=ON \\\n  -DSHERPA_ONNX_ENABLE_WASM_KWS=ON \\\n  -DSHERPA_ONNX_ENABLE_BINARY=OFF \\\n  -DSHERPA_ONNX_LINK_LIBSTDCPP_STATICALLY=OFF \\\n  ..\nmake -j8\nmake install\n\nls -lh install/bin/wasm\n"
        },
        {
          "name": "build-wasm-simd-nodejs.sh",
          "type": "blob",
          "size": 1.7080078125,
          "content": "#!/usr/bin/env bash\n# Copyright (c)  2024  Xiaomi Corporation\n#\n# This script is to build sherpa-onnx for WebAssembly (NodeJS)\n#\n# Please use NodeJS >= 18\n\nset -ex\n\nif [ x\"$EMSCRIPTEN\" == x\"\" ]; then\n  if ! command -v emcc &> /dev/null; then\n    echo \"Please install emscripten first\"\n    echo \"\"\n    echo \"You can use the following commands to install it:\"\n    echo \"\"\n    echo \"git clone https://github.com/emscripten-core/emsdk.git\"\n    echo \"cd emsdk\"\n    echo \"git pull\"\n    echo \"./emsdk install 3.1.53\"\n    echo \"./emsdk activate 3.1.53\"\n    echo \"source ./emsdk_env.sh\"\n    exit 1\n  else\n    EMSCRIPTEN=$(dirname $(realpath $(which emcc)))\n    emcc --version\n  fi\nfi\n\nexport EMSCRIPTEN=$EMSCRIPTEN\necho \"EMSCRIPTEN: $EMSCRIPTEN\"\nif [ ! -f $EMSCRIPTEN/cmake/Modules/Platform/Emscripten.cmake ]; then\n  echo \"Cannot find $EMSCRIPTEN/cmake/Modules/Platform/Emscripten.cmake\"\n  echo \"Please make sure you have installed emsdk correctly\"\n  exit 1\nfi\n\nmkdir -p build-wasm-simd-nodejs\npushd build-wasm-simd-nodejs\n\nexport SHERPA_ONNX_IS_USING_BUILD_WASM_SH=ON\n\ncmake \\\n  -DCMAKE_INSTALL_PREFIX=./install \\\n  -DCMAKE_BUILD_TYPE=Release \\\n  -DCMAKE_TOOLCHAIN_FILE=$EMSCRIPTEN/cmake/Modules/Platform/Emscripten.cmake \\\n  \\\n  -DSHERPA_ONNX_ENABLE_PYTHON=OFF \\\n  -DSHERPA_ONNX_ENABLE_TESTS=OFF \\\n  -DSHERPA_ONNX_ENABLE_CHECK=OFF \\\n  -DBUILD_SHARED_LIBS=OFF \\\n  -DSHERPA_ONNX_ENABLE_PORTAUDIO=OFF \\\n  -DSHERPA_ONNX_ENABLE_JNI=OFF \\\n  -DSHERPA_ONNX_ENABLE_C_API=ON \\\n  -DSHERPA_ONNX_ENABLE_WEBSOCKET=OFF \\\n  -DSHERPA_ONNX_ENABLE_GPU=OFF \\\n  -DSHERPA_ONNX_ENABLE_WASM=ON \\\n  -DSHERPA_ONNX_ENABLE_WASM_NODEJS=ON \\\n  -DSHERPA_ONNX_ENABLE_BINARY=OFF \\\n  -DSHERPA_ONNX_LINK_LIBSTDCPP_STATICALLY=OFF \\\n  ..\nmake -j3\nmake install\n\nls -lh install/bin/wasm/nodejs\n"
        },
        {
          "name": "build-wasm-simd-speaker-diarization.sh",
          "type": "blob",
          "size": 1.744140625,
          "content": "#!/usr/bin/env bash\n# Copyright (c)  2024  Xiaomi Corporation\n#\n# This script is to build sherpa-onnx for WebAssembly (speaker diarization)\n\nset -ex\n\nif [ x\"$EMSCRIPTEN\" == x\"\" ]; then\n  if ! command -v emcc &> /dev/null; then\n    echo \"Please install emscripten first\"\n    echo \"\"\n    echo \"You can use the following commands to install it:\"\n    echo \"\"\n    echo \"git clone https://github.com/emscripten-core/emsdk.git\"\n    echo \"cd emsdk\"\n    echo \"git pull\"\n    echo \"./emsdk install 3.1.53\"\n    echo \"./emsdk activate 3.1.53\"\n    echo \"source ./emsdk_env.sh\"\n    exit 1\n  else\n    EMSCRIPTEN=$(dirname $(realpath $(which emcc)))\n    emcc --version\n  fi\nfi\n\nexport EMSCRIPTEN=$EMSCRIPTEN\necho \"EMSCRIPTEN: $EMSCRIPTEN\"\nif [ ! -f $EMSCRIPTEN/cmake/Modules/Platform/Emscripten.cmake ]; then\n  echo \"Cannot find $EMSCRIPTEN/cmake/Modules/Platform/Emscripten.cmake\"\n  echo \"Please make sure you have installed emsdk correctly\"\n  exit 1\nfi\n\nmkdir -p build-wasm-simd-speaker-diarization\npushd build-wasm-simd-speaker-diarization\n\nexport SHERPA_ONNX_IS_USING_BUILD_WASM_SH=ON\n\ncmake \\\n  -DCMAKE_INSTALL_PREFIX=./install \\\n  -DCMAKE_BUILD_TYPE=Release \\\n  -DCMAKE_TOOLCHAIN_FILE=$EMSCRIPTEN/cmake/Modules/Platform/Emscripten.cmake \\\n  \\\n  -DSHERPA_ONNX_ENABLE_PYTHON=OFF \\\n  -DSHERPA_ONNX_ENABLE_TESTS=OFF \\\n  -DSHERPA_ONNX_ENABLE_CHECK=OFF \\\n  -DBUILD_SHARED_LIBS=OFF \\\n  -DSHERPA_ONNX_ENABLE_PORTAUDIO=OFF \\\n  -DSHERPA_ONNX_ENABLE_JNI=OFF \\\n  -DSHERPA_ONNX_ENABLE_C_API=ON \\\n  -DSHERPA_ONNX_ENABLE_WEBSOCKET=OFF \\\n  -DSHERPA_ONNX_ENABLE_GPU=OFF \\\n  -DSHERPA_ONNX_ENABLE_WASM=ON \\\n  -DSHERPA_ONNX_ENABLE_WASM_SPEAKER_DIARIZATION=ON \\\n  -DSHERPA_ONNX_ENABLE_BINARY=OFF \\\n  -DSHERPA_ONNX_LINK_LIBSTDCPP_STATICALLY=OFF \\\n  ..\nmake -j2\nmake install\n\nls -lh install/bin/wasm/speaker-diarization\n"
        },
        {
          "name": "build-wasm-simd-tts.sh",
          "type": "blob",
          "size": 1.666015625,
          "content": "#!/usr/bin/env bash\n# Copyright (c)  2024  Xiaomi Corporation\n#\n# This script is to build sherpa-onnx for WebAssembly (TTS)\n\nset -ex\n\nif [ x\"$EMSCRIPTEN\" == x\"\" ]; then\n  if ! command -v emcc &> /dev/null; then\n    echo \"Please install emscripten first\"\n    echo \"\"\n    echo \"You can use the following commands to install it:\"\n    echo \"\"\n    echo \"git clone https://github.com/emscripten-core/emsdk.git\"\n    echo \"cd emsdk\"\n    echo \"git pull\"\n    echo \"./emsdk install 3.1.53\"\n    echo \"./emsdk activate 3.1.53\"\n    echo \"source ./emsdk_env.sh\"\n    exit 1\n  else\n    EMSCRIPTEN=$(dirname $(realpath $(which emcc)))\n    emcc --version\n  fi\nfi\n\nexport EMSCRIPTEN=$EMSCRIPTEN\necho \"EMSCRIPTEN: $EMSCRIPTEN\"\nif [ ! -f $EMSCRIPTEN/cmake/Modules/Platform/Emscripten.cmake ]; then\n  echo \"Cannot find $EMSCRIPTEN/cmake/Modules/Platform/Emscripten.cmake\"\n  echo \"Please make sure you have installed emsdk correctly\"\n  exit 1\nfi\n\nmkdir -p build-wasm-simd-tts\npushd build-wasm-simd-tts\n\nexport SHERPA_ONNX_IS_USING_BUILD_WASM_SH=ON\n\ncmake \\\n  -DCMAKE_INSTALL_PREFIX=./install \\\n  -DCMAKE_BUILD_TYPE=Release \\\n  -DCMAKE_TOOLCHAIN_FILE=$EMSCRIPTEN/cmake/Modules/Platform/Emscripten.cmake \\\n  \\\n  -DSHERPA_ONNX_ENABLE_PYTHON=OFF \\\n  -DSHERPA_ONNX_ENABLE_TESTS=OFF \\\n  -DSHERPA_ONNX_ENABLE_CHECK=OFF \\\n  -DBUILD_SHARED_LIBS=OFF \\\n  -DSHERPA_ONNX_ENABLE_PORTAUDIO=OFF \\\n  -DSHERPA_ONNX_ENABLE_JNI=OFF \\\n  -DSHERPA_ONNX_ENABLE_C_API=ON \\\n  -DSHERPA_ONNX_ENABLE_WEBSOCKET=OFF \\\n  -DSHERPA_ONNX_ENABLE_GPU=OFF \\\n  -DSHERPA_ONNX_ENABLE_WASM=ON \\\n  -DSHERPA_ONNX_ENABLE_WASM_TTS=ON \\\n  -DSHERPA_ONNX_ENABLE_BINARY=OFF \\\n  -DSHERPA_ONNX_LINK_LIBSTDCPP_STATICALLY=OFF \\\n  ..\nmake -j2\nmake install\n\nls -lh install/bin/wasm/tts\n"
        },
        {
          "name": "build-wasm-simd-vad-asr.sh",
          "type": "blob",
          "size": 1.9052734375,
          "content": "#!/usr/bin/env bash\n# Copyright (c)  2024  Xiaomi Corporation\n#\n# This script is to build sherpa-onnx for WebAssembly (VAD+ASR)\n# Note: ASR here means non-streaming ASR\n\nset -ex\n\nif [ x\"$EMSCRIPTEN\" == x\"\" ]; then\n  if ! command -v emcc &> /dev/null; then\n    echo \"Please install emscripten first\"\n    echo \"\"\n    echo \"You can use the following commands to install it:\"\n    echo \"\"\n    echo \"git clone https://github.com/emscripten-core/emsdk.git\"\n    echo \"cd emsdk\"\n    echo \"git pull\"\n    echo \"./emsdk install 3.1.53\"\n    echo \"./emsdk activate 3.1.53\"\n    echo \"source ./emsdk_env.sh\"\n    exit 1\n  else\n    EMSCRIPTEN=$(dirname $(realpath $(which emcc)))\n    emcc --version\n  fi\nfi\n\nexport EMSCRIPTEN=$EMSCRIPTEN\necho \"EMSCRIPTEN: $EMSCRIPTEN\"\nif [ ! -f $EMSCRIPTEN/cmake/Modules/Platform/Emscripten.cmake ]; then\n  echo \"Cannot find $EMSCRIPTEN/cmake/Modules/Platform/Emscripten.cmake\"\n  echo \"Please make sure you have installed emsdk correctly\"\n  exit 1\nfi\n\nmkdir -p build-wasm-simd-vad-asr\npushd build-wasm-simd-vad-asr\n\nexport SHERPA_ONNX_IS_USING_BUILD_WASM_SH=ON\n\ncmake \\\n  -DCMAKE_INSTALL_PREFIX=./install \\\n  -DCMAKE_BUILD_TYPE=Release \\\n  -DCMAKE_TOOLCHAIN_FILE=$EMSCRIPTEN/cmake/Modules/Platform/Emscripten.cmake \\\n  \\\n  -DSHERPA_ONNX_ENABLE_PYTHON=OFF \\\n  -DSHERPA_ONNX_ENABLE_TESTS=OFF \\\n  -DSHERPA_ONNX_ENABLE_CHECK=OFF \\\n  -DBUILD_SHARED_LIBS=OFF \\\n  -DSHERPA_ONNX_ENABLE_PORTAUDIO=OFF \\\n  -DSHERPA_ONNX_ENABLE_JNI=OFF \\\n  -DSHERPA_ONNX_ENABLE_TTS=OFF \\\n  -DSHERPA_ONNX_ENABLE_C_API=ON \\\n  -DSHERPA_ONNX_ENABLE_WEBSOCKET=OFF \\\n  -DSHERPA_ONNX_ENABLE_GPU=OFF \\\n  -DSHERPA_ONNX_ENABLE_WASM=ON \\\n  -DSHERPA_ONNX_ENABLE_WASM_VAD_ASR=ON \\\n  -DSHERPA_ONNX_ENABLE_BINARY=OFF \\\n  -DSHERPA_ONNX_LINK_LIBSTDCPP_STATICALLY=OFF \\\n  ..\nmake -j2\nmake install\n\necho \"pwd: $PWD\"\n\ncp -fv ../wasm/vad/sherpa-onnx-vad.js ./install/bin/wasm/vad-asr/\ncp -fv ../wasm/asr/sherpa-onnx-asr.js ./install/bin/wasm/vad-asr/\n\nls -lh install/bin/wasm/vad-asr\n"
        },
        {
          "name": "build-wasm-simd-vad.sh",
          "type": "blob",
          "size": 1.6982421875,
          "content": "#!/usr/bin/env bash\n# Copyright (c)  2024  Xiaomi Corporation\n#\n# This script is to build sherpa-onnx for WebAssembly (VAD)\n\nset -ex\n\nif [ x\"$EMSCRIPTEN\" == x\"\" ]; then\n  if ! command -v emcc &> /dev/null; then\n    echo \"Please install emscripten first\"\n    echo \"\"\n    echo \"You can use the following commands to install it:\"\n    echo \"\"\n    echo \"git clone https://github.com/emscripten-core/emsdk.git\"\n    echo \"cd emsdk\"\n    echo \"git pull\"\n    echo \"./emsdk install 3.1.53\"\n    echo \"./emsdk activate 3.1.53\"\n    echo \"source ./emsdk_env.sh\"\n    exit 1\n  else\n    EMSCRIPTEN=$(dirname $(realpath $(which emcc)))\n    emcc --version\n  fi\nfi\n\nexport EMSCRIPTEN=$EMSCRIPTEN\necho \"EMSCRIPTEN: $EMSCRIPTEN\"\nif [ ! -f $EMSCRIPTEN/cmake/Modules/Platform/Emscripten.cmake ]; then\n  echo \"Cannot find $EMSCRIPTEN/cmake/Modules/Platform/Emscripten.cmake\"\n  echo \"Please make sure you have installed emsdk correctly\"\n  exit 1\nfi\n\nmkdir -p build-wasm-simd-vad\npushd build-wasm-simd-vad\n\nexport SHERPA_ONNX_IS_USING_BUILD_WASM_SH=ON\n\ncmake \\\n  -DCMAKE_INSTALL_PREFIX=./install \\\n  -DCMAKE_BUILD_TYPE=Release \\\n  -DCMAKE_TOOLCHAIN_FILE=$EMSCRIPTEN/cmake/Modules/Platform/Emscripten.cmake \\\n  \\\n  -DSHERPA_ONNX_ENABLE_PYTHON=OFF \\\n  -DSHERPA_ONNX_ENABLE_TESTS=OFF \\\n  -DSHERPA_ONNX_ENABLE_CHECK=OFF \\\n  -DBUILD_SHARED_LIBS=OFF \\\n  -DSHERPA_ONNX_ENABLE_PORTAUDIO=OFF \\\n  -DSHERPA_ONNX_ENABLE_JNI=OFF \\\n  -DSHERPA_ONNX_ENABLE_TTS=OFF \\\n  -DSHERPA_ONNX_ENABLE_C_API=ON \\\n  -DSHERPA_ONNX_ENABLE_WEBSOCKET=OFF \\\n  -DSHERPA_ONNX_ENABLE_GPU=OFF \\\n  -DSHERPA_ONNX_ENABLE_WASM=ON \\\n  -DSHERPA_ONNX_ENABLE_WASM_VAD=ON \\\n  -DSHERPA_ONNX_ENABLE_BINARY=OFF \\\n  -DSHERPA_ONNX_LINK_LIBSTDCPP_STATICALLY=OFF \\\n  ..\nmake -j2\nmake install\n\nls -lh install/bin/wasm/vad\n"
        },
        {
          "name": "c-api-examples",
          "type": "tree",
          "content": null
        },
        {
          "name": "cmake",
          "type": "tree",
          "content": null
        },
        {
          "name": "cxx-api-examples",
          "type": "tree",
          "content": null
        },
        {
          "name": "dart-api-examples",
          "type": "tree",
          "content": null
        },
        {
          "name": "dotnet-examples",
          "type": "tree",
          "content": null
        },
        {
          "name": "ffmpeg-examples",
          "type": "tree",
          "content": null
        },
        {
          "name": "flutter-examples",
          "type": "tree",
          "content": null
        },
        {
          "name": "flutter",
          "type": "tree",
          "content": null
        },
        {
          "name": "go-api-examples",
          "type": "tree",
          "content": null
        },
        {
          "name": "harmony-os",
          "type": "tree",
          "content": null
        },
        {
          "name": "ios-swift",
          "type": "tree",
          "content": null
        },
        {
          "name": "ios-swiftui",
          "type": "tree",
          "content": null
        },
        {
          "name": "java-api-examples",
          "type": "tree",
          "content": null
        },
        {
          "name": "jitpack.yml",
          "type": "blob",
          "size": 0.3232421875,
          "content": "jdk:\n  - openjdk17\n\nbefore_install:\n  - wget https://github.com/k2-fsa/sherpa-onnx/releases/download/v1.10.38/sherpa-onnx-1.10.38.aar\n\ninstall:\n  - FILE=\"-Dfile=sherpa-onnx-1.10.38.aar\"\n  - mvn install:install-file $FILE -DgroupId=com.k2fsa.sherpa.onnx -DartifactId=sherpa-onnx -Dversion=1.10.38 -Dpackaging=aar -DgeneratePom=true\n"
        },
        {
          "name": "kotlin-api-examples",
          "type": "tree",
          "content": null
        },
        {
          "name": "lazarus-examples",
          "type": "tree",
          "content": null
        },
        {
          "name": "mfc-examples",
          "type": "tree",
          "content": null
        },
        {
          "name": "new-release.sh",
          "type": "blob",
          "size": 0.99609375,
          "content": "#!/usr/bin/env bash\n\nset -ex\n\nsed -i.bak 's/1\\.10\\.37/1\\.10\\.38/g' ./build-ios-shared.sh\nsed -i.bak 's/1\\.10\\.37/1\\.10\\.38/g' ./pom.xml\nsed -i.bak 's/1\\.10\\.37/1\\.10\\.38/g' ./jitpack.yml\nsed -i.bak 's/1\\.10\\.37/1\\.10\\.38/g' ./android/SherpaOnnxAar/README.md\n\nfind android -name build.gradle -type f -exec sed -i.bak 's/sherpa-onnx:v1\\.10\\.37/sherpa-onnx:v1\\.10\\.38/g' {} \\;\n\nfind flutter -name *.yaml -type f -exec sed -i.bak 's/1\\.10\\.37/1\\.10\\.38/g' {} \\;\nfind dart-api-examples -name *.yaml -type f -exec sed -i.bak 's/1\\.10\\.37/1\\.10\\.38/g' {} \\;\nfind flutter-examples -name *.yaml -type f -exec sed -i.bak 's/1\\.10\\.37/1\\.10\\.38/g' {} \\;\nfind flutter -name *.podspec -type f -exec sed -i.bak 's/1\\.10\\.37/1\\.10\\.38/g' {} \\;\nfind nodejs-addon-examples -name package.json -type f -exec sed -i.bak 's/1\\.10\\.37/1\\.10\\.38/g' {} \\;\n\nfind harmony-os -name \"README.md\" -type f -exec sed -i.bak 's/1\\.10\\.37/1\\.10\\.38/g' {} \\;\nfind harmony-os -name oh-package.json5 -type f -exec sed -i.bak 's/1\\.10\\.37/1\\.10\\.38/g' {} \\;\n"
        },
        {
          "name": "nodejs-addon-examples",
          "type": "tree",
          "content": null
        },
        {
          "name": "nodejs-examples",
          "type": "tree",
          "content": null
        },
        {
          "name": "pascal-api-examples",
          "type": "tree",
          "content": null
        },
        {
          "name": "pom.xml",
          "type": "blob",
          "size": 0.77734375,
          "content": "<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<project xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 https://maven.apache.org/xsd/maven-4.0.0.xsd\" xmlns=\"http://maven.apache.org/POM/4.0.0\"\n    xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\">\n    <modelVersion>4.0.0</modelVersion>\n    <groupId>com.k2fsa.sherpa.onnx</groupId>\n    <artifactId>sherpa-onnx-android</artifactId>\n    <version>1.10.38</version>\n    <url>https://github.com/k2-fsa/sherpa-onnx</url>\n    <packaging>pom</packaging>\n    <description>First Android Library</description>\n\n    <licenses>\n      <license>\n        <name>The Apache Software License, Version 2.0</name>\n        <url>http://www.apache.org/licenses/LICENSE-2.0.txt</url>\n        <distribution>repo</distribution>\n      </license>\n    </licenses>\n</project>\n"
        },
        {
          "name": "python-api-examples",
          "type": "tree",
          "content": null
        },
        {
          "name": "release.sh",
          "type": "blob",
          "size": 1.2529296875,
          "content": "#!/usr/bin/env bash\n#\n# Copyright (c)  2023  Xiaomi Corporation\n#\n# Please see the end of this file for what files it will generate\n\nset -ex\nSHERPA_ONNX_VERSION=$(grep \"SHERPA_ONNX_VERSION\" ./CMakeLists.txt  | cut -d \" \" -f 2  | cut -d '\"' -f 2)\necho \"SHERPA_ONNX_VERSION: ${SHERPA_ONNX_VERSION}\"\ndst=v${SHERPA_ONNX_VERSION}\n\nif [ -d $dst ]; then\n  echo \"$dst exists - skipping\"\n  exit 0\nfi\n\n./build-android-arm64-v8a.sh\n./build-android-armv7-eabi.sh\n./build-android-x86-64.sh\n./build-android-x86.sh\n./build-ios.sh\n\nmkdir -p $dst/jniLibs/arm64-v8a\ncp -v ./build-android-arm64-v8a/install/lib/*.so $dst/jniLibs/arm64-v8a/\n\nmkdir -p $dst/jniLibs/armeabi-v7a\ncp -v ./build-android-armv7-eabi/install/lib/*.so $dst/jniLibs/armeabi-v7a/\n\nmkdir -p $dst/jniLibs/x86_64\ncp -v ./build-android-x86-64/install/lib/*.so $dst/jniLibs/x86_64\n\nmkdir -p $dst/jniLibs/x86\ncp -v ./build-android-x86/install/lib/*.so $dst/jniLibs/x86\n\nmkdir -p $dst/build-ios/\ncp -av ./build-ios/sherpa-onnx.xcframework $dst/build-ios/\n\nmkdir -p $dst/build-ios/ios-onnxruntime\ncp -av ./build-ios/ios-onnxruntime/onnxruntime.xcframework $dst/build-ios/ios-onnxruntime/\n\ncd $dst\n\ntar cjvf sherpa-onnx-v${SHERPA_ONNX_VERSION}-android.tar.bz2 ./jniLibs\n\ntar cjvf sherpa-onnx-v${SHERPA_ONNX_VERSION}-ios.tar.bz2 ./build-ios\n"
        },
        {
          "name": "rust-api-examples",
          "type": "tree",
          "content": null
        },
        {
          "name": "scripts",
          "type": "tree",
          "content": null
        },
        {
          "name": "setup.py",
          "type": "blob",
          "size": 2.5712890625,
          "content": "#!/usr/bin/env python3\n\nimport os\nimport re\nfrom pathlib import Path\n\nimport setuptools\n\nfrom cmake.cmake_extension import (\n    BuildExtension,\n    bdist_wheel,\n    cmake_extension,\n    get_binaries,\n    is_windows,\n)\n\n\ndef read_long_description():\n    with open(\"README.md\", encoding=\"utf8\") as f:\n        readme = f.read()\n    return readme\n\n\ndef get_package_version():\n    with open(\"CMakeLists.txt\") as f:\n        content = f.read()\n\n    match = re.search(r\"set\\(SHERPA_ONNX_VERSION (.*)\\)\", content)\n    latest_version = match.group(1).strip('\"')\n\n    cmake_args = os.environ.get(\"SHERPA_ONNX_CMAKE_ARGS\", \"\")\n    extra_version = \"\"\n    if \"-DSHERPA_ONNX_ENABLE_GPU=ON\" in cmake_args:\n        extra_version = \"+cuda\"\n\n    latest_version += extra_version\n\n    return latest_version\n\n\npackage_name = \"sherpa-onnx\"\n\nwith open(\"sherpa-onnx/python/sherpa_onnx/__init__.py\", \"a\") as f:\n    f.write(f\"__version__ = '{get_package_version()}'\\n\")\n\n\ndef get_binaries_to_install():\n    bin_dir = Path(\"build\") / \"sherpa_onnx\" / \"bin\"\n    bin_dir.mkdir(parents=True, exist_ok=True)\n    suffix = \".exe\" if is_windows() else \"\"\n\n    binaries = get_binaries()\n\n    exe = []\n    for f in binaries:\n        suffix = \"\" if (\".dll\" in f or \".lib\" in f) else suffix\n        t = bin_dir / (f + suffix)\n        exe.append(str(t))\n    return exe\n\n\nsetuptools.setup(\n    name=package_name,\n    python_requires=\">=3.6\",\n    version=get_package_version(),\n    author=\"The sherpa-onnx development team\",\n    author_email=\"dpovey@gmail.com\",\n    package_dir={\n        \"sherpa_onnx\": \"sherpa-onnx/python/sherpa_onnx\",\n    },\n    packages=[\"sherpa_onnx\"],\n    data_files=[(\"bin\", get_binaries_to_install())],\n    url=\"https://github.com/k2-fsa/sherpa-onnx\",\n    long_description=read_long_description(),\n    long_description_content_type=\"text/markdown\",\n    ext_modules=[cmake_extension(\"_sherpa_onnx\")],\n    cmdclass={\"build_ext\": BuildExtension, \"bdist_wheel\": bdist_wheel},\n    zip_safe=False,\n    classifiers=[\n        \"Programming Language :: C++\",\n        \"Programming Language :: Python\",\n        \"Topic :: Scientific/Engineering :: Artificial Intelligence\",\n    ],\n    entry_points={\n        \"console_scripts\": [\n            \"sherpa-onnx-cli=sherpa_onnx.cli:cli\",\n        ],\n    },\n    license=\"Apache licensed, as found in the LICENSE file\",\n)\n\nwith open(\"sherpa-onnx/python/sherpa_onnx/__init__.py\", \"r\") as f:\n    lines = f.readlines()\n\nwith open(\"sherpa-onnx/python/sherpa_onnx/__init__.py\", \"w\") as f:\n    for line in lines:\n        if \"__version__\" in line:\n            # skip __version__ = \"x.x.x\"\n            continue\n        f.write(line)\n"
        },
        {
          "name": "sherpa-onnx",
          "type": "tree",
          "content": null
        },
        {
          "name": "swift-api-examples",
          "type": "tree",
          "content": null
        },
        {
          "name": "toolchains",
          "type": "tree",
          "content": null
        },
        {
          "name": "wasm",
          "type": "tree",
          "content": null
        }
      ]
    }
  ]
}