{
  "metadata": {
    "timestamp": 1736566453345,
    "page": 1,
    "hasNextPage": false,
    "endCursor": "Y3Vyc29yOjM=",
    "completionStatus": "IN_PROGRESS"
  },
  "repositories": [
    {
      "nameWithOwner": "tensorflow/tensorflow",
      "stars": 187205,
      "defaultBranch": "master",
      "files": [
        {
          "name": ".bazelignore",
          "type": "blob",
          "size": 0.6728515625,
          "content": "# Copyright 2023 The TensorFlow Authors. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n# ==============================================================================\n"
        },
        {
          "name": ".bazelrc",
          "type": "blob",
          "size": 52.1884765625,
          "content": "# TensorFlow Bazel configuration file.\n# This file tries to group and simplify build options for TensorFlow\n#\n# ----CONFIG OPTIONS----\n# Android options:\n#    android:\n#    android_arm:\n#    android_arm64:\n#    android_x86:\n#    android_x86_64:\n#\n# iOS options:\n#     ios:\n#     ios_armv7:\n#     ios_arm64:\n#     ios_x86_64:\n#     ios_fat:\n#\n# Macosx options\n#     darwin_arm64:\n#\n# Compiler options:\n#     cuda_clang:             Use Clang when building CUDA code.\n#     avx_linux:              Build with avx instruction set on linux.\n#     avx_win:                Build with avx instruction set on windows\n#\n# Other build options:\n#     short_logs:       Only log errors during build, skip warnings.\n#     verbose_logs:     Show all compiler warnings during build.\n#     monolithic:       Build all TF C++ code into a single shared object.\n#     dynamic_kernels:  Try to link all kernels dynamically (experimental).\n#     dbg:              Build with debug info\n#\n# TF version options;\n#     v2: Build TF v2\n#\n# Feature and Third party library support options:\n#     xla:          Build TF with XLA\n#     tpu:          Build TF with TPU support\n#     cuda:         Build with CUDA support.\n#     cuda_clang    Build with CUDA Clang support.\n#     rocm:         Build with AMD GPU support (rocm)\n#     mkl:          Enable full mkl support.\n#     nogcp:        Disable GCS support.\n#     nonccl:       Disable nccl support.\n#\n#\n# Remote build execution options (only configured to work with TF team projects for now.)\n#     rbe_base:  General RBE options shared by all flavors.\n#     rbe_linux: General RBE options used on all linux builds.\n#     rbe_win_base:   General RBE options used on all Windows builds. Not to be used standalone.\n#     rbe_win_clang:  Options specific to compiling using Clang.\n#\n#     rbe_linux_cpu:                  RBE options to build with only CPU support.\n#     rbe_linux_cuda:                 RBE options to build with GPU support using clang.\n#     rbe_linux_cuda_nvcc:            RBE options to build with GPU support using nvcc.\n#\n# Embedded Linux options (experimental and only tested with TFLite build yet)\n#     elinux:          General Embedded Linux options shared by all flavors.\n#     elinux_aarch64:  Embedded Linux options for aarch64 (ARM64) CPU support.\n#     elinux_armhf:    Embedded Linux options for armhf (ARMv7) CPU support.\n#\n# Release build options (for all operating systems)\n#     release_base:                    Common options for all builds on all operating systems.\n#     release_cpu_linux:               Toolchain and CUDA options for Linux CPU builds.\n#     release_gpu_linux:               Toolchain and CUDA options for Linux GPU builds.\n#     release_cpu_macos:               Toolchain and CUDA options for MacOS CPU builds.\n#     release_cpu_windows:             Toolchain and CUDA options for Windows CPU builds.\n\n# Default build options. These are applied first and unconditionally.\n\n# For projects which use TensorFlow as part of a Bazel build process, putting\n# nothing in a bazelrc will default to a monolithic build. The following line\n# opts in to modular op registration support by default.\nbuild --define framework_shared_object=true\nbuild --define tsl_protobuf_header_only=true\n\nbuild --define=use_fast_cpp_protos=true\nbuild --define=allow_oversize_protos=true\n\nbuild --spawn_strategy=standalone\nbuild -c opt\n\n# Make Bazel print out all options from rc files.\nbuild --announce_rc\n\n# TODO(mihaimaruseac): Document this option or remove if no longer needed\nbuild --define=grpc_no_ares=true\n\n# See https://github.com/bazelbuild/bazel/issues/7362 for information on what\n# --incompatible_remove_legacy_whole_archive flag does.\n# This flag is set to true in Bazel 1.0 and newer versions. We tried to migrate\n# Tensorflow to the default, however test coverage wasn't enough to catch the\n# errors.\n# There is ongoing work on Bazel team's side to provide support for transitive\n# shared libraries. As part of migrating to transitive shared libraries, we\n# hope to provide a better mechanism for control over symbol exporting, and\n# then tackle this issue again.\n#\n# TODO: Remove the following two lines once TF doesn't depend on Bazel wrapping\n# all library archives in -whole_archive -no_whole_archive.\nbuild --noincompatible_remove_legacy_whole_archive\nbuild --features=-force_no_whole_archive\n\n# TODO(mihaimaruseac): Document this option or remove if no longer needed\nbuild --enable_platform_specific_config\n\n# Enable XLA support by default.\nbuild --define=with_xla_support=true\n\n# TODO(mihaimaruseac): Document this option or remove if no longer needed\nbuild --config=short_logs\n\n# TODO(mihaimaruseac): Document this option or remove if no longer needed\nbuild --config=v2\n\n# TF now has `cc_shared_library` targets, so it needs the experimental flag\n# TODO(rostam): Remove when `cc_shared_library` is enabled by default\nbuild --experimental_cc_shared_library\n\n# cc_shared_library ensures no library is linked statically more than once.\nbuild --experimental_link_static_libraries_once=false\n\n# Prevent regressions on those two incompatible changes\n# TODO: remove those flags when they are flipped in the default Bazel version TF uses.\nbuild --incompatible_enforce_config_setting_visibility\n# TODO: also enable this flag after fixing the visibility violations\n# build --incompatible_config_setting_private_default_visibility\n\n# Default options should come above this line.\n\n# Android configs. Bazel needs to have --cpu and --fat_apk_cpu both set to the\n# target CPU to build transient dependencies correctly. See\n# https://docs.bazel.build/versions/master/user-manual.html#flag--fat_apk_cpu\nbuild:android --crosstool_top=//external:android/crosstool\nbuild:android --host_crosstool_top=@bazel_tools//tools/cpp:toolchain\nbuild:android_arm --config=android\nbuild:android_arm --cpu=armeabi-v7a\nbuild:android_arm --fat_apk_cpu=armeabi-v7a\nbuild:android_arm64 --config=android\nbuild:android_arm64 --cpu=arm64-v8a\nbuild:android_arm64 --fat_apk_cpu=arm64-v8a\nbuild:android_x86 --config=android\nbuild:android_x86 --cpu=x86\nbuild:android_x86 --fat_apk_cpu=x86\nbuild:android_x86_64 --config=android\nbuild:android_x86_64 --cpu=x86_64\nbuild:android_x86_64 --fat_apk_cpu=x86_64\n\n# Build everything statically for Android since all static libs are later\n# bundled together into a single .so for deployment.\nbuild:android --dynamic_mode=off\n# TODO(belitskiy): Remove once on Clang 20.\nbuild:android --define=xnn_enable_avxvnniint8=false\n\n# Sets the default Apple platform to macOS.\nbuild:macos --apple_platform_type=macos\n\n# gRPC on MacOS requires this #define\nbuild:macos --copt=-DGRPC_BAZEL_BUILD\n\n# Avoid hitting command line argument limit\nbuild:macos --features=archive_param_file\n\n# Settings for MacOS on ARM CPUs.\nbuild:macos_arm64 --cpu=darwin_arm64\nbuild:macos_arm64 --macos_minimum_os=11.0\n\n# iOS configs for each architecture and the fat binary builds.\nbuild:ios --apple_platform_type=ios\nbuild:ios --apple_bitcode=embedded --copt=-fembed-bitcode\nbuild:ios --copt=-Wno-c++11-narrowing\nbuild:ios_armv7 --config=ios\nbuild:ios_armv7 --cpu=ios_armv7\nbuild:ios_arm64 --config=ios\nbuild:ios_arm64 --cpu=ios_arm64\nbuild:ios_arm64e --config=ios\nbuild:ios_arm64e --cpu=ios_arm64e\nbuild:ios_sim_arm64 --config=ios\nbuild:ios_sim_arm64 --cpu=ios_sim_arm64\nbuild:ios_x86_64 --config=ios\nbuild:ios_x86_64 --cpu=ios_x86_64\nbuild:ios_fat --config=ios\nbuild:ios_fat --ios_multi_cpus=armv7,arm64,i386,x86_64\n\n# Config to use a mostly-static build and disable modular op registration\n# support (this will revert to loading TensorFlow with RTLD_GLOBAL in Python).\n# By default, TensorFlow will build with a dependence on\n# //tensorflow:libtensorflow_framework.so.\nbuild:monolithic --define framework_shared_object=false\nbuild:monolithic --define tsl_protobuf_header_only=false\nbuild:monolithic --experimental_link_static_libraries_once=false  # b/229868128\n\n# Please note that MKL on MacOS is still not supported.\n# If you would like to use a local MKL instead of downloading, please set the\n# environment variable \"TF_MKL_ROOT\" every time before build.\nbuild:mkl --define=build_with_mkl=true --define=enable_mkl=true\nbuild:mkl --define=tensorflow_mkldnn_contraction_kernel=0\nbuild:mkl --define=build_with_openmp=true\nbuild:mkl -c opt\n\n# config to build OneDNN backend with a user specified threadpool.\nbuild:mkl_threadpool --define=build_with_mkl=true --define=enable_mkl=true\nbuild:mkl_threadpool --define=tensorflow_mkldnn_contraction_kernel=0\nbuild:mkl_threadpool --define=build_with_mkl_opensource=true\nbuild:mkl_threadpool -c opt\n\n# Config setting to build oneDNN with Compute Library for the Arm Architecture (ACL).\nbuild:mkl_aarch64 --define=build_with_mkl_aarch64=true\nbuild:mkl_aarch64 --define=build_with_openmp=true\nbuild:mkl_aarch64 --define=build_with_acl=true\nbuild:mkl_aarch64 -c opt\n\n# Config setting to build oneDNN with Compute Library for the Arm Architecture (ACL).\n# with Eigen threadpool support\nbuild:mkl_aarch64_threadpool --define=build_with_mkl_aarch64=true\nbuild:mkl_aarch64_threadpool -c opt\n\n# CUDA: This config refers to building CUDA op kernels with nvcc.\nbuild:cuda --repo_env TF_NEED_CUDA=1\nbuild:cuda --crosstool_top=@local_config_cuda//crosstool:toolchain\nbuild:cuda --@local_config_cuda//:enable_cuda\n# Default CUDA and CUDNN versions.\nbuild:cuda --repo_env=HERMETIC_CUDA_VERSION=\"12.5.1\"\nbuild:cuda --repo_env=HERMETIC_CUDNN_VERSION=\"9.3.0\"\n# This flag is needed to include CUDA libraries.\nbuild:cuda --@local_config_cuda//cuda:include_cuda_libs=true\n\n# This configuration is used for building the wheels.\nbuild:cuda_wheel --@local_config_cuda//cuda:include_cuda_libs=false\n\n# CUDA: This config refers to building CUDA op kernels with clang.\nbuild:cuda_clang --config=cuda\nbuild:cuda_clang --@local_config_cuda//:cuda_compiler=clang\nbuild:cuda_clang --copt=-Qunused-arguments\n# Select supported compute capabilities (supported graphics cards).\n# This is the same as the official TensorFlow builds.\n# See https://developer.nvidia.com/cuda-gpus#compute\n# `compute_XY` enables PTX embedding in addition to SASS. PTX\n# is forward compatible beyond the current compute capability major\n# release while SASS is only forward compatible inside the current\n# major release. Example: sm_80 kernels can run on sm_89 GPUs but\n# not on sm_90 GPUs. compute_80 kernels though can also run on sm_90 GPUs.\nbuild:cuda_clang --repo_env=HERMETIC_CUDA_COMPUTE_CAPABILITIES=\"sm_60,sm_70,sm_80,sm_89,compute_90\"\n# Permit newer CUDA versions than Clang is aware of\nbuild:cuda_clang --copt=\"-Wno-unknown-cuda-version\"\n# Set lld as the linker.\nbuild:cuda_clang --host_linkopt=\"-fuse-ld=lld\"\nbuild:cuda_clang --host_linkopt=\"-lm\"\nbuild:cuda_clang --linkopt=\"-fuse-ld=lld\"\nbuild:cuda_clang --linkopt=\"-lm\"\n\n# Set up compilation CUDA version and paths and use the CUDA Clang toolchain.\nbuild:cuda_clang_official --config=cuda_clang\nbuild:cuda_clang_official --repo_env=HERMETIC_CUDA_VERSION=\"12.5.1\"\nbuild:cuda_clang_official --repo_env=HERMETIC_CUDNN_VERSION=\"9.3.0\"\nbuild:cuda_clang_official --action_env=CLANG_CUDA_COMPILER_PATH=\"/usr/lib/llvm-18/bin/clang\"\nbuild:cuda_clang_official --crosstool_top=\"@local_config_cuda//crosstool:toolchain\"\n\n# Build with nvcc for CUDA and clang for host\nbuild:cuda_nvcc --config=cuda\nbuild:cuda_nvcc --action_env=TF_NVCC_CLANG=\"1\"\nbuild:cuda_nvcc --@local_config_cuda//:cuda_compiler=nvcc\n# Old config for backward compatibility\nbuild:nvcc_clang --config=cuda_nvcc\n\n# Debug config\nbuild:dbg -c dbg\n# Only include debug info for files under tensorflow/, excluding kernels, to\n# reduce the size of the debug info in the binary. This is because if the debug\n# sections in the ELF binary are too large, errors can occur. See\n# https://github.com/tensorflow/tensorflow/issues/48919.\n# Users can still include debug info for a specific kernel, e.g. with:\n#     --config=dbg --per_file_copt=+tensorflow/core/kernels/identity_op.*@-g\n# Since this .bazelrc file is synced between the tensorflow/tensorflow repo and\n# the openxla/xla repo, also include debug info for files under xla/.\nbuild:dbg --per_file_copt=+.*,-tensorflow.*,-xla.*@-g0\nbuild:dbg --per_file_copt=+tensorflow/core/kernels.*@-g0\n# for now, disable arm_neon. see: https://github.com/tensorflow/tensorflow/issues/33360\nbuild:dbg --cxxopt -DTF_LITE_DISABLE_X86_NEON\n# AWS SDK must be compiled in release mode. see: https://github.com/tensorflow/tensorflow/issues/37498\nbuild:dbg --copt -DDEBUG_BUILD\n\n# Config to build TF TPU\nbuild:tpu --define=with_tpu_support=true\nbuild:tpu --define=framework_shared_object=true\nbuild:tpu --copt=-DLIBTPU_ON_GCE\nbuild:tpu --define=enable_mlir_bridge=true\n\nbuild:rocm --crosstool_top=@local_config_rocm//crosstool:toolchain\nbuild:rocm --define=using_rocm_hipcc=true\nbuild:rocm --define=tensorflow_mkldnn_contraction_kernel=0\nbuild:rocm --repo_env TF_NEED_ROCM=1\n\nbuild:rocm_clang_official --config=rocm\nbuild:rocm_clang_official --action_env=CLANG_COMPILER_PATH=\"/usr/lib/llvm-18/bin/clang\"\nbuild:rocm_clang_official --action_env=TF_ROCM_CLANG=\"1\"\nbuild:rocm_clang_official --linkopt=\"-fuse-ld=lld\"\nbuild:rocm_clang_official --host_linkopt=\"-fuse-ld=lld\"\n\nbuild:rocm_ci --config=rocm_clang_official\n\nbuild:sycl --crosstool_top=@local_config_sycl//crosstool:toolchain\nbuild:sycl --define=using_sycl=true\nbuild:sycl --define=tensorflow_mkldnn_contraction_kernel=0\nbuild:sycl --repo_env TF_NEED_SYCL=1\n\n# Options to disable default on features\nbuild:nogcp --define=no_gcp_support=true\nbuild:nonccl --define=no_nccl_support=true\n\n# Modular TF build options\nbuild:dynamic_kernels --define=dynamic_loaded_kernels=true\nbuild:dynamic_kernels --copt=-DAUTOLOAD_DYNAMIC_KERNELS\n\n# Don't trigger --config=<host platform> when cross-compiling.\nbuild:android --noenable_platform_specific_config\nbuild:ios --noenable_platform_specific_config\n\n# Suppress all C++ compiler warnings, otherwise build logs become 10s of MBs.\nbuild:android --copt=-w\nbuild:ios --copt=-w\nbuild:linux --host_copt=-w\nbuild:macos --copt=-w\nbuild:windows --copt=/W0\nbuild:windows --host_copt=/W0\n\n# Suppress most C++ compiler warnings to reduce log size but allow\n# for specific warnings to still be present.\nbuild:linux --copt=\"-Wno-all\"\nbuild:linux --copt=\"-Wno-extra\"\nbuild:linux --copt=\"-Wno-deprecated\"\nbuild:linux --copt=\"-Wno-deprecated-declarations\"\nbuild:linux --copt=\"-Wno-ignored-attributes\"\nbuild:linux --copt=\"-Wno-array-bounds\"\n\n# Add unused-result as an error on Linux.\nbuild:linux --copt=\"-Wunused-result\"\nbuild:linux --copt=\"-Werror=unused-result\"\n# Add switch as an error on Linux.\nbuild:linux --copt=\"-Wswitch\"\nbuild:linux --copt=\"-Werror=switch\"\n\n# Linux ARM64 specific options\nbuild:linux_arm64 --copt=\"-mtune=generic\" --copt=\"-march=armv8-a\" --copt=\"-O3\"\n\n\n# On Windows, `__cplusplus` is wrongly defined without this switch\n# See https://devblogs.microsoft.com/cppblog/msvc-now-correctly-reports-__cplusplus/\nbuild:windows --copt=/Zc:__cplusplus\nbuild:windows --host_copt=/Zc:__cplusplus\n\n# Tensorflow uses M_* math constants that only get defined by MSVC headers if\n# _USE_MATH_DEFINES is defined.\nbuild:windows --copt=/D_USE_MATH_DEFINES\nbuild:windows --host_copt=/D_USE_MATH_DEFINES\n\n# Windows has a relatively short command line limit, which TF has begun to hit.\n# See https://docs.bazel.build/versions/main/windows.html\nbuild:windows --features=compiler_param_file\nbuild:windows --features=archive_param_file\n\n# Speed Windows compile times. Available in VS 16.4 (we are on 16.11). See\n# https://groups.google.com/a/tensorflow.org/d/topic/build/SsW98Eo7l3o/discussion\nbuild:windows --copt=/d2ReducedOptimizeHugeFunctions\nbuild:windows --host_copt=/d2ReducedOptimizeHugeFunctions\n\n# Before VS 2017 15.8, the member \"type\" would non-conformingly have an\n# alignment of only alignof(max_align_t). VS 2017 15.8 was fixed to handle this\n# correctly, but the fix inherently changes layout and breaks binary\n# compatibility (*only* for uses of aligned_storage with extended alignments).\nbuild:windows --copt=-D_ENABLE_EXTENDED_ALIGNED_STORAGE\nbuild:windows --host_copt=-D_ENABLE_EXTENDED_ALIGNED_STORAGE\n\n# Enable the runfiles symlink tree on Windows. This makes it possible to build\n# the pip package on Windows without an intermediate data-file archive, as the\n# build_pip_package script in its current form (as of Aug 2023) uses the\n# runfiles symlink tree to decide what to put into the Python wheel.\nstartup --windows_enable_symlinks\nbuild:windows --enable_runfiles\nbuild:windows --nobuild_python_zip\nbuild:windows --dynamic_mode=off\n\n# Default paths for TF_SYSTEM_LIBS\nbuild:linux --define=PREFIX=/usr\nbuild:linux --define=LIBDIR=$(PREFIX)/lib\nbuild:linux --define=INCLUDEDIR=$(PREFIX)/include\nbuild:linux --define=PROTOBUF_INCLUDE_PATH=$(PREFIX)/include\nbuild:macos --define=PREFIX=/usr\nbuild:macos --define=LIBDIR=$(PREFIX)/lib\nbuild:macos --define=INCLUDEDIR=$(PREFIX)/include\nbuild:macos --define=PROTOBUF_INCLUDE_PATH=$(PREFIX)/include\n# TF_SYSTEM_LIBS do not work on windows.\n\n# By default, build TF in C++ 17 mode.\nbuild:android --cxxopt=-std=c++17\nbuild:android --host_cxxopt=-std=c++17\nbuild:ios --cxxopt=-std=c++17\nbuild:ios --host_cxxopt=-std=c++17\nbuild:linux --cxxopt=-std=c++17\nbuild:linux --host_cxxopt=-std=c++17\nbuild:macos --cxxopt=-std=c++17\nbuild:macos --host_cxxopt=-std=c++17\nbuild:windows --cxxopt=/std:c++17\nbuild:windows --host_cxxopt=/std:c++17\n\n# On windows, we still link everything into a single DLL.\nbuild:windows --config=monolithic\n\n# On linux, we dynamically link small amount of kernels\nbuild:linux --config=dynamic_kernels\n\n# Make sure to include as little of windows.h as possible\nbuild:windows --copt=-DWIN32_LEAN_AND_MEAN\nbuild:windows --host_copt=-DWIN32_LEAN_AND_MEAN\nbuild:windows --copt=-DNOGDI\nbuild:windows --host_copt=-DNOGDI\n\n# MSVC (Windows): Standards-conformant preprocessor mode\n# See https://docs.microsoft.com/en-us/cpp/preprocessor/preprocessor-experimental-overview\nbuild:windows --copt=/Zc:preprocessor\nbuild:windows --host_copt=/Zc:preprocessor\n\n# Misc build options we need for windows.\nbuild:windows --linkopt=/DEBUG\nbuild:windows --host_linkopt=/DEBUG\nbuild:windows --linkopt=/OPT:REF\nbuild:windows --host_linkopt=/OPT:REF\nbuild:windows --linkopt=/OPT:ICF\nbuild:windows --host_linkopt=/OPT:ICF\n\n# Verbose failure logs when something goes wrong\nbuild:windows --verbose_failures\n\n# Work around potential issues with large command lines on windows.\n# See: https://github.com/bazelbuild/bazel/issues/5163\nbuild:windows --features=compiler_param_file\n\n# Do not risk cache corruption. See:\n# https://github.com/bazelbuild/bazel/issues/3360\nbuild:linux --experimental_guard_against_concurrent_changes\n\n# Configure short or long logs\nbuild:short_logs --output_filter=DONT_MATCH_ANYTHING\nbuild:verbose_logs --output_filter=\n\n# Instruction set optimizations\n# TODO(gunan): Create a feature in toolchains for avx/avx2 to\n#   avoid having to define linux/win separately.\nbuild:avx_linux --copt=-mavx\nbuild:avx_linux --host_copt=-mavx\nbuild:avx_win --copt=/arch:AVX\n\n# TODO(belitskiy): Remove once Win2019 is gone.\n# Use Clang-cl compiler on Windows\nbuild:win_clang --extra_toolchains=@local_config_cc//:cc-toolchain-x64_windows-clang-cl\nbuild:win_clang --extra_execution_platforms=//tensorflow/tools/toolchains/win:x64_windows-clang-cl\nbuild:win_clang --host_platform=//tensorflow/tools/toolchains/win:x64_windows-clang-cl\nbuild:win_clang --copt=/clang:-Weverything\nbuild:win_clang --host_copt=/clang:-Weverything\nbuild:win_clang --compiler=clang-cl\nbuild:win_clang --linkopt=/FORCE:MULTIPLE\nbuild:win_clang --host_linkopt=/FORCE:MULTIPLE\ntest:win_clang --linkopt=/FORCE:MULTIPLE\ntest:win_clang --host_linkopt=/FORCE:MULTIPLE\ntest:win_clang --action_env=PATHEXT=.COM;.EXE;.BAT;.CMD;.VBS;.VBE;.JS;.JSE;.WSF;.WSH;.MSC;.PY;.PYW\n\n# build:windows_x86_cpu --extra_toolchains=\"//tensorflow/tools/toolchains/win2022/20241118:cc-toolchain-x64_windows-clang-cl\"\n# build:windows_x86_cpu --extra_execution_platforms=\"//tensorflow/tools/toolchains/win2022:windows_ltsc2022_clang\"\n# build:windows_x86_cpu --host_platform=\"//tensorflow/tools/toolchains/win2022:windows_ltsc2022_clang\"\nbuild:windows_x86_cpu --crosstool_top=\"//tensorflow/tools/toolchains/win2022/20241118:toolchain\"\nbuild:windows_x86_cpu --extra_toolchains=\"//tensorflow/tools/toolchains/win2022/20241118:cc-toolchain-x64_windows-clang-cl\"\nbuild:windows_x86_cpu --extra_execution_platforms=\"//tensorflow/tools/toolchains/win2022:windows_ltsc2022_clang\"\nbuild:windows_x86_cpu --host_platform=\"//tensorflow/tools/toolchains/win2022:windows_ltsc2022_clang\"\nbuild:windows_x86_cpu --platforms=\"//tensorflow/tools/toolchains/win2022:windows_ltsc2022_clang\"\nbuild:windows_x86_cpu --copt=/clang:-Weverything\nbuild:windows_x86_cpu --host_copt=/clang:-Weverything\nbuild:windows_x86_cpu --compiler=clang-cl\nbuild:windows_x86_cpu --linkopt=/FORCE:MULTIPLE\nbuild:windows_x86_cpu --host_linkopt=/FORCE:MULTIPLE\ntest:windows_x86_cpu --linkopt=/FORCE:MULTIPLE\ntest:windows_x86_cpu --host_linkopt=/FORCE:MULTIPLE\ntest:windows_x86_cpu --action_env=PATHEXT=.COM;.EXE;.BAT;.CMD;.VBS;.VBE;.JS;.JSE;.WSF;.WSH;.MSC;.PY;.PYW\n\n# Options to build TensorFlow 1.x or 2.x.\n# TODO(kanglan): Change v2's define to default behavior\nbuild:v2 --define=tf_api_version=2 --action_env=TF2_BEHAVIOR=1\n\n# Enable all targets in XLA\nbuild:cpu_cross --define=with_cross_compiler_support=true\n\n# Disable XLA on mobile.\nbuild:xla     --define=with_xla_support=true # TODO: remove, it's on by default.\nbuild:android --define=with_xla_support=false\nbuild:ios     --define=with_xla_support=false\n\n# BEGIN TF REMOTE BUILD EXECUTION OPTIONS\n# Options when using remote execution\n# WARNING: THESE OPTIONS WONT WORK IF YOU DO NOT HAVE PROPER AUTHENTICATION AND PERMISSIONS\n\n# Allow creation of resultstore URLs for any bazel invocation\nbuild:resultstore --google_default_credentials\nbuild:resultstore --bes_backend=buildeventservice.googleapis.com\nbuild:resultstore --bes_instance_name=\"tensorflow-testing\"\nbuild:resultstore --bes_results_url=\"https://source.cloud.google.com/results/invocations\"\nbuild:resultstore --bes_timeout=600s\n\n# Flag to enable remote config\ncommon --experimental_repo_remote_exec\n\n# Make Bazel not try to probe the host system for a C++ toolchain.\nbuild:rbe_base --config=resultstore\nbuild:rbe_base --repo_env=BAZEL_DO_NOT_DETECT_CPP_TOOLCHAIN=1\nbuild:rbe_base --define=EXECUTOR=remote\nbuild:rbe_base --jobs=800\nbuild:rbe_base --remote_executor=grpcs://remotebuildexecution.googleapis.com\nbuild:rbe_base --remote_timeout=3600\nbuild:rbe_base --spawn_strategy=remote,worker,standalone,local\n# Attempt to minimize the amount of data transfer between bazel and the remote\n# workers:\nbuild:rbe_base --remote_download_toplevel\ntest:rbe_base --test_env=USER=anon\n\n# TODO(kanglan): Check if we want to merge rbe_linux into rbe_linux_cpu.\nbuild:rbe_linux --config=rbe_base\nbuild:rbe_linux --action_env=PATH=\"/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/local/go/bin\"\n# Non-rbe settings we should include because we do not run configure\nbuild:rbe_linux --config=avx_linux\n# TODO(gunan): Check why we need this specified in rbe, but not in other builds.\nbuild:rbe_linux --linkopt=-lrt\nbuild:rbe_linux --host_linkopt=-lrt\nbuild:rbe_linux --linkopt=-lm\nbuild:rbe_linux --host_linkopt=-lm\n\nbuild:rbe_linux_cpu --config=rbe_linux\n# Linux cpu and cuda builds share the same toolchain now.\nbuild:rbe_linux_cpu --host_crosstool_top=\"@local_config_cuda//crosstool:toolchain\"\nbuild:rbe_linux_cpu --crosstool_top=\"@local_config_cuda//crosstool:toolchain\"\nbuild:rbe_linux_cpu --extra_toolchains=\"@local_config_cuda//crosstool:toolchain-linux-x86_64\"\nbuild:rbe_linux_cpu --repo_env=CC=\"/usr/lib/llvm-18/bin/clang\"\nbuild:rbe_linux_cpu --repo_env=TF_SYSROOT=\"/dt9\"\nbuild:rbe_linux_cpu --extra_execution_platforms=\"@ml_build_config_platform//:platform\"\nbuild:rbe_linux_cpu --host_platform=\"@ml_build_config_platform//:platform\"\nbuild:rbe_linux_cpu --platforms=\"@ml_build_config_platform//:platform\"\n# This is needed for all Clang17 builds but must not be present in GCC builds.\nbuild:rbe_linux_cpu --copt=-Wno-error=unused-command-line-argument\n# This was added in clang-16 by https://reviews.llvm.org/D133574.\n# Can be removed once upb is updated, since a type definition is used within\n# offset of in the current version of ubp.\n# See https://github.com/protocolbuffers/upb/blob/9effcbcb27f0a665f9f345030188c0b291e32482/upb/upb.c#L183.\nbuild:rbe_linux_cpu --copt=-Wno-gnu-offsetof-extensions\n# Python config is the same across all containers because the binary is the same\nbuild:rbe_linux_cpu --python_path=\"/usr/bin/python3\"\n# These you may need to change for your own GCP project.\ncommon:rbe_linux_cpu --remote_instance_name=projects/tensorflow-testing/instances/default_instance\n\n# TODO(kanglan): Remove it after toolchain update is complete.\nbuild:rbe_linux_cpu_old --config=rbe_linux\nbuild:rbe_linux_cpu_old --host_crosstool_top=\"@ubuntu20.04-gcc9_manylinux2014-cuda11.2-cudnn8.1-tensorrt7.2_config_cuda//crosstool:toolchain\"\nbuild:rbe_linux_cpu_old --crosstool_top=\"@ubuntu20.04-gcc9_manylinux2014-cuda11.2-cudnn8.1-tensorrt7.2_config_cuda//crosstool:toolchain\"\nbuild:rbe_linux_cpu_old --extra_toolchains=\"@ubuntu20.04-gcc9_manylinux2014-cuda11.2-cudnn8.1-tensorrt7.2_config_cuda//crosstool:toolchain-linux-x86_64\"\nbuild:rbe_linux_cpu_old --extra_execution_platforms=\"@ubuntu20.04-gcc9_manylinux2014-cuda11.2-cudnn8.1-tensorrt7.2_config_platform//:platform\"\nbuild:rbe_linux_cpu_old --host_platform=\"@ubuntu20.04-gcc9_manylinux2014-cuda11.2-cudnn8.1-tensorrt7.2_config_platform//:platform\"\nbuild:rbe_linux_cpu_old --platforms=\"@ubuntu20.04-gcc9_manylinux2014-cuda11.2-cudnn8.1-tensorrt7.2_config_platform//:platform\"\nbuild:rbe_linux_cpu_old --python_path=\"/usr/local/bin/python3.9\"\ncommon:rbe_linux_cpu_old --remote_instance_name=projects/tensorflow-testing/instances/default_instance\n\nbuild:rbe_linux_cuda --config=cuda_clang_official\nbuild:rbe_linux_cuda --config=rbe_linux_cpu\n# For Remote build execution -- GPU configuration\nbuild:rbe_linux_cuda --repo_env=REMOTE_GPU_TESTING=1\n\nbuild:rbe_linux_cuda_nvcc --config=rbe_linux_cuda\nbuild:rbe_linux_cuda_nvcc --config=cuda_nvcc\nbuild:rbe_linux_cuda_nvcc --repo_env TF_NCCL_USE_STUB=1\n\nbuild:rbe_win_base --config=rbe_base\nbuild:rbe_win_base --shell_executable=C:\\\\tools\\\\msys64\\\\usr\\\\bin\\\\bash.exe\nbuild:rbe_win_base --remote_instance_name=projects/tensorflow-testing/instances/windows\n# Don't build the python zip archive in the RBE build.\nbuild:rbe_win_base --remote_download_minimal\nbuild:rbe_win_base --enable_runfiles\nbuild:rbe_win_base --nobuild_python_zip\nbuild:rbe_win_base --define=override_eigen_strong_inline=true\n\nbuild:rbe_win_clang --config=rbe_win_base\nbuild:rbe_win_clang --crosstool_top=\"//tensorflow/tools/toolchains/win/20240424:toolchain\"\nbuild:rbe_win_clang --extra_toolchains=\"//tensorflow/tools/toolchains/win/20240424:cc-toolchain-x64_windows-clang-cl\"\nbuild:rbe_win_clang --extra_execution_platforms=\"//tensorflow/tools/toolchains/win:x64_windows-clang-cl\"\nbuild:rbe_win_clang --host_platform=\"//tensorflow/tools/toolchains/win:x64_windows-clang-cl\"\nbuild:rbe_win_clang --platforms=\"//tensorflow/tools/toolchains/win:x64_windows-clang-cl\"\nbuild:rbe_win_clang --compiler=clang-cl\nbuild:rbe_win_clang --linkopt=/FORCE:MULTIPLE\nbuild:rbe_win_clang --host_linkopt=/FORCE:MULTIPLE\n\n# TODO(belitskiy): Rename `rbe_win_clang` to this, once done switching presubmits.\nbuild:rbe_windows_x86_cpu --config=rbe_win_clang\n\n# END TF REMOTE BUILD EXECUTION OPTIONS\n\n# TFLite build configs for generic embedded Linux\nbuild:elinux --crosstool_top=@local_config_embedded_arm//:toolchain\nbuild:elinux --host_crosstool_top=@bazel_tools//tools/cpp:toolchain\nbuild:elinux_aarch64 --config=elinux\nbuild:elinux_aarch64 --cpu=aarch64\nbuild:elinux_armhf --config=elinux\nbuild:elinux_armhf --cpu=armhf\nbuild:elinux_armhf --copt -mfp16-format=ieee\n\n# Config-specific options should come above this line.\n\n# Load rc file written by ./configure.\ntry-import %workspace%/.tf_configure.bazelrc\ntry-import %workspace%/xla_configure.bazelrc\n\n# Load rc file with user-specific options.\ntry-import %workspace%/.bazelrc.user\n\n# Here are bazelrc configs for release builds\n# Build TensorFlow v2.\ntest:release_base --test_size_filters=small,medium\n\n# Enable support for all targets\nbuild:release_base --config=cpu_cross\n\n# Ensure release_base is set on linux\nbuild:release_linux_base --config=release_base\n\n# Disable clang extension that rejects type definitions within offsetof.\n# This was added in clang-16 by https://reviews.llvm.org/D133574.\n# Can be removed once upb is updated, since a type definition is used within\n# offset of in the current version of ubp.\n# See https://github.com/protocolbuffers/upb/blob/9effcbcb27f0a665f9f345030188c0b291e32482/upb/upb.c#L183.\nbuild:release_linux_base --copt=-Wno-gnu-offsetof-extensions\nbuild:release_linux_base --copt=-Wno-error=array-parameter\nbuild:release_linux_base --copt=-Wno-error=unused-command-line-argument\n# Set lld as the linker.\nbuild:release_linux_base --linkopt=\"-fuse-ld=lld\"\nbuild:release_linux_base --linkopt=\"-lm\"\n\n# We have some invalid linker scripts in the build,\n# so we need to disable this check\nbuild:release_linux_base --linkopt=-Wl,--undefined-version\n\n# Container environment settings below this point.\n# Use Python 3.X as installed in container image\nbuild:release_linux_base --action_env PYTHON_BIN_PATH=\"/usr/bin/python3\"\nbuild:release_linux_base --action_env PYTHON_LIB_PATH=\"/usr/lib/tf_python\"\nbuild:release_linux_base --python_path=\"/usr/bin/python3\"\n# Set Clang as compiler. Use the actual path to clang installed in container.\nbuild:release_linux_base --repo_env=CC=\"/usr/lib/llvm-18/bin/clang\"\nbuild:release_linux_base --repo_env=BAZEL_COMPILER=\"/usr/lib/llvm-18/bin/clang\"\n# Test-related settings below this point.\ntest:release_linux_base --build_tests_only --keep_going --test_output=errors --verbose_failures=true\ntest:release_linux_base --local_test_jobs=HOST_CPUS\n# Give only the list of failed tests at the end of the log\ntest:release_linux_base --test_summary=short\n\n# Use the Clang toolchain to compile\nbuild:release_cpu_linux --config=release_linux_base\nbuild:release_cpu_linux --crosstool_top=\"@local_config_cuda//crosstool:toolchain\"\nbuild:release_cpu_linux --repo_env=TF_SYSROOT=\"/dt9\"\n# Target the AVX instruction set\nbuild:release_cpu_linux --config=avx_linux\n\nbuild:release_gpu_linux --config=release_cpu_linux\n# Set up compilation CUDA version and paths and use the CUDA Clang toolchain.\n# Note that linux cpu and cuda builds share the same toolchain now.\nbuild:release_gpu_linux --config=cuda_clang_official\n# Local test jobs has to be 4 because parallel_gpu_execute is fragile, I think\ntest:release_gpu_linux --test_timeout=300,450,1200,3600 --local_test_jobs=4 --run_under=//tensorflow/tools/ci_build/gpu_build:parallel_gpu_execute\n\nbuild:release_arm64_linux --config=release_linux_base\nbuild:release_arm64_linux --config=linux_arm64\nbuild:release_arm64_linux --crosstool_top=\"@ml2014_clang_aarch64_config_aarch64//crosstool:toolchain\"\nbuild:release_arm64_linux --config=mkl_aarch64_threadpool\nbuild:release_arm64_linux --copt=-flax-vector-conversions\ntest:release_arm64_linux --flaky_test_attempts=3\n\nbuild:release_cpu_macos --config=avx_linux\n\n# Base build configs for macOS\nbuild:release_macos_base --action_env  DEVELOPER_DIR=/Applications/Xcode.app/Contents/Developer\nbuild:release_macos_base --define=no_nccl_support=true --output_filter=^$\n\n# Ensure release_base is set on mac\nbuild:release_macos_base --config=release_base\n\n# Build configs for macOS x86\nbuild:release_macos_x86 --config=release_macos_base\n# Build with the AVX instruction set when on macOS x86\nbuild:release_macos_x86 --config=avx_linux\nbuild:release_macos_x86 --cpu=darwin\n# Target Catalina as the minimum compatible OS version\nbuild:release_macos_x86 --macos_minimum_os=10.15\nbuild:release_macos_x86 --action_env MACOSX_DEPLOYMENT_TARGET=10.15\n\n# Build configs for macOS Arm64\nbuild:release_macos_arm64 --config=release_macos_base\nbuild:release_macos_arm64 --cpu=darwin_arm64\nbuild:release_macos_arm64 --define=tensorflow_mkldnn_contraction_kernel=0\n# Target Moneterey as the minimum compatible OS version\nbuild:release_macos_arm64 --macos_minimum_os=12.0\nbuild:release_macos_arm64 --action_env MACOSX_DEPLOYMENT_TARGET=12.0\n\n# Base test configs for macOS\ntest:release_macos_base --verbose_failures=true --local_test_jobs=HOST_CPUS\ntest:release_macos_base --test_timeout=300,450,1200,3600 --test_output=errors\ntest:release_macos_base --build_tests_only --keep_going\ntest:release_macos_base --flaky_test_attempts=3\n\n# Test configs for macOS x86\ntest:release_macos_x86 --config=release_macos_base\n\n# Test configs for macOS Arm64\ntest:release_macos_arm64 --config=release_macos_base\n\n# Ensure release_base is set on windows\nbuild:release_cpu_windows --config=release_base\n\n# TODO(kanglan): Update windows configs after b/289091160 is fixed\nbuild:release_cpu_windows --config=avx_win\nbuild:release_cpu_windows --define=no_tensorflow_py_deps=true\n\n# Exclude TFRT integration for anything but Linux.\nbuild:android --config=no_tfrt\nbuild:macos   --config=no_tfrt\nbuild:windows --config=no_tfrt\nbuild:rocm --config=no_tfrt\nbuild:no_tfrt --deleted_packages=tensorflow/compiler/mlir/tfrt,tensorflow/compiler/mlir/tfrt/benchmarks,tensorflow/compiler/mlir/tfrt/ir,tensorflow/compiler/mlir/tfrt/ir/mlrt,tensorflow/compiler/mlir/tfrt/jit/python_binding,tensorflow/compiler/mlir/tfrt/jit/transforms,tensorflow/compiler/mlir/tfrt/python_tests,tensorflow/compiler/mlir/tfrt/tests,tensorflow/compiler/mlir/tfrt/tests/ifrt,tensorflow/compiler/mlir/tfrt/tests/mlrt,tensorflow/compiler/mlir/tfrt/tests/ir,tensorflow/compiler/mlir/tfrt/tests/analysis,tensorflow/compiler/mlir/tfrt/tests/jit,tensorflow/compiler/mlir/tfrt/tests/lhlo_to_tfrt,tensorflow/compiler/mlir/tfrt/tests/lhlo_to_jitrt,tensorflow/compiler/mlir/tfrt/tests/tf_to_corert,tensorflow/compiler/mlir/tfrt/tests/tf_to_tfrt_data,tensorflow/compiler/mlir/tfrt/tests/saved_model,tensorflow/compiler/mlir/tfrt/transforms/lhlo_gpu_to_tfrt_gpu,tensorflow/compiler/mlir/tfrt/transforms/mlrt,tensorflow/core/runtime_fallback,tensorflow/core/runtime_fallback/conversion,tensorflow/core/runtime_fallback/kernel,tensorflow/core/runtime_fallback/opdefs,tensorflow/core/runtime_fallback/runtime,tensorflow/core/runtime_fallback/util,tensorflow/core/runtime_fallback/test,tensorflow/core/runtime_fallback/test/gpu,tensorflow/core/runtime_fallback/test/saved_model,tensorflow/core/runtime_fallback/test/testdata,tensorflow/core/tfrt/stubs,tensorflow/core/tfrt/tfrt_session,tensorflow/core/tfrt/mlrt,tensorflow/core/tfrt/mlrt/attribute,tensorflow/core/tfrt/mlrt/kernel,tensorflow/core/tfrt/mlrt/bytecode,tensorflow/core/tfrt/mlrt/interpreter,tensorflow/compiler/mlir/tfrt/translate/mlrt,tensorflow/compiler/mlir/tfrt/translate/mlrt/testdata,tensorflow/core/tfrt/gpu,tensorflow/core/tfrt/run_handler_thread_pool,tensorflow/core/tfrt/runtime,tensorflow/core/tfrt/saved_model,tensorflow/core/tfrt/graph_executor,tensorflow/core/tfrt/saved_model/tests,tensorflow/core/tfrt/tpu,tensorflow/core/tfrt/utils,tensorflow/core/tfrt/utils/debug,tensorflow/core/tfrt/saved_model/python,tensorflow/core/tfrt/graph_executor/python,tensorflow/core/tfrt/saved_model/utils\n\n# BEGIN TF CACHE HELPER OPTIONS\n# Options when using remote execution\n# WARNING: THESE OPTIONS WONT WORK IF YOU DO NOT HAVE PROPER AUTHENTICATION AND PERMISSIONS\n\n# Use --config=tf_public_cache to try and use the TensorFlow public build cache\n# to build TensorFlow. Look at ci/official/envs to find which types of jobs\n# push to the cache.  For macOS, use --config=tf_public_macos_cache\nbuild:tf_public_cache --remote_cache=\"https://storage.googleapis.com/tensorflow-devinfra-bazel-cache/january2024\" --remote_upload_local_results=false\n# Cache pushes are limited to TF's CI system.\nbuild:tf_public_cache_push --config=tf_public_cache --remote_upload_local_results=true --google_default_credentials\n# Public cache for macOS builds\nbuild:tf_public_macos_cache --remote_cache=\"https://storage.googleapis.com/tensorflow-macos-bazel-cache/oct2023\" --remote_upload_local_results=false\n# Cache pushes are limited to TF's CI system.\nbuild:tf_public_macos_cache_push --config=tf_public_macos_cache --remote_upload_local_results=true --google_default_credentials\n\n# END TF CACHE HELPER OPTIONS\n# BEGIN TF TEST SUITE OPTIONS\n# These are convenience config options that effectively declare TF's CI test suites. Look\n# at the scripts of ci/official/ to see how TF's CI uses them.\n\n# LIBTENSORFLOW TESTS are for building Libtensorflow archives. These are CUDA/CPU-agnostic.\ntest:linux_libtensorflow_test --config=cuda_wheel -- //tensorflow/tools/lib_package:libtensorflow_test //tensorflow/tools/lib_package:libtensorflow_java_test\nbuild:linux_libtensorflow_build --config=cuda_wheel -- //tensorflow/tools/lib_package:libtensorflow.tar.gz //tensorflow/tools/lib_package:libtensorflow_jni.tar.gz //tensorflow/java:libtensorflow.jar //tensorflow/java:libtensorflow-src.jar //tensorflow/tools/lib_package:libtensorflow_proto.zip\nbuild:windows_libtensorflow_build --config=cuda_wheel --config=windows_x86_cpu -- //:LICENSE //tensorflow:tensorflow.dll //tensorflow:tensorflow_dll_import_lib //tensorflow/tools/lib_package:clicenses_generate //tensorflow/java:tensorflow_jni.dll //tensorflow/tools/lib_package:jnilicenses_generate\n\n# PYTHON TESTS run a suite of Python tests intended for verifying that the Python wheel\n# will work properly. These are usually run Nightly or upon Release.\n# CPU WHEEL\ntest:linux_cpu_wheel_test_filters --test_tag_filters=-no_oss,-tf_tosa,-oss_excluded,-oss_serial,-gpu,-tpu,-benchmark-test,-v1only,-no_oss_py38,-no_oss_py39,-no_oss_py310\ntest:linux_cpu_wheel_test_filters --build_tag_filters=-no_oss,-tf_tosa,-oss_excluded,-oss_serial,-gpu,-tpu,-benchmark-test,-v1only,-no_oss_py38,-no_oss_py39,-no_oss_py310\ntest:linux_cpu_wheel_test_filters --test_lang_filters=py --test_size_filters=small,medium\ntest:linux_cpu_wheel_test --@local_tsl//third_party/py:wheel_dependency=true --config=linux_cpu_wheel_test_filters -- //tensorflow/... //tensorflow/tools/pip_package:prebuilt_wheel_import_api_packages_test_cpu -//tensorflow/compiler/tf2tensorrt/... -//tensorflow/core/tpu/... -//tensorflow/lite/... -//tensorflow/tools/toolchains/...\n# CUDA WHEEL\ntest:linux_cuda_wheel_test_filters --test_tag_filters=gpu,requires-gpu,-no_gpu,-no_oss,-tf_tosa,-oss_excluded,-oss_serial,-benchmark-test,-no_cuda11,-no_oss_py38,-no_oss_py39,-no_oss_py310\ntest:linux_cuda_wheel_test_filters --build_tag_filters=gpu,requires-gpu,-no_gpu,-no_oss,-tf_tosa,-oss_excluded,-oss_serial,-benchmark-test,-no_cuda11,-no_oss_py38,-no_oss_py39,-no_oss_py310\ntest:linux_cuda_wheel_test_filters --test_lang_filters=py --test_size_filters=small,medium\ntest:linux_cuda_wheel_test --@local_tsl//third_party/py:wheel_dependency=true --config=linux_cuda_wheel_test_filters -- //tensorflow/... //tensorflow/tools/pip_package:prebuilt_wheel_import_api_packages_test_gpu -//tensorflow/compiler/tf2tensorrt/... -//tensorflow/core/tpu/... -//tensorflow/lite/... -//tensorflow/tools/toolchains/...\n# ARM64 WHEEL\ntest:linux_arm64_wheel_test_filters --test_tag_filters=-no_oss,-tf_tosa,-no_aarch64,-oss_excluded,-oss_serial,-gpu,-tpu,-benchmark-test,-v1only,-no_oss_py38,-no_oss_py39,-no_oss_py310\ntest:linux_arm64_wheel_test_filters --build_tag_filters=-no_oss,-tf_tosa,-no_aarch64,-oss_excluded,-oss_serial,-gpu,-tpu,-benchmark-test,-v1only,-no_oss_py38,-no_oss_py39,-no_oss_py310\ntest:linux_arm64_wheel_test_filters --test_lang_filters=py --test_size_filters=small,medium\ntest:linux_arm64_wheel_test --@local_tsl//third_party/py:wheel_dependency=true --config=linux_arm64_wheel_test_filters -- //tensorflow/... //tensorflow/tools/pip_package:prebuilt_wheel_import_api_packages_test_cpu -//tensorflow/compiler/tf2tensorrt/... -//tensorflow/core/tpu/... -//tensorflow/lite/... -//tensorflow/tools/toolchains/...  -//tensorflow/go/... -//tensorflow/java/... -//tensorflow/core/grappler/optimizers:auto_mixed_precision_test_cpu -//tensorflow/core/grappler/optimizers:remapper_test_cpu -//tensorflow/core/kernels/image:resize_bicubic_op_test\n# MACOS ARM64 WHEEL\ntest:macos_arm64_wheel_test_filters --test_tag_filters=-no_oss,-tf_tosa,-oss_excluded,-oss_serial,-no_oss_py39,-no_oss_py310,-nomac,-no_mac,-mac_excluded,-v1only,-gpu,-tpu,-benchmark-test,-no_mac_arm64,-no_aarch64\ntest:macos_arm64_wheel_test_filters --build_tag_filters=-no_oss,-tf_tosa,-oss_excluded,-oss_serial,-no_oss_py39,-no_oss_py310,-nomac,-no_mac,-mac_excluded,-v1only,-gpu,-tpu,-benchmark-test,-no_mac_arm64,-no_aarch64\ntest:macos_arm64_wheel_test_filters --test_lang_filters=py --test_size_filters=small,medium\ntest:macos_arm64_wheel_test --@local_tsl//third_party/py:wheel_dependency=true --config=macos_arm64_wheel_test_filters -- //tensorflow/... //tensorflow/tools/pip_package:prebuilt_wheel_import_api_packages_test_cpu -//tensorflow/compiler/tf2tensorrt/... -//tensorflow/core/tpu/... -//tensorflow/lite/... -//tensorflow/tools/toolchains/... -//tensorflow/go/... -//tensorflow/java/... -//tensorflow/compiler/aot/...\n# MACOS X86 WHEEL\ntest:macos_x86_wheel_test_filters --test_tag_filters=-no_oss,-tf_tosa,-oss_excluded,-oss_serial,-no_oss_py38,-no_oss_py39,-no_oss_py310,-nomac,-no_mac,-mac_excluded,-v1only,-gpu,-tpu,-benchmark-test\ntest:macos_x86_wheel_test_filters --build_tag_filters=-no_oss,-tf_tosa,-oss_excluded,-oss_serial,-no_oss_py38,-no_oss_py39,-no_oss_py310,-nomac,-no_mac,-mac_excluded,-v1only,-gpu,-tpu,-benchmark-test\ntest:macos_x86_wheel_test_filters --test_lang_filters=py --test_size_filters=small,medium\ntest:macos_x86_wheel_test --@local_tsl//third_party/py:wheel_dependency=true --config=macos_x86_wheel_test_filters -- //tensorflow/... //tensorflow/tools/pip_package:prebuilt_wheel_import_api_packages_test_cpu -//tensorflow/compiler/tf2tensorrt/... -//tensorflow/core/tpu/... -//tensorflow/lite/... -//tensorflow/tools/toolchains/... -//tensorflow/go/... -//tensorflow/java/... -//tensorflow/compiler/aot/...\n# WINDOWS X86 WHEEL\ntest:windows_x86_cpu_wheel_test_filters --test_tag_filters=-no_windows,-windows_excluded,-no_oss,-oss_excluded,-gpu,-tpu,-benchmark-test\ntest:windows_x86_cpu_wheel_test_filters --build_tag_filters=-no_windows,-windows_excluded,-no_oss,-oss_excluded,-benchmark-test\ntest:windows_x86_cpu_wheel_test_filters --test_lang_filters=cc,py --test_size_filters=small,medium --test_timeout=\"300,450,1200,3600\"\ntest:windows_x86_cpu_wheel_test --build_tests_only --config=windows_x86_cpu_pycpp_test_filters -- //tensorflow/... -//tensorflow/java/... -//tensorflow/lite/... -//tensorflow/compiler/...\n\n# PYCPP TESTS run a suite of Python and C++ tests to verify general correctness over\n# the whole TF code base. These are usually run continuously or upon presubmit.\n# LINUX CPU PYCPP:\ntest:linux_cpu_pycpp_test_filters --test_tag_filters=-no_oss,-tf_tosa,-oss_excluded,-oss_serial,-gpu,-tpu,-benchmark-test,-v1only\ntest:linux_cpu_pycpp_test_filters --build_tag_filters=-no_oss,-tf_tosa,-oss_excluded,-oss_serial,-gpu,-tpu,-benchmark-test,-v1only\ntest:linux_cpu_pycpp_test_filters --test_lang_filters=cc,py --test_size_filters=small,medium\ntest:linux_cpu_pycpp_test --config=linux_cpu_pycpp_test_filters -- //tensorflow/... //tensorflow/tools/pip_package:import_api_packages_test_cpu -//tensorflow/compiler/tf2tensorrt/... -//tensorflow/core/tpu/... -//tensorflow/lite/... -//tensorflow/tools/toolchains/...\n\n# LINUX CUDA PYCPP:\ntest:linux_cuda_pycpp_test_filters --test_tag_filters=-no_oss,-tf_tosa,-oss_excluded,-oss_serial,-benchmark-test,-v1only,gpu,-no_gpu,-no_gpu_presubmit,-no_cuda11\ntest:linux_cuda_pycpp_test_filters --build_tag_filters=-no_oss,-tf_tosa,-oss_excluded,-oss_serial,-benchmark-test,-v1only,gpu,-no_gpu,-no_gpu_presubmit,-no_cuda11\ntest:linux_cuda_pycpp_test_filters --test_lang_filters=cc,py --test_size_filters=small,medium\ntest:linux_cuda_pycpp_test --config=linux_cuda_pycpp_test_filters -- //tensorflow/... //tensorflow/tools/pip_package:import_api_packages_test_gpu -//tensorflow/compiler/tf2tensorrt/... -//tensorflow/core/tpu/... -//tensorflow/lite/... -//tensorflow/tools/toolchains/...\n\n# LINUX ARM64 PYCPP\n# In Linux Arm64 presubmit/continuous build, we cross-compile the binaries on\n# Linux x86 so that we can use RBE. Since tests still need to run on the single\n# host Arm64 machine, the build becomes too slow (~30 min) to be a presubmit.\n# For testing purposes, we want to see the runtime performance of an\n# experimental job that is build-only, i.e, we only build the test targets and\n# do not run them. By prefixing the configs with \"build\", we can run both\n# `bazel build` and `bazel test` commands with the same config as test configs\n# inherit from build.\nbuild:linux_arm64_pycpp_test_filters --test_tag_filters=-no_oss,-tf_tosa,-no_aarch64,-oss_excluded,-oss_serial,-gpu,-tpu,-benchmark-test,-v1only\nbuild:linux_arm64_pycpp_test_filters --build_tag_filters=-no_oss,-tf_tosa,-no_aarch64,-oss_excluded,-oss_serial,-gpu,-tpu,-benchmark-test,-v1only\nbuild:linux_arm64_pycpp_test_filters --test_lang_filters=cc,py --test_size_filters=small,medium --flaky_test_attempts=3\n# TODO(michaelhudgins): Why do we need to specifically omit go and java here?\nbuild:linux_arm64_pycpp_test --config=linux_arm64_pycpp_test_filters -- //tensorflow/... //tensorflow/tools/pip_package:import_api_packages_test_cpu -//tensorflow/compiler/tf2tensorrt/... -//tensorflow/core/tpu/... -//tensorflow/lite/... -//tensorflow/tools/toolchains/... -//tensorflow/go/... -//tensorflow/java/... -//tensorflow/core/grappler/optimizers:auto_mixed_precision_test_cpu -//tensorflow/core/grappler/optimizers:remapper_test_cpu -//tensorflow/core/kernels/image:resize_bicubic_op_test -//tensorflow/python/tools:aot_compiled_test\n# CROSS-COMPILE ARM64 PYCPP\nbuild:cross_compile_linux_arm64_pycpp_test --config=linux_arm64_pycpp_test\n# Tests that fail only when cross-compiled\nbuild:cross_compile_linux_arm64_pycpp_test -//tensorflow/compiler/mlir/quantization/stablehlo:convert_tf_quant_to_mhlo_int_test\n# MACOS ARM64 PYCPP\ntest:macos_arm64_pycpp_test_filters --test_tag_filters=-no_oss,-tf_tosa,-oss_excluded,-oss_serial,-no_oss_py39,-no_oss_py310,-nomac,-no_mac,-mac_excluded,-v1only,-gpu,-tpu,-benchmark-test,-no_mac_arm64,-no_aarch64\ntest:macos_arm64_pycpp_test_filters --build_tag_filters=-no_oss,-tf_tosa,-oss_excluded,-oss_serial,-no_oss_py39,-no_oss_py310,-nomac,-no_mac,-mac_excluded,-v1only,-gpu,-tpu,-benchmark-test,-no_mac_arm64,-no_aarch64\ntest:macos_arm64_pycpp_test_filters --test_lang_filters=cc,py --test_size_filters=small,medium\ntest:macos_arm64_pycpp_test --config=macos_arm64_pycpp_test_filters -- //tensorflow/... //tensorflow/tools/pip_package:import_api_packages_test_cpu -//tensorflow/compiler/tf2tensorrt/... -//tensorflow/core/tpu/... -//tensorflow/lite/... -//tensorflow/tools/toolchains/... -//tensorflow/go/... -//tensorflow/java/... -//tensorflow/compiler/aot/... -//tensorflow/core/kernels/image:resize_bicubic_op_test\n# MACOS X86 PYCPP\n# These are defined as build configs so that we can run a build only job. See\n# the note under \"ARM64 PYCPP\" for more details.\nbuild:macos_x86_pycpp_test_filters --test_tag_filters=-no_oss,-tf_tosa,-oss_excluded,-oss_serial,-no_oss_py38,-no_oss_py39,-no_oss_py310,-nomac,-no_mac,-mac_excluded,-v1only,-gpu,-tpu,-benchmark-test\nbuild:macos_x86_pycpp_test_filters --build_tag_filters=-no_oss,-tf_tosa,-oss_excluded,-oss_serial,-no_oss_py38,-no_oss_py39,-no_oss_py310,-nomac,-no_mac,-mac_excluded,-v1only,-gpu,-tpu,-benchmark-test\nbuild:macos_x86_pycpp_test_filters --keep_going --test_lang_filters=cc,py --test_size_filters=small,medium\nbuild:macos_x86_pycpp_test --config=macos_x86_pycpp_test_filters -- //tensorflow/... //tensorflow/tools/pip_package:import_api_packages_test_cpu -//tensorflow/compiler/tf2tensorrt/... -//tensorflow/core/tpu/... -//tensorflow/go/... -//tensorflow/java/... -//tensorflow/tools/toolchains/... -//tensorflow/lite/... -//tensorflow/compiler/aot/...\n# CROSS-COMPILE MACOS X86 PYCPP\nbuild:cross_compile_macos_x86_pycpp_test --config=macos_x86_pycpp_test\nbuild:cross_compile_macos_x86_pycpp_test -//tensorflow/core/kernels:quantized_conv_ops_test -//tensorflow/core/kernels:quantized_matmul_op_test -//tensorflow/python/ops:quantized_conv_ops_test -//tensorflow/tools/graph_transforms:transforms_test -//tensorflow/python/tools:aot_compiled_test\n# WINDOWS X86-64 CPU PYCPP\nbuild:windows_x86_cpu_pycpp_test_build_opts --copt=/d2ReducedOptimizeHugeFunctions --host_copt=/d2ReducedOptimizeHugeFunctions --dynamic_mode=off\nbuild:windows_x86_cpu_pycpp_test_build_opts_debug --config=windows_x86_cpu_pycpp_test_build_opts --linkopt=/demangle:no --host_linkopt=/demangle:no --linkopt=/errorlimit:0 --host_linkopt=/errorlimit:0\ntest:windows_x86_cpu_pycpp_test_filters --test_tag_filters=-no_windows,-windows_excluded,-no_oss,-tf_tosa,-oss_excluded,-gpu,-tpu,-benchmark-test\ntest:windows_x86_cpu_pycpp_test_filters --build_tag_filters=-no_windows,-windows_excluded,-no_oss,-tf_tosa,-oss_excluded,-benchmark-test\ntest:windows_x86_cpu_pycpp_test_filters --test_lang_filters=cc,py --test_size_filters=small,medium --test_timeout=\"300,450,1200,3600\"\ntest:windows_x86_cpu_pycpp_test_opts --config=windows_x86_cpu_pycpp_test_build_opts --build_tests_only\ntest:windows_x86_cpu_pycpp_test --config=windows_x86_cpu_pycpp_test_opts --config=windows_x86_cpu_pycpp_test_filters -- //tensorflow/... -//tensorflow/java/... -//tensorflow/lite/... -//tensorflow/compiler/...\n\n# END TF TEST SUITE OPTIONS\n\n# START CROSS-COMPILE CONFIGS\n# Set execution platform to Linux x86\n# Note: Lot of the \"host_\" flags such as \"host_cpu\" and \"host_crosstool_top\"\n# flags seem to be actually used to specify the execution platform details. It\n# seems it is this way because these flags are old and predate the distinction\n# between host and execution platform.\nbuild:cross_compile_base --host_cpu=k8\nbuild:cross_compile_base --host_crosstool_top=//tensorflow/tools/toolchains/cross_compile/cc:cross_compile_toolchain_suite\nbuild:cross_compile_base --extra_execution_platforms=//tensorflow/tools/toolchains/cross_compile/config:linux_x86_64\n\nbuild:rbe_cross_compile_base --config=rbe_base\nbuild:rbe_cross_compile_base --remote_instance_name=projects/tensorflow-testing/instances/default_instance\n\n# Test-related settings below this point\n# We cannot run cross-compiled tests on the remote Linux x86 VMs so we need to\n# force all tests to run locally on the Aarch64 host.\ntest:rbe_cross_compile_base --strategy=TestRunner=local --build_tests_only\ntest:rbe_cross_compile_base --verbose_failures=true --local_test_jobs=HOST_CPUS --test_output=errors\n\n# START LINUX AARCH64 CROSS-COMPILE CONFIGS\nbuild:cross_compile_linux_arm64 --config=cross_compile_base\n\n# Set the target CPU to Aarch64\nbuild:cross_compile_linux_arm64 --platforms=//tensorflow/tools/toolchains/cross_compile/config:linux_aarch64\nbuild:cross_compile_linux_arm64 --cpu=aarch64\nbuild:cross_compile_linux_arm64 --crosstool_top=//tensorflow/tools/toolchains/cross_compile/cc:cross_compile_toolchain_suite\n\n# RBE cross-compile configs for Linux Aarch64\nbuild:rbe_cross_compile_linux_arm64 --config=cross_compile_linux_arm64\nbuild:rbe_cross_compile_linux_arm64 --config=rbe_cross_compile_base\ntest:rbe_cross_compile_linux_arm64 --config=rbe_cross_compile_base\n\n# END LINUX AARCH64 CROSS-COMPILE CONFIGS\n\n# START MACOS CROSS-COMPILE CONFIGS\nbuild:cross_compile_macos_x86 --config=cross_compile_base\nbuild:cross_compile_macos_x86 --config=nonccl\n# Target Catalina (10.15) as the minimum supported OS\nbuild:cross_compile_macos_x86 --action_env  MACOSX_DEPLOYMENT_TARGET=10.15\n\n# Set the target CPU to Darwin x86\nbuild:cross_compile_macos_x86 --platforms=//tensorflow/tools/toolchains/cross_compile/config:darwin_x86_64\nbuild:cross_compile_macos_x86 --cpu=darwin\nbuild:cross_compile_macos_x86 --crosstool_top=//tensorflow/tools/toolchains/cross_compile/cc:cross_compile_toolchain_suite\n# When RBE cross-compiling for macOS, we need to explicitly register the\n# toolchain. Otherwise, oddly, RBE complains that a \"docker container must be\n# specified\".\nbuild:cross_compile_macos_x86 --extra_toolchains=//tensorflow/tools/toolchains/cross_compile/config:macos-x86-cross-compile-cc-toolchain\n# Map --platforms=darwin_x86_64 to --cpu=darwin and vice-versa to make selects()\n# and transistions that use these flags work.\nbuild:cross_compile_macos_x86 --platform_mappings=tensorflow/tools/toolchains/cross_compile/config/platform_mappings\n\n# RBE cross-compile configs for Darwin x86\nbuild:rbe_cross_compile_macos_x86 --config=cross_compile_macos_x86 --remote_download_minimal\nbuild:rbe_cross_compile_macos_x86 --bes_backend=\"\" --bes_results_url=\"\" --bes_timeout=\"0s\"\nbuild:rbe_cross_compile_macos_x86 --experimental_remote_build_event_upload=\"minimal\"\nbuild:rbe_cross_compile_macos_x86 --config=rbe_cross_compile_base\nbuild:rbe_cross_compile_macos_x86 --bes_upload_mode=nowait_for_upload_complete\ntest:rbe_cross_compile_macos_x86 --config=rbe_cross_compile_base\n# Increase the test timeout as tests often take longer on mac.\ntest:rbe_cross_compile_macos_x86 --test_timeout=300,450,1200,3600\n# Limit jobs to 100 to avoid running into \"out of memory\" issues (b/316266643)\nbuild:rbe_cross_compile_macos_x86 --jobs=100\ntest:rbe_cross_compile_macos_x86 --jobs=100\n# END MACOS CROSS-COMPILE CONFIGS\n# END CROSS-COMPILE CONFIGS\n\n# Try to load the XLA warnings config if available\ntry-import %workspace%/warnings.bazelrc\n"
        },
        {
          "name": ".bazelversion",
          "type": "blob",
          "size": 0.0830078125,
          "content": "6.5.0\n# NOTE: Update Bazel version in tensorflow/tools/ci_build/release/common.sh.oss"
        },
        {
          "name": ".clang-format",
          "type": "blob",
          "size": 0.12109375,
          "content": "# Run manually to reformat a file:\n# clang-format -i --style=file <file>\nBasedOnStyle: Google\nDerivePointerAlignment: false\n"
        },
        {
          "name": ".github",
          "type": "tree",
          "content": null
        },
        {
          "name": ".gitignore",
          "type": "blob",
          "size": 0.9228515625,
          "content": ".DS_Store\n.ipynb_checkpoints\nnode_modules\n/.bazelrc.user\n/.tf_configure.bazelrc\n/xla_configure.bazelrc\n/bazel-*\n/bazel_pip\n/tools/python_bin_path.sh\n/tensorflow/tools/git/gen\n/pip_test\n/_python_build\n*.pyc\n__pycache__\n*.swp\n.vscode/\ncmake_build/\ntensorflow/contrib/cmake/_build/\n.idea/**\n/build/\n[Bb]uild/\n/build_output/\n/tensorflow/core/util/version_info.cc\n/tensorflow/python/framework/fast_tensor_util.cpp\n/tensorflow/lite/gen/**\n/tensorflow/lite/tools/make/downloads/**\n/tensorflow/lite/tools/make/gen/**\n/api_init_files_list.txt\n/estimator_api_init_files_list.txt\n*.whl\ndist\nvenv/\n\n# Android\n.gradle\n.idea\n*.iml\nlocal.properties\ngradleBuild\n\n# iOS\n*.pbxproj\n*.xcworkspace\n/*.podspec\n/tensorflow/lite/**/coreml/**/BUILD\n/tensorflow/lite/**/ios/BUILD\n/tensorflow/lite/**/objc/BUILD\n/tensorflow/lite/**/swift/BUILD\n/tensorflow/lite/examples/ios/simple/data/*.tflite\n/tensorflow/lite/examples/ios/simple/data/*.txt\nPodfile.lock\nPods\nxcuserdata\n"
        },
        {
          "name": ".pylintrc",
          "type": "blob",
          "size": 0.033203125,
          "content": "tensorflow/tools/ci_build/pylintrc"
        },
        {
          "name": ".zenodo.json",
          "type": "blob",
          "size": 0.7236328125,
          "content": "{\n    \"description\": \"TensorFlow is an end-to-end open source platform for machine learning. It has a comprehensive, flexible ecosystem of tools, libraries, and community resources that lets researchers push the state-of-the-art in ML and developers easily build and deploy ML-powered applications.\",\n    \"license\": \"Apache-2.0\",\n    \"title\": \"TensorFlow\",\n    \"upload_type\": \"software\",\n    \"creators\": [\n        {\n            \"name\": \"TensorFlow Developers\"\n        }\n    ],\n    \"access_right\": \"open\",\n    \"notes\": \"Specific TensorFlow versions can be found in the \\\"Versions\\\" list on the right side of this page.<br>See the full list of authors <a href=\\\"https://github.com/tensorflow/tensorflow/graphs/contributors\\\">on GitHub</a>.\"\n}\n"
        },
        {
          "name": "AUTHORS",
          "type": "blob",
          "size": 0.3486328125,
          "content": "# This is the official list of TensorFlow authors for copyright purposes.\n# This file is distinct from the CONTRIBUTORS files.\n# See the latter for an explanation.\n\n# Names should be added to this file as:\n# Name or Organization <email address>\n# The email address is not required for organizations.\n\nGoogle Inc.\nYuan Tang <terrytangyuan@gmail.com>\nArm Ltd\n"
        },
        {
          "name": "BUILD",
          "type": "blob",
          "size": 0.1181640625,
          "content": "exports_files(glob([\"requirements*\"]) + [\n    \"configure\",\n    \"configure.py\",\n    \"ACKNOWLEDGEMENTS\",\n    \"LICENSE\",\n])\n"
        },
        {
          "name": "CITATION.cff",
          "type": "blob",
          "size": 3.533203125,
          "content": "cff-version: 1.2.0\nmessage: \"If you use TensorFlow in your research, please cite it using these metadata. Software is available from tensorflow.org.\"\ntitle: TensorFlow, Large-scale machine learning on heterogeneous systems\nabstract: TensorFlow is a machine learning system that operates at large scale and in heterogeneous environments. TensorFlow uses dataflow graphs to represent computation, shared state, and the operations that mutate that state. It maps the nodes of a dataflow graph across many machines in a cluster, and within a machine across multiple computational devices, including multicore CPUs, general purpose GPUs, and custom-designed ASICs known as Tensor Processing Units (TPUs). This architecture gives flexibility to the application developer, whereas in previous parameter server designs the management of shared state is built into the system, TensorFlow enables developers to experiment with novel optimizations and training algorithms. TensorFlow supports a variety of applications, with a focus on training and inference on deep neural networks. Several Google services use TensorFlow in production, we have released it as an open-source project, and it has become widely used for machine learning research. In this paper, we describe the TensorFlow dataflow model and demonstrate the compelling performance that TensorFlow achieves for several real-world applications.\nauthors:\n  - family-names: Abadi\n    given-names: Martn\n  - family-names: Agarwal\n    given-names: Ashish\n  - family-names: Barham\n    given-names: Paul\n  - family-names: Brevdo\n    given-names: Eugene\n  - family-names: Chen\n    given-names: Zhifeng\n  - family-names: Citro\n    given-names: Craig\n  - family-names: Corrado\n    given-names: Greg S.\n  - family-names: Davis\n    given-names: Andy\n  - family-names: Dean\n    given-names: Jeffrey\n  - family-names: Devin\n    given-names: Matthieu\n  - family-names: Ghemawat\n    given-names: Sanjay\n  - family-names: Goodfellow\n    given-names: Ian\n  - family-names: Harp\n    given-names: Andrew\n  - family-names: Irving\n    given-names: Geoffrey\n  - family-names: Isard\n    given-names: Michael\n  - family-names: Jozefowicz\n    given-names: Rafal\n  - family-names: Jia\n    given-names: Yangqing\n  - family-names: Kaiser\n    given-names: Lukasz\n  - family-names: Kudlur\n    given-names: Manjunath\n  - family-names: Levenberg\n    given-names: Josh\n  - family-names: Man\n    given-names: Dan\n  - family-names: Schuster\n    given-names: Mike\n  - family-names: Monga\n    given-names: Rajat\n  - family-names: Moore\n    given-names: Sherry\n  - family-names: Murray\n    given-names: Derek\n  - family-names: Olah\n    given-names: Chris\n  - family-names: Shlens\n    given-names: Jonathon\n  - family-names: Steiner\n    given-names: Benoit\n  - family-names: Sutskever\n    given-names: Ilya\n  - family-names: Talwar\n    given-names: Kunal\n  - family-names: Tucker\n    given-names: Paul\n  - family-names: Vanhoucke\n    given-names: Vincent\n  - family-names: Vasudevan\n    given-names: Vijay\n  - family-names: Vigas\n    given-names: Fernanda\n  - family-names: Vinyals\n    given-names: Oriol\n  - family-names: Warden\n    given-names: Pete\n  - family-names: Wattenberg\n    given-names: Martin\n  - family-names: Wicke\n    given-names: Martin\n  - family-names: Yu\n    given-names: Yuan\n  - family-names: Zheng\n    given-names: Xiaoqiang\nidentifiers:\n  - type: doi\n    value: 10.5281/zenodo.4724125\n    description: The concept DOI for the collection containing all versions of the Citation File Format.\ndate-released: \"2015-11-09\"\nlicense: \"Apache-2.0\"\ndoi: 10.5281/zenodo.4724125\n \n"
        },
        {
          "name": "CODEOWNERS",
          "type": "blob",
          "size": 0.5498046875,
          "content": "# Where component owners are known, add them here.\n\n/tensorflow/c/eager @qqfish\n/tensorflow/core/common_runtime/eager @qqfish\n/tenosrflow/core/debug @caisq\n/tensorflow/core/kernels/mkl/ @penpornk\n/tensorflow/core/kernels/sparse/ @penpornk\n/tensorflow/core/nccl/ @azaks2 @chsigg\n/tensorflow/python/autograph/ @mdanatg\n/tensorflow/python/debug @caisq\n/tensorflow/python/eager @rohan100jain\n/tensorflow/tools/docs/ @markdaoust\n/tensorflow/compiler/mlir/ @aminim\n/tensorflow/core/ir/ @aminim\n/tensorflow/core/transforms/ @aminim\n\n\n/third_party/systemlibs/ @perfinion\n"
        },
        {
          "name": "CODE_OF_CONDUCT.md",
          "type": "blob",
          "size": 5.244140625,
          "content": "# TensorFlow Code of Conduct\n\nIn the interest of fostering an open and welcoming environment, we as\ncontributors and maintainers pledge to make participation in our project and our\ncommunity a harassment-free experience for everyone, regardless of age, body\nsize, disability, ethnicity, gender identity and expression, level of\nexperience, nationality, personal appearance, race, religion, or sexual identity\nand orientation.\n\n## Our Standards\n\nExamples of behavior that contributes to creating a positive environment include:\n\n*   Using welcoming and inclusive language.\n*   Being respectful of differing viewpoints and experiences.\n*   Gracefully accepting constructive criticism.\n*   Focusing on what is best for the community.\n*   Showing empathy towards other community members.\n\nExamples of unacceptable behavior by participants include:\n\n*   The use of sexualized language or imagery and unwelcome sexual attention or\n    advances.\n*   Trolling, insulting/derogatory comments, and personal or political attacks.\n*   Public or private harassment.\n*   Publishing others' private information, such as a physical or electronic\n    address, without explicit permission.\n*   Conduct which could reasonably be considered inappropriate for the forum in\n    which it occurs.\n\nAll TensorFlow forums and spaces are meant for professional interactions, and any behavior which could reasonably be considered inappropriate in a professional setting is unacceptable.\n\n\n## Our Responsibilities\n\nProject maintainers are responsible for clarifying the standards of acceptable behavior and are expected to take appropriate and fair corrective action in response to any instances of unacceptable behavior.\n\nProject maintainers have the right and responsibility to remove, edit, or reject comments, commits, code, wiki edits, issues, and other contributions that are not aligned to this Code of Conduct, or to ban temporarily or permanently any contributor for other behaviors that they deem inappropriate, threatening, offensive, or harmful.\n\n\n## Scope\n\nThis Code of Conduct applies to all content on tensorflow.org, TensorFlows GitHub organization, or any other official TensorFlow web presence allowing for community interactions, as well as at all official TensorFlow events, whether offline or online.\n\nThe Code of Conduct also applies within project spaces and in public spaces whenever an individual is representing TensorFlow or its community. Examples of representing a project or community include using an official project e-mail address, posting via an official social media account, or acting as an appointed or de facto representative at an online or offline event. \n\n\n## Conflict Resolution\n\nConflicts in an open source project can take many forms, from someone having a bad day and using harsh and hurtful language in the issue queue, to more serious instances such as sexist/racist statements or threats of violence, and everything in between.\n\nIf the behavior is threatening or harassing, or for other reasons requires immediate escalation, please see below.\n\nHowever, for the vast majority of issues, we aim to empower individuals to first resolve conflicts themselves, asking for help when needed, and only after that fails to escalate further. This approach gives people more control over the outcome of their dispute. \n\nIf you are experiencing or witnessing conflict, we ask you to use the following escalation strategy to address the conflict:\n\n1.  Address the perceived conflict directly with those involved, preferably in a\n    real-time medium.\n2.  If this fails, get a third party (e.g. a mutual friend, and/or someone with\n    background on the issue, but not involved in the conflict) to intercede.\n3.  If you are still unable to resolve the conflict, and you believe it rises to\n    harassment or another code of conduct violation, report it.\n\n## Reporting Violations\n\nViolations of the Code of Conduct can be reported to TensorFlows Project Stewards, Thea Lamkin (thealamkin@google.com) and Joana Carrasqueira (joanafilipa@google.com). The Project Steward will determine whether the Code of Conduct was violated, and will issue an appropriate sanction, possibly including a written warning or expulsion from the project, project sponsored spaces, or project forums. We ask that you make a good-faith effort to resolve your conflict via the conflict resolution policy before submitting a report.\n\nViolations of the Code of Conduct can occur in any setting, even those unrelated to the project. We will only consider complaints about conduct that has occurred within one year of the report.\n\n\n## Enforcement\n\nIf the Project Stewards receive a report alleging a violation of the Code of Conduct, the Project Stewards will notify the accused of the report, and provide them an opportunity to discuss the report before a sanction is issued. The Project Stewards will do their utmost to keep the reporter anonymous. If the act is ongoing (such as someone engaging in harassment), or involves a threat to anyone's safety (e.g. threats of violence), the Project Stewards may issue sanctions without notice.\n\n\n## Attribution\n\nThis Code of Conduct is adapted from the Contributor Covenant, version 1.4, available at https://contributor-covenant.org/version/1/4, and includes some aspects of the Geek Feminism Code of Conduct and the Drupal Code of Conduct.\n"
        },
        {
          "name": "CONTRIBUTING.md",
          "type": "blob",
          "size": 15.8525390625,
          "content": "# Contributing guidelines\n\n## Pull Request Checklist\n\nBefore sending your pull requests, make sure you do the following:\n\n-   Read the [contributing guidelines](CONTRIBUTING.md).\n-   Read the [Code of Conduct](CODE_OF_CONDUCT.md).\n-   Ensure you have signed the\n    [Contributor License Agreement (CLA)](https://cla.developers.google.com/).\n-   Check if your changes are consistent with the\n    [guidelines](#general-guidelines-and-philosophy-for-contribution).\n-   Changes are consistent with the [Coding Style](#c-coding-style).\n-   Run the [unit tests](#running-unit-tests).\n\n## How to become a contributor and submit your own code\n\n![Screen Shot 2022-08-30 at 7 27 04 PM](https://user-images.githubusercontent.com/42785357/187579207-9924eb32-da31-47bb-99f9-d8bf1aa238ad.png)\n\n### Typical Pull Request Workflow -\n\n**1. New PR**\n\n- As a contributor, you submit a New PR on GitHub.\n- We inspect every incoming PR and add certain labels to the PR such as `size:`,\n  `comp:` etc.  At this stage we check if the PR is valid and meets certain\n  quality requirements. For example, we check if the CLA is signed, PR has\n  sufficient description, if applicable unit tests are added, if it is a\n  reasonable contribution (meaning it is not a single liner cosmetic PR).\n\n**2. Valid?**\n\n-   If the PR passes all the quality checks then we go ahead and assign a\n    reviewer.\n-   If the PR didn't meet the validation criteria, we request for additional\n    changes to be made to PR to pass quality checks and send it back or on a\n    rare occasion we may reject it.\n\n**3. Review**\n\n-   For a valid PR, reviewer (person familiar with the code/functionality)\n    checks if the PR looks good or needs additional changes.\n-   If all looks good, the reviewer will approve the PR.\n-   If a change is needed, the contributor is requested to make the suggested\n    change.\n-   You make the change and submit it for the review again.\n-   This cycle repeats itself until the PR gets approved.\n-   Note: As a friendly reminder, we may reach out to you if the PR is awaiting\n    your response for more than 2 weeks.\n\n**4. Approved**\n\n-   Once the PR is approved, it gets `kokoro:force-run` label applied and it\n    initiates CI/CD tests.\n-   We can't move forward if these tests fail.\n-   In such situations, we may request you to make further changes to your PR\n    for the tests to pass.\n-   Once the tests pass, we now bring all the code into the internal code base,\n    using a job called \"copybara\".\n\n**5. Copy to Google Internal codebase and run internal CI**\n\n-   Once the PR is in the Google codebase, we make sure it integrates well with\n    its dependencies and the rest of the system.\n-   Rarely, If the tests fail at this stage, we cannot merge the code.\n-   If needed, we may come to you to make some changes. At times, it may not be\n    you, it may be us who may have hit a snag. Please be patient while we work\n    to fix this.\n-   Once the internal tests pass, we go ahead and merge the code internally as\n    well as externally on GitHub.\n\nIn a graphical form, the entire lifetime of a PR looks like\n\n![image](https://github.com/tensorflow/tensorflow/assets/52792999/3eea4ca5-daa0-4570-b0b5-2a2b03a724a3)\n\n### Contributor License Agreements\n\nWe'd love to accept your patches! Before we can take them, we have to jump a couple of legal hurdles.\n\nPlease fill out either the individual or corporate Contributor License Agreement (CLA).\n\n  * If you are an individual writing original source code and you're sure you own the intellectual property, then you'll need to sign an [individual CLA](https://code.google.com/legal/individual-cla-v1.0.html).\n  * If you work for a company that wants to allow you to contribute your work, then you'll need to sign a [corporate CLA](https://code.google.com/legal/corporate-cla-v1.0.html).\n\nFollow either of the two links above to access the appropriate CLA and instructions for how to sign and return it. Once we receive it, we'll be able to accept your pull requests.\n\n***NOTE***: Only original source code from you and other people that have signed the CLA can be accepted into the main repository.\n\n### Contributing code\n\nIf you have improvements to TensorFlow, send us your pull requests! For those\njust getting started, GitHub has a\n[how-to](https://help.github.com/articles/using-pull-requests/).\n\nTensorFlow team members will be assigned to review your pull requests. Once the\npull requests are approved and pass continuous integration checks, a TensorFlow\nteam member will apply `ready to pull` label to your change. This means we are\nworking on getting your pull request submitted to our internal repository. After\nthe change has been submitted internally, your pull request will be merged\nautomatically on GitHub.\n\nIf you want to contribute, start working through the TensorFlow codebase,\nnavigate to the\n[GitHub \"issues\" tab](https://github.com/tensorflow/tensorflow/issues) and start\nlooking through interesting issues. If you are not sure of where to start, then\nstart by trying one of the smaller/easier issues here i.e.\n[issues with the \"good first issue\" label](https://github.com/tensorflow/tensorflow/labels/good%20first%20issue)\nand then take a look at the\n[issues with the \"contributions welcome\" label](https://github.com/tensorflow/tensorflow/labels/stat%3Acontributions%20welcome).\nThese are issues that we believe are particularly well suited for outside\ncontributions, often because we probably won't get to them right now. If you\ndecide to start on an issue, leave a comment so that other people know that\nyou're working on it. If you want to help out, but not alone, use the issue\ncomment thread to coordinate.\n\n### Contribution guidelines and standards\n\nBefore sending your pull request for\n[review](https://github.com/tensorflow/tensorflow/pulls),\nmake sure your changes are consistent with the guidelines and follow the\nTensorFlow coding style.\n\n#### General guidelines and philosophy for contribution\n\n*   Include unit tests when you contribute new features, as they help to a)\n    prove that your code works correctly, and b) guard against future breaking\n    changes to lower the maintenance cost.\n*   Bug fixes also generally require unit tests, because the presence of bugs\n    usually indicates insufficient test coverage.\n*   Keep API compatibility in mind when you change code in core TensorFlow,\n    e.g., code in\n    [tensorflow/core](https://github.com/tensorflow/tensorflow/tree/master/tensorflow/core)\n    and\n    [tensorflow/python](https://github.com/tensorflow/tensorflow/tree/master/tensorflow/python).\n    TensorFlow has passed version 1.0 and hence cannot make\n    non-backward-compatible API changes without a major release. Reviewers of\n    your pull request will comment on any API compatibility issues\n    [following API review practices](https://github.com/tensorflow/community/blob/master/governance/api-reviews.md).\n*   When you contribute a new feature to TensorFlow, the maintenance burden is\n    (by default) transferred to the TensorFlow team. This means that the benefit\n    of the contribution must be compared against the cost of maintaining the\n    feature.\n*   Full new features (e.g., a new op implementing a cutting-edge algorithm)\n    typically will live in\n    [tensorflow/addons](https://github.com/tensorflow/addons) to get some\n    airtime before a decision is made regarding whether they are to be migrated\n    to the core.\n*   As every PR requires several CPU/GPU hours of CI testing, we discourage\n    submitting PRs to fix one typo, one warning,etc. We recommend fixing the\n    same issue at the file level at least (e.g.: fix all typos in a file, fix\n    all compiler warnings in a file, etc.)\n*   Tests should follow the\n    [testing best practices](https://www.tensorflow.org/community/contribute/tests)\n    guide.\n\n#### License\n\nInclude a license at the top of new files.\n\n*   [C/C++ license example](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/framework/op.cc#L1)\n*   [Python license example](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/ops/nn.py#L1)\n*   [Java license example](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/java/src/main/java/org/tensorflow/Graph.java#L1)\n*   [Go license example](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/go/operation.go#L1)\n*   [Bash license example](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/tools/ci_build/ci_build.sh#L2)\n*   [JavaScript/TypeScript license example](https://github.com/tensorflow/tensorboard/blob/master/tensorboard/components/tf_backend/backend.ts#L1)\n\nBazel BUILD files also need to include a license section, e.g.,\n[BUILD example](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/BUILD#L61).\n\n#### C++ coding style\n\nChanges to TensorFlow C++ code should conform to\n[Google C++ Style Guide](https://google.github.io/styleguide/cppguide.html).\n\nUse `clang-tidy` to check your C/C++ changes. To install `clang-tidy` on ubuntu:16.04, do:\n\n```bash\napt-get install -y clang-tidy\n```\n\nYou can check a C/C++ file by doing:\n\n\n```bash\nclang-format <my_cc_file> --style=google > /tmp/my_cc_file.cc\ndiff <my_cc_file> /tmp/my_cc_file.cc\n```\n\n#### Python coding style\n\nChanges to TensorFlow Python code should conform to\n[Google Python Style Guide](https://github.com/google/styleguide/blob/gh-pages/pyguide.md)\n\nUse `pylint` to check your Python changes. To install `pylint` and check a file\nwith `pylint` against TensorFlow's custom style definition:\n\n```bash\npip install pylint\npylint --rcfile=tensorflow/tools/ci_build/pylintrc myfile.py\n```\n\nNote `pylint --rcfile=tensorflow/tools/ci_build/pylintrc` should run from the\ntop level tensorflow directory.\n\n#### Coding style for other languages\n\n*   [Google Java Style Guide](https://google.github.io/styleguide/javaguide.html)\n*   [Google JavaScript Style Guide](https://google.github.io/styleguide/jsguide.html)\n*   [Google Shell Style Guide](https://google.github.io/styleguide/shellguide.html)\n*   [Google Objective-C Style Guide](https://google.github.io/styleguide/objcguide.html)\n\n#### Running sanity check\n\nIf you have Docker installed on your system, you can perform a sanity check on\nyour changes by running the command:\n\n```bash\ntensorflow/tools/ci_build/ci_build.sh CPU tensorflow/tools/ci_build/ci_sanity.sh\n```\n\nThis will catch most license, Python coding style and BUILD file issues that\nmay exist in your changes.\n\n#### Running unit tests\n\nThere are two ways to run TensorFlow unit tests.\n\n1.  Using tools and libraries installed directly on your system.\n\n    Refer to the\n    [CPU-only developer Dockerfile](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/tools/dockerfiles/dockerfiles/devel-cpu.Dockerfile)\n    and\n    [GPU developer Dockerfile](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/tools/dockerfiles/dockerfiles/devel-gpu.Dockerfile)\n    for the required packages. Alternatively, use the said\n    [tensorflow/build Docker images](https://hub.docker.com/r/tensorflow/build)\n    (`tensorflow/tensorflow:devel` and `tensorflow/tensorflow:devel-gpu` are no\n    longer supported for development). Use TF SIG Build Dockerfiles in\n    development to avoid installing the packages directly on your system (in\n    which case remember to change the directory from `/root` to `/tensorflow`\n    once you get into the running container so `bazel` can find the `tensorflow`\n    workspace).\n\n    you can do this by using the following command. As an example-\n\n    ```bash\n    docker run -it --rm -v $PWD:/tmp -w /tmp tensorflow/build:2.15-python3.10\n    ```\n\n    Once you have the packages installed, you can run a specific unit test in\n    bazel by doing as follows:\n\n    ```bash\n    export flags=\"--config=opt -k\"\n    ```\n\n    If the tests are to be run on the GPU:\n\n    *   For TensorFlow versions starting from v.2.18.0: Add the `cuda` option\n        flag.\n\n        ```bash\n        export flags=\"--config=opt --config=cuda -k\"\n        ```\n\n    *   For TensorFlow versions prior v.2.18.0: Add CUDA paths to\n        LD_LIBRARY_PATH and add the `cuda` option flag.\n\n        ```bash\n        export LD_LIBRARY_PATH=\"${LD_LIBRARY_PATH}:/usr/local/cuda/lib64:/usr/local/cuda/extras/CUPTI/lib64:$LD_LIBRARY_PATH\"\n        export flags=\"--config=opt --config=cuda -k\"\n        ```\n\n    For example, to run all tests under tensorflow/python, do:\n\n    ```bash\n    bazel test ${flags} //tensorflow/python/...\n    ```\n\n    For a single component e.g. softmax op:\n\n    ```bash\n    bazel test ${flags} tensorflow/python/kernel_tests/nn_ops:softmax_op_test\n    ```\n\n    For a single/parameterized test e.g. `test_capture_variables` in\n    `tensorflow/python/saved_model/load_test.py`:\n\n    (Requires `python>=3.7`)\n\n    ```bash\n    bazel test ${flags} //tensorflow/python/saved_model:load_test --test_filter=*LoadTest.test_capture_variables*\n    ```\n\n    **Note:** You can add `--test_sharding_strategy=disabled` to the `flags` to\n    disable the sharding so that all the test outputs are in one file. However,\n    it may slow down the tests for not running in parallel and may cause the\n    test to timeout but it could be useful when you need to execute a single\n    test or more in general your filtered/selected tests have a very low\n    execution time and the sharding\n    [could create an overhead on the test execution](https://github.com/bazelbuild/bazel/issues/2113#issuecomment-264054799).\n\n2.  Using [Docker](https://www.docker.com) and TensorFlow's CI scripts.\n\n    ```bash\n    # Install Docker first, then this will build and run cpu tests\n    tensorflow/tools/ci_build/ci_build.sh CPU bazel test //tensorflow/...\n    ```\n\n    See\n    [TensorFlow Builds](https://github.com/tensorflow/tensorflow/tree/master/tensorflow/tools/ci_build)\n    for details.\n\n#### Running doctest for testable docstring\n\nThere are two ways to test the code in the docstring locally:\n\n1.  If you are only changing the docstring of a class/function/method, then you\n    can test it by passing that file's path to\n    [tf_doctest.py](https://www.tensorflow.org/code/tensorflow/tools/docs/tf_doctest.py).\n    For example:\n\n    ```bash\n    python tf_doctest.py --file=<file_path>\n    ```\n\n    This will run it using your installed version of TensorFlow. To be sure\n    you're running the same code that you're testing:\n\n    *   Use an up to date [tf-nightly](https://pypi.org/project/tf-nightly/)\n        `pip install -U tf-nightly`\n    *   Rebase your pull request onto a recent pull from\n        [TensorFlow's](https://github.com/tensorflow/tensorflow) master branch.\n\n2.  If you are changing the code and the docstring of a class/function/method,\n    then you will need to\n    [build TensorFlow from source](https://www.tensorflow.org/install/source).\n    Once you are setup to build from source, you can run the tests:\n\n    ```bash\n    bazel run //tensorflow/tools/docs:tf_doctest\n    ```\n\n    or\n\n    ```bash\n    bazel run //tensorflow/tools/docs:tf_doctest -- --module=ops.array_ops\n    ```\n\n    The `--module` is relative to `tensorflow.python`.\n\n#### Debug builds\n\nWhen [building Tensorflow](https://www.tensorflow.org/install/source), passing\n`--config=dbg` to Bazel will build with debugging information and without\noptimizations, allowing you to use GDB or other debuggers to debug C++ code. For\nexample, you can build the pip package with debugging information by running:\n\n```bash\nbazel build --config=dbg //tensorflow/tools/pip_package:build_pip_package\n```\n\nTensorFlow kernels and TensorFlow's dependencies are still not built with\ndebugging information with `--config=dbg`, as issues occur on Linux if\nthere is too much debug info (see [this GitHub\nissue](https://github.com/tensorflow/tensorflow/issues/48919) for context). If\nyou want to debug a kernel, you can compile specific files with `-g` using the\n`--per_file_copt` bazel option. For example, if you want to debug the Identity\nop, which are in files starting with `identity_op`, you can run\n\n```bash\nbazel build --config=dbg --per_file_copt=+tensorflow/core/kernels/identity_op.*@-g //tensorflow/tools/pip_package:build_pip_package\n```\n\nNote that the `--config=dbg` option is not officially supported.\n"
        },
        {
          "name": "ISSUES.md",
          "type": "blob",
          "size": 0.591796875,
          "content": "If you open a GitHub Issue, here is our policy:\n\n1.  It must be a bug/performance issue or a feature request or a build issue or\n    a documentation issue (for small doc fixes please send a PR instead).\n1.  Make sure the Issue Template is filled out.\n1.  The issue should be related to the repo it is created in.\n\n**Here's why we have this policy:** We want to focus on the work that benefits\nthe whole community, e.g., fixing bugs and adding features. Individual support\nshould be sought on Stack Overflow or other non-GitHub channels. It helps us to\naddress bugs and feature requests in a timely manner.\n"
        },
        {
          "name": "LICENSE",
          "type": "blob",
          "size": 13.2568359375,
          "content": "                                 Apache License\n                           Version 2.0, January 2004\n                        http://www.apache.org/licenses/\n\n   TERMS AND CONDITIONS FOR USE, REPRODUCTION, AND DISTRIBUTION\n\n   1. Definitions.\n\n      \"License\" shall mean the terms and conditions for use, reproduction,\n      and distribution as defined by Sections 1 through 9 of this document.\n\n      \"Licensor\" shall mean the copyright owner or entity authorized by\n      the copyright owner that is granting the License.\n\n      \"Legal Entity\" shall mean the union of the acting entity and all\n      other entities that control, are controlled by, or are under common\n      control with that entity. For the purposes of this definition,\n      \"control\" means (i) the power, direct or indirect, to cause the\n      direction or management of such entity, whether by contract or\n      otherwise, or (ii) ownership of fifty percent (50%) or more of the\n      outstanding shares, or (iii) beneficial ownership of such entity.\n\n      \"You\" (or \"Your\") shall mean an individual or Legal Entity\n      exercising permissions granted by this License.\n\n      \"Source\" form shall mean the preferred form for making modifications,\n      including but not limited to software source code, documentation\n      source, and configuration files.\n\n      \"Object\" form shall mean any form resulting from mechanical\n      transformation or translation of a Source form, including but\n      not limited to compiled object code, generated documentation,\n      and conversions to other media types.\n\n      \"Work\" shall mean the work of authorship, whether in Source or\n      Object form, made available under the License, as indicated by a\n      copyright notice that is included in or attached to the work\n      (an example is provided in the Appendix below).\n\n      \"Derivative Works\" shall mean any work, whether in Source or Object\n      form, that is based on (or derived from) the Work and for which the\n      editorial revisions, annotations, elaborations, or other modifications\n      represent, as a whole, an original work of authorship. For the purposes\n      of this License, Derivative Works shall not include works that remain\n      separable from, or merely link (or bind by name) to the interfaces of,\n      the Work and Derivative Works thereof.\n\n      \"Contribution\" shall mean any work of authorship, including\n      the original version of the Work and any modifications or additions\n      to that Work or Derivative Works thereof, that is intentionally\n      submitted to Licensor for inclusion in the Work by the copyright owner\n      or by an individual or Legal Entity authorized to submit on behalf of\n      the copyright owner. For the purposes of this definition, \"submitted\"\n      means any form of electronic, verbal, or written communication sent\n      to the Licensor or its representatives, including but not limited to\n      communication on electronic mailing lists, source code control systems,\n      and issue tracking systems that are managed by, or on behalf of, the\n      Licensor for the purpose of discussing and improving the Work, but\n      excluding communication that is conspicuously marked or otherwise\n      designated in writing by the copyright owner as \"Not a Contribution.\"\n\n      \"Contributor\" shall mean Licensor and any individual or Legal Entity\n      on behalf of whom a Contribution has been received by Licensor and\n      subsequently incorporated within the Work.\n\n   2. Grant of Copyright License. Subject to the terms and conditions of\n      this License, each Contributor hereby grants to You a perpetual,\n      worldwide, non-exclusive, no-charge, royalty-free, irrevocable\n      copyright license to reproduce, prepare Derivative Works of,\n      publicly display, publicly perform, sublicense, and distribute the\n      Work and such Derivative Works in Source or Object form.\n\n   3. Grant of Patent License. Subject to the terms and conditions of\n      this License, each Contributor hereby grants to You a perpetual,\n      worldwide, non-exclusive, no-charge, royalty-free, irrevocable\n      (except as stated in this section) patent license to make, have made,\n      use, offer to sell, sell, import, and otherwise transfer the Work,\n      where such license applies only to those patent claims licensable\n      by such Contributor that are necessarily infringed by their\n      Contribution(s) alone or by combination of their Contribution(s)\n      with the Work to which such Contribution(s) was submitted. If You\n      institute patent litigation against any entity (including a\n      cross-claim or counterclaim in a lawsuit) alleging that the Work\n      or a Contribution incorporated within the Work constitutes direct\n      or contributory patent infringement, then any patent licenses\n      granted to You under this License for that Work shall terminate\n      as of the date such litigation is filed.\n\n   4. Redistribution. You may reproduce and distribute copies of the\n      Work or Derivative Works thereof in any medium, with or without\n      modifications, and in Source or Object form, provided that You\n      meet the following conditions:\n\n      (a) You must give any other recipients of the Work or\n          Derivative Works a copy of this License; and\n\n      (b) You must cause any modified files to carry prominent notices\n          stating that You changed the files; and\n\n      (c) You must retain, in the Source form of any Derivative Works\n          that You distribute, all copyright, patent, trademark, and\n          attribution notices from the Source form of the Work,\n          excluding those notices that do not pertain to any part of\n          the Derivative Works; and\n\n      (d) If the Work includes a \"NOTICE\" text file as part of its\n          distribution, then any Derivative Works that You distribute must\n          include a readable copy of the attribution notices contained\n          within such NOTICE file, excluding those notices that do not\n          pertain to any part of the Derivative Works, in at least one\n          of the following places: within a NOTICE text file distributed\n          as part of the Derivative Works; within the Source form or\n          documentation, if provided along with the Derivative Works; or,\n          within a display generated by the Derivative Works, if and\n          wherever such third-party notices normally appear. The contents\n          of the NOTICE file are for informational purposes only and\n          do not modify the License. You may add Your own attribution\n          notices within Derivative Works that You distribute, alongside\n          or as an addendum to the NOTICE text from the Work, provided\n          that such additional attribution notices cannot be construed\n          as modifying the License.\n\n      You may add Your own copyright statement to Your modifications and\n      may provide additional or different license terms and conditions\n      for use, reproduction, or distribution of Your modifications, or\n      for any such Derivative Works as a whole, provided Your use,\n      reproduction, and distribution of the Work otherwise complies with\n      the conditions stated in this License.\n\n   5. Submission of Contributions. Unless You explicitly state otherwise,\n      any Contribution intentionally submitted for inclusion in the Work\n      by You to the Licensor shall be under the terms and conditions of\n      this License, without any additional terms or conditions.\n      Notwithstanding the above, nothing herein shall supersede or modify\n      the terms of any separate license agreement you may have executed\n      with Licensor regarding such Contributions.\n\n   6. Trademarks. This License does not grant permission to use the trade\n      names, trademarks, service marks, or product names of the Licensor,\n      except as required for reasonable and customary use in describing the\n      origin of the Work and reproducing the content of the NOTICE file.\n\n   7. Disclaimer of Warranty. Unless required by applicable law or\n      agreed to in writing, Licensor provides the Work (and each\n      Contributor provides its Contributions) on an \"AS IS\" BASIS,\n      WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or\n      implied, including, without limitation, any warranties or conditions\n      of TITLE, NON-INFRINGEMENT, MERCHANTABILITY, or FITNESS FOR A\n      PARTICULAR PURPOSE. You are solely responsible for determining the\n      appropriateness of using or redistributing the Work and assume any\n      risks associated with Your exercise of permissions under this License.\n\n   8. Limitation of Liability. In no event and under no legal theory,\n      whether in tort (including negligence), contract, or otherwise,\n      unless required by applicable law (such as deliberate and grossly\n      negligent acts) or agreed to in writing, shall any Contributor be\n      liable to You for damages, including any direct, indirect, special,\n      incidental, or consequential damages of any character arising as a\n      result of this License or out of the use or inability to use the\n      Work (including but not limited to damages for loss of goodwill,\n      work stoppage, computer failure or malfunction, or any and all\n      other commercial damages or losses), even if such Contributor\n      has been advised of the possibility of such damages.\n\n   9. Accepting Warranty or Additional Liability. While redistributing\n      the Work or Derivative Works thereof, You may choose to offer,\n      and charge a fee for, acceptance of support, warranty, indemnity,\n      or other liability obligations and/or rights consistent with this\n      License. However, in accepting such obligations, You may act only\n      on Your own behalf and on Your sole responsibility, not on behalf\n      of any other Contributor, and only if You agree to indemnify,\n      defend, and hold each Contributor harmless for any liability\n      incurred by, or claims asserted against, such Contributor by reason\n      of your accepting any such warranty or additional liability.\n\n   END OF TERMS AND CONDITIONS\n\n   APPENDIX: How to apply the Apache License to your work.\n\n      To apply the Apache License to your work, attach the following\n      boilerplate notice, with the fields enclosed by brackets \"[]\"\n      replaced with your own identifying information. (Don't include\n      the brackets!)  The text should be enclosed in the appropriate\n      comment syntax for the file format. We also recommend that a\n      file or class name and description of purpose be included on the\n      same \"printed page\" as the copyright notice for easier\n      identification within third-party archives.\n\n   Copyright [yyyy] [name of copyright owner]\n\n   Licensed under the Apache License, Version 2.0 (the \"License\");\n   you may not use this file except in compliance with the License.\n   You may obtain a copy of the License at\n\n       http://www.apache.org/licenses/LICENSE-2.0\n\n   Unless required by applicable law or agreed to in writing, software\n   distributed under the License is distributed on an \"AS IS\" BASIS,\n   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n   See the License for the specific language governing permissions and\n   limitations under the License.\n\n## Some of TensorFlow's code is derived from Caffe, which is subject to the following copyright notice:\n\nCOPYRIGHT\n\nAll contributions by the University of California:\n\nCopyright (c) 2014, The Regents of the University of California (Regents)\nAll rights reserved.\n\nAll other contributions:\n\nCopyright (c) 2014, the respective contributors\nAll rights reserved.\n\nCaffe uses a shared copyright model: each contributor holds copyright over\ntheir contributions to Caffe. The project versioning records all such\ncontribution and copyright details. If a contributor wants to further mark\ntheir specific copyright on a particular contribution, they should indicate\ntheir copyright solely in the commit message of the change when it is\ncommitted.\n\nLICENSE\n\nRedistribution and use in source and binary forms, with or without\nmodification, are permitted provided that the following conditions are met:\n\n1. Redistributions of source code must retain the above copyright notice, this\n   list of conditions and the following disclaimer.\n\n2. Redistributions in binary form must reproduce the above copyright notice,\n   this list of conditions and the following disclaimer in the documentation\n   and/or other materials provided with the distribution.\n\n   THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS \"AS IS\" AND\n   ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED\n   WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE\n   DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT OWNER OR CONTRIBUTORS BE LIABLE FOR\n   ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES\n   (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES;\n   LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND\n   ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT\n   (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS\n   SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n\nCONTRIBUTION AGREEMENT\n\nBy contributing to the BVLC/caffe repository through pull-request, comment,\nor otherwise, the contributor releases their content to the\nlicense and copyright terms herein."
        },
        {
          "name": "README.md",
          "type": "blob",
          "size": 11.9326171875,
          "content": "<div align=\"center\">\n  <img src=\"https://www.tensorflow.org/images/tf_logo_horizontal.png\">\n</div>\n\n[![Python](https://img.shields.io/pypi/pyversions/tensorflow.svg)](https://badge.fury.io/py/tensorflow)\n[![PyPI](https://badge.fury.io/py/tensorflow.svg)](https://badge.fury.io/py/tensorflow)\n[![DOI](https://zenodo.org/badge/DOI/10.5281/zenodo.4724125.svg)](https://doi.org/10.5281/zenodo.4724125)\n[![CII Best Practices](https://bestpractices.coreinfrastructure.org/projects/1486/badge)](https://bestpractices.coreinfrastructure.org/projects/1486)\n[![OpenSSF Scorecard](https://api.securityscorecards.dev/projects/github.com/tensorflow/tensorflow/badge)](https://securityscorecards.dev/viewer/?uri=github.com/tensorflow/tensorflow)\n[![Fuzzing Status](https://oss-fuzz-build-logs.storage.googleapis.com/badges/tensorflow.svg)](https://bugs.chromium.org/p/oss-fuzz/issues/list?sort=-opened&can=1&q=proj:tensorflow)\n[![Fuzzing Status](https://oss-fuzz-build-logs.storage.googleapis.com/badges/tensorflow-py.svg)](https://bugs.chromium.org/p/oss-fuzz/issues/list?sort=-opened&can=1&q=proj:tensorflow-py)\n[![OSSRank](https://shields.io/endpoint?url=https://ossrank.com/shield/44)](https://ossrank.com/p/44)\n[![Contributor Covenant](https://img.shields.io/badge/Contributor%20Covenant-v1.4%20adopted-ff69b4.svg)](CODE_OF_CONDUCT.md)\n[![TF Official Continuous](https://tensorflow.github.io/build/TF%20Official%20Continuous.svg)](https://tensorflow.github.io/build#TF%20Official%20Continuous)\n[![TF Official Nightly](https://tensorflow.github.io/build/TF%20Official%20Nightly.svg)](https://tensorflow.github.io/build#TF%20Official%20Nightly)\n\n**`Documentation`** |\n------------------- |\n[![Documentation](https://img.shields.io/badge/api-reference-blue.svg)](https://www.tensorflow.org/api_docs/) |\n\n[TensorFlow](https://www.tensorflow.org/) is an end-to-end open source platform\nfor machine learning. It has a comprehensive, flexible ecosystem of\n[tools](https://www.tensorflow.org/resources/tools),\n[libraries](https://www.tensorflow.org/resources/libraries-extensions), and\n[community](https://www.tensorflow.org/community) resources that lets\nresearchers push the state-of-the-art in ML and developers easily build and\ndeploy ML-powered applications.\n\nTensorFlow was originally developed by researchers and engineers working within\nthe Machine Intelligence team at Google Brain to conduct research in machine\nlearning and neural networks. However, the framework is versatile enough to be\nused in other areas as well.\n\nTensorFlow provides stable [Python](https://www.tensorflow.org/api_docs/python)\nand [C++](https://www.tensorflow.org/api_docs/cc) APIs, as well as a\nnon-guaranteed backward compatible API for\n[other languages](https://www.tensorflow.org/api_docs).\n\nKeep up-to-date with release announcements and security updates by subscribing\nto\n[announce@tensorflow.org](https://groups.google.com/a/tensorflow.org/forum/#!forum/announce).\nSee all the [mailing lists](https://www.tensorflow.org/community/forums).\n\n## Install\n\nSee the [TensorFlow install guide](https://www.tensorflow.org/install) for the\n[pip package](https://www.tensorflow.org/install/pip), to\n[enable GPU support](https://www.tensorflow.org/install/gpu), use a\n[Docker container](https://www.tensorflow.org/install/docker), and\n[build from source](https://www.tensorflow.org/install/source).\n\nTo install the current release, which includes support for\n[CUDA-enabled GPU cards](https://www.tensorflow.org/install/gpu) *(Ubuntu and\nWindows)*:\n\n```\n$ pip install tensorflow\n```\n\nOther devices (DirectX and MacOS-metal) are supported using\n[Device plugins](https://www.tensorflow.org/install/gpu_plugins#available_devices).\n\nA smaller CPU-only package is also available:\n\n```\n$ pip install tensorflow-cpu\n```\n\nTo update TensorFlow to the latest version, add `--upgrade` flag to the above\ncommands.\n\n*Nightly binaries are available for testing using the\n[tf-nightly](https://pypi.python.org/pypi/tf-nightly) and\n[tf-nightly-cpu](https://pypi.python.org/pypi/tf-nightly-cpu) packages on PyPi.*\n\n#### *Try your first TensorFlow program*\n\n```shell\n$ python\n```\n\n```python\n>>> import tensorflow as tf\n>>> tf.add(1, 2).numpy()\n3\n>>> hello = tf.constant('Hello, TensorFlow!')\n>>> hello.numpy()\nb'Hello, TensorFlow!'\n```\n\nFor more examples, see the\n[TensorFlow tutorials](https://www.tensorflow.org/tutorials/).\n\n## Contribution guidelines\n\n**If you want to contribute to TensorFlow, be sure to review the\n[contribution guidelines](CONTRIBUTING.md). This project adheres to TensorFlow's\n[code of conduct](CODE_OF_CONDUCT.md). By participating, you are expected to\nuphold this code.**\n\n**We use [GitHub issues](https://github.com/tensorflow/tensorflow/issues) for\ntracking requests and bugs, please see\n[TensorFlow Forum](https://discuss.tensorflow.org/) for general questions and\ndiscussion, and please direct specific questions to\n[Stack Overflow](https://stackoverflow.com/questions/tagged/tensorflow).**\n\nThe TensorFlow project strives to abide by generally accepted best practices in\nopen-source software development.\n\n## Patching guidelines\n\nFollow these steps to patch a specific version of TensorFlow, for example, to\napply fixes to bugs or security vulnerabilities:\n\n*   Clone the TensorFlow repo and switch to the corresponding branch for your\n    desired TensorFlow version, for example, branch `r2.8` for version 2.8.\n*   Apply (that is, cherry-pick) the desired changes and resolve any code\n    conflicts.\n*   Run TensorFlow tests and ensure they pass.\n*   [Build](https://www.tensorflow.org/install/source) the TensorFlow pip\n    package from source.\n\n## Continuous build status\n\nYou can find more community-supported platforms and configurations in the\n[TensorFlow SIG Build community builds table](https://github.com/tensorflow/build#community-supported-tensorflow-builds).\n\n### Official Builds\n\nBuild Type                    | Status                                                                                                                                                                           | Artifacts\n----------------------------- | -------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | ---------\n**Linux CPU**                 | [![Status](https://storage.googleapis.com/tensorflow-kokoro-build-badges/ubuntu-cc.svg)](https://storage.googleapis.com/tensorflow-kokoro-build-badges/ubuntu-cc.html)           | [PyPI](https://pypi.org/project/tf-nightly/)\n**Linux GPU**                 | [![Status](https://storage.googleapis.com/tensorflow-kokoro-build-badges/ubuntu-gpu-py3.svg)](https://storage.googleapis.com/tensorflow-kokoro-build-badges/ubuntu-gpu-py3.html) | [PyPI](https://pypi.org/project/tf-nightly-gpu/)\n**Linux XLA**                 | [![Status](https://storage.googleapis.com/tensorflow-kokoro-build-badges/ubuntu-xla.svg)](https://storage.googleapis.com/tensorflow-kokoro-build-badges/ubuntu-xla.html)         | TBA\n**macOS**                     | [![Status](https://storage.googleapis.com/tensorflow-kokoro-build-badges/macos-py2-cc.svg)](https://storage.googleapis.com/tensorflow-kokoro-build-badges/macos-py2-cc.html)     | [PyPI](https://pypi.org/project/tf-nightly/)\n**Windows CPU**               | [![Status](https://storage.googleapis.com/tensorflow-kokoro-build-badges/windows-cpu.svg)](https://storage.googleapis.com/tensorflow-kokoro-build-badges/windows-cpu.html)       | [PyPI](https://pypi.org/project/tf-nightly/)\n**Windows GPU**               | [![Status](https://storage.googleapis.com/tensorflow-kokoro-build-badges/windows-gpu.svg)](https://storage.googleapis.com/tensorflow-kokoro-build-badges/windows-gpu.html)       | [PyPI](https://pypi.org/project/tf-nightly-gpu/)\n**Android**                   | [![Status](https://storage.googleapis.com/tensorflow-kokoro-build-badges/android.svg)](https://storage.googleapis.com/tensorflow-kokoro-build-badges/android.html)               | [Download](https://bintray.com/google/tensorflow/tensorflow/_latestVersion)\n**Raspberry Pi 0 and 1**      | [![Status](https://storage.googleapis.com/tensorflow-kokoro-build-badges/rpi01-py3.svg)](https://storage.googleapis.com/tensorflow-kokoro-build-badges/rpi01-py3.html)           | [Py3](https://storage.googleapis.com/tensorflow-nightly/tensorflow-1.10.0-cp34-none-linux_armv6l.whl)\n**Raspberry Pi 2 and 3**      | [![Status](https://storage.googleapis.com/tensorflow-kokoro-build-badges/rpi23-py3.svg)](https://storage.googleapis.com/tensorflow-kokoro-build-badges/rpi23-py3.html)           | [Py3](https://storage.googleapis.com/tensorflow-nightly/tensorflow-1.10.0-cp34-none-linux_armv7l.whl)\n**Libtensorflow MacOS CPU**   | Status Temporarily Unavailable                                                                                                                                                   | [Nightly Binary](https://storage.googleapis.com/libtensorflow-nightly/prod/tensorflow/release/macos/latest/macos_cpu_libtensorflow_binaries.tar.gz) [Official GCS](https://storage.googleapis.com/tensorflow/)\n**Libtensorflow Linux CPU**   | Status Temporarily Unavailable                                                                                                                                                   | [Nightly Binary](https://storage.googleapis.com/libtensorflow-nightly/prod/tensorflow/release/ubuntu_16/latest/cpu/ubuntu_cpu_libtensorflow_binaries.tar.gz) [Official GCS](https://storage.googleapis.com/tensorflow/)\n**Libtensorflow Linux GPU**   | Status Temporarily Unavailable                                                                                                                                                   | [Nightly Binary](https://storage.googleapis.com/libtensorflow-nightly/prod/tensorflow/release/ubuntu_16/latest/gpu/ubuntu_gpu_libtensorflow_binaries.tar.gz) [Official GCS](https://storage.googleapis.com/tensorflow/)\n**Libtensorflow Windows CPU** | Status Temporarily Unavailable                                                                                                                                                   | [Nightly Binary](https://storage.googleapis.com/libtensorflow-nightly/prod/tensorflow/release/windows/latest/cpu/windows_cpu_libtensorflow_binaries.tar.gz) [Official GCS](https://storage.googleapis.com/tensorflow/)\n**Libtensorflow Windows GPU** | Status Temporarily Unavailable                                                                                                                                                   | [Nightly Binary](https://storage.googleapis.com/libtensorflow-nightly/prod/tensorflow/release/windows/latest/gpu/windows_gpu_libtensorflow_binaries.tar.gz) [Official GCS](https://storage.googleapis.com/tensorflow/)\n\n## Resources\n\n*   [TensorFlow.org](https://www.tensorflow.org)\n*   [TensorFlow Tutorials](https://www.tensorflow.org/tutorials/)\n*   [TensorFlow Official Models](https://github.com/tensorflow/models/tree/master/official)\n*   [TensorFlow Examples](https://github.com/tensorflow/examples)\n*   [TensorFlow Codelabs](https://codelabs.developers.google.com/?cat=TensorFlow)\n*   [TensorFlow Blog](https://blog.tensorflow.org)\n*   [Learn ML with TensorFlow](https://www.tensorflow.org/resources/learn-ml)\n*   [TensorFlow Twitter](https://twitter.com/tensorflow)\n*   [TensorFlow YouTube](https://www.youtube.com/channel/UC0rqucBdTuFTjJiefW5t-IQ)\n*   [TensorFlow model optimization roadmap](https://www.tensorflow.org/model_optimization/guide/roadmap)\n*   [TensorFlow White Papers](https://www.tensorflow.org/about/bib)\n*   [TensorBoard Visualization Toolkit](https://github.com/tensorflow/tensorboard)\n*   [TensorFlow Code Search](https://cs.opensource.google/tensorflow/tensorflow)\n\nLearn more about the\n[TensorFlow community](https://www.tensorflow.org/community) and how to\n[contribute](https://www.tensorflow.org/community/contribute).\n\n## Courses\n\n* [Coursera](https://www.coursera.org/search?query=TensorFlow)\n* [Udacity](https://www.udacity.com/courses/all?search=TensorFlow)\n* [Edx](https://www.edx.org/search?q=TensorFlow)\n\n## License\n\n[Apache License 2.0](LICENSE)\n"
        },
        {
          "name": "RELEASE.md",
          "type": "blob",
          "size": 736.0751953125,
          "content": "# Release 2.19.0\n\n## TensorFlow\n\n<INSERT SMALL BLURB ABOUT RELEASE FOCUS AREA AND POTENTIAL TOOLCHAIN CHANGES>\n\n### Breaking Changes\n\n* <DOCUMENT BREAKING CHANGES HERE>\n* <THIS SECTION SHOULD CONTAIN API, ABI AND BEHAVIORAL BREAKING CHANGES>\n* `LiteRT`, a.k.a. `tf.lite`:\n  * C++ API:\n    * The public constants `tflite::Interpreter:kTensorsReservedCapacity`\n      and `tflite::Interpreter:kTensorsCapacityHeadroom` are now const\n      references, rather than `constexpr` compile-time constants.\n      (This is to enable better API compatibility for TFLite in Play services\n      while preserving the implementation flexibility to change the values of\n      these constants in the future.)\n    * Interpreter:\n      * `tf.lite.Interpreter` gives deprecation warning redirecting to its new location at `ai_edge_litert.interpreter`, as the API `tf.lite.Interpreter` will be deleted in TF 2.20. See the [migration guide](https://ai.google.dev/edge/litert/migration) for details.\n\n### Known Caveats\n\n* <CAVEATS REGARDING THE RELEASE (BUT NOT BREAKING CHANGES).>\n* <ADDING/BUMPING DEPENDENCIES SHOULD GO HERE>\n* <KNOWN LACK OF SUPPORT ON SOME PLATFORM, SHOULD GO HERE>\n\n### Major Features and Improvements\n\n*  `tf.lite`\n    * `tfl.Cast` op is now supporting `bfloat16` in runtime kernel.\n*   <IF RELEASE CONTAINS MULTIPLE FEATURES FROM SAME AREA, GROUP THEM TOGETHER>\n\n### Bug Fixes and Other Changes\n\n* <SIMILAR TO ABOVE SECTION, BUT FOR OTHER IMPORTANT CHANGES / BUG FIXES>\n* <IF A CHANGE CLOSES A GITHUB ISSUE, IT SHOULD BE DOCUMENTED HERE>\n* <NOTES SHOULD BE GROUPED PER AREA>\n\n## Keras\n\n<INSERT SMALL BLURB ABOUT RELEASE FOCUS AREA AND POTENTIAL TOOLCHAIN CHANGES>\n\n### Breaking Changes\n\n* <DOCUMENT BREAKING CHANGES HERE>\n* <THIS SECTION SHOULD CONTAIN API, ABI AND BEHAVIORAL BREAKING CHANGES>\n\n### Known Caveats\n\n* <CAVEATS REGARDING THE RELEASE (BUT NOT BREAKING CHANGES).>\n* <ADDING/BUMPING DEPENDENCIES SHOULD GO HERE>\n* <KNOWN LACK OF SUPPORT ON SOME PLATFORM, SHOULD GO HERE>\n\n### Major Features and Improvements\n\n*   <INSERT MAJOR FEATURE HERE, USING MARKDOWN SYNTAX>\n*   <IF RELEASE CONTAINS MULTIPLE FEATURES FROM SAME AREA, GROUP THEM TOGETHER>\n\n### Bug Fixes and Other Changes\n\n* <SIMILAR TO ABOVE SECTION, BUT FOR OTHER IMPORTANT CHANGES / BUG FIXES>\n* <IF A CHANGE CLOSES A GITHUB ISSUE, IT SHOULD BE DOCUMENTED HERE>\n* <NOTES SHOULD BE GROUPED PER AREA>\n\n## Thanks to our Contributors\n\nThis release contains contributions from many people at Google, as well as:\n\n<INSERT>, <NAME>, <HERE>, <USING>, <GITHUB>, <HANDLE>\n\n# Release 2.18.0\n\n## TensorFlow\n\n### Breaking Changes\n\n* `tf.lite`\n    * C API:\n      * An optional, fourth parameter was added `TfLiteOperatorCreate` as a step forward towards a cleaner API for `TfLiteOperator`. Function `TfLiteOperatorCreate` was added recently, in TensorFlow Lite version 2.17.0, released on 7/11/2024, and we do not expect there will be much code using this function yet. Any code breakages can be easily resolved by passing nullptr as the new, 4th parameter.\n\n* TensorRT support is disabled in CUDA builds for code health improvement.\n\n* TensorFlow now supports and is compiled with NumPy 2.0 by default. Please see the [NumPy 2 release notes](https://numpy.org/doc/stable/release/2.0.0-notes.html) and the [NumPy 2 migration guide](https://numpy.org/devdocs/numpy_2_0_migration_guide.html#numpy-2-migration-guide).\n  * Note that NumPy's type promotion rules have been changed(See [NEP 50](https://numpy.org/neps/nep-0050-scalar-promotion.html#nep50)for details). This may change the precision at which computations happen, leading either to type errors or to numerical changes to results.\n  * Tensorflow will continue to support NumPy 1.26 until 2025, aligning with community standard deprecation timeline [here](https://scientific-python.org/specs/spec-0000/).\n\n* Hermetic CUDA support is added.\n\n  Hermetic CUDA uses a specific downloadable version of CUDA instead of the users locally installed CUDA. Bazel will download CUDA, CUDNN and NCCL distributions, and then use CUDA libraries and tools as dependencies in various Bazel targets. This enables more reproducible builds for Google ML projects and supported CUDA versions.\n\n* Remove the `EnumNamesXNNPackFlags` function in `tensorflow/lite/acceleration/configuration/configuration_generated.h`.\n\n  This change is a bug fix in the automatically generated code. This change is automatically generated by the new flatbuffer generator. The flatbuffers library is updated to 24.3.25 in https://github.com/tensorflow/tensorflow/commit/c17d64df85a83c1bd0fd7dcc0b1230812b0d3d48. The new flatbuffers library includes the following change https://github.com/google/flatbuffers/pull/7813 which fixed a underlying flatbuffer code generator bug.\n\n\n### Known Caveats\n\n### Major Features and Improvements\n\n*   `tf.lite`:\n    *   The LiteRT [repo](https://github.com/google-ai-edge/LiteRT) is live (see [announcement](https://developers.googleblog.com/en/tensorflow-lite-is-now-litert/)), which means that in the coming months there will be changes to the development experience for TFLite. The TF Lite Runtime source will be moved later this year, and sometime after that we will start accepting contributions through that repo.\n    *   SignatureRunner is now supported for models with no signatures.\n\n### Bug Fixes and Other Changes\n\n* `tf.data`\n    * Add optional `synchronous` argument to `map`, to specify that the `map` should run synchronously, as opposed to be parallelizable when `options.experimental_optimization.map_parallelization=True`. This saves memory compared to setting `num_parallel_calls=1`.\n    * Add optional `use_unbounded_threadpool` argument to `map`, to specify that the `map` should use an unbounded threadpool instead of the default pool that is based on the number of cores on the machine. This can improve throughput for map functions which perform IO or otherwise release the CPU.\n    * Add [`tf.data.experimental.get_model_proto`](https://www.tensorflow.org/api_docs/python/tf/data/experimental/get_model_proto) to allow users to peek into the analytical model inside of a dataset iterator.\n\n* `tf.lite`\n    * `Dequantize` op supports `TensorType_INT4`.\n        * This change includes per-channel dequantization.\n    * Add support for `stablehlo.composite`.\n    * `EmbeddingLookup` op supports per-channel quantization and `TensorType_INT4` values.\n    * `FullyConnected` op supports `TensorType_INT16` activation and `TensorType_Int4` weight per-channel quantization.\n    * Enable per-tensor quantization support in dynamic range quantization of `TRANSPOSE_CONV` layer. Fixes TFLite converter [bug](https://github.com/tensorflow/tensorflow/issues/76624).\n\n* `tf.tensor_scatter_update`, `tf.tensor_scatter_add` and of other reduce types.\n    * Support `bad_indices_policy`.\n\n## Thanks to our Contributors\n\nThis release contains contributions from many people at Google, as well as:\n\nAkhil Goel, akhilgoe, Alexander Pivovarov, Amir Samani, Andrew Goodbody, Andrey Portnoy, Anthony Platanios, bernardoArcari, Brett Taylor, buptzyb, Chao, Christian Clauss, Cocoa, Daniil Kutz, Darya Parygina, dependabot[bot], Dimitris Vardoulakis, Dragan Mladjenovic, Elfie Guo, eukub, Faijul Amin, flyingcat, Frdric Bastien, ganyu.08, Georg Stefan Schmid, Grigory Reznikov, Harsha H S, Harshit Monish, Heiner, Ilia Sergachev, Jan, Jane Liu, Jaroslav Sevcik, Kaixi Hou, Kanvi Khanna, Kristof Maar, Kristf Mar, LakshmiKalaKadali, Lbertho-Gpsw, lingzhi98, MarcoFalke, Masahiro Hiramori, Mmakevic-Amd, mraunak, Nobuo Tsukamoto, Notheisz57, Olli Lupton, Pearu Peterson, pemeliya, Peyara Nando, Philipp Hack, Phuong Nguyen, Pol Dellaiera, Rahul Batra, Ruturaj Vaidya, sachinmuradi, Sergey Kozub, Shanbin Ke, Sheng Yang, shengyu, Shraiysh, Shu Wang, Surya, sushreebarsa, Swatheesh-Mcw, syzygial, Tai Ly, terryysun, tilakrayal, Tj Xu, Trevor Morris, Tzung-Han Juang, wenchenvincent, wondertx, Xuefei Jiang, Ye Huang, Yimei Sun, Yunlong Liu, Zahid Iqbal, Zhan Lu, Zoranjovanovic-Ns, Zuri Obozuwa\n\n# Release 2.17.1\n\n### Bug Fixes and Other Changes\n\n* Add necessary header files in the aar library. These are needed if developers build apps with header files unpacked from tflite aar files from maven.\n* Implement Name() for GCSWritableFile to fix the profiler trace viewer cache file generation.\n* Fix `cstring.h` missing file issue with the Libtensorflow archive.\n\n# Release 2.17.0\n\n## TensorFlow\n\n### Breaking Changes\n\n* GPU\n    * Support for NVIDIA GPUs with compute capability 5.x (Maxwell generation) has been removed from TF binary distributions (Python wheels).\n\n### Major Features and Improvements\n\n*   Add `is_cpu_target_available`, which indicates whether or not TensorFlow was built with support for a given CPU target. This can be useful for skipping target-specific tests if a target is not supported.\n\n*   `tf.data`\n    * Support `data.experimental.distribued_save`. `distribued_save` uses tf.data service (https://www.tensorflow.org/api_docs/python/tf/data/experimental/service) to write distributed dataset snapshots. The call is non-blocking and returns without waiting for the snapshot to finish. Setting `wait=True` to `tf.data.Dataset.load` allows the snapshots to be read while they are being written.\n\n### Bug Fixes and Other Changes\n\n* GPU\n    * Support for NVIDIA GPUs with compute capability 8.9 (e.g. L4 & L40) has been added to TF binary distributions (Python wheels).\n* Replace `DebuggerOptions` of TensorFlow Quantizer, and migrate to `DebuggerConfig` of StableHLO Quantizer.\n* Add TensorFlow to StableHLO converter to TensorFlow pip package.\n* TensorRT support: this is the last release supporting TensorRT. It will be removed in the next release.\n* NumPy 2.0 support: TensorFlow is going to support NumPy 2.0 in the next release. It may break some edge cases of TensorFlow API usage.\n\n* `tf.lite`\n    * Quantization for `FullyConnected` layer is switched from per-tensor to per-channel scales for dynamic range quantization use case (`float32` inputs / outputs and `int8` weights). The change enables new quantization schema globally in the converter and inference engine. The new behaviour can be disabled via experimental flag `converter._experimental_disable_per_channel_quantization_for_dense_layers = True`.\n    * C API:\n        * The experimental `TfLiteRegistrationExternal` type has been renamed as `TfLiteOperator`, and likewise for the corresponding API functions.\n    * The Python TF Lite Interpreter bindings now have an option `experimental_default_delegate_latest_features` to enable all default delegate features.\n    * Flatbuffer version update:\n        * `GetTemporaryPointer()` bug fixed.\n\n* `tf.data`\n    * Add `wait` to `tf.data.Dataset.load`. If `True`, for snapshots written with `distributed_save`, it reads the snapshot while it is being written. For snapshots written with regular `save`, it waits for the snapshot until it's finished. The default is `False` for backward compatibility. Users of `distributed_save` are recommended to set it to `True`.\n\n* `tf.tpu.experimental.embedding.TPUEmbeddingV2`\n    * Add `compute_sparse_core_stats` for sparse core users to profile the  data with this API to get the `max_ids` and `max_unique_ids`. These numbers will be needed to configure the sparse core embedding mid level api.\n    * Remove the `preprocess_features` method since that's no longer needed.\n\n## Thanks to our Contributors\n\nThis release contains contributions from many people at Google, as well as:\n\nAbdulaziz Aloqeely, Ahmad-M-Al-Khateeb, Akhil Goel, akhilgoe, Alexander Pivovarov, Amir Samani, Andrew Goodbody, Andrey Portnoy, Ashiq Imran, Ben Olson, Chao, Chase Riley Roberts, Clemens Giuliani, dependabot[bot], Dimitris Vardoulakis, Dragan Mladjenovic, ekuznetsov139, Elfie Guo, Faijul Amin, Gauri1 Deshpande, Georg Stefan Schmid, guozhong.zhuang, Hao Wu, Haoyu (Daniel), Harsha H S, Harsha Hs, Harshit Monish, Ilia Sergachev, Jane Liu, Jaroslav Sevcik, Jinzhe Zeng, Justin Dhillon, Kaixi Hou, Kanvi Khanna, LakshmiKalaKadali, Learning-To-Play, lingzhi98, Lu Teng, Matt Bahr, Max Ren, Meekail Zain, Mmakevic-Amd, mraunak, neverlva, nhatle, Nicola Ferralis, Olli Lupton, Om Thakkar, orangekame3, ourfor, pateldeev, Pearu Peterson, pemeliya, Peng Sun, Philipp Hack, Pratik Joshi, prrathi, rahulbatra85, Raunak, redwrasse, Robert Kalmar, Robin Zhang, RoboSchmied, Ruturaj Vaidya, sachinmuradi, Shawn Wang, Sheng Yang, Surya, Thibaut Goetghebuer-Planchon, Thomas Preud'Homme, tilakrayal, Tj Xu, Trevor Morris, wenchenvincent, Yimei Sun, zahiqbal, Zhu Jianjiang, Zoranjovanovic-Ns\n\n# Release 2.16.2\n\n### Bug Fixes and Other Changes\n\n*  Fixed: Incorrect dependency metadata in TensorFlow Python packages causing installation failures with certain package managers such as Poetry.\n\n# Release 2.16.1\n\n## TensorFlow\n\n*   TensorFlow Windows Build:\n\n    *   Clang is now the default compiler to build TensorFlow CPU wheels on the\n        Windows Platform starting with this release. The currently supported\n        version is LLVM/clang 17. The official Wheels-published on PyPI will be\n        based on Clang; however, users retain the option to build wheels using\n        the MSVC compiler following the steps mentioned in\n        https://www.tensorflow.org/install/source_windows as has been the case\n        before\n\n### Breaking Changes\n\n*   `tf.summary.trace_on` now takes a `profiler_outdir` argument. This must be\n    set if `profiler` arg is set to `True`.\n\n    *   `tf.summary.trace_export`'s `profiler_outdir` arg is now a no-op.\n        Enabling the profiler now requires setting `profiler_outdir` in\n        `trace_on`.\n\n*   `tf.estimator`\n\n    *   The tf.estimator API is removed.\n\n*   Keras 3.0 will be the default Keras version. You may need to update your\n    script to use Keras 3.0.\n\n*   Please refer to the new Keras documentation for Keras 3.0\n    (https://keras.io/keras_3).\n\n*   To continue using Keras 2.0, do the following.\n\n*   1.  Install tf-keras via pip install tf-keras~=2.16\n\n    1.  To switch tf.keras to use Keras 2 (tf-keras), set the environment\n        variable TF_USE_LEGACY_KERAS=1 directly or in your python program by\n        import os;os.environ[\"TF_USE_LEGACY_KERAS\"]=1. Please note that this\n        will set it for all packages in your Python runtime program\n\n*   1.  Change import of keras from tensorflow as follows\n*   import tensorflow.keras as keras and import keras to import tf_keras as\n    keras\n* **Apple Silicon users:** If you previously installed TensorFlow using\n    `pip install tensorflow-macos`, please update your installation method. Use\n    `pip install tensorflow` from now on.\n* **Mac x86 users:** Mac x86 builds are being deprecated and will no longer be\n  released as a Pip package from TF 2.17 onwards.\n\n### Known Caveats\n\n*  Full aarch64 Linux and Arm64 macOS wheels are now published to the\n  `tensorflow` pypi repository and no longer redirect to a separate package.\n\n### Major Features and Improvements\n\n*  Support for Python 3.12 has been added.\n*  [tensorflow-tpu](https://pypi.org/project/tensorflow-tpu/) package is now\n   available for easier TPU based installs.\n*  TensorFlow pip packages are now built with CUDA 12.3 and cuDNN 8.9.7\n*  Added experimental support for float16 auto-mixed precision using the new AMX-FP16 instruction set on X86 CPUs.\n\n\n### Bug Fixes and Other Changes\n\n* `tf.lite`\n    * Added support for `stablehlo.gather`.\n    * Added support for `stablehlo.add`.\n    * Added support for `stablehlo.multiply`.\n    * Added support for `stablehlo.maximum`.\n    * Added support for `stablehlo.minimum`.\n    * Added boolean parameter support for `tfl.gather_nd`.\n    * C API:\n        * New API functions:\n            * `tensorflow/lite/c/c_api_experimental.h`:\n                * `TfLiteInterpreterGetVariableTensorCount`\n                * `TfLiteInterpreterGetVariableTensor`\n                * `TfLiteInterpreterGetBufferHandle`\n                * `TfLiteInterpreterSetBufferHandle`\n            * `tensorflow/lite/c/c_api_opaque.h`:\n                * `TfLiteOpaqueTensorSetAllocationTypeToDynamic`\n        * API functions promoted from experimental to stable:\n            * `tensorflow/lite/c/c_api.h`:\n                * `TfLiteInterpreterOptionsEnableCancellation`\n                * `TfLiteInterpreterCancel`\n    * C++ API:\n        * New virtual methods in the `tflite::SimpleDelegateInterface` class in `tensorflow/lite/delegates/utils/simple_delegate.h`,\n          and likewise in the `tflite::SimpleOpaqueDelegateInterface` class in `tensorflow/lite/delegates/utils/simple_opaque_delegate.h`:\n            * `CopyFromBufferHandle`\n            * `CopyToBufferHandle`\n            * `FreeBufferHandle`\n\n* `tf.train.CheckpointOptions` and `tf.saved_model.SaveOptions`\n    * These now take in a new argument called `experimental_sharding_callback`.\n      This is a callback function wrapper that will be executed to determine how\n      tensors will be split into shards when the saver writes the checkpoint\n      shards to disk. `tf.train.experimental.ShardByTaskPolicy` is the default\n      sharding behavior, but `tf.train.experimental.MaxShardSizePolicy` can be\n      used to shard the checkpoint with a maximum shard file size. Users with\n      advanced use cases can also write their own custom\n      `tf.train.experimental.ShardingCallback`s.\n\n* `tf.train.CheckpointOptions`\n    * Added `experimental_skip_slot_variables` (a boolean option) to skip\n    restoring of optimizer slot variables in a checkpoint.\n\n*   `tf.saved_model.SaveOptions`\n\n    * `SaveOptions` now takes a new argument called\n      `experimental_debug_stripper`. When enabled, this strips the debug nodes\n      from both the node defs and the function defs of the graph. Note that\n      this currently only strips the `Assert` nodes from the graph and\n      converts them into `NoOp`s instead.\n\n*   `tf.data`\n\n    * `tf.data` now has an `autotune_options.initial_parallelism` option to\n      control the initial parallelism setting used by autotune before the data\n      pipeline has started running. The default is 16. A lower value reduces\n      initial memory usage, while a higher value improves startup time.\n\n## Keras\n\n*  `keras.layers.experimental.DynamicEmbedding`\n    * Added `DynamicEmbedding` Keras layer\n    * Added 'UpdateEmbeddingCallback`\n    * `DynamicEmbedding` layer allows for the continuous updating of the\n      vocabulary and embeddings during the training process. This layer\n      maintains a hash table to track the most up-to-date vocabulary based on\n      the inputs received by the layer and the eviction policy. When this layer\n      is used with an `UpdateEmbeddingCallback`, which is a time-based callback,\n      the vocabulary lookup tensor is updated at the time interval set in the\n      `UpdateEmbeddingCallback` based on the most up-to-date vocabulary hash\n      table maintained by the layer. If this layer is not used in conjunction\n      with `UpdateEmbeddingCallback` the behavior of the layer would be same as\n      `keras.layers.Embedding`.\n*  `keras.optimizers.Adam`\n    * Added the option to set adaptive epsilon to match implementations with Jax\n      and PyTorch equivalents.\n\n## Thanks to our Contributors\n\nThis release contains contributions from many people at Google, as well as:\n\nAakar Dwivedi, Akhil Goel, Alexander Grund, Alexander Pivovarov, Andrew Goodbody, Andrey Portnoy, Aneta Kaczyska, AnetaKaczynska, ArkadebMisra, Ashiq Imran, Ayan Moitra, Ben Barsdell, Ben Creech, Benedikt Lorch, Bhavani Subramanian, Bianca Van Schaik, Chao, Chase Riley Roberts, Connor Flanagan, David Hall, David Svantesson, David Svantesson-Yeung, dependabot[bot], Dr. Christoph Mittendorf, Dragan Mladjenovic, ekuznetsov139, Eli Kobrin, Eugene Kuznetsov, Faijul Amin, Frdric Bastien, fsx950223, gaoyiyeah, Gauri1 Deshpande, Gautam, Giulio C.N, guozhong.zhuang, Harshit Monish, James Hilliard, Jane Liu, Jaroslav Sevcik, jeffhataws, Jerome Massot, Jerry Ge, jglaser, jmaksymc, Kaixi Hou, kamaljeeti, Kamil Magierski, Koan-Sin Tan, lingzhi98, looi, Mahmoud Abuzaina, Malik Shahzad Muzaffar, Meekail Zain, mraunak, Neil Girdhar, Olli Lupton, Om Thakkar, Paul Strawder, Pavel Emeliyanenko, Pearu Peterson, pemeliya, Philipp Hack, Pierluigi Urru, Pratik Joshi, radekzc, Rafik Saliev, Ragu, Rahul Batra, rahulbatra85, Raunak, redwrasse, Rodrigo Gomes, ronaghy, Sachin Muradi, Shanbin Ke, shawnwang18, Sheng Yang, Shivam Mishra, Shu Wang, Strawder, Paul, Surya, sushreebarsa, Tai Ly, talyz, Thibaut Goetghebuer-Planchon, Tj Xu, Tom Allsop, Trevor Morris, Varghese, Jojimon, weihanmines, wenchenvincent, Wenjie Zheng, Who Who Who, Yasir Ashfaq, yasiribmcon, Yoshio Soma, Yuanqiang Liu, Yuriy Chernyshov\n\n# Release 2.15.1\n\n### Bug Fixes and Other Changes\n\n*  `ml_dtypes` runtime dependency is updated to `0.3.1` to fix package conflict issues\n\n# Release 2.15.0.post1\n\n## TensorFlow\n\n### Bug Fixes and Other Changes\n\n*   Hot-fix was needed for an issue affecting the TensorFlow installation\n    process.\n    *   TensorFlow 2.15.0 Python package was requesting `tensorrt`-related\n        packages that cannot be found unless the user installs them beforehand\n        or provides additional installation flags.\n    *   This dependency affected anyone installing TensorFlow 2.15 alongside\n        NVIDIA CUDA dependencies via `pip install tensorflow[and-cuda]`.\n    *   Depending on the installation method, TensorFlow 2.14 would be installed\n        instead of 2.15, or users could receive an installation error due to\n        those missing dependencies.\n*   TensorFlow 2.15.0.post1 is being released for Linux x86_64 to resolve this\n    issue as quickly as possible.\n    *   This version removes the `tensorrt` Python package dependencies from the\n        tensorflow[and-cuda] installation method to ensure `pip install\n        tensorflow[and-cuda]` works as originally intended for TensorFlow 2.15.\n    *   Support for TensorRT is otherwise unaffected as long as TensorRT is\n        already installed on the system.\n*   Using .post1 instead of a full minor release allowed us to push this release\n    out quickly. However, please note the following caveat:\n    *   For users wishing to pin their Python dependency in a requirements file\n        or other situation, under Python's version specification rules,\n        `tensorflow[and-cuda]==2.15.0` will not install this fixed version.\n        Please use `==2.15.0.post1` to specify this exact version on Linux\n        platforms, or a fuzzy version specification, such as `==2.15.*`, to\n        specify the most recent compatible version of TensorFlow 2.15 on all\n        platforms.\n\n# Release 2.15.0\n\n## TensorFlow\n\n### Breaking Changes\n\n* `tf.types.experimental.GenericFunction` has been renamed to `tf.types.experimental.PolymorphicFunction`.\n\n### Known Caveats\n\n### Major Features and Improvements\n\n*   [oneDNN CPU performance optimizations](https://github.com/tensorflow/community/blob/master/rfcs/20210930-enable-onednn-ops.md)\n    Windows x64 & x86.\n\n    *   **Windows x64 & x86 packages:**\n        *   oneDNN optimizations are *enabled by default* on X86 CPUs\n    *   To explicitly enable or disable oneDNN optimizations, set the environment variable `TF_ENABLE_ONEDNN_OPTS` to `1` (enable) or `0` (disable) before running TensorFlow. To fall back to default settings, unset the environment variable.\n    *   oneDNN optimizations can yield slightly different numerical results compared to when oneDNN optimizations are disabled due to floating-point round-off errors from\n different computation approaches and orders.\n    *   To verify if oneDNN optimizations are on, look for a message with *\"oneDNN custom operations are on\"* in the log. If the exact phrase is not there, it means they are off.\n\n* Making the `tf.function` type system fully available:\n\n    * `tf.types.experimental.TraceType` now allows custom tf.function inputs to declare Tensor decomposition and type casting support.\n    * Introducing `tf.types.experimental.FunctionType` as the comprehensive representation of the signature of `tf.function` callables. It can be accessed through the `function_type` property of `tf.function`s and `ConcreteFunction`s. See the `tf.types.experimental.FunctionType` documentation for more details.\n\n* Introducing `tf.types.experimental.AtomicFunction` as the fastest way to perform TF computations in Python.\n\n    * Can be accessed through `inference_fn` property of `ConcreteFunction`s\n    * Does not support gradients.\n    * See `tf.types.experimental.AtomicFunction` documentation for how to call and use it.\n\n*   `tf.data`:\n\n    *   Moved option `warm_start` from `tf.data.experimental.OptimizationOptions` to `tf.data.Options`.\n\n*   `tf.lite`:\n\n    *   `sub_op` and `mul_op` support broadcasting up to 6 dimensions.\n\n    *  The `tflite::SignatureRunner` class, which provides support for named parameters and for multiple named computations within a single TF Lite model, is no longer considered experimental. Likewise for the following signature-related methods of `tflite::Interpreter`:\n\n       *   `tflite::Interpreter::GetSignatureRunner`\n       *   `tflite::Interpreter::signature_keys`\n       *   `tflite::Interpreter::signature_inputs`\n       *   `tflite::Interpreter::signature_outputs`\n       *   `tflite::Interpreter::input_tensor_by_signature`\n       *   `tflite::Interpreter::output_tensor_by_signature`\n\n    *  Similarly, the following signature runner functions in the TF Lite C API are no longer considered experimental:\n\n       *    `TfLiteInterpreterGetSignatureCount`\n       *    `TfLiteInterpreterGetSignatureKey`\n       *    `TfLiteInterpreterGetSignatureRunner`\n       *    `TfLiteSignatureRunnerAllocateTensors`\n       *    `TfLiteSignatureRunnerGetInputCount`\n       *    `TfLiteSignatureRunnerGetInputName`\n       *    `TfLiteSignatureRunnerGetInputTensor`\n       *    `TfLiteSignatureRunnerGetOutputCount`\n       *    `TfLiteSignatureRunnerGetOutputName`\n       *    `TfLiteSignatureRunnerGetOutputTensor`\n       *    `TfLiteSignatureRunnerInvoke`\n       *    `TfLiteSignatureRunnerResizeInputTensor`\n\n    * New C API function `TfLiteExtensionApisVersion` added to `tensorflow/lite/c/c_api.h`.\n\n    * Add int8 and int16x8 support for RSQRT operator\n\n* Android NDK r25 is supported.\n\n### Bug Fixes and Other Changes\n\n*   Add TensorFlow Quantizer to TensorFlow pip package.\n\n*   `tf.sparse.segment_sum` `tf.sparse.segment_mean` `tf.sparse.segment_sqrt_n` `SparseSegmentSum/Mean/SqrtN[WithNumSegments]`\n\n    *   Added `sparse_gradient` option (default=false) that makes the gradient of these functions/ops sparse (`IndexedSlices`) instead of dense (`Tensor`), using new `SparseSegmentSum/Mean/SqrtNGradV2` ops.\n\n*   `tf.nn.embedding_lookup_sparse`\n\n    *   Optimized this function for some cases by fusing internal operations.\n\n*   `tf.saved_model.SaveOptions`\n\n    *   Provided a new `experimental_skip_saver` argument which, if specified, will suppress the addition of `SavedModel`-native save and restore ops to the `SavedModel`, for cases where users already build custom save/restore ops and checkpoint formats for the model being saved, and the creation of the SavedModel-native save/restore ops simply cause longer model serialization times.\n\n* Add ops to `tensorflow.raw_ops` that were missing.\n\n* `tf.CheckpointOptions`\n    * It now takes in a new argument called `experimental_write_callbacks`. These are callbacks that will be executed after a saving event finishes writing the checkpoint file.\n\n* Add an option `disable_eager_executer_streaming_enqueue` to `tensorflow.ConfigProto.Experimental` to control the eager runtime's behavior around parallel remote function invocations; when set to `True`, the eager runtime will be allowed to execute multiple function invocations in parallel.\n\n* `tf.constant_initializer`\n    * It now takes a new argument called `support_partition`. If True, constant_initializers can create sharded variables. This is disabled by default, similar to existing behavior.\n\n* `tf.lite`\n    * Added support for `stablehlo.scatter`.\n\n* `tf.estimator`\n    * The tf.estimator API removal is in progress and will be targeted for the 2.16 release.\n\n## Keras\n\n* This will be the final release before the launch of Keras 3.0, when Keras will become multi-backend. For the compatibility page and other info, please see: https://github.com/keras-team/keras-core\n\n## Thanks to our Contributors\n\nThis release contains contributions from many people at Google, as well as:\n\nAiden Grossman, Akash Patel, Akhil Goel, Alexander Pivovarov, Andrew Goodbody, Ayan Moitra, Ben Barsdell, Ben Olson, Bhavani Subramanian, Boian Petkantchin, Bruce Lai, Chao Chen, Christian Steinmeyer, cjflan, David Korczynski, Donghak Park, Dragan Mladjenovic, Eli Kobrin, Fadi Arafeh, Feiyue Chen, Frdric Bastien, guozhong.zhuang, halseycamilla, Harshavardhan Bellamkonda, James Ward, jameshollyer, Jane Liu, johnnkp, jswag180, justkw, Kanvi Khanna, Keith Smiley, Koan-Sin Tan, Kulin Seth, Kun-Lu, kushanam, Lu Teng, mdfaijul, Mehdi Drissi, mgokulkrish, mraunak, Mustafa Uzun, Namrata Bhave, Pavel Emeliyanenko, pemeliya, Peng Sun, Philipp Hack, Pratik Joshi, Rahul Batra, Raunak, redwrasse, Saoirse Stewart, SaoirseARM, seanshpark, Shanbin Ke, Spenser Bauman, Surya, sushreebarsa, Tai Ly, Thibaut Goetghebuer-Planchon, tilakrayal, Tirumalesh, Tj Xu, Vladislav, weihanmines, Wen Chen, wenchenvincent, wenscarl, William Muir, Zhoulong, Jiang\n\n# Release 2.14.0\n\n## Tensorflow\n\n### Breaking Changes\n\n*   Support for Python 3.8 has been removed starting with TF 2.14. The TensorFlow 2.13.1 patch release will still have Python 3.8 support.\n\n*  `tf.Tensor`\n    * The class hierarchy for `tf.Tensor` has changed, and there are now explicit `EagerTensor` and `SymbolicTensor` classes for eager and tf.function respectively. Users who relied on the exact type of Tensor (e.g. `type(t) == tf.Tensor`) will need to update their code to use `isinstance(t, tf.Tensor)`. The `tf.is_symbolic_tensor` helper added in 2.13 may be used when it is necessary to determine if a value is specifically a symbolic tensor.\n\n*   `tf.compat.v1.Session`\n    * `tf.compat.v1.Session.partial_run` and `tf.compat.v1.Session.partial_run_setup` will be deprecated in the next release.\n\n### Known Caveats\n\n* `tf.lite`\n    * when converter flag \"_experimenal_use_buffer_offset\" is enabled, additional metadata is automatically excluded from the generated model. The behaviour is the same as \"exclude_conversion_metadata\" is set\n    * If the model is larger than 2GB, then we also require \"exclude_conversion_metadata\" flag to be set\n\n### Major Features and Improvements\n\n*   The `tensorflow` pip package has a new, optional installation method for Linux that installs necessary Nvidia CUDA libraries through pip. As long as the Nvidia driver is already installed on the system, you may now run `pip install tensorflow[and-cuda]` to install TensorFlow's Nvidia CUDA library dependencies in the Python environment. Aside from the Nvidia driver, no other pre-existing Nvidia CUDA packages are necessary.\n\n*   Enable JIT-compiled i64-indexed kernels on GPU for large tensors with more than 2**32 elements.\n    *   Unary GPU kernels: Abs, Atanh, Acos, Acosh, Asin, Asinh, Atan, Cos, Cosh, Sin, Sinh, Tan, Tanh.\n    *   Binary GPU kernels: AddV2, Sub, Div, DivNoNan, Mul, MulNoNan, FloorDiv, Equal, NotEqual, Greater, GreaterEqual, LessEqual, Less.\n\n* `tf.lite`\n    * Add experimental supports conversion of models that may be larger than 2GB before buffer deduplication\n\n### Bug Fixes and Other Changes\n\n* `tf.py_function` and `tf.numpy_function` can now be used as function decorators for clearer code:\n   ```\n   @tf.py_function(Tout=tf.float32)\n   def my_fun(x):\n     print(\"This always executes eagerly.\")\n     return x+1\n   ```\n\n* `tf.lite`\n    * Strided_Slice now supports `UINT32`.\n\n* `tf.config.experimental.enable_tensor_float_32_execution`\n    * Disabling TensorFloat-32 execution now causes TPUs to use float32 precision for float32 matmuls and other ops. TPUs have always used bfloat16 precision for certain ops, like matmul, when such ops had float32 inputs. Now, disabling TensorFloat-32 by calling `tf.config.experimental.enable_tensor_float_32_execution(False)` will cause TPUs to use float32 precision for such ops instead of bfloat16.\n\n*  `tf.experimental.dtensor`\n    * API changes for Relayout. Added a new API, `dtensor.relayout_like`, for relayouting a tensor according to the layout of another tensor.\n    * Added `dtensor.get_default_mesh`, for retrieving the current default mesh under the dtensor context.\n    * \\*fft\\* ops now support dtensors with any layout. Fixed bug in 'fft2d/fft3d', 'ifft2d/ifft3d', 'rfft2d/rfft3d', and 'irfft2d/irfft3d' for sharde input. Refer to this [blog post](https://blog.tensorflow.org/2023/08/distributed-fast-fourier-transform-in-tensorflow.html) for details.\n\n*  `tf.experimental.strict_mode`\n    * Added a new API, `strict_mode`, which converts all deprecation warnings into runtime errors with instructions on switching to a recommended  substitute.\n\n*   TensorFlow Debugger (tfdbg) CLI: ncurses-based CLI for tfdbg v1 was removed.\n\n*   TensorFlow now supports C++ RTTI on mobile and Android. To enable this feature, pass the flag `--define=tf_force_rtti=true` to Bazel when building TensorFlow. This may be needed when linking TensorFlow into RTTI-enabled programs since mixing RTTI and non-RTTI code can cause ABI issues.\n\n* `tf.ones`, `tf.zeros`, `tf.fill`, `tf.ones_like`, `tf.zeros_like` now take an additional Layout argument that controls the output layout of their results.\n\n* `tf.nest` and `tf.data` now support user defined classes implementing `__tf_flatten__` and `__tf_unflatten__` methods. See [nest_util code examples](https://github.com/tensorflow/tensorflow/blob/04869b4e63bfc03cb13627b3e1b879fdd0f69e34/tensorflow/python/util/nest_util.py#L97)\nfor an example.\n\n*  TensorFlow IO support is now available for Apple Silicon packages.\n\n*  Refactor CpuExecutable to propagate LLVM errors.\n\n## Keras\n\nKeras is a framework built on top of the TensorFlow. See more details on the Keras [website](https://keras.io/).\n\n### Major Features and Improvements\n\n* `tf.keras`\n    * `Model.compile` now support `steps_per_execution='auto'` as a parameter, allowing automatic tuning of steps per execution during `Model.fit`,\n    `Model.predict`, and `Model.evaluate` for a significant performance boost.\n\n## Thanks to our Contributors\n\nThis release contains contributions from many people at Google, as well as:\n\nAakar Dwivedi, Adrian Popescu, ag.ramesh, Akhil Goel, Albert Zeyer, Alex Rosen, Alexey Vishnyakov, Andrew Goodbody, angerson, Ashiq Imran, Ayan Moitra, Ben Barsdell, Bhavani Subramanian, Boian Petkantchin, BrianWieder, Chris Mc, cloudhan, Connor Flanagan, Daniel Lang, Daniel Yudelevich, Darya Parygina, David Korczynski, David Svantesson, dingyuqing05, Dragan Mladjenovic, dskkato, Eli Kobrin, Erick Ochoa, Erik Schultheis, Frdric Bastien, gaikwadrahul8, Gauri1 Deshpande, guozhong.zhuang, H. Vetinari, Isaac Cilia Attard, Jake Hall, Jason Furmanek, Jerry Ge, Jinzhe Zeng, JJ, johnnkp, Jonathan Albrecht, jongkweh, justkw, Kanvi Khanna, kikoxia, Koan-Sin Tan, Kun-Lu, ltsai1, Lu Teng, luliyucoordinate, Mahmoud Abuzaina, mdfaijul, Milos Puzovic, Nathan Luehr, Om Thakkar, pateldeev, Peng Sun, Philipp Hack, pjpratik, Poliorcetics, rahulbatra85, rangjiaheng, Renato Arantes, Robert Kalmar, roho, Rylan Justice, Sachin Muradi, samypr100, Saoirse Stewart, Shanbin Ke, Shivam Mishra, shuw, Song Ziming, Stephan Hartmann, Sulav, sushreebarsa, T Coxon, Tai Ly, talyz, Thibaut Goetghebuer-Planchon, Thomas Preud'Homme, tilakrayal, Tirumalesh, Tj Xu, Tom Allsop, Trevor Morris, Varghese, Jojimon, Wen Chen, Yaohui Liu, Yimei Sun, Zhoulong Jiang, Zhoulong, Jiang\n\n# Release 2.13.0\n\n## TensorFlow\n\n### Breaking Changes\n\n* The LMDB kernels have been changed to return an error. This is in preparation for completely removing them from TensorFlow. The LMDB dependency that these kernels are bringing to TensorFlow has been dropped, thus making the build slightly faster and more secure.\n\n### Major Features and Improvements\n\n*   `tf.lite`\n\n    *   Added 16-bit and 64-bit float type support for built-in op `cast`.\n    *   The Python TF Lite Interpreter bindings now have an option `experimental_disable_delegate_clustering` to turn-off delegate clustering.\n    *   Added int16x8 support for the built-in op `exp`\n    *   Added int16x8 support for the built-in op `mirror_pad`\n    *   Added int16x8 support for the built-in ops `space_to_batch_nd` and `batch_to_space_nd`\n    *   Added 16-bit int type support for built-in op `less`, `greater_than`, `equal`\n    *   Added 8-bit and 16-bit support for `floor_div` and `floor_mod`.\n    *   Added 16-bit and 32-bit int support for the built-in op `bitcast`.\n    *   Added 8-bit/16-bit/32-bit int/uint support for the built-in op `bitwise_xor`\n    *   Added int16 indices support for built-in op `gather` and `gather_nd`.\n    *   Added 8-bit/16-bit/32-bit int/uint support for the built-in op `right_shift`\n    *   Added reference implementation for 16-bit int unquantized `add`.\n    *   Added reference implementation for 16-bit int and 32-bit unsigned int unquantized `mul`.\n    *   `add_op` supports broadcasting up to 6 dimensions.\n    *   Added 16-bit support for `top_k`.\n\n*   `tf.function`\n\n    *   ConcreteFunction (`tf.types.experimental.ConcreteFunction`) as generated through `get_concrete_function` now performs holistic input validation similar to calling `tf.function` directly. This can cause breakages where existing calls pass Tensors with the wrong shape or omit certain non-Tensor arguments (including default values).\n\n*   `tf.nn`\n\n    *   `tf.nn.embedding_lookup_sparse` and `tf.nn.safe_embedding_lookup_sparse` now support ids and weights described by `tf.RaggedTensor`s.\n    *   Added a new boolean argument `allow_fast_lookup` to `tf.nn.embedding_lookup_sparse` and `tf.nn.safe_embedding_lookup_sparse`, which enables a simplified and typically faster lookup procedure.\n\n*   `tf.data`\n\n    *   `tf.data.Dataset.zip` now supports Python-style zipping, i.e. `Dataset.zip(a, b, c)`.\n    * `tf.data.Dataset.shuffle` now supports `tf.data.UNKNOWN_CARDINALITY` When doing a \"full shuffle\" using  `dataset = dataset.shuffle(dataset.cardinality())`. But remember, a \"full shuffle\" will load the full dataset into memory so that it can be shuffled, so make sure to only use this with small datasets or datasets of small objects (like filenames).\n\n*   `tf.math`\n\n    * `tf.nn.top_k` now supports specifying the output index type via parameter `index_type`.  Supported types are `tf.int16`, `tf.int32` (default), and `tf.int64`.\n\n*   `tf.SavedModel`\n\n    *   Introduced class method `tf.saved_model.experimental.Fingerprint.from_proto(proto)`, which can be used to construct a `Fingerprint` object directly from a protobuf.\n    *   Introduced member method `tf.saved_model.experimental.Fingerprint.singleprint()`, which provides a convenient way to uniquely identify a SavedModel.\n\n### Bug Fixes and Other Changes\n\n*   `tf.Variable`\n\n    *   Changed resource variables to inherit from `tf.compat.v2.Variable` instead of `tf.compat.v1.Variable`. Some checks for `isinstance(v, tf compat.v1.Variable)` that previously returned True may now return False.\n\n*   `tf.distribute`\n\n    *   Opened an experimental API, `tf.distribute.experimental.coordinator.get_current_worker_index`, for retrieving the worker index from within a worker, when using parameter server training with a custom training loop.\n\n*   `tf.experimental.dtensor`\n\n    *   Deprecated `dtensor.run_on` in favor of `dtensor.default_mesh` to correctly indicate that the context does not override the mesh that the ops and functions will run on, it only sets a fallback default mesh.\n    *   List of members of `dtensor.Layout` and `dtensor.Mesh` have slightly changed as part of efforts to consolidate the C++ and Python source code with pybind11. Most notably, `dtensor.Layout.serialized_string` is removed.\n    *   Minor API changes to represent Single Device Layout for non-distributed Tensors inside DTensor functions. Runtime support will be added soon.\n\n*   `tf.experimental.ExtensionType`\n\n    *   `tf.experimental.ExtensionType` now supports Python `tuple` as the type annotation of its fields.\n\n*   `tf.nest`\n\n    *   Deprecated API `tf.nest.is_sequence` has now been deleted. Please use `tf.nest.is_nested` instead.\n\n## Keras\n\nKeras is a framework built on top of the TensorFlow. See more details on the [Keras website](https://keras.io/).\n\n### Breaking Changes\n\n*  Removed the Keras scikit-learn API wrappers (`KerasClassifier` and `KerasRegressor`), which had been deprecated in August 2021. We recommend using [SciKeras](https://github.com/adriangb/scikeras) instead.\n*  The default Keras model saving format is now the Keras v3 format: calling `model.save(\"xyz.keras\")` will no longer create a H5 file, it will create a native Keras model file. This will only be breaking for you if you were manually inspecting or modifying H5 files saved by Keras under a `.keras` extension. If this breaks you, simply add `save_format=\"h5\"` to your `.save()` call to revert back to the prior behavior.\n*  Added `keras.utils.TimedThread` utility to run a timed thread every x seconds. It can be used to run a threaded function alongside model training or any other snippet of code.\n*  In the `keras` PyPI package, accessible symbols are now restricted to symbols that are intended to be public. This may affect your code if you were using `import keras` and you used `keras` functions that were not public APIs, but were accessible in earlier versions with direct imports. In those cases, please use the following guideline:\n        -  The API may be available in the public Keras API under a different name, so make sure to look for it on keras.io or TensorFlow docs and switch to the public version.\n        -  It could also be a simple python or TF utility that you could easily copy over to your own codebase. In those case, just make it your own!\n        -  If you believe it should definitely be a public Keras API, please open a feature request in keras GitHub repo.\n        -  As a workaround, you could import the same private symbol keras `keras.src`, but keep in mind the `src` namespace is not stable and those APIs may change or be removed in the future.\n\n### Major Features and Improvements\n\n*   Added F-Score metrics `tf.keras.metrics.FBetaScore`, `tf.keras.metrics.F1Score`, and `tf.keras.metrics.R2Score`.\n*   Added activation function `tf.keras.activations.mish`.\n*   Added experimental `keras.metrics.experimental.PyMetric` API for metrics that run Python code on the host CPU (compiled outside of the TensorFlow graph). This can be used for integrating metrics from external Python libraries (like sklearn or pycocotools) into Keras as first-class Keras metrics.\n*   Added `tf.keras.optimizers.Lion` optimizer.\n*   Added `tf.keras.layers.SpectralNormalization` layer wrapper to perform spectral normalization on the weights of a target layer.\n*   The `SidecarEvaluatorModelExport` callback has been added to Keras as `keras.callbacks.SidecarEvaluatorModelExport`. This callback allows for exporting the model the best-scoring model as evaluated by a `SidecarEvaluator` evaluator. The evaluator regularly evaluates the model and exports it if the user-defined comparison function determines that it is an improvement.\n*   Added warmup capabilities to `tf.keras.optimizers.schedules.CosineDecay` learning rate scheduler. You can now specify an initial and target learning rate, and our scheduler will perform a linear interpolation between the two after which it will begin a decay phase.\n*   Added experimental support for an exactly-once visitation guarantee for evaluating Keras models trained with `tf.distribute ParameterServerStrategy`, via the `exact_evaluation_shards` argument in `Model.fit` and `Model.evaluate`.\n*   Added `tf.keras.__internal__.KerasTensor`,`tf.keras.__internal__.SparseKerasTensor`, and `tf.keras.__internal__.RaggedKerasTensor` classes. You can use these classes to do instance type checking and type annotations for layer/model inputs and outputs.\n*   All the `tf.keras.dtensor.experimental.optimizers` classes have been merged with `tf.keras.optimizers`. You can migrate your code to use `tf.keras.optimizers` directly. The API namespace for `tf.keras.dtensor.experimental.optimizers` will be removed in future releases.\n*   Added support for `class_weight` for 3+ dimensional targets (e.g. image segmentation masks) in `Model.fit`.\n*   Added a new loss, `keras.losses.CategoricalFocalCrossentropy`.\n*   Remove the `tf.keras.dtensor.experimental.layout_map_scope()`. You can user the `tf.keras.dtensor.experimental.LayoutMap.scope()` instead.\n\n## Security\n\n*   Fixes correct values rank in UpperBound and LowerBound [CVE-2023-33976](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2023-33976)\n\n## Thanks to our Contributors\n\nThis release contains contributions from many people at Google, as well as:\n\n103yiran, 8bitmp3, Aakar, Aakar Dwivedi, Abinash Satapathy, Aditya Kane, ag.ramesh, Alexander Grund, Andrei Pikas, andreii, Andrew Goodbody, angerson, Anthony_256, Ashay Rane, Ashiq Imran, Awsaf, Balint Cristian, Banikumar Maiti (Intel Aipg), Ben Barsdell, bhack, cfRod, Chao Chen, chenchongsong, Chris Mc, Daniil Kutz, David Rubinstein, dianjiaogit, dixr, Dongfeng Yu, dongfengy, drah, Eric Kunze, Feiyue Chen, Frederic Bastien, Gauri1 Deshpande, guozhong.zhuang, hDn248, HYChou, ingkarat, James Hilliard, Jason Furmanek, Jaya, Jens Glaser, Jerry Ge, Jiao Dian'S Power Plant, Jie Fu, Jinzhe Zeng, Jukyy, Kaixi Hou, Kanvi Khanna, Karel Ha, karllessard, Koan-Sin Tan, Konstantin Beluchenko, Kulin Seth, Kun Lu, Kyle Gerard Felker, Leopold Cambier, Lianmin Zheng, linlifan, liuyuanqiang, Lukas Geiger, Luke Hutton, Mahmoud Abuzaina, Manas Mohanty, Mateo Fidabel, Maxiwell S. Garcia, Mayank Raunak, mdfaijul, meatybobby, Meenakshi Venkataraman, Michael Holman, Nathan John Sircombe, Nathan Luehr, nitins17, Om Thakkar, Patrice Vignola, Pavani Majety, per1234, Philipp Hack, pollfly, Prianka Liz Kariat, Rahul Batra, rahulbatra85, ratnam.parikh, Rickard Hallerbck, Roger Iyengar, Rohit Santhanam, Roman Baranchuk, Sachin Muradi, sanadani, Saoirse Stewart, seanshpark, Shawn Wang, shuw, Srinivasan Narayanamoorthy, Stewart Miles, Sunita Nadampalli, SuryanarayanaY, Takahashi Shuuji, Tatwai Chong, Thibaut Goetghebuer-Planchon, tilakrayal, Tirumalesh, TJ, Tony Sung, Trevor Morris, unda, Vertexwahn, venkat2469, William Muir, Xavier Bonaventura, xiang.zhang, Xiao-Yong Jin, yleeeee, Yong Tang, Yuriy Chernyshov, Zhang, Xiangze, zhaozheng09\n\n# Release 2.12.1\n\n### Bug Fixes and Other Changes\n\n*  The use of the ambe config to build and test aarch64 is not needed. The ambe config will be removed in the future. Making cpu_arm64_pip.sh and cpu_arm64_nonpip.sh more similar for easier future maintenance.\n\n# Release 2.12.0\n\n### Breaking Changes\n\n*   Build, Compilation and Packaging\n\n    *   Removed redundant packages `tensorflow-gpu` and `tf-nightly-gpu`. These packages were removed and replaced with packages that direct users to switch to `tensorflow` or `tf-nightly` respectively. Since TensorFlow 2.1, the only difference between these two sets of packages was their names, so there is no loss of functionality or GPU support. See https://pypi.org/project/tensorflow-gpu for more details.\n\n*   `tf.function`:\n\n    *   `tf.function` now uses the Python inspect library directly for parsing the signature of the Python function it is decorated on. This change may break code where the function signature is malformed, but was ignored previously, such as:\n        *   Using `functools.wraps` on a function with different signature\n        *   Using `functools.partial` with an invalid `tf.function` input\n    *   `tf.function` now enforces input parameter names to be valid Python identifiers. Incompatible names are automatically sanitized similarly to existing SavedModel signature behavior.\n    *   Parameterless `tf.function`s are assumed to have an empty `input_signature` instead of an undefined one even if the `input_signature` is unspecified.\n    *   `tf.types.experimental.TraceType` now requires an additional `placeholder_value` method to be defined.\n    *   `tf.function` now traces with placeholder values generated by TraceType instead of the value itself.\n\n*   Experimental APIs `tf.config.experimental.enable_mlir_graph_optimization` and `tf.config.experimental.disable_mlir_graph_optimization` were removed.\n\n### Major Features and Improvements\n\n*  Support for Python 3.11 has been added.\n*  Support for Python 3.7 has been removed. We are not releasing any more patches for Python 3.7.\n\n*   `tf.lite`:\n\n    *   Add 16-bit float type support for built-in op `fill`.\n    *   Transpose now supports 6D tensors.\n    *   Float LSTM now supports diagonal recurrent tensors: https://arxiv.org/abs/1903.08023\n\n*   `tf.experimental.dtensor`:\n\n    *   Coordination service now works with `dtensor.initialize_accelerator_system`, and enabled by default.\n    *   Add `tf.experimental.dtensor.is_dtensor` to check if a tensor is a DTensor instance.\n\n*   `tf.data`:\n\n    *   Added support for alternative checkpointing protocol which makes it possible to checkpoint the state of the input pipeline without having to store the contents of internal buffers. The new functionality can be enabled through the `experimental_symbolic_checkpoint` option of `tf.data.Options()`.\n    *   Added a new `rerandomize_each_iteration` argument for the `tf.data.Dataset.random()` operation, which controls whether the sequence of generated random numbers should be re-randomized every epoch or not (the default behavior). If `seed` is set and `rerandomize_each_iteration=True`, the `random()` operation will produce a different (deterministic) sequence of numbers every epoch.\n    *   Added a new `rerandomize_each_iteration` argument for the `tf.data.Dataset.sample_from_datasets()` operation, which controls whether the sequence of generated random numbers used for sampling should be re-randomized every epoch or not. If `seed` is set and `rerandomize_each_iteration=True`, the `sample_from_datasets()` operation will use a different (deterministic) sequence of numbers every epoch.\n\n*   `tf.test`:\n\n    *   Added `tf.test.experimental.sync_devices`, which is useful for accurately measuring performance in benchmarks.\n\n*   `tf.experimental.dtensor`:\n\n    *   Added experimental support to ReduceScatter fuse on GPU (NCCL).\n\n### Bug Fixes and Other Changes\n\n*   `tf.SavedModel`:\n    * Introduced new class `tf.saved_model.experimental.Fingerprint` that contains the fingerprint of the SavedModel. See the [SavedModel Fingerprinting RFC](https://github.com/tensorflow/community/pull/415) for details.\n    * Introduced API `tf.saved_model.experimental.read_fingerprint(export_dir)` for reading the fingerprint of a SavedModel.\n* `tf.random`\n  * Added non-experimental aliases for `tf.random.split` and `tf.random.fold_in`, the experimental endpoints are still available so no code changes are necessary.\n* `tf.experimental.ExtensionType`\n  * Added function `experimental.extension_type.as_dict()`, which converts an instance of `tf.experimental.ExtensionType` to a `dict` representation.\n* `stream_executor`\n  * Top level `stream_executor` directory has been deleted, users should use equivalent headers and targets under `compiler/xla/stream_executor`.\n* `tf.nn`\n  * Added `tf.nn.experimental.general_dropout`, which is similar to `tf.random.experimental.stateless_dropout` but accepts a custom sampler function.\n* `tf.types.experimental.GenericFunction`\n  * The `experimental_get_compiler_ir` method supports tf.TensorSpec compilation arguments.\n*  `tf.config.experimental.mlir_bridge_rollout`\n    *   Removed enums `MLIR_BRIDGE_ROLLOUT_SAFE_MODE_ENABLED` and `MLIR_BRIDGE_ROLLOUT_SAFE_MODE_FALLBACK_ENABLED` which are no longer used by the tf2xla bridge\n\n## Keras\n\n Keras is a framework built on top of the TensorFlow. See more details on the Keras [website](https://keras.io/).\n\n### Breaking Changes\n\n\n`tf.keras`:\n\n* Moved all saving-related utilities to a new namespace, `keras.saving`, for example: `keras.saving.load_model`, `keras.saving.save_model`, `keras.saving.custom_object_scope`, `keras.saving.get_custom_objects`, `keras.saving.register_keras_serializable`,`keras.saving.get_registered_name` and `keras.saving.get_registered_object`. The previous API locations (in `keras.utils` and `keras.models`) will be available indefinitely, but we recommend you update your code to point to the new API locations.\n * Improvements and fixes in Keras loss masking:\n    * Whether you represent a ragged tensor as a `tf.RaggedTensor` or using [keras masking](https://www.tensorflow.org/guide/keras/masking_and_padding), the returned loss values should be the identical to each other. In previous versions Keras may have silently ignored the mask.\n * If you use masked losses with Keras the loss values may be different in TensorFlow `2.12` compared to previous versions.\n * In cases where the mask was previously ignored, you will now get an error if you pass a mask with an incompatible shape.\n\n### Major Features and Improvements\n\n`tf.keras`:\n\n *   The new Keras model saving format (`.keras`) is available. You can start using it via `model.save(f\"{fname}.keras\", save_format=\"keras_v3\")`. In the future it will become the default for all files with the `.keras` extension. This file format targets the Python runtime only and makes it possible to reload Python objects identical to the saved originals. The format supports non-numerical state such as vocabulary files and lookup tables, and it is easy to customize in the case of custom layers with exotic elements of state (e.g. a FIFOQueue). The format does not rely on bytecode or pickling, and is safe by default. Note that as a result, Python `lambdas` are disallowed at loading time. If you want to use `lambdas`, you can pass `safe_mode=False` to the loading method (only do this if you trust the source of the model).\n*   Added a `model.export(filepath)` API to create a lightweight SavedModel artifact that can be used for inference (e.g. with TF-Serving).\n*   Added `keras.export.ExportArchive` class for low-level customization of the process of exporting SavedModel artifacts for inference. Both ways of exporting models are based on `tf.function` tracing and produce a TF program composed of TF ops. They are meant primarily for environments where the TF runtime is available, but not the Python interpreter, as is typical for production with TF Serving.\n *   Added utility `tf.keras.utils.FeatureSpace`, a one-stop shop for structured data preprocessing and encoding.\n *   Added `tf.SparseTensor` input support to `tf.keras.layers.Embedding` layer. The layer now accepts a new boolean argument `sparse`. If `sparse` is set to True, the layer returns a SparseTensor instead of a dense Tensor. Defaults to False.\n *   Added `jit_compile` as a settable property to `tf.keras.Model`.\n *   Added `synchronized` optional parameter to `layers.BatchNormalization`.\n *   Added deprecation warning to `layers.experimental.SyncBatchNormalization` and suggested to use `layers.BatchNormalization` with `synchronized=True` instead.\n *   Updated `tf.keras.layers.BatchNormalization` to support masking of the inputs (`mask` argument) when computing the mean and variance.\n *   Add `tf.keras.layers.Identity`, a placeholder pass-through layer.\n *   Add `show_trainable` option to `tf.keras.utils.model_to_dot` to display layer trainable status in model plots.\n *   Add ability to save a `tf.keras.utils.FeatureSpace` object, via `feature_space.save(\"myfeaturespace.keras\")`, and reload it via `feature_space = tf.keras.models.load_model(\"myfeaturespace.keras\")`.\n*   Added utility `tf.keras.utils.to_ordinal` to convert class vector to ordinal regression / classification matrix.\n\n### Bug Fixes and Other Changes\n\n*   N/A\n\n## Security\n\n*   Moving forward, TensorFlow will no longer update [TFSAs](https://github.com/tensorflow/tensorflow/tree/master/tensorflow/security). Please refer instead to our [GitHub security advisories](https://github.com/tensorflow/tensorflow/security/advisories), which are attached to [CVEs](https://cve.mitre.org/cve/).\n*   Fixes an FPE in TFLite in conv kernel [CVE-2023-27579](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2023-27579)\n*   Fixes a double free in Fractional(Max/Avg)Pool [CVE-2023-25801](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2023-25801)\n*   Fixes a null dereference on ParallelConcat with XLA [CVE-2023-25676](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2023-25676)\n*   Fixes a segfault in Bincount with XLA [CVE-2023-25675](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2023-25675)\n*   Fixes an NPE in RandomShuffle with XLA enable [CVE-2023-25674](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2023-25674)\n*   Fixes an FPE in TensorListSplit with XLA [CVE-2023-25673](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2023-25673)\n*   Fixes segmentation fault in tfg-translate [CVE-2023-25671](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2023-25671)\n*   Fixes an NPE in QuantizedMatMulWithBiasAndDequantize [CVE-2023-25670](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2023-25670)\n*   Fixes an FPE in AvgPoolGrad with XLA [CVE-2023-25669](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2023-25669)\n*   Fixes a heap out-of-buffer read vulnerability in the QuantizeAndDequantize operation [CVE-2023-25668](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2023-25668)\n*   Fixes a segfault when opening multiframe gif [CVE-2023-25667](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2023-25667)\n*   Fixes an NPE in SparseSparseMaximum [CVE-2023-25665](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2023-25665)\n*   Fixes an FPE in AudioSpectrogram [CVE-2023-25666](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2023-25666)\n*   Fixes a heap-buffer-overflow in AvgPoolGrad  [CVE-2023-25664](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2023-25664)\n*   Fixes a NPE in TensorArrayConcatV2  [CVE-2023-25663](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2023-25663)\n*   Fixes a Integer overflow in EditDistance  [CVE-2023-25662](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2023-25662)\n*   Fixes a Seg fault in `tf.raw_ops.Print` [CVE-2023-25660](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2023-25660)\n*   Fixes a OOB read in DynamicStitch [CVE-2023-25659](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2023-25659)\n*   Fixes a OOB Read in GRUBlockCellGrad [CVE-2023-25658](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2023-25658)\n\n## Thanks to our Contributors\n\nThis release contains contributions from many people at Google, as well as:\n\n103yiran, 8bitmp3, Aakar, Aakar Dwivedi, Abinash Satapathy, Aditya Kane, ag.ramesh, Alexander Grund, Andrei Pikas, andreii, Andrew Goodbody, angerson, Anthony_256, Ashay Rane, Ashiq Imran, Awsaf, Balint Cristian, Banikumar Maiti (Intel Aipg), Ben Barsdell, bhack, cfRod, Chao Chen, chenchongsong, Chris Mc, Daniil Kutz, David Rubinstein, dianjiaogit, dixr, Dongfeng Yu, dongfengy, drah, Eric Kunze, Feiyue Chen, Frederic Bastien, Gauri1 Deshpande, guozhong.zhuang, hDn248, HYChou, ingkarat, James Hilliard, Jason Furmanek, Jaya, Jens Glaser, Jerry Ge, Jiao Dian'S Power Plant, Jie Fu, Jinzhe Zeng, Jukyy, Kaixi Hou, Kanvi Khanna, Karel Ha, karllessard, Koan-Sin Tan, Konstantin Beluchenko, Kulin Seth, Kun Lu, Kyle Gerard Felker, Leopold Cambier, Lianmin Zheng, linlifan, liuyuanqiang, Lukas Geiger, Luke Hutton, Mahmoud Abuzaina, Manas Mohanty, Mateo Fidabel, Maxiwell S. Garcia, Mayank Raunak, mdfaijul, meatybobby, Meenakshi Venkataraman, Michael Holman, Nathan John Sircombe, Nathan Luehr, nitins17, Om Thakkar, Patrice Vignola, Pavani Majety, per1234, Philipp Hack, pollfly, Prianka Liz Kariat, Rahul Batra, rahulbatra85, ratnam.parikh, Rickard Hallerbck, Roger Iyengar, Rohit Santhanam, Roman Baranchuk, Sachin Muradi, sanadani, Saoirse Stewart, seanshpark, Shawn Wang, shuw, Srinivasan Narayanamoorthy, Stewart Miles, Sunita Nadampalli, SuryanarayanaY, Takahashi Shuuji, Tatwai Chong, Thibaut Goetghebuer-Planchon, tilakrayal, Tirumalesh, TJ, Tony Sung, Trevor Morris, unda, Vertexwahn, Vinila S, William Muir, Xavier Bonaventura, xiang.zhang, Xiao-Yong Jin, yleeeee, Yong Tang, Yuriy Chernyshov, Zhang, Xiangze, zhaozheng09\n\n\n# Release 2.11.1\n\n**Note**: TensorFlow 2.10 was the last TensorFlow release that supported GPU on native-Windows. Starting with TensorFlow 2.11, you will need to install TensorFlow in WSL2, or install tensorflow-cpu and, optionally, try the TensorFlow-DirectML-Plugin.\n*   Security vulnerability fixes will no longer be patched to this Tensorflow version. The latest Tensorflow version includes the security vulnerability fixes. You can update to the latest version (recommended) or patch security vulnerabilities yourself [steps](https://github.com/tensorflow/tensorflow#patching-guidelines). You can refer to the [release notes](https://github.com/tensorflow/tensorflow/releases) of the latest Tensorflow version for a list of newly fixed vulnerabilities. If you have any questions, please create a GitHub issue to let us know.\n\nThis release also introduces several vulnerability fixes:\n\n*   Fixes an FPE in TFLite in conv kernel [CVE-2023-27579](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2023-27579)\n*   Fixes a double free in Fractional(Max/Avg)Pool [CVE-2023-25801](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2023-25801)\n*   Fixes a null dereference on ParallelConcat with XLA [CVE-2023-25676](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2023-25676)\n*   Fixes a segfault in Bincount with XLA [CVE-2023-25675](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2023-25675)\n*   Fixes an NPE in RandomShuffle with XLA enable [CVE-2023-25674](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2023-25674)\n*   Fixes an FPE in TensorListSplit with XLA [CVE-2023-25673](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2023-25673)\n*   Fixes segmentation fault in tfg-translate [CVE-2023-25671](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2023-25671)\n*   Fixes an NPE in QuantizedMatMulWithBiasAndDequantize [CVE-2023-25670](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2023-25670)\n*   Fixes an FPE in AvgPoolGrad with XLA [CVE-2023-25669](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2023-25669)\n*   Fixes a heap out-of-buffer read vulnerability in the QuantizeAndDequantize operation [CVE-2023-25668](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2023-25668)\n*   Fixes a segfault when opening multiframe gif [CVE-2023-25667](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2023-25667)\n*   Fixes an NPE in SparseSparseMaximum [CVE-2023-25665](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2023-25665)\n*   Fixes an FPE in AudioSpectrogram [CVE-2023-25666](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2023-25666)\n*   Fixes a heap-buffer-overflow in AvgPoolGrad  [CVE-2023-25664](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2023-25664)\n*   Fixes a NPE in TensorArrayConcatV2  [CVE-2023-25663](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2023-25663)\n*   Fixes a Integer overflow in EditDistance  [CVE-2023-25662](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2023-25662)\n*   Fixes a Seg fault in `tf.raw_ops.Print` [CVE-2023-25660](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2023-25660)\n*   Fixes a OOB read in DynamicStitch [CVE-2023-25659](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2023-25659)\n*   Fixes a OOB Read in GRUBlockCellGrad [CVE-2023-25658](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2023-25658)\n\n\n# Release 2.11.0\n\n## Breaking Changes\n*   `tf.keras.optimizers.Optimizer` now points to the new Keras optimizer, and\n    old optimizers have moved to the `tf.keras.optimizers.legacy` namespace.\n    If you find your workflow failing due to this change,\n    you may be facing one of the following issues:\n\n    *   **Checkpoint loading failure.** The new optimizer handles optimizer\n        state differently from the old optimizer, which simplies the logic of\n        checkpoint saving/loading, but at the cost of breaking checkpoint\n        backward compatibility in some cases. If you want to keep using an old\n        checkpoint, please change your optimizer to\n        `tf.keras.optimizers.legacy.XXX` (e.g.\n        `tf.keras.optimizers.legacy.Adam`).\n    *   **TF1 compatibility.** The new optimizer does not support TF1 any more,\n        so please use the legacy optimizer `tf.keras.optimizer.legacy.XXX`.\n        We highly recommend to migrate your workflow to TF2 for stable\n        support and new features.\n    *   **API not found.** The new optimizer has a different set of public APIs\n        from the old optimizer. These API changes are mostly related to\n        getting rid of slot variables and TF1 support. Please check the API\n        documentation to find alternatives to the missing API. If you must\n        call the deprecated API, please change your optimizer to the legacy\n        optimizer.\n    *   **Learning rate schedule access.** When using a `LearningRateSchedule`,\n        The new optimizer's `learning_rate` property returns the\n        current learning rate value instead of a `LearningRateSchedule` object\n        as before. If you need to access the `LearningRateSchedule` object,\n        please use `optimizer._learning_rate`.\n    *   **You implemented a custom optimizer based on the old optimizer.**\n        Please set your optimizer to subclass\n        `tf.keras.optimizer.legacy.XXX`. If you want to migrate to the new\n        optimizer and find it does not support your optimizer, please file\n        an issue in the Keras GitHub repo.\n    *   **Error such as `Cannot recognize variable...`.** The new optimizer\n        requires all optimizer variables to be created at the first\n        `apply_gradients()` or `minimize()` call. If your workflow calls\n        optimizer to update different parts of model in multiple stages,\n        please call `optimizer.build(model.trainable_variables)` before the\n        training loop.\n    *   **Performance regression on `ParameterServerStrategy`.** This could be\n        significant if you have many PS servers. We are aware of this issue and\n        working on fixes, for now we suggest using the legacy optimizers when\n        using `ParameterServerStrategy`.\n    *   **Timeout or performance loss.** We don't anticipate this to happen, but\n        if you see such issues, please use the legacy optimizer, and file\n        an issue in the Keras GitHub repo.\n\n    The old Keras optimizer will never be deleted, but will not see any\n    new feature additions.\n    New optimizers (e.g., `Adafactor`) will\n    only be implemented based on `tf.keras.optimizers.Optimizer`, the new\n    base class.\n\n## Major Features and Improvements\n\n*   `tf.lite`:\n\n    *   New operations supported:\n          * tf.unsortedsegmentmin op is supported.\n          * tf.atan2 op is supported.\n          * tf.sign op is supported.\n    *   Updates to existing operations:\n          * tfl.mul now supports complex32 inputs.\n\n*   `tf.experimental.StructuredTensor`\n\n    *   Introduced `tf.experimental.StructuredTensor`, which provides a flexible\n        and Tensorflow-native way to encode structured data such as protocol\n        buffers or pandas dataframes.\n\n*   `tf.keras`:\n\n    *   Added method `get_metrics_result()` to `tf.keras.models.Model`.\n        *   Returns the current metrics values of the model as a dict.\n    *   Added group normalization layer `tf.keras.layers.GroupNormalization`.\n    *   Added weight decay support for all Keras optimizers.\n    *   Added Adafactor optimizer `tf.keras.optimizers.Adafactor`.\n    *   Added `warmstart_embedding_matrix` to `tf.keras.utils`.\n        This utility can be used to warmstart an embeddings matrix so you\n        reuse previously-learned word embeddings when working with a new set\n        of words which may include previously unseen words (the embedding\n        vectors for unseen words will be randomly initialized).\n\n*   `tf.Variable`:\n\n    *   Added `CompositeTensor` as a baseclass to `ResourceVariable`. This\n        allows `tf.Variable`s to be nested in `tf.experimental.ExtensionType`s.\n    *   Added a new constructor argument `experimental_enable_variable_lifting`\n        to `tf.Variable`, defaulting to True. When it's `False`, the variable\n        won't be lifted out of `tf.function`, thus it can be used as a\n        `tf.function`-local variable: during each execution of the\n        `tf.function`, the variable will be created and then disposed, similar\n        to a local (i.e. stack-allocated) variable in C/C++. Currently\n        `experimental_enable_variable_lifting=False` only works on non-XLA\n        devices (e.g. under `@tf.function(jit_compile=False)`).\n\n*   TF SavedModel:\n    *   Added `fingerprint.pb` to the SavedModel directory. The `fingerprint.pb`\n        file is a protobuf containing the \"fingerprint\" of the SavedModel. See\n        the [RFC](https://github.com/tensorflow/community/pull/415) for more\n        details regarding its design and properties.\n\n*   `tf.data`:\n    *   Graduated experimental APIs:\n        * [`tf.data.Dataset.ragged_batch`](https://www.tensorflow.org/api_docs/python/tf/data/Dataset/#ragged_batch), which batches elements of `tf.data.Dataset`s into `tf.RaggedTensor`s.\n        * [`tf.data.Dataset.sparse_batch`](https://www.tensorflow.org/api_docs/python/tf/data/Dataset/#sparse_batch), which batches elements of `tf.data.Dataset`s into `tf.sparse.SparseTensor`s.\n\n## Bug Fixes and Other Changes\n\n*   `tf.image`\n    *   Added an optional parameter `return_index_map` to `tf.image.ssim` which\n        causes the returned value to be the local SSIM map instead of the global\n        mean.\n\n*   TF Core:\n\n    *   `tf.custom_gradient` can now be applied to functions that accept\n        \"composite\" tensors, such as `tf.RaggedTensor`, as inputs.\n    *   Fix device placement issues related to datasets with ragged tensors of\n        strings (i.e. variant encoded data with types not supported on GPU).\n    *   'experimental_follow_type_hints' for tf.function has been deprecated.\n        Please use input_signature or reduce_retracing to minimize retracing.\n\n*   `tf.SparseTensor`:\n    *   Introduced `set_shape`, which sets the static dense shape of the sparse tensor and has the same semantics as `tf.Tensor.set_shape`.\n\n## Security\n\n* TF is currently using giflib 5.2.1 which has [CVE-2022-28506](https://nvd.nist.gov/vuln/detail/CVE-2022-28506). TF is not affected by the CVE as it does not use `DumpScreen2RGB` at all.\n*   Fixes an OOB seg fault in `DynamicStitch` due to missing validation ([CVE-2022-41883](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-41883))\n*   Fixes an overflow in `tf.keras.losses.poisson` ([CVE-2022-41887](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-41887))\n*   Fixes a heap OOB failure in `ThreadUnsafeUnigramCandidateSampler` caused by missing validation ([CVE-2022-41880](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-41880))\n*   Fixes a segfault in `ndarray_tensor_bridge` ([CVE-2022-41884](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-41884))\n*   Fixes an overflow in `FusedResizeAndPadConv2D` ([CVE-2022-41885](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-41885))\n*   Fixes a overflow in `ImageProjectiveTransformV2` ([CVE-2022-41886](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-41886))\n*   Fixes an FPE in `tf.image.generate_bounding_box_proposals` on GPU ([CVE-2022-41888](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-41888))\n*   Fixes a segfault in `pywrap_tfe_src` caused by invalid attributes ([CVE-2022-41889](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-41889))\n*   Fixes a `CHECK` fail in `BCast` ([CVE-2022-41890](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-41890))\n*   Fixes a segfault in `TensorListConcat` ([CVE-2022-41891](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-41891))\n*   Fixes a `CHECK_EQ` fail in `TensorListResize` ([CVE-2022-41893](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-41893))\n*   Fixes an overflow in `CONV_3D_TRANSPOSE` on TFLite ([CVE-2022-41894](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-41894))\n*   Fixes a heap OOB in `MirrorPadGrad` ([CVE-2022-41895](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-41895))\n*   Fixes a crash in `Mfcc` ([CVE-2022-41896](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-41896))\n*   Fixes a heap OOB in `FractionalMaxPoolGrad` ([CVE-2022-41897](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-41897))\n*   Fixes a `CHECK` fail in `SparseFillEmptyRowsGrad` ([CVE-2022-41898](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-41898))\n*   Fixes a `CHECK` fail in `SdcaOptimizer` ([CVE-2022-41899](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-41899))\n*   Fixes a heap OOB in `FractionalAvgPool` and `FractionalMaxPool`([CVE-2022-41900](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-41900))\n*   Fixes a `CHECK_EQ` in `SparseMatrixNNZ` ([CVE-2022-41901](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-41901))\n*   Fixes an OOB write in grappler ([CVE-2022-41902](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-41902))\n*   Fixes a overflow in `ResizeNearestNeighborGrad` ([CVE-2022-41907](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-41907))\n*   Fixes a `CHECK` fail in `PyFunc` ([CVE-2022-41908](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-41908))\n*   Fixes a segfault in `CompositeTensorVariantToComponents` ([CVE-2022-41909](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-41909))\n*   Fixes a invalid char to bool conversion in printing a tensor ([CVE-2022-41911](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-41911))\n*   Fixes a heap overflow in `QuantizeAndDequantizeV2` ([CVE-2022-41910](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-41910))\n*   Fixes a `CHECK` failure in `SobolSample` via missing validation ([CVE-2022-35935](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-35935))\n*   Fixes a `CHECK` fail in `TensorListScatter` and `TensorListScatterV2` in eager mode ([CVE-2022-35935](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-35935))\n\n## Thanks to our Contributors\n\nThis release contains contributions from many people at Google, as well as:\n\n103yiran, 8bitmp3, Aakar Dwivedi, Alexander Grund, alif_elham, Aman Agarwal,\namoitra, Andrei Ivanov, andreii, Andrew Goodbody, angerson, Ashay Rane,\nAzeem Shaikh, Ben Barsdell, bhack, Bhavani Subramanian, Cedric Nugteren,\nChandra Kumar Ramasamy, Christopher Bate, CohenAriel, Cotarou, cramasam,\nEnrico Minack, Francisco Unda, Frederic Bastien, gadagashwini, Gauri1 Deshpande,\ngeorge, Jake, Jeff, Jerry Ge, Jingxuan He, Jojimon Varghese, Jonathan Dekhtiar,\nKaixi Hou, Kanvi Khanna, kcoul, Keith Smiley, Kevin Hu, Kun Lu, kushanam,\nLianmin Zheng, liuyuanqiang, Louis Sugy, Mahmoud Abuzaina, Marius Brehler,\nmdfaijul, Meenakshi Venkataraman, Milos Puzovic, mohantym, Namrata-Ibm,\nNathan John Sircombe, Nathan Luehr, Olaf Lipinski, Om Thakkar, Osman F Bayram,\nPatrice Vignola, Pavani Majety, Philipp Hack, Prianka Liz Kariat, Rahul Batra,\nRajeshT, Renato Golin, riestere, Roger Iyengar, Rohit Santhanam, Rsanthanam-Amd,\nSadeed Pv, Samuel Marks, Shimokawa, Naoaki, Siddhesh Kothadi, Simengliu-Nv,\nSindre Seppola, snadampal, Srinivasan Narayanamoorthy, sushreebarsa,\nsyedshahbaaz, Tamas Bela Feher, Tatwai Chong, Thibaut Goetghebuer-Planchon,\ntilakrayal, Tom Anderson, Tomohiro Endo, Trevor Morris, vibhutisawant,\nVictor Zhang, Vremold, Xavier Bonaventura, Yanming Wang, Yasir Modak,\nYimei Sun, Yong Tang, Yulv-Git, zhuoran.liu, zotanika\n\n# Release 2.10.1\n\nThis release introduces several vulnerability fixes:\n\n*   Fixes an OOB seg fault in `DynamicStitch` due to missing validation ([CVE-2022-41883](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-41883))\n*   Fixes an overflow in `tf.keras.losses.poisson` ([CVE-2022-41887](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-41887))\n*   Fixes a heap OOB failure in `ThreadUnsafeUnigramCandidateSampler` caused by missing validation ([CVE-2022-41880](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-41880))\n*   Fixes a segfault in `ndarray_tensor_bridge` ([CVE-2022-41884](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-41884))\n*   Fixes an overflow in `FusedResizeAndPadConv2D` ([CVE-2022-41885](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-41885))\n*   Fixes a overflow in `ImageProjectiveTransformV2` ([CVE-2022-41886](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-41886))\n*   Fixes an FPE in `tf.image.generate_bounding_box_proposals` on GPU ([CVE-2022-41888](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-41888))\n*   Fixes a segfault in `pywrap_tfe_src` caused by invalid attributes ([CVE-2022-41889](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-41889))\n*   Fixes a `CHECK` fail in `BCast` ([CVE-2022-41890](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-41890))\n*   Fixes a segfault in `TensorListConcat` ([CVE-2022-41891](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-41891))\n*   Fixes a `CHECK_EQ` fail in `TensorListResize` ([CVE-2022-41893](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-41893))\n*   Fixes an overflow in `CONV_3D_TRANSPOSE` on TFLite ([CVE-2022-41894](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-41894))\n*   Fixes a heap OOB in `MirrorPadGrad` ([CVE-2022-41895](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-41895))\n*   Fixes a crash in `Mfcc` ([CVE-2022-41896](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-41896))\n*   Fixes a heap OOB in `FractionalMaxPoolGrad` ([CVE-2022-41897](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-41897))\n*   Fixes a `CHECK` fail in `SparseFillEmptyRowsGrad` ([CVE-2022-41898](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-41898))\n*   Fixes a `CHECK` fail in `SdcaOptimizer` ([CVE-2022-41899](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-41899))\n*   Fixes a heap OOB in `FractionalAvgPool` and `FractionalMaxPool`([CVE-2022-41900](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-41900))\n*   Fixes a `CHECK_EQ` in `SparseMatrixNNZ` ([CVE-2022-41901](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-41901))\n*   Fixes an OOB write in grappler ([CVE-2022-41902](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-41902))\n*   Fixes a overflow in `ResizeNearestNeighborGrad` ([CVE-2022-41907](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-41907))\n*   Fixes a `CHECK` fail in `PyFunc` ([CVE-2022-41908](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-41908))\n*   Fixes a segfault in `CompositeTensorVariantToComponents` ([CVE-2022-41909](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-41909))\n*   Fixes a invalid char to bool conversion in printing a tensor ([CVE-2022-41911](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-41911))\n*   Fixes a heap overflow in `QuantizeAndDequantizeV2` ([CVE-2022-41910](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-41910))\n*   Fixes a `CHECK` failure in `SobolSample` via missing validation ([CVE-2022-35935](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-35935))\n*   Fixes a `CHECK` fail in `TensorListScatter` and `TensorListScatterV2` in eager mode ([CVE-2022-35935](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-35935))\n\n# Release 2.9.3\n\nThis release introduces several vulnerability fixes:\n\n*   Fixes an overflow in `tf.keras.losses.poisson` ([CVE-2022-41887](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-41887))\n*   Fixes a heap OOB failure in `ThreadUnsafeUnigramCandidateSampler` caused by missing validation ([CVE-2022-41880](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-41880))\n*   Fixes a segfault in `ndarray_tensor_bridge` ([CVE-2022-41884](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-41884))\n*   Fixes an overflow in `FusedResizeAndPadConv2D` ([CVE-2022-41885](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-41885))\n*   Fixes a overflow in `ImageProjectiveTransformV2` ([CVE-2022-41886](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-41886))\n*   Fixes an FPE in `tf.image.generate_bounding_box_proposals` on GPU ([CVE-2022-41888](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-41888))\n*   Fixes a segfault in `pywrap_tfe_src` caused by invalid attributes ([CVE-2022-41889](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-41889))\n*   Fixes a `CHECK` fail in `BCast` ([CVE-2022-41890](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-41890))\n*   Fixes a segfault in `TensorListConcat` ([CVE-2022-41891](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-41891))\n*   Fixes a `CHECK_EQ` fail in `TensorListResize` ([CVE-2022-41893](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-41893))\n*   Fixes an overflow in `CONV_3D_TRANSPOSE` on TFLite ([CVE-2022-41894](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-41894))\n*   Fixes a heap OOB in `MirrorPadGrad` ([CVE-2022-41895](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-41895))\n*   Fixes a crash in `Mfcc` ([CVE-2022-41896](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-41896))\n*   Fixes a heap OOB in `FractionalMaxPoolGrad` ([CVE-2022-41897](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-41897))\n*   Fixes a `CHECK` fail in `SparseFillEmptyRowsGrad` ([CVE-2022-41898](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-41898))\n*   Fixes a `CHECK` fail in `SdcaOptimizer` ([CVE-2022-41899](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-41899))\n*   Fixes a heap OOB in `FractionalAvgPool` and `FractionalMaxPool`([CVE-2022-41900](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-41900))\n*   Fixes a `CHECK_EQ` in `SparseMatrixNNZ` ([CVE-2022-41901](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-41901))\n*   Fixes an OOB write in grappler ([CVE-2022-41902](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-41902))\n*   Fixes a overflow in `ResizeNearestNeighborGrad` ([CVE-2022-41907](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-41907))\n*   Fixes a `CHECK` fail in `PyFunc` ([CVE-2022-41908](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-41908))\n*   Fixes a segfault in `CompositeTensorVariantToComponents` ([CVE-2022-41909](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-41909))\n*   Fixes a invalid char to bool conversion in printing a tensor ([CVE-2022-41911](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-41911))\n*   Fixes a heap overflow in `QuantizeAndDequantizeV2` ([CVE-2022-41910](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-41910))\n*   Fixes a `CHECK` failure in `SobolSample` via missing validation ([CVE-2022-35935](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-35935))\n*   Fixes a `CHECK` fail in `TensorListScatter` and `TensorListScatterV2` in eager mode ([CVE-2022-35935](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-35935))\n\n# Release 2.8.4\n\nThis release introduces several vulnerability fixes:\n\n*   Fixes a heap OOB failure in `ThreadUnsafeUnigramCandidateSampler` caused by missing validation ([CVE-2022-41880](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-41880))\n*   Fixes a segfault in `ndarray_tensor_bridge` ([CVE-2022-41884](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-41884))\n*   Fixes an overflow in `FusedResizeAndPadConv2D` ([CVE-2022-41885](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-41885))\n*   Fixes a overflow in `ImageProjectiveTransformV2` ([CVE-2022-41886](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-41886))\n*   Fixes an FPE in `tf.image.generate_bounding_box_proposals` on GPU ([CVE-2022-41888](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-41888))\n*   Fixes a segfault in `pywrap_tfe_src` caused by invalid attributes ([CVE-2022-41889](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-41889))\n*   Fixes a `CHECK` fail in `BCast` ([CVE-2022-41890](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-41890))\n*   Fixes a segfault in `TensorListConcat` ([CVE-2022-41891](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-41891))\n*   Fixes a `CHECK_EQ` fail in `TensorListResize` ([CVE-2022-41893](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-41893))\n*   Fixes an overflow in `CONV_3D_TRANSPOSE` on TFLite ([CVE-2022-41894](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-41894))\n*   Fixes a heap OOB in `MirrorPadGrad` ([CVE-2022-41895](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-41895))\n*   Fixes a crash in `Mfcc` ([CVE-2022-41896](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-41896))\n*   Fixes a heap OOB in `FractionalMaxPoolGrad` ([CVE-2022-41897](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-41897))\n*   Fixes a `CHECK` fail in `SparseFillEmptyRowsGrad` ([CVE-2022-41898](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-41898))\n*   Fixes a `CHECK` fail in `SdcaOptimizer` ([CVE-2022-41899](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-41899))\n*   Fixes a heap OOB in `FractionalAvgPool` and `FractionalMaxPool`([CVE-2022-41900](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-41900))\n*   Fixes a `CHECK_EQ` in `SparseMatrixNNZ` ([CVE-2022-41901](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-41901))\n*   Fixes an OOB write in grappler ([CVE-2022-41902](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-41902))\n*   Fixes a overflow in `ResizeNearestNeighborGrad` ([CVE-2022-41907](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-41907))\n*   Fixes a `CHECK` fail in `PyFunc` ([CVE-2022-41908](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-41908))\n*   Fixes a segfault in `CompositeTensorVariantToComponents` ([CVE-2022-41909](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-41909))\n*   Fixes a invalid char to bool conversion in printing a tensor ([CVE-2022-41911](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-41911))\n*   Fixes a heap overflow in `QuantizeAndDequantizeV2` ([CVE-2022-41910](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-41910))\n*   Fixes a `CHECK` failure in `SobolSample` via missing validation ([CVE-2022-35935](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-35935))\n*   Fixes a `CHECK` fail in `TensorListScatter` and `TensorListScatterV2` in eager mode ([CVE-2022-35935](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-35935))\n\n# Release 2.10.0\n\n## Breaking Changes\n\n*   Causal attention in `keras.layers.Attention` and\n    `keras.layers.AdditiveAttention` is now specified in the `call()` method via\n    the `use_causal_mask` argument (rather than in the constructor), for\n    consistency with other layers.\n*   Some files in `tensorflow/python/training` have been moved to\n    `tensorflow/python/tracking` and `tensorflow/python/checkpoint`. Please\n    update your imports accordingly, the old files will be removed in Release\n    2.11.\n*   `tf.keras.optimizers.experimental.Optimizer` will graduate in Release 2.11,\n    which means `tf.keras.optimizers.Optimizer` will be an alias of\n    `tf.keras.optimizers.experimental.Optimizer`. The current\n    `tf.keras.optimizers.Optimizer` will continue to be supported as\n    `tf.keras.optimizers.legacy.Optimizer`,\n    e.g.,`tf.keras.optimizers.legacy.Adam`. Most users won't be affected by this\n    change, but please check the\n    [API doc](https://www.tensorflow.org/api_docs/python/tf/keras/optimizers/experimental)\n    if any API used in your workflow is changed or deprecated, and make\n    adaptations. If you decide to keep using the old optimizer, please\n    explicitly change your optimizer to `tf.keras.optimizers.legacy.Optimizer`.\n*   RNG behavior change for `tf.keras.initializers`. Keras initializers will now\n    use stateless random ops to generate random numbers.\n    *   Both seeded and unseeded initializers will always generate the same\n        values every time they are called (for a given variable shape). For\n        unseeded initializers (`seed=None`), a random seed will be created and\n        assigned at initializer creation (different initializer instances get\n        different seeds).\n    *   An unseeded initializer will raise a warning if it is reused (called)\n        multiple times. This is because it would produce the same values each\n        time, which may not be intended.\n*   API changes under `tf.experimental.dtensor`:\n    *   New API for initialization of CPU/GPU/TPU in dtensor.\n        `dtensor.initialize_accelerator_system` and\n        `dtensor.shutdown_accelerator_system`.\n    *   The following existing API will be removed:\n        `dtensor.initialize_multi_client`, `dtensor.initialize_tpu_system`, and\n        `dtensor.shutdown_tpu_system`.\n\n## Deprecations\n\n*   The C++ `tensorflow::Code` and `tensorflow::Status` will become aliases of\n    respectively `absl::StatusCode` and `absl::Status` in some future release.\n    *   Use `tensorflow::OkStatus()` instead of `tensorflow::Status::OK()`.\n    *   Stop constructing `Status` objects from `tensorflow::error::Code`.\n    *   One MUST NOT access `tensorflow::errors::Code` fields. Accessing\n        `tensorflow::error::Code` fields is fine.\n        *   Use the constructors such as `tensorflow::errors:InvalidArgument` to\n            create status using an error code without accessing it.\n        *   Use the free functions such as\n            `tensorflow::errors::IsInvalidArgument` if needed.\n        *   In the last resort, use\n            e.g.`static_cast<tensorflow::errors::Code>(error::Code::INVALID_ARGUMENT)`\n            or `static_cast<int>(code)` for comparisons.\n*   `tensorflow::StatusOr` will also become in the future an alias to\n    `absl::StatusOr`, so use `StatusOr::value` instead of\n    `StatusOr::ConsumeValueOrDie`.\n\n## Major Features and Improvements\n\n*   `tf.lite`:\n\n    *   New operations supported:\n        *   tflite SelectV2 now supports 5D.\n        *   `tf.einsum` is supported with multiple unknown shapes.\n        *   `tf.unsortedsegmentprod` op is supported.\n        *   `tf.unsortedsegmentmax` op is supported.\n        *   `tf.unsortedsegmentsum` op is supported.\n    *   Updates to existing operations:\n        *   `tfl.scatter_nd` now supports I1 for the `update` arg.\n    *   Upgrade Flatbuffers v2.0.5 from v1.12.0\n\n*   `tf.keras`:\n\n    *   `EinsumDense` layer is moved from experimental to core. Its import path\n        is moved from `tf.keras.layers.experimental.EinsumDense` to\n        `tf.keras.layers.EinsumDense`.\n    *   Added `tf.keras.utils.audio_dataset_from_directory` utility to easily\n        generate audio classification datasets from directories of `.wav` files.\n    *   Added `subset=\"both\"` support in\n        `tf.keras.utils.image_dataset_from_directory`,`tf.keras.utils.text_dataset_from_directory`,\n        and `audio_dataset_from_directory`, to be used with the\n        `validation_split` argument, for returning both dataset splits at once,\n        as a tuple.\n    *   Added `tf.keras.utils.split_dataset` utility to split a `Dataset` object\n        or a list/tuple of arrays into two `Dataset` objects (e.g. train/test).\n    *   Added step granularity to `BackupAndRestore` callback for handling\n        distributed training failures & restarts. The training state can now be\n        restored at the exact epoch and step at which it was previously saved\n        before failing.\n    *   Added\n        [`tf.keras.dtensor.experimental.optimizers.AdamW`](https://www.tensorflow.org/api_docs/python/tf/keras/dtensor/experimental/optimizers/AdamW).\n        This optimizer is similar to the existing\n        [`keras.optimizers.experimental.AdamW`](https://www.tensorflow.org/api_docs/python/tf/keras/optimizers/experimental/AdamW),\n        and works in the DTensor training use case.\n    *   Improved masking support for\n        [`tf.keras.layers.MultiHeadAttention`](https://www.tensorflow.org/api_docs/python/tf/keras/layers/MultiHeadAttention).\n        *   Implicit masks for `query`, `key` and `value` inputs will\n            automatically be used to compute a correct attention mask for the\n            layer. These padding masks will be combined with any\n            `attention_mask` passed in directly when calling the layer. This can\n            be used with\n            [`tf.keras.layers.Embedding`](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Embedding)\n            with `mask_zero=True` to automatically infer a correct padding mask.\n        *   Added a `use_causal_mask` call time argument to the layer. Passing\n            `use_causal_mask=True` will compute a causal attention mask, and\n            optionally combine it with any `attention_mask` passed in directly\n            when calling the layer.\n    *   Added `ignore_class` argument in the loss\n        `SparseCategoricalCrossentropy` and metrics `IoU` and `MeanIoU`, to\n        specify a class index to be ignored during loss/metric computation (e.g.\n        a background/void class).\n    *   Added\n        [`tf.keras.models.experimental.SharpnessAwareMinimization`](https://www.tensorflow.org/api_docs/python/tf/keras/models/experimental/SharpnessAwareMinimization).\n        This class implements the sharpness-aware minimization technique, which\n        boosts model performance on various tasks, e.g., ResNet on image\n        classification.\n\n*   `tf.data`:\n\n    *   Added support for cross-trainer data caching in tf.data service. This\n        saves computation resources when concurrent training jobs train from the\n        same dataset. See\n        (https://www.tensorflow.org/api_docs/python/tf/data/experimental/service#sharing_tfdata_service_with_concurrent_trainers)\n        for more details.\n    *   Added `dataset_id` to `tf.data.experimental.service.register_dataset`.\n        If provided, `tf.data` service will use the provided ID for the dataset.\n        If the dataset ID already exists, no new dataset will be registered.\n        This is useful if multiple training jobs need to use the same dataset\n        for training. In this case, users should call `register_dataset` with\n        the same `dataset_id`.\n    *   Added a new field, `inject_prefetch`, to\n        `tf.data.experimental.OptimizationOptions`. If it is set to\n        `True`,`tf.data` will now automatically add a `prefetch` transformation\n        to datasets that end in synchronous transformations. This enables data\n        generation to be overlapped with data consumption. This may cause a\n        small increase in memory usage due to buffering. To enable this\n        behavior, set `inject_prefetch=True` in\n        `tf.data.experimental.OptimizationOptions`.\n    *   Added a new value to `tf.data.Options.autotune.autotune_algorithm`:\n        `STAGE_BASED`. If the autotune algorithm is set to `STAGE_BASED`, then\n        it runs a new algorithm that can get the same performance with lower\n        CPU/memory usage.\n    *   Added\n        [`tf.data.experimental.from_list`](https://www.tensorflow.org/api_docs/python/tf/data/experimental/from_list),\n        a new API for creating `Dataset`s from lists of elements.\n    *   Graduated experimental APIs:\n        *   [`tf.data.Dataset.counter`](https://www.tensorflow.org/api_docs/python/tf/data/Dataset/#counter),\n            which creates `Dataset`s of indefinite sequences of numbers.\n        *   [`tf.data.Dataset.ignore_errors`](https://www.tensorflow.org/api_docs/python/tf/data/Dataset/#ignore_errors),\n            which drops erroneous elements from `Dataset`s.\n    *   Added\n        [`tf.data.Dataset.rebatch`](https://www.tensorflow.org/api_docs/python/tf/data/Dataset#rebatch),\n        a new API for rebatching the elements of a dataset.\n\n*   `tf.distribute`:\n\n    *   Added\n        [`tf.distribute.experimental.PreemptionCheckpointHandler`](https://www.tensorflow.org/api_docs/python/tf/distribute/experimental/PreemptionCheckpointHandler)\n        to handle worker preemption/maintenance and cluster-wise consistent\n        error reporting for `tf.distribute.MultiWorkerMirroredStrategy`.\n        Specifically, for the type of interruption with advance notice, it\n        automatically saves a checkpoint, exits the program without raising an\n        unrecoverable error, and restores the progress when training restarts.\n\n*   `tf.math`:\n\n    *   Added `tf.math.approx_max_k` and `tf.math.approx_min_k` which are the\n        optimized alternatives to `tf.math.top_k` on TPU. The performance\n        difference ranges from 8 to 100 times depending on the size of k. When\n        running on CPU and GPU, a non-optimized XLA kernel is used.\n\n*   `tf.train`:\n\n    *   Added `tf.train.TrackableView` which allows users to inspect the\n        TensorFlow Trackable object (e.g. `tf.Module`, Keras Layers and models).\n\n*   `tf.vectorized_map`:\n\n    *   Added an optional parameter: `warn`. This parameter controls whether or\n        not warnings will be printed when operations in the provided `fn` fall\n        back to a while loop.\n\n*   XLA:\n\n    *   `tf.distribute.MultiWorkerMirroredStrategy` is now compilable with XLA.\n    *   [Compute Library for the Arm Architecture (ACL)](https://github.com/ARM-software/ComputeLibrary)\n        is supported for aarch64 CPU XLA runtime\n\n*   CPU performance optimizations:\n\n    *   **x86 CPUs**:\n        [oneDNN](https://github.com/tensorflow/community/blob/master/rfcs/20210930-enable-onednn-ops.md)\n        bfloat16 auto-mixed precision grappler graph optimization pass has been\n        renamed from `auto_mixed_precision_mkl` to\n        `auto_mixed_precision_onednn_bfloat16`. See example usage\n        [here](https://www.intel.com/content/www/us/en/developer/articles/guide/getting-started-with-automixedprecisionmkl.html).\n    *   **aarch64 CPUs:** Experimental performance optimizations from\n        [Compute Library for the Arm Architecture (ACL)](https://github.com/ARM-software/ComputeLibrary)\n        are available through oneDNN in the default Linux aarch64 package (`pip\n        install tensorflow`).\n        *   The optimizations are disabled by default.\n        *   Set the environment variable `TF_ENABLE_ONEDNN_OPTS=1` to enable the\n            optimizations. Setting the variable to 0 or unsetting it will\n            disable the optimizations.\n        *   These optimizations can yield slightly different numerical results\n            from when they are off due to floating-point round-off errors from\n            different computation approaches and orders.\n        *   To verify that the optimizations are on, look for a message with\n            \"*oneDNN custom operations are on*\" in the log. If the exact phrase\n            is not there, it means they are off.\n\n## Bug Fixes and Other Changes\n\n*   New argument `experimental_device_ordinal` in `LogicalDeviceConfiguration`\n    to control the order of logical devices (GPU only).\n\n*   `tf.keras`:\n\n    *   Changed the TensorBoard tag names produced by the\n        `tf.keras.callbacks.TensorBoard` callback, so that summaries logged\n        automatically for model weights now include either a `/histogram` or\n        `/image` suffix in their tag names, in order to prevent tag name\n        collisions across summary types.\n\n*   When running on GPU (with cuDNN version 7.6.3 or\n    later),`tf.nn.depthwise_conv2d` backprop to `filter` (and therefore also\n    `tf.keras.layers.DepthwiseConv2D`) now operate deterministically (and\n    `tf.errors.UnimplementedError` is no longer thrown) when op-determinism has\n    been enabled via `tf.config.experimental.enable_op_determinism`. This closes\n    issue [47174](https://github.com/tensorflow/tensorflow/issues/47174).\n\n*   `tf.random`\n\n    *   Added `tf.random.experimental.stateless_shuffle`, a stateless version of\n        `tf.random.shuffle`.\n\n## Security\n\n*   Fixes a `CHECK` failure in tf.reshape caused by overflows ([CVE-2022-35934](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-35934))\n*   Fixes a `CHECK` failure in `SobolSample` caused by missing validation ([CVE-2022-35935](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-35935))\n*   Fixes an OOB read in `Gather_nd` op in TF Lite ([CVE-2022-35937](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-35937))\n*   Fixes a `CHECK` failure in `TensorListReserve` caused by missing validation ([CVE-2022-35960](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-35960))\n*   Fixes an OOB write in `Scatter_nd` op in TF Lite ([CVE-2022-35939](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-35939))\n*   Fixes an integer overflow in `RaggedRangeOp` ([CVE-2022-35940](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-35940))\n*   Fixes a `CHECK` failure in `AvgPoolOp` ([CVE-2022-35941](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-35941))\n*   Fixes a `CHECK` failures in `UnbatchGradOp` ([CVE-2022-35952](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-35952))\n*   Fixes a segfault TFLite converter on per-channel quantized transposed convolutions ([CVE-2022-36027](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-36027))\n*   Fixes a `CHECK` failures in `AvgPool3DGrad` ([CVE-2022-35959](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-35959))\n*   Fixes a `CHECK` failures in `FractionalAvgPoolGrad` ([CVE-2022-35963](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-35963))\n*   Fixes a segfault in `BlockLSTMGradV2` ([CVE-2022-35964](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-35964))\n*   Fixes a segfault in `LowerBound` and `UpperBound` ([CVE-2022-35965](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-35965))\n*   Fixes a segfault in `QuantizedAvgPool` ([CVE-2022-35966](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-35966))\n*   Fixes a segfault in `QuantizedAdd` ([CVE-2022-35967](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-35967))\n*   Fixes a `CHECK` fail in `AvgPoolGrad` ([CVE-2022-35968](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-35968))\n*   Fixes a `CHECK` fail in `Conv2DBackpropInput` ([CVE-2022-35969](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-35969))\n*   Fixes a segfault in `QuantizedInstanceNorm` ([CVE-2022-35970](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-35970))\n*   Fixes a `CHECK` fail in `FakeQuantWithMinMaxVars` ([CVE-2022-35971](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-35971))\n*   Fixes a segfault in `Requantize` ([CVE-2022-36017](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-36017))\n*   Fixes a segfault in `QuantizedBiasAdd` ([CVE-2022-35972](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-35972))\n*   Fixes a `CHECK` fail in `FakeQuantWithMinMaxVarsPerChannel` ([CVE-2022-36019](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-36019))\n*   Fixes a segfault in `QuantizedMatMul` ([CVE-2022-35973](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-35973))\n*   Fixes a segfault in `QuantizeDownAndShrinkRange` ([CVE-2022-35974](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-35974))\n*   Fixes segfaults in `QuantizedRelu` and `QuantizedRelu6` ([CVE-2022-35979](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-35979))\n*   Fixes a `CHECK` fail in `FractionalMaxPoolGrad` ([CVE-2022-35981](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-35981))\n*   Fixes a `CHECK` fail in `RaggedTensorToVariant` ([CVE-2022-36018](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-36018))\n*   Fixes a `CHECK` fail in `QuantizeAndDequantizeV3` ([CVE-2022-36026](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-36026))\n*   Fixes a segfault in `SparseBincount` ([CVE-2022-35982](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-35982))\n*   Fixes a `CHECK` fail in `Save` and `SaveSlices` ([CVE-2022-35983](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-35983))\n*   Fixes a `CHECK` fail in `ParameterizedTruncatedNormal` ([CVE-2022-35984](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-35984))\n*   Fixes a `CHECK` fail in `LRNGrad` ([CVE-2022-35985](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-35985))\n*   Fixes a segfault in `RaggedBincount` ([CVE-2022-35986](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-35986))\n*   Fixes a `CHECK` fail in `DenseBincount` ([CVE-2022-35987](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-35987))\n*   Fixes a `CHECK` fail in `tf.linalg.matrix_rank` ([CVE-2022-35988](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-35988))\n*   Fixes a `CHECK` fail in `MaxPool` ([CVE-2022-35989](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-35989))\n*   Fixes a `CHECK` fail in `Conv2DBackpropInput` ([CVE-2022-35999](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-35999))\n*   Fixes a `CHECK` fail in `EmptyTensorList` ([CVE-2022-35998](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-35998))\n*   Fixes a `CHECK` fail in `tf.sparse.cross` ([CVE-2022-35997](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-35997))\n*   Fixes a floating point exception in `Conv2D` ([CVE-2022-35996](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-35996))\n*   Fixes a `CHECK` fail in `AudioSummaryV2` ([CVE-2022-35995](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-35995))\n*   Fixes a `CHECK` fail in `CollectiveGather` ([CVE-2022-35994](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-35994))\n*   Fixes a `CHECK` fail in `SetSize` ([CVE-2022-35993](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-35993))\n*   Fixes a `CHECK` fail in `TensorListFromTensor` ([CVE-2022-35992](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-35992))\n*   Fixes a `CHECK` fail in `TensorListScatter` and `TensorListScatterV2` ([CVE-2022-35991](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-35991))\n*   Fixes a `CHECK` fail in `FakeQuantWithMinMaxVarsPerChannelGradient` ([CVE-2022-35990](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-35990))\n*   Fixes a `CHECK` fail in `FakeQuantWithMinMaxVarsGradient` ([CVE-2022-36005](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-36005))\n*   Fixes a `CHECK` fail in `tf.random.gamma` ([CVE-2022-36004](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-36004))\n*   Fixes a `CHECK` fail in `RandomPoissonV2` ([CVE-2022-36003](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-36003))\n*   Fixes a `CHECK` fail in `Unbatch` ([CVE-2022-36002](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-36002))\n*   Fixes a `CHECK` fail in `DrawBoundingBoxes` ([CVE-2022-36001](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-36001))\n*   Fixes a `CHECK` fail in `Eig` ([CVE-2022-36000](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-36000))\n*   Fixes a null dereference on MLIR on empty function attributes ([CVE-2022-36011](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-36011))\n*   Fixes an assertion failure on MLIR empty edge names ([CVE-2022-36012](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-36012))\n*   Fixes a null-dereference in `mlir::tfg::GraphDefImporter::ConvertNodeDef` ([CVE-2022-36013](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-36013))\n*   Fixes a null-dereference in `mlir::tfg::TFOp::nameAttr` ([CVE-2022-36014](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-36014))\n*   Fixes an integer overflow in math ops ([CVE-2022-36015](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-36015))\n*   Fixes a `CHECK`-fail in `tensorflow::full_type::SubstituteFromAttrs` ([CVE-2022-36016](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-36016))\n*   Fixes an OOB read in `Gather_nd` op in TF Lite Micro ([CVE-2022-35938](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-35938))\n\n## Thanks to our Contributors\n\nThis release contains contributions from many people at Google, as well as:\n\nAbolfazl Shahbazi, Adam Lanicek, Amin Benarieb, andreii, Andrew Fitzgibbon, Andrew Goodbody, angerson, Ashiq Imran, Aurlien Geron, Banikumar Maiti (Intel Aipg), Ben Barsdell, Ben Mares, bhack, Bhavani Subramanian, Bill Schnurr, Byungsoo Oh, Chandra Sr Potula, Chengji Yao, Chris Carpita, Christopher Bate, chunduriv, Cliff Woolley, Cliffs Dover, Cloud Han, Code-Review-Doctor, DEKHTIARJonathan, Deven Desai, Djacon, Duncan Riach, fedotoff, fo40225, Frederic Bastien, gadagashwini, Gauri1 Deshpande, guozhong.zhuang, Hui Peng, James Gerity, Jason Furmanek, Jonathan Dekhtiar, Jueon Park, Kaixi Hou, Kanvi Khanna, Keith Smiley, Koan-Sin Tan, Kulin Seth, kushanam, Learning-To-Play, Li-Wen Chang, lipracer, liuyuanqiang, Louis Sugy, Lucas David, Lukas Geiger, Mahmoud Abuzaina, Marius Brehler, Maxiwell S. Garcia, mdfaijul, Meenakshi Venkataraman, Michal Szutenberg, Michele Di Giorgio, Mickal Salamin, Nathan John Sircombe, Nathan Luehr, Neil Girdhar, Nils Reichardt, Nishidha Panpaliya, Nobuo Tsukamoto, Om Thakkar, Patrice Vignola, Philipp Hack, Pooya Jannaty, Prianka Liz Kariat, pshiko, Rajeshwar Reddy T, rdl4199, Rohit Santhanam, Rsanthanam-Amd, Sachin Muradi, Saoirse Stewart, Serge Panev, Shu Wang, Srinivasan Narayanamoorthy, Stella Stamenova, Stephan Hartmann, Sunita Nadampalli, synandi, Tamas Bela Feher, Tao Xu, Thibaut Goetghebuer-Planchon, Trevor Morris, Xiaoming (Jason) Cui, Yimei Sun, Yong Tang, Yuanqiang Liu, Yulv-Git, Zhoulong Jiang, ZihengJiang\n\n# Release 2.9.2\n\nThis releases introduces several vulnerability fixes:\n\n*   Fixes a `CHECK` failure in tf.reshape caused by overflows ([CVE-2022-35934](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-35934))\n*   Fixes a `CHECK` failure in `SobolSample` caused by missing validation ([CVE-2022-35935](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-35935))\n*   Fixes an OOB read in `Gather_nd` op in TF Lite ([CVE-2022-35937](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-35937))\n*   Fixes a `CHECK` failure in `TensorListReserve` caused by missing validation ([CVE-2022-35960](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-35960))\n*   Fixes an OOB write in `Scatter_nd` op in TF Lite ([CVE-2022-35939](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-35939))\n*   Fixes an integer overflow in `RaggedRangeOp` ([CVE-2022-35940](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-35940))\n*   Fixes a `CHECK` failure in `AvgPoolOp` ([CVE-2022-35941](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-35941))\n*   Fixes a `CHECK` failures in `UnbatchGradOp` ([CVE-2022-35952](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-35952))\n*   Fixes a segfault TFLite converter on per-channel quantized transposed convolutions ([CVE-2022-36027](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-36027))\n*   Fixes a `CHECK` failures in `AvgPool3DGrad` ([CVE-2022-35959](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-35959))\n*   Fixes a `CHECK` failures in `FractionalAvgPoolGrad` ([CVE-2022-35963](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-35963))\n*   Fixes a segfault in `BlockLSTMGradV2` ([CVE-2022-35964](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-35964))\n*   Fixes a segfault in `LowerBound` and `UpperBound` ([CVE-2022-35965](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-35965))\n*   Fixes a segfault in `QuantizedAvgPool` ([CVE-2022-35966](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-35966))\n*   Fixes a segfault in `QuantizedAdd` ([CVE-2022-35967](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-35967))\n*   Fixes a `CHECK` fail in `AvgPoolGrad` ([CVE-2022-35968](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-35968))\n*   Fixes a `CHECK` fail in `Conv2DBackpropInput` ([CVE-2022-35969](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-35969))\n*   Fixes a segfault in `QuantizedInstanceNorm` ([CVE-2022-35970](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-35970))\n*   Fixes a `CHECK` fail in `FakeQuantWithMinMaxVars` ([CVE-2022-35971](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-35971))\n*   Fixes a segfault in `Requantize` ([CVE-2022-36017](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-36017))\n*   Fixes a segfault in `QuantizedBiasAdd` ([CVE-2022-35972](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-35972))\n*   Fixes a `CHECK` fail in `FakeQuantWithMinMaxVarsPerChannel` ([CVE-2022-36019](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-36019))\n*   Fixes a segfault in `QuantizedMatMul` ([CVE-2022-35973](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-35973))\n*   Fixes a segfault in `QuantizeDownAndShrinkRange` ([CVE-2022-35974](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-35974))\n*   Fixes segfaults in `QuantizedRelu` and `QuantizedRelu6` ([CVE-2022-35979](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-35979))\n*   Fixes a `CHECK` fail in `FractionalMaxPoolGrad` ([CVE-2022-35981](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-35981))\n*   Fixes a `CHECK` fail in `RaggedTensorToVariant` ([CVE-2022-36018](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-36018))\n*   Fixes a `CHECK` fail in `QuantizeAndDequantizeV3` ([CVE-2022-36026](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-36026))\n*   Fixes a segfault in `SparseBincount` ([CVE-2022-35982](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-35982))\n*   Fixes a `CHECK` fail in `Save` and `SaveSlices` ([CVE-2022-35983](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-35983))\n*   Fixes a `CHECK` fail in `ParameterizedTruncatedNormal` ([CVE-2022-35984](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-35984))\n*   Fixes a `CHECK` fail in `LRNGrad` ([CVE-2022-35985](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-35985))\n*   Fixes a segfault in `RaggedBincount` ([CVE-2022-35986](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-35986))\n*   Fixes a `CHECK` fail in `DenseBincount` ([CVE-2022-35987](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-35987))\n*   Fixes a `CHECK` fail in `tf.linalg.matrix_rank` ([CVE-2022-35988](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-35988))\n*   Fixes a `CHECK` fail in `MaxPool` ([CVE-2022-35989](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-35989))\n*   Fixes a `CHECK` fail in `Conv2DBackpropInput` ([CVE-2022-35999](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-35999))\n*   Fixes a `CHECK` fail in `EmptyTensorList` ([CVE-2022-35998](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-35998))\n*   Fixes a `CHECK` fail in `tf.sparse.cross` ([CVE-2022-35997](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-35997))\n*   Fixes a floating point exception in `Conv2D` ([CVE-2022-35996](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-35996))\n*   Fixes a `CHECK` fail in `AudioSummaryV2` ([CVE-2022-35995](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-35995))\n*   Fixes a `CHECK` fail in `CollectiveGather` ([CVE-2022-35994](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-35994))\n*   Fixes a `CHECK` fail in `SetSize` ([CVE-2022-35993](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-35993))\n*   Fixes a `CHECK` fail in `TensorListFromTensor` ([CVE-2022-35992](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-35992))\n*   Fixes a `CHECK` fail in `TensorListScatter` and `TensorListScatterV2` ([CVE-2022-35991](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-35991))\n*   Fixes a `CHECK` fail in `FakeQuantWithMinMaxVarsPerChannelGradient` ([CVE-2022-35990](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-35990))\n*   Fixes a `CHECK` fail in `FakeQuantWithMinMaxVarsGradient` ([CVE-2022-36005](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-36005))\n*   Fixes a `CHECK` fail in `tf.random.gamma` ([CVE-2022-36004](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-36004))\n*   Fixes a `CHECK` fail in `RandomPoissonV2` ([CVE-2022-36003](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-36003))\n*   Fixes a `CHECK` fail in `Unbatch` ([CVE-2022-36002](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-36002))\n*   Fixes a `CHECK` fail in `DrawBoundingBoxes` ([CVE-2022-36001](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-36001))\n*   Fixes a `CHECK` fail in `Eig` ([CVE-2022-36000](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-36000))\n*   Fixes a null dereference on MLIR on empty function attributes ([CVE-2022-36011](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-36011))\n*   Fixes an assertion failure on MLIR empty edge names ([CVE-2022-36012](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-36012))\n*   Fixes a null-dereference in `mlir::tfg::GraphDefImporter::ConvertNodeDef` ([CVE-2022-36013](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-36013))\n*   Fixes a null-dereference in `mlir::tfg::TFOp::nameAttr` ([CVE-2022-36014](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-36014))\n*   Fixes an integer overflow in math ops ([CVE-2022-36015](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-36015))\n*   Fixes a `CHECK`-fail in `tensorflow::full_type::SubstituteFromAttrs` ([CVE-2022-36016](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-36016))\n*   Fixes an OOB read in `Gather_nd` op in TF Lite Micro ([CVE-2022-35938](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-35938))\n\n# Release 2.8.3\n\nThis releases introduces several vulnerability fixes:\n*   Fixes a `CHECK` failure in tf.reshape caused by overflows ([CVE-2022-35934](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-35934))\n*   Fixes a `CHECK` failure in `SobolSample` caused by missing validation ([CVE-2022-35935](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-35935))\n*   Fixes an OOB read in `Gather_nd` op in TF Lite ([CVE-2022-35937](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-35937))\n*   Fixes a `CHECK` failure in `TensorListReserve` caused by missing validation ([CVE-2022-35960](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-35960))\n*   Fixes an OOB write in `Scatter_nd` op in TF Lite ([CVE-2022-35939](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-35939))\n*   Fixes an integer overflow in `RaggedRangeOp` ([CVE-2022-35940](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-35940))\n*   Fixes a `CHECK` failure in `AvgPoolOp` ([CVE-2022-35941](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-35941))\n*   Fixes a `CHECK` failures in `UnbatchGradOp` ([CVE-2022-35952](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-35952))\n*   Fixes a segfault TFLite converter on per-channel quantized transposed convolutions ([CVE-2022-36027](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-36027))\n*   Fixes a `CHECK` failures in `AvgPool3DGrad` ([CVE-2022-35959](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-35959))\n*   Fixes a `CHECK` failures in `FractionalAvgPoolGrad` ([CVE-2022-35963](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-35963))\n*   Fixes a segfault in `BlockLSTMGradV2` ([CVE-2022-35964](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-35964))\n*   Fixes a segfault in `LowerBound` and `UpperBound` ([CVE-2022-35965](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-35965))\n*   Fixes a segfault in `QuantizedAvgPool` ([CVE-2022-35966](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-35966))\n*   Fixes a segfault in `QuantizedAdd` ([CVE-2022-35967](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-35967))\n*   Fixes a `CHECK` fail in `AvgPoolGrad` ([CVE-2022-35968](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-35968))\n*   Fixes a `CHECK` fail in `Conv2DBackpropInput` ([CVE-2022-35969](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-35969))\n*   Fixes a segfault in `QuantizedInstanceNorm` ([CVE-2022-35970](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-35970))\n*   Fixes a `CHECK` fail in `FakeQuantWithMinMaxVars` ([CVE-2022-35971](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-35971))\n*   Fixes a segfault in `Requantize` ([CVE-2022-36017](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-36017))\n*   Fixes a segfault in `QuantizedBiasAdd` ([CVE-2022-35972](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-35972))\n*   Fixes a `CHECK` fail in `FakeQuantWithMinMaxVarsPerChannel` ([CVE-2022-36019](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-36019))\n*   Fixes a segfault in `QuantizedMatMul` ([CVE-2022-35973](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-35973))\n*   Fixes a segfault in `QuantizeDownAndShrinkRange` ([CVE-2022-35974](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-35974))\n*   Fixes segfaults in `QuantizedRelu` and `QuantizedRelu6` ([CVE-2022-35979](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-35979))\n*   Fixes a `CHECK` fail in `FractionalMaxPoolGrad` ([CVE-2022-35981](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-35981))\n*   Fixes a `CHECK` fail in `RaggedTensorToVariant` ([CVE-2022-36018](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-36018))\n*   Fixes a `CHECK` fail in `QuantizeAndDequantizeV3` ([CVE-2022-36026](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-36026))\n*   Fixes a segfault in `SparseBincount` ([CVE-2022-35982](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-35982))\n*   Fixes a `CHECK` fail in `Save` and `SaveSlices` ([CVE-2022-35983](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-35983))\n*   Fixes a `CHECK` fail in `ParameterizedTruncatedNormal` ([CVE-2022-35984](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-35984))\n*   Fixes a `CHECK` fail in `LRNGrad` ([CVE-2022-35985](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-35985))\n*   Fixes a segfault in `RaggedBincount` ([CVE-2022-35986](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-35986))\n*   Fixes a `CHECK` fail in `DenseBincount` ([CVE-2022-35987](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-35987))\n*   Fixes a `CHECK` fail in `tf.linalg.matrix_rank` ([CVE-2022-35988](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-35988))\n*   Fixes a `CHECK` fail in `MaxPool` ([CVE-2022-35989](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-35989))\n*   Fixes a `CHECK` fail in `Conv2DBackpropInput` ([CVE-2022-35999](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-35999))\n*   Fixes a `CHECK` fail in `EmptyTensorList` ([CVE-2022-35998](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-35998))\n*   Fixes a `CHECK` fail in `tf.sparse.cross` ([CVE-2022-35997](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-35997))\n*   Fixes a floating point exception in `Conv2D` ([CVE-2022-35996](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-35996))\n*   Fixes a `CHECK` fail in `AudioSummaryV2` ([CVE-2022-35995](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-35995))\n*   Fixes a `CHECK` fail in `CollectiveGather` ([CVE-2022-35994](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-35994))\n*   Fixes a `CHECK` fail in `SetSize` ([CVE-2022-35993](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-35993))\n*   Fixes a `CHECK` fail in `TensorListFromTensor` ([CVE-2022-35992](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-35992))\n*   Fixes a `CHECK` fail in `TensorListScatter` and `TensorListScatterV2` ([CVE-2022-35991](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-35991))\n*   Fixes a `CHECK` fail in `FakeQuantWithMinMaxVarsPerChannelGradient` ([CVE-2022-35990](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-35990))\n*   Fixes a `CHECK` fail in `FakeQuantWithMinMaxVarsGradient` ([CVE-2022-36005](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-36005))\n*   Fixes a `CHECK` fail in `tf.random.gamma` ([CVE-2022-36004](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-36004))\n*   Fixes a `CHECK` fail in `RandomPoissonV2` ([CVE-2022-36003](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-36003))\n*   Fixes a `CHECK` fail in `Unbatch` ([CVE-2022-36002](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-36002))\n*   Fixes a `CHECK` fail in `DrawBoundingBoxes` ([CVE-2022-36001](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-36001))\n*   Fixes a `CHECK` fail in `Eig` ([CVE-2022-36000](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-36000))\n*   Fixes a null dereference on MLIR on empty function attributes ([CVE-2022-36011](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-36011))\n*   Fixes an assertion failure on MLIR empty edge names ([CVE-2022-36012](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-36012))\n*   Fixes a null-dereference in `mlir::tfg::GraphDefImporter::ConvertNodeDef` ([CVE-2022-36013](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-36013))\n*   Fixes a null-dereference in `mlir::tfg::TFOp::nameAttr` ([CVE-2022-36014](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-36014))\n*   Fixes an integer overflow in math ops ([CVE-2022-36015](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-36015))\n*   Fixes a `CHECK`-fail in `tensorflow::full_type::SubstituteFromAttrs` ([CVE-2022-36016](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-36016))\n*   Fixes an OOB read in `Gather_nd` op in TF Lite Micro ([CVE-2022-35938](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-35938))\n\n# Release 2.7.4\n\n**Note**: This is the last release in the 2.7.x series\n\nThis releases introduces several vulnerability fixes:\n\n*   Fixes a `CHECK` failure in tf.reshape caused by overflows ([CVE-2022-35934](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-35934))\n*   Fixes a `CHECK` failure in `SobolSample` caused by missing validation ([CVE-2022-35935](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-35935))\n*   Fixes an OOB read in `Gather_nd` op in TF Lite ([CVE-2022-35937](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-35937))\n*   Fixes a `CHECK` failure in `TensorListReserve` caused by missing validation ([CVE-2022-35960](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-35960))\n*   Fixes an OOB write in `Scatter_nd` op in TF Lite ([CVE-2022-35939](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-35939))\n*   Fixes an integer overflow in `RaggedRangeOp` ([CVE-2022-35940](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-35940))\n*   Fixes a `CHECK` failure in `AvgPoolOp` ([CVE-2022-35941](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-35941))\n*   Fixes a `CHECK` failures in `UnbatchGradOp` ([CVE-2022-35952](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-35952))\n*   Fixes a segfault TFLite converter on per-channel quantized transposed convolutions ([CVE-2022-36027](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-36027))\n*   Fixes a `CHECK` failures in `AvgPool3DGrad` ([CVE-2022-35959](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-35959))\n*   Fixes a `CHECK` failures in `FractionalAvgPoolGrad` ([CVE-2022-35963](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-35963))\n*   Fixes a segfault in `BlockLSTMGradV2` ([CVE-2022-35964](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-35964))\n*   Fixes a segfault in `LowerBound` and `UpperBound` ([CVE-2022-35965](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-35965))\n*   Fixes a segfault in `QuantizedAvgPool` ([CVE-2022-35966](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-35966))\n*   Fixes a segfault in `QuantizedAdd` ([CVE-2022-35967](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-35967))\n*   Fixes a `CHECK` fail in `AvgPoolGrad` ([CVE-2022-35968](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-35968))\n*   Fixes a `CHECK` fail in `Conv2DBackpropInput` ([CVE-2022-35969](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-35969))\n*   Fixes a segfault in `QuantizedInstanceNorm` ([CVE-2022-35970](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-35970))\n*   Fixes a `CHECK` fail in `FakeQuantWithMinMaxVars` ([CVE-2022-35971](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-35971))\n*   Fixes a segfault in `Requantize` ([CVE-2022-36017](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-36017))\n*   Fixes a segfault in `QuantizedBiasAdd` ([CVE-2022-35972](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-35972))\n*   Fixes a `CHECK` fail in `FakeQuantWithMinMaxVarsPerChannel` ([CVE-2022-36019](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-36019))\n*   Fixes a segfault in `QuantizedMatMul` ([CVE-2022-35973](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-35973))\n*   Fixes a segfault in `QuantizeDownAndShrinkRange` ([CVE-2022-35974](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-35974))\n*   Fixes segfaults in `QuantizedRelu` and `QuantizedRelu6` ([CVE-2022-35979](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-35979))\n*   Fixes a `CHECK` fail in `FractionalMaxPoolGrad` ([CVE-2022-35981](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-35981))\n*   Fixes a `CHECK` fail in `RaggedTensorToVariant` ([CVE-2022-36018](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-36018))\n*   Fixes a `CHECK` fail in `QuantizeAndDequantizeV3` ([CVE-2022-36026](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-36026))\n*   Fixes a segfault in `SparseBincount` ([CVE-2022-35982](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-35982))\n*   Fixes a `CHECK` fail in `Save` and `SaveSlices` ([CVE-2022-35983](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-35983))\n*   Fixes a `CHECK` fail in `ParameterizedTruncatedNormal` ([CVE-2022-35984](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-35984))\n*   Fixes a `CHECK` fail in `LRNGrad` ([CVE-2022-35985](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-35985))\n*   Fixes a segfault in `RaggedBincount` ([CVE-2022-35986](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-35986))\n*   Fixes a `CHECK` fail in `DenseBincount` ([CVE-2022-35987](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-35987))\n*   Fixes a `CHECK` fail in `tf.linalg.matrix_rank` ([CVE-2022-35988](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-35988))\n*   Fixes a `CHECK` fail in `MaxPool` ([CVE-2022-35989](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-35989))\n*   Fixes a `CHECK` fail in `Conv2DBackpropInput` ([CVE-2022-35999](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-35999))\n*   Fixes a `CHECK` fail in `EmptyTensorList` ([CVE-2022-35998](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-35998))\n*   Fixes a `CHECK` fail in `tf.sparse.cross` ([CVE-2022-35997](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-35997))\n*   Fixes a floating point exception in `Conv2D` ([CVE-2022-35996](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-35996))\n*   Fixes a `CHECK` fail in `AudioSummaryV2` ([CVE-2022-35995](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-35995))\n*   Fixes a `CHECK` fail in `CollectiveGather` ([CVE-2022-35994](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-35994))\n*   Fixes a `CHECK` fail in `SetSize` ([CVE-2022-35993](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-35993))\n*   Fixes a `CHECK` fail in `TensorListFromTensor` ([CVE-2022-35992](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-35992))\n*   Fixes a `CHECK` fail in `TensorListScatter` and `TensorListScatterV2` ([CVE-2022-35991](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-35991))\n*   Fixes a `CHECK` fail in `FakeQuantWithMinMaxVarsPerChannelGradient` ([CVE-2022-35990](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-35990))\n*   Fixes a `CHECK` fail in `FakeQuantWithMinMaxVarsGradient` ([CVE-2022-36005](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-36005))\n*   Fixes a `CHECK` fail in `tf.random.gamma` ([CVE-2022-36004](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-36004))\n*   Fixes a `CHECK` fail in `RandomPoissonV2` ([CVE-2022-36003](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-36003))\n*   Fixes a `CHECK` fail in `Unbatch` ([CVE-2022-36002](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-36002))\n*   Fixes a `CHECK` fail in `DrawBoundingBoxes` ([CVE-2022-36001](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-36001))\n*   Fixes a `CHECK` fail in `Eig` ([CVE-2022-36000](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-36000))\n*   Fixes a null dereference on MLIR on empty function attributes ([CVE-2022-36011](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-36011))\n*   Fixes an assertion failure on MLIR empty edge names ([CVE-2022-36012](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-36012))\n*   Fixes a null-dereference in `mlir::tfg::GraphDefImporter::ConvertNodeDef` ([CVE-2022-36013](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-36013))\n*   Fixes a null-dereference in `mlir::tfg::TFOp::nameAttr` ([CVE-2022-36014](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-36014))\n*   Fixes an integer overflow in math ops ([CVE-2022-36015](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-36015))\n*   Fixes a `CHECK`-fail in `tensorflow::full_type::SubstituteFromAttrs` ([CVE-2022-36016](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-36016))\n*   Fixes an OOB read in `Gather_nd` op in TF Lite Micro ([CVE-2022-35938](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-35938))\n\n# Release 2.9.1\n\nAdd an upper bound for `protobuf` in `setup.py` since `protobuf` after version 3.20 is currently incompatible with TensorFlow. See https://github.com/tensorflow/tensorflow/issues/53234, https://github.com/protocolbuffers/protobuf/issues/9954 and https://github.com/tensorflow/tensorflow/issues/56077.\n\n# Release 2.8.2\n\nAdd an upper bound for `protobuf` in `setup.py` since `protobuf` after version 3.20 is currently incompatible with TensorFlow. See https://github.com/tensorflow/tensorflow/issues/53234, https://github.com/protocolbuffers/protobuf/issues/9954 and https://github.com/tensorflow/tensorflow/issues/56077.\n\n# Release 2.7.3\n\nAdd an upper bound for `protobuf` in `setup.py` since `protobuf` after version 3.20 is currently incompatible with TensorFlow. See https://github.com/tensorflow/tensorflow/issues/53234, https://github.com/protocolbuffers/protobuf/issues/9954 and https://github.com/tensorflow/tensorflow/issues/56077.\n\n# Release 2.6.5\n\nAdd an upper bound for `protobuf` in `setup.py` since `protobuf` after version 3.20 is currently incompatible with TensorFlow. See https://github.com/tensorflow/tensorflow/issues/53234, https://github.com/protocolbuffers/protobuf/issues/9954 and https://github.com/tensorflow/tensorflow/issues/56077.\n\n# Release 2.9.0\n\n## Breaking Changes\n\n*   Due to security issues in TF 2.8, all boosted trees code has now been removed (after being deprecated in TF 2.8). Users should switch to [TensorFlow Decision Forests](https://github.com/tensorflow/decision-forests).\n*   Build, Compilation and Packaging\n    * TensorFlow is now compiled with `_GLIBCXX_USE_CXX11_ABI=1`. Downstream projects that encounter `std::__cxx11` or `[abi:cxx11]` linker errors will need to adopt this compiler option. See [the GNU C++ Library docs on Dual ABI](https://gcc.gnu.org/onlinedocs/libstdc++/manual/using_dual_abi.html).\n    * TensorFlow Python wheels now specifically conform to [manylinux2014](https://peps.python.org/pep-0599/), an upgrade from manylinux2010. The minimum Pip version supporting manylinux2014 is Pip 19.3 (see [pypa/manylinux](https://github.com/pypa/manylinux). This change may affect you if you have been using TensorFlow on a very old platform equivalent to CentOS 6, as manylinux2014 targets CentOS 7 as a compatibility base. Note that TensorFlow does not officially support either platform.\n    * Discussion for these changes can be found on SIG Build's [TensorFlow Community Forum thread](https://discuss.tensorflow.org/t/tensorflow-linux-wheels-are-being-upgraded-to-manylinux2014/8339)\n*   The `tf.keras.mixed_precision.experimental` API has been removed. The non-experimental symbols under `tf.keras.mixed_precision` have been available since TensorFlow 2.4 and should be used instead.\n    * The non-experimental API has some minor differences from the experimental API. In most cases, you only need to make three minor changes:\n      * Remove the word \"experimental\" from `tf.keras.mixed_precision` symbols. E.g., replace `tf.keras.mixed_precision.experimental.global_policy` with `tf.keras.mixed_precision.global_policy`.\n      * Replace `tf.keras.mixed_precision.experimental.set_policy` with `tf.keras.mixed_precision.set_global_policy`. The experimental symbol `set_policy` was renamed to `set_global_policy` in the non-experimental API.\n      * Replace `LossScaleOptimizer(opt, \"dynamic\")` with `LossScaleOptimizer(opt)`. If you pass anything other than `\"dynamic\"` to the second argument, see (1) of the next section.\n    * In the following rare cases, you need to make more changes when switching to the non-experimental API:\n      * If you passed anything other than `\"dynamic\"` to the `loss_scale` argument (the second argument) of `LossScaleOptimizer`:\n          * The LossScaleOptimizer constructor takes in different arguments. See the [TF 2.7 documentation of tf.keras.mixed_precision.experimental.LossScaleOptimizer](https://www.tensorflow.org/versions/r2.7/api_docs/python/tf/keras/mixed_precision/experimental/LossScaleOptimizer) for details on the differences, which has examples on how to convert to the non-experimental LossScaleOptimizer.\n      * If you passed a value to the `loss_scale` argument (the second argument) of `Policy`:\n          * The experimental version of `Policy` optionally took in a `tf.compat.v1.mixed_precision.LossScale` in the constructor, which defaulted to a dynamic loss scale for the `\"mixed_float16\"` policy and no loss scale for other policies. In `Model.compile`, if the model's policy had a loss scale, the optimizer would be wrapped with a `LossScaleOptimizer`. With the non-experimental `Policy`, there is no loss scale associated with the `Policy`, and `Model.compile` wraps the optimizer with a `LossScaleOptimizer` if and only if the policy is a `\"mixed_float16\"` policy. If you previously passed a `LossScale` to the experimental `Policy`, consider just removing it, as the default loss scaling behavior is usually what you want. If you really want to customize the loss scaling behavior, you can wrap your optimizer with a `LossScaleOptimizer` before passing it to `Model.compile`.\n      * If you use the very rarely-used function `tf.keras.mixed_precision.experimental.get_layer_policy`:\n          * Replace `tf.keras.mixed_precision.experimental.get_layer_policy(layer)` with `layer.dtype_policy`.\n* `tf.mixed_precision.experimental.LossScale` and its subclasses have been removed from the TF2 namespace. This symbols were very rarely used and were only useful in TF2 for use in the now-removed `tf.keras.mixed_precision.experimental` API. The symbols are still available under `tf.compat.v1.mixed_precision`.\n* The `experimental_relax_shapes` heuristic for `tf.function` has been deprecated and replaced with `reduce_retracing` which encompasses broader heuristics to reduce the number of retraces (see below)\n\n## Major Features and Improvements\n\n*   `tf.keras`:\n\n    *   Added `tf.keras.applications.resnet_rs` models. This includes the\n        `ResNetRS50`, `ResNetRS101`, `ResNetRS152`, `ResNetRS200`,\n        `ResNetRS270`, `ResNetRS350` and `ResNetRS420` model architectures. The\n        ResNetRS models are based on the architecture described in\n        [Revisiting ResNets: Improved Training and Scaling Strategies](https://arxiv.org/pdf/2103.07579.pdf)\n    *   Added `tf.keras.optimizers.experimental.Optimizer`. The reworked\n        optimizer gives more control over different phases of optimizer calls,\n        and is easier to customize. We provide Adam, SGD, Adadelta, AdaGrad and\n        RMSprop optimizers based on\n        `tf.keras.optimizers.experimental.Optimizer`. Generally the new\n        optimizers work in the same way as the old ones, but support new\n        constructor arguments. In the future, the symbols\n        `tf.keras.optimizers.Optimizer`/`Adam`/etc will point to the new\n        optimizers, and the previous generation of optimizers will be moved to\n        `tf.keras.optimizers.legacy.Optimizer`/`Adam`/etc.\n    *   Added L2 unit normalization layer `tf.keras.layers.UnitNormalization`.\n    *   Added `tf.keras.regularizers.OrthogonalRegularizer`, a new regularizer\n        that encourages orthogonality between the rows (or columns) or a weight\n        matrix.\n    *   Added `tf.keras.layers.RandomBrightness` layer for image preprocessing.\n    *   Added APIs for switching between interactive logging and absl logging.\n        By default, Keras always writes the logs to stdout. However, this is not\n        optimal in a non-interactive environment, where you don't have access to\n        stdout, but can only view the logs. You can use\n        `tf.keras.utils.disable_interactive_logging()` to write the logs to ABSL\n        logging. You can also use `tf.keras.utils.enable_interactive_logging()`\n        to change it back to stdout, or\n        `tf.keras.utils.is_interactive_logging_enabled()` to check if\n        interactive logging is enabled.\n    *   Changed default value for the `verbose` argument of `Model.evaluate()`\n        and `Model.predict()` to `\"auto\"`, which defaults to `verbose=1` for\n        most cases and defaults to `verbose=2` when used with\n        `ParameterServerStrategy` or with interactive logging disabled.\n    *   Argument `jit_compile` in `Model.compile()` now applies to\n        `Model.evaluate()` and `Model.predict()`. Setting `jit_compile=True` in\n        `compile()` compiles the model's training, evaluation, and inference\n        steps to [XLA](https://www.tensorflow.org/xla). Note that\n        `jit_compile=True` may not necessarily work for all models.\n    *   Added DTensor-related Keras APIs under `tf.keras.dtensor` namespace. The\n        APIs are still classified as experimental. You are welcome to try it\n        out. Please check the tutorial and guide on https://www.tensorflow.org/\n        for more details about DTensor.\n\n*   `tf.lite`:\n\n    *   Added TFLite builtin op support for the following TF ops:\n        *   `tf.math.argmin`/`tf.math.argmax` for input data type `tf.bool` on\n            CPU.\n        *   `tf.nn.gelu` op for output data type `tf.float32` and quantization\n            on CPU.\n    *   Add nominal support for unsigned 16-bit integer tensor types. Note that\n        very few TFLite kernels support this type natively, so its use in mobile\n        ML authoring is generally discouraged.\n    *   Add support for unsigned 16-bit integer tensor types in cast op.\n    *   Experimental support for lowering `list_ops.tensor_list_set_item` with\n        `DynamicUpdateSlice`.\n    *   Enabled a new MLIR-based dynamic range quantization backend by default\n        *   The new backend is used for post-training int8 dynamic range\n            quantization and post-training float16 quantization.\n        *   Set `experimental_new_dynamic_range_quantizer` in\n            tf.lite.TFLiteConverter to False to disable this change\n    *   Native TF Lite variables are now enabled during conversion by default on\n        all v2 TfLiteConverter entry points.\n        `experimental_enable_resource_variables` on tf.lite.TFLiteConverter is\n        now True by default and will be removed in the future.\n\n*   `tf.function`:\n\n    *   Custom classes used as arguments for `tf.function` can now specify rules\n        regarding when retracing needs to occur by implementing the Tracing\n        Protocol available through\n        `tf.types.experimental.SupportsTracingProtocol`.\n    *   `TypeSpec` classes (as associated with `ExtensionTypes`) also implement\n        the Tracing Protocol which can be overridden if necessary.\n    *   The newly introduced `reduce_retracing` option also uses the Tracing\n        Protocol to proactively generate generalized traces similar to\n        `experimental_relax_shapes` (which has now been deprecated).\n\n*   Unified eager and `tf.function` execution:\n\n    *   Eager mode can now execute each op as a `tf.function`, allowing for more\n        consistent feature support in future releases.\n    *   It is available for immediate use.\n        *   See the `TF_RUN_EAGER_OP_AS_FUNCTION` environment variable in\n            [eager context](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/eager/context.py).\n        *   Eager performance should be similar with this feature enabled.\n            *   A roughly 5us per-op overhead may be observed when running many\n                small functions.\n            *   Note a\n                [known issue](https://github.com/tensorflow/tensorflow/issues/55414)\n                with GPU performance.\n        *   The behavior of `tf.function` itself is unaffected.\n    *   Note: This feature will be enabled by default in an upcoming version of\n        TensorFlow.\n\n*   `tf.experimental.dtensor`: Added DTensor, an extension to TensorFlow for\n    large-scale modeling with minimal changes to user code. You are welcome to\n    try it out, though be aware that the DTensor API is experimental and up-to\n    backward-incompatible changes. DTensor and Keras integration is published\n    under `tf.keras.dtensor` in this release (refer to the `tf.keras` entry).\n    The tutoral and guide for DTensor will be published on\n    https://www.tensorflow.org/. Please stay tuned.\n\n*   [oneDNN CPU performance optimizations](https://github.com/tensorflow/community/blob/master/rfcs/20210930-enable-onednn-ops.md)\n    are available in Linux x86, Windows x86, and Linux aarch64 packages.\n\n    *   **Linux x86 packages:**\n        *   oneDNN optimizations are *enabled by default* on CPUs with\n            neural-network-focused hardware features such as AVX512_VNNI,\n            AVX512_BF16, AMX, etc.\n            ([Intel Cascade Lake](https://www.intel.com/content/www/us/en/products/platforms/details/cascade-lake.html)\n            and newer CPUs.)\n            *   [Example performance speedups.](https://medium.com/intel-analytics-software/leverage-intel-deep-learning-optimizations-in-tensorflow-129faa80ee07)\n        *   For older CPUs, oneDNN optimizations are disabled by default.\n    *   **Windows x86 package:** oneDNN optimizations are disabled by default.\n    *   **Linux aach64 (`--config=mkl_aarch64`) package:**\n        *   Experimental oneDNN optimizations are disabled by default.\n        *   If you experience issues with oneDNN optimizations on, we recommend\n            turning them off.\n    *   To explicitly enable or disable oneDNN optimizations, set the\n        environment variable `TF_ENABLE_ONEDNN_OPTS` to `1` (enable) or `0`\n        (disable) before running TensorFlow. (The variable is checked during\n        `import tensorflow`.) To fall back to default settings, unset the\n        environment variable.\n    *   These optimizations can yield slightly different numerical results from\n        when they are off due to floating-point round-off errors from different\n        computation approaches and orders.\n    *   To verify that the optimizations are on, look for a message with\n        *\"oneDNN custom operations are on\"* in the log. If the exact phrase is\n        not there, it means they are off.\n\n## Bug Fixes and Other Changes\n\n*   `tf.data`:\n    *   Fixed bug in `tf.data.experimental.parse_example_dataset` when `tf.io.RaggedFeatures` would specify `value_key` but no `partitions`. Before the fix, setting `value_key` but no `partitions` would result in the feature key being replaced by the value key, e.g. `{'value_key': <RaggedTensor>}` instead of `{'key': <RaggedTensor>}`. Now the correct feature key will be used. This aligns the behavior of `tf.data.experimental.parse_example_dataset` to match the behavior of `tf.io.parse_example`.\n    *   Added a new field, `filter_parallelization`, to `tf.data.experimental.OptimizationOptions`. If it is set to `True`, tf.data will run `Filter` transformation with multiple threads. Its default value is `False` if not specified.\n\n*   `tf.keras`:\n    *   Fixed bug in optimizers that prevented them from properly checkpointing slot variables when they are `ShardedVariable`s (used for training with `tf.distribute.experimental.ParameterServerStrategy`).\n\n*   `tf.random`:\n    * Added `tf.random.experimental.index_shuffle`, for shuffling a sequence without materializing the sequence in memory.\n\n*   `tf.RaggedTensor`:\n    *   Introduced `tf.experimental.RowPartition`, which encodes how one dimension in a RaggedTensor relates to another, into the public API.\n    *   Introduced `tf.experimental.DynamicRaggedShape`, which represents the shape of a RaggedTensor.\n\n## Security\n\n*   Fixes a code injection in `saved_model_cli` ([CVE-2022-29216](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-29216))\n*   Fixes a missing validation which causes `TensorSummaryV2` to crash ([CVE-2022-29193](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-29193))\n*   Fixes a missing validation which crashes `QuantizeAndDequantizeV4Grad` ([CVE-2022-29192](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-29192))\n*   Fixes a missing validation which causes denial of service via `DeleteSessionTensor` ([CVE-2022-29194](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-29194))\n*   Fixes a missing validation which causes denial of service via `GetSessionTensor` ([CVE-2022-29191](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-29191))\n*   Fixes a missing validation which causes denial of service via `StagePeek` ([CVE-2022-29195](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-29195))\n*   Fixes a missing validation which causes denial of service via `UnsortedSegmentJoin` ([CVE-2022-29197](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-29197))\n*   Fixes a missing validation which causes denial of service via `LoadAndRemapMatrix` ([CVE-2022-29199](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-29199))\n*   Fixes a missing validation which causes denial of service via `SparseTensorToCSRSparseMatrix` ([CVE-2022-29198](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-29198))\n*   Fixes a missing validation which causes denial of service via `LSTMBlockCell` ([CVE-2022-29200](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-29200))\n*   Fixes a missing validation which causes denial of service via `Conv3DBackpropFilterV2` ([CVE-2022-29196](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-29196))\n*   Fixes a `CHECK` failure in depthwise ops via overflows ([CVE-2021-41197](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-41197))\n*   Fixes issues arising from undefined behavior stemming from users supplying invalid resource handles ([CVE-2022-29207](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-29207))\n*   Fixes a segfault due to missing support for quantized types ([CVE-2022-29205](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-29205))\n*   Fixes a missing validation which results in undefined behavior in `SparseTensorDenseAdd` ([CVE-2022-29206](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-29206))\n*   Fixes a missing validation which results in undefined behavior in `QuantizedConv2D` ([CVE-2022-29201](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-29201))\n*   Fixes an integer overflow in `SpaceToBatchND` ([CVE-2022-29203](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-29203))\n*   Fixes a segfault and OOB write due to incomplete validation in `EditDistance` ([CVE-2022-29208](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-29208))\n*   Fixes a missing validation which causes denial of service via `Conv3DBackpropFilterV2` ([CVE-2022-29204](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-29204))\n*   Fixes a denial of service in `tf.ragged.constant` due to lack of validation ([CVE-2022-29202](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-29202))\n*   Fixes a segfault when `tf.histogram_fixed_width` is called with NaN values ([CVE-2022-29211](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-29211))\n*   Fixes a core dump when loading TFLite models with quantization ([CVE-2022-29212](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-29212))\n*   Fixes crashes stemming from incomplete validation in signal ops ([CVE-2022-29213](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-29213))\n*   Fixes a type confusion leading to `CHECK`-failure based denial of service ([CVE-2022-29209](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-29209))\n*   Fixes a heap buffer overflow due to incorrect hash function ([CVE-2022-29210](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-29210))\n*   Updates `curl` to `7.83.1` to handle ([CVE-2022-22576](https://cve.mitre.org/cgi-bin/cvename.cgi?name=VE-2022-22576), ([CVE-2022-27774](https://cve.mitre.org/cgi-bin/cvename.cgi?name=VE-2022-27774), ([CVE-2022-27775](https://cve.mitre.org/cgi-bin/cvename.cgi?name=VE-2022-27775), ([CVE-2022-27776](https://cve.mitre.org/cgi-bin/cvename.cgi?name=VE-2022-27776), ([CVE-2022-27778](https://cve.mitre.org/cgi-bin/cvename.cgi?name=VE-2022-27778), ([CVE-2022-27779](https://cve.mitre.org/cgi-bin/cvename.cgi?name=VE-2022-27779), ([CVE-2022-27780](https://cve.mitre.org/cgi-bin/cvename.cgi?name=VE-2022-27780), ([CVE-2022-27781](https://cve.mitre.org/cgi-bin/cvename.cgi?name=VE-2022-27781), ([CVE-2022-27782](https://cve.mitre.org/cgi-bin/cvename.cgi?name=VE-2022-27782) and ([CVE-2022-30115](https://cve.mitre.org/cgi-bin/cvename.cgi?name=VE-2022-30115)\n*   Updates `zlib` to `1.2.12` after `1.2.11` was pulled due to [security issue](https://www.openwall.com/lists/oss-security/2022/03/28/1)\n\n## Thanks to our Contributors\n\nThis release contains contributions from many people at Google, as well as:\n\nAaron Debattista, Abel Soares Siqueira, Abhishek Varma, Andrei Ivanov, andreii, Andrew Goodbody, apeltop, Arnab Dutta, Ashiq Imran, Banikumar Maiti (Intel Aipg), Ben Greiner, Benjamin Peterson, bhack, Christopher Bate, chunduriv, Copybara-Service, DEKHTIARJonathan, Deven Desai, Duncan Riach, Eric Kunze, Everton Constantino, Faruk D, Fredrik Knutsson, gadagashwini, Gauri1 Deshpande, gtiHibGele, Guozhong Zhuang, Islem-Esi, Ivanov Viktor, Jason Furmanek, Jason Zaman, Jim, Jinzhe Zeng, John Laxson, Jonas Eschle, Jonas Eschle 'Mayou36, Jonathan Dekhtiar, Kaixi Hou, Kanvi Khanna, KaurkerDevourer, Koan-Sin Tan, kushanam, Laramie Leavitt, Li-Wen Chang, lipracer, Louis Sugy, Lu Teng, Mahmoud Abuzaina, Malcolm Slaney, Malik Shahzad Muzaffar, Marek uppa, Matt Conley, Michael Melesse, Milos Puzovic, mohantym, Nathan John Sircombe, Nathan Luehr, Nilesh Agarwalla, Patrice Vignola, peterjc123, Philip Turner, Rajeshwar Reddy T, Robert Kalmar, Rodrigo Formigone, Rohit Santhanam, rui, Sachin Muradi, Saduf2019, sandip, Scott Leishman, Serge Panev, Shi,Guangyong, Srinivasan Narayanamoorthy, stanley, Steven I Reeves, stevenireeves, sushreebarsa, Tamas Bela Feher, Tao He, Thomas Schmeyer, Tiago Almeida, Trevor Morris, Uday Bondhugula, Uwe L. Korn, Varghese, Jojimon, Vishnuvardhan Janapati, William Muir, William Raveane, xutianming, Yasuhiro Matsumoto, Yimei Sun, Yong Tang, Yu Feng, Yuriy Chernyshov, zhaozheng09\n\n# Release 2.8.1\n\nThis releases introduces several vulnerability fixes:\n\n*   Fixes a code injection in `saved_model_cli` ([CVE-2022-29216](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-29216))\n*   Fixes a missing validation which causes `TensorSummaryV2` to crash ([CVE-2022-29193](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-29193))\n*   Fixes a missing validation which crashes `QuantizeAndDequantizeV4Grad` ([CVE-2022-29192](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-29192))\n*   Fixes a missing validation which causes denial of service via `DeleteSessionTensor` ([CVE-2022-29194](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-29194))\n*   Fixes a missing validation which causes denial of service via `GetSessionTensor` ([CVE-2022-29191](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-29191))\n*   Fixes a missing validation which causes denial of service via `StagePeek` ([CVE-2022-29195](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-29195))\n*   Fixes a missing validation which causes denial of service via `UnsortedSegmentJoin` ([CVE-2022-29197](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-29197))\n*   Fixes a missing validation which causes denial of service via `LoadAndRemapMatrix` ([CVE-2022-29199](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-29199))\n*   Fixes a missing validation which causes denial of service via `SparseTensorToCSRSparseMatrix` ([CVE-2022-29198](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-29198))\n*   Fixes a missing validation which causes denial of service via `LSTMBlockCell` ([CVE-2022-29200](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-29200))\n*   Fixes a missing validation which causes denial of service via `Conv3DBackpropFilterV2` ([CVE-2022-29196](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-29196))\n*   Fixes a `CHECK` failure in depthwise ops via overflows ([CVE-2021-41197](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-41197))\n*   Fixes issues arising from undefined behavior stemming from users supplying invalid resource handles ([CVE-2022-29207](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-29207))\n*   Fixes a segfault due to missing support for quantized types ([CVE-2022-29205](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-29205))\n*   Fixes a missing validation which results in undefined behavior in `SparseTensorDenseAdd` ([CVE-2022-29206](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-29206))\n*   Fixes a missing validation which results in undefined behavior in `QuantizedConv2D` ([CVE-2022-29201](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-29201))\n*   Fixes an integer overflow in `SpaceToBatchND` ([CVE-2022-29203](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-29203))\n*   Fixes a segfault and OOB write due to incomplete validation in `EditDistance` ([CVE-2022-29208](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-29208))\n*   Fixes a missing validation which causes denial of service via `Conv3DBackpropFilterV2` ([CVE-2022-29204](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-29204))\n*   Fixes a denial of service in `tf.ragged.constant` due to lack of validation ([CVE-2022-29202](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-29202))\n*   Fixes a segfault when `tf.histogram_fixed_width` is called with NaN values ([CVE-2022-29211](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-29211))\n*   Fixes a core dump when loading TFLite models with quantization ([CVE-2022-29212](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-29212))\n*   Fixes crashes stemming from incomplete validation in signal ops ([CVE-2022-29213](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-29213))\n*   Fixes a type confusion leading to `CHECK`-failure based denial of service ([CVE-2022-29209](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-29209))\n*   Fixes a heap buffer overflow due to incorrect hash function ([CVE-2022-29210](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-29210))\n*   Updates `curl` to `7.83.1` to handle ([CVE-2022-22576](https://cve.mitre.org/cgi-bin/cvename.cgi?name=VE-2022-22576), ([CVE-2022-27774](https://cve.mitre.org/cgi-bin/cvename.cgi?name=VE-2022-27774), ([CVE-2022-27775](https://cve.mitre.org/cgi-bin/cvename.cgi?name=VE-2022-27775), ([CVE-2022-27776](https://cve.mitre.org/cgi-bin/cvename.cgi?name=VE-2022-27776), ([CVE-2022-27778](https://cve.mitre.org/cgi-bin/cvename.cgi?name=VE-2022-27778), ([CVE-2022-27779](https://cve.mitre.org/cgi-bin/cvename.cgi?name=VE-2022-27779), ([CVE-2022-27780](https://cve.mitre.org/cgi-bin/cvename.cgi?name=VE-2022-27780), ([CVE-2022-27781](https://cve.mitre.org/cgi-bin/cvename.cgi?name=VE-2022-27781), ([CVE-2022-27782](https://cve.mitre.org/cgi-bin/cvename.cgi?name=VE-2022-27782) and ([CVE-2022-30115](https://cve.mitre.org/cgi-bin/cvename.cgi?name=VE-2022-30115)\n*   Updates `zlib` to `1.2.12` after `1.2.11` was pulled due to [security issue](https://www.openwall.com/lists/oss-security/2022/03/28/1)\n# Release 2.7.2\n\nThis releases introduces several vulnerability fixes:\n\n*   Fixes a code injection in `saved_model_cli` ([CVE-2022-29216](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-29216))\n*   Fixes a missing validation which causes `TensorSummaryV2` to crash ([CVE-2022-29193](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-29193))\n*   Fixes a missing validation which crashes `QuantizeAndDequantizeV4Grad` ([CVE-2022-29192](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-29192))\n*   Fixes a missing validation which causes denial of service via `DeleteSessionTensor` ([CVE-2022-29194](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-29194))\n*   Fixes a missing validation which causes denial of service via `GetSessionTensor` ([CVE-2022-29191](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-29191))\n*   Fixes a missing validation which causes denial of service via `StagePeek` ([CVE-2022-29195](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-29195))\n*   Fixes a missing validation which causes denial of service via `UnsortedSegmentJoin` ([CVE-2022-29197](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-29197))\n*   Fixes a missing validation which causes denial of service via `LoadAndRemapMatrix` ([CVE-2022-29199](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-29199))\n*   Fixes a missing validation which causes denial of service via `SparseTensorToCSRSparseMatrix` ([CVE-2022-29198](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-29198))\n*   Fixes a missing validation which causes denial of service via `LSTMBlockCell` ([CVE-2022-29200](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-29200))\n*   Fixes a missing validation which causes denial of service via `Conv3DBackpropFilterV2` ([CVE-2022-29196](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-29196))\n*   Fixes a `CHECK` failure in depthwise ops via overflows ([CVE-2021-41197](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-41197))\n*   Fixes issues arising from undefined behavior stemming from users supplying invalid resource handles ([CVE-2022-29207](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-29207))\n*   Fixes a segfault due to missing support for quantized types ([CVE-2022-29205](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-29205))\n*   Fixes a missing validation which results in undefined behavior in `SparseTensorDenseAdd` ([CVE-2022-29206](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-29206))\n*   Fixes a missing validation which results in undefined behavior in `QuantizedConv2D` ([CVE-2022-29201](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-29201))\n*   Fixes an integer overflow in `SpaceToBatchND` ([CVE-2022-29203](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-29203))\n*   Fixes a segfault and OOB write due to incomplete validation in `EditDistance` ([CVE-2022-29208](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-29208))\n*   Fixes a missing validation which causes denial of service via `Conv3DBackpropFilterV2` ([CVE-2022-29204](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-29204))\n*   Fixes a denial of service in `tf.ragged.constant` due to lack of validation ([CVE-2022-29202](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-29202))\n*   Fixes a segfault when `tf.histogram_fixed_width` is called with NaN values ([CVE-2022-29211](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-29211))\n*   Fixes a core dump when loading TFLite models with quantization ([CVE-2022-29212](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-29212))\n*   Fixes crashes stemming from incomplete validation in signal ops ([CVE-2022-29213](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-29213))\n*   Fixes a type confusion leading to `CHECK`-failure based denial of service ([CVE-2022-29209](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-29209))\n*   Updates `curl` to `7.83.1` to handle ([CVE-2022-22576](https://cve.mitre.org/cgi-bin/cvename.cgi?name=VE-2022-22576), ([CVE-2022-27774](https://cve.mitre.org/cgi-bin/cvename.cgi?name=VE-2022-27774), ([CVE-2022-27775](https://cve.mitre.org/cgi-bin/cvename.cgi?name=VE-2022-27775), ([CVE-2022-27776](https://cve.mitre.org/cgi-bin/cvename.cgi?name=VE-2022-27776), ([CVE-2022-27778](https://cve.mitre.org/cgi-bin/cvename.cgi?name=VE-2022-27778), ([CVE-2022-27779](https://cve.mitre.org/cgi-bin/cvename.cgi?name=VE-2022-27779), ([CVE-2022-27780](https://cve.mitre.org/cgi-bin/cvename.cgi?name=VE-2022-27780), ([CVE-2022-27781](https://cve.mitre.org/cgi-bin/cvename.cgi?name=VE-2022-27781), ([CVE-2022-27782](https://cve.mitre.org/cgi-bin/cvename.cgi?name=VE-2022-27782) and ([CVE-2022-30115](https://cve.mitre.org/cgi-bin/cvename.cgi?name=VE-2022-30115)\n*   Updates `zlib` to `1.2.12` after `1.2.11` was pulled due to [security issue](https://www.openwall.com/lists/oss-security/2022/03/28/1)\n\n# Release 2.6.4\n\nThis releases introduces several vulnerability fixes:\n\n*   Fixes a code injection in `saved_model_cli` ([CVE-2022-29216](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-29216))\n*   Fixes a missing validation which causes `TensorSummaryV2` to crash ([CVE-2022-29193](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-29193))\n*   Fixes a missing validation which crashes `QuantizeAndDequantizeV4Grad` ([CVE-2022-29192](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-29192))\n*   Fixes a missing validation which causes denial of service via `DeleteSessionTensor` ([CVE-2022-29194](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-29194))\n*   Fixes a missing validation which causes denial of service via `GetSessionTensor` ([CVE-2022-29191](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-29191))\n*   Fixes a missing validation which causes denial of service via `StagePeek` ([CVE-2022-29195](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-29195))\n*   Fixes a missing validation which causes denial of service via `UnsortedSegmentJoin` ([CVE-2022-29197](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-29197))\n*   Fixes a missing validation which causes denial of service via `LoadAndRemapMatrix` ([CVE-2022-29199](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-29199))\n*   Fixes a missing validation which causes denial of service via `SparseTensorToCSRSparseMatrix` ([CVE-2022-29198](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-29198))\n*   Fixes a missing validation which causes denial of service via `LSTMBlockCell` ([CVE-2022-29200](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-29200))\n*   Fixes a missing validation which causes denial of service via `Conv3DBackpropFilterV2` ([CVE-2022-29196](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-29196))\n*   Fixes a `CHECK` failure in depthwise ops via overflows ([CVE-2021-41197](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-41197))\n*   Fixes issues arising from undefined behavior stemming from users supplying invalid resource handles ([CVE-2022-29207](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-29207))\n*   Fixes a segfault due to missing support for quantized types ([CVE-2022-29205](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-29205))\n*   Fixes a missing validation which results in undefined behavior in `SparseTensorDenseAdd` ([CVE-2022-29206](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-29206))\n*   Fixes a missing validation which results in undefined behavior in `QuantizedConv2D` ([CVE-2022-29201](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-29201))\n*   Fixes an integer overflow in `SpaceToBatchND` ([CVE-2022-29203](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-29203))\n*   Fixes a segfault and OOB write due to incomplete validation in `EditDistance` ([CVE-2022-29208](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-29208))\n*   Fixes a missing validation which causes denial of service via `Conv3DBackpropFilterV2` ([CVE-2022-29204](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-29204))\n*   Fixes a denial of service in `tf.ragged.constant` due to lack of validation ([CVE-2022-29202](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-29202))\n*   Fixes a segfault when `tf.histogram_fixed_width` is called with NaN values ([CVE-2022-29211](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-29211))\n*   Fixes a core dump when loading TFLite models with quantization ([CVE-2022-29212](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-29212))\n*   Fixes crashes stemming from incomplete validation in signal ops ([CVE-2022-29213](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-29213))\n*   Fixes a type confusion leading to `CHECK`-failure based denial of service ([CVE-2022-29209](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-29209))\n*   Updates `curl` to `7.83.1` to handle ([CVE-2022-22576](https://cve.mitre.org/cgi-bin/cvename.cgi?name=VE-2022-22576), ([CVE-2022-27774](https://cve.mitre.org/cgi-bin/cvename.cgi?name=VE-2022-27774), ([CVE-2022-27775](https://cve.mitre.org/cgi-bin/cvename.cgi?name=VE-2022-27775), ([CVE-2022-27776](https://cve.mitre.org/cgi-bin/cvename.cgi?name=VE-2022-27776), ([CVE-2022-27778](https://cve.mitre.org/cgi-bin/cvename.cgi?name=VE-2022-27778), ([CVE-2022-27779](https://cve.mitre.org/cgi-bin/cvename.cgi?name=VE-2022-27779), ([CVE-2022-27780](https://cve.mitre.org/cgi-bin/cvename.cgi?name=VE-2022-27780), ([CVE-2022-27781](https://cve.mitre.org/cgi-bin/cvename.cgi?name=VE-2022-27781), ([CVE-2022-27782](https://cve.mitre.org/cgi-bin/cvename.cgi?name=VE-2022-27782) and ([CVE-2022-30115](https://cve.mitre.org/cgi-bin/cvename.cgi?name=VE-2022-30115)\n*   Updates `zlib` to `1.2.12` after `1.2.11` was pulled due to [security issue](https://www.openwall.com/lists/oss-security/2022/03/28/1)\n\n# Release 2.8.0\n\n## Major Features and Improvements\n\n*   `tf.lite`:\n\n    *   Added TFLite builtin op support for the following TF ops:\n        *   `tf.raw_ops.Bucketize` op on CPU.\n        *   `tf.where` op for data types\n            `tf.int32`/`tf.uint32`/`tf.int8`/`tf.uint8`/`tf.int64`.\n        *   `tf.random.normal` op for output data type `tf.float32` on CPU.\n        *   `tf.random.uniform` op for output data type `tf.float32` on CPU.\n        *   `tf.random.categorical` op for output data type `tf.int64` on CPU.\n\n*   `tensorflow.experimental.tensorrt`:\n\n    *   `conversion_params` is now deprecated inside `TrtGraphConverterV2` in\n        favor of direct arguments: `max_workspace_size_bytes`, `precision_mode`,\n        `minimum_segment_size`, `maximum_cached_engines`, `use_calibration` and\n        `allow_build_at_runtime`.\n    *   Added a new parameter called `save_gpu_specific_engines` to the\n        `.save()` function inside `TrtGraphConverterV2`. When `False`, the\n        `.save()` function won't save any TRT engines that have been built. When\n        `True` (default), the original behavior is preserved.\n    *   `TrtGraphConverterV2` provides a new API called `.summary()` which\n        outputs a summary of the inference converted by TF-TRT. It namely shows\n        each `TRTEngineOp` with their input(s)' and output(s)' shape and dtype.\n        A detailed version of the summary is available which prints additionally\n        all the TensorFlow OPs included in each of the `TRTEngineOp`s.\n\n*   `tf.tpu.experimental.embedding`:\n\n    *   `tf.tpu.experimental.embedding.FeatureConfig` now takes an additional\n        argument `output_shape` which can specify the shape of the output\n        activation for the feature.\n    *   `tf.tpu.experimental.embedding.TPUEmbedding` now has the same behavior\n        as `tf.tpu.experimental.embedding.serving_embedding_lookup` which can\n        take arbitrary rank of dense and sparse tensor. For ragged tensor,\n        though the input tensor remains to be rank 2, the activations now can be\n        rank 2 or above by specifying the output shape in the feature config or\n        via the build method.\n\n*   Add\n    [`tf.config.experimental.enable_op_determinism`](https://www.tensorflow.org/api_docs/python/tf/config/experimental/enable_op_determinism),\n    which makes TensorFlow ops run deterministically at the cost of performance.\n    Replaces the `TF_DETERMINISTIC_OPS` environmental variable, which is now\n    deprecated. The \"Bug Fixes and Other Changes\" section lists more\n    determinism-related changes.\n\n*   (Since TF 2.7) Add\n    [PluggableDevice](https://blog.tensorflow.org/2021/06/pluggabledevice-device-plugins-for-TensorFlow.html)\n    support to\n    [TensorFlow Profiler](https://github.com/tensorflow/community/blob/master/rfcs/20210513-pluggable-profiler-for-tensorflow.md).\n\n## Bug Fixes and Other Changes\n\n*   `tf.data`:\n\n    *   Fixed a bug where setting `options.deterministic = False` would only\n        modify one transformation to run non-deterministically, leaving other\n        transformations deterministic. The option will now apply the same across\n        all transformations.\n    *   The optimization `parallel_batch` now becomes default if not disabled by\n        users, which will parallelize copying of batch elements.\n    *   Added the ability for `TensorSliceDataset` to identify and handle inputs\n        that are files. This enables creating hermetic SavedModels when using\n        datasets created from files.\n\n*   `tf.lite`:\n\n    *   Adds GPU Delegation support for serialization to Java API. This boosts\n        initialization time up to 90% when OpenCL is available.\n    *   Deprecated `Interpreter::SetNumThreads`, in favor of\n        `InterpreterBuilder::SetNumThreads`.\n\n*   `tf.keras`:\n\n    *   Adds `tf.compat.v1.keras.utils.get_or_create_layer` to aid migration to\n        TF2 by enabling tracking of nested keras models created in TF1-style,\n        when used with the `tf.compat.v1.keras.utils.track_tf1_style_variables`\n        decorator.\n    *   Added a `tf.keras.layers.experimental.preprocessing.HashedCrossing`\n        layer which applies the hashing trick to the concatenation of crossed\n        scalar inputs. This provides a stateless way to try adding feature\n        crosses of integer or string data to a model.\n    *   Removed `keras.layers.experimental.preprocessing.CategoryCrossing`.\n        Users should migrate to the `HashedCrossing` layer or use\n        `tf.sparse.cross`/`tf.ragged.cross` directly.\n    *   Added additional `standardize` and `split` modes to `TextVectorization`:\n        *   `standardize=\"lower\"` will lowercase inputs.\n        *   `standardize=\"string_punctuation\"` will remove all punctuation.\n        *   `split=\"character\"` will split on every unicode character.\n    *   Added an `output_mode` argument to the `Discretization` and `Hashing`\n        layers with the same semantics as other preprocessing layers. All\n        categorical preprocessing layers now support `output_mode`.\n    *   All preprocessing layer output will follow the compute dtype of a\n        `tf.keras.mixed_precision.Policy`, unless constructed with\n        `output_mode=\"int\"` in which case output will be `tf.int64`. The output\n        type of any preprocessing layer can be controlled individually by\n        passing a `dtype` argument to the layer.\n    *   `tf.random.Generator` for keras initializers and all RNG code.\n    *   Added 3 new APIs for enable/disable/check the usage of\n        `tf.random.Generator` in keras backend, which will be the new backend\n        for all the RNG in Keras. We plan to switch on the new code path by\n        default in tf 2.8, and the behavior change will likely to cause some\n        breakage on user side (eg if the test is checking against some golden\n        number). These 3 APIs will allow user to disable and switch back to\n        legacy behavior if they prefer. In future (eg TF 2.10), we expect to\n        totally remove the legacy code path (stateful random Ops), and these 3\n        APIs will be removed as well.\n    *   `tf.keras.callbacks.experimental.BackupAndRestore` is now available as\n        `tf.keras.callbacks.BackupAndRestore`. The experimental endpoint is\n        deprecated and will be removed in a future release.\n    *   `tf.keras.experimental.SidecarEvaluator` is now available as\n        `tf.keras.utils.SidecarEvaluator`. The experimental endpoint is\n        deprecated and will be removed in a future release.\n    *   Metrics update and collection logic in default `Model.train_step()` is\n        now customizable via overriding `Model.compute_metrics()`.\n    *   Losses computation logic in default `Model.train_step()` is now\n        customizable via overriding `Model.compute_loss()`.\n    *   `jit_compile` added to `Model.compile()` on an opt-in basis to compile\n        the model's training step with [XLA](https://www.tensorflow.org/xla).\n        Note that `jit_compile=True` may not necessarily work for all models.\n\n*   Deterministic Op Functionality:\n\n    *   Fix regression in deterministic selection of deterministic cuDNN\n        convolution algorithms, a regression that was introduced in v2.5. Note\n        that nondeterministic out-of-memory events while selecting algorithms\n        could still lead to nondeterminism, although this is very unlikely. This\n        additional, unlikely source will be eliminated in a later version.\n    *   Add deterministic GPU implementations of:\n        *   `tf.function(jit_compile=True)`'s that use `Scatter`.\n        *   (since v2.7) Stateful ops used in `tf.data.Dataset`\n        *   (since v2.7) `tf.convert_to_tensor` when fed with (sparse)\n            `tf.IndexedSlices` (because it uses `tf.math.unsorted_segment_sum`)\n        *   (since v2.7) `tf.gather` backprop (because `tf.convert_to_tensor`\n            reduces `tf.gather`'s (sparse) `tf.IndexedSlices` gradients into its\n            dense `params` input)\n        *   (since v2.7) `tf.math.segment_mean`\n        *   (since v2.7) `tf.math.segment_prod`\n        *   (since v2.7) `tf.math.segment_sum`\n        *   (since v2.7) `tf.math.unsorted_segment_mean`\n        *   (since v2.7) `tf.math.unsorted_segment_prod`\n        *   (since v2.7) `tf.math.unsorted_segment_sum`\n        *   (since v2.7) `tf.math.unsorted_segment_sqrt`\n        *   (since v2.7) `tf.nn.ctc_loss` (resolved, possibly in prior release,\n            and confirmed with tests)\n        *   (since v2.7)`tf.nn.sparse_softmax_crossentropy_with_logits`\n    *   (since v2.7) Run `tf.scatter_nd` and other related scatter functions,\n        such as `tf.tensor_scatter_nd_update`, on CPU (with significant\n        performance penalty).\n    *   Add determinism-unimplemented exception-throwing to the following ops.\n        When op-determinism is expected (i.e. after\n        `tf.config.experimental.enable_op_determinism` has been called), an\n        attempt to use the specified paths through the following ops on a GPU\n        will cause `tf.errors.UnimplementedError` (with an understandable\n        message), unless otherwise specified, to be thrown.\n        *   `FakeQuantWithMinMaxVarsGradient` and\n            `FakeQuantWithMinMaxVarsPerChannelGradient`\n        *   (since v2.7) `tf.compat.v1.get_seed` if the global random seed has\n            not yet been set (via `tf.random.set_seed`). Throws `RuntimeError`\n            from Python or `InvalidArgument` from C++\n        *   (since v2.7) `tf.compat.v1.nn.fused_batch_norm` backprop to `offset`\n            when `is_training=False`\n        *   (since v2.7) `tf.image.adjust_contrast` forward\n        *   (since v2.7) `tf.image.resize` with `method=ResizeMethod.NEAREST`\n            backprop\n        *   (since v2.7) `tf.linalg.svd`\n        *   (since v2.7) `tf.math.bincount`\n        *   (since v2.7) `tf.nn.depthwise_conv2d` backprop to `filter` when not\n            using cuDNN convolution\n        *   (since v2.7) `tf.nn.dilation2d` gradient\n        *   (since v2.7) `tf.nn.max_pool_with_argmax` gradient\n        *   (since v2.7) `tf.raw_ops.DebugNumericSummary` and\n            `tf.raw_ops.DebugNumericSummaryV2`\n        *   (since v2.7) `tf.timestamp`. Throws `FailedPrecondition`\n        *   (since v2.7) `tf.Variable.scatter_add` (and other scatter methods,\n            both on ref and resource variables)\n        *   (since v2.7) The random-number-generating ops in the `tf.random`\n            module when the global random seed has not yet been set (via\n            `tf.random.set_seed`). Throws `RuntimeError` from Python or\n            `InvalidArgument` from C++\n\n*   TensorFlow-oneDNN no longer supports\n    [explicit use of oneDNN blocked tensor format](https://github.com/tensorflow/tensorflow/pull/53288),\n    e.g., setting the environment variable `TF_ENABLE_MKL_NATIVE_FORMAT` will\n    not have any effect.\n\n*   TensorFlow has been validated on Windows Subsystem for Linux 2 (aka WSL 2)\n    for both GPUs and CPUs.\n\n*   Due to security issues (see section below), all boosted trees code has been\n    deprecated. Users should switch to\n    [TensorFlow Decision Forests](https://github.com/tensorflow/decision-forests).\n    TF's boosted trees code will be eliminated before the branch cut for TF 2.9\n    and will no longer be present since that release.\n\n## Security\n\n*   Fixes a floating point division by 0 when executing convolution operators\n    ([CVE-2022-21725](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-21725))\n*   Fixes a heap OOB read in shape inference for `ReverseSequence`\n    ([CVE-2022-21728](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-21728))\n*   Fixes a heap OOB access in `Dequantize`\n    ([CVE-2022-21726](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-21726))\n*   Fixes an integer overflow in shape inference for `Dequantize`\n    ([CVE-2022-21727](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-21727))\n*   Fixes a heap OOB access in `FractionalAvgPoolGrad`\n    ([CVE-2022-21730](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-21730))\n*   Fixes an overflow and divide by zero in `UnravelIndex`\n    ([CVE-2022-21729](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-21729))\n*   Fixes a type confusion in shape inference for `ConcatV2`\n    ([CVE-2022-21731](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-21731))\n*   Fixes an OOM in `ThreadPoolHandle`\n    ([CVE-2022-21732](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-21732))\n*   Fixes an OOM due to integer overflow in `StringNGrams`\n    ([CVE-2022-21733](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-21733))\n*   Fixes more issues caused by incomplete validation in boosted trees code\n    ([CVE-2021-41208](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-41208))\n*   Fixes an integer overflows in most sparse component-wise ops\n    ([CVE-2022-23567](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-23567))\n*   Fixes an integer overflows in `AddManySparseToTensorsMap`\n    ([CVE-2022-23568](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-23568))\n*   Fixes a number of `CHECK`-failures in `MapStage`\n    ([CVE-2022-21734](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-21734))\n*   Fixes a division by zero in `FractionalMaxPool`\n    ([CVE-2022-21735](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-21735))\n*   Fixes a number of `CHECK`-fails when building invalid/overflowing tensor\n    shapes\n    ([CVE-2022-23569](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-23569))\n*   Fixes an undefined behavior in `SparseTensorSliceDataset`\n    ([CVE-2022-21736](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-21736))\n*   Fixes an assertion failure based denial of service via faulty bin count\n    operations\n    ([CVE-2022-21737](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-21737))\n*   Fixes a reference binding to null pointer in `QuantizedMaxPool`\n    ([CVE-2022-21739](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-21739))\n*   Fixes an integer overflow leading to crash in `SparseCountSparseOutput`\n    ([CVE-2022-21738](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-21738))\n*   Fixes a heap overflow in `SparseCountSparseOutput`\n    ([CVE-2022-21740](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-21740))\n*   Fixes an FPE in `BiasAndClamp` in TFLite\n    ([CVE-2022-23557](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-23557))\n*   Fixes an FPE in depthwise convolutions in TFLite\n    ([CVE-2022-21741](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-21741))\n*   Fixes an integer overflow in TFLite array creation\n    ([CVE-2022-23558](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-23558))\n*   Fixes an integer overflow in TFLite\n    ([CVE-2022-23559](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-23559))\n*   Fixes a dangerous OOB write in TFLite\n    ([CVE-2022-23561](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-23561))\n*   Fixes a vulnerability leading to read and write outside of bounds in TFLite\n    ([CVE-2022-23560](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-23560))\n*   Fixes a set of vulnerabilities caused by using insecure temporary files\n    ([CVE-2022-23563](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-23563))\n*   Fixes an integer overflow in Range resulting in undefined behavior and OOM\n    ([CVE-2022-23562](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-23562))\n*   Fixes a vulnerability where missing validation causes `tf.sparse.split` to\n    crash when `axis` is a tuple\n    ([CVE-2021-41206](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-41206))\n*   Fixes a `CHECK`-fail when decoding resource handles from proto\n    ([CVE-2022-23564](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-23564))\n*   Fixes a `CHECK`-fail with repeated `AttrDef`\n    ([CVE-2022-23565](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-23565))\n*   Fixes a heap OOB write in Grappler\n    ([CVE-2022-23566](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-23566))\n*   Fixes a `CHECK`-fail when decoding invalid tensors from proto\n    ([CVE-2022-23571](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-23571))\n*   Fixes a null-dereference when specializing tensor type\n    ([CVE-2022-23570](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-23570))\n*   Fixes a crash when type cannot be specialized\n    ([CVE-2022-23572](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-23572))\n*   Fixes a heap OOB read/write in `SpecializeType`\n    ([CVE-2022-23574](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-23574))\n*   Fixes an uninitialized variable access in `AssignOp`\n    ([CVE-2022-23573](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-23573))\n*   Fixes an integer overflow in `OpLevelCostEstimator::CalculateTensorSize`\n    ([CVE-2022-23575](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-23575))\n*   Fixes an integer overflow in `OpLevelCostEstimator::CalculateOutputSize`\n    ([CVE-2022-23576](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-23576))\n*   Fixes a null dereference in `GetInitOp`\n    ([CVE-2022-23577](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-23577))\n*   Fixes a memory leak when a graph node is invalid\n    ([CVE-2022-23578](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-23578))\n*   Fixes an abort caused by allocating a vector that is too large\n    ([CVE-2022-23580](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-23580))\n*   Fixes multiple `CHECK`-failures during Grappler's `IsSimplifiableReshape`\n    ([CVE-2022-23581](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-23581))\n*   Fixes multiple `CHECK`-failures during Grappler's `SafeToRemoveIdentity`\n    ([CVE-2022-23579](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-23579))\n*   Fixes multiple `CHECK`-failures in `TensorByteSize`\n    ([CVE-2022-23582](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-23582))\n*   Fixes multiple `CHECK`-failures in binary ops due to type confusion\n    ([CVE-2022-23583](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-23583))\n*   Fixes a use after free in `DecodePng` kernel\n    ([CVE-2022-23584](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-23584))\n*   Fixes a memory leak in decoding PNG images\n    ([CVE-2022-23585](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-23585))\n*   Fixes multiple `CHECK`-fails in `function.cc`\n    ([CVE-2022-23586](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-23586))\n*   Fixes multiple `CHECK`-fails due to attempting to build a reference tensor\n    ([CVE-2022-23588](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-23588))\n*   Fixes an integer overflow in Grappler cost estimation of crop and resize\n    operation\n    ([CVE-2022-23587](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-23587))\n*   Fixes a null pointer dereference in Grappler's `IsConstant`\n    ([CVE-2022-23589](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-23589))\n*   Fixes a `CHECK` failure in constant folding\n    ([CVE-2021-41197](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-41197))\n*   Fixes a stack overflow due to self-recursive function in `GraphDef`\n    ([CVE-2022-23591](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-23591))\n*   Fixes a heap OOB access in `RunForwardTypeInference`\n    ([CVE-2022-23592](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-23592))\n*   Fixes a crash due to erroneous `StatusOr`\n    ([CVE-2022-23590](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-23590))\n*   Fixes multiple crashes and heap OOB accesses in TFG dialect (MLIR)\n    ([CVE-2022-23594](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-23594))\n*   Fixes a segfault in `simplifyBroadcast` (MLIR)\n    ([CVE-2022-23593](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-23593))\n*   Fixes a null pointer dereference in `BuildXlaCompilationCache` (XLA)\n    ([CVE-2022-23595](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-23595))\n*   Updates `icu` to `69.1` to handle\n    [CVE-2020-10531](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2020-10531)\n\n## Thanks to our Contributors\n\nThis release contains contributions from many people at Google, as well as:\n\n8bitmp3, Adam Lanicek, ag.ramesh, alesapin, Andrew Goodbody, annasuheyla, Ariel\nElkin, Arnab Dutta, Ben Barsdell, bhack, cfRod, Chengji Yao, Christopher Bate,\ndan, Dan F-M, David Korczynski, DEKHTIARJonathan, dengzhiyuan, Deven Desai,\nDuncan Riach, Eli Osherovich, Ewout Ter Hoeven, ez2take, Faijul Amin, fo40225,\nFrederic Bastien, gadagashwini, Gauri1 Deshpande, Georgiy Manuilov, Guilherme De\nLzari, Guozhong Zhuang, H1Gdev, homuler, Hongxu Jia, Jacky_Yin, jayfurmanek,\njgehw, Jhalak Patel, Jinzhe Zeng, Johan Gunnarsson, Jonathan Dekhtiar, Kaixi\nHou, Kanvi Khanna, Kevin Cheng, Koan-Sin Tan, Kruglov-Dmitry, Kun Lu, Lemo,\nLequn Chen, long.chen, Louis Sugy, Mahmoud Abuzaina, Mao, Marius Brehler, Mark\nHarfouche, Martin Patz, Maxiwell S. Garcia, Meenakshi Venkataraman, Michael\nMelesse, Mrinal Tyagi, Mns Nilsson, Nathan John Sircombe, Nathan Luehr, Nilesh\nAgarwalla, Oktay Ozturk, Patrice Vignola, Pawel-Polyai, Rama Ketineni, Ramesh\nSampath, Reza Rahimi, Rob Suderman, Robert Kalmar, Rohit Santhanam, Sachin\nMuradi, Saduf2019, Samuel Marks, Shi,Guangyong, Sidong-Wei, Srinivasan\nNarayanamoorthy, Srishti Srivastava, Steven I Reeves, stevenireeves, Supernovae,\nTamas Bela Feher, Tao Xu, Thibaut Goetghebuer-Planchon, Thomas Schmeyer,\ntilakrayal, Valery Mironov, Victor Guo, Vignesh Kothapalli, Vishnuvardhan\nJanapati, wamuir, Wang,Quintin, William Muir, William Raveane, Yash Goel, Yimei\nSun, Yong Tang, Yuduo Wu\n\n# Release 2.7.1\n\nThis releases introduces several vulnerability fixes:\n\n*   Fixes a floating point division by 0 when executing convolution operators\n    ([CVE-2022-21725](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-21725))\n*   Fixes a heap OOB read in shape inference for `ReverseSequence`\n    ([CVE-2022-21728](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-21728))\n*   Fixes a heap OOB access in `Dequantize`\n    ([CVE-2022-21726](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-21726))\n*   Fixes an integer overflow in shape inference for `Dequantize`\n    ([CVE-2022-21727](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-21727))\n*   Fixes a heap OOB access in `FractionalAvgPoolGrad`\n    ([CVE-2022-21730](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-21730))\n*   Fixes an overflow and divide by zero in `UnravelIndex`\n    ([CVE-2022-21729](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-21729))\n*   Fixes a type confusion in shape inference for `ConcatV2`\n    ([CVE-2022-21731](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-21731))\n*   Fixes an OOM in `ThreadPoolHandle`\n    ([CVE-2022-21732](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-21732))\n*   Fixes an OOM due to integer overflow in `StringNGrams`\n    ([CVE-2022-21733](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-21733))\n*   Fixes more issues caused by incomplete validation in boosted trees code\n    ([CVE-2021-41208](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-41208))\n*   Fixes an integer overflows in most sparse component-wise ops\n    ([CVE-2022-23567](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-23567))\n*   Fixes an integer overflows in `AddManySparseToTensorsMap`\n    ([CVE-2022-23568](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-23568))\n*   Fixes a number of `CHECK`-failures in `MapStage`\n    ([CVE-2022-21734](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-21734))\n*   Fixes a division by zero in `FractionalMaxPool`\n    ([CVE-2022-21735](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-21735))\n*   Fixes a number of `CHECK`-fails when building invalid/overflowing tensor\n    shapes\n    ([CVE-2022-23569](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-23569))\n*   Fixes an undefined behavior in `SparseTensorSliceDataset`\n    ([CVE-2022-21736](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-21736))\n*   Fixes an assertion failure based denial of service via faulty bin count\n    operations\n    ([CVE-2022-21737](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-21737))\n*   Fixes a reference binding to null pointer in `QuantizedMaxPool`\n    ([CVE-2022-21739](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-21739))\n*   Fixes an integer overflow leading to crash in `SparseCountSparseOutput`\n    ([CVE-2022-21738](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-21738))\n*   Fixes a heap overflow in `SparseCountSparseOutput`\n    ([CVE-2022-21740](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-21740))\n*   Fixes an FPE in `BiasAndClamp` in TFLite\n    ([CVE-2022-23557](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-23557))\n*   Fixes an FPE in depthwise convolutions in TFLite\n    ([CVE-2022-21741](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-21741))\n*   Fixes an integer overflow in TFLite array creation\n    ([CVE-2022-23558](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-23558))\n*   Fixes an integer overflow in TFLite\n    ([CVE-2022-23559](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-23559))\n*   Fixes a dangerous OOB write in TFLite\n    ([CVE-2022-23561](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-23561))\n*   Fixes a vulnerability leading to read and write outside of bounds in TFLite\n    ([CVE-2022-23560](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-23560))\n*   Fixes a set of vulnerabilities caused by using insecure temporary files\n    ([CVE-2022-23563](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-23563))\n*   Fixes an integer overflow in Range resulting in undefined behavior and OOM\n    ([CVE-2022-23562](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-23562))\n*   Fixes a vulnerability where missing validation causes `tf.sparse.split` to\n    crash when `axis` is a tuple\n    ([CVE-2021-41206](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-41206))\n*   Fixes a `CHECK`-fail when decoding resource handles from proto\n    ([CVE-2022-23564](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-23564))\n*   Fixes a `CHECK`-fail with repeated `AttrDef`\n    ([CVE-2022-23565](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-23565))\n*   Fixes a heap OOB write in Grappler\n    ([CVE-2022-23566](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-23566))\n*   Fixes a `CHECK`-fail when decoding invalid tensors from proto\n    ([CVE-2022-23571](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-23571))\n*   Fixes a null-dereference when specializing tensor type\n    ([CVE-2022-23570](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-23570))\n*   Fixes a crash when type cannot be specialized\n    ([CVE-2022-23572](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-23572))\n*   Fixes a heap OOB read/write in `SpecializeType`\n    ([CVE-2022-23574](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-23574))\n*   Fixes an uninitialized variable access in `AssignOp`\n    ([CVE-2022-23573](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-23573))\n*   Fixes an integer overflow in `OpLevelCostEstimator::CalculateTensorSize`\n    ([CVE-2022-23575](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-23575))\n*   Fixes an integer overflow in `OpLevelCostEstimator::CalculateOutputSize`\n    ([CVE-2022-23576](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-23576))\n*   Fixes a null dereference in `GetInitOp`\n    ([CVE-2022-23577](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-23577))\n*   Fixes a memory leak when a graph node is invalid\n    ([CVE-2022-23578](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-23578))\n*   Fixes an abort caused by allocating a vector that is too large\n    ([CVE-2022-23580](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-23580))\n*   Fixes multiple `CHECK`-failures during Grappler's `IsSimplifiableReshape`\n    ([CVE-2022-23581](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-23581))\n*   Fixes multiple `CHECK`-failures during Grappler's `SafeToRemoveIdentity`\n    ([CVE-2022-23579](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-23579))\n*   Fixes multiple `CHECK`-failures in `TensorByteSize`\n    ([CVE-2022-23582](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-23582))\n*   Fixes multiple `CHECK`-failures in binary ops due to type confusion\n    ([CVE-2022-23583](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-23583))\n*   Fixes a use after free in `DecodePng` kernel\n    ([CVE-2022-23584](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-23584))\n*   Fixes a memory leak in decoding PNG images\n    ([CVE-2022-23585](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-23585))\n*   Fixes multiple `CHECK`-fails in `function.cc`\n    ([CVE-2022-23586](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-23586))\n*   Fixes multiple `CHECK`-fails due to attempting to build a reference tensor\n    ([CVE-2022-23588](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-23588))\n*   Fixes an integer overflow in Grappler cost estimation of crop and resize\n    operation\n    ([CVE-2022-23587](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-23587))\n*   Fixes a null pointer dereference in Grappler's `IsConstant`\n    ([CVE-2022-23589](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-23589))\n*   Fixes a `CHECK` failure in constant folding\n    ([CVE-2021-41197](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-41197))\n*   Fixes a stack overflow due to self-recursive function in `GraphDef`\n    ([CVE-2022-23591](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-23591))\n*   Fixes a crash due to erroneous `StatusOr`\n    ([CVE-2022-23590](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-23590))\n*   Fixes multiple crashes and heap OOB accesses in TFG dialect (MLIR)\n    ([CVE-2022-23594](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-23594))\n*   Fixes a null pointer dereference in `BuildXlaCompilationCache` (XLA)\n    ([CVE-2022-23595](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-23595))\n*   Updates `icu` to `69.1` to handle\n    [CVE-2020-10531](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2020-10531)\n\n# Release 2.6.3\n\nThis releases introduces several vulnerability fixes:\n\n*   Fixes a floating point division by 0 when executing convolution operators\n    ([CVE-2022-21725](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-21725))\n*   Fixes a heap OOB read in shape inference for `ReverseSequence`\n    ([CVE-2022-21728](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-21728))\n*   Fixes a heap OOB access in `Dequantize`\n    ([CVE-2022-21726](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-21726))\n*   Fixes an integer overflow in shape inference for `Dequantize`\n    ([CVE-2022-21727](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-21727))\n*   Fixes a heap OOB access in `FractionalAvgPoolGrad`\n    ([CVE-2022-21730](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-21730))\n*   Fixes an overflow and divide by zero in `UnravelIndex`\n    ([CVE-2022-21729](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-21729))\n*   Fixes a type confusion in shape inference for `ConcatV2`\n    ([CVE-2022-21731](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-21731))\n*   Fixes an OOM in `ThreadPoolHandle`\n    ([CVE-2022-21732](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-21732))\n*   Fixes an OOM due to integer overflow in `StringNGrams`\n    ([CVE-2022-21733](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-21733))\n*   Fixes more issues caused by incomplete validation in boosted trees code\n    ([CVE-2021-41208](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-41208))\n*   Fixes an integer overflows in most sparse component-wise ops\n    ([CVE-2022-23567](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-23567))\n*   Fixes an integer overflows in `AddManySparseToTensorsMap`\n    ([CVE-2022-23568](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-23568))\n*   Fixes a number of `CHECK`-failures in `MapStage`\n    ([CVE-2022-21734](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-21734))\n*   Fixes a division by zero in `FractionalMaxPool`\n    ([CVE-2022-21735](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-21735))\n*   Fixes a number of `CHECK`-fails when building invalid/overflowing tensor\n    shapes\n    ([CVE-2022-23569](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-23569))\n*   Fixes an undefined behavior in `SparseTensorSliceDataset`\n    ([CVE-2022-21736](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-21736))\n*   Fixes an assertion failure based denial of service via faulty bin count\n    operations\n    ([CVE-2022-21737](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-21737))\n*   Fixes a reference binding to null pointer in `QuantizedMaxPool`\n    ([CVE-2022-21739](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-21739))\n*   Fixes an integer overflow leading to crash in `SparseCountSparseOutput`\n    ([CVE-2022-21738](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-21738))\n*   Fixes a heap overflow in `SparseCountSparseOutput`\n    ([CVE-2022-21740](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-21740))\n*   Fixes an FPE in `BiasAndClamp` in TFLite\n    ([CVE-2022-23557](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-23557))\n*   Fixes an FPE in depthwise convolutions in TFLite\n    ([CVE-2022-21741](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-21741))\n*   Fixes an integer overflow in TFLite array creation\n    ([CVE-2022-23558](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-23558))\n*   Fixes an integer overflow in TFLite\n    ([CVE-2022-23559](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-23559))\n*   Fixes a dangerous OOB write in TFLite\n    ([CVE-2022-23561](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-23561))\n*   Fixes a vulnerability leading to read and write outside of bounds in TFLite\n    ([CVE-2022-23560](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-23560))\n*   Fixes a set of vulnerabilities caused by using insecure temporary files\n    ([CVE-2022-23563](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-23563))\n*   Fixes an integer overflow in Range resulting in undefined behavior and OOM\n    ([CVE-2022-23562](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-23562))\n*   Fixes a vulnerability where missing validation causes `tf.sparse.split` to\n    crash when `axis` is a tuple\n    ([CVE-2021-41206](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-41206))\n*   Fixes a `CHECK`-fail when decoding resource handles from proto\n    ([CVE-2022-23564](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-23564))\n*   Fixes a `CHECK`-fail with repeated `AttrDef`\n    ([CVE-2022-23565](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-23565))\n*   Fixes a heap OOB write in Grappler\n    ([CVE-2022-23566](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-23566))\n*   Fixes a `CHECK`-fail when decoding invalid tensors from proto\n    ([CVE-2022-23571](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-23571))\n*   Fixes a null-dereference when specializing tensor type\n    ([CVE-2022-23570](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-23570))\n*   Fixes a crash when type cannot be specialized\n    ([CVE-2022-23572](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-23572))\n*   Fixes a heap OOB read/write in `SpecializeType`\n    ([CVE-2022-23574](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-23574))\n*   Fixes an uninitialized variable access in `AssignOp`\n    ([CVE-2022-23573](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-23573))\n*   Fixes an integer overflow in `OpLevelCostEstimator::CalculateTensorSize`\n    ([CVE-2022-23575](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-23575))\n*   Fixes an integer overflow in `OpLevelCostEstimator::CalculateOutputSize`\n    ([CVE-2022-23576](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-23576))\n*   Fixes a null dereference in `GetInitOp`\n    ([CVE-2022-23577](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-23577))\n*   Fixes a memory leak when a graph node is invalid\n    ([CVE-2022-23578](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-23578))\n*   Fixes an abort caused by allocating a vector that is too large\n    ([CVE-2022-23580](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-23580))\n*   Fixes multiple `CHECK`-failures during Grappler's `IsSimplifiableReshape`\n    ([CVE-2022-23581](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-23581))\n*   Fixes multiple `CHECK`-failures during Grappler's `SafeToRemoveIdentity`\n    ([CVE-2022-23579](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-23579))\n*   Fixes multiple `CHECK`-failures in `TensorByteSize`\n    ([CVE-2022-23582](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-23582))\n*   Fixes multiple `CHECK`-failures in binary ops due to type confusion\n    ([CVE-2022-23583](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-23583))\n*   Fixes a use after free in `DecodePng` kernel\n    ([CVE-2022-23584](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-23584))\n*   Fixes a memory leak in decoding PNG images\n    ([CVE-2022-23585](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-23585))\n*   Fixes multiple `CHECK`-fails in `function.cc`\n    ([CVE-2022-23586](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-23586))\n*   Fixes multiple `CHECK`-fails due to attempting to build a reference tensor\n    ([CVE-2022-23588](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-23588))\n*   Fixes an integer overflow in Grappler cost estimation of crop and resize\n    operation\n    ([CVE-2022-23587](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-23587))\n*   Fixes a null pointer dereference in Grappler's `IsConstant`\n    ([CVE-2022-23589](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-23589))\n*   Fixes a `CHECK` failure in constant folding\n    ([CVE-2021-41197](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-41197))\n*   Fixes a stack overflow due to self-recursive function in `GraphDef`\n    ([CVE-2022-23591](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-23591))\n*   Fixes a null pointer dereference in `BuildXlaCompilationCache` (XLA)\n    ([CVE-2022-23595](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-23595))\n*   Updates `icu` to `69.1` to handle\n    [CVE-2020-10531](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2020-10531)\n\n# Release 2.5.3\n\nThis releases introduces several vulnerability fixes:\n\n*   Fixes a floating point division by 0 when executing convolution operators\n    ([CVE-2022-21725](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-21725))\n*   Fixes a heap OOB read in shape inference for `ReverseSequence`\n    ([CVE-2022-21728](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-21728))\n*   Fixes a heap OOB access in `Dequantize`\n    ([CVE-2022-21726](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-21726))\n*   Fixes an integer overflow in shape inference for `Dequantize`\n    ([CVE-2022-21727](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-21727))\n*   Fixes a heap OOB access in `FractionalAvgPoolGrad`\n    ([CVE-2022-21730](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-21730))\n*   Fixes an overflow and divide by zero in `UnravelIndex`\n    ([CVE-2022-21729](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-21729))\n*   Fixes a type confusion in shape inference for `ConcatV2`\n    ([CVE-2022-21731](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-21731))\n*   Fixes an OOM in `ThreadPoolHandle`\n    ([CVE-2022-21732](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-21732))\n*   Fixes an OOM due to integer overflow in `StringNGrams`\n    ([CVE-2022-21733](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-21733))\n*   Fixes more issues caused by incomplete validation in boosted trees code\n    ([CVE-2021-41208](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-41208))\n*   Fixes an integer overflows in most sparse component-wise ops\n    ([CVE-2022-23567](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-23567))\n*   Fixes an integer overflows in `AddManySparseToTensorsMap`\n    ([CVE-2022-23568](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-23568))\n*   Fixes a number of `CHECK`-failures in `MapStage`\n    ([CVE-2022-21734](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-21734))\n*   Fixes a division by zero in `FractionalMaxPool`\n    ([CVE-2022-21735](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-21735))\n*   Fixes a number of `CHECK`-fails when building invalid/overflowing tensor\n    shapes\n    ([CVE-2022-23569](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-23569))\n*   Fixes an undefined behavior in `SparseTensorSliceDataset`\n    ([CVE-2022-21736](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-21736))\n*   Fixes an assertion failure based denial of service via faulty bin count\n    operations\n    ([CVE-2022-21737](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-21737))\n*   Fixes a reference binding to null pointer in `QuantizedMaxPool`\n    ([CVE-2022-21739](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-21739))\n*   Fixes an integer overflow leading to crash in `SparseCountSparseOutput`\n    ([CVE-2022-21738](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-21738))\n*   Fixes a heap overflow in `SparseCountSparseOutput`\n    ([CVE-2022-21740](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-21740))\n*   Fixes an FPE in `BiasAndClamp` in TFLite\n    ([CVE-2022-23557](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-23557))\n*   Fixes an FPE in depthwise convolutions in TFLite\n    ([CVE-2022-21741](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-21741))\n*   Fixes an integer overflow in TFLite array creation\n    ([CVE-2022-23558](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-23558))\n*   Fixes an integer overflow in TFLite\n    ([CVE-2022-23559](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-23559))\n*   Fixes a dangerous OOB write in TFLite\n    ([CVE-2022-23561](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-23561))\n*   Fixes a vulnerability leading to read and write outside of bounds in TFLite\n    ([CVE-2022-23560](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-23560))\n*   Fixes a set of vulnerabilities caused by using insecure temporary files\n    ([CVE-2022-23563](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-23563))\n*   Fixes an integer overflow in Range resulting in undefined behavior and OOM\n    ([CVE-2022-23562](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-23562))\n*   Fixes a vulnerability where missing validation causes `tf.sparse.split` to\n    crash when `axis` is a tuple\n    ([CVE-2021-41206](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-41206))\n*   Fixes a `CHECK`-fail when decoding resource handles from proto\n    ([CVE-2022-23564](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-23564))\n*   Fixes a `CHECK`-fail with repeated `AttrDef`\n    ([CVE-2022-23565](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-23565))\n*   Fixes a heap OOB write in Grappler\n    ([CVE-2022-23566](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-23566))\n*   Fixes a `CHECK`-fail when decoding invalid tensors from proto\n    ([CVE-2022-23571](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-23571))\n*   Fixes an unitialized variable access in `AssignOp`\n    ([CVE-2022-23573](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-23573))\n*   Fixes an integer overflow in `OpLevelCostEstimator::CalculateTensorSize`\n    ([CVE-2022-23575](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-23575))\n*   Fixes an integer overflow in `OpLevelCostEstimator::CalculateOutputSize`\n    ([CVE-2022-23576](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-23576))\n*   Fixes a null dereference in `GetInitOp`\n    ([CVE-2022-23577](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-23577))\n*   Fixes a memory leak when a graph node is invalid\n    ([CVE-2022-23578](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-23578))\n*   Fixes an abort caused by allocating a vector that is too large\n    ([CVE-2022-23580](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-23580))\n*   Fixes multiple `CHECK`-failures during Grappler's `IsSimplifiableReshape`\n    ([CVE-2022-23581](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-23581))\n*   Fixes multiple `CHECK`-failures during Grappler's `SafeToRemoveIdentity`\n    ([CVE-2022-23579](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-23579))\n*   Fixes multiple `CHECK`-failures in `TensorByteSize`\n    ([CVE-2022-23582](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-23582))\n*   Fixes multiple `CHECK`-failures in binary ops due to type confusion\n    ([CVE-2022-23583](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-23583))\n*   Fixes a use after free in `DecodePng` kernel\n    ([CVE-2022-23584](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-23584))\n*   Fixes a memory leak in decoding PNG images\n    ([CVE-2022-23585](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-23585))\n*   Fixes multiple `CHECK`-fails in `function.cc`\n    ([CVE-2022-23586](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-23586))\n*   Fixes multiple `CHECK`-fails due to attempting to build a reference tensor\n    ([CVE-2022-23588](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-23588))\n*   Fixes an integer overflow in Grappler cost estimation of crop and resize\n    operation\n    ([CVE-2022-23587](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-23587))\n*   Fixes a null pointer dereference in Grappler's `IsConstant`\n    ([CVE-2022-23589](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-23589))\n*   Fixes a `CHECK` failure in constant folding\n    ([CVE-2021-41197](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-41197))\n*   Fixes a stack overflow due to self-recursive function in `GraphDef`\n    ([CVE-2022-23591](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-23591))\n*   Updates `icu` to `69.1` to handle\n    [CVE-2020-10531](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2020-10531)\n\n# Release 2.7.0\n\n## Breaking Changes\n\n*   `tf.keras`:\n\n    *   The methods `Model.fit()`, `Model.predict()`, and `Model.evaluate()`\n        will no longer uprank input data of shape `(batch_size,)` to become\n        `(batch_size, 1)`. This enables `Model` subclasses to process scalar\n        data in their `train_step()`/`test_step()`/`predict_step()` methods. \\\n        Note that this change may break certain subclassed models. You can\n        revert back to the previous behavior by adding upranking yourself in the\n        `train_step()`/`test_step()`/`predict_step()` methods, e.g. `if\n        x.shape.rank == 1: x = tf.expand_dims(x, axis=-1)`. Functional models as\n        well as Sequential models built with an explicit input shape are not\n        affected.\n    *   The methods `Model.to_yaml()` and `keras.models.model_from_yaml` have\n        been replaced to raise a `RuntimeError` as they can be abused to cause\n        arbitrary code execution. It is recommended to use JSON serialization\n        instead of YAML, or, a better alternative, serialize to H5.\n    *   `LinearModel` and `WideDeepModel` are moved to the\n        `tf.compat.v1.keras.models.` namespace\n        (`tf.compat.v1.keras.models.LinearModel` and\n        `tf.compat.v1.keras.models.WideDeepModel`), and their `experimental`\n        endpoints (`tf.keras.experimental.models.LinearModel` and\n        `tf.keras.experimental.models.WideDeepModel`) are being deprecated.\n    *   RNG behavior change for all `tf.keras.initializers` classes. For any\n        class constructed with a fixed seed, it will no longer generate same\n        value when invoked multiple times. Instead, it will return different\n        value, but a deterministic sequence. This change will make the\n        initialize behavior align between v1 and v2.\n\n*   `tf.lite`:\n\n    *   Rename fields `SignatureDef` table in schema to maximize the parity with\n        TF SavedModel's Signature concept.\n    *   Deprecate Makefile builds. Makefile users need to migrate their builds\n        to CMake or Bazel. Please refer to the\n        [Build TensorFlow Lite with CMake](https://www.tensorflow.org/lite/guide/build_cmake)\n        and\n        [Build TensorFlow Lite for ARM boards](https://www.tensorflow.org/lite/guide/build_arm)\n        for the migration.\n    *   Deprecate `tflite::OpResolver::GetDelegates`. The list returned by\n        TfLite's `BuiltinOpResolver::GetDelegates` is now always empty. Instead,\n        recommend using new method `tflite::OpResolver::GetDelegateCreators` in\n        order to achieve lazy initialization on TfLite delegate instances.\n\n*   TF Core:\n\n    *   `tf.Graph.get_name_scope()` now always returns a string, as documented.\n        Previously, when called within `name_scope(\"\")` or `name_scope(None)`\n        contexts, it returned `None`; now it returns the empty string.\n    *   `tensorflow/core/ir/` contains a new MLIR-based Graph dialect that is\n        isomorphic to GraphDef and will be used to replace GraphDef-based (e.g.,\n        Grappler) optimizations.\n    *   Deprecated and removed `attrs()` function in shape inference. All\n        attributes should be queried by name now (rather than range returned) to\n        enable changing the underlying storage there.\n    *   The following Python symbols were accidentally added in earlier versions\n        of TensorFlow and now are removed. Each symbol has a replacement that\n        should be used instead, but note the replacement's argument names are\n        different.\n        *   `tf.quantize_and_dequantize_v4` (accidentally introduced in\n            TensorFlow 2.4): Use `tf.quantization.quantize_and_dequantize_v2`\n            instead.\n        *   `tf.batch_mat_mul_v3` (accidentally introduced in TensorFlow 2.6):\n            Use `tf.linalg.matmul` instead.\n        *   `tf.sparse_segment_sum_grad` (accidentally introduced in TensorFlow\n            2.6): Use `tf.raw_ops.SparseSegmentSumGrad` instead. Directly\n            calling this op is typically not necessary, as it is automatically\n            used when computing the gradient of `tf.sparse.segment_sum`.\n    *   Renaming of tensorflow::int64 to int_64_t in numerous places (the former\n        is an alias for the latter) which could result in needing to regenerate\n        selective op registration headers else execution would fail with\n        unregistered kernels error.\n\n*   Modular File System Migration:\n\n    *   Support for S3 and HDFS file systems has been migrated to a modular file\n        systems based approach and is now available in\n        https://github.com/tensorflow/io. The `tensorflow-io` python package\n        should be installed for S3 and HDFS support with tensorflow.\n\n## Major Features and Improvements\n\n*   Improvements to the TensorFlow debugging experience:\n\n    *   Previously, TensorFlow error stack traces involved many internal frames,\n        which could be challenging to read through, while not being actionable\n        for end users. As of TF 2.7, TensorFlow filters internal frames in most\n        errors that it raises, to keep stack traces short, readable, and focused\n        on what's actionable for end users (their own code).\n\n    This behavior can be disabled by calling\n    `tf.debugging.disable_traceback_filtering()`, and can be re-enabled via\n    `tf.debugging.enable_traceback_filtering()`. If you are debugging a\n    TensorFlow-internal issue (e.g. to prepare a TensorFlow PR), make sure to\n    disable traceback filtering. You can check whether this feature is currently\n    enabled by calling `tf.debugging.is_traceback_filtering_enabled()`.\n\n    Note that this feature is only available with Python 3.7 or higher.\n\n    *   Improve the informativeness of error messages raised by Keras\n        `Layer.__call__()`, by adding the full list of argument values passed to\n        the layer in every exception.\n\n*   Introduce the `tf.compat.v1.keras.utils.track_tf1_style_variables`\n    decorator, which enables using large classes of tf1-style variable_scope,\n    `get_variable`, and `compat.v1.layer`-based components from within TF2\n    models running with TF2 behavior enabled.\n\n*   `tf.data`:\n\n    *   tf.data service now supports auto-sharding. Users specify the sharding\n        policy with `tf.data.experimental.service.ShardingPolicy` enum. It can\n        be one of `OFF` (equivalent to today's `\"parallel_epochs\"` mode),\n        `DYNAMIC` (equivalent to today's `\"distributed_epoch\"` mode), or one of\n        the static sharding policies: `FILE`, `DATA`, `FILE_OR_DATA`, or `HINT`\n        (corresponding to values of `tf.data.experimental.AutoShardPolicy`).\n\n        Static sharding (auto-sharding) requires the number of tf.data service\n        workers be fixed. Users need to specify the worker addresses in\n        `tensorflow.data.experimental.DispatcherConfig`.\n\n    *   `tf.data.experimental.service.register_dataset` now accepts optional\n        `compression` argument.\n\n*   Keras:\n\n    *   `tf.keras.layers.Conv` now includes a public `convolution_op` method.\n        This method can be used to simplify the implementation of Conv\n        subclasses. There are two primary ways to use this new method. The first\n        is to use the method directly in your own `call` method: `python class\n        StandardizedConv2D(tf.keras.layers.Conv2D): def call(self, inputs):\n        mean, var = tf.nn.moments(self.kernel, axes=[0, 1, 2], keepdims=True)\n        return self.convolution_op(inputs, (self.kernel - mean) / tf.sqrt(var +\n        1e-10))` Alternatively, you can override `convolution_op`: `python class\n        StandardizedConv2D(tf.keras.Layer): def convolution_op(self, inputs,\n        kernel): mean, var = tf.nn.moments(kernel, axes=[0, 1, 2],\n        keepdims=True) # Author code uses std + 1e-5 return\n        super().convolution_op(inputs, (kernel - mean) / tf.sqrt(var + 1e-10))`\n    *   Added `merge_state()` method to `tf.keras.metrics.Metric` for use in\n        distributed computations.\n    *   Added `sparse` and `ragged` options to\n        `tf.keras.layers.TextVectorization` to allow for `SparseTensor` and\n        `RaggedTensor` outputs from the layer.\n\n*   distribute.experimental.rpc package:\n\n    *   distribute.experimental.rpc package introduces APIs to create a GRPC\n        based server to register tf.function methods and a GRPC client to invoke\n        remote registered methods. RPC APIs are intended for multi-client setups\n        i.e. server and clients are started in separate binaries independently.\n\n    *   Example usage to create server: ```python server =\n        tf.distribute.experimental.rpc.Server.create(\"grpc\", \"127.0.0.1:1234\")\n        @tf.function(input_signature=[ tf.TensorSpec([], tf.int32),\n        tf.TensorSpec([], dtypes.int32) ]) def _remote_multiply(a, b): return\n        tf.math.multiply(a, b)\n\n        server.register(\"multiply\", _remote_multiply) ```\n\n    *   Example usage to create client: `python client =\n        tf.distribute.experimental.rpc.Client.create(\"grpc\", address) a =\n        tf.constant(2, dtype=tf.int32) b = tf.constant(3, dtype=tf.int32)\n        result = client.multiply(a, b)`\n\n*   `tf.lite`:\n\n    *   Add experimental API `experimental_from_jax` to support conversion from\n        Jax models to TensorFlow Lite.\n    *   Support uint32 data type for cast op.\n    *   Support int8 data type for cast op.\n    *   Add experimental quantization debugger `tf.lite.QuantizationDebugger`\n    *   Add lite.experimental.authoring.compatible API\n        *   A Python decorator to provide a way to check TFLite compatibility\n            issue of `tf.function`. This returns a callable object which\n            validates TFLite compatibility. If an incompatible operation is\n            encountered during execution, an exception will be raised with\n            information about the incompatible ops.\n    *   Add lite.experimental.Analyzer API\n        *   An experimental tool to analyze TFLite flatbuffer models. This API\n            can be used to investigate TFLite model structure and check\n            compatibility with GPU delegate.\n\n*   Extension Types\n\n    *   Add experimental API to define new Python classes that can be handled by\n        TensorFlow APIs. To create an extension type, simply define a Python\n        class with `tf.experimental.ExtensionType` as its base, and use type\n        annotations to specify the type for each field. E.g.: `python class\n        MaskedTensor(tf.experimental.ExtensionType): values: tf.Tensor mask:\n        tf.Tensor` The `tf.ExtensionType` base class works similarly to\n        [`typing.NamedTuple`](https://docs.python.org/3/library/typing.html#typing.NamedTuple)\n        and\n        [`@dataclasses.dataclass`](https://docs.python.org/3/library/dataclasses.html#dataclasses.dataclass)\n        from the standard Python library.\n    *   Extension types are supported by Keras, tf.data, TF-hub, SavedModel,\n        tf.function, control flow ops, py_function, and distribution strategy.\n    *   Add \"dispatch decorators\" that can be used to override the default\n        behavior of TensorFlow ops (such as `tf.add` or `tf.concat`) when they\n        are applied to ExtensionType values.\n    *   The `BatchableExtensionType` API can be used to define extension types\n        that support APIs that make use of batching, such as `tf.data.Dataset`\n        and `tf.map_fn`.\n    *   For more information, see the\n        [Extension types guide](https://www.tensorflow.org/guide/extension_type).\n\n## Bug Fixes and Other Changes\n\n*   TF Core:\n    *   Random number generation (RNG) system\n        *   Add argument `alg` to `tf.random.stateless_*` functions to\n            explicitly select the RNG algorithm.\n        *   Add `tf.nn.experimental.stateless_dropout`, a stateless version of\n            `tf.nn.dropout`.\n        *   `tf.random.Generator` now can be created inside the scope of\n            `tf.distribute.experimental.ParameterServerStrategy` and\n            `tf.distribute.experimental.CentralStorageStrategy`.\n    *   Add an experimental session config\n        `tf.experimental.disable_functional_ops_lowering` which disables\n        functional control flow op lowering optimization. This is useful when\n        executing within a portable runtime where control flow op kernels may\n        not be loaded due to selective registration.\n    *   Add a new experimental argument `experimental_is_anonymous` to\n        `tf.lookup.StaticHashTable.__init__` to create the table in anonymous\n        mode. In this mode, the table resource can only be accessed via resource\n        handles (not resource names) and will be deleted automatically when all\n        resource handles pointing to it are gone.\n*   `tf.data`:\n    *   Introduce the `tf.data.experimental.at` API which provides random access\n        for input pipelines that consist of transformations that support random\n        access. The initial set of transformations that support random access\n        includes:\n        `tf.data.Dataset.from_tensor_slices`,`tf.data.Dataset.shuffle`,\n        `tf.data.Dataset.batch`, `tf.data.Dataset.shard`, `tf.data.Dataset.map`,\n        and `tf.data.Dataset.range`.\n    *   Promote `tf.data.Options.experimental_deterministic` API to\n        `tf.data.Options.deterministic` and deprecate the experimental endpoint.\n    *   Move autotuning options\n        from`tf.data.Options.experimental_optimization.autotune*` to a newly\n        created `tf.data.Options.autotune.*` and remove support for\n        `tf.data.Options.experimental_optimization.autotune_buffers`.\n    *   Add support for user-defined names of tf.data core Python API, which can\n        be used to disambiguate tf.data events in TF Profiler Trace Viewer.\n    *   Promote `tf.data.experimental.sample_from_datasets` API to\n        `tf.data.Dataset.sample_from_datasets` and deprecate the experimental\n        endpoint.\n    *   Added `TF_GPU_ALLOCATOR=cuda_malloc_async` that use cudaMallocAsync from\n        CUDA 11.2. This could become the default in the future.\n*   TF SavedModel:\n    *   Custom gradients are now saved by default. See\n        `tf.saved_model.SaveOptions` to disable this.\n    *   The saved_model_cli's `--input_examples` inputs are now restricted to\n        python literals to avoid code injection.\n*   XLA:\n    *   Add a new API that allows custom call functions to signal errors. The\n        old API will be deprecated in a future release. See\n        https://www.tensorflow.org/xla/custom_call for details.\n    *   XLA:GPU reductions are deterministic by default (reductions within\n        `jit_compile=True` are now deterministic).\n    *   XLA:GPU works with Horovod (OSS contribution by Trent Lo from NVidia)\n    *   XLA:CPU and XLA:GPU can compile tf.unique and tf.where when shapes are\n        provably correct at compile time.\n*   `tf.saved_model.save`:\n    *   When saving a model, not specifying a namespace whitelist for custom ops\n        with a namespace will now default to allowing rather than rejecting them\n        all.\n*   Deterministic Op Functionality (enabled by setting the environment variable\n    `TF_DETERMINISTIC_OPS` to `\"true\"` or `\"1\"`):\n    *   Add determinsitic GPU implementations of:\n        *   `tf.math.segment_sum`\n        *   `tf.math.segment_prod`\n        *   `tf.math.segment_mean`\n        *   `tf.math.unsorted_segment_sum`\n        *   `tf.math.unsorted_segment_prod`\n        *   `tf.math.unsorted_segment_sqrt`\n        *   `tf.math.unsorted_segment_mean`\n        *   `tf.gather` backprop\n        *   `tf.convert_to_tensor` when fed with (sparse) `tf.IndexedSlices`\n        *   `tf.nn.sparse_softmax_crossentropy_with_logits`\n        *   `tf.nn.ctc_loss` (resolved, possibly in prior release, and confirmed\n            with tests)\n        *   stateful ops used in `tf.data.Dataset`\n    *   Run the following ops on CPU (with significant performance penalty):\n        *   `tf.scatter_nd` and other related scatter functions, such as\n            `tf.tensor_scatter_nd_update`\n    *   Add determinism-unimplemented exception-throwing to the following ops.\n        When op-determinism is expected (i.e. when the environment variable\n        `TF_DETERMINISTIC_OPS` is set to `\"true\"` or `\"1\"`), an attempt to use\n        the specified paths through the following ops on a GPU will cause\n        `tf.errors.UnimplementedError` (with an understandable message), unless\n        otherwise specified, to be thrown.\n        *   `tf.compat.v1.nn.fused_batch_norm` backprop to `offset` when\n            `is_training=False`\n        *   `tf.image.adjust_contrast` forward\n        *   `tf.nn.depthwise_conv2d` backprop to `filter` when not using cuDNN\n            convolution\n        *   `tf.image.resize` with `method=ResizeMethod.NEAREST` backprop\n        *   `tf.math.bincount` - TODO: confirm exception added\n        *   `tf.raw_ops.DebugNumericSummary` and\n            `tf.raw_ops.DebugNumericSummaryV2`\n        *   `tf.Variable.scatter_add` (and other scatter methods, both on ref\n            and resource variables)\n        *   `tf.linalg.svd`\n        *   `tf.nn.dilation2d` gradient\n        *   `tf.nn.max_pool_with_argmax` gradient\n        *   `tf.timestamp`. Throws `FailedPrecondition`\n        *   The random-number-generating ops in the `tf.random` module when the\n            global random seed has not yet been set (via `tf.random.set_seed`).\n            Throws `RuntimeError` from Python or `InvalidArgument` from C++\n        *   `tf.compat.v1.get_seed` if the global random seed has not yet been\n            set (via `tf.random.set_seed`). Throws `RuntimeError` from Python or\n            `InvalidArgument` from C++\n\n## Security\n\n*   Fixes a code injection issue in `saved_model_cli`\n    ([CVE-2021-41228](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-41228))\n*   Fixes a vulnerability due to use of uninitialized value in Tensorflow\n    ([CVE-2021-41225](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-41225))\n*   Fixes a heap OOB in `FusedBatchNorm` kernels\n    ([CVE-2021-41223](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-41223))\n*   Fixes an arbitrary memory read in `ImmutableConst`\n    ([CVE-2021-41227](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-41227))\n*   Fixes a heap OOB in `SparseBinCount`\n    ([CVE-2021-41226](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-41226))\n*   Fixes a heap OOB in `SparseFillEmptyRows`\n    ([CVE-2021-41224](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-41224))\n*   Fixes a segfault due to negative splits in `SplitV`\n    ([CVE-2021-41222](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-41222))\n*   Fixes segfaults and vulnerabilities caused by accesses to invalid memory\n    during shape inference in `Cudnn*` ops\n    ([CVE-2021-41221](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-41221))\n*   Fixes a null pointer exception when `Exit` node is not preceded by `Enter`\n    op\n    ([CVE-2021-41217](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-41217))\n*   Fixes an integer division by 0 in `tf.raw_ops.AllToAll`\n    ([CVE-2021-41218](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-41218))\n*   Fixes a use after free and a memory leak in `CollectiveReduceV2`\n    ([CVE-2021-41220](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-41220))\n*   Fixes an undefined behavior via `nullptr` reference binding in sparse matrix\n    multiplication\n    ([CVE-2021-41219](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-41219))\n*   Fixes a heap buffer overflow in `Transpose`\n    ([CVE-2021-41216](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-41216))\n*   Prevents deadlocks arising from mutually recursive `tf.function` objects\n    ([CVE-2021-41213](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-41213))\n*   Fixes a null pointer exception in `DeserializeSparse`\n    ([CVE-2021-41215](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-41215))\n*   Fixes an undefined behavior arising from reference binding to `nullptr` in\n    `tf.ragged.cross`\n    ([CVE-2021-41214](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-41214))\n*   Fixes a heap OOB read in `tf.ragged.cross`\n    ([CVE-2021-41212](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-41212))\n*   Fixes a heap OOB in shape inference for `QuantizeV2`\n    ([CVE-2021-41211](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-41211))\n*   Fixes a heap OOB read in all `tf.raw_ops.QuantizeAndDequantizeV*` ops\n    ([CVE-2021-41205](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-41205))\n*   Fixes an FPE in `ParallelConcat`\n    ([CVE-2021-41207](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-41207))\n*   Fixes FPE issues in convolutions with zero size filters\n    ([CVE-2021-41209](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-41209))\n*   Fixes a heap OOB read in `tf.raw_ops.SparseCountSparseOutput`\n    ([CVE-2021-41210](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-41210))\n*   Fixes vulnerabilities caused by incomplete validation in boosted trees code\n    ([CVE-2021-41208](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-41208))\n*   Fixes vulnerabilities caused by incomplete validation of shapes in multiple\n    TF ops\n    ([CVE-2021-41206](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-41206))\n*   Fixes a segfault produced while copying constant resource tensor\n    ([CVE-2021-41204](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-41204))\n*   Fixes a vulnerability caused by unitialized access in\n    `EinsumHelper::ParseEquation`\n    ([CVE-2021-41201](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-41201))\n*   Fixes several vulnerabilities and segfaults caused by missing validation\n    during checkpoint loading\n    ([CVE-2021-41203](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-41203))\n*   Fixes an overflow producing a crash in `tf.range`\n    ([CVE-2021-41202](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-41202))\n*   Fixes an overflow producing a crash in `tf.image.resize` when size is large\n    ([CVE-2021-41199](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-41199))\n*   Fixes an overflow producing a crash in `tf.tile` when tiling tensor is large\n    ([CVE-2021-41198](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-41198))\n*   Fixes a vulnerability produced due to incomplete validation in\n    `tf.summary.create_file_writer`\n    ([CVE-2021-41200](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-41200))\n*   Fixes multiple crashes due to overflow and `CHECK`-fail in ops with large\n    tensor shapes\n    ([CVE-2021-41197](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-41197))\n*   Fixes a crash in `max_pool3d` when size argument is 0 or negative\n    ([CVE-2021-41196](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-41196))\n*   Fixes a crash in `tf.math.segment_*` operations\n    ([CVE-2021-41195](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-41195))\n*   Updates `curl` to `7.78.0` to handle\n    [CVE-2021-22922](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-22922),\n    [CVE-2021-22923](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-22923),\n    [CVE-2021-22924](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-22924),\n    [CVE-2021-22925](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-22925),\n    and\n    [CVE-2021-22926](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-22926).\n\n## Thanks to our Contributors\n\nThis release contains contributions from many people at Google, as well as:\n\n8bitmp3, Abhilash Majumder, abhilash1910, AdeshChoudhar, Adrian Garcia\nBadaracco, Adrian Ratiu, ag.ramesh, Aleksandr Nikolaev, Alexander Bosch,\nAlexander Grund, Annie Tallund, Anush Elangovan, Artem Sokolovskii, azazhu,\nBalint Cristian, Bas Aarts, Ben Barsdell, bhack, cfRod, Cheney-Wang, Cheng Ren,\nChristopher Bate, collin, Danila Bespalov, David Datascientist, Deven Desai,\nDuncan Riach, Ehsan Kia, Ellie, Fan Du, fo40225, Frederic Bastien, fsx950223,\nGauri1 Deshpande, geetachavan1, Guillaume Klein, guozhong.zhuang, helen, Hkon\nSandsmark, japm48, jgehw, Jinzhe Zeng, Jonathan Dekhtiar, Kai Zhu, Kaixi Hou,\nKanvi Khanna, Koan-Sin Tan, Koki Ibukuro, Kulin Seth, KumaTea, Kun-Lu, Lemo,\nlipracer, liuyuanqiang, Mahmoud Abuzaina, Marius Brehler, Maxiwell S. Garcia,\nmdfaijul, metarutaiga, Michal Szutenberg, nammbash, Neil Girdhar, Nishidha\nPanpaliya, Nyadla-Sys, Patrice Vignola, Peter Kasting, Philipp Hack, PINTO0309,\nPrateek Gupta, puneeshkhanna, Rahul Butani, Rajeshwar Reddy T, Reza Rahimi,\nRinozaJiffry, rmothukuru, Rohit Santhanam, Saduf2019, Samuel Marks, sclarkson,\nSergii Khomenko, Sheng, Yang, Sidong-Wei, slowy07, Srinivasan Narayanamoorthy,\nSrishti Srivastava, stanley, Stella Alice Schlotter, Steven I Reeves,\nstevenireeves, svobora, Takayoshi Koizumi, Tamas Bela Feher, Thibaut\nGoetghebuer-Planchon, Trent Lo, Twice, Varghese, Jojimon, Vishnuvardhan\nJanapati, Wang Yanzhang, Wang,Quintin, William Muir, William Raveane, Yasir\nModak, Yasuhiro Matsumoto, Yi Li, Yong Tang, zhaozheng09, Zhoulong Jiang,\nzzpmiracle\n\n# Release 2.6.2\n\nFixes an issue where `keras`, `tensorflow_estimator` and `tensorboard` were\nmissing proper upper bounds and resulted in broken installs after TF 2.7 release\n\n# Release 2.6.1\n\nThis release introduces several vulnerability fixes:\n\n*   Fixes a code injection issue in `saved_model_cli`\n    ([CVE-2021-41228](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-41228))\n*   Fixes a vulnerability due to use of uninitialized value in Tensorflow\n    ([CVE-2021-41225](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-41225))\n*   Fixes a heap OOB in `FusedBatchNorm` kernels\n    ([CVE-2021-41223](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-41223))\n*   Fixes an arbitrary memory read in `ImmutableConst`\n    ([CVE-2021-41227](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-41227))\n*   Fixes a heap OOB in `SparseBinCount`\n    ([CVE-2021-41226](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-41226))\n*   Fixes a heap OOB in `SparseFillEmptyRows`\n    ([CVE-2021-41224](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-41224))\n*   Fixes a segfault due to negative splits in `SplitV`\n    ([CVE-2021-41222](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-41222))\n*   Fixes segfaults and vulnerabilities caused by accesses to invalid memory\n    during shape inference in `Cudnn*` ops\n    ([CVE-2021-41221](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-41221))\n*   Fixes a null pointer exception when `Exit` node is not preceded by `Enter`\n    op\n    ([CVE-2021-41217](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-41217))\n*   Fixes an integer division by 0 in `tf.raw_ops.AllToAll`\n    ([CVE-2021-41218](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-41218))\n*   Fixes a use after free and a memory leak in `CollectiveReduceV2`\n    ([CVE-2021-41220](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-41220))\n*   Fixes an undefined behavior via `nullptr` reference binding in sparse matrix\n    multiplication\n    ([CVE-2021-41219](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-41219))\n*   Fixes a heap buffer overflow in `Transpose`\n    ([CVE-2021-41216](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-41216))\n*   Prevents deadlocks arising from mutually recursive `tf.function` objects\n    ([CVE-2021-41213](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-41213))\n*   Fixes a null pointer exception in `DeserializeSparse`\n    ([CVE-2021-41215](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-41215))\n*   Fixes an undefined behavior arising from reference binding to `nullptr` in\n    `tf.ragged.cross`\n    ([CVE-2021-41214](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-41214))\n*   Fixes a heap OOB read in `tf.ragged.cross`\n    ([CVE-2021-41212](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-41212))\n*   Fixes a heap OOB in shape inference for `QuantizeV2`\n    ([CVE-2021-41211](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-41211))\n*   Fixes a heap OOB read in all `tf.raw_ops.QuantizeAndDequantizeV*` ops\n    ([CVE-2021-41205](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-41205))\n*   Fixes an FPE in `ParallelConcat`\n    ([CVE-2021-41207](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-41207))\n*   Fixes FPE issues in convolutions with zero size filters\n    ([CVE-2021-41209](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-41209))\n*   Fixes a heap OOB read in `tf.raw_ops.SparseCountSparseOutput`\n    ([CVE-2021-41210](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-41210))\n*   Fixes vulnerabilities caused by incomplete validation in boosted trees code\n    ([CVE-2021-41208](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-41208))\n*   Fixes vulnerabilities caused by incomplete validation of shapes in multiple\n    TF ops\n    ([CVE-2021-41206](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-41206))\n*   Fixes a segfault produced while copying constant resource tensor\n    ([CVE-2021-41204](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-41204))\n*   Fixes a vulnerability caused by unitialized access in\n    `EinsumHelper::ParseEquation`\n    ([CVE-2021-41201](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-41201))\n*   Fixes several vulnerabilities and segfaults caused by missing validation\n    during checkpoint loading\n    ([CVE-2021-41203](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-41203))\n*   Fixes an overflow producing a crash in `tf.range`\n    ([CVE-2021-41202](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-41202))\n*   Fixes an overflow producing a crash in `tf.image.resize` when size is large\n    ([CVE-2021-41199](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-41199))\n*   Fixes an overflow producing a crash in `tf.tile` when tiling tensor is large\n    ([CVE-2021-41198](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-41198))\n*   Fixes a vulnerability produced due to incomplete validation in\n    `tf.summary.create_file_writer`\n    ([CVE-2021-41200](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-41200))\n*   Fixes multiple crashes due to overflow and `CHECK`-fail in ops with large\n    tensor shapes\n    ([CVE-2021-41197](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-41197))\n*   Fixes a crash in `max_pool3d` when size argument is 0 or negative\n    ([CVE-2021-41196](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-41196))\n*   Fixes a crash in `tf.math.segment_*` operations\n    ([CVE-2021-41195](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-41195))\n*   Updates `curl` to `7.78.0` to handle\n    [CVE-2021-22922](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-22922),\n    [CVE-2021-22923](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-22923),\n    [CVE-2021-22924](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-22924),\n    [CVE-2021-22925](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-22925),\n    and\n    [CVE-2021-22926](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-22926).\n\n# Release 2.6.0\n\n## Breaking Changes\n\n*   `tf.train.experimental.enable_mixed_precision_graph_rewrite` is removed, as\n    the API only works in graph mode and is not customizable. The function is\n    still accessible under\n    `tf.compat.v1.mixed_precision.enable_mixed_precision_graph_rewrite`, but it\n    is recommended to use the\n    [Keras mixed precision API](https://www.tensorflow.org/guide/mixed_precision)\n    instead.\n\n*   `tf.lite`:\n\n    *   Remove `experimental.nn.dynamic_rnn`, `experimental.nn.TfLiteRNNCell`\n        and `experimental.nn.TfLiteLSTMCell` since they're no longer supported.\n        It's recommended to just use\n        [keras lstm](https://www.tensorflow.org/api_docs/python/tf/keras/layers/LSTM)\n        instead.\n\n*   `tf.keras`:\n\n    *   Keras been split into a separate PIP package (`keras`), and its code has\n        been moved to the GitHub\n        repository[keras-team/keras](http://github.com/keras-team/keras). The\n        API endpoints for `tf.keras` stay unchanged, but are now backed by the\n        `keras` PIP package. The existing code in tensorflow/python/keras is a\n        staled copy and will be removed in future release (2.7). Please remove\n        any imports to `tensorflow.python.keras` and replace them with public\n        tf.keras API instead.\n    *   The methods `Model.to_yaml()` and `keras.models.model_from_yaml` have\n        been replaced to raise a `RuntimeError` as they can be abused to cause\n        arbitrary code execution. It is recommended to use JSON serialization\n        instead of YAML, or, a better alternative, serialize to H5.\n\n## Known Caveats\n\n*   TF Core:\n    *   A longstanding bug in `tf.while_loop`, which caused it to execute\n        sequentially, even when `parallel_iterations>1`, has now been fixed.\n        However, the increased parallelism may result in increased memory use.\n        Users who experience unwanted regressions should reset their\n        `while_loop`'s `parallel_iterations` value to 1, which is consistent\n        with prior behavior.\n\n## Major Features and Improvements\n\n*   `tf.keras`:\n\n    *   Keras has been split into a separate PIP package (`keras`), and its code\n        has been moved to the GitHub repository\n        [keras-team/keras](http://github.com/keras-team/keras). The API\n        endpoints for `tf.keras` stay unchanged, but are now backed by the\n        `keras` PIP package. All Keras-related PRs and issues should now be\n        directed to the GitHub repository.\n        [keras-team/keras](http://github.com/keras-team/keras).\n    *   `tf.keras.utils.experimental.DatasetCreator` now takes an optional\n        `tf.distribute.InputOptions` for specific options when used with\n        distribution.\n    *   `tf.keras.experimental.SidecarEvaluator` is now available for a program\n        intended to be run on an evaluator task, which is commonly used to\n        supplement a training cluster running with\n        `tf.distribute.experimental.ParameterServerStrategy` (see\n        `https://www.tensorflow.org/tutorials/distribute/parameter_server_training).\n        It can also be used with single-worker training or other strategies. See\n        docstring for more info.\n    *   Preprocessing layers moved from experimental to core.\n        *   Import paths moved from `tf.keras.layers.preprocessing.experimental`\n            to `tf.keras.layers`.\n    *   Updates to Preprocessing layers API for consistency and clarity:\n        *   `StringLookup` and `IntegerLookup` default for `mask_token` changed\n            to `None`. This matches the default masking behavior of `Hashing`\n            and `Embedding` layers. To keep existing behavior, pass\n            `mask_token=\"\"` during layer creation.\n        *   Renamed `\"binary\"` output mode to `\"multi_hot\"` for\n            `CategoryEncoding`, `StringLookup`, `IntegerLookup`, and\n            `TextVectorization`. Multi-hot encoding will no longer automatically\n            uprank rank 1 inputs, so these layers can now multi-hot encode\n            unbatched multi-dimensional samples.\n        *   Added a new output mode `\"one_hot\"` for `CategoryEncoding`,\n            `StringLookup`, `IntegerLookup`, which will encode each element in\n            an input batch individually, and automatically append a new output\n            dimension if necessary. Use this mode on rank 1 inputs for the old\n            `\"binary\"` behavior of one-hot encoding a batch of scalars.\n        *   `Normalization` will no longer automatically uprank rank 1 inputs,\n            allowing normalization of unbatched multi-dimensional samples.\n\n*   `tf.lite`:\n\n    *   The recommended Android NDK version for building TensorFlow Lite has\n        been changed from r18b to r19c.\n    *   Supports int64 for mul.\n    *   Supports native variable builtin ops - ReadVariable, AssignVariable.\n    *   Converter:\n        *   Experimental support for variables in TFLite. To enable through\n            conversion, users need to set\n            `experimental_enable_resource_variables` on tf.lite.TFLiteConverter\n            to True. Note: mutable variables is only available using\n            `from_saved_model` in this release, support for other methods is\n            coming soon.\n        *   Old Converter (TOCO) is getting removed from next release. It's been\n            deprecated for few releases already.\n\n*   `tf.saved_model`:\n\n    *   SavedModels can now save custom gradients. Use the option\n        `tf.saved_model.SaveOption(experimental_custom_gradients=True)` to\n        enable this feature. The documentation in\n        [Advanced autodiff](https://www.tensorflow.org/guide/advanced_autodiff#custom_gradients)\n        has been updated.\n    *   Object metadata has now been deprecated and no longer saved to the\n        SavedModel.\n\n*   TF Core:\n\n    *   Added `tf.config.experimental.reset_memory_stats` to reset the tracked\n        peak memory returned by `tf.config.experimental.get_memory_info`.\n\n*   `tf.data`:\n\n    *   Added `target_workers` param to `data_service_ops.from_dataset_id` and\n        `data_service_ops.distribute`. Users can specify `\"AUTO\"`, `\"ANY\"`, or\n        `\"LOCAL\"` (case insensitive). If `\"AUTO\"`, tf.data service runtime\n        decides which workers to read from. If `\"ANY\"`, TF workers read from any\n        tf.data service workers. If `\"LOCAL\"`, TF workers will only read from\n        local in-processs tf.data service workers. `\"AUTO\"` works well for most\n        cases, while users can specify other targets. For example, `\"LOCAL\"`\n        would help avoid RPCs and data copy if every TF worker colocates with a\n        tf.data service worker. Currently, `\"AUTO\"` reads from any tf.data\n        service workers to preserve existing behavior. The default value is\n        `\"AUTO\"`.\n\n## Bug Fixes and Other Changes\n\n*   TF Core:\n    *   Added `tf.lookup.experimental.MutableHashTable`, which provides a\n        generic mutable hash table implementation.\n        *   Compared to `tf.lookup.experimental.DenseHashTable` this offers\n            lower overall memory usage, and a cleaner API. It does not require\n            specifying a `delete_key` and `empty_key` that cannot be inserted\n            into the table.\n    *   Added support for specifying number of subdivisions in all reduce host\n        collective. This parallelizes work on CPU and speeds up the collective\n        performance. Default behavior is unchanged.\n    *   Add an option `perturb_singular` to `tf.linalg.tridiagonal_solve` that\n        allows solving linear systems with a numerically singular tridiagonal\n        matrix, e.g. for use in inverse iteration.\n    *   Added `tf.linalg.eigh_tridiagonal` that computes the eigenvalues of a\n        Hermitian tridiagonal matrix.\n    *   `tf.constant` now places its output on the current default device.\n    *   SavedModel\n        *   Added `tf.saved_model.experimental.TrackableResource`, which allows\n            the creation of custom wrapper objects for resource tensors.\n        *   Added a SavedModel load option to allow restoring partial\n            checkpoints into the SavedModel. See\n            [`tf.saved_model.LoadOptions`](https://www.tensorflow.org/api_docs/python/tf/saved_model/LoadOptions)\n            for details.\n    *   Added a new op `SparseSegmentSumGrad` to match the other sparse segment\n        gradient ops and avoid an extra gather operation that was in the\n        previous gradient implementation.\n    *   Added a new session config setting `internal_fragmentation_fraction`,\n        which controls when the BFC Allocator needs to split an oversized chunk\n        to satisfy an allocation request.\n    *   Added `tf.get_current_name_scope()` which returns the current full name\n        scope string that will be prepended to op names.\n*   `tf.data`:\n    *   Promoting `tf.data.experimental.bucket_by_sequence_length` API to\n        `tf.data.Dataset.bucket_by_sequence_length` and deprecating the\n        experimental endpoint.\n    *   Promoting `tf.data.experimental.get_single_element` API to\n        `tf.data.Dataset.get_single_element` and deprecating the experimental\n        endpoint.\n    *   Promoting `tf.data.experimental.group_by_window` API to\n        `tf.data.Dataset.group_by_window` and deprecating the experimental\n        endpoint.\n    *   Promoting `tf.data.experimental.RandomDataset` API to\n        `tf.data.Dataset.random` and deprecating the experimental endpoint.\n    *   Promoting `tf.data.experimental.scan` API to `tf.data.Dataset.scan` and\n        deprecating the experimental endpoint.\n    *   Promoting `tf.data.experimental.snapshot` API to\n        `tf.data.Dataset.shapshot` and deprecating the experimental endpoint.\n    *   Promoting `tf.data.experimental.take_while` API to\n        `tf.data.Dataset.take_while` and deprecating the experimental endpoint.\n    *   Promoting `tf.data.experimental.ThreadingOptions` API to\n        `tf.data.ThreadingOptions` and deprecating the experimental endpoint.\n    *   Promoting `tf.data.experimental.unique` API to `tf.data.Dataset.unique`\n        and deprecating the experimental endpoint.\n    *   Added `stop_on_empty_dataset` parameter to `sample_from_datasets` and\n        `choose_from_datasets`. Setting `stop_on_empty_dataset=True` will stop\n        sampling if it encounters an empty dataset. This preserves the sampling\n        ratio throughout training. The prior behavior was to continue sampling,\n        skipping over exhausted datasets, until all datasets are exhausted. By\n        default, the original behavior (`stop_on_empty_dataset=False`) is\n        preserved.\n    *   Removed previously deprecated tf.data statistics related APIs:\n        *   `tf.data.Options.experimental_stats`\n        *   `tf.data.experimental.StatsAggregator`\n        *   `tf.data.experimental.StatsOptions.*`\n        *   `tf.data.experimental.bytes_produced_stats`\n        *   `tf.data.experimental.latency_stats`\n    *   Removed the following experimental tf.data optimization APIs:\n        *   `tf.data.experimental.MapVectorizationOptions.*`\n        *   `tf.data.experimental.OptimizationOptions.filter_with_random_uniform_fusion`\n        *   `tf.data.experimental.OptimizationOptions.hoist_random_uniform`\n        *   `tf.data.experimental.OptimizationOptions.map_vectorization` *\n            `tf.data.experimental.OptimizationOptions.reorder_data_discarding_ops`\n*   `tf.keras`:\n    *   Fix usage of `__getitem__` slicing in Keras Functional APIs when the\n        inputs are `RaggedTensor` objects.\n    *   Add `keepdims` argument to all `GlobalPooling` layers.\n    *   Add `include_preprocessing` argument to `MobileNetV3` architectures to\n        control the inclusion of `Rescaling` layer in the model.\n    *   Add optional argument (`force`) to `make_(train|test|predict)_funtion`\n        methods to skip the cached function and generate a new one. This is\n        useful to regenerate in a single call the compiled training function\n        when any `.trainable` attribute of any model's layer has changed.\n    *   Models now have a `save_spec` property which contains the `TensorSpec`\n        specs for calling the model. This spec is automatically saved when the\n        model is called for the first time.\n*   `tf.linalg`:\n    *   Add `CompositeTensor` as a base class to `LinearOperator`.\n*   `tf.lite`:\n    *   Fix mean op reference quantization rounding issue.\n    *   Added `framework_stable` BUILD target, which links in only the\n        non-experimental TF Lite APIs.\n    *   Remove deprecated Java `Interpreter` methods:\n        *   `modifyGraphWithDelegate` - Use `Interpreter.Options.addDelegate`\n        *   `setNumThreads` - Use `Interpreter.Options.setNumThreads`\n    *   Add Conv3DTranspose as a builtin op.\n*   `tf.summary`:\n    *   Fix `tf.summary.should_record_summaries()` so it correctly reflects when\n        summaries will be written, even when `tf.summary.record_if()` is not n\n        effect, by returning True tensor if default writer is present.\n*   Grappler:\n    *   Disable default Grappler optimization timeout to make the optimization\n        pipeline deterministic. This may lead to increased model loading time,\n        because time spent in graph optimizations is now unbounded (was 20\n        minutes).\n*   Deterministic Op Functionality (enabled by setting `TF_DETERMINISTIC_OPS` to\n    `\"true\"` or `\"1\"`):\n    *   Add a deterministic GPU implementation of\n        `tf.nn.softmax_cross_entropy_with_logits`. See PR\n        [49178](https://github.com/tensorflow/tensorflow/pull/49178).\n    *   Add a deterministic CPU implementation of `tf.image.crop_and_resize`.\n        See PR [48905](https://github.com/tensorflow/tensorflow/pull/48905).\n    *   Add determinism-unimplemented exception-throwing to the following ops.\n        When op-determinism is expected, an attempt to use the specified paths\n        through the following ops on a GPU will cause\n        `tf.errors.UnimplementedError` (with an understandable message) to be\n        thrown.\n        *   `tf.nn.sparse_softmax_cross_entropy_with_logits` forwards and/or\n            backwards. See PR\n            [47925](https://github.com/tensorflow/tensorflow/pull/47925).\n        *   `tf.image.crop_and_resize` gradient w.r.t. either `image` or\n            `boxes`. See PR\n            [48905](https://github.com/tensorflow/tensorflow/pull/48905).\n        *   `tf.sparse.sparse_dense_matmul` forwards. See PR\n            [50355](https://github.com/tensorflow/tensorflow/pull/50355).\n\n## Security\n\n*   Fixes a heap out of bounds access in sparse reduction operations\n    ([CVE-2021-37635](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-37635))\n*   Fixes a floating point exception in `SparseDenseCwiseDiv`\n    ([CVE-2021-37636](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-37636))\n*   Fixes a null pointer dereference in `CompressElement`\n    ([CVE-2021-37637](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-37637))\n*   Fixes a null pointer dereference in `RaggedTensorToTensor`\n    ([CVE-2021-37638](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-37638))\n*   Fixes a null pointer dereference and a heap OOB read arising from operations\n    restoring tensors\n    ([CVE-2021-37639](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-37639))\n*   Fixes an integer division by 0 in sparse reshaping\n    ([CVE-2021-37640](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-37640))\n*   Fixes a division by 0 in `ResourceScatterDiv`\n    ([CVE-2021-37642](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-37642))\n*   Fixes a heap OOB in `RaggedGather`\n    ([CVE-2021-37641](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-37641))\n*   Fixes a `std::abort` raised from `TensorListReserve`\n    ([CVE-2021-37644](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-37644))\n*   Fixes a null pointer dereference in `MatrixDiagPartOp`\n    ([CVE-2021-37643](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-37643))\n*   Fixes an integer overflow due to conversion to unsigned\n    ([CVE-2021-37645](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-37645))\n*   Fixes a bad allocation error in `StringNGrams` caused by integer conversion\n    ([CVE-2021-37646](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-37646))\n*   Fixes a null pointer dereference in `SparseTensorSliceDataset`\n    ([CVE-2021-37647](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-37647))\n*   Fixes an incorrect validation of `SaveV2` inputs\n    ([CVE-2021-37648](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-37648))\n*   Fixes a null pointer dereference in `UncompressElement`\n    ([CVE-2021-37649](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-37649))\n*   Fixes a segfault and a heap buffer overflow in\n    `{Experimental,}DatasetToTFRecord`\n    ([CVE-2021-37650](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-37650))\n*   Fixes a heap buffer overflow in `FractionalAvgPoolGrad`\n    ([CVE-2021-37651](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-37651))\n*   Fixes a use after free in boosted trees creation\n    ([CVE-2021-37652](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-37652))\n*   Fixes a division by 0 in `ResourceGather`\n    ([CVE-2021-37653](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-37653))\n*   Fixes a heap OOB and a `CHECK` fail in `ResourceGather`\n    ([CVE-2021-37654](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-37654))\n*   Fixes a heap OOB in `ResourceScatterUpdate`\n    ([CVE-2021-37655](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-37655))\n*   Fixes an undefined behavior arising from reference binding to nullptr in\n    `RaggedTensorToSparse`\n    ([CVE-2021-37656](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-37656))\n*   Fixes an undefined behavior arising from reference binding to nullptr in\n    `MatrixDiagV*` ops\n    ([CVE-2021-37657](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-37657))\n*   Fixes an undefined behavior arising from reference binding to nullptr in\n    `MatrixSetDiagV*` ops\n    ([CVE-2021-37658](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-37658))\n*   Fixes an undefined behavior arising from reference binding to nullptr and\n    heap OOB in binary cwise ops\n    ([CVE-2021-37659](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-37659))\n*   Fixes a division by 0 in inplace operations\n    ([CVE-2021-37660](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-37660))\n*   Fixes a crash caused by integer conversion to unsigned\n    ([CVE-2021-37661](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-37661))\n*   Fixes an undefined behavior arising from reference binding to nullptr in\n    boosted trees\n    ([CVE-2021-37662](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-37662))\n*   Fixes a heap OOB in boosted trees\n    ([CVE-2021-37664](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-37664))\n*   Fixes vulnerabilities arising from incomplete validation in `QuantizeV2`\n    ([CVE-2021-37663](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-37663))\n*   Fixes vulnerabilities arising from incomplete validation in MKL\n    requantization\n    ([CVE-2021-37665](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-37665))\n*   Fixes an undefined behavior arising from reference binding to nullptr in\n    `RaggedTensorToVariant`\n    ([CVE-2021-37666](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-37666))\n*   Fixes an undefined behavior arising from reference binding to nullptr in\n    unicode encoding\n    ([CVE-2021-37667](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-37667))\n*   Fixes an FPE in `tf.raw_ops.UnravelIndex`\n    ([CVE-2021-37668](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-37668))\n*   Fixes a crash in NMS ops caused by integer conversion to unsigned\n    ([CVE-2021-37669](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-37669))\n*   Fixes a heap OOB in `UpperBound` and `LowerBound`\n    ([CVE-2021-37670](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-37670))\n*   Fixes an undefined behavior arising from reference binding to nullptr in map\n    operations\n    ([CVE-2021-37671](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-37671))\n*   Fixes a heap OOB in `SdcaOptimizerV2`\n    ([CVE-2021-37672](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-37672))\n*   Fixes a `CHECK`-fail in `MapStage`\n    ([CVE-2021-37673](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-37673))\n*   Fixes a vulnerability arising from incomplete validation in `MaxPoolGrad`\n    ([CVE-2021-37674](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-37674))\n*   Fixes an undefined behavior arising from reference binding to nullptr in\n    shape inference\n    ([CVE-2021-37676](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-37676))\n*   Fixes a division by 0 in most convolution operators\n    ([CVE-2021-37675](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-37675))\n*   Fixes vulnerabilities arising from missing validation in shape inference for\n    `Dequantize`\n    ([CVE-2021-37677](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-37677))\n*   Fixes an arbitrary code execution due to YAML deserialization\n    ([CVE-2021-37678](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-37678))\n*   Fixes a heap OOB in nested `tf.map_fn` with `RaggedTensor`s\n    ([CVE-2021-37679](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-37679))\n*   Fixes a division by zero in TFLite\n    ([CVE-2021-37680](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-37680))\n*   Fixes an NPE in TFLite\n    ([CVE-2021-37681](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-37681))\n*   Fixes a vulnerability arising from use of unitialized value in TFLite\n    ([CVE-2021-37682](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-37682))\n*   Fixes an FPE in TFLite division operations\n    ([CVE-2021-37683](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-37683))\n*   Fixes an FPE in TFLite pooling operations\n    ([CVE-2021-37684](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-37684))\n*   Fixes an infinite loop in TFLite\n    ([CVE-2021-37686](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-37686))\n*   Fixes a heap OOB in TFLite\n    ([CVE-2021-37685](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-37685))\n*   Fixes a heap OOB in TFLite's `Gather*` implementations\n    ([CVE-2021-37687](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-37687))\n*   Fixes an undefined behavior arising from null pointer dereference in TFLite\n    ([CVE-2021-37688](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-37688))\n*   Fixes an undefined behavior arising from null pointer dereference in TFLite\n    MLIR optimizations\n    ([CVE-2021-37689](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-37689))\n*   Fixes a FPE in LSH in TFLite\n    ([CVE-2021-37691](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-37691))\n*   Fixes a segfault on strings tensors with mismatched dimensions, arising in\n    Go code\n    ([CVE-2021-37692](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-37692))\n*   Fixes a use after free and a potential segfault in shape inference functions\n    ([CVE-2021-37690](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-37690))\n*   Updates `curl` to `7.77.0` to handle\n    [CVE-2021-22876](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-22876),\n    [CVE-2021-22897](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-22897),\n    [CVE-2021-22898](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-22898),\n    and\n    [CVE-2021-22901](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-22901).\n\n## Thanks to our Contributors\n\nThis release contains contributions from many people at Google, as well as:\n\nAadhitya A, Abhilash Mahendrakar, Abhishek Varma, Abin Shahab, Adam Hillier,\nAditya Kane, AdityaKane2001, ag.ramesh, Amogh Joshi, Armen Poghosov,\narmkevincheng, Avrosh K, Ayan Moitra, azazhu, Banikumar Maiti, Bas Aarts, bhack,\nBhanu Prakash Bandaru Venkata, Billy Cao, Bohumir Zamecnik, Bradley Reece,\nCyanXu, Daniel Situnayake, David Pal, Ddavis-2015, DEKHTIARJonathan, Deven\nDesai, Duncan Riach, Edward, Eli Osherovich, Eugene Kuznetsov, europeanplaice,\nevelynmitchell, Evgeniy Polyakov, Felix Vollmer, Florentin Hennecker, Franois\nChollet, Frederic Bastien, Fredrik Knutsson, Gabriele Macchi, Gaurav Shukla,\nGauri1 Deshpande, geetachavan1, Georgiy Manuilov, H, Hengwen Tong, Henri\nWoodcock, Hiran Sarkar, Ilya Arzhannikov, Janghoo Lee, jdematos, Jens Meder,\nJerry Shih, jgehw, Jim Fisher, Jingbei Li, Jiri Podivin, Joachim Gehweiler,\nJohannes Lade, Jonas I. Liechti, Jonas Liechti, Jonas Ohlsson, Jonathan\nDekhtiar, Julian Gross, Kaixi Hou, Kevin Cheng, Koan-Sin Tan, Kulin Seth,\nlinzewen, Liubov Batanina, luisleee, Lukas Geiger, Mahmoud Abuzaina, mathgaming,\nMatt Conley, Max H. Gerlach, mdfaijul, Mh Kwon, Michael Martis, Michal\nSzutenberg, Mns Nilsson, nammbash, Neil Girdhar, Nicholas Vadivelu, Nick\nKreeger, Nirjas Jakilim, okyanusoz, Patrice Vignola, Patrik Laurell, Pedro\nMarques, Philipp Hack, Phillip Cloud, Piergiacomo De Marchi, Prashant Kumar,\npuneeshkhanna, pvarouktsis, QQ, Rajeshwar Reddy T, Rama Ketineni, Reza Rahimi,\nRobert Kalmar, rsun, Ryan Kuester, Saduf2019, Sean Morgan, Sean Moriarity,\nShaochen Shi, Sheng, Yang, Shu Wang, Shuai Zhang, Soojeong, Stanley-Nod, Steven\nI Reeves, stevenireeves, Suraj Sudhir, Sven Mayer, Tamas Bela Feher,\ntashuang.zk, tcervi, Teng Lu, Thales Elero Cervi, Thibaut Goetghebuer-Planchon,\nThomas Walther, Till Brychcy, Trent Lo, Uday Bondhugula, vishakha.agrawal,\nVishnuvardhan Janapati, wamuir, Wenwen Ouyang, wenwu, Williard Joshua Jose,\nxiaohong1031, Xiaoming (Jason) Cui, Xinan Jiang, Yasir Modak, Yi Li, Yong Tang,\nzilinzhu, , \n\n# Release 2.5.2\n\nThis release introduces several vulnerability fixes:\n\n*   Fixes a code injection issue in `saved_model_cli`\n    ([CVE-2021-41228](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-41228))\n*   Fixes a vulnerability due to use of uninitialized value in Tensorflow\n    ([CVE-2021-41225](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-41225))\n*   Fixes a heap OOB in `FusedBatchNorm` kernels\n    ([CVE-2021-41223](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-41223))\n*   Fixes an arbitrary memory read in `ImmutableConst`\n    ([CVE-2021-41227](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-41227))\n*   Fixes a heap OOB in `SparseBinCount`\n    ([CVE-2021-41226](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-41226))\n*   Fixes a heap OOB in `SparseFillEmptyRows`\n    ([CVE-2021-41224](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-41224))\n*   Fixes a segfault due to negative splits in `SplitV`\n    ([CVE-2021-41222](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-41222))\n*   Fixes segfaults and vulnerabilities caused by accesses to invalid memory\n    during shape inference in `Cudnn*` ops\n    ([CVE-2021-41221](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-41221))\n*   Fixes a null pointer exception when `Exit` node is not preceded by `Enter`\n    op\n    ([CVE-2021-41217](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-41217))\n*   Fixes an integer division by 0 in `tf.raw_ops.AllToAll`\n    ([CVE-2021-41218](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-41218))\n*   Fixes an undefined behavior via `nullptr` reference binding in sparse matrix\n    multiplication\n    ([CVE-2021-41219](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-41219))\n*   Fixes a heap buffer overflow in `Transpose`\n    ([CVE-2021-41216](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-41216))\n*   Prevents deadlocks arising from mutually recursive `tf.function` objects\n    ([CVE-2021-41213](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-41213))\n*   Fixes a null pointer exception in `DeserializeSparse`\n    ([CVE-2021-41215](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-41215))\n*   Fixes an undefined behavior arising from reference binding to `nullptr` in\n    `tf.ragged.cross`\n    ([CVE-2021-41214](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-41214))\n*   Fixes a heap OOB read in `tf.ragged.cross`\n    ([CVE-2021-41212](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-41212))\n*   Fixes a heap OOB read in all `tf.raw_ops.QuantizeAndDequantizeV*` ops\n    ([CVE-2021-41205](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-41205))\n*   Fixes an FPE in `ParallelConcat`\n    ([CVE-2021-41207](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-41207))\n*   Fixes FPE issues in convolutions with zero size filters\n    ([CVE-2021-41209](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-41209))\n*   Fixes a heap OOB read in `tf.raw_ops.SparseCountSparseOutput`\n    ([CVE-2021-41210](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-41210))\n*   Fixes vulnerabilities caused by incomplete validation in boosted trees code\n    ([CVE-2021-41208](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-41208))\n*   Fixes vulnerabilities caused by incomplete validation of shapes in multiple\n    TF ops\n    ([CVE-2021-41206](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-41206))\n*   Fixes a segfault produced while copying constant resource tensor\n    ([CVE-2021-41204](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-41204))\n*   Fixes a vulnerability caused by unitialized access in\n    `EinsumHelper::ParseEquation`\n    ([CVE-2021-41201](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-41201))\n*   Fixes several vulnerabilities and segfaults caused by missing validation\n    during checkpoint loading\n    ([CVE-2021-41203](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-41203))\n*   Fixes an overflow producing a crash in `tf.range`\n    ([CVE-2021-41202](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-41202))\n*   Fixes an overflow producing a crash in `tf.image.resize` when size is large\n    ([CVE-2021-41199](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-41199))\n*   Fixes an overflow producing a crash in `tf.tile` when tiling tensor is large\n    ([CVE-2021-41198](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-41198))\n*   Fixes a vulnerability produced due to incomplete validation in\n    `tf.summary.create_file_writer`\n    ([CVE-2021-41200](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-41200))\n*   Fixes multiple crashes due to overflow and `CHECK`-fail in ops with large\n    tensor shapes\n    ([CVE-2021-41197](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-41197))\n*   Fixes a crash in `max_pool3d` when size argument is 0 or negative\n    ([CVE-2021-41196](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-41196))\n*   Fixes a crash in `tf.math.segment_*` operations\n    ([CVE-2021-41195](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-41195))\n*   Updates `curl` to `7.78.0` to handle\n    [CVE-2021-22922](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-22922),\n    [CVE-2021-22923](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-22923),\n    [CVE-2021-22924](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-22924),\n    [CVE-2021-22925](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-22925),\n    and\n    [CVE-2021-22926](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-22926).\n\n# Release 2.5.1\n\nThis release introduces several vulnerability fixes:\n\n*   Fixes a heap out of bounds access in sparse reduction operations\n    ([CVE-2021-37635](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-37635))\n*   Fixes a floating point exception in `SparseDenseCwiseDiv`\n    ([CVE-2021-37636](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-37636))\n*   Fixes a null pointer dereference in `CompressElement`\n    ([CVE-2021-37637](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-37637))\n*   Fixes a null pointer dereference in `RaggedTensorToTensor`\n    ([CVE-2021-37638](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-37638))\n*   Fixes a null pointer dereference and a heap OOB read arising from operations\n    restoring tensors\n    ([CVE-2021-37639](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-37639))\n*   Fixes an integer division by 0 in sparse reshaping\n    ([CVE-2021-37640](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-37640))\n*   Fixes a division by 0 in `ResourceScatterDiv`\n    ([CVE-2021-37642](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-37642))\n*   Fixes a heap OOB in `RaggedGather`\n    ([CVE-2021-37641](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-37641))\n*   Fixes a `std::abort` raised from `TensorListReserve`\n    ([CVE-2021-37644](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-37644))\n*   Fixes a null pointer dereference in `MatrixDiagPartOp`\n    ([CVE-2021-37643](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-37643))\n*   Fixes an integer overflow due to conversion to unsigned\n    ([CVE-2021-37645](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-37645))\n*   Fixes a bad allocation error in `StringNGrams` caused by integer conversion\n    ([CVE-2021-37646](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-37646))\n*   Fixes a null pointer dereference in `SparseTensorSliceDataset`\n    ([CVE-2021-37647](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-37647))\n*   Fixes an incorrect validation of `SaveV2` inputs\n    ([CVE-2021-37648](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-37648))\n*   Fixes a null pointer dereference in `UncompressElement`\n    ([CVE-2021-37649](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-37649))\n*   Fixes a segfault and a heap buffer overflow in\n    `{Experimental,}DatasetToTFRecord`\n    ([CVE-2021-37650](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-37650))\n*   Fixes a heap buffer overflow in `FractionalAvgPoolGrad`\n    ([CVE-2021-37651](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-37651))\n*   Fixes a use after free in boosted trees creation\n    ([CVE-2021-37652](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-37652))\n*   Fixes a division by 0 in `ResourceGather`\n    ([CVE-2021-37653](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-37653))\n*   Fixes a heap OOB and a `CHECK` fail in `ResourceGather`\n    ([CVE-2021-37654](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-37654))\n*   Fixes a heap OOB in `ResourceScatterUpdate`\n    ([CVE-2021-37655](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-37655))\n*   Fixes an undefined behavior arising from reference binding to nullptr in\n    `RaggedTensorToSparse`\n    ([CVE-2021-37656](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-37656))\n*   Fixes an undefined behavior arising from reference binding to nullptr in\n    `MatrixDiagV*` ops\n    ([CVE-2021-37657](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-37657))\n*   Fixes an undefined behavior arising from reference binding to nullptr in\n    `MatrixSetDiagV*` ops\n    ([CVE-2021-37658](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-37658))\n*   Fixes an undefined behavior arising from reference binding to nullptr and\n    heap OOB in binary cwise ops\n    ([CVE-2021-37659](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-37659))\n*   Fixes a division by 0 in inplace operations\n    ([CVE-2021-37660](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-37660))\n*   Fixes a crash caused by integer conversion to unsigned\n    ([CVE-2021-37661](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-37661))\n*   Fixes an undefined behavior arising from reference binding to nullptr in\n    boosted trees\n    ([CVE-2021-37662](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-37662))\n*   Fixes a heap OOB in boosted trees\n    ([CVE-2021-37664](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-37664))\n*   Fixes vulnerabilities arising from incomplete validation in `QuantizeV2`\n    ([CVE-2021-37663](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-37663))\n*   Fixes vulnerabilities arising from incomplete validation in MKL\n    requantization\n    ([CVE-2021-37665](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-37665))\n*   Fixes an undefined behavior arising from reference binding to nullptr in\n    `RaggedTensorToVariant`\n    ([CVE-2021-37666](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-37666))\n*   Fixes an undefined behavior arising from reference binding to nullptr in\n    unicode encoding\n    ([CVE-2021-37667](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-37667))\n*   Fixes an FPE in `tf.raw_ops.UnravelIndex`\n    ([CVE-2021-37668](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-37668))\n*   Fixes a crash in NMS ops caused by integer conversion to unsigned\n    ([CVE-2021-37669](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-37669))\n*   Fixes a heap OOB in `UpperBound` and `LowerBound`\n    ([CVE-2021-37670](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-37670))\n*   Fixes an undefined behavior arising from reference binding to nullptr in map\n    operations\n    ([CVE-2021-37671](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-37671))\n*   Fixes a heap OOB in `SdcaOptimizerV2`\n    ([CVE-2021-37672](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-37672))\n*   Fixes a `CHECK`-fail in `MapStage`\n    ([CVE-2021-37673](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-37673))\n*   Fixes a vulnerability arising from incomplete validation in `MaxPoolGrad`\n    ([CVE-2021-37674](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-37674))\n*   Fixes an undefined behavior arising from reference binding to nullptr in\n    shape inference\n    ([CVE-2021-37676](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-37676))\n*   Fixes a division by 0 in most convolution operators\n    ([CVE-2021-37675](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-37675))\n*   Fixes vulnerabilities arising from missing validation in shape inference for\n    `Dequantize`\n    ([CVE-2021-37677](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-37677))\n*   Fixes an arbitrary code execution due to YAML deserialization\n    ([CVE-2021-37678](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-37678))\n*   Fixes a heap OOB in nested `tf.map_fn` with `RaggedTensor`s\n    ([CVE-2021-37679](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-37679))\n*   Fixes a division by zero in TFLite\n    ([CVE-2021-37680](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-37680))\n*   Fixes an NPE in TFLite\n    ([CVE-2021-37681](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-37681))\n*   Fixes a vulnerability arising from use of unitialized value in TFLite\n    ([CVE-2021-37682](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-37682))\n*   Fixes an FPE in TFLite division operations\n    ([CVE-2021-37683](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-37683))\n*   Fixes an FPE in TFLite pooling operations\n    ([CVE-2021-37684](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-37684))\n*   Fixes an infinite loop in TFLite\n    ([CVE-2021-37686](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-37686))\n*   Fixes a heap OOB in TFLite\n    ([CVE-2021-37685](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-37685))\n*   Fixes a heap OOB in TFLite's `Gather*` implementations\n    ([CVE-2021-37687](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-37687))\n*   Fixes an undefined behavior arising from null pointer dereference in TFLite\n    ([CVE-2021-37688](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-37688))\n*   Fixes an undefined behavior arising from null pointer dereference in TFLite\n    MLIR optimizations\n    ([CVE-2021-37689](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-37689))\n*   Fixes a FPE in LSH in TFLite\n    ([CVE-2021-37691](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-37691))\n*   Fixes a segfault on strings tensors with mismatched dimensions, arising in\n    Go code\n    ([CVE-2021-37692](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-37692))\n*   Fixes a use after free and a potential segfault in shape inference functions\n    ([CVE-2021-37690](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-37690))\n*   Updates `curl` to `7.77.0` to handle\n    [CVE-2021-22876](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-22876),\n    [CVE-2021-22897](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-22897),\n    [CVE-2021-22898](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-22898),\n    and\n    [CVE-2021-22901](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-22901).\n\n# Release 2.4.4\n\nThis release introduces several vulnerability fixes:\n\n*   Fixes a code injection issue in `saved_model_cli`\n    ([CVE-2021-41228](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-41228))\n*   Fixes a vulnerability due to use of uninitialized value in Tensorflow\n    ([CVE-2021-41225](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-41225))\n*   Fixes a heap OOB in `FusedBatchNorm` kernels\n    ([CVE-2021-41223](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-41223))\n*   Fixes an arbitrary memory read in `ImmutableConst`\n    ([CVE-2021-41227](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-41227))\n*   Fixes a heap OOB in `SparseBinCount`\n    ([CVE-2021-41226](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-41226))\n*   Fixes a heap OOB in `SparseFillEmptyRows`\n    ([CVE-2021-41224](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-41224))\n*   Fixes a segfault due to negative splits in `SplitV`\n    ([CVE-2021-41222](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-41222))\n*   Fixes segfaults and vulnerabilities caused by accesses to invalid memory\n    during shape inference in `Cudnn*` ops\n    ([CVE-2021-41221](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-41221))\n*   Fixes a null pointer exception when `Exit` node is not preceded by `Enter`\n    op\n    ([CVE-2021-41217](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-41217))\n*   Fixes an integer division by 0 in `tf.raw_ops.AllToAll`\n    ([CVE-2021-41218](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-41218))\n*   Fixes an undefined behavior via `nullptr` reference binding in sparse matrix\n    multiplication\n    ([CVE-2021-41219](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-41219))\n*   Fixes a heap buffer overflow in `Transpose`\n    ([CVE-2021-41216](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-41216))\n*   Prevents deadlocks arising from mutually recursive `tf.function` objects\n    ([CVE-2021-41213](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-41213))\n*   Fixes a null pointer exception in `DeserializeSparse`\n    ([CVE-2021-41215](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-41215))\n*   Fixes an undefined behavior arising from reference binding to `nullptr` in\n    `tf.ragged.cross`\n    ([CVE-2021-41214](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-41214))\n*   Fixes a heap OOB read in `tf.ragged.cross`\n    ([CVE-2021-41212](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-41212))\n*   Fixes a heap OOB read in all `tf.raw_ops.QuantizeAndDequantizeV*` ops\n    ([CVE-2021-41205](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-41205))\n*   Fixes an FPE in `ParallelConcat`\n    ([CVE-2021-41207](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-41207))\n*   Fixes FPE issues in convolutions with zero size filters\n    ([CVE-2021-41209](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-41209))\n*   Fixes a heap OOB read in `tf.raw_ops.SparseCountSparseOutput`\n    ([CVE-2021-41210](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-41210))\n*   Fixes vulnerabilities caused by incomplete validation in boosted trees code\n    ([CVE-2021-41208](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-41208))\n*   Fixes vulnerabilities caused by incomplete validation of shapes in multiple\n    TF ops\n    ([CVE-2021-41206](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-41206))\n*   Fixes a segfault produced while copying constant resource tensor\n    ([CVE-2021-41204](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-41204))\n*   Fixes a vulnerability caused by unitialized access in\n    `EinsumHelper::ParseEquation`\n    ([CVE-2021-41201](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-41201))\n*   Fixes several vulnerabilities and segfaults caused by missing validation\n    during checkpoint loading\n    ([CVE-2021-41203](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-41203))\n*   Fixes an overflow producing a crash in `tf.range`\n    ([CVE-2021-41202](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-41202))\n*   Fixes an overflow producing a crash in `tf.image.resize` when size is large\n    ([CVE-2021-41199](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-41199))\n*   Fixes an overflow producing a crash in `tf.tile` when tiling tensor is large\n    ([CVE-2021-41198](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-41198))\n*   Fixes a vulnerability produced due to incomplete validation in\n    `tf.summary.create_file_writer`\n    ([CVE-2021-41200](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-41200))\n*   Fixes multiple crashes due to overflow and `CHECK`-fail in ops with large\n    tensor shapes\n    ([CVE-2021-41197](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-41197))\n*   Fixes a crash in `max_pool3d` when size argument is 0 or negative\n    ([CVE-2021-41196](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-41196))\n*   Fixes a crash in `tf.math.segment_*` operations\n    ([CVE-2021-41195](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-41195))\n*   Updates `curl` to `7.78.0` to handle\n    [CVE-2021-22922](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-22922),\n    [CVE-2021-22923](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-22923),\n    [CVE-2021-22924](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-22924),\n    [CVE-2021-22925](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-22925),\n    and\n    [CVE-2021-22926](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-22926).\n\n# Release 2.4.3\n\nThis release introduces several vulnerability fixes:\n\n*   Fixes a heap out of bounds access in sparse reduction operations\n    ([CVE-2021-37635](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-37635))\n*   Fixes a floating point exception in `SparseDenseCwiseDiv`\n    ([CVE-2021-37636](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-37636))\n*   Fixes a null pointer dereference in `CompressElement`\n    ([CVE-2021-37637](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-37637))\n*   Fixes a null pointer dereference in `RaggedTensorToTensor`\n    ([CVE-2021-37638](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-37638))\n*   Fixes a null pointer dereference and a heap OOB read arising from operations\n    restoring tensors\n    ([CVE-2021-37639](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-37639))\n*   Fixes an integer division by 0 in sparse reshaping\n    ([CVE-2021-37640](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-37640))\n*   Fixes a division by 0 in `ResourceScatterDiv`\n    ([CVE-2021-37642](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-37642))\n*   Fixes a heap OOB in `RaggedGather`\n    ([CVE-2021-37641](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-37641))\n*   Fixes a `std::abort` raised from `TensorListReserve`\n    ([CVE-2021-37644](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-37644))\n*   Fixes a null pointer dereference in `MatrixDiagPartOp`\n    ([CVE-2021-37643](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-37643))\n*   Fixes an integer overflow due to conversion to unsigned\n    ([CVE-2021-37645](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-37645))\n*   Fixes a bad allocation error in `StringNGrams` caused by integer conversion\n    ([CVE-2021-37646](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-37646))\n*   Fixes a null pointer dereference in `SparseTensorSliceDataset`\n    ([CVE-2021-37647](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-37647))\n*   Fixes an incorrect validation of `SaveV2` inputs\n    ([CVE-2021-37648](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-37648))\n*   Fixes a null pointer dereference in `UncompressElement`\n    ([CVE-2021-37649](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-37649))\n*   Fixes a segfault and a heap buffer overflow in\n    `{Experimental,}DatasetToTFRecord`\n    ([CVE-2021-37650](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-37650))\n*   Fixes a heap buffer overflow in `FractionalAvgPoolGrad`\n    ([CVE-2021-37651](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-37651))\n*   Fixes a use after free in boosted trees creation\n    ([CVE-2021-37652](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-37652))\n*   Fixes a division by 0 in `ResourceGather`\n    ([CVE-2021-37653](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-37653))\n*   Fixes a heap OOB and a `CHECK` fail in `ResourceGather`\n    ([CVE-2021-37654](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-37654))\n*   Fixes a heap OOB in `ResourceScatterUpdate`\n    ([CVE-2021-37655](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-37655))\n*   Fixes an undefined behavior arising from reference binding to nullptr in\n    `RaggedTensorToSparse`\n    ([CVE-2021-37656](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-37656))\n*   Fixes an undefined behavior arising from reference binding to nullptr in\n    `MatrixDiagV*` ops\n    ([CVE-2021-37657](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-37657))\n*   Fixes an undefined behavior arising from reference binding to nullptr in\n    `MatrixSetDiagV*` ops\n    ([CVE-2021-37658](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-37658))\n*   Fixes an undefined behavior arising from reference binding to nullptr and\n    heap OOB in binary cwise ops\n    ([CVE-2021-37659](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-37659))\n*   Fixes a division by 0 in inplace operations\n    ([CVE-2021-37660](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-37660))\n*   Fixes a crash caused by integer conversion to unsigned\n    ([CVE-2021-37661](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-37661))\n*   Fixes an undefined behavior arising from reference binding to nullptr in\n    boosted trees\n    ([CVE-2021-37662](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-37662))\n*   Fixes a heap OOB in boosted trees\n    ([CVE-2021-37664](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-37664))\n*   Fixes vulnerabilities arising from incomplete validation in `QuantizeV2`\n    ([CVE-2021-37663](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-37663))\n*   Fixes vulnerabilities arising from incomplete validation in MKL\n    requantization\n    ([CVE-2021-37665](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-37665))\n*   Fixes an undefined behavior arising from reference binding to nullptr in\n    `RaggedTensorToVariant`\n    ([CVE-2021-37666](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-37666))\n*   Fixes an undefined behavior arising from reference binding to nullptr in\n    unicode encoding\n    ([CVE-2021-37667](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-37667))\n*   Fixes an FPE in `tf.raw_ops.UnravelIndex`\n    ([CVE-2021-37668](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-37668))\n*   Fixes a crash in NMS ops caused by integer conversion to unsigned\n    ([CVE-2021-37669](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-37669))\n*   Fixes a heap OOB in `UpperBound` and `LowerBound`\n    ([CVE-2021-37670](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-37670))\n*   Fixes an undefined behavior arising from reference binding to nullptr in map\n    operations\n    ([CVE-2021-37671](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-37671))\n*   Fixes a heap OOB in `SdcaOptimizerV2`\n    ([CVE-2021-37672](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-37672))\n*   Fixes a `CHECK`-fail in `MapStage`\n    ([CVE-2021-37673](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-37673))\n*   Fixes a vulnerability arising from incomplete validation in `MaxPoolGrad`\n    ([CVE-2021-37674](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-37674))\n*   Fixes an undefined behavior arising from reference binding to nullptr in\n    shape inference\n    ([CVE-2021-37676](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-37676))\n*   Fixes a division by 0 in most convolution operators\n    ([CVE-2021-37675](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-37675))\n*   Fixes vulnerabilities arising from missing validation in shape inference for\n    `Dequantize`\n    ([CVE-2021-37677](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-37677))\n*   Fixes an arbitrary code execution due to YAML deserialization\n    ([CVE-2021-37678](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-37678))\n*   Fixes a heap OOB in nested `tf.map_fn` with `RaggedTensor`s\n    ([CVE-2021-37679](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-37679))\n*   Fixes a division by zero in TFLite\n    ([CVE-2021-37680](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-37680))\n*   Fixes an NPE in TFLite\n    ([CVE-2021-37681](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-37681))\n*   Fixes a vulnerability arising from use of unitialized value in TFLite\n    ([CVE-2021-37682](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-37682))\n*   Fixes an FPE in TFLite division operations\n    ([CVE-2021-37683](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-37683))\n*   Fixes an FPE in TFLite pooling operations\n    ([CVE-2021-37684](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-37684))\n*   Fixes an infinite loop in TFLite\n    ([CVE-2021-37686](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-37686))\n*   Fixes a heap OOB in TFLite\n    ([CVE-2021-37685](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-37685))\n*   Fixes a heap OOB in TFLite's `Gather*` implementations\n    ([CVE-2021-37687](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-37687))\n*   Fixes an undefined behavior arising from null pointer dereference in TFLite\n    ([CVE-2021-37688](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-37688))\n*   Fixes an undefined behavior arising from null pointer dereference in TFLite\n    MLIR optimizations\n    ([CVE-2021-37689](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-37689))\n*   Fixes a FPE in LSH in TFLite\n    ([CVE-2021-37691](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-37691))\n*   Fixes a segfault on strings tensors with mismatched dimensions, arising in\n    Go code\n    ([CVE-2021-37692](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-37692))\n*   Fixes a use after free and a potential segfault in shape inference functions\n    ([CVE-2021-37690](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-37690))\n*   Updates `curl` to `7.77.0` to handle\n    [CVE-2021-22876](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-22876),\n    [CVE-2021-22897](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-22897),\n    [CVE-2021-22898](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-22898),\n    and\n    [CVE-2021-22901](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-22901).\n\n# Release 2.3.4\n\nThis release introduces several vulnerability fixes:\n\n*   Fixes a heap out of bounds access in sparse reduction operations\n    ([CVE-2021-37635](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-37635))\n*   Fixes a floating point exception in `SparseDenseCwiseDiv`\n    ([CVE-2021-37636](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-37636))\n*   Fixes a null pointer dereference in `CompressElement`\n    ([CVE-2021-37637](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-37637))\n*   Fixes a null pointer dereference in `RaggedTensorToTensor`\n    ([CVE-2021-37638](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-37638))\n*   Fixes a null pointer dereference and a heap OOB read arising from operations\n    restoring tensors\n    ([CVE-2021-37639](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-37639))\n*   Fixes an integer division by 0 in sparse reshaping\n    ([CVE-2021-37640](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-37640))\n*   Fixes a division by 0 in `ResourceScatterDiv`\n    ([CVE-2021-37642](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-37642))\n*   Fixes a heap OOB in `RaggedGather`\n    ([CVE-2021-37641](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-37641))\n*   Fixes a `std::abort` raised from `TensorListReserve`\n    ([CVE-2021-37644](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-37644))\n*   Fixes a null pointer dereference in `MatrixDiagPartOp`\n    ([CVE-2021-37643](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-37643))\n*   Fixes an integer overflow due to conversion to unsigned\n    ([CVE-2021-37645](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-37645))\n*   Fixes a bad allocation error in `StringNGrams` caused by integer conversion\n    ([CVE-2021-37646](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-37646))\n*   Fixes a null pointer dereference in `SparseTensorSliceDataset`\n    ([CVE-2021-37647](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-37647))\n*   Fixes an incorrect validation of `SaveV2` inputs\n    ([CVE-2021-37648](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-37648))\n*   Fixes a null pointer dereference in `UncompressElement`\n    ([CVE-2021-37649](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-37649))\n*   Fixes a segfault and a heap buffer overflow in\n    `{Experimental,}DatasetToTFRecord`\n    ([CVE-2021-37650](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-37650))\n*   Fixes a heap buffer overflow in `FractionalAvgPoolGrad`\n    ([CVE-2021-37651](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-37651))\n*   Fixes a use after free in boosted trees creation\n    ([CVE-2021-37652](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-37652))\n*   Fixes a division by 0 in `ResourceGather`\n    ([CVE-2021-37653](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-37653))\n*   Fixes a heap OOB and a `CHECK` fail in `ResourceGather`\n    ([CVE-2021-37654](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-37654))\n*   Fixes a heap OOB in `ResourceScatterUpdate`\n    ([CVE-2021-37655](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-37655))\n*   Fixes an undefined behavior arising from reference binding to nullptr in\n    `RaggedTensorToSparse`\n    ([CVE-2021-37656](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-37656))\n*   Fixes an undefined behavior arising from reference binding to nullptr in\n    `MatrixDiagV*` ops\n    ([CVE-2021-37657](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-37657))\n*   Fixes an undefined behavior arising from reference binding to nullptr in\n    `MatrixSetDiagV*` ops\n    ([CVE-2021-37658](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-37658))\n*   Fixes an undefined behavior arising from reference binding to nullptr and\n    heap OOB in binary cwise ops\n    ([CVE-2021-37659](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-37659))\n*   Fixes a division by 0 in inplace operations\n    ([CVE-2021-37660](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-37660))\n*   Fixes a crash caused by integer conversion to unsigned\n    ([CVE-2021-37661](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-37661))\n*   Fixes an undefined behavior arising from reference binding to nullptr in\n    boosted trees\n    ([CVE-2021-37662](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-37662))\n*   Fixes a heap OOB in boosted trees\n    ([CVE-2021-37664](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-37664))\n*   Fixes vulnerabilities arising from incomplete validation in `QuantizeV2`\n    ([CVE-2021-37663](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-37663))\n*   Fixes vulnerabilities arising from incomplete validation in MKL\n    requantization\n    ([CVE-2021-37665](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-37665))\n*   Fixes an undefined behavior arising from reference binding to nullptr in\n    `RaggedTensorToVariant`\n    ([CVE-2021-37666](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-37666))\n*   Fixes an undefined behavior arising from reference binding to nullptr in\n    unicode encoding\n    ([CVE-2021-37667](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-37667))\n*   Fixes an FPE in `tf.raw_ops.UnravelIndex`\n    ([CVE-2021-37668](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-37668))\n*   Fixes a crash in NMS ops caused by integer conversion to unsigned\n    ([CVE-2021-37669](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-37669))\n*   Fixes a heap OOB in `UpperBound` and `LowerBound`\n    ([CVE-2021-37670](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-37670))\n*   Fixes an undefined behavior arising from reference binding to nullptr in map\n    operations\n    ([CVE-2021-37671](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-37671))\n*   Fixes a heap OOB in `SdcaOptimizerV2`\n    ([CVE-2021-37672](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-37672))\n*   Fixes a `CHECK`-fail in `MapStage`\n    ([CVE-2021-37673](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-37673))\n*   Fixes a vulnerability arising from incomplete validation in `MaxPoolGrad`\n    ([CVE-2021-37674](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-37674))\n*   Fixes an undefined behavior arising from reference binding to nullptr in\n    shape inference\n    ([CVE-2021-37676](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-37676))\n*   Fixes a division by 0 in most convolution operators\n    ([CVE-2021-37675](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-37675))\n*   Fixes vulnerabilities arising from missing validation in shape inference for\n    `Dequantize`\n    ([CVE-2021-37677](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-37677))\n*   Fixes an arbitrary code execution due to YAML deserialization\n    ([CVE-2021-37678](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-37678))\n*   Fixes a heap OOB in nested `tf.map_fn` with `RaggedTensor`s\n    ([CVE-2021-37679](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-37679))\n*   Fixes a division by zero in TFLite\n    ([CVE-2021-37680](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-37680))\n*   Fixes an NPE in TFLite\n    ([CVE-2021-37681](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-37681))\n*   Fixes a vulnerability arising from use of unitialized value in TFLite\n    ([CVE-2021-37682](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-37682))\n*   Fixes an FPE in TFLite division operations\n    ([CVE-2021-37683](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-37683))\n*   Fixes an FPE in TFLite pooling operations\n    ([CVE-2021-37684](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-37684))\n*   Fixes an infinite loop in TFLite\n    ([CVE-2021-37686](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-37686))\n*   Fixes a heap OOB in TFLite\n    ([CVE-2021-37685](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-37685))\n*   Fixes a heap OOB in TFLite's `Gather*` implementations\n    ([CVE-2021-37687](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-37687))\n*   Fixes an undefined behavior arising from null pointer dereference in TFLite\n    ([CVE-2021-37688](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-37688))\n*   Fixes an undefined behavior arising from null pointer dereference in TFLite\n    MLIR optimizations\n    ([CVE-2021-37689](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-37689))\n*   Fixes a FPE in LSH in TFLite\n    ([CVE-2021-37691](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-37691))\n*   Fixes a segfault on strings tensors with mismatched dimensions, arising in\n    Go code\n    ([CVE-2021-37692](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-37692))\n*   Fixes a use after free and a potential segfault in shape inference functions\n    ([CVE-2021-37690](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-37690))\n*   Updates `curl` to `7.77.0` to handle\n    [CVE-2021-22876](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-22876),\n    [CVE-2021-22897](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-22897),\n    [CVE-2021-22898](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-22898),\n    and\n    [CVE-2021-22901](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-22901).\n\n# Release 2.4.2\n\nThis release introduces several vulnerability fixes:\n\n*   Fixes a heap buffer overflow in `RaggedBinCount`\n    ([CVE-2021-29512](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29512))\n*   Fixes a heap out of bounds write in `RaggedBinCount`\n    ([CVE-2021-29514](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29514))\n*   Fixes a type confusion during tensor casts which leads to dereferencing null\n    pointers\n    ([CVE-2021-29513](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29513))\n*   Fixes a reference binding to null pointer in `MatrixDiag*` ops\n    ([CVE-2021-29515](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29515))\n*   Fixes a null pointer dereference via invalid Ragged Tensors\n    ([CVE-2021-29516](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29516))\n*   Fixes a division by zero in `Conv3D`\n    ([CVE-2021-29517](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29517))\n*   Fixes vulnerabilities where session operations in eager mode lead to null\n    pointer dereferences\n    ([CVE-2021-29518](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29518))\n*   Fixes a `CHECK`-fail in `SparseCross` caused by type confusion\n    ([CVE-2021-29519](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29519))\n*   Fixes a segfault in `SparseCountSparseOutput`\n    ([CVE-2021-29521](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29521))\n*   Fixes a heap buffer overflow in `Conv3DBackprop*`\n    ([CVE-2021-29520](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29520))\n*   Fixes a division by 0 in `Conv3DBackprop*`\n    ([CVE-2021-29522](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29522))\n*   Fixes a `CHECK`-fail in `AddManySparseToTensorsMap`\n    ([CVE-2021-29523](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29523))\n*   Fixes a division by 0 in `Conv2DBackpropFilter`\n    ([CVE-2021-29524](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29524))\n*   Fixes a division by 0 in `Conv2DBackpropInput`\n    ([CVE-2021-29525](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29525))\n*   Fixes a division by 0 in `Conv2D`\n    ([CVE-2021-29526](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29526))\n*   Fixes a division by 0 in `QuantizedConv2D`\n    ([CVE-2021-29527](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29527))\n*   Fixes a division by 0 in `QuantizedMul`\n    ([CVE-2021-29528](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29528))\n*   Fixes vulnerabilities caused by invalid validation in\n    `SparseMatrixSparseCholesky`\n    ([CVE-2021-29530](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29530))\n*   Fixes a heap buffer overflow caused by rounding\n    ([CVE-2021-29529](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29529))\n*   Fixes a `CHECK`-fail in `tf.raw_ops.EncodePng`\n    ([CVE-2021-29531](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29531))\n*   Fixes a heap out of bounds read in `RaggedCross`\n    ([CVE-2021-29532](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29532))\n*   Fixes a `CHECK`-fail in `DrawBoundingBoxes`\n    ([CVE-2021-29533](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29533))\n*   Fixes a heap buffer overflow in `QuantizedMul`\n    ([CVE-2021-29535](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29535))\n*   Fixes a `CHECK`-fail in `SparseConcat`\n    ([CVE-2021-29534](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29534))\n*   Fixes a heap buffer overflow in `QuantizedResizeBilinear`\n    ([CVE-2021-29537](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29537))\n*   Fixes a heap buffer overflow in `QuantizedReshape`\n    ([CVE-2021-29536](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29536))\n*   Fixes a division by zero in `Conv2DBackpropFilter`\n    ([CVE-2021-29538](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29538))\n*   Fixes a heap buffer overflow in `Conv2DBackpropFilter`\n    ([CVE-2021-29540](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29540))\n*   Fixes a heap buffer overflow in `StringNGrams`\n    ([CVE-2021-29542](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29542))\n*   Fixes a null pointer dereference in `StringNGrams`\n    ([CVE-2021-29541](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29541))\n*   Fixes a `CHECK`-fail in `QuantizeAndDequantizeV4Grad`\n    ([CVE-2021-29544](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29544))\n*   Fixes a `CHECK`-fail in `CTCGreedyDecoder`\n    ([CVE-2021-29543](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29543))\n*   Fixes a heap buffer overflow in `SparseTensorToCSRSparseMatrix`\n    ([CVE-2021-29545](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29545))\n*   Fixes a division by 0 in `QuantizedBiasAdd`\n    ([CVE-2021-29546](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29546))\n*   Fixes a heap out of bounds in `QuantizedBatchNormWithGlobalNormalization`\n    ([CVE-2021-29547](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29547))\n*   Fixes a division by 0 in `QuantizedBatchNormWithGlobalNormalization`\n    ([CVE-2021-29548](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29548))\n*   Fixes a division by 0 in `QuantizedAdd`\n    ([CVE-2021-29549](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29549))\n*   Fixes a division by 0 in `FractionalAvgPool`\n    ([CVE-2021-29550](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29550))\n*   Fixes an OOB read in `MatrixTriangularSolve`\n    ([CVE-2021-29551](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29551))\n*   Fixes a heap OOB in `QuantizeAndDequantizeV3`\n    ([CVE-2021-29553](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29553))\n*   Fixes a `CHECK`-failure in `UnsortedSegmentJoin`\n    ([CVE-2021-29552](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29552))\n*   Fixes a division by 0 in `DenseCountSparseOutput`\n    ([CVE-2021-29554](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29554))\n*   Fixes a division by 0 in `FusedBatchNorm`\n    ([CVE-2021-29555](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29555))\n*   Fixes a division by 0 in `SparseMatMul`\n    ([CVE-2021-29557](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29557))\n*   Fixes a division by 0 in `Reverse`\n    ([CVE-2021-29556](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29556))\n*   Fixes a heap buffer overflow in `SparseSplit`\n    ([CVE-2021-29558](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29558))\n*   Fixes a heap OOB access in unicode ops\n    ([CVE-2021-29559](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29559))\n*   Fixes a heap buffer overflow in `RaggedTensorToTensor`\n    ([CVE-2021-29560](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29560))\n*   Fixes a `CHECK`-fail in `LoadAndRemapMatrix`\n    ([CVE-2021-29561](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29561))\n*   Fixes a `CHECK`-fail in `tf.raw_ops.IRFFT`\n    ([CVE-2021-29562](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29562))\n*   Fixes a `CHECK`-fail in `tf.raw_ops.RFFT`\n    ([CVE-2021-29563](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29563))\n*   Fixes a null pointer dereference in `EditDistance`\n    ([CVE-2021-29564](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29564))\n*   Fixes a null pointer dereference in `SparseFillEmptyRows`\n    ([CVE-2021-29565](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29565))\n*   Fixes a heap OOB access in `Dilation2DBackpropInput`\n    ([CVE-2021-29566](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29566))\n*   Fixes a reference binding to null in `ParameterizedTruncatedNormal`\n    ([CVE-2021-29568](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29568))\n*   Fixes a set of vulnerabilities caused by lack of validation in\n    `SparseDenseCwiseMul`\n    ([CVE-2021-29567](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29567))\n*   Fixes a heap out of bounds read in `MaxPoolGradWithArgmax`\n    ([CVE-2021-29570](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29570))\n*   Fixes a heap out of bounds read in `RequantizationRange`\n    ([CVE-2021-29569](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29569))\n*   Fixes a memory corruption in `DrawBoundingBoxesV2`\n    ([CVE-2021-29571](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29571))\n*   Fixes a reference binding to nullptr in `SdcaOptimizer`\n    ([CVE-2021-29572](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29572))\n*   Fixes an overflow and a denial of service in `tf.raw_ops.ReverseSequence`\n    ([CVE-2021-29575](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29575))\n*   Fixes a division by 0 in `MaxPoolGradWithArgmax`\n    ([CVE-2021-29573](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29573))\n*   Fixes an undefined behavior in `MaxPool3DGradGrad`\n    ([CVE-2021-29574](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29574))\n*   Fixes a heap buffer overflow in `MaxPool3DGradGrad`\n    ([CVE-2021-29576](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29576))\n*   Fixes a heap buffer overflow in `AvgPool3DGrad`\n    ([CVE-2021-29577](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29577))\n*   Fixes an undefined behavior and a `CHECK`-fail in `FractionalMaxPoolGrad`\n    ([CVE-2021-29580](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29580))\n*   Fixes a heap buffer overflow in `FractionalAvgPoolGrad`\n    ([CVE-2021-29578](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29578))\n*   Fixes a heap buffer overflow in `MaxPoolGrad`\n    ([CVE-2021-29579](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29579))\n*   Fixes a segfault in `CTCBeamSearchDecoder`\n    ([CVE-2021-29581](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29581))\n*   Fixes a heap OOB read in `tf.raw_ops.Dequantize`\n    ([CVE-2021-29582](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29582))\n*   Fixes a `CHECK`-fail due to integer overflow\n    ([CVE-2021-29584](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29584))\n*   Fixes a heap buffer overflow and undefined behavior in `FusedBatchNorm`\n    ([CVE-2021-29583](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29583))\n*   Fixes a division by zero in padding computation in TFLite\n    ([CVE-2021-29585](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29585))\n*   Fixes a division by zero in optimized pooling implementations in TFLite\n    ([CVE-2021-29586](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29586))\n*   Fixes a division by zero in TFLite's implementation of `SpaceToDepth`\n    ([CVE-2021-29587](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29587))\n*   Fixes a division by zero in TFLite's implementation of `GatherNd`\n    ([CVE-2021-29589](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29589))\n*   Fixes a division by zero in TFLite's implementation of `TransposeConv`\n    ([CVE-2021-29588](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29588))\n*   Fixes a heap OOB read in TFLite's implementation of `Minimum` or `Maximum`\n    ([CVE-2021-29590](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29590))\n*   Fixes a null pointer dereference in TFLite's `Reshape` operator\n    ([CVE-2021-29592](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29592))\n*   Fixes a stack overflow due to looping TFLite subgraph\n    ([CVE-2021-29591](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29591))\n*   Fixes a division by zero in TFLite's implementation of `DepthToSpace`\n    ([CVE-2021-29595](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29595))\n*   Fixes a division by zero in TFLite's convolution code\n    ([CVE-2021-29594](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29594))\n*   Fixes a division by zero in TFLite's implementation of `EmbeddingLookup`\n    ([CVE-2021-29596](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29596))\n*   Fixes a division by zero in TFLite's implementation of `BatchToSpaceNd`\n    ([CVE-2021-29593](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29593))\n*   Fixes a division by zero in TFLite's implementation of `SpaceToBatchNd`\n    ([CVE-2021-29597](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29597))\n*   Fixes a division by zero in TFLite's implementation of `SVDF`\n    ([CVE-2021-29598](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29598))\n*   Fixes a division by zero in TFLite's implementation of `Split`\n    ([CVE-2021-29599](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29599))\n*   Fixes a division by zero in TFLite's implementation of `OneHot`\n    ([CVE-2021-29600](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29600))\n*   Fixes a division by zero in TFLite's implementation of `DepthwiseConv`\n    ([CVE-2021-29602](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29602))\n*   Fixes a division by zero in TFLite's implementation of hashtable lookup\n    ([CVE-2021-29604](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29604))\n*   Fixes a integer overflow in TFLite concatentation\n    ([CVE-2021-29601](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29601))\n*   Fixes a integer overflow in TFLite memory allocation\n    ([CVE-2021-29605](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29605))\n*   Fixes a heap OOB write in TFLite\n    ([CVE-2021-29603](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29603))\n*   Fixes a heap OOB read in TFLite\n    ([CVE-2021-29606](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29606))\n*   Fixes a heap OOB and null pointer dereference in `RaggedTensorToTensor`\n    ([CVE-2021-29608](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29608))\n*   Fixes vulnerabilities caused by incomplete validation in `SparseAdd`\n    ([CVE-2021-29609](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29609))\n*   Fixes vulnerabilities caused by incomplete validation in\n    `SparseSparseMinimum`\n    ([CVE-2021-29607](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29607))\n*   Fixes vulnerabilities caused by incomplete validation in `SparseReshape`\n    ([CVE-2021-29611](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29611))\n*   Fixes vulnerabilities caused by invalid validation in\n    `QuantizeAndDequantizeV2`\n    ([CVE-2021-29610](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29610))\n*   Fixes a heap buffer overflow in `BandedTriangularSolve`\n    ([CVE-2021-29612](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29612))\n*   Fixes vulnerabilities caused by incomplete validation in\n    `tf.raw_ops.CTCLoss`\n    ([CVE-2021-29613](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29613))\n*   Fixes an interpreter crash from vulnerabilities in `tf.io.decode_raw`\n    ([CVE-2021-29614](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29614))\n*   Fixes a stack overflow in `ParseAttrValue` with nested tensors\n    ([CVE-2021-29615](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29615))\n*   Fixes a null dereference in Grappler's `TrySimplify`\n    ([CVE-2021-29616](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29616))\n*   Fixes a crash in `tf.transpose` with complex inputs\n    ([CVE-2021-29618](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29618))\n*   Fixes a crash in `tf.strings.substr` due to `CHECK`-fail\n    ([CVE-2021-29617](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29617))\n*   Fixes a segfault in `tf.raw_ops.SparseCountSparseOutput`\n    ([CVE-2021-29619](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29619))\n*   Fixes a segfault in `tf.raw_ops.ImmutableConst`\n    ([CVE-2021-29539](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29539))\n*   Updates `curl` to `7.76.0` to handle\n    [CVE-2020-8169](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2020-8169),\n    [CVE-2020-8177](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2020-8177),\n    [CVE-2020-8231](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2020-8231),\n    [CVE-2020-8284](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2020-8284),\n    [CVE-2020-8285](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2020-8285)\n    and\n    [CVE-2020-8286](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2020-8286).\n\n# Release 2.3.3\n\nThis release introduces several vulnerability fixes:\n\n*   Fixes a heap buffer overflow in `RaggedBinCount`\n    ([CVE-2021-29512](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29512))\n*   Fixes a heap out of bounds write in `RaggedBinCount`\n    ([CVE-2021-29514](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29514))\n*   Fixes a type confusion during tensor casts which leads to dereferencing null\n    pointers\n    ([CVE-2021-29513](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29513))\n*   Fixes a reference binding to null pointer in `MatrixDiag*` ops\n    ([CVE-2021-29515](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29515))\n*   Fixes a null pointer dereference via invalid Ragged Tensors\n    ([CVE-2021-29516](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29516))\n*   Fixes a division by zero in `Conv3D`\n    ([CVE-2021-29517](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29517))\n*   Fixes vulnerabilities where session operations in eager mode lead to null\n    pointer dereferences\n    ([CVE-2021-29518](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29518))\n*   Fixes a `CHECK`-fail in `SparseCross` caused by type confusion\n    ([CVE-2021-29519](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29519))\n*   Fixes a segfault in `SparseCountSparseOutput`\n    ([CVE-2021-29521](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29521))\n*   Fixes a heap buffer overflow in `Conv3DBackprop*`\n    ([CVE-2021-29520](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29520))\n*   Fixes a division by 0 in `Conv3DBackprop*`\n    ([CVE-2021-29522](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29522))\n*   Fixes a `CHECK`-fail in `AddManySparseToTensorsMap`\n    ([CVE-2021-29523](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29523))\n*   Fixes a division by 0 in `Conv2DBackpropFilter`\n    ([CVE-2021-29524](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29524))\n*   Fixes a division by 0 in `Conv2DBackpropInput`\n    ([CVE-2021-29525](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29525))\n*   Fixes a division by 0 in `Conv2D`\n    ([CVE-2021-29526](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29526))\n*   Fixes a division by 0 in `QuantizedConv2D`\n    ([CVE-2021-29527](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29527))\n*   Fixes a division by 0 in `QuantizedMul`\n    ([CVE-2021-29528](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29528))\n*   Fixes vulnerabilities caused by invalid validation in\n    `SparseMatrixSparseCholesky`\n    ([CVE-2021-29530](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29530))\n*   Fixes a heap buffer overflow caused by rounding\n    ([CVE-2021-29529](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29529))\n*   Fixes a `CHECK`-fail in `tf.raw_ops.EncodePng`\n    ([CVE-2021-29531](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29531))\n*   Fixes a heap out of bounds read in `RaggedCross`\n    ([CVE-2021-29532](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29532))\n*   Fixes a `CHECK`-fail in `DrawBoundingBoxes`\n    ([CVE-2021-29533](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29533))\n*   Fixes a heap buffer overflow in `QuantizedMul`\n    ([CVE-2021-29535](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29535))\n*   Fixes a `CHECK`-fail in `SparseConcat`\n    ([CVE-2021-29534](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29534))\n*   Fixes a heap buffer overflow in `QuantizedResizeBilinear`\n    ([CVE-2021-29537](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29537))\n*   Fixes a heap buffer overflow in `QuantizedReshape`\n    ([CVE-2021-29536](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29536))\n*   Fixes a division by zero in `Conv2DBackpropFilter`\n    ([CVE-2021-29538](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29538))\n*   Fixes a heap buffer overflow in `Conv2DBackpropFilter`\n    ([CVE-2021-29540](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29540))\n*   Fixes a heap buffer overflow in `StringNGrams`\n    ([CVE-2021-29542](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29542))\n*   Fixes a null pointer dereference in `StringNGrams`\n    ([CVE-2021-29541](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29541))\n*   Fixes a `CHECK`-fail in `QuantizeAndDequantizeV4Grad`\n    ([CVE-2021-29544](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29544))\n*   Fixes a `CHECK`-fail in `CTCGreedyDecoder`\n    ([CVE-2021-29543](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29543))\n*   Fixes a heap buffer overflow in `SparseTensorToCSRSparseMatrix`\n    ([CVE-2021-29545](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29545))\n*   Fixes a division by 0 in `QuantizedBiasAdd`\n    ([CVE-2021-29546](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29546))\n*   Fixes a heap out of bounds in `QuantizedBatchNormWithGlobalNormalization`\n    ([CVE-2021-29547](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29547))\n*   Fixes a division by 0 in `QuantizedBatchNormWithGlobalNormalization`\n    ([CVE-2021-29548](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29548))\n*   Fixes a division by 0 in `QuantizedAdd`\n    ([CVE-2021-29549](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29549))\n*   Fixes a division by 0 in `FractionalAvgPool`\n    ([CVE-2021-29550](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29550))\n*   Fixes an OOB read in `MatrixTriangularSolve`\n    ([CVE-2021-29551](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29551))\n*   Fixes a heap OOB in `QuantizeAndDequantizeV3`\n    ([CVE-2021-29553](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29553))\n*   Fixes a `CHECK`-failure in `UnsortedSegmentJoin`\n    ([CVE-2021-29552](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29552))\n*   Fixes a division by 0 in `DenseCountSparseOutput`\n    ([CVE-2021-29554](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29554))\n*   Fixes a division by 0 in `FusedBatchNorm`\n    ([CVE-2021-29555](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29555))\n*   Fixes a division by 0 in `SparseMatMul`\n    ([CVE-2021-29557](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29557))\n*   Fixes a division by 0 in `Reverse`\n    ([CVE-2021-29556](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29556))\n*   Fixes a heap buffer overflow in `SparseSplit`\n    ([CVE-2021-29558](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29558))\n*   Fixes a heap OOB access in unicode ops\n    ([CVE-2021-29559](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29559))\n*   Fixes a heap buffer overflow in `RaggedTensorToTensor`\n    ([CVE-2021-29560](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29560))\n*   Fixes a `CHECK`-fail in `LoadAndRemapMatrix`\n    ([CVE-2021-29561](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29561))\n*   Fixes a `CHECK`-fail in `tf.raw_ops.IRFFT`\n    ([CVE-2021-29562](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29562))\n*   Fixes a `CHECK`-fail in `tf.raw_ops.RFFT`\n    ([CVE-2021-29563](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29563))\n*   Fixes a null pointer dereference in `EditDistance`\n    ([CVE-2021-29564](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29564))\n*   Fixes a null pointer dereference in `SparseFillEmptyRows`\n    ([CVE-2021-29565](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29565))\n*   Fixes a heap OOB access in `Dilation2DBackpropInput`\n    ([CVE-2021-29566](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29566))\n*   Fixes a reference binding to null in `ParameterizedTruncatedNormal`\n    ([CVE-2021-29568](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29568))\n*   Fixes a set of vulnerabilities caused by lack of validation in\n    `SparseDenseCwiseMul`\n    ([CVE-2021-29567](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29567))\n*   Fixes a heap out of bounds read in `MaxPoolGradWithArgmax`\n    ([CVE-2021-29570](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29570))\n*   Fixes a heap out of bounds read in `RequantizationRange`\n    ([CVE-2021-29569](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29569))\n*   Fixes a memory corruption in `DrawBoundingBoxesV2`\n    ([CVE-2021-29571](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29571))\n*   Fixes a reference binding to nullptr in `SdcaOptimizer`\n    ([CVE-2021-29572](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29572))\n*   Fixes an overflow and a denial of service in `tf.raw_ops.ReverseSequence`\n    ([CVE-2021-29575](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29575))\n*   Fixes a division by 0 in `MaxPoolGradWithArgmax`\n    ([CVE-2021-29573](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29573))\n*   Fixes an undefined behavior in `MaxPool3DGradGrad`\n    ([CVE-2021-29574](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29574))\n*   Fixes a heap buffer overflow in `MaxPool3DGradGrad`\n    ([CVE-2021-29576](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29576))\n*   Fixes a heap buffer overflow in `AvgPool3DGrad`\n    ([CVE-2021-29577](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29577))\n*   Fixes an undefined behavior and a `CHECK`-fail in `FractionalMaxPoolGrad`\n    ([CVE-2021-29580](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29580))\n*   Fixes a heap buffer overflow in `FractionalAvgPoolGrad`\n    ([CVE-2021-29578](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29578))\n*   Fixes a heap buffer overflow in `MaxPoolGrad`\n    ([CVE-2021-29579](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29579))\n*   Fixes a segfault in `CTCBeamSearchDecoder`\n    ([CVE-2021-29581](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29581))\n*   Fixes a heap OOB read in `tf.raw_ops.Dequantize`\n    ([CVE-2021-29582](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29582))\n*   Fixes a `CHECK`-fail due to integer overflow\n    ([CVE-2021-29584](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29584))\n*   Fixes a heap buffer overflow and undefined behavior in `FusedBatchNorm`\n    ([CVE-2021-29583](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29583))\n*   Fixes a division by zero in padding computation in TFLite\n    ([CVE-2021-29585](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29585))\n*   Fixes a division by zero in optimized pooling implementations in TFLite\n    ([CVE-2021-29586](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29586))\n*   Fixes a division by zero in TFLite's implementation of `SpaceToDepth`\n    ([CVE-2021-29587](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29587))\n*   Fixes a division by zero in TFLite's implementation of `GatherNd`\n    ([CVE-2021-29589](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29589))\n*   Fixes a division by zero in TFLite's implementation of `TransposeConv`\n    ([CVE-2021-29588](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29588))\n*   Fixes a heap OOB read in TFLite's implementation of `Minimum` or `Maximum`\n    ([CVE-2021-29590](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29590))\n*   Fixes a null pointer dereference in TFLite's `Reshape` operator\n    ([CVE-2021-29592](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29592))\n*   Fixes a stack overflow due to looping TFLite subgraph\n    ([CVE-2021-29591](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29591))\n*   Fixes a division by zero in TFLite's implementation of `DepthToSpace`\n    ([CVE-2021-29595](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29595))\n*   Fixes a division by zero in TFLite's convolution code\n    ([CVE-2021-29594](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29594))\n*   Fixes a division by zero in TFLite's implementation of `EmbeddingLookup`\n    ([CVE-2021-29596](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29596))\n*   Fixes a division by zero in TFLite's implementation of `BatchToSpaceNd`\n    ([CVE-2021-29593](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29593))\n*   Fixes a division by zero in TFLite's implementation of `SpaceToBatchNd`\n    ([CVE-2021-29597](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29597))\n*   Fixes a division by zero in TFLite's implementation of `SVDF`\n    ([CVE-2021-29598](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29598))\n*   Fixes a division by zero in TFLite's implementation of `Split`\n    ([CVE-2021-29599](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29599))\n*   Fixes a division by zero in TFLite's implementation of `OneHot`\n    ([CVE-2021-29600](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29600))\n*   Fixes a division by zero in TFLite's implementation of `DepthwiseConv`\n    ([CVE-2021-29602](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29602))\n*   Fixes a division by zero in TFLite's implementation of hashtable lookup\n    ([CVE-2021-29604](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29604))\n*   Fixes a integer overflow in TFLite concatentation\n    ([CVE-2021-29601](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29601))\n*   Fixes a integer overflow in TFLite memory allocation\n    ([CVE-2021-29605](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29605))\n*   Fixes a heap OOB write in TFLite\n    ([CVE-2021-29603](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29603))\n*   Fixes a heap OOB read in TFLite\n    ([CVE-2021-29606](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29606))\n*   Fixes a heap OOB and null pointer dereference in `RaggedTensorToTensor`\n    ([CVE-2021-29608](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29608))\n*   Fixes vulnerabilities caused by incomplete validation in `SparseAdd`\n    ([CVE-2021-29609](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29609))\n*   Fixes vulnerabilities caused by incomplete validation in\n    `SparseSparseMinimum`\n    ([CVE-2021-29607](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29607))\n*   Fixes vulnerabilities caused by incomplete validation in `SparseReshape`\n    ([CVE-2021-29611](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29611))\n*   Fixes vulnerabilities caused by invalid validation in\n    `QuantizeAndDequantizeV2`\n    ([CVE-2021-29610](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29610))\n*   Fixes a heap buffer overflow in `BandedTriangularSolve`\n    ([CVE-2021-29612](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29612))\n*   Fixes vulnerabilities caused by incomplete validation in\n    `tf.raw_ops.CTCLoss`\n    ([CVE-2021-29613](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29613))\n*   Fixes an interpreter crash from vulnerabilities in `tf.io.decode_raw`\n    ([CVE-2021-29614](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29614))\n*   Fixes a stack overflow in `ParseAttrValue` with nested tensors\n    ([CVE-2021-29615](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29615))\n*   Fixes a null dereference in Grappler's `TrySimplify`\n    ([CVE-2021-29616](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29616))\n*   Fixes a crash in `tf.transpose` with complex inputs\n    ([CVE-2021-29618](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29618))\n*   Fixes a crash in `tf.strings.substr` due to `CHECK`-fail\n    ([CVE-2021-29617](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29617))\n*   Fixes a segfault in `tf.raw_ops.SparseCountSparseOutput`\n    ([CVE-2021-29619](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29619))\n*   Fixes a segfault in `tf.raw_ops.ImmutableConst`\n    ([CVE-2021-29539](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29539))\n*   Updates `curl` to `7.76.0` to handle\n    [CVE-2020-8169](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2020-8169),\n    [CVE-2020-8177](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2020-8177),\n    [CVE-2020-8231](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2020-8231),\n    [CVE-2020-8284](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2020-8284),\n    [CVE-2020-8285](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2020-8285)\n    and\n    [CVE-2020-8286](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2020-8286).\n\n# Release 2.2.3\n\nThis release introduces several vulnerability fixes:\n\n*   Fixes a heap buffer overflow in `RaggedBinCount`\n    ([CVE-2021-29512](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29512))\n*   Fixes a heap out of bounds write in `RaggedBinCount`\n    ([CVE-2021-29514](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29514))\n*   Fixes a type confusion during tensor casts which leads to dereferencing null\n    pointers\n    ([CVE-2021-29513](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29513))\n*   Fixes a reference binding to null pointer in `MatrixDiag*` ops\n    ([CVE-2021-29515](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29515))\n*   Fixes a null pointer dereference via invalid Ragged Tensors\n    ([CVE-2021-29516](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29516))\n*   Fixes a division by zero in `Conv3D`\n    ([CVE-2021-29517](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29517))\n*   Fixes vulnerabilities where session operations in eager mode lead to null\n    pointer dereferences\n    ([CVE-2021-29518](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29518))\n*   Fixes a `CHECK`-fail in `SparseCross` caused by type confusion\n    ([CVE-2021-29519](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29519))\n*   Fixes a segfault in `SparseCountSparseOutput`\n    ([CVE-2021-29521](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29521))\n*   Fixes a heap buffer overflow in `Conv3DBackprop*`\n    ([CVE-2021-29520](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29520))\n*   Fixes a division by 0 in `Conv3DBackprop*`\n    ([CVE-2021-29522](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29522))\n*   Fixes a `CHECK`-fail in `AddManySparseToTensorsMap`\n    ([CVE-2021-29523](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29523))\n*   Fixes a division by 0 in `Conv2DBackpropFilter`\n    ([CVE-2021-29524](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29524))\n*   Fixes a division by 0 in `Conv2DBackpropInput`\n    ([CVE-2021-29525](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29525))\n*   Fixes a division by 0 in `Conv2D`\n    ([CVE-2021-29526](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29526))\n*   Fixes a division by 0 in `QuantizedConv2D`\n    ([CVE-2021-29527](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29527))\n*   Fixes a division by 0 in `QuantizedMul`\n    ([CVE-2021-29528](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29528))\n*   Fixes vulnerabilities caused by invalid validation in\n    `SparseMatrixSparseCholesky`\n    ([CVE-2021-29530](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29530))\n*   Fixes a heap buffer overflow caused by rounding\n    ([CVE-2021-29529](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29529))\n*   Fixes a `CHECK`-fail in `tf.raw_ops.EncodePng`\n    ([CVE-2021-29531](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29531))\n*   Fixes a heap out of bounds read in `RaggedCross`\n    ([CVE-2021-29532](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29532))\n*   Fixes a `CHECK`-fail in `DrawBoundingBoxes`\n    ([CVE-2021-29533](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29533))\n*   Fixes a heap buffer overflow in `QuantizedMul`\n    ([CVE-2021-29535](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29535))\n*   Fixes a `CHECK`-fail in `SparseConcat`\n    ([CVE-2021-29534](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29534))\n*   Fixes a heap buffer overflow in `QuantizedResizeBilinear`\n    ([CVE-2021-29537](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29537))\n*   Fixes a heap buffer overflow in `QuantizedReshape`\n    ([CVE-2021-29536](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29536))\n*   Fixes a division by zero in `Conv2DBackpropFilter`\n    ([CVE-2021-29538](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29538))\n*   Fixes a heap buffer overflow in `Conv2DBackpropFilter`\n    ([CVE-2021-29540](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29540))\n*   Fixes a heap buffer overflow in `StringNGrams`\n    ([CVE-2021-29542](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29542))\n*   Fixes a null pointer dereference in `StringNGrams`\n    ([CVE-2021-29541](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29541))\n*   Fixes a `CHECK`-fail in `QuantizeAndDequantizeV4Grad`\n    ([CVE-2021-29544](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29544))\n*   Fixes a `CHECK`-fail in `CTCGreedyDecoder`\n    ([CVE-2021-29543](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29543))\n*   Fixes a heap buffer overflow in `SparseTensorToCSRSparseMatrix`\n    ([CVE-2021-29545](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29545))\n*   Fixes a division by 0 in `QuantizedBiasAdd`\n    ([CVE-2021-29546](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29546))\n*   Fixes a heap out of bounds in `QuantizedBatchNormWithGlobalNormalization`\n    ([CVE-2021-29547](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29547))\n*   Fixes a division by 0 in `QuantizedBatchNormWithGlobalNormalization`\n    ([CVE-2021-29548](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29548))\n*   Fixes a division by 0 in `QuantizedAdd`\n    ([CVE-2021-29549](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29549))\n*   Fixes a division by 0 in `FractionalAvgPool`\n    ([CVE-2021-29550](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29550))\n*   Fixes an OOB read in `MatrixTriangularSolve`\n    ([CVE-2021-29551](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29551))\n*   Fixes a heap OOB in `QuantizeAndDequantizeV3`\n    ([CVE-2021-29553](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29553))\n*   Fixes a `CHECK`-failure in `UnsortedSegmentJoin`\n    ([CVE-2021-29552](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29552))\n*   Fixes a division by 0 in `DenseCountSparseOutput`\n    ([CVE-2021-29554](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29554))\n*   Fixes a division by 0 in `FusedBatchNorm`\n    ([CVE-2021-29555](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29555))\n*   Fixes a division by 0 in `SparseMatMul`\n    ([CVE-2021-29557](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29557))\n*   Fixes a division by 0 in `Reverse`\n    ([CVE-2021-29556](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29556))\n*   Fixes a heap buffer overflow in `SparseSplit`\n    ([CVE-2021-29558](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29558))\n*   Fixes a heap OOB access in unicode ops\n    ([CVE-2021-29559](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29559))\n*   Fixes a heap buffer overflow in `RaggedTensorToTensor`\n    ([CVE-2021-29560](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29560))\n*   Fixes a `CHECK`-fail in `LoadAndRemapMatrix`\n    ([CVE-2021-29561](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29561))\n*   Fixes a `CHECK`-fail in `tf.raw_ops.IRFFT`\n    ([CVE-2021-29562](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29562))\n*   Fixes a `CHECK`-fail in `tf.raw_ops.RFFT`\n    ([CVE-2021-29563](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29563))\n*   Fixes a null pointer dereference in `EditDistance`\n    ([CVE-2021-29564](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29564))\n*   Fixes a null pointer dereference in `SparseFillEmptyRows`\n    ([CVE-2021-29565](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29565))\n*   Fixes a heap OOB access in `Dilation2DBackpropInput`\n    ([CVE-2021-29566](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29566))\n*   Fixes a reference binding to null in `ParameterizedTruncatedNormal`\n    ([CVE-2021-29568](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29568))\n*   Fixes a set of vulnerabilities caused by lack of validation in\n    `SparseDenseCwiseMul`\n    ([CVE-2021-29567](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29567))\n*   Fixes a heap out of bounds read in `MaxPoolGradWithArgmax`\n    ([CVE-2021-29570](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29570))\n*   Fixes a heap out of bounds read in `RequantizationRange`\n    ([CVE-2021-29569](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29569))\n*   Fixes a memory corruption in `DrawBoundingBoxesV2`\n    ([CVE-2021-29571](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29571))\n*   Fixes a reference binding to nullptr in `SdcaOptimizer`\n    ([CVE-2021-29572](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29572))\n*   Fixes an overflow and a denial of service in `tf.raw_ops.ReverseSequence`\n    ([CVE-2021-29575](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29575))\n*   Fixes a division by 0 in `MaxPoolGradWithArgmax`\n    ([CVE-2021-29573](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29573))\n*   Fixes an undefined behavior in `MaxPool3DGradGrad`\n    ([CVE-2021-29574](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29574))\n*   Fixes a heap buffer overflow in `MaxPool3DGradGrad`\n    ([CVE-2021-29576](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29576))\n*   Fixes a heap buffer overflow in `AvgPool3DGrad`\n    ([CVE-2021-29577](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29577))\n*   Fixes an undefined behavior and a `CHECK`-fail in `FractionalMaxPoolGrad`\n    ([CVE-2021-29580](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29580))\n*   Fixes a heap buffer overflow in `FractionalAvgPoolGrad`\n    ([CVE-2021-29578](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29578))\n*   Fixes a heap buffer overflow in `MaxPoolGrad`\n    ([CVE-2021-29579](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29579))\n*   Fixes a segfault in `CTCBeamSearchDecoder`\n    ([CVE-2021-29581](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29581))\n*   Fixes a heap OOB read in `tf.raw_ops.Dequantize`\n    ([CVE-2021-29582](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29582))\n*   Fixes a `CHECK`-fail due to integer overflow\n    ([CVE-2021-29584](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29584))\n*   Fixes a heap buffer overflow and undefined behavior in `FusedBatchNorm`\n    ([CVE-2021-29583](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29583))\n*   Fixes a division by zero in padding computation in TFLite\n    ([CVE-2021-29585](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29585))\n*   Fixes a division by zero in optimized pooling implementations in TFLite\n    ([CVE-2021-29586](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29586))\n*   Fixes a division by zero in TFLite's implementation of `SpaceToDepth`\n    ([CVE-2021-29587](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29587))\n*   Fixes a division by zero in TFLite's implementation of `GatherNd`\n    ([CVE-2021-29589](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29589))\n*   Fixes a division by zero in TFLite's implementation of `TransposeConv`\n    ([CVE-2021-29588](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29588))\n*   Fixes a heap OOB read in TFLite's implementation of `Minimum` or `Maximum`\n    ([CVE-2021-29590](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29590))\n*   Fixes a null pointer dereference in TFLite's `Reshape` operator\n    ([CVE-2021-29592](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29592))\n*   Fixes a stack overflow due to looping TFLite subgraph\n    ([CVE-2021-29591](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29591))\n*   Fixes a division by zero in TFLite's implementation of `DepthToSpace`\n    ([CVE-2021-29595](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29595))\n*   Fixes a division by zero in TFLite's convolution code\n    ([CVE-2021-29594](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29594))\n*   Fixes a division by zero in TFLite's implementation of `EmbeddingLookup`\n    ([CVE-2021-29596](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29596))\n*   Fixes a division by zero in TFLite's implementation of `BatchToSpaceNd`\n    ([CVE-2021-29593](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29593))\n*   Fixes a division by zero in TFLite's implementation of `SpaceToBatchNd`\n    ([CVE-2021-29597](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29597))\n*   Fixes a division by zero in TFLite's implementation of `SVDF`\n    ([CVE-2021-29598](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29598))\n*   Fixes a division by zero in TFLite's implementation of `Split`\n    ([CVE-2021-29599](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29599))\n*   Fixes a division by zero in TFLite's implementation of `OneHot`\n    ([CVE-2021-29600](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29600))\n*   Fixes a division by zero in TFLite's implementation of `DepthwiseConv`\n    ([CVE-2021-29602](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29602))\n*   Fixes a division by zero in TFLite's implementation of hashtable lookup\n    ([CVE-2021-29604](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29604))\n*   Fixes a integer overflow in TFLite concatentation\n    ([CVE-2021-29601](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29601))\n*   Fixes a integer overflow in TFLite memory allocation\n    ([CVE-2021-29605](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29605))\n*   Fixes a heap OOB write in TFLite\n    ([CVE-2021-29603](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29603))\n*   Fixes a heap OOB read in TFLite\n    ([CVE-2021-29606](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29606))\n*   Fixes a heap OOB and null pointer dereference in `RaggedTensorToTensor`\n    ([CVE-2021-29608](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29608))\n*   Fixes vulnerabilities caused by incomplete validation in `SparseAdd`\n    ([CVE-2021-29609](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29609))\n*   Fixes vulnerabilities caused by incomplete validation in\n    `SparseSparseMinimum`\n    ([CVE-2021-29607](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29607))\n*   Fixes vulnerabilities caused by incomplete validation in `SparseReshape`\n    ([CVE-2021-29611](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29611))\n*   Fixes vulnerabilities caused by invalid validation in\n    `QuantizeAndDequantizeV2`\n    ([CVE-2021-29610](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29610))\n*   Fixes a heap buffer overflow in `BandedTriangularSolve`\n    ([CVE-2021-29612](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29612))\n*   Fixes vulnerabilities caused by incomplete validation in\n    `tf.raw_ops.CTCLoss`\n    ([CVE-2021-29613](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29613))\n*   Fixes an interpreter crash from vulnerabilities in `tf.io.decode_raw`\n    ([CVE-2021-29614](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29614))\n*   Fixes a stack overflow in `ParseAttrValue` with nested tensors\n    ([CVE-2021-29615](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29615))\n*   Fixes a null dereference in Grappler's `TrySimplify`\n    ([CVE-2021-29616](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29616))\n*   Fixes a crash in `tf.transpose` with complex inputs\n    ([CVE-2021-29618](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29618))\n*   Fixes a crash in `tf.strings.substr` due to `CHECK`-fail\n    ([CVE-2021-29617](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29617))\n*   Fixes a segfault in `tf.raw_ops.SparseCountSparseOutput`\n    ([CVE-2021-29619](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29619))\n*   Fixes a segfault in `tf.raw_ops.ImmutableConst`\n    ([CVE-2021-29539](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29539))\n*   Updates `curl` to `7.76.0` to handle\n    [CVE-2020-8169](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2020-8169),\n    [CVE-2020-8177](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2020-8177),\n    [CVE-2020-8231](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2020-8231),\n    [CVE-2020-8284](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2020-8284),\n    [CVE-2020-8285](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2020-8285)\n    and\n    [CVE-2020-8286](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2020-8286).\n\n# Release 2.1.4\n\nThis release introduces several vulnerability fixes:\n\n*   Fixes a heap buffer overflow in `RaggedBinCount`\n    ([CVE-2021-29512](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29512))\n*   Fixes a heap out of bounds write in `RaggedBinCount`\n    ([CVE-2021-29514](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29514))\n*   Fixes a type confusion during tensor casts which leads to dereferencing null\n    pointers\n    ([CVE-2021-29513](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29513))\n*   Fixes a reference binding to null pointer in `MatrixDiag*` ops\n    ([CVE-2021-29515](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29515))\n*   Fixes a null pointer dereference via invalid Ragged Tensors\n    ([CVE-2021-29516](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29516))\n*   Fixes a division by zero in `Conv3D`\n    ([CVE-2021-29517](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29517))\n*   Fixes vulnerabilities where session operations in eager mode lead to null\n    pointer dereferences\n    ([CVE-2021-29518](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29518))\n*   Fixes a `CHECK`-fail in `SparseCross` caused by type confusion\n    ([CVE-2021-29519](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29519))\n*   Fixes a segfault in `SparseCountSparseOutput`\n    ([CVE-2021-29521](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29521))\n*   Fixes a heap buffer overflow in `Conv3DBackprop*`\n    ([CVE-2021-29520](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29520))\n*   Fixes a division by 0 in `Conv3DBackprop*`\n    ([CVE-2021-29522](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29522))\n*   Fixes a `CHECK`-fail in `AddManySparseToTensorsMap`\n    ([CVE-2021-29523](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29523))\n*   Fixes a division by 0 in `Conv2DBackpropFilter`\n    ([CVE-2021-29524](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29524))\n*   Fixes a division by 0 in `Conv2DBackpropInput`\n    ([CVE-2021-29525](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29525))\n*   Fixes a division by 0 in `Conv2D`\n    ([CVE-2021-29526](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29526))\n*   Fixes a division by 0 in `QuantizedConv2D`\n    ([CVE-2021-29527](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29527))\n*   Fixes a division by 0 in `QuantizedMul`\n    ([CVE-2021-29528](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29528))\n*   Fixes vulnerabilities caused by invalid validation in\n    `SparseMatrixSparseCholesky`\n    ([CVE-2021-29530](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29530))\n*   Fixes a heap buffer overflow caused by rounding\n    ([CVE-2021-29529](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29529))\n*   Fixes a `CHECK`-fail in `tf.raw_ops.EncodePng`\n    ([CVE-2021-29531](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29531))\n*   Fixes a heap out of bounds read in `RaggedCross`\n    ([CVE-2021-29532](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29532))\n*   Fixes a `CHECK`-fail in `DrawBoundingBoxes`\n    ([CVE-2021-29533](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29533))\n*   Fixes a heap buffer overflow in `QuantizedMul`\n    ([CVE-2021-29535](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29535))\n*   Fixes a `CHECK`-fail in `SparseConcat`\n    ([CVE-2021-29534](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29534))\n*   Fixes a heap buffer overflow in `QuantizedResizeBilinear`\n    ([CVE-2021-29537](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29537))\n*   Fixes a heap buffer overflow in `QuantizedReshape`\n    ([CVE-2021-29536](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29536))\n*   Fixes a division by zero in `Conv2DBackpropFilter`\n    ([CVE-2021-29538](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29538))\n*   Fixes a heap buffer overflow in `Conv2DBackpropFilter`\n    ([CVE-2021-29540](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29540))\n*   Fixes a heap buffer overflow in `StringNGrams`\n    ([CVE-2021-29542](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29542))\n*   Fixes a null pointer dereference in `StringNGrams`\n    ([CVE-2021-29541](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29541))\n*   Fixes a `CHECK`-fail in `QuantizeAndDequantizeV4Grad`\n    ([CVE-2021-29544](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29544))\n*   Fixes a `CHECK`-fail in `CTCGreedyDecoder`\n    ([CVE-2021-29543](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29543))\n*   Fixes a heap buffer overflow in `SparseTensorToCSRSparseMatrix`\n    ([CVE-2021-29545](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29545))\n*   Fixes a division by 0 in `QuantizedBiasAdd`\n    ([CVE-2021-29546](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29546))\n*   Fixes a heap out of bounds in `QuantizedBatchNormWithGlobalNormalization`\n    ([CVE-2021-29547](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29547))\n*   Fixes a division by 0 in `QuantizedBatchNormWithGlobalNormalization`\n    ([CVE-2021-29548](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29548))\n*   Fixes a division by 0 in `QuantizedAdd`\n    ([CVE-2021-29549](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29549))\n*   Fixes a division by 0 in `FractionalAvgPool`\n    ([CVE-2021-29550](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29550))\n*   Fixes an OOB read in `MatrixTriangularSolve`\n    ([CVE-2021-29551](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29551))\n*   Fixes a heap OOB in `QuantizeAndDequantizeV3`\n    ([CVE-2021-29553](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29553))\n*   Fixes a `CHECK`-failure in `UnsortedSegmentJoin`\n    ([CVE-2021-29552](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29552))\n*   Fixes a division by 0 in `DenseCountSparseOutput`\n    ([CVE-2021-29554](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29554))\n*   Fixes a division by 0 in `FusedBatchNorm`\n    ([CVE-2021-29555](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29555))\n*   Fixes a division by 0 in `SparseMatMul`\n    ([CVE-2021-29557](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29557))\n*   Fixes a division by 0 in `Reverse`\n    ([CVE-2021-29556](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29556))\n*   Fixes a heap buffer overflow in `SparseSplit`\n    ([CVE-2021-29558](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29558))\n*   Fixes a heap OOB access in unicode ops\n    ([CVE-2021-29559](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29559))\n*   Fixes a heap buffer overflow in `RaggedTensorToTensor`\n    ([CVE-2021-29560](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29560))\n*   Fixes a `CHECK`-fail in `LoadAndRemapMatrix`\n    ([CVE-2021-29561](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29561))\n*   Fixes a `CHECK`-fail in `tf.raw_ops.IRFFT`\n    ([CVE-2021-29562](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29562))\n*   Fixes a `CHECK`-fail in `tf.raw_ops.RFFT`\n    ([CVE-2021-29563](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29563))\n*   Fixes a null pointer dereference in `EditDistance`\n    ([CVE-2021-29564](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29564))\n*   Fixes a null pointer dereference in `SparseFillEmptyRows`\n    ([CVE-2021-29565](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29565))\n*   Fixes a heap OOB access in `Dilation2DBackpropInput`\n    ([CVE-2021-29566](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29566))\n*   Fixes a reference binding to null in `ParameterizedTruncatedNormal`\n    ([CVE-2021-29568](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29568))\n*   Fixes a set of vulnerabilities caused by lack of validation in\n    `SparseDenseCwiseMul`\n    ([CVE-2021-29567](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29567))\n*   Fixes a heap out of bounds read in `MaxPoolGradWithArgmax`\n    ([CVE-2021-29570](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29570))\n*   Fixes a heap out of bounds read in `RequantizationRange`\n    ([CVE-2021-29569](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29569))\n*   Fixes a memory corruption in `DrawBoundingBoxesV2`\n    ([CVE-2021-29571](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29571))\n*   Fixes a reference binding to nullptr in `SdcaOptimizer`\n    ([CVE-2021-29572](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29572))\n*   Fixes an overflow and a denial of service in `tf.raw_ops.ReverseSequence`\n    ([CVE-2021-29575](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29575))\n*   Fixes a division by 0 in `MaxPoolGradWithArgmax`\n    ([CVE-2021-29573](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29573))\n*   Fixes an undefined behavior in `MaxPool3DGradGrad`\n    ([CVE-2021-29574](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29574))\n*   Fixes a heap buffer overflow in `MaxPool3DGradGrad`\n    ([CVE-2021-29576](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29576))\n*   Fixes a heap buffer overflow in `AvgPool3DGrad`\n    ([CVE-2021-29577](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29577))\n*   Fixes an undefined behavior and a `CHECK`-fail in `FractionalMaxPoolGrad`\n    ([CVE-2021-29580](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29580))\n*   Fixes a heap buffer overflow in `FractionalAvgPoolGrad`\n    ([CVE-2021-29578](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29578))\n*   Fixes a heap buffer overflow in `MaxPoolGrad`\n    ([CVE-2021-29579](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29579))\n*   Fixes a segfault in `CTCBeamSearchDecoder`\n    ([CVE-2021-29581](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29581))\n*   Fixes a heap OOB read in `tf.raw_ops.Dequantize`\n    ([CVE-2021-29582](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29582))\n*   Fixes a `CHECK`-fail due to integer overflow\n    ([CVE-2021-29584](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29584))\n*   Fixes a heap buffer overflow and undefined behavior in `FusedBatchNorm`\n    ([CVE-2021-29583](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29583))\n*   Fixes a division by zero in padding computation in TFLite\n    ([CVE-2021-29585](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29585))\n*   Fixes a division by zero in optimized pooling implementations in TFLite\n    ([CVE-2021-29586](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29586))\n*   Fixes a division by zero in TFLite's implementation of `SpaceToDepth`\n    ([CVE-2021-29587](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29587))\n*   Fixes a division by zero in TFLite's implementation of `GatherNd`\n    ([CVE-2021-29589](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29589))\n*   Fixes a division by zero in TFLite's implementation of `TransposeConv`\n    ([CVE-2021-29588](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29588))\n*   Fixes a heap OOB read in TFLite's implementation of `Minimum` or `Maximum`\n    ([CVE-2021-29590](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29590))\n*   Fixes a null pointer dereference in TFLite's `Reshape` operator\n    ([CVE-2021-29592](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29592))\n*   Fixes a stack overflow due to looping TFLite subgraph\n    ([CVE-2021-29591](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29591))\n*   Fixes a division by zero in TFLite's implementation of `DepthToSpace`\n    ([CVE-2021-29595](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29595))\n*   Fixes a division by zero in TFLite's convolution code\n    ([CVE-2021-29594](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29594))\n*   Fixes a division by zero in TFLite's implementation of `EmbeddingLookup`\n    ([CVE-2021-29596](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29596))\n*   Fixes a division by zero in TFLite's implementation of `BatchToSpaceNd`\n    ([CVE-2021-29593](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29593))\n*   Fixes a division by zero in TFLite's implementation of `SpaceToBatchNd`\n    ([CVE-2021-29597](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29597))\n*   Fixes a division by zero in TFLite's implementation of `SVDF`\n    ([CVE-2021-29598](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29598))\n*   Fixes a division by zero in TFLite's implementation of `Split`\n    ([CVE-2021-29599](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29599))\n*   Fixes a division by zero in TFLite's implementation of `OneHot`\n    ([CVE-2021-29600](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29600))\n*   Fixes a division by zero in TFLite's implementation of `DepthwiseConv`\n    ([CVE-2021-29602](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29602))\n*   Fixes a division by zero in TFLite's implementation of hashtable lookup\n    ([CVE-2021-29604](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29604))\n*   Fixes a integer overflow in TFLite concatentation\n    ([CVE-2021-29601](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29601))\n*   Fixes a integer overflow in TFLite memory allocation\n    ([CVE-2021-29605](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29605))\n*   Fixes a heap OOB write in TFLite\n    ([CVE-2021-29603](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29603))\n*   Fixes a heap OOB read in TFLite\n    ([CVE-2021-29606](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29606))\n*   Fixes a heap OOB and null pointer dereference in `RaggedTensorToTensor`\n    ([CVE-2021-29608](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29608))\n*   Fixes vulnerabilities caused by incomplete validation in `SparseAdd`\n    ([CVE-2021-29609](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29609))\n*   Fixes vulnerabilities caused by incomplete validation in\n    `SparseSparseMinimum`\n    ([CVE-2021-29607](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29607))\n*   Fixes vulnerabilities caused by incomplete validation in `SparseReshape`\n    ([CVE-2021-29611](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29611))\n*   Fixes vulnerabilities caused by invalid validation in\n    `QuantizeAndDequantizeV2`\n    ([CVE-2021-29610](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29610))\n*   Fixes a heap buffer overflow in `BandedTriangularSolve`\n    ([CVE-2021-29612](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29612))\n*   Fixes vulnerabilities caused by incomplete validation in\n    `tf.raw_ops.CTCLoss`\n    ([CVE-2021-29613](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29613))\n*   Fixes an interpreter crash from vulnerabilities in `tf.io.decode_raw`\n    ([CVE-2021-29614](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29614))\n*   Fixes a stack overflow in `ParseAttrValue` with nested tensors\n    ([CVE-2021-29615](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29615))\n*   Fixes a null dereference in Grappler's `TrySimplify`\n    ([CVE-2021-29616](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29616))\n*   Fixes a crash in `tf.transpose` with complex inputs\n    ([CVE-2021-29618](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29618))\n*   Fixes a crash in `tf.strings.substr` due to `CHECK`-fail\n    ([CVE-2021-29617](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29617))\n*   Fixes a segfault in `tf.raw_ops.SparseCountSparseOutput`\n    ([CVE-2021-29619](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29619))\n*   Fixes a segfault in `tf.raw_ops.ImmutableConst`\n    ([CVE-2021-29539](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29539))\n*   Updates `curl` to `7.76.0` to handle\n    [CVE-2020-8169](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2020-8169),\n    [CVE-2020-8177](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2020-8177),\n    [CVE-2020-8231](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2020-8231),\n    [CVE-2020-8284](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2020-8284),\n    [CVE-2020-8285](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2020-8285)\n    and\n    [CVE-2020-8286](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2020-8286).\n\n# Release 2.5.0\n\n## Major Features and Improvements\n\n*   Support for Python3.9 has been added.\n*   `tf.data`:\n    *   `tf.data` service now supports strict round-robin reads, which is useful\n        for synchronous training workloads where example sizes vary. With strict\n        round robin reads, users can guarantee that consumers get similar-sized\n        examples in the same step.\n    *   tf.data service now supports optional compression. Previously data would\n        always be compressed, but now you can disable compression by passing\n        `compression=None` to `tf.data.experimental.service.distribute(...)`.\n    *   `tf.data.Dataset.batch()` now supports `num_parallel_calls` and\n        `deterministic` arguments. `num_parallel_calls` is used to indicate that\n        multiple input batches should be computed in parallel. With\n        `num_parallel_calls` set, `deterministic` is used to indicate that\n        outputs can be obtained in the non-deterministic order.\n    *   Options returned by `tf.data.Dataset.options()` are no longer mutable.\n    *   tf.data input pipelines can now be executed in debug mode, which\n        disables any asynchrony, parallelism, or non-determinism and forces\n        Python execution (as opposed to trace-compiled graph execution) of\n        user-defined functions passed into transformations such as `map`. The\n        debug mode can be enabled through\n        `tf.data.experimental.enable_debug_mode()`.\n*   `tf.lite`\n    *   Enabled the new MLIR-based quantization backend by default\n        *   The new backend is used for 8 bits full integer post-training\n            quantization\n        *   The new backend removes the redundant rescales and fixes some bugs\n            (shared weight/bias, extremely small scales, etc)\n        *   Set `experimental_new_quantizer` in tf.lite.TFLiteConverter to False\n            to disable this change\n*   `tf.keras`\n    *   `tf.keras.metrics.AUC` now support logit predictions.\n    *   Enabled a new supported input type in `Model.fit`,\n        `tf.keras.utils.experimental.DatasetCreator`, which takes a callable,\n        `dataset_fn`. `DatasetCreator` is intended to work across all\n        `tf.distribute` strategies, and is the only input type supported for\n        Parameter Server strategy.\n*   `tf.distribute`\n    *   `tf.distribute.experimental.ParameterServerStrategy` now supports\n        training with Keras `Model.fit` when used with `DatasetCreator`.\n    *   Creating `tf.random.Generator` under `tf.distribute.Strategy` scopes is\n        now allowed (except for\n        `tf.distribute.experimental.CentralStorageStrategy` and\n        `tf.distribute.experimental.ParameterServerStrategy`). Different\n        replicas will get different random-number streams.\n*   TPU embedding support\n    *   Added `profile_data_directory` to `EmbeddingConfigSpec` in\n        `_tpu_estimator_embedding.py`. This allows embedding lookup statistics\n        gathered at runtime to be used in embedding layer partitioning\n        decisions.\n*   PluggableDevice\n    *   Third-party devices can now connect to TensorFlow as plug-ins through\n        [StreamExecutor C API](https://github.com/tensorflow/community/blob/master/rfcs/20200612-stream-executor-c-api.md).\n        and\n        [PluggableDevice](https://github.com/tensorflow/community/blob/master/rfcs/20200624-pluggable-device-for-tensorflow.md)\n        interface.\n        *   Add custom ops and kernels through\n            [kernel and op registration C API](https://github.com/tensorflow/community/blob/master/rfcs/20190814-kernel-and-op-registration.md).\n        *   Register custom graph optimization passes with\n            [graph optimization C API](https://github.com/tensorflow/community/blob/master/rfcs/20201027-modular-tensorflow-graph-c-api.md).\n*   [oneAPI Deep Neural Network Library (oneDNN)](https://github.com/oneapi-src/oneDNN)\n    CPU performance optimizations from\n    [Intel-optimized TensorFlow](https://software.intel.com/content/www/us/en/develop/articles/intel-optimization-for-tensorflow-installation-guide.html)\n    are now available in the official x86-64 Linux and Windows builds.\n    *   They are off by default. Enable them by setting the environment variable\n        `TF_ENABLE_ONEDNN_OPTS=1`.\n    *   We do not recommend using them in GPU systems, as they have not been\n        sufficiently tested with GPUs yet.\n*   TensorFlow pip packages are now built with CUDA11.2 and cuDNN 8.1.0\n\n## Breaking Changes\n\n*   The `TF_CPP_MIN_VLOG_LEVEL` environment variable has been renamed to\n    `TF_CPP_MAX_VLOG_LEVEL` which correctly describes its effect.\n\n## Bug Fixes and Other Changes\n\n*   `tf.keras`:\n\n    *   Preprocessing layers API consistency changes:\n        *   `StringLookup` added `output_mode`, `sparse`, and\n            `pad_to_max_tokens` arguments with same semantics as\n            `TextVectorization`.\n        *   `IntegerLookup` added `output_mode`, `sparse`, and\n            `pad_to_max_tokens` arguments with same semantics as\n            `TextVectorization`. Renamed `max_values`, `oov_value` and\n            `mask_value` to `max_tokens`, `oov_token` and `mask_token` to align\n            with `StringLookup` and `TextVectorization`.\n        *   `TextVectorization` default for `pad_to_max_tokens` switched to\n            False.\n        *   `CategoryEncoding` no longer supports `adapt`, `IntegerLookup` now\n            supports equivalent functionality. `max_tokens` argument renamed to\n            `num_tokens`.\n        *   `Discretization` added `num_bins` argument for learning bins\n            boundaries through calling `adapt` on a dataset. Renamed `bins`\n            argument to `bin_boundaries` for specifying bins without `adapt`.\n    *   Improvements to model saving/loading:\n        *   `model.load_weights` now accepts paths to saved models.\n    *   Keras inputs can now be created directly from arbitrary `tf.TypeSpecs`.\n    *   Two new learning rate schedules added:\n        `tf.keras.optimizers.schedules.CosineDecay`\n        and`tf.keras.optimizers.schedules.CosineDecayRestarts`.\n\n*   `tf.data`:\n\n    *   Exposing `tf.data.experimental.ExternalStatePolicy`, which can be used\n        to control how external state should be handled during dataset\n        serialization or iterator checkpointing.\n    *   Changing `tf.data.experimental.save` to store the type specification of\n        the dataset elements. This avoids the need for explicitly specifying the\n        `element_spec` argument of `tf.data.experimental.load` when loading the\n        previously saved dataset.\n    *   Add `.element_spec` property to `tf.data.DatasetSpec` to access the\n        inner spec. This can be used to extract the structure of nested\n        datasets.\n    *   Add `tf.data.experimental.AutoShardingPolicy.HINT` which can be used to\n        provide hints to tf.distribute-based auto-sharding as to where in the\n        input pipeline to insert sharding transformations.\n    *   Make tf.data.Options persistent across `tf.function` and `GraphDef`\n        boundaries.\n\n*   XLA compilation:\n\n    *   `tf.function(experimental_compile=True)` has become a stable API,\n        renamed `tf.function(jit_compile=True)`.\n    *   XLA can now compile MirroredStrategy: the step function passed\n        to`strategy.run` can now be annoted with `jit_compile=True`.\n\n*   `tf.distribute`:\n\n    *   Rename `experimental_prefetch_to_device` in `tf.distribute.InputOptions`\n        to `experimental_fetch_to_device` to better reflect the purpose.\n\n*   `tf.lite`:\n\n    *   class `tflite::Subgraph`:\n        *   Removed the `tensors()` method and the non-const overload of the\n            `nodes_and_registration()` method, both of which were previously\n            documented as temporary and to be removed.\n            *   Uses of `tensors()` can be replaced by calling the existing\n                methods `tensors_size()` and `tensor(int)`.\n            *   Uses of the non-const overload of `nodes_and_registration` can\n                be replaced by calling the existing methods `nodes_size()` and\n                `context()`, and then calling the `GetNodeAndRegistration`\n                method in the `TfLiteContext` returned by `context()`.\n    *   NNAPI\n        *   Removed deprecated `Interpreter::UseNNAPI(bool)` C++ API.\n            *   Use `NnApiDelegate()` and related delegate configuration methods\n                directly.\n        *   Replaced the model cache key for models computation algorithm with\n            one guaranteed to be stable across runs.\n    *   16 bits quantization\n        *   Added int16x8 support for ABS, REDUCE_MAX and REDUCE_MIN operators.\n        *   Additional tests and fixes for ADD and SUB operators.\n    *   Added support for saved model's session initializer through\n        `TFLiteConverter.from_saved_model`.\n    *   Added DEPTH_TO_SPACE support in Post training quantization.\n    *   Added dynamic range quantization support for the BatchMatMul op.\n        *   Both symmetric and asymmetric quantized input tensor are supported.\n    *   Add `RFFT2D` as builtin op. (`RFFT2D` also supports `RFFTD`.) Currently\n        only supports float32 input.\n    *   Add 5D support to `SLICE` op.\n    *   TFLite Supports SingatureDef:\n        *   TFLiteConverter exports models with SignatureDef\n        *   Interpreter supports getting a list of signatures and getting\n            callable function for a given signaturedef.\n    *   Add int8 support for `ReshapeV2`.\n    *   Add experimental support for optimization with sparsity.\n    *   Add nominal support for unsigned 32-bit integer tensor types. Note that\n        very few TFLite kernels support this type natively, so its use in mobile\n        ML authoring is generally discouraged.\n    *   Add support for static hash tables through\n        `TFLiteConverter.from_saved_model`.\n    *   The Python TF Lite Interpreter bindings now has an option\n        `experimental_preserve_all_tensors` to aid in debugging conversion.\n    *   Quantized x86 execution defaults to Ruy GEMM library for platforms with\n        AVX support.\n    *   Deprecate\n        `tf.compat.v1.lite.experimental.get_potentially_supported_ops`. Use\n        `tf.lite.TFLiteConverter` directly to check whether a model is\n        convertible.\n    *   Add support to select one of three different built-in op resolvers\n    *   Enabled post training with calibrations for models that require user\n        provided TensorFlow Lite custom op libraries via\n        `converter.target_spec._experimental_custom_op_registerers`. used in\n        Python Interpreter API.\n\n*   TF Core:\n\n    *   Corrected higher-order gradients of control flow constructs (`tf.cond`,\n        `tf.while_loop`, and compositions like `tf.foldl`) computed with\n        `tf.GradientTape` inside a `tf.function`.\n    *   Changed the default step size in `gradient_checker_v2.compute_gradients`\n        to be exactly representable as a binary floating point numbers. This\n        avoids poluting gradient approximations needlessly, which is some cases\n        leads to false negatives in op gradient tests.\n    *   Added `tf.config.experimental.get_memory_info`, returning a dict with\n        the current and peak memory usage. Deprecated\n        `tf.config.experimental.get_memory_usage` in favor of this new function.\n    *   Extended `tf.config.experimental.enable_tensor_float_32_execution` to\n        control Tensor-Float-32 evaluation in RNNs.\n    *   Added a 'experimental_payloads' field to tf.errors.OpError and its\n        subclasses to support more detailed error reporting. This is inspired\n        from Abseil Status payloads:\n        https://github.com/abseil/abseil-cpp/blob/master/absl/status/status.h\n\n*   `tf.summary`:\n\n    *   New `tf.summary.graph` allows manual write of TensorFlow graph\n        (`tf.Graph` or `tf.compat.v1.GraphDef`) as a summary. This is not a\n        replacement for the trace-based API.\n\n*   Set `/d2ReducedOptimizeHugeFunctions` by default for Windows builds. This\n    provides a big compile-time speedup, and effectively raises the minimum\n    supported MSVC version to 16.4 (current: 16.8).\n\n    *   See:\n        https://groups.google.com/a/tensorflow.org/d/topic/build/SsW98Eo7l3o/discussion\n\n*   TensorRT\n\n    *   Removed the deprecated `session_config` parameter for the TF1-TRT\n        converter `TrtGraphConverter`. Previously, we issued a warning when the\n        value of the parameter is not None.\n    *   The TF2-TRT converter `TrtGraphConverterV2` takes an object of class\n        TrtConversionParams as a parameter. Removed three deprecated fields from\n        this class: `rewriter_config_template`, `is_dynamic_op`, and\n        `max_batch_size`. Previously, we issued a warning when the value of\n        `rewriter_config_template` is not None. We issued an error when the\n        value of `is_dynamic_op` is not True. We didn't use the value for\n        `max_batch_size` for building TensorRT engines. Add parameters\n        `use_dynamic_shape` to enable dynamic shape support. The default is to\n        disable dynamic shape support. Add `dynamic_shape_profile_strategy` for\n        selecting a dynamic shape profile strategy. The default is profile\n        strategy is `Range`.\n    *   Issue a warning when function get_tensorrt_rewriter_config is used.\n\n*   TF XLA\n\n    *   Add new enum value `MLIR_BRIDGE_ROLLOUT_SAFE_MODE_ENABLED` to\n        `tf.config.experimental.mlir_bridge_rollout` to enable a \\\"safe\\\" mode.\n        This runs the MLIR bridge only when an analysis of the graph only when\n        an analysis of the graph determines that it is safe to run.\n    *   Add new enum value `MLIR_BRIDGE_ROLLOUT_SAFE_MODE_FALLBACK_ENABLED'\n        to`tf.config.experimental.mlir_bridge_rollout` to enable a fallback for\n        the MLIR bridge in a \\\"safe\\\" mode. This runs the MLIR bridge in a\n        FallbackEnabled mode when an analysis of the graph determines that the\n        graph does not have unsupported features.\n\n*   Deterministic Op Functionality:\n\n    *   Add determinism-unimplemented exception-throwing to the segment-sum ops.\n        When the environment variable `TF_DETERMINISTIC_OPS` is set to `\"true\"`\n        or `\"1\"` (when op-determinism is expected), an attempt to run the\n        following ops on a GPU will throw `tf.errors.UnimplementedError` (with\n        an understandable message) when `data` is a floating-point type,\n        including complex types (if supported): `tf.math.segment_prod`,\n        `tf.math.segment_sum`, `tf.math.unsorted_segment_mean`,\n        `tf.math.unsorted_segment_sqrt_n`, `tf.math.unsorted_segment_prod`,\n        `tf.math.unsorted_segment_sum`, and therefore also\n        `tf.convert_to_tensor` when `value` is of type `tf.IndexedSlices` (such\n        as in the back prop though `tf.gather` into a dense embedding). See\n        issue [39751](https://github.com/tensorflow/tensorflow/issues/39751)\n        which this change addresses, but does not solve. This exception-throwing\n        behavior can be disabled by setting the environment variable\n        `TF_DISABLE_SEGMENT_REDUCTION_OP_DETERMINISM_EXCEPTIONS` to `\"true\"` or\n        `\"1\"`. For more information about these changes, see the description in\n        pull request\n        [47772](https://github.com/tensorflow/tensorflow/pull/47772).\n    *   In previous versions of TensorFlow, when a GPU was available,\n        `tf.sparse.sparse_dense_matmul` introduced truly random noise in the\n        forward path for data of type `tf.float32` but not for data of type\n        `tf.float64` (for which there was no GPU implementation). In this\n        current release, GPU support for other floating-point types\n        (`tf.float16`, `tf.float64`, `tf.complex64`, and `tf.complex128`) has\n        been added for this op. If you were relying on the determinism of the\n        `tf.float64` CPU implementation being automatically selected because of\n        the absence of the `tf.float64` GPU implementation, you with either need\n        to force the op to run on the CPU or use a different data type.\n\n*   Security\n\n    *   Fixes a heap buffer overflow in `RaggedBinCount`\n        ([CVE-2021-29512](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29512))\n    *   Fixes a heap out of bounds write in `RaggedBinCount`\n        ([CVE-2021-29514](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29514))\n    *   Fixes a type confusion during tensor casts which leads to dereferencing\n        null pointers\n        ([CVE-2021-29513](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29513))\n    *   Fixes a reference binding to null pointer in `MatrixDiag*` ops\n        ([CVE-2021-29515](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29515))\n    *   Fixes a null pointer dereference via invalid Ragged Tensors\n        ([CVE-2021-29516](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29516))\n    *   Fixes a division by zero in `Conv3D`\n        ([CVE-2021-29517](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29517))\n    *   Fixes vulnerabilities where session operations in eager mode lead to\n        null pointer dereferences\n        ([CVE-2021-29518](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29518))\n    *   Fixes a `CHECK`-fail in `SparseCross` caused by type confusion\n        ([CVE-2021-29519](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29519))\n    *   Fixes a segfault in `SparseCountSparseOutput`\n        ([CVE-2021-29521](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29521))\n    *   Fixes a heap buffer overflow in `Conv3DBackprop*`\n        ([CVE-2021-29520](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29520))\n    *   Fixes a division by 0 in `Conv3DBackprop*`\n        ([CVE-2021-29522](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29522))\n    *   Fixes a `CHECK`-fail in `AddManySparseToTensorsMap`\n        ([CVE-2021-29523](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29523))\n    *   Fixes a division by 0 in `Conv2DBackpropFilter`\n        ([CVE-2021-29524](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29524))\n    *   Fixes a division by 0 in `Conv2DBackpropInput`\n        ([CVE-2021-29525](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29525))\n    *   Fixes a division by 0 in `Conv2D`\n        ([CVE-2021-29526](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29526))\n    *   Fixes a division by 0 in `QuantizedConv2D`\n        ([CVE-2021-29527](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29527))\n    *   Fixes a division by 0 in `QuantizedMul`\n        ([CVE-2021-29528](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29528))\n    *   Fixes vulnerabilities caused by invalid validation in\n        `SparseMatrixSparseCholesky`\n        ([CVE-2021-29530](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29530))\n    *   Fixes a heap buffer overflow caused by rounding\n        ([CVE-2021-29529](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29529))\n    *   Fixes a `CHECK`-fail in `tf.raw_ops.EncodePng`\n        ([CVE-2021-29531](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29531))\n    *   Fixes a heap out of bounds read in `RaggedCross`\n        ([CVE-2021-29532](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29532))\n    *   Fixes a `CHECK`-fail in `DrawBoundingBoxes`\n        ([CVE-2021-29533](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29533))\n    *   Fixes a heap buffer overflow in `QuantizedMul`\n        ([CVE-2021-29535](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29535))\n    *   Fixes a `CHECK`-fail in `SparseConcat`\n        ([CVE-2021-29534](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29534))\n    *   Fixes a heap buffer overflow in `QuantizedResizeBilinear`\n        ([CVE-2021-29537](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29537))\n    *   Fixes a heap buffer overflow in `QuantizedReshape`\n        ([CVE-2021-29536](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29536))\n    *   Fixes a division by zero in `Conv2DBackpropFilter`\n        ([CVE-2021-29538](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29538))\n    *   Fixes a heap buffer overflow in `Conv2DBackpropFilter`\n        ([CVE-2021-29540](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29540))\n    *   Fixes a heap buffer overflow in `StringNGrams`\n        ([CVE-2021-29542](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29542))\n    *   Fixes a null pointer dereference in `StringNGrams`\n        ([CVE-2021-29541](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29541))\n    *   Fixes a `CHECK`-fail in `QuantizeAndDequantizeV4Grad`\n        ([CVE-2021-29544](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29544))\n    *   Fixes a `CHECK`-fail in `CTCGreedyDecoder`\n        ([CVE-2021-29543](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29543))\n    *   Fixes a heap buffer overflow in `SparseTensorToCSRSparseMatrix`\n        ([CVE-2021-29545](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29545))\n    *   Fixes a division by 0 in `QuantizedBiasAdd`\n        ([CVE-2021-29546](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29546))\n    *   Fixes a heap out of bounds in\n        `QuantizedBatchNormWithGlobalNormalization`\n        ([CVE-2021-29547](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29547))\n    *   Fixes a division by 0 in `QuantizedBatchNormWithGlobalNormalization`\n        ([CVE-2021-29548](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29548))\n    *   Fixes a division by 0 in `QuantizedAdd`\n        ([CVE-2021-29549](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29549))\n    *   Fixes a division by 0 in `FractionalAvgPool`\n        ([CVE-2021-29550](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29550))\n    *   Fixes an OOB read in `MatrixTriangularSolve`\n        ([CVE-2021-29551](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29551))\n    *   Fixes a heap OOB in `QuantizeAndDequantizeV3`\n        ([CVE-2021-29553](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29553))\n    *   Fixes a `CHECK`-failure in `UnsortedSegmentJoin`\n        ([CVE-2021-29552](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29552))\n    *   Fixes a division by 0 in `DenseCountSparseOutput`\n        ([CVE-2021-29554](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29554))\n    *   Fixes a division by 0 in `FusedBatchNorm`\n        ([CVE-2021-29555](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29555))\n    *   Fixes a division by 0 in `SparseMatMul`\n        ([CVE-2021-29557](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29557))\n    *   Fixes a division by 0 in `Reverse`\n        ([CVE-2021-29556](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29556))\n    *   Fixes a heap buffer overflow in `SparseSplit`\n        ([CVE-2021-29558](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29558))\n    *   Fixes a heap OOB access in unicode ops\n        ([CVE-2021-29559](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29559))\n    *   Fixes a heap buffer overflow in `RaggedTensorToTensor`\n        ([CVE-2021-29560](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29560))\n    *   Fixes a `CHECK`-fail in `LoadAndRemapMatrix`\n        ([CVE-2021-29561](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29561))\n    *   Fixes a `CHECK`-fail in `tf.raw_ops.IRFFT`\n        ([CVE-2021-29562](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29562))\n    *   Fixes a `CHECK`-fail in `tf.raw_ops.RFFT`\n        ([CVE-2021-29563](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29563))\n    *   Fixes a null pointer dereference in `EditDistance`\n        ([CVE-2021-29564](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29564))\n    *   Fixes a null pointer dereference in `SparseFillEmptyRows`\n        ([CVE-2021-29565](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29565))\n    *   Fixes a heap OOB access in `Dilation2DBackpropInput`\n        ([CVE-2021-29566](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29566))\n    *   Fixes a reference binding to null in `ParameterizedTruncatedNormal`\n        ([CVE-2021-29568](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29568))\n    *   Fixes a set of vulnerabilities caused by lack of validation in\n        `SparseDenseCwiseMul`\n        ([CVE-2021-29567](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29567))\n    *   Fixes a heap out of bounds read in `MaxPoolGradWithArgmax`\n        ([CVE-2021-29570](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29570))\n    *   Fixes a heap out of bounds read in `RequantizationRange`\n        ([CVE-2021-29569](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29569))\n    *   Fixes a memory corruption in `DrawBoundingBoxesV2`\n        ([CVE-2021-29571](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29571))\n    *   Fixes a reference binding to nullptr in `SdcaOptimizer`\n        ([CVE-2021-29572](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29572))\n    *   Fixes an overflow and a denial of service in\n        `tf.raw_ops.ReverseSequence`\n        ([CVE-2021-29575](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29575))\n    *   Fixes a division by 0 in `MaxPoolGradWithArgmax`\n        ([CVE-2021-29573](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29573))\n    *   Fixes an undefined behavior in `MaxPool3DGradGrad`\n        ([CVE-2021-29574](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29574))\n    *   Fixes a heap buffer overflow in `MaxPool3DGradGrad`\n        ([CVE-2021-29576](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29576))\n    *   Fixes a heap buffer overflow in `AvgPool3DGrad`\n        ([CVE-2021-29577](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29577))\n    *   Fixes an undefined behavior and a `CHECK`-fail in\n        `FractionalMaxPoolGrad`\n        ([CVE-2021-29580](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29580))\n    *   Fixes a heap buffer overflow in `FractionalAvgPoolGrad`\n        ([CVE-2021-29578](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29578))\n    *   Fixes a heap buffer overflow in `MaxPoolGrad`\n        ([CVE-2021-29579](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29579))\n    *   Fixes a segfault in `CTCBeamSearchDecoder`\n        ([CVE-2021-29581](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29581))\n    *   Fixes a heap OOB read in `tf.raw_ops.Dequantize`\n        ([CVE-2021-29582](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29582))\n    *   Fixes a `CHECK`-fail due to integer overflow\n        ([CVE-2021-29584](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29584))\n    *   Fixes a heap buffer overflow and undefined behavior in `FusedBatchNorm`\n        ([CVE-2021-29583](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29583))\n    *   Fixes a division by zero in padding computation in TFLite\n        ([CVE-2021-29585](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29585))\n    *   Fixes a division by zero in optimized pooling implementations in TFLite\n        ([CVE-2021-29586](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29586))\n    *   Fixes a division by zero in TFLite's implementation of `SpaceToDepth`\n        ([CVE-2021-29587](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29587))\n    *   Fixes a division by zero in TFLite's implementation of `GatherNd`\n        ([CVE-2021-29589](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29589))\n    *   Fixes a division by zero in TFLite's implementation of `TransposeConv`\n        ([CVE-2021-29588](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29588))\n    *   Fixes a heap OOB read in TFLite's implementation of `Minimum` or\n        `Maximum`\n        ([CVE-2021-29590](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29590))\n    *   Fixes a null pointer dereference in TFLite's `Reshape` operator\n        ([CVE-2021-29592](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29592))\n    *   Fixes a stack overflow due to looping TFLite subgraph\n        ([CVE-2021-29591](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29591))\n    *   Fixes a division by zero in TFLite's implementation of `DepthToSpace`\n        ([CVE-2021-29595](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29595))\n    *   Fixes a division by zero in TFLite's convolution code\n        ([CVE-2021-29594](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29594))\n    *   Fixes a division by zero in TFLite's implementation of `EmbeddingLookup`\n        ([CVE-2021-29596](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29596))\n    *   Fixes a division by zero in TFLite's implementation of `BatchToSpaceNd`\n        ([CVE-2021-29593](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29593))\n    *   Fixes a division by zero in TFLite's implementation of `SpaceToBatchNd`\n        ([CVE-2021-29597](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29597))\n    *   Fixes a division by zero in TFLite's implementation of `SVDF`\n        ([CVE-2021-29598](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29598))\n    *   Fixes a division by zero in TFLite's implementation of `Split`\n        ([CVE-2021-29599](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29599))\n    *   Fixes a division by zero in TFLite's implementation of `OneHot`\n        ([CVE-2021-29600](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29600))\n    *   Fixes a division by zero in TFLite's implementation of `DepthwiseConv`\n        ([CVE-2021-29602](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29602))\n    *   Fixes a division by zero in TFLite's implementation of hashtable lookup\n        ([CVE-2021-29604](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29604))\n    *   Fixes a integer overflow in TFLite concatentation\n        ([CVE-2021-29601](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29601))\n    *   Fixes a integer overflow in TFLite memory allocation\n        ([CVE-2021-29605](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29605))\n    *   Fixes a heap OOB write in TFLite\n        ([CVE-2021-29603](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29603))\n    *   Fixes a heap OOB read in TFLite\n        ([CVE-2021-29606](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29606))\n    *   Fixes a heap OOB and null pointer dereference in `RaggedTensorToTensor`\n        ([CVE-2021-29608](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29608))\n    *   Fixes vulnerabilities caused by incomplete validation in `SparseAdd`\n        ([CVE-2021-29609](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29609))\n    *   Fixes vulnerabilities caused by incomplete validation in\n        `SparseSparseMinimum`\n        ([CVE-2021-29607](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29607))\n    *   Fixes vulnerabilities caused by incomplete validation in `SparseReshape`\n        ([CVE-2021-29611](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29611))\n    *   Fixes vulnerabilities caused by invalid validation in\n        `QuantizeAndDequantizeV2`\n        ([CVE-2021-29610](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29610))\n    *   Fixes a heap buffer overflow in `BandedTriangularSolve`\n        ([CVE-2021-29612](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29612))\n    *   Fixes vulnerabilities caused by incomplete validation in\n        `tf.raw_ops.CTCLoss`\n        ([CVE-2021-29613](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29613))\n    *   Fixes an interpreter crash from vulnerabilities in `tf.io.decode_raw`\n        ([CVE-2021-29614](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29614))\n    *   Fixes a stack overflow in `ParseAttrValue` with nested tensors\n        ([CVE-2021-29615](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29615))\n    *   Fixes a null dereference in Grappler's `TrySimplify`\n        ([CVE-2021-29616](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29616))\n    *   Fixes a crash in `tf.transpose` with complex inputs\n        ([CVE-2021-29618](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29618))\n    *   Fixes a crash in `tf.strings.substr` due to `CHECK`-fail\n        ([CVE-2021-29617](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29617))\n    *   Fixes a segfault in `tf.raw_ops.SparseCountSparseOutput`\n        ([CVE-2021-29619](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29619))\n    *   Fixes a segfault in `tf.raw_ops.ImmutableConst`\n        ([CVE-2021-29539](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-29539))\n    *   Updates `curl` to `7.76.0` to handle\n        [CVE-2020-8169](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2020-8169),\n        [CVE-2020-8177](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2020-8177),\n        [CVE-2020-8231](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2020-8231),\n        [CVE-2020-8284](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2020-8284),\n        [CVE-2020-8285](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2020-8285)\n        and\n        [CVE-2020-8286](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2020-8286).\n\n*   Other\n\n    *   Added `show_debug_info` to `mlir.convert_graph_def` and\n        `mlir.convert_function`.\n    *   Added\n        [Arm Compute Library (ACL)](https://github.com/ARM-software/ComputeLibrary)\n        support to `--config=mkl_aarch64` build.\n\n## Thanks to our Contributors\n\nThis release contains contributions from many people at Google, as well as:\n\n8bitmp3, Aaron S. Mondal, Abhilash Mahendrakar, Abhinav Upadhyay, Abhishek\nKulkarni, Abolfazl Shahbazi, Adam Hillier, Aditya Kane, Ag Ramesh, ahmedsabie,\nAlbert Villanova Del Moral, Aleksey Vitebskiy, Alex Hoffman, Alexander Bayandin,\nAlfie Edwards, Aman Kishore, Amogh Joshi, andreABbauer, Andrew Goodbody, Andrzej\nPomirski, Artemiy Ryabinkov, Ashish Jha, ather, Ayan Moitra, Bairen Yi, Bart\nRibbers, Bas Aarts, Behzad Abghari, Ben Arnao, Ben Barsdell, Benjamin Klimczak,\nbhack, Brendan Collins, Can Wang, Cheng Ren, Chris Leary, Chris Olivier, Clemens\nGiuliani, Cloud Han, Corey Cole, Cui, Yifeng, Cuong V. Nguyen, Daniel Moore,\nDawid Wojciechowski, Ddavis-2015, Dean Wyatte, Denisa Roberts, dependabot[bot],\nDmitry Volodin, Dominic Jack, Duncan Riach, dushuai, Elena Zhelezina, Eli\nOsherovich, Erik Smistad, ewsn1593, Felix Fent, fo40225, Franois Chollet,\nFrederic Bastien, Freedom\" Koan-Sin Tan, fsx950223, ganand1, gbaned, Georgiy\nManuilov, gerbauz, Guillaume Klein, Guozhong Zhuang, Harry Slatyer, Harsh188,\nhenri, Henri Woodcock, Hiran Sarkar, Hollow Man, Hkon Sandsmark, I Wayan\nDharmana, icysapphire, Ikko Ashimine, Jab Hofmeier, Jack Hessel, Jacob Valdez,\nJakub Jatczak, James Bernardi, Jared Smolens, Jason Zaman, jedlimlx, Jenny\nPlunkett, Jens Elofsson, Jerry Shih, jgehw, Jia Fu Low, Jim Fisher, jpodivin,\nJulien Stephan, Jungsub Lim, Junha Park, Junhyuk So, justkw, Kaixi Hou,\nkashyapraval, Kasra Bigdeli, Kazuaki Ishizaki, Keith Mok, Kevin Cheng, kopytjuk,\nKristian Hartikainen, ksood12345, Kulin Seth, kushanam, latyas, Lequn Chen,\nLeslie-Fang, Long M. Lu, Lukas Geiger, machineko, Mahmoud Abuzaina, Manish, Mao\nYunfei, Maozhou, Ge, Marcin Juszkiewicz, Marcin Owsiany, Marconi Jiang, Marcos\nPereira, Maria Romanenko Vexlard, Maria Vexlard, Marius Brehler, marload, Martin\nKubovk, Matej, Mateusz Holenko, Maxiwell S. Garcia, Mazhar, mazharul,\nmbhuiyan, mdfaijul, Michael Gielda, Michael Kuchnik, Michal Szutenberg, Mikhail\nStepanov, Milan Straka, Mitchel Humpherys, Mohamed Moselhy, Mohamed Nour\nAbouelseoud, Mns Bermell, Mns Nilsson, Nathan Luehr, Nico Jahn, Niroop\nAmmbashankar, Oceania2018, Omri Steiner, Orivej Desh, Oskar Flordal, oujiafan,\nPatrik Laurell, Paul B. Isaac'S, Paul Klinger, Pawel Piskorski, Pedro Marques,\nPhat Tran, Piotr Zierhoffer, piyushdatta, Pnikam-Cad, Prashant Kumar, Prateek\nGupta, PratsBhatt, Pravin Karandikar, qqq.jq, QQ, Quintin, Rama Ketineni,\nravikyram, Rehan Guha, rhdong, rmothukuru, Roger Cheng, Rohit Santhanam, rposts,\nRsanthanam-Amd, rsun, Rsun-Bdti, Ryan Kuester, ryanking13, Saduf2019, Sami Kama,\nSamuel Marks, Scott Tseng, Sean Moriarity, Sergey Popov, Sergii Khomenko, Sheng,\nYang, shwetaoj, Sidong-Wei, Simon Maurer, Simrit Kaur, Srini511, Srinivasan\nNarayanamoorthy, Stephan, Stephen Matthews, Sungmann Cho, Sunoru, Suraj Sudhir,\nSuraj Upadhyay, Taebum Kim, Takayoshi Koizumi, Tamas Bela Feher, Teng Lu,\nThibaut Goetghebuer-Planchon, Tomwildenhain-Microsoft, Tony, Traun Leyden, Trent\nLo, TVLIgnacy, Tzu-Wei Sung, vaibhav, Vignesh Kothapalli, Vikram Dattu,\nviktprog, Vinayaka Bandishti, Vincent Abriou, Vishakha Agrawal, Vivek Panyam,\nVladimir Silyaev, V Vn Ngha, wamuir, Wang, Yanzhang, wangsiyu, Waqar Hameed,\nwxinix, Xiao Yang, xiaohong1031, Xiaoming (Jason) Cui, Xinan Jiang, Yair\nEhrenwald, Yajush Vyas, Yasir Modak, Yimei Sun, Yong Tang, Yosshi999,\nyoushenmebutuo, yqtianust, Yuan Tang, yuanbopeng, Yuriy Chernyshov, Yuta\nFukasawa, Zachary Deane-Mayer, Zeno Gantner, Zhoulong Jiang, zhuyie, zilinzhu,\n\n\n# Release 2.4.1\n\n*   This release removes the AVX2 requirement from TF 2.4.0.\n\n# Release 2.3.2\n\n## Bug Fixes and Other Changes\n\n*   Fixes an access to unitialized memory in Eigen code\n    ([CVE-2020-26266](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2020-26266))\n*   Fixes a security vulnerability caused by lack of validation in\n    `tf.raw_ops.DataFormatVecPermute` and `tf.raw_ops.DataFormatDimMap`\n    ([CVE-2020-26267](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2020-26267))\n*   Fixes a vulnerability caused by attempting to write to immutable memory\n    region in `tf.raw_ops.ImmutableConst`\n    ([CVE-2020-26268](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2020-26268)\n*   Fixes a `CHECK`-fail in LSTM with zero-length input\n    ([CVE-2020-26270](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2020-26270))\n*   Fixes a security vulnerability caused by accessing heap data outside of\n    bounds when loading a specially crafted `SavedModel`\n    ([CVE-2020-26271](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2020-26271))\n*   Solves an OOM issue on TPUs when XLA contexts use fused average updates\n*   Updates `libjpeg-turbo` to `2.0.5` to handle\n    [CVE-2020-13790](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2020-13790).\n*   Updates `junit` to `4.13.1` to handle\n    [CVE-2020-15250](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2020-15250).\n*   Updates `PCRE` to `8.44` to handle\n    [CVE-2019-20838](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2019-20838)\n    and\n    [CVE-2020-14155](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2020-14155).\n*   Updates `sqlite3` to `3.44.0` to keep in sync with master branch.\n\n# Release 2.2.2\n\n## Bug Fixes and Other Changes\n\n*   Fixes an access to unitialized memory in Eigen code\n    ([CVE-2020-26266](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2020-26266))\n*   Fixes a security vulnerability caused by lack of validation in\n    `tf.raw_ops.DataFormatVecPermute` and `tf.raw_ops.DataFormatDimMap`\n    ([CVE-2020-26267](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2020-26267))\n*   Fixes a vulnerability caused by attempting to write to immutable memory\n    region in `tf.raw_ops.ImmutableConst`\n    ([CVE-2020-26268](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2020-26268)\n*   Fixes a `CHECK`-fail in LSTM with zero-length input\n    ([CVE-2020-26270](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2020-26270))\n*   Fixes a security vulnerability caused by accessing heap data outside of\n    bounds when loading a specially crafted `SavedModel`\n    ([CVE-2020-26271](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2020-26271))\n*   Prevents memory leaks in loading `SavedModel`s that import functions\n*   Updates `libjpeg-turbo` to `2.0.5` to handle\n    [CVE-2020-13790](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2020-13790).\n*   Updates `junit` to `4.13.1` to handle\n    [CVE-2020-15250](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2020-15250).\n*   Updates `PCRE` to `8.44` to handle\n    [CVE-2019-20838](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2019-20838)\n    and\n    [CVE-2020-14155](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2020-14155).\n*   Updates `sqlite3` to `3.44.0` to keep in sync with master branch.\n\n# Release 2.1.3\n\n## Bug Fixes and Other Changes\n\n*   Fixes an access to unitialized memory in Eigen code\n    ([CVE-2020-26266](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2020-26266))\n*   Fixes a security vulnerability caused by lack of validation in\n    `tf.raw_ops.DataFormatVecPermute` and `tf.raw_ops.DataFormatDimMap`\n    ([CVE-2020-26267](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2020-26267))\n*   Fixes a vulnerability caused by attempting to write to immutable memory\n    region in `tf.raw_ops.ImmutableConst`\n    ([CVE-2020-26268](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2020-26268)\n*   Fixes a `CHECK`-fail in LSTM with zero-length input\n    ([CVE-2020-26270](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2020-26270))\n*   Fixes a security vulnerability caused by accessing heap data outside of\n    bounds when loading a specially crafted `SavedModel`\n    ([CVE-2020-26271](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2020-26271))\n*   Updates `libjpeg-turbo` to `2.0.5` to handle\n    [CVE-2020-13790](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2020-13790).\n*   Updates `junit` to `4.13.1` to handle\n    [CVE-2020-15250](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2020-15250).\n*   Updates `PCRE` to `8.44` to handle\n    [CVE-2019-20838](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2019-20838)\n    and\n    [CVE-2020-14155](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2020-14155).\n*   Updates `sqlite3` to `3.44.0` to keep in sync with master branch.\n*   Newer ROCm versions are supported on the 2.1 branch.\n\n# Release 2.0.4\n\nNote that this is the last patch release for the TensorFlow 2.0.x series.\n\n## Bug Fixes and Other Changes\n\n*   Fixes an access to unitialized memory in Eigen code\n    ([CVE-2020-26266](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2020-26266))\n*   Fixes a security vulnerability caused by lack of validation in\n    `tf.raw_ops.DataFormatVecPermute` and `tf.raw_ops.DataFormatDimMap`\n    ([CVE-2020-26267](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2020-26267))\n*   Fixes a vulnerability caused by attempting to write to immutable memory\n    region in `tf.raw_ops.ImmutableConst`\n    ([CVE-2020-26268](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2020-26268)\n*   Fixes a `CHECK`-fail in LSTM with zero-length input\n    ([CVE-2020-26270](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2020-26270))\n*   Fixes a security vulnerability caused by accessing heap data outside of\n    bounds when loading a specially crafted `SavedModel`\n    ([CVE-2020-26271](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2020-26271))\n*   Updates `libjpeg-turbo` to `2.0.5` to handle\n    [CVE-2020-13790](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2020-13790).\n*   Updates `junit` to `4.13.1` to handle\n    [CVE-2020-15250](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2020-15250).\n*   Updates `PCRE` to `8.44` to handle\n    [CVE-2019-20838](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2019-20838)\n    and\n    [CVE-2020-14155](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2020-14155).\n*   Updates `sqlite3` to `3.44.0` to keep in sync with master branch.\n\n# Release 1.15.5\n\nNote that this is the last patch release for the TensorFlow 1.x series.\n\n## Bug Fixes and Other Changes\n\n*   Fixes an access to unitialized memory in Eigen code\n    ([CVE-2020-26266](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2020-26266))\n*   Fixes a security vulnerability caused by lack of validation in\n    `tf.raw_ops.DataFormatVecPermute` and `tf.raw_ops.DataFormatDimMap`\n    ([CVE-2020-26267](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2020-26267))\n*   Fixes a vulnerability caused by attempting to write to immutable memory\n    region in `tf.raw_ops.ImmutableConst`\n    ([CVE-2020-26268](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2020-26268)\n*   Fixes a `CHECK`-fail in LSTM with zero-length input\n    ([CVE-2020-26270](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2020-26270))\n*   Fixes a security vulnerability caused by accessing heap data outside of\n    bounds when loading a specially crafted `SavedModel`\n    ([CVE-2020-26271](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2020-26271))\n*   Updates `libjpeg-turbo` to `2.0.5` to handle\n    [CVE-2020-13790](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2020-13790).\n*   Updates `junit` to `4.13.1` to handle\n    [CVE-2020-15250](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2020-15250).\n*   Updates `PCRE` to `8.44` to handle\n    [CVE-2019-20838](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2019-20838)\n    and\n    [CVE-2020-14155](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2020-14155).\n*   Updates `sqlite3` to `3.44.0` to keep in sync with master branch.\n\n# Release 2.4.0\n\n\\## Major Features and Improvements\n\n*   `tf.distribute` introduces experimental support for asynchronous training of\n    models via the\n    [`tf.distribute.experimental.ParameterServerStrategy`](https://www.tensorflow.org/api_docs/python/tf/distribute/experimental/ParameterServerStrategy)\n    API. Please see the\n    [tutorial](https://www.tensorflow.org/tutorials/distribute/parameter_server_training)\n    to learn more.\n\n*   [`MultiWorkerMirroredStrategy`](https://www.tensorflow.org/api_docs/python/tf/distribute/MultiWorkerMirroredStrategy)\n    is now a stable API and is no longer considered experimental. Some of the\n    major improvements involve handling peer failure and many bug fixes. Please\n    check out the detailed tutorial on\n    [Multi-worker training with Keras](https://www.tensorflow.org/tutorials/distribute/multi_worker_with_keras).\n\n*   Introduces experimental support for a new module named\n    [`tf.experimental.numpy`](https://www.tensorflow.org/api_docs/python/tf/experimental/numpy)\n    which is a NumPy-compatible API for writing TF programs. See the\n    [detailed guide](https://www.tensorflow.org/guide/tf_numpy) to learn more.\n    Additional details below.\n\n*   Adds Support for\n    [TensorFloat-32](https://blogs.nvidia.com/blog/2020/05/14/tensorfloat-32-precision-format/)\n    on Ampere based GPUs. TensorFloat-32, or TF32 for short, is a math mode for\n    NVIDIA Ampere based GPUs and is enabled by default.\n\n*   A major refactoring of the internals of the Keras Functional API has been\n    completed, that should improve the reliability, stability, and performance\n    of constructing Functional models.\n\n*   Keras mixed precision API\n    [`tf.keras.mixed_precision`](https://www.tensorflow.org/api_docs/python/tf/keras/mixed_precision?version=nightly)\n    is no longer experimental and allows the use of 16-bit floating point\n    formats during training, improving performance by up to 3x on GPUs and 60%\n    on TPUs. Please see below for additional details.\n\n*   TensorFlow Profiler now supports profiling `MultiWorkerMirroredStrategy` and\n    tracing multiple workers using the\n    [sampling mode API](https://www.tensorflow.org/guide/profiler#profiling_apis).\n\n*   TFLite Profiler for Android is available. See the detailed\n    [guide](https://www.tensorflow.org/lite/performance/measurement#trace_tensorflow_lite_internals_in_android)\n    to learn more.\n\n*   TensorFlow pip packages are now built with CUDA11 and cuDNN 8.0.2.\n\n## Breaking Changes\n\n*   TF Core:\n\n    *   Certain float32 ops run in lower precision on Ampere based GPUs,\n        including matmuls and convolutions, due to the use of\n        [TensorFloat-32](https://blogs.nvidia.com/blog/2020/05/14/tensorfloat-32-precision-format/).\n        Specifically, inputs to such ops are rounded from 23 bits of precision\n        to 10 bits of precision. This is unlikely to cause issues in practice\n        for deep learning models. In some cases, TensorFloat-32 is also used for\n        complex64 ops. TensorFloat-32 can be disabled by running\n        `tf.config.experimental.enable_tensor_float_32_execution(False)`.\n    *   The byte layout for string tensors across the C-API has been updated to\n        match TF Core/C++; i.e., a contiguous array of\n        `tensorflow::tstring`/`TF_TString`s.\n    *   C-API functions `TF_StringDecode`, `TF_StringEncode`, and\n        `TF_StringEncodedSize` are no longer relevant and have been removed; see\n        `core/platform/ctstring.h` for string access/modification in C.\n    *   `tensorflow.python`, `tensorflow.core` and `tensorflow.compiler` modules\n        are now hidden. These modules are not part of TensorFlow public API.\n    *   `tf.raw_ops.Max` and `tf.raw_ops.Min` no longer accept inputs of type\n        `tf.complex64` or `tf.complex128`, because the behavior of these ops is\n        not well defined for complex types.\n    *   XLA:CPU and XLA:GPU devices are no longer registered by default. Use\n        `TF_XLA_FLAGS=--tf_xla_enable_xla_devices` if you really need them, but\n        this flag will eventually be removed in subsequent releases.\n\n*   `tf.keras`:\n\n    *   The `steps_per_execution` argument in `model.compile()` is no longer\n        experimental; if you were passing `experimental_steps_per_execution`,\n        rename it to `steps_per_execution` in your code. This argument controls\n        the number of batches to run during each `tf.function` call when calling\n        `model.fit()`. Running multiple batches inside a single `tf.function`\n        call can greatly improve performance on TPUs or small models with a\n        large Python overhead.\n    *   A **major refactoring** of the internals of the Keras Functional API may\n        affect code that is relying on certain internal details:\n    *   Code that uses `isinstance(x, tf.Tensor)` instead of `tf.is_tensor` when\n        checking Keras symbolic inputs/outputs should switch to using\n        `tf.is_tensor`.\n    *   Code that is overly dependent on the exact names attached to symbolic\n        tensors (e.g. assumes there will be \":0\" at the end of the inputs,\n        treats names as unique identifiers instead of using `tensor.ref()`,\n        etc.) may break.\n    *   Code that uses full path for `get_concrete_function` to trace Keras\n        symbolic inputs directly should switch to building matching\n        `tf.TensorSpec`s directly and tracing the `TensorSpec` objects.\n    *   Code that relies on the exact number and names of the op layers that\n        TensorFlow operations were converted into may have changed.\n    *   Code that uses `tf.map_fn`/`tf.cond`/`tf.while_loop`/control flow as op\n        layers and happens to work before TF 2.4. These will explicitly be\n        unsupported now. Converting these ops to Functional API op layers was\n        unreliable before TF 2.4, and prone to erroring incomprehensibly or\n        being silently buggy.\n    *   Code that directly asserts on a Keras symbolic value in cases where ops\n        like `tf.rank` used to return a static or symbolic value depending on if\n        the input had a fully static shape or not. Now these ops always return\n        symbolic values.\n    *   Code already susceptible to leaking tensors outside of graphs becomes\n        slightly more likely to do so now.\n    *   Code that tries directly getting gradients with respect to symbolic\n        Keras inputs/outputs. Use `GradientTape` on the actual Tensors passed to\n        the already-constructed model instead.\n    *   Code that requires very tricky shape manipulation via converted op\n        layers in order to work, where the Keras symbolic shape inference proves\n        insufficient.\n    *   Code that tries manually walking a `tf.keras.Model` layer by layer and\n        assumes layers only ever have one positional argument. This assumption\n        doesn't hold true before TF 2.4 either, but is more likely to cause\n        issues now.\n    *   Code that manually enters `keras.backend.get_graph()` before building a\n        functional model is no longer needed.\n    *   Start enforcing input shape assumptions when calling Functional API\n        Keras models. This may potentially break some users, in case there is a\n        mismatch between the shape used when creating `Input` objects in a\n        Functional model, and the shape of the data passed to that model. You\n        can fix this mismatch by either calling the model with correctly-shaped\n        data, or by relaxing `Input` shape assumptions (note that you can pass\n        shapes with `None` entries for axes that are meant to be dynamic). You\n        can also disable the input checking entirely by setting\n        `model.input_spec = None`.\n    *   Several changes have been made to\n        `tf.keras.mixed_precision.experimental`. Note that it is now recommended\n        to use the non-experimental `tf.keras.mixed_precision` API.\n    *   `AutoCastVariable.dtype` now refers to the actual variable dtype, not\n        the dtype it will be casted to.\n    *   When mixed precision is enabled, `tf.keras.layers.Embedding` now outputs\n        a float16 or bfloat16 tensor instead of a float32 tensor.\n    *   The property\n        `tf.keras.mixed_precision.experimental.LossScaleOptimizer.loss_scale` is\n        now a tensor, not a `LossScale` object. This means to get a loss scale\n        of a `LossScaleOptimizer` as a tensor, you must now call\n        `opt.loss_scale`instead of `opt.loss_scale()`.\n    *   The property `should_cast_variables` has been removed from\n        `tf.keras.mixed_precision.experimental.Policy`\n    *   When passing a `tf.mixed_precision.experimental.DynamicLossScale` to\n        `tf.keras.mixed_precision.experimental.LossScaleOptimizer`, the\n        `DynamicLossScale`'s multiplier must be 2.\n    *   When passing a `tf.mixed_precision.experimental.DynamicLossScale` to\n        `tf.keras.mixed_precision.experimental.LossScaleOptimizer`, the weights\n        of the `DynanmicLossScale` are copied into the `LossScaleOptimizer`\n        instead of being reused. This means modifying the weights of the\n        `DynamicLossScale` will no longer affect the weights of the\n        LossScaleOptimizer, and vice versa.\n    *   The global policy can no longer be set to a non-floating point policy in\n        `tf.keras.mixed_precision.experimental.set_policy`\n    *   In `Layer.call`, `AutoCastVariable`s will no longer be casted within\n        `MirroredStrategy.run` or `ReplicaContext.merge_call`. This is because a\n        thread local variable is used to determine whether `AutoCastVariable`s\n        are casted, and those two functions run with a different thread. Note\n        this only applies if one of these two functions is called within\n        `Layer.call`; if one of those two functions calls `Layer.call`,\n        `AutoCastVariable`s will still be casted.\n\n*   `tf.data`:\n\n    *   `tf.data.experimental.service.DispatchServer` now takes a config tuple\n        instead of individual arguments. Usages should be updated to\n        `tf.data.experimental.service.DispatchServer(dispatcher_config)`.\n    *   `tf.data.experimental.service.WorkerServer` now takes a config tuple\n        instead of individual arguments. Usages should be updated to\n        `tf.data.experimental.service.WorkerServer(worker_config)`.\n\n*   `tf.distribute`:\n\n    *   Removes `tf.distribute.Strategy.experimental_make_numpy_dataset`. Please\n        use `tf.data.Dataset.from_tensor_slices` instead.\n    *   Renames `experimental_hints` in\n        `tf.distribute.StrategyExtended.reduce_to`,\n        `tf.distribute.StrategyExtended.batch_reduce_to`,\n        `tf.distribute.ReplicaContext.all_reduce` to `options`.\n    *   Renames `tf.distribute.experimental.CollectiveHints` to\n        `tf.distribute.experimental.CommunicationOptions`.\n    *   Renames `tf.distribute.experimental.CollectiveCommunication` to\n        `tf.distribute.experimental.CommunicationImplementation`.\n    *   Renames\n        `tf.distribute.Strategy.experimental_distribute_datasets_from_function`\n        to `distribute_datasets_from_function` as it is no longer experimental.\n    *   Removes `tf.distribute.Strategy.experimental_run_v2` method, which was\n        deprecated in TF 2.2.\n\n*   `tf.lite`:\n\n    *   `tf.quantization.quantize_and_dequantize_v2` has been introduced, which\n        updates the gradient definition for quantization which is outside the\n        range to be 0. To simulate the V1 the behavior of\n        `tf.quantization.quantize_and_dequantize(...)` use\n        `tf.grad_pass_through(tf.quantization.quantize_and_dequantize_v2)(...)`.\n\n*   Building TensorFlow:\n\n    *   Windows platform builds: TensorFlow on Windows under MSVC is now built\n        with `--copt=/experimental:preprocessor\n        --host_copt=/experimental:preprocessor` (see `.bazelrc` for more\n        details). Builds including TensorFlow may fail with unexpected syntax\n        errors if these flags are absent. See also\n        [this thread on SIG Build](https://groups.google.com/a/tensorflow.org/g/build/c/LbAw8RILvTg/m/ttnuhYU2BgAJ).\n\n## Known Caveats\n\n*   `tf.keras.mixed_precision`\n    *   When using mixed precision, calling `RMSprop.apply_gradients` or\n        `Nadam.apply_gradients` outside a `tf.function` does not work and will\n        raise the AttributeError \"Tensor.op is meaningless when eager execution\n        is enabled\". See this\n        [issue](https://github.com/tensorflow/tensorflow/issues/45536) for\n        details and a workaround.\n\n## Bug Fixes and Other Changes\n\n### TF Core:\n\n*   Introduces experimental support for a new module named\n    [`tf.experimental.numpy`](https://www.tensorflow.org/api_docs/python/tf/experimental/numpy),\n    which is a NumPy-compatible API for writing TF programs. This module\n    provides class `ndarray`, which mimics the `ndarray` class in NumPy, and\n    wraps an immutable `tf.Tensor` under the hood. A subset of NumPy functions\n    (e.g. `numpy.add`) are provided. Their inter-operation with TF facilities is\n    seamless in most cases. See\n    [tensorflow/python/ops/numpy_ops/README.md](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/ops/numpy_ops/README.md)\n    for details of what operations are supported and what are the differences\n    from NumPy.\n*   `tf.types.experimental.TensorLike` is a new `Union` type that can be used as\n    type annotation for variables representing a Tensor or a value that can be\n    converted to Tensor by `tf.convert_to_tensor`.\n*   Calling ops with a python constants or numpy values is now consistent with\n    tf.convert_to_tensor behavior. This avoids operations like tf.reshape\n    truncating inputs such as from int64 to int32.\n*   Adds `tf.sparse.map_values` to apply a function to the `.value`s of\n    `SparseTensor` arguments.\n*   The Python bitwise operators for `Tensor` (`__and__`, `__or__`, `__xor__`\n    and `__invert__` now support non-`bool` arguments and apply the\n    corresponding bitwise ops. `bool` arguments continue to be supported and\n    dispatch to logical ops. This brings them more in line with Python and NumPy\n    behavior.\n*   Adds `tf.SparseTensor.with_values`. This returns a new SparseTensor with the\n    same sparsity pattern, but with new provided values. It is similar to the\n    `with_values` function of `RaggedTensor`.\n*   Adds `StatelessCase` op, and uses it if none of case branches has stateful\n    ops.\n*   Adds `tf.config.experimental.get_memory_usage` to return total memory usage\n    of the device.\n*   Adds gradients for `RaggedTensorToVariant` and `RaggedTensorFromVariant`.\n*   Improve shape inference of nested function calls by supporting constant\n    folding across Arg nodes which makes more static values available to shape\n    inference functions.\n*   `tf.debugging`:\n    *   `tf.debugging.assert_shapes()` now works on `SparseTensor`s (Fixes\n        [#36268](https://github.com/tensorflow/tensorflow/issues/36268)).\n*   GPU\n    *   Adds Support for\n        [TensorFloat-32](https://blogs.nvidia.com/blog/2020/05/14/tensorfloat-32-precision-format/)\n        on Ampere based GPUs.TensorFloat-32, or TF32 for short, is a math mode\n        for NVIDIA Ampere based GPUs which causes certain float32 ops, such as\n        matrix multiplications and convolutions, to run much faster on Ampere\n        GPUs but with reduced precision. This reduced precision has not been\n        found to effect convergence quality of deep learning models in practice.\n        TensorFloat-32 is enabled by default, but can be disabled with\n        `tf.config.experimental.enable_tensor_float_32_execution`.\n*   `tf.math`:\n    *   Adds `tf.math.erfcinv`, the inverse to `tf.math.erfc`.\n*   `tf.nn`:\n    *   `tf.nn.max_pool2d` now supports explicit padding.\n*   `tf.image`:\n    *   Adds deterministic `tf.image.stateless_random_*` functions for each\n        `tf.image.random_*` function. Added a new op\n        `stateless_sample_distorted_bounding_box` which is a deterministic\n        version of `sample_distorted_bounding_box` op. Given the same seed,\n        these stateless functions/ops produce the same results independent of\n        how many times the function is called, and independent of global seed\n        settings.\n    *   Adds deterministic `tf.image.resize` backprop CUDA kernels for\n        `method=ResizeMethod.BILINEAR` (the default method). Enable by setting\n        the environment variable `TF_DETERMINISTIC_OPS` to `\"true\"` or `\"1\"`.\n*   `tf.print`:\n    *   Bug fix in `tf.print()` with `OrderedDict` where if an `OrderedDict`\n        didn't have the keys sorted, the keys and values were not being printed\n        in accordance with their correct mapping.\n*   `tf.train.Checkpoint`:\n    *   Now accepts a `root` argument in the initialization, which generates a\n        checkpoint with a root object. This allows users to create a\n        `Checkpoint` object that is compatible with Keras `model.save_weights()`\n        and `model.load_weights`. The checkpoint is also compatible with the\n        checkpoint saved in the `variables/` folder in the SavedModel.\n    *   When restoring, `save_path` can be a path to a SavedModel. The function\n        will automatically find the checkpoint in the SavedModel.\n\n### `tf.data`:\n\n*   Adds new `tf.data.experimental.service.register_dataset` and\n    `tf.data.experimental.service.from_dataset_id` APIs to enable one process to\n    register a dataset with the tf.data service, and another process to consume\n    data from the dataset.\n*   Adds support for dispatcher fault tolerance. To enable fault tolerance,\n    configure a `work_dir` when running your dispatcher server and set\n    `dispatcher_fault_tolerance=True`. The dispatcher will store its state to\n    `work_dir`, so that on restart it can continue from its previous state after\n    restart.\n*   Adds support for sharing dataset graphs via shared filesystem instead of\n    over RPC. This reduces load on the dispatcher, improving performance of\n    distributing datasets. For this to work, the dispatcher's `work_dir` must be\n    accessible from workers. If the worker fails to read from the `work_dir`, it\n    falls back to using RPC for dataset graph transfer.\n*   Adds support for a new \"distributed_epoch\" processing mode. This processing\n    mode distributes a dataset across all tf.data workers, instead of having\n    each worker process the full dataset. See\n    [the tf.data service docs](https://www.tensorflow.org/api_docs/python/tf/data/experimental/service#understand_processing_mode)\n    to learn more.\n*   Adds optional `exclude_cols` parameter to CsvDataset. This parameter is the\n    complement of `select_cols`; at most one of these should be specified.\n*   We have implemented an optimization which reorders data-discarding\n    transformations such as `take` and `shard` to happen earlier in the dataset\n    when it is safe to do so. The optimization can be disabled via the\n    `experimental_optimization.reorder_data_discarding_ops` dataset option.\n*   `tf.data.Options` were previously immutable and can now be overridden.\n*   `tf.data.Dataset.from_generator` now supports Ragged and Sparse tensors with\n    a new `output_signature` argument, which allows `from_generator` to produce\n    any type describable by a `tf.TypeSpec`.\n*   `tf.data.experimental.AUTOTUNE` is now available in the core API as\n    `tf.data.AUTOTUNE`.\n\n### `tf.distribute`:\n\n*   Introduces experimental support for asynchronous training of models via\n    `tf.distribute.experimental.ParameterServerStrategy`:\n    *   Replaces the existing\n        `tf.distribute.experimental.ParameterServerStrategy` symbol with a new\n        class that is for parameter server training in TF2. Usage of the old\n        symbol, usually with Estimator API, should be **replaced** with\n        [`tf.compat.v1.distribute.experimental.ParameterServerStrategy`].\n    *   Added `tf.distribute.experimental.coordinator.*` namespace, including\n        the main API `ClusterCoordinator` for coordinating the training cluster,\n        the related data structure `RemoteValue` and `PerWorkerValue`.\n*   `MultiWorkerMirroredStrategy`](https://www.tensorflow.org/api_docs/python/tf/distribute/MultiWorkerMirroredStrategy)\n    is now a stable API and is no longer considered experimental. Some of the\n    major improvements involve handling peer failure and many bug fixes. Please\n    check out the detailed tutorial on\n    [Multi-worer training with Keras](https://www.tensorflow.org/tutorials/distribute/multi_worker_with_keras).\n*   Adds `tf.distribute.Strategy.gather` and\n    `tf.distribute.ReplicaContext.all_gather` APIs to support gathering dense\n    distributed values.\n*   Fixes various issues with saving a distributed model.\n\n### `tf.keras`:\n\n*   Improvements from the Functional API refactoring:\n    *   Functional model construction does not need to maintain a global\n        workspace graph, removing memory leaks especially when building many\n        models or very large models.\n    *   Functional model construction should be ~8-10% faster on average.\n    *   Functional models can now contain non-symbolic values in their call\n        inputs inside of the first positional argument.\n    *   Several classes of TF ops that were not reliably converted to Keras\n        layers during functional API construction should now work,\n        e.g.`tf.image.ssim_multiscale`\n    *   Error messages when Functional API construction goes wrong (and when ops\n        cannot be converted to Keras layers automatically) should be clearer and\n        easier to understand.\n*   `Optimizer.minimize` can now accept a loss `Tensor` and a `GradientTape` as\n    an alternative to accepting a `callable` loss.\n*   Adds `beta` hyperparameter to\n    [FTRL](https://www.tensorflow.org/api_docs/python/tf/keras/optimizers/Ftrl)\n    optimizer classes (Keras and others) to match\n    [FTRL paper](https://research.google.com/pubs/archive/41159.pdf).\n*   `Optimizer.__init__` now accepts a `gradient_aggregator` to allow for\n    customization of how gradients are aggregated across devices, as well as\n    `gradients_transformers` to allow for custom gradient transformations (such\n    as gradient clipping).\n*   Improvements to Keras preprocessing layers:\n    *   TextVectorization can now accept a vocabulary list or file as an init\n        arg.\n    *   Normalization can now accept mean and variance values as init args.\n*   In `Attention` and `AdditiveAttention` layers, the `call()` method now\n    accepts a `return_attention_scores` argument. When set to True, the layer\n    returns the attention scores as an additional output argument.\n*   Adds `tf.metrics.log_cosh` and `tf.metrics.logcosh` API entrypoints with the\n    same implementation as their `tf.losses` equivalent.\n*   For Keras model, the individual call of `Model.evaluate` uses no cached data\n    for evaluation, while `Model.fit` uses cached data when `validation_data`\n    arg is provided for better performance.\n*   Adds a `save_traces` argument to `model.save`/ `tf.keras.models.save_model`\n    which determines whether the SavedModel format stores the Keras model/layer\n    call functions. The traced functions allow Keras to revive custom models and\n    layers without the original class definition, but if this isn't required the\n    tracing can be disabled with the added option.\n*   The `tf.keras.mixed_precision` API is now non-experimental. The\n    non-experimental API differs from the experimental API in several ways.\n    *   `tf.keras.mixed_precision.Policy` no longer takes in a\n        `tf.mixed_precision. experimental.LossScale` in the constructor, and no\n        longer has a `LossScale` associated with it. Instead, `Model.compile`\n        will automatically wrap the optimizer with a `LossScaleOptimizer` using\n        dynamic loss scaling if `Policy.name` is \"mixed_float16\".\n    *   `tf.keras.mixed_precision.LossScaleOptimizer`'s constructor takes in\n        different arguments. In particular, it no longer takes in a `LossScale`,\n        and there is no longer a `LossScale` associated with the\n        `LossScaleOptimizer`. Instead, `LossScaleOptimizer` directly implements\n        fixed or dynamic loss scaling. See the documentation of\n        [`tf.keras.mixed_precision.experimental.LossScaleOptimizer`](https://www.tensorflow.org/api_docs/python/tf/keras/mixed_precision/experimental/LossScaleOptimizer?version=nightly)\n        for details on the differences between the experimental\n        `LossScaleOptimizer` and the new non-experimental `LossScaleOptimizer`.\n    *   `tf.mixed_precision.experimental.LossScale` and its subclasses are\n        deprecated, as all of its functionality now exists within\n        `tf.keras.mixed_precision.LossScaleOptimizer`\n\n### `tf.lite`:\n\n*   `TFLiteConverter`:\n    *   Support optional flags `inference_input_type` and\n        `inference_output_type` for full integer quantized models. This allows\n        users to modify the model input and output type to integer types\n        (`tf.int8`, `tf.uint8`) instead of defaulting to float type\n        (`tf.float32`).\n*   NNAPI\n    *   Adds NNAPI Delegation support for requantization use cases by converting\n        the operation into a dequantize-quantize pair.\n    *   Removes deprecated `Interpreter.setUseNNAPI(boolean)` Java API. Use\n        `Interpreter.Options.setUseNNAPI` instead.\n    *   Deprecates `Interpreter::UseNNAPI(bool)` C++ API. Use `NnApiDelegate()`\n        and related delegate configuration methods directly.\n    *   Deprecates `Interpreter::SetAllowFp16PrecisionForFp32(bool)` C++ API.\n        Prefer controlling this via delegate options, e.g.\n        `tflite::StatefulNnApiDelegate::Options::allow_fp16'\n        or`TfLiteGpuDelegateOptionsV2::is_precision_loss_allowed`.\n*   GPU\n    *   GPU acceleration now supports quantized models by default\n*   `DynamicBuffer::AddJoinedString()` will now add a separator if the first\n    string to be joined is empty.\n*   Adds support for cumulative sum (cumsum), both as builtin op and MLIR\n    conversion.\n\n### `TensorRT`\n\n*   Issues a warning when the `session_config` parameter for the TF1 converter\n    is used or the `rewrite_config_template` field in the TF2 converter\n    parameter object is used.\n\n### TPU Enhancements:\n\n*   Adds support for the `beta` parameter of the FTRL optimizer for TPU\n    embeddings. Users of other TensorFlow platforms can implement equivalent\n    behavior by adjusting the `l2` parameter.\n\n### XLA Support:\n\n*   xla.experimental.compile is deprecated, use\n    `tf.function(experimental_compile=True)` instead.\n*   Adds `tf.function.experimental_get_compiler_ir` which returns compiler IR\n    (currently 'hlo' and 'optimized_hlo') for given input for given function.\n\n### Security:\n\n*   Fixes an undefined behavior causing a segfault in `tf.raw_ops.Switch`,\n    ([CVE-2020-15190](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2020-15190))\n*   Fixes three vulnerabilities in conversion to DLPack format\n    *   [CVE-2020-15191](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2020-15191),\n    *   [CVE-2020-15192](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2020-15192),\n    *   [CVE-2020-15193](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2020-15193)\n*   Fixes two vulnerabilities in `SparseFillEmptyRowsGrad`\n    *   [CVE-2020-15194](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2020-15194),\n    *   [CVE-2020-15195](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2020-15195)\n*   Fixes several vulnerabilities in `RaggedCountSparseOutput` and\n    `SparseCountSparseOutput` operations\n    *   [CVE-2020-15196](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2020-15196),\n    *   [CVE-2020-15197](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2020-15197),\n    *   [CVE-2020-15198](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2020-15198),\n    *   [CVE-2020-15199](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2020-15199),\n    *   [CVE-2020-15200](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2020-15200),\n    *   [CVE-2020-15201](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2020-15201)\n*   Fixes an integer truncation vulnerability in code using the work sharder\n    API,\n    ([CVE-2020-15202](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2020-15202))\n*   Fixes a format string vulnerability in `tf.strings.as_string`,\n    ([CVE-2020-15203](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2020-15203))\n*   Fixes segfault raised by calling session-only ops in eager mode,\n    ([CVE-2020-15204](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2020-15204))\n*   Fixes data leak and potential ASLR violation from `tf.raw_ops.StringNGrams`,\n    ([CVE-2020-15205](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2020-15205))\n*   Fixes segfaults caused by incomplete `SavedModel` validation,\n    ([CVE-2020-15206](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2020-15206))\n*   Fixes a data corruption due to a bug in negative indexing support in TFLite,\n    ([CVE-2020-15207](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2020-15207))\n*   Fixes a data corruption due to dimension mismatch in TFLite,\n    ([CVE-2020-15208](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2020-15208))\n*   Fixes several vulnerabilities in TFLite saved model format\n    *   [CVE-2020-15209](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2020-15209),\n    *   [CVE-2020-15210](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2020-15210),\n    *   [CVE-2020-15211](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2020-15211)\n*   Fixes several vulnerabilities in TFLite implementation of segment sum\n    *   [CVE-2020-15212](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2020-15212),\n    *   [CVE-2020-15213](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2020-15213),\n    *   [CVE-2020-15214](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2020-15214)\n*   Fixes a segfault in `tf.quantization.quantize_and_dequantize`,\n    ([CVE-2020-15265](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2020-15265))\n*   Fixes an undefined behavior float cast causing a crash,\n    ([CVE-2020-15266](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2020-15266))\n*   Fixes a lack of validation in `tf.raw_ops.DataFormatVecPermute` and\n    `tf.raw_ops.DataFormatDimMap` which can cause uninitialized memory access,\n    read outside bounds of arrays, data corruption and segmentation faults\n    ([CVE-2020-26267](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2020-26267))\n*   Fixes a crash caused by writing to read only memory region\n    ([CVE-2020-26268](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2020-26268))\n*   Fixes a heap out of bounds access in filesystem globbing implementation\n    ([CVE-2020-26269](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2020-26269))\n\n### Other:\n\n*   We have replaced uses of \"whitelist\" and \"blacklist\" with \"allowlist\" and\n    \"denylist\" where possible. Please see\n    [this list](https://developers.google.com/style/word-list#blacklist) for\n    more context.\n*   Adds `tf.config.experimental.mlir_bridge_rollout` which will help us rollout\n    the new MLIR TPU bridge.\n*   Adds `tf.experimental.register_filesystem_plugin` to load modular filesystem\n    plugins from Python\n\n## Thanks to our Contributors\n\nThis release contains contributions from many people at Google as well as the\nfollowing external contributors:\n\n8bitmp3, aaa.jq, Abhineet Choudhary, Abolfazl Shahbazi, acxz, Adam Hillier,\nAdrian Garcia Badaracco, Ag Ramesh, ahmedsabie, Alan Anderson, Alexander Grund,\nAlexandre Lissy, Alexey Ivanov, Amedeo Cavallo, anencore94, Aniket Kumar Singh,\nAnthony Platanios, Ashwin Phadke, Balint Cristian, Basit Ayantunde, bbbboom, Ben\nBarsdell, Benjamin Chetioui, Benjamin Peterson, bhack, Bhanu Prakash Bandaru\nVenkata, Biagio Montaruli, Brent M. Spell, bubblebooy, bzhao, cfRod, Cheng Chen,\nCheng(Kit) Chen, Chris Tessum, Christian, chuanqiw, codeadmin_peritiae,\nCOTASPAR, CuiYifeng, danielknobe, danielyou0230, dannyfriar, daria,\nDarrenZhang01, Denisa Roberts, dependabot[bot], Deven Desai, Dmitry Volodin,\nDmitry Zakharov, drebain, Duncan Riach, Eduard Feicho, Ehsan Toosi, Elena\nZhelezina, emlaprise2358, Eugene Kuznetsov, Evaderan-Lab, Evgeniy Polyakov,\nFausto Morales, Felix Johnny, fo40225, Frederic Bastien, Fredrik Knutsson,\nfsx950223, Gaurav Singh, Gauri1 Deshpande, George Grzegorz Pawelczak, gerbauz,\nGianluca Baratti, Giorgio Arena, Gmc2, Guozhong Zhuang, Hannes Achleitner,\nHarirai, HarisWang, Harsh188, hedgehog91, Hemal Mamtora, Hideto Ueno, Hugh Ku,\nIan Beauregard, Ilya Persky, jacco, Jakub Bernek, Jan Jongboom, Javier Montalt\nTordera, Jens Elofsson, Jerry Shih, jerryyin, jgehw, Jinjing Zhou, jma, jmsmdy,\nJohan Nordstrm, John Poole, Jonah Kohn, Jonathan Dekhtiar, jpodivin, Jung Daun,\nKai Katsumata, Kaixi Hou, Kamil Rakoczy, Kaustubh Maske Patil, Kazuaki Ishizaki,\nKedar Sovani, Koan-Sin Tan, Koki Ibukuro, Krzysztof Laskowski, Kushagra Sharma,\nKushan Ahmadian, Lakshay Tokas, Leicong Li, levinxo, Lukas Geiger, Maderator,\nMahmoud Abuzaina, Mao Yunfei, Marius Brehler, markf, Martin Hwasser, Martin\nKubovk, Matt Conley, Matthias, mazharul, mdfaijul, Michael137, MichelBr,\nMikhail Startsev, Milan Straka, Ml-0, Myung-Hyun Kim, Mns Nilsson, Nathan\nLuehr, ngc92, nikochiko, Niranjan Hasabnis, nyagato_00, Oceania2018, Oleg Guba,\nOngun Kanat, OscarVanL, Patrik Laurell, Paul Tanger, Peter Sobot, Phil Pearl,\nPlusPlusUltra, Poedator, Prasad Nikam, Rahul-Kamat, Rajeshwar Reddy T,\nredwrasse, Rickard, Robert Szczepanski, Rohan Lekhwani, Sam Holt, Sami Kama,\nSamuel Holt, Sandeep Giri, sboshin, Sean Settle, settle, Sharada Shiddibhavi,\nShawn Presser, ShengYang1, Shi,Guangyong, Shuxiang Gao, Sicong Li, Sidong-Wei,\nSrihari Humbarwadi, Srinivasan Narayanamoorthy, Steenu Johnson, Steven Clarkson,\nstjohnso98, Tamas Bela Feher, Tamas Nyiri, Tarandeep Singh, Teng Lu, Thibaut\nGoetghebuer-Planchon, Tim Bradley, Tomasz Strejczek, Tongzhou Wang, Torsten\nRudolf, Trent Lo, Ty Mick, Tzu-Wei Sung, Varghese, Jojimon, Vignesh Kothapalli,\nVishakha Agrawal, Vividha, Vladimir Menshakov, Vladimir Silyaev, VoVAllen, V\nVn Ngha, wondertx, xiaohong1031, Xiaoming (Jason) Cui, Xinan Jiang, Yair\nEhrenwald, Yasir Modak, Yasuhiro Matsumoto, Yimei Sun, Yiwen Li, Yixing, Yoav\nRamon, Yong Tang, Yong Wu, yuanbopeng, Yunmo Koo, Zhangqiang, Zhou Peng,\nZhuBaohe, zilinzhu, zmx\n\n# Release 2.3.1\n\n## Bug Fixes and Other Changes\n\n*   Fixes an undefined behavior causing a segfault in `tf.raw_ops.Switch`\n    ([CVE-2020-15190](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2020-15190))\n*   Fixes three vulnerabilities in conversion to DLPack format\n    ([CVE-2020-15191](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2020-15191),\n    [CVE-2020-15192](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2020-15192),\n    [CVE-2020-15193](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2020-15193))\n*   Fixes two vulnerabilities in `SparseFillEmptyRowsGrad`\n    ([CVE-2020-15194](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2020-15194),\n    [CVE-2020-15195](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2020-15195))\n*   Fixes several vulnerabilities in `RaggedCountSparseOutput` and\n    `SparseCountSparseOutput` operations\n    ([CVE-2020-15196](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2020-15196),\n    [CVE-2020-15197](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2020-15197),\n    [CVE-2020-15198](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2020-15198),\n    [CVE-2020-15199](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2020-15199),\n    [CVE-2020-15200](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2020-15200),\n    [CVE-2020-15201](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2020-15201))\n*   Fixes an integer truncation vulnerability in code using the work sharder API\n    ([CVE-2020-15202](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2020-15202))\n*   Fixes a format string vulnerability in `tf.strings.as_string`\n    ([CVE-2020-15203](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2020-15203))\n*   Fixes segfault raised by calling session-only ops in eager mode\n    ([CVE-2020-15204](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2020-15204))\n*   Fixes data leak and potential ASLR violation from `tf.raw_ops.StringNGrams`\n    ([CVE-2020-15205](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2020-15205))\n*   Fixes segfaults caused by incomplete `SavedModel` validation\n    ([CVE-2020-15206](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2020-15206))\n*   Fixes a data corruption due to a bug in negative indexing support in TFLite\n    ([CVE-2020-15207](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2020-15207))\n*   Fixes a data corruption due to dimension mismatch in TFLite\n    ([CVE-2020-15208](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2020-15208))\n*   Fixes several vulnerabilities in TFLite saved model format\n    ([CVE-2020-15209](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2020-15209),\n    [CVE-2020-15210](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2020-15210),\n    [CVE-2020-15211](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2020-15211))\n*   Fixes several vulnerabilities in TFLite implementation of segment sum\n    ([CVE-2020-15212](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2020-15212),\n    [CVE-2020-15213](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2020-15213),\n    [CVE-2020-15214](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2020-15214))\n*   Updates `sqlite3` to `3.33.00` to handle\n    [CVE-2020-15358](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2020-15358).\n*   Fixes deprecated usage of `collections` API\n*   Removes `scipy` dependency from `setup.py` since TensorFlow does not need it\n    to install the pip package\n\n# Release 2.2.1\n\n## Bug Fixes and Other Changes\n\n*   Fixes an undefined behavior causing a segfault in `tf.raw_ops.Switch`\n    ([CVE-2020-15190](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2020-15190))\n*   Fixes three vulnerabilities in conversion to DLPack format\n    ([CVE-2020-15191](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2020-15191),\n    [CVE-2020-15192](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2020-15192),\n    [CVE-2020-15193](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2020-15193))\n*   Fixes two vulnerabilities in `SparseFillEmptyRowsGrad`\n    ([CVE-2020-15194](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2020-15194),\n    [CVE-2020-15195](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2020-15195))\n*   Fixes an integer truncation vulnerability in code using the work sharder API\n    ([CVE-2020-15202](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2020-15202))\n*   Fixes a format string vulnerability in `tf.strings.as_string`\n    ([CVE-2020-15203](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2020-15203))\n*   Fixes segfault raised by calling session-only ops in eager mode\n    ([CVE-2020-15204](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2020-15204))\n*   Fixes data leak and potential ASLR violation from `tf.raw_ops.StringNGrams`\n    ([CVE-2020-15205](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2020-15205))\n*   Fixes segfaults caused by incomplete `SavedModel` validation\n    ([CVE-2020-15206](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2020-15206))\n*   Fixes a data corruption due to a bug in negative indexing support in TFLite\n    ([CVE-2020-15207](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2020-15207))\n*   Fixes a data corruption due to dimension mismatch in TFLite\n    ([CVE-2020-15208](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2020-15208))\n*   Fixes several vulnerabilities in TFLite saved model format\n    ([CVE-2020-15209](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2020-15209),\n    [CVE-2020-15210](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2020-15210),\n    [CVE-2020-15211](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2020-15211))\n*   Fixes several vulnerabilities in TFLite implementation of segment sum\n    ([CVE-2020-15212](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2020-15212),\n    [CVE-2020-15213](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2020-15213),\n    [CVE-2020-15214](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2020-15214))\n*   Updates `sqlite3` to `3.33.00` to handle\n    [CVE-2020-9327](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2020-9327),\n    [CVE-2020-11655](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2020-11655),\n    [CVE-2020-11656](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2020-11656),\n    [CVE-2020-13434](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2020-13434),\n    [CVE-2020-13435](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2020-13435),\n    [CVE-2020-13630](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2020-13630),\n    [CVE-2020-13631](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2020-13631),\n    [CVE-2020-13871](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2020-13871),\n    and\n    [CVE-2020-15358](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2020-15358).\n*   Fixes deprecated usage of `collections` API\n*   Removes `scipy` dependency from `setup.py` since TensorFlow does not need it\n    to install the pip package\n\n# Release 2.1.2\n\n## Bug Fixes and Other Changes\n\n*   Fixes an undefined behavior causing a segfault in `tf.raw_ops.Switch`\n    ([CVE-2020-15190](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2020-15190))\n*   Fixes three vulnerabilities in conversion to DLPack format\n    ([CVE-2020-15191](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2020-15191),\n    [CVE-2020-15192](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2020-15192),\n    [CVE-2020-15193](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2020-15193))\n*   Fixes two vulnerabilities in `SparseFillEmptyRowsGrad`\n    ([CVE-2020-15194](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2020-15194),\n    [CVE-2020-15195](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2020-15195))\n*   Fixes an integer truncation vulnerability in code using the work sharder API\n    ([CVE-2020-15202](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2020-15202))\n*   Fixes a format string vulnerability in `tf.strings.as_string`\n    ([CVE-2020-15203](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2020-15203))\n*   Fixes segfault raised by calling session-only ops in eager mode\n    ([CVE-2020-15204](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2020-15204))\n*   Fixes data leak and potential ASLR violation from `tf.raw_ops.StringNGrams`\n    ([CVE-2020-15205](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2020-15205))\n*   Fixes segfaults caused by incomplete `SavedModel` validation\n    ([CVE-2020-15206](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2020-15206))\n*   Fixes a data corruption due to a bug in negative indexing support in TFLite\n    ([CVE-2020-15207](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2020-15207))\n*   Fixes a data corruption due to dimension mismatch in TFLite\n    ([CVE-2020-15208](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2020-15208))\n*   Fixes several vulnerabilities in TFLite saved model format\n    ([CVE-2020-15209](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2020-15209),\n    [CVE-2020-15210](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2020-15210),\n    [CVE-2020-15211](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2020-15211))\n*   Updates `sqlite3` to `3.33.00` to handle\n    [CVE-2020-9327](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2020-9327),\n    [CVE-2020-11655](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2020-11655),\n    [CVE-2020-11656](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2020-11656),\n    [CVE-2020-13434](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2020-13434),\n    [CVE-2020-13435](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2020-13435),\n    [CVE-2020-13630](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2020-13630),\n    [CVE-2020-13631](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2020-13631),\n    [CVE-2020-13871](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2020-13871),\n    and\n    [CVE-2020-15358](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2020-15358).\n*   Removes `scipy` dependency from `setup.py` since TensorFlow does not need it\n    to install the pip package\n*   Switches ROCM builds to use ROCM 3.7\n\n# Release 2.0.3\n\n## Bug Fixes and Other Changes\n\n*   Fixes an undefined behavior causing a segfault in `tf.raw_ops.Switch`\n    ([CVE-2020-15190](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2020-15190))\n*   Fixes three vulnerabilities in conversion to DLPack format\n    ([CVE-2020-15191](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2020-15191),\n    [CVE-2020-15192](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2020-15192),\n    [CVE-2020-15193](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2020-15193))\n*   Fixes two vulnerabilities in `SparseFillEmptyRowsGrad`\n    ([CVE-2020-15194](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2020-15194),\n    [CVE-2020-15195](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2020-15195))\n*   Fixes an integer truncation vulnerability in code using the work sharder API\n    ([CVE-2020-15202](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2020-15202))\n*   Fixes a format string vulnerability in `tf.strings.as_string`\n    ([CVE-2020-15203](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2020-15203))\n*   Fixes segfault raised by calling session-only ops in eager mode\n    ([CVE-2020-15204](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2020-15204))\n*   Fixes data leak and potential ASLR violation from `tf.raw_ops.StringNGrams`\n    ([CVE-2020-15205](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2020-15205))\n*   Fixes segfaults caused by incomplete `SavedModel` validation\n    ([CVE-2020-15206](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2020-15206))\n*   Fixes a data corruption due to a bug in negative indexing support in TFLite\n    ([CVE-2020-15207](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2020-15207))\n*   Fixes a data corruption due to dimension mismatch in TFLite\n    ([CVE-2020-15208](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2020-15208))\n*   Fixes several vulnerabilities in TFLite saved model format\n    ([CVE-2020-15209](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2020-15209),\n    [CVE-2020-15210](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2020-15210),\n    [CVE-2020-15211](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2020-15211))\n*   Updates `sqlite3` to `3.33.00` to handle\n    [CVE-2020-9327](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2020-9327),\n    [CVE-2020-11655](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2020-11655),\n    [CVE-2020-11656](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2020-11656),\n    [CVE-2020-13434](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2020-13434),\n    [CVE-2020-13435](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2020-13435),\n    [CVE-2020-13630](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2020-13630),\n    [CVE-2020-13631](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2020-13631),\n    [CVE-2020-13871](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2020-13871),\n    and\n    [CVE-2020-15358](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2020-15358).\n*   Pins `numpy` to 1.18.5 to prevent ABI breakage when compiling code that uses\n    both NumPy and TensorFlow headers.\n\n# Release 1.15.4\n\n## Bug Fixes and Other Changes\n\n*   Fixes an undefined behavior causing a segfault in `tf.raw_ops.Switch`\n    ([CVE-2020-15190](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2020-15190))\n*   Fixes three vulnerabilities in conversion to DLPack format\n    ([CVE-2020-15191](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2020-15191),\n    [CVE-2020-15192](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2020-15192),\n    [CVE-2020-15193](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2020-15193))\n*   Fixes two vulnerabilities in `SparseFillEmptyRowsGrad`\n    ([CVE-2020-15194](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2020-15194),\n    [CVE-2020-15195](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2020-15195))\n*   Fixes an integer truncation vulnerability in code using the work sharder API\n    ([CVE-2020-15202](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2020-15202))\n*   Fixes a format string vulnerability in `tf.strings.as_string`\n    ([CVE-2020-15203](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2020-15203))\n*   Fixes segfault raised by calling session-only ops in eager mode\n    ([CVE-2020-15204](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2020-15204))\n*   Fixes data leak and potential ASLR violation from `tf.raw_ops.StringNGrams`\n    ([CVE-2020-15205](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2020-15205))\n*   Fixes segfaults caused by incomplete `SavedModel` validation\n    ([CVE-2020-15206](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2020-15206))\n*   Fixes a data corruption due to a bug in negative indexing support in TFLite\n    ([CVE-2020-15207](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2020-15207))\n*   Fixes a data corruption due to dimension mismatch in TFLite\n    ([CVE-2020-15208](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2020-15208))\n*   Fixes several vulnerabilities in TFLite saved model format\n    ([CVE-2020-15209](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2020-15209),\n    [CVE-2020-15210](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2020-15210),\n    [CVE-2020-15211](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2020-15211))\n*   Updates `sqlite3` to `3.33.00` to handle\n    [CVE-2020-9327](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2020-9327),\n    [CVE-2020-11655](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2020-11655),\n    [CVE-2020-11656](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2020-11656),\n    [CVE-2020-13434](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2020-13434),\n    [CVE-2020-13435](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2020-13435),\n    [CVE-2020-13630](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2020-13630),\n    [CVE-2020-13631](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2020-13631),\n    [CVE-2020-13871](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2020-13871),\n    and\n    [CVE-2020-15358](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2020-15358).\n*   Fixes #41630 by including `max_seq_length` in CuDNN descriptor cache key\n*   Pins `numpy` to 1.18.5 to prevent ABI breakage when compiling code that uses\n    both NumPy and TensorFlow headers.\n\n# Release 2.3.0\n\n## Major Features and Improvements\n\n*   `tf.data` adds two new mechanisms to solve input pipeline bottlenecks and\n    save resources:\n\n    *   [snapshot](https://www.tensorflow.org/api_docs/python/tf/data/experimental/snapshot)\n    *   [tf.data service](https://www.tensorflow.org/api_docs/python/tf/data/experimental/service).\n\n    In addition checkout the detailed\n    [guide](https://www.tensorflow.org/guide/data_performance_analysis) for\n    analyzing input pipeline performance with TF Profiler.\n\n*   [`tf.distribute.TPUStrategy`](https://www.tensorflow.org/api_docs/python/tf/distribute/TPUStrategy)\n    is now a stable API and no longer considered experimental for TensorFlow.\n    (earlier `tf.distribute.experimental.TPUStrategy`).\n\n*   [TF Profiler](https://www.tensorflow.org/guide/profiler) introduces two new\n    tools: a memory profiler to visualize your models memory usage over time\n    and a [python tracer](https://www.tensorflow.org/guide/profiler#events)\n    which allows you to trace python function calls in your model. Usability\n    improvements include better diagnostic messages and\n    [profile options](https://tensorflow.org/guide/profiler#collect_performance_data)\n    to customize the host and device trace verbosity level.\n\n*   Introduces experimental support for Keras Preprocessing Layers API\n    ([`tf.keras.layers.experimental.preprocessing.*`](https://www.tensorflow.org/api_docs/python/tf/keras/layers/experimental/preprocessing?version=nightly))\n    to handle data preprocessing operations, with support for composite tensor\n    inputs. Please see below for additional details on these layers.\n\n*   TFLite now properly supports dynamic shapes during conversion and inference.\n    Weve also added opt-in support on Android and iOS for\n    [XNNPACK](https://github.com/tensorflow/tensorflow/tree/master/tensorflow/lite/delegates/xnnpack),\n    a highly optimized set of CPU kernels, as well as opt-in support for\n    [executing quantized models on the GPU](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/lite/g3doc/performance/gpu_advanced.md#running-quantized-models-experimental).\n\n*   Libtensorflow packages are available in GCS starting this release. We have\n    also started to\n    [release a nightly version of these packages](https://github.com/tensorflow/tensorflow#official-builds).\n\n*   The experimental Python API\n    [`tf.debugging.experimental.enable_dump_debug_info()`](https://www.tensorflow.org/api_docs/python/tf/debugging/experimental/enable_dump_debug_info)\n    now allows you to instrument a TensorFlow program and dump debugging\n    information to a directory on the file system. The directory can be read and\n    visualized by a new interactive dashboard in TensorBoard 2.3 called\n    [Debugger V2](https://www.tensorflow.org/tensorboard/debugger_v2), which\n    reveals the details of the TensorFlow program including graph structures,\n    history of op executions at the Python (eager) and intra-graph levels, the\n    runtime dtype, shape, and numerical composition of tensors, as well as their\n    code locations.\n\n## Breaking Changes\n\n*   Increases the **minimum bazel version** required to build TF to **3.1.0**.\n*   `tf.data`\n    *   Makes the following (breaking) changes to the `tf.data`.\n    *   C++ API: - `IteratorBase::RestoreInternal`,\n        `IteratorBase::SaveInternal`, and `DatasetBase::CheckExternalState`\n        become pure-virtual and subclasses are now expected to provide an\n        implementation.\n    *   The deprecated `DatasetBase::IsStateful` method is removed in favor of\n        `DatasetBase::CheckExternalState`.\n    *   Deprecated overrides of `DatasetBase::MakeIterator` and\n        `MakeIteratorFromInputElement` are removed.\n    *   The signature of `tensorflow::data::IteratorBase::SaveInternal` and\n        `tensorflow::data::IteratorBase::SaveInput` has been extended with\n        `SerializationContext` argument to enable overriding the default policy\n        for the handling external state during iterator checkpointing. This is\n        not a backwards compatible change and all subclasses of `IteratorBase`\n        *need to be updated* accordingly.\n*   `tf.keras`\n    *   Add a new `BackupAndRestore` callback for handling distributed training\n        failures & restarts. Please take a look at this\n        [tutorial](https://www.tensorflow.org/tutorials/distribute/multi_worker_with_keras)\n        for details on how to use the callback.\n*   `tf.image.extract_glimpse` has been updated to correctly process the case\n    where `centered=False` and `normalized=False`. This is a breaking change as\n    the output is different from (incorrect) previous versions. Note this\n    breaking change only impacts `tf.image.extract_glimpse` and\n    `tf.compat.v2.image.extract_glimpse` API endpoints. The behavior of\n    `tf.compat.v1.image.extract_glimpse` does not change. The behavior of\n    existing C++ kernel `ExtractGlimpse` does not change either, so saved models\n    using `tf.raw_ops.ExtractGlimpse` will not be impacted.\n\n## Known Caveats\n\n*   `tf.lite`\n    *   Keras-based LSTM models must be converted with an explicit batch size in\n        the input layer.\n\n## Bug Fixes and Other Changes\n\n### TF Core:\n\n*   Set `tf2_behavior` to 1 to enable V2 for early loading cases.\n*   Add `execute_fn_for_device function` to dynamically choose the\n    implementation based on underlying device placement.\n*   Eager:\n    *   Add `reduce_logsumexp` benchmark with experiment compile.\n    *   Give `EagerTensor`s a meaningful `__array__` implementation.\n    *   Add another version of defun matmul for performance analysis.\n*   `tf.function`/AutoGraph:\n    *   `AutoGraph` now includes into TensorFlow loops any variables that are\n        closed over by local functions. Previously, such variables were\n        sometimes incorrectly ignored.\n    *   functions returned by the `get_concrete_function` method of\n        `tf.function` objects can now be called with arguments consistent with\n        the original arguments or type specs passed to `get_concrete_function`.\n        This calling convention is now the preferred way to use concrete\n        functions with nested values and composite tensors. Please check the\n        [guide](https://www.tensorflow.org/guide/concrete_function) for more\n        details on `concrete_ function`.\n    *   Update `tf.function`'s `experimental_relax_shapes` to handle composite\n        tensors appropriately.\n    *   Optimize `tf.function` invocation, by removing redundant list converter.\n    *   `tf.function` will retrace when called with a different variable instead\n        of simply using the `dtype` & `shape`.\n    *   [Improve support](https://github.com/tensorflow/tensorflow/issues/33862)\n        for dynamically-sized TensorArray inside `tf.function`.\n*   `tf.math`:\n    *   Narrow down `argmin`/`argmax` contract to always return the smallest\n        index for ties.\n    *   `tf.math.reduce_variance` and `tf.math.reduce_std` return correct\n        computation for complex types and no longer support integer types.\n    *   Add Bessel functions of order 0,1 to `tf.math.special`.\n    *   `tf.divide` now always returns a tensor to be consistent with\n        documentation and other APIs.\n*   `tf.image`:\n    *   Replaced\n        [`tf.image.non_max_suppression_padded`](https://www.tensorflow.org/versions/r2.3/api_docs/python/tf/image/non_max_suppression_padded?hl=en)\n        with a new implementation that supports batched inputs, which is\n        considerably faster on TPUs and GPUs. Boxes with area=0 will be ignored.\n        Existing usage with single inputs should still work as before.\n*   `tf.linalg`\n    *   Add `tf.linalg.banded_triangular_solve`.\n*   `tf.random`:\n    *   Add `tf.random.stateless_parameterized_truncated_normal`.\n*   `tf.ragged`:\n    *   Add `tf.ragged.cross` and `tf.ragged.cross_hashed` operations.\n*   `tf.RaggedTensor`:\n    *   `RaggedTensor.to_tensor()` now preserves static shape.\n    *   Add `tf.strings.format()` and `tf.print()` to support RaggedTensors.\n*   `tf.saved_model`:\n    *   `@tf.function` from SavedModel no longer ignores args after a\n        `RaggedTensor` when selecting the concrete function to run.\n    *   Fix save model issue for ops with a list of functions.\n    *   Add `tf.saved_model.LoadOptions` with\n        [`experimental_io_device`](https://www.tensorflow.org/versions/r2.3/api_docs/python/tf/saved_model/LoadOptions?hl=en)\n        as arg with default value `None` to choose the I/O device for loading\n        models and weights.\n    *   Update `tf.saved_model.SaveOptions` with\n        [`experimental_io_device`](https://www.tensorflow.org/versions/r2.3/api_docs/python/tf/saved_model/SaveOptions?hl=en)\n        as arg with default value `None` to choose the I/O device for saving\n        models and weights.\n    *   Mutable tables now restore checkpointed values when loaded from\n        SavedModel.\n    *   The user object metadata field in the SavedModel proto has been\n        deprecated as part of the updates to Keras SavedModel. Keras was the\n        only consumer of this field prior to the update.\n*   GPU\n    *   TF 2.3 includes PTX kernels only for\n        [compute capability](https://developer.nvidia.com/cuda-gpus) 7.0 to\n        reduce the TF pip binary size. Earlier releases included PTX for a\n        variety of older compute capabilities.\n    *   Remove environmental variable `TF_USE_CUDNN`.\n*   Others\n    *   Retain parent namescope for ops added inside\n        `tf.while_loop`/`tf.cond`/`tf.switch_case`.\n    *   Update `tf.vectorized_map` to support vectorizing `tf.while_loop` and\n        TensorList operations.\n    *   `tf.custom_gradient` can now be applied to functions that accept nested\n        structures of `tensors` as inputs (instead of just a list of tensors).\n        Note that Python structures such as tuples and lists now won't be\n        treated as tensors, so if you still want them to be treated that way,\n        you need to wrap them with `tf.convert_to_tensor`.\n    *   No lowering on gradient case op when input is `DeviceIndex` op.\n    *   Extend the ragged version of `tf.gather` to support `batch_dims` and\n        `axis` args.\n    *   Update `tf.map_fn` to support RaggedTensors and SparseTensors.\n    *   Deprecate `tf.group`. It is not useful in eager mode.\n    *   Add CPU and GPU implementation of modified variation of\n        [`FTRL`](https://www.tensorflow.org/versions/r2.3/api_docs/python/tf/raw_ops/ApplyFtrl)/[`FTRLV2`](https://www.tensorflow.org/versions/r2.3/api_docs/python/tf/raw_ops/ApplyFtrlV2)\n        that can triggerred by `multiply_linear_by_lr` allowing a learning rate\n        of zero.\n\n### `tf.data`:\n\n*   `tf.data.experimental.dense_to_ragged_batch` works correctly with tuples.\n*   `tf.data.experimental.dense_to_ragged_batch` to output variable ragged rank.\n*   `tf.data.experimental.cardinality` is now a method on `tf.data.Dataset`.\n*   `tf.data.Dataset` now supports `len(Dataset)` when the cardinality is\n    finite.\n\n### `tf.distribute`:\n\n*   Expose experimental\n    [`tf.distribute.DistributedDataset`](https://www.tensorflow.org/versions/r2.3/api_docs/python/tf/distribute/DistributedDataset?hl=en)\n    and\n    [`tf.distribute.DistributedIterator`](https://www.tensorflow.org/versions/r2.3/api_docs/python/tf/distribute/DistributedIterator)\n    to distribute input data when using `tf.distribute` to scale training on\n    multiple devices.\n    *   Added a\n        [`get_next_as_optional`](https://www.tensorflow.org/versions/r2.3/api_docs/python/tf/distribute/DistributedIterator?hl=en#get_next_as_optional)\n        method for\n        [`tf.distribute.DistributedIterator`](https://www.tensorflow.org/versions/r2.3/api_docs/python/tf/distribute/DistributedIterator?hl=en)\n        class to return a `tf.experimental.Optional` instance that contains the\n        next value for all replicas or none instead of raising an out of range\n        error. Also see *new*\n        [guide on input distribution](https://www.tensorflow.org/tutorials/distribute/input).\n*   Allow var.assign on MirroredVariables with aggregation=NONE in replica\n    context. Previously this would raise an error. We now allow this because\n    many users and library writers find using `.assign` in replica context to be\n    more convenient, instead of having to use `Strategy.extended.update` which\n    was the previous way of updating variables in this situation.\n*   `tf.distribute.experimental.MultiWorkerMirroredStrategy` adds support for\n    partial batches. Workers running out of data now continue to participate in\n    the training with empty inputs, instead of raising an error. Learn more\n    about\n    [partial batches here](https://www.tensorflow.org/tutorials/distribute/input#partial_batches).\n*   Improve the performance of reading metrics eagerly under\n    `tf.distribute.experimental.MultiWorkerMirroredStrategy`.\n*   Fix the issue that `strategy.reduce()` inside `tf.function` may raise\n    exceptions when the values to reduce are from loops or if-clauses.\n*   Fix the issue that `tf.distribute.MirroredStrategy` cannot be used together\n    with `tf.distribute.experimental.MultiWorkerMirroredStrategy`.\n*   Add a `tf.distribute.cluster_resolver.TPUClusterResolver.connect` API to\n    simplify TPU initialization.\n*   Add `tf.distribute.Strategy.gather` and\n    `tf.distribute.ReplicaContext.all_gather` methods to gather and concatenate\n    `tf.distribute.DistributedValues` across workers and devices.\n\n### `tf.keras`:\n\n*   Introduces experimental preprocessing layers API\n    (`tf.keras.layers.experimental.preprocessing`) to handle data preprocessing\n    operations such as categorical feature encoding, text vectorization, data\n    normalization, and data discretization (binning). The newly added layers\n    provide a replacement for the legacy feature column API, and support\n    composite tensor inputs.\n*   Added **categorical data** processing layers:\n    *   `IntegerLookup` & `StringLookup`: build an index of categorical feature\n        values\n    *   `CategoryEncoding`: turn integer-encoded categories into one-hot,\n        multi-hot, or tf-idf encoded representations\n    *   `CategoryCrossing`: create new categorical features representing\n        co-occurrences of previous categorical feature values\n    *   `Hashing`: the hashing trick, for large-vocabulary categorical features\n    *   `Discretization`: turn continuous numerical features into categorical\n        features by binning their values\n*   Improved **image preprocessing** layers: `CenterCrop`, `Rescaling`\n*   Improved **image augmentation** layers: `RandomCrop`, `RandomFlip`,\n    `RandomTranslation`, `RandomRotation`, `RandomHeight`, `RandomWidth`,\n    `RandomZoom`, `RandomContrast`\n*   Improved **`TextVectorization`** layer, which handles string tokenization,\n    n-gram generation, and token encoding\n    *   The `TextVectorization` layer now accounts for the mask_token as part of\n        the vocabulary size when output_mode='int'. This means that, if you have\n        a max_tokens value of 5000, your output will have 5000 unique values\n        (not 5001 as before).\n    *   Change the return value of `TextVectorization.get_vocabulary()` from\n        `byte` to `string`. Users who previously were calling 'decode' on the\n        output of this method should no longer need to do so.\n*   Introduce new Keras dataset generation utilities :\n    *   **[`image_dataset_from_directory`](https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/image_dataset_from_directory)**\n        is a utility based on `tf.data.Dataset`, meant to replace the legacy\n        `ImageDataGenerator`. It takes you from a structured directory of images\n        to a labeled dataset, in one function call. Note that it doesn't perform\n        image data augmentation (which is meant to be done using preprocessing\n        layers).\n    *   **[`text_dataset_from_directory`](https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/text_dataset_from_directory)**\n        takes you from a structured directory of text files to a labeled\n        dataset, in one function call.\n    *   **[`timeseries_dataset_from_array`](https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/timeseries_dataset_from_array)**\n        is a `tf.data.Dataset`-based replacement of the legacy\n        `TimeseriesGenerator`. It takes you from an array of timeseries data to\n        a dataset of shifting windows with their targets.\n*   Added\n    [`experimental_steps_per_execution`](https://www.tensorflow.org/versions/r2.3/api_docs/python/tf/keras/Model?hl=en#compile)\n    arg to `model.compile` to indicate the number of batches to run per\n    `tf.function` call. This can speed up Keras Models on TPUs up to 3x.\n*   Extends `tf.keras.layers.Lambda` layers to support multi-argument lambdas,\n    and keyword arguments when calling the layer.\n*   Functional models now get constructed if *any* tensor in a layer call's\n    arguments/keyword arguments comes from a keras input. Previously the\n    functional api would only work if all of the elements in the first argument\n    to the layer came from a keras input.\n*   Clean up `BatchNormalization` layer's `trainable` property to act like\n    standard python state when it's used inside `tf.functions` (frozen at\n    tracing time), instead of acting like a pseudo-variable whose updates *kind\n    of sometimes* get reflected in already-traced `tf.function` traces.\n*   Add the `Conv1DTranspose` layer.\n*   Refine the semantics of `SensitivitySpecificityBase` derived metrics. See\n    the updated API docstrings for\n    [`tf.keras.metrics.SensitivityAtSpecificity`](https://www.tensorflow.org/versions/r2.3/api_docs/python/tf/keras/metrics/SensitivityAtSpecificity)\n    and\n    [`tf.keras.metrics.SpecificityAtSensitivty`](https://www.tensorflow.org/versions/r2.3/api_docs/python/tf/keras/metrics/SpecificityAtSensitivity).\n\n### `tf.lite`:\n\n*   Converter\n    *   Restored `inference_input_type` and `inference_output_type` flags in TF\n        2.x TFLiteConverter (backward compatible with TF 1.x) to support integer\n        (tf.int8, tf.uint8) input and output types in post training full integer\n        quantized models.\n    *   Added support for converting and resizing models with dynamic\n        (placeholder) dimensions. Previously, there was only limited support for\n        dynamic batch size, and even that did not guarantee that the model could\n        be properly resized at runtime.\n        *   Enabled experimental support for a new quantization mode with 16-bit\n            activations and 8-bit weights. See\n            `lite.OpsSet.EXPERIMENTAL_TFLITE_BUILTINS_ACTIVATIONS_INT16_WEIGHTS_INT8`.\n*   CPU\n    *   Fix an issue w/ dynamic weights and `Conv2D` on x86.\n    *   Add a runtime Android flag for enabling `XNNPACK` for optimized CPU\n        performance.\n    *   Add a runtime iOS flag for enabling `XNNPACK` for optimized CPU\n        performance.\n    *   Add a compiler flag to enable building a TFLite library that applies\n        `XNNPACK` delegate automatically when the model has a `fp32` operation.\n*   GPU\n    *   Allow GPU acceleration starting with internal graph nodes\n    *   Experimental support for quantized models with the Android GPU delegate\n    *   Add GPU delegate whitelist.\n    *   Rename GPU whitelist -> compatibility (list).\n    *   Improve GPU compatibility list entries from crash reports.\n*   NNAPI\n    *   Set default value for\n        `StatefulNnApiDelegate::Options::max_number_delegated_partitions` to 3.\n    *   Add capability to disable `NNAPI` CPU and check `NNAPI` Errno.\n    *   Fix crashes when using `NNAPI` with target accelerator specified with\n        model containing Conv2d or FullyConnected or LSTM nodes with quantized\n        weights.\n    *   Fix `ANEURALNETWORKS_BAD_DATA` execution failures with\n        `sum`/`max`/`min`/`reduce` operations with `scalar` inputs.\n*   Hexagon\n    *   TFLite Hexagon Delegate out of experimental.\n    *   Experimental `int8` support for most hexagon ops.\n    *   Experimental per-channel quant support for `conv` in Hexagon delegate.\n    *   Support dynamic batch size in C++ API.\n*   CoreML\n    *   Opensource CoreML delegate\n*   Misc\n    *   Enable building Android TFLite targets on Windows\n    *   Add support for `BatchMatMul`.\n    *   Add support for `half_pixel_centers` with `ResizeNearestNeighbor`.\n    *   Add 3D support for `BatchToSpaceND`.\n    *   Add 5D support for `BroadcastSub`, `Maximum`, `Minimum`, `Transpose` and\n        `BroadcastDiv`.\n    *   Rename `kTfLiteActRelu1` to `kTfLiteActReluN1To1`.\n    *   Enable flex delegate on tensorflow.lite.Interpreter Python package.\n    *   Add `Buckettize`, `SparseCross` and `BoostedTreesBucketize` to the flex\n        whitelist.\n    *   Add support for selective registration of flex ops.\n    *   Add missing kernels for flex delegate whitelisted ops.\n    *   Fix issue when using direct `ByteBuffer` inputs with graphs that have\n        dynamic shapes.\n    *   Fix error checking supported operations in a model containing\n        `HardSwish`.\n\n### Packaging Support\n\n*   Added `tf.sysconfig.get_build_info()`. Returns a dict that describes the\n    build environment of the currently installed TensorFlow package, e.g. the\n    NVIDIA CUDA and NVIDIA CuDNN versions used when TensorFlow was built.\n\n### Profiler\n\n*   Fix a subtle use-after-free issue in `XStatVisitor::RefValue()`.\n\n### TPU Enhancements\n\n*   Adds 3D mesh support in TPU configurations ops.\n*   Added TPU code for `FTRL` with `multiply_linear_by_lr`.\n*   Silently adds a new file system registry at `gstpu`.\n*   Support `restartType` in cloud tpu client.\n*   Depend on a specific version of google-api-python-client.\n*   Fixes apiclient import.\n\n### Tracing and Debugging\n\n*   Add a `TFE_Py_Execute` traceme.\n\n### XLA Support\n\n*   Implement stable `argmin` and `argmax`\n\n## Thanks to our Contributors\n\nThis release contains contributions from many people at Google, as well as:\n\n902449@58880@bigcat_chen@ASIC, Abdul Baseer Khan, Abhineet Choudhary, Abolfazl\nShahbazi, Adam Hillier, ag.ramesh, Agoniii, Ajay P, Alex Hoffman, Alexander\nBayandin, Alexander Grund, Alexandre Abadie, Alexey Rogachevskiy, amoitra,\nAndrew Stevens, Angus-Luo, Anshuman Tripathy, Anush Elangovan, Artem Mavrin,\nAshutosh Hathidara, autoih, Ayushman Kumar, ayushmankumar7, Bairen Yi, Bas\nAarts, Bastian Eichenberger, Ben Barsdell, bhack, Bharat Raghunathan, Biagio\nMontaruli, Bigcat-Himax, blueyi, Bryan Cutler, Byambaa, Carlos\nHernandez-Vaquero, Chen Lei, Chris Knorowski, Christian Clauss, chuanqiw,\nCuiYifeng, Daniel Situnayake, Daria Zhuravleva, Dayananda-V, Deven Desai, Devi\nSandeep Endluri, Dmitry Zakharov, Dominic Jack, Duncan Riach, Edgar Liberis,\nEhsan Toosi, ekuznetsov139, Elena Zhelezina, Eugene Kuznetsov, Eugene\nMikhantiev, Evgenii Zheltonozhskii, Fabio Di Domenico, Fausto Morales, Fei Sun,\nfeihugis, Felix E. Klee, flyingcat, Frederic Bastien, Fredrik Knutsson, frreiss,\nfsx950223, ganler, Gaurav Singh, Georgios Pinitas, Gian Marco Iodice, Giorgio\nArena, Giuseppe Rossini, Gregory Keith, Guozhong Zhuang, gurushantj, Hahn\nAnselm, Harald Husum, Harjyot Bagga, Hristo Vrigazov, Ilya Persky, Ir1d, Itamar\nTurner-Trauring, jacco, Jake Tae, Janosh Riebesell, Jason Zaman, jayanth, Jeff\nDaily, Jens Elofsson, Jinzhe Zeng, JLZ, Jonas Skog, Jonathan Dekhtiar, Josh\nMeyer, Joshua Chia, Judd, justkw, Kaixi Hou, Kam D Kasravi, Kamil Rakoczy, Karol\nGugala, Kayou, Kazuaki Ishizaki, Keith Smiley, Khaled Besrour, Kilaru Yasaswi\nSri Chandra Gandhi, Kim, Young Soo, Kristian Hartikainen, Kwabena W. Agyeman,\nLeslie-Fang, Leslie-Fang-Intel, Li, Guizi, Lukas Geiger, Lutz Roeder, M\\U00E5Ns\nNilsson, Mahmoud Abuzaina, Manish, Marcel Koester, Marcin Sielski, marload,\nMartin Jul, Matt Conley, mdfaijul, Meng, Peng, Meteorix, Michael Kufl,\nMichael137, Milan Straka, Mitchell Vitez, Ml-0, Mokke Meguru, Mshr-H, nammbash,\nNathan Luehr, naumkin, Neeraj Bhadani, ngc92, Nick Morgan, nihui, Niranjan\nHasabnis, Niranjan Yadla, Nishidha Panpaliya, Oceania2018, oclyke, Ouyang Jin,\nOverLordGoldDragon, Owen Lyke, Patrick Hemmer, Paul Andrey, Peng Sun,\nperiannath, Phil Pearl, Prashant Dandriyal, Prashant Kumar, Rahul Huilgol, Rajan\nSingh, Rajeshwar Reddy T, rangjiaheng, Rishit Dagli, Rohan Reddy, rpalakkal,\nrposts, Ruan Kunliang, Rushabh Vasani, Ryohei Ikegami, Semun Lee, Seo-Inyoung,\nSergey Mironov, Sharada Shiddibhavi, ShengYang1, Shraiysh Vaishay, Shunya Ueta,\nshwetaoj, Siyavash Najafzade, Srinivasan Narayanamoorthy, Stephan Uphoff,\nstorypku, sunchenggen, sunway513, Sven-Hendrik Haase, Swapnil Parekh, Tamas Bela\nFeher, Teng Lu, tigertang, tomas, Tomohiro Ubukata, tongxuan.ltx, Tony Tonev,\nTzu-Wei Huang, To Bouvard, Uday Bondhugula, Vaibhav Jade, Vijay Tadikamalla,\nVikram Dattu, Vincent Abriou, Vishnuvardhan Janapati, Vo Van Nghia, VoVAllen,\nWill Battel, William D. Irons, wyzhao, Xiaoming (Jason) Cui, Xiaoquan Kong,\nXinan Jiang, xutianming, Yair Ehrenwald, Yasir Modak, Yasuhiro Matsumoto, Yixing\nFu, Yong Tang, Yuan Tang, zhaozheng09, Zilin Zhu, zilinzhu, \n\n# Release 2.1.1\n\n## Bug Fixes and Other Changes\n\n*   Updates `sqlite3` to `3.31.01` to handle\n    [CVE-2019-19880](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2019-19880),\n    [CVE-2019-19244](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2019-19244)\n    and\n    [CVE-2019-19645](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2019-19645)\n*   Updates `curl` to `7.69.1` to handle\n    [CVE-2019-15601](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2019-15601)\n*   Updates `libjpeg-turbo` to `2.0.4` to handle\n    [CVE-2018-19664](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2018-19664),\n    [CVE-2018-20330](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2018-20330)\n    and\n    [CVE-2019-13960](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2019-13960)\n*   Updates Apache Spark to `2.4.5` to handle\n    [CVE-2019-10099](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2019-10099),\n    [CVE-2018-17190](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2018-17190)\n    and\n    [CVE-2018-11770](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2018-11770)\n*   Fixes a versioning bug which causes Keras layers from TF 1.x to be used\n    instead of those from TF 2.x\n\n# Release 2.0.2\n\n## Bug Fixes and Other Changes\n\n*   Updates `sqlite3` to `3.31.01` to handle\n    [CVE-2019-19880](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2019-19880),\n    [CVE-2019-19244](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2019-19244)\n    and\n    [CVE-2019-19645](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2019-19645)\n*   Updates `curl` to `7.69.1` to handle\n    [CVE-2019-15601](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2019-15601)\n*   Updates `libjpeg-turbo` to `2.0.4` to handle\n    [CVE-2018-19664](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2018-19664),\n    [CVE-2018-20330](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2018-20330)\n    and\n    [CVE-2019-13960](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2019-13960)\n*   Updates Apache Spark to `2.4.5` to handle\n    [CVE-2019-10099](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2019-10099),\n    [CVE-2018-17190](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2018-17190)\n    and\n    [CVE-2018-11770](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2018-11770)\n\n# Release 1.15.3\n\n## Bug Fixes and Other Changes\n\n*   Updates `sqlite3` to `3.31.01` to handle\n    [CVE-2019-19880](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2019-19880),\n    [CVE-2019-19244](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2019-19244)\n    and\n    [CVE-2019-19645](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2019-19645)\n*   Updates `curl` to `7.69.1` to handle\n    [CVE-2019-15601](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2019-15601)\n*   Updates `libjpeg-turbo` to `2.0.4` to handle\n    [CVE-2018-19664](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2018-19664),\n    [CVE-2018-20330](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2018-20330)\n    and\n    [CVE-2019-13960](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2019-13960)\n*   Updates Apache Spark to `2.4.5` to handle\n    [CVE-2019-10099](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2019-10099),\n    [CVE-2018-17190](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2018-17190)\n    and\n    [CVE-2018-11770](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2018-11770)\n\n# Release 2.2.0\n\nTensorFlow 2.2 discontinues support for Python 2,\n[previously announced](https://groups.google.com/a/tensorflow.org/d/msg/announce/gVwS5RC8mds/dCt1ka2XAAAJ)\nas following\n[Python 2's EOL on January 1, 2020](https://www.python.org/dev/peps/pep-0373/#update).\n\nCoinciding with this change, new releases of\n[TensorFlow's Docker images](https://hub.docker.com/r/tensorflow/tensorflow/)\nprovide Python 3 exclusively. Because all images now use Python 3, Docker tags\ncontaining `-py3` will no longer be provided and existing `-py3` tags like\n`latest-py3` will not be updated.\n\n## Major Features and Improvements\n\n*   Replaced the scalar type for string tensors from `std::string` to\n    `tensorflow::tstring` which is now ABI stable.\n*   A new Profiler for TF 2 for CPU/GPU/TPU. It offers both device and host\n    performance analysis, including input pipeline and TF Ops. Optimization\n    advisory is provided whenever possible. Please see\n    [this tutorial](https://www.tensorflow.org/tensorboard/tensorboard_profiling_keras)\n    and [guide](https://www.tensorflow.org/guide/profiler) for usage guidelines.\n*   Export C++ functions to Python using `pybind11` as opposed to `SWIG` as a\n    part of our\n    [deprecation of swig efforts](https://github.com/tensorflow/community/blob/master/rfcs/20190208-pybind11.md).\n*   `tf.distribute`:\n    *   Support added for global sync `BatchNormalization` by using the newly\n        added `tf.keras.layers.experimental.SyncBatchNormalization` layer. This\n        layer will sync `BatchNormalization` statistics every step across all\n        replicas taking part in sync training.\n    *   Performance improvements for GPU multi-worker distributed training using\n        `tf.distribute.experimental.MultiWorkerMirroredStrategy`\n    *   Update NVIDIA `NCCL` to `2.5.7-1` for better performance and performance\n        tuning. Please see\n        [nccl developer guide](https://docs.nvidia.com/deeplearning/sdk/nccl-developer-guide/docs/env.html)\n        for more information on this.\n    *   Support gradient `allreduce` in `float16`. See this\n        [example](https://github.com/tensorflow/models/blob/master/official/modeling/grad_utils.py)\n        usage.\n    *   Experimental support of\n        [all reduce gradient packing](https://www.tensorflow.org/api_docs/python/tf/distribute/experimental/CollectiveHints)\n        to allow overlapping gradient aggregation with backward path\n        computation.\n    *   Deprecated `experimental_run_v2` method for distribution strategies and\n        renamed the method `run` as it is no longer experimental.\n    *   Add CompositeTensor support for DistributedIterators. This should help\n        prevent unnecessary function retracing and memory leaks.\n*   `tf.keras`:\n\n    *   `Model.fit` major improvements:\n        *   You can now use custom training logic with `Model.fit` by overriding\n            `Model.train_step`.\n        *   Easily write state-of-the-art training loops without worrying about\n            all of the features `Model.fit` handles for you (distribution\n            strategies, callbacks, data formats, looping logic, etc)\n        *   See the default\n            [`Model.train_step`](https://github.com/tensorflow/tensorflow/blob/1381fc8e15e22402417b98e3881dfd409998daea/tensorflow/python/keras/engine/training.py#L540)\n            for an example of what this function should look like. Same applies\n            for validation and inference via `Model.test_step` and\n            `Model.predict_step`.\n        *   SavedModel uses its own `Model._saved_model_inputs_spec` attr now\n            instead of relying on `Model.inputs` and `Model.input_names`, which\n            are no longer set for subclass Models. This attr is set in eager,\n            `tf.function`, and graph modes. This gets rid of the need for users\n            to manually call `Model._set_inputs` when using Custom Training\n            Loops(CTLs).\n        *   Dynamic shapes are supported for generators by calling the Model on\n            the first batch we \"peek\" from the generator. This used to happen\n            implicitly in `Model._standardize_user_data`. Long-term, a solution\n            where the `DataAdapter` doesn't need to call the Model is probably\n            preferable.\n    *   The SavedModel format now supports all Keras built-in layers (including\n        metrics, preprocessing layers, and stateful RNN layers)\n    *   Update Keras batch normalization layer to use the running mean and\n        average computation in the `fused_batch_norm`. You should see\n        significant performance improvements when using `fused_batch_norm` in\n        Eager mode.\n\n*   `tf.lite`:\n\n    *   Enable TFLite experimental new converter by default.\n\n*   XLA\n\n    *   XLA now builds and works on windows. All prebuilt packages come with XLA\n        available.\n    *   XLA can be\n        [enabled for a `tf.function`](https://www.tensorflow.org/xla#explicit_compilation_with_tffunction)\n        with compile or throw exception semantics on CPU and GPU.\n\n## Breaking Changes\n\n*   `tf.keras`:\n    *   In `tf.keras.applications` the name of the \"top\" layer has been\n        standardized to \"predictions\". This is only a problem if your code\n        relies on the exact name of the layer.\n    *   Huber loss function has been updated to be consistent with other Keras\n        losses. It now computes mean over the last axis of per-sample losses\n        before applying the reduction function.\n*   AutoGraph no longer converts functions passed to `tf.py_function`,\n    `tf.py_func` and `tf.numpy_function`.\n*   Deprecating `XLA_CPU` and `XLA_GPU` devices with this release.\n*   Increasing the minimum bazel version to build TF to 2.0.0 to use Bazel's\n    `cc_experimental_shared_library`.\n*   Keras compile/fit behavior for functional and subclassed models have been\n    unified. Model properties such as `metrics`, `metrics_names` will now be\n    available only after **training/evaluating the model on actual data** for\n    functional models. `metrics` will **now include** model `loss` and output\n    losses.`loss_functions` property has been removed from the model. This was\n    an undocumented property that was accidentally public and has now been\n    removed.\n\n## Known Caveats\n\n*   The current TensorFlow release now **requires**\n    [gast](https://pypi.org/project/gast/) version 0.3.3.\n\n## Bug Fixes and Other Changes\n\n*   `tf.data`:\n    *   Removed `autotune_algorithm` from experimental optimization options.\n*   TF Core:\n    *   `tf.constant` always creates CPU tensors irrespective of the current\n        device context.\n    *   Eager `TensorHandles` maintain a list of mirrors for any copies to local\n        or remote devices. This avoids any redundant copies due to op execution.\n    *   For `tf.Tensor` & `tf.Variable`, `.experimental_ref()` is no longer\n        experimental and is available as simply `.ref()`.\n    *   `pfor/vectorized_map`: Added support for vectorizing 56 more ops.\n        Vectorizing `tf.cond` is also supported now.\n    *   Set as much partial shape as we can infer statically within the gradient\n        impl of the gather op.\n    *   Gradient of `tf.while_loop` emits `StatelessWhile` op if `cond` and body\n        functions are stateless. This allows multiple gradients while ops to run\n        in parallel under distribution strategy.\n    *   Speed up `GradientTape` in eager mode by auto-generating list of op\n        inputs/outputs which are unused and hence not cached for gradient\n        functions.\n    *   Support `back_prop=False` in `while_v2` but mark it as deprecated.\n    *   Improve error message when attempting to use `None` in data-dependent\n        control flow.\n    *   Add `RaggedTensor.numpy()`.\n    *   Update `RaggedTensor.__getitem__` to preserve uniform dimensions & allow\n        indexing into uniform dimensions.\n    *   Update `tf.expand_dims` to always insert the new dimension as a\n        non-ragged dimension.\n    *   Update `tf.embedding_lookup` to use `partition_strategy` and `max_norm`\n        when `ids` is ragged.\n    *   Allow `batch_dims==rank(indices)` in `tf.gather`.\n    *   Add support for bfloat16 in `tf.print`.\n*   `tf.distribute`:\n    *   Support `embedding_column` with variable-length input features for\n        `MultiWorkerMirroredStrategy`.\n*   `tf.kera"
        },
        {
          "name": "SECURITY.md",
          "type": "blob",
          "size": 9.5576171875,
          "content": "# Using TensorFlow Securely\n\nThis document discusses the TensorFlow security model. It describes the security\nrisks to consider when using models, checkpoints or input data for training or\nserving. We also provide guidelines on what constitutes a vulnerability in\nTensorFlow and how to report them.\n\nThis document applies to other repositories in the TensorFlow organization,\ncovering security practices for the entirety of the TensorFlow ecosystem.\n\n## TensorFlow models are programs\n\nTensorFlow\n[**models**](https://developers.google.com/machine-learning/glossary/#model) (to\nuse a term commonly used by machine learning practitioners) are expressed as\nprograms that TensorFlow executes. TensorFlow programs are encoded as\ncomputation\n[**graphs**](https://developers.google.com/machine-learning/glossary/#graph).\nSince models are practically programs that TensorFlow executes, using untrusted\nmodels or graphs is equivalent to running untrusted code.\n\nIf you need to run untrusted models, execute them inside a\n[**sandbox**](https://developers.google.com/code-sandboxing). Memory corruptions\nin TensorFlow ops can be recognized as security issues only if they are\nreachable and exploitable through production-grade, benign models.\n\n### Compilation\n\nCompiling models via the recommended entry points described in\n[XLA](https://www.tensorflow.org/xla) and\n[JAX](https://jax.readthedocs.io/en/latest/jax-101/02-jitting.html)\ndocumentation should be safe, while some of the testing and debugging tools that\ncome with the compiler are not designed to be used with untrusted data and\nshould be used with caution when working with untrusted models.\n\n### Saved graphs and checkpoints\n\nWhen loading untrusted serialized computation graphs (in form of a `GraphDef`,\n`SavedModel`, or equivalent on-disk format), the set of computation primitives\navailable to TensorFlow is powerful enough that you should assume that the\nTensorFlow process effectively executes arbitrary code.\n\nThe risk of loading untrusted checkpoints depends on the code or graph that you\nare working with. When loading untrusted checkpoints, the values of the traced\nvariables from your model are also going to be untrusted. That means that if\nyour code interacts with the filesystem, network, etc. and uses checkpointed\nvariables as part of those interactions (ex: using a string variable to build a\nfilesystem path), a maliciously created checkpoint might be able to change the\ntargets of those operations, which could result in arbitrary\nread/write/executions.\n\n### Running a TensorFlow server\n\nTensorFlow is a platform for distributed computing, and as such there is a\nTensorFlow server (`tf.train.Server`). The TensorFlow server is intended for\ninternal communication only. It is not built for use in untrusted environments\nor networks.\n\nFor performance reasons, the default TensorFlow server does not include any\nauthorization protocol and sends messages unencrypted. It accepts connections\nfrom anywhere, and executes the graphs it is sent without performing any checks.\nTherefore, if you run a `tf.train.Server` in your network, anybody with access\nto the network can execute arbitrary code with the privileges of the user\nrunning the `tf.train.Server`.\n\n## Untrusted inputs during training and prediction\n\nTensorFlow supports a wide range of input data formats. For example it can\nprocess images, audio, videos, and text. There are several modules specialized\nin taking those formats, modifying them, and/or converting them to intermediate\nformats that can be processed by TensorFlow.\n\nThese modifications and conversions are handled by a variety of libraries that\nhave different security properties and provide different levels of confidence\nwhen dealing with untrusted data. Based on the security history of these\nlibraries we consider that it is safe to work with untrusted inputs for PNG,\nBMP, GIF, WAV, RAW, RAW\\_PADDED, CSV and PROTO formats. All other input formats,\nincluding tensorflow-io should be sandboxed if used to process untrusted data.\n\nFor example, if an attacker were to upload a malicious video file, they could\npotentially exploit a vulnerability in the TensorFlow code that handles videos,\nwhich could allow them to execute arbitrary code on the system running\nTensorFlow.\n\nIt is important to keep TensorFlow up to date with the latest security patches\nand follow the sandboxing guideline above to protect against these types of\nvulnerabilities.\n\n## Security properties of execution modes\n\nTensorFlow has several execution modes, with Eager-mode being the default in v2.\nEager mode lets users write imperative-style statements that can be easily\ninspected and debugged and it is intended to be used during the development\nphase.\n\nAs part of the differences that make Eager mode easier to debug, the [shape\ninference\nfunctions](https://www.tensorflow.org/guide/create_op#define_the_op_interface)\nare skipped, and any checks implemented inside the shape inference code are not\nexecuted.\n\nThe security impact of skipping those checks should be low, since the attack\nscenario would require a malicious user to be able to control the model which as\nstated above is already equivalent to code execution. In any case, the\nrecommendation is not to serve models using Eager mode since it also has\nperformance limitations.\n\n## Multi-Tenant environments\n\nIt is possible to run multiple TensorFlow models in parallel. For example,\n`ModelServer` collates all computation graphs exposed to it (from multiple\n`SavedModel`) and executes them in parallel on available executors. Running\nTensorFlow in a multitenant design mixes the risks described above with the\ninherent ones from multitenant configurations. The primary areas of concern are\ntenant isolation, resource allocation, model sharing and hardware attacks.\n\n### Tenant isolation\n\nSince any tenants or users providing models, graphs or checkpoints can execute\ncode in context of the TensorFlow service, it is important to design isolation\nmechanisms that prevent unwanted access to the data from other tenants.\n\nNetwork isolation between different models is also important not only to prevent\nunauthorized access to data or models, but also to prevent malicious users or\ntenants sending graphs to execute under another tenants identity.\n\nThe isolation mechanisms are the responsibility of the users to design and\nimplement, and therefore security issues deriving from their absence are not\nconsidered a vulnerability in TensorFlow.\n\n### Resource allocation\n\nA denial of service caused by one model could bring down the entire server, but\nwe don't consider this as a vulnerability, given that models can exhaust\nresources in many different ways and solutions exist to prevent this from\nhappening (e.g., rate limits, ACLs, monitors to restart broken servers).\n\n### Model sharing\n\nIf the multitenant design allows sharing models, make sure that tenants and\nusers are aware of the security risks detailed here and that they are going to\nbe practically running code provided by other users. Currently there are no good\nways to detect malicious models/graphs/checkpoints, so the recommended way to\nmitigate the risk in this scenario is to sandbox the model execution.\n\n### Hardware attacks\n\nPhysical GPUs or TPUs can also be the target of attacks. [Published\nresearch](https://scholar.google.com/scholar?q=gpu+side+channel) shows that it\nmight be possible to use side channel attacks on the GPU to leak data from other\nrunning models or processes in the same system. GPUs can also have\nimplementation bugs that might allow attackers to leave malicious code running\nand leak or tamper with applications from other users. Please report\nvulnerabilities to the vendor of the affected hardware accelerator.\n\n## Reporting vulnerabilities\n\n### Vulnerabilities in TensorFlow\n\nThis document covers different use cases for TensorFlow together with comments\nwhether these uses were recommended or considered safe, or where we recommend\nsome form of isolation when dealing with untrusted data. As a result, this\ndocument also outlines what issues we consider as TensorFlow security\nvulnerabilities.\n\nWe recognize issues as vulnerabilities only when they occur in scenarios that we\noutline as safe; issues that have a security impact only when TensorFlow is used\nin a discouraged way (e.g. running untrusted models or checkpoints, data parsing\noutside of the safe formats, etc.) are not treated as vulnerabilities.\n\n### Reporting process\n\nPlease use [Google Bug Hunters reporting form](https://g.co/vulnz) to report\nsecurity vulnerabilities. Please include the following information along with\nyour report:\n\n  - A descriptive title\n  - Your name and affiliation (if any).\n  - A description of the technical details of the vulnerabilities.\n  - A minimal example of the vulnerability. It is very important to let us know\n    how we can reproduce your findings. For memory corruption triggerable in\n    TensorFlow models, please demonstrate an exploit against one of Alphabet's\n    models in <https://tfhub.dev/>\n  - An explanation of who can exploit this vulnerability, and what they gain\n    when doing so. Write an attack scenario that demonstrates how your issue\n    violates the use cases and security assumptions defined in the threat model.\n    This will help us evaluate your report quickly, especially if the issue is\n    complex.\n  - Whether this vulnerability is public or known to third parties. If it is,\n    please provide details.\n\nWe will try to fix the problems as soon as possible. Vulnerabilities will, in\ngeneral, be batched to be fixed at the same time as a quarterly release. We\ncredit reporters for identifying security issues, although we keep your name\nconfidential if you request it. Please see Google Bug Hunters program website\nfor more info.\n"
        },
        {
          "name": "WORKSPACE",
          "type": "blob",
          "size": 3.02734375,
          "content": "# buildifier: disable=load-on-top\n\nworkspace(name = \"org_tensorflow\")\n\n# buildifier: disable=load-on-top\n\n# We must initialize hermetic python first.\nload(\"@bazel_tools//tools/build_defs/repo:http.bzl\", \"http_archive\")\n\nhttp_archive(\n    name = \"rules_java\",\n    sha256 = \"c73336802d0b4882e40770666ad055212df4ea62cfa6edf9cb0f9d29828a0934\",\n    url = \"https://github.com/bazelbuild/rules_java/releases/download/5.3.5/rules_java-5.3.5.tar.gz\",\n)\n\n# Initialize the TensorFlow repository and all dependencies.\n#\n# The cascade of load() statements and tf_workspace?() calls works around the\n# restriction that load() statements need to be at the top of .bzl files.\n# E.g. we can not retrieve a new repository with http_archive and then load()\n# a macro from that repository in the same file.\nload(\"@//tensorflow:workspace3.bzl\", \"tf_workspace3\")\n\ntf_workspace3()\n\n# Initialize hermetic Python\nload(\"@local_tsl//third_party/py:python_init_rules.bzl\", \"python_init_rules\")\n\npython_init_rules()\n\nload(\"@local_tsl//third_party/py:python_init_repositories.bzl\", \"python_init_repositories\")\n\npython_init_repositories(\n    default_python_version = \"system\",\n    local_wheel_dist_folder = \"dist\",\n    local_wheel_inclusion_list = [\n        \"tensorflow*\",\n        \"tf_nightly*\",\n    ],\n    local_wheel_workspaces = [\"//:WORKSPACE\"],\n    requirements = {\n        \"3.9\": \"//:requirements_lock_3_9.txt\",\n        \"3.10\": \"//:requirements_lock_3_10.txt\",\n        \"3.11\": \"//:requirements_lock_3_11.txt\",\n        \"3.12\": \"//:requirements_lock_3_12.txt\",\n    },\n)\n\nload(\"@local_tsl//third_party/py:python_init_toolchains.bzl\", \"python_init_toolchains\")\n\npython_init_toolchains()\n\nload(\"@local_tsl//third_party/py:python_init_pip.bzl\", \"python_init_pip\")\n\npython_init_pip()\n\nload(\"@pypi//:requirements.bzl\", \"install_deps\")\n\ninstall_deps()\n# End hermetic Python initialization\n\nload(\"@//tensorflow:workspace2.bzl\", \"tf_workspace2\")\n\ntf_workspace2()\n\nload(\"@//tensorflow:workspace1.bzl\", \"tf_workspace1\")\n\ntf_workspace1()\n\nload(\"@//tensorflow:workspace0.bzl\", \"tf_workspace0\")\n\ntf_workspace0()\n\nload(\n    \"@local_tsl//third_party/gpus/cuda/hermetic:cuda_json_init_repository.bzl\",\n    \"cuda_json_init_repository\",\n)\n\ncuda_json_init_repository()\n\nload(\n    \"@cuda_redist_json//:distributions.bzl\",\n    \"CUDA_REDISTRIBUTIONS\",\n    \"CUDNN_REDISTRIBUTIONS\",\n)\nload(\n    \"@local_tsl//third_party/gpus/cuda/hermetic:cuda_redist_init_repositories.bzl\",\n    \"cuda_redist_init_repositories\",\n    \"cudnn_redist_init_repository\",\n)\n\ncuda_redist_init_repositories(\n    cuda_redistributions = CUDA_REDISTRIBUTIONS,\n)\n\ncudnn_redist_init_repository(\n    cudnn_redistributions = CUDNN_REDISTRIBUTIONS,\n)\n\nload(\n    \"@local_tsl//third_party/gpus/cuda/hermetic:cuda_configure.bzl\",\n    \"cuda_configure\",\n)\n\ncuda_configure(name = \"local_config_cuda\")\n\nload(\n    \"@local_tsl//third_party/nccl/hermetic:nccl_redist_init_repository.bzl\",\n    \"nccl_redist_init_repository\",\n)\n\nnccl_redist_init_repository()\n\nload(\n    \"@local_tsl//third_party/nccl/hermetic:nccl_configure.bzl\",\n    \"nccl_configure\",\n)\n\nnccl_configure(name = \"local_config_nccl\")\n"
        },
        {
          "name": "arm_compiler.BUILD",
          "type": "blob",
          "size": 1.154296875,
          "content": "package(default_visibility = [\"//visibility:public\"])\n\nfilegroup(\n    name = \"gcc\",\n    srcs = glob([\"bin/*-gcc\"]),\n)\n\nfilegroup(\n    name = \"ar\",\n    srcs = glob([\"bin/*-ar\"]),\n)\n\nfilegroup(\n    name = \"ld\",\n    srcs = glob([\"bin/*-ld\"]),\n)\n\nfilegroup(\n    name = \"nm\",\n    srcs = glob([\"bin/*-nm\"]),\n)\n\nfilegroup(\n    name = \"objcopy\",\n    srcs = glob([\"bin/*-objcopy\"]),\n)\n\nfilegroup(\n    name = \"objdump\",\n    srcs = glob([\"bin/*-objdump\"]),\n)\n\nfilegroup(\n    name = \"strip\",\n    srcs = glob([\"bin/*-strip\"]),\n)\n\nfilegroup(\n    name = \"as\",\n    srcs = glob([\"bin/*-as\"]),\n)\n\nfilegroup(\n    name = \"compiler_pieces\",\n    srcs = glob([\n        \"arm-rpi-linux-gnueabihf/**\",\n        \"libexec/**\",\n        \"lib/gcc/arm-rpi-linux-gnueabihf/**\",\n        \"include/**\",\n    ]),\n)\n\nfilegroup(\n    name = \"aarch64_compiler_pieces\",\n    srcs = glob([\n        \"aarch64-none-linux-gnu/**\",\n        \"libexec/**\",\n        \"lib/gcc/aarch64-none-linux-gnu/**\",\n        \"include/**\",\n    ]),\n)\n\nfilegroup(\n    name = \"compiler_components\",\n    srcs = [\n        \":ar\",\n        \":as\",\n        \":gcc\",\n        \":ld\",\n        \":nm\",\n        \":objcopy\",\n        \":objdump\",\n        \":strip\",\n    ],\n)\n"
        },
        {
          "name": "ci",
          "type": "tree",
          "content": null
        },
        {
          "name": "configure",
          "type": "blob",
          "size": 0.2783203125,
          "content": "#!/usr/bin/env bash\n\nset -e\nset -o pipefail\n\nif [ -z \"$PYTHON_BIN_PATH\" ]; then\n  PYTHON_BIN_PATH=$(which python3 || which python || true)\nfi\n\n# Set all env variables\nCONFIGURE_DIR=$(dirname \"$0\")\n\"$PYTHON_BIN_PATH\" \"${CONFIGURE_DIR}/configure.py\" \"$@\"\n\necho \"Configuration finished\"\n\n"
        },
        {
          "name": "configure.cmd",
          "type": "blob",
          "size": 0.763671875,
          "content": ":: Copyright 2019 The TensorFlow Authors.  All Rights Reserved.\n::\n:: Licensed under the Apache License, Version 2.0 (the \"License\");\n:: you may not use this file except in compliance with the License.\n:: You may obtain a copy of the License at\n::\n::    http://www.apache.org/licenses/LICENSE-2.0\n::\n:: Unless required by applicable law or agreed to in writing, software\n:: distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n:: WARRANTIES OR CONDITIONS OF ANY KIND< either express or implied.  See the\n:: License for the specific language governing permissions and limitations under\n:: the License.\n\n@echo off\n\nset configure_dir=%~dp0\nset configure_dir=%configure_dir:~0,-1%\npython \"%configure_dir%\\configure.py\" %* || ( exit /b )\necho Configuration finished\n"
        },
        {
          "name": "configure.py",
          "type": "blob",
          "size": 48.2451171875,
          "content": "# Copyright 2017 The TensorFlow Authors. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n# ==============================================================================\n\"\"\"configure script to get build parameters from user.\"\"\"\n\nimport argparse\nimport errno\nimport json\nimport os\nimport platform\nimport re\nimport shutil\nimport subprocess\nimport sys\n\n\n_DEFAULT_CUDA_COMPUTE_CAPABILITIES = '3.5,7.0'\n\n_SUPPORTED_ANDROID_NDK_VERSIONS = [19, 20, 21, 25]\n\n_DEFAULT_PROMPT_ASK_ATTEMPTS = 10\n\n_TF_BAZELRC_FILENAME = '.tf_configure.bazelrc'\n_TF_WORKSPACE_ROOT = ''\n_TF_BAZELRC = ''\n_TF_CURRENT_BAZEL_VERSION = None\n\nNCCL_LIB_PATHS = [\n    'lib64/', 'lib/powerpc64le-linux-gnu/', 'lib/x86_64-linux-gnu/', ''\n]\n\n# List of files to configure when building Bazel on Apple platforms.\nAPPLE_BAZEL_FILES = [\n    'tensorflow/lite/ios/BUILD', 'tensorflow/lite/objc/BUILD',\n    'tensorflow/lite/swift/BUILD',\n    'tensorflow/lite/tools/benchmark/experimental/ios/BUILD'\n]\n\n# List of files to move when building for iOS.\nIOS_FILES = [\n    'tensorflow/lite/objc/TensorFlowLiteObjC.podspec',\n    'tensorflow/lite/swift/TensorFlowLiteSwift.podspec',\n]\n\n\nclass UserInputError(Exception):\n  pass\n\n\ndef is_windows():\n  return platform.system() == 'Windows'\n\n\ndef is_linux():\n  return platform.system() == 'Linux'\n\n\ndef is_macos():\n  return platform.system() == 'Darwin'\n\n\ndef is_ppc64le():\n  return platform.machine() == 'ppc64le'\n\n\ndef is_s390x():\n  return platform.machine() == 's390x'\n\n\ndef is_cygwin():\n  return platform.system().startswith('CYGWIN_NT')\n\n\ndef get_input(question):\n  try:\n    try:\n      answer = raw_input(question)\n    except NameError:\n      answer = input(question)  # pylint: disable=bad-builtin\n  except EOFError:\n    answer = ''\n  return answer\n\n\ndef symlink_force(target, link_name):\n  \"\"\"Force symlink, equivalent of 'ln -sf'.\n\n  Args:\n    target: items to link to.\n    link_name: name of the link.\n  \"\"\"\n  try:\n    os.symlink(target, link_name)\n  except OSError as e:\n    if e.errno == errno.EEXIST:\n      os.remove(link_name)\n      os.symlink(target, link_name)\n    else:\n      raise e\n\n\ndef write_to_bazelrc(line):\n  with open(_TF_BAZELRC, 'a') as f:\n    f.write(line + '\\n')\n\n\ndef write_action_env_to_bazelrc(var_name, var):\n  write_to_bazelrc('build --action_env {}=\"{}\"'.format(var_name, str(var)))\n\n\ndef write_repo_env_to_bazelrc(config_name, var_name, var):\n  write_to_bazelrc(\n      'build:{} --repo_env {}=\"{}\"'.format(config_name, var_name, str(var))\n  )\n\n\ndef run_shell(cmd, allow_non_zero=False, stderr=None):\n  if stderr is None:\n    stderr = sys.stdout\n  if allow_non_zero:\n    try:\n      output = subprocess.check_output(cmd, stderr=stderr)\n    except subprocess.CalledProcessError as e:\n      output = e.output\n  else:\n    output = subprocess.check_output(cmd, stderr=stderr)\n  return output.decode('UTF-8').strip()\n\n\ndef cygpath(path):\n  \"\"\"Convert path from posix to windows.\"\"\"\n  return os.path.abspath(path).replace('\\\\', '/')\n\n\ndef get_python_path(environ_cp, python_bin_path):\n  \"\"\"Get the python site package paths.\"\"\"\n  python_paths = []\n  if environ_cp.get('PYTHONPATH'):\n    python_paths = environ_cp.get('PYTHONPATH').split(':')\n  try:\n    stderr = open(os.devnull, 'wb')\n    library_paths = run_shell([\n        python_bin_path, '-c',\n        'import site; print(\"\\\\n\".join(site.getsitepackages()))'\n    ],\n                              stderr=stderr).split('\\n')\n  except subprocess.CalledProcessError:\n    library_paths = [\n        run_shell([\n            python_bin_path,\n            '-c',\n            'import sysconfig;print(sysconfig.get_path(\"purelib\")',\n        ])\n    ]\n\n  all_paths = set(python_paths + library_paths)\n  # Sort set so order is deterministic\n  all_paths = sorted(all_paths)\n\n  paths = []\n  for path in all_paths:\n    if os.path.isdir(path):\n      paths.append(path)\n  return paths\n\n\ndef get_python_major_version(python_bin_path):\n  \"\"\"Get the python major version.\"\"\"\n  return run_shell([python_bin_path, '-c', 'import sys; print(sys.version[0])'])\n\n\ndef setup_python(environ_cp):\n  \"\"\"Setup python related env variables.\"\"\"\n  # Get PYTHON_BIN_PATH, default is the current running python.\n  default_python_bin_path = sys.executable\n  ask_python_bin_path = ('Please specify the location of python. [Default is '\n                         '{}]: ').format(default_python_bin_path)\n  while True:\n    python_bin_path = get_from_env_or_user_or_default(environ_cp,\n                                                      'PYTHON_BIN_PATH',\n                                                      ask_python_bin_path,\n                                                      default_python_bin_path)\n    # Check if the path is valid\n    if os.path.isfile(python_bin_path) and os.access(python_bin_path, os.X_OK):\n      break\n    elif not os.path.exists(python_bin_path):\n      print('Invalid python path: {} cannot be found.'.format(python_bin_path))\n    else:\n      print('{} is not executable.  Is it the python binary?'.format(\n          python_bin_path))\n    environ_cp['PYTHON_BIN_PATH'] = ''\n\n  # Convert python path to Windows style before checking lib and version\n  if is_windows() or is_cygwin():\n    python_bin_path = cygpath(python_bin_path)\n\n  # Get PYTHON_LIB_PATH\n  python_lib_path = environ_cp.get('PYTHON_LIB_PATH')\n  if not python_lib_path:\n    python_lib_paths = get_python_path(environ_cp, python_bin_path)\n    if environ_cp.get('USE_DEFAULT_PYTHON_LIB_PATH') == '1':\n      python_lib_path = python_lib_paths[0]\n    else:\n      print('Found possible Python library paths:\\n  %s' %\n            '\\n  '.join(python_lib_paths))\n      default_python_lib_path = python_lib_paths[0]\n      python_lib_path = get_input(\n          'Please input the desired Python library path to use.  '\n          'Default is [{}]\\n'.format(python_lib_paths[0]))\n      if not python_lib_path:\n        python_lib_path = default_python_lib_path\n    environ_cp['PYTHON_LIB_PATH'] = python_lib_path\n\n  python_major_version = get_python_major_version(python_bin_path)\n  if python_major_version == '2':\n    write_to_bazelrc('build --host_force_python=PY2')\n\n  # Convert python path to Windows style before writing into bazel.rc\n  if is_windows() or is_cygwin():\n    python_lib_path = cygpath(python_lib_path)\n\n  # Set-up env variables used by python_configure.bzl\n  write_action_env_to_bazelrc('PYTHON_BIN_PATH', python_bin_path)\n  write_action_env_to_bazelrc('PYTHON_LIB_PATH', python_lib_path)\n  write_to_bazelrc('build --python_path=\\\"{}\"'.format(python_bin_path))\n  environ_cp['PYTHON_BIN_PATH'] = python_bin_path\n\n  # If chosen python_lib_path is from a path specified in the PYTHONPATH\n  # variable, need to tell bazel to include PYTHONPATH\n  if environ_cp.get('PYTHONPATH'):\n    python_paths = environ_cp.get('PYTHONPATH').split(':')\n    if python_lib_path in python_paths:\n      write_action_env_to_bazelrc('PYTHONPATH', environ_cp.get('PYTHONPATH'))\n\n  # Write tools/python_bin_path.sh\n  with open(\n      os.path.join(_TF_WORKSPACE_ROOT, 'tools', 'python_bin_path.sh'),\n      'w') as f:\n    f.write('export PYTHON_BIN_PATH=\"{}\"'.format(python_bin_path))\n\n\ndef reset_tf_configure_bazelrc():\n  \"\"\"Reset file that contains customized config settings.\"\"\"\n  open(_TF_BAZELRC, 'w').close()\n\n\ndef cleanup_makefile():\n  \"\"\"Delete any leftover BUILD files from the Makefile build.\n\n  These files could interfere with Bazel parsing.\n  \"\"\"\n  makefile_download_dir = os.path.join(_TF_WORKSPACE_ROOT, 'tensorflow',\n                                       'contrib', 'makefile', 'downloads')\n  if os.path.isdir(makefile_download_dir):\n    for root, _, filenames in os.walk(makefile_download_dir):\n      for f in filenames:\n        if f.endswith('BUILD'):\n          os.remove(os.path.join(root, f))\n\n\ndef get_var(environ_cp,\n            var_name,\n            query_item,\n            enabled_by_default,\n            question=None,\n            yes_reply=None,\n            no_reply=None):\n  \"\"\"Get boolean input from user.\n\n  If var_name is not set in env, ask user to enable query_item or not. If the\n  response is empty, use the default.\n\n  Args:\n    environ_cp: copy of the os.environ.\n    var_name: string for name of environment variable, e.g. \"TF_NEED_CUDA\".\n    query_item: string for feature related to the variable, e.g. \"CUDA for\n      Nvidia GPUs\".\n    enabled_by_default: boolean for default behavior.\n    question: optional string for how to ask for user input.\n    yes_reply: optional string for reply when feature is enabled.\n    no_reply: optional string for reply when feature is disabled.\n\n  Returns:\n    boolean value of the variable.\n\n  Raises:\n    UserInputError: if an environment variable is set, but it cannot be\n      interpreted as a boolean indicator, assume that the user has made a\n      scripting error, and will continue to provide invalid input.\n      Raise the error to avoid infinitely looping.\n  \"\"\"\n  if not question:\n    question = 'Do you wish to build TensorFlow with {} support?'.format(\n        query_item)\n  if not yes_reply:\n    yes_reply = '{} support will be enabled for TensorFlow.'.format(query_item)\n  if not no_reply:\n    no_reply = 'No {}'.format(yes_reply)\n\n  yes_reply += '\\n'\n  no_reply += '\\n'\n\n  if enabled_by_default:\n    question += ' [Y/n]: '\n  else:\n    question += ' [y/N]: '\n\n  var = environ_cp.get(var_name)\n  if var is not None:\n    var_content = var.strip().lower()\n    true_strings = ('1', 't', 'true', 'y', 'yes')\n    false_strings = ('0', 'f', 'false', 'n', 'no')\n    if var_content in true_strings:\n      var = True\n    elif var_content in false_strings:\n      var = False\n    else:\n      raise UserInputError(\n          'Environment variable %s must be set as a boolean indicator.\\n'\n          'The following are accepted as TRUE : %s.\\n'\n          'The following are accepted as FALSE: %s.\\n'\n          'Current value is %s.' %\n          (var_name, ', '.join(true_strings), ', '.join(false_strings), var))\n\n  while var is None:\n    user_input_origin = get_input(question)\n    user_input = user_input_origin.strip().lower()\n    if user_input == 'y':\n      print(yes_reply)\n      var = True\n    elif user_input == 'n':\n      print(no_reply)\n      var = False\n    elif not user_input:\n      if enabled_by_default:\n        print(yes_reply)\n        var = True\n      else:\n        print(no_reply)\n        var = False\n    else:\n      print('Invalid selection: {}'.format(user_input_origin))\n  return var\n\n\ndef set_action_env_var(environ_cp,\n                       var_name,\n                       query_item,\n                       enabled_by_default,\n                       question=None,\n                       yes_reply=None,\n                       no_reply=None,\n                       bazel_config_name=None):\n  \"\"\"Set boolean action_env variable.\n\n  Ask user if query_item will be enabled. Default is used if no input is given.\n  Set environment variable and write to .bazelrc.\n\n  Args:\n    environ_cp: copy of the os.environ.\n    var_name: string for name of environment variable, e.g. \"TF_NEED_CUDA\".\n    query_item: string for feature related to the variable, e.g. \"CUDA for\n      Nvidia GPUs\".\n    enabled_by_default: boolean for default behavior.\n    question: optional string for how to ask for user input.\n    yes_reply: optional string for reply when feature is enabled.\n    no_reply: optional string for reply when feature is disabled.\n    bazel_config_name: adding config to .bazelrc instead of action_env.\n  \"\"\"\n  var = int(\n      get_var(environ_cp, var_name, query_item, enabled_by_default, question,\n              yes_reply, no_reply))\n\n  if not bazel_config_name:\n    write_action_env_to_bazelrc(var_name, var)\n  elif var:\n    write_to_bazelrc('build --config=%s' % bazel_config_name)\n  environ_cp[var_name] = str(var)\n\n\ndef convert_version_to_int(version):\n  \"\"\"Convert a version number to a integer that can be used to compare.\n\n  Version strings of the form X.YZ and X.Y.Z-xxxxx are supported. The\n  'xxxxx' part, for instance 'homebrew' on OS/X, is ignored.\n\n  Args:\n    version: a version to be converted\n\n  Returns:\n    An integer if converted successfully, otherwise return None.\n  \"\"\"\n  version = version.split('-')[0]\n  version_segments = version.split('.')\n  # Treat \"0.24\" as \"0.24.0\"\n  if len(version_segments) == 2:\n    version_segments.append('0')\n  for seg in version_segments:\n    if not seg.isdigit():\n      return None\n\n  version_str = ''.join(['%03d' % int(seg) for seg in version_segments])\n  return int(version_str)\n\n\ndef retrieve_bazel_version():\n  \"\"\"Retrieve installed bazel version (or bazelisk).\n\n  Returns:\n    The bazel version detected.\n  \"\"\"\n  bazel_executable = shutil.which('bazel')\n  if bazel_executable is None:\n    bazel_executable = shutil.which('bazelisk')\n    if bazel_executable is None:\n      print('Cannot find bazel. Please install bazel/bazelisk.')\n      sys.exit(1)\n\n  stderr = open(os.devnull, 'wb')\n  curr_version = run_shell([bazel_executable, '--version'],\n                           allow_non_zero=True,\n                           stderr=stderr)\n  if curr_version.startswith('bazel '):\n    curr_version = curr_version.split('bazel ')[1]\n\n  curr_version_int = convert_version_to_int(curr_version)\n\n  # Check if current bazel version can be detected properly.\n  if not curr_version_int:\n    print('WARNING: current bazel installation is not a release version.')\n    return curr_version\n\n  print('You have bazel %s installed.' % curr_version)\n  return curr_version\n\n\ndef set_cc_opt_flags(environ_cp):\n  \"\"\"Set up architecture-dependent optimization flags.\n\n  Also append CC optimization flags to bazel.rc..\n\n  Args:\n    environ_cp: copy of the os.environ.\n  \"\"\"\n  if is_ppc64le():\n    # gcc on ppc64le does not support -march, use mcpu instead\n    default_cc_opt_flags = '-mcpu=native'\n  elif is_windows():\n    default_cc_opt_flags = '/arch:AVX'\n  else:\n    # On all other platforms, no longer use `-march=native` as this can result\n    # in instructions that are too modern being generated. Users that want\n    # maximum performance should compile TF in their environment and can pass\n    # `-march=native` there.\n    # See https://github.com/tensorflow/tensorflow/issues/45744 and duplicates\n    default_cc_opt_flags = '-Wno-sign-compare'\n  question = ('Please specify optimization flags to use during compilation when'\n              ' bazel option \"--config=opt\" is specified [Default is %s]: '\n             ) % default_cc_opt_flags\n  cc_opt_flags = get_from_env_or_user_or_default(environ_cp, 'CC_OPT_FLAGS',\n                                                 question, default_cc_opt_flags)\n  for opt in cc_opt_flags.split():\n    write_to_bazelrc('build:opt --copt=%s' % opt)\n    write_to_bazelrc('build:opt --host_copt=%s' % opt)\n\n\ndef set_tf_cuda_clang(environ_cp):\n  \"\"\"set TF_CUDA_CLANG action_env.\n\n  Args:\n    environ_cp: copy of the os.environ.\n  \"\"\"\n  question = 'Do you want to use clang as CUDA compiler?'\n  yes_reply = 'Clang will be used as CUDA compiler.'\n  no_reply = 'nvcc will be used as CUDA compiler.'\n  set_action_env_var(\n      environ_cp,\n      'TF_CUDA_CLANG',\n      None,\n      True,\n      question=question,\n      yes_reply=yes_reply,\n      no_reply=no_reply,\n      bazel_config_name='cuda_clang',\n  )\n\n\ndef set_tf_download_clang(environ_cp):\n  \"\"\"Set TF_DOWNLOAD_CLANG action_env.\"\"\"\n  question = 'Do you wish to download a fresh release of clang? (Experimental)'\n  yes_reply = 'Clang will be downloaded and used to compile tensorflow.'\n  no_reply = 'Clang will not be downloaded.'\n  set_action_env_var(\n      environ_cp,\n      'TF_DOWNLOAD_CLANG',\n      None,\n      False,\n      question=question,\n      yes_reply=yes_reply,\n      no_reply=no_reply,\n      bazel_config_name='download_clang')\n\n\ndef get_from_env_or_user_or_default(environ_cp, var_name, ask_for_var,\n                                    var_default):\n  \"\"\"Get var_name either from env, or user or default.\n\n  If var_name has been set as environment variable, use the preset value, else\n  ask for user input. If no input is provided, the default is used.\n\n  Args:\n    environ_cp: copy of the os.environ.\n    var_name: string for name of environment variable, e.g. \"TF_NEED_CUDA\".\n    ask_for_var: string for how to ask for user input.\n    var_default: default value string.\n\n  Returns:\n    string value for var_name\n  \"\"\"\n  var = environ_cp.get(var_name)\n  if not var:\n    var = get_input(ask_for_var)\n    print('\\n')\n  if not var:\n    var = var_default\n  return var\n\n\ndef prompt_loop_or_load_from_env(environ_cp,\n                                 var_name,\n                                 var_default,\n                                 ask_for_var,\n                                 check_success,\n                                 error_msg,\n                                 suppress_default_error=False,\n                                 resolve_symlinks=False,\n                                 n_ask_attempts=_DEFAULT_PROMPT_ASK_ATTEMPTS):\n  \"\"\"Loop over user prompts for an ENV param until receiving a valid response.\n\n  For the env param var_name, read from the environment or verify user input\n  until receiving valid input. When done, set var_name in the environ_cp to its\n  new value.\n\n  Args:\n    environ_cp: (Dict) copy of the os.environ.\n    var_name: (String) string for name of environment variable, e.g. \"TF_MYVAR\".\n    var_default: (String) default value string.\n    ask_for_var: (String) string for how to ask for user input.\n    check_success: (Function) function that takes one argument and returns a\n      boolean. Should return True if the value provided is considered valid. May\n      contain a complex error message if error_msg does not provide enough\n      information. In that case, set suppress_default_error to True.\n    error_msg: (String) String with one and only one '%s'. Formatted with each\n      invalid response upon check_success(input) failure.\n    suppress_default_error: (Bool) Suppress the above error message in favor of\n      one from the check_success function.\n    resolve_symlinks: (Bool) Translate symbolic links into the real filepath.\n    n_ask_attempts: (Integer) Number of times to query for valid input before\n      raising an error and quitting.\n\n  Returns:\n    [String] The value of var_name after querying for input.\n\n  Raises:\n    UserInputError: if a query has been attempted n_ask_attempts times without\n      success, assume that the user has made a scripting error, and will\n      continue to provide invalid input. Raise the error to avoid infinitely\n      looping.\n  \"\"\"\n  default = environ_cp.get(var_name) or var_default\n  full_query = '%s [Default is %s]: ' % (\n      ask_for_var,\n      default,\n  )\n\n  for _ in range(n_ask_attempts):\n    val = get_from_env_or_user_or_default(environ_cp, var_name, full_query,\n                                          default)\n    if check_success(val):\n      break\n    if not suppress_default_error:\n      print(error_msg % val)\n    environ_cp[var_name] = ''\n  else:\n    raise UserInputError('Invalid %s setting was provided %d times in a row. '\n                         'Assuming to be a scripting mistake.' %\n                         (var_name, n_ask_attempts))\n\n  if resolve_symlinks:\n    val = os.path.realpath(val)\n  environ_cp[var_name] = val\n  return val\n\n\ndef set_clang_cuda_compiler_path(environ_cp):\n  \"\"\"Set CLANG_CUDA_COMPILER_PATH.\"\"\"\n  # Upon clang 19 drop the check for 16\n  default_clang_path = '/usr/lib/llvm-18/bin/clang'\n  if not os.path.exists(default_clang_path):\n    default_clang_path = '/usr/lib/llvm-17/bin/clang'\n    if not os.path.exists(default_clang_path):\n      default_clang_path = '/usr/lib/llvm-16/bin/clang'\n    if not os.path.exists(default_clang_path):\n      default_clang_path = shutil.which('clang') or ''\n\n  clang_cuda_compiler_path = prompt_loop_or_load_from_env(\n      environ_cp,\n      var_name='CLANG_CUDA_COMPILER_PATH',\n      var_default=default_clang_path,\n      ask_for_var='Please specify clang path that to be used as host compiler.',\n      check_success=os.path.exists,\n      resolve_symlinks=True,\n      error_msg='Invalid clang path. %s cannot be found.',\n  )\n\n  # Set CLANG_CUDA_COMPILER_PATH\n  environ_cp['CLANG_CUDA_COMPILER_PATH'] = clang_cuda_compiler_path\n  write_action_env_to_bazelrc('CLANG_CUDA_COMPILER_PATH',\n                              clang_cuda_compiler_path)\n  return clang_cuda_compiler_path\n\n\ndef create_android_ndk_rule(environ_cp):\n  \"\"\"Set ANDROID_NDK_HOME and write Android NDK WORKSPACE rule.\"\"\"\n  if is_windows() or is_cygwin():\n    default_ndk_path = cygpath('%s/Android/Sdk/ndk-bundle' %\n                               environ_cp['APPDATA'])\n  elif is_macos():\n    default_ndk_path = '%s/library/Android/Sdk/ndk-bundle' % environ_cp['HOME']\n  else:\n    default_ndk_path = '%s/Android/Sdk/ndk-bundle' % environ_cp['HOME']\n\n  def valid_ndk_path(path):\n    return (os.path.exists(path) and\n            os.path.exists(os.path.join(path, 'source.properties')))\n\n  android_ndk_home_path = prompt_loop_or_load_from_env(\n      environ_cp,\n      var_name='ANDROID_NDK_HOME',\n      var_default=default_ndk_path,\n      ask_for_var='Please specify the home path of the Android NDK to use.',\n      check_success=valid_ndk_path,\n      error_msg=('The path %s or its child file \"source.properties\" '\n                 'does not exist.'))\n  write_action_env_to_bazelrc('ANDROID_NDK_HOME', android_ndk_home_path)\n  write_action_env_to_bazelrc(\n      'ANDROID_NDK_API_LEVEL',\n      get_ndk_api_level(environ_cp, android_ndk_home_path))\n\n\ndef create_android_sdk_rule(environ_cp):\n  \"\"\"Set Android variables and write Android SDK WORKSPACE rule.\"\"\"\n  if is_windows() or is_cygwin():\n    default_sdk_path = cygpath('%s/Android/Sdk' % environ_cp['APPDATA'])\n  elif is_macos():\n    default_sdk_path = '%s/library/Android/Sdk' % environ_cp['HOME']\n  else:\n    default_sdk_path = '%s/Android/Sdk' % environ_cp['HOME']\n\n  def valid_sdk_path(path):\n    return (os.path.exists(path) and\n            os.path.exists(os.path.join(path, 'platforms')) and\n            os.path.exists(os.path.join(path, 'build-tools')))\n\n  android_sdk_home_path = prompt_loop_or_load_from_env(\n      environ_cp,\n      var_name='ANDROID_SDK_HOME',\n      var_default=default_sdk_path,\n      ask_for_var='Please specify the home path of the Android SDK to use.',\n      check_success=valid_sdk_path,\n      error_msg=('Either %s does not exist, or it does not contain the '\n                 'subdirectories \"platforms\" and \"build-tools\".'))\n\n  platforms = os.path.join(android_sdk_home_path, 'platforms')\n  api_levels = sorted(os.listdir(platforms))\n  api_levels = [x.replace('android-', '') for x in api_levels]\n\n  def valid_api_level(api_level):\n    return os.path.exists(\n        os.path.join(android_sdk_home_path, 'platforms',\n                     'android-' + api_level))\n\n  android_api_level = prompt_loop_or_load_from_env(\n      environ_cp,\n      var_name='ANDROID_API_LEVEL',\n      var_default=api_levels[-1],\n      ask_for_var=('Please specify the Android SDK API level to use. '\n                   '[Available levels: %s]') % api_levels,\n      check_success=valid_api_level,\n      error_msg='Android-%s is not present in the SDK path.')\n\n  build_tools = os.path.join(android_sdk_home_path, 'build-tools')\n  versions = sorted(os.listdir(build_tools))\n\n  def valid_build_tools(version):\n    return os.path.exists(\n        os.path.join(android_sdk_home_path, 'build-tools', version))\n\n  android_build_tools_version = prompt_loop_or_load_from_env(\n      environ_cp,\n      var_name='ANDROID_BUILD_TOOLS_VERSION',\n      var_default=versions[-1],\n      ask_for_var=('Please specify an Android build tools version to use. '\n                   '[Available versions: %s]') % versions,\n      check_success=valid_build_tools,\n      error_msg=('The selected SDK does not have build-tools version %s '\n                 'available.'))\n\n  write_action_env_to_bazelrc('ANDROID_BUILD_TOOLS_VERSION',\n                              android_build_tools_version)\n  write_action_env_to_bazelrc('ANDROID_SDK_API_LEVEL', android_api_level)\n  write_action_env_to_bazelrc('ANDROID_SDK_HOME', android_sdk_home_path)\n\n\ndef get_ndk_api_level(environ_cp, android_ndk_home_path):\n  \"\"\"Gets the appropriate NDK API level to use for the provided Android NDK path.\n  \"\"\"\n\n  # First check to see if we're using a blessed version of the NDK.\n  properties_path = '%s/source.properties' % android_ndk_home_path\n  if is_windows() or is_cygwin():\n    properties_path = cygpath(properties_path)\n  with open(properties_path, 'r') as f:\n    filedata = f.read()\n\n  revision = re.search(r'Pkg.Revision = (\\d+)', filedata)\n  if revision:\n    ndk_version = revision.group(1)\n  else:\n    raise Exception('Unable to parse NDK revision.')\n  if int(ndk_version) not in _SUPPORTED_ANDROID_NDK_VERSIONS:\n    print('WARNING: The NDK version in %s is %s, which is not '\n          'supported by Bazel (officially supported versions: %s). Please use '\n          'another version. Compiling Android targets may result in confusing '\n          'errors.\\n' %\n          (android_ndk_home_path, ndk_version, _SUPPORTED_ANDROID_NDK_VERSIONS))\n  write_action_env_to_bazelrc('ANDROID_NDK_VERSION', ndk_version)\n\n  # Now grab the NDK API level to use. Note that this is different from the\n  # SDK API level, as the NDK API level is effectively the *min* target SDK\n  # version.\n  meta = open(os.path.join(android_ndk_home_path, 'meta/platforms.json'))\n  platforms = json.load(meta)\n  meta.close()\n  aliases = platforms['aliases']\n  api_levels = sorted(list(set([aliases[i] for i in aliases])))\n\n  android_ndk_api_level = prompt_loop_or_load_from_env(\n      environ_cp,\n      var_name='ANDROID_NDK_API_LEVEL',\n      var_default='21',  # 21 is required for ARM64 support.\n      ask_for_var=(\n          'Please specify the (min) Android NDK API level to use. '\n          '[Available levels: %s]'\n      )\n      % api_levels,\n      check_success=(lambda *_: True),\n      error_msg='Android-%s is not present in the NDK path.',\n  )\n\n  return android_ndk_api_level\n\n\ndef set_gcc_host_compiler_path(environ_cp):\n  \"\"\"Set GCC_HOST_COMPILER_PATH.\"\"\"\n  default_gcc_host_compiler_path = shutil.which('gcc') or ''\n\n  gcc_host_compiler_path = prompt_loop_or_load_from_env(\n      environ_cp,\n      var_name='GCC_HOST_COMPILER_PATH',\n      var_default=default_gcc_host_compiler_path,\n      ask_for_var='Please specify which gcc should be used by nvcc as the host '\n      'compiler.',\n      check_success=os.path.exists,\n      resolve_symlinks=True,\n      error_msg='Invalid gcc path. %s cannot be found.',\n  )\n\n  write_action_env_to_bazelrc('GCC_HOST_COMPILER_PATH', gcc_host_compiler_path)\n\n\ndef choose_compiler(environ_cp):\n  question = 'Do you want to use Clang to build TensorFlow?'\n  yes_reply = 'Clang will be used to compile TensorFlow.'\n  no_reply = 'GCC will be used to compile TensorFlow.'\n  var = int(\n      get_var(\n          environ_cp, 'TF_NEED_CLANG', None, True, question, yes_reply, no_reply\n      )\n  )\n  return var\n\n\ndef choose_compiler_Win(environ_cp):\n  question = 'Do you want to use Clang to build TensorFlow?'\n  yes_reply = 'Add \"--config=win_clang\" to compile TensorFlow with CLANG.'\n  no_reply = 'MSVC will be used to compile TensorFlow.'\n  var = int(\n      get_var(\n          environ_cp, 'TF_NEED_CLANG', None, True, question, yes_reply, no_reply\n      )\n  )\n  return var\n\n\ndef set_clang_compiler_path(environ_cp):\n  \"\"\"Set CLANG_COMPILER_PATH and environment variables.\n\n  Loop over user prompts for clang path until receiving a valid response.\n  Default is used if no input is given. Set CLANG_COMPILER_PATH and write\n  environment variables CC and BAZEL_COMPILER to .bazelrc.\n\n  Args:\n    environ_cp: (Dict) copy of the os.environ.\n\n  Returns:\n    string value for clang_compiler_path.\n  \"\"\"\n  # Default path if clang-18 is installed by using apt-get install\n  # remove 16 logic upon release of 19\n  default_clang_path = '/usr/lib/llvm-18/bin/clang'\n  if not os.path.exists(default_clang_path):\n    default_clang_path = '/usr/lib/llvm-17/bin/clang'\n    if not os.path.exists(default_clang_path):\n      default_clang_path = '/usr/lib/llvm-16/bin/clang'\n    if not os.path.exists(default_clang_path):\n      default_clang_path = shutil.which('clang') or ''\n\n  clang_compiler_path = prompt_loop_or_load_from_env(\n      environ_cp,\n      var_name='CLANG_COMPILER_PATH',\n      var_default=default_clang_path,\n      ask_for_var='Please specify the path to clang executable.',\n      check_success=os.path.exists,\n      resolve_symlinks=True,\n      error_msg=(\n          'Invalid clang path. %s cannot be found. Note that TensorFlow now'\n          ' requires clang to compile. You may override this behavior by'\n          ' setting TF_NEED_CLANG=0'\n      ),\n  )\n\n  write_action_env_to_bazelrc('CLANG_COMPILER_PATH', clang_compiler_path)\n  write_to_bazelrc('build --repo_env=CC=%s' % clang_compiler_path)\n  write_to_bazelrc('build --repo_env=BAZEL_COMPILER=%s' % clang_compiler_path)\n\n  return clang_compiler_path\n\n\ndef set_clang_compiler_path_win(environ_cp):\n  \"\"\"Set CLANG_COMPILER_PATH and environment variables.\n\n  Loop over user prompts for clang path until receiving a valid response.\n  Default is used if no input is given. Set CLANG_COMPILER_PATH and write\n  environment variables CC and BAZEL_COMPILER to .bazelrc.\n\n  Args:\n    environ_cp: (Dict) copy of the os.environ.\n\n  Returns:\n    string value for clang_compiler_path.\n  \"\"\"\n  # Default path if clang-16 is installed by using apt-get install\n  default_clang_path = 'C:/Program Files/LLVM/bin/clang.exe'\n  if not os.path.exists(default_clang_path):\n    default_clang_path = shutil.which('clang') or ''\n\n  clang_compiler_path = prompt_loop_or_load_from_env(\n      environ_cp,\n      var_name='CLANG_COMPILER_PATH',\n      var_default=default_clang_path,\n      ask_for_var='Please specify the path to clang executable.',\n      check_success=os.path.exists,\n      resolve_symlinks=True,\n      error_msg=(\n          'Invalid clang path. %s cannot be found. Note that Clang is now'\n          'preferred compiler. You may use MSVC by removing --config=win_clang'\n      ),\n  )\n\n  write_action_env_to_bazelrc('CLANG_COMPILER_PATH', clang_compiler_path)\n  write_to_bazelrc(f'build --repo_env=CC=\"{clang_compiler_path}\"')\n  write_to_bazelrc(f'build --repo_env=BAZEL_COMPILER=\"{clang_compiler_path}\"')\n\n  return clang_compiler_path\n\n\ndef retrieve_clang_version(clang_executable):\n  \"\"\"Retrieve installed clang version.\n\n  Args:\n    clang_executable: (String) path to clang executable\n\n  Returns:\n    The clang version detected.\n  \"\"\"\n  stderr = open(os.devnull, 'wb')\n  curr_version = run_shell([clang_executable, '--version'],\n                           allow_non_zero=True,\n                           stderr=stderr)\n\n  curr_version_split = curr_version.lower().split('clang version ')\n  if len(curr_version_split) > 1:\n    curr_version = curr_version_split[1].split()[0].split('git')\n\n  if len(curr_version) > 1:\n    print('WARNING: current clang installation is not a release version.\\n')\n\n  curr_version = curr_version[0]\n  curr_version_int = convert_version_to_int(curr_version)\n  # Check if current clang version can be detected properly.\n  if not curr_version_int:\n    print('WARNING: current clang installation version unknown.\\n')\n    return None\n\n  print('You have Clang %s installed.\\n' % curr_version)\n  return curr_version\n\n\n# Disable clang extension that rejects type definitions within offsetof.\n# This was added in clang-16 by https://reviews.llvm.org/D133574.\n# Still required for clang-17.\n# Can be removed once upb is updated, since a type definition is used within\n# offset of in the current version of ubp. See\n# https://github.com/protocolbuffers/upb/blob/9effcbcb27f0a665f9f345030188c0b291e32482/upb/upb.c#L183.\ndef disable_clang_offsetof_extension(clang_version):\n  if int(clang_version.split('.')[0]) in (16, 17):\n    write_to_bazelrc('build --copt=-Wno-gnu-offsetof-extensions')\n\n\ndef set_hermetic_cuda_version(environ_cp):\n  \"\"\"Set HERMETIC_CUDA_VERSION.\"\"\"\n  ask_cuda_version = (\n      'Please specify the hermetic CUDA version you want to use '\n      'or leave empty to use the default version. '\n  )\n  hermetic_cuda_version = get_from_env_or_user_or_default(\n      environ_cp, 'HERMETIC_CUDA_VERSION', ask_cuda_version, None\n  )\n  if hermetic_cuda_version:\n    environ_cp['HERMETIC_CUDA_VERSION'] = hermetic_cuda_version\n    write_repo_env_to_bazelrc(\n        'cuda', 'HERMETIC_CUDA_VERSION', hermetic_cuda_version\n    )\n\n\ndef set_hermetic_cudnn_version(environ_cp):\n  \"\"\"Set HERMETIC_CUDNN_VERSION.\"\"\"\n  ask_cudnn_version = (\n      'Please specify the hermetic cuDNN version you want to use '\n      'or leave empty to use the default version. '\n  )\n  hermetic_cudnn_version = get_from_env_or_user_or_default(\n      environ_cp, 'HERMETIC_CUDNN_VERSION', ask_cudnn_version, None\n  )\n  if hermetic_cudnn_version:\n    environ_cp['HERMETIC_CUDNN_VERSION'] = hermetic_cudnn_version\n    write_repo_env_to_bazelrc(\n        'cuda', 'HERMETIC_CUDNN_VERSION', hermetic_cudnn_version\n    )\n\n\ndef set_hermetic_cuda_compute_capabilities(environ_cp):\n  \"\"\"Set HERMETIC_CUDA_COMPUTE_CAPABILITIES.\"\"\"\n  while True:\n    default_cuda_compute_capabilities = _DEFAULT_CUDA_COMPUTE_CAPABILITIES\n\n    ask_cuda_compute_capabilities = (\n        'Please specify a list of comma-separated CUDA compute capabilities '\n        'you want to build with.\\nYou can find the compute capability of your '\n        'device at: https://developer.nvidia.com/cuda-gpus. Each capability '\n        'can be specified as \"x.y\" or \"compute_xy\" to include both virtual and'\n        ' binary GPU code, or as \"sm_xy\" to only include the binary '\n        'code.\\nPlease note that each additional compute capability '\n        'significantly increases your build time and binary size, and that '\n        'TensorFlow only supports compute capabilities >= 3.5 [Default is: '\n        '%s]: ' % default_cuda_compute_capabilities)\n    hermetic_cuda_compute_capabilities = get_from_env_or_user_or_default(\n        environ_cp,\n        'HERMETIC_CUDA_COMPUTE_CAPABILITIES',\n        ask_cuda_compute_capabilities,\n        default_cuda_compute_capabilities,\n    )\n    # Check whether all capabilities from the input is valid\n    all_valid = True\n    # Remove all whitespace characters before splitting the string\n    # that users may insert by accident, as this will result in error\n    hermetic_cuda_compute_capabilities = ''.join(\n        hermetic_cuda_compute_capabilities.split()\n    )\n    for compute_capability in hermetic_cuda_compute_capabilities.split(','):\n      m = re.match('[0-9]+.[0-9]+', compute_capability)\n      if not m:\n        # We now support sm_35,sm_50,sm_60,compute_70.\n        sm_compute_match = re.match('(sm|compute)_?([0-9]+[0-9]+)',\n                                    compute_capability)\n        if not sm_compute_match:\n          print('Invalid compute capability: %s' % compute_capability)\n          all_valid = False\n        else:\n          ver = int(sm_compute_match.group(2))\n          if ver < 30:\n            print(\n                'ERROR: TensorFlow only supports small CUDA compute'\n                ' capabilities of sm_30 and higher. Please re-specify the list'\n                ' of compute capabilities excluding version %s.' % ver)\n            all_valid = False\n          if ver < 35:\n            print('WARNING: XLA does not support CUDA compute capabilities '\n                  'lower than sm_35. Disable XLA when running on older GPUs.')\n      else:\n        ver = float(m.group(0))\n        if ver < 3.0:\n          print('ERROR: TensorFlow only supports CUDA compute capabilities 3.0 '\n                'and higher. Please re-specify the list of compute '\n                'capabilities excluding version %s.' % ver)\n          all_valid = False\n        if ver < 3.5:\n          print('WARNING: XLA does not support CUDA compute capabilities '\n                'lower than 3.5. Disable XLA when running on older GPUs.')\n\n    if all_valid:\n      break\n\n    # Reset and Retry\n    environ_cp['HERMETIC_CUDA_COMPUTE_CAPABILITIES'] = ''\n\n  # Set HERMETIC_CUDA_COMPUTE_CAPABILITIES\n  environ_cp['HERMETIC_CUDA_COMPUTE_CAPABILITIES'] = (\n      hermetic_cuda_compute_capabilities\n  )\n  write_repo_env_to_bazelrc(\n      'cuda',\n      'HERMETIC_CUDA_COMPUTE_CAPABILITIES',\n      hermetic_cuda_compute_capabilities,\n  )\n\n\ndef set_cuda_local_path(environ_cp, dist_name, env_var):\n  ask_path = (\n      'Please specify the local {} path you want to use '\n      'or leave empty to use the default version. '\n  ).format(dist_name)\n  local_path = get_from_env_or_user_or_default(\n      environ_cp, env_var, ask_path, None\n  )\n  if local_path:\n    environ_cp[env_var] = local_path\n    write_repo_env_to_bazelrc('cuda', env_var, local_path)\n\n\ndef set_other_cuda_vars(environ_cp):\n  \"\"\"Set other CUDA related variables.\"\"\"\n  # If CUDA is enabled, always use GPU during build and test.\n  if environ_cp.get('TF_CUDA_CLANG') == '1':\n    write_to_bazelrc('build --config=cuda_clang')\n  else:\n    write_to_bazelrc('build --config=cuda')\n\n\ndef system_specific_test_config(environ_cp):\n  \"\"\"Add default build and test flags required for TF tests to bazelrc.\"\"\"\n  write_to_bazelrc('test --test_size_filters=small,medium')\n\n  # Each instance of --test_tag_filters or --build_tag_filters overrides all\n  # previous instances, so we need to build up a complete list and write a\n  # single list of filters for the .bazelrc file.\n\n  # Filters to use with both --test_tag_filters and --build_tag_filters\n  test_and_build_filters = ['-benchmark-test', '-no_oss', '-oss_excluded']\n  # Additional filters for --test_tag_filters beyond those in\n  # test_and_build_filters\n  test_only_filters = ['-oss_serial']\n  if is_windows():\n    test_and_build_filters += ['-no_windows', '-windows_excluded']\n    if ((environ_cp.get('TF_NEED_CUDA', None) == '1') or\n        (environ_cp.get('TF_NEED_ROCM', None) == '1')):\n      test_and_build_filters += ['-no_windows_gpu', '-no_gpu']\n    else:\n      test_and_build_filters.append('-gpu')\n  elif is_macos():\n    test_and_build_filters += ['-gpu', '-nomac', '-no_mac', '-mac_excluded']\n  elif is_linux():\n    if ((environ_cp.get('TF_NEED_CUDA', None) == '1') or\n        (environ_cp.get('TF_NEED_ROCM', None) == '1')):\n      test_and_build_filters.append('-no_gpu')\n      write_to_bazelrc('test --test_env=LD_LIBRARY_PATH')\n    else:\n      test_and_build_filters.append('-gpu')\n\n  # Disable tests with \"v1only\" tag in \"v2\" Bazel config, but not in \"v1\" config\n  write_to_bazelrc('test:v1 --test_tag_filters=%s' %\n                   ','.join(test_and_build_filters + test_only_filters))\n  write_to_bazelrc('test:v1 --build_tag_filters=%s' %\n                   ','.join(test_and_build_filters))\n  write_to_bazelrc(\n      'test:v2 --test_tag_filters=%s' %\n      ','.join(test_and_build_filters + test_only_filters + ['-v1only']))\n  write_to_bazelrc('test:v2 --build_tag_filters=%s' %\n                   ','.join(test_and_build_filters + ['-v1only']))\n\n\ndef set_system_libs_flag(environ_cp):\n  \"\"\"Set system libs flags.\"\"\"\n  syslibs = environ_cp.get('TF_SYSTEM_LIBS', '')\n\n  if is_s390x() and 'boringssl' not in syslibs:\n    syslibs = 'boringssl' + (', ' + syslibs if syslibs else '')\n\n  if syslibs:\n    if ',' in syslibs:\n      syslibs = ','.join(sorted(syslibs.split(',')))\n    else:\n      syslibs = ','.join(sorted(syslibs.split()))\n    write_action_env_to_bazelrc('TF_SYSTEM_LIBS', syslibs)\n\n  for varname in ('PREFIX', 'LIBDIR', 'INCLUDEDIR', 'PROTOBUF_INCLUDE_PATH'):\n    if varname in environ_cp:\n      write_to_bazelrc('build --define=%s=%s' % (varname, environ_cp[varname]))\n\n\ndef set_windows_build_flags(environ_cp):\n  \"\"\"Set Windows specific build options.\"\"\"\n\n  # First available in VS 16.4. Speeds up Windows compile times by a lot. See\n  # https://groups.google.com/a/tensorflow.org/d/topic/build/SsW98Eo7l3o/discussion\n  # pylint: disable=line-too-long\n  write_to_bazelrc(\n      'build --copt=/d2ReducedOptimizeHugeFunctions --host_copt=/d2ReducedOptimizeHugeFunctions'\n  )\n\n  if get_var(\n      environ_cp, 'TF_OVERRIDE_EIGEN_STRONG_INLINE', 'Eigen strong inline',\n      True, ('Would you like to override eigen strong inline for some C++ '\n             'compilation to reduce the compilation time?'),\n      'Eigen strong inline overridden.', 'Not overriding eigen strong inline, '\n      'some compilations could take more than 20 mins.'):\n    # Due to a known MSVC compiler issue\n    # https://github.com/tensorflow/tensorflow/issues/10521\n    # Overriding eigen strong inline speeds up the compiling of\n    # conv_grad_ops_3d.cc and conv_ops_3d.cc by 20 minutes,\n    # but this also hurts the performance. Let users decide what they want.\n    write_to_bazelrc('build --define=override_eigen_strong_inline=true')\n\n\ndef config_info_line(name, help_text):\n  \"\"\"Helper function to print formatted help text for Bazel config options.\"\"\"\n  print('\\t--config=%-12s\\t# %s' % (name, help_text))\n\n\ndef configure_ios(environ_cp):\n  \"\"\"Configures TensorFlow for iOS builds.\"\"\"\n  if not is_macos():\n    return\n  if not get_var(environ_cp, 'TF_CONFIGURE_IOS', 'iOS', False):\n    return\n  for filepath in APPLE_BAZEL_FILES:\n    existing_filepath = os.path.join(_TF_WORKSPACE_ROOT, filepath + '.apple')\n    renamed_filepath = os.path.join(_TF_WORKSPACE_ROOT, filepath)\n    symlink_force(existing_filepath, renamed_filepath)\n  for filepath in IOS_FILES:\n    filename = os.path.basename(filepath)\n    new_filepath = os.path.join(_TF_WORKSPACE_ROOT, filename)\n    symlink_force(filepath, new_filepath)\n\n\ndef get_gcc_compiler(environ_cp):\n  gcc_env = environ_cp.get('CXX') or environ_cp.get('CC') or shutil.which('gcc')\n  if gcc_env is not None:\n    gcc_version = run_shell([gcc_env, '--version']).split()\n    if gcc_version[0] in ('gcc', 'g++'):\n      return gcc_env\n  return None\n\n\ndef main():\n  global _TF_WORKSPACE_ROOT\n  global _TF_BAZELRC\n  global _TF_CURRENT_BAZEL_VERSION\n\n  parser = argparse.ArgumentParser()\n  parser.add_argument(\n      '--workspace',\n      type=str,\n      default=os.path.abspath(os.path.dirname(__file__)),\n      help='The absolute path to your active Bazel workspace.')\n  args = parser.parse_args()\n\n  _TF_WORKSPACE_ROOT = args.workspace\n  _TF_BAZELRC = os.path.join(_TF_WORKSPACE_ROOT, _TF_BAZELRC_FILENAME)\n\n  # Make a copy of os.environ to be clear when functions and getting and setting\n  # environment variables.\n  environ_cp = dict(os.environ)\n\n  try:\n    current_bazel_version = retrieve_bazel_version()\n  except subprocess.CalledProcessError as e:\n    print('Error retrieving bazel version: ', e.output.decode('UTF-8').strip())\n    raise e\n\n  _TF_CURRENT_BAZEL_VERSION = convert_version_to_int(current_bazel_version)\n\n  reset_tf_configure_bazelrc()\n\n  cleanup_makefile()\n  setup_python(environ_cp)\n\n  if is_windows():\n    environ_cp['TF_NEED_OPENCL'] = '0'\n    environ_cp['TF_CUDA_CLANG'] = '0'\n    # TODO(ibiryukov): Investigate using clang as a cpu or cuda compiler on\n    # Windows.\n    environ_cp['TF_DOWNLOAD_CLANG'] = '0'\n    environ_cp['TF_NEED_MPI'] = '0'\n\n  if is_ppc64le():\n    # Enable MMA Dynamic Dispatch support if 'gcc' and if linker >= 2.35\n    gcc_env = get_gcc_compiler(environ_cp)\n    if gcc_env is not None:\n\n      # Use gold linker if 'gcc' and if 'ppc64le'\n      write_to_bazelrc('build --linkopt=\"-fuse-ld=gold\"')\n\n      # Get the linker version\n      ld_version = run_shell([gcc_env, '-Wl,-version']).split()\n\n      ld_version_int = 0\n      for i in range(len(ld_version)):\n        ld_version_int = convert_version_to_int(ld_version[i])\n        if ld_version_int is not None:\n          break\n\n      if ld_version_int is None:\n        ld_version_int = 0\n\n      # Enable if 'ld' version >= 2.35\n      if ld_version_int >= 2035000:\n        write_to_bazelrc(\n            'build --copt=\"-DEIGEN_ALTIVEC_ENABLE_MMA_DYNAMIC_DISPATCH=1\"')\n\n  with_xla_support = environ_cp.get('TF_ENABLE_XLA', None)\n  if with_xla_support is not None:\n    write_to_bazelrc('build --define=with_xla_support=%s' %\n                     ('true' if int(with_xla_support) else 'false'))\n\n  set_action_env_var(\n      environ_cp, 'TF_NEED_ROCM', 'ROCm', False, bazel_config_name='rocm')\n  if (environ_cp.get('TF_NEED_ROCM') == '1' and\n      'LD_LIBRARY_PATH' in environ_cp and\n      environ_cp.get('LD_LIBRARY_PATH') != '1'):\n    write_action_env_to_bazelrc('LD_LIBRARY_PATH',\n                                environ_cp.get('LD_LIBRARY_PATH'))\n\n  if (environ_cp.get('TF_NEED_ROCM') == '1' and environ_cp.get('ROCM_PATH')):\n    write_action_env_to_bazelrc('ROCM_PATH', environ_cp.get('ROCM_PATH'))\n\n  if (environ_cp.get('TF_NEED_ROCM') == '1' and environ_cp.get('HIP_PLATFORM')):\n    write_action_env_to_bazelrc('HIP_PLATFORM', environ_cp.get('HIP_PLATFORM'))\n\n  if is_windows():\n    print('\\nWARNING: Cannot build with CUDA support on Windows.\\n'\n          'Starting in TF 2.11, CUDA build is not supported for Windows. '\n          'For using TensorFlow GPU on Windows, you will need to build/install '\n          'TensorFlow in WSL2.\\n')\n    environ_cp['TF_NEED_CUDA'] = '0'\n  else:\n    environ_cp['TF_NEED_CUDA'] = str(\n        int(get_var(environ_cp, 'TF_NEED_CUDA', 'CUDA', False)))\n  if environ_cp.get('TF_NEED_CUDA') == '1':\n    set_hermetic_cuda_version(environ_cp)\n    set_hermetic_cudnn_version(environ_cp)\n    set_hermetic_cuda_compute_capabilities(environ_cp)\n    set_cuda_local_path(environ_cp, 'CUDA', 'LOCAL_CUDA_PATH')\n    set_cuda_local_path(environ_cp, 'CUDNN', 'LOCAL_CUDNN_PATH')\n    set_cuda_local_path(environ_cp, 'NCCL', 'LOCAL_NCCL_PATH')\n\n    if 'LD_LIBRARY_PATH' in environ_cp and environ_cp.get(\n        'LD_LIBRARY_PATH') != '1':\n      write_action_env_to_bazelrc('LD_LIBRARY_PATH',\n                                  environ_cp.get('LD_LIBRARY_PATH'))\n\n    set_tf_cuda_clang(environ_cp)\n    if environ_cp.get('TF_CUDA_CLANG') == '1':\n      # Set up which clang we should use as the cuda / host compiler.\n      clang_cuda_compiler_path = set_clang_cuda_compiler_path(environ_cp)\n      clang_version = retrieve_clang_version(clang_cuda_compiler_path)\n      disable_clang_offsetof_extension(clang_version)\n    else:\n      # Set up which gcc nvcc should use as the host compiler\n      # No need to set this on Windows\n      if not is_windows():\n        set_gcc_host_compiler_path(environ_cp)\n    set_other_cuda_vars(environ_cp)\n  else:\n    # CUDA not required. Ask whether we should use clang for the CPU build.\n    if is_linux():\n      environ_cp['TF_NEED_CLANG'] = str(choose_compiler(environ_cp))\n      if environ_cp.get('TF_NEED_CLANG') == '1':\n        clang_compiler_path = set_clang_compiler_path(environ_cp)\n        clang_version = retrieve_clang_version(clang_compiler_path)\n        disable_clang_offsetof_extension(clang_version)\n    if is_windows():\n      environ_cp['TF_NEED_CLANG'] = str(choose_compiler_Win(environ_cp))\n      if environ_cp.get('TF_NEED_CLANG') == '1':\n        clang_compiler_path = set_clang_compiler_path_win(environ_cp)\n        clang_version = retrieve_clang_version(clang_compiler_path)\n        disable_clang_offsetof_extension(clang_version)\n\n  # ROCm / CUDA are mutually exclusive.\n  # At most 1 GPU platform can be configured.\n  gpu_platform_count = 0\n  if environ_cp.get('TF_NEED_ROCM') == '1':\n    gpu_platform_count += 1\n  if environ_cp.get('TF_NEED_CUDA') == '1':\n    gpu_platform_count += 1\n  if gpu_platform_count >= 2:\n    raise UserInputError('CUDA / ROCm are mututally exclusive. '\n                         'At most 1 GPU platform can be configured.')\n\n  set_cc_opt_flags(environ_cp)\n  set_system_libs_flag(environ_cp)\n  if is_windows():\n    set_windows_build_flags(environ_cp)\n\n  if get_var(environ_cp, 'TF_SET_ANDROID_WORKSPACE', 'android workspace', False,\n             ('Would you like to interactively configure ./WORKSPACE for '\n              'Android builds?'), 'Searching for NDK and SDK installations.',\n             'Not configuring the WORKSPACE for Android builds.'):\n    create_android_ndk_rule(environ_cp)\n    create_android_sdk_rule(environ_cp)\n\n  system_specific_test_config(environ_cp)\n\n  configure_ios(environ_cp)\n\n  print('Preconfigured Bazel build configs. You can use any of the below by '\n        'adding \"--config=<>\" to your build command. See .bazelrc for more '\n        'details.')\n  config_info_line('mkl', 'Build with MKL support.')\n  config_info_line(\n      'mkl_aarch64',\n      'Build with oneDNN and Compute Library for the Arm Architecture (ACL).')\n  config_info_line('monolithic', 'Config for mostly static monolithic build.')\n  config_info_line('numa', 'Build with NUMA support.')\n  config_info_line(\n      'dynamic_kernels',\n      '(Experimental) Build kernels into separate shared objects.')\n  config_info_line('v1', 'Build with TensorFlow 1 API instead of TF 2 API.')\n\n  print('Preconfigured Bazel build configs to DISABLE default on features:')\n  config_info_line('nogcp', 'Disable GCP support.')\n  config_info_line('nonccl', 'Disable NVIDIA NCCL support.')\n\n\nif __name__ == '__main__':\n  main()\n"
        },
        {
          "name": "models.BUILD",
          "type": "blob",
          "size": 0.3203125,
          "content": "package(default_visibility = [\"//visibility:public\"])\n\nlicenses([\"notice\"])  # Apache 2.0\n\nfilegroup(\n    name = \"model_files\",\n    srcs = glob(\n        [\n            \"**/*\",\n        ],\n        exclude = [\n            \"**/BUILD\",\n            \"**/WORKSPACE\",\n            \"**/LICENSE\",\n            \"**/*.zip\",\n        ],\n    ),\n)\n"
        },
        {
          "name": "requirements_lock_3_10.txt",
          "type": "blob",
          "size": 52.8359375,
          "content": "#\n# This file is autogenerated by pip-compile with Python 3.10\n# by the following command:\n#\n#    bazel run //ci/official/requirements_updater:requirements.update\n#\nabsl-py==2.1.0 \\\n    --hash=sha256:526a04eadab8b4ee719ce68f204172ead1027549089702d99b9059f129ff1308 \\\n    --hash=sha256:7820790efbb316739cde8b4e19357243fc3608a152024288513dd968d7d959ff\n    # via\n    #   keras-nightly\n    #   tb-nightly\nastor==0.7.1 \\\n    --hash=sha256:95c30d87a6c2cf89aa628b87398466840f0ad8652f88eb173125a6df8533fb8d \\\n    --hash=sha256:fb503b9e2fdd05609fbf557b916b4a7824171203701660f0c55bbf5a7a68713e\n    # via -r ci/official/requirements_updater/requirements.in\nastunparse==1.6.3 \\\n    --hash=sha256:5ad93a8456f0d084c3456d059fd9a92cce667963232cbf763eac3bc5b7940872 \\\n    --hash=sha256:c2652417f2c8b5bb325c885ae329bdf3f86424075c4fd1a128674bc6fba4b8e8\n    # via -r ci/official/requirements_updater/requirements.in\nauditwheel==6.1.0 \\\n    --hash=sha256:3bdc686e774cf9e355e924b0fe5a562d55caa385d72234ffe7b81b378dba360f \\\n    --hash=sha256:e52f734861859e3743eb29fcac7da9c4921a1e4bea58f954b52f2926f8e9e364\n    # via -r ci/official/requirements_updater/requirements.in\ncertifi==2024.7.4 \\\n    --hash=sha256:5a1e7645bc0ec61a09e26c36f6106dd4cf40c6db3a1fb6352b0244e7fb057c7b \\\n    --hash=sha256:c198e21b1289c2ab85ee4e67bb4b4ef3ead0892059901a8d5b622f24a1101e90\n    # via requests\ncharset-normalizer==3.3.2 \\\n    --hash=sha256:06435b539f889b1f6f4ac1758871aae42dc3a8c0e24ac9e60c2384973ad73027 \\\n    --hash=sha256:06a81e93cd441c56a9b65d8e1d043daeb97a3d0856d177d5c90ba85acb3db087 \\\n    --hash=sha256:0a55554a2fa0d408816b3b5cedf0045f4b8e1a6065aec45849de2d6f3f8e9786 \\\n    --hash=sha256:0b2b64d2bb6d3fb9112bafa732def486049e63de9618b5843bcdd081d8144cd8 \\\n    --hash=sha256:10955842570876604d404661fbccbc9c7e684caf432c09c715ec38fbae45ae09 \\\n    --hash=sha256:122c7fa62b130ed55f8f285bfd56d5f4b4a5b503609d181f9ad85e55c89f4185 \\\n    --hash=sha256:1ceae2f17a9c33cb48e3263960dc5fc8005351ee19db217e9b1bb15d28c02574 \\\n    --hash=sha256:1d3193f4a680c64b4b6a9115943538edb896edc190f0b222e73761716519268e \\\n    --hash=sha256:1f79682fbe303db92bc2b1136016a38a42e835d932bab5b3b1bfcfbf0640e519 \\\n    --hash=sha256:2127566c664442652f024c837091890cb1942c30937add288223dc895793f898 \\\n    --hash=sha256:22afcb9f253dac0696b5a4be4a1c0f8762f8239e21b99680099abd9b2b1b2269 \\\n    --hash=sha256:25baf083bf6f6b341f4121c2f3c548875ee6f5339300e08be3f2b2ba1721cdd3 \\\n    --hash=sha256:2e81c7b9c8979ce92ed306c249d46894776a909505d8f5a4ba55b14206e3222f \\\n    --hash=sha256:3287761bc4ee9e33561a7e058c72ac0938c4f57fe49a09eae428fd88aafe7bb6 \\\n    --hash=sha256:34d1c8da1e78d2e001f363791c98a272bb734000fcef47a491c1e3b0505657a8 \\\n    --hash=sha256:37e55c8e51c236f95b033f6fb391d7d7970ba5fe7ff453dad675e88cf303377a \\\n    --hash=sha256:3d47fa203a7bd9c5b6cee4736ee84ca03b8ef23193c0d1ca99b5089f72645c73 \\\n    --hash=sha256:3e4d1f6587322d2788836a99c69062fbb091331ec940e02d12d179c1d53e25fc \\\n    --hash=sha256:42cb296636fcc8b0644486d15c12376cb9fa75443e00fb25de0b8602e64c1714 \\\n    --hash=sha256:45485e01ff4d3630ec0d9617310448a8702f70e9c01906b0d0118bdf9d124cf2 \\\n    --hash=sha256:4a78b2b446bd7c934f5dcedc588903fb2f5eec172f3d29e52a9096a43722adfc \\\n    --hash=sha256:4ab2fe47fae9e0f9dee8c04187ce5d09f48eabe611be8259444906793ab7cbce \\\n    --hash=sha256:4d0d1650369165a14e14e1e47b372cfcb31d6ab44e6e33cb2d4e57265290044d \\\n    --hash=sha256:549a3a73da901d5bc3ce8d24e0600d1fa85524c10287f6004fbab87672bf3e1e \\\n    --hash=sha256:55086ee1064215781fff39a1af09518bc9255b50d6333f2e4c74ca09fac6a8f6 \\\n    --hash=sha256:572c3763a264ba47b3cf708a44ce965d98555f618ca42c926a9c1616d8f34269 \\\n    --hash=sha256:573f6eac48f4769d667c4442081b1794f52919e7edada77495aaed9236d13a96 \\\n    --hash=sha256:5b4c145409bef602a690e7cfad0a15a55c13320ff7a3ad7ca59c13bb8ba4d45d \\\n    --hash=sha256:6463effa3186ea09411d50efc7d85360b38d5f09b870c48e4600f63af490e56a \\\n    --hash=sha256:65f6f63034100ead094b8744b3b97965785388f308a64cf8d7c34f2f2e5be0c4 \\\n    --hash=sha256:663946639d296df6a2bb2aa51b60a2454ca1cb29835324c640dafb5ff2131a77 \\\n    --hash=sha256:6897af51655e3691ff853668779c7bad41579facacf5fd7253b0133308cf000d \\\n    --hash=sha256:68d1f8a9e9e37c1223b656399be5d6b448dea850bed7d0f87a8311f1ff3dabb0 \\\n    --hash=sha256:6ac7ffc7ad6d040517be39eb591cac5ff87416c2537df6ba3cba3bae290c0fed \\\n    --hash=sha256:6b3251890fff30ee142c44144871185dbe13b11bab478a88887a639655be1068 \\\n    --hash=sha256:6c4caeef8fa63d06bd437cd4bdcf3ffefe6738fb1b25951440d80dc7df8c03ac \\\n    --hash=sha256:6ef1d82a3af9d3eecdba2321dc1b3c238245d890843e040e41e470ffa64c3e25 \\\n    --hash=sha256:753f10e867343b4511128c6ed8c82f7bec3bd026875576dfd88483c5c73b2fd8 \\\n    --hash=sha256:7cd13a2e3ddeed6913a65e66e94b51d80a041145a026c27e6bb76c31a853c6ab \\\n    --hash=sha256:7ed9e526742851e8d5cc9e6cf41427dfc6068d4f5a3bb03659444b4cabf6bc26 \\\n    --hash=sha256:7f04c839ed0b6b98b1a7501a002144b76c18fb1c1850c8b98d458ac269e26ed2 \\\n    --hash=sha256:802fe99cca7457642125a8a88a084cef28ff0cf9407060f7b93dca5aa25480db \\\n    --hash=sha256:80402cd6ee291dcb72644d6eac93785fe2c8b9cb30893c1af5b8fdd753b9d40f \\\n    --hash=sha256:8465322196c8b4d7ab6d1e049e4c5cb460d0394da4a27d23cc242fbf0034b6b5 \\\n    --hash=sha256:86216b5cee4b06df986d214f664305142d9c76df9b6512be2738aa72a2048f99 \\\n    --hash=sha256:87d1351268731db79e0f8e745d92493ee2841c974128ef629dc518b937d9194c \\\n    --hash=sha256:8bdb58ff7ba23002a4c5808d608e4e6c687175724f54a5dade5fa8c67b604e4d \\\n    --hash=sha256:8c622a5fe39a48f78944a87d4fb8a53ee07344641b0562c540d840748571b811 \\\n    --hash=sha256:8d756e44e94489e49571086ef83b2bb8ce311e730092d2c34ca8f7d925cb20aa \\\n    --hash=sha256:8f4a014bc36d3c57402e2977dada34f9c12300af536839dc38c0beab8878f38a \\\n    --hash=sha256:9063e24fdb1e498ab71cb7419e24622516c4a04476b17a2dab57e8baa30d6e03 \\\n    --hash=sha256:90d558489962fd4918143277a773316e56c72da56ec7aa3dc3dbbe20fdfed15b \\\n    --hash=sha256:923c0c831b7cfcb071580d3f46c4baf50f174be571576556269530f4bbd79d04 \\\n    --hash=sha256:95f2a5796329323b8f0512e09dbb7a1860c46a39da62ecb2324f116fa8fdc85c \\\n    --hash=sha256:96b02a3dc4381e5494fad39be677abcb5e6634bf7b4fa83a6dd3112607547001 \\\n    --hash=sha256:9f96df6923e21816da7e0ad3fd47dd8f94b2a5ce594e00677c0013018b813458 \\\n    --hash=sha256:a10af20b82360ab00827f916a6058451b723b4e65030c5a18577c8b2de5b3389 \\\n    --hash=sha256:a50aebfa173e157099939b17f18600f72f84eed3049e743b68ad15bd69b6bf99 \\\n    --hash=sha256:a981a536974bbc7a512cf44ed14938cf01030a99e9b3a06dd59578882f06f985 \\\n    --hash=sha256:a9a8e9031d613fd2009c182b69c7b2c1ef8239a0efb1df3f7c8da66d5dd3d537 \\\n    --hash=sha256:ae5f4161f18c61806f411a13b0310bea87f987c7d2ecdbdaad0e94eb2e404238 \\\n    --hash=sha256:aed38f6e4fb3f5d6bf81bfa990a07806be9d83cf7bacef998ab1a9bd660a581f \\\n    --hash=sha256:b01b88d45a6fcb69667cd6d2f7a9aeb4bf53760d7fc536bf679ec94fe9f3ff3d \\\n    --hash=sha256:b261ccdec7821281dade748d088bb6e9b69e6d15b30652b74cbbac25e280b796 \\\n    --hash=sha256:b2b0a0c0517616b6869869f8c581d4eb2dd83a4d79e0ebcb7d373ef9956aeb0a \\\n    --hash=sha256:b4a23f61ce87adf89be746c8a8974fe1c823c891d8f86eb218bb957c924bb143 \\\n    --hash=sha256:bd8f7df7d12c2db9fab40bdd87a7c09b1530128315d047a086fa3ae3435cb3a8 \\\n    --hash=sha256:beb58fe5cdb101e3a055192ac291b7a21e3b7ef4f67fa1d74e331a7f2124341c \\\n    --hash=sha256:c002b4ffc0be611f0d9da932eb0f704fe2602a9a949d1f738e4c34c75b0863d5 \\\n    --hash=sha256:c083af607d2515612056a31f0a8d9e0fcb5876b7bfc0abad3ecd275bc4ebc2d5 \\\n    --hash=sha256:c180f51afb394e165eafe4ac2936a14bee3eb10debc9d9e4db8958fe36afe711 \\\n    --hash=sha256:c235ebd9baae02f1b77bcea61bce332cb4331dc3617d254df3323aa01ab47bd4 \\\n    --hash=sha256:cd70574b12bb8a4d2aaa0094515df2463cb429d8536cfb6c7ce983246983e5a6 \\\n    --hash=sha256:d0eccceffcb53201b5bfebb52600a5fb483a20b61da9dbc885f8b103cbe7598c \\\n    --hash=sha256:d965bba47ddeec8cd560687584e88cf699fd28f192ceb452d1d7ee807c5597b7 \\\n    --hash=sha256:db364eca23f876da6f9e16c9da0df51aa4f104a972735574842618b8c6d999d4 \\\n    --hash=sha256:ddbb2551d7e0102e7252db79ba445cdab71b26640817ab1e3e3648dad515003b \\\n    --hash=sha256:deb6be0ac38ece9ba87dea880e438f25ca3eddfac8b002a2ec3d9183a454e8ae \\\n    --hash=sha256:e06ed3eb3218bc64786f7db41917d4e686cc4856944f53d5bdf83a6884432e12 \\\n    --hash=sha256:e27ad930a842b4c5eb8ac0016b0a54f5aebbe679340c26101df33424142c143c \\\n    --hash=sha256:e537484df0d8f426ce2afb2d0f8e1c3d0b114b83f8850e5f2fbea0e797bd82ae \\\n    --hash=sha256:eb00ed941194665c332bf8e078baf037d6c35d7c4f3102ea2d4f16ca94a26dc8 \\\n    --hash=sha256:eb6904c354526e758fda7167b33005998fb68c46fbc10e013ca97f21ca5c8887 \\\n    --hash=sha256:eb8821e09e916165e160797a6c17edda0679379a4be5c716c260e836e122f54b \\\n    --hash=sha256:efcb3f6676480691518c177e3b465bcddf57cea040302f9f4e6e191af91174d4 \\\n    --hash=sha256:f27273b60488abe721a075bcca6d7f3964f9f6f067c8c4c605743023d7d3944f \\\n    --hash=sha256:f30c3cb33b24454a82faecaf01b19c18562b1e89558fb6c56de4d9118a032fd5 \\\n    --hash=sha256:fb69256e180cb6c8a894fee62b3afebae785babc1ee98b81cdf68bbca1987f33 \\\n    --hash=sha256:fd1abc0d89e30cc4e02e4064dc67fcc51bd941eb395c502aac3ec19fab46b519 \\\n    --hash=sha256:ff8fa367d09b717b2a17a052544193ad76cd49979c805768879cb63d9ca50561\n    # via requests\ndill==0.3.7 \\\n    --hash=sha256:76b122c08ef4ce2eedcd4d1abd8e641114bfc6c2867f49f3c41facf65bf19f5e \\\n    --hash=sha256:cc1c8b182eb3013e24bd475ff2e9295af86c1a38eb1aff128dac8962a9ce3c03\n    # via -r ci/official/requirements_updater/requirements.in\ndm-tree==0.1.8 \\\n    --hash=sha256:054b461f8176f4bce7a21f7b1870f873a1ced3bdbe1282c816c550bb43c71fa6 \\\n    --hash=sha256:09964470f76a5201aff2e8f9b26842976de7889300676f927930f6285e256760 \\\n    --hash=sha256:0d3172394079a86c3a759179c65f64c48d1a42b89495fcf38976d11cc3bb952c \\\n    --hash=sha256:0e9620ccf06393eb6b613b5e366469304622d4ea96ae6540b28a33840e6c89cf \\\n    --hash=sha256:0fcaabbb14e7980377439e7140bd05552739ca5e515ecb3119f234acee4b9430 \\\n    --hash=sha256:1607ce49aa42f010d1e5e616d92ce899d66835d4d8bea49679582435285515de \\\n    --hash=sha256:181c35521d480d0365f39300542cb6cd7fd2b77351bb43d7acfda15aef63b317 \\\n    --hash=sha256:1d7c26e431fc93cc7e0cba867eb000db6a05f6f2b25af11ac4e9dada88fc5bca \\\n    --hash=sha256:1fe962015b2fe1282892b28ebe962faed53c7f98d942da9a4625cbf27baef913 \\\n    --hash=sha256:250b692fb75f45f02e2f58fbef9ab338904ef334b90557565621fa251df267cf \\\n    --hash=sha256:2869228d9c619074de501a3c10dc7f07c75422f8fab36ecdcb859b6f1b1ec3ef \\\n    --hash=sha256:28c52cbf4f8b3dbd0beaedf44f69fa85eec5e9dede612e08035e06ada6ec9426 \\\n    --hash=sha256:2f7915660f59c09068e428613c480150180df1060561fd0d1470684ae7007bd1 \\\n    --hash=sha256:343a4a4ebaa127451ff971254a4be4084eb4bdc0b2513c32b46f6f728fd03f9e \\\n    --hash=sha256:35cc164a79336bfcfafb47e5f297898359123bbd3330c1967f0c4994f9cf9f60 \\\n    --hash=sha256:378cc8ad93c5fe3590f405a309980721f021c790ca1bdf9b15bb1d59daec57f5 \\\n    --hash=sha256:39070ba268c0491af9fe7a58644d99e8b4f2cde6e5884ba3380bddc84ed43d5f \\\n    --hash=sha256:435227cf3c5dc63f4de054cf3d00183790bd9ead4c3623138c74dde7f67f521b \\\n    --hash=sha256:5483dca4d7eb1a0d65fe86d3b6a53ae717face83c1f17e0887b1a4a64ae5c410 \\\n    --hash=sha256:694c3654cfd2a81552c08ec66bb5c4a3d48fa292b9a181880fb081c36c5b9134 \\\n    --hash=sha256:75c5d528bb992981c20793b6b453e91560784215dffb8a5440ba999753c14ceb \\\n    --hash=sha256:803bfc53b4659f447ac694dbd04235f94a73ef7c1fd1e0df7c84ac41e0bc963b \\\n    --hash=sha256:81fce77f22a302d7a5968aebdf4efafef4def7ce96528719a354e6990dcd49c7 \\\n    --hash=sha256:83b7764de0d855338abefc6e3ee9fe40d301668310aa3baea3f778ff051f4393 \\\n    --hash=sha256:8c60a7eadab64c2278861f56bca320b2720f163dca9d7558103c3b77f2416571 \\\n    --hash=sha256:8ed3564abed97c806db122c2d3e1a2b64c74a63debe9903aad795167cc301368 \\\n    --hash=sha256:94d3f0826311f45ee19b75f5b48c99466e4218a0489e81c0f0167bda50cacf22 \\\n    --hash=sha256:96a548a406a6fb15fe58f6a30a57ff2f2aafbf25f05afab00c8f5e5977b6c715 \\\n    --hash=sha256:a5d819c38c03f0bb5b3b3703c60e4b170355a0fc6b5819325bf3d4ceb3ae7e80 \\\n    --hash=sha256:ad16ceba90a56ec47cf45b21856d14962ac314787975ef786efb5e6e9ca75ec7 \\\n    --hash=sha256:af4b3d372f2477dcd89a6e717e4a575ca35ccc20cc4454a8a4b6f8838a00672d \\\n    --hash=sha256:b095ba4f8ca1ba19350fd53cf1f8f3eb0bd406aa28af64a6dfc86707b32a810a \\\n    --hash=sha256:b9bd9b9ccb59409d33d51d84b7668010c04c2af7d4a371632874c1ca356cff3d \\\n    --hash=sha256:b9f89a454e98806b44fe9d40ec9eee61f848388f7e79ac2371a55679bd5a3ac6 \\\n    --hash=sha256:bb2d109f42190225112da899b9f3d46d0d5f26aef501c61e43529fe9322530b5 \\\n    --hash=sha256:c0a94aba18a35457a1b5cd716fd7b46c5dafdc4cf7869b4bae665b91c4682a8e \\\n    --hash=sha256:c5c8c12e3fda754ef6af94161bacdaeda816d941995fac415d6855c6c386af68 \\\n    --hash=sha256:d1612fcaecd79023dbc6a6ae48d51a80beb5c385d6f3f6d71688e57bc8d07de8 \\\n    --hash=sha256:d16e1f2a073604cfcc09f7131ae8d534674f43c3aef4c25742eae295bc60d04f \\\n    --hash=sha256:d20f2faa3672b52e5013f4077117bfb99c4cfc0b445d3bde1584c34032b57436 \\\n    --hash=sha256:d40fa4106ca6edc66760246a08f500ec0c85ef55c762fb4a363f6ee739ba02ee \\\n    --hash=sha256:de287fabc464b8734be251e46e06aa9aa1001f34198da2b6ce07bd197172b9cb \\\n    --hash=sha256:e4d714371bb08839e4e5e29024fc95832d9affe129825ef38836b143028bd144 \\\n    --hash=sha256:ea9e59e0451e7d29aece402d9f908f2e2a80922bcde2ebfd5dcb07750fcbfee8 \\\n    --hash=sha256:f7ac31b9aecccb2c6e1ab29706f6ded3eba0c2c69c770322c9c685929c3d6afb \\\n    --hash=sha256:fa42a605d099ee7d41ba2b5fb75e21423951fd26e5d50583a00471238fb3021d\n    # via keras-nightly\nflatbuffers==24.3.25 \\\n    --hash=sha256:8dbdec58f935f3765e4f7f3cf635ac3a77f83568138d6a2311f524ec96364812 \\\n    --hash=sha256:de2ec5b203f21441716617f38443e0a8ebf3d25bf0d9c0bb0ce68fa00ad546a4\n    # via -r ci/official/requirements_updater/requirements.in\ngast==0.4.0 \\\n    --hash=sha256:40feb7b8b8434785585ab224d1568b857edb18297e5a3047f1ba012bc83b42c1 \\\n    --hash=sha256:b7adcdd5adbebf1adf17378da5ba3f543684dbec47b1cda1f3997e573cd542c4\n    # via -r ci/official/requirements_updater/requirements.in\ngoogle-pasta==0.2.0 \\\n    --hash=sha256:4612951da876b1a10fe3960d7226f0c7682cf901e16ac06e473b267a5afa8954 \\\n    --hash=sha256:b32482794a366b5366a32c92a9a9201b107821889935a02b3e51f6b432ea84ed \\\n    --hash=sha256:c9f2c8dfc8f96d0d5808299920721be30c9eec37f2389f28904f454565c8a16e\n    # via -r ci/official/requirements_updater/requirements.in\ngrpcio==1.64.1 \\\n    --hash=sha256:03b43d0ccf99c557ec671c7dede64f023c7da9bb632ac65dbc57f166e4970040 \\\n    --hash=sha256:0a12ddb1678ebc6a84ec6b0487feac020ee2b1659cbe69b80f06dbffdb249122 \\\n    --hash=sha256:0a2813093ddb27418a4c99f9b1c223fab0b053157176a64cc9db0f4557b69bd9 \\\n    --hash=sha256:0cc79c982ccb2feec8aad0e8fb0d168bcbca85bc77b080d0d3c5f2f15c24ea8f \\\n    --hash=sha256:1257b76748612aca0f89beec7fa0615727fd6f2a1ad580a9638816a4b2eb18fd \\\n    --hash=sha256:1262402af5a511c245c3ae918167eca57342c72320dffae5d9b51840c4b2f86d \\\n    --hash=sha256:19264fc964576ddb065368cae953f8d0514ecc6cb3da8903766d9fb9d4554c33 \\\n    --hash=sha256:198908f9b22e2672a998870355e226a725aeab327ac4e6ff3a1399792ece4762 \\\n    --hash=sha256:1de403fc1305fd96cfa75e83be3dee8538f2413a6b1685b8452301c7ba33c294 \\\n    --hash=sha256:20405cb8b13fd779135df23fabadc53b86522d0f1cba8cca0e87968587f50650 \\\n    --hash=sha256:2981c7365a9353f9b5c864595c510c983251b1ab403e05b1ccc70a3d9541a73b \\\n    --hash=sha256:2c3c1b90ab93fed424e454e93c0ed0b9d552bdf1b0929712b094f5ecfe7a23ad \\\n    --hash=sha256:39b9d0acaa8d835a6566c640f48b50054f422d03e77e49716d4c4e8e279665a1 \\\n    --hash=sha256:3b64ae304c175671efdaa7ec9ae2cc36996b681eb63ca39c464958396697daff \\\n    --hash=sha256:4657d24c8063e6095f850b68f2d1ba3b39f2b287a38242dcabc166453e950c59 \\\n    --hash=sha256:4d6dab6124225496010bd22690f2d9bd35c7cbb267b3f14e7a3eb05c911325d4 \\\n    --hash=sha256:55260032b95c49bee69a423c2f5365baa9369d2f7d233e933564d8a47b893027 \\\n    --hash=sha256:55697ecec192bc3f2f3cc13a295ab670f51de29884ca9ae6cd6247df55df2502 \\\n    --hash=sha256:5841dd1f284bd1b3d8a6eca3a7f062b06f1eec09b184397e1d1d43447e89a7ae \\\n    --hash=sha256:58b1041e7c870bb30ee41d3090cbd6f0851f30ae4eb68228955d973d3efa2e61 \\\n    --hash=sha256:5e42634a989c3aa6049f132266faf6b949ec2a6f7d302dbb5c15395b77d757eb \\\n    --hash=sha256:5e56462b05a6f860b72f0fa50dca06d5b26543a4e88d0396259a07dc30f4e5aa \\\n    --hash=sha256:5f8b75f64d5d324c565b263c67dbe4f0af595635bbdd93bb1a88189fc62ed2e5 \\\n    --hash=sha256:62b4e6eb7bf901719fce0ca83e3ed474ae5022bb3827b0a501e056458c51c0a1 \\\n    --hash=sha256:6503b64c8b2dfad299749cad1b595c650c91e5b2c8a1b775380fcf8d2cbba1e9 \\\n    --hash=sha256:6c024ffc22d6dc59000faf8ad781696d81e8e38f4078cb0f2630b4a3cf231a90 \\\n    --hash=sha256:73819689c169417a4f978e562d24f2def2be75739c4bed1992435d007819da1b \\\n    --hash=sha256:75dbbf415026d2862192fe1b28d71f209e2fd87079d98470db90bebe57b33179 \\\n    --hash=sha256:8caee47e970b92b3dd948371230fcceb80d3f2277b3bf7fbd7c0564e7d39068e \\\n    --hash=sha256:8d51dd1c59d5fa0f34266b80a3805ec29a1f26425c2a54736133f6d87fc4968a \\\n    --hash=sha256:940e3ec884520155f68a3b712d045e077d61c520a195d1a5932c531f11883489 \\\n    --hash=sha256:a011ac6c03cfe162ff2b727bcb530567826cec85eb8d4ad2bfb4bd023287a52d \\\n    --hash=sha256:a3a035c37ce7565b8f4f35ff683a4db34d24e53dc487e47438e434eb3f701b2a \\\n    --hash=sha256:a5e771d0252e871ce194d0fdcafd13971f1aae0ddacc5f25615030d5df55c3a2 \\\n    --hash=sha256:ac15b6c2c80a4d1338b04d42a02d376a53395ddf0ec9ab157cbaf44191f3ffdd \\\n    --hash=sha256:b1a82e0b9b3022799c336e1fc0f6210adc019ae84efb7321d668129d28ee1efb \\\n    --hash=sha256:bac71b4b28bc9af61efcdc7630b166440bbfbaa80940c9a697271b5e1dabbc61 \\\n    --hash=sha256:bbc5b1d78a7822b0a84c6f8917faa986c1a744e65d762ef6d8be9d75677af2ca \\\n    --hash=sha256:c1a786ac592b47573a5bb7e35665c08064a5d77ab88a076eec11f8ae86b3e3f6 \\\n    --hash=sha256:c84ad903d0d94311a2b7eea608da163dace97c5fe9412ea311e72c3684925602 \\\n    --hash=sha256:d4d29cc612e1332237877dfa7fe687157973aab1d63bd0f84cf06692f04c0367 \\\n    --hash=sha256:e3d9f8d1221baa0ced7ec7322a981e28deb23749c76eeeb3d33e18b72935ab62 \\\n    --hash=sha256:e7cd5c1325f6808b8ae31657d281aadb2a51ac11ab081ae335f4f7fc44c1721d \\\n    --hash=sha256:ed6091fa0adcc7e4ff944090cf203a52da35c37a130efa564ded02b7aff63bcd \\\n    --hash=sha256:ee73a2f5ca4ba44fa33b4d7d2c71e2c8a9e9f78d53f6507ad68e7d2ad5f64a22 \\\n    --hash=sha256:f10193c69fc9d3d726e83bbf0f3d316f1847c3071c8c93d8090cf5f326b14309\n    # via\n    #   -r ci/official/requirements_updater/requirements.in\n    #   tb-nightly\nh5py==3.11.0 \\\n    --hash=sha256:083e0329ae534a264940d6513f47f5ada617da536d8dccbafc3026aefc33c90e \\\n    --hash=sha256:1625fd24ad6cfc9c1ccd44a66dac2396e7ee74940776792772819fc69f3a3731 \\\n    --hash=sha256:21dbdc5343f53b2e25404673c4f00a3335aef25521bd5fa8c707ec3833934892 \\\n    --hash=sha256:52c416f8eb0daae39dabe71415cb531f95dce2d81e1f61a74537a50c63b28ab3 \\\n    --hash=sha256:55106b04e2c83dfb73dc8732e9abad69d83a436b5b82b773481d95d17b9685e1 \\\n    --hash=sha256:67462d0669f8f5459529de179f7771bd697389fcb3faab54d63bf788599a48ea \\\n    --hash=sha256:6c4b760082626120031d7902cd983d8c1f424cdba2809f1067511ef283629d4b \\\n    --hash=sha256:731839240c59ba219d4cb3bc5880d438248533366f102402cfa0621b71796b62 \\\n    --hash=sha256:754c0c2e373d13d6309f408325343b642eb0f40f1a6ad21779cfa9502209e150 \\\n    --hash=sha256:75bd7b3d93fbeee40860fd70cdc88df4464e06b70a5ad9ce1446f5f32eb84007 \\\n    --hash=sha256:77b19a40788e3e362b54af4dcf9e6fde59ca016db2c61360aa30b47c7b7cef00 \\\n    --hash=sha256:7b7e8f78072a2edec87c9836f25f34203fd492a4475709a18b417a33cfb21fa9 \\\n    --hash=sha256:8ec9df3dd2018904c4cc06331951e274f3f3fd091e6d6cc350aaa90fa9b42a76 \\\n    --hash=sha256:a76cae64080210389a571c7d13c94a1a6cf8cb75153044fd1f822a962c97aeab \\\n    --hash=sha256:aa6ae84a14103e8dc19266ef4c3e5d7c00b68f21d07f2966f0ca7bdb6c2761fb \\\n    --hash=sha256:bbd732a08187a9e2a6ecf9e8af713f1d68256ee0f7c8b652a32795670fb481ba \\\n    --hash=sha256:c072655ad1d5fe9ef462445d3e77a8166cbfa5e599045f8aa3c19b75315f10e5 \\\n    --hash=sha256:d9c944d364688f827dc889cf83f1fca311caf4fa50b19f009d1f2b525edd33a3 \\\n    --hash=sha256:ef4e2f338fc763f50a8113890f455e1a70acd42a4d083370ceb80c463d803972 \\\n    --hash=sha256:f3736fe21da2b7d8a13fe8fe415f1272d2a1ccdeff4849c1421d2fb30fd533bc \\\n    --hash=sha256:f4e025e852754ca833401777c25888acb96889ee2c27e7e629a19aee288833f0\n    # via\n    #   -r ci/official/requirements_updater/requirements.in\n    #   keras-nightly\nidna==3.7 \\\n    --hash=sha256:028ff3aadf0609c1fd278d8ea3089299412a7a8b9bd005dd08b9f8285bcb5cfc \\\n    --hash=sha256:82fee1fc78add43492d3a1898bfa6d8a904cc97d8427f683ed8e798d07761aa0\n    # via requests\njax==0.4.7 \\\n    --hash=sha256:5e7002d74db25f97c99b979d4ba1233b1ef26e1597e5fc468ad11d1c8a9dc4f8\n    # via -r ci/official/requirements_updater/requirements.in\nkeras-nightly==3.0.4.dev2024021403 \\\n    --hash=sha256:24ce69d29d582771685bf4235f59663723405b5a5b16f3eaff2657e52e74663a \\\n    --hash=sha256:9f416e66b820ef833779d219d255b346b8b90a72fdbd0b2f1e90a43ad142a03d\n    # via -r ci/official/requirements_updater/requirements.in\nlibclang==18.1.1 \\\n    --hash=sha256:0b2e143f0fac830156feb56f9231ff8338c20aecfe72b4ffe96f19e5a1dbb69a \\\n    --hash=sha256:3f0e1f49f04d3cd198985fea0511576b0aee16f9ff0e0f0cad7f9c57ec3c20e8 \\\n    --hash=sha256:4dd2d3b82fab35e2bf9ca717d7b63ac990a3519c7e312f19fa8e86dcc712f7fb \\\n    --hash=sha256:54dda940a4a0491a9d1532bf071ea3ef26e6dbaf03b5000ed94dd7174e8f9592 \\\n    --hash=sha256:69f8eb8f65c279e765ffd28aaa7e9e364c776c17618af8bff22a8df58677ff4f \\\n    --hash=sha256:6f14c3f194704e5d09769108f03185fce7acaf1d1ae4bbb2f30a72c2400cb7c5 \\\n    --hash=sha256:83ce5045d101b669ac38e6da8e58765f12da2d3aafb3b9b98d88b286a60964d8 \\\n    --hash=sha256:a1214966d08d73d971287fc3ead8dfaf82eb07fb197680d8b3859dbbbbf78250 \\\n    --hash=sha256:c533091d8a3bbf7460a00cb6c1a71da93bffe148f172c7d03b1c31fbf8aa2a0b \\\n    --hash=sha256:cf4a99b05376513717ab5d82a0db832c56ccea4fd61a69dbb7bccf2dfb207dbe\n    # via -r ci/official/requirements_updater/requirements.in\nlit==17.0.6 \\\n    --hash=sha256:dfa9af9b55fc4509a56be7bf2346f079d7f4a242d583b9f2e0b078fd0abae31b\n    # via -r ci/official/requirements_updater/requirements.in\nmarkdown==3.6 \\\n    --hash=sha256:48f276f4d8cfb8ce6527c8f79e2ee29708508bf4d40aa410fbc3b4ee832c850f \\\n    --hash=sha256:ed4f41f6daecbeeb96e576ce414c41d2d876daa9a16cb35fa8ed8c2ddfad0224\n    # via tb-nightly\nmarkdown-it-py==3.0.0 \\\n    --hash=sha256:355216845c60bd96232cd8d8c40e8f9765cc86f46880e43a8fd22dc1a1a8cab1 \\\n    --hash=sha256:e3f60a94fa066dc52ec76661e37c851cb232d92f9886b15cb560aaada2df8feb\n    # via rich\nmarkupsafe==2.1.5 \\\n    --hash=sha256:00e046b6dd71aa03a41079792f8473dc494d564611a8f89bbbd7cb93295ebdcf \\\n    --hash=sha256:075202fa5b72c86ad32dc7d0b56024ebdbcf2048c0ba09f1cde31bfdd57bcfff \\\n    --hash=sha256:0e397ac966fdf721b2c528cf028494e86172b4feba51d65f81ffd65c63798f3f \\\n    --hash=sha256:17b950fccb810b3293638215058e432159d2b71005c74371d784862b7e4683f3 \\\n    --hash=sha256:1f3fbcb7ef1f16e48246f704ab79d79da8a46891e2da03f8783a5b6fa41a9532 \\\n    --hash=sha256:2174c595a0d73a3080ca3257b40096db99799265e1c27cc5a610743acd86d62f \\\n    --hash=sha256:2b7c57a4dfc4f16f7142221afe5ba4e093e09e728ca65c51f5620c9aaeb9a617 \\\n    --hash=sha256:2d2d793e36e230fd32babe143b04cec8a8b3eb8a3122d2aceb4a371e6b09b8df \\\n    --hash=sha256:30b600cf0a7ac9234b2638fbc0fb6158ba5bdcdf46aeb631ead21248b9affbc4 \\\n    --hash=sha256:397081c1a0bfb5124355710fe79478cdbeb39626492b15d399526ae53422b906 \\\n    --hash=sha256:3a57fdd7ce31c7ff06cdfbf31dafa96cc533c21e443d57f5b1ecc6cdc668ec7f \\\n    --hash=sha256:3c6b973f22eb18a789b1460b4b91bf04ae3f0c4234a0a6aa6b0a92f6f7b951d4 \\\n    --hash=sha256:3e53af139f8579a6d5f7b76549125f0d94d7e630761a2111bc431fd820e163b8 \\\n    --hash=sha256:4096e9de5c6fdf43fb4f04c26fb114f61ef0bf2e5604b6ee3019d51b69e8c371 \\\n    --hash=sha256:4275d846e41ecefa46e2015117a9f491e57a71ddd59bbead77e904dc02b1bed2 \\\n    --hash=sha256:4c31f53cdae6ecfa91a77820e8b151dba54ab528ba65dfd235c80b086d68a465 \\\n    --hash=sha256:4f11aa001c540f62c6166c7726f71f7573b52c68c31f014c25cc7901deea0b52 \\\n    --hash=sha256:5049256f536511ee3f7e1b3f87d1d1209d327e818e6ae1365e8653d7e3abb6a6 \\\n    --hash=sha256:58c98fee265677f63a4385256a6d7683ab1832f3ddd1e66fe948d5880c21a169 \\\n    --hash=sha256:598e3276b64aff0e7b3451b72e94fa3c238d452e7ddcd893c3ab324717456bad \\\n    --hash=sha256:5b7b716f97b52c5a14bffdf688f971b2d5ef4029127f1ad7a513973cfd818df2 \\\n    --hash=sha256:5dedb4db619ba5a2787a94d877bc8ffc0566f92a01c0ef214865e54ecc9ee5e0 \\\n    --hash=sha256:619bc166c4f2de5caa5a633b8b7326fbe98e0ccbfacabd87268a2b15ff73a029 \\\n    --hash=sha256:629ddd2ca402ae6dbedfceeba9c46d5f7b2a61d9749597d4307f943ef198fc1f \\\n    --hash=sha256:656f7526c69fac7f600bd1f400991cc282b417d17539a1b228617081106feb4a \\\n    --hash=sha256:6ec585f69cec0aa07d945b20805be741395e28ac1627333b1c5b0105962ffced \\\n    --hash=sha256:72b6be590cc35924b02c78ef34b467da4ba07e4e0f0454a2c5907f473fc50ce5 \\\n    --hash=sha256:7502934a33b54030eaf1194c21c692a534196063db72176b0c4028e140f8f32c \\\n    --hash=sha256:7a68b554d356a91cce1236aa7682dc01df0edba8d043fd1ce607c49dd3c1edcf \\\n    --hash=sha256:7b2e5a267c855eea6b4283940daa6e88a285f5f2a67f2220203786dfa59b37e9 \\\n    --hash=sha256:823b65d8706e32ad2df51ed89496147a42a2a6e01c13cfb6ffb8b1e92bc910bb \\\n    --hash=sha256:8590b4ae07a35970728874632fed7bd57b26b0102df2d2b233b6d9d82f6c62ad \\\n    --hash=sha256:8dd717634f5a044f860435c1d8c16a270ddf0ef8588d4887037c5028b859b0c3 \\\n    --hash=sha256:8dec4936e9c3100156f8a2dc89c4b88d5c435175ff03413b443469c7c8c5f4d1 \\\n    --hash=sha256:97cafb1f3cbcd3fd2b6fbfb99ae11cdb14deea0736fc2b0952ee177f2b813a46 \\\n    --hash=sha256:a17a92de5231666cfbe003f0e4b9b3a7ae3afb1ec2845aadc2bacc93ff85febc \\\n    --hash=sha256:a549b9c31bec33820e885335b451286e2969a2d9e24879f83fe904a5ce59d70a \\\n    --hash=sha256:ac07bad82163452a6884fe8fa0963fb98c2346ba78d779ec06bd7a6262132aee \\\n    --hash=sha256:ae2ad8ae6ebee9d2d94b17fb62763125f3f374c25618198f40cbb8b525411900 \\\n    --hash=sha256:b91c037585eba9095565a3556f611e3cbfaa42ca1e865f7b8015fe5c7336d5a5 \\\n    --hash=sha256:bc1667f8b83f48511b94671e0e441401371dfd0f0a795c7daa4a3cd1dde55bea \\\n    --hash=sha256:bec0a414d016ac1a18862a519e54b2fd0fc8bbfd6890376898a6c0891dd82e9f \\\n    --hash=sha256:bf50cd79a75d181c9181df03572cdce0fbb75cc353bc350712073108cba98de5 \\\n    --hash=sha256:bff1b4290a66b490a2f4719358c0cdcd9bafb6b8f061e45c7a2460866bf50c2e \\\n    --hash=sha256:c061bb86a71b42465156a3ee7bd58c8c2ceacdbeb95d05a99893e08b8467359a \\\n    --hash=sha256:c8b29db45f8fe46ad280a7294f5c3ec36dbac9491f2d1c17345be8e69cc5928f \\\n    --hash=sha256:ce409136744f6521e39fd8e2a24c53fa18ad67aa5bc7c2cf83645cce5b5c4e50 \\\n    --hash=sha256:d050b3361367a06d752db6ead6e7edeb0009be66bc3bae0ee9d97fb326badc2a \\\n    --hash=sha256:d283d37a890ba4c1ae73ffadf8046435c76e7bc2247bbb63c00bd1a709c6544b \\\n    --hash=sha256:d9fad5155d72433c921b782e58892377c44bd6252b5af2f67f16b194987338a4 \\\n    --hash=sha256:daa4ee5a243f0f20d528d939d06670a298dd39b1ad5f8a72a4275124a7819eff \\\n    --hash=sha256:db0b55e0f3cc0be60c1f19efdde9a637c32740486004f20d1cff53c3c0ece4d2 \\\n    --hash=sha256:e61659ba32cf2cf1481e575d0462554625196a1f2fc06a1c777d3f48e8865d46 \\\n    --hash=sha256:ea3d8a3d18833cf4304cd2fc9cbb1efe188ca9b5efef2bdac7adc20594a0e46b \\\n    --hash=sha256:ec6a563cff360b50eed26f13adc43e61bc0c04d94b8be985e6fb24b81f6dcfdf \\\n    --hash=sha256:f5dfb42c4604dddc8e4305050aa6deb084540643ed5804d7455b5df8fe16f5e5 \\\n    --hash=sha256:fa173ec60341d6bb97a89f5ea19c85c5643c1e7dedebc22f5181eb73573142c5 \\\n    --hash=sha256:fa9db3f79de01457b03d4f01b34cf91bc0048eb2c3846ff26f66687c2f6d16ab \\\n    --hash=sha256:fce659a462a1be54d2ffcacea5e3ba2d74daa74f30f5f143fe0c58636e355fdd \\\n    --hash=sha256:ffee1f21e5ef0d712f9033568f8344d5da8cc2869dbd08d87c84656e6a2d2f68\n    # via werkzeug\nmdurl==0.1.2 \\\n    --hash=sha256:84008a41e51615a49fc9966191ff91509e3c40b939176e643fd50a5c2196b8f8 \\\n    --hash=sha256:bb413d29f5eea38f31dd4754dd7377d4465116fb207585f97bf925588687c1ba\n    # via markdown-it-py\nml-dtypes==0.4.0 \\\n    --hash=sha256:03e7cda6ef164eed0abb31df69d2c00c3a5ab3e2610b6d4c42183a43329c72a5 \\\n    --hash=sha256:2bb83fd064db43e67e67d021e547698af4c8d5c6190f2e9b1c53c09f6ff5531d \\\n    --hash=sha256:3b67ec73a697c88c1122038e0de46520e48dc2ec876d42cf61bc5efe3c0b7675 \\\n    --hash=sha256:41affb38fdfe146e3db226cf2953021184d6f0c4ffab52136613e9601706e368 \\\n    --hash=sha256:43cf4356a0fe2eeac6d289018d0734e17a403bdf1fd911953c125dd0358edcc0 \\\n    --hash=sha256:723af6346447268a3cf0b7356e963d80ecb5732b5279b2aa3fa4b9fc8297c85e \\\n    --hash=sha256:75b4faf99d0711b81f393db36d210b4255fd419f6f790bc6c1b461f95ffb7a9e \\\n    --hash=sha256:93afe37f3a879d652ec9ef1fc47612388890660a2657fbb5747256c3b818fd81 \\\n    --hash=sha256:a15d96d090aebb55ee85173d1775ae325a001aab607a76c8ea0b964ccd6b5364 \\\n    --hash=sha256:ad6849a2db386b38e4d54fe13eb3293464561780531a918f8ef4c8169170dd49 \\\n    --hash=sha256:bdf689be7351cc3c95110c910c1b864002f113e682e44508910c849e144f3df1 \\\n    --hash=sha256:c83e4d443962d891d51669ff241d5aaad10a8d3d37a81c5532a45419885d591c \\\n    --hash=sha256:e1e2f4237b459a63c97c2c9f449baa637d7e4c20addff6a9bac486f22432f3b6 \\\n    --hash=sha256:eaa32979ebfde3a0d7c947cafbf79edc1ec77ac05ad0780ee86c1d8df70f2259 \\\n    --hash=sha256:eaf197e72f4f7176a19fe3cb8b61846b38c6757607e7bf9cd4b1d84cd3e74deb \\\n    --hash=sha256:ee9f91d4c4f9959a7e1051c141dc565f39e54435618152219769e24f5e9a4d06 \\\n    --hash=sha256:f1724ddcdf5edbaf615a62110af47407f1719b8d02e68ccee60683acb5f74da1\n    # via\n    #   -r ci/official/requirements_updater/requirements.in\n    #   jax\n    #   keras-nightly\nnamex==0.0.8 \\\n    --hash=sha256:32a50f6c565c0bb10aa76298c959507abdc0e850efe085dc38f3440fcb3aa90b \\\n    --hash=sha256:7ddb6c2bb0e753a311b7590f84f6da659dd0c05e65cb89d519d54c0a250c0487\n    # via keras-nightly\nnumpy==2.1.1 \\\n    --hash=sha256:046356b19d7ad1890c751b99acad5e82dc4a02232013bd9a9a712fddf8eb60f5 \\\n    --hash=sha256:0b8cc2715a84b7c3b161f9ebbd942740aaed913584cae9cdc7f8ad5ad41943d0 \\\n    --hash=sha256:0d07841fd284718feffe7dd17a63a2e6c78679b2d386d3e82f44f0108c905550 \\\n    --hash=sha256:13cc11c00000848702322af4de0147ced365c81d66053a67c2e962a485b3717c \\\n    --hash=sha256:13ce49a34c44b6de5241f0b38b07e44c1b2dcacd9e36c30f9c2fcb1bb5135db7 \\\n    --hash=sha256:24c2ad697bd8593887b019817ddd9974a7f429c14a5469d7fad413f28340a6d2 \\\n    --hash=sha256:251105b7c42abe40e3a689881e1793370cc9724ad50d64b30b358bbb3a97553b \\\n    --hash=sha256:2ca4b53e1e0b279142113b8c5eb7d7a877e967c306edc34f3b58e9be12fda8df \\\n    --hash=sha256:3269c9eb8745e8d975980b3a7411a98976824e1fdef11f0aacf76147f662b15f \\\n    --hash=sha256:397bc5ce62d3fb73f304bec332171535c187e0643e176a6e9421a6e3eacef06d \\\n    --hash=sha256:3fc5eabfc720db95d68e6646e88f8b399bfedd235994016351b1d9e062c4b270 \\\n    --hash=sha256:50a95ca3560a6058d6ea91d4629a83a897ee27c00630aed9d933dff191f170cd \\\n    --hash=sha256:52ac2e48f5ad847cd43c4755520a2317f3380213493b9d8a4c5e37f3b87df504 \\\n    --hash=sha256:53e27293b3a2b661c03f79aa51c3987492bd4641ef933e366e0f9f6c9bf257ec \\\n    --hash=sha256:57eb525e7c2a8fdee02d731f647146ff54ea8c973364f3b850069ffb42799647 \\\n    --hash=sha256:5889dd24f03ca5a5b1e8a90a33b5a0846d8977565e4ae003a63d22ecddf6782f \\\n    --hash=sha256:59ca673ad11d4b84ceb385290ed0ebe60266e356641428c845b39cd9df6713ab \\\n    --hash=sha256:6435c48250c12f001920f0751fe50c0348f5f240852cfddc5e2f97e007544cbe \\\n    --hash=sha256:6e5a9cb2be39350ae6c8f79410744e80154df658d5bea06e06e0ac5bb75480d5 \\\n    --hash=sha256:7be6a07520b88214ea85d8ac8b7d6d8a1839b0b5cb87412ac9f49fa934eb15d5 \\\n    --hash=sha256:7c803b7934a7f59563db459292e6aa078bb38b7ab1446ca38dd138646a38203e \\\n    --hash=sha256:7dd86dfaf7c900c0bbdcb8b16e2f6ddf1eb1fe39c6c8cca6e94844ed3152a8fd \\\n    --hash=sha256:8661c94e3aad18e1ea17a11f60f843a4933ccaf1a25a7c6a9182af70610b2313 \\\n    --hash=sha256:8ae0fd135e0b157365ac7cc31fff27f07a5572bdfc38f9c2d43b2aff416cc8b0 \\\n    --hash=sha256:910b47a6d0635ec1bd53b88f86120a52bf56dcc27b51f18c7b4a2e2224c29f0f \\\n    --hash=sha256:913cc1d311060b1d409e609947fa1b9753701dac96e6581b58afc36b7ee35af6 \\\n    --hash=sha256:920b0911bb2e4414c50e55bd658baeb78281a47feeb064ab40c2b66ecba85553 \\\n    --hash=sha256:950802d17a33c07cba7fd7c3dcfa7d64705509206be1606f196d179e539111ed \\\n    --hash=sha256:981707f6b31b59c0c24bcda52e5605f9701cb46da4b86c2e8023656ad3e833cb \\\n    --hash=sha256:98ce7fb5b8063cfdd86596b9c762bf2b5e35a2cdd7e967494ab78a1fa7f8b86e \\\n    --hash=sha256:99f4a9ee60eed1385a86e82288971a51e71df052ed0b2900ed30bc840c0f2e39 \\\n    --hash=sha256:9a8e06c7a980869ea67bbf551283bbed2856915f0a792dc32dd0f9dd2fb56728 \\\n    --hash=sha256:ae8ce252404cdd4de56dcfce8b11eac3c594a9c16c231d081fb705cf23bd4d9e \\\n    --hash=sha256:afd9c680df4de71cd58582b51e88a61feed4abcc7530bcd3d48483f20fc76f2a \\\n    --hash=sha256:b49742cdb85f1f81e4dc1b39dcf328244f4d8d1ded95dea725b316bd2cf18c95 \\\n    --hash=sha256:b5613cfeb1adfe791e8e681128f5f49f22f3fcaa942255a6124d58ca59d9528f \\\n    --hash=sha256:bab7c09454460a487e631ffc0c42057e3d8f2a9ddccd1e60c7bb8ed774992480 \\\n    --hash=sha256:c8a0e34993b510fc19b9a2ce7f31cb8e94ecf6e924a40c0c9dd4f62d0aac47d9 \\\n    --hash=sha256:caf5d284ddea7462c32b8d4a6b8af030b6c9fd5332afb70e7414d7fdded4bfd0 \\\n    --hash=sha256:cea427d1350f3fd0d2818ce7350095c1a2ee33e30961d2f0fef48576ddbbe90f \\\n    --hash=sha256:d0cf7d55b1051387807405b3898efafa862997b4cba8aa5dbe657be794afeafd \\\n    --hash=sha256:d10c39947a2d351d6d466b4ae83dad4c37cd6c3cdd6d5d0fa797da56f710a6ae \\\n    --hash=sha256:d2b9cd92c8f8e7b313b80e93cedc12c0112088541dcedd9197b5dee3738c1201 \\\n    --hash=sha256:d4c57b68c8ef5e1ebf47238e99bf27657511ec3f071c465f6b1bccbef12d4136 \\\n    --hash=sha256:d51fc141ddbe3f919e91a096ec739f49d686df8af254b2053ba21a910ae518bf \\\n    --hash=sha256:e097507396c0be4e547ff15b13dc3866f45f3680f789c1a1301b07dadd3fbc78 \\\n    --hash=sha256:e30356d530528a42eeba51420ae8bf6c6c09559051887196599d96ee5f536468 \\\n    --hash=sha256:e8d5f8a8e3bc87334f025194c6193e408903d21ebaeb10952264943a985066ca \\\n    --hash=sha256:e8dfa9e94fc127c40979c3eacbae1e61fda4fe71d84869cc129e2721973231ef \\\n    --hash=sha256:f212d4f46b67ff604d11fff7cc62d36b3e8714edf68e44e9760e19be38c03eb0 \\\n    --hash=sha256:f7506387e191fe8cdb267f912469a3cccc538ab108471291636a96a54e599556 \\\n    --hash=sha256:fac6e277a41163d27dfab5f4ec1f7a83fac94e170665a4a50191b545721c6521 \\\n    --hash=sha256:fcd8f556cdc8cfe35e70efb92463082b7f43dd7e547eb071ffc36abc0ca4699b\n    # via\n    #   -r ci/official/requirements_updater/requirements.in\n    #   h5py\n    #   jax\n    #   keras-nightly\n    #   ml-dtypes\n    #   opt-einsum\n    #   scipy\n    #   tb-nightly\nnvidia-cublas-cu12==12.5.3.2 \\\n    --hash=sha256:4960f3dc5f39699acadf76fa6d94b10a2a00f2956c2c442efa299fb22b0748f3 \\\n    --hash=sha256:7d0191251180de606023d396b94d66f66470a0ae96d1dbb906c7656ea0f71eda \\\n    --hash=sha256:ca070ad70e9fa6654084575d01bd001f30cc4665e33d4bb9fc8e0f321caa034b\n    # via\n    #   -r ci/official/requirements_updater/requirements.in\n    #   nvidia-cudnn-cu12\n    #   nvidia-cusolver-cu12\nnvidia-cuda-cupti-cu12==12.5.82 \\\n    --hash=sha256:4f835281cf492e2bedd153f5c3de9da8f1d775a419468305e64ce73b3b0c6dc3 \\\n    --hash=sha256:bde77a5feb66752ec61db2adfe47f56b941842825b4c7e2068aff27c9d107953 \\\n    --hash=sha256:d32c06490c6ba35c4323730820c7d0c4c126c04ed58d2f57275adb8d54b138fe\n    # via -r ci/official/requirements_updater/requirements.in\nnvidia-cuda-nvrtc-cu12==12.5.82 \\\n    --hash=sha256:3dbd97b0104b4bfbc3c4f8c79cd2496307c89c43c29a9f83125f1d76296ff3fd \\\n    --hash=sha256:5bb6a0eb01d4974bb7ca3d48bd3859472debb3c3057a5e7de2b08fbdf35eed7e \\\n    --hash=sha256:e5db37e990056c70953b7772dd778336ef9da0a0b5bb28f9f2a61c2e42b51d78\n    # via -r ci/official/requirements_updater/requirements.in\nnvidia-cuda-runtime-cu12==12.5.82 \\\n    --hash=sha256:0fd5fbca289bceb9f0690aa9858f06187b554fdeb7e2711dfd5bb3ce58900b46 \\\n    --hash=sha256:3e79a060e126df40fd3a068f3f787eb000fa51b251ec6cd97d09579632687115 \\\n    --hash=sha256:71f015dbf9df05dd71f7480132c6ebf47a6ceb2ab53d7db8e08e4b30ebb87e14\n    # via -r ci/official/requirements_updater/requirements.in\nnvidia-cudnn-cu12==9.3.0.75 \\\n    --hash=sha256:9ad9c6929ebb5295eb4a1728024666d1c88283373e265a0c5c883e6f9d5cd76d \\\n    --hash=sha256:c5cf7ff3415e446adf195a5b7dd2ba56cd00c3ee78bfdc566e51698931aa4b7f \\\n    --hash=sha256:c819e82eed8cf564b9d37478ea4eab9e87194bb3b7f7f8098bc1f67c9b80f1b6\n    # via -r ci/official/requirements_updater/requirements.in\nnvidia-cufft-cu12==11.2.3.61 \\\n    --hash=sha256:4a8f6f0ce93c52a50ee83422a80472b5f376054a63f38532d0eab4007e7ef28b \\\n    --hash=sha256:6d45b48a5ee7599e57131129cda2c58544d9b78b95064d3ec3e5c6b96e2b58cc \\\n    --hash=sha256:9a6e8df162585750f61983a638104a48c756aa13f9f48e19ab079b38e3c828b8\n    # via -r ci/official/requirements_updater/requirements.in\nnvidia-curand-cu12==10.3.6.82 \\\n    --hash=sha256:0631ba65231260ad832ce233ddda57e7b3b7158eabf000d78e46cbb5bd5b7aae \\\n    --hash=sha256:2823fb27de4e44dbb22394a6adf53aa6e1b013aca0f8c22867d1cfae58405536 \\\n    --hash=sha256:36aabeb5990297bbce3df324ea7c7c13c3aabb140c86d50ab3b23e4ec61672f1\n    # via -r ci/official/requirements_updater/requirements.in\nnvidia-cusolver-cu12==11.6.3.83 \\\n    --hash=sha256:1b8b77d2fe8abe72bb722dafb708cceaeb81f1a03999477f20b33b34f46ab885 \\\n    --hash=sha256:6224732963cba312a84c78114b9a38c4ffabb2e2a6a120923ac99ba6f895c8cf \\\n    --hash=sha256:93cfafacde4428b71778eeb092ec615a02a3d05404da1bcf91c53e3fa1bce42b\n    # via -r ci/official/requirements_updater/requirements.in\nnvidia-cusparse-cu12==12.5.1.3 \\\n    --hash=sha256:016df8e993c437e8301e62739f01775cba988fd5253cd4c64173f8e8d2f8e752 \\\n    --hash=sha256:33520db374e2f5ebc976d6faa1852b98c398a57e6f71150fe59705928596ffd1 \\\n    --hash=sha256:7b97fd01f0a61628af99d0efd52132fccc8c18fc5c509f13802dccf0574a19c2\n    # via\n    #   -r ci/official/requirements_updater/requirements.in\n    #   nvidia-cusolver-cu12\nnvidia-nccl-cu12==2.23.4 \\\n    --hash=sha256:aa946c8327e22ced28e7cef508a334673abc42064ec85f02d005ba1785ea4cec \\\n    --hash=sha256:b097258d9aab2fa9f686e33c6fe40ae57b27df60cedbd15d139701bb5509e0c1\n    # via -r ci/official/requirements_updater/requirements.in\nnvidia-nvjitlink-cu12==12.5.82 \\\n    --hash=sha256:98103729cc5226e13ca319a10bbf9433bbbd44ef64fe72f45f067cacc14b8d27 \\\n    --hash=sha256:e782564d705ff0bf61ac3e1bf730166da66dd2fe9012f111ede5fc49b64ae697 \\\n    --hash=sha256:f9b37bc5c8cf7509665cb6ada5aaa0ce65618f2332b7d3e78e9790511f111212\n    # via\n    #   -r ci/official/requirements_updater/requirements.in\n    #   nvidia-cufft-cu12\n    #   nvidia-cusolver-cu12\n    #   nvidia-cusparse-cu12\nopt-einsum==3.3.0 \\\n    --hash=sha256:2455e59e3947d3c275477df7f5205b30635e266fe6dc300e3d9f9646bfcea147 \\\n    --hash=sha256:59f6475f77bbc37dcf7cd748519c0ec60722e91e63ca114e68821c0c54a46549\n    # via\n    #   -r ci/official/requirements_updater/requirements.in\n    #   jax\npackaging==23.2 \\\n    --hash=sha256:048fb0e9405036518eaaf48a55953c750c11e1a1b68e0dd1a9d62ed0c092cfc5 \\\n    --hash=sha256:8c491190033a9af7e1d931d0b5dacc2ef47509b34dd0de67ed209b5203fc88c7\n    # via -r ci/official/requirements_updater/requirements.in\n    #   tb-nightly\nportpicker==1.6.0 \\\n    --hash=sha256:b2787a41404cf7edbe29b07b9e0ed863b09f2665dcc01c1eb0c2261c1e7d0755 \\\n    --hash=sha256:bd507fd6f96f65ee02781f2e674e9dc6c99bbfa6e3c39992e3916204c9d431fa\n    # via -r ci/official/requirements_updater/requirements.in\nprotobuf==4.25.3 \\\n    --hash=sha256:19b270aeaa0099f16d3ca02628546b8baefe2955bbe23224aaf856134eccf1e4 \\\n    --hash=sha256:209ba4cc916bab46f64e56b85b090607a676f66b473e6b762e6f1d9d591eb2e8 \\\n    --hash=sha256:25b5d0b42fd000320bd7830b349e3b696435f3b329810427a6bcce6a5492cc5c \\\n    --hash=sha256:7c8daa26095f82482307bc717364e7c13f4f1c99659be82890dcfc215194554d \\\n    --hash=sha256:c053062984e61144385022e53678fbded7aea14ebb3e0305ae3592fb219ccfa4 \\\n    --hash=sha256:d4198877797a83cbfe9bffa3803602bbe1625dc30d8a097365dbc762e5790faa \\\n    --hash=sha256:e3c97a1555fd6388f857770ff8b9703083de6bf1f9274a002a332d65fbb56c8c \\\n    --hash=sha256:e7cb0ae90dd83727f0c0718634ed56837bfeeee29a5f82a7514c03ee1364c019 \\\n    --hash=sha256:f0700d54bcf45424477e46a9f0944155b46fb0639d69728739c0e47bab83f2b9 \\\n    --hash=sha256:f1279ab38ecbfae7e456a108c5c0681e4956d5b1090027c1de0f934dfdb4b35c \\\n    --hash=sha256:f4f118245c4a087776e0a8408be33cf09f6c547442c00395fbfb116fac2f8ac2\n    # via tb-nightly\npsutil==5.9.8 \\\n    --hash=sha256:02615ed8c5ea222323408ceba16c60e99c3f91639b07da6373fb7e6539abc56d \\\n    --hash=sha256:05806de88103b25903dff19bb6692bd2e714ccf9e668d050d144012055cbca73 \\\n    --hash=sha256:26bd09967ae00920df88e0352a91cff1a78f8d69b3ecabbfe733610c0af486c8 \\\n    --hash=sha256:27cc40c3493bb10de1be4b3f07cae4c010ce715290a5be22b98493509c6299e2 \\\n    --hash=sha256:36f435891adb138ed3c9e58c6af3e2e6ca9ac2f365efe1f9cfef2794e6c93b4e \\\n    --hash=sha256:50187900d73c1381ba1454cf40308c2bf6f34268518b3f36a9b663ca87e65e36 \\\n    --hash=sha256:611052c4bc70432ec770d5d54f64206aa7203a101ec273a0cd82418c86503bb7 \\\n    --hash=sha256:6be126e3225486dff286a8fb9a06246a5253f4c7c53b475ea5f5ac934e64194c \\\n    --hash=sha256:7d79560ad97af658a0f6adfef8b834b53f64746d45b403f225b85c5c2c140eee \\\n    --hash=sha256:8cb6403ce6d8e047495a701dc7c5bd788add903f8986d523e3e20b98b733e421 \\\n    --hash=sha256:8db4c1b57507eef143a15a6884ca10f7c73876cdf5d51e713151c1236a0e68cf \\\n    --hash=sha256:aee678c8720623dc456fa20659af736241f575d79429a0e5e9cf88ae0605cc81 \\\n    --hash=sha256:bc56c2a1b0d15aa3eaa5a60c9f3f8e3e565303b465dbf57a1b730e7a2b9844e0 \\\n    --hash=sha256:bd1184ceb3f87651a67b2708d4c3338e9b10c5df903f2e3776b62303b26cb631 \\\n    --hash=sha256:d06016f7f8625a1825ba3732081d77c94589dca78b7a3fc072194851e88461a4 \\\n    --hash=sha256:d16bbddf0693323b8c6123dd804100241da461e41d6e332fb0ba6058f630f8c8\n    # via portpicker\npyelftools==0.31 \\\n    --hash=sha256:c774416b10310156879443b81187d182d8d9ee499660380e645918b50bc88f99 \\\n    --hash=sha256:f52de7b3c7e8c64c8abc04a79a1cf37ac5fb0b8a49809827130b858944840607\n    # via auditwheel\npygments==2.18.0 \\\n    --hash=sha256:786ff802f32e91311bff3889f6e9a86e81505fe99f2735bb6d60ae0c5004f199 \\\n    --hash=sha256:b8e6aca0523f3ab76fee51799c488e38782ac06eafcf95e7ba832985c8e7b13a\n    # via rich\nrequests==2.32.3 \\\n    --hash=sha256:55365417734eb18255590a9ff9eb97e9e1da868d4ccd6402399eaf68af20a760 \\\n    --hash=sha256:70761cfe03c773ceb22aa2f671b4757976145175cdfca038c02654d061d6dcc6\n    # via -r ci/official/requirements_updater/requirements.in\nrich==13.7.1 \\\n    --hash=sha256:4edbae314f59eb482f54e9e30bf00d33350aaa94f4bfcd4e9e3110e64d0d7222 \\\n    --hash=sha256:9be308cb1fe2f1f57d67ce99e95af38a1e2bc71ad9813b0e247cf7ffbcc3a432\n    # via keras-nightly\nscipy==1.13.1 \\\n    --hash=sha256:017367484ce5498445aade74b1d5ab377acdc65e27095155e448c88497755a5d \\\n    --hash=sha256:095a87a0312b08dfd6a6155cbbd310a8c51800fc931b8c0b84003014b874ed3c \\\n    --hash=sha256:20335853b85e9a49ff7572ab453794298bcf0354d8068c5f6775a0eabf350aca \\\n    --hash=sha256:27e52b09c0d3a1d5b63e1105f24177e544a222b43611aaf5bc44d4a0979e32f9 \\\n    --hash=sha256:2831f0dc9c5ea9edd6e51e6e769b655f08ec6db6e2e10f86ef39bd32eb11da54 \\\n    --hash=sha256:2ac65fb503dad64218c228e2dc2d0a0193f7904747db43014645ae139c8fad16 \\\n    --hash=sha256:392e4ec766654852c25ebad4f64e4e584cf19820b980bc04960bca0b0cd6eaa2 \\\n    --hash=sha256:436bbb42a94a8aeef855d755ce5a465479c721e9d684de76bf61a62e7c2b81d5 \\\n    --hash=sha256:45484bee6d65633752c490404513b9ef02475b4284c4cfab0ef946def50b3f59 \\\n    --hash=sha256:54f430b00f0133e2224c3ba42b805bfd0086fe488835effa33fa291561932326 \\\n    --hash=sha256:5713f62f781eebd8d597eb3f88b8bf9274e79eeabf63afb4a737abc6c84ad37b \\\n    --hash=sha256:5d72782f39716b2b3509cd7c33cdc08c96f2f4d2b06d51e52fb45a19ca0c86a1 \\\n    --hash=sha256:637e98dcf185ba7f8e663e122ebf908c4702420477ae52a04f9908707456ba4d \\\n    --hash=sha256:8335549ebbca860c52bf3d02f80784e91a004b71b059e3eea9678ba994796a24 \\\n    --hash=sha256:949ae67db5fa78a86e8fa644b9a6b07252f449dcf74247108c50e1d20d2b4627 \\\n    --hash=sha256:a014c2b3697bde71724244f63de2476925596c24285c7a637364761f8710891c \\\n    --hash=sha256:a78b4b3345f1b6f68a763c6e25c0c9a23a9fd0f39f5f3d200efe8feda560a5fa \\\n    --hash=sha256:cdd7dacfb95fea358916410ec61bbc20440f7860333aee6d882bb8046264e949 \\\n    --hash=sha256:cfa31f1def5c819b19ecc3a8b52d28ffdcc7ed52bb20c9a7589669dd3c250989 \\\n    --hash=sha256:d533654b7d221a6a97304ab63c41c96473ff04459e404b83275b60aa8f4b7004 \\\n    --hash=sha256:d605e9c23906d1994f55ace80e0125c587f96c020037ea6aa98d01b4bd2e222f \\\n    --hash=sha256:de3ade0e53bc1f21358aa74ff4830235d716211d7d077e340c7349bc3542e884 \\\n    --hash=sha256:e89369d27f9e7b0884ae559a3a956e77c02114cc60a6058b4e5011572eea9299 \\\n    --hash=sha256:eccfa1906eacc02de42d70ef4aecea45415f5be17e72b61bafcfd329bdc52e94 \\\n    --hash=sha256:f26264b282b9da0952a024ae34710c2aff7d27480ee91a2e82b7b7073c24722f\n    # via\n    #   -r ci/official/requirements_updater/requirements.in\n    #   jax\nsix==1.16.0 \\\n    --hash=sha256:1e61c37477a1626458e36f7b1d82aa5c9b094fa4802892072e49de9c60c4c926 \\\n    --hash=sha256:8abb2f1d86890a2dfb989f9a77cfcfd3e47c2a354b01111771326f8aa26e0254\n    # via\n    #   astunparse\n    #   google-pasta\n    #   tb-nightly\ntb-nightly==2.19.0a20240926 \\\n    --hash=sha256:4f2f4dd02eda684fbb2edd9cb46b7bd0ee7ba6ca35d38e4de2e293df8567c1b4\n    # via -r ci/official/requirements_updater/requirements.in\ntblib==2.0.0 \\\n    --hash=sha256:9100bfa016b047d5b980d66e7efed952fbd20bd85b56110aaf473cb97d18709a \\\n    --hash=sha256:a6df30f272c08bf8be66e0775fad862005d950a6b8449b94f7c788731d70ecd7\n    # via -r ci/official/requirements_updater/requirements.in\ntensorboard-data-server==0.7.2 \\\n    --hash=sha256:7e0610d205889588983836ec05dc098e80f97b7e7bbff7e994ebb78f578d0ddb \\\n    --hash=sha256:9fe5d24221b29625dbc7328b0436ca7fc1c23de4acf4d272f1180856e32f9f60 \\\n    --hash=sha256:ef687163c24185ae9754ed5650eb5bc4d84ff257aabdc33f0cc6f74d8ba54530\n    # via tb-nightly\ntensorflow-io-gcs-filesystem==0.37.1 \\\n    --hash=sha256:0df00891669390078a003cedbdd3b8e645c718b111917535fa1d7725e95cdb95 \\\n    --hash=sha256:249c12b830165841411ba71e08215d0e94277a49c551e6dd5d72aab54fe5491b \\\n    --hash=sha256:257aab23470a0796978efc9c2bcf8b0bc80f22e6298612a4c0a50d3f4e88060c \\\n    --hash=sha256:286389a203a5aee1a4fa2e53718c661091aa5fea797ff4fa6715ab8436b02e6c \\\n    --hash=sha256:32c50ab4e29a23c1f91cd0f9ab8c381a0ab10f45ef5c5252e94965916041737c \\\n    --hash=sha256:426de1173cb81fbd62becec2012fc00322a295326d90eb6c737fab636f182aed \\\n    --hash=sha256:6e1f2796b57e799a8ca1b75bf47c2aaa437c968408cc1a402a9862929e104cda \\\n    --hash=sha256:8943036bbf84e7a2be3705cb56f9c9df7c48c9e614bb941f0936c58e3ca89d6f \\\n    --hash=sha256:8febbfcc67c61e542a5ac1a98c7c20a91a5e1afc2e14b1ef0cb7c28bc3b6aa70 \\\n    --hash=sha256:9679b36e3a80921876f31685ab6f7270f3411a4cc51bc2847e80d0e4b5291e27 \\\n    --hash=sha256:b02f9c5f94fd62773954a04f69b68c4d576d076fd0db4ca25d5479f0fbfcdbad \\\n    --hash=sha256:ee5da49019670ed364f3e5fb86b46420841a6c3cb52a300553c63841671b3e6d \\\n    --hash=sha256:ee7c8ee5fe2fd8cb6392669ef16e71841133041fee8a330eff519ad9b36e4556 \\\n    --hash=sha256:fbb33f1745f218464a59cecd9a18e32ca927b0f4d77abd8f8671b645cc1a182f \\\n    --hash=sha256:fe8dcc6d222258a080ac3dfcaaaa347325ce36a7a046277f6b3e19abc1efb3c5 \\\n    --hash=sha256:ffebb6666a7bfc28005f4fbbb111a455b5e7d6cd3b12752b7050863ecb27d5cc\n    # via -r ci/official/requirements_updater/requirements.in\ntermcolor==2.3.0 \\\n    --hash=sha256:3afb05607b89aed0ffe25202399ee0867ad4d3cb4180d98aaf8eefa6a5f7d475 \\\n    --hash=sha256:b5b08f68937f138fe92f6c089b99f1e2da0ae56c52b78bf7075fd95420fd9a5a\n    # via -r ci/official/requirements_updater/requirements.in\ntyping-extensions==4.8.0 \\\n    --hash=sha256:8f92fc8806f9a6b641eaa5318da32b44d401efaac0f6678c9bc448ba3605faa0 \\\n    --hash=sha256:df8e4339e9cb77357558cbdbceca33c303714cf861d1eef15e1070055ae8b7ef\n    # via -r ci/official/requirements_updater/requirements.in\nurllib3==2.2.2 \\\n    --hash=sha256:a448b2f64d686155468037e1ace9f2d2199776e17f0a46610480d311f73e3472 \\\n    --hash=sha256:dd505485549a7a552833da5e6063639d0d177c04f23bc3864e41e5dc5f612168\n    # via requests\nwerkzeug==3.0.6 \\\n    --hash=sha256:1bc0c2310d2fbb07b1dd1105eba2f7af72f322e1e455f2f93c993bee8c8a5f17 \\\n    --hash=sha256:a8dd59d4de28ca70471a34cba79bed5f7ef2e036a76b3ab0835474246eb41f8d\n    # via tb-nightly\nwheel==0.41.3 \\\n    --hash=sha256:488609bc63a29322326e05560731bf7bfea8e48ad646e1f5e40d366607de0942 \\\n    --hash=sha256:4d4987ce51a49370ea65c0bfd2234e8ce80a12780820d9dc462597a6e60d0841\n    # via\n    #   -r ci/official/requirements_updater/requirements.in\n    #   astunparse\nwrapt==1.16.0 \\\n    --hash=sha256:0d2691979e93d06a95a26257adb7bfd0c93818e89b1406f5a28f36e0d8c1e1fc \\\n    --hash=sha256:14d7dc606219cdd7405133c713f2c218d4252f2a469003f8c46bb92d5d095d81 \\\n    --hash=sha256:1a5db485fe2de4403f13fafdc231b0dbae5eca4359232d2efc79025527375b09 \\\n    --hash=sha256:1acd723ee2a8826f3d53910255643e33673e1d11db84ce5880675954183ec47e \\\n    --hash=sha256:1ca9b6085e4f866bd584fb135a041bfc32cab916e69f714a7d1d397f8c4891ca \\\n    --hash=sha256:1dd50a2696ff89f57bd8847647a1c363b687d3d796dc30d4dd4a9d1689a706f0 \\\n    --hash=sha256:2076fad65c6736184e77d7d4729b63a6d1ae0b70da4868adeec40989858eb3fb \\\n    --hash=sha256:2a88e6010048489cda82b1326889ec075a8c856c2e6a256072b28eaee3ccf487 \\\n    --hash=sha256:3ebf019be5c09d400cf7b024aa52b1f3aeebeff51550d007e92c3c1c4afc2a40 \\\n    --hash=sha256:418abb18146475c310d7a6dc71143d6f7adec5b004ac9ce08dc7a34e2babdc5c \\\n    --hash=sha256:43aa59eadec7890d9958748db829df269f0368521ba6dc68cc172d5d03ed8060 \\\n    --hash=sha256:44a2754372e32ab315734c6c73b24351d06e77ffff6ae27d2ecf14cf3d229202 \\\n    --hash=sha256:490b0ee15c1a55be9c1bd8609b8cecd60e325f0575fc98f50058eae366e01f41 \\\n    --hash=sha256:49aac49dc4782cb04f58986e81ea0b4768e4ff197b57324dcbd7699c5dfb40b9 \\\n    --hash=sha256:5eb404d89131ec9b4f748fa5cfb5346802e5ee8836f57d516576e61f304f3b7b \\\n    --hash=sha256:5f15814a33e42b04e3de432e573aa557f9f0f56458745c2074952f564c50e664 \\\n    --hash=sha256:5f370f952971e7d17c7d1ead40e49f32345a7f7a5373571ef44d800d06b1899d \\\n    --hash=sha256:66027d667efe95cc4fa945af59f92c5a02c6f5bb6012bff9e60542c74c75c362 \\\n    --hash=sha256:66dfbaa7cfa3eb707bbfcd46dab2bc6207b005cbc9caa2199bcbc81d95071a00 \\\n    --hash=sha256:685f568fa5e627e93f3b52fda002c7ed2fa1800b50ce51f6ed1d572d8ab3e7fc \\\n    --hash=sha256:6906c4100a8fcbf2fa735f6059214bb13b97f75b1a61777fcf6432121ef12ef1 \\\n    --hash=sha256:6a42cd0cfa8ffc1915aef79cb4284f6383d8a3e9dcca70c445dcfdd639d51267 \\\n    --hash=sha256:6dcfcffe73710be01d90cae08c3e548d90932d37b39ef83969ae135d36ef3956 \\\n    --hash=sha256:6f6eac2360f2d543cc875a0e5efd413b6cbd483cb3ad7ebf888884a6e0d2e966 \\\n    --hash=sha256:72554a23c78a8e7aa02abbd699d129eead8b147a23c56e08d08dfc29cfdddca1 \\\n    --hash=sha256:73870c364c11f03ed072dda68ff7aea6d2a3a5c3fe250d917a429c7432e15228 \\\n    --hash=sha256:73aa7d98215d39b8455f103de64391cb79dfcad601701a3aa0dddacf74911d72 \\\n    --hash=sha256:75ea7d0ee2a15733684badb16de6794894ed9c55aa5e9903260922f0482e687d \\\n    --hash=sha256:7bd2d7ff69a2cac767fbf7a2b206add2e9a210e57947dd7ce03e25d03d2de292 \\\n    --hash=sha256:807cc8543a477ab7422f1120a217054f958a66ef7314f76dd9e77d3f02cdccd0 \\\n    --hash=sha256:8e9723528b9f787dc59168369e42ae1c3b0d3fadb2f1a71de14531d321ee05b0 \\\n    --hash=sha256:9090c9e676d5236a6948330e83cb89969f433b1943a558968f659ead07cb3b36 \\\n    --hash=sha256:9153ed35fc5e4fa3b2fe97bddaa7cbec0ed22412b85bcdaf54aeba92ea37428c \\\n    --hash=sha256:9159485323798c8dc530a224bd3ffcf76659319ccc7bbd52e01e73bd0241a0c5 \\\n    --hash=sha256:941988b89b4fd6b41c3f0bfb20e92bd23746579736b7343283297c4c8cbae68f \\\n    --hash=sha256:94265b00870aa407bd0cbcfd536f17ecde43b94fb8d228560a1e9d3041462d73 \\\n    --hash=sha256:98b5e1f498a8ca1858a1cdbffb023bfd954da4e3fa2c0cb5853d40014557248b \\\n    --hash=sha256:9b201ae332c3637a42f02d1045e1d0cccfdc41f1f2f801dafbaa7e9b4797bfc2 \\\n    --hash=sha256:a0ea261ce52b5952bf669684a251a66df239ec6d441ccb59ec7afa882265d593 \\\n    --hash=sha256:a33a747400b94b6d6b8a165e4480264a64a78c8a4c734b62136062e9a248dd39 \\\n    --hash=sha256:a452f9ca3e3267cd4d0fcf2edd0d035b1934ac2bd7e0e57ac91ad6b95c0c6389 \\\n    --hash=sha256:a86373cf37cd7764f2201b76496aba58a52e76dedfaa698ef9e9688bfd9e41cf \\\n    --hash=sha256:ac83a914ebaf589b69f7d0a1277602ff494e21f4c2f743313414378f8f50a4cf \\\n    --hash=sha256:aefbc4cb0a54f91af643660a0a150ce2c090d3652cf4052a5397fb2de549cd89 \\\n    --hash=sha256:b3646eefa23daeba62643a58aac816945cadc0afaf21800a1421eeba5f6cfb9c \\\n    --hash=sha256:b47cfad9e9bbbed2339081f4e346c93ecd7ab504299403320bf85f7f85c7d46c \\\n    --hash=sha256:b935ae30c6e7400022b50f8d359c03ed233d45b725cfdd299462f41ee5ffba6f \\\n    --hash=sha256:bb2dee3874a500de01c93d5c71415fcaef1d858370d405824783e7a8ef5db440 \\\n    --hash=sha256:bc57efac2da352a51cc4658878a68d2b1b67dbe9d33c36cb826ca449d80a8465 \\\n    --hash=sha256:bf5703fdeb350e36885f2875d853ce13172ae281c56e509f4e6eca049bdfb136 \\\n    --hash=sha256:c31f72b1b6624c9d863fc095da460802f43a7c6868c5dda140f51da24fd47d7b \\\n    --hash=sha256:c5cd603b575ebceca7da5a3a251e69561bec509e0b46e4993e1cac402b7247b8 \\\n    --hash=sha256:d2efee35b4b0a347e0d99d28e884dfd82797852d62fcd7ebdeee26f3ceb72cf3 \\\n    --hash=sha256:d462f28826f4657968ae51d2181a074dfe03c200d6131690b7d65d55b0f360f8 \\\n    --hash=sha256:d5e49454f19ef621089e204f862388d29e6e8d8b162efce05208913dde5b9ad6 \\\n    --hash=sha256:da4813f751142436b075ed7aa012a8778aa43a99f7b36afe9b742d3ed8bdc95e \\\n    --hash=sha256:db2e408d983b0e61e238cf579c09ef7020560441906ca990fe8412153e3b291f \\\n    --hash=sha256:db98ad84a55eb09b3c32a96c576476777e87c520a34e2519d3e59c44710c002c \\\n    --hash=sha256:dbed418ba5c3dce92619656802cc5355cb679e58d0d89b50f116e4a9d5a9603e \\\n    --hash=sha256:dcdba5c86e368442528f7060039eda390cc4091bfd1dca41e8046af7c910dda8 \\\n    --hash=sha256:decbfa2f618fa8ed81c95ee18a387ff973143c656ef800c9f24fb7e9c16054e2 \\\n    --hash=sha256:e4fdb9275308292e880dcbeb12546df7f3e0f96c6b41197e0cf37d2826359020 \\\n    --hash=sha256:eb1b046be06b0fce7249f1d025cd359b4b80fc1c3e24ad9eca33e0dcdb2e4a35 \\\n    --hash=sha256:eb6e651000a19c96f452c85132811d25e9264d836951022d6e81df2fff38337d \\\n    --hash=sha256:ed867c42c268f876097248e05b6117a65bcd1e63b779e916fe2e33cd6fd0d3c3 \\\n    --hash=sha256:edfad1d29c73f9b863ebe7082ae9321374ccb10879eeabc84ba3b69f2579d537 \\\n    --hash=sha256:f2058f813d4f2b5e3a9eb2eb3faf8f1d99b81c3e51aeda4b168406443e8ba809 \\\n    --hash=sha256:f6b2d0c6703c988d334f297aa5df18c45e97b0af3679bb75059e0e0bd8b1069d \\\n    --hash=sha256:f8212564d49c50eb4565e502814f694e240c55551a5f1bc841d4fcaabb0a9b8a \\\n    --hash=sha256:ffa565331890b90056c01db69c0fe634a776f8019c143a5ae265f9c6bc4bd6d4\n    # via -r ci/official/requirements_updater/requirements.in\n\n# The following packages are considered to be unsafe in a requirements file:\nsetuptools==70.0.0 \\\n    --hash=sha256:54faa7f2e8d2d11bcd2c07bed282eef1046b5c080d1c32add737d7b5817b1ad4 \\\n    --hash=sha256:f211a66637b8fa059bb28183da127d4e86396c991a942b028c6650d4319c3fd0\n    # via\n    #   -r ci/official/requirements_updater/requirements.in\n    #   tb-nightly\n"
        },
        {
          "name": "requirements_lock_3_11.txt",
          "type": "blob",
          "size": 52.8359375,
          "content": "#\n# This file is autogenerated by pip-compile with Python 3.11\n# by the following command:\n#\n#    bazel run //ci/official/requirements_updater:requirements.update\n#\nabsl-py==2.1.0 \\\n    --hash=sha256:526a04eadab8b4ee719ce68f204172ead1027549089702d99b9059f129ff1308 \\\n    --hash=sha256:7820790efbb316739cde8b4e19357243fc3608a152024288513dd968d7d959ff\n    # via\n    #   keras-nightly\n    #   tb-nightly\nastor==0.7.1 \\\n    --hash=sha256:95c30d87a6c2cf89aa628b87398466840f0ad8652f88eb173125a6df8533fb8d \\\n    --hash=sha256:fb503b9e2fdd05609fbf557b916b4a7824171203701660f0c55bbf5a7a68713e\n    # via -r ci/official/requirements_updater/requirements.in\nastunparse==1.6.3 \\\n    --hash=sha256:5ad93a8456f0d084c3456d059fd9a92cce667963232cbf763eac3bc5b7940872 \\\n    --hash=sha256:c2652417f2c8b5bb325c885ae329bdf3f86424075c4fd1a128674bc6fba4b8e8\n    # via -r ci/official/requirements_updater/requirements.in\nauditwheel==6.1.0 \\\n    --hash=sha256:3bdc686e774cf9e355e924b0fe5a562d55caa385d72234ffe7b81b378dba360f \\\n    --hash=sha256:e52f734861859e3743eb29fcac7da9c4921a1e4bea58f954b52f2926f8e9e364\n    # via -r ci/official/requirements_updater/requirements.in\ncertifi==2024.7.4 \\\n    --hash=sha256:5a1e7645bc0ec61a09e26c36f6106dd4cf40c6db3a1fb6352b0244e7fb057c7b \\\n    --hash=sha256:c198e21b1289c2ab85ee4e67bb4b4ef3ead0892059901a8d5b622f24a1101e90\n    # via requests\ncharset-normalizer==3.3.2 \\\n    --hash=sha256:06435b539f889b1f6f4ac1758871aae42dc3a8c0e24ac9e60c2384973ad73027 \\\n    --hash=sha256:06a81e93cd441c56a9b65d8e1d043daeb97a3d0856d177d5c90ba85acb3db087 \\\n    --hash=sha256:0a55554a2fa0d408816b3b5cedf0045f4b8e1a6065aec45849de2d6f3f8e9786 \\\n    --hash=sha256:0b2b64d2bb6d3fb9112bafa732def486049e63de9618b5843bcdd081d8144cd8 \\\n    --hash=sha256:10955842570876604d404661fbccbc9c7e684caf432c09c715ec38fbae45ae09 \\\n    --hash=sha256:122c7fa62b130ed55f8f285bfd56d5f4b4a5b503609d181f9ad85e55c89f4185 \\\n    --hash=sha256:1ceae2f17a9c33cb48e3263960dc5fc8005351ee19db217e9b1bb15d28c02574 \\\n    --hash=sha256:1d3193f4a680c64b4b6a9115943538edb896edc190f0b222e73761716519268e \\\n    --hash=sha256:1f79682fbe303db92bc2b1136016a38a42e835d932bab5b3b1bfcfbf0640e519 \\\n    --hash=sha256:2127566c664442652f024c837091890cb1942c30937add288223dc895793f898 \\\n    --hash=sha256:22afcb9f253dac0696b5a4be4a1c0f8762f8239e21b99680099abd9b2b1b2269 \\\n    --hash=sha256:25baf083bf6f6b341f4121c2f3c548875ee6f5339300e08be3f2b2ba1721cdd3 \\\n    --hash=sha256:2e81c7b9c8979ce92ed306c249d46894776a909505d8f5a4ba55b14206e3222f \\\n    --hash=sha256:3287761bc4ee9e33561a7e058c72ac0938c4f57fe49a09eae428fd88aafe7bb6 \\\n    --hash=sha256:34d1c8da1e78d2e001f363791c98a272bb734000fcef47a491c1e3b0505657a8 \\\n    --hash=sha256:37e55c8e51c236f95b033f6fb391d7d7970ba5fe7ff453dad675e88cf303377a \\\n    --hash=sha256:3d47fa203a7bd9c5b6cee4736ee84ca03b8ef23193c0d1ca99b5089f72645c73 \\\n    --hash=sha256:3e4d1f6587322d2788836a99c69062fbb091331ec940e02d12d179c1d53e25fc \\\n    --hash=sha256:42cb296636fcc8b0644486d15c12376cb9fa75443e00fb25de0b8602e64c1714 \\\n    --hash=sha256:45485e01ff4d3630ec0d9617310448a8702f70e9c01906b0d0118bdf9d124cf2 \\\n    --hash=sha256:4a78b2b446bd7c934f5dcedc588903fb2f5eec172f3d29e52a9096a43722adfc \\\n    --hash=sha256:4ab2fe47fae9e0f9dee8c04187ce5d09f48eabe611be8259444906793ab7cbce \\\n    --hash=sha256:4d0d1650369165a14e14e1e47b372cfcb31d6ab44e6e33cb2d4e57265290044d \\\n    --hash=sha256:549a3a73da901d5bc3ce8d24e0600d1fa85524c10287f6004fbab87672bf3e1e \\\n    --hash=sha256:55086ee1064215781fff39a1af09518bc9255b50d6333f2e4c74ca09fac6a8f6 \\\n    --hash=sha256:572c3763a264ba47b3cf708a44ce965d98555f618ca42c926a9c1616d8f34269 \\\n    --hash=sha256:573f6eac48f4769d667c4442081b1794f52919e7edada77495aaed9236d13a96 \\\n    --hash=sha256:5b4c145409bef602a690e7cfad0a15a55c13320ff7a3ad7ca59c13bb8ba4d45d \\\n    --hash=sha256:6463effa3186ea09411d50efc7d85360b38d5f09b870c48e4600f63af490e56a \\\n    --hash=sha256:65f6f63034100ead094b8744b3b97965785388f308a64cf8d7c34f2f2e5be0c4 \\\n    --hash=sha256:663946639d296df6a2bb2aa51b60a2454ca1cb29835324c640dafb5ff2131a77 \\\n    --hash=sha256:6897af51655e3691ff853668779c7bad41579facacf5fd7253b0133308cf000d \\\n    --hash=sha256:68d1f8a9e9e37c1223b656399be5d6b448dea850bed7d0f87a8311f1ff3dabb0 \\\n    --hash=sha256:6ac7ffc7ad6d040517be39eb591cac5ff87416c2537df6ba3cba3bae290c0fed \\\n    --hash=sha256:6b3251890fff30ee142c44144871185dbe13b11bab478a88887a639655be1068 \\\n    --hash=sha256:6c4caeef8fa63d06bd437cd4bdcf3ffefe6738fb1b25951440d80dc7df8c03ac \\\n    --hash=sha256:6ef1d82a3af9d3eecdba2321dc1b3c238245d890843e040e41e470ffa64c3e25 \\\n    --hash=sha256:753f10e867343b4511128c6ed8c82f7bec3bd026875576dfd88483c5c73b2fd8 \\\n    --hash=sha256:7cd13a2e3ddeed6913a65e66e94b51d80a041145a026c27e6bb76c31a853c6ab \\\n    --hash=sha256:7ed9e526742851e8d5cc9e6cf41427dfc6068d4f5a3bb03659444b4cabf6bc26 \\\n    --hash=sha256:7f04c839ed0b6b98b1a7501a002144b76c18fb1c1850c8b98d458ac269e26ed2 \\\n    --hash=sha256:802fe99cca7457642125a8a88a084cef28ff0cf9407060f7b93dca5aa25480db \\\n    --hash=sha256:80402cd6ee291dcb72644d6eac93785fe2c8b9cb30893c1af5b8fdd753b9d40f \\\n    --hash=sha256:8465322196c8b4d7ab6d1e049e4c5cb460d0394da4a27d23cc242fbf0034b6b5 \\\n    --hash=sha256:86216b5cee4b06df986d214f664305142d9c76df9b6512be2738aa72a2048f99 \\\n    --hash=sha256:87d1351268731db79e0f8e745d92493ee2841c974128ef629dc518b937d9194c \\\n    --hash=sha256:8bdb58ff7ba23002a4c5808d608e4e6c687175724f54a5dade5fa8c67b604e4d \\\n    --hash=sha256:8c622a5fe39a48f78944a87d4fb8a53ee07344641b0562c540d840748571b811 \\\n    --hash=sha256:8d756e44e94489e49571086ef83b2bb8ce311e730092d2c34ca8f7d925cb20aa \\\n    --hash=sha256:8f4a014bc36d3c57402e2977dada34f9c12300af536839dc38c0beab8878f38a \\\n    --hash=sha256:9063e24fdb1e498ab71cb7419e24622516c4a04476b17a2dab57e8baa30d6e03 \\\n    --hash=sha256:90d558489962fd4918143277a773316e56c72da56ec7aa3dc3dbbe20fdfed15b \\\n    --hash=sha256:923c0c831b7cfcb071580d3f46c4baf50f174be571576556269530f4bbd79d04 \\\n    --hash=sha256:95f2a5796329323b8f0512e09dbb7a1860c46a39da62ecb2324f116fa8fdc85c \\\n    --hash=sha256:96b02a3dc4381e5494fad39be677abcb5e6634bf7b4fa83a6dd3112607547001 \\\n    --hash=sha256:9f96df6923e21816da7e0ad3fd47dd8f94b2a5ce594e00677c0013018b813458 \\\n    --hash=sha256:a10af20b82360ab00827f916a6058451b723b4e65030c5a18577c8b2de5b3389 \\\n    --hash=sha256:a50aebfa173e157099939b17f18600f72f84eed3049e743b68ad15bd69b6bf99 \\\n    --hash=sha256:a981a536974bbc7a512cf44ed14938cf01030a99e9b3a06dd59578882f06f985 \\\n    --hash=sha256:a9a8e9031d613fd2009c182b69c7b2c1ef8239a0efb1df3f7c8da66d5dd3d537 \\\n    --hash=sha256:ae5f4161f18c61806f411a13b0310bea87f987c7d2ecdbdaad0e94eb2e404238 \\\n    --hash=sha256:aed38f6e4fb3f5d6bf81bfa990a07806be9d83cf7bacef998ab1a9bd660a581f \\\n    --hash=sha256:b01b88d45a6fcb69667cd6d2f7a9aeb4bf53760d7fc536bf679ec94fe9f3ff3d \\\n    --hash=sha256:b261ccdec7821281dade748d088bb6e9b69e6d15b30652b74cbbac25e280b796 \\\n    --hash=sha256:b2b0a0c0517616b6869869f8c581d4eb2dd83a4d79e0ebcb7d373ef9956aeb0a \\\n    --hash=sha256:b4a23f61ce87adf89be746c8a8974fe1c823c891d8f86eb218bb957c924bb143 \\\n    --hash=sha256:bd8f7df7d12c2db9fab40bdd87a7c09b1530128315d047a086fa3ae3435cb3a8 \\\n    --hash=sha256:beb58fe5cdb101e3a055192ac291b7a21e3b7ef4f67fa1d74e331a7f2124341c \\\n    --hash=sha256:c002b4ffc0be611f0d9da932eb0f704fe2602a9a949d1f738e4c34c75b0863d5 \\\n    --hash=sha256:c083af607d2515612056a31f0a8d9e0fcb5876b7bfc0abad3ecd275bc4ebc2d5 \\\n    --hash=sha256:c180f51afb394e165eafe4ac2936a14bee3eb10debc9d9e4db8958fe36afe711 \\\n    --hash=sha256:c235ebd9baae02f1b77bcea61bce332cb4331dc3617d254df3323aa01ab47bd4 \\\n    --hash=sha256:cd70574b12bb8a4d2aaa0094515df2463cb429d8536cfb6c7ce983246983e5a6 \\\n    --hash=sha256:d0eccceffcb53201b5bfebb52600a5fb483a20b61da9dbc885f8b103cbe7598c \\\n    --hash=sha256:d965bba47ddeec8cd560687584e88cf699fd28f192ceb452d1d7ee807c5597b7 \\\n    --hash=sha256:db364eca23f876da6f9e16c9da0df51aa4f104a972735574842618b8c6d999d4 \\\n    --hash=sha256:ddbb2551d7e0102e7252db79ba445cdab71b26640817ab1e3e3648dad515003b \\\n    --hash=sha256:deb6be0ac38ece9ba87dea880e438f25ca3eddfac8b002a2ec3d9183a454e8ae \\\n    --hash=sha256:e06ed3eb3218bc64786f7db41917d4e686cc4856944f53d5bdf83a6884432e12 \\\n    --hash=sha256:e27ad930a842b4c5eb8ac0016b0a54f5aebbe679340c26101df33424142c143c \\\n    --hash=sha256:e537484df0d8f426ce2afb2d0f8e1c3d0b114b83f8850e5f2fbea0e797bd82ae \\\n    --hash=sha256:eb00ed941194665c332bf8e078baf037d6c35d7c4f3102ea2d4f16ca94a26dc8 \\\n    --hash=sha256:eb6904c354526e758fda7167b33005998fb68c46fbc10e013ca97f21ca5c8887 \\\n    --hash=sha256:eb8821e09e916165e160797a6c17edda0679379a4be5c716c260e836e122f54b \\\n    --hash=sha256:efcb3f6676480691518c177e3b465bcddf57cea040302f9f4e6e191af91174d4 \\\n    --hash=sha256:f27273b60488abe721a075bcca6d7f3964f9f6f067c8c4c605743023d7d3944f \\\n    --hash=sha256:f30c3cb33b24454a82faecaf01b19c18562b1e89558fb6c56de4d9118a032fd5 \\\n    --hash=sha256:fb69256e180cb6c8a894fee62b3afebae785babc1ee98b81cdf68bbca1987f33 \\\n    --hash=sha256:fd1abc0d89e30cc4e02e4064dc67fcc51bd941eb395c502aac3ec19fab46b519 \\\n    --hash=sha256:ff8fa367d09b717b2a17a052544193ad76cd49979c805768879cb63d9ca50561\n    # via requests\ndill==0.3.7 \\\n    --hash=sha256:76b122c08ef4ce2eedcd4d1abd8e641114bfc6c2867f49f3c41facf65bf19f5e \\\n    --hash=sha256:cc1c8b182eb3013e24bd475ff2e9295af86c1a38eb1aff128dac8962a9ce3c03\n    # via -r ci/official/requirements_updater/requirements.in\ndm-tree==0.1.8 \\\n    --hash=sha256:054b461f8176f4bce7a21f7b1870f873a1ced3bdbe1282c816c550bb43c71fa6 \\\n    --hash=sha256:09964470f76a5201aff2e8f9b26842976de7889300676f927930f6285e256760 \\\n    --hash=sha256:0d3172394079a86c3a759179c65f64c48d1a42b89495fcf38976d11cc3bb952c \\\n    --hash=sha256:0e9620ccf06393eb6b613b5e366469304622d4ea96ae6540b28a33840e6c89cf \\\n    --hash=sha256:0fcaabbb14e7980377439e7140bd05552739ca5e515ecb3119f234acee4b9430 \\\n    --hash=sha256:1607ce49aa42f010d1e5e616d92ce899d66835d4d8bea49679582435285515de \\\n    --hash=sha256:181c35521d480d0365f39300542cb6cd7fd2b77351bb43d7acfda15aef63b317 \\\n    --hash=sha256:1d7c26e431fc93cc7e0cba867eb000db6a05f6f2b25af11ac4e9dada88fc5bca \\\n    --hash=sha256:1fe962015b2fe1282892b28ebe962faed53c7f98d942da9a4625cbf27baef913 \\\n    --hash=sha256:250b692fb75f45f02e2f58fbef9ab338904ef334b90557565621fa251df267cf \\\n    --hash=sha256:2869228d9c619074de501a3c10dc7f07c75422f8fab36ecdcb859b6f1b1ec3ef \\\n    --hash=sha256:28c52cbf4f8b3dbd0beaedf44f69fa85eec5e9dede612e08035e06ada6ec9426 \\\n    --hash=sha256:2f7915660f59c09068e428613c480150180df1060561fd0d1470684ae7007bd1 \\\n    --hash=sha256:343a4a4ebaa127451ff971254a4be4084eb4bdc0b2513c32b46f6f728fd03f9e \\\n    --hash=sha256:35cc164a79336bfcfafb47e5f297898359123bbd3330c1967f0c4994f9cf9f60 \\\n    --hash=sha256:378cc8ad93c5fe3590f405a309980721f021c790ca1bdf9b15bb1d59daec57f5 \\\n    --hash=sha256:39070ba268c0491af9fe7a58644d99e8b4f2cde6e5884ba3380bddc84ed43d5f \\\n    --hash=sha256:435227cf3c5dc63f4de054cf3d00183790bd9ead4c3623138c74dde7f67f521b \\\n    --hash=sha256:5483dca4d7eb1a0d65fe86d3b6a53ae717face83c1f17e0887b1a4a64ae5c410 \\\n    --hash=sha256:694c3654cfd2a81552c08ec66bb5c4a3d48fa292b9a181880fb081c36c5b9134 \\\n    --hash=sha256:75c5d528bb992981c20793b6b453e91560784215dffb8a5440ba999753c14ceb \\\n    --hash=sha256:803bfc53b4659f447ac694dbd04235f94a73ef7c1fd1e0df7c84ac41e0bc963b \\\n    --hash=sha256:81fce77f22a302d7a5968aebdf4efafef4def7ce96528719a354e6990dcd49c7 \\\n    --hash=sha256:83b7764de0d855338abefc6e3ee9fe40d301668310aa3baea3f778ff051f4393 \\\n    --hash=sha256:8c60a7eadab64c2278861f56bca320b2720f163dca9d7558103c3b77f2416571 \\\n    --hash=sha256:8ed3564abed97c806db122c2d3e1a2b64c74a63debe9903aad795167cc301368 \\\n    --hash=sha256:94d3f0826311f45ee19b75f5b48c99466e4218a0489e81c0f0167bda50cacf22 \\\n    --hash=sha256:96a548a406a6fb15fe58f6a30a57ff2f2aafbf25f05afab00c8f5e5977b6c715 \\\n    --hash=sha256:a5d819c38c03f0bb5b3b3703c60e4b170355a0fc6b5819325bf3d4ceb3ae7e80 \\\n    --hash=sha256:ad16ceba90a56ec47cf45b21856d14962ac314787975ef786efb5e6e9ca75ec7 \\\n    --hash=sha256:af4b3d372f2477dcd89a6e717e4a575ca35ccc20cc4454a8a4b6f8838a00672d \\\n    --hash=sha256:b095ba4f8ca1ba19350fd53cf1f8f3eb0bd406aa28af64a6dfc86707b32a810a \\\n    --hash=sha256:b9bd9b9ccb59409d33d51d84b7668010c04c2af7d4a371632874c1ca356cff3d \\\n    --hash=sha256:b9f89a454e98806b44fe9d40ec9eee61f848388f7e79ac2371a55679bd5a3ac6 \\\n    --hash=sha256:bb2d109f42190225112da899b9f3d46d0d5f26aef501c61e43529fe9322530b5 \\\n    --hash=sha256:c0a94aba18a35457a1b5cd716fd7b46c5dafdc4cf7869b4bae665b91c4682a8e \\\n    --hash=sha256:c5c8c12e3fda754ef6af94161bacdaeda816d941995fac415d6855c6c386af68 \\\n    --hash=sha256:d1612fcaecd79023dbc6a6ae48d51a80beb5c385d6f3f6d71688e57bc8d07de8 \\\n    --hash=sha256:d16e1f2a073604cfcc09f7131ae8d534674f43c3aef4c25742eae295bc60d04f \\\n    --hash=sha256:d20f2faa3672b52e5013f4077117bfb99c4cfc0b445d3bde1584c34032b57436 \\\n    --hash=sha256:d40fa4106ca6edc66760246a08f500ec0c85ef55c762fb4a363f6ee739ba02ee \\\n    --hash=sha256:de287fabc464b8734be251e46e06aa9aa1001f34198da2b6ce07bd197172b9cb \\\n    --hash=sha256:e4d714371bb08839e4e5e29024fc95832d9affe129825ef38836b143028bd144 \\\n    --hash=sha256:ea9e59e0451e7d29aece402d9f908f2e2a80922bcde2ebfd5dcb07750fcbfee8 \\\n    --hash=sha256:f7ac31b9aecccb2c6e1ab29706f6ded3eba0c2c69c770322c9c685929c3d6afb \\\n    --hash=sha256:fa42a605d099ee7d41ba2b5fb75e21423951fd26e5d50583a00471238fb3021d\n    # via keras-nightly\nflatbuffers==24.3.25 \\\n    --hash=sha256:8dbdec58f935f3765e4f7f3cf635ac3a77f83568138d6a2311f524ec96364812 \\\n    --hash=sha256:de2ec5b203f21441716617f38443e0a8ebf3d25bf0d9c0bb0ce68fa00ad546a4\n    # via -r ci/official/requirements_updater/requirements.in\ngast==0.4.0 \\\n    --hash=sha256:40feb7b8b8434785585ab224d1568b857edb18297e5a3047f1ba012bc83b42c1 \\\n    --hash=sha256:b7adcdd5adbebf1adf17378da5ba3f543684dbec47b1cda1f3997e573cd542c4\n    # via -r ci/official/requirements_updater/requirements.in\ngoogle-pasta==0.2.0 \\\n    --hash=sha256:4612951da876b1a10fe3960d7226f0c7682cf901e16ac06e473b267a5afa8954 \\\n    --hash=sha256:b32482794a366b5366a32c92a9a9201b107821889935a02b3e51f6b432ea84ed \\\n    --hash=sha256:c9f2c8dfc8f96d0d5808299920721be30c9eec37f2389f28904f454565c8a16e\n    # via -r ci/official/requirements_updater/requirements.in\ngrpcio==1.64.1 \\\n    --hash=sha256:03b43d0ccf99c557ec671c7dede64f023c7da9bb632ac65dbc57f166e4970040 \\\n    --hash=sha256:0a12ddb1678ebc6a84ec6b0487feac020ee2b1659cbe69b80f06dbffdb249122 \\\n    --hash=sha256:0a2813093ddb27418a4c99f9b1c223fab0b053157176a64cc9db0f4557b69bd9 \\\n    --hash=sha256:0cc79c982ccb2feec8aad0e8fb0d168bcbca85bc77b080d0d3c5f2f15c24ea8f \\\n    --hash=sha256:1257b76748612aca0f89beec7fa0615727fd6f2a1ad580a9638816a4b2eb18fd \\\n    --hash=sha256:1262402af5a511c245c3ae918167eca57342c72320dffae5d9b51840c4b2f86d \\\n    --hash=sha256:19264fc964576ddb065368cae953f8d0514ecc6cb3da8903766d9fb9d4554c33 \\\n    --hash=sha256:198908f9b22e2672a998870355e226a725aeab327ac4e6ff3a1399792ece4762 \\\n    --hash=sha256:1de403fc1305fd96cfa75e83be3dee8538f2413a6b1685b8452301c7ba33c294 \\\n    --hash=sha256:20405cb8b13fd779135df23fabadc53b86522d0f1cba8cca0e87968587f50650 \\\n    --hash=sha256:2981c7365a9353f9b5c864595c510c983251b1ab403e05b1ccc70a3d9541a73b \\\n    --hash=sha256:2c3c1b90ab93fed424e454e93c0ed0b9d552bdf1b0929712b094f5ecfe7a23ad \\\n    --hash=sha256:39b9d0acaa8d835a6566c640f48b50054f422d03e77e49716d4c4e8e279665a1 \\\n    --hash=sha256:3b64ae304c175671efdaa7ec9ae2cc36996b681eb63ca39c464958396697daff \\\n    --hash=sha256:4657d24c8063e6095f850b68f2d1ba3b39f2b287a38242dcabc166453e950c59 \\\n    --hash=sha256:4d6dab6124225496010bd22690f2d9bd35c7cbb267b3f14e7a3eb05c911325d4 \\\n    --hash=sha256:55260032b95c49bee69a423c2f5365baa9369d2f7d233e933564d8a47b893027 \\\n    --hash=sha256:55697ecec192bc3f2f3cc13a295ab670f51de29884ca9ae6cd6247df55df2502 \\\n    --hash=sha256:5841dd1f284bd1b3d8a6eca3a7f062b06f1eec09b184397e1d1d43447e89a7ae \\\n    --hash=sha256:58b1041e7c870bb30ee41d3090cbd6f0851f30ae4eb68228955d973d3efa2e61 \\\n    --hash=sha256:5e42634a989c3aa6049f132266faf6b949ec2a6f7d302dbb5c15395b77d757eb \\\n    --hash=sha256:5e56462b05a6f860b72f0fa50dca06d5b26543a4e88d0396259a07dc30f4e5aa \\\n    --hash=sha256:5f8b75f64d5d324c565b263c67dbe4f0af595635bbdd93bb1a88189fc62ed2e5 \\\n    --hash=sha256:62b4e6eb7bf901719fce0ca83e3ed474ae5022bb3827b0a501e056458c51c0a1 \\\n    --hash=sha256:6503b64c8b2dfad299749cad1b595c650c91e5b2c8a1b775380fcf8d2cbba1e9 \\\n    --hash=sha256:6c024ffc22d6dc59000faf8ad781696d81e8e38f4078cb0f2630b4a3cf231a90 \\\n    --hash=sha256:73819689c169417a4f978e562d24f2def2be75739c4bed1992435d007819da1b \\\n    --hash=sha256:75dbbf415026d2862192fe1b28d71f209e2fd87079d98470db90bebe57b33179 \\\n    --hash=sha256:8caee47e970b92b3dd948371230fcceb80d3f2277b3bf7fbd7c0564e7d39068e \\\n    --hash=sha256:8d51dd1c59d5fa0f34266b80a3805ec29a1f26425c2a54736133f6d87fc4968a \\\n    --hash=sha256:940e3ec884520155f68a3b712d045e077d61c520a195d1a5932c531f11883489 \\\n    --hash=sha256:a011ac6c03cfe162ff2b727bcb530567826cec85eb8d4ad2bfb4bd023287a52d \\\n    --hash=sha256:a3a035c37ce7565b8f4f35ff683a4db34d24e53dc487e47438e434eb3f701b2a \\\n    --hash=sha256:a5e771d0252e871ce194d0fdcafd13971f1aae0ddacc5f25615030d5df55c3a2 \\\n    --hash=sha256:ac15b6c2c80a4d1338b04d42a02d376a53395ddf0ec9ab157cbaf44191f3ffdd \\\n    --hash=sha256:b1a82e0b9b3022799c336e1fc0f6210adc019ae84efb7321d668129d28ee1efb \\\n    --hash=sha256:bac71b4b28bc9af61efcdc7630b166440bbfbaa80940c9a697271b5e1dabbc61 \\\n    --hash=sha256:bbc5b1d78a7822b0a84c6f8917faa986c1a744e65d762ef6d8be9d75677af2ca \\\n    --hash=sha256:c1a786ac592b47573a5bb7e35665c08064a5d77ab88a076eec11f8ae86b3e3f6 \\\n    --hash=sha256:c84ad903d0d94311a2b7eea608da163dace97c5fe9412ea311e72c3684925602 \\\n    --hash=sha256:d4d29cc612e1332237877dfa7fe687157973aab1d63bd0f84cf06692f04c0367 \\\n    --hash=sha256:e3d9f8d1221baa0ced7ec7322a981e28deb23749c76eeeb3d33e18b72935ab62 \\\n    --hash=sha256:e7cd5c1325f6808b8ae31657d281aadb2a51ac11ab081ae335f4f7fc44c1721d \\\n    --hash=sha256:ed6091fa0adcc7e4ff944090cf203a52da35c37a130efa564ded02b7aff63bcd \\\n    --hash=sha256:ee73a2f5ca4ba44fa33b4d7d2c71e2c8a9e9f78d53f6507ad68e7d2ad5f64a22 \\\n    --hash=sha256:f10193c69fc9d3d726e83bbf0f3d316f1847c3071c8c93d8090cf5f326b14309\n    # via\n    #   -r ci/official/requirements_updater/requirements.in\n    #   tb-nightly\nh5py==3.11.0 \\\n    --hash=sha256:083e0329ae534a264940d6513f47f5ada617da536d8dccbafc3026aefc33c90e \\\n    --hash=sha256:1625fd24ad6cfc9c1ccd44a66dac2396e7ee74940776792772819fc69f3a3731 \\\n    --hash=sha256:21dbdc5343f53b2e25404673c4f00a3335aef25521bd5fa8c707ec3833934892 \\\n    --hash=sha256:52c416f8eb0daae39dabe71415cb531f95dce2d81e1f61a74537a50c63b28ab3 \\\n    --hash=sha256:55106b04e2c83dfb73dc8732e9abad69d83a436b5b82b773481d95d17b9685e1 \\\n    --hash=sha256:67462d0669f8f5459529de179f7771bd697389fcb3faab54d63bf788599a48ea \\\n    --hash=sha256:6c4b760082626120031d7902cd983d8c1f424cdba2809f1067511ef283629d4b \\\n    --hash=sha256:731839240c59ba219d4cb3bc5880d438248533366f102402cfa0621b71796b62 \\\n    --hash=sha256:754c0c2e373d13d6309f408325343b642eb0f40f1a6ad21779cfa9502209e150 \\\n    --hash=sha256:75bd7b3d93fbeee40860fd70cdc88df4464e06b70a5ad9ce1446f5f32eb84007 \\\n    --hash=sha256:77b19a40788e3e362b54af4dcf9e6fde59ca016db2c61360aa30b47c7b7cef00 \\\n    --hash=sha256:7b7e8f78072a2edec87c9836f25f34203fd492a4475709a18b417a33cfb21fa9 \\\n    --hash=sha256:8ec9df3dd2018904c4cc06331951e274f3f3fd091e6d6cc350aaa90fa9b42a76 \\\n    --hash=sha256:a76cae64080210389a571c7d13c94a1a6cf8cb75153044fd1f822a962c97aeab \\\n    --hash=sha256:aa6ae84a14103e8dc19266ef4c3e5d7c00b68f21d07f2966f0ca7bdb6c2761fb \\\n    --hash=sha256:bbd732a08187a9e2a6ecf9e8af713f1d68256ee0f7c8b652a32795670fb481ba \\\n    --hash=sha256:c072655ad1d5fe9ef462445d3e77a8166cbfa5e599045f8aa3c19b75315f10e5 \\\n    --hash=sha256:d9c944d364688f827dc889cf83f1fca311caf4fa50b19f009d1f2b525edd33a3 \\\n    --hash=sha256:ef4e2f338fc763f50a8113890f455e1a70acd42a4d083370ceb80c463d803972 \\\n    --hash=sha256:f3736fe21da2b7d8a13fe8fe415f1272d2a1ccdeff4849c1421d2fb30fd533bc \\\n    --hash=sha256:f4e025e852754ca833401777c25888acb96889ee2c27e7e629a19aee288833f0\n    # via\n    #   -r ci/official/requirements_updater/requirements.in\n    #   keras-nightly\nidna==3.7 \\\n    --hash=sha256:028ff3aadf0609c1fd278d8ea3089299412a7a8b9bd005dd08b9f8285bcb5cfc \\\n    --hash=sha256:82fee1fc78add43492d3a1898bfa6d8a904cc97d8427f683ed8e798d07761aa0\n    # via requests\njax==0.4.7 \\\n    --hash=sha256:5e7002d74db25f97c99b979d4ba1233b1ef26e1597e5fc468ad11d1c8a9dc4f8\n    # via -r ci/official/requirements_updater/requirements.in\nkeras-nightly==3.0.4.dev2024021403 \\\n    --hash=sha256:24ce69d29d582771685bf4235f59663723405b5a5b16f3eaff2657e52e74663a \\\n    --hash=sha256:9f416e66b820ef833779d219d255b346b8b90a72fdbd0b2f1e90a43ad142a03d\n    # via -r ci/official/requirements_updater/requirements.in\nlibclang==18.1.1 \\\n    --hash=sha256:0b2e143f0fac830156feb56f9231ff8338c20aecfe72b4ffe96f19e5a1dbb69a \\\n    --hash=sha256:3f0e1f49f04d3cd198985fea0511576b0aee16f9ff0e0f0cad7f9c57ec3c20e8 \\\n    --hash=sha256:4dd2d3b82fab35e2bf9ca717d7b63ac990a3519c7e312f19fa8e86dcc712f7fb \\\n    --hash=sha256:54dda940a4a0491a9d1532bf071ea3ef26e6dbaf03b5000ed94dd7174e8f9592 \\\n    --hash=sha256:69f8eb8f65c279e765ffd28aaa7e9e364c776c17618af8bff22a8df58677ff4f \\\n    --hash=sha256:6f14c3f194704e5d09769108f03185fce7acaf1d1ae4bbb2f30a72c2400cb7c5 \\\n    --hash=sha256:83ce5045d101b669ac38e6da8e58765f12da2d3aafb3b9b98d88b286a60964d8 \\\n    --hash=sha256:a1214966d08d73d971287fc3ead8dfaf82eb07fb197680d8b3859dbbbbf78250 \\\n    --hash=sha256:c533091d8a3bbf7460a00cb6c1a71da93bffe148f172c7d03b1c31fbf8aa2a0b \\\n    --hash=sha256:cf4a99b05376513717ab5d82a0db832c56ccea4fd61a69dbb7bccf2dfb207dbe\n    # via -r ci/official/requirements_updater/requirements.in\nlit==17.0.6 \\\n    --hash=sha256:dfa9af9b55fc4509a56be7bf2346f079d7f4a242d583b9f2e0b078fd0abae31b\n    # via -r ci/official/requirements_updater/requirements.in\nmarkdown==3.6 \\\n    --hash=sha256:48f276f4d8cfb8ce6527c8f79e2ee29708508bf4d40aa410fbc3b4ee832c850f \\\n    --hash=sha256:ed4f41f6daecbeeb96e576ce414c41d2d876daa9a16cb35fa8ed8c2ddfad0224\n    # via tb-nightly\nmarkdown-it-py==3.0.0 \\\n    --hash=sha256:355216845c60bd96232cd8d8c40e8f9765cc86f46880e43a8fd22dc1a1a8cab1 \\\n    --hash=sha256:e3f60a94fa066dc52ec76661e37c851cb232d92f9886b15cb560aaada2df8feb\n    # via rich\nmarkupsafe==2.1.5 \\\n    --hash=sha256:00e046b6dd71aa03a41079792f8473dc494d564611a8f89bbbd7cb93295ebdcf \\\n    --hash=sha256:075202fa5b72c86ad32dc7d0b56024ebdbcf2048c0ba09f1cde31bfdd57bcfff \\\n    --hash=sha256:0e397ac966fdf721b2c528cf028494e86172b4feba51d65f81ffd65c63798f3f \\\n    --hash=sha256:17b950fccb810b3293638215058e432159d2b71005c74371d784862b7e4683f3 \\\n    --hash=sha256:1f3fbcb7ef1f16e48246f704ab79d79da8a46891e2da03f8783a5b6fa41a9532 \\\n    --hash=sha256:2174c595a0d73a3080ca3257b40096db99799265e1c27cc5a610743acd86d62f \\\n    --hash=sha256:2b7c57a4dfc4f16f7142221afe5ba4e093e09e728ca65c51f5620c9aaeb9a617 \\\n    --hash=sha256:2d2d793e36e230fd32babe143b04cec8a8b3eb8a3122d2aceb4a371e6b09b8df \\\n    --hash=sha256:30b600cf0a7ac9234b2638fbc0fb6158ba5bdcdf46aeb631ead21248b9affbc4 \\\n    --hash=sha256:397081c1a0bfb5124355710fe79478cdbeb39626492b15d399526ae53422b906 \\\n    --hash=sha256:3a57fdd7ce31c7ff06cdfbf31dafa96cc533c21e443d57f5b1ecc6cdc668ec7f \\\n    --hash=sha256:3c6b973f22eb18a789b1460b4b91bf04ae3f0c4234a0a6aa6b0a92f6f7b951d4 \\\n    --hash=sha256:3e53af139f8579a6d5f7b76549125f0d94d7e630761a2111bc431fd820e163b8 \\\n    --hash=sha256:4096e9de5c6fdf43fb4f04c26fb114f61ef0bf2e5604b6ee3019d51b69e8c371 \\\n    --hash=sha256:4275d846e41ecefa46e2015117a9f491e57a71ddd59bbead77e904dc02b1bed2 \\\n    --hash=sha256:4c31f53cdae6ecfa91a77820e8b151dba54ab528ba65dfd235c80b086d68a465 \\\n    --hash=sha256:4f11aa001c540f62c6166c7726f71f7573b52c68c31f014c25cc7901deea0b52 \\\n    --hash=sha256:5049256f536511ee3f7e1b3f87d1d1209d327e818e6ae1365e8653d7e3abb6a6 \\\n    --hash=sha256:58c98fee265677f63a4385256a6d7683ab1832f3ddd1e66fe948d5880c21a169 \\\n    --hash=sha256:598e3276b64aff0e7b3451b72e94fa3c238d452e7ddcd893c3ab324717456bad \\\n    --hash=sha256:5b7b716f97b52c5a14bffdf688f971b2d5ef4029127f1ad7a513973cfd818df2 \\\n    --hash=sha256:5dedb4db619ba5a2787a94d877bc8ffc0566f92a01c0ef214865e54ecc9ee5e0 \\\n    --hash=sha256:619bc166c4f2de5caa5a633b8b7326fbe98e0ccbfacabd87268a2b15ff73a029 \\\n    --hash=sha256:629ddd2ca402ae6dbedfceeba9c46d5f7b2a61d9749597d4307f943ef198fc1f \\\n    --hash=sha256:656f7526c69fac7f600bd1f400991cc282b417d17539a1b228617081106feb4a \\\n    --hash=sha256:6ec585f69cec0aa07d945b20805be741395e28ac1627333b1c5b0105962ffced \\\n    --hash=sha256:72b6be590cc35924b02c78ef34b467da4ba07e4e0f0454a2c5907f473fc50ce5 \\\n    --hash=sha256:7502934a33b54030eaf1194c21c692a534196063db72176b0c4028e140f8f32c \\\n    --hash=sha256:7a68b554d356a91cce1236aa7682dc01df0edba8d043fd1ce607c49dd3c1edcf \\\n    --hash=sha256:7b2e5a267c855eea6b4283940daa6e88a285f5f2a67f2220203786dfa59b37e9 \\\n    --hash=sha256:823b65d8706e32ad2df51ed89496147a42a2a6e01c13cfb6ffb8b1e92bc910bb \\\n    --hash=sha256:8590b4ae07a35970728874632fed7bd57b26b0102df2d2b233b6d9d82f6c62ad \\\n    --hash=sha256:8dd717634f5a044f860435c1d8c16a270ddf0ef8588d4887037c5028b859b0c3 \\\n    --hash=sha256:8dec4936e9c3100156f8a2dc89c4b88d5c435175ff03413b443469c7c8c5f4d1 \\\n    --hash=sha256:97cafb1f3cbcd3fd2b6fbfb99ae11cdb14deea0736fc2b0952ee177f2b813a46 \\\n    --hash=sha256:a17a92de5231666cfbe003f0e4b9b3a7ae3afb1ec2845aadc2bacc93ff85febc \\\n    --hash=sha256:a549b9c31bec33820e885335b451286e2969a2d9e24879f83fe904a5ce59d70a \\\n    --hash=sha256:ac07bad82163452a6884fe8fa0963fb98c2346ba78d779ec06bd7a6262132aee \\\n    --hash=sha256:ae2ad8ae6ebee9d2d94b17fb62763125f3f374c25618198f40cbb8b525411900 \\\n    --hash=sha256:b91c037585eba9095565a3556f611e3cbfaa42ca1e865f7b8015fe5c7336d5a5 \\\n    --hash=sha256:bc1667f8b83f48511b94671e0e441401371dfd0f0a795c7daa4a3cd1dde55bea \\\n    --hash=sha256:bec0a414d016ac1a18862a519e54b2fd0fc8bbfd6890376898a6c0891dd82e9f \\\n    --hash=sha256:bf50cd79a75d181c9181df03572cdce0fbb75cc353bc350712073108cba98de5 \\\n    --hash=sha256:bff1b4290a66b490a2f4719358c0cdcd9bafb6b8f061e45c7a2460866bf50c2e \\\n    --hash=sha256:c061bb86a71b42465156a3ee7bd58c8c2ceacdbeb95d05a99893e08b8467359a \\\n    --hash=sha256:c8b29db45f8fe46ad280a7294f5c3ec36dbac9491f2d1c17345be8e69cc5928f \\\n    --hash=sha256:ce409136744f6521e39fd8e2a24c53fa18ad67aa5bc7c2cf83645cce5b5c4e50 \\\n    --hash=sha256:d050b3361367a06d752db6ead6e7edeb0009be66bc3bae0ee9d97fb326badc2a \\\n    --hash=sha256:d283d37a890ba4c1ae73ffadf8046435c76e7bc2247bbb63c00bd1a709c6544b \\\n    --hash=sha256:d9fad5155d72433c921b782e58892377c44bd6252b5af2f67f16b194987338a4 \\\n    --hash=sha256:daa4ee5a243f0f20d528d939d06670a298dd39b1ad5f8a72a4275124a7819eff \\\n    --hash=sha256:db0b55e0f3cc0be60c1f19efdde9a637c32740486004f20d1cff53c3c0ece4d2 \\\n    --hash=sha256:e61659ba32cf2cf1481e575d0462554625196a1f2fc06a1c777d3f48e8865d46 \\\n    --hash=sha256:ea3d8a3d18833cf4304cd2fc9cbb1efe188ca9b5efef2bdac7adc20594a0e46b \\\n    --hash=sha256:ec6a563cff360b50eed26f13adc43e61bc0c04d94b8be985e6fb24b81f6dcfdf \\\n    --hash=sha256:f5dfb42c4604dddc8e4305050aa6deb084540643ed5804d7455b5df8fe16f5e5 \\\n    --hash=sha256:fa173ec60341d6bb97a89f5ea19c85c5643c1e7dedebc22f5181eb73573142c5 \\\n    --hash=sha256:fa9db3f79de01457b03d4f01b34cf91bc0048eb2c3846ff26f66687c2f6d16ab \\\n    --hash=sha256:fce659a462a1be54d2ffcacea5e3ba2d74daa74f30f5f143fe0c58636e355fdd \\\n    --hash=sha256:ffee1f21e5ef0d712f9033568f8344d5da8cc2869dbd08d87c84656e6a2d2f68\n    # via werkzeug\nmdurl==0.1.2 \\\n    --hash=sha256:84008a41e51615a49fc9966191ff91509e3c40b939176e643fd50a5c2196b8f8 \\\n    --hash=sha256:bb413d29f5eea38f31dd4754dd7377d4465116fb207585f97bf925588687c1ba\n    # via markdown-it-py\nml-dtypes==0.4.0 \\\n    --hash=sha256:03e7cda6ef164eed0abb31df69d2c00c3a5ab3e2610b6d4c42183a43329c72a5 \\\n    --hash=sha256:2bb83fd064db43e67e67d021e547698af4c8d5c6190f2e9b1c53c09f6ff5531d \\\n    --hash=sha256:3b67ec73a697c88c1122038e0de46520e48dc2ec876d42cf61bc5efe3c0b7675 \\\n    --hash=sha256:41affb38fdfe146e3db226cf2953021184d6f0c4ffab52136613e9601706e368 \\\n    --hash=sha256:43cf4356a0fe2eeac6d289018d0734e17a403bdf1fd911953c125dd0358edcc0 \\\n    --hash=sha256:723af6346447268a3cf0b7356e963d80ecb5732b5279b2aa3fa4b9fc8297c85e \\\n    --hash=sha256:75b4faf99d0711b81f393db36d210b4255fd419f6f790bc6c1b461f95ffb7a9e \\\n    --hash=sha256:93afe37f3a879d652ec9ef1fc47612388890660a2657fbb5747256c3b818fd81 \\\n    --hash=sha256:a15d96d090aebb55ee85173d1775ae325a001aab607a76c8ea0b964ccd6b5364 \\\n    --hash=sha256:ad6849a2db386b38e4d54fe13eb3293464561780531a918f8ef4c8169170dd49 \\\n    --hash=sha256:bdf689be7351cc3c95110c910c1b864002f113e682e44508910c849e144f3df1 \\\n    --hash=sha256:c83e4d443962d891d51669ff241d5aaad10a8d3d37a81c5532a45419885d591c \\\n    --hash=sha256:e1e2f4237b459a63c97c2c9f449baa637d7e4c20addff6a9bac486f22432f3b6 \\\n    --hash=sha256:eaa32979ebfde3a0d7c947cafbf79edc1ec77ac05ad0780ee86c1d8df70f2259 \\\n    --hash=sha256:eaf197e72f4f7176a19fe3cb8b61846b38c6757607e7bf9cd4b1d84cd3e74deb \\\n    --hash=sha256:ee9f91d4c4f9959a7e1051c141dc565f39e54435618152219769e24f5e9a4d06 \\\n    --hash=sha256:f1724ddcdf5edbaf615a62110af47407f1719b8d02e68ccee60683acb5f74da1\n    # via\n    #   -r ci/official/requirements_updater/requirements.in\n    #   jax\n    #   keras-nightly\nnamex==0.0.8 \\\n    --hash=sha256:32a50f6c565c0bb10aa76298c959507abdc0e850efe085dc38f3440fcb3aa90b \\\n    --hash=sha256:7ddb6c2bb0e753a311b7590f84f6da659dd0c05e65cb89d519d54c0a250c0487\n    # via keras-nightly\nnumpy==2.1.1 \\\n    --hash=sha256:046356b19d7ad1890c751b99acad5e82dc4a02232013bd9a9a712fddf8eb60f5 \\\n    --hash=sha256:0b8cc2715a84b7c3b161f9ebbd942740aaed913584cae9cdc7f8ad5ad41943d0 \\\n    --hash=sha256:0d07841fd284718feffe7dd17a63a2e6c78679b2d386d3e82f44f0108c905550 \\\n    --hash=sha256:13cc11c00000848702322af4de0147ced365c81d66053a67c2e962a485b3717c \\\n    --hash=sha256:13ce49a34c44b6de5241f0b38b07e44c1b2dcacd9e36c30f9c2fcb1bb5135db7 \\\n    --hash=sha256:24c2ad697bd8593887b019817ddd9974a7f429c14a5469d7fad413f28340a6d2 \\\n    --hash=sha256:251105b7c42abe40e3a689881e1793370cc9724ad50d64b30b358bbb3a97553b \\\n    --hash=sha256:2ca4b53e1e0b279142113b8c5eb7d7a877e967c306edc34f3b58e9be12fda8df \\\n    --hash=sha256:3269c9eb8745e8d975980b3a7411a98976824e1fdef11f0aacf76147f662b15f \\\n    --hash=sha256:397bc5ce62d3fb73f304bec332171535c187e0643e176a6e9421a6e3eacef06d \\\n    --hash=sha256:3fc5eabfc720db95d68e6646e88f8b399bfedd235994016351b1d9e062c4b270 \\\n    --hash=sha256:50a95ca3560a6058d6ea91d4629a83a897ee27c00630aed9d933dff191f170cd \\\n    --hash=sha256:52ac2e48f5ad847cd43c4755520a2317f3380213493b9d8a4c5e37f3b87df504 \\\n    --hash=sha256:53e27293b3a2b661c03f79aa51c3987492bd4641ef933e366e0f9f6c9bf257ec \\\n    --hash=sha256:57eb525e7c2a8fdee02d731f647146ff54ea8c973364f3b850069ffb42799647 \\\n    --hash=sha256:5889dd24f03ca5a5b1e8a90a33b5a0846d8977565e4ae003a63d22ecddf6782f \\\n    --hash=sha256:59ca673ad11d4b84ceb385290ed0ebe60266e356641428c845b39cd9df6713ab \\\n    --hash=sha256:6435c48250c12f001920f0751fe50c0348f5f240852cfddc5e2f97e007544cbe \\\n    --hash=sha256:6e5a9cb2be39350ae6c8f79410744e80154df658d5bea06e06e0ac5bb75480d5 \\\n    --hash=sha256:7be6a07520b88214ea85d8ac8b7d6d8a1839b0b5cb87412ac9f49fa934eb15d5 \\\n    --hash=sha256:7c803b7934a7f59563db459292e6aa078bb38b7ab1446ca38dd138646a38203e \\\n    --hash=sha256:7dd86dfaf7c900c0bbdcb8b16e2f6ddf1eb1fe39c6c8cca6e94844ed3152a8fd \\\n    --hash=sha256:8661c94e3aad18e1ea17a11f60f843a4933ccaf1a25a7c6a9182af70610b2313 \\\n    --hash=sha256:8ae0fd135e0b157365ac7cc31fff27f07a5572bdfc38f9c2d43b2aff416cc8b0 \\\n    --hash=sha256:910b47a6d0635ec1bd53b88f86120a52bf56dcc27b51f18c7b4a2e2224c29f0f \\\n    --hash=sha256:913cc1d311060b1d409e609947fa1b9753701dac96e6581b58afc36b7ee35af6 \\\n    --hash=sha256:920b0911bb2e4414c50e55bd658baeb78281a47feeb064ab40c2b66ecba85553 \\\n    --hash=sha256:950802d17a33c07cba7fd7c3dcfa7d64705509206be1606f196d179e539111ed \\\n    --hash=sha256:981707f6b31b59c0c24bcda52e5605f9701cb46da4b86c2e8023656ad3e833cb \\\n    --hash=sha256:98ce7fb5b8063cfdd86596b9c762bf2b5e35a2cdd7e967494ab78a1fa7f8b86e \\\n    --hash=sha256:99f4a9ee60eed1385a86e82288971a51e71df052ed0b2900ed30bc840c0f2e39 \\\n    --hash=sha256:9a8e06c7a980869ea67bbf551283bbed2856915f0a792dc32dd0f9dd2fb56728 \\\n    --hash=sha256:ae8ce252404cdd4de56dcfce8b11eac3c594a9c16c231d081fb705cf23bd4d9e \\\n    --hash=sha256:afd9c680df4de71cd58582b51e88a61feed4abcc7530bcd3d48483f20fc76f2a \\\n    --hash=sha256:b49742cdb85f1f81e4dc1b39dcf328244f4d8d1ded95dea725b316bd2cf18c95 \\\n    --hash=sha256:b5613cfeb1adfe791e8e681128f5f49f22f3fcaa942255a6124d58ca59d9528f \\\n    --hash=sha256:bab7c09454460a487e631ffc0c42057e3d8f2a9ddccd1e60c7bb8ed774992480 \\\n    --hash=sha256:c8a0e34993b510fc19b9a2ce7f31cb8e94ecf6e924a40c0c9dd4f62d0aac47d9 \\\n    --hash=sha256:caf5d284ddea7462c32b8d4a6b8af030b6c9fd5332afb70e7414d7fdded4bfd0 \\\n    --hash=sha256:cea427d1350f3fd0d2818ce7350095c1a2ee33e30961d2f0fef48576ddbbe90f \\\n    --hash=sha256:d0cf7d55b1051387807405b3898efafa862997b4cba8aa5dbe657be794afeafd \\\n    --hash=sha256:d10c39947a2d351d6d466b4ae83dad4c37cd6c3cdd6d5d0fa797da56f710a6ae \\\n    --hash=sha256:d2b9cd92c8f8e7b313b80e93cedc12c0112088541dcedd9197b5dee3738c1201 \\\n    --hash=sha256:d4c57b68c8ef5e1ebf47238e99bf27657511ec3f071c465f6b1bccbef12d4136 \\\n    --hash=sha256:d51fc141ddbe3f919e91a096ec739f49d686df8af254b2053ba21a910ae518bf \\\n    --hash=sha256:e097507396c0be4e547ff15b13dc3866f45f3680f789c1a1301b07dadd3fbc78 \\\n    --hash=sha256:e30356d530528a42eeba51420ae8bf6c6c09559051887196599d96ee5f536468 \\\n    --hash=sha256:e8d5f8a8e3bc87334f025194c6193e408903d21ebaeb10952264943a985066ca \\\n    --hash=sha256:e8dfa9e94fc127c40979c3eacbae1e61fda4fe71d84869cc129e2721973231ef \\\n    --hash=sha256:f212d4f46b67ff604d11fff7cc62d36b3e8714edf68e44e9760e19be38c03eb0 \\\n    --hash=sha256:f7506387e191fe8cdb267f912469a3cccc538ab108471291636a96a54e599556 \\\n    --hash=sha256:fac6e277a41163d27dfab5f4ec1f7a83fac94e170665a4a50191b545721c6521 \\\n    --hash=sha256:fcd8f556cdc8cfe35e70efb92463082b7f43dd7e547eb071ffc36abc0ca4699b\n    # via\n    #   -r ci/official/requirements_updater/requirements.in\n    #   h5py\n    #   jax\n    #   keras-nightly\n    #   ml-dtypes\n    #   opt-einsum\n    #   scipy\n    #   tb-nightly\nnvidia-cublas-cu12==12.5.3.2 \\\n    --hash=sha256:4960f3dc5f39699acadf76fa6d94b10a2a00f2956c2c442efa299fb22b0748f3 \\\n    --hash=sha256:7d0191251180de606023d396b94d66f66470a0ae96d1dbb906c7656ea0f71eda \\\n    --hash=sha256:ca070ad70e9fa6654084575d01bd001f30cc4665e33d4bb9fc8e0f321caa034b\n    # via\n    #   -r ci/official/requirements_updater/requirements.in\n    #   nvidia-cudnn-cu12\n    #   nvidia-cusolver-cu12\nnvidia-cuda-cupti-cu12==12.5.82 \\\n    --hash=sha256:4f835281cf492e2bedd153f5c3de9da8f1d775a419468305e64ce73b3b0c6dc3 \\\n    --hash=sha256:bde77a5feb66752ec61db2adfe47f56b941842825b4c7e2068aff27c9d107953 \\\n    --hash=sha256:d32c06490c6ba35c4323730820c7d0c4c126c04ed58d2f57275adb8d54b138fe\n    # via -r ci/official/requirements_updater/requirements.in\nnvidia-cuda-nvrtc-cu12==12.5.82 \\\n    --hash=sha256:3dbd97b0104b4bfbc3c4f8c79cd2496307c89c43c29a9f83125f1d76296ff3fd \\\n    --hash=sha256:5bb6a0eb01d4974bb7ca3d48bd3859472debb3c3057a5e7de2b08fbdf35eed7e \\\n    --hash=sha256:e5db37e990056c70953b7772dd778336ef9da0a0b5bb28f9f2a61c2e42b51d78\n    # via -r ci/official/requirements_updater/requirements.in\nnvidia-cuda-runtime-cu12==12.5.82 \\\n    --hash=sha256:0fd5fbca289bceb9f0690aa9858f06187b554fdeb7e2711dfd5bb3ce58900b46 \\\n    --hash=sha256:3e79a060e126df40fd3a068f3f787eb000fa51b251ec6cd97d09579632687115 \\\n    --hash=sha256:71f015dbf9df05dd71f7480132c6ebf47a6ceb2ab53d7db8e08e4b30ebb87e14\n    # via -r ci/official/requirements_updater/requirements.in\nnvidia-cudnn-cu12==9.3.0.75 \\\n    --hash=sha256:9ad9c6929ebb5295eb4a1728024666d1c88283373e265a0c5c883e6f9d5cd76d \\\n    --hash=sha256:c5cf7ff3415e446adf195a5b7dd2ba56cd00c3ee78bfdc566e51698931aa4b7f \\\n    --hash=sha256:c819e82eed8cf564b9d37478ea4eab9e87194bb3b7f7f8098bc1f67c9b80f1b6\n    # via -r ci/official/requirements_updater/requirements.in\nnvidia-cufft-cu12==11.2.3.61 \\\n    --hash=sha256:4a8f6f0ce93c52a50ee83422a80472b5f376054a63f38532d0eab4007e7ef28b \\\n    --hash=sha256:6d45b48a5ee7599e57131129cda2c58544d9b78b95064d3ec3e5c6b96e2b58cc \\\n    --hash=sha256:9a6e8df162585750f61983a638104a48c756aa13f9f48e19ab079b38e3c828b8\n    # via -r ci/official/requirements_updater/requirements.in\nnvidia-curand-cu12==10.3.6.82 \\\n    --hash=sha256:0631ba65231260ad832ce233ddda57e7b3b7158eabf000d78e46cbb5bd5b7aae \\\n    --hash=sha256:2823fb27de4e44dbb22394a6adf53aa6e1b013aca0f8c22867d1cfae58405536 \\\n    --hash=sha256:36aabeb5990297bbce3df324ea7c7c13c3aabb140c86d50ab3b23e4ec61672f1\n    # via -r ci/official/requirements_updater/requirements.in\nnvidia-cusolver-cu12==11.6.3.83 \\\n    --hash=sha256:1b8b77d2fe8abe72bb722dafb708cceaeb81f1a03999477f20b33b34f46ab885 \\\n    --hash=sha256:6224732963cba312a84c78114b9a38c4ffabb2e2a6a120923ac99ba6f895c8cf \\\n    --hash=sha256:93cfafacde4428b71778eeb092ec615a02a3d05404da1bcf91c53e3fa1bce42b\n    # via -r ci/official/requirements_updater/requirements.in\nnvidia-cusparse-cu12==12.5.1.3 \\\n    --hash=sha256:016df8e993c437e8301e62739f01775cba988fd5253cd4c64173f8e8d2f8e752 \\\n    --hash=sha256:33520db374e2f5ebc976d6faa1852b98c398a57e6f71150fe59705928596ffd1 \\\n    --hash=sha256:7b97fd01f0a61628af99d0efd52132fccc8c18fc5c509f13802dccf0574a19c2\n    # via\n    #   -r ci/official/requirements_updater/requirements.in\n    #   nvidia-cusolver-cu12\nnvidia-nccl-cu12==2.23.4 \\\n    --hash=sha256:aa946c8327e22ced28e7cef508a334673abc42064ec85f02d005ba1785ea4cec \\\n    --hash=sha256:b097258d9aab2fa9f686e33c6fe40ae57b27df60cedbd15d139701bb5509e0c1\n    # via -r ci/official/requirements_updater/requirements.in\nnvidia-nvjitlink-cu12==12.5.82 \\\n    --hash=sha256:98103729cc5226e13ca319a10bbf9433bbbd44ef64fe72f45f067cacc14b8d27 \\\n    --hash=sha256:e782564d705ff0bf61ac3e1bf730166da66dd2fe9012f111ede5fc49b64ae697 \\\n    --hash=sha256:f9b37bc5c8cf7509665cb6ada5aaa0ce65618f2332b7d3e78e9790511f111212\n    # via\n    #   -r ci/official/requirements_updater/requirements.in\n    #   nvidia-cufft-cu12\n    #   nvidia-cusolver-cu12\n    #   nvidia-cusparse-cu12\nopt-einsum==3.3.0 \\\n    --hash=sha256:2455e59e3947d3c275477df7f5205b30635e266fe6dc300e3d9f9646bfcea147 \\\n    --hash=sha256:59f6475f77bbc37dcf7cd748519c0ec60722e91e63ca114e68821c0c54a46549\n    # via\n    #   -r ci/official/requirements_updater/requirements.in\n    #   jax\npackaging==23.2 \\\n    --hash=sha256:048fb0e9405036518eaaf48a55953c750c11e1a1b68e0dd1a9d62ed0c092cfc5 \\\n    --hash=sha256:8c491190033a9af7e1d931d0b5dacc2ef47509b34dd0de67ed209b5203fc88c7\n    # via -r ci/official/requirements_updater/requirements.in\n    #   tb-nightly\nportpicker==1.6.0 \\\n    --hash=sha256:b2787a41404cf7edbe29b07b9e0ed863b09f2665dcc01c1eb0c2261c1e7d0755 \\\n    --hash=sha256:bd507fd6f96f65ee02781f2e674e9dc6c99bbfa6e3c39992e3916204c9d431fa\n    # via -r ci/official/requirements_updater/requirements.in\nprotobuf==4.25.3 \\\n    --hash=sha256:19b270aeaa0099f16d3ca02628546b8baefe2955bbe23224aaf856134eccf1e4 \\\n    --hash=sha256:209ba4cc916bab46f64e56b85b090607a676f66b473e6b762e6f1d9d591eb2e8 \\\n    --hash=sha256:25b5d0b42fd000320bd7830b349e3b696435f3b329810427a6bcce6a5492cc5c \\\n    --hash=sha256:7c8daa26095f82482307bc717364e7c13f4f1c99659be82890dcfc215194554d \\\n    --hash=sha256:c053062984e61144385022e53678fbded7aea14ebb3e0305ae3592fb219ccfa4 \\\n    --hash=sha256:d4198877797a83cbfe9bffa3803602bbe1625dc30d8a097365dbc762e5790faa \\\n    --hash=sha256:e3c97a1555fd6388f857770ff8b9703083de6bf1f9274a002a332d65fbb56c8c \\\n    --hash=sha256:e7cb0ae90dd83727f0c0718634ed56837bfeeee29a5f82a7514c03ee1364c019 \\\n    --hash=sha256:f0700d54bcf45424477e46a9f0944155b46fb0639d69728739c0e47bab83f2b9 \\\n    --hash=sha256:f1279ab38ecbfae7e456a108c5c0681e4956d5b1090027c1de0f934dfdb4b35c \\\n    --hash=sha256:f4f118245c4a087776e0a8408be33cf09f6c547442c00395fbfb116fac2f8ac2\n    # via tb-nightly\npsutil==5.9.8 \\\n    --hash=sha256:02615ed8c5ea222323408ceba16c60e99c3f91639b07da6373fb7e6539abc56d \\\n    --hash=sha256:05806de88103b25903dff19bb6692bd2e714ccf9e668d050d144012055cbca73 \\\n    --hash=sha256:26bd09967ae00920df88e0352a91cff1a78f8d69b3ecabbfe733610c0af486c8 \\\n    --hash=sha256:27cc40c3493bb10de1be4b3f07cae4c010ce715290a5be22b98493509c6299e2 \\\n    --hash=sha256:36f435891adb138ed3c9e58c6af3e2e6ca9ac2f365efe1f9cfef2794e6c93b4e \\\n    --hash=sha256:50187900d73c1381ba1454cf40308c2bf6f34268518b3f36a9b663ca87e65e36 \\\n    --hash=sha256:611052c4bc70432ec770d5d54f64206aa7203a101ec273a0cd82418c86503bb7 \\\n    --hash=sha256:6be126e3225486dff286a8fb9a06246a5253f4c7c53b475ea5f5ac934e64194c \\\n    --hash=sha256:7d79560ad97af658a0f6adfef8b834b53f64746d45b403f225b85c5c2c140eee \\\n    --hash=sha256:8cb6403ce6d8e047495a701dc7c5bd788add903f8986d523e3e20b98b733e421 \\\n    --hash=sha256:8db4c1b57507eef143a15a6884ca10f7c73876cdf5d51e713151c1236a0e68cf \\\n    --hash=sha256:aee678c8720623dc456fa20659af736241f575d79429a0e5e9cf88ae0605cc81 \\\n    --hash=sha256:bc56c2a1b0d15aa3eaa5a60c9f3f8e3e565303b465dbf57a1b730e7a2b9844e0 \\\n    --hash=sha256:bd1184ceb3f87651a67b2708d4c3338e9b10c5df903f2e3776b62303b26cb631 \\\n    --hash=sha256:d06016f7f8625a1825ba3732081d77c94589dca78b7a3fc072194851e88461a4 \\\n    --hash=sha256:d16bbddf0693323b8c6123dd804100241da461e41d6e332fb0ba6058f630f8c8\n    # via portpicker\npyelftools==0.31 \\\n    --hash=sha256:c774416b10310156879443b81187d182d8d9ee499660380e645918b50bc88f99 \\\n    --hash=sha256:f52de7b3c7e8c64c8abc04a79a1cf37ac5fb0b8a49809827130b858944840607\n    # via auditwheel\npygments==2.18.0 \\\n    --hash=sha256:786ff802f32e91311bff3889f6e9a86e81505fe99f2735bb6d60ae0c5004f199 \\\n    --hash=sha256:b8e6aca0523f3ab76fee51799c488e38782ac06eafcf95e7ba832985c8e7b13a\n    # via rich\nrequests==2.32.3 \\\n    --hash=sha256:55365417734eb18255590a9ff9eb97e9e1da868d4ccd6402399eaf68af20a760 \\\n    --hash=sha256:70761cfe03c773ceb22aa2f671b4757976145175cdfca038c02654d061d6dcc6\n    # via -r ci/official/requirements_updater/requirements.in\nrich==13.7.1 \\\n    --hash=sha256:4edbae314f59eb482f54e9e30bf00d33350aaa94f4bfcd4e9e3110e64d0d7222 \\\n    --hash=sha256:9be308cb1fe2f1f57d67ce99e95af38a1e2bc71ad9813b0e247cf7ffbcc3a432\n    # via keras-nightly\nscipy==1.13.1 \\\n    --hash=sha256:017367484ce5498445aade74b1d5ab377acdc65e27095155e448c88497755a5d \\\n    --hash=sha256:095a87a0312b08dfd6a6155cbbd310a8c51800fc931b8c0b84003014b874ed3c \\\n    --hash=sha256:20335853b85e9a49ff7572ab453794298bcf0354d8068c5f6775a0eabf350aca \\\n    --hash=sha256:27e52b09c0d3a1d5b63e1105f24177e544a222b43611aaf5bc44d4a0979e32f9 \\\n    --hash=sha256:2831f0dc9c5ea9edd6e51e6e769b655f08ec6db6e2e10f86ef39bd32eb11da54 \\\n    --hash=sha256:2ac65fb503dad64218c228e2dc2d0a0193f7904747db43014645ae139c8fad16 \\\n    --hash=sha256:392e4ec766654852c25ebad4f64e4e584cf19820b980bc04960bca0b0cd6eaa2 \\\n    --hash=sha256:436bbb42a94a8aeef855d755ce5a465479c721e9d684de76bf61a62e7c2b81d5 \\\n    --hash=sha256:45484bee6d65633752c490404513b9ef02475b4284c4cfab0ef946def50b3f59 \\\n    --hash=sha256:54f430b00f0133e2224c3ba42b805bfd0086fe488835effa33fa291561932326 \\\n    --hash=sha256:5713f62f781eebd8d597eb3f88b8bf9274e79eeabf63afb4a737abc6c84ad37b \\\n    --hash=sha256:5d72782f39716b2b3509cd7c33cdc08c96f2f4d2b06d51e52fb45a19ca0c86a1 \\\n    --hash=sha256:637e98dcf185ba7f8e663e122ebf908c4702420477ae52a04f9908707456ba4d \\\n    --hash=sha256:8335549ebbca860c52bf3d02f80784e91a004b71b059e3eea9678ba994796a24 \\\n    --hash=sha256:949ae67db5fa78a86e8fa644b9a6b07252f449dcf74247108c50e1d20d2b4627 \\\n    --hash=sha256:a014c2b3697bde71724244f63de2476925596c24285c7a637364761f8710891c \\\n    --hash=sha256:a78b4b3345f1b6f68a763c6e25c0c9a23a9fd0f39f5f3d200efe8feda560a5fa \\\n    --hash=sha256:cdd7dacfb95fea358916410ec61bbc20440f7860333aee6d882bb8046264e949 \\\n    --hash=sha256:cfa31f1def5c819b19ecc3a8b52d28ffdcc7ed52bb20c9a7589669dd3c250989 \\\n    --hash=sha256:d533654b7d221a6a97304ab63c41c96473ff04459e404b83275b60aa8f4b7004 \\\n    --hash=sha256:d605e9c23906d1994f55ace80e0125c587f96c020037ea6aa98d01b4bd2e222f \\\n    --hash=sha256:de3ade0e53bc1f21358aa74ff4830235d716211d7d077e340c7349bc3542e884 \\\n    --hash=sha256:e89369d27f9e7b0884ae559a3a956e77c02114cc60a6058b4e5011572eea9299 \\\n    --hash=sha256:eccfa1906eacc02de42d70ef4aecea45415f5be17e72b61bafcfd329bdc52e94 \\\n    --hash=sha256:f26264b282b9da0952a024ae34710c2aff7d27480ee91a2e82b7b7073c24722f\n    # via\n    #   -r ci/official/requirements_updater/requirements.in\n    #   jax\nsix==1.16.0 \\\n    --hash=sha256:1e61c37477a1626458e36f7b1d82aa5c9b094fa4802892072e49de9c60c4c926 \\\n    --hash=sha256:8abb2f1d86890a2dfb989f9a77cfcfd3e47c2a354b01111771326f8aa26e0254\n    # via\n    #   astunparse\n    #   google-pasta\n    #   tb-nightly\ntb-nightly==2.19.0a20240926 \\\n    --hash=sha256:4f2f4dd02eda684fbb2edd9cb46b7bd0ee7ba6ca35d38e4de2e293df8567c1b4\n    # via -r ci/official/requirements_updater/requirements.in\ntblib==2.0.0 \\\n    --hash=sha256:9100bfa016b047d5b980d66e7efed952fbd20bd85b56110aaf473cb97d18709a \\\n    --hash=sha256:a6df30f272c08bf8be66e0775fad862005d950a6b8449b94f7c788731d70ecd7\n    # via -r ci/official/requirements_updater/requirements.in\ntensorboard-data-server==0.7.2 \\\n    --hash=sha256:7e0610d205889588983836ec05dc098e80f97b7e7bbff7e994ebb78f578d0ddb \\\n    --hash=sha256:9fe5d24221b29625dbc7328b0436ca7fc1c23de4acf4d272f1180856e32f9f60 \\\n    --hash=sha256:ef687163c24185ae9754ed5650eb5bc4d84ff257aabdc33f0cc6f74d8ba54530\n    # via tb-nightly\ntensorflow-io-gcs-filesystem==0.37.1 \\\n    --hash=sha256:0df00891669390078a003cedbdd3b8e645c718b111917535fa1d7725e95cdb95 \\\n    --hash=sha256:249c12b830165841411ba71e08215d0e94277a49c551e6dd5d72aab54fe5491b \\\n    --hash=sha256:257aab23470a0796978efc9c2bcf8b0bc80f22e6298612a4c0a50d3f4e88060c \\\n    --hash=sha256:286389a203a5aee1a4fa2e53718c661091aa5fea797ff4fa6715ab8436b02e6c \\\n    --hash=sha256:32c50ab4e29a23c1f91cd0f9ab8c381a0ab10f45ef5c5252e94965916041737c \\\n    --hash=sha256:426de1173cb81fbd62becec2012fc00322a295326d90eb6c737fab636f182aed \\\n    --hash=sha256:6e1f2796b57e799a8ca1b75bf47c2aaa437c968408cc1a402a9862929e104cda \\\n    --hash=sha256:8943036bbf84e7a2be3705cb56f9c9df7c48c9e614bb941f0936c58e3ca89d6f \\\n    --hash=sha256:8febbfcc67c61e542a5ac1a98c7c20a91a5e1afc2e14b1ef0cb7c28bc3b6aa70 \\\n    --hash=sha256:9679b36e3a80921876f31685ab6f7270f3411a4cc51bc2847e80d0e4b5291e27 \\\n    --hash=sha256:b02f9c5f94fd62773954a04f69b68c4d576d076fd0db4ca25d5479f0fbfcdbad \\\n    --hash=sha256:ee5da49019670ed364f3e5fb86b46420841a6c3cb52a300553c63841671b3e6d \\\n    --hash=sha256:ee7c8ee5fe2fd8cb6392669ef16e71841133041fee8a330eff519ad9b36e4556 \\\n    --hash=sha256:fbb33f1745f218464a59cecd9a18e32ca927b0f4d77abd8f8671b645cc1a182f \\\n    --hash=sha256:fe8dcc6d222258a080ac3dfcaaaa347325ce36a7a046277f6b3e19abc1efb3c5 \\\n    --hash=sha256:ffebb6666a7bfc28005f4fbbb111a455b5e7d6cd3b12752b7050863ecb27d5cc\n    # via -r ci/official/requirements_updater/requirements.in\ntermcolor==2.3.0 \\\n    --hash=sha256:3afb05607b89aed0ffe25202399ee0867ad4d3cb4180d98aaf8eefa6a5f7d475 \\\n    --hash=sha256:b5b08f68937f138fe92f6c089b99f1e2da0ae56c52b78bf7075fd95420fd9a5a\n    # via -r ci/official/requirements_updater/requirements.in\ntyping-extensions==4.8.0 \\\n    --hash=sha256:8f92fc8806f9a6b641eaa5318da32b44d401efaac0f6678c9bc448ba3605faa0 \\\n    --hash=sha256:df8e4339e9cb77357558cbdbceca33c303714cf861d1eef15e1070055ae8b7ef\n    # via -r ci/official/requirements_updater/requirements.in\nurllib3==2.2.2 \\\n    --hash=sha256:a448b2f64d686155468037e1ace9f2d2199776e17f0a46610480d311f73e3472 \\\n    --hash=sha256:dd505485549a7a552833da5e6063639d0d177c04f23bc3864e41e5dc5f612168\n    # via requests\nwerkzeug==3.0.6 \\\n    --hash=sha256:1bc0c2310d2fbb07b1dd1105eba2f7af72f322e1e455f2f93c993bee8c8a5f17 \\\n    --hash=sha256:a8dd59d4de28ca70471a34cba79bed5f7ef2e036a76b3ab0835474246eb41f8d\n    # via tb-nightly\nwheel==0.41.3 \\\n    --hash=sha256:488609bc63a29322326e05560731bf7bfea8e48ad646e1f5e40d366607de0942 \\\n    --hash=sha256:4d4987ce51a49370ea65c0bfd2234e8ce80a12780820d9dc462597a6e60d0841\n    # via\n    #   -r ci/official/requirements_updater/requirements.in\n    #   astunparse\nwrapt==1.16.0 \\\n    --hash=sha256:0d2691979e93d06a95a26257adb7bfd0c93818e89b1406f5a28f36e0d8c1e1fc \\\n    --hash=sha256:14d7dc606219cdd7405133c713f2c218d4252f2a469003f8c46bb92d5d095d81 \\\n    --hash=sha256:1a5db485fe2de4403f13fafdc231b0dbae5eca4359232d2efc79025527375b09 \\\n    --hash=sha256:1acd723ee2a8826f3d53910255643e33673e1d11db84ce5880675954183ec47e \\\n    --hash=sha256:1ca9b6085e4f866bd584fb135a041bfc32cab916e69f714a7d1d397f8c4891ca \\\n    --hash=sha256:1dd50a2696ff89f57bd8847647a1c363b687d3d796dc30d4dd4a9d1689a706f0 \\\n    --hash=sha256:2076fad65c6736184e77d7d4729b63a6d1ae0b70da4868adeec40989858eb3fb \\\n    --hash=sha256:2a88e6010048489cda82b1326889ec075a8c856c2e6a256072b28eaee3ccf487 \\\n    --hash=sha256:3ebf019be5c09d400cf7b024aa52b1f3aeebeff51550d007e92c3c1c4afc2a40 \\\n    --hash=sha256:418abb18146475c310d7a6dc71143d6f7adec5b004ac9ce08dc7a34e2babdc5c \\\n    --hash=sha256:43aa59eadec7890d9958748db829df269f0368521ba6dc68cc172d5d03ed8060 \\\n    --hash=sha256:44a2754372e32ab315734c6c73b24351d06e77ffff6ae27d2ecf14cf3d229202 \\\n    --hash=sha256:490b0ee15c1a55be9c1bd8609b8cecd60e325f0575fc98f50058eae366e01f41 \\\n    --hash=sha256:49aac49dc4782cb04f58986e81ea0b4768e4ff197b57324dcbd7699c5dfb40b9 \\\n    --hash=sha256:5eb404d89131ec9b4f748fa5cfb5346802e5ee8836f57d516576e61f304f3b7b \\\n    --hash=sha256:5f15814a33e42b04e3de432e573aa557f9f0f56458745c2074952f564c50e664 \\\n    --hash=sha256:5f370f952971e7d17c7d1ead40e49f32345a7f7a5373571ef44d800d06b1899d \\\n    --hash=sha256:66027d667efe95cc4fa945af59f92c5a02c6f5bb6012bff9e60542c74c75c362 \\\n    --hash=sha256:66dfbaa7cfa3eb707bbfcd46dab2bc6207b005cbc9caa2199bcbc81d95071a00 \\\n    --hash=sha256:685f568fa5e627e93f3b52fda002c7ed2fa1800b50ce51f6ed1d572d8ab3e7fc \\\n    --hash=sha256:6906c4100a8fcbf2fa735f6059214bb13b97f75b1a61777fcf6432121ef12ef1 \\\n    --hash=sha256:6a42cd0cfa8ffc1915aef79cb4284f6383d8a3e9dcca70c445dcfdd639d51267 \\\n    --hash=sha256:6dcfcffe73710be01d90cae08c3e548d90932d37b39ef83969ae135d36ef3956 \\\n    --hash=sha256:6f6eac2360f2d543cc875a0e5efd413b6cbd483cb3ad7ebf888884a6e0d2e966 \\\n    --hash=sha256:72554a23c78a8e7aa02abbd699d129eead8b147a23c56e08d08dfc29cfdddca1 \\\n    --hash=sha256:73870c364c11f03ed072dda68ff7aea6d2a3a5c3fe250d917a429c7432e15228 \\\n    --hash=sha256:73aa7d98215d39b8455f103de64391cb79dfcad601701a3aa0dddacf74911d72 \\\n    --hash=sha256:75ea7d0ee2a15733684badb16de6794894ed9c55aa5e9903260922f0482e687d \\\n    --hash=sha256:7bd2d7ff69a2cac767fbf7a2b206add2e9a210e57947dd7ce03e25d03d2de292 \\\n    --hash=sha256:807cc8543a477ab7422f1120a217054f958a66ef7314f76dd9e77d3f02cdccd0 \\\n    --hash=sha256:8e9723528b9f787dc59168369e42ae1c3b0d3fadb2f1a71de14531d321ee05b0 \\\n    --hash=sha256:9090c9e676d5236a6948330e83cb89969f433b1943a558968f659ead07cb3b36 \\\n    --hash=sha256:9153ed35fc5e4fa3b2fe97bddaa7cbec0ed22412b85bcdaf54aeba92ea37428c \\\n    --hash=sha256:9159485323798c8dc530a224bd3ffcf76659319ccc7bbd52e01e73bd0241a0c5 \\\n    --hash=sha256:941988b89b4fd6b41c3f0bfb20e92bd23746579736b7343283297c4c8cbae68f \\\n    --hash=sha256:94265b00870aa407bd0cbcfd536f17ecde43b94fb8d228560a1e9d3041462d73 \\\n    --hash=sha256:98b5e1f498a8ca1858a1cdbffb023bfd954da4e3fa2c0cb5853d40014557248b \\\n    --hash=sha256:9b201ae332c3637a42f02d1045e1d0cccfdc41f1f2f801dafbaa7e9b4797bfc2 \\\n    --hash=sha256:a0ea261ce52b5952bf669684a251a66df239ec6d441ccb59ec7afa882265d593 \\\n    --hash=sha256:a33a747400b94b6d6b8a165e4480264a64a78c8a4c734b62136062e9a248dd39 \\\n    --hash=sha256:a452f9ca3e3267cd4d0fcf2edd0d035b1934ac2bd7e0e57ac91ad6b95c0c6389 \\\n    --hash=sha256:a86373cf37cd7764f2201b76496aba58a52e76dedfaa698ef9e9688bfd9e41cf \\\n    --hash=sha256:ac83a914ebaf589b69f7d0a1277602ff494e21f4c2f743313414378f8f50a4cf \\\n    --hash=sha256:aefbc4cb0a54f91af643660a0a150ce2c090d3652cf4052a5397fb2de549cd89 \\\n    --hash=sha256:b3646eefa23daeba62643a58aac816945cadc0afaf21800a1421eeba5f6cfb9c \\\n    --hash=sha256:b47cfad9e9bbbed2339081f4e346c93ecd7ab504299403320bf85f7f85c7d46c \\\n    --hash=sha256:b935ae30c6e7400022b50f8d359c03ed233d45b725cfdd299462f41ee5ffba6f \\\n    --hash=sha256:bb2dee3874a500de01c93d5c71415fcaef1d858370d405824783e7a8ef5db440 \\\n    --hash=sha256:bc57efac2da352a51cc4658878a68d2b1b67dbe9d33c36cb826ca449d80a8465 \\\n    --hash=sha256:bf5703fdeb350e36885f2875d853ce13172ae281c56e509f4e6eca049bdfb136 \\\n    --hash=sha256:c31f72b1b6624c9d863fc095da460802f43a7c6868c5dda140f51da24fd47d7b \\\n    --hash=sha256:c5cd603b575ebceca7da5a3a251e69561bec509e0b46e4993e1cac402b7247b8 \\\n    --hash=sha256:d2efee35b4b0a347e0d99d28e884dfd82797852d62fcd7ebdeee26f3ceb72cf3 \\\n    --hash=sha256:d462f28826f4657968ae51d2181a074dfe03c200d6131690b7d65d55b0f360f8 \\\n    --hash=sha256:d5e49454f19ef621089e204f862388d29e6e8d8b162efce05208913dde5b9ad6 \\\n    --hash=sha256:da4813f751142436b075ed7aa012a8778aa43a99f7b36afe9b742d3ed8bdc95e \\\n    --hash=sha256:db2e408d983b0e61e238cf579c09ef7020560441906ca990fe8412153e3b291f \\\n    --hash=sha256:db98ad84a55eb09b3c32a96c576476777e87c520a34e2519d3e59c44710c002c \\\n    --hash=sha256:dbed418ba5c3dce92619656802cc5355cb679e58d0d89b50f116e4a9d5a9603e \\\n    --hash=sha256:dcdba5c86e368442528f7060039eda390cc4091bfd1dca41e8046af7c910dda8 \\\n    --hash=sha256:decbfa2f618fa8ed81c95ee18a387ff973143c656ef800c9f24fb7e9c16054e2 \\\n    --hash=sha256:e4fdb9275308292e880dcbeb12546df7f3e0f96c6b41197e0cf37d2826359020 \\\n    --hash=sha256:eb1b046be06b0fce7249f1d025cd359b4b80fc1c3e24ad9eca33e0dcdb2e4a35 \\\n    --hash=sha256:eb6e651000a19c96f452c85132811d25e9264d836951022d6e81df2fff38337d \\\n    --hash=sha256:ed867c42c268f876097248e05b6117a65bcd1e63b779e916fe2e33cd6fd0d3c3 \\\n    --hash=sha256:edfad1d29c73f9b863ebe7082ae9321374ccb10879eeabc84ba3b69f2579d537 \\\n    --hash=sha256:f2058f813d4f2b5e3a9eb2eb3faf8f1d99b81c3e51aeda4b168406443e8ba809 \\\n    --hash=sha256:f6b2d0c6703c988d334f297aa5df18c45e97b0af3679bb75059e0e0bd8b1069d \\\n    --hash=sha256:f8212564d49c50eb4565e502814f694e240c55551a5f1bc841d4fcaabb0a9b8a \\\n    --hash=sha256:ffa565331890b90056c01db69c0fe634a776f8019c143a5ae265f9c6bc4bd6d4\n    # via -r ci/official/requirements_updater/requirements.in\n\n# The following packages are considered to be unsafe in a requirements file:\nsetuptools==70.0.0 \\\n    --hash=sha256:54faa7f2e8d2d11bcd2c07bed282eef1046b5c080d1c32add737d7b5817b1ad4 \\\n    --hash=sha256:f211a66637b8fa059bb28183da127d4e86396c991a942b028c6650d4319c3fd0\n    # via\n    #   -r ci/official/requirements_updater/requirements.in\n    #   tb-nightly\n"
        },
        {
          "name": "requirements_lock_3_12.txt",
          "type": "blob",
          "size": 52.8359375,
          "content": "#\n# This file is autogenerated by pip-compile with Python 3.12\n# by the following command:\n#\n#    bazel run //ci/official/requirements_updater:requirements.update\n#\nabsl-py==2.1.0 \\\n    --hash=sha256:526a04eadab8b4ee719ce68f204172ead1027549089702d99b9059f129ff1308 \\\n    --hash=sha256:7820790efbb316739cde8b4e19357243fc3608a152024288513dd968d7d959ff\n    # via\n    #   keras-nightly\n    #   tb-nightly\nastor==0.7.1 \\\n    --hash=sha256:95c30d87a6c2cf89aa628b87398466840f0ad8652f88eb173125a6df8533fb8d \\\n    --hash=sha256:fb503b9e2fdd05609fbf557b916b4a7824171203701660f0c55bbf5a7a68713e\n    # via -r ci/official/requirements_updater/requirements.in\nastunparse==1.6.3 \\\n    --hash=sha256:5ad93a8456f0d084c3456d059fd9a92cce667963232cbf763eac3bc5b7940872 \\\n    --hash=sha256:c2652417f2c8b5bb325c885ae329bdf3f86424075c4fd1a128674bc6fba4b8e8\n    # via -r ci/official/requirements_updater/requirements.in\nauditwheel==6.1.0 \\\n    --hash=sha256:3bdc686e774cf9e355e924b0fe5a562d55caa385d72234ffe7b81b378dba360f \\\n    --hash=sha256:e52f734861859e3743eb29fcac7da9c4921a1e4bea58f954b52f2926f8e9e364\n    # via -r ci/official/requirements_updater/requirements.in\ncertifi==2024.7.4 \\\n    --hash=sha256:5a1e7645bc0ec61a09e26c36f6106dd4cf40c6db3a1fb6352b0244e7fb057c7b \\\n    --hash=sha256:c198e21b1289c2ab85ee4e67bb4b4ef3ead0892059901a8d5b622f24a1101e90\n    # via requests\ncharset-normalizer==3.3.2 \\\n    --hash=sha256:06435b539f889b1f6f4ac1758871aae42dc3a8c0e24ac9e60c2384973ad73027 \\\n    --hash=sha256:06a81e93cd441c56a9b65d8e1d043daeb97a3d0856d177d5c90ba85acb3db087 \\\n    --hash=sha256:0a55554a2fa0d408816b3b5cedf0045f4b8e1a6065aec45849de2d6f3f8e9786 \\\n    --hash=sha256:0b2b64d2bb6d3fb9112bafa732def486049e63de9618b5843bcdd081d8144cd8 \\\n    --hash=sha256:10955842570876604d404661fbccbc9c7e684caf432c09c715ec38fbae45ae09 \\\n    --hash=sha256:122c7fa62b130ed55f8f285bfd56d5f4b4a5b503609d181f9ad85e55c89f4185 \\\n    --hash=sha256:1ceae2f17a9c33cb48e3263960dc5fc8005351ee19db217e9b1bb15d28c02574 \\\n    --hash=sha256:1d3193f4a680c64b4b6a9115943538edb896edc190f0b222e73761716519268e \\\n    --hash=sha256:1f79682fbe303db92bc2b1136016a38a42e835d932bab5b3b1bfcfbf0640e519 \\\n    --hash=sha256:2127566c664442652f024c837091890cb1942c30937add288223dc895793f898 \\\n    --hash=sha256:22afcb9f253dac0696b5a4be4a1c0f8762f8239e21b99680099abd9b2b1b2269 \\\n    --hash=sha256:25baf083bf6f6b341f4121c2f3c548875ee6f5339300e08be3f2b2ba1721cdd3 \\\n    --hash=sha256:2e81c7b9c8979ce92ed306c249d46894776a909505d8f5a4ba55b14206e3222f \\\n    --hash=sha256:3287761bc4ee9e33561a7e058c72ac0938c4f57fe49a09eae428fd88aafe7bb6 \\\n    --hash=sha256:34d1c8da1e78d2e001f363791c98a272bb734000fcef47a491c1e3b0505657a8 \\\n    --hash=sha256:37e55c8e51c236f95b033f6fb391d7d7970ba5fe7ff453dad675e88cf303377a \\\n    --hash=sha256:3d47fa203a7bd9c5b6cee4736ee84ca03b8ef23193c0d1ca99b5089f72645c73 \\\n    --hash=sha256:3e4d1f6587322d2788836a99c69062fbb091331ec940e02d12d179c1d53e25fc \\\n    --hash=sha256:42cb296636fcc8b0644486d15c12376cb9fa75443e00fb25de0b8602e64c1714 \\\n    --hash=sha256:45485e01ff4d3630ec0d9617310448a8702f70e9c01906b0d0118bdf9d124cf2 \\\n    --hash=sha256:4a78b2b446bd7c934f5dcedc588903fb2f5eec172f3d29e52a9096a43722adfc \\\n    --hash=sha256:4ab2fe47fae9e0f9dee8c04187ce5d09f48eabe611be8259444906793ab7cbce \\\n    --hash=sha256:4d0d1650369165a14e14e1e47b372cfcb31d6ab44e6e33cb2d4e57265290044d \\\n    --hash=sha256:549a3a73da901d5bc3ce8d24e0600d1fa85524c10287f6004fbab87672bf3e1e \\\n    --hash=sha256:55086ee1064215781fff39a1af09518bc9255b50d6333f2e4c74ca09fac6a8f6 \\\n    --hash=sha256:572c3763a264ba47b3cf708a44ce965d98555f618ca42c926a9c1616d8f34269 \\\n    --hash=sha256:573f6eac48f4769d667c4442081b1794f52919e7edada77495aaed9236d13a96 \\\n    --hash=sha256:5b4c145409bef602a690e7cfad0a15a55c13320ff7a3ad7ca59c13bb8ba4d45d \\\n    --hash=sha256:6463effa3186ea09411d50efc7d85360b38d5f09b870c48e4600f63af490e56a \\\n    --hash=sha256:65f6f63034100ead094b8744b3b97965785388f308a64cf8d7c34f2f2e5be0c4 \\\n    --hash=sha256:663946639d296df6a2bb2aa51b60a2454ca1cb29835324c640dafb5ff2131a77 \\\n    --hash=sha256:6897af51655e3691ff853668779c7bad41579facacf5fd7253b0133308cf000d \\\n    --hash=sha256:68d1f8a9e9e37c1223b656399be5d6b448dea850bed7d0f87a8311f1ff3dabb0 \\\n    --hash=sha256:6ac7ffc7ad6d040517be39eb591cac5ff87416c2537df6ba3cba3bae290c0fed \\\n    --hash=sha256:6b3251890fff30ee142c44144871185dbe13b11bab478a88887a639655be1068 \\\n    --hash=sha256:6c4caeef8fa63d06bd437cd4bdcf3ffefe6738fb1b25951440d80dc7df8c03ac \\\n    --hash=sha256:6ef1d82a3af9d3eecdba2321dc1b3c238245d890843e040e41e470ffa64c3e25 \\\n    --hash=sha256:753f10e867343b4511128c6ed8c82f7bec3bd026875576dfd88483c5c73b2fd8 \\\n    --hash=sha256:7cd13a2e3ddeed6913a65e66e94b51d80a041145a026c27e6bb76c31a853c6ab \\\n    --hash=sha256:7ed9e526742851e8d5cc9e6cf41427dfc6068d4f5a3bb03659444b4cabf6bc26 \\\n    --hash=sha256:7f04c839ed0b6b98b1a7501a002144b76c18fb1c1850c8b98d458ac269e26ed2 \\\n    --hash=sha256:802fe99cca7457642125a8a88a084cef28ff0cf9407060f7b93dca5aa25480db \\\n    --hash=sha256:80402cd6ee291dcb72644d6eac93785fe2c8b9cb30893c1af5b8fdd753b9d40f \\\n    --hash=sha256:8465322196c8b4d7ab6d1e049e4c5cb460d0394da4a27d23cc242fbf0034b6b5 \\\n    --hash=sha256:86216b5cee4b06df986d214f664305142d9c76df9b6512be2738aa72a2048f99 \\\n    --hash=sha256:87d1351268731db79e0f8e745d92493ee2841c974128ef629dc518b937d9194c \\\n    --hash=sha256:8bdb58ff7ba23002a4c5808d608e4e6c687175724f54a5dade5fa8c67b604e4d \\\n    --hash=sha256:8c622a5fe39a48f78944a87d4fb8a53ee07344641b0562c540d840748571b811 \\\n    --hash=sha256:8d756e44e94489e49571086ef83b2bb8ce311e730092d2c34ca8f7d925cb20aa \\\n    --hash=sha256:8f4a014bc36d3c57402e2977dada34f9c12300af536839dc38c0beab8878f38a \\\n    --hash=sha256:9063e24fdb1e498ab71cb7419e24622516c4a04476b17a2dab57e8baa30d6e03 \\\n    --hash=sha256:90d558489962fd4918143277a773316e56c72da56ec7aa3dc3dbbe20fdfed15b \\\n    --hash=sha256:923c0c831b7cfcb071580d3f46c4baf50f174be571576556269530f4bbd79d04 \\\n    --hash=sha256:95f2a5796329323b8f0512e09dbb7a1860c46a39da62ecb2324f116fa8fdc85c \\\n    --hash=sha256:96b02a3dc4381e5494fad39be677abcb5e6634bf7b4fa83a6dd3112607547001 \\\n    --hash=sha256:9f96df6923e21816da7e0ad3fd47dd8f94b2a5ce594e00677c0013018b813458 \\\n    --hash=sha256:a10af20b82360ab00827f916a6058451b723b4e65030c5a18577c8b2de5b3389 \\\n    --hash=sha256:a50aebfa173e157099939b17f18600f72f84eed3049e743b68ad15bd69b6bf99 \\\n    --hash=sha256:a981a536974bbc7a512cf44ed14938cf01030a99e9b3a06dd59578882f06f985 \\\n    --hash=sha256:a9a8e9031d613fd2009c182b69c7b2c1ef8239a0efb1df3f7c8da66d5dd3d537 \\\n    --hash=sha256:ae5f4161f18c61806f411a13b0310bea87f987c7d2ecdbdaad0e94eb2e404238 \\\n    --hash=sha256:aed38f6e4fb3f5d6bf81bfa990a07806be9d83cf7bacef998ab1a9bd660a581f \\\n    --hash=sha256:b01b88d45a6fcb69667cd6d2f7a9aeb4bf53760d7fc536bf679ec94fe9f3ff3d \\\n    --hash=sha256:b261ccdec7821281dade748d088bb6e9b69e6d15b30652b74cbbac25e280b796 \\\n    --hash=sha256:b2b0a0c0517616b6869869f8c581d4eb2dd83a4d79e0ebcb7d373ef9956aeb0a \\\n    --hash=sha256:b4a23f61ce87adf89be746c8a8974fe1c823c891d8f86eb218bb957c924bb143 \\\n    --hash=sha256:bd8f7df7d12c2db9fab40bdd87a7c09b1530128315d047a086fa3ae3435cb3a8 \\\n    --hash=sha256:beb58fe5cdb101e3a055192ac291b7a21e3b7ef4f67fa1d74e331a7f2124341c \\\n    --hash=sha256:c002b4ffc0be611f0d9da932eb0f704fe2602a9a949d1f738e4c34c75b0863d5 \\\n    --hash=sha256:c083af607d2515612056a31f0a8d9e0fcb5876b7bfc0abad3ecd275bc4ebc2d5 \\\n    --hash=sha256:c180f51afb394e165eafe4ac2936a14bee3eb10debc9d9e4db8958fe36afe711 \\\n    --hash=sha256:c235ebd9baae02f1b77bcea61bce332cb4331dc3617d254df3323aa01ab47bd4 \\\n    --hash=sha256:cd70574b12bb8a4d2aaa0094515df2463cb429d8536cfb6c7ce983246983e5a6 \\\n    --hash=sha256:d0eccceffcb53201b5bfebb52600a5fb483a20b61da9dbc885f8b103cbe7598c \\\n    --hash=sha256:d965bba47ddeec8cd560687584e88cf699fd28f192ceb452d1d7ee807c5597b7 \\\n    --hash=sha256:db364eca23f876da6f9e16c9da0df51aa4f104a972735574842618b8c6d999d4 \\\n    --hash=sha256:ddbb2551d7e0102e7252db79ba445cdab71b26640817ab1e3e3648dad515003b \\\n    --hash=sha256:deb6be0ac38ece9ba87dea880e438f25ca3eddfac8b002a2ec3d9183a454e8ae \\\n    --hash=sha256:e06ed3eb3218bc64786f7db41917d4e686cc4856944f53d5bdf83a6884432e12 \\\n    --hash=sha256:e27ad930a842b4c5eb8ac0016b0a54f5aebbe679340c26101df33424142c143c \\\n    --hash=sha256:e537484df0d8f426ce2afb2d0f8e1c3d0b114b83f8850e5f2fbea0e797bd82ae \\\n    --hash=sha256:eb00ed941194665c332bf8e078baf037d6c35d7c4f3102ea2d4f16ca94a26dc8 \\\n    --hash=sha256:eb6904c354526e758fda7167b33005998fb68c46fbc10e013ca97f21ca5c8887 \\\n    --hash=sha256:eb8821e09e916165e160797a6c17edda0679379a4be5c716c260e836e122f54b \\\n    --hash=sha256:efcb3f6676480691518c177e3b465bcddf57cea040302f9f4e6e191af91174d4 \\\n    --hash=sha256:f27273b60488abe721a075bcca6d7f3964f9f6f067c8c4c605743023d7d3944f \\\n    --hash=sha256:f30c3cb33b24454a82faecaf01b19c18562b1e89558fb6c56de4d9118a032fd5 \\\n    --hash=sha256:fb69256e180cb6c8a894fee62b3afebae785babc1ee98b81cdf68bbca1987f33 \\\n    --hash=sha256:fd1abc0d89e30cc4e02e4064dc67fcc51bd941eb395c502aac3ec19fab46b519 \\\n    --hash=sha256:ff8fa367d09b717b2a17a052544193ad76cd49979c805768879cb63d9ca50561\n    # via requests\ndill==0.3.7 \\\n    --hash=sha256:76b122c08ef4ce2eedcd4d1abd8e641114bfc6c2867f49f3c41facf65bf19f5e \\\n    --hash=sha256:cc1c8b182eb3013e24bd475ff2e9295af86c1a38eb1aff128dac8962a9ce3c03\n    # via -r ci/official/requirements_updater/requirements.in\ndm-tree==0.1.8 \\\n    --hash=sha256:054b461f8176f4bce7a21f7b1870f873a1ced3bdbe1282c816c550bb43c71fa6 \\\n    --hash=sha256:09964470f76a5201aff2e8f9b26842976de7889300676f927930f6285e256760 \\\n    --hash=sha256:0d3172394079a86c3a759179c65f64c48d1a42b89495fcf38976d11cc3bb952c \\\n    --hash=sha256:0e9620ccf06393eb6b613b5e366469304622d4ea96ae6540b28a33840e6c89cf \\\n    --hash=sha256:0fcaabbb14e7980377439e7140bd05552739ca5e515ecb3119f234acee4b9430 \\\n    --hash=sha256:1607ce49aa42f010d1e5e616d92ce899d66835d4d8bea49679582435285515de \\\n    --hash=sha256:181c35521d480d0365f39300542cb6cd7fd2b77351bb43d7acfda15aef63b317 \\\n    --hash=sha256:1d7c26e431fc93cc7e0cba867eb000db6a05f6f2b25af11ac4e9dada88fc5bca \\\n    --hash=sha256:1fe962015b2fe1282892b28ebe962faed53c7f98d942da9a4625cbf27baef913 \\\n    --hash=sha256:250b692fb75f45f02e2f58fbef9ab338904ef334b90557565621fa251df267cf \\\n    --hash=sha256:2869228d9c619074de501a3c10dc7f07c75422f8fab36ecdcb859b6f1b1ec3ef \\\n    --hash=sha256:28c52cbf4f8b3dbd0beaedf44f69fa85eec5e9dede612e08035e06ada6ec9426 \\\n    --hash=sha256:2f7915660f59c09068e428613c480150180df1060561fd0d1470684ae7007bd1 \\\n    --hash=sha256:343a4a4ebaa127451ff971254a4be4084eb4bdc0b2513c32b46f6f728fd03f9e \\\n    --hash=sha256:35cc164a79336bfcfafb47e5f297898359123bbd3330c1967f0c4994f9cf9f60 \\\n    --hash=sha256:378cc8ad93c5fe3590f405a309980721f021c790ca1bdf9b15bb1d59daec57f5 \\\n    --hash=sha256:39070ba268c0491af9fe7a58644d99e8b4f2cde6e5884ba3380bddc84ed43d5f \\\n    --hash=sha256:435227cf3c5dc63f4de054cf3d00183790bd9ead4c3623138c74dde7f67f521b \\\n    --hash=sha256:5483dca4d7eb1a0d65fe86d3b6a53ae717face83c1f17e0887b1a4a64ae5c410 \\\n    --hash=sha256:694c3654cfd2a81552c08ec66bb5c4a3d48fa292b9a181880fb081c36c5b9134 \\\n    --hash=sha256:75c5d528bb992981c20793b6b453e91560784215dffb8a5440ba999753c14ceb \\\n    --hash=sha256:803bfc53b4659f447ac694dbd04235f94a73ef7c1fd1e0df7c84ac41e0bc963b \\\n    --hash=sha256:81fce77f22a302d7a5968aebdf4efafef4def7ce96528719a354e6990dcd49c7 \\\n    --hash=sha256:83b7764de0d855338abefc6e3ee9fe40d301668310aa3baea3f778ff051f4393 \\\n    --hash=sha256:8c60a7eadab64c2278861f56bca320b2720f163dca9d7558103c3b77f2416571 \\\n    --hash=sha256:8ed3564abed97c806db122c2d3e1a2b64c74a63debe9903aad795167cc301368 \\\n    --hash=sha256:94d3f0826311f45ee19b75f5b48c99466e4218a0489e81c0f0167bda50cacf22 \\\n    --hash=sha256:96a548a406a6fb15fe58f6a30a57ff2f2aafbf25f05afab00c8f5e5977b6c715 \\\n    --hash=sha256:a5d819c38c03f0bb5b3b3703c60e4b170355a0fc6b5819325bf3d4ceb3ae7e80 \\\n    --hash=sha256:ad16ceba90a56ec47cf45b21856d14962ac314787975ef786efb5e6e9ca75ec7 \\\n    --hash=sha256:af4b3d372f2477dcd89a6e717e4a575ca35ccc20cc4454a8a4b6f8838a00672d \\\n    --hash=sha256:b095ba4f8ca1ba19350fd53cf1f8f3eb0bd406aa28af64a6dfc86707b32a810a \\\n    --hash=sha256:b9bd9b9ccb59409d33d51d84b7668010c04c2af7d4a371632874c1ca356cff3d \\\n    --hash=sha256:b9f89a454e98806b44fe9d40ec9eee61f848388f7e79ac2371a55679bd5a3ac6 \\\n    --hash=sha256:bb2d109f42190225112da899b9f3d46d0d5f26aef501c61e43529fe9322530b5 \\\n    --hash=sha256:c0a94aba18a35457a1b5cd716fd7b46c5dafdc4cf7869b4bae665b91c4682a8e \\\n    --hash=sha256:c5c8c12e3fda754ef6af94161bacdaeda816d941995fac415d6855c6c386af68 \\\n    --hash=sha256:d1612fcaecd79023dbc6a6ae48d51a80beb5c385d6f3f6d71688e57bc8d07de8 \\\n    --hash=sha256:d16e1f2a073604cfcc09f7131ae8d534674f43c3aef4c25742eae295bc60d04f \\\n    --hash=sha256:d20f2faa3672b52e5013f4077117bfb99c4cfc0b445d3bde1584c34032b57436 \\\n    --hash=sha256:d40fa4106ca6edc66760246a08f500ec0c85ef55c762fb4a363f6ee739ba02ee \\\n    --hash=sha256:de287fabc464b8734be251e46e06aa9aa1001f34198da2b6ce07bd197172b9cb \\\n    --hash=sha256:e4d714371bb08839e4e5e29024fc95832d9affe129825ef38836b143028bd144 \\\n    --hash=sha256:ea9e59e0451e7d29aece402d9f908f2e2a80922bcde2ebfd5dcb07750fcbfee8 \\\n    --hash=sha256:f7ac31b9aecccb2c6e1ab29706f6ded3eba0c2c69c770322c9c685929c3d6afb \\\n    --hash=sha256:fa42a605d099ee7d41ba2b5fb75e21423951fd26e5d50583a00471238fb3021d\n    # via keras-nightly\nflatbuffers==24.3.25 \\\n    --hash=sha256:8dbdec58f935f3765e4f7f3cf635ac3a77f83568138d6a2311f524ec96364812 \\\n    --hash=sha256:de2ec5b203f21441716617f38443e0a8ebf3d25bf0d9c0bb0ce68fa00ad546a4\n    # via -r ci/official/requirements_updater/requirements.in\ngast==0.4.0 \\\n    --hash=sha256:40feb7b8b8434785585ab224d1568b857edb18297e5a3047f1ba012bc83b42c1 \\\n    --hash=sha256:b7adcdd5adbebf1adf17378da5ba3f543684dbec47b1cda1f3997e573cd542c4\n    # via -r ci/official/requirements_updater/requirements.in\ngoogle-pasta==0.2.0 \\\n    --hash=sha256:4612951da876b1a10fe3960d7226f0c7682cf901e16ac06e473b267a5afa8954 \\\n    --hash=sha256:b32482794a366b5366a32c92a9a9201b107821889935a02b3e51f6b432ea84ed \\\n    --hash=sha256:c9f2c8dfc8f96d0d5808299920721be30c9eec37f2389f28904f454565c8a16e\n    # via -r ci/official/requirements_updater/requirements.in\ngrpcio==1.64.1 \\\n    --hash=sha256:03b43d0ccf99c557ec671c7dede64f023c7da9bb632ac65dbc57f166e4970040 \\\n    --hash=sha256:0a12ddb1678ebc6a84ec6b0487feac020ee2b1659cbe69b80f06dbffdb249122 \\\n    --hash=sha256:0a2813093ddb27418a4c99f9b1c223fab0b053157176a64cc9db0f4557b69bd9 \\\n    --hash=sha256:0cc79c982ccb2feec8aad0e8fb0d168bcbca85bc77b080d0d3c5f2f15c24ea8f \\\n    --hash=sha256:1257b76748612aca0f89beec7fa0615727fd6f2a1ad580a9638816a4b2eb18fd \\\n    --hash=sha256:1262402af5a511c245c3ae918167eca57342c72320dffae5d9b51840c4b2f86d \\\n    --hash=sha256:19264fc964576ddb065368cae953f8d0514ecc6cb3da8903766d9fb9d4554c33 \\\n    --hash=sha256:198908f9b22e2672a998870355e226a725aeab327ac4e6ff3a1399792ece4762 \\\n    --hash=sha256:1de403fc1305fd96cfa75e83be3dee8538f2413a6b1685b8452301c7ba33c294 \\\n    --hash=sha256:20405cb8b13fd779135df23fabadc53b86522d0f1cba8cca0e87968587f50650 \\\n    --hash=sha256:2981c7365a9353f9b5c864595c510c983251b1ab403e05b1ccc70a3d9541a73b \\\n    --hash=sha256:2c3c1b90ab93fed424e454e93c0ed0b9d552bdf1b0929712b094f5ecfe7a23ad \\\n    --hash=sha256:39b9d0acaa8d835a6566c640f48b50054f422d03e77e49716d4c4e8e279665a1 \\\n    --hash=sha256:3b64ae304c175671efdaa7ec9ae2cc36996b681eb63ca39c464958396697daff \\\n    --hash=sha256:4657d24c8063e6095f850b68f2d1ba3b39f2b287a38242dcabc166453e950c59 \\\n    --hash=sha256:4d6dab6124225496010bd22690f2d9bd35c7cbb267b3f14e7a3eb05c911325d4 \\\n    --hash=sha256:55260032b95c49bee69a423c2f5365baa9369d2f7d233e933564d8a47b893027 \\\n    --hash=sha256:55697ecec192bc3f2f3cc13a295ab670f51de29884ca9ae6cd6247df55df2502 \\\n    --hash=sha256:5841dd1f284bd1b3d8a6eca3a7f062b06f1eec09b184397e1d1d43447e89a7ae \\\n    --hash=sha256:58b1041e7c870bb30ee41d3090cbd6f0851f30ae4eb68228955d973d3efa2e61 \\\n    --hash=sha256:5e42634a989c3aa6049f132266faf6b949ec2a6f7d302dbb5c15395b77d757eb \\\n    --hash=sha256:5e56462b05a6f860b72f0fa50dca06d5b26543a4e88d0396259a07dc30f4e5aa \\\n    --hash=sha256:5f8b75f64d5d324c565b263c67dbe4f0af595635bbdd93bb1a88189fc62ed2e5 \\\n    --hash=sha256:62b4e6eb7bf901719fce0ca83e3ed474ae5022bb3827b0a501e056458c51c0a1 \\\n    --hash=sha256:6503b64c8b2dfad299749cad1b595c650c91e5b2c8a1b775380fcf8d2cbba1e9 \\\n    --hash=sha256:6c024ffc22d6dc59000faf8ad781696d81e8e38f4078cb0f2630b4a3cf231a90 \\\n    --hash=sha256:73819689c169417a4f978e562d24f2def2be75739c4bed1992435d007819da1b \\\n    --hash=sha256:75dbbf415026d2862192fe1b28d71f209e2fd87079d98470db90bebe57b33179 \\\n    --hash=sha256:8caee47e970b92b3dd948371230fcceb80d3f2277b3bf7fbd7c0564e7d39068e \\\n    --hash=sha256:8d51dd1c59d5fa0f34266b80a3805ec29a1f26425c2a54736133f6d87fc4968a \\\n    --hash=sha256:940e3ec884520155f68a3b712d045e077d61c520a195d1a5932c531f11883489 \\\n    --hash=sha256:a011ac6c03cfe162ff2b727bcb530567826cec85eb8d4ad2bfb4bd023287a52d \\\n    --hash=sha256:a3a035c37ce7565b8f4f35ff683a4db34d24e53dc487e47438e434eb3f701b2a \\\n    --hash=sha256:a5e771d0252e871ce194d0fdcafd13971f1aae0ddacc5f25615030d5df55c3a2 \\\n    --hash=sha256:ac15b6c2c80a4d1338b04d42a02d376a53395ddf0ec9ab157cbaf44191f3ffdd \\\n    --hash=sha256:b1a82e0b9b3022799c336e1fc0f6210adc019ae84efb7321d668129d28ee1efb \\\n    --hash=sha256:bac71b4b28bc9af61efcdc7630b166440bbfbaa80940c9a697271b5e1dabbc61 \\\n    --hash=sha256:bbc5b1d78a7822b0a84c6f8917faa986c1a744e65d762ef6d8be9d75677af2ca \\\n    --hash=sha256:c1a786ac592b47573a5bb7e35665c08064a5d77ab88a076eec11f8ae86b3e3f6 \\\n    --hash=sha256:c84ad903d0d94311a2b7eea608da163dace97c5fe9412ea311e72c3684925602 \\\n    --hash=sha256:d4d29cc612e1332237877dfa7fe687157973aab1d63bd0f84cf06692f04c0367 \\\n    --hash=sha256:e3d9f8d1221baa0ced7ec7322a981e28deb23749c76eeeb3d33e18b72935ab62 \\\n    --hash=sha256:e7cd5c1325f6808b8ae31657d281aadb2a51ac11ab081ae335f4f7fc44c1721d \\\n    --hash=sha256:ed6091fa0adcc7e4ff944090cf203a52da35c37a130efa564ded02b7aff63bcd \\\n    --hash=sha256:ee73a2f5ca4ba44fa33b4d7d2c71e2c8a9e9f78d53f6507ad68e7d2ad5f64a22 \\\n    --hash=sha256:f10193c69fc9d3d726e83bbf0f3d316f1847c3071c8c93d8090cf5f326b14309\n    # via\n    #   -r ci/official/requirements_updater/requirements.in\n    #   tb-nightly\nh5py==3.11.0 \\\n    --hash=sha256:083e0329ae534a264940d6513f47f5ada617da536d8dccbafc3026aefc33c90e \\\n    --hash=sha256:1625fd24ad6cfc9c1ccd44a66dac2396e7ee74940776792772819fc69f3a3731 \\\n    --hash=sha256:21dbdc5343f53b2e25404673c4f00a3335aef25521bd5fa8c707ec3833934892 \\\n    --hash=sha256:52c416f8eb0daae39dabe71415cb531f95dce2d81e1f61a74537a50c63b28ab3 \\\n    --hash=sha256:55106b04e2c83dfb73dc8732e9abad69d83a436b5b82b773481d95d17b9685e1 \\\n    --hash=sha256:67462d0669f8f5459529de179f7771bd697389fcb3faab54d63bf788599a48ea \\\n    --hash=sha256:6c4b760082626120031d7902cd983d8c1f424cdba2809f1067511ef283629d4b \\\n    --hash=sha256:731839240c59ba219d4cb3bc5880d438248533366f102402cfa0621b71796b62 \\\n    --hash=sha256:754c0c2e373d13d6309f408325343b642eb0f40f1a6ad21779cfa9502209e150 \\\n    --hash=sha256:75bd7b3d93fbeee40860fd70cdc88df4464e06b70a5ad9ce1446f5f32eb84007 \\\n    --hash=sha256:77b19a40788e3e362b54af4dcf9e6fde59ca016db2c61360aa30b47c7b7cef00 \\\n    --hash=sha256:7b7e8f78072a2edec87c9836f25f34203fd492a4475709a18b417a33cfb21fa9 \\\n    --hash=sha256:8ec9df3dd2018904c4cc06331951e274f3f3fd091e6d6cc350aaa90fa9b42a76 \\\n    --hash=sha256:a76cae64080210389a571c7d13c94a1a6cf8cb75153044fd1f822a962c97aeab \\\n    --hash=sha256:aa6ae84a14103e8dc19266ef4c3e5d7c00b68f21d07f2966f0ca7bdb6c2761fb \\\n    --hash=sha256:bbd732a08187a9e2a6ecf9e8af713f1d68256ee0f7c8b652a32795670fb481ba \\\n    --hash=sha256:c072655ad1d5fe9ef462445d3e77a8166cbfa5e599045f8aa3c19b75315f10e5 \\\n    --hash=sha256:d9c944d364688f827dc889cf83f1fca311caf4fa50b19f009d1f2b525edd33a3 \\\n    --hash=sha256:ef4e2f338fc763f50a8113890f455e1a70acd42a4d083370ceb80c463d803972 \\\n    --hash=sha256:f3736fe21da2b7d8a13fe8fe415f1272d2a1ccdeff4849c1421d2fb30fd533bc \\\n    --hash=sha256:f4e025e852754ca833401777c25888acb96889ee2c27e7e629a19aee288833f0\n    # via\n    #   -r ci/official/requirements_updater/requirements.in\n    #   keras-nightly\nidna==3.7 \\\n    --hash=sha256:028ff3aadf0609c1fd278d8ea3089299412a7a8b9bd005dd08b9f8285bcb5cfc \\\n    --hash=sha256:82fee1fc78add43492d3a1898bfa6d8a904cc97d8427f683ed8e798d07761aa0\n    # via requests\njax==0.4.7 \\\n    --hash=sha256:5e7002d74db25f97c99b979d4ba1233b1ef26e1597e5fc468ad11d1c8a9dc4f8\n    # via -r ci/official/requirements_updater/requirements.in\nkeras-nightly==3.0.4.dev2024021403 \\\n    --hash=sha256:24ce69d29d582771685bf4235f59663723405b5a5b16f3eaff2657e52e74663a \\\n    --hash=sha256:9f416e66b820ef833779d219d255b346b8b90a72fdbd0b2f1e90a43ad142a03d\n    # via -r ci/official/requirements_updater/requirements.in\nlibclang==18.1.1 \\\n    --hash=sha256:0b2e143f0fac830156feb56f9231ff8338c20aecfe72b4ffe96f19e5a1dbb69a \\\n    --hash=sha256:3f0e1f49f04d3cd198985fea0511576b0aee16f9ff0e0f0cad7f9c57ec3c20e8 \\\n    --hash=sha256:4dd2d3b82fab35e2bf9ca717d7b63ac990a3519c7e312f19fa8e86dcc712f7fb \\\n    --hash=sha256:54dda940a4a0491a9d1532bf071ea3ef26e6dbaf03b5000ed94dd7174e8f9592 \\\n    --hash=sha256:69f8eb8f65c279e765ffd28aaa7e9e364c776c17618af8bff22a8df58677ff4f \\\n    --hash=sha256:6f14c3f194704e5d09769108f03185fce7acaf1d1ae4bbb2f30a72c2400cb7c5 \\\n    --hash=sha256:83ce5045d101b669ac38e6da8e58765f12da2d3aafb3b9b98d88b286a60964d8 \\\n    --hash=sha256:a1214966d08d73d971287fc3ead8dfaf82eb07fb197680d8b3859dbbbbf78250 \\\n    --hash=sha256:c533091d8a3bbf7460a00cb6c1a71da93bffe148f172c7d03b1c31fbf8aa2a0b \\\n    --hash=sha256:cf4a99b05376513717ab5d82a0db832c56ccea4fd61a69dbb7bccf2dfb207dbe\n    # via -r ci/official/requirements_updater/requirements.in\nlit==17.0.6 \\\n    --hash=sha256:dfa9af9b55fc4509a56be7bf2346f079d7f4a242d583b9f2e0b078fd0abae31b\n    # via -r ci/official/requirements_updater/requirements.in\nmarkdown==3.6 \\\n    --hash=sha256:48f276f4d8cfb8ce6527c8f79e2ee29708508bf4d40aa410fbc3b4ee832c850f \\\n    --hash=sha256:ed4f41f6daecbeeb96e576ce414c41d2d876daa9a16cb35fa8ed8c2ddfad0224\n    # via tb-nightly\nmarkdown-it-py==3.0.0 \\\n    --hash=sha256:355216845c60bd96232cd8d8c40e8f9765cc86f46880e43a8fd22dc1a1a8cab1 \\\n    --hash=sha256:e3f60a94fa066dc52ec76661e37c851cb232d92f9886b15cb560aaada2df8feb\n    # via rich\nmarkupsafe==2.1.5 \\\n    --hash=sha256:00e046b6dd71aa03a41079792f8473dc494d564611a8f89bbbd7cb93295ebdcf \\\n    --hash=sha256:075202fa5b72c86ad32dc7d0b56024ebdbcf2048c0ba09f1cde31bfdd57bcfff \\\n    --hash=sha256:0e397ac966fdf721b2c528cf028494e86172b4feba51d65f81ffd65c63798f3f \\\n    --hash=sha256:17b950fccb810b3293638215058e432159d2b71005c74371d784862b7e4683f3 \\\n    --hash=sha256:1f3fbcb7ef1f16e48246f704ab79d79da8a46891e2da03f8783a5b6fa41a9532 \\\n    --hash=sha256:2174c595a0d73a3080ca3257b40096db99799265e1c27cc5a610743acd86d62f \\\n    --hash=sha256:2b7c57a4dfc4f16f7142221afe5ba4e093e09e728ca65c51f5620c9aaeb9a617 \\\n    --hash=sha256:2d2d793e36e230fd32babe143b04cec8a8b3eb8a3122d2aceb4a371e6b09b8df \\\n    --hash=sha256:30b600cf0a7ac9234b2638fbc0fb6158ba5bdcdf46aeb631ead21248b9affbc4 \\\n    --hash=sha256:397081c1a0bfb5124355710fe79478cdbeb39626492b15d399526ae53422b906 \\\n    --hash=sha256:3a57fdd7ce31c7ff06cdfbf31dafa96cc533c21e443d57f5b1ecc6cdc668ec7f \\\n    --hash=sha256:3c6b973f22eb18a789b1460b4b91bf04ae3f0c4234a0a6aa6b0a92f6f7b951d4 \\\n    --hash=sha256:3e53af139f8579a6d5f7b76549125f0d94d7e630761a2111bc431fd820e163b8 \\\n    --hash=sha256:4096e9de5c6fdf43fb4f04c26fb114f61ef0bf2e5604b6ee3019d51b69e8c371 \\\n    --hash=sha256:4275d846e41ecefa46e2015117a9f491e57a71ddd59bbead77e904dc02b1bed2 \\\n    --hash=sha256:4c31f53cdae6ecfa91a77820e8b151dba54ab528ba65dfd235c80b086d68a465 \\\n    --hash=sha256:4f11aa001c540f62c6166c7726f71f7573b52c68c31f014c25cc7901deea0b52 \\\n    --hash=sha256:5049256f536511ee3f7e1b3f87d1d1209d327e818e6ae1365e8653d7e3abb6a6 \\\n    --hash=sha256:58c98fee265677f63a4385256a6d7683ab1832f3ddd1e66fe948d5880c21a169 \\\n    --hash=sha256:598e3276b64aff0e7b3451b72e94fa3c238d452e7ddcd893c3ab324717456bad \\\n    --hash=sha256:5b7b716f97b52c5a14bffdf688f971b2d5ef4029127f1ad7a513973cfd818df2 \\\n    --hash=sha256:5dedb4db619ba5a2787a94d877bc8ffc0566f92a01c0ef214865e54ecc9ee5e0 \\\n    --hash=sha256:619bc166c4f2de5caa5a633b8b7326fbe98e0ccbfacabd87268a2b15ff73a029 \\\n    --hash=sha256:629ddd2ca402ae6dbedfceeba9c46d5f7b2a61d9749597d4307f943ef198fc1f \\\n    --hash=sha256:656f7526c69fac7f600bd1f400991cc282b417d17539a1b228617081106feb4a \\\n    --hash=sha256:6ec585f69cec0aa07d945b20805be741395e28ac1627333b1c5b0105962ffced \\\n    --hash=sha256:72b6be590cc35924b02c78ef34b467da4ba07e4e0f0454a2c5907f473fc50ce5 \\\n    --hash=sha256:7502934a33b54030eaf1194c21c692a534196063db72176b0c4028e140f8f32c \\\n    --hash=sha256:7a68b554d356a91cce1236aa7682dc01df0edba8d043fd1ce607c49dd3c1edcf \\\n    --hash=sha256:7b2e5a267c855eea6b4283940daa6e88a285f5f2a67f2220203786dfa59b37e9 \\\n    --hash=sha256:823b65d8706e32ad2df51ed89496147a42a2a6e01c13cfb6ffb8b1e92bc910bb \\\n    --hash=sha256:8590b4ae07a35970728874632fed7bd57b26b0102df2d2b233b6d9d82f6c62ad \\\n    --hash=sha256:8dd717634f5a044f860435c1d8c16a270ddf0ef8588d4887037c5028b859b0c3 \\\n    --hash=sha256:8dec4936e9c3100156f8a2dc89c4b88d5c435175ff03413b443469c7c8c5f4d1 \\\n    --hash=sha256:97cafb1f3cbcd3fd2b6fbfb99ae11cdb14deea0736fc2b0952ee177f2b813a46 \\\n    --hash=sha256:a17a92de5231666cfbe003f0e4b9b3a7ae3afb1ec2845aadc2bacc93ff85febc \\\n    --hash=sha256:a549b9c31bec33820e885335b451286e2969a2d9e24879f83fe904a5ce59d70a \\\n    --hash=sha256:ac07bad82163452a6884fe8fa0963fb98c2346ba78d779ec06bd7a6262132aee \\\n    --hash=sha256:ae2ad8ae6ebee9d2d94b17fb62763125f3f374c25618198f40cbb8b525411900 \\\n    --hash=sha256:b91c037585eba9095565a3556f611e3cbfaa42ca1e865f7b8015fe5c7336d5a5 \\\n    --hash=sha256:bc1667f8b83f48511b94671e0e441401371dfd0f0a795c7daa4a3cd1dde55bea \\\n    --hash=sha256:bec0a414d016ac1a18862a519e54b2fd0fc8bbfd6890376898a6c0891dd82e9f \\\n    --hash=sha256:bf50cd79a75d181c9181df03572cdce0fbb75cc353bc350712073108cba98de5 \\\n    --hash=sha256:bff1b4290a66b490a2f4719358c0cdcd9bafb6b8f061e45c7a2460866bf50c2e \\\n    --hash=sha256:c061bb86a71b42465156a3ee7bd58c8c2ceacdbeb95d05a99893e08b8467359a \\\n    --hash=sha256:c8b29db45f8fe46ad280a7294f5c3ec36dbac9491f2d1c17345be8e69cc5928f \\\n    --hash=sha256:ce409136744f6521e39fd8e2a24c53fa18ad67aa5bc7c2cf83645cce5b5c4e50 \\\n    --hash=sha256:d050b3361367a06d752db6ead6e7edeb0009be66bc3bae0ee9d97fb326badc2a \\\n    --hash=sha256:d283d37a890ba4c1ae73ffadf8046435c76e7bc2247bbb63c00bd1a709c6544b \\\n    --hash=sha256:d9fad5155d72433c921b782e58892377c44bd6252b5af2f67f16b194987338a4 \\\n    --hash=sha256:daa4ee5a243f0f20d528d939d06670a298dd39b1ad5f8a72a4275124a7819eff \\\n    --hash=sha256:db0b55e0f3cc0be60c1f19efdde9a637c32740486004f20d1cff53c3c0ece4d2 \\\n    --hash=sha256:e61659ba32cf2cf1481e575d0462554625196a1f2fc06a1c777d3f48e8865d46 \\\n    --hash=sha256:ea3d8a3d18833cf4304cd2fc9cbb1efe188ca9b5efef2bdac7adc20594a0e46b \\\n    --hash=sha256:ec6a563cff360b50eed26f13adc43e61bc0c04d94b8be985e6fb24b81f6dcfdf \\\n    --hash=sha256:f5dfb42c4604dddc8e4305050aa6deb084540643ed5804d7455b5df8fe16f5e5 \\\n    --hash=sha256:fa173ec60341d6bb97a89f5ea19c85c5643c1e7dedebc22f5181eb73573142c5 \\\n    --hash=sha256:fa9db3f79de01457b03d4f01b34cf91bc0048eb2c3846ff26f66687c2f6d16ab \\\n    --hash=sha256:fce659a462a1be54d2ffcacea5e3ba2d74daa74f30f5f143fe0c58636e355fdd \\\n    --hash=sha256:ffee1f21e5ef0d712f9033568f8344d5da8cc2869dbd08d87c84656e6a2d2f68\n    # via werkzeug\nmdurl==0.1.2 \\\n    --hash=sha256:84008a41e51615a49fc9966191ff91509e3c40b939176e643fd50a5c2196b8f8 \\\n    --hash=sha256:bb413d29f5eea38f31dd4754dd7377d4465116fb207585f97bf925588687c1ba\n    # via markdown-it-py\nml-dtypes==0.4.0 \\\n    --hash=sha256:03e7cda6ef164eed0abb31df69d2c00c3a5ab3e2610b6d4c42183a43329c72a5 \\\n    --hash=sha256:2bb83fd064db43e67e67d021e547698af4c8d5c6190f2e9b1c53c09f6ff5531d \\\n    --hash=sha256:3b67ec73a697c88c1122038e0de46520e48dc2ec876d42cf61bc5efe3c0b7675 \\\n    --hash=sha256:41affb38fdfe146e3db226cf2953021184d6f0c4ffab52136613e9601706e368 \\\n    --hash=sha256:43cf4356a0fe2eeac6d289018d0734e17a403bdf1fd911953c125dd0358edcc0 \\\n    --hash=sha256:723af6346447268a3cf0b7356e963d80ecb5732b5279b2aa3fa4b9fc8297c85e \\\n    --hash=sha256:75b4faf99d0711b81f393db36d210b4255fd419f6f790bc6c1b461f95ffb7a9e \\\n    --hash=sha256:93afe37f3a879d652ec9ef1fc47612388890660a2657fbb5747256c3b818fd81 \\\n    --hash=sha256:a15d96d090aebb55ee85173d1775ae325a001aab607a76c8ea0b964ccd6b5364 \\\n    --hash=sha256:ad6849a2db386b38e4d54fe13eb3293464561780531a918f8ef4c8169170dd49 \\\n    --hash=sha256:bdf689be7351cc3c95110c910c1b864002f113e682e44508910c849e144f3df1 \\\n    --hash=sha256:c83e4d443962d891d51669ff241d5aaad10a8d3d37a81c5532a45419885d591c \\\n    --hash=sha256:e1e2f4237b459a63c97c2c9f449baa637d7e4c20addff6a9bac486f22432f3b6 \\\n    --hash=sha256:eaa32979ebfde3a0d7c947cafbf79edc1ec77ac05ad0780ee86c1d8df70f2259 \\\n    --hash=sha256:eaf197e72f4f7176a19fe3cb8b61846b38c6757607e7bf9cd4b1d84cd3e74deb \\\n    --hash=sha256:ee9f91d4c4f9959a7e1051c141dc565f39e54435618152219769e24f5e9a4d06 \\\n    --hash=sha256:f1724ddcdf5edbaf615a62110af47407f1719b8d02e68ccee60683acb5f74da1\n    # via\n    #   -r ci/official/requirements_updater/requirements.in\n    #   jax\n    #   keras-nightly\nnamex==0.0.8 \\\n    --hash=sha256:32a50f6c565c0bb10aa76298c959507abdc0e850efe085dc38f3440fcb3aa90b \\\n    --hash=sha256:7ddb6c2bb0e753a311b7590f84f6da659dd0c05e65cb89d519d54c0a250c0487\n    # via keras-nightly\nnumpy==2.1.1 \\\n    --hash=sha256:046356b19d7ad1890c751b99acad5e82dc4a02232013bd9a9a712fddf8eb60f5 \\\n    --hash=sha256:0b8cc2715a84b7c3b161f9ebbd942740aaed913584cae9cdc7f8ad5ad41943d0 \\\n    --hash=sha256:0d07841fd284718feffe7dd17a63a2e6c78679b2d386d3e82f44f0108c905550 \\\n    --hash=sha256:13cc11c00000848702322af4de0147ced365c81d66053a67c2e962a485b3717c \\\n    --hash=sha256:13ce49a34c44b6de5241f0b38b07e44c1b2dcacd9e36c30f9c2fcb1bb5135db7 \\\n    --hash=sha256:24c2ad697bd8593887b019817ddd9974a7f429c14a5469d7fad413f28340a6d2 \\\n    --hash=sha256:251105b7c42abe40e3a689881e1793370cc9724ad50d64b30b358bbb3a97553b \\\n    --hash=sha256:2ca4b53e1e0b279142113b8c5eb7d7a877e967c306edc34f3b58e9be12fda8df \\\n    --hash=sha256:3269c9eb8745e8d975980b3a7411a98976824e1fdef11f0aacf76147f662b15f \\\n    --hash=sha256:397bc5ce62d3fb73f304bec332171535c187e0643e176a6e9421a6e3eacef06d \\\n    --hash=sha256:3fc5eabfc720db95d68e6646e88f8b399bfedd235994016351b1d9e062c4b270 \\\n    --hash=sha256:50a95ca3560a6058d6ea91d4629a83a897ee27c00630aed9d933dff191f170cd \\\n    --hash=sha256:52ac2e48f5ad847cd43c4755520a2317f3380213493b9d8a4c5e37f3b87df504 \\\n    --hash=sha256:53e27293b3a2b661c03f79aa51c3987492bd4641ef933e366e0f9f6c9bf257ec \\\n    --hash=sha256:57eb525e7c2a8fdee02d731f647146ff54ea8c973364f3b850069ffb42799647 \\\n    --hash=sha256:5889dd24f03ca5a5b1e8a90a33b5a0846d8977565e4ae003a63d22ecddf6782f \\\n    --hash=sha256:59ca673ad11d4b84ceb385290ed0ebe60266e356641428c845b39cd9df6713ab \\\n    --hash=sha256:6435c48250c12f001920f0751fe50c0348f5f240852cfddc5e2f97e007544cbe \\\n    --hash=sha256:6e5a9cb2be39350ae6c8f79410744e80154df658d5bea06e06e0ac5bb75480d5 \\\n    --hash=sha256:7be6a07520b88214ea85d8ac8b7d6d8a1839b0b5cb87412ac9f49fa934eb15d5 \\\n    --hash=sha256:7c803b7934a7f59563db459292e6aa078bb38b7ab1446ca38dd138646a38203e \\\n    --hash=sha256:7dd86dfaf7c900c0bbdcb8b16e2f6ddf1eb1fe39c6c8cca6e94844ed3152a8fd \\\n    --hash=sha256:8661c94e3aad18e1ea17a11f60f843a4933ccaf1a25a7c6a9182af70610b2313 \\\n    --hash=sha256:8ae0fd135e0b157365ac7cc31fff27f07a5572bdfc38f9c2d43b2aff416cc8b0 \\\n    --hash=sha256:910b47a6d0635ec1bd53b88f86120a52bf56dcc27b51f18c7b4a2e2224c29f0f \\\n    --hash=sha256:913cc1d311060b1d409e609947fa1b9753701dac96e6581b58afc36b7ee35af6 \\\n    --hash=sha256:920b0911bb2e4414c50e55bd658baeb78281a47feeb064ab40c2b66ecba85553 \\\n    --hash=sha256:950802d17a33c07cba7fd7c3dcfa7d64705509206be1606f196d179e539111ed \\\n    --hash=sha256:981707f6b31b59c0c24bcda52e5605f9701cb46da4b86c2e8023656ad3e833cb \\\n    --hash=sha256:98ce7fb5b8063cfdd86596b9c762bf2b5e35a2cdd7e967494ab78a1fa7f8b86e \\\n    --hash=sha256:99f4a9ee60eed1385a86e82288971a51e71df052ed0b2900ed30bc840c0f2e39 \\\n    --hash=sha256:9a8e06c7a980869ea67bbf551283bbed2856915f0a792dc32dd0f9dd2fb56728 \\\n    --hash=sha256:ae8ce252404cdd4de56dcfce8b11eac3c594a9c16c231d081fb705cf23bd4d9e \\\n    --hash=sha256:afd9c680df4de71cd58582b51e88a61feed4abcc7530bcd3d48483f20fc76f2a \\\n    --hash=sha256:b49742cdb85f1f81e4dc1b39dcf328244f4d8d1ded95dea725b316bd2cf18c95 \\\n    --hash=sha256:b5613cfeb1adfe791e8e681128f5f49f22f3fcaa942255a6124d58ca59d9528f \\\n    --hash=sha256:bab7c09454460a487e631ffc0c42057e3d8f2a9ddccd1e60c7bb8ed774992480 \\\n    --hash=sha256:c8a0e34993b510fc19b9a2ce7f31cb8e94ecf6e924a40c0c9dd4f62d0aac47d9 \\\n    --hash=sha256:caf5d284ddea7462c32b8d4a6b8af030b6c9fd5332afb70e7414d7fdded4bfd0 \\\n    --hash=sha256:cea427d1350f3fd0d2818ce7350095c1a2ee33e30961d2f0fef48576ddbbe90f \\\n    --hash=sha256:d0cf7d55b1051387807405b3898efafa862997b4cba8aa5dbe657be794afeafd \\\n    --hash=sha256:d10c39947a2d351d6d466b4ae83dad4c37cd6c3cdd6d5d0fa797da56f710a6ae \\\n    --hash=sha256:d2b9cd92c8f8e7b313b80e93cedc12c0112088541dcedd9197b5dee3738c1201 \\\n    --hash=sha256:d4c57b68c8ef5e1ebf47238e99bf27657511ec3f071c465f6b1bccbef12d4136 \\\n    --hash=sha256:d51fc141ddbe3f919e91a096ec739f49d686df8af254b2053ba21a910ae518bf \\\n    --hash=sha256:e097507396c0be4e547ff15b13dc3866f45f3680f789c1a1301b07dadd3fbc78 \\\n    --hash=sha256:e30356d530528a42eeba51420ae8bf6c6c09559051887196599d96ee5f536468 \\\n    --hash=sha256:e8d5f8a8e3bc87334f025194c6193e408903d21ebaeb10952264943a985066ca \\\n    --hash=sha256:e8dfa9e94fc127c40979c3eacbae1e61fda4fe71d84869cc129e2721973231ef \\\n    --hash=sha256:f212d4f46b67ff604d11fff7cc62d36b3e8714edf68e44e9760e19be38c03eb0 \\\n    --hash=sha256:f7506387e191fe8cdb267f912469a3cccc538ab108471291636a96a54e599556 \\\n    --hash=sha256:fac6e277a41163d27dfab5f4ec1f7a83fac94e170665a4a50191b545721c6521 \\\n    --hash=sha256:fcd8f556cdc8cfe35e70efb92463082b7f43dd7e547eb071ffc36abc0ca4699b\n    # via\n    #   -r ci/official/requirements_updater/requirements.in\n    #   h5py\n    #   jax\n    #   keras-nightly\n    #   ml-dtypes\n    #   opt-einsum\n    #   scipy\n    #   tb-nightly\nnvidia-cublas-cu12==12.5.3.2 \\\n    --hash=sha256:4960f3dc5f39699acadf76fa6d94b10a2a00f2956c2c442efa299fb22b0748f3 \\\n    --hash=sha256:7d0191251180de606023d396b94d66f66470a0ae96d1dbb906c7656ea0f71eda \\\n    --hash=sha256:ca070ad70e9fa6654084575d01bd001f30cc4665e33d4bb9fc8e0f321caa034b\n    # via\n    #   -r ci/official/requirements_updater/requirements.in\n    #   nvidia-cudnn-cu12\n    #   nvidia-cusolver-cu12\nnvidia-cuda-cupti-cu12==12.5.82 \\\n    --hash=sha256:4f835281cf492e2bedd153f5c3de9da8f1d775a419468305e64ce73b3b0c6dc3 \\\n    --hash=sha256:bde77a5feb66752ec61db2adfe47f56b941842825b4c7e2068aff27c9d107953 \\\n    --hash=sha256:d32c06490c6ba35c4323730820c7d0c4c126c04ed58d2f57275adb8d54b138fe\n    # via -r ci/official/requirements_updater/requirements.in\nnvidia-cuda-nvrtc-cu12==12.5.82 \\\n    --hash=sha256:3dbd97b0104b4bfbc3c4f8c79cd2496307c89c43c29a9f83125f1d76296ff3fd \\\n    --hash=sha256:5bb6a0eb01d4974bb7ca3d48bd3859472debb3c3057a5e7de2b08fbdf35eed7e \\\n    --hash=sha256:e5db37e990056c70953b7772dd778336ef9da0a0b5bb28f9f2a61c2e42b51d78\n    # via -r ci/official/requirements_updater/requirements.in\nnvidia-cuda-runtime-cu12==12.5.82 \\\n    --hash=sha256:0fd5fbca289bceb9f0690aa9858f06187b554fdeb7e2711dfd5bb3ce58900b46 \\\n    --hash=sha256:3e79a060e126df40fd3a068f3f787eb000fa51b251ec6cd97d09579632687115 \\\n    --hash=sha256:71f015dbf9df05dd71f7480132c6ebf47a6ceb2ab53d7db8e08e4b30ebb87e14\n    # via -r ci/official/requirements_updater/requirements.in\nnvidia-cudnn-cu12==9.3.0.75 \\\n    --hash=sha256:9ad9c6929ebb5295eb4a1728024666d1c88283373e265a0c5c883e6f9d5cd76d \\\n    --hash=sha256:c5cf7ff3415e446adf195a5b7dd2ba56cd00c3ee78bfdc566e51698931aa4b7f \\\n    --hash=sha256:c819e82eed8cf564b9d37478ea4eab9e87194bb3b7f7f8098bc1f67c9b80f1b6\n    # via -r ci/official/requirements_updater/requirements.in\nnvidia-cufft-cu12==11.2.3.61 \\\n    --hash=sha256:4a8f6f0ce93c52a50ee83422a80472b5f376054a63f38532d0eab4007e7ef28b \\\n    --hash=sha256:6d45b48a5ee7599e57131129cda2c58544d9b78b95064d3ec3e5c6b96e2b58cc \\\n    --hash=sha256:9a6e8df162585750f61983a638104a48c756aa13f9f48e19ab079b38e3c828b8\n    # via -r ci/official/requirements_updater/requirements.in\nnvidia-curand-cu12==10.3.6.82 \\\n    --hash=sha256:0631ba65231260ad832ce233ddda57e7b3b7158eabf000d78e46cbb5bd5b7aae \\\n    --hash=sha256:2823fb27de4e44dbb22394a6adf53aa6e1b013aca0f8c22867d1cfae58405536 \\\n    --hash=sha256:36aabeb5990297bbce3df324ea7c7c13c3aabb140c86d50ab3b23e4ec61672f1\n    # via -r ci/official/requirements_updater/requirements.in\nnvidia-cusolver-cu12==11.6.3.83 \\\n    --hash=sha256:1b8b77d2fe8abe72bb722dafb708cceaeb81f1a03999477f20b33b34f46ab885 \\\n    --hash=sha256:6224732963cba312a84c78114b9a38c4ffabb2e2a6a120923ac99ba6f895c8cf \\\n    --hash=sha256:93cfafacde4428b71778eeb092ec615a02a3d05404da1bcf91c53e3fa1bce42b\n    # via -r ci/official/requirements_updater/requirements.in\nnvidia-cusparse-cu12==12.5.1.3 \\\n    --hash=sha256:016df8e993c437e8301e62739f01775cba988fd5253cd4c64173f8e8d2f8e752 \\\n    --hash=sha256:33520db374e2f5ebc976d6faa1852b98c398a57e6f71150fe59705928596ffd1 \\\n    --hash=sha256:7b97fd01f0a61628af99d0efd52132fccc8c18fc5c509f13802dccf0574a19c2\n    # via\n    #   -r ci/official/requirements_updater/requirements.in\n    #   nvidia-cusolver-cu12\nnvidia-nccl-cu12==2.23.4 \\\n    --hash=sha256:aa946c8327e22ced28e7cef508a334673abc42064ec85f02d005ba1785ea4cec \\\n    --hash=sha256:b097258d9aab2fa9f686e33c6fe40ae57b27df60cedbd15d139701bb5509e0c1\n    # via -r ci/official/requirements_updater/requirements.in\nnvidia-nvjitlink-cu12==12.5.82 \\\n    --hash=sha256:98103729cc5226e13ca319a10bbf9433bbbd44ef64fe72f45f067cacc14b8d27 \\\n    --hash=sha256:e782564d705ff0bf61ac3e1bf730166da66dd2fe9012f111ede5fc49b64ae697 \\\n    --hash=sha256:f9b37bc5c8cf7509665cb6ada5aaa0ce65618f2332b7d3e78e9790511f111212\n    # via\n    #   -r ci/official/requirements_updater/requirements.in\n    #   nvidia-cufft-cu12\n    #   nvidia-cusolver-cu12\n    #   nvidia-cusparse-cu12\nopt-einsum==3.3.0 \\\n    --hash=sha256:2455e59e3947d3c275477df7f5205b30635e266fe6dc300e3d9f9646bfcea147 \\\n    --hash=sha256:59f6475f77bbc37dcf7cd748519c0ec60722e91e63ca114e68821c0c54a46549\n    # via\n    #   -r ci/official/requirements_updater/requirements.in\n    #   jax\npackaging==23.2 \\\n    --hash=sha256:048fb0e9405036518eaaf48a55953c750c11e1a1b68e0dd1a9d62ed0c092cfc5 \\\n    --hash=sha256:8c491190033a9af7e1d931d0b5dacc2ef47509b34dd0de67ed209b5203fc88c7\n    # via -r ci/official/requirements_updater/requirements.in\n    #   tb-nightly\nportpicker==1.6.0 \\\n    --hash=sha256:b2787a41404cf7edbe29b07b9e0ed863b09f2665dcc01c1eb0c2261c1e7d0755 \\\n    --hash=sha256:bd507fd6f96f65ee02781f2e674e9dc6c99bbfa6e3c39992e3916204c9d431fa\n    # via -r ci/official/requirements_updater/requirements.in\nprotobuf==4.25.3 \\\n    --hash=sha256:19b270aeaa0099f16d3ca02628546b8baefe2955bbe23224aaf856134eccf1e4 \\\n    --hash=sha256:209ba4cc916bab46f64e56b85b090607a676f66b473e6b762e6f1d9d591eb2e8 \\\n    --hash=sha256:25b5d0b42fd000320bd7830b349e3b696435f3b329810427a6bcce6a5492cc5c \\\n    --hash=sha256:7c8daa26095f82482307bc717364e7c13f4f1c99659be82890dcfc215194554d \\\n    --hash=sha256:c053062984e61144385022e53678fbded7aea14ebb3e0305ae3592fb219ccfa4 \\\n    --hash=sha256:d4198877797a83cbfe9bffa3803602bbe1625dc30d8a097365dbc762e5790faa \\\n    --hash=sha256:e3c97a1555fd6388f857770ff8b9703083de6bf1f9274a002a332d65fbb56c8c \\\n    --hash=sha256:e7cb0ae90dd83727f0c0718634ed56837bfeeee29a5f82a7514c03ee1364c019 \\\n    --hash=sha256:f0700d54bcf45424477e46a9f0944155b46fb0639d69728739c0e47bab83f2b9 \\\n    --hash=sha256:f1279ab38ecbfae7e456a108c5c0681e4956d5b1090027c1de0f934dfdb4b35c \\\n    --hash=sha256:f4f118245c4a087776e0a8408be33cf09f6c547442c00395fbfb116fac2f8ac2\n    # via tb-nightly\npsutil==5.9.8 \\\n    --hash=sha256:02615ed8c5ea222323408ceba16c60e99c3f91639b07da6373fb7e6539abc56d \\\n    --hash=sha256:05806de88103b25903dff19bb6692bd2e714ccf9e668d050d144012055cbca73 \\\n    --hash=sha256:26bd09967ae00920df88e0352a91cff1a78f8d69b3ecabbfe733610c0af486c8 \\\n    --hash=sha256:27cc40c3493bb10de1be4b3f07cae4c010ce715290a5be22b98493509c6299e2 \\\n    --hash=sha256:36f435891adb138ed3c9e58c6af3e2e6ca9ac2f365efe1f9cfef2794e6c93b4e \\\n    --hash=sha256:50187900d73c1381ba1454cf40308c2bf6f34268518b3f36a9b663ca87e65e36 \\\n    --hash=sha256:611052c4bc70432ec770d5d54f64206aa7203a101ec273a0cd82418c86503bb7 \\\n    --hash=sha256:6be126e3225486dff286a8fb9a06246a5253f4c7c53b475ea5f5ac934e64194c \\\n    --hash=sha256:7d79560ad97af658a0f6adfef8b834b53f64746d45b403f225b85c5c2c140eee \\\n    --hash=sha256:8cb6403ce6d8e047495a701dc7c5bd788add903f8986d523e3e20b98b733e421 \\\n    --hash=sha256:8db4c1b57507eef143a15a6884ca10f7c73876cdf5d51e713151c1236a0e68cf \\\n    --hash=sha256:aee678c8720623dc456fa20659af736241f575d79429a0e5e9cf88ae0605cc81 \\\n    --hash=sha256:bc56c2a1b0d15aa3eaa5a60c9f3f8e3e565303b465dbf57a1b730e7a2b9844e0 \\\n    --hash=sha256:bd1184ceb3f87651a67b2708d4c3338e9b10c5df903f2e3776b62303b26cb631 \\\n    --hash=sha256:d06016f7f8625a1825ba3732081d77c94589dca78b7a3fc072194851e88461a4 \\\n    --hash=sha256:d16bbddf0693323b8c6123dd804100241da461e41d6e332fb0ba6058f630f8c8\n    # via portpicker\npyelftools==0.31 \\\n    --hash=sha256:c774416b10310156879443b81187d182d8d9ee499660380e645918b50bc88f99 \\\n    --hash=sha256:f52de7b3c7e8c64c8abc04a79a1cf37ac5fb0b8a49809827130b858944840607\n    # via auditwheel\npygments==2.18.0 \\\n    --hash=sha256:786ff802f32e91311bff3889f6e9a86e81505fe99f2735bb6d60ae0c5004f199 \\\n    --hash=sha256:b8e6aca0523f3ab76fee51799c488e38782ac06eafcf95e7ba832985c8e7b13a\n    # via rich\nrequests==2.32.3 \\\n    --hash=sha256:55365417734eb18255590a9ff9eb97e9e1da868d4ccd6402399eaf68af20a760 \\\n    --hash=sha256:70761cfe03c773ceb22aa2f671b4757976145175cdfca038c02654d061d6dcc6\n    # via -r ci/official/requirements_updater/requirements.in\nrich==13.7.1 \\\n    --hash=sha256:4edbae314f59eb482f54e9e30bf00d33350aaa94f4bfcd4e9e3110e64d0d7222 \\\n    --hash=sha256:9be308cb1fe2f1f57d67ce99e95af38a1e2bc71ad9813b0e247cf7ffbcc3a432\n    # via keras-nightly\nscipy==1.13.1 \\\n    --hash=sha256:017367484ce5498445aade74b1d5ab377acdc65e27095155e448c88497755a5d \\\n    --hash=sha256:095a87a0312b08dfd6a6155cbbd310a8c51800fc931b8c0b84003014b874ed3c \\\n    --hash=sha256:20335853b85e9a49ff7572ab453794298bcf0354d8068c5f6775a0eabf350aca \\\n    --hash=sha256:27e52b09c0d3a1d5b63e1105f24177e544a222b43611aaf5bc44d4a0979e32f9 \\\n    --hash=sha256:2831f0dc9c5ea9edd6e51e6e769b655f08ec6db6e2e10f86ef39bd32eb11da54 \\\n    --hash=sha256:2ac65fb503dad64218c228e2dc2d0a0193f7904747db43014645ae139c8fad16 \\\n    --hash=sha256:392e4ec766654852c25ebad4f64e4e584cf19820b980bc04960bca0b0cd6eaa2 \\\n    --hash=sha256:436bbb42a94a8aeef855d755ce5a465479c721e9d684de76bf61a62e7c2b81d5 \\\n    --hash=sha256:45484bee6d65633752c490404513b9ef02475b4284c4cfab0ef946def50b3f59 \\\n    --hash=sha256:54f430b00f0133e2224c3ba42b805bfd0086fe488835effa33fa291561932326 \\\n    --hash=sha256:5713f62f781eebd8d597eb3f88b8bf9274e79eeabf63afb4a737abc6c84ad37b \\\n    --hash=sha256:5d72782f39716b2b3509cd7c33cdc08c96f2f4d2b06d51e52fb45a19ca0c86a1 \\\n    --hash=sha256:637e98dcf185ba7f8e663e122ebf908c4702420477ae52a04f9908707456ba4d \\\n    --hash=sha256:8335549ebbca860c52bf3d02f80784e91a004b71b059e3eea9678ba994796a24 \\\n    --hash=sha256:949ae67db5fa78a86e8fa644b9a6b07252f449dcf74247108c50e1d20d2b4627 \\\n    --hash=sha256:a014c2b3697bde71724244f63de2476925596c24285c7a637364761f8710891c \\\n    --hash=sha256:a78b4b3345f1b6f68a763c6e25c0c9a23a9fd0f39f5f3d200efe8feda560a5fa \\\n    --hash=sha256:cdd7dacfb95fea358916410ec61bbc20440f7860333aee6d882bb8046264e949 \\\n    --hash=sha256:cfa31f1def5c819b19ecc3a8b52d28ffdcc7ed52bb20c9a7589669dd3c250989 \\\n    --hash=sha256:d533654b7d221a6a97304ab63c41c96473ff04459e404b83275b60aa8f4b7004 \\\n    --hash=sha256:d605e9c23906d1994f55ace80e0125c587f96c020037ea6aa98d01b4bd2e222f \\\n    --hash=sha256:de3ade0e53bc1f21358aa74ff4830235d716211d7d077e340c7349bc3542e884 \\\n    --hash=sha256:e89369d27f9e7b0884ae559a3a956e77c02114cc60a6058b4e5011572eea9299 \\\n    --hash=sha256:eccfa1906eacc02de42d70ef4aecea45415f5be17e72b61bafcfd329bdc52e94 \\\n    --hash=sha256:f26264b282b9da0952a024ae34710c2aff7d27480ee91a2e82b7b7073c24722f\n    # via\n    #   -r ci/official/requirements_updater/requirements.in\n    #   jax\nsix==1.16.0 \\\n    --hash=sha256:1e61c37477a1626458e36f7b1d82aa5c9b094fa4802892072e49de9c60c4c926 \\\n    --hash=sha256:8abb2f1d86890a2dfb989f9a77cfcfd3e47c2a354b01111771326f8aa26e0254\n    # via\n    #   astunparse\n    #   google-pasta\n    #   tb-nightly\ntb-nightly==2.19.0a20240926 \\\n    --hash=sha256:4f2f4dd02eda684fbb2edd9cb46b7bd0ee7ba6ca35d38e4de2e293df8567c1b4\n    # via -r ci/official/requirements_updater/requirements.in\ntblib==2.0.0 \\\n    --hash=sha256:9100bfa016b047d5b980d66e7efed952fbd20bd85b56110aaf473cb97d18709a \\\n    --hash=sha256:a6df30f272c08bf8be66e0775fad862005d950a6b8449b94f7c788731d70ecd7\n    # via -r ci/official/requirements_updater/requirements.in\ntensorboard-data-server==0.7.2 \\\n    --hash=sha256:7e0610d205889588983836ec05dc098e80f97b7e7bbff7e994ebb78f578d0ddb \\\n    --hash=sha256:9fe5d24221b29625dbc7328b0436ca7fc1c23de4acf4d272f1180856e32f9f60 \\\n    --hash=sha256:ef687163c24185ae9754ed5650eb5bc4d84ff257aabdc33f0cc6f74d8ba54530\n    # via tb-nightly\ntensorflow-io-gcs-filesystem==0.37.1 \\\n    --hash=sha256:0df00891669390078a003cedbdd3b8e645c718b111917535fa1d7725e95cdb95 \\\n    --hash=sha256:249c12b830165841411ba71e08215d0e94277a49c551e6dd5d72aab54fe5491b \\\n    --hash=sha256:257aab23470a0796978efc9c2bcf8b0bc80f22e6298612a4c0a50d3f4e88060c \\\n    --hash=sha256:286389a203a5aee1a4fa2e53718c661091aa5fea797ff4fa6715ab8436b02e6c \\\n    --hash=sha256:32c50ab4e29a23c1f91cd0f9ab8c381a0ab10f45ef5c5252e94965916041737c \\\n    --hash=sha256:426de1173cb81fbd62becec2012fc00322a295326d90eb6c737fab636f182aed \\\n    --hash=sha256:6e1f2796b57e799a8ca1b75bf47c2aaa437c968408cc1a402a9862929e104cda \\\n    --hash=sha256:8943036bbf84e7a2be3705cb56f9c9df7c48c9e614bb941f0936c58e3ca89d6f \\\n    --hash=sha256:8febbfcc67c61e542a5ac1a98c7c20a91a5e1afc2e14b1ef0cb7c28bc3b6aa70 \\\n    --hash=sha256:9679b36e3a80921876f31685ab6f7270f3411a4cc51bc2847e80d0e4b5291e27 \\\n    --hash=sha256:b02f9c5f94fd62773954a04f69b68c4d576d076fd0db4ca25d5479f0fbfcdbad \\\n    --hash=sha256:ee5da49019670ed364f3e5fb86b46420841a6c3cb52a300553c63841671b3e6d \\\n    --hash=sha256:ee7c8ee5fe2fd8cb6392669ef16e71841133041fee8a330eff519ad9b36e4556 \\\n    --hash=sha256:fbb33f1745f218464a59cecd9a18e32ca927b0f4d77abd8f8671b645cc1a182f \\\n    --hash=sha256:fe8dcc6d222258a080ac3dfcaaaa347325ce36a7a046277f6b3e19abc1efb3c5 \\\n    --hash=sha256:ffebb6666a7bfc28005f4fbbb111a455b5e7d6cd3b12752b7050863ecb27d5cc\n    # via -r ci/official/requirements_updater/requirements.in\ntermcolor==2.3.0 \\\n    --hash=sha256:3afb05607b89aed0ffe25202399ee0867ad4d3cb4180d98aaf8eefa6a5f7d475 \\\n    --hash=sha256:b5b08f68937f138fe92f6c089b99f1e2da0ae56c52b78bf7075fd95420fd9a5a\n    # via -r ci/official/requirements_updater/requirements.in\ntyping-extensions==4.8.0 \\\n    --hash=sha256:8f92fc8806f9a6b641eaa5318da32b44d401efaac0f6678c9bc448ba3605faa0 \\\n    --hash=sha256:df8e4339e9cb77357558cbdbceca33c303714cf861d1eef15e1070055ae8b7ef\n    # via -r ci/official/requirements_updater/requirements.in\nurllib3==2.2.2 \\\n    --hash=sha256:a448b2f64d686155468037e1ace9f2d2199776e17f0a46610480d311f73e3472 \\\n    --hash=sha256:dd505485549a7a552833da5e6063639d0d177c04f23bc3864e41e5dc5f612168\n    # via requests\nwerkzeug==3.0.6 \\\n    --hash=sha256:1bc0c2310d2fbb07b1dd1105eba2f7af72f322e1e455f2f93c993bee8c8a5f17 \\\n    --hash=sha256:a8dd59d4de28ca70471a34cba79bed5f7ef2e036a76b3ab0835474246eb41f8d\n    # via tb-nightly\nwheel==0.41.3 \\\n    --hash=sha256:488609bc63a29322326e05560731bf7bfea8e48ad646e1f5e40d366607de0942 \\\n    --hash=sha256:4d4987ce51a49370ea65c0bfd2234e8ce80a12780820d9dc462597a6e60d0841\n    # via\n    #   -r ci/official/requirements_updater/requirements.in\n    #   astunparse\nwrapt==1.16.0 \\\n    --hash=sha256:0d2691979e93d06a95a26257adb7bfd0c93818e89b1406f5a28f36e0d8c1e1fc \\\n    --hash=sha256:14d7dc606219cdd7405133c713f2c218d4252f2a469003f8c46bb92d5d095d81 \\\n    --hash=sha256:1a5db485fe2de4403f13fafdc231b0dbae5eca4359232d2efc79025527375b09 \\\n    --hash=sha256:1acd723ee2a8826f3d53910255643e33673e1d11db84ce5880675954183ec47e \\\n    --hash=sha256:1ca9b6085e4f866bd584fb135a041bfc32cab916e69f714a7d1d397f8c4891ca \\\n    --hash=sha256:1dd50a2696ff89f57bd8847647a1c363b687d3d796dc30d4dd4a9d1689a706f0 \\\n    --hash=sha256:2076fad65c6736184e77d7d4729b63a6d1ae0b70da4868adeec40989858eb3fb \\\n    --hash=sha256:2a88e6010048489cda82b1326889ec075a8c856c2e6a256072b28eaee3ccf487 \\\n    --hash=sha256:3ebf019be5c09d400cf7b024aa52b1f3aeebeff51550d007e92c3c1c4afc2a40 \\\n    --hash=sha256:418abb18146475c310d7a6dc71143d6f7adec5b004ac9ce08dc7a34e2babdc5c \\\n    --hash=sha256:43aa59eadec7890d9958748db829df269f0368521ba6dc68cc172d5d03ed8060 \\\n    --hash=sha256:44a2754372e32ab315734c6c73b24351d06e77ffff6ae27d2ecf14cf3d229202 \\\n    --hash=sha256:490b0ee15c1a55be9c1bd8609b8cecd60e325f0575fc98f50058eae366e01f41 \\\n    --hash=sha256:49aac49dc4782cb04f58986e81ea0b4768e4ff197b57324dcbd7699c5dfb40b9 \\\n    --hash=sha256:5eb404d89131ec9b4f748fa5cfb5346802e5ee8836f57d516576e61f304f3b7b \\\n    --hash=sha256:5f15814a33e42b04e3de432e573aa557f9f0f56458745c2074952f564c50e664 \\\n    --hash=sha256:5f370f952971e7d17c7d1ead40e49f32345a7f7a5373571ef44d800d06b1899d \\\n    --hash=sha256:66027d667efe95cc4fa945af59f92c5a02c6f5bb6012bff9e60542c74c75c362 \\\n    --hash=sha256:66dfbaa7cfa3eb707bbfcd46dab2bc6207b005cbc9caa2199bcbc81d95071a00 \\\n    --hash=sha256:685f568fa5e627e93f3b52fda002c7ed2fa1800b50ce51f6ed1d572d8ab3e7fc \\\n    --hash=sha256:6906c4100a8fcbf2fa735f6059214bb13b97f75b1a61777fcf6432121ef12ef1 \\\n    --hash=sha256:6a42cd0cfa8ffc1915aef79cb4284f6383d8a3e9dcca70c445dcfdd639d51267 \\\n    --hash=sha256:6dcfcffe73710be01d90cae08c3e548d90932d37b39ef83969ae135d36ef3956 \\\n    --hash=sha256:6f6eac2360f2d543cc875a0e5efd413b6cbd483cb3ad7ebf888884a6e0d2e966 \\\n    --hash=sha256:72554a23c78a8e7aa02abbd699d129eead8b147a23c56e08d08dfc29cfdddca1 \\\n    --hash=sha256:73870c364c11f03ed072dda68ff7aea6d2a3a5c3fe250d917a429c7432e15228 \\\n    --hash=sha256:73aa7d98215d39b8455f103de64391cb79dfcad601701a3aa0dddacf74911d72 \\\n    --hash=sha256:75ea7d0ee2a15733684badb16de6794894ed9c55aa5e9903260922f0482e687d \\\n    --hash=sha256:7bd2d7ff69a2cac767fbf7a2b206add2e9a210e57947dd7ce03e25d03d2de292 \\\n    --hash=sha256:807cc8543a477ab7422f1120a217054f958a66ef7314f76dd9e77d3f02cdccd0 \\\n    --hash=sha256:8e9723528b9f787dc59168369e42ae1c3b0d3fadb2f1a71de14531d321ee05b0 \\\n    --hash=sha256:9090c9e676d5236a6948330e83cb89969f433b1943a558968f659ead07cb3b36 \\\n    --hash=sha256:9153ed35fc5e4fa3b2fe97bddaa7cbec0ed22412b85bcdaf54aeba92ea37428c \\\n    --hash=sha256:9159485323798c8dc530a224bd3ffcf76659319ccc7bbd52e01e73bd0241a0c5 \\\n    --hash=sha256:941988b89b4fd6b41c3f0bfb20e92bd23746579736b7343283297c4c8cbae68f \\\n    --hash=sha256:94265b00870aa407bd0cbcfd536f17ecde43b94fb8d228560a1e9d3041462d73 \\\n    --hash=sha256:98b5e1f498a8ca1858a1cdbffb023bfd954da4e3fa2c0cb5853d40014557248b \\\n    --hash=sha256:9b201ae332c3637a42f02d1045e1d0cccfdc41f1f2f801dafbaa7e9b4797bfc2 \\\n    --hash=sha256:a0ea261ce52b5952bf669684a251a66df239ec6d441ccb59ec7afa882265d593 \\\n    --hash=sha256:a33a747400b94b6d6b8a165e4480264a64a78c8a4c734b62136062e9a248dd39 \\\n    --hash=sha256:a452f9ca3e3267cd4d0fcf2edd0d035b1934ac2bd7e0e57ac91ad6b95c0c6389 \\\n    --hash=sha256:a86373cf37cd7764f2201b76496aba58a52e76dedfaa698ef9e9688bfd9e41cf \\\n    --hash=sha256:ac83a914ebaf589b69f7d0a1277602ff494e21f4c2f743313414378f8f50a4cf \\\n    --hash=sha256:aefbc4cb0a54f91af643660a0a150ce2c090d3652cf4052a5397fb2de549cd89 \\\n    --hash=sha256:b3646eefa23daeba62643a58aac816945cadc0afaf21800a1421eeba5f6cfb9c \\\n    --hash=sha256:b47cfad9e9bbbed2339081f4e346c93ecd7ab504299403320bf85f7f85c7d46c \\\n    --hash=sha256:b935ae30c6e7400022b50f8d359c03ed233d45b725cfdd299462f41ee5ffba6f \\\n    --hash=sha256:bb2dee3874a500de01c93d5c71415fcaef1d858370d405824783e7a8ef5db440 \\\n    --hash=sha256:bc57efac2da352a51cc4658878a68d2b1b67dbe9d33c36cb826ca449d80a8465 \\\n    --hash=sha256:bf5703fdeb350e36885f2875d853ce13172ae281c56e509f4e6eca049bdfb136 \\\n    --hash=sha256:c31f72b1b6624c9d863fc095da460802f43a7c6868c5dda140f51da24fd47d7b \\\n    --hash=sha256:c5cd603b575ebceca7da5a3a251e69561bec509e0b46e4993e1cac402b7247b8 \\\n    --hash=sha256:d2efee35b4b0a347e0d99d28e884dfd82797852d62fcd7ebdeee26f3ceb72cf3 \\\n    --hash=sha256:d462f28826f4657968ae51d2181a074dfe03c200d6131690b7d65d55b0f360f8 \\\n    --hash=sha256:d5e49454f19ef621089e204f862388d29e6e8d8b162efce05208913dde5b9ad6 \\\n    --hash=sha256:da4813f751142436b075ed7aa012a8778aa43a99f7b36afe9b742d3ed8bdc95e \\\n    --hash=sha256:db2e408d983b0e61e238cf579c09ef7020560441906ca990fe8412153e3b291f \\\n    --hash=sha256:db98ad84a55eb09b3c32a96c576476777e87c520a34e2519d3e59c44710c002c \\\n    --hash=sha256:dbed418ba5c3dce92619656802cc5355cb679e58d0d89b50f116e4a9d5a9603e \\\n    --hash=sha256:dcdba5c86e368442528f7060039eda390cc4091bfd1dca41e8046af7c910dda8 \\\n    --hash=sha256:decbfa2f618fa8ed81c95ee18a387ff973143c656ef800c9f24fb7e9c16054e2 \\\n    --hash=sha256:e4fdb9275308292e880dcbeb12546df7f3e0f96c6b41197e0cf37d2826359020 \\\n    --hash=sha256:eb1b046be06b0fce7249f1d025cd359b4b80fc1c3e24ad9eca33e0dcdb2e4a35 \\\n    --hash=sha256:eb6e651000a19c96f452c85132811d25e9264d836951022d6e81df2fff38337d \\\n    --hash=sha256:ed867c42c268f876097248e05b6117a65bcd1e63b779e916fe2e33cd6fd0d3c3 \\\n    --hash=sha256:edfad1d29c73f9b863ebe7082ae9321374ccb10879eeabc84ba3b69f2579d537 \\\n    --hash=sha256:f2058f813d4f2b5e3a9eb2eb3faf8f1d99b81c3e51aeda4b168406443e8ba809 \\\n    --hash=sha256:f6b2d0c6703c988d334f297aa5df18c45e97b0af3679bb75059e0e0bd8b1069d \\\n    --hash=sha256:f8212564d49c50eb4565e502814f694e240c55551a5f1bc841d4fcaabb0a9b8a \\\n    --hash=sha256:ffa565331890b90056c01db69c0fe634a776f8019c143a5ae265f9c6bc4bd6d4\n    # via -r ci/official/requirements_updater/requirements.in\n\n# The following packages are considered to be unsafe in a requirements file:\nsetuptools==70.0.0 \\\n    --hash=sha256:54faa7f2e8d2d11bcd2c07bed282eef1046b5c080d1c32add737d7b5817b1ad4 \\\n    --hash=sha256:f211a66637b8fa059bb28183da127d4e86396c991a942b028c6650d4319c3fd0\n    # via\n    #   -r ci/official/requirements_updater/requirements.in\n    #   tb-nightly\n"
        },
        {
          "name": "requirements_lock_3_9.txt",
          "type": "blob",
          "size": 52.587890625,
          "content": "#\n# This file is autogenerated by pip-compile with Python 3.9\n# by the following command:\n#\n#    bazel run //ci/official/requirements_updater:requirements.update\n#\nabsl-py==2.1.0 \\\n    --hash=sha256:526a04eadab8b4ee719ce68f204172ead1027549089702d99b9059f129ff1308 \\\n    --hash=sha256:7820790efbb316739cde8b4e19357243fc3608a152024288513dd968d7d959ff\n    # via\n    #   keras-nightly\n    #   tb-nightly\nastor==0.7.1 \\\n    --hash=sha256:95c30d87a6c2cf89aa628b87398466840f0ad8652f88eb173125a6df8533fb8d \\\n    --hash=sha256:fb503b9e2fdd05609fbf557b916b4a7824171203701660f0c55bbf5a7a68713e\n    # via -r ci/official/requirements_updater/requirements.in\nastunparse==1.6.3 \\\n    --hash=sha256:5ad93a8456f0d084c3456d059fd9a92cce667963232cbf763eac3bc5b7940872 \\\n    --hash=sha256:c2652417f2c8b5bb325c885ae329bdf3f86424075c4fd1a128674bc6fba4b8e8\n    # via -r ci/official/requirements_updater/requirements.in\nauditwheel==6.1.0 \\\n    --hash=sha256:3bdc686e774cf9e355e924b0fe5a562d55caa385d72234ffe7b81b378dba360f \\\n    --hash=sha256:e52f734861859e3743eb29fcac7da9c4921a1e4bea58f954b52f2926f8e9e364\n    # via -r ci/official/requirements_updater/requirements.in\ncertifi==2024.7.4 \\\n    --hash=sha256:5a1e7645bc0ec61a09e26c36f6106dd4cf40c6db3a1fb6352b0244e7fb057c7b \\\n    --hash=sha256:c198e21b1289c2ab85ee4e67bb4b4ef3ead0892059901a8d5b622f24a1101e90\n    # via requests\ncharset-normalizer==3.3.2 \\\n    --hash=sha256:06435b539f889b1f6f4ac1758871aae42dc3a8c0e24ac9e60c2384973ad73027 \\\n    --hash=sha256:06a81e93cd441c56a9b65d8e1d043daeb97a3d0856d177d5c90ba85acb3db087 \\\n    --hash=sha256:0a55554a2fa0d408816b3b5cedf0045f4b8e1a6065aec45849de2d6f3f8e9786 \\\n    --hash=sha256:0b2b64d2bb6d3fb9112bafa732def486049e63de9618b5843bcdd081d8144cd8 \\\n    --hash=sha256:10955842570876604d404661fbccbc9c7e684caf432c09c715ec38fbae45ae09 \\\n    --hash=sha256:122c7fa62b130ed55f8f285bfd56d5f4b4a5b503609d181f9ad85e55c89f4185 \\\n    --hash=sha256:1ceae2f17a9c33cb48e3263960dc5fc8005351ee19db217e9b1bb15d28c02574 \\\n    --hash=sha256:1d3193f4a680c64b4b6a9115943538edb896edc190f0b222e73761716519268e \\\n    --hash=sha256:1f79682fbe303db92bc2b1136016a38a42e835d932bab5b3b1bfcfbf0640e519 \\\n    --hash=sha256:2127566c664442652f024c837091890cb1942c30937add288223dc895793f898 \\\n    --hash=sha256:22afcb9f253dac0696b5a4be4a1c0f8762f8239e21b99680099abd9b2b1b2269 \\\n    --hash=sha256:25baf083bf6f6b341f4121c2f3c548875ee6f5339300e08be3f2b2ba1721cdd3 \\\n    --hash=sha256:2e81c7b9c8979ce92ed306c249d46894776a909505d8f5a4ba55b14206e3222f \\\n    --hash=sha256:3287761bc4ee9e33561a7e058c72ac0938c4f57fe49a09eae428fd88aafe7bb6 \\\n    --hash=sha256:34d1c8da1e78d2e001f363791c98a272bb734000fcef47a491c1e3b0505657a8 \\\n    --hash=sha256:37e55c8e51c236f95b033f6fb391d7d7970ba5fe7ff453dad675e88cf303377a \\\n    --hash=sha256:3d47fa203a7bd9c5b6cee4736ee84ca03b8ef23193c0d1ca99b5089f72645c73 \\\n    --hash=sha256:3e4d1f6587322d2788836a99c69062fbb091331ec940e02d12d179c1d53e25fc \\\n    --hash=sha256:42cb296636fcc8b0644486d15c12376cb9fa75443e00fb25de0b8602e64c1714 \\\n    --hash=sha256:45485e01ff4d3630ec0d9617310448a8702f70e9c01906b0d0118bdf9d124cf2 \\\n    --hash=sha256:4a78b2b446bd7c934f5dcedc588903fb2f5eec172f3d29e52a9096a43722adfc \\\n    --hash=sha256:4ab2fe47fae9e0f9dee8c04187ce5d09f48eabe611be8259444906793ab7cbce \\\n    --hash=sha256:4d0d1650369165a14e14e1e47b372cfcb31d6ab44e6e33cb2d4e57265290044d \\\n    --hash=sha256:549a3a73da901d5bc3ce8d24e0600d1fa85524c10287f6004fbab87672bf3e1e \\\n    --hash=sha256:55086ee1064215781fff39a1af09518bc9255b50d6333f2e4c74ca09fac6a8f6 \\\n    --hash=sha256:572c3763a264ba47b3cf708a44ce965d98555f618ca42c926a9c1616d8f34269 \\\n    --hash=sha256:573f6eac48f4769d667c4442081b1794f52919e7edada77495aaed9236d13a96 \\\n    --hash=sha256:5b4c145409bef602a690e7cfad0a15a55c13320ff7a3ad7ca59c13bb8ba4d45d \\\n    --hash=sha256:6463effa3186ea09411d50efc7d85360b38d5f09b870c48e4600f63af490e56a \\\n    --hash=sha256:65f6f63034100ead094b8744b3b97965785388f308a64cf8d7c34f2f2e5be0c4 \\\n    --hash=sha256:663946639d296df6a2bb2aa51b60a2454ca1cb29835324c640dafb5ff2131a77 \\\n    --hash=sha256:6897af51655e3691ff853668779c7bad41579facacf5fd7253b0133308cf000d \\\n    --hash=sha256:68d1f8a9e9e37c1223b656399be5d6b448dea850bed7d0f87a8311f1ff3dabb0 \\\n    --hash=sha256:6ac7ffc7ad6d040517be39eb591cac5ff87416c2537df6ba3cba3bae290c0fed \\\n    --hash=sha256:6b3251890fff30ee142c44144871185dbe13b11bab478a88887a639655be1068 \\\n    --hash=sha256:6c4caeef8fa63d06bd437cd4bdcf3ffefe6738fb1b25951440d80dc7df8c03ac \\\n    --hash=sha256:6ef1d82a3af9d3eecdba2321dc1b3c238245d890843e040e41e470ffa64c3e25 \\\n    --hash=sha256:753f10e867343b4511128c6ed8c82f7bec3bd026875576dfd88483c5c73b2fd8 \\\n    --hash=sha256:7cd13a2e3ddeed6913a65e66e94b51d80a041145a026c27e6bb76c31a853c6ab \\\n    --hash=sha256:7ed9e526742851e8d5cc9e6cf41427dfc6068d4f5a3bb03659444b4cabf6bc26 \\\n    --hash=sha256:7f04c839ed0b6b98b1a7501a002144b76c18fb1c1850c8b98d458ac269e26ed2 \\\n    --hash=sha256:802fe99cca7457642125a8a88a084cef28ff0cf9407060f7b93dca5aa25480db \\\n    --hash=sha256:80402cd6ee291dcb72644d6eac93785fe2c8b9cb30893c1af5b8fdd753b9d40f \\\n    --hash=sha256:8465322196c8b4d7ab6d1e049e4c5cb460d0394da4a27d23cc242fbf0034b6b5 \\\n    --hash=sha256:86216b5cee4b06df986d214f664305142d9c76df9b6512be2738aa72a2048f99 \\\n    --hash=sha256:87d1351268731db79e0f8e745d92493ee2841c974128ef629dc518b937d9194c \\\n    --hash=sha256:8bdb58ff7ba23002a4c5808d608e4e6c687175724f54a5dade5fa8c67b604e4d \\\n    --hash=sha256:8c622a5fe39a48f78944a87d4fb8a53ee07344641b0562c540d840748571b811 \\\n    --hash=sha256:8d756e44e94489e49571086ef83b2bb8ce311e730092d2c34ca8f7d925cb20aa \\\n    --hash=sha256:8f4a014bc36d3c57402e2977dada34f9c12300af536839dc38c0beab8878f38a \\\n    --hash=sha256:9063e24fdb1e498ab71cb7419e24622516c4a04476b17a2dab57e8baa30d6e03 \\\n    --hash=sha256:90d558489962fd4918143277a773316e56c72da56ec7aa3dc3dbbe20fdfed15b \\\n    --hash=sha256:923c0c831b7cfcb071580d3f46c4baf50f174be571576556269530f4bbd79d04 \\\n    --hash=sha256:95f2a5796329323b8f0512e09dbb7a1860c46a39da62ecb2324f116fa8fdc85c \\\n    --hash=sha256:96b02a3dc4381e5494fad39be677abcb5e6634bf7b4fa83a6dd3112607547001 \\\n    --hash=sha256:9f96df6923e21816da7e0ad3fd47dd8f94b2a5ce594e00677c0013018b813458 \\\n    --hash=sha256:a10af20b82360ab00827f916a6058451b723b4e65030c5a18577c8b2de5b3389 \\\n    --hash=sha256:a50aebfa173e157099939b17f18600f72f84eed3049e743b68ad15bd69b6bf99 \\\n    --hash=sha256:a981a536974bbc7a512cf44ed14938cf01030a99e9b3a06dd59578882f06f985 \\\n    --hash=sha256:a9a8e9031d613fd2009c182b69c7b2c1ef8239a0efb1df3f7c8da66d5dd3d537 \\\n    --hash=sha256:ae5f4161f18c61806f411a13b0310bea87f987c7d2ecdbdaad0e94eb2e404238 \\\n    --hash=sha256:aed38f6e4fb3f5d6bf81bfa990a07806be9d83cf7bacef998ab1a9bd660a581f \\\n    --hash=sha256:b01b88d45a6fcb69667cd6d2f7a9aeb4bf53760d7fc536bf679ec94fe9f3ff3d \\\n    --hash=sha256:b261ccdec7821281dade748d088bb6e9b69e6d15b30652b74cbbac25e280b796 \\\n    --hash=sha256:b2b0a0c0517616b6869869f8c581d4eb2dd83a4d79e0ebcb7d373ef9956aeb0a \\\n    --hash=sha256:b4a23f61ce87adf89be746c8a8974fe1c823c891d8f86eb218bb957c924bb143 \\\n    --hash=sha256:bd8f7df7d12c2db9fab40bdd87a7c09b1530128315d047a086fa3ae3435cb3a8 \\\n    --hash=sha256:beb58fe5cdb101e3a055192ac291b7a21e3b7ef4f67fa1d74e331a7f2124341c \\\n    --hash=sha256:c002b4ffc0be611f0d9da932eb0f704fe2602a9a949d1f738e4c34c75b0863d5 \\\n    --hash=sha256:c083af607d2515612056a31f0a8d9e0fcb5876b7bfc0abad3ecd275bc4ebc2d5 \\\n    --hash=sha256:c180f51afb394e165eafe4ac2936a14bee3eb10debc9d9e4db8958fe36afe711 \\\n    --hash=sha256:c235ebd9baae02f1b77bcea61bce332cb4331dc3617d254df3323aa01ab47bd4 \\\n    --hash=sha256:cd70574b12bb8a4d2aaa0094515df2463cb429d8536cfb6c7ce983246983e5a6 \\\n    --hash=sha256:d0eccceffcb53201b5bfebb52600a5fb483a20b61da9dbc885f8b103cbe7598c \\\n    --hash=sha256:d965bba47ddeec8cd560687584e88cf699fd28f192ceb452d1d7ee807c5597b7 \\\n    --hash=sha256:db364eca23f876da6f9e16c9da0df51aa4f104a972735574842618b8c6d999d4 \\\n    --hash=sha256:ddbb2551d7e0102e7252db79ba445cdab71b26640817ab1e3e3648dad515003b \\\n    --hash=sha256:deb6be0ac38ece9ba87dea880e438f25ca3eddfac8b002a2ec3d9183a454e8ae \\\n    --hash=sha256:e06ed3eb3218bc64786f7db41917d4e686cc4856944f53d5bdf83a6884432e12 \\\n    --hash=sha256:e27ad930a842b4c5eb8ac0016b0a54f5aebbe679340c26101df33424142c143c \\\n    --hash=sha256:e537484df0d8f426ce2afb2d0f8e1c3d0b114b83f8850e5f2fbea0e797bd82ae \\\n    --hash=sha256:eb00ed941194665c332bf8e078baf037d6c35d7c4f3102ea2d4f16ca94a26dc8 \\\n    --hash=sha256:eb6904c354526e758fda7167b33005998fb68c46fbc10e013ca97f21ca5c8887 \\\n    --hash=sha256:eb8821e09e916165e160797a6c17edda0679379a4be5c716c260e836e122f54b \\\n    --hash=sha256:efcb3f6676480691518c177e3b465bcddf57cea040302f9f4e6e191af91174d4 \\\n    --hash=sha256:f27273b60488abe721a075bcca6d7f3964f9f6f067c8c4c605743023d7d3944f \\\n    --hash=sha256:f30c3cb33b24454a82faecaf01b19c18562b1e89558fb6c56de4d9118a032fd5 \\\n    --hash=sha256:fb69256e180cb6c8a894fee62b3afebae785babc1ee98b81cdf68bbca1987f33 \\\n    --hash=sha256:fd1abc0d89e30cc4e02e4064dc67fcc51bd941eb395c502aac3ec19fab46b519 \\\n    --hash=sha256:ff8fa367d09b717b2a17a052544193ad76cd49979c805768879cb63d9ca50561\n    # via requests\ndill==0.3.7 \\\n    --hash=sha256:76b122c08ef4ce2eedcd4d1abd8e641114bfc6c2867f49f3c41facf65bf19f5e \\\n    --hash=sha256:cc1c8b182eb3013e24bd475ff2e9295af86c1a38eb1aff128dac8962a9ce3c03\n    # via -r ci/official/requirements_updater/requirements.in\ndm-tree==0.1.8 \\\n    --hash=sha256:054b461f8176f4bce7a21f7b1870f873a1ced3bdbe1282c816c550bb43c71fa6 \\\n    --hash=sha256:09964470f76a5201aff2e8f9b26842976de7889300676f927930f6285e256760 \\\n    --hash=sha256:0d3172394079a86c3a759179c65f64c48d1a42b89495fcf38976d11cc3bb952c \\\n    --hash=sha256:0e9620ccf06393eb6b613b5e366469304622d4ea96ae6540b28a33840e6c89cf \\\n    --hash=sha256:0fcaabbb14e7980377439e7140bd05552739ca5e515ecb3119f234acee4b9430 \\\n    --hash=sha256:1607ce49aa42f010d1e5e616d92ce899d66835d4d8bea49679582435285515de \\\n    --hash=sha256:181c35521d480d0365f39300542cb6cd7fd2b77351bb43d7acfda15aef63b317 \\\n    --hash=sha256:1d7c26e431fc93cc7e0cba867eb000db6a05f6f2b25af11ac4e9dada88fc5bca \\\n    --hash=sha256:1fe962015b2fe1282892b28ebe962faed53c7f98d942da9a4625cbf27baef913 \\\n    --hash=sha256:250b692fb75f45f02e2f58fbef9ab338904ef334b90557565621fa251df267cf \\\n    --hash=sha256:2869228d9c619074de501a3c10dc7f07c75422f8fab36ecdcb859b6f1b1ec3ef \\\n    --hash=sha256:28c52cbf4f8b3dbd0beaedf44f69fa85eec5e9dede612e08035e06ada6ec9426 \\\n    --hash=sha256:2f7915660f59c09068e428613c480150180df1060561fd0d1470684ae7007bd1 \\\n    --hash=sha256:343a4a4ebaa127451ff971254a4be4084eb4bdc0b2513c32b46f6f728fd03f9e \\\n    --hash=sha256:35cc164a79336bfcfafb47e5f297898359123bbd3330c1967f0c4994f9cf9f60 \\\n    --hash=sha256:378cc8ad93c5fe3590f405a309980721f021c790ca1bdf9b15bb1d59daec57f5 \\\n    --hash=sha256:39070ba268c0491af9fe7a58644d99e8b4f2cde6e5884ba3380bddc84ed43d5f \\\n    --hash=sha256:435227cf3c5dc63f4de054cf3d00183790bd9ead4c3623138c74dde7f67f521b \\\n    --hash=sha256:5483dca4d7eb1a0d65fe86d3b6a53ae717face83c1f17e0887b1a4a64ae5c410 \\\n    --hash=sha256:694c3654cfd2a81552c08ec66bb5c4a3d48fa292b9a181880fb081c36c5b9134 \\\n    --hash=sha256:75c5d528bb992981c20793b6b453e91560784215dffb8a5440ba999753c14ceb \\\n    --hash=sha256:803bfc53b4659f447ac694dbd04235f94a73ef7c1fd1e0df7c84ac41e0bc963b \\\n    --hash=sha256:81fce77f22a302d7a5968aebdf4efafef4def7ce96528719a354e6990dcd49c7 \\\n    --hash=sha256:83b7764de0d855338abefc6e3ee9fe40d301668310aa3baea3f778ff051f4393 \\\n    --hash=sha256:8c60a7eadab64c2278861f56bca320b2720f163dca9d7558103c3b77f2416571 \\\n    --hash=sha256:8ed3564abed97c806db122c2d3e1a2b64c74a63debe9903aad795167cc301368 \\\n    --hash=sha256:94d3f0826311f45ee19b75f5b48c99466e4218a0489e81c0f0167bda50cacf22 \\\n    --hash=sha256:96a548a406a6fb15fe58f6a30a57ff2f2aafbf25f05afab00c8f5e5977b6c715 \\\n    --hash=sha256:a5d819c38c03f0bb5b3b3703c60e4b170355a0fc6b5819325bf3d4ceb3ae7e80 \\\n    --hash=sha256:ad16ceba90a56ec47cf45b21856d14962ac314787975ef786efb5e6e9ca75ec7 \\\n    --hash=sha256:af4b3d372f2477dcd89a6e717e4a575ca35ccc20cc4454a8a4b6f8838a00672d \\\n    --hash=sha256:b095ba4f8ca1ba19350fd53cf1f8f3eb0bd406aa28af64a6dfc86707b32a810a \\\n    --hash=sha256:b9bd9b9ccb59409d33d51d84b7668010c04c2af7d4a371632874c1ca356cff3d \\\n    --hash=sha256:b9f89a454e98806b44fe9d40ec9eee61f848388f7e79ac2371a55679bd5a3ac6 \\\n    --hash=sha256:bb2d109f42190225112da899b9f3d46d0d5f26aef501c61e43529fe9322530b5 \\\n    --hash=sha256:c0a94aba18a35457a1b5cd716fd7b46c5dafdc4cf7869b4bae665b91c4682a8e \\\n    --hash=sha256:c5c8c12e3fda754ef6af94161bacdaeda816d941995fac415d6855c6c386af68 \\\n    --hash=sha256:d1612fcaecd79023dbc6a6ae48d51a80beb5c385d6f3f6d71688e57bc8d07de8 \\\n    --hash=sha256:d16e1f2a073604cfcc09f7131ae8d534674f43c3aef4c25742eae295bc60d04f \\\n    --hash=sha256:d20f2faa3672b52e5013f4077117bfb99c4cfc0b445d3bde1584c34032b57436 \\\n    --hash=sha256:d40fa4106ca6edc66760246a08f500ec0c85ef55c762fb4a363f6ee739ba02ee \\\n    --hash=sha256:de287fabc464b8734be251e46e06aa9aa1001f34198da2b6ce07bd197172b9cb \\\n    --hash=sha256:e4d714371bb08839e4e5e29024fc95832d9affe129825ef38836b143028bd144 \\\n    --hash=sha256:ea9e59e0451e7d29aece402d9f908f2e2a80922bcde2ebfd5dcb07750fcbfee8 \\\n    --hash=sha256:f7ac31b9aecccb2c6e1ab29706f6ded3eba0c2c69c770322c9c685929c3d6afb \\\n    --hash=sha256:fa42a605d099ee7d41ba2b5fb75e21423951fd26e5d50583a00471238fb3021d\n    # via keras-nightly\nflatbuffers==24.3.25 \\\n    --hash=sha256:8dbdec58f935f3765e4f7f3cf635ac3a77f83568138d6a2311f524ec96364812 \\\n    --hash=sha256:de2ec5b203f21441716617f38443e0a8ebf3d25bf0d9c0bb0ce68fa00ad546a4\n    # via -r ci/official/requirements_updater/requirements.in\ngast==0.4.0 \\\n    --hash=sha256:40feb7b8b8434785585ab224d1568b857edb18297e5a3047f1ba012bc83b42c1 \\\n    --hash=sha256:b7adcdd5adbebf1adf17378da5ba3f543684dbec47b1cda1f3997e573cd542c4\n    # via -r ci/official/requirements_updater/requirements.in\ngoogle-pasta==0.2.0 \\\n    --hash=sha256:4612951da876b1a10fe3960d7226f0c7682cf901e16ac06e473b267a5afa8954 \\\n    --hash=sha256:b32482794a366b5366a32c92a9a9201b107821889935a02b3e51f6b432ea84ed \\\n    --hash=sha256:c9f2c8dfc8f96d0d5808299920721be30c9eec37f2389f28904f454565c8a16e\n    # via -r ci/official/requirements_updater/requirements.in\ngrpcio==1.64.1 \\\n    --hash=sha256:03b43d0ccf99c557ec671c7dede64f023c7da9bb632ac65dbc57f166e4970040 \\\n    --hash=sha256:0a12ddb1678ebc6a84ec6b0487feac020ee2b1659cbe69b80f06dbffdb249122 \\\n    --hash=sha256:0a2813093ddb27418a4c99f9b1c223fab0b053157176a64cc9db0f4557b69bd9 \\\n    --hash=sha256:0cc79c982ccb2feec8aad0e8fb0d168bcbca85bc77b080d0d3c5f2f15c24ea8f \\\n    --hash=sha256:1257b76748612aca0f89beec7fa0615727fd6f2a1ad580a9638816a4b2eb18fd \\\n    --hash=sha256:1262402af5a511c245c3ae918167eca57342c72320dffae5d9b51840c4b2f86d \\\n    --hash=sha256:19264fc964576ddb065368cae953f8d0514ecc6cb3da8903766d9fb9d4554c33 \\\n    --hash=sha256:198908f9b22e2672a998870355e226a725aeab327ac4e6ff3a1399792ece4762 \\\n    --hash=sha256:1de403fc1305fd96cfa75e83be3dee8538f2413a6b1685b8452301c7ba33c294 \\\n    --hash=sha256:20405cb8b13fd779135df23fabadc53b86522d0f1cba8cca0e87968587f50650 \\\n    --hash=sha256:2981c7365a9353f9b5c864595c510c983251b1ab403e05b1ccc70a3d9541a73b \\\n    --hash=sha256:2c3c1b90ab93fed424e454e93c0ed0b9d552bdf1b0929712b094f5ecfe7a23ad \\\n    --hash=sha256:39b9d0acaa8d835a6566c640f48b50054f422d03e77e49716d4c4e8e279665a1 \\\n    --hash=sha256:3b64ae304c175671efdaa7ec9ae2cc36996b681eb63ca39c464958396697daff \\\n    --hash=sha256:4657d24c8063e6095f850b68f2d1ba3b39f2b287a38242dcabc166453e950c59 \\\n    --hash=sha256:4d6dab6124225496010bd22690f2d9bd35c7cbb267b3f14e7a3eb05c911325d4 \\\n    --hash=sha256:55260032b95c49bee69a423c2f5365baa9369d2f7d233e933564d8a47b893027 \\\n    --hash=sha256:55697ecec192bc3f2f3cc13a295ab670f51de29884ca9ae6cd6247df55df2502 \\\n    --hash=sha256:5841dd1f284bd1b3d8a6eca3a7f062b06f1eec09b184397e1d1d43447e89a7ae \\\n    --hash=sha256:58b1041e7c870bb30ee41d3090cbd6f0851f30ae4eb68228955d973d3efa2e61 \\\n    --hash=sha256:5e42634a989c3aa6049f132266faf6b949ec2a6f7d302dbb5c15395b77d757eb \\\n    --hash=sha256:5e56462b05a6f860b72f0fa50dca06d5b26543a4e88d0396259a07dc30f4e5aa \\\n    --hash=sha256:5f8b75f64d5d324c565b263c67dbe4f0af595635bbdd93bb1a88189fc62ed2e5 \\\n    --hash=sha256:62b4e6eb7bf901719fce0ca83e3ed474ae5022bb3827b0a501e056458c51c0a1 \\\n    --hash=sha256:6503b64c8b2dfad299749cad1b595c650c91e5b2c8a1b775380fcf8d2cbba1e9 \\\n    --hash=sha256:6c024ffc22d6dc59000faf8ad781696d81e8e38f4078cb0f2630b4a3cf231a90 \\\n    --hash=sha256:73819689c169417a4f978e562d24f2def2be75739c4bed1992435d007819da1b \\\n    --hash=sha256:75dbbf415026d2862192fe1b28d71f209e2fd87079d98470db90bebe57b33179 \\\n    --hash=sha256:8caee47e970b92b3dd948371230fcceb80d3f2277b3bf7fbd7c0564e7d39068e \\\n    --hash=sha256:8d51dd1c59d5fa0f34266b80a3805ec29a1f26425c2a54736133f6d87fc4968a \\\n    --hash=sha256:940e3ec884520155f68a3b712d045e077d61c520a195d1a5932c531f11883489 \\\n    --hash=sha256:a011ac6c03cfe162ff2b727bcb530567826cec85eb8d4ad2bfb4bd023287a52d \\\n    --hash=sha256:a3a035c37ce7565b8f4f35ff683a4db34d24e53dc487e47438e434eb3f701b2a \\\n    --hash=sha256:a5e771d0252e871ce194d0fdcafd13971f1aae0ddacc5f25615030d5df55c3a2 \\\n    --hash=sha256:ac15b6c2c80a4d1338b04d42a02d376a53395ddf0ec9ab157cbaf44191f3ffdd \\\n    --hash=sha256:b1a82e0b9b3022799c336e1fc0f6210adc019ae84efb7321d668129d28ee1efb \\\n    --hash=sha256:bac71b4b28bc9af61efcdc7630b166440bbfbaa80940c9a697271b5e1dabbc61 \\\n    --hash=sha256:bbc5b1d78a7822b0a84c6f8917faa986c1a744e65d762ef6d8be9d75677af2ca \\\n    --hash=sha256:c1a786ac592b47573a5bb7e35665c08064a5d77ab88a076eec11f8ae86b3e3f6 \\\n    --hash=sha256:c84ad903d0d94311a2b7eea608da163dace97c5fe9412ea311e72c3684925602 \\\n    --hash=sha256:d4d29cc612e1332237877dfa7fe687157973aab1d63bd0f84cf06692f04c0367 \\\n    --hash=sha256:e3d9f8d1221baa0ced7ec7322a981e28deb23749c76eeeb3d33e18b72935ab62 \\\n    --hash=sha256:e7cd5c1325f6808b8ae31657d281aadb2a51ac11ab081ae335f4f7fc44c1721d \\\n    --hash=sha256:ed6091fa0adcc7e4ff944090cf203a52da35c37a130efa564ded02b7aff63bcd \\\n    --hash=sha256:ee73a2f5ca4ba44fa33b4d7d2c71e2c8a9e9f78d53f6507ad68e7d2ad5f64a22 \\\n    --hash=sha256:f10193c69fc9d3d726e83bbf0f3d316f1847c3071c8c93d8090cf5f326b14309\n    # via\n    #   -r ci/official/requirements_updater/requirements.in\n    #   tb-nightly\nh5py==3.11.0 \\\n    --hash=sha256:083e0329ae534a264940d6513f47f5ada617da536d8dccbafc3026aefc33c90e \\\n    --hash=sha256:1625fd24ad6cfc9c1ccd44a66dac2396e7ee74940776792772819fc69f3a3731 \\\n    --hash=sha256:21dbdc5343f53b2e25404673c4f00a3335aef25521bd5fa8c707ec3833934892 \\\n    --hash=sha256:52c416f8eb0daae39dabe71415cb531f95dce2d81e1f61a74537a50c63b28ab3 \\\n    --hash=sha256:55106b04e2c83dfb73dc8732e9abad69d83a436b5b82b773481d95d17b9685e1 \\\n    --hash=sha256:67462d0669f8f5459529de179f7771bd697389fcb3faab54d63bf788599a48ea \\\n    --hash=sha256:6c4b760082626120031d7902cd983d8c1f424cdba2809f1067511ef283629d4b \\\n    --hash=sha256:731839240c59ba219d4cb3bc5880d438248533366f102402cfa0621b71796b62 \\\n    --hash=sha256:754c0c2e373d13d6309f408325343b642eb0f40f1a6ad21779cfa9502209e150 \\\n    --hash=sha256:75bd7b3d93fbeee40860fd70cdc88df4464e06b70a5ad9ce1446f5f32eb84007 \\\n    --hash=sha256:77b19a40788e3e362b54af4dcf9e6fde59ca016db2c61360aa30b47c7b7cef00 \\\n    --hash=sha256:7b7e8f78072a2edec87c9836f25f34203fd492a4475709a18b417a33cfb21fa9 \\\n    --hash=sha256:8ec9df3dd2018904c4cc06331951e274f3f3fd091e6d6cc350aaa90fa9b42a76 \\\n    --hash=sha256:a76cae64080210389a571c7d13c94a1a6cf8cb75153044fd1f822a962c97aeab \\\n    --hash=sha256:aa6ae84a14103e8dc19266ef4c3e5d7c00b68f21d07f2966f0ca7bdb6c2761fb \\\n    --hash=sha256:bbd732a08187a9e2a6ecf9e8af713f1d68256ee0f7c8b652a32795670fb481ba \\\n    --hash=sha256:c072655ad1d5fe9ef462445d3e77a8166cbfa5e599045f8aa3c19b75315f10e5 \\\n    --hash=sha256:d9c944d364688f827dc889cf83f1fca311caf4fa50b19f009d1f2b525edd33a3 \\\n    --hash=sha256:ef4e2f338fc763f50a8113890f455e1a70acd42a4d083370ceb80c463d803972 \\\n    --hash=sha256:f3736fe21da2b7d8a13fe8fe415f1272d2a1ccdeff4849c1421d2fb30fd533bc \\\n    --hash=sha256:f4e025e852754ca833401777c25888acb96889ee2c27e7e629a19aee288833f0\n    # via\n    #   -r ci/official/requirements_updater/requirements.in\n    #   keras-nightly\nidna==3.7 \\\n    --hash=sha256:028ff3aadf0609c1fd278d8ea3089299412a7a8b9bd005dd08b9f8285bcb5cfc \\\n    --hash=sha256:82fee1fc78add43492d3a1898bfa6d8a904cc97d8427f683ed8e798d07761aa0\n    # via requests\nimportlib-metadata==7.1.0 \\\n    --hash=sha256:30962b96c0c223483ed6cc7280e7f0199feb01a0e40cfae4d4450fc6fab1f570 \\\n    --hash=sha256:b78938b926ee8d5f020fc4772d487045805a55ddbad2ecf21c6d60938dc7fcd2\n    # via markdown\njax==0.4.7 \\\n    --hash=sha256:5e7002d74db25f97c99b979d4ba1233b1ef26e1597e5fc468ad11d1c8a9dc4f8\n    # via -r ci/official/requirements_updater/requirements.in\nkeras-nightly==3.0.4.dev2024021403 \\\n    --hash=sha256:24ce69d29d582771685bf4235f59663723405b5a5b16f3eaff2657e52e74663a \\\n    --hash=sha256:9f416e66b820ef833779d219d255b346b8b90a72fdbd0b2f1e90a43ad142a03d\n    # via -r ci/official/requirements_updater/requirements.in\nlibclang==18.1.1 \\\n    --hash=sha256:0b2e143f0fac830156feb56f9231ff8338c20aecfe72b4ffe96f19e5a1dbb69a \\\n    --hash=sha256:3f0e1f49f04d3cd198985fea0511576b0aee16f9ff0e0f0cad7f9c57ec3c20e8 \\\n    --hash=sha256:4dd2d3b82fab35e2bf9ca717d7b63ac990a3519c7e312f19fa8e86dcc712f7fb \\\n    --hash=sha256:54dda940a4a0491a9d1532bf071ea3ef26e6dbaf03b5000ed94dd7174e8f9592 \\\n    --hash=sha256:69f8eb8f65c279e765ffd28aaa7e9e364c776c17618af8bff22a8df58677ff4f \\\n    --hash=sha256:6f14c3f194704e5d09769108f03185fce7acaf1d1ae4bbb2f30a72c2400cb7c5 \\\n    --hash=sha256:83ce5045d101b669ac38e6da8e58765f12da2d3aafb3b9b98d88b286a60964d8 \\\n    --hash=sha256:a1214966d08d73d971287fc3ead8dfaf82eb07fb197680d8b3859dbbbbf78250 \\\n    --hash=sha256:c533091d8a3bbf7460a00cb6c1a71da93bffe148f172c7d03b1c31fbf8aa2a0b \\\n    --hash=sha256:cf4a99b05376513717ab5d82a0db832c56ccea4fd61a69dbb7bccf2dfb207dbe\n    # via -r ci/official/requirements_updater/requirements.in\nlit==17.0.6 \\\n    --hash=sha256:dfa9af9b55fc4509a56be7bf2346f079d7f4a242d583b9f2e0b078fd0abae31b\n    # via -r ci/official/requirements_updater/requirements.in\nmarkdown==3.6 \\\n    --hash=sha256:48f276f4d8cfb8ce6527c8f79e2ee29708508bf4d40aa410fbc3b4ee832c850f \\\n    --hash=sha256:ed4f41f6daecbeeb96e576ce414c41d2d876daa9a16cb35fa8ed8c2ddfad0224\n    # via tb-nightly\nmarkdown-it-py==3.0.0 \\\n    --hash=sha256:355216845c60bd96232cd8d8c40e8f9765cc86f46880e43a8fd22dc1a1a8cab1 \\\n    --hash=sha256:e3f60a94fa066dc52ec76661e37c851cb232d92f9886b15cb560aaada2df8feb\n    # via rich\nmarkupsafe==2.1.5 \\\n    --hash=sha256:00e046b6dd71aa03a41079792f8473dc494d564611a8f89bbbd7cb93295ebdcf \\\n    --hash=sha256:075202fa5b72c86ad32dc7d0b56024ebdbcf2048c0ba09f1cde31bfdd57bcfff \\\n    --hash=sha256:0e397ac966fdf721b2c528cf028494e86172b4feba51d65f81ffd65c63798f3f \\\n    --hash=sha256:17b950fccb810b3293638215058e432159d2b71005c74371d784862b7e4683f3 \\\n    --hash=sha256:1f3fbcb7ef1f16e48246f704ab79d79da8a46891e2da03f8783a5b6fa41a9532 \\\n    --hash=sha256:2174c595a0d73a3080ca3257b40096db99799265e1c27cc5a610743acd86d62f \\\n    --hash=sha256:2b7c57a4dfc4f16f7142221afe5ba4e093e09e728ca65c51f5620c9aaeb9a617 \\\n    --hash=sha256:2d2d793e36e230fd32babe143b04cec8a8b3eb8a3122d2aceb4a371e6b09b8df \\\n    --hash=sha256:30b600cf0a7ac9234b2638fbc0fb6158ba5bdcdf46aeb631ead21248b9affbc4 \\\n    --hash=sha256:397081c1a0bfb5124355710fe79478cdbeb39626492b15d399526ae53422b906 \\\n    --hash=sha256:3a57fdd7ce31c7ff06cdfbf31dafa96cc533c21e443d57f5b1ecc6cdc668ec7f \\\n    --hash=sha256:3c6b973f22eb18a789b1460b4b91bf04ae3f0c4234a0a6aa6b0a92f6f7b951d4 \\\n    --hash=sha256:3e53af139f8579a6d5f7b76549125f0d94d7e630761a2111bc431fd820e163b8 \\\n    --hash=sha256:4096e9de5c6fdf43fb4f04c26fb114f61ef0bf2e5604b6ee3019d51b69e8c371 \\\n    --hash=sha256:4275d846e41ecefa46e2015117a9f491e57a71ddd59bbead77e904dc02b1bed2 \\\n    --hash=sha256:4c31f53cdae6ecfa91a77820e8b151dba54ab528ba65dfd235c80b086d68a465 \\\n    --hash=sha256:4f11aa001c540f62c6166c7726f71f7573b52c68c31f014c25cc7901deea0b52 \\\n    --hash=sha256:5049256f536511ee3f7e1b3f87d1d1209d327e818e6ae1365e8653d7e3abb6a6 \\\n    --hash=sha256:58c98fee265677f63a4385256a6d7683ab1832f3ddd1e66fe948d5880c21a169 \\\n    --hash=sha256:598e3276b64aff0e7b3451b72e94fa3c238d452e7ddcd893c3ab324717456bad \\\n    --hash=sha256:5b7b716f97b52c5a14bffdf688f971b2d5ef4029127f1ad7a513973cfd818df2 \\\n    --hash=sha256:5dedb4db619ba5a2787a94d877bc8ffc0566f92a01c0ef214865e54ecc9ee5e0 \\\n    --hash=sha256:619bc166c4f2de5caa5a633b8b7326fbe98e0ccbfacabd87268a2b15ff73a029 \\\n    --hash=sha256:629ddd2ca402ae6dbedfceeba9c46d5f7b2a61d9749597d4307f943ef198fc1f \\\n    --hash=sha256:656f7526c69fac7f600bd1f400991cc282b417d17539a1b228617081106feb4a \\\n    --hash=sha256:6ec585f69cec0aa07d945b20805be741395e28ac1627333b1c5b0105962ffced \\\n    --hash=sha256:72b6be590cc35924b02c78ef34b467da4ba07e4e0f0454a2c5907f473fc50ce5 \\\n    --hash=sha256:7502934a33b54030eaf1194c21c692a534196063db72176b0c4028e140f8f32c \\\n    --hash=sha256:7a68b554d356a91cce1236aa7682dc01df0edba8d043fd1ce607c49dd3c1edcf \\\n    --hash=sha256:7b2e5a267c855eea6b4283940daa6e88a285f5f2a67f2220203786dfa59b37e9 \\\n    --hash=sha256:823b65d8706e32ad2df51ed89496147a42a2a6e01c13cfb6ffb8b1e92bc910bb \\\n    --hash=sha256:8590b4ae07a35970728874632fed7bd57b26b0102df2d2b233b6d9d82f6c62ad \\\n    --hash=sha256:8dd717634f5a044f860435c1d8c16a270ddf0ef8588d4887037c5028b859b0c3 \\\n    --hash=sha256:8dec4936e9c3100156f8a2dc89c4b88d5c435175ff03413b443469c7c8c5f4d1 \\\n    --hash=sha256:97cafb1f3cbcd3fd2b6fbfb99ae11cdb14deea0736fc2b0952ee177f2b813a46 \\\n    --hash=sha256:a17a92de5231666cfbe003f0e4b9b3a7ae3afb1ec2845aadc2bacc93ff85febc \\\n    --hash=sha256:a549b9c31bec33820e885335b451286e2969a2d9e24879f83fe904a5ce59d70a \\\n    --hash=sha256:ac07bad82163452a6884fe8fa0963fb98c2346ba78d779ec06bd7a6262132aee \\\n    --hash=sha256:ae2ad8ae6ebee9d2d94b17fb62763125f3f374c25618198f40cbb8b525411900 \\\n    --hash=sha256:b91c037585eba9095565a3556f611e3cbfaa42ca1e865f7b8015fe5c7336d5a5 \\\n    --hash=sha256:bc1667f8b83f48511b94671e0e441401371dfd0f0a795c7daa4a3cd1dde55bea \\\n    --hash=sha256:bec0a414d016ac1a18862a519e54b2fd0fc8bbfd6890376898a6c0891dd82e9f \\\n    --hash=sha256:bf50cd79a75d181c9181df03572cdce0fbb75cc353bc350712073108cba98de5 \\\n    --hash=sha256:bff1b4290a66b490a2f4719358c0cdcd9bafb6b8f061e45c7a2460866bf50c2e \\\n    --hash=sha256:c061bb86a71b42465156a3ee7bd58c8c2ceacdbeb95d05a99893e08b8467359a \\\n    --hash=sha256:c8b29db45f8fe46ad280a7294f5c3ec36dbac9491f2d1c17345be8e69cc5928f \\\n    --hash=sha256:ce409136744f6521e39fd8e2a24c53fa18ad67aa5bc7c2cf83645cce5b5c4e50 \\\n    --hash=sha256:d050b3361367a06d752db6ead6e7edeb0009be66bc3bae0ee9d97fb326badc2a \\\n    --hash=sha256:d283d37a890ba4c1ae73ffadf8046435c76e7bc2247bbb63c00bd1a709c6544b \\\n    --hash=sha256:d9fad5155d72433c921b782e58892377c44bd6252b5af2f67f16b194987338a4 \\\n    --hash=sha256:daa4ee5a243f0f20d528d939d06670a298dd39b1ad5f8a72a4275124a7819eff \\\n    --hash=sha256:db0b55e0f3cc0be60c1f19efdde9a637c32740486004f20d1cff53c3c0ece4d2 \\\n    --hash=sha256:e61659ba32cf2cf1481e575d0462554625196a1f2fc06a1c777d3f48e8865d46 \\\n    --hash=sha256:ea3d8a3d18833cf4304cd2fc9cbb1efe188ca9b5efef2bdac7adc20594a0e46b \\\n    --hash=sha256:ec6a563cff360b50eed26f13adc43e61bc0c04d94b8be985e6fb24b81f6dcfdf \\\n    --hash=sha256:f5dfb42c4604dddc8e4305050aa6deb084540643ed5804d7455b5df8fe16f5e5 \\\n    --hash=sha256:fa173ec60341d6bb97a89f5ea19c85c5643c1e7dedebc22f5181eb73573142c5 \\\n    --hash=sha256:fa9db3f79de01457b03d4f01b34cf91bc0048eb2c3846ff26f66687c2f6d16ab \\\n    --hash=sha256:fce659a462a1be54d2ffcacea5e3ba2d74daa74f30f5f143fe0c58636e355fdd \\\n    --hash=sha256:ffee1f21e5ef0d712f9033568f8344d5da8cc2869dbd08d87c84656e6a2d2f68\n    # via werkzeug\nmdurl==0.1.2 \\\n    --hash=sha256:84008a41e51615a49fc9966191ff91509e3c40b939176e643fd50a5c2196b8f8 \\\n    --hash=sha256:bb413d29f5eea38f31dd4754dd7377d4465116fb207585f97bf925588687c1ba\n    # via markdown-it-py\nml-dtypes==0.4.0 \\\n    --hash=sha256:03e7cda6ef164eed0abb31df69d2c00c3a5ab3e2610b6d4c42183a43329c72a5 \\\n    --hash=sha256:2bb83fd064db43e67e67d021e547698af4c8d5c6190f2e9b1c53c09f6ff5531d \\\n    --hash=sha256:3b67ec73a697c88c1122038e0de46520e48dc2ec876d42cf61bc5efe3c0b7675 \\\n    --hash=sha256:41affb38fdfe146e3db226cf2953021184d6f0c4ffab52136613e9601706e368 \\\n    --hash=sha256:43cf4356a0fe2eeac6d289018d0734e17a403bdf1fd911953c125dd0358edcc0 \\\n    --hash=sha256:723af6346447268a3cf0b7356e963d80ecb5732b5279b2aa3fa4b9fc8297c85e \\\n    --hash=sha256:75b4faf99d0711b81f393db36d210b4255fd419f6f790bc6c1b461f95ffb7a9e \\\n    --hash=sha256:93afe37f3a879d652ec9ef1fc47612388890660a2657fbb5747256c3b818fd81 \\\n    --hash=sha256:a15d96d090aebb55ee85173d1775ae325a001aab607a76c8ea0b964ccd6b5364 \\\n    --hash=sha256:ad6849a2db386b38e4d54fe13eb3293464561780531a918f8ef4c8169170dd49 \\\n    --hash=sha256:bdf689be7351cc3c95110c910c1b864002f113e682e44508910c849e144f3df1 \\\n    --hash=sha256:c83e4d443962d891d51669ff241d5aaad10a8d3d37a81c5532a45419885d591c \\\n    --hash=sha256:e1e2f4237b459a63c97c2c9f449baa637d7e4c20addff6a9bac486f22432f3b6 \\\n    --hash=sha256:eaa32979ebfde3a0d7c947cafbf79edc1ec77ac05ad0780ee86c1d8df70f2259 \\\n    --hash=sha256:eaf197e72f4f7176a19fe3cb8b61846b38c6757607e7bf9cd4b1d84cd3e74deb \\\n    --hash=sha256:ee9f91d4c4f9959a7e1051c141dc565f39e54435618152219769e24f5e9a4d06 \\\n    --hash=sha256:f1724ddcdf5edbaf615a62110af47407f1719b8d02e68ccee60683acb5f74da1\n    # via\n    #   -r ci/official/requirements_updater/requirements.in\n    #   jax\n    #   keras-nightly\nnamex==0.0.8 \\\n    --hash=sha256:32a50f6c565c0bb10aa76298c959507abdc0e850efe085dc38f3440fcb3aa90b \\\n    --hash=sha256:7ddb6c2bb0e753a311b7590f84f6da659dd0c05e65cb89d519d54c0a250c0487\n    # via keras-nightly\nnumpy==2.0.2 \\\n    --hash=sha256:0123ffdaa88fa4ab64835dcbde75dcdf89c453c922f18dced6e27c90d1d0ec5a \\\n    --hash=sha256:11a76c372d1d37437857280aa142086476136a8c0f373b2e648ab2c8f18fb195 \\\n    --hash=sha256:13e689d772146140a252c3a28501da66dfecd77490b498b168b501835041f951 \\\n    --hash=sha256:1e795a8be3ddbac43274f18588329c72939870a16cae810c2b73461c40718ab1 \\\n    --hash=sha256:26df23238872200f63518dd2aa984cfca675d82469535dc7162dc2ee52d9dd5c \\\n    --hash=sha256:286cd40ce2b7d652a6f22efdfc6d1edf879440e53e76a75955bc0c826c7e64dc \\\n    --hash=sha256:2b2955fa6f11907cf7a70dab0d0755159bca87755e831e47932367fc8f2f2d0b \\\n    --hash=sha256:2da5960c3cf0df7eafefd806d4e612c5e19358de82cb3c343631188991566ccd \\\n    --hash=sha256:312950fdd060354350ed123c0e25a71327d3711584beaef30cdaa93320c392d4 \\\n    --hash=sha256:423e89b23490805d2a5a96fe40ec507407b8ee786d66f7328be214f9679df6dd \\\n    --hash=sha256:496f71341824ed9f3d2fd36cf3ac57ae2e0165c143b55c3a035ee219413f3318 \\\n    --hash=sha256:49ca4decb342d66018b01932139c0961a8f9ddc7589611158cb3c27cbcf76448 \\\n    --hash=sha256:51129a29dbe56f9ca83438b706e2e69a39892b5eda6cedcb6b0c9fdc9b0d3ece \\\n    --hash=sha256:5fec9451a7789926bcf7c2b8d187292c9f93ea30284802a0ab3f5be8ab36865d \\\n    --hash=sha256:671bec6496f83202ed2d3c8fdc486a8fc86942f2e69ff0e986140339a63bcbe5 \\\n    --hash=sha256:7f0a0c6f12e07fa94133c8a67404322845220c06a9e80e85999afe727f7438b8 \\\n    --hash=sha256:807ec44583fd708a21d4a11d94aedf2f4f3c3719035c76a2bbe1fe8e217bdc57 \\\n    --hash=sha256:883c987dee1880e2a864ab0dc9892292582510604156762362d9326444636e78 \\\n    --hash=sha256:8c5713284ce4e282544c68d1c3b2c7161d38c256d2eefc93c1d683cf47683e66 \\\n    --hash=sha256:8cafab480740e22f8d833acefed5cc87ce276f4ece12fdaa2e8903db2f82897a \\\n    --hash=sha256:8df823f570d9adf0978347d1f926b2a867d5608f434a7cff7f7908c6570dcf5e \\\n    --hash=sha256:9059e10581ce4093f735ed23f3b9d283b9d517ff46009ddd485f1747eb22653c \\\n    --hash=sha256:905d16e0c60200656500c95b6b8dca5d109e23cb24abc701d41c02d74c6b3afa \\\n    --hash=sha256:9189427407d88ff25ecf8f12469d4d39d35bee1db5d39fc5c168c6f088a6956d \\\n    --hash=sha256:96a55f64139912d61de9137f11bf39a55ec8faec288c75a54f93dfd39f7eb40c \\\n    --hash=sha256:97032a27bd9d8988b9a97a8c4d2c9f2c15a81f61e2f21404d7e8ef00cb5be729 \\\n    --hash=sha256:984d96121c9f9616cd33fbd0618b7f08e0cfc9600a7ee1d6fd9b239186d19d97 \\\n    --hash=sha256:9a92ae5c14811e390f3767053ff54eaee3bf84576d99a2456391401323f4ec2c \\\n    --hash=sha256:9ea91dfb7c3d1c56a0e55657c0afb38cf1eeae4544c208dc465c3c9f3a7c09f9 \\\n    --hash=sha256:a15f476a45e6e5a3a79d8a14e62161d27ad897381fecfa4a09ed5322f2085669 \\\n    --hash=sha256:a392a68bd329eafac5817e5aefeb39038c48b671afd242710b451e76090e81f4 \\\n    --hash=sha256:a3f4ab0caa7f053f6797fcd4e1e25caee367db3112ef2b6ef82d749530768c73 \\\n    --hash=sha256:a46288ec55ebbd58947d31d72be2c63cbf839f0a63b49cb755022310792a3385 \\\n    --hash=sha256:a61ec659f68ae254e4d237816e33171497e978140353c0c2038d46e63282d0c8 \\\n    --hash=sha256:a842d573724391493a97a62ebbb8e731f8a5dcc5d285dfc99141ca15a3302d0c \\\n    --hash=sha256:becfae3ddd30736fe1889a37f1f580e245ba79a5855bff5f2a29cb3ccc22dd7b \\\n    --hash=sha256:c05e238064fc0610c840d1cf6a13bf63d7e391717d247f1bf0318172e759e692 \\\n    --hash=sha256:c1c9307701fec8f3f7a1e6711f9089c06e6284b3afbbcd259f7791282d660a15 \\\n    --hash=sha256:c7b0be4ef08607dd04da4092faee0b86607f111d5ae68036f16cc787e250a131 \\\n    --hash=sha256:cfd41e13fdc257aa5778496b8caa5e856dc4896d4ccf01841daee1d96465467a \\\n    --hash=sha256:d731a1c6116ba289c1e9ee714b08a8ff882944d4ad631fd411106a30f083c326 \\\n    --hash=sha256:df55d490dea7934f330006d0f81e8551ba6010a5bf035a249ef61a94f21c500b \\\n    --hash=sha256:ec9852fb39354b5a45a80bdab5ac02dd02b15f44b3804e9f00c556bf24b4bded \\\n    --hash=sha256:f15975dfec0cf2239224d80e32c3170b1d168335eaedee69da84fbe9f1f9cd04 \\\n    --hash=sha256:f26b258c385842546006213344c50655ff1555a9338e2e5e02a0756dc3e803dd\n    # via\n    #   -r ci/official/requirements_updater/requirements.in\n    #   h5py\n    #   jax\n    #   keras-nightly\n    #   ml-dtypes\n    #   opt-einsum\n    #   scipy\n    #   tb-nightly\nnvidia-cublas-cu12==12.5.3.2 \\\n    --hash=sha256:4960f3dc5f39699acadf76fa6d94b10a2a00f2956c2c442efa299fb22b0748f3 \\\n    --hash=sha256:7d0191251180de606023d396b94d66f66470a0ae96d1dbb906c7656ea0f71eda \\\n    --hash=sha256:ca070ad70e9fa6654084575d01bd001f30cc4665e33d4bb9fc8e0f321caa034b\n    # via\n    #   -r ci/official/requirements_updater/requirements.in\n    #   nvidia-cudnn-cu12\n    #   nvidia-cusolver-cu12\nnvidia-cuda-cupti-cu12==12.5.82 \\\n    --hash=sha256:4f835281cf492e2bedd153f5c3de9da8f1d775a419468305e64ce73b3b0c6dc3 \\\n    --hash=sha256:bde77a5feb66752ec61db2adfe47f56b941842825b4c7e2068aff27c9d107953 \\\n    --hash=sha256:d32c06490c6ba35c4323730820c7d0c4c126c04ed58d2f57275adb8d54b138fe\n    # via -r ci/official/requirements_updater/requirements.in\nnvidia-cuda-nvrtc-cu12==12.5.82 \\\n    --hash=sha256:3dbd97b0104b4bfbc3c4f8c79cd2496307c89c43c29a9f83125f1d76296ff3fd \\\n    --hash=sha256:5bb6a0eb01d4974bb7ca3d48bd3859472debb3c3057a5e7de2b08fbdf35eed7e \\\n    --hash=sha256:e5db37e990056c70953b7772dd778336ef9da0a0b5bb28f9f2a61c2e42b51d78\n    # via -r ci/official/requirements_updater/requirements.in\nnvidia-cuda-runtime-cu12==12.5.82 \\\n    --hash=sha256:0fd5fbca289bceb9f0690aa9858f06187b554fdeb7e2711dfd5bb3ce58900b46 \\\n    --hash=sha256:3e79a060e126df40fd3a068f3f787eb000fa51b251ec6cd97d09579632687115 \\\n    --hash=sha256:71f015dbf9df05dd71f7480132c6ebf47a6ceb2ab53d7db8e08e4b30ebb87e14\n    # via -r ci/official/requirements_updater/requirements.in\nnvidia-cudnn-cu12==9.3.0.75 \\\n    --hash=sha256:9ad9c6929ebb5295eb4a1728024666d1c88283373e265a0c5c883e6f9d5cd76d \\\n    --hash=sha256:c5cf7ff3415e446adf195a5b7dd2ba56cd00c3ee78bfdc566e51698931aa4b7f \\\n    --hash=sha256:c819e82eed8cf564b9d37478ea4eab9e87194bb3b7f7f8098bc1f67c9b80f1b6\n    # via -r ci/official/requirements_updater/requirements.in\nnvidia-cufft-cu12==11.2.3.61 \\\n    --hash=sha256:4a8f6f0ce93c52a50ee83422a80472b5f376054a63f38532d0eab4007e7ef28b \\\n    --hash=sha256:6d45b48a5ee7599e57131129cda2c58544d9b78b95064d3ec3e5c6b96e2b58cc \\\n    --hash=sha256:9a6e8df162585750f61983a638104a48c756aa13f9f48e19ab079b38e3c828b8\n    # via -r ci/official/requirements_updater/requirements.in\nnvidia-curand-cu12==10.3.6.82 \\\n    --hash=sha256:0631ba65231260ad832ce233ddda57e7b3b7158eabf000d78e46cbb5bd5b7aae \\\n    --hash=sha256:2823fb27de4e44dbb22394a6adf53aa6e1b013aca0f8c22867d1cfae58405536 \\\n    --hash=sha256:36aabeb5990297bbce3df324ea7c7c13c3aabb140c86d50ab3b23e4ec61672f1\n    # via -r ci/official/requirements_updater/requirements.in\nnvidia-cusolver-cu12==11.6.3.83 \\\n    --hash=sha256:1b8b77d2fe8abe72bb722dafb708cceaeb81f1a03999477f20b33b34f46ab885 \\\n    --hash=sha256:6224732963cba312a84c78114b9a38c4ffabb2e2a6a120923ac99ba6f895c8cf \\\n    --hash=sha256:93cfafacde4428b71778eeb092ec615a02a3d05404da1bcf91c53e3fa1bce42b\n    # via -r ci/official/requirements_updater/requirements.in\nnvidia-cusparse-cu12==12.5.1.3 \\\n    --hash=sha256:016df8e993c437e8301e62739f01775cba988fd5253cd4c64173f8e8d2f8e752 \\\n    --hash=sha256:33520db374e2f5ebc976d6faa1852b98c398a57e6f71150fe59705928596ffd1 \\\n    --hash=sha256:7b97fd01f0a61628af99d0efd52132fccc8c18fc5c509f13802dccf0574a19c2\n    # via\n    #   -r ci/official/requirements_updater/requirements.in\n    #   nvidia-cusolver-cu12\nnvidia-nccl-cu12==2.23.4 \\\n    --hash=sha256:aa946c8327e22ced28e7cef508a334673abc42064ec85f02d005ba1785ea4cec \\\n    --hash=sha256:b097258d9aab2fa9f686e33c6fe40ae57b27df60cedbd15d139701bb5509e0c1\n    # via -r ci/official/requirements_updater/requirements.in\nnvidia-nvjitlink-cu12==12.5.82 \\\n    --hash=sha256:98103729cc5226e13ca319a10bbf9433bbbd44ef64fe72f45f067cacc14b8d27 \\\n    --hash=sha256:e782564d705ff0bf61ac3e1bf730166da66dd2fe9012f111ede5fc49b64ae697 \\\n    --hash=sha256:f9b37bc5c8cf7509665cb6ada5aaa0ce65618f2332b7d3e78e9790511f111212\n    # via\n    #   -r ci/official/requirements_updater/requirements.in\n    #   nvidia-cufft-cu12\n    #   nvidia-cusolver-cu12\n    #   nvidia-cusparse-cu12\nopt-einsum==3.3.0 \\\n    --hash=sha256:2455e59e3947d3c275477df7f5205b30635e266fe6dc300e3d9f9646bfcea147 \\\n    --hash=sha256:59f6475f77bbc37dcf7cd748519c0ec60722e91e63ca114e68821c0c54a46549\n    # via\n    #   -r ci/official/requirements_updater/requirements.in\n    #   jax\npackaging==23.2 \\\n    --hash=sha256:048fb0e9405036518eaaf48a55953c750c11e1a1b68e0dd1a9d62ed0c092cfc5 \\\n    --hash=sha256:8c491190033a9af7e1d931d0b5dacc2ef47509b34dd0de67ed209b5203fc88c7\n    # via -r ci/official/requirements_updater/requirements.in\n    #   tb-nightly\nportpicker==1.6.0 \\\n    --hash=sha256:b2787a41404cf7edbe29b07b9e0ed863b09f2665dcc01c1eb0c2261c1e7d0755 \\\n    --hash=sha256:bd507fd6f96f65ee02781f2e674e9dc6c99bbfa6e3c39992e3916204c9d431fa\n    # via -r ci/official/requirements_updater/requirements.in\nprotobuf==4.25.3 \\\n    --hash=sha256:19b270aeaa0099f16d3ca02628546b8baefe2955bbe23224aaf856134eccf1e4 \\\n    --hash=sha256:209ba4cc916bab46f64e56b85b090607a676f66b473e6b762e6f1d9d591eb2e8 \\\n    --hash=sha256:25b5d0b42fd000320bd7830b349e3b696435f3b329810427a6bcce6a5492cc5c \\\n    --hash=sha256:7c8daa26095f82482307bc717364e7c13f4f1c99659be82890dcfc215194554d \\\n    --hash=sha256:c053062984e61144385022e53678fbded7aea14ebb3e0305ae3592fb219ccfa4 \\\n    --hash=sha256:d4198877797a83cbfe9bffa3803602bbe1625dc30d8a097365dbc762e5790faa \\\n    --hash=sha256:e3c97a1555fd6388f857770ff8b9703083de6bf1f9274a002a332d65fbb56c8c \\\n    --hash=sha256:e7cb0ae90dd83727f0c0718634ed56837bfeeee29a5f82a7514c03ee1364c019 \\\n    --hash=sha256:f0700d54bcf45424477e46a9f0944155b46fb0639d69728739c0e47bab83f2b9 \\\n    --hash=sha256:f1279ab38ecbfae7e456a108c5c0681e4956d5b1090027c1de0f934dfdb4b35c \\\n    --hash=sha256:f4f118245c4a087776e0a8408be33cf09f6c547442c00395fbfb116fac2f8ac2\n    # via tb-nightly\npsutil==5.9.8 \\\n    --hash=sha256:02615ed8c5ea222323408ceba16c60e99c3f91639b07da6373fb7e6539abc56d \\\n    --hash=sha256:05806de88103b25903dff19bb6692bd2e714ccf9e668d050d144012055cbca73 \\\n    --hash=sha256:26bd09967ae00920df88e0352a91cff1a78f8d69b3ecabbfe733610c0af486c8 \\\n    --hash=sha256:27cc40c3493bb10de1be4b3f07cae4c010ce715290a5be22b98493509c6299e2 \\\n    --hash=sha256:36f435891adb138ed3c9e58c6af3e2e6ca9ac2f365efe1f9cfef2794e6c93b4e \\\n    --hash=sha256:50187900d73c1381ba1454cf40308c2bf6f34268518b3f36a9b663ca87e65e36 \\\n    --hash=sha256:611052c4bc70432ec770d5d54f64206aa7203a101ec273a0cd82418c86503bb7 \\\n    --hash=sha256:6be126e3225486dff286a8fb9a06246a5253f4c7c53b475ea5f5ac934e64194c \\\n    --hash=sha256:7d79560ad97af658a0f6adfef8b834b53f64746d45b403f225b85c5c2c140eee \\\n    --hash=sha256:8cb6403ce6d8e047495a701dc7c5bd788add903f8986d523e3e20b98b733e421 \\\n    --hash=sha256:8db4c1b57507eef143a15a6884ca10f7c73876cdf5d51e713151c1236a0e68cf \\\n    --hash=sha256:aee678c8720623dc456fa20659af736241f575d79429a0e5e9cf88ae0605cc81 \\\n    --hash=sha256:bc56c2a1b0d15aa3eaa5a60c9f3f8e3e565303b465dbf57a1b730e7a2b9844e0 \\\n    --hash=sha256:bd1184ceb3f87651a67b2708d4c3338e9b10c5df903f2e3776b62303b26cb631 \\\n    --hash=sha256:d06016f7f8625a1825ba3732081d77c94589dca78b7a3fc072194851e88461a4 \\\n    --hash=sha256:d16bbddf0693323b8c6123dd804100241da461e41d6e332fb0ba6058f630f8c8\n    # via portpicker\npyelftools==0.31 \\\n    --hash=sha256:c774416b10310156879443b81187d182d8d9ee499660380e645918b50bc88f99 \\\n    --hash=sha256:f52de7b3c7e8c64c8abc04a79a1cf37ac5fb0b8a49809827130b858944840607\n    # via auditwheel\npygments==2.18.0 \\\n    --hash=sha256:786ff802f32e91311bff3889f6e9a86e81505fe99f2735bb6d60ae0c5004f199 \\\n    --hash=sha256:b8e6aca0523f3ab76fee51799c488e38782ac06eafcf95e7ba832985c8e7b13a\n    # via rich\nrequests==2.32.3 \\\n    --hash=sha256:55365417734eb18255590a9ff9eb97e9e1da868d4ccd6402399eaf68af20a760 \\\n    --hash=sha256:70761cfe03c773ceb22aa2f671b4757976145175cdfca038c02654d061d6dcc6\n    # via -r ci/official/requirements_updater/requirements.in\nrich==13.7.1 \\\n    --hash=sha256:4edbae314f59eb482f54e9e30bf00d33350aaa94f4bfcd4e9e3110e64d0d7222 \\\n    --hash=sha256:9be308cb1fe2f1f57d67ce99e95af38a1e2bc71ad9813b0e247cf7ffbcc3a432\n    # via keras-nightly\nscipy==1.13.1 \\\n    --hash=sha256:017367484ce5498445aade74b1d5ab377acdc65e27095155e448c88497755a5d \\\n    --hash=sha256:095a87a0312b08dfd6a6155cbbd310a8c51800fc931b8c0b84003014b874ed3c \\\n    --hash=sha256:20335853b85e9a49ff7572ab453794298bcf0354d8068c5f6775a0eabf350aca \\\n    --hash=sha256:27e52b09c0d3a1d5b63e1105f24177e544a222b43611aaf5bc44d4a0979e32f9 \\\n    --hash=sha256:2831f0dc9c5ea9edd6e51e6e769b655f08ec6db6e2e10f86ef39bd32eb11da54 \\\n    --hash=sha256:2ac65fb503dad64218c228e2dc2d0a0193f7904747db43014645ae139c8fad16 \\\n    --hash=sha256:392e4ec766654852c25ebad4f64e4e584cf19820b980bc04960bca0b0cd6eaa2 \\\n    --hash=sha256:436bbb42a94a8aeef855d755ce5a465479c721e9d684de76bf61a62e7c2b81d5 \\\n    --hash=sha256:45484bee6d65633752c490404513b9ef02475b4284c4cfab0ef946def50b3f59 \\\n    --hash=sha256:54f430b00f0133e2224c3ba42b805bfd0086fe488835effa33fa291561932326 \\\n    --hash=sha256:5713f62f781eebd8d597eb3f88b8bf9274e79eeabf63afb4a737abc6c84ad37b \\\n    --hash=sha256:5d72782f39716b2b3509cd7c33cdc08c96f2f4d2b06d51e52fb45a19ca0c86a1 \\\n    --hash=sha256:637e98dcf185ba7f8e663e122ebf908c4702420477ae52a04f9908707456ba4d \\\n    --hash=sha256:8335549ebbca860c52bf3d02f80784e91a004b71b059e3eea9678ba994796a24 \\\n    --hash=sha256:949ae67db5fa78a86e8fa644b9a6b07252f449dcf74247108c50e1d20d2b4627 \\\n    --hash=sha256:a014c2b3697bde71724244f63de2476925596c24285c7a637364761f8710891c \\\n    --hash=sha256:a78b4b3345f1b6f68a763c6e25c0c9a23a9fd0f39f5f3d200efe8feda560a5fa \\\n    --hash=sha256:cdd7dacfb95fea358916410ec61bbc20440f7860333aee6d882bb8046264e949 \\\n    --hash=sha256:cfa31f1def5c819b19ecc3a8b52d28ffdcc7ed52bb20c9a7589669dd3c250989 \\\n    --hash=sha256:d533654b7d221a6a97304ab63c41c96473ff04459e404b83275b60aa8f4b7004 \\\n    --hash=sha256:d605e9c23906d1994f55ace80e0125c587f96c020037ea6aa98d01b4bd2e222f \\\n    --hash=sha256:de3ade0e53bc1f21358aa74ff4830235d716211d7d077e340c7349bc3542e884 \\\n    --hash=sha256:e89369d27f9e7b0884ae559a3a956e77c02114cc60a6058b4e5011572eea9299 \\\n    --hash=sha256:eccfa1906eacc02de42d70ef4aecea45415f5be17e72b61bafcfd329bdc52e94 \\\n    --hash=sha256:f26264b282b9da0952a024ae34710c2aff7d27480ee91a2e82b7b7073c24722f\n    # via\n    #   -r ci/official/requirements_updater/requirements.in\n    #   jax\nsix==1.16.0 \\\n    --hash=sha256:1e61c37477a1626458e36f7b1d82aa5c9b094fa4802892072e49de9c60c4c926 \\\n    --hash=sha256:8abb2f1d86890a2dfb989f9a77cfcfd3e47c2a354b01111771326f8aa26e0254\n    # via\n    #   astunparse\n    #   google-pasta\n    #   tb-nightly\ntb-nightly==2.19.0a20240926 \\\n    --hash=sha256:4f2f4dd02eda684fbb2edd9cb46b7bd0ee7ba6ca35d38e4de2e293df8567c1b4\n    # via -r ci/official/requirements_updater/requirements.in\ntblib==2.0.0 \\\n    --hash=sha256:9100bfa016b047d5b980d66e7efed952fbd20bd85b56110aaf473cb97d18709a \\\n    --hash=sha256:a6df30f272c08bf8be66e0775fad862005d950a6b8449b94f7c788731d70ecd7\n    # via -r ci/official/requirements_updater/requirements.in\ntensorboard-data-server==0.7.2 \\\n    --hash=sha256:7e0610d205889588983836ec05dc098e80f97b7e7bbff7e994ebb78f578d0ddb \\\n    --hash=sha256:9fe5d24221b29625dbc7328b0436ca7fc1c23de4acf4d272f1180856e32f9f60 \\\n    --hash=sha256:ef687163c24185ae9754ed5650eb5bc4d84ff257aabdc33f0cc6f74d8ba54530\n    # via tb-nightly\ntensorflow-io-gcs-filesystem==0.37.1 \\\n    --hash=sha256:0df00891669390078a003cedbdd3b8e645c718b111917535fa1d7725e95cdb95 \\\n    --hash=sha256:249c12b830165841411ba71e08215d0e94277a49c551e6dd5d72aab54fe5491b \\\n    --hash=sha256:257aab23470a0796978efc9c2bcf8b0bc80f22e6298612a4c0a50d3f4e88060c \\\n    --hash=sha256:286389a203a5aee1a4fa2e53718c661091aa5fea797ff4fa6715ab8436b02e6c \\\n    --hash=sha256:32c50ab4e29a23c1f91cd0f9ab8c381a0ab10f45ef5c5252e94965916041737c \\\n    --hash=sha256:426de1173cb81fbd62becec2012fc00322a295326d90eb6c737fab636f182aed \\\n    --hash=sha256:6e1f2796b57e799a8ca1b75bf47c2aaa437c968408cc1a402a9862929e104cda \\\n    --hash=sha256:8943036bbf84e7a2be3705cb56f9c9df7c48c9e614bb941f0936c58e3ca89d6f \\\n    --hash=sha256:8febbfcc67c61e542a5ac1a98c7c20a91a5e1afc2e14b1ef0cb7c28bc3b6aa70 \\\n    --hash=sha256:9679b36e3a80921876f31685ab6f7270f3411a4cc51bc2847e80d0e4b5291e27 \\\n    --hash=sha256:b02f9c5f94fd62773954a04f69b68c4d576d076fd0db4ca25d5479f0fbfcdbad \\\n    --hash=sha256:ee5da49019670ed364f3e5fb86b46420841a6c3cb52a300553c63841671b3e6d \\\n    --hash=sha256:ee7c8ee5fe2fd8cb6392669ef16e71841133041fee8a330eff519ad9b36e4556 \\\n    --hash=sha256:fbb33f1745f218464a59cecd9a18e32ca927b0f4d77abd8f8671b645cc1a182f \\\n    --hash=sha256:fe8dcc6d222258a080ac3dfcaaaa347325ce36a7a046277f6b3e19abc1efb3c5 \\\n    --hash=sha256:ffebb6666a7bfc28005f4fbbb111a455b5e7d6cd3b12752b7050863ecb27d5cc\n    # via -r ci/official/requirements_updater/requirements.in\ntermcolor==2.3.0 \\\n    --hash=sha256:3afb05607b89aed0ffe25202399ee0867ad4d3cb4180d98aaf8eefa6a5f7d475 \\\n    --hash=sha256:b5b08f68937f138fe92f6c089b99f1e2da0ae56c52b78bf7075fd95420fd9a5a\n    # via -r ci/official/requirements_updater/requirements.in\ntyping-extensions==4.8.0 \\\n    --hash=sha256:8f92fc8806f9a6b641eaa5318da32b44d401efaac0f6678c9bc448ba3605faa0 \\\n    --hash=sha256:df8e4339e9cb77357558cbdbceca33c303714cf861d1eef15e1070055ae8b7ef\n    # via -r ci/official/requirements_updater/requirements.in\nurllib3==2.2.2 \\\n    --hash=sha256:a448b2f64d686155468037e1ace9f2d2199776e17f0a46610480d311f73e3472 \\\n    --hash=sha256:dd505485549a7a552833da5e6063639d0d177c04f23bc3864e41e5dc5f612168\n    # via requests\nwerkzeug==3.0.6 \\\n    --hash=sha256:1bc0c2310d2fbb07b1dd1105eba2f7af72f322e1e455f2f93c993bee8c8a5f17 \\\n    --hash=sha256:a8dd59d4de28ca70471a34cba79bed5f7ef2e036a76b3ab0835474246eb41f8d\n    # via tb-nightly\nwheel==0.41.3 \\\n    --hash=sha256:488609bc63a29322326e05560731bf7bfea8e48ad646e1f5e40d366607de0942 \\\n    --hash=sha256:4d4987ce51a49370ea65c0bfd2234e8ce80a12780820d9dc462597a6e60d0841\n    # via\n    #   -r ci/official/requirements_updater/requirements.in\n    #   astunparse\nwrapt==1.16.0 \\\n    --hash=sha256:0d2691979e93d06a95a26257adb7bfd0c93818e89b1406f5a28f36e0d8c1e1fc \\\n    --hash=sha256:14d7dc606219cdd7405133c713f2c218d4252f2a469003f8c46bb92d5d095d81 \\\n    --hash=sha256:1a5db485fe2de4403f13fafdc231b0dbae5eca4359232d2efc79025527375b09 \\\n    --hash=sha256:1acd723ee2a8826f3d53910255643e33673e1d11db84ce5880675954183ec47e \\\n    --hash=sha256:1ca9b6085e4f866bd584fb135a041bfc32cab916e69f714a7d1d397f8c4891ca \\\n    --hash=sha256:1dd50a2696ff89f57bd8847647a1c363b687d3d796dc30d4dd4a9d1689a706f0 \\\n    --hash=sha256:2076fad65c6736184e77d7d4729b63a6d1ae0b70da4868adeec40989858eb3fb \\\n    --hash=sha256:2a88e6010048489cda82b1326889ec075a8c856c2e6a256072b28eaee3ccf487 \\\n    --hash=sha256:3ebf019be5c09d400cf7b024aa52b1f3aeebeff51550d007e92c3c1c4afc2a40 \\\n    --hash=sha256:418abb18146475c310d7a6dc71143d6f7adec5b004ac9ce08dc7a34e2babdc5c \\\n    --hash=sha256:43aa59eadec7890d9958748db829df269f0368521ba6dc68cc172d5d03ed8060 \\\n    --hash=sha256:44a2754372e32ab315734c6c73b24351d06e77ffff6ae27d2ecf14cf3d229202 \\\n    --hash=sha256:490b0ee15c1a55be9c1bd8609b8cecd60e325f0575fc98f50058eae366e01f41 \\\n    --hash=sha256:49aac49dc4782cb04f58986e81ea0b4768e4ff197b57324dcbd7699c5dfb40b9 \\\n    --hash=sha256:5eb404d89131ec9b4f748fa5cfb5346802e5ee8836f57d516576e61f304f3b7b \\\n    --hash=sha256:5f15814a33e42b04e3de432e573aa557f9f0f56458745c2074952f564c50e664 \\\n    --hash=sha256:5f370f952971e7d17c7d1ead40e49f32345a7f7a5373571ef44d800d06b1899d \\\n    --hash=sha256:66027d667efe95cc4fa945af59f92c5a02c6f5bb6012bff9e60542c74c75c362 \\\n    --hash=sha256:66dfbaa7cfa3eb707bbfcd46dab2bc6207b005cbc9caa2199bcbc81d95071a00 \\\n    --hash=sha256:685f568fa5e627e93f3b52fda002c7ed2fa1800b50ce51f6ed1d572d8ab3e7fc \\\n    --hash=sha256:6906c4100a8fcbf2fa735f6059214bb13b97f75b1a61777fcf6432121ef12ef1 \\\n    --hash=sha256:6a42cd0cfa8ffc1915aef79cb4284f6383d8a3e9dcca70c445dcfdd639d51267 \\\n    --hash=sha256:6dcfcffe73710be01d90cae08c3e548d90932d37b39ef83969ae135d36ef3956 \\\n    --hash=sha256:6f6eac2360f2d543cc875a0e5efd413b6cbd483cb3ad7ebf888884a6e0d2e966 \\\n    --hash=sha256:72554a23c78a8e7aa02abbd699d129eead8b147a23c56e08d08dfc29cfdddca1 \\\n    --hash=sha256:73870c364c11f03ed072dda68ff7aea6d2a3a5c3fe250d917a429c7432e15228 \\\n    --hash=sha256:73aa7d98215d39b8455f103de64391cb79dfcad601701a3aa0dddacf74911d72 \\\n    --hash=sha256:75ea7d0ee2a15733684badb16de6794894ed9c55aa5e9903260922f0482e687d \\\n    --hash=sha256:7bd2d7ff69a2cac767fbf7a2b206add2e9a210e57947dd7ce03e25d03d2de292 \\\n    --hash=sha256:807cc8543a477ab7422f1120a217054f958a66ef7314f76dd9e77d3f02cdccd0 \\\n    --hash=sha256:8e9723528b9f787dc59168369e42ae1c3b0d3fadb2f1a71de14531d321ee05b0 \\\n    --hash=sha256:9090c9e676d5236a6948330e83cb89969f433b1943a558968f659ead07cb3b36 \\\n    --hash=sha256:9153ed35fc5e4fa3b2fe97bddaa7cbec0ed22412b85bcdaf54aeba92ea37428c \\\n    --hash=sha256:9159485323798c8dc530a224bd3ffcf76659319ccc7bbd52e01e73bd0241a0c5 \\\n    --hash=sha256:941988b89b4fd6b41c3f0bfb20e92bd23746579736b7343283297c4c8cbae68f \\\n    --hash=sha256:94265b00870aa407bd0cbcfd536f17ecde43b94fb8d228560a1e9d3041462d73 \\\n    --hash=sha256:98b5e1f498a8ca1858a1cdbffb023bfd954da4e3fa2c0cb5853d40014557248b \\\n    --hash=sha256:9b201ae332c3637a42f02d1045e1d0cccfdc41f1f2f801dafbaa7e9b4797bfc2 \\\n    --hash=sha256:a0ea261ce52b5952bf669684a251a66df239ec6d441ccb59ec7afa882265d593 \\\n    --hash=sha256:a33a747400b94b6d6b8a165e4480264a64a78c8a4c734b62136062e9a248dd39 \\\n    --hash=sha256:a452f9ca3e3267cd4d0fcf2edd0d035b1934ac2bd7e0e57ac91ad6b95c0c6389 \\\n    --hash=sha256:a86373cf37cd7764f2201b76496aba58a52e76dedfaa698ef9e9688bfd9e41cf \\\n    --hash=sha256:ac83a914ebaf589b69f7d0a1277602ff494e21f4c2f743313414378f8f50a4cf \\\n    --hash=sha256:aefbc4cb0a54f91af643660a0a150ce2c090d3652cf4052a5397fb2de549cd89 \\\n    --hash=sha256:b3646eefa23daeba62643a58aac816945cadc0afaf21800a1421eeba5f6cfb9c \\\n    --hash=sha256:b47cfad9e9bbbed2339081f4e346c93ecd7ab504299403320bf85f7f85c7d46c \\\n    --hash=sha256:b935ae30c6e7400022b50f8d359c03ed233d45b725cfdd299462f41ee5ffba6f \\\n    --hash=sha256:bb2dee3874a500de01c93d5c71415fcaef1d858370d405824783e7a8ef5db440 \\\n    --hash=sha256:bc57efac2da352a51cc4658878a68d2b1b67dbe9d33c36cb826ca449d80a8465 \\\n    --hash=sha256:bf5703fdeb350e36885f2875d853ce13172ae281c56e509f4e6eca049bdfb136 \\\n    --hash=sha256:c31f72b1b6624c9d863fc095da460802f43a7c6868c5dda140f51da24fd47d7b \\\n    --hash=sha256:c5cd603b575ebceca7da5a3a251e69561bec509e0b46e4993e1cac402b7247b8 \\\n    --hash=sha256:d2efee35b4b0a347e0d99d28e884dfd82797852d62fcd7ebdeee26f3ceb72cf3 \\\n    --hash=sha256:d462f28826f4657968ae51d2181a074dfe03c200d6131690b7d65d55b0f360f8 \\\n    --hash=sha256:d5e49454f19ef621089e204f862388d29e6e8d8b162efce05208913dde5b9ad6 \\\n    --hash=sha256:da4813f751142436b075ed7aa012a8778aa43a99f7b36afe9b742d3ed8bdc95e \\\n    --hash=sha256:db2e408d983b0e61e238cf579c09ef7020560441906ca990fe8412153e3b291f \\\n    --hash=sha256:db98ad84a55eb09b3c32a96c576476777e87c520a34e2519d3e59c44710c002c \\\n    --hash=sha256:dbed418ba5c3dce92619656802cc5355cb679e58d0d89b50f116e4a9d5a9603e \\\n    --hash=sha256:dcdba5c86e368442528f7060039eda390cc4091bfd1dca41e8046af7c910dda8 \\\n    --hash=sha256:decbfa2f618fa8ed81c95ee18a387ff973143c656ef800c9f24fb7e9c16054e2 \\\n    --hash=sha256:e4fdb9275308292e880dcbeb12546df7f3e0f96c6b41197e0cf37d2826359020 \\\n    --hash=sha256:eb1b046be06b0fce7249f1d025cd359b4b80fc1c3e24ad9eca33e0dcdb2e4a35 \\\n    --hash=sha256:eb6e651000a19c96f452c85132811d25e9264d836951022d6e81df2fff38337d \\\n    --hash=sha256:ed867c42c268f876097248e05b6117a65bcd1e63b779e916fe2e33cd6fd0d3c3 \\\n    --hash=sha256:edfad1d29c73f9b863ebe7082ae9321374ccb10879eeabc84ba3b69f2579d537 \\\n    --hash=sha256:f2058f813d4f2b5e3a9eb2eb3faf8f1d99b81c3e51aeda4b168406443e8ba809 \\\n    --hash=sha256:f6b2d0c6703c988d334f297aa5df18c45e97b0af3679bb75059e0e0bd8b1069d \\\n    --hash=sha256:f8212564d49c50eb4565e502814f694e240c55551a5f1bc841d4fcaabb0a9b8a \\\n    --hash=sha256:ffa565331890b90056c01db69c0fe634a776f8019c143a5ae265f9c6bc4bd6d4\n    # via -r ci/official/requirements_updater/requirements.in\nzipp==3.19.2 \\\n    --hash=sha256:bf1dcf6450f873a13e952a29504887c89e6de7506209e5b1bcc3460135d4de19 \\\n    --hash=sha256:f091755f667055f2d02b32c53771a7a6c8b47e1fdbc4b72a8b9072b3eef8015c\n    # via importlib-metadata\n\n# The following packages are considered to be unsafe in a requirements file:\nsetuptools==70.0.0 \\\n    --hash=sha256:54faa7f2e8d2d11bcd2c07bed282eef1046b5c080d1c32add737d7b5817b1ad4 \\\n    --hash=sha256:f211a66637b8fa059bb28183da127d4e86396c991a942b028c6650d4319c3fd0\n    # via\n    #   -r ci/official/requirements_updater/requirements.in\n    #   tb-nightly\n"
        },
        {
          "name": "tensorflow",
          "type": "tree",
          "content": null
        },
        {
          "name": "third_party",
          "type": "tree",
          "content": null
        },
        {
          "name": "tools",
          "type": "tree",
          "content": null
        }
      ]
    }
  ]
}