{
  "metadata": {
    "timestamp": 1736566372169,
    "page": 133,
    "hasNextPage": true,
    "endCursor": "Y3Vyc29yOjE0MA==",
    "completionStatus": "IN_PROGRESS"
  },
  "repositories": [
    {
      "nameWithOwner": "ArduPilot/ardupilot",
      "stars": 11368,
      "defaultBranch": "master",
      "files": [
        {
          "name": ".dir-locals.el",
          "type": "blob",
          "size": 0.1337890625,
          "content": "((prog-mode . ((indent-tabs-mode . nil)\n               (tab-width . 4)\n               (c-basic-offset . 4)))\n (c-mode . ((mode . C++))))\n"
        },
        {
          "name": ".dockerignore",
          "type": "blob",
          "size": 0.41796875,
          "content": "# Docker context ignore list\n.azure\n.github\n.git\n.idea\n.vagrant\nAntennaTracker\nRover\nArduCopter\nArduPlane\nArduSub\nbenchmarks\nbuild\ndocs\nlibraries\nmk\nmodules\ntests\nTools\n# autotest directories\ntest.*\nterrain\nlogs\n# mavproxy stuff\nmav.*\n\n# include the setup script and completion\n!Tools/environment_install/install-prereqs-ubuntu.sh\n!Tools/environment_install/install-prereqs-arch.sh\n!Tools/completion\nautotest_result_*_junit.xml\n"
        },
        {
          "name": ".editorconfig",
          "type": "blob",
          "size": 0.6640625,
          "content": "# This file provide reference settings for the APM code conventions\n# There are plug-ins available for nearly every text editor to automatically\n# respect the conventions contained within this file.\n#\n# Please see editorconfig.org for complete information.\n#\n# If you find errors in this file, please send a pull-request with a fix.\n#\nroot = true\n\n[*]\nindent_style = space\nindent_size = 4\nend_of_line = lf\ncharset = utf-8\n# These are the correct rules for APM coding standards, but fixing up old files causes git spam\ntrim_trailing_whitespace = false\ninsert_final_newline = true\n\n[*.mk]\nindent_style = tab\nindent_size = 8\n\n[{makefile,Makefile}]\nindent_style = tab\nindent_size = 8\n"
        },
        {
          "name": ".flake8",
          "type": "blob",
          "size": 0.4765625,
          "content": "[flake8]\nextend-ignore =\n    # H301: one import per line\n    H301,\n    # H306: imports not in alphabetical order (time, os)\n    H306,\n    # E226: missing whitespace around arithmetic operator\n    E226,\n    # E261 at least two spaces before inline comment\n    E261,\n    # W504 line break after binary operator\n    W504,\n    # E203 whitespace before ':'\n    E203,\n    # E221 multiple spaces before operator\n    E221\n\nextend-exclude =\n    build,\n    modules,\n    .git\n\nmax-line-length = 127\n"
        },
        {
          "name": ".git-blame-ignore-revs",
          "type": "blob",
          "size": 0.3564453125,
          "content": "# This file allows ignoring commits in git blame view on Github.\n# For more info, see here:\n# https://docs.github.com/en/repositories/working-with-files/using-files/viewing-a-file#ignore-commits-in-the-blame-view\n\n# Tools: ros2: Run ament_black on all files\n85172b56467668bee9fa0e68081027b13bc18c4a\n\n# Tools: ros2: Reformat\n4d9822131354dc7dc3351f24660969f58720a1de\n"
        },
        {
          "name": ".gitattributes",
          "type": "blob",
          "size": 0.2431640625,
          "content": "\n# bash gets confused if you pass in .sh files from windows\n# This breaks Vagrant for some users.\n*.sh text eol=lf\n\n*.bin -diff\n*.elf -diff\n*.hex -diff\n\n*.bin binary linguist-generated\n*.elf binary linguist-generated\n*.hex binary linguist-generated\n"
        },
        {
          "name": ".github",
          "type": "tree",
          "content": null
        },
        {
          "name": ".gitignore",
          "type": "blob",
          "size": 2.80078125,
          "content": "/.lock-waf*\n/.waf*\n/Tools/autotest/aircraft/Rascal/reset.xml\n/Tools/autotest/ch7_mission.txt\n/Tools/autotest/param_metadata/Parameters.html\n/Tools/autotest/param_metadata/Parameters.rst\n/Tools/autotest/param_metadata/ParametersLatex.rst\n/Tools/autotest/param_metadata/Parameters.wiki\n/Tools/autotest/param_metadata/Parameters.md\n/Tools/autotest/param_metadata/apm.pdef.xml\n/Tools/autotest/param_metadata/apm.pdef.json\n/Tools/autotest/jsb_sim/fgout.xml\n/Tools/autotest/jsb_sim/rascal_test.xml\n/Tools/autotest/jsbsim_fgout_0.xml\n/Tools/autotest/jsbsim_start_0.xml\n/Tools/autotest/rover-ch7_mission.txt\n/tmp/*\n# Exclude all bins but allow font bins and bootloaders\n*.bin\n!*_bl.bin\n!font*.bin\n*.d\n*.dfu\n*.dll\n*.elf\n*.exe\n*.generated.h\n*.hex\n*.lst\n*.o\n*.obj\n*.px4\n*.pyc\n*.tlog\n*.tlog.raw\n*.vbrain\n*.vrx\n*.zip\n!Tools/autotest/tilecache/**/*.zip\n*~\n.*.swo\n.*.swp\n*.i\n*.ii\n.DS_Store\n.autotools\n.built\n.context\n.cproject\n.pydevproject\n.depend\n.directory\n.metadata/\n.project\n.settings/\n.tags\n.tags_sorted_by_file\n.vagrant\nTools/vagrant/*.log\nRover/test.Rover/\nRover/way.txt\nArduCopter/Debug/\nArduCopter/arducopter.exe.stackdump\nArduCopter/fence.txt\nArduCopter/ral.txt\nArduCopter/test.ArduCopter/\nArduCopter/test/*\nArduCopter/way.txt\nArduPlane/test.ArduPlane/\nArduPlane/test/*\nArduPlane/way.txt\nBuild.Rover/*\nBuild.AntennaTracker/*\nBuild.ArduCopter/*\nBuild.ArduPlane/*\nBuild.ArduSub/*\nCMakeCache.txt\nCMakeFiles\nLASTLOG.TXT\nMake.dep\nThumbs.db\nautotest.lck\nbuild\ncmake_install.cmake\ncscope.in.out\ncscope.out\ncscope.po.out\ndataflash.bin\neeprom.bin\nindex.html\nlogs/\nmav.log\nmav.log.raw\nmav.parm\nmission.stg\n/defaults.parm\n/ArduCopter/defaults.parm\n/ArduPlane/defaults.parm\n/AntennaTracker/defaults.parm\n/ArduSub/defaults.parm\n/Blimp/defaults.parm\n/Rover/defaults.parm\nmk/PX4/ROMFS/default.parm\nmodule.mk\nserialsent.raw\nstatus.txt\ntags\nterrain/\ntest.ArduCopter/*\nGPATH\nGRTAGS\nGTAGS\n*.apj\n.gdbinit\n.vscode/*\n!.vscode/extensions.json\n/.history\nParameters.html\nParameters.md\nParameters.rst\nParameters.wiki\nParameterMetaDataBackup.xml\nParameterMetaData.xml\napm.pdef.xml\napm.pdef.json\nparameters.edn\nLogMessages.html\nLogMessages.rst\nLogMessages.xml\nLogMessages.md\n# JetBrains IDE files\n.idea/*\n# CMake\ncmake-build-*/\n/reports/\n/GCOV_*.log\nway.txt\n*.wbproj\n*.wbproj\nsegv_*out\n/scripts/\n/repl/\n/Rover/scripts/\n/Rover/repl/\n/AntennaTracker/scripts/\n/AntennaTracker/repl/\n/ArduCopter/scripts/\n/ArduCopter/repl/\n/ArduPlane/scripts/\n/ArduPlane/repl/\n/ArduSub/scripts/\n/ArduSub/repl/\npersistent.dat\ndumpstack_*out\nbuild.tmp.binaries/\ntasklist.json\nmodules/esp_idf\n\n# lua-language-server linter\nScriptingDocs.md\n/lua-language-server/\nrepo-LuaLS-lua-language-server.cache\n\n# Ignore Python virtual environments\n#   from: https://github.com/github/gitignore/blob/4488915eec0b3a45b5c63ead28f286819c0917de/Python.gitignore#L125\n.env\n.venv\nenv/\nvenv/\nENV/\nenv.bak/\nvenv.bak/\nautotest_result_*_junit.xml\n"
        },
        {
          "name": ".gitmodules",
          "type": "blob",
          "size": 1.5185546875,
          "content": "[submodule \"modules/waf\"]\n\tpath = modules/waf\n\turl = https://github.com/ArduPilot/waf.git\n[submodule \"modules/gbenchmark\"]\n\tpath = modules/gbenchmark\n\turl = https://github.com/google/benchmark.git\n[submodule \"modules/mavlink\"]\n\tpath = modules/mavlink\n\turl = https://github.com/ArduPilot/mavlink\n[submodule \"gtest\"]\n\tpath = modules/gtest\n\turl = https://github.com/ArduPilot/googletest\n[submodule \"modules/ChibiOS\"]\n\tpath = modules/ChibiOS\n\turl = https://github.com/ArduPilot/ChibiOS.git\n[submodule \"modules/gsoap\"]\n\tpath = modules/gsoap\n\turl = https://github.com/ArduPilot/gsoap\n[submodule \"modules/DroneCAN/DSDL\"]\n\tpath = modules/DroneCAN/DSDL\n\turl = https://github.com/DroneCAN/DSDL.git\n[submodule \"modules/CrashDebug\"]\n\tpath = modules/CrashDebug\n\turl = https://github.com/ardupilot/CrashDebug\n[submodule \"modules/DroneCAN/pydronecan\"]\n\tpath = modules/DroneCAN/pydronecan\n\turl = https://github.com/DroneCAN/pydronecan\n[submodule \"modules/DroneCAN/dronecan_dsdlc\"]\n\tpath = modules/DroneCAN/dronecan_dsdlc\n\turl = https://github.com/DroneCAN/dronecan_dsdlc\n[submodule \"modules/DroneCAN/libcanard\"]\n\tpath = modules/DroneCAN/libcanard\n\turl = https://github.com/DroneCAN/libcanard\n[submodule \"modules/Micro-XRCE-DDS-Client\"]\n\tpath = modules/Micro-XRCE-DDS-Client\n\turl = https://github.com/ardupilot/Micro-XRCE-DDS-Client.git\n\tbranch = master\n[submodule \"modules/Micro-CDR\"]\n\tpath = modules/Micro-CDR\n\turl = https://github.com/ardupilot/Micro-CDR.git\n\tbranch = master\n[submodule \"modules/lwip\"]\n\tpath = modules/lwip\n\turl = https://github.com/ArduPilot/lwip.git\n"
        },
        {
          "name": ".pre-commit-config.yaml",
          "type": "blob",
          "size": 2.2890625,
          "content": "# See https://pre-commit.com for more information, specially https://pre-commit.com/#pre-commit-run for manual trigger\n# Some example useful invocations:\n#  pre-commit run: this is what pre-commit runs by default when committing. This will run all hooks against currently staged files.\n#  pre-commit run --all-files: run all the hooks against all the files. This is a useful invocation if you are using pre-commit in CI.\n#  pre-commit run check-executables-have-shebangs: run the check-executables-have-shebangs hook against all staged files.\n\n# Files or directory we want to excude from checking\nexclude: |\n  (?x)(\n  ^modules/ |\n  ^build/ |\n  ^cmake-build-debug/ |\n  \\.m |\n  ^libraries/AP_HAL_ChibiOS/hwdef/scripts/\n  )\n\nrepos:\n  -   repo: https://github.com/pre-commit/pre-commit-hooks\n      rev: v4.4.0\n      hooks:\n        #-   id: trailing-whitespace\n        #-   id: end-of-file-fixer\n        -   id: mixed-line-ending\n            name: Check line ending character (LF)\n            args: [\"--fix=lf\"]\n            types_or: [python, c, c++, shell]\n            exclude: |\n              (?x)^(\n                libraries/AP_ADSB/AP_ADSB_Sagetech_MXS.cpp |\n                libraries/AP_ADSB/AP_ADSB_Sagetech_MXS.h\n              )$\n        -   id: check-added-large-files\n        -   id: check-executables-have-shebangs\n        -   id: check-shebang-scripts-are-executable\n            exclude: |\n              (?x)^(\n                .*\\/wscript |\n                wscript\n              )$\n        -   id: check-merge-conflict\n        -   id: check-xml\n        -   id: check-yaml\n\n  -   repo: https://github.com/psf/black\n      rev: 23.7.0\n      hooks:\n        - id: black\n          files: |\n            (?x)^(\n              libraries\\/AP_DDS\\/(wscript|.*\\.py)$ |\n              Tools/ros2/.*\\.py\n            )$\n\n# # Use to sort python imports by name and put system import first.\n#   -   repo: https://github.com/pycqa/isort\n#       rev: 5.12.0\n#       hooks:\n#         - id: isort\n#           args: [--check-only]\n#           name: isort (python)\n\n# # Use to check python typing to show errors.\n#   -   repo: https://github.com/pre-commit/mirrors-mypy\n#       rev: 'v0.950'\n#       hooks:\n#         - id: mypy\n#           args: [--no-strict-optional, --ignore-missing-imports]\n#           additional_dependencies: [types-PyYAML, types-requests]\n"
        },
        {
          "name": ".pydevproject",
          "type": "blob",
          "size": 0.2998046875,
          "content": "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\r\n<?eclipse-pydev version=\"1.0\"?><pydev_project>\r\n<pydev_property name=\"org.python.pydev.PYTHON_PROJECT_INTERPRETER\">Default</pydev_property>\r\n<pydev_property name=\"org.python.pydev.PYTHON_PROJECT_VERSION\">python 2.7</pydev_property>\r\n</pydev_project>\r\n"
        },
        {
          "name": ".valgrind-suppressions",
          "type": "blob",
          "size": 0.1630859375,
          "content": "{\n   <linux-stack-poisoning>\n   Memcheck:Addr4\n   fun:_ZN5Linux6Thread13_poison_stackEv\n   fun:_ZN5Linux6Thread15_run_trampolineEPv\n   fun:start_thread\n   fun:clone\n}\n"
        },
        {
          "name": ".valgrindrc",
          "type": "blob",
          "size": 0.037109375,
          "content": "--suppressions=.valgrind-suppressions\n"
        },
        {
          "name": ".vscode",
          "type": "tree",
          "content": null
        },
        {
          "name": "AntennaTracker",
          "type": "tree",
          "content": null
        },
        {
          "name": "ArduCopter",
          "type": "tree",
          "content": null
        },
        {
          "name": "ArduPlane",
          "type": "tree",
          "content": null
        },
        {
          "name": "ArduSub",
          "type": "tree",
          "content": null
        },
        {
          "name": "BUILD.md",
          "type": "blob",
          "size": 12.2041015625,
          "content": "# Building ArduPilot #\n\n## Get the Source\n\nClone the project from GitHub:\n```sh\ngit clone --recursive https://github.com/ArduPilot/ardupilot.git\ncd ardupilot\n```\n\nYou can also read more about the build system in the\n[Waf Book](https://waf.io/book/).\n\nwaf should always be called from the locally cloned ardupilot root directory for the local branch you are trying to build from.\n\n**Note**\nDo not run `waf` with `sudo`!  This leads to permission and environment problems.\n\n## Basic usage ##\n\nThere are several commands in the build system for advanced usage, but here we\nlist some basic and more used commands as example.\n\n* **Build ArduCopter**\n\n    Below shows how to build ArduCopter for the Pixhawk2/Cube. Many other boards are\n    supported and the next section shows how to get a full list of them.\n\n    ```sh\n    ./waf configure --board CubeBlack\n    ./waf copter\n    ```\n\n    The first command should be called only once or when you want to change a\n    configuration option. One configuration often used is the `--board` option to\n    switch from one board to another one. For example we could switch to\n    SkyViper GPS drone and build again:\n\n    ```sh\n    ./waf configure --board skyviper-v2450\n    ./waf copter\n    ```\n\n    If building for the bebop2 the binary must be built statically:\n\n    ```sh\n    ./waf configure --board bebop --static\n    ./waf copter\n    ```    \n\n    The \"arducopter\" binary should appear in the `build/<board-name>/bin` directory.\n\n* **List available boards**\n\n\n    It's possible to get a list of supported boards on ArduPilot with the command\n    below\n\n    ```sh\n    ./waf list_boards\n\n    ```\n\n    Here are some commands to configure waf for commonly used boards:\n\n    ```sh\n    ./waf configure --board bebop --static # Bebop or Bebop2\n    ./waf configure --board edge           # emlid edge\n    ./waf configure --board fmuv3          # 3DR Pixhawk 2 boards\n    ./waf configure --board navio2         # emlid navio2\n    ./waf configure --board Pixhawk1       # Pixhawk1\n    ./waf configure --board CubeBlack      # Hex/ProfiCNC Cube Black (formerly known as Pixhawk 2.1)\n    ./waf configure --board Pixracer       # Pixracer\n    ./waf configure --board skyviper-v2450 # SkyRocket's SkyViper GPS drone using ChibiOS\n    ./waf configure --board sitl           # software-in-the-loop simulator\n    ./waf configure --board sitl --debug   # software-in-the-loop simulator with debug symbols\n\n    ```\n\n* **List of available vehicle types**\n\n    Here is a list of the most common vehicle build targets:\n\n    ```sh\n    ./waf copter                            # All multirotor types\n    ./waf heli                              # Helicopter types\n    ./waf plane                             # Fixed wing airplanes including VTOL\n    ./waf rover                             # Ground-based rovers and surface boats\n    ./waf sub                               # ROV and other submarines\n    ./waf antennatracker                    # Antenna trackers\n    ./waf AP_Periph                         # AP Peripheral\n    \n    ```\n\n* **Clean the build**\n\n    Commands `clean` and `distclean` can be used to clean the objects produced by\n    the build. The first keeps the `configure` information, cleaning only the\n    objects for the current board. The second cleans everything for every board,\n    including the saved `configure` information.\n\n    Cleaning the build is very often not necessary and discouraged. We do\n    incremental builds reducing the build time by orders of magnitude.\n\n    If submodules are failing to be synchronized, `submodulesync` may be used\n    to resync the submodules. This is usually necessary when shifting development\n    between stable releases or a stable release and the master branch.\n\n    In some some cases `submodule_force_clean` may be necessary. This removes all submodules and then performs a `submodulesync`. (Note whitelisted modules like esp_idf is not removed.)\n\n* **Upload or install**\n\n    Build commands have a `--upload` option in order to upload the binary built\n    to a connected board. This option is supported by Pixhawk and Linux-based boards.\n    The command below uses the `--targets` option that is explained in the next item.\n\n    ```sh\n    ./waf --targets bin/arducopter --upload\n    ```\n\n    For Linux boards you need first to configure the IP of the board you\n    are going to upload to. This is done on configure phase with:\n\n    ```sh\n    ./waf configure --board <board> --rsync-dest <destination>\n    ```\n\n    The commands below give a concrete example (board and destination\n    IP will change according to the board used):\n\n    ```sh\n    ./waf configure --board navio2 --rsync-dest root@192.168.1.2:/\n    ./waf --target bin/arducopter --upload\n    ```\n\n    This allows to set a destination to which the `--upload` option will upload\n    the binary.  Under the hood  it installs to a temporary location and calls\n    `rsync <temp_install_location>/ <destination>`.\n\n    On Linux boards there's also an install command, which will install to a certain\n    directory, just like the temporary install above does. This can be\n    used by distributors to create .deb, .rpm or other package types:\n\n    ```sh\n    ./waf copter\n    DESTDIR=/my/temporary/location ./waf install\n    ```\n\n* **Use different targets**\n\n    The build commands in the items above use `copter` as argument. This\n    builds all binaries that fall under the \"copter\" group. See the\n    section [Advanced usage](#advanced-usage) below for more details regarding\n    groups.\n\n    This shows a list of all possible targets:\n\n    ```\n    ./waf list\n    ```\n\n    For example, to build only a single binary:\n\n    ```\n    # Quad frame of ArduCopter\n    ./waf --targets bin/arducopter\n\n    # unit test of our math functions\n    ./waf --targets tests/test_math\n    ```\n\n* **Use clang instead of gcc**\n\n    Currently, gcc is the default on linux, and clang is used for MacOS.\n    Building with clang on linux can be accomplished by setting the CXX\n    environment variables during the configure step, e.g.:\n\n    ```\n    CXX=clang++ CC=clang ./waf configure --board=sitl\n    ```\n\n    Note: Your clang binary names may differ.\n\n* **Other options**\n\n    It's possible to see all available commands and options:\n\n    ```\n    ./waf -h\n    ```\n\n    Also, take a look on the [Advanced section](#advanced-usage) below.\n\n### Using Docker ###\n\nA docker environment is provided which may be helpful for building in a clean\nenvironment and avoiding modification of the host environment.\n\nTo build the docker image (should only need to be done once), run:\n\n```bash\ndocker build --rm -t ardupilot-dev .\n```\n\nTo build inside the container, prefix your `waf` commands, e.g.:\n\n```bash\ndocker run --rm -it -v $PWD:/ardupilot ardupilot-dev ./waf configure --board=sitl\ndocker run --rm -it -v $PWD:/ardupilot ardupilot-dev ./waf copter\n```\n\nAlternatively, simply run `docker run --rm -it -v $PWD:/ardupilot ardupilot-dev` to\nstart a `bash` shell in which you can run other commands from this document.\n\n## Advanced usage ##\n\nThis section contains some explanations on how the Waf build system works\nand how you can use more advanced features.\n\nWaf build system is composed of commands. For example, the command below\n(`configure`) is for configuring the build with all the options used by this\nparticular build.\n\n```bash\n# Configure the Linux board\n./waf configure --board=linux\n```\n\nConsequently, in order to build, a \"build\" command is issued, thus `waf build`.\nThat is the default command, so calling just `waf` is enough:\n\n```bash\n# Build programs from bin group\n./waf\n\n# Waf also accepts '-j' option to parallelize the build.\n./waf -j8\n```\n\nBy default waf tries to parallelize the build automatically to all processors\nso the `-j` option is usually not needed, unless you are using icecc (thus\nyou want a bigger value) or you don't want to stress your machine with\nthe build.\n\n### Program groups ###\n\nProgram groups are used to represent a class of programs. They can be used to\nbuild all programs of a certain class without having to specify each program.\nIt's possible for two groups to overlap, except when both groups are main\ngroups. In other words, a program can belong to more than one group, but only\nto one main group.\n\nThere's a special group, called \"all\", that comprises all programs.\n\n#### Main groups ####\n\nThe main groups form a partition of all programs. Besides separating the\nprograms logically, they also define where they are built.\n\nThe main groups are:\n\n - bin: *the main binaries, that is, ardupilot's main products - the vehicles and\n   Antenna Tracker*\n - tools\n - examples: *programs that show how certain libraries are used or to simply\n   test their operation*\n - benchmarks: *requires `--enable-benchmarks` during configurarion*\n - tests: *basically unit tests to ensure changes don't break the system's\n   logic*\n\nAll build files are placed under `build/<board>/`, where `<board>` represents\nthe board/platform you selected during configuration. Each main program group\nhas a folder with its name directly under `build/<board>/`. Thus, a program\nwill be stored in `build/<board>/<main_group>/`, where `<main_group>` is the\nmain group the program belongs to. For example, for a linux build, arduplane,\nwhich belongs to the main group \"bin\", will be located at\n`build/linux/bin/arduplane`.\n\n#### Main product groups ####\n\nThose are groups for ardupilot's main products. They contain programs for the\nproduct they represent. Currently only the \"copter\" group has more than one\nprogram - one for each frame type.\n\nThe main product groups are:\n\n - antennatracker\n - copter\n - plane\n - rover\n\n#### Building a program group ####\n\nArdupilot adds to waf an option called `--program-group`, which receives as\nargument the group you want it to build. For a build command, if you don't pass\nany of `--targets` or `--program-group`, then the group \"bin\" is selected by\ndefault. The option `--program-group` can be passed multiple times.\n\nExamples:\n\n```bash\n# Group bin is the default one\n./waf\n\n# Build all vehicles and Antenna Tracker\n./waf --program-group bin\n\n# Build all benchmarks and tests\n./waf --program-group benchmarks --program-group tests\n```\n#### Shortcut for program groups ####\n\nFor less typing, you can use the group name as the command to waf. Examples:\n\n```bash\n# Build all vehicles and Antenna Tracker\n./waf bin\n\n# Build all examples\n./waf examples\n\n# Build arducopter binaries\n./waf copter\n```\n\n### Building a specific program ###\n\nIn order to build a specific program, you just need to pass its path relative\nto `build/<board>/` to the option `--targets`. Example:\n\n```bash\n# Build arducopter for quad frame\n./waf --targets bin/arducopter\n\n# Build vectors unit test\n./waf --targets tests/test_vectors\n```\n\n### Checking ###\n\nThe command `check` builds all programs and then executes the relevant tests.\nIn that context, a relevant test is a program from the group \"tests\" that makes\none of the following statements true:\n\n - it's the first time the test is built since the last cleanup or when the\n   project was cloned.\n - the program had to be rebuilt (due to modifications in the code or\n   dependencies, for example)\n - the test program failed in the previous check.\n\nThat is, the tests are run only if necessary. If you want waf to run all tests,\nthen you can use either option `--alltests` or the shortcut command\n`check-all`.\n\nExamples:\n\n```bash\n# Build everything and run relevant tests\n./waf check\n\n# Build everything and run all tests\n./waf check --alltests\n\n# Build everything and run all tests\n./waf check-all\n```\n\n### Debugging ###\n\nIt's possible to pass the option `--debug` to the `configure` command. That\nwill set compiler flags to store debugging information in the binaries so that\nyou can use them with `gdb`, for example. That option might come handy when using SITL.\n\n### Build-system wrappers ###\n\nThe `waf` binary on root tree is actually a wrapper to the real `waf` that's\nmaintained in its own submodule.  It's possible to call the latter directly via\n`./modules/waf/waf-light` or to use an alias if you prefer typing `waf` over\n`./waf`.\n\n```sh\nalias waf=\"<ardupilot-directory>/modules/waf/waf-light\"\n\n```\n\nThere's also a make wrapper called `Makefile.waf`. You can use\n`make -f Makefile.waf help` for instructions on how to use it.\n\n### Command line help ###\n\nYou can use `waf --help` to see information about commands and options built-in\nto waf as well as some quick help on those added by ardupilot.\n"
        },
        {
          "name": "Blimp",
          "type": "tree",
          "content": null
        },
        {
          "name": "CODE_OF_CONDUCT.md",
          "type": "blob",
          "size": 4.6845703125,
          "content": "ArduPilot Developer Code of Conduct\n===================================\n\nRev 1.0 Jan 2nd 2018\n\nOur Aim\n-------\n\nArduPilot aims to enable the creation and use of trusted, autonomous,\nunmanned vehicle systems for the peaceful benefit of all.\n\nOur Team\n--------\n\nThe ArduPilot team is global. It consists of the Development Team plus\nmany contributors, from many fields and many places. By choosing to be\npart of the ArduPilot Development Team, you choose to accept this Code\nof Conduct.\n\nOur Pledge\n----------\n\nIn the interest of fostering an open and welcoming environment, we as\ndevelopers and maintainers pledge to:\n\n-   Endeavour to make participation in our project and our community a\n    harassment-free experience for everyone, regardless of age, body\n    size, disability, ethnicity, gender identity and expression, level\n    of experience, nationality, personal appearance, race, religion, or\n    sexual identity and orientation.\n-   Endeavour to understand the intent of development activities they\n    undertake, where there may be reason to think that the vehicle may\n    be used as a weapon or in an application where it is effectively in\n    control of human life.\n-   Not knowingly support or facilitate the weaponization of systems\n    using ArduPilot\n-   ArduPilot is NOT certified for use in applications where ArduPilot\n    is effectively in control of human lives. Members of the development\n    team must not knowingly assist in projects where ArduPilot will be\n    in control of human lives. “In control of human lives” includes but\n    isn’t limited to manned aircraft.\n\nOur Standards\n-------------\n\nExamples of behavior that contributes to achieving the aims of ArduPilot\ninclude:\n\n-   Using welcoming and inclusive language\n-   Being respectful of differing viewpoints and experiences\n-   Gracefully accepting constructive criticism\n-   Focusing on what is best for the community\n-   Showing empathy towards other community members\n\nExamples of unacceptable behavior by contributors include:\n\n-   The use of sexualized language or imagery and unwelcome sexual\n    attention or advances\n-   Trolling, insulting/derogatory comments, and personal or political\n    attacks\n-   Public or private harassment\n-   Publishing others’ private information, such as a physical or\n    electronic address, without explicit permission\n-   Modifying ArduPilot code to intentionally support weaponization\n-   Knowingly designing, testing or using weaponized systems running\n    ArduPilot\n-   Other conduct which could reasonably be considered inappropriate in\n    a public or professional setting\n\nOur Responsibilities\n--------------------\n\nProject maintainers are responsible for clarifying the standards of\nacceptable behavior and are expected to take appropriate and fair\ncorrective action in response to any instances of unacceptable behavior.\n\nProject maintainers have the right and responsibility to remove, edit,\nor reject comments, commits, code, wiki edits, issues, and other\ncontributions that are not aligned to this Code of Conduct, or to ban\ntemporarily or permanently any contributor for other behaviors that they\ndeem inappropriate, threatening, offensive, or harmful.\n\nScope\n-----\n\nThis Code of Conduct applies both within project spaces and in public\nspaces when an individual is representing the ArduPilot project or its\ncommunity. Examples of representing the ArduPilot project or community\ninclude using an official project e-mail address, posting via an\nofficial social media account, or acting as an appointed representative\nat an online or offline event. Representation of the ArduPilot project\nmay be further defined and clarified by project maintainers.\n\nIn addition, the rules regarding weaponization and manned vehicles using\nArduPilot apply regardless of whether you are representing the ArduPilot\nproject at the time.\n\nEnforcement\n-----------\n\nInstances of abusive, harassing, or otherwise unacceptable behavior, and\nother actions not consistent with this Code of Conduct may be reported\nby contacting the project team at <ardupilot.devel@gmail.com>. All\ncomplaints will be reviewed and investigated and will result in a\nresponse that is deemed necessary and appropriate to the circumstances.\nThe project team is obligated to maintain confidentiality with regard to\nthe reporter of an incident. Further details of specific enforcement\npolicies may be posted separately. Project maintainers who do not follow\nor enforce the Code of Conduct in good faith may face temporary or\npermanent repercussions as determined by other members of the project’s\nleadership team.\n\nAttribution\n-----------\n\nThis Code of Conduct is adapted from the Contributor Covenant, version\n1.4, available at\n<https://www.contributor-covenant.org/version/1/4/code-of-conduct.html>\n"
        },
        {
          "name": "COPYING.txt",
          "type": "blob",
          "size": 34.3232421875,
          "content": "                    GNU GENERAL PUBLIC LICENSE\n                       Version 3, 29 June 2007\n\n Copyright (C) 2007 Free Software Foundation, Inc. <http://fsf.org/>\n Everyone is permitted to copy and distribute verbatim copies\n of this license document, but changing it is not allowed.\n\n                            Preamble\n\n  The GNU General Public License is a free, copyleft license for\nsoftware and other kinds of works.\n\n  The licenses for most software and other practical works are designed\nto take away your freedom to share and change the works.  By contrast,\nthe GNU General Public License is intended to guarantee your freedom to\nshare and change all versions of a program--to make sure it remains free\nsoftware for all its users.  We, the Free Software Foundation, use the\nGNU General Public License for most of our software; it applies also to\nany other work released this way by its authors.  You can apply it to\nyour programs, too.\n\n  When we speak of free software, we are referring to freedom, not\nprice.  Our General Public Licenses are designed to make sure that you\nhave the freedom to distribute copies of free software (and charge for\nthem if you wish), that you receive source code or can get it if you\nwant it, that you can change the software or use pieces of it in new\nfree programs, and that you know you can do these things.\n\n  To protect your rights, we need to prevent others from denying you\nthese rights or asking you to surrender the rights.  Therefore, you have\ncertain responsibilities if you distribute copies of the software, or if\nyou modify it: responsibilities to respect the freedom of others.\n\n  For example, if you distribute copies of such a program, whether\ngratis or for a fee, you must pass on to the recipients the same\nfreedoms that you received.  You must make sure that they, too, receive\nor can get the source code.  And you must show them these terms so they\nknow their rights.\n\n  Developers that use the GNU GPL protect your rights with two steps:\n(1) assert copyright on the software, and (2) offer you this License\ngiving you legal permission to copy, distribute and/or modify it.\n\n  For the developers' and authors' protection, the GPL clearly explains\nthat there is no warranty for this free software.  For both users' and\nauthors' sake, the GPL requires that modified versions be marked as\nchanged, so that their problems will not be attributed erroneously to\nauthors of previous versions.\n\n  Some devices are designed to deny users access to install or run\nmodified versions of the software inside them, although the manufacturer\ncan do so.  This is fundamentally incompatible with the aim of\nprotecting users' freedom to change the software.  The systematic\npattern of such abuse occurs in the area of products for individuals to\nuse, which is precisely where it is most unacceptable.  Therefore, we\nhave designed this version of the GPL to prohibit the practice for those\nproducts.  If such problems arise substantially in other domains, we\nstand ready to extend this provision to those domains in future versions\nof the GPL, as needed to protect the freedom of users.\n\n  Finally, every program is threatened constantly by software patents.\nStates should not allow patents to restrict development and use of\nsoftware on general-purpose computers, but in those that do, we wish to\navoid the special danger that patents applied to a free program could\nmake it effectively proprietary.  To prevent this, the GPL assures that\npatents cannot be used to render the program non-free.\n\n  The precise terms and conditions for copying, distribution and\nmodification follow.\n\n                       TERMS AND CONDITIONS\n\n  0. Definitions.\n\n  \"This License\" refers to version 3 of the GNU General Public License.\n\n  \"Copyright\" also means copyright-like laws that apply to other kinds of\nworks, such as semiconductor masks.\n\n  \"The Program\" refers to any copyrightable work licensed under this\nLicense.  Each licensee is addressed as \"you\".  \"Licensees\" and\n\"recipients\" may be individuals or organizations.\n\n  To \"modify\" a work means to copy from or adapt all or part of the work\nin a fashion requiring copyright permission, other than the making of an\nexact copy.  The resulting work is called a \"modified version\" of the\nearlier work or a work \"based on\" the earlier work.\n\n  A \"covered work\" means either the unmodified Program or a work based\non the Program.\n\n  To \"propagate\" a work means to do anything with it that, without\npermission, would make you directly or secondarily liable for\ninfringement under applicable copyright law, except executing it on a\ncomputer or modifying a private copy.  Propagation includes copying,\ndistribution (with or without modification), making available to the\npublic, and in some countries other activities as well.\n\n  To \"convey\" a work means any kind of propagation that enables other\nparties to make or receive copies.  Mere interaction with a user through\na computer network, with no transfer of a copy, is not conveying.\n\n  An interactive user interface displays \"Appropriate Legal Notices\"\nto the extent that it includes a convenient and prominently visible\nfeature that (1) displays an appropriate copyright notice, and (2)\ntells the user that there is no warranty for the work (except to the\nextent that warranties are provided), that licensees may convey the\nwork under this License, and how to view a copy of this License.  If\nthe interface presents a list of user commands or options, such as a\nmenu, a prominent item in the list meets this criterion.\n\n  1. Source Code.\n\n  The \"source code\" for a work means the preferred form of the work\nfor making modifications to it.  \"Object code\" means any non-source\nform of a work.\n\n  A \"Standard Interface\" means an interface that either is an official\nstandard defined by a recognized standards body, or, in the case of\ninterfaces specified for a particular programming language, one that\nis widely used among developers working in that language.\n\n  The \"System Libraries\" of an executable work include anything, other\nthan the work as a whole, that (a) is included in the normal form of\npackaging a Major Component, but which is not part of that Major\nComponent, and (b) serves only to enable use of the work with that\nMajor Component, or to implement a Standard Interface for which an\nimplementation is available to the public in source code form.  A\n\"Major Component\", in this context, means a major essential component\n(kernel, window system, and so on) of the specific operating system\n(if any) on which the executable work runs, or a compiler used to\nproduce the work, or an object code interpreter used to run it.\n\n  The \"Corresponding Source\" for a work in object code form means all\nthe source code needed to generate, install, and (for an executable\nwork) run the object code and to modify the work, including scripts to\ncontrol those activities.  However, it does not include the work's\nSystem Libraries, or general-purpose tools or generally available free\nprograms which are used unmodified in performing those activities but\nwhich are not part of the work.  For example, Corresponding Source\nincludes interface definition files associated with source files for\nthe work, and the source code for shared libraries and dynamically\nlinked subprograms that the work is specifically designed to require,\nsuch as by intimate data communication or control flow between those\nsubprograms and other parts of the work.\n\n  The Corresponding Source need not include anything that users\ncan regenerate automatically from other parts of the Corresponding\nSource.\n\n  The Corresponding Source for a work in source code form is that\nsame work.\n\n  2. Basic Permissions.\n\n  All rights granted under this License are granted for the term of\ncopyright on the Program, and are irrevocable provided the stated\nconditions are met.  This License explicitly affirms your unlimited\npermission to run the unmodified Program.  The output from running a\ncovered work is covered by this License only if the output, given its\ncontent, constitutes a covered work.  This License acknowledges your\nrights of fair use or other equivalent, as provided by copyright law.\n\n  You may make, run and propagate covered works that you do not\nconvey, without conditions so long as your license otherwise remains\nin force.  You may convey covered works to others for the sole purpose\nof having them make modifications exclusively for you, or provide you\nwith facilities for running those works, provided that you comply with\nthe terms of this License in conveying all material for which you do\nnot control copyright.  Those thus making or running the covered works\nfor you must do so exclusively on your behalf, under your direction\nand control, on terms that prohibit them from making any copies of\nyour copyrighted material outside their relationship with you.\n\n  Conveying under any other circumstances is permitted solely under\nthe conditions stated below.  Sublicensing is not allowed; section 10\nmakes it unnecessary.\n\n  3. Protecting Users' Legal Rights From Anti-Circumvention Law.\n\n  No covered work shall be deemed part of an effective technological\nmeasure under any applicable law fulfilling obligations under article\n11 of the WIPO copyright treaty adopted on 20 December 1996, or\nsimilar laws prohibiting or restricting circumvention of such\nmeasures.\n\n  When you convey a covered work, you waive any legal power to forbid\ncircumvention of technological measures to the extent such circumvention\nis effected by exercising rights under this License with respect to\nthe covered work, and you disclaim any intention to limit operation or\nmodification of the work as a means of enforcing, against the work's\nusers, your or third parties' legal rights to forbid circumvention of\ntechnological measures.\n\n  4. Conveying Verbatim Copies.\n\n  You may convey verbatim copies of the Program's source code as you\nreceive it, in any medium, provided that you conspicuously and\nappropriately publish on each copy an appropriate copyright notice;\nkeep intact all notices stating that this License and any\nnon-permissive terms added in accord with section 7 apply to the code;\nkeep intact all notices of the absence of any warranty; and give all\nrecipients a copy of this License along with the Program.\n\n  You may charge any price or no price for each copy that you convey,\nand you may offer support or warranty protection for a fee.\n\n  5. Conveying Modified Source Versions.\n\n  You may convey a work based on the Program, or the modifications to\nproduce it from the Program, in the form of source code under the\nterms of section 4, provided that you also meet all of these conditions:\n\n    a) The work must carry prominent notices stating that you modified\n    it, and giving a relevant date.\n\n    b) The work must carry prominent notices stating that it is\n    released under this License and any conditions added under section\n    7.  This requirement modifies the requirement in section 4 to\n    \"keep intact all notices\".\n\n    c) You must license the entire work, as a whole, under this\n    License to anyone who comes into possession of a copy.  This\n    License will therefore apply, along with any applicable section 7\n    additional terms, to the whole of the work, and all its parts,\n    regardless of how they are packaged.  This License gives no\n    permission to license the work in any other way, but it does not\n    invalidate such permission if you have separately received it.\n\n    d) If the work has interactive user interfaces, each must display\n    Appropriate Legal Notices; however, if the Program has interactive\n    interfaces that do not display Appropriate Legal Notices, your\n    work need not make them do so.\n\n  A compilation of a covered work with other separate and independent\nworks, which are not by their nature extensions of the covered work,\nand which are not combined with it such as to form a larger program,\nin or on a volume of a storage or distribution medium, is called an\n\"aggregate\" if the compilation and its resulting copyright are not\nused to limit the access or legal rights of the compilation's users\nbeyond what the individual works permit.  Inclusion of a covered work\nin an aggregate does not cause this License to apply to the other\nparts of the aggregate.\n\n  6. Conveying Non-Source Forms.\n\n  You may convey a covered work in object code form under the terms\nof sections 4 and 5, provided that you also convey the\nmachine-readable Corresponding Source under the terms of this License,\nin one of these ways:\n\n    a) Convey the object code in, or embodied in, a physical product\n    (including a physical distribution medium), accompanied by the\n    Corresponding Source fixed on a durable physical medium\n    customarily used for software interchange.\n\n    b) Convey the object code in, or embodied in, a physical product\n    (including a physical distribution medium), accompanied by a\n    written offer, valid for at least three years and valid for as\n    long as you offer spare parts or customer support for that product\n    model, to give anyone who possesses the object code either (1) a\n    copy of the Corresponding Source for all the software in the\n    product that is covered by this License, on a durable physical\n    medium customarily used for software interchange, for a price no\n    more than your reasonable cost of physically performing this\n    conveying of source, or (2) access to copy the\n    Corresponding Source from a network server at no charge.\n\n    c) Convey individual copies of the object code with a copy of the\n    written offer to provide the Corresponding Source.  This\n    alternative is allowed only occasionally and noncommercially, and\n    only if you received the object code with such an offer, in accord\n    with subsection 6b.\n\n    d) Convey the object code by offering access from a designated\n    place (gratis or for a charge), and offer equivalent access to the\n    Corresponding Source in the same way through the same place at no\n    further charge.  You need not require recipients to copy the\n    Corresponding Source along with the object code.  If the place to\n    copy the object code is a network server, the Corresponding Source\n    may be on a different server (operated by you or a third party)\n    that supports equivalent copying facilities, provided you maintain\n    clear directions next to the object code saying where to find the\n    Corresponding Source.  Regardless of what server hosts the\n    Corresponding Source, you remain obligated to ensure that it is\n    available for as long as needed to satisfy these requirements.\n\n    e) Convey the object code using peer-to-peer transmission, provided\n    you inform other peers where the object code and Corresponding\n    Source of the work are being offered to the general public at no\n    charge under subsection 6d.\n\n  A separable portion of the object code, whose source code is excluded\nfrom the Corresponding Source as a System Library, need not be\nincluded in conveying the object code work.\n\n  A \"User Product\" is either (1) a \"consumer product\", which means any\ntangible personal property which is normally used for personal, family,\nor household purposes, or (2) anything designed or sold for incorporation\ninto a dwelling.  In determining whether a product is a consumer product,\ndoubtful cases shall be resolved in favor of coverage.  For a particular\nproduct received by a particular user, \"normally used\" refers to a\ntypical or common use of that class of product, regardless of the status\nof the particular user or of the way in which the particular user\nactually uses, or expects or is expected to use, the product.  A product\nis a consumer product regardless of whether the product has substantial\ncommercial, industrial or non-consumer uses, unless such uses represent\nthe only significant mode of use of the product.\n\n  \"Installation Information\" for a User Product means any methods,\nprocedures, authorization keys, or other information required to install\nand execute modified versions of a covered work in that User Product from\na modified version of its Corresponding Source.  The information must\nsuffice to ensure that the continued functioning of the modified object\ncode is in no case prevented or interfered with solely because\nmodification has been made.\n\n  If you convey an object code work under this section in, or with, or\nspecifically for use in, a User Product, and the conveying occurs as\npart of a transaction in which the right of possession and use of the\nUser Product is transferred to the recipient in perpetuity or for a\nfixed term (regardless of how the transaction is characterized), the\nCorresponding Source conveyed under this section must be accompanied\nby the Installation Information.  But this requirement does not apply\nif neither you nor any third party retains the ability to install\nmodified object code on the User Product (for example, the work has\nbeen installed in ROM).\n\n  The requirement to provide Installation Information does not include a\nrequirement to continue to provide support service, warranty, or updates\nfor a work that has been modified or installed by the recipient, or for\nthe User Product in which it has been modified or installed.  Access to a\nnetwork may be denied when the modification itself materially and\nadversely affects the operation of the network or violates the rules and\nprotocols for communication across the network.\n\n  Corresponding Source conveyed, and Installation Information provided,\nin accord with this section must be in a format that is publicly\ndocumented (and with an implementation available to the public in\nsource code form), and must require no special password or key for\nunpacking, reading or copying.\n\n  7. Additional Terms.\n\n  \"Additional permissions\" are terms that supplement the terms of this\nLicense by making exceptions from one or more of its conditions.\nAdditional permissions that are applicable to the entire Program shall\nbe treated as though they were included in this License, to the extent\nthat they are valid under applicable law.  If additional permissions\napply only to part of the Program, that part may be used separately\nunder those permissions, but the entire Program remains governed by\nthis License without regard to the additional permissions.\n\n  When you convey a copy of a covered work, you may at your option\nremove any additional permissions from that copy, or from any part of\nit.  (Additional permissions may be written to require their own\nremoval in certain cases when you modify the work.)  You may place\nadditional permissions on material, added by you to a covered work,\nfor which you have or can give appropriate copyright permission.\n\n  Notwithstanding any other provision of this License, for material you\nadd to a covered work, you may (if authorized by the copyright holders of\nthat material) supplement the terms of this License with terms:\n\n    a) Disclaiming warranty or limiting liability differently from the\n    terms of sections 15 and 16 of this License; or\n\n    b) Requiring preservation of specified reasonable legal notices or\n    author attributions in that material or in the Appropriate Legal\n    Notices displayed by works containing it; or\n\n    c) Prohibiting misrepresentation of the origin of that material, or\n    requiring that modified versions of such material be marked in\n    reasonable ways as different from the original version; or\n\n    d) Limiting the use for publicity purposes of names of licensors or\n    authors of the material; or\n\n    e) Declining to grant rights under trademark law for use of some\n    trade names, trademarks, or service marks; or\n\n    f) Requiring indemnification of licensors and authors of that\n    material by anyone who conveys the material (or modified versions of\n    it) with contractual assumptions of liability to the recipient, for\n    any liability that these contractual assumptions directly impose on\n    those licensors and authors.\n\n  All other non-permissive additional terms are considered \"further\nrestrictions\" within the meaning of section 10.  If the Program as you\nreceived it, or any part of it, contains a notice stating that it is\ngoverned by this License along with a term that is a further\nrestriction, you may remove that term.  If a license document contains\na further restriction but permits relicensing or conveying under this\nLicense, you may add to a covered work material governed by the terms\nof that license document, provided that the further restriction does\nnot survive such relicensing or conveying.\n\n  If you add terms to a covered work in accord with this section, you\nmust place, in the relevant source files, a statement of the\nadditional terms that apply to those files, or a notice indicating\nwhere to find the applicable terms.\n\n  Additional terms, permissive or non-permissive, may be stated in the\nform of a separately written license, or stated as exceptions;\nthe above requirements apply either way.\n\n  8. Termination.\n\n  You may not propagate or modify a covered work except as expressly\nprovided under this License.  Any attempt otherwise to propagate or\nmodify it is void, and will automatically terminate your rights under\nthis License (including any patent licenses granted under the third\nparagraph of section 11).\n\n  However, if you cease all violation of this License, then your\nlicense from a particular copyright holder is reinstated (a)\nprovisionally, unless and until the copyright holder explicitly and\nfinally terminates your license, and (b) permanently, if the copyright\nholder fails to notify you of the violation by some reasonable means\nprior to 60 days after the cessation.\n\n  Moreover, your license from a particular copyright holder is\nreinstated permanently if the copyright holder notifies you of the\nviolation by some reasonable means, this is the first time you have\nreceived notice of violation of this License (for any work) from that\ncopyright holder, and you cure the violation prior to 30 days after\nyour receipt of the notice.\n\n  Termination of your rights under this section does not terminate the\nlicenses of parties who have received copies or rights from you under\nthis License.  If your rights have been terminated and not permanently\nreinstated, you do not qualify to receive new licenses for the same\nmaterial under section 10.\n\n  9. Acceptance Not Required for Having Copies.\n\n  You are not required to accept this License in order to receive or\nrun a copy of the Program.  Ancillary propagation of a covered work\noccurring solely as a consequence of using peer-to-peer transmission\nto receive a copy likewise does not require acceptance.  However,\nnothing other than this License grants you permission to propagate or\nmodify any covered work.  These actions infringe copyright if you do\nnot accept this License.  Therefore, by modifying or propagating a\ncovered work, you indicate your acceptance of this License to do so.\n\n  10. Automatic Licensing of Downstream Recipients.\n\n  Each time you convey a covered work, the recipient automatically\nreceives a license from the original licensors, to run, modify and\npropagate that work, subject to this License.  You are not responsible\nfor enforcing compliance by third parties with this License.\n\n  An \"entity transaction\" is a transaction transferring control of an\norganization, or substantially all assets of one, or subdividing an\norganization, or merging organizations.  If propagation of a covered\nwork results from an entity transaction, each party to that\ntransaction who receives a copy of the work also receives whatever\nlicenses to the work the party's predecessor in interest had or could\ngive under the previous paragraph, plus a right to possession of the\nCorresponding Source of the work from the predecessor in interest, if\nthe predecessor has it or can get it with reasonable efforts.\n\n  You may not impose any further restrictions on the exercise of the\nrights granted or affirmed under this License.  For example, you may\nnot impose a license fee, royalty, or other charge for exercise of\nrights granted under this License, and you may not initiate litigation\n(including a cross-claim or counterclaim in a lawsuit) alleging that\nany patent claim is infringed by making, using, selling, offering for\nsale, or importing the Program or any portion of it.\n\n  11. Patents.\n\n  A \"contributor\" is a copyright holder who authorizes use under this\nLicense of the Program or a work on which the Program is based.  The\nwork thus licensed is called the contributor's \"contributor version\".\n\n  A contributor's \"essential patent claims\" are all patent claims\nowned or controlled by the contributor, whether already acquired or\nhereafter acquired, that would be infringed by some manner, permitted\nby this License, of making, using, or selling its contributor version,\nbut do not include claims that would be infringed only as a\nconsequence of further modification of the contributor version.  For\npurposes of this definition, \"control\" includes the right to grant\npatent sublicenses in a manner consistent with the requirements of\nthis License.\n\n  Each contributor grants you a non-exclusive, worldwide, royalty-free\npatent license under the contributor's essential patent claims, to\nmake, use, sell, offer for sale, import and otherwise run, modify and\npropagate the contents of its contributor version.\n\n  In the following three paragraphs, a \"patent license\" is any express\nagreement or commitment, however denominated, not to enforce a patent\n(such as an express permission to practice a patent or covenant not to\nsue for patent infringement).  To \"grant\" such a patent license to a\nparty means to make such an agreement or commitment not to enforce a\npatent against the party.\n\n  If you convey a covered work, knowingly relying on a patent license,\nand the Corresponding Source of the work is not available for anyone\nto copy, free of charge and under the terms of this License, through a\npublicly available network server or other readily accessible means,\nthen you must either (1) cause the Corresponding Source to be so\navailable, or (2) arrange to deprive yourself of the benefit of the\npatent license for this particular work, or (3) arrange, in a manner\nconsistent with the requirements of this License, to extend the patent\nlicense to downstream recipients.  \"Knowingly relying\" means you have\nactual knowledge that, but for the patent license, your conveying the\ncovered work in a country, or your recipient's use of the covered work\nin a country, would infringe one or more identifiable patents in that\ncountry that you have reason to believe are valid.\n\n  If, pursuant to or in connection with a single transaction or\narrangement, you convey, or propagate by procuring conveyance of, a\ncovered work, and grant a patent license to some of the parties\nreceiving the covered work authorizing them to use, propagate, modify\nor convey a specific copy of the covered work, then the patent license\nyou grant is automatically extended to all recipients of the covered\nwork and works based on it.\n\n  A patent license is \"discriminatory\" if it does not include within\nthe scope of its coverage, prohibits the exercise of, or is\nconditioned on the non-exercise of one or more of the rights that are\nspecifically granted under this License.  You may not convey a covered\nwork if you are a party to an arrangement with a third party that is\nin the business of distributing software, under which you make payment\nto the third party based on the extent of your activity of conveying\nthe work, and under which the third party grants, to any of the\nparties who would receive the covered work from you, a discriminatory\npatent license (a) in connection with copies of the covered work\nconveyed by you (or copies made from those copies), or (b) primarily\nfor and in connection with specific products or compilations that\ncontain the covered work, unless you entered into that arrangement,\nor that patent license was granted, prior to 28 March 2007.\n\n  Nothing in this License shall be construed as excluding or limiting\nany implied license or other defenses to infringement that may\notherwise be available to you under applicable patent law.\n\n  12. No Surrender of Others' Freedom.\n\n  If conditions are imposed on you (whether by court order, agreement or\notherwise) that contradict the conditions of this License, they do not\nexcuse you from the conditions of this License.  If you cannot convey a\ncovered work so as to satisfy simultaneously your obligations under this\nLicense and any other pertinent obligations, then as a consequence you may\nnot convey it at all.  For example, if you agree to terms that obligate you\nto collect a royalty for further conveying from those to whom you convey\nthe Program, the only way you could satisfy both those terms and this\nLicense would be to refrain entirely from conveying the Program.\n\n  13. Use with the GNU Affero General Public License.\n\n  Notwithstanding any other provision of this License, you have\npermission to link or combine any covered work with a work licensed\nunder version 3 of the GNU Affero General Public License into a single\ncombined work, and to convey the resulting work.  The terms of this\nLicense will continue to apply to the part which is the covered work,\nbut the special requirements of the GNU Affero General Public License,\nsection 13, concerning interaction through a network will apply to the\ncombination as such.\n\n  14. Revised Versions of this License.\n\n  The Free Software Foundation may publish revised and/or new versions of\nthe GNU General Public License from time to time.  Such new versions will\nbe similar in spirit to the present version, but may differ in detail to\naddress new problems or concerns.\n\n  Each version is given a distinguishing version number.  If the\nProgram specifies that a certain numbered version of the GNU General\nPublic License \"or any later version\" applies to it, you have the\noption of following the terms and conditions either of that numbered\nversion or of any later version published by the Free Software\nFoundation.  If the Program does not specify a version number of the\nGNU General Public License, you may choose any version ever published\nby the Free Software Foundation.\n\n  If the Program specifies that a proxy can decide which future\nversions of the GNU General Public License can be used, that proxy's\npublic statement of acceptance of a version permanently authorizes you\nto choose that version for the Program.\n\n  Later license versions may give you additional or different\npermissions.  However, no additional obligations are imposed on any\nauthor or copyright holder as a result of your choosing to follow a\nlater version.\n\n  15. Disclaimer of Warranty.\n\n  THERE IS NO WARRANTY FOR THE PROGRAM, TO THE EXTENT PERMITTED BY\nAPPLICABLE LAW.  EXCEPT WHEN OTHERWISE STATED IN WRITING THE COPYRIGHT\nHOLDERS AND/OR OTHER PARTIES PROVIDE THE PROGRAM \"AS IS\" WITHOUT WARRANTY\nOF ANY KIND, EITHER EXPRESSED OR IMPLIED, INCLUDING, BUT NOT LIMITED TO,\nTHE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR\nPURPOSE.  THE ENTIRE RISK AS TO THE QUALITY AND PERFORMANCE OF THE PROGRAM\nIS WITH YOU.  SHOULD THE PROGRAM PROVE DEFECTIVE, YOU ASSUME THE COST OF\nALL NECESSARY SERVICING, REPAIR OR CORRECTION.\n\n  16. Limitation of Liability.\n\n  IN NO EVENT UNLESS REQUIRED BY APPLICABLE LAW OR AGREED TO IN WRITING\nWILL ANY COPYRIGHT HOLDER, OR ANY OTHER PARTY WHO MODIFIES AND/OR CONVEYS\nTHE PROGRAM AS PERMITTED ABOVE, BE LIABLE TO YOU FOR DAMAGES, INCLUDING ANY\nGENERAL, SPECIAL, INCIDENTAL OR CONSEQUENTIAL DAMAGES ARISING OUT OF THE\nUSE OR INABILITY TO USE THE PROGRAM (INCLUDING BUT NOT LIMITED TO LOSS OF\nDATA OR DATA BEING RENDERED INACCURATE OR LOSSES SUSTAINED BY YOU OR THIRD\nPARTIES OR A FAILURE OF THE PROGRAM TO OPERATE WITH ANY OTHER PROGRAMS),\nEVEN IF SUCH HOLDER OR OTHER PARTY HAS BEEN ADVISED OF THE POSSIBILITY OF\nSUCH DAMAGES.\n\n  17. Interpretation of Sections 15 and 16.\n\n  If the disclaimer of warranty and limitation of liability provided\nabove cannot be given local legal effect according to their terms,\nreviewing courts shall apply local law that most closely approximates\nan absolute waiver of all civil liability in connection with the\nProgram, unless a warranty or assumption of liability accompanies a\ncopy of the Program in return for a fee.\n\n                     END OF TERMS AND CONDITIONS\n\n            How to Apply These Terms to Your New Programs\n\n  If you develop a new program, and you want it to be of the greatest\npossible use to the public, the best way to achieve this is to make it\nfree software which everyone can redistribute and change under these terms.\n\n  To do so, attach the following notices to the program.  It is safest\nto attach them to the start of each source file to most effectively\nstate the exclusion of warranty; and each file should have at least\nthe \"copyright\" line and a pointer to where the full notice is found.\n\n    <one line to give the program's name and a brief idea of what it does.>\n    Copyright (C) <year>  <name of author>\n\n    This program is free software: you can redistribute it and/or modify\n    it under the terms of the GNU General Public License as published by\n    the Free Software Foundation, either version 3 of the License, or\n    (at your option) any later version.\n\n    This program is distributed in the hope that it will be useful,\n    but WITHOUT ANY WARRANTY; without even the implied warranty of\n    MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n    GNU General Public License for more details.\n\n    You should have received a copy of the GNU General Public License\n    along with this program.  If not, see <http://www.gnu.org/licenses/>.\n\nAlso add information on how to contact you by electronic and paper mail.\n\n  If the program does terminal interaction, make it output a short\nnotice like this when it starts in an interactive mode:\n\n    <program>  Copyright (C) <year>  <name of author>\n    This program comes with ABSOLUTELY NO WARRANTY; for details type `show w'.\n    This is free software, and you are welcome to redistribute it\n    under certain conditions; type `show c' for details.\n\nThe hypothetical commands `show w' and `show c' should show the appropriate\nparts of the General Public License.  Of course, your program's commands\nmight be different; for a GUI interface, you would use an \"about box\".\n\n  You should also get your employer (if you work as a programmer) or school,\nif any, to sign a \"copyright disclaimer\" for the program, if necessary.\nFor more information on this, and how to apply and follow the GNU GPL, see\n<http://www.gnu.org/licenses/>.\n\n  The GNU General Public License does not permit incorporating your program\ninto proprietary programs.  If your program is a subroutine library, you\nmay consider it more useful to permit linking proprietary applications with\nthe library.  If this is what you want to do, use the GNU Lesser General\nPublic License instead of this License.  But first, please read\n<http://www.gnu.org/philosophy/why-not-lgpl.html>.\n"
        },
        {
          "name": "Dockerfile",
          "type": "blob",
          "size": 2.603515625,
          "content": "ARG BASE_IMAGE=\"ubuntu\"\nARG TAG=\"22.04\"\nFROM ${BASE_IMAGE}:${TAG}\nWORKDIR /ardupilot\n\nARG DEBIAN_FRONTEND=noninteractive\nARG USER_NAME=ardupilot\nARG USER_UID=1000\nARG USER_GID=1000\nARG SKIP_AP_EXT_ENV=0\nARG SKIP_AP_GRAPHIC_ENV=1\nARG SKIP_AP_COV_ENV=1\nARG SKIP_AP_GIT_CHECK=1\nARG DO_AP_STM_ENV=1\n\nRUN groupadd ${USER_NAME} --gid ${USER_GID}\\\n    && useradd -l -m ${USER_NAME} -u ${USER_UID} -g ${USER_GID} -s /bin/bash\n\nRUN apt-get update && apt-get install --no-install-recommends -y \\\n    lsb-release \\\n    sudo \\\n    tzdata \\\n    git \\\n    default-jre \\\n    bash-completion\n\nCOPY Tools/environment_install/install-prereqs-ubuntu.sh /ardupilot/Tools/environment_install/\nCOPY Tools/completion /ardupilot/Tools/completion/\n\n# Create non root user for pip\nRUN echo \"ardupilot ALL=(ALL) NOPASSWD:ALL\" > /etc/sudoers.d/${USER_NAME}\nRUN chmod 0440 /etc/sudoers.d/${USER_NAME}\n\nRUN chown -R ${USER_NAME}:${USER_NAME} /${USER_NAME}\n\nUSER ${USER_NAME}\n\nRUN SKIP_AP_EXT_ENV=$SKIP_AP_EXT_ENV SKIP_AP_GRAPHIC_ENV=$SKIP_AP_GRAPHIC_ENV SKIP_AP_COV_ENV=$SKIP_AP_COV_ENV SKIP_AP_GIT_CHECK=$SKIP_AP_GIT_CHECK \\\n    DO_AP_STM_ENV=$DO_AP_STM_ENV \\\n    AP_DOCKER_BUILD=1 \\\n    USER=${USER_NAME} \\\n    Tools/environment_install/install-prereqs-ubuntu.sh -y\n\n# Rectify git perms issue that seems to crop up only on OSX\nRUN git config --global --add safe.directory $PWD\n\n# Check that local/bin are in PATH for pip --user installed package\nRUN echo \"if [ -d \\\"\\$HOME/.local/bin\\\" ] ; then\\nPATH=\\\"\\$HOME/.local/bin:\\$PATH\\\"\\nfi\" >> ~/.ardupilot_env\n\n# Clone & install Micro-XRCE-DDS-Gen dependancy\nRUN git clone --recurse-submodules https://github.com/ardupilot/Micro-XRCE-DDS-Gen.git /home/${USER_NAME}/Micro-XRCE-DDS-Gen \\\n    && cd /home/${USER_NAME}/Micro-XRCE-DDS-Gen \\\n    && ./gradlew assemble \\\n    && export AP_ENV_LOC=\"/home/${USER_NAME}/.ardupilot_env\" \\\n    && echo \"export PATH=\\$PATH:$PWD/scripts\" >> $AP_ENV_LOC\n\n# Create entrypoint as docker cannot do shell substitution correctly\nRUN export ARDUPILOT_ENTRYPOINT=\"/home/${USER_NAME}/ardupilot_entrypoint.sh\" \\\n    && echo \"#!/bin/bash\" > $ARDUPILOT_ENTRYPOINT \\\n    && echo \"set -e\" >> $ARDUPILOT_ENTRYPOINT \\\n    && echo \"source /home/${USER_NAME}/.ardupilot_env\" >> $ARDUPILOT_ENTRYPOINT \\\n    && echo 'exec \"$@\"' >> $ARDUPILOT_ENTRYPOINT \\\n    && chmod +x $ARDUPILOT_ENTRYPOINT \\\n    && sudo mv $ARDUPILOT_ENTRYPOINT /ardupilot_entrypoint.sh\n\n# Set the buildlogs directory into /tmp as other directory aren't accessible\nENV BUILDLOGS=/tmp/buildlogs\n\n# Cleanup\nRUN sudo apt-get clean \\\n    && sudo rm -rf /var/lib/apt/lists/* /tmp/* /var/tmp/*\n\nENV CCACHE_MAXSIZE=1G\nENTRYPOINT [\"/ardupilot_entrypoint.sh\"]\nCMD [\"bash\"]\n"
        },
        {
          "name": "Doxyfile.in",
          "type": "blob",
          "size": 62.2158203125,
          "content": "# Doxyfile 1.5.8\n\n# This file describes the settings to be used by the documentation system\n# doxygen (www.doxygen.org) for a project\n#\n# All text after a hash (#) is considered a comment and will be ignored\n# The format is:\n#       TAG = value [value, ...]\n# For lists items can also be appended using:\n#       TAG += value [value, ...]\n# Values that contain spaces should be placed between quotes (\" \")\n\n#---------------------------------------------------------------------------\n# Project related configuration options\n#---------------------------------------------------------------------------\n\n# This tag specifies the encoding used for all characters in the config file \n# that follow. The default is UTF-8 which is also the encoding used for all \n# text before the first occurrence of this tag. Doxygen uses libiconv (or the \n# iconv built into libc) for the transcoding. See \n# http://www.gnu.org/software/libiconv for the list of possible encodings.\n\nDOXYFILE_ENCODING      = UTF-8\n\n# The PROJECT_NAME tag is a single word (or a sequence of words surrounded \n# by quotes) that should identify the project.\n\nPROJECT_NAME           = \"@PROJECT_NAME@\"\n\n# The PROJECT_NUMBER tag can be used to enter a project or revision number. \n# This could be handy for archiving the generated documentation or \n# if some version control system is used.\n\nPROJECT_NUMBER         = \"@PROJECT_VERSION@\"\n\n# The OUTPUT_DIRECTORY tag is used to specify the (relative or absolute) \n# base path where the generated documentation will be put. \n# If a relative path is entered, it will be relative to the location \n# where doxygen was started. If left blank the current directory will be used.\n\nOUTPUT_DIRECTORY       = \"@DOXYFILE_OUTPUT_DIR@\"\n\n# If the CREATE_SUBDIRS tag is set to YES, then doxygen will create \n# 4096 sub-directories (in 2 levels) under the output directory of each output \n# format and will distribute the generated files over these directories. \n# Enabling this option can be useful when feeding doxygen a huge amount of \n# source files, where putting all generated files in the same directory would \n# otherwise cause performance problems for the file system.\n\nCREATE_SUBDIRS         = NO\n\n# The OUTPUT_LANGUAGE tag is used to specify the language in which all \n# documentation generated by doxygen is written. Doxygen will use this \n# information to generate all constant output in the proper language. \n# The default language is English, other supported languages are: \n# Afrikaans, Arabic, Brazilian, Catalan, Chinese, Chinese-Traditional, \n# Croatian, Czech, Danish, Dutch, Farsi, Finnish, French, German, Greek, \n# Hungarian, Italian, Japanese, Japanese-en (Japanese with English messages), \n# Korean, Korean-en, Lithuanian, Norwegian, Macedonian, Persian, Polish, \n# Portuguese, Romanian, Russian, Serbian, Serbian-Cyrilic, Slovak, Slovene, \n# Spanish, Swedish, and Ukrainian.\n\nOUTPUT_LANGUAGE        = English\n\n# If the BRIEF_MEMBER_DESC tag is set to YES (the default) Doxygen will \n# include brief member descriptions after the members that are listed in \n# the file and class documentation (similar to JavaDoc). \n# Set to NO to disable this.\n\nBRIEF_MEMBER_DESC      = YES\n\n# If the REPEAT_BRIEF tag is set to YES (the default) Doxygen will prepend \n# the brief description of a member or function before the detailed description. \n# Note: if both HIDE_UNDOC_MEMBERS and BRIEF_MEMBER_DESC are set to NO, the \n# brief descriptions will be completely suppressed.\n\nREPEAT_BRIEF           = YES\n\n# This tag implements a quasi-intelligent brief description abbreviator \n# that is used to form the text in various listings. Each string \n# in this list, if found as the leading text of the brief description, will be \n# stripped from the text and the result after processing the whole list, is \n# used as the annotated text. Otherwise, the brief description is used as-is. \n# If left blank, the following values are used (\"$name\" is automatically \n# replaced with the name of the entity): \"The $name class\" \"The $name widget\" \n# \"The $name file\" \"is\" \"provides\" \"specifies\" \"contains\" \n# \"represents\" \"a\" \"an\" \"the\"\n\nABBREVIATE_BRIEF       = \n\n# If the ALWAYS_DETAILED_SEC and REPEAT_BRIEF tags are both set to YES then \n# Doxygen will generate a detailed section even if there is only a brief \n# description.\n\nALWAYS_DETAILED_SEC    = NO\n\n# If the INLINE_INHERITED_MEMB tag is set to YES, doxygen will show all \n# inherited members of a class in the documentation of that class as if those \n# members were ordinary class members. Constructors, destructors and assignment \n# operators of the base classes will not be shown.\n\nINLINE_INHERITED_MEMB  = NO\n\n# If the FULL_PATH_NAMES tag is set to YES then Doxygen will prepend the full \n# path before files name in the file list and in the header files. If set \n# to NO the shortest path that makes the file name unique will be used.\n\nFULL_PATH_NAMES        = NO\n\n# If the FULL_PATH_NAMES tag is set to YES then the STRIP_FROM_PATH tag \n# can be used to strip a user-defined part of the path. Stripping is \n# only done if one of the specified strings matches the left-hand part of \n# the path. The tag can be used to show relative paths in the file list. \n# If left blank the directory from which doxygen is run is used as the \n# path to strip.\n\nSTRIP_FROM_PATH        = \n\n# The STRIP_FROM_INC_PATH tag can be used to strip a user-defined part of \n# the path mentioned in the documentation of a class, which tells \n# the reader which header file to include in order to use a class. \n# If left blank only the name of the header file containing the class \n# definition is used. Otherwise one should specify the include paths that \n# are normally passed to the compiler using the -I flag.\n\nSTRIP_FROM_INC_PATH    = \n\n# If the SHORT_NAMES tag is set to YES, doxygen will generate much shorter \n# (but less readable) file names. This can be useful is your file systems \n# doesn't support long names like on DOS, Mac, or CD-ROM.\n\nSHORT_NAMES            = NO\n\n# If the JAVADOC_AUTOBRIEF tag is set to YES then Doxygen \n# will interpret the first line (until the first dot) of a JavaDoc-style \n# comment as the brief description. If set to NO, the JavaDoc \n# comments will behave just like regular Qt-style comments \n# (thus requiring an explicit @brief command for a brief description.)\n\nJAVADOC_AUTOBRIEF      = NO\n\n# If the QT_AUTOBRIEF tag is set to YES then Doxygen will \n# interpret the first line (until the first dot) of a Qt-style \n# comment as the brief description. If set to NO, the comments \n# will behave just like regular Qt-style comments (thus requiring \n# an explicit \\brief command for a brief description.)\n\nQT_AUTOBRIEF           = NO\n\n# The MULTILINE_CPP_IS_BRIEF tag can be set to YES to make Doxygen \n# treat a multi-line C++ special comment block (i.e. a block of //! or /// \n# comments) as a brief description. This used to be the default behaviour. \n# The new default is to treat a multi-line C++ comment block as a detailed \n# description. Set this tag to YES if you prefer the old behaviour instead.\n\nMULTILINE_CPP_IS_BRIEF = NO\n\n# If the INHERIT_DOCS tag is set to YES (the default) then an undocumented \n# member inherits the documentation from any documented member that it \n# re-implements.\n\nINHERIT_DOCS           = YES\n\n# If the SEPARATE_MEMBER_PAGES tag is set to YES, then doxygen will produce \n# a new page for each member. If set to NO, the documentation of a member will \n# be part of the file/class/namespace that contains it.\n\nSEPARATE_MEMBER_PAGES  = NO\n\n# The TAB_SIZE tag can be used to set the number of spaces in a tab. \n# Doxygen uses this value to replace tabs by spaces in code fragments.\n\nTAB_SIZE               = 8\n\n# This tag can be used to specify a number of aliases that acts \n# as commands in the documentation. An alias has the form \"name=value\". \n# For example adding \"sideeffect=\\par Side Effects:\\n\" will allow you to \n# put the command \\sideeffect (or @sideeffect) in the documentation, which \n# will result in a user-defined paragraph with heading \"Side Effects:\". \n# You can put \\n's in the value part of an alias to insert newlines.\n\nALIASES                = \n\n# Set the OPTIMIZE_OUTPUT_FOR_C tag to YES if your project consists of C \n# sources only. Doxygen will then generate output that is more tailored for C. \n# For instance, some of the names that are used will be different. The list \n# of all members will be omitted, etc.\n\nOPTIMIZE_OUTPUT_FOR_C  = NO\n\n# Set the OPTIMIZE_OUTPUT_JAVA tag to YES if your project consists of Java \n# sources only. Doxygen will then generate output that is more tailored for \n# Java. For instance, namespaces will be presented as packages, qualified \n# scopes will look different, etc.\n\nOPTIMIZE_OUTPUT_JAVA   = NO\n\n# Set the OPTIMIZE_FOR_FORTRAN tag to YES if your project consists of Fortran \n# sources only. Doxygen will then generate output that is more tailored for \n# Fortran.\n\nOPTIMIZE_FOR_FORTRAN   = NO\n\n# Set the OPTIMIZE_OUTPUT_VHDL tag to YES if your project consists of VHDL \n# sources. Doxygen will then generate output that is tailored for \n# VHDL.\n\nOPTIMIZE_OUTPUT_VHDL   = NO\n\n# Doxygen selects the parser to use depending on the extension of the files it parses. \n# With this tag you can assign which parser to use for a given extension. \n# Doxygen has a built-in mapping, but you can override or extend it using this tag. \n# The format is ext=language, where ext is a file extension, and language is one of \n# the parsers supported by doxygen: IDL, Java, Javascript, C#, C, C++, D, PHP, \n# Objective-C, Python, Fortran, VHDL, C, C++. For instance to make doxygen treat \n# .inc files as Fortran files (default is PHP), and .f files as C (default is Fortran), \n# use: inc=Fortran f=C\n\nEXTENSION_MAPPING      = \n\n# If you use STL classes (i.e. std::string, std::vector, etc.) but do not want \n# to include (a tag file for) the STL sources as input, then you should \n# set this tag to YES in order to let doxygen match functions declarations and \n# definitions whose arguments contain STL classes (e.g. func(std::string); v.s. \n# func(std::string) {}). This also make the inheritance and collaboration \n# diagrams that involve STL classes more complete and accurate.\n\nBUILTIN_STL_SUPPORT    = NO\n\n# If you use Microsoft's C++/CLI language, you should set this option to YES to \n# enable parsing support.\n\nCPP_CLI_SUPPORT        = NO\n\n# Set the SIP_SUPPORT tag to YES if your project consists of sip sources only. \n# Doxygen will parse them like normal C++ but will assume all classes use public \n# instead of private inheritance when no explicit protection keyword is present.\n\nSIP_SUPPORT            = NO\n\n# For Microsoft's IDL there are propget and propput attributes to indicate getter \n# and setter methods for a property. Setting this option to YES (the default) \n# will make doxygen to replace the get and set methods by a property in the \n# documentation. This will only work if the methods are indeed getting or \n# setting a simple type. If this is not the case, or you want to show the \n# methods anyway, you should set this option to NO.\n\nIDL_PROPERTY_SUPPORT   = YES\n\n# If member grouping is used in the documentation and the DISTRIBUTE_GROUP_DOC \n# tag is set to YES, then doxygen will reuse the documentation of the first \n# member in the group (if any) for the other members of the group. By default \n# all members of a group must be documented explicitly.\n\nDISTRIBUTE_GROUP_DOC   = NO\n\n# Set the SUBGROUPING tag to YES (the default) to allow class member groups of \n# the same type (for instance a group of public functions) to be put as a \n# subgroup of that type (e.g. under the Public Functions section). Set it to \n# NO to prevent subgrouping. Alternatively, this can be done per class using \n# the \\nosubgrouping command.\n\nSUBGROUPING            = YES\n\n# When TYPEDEF_HIDES_STRUCT is enabled, a typedef of a struct, union, or enum \n# is documented as struct, union, or enum with the name of the typedef. So \n# typedef struct TypeS {} TypeT, will appear in the documentation as a struct \n# with name TypeT. When disabled the typedef will appear as a member of a file, \n# namespace, or class. And the struct will be named TypeS. This can typically \n# be useful for C code in case the coding convention dictates that all compound \n# types are typedef'ed and only the typedef is referenced, never the tag name.\n\nTYPEDEF_HIDES_STRUCT   = NO\n\n# The SYMBOL_CACHE_SIZE determines the size of the internal cache use to \n# determine which symbols to keep in memory and which to flush to disk. \n# When the cache is full, less often used symbols will be written to disk. \n# For small to medium size projects (<1000 input files) the default value is \n# probably good enough. For larger projects a too small cache size can cause \n# doxygen to be busy swapping symbols to and from disk most of the time \n# causing a significant performance penality. \n# If the system has enough physical memory increasing the cache will improve the \n# performance by keeping more symbols in memory. Note that the value works on \n# a logarithmic scale so increasing the size by one will roughly double the \n# memory usage. The cache size is given by this formula: \n# 2^(16+SYMBOL_CACHE_SIZE). The valid range is 0..9, the default is 0, \n# corresponding to a cache size of 2^16 = 65536 symbols\n\nSYMBOL_CACHE_SIZE      = 0\n\n#---------------------------------------------------------------------------\n# Build related configuration options\n#---------------------------------------------------------------------------\n\n# If the EXTRACT_ALL tag is set to YES doxygen will assume all entities in \n# documentation are documented, even if no documentation was available. \n# Private class members and static file members will be hidden unless \n# the EXTRACT_PRIVATE and EXTRACT_STATIC tags are set to YES\n\nEXTRACT_ALL            = NO\n\n# If the EXTRACT_PRIVATE tag is set to YES all private members of a class \n# will be included in the documentation.\n\nEXTRACT_PRIVATE        = NO\n\n# If the EXTRACT_STATIC tag is set to YES all static members of a file \n# will be included in the documentation.\n\nEXTRACT_STATIC         = NO\n\n# If the EXTRACT_LOCAL_CLASSES tag is set to YES classes (and structs) \n# defined locally in source files will be included in the documentation. \n# If set to NO only classes defined in header files are included.\n\nEXTRACT_LOCAL_CLASSES  = YES\n\n# This flag is only useful for Objective-C code. When set to YES local \n# methods, which are defined in the implementation section but not in \n# the interface are included in the documentation. \n# If set to NO (the default) only methods in the interface are included.\n\nEXTRACT_LOCAL_METHODS  = NO\n\n# If this flag is set to YES, the members of anonymous namespaces will be \n# extracted and appear in the documentation as a namespace called \n# 'anonymous_namespace{file}', where file will be replaced with the base \n# name of the file that contains the anonymous namespace. By default \n# anonymous namespace are hidden.\n\nEXTRACT_ANON_NSPACES   = NO\n\n# If the HIDE_UNDOC_MEMBERS tag is set to YES, Doxygen will hide all \n# undocumented members of documented classes, files or namespaces. \n# If set to NO (the default) these members will be included in the \n# various overviews, but no documentation section is generated. \n# This option has no effect if EXTRACT_ALL is enabled.\n\nHIDE_UNDOC_MEMBERS     = NO\n\n# If the HIDE_UNDOC_CLASSES tag is set to YES, Doxygen will hide all \n# undocumented classes that are normally visible in the class hierarchy. \n# If set to NO (the default) these classes will be included in the various \n# overviews. This option has no effect if EXTRACT_ALL is enabled.\n\nHIDE_UNDOC_CLASSES     = NO\n\n# If the HIDE_FRIEND_COMPOUNDS tag is set to YES, Doxygen will hide all \n# friend (class|struct|union) declarations. \n# If set to NO (the default) these declarations will be included in the \n# documentation.\n\nHIDE_FRIEND_COMPOUNDS  = NO\n\n# If the HIDE_IN_BODY_DOCS tag is set to YES, Doxygen will hide any \n# documentation blocks found inside the body of a function. \n# If set to NO (the default) these blocks will be appended to the \n# function's detailed documentation block.\n\nHIDE_IN_BODY_DOCS      = NO\n\n# The INTERNAL_DOCS tag determines if documentation \n# that is typed after a \\internal command is included. If the tag is set \n# to NO (the default) then the documentation will be excluded. \n# Set it to YES to include the internal documentation.\n\nINTERNAL_DOCS          = NO\n\n# If the CASE_SENSE_NAMES tag is set to NO then Doxygen will only generate \n# file names in lower-case letters. If set to YES upper-case letters are also \n# allowed. This is useful if you have classes or files whose names only differ \n# in case and if your file system supports case sensitive file names. Windows \n# and Mac users are advised to set this option to NO.\n\nCASE_SENSE_NAMES       = YES\n\n# If the HIDE_SCOPE_NAMES tag is set to NO (the default) then Doxygen \n# will show members with their full class and namespace scopes in the \n# documentation. If set to YES the scope will be hidden.\n\nHIDE_SCOPE_NAMES       = NO\n\n# If the SHOW_INCLUDE_FILES tag is set to YES (the default) then Doxygen \n# will put a list of the files that are included by a file in the documentation \n# of that file.\n\nSHOW_INCLUDE_FILES     = YES\n\n# If the INLINE_INFO tag is set to YES (the default) then a tag [inline] \n# is inserted in the documentation for inline members.\n\nINLINE_INFO            = YES\n\n# If the SORT_MEMBER_DOCS tag is set to YES (the default) then doxygen \n# will sort the (detailed) documentation of file and class members \n# alphabetically by member name. If set to NO the members will appear in \n# declaration order.\n\nSORT_MEMBER_DOCS       = YES\n\n# If the SORT_BRIEF_DOCS tag is set to YES then doxygen will sort the \n# brief documentation of file, namespace and class members alphabetically \n# by member name. If set to NO (the default) the members will appear in \n# declaration order.\n\nSORT_BRIEF_DOCS        = NO\n\n# If the SORT_GROUP_NAMES tag is set to YES then doxygen will sort the \n# hierarchy of group names into alphabetical order. If set to NO (the default) \n# the group names will appear in their defined order.\n\nSORT_GROUP_NAMES       = NO\n\n# If the SORT_BY_SCOPE_NAME tag is set to YES, the class list will be \n# sorted by fully-qualified names, including namespaces. If set to \n# NO (the default), the class list will be sorted only by class name, \n# not including the namespace part. \n# Note: This option is not very useful if HIDE_SCOPE_NAMES is set to YES. \n# Note: This option applies only to the class list, not to the \n# alphabetical list.\n\nSORT_BY_SCOPE_NAME     = NO\n\n# The GENERATE_TODOLIST tag can be used to enable (YES) or \n# disable (NO) the todo list. This list is created by putting \\todo \n# commands in the documentation.\n\nGENERATE_TODOLIST      = YES\n\n# The GENERATE_TESTLIST tag can be used to enable (YES) or \n# disable (NO) the test list. This list is created by putting \\test \n# commands in the documentation.\n\nGENERATE_TESTLIST      = YES\n\n# The GENERATE_BUGLIST tag can be used to enable (YES) or \n# disable (NO) the bug list. This list is created by putting \\bug \n# commands in the documentation.\n\nGENERATE_BUGLIST       = YES\n\n# The GENERATE_DEPRECATEDLIST tag can be used to enable (YES) or \n# disable (NO) the deprecated list. This list is created by putting \n# \\deprecated commands in the documentation.\n\nGENERATE_DEPRECATEDLIST= YES\n\n# The ENABLED_SECTIONS tag can be used to enable conditional \n# documentation sections, marked by \\if sectionname ... \\endif.\n\nENABLED_SECTIONS       = \n\n# The MAX_INITIALIZER_LINES tag determines the maximum number of lines \n# the initial value of a variable or define consists of for it to appear in \n# the documentation. If the initializer consists of more lines than specified \n# here it will be hidden. Use a value of 0 to hide initializers completely. \n# The appearance of the initializer of individual variables and defines in the \n# documentation can be controlled using \\showinitializer or \\hideinitializer \n# command in the documentation regardless of this setting.\n\nMAX_INITIALIZER_LINES  = 30\n\n# Set the SHOW_USED_FILES tag to NO to disable the list of files generated \n# at the bottom of the documentation of classes and structs. If set to YES the \n# list will mention the files that were used to generate the documentation.\n\nSHOW_USED_FILES        = YES\n\n# If the sources in your project are distributed over multiple directories \n# then setting the SHOW_DIRECTORIES tag to YES will show the directory hierarchy \n# in the documentation. The default is NO.\n\nSHOW_DIRECTORIES       = NO\n\n# Set the SHOW_FILES tag to NO to disable the generation of the Files page. \n# This will remove the Files entry from the Quick Index and from the \n# Folder Tree View (if specified). The default is YES.\n\nSHOW_FILES             = YES\n\n# Set the SHOW_NAMESPACES tag to NO to disable the generation of the \n# Namespaces page. \n# This will remove the Namespaces entry from the Quick Index \n# and from the Folder Tree View (if specified). The default is YES.\n\nSHOW_NAMESPACES        = YES\n\n# The FILE_VERSION_FILTER tag can be used to specify a program or script that \n# doxygen should invoke to get the current version for each file (typically from \n# the version control system). Doxygen will invoke the program by executing (via \n# popen()) the command <command> <input-file>, where <command> is the value of \n# the FILE_VERSION_FILTER tag, and <input-file> is the name of an input file \n# provided by doxygen. Whatever the program writes to standard output \n# is used as the file version. See the manual for examples.\n\nFILE_VERSION_FILTER    = \n\n# The LAYOUT_FILE tag can be used to specify a layout file which will be parsed by \n# doxygen. The layout file controls the global structure of the generated output files \n# in an output format independent way. The create the layout file that represents \n# doxygen's defaults, run doxygen with the -l option. You can optionally specify a \n# file name after the option, if omitted DoxygenLayout.xml will be used as the name \n# of the layout file.\n\nLAYOUT_FILE            = \n\n#---------------------------------------------------------------------------\n# configuration options related to warning and progress messages\n#---------------------------------------------------------------------------\n\n# The QUIET tag can be used to turn on/off the messages that are generated \n# by doxygen. Possible values are YES and NO. If left blank NO is used.\n\nQUIET                  = YES\n\n# The WARNINGS tag can be used to turn on/off the warning messages that are \n# generated by doxygen. Possible values are YES and NO. If left blank \n# NO is used.\n\nWARNINGS               = YES\n\n# If WARN_IF_UNDOCUMENTED is set to YES, then doxygen will generate warnings \n# for undocumented members. If EXTRACT_ALL is set to YES then this flag will \n# automatically be disabled.\n\nWARN_IF_UNDOCUMENTED   = YES\n\n# If WARN_IF_DOC_ERROR is set to YES, doxygen will generate warnings for \n# potential errors in the documentation, such as not documenting some \n# parameters in a documented function, or documenting parameters that \n# don't exist or using markup commands wrongly.\n\nWARN_IF_DOC_ERROR      = YES\n\n# This WARN_NO_PARAMDOC option can be abled to get warnings for \n# functions that are documented, but have no documentation for their parameters \n# or return value. If set to NO (the default) doxygen will only warn about \n# wrong or incomplete parameter documentation, but not about the absence of \n# documentation.\n\nWARN_NO_PARAMDOC       = NO\n\n# The WARN_FORMAT tag determines the format of the warning messages that \n# doxygen can produce. The string should contain the $file, $line, and $text \n# tags, which will be replaced by the file and line number from which the \n# warning originated and the warning text. Optionally the format may contain \n# $version, which will be replaced by the version of the file (if it could \n# be obtained via FILE_VERSION_FILTER)\n\nWARN_FORMAT            = \"$file:$line: $text\"\n\n# The WARN_LOGFILE tag can be used to specify a file to which warning \n# and error messages should be written. If left blank the output is written \n# to stderr.\n\nWARN_LOGFILE           = \n\n#---------------------------------------------------------------------------\n# configuration options related to the input files\n#---------------------------------------------------------------------------\n\n# The INPUT tag can be used to specify the files and/or directories that contain \n# documented source files. You may enter file names like \"myfile.cpp\" or \n# directories like \"/usr/src/myproject\". Separate the files or directories \n# with spaces.\n\nINPUT                  = @DOXYFILE_SOURCE_DIRS@\n\n# This tag can be used to specify the character encoding of the source files \n# that doxygen parses. Internally doxygen uses the UTF-8 encoding, which is \n# also the default input encoding. Doxygen uses libiconv (or the iconv built \n# into libc) for the transcoding. See http://www.gnu.org/software/libiconv for \n# the list of possible encodings.\n\nINPUT_ENCODING         = UTF-8\n\n# If the value of the INPUT tag contains directories, you can use the \n# FILE_PATTERNS tag to specify one or more wildcard pattern (like *.cpp \n# and *.h) to filter out the source-files in the directories. If left \n# blank the following patterns are tested: \n# *.c *.cc *.cxx *.cpp *.c++ *.java *.ii *.ixx *.ipp *.i++ *.inl *.h *.hh *.hxx \n# *.hpp *.h++ *.idl *.odl *.cs *.php *.php3 *.inc *.m *.mm *.py *.f90\n\nFILE_PATTERNS          = \n\n# The RECURSIVE tag can be used to turn specify whether or not subdirectories \n# should be searched for input files as well. Possible values are YES and NO. \n# If left blank NO is used.\n\nRECURSIVE              = YES\n\n# The EXCLUDE tag can be used to specify files and/or directories that should \n# excluded from the INPUT source files. This way you can easily exclude a \n# subdirectory from a directory tree whose root is specified with the INPUT tag.\n\nEXCLUDE                = \"_darcs\"\n\n# The EXCLUDE_SYMLINKS tag can be used select whether or not files or \n# directories that are symbolic links (a Unix filesystem feature) are excluded \n# from the input.\n\nEXCLUDE_SYMLINKS       = NO\n\n# If the value of the INPUT tag contains directories, you can use the \n# EXCLUDE_PATTERNS tag to specify one or more wildcard patterns to exclude \n# certain files from those directories. Note that the wildcards are matched \n# against the file with absolute path, so to exclude all test directories \n# for example use the pattern */test/*\n\nEXCLUDE_PATTERNS       = \"*/.*\" \"*/.*/*\"\n\n# The EXCLUDE_SYMBOLS tag can be used to specify one or more symbol names \n# (namespaces, classes, functions, etc.) that should be excluded from the \n# output. The symbol name can be a fully qualified name, a word, or if the \n# wildcard * is used, a substring. Examples: ANamespace, AClass, \n# AClass::ANamespace, ANamespace::*Test\n\nEXCLUDE_SYMBOLS        = \n\n# The EXAMPLE_PATH tag can be used to specify one or more files or \n# directories that contain example code fragments that are included (see \n# the \\include command).\n\nEXAMPLE_PATH           = \"@CMAKE_CURRENT_SOURCE_DIR@/examples\"\n\n# If the value of the EXAMPLE_PATH tag contains directories, you can use the \n# EXAMPLE_PATTERNS tag to specify one or more wildcard pattern (like *.cpp \n# and *.h) to filter out the source-files in the directories. If left \n# blank all files are included.\n\nEXAMPLE_PATTERNS       = \n\n# If the EXAMPLE_RECURSIVE tag is set to YES then subdirectories will be \n# searched for input files to be used with the \\include or \\dontinclude \n# commands irrespective of the value of the RECURSIVE tag. \n# Possible values are YES and NO. If left blank NO is used.\n\nEXAMPLE_RECURSIVE      = NO\n\n# The IMAGE_PATH tag can be used to specify one or more files or \n# directories that contain image that are included in the documentation (see \n# the \\image command).\n\nIMAGE_PATH             = \"@CMAKE_CURRENT_SOURCE_DIR@\"\n\n# The INPUT_FILTER tag can be used to specify a program that doxygen should \n# invoke to filter for each input file. Doxygen will invoke the filter program \n# by executing (via popen()) the command <filter> <input-file>, where <filter> \n# is the value of the INPUT_FILTER tag, and <input-file> is the name of an \n# input file. Doxygen will then use the output that the filter program writes \n# to standard output. \n# If FILTER_PATTERNS is specified, this tag will be \n# ignored.\n\nINPUT_FILTER           = \n\n# The FILTER_PATTERNS tag can be used to specify filters on a per file pattern \n# basis. \n# Doxygen will compare the file name with each pattern and apply the \n# filter if there is a match. \n# The filters are a list of the form: \n# pattern=filter (like *.cpp=my_cpp_filter). See INPUT_FILTER for further \n# info on how filters are used. If FILTER_PATTERNS is empty, INPUT_FILTER \n# is applied to all files.\n\nFILTER_PATTERNS        = \n\n# If the FILTER_SOURCE_FILES tag is set to YES, the input filter (if set using \n# INPUT_FILTER) will be used to filter the input files when producing source \n# files to browse (i.e. when SOURCE_BROWSER is set to YES).\n\nFILTER_SOURCE_FILES    = NO\n\n#---------------------------------------------------------------------------\n# configuration options related to source browsing\n#---------------------------------------------------------------------------\n\n# If the SOURCE_BROWSER tag is set to YES then a list of source files will \n# be generated. Documented entities will be cross-referenced with these sources. \n# Note: To get rid of all source code in the generated output, make sure also \n# VERBATIM_HEADERS is set to NO.\n\nSOURCE_BROWSER         = NO\n\n# Setting the INLINE_SOURCES tag to YES will include the body \n# of functions and classes directly in the documentation.\n\nINLINE_SOURCES         = NO\n\n# Setting the STRIP_CODE_COMMENTS tag to YES (the default) will instruct \n# doxygen to hide any special comment blocks from generated source code \n# fragments. Normal C and C++ comments will always remain visible.\n\nSTRIP_CODE_COMMENTS    = YES\n\n# If the REFERENCED_BY_RELATION tag is set to YES \n# then for each documented function all documented \n# functions referencing it will be listed.\n\nREFERENCED_BY_RELATION = NO\n\n# If the REFERENCES_RELATION tag is set to YES \n# then for each documented function all documented entities \n# called/used by that function will be listed.\n\nREFERENCES_RELATION    = NO\n\n# If the REFERENCES_LINK_SOURCE tag is set to YES (the default) \n# and SOURCE_BROWSER tag is set to YES, then the hyperlinks from \n# functions in REFERENCES_RELATION and REFERENCED_BY_RELATION lists will \n# link to the source code. \n# Otherwise they will link to the documentation.\n\nREFERENCES_LINK_SOURCE = YES\n\n# If the USE_HTAGS tag is set to YES then the references to source code \n# will point to the HTML generated by the htags(1) tool instead of doxygen \n# built-in source browser. The htags tool is part of GNU's global source \n# tagging system (see http://www.gnu.org/software/global/global.html). You \n# will need version 4.8.6 or higher.\n\nUSE_HTAGS              = NO\n\n# If the VERBATIM_HEADERS tag is set to YES (the default) then Doxygen \n# will generate a verbatim copy of the header file for each class for \n# which an include is specified. Set to NO to disable this.\n\nVERBATIM_HEADERS       = YES\n\n#---------------------------------------------------------------------------\n# configuration options related to the alphabetical class index\n#---------------------------------------------------------------------------\n\n# If the ALPHABETICAL_INDEX tag is set to YES, an alphabetical index \n# of all compounds will be generated. Enable this if the project \n# contains a lot of classes, structs, unions or interfaces.\n\nALPHABETICAL_INDEX     = NO\n\n# If the alphabetical index is enabled (see ALPHABETICAL_INDEX) then \n# the COLS_IN_ALPHA_INDEX tag can be used to specify the number of columns \n# in which this list will be split (can be a number in the range [1..20])\n\nCOLS_IN_ALPHA_INDEX    = 5\n\n# In case all classes in a project start with a common prefix, all \n# classes will be put under the same header in the alphabetical index. \n# The IGNORE_PREFIX tag can be used to specify one or more prefixes that \n# should be ignored while generating the index headers.\n\nIGNORE_PREFIX          = \n\n#---------------------------------------------------------------------------\n# configuration options related to the HTML output\n#---------------------------------------------------------------------------\n\n# If the GENERATE_HTML tag is set to YES (the default) Doxygen will \n# generate HTML output.\n\nGENERATE_HTML          = YES\n\n# The HTML_OUTPUT tag is used to specify where the HTML docs will be put. \n# If a relative path is entered the value of OUTPUT_DIRECTORY will be \n# put in front of it. If left blank `html' will be used as the default path.\n\nHTML_OUTPUT            = \"@DOXYFILE_HTML_DIR@\"\n\n# The HTML_FILE_EXTENSION tag can be used to specify the file extension for \n# each generated HTML page (for example: .htm,.php,.asp). If it is left blank \n# doxygen will generate files with .html extension.\n\nHTML_FILE_EXTENSION    = .html\n\n# The HTML_HEADER tag can be used to specify a personal HTML header for \n# each generated HTML page. If it is left blank doxygen will generate a \n# standard header.\n\nHTML_HEADER            = \n\n# The HTML_FOOTER tag can be used to specify a personal HTML footer for \n# each generated HTML page. If it is left blank doxygen will generate a \n# standard footer.\n\nHTML_FOOTER            = \n\n# The HTML_STYLESHEET tag can be used to specify a user-defined cascading \n# style sheet that is used by each HTML page. It can be used to \n# fine-tune the look of the HTML output. If the tag is left blank doxygen \n# will generate a default style sheet. Note that doxygen will try to copy \n# the style sheet file to the HTML output directory, so don't put your own \n# stylesheet in the HTML output directory as well, or it will be erased!\n\nHTML_STYLESHEET        = \n\n# If the HTML_ALIGN_MEMBERS tag is set to YES, the members of classes, \n# files or namespaces will be aligned in HTML using tables. If set to \n# NO a bullet list will be used.\n\nHTML_ALIGN_MEMBERS     = YES\n\n# If the HTML_DYNAMIC_SECTIONS tag is set to YES then the generated HTML \n# documentation will contain sections that can be hidden and shown after the \n# page has loaded. For this to work a browser that supports \n# JavaScript and DHTML is required (for instance Mozilla 1.0+, Firefox \n# Netscape 6.0+, Internet explorer 5.0+, Konqueror, or Safari).\n\nHTML_DYNAMIC_SECTIONS  = NO\n\n# If the GENERATE_DOCSET tag is set to YES, additional index files \n# will be generated that can be used as input for Apple's Xcode 3 \n# integrated development environment, introduced with OSX 10.5 (Leopard). \n# To create a documentation set, doxygen will generate a Makefile in the \n# HTML output directory. Running make will produce the docset in that \n# directory and running \"make install\" will install the docset in \n# ~/Library/Developer/Shared/Documentation/DocSets so that Xcode will find \n# it at startup. \n# See http://developer.apple.com/tools/creatingdocsetswithdoxygen.html for more information.\n\nGENERATE_DOCSET        = NO\n\n# When GENERATE_DOCSET tag is set to YES, this tag determines the name of the \n# feed. A documentation feed provides an umbrella under which multiple \n# documentation sets from a single provider (such as a company or product suite) \n# can be grouped.\n\nDOCSET_FEEDNAME        = \"Doxygen generated docs\"\n\n# When GENERATE_DOCSET tag is set to YES, this tag specifies a string that \n# should uniquely identify the documentation set bundle. This should be a \n# reverse domain-name style string, e.g. com.mycompany.MyDocSet. Doxygen \n# will append .docset to the name.\n\nDOCSET_BUNDLE_ID       = org.doxygen.Project\n\n# If the GENERATE_HTMLHELP tag is set to YES, additional index files \n# will be generated that can be used as input for tools like the \n# Microsoft HTML help workshop to generate a compiled HTML help file (.chm) \n# of the generated HTML documentation.\n\nGENERATE_HTMLHELP      = NO\n\n# If the GENERATE_HTMLHELP tag is set to YES, the CHM_FILE tag can \n# be used to specify the file name of the resulting .chm file. You \n# can add a path in front of the file if the result should not be \n# written to the html output directory.\n\nCHM_FILE               = \n\n# If the GENERATE_HTMLHELP tag is set to YES, the HHC_LOCATION tag can \n# be used to specify the location (absolute path including file name) of \n# the HTML help compiler (hhc.exe). If non-empty doxygen will try to run \n# the HTML help compiler on the generated index.hhp.\n\nHHC_LOCATION           = \n\n# If the GENERATE_HTMLHELP tag is set to YES, the GENERATE_CHI flag \n# controls if a separate .chi index file is generated (YES) or that \n# it should be included in the master .chm file (NO).\n\nGENERATE_CHI           = NO\n\n# If the GENERATE_HTMLHELP tag is set to YES, the CHM_INDEX_ENCODING \n# is used to encode HtmlHelp index (hhk), content (hhc) and project file \n# content.\n\nCHM_INDEX_ENCODING     = \n\n# If the GENERATE_HTMLHELP tag is set to YES, the BINARY_TOC flag \n# controls whether a binary table of contents is generated (YES) or a \n# normal table of contents (NO) in the .chm file.\n\nBINARY_TOC             = NO\n\n# The TOC_EXPAND flag can be set to YES to add extra items for group members \n# to the contents of the HTML help documentation and to the tree view.\n\nTOC_EXPAND             = NO\n\n# If the GENERATE_QHP tag is set to YES and both QHP_NAMESPACE and QHP_VIRTUAL_FOLDER \n# are set, an additional index file will be generated that can be used as input for \n# Qt's qhelpgenerator to generate a Qt Compressed Help (.qch) of the generated \n# HTML documentation.\n\nGENERATE_QHP           = NO\n\n# If the QHG_LOCATION tag is specified, the QCH_FILE tag can \n# be used to specify the file name of the resulting .qch file. \n# The path specified is relative to the HTML output folder.\n\nQCH_FILE               = \n\n# The QHP_NAMESPACE tag specifies the namespace to use when generating \n# Qt Help Project output. For more information please see \n# http://doc.trolltech.com/qthelpproject.html#namespace\n\nQHP_NAMESPACE          = \n\n# The QHP_VIRTUAL_FOLDER tag specifies the namespace to use when generating \n# Qt Help Project output. For more information please see \n# http://doc.trolltech.com/qthelpproject.html#virtual-folders\n\nQHP_VIRTUAL_FOLDER     = doc\n\n# If QHP_CUST_FILTER_NAME is set, it specifies the name of a custom filter to add. \n# For more information please see \n# http://doc.trolltech.com/qthelpproject.html#custom-filters\n\nQHP_CUST_FILTER_NAME   = \n\n# The QHP_CUST_FILT_ATTRS tag specifies the list of the attributes of the custom filter to add.For more information please see \n# <a href=\"http://doc.trolltech.com/qthelpproject.html#custom-filters\">Qt Help Project / Custom Filters</a>.\n\nQHP_CUST_FILTER_ATTRS  = \n\n# The QHP_SECT_FILTER_ATTRS tag specifies the list of the attributes this project's \n# filter section matches. \n# <a href=\"http://doc.trolltech.com/qthelpproject.html#filter-attributes\">Qt Help Project / Filter Attributes</a>.\n\nQHP_SECT_FILTER_ATTRS  = \n\n# If the GENERATE_QHP tag is set to YES, the QHG_LOCATION tag can \n# be used to specify the location of Qt's qhelpgenerator. \n# If non-empty doxygen will try to run qhelpgenerator on the generated \n# .qhp file.\n\nQHG_LOCATION           = \n\n# The DISABLE_INDEX tag can be used to turn on/off the condensed index at \n# top of each HTML page. The value NO (the default) enables the index and \n# the value YES disables it.\n\nDISABLE_INDEX          = NO\n\n# This tag can be used to set the number of enum values (range [1..20]) \n# that doxygen will group on one line in the generated HTML documentation.\n\nENUM_VALUES_PER_LINE   = 4\n\n# The GENERATE_TREEVIEW tag is used to specify whether a tree-like index \n# structure should be generated to display hierarchical information. \n# If the tag value is set to FRAME, a side panel will be generated \n# containing a tree-like index structure (just like the one that \n# is generated for HTML Help). For this to work a browser that supports \n# JavaScript, DHTML, CSS and frames is required (for instance Mozilla 1.0+, \n# Netscape 6.0+, Internet explorer 5.0+, or Konqueror). Windows users are \n# probably better off using the HTML help feature. Other possible values \n# for this tag are: HIERARCHIES, which will generate the Groups, Directories, \n# and Class Hierarchy pages using a tree view instead of an ordered list; \n# ALL, which combines the behavior of FRAME and HIERARCHIES; and NONE, which \n# disables this behavior completely. For backwards compatibility with previous \n# releases of Doxygen, the values YES and NO are equivalent to FRAME and NONE \n# respectively.\n\nGENERATE_TREEVIEW      = NONE\n\n# If the treeview is enabled (see GENERATE_TREEVIEW) then this tag can be \n# used to set the initial width (in pixels) of the frame in which the tree \n# is shown.\n\nTREEVIEW_WIDTH         = 250\n\n# Use this tag to change the font size of Latex formulas included \n# as images in the HTML documentation. The default is 10. Note that \n# when you change the font size after a successful doxygen run you need \n# to manually remove any form_*.png images from the HTML output directory \n# to force them to be regenerated.\n\nFORMULA_FONTSIZE       = 10\n\n#---------------------------------------------------------------------------\n# configuration options related to the LaTeX output\n#---------------------------------------------------------------------------\n\n# If the GENERATE_LATEX tag is set to YES (the default) Doxygen will \n# generate Latex output.\n\nGENERATE_LATEX         = @DOXYFILE_GENERATE_LATEX@\n\n# The LATEX_OUTPUT tag is used to specify where the LaTeX docs will be put. \n# If a relative path is entered the value of OUTPUT_DIRECTORY will be \n# put in front of it. If left blank `latex' will be used as the default path.\n\nLATEX_OUTPUT           = \"@DOXYFILE_LATEX_DIR@\"\n\n# The LATEX_CMD_NAME tag can be used to specify the LaTeX command name to be \n# invoked. If left blank `latex' will be used as the default command name.\n\nLATEX_CMD_NAME         = \"@LATEX_COMPILER@\"\n\n# The MAKEINDEX_CMD_NAME tag can be used to specify the command name to \n# generate index for LaTeX. If left blank `makeindex' will be used as the \n# default command name.\n\nMAKEINDEX_CMD_NAME     = \"@MAKEINDEX_COMPILER@\"\n\n# If the COMPACT_LATEX tag is set to YES Doxygen generates more compact \n# LaTeX documents. This may be useful for small projects and may help to \n# save some trees in general.\n\nCOMPACT_LATEX          = NO\n\n# The PAPER_TYPE tag can be used to set the paper type that is used \n# by the printer. Possible values are: a4, a4wide, letter, legal and \n# executive. If left blank a4wide will be used.\n\nPAPER_TYPE             = a4wide\n\n# The EXTRA_PACKAGES tag can be to specify one or more names of LaTeX \n# packages that should be included in the LaTeX output.\n\nEXTRA_PACKAGES         = \n\n# The LATEX_HEADER tag can be used to specify a personal LaTeX header for \n# the generated latex document. The header should contain everything until \n# the first chapter. If it is left blank doxygen will generate a \n# standard header. Notice: only use this tag if you know what you are doing!\n\nLATEX_HEADER           = \n\n# If the PDF_HYPERLINKS tag is set to YES, the LaTeX that is generated \n# is prepared for conversion to pdf (using ps2pdf). The pdf file will \n# contain links (just like the HTML output) instead of page references \n# This makes the output suitable for online browsing using a pdf viewer.\n\nPDF_HYPERLINKS         = YES\n\n# If the USE_PDFLATEX tag is set to YES, pdflatex will be used instead of \n# plain latex in the generated Makefile. Set this option to YES to get a \n# higher quality PDF documentation.\n\nUSE_PDFLATEX           = @DOXYFILE_PDFLATEX@\n\n# If the LATEX_BATCHMODE tag is set to YES, doxygen will add the \\\\batchmode. \n# command to the generated LaTeX files. This will instruct LaTeX to keep \n# running if errors occur, instead of asking the user for help. \n# This option is also used when generating formulas in HTML.\n\nLATEX_BATCHMODE        = YES\n\n# If LATEX_HIDE_INDICES is set to YES then doxygen will not \n# include the index chapters (such as File Index, Compound Index, etc.) \n# in the output.\n\nLATEX_HIDE_INDICES     = NO\n\n#---------------------------------------------------------------------------\n# configuration options related to the RTF output\n#---------------------------------------------------------------------------\n\n# If the GENERATE_RTF tag is set to YES Doxygen will generate RTF output \n# The RTF output is optimized for Word 97 and may not look very pretty with \n# other RTF readers or editors.\n\nGENERATE_RTF           = NO\n\n# The RTF_OUTPUT tag is used to specify where the RTF docs will be put. \n# If a relative path is entered the value of OUTPUT_DIRECTORY will be \n# put in front of it. If left blank `rtf' will be used as the default path.\n\nRTF_OUTPUT             = rtf\n\n# If the COMPACT_RTF tag is set to YES Doxygen generates more compact \n# RTF documents. This may be useful for small projects and may help to \n# save some trees in general.\n\nCOMPACT_RTF            = NO\n\n# If the RTF_HYPERLINKS tag is set to YES, the RTF that is generated \n# will contain hyperlink fields. The RTF file will \n# contain links (just like the HTML output) instead of page references. \n# This makes the output suitable for online browsing using WORD or other \n# programs which support those fields. \n# Note: wordpad (write) and others do not support links.\n\nRTF_HYPERLINKS         = NO\n\n# Load stylesheet definitions from file. Syntax is similar to doxygen's \n# config file, i.e. a series of assignments. You only have to provide \n# replacements, missing definitions are set to their default value.\n\nRTF_STYLESHEET_FILE    = \n\n# Set optional variables used in the generation of an rtf document. \n# Syntax is similar to doxygen's config file.\n\nRTF_EXTENSIONS_FILE    = \n\n#---------------------------------------------------------------------------\n# configuration options related to the man page output\n#---------------------------------------------------------------------------\n\n# If the GENERATE_MAN tag is set to YES (the default) Doxygen will \n# generate man pages\n\nGENERATE_MAN           = NO\n\n# The MAN_OUTPUT tag is used to specify where the man pages will be put. \n# If a relative path is entered the value of OUTPUT_DIRECTORY will be \n# put in front of it. If left blank `man' will be used as the default path.\n\nMAN_OUTPUT             = man\n\n# The MAN_EXTENSION tag determines the extension that is added to \n# the generated man pages (default is the subroutine's section .3)\n\nMAN_EXTENSION          = .3\n\n# If the MAN_LINKS tag is set to YES and Doxygen generates man output, \n# then it will generate one additional man file for each entity \n# documented in the real man page(s). These additional files \n# only source the real man page, but without them the man command \n# would be unable to find the correct page. The default is NO.\n\nMAN_LINKS              = NO\n\n#---------------------------------------------------------------------------\n# configuration options related to the XML output\n#---------------------------------------------------------------------------\n\n# If the GENERATE_XML tag is set to YES Doxygen will \n# generate an XML file that captures the structure of \n# the code including all documentation.\n\nGENERATE_XML           = NO\n\n# The XML_OUTPUT tag is used to specify where the XML pages will be put. \n# If a relative path is entered the value of OUTPUT_DIRECTORY will be \n# put in front of it. If left blank `xml' will be used as the default path.\n\nXML_OUTPUT             = xml\n\n# The XML_SCHEMA tag can be used to specify an XML schema, \n# which can be used by a validating XML parser to check the \n# syntax of the XML files.\n\nXML_SCHEMA             = \n\n# The XML_DTD tag can be used to specify an XML DTD, \n# which can be used by a validating XML parser to check the \n# syntax of the XML files.\n\nXML_DTD                = \n\n# If the XML_PROGRAMLISTING tag is set to YES Doxygen will \n# dump the program listings (including syntax highlighting \n# and cross-referencing information) to the XML output. Note that \n# enabling this will significantly increase the size of the XML output.\n\nXML_PROGRAMLISTING     = YES\n\n#---------------------------------------------------------------------------\n# configuration options for the AutoGen Definitions output\n#---------------------------------------------------------------------------\n\n# If the GENERATE_AUTOGEN_DEF tag is set to YES Doxygen will \n# generate an AutoGen Definitions (see autogen.sf.net) file \n# that captures the structure of the code including all \n# documentation. Note that this feature is still experimental \n# and incomplete at the moment.\n\nGENERATE_AUTOGEN_DEF   = NO\n\n#---------------------------------------------------------------------------\n# configuration options related to the Perl module output\n#---------------------------------------------------------------------------\n\n# If the GENERATE_PERLMOD tag is set to YES Doxygen will \n# generate a Perl module file that captures the structure of \n# the code including all documentation. Note that this \n# feature is still experimental and incomplete at the \n# moment.\n\nGENERATE_PERLMOD       = NO\n\n# If the PERLMOD_LATEX tag is set to YES Doxygen will generate \n# the necessary Makefile rules, Perl scripts and LaTeX code to be able \n# to generate PDF and DVI output from the Perl module output.\n\nPERLMOD_LATEX          = NO\n\n# If the PERLMOD_PRETTY tag is set to YES the Perl module output will be \n# nicely formatted so it can be parsed by a human reader. \n# This is useful \n# if you want to understand what is going on. \n# On the other hand, if this \n# tag is set to NO the size of the Perl module output will be much smaller \n# and Perl will parse it just the same.\n\nPERLMOD_PRETTY         = YES\n\n# The names of the make variables in the generated doxyrules.make file \n# are prefixed with the string contained in PERLMOD_MAKEVAR_PREFIX. \n# This is useful so different doxyrules.make files included by the same \n# Makefile don't overwrite each other's variables.\n\nPERLMOD_MAKEVAR_PREFIX = \n\n#---------------------------------------------------------------------------\n# Configuration options related to the preprocessor   \n#---------------------------------------------------------------------------\n\n# If the ENABLE_PREPROCESSING tag is set to YES (the default) Doxygen will \n# evaluate all C-preprocessor directives found in the sources and include \n# files.\n\nENABLE_PREPROCESSING   = YES\n\n# If the MACRO_EXPANSION tag is set to YES Doxygen will expand all macro \n# names in the source code. If set to NO (the default) only conditional \n# compilation will be performed. Macro expansion can be done in a controlled \n# way by setting EXPAND_ONLY_PREDEF to YES.\n\nMACRO_EXPANSION        = NO\n\n# If the EXPAND_ONLY_PREDEF and MACRO_EXPANSION tags are both set to YES \n# then the macro expansion is limited to the macros specified with the \n# PREDEFINED and EXPAND_AS_DEFINED tags.\n\nEXPAND_ONLY_PREDEF     = NO\n\n# If the SEARCH_INCLUDES tag is set to YES (the default) the includes files \n# in the INCLUDE_PATH (see below) will be search if a #include is found.\n\nSEARCH_INCLUDES        = YES\n\n# The INCLUDE_PATH tag can be used to specify one or more directories that \n# contain include files that are not input files but should be processed by \n# the preprocessor.\n\nINCLUDE_PATH           = \n\n# You can use the INCLUDE_FILE_PATTERNS tag to specify one or more wildcard \n# patterns (like *.h and *.hpp) to filter out the header-files in the \n# directories. If left blank, the patterns specified with FILE_PATTERNS will \n# be used.\n\nINCLUDE_FILE_PATTERNS  = \n\n# The PREDEFINED tag can be used to specify one or more macro names that \n# are defined before the preprocessor is started (similar to the -D option of \n# gcc). The argument of the tag is a list of macros of the form: name \n# or name=definition (no spaces). If the definition and the = are \n# omitted =1 is assumed. To prevent a macro definition from being \n# undefined via #undef or recursively expanded use the := operator \n# instead of the = operator.\n\nPREDEFINED             = \n\n# If the MACRO_EXPANSION and EXPAND_ONLY_PREDEF tags are set to YES then \n# this tag can be used to specify a list of macro names that should be expanded. \n# The macro definition that is found in the sources will be used. \n# Use the PREDEFINED tag if you want to use a different macro definition.\n\nEXPAND_AS_DEFINED      = \n\n# If the SKIP_FUNCTION_MACROS tag is set to YES (the default) then \n# doxygen's preprocessor will remove all function-like macros that are alone \n# on a line, have an all uppercase name, and do not end with a semicolon. Such \n# function macros are typically used for boiler-plate code, and will confuse \n# the parser if not removed.\n\nSKIP_FUNCTION_MACROS   = YES\n\n#---------------------------------------------------------------------------\n# Configuration::additions related to external references   \n#---------------------------------------------------------------------------\n\n# The TAGFILES option can be used to specify one or more tagfiles. \n# Optionally an initial location of the external documentation \n# can be added for each tagfile. The format of a tag file without \n# this location is as follows: \n#  \n# TAGFILES = file1 file2 ... \n# Adding location for the tag files is done as follows: \n#  \n# TAGFILES = file1=loc1 \"file2 = loc2\" ... \n# where \"loc1\" and \"loc2\" can be relative or absolute paths or \n# URLs. If a location is present for each tag, the installdox tool \n# does not have to be run to correct the links. \n# Note that each tag file must have a unique name \n# (where the name does NOT include the path) \n# If a tag file is not located in the directory in which doxygen \n# is run, you must also specify the path to the tagfile here.\n\nTAGFILES               = \n\n# When a file name is specified after GENERATE_TAGFILE, doxygen will create \n# a tag file that is based on the input files it reads.\n\nGENERATE_TAGFILE       = \n\n# If the ALLEXTERNALS tag is set to YES all external classes will be listed \n# in the class index. If set to NO only the inherited external classes \n# will be listed.\n\nALLEXTERNALS           = NO\n\n# If the EXTERNAL_GROUPS tag is set to YES all external groups will be listed \n# in the modules index. If set to NO, only the current project's groups will \n# be listed.\n\nEXTERNAL_GROUPS        = YES\n\n# The PERL_PATH should be the absolute path and name of the perl script \n# interpreter (i.e. the result of `which perl').\n\nPERL_PATH              = /usr/bin/perl\n\n#---------------------------------------------------------------------------\n# Configuration options related to the dot tool   \n#---------------------------------------------------------------------------\n\n# If the CLASS_DIAGRAMS tag is set to YES (the default) Doxygen will \n# generate a inheritance diagram (in HTML, RTF and LaTeX) for classes with base \n# or super classes. Setting the tag to NO turns the diagrams off. Note that \n# this option is superseded by the HAVE_DOT option below. This is only a \n# fallback. It is recommended to install and use dot, since it yields more \n# powerful graphs.\n\nCLASS_DIAGRAMS         = YES\n\n# You can define message sequence charts within doxygen comments using the \\msc \n# command. Doxygen will then run the mscgen tool (see \n# http://www.mcternan.me.uk/mscgen/) to produce the chart and insert it in the \n# documentation. The MSCGEN_PATH tag allows you to specify the directory where \n# the mscgen tool resides. If left empty the tool is assumed to be found in the \n# default search path.\n\nMSCGEN_PATH            = \n\n# If set to YES, the inheritance and collaboration graphs will hide \n# inheritance and usage relations if the target is undocumented \n# or is not a class.\n\nHIDE_UNDOC_RELATIONS   = YES\n\n# If you set the HAVE_DOT tag to YES then doxygen will assume the dot tool is \n# available from the path. This tool is part of Graphviz, a graph visualization \n# toolkit from AT&T and Lucent Bell Labs. The other options in this section \n# have no effect if this option is set to NO (the default)\n\nHAVE_DOT               = @DOXYFILE_DOT@\n\n# By default doxygen will write a font called FreeSans.ttf to the output \n# directory and reference it in all dot files that doxygen generates. This \n# font does not include all possible unicode characters however, so when you need \n# these (or just want a differently looking font) you can specify the font name \n# using DOT_FONTNAME. You need need to make sure dot is able to find the font, \n# which can be done by putting it in a standard location or by setting the \n# DOTFONTPATH environment variable or by setting DOT_FONTPATH to the directory \n# containing the font.\n\nDOT_FONTNAME           = FreeSans\n\n# The DOT_FONTSIZE tag can be used to set the size of the font of dot graphs. \n# The default size is 10pt.\n\nDOT_FONTSIZE           = 10\n\n# By default doxygen will tell dot to use the output directory to look for the \n# FreeSans.ttf font (which doxygen will put there itself). If you specify a \n# different font using DOT_FONTNAME you can set the path where dot \n# can find it using this tag.\n\nDOT_FONTPATH           = \n\n# If the CLASS_GRAPH and HAVE_DOT tags are set to YES then doxygen \n# will generate a graph for each documented class showing the direct and \n# indirect inheritance relations. Setting this tag to YES will force the \n# the CLASS_DIAGRAMS tag to NO.\n\nCLASS_GRAPH            = YES\n\n# If the COLLABORATION_GRAPH and HAVE_DOT tags are set to YES then doxygen \n# will generate a graph for each documented class showing the direct and \n# indirect implementation dependencies (inheritance, containment, and \n# class references variables) of the class with other documented classes.\n\nCOLLABORATION_GRAPH    = YES\n\n# If the GROUP_GRAPHS and HAVE_DOT tags are set to YES then doxygen \n# will generate a graph for groups, showing the direct groups dependencies\n\nGROUP_GRAPHS           = YES\n\n# If the UML_LOOK tag is set to YES doxygen will generate inheritance and \n# collaboration diagrams in a style similar to the OMG's Unified Modeling \n# Language.\n\nUML_LOOK               = NO\n\n# If set to YES, the inheritance and collaboration graphs will show the \n# relations between templates and their instances.\n\nTEMPLATE_RELATIONS     = NO\n\n# If the ENABLE_PREPROCESSING, SEARCH_INCLUDES, INCLUDE_GRAPH, and HAVE_DOT \n# tags are set to YES then doxygen will generate a graph for each documented \n# file showing the direct and indirect include dependencies of the file with \n# other documented files.\n\nINCLUDE_GRAPH          = YES\n\n# If the ENABLE_PREPROCESSING, SEARCH_INCLUDES, INCLUDED_BY_GRAPH, and \n# HAVE_DOT tags are set to YES then doxygen will generate a graph for each \n# documented header file showing the documented files that directly or \n# indirectly include this file.\n\nINCLUDED_BY_GRAPH      = YES\n\n# If the CALL_GRAPH and HAVE_DOT options are set to YES then \n# doxygen will generate a call dependency graph for every global function \n# or class method. Note that enabling this option will significantly increase \n# the time of a run. So in most cases it will be better to enable call graphs \n# for selected functions only using the \\callgraph command.\n\nCALL_GRAPH             = NO\n\n# If the CALLER_GRAPH and HAVE_DOT tags are set to YES then \n# doxygen will generate a caller dependency graph for every global function \n# or class method. Note that enabling this option will significantly increase \n# the time of a run. So in most cases it will be better to enable caller \n# graphs for selected functions only using the \\callergraph command.\n\nCALLER_GRAPH           = NO\n\n# If the GRAPHICAL_HIERARCHY and HAVE_DOT tags are set to YES then doxygen \n# will graphical hierarchy of all classes instead of a textual one.\n\nGRAPHICAL_HIERARCHY    = YES\n\n# If the DIRECTORY_GRAPH, SHOW_DIRECTORIES and HAVE_DOT tags are set to YES \n# then doxygen will show the dependencies a directory has on other directories \n# in a graphical way. The dependency relations are determined by the #include \n# relations between the files in the directories.\n\nDIRECTORY_GRAPH        = YES\n\n# The DOT_IMAGE_FORMAT tag can be used to set the image format of the images \n# generated by dot. Possible values are png, jpg, or gif \n# If left blank png will be used.\n\nDOT_IMAGE_FORMAT       = png\n\n# The tag DOT_PATH can be used to specify the path where the dot tool can be \n# found. If left blank, it is assumed the dot tool can be found in the path.\n\nDOT_PATH               = \"@DOXYGEN_DOT_PATH@\"\n\n# The DOTFILE_DIRS tag can be used to specify one or more directories that \n# contain dot files that are included in the documentation (see the \n# \\dotfile command).\n\nDOTFILE_DIRS           = \n\n# The DOT_GRAPH_MAX_NODES tag can be used to set the maximum number of \n# nodes that will be shown in the graph. If the number of nodes in a graph \n# becomes larger than this value, doxygen will truncate the graph, which is \n# visualized by representing a node as a red box. Note that doxygen if the \n# number of direct children of the root node in a graph is already larger than \n# DOT_GRAPH_MAX_NODES then the graph will not be shown at all. Also note \n# that the size of a graph can be further restricted by MAX_DOT_GRAPH_DEPTH.\n\nDOT_GRAPH_MAX_NODES    = 50\n\n# The MAX_DOT_GRAPH_DEPTH tag can be used to set the maximum depth of the \n# graphs generated by dot. A depth value of 3 means that only nodes reachable \n# from the root by following a path via at most 3 edges will be shown. Nodes \n# that lay further from the root node will be omitted. Note that setting this \n# option to 1 or 2 may greatly reduce the computation time needed for large \n# code bases. Also note that the size of a graph can be further restricted by \n# DOT_GRAPH_MAX_NODES. Using a depth of 0 means no depth restriction.\n\nMAX_DOT_GRAPH_DEPTH    = 0\n\n# Set the DOT_TRANSPARENT tag to YES to generate images with a transparent \n# background. This is disabled by default, because dot on Windows does not \n# seem to support this out of the box. Warning: Depending on the platform used, \n# enabling this option may lead to badly anti-aliased labels on the edges of \n# a graph (i.e. they become hard to read).\n\nDOT_TRANSPARENT        = YES\n\n# Set the DOT_MULTI_TARGETS tag to YES allow dot to generate multiple output \n# files in one run (i.e. multiple -o and -T options on the command line). This \n# makes dot run faster, but since only newer versions of dot (>1.8.10) \n# support this, this feature is disabled by default.\n\nDOT_MULTI_TARGETS      = NO\n\n# If the GENERATE_LEGEND tag is set to YES (the default) Doxygen will \n# generate a legend page explaining the meaning of the various boxes and \n# arrows in the dot generated graphs.\n\nGENERATE_LEGEND        = YES\n\n# If the DOT_CLEANUP tag is set to YES (the default) Doxygen will \n# remove the intermediate dot files that are used to generate \n# the various graphs.\n\nDOT_CLEANUP            = YES\n\n#---------------------------------------------------------------------------\n# Options related to the search engine\n#---------------------------------------------------------------------------\n\n# The SEARCHENGINE tag specifies whether or not a search engine should be \n# used. If set to NO the values of all tags below this one will be ignored.\n\nSEARCHENGINE           = NO\n"
        },
        {
          "name": "Makefile",
          "type": "blob",
          "size": 3.3662109375,
          "content": "ROOT = $(dir $(lastword $(MAKEFILE_LIST)))\n\nWAF_BINARY = $(realpath $(ROOT)/modules/waf/waf-light)\nWAF = python $(WAF_BINARY) $(WAF_FLAGS)\n\nEXPLICIT_COMMANDS = check check-all clean list_boards\n\nVEHICLES = copter plane rover sub heli\n\nBOARD_LIST := $(shell $(WAF) list_boards | head -1)\n\nall: help\n\n$(WAF_BINARY):\n\t@git submodule init && git submodule update\n\nwaf-%: $(WAF_BINARY)\n\t@$(WAF) $*\n\n%-configure: $(WAF_BINARY)\n\t@$(WAF) configure --board $*\n\n$(EXPLICIT_COMMANDS): $(WAF_BINARY)\n\t@$(WAF) $@\n\n$(VEHICLES): $(WAF_BINARY)\n\t@echo Build for vehicle $@\n\t@$(WAF) $@\n\n.DEFAULT: %-configure\n\t@$(WAF) configure --board $@ build\n\ndefine target_template\n$(1)-$(2) : $(1)-configure $(2)\nendef\n\n$(foreach board,$(BOARD_LIST),$(foreach vehicle,$(VEHICLES),$(eval $(call target_template,$(board),$(vehicle)))))\n\nhelp:\n\t@echo \"Ardupilot Building\"\n\t@echo \"==================\"\n\t@echo \"This is a make wrapper for Ardupilot's Waf build system. This wrapper is\"\n\t@echo \"intended to provide convenience for basic and common build tasks. If you need\"\n\t@echo \"more than what this wrapper provides, it's a good idea to use waf directly.\"\n\t@echo \"The waf executable is at '$(WAF_BINARY)'.\"\n\t@echo \"\"\n\t@echo \"For more detailed instructions see https://ardupilot.org/dev/docs/building-the-code.html\"\n\t@echo \"\"\n\t@echo \"Boards\"\n\t@echo \"------\"\n\t@echo \"\"\n\t@echo \"In order to trigger the build for a board/platform, the name of the board is\"\n\t@echo \"used as the target. Example: make linux\"\n\t@echo \"If no target is passed, then the build will be triggered for the last board\"\n\t@echo \"used. You can suffix the board/platform with '-configure' in order to just \"\n\t@echo \"configure without triggering a build command.\"\n\t@echo \"\"\n\t@echo \"You can get a list of available boards using the command:\"\n\t@echo \"    make list_boards\"\n\t@echo \"\"\n\t@echo \"Vehicles\"\n\t@echo \"--------\"\n\t@echo \"\"\n\t@echo \"It's possible to build for a specific vehicle by defining the target as one of:\"\n\t@echo \"    $(VEHICLES)\"\n\t@echo \"\"\n\t@echo \"Not that if it's your first time building or you want to change the target \"\n\t@echo \"board/platform, you'll need to configure the build before (e.g\"\n\t@echo \"make linux-configure)\"\n\t@echo \"\"\n\t@echo \"Combinations\"\n\t@echo \"------------\"\n\t@echo \"\"\n\t@echo \"It's possible to build for a specific vehicle type and board using\"\n\t@echo \"    make BOARD-VEHICLE\"\n\t@echo \"\"\n\t@echo \"For example, to build copter for the Pixracer, use this:\"\n\t@echo \"    make Pixracer-copter\"\n\t@echo \"\"\n\t@echo \"Check\"\n\t@echo \"-----\"\n\t@echo \"\"\n\t@echo \"Check targets are used for running tests. There are two targets available:\"\n\t@echo \"    check:\t for running tests that are still failing or that are new or\"\n\t@echo \"    \t\t   have been modified\"\n\t@echo \"    check-all: to run all tests\"\n\t@echo \"\"\n\t@echo \"Waf commands\"\n\t@echo \"------------\"\n\t@echo \"\"\n\t@echo \"Waf commands can be explicitly called with targets prefixed by 'waf-'. Example:\"\n\t@echo \"    make waf-clean\"\n\t@echo \"    make waf-build\"\n\t@echo \"\"\n\t@echo \"Common commands\"\n\t@echo \"---------------\"\n\t@echo \"\"\n\t@echo \"Some Waf commands can be executed without the need of prefixing the target name\"\n\t@echo \"with 'waf-'. They are: $(EXPLICIT_COMMANDS)\"\n\t@echo \"\"\n\t@echo \"Waf flags\"\n\t@echo \"---------\"\n\t@echo \"\"\n\t@echo \"The variable WAF_FLAGS can be used to set any waf command line options that\"\n\t@echo \"come to be necessary. Ex: make linux WAF_FLAGS='-c no'\"\n\t@echo \"\"\n\n# Don't run in parallel, let waf take care of that.\n.NOTPARALLEL:\n"
        },
        {
          "name": "README.md",
          "type": "blob",
          "size": 9.1494140625,
          "content": "# ArduPilot Project\n\n<a href=\"https://ardupilot.org/discord\"><img src=\"https://img.shields.io/discord/674039678562861068.svg\" alt=\"Discord\">\n\n[![Test Copter](https://github.com/ArduPilot/ardupilot/workflows/test%20copter/badge.svg?branch=master)](https://github.com/ArduPilot/ardupilot/actions/workflows/test_sitl_copter.yml) [![Test Plane](https://github.com/ArduPilot/ardupilot/workflows/test%20plane/badge.svg?branch=master)](https://github.com/ArduPilot/ardupilot/actions/workflows/test_sitl_plane.yml) [![Test Rover](https://github.com/ArduPilot/ardupilot/workflows/test%20rover/badge.svg?branch=master)](https://github.com/ArduPilot/ardupilot/actions/workflows/test_sitl_rover.yml) [![Test Sub](https://github.com/ArduPilot/ardupilot/workflows/test%20sub/badge.svg?branch=master)](https://github.com/ArduPilot/ardupilot/actions/workflows/test_sitl_sub.yml) [![Test Tracker](https://github.com/ArduPilot/ardupilot/workflows/test%20tracker/badge.svg?branch=master)](https://github.com/ArduPilot/ardupilot/actions/workflows/test_sitl_tracker.yml)\n\n[![Test AP_Periph](https://github.com/ArduPilot/ardupilot/workflows/test%20ap_periph/badge.svg?branch=master)](https://github.com/ArduPilot/ardupilot/actions/workflows/test_sitl_periph.yml) [![Test Chibios](https://github.com/ArduPilot/ardupilot/workflows/test%20chibios/badge.svg?branch=master)](https://github.com/ArduPilot/ardupilot/actions/workflows/test_chibios.yml) [![Test Linux SBC](https://github.com/ArduPilot/ardupilot/workflows/test%20Linux%20SBC/badge.svg?branch=master)](https://github.com/ArduPilot/ardupilot/actions/workflows/test_linux_sbc.yml) [![Test Replay](https://github.com/ArduPilot/ardupilot/workflows/test%20replay/badge.svg?branch=master)](https://github.com/ArduPilot/ardupilot/actions/workflows/test_replay.yml)\n\n[![Test Unit Tests](https://github.com/ArduPilot/ardupilot/workflows/test%20unit%20tests%20and%20sitl%20building/badge.svg?branch=master)](https://github.com/ArduPilot/ardupilot/actions/workflows/test_unit_tests.yml)[![test size](https://github.com/ArduPilot/ardupilot/actions/workflows/test_size.yml/badge.svg)](https://github.com/ArduPilot/ardupilot/actions/workflows/test_size.yml)\n\n[![Test Environment Setup](https://github.com/ArduPilot/ardupilot/actions/workflows/test_environment.yml/badge.svg?branch=master)](https://github.com/ArduPilot/ardupilot/actions/workflows/test_environment.yml)\n\n[![Cygwin Build](https://github.com/ArduPilot/ardupilot/actions/workflows/cygwin_build.yml/badge.svg)](https://github.com/ArduPilot/ardupilot/actions/workflows/cygwin_build.yml) [![Macos Build](https://github.com/ArduPilot/ardupilot/actions/workflows/macos_build.yml/badge.svg)](https://github.com/ArduPilot/ardupilot/actions/workflows/macos_build.yml)\n\n[![Coverity Scan Build Status](https://scan.coverity.com/projects/5331/badge.svg)](https://scan.coverity.com/projects/ardupilot-ardupilot)\n\n[![Test Coverage](https://github.com/ArduPilot/ardupilot/actions/workflows/test_coverage.yml/badge.svg?branch=master)](https://github.com/ArduPilot/ardupilot/actions/workflows/test_coverage.yml)\n\n[![Autotest Status](https://autotest.ardupilot.org/autotest-badge.svg)](https://autotest.ardupilot.org/)\n\nArduPilot is the most advanced, full-featured, and reliable open source autopilot software available.\nIt has been under development since 2010 by a diverse team of professional engineers, computer scientists, and community contributors.\nOur autopilot software is capable of controlling almost any vehicle system imaginable, from conventional airplanes, quad planes, multi-rotors, and helicopters to rovers, boats, balance bots, and even submarines.\nIt is continually being expanded to provide support for new emerging vehicle types.\n\n## The ArduPilot project is made up of: ##\n\n- ArduCopter: [code](https://github.com/ArduPilot/ardupilot/tree/master/ArduCopter), [wiki](https://ardupilot.org/copter/index.html)\n\n- ArduPlane: [code](https://github.com/ArduPilot/ardupilot/tree/master/ArduPlane), [wiki](https://ardupilot.org/plane/index.html)\n\n- Rover: [code](https://github.com/ArduPilot/ardupilot/tree/master/Rover), [wiki](https://ardupilot.org/rover/index.html)\n\n- ArduSub : [code](https://github.com/ArduPilot/ardupilot/tree/master/ArduSub), [wiki](http://ardusub.com/)\n\n- Antenna Tracker : [code](https://github.com/ArduPilot/ardupilot/tree/master/AntennaTracker), [wiki](https://ardupilot.org/antennatracker/index.html)\n\n## User Support & Discussion Forums ##\n\n- Support Forum: <https://discuss.ardupilot.org/>\n\n- Community Site: <https://ardupilot.org>\n\n## Developer Information ##\n\n- Github repository: <https://github.com/ArduPilot/ardupilot>\n\n- Main developer wiki: <https://ardupilot.org/dev/>\n\n- Developer discussion: <https://discuss.ardupilot.org>\n\n- Developer chat: <https://discord.com/channels/ardupilot>\n\n## Top Contributors ##\n\n- [Flight code contributors](https://github.com/ArduPilot/ardupilot/graphs/contributors)\n- [Wiki contributors](https://github.com/ArduPilot/ardupilot_wiki/graphs/contributors)\n- [Most active support forum users](https://discuss.ardupilot.org/u?order=post_count&period=quarterly)\n- [Partners who contribute financially](https://ardupilot.org/about/Partners)\n\n## How To Get Involved ##\n\n- The ArduPilot project is open source and we encourage participation and code contributions: [guidelines for contributors to the ardupilot codebase](https://ardupilot.org/dev/docs/contributing.html)\n\n- We have an active group of Beta Testers to help us improve our code: [release procedures](https://ardupilot.org/dev/docs/release-procedures.html)\n\n- Desired Enhancements and Bugs can be posted to the [issues list](https://github.com/ArduPilot/ardupilot/issues).\n\n- Help other users with log analysis in the [support forums](https://discuss.ardupilot.org/)\n\n- Improve the wiki and chat with other [wiki editors on Discord #documentation](https://discord.com/channels/ardupilot)\n\n- Contact the developers on one of the [communication channels](https://ardupilot.org/copter/docs/common-contact-us.html)\n\n## License ##\n\nThe ArduPilot project is licensed under the GNU General Public\nLicense, version 3.\n\n- [Overview of license](https://ardupilot.org/dev/docs/license-gplv3.html)\n\n- [Full Text](https://github.com/ArduPilot/ardupilot/blob/master/COPYING.txt)\n\n## Maintainers ##\n\nArduPilot is comprised of several parts, vehicles and boards. The list below\ncontains the people that regularly contribute to the project and are responsible\nfor reviewing patches on their specific area.\n\n- [Andrew Tridgell](https://github.com/tridge):\n  - ***Vehicle***: Plane, AntennaTracker\n  - ***Board***: Pixhawk, Pixhawk2, PixRacer\n- [Francisco Ferreira](https://github.com/oxinarf):\n  - ***Bug Master***\n- [Grant Morphett](https://github.com/gmorph):\n  - ***Vehicle***: Rover\n- [Willian Galvani](https://github.com/williangalvani):\n  - ***Vehicle***: Sub\n  - ***Board***: Navigator\n- [Michael du Breuil](https://github.com/WickedShell):\n  - ***Subsystem***: Batteries\n  - ***Subsystem***: GPS\n  - ***Subsystem***: Scripting\n- [Peter Barker](https://github.com/peterbarker):\n  - ***Subsystem***: DataFlash, Tools\n- [Randy Mackay](https://github.com/rmackay9):\n  - ***Vehicle***: Copter, Rover, AntennaTracker\n- [Siddharth Purohit](https://github.com/bugobliterator):\n  - ***Subsystem***: CAN, Compass\n  - ***Board***: Cube*\n- [Tom Pittenger](https://github.com/magicrub):\n  - ***Vehicle***: Plane\n- [Bill Geyer](https://github.com/bnsgeyer):\n  - ***Vehicle***: TradHeli\n- [Emile Castelnuovo](https://github.com/emilecastelnuovo):\n  - ***Board***: VRBrain\n- [Georgii Staroselskii](https://github.com/staroselskii):\n  - ***Board***: NavIO\n- [Gustavo José de Sousa](https://github.com/guludo):\n  - ***Subsystem***: Build system\n- [Julien Beraud](https://github.com/jberaud):\n  - ***Board***: Bebop & Bebop 2\n- [Leonard Hall](https://github.com/lthall):\n  - ***Subsystem***: Copter attitude control and navigation\n- [Matt Lawrence](https://github.com/Pedals2Paddles):\n  - ***Vehicle***: 3DR Solo & Solo based vehicles\n- [Matthias Badaire](https://github.com/badzz):\n  - ***Subsystem***: FRSky\n- [Mirko Denecke](https://github.com/mirkix):\n  - ***Board***: BBBmini, BeagleBone Blue, PocketPilot\n- [Paul Riseborough](https://github.com/priseborough):\n  - ***Subsystem***: AP_NavEKF2\n  - ***Subsystem***: AP_NavEKF3\n- [Víctor Mayoral Vilches](https://github.com/vmayoral):\n  - ***Board***: PXF, Erle-Brain 2, PXFmini\n- [Amilcar Lucas](https://github.com/amilcarlucas):\n  - ***Subsystem***: Marvelmind\n- [Samuel Tabor](https://github.com/samuelctabor):\n  - ***Subsystem***: Soaring/Gliding\n- [Henry Wurzburg](https://github.com/Hwurzburg):\n  - ***Subsystem***: OSD\n  - ***Site***: Wiki\n- [Peter Hall](https://github.com/IamPete1):\n  - ***Vehicle***: Tailsitters\n  - ***Vehicle***: Sailboat\n  - ***Subsystem***: Scripting\n- [Andy Piper](https://github.com/andyp1per):\n  - ***Subsystem***: Crossfire\n  - ***Subsystem***: ESC\n  - ***Subsystem***: OSD\n  - ***Subsystem***: SmartAudio\n- [Alessandro Apostoli ](https://github.com/yaapu):\n  - ***Subsystem***: Telemetry\n  - ***Subsystem***: OSD\n- [Rishabh Singh ](https://github.com/rishabsingh3003):\n  - ***Subsystem***: Avoidance/Proximity\n- [David Bussenschutt ](https://github.com/davidbuzz):\n  - ***Subsystem***: ESP32,AP_HAL_ESP32\n- [Charles Villard ](https://github.com/Silvanosky):\n  - ***Subsystem***: ESP32,AP_HAL_ESP32\n"
        },
        {
          "name": "Rover",
          "type": "tree",
          "content": null
        },
        {
          "name": "Tools",
          "type": "tree",
          "content": null
        },
        {
          "name": "Vagrantfile",
          "type": "blob",
          "size": 11.2060546875,
          "content": "# -*- mode: ruby -*-\n# vi: set ft=ruby :\n\n# Testing an ArduPilot VM:\n# rm -rf /vagrant/build\n# dpkg -l | grep modemmanager\n# sim_vehicle.py --map --console # in the starting directory should start a Copter simulation\n# sim_vehicle.py --debug --gdb\n# sim_vehicle.py --debug --valgrind\n# time (cd /vagrant && ./waf configure --board=fmuv2 && ./waf build --target=bin/ardusub) # ~9 minutes\n# time (cd /vagrant && ./waf configure --board=fmuv3 && ./waf build --target=bin/ardusub) # ~ minutes (after building fmuv2)\n# time (cd /vagrant && ./waf configure --board=navio2 && ./waf build --target=bin/arduplane)\n# time (cd /vagrant && ./Tools/autotest/sim_vehicle.py --map --console -v ArduPlane -f jsbsim) # should test JSBSim\n# time (cd /vagrant && ./Tools/autotest/autotest.py build.Rover test.Rover)\n\n# Vagrantfile API/syntax version. Don't touch unless you know what you're doing!\nVAGRANTFILE_API_VERSION = \"2\"\n\nVagrant.configure(VAGRANTFILE_API_VERSION) do |config|\n  config.ssh.forward_x11 = true\n\n  # Provider-specific configuration so you can fine-tune various\n  # backing providers for Vagrant. These expose provider-specific options.\n  # Example for VirtualBox:\n  #\n  config.vm.provider \"virtualbox\" do |vb|\n      # Don't boot with headless mode\n      #   vb.gui = true\n      #\n      #   # Use VBoxManage to customize the VM. For example to change memory:\n      vb.customize [\"modifyvm\", :id, \"--memory\", \"3192\"]\n      vb.customize [\"modifyvm\", :id, \"--ioapic\", \"on\"]\n      vb.customize [\"modifyvm\", :id, \"--cpus\", \"2\"]\n      # Make some effort to avoid clock skew\n      vb.customize [\"guestproperty\", \"set\", :id, \"/VirtualBox/GuestAdd/VBoxService/--timesync-set-threshold\", \"5000\"]\n      vb.customize [\"guestproperty\", \"set\", :id, \"/VirtualBox/GuestAdd/VBoxService/--timesync-set-start\"]\n      vb.customize [\"guestproperty\", \"set\", :id, \"/VirtualBox/GuestAdd/VBoxService/--timesync-set-on-restore\", \"1\"]\n  end\n\n  # If you are on windows then you must use a version of git >= 1.8.x\n  # to update the submodules in order to build. Older versions of git\n  # use absolute paths for submodules which confuses things.\n\n  # removing this line causes \"A box must be specified.\" error\n  # and this is the default box that will be booted if no name is specified\n  config.vm.boot_timeout = 1500\n\n  # LTS, EOL April, 2019:\n  config.vm.define \"trusty32\", autostart: false do |trusty32|\n    trusty32.vm.box = \"ubuntu/trusty32\"\n    trusty32.vm.provision \"trusty32\", type: \"shell\", path: \"Tools/vagrant/initvagrant.sh\"\n    trusty32.vm.provider \"virtualbox\" do |vb|\n      vb.name = \"ArduPilot (trusty32)\"\n    end\n  end\n\n  # 14.04.5 LTS, EOL April, 2019:\n  config.vm.define \"trusty64\", autostart: false do |trusty64|\n    trusty64.vm.box = \"ubuntu/trusty64\"\n    trusty64.vm.provision \"trusty64\", type: \"shell\", path: \"Tools/vagrant/initvagrant.sh\"\n    trusty64.vm.provider \"virtualbox\" do |vb|\n      vb.name = \"ArduPilot (trusty64)\"\n    end\n  end\n\n  # LTS, EOL April 2021\n  # this VM is useful for running valgrind on!\n  config.vm.define \"xenial32\", autostart: false do |xenial32|\n    xenial32.vm.box = \"ubuntu/xenial32\"\n    xenial32.vm.provision :shell, path: \"Tools/vagrant/initvagrant.sh\"\n    xenial32.vm.provider \"virtualbox\" do |vb|\n      vb.name = \"ArduPilot (xenial32)\"\n    end\n  end\n\n  config.vm.define \"xenial64\", autostart: false do |xenial64|\n    xenial64.vm.box = \"ubuntu/xenial64\"\n    xenial64.vm.provision :shell, path: \"Tools/vagrant/initvagrant.sh\"\n    xenial64.vm.provider \"virtualbox\" do |vb|\n      vb.name = \"ArduPilot (xenial64)\"\n    end\n  end\n\n  # NO LONGER AVAILABLE FOR DOWNLOAD, EOL January 2018\n  # EOL January 2018\n  # Only kept around for those few dev's who have already got this image and continue to use it.\n  config.vm.define \"zesty32\", autostart: false do |zesty32|\n    zesty32.vm.box = \"ubuntu/zesty32\"\n    zesty32.vm.provision :shell, path: \"Tools/vagrant/initvagrant.sh\"\n    zesty32.vm.provider \"virtualbox\" do |vb|\n      vb.name = \"ArduPilot (zesty32)\"\n    end\n  end\n\n  # 17.10, EOL July 2018\n  # Only kept around for those few dev's who have already got this image and continue to use it; not available for download\n  config.vm.define \"artful32\", autostart: false do |artful32|\n    artful32.vm.box = \"ubuntu/artful32\"\n    artful32.vm.provision :shell, path: \"Tools/vagrant/initvagrant.sh\"\n    artful32.vm.provider \"virtualbox\" do |vb|\n      vb.name = \"ArduPilot (artful32)\"\n    end\n  end\n\n  # 18.04 LTS EOL April 2023\n  # Only kept around for those few dev's who have already got this image and continue to use it; not available for download\n  config.vm.define \"bionic32\", autostart: false do |bionic32|\n    bionic32.vm.box = \"ubuntu/bionic32\"\n    bionic32.vm.provision :shell, path: \"Tools/vagrant/initvagrant.sh\"\n    bionic32.vm.provider \"virtualbox\" do |vb|\n      vb.name = \"ArduPilot (bionic32)\"\n    end\n  end\n\n  # 18.04 LTS EOL April 2023\n  config.vm.define \"bionic64\", autostart: false do |bionic64|\n    bionic64.vm.box = \"ubuntu/bionic64\"\n    bionic64.vm.provision :shell, path: \"Tools/vagrant/initvagrant.sh\"\n    bionic64.vm.provider \"virtualbox\" do |vb|\n      vb.name = \"ArduPilot (bionic64)\"\n    end\n  end\n\n  # 18.04 LTS EOL April 2023\n  config.vm.define \"bionic64-desktop\", autostart: false do |bionic64|\n    bionic64.vm.box = \"ubuntu/bionic64\"\n    bionic64.vm.provision :shell, path: \"Tools/vagrant/initvagrant-desktop.sh\"\n    bionic64.vm.provider \"virtualbox\" do |vb|\n      vb.name = \"ArduPilot (bionic64-desktop)\"\n      vb.gui = true\n    end\n  end\n\n  # 18.10\n  config.vm.define \"cosmic32\", autostart: false do |cosmic32|\n    cosmic32.vm.box = \"ubuntu/cosmic32\"\n    cosmic32.vm.provision :shell, path: \"Tools/vagrant/initvagrant.sh\"\n    cosmic32.vm.provider \"virtualbox\" do |vb|\n      vb.name = \"ArduPilot (cosmic32)\"\n    end\n  end\n\n  # 18.10\n  config.vm.define \"cosmic64\", autostart: false do |cosmic64|\n    cosmic64.vm.box = \"ubuntu/cosmic64\"\n    cosmic64.vm.provision :shell, path: \"Tools/vagrant/initvagrant.sh\"\n    cosmic64.vm.provider \"virtualbox\" do |vb|\n      vb.name = \"ArduPilot (cosmic64)\"\n    end\n  end\n\n  # 19.04\n  config.vm.define \"disco64\", autostart: false do |disco64|\n    disco64.vm.box = \"ubuntu/disco64\"\n    disco64.vm.provision :shell, path: \"Tools/vagrant/initvagrant.sh\"\n    disco64.vm.provider \"virtualbox\" do |vb|\n      vb.name = \"ArduPilot (disco64)\"\n    end\n  end\n\n  # 19.10 - broken; fails to use NamedTemporaryFile to create file for gdb\n#  config.vm.define \"eoan\", autostart: false do |eoan|\n#    eoan.vm.box = \"ubuntu/eoan64\"\n#    eoan.vm.provision :shell, path: \"Tools/vagrant/initvagrant.sh\"\n#    eoan.vm.provider \"virtualbox\" do |vb|\n#      vb.name = \"ArduPilot (eoan)\"\n#    end\n#    eoan.vm.boot_timeout = 1200\n#  end\n\n  # 20.04 LTS  EOL April 2025\n  config.vm.define \"focal\", autostart: false do |focal|\n    focal.vm.box = \"ubuntu/focal64\"\n    focal.vm.provision :shell, path: \"Tools/vagrant/initvagrant.sh\"\n    focal.vm.provider \"virtualbox\" do |vb|\n      vb.name = \"ArduPilot (focal)\"\n    end\n    focal.vm.boot_timeout = 1200\n  end\n  config.vm.define \"focal-desktop\", autostart: false do |focal|\n    focal.vm.box = \"ubuntu/focal64\"\n    focal.vm.provision :shell, path: \"Tools/vagrant/initvagrant-desktop.sh\"\n    focal.vm.provider \"virtualbox\" do |vb|\n      vb.name = \"ArduPilot (focal-desktop)\"\n      vb.gui = true\n    end\n    focal.vm.boot_timeout = 1500\n  end\n\n  # 20.10  EOL July 2021\n#   config.vm.define \"groovy\", autostart: false do |groovy|\n#     groovy.vm.box = \"ubuntu/groovy64\"\n#     groovy.vm.provision :shell, path: \"Tools/vagrant/initvagrant.sh\"\n#     groovy.vm.provider \"virtualbox\" do |vb|\n#       vb.name = \"ArduPilot (groovy)\"\n#     end\n#     groovy.vm.boot_timeout = 1200\n#   end\n\n  # 21.04 EOL January 2022 apt repo down\n#   config.vm.define \"hirsute\", autostart: false do |hirsute|\n#     hirsute.vm.box = \"ubuntu/hirsute64\"\n#     hirsute.vm.provision :shell, path: \"Tools/vagrant/initvagrant.sh\"\n#     hirsute.vm.provider \"virtualbox\" do |vb|\n#       vb.name = \"ArduPilot (hirsute)\"\n#     end\n#     hirsute.vm.boot_timeout = 1200\n#   end\n#   config.vm.define \"hirsute-desktop\", autostart: false do |hirsute|\n#     hirsute.vm.box = \"ubuntu/hirsute64\"\n#     hirsute.vm.provision :shell, path: \"Tools/vagrant/initvagrant-desktop.sh\"\n#     hirsute.vm.provider \"virtualbox\" do |vb|\n#       vb.name = \"ArduPilot (hirsute-desktop)\"\n#       vb.gui = true\n#     end\n#     hirsute.vm.boot_timeout = 1200\n#   end\n\n  # 21.10 EOL July 2022\n#   config.vm.define \"impish\", autostart: false do |impish|\n#     impish.vm.box = \"ubuntu/impish64\"\n#     impish.vm.provision :shell, path: \"Tools/vagrant/initvagrant.sh\"\n#     impish.vm.provider \"virtualbox\" do |vb|\n#       vb.name = \"ArduPilot (impish)\"\n#     end\n#     impish.vm.boot_timeout = 1200\n#   end\n\n  # 22.04 LTS EOL Apr 2032\n  config.vm.define \"jammy\", primary: true do |jammy|\n    jammy.vm.box = \"ubuntu/jammy64\"\n    jammy.vm.provision :shell, path: \"Tools/vagrant/initvagrant.sh\"\n    jammy.vm.provider \"virtualbox\" do |vb|\n      vb.name = \"ArduPilot (jammy)\"\n    end\n    jammy.vm.boot_timeout = 1200\n  end\n  config.vm.define \"jammy-desktop\", autostart: false do |jammy|\n    jammy.vm.box = \"ubuntu/jammy64\"\n    jammy.vm.provision :shell, path: \"Tools/vagrant/initvagrant-desktop.sh\"\n    jammy.vm.provider \"virtualbox\" do |vb|\n      vb.name = \"ArduPilot (jammy-desktop)\"\n      vb.gui = true\n    end\n    jammy.vm.boot_timeout = 1200\n  end\n\n  # 23.04 EOL Jan 2024\n  config.vm.define \"lunar\", autostart: false do |lunar|\n    lunar.vm.box = \"ubuntu/lunar64\"\n    lunar.vm.provision :shell, path: \"Tools/vagrant/initvagrant.sh\"\n    lunar.vm.provider \"virtualbox\" do |vb|\n      vb.name = \"ArduPilot (lunar)\"\n    end\n    lunar.vm.boot_timeout = 1200\n  end\n  config.vm.define \"lunar-desktop\", autostart: false do |lunar|\n    lunar.vm.box = \"ubuntu/lunar64\"\n    lunar.vm.provision :shell, path: \"Tools/vagrant/initvagrant-desktop.sh\"\n    lunar.vm.provider \"virtualbox\" do |vb|\n      vb.name = \"ArduPilot (lunar-desktop)\"\n      vb.gui = true\n    end\n    lunar.vm.boot_timeout = 1200\n  end\n\n  # 23.10 EOL Jul 2024\n  config.vm.define \"mantic\", autostart: false do |mantic|\n    mantic.vm.box = \"ubuntu/mantic64\"\n    mantic.vm.provision :shell, path: \"Tools/vagrant/initvagrant.sh\"\n    mantic.vm.provider \"virtualbox\" do |vb|\n      vb.name = \"ArduPilot (mantic)\"\n    end\n    mantic.vm.boot_timeout = 1200\n  end\n  config.vm.define \"mantic-desktop\", autostart: false do |mantic|\n    mantic.vm.box = \"ubuntu/mantic64\"\n    mantic.vm.provision :shell, path: \"Tools/vagrant/initvagrant-desktop.sh\"\n    mantic.vm.provider \"virtualbox\" do |vb|\n      vb.name = \"ArduPilot (mantic-desktop)\"\n      vb.gui = true\n    end\n    mantic.vm.boot_timeout = 1200\n  end\n\n  # 24.04 end of standard support Jun 2029\n  # note the use of \"bento\" here; Ubuntu stopped providing Vagrant\n  # images due to Hashicorp adopting the \"Business Source License\".\n  config.vm.define \"noble\", autostart: false do |noble|\n    noble.vm.box = \"bento/ubuntu-24.04\"\n    noble.vm.provision :shell, path: \"Tools/vagrant/initvagrant.sh\"\n    noble.vm.provider \"virtualbox\" do |vb|\n      vb.name = \"ArduPilot (noble)\"\n    end\n    noble.vm.boot_timeout = 1200\n  end\n  config.vm.define \"noble-desktop\", autostart: false do |noble|\n    noble.vm.box = \"bento/ubuntu-24.04\"\n    noble.vm.provision :shell, path: \"Tools/vagrant/initvagrant-desktop.sh\"\n    noble.vm.provider \"virtualbox\" do |vb|\n      vb.name = \"ArduPilot (noble-desktop)\"\n      vb.gui = true\n    end\n    noble.vm.boot_timeout = 1200\n  end\nend\n"
        },
        {
          "name": "benchmarks",
          "type": "tree",
          "content": null
        },
        {
          "name": "docs",
          "type": "tree",
          "content": null
        },
        {
          "name": "libraries",
          "type": "tree",
          "content": null
        },
        {
          "name": "modules",
          "type": "tree",
          "content": null
        },
        {
          "name": "pyproject.toml",
          "type": "blob",
          "size": 0.2548828125,
          "content": "[tool.isort]\nprofile = \"black\"\nskip = [\"./modules/\", \"./build/\"]\n\n[tool.black]\nline-length = 120\nskip-string-normalization = true\n\n[tool.mypy]\nignore_missing_imports = true\nexclude = [\n    'modules/',\n    'build/',\n    'cmake-build-debug/',\n    '/setup\\.py$'\n]\n"
        },
        {
          "name": "tests",
          "type": "tree",
          "content": null
        },
        {
          "name": "waf",
          "type": "blob",
          "size": 0.740234375,
          "content": "#!/usr/bin/env python3\n\nfrom __future__ import print_function\nimport subprocess\nimport os.path as p\nimport sys\n\nd = p.dirname(p.realpath(__file__))\nwaf_light = p.join(d, 'modules', 'waf', 'waf-light')\n\npython = sys.executable\n\ntry:\n    subprocess.check_call([python, waf_light] + sys.argv[1:])\nexcept subprocess.CalledProcessError as e:\n    if e.returncode != 2 or p.isfile(waf_light):\n        sys.exit(1)\n\n    print('Missing waf submodule. Trying to get it')\n\n    try:\n        subprocess.check_call(['git', 'submodule', 'update', '--init',\n                               'modules/waf'])\n    except subprocess.CalledProcessError:\n        print('Could not update submodule', file=sys.stderr)\n        sys.exit(1)\n\n    print('Submodules OK, try running again')\n"
        },
        {
          "name": "wscript",
          "type": "blob",
          "size": 30.7548828125,
          "content": "#!/usr/bin/env python3\n# encoding: utf-8\n\nfrom __future__ import print_function\n\nimport os.path\nimport os\nimport sys\nimport subprocess\nimport json\nimport fnmatch\nsys.path.insert(0, 'Tools/ardupilotwaf/')\nsys.path.insert(0, 'Tools/scripts/')\n\nimport ardupilotwaf\nimport boards\nimport shutil\nimport build_options\n\nfrom waflib import Build, ConfigSet, Configure, Context, Utils\nfrom waflib.Configure import conf\n\n# Ref: https://stackoverflow.com/questions/40590192/getting-an-error-attributeerror-module-object-has-no-attribute-run-while\ntry:\n    from subprocess import CompletedProcess\nexcept ImportError:\n    # Python 2\n    class CompletedProcess:\n\n        def __init__(self, args, returncode, stdout=None, stderr=None):\n            self.args = args\n            self.returncode = returncode\n            self.stdout = stdout\n            self.stderr = stderr\n\n        def check_returncode(self):\n            if self.returncode != 0:\n                err = subprocess.CalledProcessError(self.returncode, self.args, output=self.stdout)\n                raise err\n            return self.returncode\n\n    def sp_run(*popenargs, **kwargs):\n        input = kwargs.pop(\"input\", None)\n        check = kwargs.pop(\"handle\", False)\n        kwargs.pop(\"capture_output\", True)\n        if input is not None:\n            if 'stdin' in kwargs:\n                raise ValueError('stdin and input arguments may not both be used.')\n            kwargs['stdin'] = subprocess.PIPE\n        process = subprocess.Popen(*popenargs, **kwargs)\n        try:\n            outs, errs = process.communicate(input)\n        except:\n            process.kill()\n            process.wait()\n            raise\n        returncode = process.poll()\n        if check and returncode:\n            raise subprocess.CalledProcessError(returncode, popenargs, output=outs)\n        return CompletedProcess(popenargs, returncode, stdout=outs, stderr=errs)\n\n    subprocess.run = sp_run\n    # ^ This monkey patch allows it work on Python 2 or 3 the same way\n\n\n# TODO: implement a command 'waf help' that shows the basic tasks a\n# developer might want to do: e.g. how to configure a board, compile a\n# vehicle, compile all the examples, add a new example. Should fit in\n# less than a terminal screen, ideally commands should be copy\n# pastable. Add the 'export waf=\"$PWD/waf\"' trick to be copy-pastable\n# as well.\n\n# TODO: replace defines with the use of the generated ap_config.h file\n# this makes recompilation at least when defines change. which might\n# be sufficient.\n\n# Default installation prefix for Linux boards\ndefault_prefix = '/usr/'\n\n# Override Build execute and Configure post_recurse methods for autoconfigure purposes\nBuild.BuildContext.execute = ardupilotwaf.ap_autoconfigure(Build.BuildContext.execute)\nConfigure.ConfigurationContext.post_recurse = ardupilotwaf.ap_configure_post_recurse()\n\n\ndef _set_build_context_variant(board):\n    for c in Context.classes:\n        if not issubclass(c, Build.BuildContext):\n            continue\n        c.variant = board\n\n# Remove all submodules and then sync\n@conf\ndef submodule_force_clean(ctx):\n    whitelist = {\n                            'COLCON_IGNORE',\n                            'esp_idf',\n                          }\n\n    # Get all items in the modules folder\n    module_list = os.scandir('modules')\n\n    # Delete all directories except those in the whitelist\n    for module in module_list:\n        if (module.is_dir()) and (module.name not in whitelist):\n            shutil.rmtree(module)\n\n    submodulesync(ctx)\n\n# run Tools/gittools/submodule-sync.sh to sync submodules\n@conf\ndef submodulesync(ctx):\n    subprocess.call(['Tools/gittools/submodule-sync.sh'])\n\ndef init(ctx):\n    # Generate Task List, so that VS Code extension can keep track\n    # of changes to possible build targets\n    generate_tasklist(ctx, False)\n    env = ConfigSet.ConfigSet()\n    try:\n        p = os.path.join(Context.out_dir, Build.CACHE_DIR, Build.CACHE_SUFFIX)\n        env.load(p)\n    except EnvironmentError:\n        return\n\n    Configure.autoconfig = 'clobber' if env.AUTOCONFIG else False\n\n    board = ctx.options.board or env.BOARD\n\n    if not board:\n        return\n\n    # define the variant build commands according to the board\n    _set_build_context_variant(board)\n\ndef options(opt):\n    opt.load('compiler_cxx compiler_c waf_unit_test python')\n    opt.load('ardupilotwaf')\n    opt.load('build_summary')\n\n    g = opt.ap_groups['configure']\n\n    boards_names = boards.get_boards_names()\n    removed_names = boards.get_removed_boards()\n    g.add_option('--board',\n        action='store',\n        default=None,\n        help='Target board to build, choices are %s.' % ', '.join(boards_names))\n\n    g.add_option('--debug',\n        action='store_true',\n        default=False,\n        help='Configure as debug variant.')\n\n    g.add_option('--debug-symbols', '-g',\n        action='store_true',\n        default=False,\n        help='Add debug symbolds to build.')\n    \n    g.add_option('--disable-watchdog',\n        action='store_true',\n        default=False,\n        help='Build with watchdog disabled.')\n\n    g.add_option('--coverage',\n                 action='store_true',\n                 default=False,\n                 help='Configure coverage flags.')\n\n    g.add_option('--Werror',\n        action='store_true',\n        default=None,\n        help='build with -Werror.')\n\n    g.add_option('--disable-Werror',\n        action='store_true',\n        default=None,\n        help='Disable -Werror.')\n    \n    g.add_option('--toolchain',\n        action='store',\n        default=None,\n        help='Override default toolchain used for the board. Use \"native\" for using the host toolchain.')\n\n    g.add_option('--disable-gccdeps',\n        action='store_true',\n        default=False,\n        help='Disable the use of GCC dependencies output method and use waf default method.')\n\n    g.add_option('--enable-asserts',\n        action='store_true',\n        default=False,\n        help='enable OS level asserts.')\n\n    g.add_option('--save-temps',\n        action='store_true',\n        default=False,\n        help='save compiler temporary files.')\n    \n    g.add_option('--enable-malloc-guard',\n        action='store_true',\n        default=False,\n        help='enable malloc guard regions.')\n\n    g.add_option('--enable-stats',\n        action='store_true',\n        default=False,\n        help='enable OS level thread statistics.')\n\n    g.add_option('--bootloader',\n        action='store_true',\n        default=False,\n        help='Configure for building a bootloader.')\n\n    g.add_option('--signed-fw',\n        action='store_true',\n        default=False,\n        help='Configure for signed firmware support.')\n\n    g.add_option('--private-key',\n                 action='store',\n                 default=None,\n            help='path to private key for signing firmware.')\n    \n    g.add_option('--no-autoconfig',\n        dest='autoconfig',\n        action='store_false',\n        default=True,\n        help='''Disable autoconfiguration feature. By default, the build system\ntriggers a reconfiguration whenever it thinks it's necessary - this\noption disables that.\n''')\n\n    g.add_option('--no-submodule-update',\n        dest='submodule_update',\n        action='store_false',\n        default=True,\n        help='''Don't update git submodules. Useful for building with\nsubmodules at specific revisions.\n''')\n\n    g.add_option('--enable-header-checks', action='store_true',\n        default=False,\n        help=\"Enable checking of headers\")\n\n    g.add_option('--default-parameters',\n        default=None,\n        help='set default parameters to embed in the firmware')\n\n    g.add_option('--enable-math-check-indexes',\n                 action='store_true',\n                 default=False,\n                 help=\"Enable checking of math indexes\")\n\n    g.add_option('--disable-scripting', action='store_true',\n                 default=False,\n                 help=\"Disable onboard scripting engine\")\n\n    g.add_option('--enable-scripting', action='store_true',\n                 default=False,\n                 help=\"Enable onboard scripting engine\")\n\n    g.add_option('--no-gcs', action='store_true',\n                 default=False,\n                 help=\"Disable GCS code\")\n    \n    g.add_option('--scripting-checks', action='store_true',\n                 default=True,\n                 help=\"Enable runtime scripting sanity checks\")\n\n    g.add_option('--enable-onvif', action='store_true',\n                 default=False,\n                 help=\"Enables and sets up ONVIF camera control\")\n\n    g.add_option('--scripting-docs', action='store_true',\n                 default=False,\n                 help=\"enable generation of scripting documentation\")\n\n    g.add_option('--enable-opendroneid', action='store_true',\n                 default=False,\n                 help=\"Enables OpenDroneID\")\n\n    g.add_option('--enable-check-firmware', action='store_true',\n                 default=False,\n                 help=\"Enables firmware ID checking on boot\")\n\n    g.add_option('--enable-custom-controller', action='store_true',\n                 default=False,\n                 help=\"Enables custom controller\")\n\n    g.add_option('--enable-gps-logging', action='store_true',\n                 default=False,\n                 help=\"Enables GPS logging\")\n    \n    g.add_option('--enable-dds', action='store_true',\n                 help=\"Enable the dds client to connect with ROS2/DDS.\")\n\n    g.add_option('--disable-networking', action='store_true',\n                 help=\"Disable the networking API code\")\n\n    g.add_option('--enable-networking-tests', action='store_true',\n                 help=\"Enable the networking test code. Automatically enables networking.\")\n    \n    g.add_option('--enable-dronecan-tests', action='store_true',\n                 default=False,\n                 help=\"Enables DroneCAN tests in sitl\")\n    g = opt.ap_groups['linux']\n\n    linux_options = ('--prefix', '--destdir', '--bindir', '--libdir')\n    for k in linux_options:\n        option = opt.parser.get_option(k)\n        if option:\n            opt.parser.remove_option(k)\n            g.add_option(option)\n\n    g.add_option('--apstatedir',\n        action='store',\n        default='',\n        help='''Where to save data like parameters, log and terrain.\nThis is the --localstatedir + ArduPilots subdirectory [default:\nboard-dependent, usually /var/lib/ardupilot]''')\n\n    g.add_option('--rsync-dest',\n        dest='rsync_dest',\n        action='store',\n        default='',\n        help='''Destination for the rsync Waf command. It can be passed during\nconfiguration in order to save typing.\n''')\n\n    g.add_option('--enable-benchmarks',\n        action='store_true',\n        default=False,\n        help='Enable benchmarks.')\n\n    g.add_option('--enable-lttng', action='store_true',\n        default=False,\n        help=\"Enable lttng integration\")\n\n    g.add_option('--disable-libiio', action='store_true',\n        default=False,\n        help=\"Don't use libiio even if supported by board and dependencies available\")\n\n    g.add_option('--disable-tests', action='store_true',\n        default=False,\n        help=\"Disable compilation and test execution\")\n\n    g.add_option('--enable-sfml', action='store_true',\n                 default=False,\n                 help=\"Enable SFML graphics library\")\n\n    g.add_option('--enable-sfml-joystick', action='store_true',\n                 default=False,\n                 help=\"Enable SFML joystick input library\")\n\n    g.add_option('--enable-sfml-audio', action='store_true',\n                 default=False,\n                 help=\"Enable SFML audio library\")\n\n    g.add_option('--osd', action='store_true',\n                 default=False,\n                 help=\"Enable OSD support\")\n\n    g.add_option('--osd-fonts', action='store_true',\n                 default=False,\n                 help=\"Enable OSD support with fonts\")\n    \n    g.add_option('--sitl-osd', action='store_true',\n                 default=False,\n                 help=\"Enable SITL OSD\")\n\n    g.add_option('--sitl-rgbled', action='store_true',\n                 default=False,\n                 help=\"Enable SITL RGBLed\")\n\n    g.add_option('--force-32bit', action='store_true',\n                 default=False,\n                 help=\"Force 32bit build\")\n\n    g.add_option('--build-dates', action='store_true',\n                 default=False,\n                 help=\"Include build date in binaries.  Appears in AUTOPILOT_VERSION.os_sw_version\")\n\n    g.add_option('--sitl-flash-storage',\n        action='store_true',\n        default=False,\n        help='Use flash storage emulation.')\n\n    g.add_option('--ekf-double',\n        action='store_true',\n        default=False,\n        help='Configure EKF as double precision.')\n\n    g.add_option('--ekf-single',\n        action='store_true',\n        default=False,\n        help='Configure EKF as single precision.')\n    \n    g.add_option('--static',\n        action='store_true',\n        default=False,\n        help='Force a static build')\n\n    g.add_option('--postype-single',\n        action='store_true',\n        default=False,\n        help='force single precision postype_t')\n\n    g.add_option('--consistent-builds',\n        action='store_true',\n        default=False,\n        help='force consistent build outputs for things like __LINE__')\n\n    g.add_option('--extra-hwdef',\n\t    action='store',\n\t    default=None,\n\t    help='Extra hwdef.dat file for custom build.')\n\n    g.add_option('--assert-cc-version',\n                 default=None,\n                 help='fail configure if not using the specified gcc version')\n\n    g.add_option('--num-aux-imus',\n                 type='int',\n                 default=0,\n                 help='number of auxiliary IMUs')\n\n    g.add_option('--board-start-time',\n                 type='int',\n                 default=0,\n                 help='zero time on boot in microseconds')\n\n    g.add_option('--enable-iomcu-profiled-support',\n                    action='store_true',\n                    default=False,\n                    help='enable iomcu profiled support')\n\n    g.add_option('--enable-new-checking',\n        action='store_true',\n        default=False,\n        help='enables checking of new to ensure NEW_NOTHROW is used')\n\n    # support enabling any option in build_options.py\n    for opt in build_options.BUILD_OPTIONS:\n        enable_option = \"--\" + opt.config_option()\n        disable_option = enable_option.replace(\"--enable\", \"--disable\")\n        enable_description = opt.description\n        if not enable_description.lower().startswith(\"enable\"):\n            enable_description = \"Enable \" + enable_description\n        disable_description = \"Disable \" + enable_description[len(\"Enable \"):]\n        g.add_option(enable_option,\n                     action='store_true',\n                     default=False,\n                     help=enable_description)\n        g.add_option(disable_option,\n                     action='store_true',\n                     default=False,\n                     help=disable_description)\n    \n    \ndef _collect_autoconfig_files(cfg):\n    for m in sys.modules.values():\n        paths = []\n        if hasattr(m, '__file__') and m.__file__ is not None:\n            paths.append(m.__file__)\n        elif hasattr(m, '__path__'):\n            for p in m.__path__:\n                if p is not None:\n                    paths.append(p)\n\n        for p in paths:\n            if p in cfg.files or not os.path.isfile(p):\n                continue\n\n            with open(p, 'rb') as f:\n                cfg.hash = Utils.h_list((cfg.hash, f.read()))\n                cfg.files.append(p)\n\ndef configure(cfg):\n\t# we need to enable debug mode when building for gconv, and force it to sitl\n    if cfg.options.board is None:\n        cfg.options.board = 'sitl'\n\n    boards_names = boards.get_boards_names()\n    if not cfg.options.board in boards_names:\n        for b in boards_names:\n            if b.upper() == cfg.options.board.upper():\n                cfg.options.board = b\n                break\n        \n    cfg.env.BOARD = cfg.options.board\n    cfg.env.DEBUG = cfg.options.debug\n    cfg.env.DEBUG_SYMBOLS = cfg.options.debug_symbols\n    cfg.env.COVERAGE = cfg.options.coverage\n    cfg.env.AUTOCONFIG = cfg.options.autoconfig\n\n    _set_build_context_variant(cfg.env.BOARD)\n    cfg.setenv(cfg.env.BOARD)\n\n    if cfg.options.signed_fw:\n        cfg.env.AP_SIGNED_FIRMWARE = True\n        cfg.options.enable_check_firmware = True\n\n    cfg.env.BOARD = cfg.options.board\n    cfg.env.DEBUG = cfg.options.debug\n    cfg.env.DEBUG_SYMBOLS = cfg.options.debug_symbols\n    cfg.env.COVERAGE = cfg.options.coverage\n    cfg.env.FORCE32BIT = cfg.options.force_32bit\n    cfg.env.ENABLE_ASSERTS = cfg.options.enable_asserts\n    cfg.env.BOOTLOADER = cfg.options.bootloader\n    cfg.env.ENABLE_MALLOC_GUARD = cfg.options.enable_malloc_guard\n    cfg.env.ENABLE_STATS = cfg.options.enable_stats\n    cfg.env.SAVE_TEMPS = cfg.options.save_temps\n\n    extra_hwdef = cfg.options.extra_hwdef\n    if extra_hwdef is not None and not os.path.exists(extra_hwdef):\n        raise FileNotFoundError(f\"extra-hwdef file NOT found: '{cfg.options.extra_hwdef}'\")\n    cfg.env.HWDEF_EXTRA = cfg.options.extra_hwdef\n    if cfg.env.HWDEF_EXTRA:\n        cfg.env.HWDEF_EXTRA = os.path.abspath(cfg.env.HWDEF_EXTRA)\n\n    cfg.env.OPTIONS = cfg.options.__dict__\n\n    # Allow to differentiate our build from the make build\n    cfg.define('WAF_BUILD', 1)\n\n    cfg.msg('Autoconfiguration', 'enabled' if cfg.options.autoconfig else 'disabled')\n\n    if cfg.options.static:\n        cfg.msg('Using static linking', 'yes', color='YELLOW')\n        cfg.env.STATIC_LINKING = True\n\n    if cfg.options.num_aux_imus > 0:\n        cfg.define('INS_AUX_INSTANCES', cfg.options.num_aux_imus)\n\n    if cfg.options.board_start_time != 0:\n        cfg.define('AP_BOARD_START_TIME', cfg.options.board_start_time)\n        # also in env for hrt.c\n        cfg.env.AP_BOARD_START_TIME = cfg.options.board_start_time\n\n    # require python 3.8.x or later\n    cfg.load('python')\n    cfg.check_python_version(minver=(3,6,9))\n\n    cfg.load('ap_library')\n\n    cfg.msg('Setting board to', cfg.options.board)\n    cfg.get_board().configure(cfg)\n\n    cfg.load('waf_unit_test')\n    cfg.load('mavgen')\n    cfg.load('dronecangen')\n\n    cfg.env.SUBMODULE_UPDATE = cfg.options.submodule_update\n\n    cfg.start_msg('Source is git repository')\n    if cfg.srcnode.find_node('.git'):\n        cfg.end_msg('yes')\n    else:\n        cfg.end_msg('no')\n        cfg.env.SUBMODULE_UPDATE = False\n\n    cfg.msg('Update submodules', 'yes' if cfg.env.SUBMODULE_UPDATE else 'no')\n    cfg.load('git_submodule')\n\n    if cfg.options.enable_benchmarks:\n        cfg.load('gbenchmark')\n    cfg.load('gtest')\n    cfg.load('static_linking')\n    cfg.load('build_summary')\n\n    cfg.start_msg('Benchmarks')\n    if cfg.env.HAS_GBENCHMARK:\n        cfg.end_msg('enabled')\n    else:\n        cfg.end_msg('disabled', color='YELLOW')\n\n    cfg.start_msg('Unit tests')\n    if cfg.env.HAS_GTEST:\n        cfg.end_msg('enabled')\n    else:\n        cfg.end_msg('disabled', color='YELLOW')\n\n    cfg.start_msg('Scripting')\n    if cfg.options.disable_scripting:\n        cfg.end_msg('disabled', color='YELLOW')\n    elif cfg.options.enable_scripting:\n        cfg.end_msg('enabled')\n    else:\n        cfg.end_msg('maybe')\n    cfg.recurse('libraries/AP_Scripting')\n\n    cfg.recurse('libraries/AP_GPS')\n    cfg.recurse('libraries/AP_HAL_SITL')\n    cfg.recurse('libraries/SITL')\n\n    cfg.recurse('libraries/AP_Networking')\n\n    cfg.start_msg('Scripting runtime checks')\n    if cfg.options.scripting_checks:\n        cfg.end_msg('enabled')\n    else:\n        cfg.end_msg('disabled', color='YELLOW')\n\n    cfg.start_msg('Debug build')\n    if cfg.env.DEBUG:\n        cfg.end_msg('enabled')\n    else:\n        cfg.end_msg('disabled', color='YELLOW')\n\n    cfg.start_msg('Coverage build')\n    if cfg.env.COVERAGE:\n        cfg.end_msg('enabled')\n    else:\n        cfg.end_msg('disabled', color='YELLOW')\n\n    cfg.start_msg('Force 32-bit build')\n    if cfg.env.FORCE32BIT:\n        cfg.end_msg('enabled')\n    else:\n        cfg.end_msg('disabled', color='YELLOW')\n\n    cfg.env.append_value('GIT_SUBMODULES', 'mavlink')\n\n    cfg.env.prepend_value('INCLUDES', [\n        cfg.srcnode.abspath() + '/libraries/',\n    ])\n\n    cfg.find_program('rsync', mandatory=False)\n    if cfg.options.rsync_dest:\n        cfg.msg('Setting rsync destination to', cfg.options.rsync_dest)\n        cfg.env.RSYNC_DEST = cfg.options.rsync_dest\n\n    if cfg.options.enable_header_checks:\n        cfg.msg('Enabling header checks', cfg.options.enable_header_checks)\n        cfg.env.ENABLE_HEADER_CHECKS = True\n    else:\n        cfg.env.ENABLE_HEADER_CHECKS = False\n\n    # Always use system extensions\n    cfg.define('_GNU_SOURCE', 1)\n\n    if cfg.options.Werror:\n        # print(cfg.options.Werror)\n        if cfg.options.disable_Werror:\n            cfg.options.Werror = False\n\n    cfg.write_config_header(os.path.join(cfg.variant, 'ap_config.h'), guard='_AP_CONFIG_H_')\n\n    # add in generated flags\n    cfg.env.CXXFLAGS += ['-include', 'ap_config.h']\n\n    cfg.remove_target_list()\n    _collect_autoconfig_files(cfg)\n\ndef collect_dirs_to_recurse(bld, globs, **kw):\n    dirs = []\n    globs = Utils.to_list(globs)\n\n    if bld.bldnode.is_child_of(bld.srcnode):\n        kw['excl'] = Utils.to_list(kw.get('excl', []))\n        kw['excl'].append(bld.bldnode.path_from(bld.srcnode))\n\n    for g in globs:\n        for d in bld.srcnode.ant_glob(g + '/wscript', **kw):\n            dirs.append(d.parent.relpath())\n    return dirs\n\ndef list_boards(ctx):\n    print(*boards.get_boards_names())\n\ndef list_ap_periph_boards(ctx):\n    print(*boards.get_ap_periph_boards())\n\n@conf\ndef ap_periph_boards(ctx):\n    return boards.get_ap_periph_boards()\n\nvehicles = ['antennatracker', 'blimp', 'copter', 'heli', 'plane', 'rover', 'sub']\n\ndef generate_tasklist(ctx, do_print=True):\n    boardlist = boards.get_boards_names()\n    ap_periph_targets = boards.get_ap_periph_boards()\n    tasks = []\n    with open(os.path.join(Context.top_dir, \"tasklist.json\"), \"w\") as tlist:\n        for board in boardlist:\n            task = {}\n            task['configure'] = board\n            if board in ap_periph_targets:\n                if 'sitl' not in board:\n                    # we only support AP_Periph and bootloader builds\n                    task['targets'] = ['AP_Periph', 'bootloader']\n                else:\n                    task['targets'] = ['AP_Periph']\n            elif 'iofirmware' in board:\n                task['targets'] = ['iofirmware', 'bootloader']\n            else:\n                if boards.is_board_based(board, boards.sitl):\n                    task['targets'] = vehicles + ['replay']\n                elif boards.is_board_based(board, boards.linux):\n                    task['targets'] = vehicles\n                else:\n                    task['targets'] = vehicles + ['bootloader']\n                    task['buildOptions'] = '--upload'\n            tasks.append(task)\n        tlist.write(json.dumps(tasks))\n        if do_print:\n            print(json.dumps(tasks))\n\ndef board(ctx):\n    env = ConfigSet.ConfigSet()\n    try:\n        p = os.path.join(Context.out_dir, Build.CACHE_DIR, Build.CACHE_SUFFIX)\n        env.load(p)\n    except:\n        print('No board currently configured')\n        return\n\n    print('Board configured to: {}'.format(env.BOARD))\n\ndef _build_cmd_tweaks(bld):\n    if bld.cmd == 'check-all':\n        bld.options.all_tests = True\n        bld.cmd = 'check'\n\n    if bld.cmd == 'check':\n        if not bld.env.HAS_GTEST:\n            bld.fatal('check: gtest library is required')\n        bld.options.clear_failed_tests = True\n\ndef _build_dynamic_sources(bld):\n    if not bld.env.BOOTLOADER:\n        bld(\n            features='mavgen',\n            source='modules/mavlink/message_definitions/v1.0/all.xml',\n            output_dir='libraries/GCS_MAVLink/include/mavlink/v2.0/',\n            name='mavlink',\n            # this below is not ideal, mavgen tool should set this, but that's not\n            # currently possible\n            export_includes=[\n            bld.bldnode.make_node('libraries').abspath(),\n            bld.bldnode.make_node('libraries/GCS_MAVLink').abspath(),\n            ],\n            )\n\n    if (bld.get_board().with_can or bld.env.HAL_NUM_CAN_IFACES) and not bld.env.AP_PERIPH:\n        bld(\n            features='dronecangen',\n            source=bld.srcnode.ant_glob('modules/DroneCAN/DSDL/[a-z]* libraries/AP_DroneCAN/dsdl/[a-z]*', dir=True, src=False),\n            output_dir='modules/DroneCAN/libcanard/dsdlc_generated/',\n            name='dronecan',\n            export_includes=[\n                bld.bldnode.make_node('modules/DroneCAN/libcanard/dsdlc_generated/include').abspath(),\n                bld.srcnode.find_dir('modules/DroneCAN/libcanard/').abspath(),\n                bld.srcnode.find_dir('libraries/AP_DroneCAN/canard/').abspath(),\n                ]\n            )\n    elif bld.env.AP_PERIPH:\n        bld(\n            features='dronecangen',\n            source=bld.srcnode.ant_glob('modules/DroneCAN/DSDL/* libraries/AP_DroneCAN/dsdl/*', dir=True, src=False),\n            output_dir='modules/DroneCAN/libcanard/dsdlc_generated/',\n            name='dronecan',\n            export_includes=[\n                bld.bldnode.make_node('modules/DroneCAN/libcanard/dsdlc_generated/include').abspath(),\n                bld.srcnode.find_dir('modules/DroneCAN/libcanard/').abspath(),\n            ]\n        )\n\n    if bld.env.ENABLE_DDS:\n        bld.recurse(\"libraries/AP_DDS\")\n\n    def write_version_header(tsk):\n        bld = tsk.generator.bld\n        return bld.write_version_header(tsk.outputs[0].abspath())\n\n    bld(\n        name='ap_version',\n        target='ap_version.h',\n        vars=['AP_VERSION_ITEMS'],\n        rule=write_version_header,\n    )\n\n    bld.env.prepend_value('INCLUDES', [\n        bld.bldnode.abspath(),\n    ])\n\ndef _build_common_taskgens(bld):\n    # NOTE: Static library with vehicle set to UNKNOWN, shared by all\n    # the tools and examples. This is the first step until the\n    # dependency on the vehicles is reduced. Later we may consider\n    # split into smaller pieces with well defined boundaries.\n    bld.ap_stlib(\n        name='ap',\n        ap_vehicle='UNKNOWN',\n        ap_libraries=bld.ap_get_all_libraries(),\n    )\n\n    if bld.env.HAS_GTEST:\n        bld.libgtest(cxxflags=['-include', 'ap_config.h'])\n\n    if bld.env.HAS_GBENCHMARK:\n        bld.libbenchmark()\n\ndef _build_recursion(bld):\n    common_dirs_patterns = [\n        # TODO: Currently each vehicle also generate its own copy of the\n        # libraries. Fix this, or at least reduce the amount of\n        # vehicle-dependent libraries.\n        '*',\n        'Tools/*',\n        'libraries/*/examples/*',\n        'libraries/*/tests',\n        'libraries/*/utility/tests',\n        'libraries/*/benchmarks',\n    ]\n\n    common_dirs_excl = [\n        'modules',\n        'libraries/AP_HAL_*',\n    ]\n\n    hal_dirs_patterns = [\n        'libraries/%s/tests',\n        'libraries/%s/*/tests',\n        'libraries/%s/*/benchmarks',\n        'libraries/%s/examples/*',\n    ]\n\n    dirs_to_recurse = collect_dirs_to_recurse(\n        bld,\n        common_dirs_patterns,\n        excl=common_dirs_excl,\n    )\n    if bld.env.IOMCU_FW is not None:\n        if bld.env.IOMCU_FW:\n            dirs_to_recurse.append('libraries/AP_IOMCU/iofirmware')\n\n    if bld.env.PERIPH_FW is not None:\n        if bld.env.PERIPH_FW:\n            dirs_to_recurse.append('Tools/AP_Periph')\n\n    dirs_to_recurse.append('libraries/AP_Scripting')\n\n    if bld.env.ENABLE_ONVIF:\n        dirs_to_recurse.append('libraries/AP_ONVIF')\n\n    for p in hal_dirs_patterns:\n        dirs_to_recurse += collect_dirs_to_recurse(\n            bld,\n            [p % l for l in bld.env.AP_LIBRARIES],\n        )\n\n    # NOTE: we need to sort to ensure the repeated sources get the\n    # same index, and random ordering of the filesystem doesn't cause\n    # recompilation.\n    dirs_to_recurse.sort()\n\n    for d in dirs_to_recurse:\n        bld.recurse(d)\n\ndef _build_post_funs(bld):\n    if bld.cmd == 'check':\n        bld.add_post_fun(ardupilotwaf.test_summary)\n    else:\n        bld.build_summary_post_fun()\n\n    if bld.env.SUBMODULE_UPDATE:\n        bld.git_submodule_post_fun()\n\ndef _load_pre_build(bld):\n    '''allow for a pre_build() function in build modules'''\n    if bld.cmd == 'clean':\n        return\n    brd = bld.get_board()\n    if getattr(brd, 'pre_build', None):\n        brd.pre_build(bld)    \n\ndef build(bld):\n    config_hash = Utils.h_file(bld.bldnode.make_node('ap_config.h').abspath())\n    bld.env.CCDEPS = config_hash\n    bld.env.CXXDEPS = config_hash\n\n    bld.post_mode = Build.POST_LAZY\n\n    bld.load('ardupilotwaf')\n\n    bld.env.AP_LIBRARIES_OBJECTS_KW.update(\n        use=['mavlink'],\n        cxxflags=['-include', 'ap_config.h'],\n    )\n\n    _load_pre_build(bld)\n\n    if bld.get_board().with_can:\n        bld.env.AP_LIBRARIES_OBJECTS_KW['use'] += ['dronecan']\n\n    _build_cmd_tweaks(bld)\n\n    if bld.env.SUBMODULE_UPDATE:\n        bld.add_group('git_submodules')\n        for name in bld.env.GIT_SUBMODULES:\n            bld.git_submodule(name)\n\n    bld.add_group('dynamic_sources')\n    _build_dynamic_sources(bld)\n\n    bld.add_group('build')\n    bld.get_board().build(bld)\n    _build_common_taskgens(bld)\n\n    _build_recursion(bld)\n\n    _build_post_funs(bld)\n\nardupilotwaf.build_command('check',\n    program_group_list='all',\n    doc='builds all programs and run tests',\n)\nardupilotwaf.build_command('check-all',\n    program_group_list='all',\n    doc='shortcut for `waf check --alltests`',\n)\n\nfor name in (vehicles + ['bootloader','iofirmware','AP_Periph','replay']):\n    ardupilotwaf.build_command(name,\n        program_group_list=name,\n        doc='builds %s programs' % name,\n    )\n\nfor program_group in ('all', 'bin', 'tool', 'examples', 'tests', 'benchmarks'):\n    ardupilotwaf.build_command(program_group,\n        program_group_list=program_group,\n        doc='builds all programs of %s group' % program_group,\n    )\n\nclass LocalInstallContext(Build.InstallContext):\n    \"\"\"runs install using BLD/install as destdir, where BLD is the build variant directory\"\"\"\n    cmd = 'localinstall'\n\n    def __init__(self, **kw):\n        super(LocalInstallContext, self).__init__(**kw)\n        self.local_destdir = os.path.join(self.variant_dir, 'install')\n\n    def execute(self):\n        old_destdir = self.options.destdir\n        self.options.destdir = self.local_destdir\n        r = super(LocalInstallContext, self).execute()\n        self.options.destdir = old_destdir\n        return r\n\nclass RsyncContext(LocalInstallContext):\n    \"\"\"runs localinstall and then rsyncs BLD/install with the target system\"\"\"\n    cmd = 'rsync'\n\n    def __init__(self, **kw):\n        super(RsyncContext, self).__init__(**kw)\n        self.add_pre_fun(RsyncContext.create_rsync_taskgen)\n\n    def create_rsync_taskgen(self):\n        if 'RSYNC' not in self.env:\n            self.fatal('rsync program seems not to be installed, can\\'t continue')\n\n        self.add_group()\n\n        tg = self(\n            name='rsync',\n            rule='${RSYNC} -a ${RSYNC_SRC}/ ${RSYNC_DEST}',\n            always=True,\n        )\n\n        tg.env.RSYNC_SRC = self.local_destdir\n        if self.options.rsync_dest:\n            self.env.RSYNC_DEST = self.options.rsync_dest\n\n        if 'RSYNC_DEST' not in tg.env:\n            self.fatal('Destination for rsync not defined. Either pass --rsync-dest here or during configuration.')\n\n        tg.post()\n"
        }
      ]
    }
  ]
}