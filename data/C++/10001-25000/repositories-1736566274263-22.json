{
  "metadata": {
    "timestamp": 1736566274263,
    "page": 22,
    "hasNextPage": true,
    "endCursor": "Y3Vyc29yOjMw",
    "completionStatus": "IN_PROGRESS"
  },
  "repositories": [
    {
      "nameWithOwner": "Tencent/ncnn",
      "stars": 20781,
      "defaultBranch": "master",
      "files": [
        {
          "name": ".astylerc",
          "type": "blob",
          "size": 0.6083984375,
          "content": "# astyle -n -r \"benchmark/*.h,*.cpp\" \"src/*.h,*.cpp\" \"tests/*.h,*.cpp\" \"tools/*.h,*.cpp\" \"examples/*.h,*.cpp\"\n\n# brace style\n--style=allman\n\n# tab\n--attach-namespaces\n--attach-extern-c\n--attach-closing-while\n\n# indentation\n--indent-preproc-define\n--indent-col1-comments\n--min-conditional-indent=0\n--max-continuation-indent=120\n\n# padding\n--pad-oper\n--pad-comma\n--pad-header\n--align-pointer=type\n--align-reference=type\n\n# formatting\n--break-closing-braces\n--attach-return-type\n--attach-return-type-decl\n--keep-one-line-blocks\n--keep-one-line-statements\n--convert-tabs\n--max-code-length=200\n--mode=c\n\n# other\n--lineend=linux\n"
        },
        {
          "name": ".ci",
          "type": "tree",
          "content": null
        },
        {
          "name": ".clang-format",
          "type": "blob",
          "size": 3.65625,
          "content": "# find src/ tools/ tests/ examples/ benchmark/ -type f -name '*.c' -o -name '*.cpp' -o -name '*.h' | xargs -i clang-format -i {}\n\n# need clang-format >= 10.0\n\nAccessModifierOffset: -4\nAlignAfterOpenBracket: Align\nAlignConsecutiveAssignments: false\n# AlignConsecutiveBitFields: true\nAlignConsecutiveDeclarations: false\nAlignConsecutiveMacros: true\nAlignEscapedNewlines: Left\n# AlignOperands: AlignAfterOperator\nAlignTrailingComments: true\nAllowAllArgumentsOnNextLine: true\nAllowAllConstructorInitializersOnNextLine: true\nAllowAllParametersOfDeclarationOnNextLine: true\nAllowShortBlocksOnASingleLine: Always\nAllowShortCaseLabelsOnASingleLine: true\n# AllowShortEnumsOnASingleLine: true\nAllowShortFunctionsOnASingleLine: None\nAllowShortIfStatementsOnASingleLine: WithoutElse\nAllowShortLambdasOnASingleLine: All\nAllowShortLoopsOnASingleLine: true\nAlwaysBreakAfterReturnType: None\nAlwaysBreakBeforeMultilineStrings: false\nAlwaysBreakTemplateDeclarations: Yes\nBinPackArguments: true\nBinPackParameters: true\nBraceWrapping:\n  AfterCaseLabel: true\n  AfterClass: true\n  AfterControlStatement: Always\n  AfterEnum: true\n  AfterFunction: true\n  AfterNamespace: false\n  AfterObjCDeclaration: false\n  AfterStruct: true\n  AfterUnion: true\n  AfterExternBlock: false\n  BeforeCatch: true\n  BeforeElse: true\n#  BeforeLambdaBody: false\n#  BeforeWhile: false\n  IndentBraces: false\n  SplitEmptyFunction: true\n  SplitEmptyRecord: true\n  SplitEmptyNamespace: false\nBreakAfterJavaFieldAnnotations: true\nBreakBeforeBinaryOperators: All\nBreakBeforeBraces: Custom\nBreakBeforeTernaryOperators: true\nBreakConstructorInitializers: BeforeColon\nBreakInheritanceList: BeforeColon\nBreakStringLiterals: false\nColumnLimit: 0\n# CommentPragmas:\nCompactNamespaces: false\nConstructorInitializerAllOnOneLineOrOnePerLine: true\nConstructorInitializerIndentWidth: 4\nContinuationIndentWidth: 4\nCpp11BracedListStyle: true\nDeriveLineEnding: false\nDerivePointerAlignment: false\n# DisableFormat:\n# ExperimentalAutoDetectBinPacking:\nFixNamespaceComments: true\n# ForEachMacros:\nIncludeBlocks: Regroup\n# IncludeCategories:\n# IncludeIsMainRegex:\n# IncludeIsMainSourceRegex:\n# IndentCaseBlocks: false\nIndentCaseLabels: false\n# IndentExternBlock: NoIndent\nIndentGotoLabels: false\nIndentPPDirectives: None\nIndentWidth: 4\n# IndentWrappedFunctionNames: 4\n# InsertTrailingCommas: None\n# JavaImportGroups:\n# JavaScriptQuotes\n# JavaScriptWrapImports:\nKeepEmptyLinesAtTheStartOfBlocks: false\nLanguage: Cpp\n# MacroBlockBegin:\n# MacroBlockEnd:\nMaxEmptyLinesToKeep: 1\nNamespaceIndentation: None\n# NamespaceMacros:\n# ObjCBinPackProtocolList:\n# ObjCBlockIndentWidth:\n# ObjCBreakBeforeNestedBlockParam:\n# ObjCSpaceAfterProperty:\n# ObjCSpaceBeforeProtocolList:\n# PenaltyBreakAssignment:\n# PenaltyBreakBeforeFirstCallParameter:\n# PenaltyBreakComment:\n# PenaltyBreakFirstLessLess:\n# PenaltyBreakString:\n# PenaltyBreakTemplateDeclaration:\n# PenaltyExcessCharacter:\n# PenaltyReturnTypeOnItsOwnLine:\nPointerAlignment: Left\n# RawStringFormats:\nReflowComments: false\nSortIncludes: false\nSortUsingDeclarations: true\nSpaceAfterCStyleCast: false\nSpaceAfterLogicalNot: false\nSpaceAfterTemplateKeyword: false\nSpaceBeforeAssignmentOperators: true\nSpaceBeforeCpp11BracedList: false\nSpaceBeforeCtorInitializerColon: true\nSpaceBeforeInheritanceColon: true\nSpaceBeforeParens: ControlStatements\nSpaceBeforeRangeBasedForLoopColon: true\nSpaceBeforeSquareBrackets: false\nSpaceInEmptyBlock: false\nSpaceInEmptyParentheses: false\nSpacesBeforeTrailingComments: 1\nSpacesInAngles: false\nSpacesInCStyleCastParentheses: false\nSpacesInConditionalStatement: false\nSpacesInContainerLiterals: false\nSpacesInParentheses: false\nSpacesInSquareBrackets: false\nStandard: c++03\n#StatementMacros:\nTabWidth: 4\n# TypenameMacros:\nUseCRLF: false\nUseTab: Never\n"
        },
        {
          "name": ".gitattributes",
          "type": "blob",
          "size": 0.029296875,
          "content": "*.comp linguist-language=GLSL\n"
        },
        {
          "name": ".github",
          "type": "tree",
          "content": null
        },
        {
          "name": ".gitignore",
          "type": "blob",
          "size": 0.5185546875,
          "content": "# CMake build directory\nbuild*/\n\n# Backup files.\n*~\n\n# Prerequisites\n*.d\n\n# Compiled Object files\n*.slo\n*.lo\n*.o\n*.obj\n\n# Precompiled Headers\n*.gch\n*.pch\n\n# Compiled Dynamic libraries\n*.so\n*.dylib\n*.dll\n\n# Fortran module files\n*.mod\n*.smod\n\n# Compiled Static libraries\n*.lai\n*.la\n*.a\n*.lib\n\n# Executables\n*.exe\n*.out\n*.app\n\n# MACOSX\n.DS_Store\n\n# IDE\n.vs\n.vscode\n.idea\ncmake-build-debug\ncmake-build-release\nCMakeSettings.json\n\n# Compiled python\n__pycache__\n*.pyc\n*.pyd\n*.egg-info/\npython/setup.py\n\n# Clangd\n.cache/\n\n# Xmake\n.xmake/\n"
        },
        {
          "name": ".gitmodules",
          "type": "blob",
          "size": 0.1806640625,
          "content": "[submodule \"glslang\"]\n\tpath = glslang\n\turl = https://github.com/KhronosGroup/glslang\n[submodule \"python/pybind11\"]\n\tpath = python/pybind11\n\turl = https://github.com/pybind/pybind11.git\n"
        },
        {
          "name": "CITATION.cff",
          "type": "blob",
          "size": 0.6435546875,
          "content": "cff-version: 1.2.0\ntitle: ncnn\nmessage: >-\n  If you use this software, please cite it using the\n  metadata from this file.\ntype: software\nauthors:\n  - family-names: \"Ni\"\n    given-names: \"Hui\"\n  - name: \"The ncnn contributors\"\nabstract: >-\n  ncnn is a high-performance neural network inference\n  computing framework optimized for mobile platforms. \ndate-released: 2017-06-30\nkeywords:\n  - \"neural network\"\n  - \"artificial intelligence\"\n  - \"deep learning\"\n  - android\n  - ios\n  - windows\n  - linux\n  - macos\n  - pnnx\n  - simd\n  - vulkan\n  - riscv\n  - x86\n  - arm\n  - mips\n  - loongarch\nlicense: BSD-3-Clause\nrepository-code: \"https://github.com/Tencent/ncnn\"\n"
        },
        {
          "name": "CMakeLists.txt",
          "type": "blob",
          "size": 47.75,
          "content": "if(CMAKE_TOOLCHAIN_FILE)\n    set(LIBRARY_OUTPUT_PATH_ROOT ${CMAKE_BINARY_DIR} CACHE PATH \"root for library output, set this to change where android libs are compiled to\")\n    # get absolute path, but get_filename_component ABSOLUTE only refer with source dir, so find_file here :(\n    get_filename_component(CMAKE_TOOLCHAIN_FILE_NAME ${CMAKE_TOOLCHAIN_FILE} NAME)\n    find_file(CMAKE_TOOLCHAIN_FILE ${CMAKE_TOOLCHAIN_FILE_NAME} PATHS ${CMAKE_SOURCE_DIR} NO_DEFAULT_PATH)\n    message(STATUS \"CMAKE_TOOLCHAIN_FILE = ${CMAKE_TOOLCHAIN_FILE}\")\nendif()\n\nif(NOT DEFINED CMAKE_INSTALL_PREFIX)\n    set(CMAKE_INSTALL_PREFIX \"${CMAKE_BINARY_DIR}/install\" CACHE PATH \"Installation Directory\")\nendif()\nmessage(STATUS \"CMAKE_INSTALL_PREFIX = ${CMAKE_INSTALL_PREFIX}\")\n\nif(NOT DEFINED NCNN_VERSION)\n    string(TIMESTAMP NCNN_VERSION \"%Y%m%d\")\nendif()\n\nset(NCNN_VERSION_MAJOR 1)\nset(NCNN_VERSION_MINOR 0)\nset(NCNN_VERSION_PATCH ${NCNN_VERSION})\nset(NCNN_VERSION_STRING ${NCNN_VERSION_MAJOR}.${NCNN_VERSION_MINOR}.${NCNN_VERSION_PATCH})\nmessage(STATUS \"NCNN_VERSION_STRING = ${NCNN_VERSION_STRING}\")\n\ncmake_minimum_required(VERSION 2.8.12)\n\nif(NOT CMAKE_BUILD_TYPE)\n    set(CMAKE_BUILD_TYPE release CACHE STRING \"Choose the type of build\" FORCE)\nendif()\n\nif(NOT CMAKE_VERSION VERSION_LESS \"3.15\")\n    # enable CMAKE_MSVC_RUNTIME_LIBRARY\n    cmake_policy(SET CMP0091 NEW)\nendif()\n\nif(POLICY CMP0025)\n    # reference from https://cmake.org/cmake/help/latest/policy/CMP0025.html\n    cmake_policy(SET CMP0025 NEW)\nendif()\n\nif(POLICY CMP0057)\n    # reference from https://cmake.org/cmake/help/latest/policy/CMP0057.html\n    cmake_policy(SET CMP0057 NEW)\nendif()\n\nproject(ncnn)\n\nif(MSVC AND NOT CMAKE_VERSION VERSION_LESS \"3.15\")\n    option(NCNN_BUILD_WITH_STATIC_CRT \"Enables use of statically linked CRT for statically linked ncnn\" OFF)\n    if(NCNN_BUILD_WITH_STATIC_CRT)\n        # cmake before version 3.15 not work\n        set(CMAKE_MSVC_RUNTIME_LIBRARY \"MultiThreaded$<$<CONFIG:Debug>:Debug>\")\n    endif()\nendif()\n\noption(NCNN_SHARED_LIB \"shared library support\" OFF)\noption(NCNN_ENABLE_LTO \"enable link-time optimization\" OFF)\noption(NCNN_OPENMP \"openmp support\" ON)\noption(NCNN_STDIO \"load model from external file\" ON)\noption(NCNN_STRING \"plain and verbose string\" ON)\noption(NCNN_INSTALL_SDK \"install ncnn library and headers\" ON)\noption(NCNN_SIMPLEOCV \"minimal opencv structure emulation\" OFF)\noption(NCNN_SIMPLEOMP \"minimal openmp runtime emulation\" OFF)\noption(NCNN_SIMPLESTL \"minimal cpp stl structure emulation\" OFF)\noption(NCNN_SIMPLEMATH \"minimal cmath\" OFF)\noption(NCNN_THREADS \"build with threads\" ON)\noption(NCNN_BENCHMARK \"print benchmark information for every layer\" OFF)\noption(NCNN_C_API \"build with C api\" ON)\noption(NCNN_PLATFORM_API \"build with platform api candy\" ON)\noption(NCNN_PIXEL \"convert and resize from/to image pixel\" ON)\noption(NCNN_PIXEL_ROTATE \"rotate image pixel orientation\" ON)\noption(NCNN_PIXEL_AFFINE \"warp affine image pixel\" ON)\noption(NCNN_PIXEL_DRAWING \"draw basic figure and text\" ON)\noption(NCNN_CMAKE_VERBOSE \"print verbose cmake messages\" OFF)\noption(NCNN_VULKAN \"vulkan compute support\" OFF)\noption(NCNN_SIMPLEVK \"minimal in-house vulkan loader\" ON)\noption(NCNN_SYSTEM_GLSLANG \"use system glslang library\" OFF)\noption(NCNN_RUNTIME_CPU \"runtime dispatch cpu routines\" ON)\noption(NCNN_DISABLE_PIC \"disable position-independent code\" OFF)\noption(NCNN_BUILD_TESTS \"build tests\" OFF)\noption(NCNN_COVERAGE \"build for coverage\" OFF)\noption(NCNN_ASAN \"build for address sanitizer\" OFF)\noption(NCNN_BUILD_BENCHMARK \"build benchmark\" ON)\noption(NCNN_PYTHON \"build python api\" OFF)\noption(NCNN_INT8 \"int8 inference\" ON)\noption(NCNN_BF16 \"bf16 inference\" ON)\noption(NCNN_FORCE_INLINE \"force inline some function\" ON)\n\nif(ANDROID OR IOS OR NCNN_SIMPLESTL)\n    option(NCNN_DISABLE_RTTI \"disable rtti\" ON)\n    option(NCNN_DISABLE_EXCEPTION \"disable exception\" ON)\nelse()\n    option(NCNN_DISABLE_RTTI \"disable rtti\" OFF)\n    option(NCNN_DISABLE_EXCEPTION \"disable exception\" OFF)\nendif()\n\nif(ANDROID OR IOS OR NCNN_SIMPLESTL OR CMAKE_CROSSCOMPILING)\n    option(NCNN_BUILD_TOOLS \"build tools\" OFF)\n    option(NCNN_BUILD_EXAMPLES \"build examples\" OFF)\nelse()\n    option(NCNN_BUILD_TOOLS \"build tools\" ON)\n    option(NCNN_BUILD_EXAMPLES \"build examples\" ON)\nendif()\n\nif(NCNN_SHARED_LIB)\n    if(NCNN_ENABLE_LTO)\n        # enable global link time optimization\n        cmake_policy(SET CMP0069 NEW)\n        set(CMAKE_POLICY_DEFAULT_CMP0069 NEW)\n        include(CheckIPOSupported)\n        check_ipo_supported(RESULT ipo_supported OUTPUT ipo_supported_output)\n        if(ipo_supported)\n            set(CMAKE_INTERPROCEDURAL_OPTIMIZATION TRUE)\n        else()\n            message(WARNING \"IPO is not supported: ${ipo_supported_output}\")\n            set(NCNN_ENABLE_LTO OFF)\n        endif()\n    endif()\nendif()\n\nif(NOT NCNN_STDIO OR NOT NCNN_STRING)\n    if(NCNN_BUILD_TOOLS)\n        message(WARNING \"NCNN_STDIO or NCNN_STRING disabled, NCNN_BUILD_TOOLS will be turned off.\")\n        set(NCNN_BUILD_TOOLS OFF)\n    endif()\n    if(NCNN_BUILD_EXAMPLES)\n        message(WARNING \"NCNN_STDIO or NCNN_STRING disabled, NCNN_BUILD_EXAMPLES will be turned off.\")\n        set(NCNN_BUILD_EXAMPLES OFF)\n    endif()\n    if(NCNN_BUILD_BENCHMARK)\n        message(WARNING \"NCNN_STDIO or NCNN_STRING disabled, NCNN_BUILD_BENCHMARK will be turned off.\")\n        set(NCNN_BUILD_BENCHMARK OFF)\n    endif()\n    if(NCNN_BUILD_TESTS)\n        message(WARNING \"NCNN_STDIO or NCNN_STRING disabled, NCNN_BUILD_TESTS will be turned off.\")\n        set(NCNN_BUILD_TESTS OFF)\n    endif()\nendif()\n\n##############################################\n\ninclude(CheckCXXCompilerFlag)\nset(CMAKE_TRY_COMPILE_CONFIGURATION release)\nset(CMAKE_TRY_COMPILE_TARGET_TYPE STATIC_LIBRARY)\n\n# gnu inline assembly in clang msvc does not work actually\nif(NOT (CMAKE_CXX_COMPILER_ID MATCHES \"MSVC\" OR (CMAKE_CXX_COMPILER_ID MATCHES \"Clang\" AND CMAKE_CXX_SIMULATE_ID MATCHES \"MSVC\" AND CMAKE_CXX_COMPILER_FRONTEND_VARIANT MATCHES \"MSVC\")))\n    check_cxx_source_compiles(\"int test(int a) { asm volatile(\\\"\\\" : \\\"=r\\\"(a) : \\\"0\\\"(a) : \\\"memory\\\"); return a; }\" NCNN_COMPILER_SUPPORT_GNU_INLINE_ASM)\n    if(NCNN_COMPILER_SUPPORT_GNU_INLINE_ASM)\n        option(NCNN_GNU_INLINE_ASM \"optimize platform with gnu style inline assembly\" ON)\n    else()\n        message(WARNING \"The compiler does not support gnu style inline assembly. NCNN_GNU_INLINE_ASM will be OFF.\")\n    endif()\nendif()\n\nif((IOS AND CMAKE_OSX_ARCHITECTURES MATCHES \"arm\")\n    OR (APPLE AND CMAKE_OSX_ARCHITECTURES MATCHES \"arm64\")\n    OR (CMAKE_SYSTEM_PROCESSOR MATCHES \"^(arm|aarch64)\")\n    OR (CMAKE_CXX_COMPILER_ARCHITECTURE_ID MATCHES \"(ARMV7|ARM64)\")\n    OR ((CMAKE_CXX_COMPILER_ID MATCHES \"MSVC\" OR (CMAKE_CXX_COMPILER_ID MATCHES \"Clang\" AND CMAKE_CXX_SIMULATE_ID MATCHES \"MSVC\" AND CMAKE_CXX_COMPILER_FRONTEND_VARIANT MATCHES \"MSVC\")) AND (${CMAKE_GENERATOR_PLATFORM} MATCHES \"^(arm|arm64)\")))\n    set(NCNN_TARGET_ARCH arm)\n\n    if(APPLE AND CMAKE_OSX_ARCHITECTURES STREQUAL \"arm64_32\")\n        set(NCNN_TARGET_ILP32 TRUE)\n    endif()\n\n    if(CMAKE_SIZEOF_VOID_P EQUAL 4 AND NOT NCNN_TARGET_ILP32)\n        check_cxx_source_compiles(\"#include <arm_neon.h>\\nfloat32x4_t test(float32x4_t s, float32x4_t a, float32x4_t b) { return vmlaq_f32(s, a, b); }\" NCNN_COMPILER_SUPPORT_ARM_NEON)\n\n        if(NCNN_COMPILER_SUPPORT_ARM_NEON)\n            if(CMAKE_CXX_COMPILER_ID MATCHES \"MSVC\" OR (CMAKE_CXX_COMPILER_ID MATCHES \"Clang\" AND CMAKE_CXX_SIMULATE_ID MATCHES \"MSVC\" AND CMAKE_CXX_COMPILER_FRONTEND_VARIANT MATCHES \"MSVC\"))\n                set(CMAKE_REQUIRED_FLAGS \"/arch:VFPv4\")\n                check_cxx_source_compiles(\"#include <arm_neon.h>\\nfloat16x4_t test(float32x4_t a) { return vcvt_f16_f32(a); }\" NCNN_COMPILER_SUPPORT_ARM_VFPV4)\n\n                unset(CMAKE_REQUIRED_FLAGS)\n            else()\n                set(CMAKE_REQUIRED_FLAGS \"-mfpu=neon-vfpv4\")\n                check_cxx_source_compiles(\"#include <arm_neon.h>\\nfloat16x4_t test(float32x4_t a) { return vcvt_f16_f32(a); }\" NCNN_COMPILER_SUPPORT_ARM_VFPV4)\n\n                if(NOT NCNN_COMPILER_SUPPORT_ARM_VFPV4)\n                    set(CMAKE_REQUIRED_FLAGS \"-mfpu=neon-vfpv4 -mfp16-format=ieee\")\n                    check_cxx_source_compiles(\"#include <arm_neon.h>\\nfloat16x4_t test(float32x4_t a) { return vcvt_f16_f32(a); }\" NCNN_COMPILER_SUPPORT_ARM_VFPV4_FP16)\n                endif()\n\n                unset(CMAKE_REQUIRED_FLAGS)\n            endif()\n        endif()\n\n        if(NCNN_COMPILER_SUPPORT_ARM_VFPV4 OR NCNN_COMPILER_SUPPORT_ARM_VFPV4_FP16)\n            option(NCNN_VFPV4 \"optimize armv7 platform with vfpv4\" ON)\n        else()\n            message(WARNING \"The compiler does not support arm vfpv4. NCNN_VFPV4 will be OFF.\")\n        endif()\n    endif()\n\n    if(CMAKE_SIZEOF_VOID_P EQUAL 8 OR NCNN_TARGET_ILP32)\n        if(CMAKE_CXX_COMPILER_ID MATCHES \"MSVC\")\n            set(CMAKE_REQUIRED_FLAGS \"/arch:armv8.0\")\n            check_cxx_source_compiles(\"#include <arm_neon.h>\\nfloat16x4_t test(float32x4_t a) { return vcvt_f16_f32(a); }\" NCNN_COMPILER_SUPPORT_ARM_VFPV4)\n\n            set(CMAKE_REQUIRED_FLAGS \"/arch:armv8.2\")\n            check_cxx_source_compiles(\"#include <arm_neon.h>\\nfloat16x8_t test(float16x8_t s, float16x8_t a, float16x8_t b) { return vfmaq_f16(s, a, b); }\" NCNN_COMPILER_SUPPORT_ARM82_FP16)\n\n            set(CMAKE_REQUIRED_FLAGS \"/arch:armv8.2\")\n            check_cxx_source_compiles(\"#include <arm_neon.h>\\nint32x4_t test(int32x4_t s, int8x16_t a, int8x16_t b) { return vdotq_s32(s, a, b); }\" NCNN_COMPILER_SUPPORT_ARM82_DOTPROD)\n\n            set(CMAKE_REQUIRED_FLAGS \"/arch:armv8.2\")\n            check_cxx_source_compiles(\"#include <arm_neon.h>\\nfloat32x4_t test(float32x4_t s, float16x8_t a, float16x8_t b) { return vfmlalq_low_f16(s, a, b); }\" NCNN_COMPILER_SUPPORT_ARM82_FP16FML)\n\n            set(CMAKE_REQUIRED_FLAGS \"/arch:armv8.4\")\n            check_cxx_source_compiles(\"#include <arm_neon.h>\\nfloat32x4_t test(float32x4_t s, bfloat16x8_t a, bfloat16x8_t b) { return vcvt_f32_bf16(vcvt_bf16_f32(vbfmmlaq_f32(s, a, b))); }\" NCNN_COMPILER_SUPPORT_ARM84_BF16)\n\n            set(CMAKE_REQUIRED_FLAGS \"/arch:armv8.4\")\n            check_cxx_source_compiles(\"#include <arm_neon.h>\\nint32x4_t test(int32x4_t s, int8x16_t a, int8x16_t b) { return vmmlaq_s32(s, a, b); }\" NCNN_COMPILER_SUPPORT_ARM84_I8MM)\n\n            set(CMAKE_REQUIRED_FLAGS \"/arch:armv8.6\")\n            check_cxx_source_compiles(\"#include <arm_sve.h>\\nsvfloat16_t test(svfloat16_t s, svfloat16_t a, svfloat16_t b, svbool_t bp) { return svmla_f16_z(bp, s, a, b); }\" NCNN_COMPILER_SUPPORT_ARM86_SVE)\n\n            set(CMAKE_REQUIRED_FLAGS \"/arch:armv8.6\")\n            check_cxx_source_compiles(\"#include <arm_sve.h>\\nsvint16_t test(svint16_t s, svint8_t a, svint8_t b) { return svmlslb_s16(s, a, b); }\" NCNN_COMPILER_SUPPORT_ARM86_SVE2)\n\n            set(CMAKE_REQUIRED_FLAGS \"/arch:armv8.6\")\n            check_cxx_source_compiles(\"#include <arm_sve.h>\\nsvfloat32_t test(svfloat32_t s, svbfloat16_t a, svbfloat16_t b) { return svbfmmla_f32(s, a, b); }\" NCNN_COMPILER_SUPPORT_ARM86_SVEBF16)\n\n            set(CMAKE_REQUIRED_FLAGS \"/arch:armv8.6\")\n            check_cxx_source_compiles(\"#include <arm_sve.h>\\nsvint32_t test(svint32_t s, svint8_t a, svint8_t b) { return svmmla_s32(s, a, b); }\" NCNN_COMPILER_SUPPORT_ARM86_SVEI8MM)\n\n            set(CMAKE_REQUIRED_FLAGS \"/arch:armv8.6\")\n            check_cxx_source_compiles(\"#include <arm_sve.h>\\nsvfloat32_t test(svfloat32_t s, svfloat32_t a, svfloat32_t b) { return svmmla_f32(s, a, b); }\" NCNN_COMPILER_SUPPORT_ARM86_SVEF32MM)\n\n            unset(CMAKE_REQUIRED_FLAGS)\n        elseif(CMAKE_CXX_COMPILER_ID MATCHES \"Clang\" AND CMAKE_CXX_SIMULATE_ID MATCHES \"MSVC\" AND CMAKE_CXX_COMPILER_FRONTEND_VARIANT MATCHES \"MSVC\")\n            set(CMAKE_REQUIRED_FLAGS \"/arch:armv8.0\")\n            check_cxx_source_compiles(\"#include <arm_neon.h>\\nfloat16x4_t test(float32x4_t a) { return vcvt_f16_f32(a); }\" NCNN_COMPILER_SUPPORT_ARM_VFPV4)\n\n            set(CMAKE_REQUIRED_FLAGS \"/arch:armv8.2 -march=armv8.2-a+fp16\")\n            check_cxx_source_compiles(\"#include <arm_neon.h>\\nfloat16x8_t test(float16x8_t s, float16x8_t a, float16x8_t b) { return vfmaq_f16(s, a, b); }\" NCNN_COMPILER_SUPPORT_ARM82_FP16)\n\n            set(CMAKE_REQUIRED_FLAGS \"/arch:armv8.2 -march=armv8.2-a+dotprod\")\n            check_cxx_source_compiles(\"#include <arm_neon.h>\\nint32x4_t test(int32x4_t s, int8x16_t a, int8x16_t b) { return vdotq_s32(s, a, b); }\" NCNN_COMPILER_SUPPORT_ARM82_DOTPROD)\n\n            set(CMAKE_REQUIRED_FLAGS \"/arch:armv8.2 -march=armv8.2-a+fp16fml\")\n            check_cxx_source_compiles(\"#include <arm_neon.h>\\nfloat32x4_t test(float32x4_t s, float16x8_t a, float16x8_t b) { return vfmlalq_low_f16(s, a, b); }\" NCNN_COMPILER_SUPPORT_ARM82_FP16FML)\n\n            set(CMAKE_REQUIRED_FLAGS \"/arch:armv8.4 -march=armv8.4-a+bf16\")\n            check_cxx_source_compiles(\"#include <arm_neon.h>\\nfloat32x4_t test(float32x4_t s, bfloat16x8_t a, bfloat16x8_t b) { return vcvt_f32_bf16(vcvt_bf16_f32(vbfmmlaq_f32(s, a, b))); }\" NCNN_COMPILER_SUPPORT_ARM84_BF16)\n\n            set(CMAKE_REQUIRED_FLAGS \"/arch:armv8.4 -march=armv8.4-a+i8mm\")\n            check_cxx_source_compiles(\"#include <arm_neon.h>\\nint32x4_t test(int32x4_t s, int8x16_t a, int8x16_t b) { return vmmlaq_s32(s, a, b); }\" NCNN_COMPILER_SUPPORT_ARM84_I8MM)\n\n            set(CMAKE_REQUIRED_FLAGS \"/arch:armv8.6 -march=armv8.6-a+sve\")\n            check_cxx_source_compiles(\"#include <arm_sve.h>\\nsvfloat16_t test(svfloat16_t s, svfloat16_t a, svfloat16_t b, svbool_t bp) { return svmla_f16_z(bp, s, a, b); }\" NCNN_COMPILER_SUPPORT_ARM86_SVE)\n\n            set(CMAKE_REQUIRED_FLAGS \"/arch:armv8.6 -march=armv8.6-a+sve2\")\n            check_cxx_source_compiles(\"#include <arm_sve.h>\\nsvint16_t test(svint16_t s, svint8_t a, svint8_t b) { return svmlslb_s16(s, a, b); }\" NCNN_COMPILER_SUPPORT_ARM86_SVE2)\n\n            set(CMAKE_REQUIRED_FLAGS \"/arch:armv8.6 -march=armv8.6-a+sve+bf16\")\n            check_cxx_source_compiles(\"#include <arm_sve.h>\\nsvfloat32_t test(svfloat32_t s, svbfloat16_t a, svbfloat16_t b) { return svbfmmla_f32(s, a, b); }\" NCNN_COMPILER_SUPPORT_ARM86_SVEBF16)\n\n            set(CMAKE_REQUIRED_FLAGS \"/arch:armv8.6 -march=armv8.6-a+sve+i8mm\")\n            check_cxx_source_compiles(\"#include <arm_sve.h>\\nsvint32_t test(svint32_t s, svint8_t a, svint8_t b) { return svmmla_s32(s, a, b); }\" NCNN_COMPILER_SUPPORT_ARM86_SVEI8MM)\n\n            set(CMAKE_REQUIRED_FLAGS \"/arch:armv8.6 -march=armv8.6-a+sve+f32mm\")\n            check_cxx_source_compiles(\"#include <arm_sve.h>\\nsvfloat32_t test(svfloat32_t s, svfloat32_t a, svfloat32_t b) { return svmmla_f32(s, a, b); }\" NCNN_COMPILER_SUPPORT_ARM86_SVEF32MM)\n\n            unset(CMAKE_REQUIRED_FLAGS)\n        else()\n            set(CMAKE_REQUIRED_FLAGS \"-march=armv8-a\")\n            check_cxx_source_compiles(\"#include <arm_neon.h>\\nfloat16x4_t test(float32x4_t a) { return vcvt_f16_f32(a); }\" NCNN_COMPILER_SUPPORT_ARM_VFPV4)\n\n            set(CMAKE_REQUIRED_FLAGS \"-march=armv8.2-a+fp16\")\n            check_cxx_source_compiles(\"#include <arm_neon.h>\\nfloat16x8_t test(float16x8_t s, float16x8_t a, float16x8_t b) { return vfmaq_f16(s, a, b); }\" NCNN_COMPILER_SUPPORT_ARM82_FP16)\n\n            set(CMAKE_REQUIRED_FLAGS \"-march=armv8.2-a+dotprod\")\n            check_cxx_source_compiles(\"#include <arm_neon.h>\\nint32x4_t test(int32x4_t s, int8x16_t a, int8x16_t b) { return vdotq_s32(s, a, b); }\" NCNN_COMPILER_SUPPORT_ARM82_DOTPROD)\n\n            set(CMAKE_REQUIRED_FLAGS \"-march=armv8.2-a+fp16fml\")\n            check_cxx_source_compiles(\"#include <arm_neon.h>\\nfloat32x4_t test(float32x4_t s, float16x8_t a, float16x8_t b) { return vfmlalq_low_f16(s, a, b); }\" NCNN_COMPILER_SUPPORT_ARM82_FP16FML)\n\n            set(CMAKE_REQUIRED_FLAGS \"-march=armv8.4-a+bf16\")\n            check_cxx_source_compiles(\"#include <arm_neon.h>\\nfloat32x4_t test(float32x4_t s, bfloat16x8_t a, bfloat16x8_t b) { return vcvt_f32_bf16(vcvt_bf16_f32(vbfmmlaq_f32(s, a, b))); }\" NCNN_COMPILER_SUPPORT_ARM84_BF16)\n\n            set(CMAKE_REQUIRED_FLAGS \"-march=armv8.4-a+i8mm\")\n            check_cxx_source_compiles(\"#include <arm_neon.h>\\nint32x4_t test(int32x4_t s, int8x16_t a, int8x16_t b) { return vmmlaq_s32(s, a, b); }\" NCNN_COMPILER_SUPPORT_ARM84_I8MM)\n\n            set(CMAKE_REQUIRED_FLAGS \"-march=armv8.6-a+sve\")\n            check_cxx_source_compiles(\"#include <arm_sve.h>\\nsvfloat16_t test(svfloat16_t s, svfloat16_t a, svfloat16_t b, svbool_t bp) { return svmla_f16_z(bp, s, a, b); }\" NCNN_COMPILER_SUPPORT_ARM86_SVE)\n\n            set(CMAKE_REQUIRED_FLAGS \"-march=armv8.6-a+sve2\")\n            check_cxx_source_compiles(\"#include <arm_sve.h>\\nsvint16_t test(svint16_t s, svint8_t a, svint8_t b) { return svmlslb_s16(s, a, b); }\" NCNN_COMPILER_SUPPORT_ARM86_SVE2)\n\n            set(CMAKE_REQUIRED_FLAGS \"-march=armv8.6-a+sve+bf16\")\n            check_cxx_source_compiles(\"#include <arm_sve.h>\\nsvfloat32_t test(svfloat32_t s, svbfloat16_t a, svbfloat16_t b) { return svbfmmla_f32(s, a, b); }\" NCNN_COMPILER_SUPPORT_ARM86_SVEBF16)\n\n            set(CMAKE_REQUIRED_FLAGS \"-march=armv8.6-a+sve+i8mm\")\n            check_cxx_source_compiles(\"#include <arm_sve.h>\\nsvint32_t test(svint32_t s, svint8_t a, svint8_t b) { return svmmla_s32(s, a, b); }\" NCNN_COMPILER_SUPPORT_ARM86_SVEI8MM)\n\n            set(CMAKE_REQUIRED_FLAGS \"-march=armv8.6-a+sve+f32mm\")\n            check_cxx_source_compiles(\"#include <arm_sve.h>\\nsvfloat32_t test(svfloat32_t s, svfloat32_t a, svfloat32_t b) { return svmmla_f32(s, a, b); }\" NCNN_COMPILER_SUPPORT_ARM86_SVEF32MM)\n\n            unset(CMAKE_REQUIRED_FLAGS)\n        endif()\n\n        if(NCNN_COMPILER_SUPPORT_ARM_VFPV4)\n            option(NCNN_VFPV4 \"optimize aarch64 platform with vfpv4\" ON)\n        else()\n            message(WARNING \"The compiler does not support arm vfpv4. NCNN_VFPV4 will be OFF.\")\n        endif()\n\n        if(NCNN_COMPILER_SUPPORT_ARM82_FP16)\n            option(NCNN_ARM82 \"optimize aarch64 platform with armv8.2 fp16\" ON)\n            if(NCNN_COMPILER_SUPPORT_ARM82_DOTPROD)\n                if(NCNN_ARM82)\n                    option(NCNN_ARM82DOT \"optimize aarch64 platform with armv8.2 dotprod\" ON)\n                endif()\n            else()\n                message(WARNING \"The compiler does not support armv8.2 dotprod. NCNN_ARM82DOT will be OFF.\")\n            endif()\n            if(NCNN_COMPILER_SUPPORT_ARM82_FP16FML)\n                if(NCNN_ARM82)\n                    option(NCNN_ARM82FP16FML \"optimize aarch64 platform with armv8.2 fp16fml\" ON)\n                endif()\n            else()\n                message(WARNING \"The compiler does not support armv8.2 fp16fml. NCNN_ARM82FP16FML will be OFF.\")\n            endif()\n            if(NCNN_COMPILER_SUPPORT_ARM84_BF16)\n                if(NCNN_ARM82DOT AND NCNN_ARM82FP16FML)\n                    option(NCNN_ARM84BF16 \"optimize aarch64 platform with armv8.4 bf16\" ON)\n                endif()\n            else()\n                message(WARNING \"The compiler does not support armv8.4 bf16. NCNN_ARM86BF16 will be OFF.\")\n            endif()\n            if(NCNN_COMPILER_SUPPORT_ARM84_I8MM)\n                if(NCNN_ARM82DOT AND NCNN_ARM82FP16FML)\n                    option(NCNN_ARM84I8MM \"optimize aarch64 platform with armv8.4 i8mm\" ON)\n                endif()\n            else()\n                message(WARNING \"The compiler does not support armv8.4 i8mm. NCNN_ARM84I8MM will be OFF.\")\n            endif()\n            if(NCNN_COMPILER_SUPPORT_ARM86_SVE)\n                if(NCNN_ARM84BF16 AND NCNN_ARM84I8MM)\n                    option(NCNN_ARM86SVE \"optimize aarch64 platform with armv8.6 sve\" ON)\n                    if(NCNN_COMPILER_SUPPORT_ARM86_SVE2)\n                        if(NCNN_ARM86SVE)\n                            option(NCNN_ARM86SVE2 \"optimize aarch64 platform with armv8.6 sve2\" ON)\n                        endif()\n                    else()\n                        message(WARNING \"The compiler does not support armv8.6 sve2. NCNN_ARM86SVE2 will be OFF.\")\n                    endif()\n                    if(NCNN_COMPILER_SUPPORT_ARM86_SVEBF16)\n                        if(NCNN_ARM86SVE)\n                            option(NCNN_ARM86SVEBF16 \"optimize aarch64 platform with armv8.6 sve bf16\" ON)\n                        endif()\n                    else()\n                        message(WARNING \"The compiler does not support armv8.6 sve bf16. NCNN_ARM86SVEBF16 will be OFF.\")\n                    endif()\n                    if(NCNN_COMPILER_SUPPORT_ARM86_SVEI8MM)\n                        if(NCNN_ARM86SVE)\n                            option(NCNN_ARM86SVEI8MM \"optimize aarch64 platform with armv8.6 sve i8mm\" ON)\n                        endif()\n                    else()\n                        message(WARNING \"The compiler does not support armv8.6 sve i8mm. NCNN_ARM86SVEI8MM will be OFF.\")\n                    endif()\n                    if(NCNN_COMPILER_SUPPORT_ARM86_SVEF32MM)\n                        if(NCNN_ARM86SVE)\n                            option(NCNN_ARM86SVEF32MM \"optimize aarch64 platform with armv8.6 sve f32mm\" ON)\n                        endif()\n                    else()\n                        message(WARNING \"The compiler does not support armv8.6 sve f32mm. NCNN_ARM86SVEF32MM will be OFF.\")\n                    endif()\n                endif()\n            else()\n                message(WARNING \"The compiler does not support armv8.6 sve. NCNN_ARM86SVE will be OFF.\")\n            endif()\n        else()\n            message(WARNING \"The compiler does not support armv8.2 fp16. NCNN_ARM82 will be OFF.\")\n        endif()\n    endif()\nelseif(CMAKE_SYSTEM_PROCESSOR MATCHES \"^(mips)\")\n    set(NCNN_TARGET_ARCH mips)\n\n    check_cxx_compiler_flag(\"-mmsa\" NCNN_COMPILER_SUPPORT_MIPS_MSA)\n\n    set(CMAKE_REQUIRED_FLAGS \"-mloongson-mmi -I${CMAKE_CURRENT_SOURCE_DIR}/src/layer/mips\")\n    check_cxx_source_compiles(\"#include \\\"loongson_mmi.h\\\"\\nint32x2_t test(int16x4_t a, int16x4_t b) { return __mmi_pmaddhw(a, b); }\" NCNN_COMPILER_SUPPORT_LOONGSON_MMI)\n\n    unset(CMAKE_REQUIRED_FLAGS)\n\n    if(NCNN_COMPILER_SUPPORT_MIPS_MSA)\n        option(NCNN_MSA \"optimize mips platform with msa extension\" ON)\n    else()\n        message(WARNING \"The compiler does not support msa extension. NCNN_MSA will be OFF.\")\n    endif()\n    if(NCNN_COMPILER_SUPPORT_LOONGSON_MMI)\n        option(NCNN_MMI \"optimize mips platform with loongson mmi extension\" ON)\n    else()\n        message(WARNING \"The compiler does not support loongson mmi extension. NCNN_MMI will be OFF.\")\n    endif()\nelseif(CMAKE_SYSTEM_PROCESSOR MATCHES \"^(loongarch64|loongarch32)\")\n    set(NCNN_TARGET_ARCH loongarch)\n\n    set(CMAKE_REQUIRED_FLAGS \"-mlsx\")\n    check_cxx_source_compiles(\"#include <lsxintrin.h>\\n__m128 test(__m128 a, __m128 b, __m128 c) { return __lsx_vfmadd_s(a, b, c); }\" NCNN_COMPILER_SUPPORT_LOONGARCH_LSX)\n\n    set(CMAKE_REQUIRED_FLAGS \"-mlasx\")\n    check_cxx_source_compiles(\"#include <lasxintrin.h>\\n__m256 test(__m256 a, __m256 b, __m256 c) { return __lasx_xvfmadd_s(a, b, c); }\" NCNN_COMPILER_SUPPORT_LOONGARCH_LASX)\n\n    unset(CMAKE_REQUIRED_FLAGS)\n\n    if(NCNN_COMPILER_SUPPORT_LOONGARCH_LSX)\n        option(NCNN_LSX \"optimize loongarch platform with lsx extension\" ON)\n        if(NCNN_COMPILER_SUPPORT_LOONGARCH_LASX)\n            option(NCNN_LASX \"optimize loongarch platform with lasx extension\" ON)\n        else()\n            message(WARNING \"The compiler does not support lasx extension. NCNN_LASX will be OFF.\")\n        endif()\n    else()\n        message(WARNING \"The compiler does not support lsx extension. NCNN_LSX will be OFF.\")\n    endif()\n\nelseif(CMAKE_SYSTEM_PROCESSOR MATCHES \"^(riscv)\")\n    set(NCNN_TARGET_ARCH riscv)\n\n    if(CMAKE_SIZEOF_VOID_P EQUAL 8)\n        set(CMAKE_REQUIRED_FLAGS \"-march=rv64gcv\")\n        check_cxx_source_compiles(\"#include <riscv_vector.h>\\nvfloat32m8_t test(vfloat32m8_t s, vfloat32m8_t w, float v, size_t vl) { return __riscv_vfmacc_vf_f32m8(s, v, w, vl); }\\nvfloat32m1x2_t test2(vfloat32m1_t x) { return __riscv_vcreate_v_f32m1x2(x, x); }\" NCNN_COMPILER_SUPPORT_RISCV_V)\n\n        set(CMAKE_REQUIRED_FLAGS \"-march=rv64gc_zfh -D__fp16=_Float16\")\n        check_cxx_source_compiles(\"__fp16 test(__fp16 a) { return a * a; }\" NCNN_COMPILER_SUPPORT_RISCV_ZFH)\n\n        set(CMAKE_REQUIRED_FLAGS \"-march=rv64gcv_zfh_zvfh -D__fp16=_Float16\")\n        check_cxx_source_compiles(\"#include <riscv_vector.h>\\nvfloat16m8_t test(vfloat16m8_t s, vfloat16m8_t w, __fp16 v, size_t vl) { return __riscv_vfmacc_vf_f16m8(s, v, w, vl); }\\nvfloat16m1x2_t test2(vfloat16m1_t x){ return __riscv_vcreate_v_f16m1x2(x, x); }\" NCNN_COMPILER_SUPPORT_RISCV_ZVFH)\n\n        set(CMAKE_REQUIRED_FLAGS \"-march=rv64gc_zfh_xtheadvector -D__fp16=_Float16\")\n        check_cxx_source_compiles(\"#include <riscv_vector.h>\\nvfloat16m8_t test(vfloat16m8_t s, vfloat16m8_t w, __fp16 v, size_t vl) { return __riscv_vfmacc_vf_f16m8(s, v, w, vl); }\\nvfloat16m1x2_t test2(vfloat16m1_t x){ return __riscv_vcreate_v_f16m1x2(x, x); }\" NCNN_COMPILER_SUPPORT_RISCV_XTHEADVECTOR)\n\n        unset(CMAKE_REQUIRED_FLAGS)\n\n        if(NCNN_COMPILER_SUPPORT_RISCV_V OR NCNN_COMPILER_SUPPORT_RISCV_XTHEADVECTOR)\n            option(NCNN_RVV \"optimize risc-v platform with v extension\" ON)\n        else()\n            message(WARNING \"The compiler does not support risc-v v or xtheadvector extension. NCNN_RVV will be OFF.\")\n        endif()\n\n        if(NCNN_COMPILER_SUPPORT_RISCV_XTHEADVECTOR)\n            option(NCNN_XTHEADVECTOR \"optimize risc-v platform with xtheadvector extension\" ON)\n        else()\n            message(WARNING \"The compiler does not support risc-v xtheadvector extension. NCNN_XTHEADVECTOR will be OFF.\")\n        endif()\n\n        if(NCNN_COMPILER_SUPPORT_RISCV_ZFH)\n            option(NCNN_ZFH \"optimize risc-v platform with zfh extension\" ON)\n            if(NCNN_COMPILER_SUPPORT_RISCV_ZVFH OR NCNN_COMPILER_SUPPORT_RISCV_XTHEADVECTOR)\n                if(NCNN_RVV AND NCNN_ZFH)\n                    option(NCNN_ZVFH \"optimize risc-v platform with zvfh extension\" ON)\n                endif()\n            else()\n                message(WARNING \"The compiler does not support zvfh extension. NCNN_ZVFH will be OFF.\")\n            endif()\n        else()\n            message(WARNING \"The compiler does not support risc-v zfh extension. NCNN_ZFH will be OFF.\")\n        endif()\n\n    endif()\nelseif(CMAKE_SYSTEM_PROCESSOR MATCHES \"^(powerpc|ppc)\")\n    set(NCNN_TARGET_ARCH powerpc)\n\n    if(NCNN_PPC64LE_VSX)\n        set(NCNN_TARGET_ARCH x86)\n\n        set(CMAKE_REQUIRED_FLAGS \"-DNO_WARN_X86_INTRINSICS -D__SSE2__\")\n        check_cxx_source_compiles(\"#include <emmintrin.h>\\n__m128i test(__m128i a, __m128i b) { return _mm_madd_epi16(a, b); }\" NCNN_COMPILER_SUPPORT_PPC64LE_SSE2)\n        unset(CMAKE_REQUIRED_FLAGS)\n\n        set(CMAKE_REQUIRED_FLAGS \"-DNO_WARN_X86_INTRINSICS -D__SSE4_1__\")\n        check_cxx_source_compiles(\"#include <smmintrin.h>\\n__m128i test(__m128i a, __m128i b) { return _mm_packus_epi32(a, b); }\" NCNN_COMPILER_SUPPORT_PPC64LE_SSE41)\n        unset(CMAKE_REQUIRED_FLAGS)\n\n        if(NCNN_COMPILER_SUPPORT_PPC64LE_SSE2)\n            option(NCNN_VSX_SSE2 \"optimize ppc64le platform with sse2 extension\" ON)\n        else()\n            message(WARNING \"The compiler does not support sse2 extension. NCNN_VSX_SSE2 will be OFF.\")\n        endif()\n\n        if(NCNN_COMPILER_SUPPORT_PPC64LE_SSE41)\n            option(NCNN_VSX_SSE41 \"optimize ppc64le platform with sse4.1 extension\" ON)\n        else()\n            message(WARNING \"The compiler does not support sse4.1 extension. NCNN_VSX_SSE41 will be OFF.\")\n        endif()\n    endif()\nelseif(CMAKE_SYSTEM_PROCESSOR MATCHES \"^(xtensa)\")\n    set(NCNN_TARGET_ARCH xtensa)\nelseif(CMAKE_SYSTEM_PROCESSOR MATCHES \"^(s390x)\")\n    set(NCNN_TARGET_ARCH s390x)\nelseif(CMAKE_SYSTEM_PROCESSOR MATCHES \"^(sw_64)\")\n    set(NCNN_TARGET_ARCH sw_64)\n    #sw_64 is alpha-like platform\n    set(CMAKE_C_FLAGS \"${CMAKE_C_FLAGS} -mieee\")\n    set(CMAKE_CXX_FLAGS \"${CMAKE_CXX_FLAGS} -mieee\")\nelse()\n    set(NCNN_TARGET_ARCH x86)\n\n    option(NCNN_SSE2 \"optimize x86 platform with sse2 extension\" ON)\n\n    if(CMAKE_CXX_COMPILER_ID MATCHES \"MSVC\")\n        set(CMAKE_REQUIRED_FLAGS \"/arch:AVX\")\n        check_cxx_source_compiles(\"#include <immintrin.h>\\n__m256 test(__m256 a, __m256 b) { return _mm256_mul_ps(a, b); }\" NCNN_COMPILER_SUPPORT_X86_AVX)\n\n        set(CMAKE_REQUIRED_FLAGS \"/arch:AVX\")\n        check_cxx_source_compiles(\"#include <immintrin.h>\\n__m256 test(__m256 s, __m256 a, __m256 b) { return _mm256_fmadd_ps(a, b, s); }\" NCNN_COMPILER_SUPPORT_X86_FMA)\n\n        set(CMAKE_REQUIRED_FLAGS \"/arch:AVX\")\n        check_cxx_source_compiles(\"#include <immintrin.h>\\n#include <ammintrin.h>\\n__m128i test(__m128i s, __m128i a, __m128i b) { return _mm_maddd_epi16(a, b, s); }\" NCNN_COMPILER_SUPPORT_X86_XOP)\n\n        set(CMAKE_REQUIRED_FLAGS \"/arch:AVX\")\n        check_cxx_source_compiles(\"#include <immintrin.h>\\n__m256 test(__m128i a) { return _mm256_cvtph_ps(a); }\" NCNN_COMPILER_SUPPORT_X86_F16C)\n\n        set(CMAKE_REQUIRED_FLAGS \"/arch:AVX2\")\n        check_cxx_source_compiles(\"#include <immintrin.h>\\n__m256i test(__m256i a, __m256i b) { return _mm256_madd_epi16(a, b); }\" NCNN_COMPILER_SUPPORT_X86_AVX2)\n\n        set(CMAKE_REQUIRED_FLAGS \"/arch:AVX512\")\n        check_cxx_source_compiles(\"#include <immintrin.h>\\n__m512i test(__m512i a, __m512i b) { return _mm512_madd_epi16(a, b); }\" NCNN_COMPILER_SUPPORT_X86_AVX512)\n\n        set(CMAKE_REQUIRED_FLAGS \"/arch:AVX2\")\n        check_cxx_source_compiles(\"#include <immintrin.h>\\n__m256i test(__m256i s, __m256i a, __m256i b) { return _mm256_dpwssd_avx_epi32(s, a, b); }\" NCNN_COMPILER_SUPPORT_X86_AVX_VNNI)\n\n        set(CMAKE_REQUIRED_FLAGS \"/arch:AVX2\")\n        check_cxx_source_compiles(\"#include <immintrin.h>\\n__m256i test(__m256i s, __m256i a, __m256i b) { return _mm256_dpbssd_epi32(s, a, b); }\" NCNN_COMPILER_SUPPORT_X86_AVX_VNNI_INT8)\n\n        set(CMAKE_REQUIRED_FLAGS \"/arch:AVX2\")\n        check_cxx_source_compiles(\"#include <immintrin.h>\\n__m256i test(__m256i s, __m256i a, __m256i b) { return _mm256_dpwsud_avx_epi32(s, a, b); }\" NCNN_COMPILER_SUPPORT_X86_AVX_VNNI_INT16)\n\n        set(CMAKE_REQUIRED_FLAGS \"/arch:AVX2\")\n        check_cxx_source_compiles(\"#include <immintrin.h>\\n__m128bh test(__m256 a) { return _mm256_cvtneps_avx_pbh(a); }\" NCNN_COMPILER_SUPPORT_X86_AVX_NE_CONVERT)\n\n        set(CMAKE_REQUIRED_FLAGS \"/arch:AVX512\")\n        check_cxx_source_compiles(\"#include <immintrin.h>\\n__m512i test(__m512i s, __m512i a, __m512i b) { return _mm512_dpwssd_epi32(s, a, b); }\" NCNN_COMPILER_SUPPORT_X86_AVX512_VNNI)\n\n        set(CMAKE_REQUIRED_FLAGS \"/arch:AVX512\")\n        check_cxx_source_compiles(\"#include <immintrin.h>\\n__m256bh test(__m256bh s, __m512bh a, __m512bh b) { return _mm512_cvtneps_pbh(_mm512_dpbf16_ps(_mm512_cvtpbh_ps(s), a, b)); }\\n__m512i test2(__m512 a) { __m256i _a = (__m256i)_mm512_cvtneps_pbh(a); return _mm512_inserti32x8(_mm512_castsi256_si512(_a), _a, 1); }\" NCNN_COMPILER_SUPPORT_X86_AVX512_BF16)\n\n        set(CMAKE_REQUIRED_FLAGS \"/arch:AVX512\")\n        check_cxx_source_compiles(\"#include <immintrin.h>\\n__m512h test(__m512h s, __m512h a, __m512h b) { return _mm512_fmadd_ph(s, a, b); }\\n__m512 test2(__m512 a) { return _mm512_cvtxph_ps(_mm512_cvtxps_ph(a)); }\" NCNN_COMPILER_SUPPORT_X86_AVX512_FP16)\n\n        unset(CMAKE_REQUIRED_FLAGS)\n    elseif(CMAKE_CXX_COMPILER_ID MATCHES \"Clang\" AND CMAKE_CXX_SIMULATE_ID MATCHES \"MSVC\" AND CMAKE_CXX_COMPILER_FRONTEND_VARIANT MATCHES \"MSVC\")\n        check_cxx_compiler_flag(\"-mrecip=none\" NCNN_COMPILER_SUPPORT_X86_RECIP_NONE)\n\n        set(CMAKE_REQUIRED_FLAGS \"/arch:AVX\")\n        check_cxx_source_compiles(\"#include <immintrin.h>\\n__m256 test(__m256 a, __m256 b) { return _mm256_mul_ps(a, b); }\" NCNN_COMPILER_SUPPORT_X86_AVX)\n\n        set(CMAKE_REQUIRED_FLAGS \"/arch:AVX -mfma -mf16c\")\n        check_cxx_source_compiles(\"#include <immintrin.h>\\n__m256 test(__m256 s, __m256 a, __m256 b) { return _mm256_fmadd_ps(a, b, s); }\" NCNN_COMPILER_SUPPORT_X86_FMA)\n\n        set(CMAKE_REQUIRED_FLAGS \"/arch:AVX -mxop\")\n        check_cxx_source_compiles(\"#include <x86intrin.h>\\n__m128i test(__m128i s, __m128i a, __m128i b) { return _mm_maddd_epi16(a, b, s); }\" NCNN_COMPILER_SUPPORT_X86_XOP)\n\n        set(CMAKE_REQUIRED_FLAGS \"/arch:AVX -mf16c\")\n        check_cxx_source_compiles(\"#include <immintrin.h>\\n__m256 test(__m128i a) { return _mm256_cvtph_ps(a); }\" NCNN_COMPILER_SUPPORT_X86_F16C)\n\n        set(CMAKE_REQUIRED_FLAGS \"/arch:AVX2 -mfma -mf16c\")\n        check_cxx_source_compiles(\"#include <immintrin.h>\\n__m256i test(__m256i a, __m256i b) { return _mm256_madd_epi16(a, b); }\" NCNN_COMPILER_SUPPORT_X86_AVX2)\n\n        set(CMAKE_REQUIRED_FLAGS \"/arch:AVX512 -mfma -mf16c -mavx512cd -mavx512bw -mavx512dq -mavx512vl\")\n        check_cxx_source_compiles(\"#include <immintrin.h>\\n__m512i test(__m512i a, __m512i b) { return _mm512_madd_epi16(a, b); }\" NCNN_COMPILER_SUPPORT_X86_AVX512)\n\n        set(CMAKE_REQUIRED_FLAGS \"/arch:AVX2 -mfma -mf16c -mavxvnni\")\n        check_cxx_source_compiles(\"#include <immintrin.h>\\n__m256i test(__m256i s, __m256i a, __m256i b) { return _mm256_dpwssd_avx_epi32(s, a, b); }\" NCNN_COMPILER_SUPPORT_X86_AVX_VNNI)\n\n        set(CMAKE_REQUIRED_FLAGS \"/arch:AVX2 -mfma -mf16c -mavxvnni -mavxvnniint8\")\n        check_cxx_source_compiles(\"#include <immintrin.h>\\n__m256i test(__m256i s, __m256i a, __m256i b) { return _mm256_dpbssd_epi32(s, a, b); }\" NCNN_COMPILER_SUPPORT_X86_AVX_VNNI_INT8)\n\n        set(CMAKE_REQUIRED_FLAGS \"/arch:AVX2 -mfma -mf16c -mavxvnni -mavxvnniint16\")\n        check_cxx_source_compiles(\"#include <immintrin.h>\\n__m256i test(__m256i s, __m256i a, __m256i b) { return _mm256_dpwsud_avx_epi32(s, a, b); }\" NCNN_COMPILER_SUPPORT_X86_AVX_VNNI_INT16)\n\n        set(CMAKE_REQUIRED_FLAGS \"/arch:AVX2 -mfma -mf16c -mavxneconvert\")\n        check_cxx_source_compiles(\"#include <immintrin.h>\\n__m128bh test(__m256 a) { return _mm256_cvtneps_avx_pbh(a); }\" NCNN_COMPILER_SUPPORT_X86_AVX_NE_CONVERT)\n\n        set(CMAKE_REQUIRED_FLAGS \"/arch:AVX512 -mfma -mf16c -mavx512cd -mavx512bw -mavx512dq -mavx512vl -mavx512vnni\")\n        check_cxx_source_compiles(\"#include <immintrin.h>\\n__m512i test(__m512i s, __m512i a, __m512i b) { return _mm512_dpwssd_epi32(s, a, b); }\" NCNN_COMPILER_SUPPORT_X86_AVX512_VNNI)\n\n        set(CMAKE_REQUIRED_FLAGS \"/arch:AVX512 -mfma -mf16c -mavx512cd -mavx512bw -mavx512dq -mavx512vl -mavx512bf16\")\n        check_cxx_source_compiles(\"#include <immintrin.h>\\n__m256bh test(__m256bh s, __m512bh a, __m512bh b) { return _mm512_cvtneps_pbh(_mm512_dpbf16_ps(_mm512_cvtpbh_ps(s), a, b)); }\\n__m512i test2(__m512 a) { __m256i _a = (__m256i)_mm512_cvtneps_pbh(a); return _mm512_inserti32x8(_mm512_castsi256_si512(_a), _a, 1); }\" NCNN_COMPILER_SUPPORT_X86_AVX512_BF16)\n\n        set(CMAKE_REQUIRED_FLAGS \"/arch:AVX512 -mfma -mf16c -mavx512cd -mavx512bw -mavx512dq -mavx512vl -mavx512fp16\")\n        check_cxx_source_compiles(\"#include <immintrin.h>\\n__m512h test(__m512h s, __m512h a, __m512h b) { return _mm512_fmadd_ph(s, a, b); }\\n__m512 test2(__m512 a) { return _mm512_cvtxph_ps(_mm512_cvtxps_ph(a)); }\" NCNN_COMPILER_SUPPORT_X86_AVX512_FP16)\n\n        unset(CMAKE_REQUIRED_FLAGS)\n    else()\n        check_cxx_compiler_flag(\"-mrecip=none\" NCNN_COMPILER_SUPPORT_X86_RECIP_NONE)\n\n        set(CMAKE_REQUIRED_FLAGS \"-mavx\")\n        check_cxx_source_compiles(\"#include <immintrin.h>\\n__m256 test(__m256 a, __m256 b) { return _mm256_mul_ps(a, b); }\" NCNN_COMPILER_SUPPORT_X86_AVX)\n\n        set(CMAKE_REQUIRED_FLAGS \"-mfma -mf16c\")\n        check_cxx_source_compiles(\"#include <immintrin.h>\\n__m256 test(__m256 s, __m256 a, __m256 b) { return _mm256_fmadd_ps(a, b, s); }\" NCNN_COMPILER_SUPPORT_X86_FMA)\n\n        set(CMAKE_REQUIRED_FLAGS \"-mfma -mxop\")\n        check_cxx_source_compiles(\"#include <x86intrin.h>\\n__m128i test(__m128i s, __m128i a, __m128i b) { return _mm_maddd_epi16(a, b, s); }\" NCNN_COMPILER_SUPPORT_X86_XOP)\n\n        set(CMAKE_REQUIRED_FLAGS \"-mf16c\")\n        check_cxx_source_compiles(\"#include <immintrin.h>\\n__m256 test(__m128i a) { return _mm256_cvtph_ps(a); }\" NCNN_COMPILER_SUPPORT_X86_F16C)\n\n        set(CMAKE_REQUIRED_FLAGS \"-mfma -mf16c -mavx2\")\n        check_cxx_source_compiles(\"#include <immintrin.h>\\n__m256i test(__m256i a, __m256i b) { return _mm256_madd_epi16(a, b); }\" NCNN_COMPILER_SUPPORT_X86_AVX2)\n\n        set(CMAKE_REQUIRED_FLAGS \"-mfma -mf16c -mavx512f -mavx512cd -mavx512bw -mavx512dq -mavx512vl\")\n        check_cxx_source_compiles(\"#include <immintrin.h>\\n__m512i test(__m512i a, __m512i b) { return _mm512_madd_epi16(a, b); }\" NCNN_COMPILER_SUPPORT_X86_AVX512)\n\n        set(CMAKE_REQUIRED_FLAGS \"-mfma -mf16c -mavx2 -mavxvnni\")\n        check_cxx_source_compiles(\"#include <immintrin.h>\\n__m256i test(__m256i s, __m256i a, __m256i b) { return _mm256_dpwssd_avx_epi32(s, a, b); }\" NCNN_COMPILER_SUPPORT_X86_AVX_VNNI)\n\n        set(CMAKE_REQUIRED_FLAGS \"-mfma -mf16c -mavx2 -mavxvnni -mavxvnniint8\")\n        check_cxx_source_compiles(\"#include <immintrin.h>\\n__m256i test(__m256i s, __m256i a, __m256i b) { return _mm256_dpbssd_epi32(s, a, b); }\" NCNN_COMPILER_SUPPORT_X86_AVX_VNNI_INT8)\n\n        set(CMAKE_REQUIRED_FLAGS \"-mfma -mf16c -mavx2 -mavxvnni -mavxvnniint16\")\n        check_cxx_source_compiles(\"#include <immintrin.h>\\n__m256i test(__m256i s, __m256i a, __m256i b) { return _mm256_dpwsud_avx_epi32(s, a, b); }\" NCNN_COMPILER_SUPPORT_X86_AVX_VNNI_INT16)\n\n        set(CMAKE_REQUIRED_FLAGS \"-mfma -mf16c -mavx2 -mavxneconvert\")\n        check_cxx_source_compiles(\"#include <immintrin.h>\\n__m128bh test(__m256 a) { return _mm256_cvtneps_avx_pbh(a); }\" NCNN_COMPILER_SUPPORT_X86_AVX_NE_CONVERT)\n\n        set(CMAKE_REQUIRED_FLAGS \"-mfma -mf16c -mavx512f -mavx512cd -mavx512bw -mavx512dq -mavx512vl -mavx512vnni\")\n        check_cxx_source_compiles(\"#include <immintrin.h>\\n__m512i test(__m512i s, __m512i a, __m512i b) { return _mm512_dpwssd_epi32(s, a, b); }\" NCNN_COMPILER_SUPPORT_X86_AVX512_VNNI)\n\n        set(CMAKE_REQUIRED_FLAGS \"-mfma -mf16c -mavx512f -mavx512cd -mavx512bw -mavx512dq -mavx512vl -mavx512bf16\")\n        check_cxx_source_compiles(\"#include <immintrin.h>\\n__m256bh test(__m256bh s, __m512bh a, __m512bh b) { return _mm512_cvtneps_pbh(_mm512_dpbf16_ps(_mm512_cvtpbh_ps(s), a, b)); }\\n__m512i test2(__m512 a) { __m256i _a = (__m256i)_mm512_cvtneps_pbh(a); return _mm512_inserti32x8(_mm512_castsi256_si512(_a), _a, 1); }\" NCNN_COMPILER_SUPPORT_X86_AVX512_BF16)\n\n        set(CMAKE_REQUIRED_FLAGS \"-mfma -mf16c -mavx512f -mavx512cd -mavx512bw -mavx512dq -mavx512vl -mavx512fp16\")\n        check_cxx_source_compiles(\"#include <immintrin.h>\\n__m512h test(__m512h s, __m512h a, __m512h b) { return _mm512_fmadd_ph(s, a, b); }\\n__m512 test2(__m512 a) { return _mm512_cvtxph_ps(_mm512_cvtxps_ph(a)); }\" NCNN_COMPILER_SUPPORT_X86_AVX512_FP16)\n\n        unset(CMAKE_REQUIRED_FLAGS)\n    endif()\n\n    if(NOT CMAKE_SYSTEM_NAME MATCHES \"Emscripten|WASI\" AND NCNN_COMPILER_SUPPORT_X86_AVX)\n        option(NCNN_AVX \"optimize x86 platform with avx extension\" ON)\n        if(NCNN_COMPILER_SUPPORT_X86_FMA)\n            if(NCNN_AVX)\n                option(NCNN_FMA \"optimize x86 platform with fma extension\" ON)\n            endif()\n        else()\n            message(WARNING \"The compiler does not support fma extension. NCNN_FMA will be OFF.\")\n        endif()\n        if(NCNN_COMPILER_SUPPORT_X86_XOP)\n            if(NCNN_AVX)\n                option(NCNN_XOP \"optimize x86 platform with xop extension\" ON)\n            endif()\n        else()\n            message(WARNING \"The compiler does not support xop extension. NCNN_XOP will be OFF.\")\n        endif()\n        if(NCNN_COMPILER_SUPPORT_X86_F16C)\n            if(NCNN_AVX)\n                option(NCNN_F16C \"optimize x86 platform with f16c extension\" ON)\n            endif()\n        else()\n            message(WARNING \"The compiler does not support f16c extension. NCNN_F16C will be OFF.\")\n        endif()\n        if(NCNN_COMPILER_SUPPORT_X86_AVX2)\n            if(NCNN_AVX)\n                option(NCNN_AVX2 \"optimize x86 platform with avx2 extension\" ON)\n            endif()\n            if(NCNN_COMPILER_SUPPORT_X86_AVX_VNNI)\n                if(NCNN_AVX2)\n                    option(NCNN_AVXVNNI \"optimize x86 platform with avx vnni extension\" ON)\n                endif()\n                if(NCNN_COMPILER_SUPPORT_X86_AVX_VNNI_INT8)\n                    if(NCNN_AVXVNNI)\n                        option(NCNN_AVXVNNIINT8 \"optimize x86 platform with avx vnni int8 extension\" ON)\n                    endif()\n                else()\n                    message(WARNING \"The compiler does not support avx vnni int8 extension. NCNN_AVXVNNIINT8 will be OFF.\")\n                endif()\n                if(NCNN_COMPILER_SUPPORT_X86_AVX_VNNI_INT16)\n                    if(NCNN_AVXVNNI)\n                        option(NCNN_AVXVNNIINT16 \"optimize x86 platform with avx vnni int16 extension\" ON)\n                    endif()\n                else()\n                    message(WARNING \"The compiler does not support avx vnni int16 extension. NCNN_AVXVNNIINT16 will be OFF.\")\n                endif()\n            else()\n                message(WARNING \"The compiler does not support avx vnni extension. NCNN_AVXVNNI will be OFF.\")\n            endif()\n            if(NCNN_COMPILER_SUPPORT_X86_AVX_NE_CONVERT)\n                if(NCNN_AVX2)\n                    option(NCNN_AVXNECONVERT \"optimize x86 platform with avx ne convert extension\" ON)\n                endif()\n            else()\n                message(WARNING \"The compiler does not support avx ne convert extension. NCNN_AVXNECONVERT will be OFF.\")\n            endif()\n            if(NCNN_COMPILER_SUPPORT_X86_AVX512)\n                if(NCNN_AVX2)\n                    option(NCNN_AVX512 \"optimize x86 platform with avx512 extension\" ON)\n                endif()\n                if(NCNN_COMPILER_SUPPORT_X86_AVX512_VNNI)\n                    if(NCNN_AVX512)\n                        option(NCNN_AVX512VNNI \"optimize x86 platform with avx512 vnni extension\" ON)\n                    endif()\n                else()\n                    message(WARNING \"The compiler does not support avx512 vnni extension. NCNN_AVX512VNNI will be OFF.\")\n                endif()\n                if(NCNN_COMPILER_SUPPORT_X86_AVX512_BF16)\n                    if(NCNN_AVX512)\n                        option(NCNN_AVX512BF16 \"optimize x86 platform with avx512 bf16 extension\" ON)\n                    endif()\n                else()\n                    message(WARNING \"The compiler does not support avx512 bf16 extension. NCNN_AVX512BF16 will be OFF.\")\n                endif()\n                if(NCNN_COMPILER_SUPPORT_X86_AVX512_FP16)\n                    if(NCNN_AVX512)\n                        option(NCNN_AVX512FP16 \"optimize x86 platform with avx512 fp16 extension\" ON)\n                    endif()\n                else()\n                    message(WARNING \"The compiler does not support avx512 fp16 extension. NCNN_AVX512FP16 will be OFF.\")\n                endif()\n            else()\n                message(WARNING \"The compiler does not support avx512 extension. NCNN_AVX512 will be OFF.\")\n            endif()\n        else()\n            message(WARNING \"The compiler does not support avx2 extension. NCNN_AVX2 will be OFF.\")\n        endif()\n    else()\n        message(WARNING \"The compiler does not support avx extension. NCNN_AVX will be OFF.\")\n    endif()\nendif()\n\nunset(CMAKE_TRY_COMPILE_CONFIGURATION)\nunset(CMAKE_TRY_COMPILE_TARGET_TYPE)\n\nif(NCNN_TARGET_ILP32)\n    message(STATUS \"Target arch: ${NCNN_TARGET_ARCH} 64bit ilp32\")\nelseif(CMAKE_SIZEOF_VOID_P EQUAL 8)\n    message(STATUS \"Target arch: ${NCNN_TARGET_ARCH} 64bit\")\nelse()\n    message(STATUS \"Target arch: ${NCNN_TARGET_ARCH} 32bit\")\nendif()\n\n##############################################\n\n# set cmake default folder name\nset_property(GLOBAL PROPERTY USE_FOLDERS ON)\nset_property(GLOBAL PROPERTY PREDEFINED_TARGETS_FOLDER \"cmake\")\n\nif(CMAKE_SYSTEM_NAME STREQUAL \"Emscripten\")\n    set(CMAKE_C_FLAGS \"${CMAKE_C_FLAGS} -s FORCE_FILESYSTEM=1 -s INITIAL_MEMORY=256MB -s EXIT_RUNTIME=1\")\n    set(CMAKE_CXX_FLAGS \"${CMAKE_CXX_FLAGS} -s FORCE_FILESYSTEM=1 -s INITIAL_MEMORY=256MB -s EXIT_RUNTIME=1\")\n    set(CMAKE_EXECUTBLE_LINKER_FLAGS \"${CMAKE_EXECUTBLE_LINKER_FLAGS} -s FORCE_FILESYSTEM=1 -s INITIAL_MEMORY=256MB -s EXIT_RUNTIME=1\")\n\n    if(NCNN_OPENMP AND NCNN_SIMPLEOMP)\n        # TODO better flags for emscripten\n        # node --experimental-wasm-threads xxx.js\n        set(CMAKE_C_FLAGS \"${CMAKE_C_FLAGS} -s USE_PTHREADS=1 -s PTHREAD_POOL_SIZE=15\")\n        set(CMAKE_CXX_FLAGS \"${CMAKE_CXX_FLAGS} -s USE_PTHREADS=1 -s PTHREAD_POOL_SIZE=15\")\n        set(CMAKE_EXECUTBLE_LINKER_FLAGS \"${CMAKE_EXECUTBLE_LINKER_FLAGS} -s USE_PTHREADS=1 -s PTHREAD_POOL_SIZE=15\")\n    endif()\nendif()\n\nif(NCNN_VULKAN)\n    if(NCNN_SYSTEM_GLSLANG)\n        find_package(Threads)\n        find_package(glslang QUIET)\n        if(glslang_FOUND)\n            add_library(glslang ALIAS glslang::glslang)\n            add_library(SPIRV ALIAS glslang::SPIRV)\n        else()\n            set(GLSLANG_TARGET_DIR \"GLSLANG-NOTFOUND\" CACHE PATH \"Absolute path to glslangTargets.cmake directory\")\n            if(NOT GLSLANG_TARGET_DIR AND NOT DEFINED ENV{GLSLANG_TARGET_DIR})\n                message(WARNING \"set glslang_DIR to glslang-config.cmake directory for using system glslang.\")\n                message(WARNING \"GLSLANG_TARGET_DIR must be defined! NCNN_SYSTEM_GLSLANG will be turned off.\")\n                set(NCNN_SYSTEM_GLSLANG OFF)\n            else()\n                include(\"${GLSLANG_TARGET_DIR}/OSDependentTargets.cmake\")\n                include(\"${GLSLANG_TARGET_DIR}/OGLCompilerTargets.cmake\")\n                if(EXISTS \"${GLSLANG_TARGET_DIR}/HLSLTargets.cmake\")\n                    # hlsl support can be optional\n                    include(\"${GLSLANG_TARGET_DIR}/HLSLTargets.cmake\")\n                endif()\n                include(\"${GLSLANG_TARGET_DIR}/glslangTargets.cmake\")\n                include(\"${GLSLANG_TARGET_DIR}/SPIRVTargets.cmake\")\n            endif()\n        endif()\n\n        if (TARGET glslang AND TARGET SPIRV)\n            get_property(glslang_location TARGET glslang PROPERTY LOCATION)\n            get_property(SPIRV_location TARGET SPIRV PROPERTY LOCATION)\n            message(STATUS \"Found glslang: ${glslang_location} (found version \\\"${glslang_VERSION}\\\")\")\n            message(STATUS \"Found SPIRV: ${SPIRV_location} (found version \\\"${glslang_VERSION}\\\")\")\n        else()\n            message(WARNING \"glslang or SPIRV target not found! NCNN_SYSTEM_GLSLANG will be turned off.\")\n            set(NCNN_SYSTEM_GLSLANG OFF)\n        endif()\n    endif()\n\n    if(NOT NCNN_SYSTEM_GLSLANG)\n        if(NOT EXISTS \"${CMAKE_CURRENT_SOURCE_DIR}/glslang/CMakeLists.txt\")\n            message(FATAL_ERROR \"The submodules were not downloaded! Please update submodules with \\\"git submodule update --init\\\" and try again.\")\n        else()\n            # glslang requires c++11\n            set(CMAKE_CXX_STANDARD 11)\n\n            option(BUILD_EXTERNAL \"\" OFF)\n            option(ENABLE_SPVREMAPPER \"\" OFF)\n            option(ENABLE_GLSLANG_BINARIES \"\" OFF)\n            option(ENABLE_HLSL \"\" OFF)\n            option(ENABLE_RTTI \"\" OFF)\n            option(ENABLE_EXCEPTIONS \"\" OFF)\n            option(ENABLE_OPT \"\" OFF)\n            option(ENABLE_PCH \"\" OFF)\n            option(ENABLE_CTEST \"\" OFF)\n            if(NCNN_SHARED_LIB)\n                option(SKIP_GLSLANG_INSTALL \"\" ON)\n            endif()\n            add_subdirectory(glslang)\n            if(NCNN_SHARED_LIB)\n                if(CMAKE_CXX_COMPILER_ID MATCHES \"GNU\" OR (CMAKE_CXX_COMPILER_ID MATCHES \"Clang\" AND NOT CMAKE_CXX_COMPILER_FRONTEND_VARIANT MATCHES \"MSVC\"))\n                    target_compile_options(glslang PRIVATE -fvisibility=hidden -fvisibility-inlines-hidden)\n                    target_compile_options(OGLCompiler PRIVATE -fvisibility=hidden -fvisibility-inlines-hidden)\n                    target_compile_options(OSDependent PRIVATE -fvisibility=hidden -fvisibility-inlines-hidden)\n                    target_compile_options(SPIRV PRIVATE -fvisibility=hidden -fvisibility-inlines-hidden)\n                endif()\n                if(NCNN_ENABLE_LTO)\n                    set_target_properties(glslang PROPERTIES INTERPROCEDURAL_OPTIMIZATION ON)\n                    set_target_properties(OGLCompiler PROPERTIES INTERPROCEDURAL_OPTIMIZATION ON)\n                    set_target_properties(OSDependent PROPERTIES INTERPROCEDURAL_OPTIMIZATION ON)\n                    set_target_properties(SPIRV PROPERTIES INTERPROCEDURAL_OPTIMIZATION ON)\n                endif()\n            endif()\n        endif()\n    endif()\nendif()\n\nadd_subdirectory(src)\nif(NCNN_BUILD_BENCHMARK)\n    add_subdirectory(benchmark)\nendif()\nif(NCNN_BUILD_EXAMPLES)\n    add_subdirectory(examples)\nendif()\nif(NCNN_BUILD_TOOLS)\n    add_subdirectory(tools)\nendif()\nif(NCNN_BUILD_TESTS)\n    enable_testing()\n    add_subdirectory(tests)\nendif()\nif(NCNN_PYTHON)\n    add_subdirectory(python)\nendif()\n"
        },
        {
          "name": "CONTRIBUTING.md",
          "type": "blob",
          "size": 0.404296875,
          "content": "\n# Acknowledgements\n\n- Thanks to bug1989 [https://github.com/bug1989] for contributing the initial quantized int8 inference code and a large variety of device benchmark\n- Thanks to zhiliu6 [https://github.com/zhiliu6] for contributing the darknet conversion tool, operators and YOLO examples\n- Thanks to Tijmen Verhulsdonck [https://github.com/Timen] for contributing the massive AVX optimization for x86 platform\n"
        },
        {
          "name": "Info.plist",
          "type": "blob",
          "size": 0.5615234375,
          "content": "<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<!DOCTYPE plist PUBLIC \"-//Apple//DTD PLIST 1.0//EN\" \"http://www.apple.com/DTDs/PropertyList-1.0.dtd\">\n<plist version=\"1.0\">\n<dict>\n    <key>CFBundleName</key>\n    <string>__NAME__</string>\n    <key>CFBundleIdentifier</key>\n    <string>__IDENTIFIER__</string>\n    <key>CFBundleVersion</key>\n    <string>__VERSION__</string>\n    <key>CFBundleShortVersionString</key>\n    <string>__VERSION__</string>\n    <key>CFBundleSignature</key>\n    <string>????</string>\n    <key>CFBundlePackageType</key>\n    <string>FMWK</string>\n</dict>\n</plist>\n"
        },
        {
          "name": "LICENSE.txt",
          "type": "blob",
          "size": 6.349609375,
          "content": "Tencent is pleased to support the open source community by making ncnn available.\nCopyright (C) 2017 THL A29 Limited, a Tencent company.  All rights reserved.\nIf you have downloaded a copy of the ncnn binary from Tencent, please note that the ncnn binary is licensed under the BSD 3-Clause License.\nIf you have downloaded a copy of the ncnn source code from Tencent, please note that ncnn source code is licensed under the BSD 3-Clause License, except for the third-party components listed below which are subject to different license terms.  Your integration of ncnn into your own projects may require compliance with the BSD 3-Clause License, as well as the other licenses applicable to the third-party components included within ncnn.\nA copy of the BSD 3-Clause License is included in this file.\n\nOther dependencies and licenses:\n\nOpen Source Software Licensed Under the zlib License:\nThe below software in this distribution may have been modified by THL A29 Limited (“Tencent Modifications”). All Tencent Modifications are Copyright (C) 2017 THL A29 Limited.\n----------------------------------------------------------------------------------------\n1. neon_mathfun.h\nCopyright (C) 2011 Julien Pommier\n\n2. sse_mathfun.h\nCopyright (C) 2007 Julien Pommier\n\n3. avx_mathfun.h\nCopyright (C) 2012 Giovanni Garberoglio\nInterdisciplinary Laboratory for Computational Science (LISC)\nFondazione Bruno Kessler and University of Trento\nvia Sommarive, 18\nI-38123 Trento (Italy)\n\n\nTerms of the zlib License:\n---------------------------------------------------\nCopyright (c) <year> <copyright holders>\n\nThis software is provided 'as-is', without any express or implied warranty. In no event will the authors be held liable for any damages arising from the use of this software.\n\nPermission is granted to anyone to use this software for any purpose, including commercial applications, and to alter it and redistribute it freely, subject to the following restrictions:\n\n1. The origin of this software must not be misrepresented; you must not claim that you wrote the original software. If you use this software in a product, an acknowledgment in the product documentation would be appreciated but is not required.\n2. Altered source versions must be plainly marked as such, and must not be misrepresented as being the original software.\n3. This notice may not be removed or altered from any source distribution.\n\n\n\nOpen Source Software Licensed Under the BSD 2-Clause License:\nThe below software in this distribution may have been modified by THL A29 Limited (“Tencent Modifications”). All Tencent Modifications are Copyright (C) 2017 THL A29 Limited.\n----------------------------------------------------------------------------------------\n1. squeezenet  1.1\nCopyright (c) 2016 Forrest N. Iandola and Matthew W. Moskewicz and Khalid Ashraf and Song Han and William J. Dally and Kurt Keutzer\nAll rights reserved.\n\n2. caffe.proto  master\nAll contributions by the University of California:\nCopyright (c) 2014-2017 The Regents of the University of California (Regents)\nAll rights reserved.\n\nAll other contributions:\nCopyright (c) 2014-2017, the respective contributors\nAll rights reserved.\n\n\nTerms of the BSD 2-Clause License:\n--------------------------------------------------------------------\nRedistribution and use in source and binary forms, with or without modification, are permitted provided that the following conditions are met:\n\nRedistributions of source code must retain the above copyright notice, this list of conditions and the following disclaimer.\nRedistributions in binary form must reproduce the above copyright notice, this list of conditions and the following disclaimer in the documentation and/or other materials provided with the distribution.\n\nTHIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS \"AS IS\" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n\n\n\nOpen Source Software Licensed Under the BSD 3-Clause License:\nThe below software in this distribution may have been modified by THL A29 Limited (“Tencent Modifications”). All Tencent Modifications are Copyright (C) 2017 THL A29 Limited.\n----------------------------------------------------------------------------------------\n1. android.toolchain.cmake  master\nCopyright (c) 2010-2011, Ethan Rublee\nCopyright (c) 2011-2014, Andrey Kamaev\nAll rights reserved.\n\n\nTerms of the BSD 3-Clause License:\n--------------------------------------------------------------------\n\nRedistribution and use in source and binary forms, with or without modification, are permitted provided that the following conditions are met:\n\nRedistributions of source code must retain the above copyright notice, this list of conditions and the following disclaimer.\nRedistributions in binary form must reproduce the above copyright notice, this list of conditions and the following disclaimer in the documentation and/or other materials provided with the distribution.\nNeither the name of [copyright holder] nor the names of its contributors may be used to endorse or promote products derived from this software without specific prior written permission.\n\nTHIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS \"AS IS\" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n"
        },
        {
          "name": "README.md",
          "type": "blob",
          "size": 25.8515625,
          "content": "![ncnn](https://raw.githubusercontent.com/Tencent/ncnn/master/images/256-ncnn.png)\n\n# ncnn\n\n[![License](https://img.shields.io/badge/license-BSD_3_Clause-blue.svg?style=for-the-badge)](LICENSE.txt)\n[![Download Total Count](https://img.shields.io/github/downloads/Tencent/ncnn/total.svg?style=for-the-badge)](https://github.com/Tencent/ncnn/releases)\n[![codecov](https://img.shields.io/codecov/c/github/Tencent/ncnn/master?style=for-the-badge)](https://codecov.io/gh/Tencent/ncnn)\n\nncnn is a high-performance neural network inference computing framework optimized for mobile platforms.\nncnn is deeply considerate about deployment and uses on mobile phones from the beginning of design.\nncnn does not have third-party dependencies.\nIt is cross-platform and runs faster than all known open-source frameworks on mobile phone cpu.\nDevelopers can easily deploy deep learning algorithm models to the mobile platform by using efficient ncnn implementation, creating intelligent APPs, and bringing artificial intelligence to your fingertips.\nncnn is currently being used in many Tencent applications, such as QQ, Qzone, WeChat, Pitu, and so on.\n\nncnn 是一个为手机端极致优化的高性能神经网络前向计算框架。\nncnn 从设计之初深刻考虑手机端的部署和使用。\n无第三方依赖，跨平台，手机端 cpu 的速度快于目前所有已知的开源框架。\n基于 ncnn，开发者能够将深度学习算法轻松移植到手机端高效执行，\n开发出人工智能 APP，将 AI 带到你的指尖。\nncnn 目前已在腾讯多款应用中使用，如：QQ，Qzone，微信，天天 P 图等。\n\n---\n\n<table>\n<tr>\n<td>\n<b>技术交流 QQ 群</b><br />\n637093648 (超多大佬)<br />\n答案：卷卷卷卷卷（已满）\n</td>\n<td rowspan=3>\n<b>Telegram Group</b>\n\n<https://t.me/ncnnyes>\n</td>\n<td rowspan=3>\n<b>Discord Channel</b>\n\n<https://discord.gg/YRsxgmF>\n</td>\n</tr>\n<tr>\n<td>\n<b>Pocky QQ 群（MLIR YES!）</b><br />\n677104663 (超多大佬)<br />\n答案：multi-level intermediate representation\n</td>\n</tr>\n<tr>\n<td>\n<b>他们都不知道 pnnx 有多好用群</b><br />\n818998520 (新群！)\n</td>\n</tr>\n</table>\n\n---\n\n## Download & Build status\n\nhttps://github.com/Tencent/ncnn/releases/latest\n\n\n<table>\n<tr>\n<td rowspan=2>\n  <img src=\"https://user-images.githubusercontent.com/25181517/192108372-f71d70ac-7ae6-4c0d-8395-51d8870c2ef0.png\" width=\"120\" height=\"auto\">\n</td>\n<td colspan=3>\n\n  **[how to build ncnn library](https://github.com/Tencent/ncnn/wiki/how-to-build) on Linux / Windows / macOS / Raspberry Pi3, Pi4 / POWER / Android / NVIDIA Jetson / iOS / WebAssembly / AllWinner D1 / Loongson 2K1000**\n\n</td>\n</tr>\n<tr>\n<td>Source</td>\n<td colspan=2>\n\n  [<img src=\"https://img.shields.io/badge/download-blue?style=for-the-badge\">](https://github.com/Tencent/ncnn/releases/latest/download/ncnn-20241226-full-source.zip)\n\n</td>\n</tr>\n\n<tr>\n<td rowspan=3>\n  <img src=\"https://user-images.githubusercontent.com/25181517/117269608-b7dcfb80-ae58-11eb-8e66-6cc8753553f0.png\" width=\"120\" height=\"auto\">\n</td>\n<td colspan=3>\n\n- [Build for Android](https://github.com/Tencent/ncnn/wiki/how-to-build#build-for-android)\n- [Build for Termux on Android](https://github.com/Tencent/ncnn/wiki/how-to-build#build-for-termux-on-android)\n\n</td>\n</tr>\n<tr>\n<td>Android</td>\n<td>\n\n  [<img src=\"https://img.shields.io/badge/download-blue?style=for-the-badge\">](https://github.com/Tencent/ncnn/releases/latest/download/ncnn-20241226-android-vulkan.zip)\n  [<img src=\"https://img.shields.io/badge/+cpuonly-blue?style=for-the-badge\">](https://github.com/Tencent/ncnn/releases/latest/download/ncnn-20241226-android.zip)\n\n</td>\n<td rowspan=2>\n\n  [<img src=\"https://img.shields.io/github/actions/workflow/status/Tencent/ncnn/android.yml?branch=master&style=for-the-badge&label=build\">](https://github.com/Tencent/ncnn/actions?query=workflow%3Aandroid)\n\n</td>\n</tr>\n<tr>\n<td>Android shared</td>\n<td>\n\n  [<img src=\"https://img.shields.io/badge/download-blue?style=for-the-badge\">](https://github.com/Tencent/ncnn/releases/latest/download/ncnn-20241226-android-vulkan-shared.zip)\n  [<img src=\"https://img.shields.io/badge/+cpuonly-blue?style=for-the-badge\">](https://github.com/Tencent/ncnn/releases/latest/download/ncnn-20241226-android-shared.zip)\n\n</td>\n</tr>\n\n<tr>\n<td rowspan=3>\n  <img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/3/37/HMOS_Logo_Icon.svg/240px-HMOS_Logo_Icon.svg.png\" width=\"120\" height=\"auto\">\n</td>\n<td colspan=3>\n\n- [Build for HarmonyOS with cross-compiling](https://github.com/Tencent/ncnn/wiki/how-to-build#build-for-harmonyos-with-cross-compiling)\n\n</td>\n</tr>\n<tr>\n<td>HarmonyOS</td>\n<td>\n\n</td>\n<td rowspan=2>\n\n  [<img src=\"https://img.shields.io/github/actions/workflow/status/Tencent/ncnn/harmonyos.yml?branch=master&style=for-the-badge&label=build\">](https://github.com/Tencent/ncnn/actions?query=workflow%3Aharmonyos)\n\n</td>\n</tr>\n<tr>\n<td>HarmonyOS shared</td>\n<td>\n\n</td>\n</tr>\n\n<tr>\n<td rowspan=3>\n  <img src=\"https://user-images.githubusercontent.com/25181517/121406611-a8246b80-c95e-11eb-9b11-b771486377f6.png\" width=\"120\" height=\"auto\">\n</td>\n<td colspan=3>\n\n- [Build for iOS on macOS with xcode](https://github.com/Tencent/ncnn/wiki/how-to-build#build-for-ios-on-macos-with-xcode)\n\n</td>\n</tr>\n<tr>\n<td>iOS</td>\n<td>\n\n  [<img src=\"https://img.shields.io/badge/download-blue?style=for-the-badge\">](https://github.com/Tencent/ncnn/releases/latest/download/ncnn-20241226-ios-vulkan.zip)\n  [<img src=\"https://img.shields.io/badge/+cpuonly-blue?style=for-the-badge\">](https://github.com/Tencent/ncnn/releases/latest/download/ncnn-20241226-ios.zip)\n\n</td>\n<td rowspan=2>\n\n  [<img src=\"https://img.shields.io/github/actions/workflow/status/Tencent/ncnn/ios.yml?branch=master&style=for-the-badge&label=build\">](https://github.com/Tencent/ncnn/actions?query=workflow%3Aios)\n\n</td>\n</tr>\n<tr>\n<td>iOS-Simulator</td>\n<td>\n\n  [<img src=\"https://img.shields.io/badge/download-blue?style=for-the-badge\">](https://github.com/Tencent/ncnn/releases/latest/download/ncnn-20241226-ios-simulator-vulkan.zip)\n  [<img src=\"https://img.shields.io/badge/+cpuonly-blue?style=for-the-badge\">](https://github.com/Tencent/ncnn/releases/latest/download/ncnn-20241226-ios-simulator.zip)\n\n</td>\n</tr>\n\n<tr>\n<td rowspan=10>\n  <img src=\"https://user-images.githubusercontent.com/25181517/186884152-ae609cca-8cf1-4175-8d60-1ce1fa078ca2.png\" width=\"120\" height=\"auto\">\n</td>\n<td colspan=3>\n\n- [Build for macOS](https://github.com/Tencent/ncnn/wiki/how-to-build#build-for-macos)\n\n</td>\n</tr>\n<tr>\n<td>macOS</td>\n<td>\n\n  [<img src=\"https://img.shields.io/badge/download-blue?style=for-the-badge\">](https://github.com/Tencent/ncnn/releases/latest/download/ncnn-20241226-macos-vulkan.zip)\n  [<img src=\"https://img.shields.io/badge/+cpuonly-blue?style=for-the-badge\">](https://github.com/Tencent/ncnn/releases/latest/download/ncnn-20241226-macos.zip)\n\n</td>\n<td rowspan=1>\n\n  [<img src=\"https://img.shields.io/github/actions/workflow/status/Tencent/ncnn/macos.yml?branch=master&style=for-the-badge&label=build\">](https://github.com/Tencent/ncnn/actions?query=workflow%3Amacos)\n\n</td>\n</tr>\n<tr>\n<td>Mac-Catalyst</td>\n<td>\n\n  [<img src=\"https://img.shields.io/badge/download-blue?style=for-the-badge\">](https://github.com/Tencent/ncnn/releases/latest/download/ncnn-20241226-mac-catalyst-vulkan.zip)\n  [<img src=\"https://img.shields.io/badge/+cpuonly-blue?style=for-the-badge\">](https://github.com/Tencent/ncnn/releases/latest/download/ncnn-20241226-mac-catalyst.zip)\n\n</td>\n<td rowspan=1>\n\n  [<img src=\"https://img.shields.io/github/actions/workflow/status/Tencent/ncnn/mac-catalyst.yml?branch=master&style=for-the-badge&label=build\">](https://github.com/Tencent/ncnn/actions?query=workflow%3Amac-catalyst)\n\n</td>\n</tr>\n<tr>\n<td>watchOS</td>\n<td>\n\n  [<img src=\"https://img.shields.io/badge/download-blue?style=for-the-badge\">](https://github.com/Tencent/ncnn/releases/latest/download/ncnn-20241226-watchos.zip)\n\n</td>\n<td rowspan=2>\n\n  [<img src=\"https://img.shields.io/github/actions/workflow/status/Tencent/ncnn/watchos.yml?branch=master&style=for-the-badge&label=build\">](https://github.com/Tencent/ncnn/actions?query=workflow%3Awatchos)\n\n</td>\n</tr>\n<tr>\n<td>watchOS-Simulator</td>\n<td>\n\n  [<img src=\"https://img.shields.io/badge/download-blue?style=for-the-badge\">](https://github.com/Tencent/ncnn/releases/latest/download/ncnn-20241226-watchos-simulator.zip)\n\n</td>\n</tr>\n<tr>\n<td>tvOS</td>\n<td>\n\n  [<img src=\"https://img.shields.io/badge/download-blue?style=for-the-badge\">](https://github.com/Tencent/ncnn/releases/latest/download/ncnn-20241226-tvos-vulkan.zip)\n  [<img src=\"https://img.shields.io/badge/+cpuonly-blue?style=for-the-badge\">](https://github.com/Tencent/ncnn/releases/latest/download/ncnn-20241226-tvos.zip)\n\n</td>\n<td rowspan=2>\n\n  [<img src=\"https://img.shields.io/github/actions/workflow/status/Tencent/ncnn/tvos.yml?branch=master&style=for-the-badge&label=build\">](https://github.com/Tencent/ncnn/actions?query=workflow%3Atvos)\n\n</td>\n</tr>\n<tr>\n<td>tvOS-Simulator</td>\n<td>\n\n  [<img src=\"https://img.shields.io/badge/download-blue?style=for-the-badge\">](https://github.com/Tencent/ncnn/releases/latest/download/ncnn-20241226-tvos-simulator-vulkan.zip)\n  [<img src=\"https://img.shields.io/badge/+cpuonly-blue?style=for-the-badge\">](https://github.com/Tencent/ncnn/releases/latest/download/ncnn-20241226-tvos-simulator.zip)\n\n</td>\n</tr>\n<tr>\n<td>visionOS</td>\n<td>\n\n  [<img src=\"https://img.shields.io/badge/download-blue?style=for-the-badge\">](https://github.com/Tencent/ncnn/releases/latest/download/ncnn-20241226-visionos-vulkan.zip)\n  [<img src=\"https://img.shields.io/badge/+cpuonly-blue?style=for-the-badge\">](https://github.com/Tencent/ncnn/releases/latest/download/ncnn-20241226-visionos.zip)\n\n</td>\n<td rowspan=2>\n\n  [<img src=\"https://img.shields.io/github/actions/workflow/status/Tencent/ncnn/visionos.yml?branch=master&style=for-the-badge&label=build\">](https://github.com/Tencent/ncnn/actions?query=workflow%3Avisionos)\n\n</td>\n</tr>\n<tr>\n<td>visionOS-Simulator</td>\n<td>\n\n  [<img src=\"https://img.shields.io/badge/download-blue?style=for-the-badge\">](https://github.com/Tencent/ncnn/releases/latest/download/ncnn-20241226-visionos-simulator-vulkan.zip)\n  [<img src=\"https://img.shields.io/badge/+cpuonly-blue?style=for-the-badge\">](https://github.com/Tencent/ncnn/releases/latest/download/ncnn-20241226-visionos-simulator.zip)\n\n</td>\n</tr>\n<tr>\n<td>Apple xcframework</td>\n<td>\n\n  [<img src=\"https://img.shields.io/badge/download-blue?style=for-the-badge\">](https://github.com/Tencent/ncnn/releases/latest/download/ncnn-20241226-apple-vulkan.zip)\n  [<img src=\"https://img.shields.io/badge/+cpuonly-blue?style=for-the-badge\">](https://github.com/Tencent/ncnn/releases/latest/download/ncnn-20241226-apple.zip)\n\n</td>\n<td rowspan=1>\n\n</td>\n</tr>\n\n<tr>\n<td rowspan=4>\n  <img src=\"https://user-images.githubusercontent.com/25181517/186884153-99edc188-e4aa-4c84-91b0-e2df260ebc33.png\" width=\"120\" height=\"auto\">\n</td>\n<td colspan=4>\n\n- [Build for Linux / NVIDIA Jetson / Raspberry Pi3, Pi4 / POWER](https://github.com/Tencent/ncnn/wiki/how-to-build#build-for-linux)\n\n</td>\n</tr>\n<tr>\n<td>Ubuntu 20.04</td>\n<td>\n\n  [<img src=\"https://img.shields.io/badge/download-blue?style=for-the-badge\">](https://github.com/Tencent/ncnn/releases/latest/download/ncnn-20241226-ubuntu-2004.zip)\n  [<img src=\"https://img.shields.io/badge/+shared-blue?style=for-the-badge\">](https://github.com/Tencent/ncnn/releases/latest/download/ncnn-20241226-ubuntu-2004-shared.zip)\n\n</td>\n<td rowspan=3>\n\n  [<img src=\"https://img.shields.io/github/actions/workflow/status/Tencent/ncnn/linux-x64-gpu-gcc.yml?branch=master&style=for-the-badge&label=build\">](https://github.com/Tencent/ncnn/actions?query=workflow%3Alinux-x64-gpu-gcc)\n\n</td>\n</tr>\n<tr>\n<td>Ubuntu 22.04</td>\n<td>\n\n  [<img src=\"https://img.shields.io/badge/download-blue?style=for-the-badge\">](https://github.com/Tencent/ncnn/releases/latest/download/ncnn-20241226-ubuntu-2204.zip)\n  [<img src=\"https://img.shields.io/badge/+shared-blue?style=for-the-badge\">](https://github.com/Tencent/ncnn/releases/latest/download/ncnn-20241226-ubuntu-2204-shared.zip)\n\n</td>\n</tr>\n<tr>\n<td>Ubuntu 24.04</td>\n<td>\n\n  [<img src=\"https://img.shields.io/badge/download-blue?style=for-the-badge\">](https://github.com/Tencent/ncnn/releases/latest/download/ncnn-20241226-ubuntu-2404.zip)\n  [<img src=\"https://img.shields.io/badge/+shared-blue?style=for-the-badge\">](https://github.com/Tencent/ncnn/releases/latest/download/ncnn-20241226-ubuntu-2404-shared.zip)\n\n</td>\n</tr>\n\n<tr>\n<td rowspan=5>\n  <img alt=\"windows\" src=\"https://user-images.githubusercontent.com/25181517/186884150-05e9ff6d-340e-4802-9533-2c3f02363ee3.png\" width=\"120\" height=\"auto\">\n</td>\n<td colspan=3>\n\n- [Build for Windows x64 using VS2017](https://github.com/Tencent/ncnn/wiki/how-to-build#build-for-windows-x64-using-visual-studio-community-2017)\n- [Build for Windows x64 using MinGW-w64](https://github.com/Tencent/ncnn/wiki/how-to-build#build-for-windows-x64-using-mingw-w64)\n\n</td>\n</tr>\n<tr>\n<td>VS2015</td>\n<td>\n\n  [<img src=\"https://img.shields.io/badge/download-blue?style=for-the-badge\">](https://github.com/Tencent/ncnn/releases/latest/download/ncnn-20241226-windows-vs2015.zip)\n  [<img src=\"https://img.shields.io/badge/+shared-blue?style=for-the-badge\">](https://github.com/Tencent/ncnn/releases/latest/download/ncnn-20241226-windows-vs2015-shared.zip)\n\n</td>\n<td rowspan=4>\n\n  [<img src=\"https://img.shields.io/github/actions/workflow/status/Tencent/ncnn/windows.yml?branch=master&style=for-the-badge&label=build\">](https://github.com/Tencent/ncnn/actions?query=workflow%3Awindows)\n\n</td>\n</tr>\n<tr>\n<td>VS2017</td>\n<td>\n\n  [<img src=\"https://img.shields.io/badge/download-blue?style=for-the-badge\">](https://github.com/Tencent/ncnn/releases/latest/download/ncnn-20241226-windows-vs2017.zip)\n  [<img src=\"https://img.shields.io/badge/+shared-blue?style=for-the-badge\">](https://github.com/Tencent/ncnn/releases/latest/download/ncnn-20241226-windows-vs2017-shared.zip)\n\n</td>\n</tr>\n<tr>\n<td>VS2019</td>\n<td>\n\n  [<img src=\"https://img.shields.io/badge/download-blue?style=for-the-badge\">](https://github.com/Tencent/ncnn/releases/latest/download/ncnn-20241226-windows-vs2019.zip)\n  [<img src=\"https://img.shields.io/badge/+shared-blue?style=for-the-badge\">](https://github.com/Tencent/ncnn/releases/latest/download/ncnn-20241226-windows-vs2019-shared.zip)\n\n</td>\n</tr>\n<tr>\n<td>VS2022</td>\n<td>\n\n  [<img src=\"https://img.shields.io/badge/download-blue?style=for-the-badge\">](https://github.com/Tencent/ncnn/releases/latest/download/ncnn-20241226-windows-vs2022.zip)\n  [<img src=\"https://img.shields.io/badge/+shared-blue?style=for-the-badge\">](https://github.com/Tencent/ncnn/releases/latest/download/ncnn-20241226-windows-vs2022-shared.zip)\n\n</td>\n</tr>\n\n<tr>\n<td rowspan=2>\n  <img src=\"https://user-images.githubusercontent.com/25181517/188324036-d704ac9a-6e61-4722-b978-254b25b61bed.png\" width=\"120\" height=\"auto\">\n</td>\n<td colspan=3>\n\n- [Build for WebAssembly](https://github.com/Tencent/ncnn/wiki/how-to-build#build-for-webassembly)\n\n</td>\n</tr>\n<tr>\n<td>WebAssembly</td>\n<td>\n\n  [<img src=\"https://img.shields.io/badge/download-blue?style=for-the-badge\">](https://github.com/Tencent/ncnn/releases/latest/download/ncnn-20241226-webassembly.zip)\n\n</td>\n<td>\n\n  [<img src=\"https://img.shields.io/github/actions/workflow/status/Tencent/ncnn/web-assembly.yml?branch=master&style=for-the-badge&label=build\">](https://github.com/Tencent/ncnn/actions?query=workflow%3Aweb-assembly)\n\n</td>\n</tr>\n\n<tr>\n<td rowspan=8>\n  <img src=\"https://github.com/marwin1991/profile-technology-icons/assets/76662862/2481dc48-be6b-4ebb-9e8c-3b957efe69fa\" width=\"120\" height=\"auto\">\n</td>\n<td colspan=3>\n\n- [Build for ARM Cortex-A family with cross-compiling](https://github.com/Tencent/ncnn/wiki/how-to-build#build-for-arm-cortex-a-family-with-cross-compiling)\n- [Build for Hisilicon platform with cross-compiling](https://github.com/Tencent/ncnn/wiki/how-to-build#build-for-hisilicon-platform-with-cross-compiling)\n- [Build for AllWinner D1](https://github.com/Tencent/ncnn/wiki/how-to-build#build-for-allwinner-d1)\n- [Build for Loongson 2K1000](https://github.com/Tencent/ncnn/wiki/how-to-build#build-for-loongson-2k1000)\n- [Build for QNX](https://github.com/Tencent/ncnn/wiki/how-to-build#build-for-qnx)\n\n</td>\n</tr>\n<tr>\n<td>Linux (arm)</td>\n<td></td>\n<td>\n\n  [<img src=\"https://img.shields.io/github/actions/workflow/status/Tencent/ncnn/linux-arm.yml?branch=master&style=for-the-badge&label=build\">](https://github.com/Tencent/ncnn/actions?query=workflow%3Alinux-arm)\n\n</td>\n</tr>\n<tr>\n<td>Linux (aarch64)</td>\n<td></td>\n<td>\n\n  [<img src=\"https://img.shields.io/github/actions/workflow/status/Tencent/ncnn/linux-aarch64.yml?branch=master&style=for-the-badge&label=build\">](https://github.com/Tencent/ncnn/actions?query=workflow%3Alinux-aarch64)\n\n</td>\n</tr>\n<tr>\n<td>Linux (mips)</td>\n<td></td>\n<td>\n\n  [<img src=\"https://img.shields.io/github/actions/workflow/status/Tencent/ncnn/linux-mips.yml?branch=master&style=for-the-badge&label=build\">](https://github.com/Tencent/ncnn/actions?query=workflow%3Alinux-mips)\n\n</td>\n</tr>\n<tr>\n<td>Linux (mips64)</td>\n<td></td>\n<td>\n\n  [<img src=\"https://img.shields.io/github/actions/workflow/status/Tencent/ncnn/linux-mips64.yml?branch=master&style=for-the-badge&label=build\">](https://github.com/Tencent/ncnn/actions?query=workflow%3Alinux-mips64)\n\n</td>\n</tr>\n<tr>\n<td>Linux (ppc64)</td>\n<td></td>\n<td>\n\n  [<img src=\"https://img.shields.io/github/actions/workflow/status/Tencent/ncnn/linux-ppc64.yml?branch=master&style=for-the-badge&label=build\">](https://github.com/Tencent/ncnn/actions?query=workflow%3Alinux-ppc64)\n\n</td>\n</tr>\n<tr>\n<td>Linux (riscv64)</td>\n<td></td>\n<td>\n\n  [<img src=\"https://img.shields.io/github/actions/workflow/status/Tencent/ncnn/linux-riscv64.yml?branch=master&style=for-the-badge&label=build\">](https://github.com/Tencent/ncnn/actions?query=workflow%3Alinux-riscv64)\n\n</td>\n</tr>\n<tr>\n<td>Linux (loongarch64)</td>\n<td></td>\n<td>\n\n  [<img src=\"https://img.shields.io/github/actions/workflow/status/Tencent/ncnn/linux-loongarch64.yml?branch=master&style=for-the-badge&label=build\">](https://github.com/Tencent/ncnn/actions?query=workflow%3Alinux-loongarch64)\n\n</td>\n</tr>\n\n</table>\n\n\n---\n\n## Support most commonly used CNN network\n\n## 支持大部分常用的 CNN 网络\n\n- Classical CNN:\n  [VGG](https://github.com/BVLC/caffe/wiki/Model-Zoo#models-used-by-the-vgg-team-in-ilsvrc-2014)\n  [AlexNet](https://github.com/BVLC/caffe/tree/9b891540183ddc834a02b2bd81b31afae71b2153/models/bvlc_alexnet)\n  [GoogleNet](https://github.com/BVLC/caffe/tree/9b891540183ddc834a02b2bd81b31afae71b2153/models/bvlc_googlenet)\n  Inception\n  ...\n- Practical CNN:\n  [ResNet](https://github.com/tornadomeet/ResNet)\n  [DenseNet](https://github.com/liuzhuang13/DenseNet)\n  [SENet](https://github.com/hujie-frank/SENet)\n  [FPN](https://github.com/unsky/FPN)\n  ...\n- Light-weight CNN:\n  [SqueezeNet](https://github.com/forresti/SqueezeNet)\n  [MobileNetV1](https://github.com/tensorflow/models/blob/master/research/slim/nets/mobilenet_v1.md)\n  [MobileNetV2/V3](https://github.com/tensorflow/models/blob/master/research/slim/nets/mobilenet/README.md)\n  [ShuffleNetV1](https://github.com/farmingyard/ShuffleNet)\n  [ShuffleNetV2](https://github.com/opconty/keras-shufflenetV2)\n  [MNasNet](https://github.com/tensorflow/models/tree/master/research/slim/nets/nasnet)\n  ...\n- Face Detection:\n  [MTCNN](https://github.com/ipazc/mtcnn)\n  [RetinaFace](https://github.com/biubug6/Pytorch_Retinaface)\n  [scrfd](https://github.com/nihui/ncnn-android-scrfd)\n  ...\n- Detection:\n  [VGG-SSD](https://github.com/lzx1413/CAFFE_SSD)\n  [MobileNet-SSD](https://github.com/chuanqi305/MobileNet-SSD)\n  [SqueezeNet-SSD](https://github.com/chuanqi305/SqueezeNet-SSD)\n  [MobileNetV2-SSDLite](https://github.com/chuanqi305/MobileNetv2-SSDLite)\n  [MobileNetV3-SSDLite](https://github.com/XiaoyuHuang96/MobilenetV3SSDLite-tfkeras)\n  ...\n- Detection:\n  [Faster-RCNN](https://github.com/rbgirshick/py-faster-rcnn)\n  [R-FCN](https://github.com/daijifeng001/R-FCN)\n  ...\n- Detection:\n  [YOLOv2](https://github.com/longcw/yolo2-pytorch)\n  [YOLOv3](https://github.com/ultralytics/yolov3)\n  [MobileNet-YOLOv3](https://github.com/eric612/MobileNet-YOLO)\n  [YOLOv4](https://github.com/Tianxiaomo/pytorch-YOLOv4)\n  [YOLOv5](https://github.com/ultralytics/yolov5)\n  [YOLOv7](https://github.com/WongKinYiu/yolov7)\n  [YOLOX](https://github.com/Megvii-BaseDetection/YOLOX)\n  ...\n- Detection:\n  [NanoDet](https://github.com/RangiLyu/nanodet)\n- Segmentation:\n  [FCN](https://github.com/unsky/FPN)\n  [PSPNet](https://github.com/hszhao/PSPNet)\n  [UNet](https://github.com/zhixuhao/unet)\n  [YOLACT](https://github.com/dbolya/yolact)\n  ...\n- Pose Estimation:\n  [SimplePose](https://github.com/dog-qiuqiu/Ultralight-SimplePose)\n  ...\n\n---\n\n## HowTo\n\n**[use ncnn with alexnet](https://github.com/Tencent/ncnn/wiki/use-ncnn-with-alexnet) with detailed steps, recommended for beginners :)**\n\n**[ncnn 组件使用指北 alexnet](https://github.com/Tencent/ncnn/wiki/use-ncnn-with-alexnet.zh) 附带详细步骤，新人强烈推荐 :)**\n\n**[use netron for ncnn model visualization](https://netron.app)**\n\n**[use ncnn with pytorch or onnx](https://github.com/Tencent/ncnn/wiki/use-ncnn-with-pytorch-or-onnx)**\n\n[ncnn low-level operation api](https://github.com/Tencent/ncnn/wiki/low-level-operation-api)\n\n[ncnn param and model file spec](https://github.com/Tencent/ncnn/wiki/param-and-model-file-structure)\n\n[ncnn operation param weight table](https://github.com/Tencent/ncnn/wiki/operation-param-weight-table)\n\n[how to implement custom layer step by step](https://github.com/Tencent/ncnn/wiki/how-to-implement-custom-layer-step-by-step)\n\n---\n\n## FAQ\n\n**[ncnn throw error](https://github.com/Tencent/ncnn/wiki/FAQ-ncnn-throw-error)**\n\n**[ncnn produce wrong result](https://github.com/Tencent/ncnn/wiki/FAQ-ncnn-produce-wrong-result)**\n\n**[ncnn vulkan](https://github.com/Tencent/ncnn/wiki/FAQ-ncnn-vulkan)**\n\n---\n\n## Features\n\n- Supports convolutional neural networks, supports multiple input and multi-branch structure, can calculate part of the branch\n- No third-party library dependencies, does not rely on BLAS / NNPACK or any other computing framework\n- Pure C++ implementation, cross-platform, supports Android, iOS and so on\n- ARM NEON assembly level of careful optimization, calculation speed is extremely high\n- Sophisticated memory management and data structure design, very low memory footprint\n- Supports multi-core parallel computing acceleration, ARM big.LITTLE CPU scheduling optimization\n- Supports GPU acceleration via the next-generation low-overhead Vulkan API\n- Extensible model design, supports 8bit quantization and half-precision floating point storage, can import caffe/pytorch/mxnet/onnx/darknet/keras/tensorflow(mlir) models\n- Support direct memory zero copy reference load network model\n- Can be registered with custom layer implementation and extended\n- Well, it is strong, not afraid of being stuffed with 卷 QvQ\n\n## 功能概述\n\n- 支持卷积神经网络，支持多输入和多分支结构，可计算部分分支\n- 无任何第三方库依赖，不依赖 BLAS/NNPACK 等计算框架\n- 纯 C++ 实现，跨平台，支持 Android / iOS 等\n- ARM Neon 汇编级良心优化，计算速度极快\n- 精细的内存管理和数据结构设计，内存占用极低\n- 支持多核并行计算加速，ARM big.LITTLE CPU 调度优化\n- 支持基于全新低消耗的 Vulkan API GPU 加速\n- 可扩展的模型设计，支持 8bit [量化](tools/quantize) 和半精度浮点存储，可导入 caffe/pytorch/mxnet/onnx/darknet/keras/tensorflow(mlir) 模型\n- 支持直接内存零拷贝引用加载网络模型\n- 可注册自定义层实现并扩展\n- 恩，很强就是了，不怕被塞卷 QvQ\n\n---\n\n## supported platform matrix\n\n- ✅ = known work and runs fast with good optimization\n- ✔️ = known work, but speed may not be fast enough\n- ❔ = shall work, not confirmed\n- / = not applied\n\n|            | Windows | Linux | Android | macOS | iOS |\n| ---------- | ------- | ----- | ------- | ----- | --- |\n| intel-cpu  | ✔️      | ✔️    | ❔      | ✔️    | /   |\n| intel-gpu  | ✔️      | ✔️    | ❔      | ❔    | /   |\n| amd-cpu    | ✔️      | ✔️    | ❔      | ✔️    | /   |\n| amd-gpu    | ✔️      | ✔️    | ❔      | ❔    | /   |\n| nvidia-gpu | ✔️      | ✔️    | ❔      | ❔    | /   |\n| qcom-cpu   | ❔      | ✔️    | ✅      | /     | /   |\n| qcom-gpu   | ❔      | ✔️    | ✔️      | /     | /   |\n| arm-cpu    | ❔      | ❔    | ✅      | /     | /   |\n| arm-gpu    | ❔      | ❔    | ✔️      | /     | /   |\n| apple-cpu  | /       | /     | /       | ✔️    | ✅  |\n| apple-gpu  | /       | /     | /       | ✔️    | ✔️  |\n| ibm-cpu    | /       | ✔️     | /       | /    | /  |\n\n---\n\n## Project examples\n\n- <https://github.com/nihui/ncnn-android-squeezenet>\n- <https://github.com/nihui/ncnn-android-styletransfer>\n- <https://github.com/nihui/ncnn-android-mobilenetssd>\n- <https://github.com/moli232777144/mtcnn_ncnn>\n- <https://github.com/nihui/ncnn-android-yolov5>\n- <https://github.com/xiang-wuu/ncnn-android-yolov7>\n- <https://github.com/nihui/ncnn-android-scrfd> 🤩\n- <https://github.com/shaoshengsong/qt_android_ncnn_lib_encrypt_example>\n\n<img src=\"https://github.com/nihui/ncnn-assets/raw/master/20181217/ncnn-2.jpg\" height =\"230\"/><img src=\"https://github.com/nihui/ncnn-assets/raw/master/20181217/4.jpg\" height =\"230\"/><img src=\"https://github.com/nihui/ncnn-assets/raw/master/20181217/ncnn-33.jpg\" height =\"230\"/><img src=\"https://github.com/nihui/ncnn-assets/raw/master/20181217/ncnn-m.png\" height =\"230\"/><img src=\"https://github.com/nihui/ncnn-android-yolov5/raw/master/screenshot.jpg\" height =\"230\"/><img src=\"https://github.com/nihui/ncnn-android-scrfd/raw/master/screenshot.jpg\" height =\"230\"/><br>\n\n- <https://github.com/magicse/ncnn-colorization-siggraph17><br>\n<img src=\"https://user-images.githubusercontent.com/13585785/189326958-f5a8d6f8-caef-49bf-88da-ae494371195d.jpg\" width =\"700\"/>\n\n- <https://github.com/mizu-bai/ncnn-fortran> Call ncnn from Fortran\n\n- <https://github.com/k2-fsa/sherpa> Use ncnn for real-time speech\n  recognition (i.e., speech-to-text); also support embedded devices and provide\n  mobile Apps (e.g., Android App)\n\n---\n\n## License\n\n[BSD 3 Clause](LICENSE.txt)\n"
        },
        {
          "name": "benchmark",
          "type": "tree",
          "content": null
        },
        {
          "name": "build-android.cmd",
          "type": "blob",
          "size": 2.2705078125,
          "content": ":: Set android ndk root\n@ECHO OFF\n@SETLOCAL\n@SET ANDROID_NDK=<your-ndk-root_path, such as\"E:\\android-ndk-r27\">\n\n:: Set ninja.exe\n:: @SET NINJA_EXE=<your-ninja-exe_path, such as\"D:\\android\\sdk\\cmake\\3.10.2.4988404\\bin\\ninja.exe\">\n\n:: android armv7\nmkdir build-android-armv7-vulkan\npushd build-android-armv7-vulkan\ncmake -G \"Unix Makefiles\" -DCMAKE_TOOLCHAIN_FILE=%ANDROID_NDK%/build/cmake/android.toolchain.cmake -DCMAKE_MAKE_PROGRAM=\"%ANDROID_NDK%/prebuilt/windows-x86_64/bin/make.exe\" -DANDROID_ABI=\"armeabi-v7a\" -DANDROID_ARM_NEON=ON -DANDROID_PLATFORM=android-19 -DNCNN_VULKAN=ON ..\ncmake --build . --parallel %NUMBER_OF_PROCESSORS%\ncmake --build . --target install\npopd\n\n:: android aarch64\nmkdir build-android-aarch64-vulkan\npushd build-android-aarch64-vulkan\ncmake -G \"Unix Makefiles\" -DCMAKE_TOOLCHAIN_FILE=%ANDROID_NDK%/build/cmake/android.toolchain.cmake -DCMAKE_MAKE_PROGRAM=\"%ANDROID_NDK%/prebuilt/windows-x86_64/bin/make.exe\" -DANDROID_ABI=\"arm64-v8a\" -DANDROID_PLATFORM=android-21 -DNCNN_VULKAN=ON ..\ncmake --build . --parallel %NUMBER_OF_PROCESSORS%\ncmake --build . --target install\npopd\n\n:: android x86\nmkdir build-android-x86\npushd build-android-x86\ncmake -G \"Unix Makefiles\" -DCMAKE_TOOLCHAIN_FILE=%ANDROID_NDK%/build/cmake/android.toolchain.cmake -DCMAKE_MAKE_PROGRAM=\"%ANDROID_NDK%/prebuilt/windows-x86_64/bin/make.exe\" -DANDROID_ABI=\"x86\" -DANDROID_PLATFORM=android-19 -DNCNN_VULKAN=ON ..\ncmake --build . --parallel %NUMBER_OF_PROCESSORS%\ncmake --build . --target install\npopd\n\n:: android x86_64\nmkdir build-android-x86_64\npushd build-android-x86_64\ncmake -G \"Unix Makefiles\" -DCMAKE_TOOLCHAIN_FILE=%ANDROID_NDK%/build/cmake/android.toolchain.cmake -DCMAKE_MAKE_PROGRAM=\"%ANDROID_NDK%/prebuilt/windows-x86_64/bin/make.exe\" -DANDROID_ABI=\"x86_64\" -DANDROID_PLATFORM=android-21 -DNCNN_VULKAN=ON ..\ncmake --build . --parallel %NUMBER_OF_PROCESSORS%\ncmake --build . --target install\npopd\n\n:: android riscv64\nmkdir build-android-riscv64\npushd build-android-riscv64\ncmake -G \"Unix Makefiles\" -DCMAKE_TOOLCHAIN_FILE=%ANDROID_NDK%/build/cmake/android.toolchain.cmake -DCMAKE_MAKE_PROGRAM=\"%ANDROID_NDK%/prebuilt/windows-x86_64/bin/make.exe\" -DANDROID_ABI=\"riscv64\" -DANDROID_PLATFORM=android-35 -DNCNN_VULKAN=ON ..\ncmake --build . --parallel %NUMBER_OF_PROCESSORS%\ncmake --build . --target install\npopd\n\n@ENDLOCAL\n"
        },
        {
          "name": "build.sh",
          "type": "blob",
          "size": 3.7001953125,
          "content": "#!/usr/bin/env bash\n\n##### android armv7 without neon\nmkdir -p build-android-armv7-without-neon\npushd build-android-armv7-without-neon\ncmake -DCMAKE_TOOLCHAIN_FILE=$ANDROID_NDK/build/cmake/android.toolchain.cmake -DANDROID_ABI=\"armeabi-v7a\" -DANDROID_ARM_NEON=OFF -DANDROID_PLATFORM=android-19 -DNCNN_VULKAN=ON ..\nmake -j4\nmake install\npopd\n\n##### android armv7\nmkdir -p build-android-armv7\npushd build-android-armv7\ncmake -DCMAKE_TOOLCHAIN_FILE=$ANDROID_NDK/build/cmake/android.toolchain.cmake -DANDROID_ABI=\"armeabi-v7a\" -DANDROID_ARM_NEON=ON -DANDROID_PLATFORM=android-19 -DNCNN_VULKAN=ON ..\nmake -j4\nmake install\npopd\n\n##### android aarch64\nmkdir -p build-android-aarch64\npushd build-android-aarch64\ncmake -DCMAKE_TOOLCHAIN_FILE=$ANDROID_NDK/build/cmake/android.toolchain.cmake -DANDROID_ABI=\"arm64-v8a\" -DANDROID_PLATFORM=android-21 -DNCNN_VULKAN=ON ..\nmake -j4\nmake install\npopd\n\n##### android x86\nmkdir -p build-android-x86\npushd build-android-x86\ncmake -DCMAKE_TOOLCHAIN_FILE=$ANDROID_NDK/build/cmake/android.toolchain.cmake -DANDROID_ABI=\"x86\" -DANDROID_PLATFORM=android-19 -DNCNN_VULKAN=ON ..\nmake -j4\nmake install\npopd\n\n##### android x86_64\nmkdir -p build-android-x86_64\npushd build-android-x86_64\ncmake -DCMAKE_TOOLCHAIN_FILE=$ANDROID_NDK/build/cmake/android.toolchain.cmake -DANDROID_ABI=\"x86_64\" -DANDROID_PLATFORM=android-21 -DNCNN_VULKAN=ON ..\nmake -j4\nmake install\npopd\n\n##### android riscv64\nmkdir -p build-android-riscv64\npushd build-android-riscv64\ncmake -DCMAKE_TOOLCHAIN_FILE=$ANDROID_NDK/build/cmake/android.toolchain.cmake -DANDROID_ABI=\"riscv64\" -DANDROID_PLATFORM=android-35 -DNCNN_VULKAN=ON ..\nmake -j4\nmake install\npopd\n\n##### linux of hisiv300 (forgot the chip name) toolchain with neon and openmp\nmkdir -p build-hisiv300-linux\npushd build-hisiv300-linux\ncmake -DCMAKE_TOOLCHAIN_FILE=../toolchains/hisiv300.toolchain.cmake ..\nmake -j4\nmake install\npopd\n\n##### linux of hisiv500 (Hi3516CV200 and Hi3519V101) toolchain with neon and openmp\nmkdir -p build-hisiv500-linux\npushd build-hisiv500-linux\ncmake -DCMAKE_TOOLCHAIN_FILE=../toolchains/hisiv500.toolchain.cmake ..\nmake -j4\nmake install\npopd\n\n##### linux of hisiv600 (Hi3559V100) toolchain with neon and no openmp (due to only one cpu, close openmp)\nmkdir -p build-hisiv600-linux\npushd build-hisiv600-linux\ncmake -DCMAKE_TOOLCHAIN_FILE=../toolchains/hisiv600.toolchain.cmake ..\nmake -j4\nmake install\npopd\n\n##### linux of himix100 (Hi3559a) toolchain with neon and openmp\nmkdir -p build-himix100-linux\npushd build-himix100-linux\ncmake -DCMAKE_TOOLCHAIN_FILE=../toolchains/himix100.toolchain.cmake ..\nmake -j4\nmake install\npopd\n\n##### linux of arm-linux-gnueabi toolchain\nmkdir -p build-arm-linux-gnueabi\npushd build-arm-linux-gnueabi\ncmake -DCMAKE_TOOLCHAIN_FILE=../toolchains/arm-linux-gnueabi.toolchain.cmake ..\nmake -j4\nmake install\npopd\n\n##### linux of arm-linux-gnueabihf toolchain\nmkdir -p build-arm-linux-gnueabihf\npushd build-arm-linux-gnueabihf\ncmake -DCMAKE_TOOLCHAIN_FILE=../toolchains/arm-linux-gnueabihf.toolchain.cmake ..\nmake -j4\nmake install\npopd\n\n##### linux of v831 toolchain with neon and openmp\nmkdir -p build-v831-linux\npushd build-v831-linux\ncmake -DCMAKE_TOOLCHAIN_FILE=../toolchains/v831.toolchain.cmake ..\nmake -j4\nmake install\npopd\n\n##### linux for aarch64-linux-gnu toolchain\nmkdir -p build-aarch64-linux-gnu\npushd build-aarch64-linux-gnu\ncmake -DCMAKE_TOOLCHAIN_FILE=../toolchains/aarch64-linux-gnu.toolchain.cmake ..\nmake -j4\nmake install\npopd\n\n##### linux host system with gcc/g++\nmkdir -p build-host-gcc-linux\npushd build-host-gcc-linux\ncmake -DCMAKE_TOOLCHAIN_FILE=../toolchains/host.gcc.toolchain.cmake ..\nmake -j4\nmake install\npopd\n\n##### MacOS\nmkdir -p build-mac\npushd build-mac\ncmake   -DNCNN_OPENMP=OFF \\\n        -DNCNN_BENCHMARK=ON \\\n        ..\nmake -j8\nmake install\npopd\n"
        },
        {
          "name": "cmake",
          "type": "tree",
          "content": null
        },
        {
          "name": "codeformat.sh",
          "type": "blob",
          "size": 0.7568359375,
          "content": "#!/usr/bin/env bash\n\n# we run clang-format and astyle twice to get stable format output\n\nformat_code() {\n    find src/ tools/ tests/ examples/ benchmark/ python/ -type f -name '*.c' -o -name '*.cpp' -o -name '*.cc' -o -name '*.h' | grep -v python/pybind11 | grep -v stb_image | grep -v ruapu | xargs -i clang-format -i {}\n    astyle -n -r \"benchmark/*.h,*.cpp,*.cc\" \"tests/*.h,*.cpp,*.cc\" \"tools/*.h,*.cpp,*.cc\" \"examples/*.h,*.cpp,*.cc\"\n    astyle -n -r \"src/*.h,*.cpp,*.cc\" --exclude=src/stb_image.h --exclude=src/stb_image_write.h --exclude=src/ruapu.h\n    astyle -n -r \"python/*.h,*.cpp,*.cc\" --exclude=python/pybind11\n}\n\nformat_code || { echo 'Formatting failed' ; exit 1; } #first time execute\nformat_code || { echo 'Formatting failed' ; exit 1; } #second time execute\n"
        },
        {
          "name": "docs",
          "type": "tree",
          "content": null
        },
        {
          "name": "examples",
          "type": "tree",
          "content": null
        },
        {
          "name": "glslang",
          "type": "commit",
          "content": null
        },
        {
          "name": "images",
          "type": "tree",
          "content": null
        },
        {
          "name": "package.sh",
          "type": "blob",
          "size": 6.8759765625,
          "content": "#!/usr/bin/bash\n\nNAME=ncnn\n\n##### package android lib\nANDROIDPKGNAME=${NAME}-android-lib\nrm -rf $ANDROIDPKGNAME\nmkdir -p $ANDROIDPKGNAME\nmkdir -p $ANDROIDPKGNAME/armeabi-v7a\nmkdir -p $ANDROIDPKGNAME/arm64-v8a\nmkdir -p $ANDROIDPKGNAME/x86\nmkdir -p $ANDROIDPKGNAME/x86_64\nmkdir -p $ANDROIDPKGNAME/include\ncp build-android-armv7/install/lib/lib*.a $ANDROIDPKGNAME/armeabi-v7a/\ncp build-android-aarch64/install/lib/lib*.a $ANDROIDPKGNAME/arm64-v8a/\ncp build-android-x86/install/lib/lib*.a $ANDROIDPKGNAME/x86/\ncp build-android-x86_64/install/lib/lib*.a $ANDROIDPKGNAME/x86_64/\ncp -r build-android-aarch64/install/include/* $ANDROIDPKGNAME/include/\nrm -f $ANDROIDPKGNAME.zip\nzip -9 -r $ANDROIDPKGNAME.zip $ANDROIDPKGNAME\n\n##### package ios framework\nIOSPKGNAME=${NAME}.framework\nrm -rf $IOSPKGNAME\nmkdir -p $IOSPKGNAME/Versions/A/Headers\nmkdir -p $IOSPKGNAME/Versions/A/Resources\nln -s A $IOSPKGNAME/Versions/Current\nln -s Versions/Current/Headers $IOSPKGNAME/Headers\nln -s Versions/Current/Resources $IOSPKGNAME/Resources\nln -s Versions/Current/${NAME} $IOSPKGNAME/${NAME}\nlipo -create \\\n    build-ios/install/lib/lib${NAME}.a \\\n    build-ios-sim/install/lib/lib${NAME}.a \\\n    -o $IOSPKGNAME/Versions/A/${NAME}\ncp -r build-ios/install/include/* $IOSPKGNAME/Versions/A/Headers/\ncp Info.plist ${IOSPKGNAME}/Versions/A/Resources/\nrm -f $IOSPKGNAME.zip\nzip -9 -y -r $IOSPKGNAME.zip $IOSPKGNAME\n\n##### package ios framework bitcode\nIOSPKGNAME=${NAME}.framework\nrm -rf $IOSPKGNAME\nmkdir -p $IOSPKGNAME/Versions/A/Headers\nmkdir -p $IOSPKGNAME/Versions/A/Resources\nln -s A $IOSPKGNAME/Versions/Current\nln -s Versions/Current/Headers $IOSPKGNAME/Headers\nln -s Versions/Current/Resources $IOSPKGNAME/Resources\nln -s Versions/Current/${NAME} $IOSPKGNAME/${NAME}\nlipo -create \\\n    build-ios-bitcode/install/lib/lib${NAME}.a \\\n    build-ios-sim-bitcode/install/lib/lib${NAME}.a \\\n    -o $IOSPKGNAME/Versions/A/${NAME}\ncp -r build-ios-bitcode/install/include/ncnn $IOSPKGNAME/Versions/A/Headers/\ncp Info.plist ${IOSPKGNAME}/Versions/A/Resources/\nrm -f $IOSPKGNAME-bitcode.zip\nzip -9 -y -r $IOSPKGNAME-bitcode.zip $IOSPKGNAME\n\n\n##### package android lib vulkan\nANDROIDPKGNAME=${NAME}-android-vulkan-lib\nrm -rf $ANDROIDPKGNAME\nmkdir -p $ANDROIDPKGNAME\nmkdir -p $ANDROIDPKGNAME/armeabi-v7a\nmkdir -p $ANDROIDPKGNAME/arm64-v8a\nmkdir -p $ANDROIDPKGNAME/x86\nmkdir -p $ANDROIDPKGNAME/x86_64\nmkdir -p $ANDROIDPKGNAME/include\ncp build-android-armv7-vulkan/install/lib/lib*.a $ANDROIDPKGNAME/armeabi-v7a/\ncp build-android-aarch64-vulkan/install/lib/lib*.a $ANDROIDPKGNAME/arm64-v8a/\ncp build-android-x86-vulkan/install/lib/lib*.a $ANDROIDPKGNAME/x86/\ncp build-android-x86_64-vulkan/install/lib/lib*.a $ANDROIDPKGNAME/x86_64/\ncp -r build-android-aarch64-vulkan/install/include/* $ANDROIDPKGNAME/include/\nrm -f $ANDROIDPKGNAME.zip\nzip -9 -r $ANDROIDPKGNAME.zip $ANDROIDPKGNAME\n\n##### package ios framework vulkan\nIOSPKGNAME=${NAME}.framework\nrm -rf $IOSPKGNAME\nmkdir -p $IOSPKGNAME/Versions/A/Headers\nmkdir -p $IOSPKGNAME/Versions/A/Resources\nln -s A $IOSPKGNAME/Versions/Current\nln -s Versions/Current/Headers $IOSPKGNAME/Headers\nln -s Versions/Current/Resources $IOSPKGNAME/Resources\nln -s Versions/Current/${NAME} $IOSPKGNAME/${NAME}\nlipo -create \\\n    build-ios-vulkan/install/lib/lib${NAME}.a \\\n    build-ios-sim-vulkan/install/lib/lib${NAME}.a \\\n    -o $IOSPKGNAME/Versions/A/${NAME}\ncp -r build-ios-vulkan/install/include/ncnn $IOSPKGNAME/Versions/A/Headers/\ncp Info.plist ${IOSPKGNAME}/Versions/A/Resources/\nrm -f $IOSPKGNAME-vulkan.zip\nzip -9 -y -r $IOSPKGNAME-vulkan.zip $IOSPKGNAME\n\n##### package ios framework vulkan bitcode\nIOSPKGNAME=${NAME}.framework\nrm -rf $IOSPKGNAME\nmkdir -p $IOSPKGNAME/Versions/A/Headers\nmkdir -p $IOSPKGNAME/Versions/A/Resources\nln -s A $IOSPKGNAME/Versions/Current\nln -s Versions/Current/Headers $IOSPKGNAME/Headers\nln -s Versions/Current/Resources $IOSPKGNAME/Resources\nln -s Versions/Current/${NAME} $IOSPKGNAME/${NAME}\nlipo -create \\\n    build-ios-vulkan-bitcode/install/lib/lib${NAME}.a \\\n    build-ios-sim-vulkan-bitcode/install/lib/lib${NAME}.a \\\n    -o $IOSPKGNAME/Versions/A/${NAME}\ncp -r build-ios-vulkan-bitcode/install/include/ncnn $IOSPKGNAME/Versions/A/Headers/\ncp Info.plist ${IOSPKGNAME}/Versions/A/Resources/\nrm -f $IOSPKGNAME-vulkan-bitcode.zip\nzip -9 -y -r $IOSPKGNAME-vulkan-bitcode.zip $IOSPKGNAME\n\n\n##### package ios framework glslang\nIOSPKGNAME=glslang.framework\nrm -rf $IOSPKGNAME\nmkdir -p $IOSPKGNAME/Versions/A/Headers\nmkdir -p $IOSPKGNAME/Versions/A/Resources\nln -s A $IOSPKGNAME/Versions/Current\nln -s Versions/Current/Headers $IOSPKGNAME/Headers\nln -s Versions/Current/Resources $IOSPKGNAME/Resources\nln -s Versions/Current/glslang $IOSPKGNAME/glslang\nlibtool -static \\\n    build-ios-vulkan/install/lib/libglslang.a \\\n    build-ios-vulkan/install/lib/libSPIRV.a \\\n    build-ios-vulkan/install/lib/libOGLCompiler.a \\\n    build-ios-vulkan/install/lib/libOSDependent.a \\\n    -o build-ios-vulkan/install/lib/libglslang_combined.a\nlibtool -static \\\n    build-ios-sim-vulkan/install/lib/libglslang.a \\\n    build-ios-sim-vulkan/install/lib/libSPIRV.a \\\n    build-ios-sim-vulkan/install/lib/libOGLCompiler.a \\\n    build-ios-sim-vulkan/install/lib/libOSDependent.a \\\n    -o build-ios-sim-vulkan/install/lib/libglslang_combined.a\nlipo -create \\\n    build-ios-vulkan/install/lib/libglslang_combined.a \\\n    build-ios-sim-vulkan/install/lib/libglslang_combined.a \\\n    -o $IOSPKGNAME/Versions/A/glslang\ncp -r build-ios-vulkan/install/include/glslang $IOSPKGNAME/Versions/A/Headers/\ncp Info.plist ${IOSPKGNAME}/Versions/A/Resources/\nrm -f $IOSPKGNAME.zip\nzip -9 -y -r $IOSPKGNAME.zip $IOSPKGNAME\n\n##### package ios framework glslang bitcode\nIOSPKGNAME=glslang.framework\nrm -rf $IOSPKGNAME\nmkdir -p $IOSPKGNAME/Versions/A/Headers\nmkdir -p $IOSPKGNAME/Versions/A/Resources\nln -s A $IOSPKGNAME/Versions/Current\nln -s Versions/Current/Headers $IOSPKGNAME/Headers\nln -s Versions/Current/Resources $IOSPKGNAME/Resources\nln -s Versions/Current/glslang $IOSPKGNAME/glslang\nlibtool -static \\\n    build-ios-vulkan-bitcode/install/lib/libglslang.a \\\n    build-ios-vulkan-bitcode/install/lib/libSPIRV.a \\\n    build-ios-vulkan-bitcode/install/lib/libOGLCompiler.a \\\n    build-ios-vulkan-bitcode/install/lib/libOSDependent.a \\\n    -o build-ios-vulkan-bitcode/install/lib/libglslang_combined.a\nlibtool -static \\\n    build-ios-sim-vulkan-bitcode/install/lib/libglslang.a \\\n    build-ios-sim-vulkan-bitcode/install/lib/libSPIRV.a \\\n    build-ios-sim-vulkan-bitcode/install/lib/libOGLCompiler.a \\\n    build-ios-sim-vulkan-bitcode/install/lib/libOSDependent.a \\\n    -o build-ios-sim-vulkan-bitcode/install/lib/libglslang_combined.a\nlipo -create \\\n    build-ios-vulkan-bitcode/install/lib/libglslang_combined.a \\\n    build-ios-sim-vulkan-bitcode/install/lib/libglslang_combined.a \\\n    -o $IOSPKGNAME/Versions/A/glslang\ncp -r build-ios-vulkan-bitcode/install/include/glslang $IOSPKGNAME/Versions/A/Headers/\ncp Info.plist ${IOSPKGNAME}/Versions/A/Resources/\nrm -f $IOSPKGNAME-bitcode.zip\nzip -9 -y -r $IOSPKGNAME-bitcode.zip $IOSPKGNAME\n"
        },
        {
          "name": "pyproject.toml",
          "type": "blob",
          "size": 0.18359375,
          "content": "[build-system]\nrequires = [\n    \"setuptools>=42\",\n    \"wheel\",\n    \"ninja; sys_platform != 'win32'\",\n    \"cmake>=3.12\",\n    \"importlib-metadata\",\n]\nbuild-backend = \"setuptools.build_meta\"\n"
        },
        {
          "name": "python",
          "type": "tree",
          "content": null
        },
        {
          "name": "setup.py",
          "type": "blob",
          "size": 8.1982421875,
          "content": "import io\nimport os\nimport sys\nimport time\nimport re\nimport subprocess\n\nfrom setuptools import setup, find_packages, Extension\nfrom setuptools.command.build_ext import build_ext\nfrom setuptools.command.install import install\n\n\ndef find_version():\n    with io.open(\"CMakeLists.txt\", encoding=\"utf8\") as f:\n        version_file = f.read()\n\n    version_major = re.findall(r\"NCNN_VERSION_MAJOR (.+?)\", version_file)\n    version_minor = re.findall(r\"NCNN_VERSION_MINOR (.+?)\", version_file)\n\n    if version_major and version_minor:\n        ncnn_version = time.strftime(\"%Y%m%d\", time.localtime())\n\n        return version_major[0] + \".\" + version_minor[0] + \".\" + ncnn_version\n    raise RuntimeError(\"Unable to find version string.\")\n\n# Parse environment variables\nVulkan_LIBRARY = os.environ.get(\"Vulkan_LIBRARY\", \"\")\nCMAKE_TOOLCHAIN_FILE = os.environ.get(\"CMAKE_TOOLCHAIN_FILE\", \"\")\nPLATFORM = os.environ.get(\"PLATFORM\", \"\")\nARCHS = os.environ.get(\"ARCHS\", \"\")\nDEPLOYMENT_TARGET = os.environ.get(\"DEPLOYMENT_TARGET\", \"\")\nOpenMP_C_FLAGS = os.environ.get(\"OpenMP_C_FLAGS\", \"\")\nOpenMP_CXX_FLAGS = os.environ.get(\"OpenMP_CXX_FLAGS\", \"\")\nOpenMP_C_LIB_NAMES = os.environ.get(\"OpenMP_C_LIB_NAMES\", \"\")\nOpenMP_CXX_LIB_NAMES = os.environ.get(\"OpenMP_CXX_LIB_NAMES\", \"\")\nOpenMP_libomp_LIBRARY = os.environ.get(\"OpenMP_libomp_LIBRARY\", \"\")\nENABLE_BITCODE = os.environ.get(\"ENABLE_BITCODE\", \"\")\nENABLE_ARC = os.environ.get(\"ENABLE_ARC\", \"\")\nENABLE_VISIBILITY = os.environ.get(\"ENABLE_VISIBILITY\", \"\")\n\n# Parse variables from command line with setup.py install\nclass InstallCommand(install):\n    user_options = install.user_options + [\n        ('vulkan=', None, 'Enable the usage of Vulkan.'),\n    ]\n    def initialize_options(self):\n        install.initialize_options(self)\n        self.vulkan = None\n\n    def finalize_options(self):\n        install.finalize_options(self)\n\n    def run(self):\n        install.run(self)\n\n# Convert distutils Windows platform specifiers to CMake -A arguments\nPLAT_TO_CMAKE = {\n    \"win32\": \"Win32\",\n    \"win-amd64\": \"x64\",\n    \"win-arm32\": \"ARM\",\n    \"win-arm64\": \"ARM64\",\n}\n\n# A CMakeExtension needs a sourcedir instead of a file list.\n# The name must be the _single_ output extension from the CMake build.\n# If you need multiple extensions, see scikit-build.\nclass CMakeExtension(Extension):\n    def __init__(self, name, sourcedir=\"\"):\n        Extension.__init__(self, name, sources=[])\n        self.sourcedir = os.path.abspath(sourcedir)\n\n\nclass CMakeBuild(build_ext):\n    def build_extension(self, ext):\n        extdir = os.path.abspath(os.path.dirname(self.get_ext_fullpath(ext.name)))\n        extdir = os.path.join(extdir, \"ncnn\")\n\n        # required for auto-detection of auxiliary \"native\" libs\n        if not extdir.endswith(os.path.sep):\n            extdir += os.path.sep\n\n        cfg = \"Debug\" if self.debug else \"Release\"\n\n        # CMake lets you override the generator - we need to check this.\n        # Can be set with Conda-Build, for example.\n        cmake_generator = os.environ.get(\"CMAKE_GENERATOR\", \"\")\n\n        # Set Python_EXECUTABLE instead if you use PYBIND11_FINDPYTHON\n        # EXAMPLE_VERSION_INFO shows you how to pass a value into the C++ code\n        # from Python.\n        cmake_args = [\n            \"-DCMAKE_LIBRARY_OUTPUT_DIRECTORY={}\".format(extdir),\n            \"-DCMAKE_LIBRARY_OUTPUT_DIRECTORY_RELEASE={}\".format(extdir),\n            \"-DPYTHON_EXECUTABLE={}\".format(sys.executable),\n            \"-DCMAKE_BUILD_TYPE={}\".format(cfg),  # not used on MSVC, but no harm\n            \"-DNCNN_PYTHON=ON\",\n            \"-DNCNN_VULKAN=ON\",\n            \"-DNCNN_DISABLE_RTTI=OFF\",\n            \"-DNCNN_DISABLE_EXCEPTION=OFF\",\n            \"-DNCNN_BUILD_BENCHMARK=OFF\",\n            \"-DNCNN_BUILD_EXAMPLES=OFF\",\n            \"-DNCNN_BUILD_TOOLS=OFF\",\n        ]\n        if Vulkan_LIBRARY != \"\":\n            cmake_args.append(\"-DVulkan_LIBRARY=\" + Vulkan_LIBRARY)\n        if CMAKE_TOOLCHAIN_FILE != \"\":\n            cmake_args.append(\"-DCMAKE_TOOLCHAIN_FILE=\" + CMAKE_TOOLCHAIN_FILE)\n        if PLATFORM != \"\":\n            cmake_args.append(\"-DPLATFORM=\" + PLATFORM)\n        if ARCHS != \"\":\n            cmake_args.append(\"-DARCHS=\" + ARCHS)\n        if DEPLOYMENT_TARGET != \"\":\n            cmake_args.append(\"-DDEPLOYMENT_TARGET=\" + DEPLOYMENT_TARGET)\n        if OpenMP_C_FLAGS != \"\":\n            cmake_args.append(\"-DOpenMP_C_FLAGS=\" + OpenMP_C_FLAGS)\n        if OpenMP_CXX_FLAGS != \"\":\n            cmake_args.append(\"-DOpenMP_CXX_FLAGS=\" + OpenMP_CXX_FLAGS)\n        if OpenMP_C_LIB_NAMES != \"\":\n            cmake_args.append(\"-DOpenMP_C_LIB_NAMES=\" + OpenMP_C_LIB_NAMES)\n        if OpenMP_CXX_LIB_NAMES != \"\":\n            cmake_args.append(\"-DOpenMP_CXX_LIB_NAMES=\" + OpenMP_CXX_LIB_NAMES)\n        if OpenMP_libomp_LIBRARY != \"\":\n            cmake_args.append(\"-DOpenMP_libomp_LIBRARY=\" + OpenMP_libomp_LIBRARY)\n        if ENABLE_BITCODE != \"\":\n            cmake_args.append(\"-DENABLE_BITCODE=\" + ENABLE_BITCODE)\n        if ENABLE_ARC != \"\":\n            cmake_args.append(\"-DENABLE_ARC=\" + ENABLE_ARC)\n        if ENABLE_VISIBILITY != \"\":\n            cmake_args.append(\"-DENABLE_VISIBILITY=\" + ENABLE_VISIBILITY)\n\n        build_args = []\n\n        if self.compiler.compiler_type == \"msvc\":\n            # Single config generators are handled \"normally\"\n            single_config = any(x in cmake_generator for x in {\"NMake\", \"Ninja\"})\n\n            # CMake allows an arch-in-generator style for backward compatibility\n            contains_arch = any(x in cmake_generator for x in {\"ARM\", \"Win64\"})\n\n            # Specify the arch if using MSVC generator, but only if it doesn't\n            # contain a backward-compatibility arch spec already in the\n            # generator name.\n            if not single_config and not contains_arch:\n                cmake_args += [\"-A\", PLAT_TO_CMAKE[self.plat_name]]\n\n            # Multi-config generators have a different way to specify configs\n            if not single_config:\n                cmake_args += [\n                    \"-DCMAKE_LIBRARY_OUTPUT_DIRECTORY_{}={}\".format(cfg.upper(), extdir)\n                ]\n                build_args += [\"--config\", cfg]\n\n        # Set CMAKE_BUILD_PARALLEL_LEVEL to control the parallel build level\n        # across all generators.\n        if \"CMAKE_BUILD_PARALLEL_LEVEL\" not in os.environ:\n            # self.parallel is a Python 3 only way to set parallel jobs by hand\n            # using -j in the build_ext call, not supported by pip or PyPA-build.\n            if hasattr(self, \"parallel\") and self.parallel:\n                # CMake 3.12+ only.\n                build_args += [\"-j{}\".format(self.parallel)]\n            else:\n                build_args += [\"-j4\"]\n\n        if not os.path.exists(self.build_temp):\n            os.makedirs(self.build_temp)\n\n        subprocess.check_call(\n            [\"cmake\", ext.sourcedir] + cmake_args, cwd=self.build_temp\n        )\n        subprocess.check_call(\n            [\"cmake\", \"--build\", \".\"] + build_args, cwd=self.build_temp\n        )\n\n\nif sys.version_info < (3, 0):\n    sys.exit(\"Sorry, Python < 3.0 is not supported\")\n\nrequirements = [\"numpy\", \"tqdm\", \"requests\", \"portalocker\", \"opencv-python\"]\n\nwith io.open(\"README.md\", encoding=\"utf-8\") as h:\n    long_description = h.read()\n\nsetup(\n    name=\"ncnn\",\n    version=find_version(),\n    author=\"nihui\",\n    author_email=\"nihuini@tencent.com\",\n    maintainer=\"caishanli\",\n    maintainer_email=\"caishanli25@gmail.com\",\n    description=\"ncnn is a high-performance neural network inference framework optimized for the mobile platform\",\n    long_description=long_description,\n    long_description_content_type=\"text/markdown\",\n    url=\"https://github.com/Tencent/ncnn\",\n    classifiers=[\n        \"Programming Language :: C++\",\n        \"Programming Language :: Python :: 3\",\n        \"Programming Language :: Python :: 3.6\",\n        \"Programming Language :: Python :: 3.7\",\n        \"Programming Language :: Python :: 3.8\",\n        \"Programming Language :: Python :: 3.9\",\n        \"Programming Language :: Python :: 3.10\",\n        \"License :: OSI Approved :: BSD License\",\n        \"Operating System :: OS Independent\",\n    ],\n    license=\"BSD-3\",\n    python_requires=\">=3.5\",\n    packages=find_packages(\"python\"),\n    package_dir={\"\": \"python\"},\n    install_requires=requirements,\n    ext_modules=[CMakeExtension(\"ncnn\")],\n    cmdclass={'install': InstallCommand, \"build_ext\": CMakeBuild},\n)\n"
        },
        {
          "name": "src",
          "type": "tree",
          "content": null
        },
        {
          "name": "tests",
          "type": "tree",
          "content": null
        },
        {
          "name": "toolchains",
          "type": "tree",
          "content": null
        },
        {
          "name": "tools",
          "type": "tree",
          "content": null
        }
      ]
    }
  ]
}