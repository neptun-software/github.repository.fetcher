{
  "metadata": {
    "timestamp": 1736566358543,
    "page": 118,
    "hasNextPage": true,
    "endCursor": "Y3Vyc29yOjEyMA==",
    "completionStatus": "IN_PROGRESS"
  },
  "repositories": [
    {
      "nameWithOwner": "capnproto/capnproto",
      "stars": 11848,
      "defaultBranch": "v2",
      "files": [
        {
          "name": ".cirrus.yml",
          "type": "blob",
          "size": 0.9375,
          "content": "env:\n  CIRRUS_CLONE_DEPTH: 1\n\nfreebsd_task:\n  matrix:\n    - name: FreeBSD 13.0 (GCC 10 from packages)\n      # RunCatchingExceptionsOtherException fails on 13.0 with system Clang\n      # 11.0 and ports Clang 10/11 as well, so GCC 10 is used instead.\n      freebsd_instance:\n        image_family: freebsd-13-0\n      preinstall_script:\n        # Stock clang11 fails some exception unit tests\n        pkg install -y gcc10\n      env:\n        CC: gcc10\n        CXX: g++10\n    - name: FreeBSD 12.2 (System Clang 10)\n      freebsd_instance:\n        image_family: freebsd-12-2\n    - name: FreeBSD 11.4 (System Clang 10)\n      freebsd_instance:\n        image_family: freebsd-11-4\n  install_script:\n    pkg install -y automake autoconf libtool\n  compiler_version_script:\n    ${CXX:-\"c++\"} --version\n  autoreconf_script:\n    - cd c++ && autoreconf -i\n  configure_script:\n    - cd c++ && ./configure\n  build_script:\n    - make -C c++\n  test_script:\n    - make -C c++ check\n"
        },
        {
          "name": ".github",
          "type": "tree",
          "content": null
        },
        {
          "name": ".gitignore",
          "type": "blob",
          "size": 1.2939453125,
          "content": "# Kenton's personal backup script.\n/backup.sh\n\n# Eclipse-generated stuff.\n.cproject\n.project\n.pydevproject\n.settings\n.dist-buildwrapper\n/c++/gen/\n\n# VS Code config\n.vscode/\n\n# Code you may want to map in from elsewhere.\n/c++/src/base\n/c++/src/capnp/compilerbin\n/c++/src/ekam\n/c++/src/os\n/c++/src/protobuf\n/c++/src/snappy\n/c++/src/samples\n\n# Ekam build artifacts.\n/c++/tmp/\n/c++/bin/\n/c++/deps/\n\n# setup-ekam.sh\n/c++/.ekam\n\n# super-test.sh\n/tmp-staging\n\n# Jekyll-generated site\n/doc/_site\n\n# Checkout of gh-pages made by /doc/push-site.sh\n/doc/.gh-pages\n\n# cabal-install artifacts\n/compiler/dist/\n\n# Make artefacts\n/c++/.libs/\n/c++/Makefile\n/c++/Makefile.in\n/c++/**/*.o\n/c++/**/*.lo\n/c++/**/.deps/\n/c++/**/.dirstamp\n/c++/stamp-h1\n/c++/**/*.log\n/c++/test_capnpc_middleman\n/c++/**/test*.capnp.*\n/c++/*.la\n/c++/**/*.trs\n/c++/aclocal.m4\n/c++/autom4te.cache/\n/c++/build-aux/\n/c++/capnp\n/c++/capnp-evolution-test\n/c++/cmake/CapnProtoConfig.cmake\n/c++/cmake/CapnProtoConfigVersion.cmake\n/c++/pkgconfig/*.pc\n/c++/capnp-test\n/c++/capnpc-c++\n/c++/capnpc-capnp\n/c++/config.*\n/c++/configure\n/c++/libtool\n/c++/m4/libtool.m4\n/c++/m4/ltoptions.m4\n/c++/m4/ltsugar.m4\n/c++/m4/ltversion.m4\n/c++/m4/lt~obsolete.m4\n/c++/samples/addressbook\n/c++/.cache/\n\n# editor artefacts\n*~\n\n# cross-compiling / glibc testing\n/dockcross\n\n# bazel output\nbazel-*\n"
        },
        {
          "name": "CMakeLists.txt",
          "type": "blob",
          "size": 0.1044921875,
          "content": "cmake_minimum_required(VERSION 3.16)\nproject(\"Cap'n Proto Root\" CXX)\ninclude(CTest)\n\nadd_subdirectory(c++)\n"
        },
        {
          "name": "CONTRIBUTORS",
          "type": "blob",
          "size": 1.470703125,
          "content": "The following people have made large code contributions to this repository.\nThose contributions are copyright the respective authors and licensed by them\nunder the same MIT license terms as the rest of the library.\n\nKenton Varda <kenton@sandstorm.io> <kenton@cloudflare.com>: Primary Author\nJason Choy <jjwchoy@gmail.com>: kj/threadlocal.h and other iOS tweaks, `name` annotation in C++ code generator\nRemy Blank <rblank@google.com> (contributions copyright Google Inc.): KJ Timers\nJoshua Warner <joshuawarner32@gmail.com>: cmake build, AnyStruct/AnyList, other stuff\nScott Purdy <scott@fer.io>: kj/std iostream interface\nBryan Borham <bjboreham@gmail.com>: Initial MSVC support\nPhilip Quinn <p@partylemon.com>: cmake build and other assorted bits\nBrian Taylor <el.wubo@gmail.com>: emacs syntax highlighting\nBen Laurie <ben@links.org>: discovered and responsibly disclosed security bugs\nKamal Marhubi <kamal@marhubi.com>: JSON parser\nOliver Kuckertz <oliver.kuckertz@mologie.de>: FdObserver POLLPRI support\nHarris Hancock <vortrab@gmail.com>: MSVC support\nBranislav Katreniak <branislav.katreniak@digitalstrom.com>: JSON decode\nMatthew Maurer <matthew.r.maurer@gmail.com>: Canonicalization Support\nDavid Renshaw <david@sandstorm.io>: bugfixes and miscellaneous maintenance\nIngvar Stepanyan <me@rreverser.com> <ingvar@cloudflare.com>: Custom handlers for JSON decode\n\nThis file does not list people who maintain their own Cap'n Proto\nimplementations as separate projects.  Those people are awesome too!  :)\n"
        },
        {
          "name": "LICENSE",
          "type": "blob",
          "size": 1.2021484375,
          "content": "Copyright (c) 2013-2017 Sandstorm Development Group, Inc.; Cloudflare, Inc.;\nand other contributors. Each commit is copyright by its respective author or\nauthor's employer.\n\nLicensed under the MIT License:\n\nPermission is hereby granted, free of charge, to any person obtaining a copy\nof this software and associated documentation files (the \"Software\"), to deal\nin the Software without restriction, including without limitation the rights\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\ncopies of the Software, and to permit persons to whom the Software is\nfurnished to do so, subject to the following conditions:\n\nThe above copyright notice and this permission notice shall be included in\nall copies or substantial portions of the Software.\n\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN\nTHE SOFTWARE.\n\n"
        },
        {
          "name": "README.md",
          "type": "blob",
          "size": 0.822265625,
          "content": "**THIS IS THE V2 DEVELOPMENT BRANCH**\n\nOn this branch, we may make breaking changes to the API at any time. Do not use this branch if you want stability. If you want \"1.0 plus bug fixes\", use the `master` branch.\n\nFor more, see the 1.0 release announcement:\n\nhttps://capnproto.org/news/2023-07-28-capnproto-1.0.html\n\n------------------------------------------------------------\n\n<img src='http://kentonv.github.io/capnproto/images/infinity-times-faster.png' style='width:334px; height:306px; float: right;'>\n\nCap'n Proto is an insanely fast data interchange format and capability-based RPC system. Think\nJSON, except binary. Or think [Protocol Buffers](https://github.com/google/protobuf), except faster.\nIn fact, in benchmarks, Cap'n Proto is INFINITY TIMES faster than Protocol Buffers.\n\n[Read more...](http://kentonv.github.io/capnproto/)\n"
        },
        {
          "name": "RELEASE-PROCESS.md",
          "type": "blob",
          "size": 3.3369140625,
          "content": "How to release\n==============\n\n**Developing**\n\n* First, develop some new features to release!  As you do, make sure to keep the documentation\n  up-to-date.\n\n**Testing**\n\n* Run `super-test.sh` on as many platforms as you have available.  Remember that you can easily run\n  on any machine available through ssh using `./super-test.sh remote [hostname]`.  Also run in\n  Clang mode.  (If you are Kenton and running from Kenton's home machine and network, use\n  `./mega-test.py mega-test.cfg` to run on all supported compilers and platforms.)\n\n* Manually test Windows/MSVC -- unfortunately this can't be automated by super-test.sh.\n\n* Manually run the pointer fuzz tests under Valgrind. This will take 40-80 minutes.\n\n      valgrind ./capnp-test -fcapnp/fuzz-test.c++\n\n* Manually run the AFL fuzz tests by running `afl-fuzz.sh`. There are three test cases, and ideally each should run for 24 hours or more.\n\n**Documenting**\n\n* Write a blog post discussing what is new, placing it in doc/_posts.\n\n* Run jekyll locally and review the blog post and docs.\n\n**Releasing**\n\n* Check out the master branch in a fresh directory.  Do NOT use your regular repo, as the release\n  script commits changes and if anything goes wrong you'll probably want to trash the whole thing\n  without pushing.  DO NOT git clone the repo from an existing local repo -- check it out directly\n  from github.  Otherwise, when it pushes its changes back, they'll only be pushed back to your\n  local repo.\n\n* Run `./release.sh candidate`.  This creates a new release branch, updates the version number to\n  `-rc1`, builds release tarballs, copies them to the current directory, then switches back to the\n  master branch and bumps the version number there.  After asking for final confirmation, it will\n  upload the tarball to S3 and push all changes back to github.\n\n* Install your release candidates on your local machine, as if you were a user.\n\n* Go to `c++/samples` in the git repo and run `./test.sh`.  It will try to build against your\n  installed copy.\n\n* Post the release candidates somewhere public and then send links to the mailing list for people\n  to test.  Wait a bit for bug reports.\n\n* If there are any problems, fix them in master and start a new release candidate by running\n  `./release.sh candidate <commit>...` from the release branch.  This will cherry-pick the specified\n  commits into the release branch and create a new candidate.  Repeat until all problems are fixed.\n  Be sure that any such fixes include tests or process changes so that they don't happen again.\n\n* You should now be ready for an official release.  Run `./release.sh final`.  This will remove the\n  \"-rcN\" suffix from the version number, update the version number shown on the downloads page,\n  build the final release package, and -- after final confirmation -- upload the binary, push\n  changes to git, and publish the new documentation.\n\n* Submit the newly-published blog post to news sites and social media as you see fit.\n\n* If problems are discovered in the release, fix them in master and run\n  `./release.sh candidate <commit>...` in the release branch to start a new micro release.  The\n  script automatically sees that the current branch's version no longer contains `-rc`, so it starts\n  a new branch.  Repeat the rest of the process above.  If you decide to write a blog post (not\n  always necessary), do it in the master branch and cherry-pick it.\n"
        },
        {
          "name": "c++",
          "type": "tree",
          "content": null
        },
        {
          "name": "doc",
          "type": "tree",
          "content": null
        },
        {
          "name": "highlighting",
          "type": "tree",
          "content": null
        },
        {
          "name": "kjdoc",
          "type": "tree",
          "content": null
        },
        {
          "name": "mega-test-kenton-home.cfg",
          "type": "blob",
          "size": 0.42578125,
          "content": "linux-gcc-4.9      9717 ./super-test.sh tmpdir capnp-gcc-4.9 -j8 gcc-4.9\nlinux-gcc          9720 ./super-test.sh tmpdir capnp-gcc -j8\nlinux-clang-3.5    9855 ./super-test.sh tmpdir capnp-clang-3.5 -j8 compiler clang++-3.5\nlinux-clang-5.0    9858 ./super-test.sh tmpdir capnp-clang-5.0 -j8 compiler clang++-5.0\nmac                7037 ./super-test.sh remote beat caffeinate\ncygwin             8465 ./super-test.sh remote Kenton@flashman\n"
        },
        {
          "name": "mega-test-kenton-work.cfg",
          "type": "blob",
          "size": 0.3701171875,
          "content": "linux-gcc-5        9717 ./super-test.sh tmpdir capnp-gcc-5 compiler g++-5\nlinux-gcc-6        9710 ./super-test.sh tmpdir capnp-gcc-6 compiler g++-6\nlinux-clang-3      9855 ./super-test.sh tmpdir capnp-clang-3 compiler clang++-3.8\nlinux-clang-5      9858 ./super-test.sh tmpdir capnp-clang-5 compiler clang++-5.0\nexotic             4759 ./super-test.sh tmpdir capnp-exotic exotic\n"
        },
        {
          "name": "mega-test-quick.cfg",
          "type": "blob",
          "size": 0.3505859375,
          "content": "linux-gcc-4.9       950 ./super-test.sh tmpdir capnp-gcc-4.9 quick gcc-4.9\nlinux-gcc-4.8       950 ./super-test.sh tmpdir capnp-gcc-4.8 quick gcc-4.8\nlinux-clang         980 ./super-test.sh tmpdir capnp-clang quick clang\nmac                 905 ./super-test.sh remote beat caffeinate quick\ncygwin              945 ./super-test.sh remote Kenton@flashman quick\n"
        },
        {
          "name": "mega-test.py",
          "type": "blob",
          "size": 3.833984375,
          "content": "#! /usr/bin/env python\n\n# MEGA TEST\n#\n# usage:  mega-test.py <config>\n#\n# This runs several tests in parallel and shows progress bars for each, based on a config file.\n#\n# <config> is a file containing a list of commands to run along with the expected number of lines\n# they will output (to stdout and stderr combined), which is how the progress bar is calculated.\n# The format of the file is simply one test per line, with the line containing the test name,\n# the number of output lines expected, and the test command.  Example:\n#\n#     mytest 1523 ./my-test --foo bar\n#     another 862 ./another-test --baz\n#\n# Each command is interpreted by `sh -euc`, therefore it is acceptable to use environment\n# variables and other shell syntax.\n#\n# After all tests complete, the config file will be rewritten to update the line counts to the\n# actual number of lines seen for all passing tests (failing tests are not updated).\n\nimport sys\nimport re\nimport os\nfrom errno import EAGAIN\nfrom fcntl import fcntl, F_GETFL, F_SETFL\nfrom select import poll, POLLIN, POLLHUP\nfrom subprocess import Popen, PIPE, STDOUT\n\nCONFIG_LINE = re.compile(\"^([^ ]+) +([0-9]+) +(.*)$\")\n\nif len(sys.argv) != 2:\n  sys.stderr.write(\"Wrong number of arguments.\\n\");\n  sys.exit(1)\n\nif not os.access(\"/tmp/test-output\", os.F_OK):\n  os.mkdir(\"/tmp/test-output\")\n\nconfig = open(sys.argv[1], 'r')\n\ntests = []\n\nclass Test:\n  def __init__(self, name, command, lines):\n    self.name = name\n    self.command = command\n    self.lines = lines\n    self.count = 0\n    self.done = False\n\n  def start(self, poller):\n    self.proc = Popen([\"sh\", \"-euc\", test.command], stdin=dev_null, stdout=PIPE, stderr=STDOUT)\n    fd = self.proc.stdout.fileno()\n    flags = fcntl(fd, F_GETFL)\n    fcntl(fd, F_SETFL, flags | os.O_NONBLOCK)\n    poller.register(self.proc.stdout, POLLIN)\n    self.log = open(\"/tmp/test-output/\" + self.name + \".log\", \"w\")\n\n  def update(self):\n    try:\n      while True:\n        text = self.proc.stdout.read()\n        if text == \"\":\n          self.proc.wait()\n          self.done = True\n          self.log.close()\n          return True\n        self.count += text.count(\"\\n\")\n        self.log.write(text)\n    except IOError as e:\n      if e.errno == EAGAIN:\n        return False\n      raise\n\n  def print_bar(self):\n    percent = self.count * 100 / self.lines\n    status = \"(%3d%%)\" % percent\n\n    color_on = \"\"\n    color_off = \"\"\n\n    if self.done:\n      if self.proc.returncode == 0:\n        color_on = \"\\033[0;32m\"\n        status = \"PASS\"\n      else:\n        color_on = \"\\033[0;31m\"\n        status = \"FAIL: /tmp/test-output/%s.log\" % self.name\n      color_off = \"\\033[0m\"\n\n    print \"%s%-16s |%-25s| %6d/%6d %s%s    \" % (\n        color_on, self.name, '=' * min(percent / 4, 25), self.count, self.lines, status, color_off)\n\n  def passed(self):\n    return self.proc.returncode == 0\n\nfor line in config:\n  if len(line) > 0 and not line.startswith(\"#\"):\n    match = CONFIG_LINE.match(line)\n    if not match:\n      sys.stderr.write(\"Invalid config syntax: %s\\n\" % line);\n      sys.exit(1)\n    test = Test(match.group(1), match.group(3), int(match.group(2)))\n    tests.append(test)\n\nconfig.close()\n\ndev_null = open(\"/dev/null\", \"rw\")\npoller = poll()\nfd_map = {}\n\nfor test in tests:\n  test.start(poller)\n  fd_map[test.proc.stdout.fileno()] = test\n\nactive_count = len(tests)\n\ndef print_bars():\n  for test in tests:\n    test.print_bar()\n\nprint_bars()\n\nwhile active_count > 0:\n  for (fd, event) in poller.poll():\n    if fd_map[fd].update():\n      active_count -= 1\n      poller.unregister(fd)\n  sys.stdout.write(\"\\033[%dA\\r\" % len(tests))\n  print_bars()\n\nnew_config = open(sys.argv[1], \"w\")\nfor test in tests:\n  if test.passed():\n    new_config.write(\"%-16s %6d %s\\n\" % (test.name, test.count, test.command))\n  else:\n    new_config.write(\"%-16s %6d %s\\n\" % (test.name, test.lines, test.command))\n\nfor test in tests:\n  if not test.passed():\n    sys.exit(1)\n\nsys.exit(0)\n"
        },
        {
          "name": "release.sh",
          "type": "blob",
          "size": 11.6923828125,
          "content": "#! /usr/bin/env bash\n\nset -euo pipefail\n\nif [ \"$1\" != \"package\" ] && [ \"$1\" != \"bump-major\" ]; then\n  if (git grep -Er KJ_DBG c++/src | egrep -v '/debug(-test)?[.]' | grep -v 'See KJ_DBG\\.$'); then\n    echo '*** Error:  There are instances of KJ_DBG in the code.' >&2\n    exit 1\n  fi\n\n  if (git grep -Er 'TODO\\((now|soon)\\)' *); then\n    echo '*** Error:  There are release-blocking TODOs in the code.' >&2\n    exit 1\n  fi\nfi\n\ndoit() {\n  echo \"@@@@ $@\"\n  \"$@\"\n}\n\nget_version() {\n  local VERSION=$(grep '^AC_INIT' c++/configure.ac | sed -e 's/^[^]]*],\\[\\([^]]*\\)].*$/\\1/g')\n  if [[ ! \"$VERSION\" =~ $1 ]]; then\n    echo \"Couldn't parse version: $VERSION\" >&2\n    exit 1\n  fi\n  echo \"$VERSION\"\n}\n\nget_release_version() {\n  get_version '^[0-9]+[.][0-9]+[.][0-9]+(-rc[0-9]+|[.][0-9]+)?$'\n}\n\nupdate_version() {\n  local OLD=$1\n  local NEW=$2\n  local BRANCH_DESC=$3\n\n  local OLD_REGEX=${OLD//./[.]}\n  doit sed -i -e \"s/$OLD_REGEX/$NEW/g\" c++/configure.ac\n  doit sed -i -e \"s/set(VERSION.*)/set(VERSION $NEW)/g\" c++/CMakeLists.txt\n\n  local NEW_NOTAG=${NEW%%-*}\n  declare -a NEW_ARR=(${NEW_NOTAG//./ })\n  doit sed -i -re \"\n      s/^#define CAPNP_VERSION_MAJOR [0-9]+\\$/#define CAPNP_VERSION_MAJOR ${NEW_ARR[0]}/g;\n      s/^#define CAPNP_VERSION_MINOR [0-9]+\\$/#define CAPNP_VERSION_MINOR ${NEW_ARR[1]}/g;\n      s/^#define CAPNP_VERSION_MICRO [0-9]+\\$/#define CAPNP_VERSION_MICRO ${NEW_ARR[2]:-0}/g\" \\\n      c++/src/capnp/common.h\n\n  local NEW_COMBINED=$(( ${NEW_ARR[0]} * 1000000 + ${NEW_ARR[1]} * 1000 + ${NEW_ARR[2]:-0 }))\n  doit sed -i -re \"s/^#elif CAPNP_VERSION != [0-9]*\\$/#elif CAPNP_VERSION != $NEW_COMBINED/g\" \\\n      c++/src/*/*.capnp.h c++/src/*/*/*.capnp.h\n\n  doit git commit -a -m \"Set $BRANCH_DESC version to $NEW.\"\n}\n\nbuild_packages() {\n  local VERSION=$1\n  local VERSION_BASE=${VERSION%%-*}\n\n  echo \"=========================================================================\"\n  echo \"Building C++ package...\"\n  echo \"=========================================================================\"\n\n  # make dist tarball and move into ..\n  cd c++\n  doit autoreconf -i\n  doit ./configure\n  doit make -j$(nproc) distcheck\n  doit mv capnproto-c++-$VERSION.tar.gz ..\n  doit make distclean\n\n  # build windows executables\n  doit ./configure --host=i686-w64-mingw32 --with-external-capnp \\\n      --disable-shared CXXFLAGS='-static-libgcc -static-libstdc++'\n  doit make -j$(nproc) capnp.exe capnpc-c++.exe capnpc-capnp.exe\n  doit i686-w64-mingw32-strip capnp.exe capnpc-c++.exe capnpc-capnp.exe\n  doit mkdir capnproto-tools-win32-$VERSION\n  doit mv capnp.exe capnpc-c++.exe capnpc-capnp.exe capnproto-tools-win32-$VERSION\n  doit make maintainer-clean\n\n  # repack dist tarball and win32 tools into win32 zip, with DOS line endings\n  doit tar zxf ../capnproto-c++-$VERSION.tar.gz\n  find capnproto-c++-$VERSION -name '*.c++' -o -name '*.h' -o -name '*.capnp' -o -name '*.md' -o -name '*.txt' | grep -v testdata | doit xargs unix2dos\n  doit zip -r ../capnproto-c++-win32-$VERSION.zip capnproto-c++-$VERSION capnproto-tools-win32-$VERSION\n\n  rm -rf capnproto-c++-$VERSION capnproto-tools-win32-$VERSION\n  cd ..\n}\n\ncherry_pick() {\n  shift\n  if [ $# -gt 0 ]; then\n    echo \"=========================================================================\"\n    echo \"Cherry-picking fixes\"\n    echo \"=========================================================================\"\n    doit git cherry-pick \"$@\"\n  fi\n}\n\ndone_banner() {\n  local VERSION=$1\n  local PUSH=$2\n  local FINAL=$3\n  echo \"=========================================================================\"\n  echo \"Done\"\n  echo \"=========================================================================\"\n  echo \"Ready to release:\"\n  echo \"  capnproto-c++-$VERSION.tar.gz\"\n  echo \"  capnproto-c++-win32-$VERSION.zip\"\n  echo \"Don't forget to push changes:\"\n  echo \"  git push origin $PUSH\"\n\n  read -s -n 1 -p \"Shall I push to git and upload to capnproto.org now? (y/N)\" YESNO\n\n  echo\n  case \"$YESNO\" in\n    y | Y )\n      doit git push origin $PUSH\n      doit gce-ss copy-files capnproto-c++-$VERSION.tar.gz capnproto-c++-win32-$VERSION.zip \\\n          alpha2:/var/www/capnproto.org\n\n      if [ \"$FINAL\" = yes ]; then\n        echo \"=========================================================================\"\n        echo \"Publishing docs\"\n        echo \"=========================================================================\"\n        cd doc\n        doit ./push-site.sh\n        cd ..\n        echo \"=========================================================================\"\n        echo \"Really done\"\n        echo \"=========================================================================\"\n      fi\n\n      echo \"Release is available at:\"\n      echo \"  http://capnproto.org/capnproto-c++-$VERSION.tar.gz\"\n      ;;\n    * )\n      echo \"OK, do it yourself then.\"\n      ;;\n  esac\n}\n\nBRANCH=$(git rev-parse --abbrev-ref HEAD)\n\ncase \"${1-}:$BRANCH\" in\n  bump-major:* )\n    echo \"Bump major version number on HEAD.\"\n    HEAD_VERSION=$(get_version '^[0-9]+[.][0-9]+-dev$')\n    OLD_MAJOR=$(echo $HEAD_VERSION | cut -d. -f1)\n    NEW_VERSION=$(( OLD_MAJOR + 1 )).0-dev\n    update_version $HEAD_VERSION $NEW_VERSION \"mainline\"\n    ;;\n\n  # ======================================================================================\n  candidate:master )\n    echo \"New major release.\"\n\n    if [ $# -gt 1 ]; then\n      echo \"Cannot cherry-pick when starting from master.  Do it yourself.\" >&2\n      exit 1\n    fi\n\n    HEAD_VERSION=$(get_version '^[0-9]+[.][0-9]+-dev$')\n    RELEASE_VERSION=${HEAD_VERSION%%-dev}.0\n\n    echo \"Version: $RELEASE_VERSION\"\n\n    echo \"=========================================================================\"\n    echo \"Creating release branch...\"\n    echo \"=========================================================================\"\n    doit git checkout -b release-$RELEASE_VERSION\n\n    update_version $HEAD_VERSION $RELEASE_VERSION-rc1 \"release branch\"\n\n    build_packages $RELEASE_VERSION-rc1\n\n    echo \"=========================================================================\"\n    echo \"Updating version in master branch...\"\n    echo \"=========================================================================\"\n\n    doit git checkout master\n    declare -a VERSION_ARR=(${RELEASE_VERSION//./ })\n    NEXT_VERSION=${VERSION_ARR[0]}.$((VERSION_ARR[1] + 1))\n\n    update_version $HEAD_VERSION $NEXT_VERSION-dev \"mainline\"\n\n    done_banner $RELEASE_VERSION-rc1 \"master release-$RELEASE_VERSION\" no\n    ;;\n\n  # ======================================================================================\n  candidate:release-* )\n    echo \"New release candidate.\"\n    OLD_VERSION=$(get_release_version)\n\n    if [[ $OLD_VERSION == *-rc* ]]; then\n      # New release candidate for existing release.\n\n      RC=${OLD_VERSION##*-rc}\n      BRANCH_VERSION=${OLD_VERSION%%-rc*}\n      RC_VERSION=$BRANCH_VERSION-rc$(( RC + 1 ))\n\n      echo \"Version: $RC_VERSION\"\n    else\n      # New micro release.\n\n      declare -a VERSION_ARR=(${OLD_VERSION//./ })\n      BRANCH_VERSION=${VERSION_ARR[0]}.${VERSION_ARR[1]}.$((VERSION_ARR[2] + 1))\n\n      RC_VERSION=$BRANCH_VERSION-rc1\n      echo \"Version: $RC_VERSION\"\n\n      echo \"=========================================================================\"\n      echo \"Creating new release branch...\"\n      echo \"=========================================================================\"\n\n      doit git checkout -b release-$BRANCH_VERSION\n    fi\n\n    echo \"=========================================================================\"\n    echo \"Updating version number to $RC_VERSION...\"\n    echo \"=========================================================================\"\n\n    update_version $OLD_VERSION $RC_VERSION \"release branch\"\n\n    cherry_pick \"$@\"\n\n    build_packages $RC_VERSION\n\n    done_banner $RC_VERSION release-$BRANCH_VERSION no\n    ;;\n\n  # ======================================================================================\n  final:release-* )\n    echo \"Final release.\"\n    OLD_VERSION=$(get_release_version)\n\n    if [[ $OLD_VERSION != *-rc* ]]; then\n      echo \"Current version is already a final release.  You need to create a new candidate first.\" >&2\n      exit 1\n    fi\n\n    if [ $# -gt 1 ]; then\n      echo \"Cannot cherry-pick into final release.  Make another candidate.\" >&2\n      exit 1\n    fi\n\n    RC=${OLD_VERSION##*-rc}\n    NEW_VERSION=${OLD_VERSION%%-rc*}\n\n    echo \"Version: $NEW_VERSION\"\n\n    echo \"=========================================================================\"\n    echo \"Updating version number to $NEW_VERSION...\"\n    echo \"=========================================================================\"\n\n    doit sed -i -re \"s/capnproto-c[+][+]-[0-9]+[.][0-9]+[.][0-9]+([.][0-9]+)?\\>/capnproto-c++-$NEW_VERSION/g\" doc/install.md\n    doit sed -i -re \"s/capnproto-c[+][+]-win32-[0-9]+[.][0-9]+[.][0-9]+([.][0-9]+)?\\>/capnproto-c++-win32-$NEW_VERSION/g\" doc/install.md\n    doit sed -i -re \"s/capnproto-tools-win32-[0-9]+[.][0-9]+[.][0-9]+([.][0-9]+)?\\>/capnproto-tools-win32-$NEW_VERSION/g\" doc/install.md\n    update_version $OLD_VERSION $NEW_VERSION \"release branch\"\n\n    doit git tag v$NEW_VERSION\n\n    build_packages $NEW_VERSION\n\n    done_banner $NEW_VERSION \"v$NEW_VERSION release-$NEW_VERSION\" yes\n    ;;\n\n  # ======================================================================================\n  security:release-* )\n    echo \"Security release.\"\n    OLD_VERSION=$(get_release_version)\n\n    if [[ $OLD_VERSION == *-rc* ]]; then\n      echo \"Security releases don't have candidates.\" >&2\n      exit 1\n    fi\n\n    declare -a VERSION_ARR=(${OLD_VERSION//./ } 0)\n    NEW_VERSION=${VERSION_ARR[0]}.${VERSION_ARR[1]}.${VERSION_ARR[2]}.$((VERSION_ARR[3] + 1))\n\n    echo \"Version: $NEW_VERSION\"\n\n    echo \"=========================================================================\"\n    echo \"Updating version number to $NEW_VERSION...\"\n    echo \"=========================================================================\"\n\n    doit sed -i -re \"s/capnproto-c[+][+]-[0-9]+[.][0-9]+[.][0-9]+([.][0-9]+)?\\>/capnproto-c++-$NEW_VERSION/g\" doc/install.md\n    doit sed -i -re \"s/capnproto-c[+][+]-win32-[0-9]+[.][0-9]+[.][0-9]+([.][0-9]+)?\\>/capnproto-c++-win32-$NEW_VERSION/g\" doc/install.md\n    doit sed -i -re \"s/capnproto-tools-win32-[0-9]+[.][0-9]+[.][0-9]+([.][0-9]+)?\\>/capnproto-tools-win32-$NEW_VERSION/g\" doc/install.md\n    update_version $OLD_VERSION $NEW_VERSION \"release branch\"\n\n    cherry_pick \"$@\"\n\n    doit git tag v$NEW_VERSION\n\n    build_packages $NEW_VERSION\n\n    done_banner $NEW_VERSION \"v$NEW_VERSION release-$NEW_VERSION\" yes\n    ;;\n\n  # ======================================================================================\n  retry:release-* )\n    echo \"Retrying release.\"\n    OLD_VERSION=$(get_release_version)\n    echo \"Version: $OLD_VERSION\"\n\n    if [[ $OLD_VERSION == *-rc* ]]; then\n      # We can add more cherry-picks when retrying a candidate.\n      cherry_pick \"$@\"\n    else\n      if [ $# -gt 1 ]; then\n        echo \"Cannot cherry-pick into final release.  Make another candidate.\" >&2\n        exit 1\n      fi\n    fi\n\n    OLD_VERSION=$(get_release_version)\n    build_packages $OLD_VERSION\n\n    if [[ $OLD_VERSION == *-rc* ]]; then\n      BRANCH_VERSION=${OLD_VERSION%%-rc*}\n      done_banner $OLD_VERSION release-$BRANCH_VERSION no\n    else\n      doit git tag v$OLD_VERSION\n      done_banner $OLD_VERSION \"v$OLD_VERSION release-$OLD_VERSION\" no\n    fi\n    ;;\n\n  # ======================================================================================\n  package:* )\n    echo \"Just building a package.\"\n    build_packages $(get_version '.*')\n    ;;\n\n  # ======================================================================================\n  *:master )\n    echo \"Invalid command for mainline branch.  Only command is 'candidate'.\" >&2\n    exit 1\n    ;;\n\n  *:release-* )\n    echo \"Invalid command for release branch.  Commands are 'candidate', 'final', and 'retry'.\" >&2\n    exit 1\n    ;;\n\n  * )\n    echo \"Not a master or release branch.\" >&2\n    exit 1\n    ;;\nesac\n"
        },
        {
          "name": "security-advisories",
          "type": "tree",
          "content": null
        },
        {
          "name": "style-guide.md",
          "type": "blob",
          "size": 49.0869140625,
          "content": "# KJ Style\n\nThis document describes how to write C++ code in KJ style. It may be compared to the [Google C++ Style Guide](http://google-styleguide.googlecode.com/svn/trunk/cppguide.html).\n\nKJ style is used by KJ (obviously), [Cap'n Proto](https://capnproto.org), [Sandstorm.io](https://sandstorm.io), and possibly other projects. When submitting code to these projects, you should follow this guide.\n\n**Table of Contents**\n\n- [Rule #1: There are no rules](#rule-1-there-are-no-rules)\n- [Design Philosophy](#design-philosophy)\n  - [Value Types vs. Resource Types](#value-types-vs-resource-types)\n  - [RAII (Resource Acquisition Is Initialization)](#raii-resource-acquisition-is-initialization)\n  - [Ownership](#ownership)\n  - [No Singletons](#no-singletons)\n  - [Exceptions](#exceptions)\n  - [Threads vs. Event Loops](#threads-vs-event-loops)\n  - [Lazy input validation](#lazy-input-validation)\n  - [Premature optimization fallacy](#premature-optimization-fallacy)\n  - [Text is always UTF-8](#text-is-always-utf-8)\n- [C++ usage](#c-usage)\n  - [Use C++11 (or later)](#use-c11-or-later)\n  - [Heap allocation](#heap-allocation)\n  - [Pointers, references](#pointers-references)\n  - [Constness](#constness)\n  - [Inheritance](#inheritance)\n  - [Exceptions Usage](#exceptions-usage)\n  - [Template Metaprogramming](#template-metaprogramming)\n  - [Global Constructors](#global-constructors)\n  - [`dynamic_cast`](#dynamic_cast)\n  - [Use of Standard libraries](#use-of-standard-libraries)\n  - [Compiler warnings](#compiler-warnings)\n  - [Tools](#tools)\n- [Irrelevant formatting rules](#irrelevant-formatting-rules)\n  - [Naming](#naming)\n  - [Spacing and bracing](#spacing-and-bracing)\n  - [Comments](#comments)\n  - [File templates](#file-templates)\n\n## Rule #1: There are no rules\n\nThis guide contains suggestions, not rules.\n\nIf you wish to submit code to a project following KJ style, you should follow the guide so long as there is no good reason not to. You should not break rules just because you feel like it -- consistency is important for future maintainability. But, if you have a good, pragmatic reason to break a rule, do it. Do not ask permission. Just do it.\n\n## Design Philosophy\n\nThis section contains guidelines on software design that aren't necessarily C++-specific (though KJ's preferences here are obviously influenced by C++).\n\n### Value Types vs. Resource Types\n\nThere are two kinds of types: values and resources. Value types are simple data structures; they serve no purpose except to represent pure data. Resource types represent live objects with state and behavior, and often represent resources external to the program.\n\n* Value types make sense to copy (though they don't necessarily have copy constructors). Resource types are not copyable.\n* Value types always have move constructors (and sometimes copy constructors). Resource types are not movable; if ownership transfer is needed, the resource must be allocated on the heap.\n* Value types almost always have implicit destructors. Resource types may have an explicit destructor.\n* Value types should only be compared by value, not identity. Resource types can only be compared by identity.\n* Value types make sense to serialize. Resource types fundamentally cannot be serialized.\n* Value types rarely use inheritance and never have virtual methods. Resource types commonly do.\n* Value types generally use templates for polymorphism. Resource types generally use virtual methods / abstract interfaces.\n* You might even say that value types are used in functional programming style while resource types are used in object-oriented style.\n\nIn Cap'n Proto there is a very clear distinction between values and resources: interfaces are resource types whereas everything else is a value.\n\n### RAII (Resource Acquisition Is Initialization)\n\nKJ code is RAII-strict. Whenever it is the case that \"this block of code cannot exit cleanly without performing operation X\", then X *must* be performed in a destructor, so that X will happen regardless of how the block is exited (including by exception).\n\nUse the macros `KJ_DEFER`, `KJ_ON_SCOPE_SUCCESS`, and `KJ_ON_SCOPE_FAILURE` to easily specify some code that must be executed on exit from the current scope, without the need to define a whole class with a destructor.\n\nBe careful when writing complicated destructors. If a destructor performs multiple cleanup actions, you generally need to make sure that the latter actions occur even if the former ones throw an exception. For this reason, a destructor should generally perform no more than one cleanup action. If you need to clean up multiple things, have your class contain multiple members representing the different things that need cleanup, each with its own destructor. This way, if one member's destructor throws, the others still run.\n\n### Ownership\n\nEvery object has an \"owner\". The owner may be another object, or it may be a stack frame (which is in turn owned by its parent stack frame, and so on up to the top frame, which is owned by the thread, which itself is an object which is owned by something).\n\nThe owner decides when to destroy an object. If the owner itself is destroyed, everything it owns must be transitively destroyed. This should be accomplished through RAII style.\n\nThe owner specifies the lifetime of the object and how the object may be accessed. This specification may be through documented convention or actually enforced through the type system; the latter is preferred when possible.\n\nAn object can never own itself, including transitively.\n\nWhen declaring a pointer to an object which is owned by the scope, always use `kj::Own<T>`. Regular C++ pointers and references always point to objects that are *not* owned.\n\nWhen passing a regular C++ pointer or reference as a parameter or return value of a function, care must be taken to document assumptions about the lifetime of the object. In the absence of documentation, make the following assumptions:\n\n* A pointer or reference passed as a constructor parameter must remain valid for the lifetime of the constructed object.\n* A pointer or reference passed as a function or method parameter must remain valid until the function returns. In the case that the function returns a promise, then the object must remain live until the promise completes or is canceled.\n* A pointer or reference returned by a method remains valid at least until the object whose method was called is destroyed.\n* A pointer or reference returned by a stand-alone function likely refers to content of one of the function's parameters, and remains valid until that parameter is destroyed.\n\nNote that ownership isn't just about memory management -- it matters even in languages that implement garbage collection! Unless an object is 100% immutable, you need to keep track of who is allowed to modify it, and that generally requires declaring an owner. Moreover, even with GC, resource types commonly need `close()` method that acts very much like a C++ destructor, leading to all the same considerations. It is therefore completely wrong to believe garbage collection absolves you of thinking about ownership -- and this misconception commonly leads to huge problems in large-scale systems written in GC languages.\n\n#### Reference Counting\n\nReference counting is allowed, in which case an object will have multiple owners.\n\nWhen using reference counting, care must be taken to ensure that there is a clear contract between all owners about how the object shall be accessed. In general, this should mean one of the following:\n\n* Reference-counted value types should be immutable.\n* Reference-counted resource types should have an interface which clearly specifies how multiple clients should coordinate.\n\nCare must also be taken to avoid cyclic references (which would constitute self-ownership, and would cause a memory leak). Think carefully about what the object ownership graph looks like.\n\nAvoid reference counting when it is not absolutely necessary.\n\nKeep in mind that atomic (thread-safe) reference counting can be extremely slow. Consider non-atomic reference counting if it is feasible under your threading philosophy (under KJ's philosophy, non-atomic reference counting is OK).\n\n### No Singletons\n\nA \"singleton\" is any mutable object or value that is globally accessible. \"Globally accessible\" means that the object is declared as a global variable or static member variable, or that the object can be found by following pointers from such variables.\n\nNever use singletons. Singletons cause invisible and unexpected dependencies between components of your software that appear unrelated. Worse, the assumption that \"there should only be one of this object per process\" is almost always wrong, but its wrongness only becomes apparent after so much code uses the singleton that it is infeasible to change. Singleton interfaces often turn into unusable monstrosities in an attempt to work around the fact that they should never have been a singleton in the first place.\n\nSee [\"Singletons Considered Harmful\"](http://www.object-oriented-security.org/lets-argue/singletons) for a complete discussion.\n\n#### Global registries are singletons\n\nAn all-too-common-pattern in modular frameworks is to design a way to register named components via global-scope macros. For example:\n\n    // BAD BAD BAD\n    REGISTER_PLUGIN(\"foo\", fooEntryPoint);\n\nThis global registry is a singleton, and has many of the same problems as singletons. Don't do this. Again, see [\"Singletons Considered Harmful\"](http://www.object-oriented-security.org/lets-argue/singletons) for discussion.\n\n#### What to do instead\n\nHigh-level code (such as your `main()` function) should explicitly initialize the components the program needs. If component Foo depends on component Bar, then Foo's constructor should take a pointer to Bar as a parameter; the high-level code can then point each component at its dependencies explicitly.\n\nFor example, instead of a global registry, have high-level code construct a registry object and explicitly call some `register()` method to register each component that should be available through it. This way, when you read your `main()` function it's easy to see what components your program is using.\n\n#### Working around OS singletons\n\nUnfortunately, operating system APIs are traditionally singleton-heavy. The most obvious example is, of course, the filesystem.\n\nIn order to use these APIs while avoiding the problems of singletons, try to encapsulate OS singletons inside non-singleton interfaces as early on as possible in your program. For example, you might define an abstract interface called `Directory` with an implementation `DiskDirectory` representing a directory on disk. In your `main()` function, create two `DiskDirectory`s representing the root directory and the current working directory. From then on, have all of your code operate in terms of `Directory`. Pass the original `DiskDirectory` pointers into the components that need it.\n\n### Exceptions\n\nAn exception represents something that \"should never happen\", assuming everything is working as expected. Of course, things that \"should never happen\" in fact happen all the time. But, a program should never be written in such a way that it _expects_ an exception under normal circumstances.\n\nPut another way, exceptions are a way to achieve _fault tolerance_. Throwing an exception is a less-disruptive alternative to aborting the process. Exceptions are a _logistical_ construct, as opposed to a semantic one: an exception should never be part of your \"business logic\".\n\nFor example, exceptions may indicate conditions like:\n\n* Logistics of software development:\n  * There is a bug in the code.\n  * The requested method is not implemented.\n* Logistics of software usage:\n  * There is an error in the program's configuration.\n  * The input is invalid.\n* Logistics of distributed systems:\n  * A network connection was reset.\n  * An optimistic transaction was aborted due to concurrent modification.\n* Logistics of physical computation:\n  * The system's resources are exhausted (e.g. out of memory, out of disk space).\n  * The system is overloaded and must reject some requests to avoid long queues.\n\n#### Business logic should never catch\n\nIf you find that callers of your interface need to catch and handle certain kinds of exceptions in order to operate correctly, then you must change your interface (or overload it) such that those conditions can be handled without an exception ever being thrown. For example, if you have a method `Own<File> open(StringPtr name)` that opens a file, you may also want to offer `Maybe<Own<File>> openIfExists(StringPtr name)` that returns null rather than throwing an exception if the file is not found. (But you should probably keep `open()` as well, for the convenience of the common case where the caller will just throw an exception anyway.)\n\nNote that with this exception philosophy, Java-style \"checked exceptions\" (exceptions which are explicitly declared to be thrown by an interface) make no sense.\n\n#### How to handle an exception\n\nIn framework and logistical code, you may catch exceptions and try to handle them. Given the nature of exceptions, though, there are only a few things that are reasonable to do when receiving an exception:\n\n* On network disconnect or transaction failures, back up and start over from the beginning (restore connections and state, redo operations).\n* On resources exhausted / overloaded, retry again later, with exponential back-off.\n* On unimplemented methods, retry with a different implementation strategy, if there is one.\n* When no better option is available, report the problem to a human (the user and/or the developer).\n\n#### Exceptions can happen anywhere (including destructors)\n\nAny piece of code may contain a bug. Therefore, an exception can happen anywhere. This includes destructors. It doesn't matter how much you argue that destructors should not throw exceptions, because that is equivalent to arguing that code should not have bugs. We all wish our code never had bugs, but nevertheless it happens.\n\nUnfortunately, C++ made the awful decision that an exception thrown from a destructor that itself is called during stack unwind due to some other exception should cause the process to abort. This is an error in the language specification. Apparently, the committee could not agree on any other behavior, so they chose the worst possible behavior.\n\nIf exceptions are merely a means to fault tolerance, then it is perfectly clear what should happen in the case that a second exception is thrown while unwinding due to a first: the second exception should merely be discarded, or perhaps attached to the first as a supplementary note. The catching code usually does not care about the exception details anyway; it's just going to report that something went wrong, then maybe try to continue executing other, unrelated parts of the program. In fact, in most cases discarding the secondary exception makes sense, because it is often simply a side-effect of the fact that the code didn't complete normally, and so provides no useful additional information.\n\nAlas, C++ is what it is. So, in KJ, we work around the problem in a couple ways:\n\n* `kj::UnwindDetector` may be used to detect when a destructor is called during unwind and squelch secondary exceptions.\n* The `KJ_ASSERT` family of macros -- from which most exceptions are thrown in the first place -- implement a concept of \"recoverable\" exceptions, where it is safe to continue execution without throwing in cases where throwing would be bad. Assert macros in destructors must always be recoverable.\n\n#### Allowing `-fno-exceptions`\n\nKJ and Cap'n Proto are designed to function even when compiled with `-fno-exceptions`. In this case, throwing an exception behaves differently depending on whether the exception is \"fatal\" or \"recoverable\". Fatal exceptions abort the process. On a recoverable exception, on the other hand, execution continues normally, perhaps after replacing invalid data with some safe default. The exception itself is stored in a thread-local variable where code up the stack can check for it later on.\n\nThis compromise is made only so that C++ applications which eschew exceptions are still able to use Cap'n Proto. We do NOT recommend disabling exceptions if you have a choice. Moreover, code following this style guide (other than KJ and Cap'n Proto) is not required to be `-fno-exceptions`-safe, and in fact we recommend against it.\n\n### Threads vs. Event Loops\n\nThreads are hard, and synchronization between threads is slow. Even \"lock-free\" data structures usually require atomic operations, which are costly, and such algorithms are notoriously difficult to get right. Fine-grained synchronization will therefore be expensive at best and highly unstable at worst.\n\nKJ instead prefers event loop concurrency. In this model, each event callback is effectively a transaction; it does not need to worry about concurrent modification within the body of the function.\n\nMultiple threads may exist, but each one has its own event loop and is treated as sort of a lightweight process with shared memory. Every object in the process either belongs to a specific thread (who is allowed to read and modify it) or is transitively immutable (in which case all threads can safely read it concurrently). Threads communicate through asynchronous message-passing. In fact, the only big difference between KJ-style threads compared to using separate processes is that threads may transfer ownership of in-memory objects as part of a message send.\n\nNote that with hardware transactional memory, it may become possible to execute a single event loop across multiple CPU cores while behaving equivalently to a single thread, by executing each event callback as a hardware transaction. If so, this will be implemented as part of KJ's event loop machinery, transparently to apps.\n\n### Lazy input validation\n\nAs we all know, you should always validate your input.\n\nBut, when should you validate it? There are two plausible answers:\n\n* Upfront, on receipt.\n* Lazily, on use.\n\nUpfront validation occasionally makes sense for the purpose of easier debugging of problems: if an error is reported earlier, it's easier to find where it came from.\n\nHowever, upfront validation has some big problems.\n\n* It is inefficient, as it requires a redundant pass over the data. Lazy validation, in contrast, occurs at a time when you have already loaded the data for the purpose of using it. Extra passes are often cache-unfriendly and/or entail redundant I/O operations.\n\n* It encourages people to skip validation at time of use, on the assumption that it was already validated earlier. This is dangerous, as it entails a non-local assumption. E.g. are you really sure that there is no way to insert data into your database without having validated it? Are you really sure that the data hasn't been corrupted? Are you really sure that your code will never be called in a new situation where validation hasn't happened? Are you sure the data cannot have been modified between validation and use? In practice, you should be validating your input at time of use _even if_ you know it has already been checked previously.\n\n* The biggest problem: Upfront validation tends not to match actual usage, because the validation site is far away from the usage site. Over time, as the usage code changes, the validator can easily get out-of-sync. Note that this could mean the code itself is out-of-sync, or it could be that running servers are out-of-sync, because they have different update schedules. Or, the validator may be written with incorrect assumptions in the first place. The consequences of this can be severe. Protocol Buffers' concept of \"required fields\" is essentially an upfront validation check that [has been responsible for outages of Google Search, GMail, and others](https://capnproto.org/faq.html#how-do-i-make-a-field-required-like-in-protocol-buffers).\n\nWe recommend, therefore, that validation occur at time of use. Code should be written to be tolerant of validation failures. For example, most code dealing with UTF-8 text should treat it as a blob of bytes, not worrying about invalid byte sequences. When you actually need to decode the code points -- such as to display them -- you should do something reasonable with invalid sequences -- such as display the Unicode replacement character.\n\nWith that said, when storing data in a database long-term, it can make sense to perform an additional validation check at time of storage, in order to more directly notify the caller that their input was invalid. This validation should be considered optional, since the data will be validated again when it is read from storage and used.\n\n### Premature optimization fallacy\n\n_\"We should forget about small efficiencies, say about 97% of the time: premature optimization is the root of all evil.\"_ -- Donald Knuth\n\n_\"The improvement in speed from Example 2 to Example 2a is only about 12%, and many people would pronounce that insignificant. The conventional wisdom shared by many of today’s software engineers calls for ignoring efficiency in the small; but I believe this is simply an overreaction to the abuses they see being practiced by penny-wise- and-pound-foolish programmers, who can’t debug or maintain their “optimized” programs. In established engineering disciplines a 12% improvement, easily obtained, is never considered marginal; and I believe the same viewpoint should prevail in software engineering. Of course I wouldn’t bother making such optimizations on a one-shot job, but when it’s a question of preparing quality programs, I don’t want to restrict myself to tools that deny me such efficiencies.\"_ -- Donald Knuth, **in the same paper**.\n\n(Credit: [Stop Misquoting Donald Knuth!](http://www.joshbarczak.com/blog/?p=580))\n\nYou should not obsess over optimization or write unmaintainable code for the sake of speed.\n\nHowever, you _should_ be thinking about efficiency of all the code you write. When writing efficient code is not much harder and not much uglier than inefficient code, you should be writing efficient code. If the efficient approach to a problem would take _much_ longer than the inefficient way then go ahead and code the inefficient way first, but in many cases it's not that stark. Rewriting your code later is _much_ more expensive than writing it correctly the first time, because by then you'll have lost context.\n\nYou should be constantly aware of whether the code you are writing is low-level (called frequently) or high-level (called infrequently). You should consider optimizations relative to the code's level. In low-level code, optimizations like avoiding heap allocations may make sense. In high-level code you should not worry about heap, but you may still want to think about expensive operations like disk I/O or contacting remote servers (things that low-level code should never do in the first place, of course).\n\nProgrammers who ignore efficiency until they have no choice inevitably end up shipping slow, bloated software. Their code's speed is always pushing the boundary of bearability, because they only do anything about it when it becomes unbearable. But programs which are \"bearable\" can still make users intensely unhappy due to their slowness.\n\n### Text is always UTF-8\n\nAlways encode text as UTF-8. Always assume text is encoded as UTF-8.\n\n(Do not, however, assume text is _valid_ UTF-8; see the section on lazy validation.)\n\nDo not write code that tries to distinguish characters. Unless you are writing code to render text to a display, you probably don't care about characters. Besides, Unicode itself contains code points which act as modifiers to previous characters; it's futile for you to handle these. Most code only really cares about bytes.\n\nNote that even parsers for machine-readable text-based languages (config languages, programming languages, other DSLs) do not really care about \"characters\" in the Unicode sense because such languages are almost always pure-ASCII. They may allow arbitrary UTF-8 in, say, string literals, but only ASCII code points have any special meaning to the language. Therefore, they still only care about bytes (since ASCII characters are single-byte, and multi-byte UTF-8 codepoints never contain individual bytes in the ASCII range).\n\n## C++ usage\n\nThis section contains guidelines for usage of C++ language features.\n\n### Use C++20 (or later)\n\nC++11 and later revisions completely transformed the way the C++ language is used. New code should take heavy advantage of the new features, especially rvalue references (move semantics), lambda expressions, and the `co_await` keyword (from C++20) to await promises.\n\nKJ requires C++20. Application code (not used as a library) may consider requiring later revisions, or even requiring a specific compiler and tracking the latest language features implemented by it.\n\n### Heap allocation\n\n* Never write `new` or `delete` explicitly. Use `kj::heap` to allocate single objects or `kj::heapArray` for arrays; these return \"owned\" pointers (`kj::Own<T>` or `kj::Array<T>`, respectively) which enforce RAII/ownership semantics. You may transfer ownership of these pointers via move semantics, but otherwise the objects will be automatically deleted when they go out of scope. This makes memory leaks very rare in KJ code.\n* Only allocate objects on the heap when you actually need to be able to move them. Otherwise, avoid a heap allocation by declaring the object directly on the stack or as a member of some other object.\n* If a class's copy constructor would require memory allocation, consider providing a `clone()` method instead and deleting the copy constructor. Allocation in implicit copies is a common source of death-by-1000-cuts performance problems. `kj::String`, for example, is movable but not copyable.\n\n### Pointers, references\n\n* Pointers and references always point to things that are owned by someone else. Take care to think about the lifetime of that object compared to the lifetime of the pointer.\n* Always use `kj::ArrayPtr<T>` rather than `T*` to point to an array.\n* Always use `kj::StringPtr` rather than `const char*` to point to a NUL-terminated string.\n* Always use `kj::Maybe<T&>` rather than `T*` when a pointer can be null. This forces the user to check for null-ness.\n* In other cases, prefer references over pointers. Note, though, that members of an assignable type cannot be references, so you'll need to use pointers in that case (darn).\n\n**Rationale:** There is an argument that says that references should always be const and pointers mutable, because then when you see `foo(&bar)` you know that the function modifies `bar`. This is a nice theory, but in practice real C++ code is rarely so consistent that you can use this as a real signal. We prefer references because they make it unambiguous that the value cannot be null.\n\n### Constness\n\n* Treat `const`-ness as transitive. So, if you have a const instance of a struct which in turn contains a pointer (or reference), treat that pointer as pointing to const even if it is not declared as such. To enforce this, copyable classes which contain pointer fields should declare their copy constructor as `T(T& other)` rather than `T(const T& other)` (and similarly for assignment operators) in order to prevent escalating a transitively-const pointer to non-const via copy. You may inherit `kj::DisallowConstCopy` to force the implicit copy constructor and assignment operator to be declared this way.\n* Try to treat const/non-const pointers like shared/exclusive locks. So, when a new const pointer to an object is created, all other pointers should also be considered const at least until the new pointer is destroyed. When a new non-const pointer is created, all other pointers should be considered not dereferenceable until the non-const pointer is destroyed. In theory, these rules help keep different objects from interfering with each other by modifying some third object in incompatible ways. Note that these rules are (as I understand it) enforceable by the Rust type system.\n* `const` methods are safe to call on the same object from multiple threads simultaneously. Conversely, it is unsafe to call a non-`const` method if any other thread might be calling methods on that object concurrently. Note that KJ defines synchronization primitives including `kj::Mutex` which integrate nicely with this rule.\n\n### Inheritance\n\nA class is either an interface or an implementation. Interfaces have no fields. Implementations have no non-final virtual methods. You should not mix these: a class with state should never have virtual methods, as this leads to fragile base class syndrome.\n\nInterfaces should NOT declare a destructor, because:\n\n* That destructor is never called anyway (because we don't use `delete`, and `kj::Own` has a different mechanism for dispatching the destructor).\n* Declaring destructors for interfaces is tedious.\n* If you declare a destructor but do not declare it `noexcept(false)`, C++11 will (regrettably) decide that it is `noexcept` and that all derived classes must also have a `noexcept` destructor, which is wrong. (See the exceptions philosophy section for discussion on exceptions in destructors.)\n\nMultiple inheritance is allowed and encouraged, keeping in mind that you are usually inheriting interfaces.\n\nYou should think carefully about whether to use virtual inheritance; it's not often needed, and it is relatively inefficient, but in complex inheritance hierarchies it becomes critical.\n\nImplementation inheritance (that is, inheriting an implementation class) is allowed as a way to compose classes without requiring extra allocations. For example, Cap'n Proto's `capnp::InputStreamMessageReader` implements the `capnp::MessageReader` interface by reading from a `kj::InputStream`, which is itself an interface. One implementation of `kj::InputStream` is `kj::FdInputStream`, which reads from a unix file descriptor. As a convenience, Cap'n Proto defines `capnp::StreamFdMessageReader` which multiply-inherits `capnp::InputStreamMessageReader` and `kj::FdInputStream` -- that is, it inherits two implementations, and even inherits the latter privately. Many style guides would consider this taboo. The benefit, though, is that people can declare this composed class on the stack as one unit, with no heap allocation, and end up with something that they can directly treat as a `capnp::MessageReader`; any other solution would lose one of these benefits.\n\n### Exceptions Usage\n\nKJ's exception philosophy is described earlier in this document. Here we describe only how to actually use exceptions in code.\n\nNever use `throw` explicitly. Almost all exceptions should originate from the `KJ_ASSERT`, `KJ_REQUIRE`, and `KJ_SYSCALL` macros (see `kj/debug.h`). These macros allow you to easily attach useful debug information to the exception message without spending time on string formatting.\n\nNever declare anything `noexcept`. As explained in the philosophy section, whether you like it or not, bugs can happen anywhere and therefore exceptions can happen anywhere. `noexcept` causes the process to abort on exceptions. Aborting is _never_ the right answer.\n\nExplicit destructors must always be declared `noexcept(false)`, to work around C++11's regrettable decision that destructors should be `noexcept` by default. In destructors, always use `kj::UnwindDetector` or make all your asserts recoverable in order to ensure that an exception is not thrown during unwind.\n\nDo not fret too much about recovering into a perfectly consistent state after every exception. That's not the point. The point is to be able to recover at all -- to _improve_ reliability, but not to make it perfect. So, write your code to do a reasonable thing in most cases.\n\nFor example, if you are implementing a data structure like a vector, do not worry about whether move constructors might throw. In practice, it is extraordinarily rare for move constructors to contain any code that could throw. So just assume they don't. Do NOT do what the C++ standard library does and require that all move constructors be explicitly `noexcept`, because people will not remember to mark their move constructors `noexcept`, and you'll just be creating a huge headache for everyone with _no practical benefit_.\n\n### Template Metaprogramming\n\n#### Reducing Verbosity\n\nBefore C++11, it was common practice to write \"template functions\" in the form of a templated struct which contained a single member representing the output of the function. For example, you might see `std::is_integral<int>::value` to check if `int` is integral. This pattern is excessively verbose, especially when composed into complex expressions.\n\nIn C++11, we can do better. Where before you would have declared a struct named `Foo<T>` with a single member as described above, in C++11 you should:\n\n1. Define the struct as before, but with the name `Foo_<T>`.\n2. Define a template `Foo<T>` which directly aliases the single member of `Foo_<T>`. If the output is a type, use a template `using`, whereas if the output is a value, use a `constexpr` function.\n\nExample:\n\n    template <typename T> struct IsConst_ { static constexpr bool value = false; };\n    template <typename T> struct IsConst_<const T> { static constexpr bool value = true; };\n    template <typename T> constexpr bool isConst() { return IsConst_<T>::value; }\n    // Return true if T is const.\n\nOr:\n\n    template <typename T> struct UnConst_ { typedef T Type; };\n    template <typename T> struct UnConst_<const T> { typedef T Type; };\n    template <typename T> using UnConst = typename UnConst_<T>::Type;\n    // If T is const, return the underlying non-const type.\n    // Otherwise, just return T.\n\nNow people can use your template metafunction without the pesky `::Type` or `::value` suffix.\n\n#### Other hints\n\n* To explicitly disable a template under certain circumstances, bind an unnamed template parameter to `kj::EnableIf`:\n\n        template <typename T, typename = kj::EnableIf(!isConst<T>())>\n        void mutate(T& ptr);\n        // T must not be const.\n\n* Say you're writing a template type with a constructor function like so:\n\n        template <typename T>\n        Wrapper<T> makeWrapper(T&& inner);\n        // Wraps `inner` and returns the wrapper.\n\n  Should `inner` be taken by reference or by value here? Both might be useful, depending on the use case. The right answer is actually to support both: if the input is an lvalue, take it by reference, but if it's an rvalue, take it by value (move). And as it turns out, if you write your declaration exactly as shown above, this is exactly what you get, because if the input is an lvalue, `T` will implicitly bind to a reference type, whereas if the input is an rvalue or rvalue reference, T will not be a reference.\n\n  In general, you should assume KJ code in this pattern uses this rule, so if you are passing in an lvalue but don't actually want it wrapped by reference, wrap it in `kj::mv()`.\n\n* Never use function or method pointers. Prefer templating across functors (like STL does), or for non-templates use `kj::Function` (which will handle this for you).\n\n### Global Constructors\n\nDo not declare global or static variables with dynamic constructors. Global constructors disproportionately hurt startup time because they force code to be paged in before it is really needed. They also are usually only needed by singletons, which you should not be using in general (see philosophy section).\n\nYou can have global constants of non-trivial class type as long as they are declared `constexpr`. If you want to declare complex data structures as constants, try to declare all the pieces as separate globals that reference each other, so that nothing has to be heap allocated and everything can be `constexpr`.\n\nUse Clang's `-Wglobal-constructors` warning to catch mistakes.\n\n### `dynamic_cast`\n\nDo not use `dynamic_cast` as a way to implement polymorphism. That is, do not write long blocks of if/else statements each trying to cast an object to a different derived class to handle in a different way. Instead, extend the base class's interface to cover the functionality you need.\n\nWith that said, `dynamic_cast` is not always bad. It is fine to use `dynamic_cast` for \"logistical\" improvements, such as optimization. As a rule of thumb, imagine if `dynamic_cast` were replaced with a function that always returned null. Would your code still be correct (if, perhaps, slower, or with less detailed logging, etc.)? If so, then your use of `dynamic_cast` is fine.\n\n#### `-fno-rtti`\n\nThe KJ and Cap'n Proto libraries are designed to function correctly when compiled with `-fno-rtti`. To that end, `kj::dynamicCastIfAvailable` is a version of `dynamic_cast` that, when compiled with `-fno-rtti`, always returns null, and KJ and Cap'n Proto code always uses this version.\n\nWe do NOT recommend disabling RTTI in your own code.\n\n### Lambdas\n\nLambda capture lists must never use `=` to specify \"capture all by value\", because this makes it hard to review the capture list for possible lifetime issues.\n\nCapture lists *may* use `&` (\"capture all by reference\") but *only* in cases where it is known that the lambda will not outlive the current stack frame. In fact, they generally *should* use `&` in this case, to make clear that there are no lifetime issues to think about.\n\n### Use of Standard libraries\n\n#### C++ Standard Library\n\nThe C++ standard library is old and full of a lot of cruft. Many APIs are designed in pre-C++11 styles that are no longer ideal. Mistakes like giving copy constructors to objects that own heap space (because in the absence of move semantics, it was needed for usability) and atomically-reference-counted strings (intended as an optimization to avoid so much heap copying, but actually a pessimization) are now baked into the library and cannot change. The `iostream` library was designed before anyone knew how to write good C++ code and is absolutely awful by today's standards. Some parts of the library, such as `<chrono>`, are over-engineered, designed by committees more interested in theoretical perfection than practicality. To add insult to injury, the library's naming style does not distinguish types from values.\n\nFor these reasons and others, KJ aims to be a replacement for the C++ standard libraries.\n\nIt is not there yet. As of this writing, the biggest missing piece is that KJ provides no implementation of maps or sets, nor a `sort()` function.\n\nWe recommend that KJ code use KJ APIs where available, falling back to C++ standard types when necessary. To avoid breaking clients later, avoid including C++ standard library headers from other headers; only include them from source files.\n\nAll users of the KJ library should familiarize themselves at least with the declarations in the following files, as you will use them all the time:\n\n* `kj/common.h`\n* `kj/memory.h`\n* `kj/array.h`\n* `kj/string.h`\n* `kj/vector.h`\n* `kj/debug.h`\n\n#### C Library\n\nAs a general rule of thumb, C library functions documented in man section 3 should be treated with skepticism.\n\nDo not use the C standard I/O functions -- your code should never contain `FILE*`. For formatting strings, `kj::str()` is much safer and easier than `sprintf()`. For debug logging, `KJ_DBG()` will produce more information with fewer keystrokes compared to `printf()`. For parsing, KJ's parser combinator library is cleaner and more powerful than `scanf()`. `fread()` and `fwrite()` imply buffering that you usually don't want; use `kj/io.h` instead, or raw file descriptors.\n\n### Compiler warnings\n\nUse the following warning settings with Clang or GCC:\n\n* `-Wall -Wextra`: Enable most warnings.\n* `-Wglobal-constructors`: (Clang-only) This catches global variables with constructors, which KJ style disallows (see above). You will, however, want to disable this warning in tests, since test frameworks use global constructors and are excepted from the style rule.\n* `-Wno-sign-compare`: While comparison between signed and unsigned values could be a serious bug, we find that in practice this warning is almost always spurious.\n* `-Wno-unused-parameter`: This warning is always spurious. I have never seen it find a real bug. Worse, it encourages people to delete parameter names which harms readability.\n\nFor development builds, `-Werror` should also be enabled. However, this should not be on by default in open source code as not everyone uses the same compiler or compiler version and different compiler versions often produce different warnings.\n\n### Tools\n\nWe use:\n\n* Clang for compiling.\n* `KJ_DBG()` for simple debugging.\n* Valgrind for complicated debugging.\n* [Ekam](https://github.com/capnproto/ekam) for a build system.\n* Git for version control.\n\n## Irrelevant formatting rules\n\nMany style guides dwell on formatting. We mention it only because it's vaguely nice to have some formatting consistency, but know that this section is the *least* relevant section of the document.\n\nAs a code reviewer, when you see a violation of formatting rules, think carefully about whether or not it really matters that you point it out. If you believe the author may be unfamiliar with the rules, it may be worth letting them know to read this document, if only so that they can try to be consistent in the future. However, it is NOT worth the time to comment on every misplaced whitespace. As long as the code is readable, move on.\n\n### Naming\n\n* Type names: `TitleCase`\n* Variable, member, function, and method names: `camelCase`\n* Constant and enumerant names: `CAPITAL_WITH_UNDERSCORES`\n* Macro names: `CAPITAL_WITH_UNDERSCORES`, with an appropriate project-specific prefix like `KJ_` or `CAPNP_`.\n* Namespaces: `oneword`. Namespaces should be kept short, because you'll have to type them a lot. The name of KJ itself was chosen for the sole purpose of making the namespace easy to type (while still being sufficiently unique). Use a nested namespace called `_` to contain package-private declarations.\n* Files: `module-name.c++`, `module-name.h`, `module-name-test.c++`\n\n**Rationale:** There has never been broad agreement on C++ naming style. The closest we have is the C++ standard library. Unfortunately, the C++ standard library made the awful decision of naming types and values in the same style, losing a highly useful visual cue that makes programming more pleasant, and preventing variables from being named after their type (which in many contexts is perfectly appropriate).\n\nMeanwhile, the Java style, which KJ emulates, has been broadly adopted to varying degrees in other languages, from JavaScript to Haskell. Using a similar style in KJ code makes it less jarring to switch between C++ and those other languages. Being consistent with JavaScript is especially useful because it is the one language that everyone pretty much has to use, due to its use in the web platform.\n\nThere has also never been any agreement on C++ file extensions, for some reason. The extension `.c++`, though not widely used, is accepted by all reasonable tools and is clearly the most precise choice.\n\n### Spacing and bracing\n\n* Indents are two spaces.\n* Never use tabs.\n* Maximum line length is 100 characters.\n* Indent continuation lines for braced init lists by two spaces.\n* Indent all other continuation lines by four spaces.\n* Alternatively, line up continuation lines with previous lines if it makes them easier to read.\n* Place a space between a keyword and an open parenthesis, e.g.: `if (foo)`\n* Do not place a space between a function name and an open parenthesis, e.g.: `foo(bar)`\n* Place an opening brace at the end of the statement which initiates the block, not on its own line.\n* Place a closing brace on a new line indented the same as the parent block. If there is post-brace code related to the block (e.g. `else` or `while`), place it on the same line as the closing brace.\n* Always place braces around a block *unless* the block is so short that it can actually go on the same line as the introductory `if` or `while`, e.g.: `if (done) return;`.\n* `case` statements are indented within the `switch`, and their following blocks are **further** indented (so the actual statements in a case are indented four spaces more than the `switch`).\n* `public:`, `private:`, and `protected:` are reverse-indented by one stop.\n* Statements inside a `namespace` are **not** indented unless the namespace is a short block that is just forward-declaring things at the top of a file.\n* Set your editor to strip trailing whitespace on save, otherwise other people who use this setting will see spurious diffs when they edit a file after you.\n\n<br>\n\n    if (foo) {\n      bar();\n    } else if (baz) {\n      qux(quux);\n    } else {\n      corge();\n    }\n\n    if (done) return;\n\n    switch (grault) {\n      case GARPLY:\n        print(\"mew\");\n        break;\n      case WALDO: {  // note: needs braces due to variable\n        Location location = findWaldo();\n        print(location);\n        break;\n      }\n    }\n\n<br>\n\n    namespace external {\n      class Forward;\n      class Declarations;\n      namespace nested {\n        class More;\n      }\n    }\n\n    namespace myproj {\n\n    class Fred {\n    public:\n      Fred();\n      ~Fred();\n    private:\n      int plugh;\n    };\n\n    }  // namespace myproj\n\n**Rationale:** Code which is inconsistently or sloppily formatted gives the impression that the author is not observant or simply doesn't care about quality, and annoys other people trying to read your code.\n\nOther than that, there is absolutely no good reason to space things one way or another.\n\n### Comments\n\n* Always use line comments (`//`). Never use block comments (`/**/`).\n\n  **Rationale:** Block comments don't nest. Block comments tend to be harder to re-arrange, whereas a group of line comments can be moved easily. Also, typing `*` is just way harder than typing `/` so why would you want to?\n\n* Write comments that add useful information that the reader might not already know. Do NOT write comments which say things that are already blatantly obvious from the code. For example, for a function `void frob(Bar bar)`, do not write a comment `// Frobs the Bar.`; that's already obvious. It's better to have no comment.\n\n* Doc comments go **after** the declaration. If the declaration starts a block, the doc comment should go inside the block at the top. A group of related declarations can have a single group doc comment after the last one as long as there are no black lines between the declarations.\n\n        int foo();\n        // This is documentation for foo().\n\n        class Bar {\n          // This is documentation for Bar.\n        public:\n          Bar();\n\n          inline int baz() { return 5; }\n          inline int qux() { return 6; }\n          // This is documentation for baz() and qux().\n        };\n\n  **Rationale:** When you start reading a doc comment, the first thing you want to know is *what the heck is being documented*. Having to scroll down through a long comment to see the declaration, then back up to read the docs, is bad. Sometimes, people actually repeat the declaration at the top of the comment just so that it's visible. This is silly. Let's just put the comment after the declaration.\n\n* TODO comments are of the form `// TODO(type): description`, where `type` is one of:\n  * `now`: Do before next `git push`.\n  * `soon`: Do before next stable release.\n  * `someday`: A feature that might be nice to have some day, but no urgency.\n  * `perf`: Possible performance enhancement.\n  * `security`: Possible security concern. (Used for low-priority issues. Obviously, code with serious security problems should never be written in the first place.)\n  * `cleanup`: An improvement to maintainability with no user-visible effects.\n  * `port`: Things to do when porting to a new platform.\n  * `test`: Something that needs better testing.\n  * `msvc`: Something to revisit when the next, hopefully less-broken version of Microsoft Visual Studio becomes available.\n  * others: Additional TODO types may be defined for use in certain contexts.\n\n  **Rationale:** Google's guide suggests that TODOs should bear the name of their author (\"the person to ask for more information about the comment\"), but in practice there's no particular reason why knowing the author is more useful for TODOs than for any other comment (or, indeed, code), and anyway that's what `git blame` is for. Meanwhile, having TODOs classified by type allows for useful searches, so that e.g. release scripts can error out if release-blocking TODOs are present.\n\n### File templates\n\nGenerally, a \"module\" should consist of three files: `module.h`, `module.c++`, and `module-test.c++`. One or more of these can be omitted if it would otherwise be empty. Use the following templates when creating new files.\n\nHeaders:\n\n    // Project Name - Project brief description\n    // Copyright (c) 2015 Primary Author and contributors\n    //\n    // Licensed under the Whatever License blah blah no warranties.\n\n    #pragma once\n    // Documentation for file.\n\n    #include <kj/common.h>\n\n    namespace myproject {\n\n    // declarations\n\n    namespace _ {  // private\n\n    // private declarations\n\n    }  // namespace _ (private)\n\n    }  // namespace myproject\n\nSource code:\n\n    // Project Name - Project brief description\n    // Copyright (c) 2015 Primary Author and contributors\n    //\n    // Licensed under the Whatever License blah blah no warranties.\n\n    #include \"this-module.h\"\n    #include <other-module.h>\n\n    namespace myproject {\n\n    // definitions\n\n    }  // namespace myproject\n\nTest:\n\n    // Project Name - Project brief description\n    // Copyright (c) 2015 Primary Author and contributors\n    //\n    // Licensed under the Whatever License blah blah no warranties.\n\n    #include \"this-module.h\"\n    #include <other-module.h>\n\n    namespace myproject {\n    namespace {\n\n    // KJ_TESTs\n\n    }  // namespace\n    }  // namespace myproject\n\nNote that in both the source and test files, you should *always* include the corresponding header first, in order to ensure that it is self-contained (does not secretly require including some other header before it).\n"
        },
        {
          "name": "super-test.sh",
          "type": "blob",
          "size": 20.9560546875,
          "content": "#! /usr/bin/env bash\n\nset -euo pipefail\n\ndoit() {\n  echo \"@@@@ $@\"\n  \"$@\"\n}\n\nfunction test_samples() {\n  echo \"@@@@ ./addressbook (in various configurations)\"\n  ./addressbook write | ./addressbook read\n  ./addressbook dwrite | ./addressbook dread\n  rm -f /tmp/capnp-calculator-example-$$\n  ./calculator-server unix:/tmp/capnp-calculator-example-$$ &\n  local SERVER_PID=$!\n  sleep 1\n  ./calculator-client unix:/tmp/capnp-calculator-example-$$\n  # `kill %./calculator-server` doesn't seem to work on recent Cygwins, but we can kill by PID.\n  kill -9 $SERVER_PID\n  # This `fg` will fail if bash happens to have already noticed the quit and reaped the process\n  # before `fg` is invoked, so in that case we just proceed.\n  fg %./calculator-server || true\n  rm -f /tmp/capnp-calculator-example-$$\n}\n\nQUICK=\nCPP_FEATURES=\nEXTRA_LIBS=\n\nPARALLEL=$(nproc 2>/dev/null || echo 1)\n\n# Have automake dump test failure to stdout. Important for CI.\nexport VERBOSE=true\n\nwhile [ $# -gt 0 ]; do\n  case \"$1\" in\n    -j* )\n      PARALLEL=${1#-j}\n      ;;\n    test )\n      ;;  # nothing\n    quick )\n      QUICK=quick\n      ;;\n    cpp-features )\n      if [ \"$#\" -lt 2 ] || [ -n \"$CPP_FEATURES\" ]; then\n        echo \"usage: $0 cpp-features CPP_DEFINES\" >&2\n        echo \"e.g. $0 cpp-features '-DSOME_VAR=5 -DSOME_OTHER_VAR=6'\" >&2\n        if [ -n \"$CPP_FEATURES\" ]; then\n          echo \"cpp-features provided multiple times\" >&2\n        fi\n        exit 1\n      fi\n      CPP_FEATURES=\"$2\"\n      shift\n      ;;\n    extra-libs )\n      if [ \"$#\" -lt 2 ] || [ -n \"$EXTRA_LIBS\" ]; then\n        echo \"usage: $0 extra-libs EXTRA_LIBS\" >&2\n        echo \"e.g. $0 extra-libs '-lrt'\" >&2\n        if [ -n \"$EXTRA_LIBS\" ]; then\n          echo \"extra-libs provided multiple times\" >&2\n        fi\n        exit 1\n      fi\n      EXTRA_LIBS=\"$2\"\n      shift\n      ;;\n    caffeinate )\n      # Re-run preventing sleep.\n      shift\n      exec caffeinate -ims $0 $@\n      ;;\n    tmpdir )\n      # Clone to a temp directory.\n      if [ \"$#\" -lt 2 ]; then\n        echo \"usage: $0 tmpdir NAME [COMMAND]\" >&2\n        exit 1\n      fi\n      DIR=/tmp/$2\n      shift 2\n      if [ -e $DIR ]; then\n        if [ \"${DIR/*..*}\" = \"\" ]; then\n          echo \"NO DO NOT PUT .. IN THERE IT'S GOING TO GO IN /tmp AND I'M GONNA DELETE IT\" >&2\n          exit 1\n        fi\n        if [ ! -e \"$DIR/super-test.sh\" ]; then\n          echo \"$DIR exists and it doesn't look like one of mine.\" >&2\n          exit 1\n        fi\n        # make distcheck leaves non-writable files when it fails, so we need to chmod to be safe.\n        chmod -R +w $DIR\n        rm -rf $DIR\n      fi\n      git clone . $DIR\n      cd $DIR\n      exec ./super-test.sh \"$@\"\n      ;;\n    remote )\n      if [ \"$#\" -lt 2 ]; then\n        echo \"usage: $0 remote HOST [COMMAND]\" >&2\n        exit 1\n      fi\n      HOST=$2\n      shift 2\n      echo \"=========================================================================\"\n      echo \"Pushing code to $HOST...\"\n      echo \"=========================================================================\"\n      BRANCH=$(git rev-parse --abbrev-ref HEAD)\n      ssh $HOST '(chmod -fR +w tmp-test-capnp || true) && rm -rf tmp-test-capnp && mkdir tmp-test-capnp && git init tmp-test-capnp'\n      git push ssh://$HOST/~/tmp-test-capnp \"$BRANCH:test\"\n      ssh $HOST \"cd tmp-test-capnp && git checkout test\"\n      exec ssh $HOST \"cd tmp-test-capnp && ./super-test.sh $@ && cd .. && rm -rf tmp-test-capnp\"\n      ;;\n    compiler )\n      if [ \"$#\" -lt 2 ]; then\n        echo \"usage: $0 compiler CXX_NAME\" >&2\n        exit 1\n      fi\n      export CXX=\"$2\"\n      shift\n      ;;\n    clang* )\n      # Need to set CC as well for configure to handle -fcoroutines-ts.\n      export CC=clang${1#clang}\n      export CXX=clang++${1#clang}\n      export LIB_FUZZING_ENGINE=-fsanitize=fuzzer\n      ;;\n    gcc* )\n      export CXX=g++${1#gcc}\n      ;;\n    g++* )\n      export CXX=$1\n      ;;\n    mingw )\n      if [ \"$#\" -ne 2 ]; then\n        echo \"usage: $0 mingw CROSS_HOST\" >&2\n        exit 1\n      fi\n      CROSS_HOST=$2\n\n      cd c++\n      test -e configure || doit autoreconf -i\n      test ! -e Makefile || (echo \"ERROR: Directory unclean!\" >&2 && false)\n\n      export WINEPATH='Z:\\usr\\'\"$CROSS_HOST\"'\\lib;Z:\\usr\\lib\\gcc\\'\"$CROSS_HOST\"'\\6.3-win32;Z:'\"$PWD\"'\\.libs'\n\n      doit ./configure --host=\"$CROSS_HOST\" --disable-shared CXXFLAGS=\"-static-libgcc -static-libstdc++ $CPP_FEATURES\" LIBS=\"$EXTRA_LIBS\"\n\n      doit make -j$PARALLEL check\n      doit make distclean\n      rm -f *-mingw.exe\n      exit 0\n      ;;\n    android )\n      # To install Android SDK:\n      # - Download command-line tools: https://developer.android.com/studio/index.html#command-tools\n      # - Run $SDK_HOME/tools/bin/sdkmanager platform-tools 'platforms;android-25' 'system-images;android-25;google_apis;armeabi-v7a' emulator 'build-tools;25.0.2' ndk-bundle\n      # - Run $SDK_HOME/tools/bin/avdmanager create avd -n capnp -k 'system-images;android-25;google_apis;armeabi-v7a' -b google_apis/armeabi-v7a\n      if [ \"$#\" -ne 4 ]; then\n        echo \"usage: $0 android SDK_HOME CROSS_HOST COMPILER_PREFIX\" >&2\n        echo\n        echo \"SDK_HOME: Location where android-sdk is installed.\" >&2\n        echo \"CROSS_HOST: E.g. arm-linux-androideabi\" >&2\n        echo \"COMPILER_PREFIX: E.g. armv7a-linux-androideabi24\" >&2\n        exit 1\n      fi\n      SDK_HOME=$2\n      CROSS_HOST=$3\n      COMPILER_PREFIX=$4\n\n      cd c++\n      test -e configure || doit autoreconf -i\n      test ! -e Makefile || (echo \"ERROR: Directory unclean!\" >&2 && false)\n      doit ./configure --disable-shared\n      doit make -j$PARALLEL capnp capnpc-c++\n\n      cp capnp capnp-host\n      cp capnpc-c++ capnpc-c++-host\n\n      export PATH=\"$SDK_HOME/ndk-bundle/toolchains/llvm/prebuilt/linux-x86_64/bin:$PATH\"\n      doit make distclean\n      doit ./configure --host=\"$CROSS_HOST\" CC=\"$COMPILER_PREFIX-clang\" CXX=\"$COMPILER_PREFIX-clang++\" --with-external-capnp --disable-shared CXXFLAGS=\"-fPIE $CPP_FEATURES\" LDFLAGS='-pie' LIBS=\"-static-libstdc++ -static-libgcc -ldl $EXTRA_LIBS\" CAPNP=./capnp-host CAPNPC_CXX=./capnpc-c++-host\n\n      doit make -j$PARALLEL\n      doit make -j$PARALLEL capnp-test\n\n      echo \"Starting emulator...\"\n      trap 'kill $(jobs -p)' EXIT\n      # TODO(someday): Speed up with KVM? Then maybe we won't have to skip fuzz tests?\n      $SDK_HOME/emulator/emulator -avd capnp -no-window &\n      $SDK_HOME/platform-tools/adb 'wait-for-device'\n      echo \"Waiting for localhost to be resolvable...\"\n      doit $SDK_HOME/platform-tools/adb shell 'while ! ping -c 1 localhost > /dev/null 2>&1; do sleep 1; done'\n      # TODO(cleanup): With 'adb shell' I find I cannot put files anywhere, so I'm using 'su' a\n      #   lot here. There is probably a better way.\n      doit $SDK_HOME/platform-tools/adb shell 'su 0 tee /data/capnp-test > /dev/null' < capnp-test\n      doit $SDK_HOME/platform-tools/adb shell 'su 0 chmod a+rx /data/capnp-test'\n      doit $SDK_HOME/platform-tools/adb shell 'cd /data && CAPNP_SKIP_FUZZ_TEST=1 su 0 /data/capnp-test && echo ANDROID_\"\"TESTS_PASSED' | tee android-test.log\n      grep -q ANDROID_TESTS_PASSED android-test.log\n\n      doit make distclean\n      rm -f capnp-host capnpc-c++-host\n      exit 0\n      ;;\n    cmake )\n      cd c++\n      rm -rf cmake-build\n      mkdir cmake-build\n      cd cmake-build\n      doit cmake -G \"Unix Makefiles\" ..\n      doit make -j$PARALLEL check\n      exit 0\n      ;;\n    cmake-package )\n      # Test that a particular configuration of Cap'n Proto can be discovered and configured against\n      # by a CMake project using the find_package() command. This is currently implemented by\n      # building the samples against the desired configuration.\n      #\n      # Takes one argument, the build configuration, which must be one of:\n      #\n      #   autotools-shared\n      #   autotools-static\n      #   cmake-shared\n      #   cmake-static\n\n      if [ \"$#\" -ne 2 ]; then\n        echo \"usage: $0 cmake-package CONFIGURATION\" >&2\n        echo \"  where CONFIGURATION is one of {autotools,cmake}-{static,shared}\" >&2\n        exit 1\n      fi\n\n      CONFIGURATION=$2\n      WORKSPACE=$(pwd)/cmake-package/$CONFIGURATION\n      SOURCE_DIR=$(pwd)/c++\n\n      rm -rf $WORKSPACE\n      mkdir -p $WORKSPACE/{build,build-samples,inst}\n\n      # Configure\n      cd $WORKSPACE/build\n      case \"$CONFIGURATION\" in\n        autotools-shared )\n          autoreconf -i $SOURCE_DIR\n          doit $SOURCE_DIR/configure --prefix=\"$WORKSPACE/inst\" --disable-static\n          ;;\n        autotools-static )\n          autoreconf -i $SOURCE_DIR\n          doit $SOURCE_DIR/configure --prefix=\"$WORKSPACE/inst\" --disable-shared\n          ;;\n        cmake-shared )\n          doit cmake $SOURCE_DIR -G \"Unix Makefiles\" -DCMAKE_INSTALL_PREFIX=\"$WORKSPACE/inst\" \\\n              -DBUILD_TESTING=OFF -DBUILD_SHARED_LIBS=ON\n          # The CMake build does not currently set the rpath of the capnp compiler tools.\n          export LD_LIBRARY_PATH=\"$WORKSPACE/inst/lib\"\n          ;;\n        cmake-static )\n          doit cmake $SOURCE_DIR -G \"Unix Makefiles\" -DCMAKE_INSTALL_PREFIX=\"$WORKSPACE/inst\" \\\n              -DBUILD_TESTING=OFF -DBUILD_SHARED_LIBS=OFF\n          ;;\n        * )\n          echo \"Unrecognized cmake-package CONFIGURATION argument, must be {autotools,cmake}-{static,shared}\" >&2\n          exit 1\n          ;;\n      esac\n\n      # Build and install\n      doit make -j$PARALLEL install\n\n      # Configure, build, and execute the samples.\n      cd $WORKSPACE/build-samples\n      doit cmake $SOURCE_DIR/samples -G \"Unix Makefiles\" -DCMAKE_PREFIX_PATH=\"$WORKSPACE/inst\" \\\n          -DCAPNPC_FLAGS=--no-standard-import -DCAPNPC_IMPORT_DIRS=\"$WORKSPACE/inst/include\"\n      doit make -j$PARALLEL\n\n      test_samples\n\n      echo \"=========================================================================\"\n      echo \"Cap'n Proto ($CONFIGURATION) installs a working CMake config package.\"\n      echo \"=========================================================================\"\n\n      exit 0\n      ;;\n    exotic )\n      echo \"=========================================================================\"\n      echo \"MinGW 64-bit\"\n      echo \"=========================================================================\"\n      \"$0\" mingw x86_64-w64-mingw32\n      echo \"=========================================================================\"\n      echo \"MinGW 32-bit\"\n      echo \"=========================================================================\"\n      \"$0\" mingw i686-w64-mingw32\n      echo \"=========================================================================\"\n      echo \"Android\"\n      echo \"=========================================================================\"\n      \"$0\" android /home/kenton/android-sdk-linux /home/kenton/android-24 arm-linux-androideabi\n      echo \"=========================================================================\"\n      echo \"CMake\"\n      echo \"=========================================================================\"\n      \"$0\" cmake\n      echo \"=========================================================================\"\n      echo \"CMake config packages\"\n      echo \"=========================================================================\"\n      \"$0\" cmake-package autotools-shared\n      \"$0\" cmake-package autotools-static\n      \"$0\" cmake-package cmake-shared\n      \"$0\" cmake-package cmake-static\n      exit 0\n      ;;\n    clean )\n      rm -rf tmp-staging\n      cd c++\n      if [ -e Makefile ]; then\n        doit make maintainer-clean\n      fi\n      rm -f capnproto-*.tar.gz samples/addressbook samples/addressbook.capnp.c++ \\\n            samples/addressbook.capnp.h\n      exit 0\n      ;;\n    help )\n      echo \"usage: $0 [COMMAND]\"\n      echo \"commands:\"\n      echo \"  test          Runs tests (the default).\"\n      echo \"  clang         Runs tests using Clang compiler.\"\n      echo \"  gcc-4.7       Runs tests using gcc-4.7.\"\n      echo \"  gcc-4.8       Runs tests using gcc-4.8.\"\n      echo \"  gcc-4.9       Runs tests using gcc-4.9.\"\n      echo \"  remote HOST   Runs tests on HOST via SSH.\"\n      echo \"  mingw         Cross-compiles to MinGW and runs tests using WINE.\"\n      echo \"  android       Cross-compiles to Android and runs tests using emulator.\"\n      echo \"  clean         Delete temporary files that may be left after failure.\"\n      echo \"  help          Prints this help text.\"\n      exit 0\n      ;;\n    * )\n      echo \"unknown command: $1\" >&2\n      echo \"try: $0 help\" >&2\n      exit 1\n      ;;\n  esac\n  shift\ndone\n\n# Build optimized builds because they catch more problems, but also enable debugging macros.\n# Enable lots of warnings and make sure the build breaks if they fire.  Disable strict-aliasing\n# because GCC warns about code that I know is OK.  Disable sign-compare because I've fixed more\n# sign-compare warnings than probably all other warnings combined and I've never seen it flag a\n# real problem. Disable unused parameters because it's stupidly noisy and never a real problem.\n# Enable expensive release-gating tests.\nexport CXXFLAGS=\"-O2 -DDEBUG -Wall -Wextra -Werror -Wsuggest-override -Wno-strict-aliasing -Wno-sign-compare -Wno-unused-parameter -DCAPNP_EXPENSIVE_TESTS=1 ${CPP_FEATURES}\"\nexport LIBS=\"$EXTRA_LIBS\"\n\nif [ \"${CXX:-}\" != \"g++-5\" ]; then\n  # This warning flag is missing on g++-5 but available on all other GCC/Clang versions we target\n  # in CI.\n  export CXXFLAGS=\"$CXXFLAGS -Wimplicit-fallthrough\"\nfi\n\nSTAGING=$PWD/tmp-staging\n\nrm -rf \"$STAGING\"\nmkdir \"$STAGING\"\nmkdir \"$STAGING/bin\"\nmkdir \"$STAGING/lib\"\nexport PATH=$STAGING/bin:$PATH\nexport LD_LIBRARY_PATH=$STAGING/lib${LD_LIBRARY_PATH:+:$LD_LIBRARY_PATH}\nexport PKG_CONFIG_PATH=$STAGING/lib/pkgconfig\n\nif [ \"$QUICK\" = quick ]; then\n  echo \"************************** QUICK TEST ***********************************\"\nfi\n\necho \"=========================================================================\"\necho \"Building c++\"\necho \"=========================================================================\"\n\n# Apple now aliases gcc to clang, so probe to find out what compiler we're really using.\n#\n# NOTE: You might be tempted to use `grep -q` here instead of sending output to /dev/null. However,\n#   we cannot, because `grep -q` exits immediately upon seeing a match. If it exits too soon, the\n#   first stage of the pipeline gets killed, and the whole expression is considered to have failed\n#   since we are running bash with the `pipefail` option enabled.\n# FUN STORY: We used to use grep -q. One day, we found that Clang 9 when running under GitHub\n#   Actions was detected as *not* Clang. But if we ran it twice, it would succeed on the second\n#   try. It turns out that under previous versions of Clang, the `__clang__` define was pretty\n#   close to the end of the list, so it always managed to write the whole list before `grep -q`\n#   exited. But under Clang 9, there's a bunch more defines after this one, giving more time for\n#   `grep -q` to exit and break everything. But if the compiler had executed once recently then\n#   the second run would go faster due to caching (I guess) and manage to get all the data out\n#   to the buffer in time.\nif (${CXX:-g++} -dM -E -x c++ /dev/null 2>&1 | grep '__clang__' > /dev/null); then\n  IS_CLANG=yes\n  DISABLE_OPTIMIZATION_IF_GCC=\nelse\n  IS_CLANG=no\n  DISABLE_OPTIMIZATION_IF_GCC=-O0\nfi\n\nif [ $IS_CLANG = yes ]; then\n  if [ \"${CXX#*-}\" -ge 12 ] 2>/dev/null; then\n    # TODO(someday): On Ubuntu 22.04, clang 12, 13, 14, and 15 with -stdlib=libc++ fail to link with\n    #   libfuzzer, which looks like it might itself be linked against libstdc++? Need to\n    #   investigate.\n    unset LIB_FUZZING_ENGINE\n  fi\n\n  # Don't fail out on this ridiculous \"argument unused during compilation\" warning.\n  export CXXFLAGS=\"$CXXFLAGS -Wno-error=unused-command-line-argument\"\n\n  # Require C++20.\n  export CXXFLAGS=\"$CXXFLAGS -std=gnu++20\"\n\n  # Embed -stdlib=libc++ into CXX instead of CXXFLAGS in order to work around an irritating libtool\n  # bug.\n  export CXX=\"${CXX:-g++} -stdlib=libc++\"\nelse\n  # GCC emits uninitialized warnings all over and they seem bogus. We use valgrind to test for\n  # uninitialized memory usage later on. GCC 4 also emits strange bogus warnings with\n  # -Wstrict-overflow, so we disable it.\n  CXXFLAGS=\"$CXXFLAGS -Wno-maybe-uninitialized -Wno-strict-overflow\"\n\n  export CXXFLAGS=\"$CXXFLAGS -std=gnu++20\"\nfi\n\ncd c++\ndoit autoreconf -i\ndoit ./configure --prefix=\"$STAGING\" || (cat config.log && exit 1)\ndoit make -j$PARALLEL check\n\nif [ $IS_CLANG = no ]; then\n  # Verify that generated code compiles with pedantic warnings.  Make sure to treat capnp headers\n  # as system headers so warnings in them are ignored.\n  doit ${CXX:-g++} -isystem src -std=c++20 -fno-permissive -pedantic -Wall -Wextra -Werror \\\n      -c src/capnp/test.capnp.c++ -o /dev/null\nfi\n\necho \"=========================================================================\"\necho \"Testing c++ install\"\necho \"=========================================================================\"\n\ndoit make install\n\ntest \"x$(which capnp)\" = \"x$STAGING/bin/capnp\"\ntest \"x$(which capnpc-c++)\" = \"x$STAGING/bin/capnpc-c++\"\n\ncd samples\n\ndoit capnp compile -oc++ addressbook.capnp -I\"$STAGING\"/include --no-standard-import\ndoit ${CXX:-g++} -std=c++20 addressbook.c++ addressbook.capnp.c++ -o addressbook \\\n    $CXXFLAGS $(pkg-config --cflags --libs capnp)\n\ndoit capnp compile -oc++ calculator.capnp -I\"$STAGING\"/include --no-standard-import\ndoit ${CXX:-g++} -std=c++20 calculator-client.c++ calculator.capnp.c++ -o calculator-client \\\n    $CXXFLAGS $(pkg-config --cflags --libs capnp-rpc)\ndoit ${CXX:-g++} -std=c++20 calculator-server.c++ calculator.capnp.c++ -o calculator-server \\\n    $CXXFLAGS $(pkg-config --cflags --libs capnp-rpc)\n\ntest_samples\nrm addressbook addressbook.capnp.c++ addressbook.capnp.h\nrm calculator-client calculator-server calculator.capnp.c++ calculator.capnp.h\n\nrm -rf cmake-build\nmkdir cmake-build\ncd cmake-build\n\ndoit cmake .. -G \"Unix Makefiles\" -DCMAKE_PREFIX_PATH=\"$STAGING\" \\\n    -DCAPNPC_FLAGS=--no-standard-import -DCAPNPC_IMPORT_DIRS=\"$STAGING/include\"\ndoit make -j$PARALLEL\n\ntest_samples\ncd ../..\nrm -rf samples/cmake-build\n\nif [ \"$QUICK\" = quick ]; then\n  doit make maintainer-clean\n  rm -rf \"$STAGING\"\n  exit 0\nfi\n\necho \"=========================================================================\"\necho \"Testing --with-external-capnp and --disable-reflection\"\necho \"=========================================================================\"\n\ndoit make distclean\ndoit ./configure --prefix=\"$STAGING\" --disable-shared --disable-reflection \\\n    --with-external-capnp CAPNP=$STAGING/bin/capnp\ndoit make -j$PARALLEL check\ndoit make distclean\n\n# Test 32-bit build now while we have $STAGING available for cross-compiling.\n#\n# Cygwin64 can cross-compile to Cygwin32 but can't actually run the cross-compiled binaries. Let's\n# just skip this test on Cygwin since it's so slow and honestly no one cares.\n#\n# MacOS apparently no longer distributes 32-bit standard libraries. OK fine let's restrict this to\n# Linux.\nif [ \"x`uname -m`\" = \"xx86_64\" ] && [ \"x`uname`\" = xLinux ]; then\n  echo \"=========================================================================\"\n  echo \"Testing 32-bit build\"\n  echo \"=========================================================================\"\n\n  doit ./configure CXX=\"${CXX:-g++} -m32\" CXXFLAGS=\"$CXXFLAGS ${ADDL_M32_FLAGS:-}\" --disable-shared\n  doit make -j$PARALLEL check\n  doit make distclean\nfi\n\necho \"=========================================================================\"\necho \"Testing c++ uninstall\"\necho \"=========================================================================\"\n\ndoit ./configure --prefix=\"$STAGING\"\ndoit make uninstall\n\necho \"=========================================================================\"\necho \"Testing c++ dist\"\necho \"=========================================================================\"\n\ndoit make -j$PARALLEL distcheck\ndoit make distclean\nrm capnproto-*.tar.gz\n\nif [ \"x`uname`\" = xLinux ]; then\n  echo \"=========================================================================\"\n  echo \"Testing generic Unix (no Linux-specific features)\"\n  echo \"=========================================================================\"\n\n  doit ./configure --disable-shared CXXFLAGS=\"$CXXFLAGS -DKJ_USE_FUTEX=0 -DKJ_USE_EPOLL=0\"\n  doit make -j$PARALLEL check\n  doit make distclean\nfi\n\necho \"=========================================================================\"\necho \"Testing with -fno-rtti\"\necho \"=========================================================================\"\n\ndoit ./configure --disable-shared CXXFLAGS=\"$CXXFLAGS -fno-rtti\"\ndoit make -j$PARALLEL check\n\nif [ \"x`uname`\" = xLinux ]; then\n  doit make distclean\n\n  echo \"=========================================================================\"\n  echo \"Testing with valgrind\"\n  echo \"=========================================================================\"\n\n  doit ./configure --disable-shared CXXFLAGS=\"-g $CPP_FEATURES\"\n  doit make -j$PARALLEL\n  doit make -j$PARALLEL capnp-test\n  # Running the fuzz tests under Valgrind is a great thing to do -- but it takes\n  # some 40 minutes. So, it needs to be done as a separate step of the release\n  # process, perhaps along with the AFL tests.\n  CAPNP_SKIP_FUZZ_TEST=1 doit valgrind --leak-check=full --track-fds=yes --error-exitcode=1 --child-silent-after-fork=yes --sim-hints=lax-ioctls --suppressions=valgrind.supp ./capnp-test\nfi\n\ndoit make maintainer-clean\n\nrm -rf \"$STAGING\"\n"
        }
      ]
    }
  ]
}