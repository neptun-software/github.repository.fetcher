{
  "metadata": {
    "timestamp": 1736711072536,
    "page": 852,
    "hasNextPage": true,
    "endCursor": "Y3Vyc29yOjg2MA==",
    "completionStatus": "IN_PROGRESS"
  },
  "repositories": [
    {
      "nameWithOwner": "dotnet/TorchSharp",
      "stars": 1463,
      "defaultBranch": "main",
      "files": [
        {
          "name": ".editorconfig",
          "type": "blob",
          "size": 3.224609375,
          "content": "# EditorConfig is awesome:http://EditorConfig.org\n\n# top-most EditorConfig file\nroot = true\n\n# Baseline\n[*]\ncharset = utf-8\nindent_style = tab\ntrim_trailing_whitespace = true\nmax_line_length = 120\n\n# MSBuild\n[*.{csproj,proj,projitems,shproj,fsproj,target,props}]\nindent_style = space\nindent_size = 2\n\n# C++\n[*.{cpp,h,hpp,c}]\nindent_style = space\nindent_size = 4\n\n# XML config files\n[*.{config,nuspec,resx}]\nindent_style = space\nindent_size = 2\n\n# JSON files\n[*.json]\nindent_style = space\nindent_size = 2\n\n# F# files\n[*.{fs, fsx, fsi}]\nindent_style = space\nindent_size = 4\n\n# Dotnet code style settings:\n[*.{cs,vb,tt}]\n\nindent_style = space\n# Sort using and Import directives with System.* appearing first\ndotnet_sort_system_directives_first = true\n\n# Avoid \"this.\" and \"Me.\" if not necessary\ndotnet_style_qualification_for_field = false:suggestion\ndotnet_style_qualification_for_property = false:suggestion\ndotnet_style_qualification_for_method = false:suggestion\ndotnet_style_qualification_for_event = false:suggestion\n\n# Use language keywords instead of framework type names for type references\ndotnet_style_predefined_type_for_locals_parameters_members = true:suggestion\ndotnet_style_predefined_type_for_member_access = true:suggestion\n\n# Suggest more modern language features when available\ndotnet_style_object_initializer = true:suggestion\ndotnet_style_collection_initializer = true:suggestion\ndotnet_style_coalesce_expression = true:suggestion\ndotnet_style_null_propagation = true:suggestion\ndotnet_style_explicit_tuple_names = true:suggestion\n\n# CSharp code style settings:\n[*.cs]\n\n# spaces before parens\ncsharp_space_between_method_declaration_name_and_open_parenthesis = false\ncsharp_space_between_method_call_name_and_opening_parenthesis = false\ncsharp_space_after_keywords_in_control_flow_statements = true\n\n# Newline settings\ncsharp_new_line_before_open_brace = types,methods\ncsharp_new_line_before_else = false\ncsharp_new_line_before_catch = false\ncsharp_new_line_before_finally = false\ncsharp_new_line_before_members_in_object_initializers = true\ncsharp_new_line_before_members_in_anonymous_types = true\n\n# Switch indentation\ncsharp_indent_switch_labels = false\n\n# Prefer \"var\" everywhere it's apparent\ncsharp_style_var_for_built_in_types = true:none\ncsharp_style_var_when_type_is_apparent = true:suggestion\ncsharp_style_var_elsewhere = true:none\n\n# Prefer method-like constructs to have a block body\ncsharp_style_expression_bodied_methods = false:none\ncsharp_style_expression_bodied_constructors = false:none\ncsharp_style_expression_bodied_operators = false:none\n\n# Prefer property-like constructs to have an expression-body\ncsharp_style_expression_bodied_properties = true:none\ncsharp_style_expression_bodied_indexers = true:none\ncsharp_style_expression_bodied_accessors = true:none\n\n# Suggest more modern language features when available\ncsharp_style_pattern_matching_over_is_with_cast_check = true:suggestion\ncsharp_style_pattern_matching_over_as_with_null_check = true:suggestion\ncsharp_style_inlined_variable_declaration = true:suggestion\ncsharp_style_throw_expression = true:suggestion\ncsharp_style_conditional_delegate_call = true:suggestion\n\n# Avoid redundant accessibility modifiers when they're default\ndotnet_style_require_accessibility_modifiers = omit_if_default:suggestion\n"
        },
        {
          "name": ".gitattributes",
          "type": "blob",
          "size": 0.3896484375,
          "content": "###############################################################################\n# Set default behavior to automatically normalize line endings.\n###############################################################################\n* text=auto\n\n# Force bash scripts to always use lf line endings so that if a repo is accessed\n# in Unix via a file share from Windows, the scripts will work.\n*.sh text eol=lf\n"
        },
        {
          "name": ".gitignore",
          "type": "blob",
          "size": 4.513671875,
          "content": "## Ignore Visual Studio temporary files, build results, and\n## files generated by popular Visual Studio add-ons.\n##\n## Get latest from https://github.com/github/gitignore/blob/master/VisualStudio.gitignore\n\n# Tool Runtime Dir\n/[Tt]ools/\n\n# User-specific files\n*.suo\n*.user\n*.userosscache\n*.sln.docstates\n\n# User-specific files (MonoDevelop/Xamarin Studio)\n*.userprefs\n\n# Build results\n[Dd]ebug/\n[Dd]ebugPublic/\n[Rr]elease/\n[Rr]eleases/\nx64/\nx86/\nbld/\n[Bb]in/\n[Oo]bj/\n[Ll]og/\nmsbuild.log\nmsbuild.err\nmsbuild.wrn\nmsbuild.binlog\n\n# Visual Studio 2015/2017 cache/options directory\n.vs/\n# Uncomment if you have tasks that create the project's static files in wwwroot\n#wwwroot/\n\n# Visual Studio 2017 auto generated files\nGenerated\\ Files/\n\n# MSTest test Results\n[Tt]est[Rr]esult*/\n[Bb]uild[Ll]og.*\n\n# NUNIT\n*.VisualState.xml\nTestResult.xml\n\n# Benchmark Results\nBenchmarkDotNet.Artifacts/\n\n# StyleCop\nStyleCopReport.xml\n\n# Files built by Visual Studio\n*_i.c\n*_p.c\n*_i.h\n*.ilk\n*.meta\n*.obj\n*.pch\n*.pdb\n*.pgc\n*.pgd\n*.rsp\n*.sbr\n*.tlb\n*.tli\n*.tlh\n*.tmp\n*.tmp_proj\n*.log\n*.vspscc\n*.vssscc\n.builds\n*.pidb\n*.svclog\n*.scc\n\n# Chutzpah Test files\n_Chutzpah*\n\n# Visual C++ cache files\nipch/\n*.aps\n*.ncb\n*.opendb\n*.opensdf\n*.sdf\n*.cachefile\n*.VC.db\n*.VC.VC.opendb\n\n# Visual Studio profiler\n*.psess\n*.vsp\n*.vspx\n*.sap\n\n# Visual Studio Trace Files\n*.e2e\n\n# TFS 2012 Local Workspace\n$tf/\n\n# Guidance Automation Toolkit\n*.gpState\n\n# ReSharper is a .NET coding add-in\n_ReSharper*/\n*.[Rr]e[Ss]harper\n*.DotSettings.user\n\n# JustCode is a .NET coding add-in\n.JustCode\n\n# TeamCity is a build add-in\n_TeamCity*\n\n# DotCover is a Code Coverage Tool\n*.dotCover\n\n# AxoCover is a Code Coverage Tool\n.axoCover/*\n!.axoCover/settings.json\n\n# Visual Studio code coverage results\n*.coverage\n*.coveragexml\n\n# NCrunch\n_NCrunch_*\n.*crunch*.local.xml\nnCrunchTemp_*\n\n# MightyMoose\n*.mm.*\nAutoTest.Net/\n\n# Web workbench (sass)\n.sass-cache/\n\n# Installshield output folder\n[Ee]xpress/\n\n# DocProject is a documentation generator add-in\nDocProject/buildhelp/\nDocProject/Help/*.HxT\nDocProject/Help/*.HxC\nDocProject/Help/*.hhc\nDocProject/Help/*.hhk\nDocProject/Help/*.hhp\nDocProject/Help/Html2\nDocProject/Help/html\n\n# Click-Once directory\npublish/\n\n# Publish Web Output\n*.[Pp]ublish.xml\n*.azurePubxml\n# Note: Comment the next line if you want to checkin your web deploy settings,\n# but database connection strings (with potential passwords) will be unencrypted\n*.pubxml\n*.publishproj\n\n# Microsoft Azure Web App publish settings. Comment the next line if you want to\n# checkin your Azure Web App publish settings, but sensitive information contained\n# in these scripts will be unencrypted\nPublishScripts/\n\n# NuGet Packages\n*.nupkg\n# The packages folder can be ignored because of Package Restore\n**/[Pp]ackages/*\n# except build/, which is used as an MSBuild target.\n!**/[Pp]ackages/build/\n# Uncomment if necessary however generally it will be regenerated when needed\n#!**/[Pp]ackages/repositories.config\n# NuGet v3's project.json files produces more ignorable files\n*.nuget.props\n*.nuget.targets\n\n# Microsoft Azure Build Output\ncsx/\n*.build.csdef\n\n# Microsoft Azure Emulator\necf/\nrcf/\n\n# Windows Store app package directories and files\nAppPackages/\nBundleArtifacts/\nPackage.StoreAssociation.xml\n_pkginfo.txt\n*.appx\n\n\n# Others\nClientBin/\n~$*\n*~\n*.dbmdl\n*.dbproj.schemaview\n*.jfm\n*.pfx\n*.publishsettings\norleans.codegen.cs\n\n\n# Backup & report files from converting an old project file\n# to a newer Visual Studio version. Backup files are not needed,\n# because we have git ;-)\n_UpgradeReport_Files/\nBackup*/\nUpgradeLog*.XML\nUpgradeLog*.htm\nServiceFabricBackup/\n\n# CodeRush\n.cr/\n\n# Python Tools for Visual Studio (PTVS)\n__pycache__/\n*.pyc\n\n# Cake - Uncomment if you are using it\n# tools/**\n# !tools/packages.config\n\n# Tabs Studio\n*.tss\n\n# Telerik's JustMock configuration file\n*.jmconfig\n\n# BizTalk build output\n*.btp.cs\n*.btm.cs\n*.odx.cs\n*.xsd.cs\n\n# OpenCover UI analysis results\nOpenCover/\n\n# Azure Stream Analytics local run output \nASALocalRun/\n\n# MSBuild Binary and Structured Log\n*.binlog\n# Ignore external test datasets.\n/test/data/external/\n/src/Examples/Data/train-labels-idx1-ubyte\n/src/Examples/Data/train-images-idx3-ubyte\n/src/Examples/Data/test_batch.bin\n/src/Examples/Data/t10k-labels-idx1-ubyte\n/src/Examples/Data/t10k-images-idx3-ubyte\n/src/Examples/Data/data_batch_5.bin\n/src/Examples/Data/data_batch_4.bin\n/src/Examples/Data/data_batch_3.bin\n/src/Examples/Data/data_batch_2.bin\n/src/Examples/Data/data_batch_1.bin\npackages/\n.fake\n.ionide\n*.bin\n/*.png\n/src/Native/out/build/x64-Debug\n*.code-workspace\n/.idea\n/test/TorchSharpTest/exportsd.py\n.vscode/settings.json\n"
        },
        {
          "name": "CODE-OF-CONDUCT.md",
          "type": "blob",
          "size": 0.2529296875,
          "content": "# Code of Conduct\n\nThis project has adopted the code of conduct defined by the Contributor Covenant\nto clarify expected behavior in our community.\n\nFor more information, see the [.NET Foundation Code of Conduct](https://dotnetfoundation.org/code-of-conduct).\n"
        },
        {
          "name": "CONTRIBUTING.md",
          "type": "blob",
          "size": 3.185546875,
          "content": "Contributing to TorchSharp\n==========================\n\nIf you are here, it means you are interested in helping us out. A hearty welcome and thank you! There are many ways you can contribute to the ML.NET project:\n\n* Offer PR's to fix bugs or implement new features.\n* Give us feedback and bug reports regarding the software or the documentation.\n* Improve our examples, tutorials, and documentation.\n\nThis document describes contribution guidelines that are specific to TorchSharp. Please read [.NET Core Guidelines](https://github.com/dotnet/coreclr/blob/main/Documentation/project-docs/contributing.md) for more general .NET Core contribution guidelines.\n\n## Developers\n\nSee the [Developer Guide](DEVGUIDE.md) for details about building and developing in this repo.\n\n\n## Pull Requests\n\nIf you send us a PR, whether for documentation, examples, or library code, we require that you sign a digital Contributor License Agreement (CLA), so that we know you have the right to contribute. Once you have signed it, future PRs should go through without further requests to sign.\n\n* **DO** use your own forked repository for all development, and submit cross-fork PRs.\n* **DO** resolve merge conflicts early, by merging recent changes to 'main' into your development fork before submitting a PR.\n* **DO** submit all code changes via pull requests (PRs). PRs will be reviewed and potentially merged by the repo maintainers after a peer review that includes at least one maintainer.\n* **DO** give PRs short-but-descriptive names (for example, \"Improve code coverage for System.Console by 10%\", not \"Fix #1234\")\n* **DO** refer to any relevant issues, and include [keywords](https://help.github.com/articles/closing-issues-via-commit-messages/) that automatically close issues when the PR is merged.\n* **DO** tag any users that should know about and/or review the change.\n* **DO** ensure each commit successfully builds.  The entire PR must pass all tests in the Continuous Integration (CI) system before it'll be merged.\n* **DO** add a brief description to the RELEASENOTES.md file at the top under the heading of the upcoming release.\n* **DO** address PR feedback in an additional commit(s) rather than amending the existing commits, and only rebase/squash them when necessary.  This makes it easier for reviewers to track changes.\n* **DO** assume that [\"Squash and Merge\"](https://github.com/blog/2141-squash-your-commits) will be used to merge your commit unless you request otherwise in the PR.\n* **DO NOT** fix merge conflicts using a merge commit. Prefer `git rebase`.\n* **DO NOT** mix independent, unrelated changes in one PR. Separate unrelated fixes into separate PRs.\n\n\n## A Useful Tip\n\nA useful tip from the Tensorflow.NET repo:\n\nAfter you fork, add dotnet/TorchSharp as 'upstream' to your local repo ...\n\n```git\ngit remote add upstream https://github.com/dotnet/TorchSharp.git\n```\n\nThis makes it easy to keep your fork up to date by regularly pulling and merging from upstream.\n\nAssuming that you do all your development off your main branch, keep your main updated\nwith these commands:\n\n```git\ngit checkout main\ngit pull upstream main\ngit push origin main\n```\n\nThen, you merge onto your dev branch:\n\n```git\ngit checkout <<your dev branch>>\ngit merge main\n```\n"
        },
        {
          "name": "DEVGUIDE.md",
          "type": "blob",
          "size": 18.9482421875,
          "content": "\n# Building\n\n## Windows\n\nRequirements:\n- Visual Studio 2022, fully updated with C/C++ desktop development and Windows SDK installed\n- git\n- cmake (tested with 3.18)\n\nFrom a VS 'x64 Native Tools' command prompt, build with:\n\n    dotnet build /p:SkipNative=true\n    dotnet build  # for cuda support on Windows and Linux\n    dotnet test\n    dotnet pack\n\n## Linux\n\nRequirements:\n- requirements to run .NET Core 3.1\n- git\n- cmake (tested with 3.14)\n- clang 6.x +\n\nExample to fulfill the requirements in Ubuntu 16:\n```\nwget -O - https://apt.llvm.org/llvm-snapshot.gpg.key | sudo apt-key add -\nsudo apt-add-repository \"deb https://apt.llvm.org/xenial/ llvm-toolchain-xenial-6.0 main\"\nsudo apt-get -y update\nsudo apt-get -y install clang-6.0 git cmake libunwind8 curl libomp-dev\n```\n\nCommands:\n\n    dotnet build /p:SkipNative=true\n    dotnet build  # for cuda support on Windows and Linux\n    dotnet test\n\n## Mac\n\nRequirements:\n- Clang/LLVM 12.0.0\n- git\n- .NET SDK 5.0.300\n- Cmake 3.20.3\n\nBuild with\n\n    dotnet build\n    dotnet test\n\n## Packages\n\nAn ephemeral feed of packages from Azure DevOps CI is available for those\n\n* View link: https://dotnet.visualstudio.com/TorchSharp/_packaging?_a=feed&feed=SignedPackages\n* Nuget feed: https://dotnet.pkgs.visualstudio.com/TorchSharp/_packaging/SignedPackages/nuget/v3/index.json\n\nSome releases are pushed to nuget\n\n## Building the TorchSharp package\n\n    dotnet build\n    dotnet pack\n\nLocally built packages have names like this, names update every day.  If repeatedly rebuilding them locally you may have to remove them\nfrom your local `.nuget` package cache.\n\n    bin/packages/Debug/TorchSharp.0.3.0-local-Debug-20200520.nupkg\n    bin/packages/Release/TorchSharp.0.3.0-local-Release-20200520.nupkg\n\nTo change the TorchSharp package version update this [file](https://github.com/dotnet/TorchSharp/blob/main/build/BranchInfo.props).\n\n## Doing releases of the TorchSharp package\n\nThe TorchSharp package is pushed to nuget.org via Azure DevOps CI release pipeline.  Assuming you're not building or updating the LibTorch packages\n(`BuildLibTorchPackages` is `false` in [azure-pipelines.yml](azure-pipelines.yml)) this is pretty simple once you have the permissions:\n\n1. Update the version number in [./build/BranchInfo.props](./build/BranchInfo.props) and in the [Release Notes](./RELEASENOTES.md) file and then submit a PR.\n\n   Updating the major or minor version number should only be done after a discussion with repo admins. The patch number should be incremented by one each release and set to zero after a change to the major or minor version.\n2. Integrate code to main and wait for CI to process\n3. Go to [releases](https://donsyme.visualstudio.com/TorchSharp/_release) and choose \"Create Release\" (top right)\n4. Under \"Artifacts-->Version\" choose the pipeline build corresponding to the thing you want to release.  It should be a successful build on main\n5. Press \"Create\"\n\n6. Once the package has been successfully pushed and is available in the NuGet gallery, create a GitHub tag in the 'main' branch with the version  as the name of the tag.\n\n# The libtorch packages\n\nThe libtorch packages are huge (~3GB compressed combined for CUDA Windows) and cause a\nlot of problems to make and deliver due to NuGet package size restrictions.\n\nThese problems include:\n\n1. A massive 2GB binary in the linux CUDA package and multiple 1.0GB binaries in Windows CUDA package\n\n2. Size limitations of about ~500MB on NuGet packages on the Azure DevOps CI system and about ~250MB on `nuget.org`\n\n4. Regular download/upload failures on these systems due to network interruptions for packages of this size\n\n5. 10GB VM image size restrictions for the containers userd to build these packages in the Azure DevOps CI system, we can easily run out of room.\n\n6. Complete libtorch-cpu packages can't be built using your local machine alone, since they won't contain the\n   full range of native bits. Instead they are built using Azure Pipelines by combining builds\n\nFor this reason, we do the following\n\n1. The head, referenceable packages that deliver a functioning runtime are any of:\n\n       libtorch-cpu\n       libtorch-cuda-12.1-linux-x64\n       libtorch-cuda-12.1-win-x64\n\n2. These packages are combo packages that reference multiple parts.  The parts are **not** independently useful.\n   Some parts deliver a single vast file via `primary` and `fragment` packages.  A build task is then used to \"stitch\" these files back together\n   to one file on the target machine with a SHA check.  This is a hack but there is no other realistic way to deliver\n   these vast files as packages (the alternative is to abandon packaging and require a manual\n   install/detect/link of PyTorch CUDA on all downstream systems, whcih is extremely problematic\n   for many practical reasons).\n\n   For example, the CUDA package fragments are defined in [libtorch-cuda](src/Redist/libtorch-cuda-12.1/libtorch-cuda-12.1.proj). See more details later in this document.\n\n3. The `libtorch-*` packages are built in Azure DevOps CI\n   [using this build pipeline](https://donsyme.visualstudio.com/TorchSharp/_build?definitionId=1&_a=summary) but only in main\n   branch and only when `BuildLibTorchPackages` is set to true in [azure-pipelines.yml](azure-pipelines.yml) in the main branch.\n   You must currently manually edit this and submit to main to get new `libtorch-*` packages\n   built.  Also increment `LibTorchPackageVersion` if necessary.  Do a push to main and the packages will build.  This process could be adjusted but at least gets us off the ground.\n\n4. After a successful build, the `libtorch-*` packages can be trialled using the package feed from CI (see above).  When\n   they are appropriate they can be  pushed to nuget using\n   [this manually invoked release pipeline](https://donsyme.visualstudio.com/TorchSharp/_release?_a=releases&view=mine&definitionId=1) in\n   Azure DevOps CI (so they don't have to be manually downloaded and pushed to `nuget.org`)\n\n   a. [Go to release pipeline](https://donsyme.visualstudio.com/TorchSharp/_release?_a=releases&view=mine&definitionId=1)\n\n   b. Press 'New Release'\n\n   c. Select the successful main CI build that includes the `libtorch` packages, create the release and wait for it to finish. You should\n      see `Initialize job`, `Download artifact - dotnet.TorchSharp - packages`, `NuGet push`, `Finalize Job` succeeded.\n\n   d. All packages should now be pushed to `nuget.org` and will appear after indexing.\n\n6. If updating libtorch packages, remember to delete all massive artifacts from Azure DevOps and reset this `BuildLibTorchPackages` in [azure-pipelines.yml](azure-pipelines.yml) in main branch.\n\n### Updating PyTorch version for new libtorch packages\n\nThis project grabs LibTorch and makes a C API wrapper for it, then calls these from C#. When updating to a newer\nversion of PyTorch then quite a lot of careful work needs to be done.\n\n0. Make sure you have plenty of disk space, e.g. 15GB.\n\n1. Clean and reset to main\n\n       git checkout main\n       git clean -xfd .\n\n2. Familiarise yourself with download links. See https://pytorch.org/get-started/locally/ for download links.\n\n   For example Linux, LibTorch 2.2.0 CPU download uses the link:\n\n       https://download.pytorch.org/libtorch/cpu/libtorch-cxx11-abi-shared-with-deps-2.2.0%2Bcpu.zip\n\n   Don't download anything yet, or manually. The downloads are acquired automatically in step 2.\n\n   To update the version, update this in [Dependencies.props](build/Dependencies.props):\n\n       <LibTorchVersion>2.2.0</LibTorchVersion>\n\n    The libtorch version number is also referenced in source code, in the file 'src/TorchSharp/Torch.cs':\n\n    ```C#\n    const string libtorchPackageVersion = \"2.2.0.1\";\n    ```\n\n3. Run these to test downloads and update SHA hashes for the various LibTorch downloads\n\nOn Windows:\n\n        dotnet build src\\Redist\\libtorch-cpu\\libtorch-cpu.proj /p:UpdateSHA=true /p:TargetOS=linux /p:Configuration=Release /t:Build /p:IncludeLibTorchCpuPackages=true\n        dotnet build src\\Redist\\libtorch-cpu\\libtorch-cpu.proj /p:UpdateSHA=true /p:TargetOS=mac /p:TargetArchitecture=arm64 /p:Configuration=Release /t:Build /p:IncludeLibTorchCpuPackages=true\n        dotnet build src\\Redist\\libtorch-cpu\\libtorch-cpu.proj /p:UpdateSHA=true /p:TargetOS=windows /p:Configuration=Release /t:Build /p:IncludeLibTorchCpuPackages=true\n        dotnet build src\\Redist\\libtorch-cpu\\libtorch-cpu.proj /p:UpdateSHA=true /p:TargetOS=windows /p:Configuration=Debug /t:Build /p:IncludeLibTorchCpuPackages=true\n\n        dotnet build src\\Redist\\libtorch-cuda-12.1\\libtorch-cuda-12.1.proj /p:UpdateSHA=true /p:TargetOS=linux /p:Configuration=Release /t:Build /p:IncludeLibTorchCudaPackages=true\n        dotnet build src\\Redist\\libtorch-cuda-12.1\\libtorch-cuda-12.1.proj /p:UpdateSHA=true /p:TargetOS=windows /p:Configuration=Release /t:Build /p:IncludeLibTorchCudaPackages=true\n        dotnet build src\\Redist\\libtorch-cuda-12.1\\libtorch-cuda-12.1.proj /p:UpdateSHA=true /p:TargetOS=windows /p:Configuration=Debug /t:Build /p:IncludeLibTorchCudaPackages=true\n\nOn Linux / Mac:\n\n        dotnet build src/Redist/libtorch-cpu/libtorch-cpu.proj /p:UpdateSHA=true /p:TargetOS=linux /p:Configuration=Release /t:Build /p:IncludeLibTorchCpuPackages=true\n        dotnet build src/Redist/libtorch-cpu/libtorch-cpu.proj /p:UpdateSHA=true /p:TargetOS=mac /p:TargetArchitecture=arm64 /p:Configuration=Release /t:Build /p:IncludeLibTorchCpuPackages=true\n        dotnet build src/Redist/libtorch-cpu/libtorch-cpu.proj /p:UpdateSHA=true /p:TargetOS=windows /p:Configuration=Release /t:Build /p:IncludeLibTorchCpuPackages=true\n        dotnet build src/Redist/libtorch-cpu/libtorch-cpu.proj /p:UpdateSHA=true /p:TargetOS=windows /p:Configuration=Debug /t:Build /p:IncludeLibTorchCpuPackages=true\n\n        dotnet build src/Redist/libtorch-cuda-12.1/libtorch-cuda-12.1.proj /p:UpdateSHA=true /p:TargetOS=linux /p:Configuration=Release /t:Build /p:IncludeLibTorchCudaPackages=true\n        dotnet build src/Redist/libtorch-cuda-12.1/libtorch-cuda-12.1.proj /p:UpdateSHA=true /p:TargetOS=windows /p:Configuration=Release /t:Build /p:IncludeLibTorchCudaPackages=true\n        dotnet build src/Redist/libtorch-cuda-12.1/libtorch-cuda-12.1.proj /p:UpdateSHA=true /p:TargetOS=windows /p:Configuration=Debug /t:Build /p:IncludeLibTorchCudaPackages=true\n\n\n   Each of these will take a **very very long time** depending on your broadband connection.  This can't currently be done in CI.\n\n   If file names in the distribution have changed, or files have been removed, you will get errors saying that files cannot be found. That's okay and will be taken care of in the next step.\n\n4. At this point you must **very very carefully** update the `<File Include= ...` entries under src\\Redist projects for\n   [libtorch-cpu](src/Redist/libtorch-cpu/libtorch-cpu.proj) and [libtorch-cuda](src/Redist/libtorch-cuda-12.1/libtorch-cuda-12.1.proj).\n\n   This is the step in the upgrade process that takes the most effort and time. It requires extreme care.\n\n   Check the contents of the unzip of the archive, e.g.\n\n       dir bin\\obj\\x64.Release\\libtorch-cpu\\libtorch-cxx11-abi-shared-with-deps-2.2.0cpu\\libtorch\\lib\\*.so*\n\n   You may also need to precisely refactor the binaries into multiple parts so each package ends up under ~300MB. Before release 2.2.0 of libtorch, this really only affected the CUDA packagages, but it is now also affecting the CPU packages on Linux and OSX. Windows CPU is still small enough to be contained in just one package. The NuGet gallery does not allow packages larger than 250MB, so if files are 300MB, after compression, they are likely to be smaller than 250MB. However, you have to look out: if the compression is poor, then packages may end up larger. Note that it is 250 million\n   bytes that is the limit, **not** 250*1024*1024. In other words, it is 250 MB, not 250 MiB. Note that Windows Explorer will show file sizes in KiB, not thousands of bytes. Use 'dir' from a CMD window to get the exact size in bytes for each file. For example -- the file `libtorch_cpu.so` shows up as 511,872 KB in Windows Explorer, but 524,156,144 bytes in CMD. The 2.4% difference can be significant. Getting the partitioning right requires precision.\n\n   If the combined size of the files going into a part is smaller than 250MB, then everything is fine, and there is no need to split the part. It can be singular. If that is not the case, then the part should be fragmented into two or more parts that are linked together by their names.\n\n   For example, the following snippet spreads the `torch_cuda_cu.dll` binary file into four fragments of 250 MB each. After compression, they will be even smaller.\n\n   ```xml\n    <File Include= \"libtorch\\lib\\torch_cuda_cu.dll\"  PackageSuffix=\"part9-primary\" FileUnstitchIndex=\"0\" FileUnstitchStart=\"0\" FileUnstitchSize=\"250000000\" />\n    <File Include= \"libtorch\\lib\\torch_cuda_cu.dll\"  PackageSuffix=\"part9-fragment1\" FileUnstitchIndex=\"1\" FileUnstitchStart=\"250000000\" FileUnstitchSize=\"250000000\" />\n    <File Include= \"libtorch\\lib\\torch_cuda_cu.dll\"  PackageSuffix=\"part9-fragment2\" FileUnstitchIndex=\"2\" FileUnstitchStart=\"500000000\" FileUnstitchSize=\"250000000\" />\n    <File Include= \"libtorch\\lib\\torch_cuda_cu.dll\"  PackageSuffix=\"part9-fragment3\" FileUnstitchIndex=\"3\" FileUnstitchStart=\"750000000\" FileUnstitchSize=\"-1\" />\n   ```\n\n   They must all be called either 'primary,' which should be the first fragment, or 'fragmentN' where 'N' is the ordinal number of the fragment, starting with '1'. The current logic allows for as many as 10 non-primary fragments. If more are needed, the code in [FileRestitcher.cs](pkg/FileRestitcher/FileRestitcher/FileRestitcher.cs) and [RestitchPackage.targets](pkg/common/RestitchPackage.targets) needs to be updated. Note that the size of each fragment is expressed in bytes, and that fragment start must be\n   the sum of the size of all previous fragments. A '-1' should be used for the last fragment (and only for the last fragment): it means that the fragment size will be based on how much there is still left of the file.\n\n   Each part, whether singular or fragmented, should have its own .nupkgproj file in its own folder under pkg. The folder and file should have the same name as the part. If you need to add new fragments, it is straightforward to just copy an existing fragment folder and rename it as well as the project file to the new fragment.\n\n   __Important:__\n\n   If you must fragment a previously singular part, it is best to rename the existing folder and file to '-fragment1' and then copy a '-primary' folder and rename with the right part name. This is because the primary .nupkgproj files look different from others.\n\n   Specifically, they include different build targets:\n\n    ```xml\n    <Content Include=\"..\\common\\NormalPackage.props\" Pack=\"true\" PackagePath=\"buildTransitive\\netstandard2.0\\$(MSBuildProjectName).props\" />\n    <Content Include=\"..\\common\\NormalPackage.targets\" Pack=\"true\" PackagePath=\"buildTransitive\\netstandard2.0\\$(MSBuildProjectName).targets\" />\n    ```\n    vs.\n    ```xml\n    <Content Include=\"..\\common\\RestitchPackage.props\" Pack=\"true\" PackagePath=\"buildTransitive\\netstandard2.0\\$(MSBuildProjectName).props\" />\n    <Content Include=\"..\\common\\RestitchPackage.targets\" Pack=\"true\" PackagePath=\"buildTransitive\\netstandard2.0\\$(MSBuildProjectName).targets\" />\n    ```\n\n   It is the 'RestitchPackage.targets' that will trigger restitching packages on first build after a download, and only a project that is a primary in a multiple-fragment package should use the latter version.\n\n   Because file sizes change from release to release, it may be necessary to add or remove fragments. When you add a fragment, you also need to add a corresponding project folder under the `pkg/` top-level folder. The process of doing so is copy-paste-rename of existing folders. The same goes for adding parts (whether fragmented or not): you should add a corresponding folder and project file. If you remove a fragment (or part), you should remove the corresponding folder, or CI will end up building empty packages.\n\n   Once you have carefully edited the parts and the files that go into them, clean the build directory and re-issue the libtorch downloads commands until there are no errors.\n\n5. Add the SHA files:\n\n       git add src\\Redist\\libtorch-cpu\\*.sha\n       git add src\\Redist\\libtorch-cuda-12.1\\*.sha\n\n   After this you may as well submit to CI just to see what happens, though keep going with the other steps below as well.\n\n6. Build the native and managed code without CUDA\n\n       dotnet build /p:SkipCuda=true\n\n   The first stage unzips the archives, then CMAKE is run.\n\n   Unzipping the archives may take quite a while\n\n   Note that things may have changed in the LibTorch header files, linking flags etc.  There is a CMakeLists.txt that acquires\n   the cmake information delievered in the LibTorch download. It can be subtle.\n\n   If the vxcproj for the native code gets configured by cmake then you should now be able to start developing the C++ code in Visual Studio. In order to get the correct environment variables and PATH, start VS from the command line, not from the Start menu:\n\n       devenv TorchSharp.sln\n\n   e.g. the vcxproj is created here:\n\n       bin\\obj\\x64.Debug\\Native\\LibTorchSharp\\LibTorchSharp.vcxproj\n\n7. Similarly build the native code with CUDA\n\n       dotnet build\n\n8. You must also adjust the set of binaries referenced for tests, see various files under `tests` and `NativeAssemblyReference` in `TorchSharp\\Directory.Build.targets`.\n\n9. Run tests\n\n       dotnet test -c Debug\n       dotnet test -c Release\n\n10. Try building packages locally. The build (including CI) doesn't build `libtorch-*` packages by default, just the managed package. To\n   get CI to build new `libtorch-*` packages update this version and set `BuildLibTorchPackages` in [azure-pipelines.yml](azure-pipelines.yml):\n\n       <LibTorchPackageVersion>2.0.1.1</LibTorchPackageVersion>\n\n       dotnet pack -c Release -v:n /p:SkipNative=true /p:SkipTests=true /p:IncludeTorchSharpPackage=true /p:IncludeLibTorchCpuPackages=true /p:IncludeLibTorchCudaPackages=true\n       dotnet pack -c Release -v:n /p:SkipNative=true /p:SkipTests=true /p:TargetOS=linux /p:IncludeTorchSharpPackage=true /p:IncludeLibTorchCpuPackages=true /p:IncludeLibTorchCudaPackages=true\n\n    Once these finish, the output can be found in `bin\\packages\\Release`. Look at the file sizes -- if anything is larger than 250,000,000 bytes, you need to go back to #3 above and redefine the package contents and fragmentation scheme. It maybe necessary to introduce new fragments.\n\n\t**Note:** The locally built TorchSharp packages will only contain binaries for the local platform, so they cannot be used with other platforms. Therefore, only the packages built in Azure Pipelines can be used across platforms.\n\n11. Submit to CI and debug problems.\n\n12. Remember to delete all massive artifacts from Azure DevOps and reset this `BuildLibTorchPackages` in in [azure-pipelines.yml](azure-pipelines.yml)\n\n\n## Building with Visual Studio\n\nIn order for builds to work properly using Visual Studio 2019 or 2022, you must start VS from the 'x64 Native Tools Command Prompt for VS 2022' (or 2019) in order for the full environment to be set up correctly. Starting VS from the desktop or taskbar will not work properly.\n"
        },
        {
          "name": "Directory.Build.props",
          "type": "blob",
          "size": 10.1044921875,
          "content": "<Project>\n  <!-- Directory.Build.props contains the common build settings for all projects in the repo. -->\n\n  <Import Project=\"build/BranchInfo.props\" />\n  <Import Project=\"build/Dependencies.props\" />\n\n  <PropertyGroup>\n    <Configuration Condition=\"'$(Configuration)'==''\">Debug</Configuration>\n    <Configurations>Debug;Release</Configurations>\n    <_DefaultArchitecture>$([System.Runtime.InteropServices.RuntimeInformation]::OSArchitecture.ToString().ToLower())</_DefaultArchitecture>\n    <Platform Condition=\"'$(Platform)'==''\">AnyCPU</Platform>\n    <TargetArchitecture Condition=\"'$(TargetArchitecture)' == ''\">$(_DefaultArchitecture)</TargetArchitecture>\n    <NativeTargetArchitecture Condition=\"'$(NativeTargetArchitecture)' == ''\">$(TargetArchitecture)</NativeTargetArchitecture>\n    <PlatformConfig>$(Platform).$(Configuration)</PlatformConfig>\n  </PropertyGroup>\n\n  <!-- Common repo directories -->\n  <PropertyGroup>\n    <RepoRoot>$(MSBuildThisFileDirectory)</RepoRoot>\n    <SourceDir>$(RepoRoot)src/</SourceDir>\n    <PkgDir>$(RepoRoot)pkg/</PkgDir>\n\n    <LibTorchPackageVersion>2.5.1.0</LibTorchPackageVersion>\n    <LibTorchPackageVersion Condition=\"'$(TargetOS)' == 'mac' and '$(TargetArchitecture)' == 'x64'\">2.2.2.0</LibTorchPackageVersion>\n\n    <!-- when building on local machines the massive downloads get placed up one directory -->\n    <!-- so we can clean without triggering a re-download-->\n    <MassiveDownloadRoot>$(RepoRoot)../</MassiveDownloadRoot>\n    <MassiveDownloadRoot Condition=\"'$(TF_BUILD)' != ''\">$(RepoRoot)bin/downloads/</MassiveDownloadRoot>\n\n    <!-- Output directories -->\n    <BinDir Condition=\"'$(BinDir)'==''\">$(RepoRoot)bin/</BinDir>\n    <BaseOutputPath Condition=\"'$(BaseOutputPath)'==''\">$(BinDir)</BaseOutputPath>\n    <ObjDir Condition=\"'$(ObjDir)'==''\">$(BinDir)obj/</ObjDir>\n    <RootIntermediateOutputPath Condition=\"'$(RootIntermediateOutputPath)'==''\">$(ObjDir)</RootIntermediateOutputPath>\n\n    <IntermediateOutputRootPath Condition=\"'$(IntermediateOutputRootPath)' == ''\">$(RootIntermediateOutputPath)$(PlatformConfig)\\</IntermediateOutputRootPath>\n    <IntermediateOutputPath Condition=\"'$(IntermediateOutputPath)' == ''\">$(IntermediateOutputRootPath)$(MSBuildProjectName)\\</IntermediateOutputPath>\n    <BaseIntermediateOutputPath Condition=\"'$(BaseIntermediateOutputPath)' == ''\">$(IntermediateOutputPath)</BaseIntermediateOutputPath>\n\n    <OutputPath Condition=\"'$(OutputPath)'==''\">$(BaseOutputPath)$(PlatformConfig)\\$(MSBuildProjectName)\\</OutputPath>\n\n    <PackagePreparationPath>$(ObjDir)packprep/$(Configuration)/</PackagePreparationPath>\n\n    <PackageOutputPath Condition=\"'$(PackageOutputPath)'==''\">$(BinDir)packages/$(Configuration)/</PackageOutputPath>\n\n    <NativeConfiguration>$(Configuration)</NativeConfiguration>\n\n    <!-- Setting TargetOS allows us to download LibTorch for Linux etc, update the SHA and update file lists under src\\Redist -->\n    <!-- The only thing we can't do locally is build the C++ code for all the various target platforms (which is ultimately done on Azure Pipelines) -->\n    <TargetOS Condition=\"'$(TargetOS)' == '' AND '$(OS)' == 'Windows_NT'\">windows</TargetOS>\n    <TargetOS Condition=\"'$(TargetOS)' == '' AND $([MSBuild]::IsOSPlatform('osx'))\">mac</TargetOS>\n    <TargetOS Condition=\"'$(TargetOS)' == '' AND '$(OS)' != 'Windows_NT'\">linux</TargetOS>\n\n    <TargetPlatform Condition=\"'$(TargetPlatform)' == ''\">$(TargetOS)-$(TargetArchitecture)</TargetPlatform>\n\n    <TargetRuntimeID Condition=\"'$(TargetOS)' == 'windows'\">win-x64</TargetRuntimeID>\n    <TargetRuntimeID Condition=\"'$(TargetOS)' == 'linux'\">linux-x64</TargetRuntimeID>\n    <TargetRuntimeID Condition=\"'$(TargetPlatform)' == 'mac-arm64'\">osx-arm64</TargetRuntimeID>\n\n    <TargetRuntimeID Condition=\"'$(TargetOS)' == 'windows'\">win-x64</TargetRuntimeID>\n    <TargetRuntimeID Condition=\"'$(TargetOS)' == 'linux'\">linux-x64</TargetRuntimeID>\n    <TargetRuntimeID Condition=\"'$(TargetOS)' == 'mac'\">osx-$(TargetArchitecture)</TargetRuntimeID>\n\n    <!-- on windows separate debug binaries of LibTorch are available-->\n    <LibTorchDebug Condition=\"('$(NativeConfiguration)' == 'Debug') AND '$(TargetOS)' == 'windows'\">-debug</LibTorchDebug>\n\n    <NativeOutputPath>$(BaseOutputPath)$(NativeTargetArchitecture).$(NativeConfiguration)\\Native\\</NativeOutputPath>\n    <NativeCudaOutputPath>$(NativeOutputPath)cuda\\</NativeCudaOutputPath>\n\n  </PropertyGroup>\n\n  <!-- Version properties -->\n  <PropertyGroup>\n\n    <VersionPrefix >$(MajorVersion).$(MinorVersion).$(PatchVersion)</VersionPrefix>\n    <!--\n    <VersionSuffix>local-$(Configuration)-$([System.DateTime]::Now.ToString(yyyyMMdd))</VersionSuffix>\n\n    <VersionPrefix Condition=\"'$(TF_BUILD)' != ''\">$(MajorVersion).$(MinorVersion).$(MyRunNumber)</VersionPrefix>\n    <VersionSuffix Condition=\"'$(TF_BUILD)' != ''  AND '$(BUILD_SOURCEBRANCHNAME)' == 'main'\"></VersionSuffix>\n    <VersionSuffix Condition=\"'$(TF_BUILD)' != '' AND '$(BUILD_SOURCEBRANCHNAME)' != 'main'\">preview-$(VersionSuffix)</VersionSuffix>\n    -->\n  </PropertyGroup>\n\n  <!-- use stable versions for libtorch packages based on LibTorch version number scheme-->\n  <!-- we manually update these -->\n  <PropertyGroup Condition=\"'$(MSBuildProjectName.IndexOf(`libtorch-`))' != '-1'\">\n    <LibTorchPackageVersion>2.5.1.0</LibTorchPackageVersion>\n    <LibTorchPackageVersion Condition=\"'$(TargetOS)' == 'mac' and '$(TargetArchitecture)' == 'x64'\">2.2.2.0</LibTorchPackageVersion>\n    <EnablePackageValidation>false</EnablePackageValidation>\n    <VersionPrefix>$(LibTorchPackageVersion)</VersionPrefix>\n    <VersionSuffix></VersionSuffix>\n  </PropertyGroup>\n\n  <PropertyGroup>\n    <!-- turned on/off manually in separate CI jobs -->\n    <SkipCuda Condition=\"'$(TargetOS)' == 'mac'\">true</SkipCuda>\n    <SkipCuda Condition=\"'$(TargetOS)' != 'mac'\">false</SkipCuda>\n    <SkipTests>false</SkipTests>\n\n    <!-- By default only TorchSharp and no libtorch-cpu or libtorch-cuda packages are built.  The CI file controls these via 'BuildLibTorchPackages' -->\n    <!-- This then selectively turns these on over several CI jobs since different pacakges are done in different jobs -->\n    <IncludeTorchSharpPackage>true</IncludeTorchSharpPackage>\n    <IncludeLibTorchCpuPackages>false</IncludeLibTorchCpuPackages>\n    <IncludeLibTorchCudaPackages>false</IncludeLibTorchCudaPackages>\n  </PropertyGroup>\n\n  <!--\n  Source code control properties used by the .NET Core SDK to inject SCC info into the NuGet package.\n  In future versions, these will be used for SourceLink and to generate AssemblyInfo.\n  -->\n  <PropertyGroup>\n    <PrivateRepositoryUrl>https://github.com/dotnet/$(GitHubRepositoryName)</PrivateRepositoryUrl>\n    <PublishRepositoryUrl>true</PublishRepositoryUrl>\n    <SourceRevisionId>$(LatestCommit)</SourceRevisionId>\n  </PropertyGroup>\n\n  <PropertyGroup>\n    <PackageRid Condition=\"'$(TargetOS)' == 'windows'\">win</PackageRid>\n    <PackageRid Condition=\"'$(TargetOS)' == 'linux'\">linux</PackageRid>\n    <PackageRid Condition=\"'$(TargetOS)' == 'mac'\">osx</PackageRid>\n    <PackageRid>$(PackageRid)-$(TargetArchitecture)</PackageRid>\n  </PropertyGroup>\n\n  <PropertyGroup>\n    <NativeLibPrefix Condition=\"'$(TargetOS)' == 'linux' OR '$(TargetOS)' == 'mac'\">lib</NativeLibPrefix>\n    <NativeLibExtension Condition=\"'$(TargetOS)' == 'windows'\">.dll</NativeLibExtension>\n    <NativeLibExtension Condition=\"'$(TargetOS)' == 'linux'\">.so</NativeLibExtension>\n    <NativeLibExtension Condition=\"'$(TargetOS)' == 'mac'\">.dylib</NativeLibExtension>\n\n    <NativeLibSymbolExtension Condition=\"'$(TargetOS)' == 'windows'\">.pdb</NativeLibSymbolExtension>\n    <NativeLibSymbolExtension Condition=\"'$(TargetOS)' == 'linux'\">.so.dbg</NativeLibSymbolExtension>\n    <NativeLibSymbolExtension Condition=\"'$(TargetOS)' == 'mac'\">.dylib.dwarf</NativeLibSymbolExtension>\n  </PropertyGroup>\n\n  <PropertyGroup>\n    <LibTorchArchiveSource>pytorch</LibTorchArchiveSource>\n    <LibTorchCpuArchiveNameSuffix Condition=\"'$(TargetOS)' != 'mac'\">%252Bcpu</LibTorchCpuArchiveNameSuffix>\n    <LibTorchCudaArchiveNameSuffix>%252Bcu$(CudaVersionNoDot)</LibTorchCudaArchiveNameSuffix>\n    <LibTorchCpuLocalNameSuffix>cpu</LibTorchCpuLocalNameSuffix>\n    <LibTorchCudaLocalNameSuffix>cu$(CudaVersionNoDot)</LibTorchCudaLocalNameSuffix>\n    <LibTorchArchiveCoreName Condition=\"'$(TargetOS)' == 'windows'\">libtorch-win-shared-with-deps$(LibTorchDebug)</LibTorchArchiveCoreName>\n    <LibTorchArchiveCoreName Condition=\"'$(TargetOS)' == 'linux'\">libtorch-cxx11-abi-shared-with-deps</LibTorchArchiveCoreName>\n    <LibTorchArchiveCoreName Condition=\"'$(TargetOS)' == 'mac'\">libtorch-macos-x86_64</LibTorchArchiveCoreName>\n    <LibTorchArchiveCoreName Condition=\"'$(TargetPlatform)' == 'mac-arm64'\">libtorch-macos-arm64</LibTorchArchiveCoreName>\n    <LibTorchCpuArchiveBase>$(LibTorchArchiveCoreName)-$(LibTorchVersion)$(LibTorchCpuArchiveNameSuffix)</LibTorchCpuArchiveBase>\n    <LibTorchCudaArchiveBase>$(LibTorchArchiveCoreName)-$(LibTorchVersion)$(LibTorchCudaArchiveNameSuffix)</LibTorchCudaArchiveBase>\n    <LibTorchCpuLocalBase>$(LibTorchArchiveCoreName)-$(LibTorchVersion)$(LibTorchCpuLocalNameSuffix)</LibTorchCpuLocalBase>\n    <LibTorchCudaLocalBase>$(LibTorchArchiveCoreName)-$(LibTorchVersion)$(LibTorchCudaLocalNameSuffix)</LibTorchCudaLocalBase>\n    <LibTorchCmakePath>$(IntermediateOutputRootPath)libtorch-cpu\\$(LibTorchCpuLocalBase)\\libtorch\\share\\cmake\\Torch</LibTorchCmakePath>\n  </PropertyGroup>\n\n  <!-- Language configuration -->\n  <PropertyGroup>\n    <LangVersion>latest</LangVersion> <!-- default to allowing all language features -->\n    <TreatWarningsAsErrors>true</TreatWarningsAsErrors>\n  </PropertyGroup>\n\n  <!-- Need to explicitly set these properties for the -Intrinsics or -Netfx configurations becuase they are typically based off 'Debug' or 'Release' configs -->\n  <!-- Taken from https://github.com/dotnet/sdk/blob/073c98b92c81066c6c2e17c3674adbb6e833409a/src/Tasks/Microsoft.NET.Build.Tasks/targets/Microsoft.NET.Sdk.props#L41-L47 -->\n  <PropertyGroup Condition=\"$(Configuration.StartsWith('Debug'))\">\n    <DebugSymbols>true</DebugSymbols>\n    <DefineConstants>$(DefineContants);DEBUG</DefineConstants>\n    <Optimize>false</Optimize>\n  </PropertyGroup>\n  <PropertyGroup Condition=\"$(Configuration.StartsWith('Release'))\">\n    <Optimize>true</Optimize>\n  </PropertyGroup>\n\n</Project>\n"
        },
        {
          "name": "Directory.Build.targets",
          "type": "blob",
          "size": 6.810546875,
          "content": "<Project>\n  \n  <!-- We copy over the LibTorch native binaries in order to run tests.  This can probably be automated better. -->\n  <!-- These lists are duplicated in redist/... with file splitting added for package prep --> \n\n  <ItemGroup  Condition=\"'$(TestUsesLibTorch)' == 'true' and '$(SkipNative)' != 'true' \">\n    <NativeAssemblyReference Include=\"LibTorchSharp\" />\n  </ItemGroup>\n\n  <!-- Windows CPU libtorch binary list used for examples and testing -->\n  <ItemGroup Condition=\"'$(NativeTargetArchitecture)' == 'x64' and '$(OS)' == 'Windows_NT' and '$(TestUsesLibTorch)' == 'true' and ('$(TestCuda)' != 'true' or '$(SkipCuda)' == 'true') and '$(SkipNative)' != 'true' \">\n    <NativeAssemblyReference Include=\"asmjit\" />\n    <NativeAssemblyReference Include=\"c10\" />\n    <NativeAssemblyReference Include=\"fbgemm\" />\n    <NativeAssemblyReference Include=\"libiomp5md\" />\n    <NativeAssemblyReference Include=\"libiompstubs5md\" />\n    <NativeAssemblyReference Include=\"torch\" />\n    <NativeAssemblyReference Include=\"torch_cpu\" />\n    <NativeAssemblyReference Include=\"torch_global_deps\" />\n    <NativeAssemblyReference Include=\"uv\" />\n  </ItemGroup>\n\n  <!-- Windows CUDA 12.1 libtorch binary list used for examples and testing -->\n  <ItemGroup Condition=\"'$(NativeTargetArchitecture)' == 'x64' and '$(OS)' == 'Windows_NT' and '$(TestUsesLibTorch)' == 'true' and ('$(TestCuda)' == 'true' and '$(SkipCuda)' != 'true') and '$(SkipNative)' != 'true' \">\n    <NativeAssemblyReference Include=\"asmjit\" Variant=\"cuda\\\" />\n    <NativeAssemblyReference Include=\"c10\" Variant=\"cuda\\\" />\n    <NativeAssemblyReference Include=\"c10_cuda\" Variant=\"cuda\\\" />\n    <NativeAssemblyReference Include=\"caffe2_nvrtc\" Variant=\"cuda\\\" />\n    <NativeAssemblyReference Include=\"cublas64_12\" Variant=\"cuda\\\" />\n    <NativeAssemblyReference Include=\"cublasLt64_12\" Variant=\"cuda\\\" />\n    <NativeAssemblyReference Include=\"cudart64_12\" Variant=\"cuda\\\" />\n    <NativeAssemblyReference Include=\"cudnn64_9\" Variant=\"cuda\\\" />\n    <NativeAssemblyReference Include=\"cudnn_adv64_9\" Variant=\"cuda\\\" />\n    <NativeAssemblyReference Include=\"cudnn_cnn64_9\" Variant=\"cuda\\\" />\n    <NativeAssemblyReference Include=\"cudnn_engines_precompiled64_9\" Variant=\"cuda\\\" />\n    <NativeAssemblyReference Include=\"cudnn_engines_runtime_compiled64_9\" Variant=\"cuda\\\" />\n    <NativeAssemblyReference Include=\"cudnn_graph64_9\" Variant=\"cuda\\\" />\n    <NativeAssemblyReference Include=\"cudnn_heuristic64_9\" Variant=\"cuda\\\" />\n    <NativeAssemblyReference Include=\"cudnn_ops64_9\" Variant=\"cuda\\\" />\n    <NativeAssemblyReference Include=\"cufft64_11\" Variant=\"cuda\\\" />\n    <NativeAssemblyReference Include=\"cufftw64_11\" Variant=\"cuda\\\" />\n    <NativeAssemblyReference Include=\"cupti64_2023.1.1\" Variant=\"cuda\\\" />\n    <NativeAssemblyReference Include=\"curand64_10\" Variant=\"cuda\\\" />\n    <NativeAssemblyReference Include=\"cusolver64_11\" Variant=\"cuda\\\" />\n    <NativeAssemblyReference Include=\"cusolverMg64_11\" Variant=\"cuda\\\" />\n    <NativeAssemblyReference Include=\"cusparse64_12\" Variant=\"cuda\\\" />\n    <NativeAssemblyReference Include=\"fbgemm\" Variant=\"cuda\\\" />\n    <NativeAssemblyReference Include=\"libiomp5md\" Variant=\"cuda\\\" />\n    <NativeAssemblyReference Include=\"libiompstubs5md\" Variant=\"cuda\\\" />\n    <NativeAssemblyReference Include=\"nvJitLink_120_0\" Variant=\"cuda\\\" />\n    <NativeAssemblyReference Include=\"nvToolsExt64_1\" Variant=\"cuda\\\" />\n    <NativeAssemblyReference Include=\"nvrtc-builtins64_121\" Variant=\"cuda\\\" />\n    <NativeAssemblyReference Include=\"nvrtc64_120_0\" Variant=\"cuda\\\" />\n    <NativeAssemblyReference Include=\"torch\" Variant=\"cuda\\\" />\n    <NativeAssemblyReference Include=\"torch_cpu\" Variant=\"cuda\\\" />\n    <NativeAssemblyReference Include=\"torch_cuda\" Variant=\"cuda\\\" />\n    <NativeAssemblyReference Include=\"torch_global_deps\" Variant=\"cuda\\\" />\n    <NativeAssemblyReference Include=\"uv\" Variant=\"cuda\\\" />\n    <NativeAssemblyReference Include=\"zlibwapi\" Variant=\"cuda\\\" />\n  </ItemGroup>\n\n\t<!-- Mac arm64 libtorch binary list used for examples and testing -->\n  <ItemGroup Condition=\"'$(NativeTargetArchitecture)' == 'arm64'and $([MSBuild]::IsOSPlatform('osx')) and '$(TestUsesLibTorch)' == 'true'  and '$(SkipNative)' != 'true' \">\n    <NativeAssemblyReference Include=\"c10\" />\n    <NativeAssemblyReference Include=\"omp\" />\n    <NativeAssemblyReference Include=\"shm\" />\n    <NativeAssemblyReference Include=\"torch\" />\n    <NativeAssemblyReference Include=\"torch_cpu\" />\n    <NativeAssemblyReference Include=\"torch_global_deps\" />\n    <NativeAssemblyReference Include=\"torch_python\" />\n  </ItemGroup>\n\n  <!-- Linux CPU libtorch binary list used for examples and testing -->\n  <ItemGroup Condition=\"'$(NativeTargetArchitecture)' == 'x64' and $([MSBuild]::IsOSPlatform('linux')) and '$(TestUsesLibTorch)' == 'true'  and '$(SkipNative)' != 'true' \">\n    <NativeAssemblyReference Include=\"aoti_custom_ops\" />\n    <NativeAssemblyReference Include=\"backend_with_compiler\" />\n    <NativeAssemblyReference Include=\"c10\" />\n    <NativeAssemblyReference Include=\"jitbackend_test\" />\n    <NativeAssemblyReference Include=\"nnapi_backend\" />\n    <NativeAssemblyReference Include=\"shm\" />\n    <NativeAssemblyReference Include=\"torch\" />\n    <NativeAssemblyReference Include=\"torch_cpu\" />\n    <NativeAssemblyReference Include=\"torch_global_deps\" />\n    <NativeAssemblyReference Include=\"torch_python\" />\n    <NativeAssemblyReference Include=\"torchbind_test\" />\n    <NativeAssemblyReference Include=\"gomp-98b21ff3\" ExtraExtension=\".1\" />\n  </ItemGroup>\n\n  <Target Name=\"CopyNativeAssemblies\"\n          BeforeTargets=\"PrepareForRun\"\n\t\t\t\t\tCondition=\"'$(SkipTests)' != 'true'\">\n\n    <PropertyGroup>\n      <NativeLibPrefix Condition=\"'$(TargetOS)' == 'linux' OR '$(TargetOS)' == 'mac'\">lib</NativeLibPrefix>\n      <NativeLibExtension Condition=\"'$(TargetOS)' == 'windows'\">.dll</NativeLibExtension>\n      <NativeLibExtension Condition=\"'$(TargetOS)' == 'linux'\">.so</NativeLibExtension>\n      <NativeLibExtension Condition=\"'$(TargetOS)' == 'mac'\">.dylib</NativeLibExtension>\n    </PropertyGroup>\n\n    <ItemGroup>\n      <NativeAssemblyReference>\n        <FullAssemblyPath>$(NativeOutputPath)%(NativeAssemblyReference.Variant)$(NativeLibPrefix)%(NativeAssemblyReference.Identity)$(NativeLibExtension)%(NativeAssemblyReference.ExtraExtension)</FullAssemblyPath>\n      </NativeAssemblyReference>\n    </ItemGroup>\n\n    <Copy SourceFiles = \"@(NativeAssemblyReference->'%(FullAssemblyPath)')\"\n          DestinationFolder=\"$(OutputPath)\"\n          OverwriteReadOnlyFiles=\"$(OverwriteReadOnlyFiles)\"\n          Retries=\"$(CopyRetryCount)\"\n          SkipUnchangedFiles=\"true\"\n          RetryDelayMilliseconds=\"$(CopyRetryDelayMilliseconds)\"\n          UseHardlinksIfPossible=\"$(CreateHardLinksForPublishFilesIfPossible)\"\n          UseSymboliclinksIfPossible=\"$(CreateSymbolicLinksForPublishFilesIfPossible)\">\n      <Output TaskParameter=\"DestinationFiles\" ItemName=\"FileWrites\"/>\n    </Copy>\n\n  </Target>\n  \n</Project>"
        },
        {
          "name": "LICENSE.txt",
          "type": "blob",
          "size": 1.078125,
          "content": "MIT License\n\nCopyright (c) .NET Foundation and Contributors\nAll Rights Reserved\n\nPermission is hereby granted, free of charge, to any person obtaining a copy\nof this software and associated documentation files (the \"Software\"), to deal\nin the Software without restriction, including without limitation the rights\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\ncopies of the Software, and to permit persons to whom the Software is\nfurnished to do so, subject to the following conditions:\n\nThe above copyright notice and this permission notice shall be included in all\ncopies or substantial portions of the Software.\n\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\nSOFTWARE.\n"
        },
        {
          "name": "README.md",
          "type": "blob",
          "size": 7.8544921875,
          "content": "[![Gitter](https://badges.gitter.im/dotnet/TorchSharp.svg)](https://gitter.im/dotnet/TorchSharp?utm_source=badge&utm_medium=badge&utm_campaign=pr-badge)\n<br/>\n[![Build Status](https://dotnet.visualstudio.com/TorchSharp/_apis/build/status/dotnet.TorchSharp?branchName=main)](https://dotnet.visualstudio.com/TorchSharp/_build/latest?definitionId=174&branchName=main)\n<br/>\n[![TorchSharp](https://img.shields.io/nuget/vpre/TorchSharp.svg?cacheSeconds=3600&label=TorchSharp%20nuget)](https://www.nuget.org/packages/TorchSharp)<br/>\n[![TorchAudio](https://img.shields.io/nuget/vpre/TorchAudio.svg?cacheSeconds=3600&label=TorchAudio%20nuget)](https://www.nuget.org/packages/TorchAudio)<br/>\n[![TorchVision](https://img.shields.io/nuget/vpre/TorchVision.svg?cacheSeconds=3600&label=TorchVision%20nuget)](https://www.nuget.org/packages/TorchVision)<br/>\n[![TorchSharp-cpu](https://img.shields.io/nuget/vpre/TorchSharp-cpu.svg?cacheSeconds=3600&label=TorchSharp-cpu%20nuget)](https://www.nuget.org/packages/TorchSharp-cpu)\n[![TorchSharp-cuda-windows](https://img.shields.io/nuget/vpre/TorchSharp-cuda-windows.svg?cacheSeconds=3600&label=TorchSharp-cuda-windows%20nuget)](https://www.nuget.org/packages/TorchSharp-cuda-windows)\n[![TorchSharp-cuda-linux](https://img.shields.io/nuget/vpre/TorchSharp-cuda-linux.svg?cacheSeconds=3600&label=TorchSharp-cuda-linux%20nuget)](https://www.nuget.org/packages/TorchSharp-cuda-linux)<br/>\n<br/>\nPlease check the [Release Notes](RELEASENOTES.md) file for news on what's been updated in each new release.\n\n\n__TorchSharp no longer supports MacOS on Intel hardware.__\n\nWith libtorch release 2.4.0, Intel HW support was deprecated for libtorch. This means that the last version of TorchSharp to work on Intel Macintosh hardware is 0.102.8. Starting with 0.103.0, only Macs based on Apple Silicon are supported.\n\n__TorchSharp examples has their own home!__\n\nHead over to the [TorchSharp Examples Repo](https://github.com/dotnet/TorchSharpExamples) for convenient access to existing and upcoming examples.\n\n__IMPORTANT NOTES:__\n\nWhen targeting __.NET FX__ on Windows, the project configuration must be set to 'x64' rather than 'Any CPU' for anything that depends on TorchSharp.\n\nAs we build up to a v1.0 release, we will continue to make breaking changes, but only when we consider it necessary for usability. Similarity to the PyTorch experience is a primary design tenet, and we will continue on that path.\n\n# TorchSharp\n\nTorchSharp is a .NET library that provides access to the library that powers PyTorch. It is part of the .NET Foundation.\n\nThe focus is to bind the API surfaced by LibTorch with a particular focus on tensors. The design intent is to stay as close as possible to the Pytorch experience, while still taking advantage of the benefits of the .NET static type system where it makes sense. For example: method overloading is relied on when Pytorch defines multiple valid types for a particular parameter.\n\nThe technology is a \"wrapper library\": no more, no less. [DiffSharp](https://github.com/DiffSharp/DiffSharp/) uses this\nrepository extensively and has been a major factor in iterating support.\n\nThings that you can try:\n\n```csharp\nusing TorchSharp;\nusing static TorchSharp.torch.nn;\n\nvar lin1 = Linear(1000, 100);\nvar lin2 = Linear(100, 10);\nvar seq = Sequential((\"lin1\", lin1), (\"relu1\", ReLU()), (\"drop1\", Dropout(0.1)), (\"lin2\", lin2));\n\nusing var x = torch.randn(64, 1000);\nusing var y = torch.randn(64, 10);\n\nvar optimizer = torch.optim.Adam(seq.parameters());\n\nfor (int i = 0; i < 10; i++) {\n    using var eval = seq.forward(x);\n    using var output = functional.mse_loss(eval, y, Reduction.Sum);\n\n    optimizer.zero_grad();\n\n    output.backward();\n\n    optimizer.step();\n}\n```\n\n## A Few Things to Know\n\nWhile the intent has been to stay close to the Pytorch experience, there are some peculiarities to take note of:\n\n1. We have disregarded .NET naming conventions in favor of Python where it impacts the experience. We know this will feel wrong to some, but after a lot of deliberation, we decided to follow the lead of the SciSharp community and embrace naming similarity with Python over .NET tradition. We believe this will make it easier to take Python-based examples and snippets and apply them in .NET.\n\n2. In order to make a constructor call look more the Pytorch code, each class has a factory method with the same name. Because we cannot have a method and a class with the same name in a scope, we moved the class declarations to a nested scope 'Modules.'\n\n    For example:\n\n    ```csharp\n\n    Module conv1 = Conv1d(...);\n\n    ```\n    creates an instance of `Modules.Conv1d`, which has 'torch.Module' as its base class.\n\n3. C# uses ':' when passing a named parameter, while F# and Python uses '=', and Pytorch functions have enough parameters to encourage passing them by name. This means that you cannot simply copy a lot of code into C#.\n\n4. There are a number of APIs where Pytorch encodes what are effectively enum types as strings. We have chosen to use proper .NET enumeration types in most cases.\n\n5. The type `torch.device` is `torch.Device` in TorchSharp. We felt that using all-lowercase for a class type was one step too far. The device object constructors, which is what you use most of the time, are still called `device()`\n\n\n# Memory management\n\nSee [docfx/articles/memory.md](docfx/articles/memory.md).\n\n# Download\n\nTorchSharp is distributed via the NuGet gallery: [https://www.nuget.org/packages/TorchSharp/](https://www.nuget.org/packages/TorchSharp/)\n\nWe recommend using one of the 'bundled' packages, which will pull in both TorchSharp and the right backends:\n\n- [TorchSharp-cpu](https://www.nuget.org/packages/TorchSharp-cpu) (CPU, Linux/Windows/OSX)\n- [TorchSharp-cuda-windows](https://www.nuget.org/packages/TorchSharp-cuda-windows) (CPU/CUDA 12.1, Windows)\n- [TorchSharp-cuda-linux](https://www.nuget.org/packages/TorchSharp-cuda-linux) (CPU/CUDA 12.1, Linux)\n\nOtherwise, you also need one of the LibTorch backend packages: https://www.nuget.org/packages?q=libtorch, specifically one of\n\n* `libtorch-cpu-linux-x64` (CPU, Linux)\n\n* `libtorch-cpu-win-x64` (CPU, Windows)\n\n* `libtorch-cpu-osx-arm64` (CPU, OSX)\n\n* `libtorch-cpu` (CPU, references all three, larger download but simpler)\n\n* `libtorch-cuda-12.1-linux-x64` (CPU/CUDA 12.1, Linux)\n\n  > NOTE: Due to the presence of very large native binaries, using the `libtorch-cuda-12.1-linux-x64` package requires\n  > .NET 6, e.g. .NET SDK version `6.0.100-preview.5.21302.13` or greater.\n\n* `libtorch-cuda-12.1-win-x64` (CPU/CUDA 12.1, Windows)\n\nAlternatively you can access the LibTorch native binaries via direct reference to existing local native\nbinaries of LibTorch installed through other means (for example, by installing [PyTorch](https://pytorch.org/) using a Python package manager). You will have to add an explicit load of the relevant native library, for example:\n\n```csharp\n    using System.Runtime.InteropServices;\n    NativeLibrary.Load(\"/home/gunes/anaconda3/lib/python3.8/site-packages/torch/lib/libtorch.so\")\n```\n\n**NOTE:** Some have reported that in order to use TorchSharp on Windows, the C++ redistributable needs to be installed. This will be the case where VS is installed, but it maybe necessary to install this version of the C++ redist on machines where TorchSharp is deployed:\n\n```\nMicrosoft Visual C++ 2015-2022 ( 14.36.32532 )\n```\n\n# Code of Conduct\nThis project has adopted the code of conduct defined by the Contributor Covenant to clarify expected behavior in our community.\nFor more information see the [.NET Foundation Code of Conduct](https://dotnetfoundation.org/code-of-conduct).\n\n# Developing and Contributing\n\nSee [DEVGUIDE.md](DEVGUIDE.md) and [CONTRIBUTING.md](CONTRIBUTING.md).\n\n<a href=\"https://github.com/dotnet/TorchSharp/graphs/contributors\">\n  <img src=\"https://contrib.rocks/image?repo=dotnet/TorchSharp\" />\n</a>\n\n# Uses\n\n[DiffSharp](https://github.com/DiffSharp/DiffSharp/) also uses this\nrepository extensively and has been a major factor in iterating support.\n"
        },
        {
          "name": "RELEASENOTES.md",
          "type": "blob",
          "size": 41.185546875,
          "content": "## TorchSharp Release Notes\n\nReleases, starting with 9/2/2021, are listed with the most recent release at the top.\n\n# NuGet Version 0.105.0\n\nMove to libtorch 2.5.1. As with the 2.4.0 release, MacOS / Intel is no longer supported by libtorch, so TorchSharp doesn, either.\n\n# NuGet Version 0.104.0\n\nThis is a big change in implementation, but not as big in API surface area. Many of the builtin modules, but not all, were re-implemented in managed code calling into native code via the functional APIs. This has several advantages:\n\n1. Align with the Pytorch implementations.<br/>\n2. More easily expose module attributes as properties as Pytorch does.<br/>\n3. In some cases, avoid native code altogether.<br/>\n4. The builtin modules can serve as \"best practice\" examples for custom module authors.<br/>\n\n__Breaking Changes__:\n\nThe names of several arguments have been changed to align better with Pytorch naming. This may break code that passes such arguments by name, but will be caught at compile time.<br/>\nThe argument defaults for `torch.diagonal()` and `Tensor.diagonal()` arguments have been corrected.<br/>\nThe default `newLine` for `str`, `jlstr`, `npstr`, `cstr` and `print` have been corrected.<br/>\n\n__Issues fixed__:\n\n#1397 Look into whether parameter creation from a tensor leads to incorrect dispose scope statistics. This bug was discovered during testing of the PR.<br/>\n#1210 Attribute omissions.<br/>\n#1400 There may be an error in torchvision.transforms.GaussianBlur<br/>\n#1402 diagonal() has incorrect default<br/>\n\n__API Changes__:\n\n #1382: Add support for torch.nn.functional.normalize<br/>\n\n# NuGet Version 0.103.1\n\n__Breaking Changes__:\n#1376 `torch.Tensor.backward`'s function signature has been updated to match PyTorch's implementation. Previously, passing `create_graph` or `retain_graph` by position would work like PyTorch's `torch.Tensor.backward`, but not if passing by name (`create_graph`'s value was swapped with `retain_graph`). This has been corrected; however, this means any code that passes `create_graph` or `retain_graph` by name needs to be updated to reflect the intended functionality.<br/>\n\n__Bug Fixes__:\n\n#1383 `torch.linalg.vector_norm`: Make `ord`-argument optional, as specified in docs<br/>\n#1385 PackedSequence now participates in the DisposeScope system at the same level as Tensor objects.<br/>\n#1387 Attaching tensor to a DisposeScope no longer makes Statistics.DetachedFromScopeCount go negative.<br/>\n#1390 DisposeScopeManager.Statistics now includes DisposedOutsideScopeCount and AttachedToScopeCount. ThreadTotalLiveCount is now exact instead of approximate. ToString gives a useful debug string, and documentation is added for how to troubleshoot memory leaks. Also DisposeScopeManager.Statistics.TensorStatistics and DisposeScopeManager.Statistics.PackedSequenceStatistics provide separate metrics for these objects.<br/>\n#1392 ToTensor() extension method memory leaks fixed.<br/>\n#1414 tensor.print() - Missing default \"newLine\" Parameter<br/>\n\n# NuGet Version 0.103.0\n\nMove to libtorch 2.4.0.\n\n# NuGet Version 0.102.8\n\n__Bug Fixes__:\n\n#1359 torch.nn.functional.l1_loss computes a criterion with the MSE, not the MAE.<br/>\n\n# NuGet Version 0.102.6\n\n__Breaking Changes__:\n\nWhen creating a tensor from a 1-D array, and passing in a shape, there is now an ambiguity between the IList and Memory overloads of `torch.tensor()`. The ambiguity is resolved by removing the `dimensions` argument if it is redundant, or by an explicit cast to IList if it is not.\n\n__API Changes__:\n\n #1326 Allow arrays used to create tensors to be larger than the tensor. Create tensors from a Memory instance.<br/>\n\n__Bug Fixes__:\n\n#1334 MultivariateNormal.log_prob() exception in TorchSharp but works in pytorch.<br/>\n\n# NuGet Version 0.102.5\n\n__Breaking Changes__:\n\n`torchvision.dataset.MNIST` will try more mirrors. The thrown exception might be changed when it fails to download `MNIST`, `FashionMNIST` or `KMNIST`.<br/>\n`ObjectDisposedException` will now be thrown when trying to use a disposed dispose scopes.<br/>\nThe constructor of dispose scopes is no longer `public`. Use `torch.NewDisposeScope` instead.<br/>\n\n__API Changes__:\n\n#1317 How to set default device type in torchsharp.<br/>\n#1314 Grant read-only access to DataLoader attributes<br/>\n#1313 Add 'non_blocking' argument to tensor and module 'to()' signatures.<br/>\n#1291 `Tensor.grad()` and `Tensor.set_grad()` have been replaced by a new property `Tensor.grad`.<br/>\nA potential memory leak caused by `set_grad` has been resolved.<br/>\n`Include` method of dispose scopes has been removed. Use `Attach` instead.<br/>\nTwo more `Attach` methods that accepts `IEnumerable<IDisposable>`s and arrays as the parameter have been added into dispose scopes.<br/>\nA new property `torch.CurrentDisposeScope` has been added to provide the ability to get the current dispose scope.<br/>\nAdd module hooks that take no input/output arguments, just the module itself.<br/>\n\n__Bug Fixes__:\n\n#1300 `Adadelta`, `Adam` and `AdamW` will no longer throw `NullReferenceException` when `maximize` is `true` and `grad` is `null`.<br/>\ntorch.normal` will now correctly return a leaf tensor.<br/>\nNew options `disposeBatch` and `disposeDataset` have been added into `DataLoader`.<br/>\nThe default collate functions will now always dispose the intermediate tensors, rather than wait for the next iteration.<br/>\n\n__Bug Fixes__:\n\n`TensorDataset` will now keep the aliases detached from dispose scopes, to avoid the unexpected disposal.<br/>\n`DataLoaderEnumerator` has been completely rewritten to resolve the unexpected shuffler disposal, the ignorance of `drop_last`, the incorrect count of worker, and the potential leak cause by multithreading.<br/>\n#1303 Allow dispose scopes to be disposed out of LIFO order.<br/>\n\n# NuGet Version 0.102.4\n\n__Breaking Changes__:\n\nCorrect `torch.finfo`. (`torch.set_default_dtype`, `Categorical.entropy`, `_CorrCholesky.check`, `Distribution.ClampProbs`, `FisherSnedecor.rsample`, `Gamma.rsample`, `Geometric.rsample`, `distributions.Gumbel`, `Laplace.rsample`, `SigmoidTransform._call` and `SigmoidTransform._inverse` are influenced.)<br/>\n\n__API Changes__:\n\n#1284 make `torch.unique` and `torch.unique_consecutive` public.<br/>\n\n# NuGet Version 0.102.3\n\n__Breaking Changes__:\n\nThe 'paddingMode' parameter of convolution has been changed to 'padding_mode', and the 'outputPadding' is now 'output_padding'.\n\n__API Changes__:\n\n#1243 `fuse_conv_bn_weights` and `fuse_linear_bn_weights` are added.<br/>\n#1274 ConvTranspose3d does not accept non-uniform kernelSize/stride values<br/>\n\n\n# NuGet Version 0.102.2\n\n__Bug Fixes__:\n\n#1257 InverseMelScale in NewDisposeScope doesn't dispose tensors<br/>\n\n# NuGet Version 0.102.1\n\n__Breaking Changes__:\n\nThe `kernelSize` parameter in the function and class of `AvgPool1D` was renamed to `kernel_size` to match PyTorch naming.\nThe `stride` parameter in the `torch.nn.functional.avg_pool1d` call now defaults to `kernelSize` instead of 1, to match the PyTorch behavior.\n\n\n__Bug Fixes__:\n\n`module.load_state_dict()` throws error for in-place operation on a leaf variable that requires grad. <br/>\n#1250 cstr and npstr for 0d tensors <br/>\n#1249 torch.nn.functional.avg_pool1d is not working correctly<br/>\n`module.load()` with streams which don't read the requested # of bytes throws error. <br/>\n #1246 Issue running in notebook on Apple Silicon<br/>\n\n## NuGet Version 0.102.0\n\nThis release upgrades the libtorch backend to v2.2.1.\n\n__Breaking Changes__:\n\nThe Ubuntu builds are now done on a 22.04 version of the OS. This may (or may not) affect TorchSharp use on earlier versions.<br/>\nThe default value for the `end_factor` argument in the constructor for `LinearLR` was changed to 1.0 to match PyTorch.<br/>\nAny code that checks whether a device is 'CUDA' and does something rather than checking that it isn't 'CPU' will now fail to work, since there is now support for the 'MPS' device on MacOS.<br/>\n\n__API Changes__:\n\n#652: Apple Silicon support .<br/>\n#1219: Added support for loading and saving tensors that are >2GB.<br/>\n\n__Bug Fixes__:\n\nFixed LinearLR scheduler calculation with misplaced parentheses<br/>\nAdded `get_closed_form_lr` to scheduler to match PyTorch behavior when specifying epoch in `.step()`<br/>\n\n## NuGet Version 0.101.6\n\n__API Changes__:\n\n#1223: Missing prod function torch.prod or a.prod() where a is Tensor<br/>\n#1201: How to access the attributes of a model?<br/>\n#1094: ScriptModule from Stream / ByteArray<br/>\n#1149: Implementation for `torch.autograd.functional.jacobian` to compute Jacobian of a function<br/>\nImplemenation for a custom `torch.autograd.Function` class<br/>\n\n__Bug Fixes__:\n\n#1198: CUDA not available when calling backwards before using CUDA<br/>\n#1200: Bugs in torch.nn.AvgPool2d and torch.nn.AvgPool3d methods.<br/>\n\n## NuGet Version 0.101.5\n\n__Bug Fixes__:\n\n#1191 : Having trouble moving a module from one GPU to another with gradients.<br/>\n\n\n## NuGet Version 0.101.4\n\nA fast-follow release addressing a regression in v0.101.3\n\n__Bug Fixes__:\n\n#1185 : Incomplete transfer of module to device (only with 0.101.3)<br/>\n\n## NuGet Version 0.101.3\n\n__Breaking Changes__:\n\nThe base `OptimizerState` class was modified and includes two changes:\n\n1. Custom optimizer state objects derived from `OptimizerState` must now explicitly pass the related `torch.nn.Parameter` object to the `OptimizerState` base constructor to maintain correct linkage.\n2. Custom state objects must implement an Initialize function. This function is responsible for initializing the properties of the state. Note that this function can be called as a re-intialization, so proper disposal of the previous tensor objects should be handled.\n\n__API Changes__:\n\nIntroduced `InferenceMode`, a block-based scoping class for optimizing TorchSharp model inference by disabling gradient computation and enhancing performance.<br/>\nAdded `Tensor.to_type()` conversion aliases for short, half, bfloat16, cfloat, and cdouble.<br/>\nAdded `Module.to()` conversion aliases for all the scalar types.<br/>\nAll distribution classes now implement IDisposable.<br/>\n\n__Bug Fixes__:\n\n#1154 : `mu_product` was not initialized in `NAdam` optimizer<br/>\n#1170 : Calling `torch.nn.rnn.utils.pad_packed_sequence` with a CUDA tensor and unsorted_indices threw an error<br/>\n#1172 : `optim.LoadStateDict` from an existing `StateDictionary` updated to make sure to copy value and to the right device.<br/>\n#1176 : When specific `Optimizers` load in a conditional tensor, made sure to copy to the right device.<br/>\n#1174 : Loading CUDA tensor from stream threw an error<br/>\n#1179 : Calling `Module.to()` with the `ParameterList` and `ParameterDict` module didn't move the parameters stored in the field.<br/>\n#1148 : Calling `Module.to()` shouldn't be differentiable<br/>\n#1126 : Calling `ScriptModule.to()` doesn't move attributes<br/>\n#1180 : Module.to(ScalarType) has restrictions in PyTorch which aren't restricted in TorchSharp.<br/>\n\n## NuGet Version 0.101.2\n\n__API Changes__:\n\nAdded extension method `ScalarType.ElementSize()` to get the size of each element of a given ScalarType.<br/>\nAdded methods for loading and saving individual tensors with more overloads.<br/>\nAdded 'persistent' flag to register_buffer()<br/>\n\n__Bug Fixes__:\n\nFixed byte stream advancement issue in non-strict mode, ensuring proper skipping of non-existent parameters while loading models.<br/>\n\n## NuGet Version 0.101.1\n\nThis is a fast-follower bug fix release, addressing persistent issues with stability of using TorchScript from TorchSharp.\n\n__Bug Fixes__:\n\n#1047 Torchscript execution failures (hangs, access violation, Fatal error. Internal CLR fatal error. (0x80131506) )<br/>\n\n## NuGet Version 0.101.0\n\nThis is an upgrade to libtorch 2.1.0. It also moves the underlying CUDA support to 12.1 from 11.7, which means that all the libtorch-cuda-* packages have been renamed. Please update your CUDA driver to one that support CUDA 12.1.\n\n__API Changes__:\n\nEnhanced `Module.load` function to return matching status of parameters in non-strict mode via an output dictionary.<br/>\nIntroduced attribute-based parameter naming for module state dictionaries, allowing custom names to override default field names.<br/>\n\n## NuGet Version 0.100.7\n\n__Breaking Changes__:\n\nDataLoader should no longer be created using `new` -- instead, the overall pattern is followed, placing the classes in `TorchSharp.Modules` and the factories in the static class. This will break any code that creates a DataLoader, but can be fixed by:\n\n1. Removing the `new` in `new torch.utils.data.DataLoader(...)`<br/>\n2. Adding a `using TorchSharp.Modules` (C#) or `open TorchSharp.Modules` (F#) to files where `DataLoader` is used as a type name.<br/>\n\n__API Changes__:\n\nAdding an `IterableDataset` abstract class, and making `TensorDataset` derive from it.<br/>\nMoving the `DataLoader` class to `TorchSharp.Modules` and adding DataLoader factories.<br/>\n#1092: got error when using DataLoader <br/>\n#1069: Implementation of torch.sparse_coo_tensor for sparse tensor creation<br/>\nRenamed `torch.nn.functional.SiLU` -> `torch.nn.functional.silu`<br/>\nAdded a set of generic `Sequential` classes.<br/>\n\n__Bug Fixes__:\n\n#1083: Compiler rejects scalar operand due to ambiguous implicit conversion<br/>\n\n## NuGet Version 0.100.6\n\n__Bug Fixes__:\n\nScriptModule: adding `forward` and the ability to hook.<br/>\nUpdate to SkiaSharp 2.88.6 to avoid the libwebp vulnerability.<br/>\n#1105: Dataset files get written to the wrong directory<br/>\n#1116: Gradient null for simple calculation<br/>\n\n## NuGet Version 0.100.5\n\n__Breaking Changes__:\n\nInplace operators no longer create an alias, but instead return 'this'. This change will impact any code that explicitly calls `Dispose` on a tensor after the operation.\n\n__Bug Fixes__:\n\n#1041 Running example code got error in Windows 10<br/>\n#1064 Inplace operators create an alias<br/>\n#1084 Module.zero_grad() does not work<br/>\n#1089 max_pool2d overload creates tensor with incorrect shape<br/>\n\n## NuGet Version 0.100.4\n\n__Breaking Changes__:\n\nThe constructor for TensorAccessor is now `internal`, which means that the only way to create one is to use the `data<T>()` method on Tensor. This was always the intent.\n\n__API Changes__:\n\nTensor.randperm_out() deprecated.<br/>\ntorch.randperm accepts 'out' argument<br/>\nAdding PReLU module.<br/>\nAdding scaled_dot_product_attention.<br/>\nThe constructor for TensorAccessor was made `internal`<br/>\ntorchvision.utils.save_image implemented<br/>\ntorchvision.utils.make_grid implemented<br/>\ntorchvision.transforms.RandAugment implemented<br/>\n\n__Bug Fixes__:\n\nFixed torch.cuda.synchronize() method<br/>\nSuppress runtime warning by setting align_corners to 'false'<br/>\nFixed argument validation bug in Grayscale<br/>\n#1056: Access violation with TensorAccessor.ToArray - incompatible data types<br/>\n#1057: Memory leak with requires_grad<br/>\n\n## NuGet Version 0.100.3\n\nThis release is primarily, but not exclusively, focused on fixing bugs in distributions and adding a few new ones.\n\n__Breaking Changes__:\n\nThe two main arguments to `torch.linalg.solve()` and `torch.linalg.solve_ex()` were renamed 'A' and 'B' to align with PyTorch.\n\n__API Changes__:\n\nAdding torch.linalg.solve_triangular()<br/>\nAdding torch.distributions.MultivariateNormal<br/>\nAdding torch.distributions.NegativeBinomial<br/>\nAdding in-place versions of `Tensor.triu()` and `Tensor.tril()`<br/>\nAdding torch.linalg.logsigmoid() and torch.nn.LogSigmoid<br/>\nA number of distributions were missing the `mode` property.<br/>\nAdding a C#-like string formatting style for tensors.<br/>\n\n__Bug Fixes__:\n\nTorchVision `rotate()`, `solarize()` and `invert()` were incorrectly implemented.<br/>\nFixed bug in Bernoulli's `entropy()` and `log_prob()` implementations.<br/>\nFixed bug in Cauchy's `log_prob()` implementation.<br/>\nFixed several bugs in HalfCauchy and HalfNormal.<br/>\nThe Numpy-style string formatting of tensors was missing commas between elements<br/>\n\n## NuGet Version 0.100.2\n\n__API Changes__:\n\nAdd torchvision.datasets.CelebA()<br/>\nAdd support for properly formatting Tensors in Polyglot notebooks without the 'Register' call that was necessary before.<br/>\n\n__Bug Fixes__:\n\n#1014 AdamW.State.to() ignores returns<br/>\n#999 Error in Torchsharp model inference in version 0.100.0<br/>\n\n## NuGet Version 0.100.1\n\n__Breaking Changes__:\n\nTorchSharp no longer supports any .NET Core versions prior to 6.0. .NET FX version support is still the same: 4.7.2 and up.\n\n__API Changes__:\n\nAdded operator functionality to Torchvision, but roi are still missing.<br/>\nAdded support for additional types related to TorchScript modules. Scripts can now return lists of lists and tuples of lists and tuples, to an arbitrary level of nesting.\nScripts can now accept lists of Tensors.\n\n__Bug Fixes__:\n\n#1001 Issue with resnet50, resnet101, and resnet152<br/>\n\n## NuGet Version 0.100.0\n\nUpdated backend binaries to libtorch v2.0.1.\n\nUpdated the NuGet metadata to use a license expression rather than a reference to a license file. This will help with automated license checking by users.\n\n__Breaking Changes__:\n\nWith v2.0.1, `torch.istft()` expects complex numbers in the input tensor.\n\n__API Changes__:\n\n#989 Adding anomaly detection APIs to `torch.autograd`<br/>\n\n__Fixed Bugs__:\n\n\n## NuGet Version 0.99.6\n\n__Breaking Changes__:\n\nThere was a second version of `torch.squeeze()` with incorrect default arguments. It has now been removed.\n\n__API Changes__:\n\nRemoved incorrect `torch.squeeze()` method.<br/>\nAdding two-tensor versions of `min()` and `max()`<br/>\n\n__Fixed Bugs__:\n\n#984 Conversion from System.Index to TensorIndex is missing<br/>\n#987 Different versions of System.Memory between build and package creation.<br/>\n\n## NuGet Version 0.99.5\n\n__API Changes__:\n\nAdded Tensorboard support for histograms, images, video, and text.\n\n## NuGet Version 0.99.4\n\n__Breaking Changes__:\n\nThere were some changes to the binary format storing optimizer state. This means that any such state generated before updating to this version is invalid and will likely result in a runtime error.\n\n__API Changes__:\n\nAdding torch.tensordot<br/>\nAdding torch.nn.Fold and Unfold modules.<br/>\nAdding `Module.call()` to all the Module<T...> classes. This wraps `Module.forward()` and allows hooks to be registered. `Module.forward()` is still available, but the most general way to invoke a module's logic is through `call()`.<br/>\nAdding tuple overloads for all the padding-related modules.<br/>\nAdding support for exporting optimizer state from PyTorch and loading it in TorchSharp<br/>\n\n__Fixed Bugs__:\n\n#842 How to use register_forward_hook?<br/>\n#940 Missing torch.searchsorted<br/>\n#942 nn.ReplicationPad1d(long[] padding) missing<br/>\n#943 LRScheduler.get_last_lr missing<br/>\n#951 DataLoader constructor missing drop_last parameter<br/>\n#953 TensorDataset is missing<br/>\n#962 Seed passed to torch.random.manual_seed(seed) is unused<br/>\n#949 Passing optimizer state dictionary from PyTorch to TorchSharp<br/>\n#971 std results are inconsistent<br/>\n\n## NuGet Version 0.99.3\n\n__API Changes__:\n\nFixing misspelling of 'DetachFromDisposeScope,' deprecating the old spelling.<br/>\nAdding allow_tf32<br/>\nAdding overloads of Module.save() and Module.load() taking a 'Stream' argument.<br/>\nAdding torch.softmax() and Tensor.softmax() as aliases for torch.special.softmax()<br/>\nAdding torch.from_file()<br/>\nAdding a number of missing pointwise Tensor operations.<br/>\nAdding select_scatter, diagonal_scatter, and slice_scatter<br/>\nAdding torch.set_printoptions<br/>\nAdding torch.cartesian_prod, combinations, and cov.<br/>\nAdding torch.cdist, diag_embed, rot90, triu_indices, tril_indices<br/>\n\n__Fixed Bugs__:\n\n#913 conv = nn.Conv2d(c1, 1, 1, bias=False).requires_grad_(False)<br/>\n#910 nn.Module.modules is missing<br/>\n#912 nn.Module save and state_ dict method error<br/>\n\n## NuGet Version 0.99.2\n\n__API Changes__:\n\nAdding 'maximize' argument to the Adadelta optimizer<br/>\nAdding linalg.ldl_factor and linalg.ldl_solve<br/>\nAdding a couple of missing APIs (see #872)<br/>\nAdding SoftplusTransform<br/>\nSupport indexing and slicing of Sequential<br/>\nAdding ToNDArray() to TensorAccessor<br/>\n\n__Fixed Bugs__:\n\n#870 nn.AvgPool2d(kernel_size=3, stride=2, padding=1) torchsharp not support padding<br/>\n#872 Tensor.masked_fill_(mask, value) missing<br/>\n#877 duplicate module parameters called named_parameters() while load model by cuda<br/>\n#888 THSTensor_meshgrid throws exception<br/>\n\n## NuGet Version 0.99.1\n\n__Breaking Changes__:\n\nThe options to the ASGD, Rprop, and RMSprop optimizers have been changed to add a 'maximize' flag. This means that saved state dictionaries for these optimizers will not carry over.\n\nThe return type of Sequential.append() has changed from 'void' to 'Sequential.' This breaks binary compatibility, but not source compat.\n\n__API Changes__:\n\nAdded a number of 1.13 APIs under `torch.special`<br/>\nAdded a `maximize` flag to the ASGD, Rprop and RMSprop optimizers.<br/>\nAdded PolynomialLR scheduler<br/>\nThe return type of Sequential.append() has changed from 'void' to 'Sequential.'<br/>\nAdded 1-dimensional array overloads for `torch.as_tensor()`<br/>\n\n__Fixed Bugs__:\n\n#836 Categorical seems to be miscalculated<br/>\n#838 New Bernoulli get \"Object reference not set to an instance of an object.\"<br/>\n#845 registered buffers are being ignored in move model to device<br/>\n#851 tensor.ToString(TorchSharp.TensorStringStyle.Numpy)<br/>\n#852 The content returned by torch.nn.Sequential.append() is inconsistent with the official<br/>\n\n## NuGet Version 0.99.0\n\nThis is an upgrade to libtorch 1.13. It also moves the underlying CUDA support to 11.7 from 11.3, which means that all the libtorch-cuda-* packages have been renamed.\n\n__Breaking Changes__:\n\nSee API Changes.<br/>\n\n__API Changes__:\n\nRemoved Tensor.lstsq, paralleling PyTorch. Use torch.linalg.lstsq, instead. This is a breaking change.<br/>\nAdded 'left' Boolean argument to `torch.linalg.solve()`<br/>\n\n## NuGet Version 0.98.3\n\n__Fixed Bugs__:\n\nMultiStepLR scheduler was not computing the next LR correctly.<br/>\nFixed incorrect version in package reference.<br/>\nAdded missing package references to TorchVision manifest.<br/>\n\n## NuGet Version 0.98.2\n\n__Breaking Changes__:\n\nThe .NET 5.0 is no longer supported. Instead, .NET 6.0 is the minimum version. .NET FX 4.7.2 and higher are still supported.\n\n__API Changes__:\n\nSupport 'null' as input and output to/from TorchScript.<br/>\nAdded support for label smoothing in CrossEntropyLoss.<br/>\nAdded torchaudio.transforms.MelSpectrogram().<br/>\nAdding squeeze_()<br/>\nAdding older-style tensor factories -- IntTensor, FloatTensor, etc.<br/>\n\n__Fixed Bugs__:\n\n#783 Download progress bar missing<br/>\n#787 torch.where(condition)  tuple of LongTensor function missing<br/>\n#799 TorchSharp.csproj refers Skia<br/>\n\n__Source Code Cleanup__:\n\nMoved P/Invoke declarations into dedicated class.<br/>\nAdded C# language version to all .csproj files.<br/>\n\n## NuGet Version 0.98.1\n\n__Breaking Changes:__\n\nTorchVision and TorchAudio have beeen moved into their own NuGet packages, which need to be added to any project using their APIs.\n\nModuleList and ModuleDict are now generic types, taking the module type as the type parameter. torch.nn.ModuleDict() will return a ModuleDict<Module>, which torch.nn.ModuleDict<T>() will return a ModuleDict<T>, where T must be a Module type.\n\n__Fixed Bugs:__\n\n#568 Overloads for Named Tensors<br/>\n#765 Support invoking ScriptModule methods<br/>\n#775 torch.jit.load: support specifying a target device<br/>\n#792 Add SkiaSharp-based default imager for torchvision.io<br/>\n\n__API Changes__:\n\nGeneric ModuleDict and ModuleList<br/>\nAdded torchaudio.transforms.GriffinLim\nAdded support for named tensors\nAdded default dim argument value for 'cat'\n\n## NuGet Version 0.98.0\n\n__Breaking Changes:__\n\nSome parameter names were changed to align with PyTorch. This affects names like 'dimension,' 'probability,' and 'keepDims' and will break code that is passing these parameters by name.\n\nModule.to(), cpu(), and cuda() were moved to a static class for extension methods. This means that it is necessary to have a 'using TorchSharp;' (C#) or 'open TorchSharp' (F#) in each file using them.\n\nDoing so (rather than qualifying names with 'TorchSharp.') was already recommended as a best practice, since such a using/open directive will allows qualified names to align with the PyTorch module hierarchy.\n\n__Loss functions are now aligned with the PyTorch APIs.__ This is a major change and the reason for incrementing the minor version number. The most direct consequence is that losses are modules rather than delegates, which means you need to call .forward() to actually compute the loss. Also, the factories are in torch.nn rather than torch.nn.functional and have the same Pascal-case names as the corresponding types. The members of the torch.nn.functional static class are now proper immediate loss functions, whereas the previous ones returned a loss delegate.\n\n__Generic Module base class.__ The second major change is that Module is made type-safe with respect to the `forward()` function. Module is now an abstract base class, and interfaces `IModule<T,TResult>`, `IModule<T1,T2,TResult>`,... are introduced to define the signature of the `forward()` function. For most custom modules, this  means that the base class has to be changed to `Module<Tensor,Tensor>`, but some modules may require more significant changes.\n\nScriptModule follows this pattern, but this version introduces `ScriptModule<T...,TResult>` base classes, with corresponding `torch.jit.load<T...,TResult>()` static factory methods.\n\n__Fixed Bugs:__\n\n#323 forward() should take a variable-length list of arguments<br/>\n#558 Fix deviation from the Pytorch loss function/module APIs<br/>\n#742 Ease of use: Module.to method should be generic T -> T<br/>\n#743 Ease of use: module factories should have dtype and device<br/>\n#745 Executing a TorchScript that returns multiple values, throws an exception<br/>\n#744 Some of functions with inconsistent argument names<br/>\n#749 functional.linear is wrong<br/>\n#761 Stateful optimizers should have support for save/load from disk.<br/>\n#771 Support more types for ScriptModule<br/>\n\n__API Changes__:\n\nModule.to(), cpu(), and cuda() were redone as extension methods. The virtual methods to override, if necessary, are now named '_to'. A need to do so should be extremely rare.<br/>\nSupport for saving and restoring hyperparameters and state of optimizers<br/>\nLoss functions are now Modules rather than delegates.<br/>\nCustom modules should now use generic versions as base classes.<br/>\nScriptModule supports calling methods other than forward()<br/>\nAdded torch.jit.compile().<br/>\n\n## NuGet Version 0.97.6\n\n__Breaking Changes:__\n\nThis release changes TorchSharp.torchvision from a namespace to a static class. This will break any using directives that assumes that it is a namespace.\n\n__Fixed Bugs:__\n\n#719 ResNet maxpool<br/>\n#730 Sequential.Add<br/>\n#729 Changing torchvision namespace into a static class?<br/>\n\n__API Changes__:\n\nAdding 'append()' to torch.nn.Sequential<br/>\nAdding torch.numel() and torch.__version__<br/>\nAdding modifiable global default for tensor string formatting<br/>\n\n## NuGet Version 0.97.5\n\n__Fixed Bugs:__\n\n#715 How to implement the following code <br/>\n\n__API Changes__:\n\nAdd functional normalizations<br/>\nAdded torch.utils.tensorboard.SummaryWriter. Support for scalars only.<br/>\n\n\n## NuGet Version 0.97.3\n\n__Fixed Bugs:__\n\n#694 torch.log10() computes torch.log()<br/>\n#691 torch.autograd.backward()<br/>\n#686 torch.nn.functional.Dropout() doesn't have the training argument.<br/>\n\n__API Changes__:\n\nAdd `repeat_interleave()`<br/>\nAdd torch.broadcast_shapes()<br/>\nAdded meshgrid, mT, mH, and H<br/>\nAdded additional distributions.<br/>\nAdd dct and mu-law to torchaudio\nAdded torchvision -- sigmoid_focal_loss()<br/>\nUpdate the arguments of `dropout()` in `Tacotron2`<br/>\nAdd static function for `all()`, `any()`, `tile()`, `repeat_interleave()`.<br/>\nAdd an implementation of the ReduceLROnPlateau learning rate scheduler.<br/>\n\n## NuGet Version 0.97.2\n\n__Breaking Changes:__\n\nThis release contains a breaking change__ related to `torch.tensor()` and `torch.from_array()` which were not adhering to the semantics of the Pytorch equivalents (`torch.from_numpy()` in the case of `torch.from_array()`).\n\nWith this change, there will be a number of different APIs to create a tensor form a .NET array. The most significant difference between them is whether the underlying storage is shared, or whether a copy is made. Depending on the size of the input array, copying can take orders of magnitude more time in creation than sharing storage, which is done in constant time (a few s).\n\nThe resulting tensors may be reshaped, but not resized.\n\n```C#\n// Never copy:\npublic static Tensor from_array(Array input)\n\n// Copy only if dtype or device arguments require it:\npublic static Tensor frombuffer(Array input, ScalarType dtype, long count = -1, long offset = 0, bool requiresGrad = false, Device? device = null)\npublic static Tensor as_tensor(Array input,  ScalarType? dtype = null, Device? device = null)\npublic static Tensor as_tensor(Tensor input, ScalarType? dtype = null, Device? device = null)\n\n// Always copy:\npublic static Tensor as_tensor(IList<<VARIOUS TYPES>> input,  ScalarType? dtype = null, Device? device = null)\npublic static Tensor tensor(<<VARIOUS TYPES>> input, torch.Device? device = null, bool requiresGrad = false)\n```\n\n__Fixed Bugs:__\n\n#670 Better align methods for creating tensors from .NET arrays with Pytorch APIs. _This is the breaking change mentioned earlier._<br/>\n#679 The default value of onesided or torch.istft() is not aligned with PyTorch<br/>\n\n__API Changes__:\n\nAdded torch.nn.init.trunc_normal_<br/>\nAdded index_add, index_copy, index_fill<br/>\nAdded torch.frombuffer()<br/>\nAdded torch.fft.hfft2, hfftn, ihfft2, ihfftn<br/>\nAdding SequentialLR to the collection of LR schedulers.<br/>\nAdd 'training' flag to functional dropout methods.<br/>\nAdd missing functions to torchaudio.functional<br/>\nAdding TestOfAttribute to unit tests<br/>\n\n## NuGet Version 0.97.1\n\nThis release is made shortly after 0.97.0, since it adresses a serious performance issue when creating large tensors from .NET arrays.\n\n__Fixed Bugs:__\n\n#670 Tensor allocation insanely slow for from_array()<br/>\n\n__API Changes__:\n\nRNN, LSTM, GRU support PackedSequence<br/>\nAdd element-wise comparison methods of torch class.<br/>\nFix clamp and (non)quantile method declarations<br/>\nImplementing isnan()<br/>\nAdded torchaudio.models.Tacotron2()<br/>\n\n## NuGet Version 0.97.0\n\n__Fixed Bugs:__\n\n#653:Tensor.to(Tensor) doesn't change dtype of Tensor.<br/>\n\n__API Changes__:\n\nAdd ability to load and save TorchScript modules created using Pytorch<br/>\nAdd torch.utils.rnn<br/>\nAdd torchvision.io<br/>\nAdd Tensor.trace() and torch.trace() (unrelated to torch.jit.trace)<br/>\nAdd Tensor.var and Tensor.var_mean<br/>\nAdd torchaudio.datasets.SPEECHCOMMANDS<br/>\nAdd torchaudio.Resample()<br/>\n\n## NuGet Version 0.96.8\n\n__Breaking Changes:__\n\nThis release contains a fix to inadvertent breaking changes in 0.96.7, related to Tensor.str(). This fix is itself breaking, in that it breaks any code that relies on the order of\narguments to str() introduced in 0.96.7. However, since the pre-0.96.7 argument order makes more sense, we're taking this hit now rather than keeping the inconvenient order in 0.96.7.\n\n__Fixed Bugs:__\n\n#618 TorchSharp.Modules.Normal.sample() Expected all tensors [...]<br/>\n#621 torch.roll missing<br/>\n#629 Missing dependency in 0.96.7 calling TorchSharp.torchvision.datasets.MNIST<br/>\n#632 gaussian_nll_loss doesn't work on GPU<br/>\n\n__API Changes:__\n\nAdd torchaudio.datasets.YESNO().<br/>\nAdded torch.from_array() API to create a tensor from an arbitry-dimension .NET array.<br/>\nAdded torch.tensor() overloads for most common dimensions of .NET arrays: ndim = [1,2,3,4]<br/>\nAdded the most significant API additions from Pytorch 1.11.<br/>\nAdded juliastr() and npstr().<br/>\nAdded two torchaudio APIs.<br/>\nAdded 'decimals' argument to Tensor.round()<br/>\nChanged tensor.str() to undo the breaking change in 0.96.7<br/>\nAdded torch.std_mean()<br/>\n\n## NuGet Version 0.96.7\n\n__Dependency Changes:__\n\nThis version integrates with the libtorch 1.11.0 backend. API updates to follow.<br/>\n\n__API Changes:__\n\nStrong name signing of the TorchSharp library to allow loading it in .NET Framework strongly name signed apps.<br/>\nAdded the 'META' device type, which can be used to examine the affect of shape from tensor operations without actually doing any computations.<br/>\nAdded a few methods from the torch.nn.utils namespace.<br/>\nAdd torch.stft() and torch.istft()\n\n__Fixed Bugs:__\n\n#567 pad missing the choice to fill at start or end<br/>\n\n## NuGet Version 0.96.6\n\n__API Changes:__\n\n#587 Added the Storage classes, and Tensor.storage()<br/>\nAdded torchvision.models.resnet***() factories<br/>\nAdded torchvision.models.alexnet() factory<br/>\nAdded torchvision.models.vgg*() factories<br/>\nAdded 'skip' list for loading and saving weights.<br/>\nAdded torchvision.models.interception_v3() factory<br/>\nAdded torchvision.models.googlenet() factory<br/>\n\n__Fixed Bugs:__\n\n#582 unbind missing<br/>\n#592 GRU and Input and hidden tensors are not at the same device,[...]<br/>\nFixed Module.Dispose() and Sequential.Dispose() (no issue filed)\n\n## NuGet Version 0.96.5\n\nSame-day release. The previous release was made without propert testing of the ToString() improvements in a notebook context. It turned out that when the standard Windows line-terminator \"\\r\\n\" is used in a VS Code notebook, an extra blank line is created.\n\nThis release fixes that by allowing the caller of ToString() to pass in the line terminator string that should be used when formatting the string. This is easily done in the notebook.\n\n## NuGet Version 0.96.4\n\nIn this release, the big change is support for .NET FX 4.7.2 and later.\n\nThere are no breaking changes that we are aware of, but see the comment on API Changes below -- backporting code to .NET 4.7 or 4.8, which were not previously supported, may lead to errors in code that uses tensor indexing.\n\n__API Changes:__\n\nDue to the unavailability of `System.Range` in .NET FX 4.7, indexing of tensors using the `[a..b]` syntax is not available. In its place, we have added support for using tuples as index expressions, with the same semantics, except that the \"from end\" unary operator `^` of the C# range syntax is not available. The tuple syntax is also available for versions of .NET that do support `System.Range`\n\nA second piece of new functionality was to integrate @dayo05's work on DataLoader into the Examples. A couple of MNIST and CIFAR data sets are now found in `torchvision.datasets`\n\nA Numpy-style version of ToString() was added to the existing Julia-style, and the argument to the verbose ToString() was changed from 'Boolean' to an enumeration.\n\nA number of the \"bugs\" listed below represent missing APIs.\n\n__Fixed Bugs:__\n\n#519 Multiprocessing dataloader support<br/>\n#529 pin_memory missing<br/>\n#545 Implement FractionalMaxPool{23}d<br/>\n#554 Implement MaxUnpool{123}d<br/>\n#555 Implement LPPool{12}d<br/>\n#556 Implement missing activation modules<br/>\n#559 Implement miscellaneous missing layers.<br/>\n#564 torch.Tensor.tolist<br/>\n#566 Implicit conversion of scalars to tensors<br/>\n#576 load_state_dict functionality<br/>\n\n## NuGet Version 0.96.3\n\n__API Changes:__\n\n__NOTE__: This release contains breaking changes.<br/>\n\nThe APIs to create optimizers all take 'parameters()' as well as 'named_parameters()' now.<br/>\nSupport for parameter groups in most optimizers.<br/>\nSupport for parameter groups in LR schedulers.<br/>\n\n__Fixed Bugs:__\n\n#495 Add support for OptimizerParamGroup<br/>\n#509 Tensor.conj() not implemented<br/>\n#515 what's reason for making register_module internal?<br/>\n#516 AdamW bug on v0.96.0<br/>\n#521 Can't set Tensor slice using indexing<br/>\n#525 LSTM's forward function not work with null hidden and cell state<br/>\n#532 Why does storing module layers in arrays break the learning process?<br/>\n\n## NuGet Version 0.96.2\n\nNOT RELEASED\n\n## NuGet Version 0.96.1\n\n__API Changes:__\n\n__Fixed Bugs:__\n\nUsing libtorch CPU packages from F# Interactive required explicit native loads\n\n#510 Module.Load throws Mismatched state_dict sizes exception on BatchNorm1d<br/>\n\n## NuGet Version 0.96.0\n\n__API Changes:__\n\n__NOTE__: This release contains breaking changes.\n\n'Module.named_parameters()', 'parameters()', 'named_modules()', 'named_children()' all return IEnumerable instances instead of arrays.<br/>\nAdding weight and bias properties to the RNN modules.<br/>\nLower-cased names: Module.Train --> Module.train and Module.Eval --> Module.eval\n\n__Fixed Bugs:__\n\n#496 Wrong output shape of torch.nn.Conv2d with 2d stride overload<br/>\n#499 Setting Linear.weight is not reflected in 'parameters()'<br/>\n#500 BatchNorm1d throws exception during eval with batch size of 1<br/>\n\n## NuGet Version 0.95.4\n\n__API Changes:__\n\nAdded OneCycleLR and CyclicLR schedulers<br/>\nAdded DisposeScopeManager and torch.NewDisposeScope() to facilitate a new solution for managing disposing of  tensors with fewer usings.<br/>\nAdded Tensor.set_()<br/>\nAdded 'copy' argument to Tensor.to()\n\n__NOTES__: <br/>\nThe 'Weight' and 'Bias' properties on some modules have been renamed 'weight' and 'bias'.<br/>\nThe 'LRScheduler.LearningRate' property has been removed. To log the learning rate, get it from the optimizer that is in use.\n\n__Fixed Bugs:__\n\n#476 BatchNorm does not expose bias,weight,running_mean,running_var<br/>\n#475 Loading Module that's on CUDA<br/>\n#372 Module.save moves Module to CPU<br/>\n#468 How to set Conv2d kernel_size=(2,300)<br/>\n#450 Smoother disposing\n\n## NuGet Version 0.95.3\n\n__API Changes:__\n\nThe previously unused Tensor.free() method was renamed 'DecoupleFromNativeHandle()' and is meant to be used in native interop scenarios.<br/>\nTensor.Handle will now validate that the internal handle is not 'Zero', and throw an exception when it is. This will catch situations where a disposed tensor is accessed.<br/>\n\n__Fixed Bugs:__\n\nThere were a number of functions in torchvision, as well as a number of optimizers, that did not properly dispose of temporary and intermediate tensor values, leading to \"memory leaks\" in the absence of explicit GC.Collect() calls.<br/>\nA couple of randint() overloads caused infinite recursion, crashing the process.\n\n## NuGet Version 0.95.2\n\n__API Changes:__\n\nAdded a Sequential factory method to create Sequential from a list of anonymous submodules.<br/>\nAdded TotalCount and PeakCount static properties to Tensor, useful for diagnostic purposes.<br/>\n\n__Fixed Bugs:__\n\n#432 Sequential does not dispose of intermediary tensors.\n\n## NuGet Version 0.95.1\n\nThis version integrates with LibTorch 1.10.0.\n\n__API Changes:__\n\nAdded a 'strict' option to Module.load().\n\nSee tracking issue #416 for a list of new 1.10.0 APIs.\nhttps://github.com/dotnet/TorchSharp/issues/416\n\n## NuGet Version 0.93.9\n\n__Fixed Bugs:__\n\n#414 LRScheduler -- not calling the optimizer to step() [The original, closing fix was actually incorrect, but was then fixed again.]\n\n__API Changes:__\n\nAdded the NAdam and RAdam optimizers.<br/>\nAdded several missing and new learning rate schedulers.\n\n\n## NuGet Version 0.93.8\n\n__Fixed Bugs:__\n\n#413 Random Distributions Should Take a Generator Argument<br/>\n#414 LRScheduler -- not calling the optimizer to step()\n\n__API Changes:__\n\nAdded Module.Create<T>() to create a model and load weights.\n\n## NuGet Version 0.93.6\n\n__Fixed Bugs:__\n\n#407 rand() and randn() must check that the data type is floating-point.<br/>\n#410 Support for passing random number generators to rand(), randn(), and randint()\n\n\n__API Changes:__\n\nAdded some overloads to make F# usage more convenient.<br/>\nAdded convenience overloads to a number of random distribution factories.<br/>\nAdded '_' to the torch.nn.init functions. They overwrite the input tensor, so they should have the in-place indicator.\n\n## NuGet Version 0.93.5\n\n__Fixed Bugs:__\n\n#399 Data<T>() returns span that must be indexed using strides.\n\nThis was a major bug, affecting any code that pulled data out of a tensor view.\n\n__API Changes:__\n\nTensor.Data<T>() -> Tensor.data<T>()<br/>\nTensor.DataItem<T>() -> Tensor.item<T>()<br/>\nTensor.Bytes() -> Tensor.bytes<br/>\nTensor.SetBytes() -> Tensor.bytes<br/>\n\n## NuGet Version 0.93.4\n\nThis release introduces a couple of new NuGet packages, which bundle the native libraries that you need:\n\nTorchSharp-cpu<br/>\nTorchSharp-cuda-linux<br/>\nTorchSharp-cuda-windows<br/>\n\n## NuGet Version 0.93.1\n\nWith this release, the native libtorch package version was updated to 1.9.0.11, and that required rebuilding this package.\n\n## NuGet Version 0.93.0\n\nWith this release, releases will have explicit control over the patch version number.\n\n__Fixed Bugs:__\n\nFixed incorrectly implemented Module APIs related to parameter / module registration.<br/>\nChanged Module.state_dict() and Module.load() to 'virtual,' so that saving and restoring state may be customized.<br/>\n#353 Missing torch.minimum (with an alternative raising exception)<br/>\n#327 Tensor.Data<T> should do a type check<br/>\n#358 Implement ModuleList / ModuleDict / Parameter / ParameterList / ParameterDict\n\n__API Changes:__\n\nRemoved the type-named tensor factories, such as 'Int32Tensor.rand(),' etc.\n\n__Documentation Changes:__\n\nAdded an article on creating custom modules.\n\n## NuGet Version 0.92.52220\n\nThis was the first release since moving TorchSharp to the .NET Foundation organization. Most of the new functionality is related to continuing the API changes that were started in the previous release, and fixing some bugs.\n\n__Fixed Bugs:__\n\n#318 A few inconsistencies with the new naming\n\n__Added Features:__\n\n'''\ntorch.nn.MultiHeadAttention\ntorch.linalg.cond\ntorch.linalg.cholesky_ex\ntorch.linalg.inv_ex\ntorch.amax/amin\ntorch.matrix_exp\ntorch.distributions.*   (about half the namespace)\n'''\n\n__API Changes:__\n\nCustomModule removed, its APIs moved to Module.\n"
        },
        {
          "name": "THIRD-PARTY-NOTICES.TXT",
          "type": "blob",
          "size": 21.693359375,
          "content": "MIT License\n\nCopyright (c) 2018 Microsoft Corp\n\nPermission is hereby granted, free of charge, to any person obtaining a copy\nof this software and associated documentation files (the \"Software\"), to deal\nin the Software without restriction, including without limitation the rights\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\ncopies of the Software, and to permit persons to whom the Software is\nfurnished to do so, subject to the following conditions:\n\nThe above copyright notice and this permission notice shall be included in all\ncopies or substantial portions of the Software.\n\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\nSOFTWARE.\n\nThis software incorporates material from third parties listed below:\n\n==================\n\nFrom PyTorch\n\nCopyright (c) 2016-     Facebook, Inc            (Adam Paszke)\nCopyright (c) 2014-     Facebook, Inc            (Soumith Chintala)\nCopyright (c) 2011-2014 Idiap Research Institute (Ronan Collobert)\nCopyright (c) 2012-2014 Deepmind Technologies    (Koray Kavukcuoglu)\nCopyright (c) 2011-2012 NEC Laboratories America (Koray Kavukcuoglu)\nCopyright (c) 2011-2013 NYU                      (Clement Farabet)\nCopyright (c) 2006-2010 NEC Laboratories America (Ronan Collobert, Leon Bottou, Iain Melvin, Jason Weston)\nCopyright (c) 2006      Idiap Research Institute (Samy Bengio)\nCopyright (c) 2001-2004 Idiap Research Institute (Ronan Collobert, Samy Bengio, Johnny Mariethoz)\n\nFrom Caffe2:\n\nCopyright (c) 2016-present, Facebook Inc. All rights reserved.\n\nAll contributions by Facebook:\nCopyright (c) 2016 Facebook Inc.\n\nAll contributions by Google:\nCopyright (c) 2015 Google Inc.\nAll rights reserved.\n\nAll contributions by Yangqing Jia:\nCopyright (c) 2015 Yangqing Jia\nAll rights reserved.\n\nAll contributions from Caffe:\nCopyright(c) 2013, 2014, 2015, the respective contributors\nAll rights reserved.\n\nAll other contributions:\nCopyright(c) 2015, 2016 the respective contributors\nAll rights reserved.\n\nCaffe2 uses a copyright model similar to Caffe: each contributor holds\ncopyright over their contributions to Caffe2. The project versioning records\nall such contribution and copyright details. If a contributor wants to further\nmark their specific copyright on a particular contribution, they should\nindicate their copyright solely in the commit message of the change when it is\ncommitted.\n\nAll rights reserved.\n\nRedistribution and use in source and binary forms, with or without\nmodification, are permitted provided that the following conditions are met:\n\n1. Redistributions of source code must retain the above copyright\n   notice, this list of conditions and the following disclaimer.\n\n2. Redistributions in binary form must reproduce the above copyright\n   notice, this list of conditions and the following disclaimer in the\n   documentation and/or other materials provided with the distribution.\n\n3. Neither the names of Facebook, Deepmind Technologies, NYU, NEC Laboratories America\n   and IDIAP Research Institute nor the names of its contributors may be\n   used to endorse or promote products derived from this software without\n   specific prior written permission.\n\nTHIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS \"AS IS\"\nAND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE\nIMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE\nARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT OWNER OR CONTRIBUTORS BE\nLIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR\nCONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF\nSUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS\nINTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN\nCONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)\nARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE\nPOSSIBILITY OF SUCH DAMAGE.\n\n==================\nPart of CRC-32C library: https://crc32c.machinezoo.com/\n\nCopyright (c) 2013 - 2014, 2016 Mark Adler, Robert Vazan, Max Vysokikh\n\nThis software is provided 'as-is', without any express or implied\nwarranty.  In no event will the author be held liable for any damages\narising from the use of this software.\n\nPermission is granted to anyone to use this software for any purpose,\nincluding commercial applications, and to alter it and redistribute it\nfreely, subject to the following restrictions:\n\n1. The origin of this software must not be misrepresented; you must not\nclaim that you wrote the original software. If you use this software\nin a product, an acknowledgment in the product documentation would be\nappreciated but is not required.\n2. Altered source versions must be plainly marked as such, and must not be\nmisrepresented as being the original software.\n3. This notice may not be removed or altered from any source distribution.\n\n==================\nIntel MKL-DNN\n\nCopyright 2017-2018 Intel Corporation\n\nApache License\n\n                           Version 2.0, January 2004\n\n                        http://www.apache.org/licenses/\n\n\n\n   TERMS AND CONDITIONS FOR USE, REPRODUCTION, AND DISTRIBUTION\n\n\n\n   1. Definitions.\n\n\n\n      \"License\" shall mean the terms and conditions for use, reproduction,\n\n      and distribution as defined by Sections 1 through 9 of this document.\n\n\n\n      \"Licensor\" shall mean the copyright owner or entity authorized by\n\n      the copyright owner that is granting the License.\n\n\n\n      \"Legal Entity\" shall mean the union of the acting entity and all\n\n      other entities that control, are controlled by, or are under common\n\n      control with that entity. For the purposes of this definition,\n\n      \"control\" means (i) the power, direct or indirect, to cause the\n\n      direction or management of such entity, whether by contract or\n\n      otherwise, or (ii) ownership of fifty percent (50%) or more of the\n\n      outstanding shares, or (iii) beneficial ownership of such entity.\n\n\n\n      \"You\" (or \"Your\") shall mean an individual or Legal Entity\n\n      exercising permissions granted by this License.\n\n\n\n      \"Source\" form shall mean the preferred form for making modifications,\n\n      including but not limited to software source code, documentation\n\n      source, and configuration files.\n\n\n\n      \"Object\" form shall mean any form resulting from mechanical\n\n      transformation or translation of a Source form, including but\n\n      not limited to compiled object code, generated documentation,\n\n      and conversions to other media types.\n\n\n\n      \"Work\" shall mean the work of authorship, whether in Source or\n\n      Object form, made available under the License, as indicated by a\n\n      copyright notice that is included in or attached to the work\n\n      (an example is provided in the Appendix below).\n\n\n\n      \"Derivative Works\" shall mean any work, whether in Source or Object\n\n      form, that is based on (or derived from) the Work and for which the\n\n      editorial revisions, annotations, elaborations, or other modifications\n\n      represent, as a whole, an original work of authorship. For the purposes\n\n      of this License, Derivative Works shall not include works that remain\n\n      separable from, or merely link (or bind by name) to the interfaces of,\n\n      the Work and Derivative Works thereof.\n\n\n\n      \"Contribution\" shall mean any work of authorship, including\n\n      the original version of the Work and any modifications or additions\n\n      to that Work or Derivative Works thereof, that is intentionally\n\n      submitted to Licensor for inclusion in the Work by the copyright owner\n\n      or by an individual or Legal Entity authorized to submit on behalf of\n\n      the copyright owner. For the purposes of this definition, \"submitted\"\n\n      means any form of electronic, verbal, or written communication sent\n\n      to the Licensor or its representatives, including but not limited to\n\n      communication on electronic mailing lists, source code control systems,\n\n      and issue tracking systems that are managed by, or on behalf of, the\n\n      Licensor for the purpose of discussing and improving the Work, but\n\n      excluding communication that is conspicuously marked or otherwise\n\n      designated in writing by the copyright owner as \"Not a Contribution.\"\n\n\n\n      \"Contributor\" shall mean Licensor and any individual or Legal Entity\n\n      on behalf of whom a Contribution has been received by Licensor and\n\n      subsequently incorporated within the Work.\n\n\n\n   2. Grant of Copyright License. Subject to the terms and conditions of\n\n      this License, each Contributor hereby grants to You a perpetual,\n\n      worldwide, non-exclusive, no-charge, royalty-free, irrevocable\n\n      copyright license to reproduce, prepare Derivative Works of,\n\n      publicly display, publicly perform, sublicense, and distribute the\n\n      Work and such Derivative Works in Source or Object form.\n\n\n\n   3. Grant of Patent License. Subject to the terms and conditions of\n\n      this License, each Contributor hereby grants to You a perpetual,\n\n      worldwide, non-exclusive, no-charge, royalty-free, irrevocable\n\n      (except as stated in this section) patent license to make, have made,\n\n      use, offer to sell, sell, import, and otherwise transfer the Work,\n\n      where such license applies only to those patent claims licensable\n\n      by such Contributor that are necessarily infringed by their\n\n      Contribution(s) alone or by combination of their Contribution(s)\n\n      with the Work to which such Contribution(s) was submitted. If You\n\n      institute patent litigation against any entity (including a\n\n      cross-claim or counterclaim in a lawsuit) alleging that the Work\n\n      or a Contribution incorporated within the Work constitutes direct\n\n      or contributory patent infringement, then any patent licenses\n\n      granted to You under this License for that Work shall terminate\n\n      as of the date such litigation is filed.\n\n\n\n   4. Redistribution. You may reproduce and distribute copies of the\n\n      Work or Derivative Works thereof in any medium, with or without\n\n      modifications, and in Source or Object form, provided that You\n\n      meet the following conditions:\n\n\n\n      (a) You must give any other recipients of the Work or\n\n          Derivative Works a copy of this License; and\n\n\n\n      (b) You must cause any modified files to carry prominent notices\n\n          stating that You changed the files; and\n\n\n\n      (c) You must retain, in the Source form of any Derivative Works\n\n          that You distribute, all copyright, patent, trademark, and\n\n          attribution notices from the Source form of the Work,\n\n          excluding those notices that do not pertain to any part of\n\n          the Derivative Works; and\n\n\n\n      (d) If the Work includes a \"NOTICE\" text file as part of its\n\n          distribution, then any Derivative Works that You distribute must\n\n          include a readable copy of the attribution notices contained\n\n          within such NOTICE file, excluding those notices that do not\n\n          pertain to any part of the Derivative Works, in at least one\n\n          of the following places: within a NOTICE text file distributed\n\n          as part of the Derivative Works; within the Source form or\n\n          documentation, if provided along with the Derivative Works; or,\n\n          within a display generated by the Derivative Works, if and\n\n          wherever such third-party notices normally appear. The contents\n\n          of the NOTICE file are for informational purposes only and\n\n          do not modify the License. You may add Your own attribution\n\n          notices within Derivative Works that You distribute, alongside\n\n          or as an addendum to the NOTICE text from the Work, provided\n\n          that such additional attribution notices cannot be construed\n\n          as modifying the License.\n\n\n\n      You may add Your own copyright statement to Your modifications and\n\n      may provide additional or different license terms and conditions\n\n      for use, reproduction, or distribution of Your modifications, or\n\n      for any such Derivative Works as a whole, provided Your use,\n\n      reproduction, and distribution of the Work otherwise complies with\n\n      the conditions stated in this License.\n\n\n\n   5. Submission of Contributions. Unless You explicitly state otherwise,\n\n      any Contribution intentionally submitted for inclusion in the Work\n\n      by You to the Licensor shall be under the terms and conditions of\n\n      this License, without any additional terms or conditions.\n\n      Notwithstanding the above, nothing herein shall supersede or modify\n\n      the terms of any separate license agreement you may have executed\n\n      with Licensor regarding such Contributions.\n\n\n\n   6. Trademarks. This License does not grant permission to use the trade\n\n      names, trademarks, service marks, or product names of the Licensor,\n\n      except as required for reasonable and customary use in describing the\n\n      origin of the Work and reproducing the content of the NOTICE file.\n\n\n\n   7. Disclaimer of Warranty. Unless required by applicable law or\n\n      agreed to in writing, Licensor provides the Work (and each\n\n      Contributor provides its Contributions) on an \"AS IS\" BASIS,\n\n      WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or\n\n      implied, including, without limitation, any warranties or conditions\n\n      of TITLE, NON-INFRINGEMENT, MERCHANTABILITY, or FITNESS FOR A\n\n      PARTICULAR PURPOSE. You are solely responsible for determining the\n\n      appropriateness of using or redistributing the Work and assume any\n\n      risks associated with Your exercise of permissions under this License.\n\n\n\n   8. Limitation of Liability. In no event and under no legal theory,\n\n      whether in tort (including negligence), contract, or otherwise,\n\n      unless required by applicable law (such as deliberate and grossly\n\n      negligent acts) or agreed to in writing, shall any Contributor be\n\n      liable to You for damages, including any direct, indirect, special,\n\n      incidental, or consequential damages of any character arising as a\n\n      result of this License or out of the use or inability to use the\n\n      Work (including but not limited to damages for loss of goodwill,\n\n      work stoppage, computer failure or malfunction, or any and all\n\n      other commercial damages or losses), even if such Contributor\n\n      has been advised of the possibility of such damages.\n\n\n\n   9. Accepting Warranty or Additional Liability. While redistributing\n\n      the Work or Derivative Works thereof, You may choose to offer,\n\n      and charge a fee for, acceptance of support, warranty, indemnity,\n\n      or other liability obligations and/or rights consistent with this\n\n      License. However, in accepting such obligations, You may act only\n\n      on Your own behalf and on Your sole responsibility, not on behalf\n\n      of any other Contributor, and only if You agree to indemnify,\n\n      defend, and hold each Contributor harmless for any liability\n\n      incurred by, or claims asserted against, such Contributor by reason\n\n      of your accepting any such warranty or additional liability.\n\n\n\n   END OF TERMS AND CONDITIONS\n\n\n\n   APPENDIX: How to apply the Apache License to your work.\n\n\n\n      To apply the Apache License to your work, attach the following\n\n      boilerplate notice, with the fields enclosed by brackets \"{}\"\n\n      replaced with your own identifying information. (Don't include\n\n      the brackets!)  The text should be enclosed in the appropriate\n\n      comment syntax for the file format. We also recommend that a\n\n      file or class name and description of purpose be included on the\n\n      same \"printed page\" as the copyright notice for easier\n\n      identification within third-party archives.\n\n\n\n   Copyright {yyyy} {name of copyright owner}\n\n\n\n   Licensed under the Apache License, Version 2.0 (the \"License\");\n\n   you may not use this file except in compliance with the License.\n\n   You may obtain a copy of the License at\n\n\n\n       http://www.apache.org/licenses/LICENSE-2.0\n\n\n\n   Unless required by applicable law or agreed to in writing, software\n\n   distributed under the License is distributed on an \"AS IS\" BASIS,\n\n   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n\n   See the License for the specific language governing permissions and\n\n   limitations under the License.\n\n\n\n   ============================================================================\n\n\n\n   Intel MKL-DNN includes components with separate copyright\n\n   notices and license terms.\n\n\n\n   XByak, 3-clause BSD license\n\n   Copyright (c) 2007 MITSUNARI Shigeo\n\n   See full copyright notice and license text in src/cpu/xbyak/COPYRIGHT\n\n\n\n   gtest, 3-clause BSD license\n\n   Copyright 2008, Google Inc.\n\n   See full copyright notice and license text in tests/gtests/gtest/LICENSE\n\n\n\n   ittnotify, 3-clause BSD license\n\n   Copyright (c) 2011, Intel Corporation\n\n   See full copyright notice and license text in\n\n   src/cpu/jit_utils/jitprofiling/LICENSE.BSD\n\n   ==================\n   Numpy\n\n   Copyright (c) 2005-2023, NumPy Developers.\n   All rights reserved.\n\n   Redistribution and use in source and binary forms, with or without\n   modification, are permitted provided that the following conditions are\n   met:\n\n      * Redistributions of source code must retain the above copyright\n         notice, this list of conditions and the following disclaimer.\n\n      * Redistributions in binary form must reproduce the above\n         copyright notice, this list of conditions and the following\n         disclaimer in the documentation and/or other materials provided\n         with the distribution.\n\n      * Neither the name of the NumPy Developers nor the names of any\n         contributors may be used to endorse or promote products derived\n         from this software without specific prior written permission.\n\n   THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS\n   \"AS IS\" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT\n   LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR\n   A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT\n   OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,\n   SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT\n   LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,\n   DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY\n   THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT\n   (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE\n   OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n\n\t==================\n\tAndroid Code(gif_encoder)\n\thttps://cs.android.com/android/platform/superproject/+/master:external/glide/LICENSE\n\thttps://cs.android.com/android/platform/superproject/+/master:external/glide/third_party/gif_encoder/LICENSE\n\n\tCopyright 2014 Google, Inc. All rights reserved.\n\n\tRedistribution and use in source and binary forms, with or without modification, are\n\tpermitted provided that the following conditions are met:\n\n\t\t1. Redistributions of source code must retain the above copyright notice, this list of\n\t\t\t\tconditions and the following disclaimer.\n\n\t\t2. Redistributions in binary form must reproduce the above copyright notice, this list\n\t\t\t\tof conditions and the following disclaimer in the documentation and/or other materials\n\t\t\t\tprovided with the distribution.\n\n\tTHIS SOFTWARE IS PROVIDED BY GOOGLE, INC. ``AS IS'' AND ANY EXPRESS OR IMPLIED\n\tWARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND\n\tFITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL GOOGLE, INC. OR\n\tCONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR\n\tCONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR\n\tSERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON\n\tANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING\n\tNEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF\n\tADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n\n\tThe views and conclusions contained in the software and documentation are those of the\n\tauthors and should not be interpreted as representing official policies, either expressed\n\tor implied, of Google, Inc.\n\t---------------------------------------------------------------------------------------------\n\n\tLicense for Encoder.cs and LZWEncoder.cs\n\n\tNo copyright asserted on the source code of this class. May be used for any\n\tpurpose, however, refer to the Unisys LZW patent for restrictions on use of\n\tthe associated LZWEncoder class. Please forward any corrections to\n\tkweiner@fmsware.com.\n\n\t-----------------------------------------------------------------------------\n\tLicense for NeuQuant.cs\n\n\tCopyright (c) 1994 Anthony Dekker\n\n\tNEUQUANT Neural-Net quantization algorithm by Anthony Dekker, 1994. See\n\t\"Kohonen neural networks for optimal colour quantization\" in \"Network:\n\tComputation in Neural Systems\" Vol. 5 (1994) pp 351-367. for a discussion of\n\tthe algorithm.\n\n\tAny party obtaining a copy of these files from the author, directly or\n\tindirectly, is granted, free of charge, a full and unrestricted irrevocable,\n\tworld-wide, paid up, royalty-free, nonexclusive right and license to deal in\n\tthis software and documentation files (the \"Software\"), including without\n\tlimitation the rights to use, copy, modify, merge, publish, distribute,\n\tsublicense, and/or sell copies of the Software, and to permit persons who\n\treceive copies from any such party to do so, with the only requirement being\n\tthat this copyright notice remain intact."
        },
        {
          "name": "TorchSharp.sln",
          "type": "blob",
          "size": 13.40625,
          "content": "Microsoft Visual Studio Solution File, Format Version 12.00\n# Visual Studio Version 17\nVisualStudioVersion = 17.0.31903.59\nMinimumVisualStudioVersion = 10.0.40219.1\nProject(\"{2150E333-8FDC-42A3-9474-1A3956D46DE8}\") = \"src\", \"src\", \"{09EADF06-BE25-4228-AB53-95AE3E15B530}\"\n\tProjectSection(SolutionItems) = preProject\n\t\tsrc\\Source.ruleset = src\\Source.ruleset\n\tEndProjectSection\nEndProject\nProject(\"{2150E333-8FDC-42A3-9474-1A3956D46DE8}\") = \"test\", \"test\", \"{AED9C836-31E3-4F3F-8ABC-929555D3F3C4}\"\nEndProject\nProject(\"{2150E333-8FDC-42A3-9474-1A3956D46DE8}\") = \"pkg\", \"pkg\", \"{D3D38B03-B557-484D-8348-8BADEE4DF592}\"\n\tProjectSection(SolutionItems) = preProject\n\t\tpkg\\Directory.Build.props = pkg\\Directory.Build.props\n\t\tpkg\\pack.proj = pkg\\pack.proj\n\tEndProjectSection\nEndProject\nProject(\"{2150E333-8FDC-42A3-9474-1A3956D46DE8}\") = \"common\", \"common\", \"{A84717CB-F11A-41C5-A74D-C0F1D47B7431}\"\n\tProjectSection(SolutionItems) = preProject\n\t\tpkg\\common\\DnnImageFeaturizer.props = pkg\\common\\DnnImageFeaturizer.props\n\t\tpkg\\common\\RestitchPackage.props = pkg\\common\\RestitchPackage.props\n\t\tpkg\\common\\RestitchPackage.targets = pkg\\common\\RestitchPackage.targets\n\tEndProjectSection\nEndProject\nProject(\"{9A19103F-16F7-4668-BE54-9A1E7A4F7556}\") = \"TorchSharp\", \"src\\TorchSharp\\TorchSharp.csproj\", \"{061CCBA1-A859-4392-8F45-249E5DAF1C88}\"\nEndProject\nProject(\"{9A19103F-16F7-4668-BE54-9A1E7A4F7556}\") = \"TorchSharpTest\", \"test\\TorchSharpTest\\TorchSharpTest.csproj\", \"{6C323B05-9028-4B09-911C-3C03AE058BEE}\"\nEndProject\nProject(\"{9A19103F-16F7-4668-BE54-9A1E7A4F7556}\") = \"Examples\", \"src\\Examples\\Examples.csproj\", \"{42B45168-476D-4BFA-87B8-81A34E6295CD}\"\nEndProject\nProject(\"{2150E333-8FDC-42A3-9474-1A3956D46DE8}\") = \"TorchSharp\", \"TorchSharp\", \"{567456AD-B026-4CB6-B98D-4FC930C90223}\"\n\tProjectSection(SolutionItems) = preProject\n\t\tpkg\\TorchSharp\\TorchSharp.nupkgproj = pkg\\TorchSharp\\TorchSharp.nupkgproj\n\t\tpkg\\TorchSharp\\TorchSharp.symbols.nupkgproj = pkg\\TorchSharp\\TorchSharp.symbols.nupkgproj\n\tEndProjectSection\nEndProject\nProject(\"{8BC9CEB8-8B4A-11D0-8D11-00A0C91BC942}\") = \"LibTorchSharp\", \"bin\\obj\\x64.Debug\\Native\\LibTorchSharp\\LibTorchSharp.vcxproj\", \"{CAD9DB7F-3223-3324-884D-FA2381593DA7}\"\nEndProject\nProject(\"{8BC9CEB8-8B4A-11D0-8D11-00A0C91BC942}\") = \"LibTorchSharp\", \"bin\\obj\\x64.Release\\Native\\LibTorchSharp\\LibTorchSharp.vcxproj\", \"{BB811429-0DF1-3D22-B664-09C2F5A9E0AB}\"\nEndProject\nProject(\"{2150E333-8FDC-42A3-9474-1A3956D46DE8}\") = \"Native-Debug\", \"Native-Debug\", \"{CF2C1A9E-3A8A-4329-8A6E-7880C15AAC3D}\"\n\tProjectSection(SolutionItems) = preProject\n\t\tsrc\\Native\\build.proj = src\\Native\\build.proj\n\tEndProjectSection\nEndProject\nProject(\"{2150E333-8FDC-42A3-9474-1A3956D46DE8}\") = \"Redist\", \"Redist\", \"{D8C60CD8-8429-45F2-A755-47B6CD10FDF8}\"\n\tProjectSection(SolutionItems) = preProject\n\t\tsrc\\Redist\\libtorch-cpu\\libtorch-cpu.proj = src\\Redist\\libtorch-cpu\\libtorch-cpu.proj\n\t\tsrc\\Redist\\libtorch-cuda-12.1\\libtorch-cuda-12.1.proj = src\\Redist\\libtorch-cuda-12.1\\libtorch-cuda-12.1.proj\n\tEndProjectSection\nEndProject\nProject(\"{2150E333-8FDC-42A3-9474-1A3956D46DE8}\") = \"Native-Release\", \"Native-Release\", \"{4DB9E84D-324C-408F-87A6-246E86205540}\"\nEndProject\nProject(\"{9A19103F-16F7-4668-BE54-9A1E7A4F7556}\") = \"TorchSharpTest.WithCudaBinaries\", \"test\\TorchSharpTest.WithCudaBinaries\\TorchSharpTest.WithCudaBinaries.csproj\", \"{DD652544-711E-4029-83FF-DA4A9600E6E7}\"\nEndProject\nProject(\"{6EC3EE1D-3C4E-46DD-8F32-0CC8E7565705}\") = \"FSharp.Examples\", \"src\\FSharp.Examples\\FSharp.Examples.fsproj\", \"{05031D1C-D0B2-4BF3-A6AF-3339A78437E3}\"\nEndProject\nProject(\"{9A19103F-16F7-4668-BE54-9A1E7A4F7556}\") = \"Examples.Utils\", \"src\\Examples.Utils\\Examples.Utils.csproj\", \"{AACEAE55-804D-45BC-BC3D-1AB8E856E0E8}\"\nEndProject\nProject(\"{9A19103F-16F7-4668-BE54-9A1E7A4F7556}\") = \"FileRestitcher\", \"pkg\\FileRestitcher\\FileRestitcher\\FileRestitcher.csproj\", \"{95493944-D1AE-414E-964B-B58AEAE672E5}\"\nEndProject\nProject(\"{9A19103F-16F7-4668-BE54-9A1E7A4F7556}\") = \"FileRestitcher.Tests\", \"pkg\\FileRestitcher\\FileRestitcher.Tests\\FileRestitcher.Tests.csproj\", \"{6D3CE8AA-F369-4D2D-BDA7-9F89D6BE1B2E}\"\nEndProject\nProject(\"{2150E333-8FDC-42A3-9474-1A3956D46DE8}\") = \"Solution Items\", \"Solution Items\", \"{1BBCA8A0-C5AB-4BD5-8B1A-A586E4BC189A}\"\n\tProjectSection(SolutionItems) = preProject\n\t\tazure-pipelines.yml = azure-pipelines.yml\n\t\tbuild\\BranchInfo.props = build\\BranchInfo.props\n\t\tDEVGUIDE.md = DEVGUIDE.md\n\t\tglobal.json = global.json\n\t\tREADME.md = README.md\n\t\tRELEASENOTES.md = RELEASENOTES.md\n\tEndProjectSection\nEndProject\nProject(\"{9A19103F-16F7-4668-BE54-9A1E7A4F7556}\") = \"TorchVision\", \"src\\TorchVision\\TorchVision.csproj\", \"{DCF01EE5-6431-4115-85E0-1FC4C3DE86A2}\"\nEndProject\nProject(\"{9A19103F-16F7-4668-BE54-9A1E7A4F7556}\") = \"TorchAudio\", \"src\\TorchAudio\\TorchAudio.csproj\", \"{B3AAC8E8-9CA4-4B01-96CF-206AE7327DDE}\"\nEndProject\nGlobal\n\tGlobalSection(SolutionConfigurationPlatforms) = preSolution\n\t\tDebug|Any CPU = Debug|Any CPU\n\t\tDebug|x64 = Debug|x64\n\t\tRelease|Any CPU = Release|Any CPU\n\t\tRelease|x64 = Release|x64\n\tEndGlobalSection\n\tGlobalSection(ProjectConfigurationPlatforms) = postSolution\n\t\t{061CCBA1-A859-4392-8F45-249E5DAF1C88}.Debug|Any CPU.ActiveCfg = Debug|Any CPU\n\t\t{061CCBA1-A859-4392-8F45-249E5DAF1C88}.Debug|Any CPU.Build.0 = Debug|Any CPU\n\t\t{061CCBA1-A859-4392-8F45-249E5DAF1C88}.Debug|x64.ActiveCfg = Debug|Any CPU\n\t\t{061CCBA1-A859-4392-8F45-249E5DAF1C88}.Debug|x64.Build.0 = Debug|Any CPU\n\t\t{061CCBA1-A859-4392-8F45-249E5DAF1C88}.Release|Any CPU.ActiveCfg = Release|Any CPU\n\t\t{061CCBA1-A859-4392-8F45-249E5DAF1C88}.Release|Any CPU.Build.0 = Release|Any CPU\n\t\t{061CCBA1-A859-4392-8F45-249E5DAF1C88}.Release|x64.ActiveCfg = Release|Any CPU\n\t\t{061CCBA1-A859-4392-8F45-249E5DAF1C88}.Release|x64.Build.0 = Release|Any CPU\n\t\t{6C323B05-9028-4B09-911C-3C03AE058BEE}.Debug|Any CPU.ActiveCfg = Debug|Any CPU\n\t\t{6C323B05-9028-4B09-911C-3C03AE058BEE}.Debug|Any CPU.Build.0 = Debug|Any CPU\n\t\t{6C323B05-9028-4B09-911C-3C03AE058BEE}.Debug|x64.ActiveCfg = Debug|Any CPU\n\t\t{6C323B05-9028-4B09-911C-3C03AE058BEE}.Debug|x64.Build.0 = Debug|Any CPU\n\t\t{6C323B05-9028-4B09-911C-3C03AE058BEE}.Release|Any CPU.ActiveCfg = Release|Any CPU\n\t\t{6C323B05-9028-4B09-911C-3C03AE058BEE}.Release|Any CPU.Build.0 = Release|Any CPU\n\t\t{6C323B05-9028-4B09-911C-3C03AE058BEE}.Release|x64.ActiveCfg = Release|Any CPU\n\t\t{6C323B05-9028-4B09-911C-3C03AE058BEE}.Release|x64.Build.0 = Release|Any CPU\n\t\t{42B45168-476D-4BFA-87B8-81A34E6295CD}.Debug|Any CPU.ActiveCfg = Debug|Any CPU\n\t\t{42B45168-476D-4BFA-87B8-81A34E6295CD}.Debug|Any CPU.Build.0 = Debug|Any CPU\n\t\t{42B45168-476D-4BFA-87B8-81A34E6295CD}.Debug|x64.ActiveCfg = Debug|Any CPU\n\t\t{42B45168-476D-4BFA-87B8-81A34E6295CD}.Debug|x64.Build.0 = Debug|Any CPU\n\t\t{42B45168-476D-4BFA-87B8-81A34E6295CD}.Release|Any CPU.ActiveCfg = Release|Any CPU\n\t\t{42B45168-476D-4BFA-87B8-81A34E6295CD}.Release|Any CPU.Build.0 = Release|Any CPU\n\t\t{42B45168-476D-4BFA-87B8-81A34E6295CD}.Release|x64.ActiveCfg = Release|Any CPU\n\t\t{42B45168-476D-4BFA-87B8-81A34E6295CD}.Release|x64.Build.0 = Release|Any CPU\n\t\t{CAD9DB7F-3223-3324-884D-FA2381593DA7}.Debug|Any CPU.ActiveCfg = Debug|x64\n\t\t{CAD9DB7F-3223-3324-884D-FA2381593DA7}.Debug|x64.ActiveCfg = Debug|x64\n\t\t{CAD9DB7F-3223-3324-884D-FA2381593DA7}.Release|Any CPU.ActiveCfg = Release|x64\n\t\t{CAD9DB7F-3223-3324-884D-FA2381593DA7}.Release|x64.ActiveCfg = Release|x64\n\t\t{E4C0DBEE-0815-311B-9065-137BB50BD793}.Debug|Any CPU.ActiveCfg = Debug|x64\n\t\t{E4C0DBEE-0815-311B-9065-137BB50BD793}.Debug|x64.ActiveCfg = Debug|x64\n\t\t{E4C0DBEE-0815-311B-9065-137BB50BD793}.Release|Any CPU.ActiveCfg = Release|x64\n\t\t{E4C0DBEE-0815-311B-9065-137BB50BD793}.Release|x64.ActiveCfg = Release|x64\n\t\t{DD652544-711E-4029-83FF-DA4A9600E6E7}.Debug|Any CPU.ActiveCfg = Debug|Any CPU\n\t\t{DD652544-711E-4029-83FF-DA4A9600E6E7}.Debug|Any CPU.Build.0 = Debug|Any CPU\n\t\t{DD652544-711E-4029-83FF-DA4A9600E6E7}.Debug|x64.ActiveCfg = Debug|Any CPU\n\t\t{DD652544-711E-4029-83FF-DA4A9600E6E7}.Debug|x64.Build.0 = Debug|Any CPU\n\t\t{DD652544-711E-4029-83FF-DA4A9600E6E7}.Release|Any CPU.ActiveCfg = Release|Any CPU\n\t\t{DD652544-711E-4029-83FF-DA4A9600E6E7}.Release|Any CPU.Build.0 = Release|Any CPU\n\t\t{DD652544-711E-4029-83FF-DA4A9600E6E7}.Release|x64.ActiveCfg = Release|Any CPU\n\t\t{DD652544-711E-4029-83FF-DA4A9600E6E7}.Release|x64.Build.0 = Release|Any CPU\n\t\t{05031D1C-D0B2-4BF3-A6AF-3339A78437E3}.Debug|Any CPU.ActiveCfg = Debug|Any CPU\n\t\t{05031D1C-D0B2-4BF3-A6AF-3339A78437E3}.Debug|Any CPU.Build.0 = Debug|Any CPU\n\t\t{05031D1C-D0B2-4BF3-A6AF-3339A78437E3}.Debug|x64.ActiveCfg = Debug|Any CPU\n\t\t{05031D1C-D0B2-4BF3-A6AF-3339A78437E3}.Debug|x64.Build.0 = Debug|Any CPU\n\t\t{05031D1C-D0B2-4BF3-A6AF-3339A78437E3}.Release|Any CPU.ActiveCfg = Release|Any CPU\n\t\t{05031D1C-D0B2-4BF3-A6AF-3339A78437E3}.Release|Any CPU.Build.0 = Release|Any CPU\n\t\t{05031D1C-D0B2-4BF3-A6AF-3339A78437E3}.Release|x64.ActiveCfg = Release|Any CPU\n\t\t{05031D1C-D0B2-4BF3-A6AF-3339A78437E3}.Release|x64.Build.0 = Release|Any CPU\n\t\t{AACEAE55-804D-45BC-BC3D-1AB8E856E0E8}.Debug|Any CPU.ActiveCfg = Debug|Any CPU\n\t\t{AACEAE55-804D-45BC-BC3D-1AB8E856E0E8}.Debug|Any CPU.Build.0 = Debug|Any CPU\n\t\t{AACEAE55-804D-45BC-BC3D-1AB8E856E0E8}.Debug|x64.ActiveCfg = Debug|Any CPU\n\t\t{AACEAE55-804D-45BC-BC3D-1AB8E856E0E8}.Debug|x64.Build.0 = Debug|Any CPU\n\t\t{AACEAE55-804D-45BC-BC3D-1AB8E856E0E8}.Release|Any CPU.ActiveCfg = Release|Any CPU\n\t\t{AACEAE55-804D-45BC-BC3D-1AB8E856E0E8}.Release|Any CPU.Build.0 = Release|Any CPU\n\t\t{AACEAE55-804D-45BC-BC3D-1AB8E856E0E8}.Release|x64.ActiveCfg = Release|Any CPU\n\t\t{AACEAE55-804D-45BC-BC3D-1AB8E856E0E8}.Release|x64.Build.0 = Release|Any CPU\n\t\t{95493944-D1AE-414E-964B-B58AEAE672E5}.Debug|Any CPU.ActiveCfg = Debug|Any CPU\n\t\t{95493944-D1AE-414E-964B-B58AEAE672E5}.Debug|Any CPU.Build.0 = Debug|Any CPU\n\t\t{95493944-D1AE-414E-964B-B58AEAE672E5}.Debug|x64.ActiveCfg = Debug|Any CPU\n\t\t{95493944-D1AE-414E-964B-B58AEAE672E5}.Debug|x64.Build.0 = Debug|Any CPU\n\t\t{95493944-D1AE-414E-964B-B58AEAE672E5}.Release|Any CPU.ActiveCfg = Release|Any CPU\n\t\t{95493944-D1AE-414E-964B-B58AEAE672E5}.Release|Any CPU.Build.0 = Release|Any CPU\n\t\t{95493944-D1AE-414E-964B-B58AEAE672E5}.Release|x64.ActiveCfg = Release|Any CPU\n\t\t{95493944-D1AE-414E-964B-B58AEAE672E5}.Release|x64.Build.0 = Release|Any CPU\n\t\t{6D3CE8AA-F369-4D2D-BDA7-9F89D6BE1B2E}.Debug|Any CPU.ActiveCfg = Debug|Any CPU\n\t\t{6D3CE8AA-F369-4D2D-BDA7-9F89D6BE1B2E}.Debug|x64.ActiveCfg = Debug|Any CPU\n\t\t{6D3CE8AA-F369-4D2D-BDA7-9F89D6BE1B2E}.Debug|x64.Build.0 = Debug|Any CPU\n\t\t{6D3CE8AA-F369-4D2D-BDA7-9F89D6BE1B2E}.Release|Any CPU.ActiveCfg = Release|Any CPU\n\t\t{6D3CE8AA-F369-4D2D-BDA7-9F89D6BE1B2E}.Release|Any CPU.Build.0 = Release|Any CPU\n\t\t{6D3CE8AA-F369-4D2D-BDA7-9F89D6BE1B2E}.Release|x64.ActiveCfg = Release|Any CPU\n\t\t{6D3CE8AA-F369-4D2D-BDA7-9F89D6BE1B2E}.Release|x64.Build.0 = Release|Any CPU\n\t\t{DCF01EE5-6431-4115-85E0-1FC4C3DE86A2}.Debug|Any CPU.ActiveCfg = Debug|Any CPU\n\t\t{DCF01EE5-6431-4115-85E0-1FC4C3DE86A2}.Debug|Any CPU.Build.0 = Debug|Any CPU\n\t\t{DCF01EE5-6431-4115-85E0-1FC4C3DE86A2}.Debug|x64.ActiveCfg = Debug|Any CPU\n\t\t{DCF01EE5-6431-4115-85E0-1FC4C3DE86A2}.Debug|x64.Build.0 = Debug|Any CPU\n\t\t{DCF01EE5-6431-4115-85E0-1FC4C3DE86A2}.Release|Any CPU.ActiveCfg = Release|Any CPU\n\t\t{DCF01EE5-6431-4115-85E0-1FC4C3DE86A2}.Release|Any CPU.Build.0 = Release|Any CPU\n\t\t{DCF01EE5-6431-4115-85E0-1FC4C3DE86A2}.Release|x64.ActiveCfg = Release|Any CPU\n\t\t{DCF01EE5-6431-4115-85E0-1FC4C3DE86A2}.Release|x64.Build.0 = Release|Any CPU\n\t\t{B3AAC8E8-9CA4-4B01-96CF-206AE7327DDE}.Debug|Any CPU.ActiveCfg = Debug|Any CPU\n\t\t{B3AAC8E8-9CA4-4B01-96CF-206AE7327DDE}.Debug|Any CPU.Build.0 = Debug|Any CPU\n\t\t{B3AAC8E8-9CA4-4B01-96CF-206AE7327DDE}.Debug|x64.ActiveCfg = Debug|Any CPU\n\t\t{B3AAC8E8-9CA4-4B01-96CF-206AE7327DDE}.Debug|x64.Build.0 = Debug|Any CPU\n\t\t{B3AAC8E8-9CA4-4B01-96CF-206AE7327DDE}.Release|Any CPU.ActiveCfg = Release|Any CPU\n\t\t{B3AAC8E8-9CA4-4B01-96CF-206AE7327DDE}.Release|Any CPU.Build.0 = Release|Any CPU\n\t\t{B3AAC8E8-9CA4-4B01-96CF-206AE7327DDE}.Release|x64.ActiveCfg = Release|Any CPU\n\t\t{B3AAC8E8-9CA4-4B01-96CF-206AE7327DDE}.Release|x64.Build.0 = Release|Any CPU\n\tEndGlobalSection\n\tGlobalSection(SolutionProperties) = preSolution\n\t\tHideSolutionNode = FALSE\n\tEndGlobalSection\n\tGlobalSection(NestedProjects) = preSolution\n\t\t{A84717CB-F11A-41C5-A74D-C0F1D47B7431} = {D3D38B03-B557-484D-8348-8BADEE4DF592}\n\t\t{061CCBA1-A859-4392-8F45-249E5DAF1C88} = {09EADF06-BE25-4228-AB53-95AE3E15B530}\n\t\t{6C323B05-9028-4B09-911C-3C03AE058BEE} = {AED9C836-31E3-4F3F-8ABC-929555D3F3C4}\n\t\t{42B45168-476D-4BFA-87B8-81A34E6295CD} = {09EADF06-BE25-4228-AB53-95AE3E15B530}\n\t\t{567456AD-B026-4CB6-B98D-4FC930C90223} = {D3D38B03-B557-484D-8348-8BADEE4DF592}\n\t\t{CAD9DB7F-3223-3324-884D-FA2381593DA7} = {CF2C1A9E-3A8A-4329-8A6E-7880C15AAC3D}\n\t\t{BB811429-0DF1-3D22-B664-09C2F5A9E0AB} = {4DB9E84D-324C-408F-87A6-246E86205540}\n\t\t{CF2C1A9E-3A8A-4329-8A6E-7880C15AAC3D} = {09EADF06-BE25-4228-AB53-95AE3E15B530}\n\t\t{D8C60CD8-8429-45F2-A755-47B6CD10FDF8} = {09EADF06-BE25-4228-AB53-95AE3E15B530}\n\t\t{4DB9E84D-324C-408F-87A6-246E86205540} = {CF2C1A9E-3A8A-4329-8A6E-7880C15AAC3D}\n\t\t{DD652544-711E-4029-83FF-DA4A9600E6E7} = {AED9C836-31E3-4F3F-8ABC-929555D3F3C4}\n\t\t{05031D1C-D0B2-4BF3-A6AF-3339A78437E3} = {09EADF06-BE25-4228-AB53-95AE3E15B530}\n\t\t{AACEAE55-804D-45BC-BC3D-1AB8E856E0E8} = {09EADF06-BE25-4228-AB53-95AE3E15B530}\n\t\t{95493944-D1AE-414E-964B-B58AEAE672E5} = {D3D38B03-B557-484D-8348-8BADEE4DF592}\n\t\t{6D3CE8AA-F369-4D2D-BDA7-9F89D6BE1B2E} = {D3D38B03-B557-484D-8348-8BADEE4DF592}\n\t\t{DCF01EE5-6431-4115-85E0-1FC4C3DE86A2} = {09EADF06-BE25-4228-AB53-95AE3E15B530}\n\t\t{B3AAC8E8-9CA4-4B01-96CF-206AE7327DDE} = {09EADF06-BE25-4228-AB53-95AE3E15B530}\n\tEndGlobalSection\n\tGlobalSection(ExtensibilityGlobals) = postSolution\n\t\tSolutionGuid = {41165AF1-35BB-4832-A189-73060F82B01D}\n\tEndGlobalSection\nEndGlobal\n"
        },
        {
          "name": "azure-pipelines.yml",
          "type": "blob",
          "size": 33.5517578125,
          "content": "################################################################################\n# TorchSharp's PR validation build\n################################################################################\n\nname: $(TeamProject)_$(Build.DefinitionName)_$(SourceBranchName)_$(Date:yyyyMMdd)$(Rev:.r)\n\nparameters:\n  # Set this to 'true' to build the libtorch-* packages as part of main branch CI and\n  # push them to the artifacts feed of the Azure CI project\n  - name: BuildLibTorchPackages\n    type: boolean\n    default: false\n  - name: PushPackagesToFeed\n    type: boolean\n    default: false\n  # Set which source branch to build libtorch-* packages.\n  # The build-libtorch jobs are only run if the source branch is the same as this value.\n  # The default is 'main' branch.\n  - name: SourceBranchName\n    type: string\n    default: 'main'\n\nvariables:\n  MyRunNumber:  $[counter('MyRunNumber', 52201)]\n  LinuxPrepScript: |\n    ldd --version && (/sbin/ldconfig -p | grep stdc++) && (strings /usr/lib/x86_64-linux-gnu/libstdc++.so.6 | grep LIBCXX)\n    sudo apt-key adv --keyserver keyserver.ubuntu.com --recv-keys DE19EB17684BA42D\n    sudo apt-get -y update\n    sudo apt-get -y install cmake clang git libunwind8 curl libomp-dev libomp5 wget\n    wget https://packages.microsoft.com/config/ubuntu/20.04/packages-microsoft-prod.deb -O packages-microsoft-prod.deb\n    sudo dpkg --purge packages-microsoft-prod && sudo dpkg -i packages-microsoft-prod.deb\n    sudo apt-get update; sudo apt-get install -y apt-transport-https && sudo apt-get update\n    ldd --version && (/sbin/ldconfig -p | grep stdc++) && (strings /usr/lib/x86_64-linux-gnu/libstdc++.so.6 | grep LIBCXX)\n\nresources:\n  containers:\n#   - container: CentosContainer\n#     image: mcr.microsoft.com/dotnet-buildtools/prereqs:centos-7-mlnet-8bba86b-20190314145033\n# dotnet-buildtools/prereqs containers can be browsed at\n#   https://github.com/dotnet/versions/blob/main/build-info/docker/image-info.dotnet-dotnet-buildtools-prereqs-docker-main.json\n\n   - container: UbuntuContainer\n     image: mcr.microsoft.com/dotnet-buildtools/prereqs:ubuntu-20.04-20240708213715-dcf0bb9\n\njobs:\n- template: /build/ci/job-template.yml\n  parameters:\n    name: Ubuntu_x64\n    # This reports the GLIB_ and GLIBCXX_ dependencies on the system which ends up getting baked into\n    # the generated libTorchSharp.so (and partly determines which Linux systems that binary will\n    # be usable on), then installs clang-7.0 (LibTorch likes this for building C++ 14), then installs .NET 6.0\n    prepScript: ${{ variables.LinuxPrepScript }}\n    buildScript: dotnet build /p:SkipCuda=true -c\n    testScript: dotnet test /p:SkipCuda=true --blame test/TorchSharpTest/TorchSharpTest.csproj -c\n    pool:\n      vmImage: 'ubuntu-latest'\n    container: UbuntuContainer\n\n- template: /build/ci/job-template.yml\n  parameters:\n    prepScript: echo \"no prep needed\"\n    name: Windows_x64_NetCore\n    buildScript: dotnet build /p:SkipCuda=true /p:SkipNetFxBuild=true -c\n    testScript: dotnet test /p:SkipCuda=true /p:SkipNetFxBuild=true --blame test\\TorchSharpTest\\TorchSharpTest.csproj -c\n    pool:\n      vmImage: 'windows-latest'\n\n- template: /build/ci/job-template.yml\n  parameters:\n    prepScript: echo \"no prep needed\"\n    name: Windows_x64_NetFX\n    buildScript: dotnet build /p:SkipCuda=true /p:SkipNetCoreBuild=true -c\n    testScript: dotnet test /p:SkipCuda=true /p:SkipNetCoreBuild=true --blame test\\TorchSharpTest\\TorchSharpTest.csproj -c\n    pool:\n      vmImage: 'windows-latest'\n\n- template: /build/ci/job-template.yml\n  parameters:\n    prepScript: echo \"no prep needed\"\n    name: MacOS_arm64\n    buildScript: dotnet build /p:SkipCuda=true /p:TargetArchitecture=arm64 -c\n    testScript: echo \"Azure Pipelines does not support arm64 yet, can't run tests\"\n    pool:\n      vmImage: 'macos-latest'\n\n################################################################################\n# {Build} --> combine --> package to build native bits on multiple OS's\n################################################################################\n\n\n################################################################################\n- job: Linux_Native_Build_For_Packages\n################################################################################\n  condition: and(ne(variables['system.pullrequest.isfork'], true), eq(variables['build.sourcebranchname'], '${{ parameters.SourceBranchName }}'))\n  variables:\n    BuildConfig: Release\n    OfficialBuildId: $(BUILD.BUILDNUMBER)\n    DOTNET_CLI_TELEMETRY_OPTOUT: 1\n    DOTNET_SKIP_FIRST_TIME_EXPERIENCE: 1\n    DOTNET_MULTILEVEL_LOOKUP: 0\n  pool:\n    vmImage: 'ubuntu-latest'\n  container: UbuntuContainer\n  # Exact copy of the dependency install above - TODO share this somewhere\n  steps:\n  - task: UseDotNet@2\n    displayName: 'Use .NET Core sdk'\n    inputs:\n      packageType: sdk\n      version: 6.0.402\n      installationPath: $(Agent.ToolsDirectory)/dotnet\n\n  - script: ${{ variables.LinuxPrepScript }}\n    displayName: Install dependencies\n\n  - script: dotnet build -c $(BuildConfig) src/Redist/libtorch-cpu/libtorch-cpu.proj /p:UpdateSHA=true /p:SkipTests=true /p:TargetOS=linux /t:Build /p:IncludeLibTorchCpuPackages=true\n    condition: eq('${{ parameters.BuildLibTorchPackages }}', true)\n    displayName: Download libtorch native binaries\n\n  - script: dotnet build -c $(BuildConfig) src/Redist/libtorch-cuda-12.1/libtorch-cuda-12.1.proj /p:UpdateSHA=true /p:SkipTests=true /p:TargetOS=linux /t:Build /p:IncludeLibTorchCudaPackages=true\n    condition: eq('${{ parameters.BuildLibTorchPackages }}', true)\n    displayName: Download libtorch native CUDA binaries\n\n  - script: dotnet build -c $(BuildConfig) src/TorchSharp/TorchSharp.csproj /p:SkipCuda=true /p:SkipTests=true\n    displayName: Build linux\n\n  - script: dotnet build -c $(BuildConfig) src/TorchVision/TorchVision.csproj /p:SkipCuda=true /p:SkipTests=true\n    displayName: Build TorchVision\n\n  - script: dotnet build -c $(BuildConfig) src/TorchAudio/TorchAudio.csproj /p:SkipCuda=true /p:SkipTests=true\n    displayName: Build TorchAudio\n\n  - publish: $(Build.SourcesDirectory)/bin/obj/packprep/$(BuildConfig)\n    artifact: LinuxAssets\n\n################################################################################\n- job: Windows_Native_Build_For_Packages\n################################################################################\n  condition: and(ne(variables['system.pullrequest.isfork'], true), eq(variables['build.sourcebranchname'], '${{ parameters.SourceBranchName }}'))\n  variables:\n    BuildConfig: Release\n    OfficialBuildId: $(BUILD.BUILDNUMBER)\n    DOTNET_CLI_TELEMETRY_OPTOUT: 1\n    DOTNET_SKIP_FIRST_TIME_EXPERIENCE: 1\n    DOTNET_MULTILEVEL_LOOKUP: 0\n  pool:\n    vmImage: 'windows-latest'\n\n  steps:\n  - task: UseDotNet@2\n    displayName: 'Use .NET Core sdk'\n    inputs:\n      packageType: sdk\n      version: 6.0.402\n      installationPath: $(Agent.ToolsDirectory)/dotnet\n\n  - script: dotnet build -c $(BuildConfig) src/Redist/libtorch-cpu/libtorch-cpu.proj /p:UpdateSHA=true /p:SkipTests=true /p:TargetOS=windows /t:Build /p:IncludeLibTorchCpuPackages=true\n    displayName: Download libtorch native binaries\n\n  - script: dotnet build -c $(BuildConfig) src/Redist/libtorch-cuda-12.1/libtorch-cuda-12.1.proj /p:UpdateSHA=true /p:SkipTests=true /p:TargetOS=windows /t:Build /p:IncludeLibTorchCudaPackages=true\n    condition: eq('${{ parameters.BuildLibTorchPackages }}', true)\n    displayName: Download libtorch native CUDA binaries\n\n  - script: dotnet build -c $(BuildConfig) src/TorchSharp/TorchSharp.csproj /p:SkipCuda=true /p:SkipTests=true\n    condition: eq('${{ parameters.BuildLibTorchPackages }}', true)\n    displayName: Build Windows\n\n  - script: dotnet build -c $(BuildConfig) src/TorchVision/TorchVision.csproj /p:SkipCuda=true /p:SkipTests=true\n    displayName: Build TorchVision\n\n  - script: dotnet build -c $(BuildConfig) src/TorchAudio/TorchAudio.csproj /p:SkipCuda=true /p:SkipTests=true\n    displayName: Build TorchAudio\n\n  - publish: $(Build.SourcesDirectory)/bin/obj/packprep/$(BuildConfig)\n    artifact: WindowsAssets\n\n  # ################################################################################\n- job: MacOS_arm64_Native_Build_For_Packages\n  # ################################################################################\n  condition: and(ne(variables['system.pullrequest.isfork'], true), eq(variables['build.sourcebranchname'], '${{ parameters.SourceBranchName }}'))\n  variables:\n    BuildConfig: Release\n    OfficialBuildId: $(BUILD.BUILDNUMBER)\n    DOTNET_CLI_TELEMETRY_OPTOUT: 1\n    DOTNET_SKIP_FIRST_TIME_EXPERIENCE: 1\n    DOTNET_MULTILEVEL_LOOKUP: 0\n  pool:\n    vmImage: 'macos-latest'\n  steps:\n    - script: dotnet build -c $(BuildConfig) src/Redist/libtorch-cpu/libtorch-cpu.proj /p:UpdateSHA=true /p:TargetOS=mac /p:TargetArchitecture=arm64 /t:Build /p:IncludeLibTorchCpuPackages=true\n      displayName: Download libtorch native binaries\n\n    - script: dotnet build -c $(BuildConfig) src/TorchSharp/TorchSharp.csproj /p:SkipCuda=true /p:SkipTests=true /p:TargetArchitecture=arm64\n      displayName: Build mac-arm64\n\n    - script: dotnet build -c $(BuildConfig) src/TorchVision/TorchVision.csproj /p:SkipCuda=true /p:SkipTests=true /p:TargetArchitecture=arm64\n      displayName: Build TorchVision\n\n    - script: dotnet build -c $(BuildConfig) src/TorchAudio/TorchAudio.csproj /p:SkipCuda=true /p:SkipTests=true /p:TargetArchitecture=arm64\n      displayName: Build TorchAudio\n\n    - publish: $(Build.SourcesDirectory)/bin/obj/packprep/$(BuildConfig)\n      artifact: MacAssets_arm64\n\n\n################################################################################\n- job: Build_TorchSharp_And_libtorch_cpu_Packages\n################################################################################\n  condition: and(ne(variables['system.pullrequest.isfork'], true), eq(variables['build.sourcebranchname'], '${{ parameters.SourceBranchName }}'))\n  dependsOn:\n  - Linux_Native_Build_For_Packages\n  - Windows_Native_Build_For_Packages\n  - MacOS_arm64_Native_Build_For_Packages\n  variables:\n    BuildConfig: Release\n    OfficialBuildId: $(BUILD.BUILDNUMBER)\n    DOTNET_CLI_TELEMETRY_OPTOUT: 1\n    DOTNET_SKIP_FIRST_TIME_EXPERIENCE: 1\n    DOTNET_MULTILEVEL_LOOKUP: 0\n  pool:\n    vmImage: 'windows-latest'\n  steps:\n\n  # We are 10GB space-constrained on the Azure Pipelines CI system so clean up what we can\n  # yup we even nuke the .git\n  - script: rmdir /q /s .git\n    displayName: Clean up space (.git)\n    continueOnError: true\n\n    # Download all bits contributing to the packages from the Linux build\n  - download: current\n    artifact: LinuxAssets\n\n  - task: CopyFiles@2\n    displayName: Copy linux native assets (TorchSharp) to correct folder where the bits contributing to the packages are assembled\n    inputs:\n      sourceFolder: $(Pipeline.Workspace)/LinuxAssets/TorchSharp\n      targetFolder: $(Build.SourcesDirectory)/bin/obj/packprep/$(BuildConfig)/TorchSharp\n\n  - task: CopyFiles@2\n    displayName: Copy linux native assets (TorchAudio) to correct folder where the bits contributing to the packages are assembled\n    inputs:\n      sourceFolder: $(Pipeline.Workspace)/LinuxAssets/TorchAudio\n      targetFolder: $(Build.SourcesDirectory)/bin/obj/packprep/$(BuildConfig)/TorchAudio\n\n  - task: CopyFiles@2\n    displayName: Copy linux native assets (TorchVision) to correct folder where the bits contributing to the packages are assembled\n    inputs:\n      sourceFolder: $(Pipeline.Workspace)/LinuxAssets/TorchVision\n      targetFolder: $(Build.SourcesDirectory)/bin/obj/packprep/$(BuildConfig)/TorchVision\n\n  - task: CopyFiles@2\n    displayName: Copy linux native assets to correct folder where the bits contributing to the packages are assembled\n    inputs:\n      sourceFolder: $(Pipeline.Workspace)/LinuxAssets\n      targetFolder: $(Build.SourcesDirectory)/bin/obj/packprep/$(BuildConfig)\n\n  - script: rmdir /s /q  $(Pipeline.Workspace)\\LinuxAssets\n    displayName: Free up space (LinuxAssets in workspace)\n\n    # Download all bits contributing to the packages from the Mac build\n  - download: current\n    artifact: MacAssets_arm64\n\n  - task: CopyFiles@2\n    displayName: Copy mac-arm64 native assets (TorchSharp) to correct folder where the bits contributing to the packages are assembled\n    inputs:\n      sourceFolder: $(Pipeline.Workspace)/MacAssets_arm64/TorchSharp\n      targetFolder: $(Build.SourcesDirectory)/bin/obj/packprep/$(BuildConfig)/TorchSharp\n\n  - task: CopyFiles@2\n    displayName: Copy mac-arm64 native assets (TorchAudio) to correct folder where the bits contributing to the packages are assembled\n    inputs:\n      sourceFolder: $(Pipeline.Workspace)/MacAssets_arm64/TorchAudio\n      targetFolder: $(Build.SourcesDirectory)/bin/obj/packprep/$(BuildConfig)/TorchAudio\n\n  - task: CopyFiles@2\n    displayName: Copy mac-arm64 native assets (TorchVision) to correct folder where the bits contributing to the packages are assembled\n    inputs:\n      sourceFolder: $(Pipeline.Workspace)/MacAssets_arm64/TorchVision\n      targetFolder: $(Build.SourcesDirectory)/bin/obj/packprep/$(BuildConfig)/TorchVision\n\n  - task: CopyFiles@2\n    displayName: Copy mac-arm64 native assets (libtorch-cpu) to correct folder where the bits contributing to the packages are assembled\n    inputs:\n      sourceFolder: $(Pipeline.Workspace)/MacAssets_arm64\n      targetFolder: $(Build.SourcesDirectory)/bin/obj/packprep/$(BuildConfig)\n\n  - script: rmdir /s /q  $(Pipeline.Workspace)\\MacAssets_arm64\n    displayName: Free up space (MacAssets_arm64 in workspace)\n\n  - download: current\n    artifact: WindowsAssets\n\n  - task: CopyFiles@2\n    displayName: Copy windows native assets (TorchSharp) to correct folder where the bits contributing to the packages are assembled\n    inputs:\n      sourceFolder: $(Pipeline.Workspace)/WindowsAssets/TorchSharp\n      targetFolder: $(Build.SourcesDirectory)/bin/obj/packprep/$(BuildConfig)/TorchSharp\n\n  - task: CopyFiles@2\n    displayName: Copy windows native assets (TorchAudio) to correct folder where the bits contributing to the packages are assembled\n    inputs:\n      sourceFolder: $(Pipeline.Workspace)/WindowsAssets/TorchAudio\n      targetFolder: $(Build.SourcesDirectory)/bin/obj/packprep/$(BuildConfig)/TorchAudio\n\n  - task: CopyFiles@2\n    displayName: Copy windows native assets (TorchVision) to correct folder where the bits contributing to the packages are assembled\n    inputs:\n      sourceFolder: $(Pipeline.Workspace)/WindowsAssets/TorchVision\n      targetFolder: $(Build.SourcesDirectory)/bin/obj/packprep/$(BuildConfig)/TorchVision\n\n  - task: CopyFiles@2\n    displayName: Copy windows native assets (libtorch-cpu) to correct folder where the bits contributing to the packages are assembled\n    inputs:\n      sourceFolder: $(Pipeline.Workspace)/WindowsAssets/libtorch-cpu-win-x64\n      targetFolder: $(Build.SourcesDirectory)/bin/obj/packprep/$(BuildConfig)/libtorch-cpu-win-x64\n\n  - script: rmdir /s /q  $(Pipeline.Workspace)\\WindowsAssets\n    displayName: Free up space (windows assets in workspace)\n\n  - script: dotnet restore pkg/pack.proj /p:Configuration=Release\n    displayName: Restore package projects\n\n  # Pack TorchSharp (and libtorch-cpu if BuildLibTorchPackages is true)\n  - script: dotnet pack -c $(BuildConfig) --no-build -v:n /p:SkipNative=true /p:SkipTests=true /p:IncludeTorchSharpPackage=true /p:IncludeLibTorchCpuPackages=${{ parameters.BuildLibTorchPackages }} /p:GenerateCompatibilitySuppressionFile=true pkg/pack.proj\n    displayName: Create Packages\n\n  - script: rmdir /q /s bin\\obj\n    displayName: Clean up space (bin\\obj)\n    continueOnError: true\n\n  - task: CopyFiles@2\n    displayName: Copy packaged assets to staging folder\n    inputs:\n      sourceFolder: $(Build.SourcesDirectory)/bin/packages/$(BuildConfig)\n      targetFolder: $(Build.ArtifactStagingDirectory)\n\n  - publish: $(Build.ArtifactStagingDirectory)\n    displayName: Publish build packages\n    artifact: BuildTorchSharpPackages\n\n  - publish: $(Build.SourcesDirectory)/config\n    displayName: Publish signing config\n    artifact: config\n\n################################################################################\n# Only run if BuildLibTorchPackages is true\n- job: Build_libtorch_cuda_win_Packages\n################################################################################\n  condition: and(ne(variables['system.pullrequest.isfork'], true), eq(variables['build.sourcebranchname'], '${{ parameters.SourceBranchName }}'), eq('${{ parameters.BuildLibTorchPackages }}', true))\n  dependsOn:\n  - Windows_Native_Build_For_Packages\n  variables:\n    BuildConfig: Release\n    OfficialBuildId: $(BUILD.BUILDNUMBER)\n    DOTNET_CLI_TELEMETRY_OPTOUT: 1\n    DOTNET_SKIP_FIRST_TIME_EXPERIENCE: 1\n    DOTNET_MULTILEVEL_LOOKUP: 0\n  pool:\n    vmImage: 'windows-latest'\n  steps:\n\n  # We are 10GB space-constrained on the Azure Pipelines CI system so clean up what we can\n  # yup we even nuke the .git\n  - script: rmdir /q /s .git\n    displayName: Clean up space (.git)\n    continueOnError: true\n\n  - download: current\n    artifact: WindowsAssets\n\n  - task: CopyFiles@2\n    displayName: Copy windows native assets to correct folder where the bits contributing to the packages are assembled\n    inputs:\n      sourceFolder: $(Pipeline.Workspace)/WindowsAssets\n      targetFolder: $(Build.SourcesDirectory)/bin/obj/packprep/$(BuildConfig)\n\n  - script: rmdir /s /q  $(Pipeline.Workspace)\\WindowsAssets\n    displayName: Free up space (windows assets in workspace)\n\n  - script: dotnet restore pkg/pack.proj /p:Configuration=Release\n    displayName: Restore package projects\n\n  - script: dotnet pack -c $(BuildConfig) --no-build -v:n /p:SkipNative=true /p:SkipTests=true /p:IncludeTorchSharpPackage=false /p:IncludeLibTorchCpuPackages=false /p:IncludeLibTorchCudaPackages=true pkg/pack.proj\n    displayName: Create Packages\n\n  # We are 10GB space-constrained on the Azure Pipelines CI system so clean up what we can\n  - script: rmdir /q /s bin\\obj\n    displayName: Clean up space (bin\\obj)\n    continueOnError: true\n\n  - task: CopyFiles@2\n    displayName: Copy packaged assets to staging folder\n    inputs:\n      sourceFolder: $(Build.SourcesDirectory)/bin/packages/$(BuildConfig)\n      targetFolder: $(Build.ArtifactStagingDirectory)\n\n  - publish: $(Build.ArtifactStagingDirectory)\n    displayName: Publish Windows CUDA build packages\n    artifact: BuildWinCUDAPackages\n\n################################################################################\n- job: Build_libtorch_cuda_linux_Packages\n################################################################################\n  condition: and(ne(variables['system.pullrequest.isfork'], true), eq(variables['build.sourcebranchname'], '${{ parameters.SourceBranchName }}'), eq('${{ parameters.BuildLibTorchPackages }}', true))\n  dependsOn:\n  - Linux_Native_Build_For_Packages\n  variables:\n    BuildConfig: Release\n    OfficialBuildId: $(BUILD.BUILDNUMBER)\n    DOTNET_CLI_TELEMETRY_OPTOUT: 1\n    DOTNET_SKIP_FIRST_TIME_EXPERIENCE: 1\n    DOTNET_MULTILEVEL_LOOKUP: 0\n  pool:\n    vmImage: 'ubuntu-latest'\n  container: UbuntuContainer\n  # Exact copy of the dependency install above - TODO share this somewhere\n  steps:\n  - task: UseDotNet@2\n    displayName: 'Use .NET Core sdk'\n    inputs:\n      packageType: sdk\n      version: 6.x\n      installationPath: $(Agent.ToolsDirectory)/dotnet\n\n  - script: ${{ variables.LinuxPrepScript }}\n    displayName: Install dependencies\n\n  # We are 10GB space-constrained on the Azure Pipelines CI system so clean up what we can\n  # yup we even nuke the .git\n  - script: rm -fr .git\n    displayName: Clean up space (.git)\n    continueOnError: true\n\n  - download: current\n    artifact: LinuxAssets\n\n  - task: CopyFiles@2\n    displayName: Copy linux native assets to correct folder where the bits contributing to the packages are assembled\n    inputs:\n      sourceFolder: $(Pipeline.Workspace)/LinuxAssets\n      targetFolder: $(Build.SourcesDirectory)/bin/obj/packprep/$(BuildConfig)\n\n  - script: rm -fr  $(Pipeline.Workspace)/LinuxAssets\n    displayName: Free up space (linux assets in workspace)\n\n  - script: dotnet restore pkg/pack.proj /p:Configuration=Release\n    displayName: Restore package projects\n\n  - script: dotnet pack -c $(BuildConfig) --no-build -v:n /p:SkipNative=true /p:SkipTests=true /p:ApiCompatGenerateSuppressionFile=true /p:IncludeTorchSharpPackage=false /p:IncludeLibTorchCpuPackages=false /p:IncludeLibTorchCudaPackages=true pkg/pack.proj\n    displayName: Create Packages\n\n  # We are 10GB space-constrained on the Azure Pipelines CI system so clean up what we can\n  - script: rm -fr bin/obj\n    displayName: Clean up space (bin/obj)\n    continueOnError: true\n\n  - task: CopyFiles@2\n    displayName: Copy packaged assets to staging folder\n    inputs:\n      sourceFolder: $(Build.SourcesDirectory)/bin/packages/$(BuildConfig)\n      targetFolder: $(Build.ArtifactStagingDirectory)\n\n  - publish: $(Build.ArtifactStagingDirectory)\n    displayName: Publish Linux CUDA build packages\n    artifact: BuildLinuxCUDAPackages\n\n################################################################################\n- job: CodeSign_Core\n################################################################################\n  condition: and(ne(variables['system.pullrequest.isfork'], true), eq(variables['build.sourcebranchname'], '${{ parameters.SourceBranchName }}'))\n  dependsOn:\n  - Build_TorchSharp_And_libtorch_cpu_Packages\n  variables:\n  - group: SignClient Credentials\n  pool:\n    vmImage: 'windows-latest'\n  steps:\n\n  - task: DotNetCoreCLI@2\n    inputs:\n      command: custom\n      custom: tool\n      arguments: install --tool-path . SignClient\n    displayName: Install SignTool tool\n\n  - download: current\n    displayName: Download configuration\n    artifact: config\n\n  - download: current\n    displayName: Download TorchSharp Packages\n    artifact: BuildTorchSharpPackages\n\n  - pwsh: |\n      .\\SignClient 'Sign' `\n      --baseDirectory '$(Pipeline.Workspace)\\BuildTorchSharpPackages' `\n      --input '**/*.nupkg' `\n      --config '$(Pipeline.Workspace)\\config\\SignClient.json' `\n      --filelist '$(Pipeline.Workspace)\\config\\signedfiles.txt' `\n      --user '$(SignClientUser)' `\n      --secret '$(SignClientSecret)' `\n      --name 'TorchSharp' `\n      --description 'TorchSharp' `\n      --descriptionUrl 'https://github.com/dotnet/TorchSharp'\n    displayName: Sign packages\n\n  - publish: $(Pipeline.Workspace)/BuildTorchSharpPackages\n    displayName: Publish Signed TorchSharp Packages\n    artifact: SignedTorchSharpPackages\n    continueOnError: true\n\n  - script: rmdir /s /q  $(Pipeline.Workspace)\\BuildTorchSharpPackages\n    displayName: Free up space (TorchSharp packages in workspace)\n\n################################################################################\n- job: CodeSign_Extras\n################################################################################\n  condition: and(ne(variables['system.pullrequest.isfork'], true), eq(variables['build.sourcebranchname'], '${{ parameters.SourceBranchName }}'), eq('${{ parameters.BuildLibTorchPackages }}', true))\n  dependsOn:\n  - Build_libtorch_cuda_win_Packages\n  - Build_libtorch_cuda_linux_Packages\n  variables:\n  - group: SignClient Credentials\n  pool:\n    vmImage: 'windows-latest'\n  steps:\n\n  - task: DotNetCoreCLI@2\n    inputs:\n      command: custom\n      custom: tool\n      arguments: install --tool-path . SignClient\n    displayName: Install SignTool tool\n\n  - download: current\n    displayName: Download configuration\n    artifact: config\n\n  - download: current\n    displayName: Download Windows CUDA Packages\n    artifact: BuildWinCUDAPackages\n\n  - pwsh: |\n      .\\SignClient 'Sign' `\n      --baseDirectory '$(Pipeline.Workspace)\\BuildWinCUDAPackages' `\n      --input '**/*.nupkg' `\n      --config '$(Pipeline.Workspace)\\config\\SignClient.json' `\n      --filelist '$(Pipeline.Workspace)\\config\\signedfiles.txt' `\n      --user '$(SignClientUser)' `\n      --secret '$(SignClientSecret)' `\n      --name 'TorchSharp' `\n      --description 'TorchSharp' `\n      --descriptionUrl 'https://github.com/dotnet/TorchSharp'\n    displayName: Sign packages\n\n  - publish: $(Pipeline.Workspace)/BuildWinCUDAPackages\n    displayName: Publish Signed Windows CUDA Packages\n    artifact: SignedWinCUDAPackages\n    continueOnError: true\n\n  - script: rmdir /s /q  $(Pipeline.Workspace)\\BuildWinCUDAPackages\n    displayName: Free up space (TorchSharp packages in workspace)\n\n  - download: current\n    displayName: Download Linux CUDA Packages\n    artifact: BuildLinuxCUDAPackages\n\n  - pwsh: |\n      .\\SignClient 'Sign' `\n      --baseDirectory '$(Pipeline.Workspace)\\BuildLinuxCUDAPackages' `\n      --input '**/*.nupkg' `\n      --config '$(Pipeline.Workspace)\\config\\SignClient.json' `\n      --filelist '$(Pipeline.Workspace)\\config\\signedfiles.txt' `\n      --user '$(SignClientUser)' `\n      --secret '$(SignClientSecret)' `\n      --name 'TorchSharp' `\n      --description 'TorchSharp' `\n      --descriptionUrl 'https://github.com/dotnet/TorchSharp'\n    displayName: Sign packages\n\n  - publish: $(Pipeline.Workspace)/BuildLinuxCUDAPackages\n    displayName: Publish Signed Linux CUDA Packages\n    artifact: SignedLinuxCUDAPackages\n    continueOnError: true\n\n  - script: rmdir /s /q  $(Pipeline.Workspace)\\BuildLinuxCUDAPackages\n    displayName: Free up space (TorchSharp packages in workspace)\n\n################################################################################\n- job: Push_TorchSharp_And_libtorch_cpu_Packages\n################################################################################\n  condition: and(eq('${{ parameters.PushPackagesToFeed }}', true), ne(variables['system.pullrequest.isfork'], true), eq(variables['build.sourcebranchname'], '${{ parameters.SourceBranchName }}'))\n  dependsOn:\n  - Build_TorchSharp_And_libtorch_cpu_Packages\n  - CodeSign_Core\n  variables:\n    BuildConfig: Release\n    OfficialBuildId: $(BUILD.BUILDNUMBER)\n    DOTNET_CLI_TELEMETRY_OPTOUT: 1\n    DOTNET_SKIP_FIRST_TIME_EXPERIENCE: 1\n    DOTNET_MULTILEVEL_LOOKUP: 0\n  pool:\n    vmImage: 'windows-latest'\n  steps:\n\n  # Push packages to feed\n  #\n  # Doing these one by one as we're getting a lot of failures pushing them\n  # Also replaying them multiple times for the same reason\n  #\n  - task: NuGetAuthenticate@0\n    displayName: 'NuGet Authenticate'\n\n  - download: current\n    displayName: Download Signed TorchSharp Packages\n    artifact: SignedTorchSharpPackages\n\n  - task: NuGetCommand@2\n    displayName: 'NuGet push (TorchSharp)'\n    inputs:\n      command: push\n      packagesToPush:  '$(Pipeline.Workspace)/**/TorchSharp.*.nupkg'\n      publishVstsFeed: 'TorchSharp/TestPackages'\n      allowPackageConflicts: true\n    continueOnError: true\n\n  - task: NuGetCommand@2\n    displayName: 'NuGet push (TorchAudio)'\n    inputs:\n      command: push\n      packagesToPush:  '$(Pipeline.Workspace)/**/TorchAudio.*.nupkg'\n      publishVstsFeed: 'TorchSharp/SignedPackages'\n      allowPackageConflicts: true\n    continueOnError: true\n\n  - task: NuGetCommand@2\n    displayName: 'NuGet push (TorchVision)'\n    inputs:\n      command: push\n      packagesToPush:  '$(Pipeline.Workspace)/**/TorchVision.*.nupkg'\n      publishVstsFeed: 'TorchSharp/SignedPackages'\n      allowPackageConflicts: true\n    continueOnError: true\n\n  - task: NuGetCommand@2\n    displayName: 'NuGet push (TorchSharp-cpu)'\n    inputs:\n      command: push\n      packagesToPush:  '$(Pipeline.Workspace)/**/TorchSharp-*.nupkg'\n      publishVstsFeed: 'TorchSharp/TestPackages'\n      allowPackageConflicts: true\n    continueOnError: true\n\n  # push the CPU runtime packages\n  - task: NuGetCommand@2\n    displayName: 'NuGet push (libtorch-cpu)'\n    inputs:\n      command: push\n      packagesToPush:  '$(Pipeline.Workspace)/**/libtorch-cpu*.nupkg'\n      publishVstsFeed: 'TorchSharp/TestPackages'\n      allowPackageConflicts: true\n    continueOnError: true\n\n  # push the CPU runtime packages (retry - we get so many failures!)\n  - task: NuGetCommand@2\n    displayName: 'NuGet push (libtorch-cpu - retry)'\n    inputs:\n      command: push\n      packagesToPush:  '$(Pipeline.Workspace)/**/libtorch-cpu*.nupkg'\n      publishVstsFeed: 'TorchSharp/TestPackages'\n      allowPackageConflicts: true\n    continueOnError: true\n\n  # push the CPU runtime packages (retry - we get so many failures!)\n  - task: NuGetCommand@2\n    displayName: 'NuGet push (libtorch-cpu - retry)'\n    inputs:\n      command: push\n      packagesToPush:  '$(Pipeline.Workspace)/**/libtorch-cpu*.nupkg'\n      publishVstsFeed: 'TorchSharp/TestPackages'\n      allowPackageConflicts: true\n    continueOnError: true\n\n  # Terminate all dotnet build processes.\n  - script: dotnet build-server shutdown\n    displayName: Dotnet Server Shutdown\n\n\n################################################################################\n# Only run if BuildLibTorchPackages is true\n- job: Push_libtorch_cuda_win_Packages\n################################################################################\n  condition: and(eq('${{ parameters.BuildLibTorchPackages }}', true), eq('${{ parameters.PushPackagesToFeed }}', true), ne(variables['system.pullrequest.isfork'], true))\n  dependsOn:\n  - Build_libtorch_cuda_win_Packages\n  - CodeSign_Extras\n  variables:\n    BuildConfig: Release\n    OfficialBuildId: $(BUILD.BUILDNUMBER)\n    DOTNET_CLI_TELEMETRY_OPTOUT: 1\n    DOTNET_SKIP_FIRST_TIME_EXPERIENCE: 1\n    DOTNET_MULTILEVEL_LOOKUP: 0\n  pool:\n    vmImage: 'windows-latest'\n  steps:\n\n  # Push packages to feed\n  #\n  # Doing these one by one as we're getting a lot of failures pushing them\n  # Also replaying them multiple times for the same reason\n  #\n  - task: NuGetAuthenticate@0\n    displayName: 'NuGet Authenticate'\n\n  - download: current\n    displayName: Download Signed Windows CUDA Packages\n    artifact: SignedWinCUDAPackages\n\n  # push the Windows Cuda packages\n  - task: NuGetCommand@2\n    displayName: 'NuGet push (cuda win-x64)'\n    inputs:\n      command: push\n      packagesToPush:  '$(Pipeline.Workspace)/**/*cuda*win*.nupkg'\n      publishVstsFeed: 'TorchSharp/TestPackages'\n      allowPackageConflicts: true\n      # often fails - try but ignore the error until we sort it out\n    continueOnError: true\n\n  # push the Windows Cuda packages\n  - task: NuGetCommand@2\n    displayName: 'NuGet push (cuda win-x64 retry)'\n    inputs:\n      command: push\n      packagesToPush:  '$(Pipeline.Workspace)/**/*cuda*win*.nupkg'\n      publishVstsFeed: 'TorchSharp/TestPackages'\n      allowPackageConflicts: true\n      # often fails - try but ignore the error until we sort it out\n    continueOnError: true\n\n  # push the Windows Cuda packages\n  - task: NuGetCommand@2\n    displayName: 'NuGet push (cuda win-x64 retry)'\n    inputs:\n      command: push\n      packagesToPush:  '$(Pipeline.Workspace)/**/*cuda*win*.nupkg'\n      publishVstsFeed: 'TorchSharp/TestPackages'\n      allowPackageConflicts: true\n      # often fails - try but ignore the error until we sort it out\n    continueOnError: true\n\n  # push the Windows Cuda packages\n  - task: NuGetCommand@2\n    displayName: 'NuGet push (cuda win-x64 retry)'\n    inputs:\n      command: push\n      packagesToPush:  '$(Pipeline.Workspace)/**/*cuda*win*.nupkg'\n      publishVstsFeed: 'TorchSharp/TestPackages'\n      allowPackageConflicts: true\n      # often fails - try but ignore the error until we sort it out\n    continueOnError: true\n\n  # push the Windows Cuda packages\n  - task: NuGetCommand@2\n    displayName: 'NuGet push (cuda win-x64 retry)'\n    inputs:\n      command: push\n      packagesToPush:  '$(Pipeline.Workspace)/**/*cuda*win*.nupkg'\n      publishVstsFeed: 'TorchSharp/TestPackages'\n      allowPackageConflicts: true\n      # often fails - try but ignore the error until we sort it out\n    continueOnError: true\n\n\n################################################################################\n- job: Push_libtorch_cuda_linux_Packages\n################################################################################\n  condition: and(eq('${{ parameters.BuildLibTorchPackages }}', 'true'), eq('${{ parameters.PushPackagesToFeed }}', true), ne(variables['system.pullrequest.isfork'], true))\n  dependsOn:\n  - Build_libtorch_cuda_linux_Packages\n  - CodeSign_Extras\n  variables:\n    BuildConfig: Release\n    OfficialBuildId: $(BUILD.BUILDNUMBER)\n    DOTNET_CLI_TELEMETRY_OPTOUT: 1\n    DOTNET_SKIP_FIRST_TIME_EXPERIENCE: 1\n    DOTNET_MULTILEVEL_LOOKUP: 0\n  pool:\n    vmImage: 'windows-latest'\n  # container: UbuntuContainer\n  # Exact copy of the dependency install above - TODO share this somewhere\n  steps:\n\n  # Push packages to feed\n  #\n  # Doing these one by one as we're getting a lot of failures pushing them\n  # Also replaying them multiple times for the same reason\n  #\n  - task: NuGetAuthenticate@0\n    displayName: 'NuGet Authenticate'\n\n  - download: current\n    displayName: Download Signed Linux CUDA Packages\n    artifact: SignedLinuxCUDAPackages\n\n  # push the Linux Cuda packages\n  - task: NuGetCommand@2\n    displayName: 'NuGet push (cuda linux-x64)'\n    inputs:\n      command: push\n      packagesToPush:  '$(Pipeline.Workspace)/**/*cuda*linux*.nupkg'\n      publishVstsFeed: 'TorchSharp/TestPackages'\n      allowPackageConflicts: true\n      # often fails - try but ignore the error until we sort it out\n    continueOnError: true\n\n  # push the Linux Cuda packages\n  - task: NuGetCommand@2\n    displayName: 'NuGet push (cuda linux-x64)'\n    inputs:\n      command: push\n      packagesToPush:  '$(Pipeline.Workspace)/**/*cuda*linux*.nupkg'\n      publishVstsFeed: 'TorchSharp/TestPackages'\n      allowPackageConflicts: true\n      # often fails - try but ignore the error until we sort it out\n    continueOnError: true\n\n  # push the Linux Cuda packages\n  - task: NuGetCommand@2\n    displayName: 'NuGet push (cuda linux-x64)'\n    inputs:\n      command: push\n      packagesToPush:  '$(Pipeline.Workspace)/**/*cuda*linux*.nupkg'\n      publishVstsFeed: 'TorchSharp/TestPackages'\n      allowPackageConflicts: true\n      # often fails - try but ignore the error until we sort it out\n    continueOnError: true\n\n  # push the Linux Cuda packages\n  - task: NuGetCommand@2\n    displayName: 'NuGet push (cuda linux-x64)'\n    inputs:\n      command: push\n      packagesToPush:  '$(Pipeline.Workspace)/**/*cuda*linux*.nupkg'\n      publishVstsFeed: 'TorchSharp/TestPackages'\n      allowPackageConflicts: true\n      # often fails - try but ignore the error until we sort it out\n    continueOnError: true\n"
        },
        {
          "name": "build",
          "type": "tree",
          "content": null
        },
        {
          "name": "codecov.yml",
          "type": "blob",
          "size": 0.3251953125,
          "content": "# https://docs.codecov.io/docs/codecov-yaml\n# https://github.com/codecov/support/wiki/Codecov-Yaml\n\ncoverage:\n  status:\n    project:\n      default: false\n    patch:\n      default: false\n  fixes:\n    - \"build/::/\"\n\ncomment:\n  layout: \"diff, flags, files\"\n\nflags:\n  production:\n    paths:\n      - src/\n  test:\n    paths:\n      - test/\n"
        },
        {
          "name": "config",
          "type": "tree",
          "content": null
        },
        {
          "name": "docfx",
          "type": "tree",
          "content": null
        },
        {
          "name": "global.json",
          "type": "blob",
          "size": 0.09375,
          "content": "{\n  \"sdk\": {\n    \"version\": \"6.0\",\n    \"rollForward\": \"minor\",\n    \"allowPrerelease\": true\n  }\n}"
        },
        {
          "name": "linux_cuda.txt",
          "type": "blob",
          "size": 1.064453125,
          "content": "      331,816 libaoti_custom_ops.so\n      288,672 libbackend_with_compiler.so\n    1,215,456 libc10.so\n      833,576 libc10d_cuda_test.so\n    1,482,296 libc10_cuda.so\n       22,545 libcaffe2_nvrtc.so\n  107,496,985 libcublas-37d11411.so.12\n  515,090,264 libcublasLt-f97bfc2c.so.12\n      695,585 libcudart-9335f6a2.so.12\n      104,664 libcudnn.so.9\n  240,675,313 libcudnn_adv.so.9\n    4,700,665 libcudnn_cnn.so.9\n  569,612,689 libcudnn_engines_precompiled.so.9\n    9,562,545 libcudnn_engines_runtime_compiled.so.9\n    3,141,321 libcudnn_graph.so.9\n   86,313,377 libcudnn_heuristic.so.9\n  108,399,185 libcudnn_ops.so.9\n      283,265 libgomp-98b21ff3.so.1\n      244,496 libjitbackend_test.so\n      390,312 libnnapi_backend.so\n   56,875,329 libnvrtc-b51b459d.so.12\n    6,846,017 libnvrtc-builtins.so\n       43,681 libnvToolsExt-847d78f2.so.1\n       53,625 libshm.so\n       15,704 libtorch.so\n    1,025,232 libtorchbind_test.so\n  447,891,009 libtorch_cpu.so\n1,490,739,561 libtorch_cuda.so\n  389,644,088 libtorch_cuda_linalg.so\n       16,881 libtorch_global_deps.so\n   28,364,592 libtorch_python.so"
        },
        {
          "name": "pkg",
          "type": "tree",
          "content": null
        },
        {
          "name": "src",
          "type": "tree",
          "content": null
        },
        {
          "name": "test",
          "type": "tree",
          "content": null
        },
        {
          "name": "vision",
          "type": "commit",
          "content": null
        },
        {
          "name": "windows_cuda.txt",
          "type": "blob",
          "size": 1.013671875,
          "content": "    358,912 asmjit.dll\n    877,568 c10.dll\n    379,392 c10_cuda.dll\n     16,384 caffe2_nvrtc.dll\n 98,058,240 cublas64_12.dll\n538,818,048 cublasLt64_12.dll\n    527,872 cudart64_12.dll\n    438,840 cudnn64_9.dll\n241,576,488 cudnn_adv64_9.dll\n  4,019,752 cudnn_cnn64_9.dll\n588,910,632 cudnn_engines_precompiled64_9.dll\n  8,235,560 cudnn_engines_runtime_compiled64_9.dll\n  2,160,680 cudnn_graph64_9.dll\n 85,741,608 cudnn_heuristic64_9.dll\n107,721,256 cudnn_ops64_9.dll\n190,346,752 cufft64_11.dll\n    295,936 cufftw64_11.dll\n  4,327,424 cupti64_2023.1.1.dll\n 63,505,408 curand64_10.dll\n110,190,080 cusolver64_11.dll\n 77,008,384 cusolverMg64_11.dll\n262,348,288 cusparse64_12.dll\n  4,961,280 fbgemm.dll\n  1,250,312 libiomp5md.dll\n     41,992 libiompstubs5md.dll\n 34,385,920 nvJitLink_120_0.dll\n  7,001,600 nvrtc-builtins64_121.dll\n 42,161,152 nvrtc64_120_0.dll\n     48,128 nvToolsExt64_1.dll\n      9,728 torch.dll\n249,325,056 torch_cpu.dll\n927,949,824 torch_cuda.dll\n      9,728 torch_global_deps.dll\n    195,072 uv.dll\n     89,088 zlibwapi.dll\n\n"
        }
      ]
    }
  ]
}