{
  "metadata": {
    "timestamp": 1736711115477,
    "page": 941,
    "hasNextPage": true,
    "endCursor": "Y3Vyc29yOjk1MA==",
    "completionStatus": "IN_PROGRESS"
  },
  "repositories": [
    {
      "nameWithOwner": "mariotoffia/FluentDocker",
      "stars": 1345,
      "defaultBranch": "master",
      "files": [
        {
          "name": ".circleci",
          "type": "tree",
          "content": null
        },
        {
          "name": ".editorconfig",
          "type": "blob",
          "size": 13.6328125,
          "content": "root = true\n\n[*]\n# http://kent-boogaart.com/blog/editorconfig-reference-for-c-developers#end_of_line\nend_of_line = lf\n\n# http://kent-boogaart.com/blog/editorconfig-reference-for-c-developers#indent_size\nindent_size = 2\n\n# http://kent-boogaart.com/blog/editorconfig-reference-for-c-developers#tab_width\ntab_width = 2\n\n# http://kent-boogaart.com/blog/editorconfig-reference-for-c-developers#indent_style\nindent_style = space\n\n# http://kent-boogaart.com/blog/editorconfig-reference-for-c-developers#insert_final_newline\ninsert_final_newline = true\n\ncharset = utf-8\n\ntrim_trailing_whitespace = true\n\n[*.cs]\n# http://kent-boogaart.com/blog/editorconfig-reference-for-c-developers#indent_size\nindent_size = 2\n\n# http://kent-boogaart.com/blog/editorconfig-reference-for-c-developers#csharp_indent_block_contents\ncsharp_indent_block_contents = true\n\n# http://kent-boogaart.com/blog/editorconfig-reference-for-c-developers#csharp_indent_braces\ncsharp_indent_braces = false\n\n# http://kent-boogaart.com/blog/editorconfig-reference-for-c-developers#csharp_indent_case_contents\ncsharp_indent_case_contents = true\n\n# http://kent-boogaart.com/blog/editorconfig-reference-for-c-developers#csharp_indent_labels\ncsharp_indent_labels = one_less_than_current\n\n# http://kent-boogaart.com/blog/editorconfig-reference-for-c-developers#csharp_indent_switch_labels\ncsharp_indent_switch_labels = true\n\n# http://kent-boogaart.com/blog/editorconfig-reference-for-c-developers#csharp_new_line_before_catch\ncsharp_new_line_before_catch = true\n\n# http://kent-boogaart.com/blog/editorconfig-reference-for-c-developers#csharp_new_line_before_else\ncsharp_new_line_before_else = true\n\n# http://kent-boogaart.com/blog/editorconfig-reference-for-c-developers#csharp_new_line_before_finally\ncsharp_new_line_before_finally = true\n\n# http://kent-boogaart.com/blog/editorconfig-reference-for-c-developers#csharp_new_line_before_members_in_anonymous_types\ncsharp_new_line_before_members_in_anonymous_types = true\n\n# http://kent-boogaart.com/blog/editorconfig-reference-for-c-developers#csharp_new_line_before_members_in_object_initializers\ncsharp_new_line_before_members_in_object_initializers = true\n\n# http://kent-boogaart.com/blog/editorconfig-reference-for-c-developers#csharp_new_line_before_open_brace\ncsharp_new_line_before_open_brace = all\n\n# http://kent-boogaart.com/blog/editorconfig-reference-for-c-developers#csharp_new_line_between_query_expression_clauses\ncsharp_new_line_between_query_expression_clauses = true\n\n# http://kent-boogaart.com/blog/editorconfig-reference-for-c-developers#csharp_prefer_braces\n# csharp_prefer_braces = true:error\n\n# http://kent-boogaart.com/blog/editorconfig-reference-for-c-developers#csharp_prefer_simple_default_expression\ncsharp_prefer_simple_default_expression = true:error\n\n# http://kent-boogaart.com/blog/editorconfig-reference-for-c-developers#csharp_preserve_single_line_blocks\ncsharp_preserve_single_line_blocks = true\n\n# http://kent-boogaart.com/blog/editorconfig-reference-for-c-developers#csharp_preserve_single_line_statements\ncsharp_preserve_single_line_statements = false\n\n# http://kent-boogaart.com/blog/editorconfig-reference-for-c-developers#csharp_space_after_cast\ncsharp_space_after_cast = false\n\n# http://kent-boogaart.com/blog/editorconfig-reference-for-c-developers#csharp_space_after_colon_in_inheritance_clause\ncsharp_space_after_colon_in_inheritance_clause = true\n\n# http://kent-boogaart.com/blog/editorconfig-reference-for-c-developers#csharp_space_after_comma\ncsharp_space_after_comma = true\n\n# http://kent-boogaart.com/blog/editorconfig-reference-for-c-developers#csharp_space_after_dot\ncsharp_space_after_dot = false\n\n# http://kent-boogaart.com/blog/editorconfig-reference-for-c-developers#csharp_space_after_keywords_in_control_flow_statements\ncsharp_space_after_keywords_in_control_flow_statements = true\n\n# http://kent-boogaart.com/blog/editorconfig-reference-for-c-developers#csharp_space_after_semicolon_in_for_statement\ncsharp_space_after_semicolon_in_for_statement = true\n\n# http://kent-boogaart.com/blog/editorconfig-reference-for-c-developers#csharp_space_around_binary_operators\ncsharp_space_around_binary_operators = before_and_after\n\n# http://kent-boogaart.com/blog/editorconfig-reference-for-c-developers#csharp_space_around_declaration_statements\ncsharp_space_around_declaration_statements = do_not_ignore\n\n# http://kent-boogaart.com/blog/editorconfig-reference-for-c-developers#csharp_space_before_colon_in_inheritance_clause\ncsharp_space_before_colon_in_inheritance_clause = true\n\n# http://kent-boogaart.com/blog/editorconfig-reference-for-c-developers#csharp_space_before_comma\ncsharp_space_before_comma = false\n\n# http://kent-boogaart.com/blog/editorconfig-reference-for-c-developers#csharp_space_before_dot\ncsharp_space_before_dot = false\n\n# http://kent-boogaart.com/blog/editorconfig-reference-for-c-developers#csharp_space_before_open_square_brackets\ncsharp_space_before_open_square_brackets = false\n\n# http://kent-boogaart.com/blog/editorconfig-reference-for-c-developers#csharp_space_before_semicolon_in_for_statement\ncsharp_space_before_semicolon_in_for_statement = false\n\n# http://kent-boogaart.com/blog/editorconfig-reference-for-c-developers#csharp_space_between_empty_square_brackets\ncsharp_space_between_empty_square_brackets = false\n\n# http://kent-boogaart.com/blog/editorconfig-reference-for-c-developers#csharp_space_between_method_call_empty_parameter_list_parentheses\ncsharp_space_between_method_call_empty_parameter_list_parentheses = false\n\n# http://kent-boogaart.com/blog/editorconfig-reference-for-c-developers#csharp_space_between_method_call_name_and_opening_parenthesis\ncsharp_space_between_method_call_name_and_opening_parenthesis = false\n\n# http://kent-boogaart.com/blog/editorconfig-reference-for-c-developers#csharp_space_between_method_call_parameter_list_parentheses\ncsharp_space_between_method_call_parameter_list_parentheses = false\n\n# http://kent-boogaart.com/blog/editorconfig-reference-for-c-developers#csharp_space_between_method_declaration_empty_parameter_list_parentheses\ncsharp_space_between_method_declaration_empty_parameter_list_parentheses = false\n\n# http://kent-boogaart.com/blog/editorconfig-reference-for-c-developers#csharp_space_between_method_declaration_name_and_open_parenthesis\ncsharp_space_between_method_declaration_name_and_open_parenthesis = false\n\n# http://kent-boogaart.com/blog/editorconfig-reference-for-c-developers#csharp_space_between_method_declaration_parameter_list_parentheses\ncsharp_space_between_method_declaration_parameter_list_parentheses = false\n\n# http://kent-boogaart.com/blog/editorconfig-reference-for-c-developers#csharp_space_between_parentheses\ncsharp_space_between_parentheses = none\n\n# http://kent-boogaart.com/blog/editorconfig-reference-for-c-developers#csharp_space_between_square_brackets\ncsharp_space_between_square_brackets = false\n\n# http://kent-boogaart.com/blog/editorconfig-reference-for-c-developers#csharp_style_conditional_delegate_call\ncsharp_style_conditional_delegate_call = true:error\n\n# http://kent-boogaart.com/blog/editorconfig-reference-for-c-developers#csharp_style_expression_bodied_accessors\ncsharp_style_expression_bodied_accessors = true:warning\n\n# http://kent-boogaart.com/blog/editorconfig-reference-for-c-developers#csharp_style_expression_bodied_constructors\ncsharp_style_expression_bodied_constructors = true:warning\n\n# http://kent-boogaart.com/blog/editorconfig-reference-for-c-developers#csharp_style_expression_bodied_indexers\ncsharp_style_expression_bodied_indexers = true:error\n\n# http://kent-boogaart.com/blog/editorconfig-reference-for-c-developers#csharp_style_expression_bodied_methods\ncsharp_style_expression_bodied_methods = true\n\n# http://kent-boogaart.com/blog/editorconfig-reference-for-c-developers#csharp_style_expression_bodied_operators\ncsharp_style_expression_bodied_operators = true:error\n\n# http://kent-boogaart.com/blog/editorconfig-reference-for-c-developers#csharp_style_expression_bodied_properties\ncsharp_style_expression_bodied_properties = true:error\n\n# http://kent-boogaart.com/blog/editorconfig-reference-for-c-developers#csharp_style_inlined_variable_declaration\ncsharp_style_inlined_variable_declaration = true:error\n\n# http://kent-boogaart.com/blog/editorconfig-reference-for-c-developers#csharp_style_pattern_matching_over_as_with_null_check\ncsharp_style_pattern_matching_over_as_with_null_check = true:error\n\n# http://kent-boogaart.com/blog/editorconfig-reference-for-c-developers#csharp_style_pattern_matching_over_is_with_cast_check\ncsharp_style_pattern_matching_over_is_with_cast_check = true:error\n\n# http://kent-boogaart.com/blog/editorconfig-reference-for-c-developers#csharp_style_throw_expression\ncsharp_style_throw_expression = true:error\n\n# http://kent-boogaart.com/blog/editorconfig-reference-for-c-developers#csharp_style_var_elsewhere\ncsharp_style_var_elsewhere = true:suggestion\n\n# http://kent-boogaart.com/blog/editorconfig-reference-for-c-developers#csharp_style_var_for_built_in_types\ncsharp_style_var_for_built_in_types = true:error\n\n# http://kent-boogaart.com/blog/editorconfig-reference-for-c-developers#csharp_style_var_when_type_is_apparent\ncsharp_style_var_when_type_is_apparent = true:error\n\n# https://www.jetbrains.com/help/resharper/EditorConfig_CSHARP_SpacesPageSchema.html#resharper_csharp_space_in_singleline_method\ncsharp_space_in_singleline_method = true\n\n# http://kent-boogaart.com/blog/editorconfig-reference-for-c-developers#dotnet_sort_system_directives_first\ndotnet_sort_system_directives_first = true\n\n# http://kent-boogaart.com/blog/editorconfig-reference-for-c-developers#dotnet_style_coalesce_expression\ndotnet_style_coalesce_expression = true:error\n\n# http://kent-boogaart.com/blog/editorconfig-reference-for-c-developers#dotnet_style_collection_initializer\ndotnet_style_collection_initializer = true:error\n\n# http://kent-boogaart.com/blog/editorconfig-reference-for-c-developers#dotnet_style_explicit_tuple_names\ndotnet_style_explicit_tuple_names = true:error\n\n# http://kent-boogaart.com/blog/editorconfig-reference-for-c-developers#dotnet_style_null_propagation\ndotnet_style_null_propagation = true:warning\n\n# http://kent-boogaart.com/blog/editorconfig-reference-for-c-developers#dotnet_style_object_initializer\ndotnet_style_object_initializer = true:error\n\n# http://kent-boogaart.com/blog/editorconfig-reference-for-c-developers#dotnet_style_predefined_type_for_locals_parameters_members\ndotnet_style_predefined_type_for_locals_parameters_members = true:error\n\n# http://kent-boogaart.com/blog/editorconfig-reference-for-c-developers#dotnet_style_predefined_type_for_member_access\ndotnet_style_predefined_type_for_member_access = true:error\n\n# http://kent-boogaart.com/blog/editorconfig-reference-for-c-developers#dotnet_style_qualification_for_event\ndotnet_style_qualification_for_event = true:error\n\n# http://kent-boogaart.com/blog/editorconfig-reference-for-c-developers#dotnet_style_qualification_for_field\ndotnet_style_qualification_for_field = false:error\n\n# http://kent-boogaart.com/blog/editorconfig-reference-for-c-developers#dotnet_style_qualification_for_method\ndotnet_style_qualification_for_method = false:error\n\n# http://kent-boogaart.com/blog/editorconfig-reference-for-c-developers#dotnet_style_qualification_for_property\ndotnet_style_qualification_for_property = false:error\n\n# http://kent-boogaart.com/blog/editorconfig-reference-for-c-developers#dotnet_naming_\n#dotnet_naming_symbols.private_field_symbol.applicable_kinds = field\n#dotnet_naming_symbols.private_field_symbol.applicable_accessibilities = private\n#dotnet_naming_style.private_field_style.capitalization = camel_case\n#dotnet_naming_rule.private_fields_are_camel_case.severity = error\n#dotnet_naming_rule.private_fields_are_camel_case.symbols = private_field_symbol\n#dotnet_naming_rule.private_fields_are_camel_case.style = private_field_style\n\ndotnet_naming_symbols.non_private_field_symbol.applicable_kinds = field\ndotnet_naming_symbols.non_private_field_symbol.applicable_accessibilities = public, internal, friend, protected, protected_internal, protected_friend\ndotnet_naming_style.non_private_field_style.capitalization = pascal_case\ndotnet_naming_rule.non_private_fields_are_pascal_case.severity = error\ndotnet_naming_rule.non_private_fields_are_pascal_case.symbols = non_private_field_symbol\ndotnet_naming_rule.non_private_fields_are_pascal_case.style = non_private_field_style\n\ndotnet_naming_symbols.parameter_symbol.applicable_kinds = parameter\ndotnet_naming_style.parameter_style.capitalization = camel_case\ndotnet_naming_rule.parameters_are_camel_case.severity = error\ndotnet_naming_rule.parameters_are_camel_case.symbols = parameter_symbol\ndotnet_naming_rule.parameters_are_camel_case.style = parameter_style\n\ndotnet_naming_symbols.non_interface_type_symbol.applicable_kinds = class, struct, enum, delegate\ndotnet_naming_style.non_interface_type_style.capitalization = pascal_case\ndotnet_naming_rule.non_interface_types_are_pascal_case.severity = error\ndotnet_naming_rule.non_interface_types_are_pascal_case.symbols = non_interface_type_symbol\ndotnet_naming_rule.non_interface_types_are_pascal_case.style = non_interface_type_style\n\ndotnet_naming_symbols.interface_type_symbol.applicable_kinds = interface\ndotnet_naming_style.interface_type_style.capitalization = pascal_case\ndotnet_naming_style.interface_type_style.required_prefix = I\ndotnet_naming_rule.interface_types_must_be_prefixed_with_I.severity = error\ndotnet_naming_rule.interface_types_must_be_prefixed_with_I.symbols = interface_type_symbol\ndotnet_naming_rule.interface_types_must_be_prefixed_with_I.style = interface_type_style\n\ndotnet_naming_symbols.member_symbol.applicable_kinds = method, property, event\ndotnet_naming_style.member_style.capitalization = pascal_case\ndotnet_naming_rule.members_are_pascal_case.severity = error\ndotnet_naming_rule.members_are_pascal_case.symbols = member_symbol\ndotnet_naming_rule.members_are_pascal_case.style = member_style\n"
        },
        {
          "name": ".gitattributes",
          "type": "blob",
          "size": 2.458984375,
          "content": "###############################################################################\n# Set default behavior to automatically normalize line endings.\n###############################################################################\n* text=auto\n\n###############################################################################\n# Set default behavior for command prompt diff.\n#\n# This is need for earlier builds of msysgit that does not have it on by\n# default for csharp files.\n# Note: This is only used by command line\n###############################################################################\n#*.cs     diff=csharp\n\n###############################################################################\n# Set the merge driver for project and solution files\n#\n# Merging from the command prompt will add diff markers to the files if there\n# are conflicts (Merging from VS is not affected by the settings below, in VS\n# the diff markers are never inserted). Diff markers may cause the following \n# file extensions to fail to load in VS. An alternative would be to treat\n# these files as binary and thus will always conflict and require user\n# intervention with every merge. To do so, just uncomment the entries below\n###############################################################################\n#*.sln       merge=binary\n#*.csproj    merge=binary\n#*.vbproj    merge=binary\n#*.vcxproj   merge=binary\n#*.vcproj    merge=binary\n#*.dbproj    merge=binary\n#*.fsproj    merge=binary\n#*.lsproj    merge=binary\n#*.wixproj   merge=binary\n#*.modelproj merge=binary\n#*.sqlproj   merge=binary\n#*.wwaproj   merge=binary\n\n###############################################################################\n# behavior for image files\n#\n# image files are treated as binary by default.\n###############################################################################\n#*.jpg   binary\n#*.png   binary\n#*.gif   binary\n\n###############################################################################\n# diff behavior for common document formats\n# \n# Convert binary document formats to text before diffing them. This feature\n# is only available from the command line. Turn it on by uncommenting the \n# entries below.\n###############################################################################\n#*.doc   diff=astextplain\n#*.DOC   diff=astextplain\n#*.docx  diff=astextplain\n#*.DOCX  diff=astextplain\n#*.dot   diff=astextplain\n#*.DOT   diff=astextplain\n#*.pdf   diff=astextplain\n#*.PDF   diff=astextplain\n#*.rtf   diff=astextplain\n#*.RTF   diff=astextplain\n"
        },
        {
          "name": ".github",
          "type": "tree",
          "content": null
        },
        {
          "name": ".gitignore",
          "type": "blob",
          "size": 3.1630859375,
          "content": "## Ignore Visual Studio temporary files, build results, and\n## files generated by popular Visual Studio add-ons.\n## Ignore .idea Rider files\n\n# IntelliJ Rider\n.idea/\n\n# Sonarqube\n.sonarqube/\n\n# User-specific files\n*.suo\n*.user\n*.userosscache\n*.sln.docstates\n\n# User-specific files (MonoDevelop/Xamarin Studio)\n*.userprefs\n\n# Build results\n[Dd]ebug/\n[Dd]ebugPublic/\n[Rr]elease/\n[Rr]eleases/\nx64/\nx86/\nbuild/\nbld/\n[Bb]in/\n[Oo]bj/\n\n# Visual Studio 2015 cache/options directory\n.vs/\n\n# MSTest test Results\n[Tt]est[Rr]esult*/\n[Bb]uild[Ll]og.*\n\n# NUNIT\n*.VisualState.xml\nTestResult.xml\n\n# Build Results of an ATL Project\n[Dd]ebugPS/\n[Rr]eleasePS/\ndlldata.c\n\n# DNX\nproject.lock.json\nartifacts/\n\n*_i.c\n*_p.c\n*_i.h\n*.ilk\n*.meta\n*.obj\n*.pch\n*.pdb\n*.pgc\n*.pgd\n*.rsp\n*.sbr\n*.tlb\n*.tli\n*.tlh\n*.tmp\n*.tmp_proj\n*.log\n*.vspscc\n*.vssscc\n.builds\n*.pidb\n*.svclog\n*.scc\n\n# Chutzpah Test files\n_Chutzpah*\n\n# Visual C++ cache files\nipch/\n*.aps\n*.ncb\n*.opensdf\n*.sdf\n*.cachefile\n\n# Visual Studio profiler\n*.psess\n*.vsp\n*.vspx\n\n# TFS 2012 Local Workspace\n$tf/\n\n# Guidance Automation Toolkit\n*.gpState\n\n# ReSharper is a .NET coding add-in\n_ReSharper*/\n*.[Rr]e[Ss]harper\n*.DotSettings.user\n\n# JustCode is a .NET coding add-in\n.JustCode\n\n# TeamCity is a build add-in\n_TeamCity*\n\n# DotCover is a Code Coverage Tool\n*.dotCover\n\n# NCrunch\n_NCrunch_*\n.*crunch*.local.xml\n\n# MightyMoose\n*.mm.*\nAutoTest.Net/\n\n# Web workbench (sass)\n.sass-cache/\n\n# Installshield output folder\n[Ee]xpress/\n\n# DocProject is a documentation generator add-in\nDocProject/buildhelp/\nDocProject/Help/*.HxT\nDocProject/Help/*.HxC\nDocProject/Help/*.hhc\nDocProject/Help/*.hhk\nDocProject/Help/*.hhp\nDocProject/Help/Html2\nDocProject/Help/html\n\n# Click-Once directory\npublish/\n\n# Publish Web Output\n*.[Pp]ublish.xml\n*.azurePubxml\n## TODO: Comment the next line if you want to checkin your\n## web deploy settings but do note that will include unencrypted\n## passwords\n#*.pubxml\n\n*.publishproj\n\n# NuGet Packages\n*.nupkg\n# The packages folder can be ignored because of Package Restore\n**/packages/*\n# except build/, which is used as an MSBuild target.\n!**/packages/build/\n# Uncomment if necessary however generally it will be regenerated when needed\n#!**/packages/repositories.config\n\n# Windows Azure Build Output\ncsx/\n*.build.csdef\n\n# Windows Store app package directory\nAppPackages/\n\n# Visual Studio cache files\n# files ending in .cache can be ignored\n*.[Cc]ache\n# but keep track of directories ending in .cache\n!*.[Cc]ache/\n\n# Others\nClientBin/\n[Ss]tyle[Cc]op.*\n~$*\n*~\n*.dbmdl\n*.dbproj.schemaview\n*.pfx\n*.publishsettings\nnode_modules/\norleans.codegen.cs\n\n# RIA/Silverlight projects\nGenerated_Code/\n\n# Backup & report files from converting an old project file\n# to a newer Visual Studio version. Backup files are not needed,\n# because we have git ;-)\n_UpgradeReport_Files/\nBackup*/\nUpgradeLog*.XML\nUpgradeLog*.htm\n\n# SQL Server files\n*.mdf\n*.ldf\n\n# Business Intelligence projects\n*.rdl.data\n*.bim.layout\n*.bim_*.settings\n\n# Microsoft Fakes\nFakesAssemblies/\n\n# Node.js Tools for Visual Studio\n.ntvs_analysis.dat\n\n# Visual Studio 6 build log\n*.plg\n\n# Visual Studio 6 workspace options file\n*.opt\n\n# LightSwitch generated files\nGeneratedArtifacts/\n_Pvt_Extensions/\nModelManifest.xml\n\n# JetBrains IDEs\n.idea"
        },
        {
          "name": ".vscode",
          "type": "tree",
          "content": null
        },
        {
          "name": "Ductus.FluentDocker.MsTest",
          "type": "tree",
          "content": null
        },
        {
          "name": "Ductus.FluentDocker.Tests",
          "type": "tree",
          "content": null
        },
        {
          "name": "Ductus.FluentDocker.XUnit",
          "type": "tree",
          "content": null
        },
        {
          "name": "Ductus.FluentDocker",
          "type": "tree",
          "content": null
        },
        {
          "name": "Examples",
          "type": "tree",
          "content": null
        },
        {
          "name": "FluentDocker.sln",
          "type": "blob",
          "size": 3.5947265625,
          "content": "﻿\nMicrosoft Visual Studio Solution File, Format Version 12.00\n# Visual Studio Version 16\nVisualStudioVersion = 16.0.29424.173\nMinimumVisualStudioVersion = 10.0.40219.1\nProject(\"{2150E333-8FDC-42A3-9474-1A3956D46DE8}\") = \"Solution Items\", \"Solution Items\", \"{C7FD34B0-1CBF-44EC-A92C-59543CBE383B}\"\n\tProjectSection(SolutionItems) = preProject\n\t\t.editorconfig = .editorconfig\n\t\tdocs\\_config.yml = docs\\_config.yml\n\t\tappveyor.yml = appveyor.yml\n\t\tcoverletArgs.runsettings = coverletArgs.runsettings\n\t\tGitVersion.yml = GitVersion.yml\n\t\tglobal.json = global.json\n\t\tdocs\\index.md = docs\\index.md\n\t\tNuGet.config = NuGet.config\n\t\tREADME.md = README.md\n\tEndProjectSection\nEndProject\nProject(\"{9A19103F-16F7-4668-BE54-9A1E7A4F7556}\") = \"Ductus.FluentDocker\", \"Ductus.FluentDocker\\Ductus.FluentDocker.csproj\", \"{20B06EAB-41AD-4C1C-8375-5FE120F22B91}\"\nEndProject\nProject(\"{9A19103F-16F7-4668-BE54-9A1E7A4F7556}\") = \"Ductus.FluentDocker.MsTest\", \"Ductus.FluentDocker.MsTest\\Ductus.FluentDocker.MsTest.csproj\", \"{0BA07552-BC03-43EC-8D01-087AE89BE436}\"\nEndProject\nProject(\"{9A19103F-16F7-4668-BE54-9A1E7A4F7556}\") = \"Ductus.FluentDocker.Tests\", \"Ductus.FluentDocker.Tests\\Ductus.FluentDocker.Tests.csproj\", \"{FA836F5A-6361-4042-9B12-E38EB057CD41}\"\nEndProject\nProject(\"{2150E333-8FDC-42A3-9474-1A3956D46DE8}\") = \"data\", \"data\", \"{60257CD9-E6FE-4F23-A675-34B7DD1C27F1}\"\n\tProjectSection(SolutionItems) = preProject\n\t\tdata\\docker_event_sample_1.json = data\\docker_event_sample_1.json\n\t\tdata\\docker_network_inspect.json = data\\docker_network_inspect.json\n\tEndProjectSection\nEndProject\nProject(\"{FAE04EC0-301F-11D3-BF4B-00C04F79EFBC}\") = \"Ductus.FluentDocker.XUnit\", \"Ductus.FluentDocker.XUnit\\Ductus.FluentDocker.XUnit.csproj\", \"{F8020BBA-78F7-426A-BE28-13716CC17966}\"\nEndProject\nGlobal\n\tGlobalSection(SolutionConfigurationPlatforms) = preSolution\n\t\tDebug|Any CPU = Debug|Any CPU\n\t\tRelease|Any CPU = Release|Any CPU\n\tEndGlobalSection\n\tGlobalSection(ProjectConfigurationPlatforms) = postSolution\n\t\t{20B06EAB-41AD-4C1C-8375-5FE120F22B91}.Debug|Any CPU.ActiveCfg = Debug|Any CPU\n\t\t{20B06EAB-41AD-4C1C-8375-5FE120F22B91}.Debug|Any CPU.Build.0 = Debug|Any CPU\n\t\t{20B06EAB-41AD-4C1C-8375-5FE120F22B91}.Release|Any CPU.ActiveCfg = Release|Any CPU\n\t\t{20B06EAB-41AD-4C1C-8375-5FE120F22B91}.Release|Any CPU.Build.0 = Release|Any CPU\n\t\t{0BA07552-BC03-43EC-8D01-087AE89BE436}.Debug|Any CPU.ActiveCfg = Debug|Any CPU\n\t\t{0BA07552-BC03-43EC-8D01-087AE89BE436}.Debug|Any CPU.Build.0 = Debug|Any CPU\n\t\t{0BA07552-BC03-43EC-8D01-087AE89BE436}.Release|Any CPU.ActiveCfg = Release|Any CPU\n\t\t{0BA07552-BC03-43EC-8D01-087AE89BE436}.Release|Any CPU.Build.0 = Release|Any CPU\n\t\t{FA836F5A-6361-4042-9B12-E38EB057CD41}.Debug|Any CPU.ActiveCfg = Debug|Any CPU\n\t\t{FA836F5A-6361-4042-9B12-E38EB057CD41}.Debug|Any CPU.Build.0 = Debug|Any CPU\n\t\t{FA836F5A-6361-4042-9B12-E38EB057CD41}.Release|Any CPU.ActiveCfg = Release|Any CPU\n\t\t{FA836F5A-6361-4042-9B12-E38EB057CD41}.Release|Any CPU.Build.0 = Release|Any CPU\n\t\t{F8020BBA-78F7-426A-BE28-13716CC17966}.Debug|Any CPU.ActiveCfg = Debug|Any CPU\n\t\t{F8020BBA-78F7-426A-BE28-13716CC17966}.Debug|Any CPU.Build.0 = Debug|Any CPU\n\t\t{F8020BBA-78F7-426A-BE28-13716CC17966}.Release|Any CPU.ActiveCfg = Release|Any CPU\n\t\t{F8020BBA-78F7-426A-BE28-13716CC17966}.Release|Any CPU.Build.0 = Release|Any CPU\n\tEndGlobalSection\n\tGlobalSection(SolutionProperties) = preSolution\n\t\tHideSolutionNode = FALSE\n\tEndGlobalSection\n\tGlobalSection(NestedProjects) = preSolution\n\t\t{60257CD9-E6FE-4F23-A675-34B7DD1C27F1} = {C7FD34B0-1CBF-44EC-A92C-59543CBE383B}\n\tEndGlobalSection\n\tGlobalSection(ExtensibilityGlobals) = postSolution\n\t\tSolutionGuid = {E5379AC0-CB30-46F7-B995-C515FA19102D}\n\tEndGlobalSection\nEndGlobal\n"
        },
        {
          "name": "FluentDocker.sln.DotSettings",
          "type": "blob",
          "size": 0.4794921875,
          "content": "﻿<wpf:ResourceDictionary xml:space=\"preserve\" xmlns:x=\"http://schemas.microsoft.com/winfx/2006/xaml\" xmlns:s=\"clr-namespace:System;assembly=mscorlib\" xmlns:ss=\"urn:shemas-jetbrains-com:settings-storage-xaml\" xmlns:wpf=\"http://schemas.microsoft.com/winfx/2006/xaml/presentation\">\n\t<s:Boolean x:Key=\"/Default/UserDictionary/Words/=Ductus/@EntryIndexedValue\">True</s:Boolean>\n\t<s:Boolean x:Key=\"/Default/UserDictionary/Words/=prms/@EntryIndexedValue\">True</s:Boolean></wpf:ResourceDictionary>"
        },
        {
          "name": "GitVersion.yml",
          "type": "blob",
          "size": 0.0458984375,
          "content": "mode: Mainline\nbranches:\n  master:\n    tag: ''\n"
        },
        {
          "name": "LICENSE",
          "type": "blob",
          "size": 11.091796875,
          "content": "                                 Apache License\n                           Version 2.0, January 2004\n                        http://www.apache.org/licenses/\n\n   TERMS AND CONDITIONS FOR USE, REPRODUCTION, AND DISTRIBUTION\n\n   1. Definitions.\n\n      \"License\" shall mean the terms and conditions for use, reproduction,\n      and distribution as defined by Sections 1 through 9 of this document.\n\n      \"Licensor\" shall mean the copyright owner or entity authorized by\n      the copyright owner that is granting the License.\n\n      \"Legal Entity\" shall mean the union of the acting entity and all\n      other entities that control, are controlled by, or are under common\n      control with that entity. For the purposes of this definition,\n      \"control\" means (i) the power, direct or indirect, to cause the\n      direction or management of such entity, whether by contract or\n      otherwise, or (ii) ownership of fifty percent (50%) or more of the\n      outstanding shares, or (iii) beneficial ownership of such entity.\n\n      \"You\" (or \"Your\") shall mean an individual or Legal Entity\n      exercising permissions granted by this License.\n\n      \"Source\" form shall mean the preferred form for making modifications,\n      including but not limited to software source code, documentation\n      source, and configuration files.\n\n      \"Object\" form shall mean any form resulting from mechanical\n      transformation or translation of a Source form, including but\n      not limited to compiled object code, generated documentation,\n      and conversions to other media types.\n\n      \"Work\" shall mean the work of authorship, whether in Source or\n      Object form, made available under the License, as indicated by a\n      copyright notice that is included in or attached to the work\n      (an example is provided in the Appendix below).\n\n      \"Derivative Works\" shall mean any work, whether in Source or Object\n      form, that is based on (or derived from) the Work and for which the\n      editorial revisions, annotations, elaborations, or other modifications\n      represent, as a whole, an original work of authorship. For the purposes\n      of this License, Derivative Works shall not include works that remain\n      separable from, or merely link (or bind by name) to the interfaces of,\n      the Work and Derivative Works thereof.\n\n      \"Contribution\" shall mean any work of authorship, including\n      the original version of the Work and any modifications or additions\n      to that Work or Derivative Works thereof, that is intentionally\n      submitted to Licensor for inclusion in the Work by the copyright owner\n      or by an individual or Legal Entity authorized to submit on behalf of\n      the copyright owner. For the purposes of this definition, \"submitted\"\n      means any form of electronic, verbal, or written communication sent\n      to the Licensor or its representatives, including but not limited to\n      communication on electronic mailing lists, source code control systems,\n      and issue tracking systems that are managed by, or on behalf of, the\n      Licensor for the purpose of discussing and improving the Work, but\n      excluding communication that is conspicuously marked or otherwise\n      designated in writing by the copyright owner as \"Not a Contribution.\"\n\n      \"Contributor\" shall mean Licensor and any individual or Legal Entity\n      on behalf of whom a Contribution has been received by Licensor and\n      subsequently incorporated within the Work.\n\n   2. Grant of Copyright License. Subject to the terms and conditions of\n      this License, each Contributor hereby grants to You a perpetual,\n      worldwide, non-exclusive, no-charge, royalty-free, irrevocable\n      copyright license to reproduce, prepare Derivative Works of,\n      publicly display, publicly perform, sublicense, and distribute the\n      Work and such Derivative Works in Source or Object form.\n\n   3. Grant of Patent License. Subject to the terms and conditions of\n      this License, each Contributor hereby grants to You a perpetual,\n      worldwide, non-exclusive, no-charge, royalty-free, irrevocable\n      (except as stated in this section) patent license to make, have made,\n      use, offer to sell, sell, import, and otherwise transfer the Work,\n      where such license applies only to those patent claims licensable\n      by such Contributor that are necessarily infringed by their\n      Contribution(s) alone or by combination of their Contribution(s)\n      with the Work to which such Contribution(s) was submitted. If You\n      institute patent litigation against any entity (including a\n      cross-claim or counterclaim in a lawsuit) alleging that the Work\n      or a Contribution incorporated within the Work constitutes direct\n      or contributory patent infringement, then any patent licenses\n      granted to You under this License for that Work shall terminate\n      as of the date such litigation is filed.\n\n   4. Redistribution. You may reproduce and distribute copies of the\n      Work or Derivative Works thereof in any medium, with or without\n      modifications, and in Source or Object form, provided that You\n      meet the following conditions:\n\n      (a) You must give any other recipients of the Work or\n          Derivative Works a copy of this License; and\n\n      (b) You must cause any modified files to carry prominent notices\n          stating that You changed the files; and\n\n      (c) You must retain, in the Source form of any Derivative Works\n          that You distribute, all copyright, patent, trademark, and\n          attribution notices from the Source form of the Work,\n          excluding those notices that do not pertain to any part of\n          the Derivative Works; and\n\n      (d) If the Work includes a \"NOTICE\" text file as part of its\n          distribution, then any Derivative Works that You distribute must\n          include a readable copy of the attribution notices contained\n          within such NOTICE file, excluding those notices that do not\n          pertain to any part of the Derivative Works, in at least one\n          of the following places: within a NOTICE text file distributed\n          as part of the Derivative Works; within the Source form or\n          documentation, if provided along with the Derivative Works; or,\n          within a display generated by the Derivative Works, if and\n          wherever such third-party notices normally appear. The contents\n          of the NOTICE file are for informational purposes only and\n          do not modify the License. You may add Your own attribution\n          notices within Derivative Works that You distribute, alongside\n          or as an addendum to the NOTICE text from the Work, provided\n          that such additional attribution notices cannot be construed\n          as modifying the License.\n\n      You may add Your own copyright statement to Your modifications and\n      may provide additional or different license terms and conditions\n      for use, reproduction, or distribution of Your modifications, or\n      for any such Derivative Works as a whole, provided Your use,\n      reproduction, and distribution of the Work otherwise complies with\n      the conditions stated in this License.\n\n   5. Submission of Contributions. Unless You explicitly state otherwise,\n      any Contribution intentionally submitted for inclusion in the Work\n      by You to the Licensor shall be under the terms and conditions of\n      this License, without any additional terms or conditions.\n      Notwithstanding the above, nothing herein shall supersede or modify\n      the terms of any separate license agreement you may have executed\n      with Licensor regarding such Contributions.\n\n   6. Trademarks. This License does not grant permission to use the trade\n      names, trademarks, service marks, or product names of the Licensor,\n      except as required for reasonable and customary use in describing the\n      origin of the Work and reproducing the content of the NOTICE file.\n\n   7. Disclaimer of Warranty. Unless required by applicable law or\n      agreed to in writing, Licensor provides the Work (and each\n      Contributor provides its Contributions) on an \"AS IS\" BASIS,\n      WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or\n      implied, including, without limitation, any warranties or conditions\n      of TITLE, NON-INFRINGEMENT, MERCHANTABILITY, or FITNESS FOR A\n      PARTICULAR PURPOSE. You are solely responsible for determining the\n      appropriateness of using or redistributing the Work and assume any\n      risks associated with Your exercise of permissions under this License.\n\n   8. Limitation of Liability. In no event and under no legal theory,\n      whether in tort (including negligence), contract, or otherwise,\n      unless required by applicable law (such as deliberate and grossly\n      negligent acts) or agreed to in writing, shall any Contributor be\n      liable to You for damages, including any direct, indirect, special,\n      incidental, or consequential damages of any character arising as a\n      result of this License or out of the use or inability to use the\n      Work (including but not limited to damages for loss of goodwill,\n      work stoppage, computer failure or malfunction, or any and all\n      other commercial damages or losses), even if such Contributor\n      has been advised of the possibility of such damages.\n\n   9. Accepting Warranty or Additional Liability. While redistributing\n      the Work or Derivative Works thereof, You may choose to offer,\n      and charge a fee for, acceptance of support, warranty, indemnity,\n      or other liability obligations and/or rights consistent with this\n      License. However, in accepting such obligations, You may act only\n      on Your own behalf and on Your sole responsibility, not on behalf\n      of any other Contributor, and only if You agree to indemnify,\n      defend, and hold each Contributor harmless for any liability\n      incurred by, or claims asserted against, such Contributor by reason\n      of your accepting any such warranty or additional liability.\n\n   END OF TERMS AND CONDITIONS\n\n   APPENDIX: How to apply the Apache License to your work.\n\n      To apply the Apache License to your work, attach the following\n      boilerplate notice, with the fields enclosed by brackets \"[]\"\n      replaced with your own identifying information. (Don't include\n      the brackets!)  The text should be enclosed in the appropriate\n      comment syntax for the file format. We also recommend that a\n      file or class name and description of purpose be included on the\n      same \"printed page\" as the copyright notice for easier\n      identification within third-party archives.\n\n   Copyright [yyyy] [name of copyright owner]\n\n   Licensed under the Apache License, Version 2.0 (the \"License\");\n   you may not use this file except in compliance with the License.\n   You may obtain a copy of the License at\n\n       http://www.apache.org/licenses/LICENSE-2.0\n\n   Unless required by applicable law or agreed to in writing, software\n   distributed under the License is distributed on an \"AS IS\" BASIS,\n   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n   See the License for the specific language governing permissions and\n   limitations under the License.\n\n"
        },
        {
          "name": "NuGet.config",
          "type": "blob",
          "size": 0.3486328125,
          "content": "<?xml version=\"1.0\" encoding=\"utf-8\"?>\n<configuration>\n  <disabledPackageSources>\n    <clear />\n  </disabledPackageSources>\n  <packageSources>\n    <clear />\n    <add key=\"nuget.org\" value=\"https://api.nuget.org/v3/index.json\" />\n    <add key=\"gitversion\" value=\"https://ci.appveyor.com/nuget/gitversion-8nigugxjftrw\" />\n  </packageSources>\n</configuration>\n"
        },
        {
          "name": "README.md",
          "type": "blob",
          "size": 52.6884765625,
          "content": "[![Quality Gate Status](https://sonarcloud.io/api/project_badges/measure?project=mariotoffia_FluentDocker&metric=alert_status)](https://sonarcloud.io/dashboard?id=mariotoffia_FluentDocker)\n[![Build status](https://ci.appveyor.com/api/projects/status/kqqrkcv8wp3e9my6/branch/master?svg=true)](https://ci.appveyor.com/project/mariotoffia/fluentdocker) \n\n| Package        | NuGet          |\n| ---------------|:--------------:|\n| FluentDocker   |[![NuGet](https://img.shields.io/nuget/v/Ductus.FluentDocker.svg)](https://www.nuget.org/packages/Ductus.FluentDocker) |\n| Microsoft Test | [![NuGet](https://img.shields.io/nuget/v/Ductus.FluentDocker.MsTest.svg)](https://www.nuget.org/packages/Ductus.FluentDocker.MsTest) |\n| XUnit Test     | [![NuGet](https://img.shields.io/nuget/v/Ductus.FluentDocker.XUnit.svg)](https://www.nuget.org/packages/Ductus.FluentDocker.XUnit) |\n\n# FluentDocker\n\nThis library enables `docker` and `docker-compose` interactions usinga _Fluent API_. It is supported on Linux, Windows and Mac. It also has support for the legazy `docker-machine` interactions.\n\n**Sample Fluent API usage**\n```cs\n      using (\n        var container =\n          new Builder().UseContainer()\n            .UseImage(\"kiasaki/alpine-postgres\")\n            .ExposePort(5432)\n            .WithEnvironment(\"POSTGRES_PASSWORD=mysecretpassword\")\n            .WaitForPort(\"5432/tcp\", 30000 /*30s*/)\n            .Build()\n            .Start())\n      {\n        var config = container.GetConfiguration(true);\n        Assert.AreEqual(ServiceRunningState.Running, config.State.ToServiceState());\n      }\n```\nThis fires up a postgres and waits for it to be ready. To use compose, just do it like this:\n\n:bulb: **NOTE: Use the AssumeComposeVersion(ComposeVersion.V2) to use the V2 behaviour, default is still V1 (to be changed to default to V2 later this year)**\n\n```cs\n      var file = Path.Combine(Directory.GetCurrentDirectory(),\n        (TemplateString) \"Resources/ComposeTests/WordPress/docker-compose.yml\");\n\n      // @formatter:off\n      using (var svc = new Builder()\n                        .UseContainer()\n                        .UseCompose()\n                        .FromFile(file)\n                        .RemoveOrphans()\n                        .WaitForHttp(\"wordpress\", \"http://localhost:8000/wp-admin/install.php\") \n                        .Build().Start())\n        // @formatter:on\n      {\n        // We now have a running WordPress with a MySql database        \n        var installPage = await \"http://localhost:8000/wp-admin/install.php\".Wget();\n\n        Assert.IsTrue(installPage.IndexOf(\"https://wordpress.org/\", StringComparison.Ordinal) != -1);\n        Assert.AreEqual(1, svc.Hosts.Count); // The host used by compose\n        Assert.AreEqual(2, svc.Containers.Count); // We can access each individual container\n        Assert.AreEqual(2, svc.Images.Count); // And the images used.\n      }\n```\n\n:bulb **Note for Linux Users:** Docker requires _sudo_ by default and the library by default expects that executing user do not\nneed to do _sudo_ in order to talk to the docker daemon. More description can be found in the _Talking to Docker Daemon_ chapter.\n\nThe fluent _API_ builds up one or more services. Each service may be composite or singular. Therefore it is possible\nto e.g. fire up several _docker-compose_ based services and manage each of them as a single service or dig in and use\nall underlying services on each _docker-compose_ service. It is also possible to use services directly e.g.\n```cs\n      var file = Path.Combine(Directory.GetCurrentDirectory(),\n        (TemplateString) \"Resources/ComposeTests/WordPress/docker-compose.yml\");\n\n      using (var svc = new DockerComposeCompositeService(DockerHost, new DockerComposeConfig\n      {\n        ComposeFilePath = new List<string> { file }, ForceRecreate = true, RemoveOrphans = true,\n        StopOnDispose = true\n      }))\n      {\n        svc.Start();\n        \n        // We now have a running WordPress with a MySql database\n        var installPage = await $\"http://localhost:8000/wp-admin/install.php\".Wget();\n        \n        Assert.IsTrue(installPage.IndexOf(\"https://wordpress.org/\", StringComparison.Ordinal) != -1);\n      }\n```\nThe above example creates a _docker-compose_ service from a single compose file. When the service is disposed all\nunderlying services is automatically stopped.\n\nThe library is supported by .NET full 4.51 framework and higher, .NET standard 1.6, 2.0. It is divided into \nthree thin layers, each layer is accessible:\n\n1. Docker Binaries interactions - Static commands and docker environment\n2. Services - thin service layer to manage machines, containers etc.\n3. Fluent API - API to build/discover services to be used\n\nThe Majority of the service methods are extension methods and not hardwired into the service itself, making them lightweight and customizable. Since everything is accessible it is e.g. easy to add extensions method for a service that uses the layer 1 commands to provide functionality. \n\n## Contribution\nI do welcome contribution, though there is no contribution guideline as of yet, make sure to adhere to _.editorconfig_ when doing the Pull Requests.\nOtherwise the build will fail. I'll update with a **real** guideline sooner or later this year.\n\n## Basic Usage of Commands (Layer 1)\nAll commands needs a ```DockerUri``` to work with. It is the Uri to the docker daemon, either locally or remote. It can be discoverable or hardcoded. Discovery of local ```DockerUri``` can be done by \n```cs\n     var hosts = new Hosts().Discover();\n     var _docker = hosts.FirstOrDefault(x => x.IsNative) ?? hosts.FirstOrDefault(x => x.Name == \"default\");\n```\nThe example snipped will check for native, or docker beta \"native\" hosts, if not choose the docker-machine \"default\" as host. If you're using docker-machine and no machine exists or is not started it is easy to create / start a docker-machine by e.g. ```\"test-machine\".Create(1024,20000000,1)```. This will create a docker machine named \"test-machine\" with 1GB of RAM, 20GB Disk, and use one CPU.\n\nIt is now possible to use the Uri to communicate using the commands. For example to get the version of client and server docker binaries:\n```cs\n     var result = _docker.Host.Version(_docker.Certificates);\n     Debug.WriteLine(result.Data); // Will Print the Client and Server Version and API Versions respectively.\n```\nAll commands return a CommandResponse<T> such that it is possible to check success factor by ```response.Success```. If any data associated with the command it is returned in the ```response.Data``` property.\n\nThen it is simple as below to start and stop include delete a container using the commands. Below starts a container and do a PS on it and then deletes it.\n```cs\n     var id = _docker.Host.Run(\"nginx:latest\", null, _docker.Certificates).Data;\n     var ps = _docker.Host.Ps(null, _docker.Certificates).Data;\n     \n     _docker.Host.RemoveContainer(id, true, true, null, _docker.Certificates);\n```\nWhen running on windows, one can choose to run linux or windows container. Use the ```LinuxDaemon``` or ```WindowsDaemon``` to control which daemon to talk to.\n```cs\n     _docker.LinuxDaemon(); // ensures that it will talk to linux daemon, if windows daemon it will switch\n```\n\nSome commands returns a stream of data when e.g. events or logs is wanted using a continuous stream. Streams can be used in background tasks and support ```CancellationToken```. Below example tails a log.\n```cs\n     using (var logs = _docker.Host.Logs(id, _docker.Certificates))\n     {\n          while (!logs.IsFinished)\n          {\n               var line = logs.TryRead(5000); // Do a read with timeout\n               if (null == line)\n               {\n                    break;\n               }\n\n               Debug.WriteLine(line);\n          }\n     }\n```\n\nUtility methods exists for commands. They come in different flaviours such as networking etc. For example when reading a log to the end:\n```cs\n     using (var logs = _docker.Host.Logs(id, _docker.Certificates))\n     {\n          foreach (var line in logs.ReadToEnd())\n          {\n            Debug.WriteLine(line);\n          }\n     }\n```\n\n## Using Fluent API\nThe highest layer of this library is the fluent API where you can define and control machines, images, and containers. For example to setup a load balancer with two nodejs servers reading from a redis server can look like this (node image is custom built if not found in the repository).\n\n```cs\n     var fullPath = (TemplateString) @\"${TEMP}/fluentdockertest/${RND}\";\n      var nginx = Path.Combine(fullPath, \"nginx.conf\");\n\n      Directory.CreateDirectory(fullPath);\n      typeof(NsResolver).ResourceExtract(fullPath, \"index.js\");\n\n        using (var services = new Builder()\n\n          // Define custom node image to be used\n          .DefineImage(\"mariotoffia/nodetest\").ReuseIfAlreadyExists()\n          .From(\"ubuntu\")\n          .Maintainer(\"Mario Toffia <mario.toffia@xyz.com>\")\n          .Run(\"apt-get update &&\",\n            \"apt-get -y install curl &&\",\n            \"curl -sL https://deb.nodesource.com/setup | sudo bash - &&\",\n            \"apt-get -y install python build-essential nodejs\")\n          .Run(\"npm install -g nodemon\")\n          .Add(\"emb:Ductus.FluentDockerTest/Ductus.FluentDockerTest.MultiContainerTestFiles/package.txt\",\n            \"/tmp/package.json\")\n          .Run(\"cd /tmp && npm install\")\n          .Run(\"mkdir -p /src && cp -a /tmp/node_modules /src/\")\n          .UseWorkDir(\"/src\")\n          .Add(\"index.js\", \"/src\")\n          .ExposePorts(8080)\n          .Command(\"nodemon\", \"/src/index.js\").Builder()\n\n          // Redis Db Backend\n          .UseContainer().WithName(\"redis\").UseImage(\"redis\").Builder()\n\n          // Node server 1 & 2\n          .UseContainer().WithName(\"node1\").UseImage(\"mariotoffia/nodetest\").Link(\"redis\").Builder()\n          .UseContainer().WithName(\"node2\").UseImage(\"mariotoffia/nodetest\").Link(\"redis\").Builder()\n\n          // Nginx as load balancer\n          .UseContainer().WithName(\"nginx\").UseImage(\"nginx\").Link(\"node1\", \"node2\")\n          .CopyOnStart(nginx, \"/etc/nginx/nginx.conf\")\n          .ExposePort(80).Builder()\n          .Build().Start())\n        {\n          Assert.AreEqual(4, services.Containers.Count);\n\n          var ep = services.Containers.First(x => x.Name == \"nginx\").ToHostExposedEndpoint(\"80/tcp\");\n          Assert.IsNotNull(ep);\n\n          var round1 = $\"http://{ep.Address}:{ep.Port}\".Wget();\n          Assert.AreEqual(\"This page has been viewed 1 times!\", round1);\n\n          var round2 = $\"http://{ep.Address}:{ep.Port}\".Wget();\n          Assert.AreEqual(\"This page has been viewed 2 times!\", round2);\n        }\n```\n\nThe above example defines a _Dockerfile_, builds it, for the node image. It then uses vanilla redis and nginx. \nIf you just want to use an existing _Dockerfile_ it can be done like this.\n\n```cs\n        using (var services = new Builder()\n\n          .DefineImage(\"mariotoffia/nodetest\").ReuseIfAlreadyExists()\n          .FromFile(\"/tmp/Dockerfile\")\n          .Build().Start())\n        {\n         // Container either build to reused if found in registry and started here.\n        }\n```\n  \nThe fluent API supports from defining a docker-machine to a set of docker instances. It has built-in support for e.g. \nwaiting for a specific port or a process within the container before ```Build()``` completes and thus can be safely \nbe used within a using statement. If specific management on wait timeouts etc. you can always build and start the \ncontainer and use extension methods to do the waiting on the container itself.\n\nTo create a container just omit the start. For example:\n```cs\nusing (\n        var container =\n          new Builder().UseContainer()\n            .UseImage(\"kiasaki/alpine-postgres\")\n            .WithEnvironment(\"POSTGRES_PASSWORD=mysecretpassword\")\n            .Build())\n      {\n        Assert.AreEqual(ServiceRunningState.Stopped, container.State);\n      }\n```\nThis example creates a container with postgres, configure one environment variable. Within the using statement it is possible to start the ```IContainerService```. Thus each built container is wrapped in a ```IContainerService```. It is also possible to use the ```IHostService.GetContainers(...)``` to obtain the created, running, and exited containers. From the ```IHostService``` it is also possible to get all the images in the local repository to create containers from.\n\nWhe you want to run a single container do use the fluent or container service start method. For example:\n```cs\n      using (\n        var container =\n          new Builder().UseContainer()\n            .UseImage(\"kiasaki/alpine-postgres\")\n            .WithEnvironment(\"POSTGRES_PASSWORD=mysecretpassword\")\n            .Build()\n            .Start())\n      {\n        var config = container.GetConfiguration();\n\n        Assert.AreEqual(ServiceRunningState.Running, container.State);\n        Assert.IsTrue(config.Config.Env.Any(x => x == \"POSTGRES_PASSWORD=mysecretpassword\"));\n      }\n```\n\nBy default the container is stopped and deleted when the Dispose method is run, in order to keep the container in archve, use the ```KeepContainer()``` on the fluent API. When ```Dispose()``` is invoked it will be stopped but not deleted. It is also possible to keep it running after dispose as well.\n\n### Working with ports\nIt is possible to expose ports both explicit or randomly. Either way it is possible to resolve the IP (in case of machine) and the port (in case of random port) to use in code. For example:\n\n```cs\n      using (\n        var container =\n          new Builder().UseContainer()\n            .UseImage(\"kiasaki/alpine-postgres\")\n            .ExposePort(40001, 5432)\n            .WithEnvironment(\"POSTGRES_PASSWORD=mysecretpassword\")\n            .Build()\n            .Start())\n      {\n        var endpoint = container.ToHostExposedEndpoint(\"5432/tcp\");\n        Assert.AreEqual(40001, endpoint.Port);\n      }\n```\n\nHere we map the container port 5432 to host port 40001 explicitly. Note the use of ```container.ToHostExposedEndpoint(...)```. This is to always resolve to a working ip and port to communicate with the docker container. It is also possible to map a random port, i.e. let Docker choose a available port. For example:\n\n```cs\n      using (\n        var container =\n          new Builder().UseContainer()\n            .UseImage(\"kiasaki/alpine-postgres\")\n            .ExposePort(5432)\n            .WithEnvironment(\"POSTGRES_PASSWORD=mysecretpassword\")\n            .Build()\n            .Start())\n      {\n        var endpoint = container.ToHostExposedEndpoint(\"5432/tcp\");\n        Assert.AreNotEqual(0, endpoint.Port);\n      }\n```\nThe only difference here is that only one argument is used when ```ExposePort(...)``` was used to configure the container. The same usage applies otherwise and thus is transparent for the code.\n\nIn order to know when a certain service is up and running before starting to e.g. connect to it. It is possible to wait for a specific port to be open. For example:\n```cs\n      using (\n        var container =\n          new Builder().UseContainer()\n            .UseImage(\"kiasaki/alpine-postgres\")\n            .ExposePort(5432)\n            .WithEnvironment(\"POSTGRES_PASSWORD=mysecretpassword\")\n            .WaitForPort(\"5432/tcp\", 30000 /*30s*/)\n            .Build()\n            .Start())\n      {\n        var config = container.GetConfiguration(true);\n        Assert.AreEqual(ServiceRunningState.Running, config.State.ToServiceState());\n      }\n```\nIn the above example we wait for the container port 5432 to be opened within 30 seconds. If it fails, it will throw an exception and thus the container will be disposed and removed (since we dont have any keep container etc. configuration).\n\n\n```cs\n      using (\n        var container =\n          new Builder().UseContainer()\n            .UseImage(\"kiasaki/alpine-postgres\")\n            .ExposePort(5432)\n            .WithEnvironment(\"POSTGRES_PASSWORD=mysecretpassword\")\n            .WaitForPort(\"5432/tcp\", 30000 /*30s*/, \"127.0.0.1\")\n            .Build()\n            .Start())\n      {\n        var config = container.GetConfiguration(true);\n        Assert.AreEqual(ServiceRunningState.Running, config.State.ToServiceState());\n      }\n```\nSometimes it is not possible to directly reach the container, by local ip and port, instead e.g. the container has an exposed port on the loopback interface (_127.0.0.1_) and that is the only way of reaching the container from the program. The above example forces the\naddress to be _127.0.0.1_ but still resolves the host port. By default, _FluentDocker_ uses the network inspect on the container to determine the network configuration.\n\nSometime it is not sufficient to just wait for a port. Sometimes a container process is much more vital to wait for. Therefore a wait for process method exist in the fluent API as well as an extension method on the container object. For example: \n```cs\n      using (\n        var container =\n          new Builder().UseContainer()\n            .UseImage(\"kiasaki/alpine-postgres\")\n            .ExposePort(5432)\n            .WithEnvironment(\"POSTGRES_PASSWORD=mysecretpassword\")\n            .WaitForProcess(\"postgres\", 30000 /*30s*/)\n            .Build()\n            .Start())\n      {\n        var config = container.GetConfiguration(true);\n        Assert.AreEqual(ServiceRunningState.Running, config.State.ToServiceState());\n      }\n```\nIn the above example ```Build()``` will return control when the process \"postgres\" have been started within the container.\n\n### Filesystem & Files\nIn order to make use of containers, sometimes it is necessary to mount volumes in the container onto the host or just copy from or to the container. Depending on if you're running machine or docker natively volume mapping have the constraint that it must be reachable from the virtual machine.\n\nA normal use case is to have e.g. a webserver serving content on a docker container and the user edits files on the host file system. In such scenario it is necessary to mount a docker container volume onto the host. For example: \n\n```cs\n     const string html = \"<html><head>Hello World</head><body><h1>Hello world</h1></body></html>\";\n      var hostPath = (TemplateString) @\"${TEMP}/fluentdockertest/${RND}\";\n      Directory.CreateDirectory(hostPath);\n\n      using (\n        var container =\n          new Builder().UseContainer()\n            .UseImage(\"nginx:latest\")\n            .ExposePort(80)\n            .Mount(hostPath, \"/usr/share/nginx/html\", MountType.ReadOnly)\n            .Build()\n            .Start()\n            .WaitForPort(\"80/tcp\", 30000 /*30s*/))\n      {\n          File.WriteAllText(Path.Combine(hostPath, \"hello.html\"), html);\n\n          var response = $\"http://{container.ToHostExposedEndpoint(\"80/tcp\")}/hello.html\".Wget();\n          Assert.AreEqual(html, response);\n      }\n```\nIn the above example a nginx container is started and mounts '/usr/share/nginx/html' onto a (random, in temp directory) host path. A HTML file is copied into the host path and when a HTTP get towards the nginx docker container is done, that same file is served.\n\nSometimes it is necessary copy files to and from a container. For example copy a configuration file, configure it and copy it back. More common scenario is to copy a configuration file to the container, just before it is started. The multi container example copies a nginx configuration file just before it is started. Thus it is possible to avoid manually creating a Dockerfile and a image for such a simple task. Instead just use e.g. an official or custom image, copy configuration and run.\n```cs\n using (new Builder().UseContainer()\n          .UseImage(\"kiasaki/alpine-postgres\")\n          .ExposePort(5432)\n          .WithEnvironment(\"POSTGRES_PASSWORD=mysecretpassword\")\n          .Build()\n          .Start()\n          .CopyFrom(\"/etc/conf.d\", fullPath))\n        {\n          var files = Directory.EnumerateFiles(Path.Combine(fullPath, \"conf.d\")).ToArray();\n          Assert.IsTrue(files.Any(x => x.EndsWith(\"pg-restore\")));\n          Assert.IsTrue(files.Any(x => x.EndsWith(\"postgresql\")));\n        }\n```\nAbove example copies a directory to a host path (fullPath) from a running container. Note the use of extension method here, thus not using the fluent API (since CopyFrom is after Start()). If you want to copy files from the container just before starting use the Fluent API instead.\n```cs\n       using (new Builder().UseContainer()\n          .UseImage(\"kiasaki/alpine-postgres\")\n          .ExposePort(5432)\n          .WithEnvironment(\"POSTGRES_PASSWORD=mysecretpassword\")\n          .CopyOnStart(\"/etc/conf.d\", fullPath)\n          .Build()\n          .Start())\n        {\n        }\n```\n\nThe below example illustrates a much more common scenario where files are copied to the container. This example makes use of the extension method instead of the fluent API version. It takes a Diff snapshot before copy and then just after the copy. In the latter\nthe hello.html is present.\n```cs\n       using (\n          var container =\n            new Builder().UseContainer()\n              .UseImage(\"kiasaki/alpine-postgres\")\n              .ExposePort(5432)\n              .WithEnvironment(\"POSTGRES_PASSWORD=mysecretpassword\")\n              .Build()\n              .Start()\n              .WaitForProcess(\"postgres\", 30000 /*30s*/)\n              .Diff(out before)\n              .CopyTo(\"/bin\", fullPath))\n        {\n          var after = container.Diff();\n\n          Assert.IsFalse(before.Any(x => x.Item == \"/bin/hello.html\"));\n          Assert.IsTrue(after.Any(x => x.Item == \"/bin/hello.html\"));\n        }\n```\n\nSometime is it useful to copy files in the ```IContainerService.Dispose()``` (just before container has stopped). Therefore a fluent API exists to ensure that it will just do that.\n```cs\nusing (new Builder().UseContainer()\n          .UseImage(\"kiasaki/alpine-postgres\")\n          .ExposePort(5432)\n          .WithEnvironment(\"POSTGRES_PASSWORD=mysecretpassword\")\n          .CopyOnDispose(\"/etc/conf.d\", fullPath)\n          .Build()\n          .Start())\n        {\n        }\n```\nIn order to analyze a container, export extension method and fluent API methods exists. Most notably is the possibility to export a container when a ```IContainerService``` is disposed.\n```cs\n        using (new Builder().UseContainer()\n          .UseImage(\"kiasaki/alpine-postgres\")\n          .ExposePort(5432)\n          .WithEnvironment(\"POSTGRES_PASSWORD=mysecretpassword\")\n          .ExportOnDispose(fullPath)\n          .Build()\n          .Start())\n        {\n        }\n```\nThis will produce a container export (tar file) on the host (fullPath). If you rather have it exploded (un-tared) use the ```ExportExplodedOnDispose``` method instead. Of course you can export the container any time using a extension method on the container.\n\nA useful trick when it comes to unit-testing is to export the container state when the unit test fails for some reason, therefore it exists a Fluent API that will export when a certain Lambda condition is met. For example:\n```cs\n      var failure = false;\n        using (new Builder().UseContainer()\n          .UseImage(\"kiasaki/alpine-postgres\")\n          .ExposePort(5432)\n          .WithEnvironment(\"POSTGRES_PASSWORD=mysecretpassword\")\n          .ExportOnDispose(fullPath, svc => failure)\n          .Build()\n          .Start())\n        {\n          failure = true;\n        }\n```\nThis snippet will export the container when the using statement is disposing the container since the failure variable is set to true and is used in the ```ExportOnDispose``` expression.\n\n#### IService Hooks\nAll services can be extended with hooks. In the ```ExportOnDispose(path, lambda)``` installs a Hook when the service state is set to execute the lambda when the state is ```Removing```. It is possible to install and remove hooks on the fly. If multiple hooks are registered on same service instance, with same ```ServiceRunningState```, they will be executed in installation order. \n\nThe hooks are particulary good if you want something to be executed when a state is about to be set (or executed) on the service such as ```Starting```. The Fluent API makes use of those in some situations such as Copy files, export, etc.\n\n## Docker Networking\nFluentDocker do support all docker network commands. It can discover networks by ```_docker.NetworkLs()``` where it discovers all networks and some simple parameters defined in ```NetworkRow```. It can also inspect to gain deeper information about the network (such as which containers is in the network and Ipam configuration) by ```_docker.NetworkInspect(network:\"networkId\")```.\n\nIn order to create a new network, use the ```_docker.NetworkCreate(\"name_of_network\")```. It is also possible to supply ```NetworkCreateParams``` where everything can be customized such as creating a _overlay_ network och change the Ipam configuration. To delete a network, just use the ```_docker.NetworkRm(network:\"networkId\")```.\n\n*Note that networks are not deleted if there are any containers attached to it!*\n\nWhen a network is created it is possible to put one or more containers into it using the ```_docker.NetworkConnect(\"containerId\",\"networkId\")```. Note that containers may be in several networks at a time, thus can proxy request between isolated networks. To disconnect a container from a network, simple do a ```_docker.NetworkDisconnect(\"containerId\",\"networkId\")```.\n\nThe following sample runs a container, creates a new network, and connects the running container into the network. It then disconnect the container, delete it, and delete the network.\n```cs\n    var cmd = _docker.Run(\"postgres:9.6-alpine\", new ContainerCreateParams\n        {\n          PortMappings = new[] {\"40001:5432\"},\n          Environment = new[] {\"POSTGRES_PASSWORD=mysecretpassword\"}\n        }, _certificates);\n\n    var container = cmd.Data;\n    var network = string.Empty;\n\n    var created = _docker.NetworkCreate(\"test-network\");\n    if (created.Success)\n      network = created.Data[0];\n\n    _docker.NetworkConnect(container, network);\n\n    // Container is now running and has address in the newly created 'test-network'\n\n    _docker.NetworkDisconnect(container, id, true /*force*/);\n    _docker.RemoveContainer(container, true, true);\n\n    // Now it is possible to delete the network since it has been disconnected from the network\n    _docker.NetworkRm(network: network);\n```\n### Fluent Networking\nIt is also possible to use a fluent builder to build new or reuse existing docker networks. Those can then be referenced while building _containers_. It is possible to build more than one docker network and attach a container to more than one network at a time.\n```cs\n    using(var nw = new Builder().UseNetwork(\"test-network\")) \n    {\n      using (\n        var container =\n          new DockerBuilder()\n            .WithImage(\"kiasaki/alpine-postgres\")\n            .WithEnvironment(\"POSTGRES_PASSWORD=mysecretpassword\")\n            .ExposePorts(\"5432\")\n            .UseNetwork(nw)\n            .WaitForPort(\"5432/tcp\", 30000 /*30s*/)\n            .Build())\n      {\n        container.Create().Start();\n      }\n    }\n```\nThe above code snippet creates a new network called _test-network_ and then creates a container that is attached to the _test-network_. When the ```Dispose()``` is called on _nw_ it will remove the network.\nIt is also possible to do static _IP_ container assignments within the network by `UseIpV4` or `UseIpV6`. For example:\n```cs\nusing (var nw = Fd.UseNetwork(\"unit-test-nw\")\n                .UseSubnet(\"10.18.0.0/16\").Build())\n{\n\tusing (\n\t\tvar container =\n\t\tFd.UseContainer()\n\t\t\t.UseImage(\"postgres:9.6-alpine\")\n\t\t\t.WithEnvironment(\"POSTGRES_PASSWORD=mysecretpassword\")\n\t\t\t.ExposePort(5432)\n\t\t\t.UseNetwork(nw)\n\t\t\t.UseIpV4(\"10.18.0.22\")              \n\t\t\t.WaitForPort(\"5432/tcp\", 30000 /*30s*/)\n\t\t\t.Build()\n\t\t\t.Start())\n\t{\n\t\tvar ip = container.GetConfiguration().NetworkSettings.Networks[\"unit-test-nw\"].IPAddress;\n\t\tAssert.AreEqual(\"10.18.0.22\", ip);\n\t}\n}\n```\nThe above example creates a new network _unit-test-nw_ with ip-range _10.18.0.0/16_. It is the used in the new container. The IP for the container is set to _10.18.0.22_ and is static due to `UseIpV4` command.\n## Volume Support\nFluentDocker supports docker volume management both from commands and from a fluent API. Therefore it is possible to have total control on volumes used in container such if it shall be disposed, reused, what driver to use etc.\n\n```cs\n  var volume = _docker.VolumeCreate(\"test-volume\", \"local\", opts: {\n                                      {\"type\",\"nfs\"},\n                                      {\"o=addr\",\"192.168.1.1,rw\"},\n                                      {\"device\",\":/path/to/dir\"}\n                                    });\n\n  var cfg = _docker.VolumeInspect(_certificates, \"test-volume\");\n  _docker.VolumeRm(force: true, id: \"test-volume\");\n```\nThe above snippet creates a new volume with name _test-volume_ and is of _NFS_ type. It then inspects the just created volume and lastly force delete the volume.\n\n### Fluent Volume API\nIt is also possible to use a fluent API to create or use volumes. They can then be used when building a container. This is especially useful when creation of volumes are special or lifetime needs to be controlled.\n```cs\n      using (var vol = new Builder().UseVolume(\"test-volume\").RemoveOnDispose().Build())\n      {\n        using (\n          var container =\n            new Builder().UseContainer()\n              .UseImage(\"postgres:9.6-alpine\")\n              .WithEnvironment(\"POSTGRES_PASSWORD=mysecretpassword\")\n              .MountVolume(vol, \"/var/lib/postgresql/data\", MountType.ReadWrite)\n              .Build()\n              .Start())\n        {\n          var config = container.GetConfiguration();\n\n          Assert.AreEqual(1, config.Mounts.Length);\n          Assert.AreEqual(\"test-volume\", config.Mounts[0].Name);\n        }\n      }\n```\nThe above sample creates a new volume called _test-volume_ and it is scheduled to be delete when ```Dispose()``` is invoked on the ```IVolumeService```. The container is created and mounts the newly created volume to _/var/lib/postgresql/data_ as _read/write_ access mode.\nSince the container is within the scope of the ```using``` statement of the volume it's lifetime spans the whole container lifetime and then gets deleted.\n\n### Events\n\n_FluentDocker_ supports, connecting to the docker event mechanism to listen to the events it sends.\n\n```cs\nusing (var events = Fd.Native().Events())\n{\n  using (\n      var container =\n          new Builder().UseContainer()\n              .UseImage(\"postgres:9.6-alpine\")\n              .ExposePort(5432)\n              .WithEnvironment(\"POSTGRES_PASSWORD=mysecretpassword\")\n              .WaitForPort(\"5432/tcp\", 30000 /*30s*/)\n              .Build()\n              .Start())\n  {\n    FdEvent e;\n    while ((e= events.TryRead(3000)) != null)\n    {\n      if (e.Type == EventType.Container && e.Action == EventAction.Start)\n        break;\n    }\n  }\n}\n```\n\nEvent listener is global and may handle many `EventAction` types. \n\nFor example\n\n* Pull\n* Create\n* Start\n* Kill\n* Die\n* Connect\n* Disconnect\n* Stop\n* Destroy\n\nDepending on action, the event type may differ such as `ContainerKillEvent` for `EventAction.Kill`. All events derive from `FdEvent`. That means all shared properties is in the base event and the explicit ones are in the derived.\n\nFor example, the ´ContainerKillEvent` contains the following properties:\n\n```cs\npublic sealed class ContainerKillActor : EventActor\n{\n  /// <summary>\n  /// The image name and label such as \"alpine:latest\".\n  /// </summary>\n  public string Image { get; set; }\n  /// <summary>\n  /// Name of the container.\n  /// </summary>\n  public string Name { get; set; }\n  /// <summary>\n  /// The signal that the container has been signalled.\n  /// </summary>\n  public string Signal { get; set; }\n}\n```\n\nThis event loop may be used to pick up events and drive your instantiated `IService` instances. Or if you need to react to e.g. a network is added or deleted.\n\n### Logging\nIn the full framework it uses verbose logging using the ```System.Diagnostics.Debugger.Log```. For .net core it uses the standard\n```Microsoft.Extensions.Logging.ILog``` to log. Both are using the category _Ductus.FluentDocker_ and therefore may be configured\nto participate in logging or not and configure different logging destinations.\n\nIn .net core you can provide the logging segment in the application config file.\n```\n{\n  \"Logging\": {\n    \"IncludeScopes\": false,\n    \"LogLevel\": {\n      \"Ductus.FluentDocker\": \"None\"\n      }\n   }\n}\n```\nPlease check the https://docs.microsoft.com/en-us/aspnet/core/fundamentals/logging/?view=aspnetcore-2.1 for more information.\nFor full framework please check out the _XML_ needed in the appconfig for the full framework described in https://docs.microsoft.com/en-us/dotnet/framework/wcf/diagnostics/tracing/configuring-tracing.\n\nThere's a quick way of disabling / enabling logging via (```Ductus.FluentDocker.Services```) ```Logging.Enabled()``` or ```Logging.Disabled()```. This will forcefully enable / disable logging.\n\n### Custom IPEndpoint Resolvers\n\nIt is possible to override the default mechanism of _FluentDocker_ resolves the container IP from the clients perspective in e.g. `WaitForPort`. This can be overridden on `ContainerBuilder` basis.\n\nThe below sample, overrides the _default_ behaviour. When it returns `null` the _default_ resolver kicks in.\n  \n```cs\nusing (\n  var container =\n    Fd.UseContainer()\n      .UseImage(\"postgres:9.6-alpine\")\n      .WithEnvironment(\"POSTGRES_PASSWORD=mysecretpassword\")\n      .ExposePort(5432)\n      .UseCustomResolver((\n        ports, portAndProto, dockerUri) =>\n      {\n        if (null == ports || string.IsNullOrEmpty(portAndProto))\n          return null;\n\n        if (!ports.TryGetValue(portAndProto, out var endpoints))\n          return null;\n\n        if (null == endpoints || endpoints.Length == 0)\n          return null;\n\n        if (CommandExtensions.IsNative())\n          return endpoints[0];\n\n        if (CommandExtensions.IsEmulatedNative())\n          return CommandExtensions.IsDockerDnsAvailable()\n            ? new IPEndPoint(CommandExtensions.EmulatedNativeAddress(), endpoints[0].Port)\n            : new IPEndPoint(IPAddress.Loopback, endpoints[0].Port);\n\n        if (Equals(endpoints[0].Address, IPAddress.Any) && null != dockerUri)\n          return new IPEndPoint(IPAddress.Parse(dockerUri.Host), endpoints[0].Port);\n\n        return endpoints[0];\n      })\n      .WaitForPort(\"5432/tcp\", 30000 /*30s*/)\n      .Build()\n      .Start())\n{\n  var state = container.GetConfiguration(true/*force*/).State.ToServiceState();\n  Assert.AreEqual(ServiceRunningState.Running, state);\n}\n```\n\n### Talking to custom docker daemon URI without docker-machine\n\nThere's limited support to use the _FluentAPI_ to talk to a remote docker daemon without using docker-machine. This is done either by manually creating a instance of a `DockerHostService` or use `FromUri` on `HostBuilder`.\n\n```cs\n  using(var container = Fd.UseHost().\n                          FromUri(Settings.DockerUri, isWindowsHost: true).\n                          UseContainer().\n                          Build()) \n  {\n  }\n```\n\nThe above sample connects to a custom `DockerUri` from a setting and is a windows container docker daemon.\n\n\n* `FromUri` that uses a `DockerUri` to create a `IHostService`. This _uri_ is arbitrary. It also support other properties (_see below_).\n\n```cs\n   public HostBuilder FromUri(\n      DockerUri uri,\n      string name = null,\n      bool isNative = true,\n      bool stopWhenDisposed = false,\n      bool isWindowsHost = false,\n      string certificatePath = null) {/*...*/}\n```\n\nIt will use _\"sensible\"_ defaults on all parameters. Most of the case the _uri_ is sufficient. For example if not providing the _certificatePath_ it will try to get it from the environment _DOCKER_CERT_PATH_. If not found in the environment, it will default to none.\n\n* `UseHost` that takes a instantiated `IHostService` implementation.\n\n## Docker Compose Support\nThe library support _docker-compose_ to use existing compose files to render services and manage lifetime of such.\n\nThe following sample will do have compose file that fires up a _MySql_ and a _WordPress_. Therefore the single compose\nservice will have two _container_ services below it. By default, it will stop the services and clean up when \n```Dispose()``` is invoked. This can be overridden by ```KeepContainers()``` in the _fluent_ configuration.\n\n```yml\nversion: '3.3'\n\nservices:\n  db:\n    image: mysql:5.7\n    volumes:\n    - db_data:/var/lib/mysql\n    restart: always\n    environment:\n      MYSQL_ROOT_PASSWORD: somewordpress\n      MYSQL_DATABASE: wordpress\n      MYSQL_USER: wordpress\n      MYSQL_PASSWORD: wordpress\n\n  wordpress:\n    depends_on:\n    - db\n    image: wordpress:latest\n    ports:\n    - \"8000:80\"\n    restart: always\n    environment:\n      WORDPRESS_DB_HOST: db:3306\n      WORDPRESS_DB_USER: wordpress\n      WORDPRESS_DB_PASSWORD: wordpress\nvolumes:\n  db_data:\n``` \nThe above file is the _docker-compose_ file to stitch up the complete service.\n\n```cs\n      var file = Path.Combine(Directory.GetCurrentDirectory(),\n        (TemplateString) \"Resources/ComposeTests/WordPress/docker-compose.yml\");\n\n      using (var svc = new Builder()\n                        .UseContainer()\n                        .UseCompose()\n                        .FromFile(file)\n                        .RemoveOrphans()\n                        .Build().Start())\n      {\n        var installPage = await \"http://localhost:8000/wp-admin/install.php\".Wget();\n\n        Assert.IsTrue(installPage.IndexOf(\"https://wordpress.org/\", StringComparison.Ordinal) != -1);\n        Assert.AreEqual(1, svc.Hosts.Count);\n        Assert.AreEqual(2, svc.Containers.Count);\n        Assert.AreEqual(2, svc.Images.Count);\n        Assert.AreEqual(5, svc.Services.Count);\n      }\n``` \n The above snippet is fluently configuring the _docker-compose_ service and invokes the install page to verify that\n WordPress is indeed working.\n \n It is also possible to do all the operations that a single container supports such as copy on, export, wait operations. For example:\n```cs\n      var file = Path.Combine(Directory.GetCurrentDirectory(),\n        (TemplateString) \"Resources/ComposeTests/WordPress/docker-compose.yml\");\n\n      // @formatter:off\n      using (new Builder()\n                .UseContainer()\n                .UseCompose()\n                .FromFile(file)\n                .RemoveOrphans()\n                .WaitForHttp(\"wordpress\",  \"http://localhost:8000/wp-admin/install.php\", continuation: (resp, cnt) =>  \n                             resp.Body.IndexOf(\"https://wordpress.org/\", StringComparison.Ordinal) != -1 ? 0 : 500)\n                .Build().Start())\n        // @formatter:on\n      {\n        // Since we have waited - this shall now always work.       \n        var installPage = await \"http://localhost:8000/wp-admin/install.php\".Wget();\n        Assert.IsTrue(installPage.IndexOf(\"https://wordpress.org/\", StringComparison.Ordinal) != -1);\n      }\n```\nThe above snippet fires up the wordpress docker compose project and checks the _URL_ http://localhost:8000/wp-admin/install.php it it returns a certain value in the body \n(in this case \"https://wordpress.org/\"). If not it returns _500_ and the ```WaitForHttp``` function will wait 500 milliseconds before invoking again. This works for any custom\nlambda as well, just use ```WaitFor``` instead. Thus it is possible to e.g. query a database before continuing inside the using scope.\n\n## Talking to Docker Daemon\nFor Linux and Mac users there are several options how to authenticate towards the socket. _FluentDocker_ supports no _sudo_, _sudo_ without any password (user added as NOPASSWD in /etc/sudoer), or\n_sudo_ with password. The default is that FluentDocker expects to be able to talk without any _sudo_. The options ar global but can be changed in runtime.\n\n```cs\n     SudoMechanism.None.SetSudo(); // This is the default\n     SudoMechanism.Password.SetSudo(\"<my-sudo-password>\");\n     SudoMechanism.NoPassword.SetSudo();\n```\n\nIf you wish to turn off _sudo_ to communicate with the docker daemon, you can follow a docker [tutorial](https://docs.docker.com/install/linux/docker-ce/ubuntu/) and do the last step of adding your user to docker group.\n\n### Connecting to Remote Docker Daemons\nFluentDocker supports connection to remote docker daemons. The fluent API supports e.g. \n```cs\nnew Builder().UseHost().UseMachine().WithName(\"remote-daemon\")\n```\nwhere this requires a already pre-setup entry in the _docker-machine_ registry. It is also possible to\ndefine _SSH_ based _docker-machine_ registry entires to connect to remote daemon.\n\n```cs\n      using (\n        var container =\n          new Builder().UseHost()\n            .UseSsh(\"192.168.1.27\").WithName(\"remote-daemon\")\n            .WithSshUser(\"solo\").WithSshKeyPath(\"${E_LOCALAPPDATA}/lxss/home/martoffi/.ssh/id_rsa\")\n            .UseContainer()\n            .UseImage(\"postgres:9.6-alpine\")\n            .WithEnvironment(\"POSTGRES_PASSWORD=mysecretpassword\")\n            .Build())\n      {\n        Assert.AreEqual(ServiceRunningState.Stopped, container.State);\n      }\n```\nThis example will create a new _docker-machine_ registry entry named _remote-daemon_ that uses _SSH_ with\nip address of _192.168.1.27_ and the _SSH_ user _solo_. If a entry is already found named _remote-daemon_\nit will just reuse this entry. Then it gets a _IHostService_ with correct certificates and _URL_ for the\nremote daemon. Thus, it is possible then to create a docker container on the remote daemon, in thus case\nit is the _postgres_ image. When it disposes the container, as usual it deletes it from the remote docker.\nThe _IHostService_ do make sure to pick upp all necessary certificates in order to authenticate the connection.\n\nThe above example produces this _docker-machine_ registry entry.\n```\nC:\\Users\\martoffi>docker-machine ls\nNAME           ACTIVE   DRIVER    STATE     URL                       SWARM   DOCKER        ERRORS\nremote-daemon  *        generic   Running   tcp://192.168.1.27:2376           v18.06.1-ce\n```\n\nIn order to use ```UseSsh(...)``` a _SSH_ tunnel with no password must been set up. In addition the user\nthat uses the tunnel must be allowed to access the docker daemon.\n\nFollow these tutorial how to setup the _SSH_ tunnel and make sure the user can access the docker daemon.\n1) https://www.kevinkuszyk.com/2016/11/28/connect-your-docker-client-to-a-remote-docker-host/\n2) https://askubuntu.com/questions/192050/how-to-run-sudo-command-with-no-password\n\nBasically create a new rsa key to use with the _SSH_ tunnel using ```ssh-keygen -t rsa``` and then\ncopy it to the remote host by ```ssh-copy-id {username}@{host}```.\n\nEdit the /etc/sudoers as specified in the second tutorial.\n\nWhen this is done, you now can access the remote docker daemon by the generic driver or the fluent API\nspecified above. To do the same thing manually as specified in the example it would look something like this.\n\n\n```\nC:\\Users\\martoffi>docker-machine.exe create --driver generic --generic-ip-address=192.168.1.27 --generic-ssh-key=\"%localappdata%/lxss/home/martoffi/.ssh/id_rsa\" --generic-ssh-user=solo remote-daemon\nRunning pre-create checks...\nCreating machine...\n(remote-daemon) Importing SSH key...\nWaiting for machine to be running, this may take a few minutes...\nDetecting operating system of created instance...\nWaiting for SSH to be available...\nDetecting the provisioner...\nProvisioning with ubuntu(systemd)...\nInstalling Docker...\nCopying certs to the local machine directory...\nCopying certs to the remote machine...\nSetting Docker configuration on the remote daemon...\nChecking connection to Docker...\nDocker is up and running!\nTo see how to connect your Docker Client to the Docker Engine running on this virtual machine, run: docker-machine.exe env remote-daemon\n```\n\nNow the registry entry is created, it is possible set the environment for the terminal docker.\n\n```\nC:\\Users\\martoffi>docker-machine.exe env remote-daemon\nSET DOCKER_TLS_VERIFY=1\nSET DOCKER_HOST=tcp://192.168.1.24:2376\nSET DOCKER_CERT_PATH=C:\\Users\\martoffi\\.docker\\machine\\machines\\remote-daemon\nSET DOCKER_MACHINE_NAME=remote-daemon\nSET COMPOSE_CONVERT_WINDOWS_PATHS=true\nREM Run this command to configure your shell:\nREM     @FOR /f \"tokens=*\" %i IN ('docker-machine.exe env remote-daemon') DO @%i\n```\n\nRun this to make docker client use the remote docker daemon.\n```\n@FOR /f \"tokens=*\" %i IN ('docker-machine.exe env remote-daemon') DO @%i\n```\nAll commands using the ```docker``` binary will now execute on the remote docker daemon.\n\n### Hyper-V\nWhen creating and querying, via machine, a hyper-v docker machine the process needs to be elevated since Hyper-V will not\nrespond to API calls in standard user mode.\n\n## Misc\n\n### Health Check\nIt is possible to specify a health check for the docker container to report the state of the container based on such activity. The following example\nis using a health check that the container has exited or not. It is possible to check the configuration (make sure to force refresh) what status\nthe health check is reporting.\n```cs\n      using (\n        var container =\n          Fd.UseContainer()\n            .UseImage(\"postgres:latest\", force: true)\n            .HealthCheck(\"exit\")\n            .WithEnvironment(\"POSTGRES_PASSWORD=mysecretpassword\")\n            .Build()\n            .Start())\n      {\n        var config = container.GetConfiguration(true);\n        AreEqual(HealthState.Starting, config.State.Health.Status);\n      }\n```\n\n### ulimit\nIt is possible via the _Fluent API_ and `ContainerCreateParams` specify ulimit to the docker container to e.g. limit the number of open files etc. For example\nusing the _Fluent API_ could look like this when restricting the number of open files to 2048 (both soft and hard).\n```cs\nusing (\n        var container =\n          Fd.UseContainer()\n            .UseImage(\"postgres:latest\", force: true)\n            .UseUlimit(Ulimit.NoFile,2048, 2048)\n            .WithEnvironment(\"POSTGRES_PASSWORD=mysecretpassword\")\n            .Build()\n            .Start())\n      {\n        // Do stuff\n      }\n```\n\n## Test Support\nThis repo contains three nuget packages, one for the fluent access, one for ms-test base classes and another for xunit base classes to be used while testing. For example in a unit-test it is possible to fire up a postgres container and wait when the the db has booted.\n\n### XUnit\n```cs\n     public class PostgresXUnitTests : IClassFixture<PostgresTestBase>\n     {\n          [Fact]\n          public void Test()\n          {\n               // We now have a running postgres\n               // and a valid connection string to use.\n          }\n     }\n```\n\n\n### MSTest\n```cs\n     using (\n        var container =\n          new DockerBuilder()\n            .WithImage(\"kiasaki/alpine-postgres\")\n            .WithEnvironment(\"POSTGRES_PASSWORD=mysecretpassword\")\n            .ExposePorts(\"5432\")\n            .WaitForPort(\"5432/tcp\", 30000 /*30s*/)\n            .Build())\n      {\n        container.Create().Start();\n      }\n```\nIt is also possible to re-use abstract base classes, for example postgres test base to simplify and make clean unittest towards a container.\n```cs\n     [TestClass]\n     public class PostgresMsTests : PostgresTestBase\n     {\n          [TestMethod]\n          public void Test()\n          {\n               // We now have a running postgres\n               // and a valid connection string to use.\n          }\n     }\n```  \nThe `FluentDockerTestBase` allows for simple overrides to do whatever custom docker backed test easily. Just create a test class and derive from the `FluentDockerTestBase` and override suitable methods. For example.\n```cs\n     protected override DockerBuilder Build()\n     {\n          return new DockerBuilder()\n               .WithImage(\"kiasaki/alpine-postgres\")\n               .WithEnvironment($\"POSTGRES_PASSWORD={PostgresPassword}\")\n               .ExposePorts(\"5432\")\n               .WaitForPort(\"5432/tcp\", 30000 /*30s*/);\n     }\n```     \nThis will create a builder with docker image postgres:latest and set one environment string, it will also expose the postgres db port 5432 to the host so one can connect to the db within the container. Lastly it will wait for the port 5432. This ensures that the db is running and have properly booted. If timeout, in this example set to 30 seconds, it will throw an exception and the container is stopped and removed. Note that the host port is not 5432! Use `Container.GetHostPort(\"5432/tcp\")` to get the host port. The host ip can be retrieved by `Container.Host` property and thus shall be used when communicating with the app in the container. \n\nIf a callback is needed when the container has been successfully pulled, created, and started.\n```cs\n     protected override void OnContainerInitialized()\n     {\n          ConnectionString = string.Format(PostgresConnectionString, Container.Host,\n               Container.GetHostPort(\"5432/tcp\"), PostgresUser,\n               PostgresPassword, PostgresDb);\n     }\n```     \nThis example renders a proper connection string to the postgresql db within the newly spun up container. This can be used to connect using Npgsql, EF7, NHibernate, Marten or other compatible tools. This method will not be called if pulling of the image from the docker repository or it could not create/start the container.\n\nIf a before shutdown container hook is wanted override.\n```cs\n     protected virtual void OnContainerTearDown()\n     {\n          // Do stuff before container is shut down.\n     }\n```\nNote that if un-named container, if not properly disposed, the docker container will still run and must be manually removed. This is a feature not a bug since you might want several containers running in your test. The `DockerContainer` class manages the instance id of the container and thus only interact with it and no other container.\n\nWhen creating / starting a new container it will first check the local repository if the container image is already present and will download it if not found. This may take some time and there's just a Debug Log if enabled it is possible to monitor the download process.\n\n## Miscellanious\n\n### Unhandled Exceptions\nWhen a unhandled exception occurs and the application _FailFast_ i.e. terminates quickly it\nwill *not* invoke ```finally``` clause. Thus a failing ```WaitForPort``` inside a ```using``` statement will *not* \ndispose the container service. Therefore the container is is still running. To fix this, either have a global \ntry...catch or inject one locally e.g.\n```cs\n            try\n            {\n                using (var container =\n                        new Builder().UseContainer()\n                            .UseImage(\"postgres:9.6-alpine\")\n                            .ExposePort(5432)\n                            .WithEnvironment(\"POSTGRES_PASSWORD=postgres\")\n                            .WaitForPort(\"5777/tcp\", 10000) // Fail here since 5777 is not valid port\n                            .Build())\n                {\n                    container.Start(); // FluentDockerException is thrown here since WaitForPort is executed\n                }\n            } catch { throw; }\n```\nBut it this is only when application termination is done due to the ```FluentDockerException``` thrown in the\n```WaitForPort```, otherwise it will dispose the container properly and thus the ```try...catch``` is not needed.\n\nThis could also be solved using the ```Fd.Build``` functions (_see Using Builder Extensions_ for more information).\n\n### Using Builder Extensions\nThe class ```Fd``` is a static _class_ that provides convenience methods for building and running single\nand composed containers. To build a container just use:\n```cs\n    var build = Fd.Build(c => c.UseContainer()\n                    .UseImage(\"postgres:9.6-alpine\")\n                    .ExposePort(5432)\n                    .WithEnvironment(\"POSTGRES_PASSWORD=mysecretpassword\")\n                    .WaitForPort(\"5432/tcp\", TimeSpan.FromSeconds(30)));\n\n// This is the equivalent of\n    var build = new Builder().UseContainer()\n                             .UseImage(\"postgres:9.6-alpine\")\n                             .ExposePort(5432)\n                             .WithEnvironment(\"POSTGRES_PASSWORD=mysecretpassword\")\n                             .WaitForPort(\"5432/tcp\", TimeSpan.FromSeconds(30));\n```\nThis can then be used to start the containers within a _safe_ ```using``` clause that is **guaranteed** to be\ndisposed even if uncaught exception.\n```cs\n    build.Container(svc =>\n    {\n        var config = svc.GetConfiguration();\n        // Do stuff...\n    });   \n```\nAfter the ```Container``` method has been executed the container is in this case stopped and removed. This is the quivalent of\n```cs\n   // This is equivalent of\n    try\n    {\n        using(var svc = build.Build()) \n        {\n            svc.Start();\n            \n            var config = svc.GetConfiguration();\n            // Do stuff...            \n        }\n    }\n    catch\n    {\n        Log(...);\n        throw;\n    }\n```\n\n\nIt is also possible to combine builder and running e.g. via:\n```cs\n      Fd.Container(c => c.UseContainer()\n          .UseImage(\"postgres:9.6-alpine\")\n          .ExposePort(5432)\n          .WithEnvironment(\"POSTGRES_PASSWORD=mysecretpassword\")\n          .WaitForPort(\"5432/tcp\", TimeSpan.FromSeconds(30)),\n        svc =>\n        {\n          var config = svc.GetConfiguration();\n          // Do stuff...\n        });\n```\nThe above example will build the container, start, stop, and finally delete the container. Even if and\n```Exception``` is thrown it will be ```Disposed```. Of course it is possible to use compsed container using \n```composite``` extension methods as with ```container```.\n"
        },
        {
          "name": "appveyor.yml",
          "type": "blob",
          "size": 2.0078125,
          "content": "skip_non_tags: false\n#test: off\nimage: Visual Studio 2019\nconfiguration: Release\n\n# Only build when [release] is in the commit title\n#only_commits:\n#  message: /\\[release\\]/\n\nskip_commits:\n  files:\n    - Examples/**/*\n    - '**/*.md'\n\ndotnet_csproj:\n  patch: true\n  file: '**\\*.csproj'\n  version: '{version}'\n  package_version: '{version}'\n  assembly_version: '{version}'\n  file_version: '{version}'\n  informational_version: '{version}'\n\ninit:\n  - set PATH=C:\\Program Files\\Java\\jdk15\\bin;%PATH%\n  - set JAVA_HOME_11_X64=C:\\Program Files\\Java\\jdk15\n  - set JAVA_HOME=C:\\Program Files\\Java\\jdk15\n\ninstall:\n  - ps: Switch-DockerLinux\n  - ps: dotnet tool install -g GitVersion.Tool\n  - ps: dotnet tool install -g dotnet-format\n  - ps: dotnet tool install -g dotnet-sonarscanner -v:m\n\nbefore_build:\n  - nuget restore\n # - ps: dotnet format --check --dry-run\n  - ps: dotnet gitversion /l console /output buildserver\n  - ps: dotnet sonarscanner begin /d:sonar.host.url=https://sonarcloud.io /d:sonar.login=e220dd372506f00fe34923f011ea45f8568e9bcc /k:mariotoffia_FluentDocker /o:mariotoffia /v:\"$env:APPVEYOR_BUILD_NUMBER\" /d:sonar.cs.opencover.reportsPaths=\"./output/coverage.opencover.xml\" /d:sonar.coverage.exclusions=\"**Tests*.cs\"\n  - ps: $env:good_to_deploy=\"true\"\n  - ps: if (Test-Path env:APPVEYOR_PULL_REQUEST_HEAD_REPO_BRANCH) {echo \"Not going to deploy because pull request.\"}\n  - ps: if (Test-Path env:APPVEYOR_PULL_REQUEST_HEAD_REPO_BRANCH) {$env:good_to_deploy=\"false\"}\n  - echo good_to_deploy=%good_to_deploy%\n\nbuild:\n  project: FluentDocker.sln\n  publish_nuget: true\n  verbosity: minimal\n\ntest_script:\n  - ps: dotnet test --settings coverletArgs.runsettings --filter TestCategory=CI -f netcoreapp3.1\n\nafter_test:\n  - ps: dotnet sonarscanner end /d:sonar.login=e220dd372506f00fe34923f011ea45f8568e9bcc\n\nartifacts:\n  - path: '.\\**\\Release\\*.nupkg'\n    name: NuGet Packages\n\ndeploy:\n  - provider: NuGet\n    on:\n      branch: master\n      good_to_deploy: true\n    api_key:\n      secure: JltY4YIjjAWA5cjaWbc9b2LWTE41Wthz886xZt3zCXz3PZWF/JQ286freKBTNqnM\n"
        },
        {
          "name": "coverletArgs.runsettings",
          "type": "blob",
          "size": 0.396484375,
          "content": "<?xml version=\"1.0\" encoding=\"utf-8\" ?>\n<RunSettings>\n  <DataCollectionRunSettings>\n    <DataCollectors>\n      <DataCollector friendlyName=\"XPlat code coverage\">\n        <Configuration>\n          <Format>xml,opencover</Format>\n          <MergeWith>output/coverage.opencover.xml</MergeWith>\n        </Configuration>\n      </DataCollector>\n    </DataCollectors>\n  </DataCollectionRunSettings>\n</RunSettings>\n"
        },
        {
          "name": "docs",
          "type": "tree",
          "content": null
        },
        {
          "name": "global.json",
          "type": "blob",
          "size": 0.15625,
          "content": "{\n  \"$schema\": \"https://json.schemastore.org/global\",\n  \"sdk\": {\n    \"version\": \"5.0.200\",\n    \"allowPrerelease\": false,\n    \"rollForward\": \"latestMinor\"\n  }\n}\n"
        },
        {
          "name": "keypair.snk",
          "type": "blob",
          "size": 2.26953125,
          "content": null
        }
      ]
    }
  ]
}