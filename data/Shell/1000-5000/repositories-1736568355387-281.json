{
  "metadata": {
    "timestamp": 1736568355387,
    "page": 281,
    "hasNextPage": true,
    "endCursor": "Y3Vyc29yOjI5MA==",
    "completionStatus": "IN_PROGRESS"
  },
  "repositories": [
    {
      "nameWithOwner": "kubernetes/git-sync",
      "stars": 2306,
      "defaultBranch": "master",
      "files": [
        {
          "name": ".gitallowed",
          "type": "blob",
          "size": 0.009765625,
          "content": "xxxyyyzzz\n"
        },
        {
          "name": ".github",
          "type": "tree",
          "content": null
        },
        {
          "name": ".gitignore",
          "type": "blob",
          "size": 0.078125,
          "content": "/bin\n/.go\n/.push-*\n/.container-*\n/.dockerfile-*\n/.buildx-initialized\n/.licenses\n"
        },
        {
          "name": ".golangci.yaml",
          "type": "blob",
          "size": 0.5732421875,
          "content": "# This file configures checks that all new code for Kubernetes is meant to\n# pass, in contrast to .golangci.yaml which defines checks that also the\n# existing code passes.\n\nrun:\n  timeout: 30m\n\nlinters:\n  disable-all: false\n  enable: # please keep this alphabetized\n    - ginkgolinter\n    - gocritic\n    - govet\n    - ineffassign\n    # Should we add logcheck, for consistency with kubernetes/kubernetes?\n    # - logcheck\n    - staticcheck\n    - stylecheck\n    - unused\n\nlinters-settings: # please keep this alphabetized\n  gocritic:\n  staticcheck:\n    checks:\n      - \"all\"\n  stylecheck:\n"
        },
        {
          "name": "CONTRIBUTING.md",
          "type": "blob",
          "size": 0.693359375,
          "content": "# Contributing\n\nWelcome to git-sync!\n\nThe [Kubernetes community repo](https://github.com/kubernetes/community) contains information about how to get started, how the community organizes, and more.\n\n## Sign the CLA\n\nWe'd love to accept your patches, but before we can do that, you must sign the CNCF [Contributor License Agreement](https://git.k8s.io/community/contributors/guide/README.md#sign-the-cla).\n\n\n## Contributing A Patch\n\n1. Submit an issue describing your proposed change.\n1. If your proposal is accepted, and you haven't already done so, sign the Contributor License Agreement (see details above).\n1. Fork the repo, develop and test your code changes.  Don't forget tests!\n1. Submit a pull request.\n"
        },
        {
          "name": "Dockerfile.in",
          "type": "blob",
          "size": 5.6630859375,
          "content": "# Copyright 2016 The Kubernetes Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# HOW TO USE THIS CONTAINER:\n#\n# The only commandline argument (or env var) that is really required is\n# `--repo` ($GITSYNC_REPO).  Everything else is optional (run this with\n# `--man` for details).\n#\n# This container will run as UID:GID 65533:65533 by default.  For most users,\n# the simplest ways to use this container are either:\n#   a) use the default UID/GID and mount a volume on /git writeable by those\n#   b) set your own UID/GID and mount a volume on /git writeable by those\n#\n# If you mount a volume anywhere else, you must set `--root` ($GITSYNC_ROOT).\n# If you do not mount a volume, this will run but you can't access the results\n# (which might be useful for testing, but not much else).\n#\n# Newly created docker volumes (the very first `docker run -v`) are initialized\n# based on the in-image mountpoint's UID/GID?mode, so another solution for\n# using this with docker is to set your own UID/GID and also add the default\n# GID as a supplemental group (see `docker run --group-add`).\n#\n# Kubernetes offers `Pod.spec.securityContext.fsGroup` to manage volume\n# permissions.\n#\n# If you set any UID other than the default and want to use git over SSH, you\n# should set `--add-user` ($GITSYNC_ADD_USER).\n\n#############################################################################\n# First we prepare the image that we want, regardless of build layers.\n#############################################################################\nFROM {ARG_FROM} AS base\n\n# When building, we can pass a unique value (e.g. `date +%s`) for this arg,\n# which will force a rebuild from here (by invalidating docker's cache).\nARG FORCE_REBUILD=0\n\nRUN apt-get -y -qq -o Dpkg::Use-Pty=0 update\nRUN apt-get -y -qq -o Dpkg::Use-Pty=0 -y upgrade\n\nRUN apt-get -y -qq -o Dpkg::Use-Pty=0 install --no-install-recommends bash # for the staging scripts and ldd\nRUN mkdir -p {ARG_STAGING}\nCOPY stage_binaries.sh /\nRUN /stage_binaries.sh -o {ARG_STAGING} \\\n\t-p base-files \\\n\t-p bash \\\n\t-p coreutils \\\n\t-p git \\\n\t-p openssh-client \\\n\t-p ca-certificates \\\n\t-p curl \\\n\t-p socat \\\n\t-b /bin/grep \\\n\t-b /bin/sed \\\n\t-f /etc/debian_version \\\n\t-f /etc/group \\\n\t-f /etc/nsswitch.conf \\\n\t-f /etc/os-release \\\n\t-f /etc/passwd \\\n\t-f /tmp\nRUN ln -s /bin/bash {ARG_STAGING}/bin/sh # Not sure why this is not set up automatically\n\nFROM scratch AS intermediate\n\n# Docker doesn't do vars in COPY, so we can't use a regular ARG.\nCOPY --from=base {ARG_STAGING} /\n\n# This list is not generic - it is specific to git-sync on debian bookworm.\nRUN rm -rf \\\n    /usr/share/base-files \\\n    /usr/share/doc \\\n    /usr/share/man \\\n    /usr/lib/*-linux-gnu/gconv \\\n    /usr/bin/c_rehash \\\n    /usr/bin/git-shell \\\n    /usr/bin/openssl \\\n    /usr/bin/scalar \\\n    /usr/bin/scp \\\n    /usr/bin/sftp \\\n    /usr/bin/ssh-add \\\n    /usr/bin/ssh-agent \\\n    /usr/bin/ssh-keygen \\\n    /usr/bin/ssh-keyscan \\\n    /usr/lib/git-core/git-shell \\\n    /usr/bin/openssl \\\n    /usr/lib/git-core/git-daemon \\\n    /usr/lib/git-core/git-http-backend \\\n    /usr/lib/git-core/git-http-fetch \\\n    /usr/lib/git-core/git-http-push \\\n    /usr/lib/git-core/git-imap-send \\\n    /usr/lib/openssh/ssh-keysign \\\n    /usr/lib/openssh/ssh-pkcs11-helper \\\n    /usr/lib/openssh/ssh-sk-helper \\\n    /usr/share/gitweb\n\n# Add the default UID to /etc/passwd so SSH is satisfied.\nRUN echo \"git-sync:x:65533:65533::/tmp:/sbin/nologin\" >> /etc/passwd\n# A user might choose a different UID and set the `--add-user` flag, which\n# needs to be able to write to /etc/passwd.\nRUN chmod 0666 /etc/passwd\n\n# Add the default GID to /etc/group for completeness.\nRUN echo \"git-sync:x:65533:git-sync\" >> /etc/group\n\n# Make a directory that can be used to mount volumes.  Setting the mode to\n# include group-write allows users to run this image as a different user, as\n# long as they use our git-sync group.\nRUN mkdir -m 02775 /git && chown 65533:65533 /git\n\n# When building, we can pass a hash of the licenses tree, which docker checks\n# against its cache and can force a rebuild from here.\nARG HASH_LICENSES=0\n\n# Add third-party licenses.\nCOPY .licenses/ /LICENSES/\n\n# When building, we can pass a hash of the binary, which docker checks against\n# its cache and can force a rebuild from here.\nARG HASH_BINARY=0\n\n# Add the platform-specific binary.\nCOPY bin/{ARG_OS}_{ARG_ARCH}/{ARG_BIN} /{ARG_BIN}\n\n#############################################################################\n# Now we make a \"clean\" final image.\n#############################################################################\nFROM scratch\nCOPY --from=intermediate / /\n\n# Run as non-root by default.  There's simply no reason to run as root.\nUSER 65533:65533\n\n# Setting HOME ensures that whatever UID this ultimately runs as can write to\n# files like ~/.gitconfig.\nENV HOME=/tmp\nWORKDIR /tmp\n\n# Default values for flags.\n# Git-sync itself does not default the `--root` ($GITSYNC_ROOT) flag, but we\n# can set a default here, which makes the container image easier to use.  The\n# permissions were set for the default git-sync UID and GID.  If the user needs\n# a different group or sets `--root` ($GITSYNC_ROOT), their values will\n# override this, and we assume they are handling permissions themselves.\nENV GITSYNC_ROOT=/git\n\nENTRYPOINT [\"/{ARG_BIN}\"]\n"
        },
        {
          "name": "LICENSE",
          "type": "blob",
          "size": 11.0908203125,
          "content": "                                 Apache License\n                           Version 2.0, January 2004\n                        http://www.apache.org/licenses/\n\n   TERMS AND CONDITIONS FOR USE, REPRODUCTION, AND DISTRIBUTION\n\n   1. Definitions.\n\n      \"License\" shall mean the terms and conditions for use, reproduction,\n      and distribution as defined by Sections 1 through 9 of this document.\n\n      \"Licensor\" shall mean the copyright owner or entity authorized by\n      the copyright owner that is granting the License.\n\n      \"Legal Entity\" shall mean the union of the acting entity and all\n      other entities that control, are controlled by, or are under common\n      control with that entity. For the purposes of this definition,\n      \"control\" means (i) the power, direct or indirect, to cause the\n      direction or management of such entity, whether by contract or\n      otherwise, or (ii) ownership of fifty percent (50%) or more of the\n      outstanding shares, or (iii) beneficial ownership of such entity.\n\n      \"You\" (or \"Your\") shall mean an individual or Legal Entity\n      exercising permissions granted by this License.\n\n      \"Source\" form shall mean the preferred form for making modifications,\n      including but not limited to software source code, documentation\n      source, and configuration files.\n\n      \"Object\" form shall mean any form resulting from mechanical\n      transformation or translation of a Source form, including but\n      not limited to compiled object code, generated documentation,\n      and conversions to other media types.\n\n      \"Work\" shall mean the work of authorship, whether in Source or\n      Object form, made available under the License, as indicated by a\n      copyright notice that is included in or attached to the work\n      (an example is provided in the Appendix below).\n\n      \"Derivative Works\" shall mean any work, whether in Source or Object\n      form, that is based on (or derived from) the Work and for which the\n      editorial revisions, annotations, elaborations, or other modifications\n      represent, as a whole, an original work of authorship. For the purposes\n      of this License, Derivative Works shall not include works that remain\n      separable from, or merely link (or bind by name) to the interfaces of,\n      the Work and Derivative Works thereof.\n\n      \"Contribution\" shall mean any work of authorship, including\n      the original version of the Work and any modifications or additions\n      to that Work or Derivative Works thereof, that is intentionally\n      submitted to Licensor for inclusion in the Work by the copyright owner\n      or by an individual or Legal Entity authorized to submit on behalf of\n      the copyright owner. For the purposes of this definition, \"submitted\"\n      means any form of electronic, verbal, or written communication sent\n      to the Licensor or its representatives, including but not limited to\n      communication on electronic mailing lists, source code control systems,\n      and issue tracking systems that are managed by, or on behalf of, the\n      Licensor for the purpose of discussing and improving the Work, but\n      excluding communication that is conspicuously marked or otherwise\n      designated in writing by the copyright owner as \"Not a Contribution.\"\n\n      \"Contributor\" shall mean Licensor and any individual or Legal Entity\n      on behalf of whom a Contribution has been received by Licensor and\n      subsequently incorporated within the Work.\n\n   2. Grant of Copyright License. Subject to the terms and conditions of\n      this License, each Contributor hereby grants to You a perpetual,\n      worldwide, non-exclusive, no-charge, royalty-free, irrevocable\n      copyright license to reproduce, prepare Derivative Works of,\n      publicly display, publicly perform, sublicense, and distribute the\n      Work and such Derivative Works in Source or Object form.\n\n   3. Grant of Patent License. Subject to the terms and conditions of\n      this License, each Contributor hereby grants to You a perpetual,\n      worldwide, non-exclusive, no-charge, royalty-free, irrevocable\n      (except as stated in this section) patent license to make, have made,\n      use, offer to sell, sell, import, and otherwise transfer the Work,\n      where such license applies only to those patent claims licensable\n      by such Contributor that are necessarily infringed by their\n      Contribution(s) alone or by combination of their Contribution(s)\n      with the Work to which such Contribution(s) was submitted. If You\n      institute patent litigation against any entity (including a\n      cross-claim or counterclaim in a lawsuit) alleging that the Work\n      or a Contribution incorporated within the Work constitutes direct\n      or contributory patent infringement, then any patent licenses\n      granted to You under this License for that Work shall terminate\n      as of the date such litigation is filed.\n\n   4. Redistribution. You may reproduce and distribute copies of the\n      Work or Derivative Works thereof in any medium, with or without\n      modifications, and in Source or Object form, provided that You\n      meet the following conditions:\n\n      (a) You must give any other recipients of the Work or\n          Derivative Works a copy of this License; and\n\n      (b) You must cause any modified files to carry prominent notices\n          stating that You changed the files; and\n\n      (c) You must retain, in the Source form of any Derivative Works\n          that You distribute, all copyright, patent, trademark, and\n          attribution notices from the Source form of the Work,\n          excluding those notices that do not pertain to any part of\n          the Derivative Works; and\n\n      (d) If the Work includes a \"NOTICE\" text file as part of its\n          distribution, then any Derivative Works that You distribute must\n          include a readable copy of the attribution notices contained\n          within such NOTICE file, excluding those notices that do not\n          pertain to any part of the Derivative Works, in at least one\n          of the following places: within a NOTICE text file distributed\n          as part of the Derivative Works; within the Source form or\n          documentation, if provided along with the Derivative Works; or,\n          within a display generated by the Derivative Works, if and\n          wherever such third-party notices normally appear. The contents\n          of the NOTICE file are for informational purposes only and\n          do not modify the License. You may add Your own attribution\n          notices within Derivative Works that You distribute, alongside\n          or as an addendum to the NOTICE text from the Work, provided\n          that such additional attribution notices cannot be construed\n          as modifying the License.\n\n      You may add Your own copyright statement to Your modifications and\n      may provide additional or different license terms and conditions\n      for use, reproduction, or distribution of Your modifications, or\n      for any such Derivative Works as a whole, provided Your use,\n      reproduction, and distribution of the Work otherwise complies with\n      the conditions stated in this License.\n\n   5. Submission of Contributions. Unless You explicitly state otherwise,\n      any Contribution intentionally submitted for inclusion in the Work\n      by You to the Licensor shall be under the terms and conditions of\n      this License, without any additional terms or conditions.\n      Notwithstanding the above, nothing herein shall supersede or modify\n      the terms of any separate license agreement you may have executed\n      with Licensor regarding such Contributions.\n\n   6. Trademarks. This License does not grant permission to use the trade\n      names, trademarks, service marks, or product names of the Licensor,\n      except as required for reasonable and customary use in describing the\n      origin of the Work and reproducing the content of the NOTICE file.\n\n   7. Disclaimer of Warranty. Unless required by applicable law or\n      agreed to in writing, Licensor provides the Work (and each\n      Contributor provides its Contributions) on an \"AS IS\" BASIS,\n      WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or\n      implied, including, without limitation, any warranties or conditions\n      of TITLE, NON-INFRINGEMENT, MERCHANTABILITY, or FITNESS FOR A\n      PARTICULAR PURPOSE. You are solely responsible for determining the\n      appropriateness of using or redistributing the Work and assume any\n      risks associated with Your exercise of permissions under this License.\n\n   8. Limitation of Liability. In no event and under no legal theory,\n      whether in tort (including negligence), contract, or otherwise,\n      unless required by applicable law (such as deliberate and grossly\n      negligent acts) or agreed to in writing, shall any Contributor be\n      liable to You for damages, including any direct, indirect, special,\n      incidental, or consequential damages of any character arising as a\n      result of this License or out of the use or inability to use the\n      Work (including but not limited to damages for loss of goodwill,\n      work stoppage, computer failure or malfunction, or any and all\n      other commercial damages or losses), even if such Contributor\n      has been advised of the possibility of such damages.\n\n   9. Accepting Warranty or Additional Liability. While redistributing\n      the Work or Derivative Works thereof, You may choose to offer,\n      and charge a fee for, acceptance of support, warranty, indemnity,\n      or other liability obligations and/or rights consistent with this\n      License. However, in accepting such obligations, You may act only\n      on Your own behalf and on Your sole responsibility, not on behalf\n      of any other Contributor, and only if You agree to indemnify,\n      defend, and hold each Contributor harmless for any liability\n      incurred by, or claims asserted against, such Contributor by reason\n      of your accepting any such warranty or additional liability.\n\n   END OF TERMS AND CONDITIONS\n\n   APPENDIX: How to apply the Apache License to your work.\n\n      To apply the Apache License to your work, attach the following\n      boilerplate notice, with the fields enclosed by brackets \"{}\"\n      replaced with your own identifying information. (Don't include\n      the brackets!)  The text should be enclosed in the appropriate\n      comment syntax for the file format. We also recommend that a\n      file or class name and description of purpose be included on the\n      same \"printed page\" as the copyright notice for easier\n      identification within third-party archives.\n\n   Copyright {yyyy} {name of copyright owner}\n\n   Licensed under the Apache License, Version 2.0 (the \"License\");\n   you may not use this file except in compliance with the License.\n   You may obtain a copy of the License at\n\n       http://www.apache.org/licenses/LICENSE-2.0\n\n   Unless required by applicable law or agreed to in writing, software\n   distributed under the License is distributed on an \"AS IS\" BASIS,\n   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n   See the License for the specific language governing permissions and\n   limitations under the License.\n"
        },
        {
          "name": "Makefile",
          "type": "blob",
          "size": 10.6064453125,
          "content": "# Copyright 2016 The Kubernetes Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# The binary to build (just the basename).\nBIN := git-sync\n\n# Where to push the docker image.\nREGISTRY ?= gcr.io/k8s-staging-git-sync\n\n# This version-strategy uses git tags to set the version string\nVERSION ?= $(shell git describe --tags --always --dirty)\n#\n# This version-strategy uses a manual value to set the version string\n#VERSION ?= 1.2.3\n\n# Set these to cross-compile.\nGOOS ?=\nGOARCH ?=\n\n# Set this to 1 to build a debugger-friendly binary.\nDBG ?=\n\n# These are passed to docker when building and testing.\nHTTP_PROXY ?=\nHTTPS_PROXY ?=\n\n###\n### These variables should not need tweaking.\n###\n\nALL_PLATFORMS := linux/amd64 linux/arm linux/arm64 linux/ppc64le linux/s390x\n\n# Used internally.  Users should pass GOOS and/or GOARCH.\nOS := $(if $(GOOS),$(GOOS),$(shell go env GOOS))\nARCH := $(if $(GOARCH),$(GOARCH),$(shell go env GOARCH))\n\nBASEIMAGE ?= registry.k8s.io/build-image/debian-base:bookworm-v1.0.2\n\nIMAGE := $(REGISTRY)/$(BIN)\nTAG := $(VERSION)\nOS_ARCH_TAG := $(TAG)__$(OS)_$(ARCH)\n\nBUILD_IMAGE ?= golang:1.22\n\nDBG_MAKEFILE ?=\nifneq ($(DBG_MAKEFILE),1)\n    # If we're not debugging the Makefile, don't echo recipes.\n    MAKEFLAGS += -s\nendif\n\n# It's necessary to set this because some environments don't link sh -> bash.\nSHELL := /usr/bin/env bash -o errexit -o pipefail -o nounset\n\n# We don't need make's built-in rules.\nMAKEFLAGS += --no-builtin-rules\n# Be pedantic about undefined variables.\nMAKEFLAGS += --warn-undefined-variables\n.SUFFIXES:\n\n# If you want to build all binaries, see the 'all-build' rule.\n# If you want to build all containers, see the 'all-container' rule.\n# If you want to build AND push all containers, see the 'all-push' rule.\nall: build\n\n# For the following OS/ARCH expansions, we transform OS/ARCH into OS_ARCH\n# because make pattern rules don't match with embedded '/' characters.\n\nbuild-%:\n\t$(MAKE) build                         \\\n\t    --no-print-directory              \\\n\t    GOOS=$(firstword $(subst _, ,$*)) \\\n\t    GOARCH=$(lastword $(subst _, ,$*))\n\ncontainer-%:\n\t$(MAKE) container                     \\\n\t    --no-print-directory              \\\n\t    GOOS=$(firstword $(subst _, ,$*)) \\\n\t    GOARCH=$(lastword $(subst _, ,$*))\n\npush-%:\n\t$(MAKE) push                          \\\n\t    --no-print-directory              \\\n\t    GOOS=$(firstword $(subst _, ,$*)) \\\n\t    GOARCH=$(lastword $(subst _, ,$*))\n\nall-build: $(addprefix build-, $(subst /,_, $(ALL_PLATFORMS)))\n\nall-container: $(addprefix container-, $(subst /,_, $(ALL_PLATFORMS)))\n\nall-push: $(addprefix push-, $(subst /,_, $(ALL_PLATFORMS)))\n\nbuild: bin/$(OS)_$(ARCH)/$(BIN)\n\nBUILD_DIRS :=             \\\n    bin/$(OS)_$(ARCH)     \\\n    bin/tools             \\\n    .go/bin/$(OS)_$(ARCH) \\\n    .go/cache\n\n# The following structure defeats Go's (intentional) behavior to always touch\n# result files, even if they have not changed.  This will still run `go` but\n# will not trigger further work if nothing has actually changed.\nOUTBIN = bin/$(OS)_$(ARCH)/$(BIN)\n$(OUTBIN): .go/$(OUTBIN).stamp\n\ttrue\n\n# This will build the binary under ./.go and update the real binary iff needed.\n.PHONY: .go/$(OUTBIN).stamp\n.go/$(OUTBIN).stamp: $(BUILD_DIRS)\n\techo \"making $(OUTBIN)\"\n\tdocker run                                                 \\\n\t    -i                                                     \\\n\t    --rm                                                   \\\n\t    -u $$(id -u):$$(id -g)                                 \\\n\t    -v $$(pwd):/src                                        \\\n\t    -w /src                                                \\\n\t    -v $$(pwd)/.go/bin/$(OS)_$(ARCH):/go/bin               \\\n\t    -v $$(pwd)/.go/bin/$(OS)_$(ARCH):/go/bin/$(OS)_$(ARCH) \\\n\t    -v $$(pwd)/.go/cache:/.cache                           \\\n\t    --env HTTP_PROXY=$(HTTP_PROXY)                         \\\n\t    --env HTTPS_PROXY=$(HTTPS_PROXY)                       \\\n\t    $(BUILD_IMAGE)                                         \\\n\t    /bin/sh -c \"                                           \\\n\t        ARCH=$(ARCH)                                       \\\n\t        OS=$(OS)                                           \\\n\t        VERSION=$(VERSION)                                 \\\n\t        BUILD_DEBUG=$(DBG)                                 \\\n\t        ./build/build.sh                                   \\\n\t    \"\n\tif ! cmp -s .go/$(OUTBIN) $(OUTBIN); then  \\\n\t    mv .go/$(OUTBIN) $(OUTBIN);            \\\n\t    date >$@;                              \\\n\tfi\n\n# Used to track state in hidden files.\nDOTFILE_IMAGE = $(subst /,_,$(IMAGE))-$(OS_ARCH_TAG)\n\nLICENSES = .licenses\n\n$(LICENSES):\n\tpushd tools >/dev/null;                                   \\\n\t  export GOOS=$(shell go env GOHOSTOS);                   \\\n\t  export GOARCH=$(shell go env GOHOSTARCH);               \\\n\t  go build -o ../bin/tools github.com/google/go-licenses; \\\n\t  popd >/dev/null\n\trm -rf $(LICENSES)\n\t./bin/tools/go-licenses save ./... --save_path=$(LICENSES)\n\tchmod -R a+rx $(LICENSES)\n\n# Set this to any value to skip repeating the apt-get steps.  Caution.\nALLOW_STALE_APT ?=\n\ncontainer: .container-$(DOTFILE_IMAGE) container-name\n.container-$(DOTFILE_IMAGE): bin/$(OS)_$(ARCH)/$(BIN) $(LICENSES) Dockerfile.in .buildx-initialized\n\tsed                                  \\\n\t    -e 's|{ARG_BIN}|$(BIN)|g'        \\\n\t    -e 's|{ARG_ARCH}|$(ARCH)|g'      \\\n\t    -e 's|{ARG_OS}|$(OS)|g'          \\\n\t    -e 's|{ARG_FROM}|$(BASEIMAGE)|g' \\\n\t    -e 's|{ARG_STAGING}|/staging|g' \\\n\t    Dockerfile.in > .dockerfile-$(OS)_$(ARCH)\n\tHASH_LICENSES=$$(find $(LICENSES) -type f                    \\\n\t    | xargs md5sum | md5sum | cut -f1 -d' ');                \\\n\tHASH_BINARY=$$(md5sum bin/$(OS)_$(ARCH)/$(BIN)               \\\n\t    | cut -f1 -d' ');                                        \\\n\tFORCE=0;                                                     \\\n\tif [ -z \"$(ALLOW_STALE_APT)\" ]; then FORCE=$$(date +%s); fi; \\\n\tdocker buildx build                                          \\\n\t    --builder git-sync                                       \\\n\t    --build-arg FORCE_REBUILD=\"$$FORCE\"                      \\\n\t    --build-arg HASH_LICENSES=\"$$HASH_LICENSES\"              \\\n\t    --build-arg HASH_BINARY=\"$$HASH_BINARY\"                  \\\n\t    --progress=plain                                         \\\n\t    --load                                                   \\\n\t    --platform \"$(OS)/$(ARCH)\"                               \\\n\t    --build-arg HTTP_PROXY=$(HTTP_PROXY)                     \\\n\t    --build-arg HTTPS_PROXY=$(HTTPS_PROXY)                   \\\n\t    -t $(IMAGE):$(OS_ARCH_TAG)                               \\\n\t    -f .dockerfile-$(OS)_$(ARCH)                             \\\n\t    .\n\tdocker images -q $(IMAGE):$(OS_ARCH_TAG) > $@\n\ncontainer-name:\n\techo \"container: $(IMAGE):$(OS_ARCH_TAG)\"\n\techo\n\npush: .push-$(DOTFILE_IMAGE) push-name\n.push-$(DOTFILE_IMAGE): .container-$(DOTFILE_IMAGE)\n\tdocker push $(IMAGE):$(OS_ARCH_TAG)\n\tdocker images -q $(IMAGE):$(OS_ARCH_TAG) > $@\n\npush-name:\n\techo \"pushed: $(IMAGE):$(OS_ARCH_TAG)\"\n\techo\n\n# This depends on github.com/estesp/manifest-tool in $PATH.\nmanifest-list: all-push\n\techo \"manifest-list: $(REGISTRY)/$(BIN):$(TAG)\"\n\tpushd tools >/dev/null;                                   \\\n\t  export GOOS=$(shell go env GOHOSTOS);                   \\\n\t  export GOARCH=$(shell go env GOHOSTARCH);               \\\n\t  go build -o ../bin/tools github.com/estesp/manifest-tool/v2/cmd/manifest-tool; \\\n\t  popd >/dev/null\n\tplatforms=$$(echo $(ALL_PLATFORMS) | sed 's/ /,/g');  \\\n\t./bin/tools/manifest-tool                             \\\n\t    --username=oauth2accesstoken                      \\\n\t    --password=$$(gcloud auth print-access-token)     \\\n\t    push from-args                                    \\\n\t    --platforms \"$$platforms\"                         \\\n\t    --template $(REGISTRY)/$(BIN):$(TAG)__OS_ARCH \\\n\t    --target $(REGISTRY)/$(BIN):$(TAG)\n\nrelease:\n\tif [ -z \"$(TAG)\" ]; then        \\\n\t\techo \"ERROR: TAG must be set\"; \\\n\t\tfalse;                  \\\n\tfi\n\tdocker pull \"$(BUILD_IMAGE)\"\n\tgit tag -am \"$(TAG)\" \"$(TAG)\"\n\tmake manifest-list\n\nversion:\n\techo $(VERSION)\n\ntest: $(BUILD_DIRS)\n\tdocker run                                                 \\\n\t    -i                                                     \\\n\t    -u $$(id -u):$$(id -g)                                 \\\n\t    -v $$(pwd):/src                                        \\\n\t    -w /src                                                \\\n\t    -v $$(pwd)/.go/bin/$(OS)_$(ARCH):/go/bin               \\\n\t    -v $$(pwd)/.go/bin/$(OS)_$(ARCH):/go/bin/$(OS)_$(ARCH) \\\n\t    -v $$(pwd)/.go/cache:/.cache                           \\\n\t    --env HTTP_PROXY=$(HTTP_PROXY)                         \\\n\t    --env HTTPS_PROXY=$(HTTPS_PROXY)                       \\\n\t    $(BUILD_IMAGE)                                         \\\n\t    /bin/sh -c \"                                           \\\n\t        ./build/test.sh ./...                              \\\n\t    \"\n\tVERBOSE=1 ./test_e2e.sh\n\nTEST_TOOLS := $(shell find _test_tools/* -type d -printf \"%f \")\ntest-tools: $(foreach tool, $(TEST_TOOLS), .container-test_tool.$(tool))\n\n.container-test_tool.%: _test_tools/% _test_tools/%/*\n\tdocker build -t $(REGISTRY)/test/$$(basename $<) $<\n\tdocker images -q $(REGISTRY)/test/$$(basename $<) > $@\n\n# Help set up multi-arch build tools.  This assumes you have the tools\n# installed.  If you already have a buildx builder available, you don't need\n# this.  See https://medium.com/@artur.klauser/building-multi-architecture-docker-images-with-buildx-27d80f7e2408\n# for great context.\n.buildx-initialized:\n\tdocker buildx create --name git-sync --node git-sync-0 >/dev/null\n\tdocker run --rm --privileged multiarch/qemu-user-static --reset -p yes >/dev/null\n\tdate > $@\n\n$(BUILD_DIRS):\n\tmkdir -p $@\n\nclean: container-clean bin-clean\n\ncontainer-clean:\n\trm -rf .container-* .dockerfile-* .push-* .buildx-initialized $(LICENSES)\n\nbin-clean:\n\trm -rf .go bin\n\nlint-staticcheck:\n\tgo run honnef.co/go/tools/cmd/staticcheck@2023.1.3\n\nlint-golangci-lint:\n\tgo run github.com/golangci/golangci-lint/cmd/golangci-lint@v1.59.0 run\n\nlint-shellcheck:\n\tdocker run \\\n\t    --rm \\\n\t    -v `pwd`:`pwd` \\\n\t    -w `pwd` \\\n\t    docker.io/koalaman/shellcheck-alpine:v0.9.0 \\\n\t        shellcheck \\\n\t        $$(git ls-files ':!:vendor' '*.sh')\n\nlint: lint-staticcheck lint-golangci-lint lint-shellcheck\n"
        },
        {
          "name": "OWNERS",
          "type": "blob",
          "size": 0.048828125,
          "content": "approvers:\n- thockin\n- stp-ip\n- janetkuo\n- nan-yu\n"
        },
        {
          "name": "README.md",
          "type": "blob",
          "size": 26.49609375,
          "content": "# NOTE: THIS DOCUMENT COVERS GIT-SYNC v4\n\nThis is the \"master\" branch, which is under development.  If you are looking \nfor docs on older (v3) versions of git-sync, you probably want to use the\n[v3.x branch](https://github.com/kubernetes/git-sync/tree/release-3.x).\n\n# git-sync\n\ngit-sync is a simple command that pulls a git repository into a local\ndirectory, waits for a while, then repeats.  As the remote repository changes,\nthose changes will be synced locally.  It is a perfect \"sidecar\" container in\nKubernetes - it can pull files down from a repository so that an application\ncan consume them.\n\ngit-sync can pull one time, or on a regular interval.  It can pull from the\nHEAD of a branch, from a git tag, or from a specific git hash.  It will only\nre-pull if the referenced target has changed in the upstream repository (e.g. a\nnew commit on a branch).  It \"publishes\" each sync through a worktree and a\nnamed symlink.  This ensures an atomic update - consumers will not see a\npartially constructed view of the local repository.\n\ngit-sync can pull over HTTP(S) (with authentication or not) or SSH.\n\ngit-sync can also be configured to make a webhook call or exec a command upon\nsuccessful git repo synchronization. The call is made after the symlink is\nupdated.\n\n## What it produces and why - the contract\n\ngit-sync has two required flags: `--repo`, which specifies which remote git\nrepo to sync, and `--root` which specifies a working directory for git-sync,\nwhich presents an \"API\" of sorts.\n\nThe `--root` directory is _not_ the synced data.\n\nInside the `--root` directory git-sync stores the synced git state and other\nthings.  That directory may or may not respond to git commands - it's an\nimplementation detail.\n\nOne of the things in that directory is a symlink (see the `--link` flag) to the\nmost recently synced data.  This is how the data is expected to be consumed,\nand is considered to be the \"contract\" between git-sync and consumers.  The\nexact target of that symlink is an implementation detail, but the leaf\ncomponent of the target (i.e. `basename \"$(readlink <link>)\"`) is the git hash\nof the synced revision.  This is also part of the contract.\n\ngit-sync looks for changes in the remote repo periodically (see the `--period`\nflag) and will attempt to transfer as little data as possible and use as little\ndisk space as possible (see the `--depth` and `--git-gc` flags), but this is\nnot part of the contract.\n\n### Why the symlink?\n\ngit checkouts are not \"atomic\" operations.  If you look at the repository while\na checkout is happening, you might see data that is neither exactly the old\nrevision nor the new.  git-sync \"publishes\" updates via the symlink to present\nan atomic interface to consumers.  When the remote repo has changed, git-sync\nwill fetch the data _without_ checking it out, then create a new worktree, then\nchange the symlink to point to that new worktree.\n\ngit-sync does not currently have a no-symlink mode.\n\n## Major update: v3.x -> v4.x\n\ngit-sync has undergone many significant changes between v3.x and v4.x.  [See\nhere](v3-to-v4.md) for more details.\n\n## Building it\n\nWe use [docker buildx](https://github.com/docker/buildx) to build images.\n\n```\n# build the container\nmake container REGISTRY=registry VERSION=tag\n```\n\n```\n# build the container behind a proxy\nmake container REGISTRY=registry VERSION=tag \\\n    HTTP_PROXY=http://<proxy_address>:<proxy_port> \\\n    HTTPS_PROXY=https://<proxy_address>:<proxy_port>\n```\n\n```\n# build the container for an OS/arch other than the current (e.g. you are on\n# MacOS and want to run on Linux)\nmake container REGISTRY=registry VERSION=tag \\\n    GOOS=linux GOARCH=amd64\n```\n\n## Usage\n\n```\n# make a directory (owned by you) for the volume\nexport DIR=\"/tmp/git-data\"\nmkdir -p $DIR\n\n# run the container (as your own UID)\ndocker run -d \\\n    -v $DIR:/tmp/git \\\n    -u$(id -u):$(id -g) \\\n    registry/git-sync:tag \\\n        --repo=https://github.com/kubernetes/git-sync \\\n        --root=/tmp/git/root \\\n        --period=30s\n\n# run an nginx container to serve the content\ndocker run -d \\\n    -p 8080:80 \\\n    -v $DIR:/usr/share/nginx/html \\\n    nginx\n```\n\n### Flags\n\ngit-sync has many flags and optional features (see the manual below).  Most of\nthose flags can be configured through environment variables, but in most cases\n(with the obvious exception of passwords) flags are preferred, because the\nprogram can abort if an invalid flag is specified, but a misspelled environment\nvariable will just be ignored.  We've tried to stay backwards-compatible across\nmajor versions (by accepting deprecated flags and environment variables), but\nsome things have evolved, and users are encouraged to use the most recent flags\nfor their major version.\n\n### Volumes\n\nThe `--root` flag must indicate either a directory that either a) does not\nexist (it will be created); or b) exists and is empty; or c) can be emptied by\nremoving all of the contents.\n\nWhy?  Git really wants an empty directory, to avoid any confusion.  If the\ndirectory exists and is not empty, git-sync will try to empty it by removing\neverything in it (we can't just `rm -rf` the dir because it might be a mounted\nvolume).  If that fails, git-sync will abort.\n\nWith the above example or with a Kubernetes `emptyDir`, there is usually no\nproblem.  The problematic case is when the volume is the root of a filesystem,\nwhich sometimes contains metadata (e.g. ext{2,3,4} have a `lost+found` dir).\nThe only real solution is to use a sub-directory of the volume as the `--root`.\n\n## More docs\n\nMore documentation on specific topics can be [found here](./docs).\n\n## Manual\n\n```\nGIT-SYNC\n\nNAME\n    git-sync - sync a remote git repository\n\nSYNOPSIS\n    git-sync --repo=<repo> --root=<path> [OPTIONS]...\n\nDESCRIPTION\n\n    Fetch a remote git repository to a local directory, poll the remote for\n    changes, and update the local copy.\n\n    This is a perfect \"sidecar\" container in Kubernetes.  For example, it can\n    periodically pull files down from a repository so that an application can\n    consume them.\n\n    git-sync can pull one time, or on a regular interval.  It can read from the\n    HEAD of a branch, from a git tag, or from a specific git hash.  It will only\n    re-pull if the target has changed in the remote repository.  When it\n    re-pulls, it updates the destination directory atomically.  In order to do\n    this, it uses a git worktree in a subdirectory of the --root and flips a\n    symlink.\n\n    git-sync can pull over HTTP(S) (with authentication or not) or SSH.\n\n    git-sync can also be configured to make a webhook call upon successful git\n    repo synchronization.  The call is made after the symlink is updated.\n\nCONTRACT\n\n    git-sync has two required flags:\n      --repo: specifies which remote git repo to sync\n      --root: specifies a working directory for git-sync\n\n    The root directory is not the synced data.\n\n    Inside the root directory, git-sync stores the synced git state and other\n    things.  That directory may or may not respond to git commands - it's an\n    implementation detail.\n\n    One of the things in that directory is a symlink (see the --link flag) to\n    the most recently synced data.  This is how the data is expected to be\n    consumed, and is considered to be the \"contract\" between git-sync and\n    consumers.  The exact target of that symlink is an implementation detail,\n    but the leaf component of the target (i.e. basename \"$(readlink <link>)\")\n    is the git hash of the synced revision.  This is also part of the contract.\n\n    Why the symlink?  git checkouts are not \"atomic\" operations.  If you look\n    at the repository while a checkout is happening, you might see data that is\n    neither exactly the old revision nor the new.  git-sync \"publishes\" updates\n    via the symlink to present an atomic interface to consumers.  When the\n    remote repo has changed, git-sync will fetch the data _without_ checking it\n    out, then create a new worktree, then change the symlink to point to that\n    new worktree.\n\n    git-sync looks for changes in the remote repo periodically (see the\n    --period flag) and will attempt to transfer as little data as possible and\n    use as little disk space as possible (see the --depth and --git-gc flags),\n    but this is not part of the contract.\n\nOPTIONS\n\n    Many options can be specified as either a commandline flag or an environment\n    variable, but flags are preferred because a misspelled flag is a fatal\n    error while a misspelled environment variable is silently ignored.  Some\n    options can only be specified as an environment variable.\n\n    --add-user, $GITSYNC_ADD_USER\n            Add a record to /etc/passwd for the current UID/GID.  This is\n            needed to use SSH with an arbitrary UID.  This assumes that\n            /etc/passwd is writable by the current UID.\n\n    --askpass-url <string>, $GITSYNC_ASKPASS_URL\n            A URL to query for git credentials.  The query must return success\n            (200) and produce a series of key=value lines, including\n            \"username=<value>\" and \"password=<value>\".\n\n    --cookie-file <string>, $GITSYNC_COOKIE_FILE\n            Use a git cookiefile (/etc/git-secret/cookie_file) for\n            authentication.\n\n    --credential <string>, $GITSYNC_CREDENTIAL\n            Make one or more credentials available for authentication (see git\n            help credential).  This is similar to --username and\n            $GITSYNC_PASSWORD or --password-file, but for specific URLs, for\n            example when using submodules.  The value for this flag is either a\n            JSON-encoded object (see the schema below) or a JSON-encoded list\n            of that same object type.  This flag may be specified more than\n            once.\n\n            Object schema:\n              - url:            string, required\n              - username:       string, required\n              - password:       string, optional\n              - password-file:  string, optional\n\n            One of password or password-file must be specified.  Users should\n            prefer password-file for better security.\n\n            Example:\n              --credential='{\"url\":\"https://github.com\", \"username\":\"myname\", \"password-file\":\"/creds/mypass\"}'\n\n    --depth <int>, $GITSYNC_DEPTH\n            Create a shallow clone with history truncated to the specified\n            number of commits.  If not specified, this defaults to syncing a\n            single commit.  Setting this to 0 will sync the full history of the\n            repo.\n\n    --error-file <string>, $GITSYNC_ERROR_FILE\n            The path to an optional file into which errors will be written.\n            This may be an absolute path or a relative path, in which case it\n            is relative to --root.\n\n    --exechook-backoff <duration>, $GITSYNC_EXECHOOK_BACKOFF\n            The time to wait before retrying a failed --exechook-command.  If\n            not specified, this defaults to 3 seconds (\"3s\").\n\n    --exechook-command <string>, $GITSYNC_EXECHOOK_COMMAND\n            An optional command to be executed after syncing a new hash of the\n            remote repository.  This command does not take any arguments and\n            executes with the synced repo as its working directory.  The\n            $GITSYNC_HASH environment variable will be set to the git hash that\n            was synced.  If, at startup, git-sync finds that the --root already\n            has the correct hash, this hook will still be invoked.  This means\n            that hooks can be invoked more than one time per hash, so they\n            must be idempotent.  This flag obsoletes --sync-hook-command, but\n            if sync-hook-command is specified, it will take precedence.\n\n    --exechook-timeout <duration>, $GITSYNC_EXECHOOK_TIMEOUT\n            The timeout for the --exechook-command.  If not specifid, this\n            defaults to 30 seconds (\"30s\").\n\n    --git <string>, $GITSYNC_GIT\n            The git command to run (subject to PATH search, mostly for\n            testing).  This defaults to \"git\".\n\n    --git-config <string>, $GITSYNC_GIT_CONFIG\n            Additional git config options in a comma-separated 'key:val'\n            format.  The parsed keys and values are passed to 'git config' and\n            must be valid syntax for that command.\n\n            Both keys and values can be either quoted or unquoted strings.\n            Within quoted keys and all values (quoted or not), the following\n            escape sequences are supported:\n                '\\n' => [newline]\n                '\\t' => [tab]\n                '\\\"' => '\"'\n                '\\,' => ','\n                '\\\\' => '\\'\n            To include a colon within a key (e.g. a URL) the key must be\n            quoted.  Within unquoted values commas must be escaped.  Within\n            quoted values commas may be escaped, but are not required to be.\n            Any other escape sequence is an error.\n\n    --git-gc <string>, $GITSYNC_GIT_GC\n            The git garbage collection behavior: one of \"auto\", \"always\",\n            \"aggressive\", or \"off\".  If not specified, this defaults to\n            \"auto\".\n\n            - auto: Run \"git gc --auto\" once per successful sync.  This mode\n              respects git's gc.* config params.\n            - always: Run \"git gc\" once per successful sync.\n            - aggressive: Run \"git gc --aggressive\" once per successful sync.\n              This mode can be slow and may require a longer --sync-timeout value.\n            - off: Disable explicit git garbage collection, which may be a good\n              fit when also using --one-time.\n\n    --github-base-url <string>, $GITSYNC_GITHUB_BASE_URL\n            The GitHub base URL to use in GitHub requests when GitHub app\n            authentication is used. If not specified, defaults to\n            https://api.github.com/.\n\n    --github-app-private-key-file <string>, $GITSYNC_GITHUB_APP_PRIVATE_KEY_FILE\n            The file from which the private key to use for GitHub app\n            authentication will be read.\n\n    --github-app-installation-id <int>, $GITSYNC_GITHUB_APP_INSTALLATION_ID\n            The installation ID of the GitHub app used for GitHub app\n            authentication.\n\n    --github-app-application-id <int>, $GITSYNC_GITHUB_APP_APPLICATION_ID\n            The app ID of the GitHub app used for GitHub app authentication.\n            One of --github-app-application-id or --github-app-client-id is required\n            when GitHub app authentication is used.\n\n    --github-app-client-id <int>, $GITSYNC_GITHUB_APP_CLIENT_ID\n            The client ID of the GitHub app used for GitHub app authentication.\n            One of --github-app-application-id or --github-app-client-id is required\n            when GitHub app authentication is used.\n\n    --group-write, $GITSYNC_GROUP_WRITE\n            Ensure that data written to disk (including the git repo metadata,\n            checked out files, worktrees, and symlink) are all group writable.\n            This corresponds to git's notion of a \"shared repository\".  This is\n            useful in cases where data produced by git-sync is used by a\n            different UID.  This replaces the older --change-permissions flag.\n\n    -?, -h, --help\n            Print help text and exit.\n\n    --http-bind <string>, $GITSYNC_HTTP_BIND\n            The bind address (including port) for git-sync's HTTP endpoint.\n            The '/' URL of this endpoint is suitable for Kubernetes startup and\n            liveness probes, returning a 5xx error until the first sync is\n            complete, and a 200 status thereafter. If not specified, the HTTP\n            endpoint is not enabled.\n\n            Examples:\n              \":1234\": listen on any IP, port 1234\n              \"127.0.0.1:1234\": listen on localhost, port 1234\n\n    --http-metrics, $GITSYNC_HTTP_METRICS\n            Enable metrics on git-sync's HTTP endpoint at /metrics.  Requires\n            --http-bind to be specified.\n\n    --http-pprof, $GITSYNC_HTTP_PPROF\n            Enable the pprof debug endpoints on git-sync's HTTP endpoint at\n            /debug/pprof.  Requires --http-bind to be specified.\n\n    --link <string>, $GITSYNC_LINK\n            The path to at which to create a symlink which points to the\n            current git directory, at the currently synced hash.  This may be\n            an absolute path or a relative path, in which case it is relative\n            to --root.  Consumers of the synced files should always use this\n            link - it is updated atomically and should always be valid.  The\n            basename of the target of the link is the current hash.  If not\n            specified, this defaults to the leaf dir of --repo.\n\n    --man\n            Print this manual and exit.\n\n    --max-failures <int>, $GITSYNC_MAX_FAILURES\n            The number of consecutive failures allowed before aborting.\n            Setting this to a negative value will retry forever.  If not\n            specified, this defaults to 0, meaning any sync failure will\n            terminate git-sync.\n\n    --one-time, $GITSYNC_ONE_TIME\n            Exit after one sync.\n\n    $GITSYNC_PASSWORD\n            The password or personal access token (see github docs) to use for\n            git authentication (see --username).  See also --password-file.\n\n    --password-file <string>, $GITSYNC_PASSWORD_FILE\n            The file from which the password or personal access token (see\n            github docs) to use for git authentication (see --username) will be\n            read.  See also $GITSYNC_PASSWORD.\n\n    --period <duration>, $GITSYNC_PERIOD\n            How long to wait between sync attempts.  This must be at least\n            10ms.  This flag obsoletes --wait, but if --wait is specified, it\n            will take precedence.  If not specified, this defaults to 10\n            seconds (\"10s\").\n\n    --ref <string>, $GITSYNC_REF\n            The git revision (branch, tag, or hash) to check out.  If not\n            specified, this defaults to \"HEAD\" (of the upstream repo's default\n            branch).\n\n    --repo <string>, $GITSYNC_REPO\n            The git repository to sync.  This flag is required.\n\n    --root <string>, $GITSYNC_ROOT\n            The root directory for git-sync operations, under which --link will\n            be created.  This must be a path that either a) does not exist (it\n            will be created); b) is an empty directory; or c) is a directory\n            which can be emptied by removing all of the contents.  This flag is\n            required.\n\n    --sparse-checkout-file <string>, $GITSYNC_SPARSE_CHECKOUT_FILE\n            The path to a git sparse-checkout file (see git documentation for\n            details) which controls which files and directories will be checked\n            out.  If not specified, the default is to check out the entire repo.\n\n    --ssh-key-file <string>, $GITSYNC_SSH_KEY_FILE\n            The SSH key(s) to use when using git over SSH.  This flag may be\n            specified more than once and the environment variable will be\n            parsed like PATH - using a colon (':') to separate elements.  If\n            not specified, this defaults to \"/etc/git-secret/ssh\".\n\n    --ssh-known-hosts, $GITSYNC_SSH_KNOWN_HOSTS\n            Enable SSH known_hosts verification when using git over SSH.  If\n            not specified, this defaults to true.\n\n    --ssh-known-hosts-file <string>, $GITSYNC_SSH_KNOWN_HOSTS_FILE\n            The known_hosts file to use when --ssh-known-hosts is specified.\n            If not specified, this defaults to \"/etc/git-secret/known_hosts\".\n\n    --stale-worktree-timeout <duration>, $GITSYNC_STALE_WORKTREE_TIMEOUT\n            The length of time to retain stale (not the current link target)\n            worktrees before being removed. Once this duration has elapsed,\n            a stale worktree will be removed during the next sync attempt\n            (as determined by --sync-timeout). If not specified, this defaults\n            to 0, meaning that stale worktrees will be removed immediately.\n\n    --submodules <string>, $GITSYNC_SUBMODULES\n            The git submodule behavior: one of \"recursive\", \"shallow\", or\n            \"off\".  If not specified, this defaults to \"recursive\".\n\n    --sync-on-signal <string>, $GITSYNC_SYNC_ON_SIGNAL\n            Indicates that a sync attempt should occur upon receipt of the\n            specified signal name (e.g. SIGHUP) or number (e.g. 1). If a sync\n            is already in progress, another sync will be triggered as soon as\n            the current one completes. If not specified, signals will not\n            trigger syncs.\n\n    --sync-timeout <duration>, $GITSYNC_SYNC_TIMEOUT\n            The total time allowed for one complete sync.  This must be at least\n            10ms.  This flag obsoletes --timeout, but if --timeout is specified,\n            it will take precedence.  If not specified, this defaults to 120\n            seconds (\"120s\").\n\n    --touch-file <string>, $GITSYNC_TOUCH_FILE\n            The path to an optional file which will be touched whenever a sync\n            completes.  This may be an absolute path or a relative path, in\n            which case it is relative to --root.\n\n    --username <string>, $GITSYNC_USERNAME\n            The username to use for git authentication (see --password-file or\n            $GITSYNC_PASSWORD).  If more than one username and password is\n            required (e.g. with submodules), use --credential.\n\n    -v, --verbose <int>, $GITSYNC_VERBOSE\n            Set the log verbosity level.  Logs at this level and lower will be\n            printed.  Logs follow these guidelines:\n\n            - 0: Minimal, just log updates\n            - 1: More details about updates\n            - 2: Log the sync loop\n            - 3: More details about the sync loop\n            - 4: More details\n            - 5: Log all executed commands\n            - 6: Log stdout/stderr of all executed commands\n            - 9: Tracing and debug messages\n\n    --version\n            Print the version and exit.\n\n    --webhook-backoff <duration>, $GITSYNC_WEBHOOK_BACKOFF\n            The time to wait before retrying a failed --webhook-url.  If not\n            specified, this defaults to 3 seconds (\"3s\").\n\n    --webhook-method <string>, $GITSYNC_WEBHOOK_METHOD\n            The HTTP method for the --webhook-url.  If not specified, this defaults to \"POST\".\n\n    --webhook-success-status <int>, $GITSYNC_WEBHOOK_SUCCESS_STATUS\n            The HTTP status code indicating a successful --webhook-url.  Setting\n            this to 0 disables success checks, which makes webhooks\n            \"fire-and-forget\".  If not specified, this defaults to 200.\n\n    --webhook-timeout <duration>, $GITSYNC_WEBHOOK_TIMEOUT\n            The timeout for the --webhook-url.  If not specified, this defaults\n            to 1 second (\"1s\").\n\n    --webhook-url <string>, $GITSYNC_WEBHOOK_URL\n            A URL for optional webhook notifications when syncs complete.  The\n            header 'Gitsync-Hash' will be set to the git hash that was synced.\n            If, at startup, git-sync finds that the --root already has the\n            correct hash, this hook will still be invoked.  This means that\n            hooks can be invoked more than one time per hash, so they must be\n            idempotent.\n\nEXAMPLE USAGE\n\n    git-sync \\\n        --repo=https://github.com/kubernetes/git-sync \\\n        --ref=HEAD \\\n        --period=10s \\\n        --root=/mnt/git\n\nAUTHENTICATION\n\n    Git-sync offers several authentication options to choose from.  If none of\n    the following are specified, git-sync will try to access the repo in the\n    \"natural\" manner.  For example, \"https://repo\" will try to use plain HTTPS\n    and \"git@example.com:repo\" will try to use SSH.\n\n    username/password\n            The --username ($GITSYNC_USERNAME) and $GITSYNC_PASSWORD or\n            --password-file ($GITSYNC_PASSWORD_FILE) flags will be used.  To\n            prevent password leaks, the --password-file flag or\n            $GITSYNC_PASSWORD environment variable is almost always preferred\n            to the --password flag, which is deprecated.\n\n            A variant of this is --askpass-url ($GITSYNC_ASKPASS_URL), which\n            consults a URL (e.g. http://metadata) to get credentials on each\n            sync.\n\n            When using submodules it may be necessary to specify more than one\n            username and password, which can be done with --credential\n            ($GITSYNC_CREDENTIAL).  All of the username+password pairs, from\n            both --username/$GITSYNC_PASSWORD and --credential are fed into\n            'git credential approve'.\n\n    SSH\n            When an SSH transport is specified, the key(s) defined in\n            --ssh-key-file ($GITSYNC_SSH_KEY_FILE) will be used.  Users are\n            strongly advised to also use --ssh-known-hosts\n            ($GITSYNC_SSH_KNOWN_HOSTS) and --ssh-known-hosts-file\n            ($GITSYNC_SSH_KNOWN_HOSTS_FILE) when using SSH.\n\n    cookies\n            When --cookie-file ($GITSYNC_COOKIE_FILE) is specified, the\n            associated cookies can contain authentication information.\n\n    github app\n           When --github-app-private-key-file ($GITSYNC_GITHUB_APP_PRIVATE_KEY_FILE),\n           --github-app-application-id ($GITSYNC_GITHUB_APP_APPLICATION_ID) or\n           --github-app-client-id ($GITSYNC_GITHUB_APP_CLIENT_ID)\n           and --github-app-installation_id ($GITSYNC_GITHUB_APP_INSTALLATION_ID)\n           are specified, GitHub app authentication will be used.\n\n           These credentials are used to request a short-lived token which\n           is used for authentication. The base URL of the GitHub request made\n           to retrieve the token can also be specified via\n           --github-base-url ($GITSYNC_GITHUB_BASE_URL), which defaults to\n           https://api.github.com/.\n\n           The GitHub app must have sufficient access to the repository to sync.\n           It should be installed to the repository or organization containing\n           the repository, and given read access (see github docs).\n\nHOOKS\n\n    Webhooks and exechooks are executed asynchronously from the main git-sync\n    process.  If a --webhook-url or --exechook-command is configured, they will\n    be invoked whenever a new hash is synced, including when git-sync starts up\n    and find that the --root directory already has the correct hash.  For\n    exechook, that means the command is exec()'ed, and for webhooks that means\n    an HTTP request is sent using the method defined in --webhook-method.\n    Git-sync will retry both forms of hooks until they succeed (exit code 0 for\n    exechooks, or --webhook-success-status for webhooks).  If unsuccessful,\n    git-sync will wait --exechook-backoff or --webhook-backoff (as appropriate)\n    before re-trying the hook.  Git-sync does not ensure that hooks are invoked\n    exactly once, so hooks must be idempotent.\n\n    Hooks are not guaranteed to succeed on every single hash change.  For example,\n    if a hook fails and a new hash is synced during the backoff period, the\n    retried hook will fire for the newest hash.\n```\n"
        },
        {
          "name": "RELEASING.md",
          "type": "blob",
          "size": 2.0302734375,
          "content": "# Cutting a release\n\n## Tags\n\nFirst, pick the new tag.  Usually this means to see what has already been\ntagged, and pick the next release number.\n\n```\ngit tag\n```\n\n## Log in\n\nMake sure you are logged into Google Cloud (to push to GCR).\n\n```\ngcloud auth login\n```\n\n## Build and push to staging\n\nTo build git-sync you need [docker buildx](https://github.com/docker/buildx).\n\nThe following step will build for all platforms and push the container images\nto our staging repo (gcr.io/k8s-staging-git-sync).\n\n```\nmake release TAG=\"<tag you chose above>\"\n```\n\nThis will produce output like:\n\n```\n<...lots of output...>\nSuccessfully tagged gcr.io/k8s-staging-git-sync/git-sync:v3.3.2__linux_amd64\n<...lots of output...>\nv3.3.2__linux_amd64: digest: sha256:74cd8777ba08c7b725cd2f6de34a638ba50b48cde59f829e1dc982c8c8c9959a size: 951\npushed: gcr.io/k8s-staging-git-sync/git-sync:v3.3.2__linux_amd64\n<...lots of output...>\nDigest: sha256:853ae812df916e59a7b27516f791ea952d503ad26bc8660deced8cd528f128ae 433\n```\n\nTake note of this final sha256.\n\n## Promote the images\n\nMake a PR against\nhttps://github.com/kubernetes/k8s.io to edit the file\nk8s.gcr.io/images/k8s-staging-git-sync/images.yaml and add the sha256 and tag\nname from above.  For example:\n\n```\n - name: git-sync\n   dmap:\n+    \"sha256:853ae812df916e59a7b27516f791ea952d503ad26bc8660deced8cd528f128ae\": [\"v3.3.2\"]\n     \"sha256:95bfb980d3b640f6015f0d1ec25c8c0161d0babcf83d31d4c0453dd2b59923db\": [\"v3.3.1\"]\n     \"sha256:5f3d12cb753c6cd00c3ef9cc6f5ce4e584da81d5210c15653644ece675f19ec6\": [\"v3.3.0\"]\n     \"sha256:6a543fb2d1e92008aad697da2672478dcfac715e3dddd33801d772da6e70cf24\": [\"v3.2.2\"]\n```\n\nWhen that PR is merged, the promoter bot will copy the images from staging to\nthe final prod location (e.g. `registry.k8s.io/git-sync/git-sync:v3.3.2`).\n\n## Make a GitHub release\n\nLastly, make a release through the [github UI](https://github.com/kubernetes/git-sync/releases).\nInclude all the notable changes since the last release and the final container\nimage location.  The \"Auto-generate release notes\" button is a great starting\nplace.\n"
        },
        {
          "name": "SECURITY.md",
          "type": "blob",
          "size": 1.0439453125,
          "content": "# Security Policy\n\n## Security Announcements\n\nJoin the [kubernetes-security-announce] group for security and vulnerability announcements.\n\nYou can also subscribe to an RSS feed of the above using [this link][kubernetes-security-announce-rss].\n\n## Reporting a Vulnerability\n\nInstructions for reporting a vulnerability can be found on the\n[Kubernetes Security and Disclosure Information] page.\n\n## Supported Versions\n\nInformation about supported Kubernetes versions can be found on the\n[Kubernetes version and version skew support policy] page on the Kubernetes website.\n\n[kubernetes-security-announce]: https://groups.google.com/forum/#!forum/kubernetes-security-announce\n[kubernetes-security-announce-rss]: https://groups.google.com/forum/feed/kubernetes-security-announce/msgs/rss_v2_0.xml?num=50\n[Kubernetes version and version skew support policy]: https://kubernetes.io/docs/setup/release/version-skew-policy/#supported-versions\n[Kubernetes Security and Disclosure Information]: https://kubernetes.io/docs/reference/issues-security/security/#report-a-vulnerability\n"
        },
        {
          "name": "SECURITY_CONTACTS",
          "type": "blob",
          "size": 0.5205078125,
          "content": "# Defined below are the security contacts for this repo.\n#\n# They are the contact point for the Product Security Committee to reach out\n# to for triaging and handling of incoming issues.\n#\n# The below names agree to abide by the\n# [Embargo Policy](https://git.k8s.io/security/private-distributors-list.md#embargo-policy)\n# and will be removed and replaced if they violate that agreement.\n#\n# DO NOT REPORT SECURITY VULNERABILITIES DIRECTLY TO THESE NAMES, FOLLOW THE\n# INSTRUCTIONS AT https://kubernetes.io/security/\n\nthockin\nstp-ip\n"
        },
        {
          "name": "_test_tools",
          "type": "tree",
          "content": null
        },
        {
          "name": "abspath.go",
          "type": "blob",
          "size": 2.6298828125,
          "content": "/*\nCopyright 2014 The Kubernetes Authors All rights reserved.\n\nLicensed under the Apache License, Version 2.0 (the \"License\");\nyou may not use this file except in compliance with the License.\nYou may obtain a copy of the License at\n\n    http://www.apache.org/licenses/LICENSE-2.0\n\nUnless required by applicable law or agreed to in writing, software\ndistributed under the License is distributed on an \"AS IS\" BASIS,\nWITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\nSee the License for the specific language governing permissions and\nlimitations under the License.\n*/\n\npackage main\n\nimport (\n\t\"os\"\n\t\"path/filepath\"\n\t\"strings\"\n)\n\n// absPath is an absolute path string.  This type is intended to make it clear\n// when strings are absolute paths vs something else.  This does not verify or\n// mutate the input, so careless callers could make instances of this type that\n// are not actually absolute paths, or even \"\".\ntype absPath string\n\n// String returns abs as a string.\nfunc (abs absPath) String() string {\n\treturn string(abs)\n}\n\n// Canonical returns a canonicalized form of abs, similar to filepath.Abs\n// (including filepath.Clean).  Unlike filepath.Clean, this preserves \"\" as a\n// special case.\nfunc (abs absPath) Canonical() (absPath, error) {\n\tif abs == \"\" {\n\t\treturn abs, nil\n\t}\n\n\tresult, err := filepath.Abs(abs.String())\n\tif err != nil {\n\t\treturn \"\", err\n\t}\n\treturn absPath(result), nil\n}\n\n// Join appends more path elements to abs, like filepath.Join. This will clean\n// the final path (e.g. resolve \"..\" elements).\nfunc (abs absPath) Join(elems ...string) absPath {\n\tall := make([]string, 0, 1+len(elems))\n\tall = append(all, abs.String())\n\tall = append(all, elems...)\n\treturn absPath(filepath.Join(all...))\n}\n\n// Split breaks abs into stem and leaf parts (often directory and file, but not\n// necessarily), similar to filepath.Split.  Unlike filepath.Split, the\n// resulting stem part does not have any trailing path separators.\nfunc (abs absPath) Split() (absPath, string) {\n\tif abs == \"\" {\n\t\treturn \"\", \"\"\n\t}\n\n\t// filepath.Split promises that dir+base == input, but trailing slashes on\n\t// the dir is confusing and ugly.\n\tpathSep := string(os.PathSeparator)\n\tdir, base := filepath.Split(strings.TrimRight(abs.String(), pathSep))\n\tdir = strings.TrimRight(dir, pathSep)\n\tif len(dir) == 0 {\n\t\tdir = string(os.PathSeparator)\n\t}\n\n\treturn absPath(dir), base\n}\n\n// Dir returns the stem part of abs without the leaf, like filepath.Dir.\nfunc (abs absPath) Dir() string {\n\tdir, _ := abs.Split()\n\treturn string(dir)\n}\n\n// Base returns the leaf part of abs without the stem, like filepath.Base.\nfunc (abs absPath) Base() string {\n\t_, base := abs.Split()\n\treturn base\n}\n"
        },
        {
          "name": "abspath_test.go",
          "type": "blob",
          "size": 4.2265625,
          "content": "/*\nCopyright 2015 The Kubernetes Authors All rights reserved.\n\nLicensed under the Apache License, Version 2.0 (the \"License\");\nyou may not use this file except in compliance with the License.\nYou may obtain a copy of the License at\n\n    http://www.apache.org/licenses/LICENSE-2.0\n\nUnless required by applicable law or agreed to in writing, software\ndistributed under the License is distributed on an \"AS IS\" BASIS,\nWITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\nSee the License for the specific language governing permissions and\nlimitations under the License.\n*/\n\npackage main\n\nimport (\n\t\"testing\"\n)\n\nfunc TestAbsPathString(t *testing.T) {\n\ttestCases := []string{\n\t\t\"\",\n\t\t\"/\",\n\t\t\"//\",\n\t\t\"/dir\",\n\t\t\"/dir/\",\n\t\t\"/dir//\",\n\t\t\"/dir/sub\",\n\t\t\"/dir/sub/\",\n\t\t\"/dir//sub\",\n\t\t\"/dir//sub/\",\n\t\t\"dir\",\n\t\t\"dir/sub\",\n\t}\n\n\tfor _, tc := range testCases {\n\t\tif want, got := tc, absPath(tc).String(); want != got {\n\t\t\tt.Errorf(\"expected %q, got %q\", want, got)\n\t\t}\n\t}\n}\n\nfunc TestAbsPathCanonical(t *testing.T) {\n\ttestCases := []struct {\n\t\tin  absPath\n\t\texp absPath\n\t}{{\n\t\tin:  \"\",\n\t\texp: \"\",\n\t}, {\n\t\tin:  \"/\",\n\t\texp: \"/\",\n\t}, {\n\t\tin:  \"/one\",\n\t\texp: \"/one\",\n\t}, {\n\t\tin:  \"/one/two\",\n\t\texp: \"/one/two\",\n\t}, {\n\t\tin:  \"/one/two/\",\n\t\texp: \"/one/two\",\n\t}, {\n\t\tin:  \"/one//two\",\n\t\texp: \"/one/two\",\n\t}, {\n\t\tin:  \"/one/two/../three\",\n\t\texp: \"/one/three\",\n\t}}\n\n\tfor _, tc := range testCases {\n\t\twant := tc.exp\n\t\tgot, err := tc.in.Canonical()\n\t\tif err != nil {\n\t\t\tt.Errorf(\"%q: unexpected error: %v\", tc.in, err)\n\t\t} else if want != got {\n\t\t\tt.Errorf(\"%q: expected %q, got %q\", tc.in, want, got)\n\t\t}\n\t}\n}\n\nfunc TestAbsPathJoin(t *testing.T) {\n\ttestCases := []struct {\n\t\tbase   absPath\n\t\tmore   []string\n\t\texpect absPath\n\t}{{\n\t\tbase:   \"/dir\",\n\t\tmore:   nil,\n\t\texpect: \"/dir\",\n\t}, {\n\t\tbase:   \"/dir\",\n\t\tmore:   []string{\"one\"},\n\t\texpect: \"/dir/one\",\n\t}, {\n\t\tbase:   \"/dir\",\n\t\tmore:   []string{\"one\", \"two\"},\n\t\texpect: \"/dir/one/two\",\n\t}, {\n\t\tbase:   \"/dir\",\n\t\tmore:   []string{\"one\", \"two\", \"three\"},\n\t\texpect: \"/dir/one/two/three\",\n\t}, {\n\t\tbase:   \"/dir\",\n\t\tmore:   []string{\"with/slash\"},\n\t\texpect: \"/dir/with/slash\",\n\t}, {\n\t\tbase:   \"/dir\",\n\t\tmore:   []string{\"with/trailingslash/\"},\n\t\texpect: \"/dir/with/trailingslash\",\n\t}, {\n\t\tbase:   \"/dir\",\n\t\tmore:   []string{\"with//twoslash\"},\n\t\texpect: \"/dir/with/twoslash\",\n\t}, {\n\t\tbase:   \"/dir\",\n\t\tmore:   []string{\"one/1\", \"two/2\", \"three/3\"},\n\t\texpect: \"/dir/one/1/two/2/three/3\",\n\t}}\n\n\tfor _, tc := range testCases {\n\t\tif want, got := tc.expect, tc.base.Join(tc.more...); want != got {\n\t\t\tt.Errorf(\"(%q, %q): expected %q, got %q\", tc.base, tc.more, want, got)\n\t\t}\n\t}\n}\n\nfunc TestAbsPathSplit(t *testing.T) {\n\ttestCases := []struct {\n\t\tin      absPath\n\t\texpDir  absPath\n\t\texpBase string\n\t}{{\n\t\tin:      \"\",\n\t\texpDir:  \"\",\n\t\texpBase: \"\",\n\t}, {\n\t\tin:      \"/\",\n\t\texpDir:  \"/\",\n\t\texpBase: \"\",\n\t}, {\n\t\tin:      \"//\",\n\t\texpDir:  \"/\",\n\t\texpBase: \"\",\n\t}, {\n\t\tin:      \"/one\",\n\t\texpDir:  \"/\",\n\t\texpBase: \"one\",\n\t}, {\n\t\tin:      \"/one/two\",\n\t\texpDir:  \"/one\",\n\t\texpBase: \"two\",\n\t}, {\n\t\tin:      \"/one/two/\",\n\t\texpDir:  \"/one\",\n\t\texpBase: \"two\",\n\t}, {\n\t\tin:      \"/one//two\",\n\t\texpDir:  \"/one\",\n\t\texpBase: \"two\",\n\t}}\n\n\tfor _, tc := range testCases {\n\t\twantDir, wantBase := tc.expDir, tc.expBase\n\t\tif gotDir, gotBase := tc.in.Split(); wantDir != gotDir || wantBase != gotBase {\n\t\t\tt.Errorf(\"%q: expected (%q, %q), got (%q, %q)\", tc.in, wantDir, wantBase, gotDir, gotBase)\n\t\t}\n\t}\n}\n\nfunc TestAbsPathDir(t *testing.T) {\n\ttestCases := []struct {\n\t\tin  absPath\n\t\texp string\n\t}{{\n\t\tin:  \"\",\n\t\texp: \"\",\n\t}, {\n\t\tin:  \"/\",\n\t\texp: \"/\",\n\t}, {\n\t\tin:  \"/one\",\n\t\texp: \"/\",\n\t}, {\n\t\tin:  \"/one/two\",\n\t\texp: \"/one\",\n\t}, {\n\t\tin:  \"/one/two/\",\n\t\texp: \"/one\",\n\t}, {\n\t\tin:  \"/one//two\",\n\t\texp: \"/one\",\n\t}}\n\n\tfor _, tc := range testCases {\n\t\tif want, got := tc.exp, tc.in.Dir(); want != got {\n\t\t\tt.Errorf(\"%q: expected %q, got %q\", tc.in, want, got)\n\t\t}\n\t}\n}\n\nfunc TestAbsPathBase(t *testing.T) {\n\ttestCases := []struct {\n\t\tin  absPath\n\t\texp string\n\t}{{\n\t\tin:  \"\",\n\t\texp: \"\",\n\t}, {\n\t\tin:  \"/\",\n\t\texp: \"\",\n\t}, {\n\t\tin:  \"/one\",\n\t\texp: \"one\",\n\t}, {\n\t\tin:  \"/one/two\",\n\t\texp: \"two\",\n\t}, {\n\t\tin:  \"/one/two/\",\n\t\texp: \"two\",\n\t}, {\n\t\tin:  \"/one//two\",\n\t\texp: \"two\",\n\t}}\n\n\tfor _, tc := range testCases {\n\t\tif want, got := tc.exp, tc.in.Base(); want != got {\n\t\t\tt.Errorf(\"%q: expected %q, got %q\", tc.in, want, got)\n\t\t}\n\t}\n}\n"
        },
        {
          "name": "build",
          "type": "tree",
          "content": null
        },
        {
          "name": "code-of-conduct.md",
          "type": "blob",
          "size": 0.14453125,
          "content": "# Kubernetes Community Code of Conduct\n\nPlease refer to our [Kubernetes Community Code of Conduct](https://git.k8s.io/community/code-of-conduct.md)\n"
        },
        {
          "name": "credential.go",
          "type": "blob",
          "size": 3.716796875,
          "content": "/*\nCopyright 2014 The Kubernetes Authors All rights reserved.\n\nLicensed under the Apache License, Version 2.0 (the \"License\");\nyou may not use this file except in compliance with the License.\nYou may obtain a copy of the License at\n\n    http://www.apache.org/licenses/LICENSE-2.0\n\nUnless required by applicable law or agreed to in writing, software\ndistributed under the License is distributed on an \"AS IS\" BASIS,\nWITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\nSee the License for the specific language governing permissions and\nlimitations under the License.\n*/\n\npackage main\n\nimport (\n\t\"encoding/json\"\n\t\"fmt\"\n\t\"strings\"\n\n\t\"github.com/spf13/pflag\"\n)\n\ntype credential struct {\n\tURL          string `json:\"url\"`\n\tUsername     string `json:\"username\"`\n\tPassword     string `json:\"password,omitempty\"`\n\tPasswordFile string `json:\"password-file,omitempty\"`\n}\n\nfunc (c credential) String() string {\n\tjb, err := json.Marshal(c)\n\tif err != nil {\n\t\treturn fmt.Sprintf(\"<encoding error: %v>\", err)\n\t}\n\treturn string(jb)\n}\n\n// credentialSliceValue is for flags.\ntype credentialSliceValue struct {\n\tvalue   []credential\n\tchanged bool\n}\n\nvar _ pflag.Value = &credentialSliceValue{}\nvar _ pflag.SliceValue = &credentialSliceValue{}\n\n// pflagCredentialSlice is like pflag.StringSlice()\nfunc pflagCredentialSlice(name, def, usage string) *[]credential {\n\tp := &credentialSliceValue{}\n\t_ = p.Set(def)\n\tpflag.Var(p, name, usage)\n\treturn &p.value\n}\n\n// unmarshal is like json.Unmarshal, but fails on unknown fields.\nfunc (cs credentialSliceValue) unmarshal(val string, out any) error {\n\tdec := json.NewDecoder(strings.NewReader(val))\n\tdec.DisallowUnknownFields()\n\treturn dec.Decode(out)\n}\n\n// decodeList handles a string-encoded JSON object.\nfunc (cs credentialSliceValue) decodeObject(val string) (credential, error) {\n\tvar cred credential\n\tif err := cs.unmarshal(val, &cred); err != nil {\n\t\treturn credential{}, err\n\t}\n\treturn cred, nil\n}\n\n// decodeList handles a string-encoded JSON list.\nfunc (cs credentialSliceValue) decodeList(val string) ([]credential, error) {\n\tvar creds []credential\n\tif err := cs.unmarshal(val, &creds); err != nil {\n\t\treturn nil, err\n\t}\n\treturn creds, nil\n}\n\n// decode handles a string-encoded JSON object or list.\nfunc (cs credentialSliceValue) decode(val string) ([]credential, error) {\n\ts := strings.TrimSpace(val)\n\tif s == \"\" {\n\t\treturn nil, nil\n\t}\n\t// If it tastes like an object...\n\tif s[0] == '{' {\n\t\tcred, err := cs.decodeObject(s)\n\t\treturn []credential{cred}, err\n\t}\n\t// If it tastes like a list...\n\tif s[0] == '[' {\n\t\treturn cs.decodeList(s)\n\t}\n\t// Otherwise, bad\n\treturn nil, fmt.Errorf(\"not a JSON object or list\")\n}\n\nfunc (cs *credentialSliceValue) Set(val string) error {\n\tv, err := cs.decode(val)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\tif !cs.changed {\n\t\tcs.value = v\n\t} else {\n\t\tcs.value = append(cs.value, v...)\n\t}\n\tcs.changed = true\n\n\treturn nil\n}\n\nfunc (cs credentialSliceValue) Type() string {\n\treturn \"credentialSlice\"\n}\n\nfunc (cs credentialSliceValue) String() string {\n\tif len(cs.value) == 0 {\n\t\treturn \"[]\"\n\t}\n\tjb, err := json.Marshal(cs.value)\n\tif err != nil {\n\t\treturn fmt.Sprintf(\"<encoding error: %v>\", err)\n\t}\n\treturn string(jb)\n}\n\nfunc (cs *credentialSliceValue) Append(val string) error {\n\tv, err := cs.decodeObject(val)\n\tif err != nil {\n\t\treturn err\n\t}\n\tcs.value = append(cs.value, v)\n\treturn nil\n}\n\nfunc (cs *credentialSliceValue) Replace(val []string) error {\n\tcreds := []credential{}\n\tfor _, s := range val {\n\t\tv, err := cs.decodeObject(s)\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\t\tcreds = append(creds, v)\n\t}\n\tcs.value = creds\n\treturn nil\n}\n\nfunc (cs credentialSliceValue) GetSlice() []string {\n\tif len(cs.value) == 0 {\n\t\treturn nil\n\t}\n\tret := []string{}\n\tfor _, cred := range cs.value {\n\t\tret = append(ret, cred.String())\n\t}\n\treturn ret\n}\n"
        },
        {
          "name": "demo",
          "type": "tree",
          "content": null
        },
        {
          "name": "docs",
          "type": "tree",
          "content": null
        },
        {
          "name": "env.go",
          "type": "blob",
          "size": 8.236328125,
          "content": "/*\nCopyright 2014 The Kubernetes Authors All rights reserved.\n\nLicensed under the Apache License, Version 2.0 (the \"License\");\nyou may not use this file except in compliance with the License.\nYou may obtain a copy of the License at\n\n    http://www.apache.org/licenses/LICENSE-2.0\n\nUnless required by applicable law or agreed to in writing, software\ndistributed under the License is distributed on an \"AS IS\" BASIS,\nWITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\nSee the License for the specific language governing permissions and\nlimitations under the License.\n*/\n\npackage main\n\nimport (\n\t\"cmp\"\n\t\"fmt\"\n\t\"io\"\n\t\"os\"\n\t\"slices\"\n\t\"strconv\"\n\t\"strings\"\n\t\"time\"\n\n\t\"github.com/spf13/pflag\"\n)\n\n// Tests can set this or set it to nil.\nvar envWarnfOverride func(format string, args ...any)\n\nfunc envWarnf(format string, args ...any) {\n\tif envWarnfOverride != nil {\n\t\tenvWarnfOverride(format, args...)\n\t} else {\n\t\tfmt.Fprintf(os.Stderr, format, args...)\n\t}\n}\n\nfunc envString(def string, key string, alts ...string) string {\n\tfound := 0\n\tresult := \"\"\n\tresultKey := \"\"\n\n\tif val, ok := os.LookupEnv(key); ok {\n\t\tfound++\n\t\tresult = val\n\t\tresultKey = key\n\t}\n\tfor _, alt := range alts {\n\t\tif val, ok := os.LookupEnv(alt); ok {\n\t\t\tenvWarnf(\"env $%s has been deprecated, use $%s instead\\n\", alt, key)\n\t\t\tfound++\n\t\t\tresult = val\n\t\t\tresultKey = alt\n\t\t}\n\t}\n\tif found == 0 {\n\t\treturn def\n\t}\n\tif found > 1 {\n\t\tenvWarnf(\"env $%s was overridden by $%s\\n\", key, resultKey)\n\t}\n\treturn result\n}\nfunc envFlagString(key string, def string, usage string, alts ...string) *string {\n\tregisterEnvFlag(key, \"string\", usage)\n\tval := envString(def, key, alts...)\n\t// also expose it as a flag, for easier testing\n\tflName := \"__env__\" + key\n\tflHelp := \"DO NOT SET THIS FLAG EXCEPT IN TESTS; use $\" + key\n\tnewExplicitFlag(&val, flName, flHelp, pflag.String)\n\tif err := pflag.CommandLine.MarkHidden(flName); err != nil {\n\t\tfmt.Fprintf(os.Stderr, \"FATAL: %v\\n\", err)\n\t\tos.Exit(1)\n\t}\n\treturn &val\n}\n\nfunc envStringArray(def string, key string, alts ...string) []string {\n\tparse := func(s string) []string {\n\t\treturn strings.Split(s, \":\")\n\t}\n\n\tfound := 0\n\tresult := \"\"\n\tresultKey := \"\"\n\n\tif val, ok := os.LookupEnv(key); ok {\n\t\tfound++\n\t\tresult = val\n\t\tresultKey = key\n\t}\n\tfor _, alt := range alts {\n\t\tif val, ok := os.LookupEnv(alt); ok {\n\t\t\tenvWarnf(\"env $%s has been deprecated, use $%s instead\\n\", alt, key)\n\t\t\tfound++\n\t\t\tresult = val\n\t\t\tresultKey = key\n\t\t}\n\t}\n\tif found == 0 {\n\t\treturn parse(def)\n\t}\n\tif found > 1 {\n\t\tenvWarnf(\"env $%s was overridden by $%s\\n\", key, resultKey)\n\t}\n\n\treturn parse(result)\n}\n\nfunc envBoolOrError(def bool, key string, alts ...string) (bool, error) {\n\tparse := func(key, val string) (bool, error) {\n\t\tparsed, err := strconv.ParseBool(val)\n\t\tif err == nil {\n\t\t\treturn parsed, nil\n\t\t}\n\t\treturn false, fmt.Errorf(\"invalid bool env %s=%q: %w\", key, val, err)\n\t}\n\n\tfound := 0\n\tresult := \"\"\n\tresultKey := \"\"\n\n\tif val, ok := os.LookupEnv(key); ok {\n\t\tfound++\n\t\tresult = val\n\t\tresultKey = key\n\t}\n\tfor _, alt := range alts {\n\t\tif val, ok := os.LookupEnv(alt); ok {\n\t\t\tenvWarnf(\"env $%s has been deprecated, use $%s instead\\n\", alt, key)\n\t\t\tfound++\n\t\t\tresult = val\n\t\t\tresultKey = key\n\t\t}\n\t}\n\tif found == 0 {\n\t\treturn def, nil\n\t}\n\tif found > 1 {\n\t\tenvWarnf(\"env $%s was overridden by $%s\\n\", key, resultKey)\n\t}\n\treturn parse(resultKey, result)\n}\nfunc envBool(def bool, key string, alts ...string) bool {\n\tval, err := envBoolOrError(def, key, alts...)\n\tif err != nil {\n\t\tfmt.Fprintf(os.Stderr, \"FATAL: %v\\n\", err)\n\t\tos.Exit(1)\n\t\treturn false\n\t}\n\treturn val\n}\n\nfunc envIntOrError(def int, key string, alts ...string) (int, error) {\n\tparse := func(key, val string) (int, error) {\n\t\tparsed, err := strconv.ParseInt(val, 0, 0)\n\t\tif err == nil {\n\t\t\treturn int(parsed), nil\n\t\t}\n\t\treturn 0, fmt.Errorf(\"invalid int env %s=%q: %w\", key, val, err)\n\t}\n\n\tfound := 0\n\tresult := \"\"\n\tresultKey := \"\"\n\n\tif val, ok := os.LookupEnv(key); ok {\n\t\tfound++\n\t\tresult = val\n\t\tresultKey = key\n\t}\n\tfor _, alt := range alts {\n\t\tif val, ok := os.LookupEnv(alt); ok {\n\t\t\tenvWarnf(\"env $%s has been deprecated, use $%s instead\\n\", alt, key)\n\t\t\tfound++\n\t\t\tresult = val\n\t\t\tresultKey = key\n\t\t}\n\t}\n\tif found == 0 {\n\t\treturn def, nil\n\t}\n\tif found > 1 {\n\t\tenvWarnf(\"env $%s was overridden by $%s\\n\", key, resultKey)\n\t}\n\treturn parse(resultKey, result)\n}\nfunc envInt(def int, key string, alts ...string) int {\n\tval, err := envIntOrError(def, key, alts...)\n\tif err != nil {\n\t\tfmt.Fprintf(os.Stderr, \"FATAL: %v\\n\", err)\n\t\tos.Exit(1)\n\t\treturn 0\n\t}\n\treturn val\n}\n\nfunc envFloatOrError(def float64, key string, alts ...string) (float64, error) {\n\tparse := func(key, val string) (float64, error) {\n\t\tparsed, err := strconv.ParseFloat(val, 64)\n\t\tif err == nil {\n\t\t\treturn parsed, nil\n\t\t}\n\t\treturn 0, fmt.Errorf(\"invalid float env %s=%q: %w\", key, val, err)\n\t}\n\n\tfound := 0\n\tresult := \"\"\n\tresultKey := \"\"\n\n\tif val, ok := os.LookupEnv(key); ok {\n\t\tfound++\n\t\tresult = val\n\t\tresultKey = key\n\t}\n\tfor _, alt := range alts {\n\t\tif val, ok := os.LookupEnv(alt); ok {\n\t\t\tenvWarnf(\"env $%s has been deprecated, use $%s instead\\n\", alt, key)\n\t\t\tfound++\n\t\t\tresult = val\n\t\t\tresultKey = key\n\t\t}\n\t}\n\tif found == 0 {\n\t\treturn def, nil\n\t}\n\tif found > 1 {\n\t\tenvWarnf(\"env $%s was overridden by $%s\\n\", key, resultKey)\n\t}\n\treturn parse(resultKey, result)\n}\nfunc envFloat(def float64, key string, alts ...string) float64 {\n\tval, err := envFloatOrError(def, key, alts...)\n\tif err != nil {\n\t\tfmt.Fprintf(os.Stderr, \"FATAL: %v\\n\", err)\n\t\tos.Exit(1)\n\t\treturn 0\n\t}\n\treturn val\n}\n\nfunc envDurationOrError(def time.Duration, key string, alts ...string) (time.Duration, error) {\n\tparse := func(key, val string) (time.Duration, error) {\n\t\tparsed, err := time.ParseDuration(val)\n\t\tif err == nil {\n\t\t\treturn parsed, nil\n\t\t}\n\t\treturn 0, fmt.Errorf(\"invalid duration env %s=%q: %w\", key, val, err)\n\t}\n\n\tfound := 0\n\tresult := \"\"\n\tresultKey := \"\"\n\n\tif val, ok := os.LookupEnv(key); ok {\n\t\tfound++\n\t\tresult = val\n\t\tresultKey = key\n\t}\n\tfor _, alt := range alts {\n\t\tif val, ok := os.LookupEnv(alt); ok {\n\t\t\tenvWarnf(\"env $%s has been deprecated, use $%s instead\\n\", alt, key)\n\t\t\tfound++\n\t\t\tresult = val\n\t\t\tresultKey = key\n\t\t}\n\t}\n\tif found == 0 {\n\t\treturn def, nil\n\t}\n\tif found > 1 {\n\t\tenvWarnf(\"env $%s was overridden by $%s\\n\", key, resultKey)\n\t}\n\treturn parse(resultKey, result)\n}\nfunc envDuration(def time.Duration, key string, alts ...string) time.Duration {\n\tval, err := envDurationOrError(def, key, alts...)\n\tif err != nil {\n\t\tfmt.Fprintf(os.Stderr, \"FATAL: %v\\n\", err)\n\t\tos.Exit(1)\n\t\treturn 0\n\t}\n\treturn val\n}\n\n// explicitFlag is a pflag.Value which only sets the real value if the flag is\n// set to a non-zero-value.\ntype explicitFlag[T comparable] struct {\n\tpflag.Value\n\trealPtr *T\n\tflagPtr *T\n}\n\n// newExplicitFlag allocates an explicitFlag\nfunc newExplicitFlag[T comparable](ptr *T, name, usage string, fn func(name string, value T, usage string) *T) {\n\th := &explicitFlag[T]{\n\t\trealPtr: ptr,\n\t}\n\tvar zero T\n\th.flagPtr = fn(name, zero, usage)\n\tfl := pflag.CommandLine.Lookup(name)\n\t// wrap the original pflag.Value with our own\n\th.Value = fl.Value\n\tfl.Value = h\n}\n\nfunc (h *explicitFlag[T]) Set(val string) error {\n\tif err := h.Value.Set(val); err != nil {\n\t\treturn err\n\t}\n\tvar zero T\n\tif v := *h.flagPtr; v != zero {\n\t\t*h.realPtr = v\n\t}\n\treturn nil\n}\n\n// envFlag is like a flag in that it is declared with a type, validated, and\n// shows up in help messages, but can only be set by env-var, not on the CLI.\n// This is useful for things like passwords, which should not be on the CLI\n// because it can be seen in `ps`.\ntype envFlag struct {\n\tname string\n\ttyp  string\n\thelp string\n}\n\nvar allEnvFlags = []envFlag{}\n\n// registerEnvFlag is internal.  Use functions like envFlagString to actually\n// create envFlags.\nfunc registerEnvFlag(name, typ, help string) {\n\tfor _, ef := range allEnvFlags {\n\t\tif ef.name == name {\n\t\t\tfmt.Fprintf(os.Stderr, \"FATAL: duplicate env var declared: %q\\n\", name)\n\t\t\tos.Exit(1)\n\t\t}\n\t}\n\tallEnvFlags = append(allEnvFlags, envFlag{name, typ, help})\n}\n\n// printEnvFlags prints \"usage\" for all registered envFlags.\nfunc printEnvFlags(out io.Writer) {\n\twidth := 0\n\tfor _, ef := range allEnvFlags {\n\t\tif n := len(ef.name); n > width {\n\t\t\twidth = n\n\t\t}\n\t}\n\tslices.SortFunc(allEnvFlags, func(l, r envFlag) int { return cmp.Compare(l.name, r.name) })\n\n\tfor _, ef := range allEnvFlags {\n\t\tfmt.Fprintf(out, \"% *s %s %*s%s\\n\", width+2, ef.name, ef.typ, max(8, 32-width), \"\", ef.help)\n\t}\n}\n"
        },
        {
          "name": "env_test.go",
          "type": "blob",
          "size": 5.98828125,
          "content": "/*\nCopyright 2015 The Kubernetes Authors All rights reserved.\n\nLicensed under the Apache License, Version 2.0 (the \"License\");\nyou may not use this file except in compliance with the License.\nYou may obtain a copy of the License at\n\n    http://www.apache.org/licenses/LICENSE-2.0\n\nUnless required by applicable law or agreed to in writing, software\ndistributed under the License is distributed on an \"AS IS\" BASIS,\nWITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\nSee the License for the specific language governing permissions and\nlimitations under the License.\n*/\n\npackage main\n\nimport (\n\t\"os\"\n\t\"testing\"\n\t\"time\"\n)\n\nconst (\n\ttestKey = \"KEY\"\n\talt1Key = \"ALT1\"\n\talt2Key = \"ALT2\"\n)\n\nfunc setupEnv(val, alt1, alt2 string) {\n\tif val != \"\" {\n\t\tos.Setenv(testKey, val)\n\t}\n\tif alt1 != \"\" {\n\t\tos.Setenv(alt1Key, alt1)\n\t}\n\tif alt2 != \"\" {\n\t\tos.Setenv(alt2Key, alt2)\n\t}\n}\n\nfunc resetEnv() {\n\tos.Unsetenv(testKey)\n\tos.Unsetenv(alt1Key)\n\tos.Unsetenv(alt2Key)\n}\n\nfunc TestEnvBool(t *testing.T) {\n\tenvWarnfOverride = func(format string, args ...any) {\n\t\tt.Logf(format, args...)\n\t}\n\tdefer func() { envWarnfOverride = nil }()\n\n\tcases := []struct {\n\t\tvalue string\n\t\talt1  string\n\t\talt2  string\n\t\tdef   bool\n\t\texp   bool\n\t\terr   bool\n\t}{\n\t\t{\"true\", \"\", \"\", true, true, false},\n\t\t{\"true\", \"\", \"\", false, true, false},\n\t\t{\"\", \"\", \"\", true, true, false},\n\t\t{\"\", \"\", \"\", false, false, false},\n\t\t{\"false\", \"\", \"\", true, false, false},\n\t\t{\"false\", \"\", \"\", false, false, false},\n\t\t{\"\", \"\", \"\", true, true, false},\n\t\t{\"\", \"\", \"\", false, false, false},\n\t\t{\"invalid\", \"\", \"\", false, false, true},\n\t\t{\"invalid\", \"true\", \"\", false, true, false},\n\t\t{\"true\", \"invalid\", \"\", false, false, true},\n\t\t{\"invalid\", \"invalid\", \"true\", false, true, false},\n\t\t{\"true\", \"true\", \"invalid\", false, false, true},\n\t\t{\"invalid\", \"invalid\", \"invalid\", false, false, true},\n\t}\n\n\tfor i, tc := range cases {\n\t\tresetEnv()\n\t\tsetupEnv(tc.value, tc.alt1, tc.alt2)\n\t\tval, err := envBoolOrError(tc.def, testKey, alt1Key, alt2Key)\n\t\tif err != nil && !tc.err {\n\t\t\tt.Fatalf(\"%d: %q: unexpected error: %v\", i, tc.value, err)\n\t\t}\n\t\tif err == nil && tc.err {\n\t\t\tt.Fatalf(\"%d: %q: unexpected success\", i, tc.value)\n\t\t}\n\t\tif val != tc.exp {\n\t\t\tt.Fatalf(\"%d: expected: %v, got: %v\", i, tc.exp, val)\n\t\t}\n\t}\n}\n\nfunc TestEnvString(t *testing.T) {\n\tenvWarnfOverride = func(format string, args ...any) {\n\t\tt.Logf(format, args...)\n\t}\n\tdefer func() { envWarnfOverride = nil }()\n\n\tcases := []struct {\n\t\tvalue string\n\t\talt1  string\n\t\talt2  string\n\t\tdef   string\n\t\texp   string\n\t}{\n\t\t{\"foo\", \"\", \"\", \"foo\", \"foo\"},\n\t\t{\"foo\", \"\", \"\", \"bar\", \"foo\"},\n\t\t{\"\", \"\", \"\", \"foo\", \"foo\"},\n\t\t{\"\", \"\", \"\", \"bar\", \"bar\"},\n\t\t{\"bar\", \"\", \"\", \"foo\", \"bar\"},\n\t\t{\"bar\", \"\", \"\", \"bar\", \"bar\"},\n\t\t{\"\", \"\", \"\", \"foo\", \"foo\"},\n\t\t{\"\", \"\", \"\", \"bar\", \"bar\"},\n\t\t{\"foo1\", \"foo2\", \"\", \"bar\", \"foo2\"},\n\t\t{\"foo1\", \"foo2\", \"foo3\", \"bar\", \"foo3\"},\n\t}\n\n\tfor i, tc := range cases {\n\t\tresetEnv()\n\t\tsetupEnv(tc.value, tc.alt1, tc.alt2)\n\t\tval := envString(tc.def, testKey, alt1Key, alt2Key)\n\t\tif val != tc.exp {\n\t\t\tt.Fatalf(\"%d: expected: %q, got: %q\", i, tc.exp, val)\n\t\t}\n\t}\n}\n\nfunc TestEnvInt(t *testing.T) {\n\tenvWarnfOverride = func(format string, args ...any) {\n\t\tt.Logf(format, args...)\n\t}\n\tdefer func() { envWarnfOverride = nil }()\n\n\tcases := []struct {\n\t\tvalue string\n\t\talt1  string\n\t\talt2  string\n\t\tdef   int\n\t\texp   int\n\t\terr   bool\n\t}{\n\t\t{\"0\", \"\", \"\", 1, 0, false},\n\t\t{\"\", \"\", \"\", 0, 0, false},\n\t\t{\"-1\", \"\", \"\", 0, -1, false},\n\t\t{\"invalid\", \"\", \"\", 0, 0, true},\n\t\t{\"invalid\", \"0\", \"\", 1, 0, false},\n\t\t{\"0\", \"invalid\", \"\", 0, 0, true},\n\t\t{\"invalid\", \"invalid\", \"0\", 1, 0, false},\n\t\t{\"0\", \"0\", \"invalid\", 0, 0, true},\n\t\t{\"invalid\", \"invalid\", \"invalid\", 0, 0, true},\n\t}\n\n\tfor i, tc := range cases {\n\t\tresetEnv()\n\t\tsetupEnv(tc.value, tc.alt1, tc.alt2)\n\t\tval, err := envIntOrError(tc.def, testKey, alt1Key, alt2Key)\n\t\tif err != nil && !tc.err {\n\t\t\tt.Fatalf(\"%d: %q: unexpected error: %v\", i, tc.value, err)\n\t\t}\n\t\tif err == nil && tc.err {\n\t\t\tt.Fatalf(\"%d: %q: unexpected success\", i, tc.value)\n\t\t}\n\t\tif val != tc.exp {\n\t\t\tt.Fatalf(\"%d: expected: %v, got: %v\", i, tc.exp, val)\n\t\t}\n\t}\n}\n\nfunc TestEnvFloat(t *testing.T) {\n\tenvWarnfOverride = func(format string, args ...any) {\n\t\tt.Logf(format, args...)\n\t}\n\tdefer func() { envWarnfOverride = nil }()\n\n\tcases := []struct {\n\t\tvalue string\n\t\talt1  string\n\t\talt2  string\n\t\tdef   float64\n\t\texp   float64\n\t\terr   bool\n\t}{\n\t\t{\"0.5\", \"\", \"\", 0, 0.5, false},\n\t\t{\"\", \"\", \"\", 0.5, 0.5, false},\n\t\t{\"-0.5\", \"\", \"\", 0, -0.5, false},\n\t\t{\"invalid\", \"\", \"\", 0, 0, true},\n\t\t{\"invalid\", \"0.5\", \"\", 0, 0.5, false},\n\t\t{\"0.5\", \"invalid\", \"\", 0, 0, true},\n\t\t{\"invalid\", \"invalid\", \"0.5\", 0, 0.5, false},\n\t\t{\"0.5\", \"0.5\", \"invalid\", 0, 0, true},\n\t\t{\"invalid\", \"invalid\", \"invalid\", 0, 0, true},\n\t}\n\n\tfor i, tc := range cases {\n\t\tresetEnv()\n\t\tsetupEnv(tc.value, tc.alt1, tc.alt2)\n\t\tval, err := envFloatOrError(tc.def, testKey, alt1Key, alt2Key)\n\t\tif err != nil && !tc.err {\n\t\t\tt.Fatalf(\"%d: %q: unexpected error: %v\", i, tc.value, err)\n\t\t}\n\t\tif err == nil && tc.err {\n\t\t\tt.Fatalf(\"%d: %q: unexpected success\", i, tc.value)\n\t\t}\n\t\tif val != tc.exp {\n\t\t\tt.Fatalf(\"%d: expected: %v, got: %v\", i, tc.exp, val)\n\t\t}\n\t}\n}\n\nfunc TestEnvDuration(t *testing.T) {\n\tcases := []struct {\n\t\tvalue string\n\t\talt1  string\n\t\talt2  string\n\t\tdef   time.Duration\n\t\texp   time.Duration\n\t\terr   bool\n\t}{\n\t\t{\"1s\", \"\", \"\", 0, time.Second, false},\n\t\t{\"\", \"\", \"\", time.Minute, time.Minute, false},\n\t\t{\"1h\", \"\", \"\", 0, time.Hour, false},\n\t\t{\"invalid\", \"\", \"\", 0, 0, true},\n\t\t{\"invalid\", \"1s\", \"\", 0, time.Second, false},\n\t\t{\"1s\", \"invalid\", \"\", 0, 0, true},\n\t\t{\"invalid\", \"invalid\", \"1s\", 0, time.Second, false},\n\t\t{\"1s\", \"1s\", \"invalid\", 0, 0, true},\n\t\t{\"invalid\", \"invalid\", \"invalid\", 0, 0, true},\n\t}\n\n\tfor i, tc := range cases {\n\t\tresetEnv()\n\t\tsetupEnv(tc.value, tc.alt1, tc.alt2)\n\t\tval, err := envDurationOrError(tc.def, testKey, alt1Key, alt2Key)\n\t\tif err != nil && !tc.err {\n\t\t\tt.Fatalf(\"%d: %q: unexpected error: %v\", i, tc.value, err)\n\t\t}\n\t\tif err == nil && tc.err {\n\t\t\tt.Fatalf(\"%d: %q: unexpected success\", i, tc.value)\n\t\t}\n\t\tif val != tc.exp {\n\t\t\tt.Fatalf(\"%d: expected: %v, got: %v\", i, tc.exp, val)\n\t\t}\n\t}\n}\n"
        },
        {
          "name": "go.mod",
          "type": "blob",
          "size": 0.70703125,
          "content": "module k8s.io/git-sync\n\nrequire (\n\tgithub.com/go-logr/logr v1.2.3\n\tgithub.com/golang-jwt/jwt/v4 v4.5.0\n\tgithub.com/prometheus/client_golang v1.14.0\n\tgithub.com/spf13/pflag v1.0.5\n\tgo.uber.org/goleak v1.2.1\n\tgolang.org/x/sys v0.0.0-20220520151302-bc2c85ada10a\n)\n\nrequire (\n\tgithub.com/beorn7/perks v1.0.1 // indirect\n\tgithub.com/cespare/xxhash/v2 v2.1.2 // indirect\n\tgithub.com/golang/protobuf v1.5.2 // indirect\n\tgithub.com/matttproud/golang_protobuf_extensions v1.0.2-0.20181231171920-c182affec369 // indirect\n\tgithub.com/prometheus/client_model v0.3.0 // indirect\n\tgithub.com/prometheus/common v0.37.0 // indirect\n\tgithub.com/prometheus/procfs v0.8.0 // indirect\n\tgoogle.golang.org/protobuf v1.33.0 // indirect\n)\n\ngo 1.22\n"
        },
        {
          "name": "go.sum",
          "type": "blob",
          "size": 48.0869140625,
          "content": "cloud.google.com/go v0.26.0/go.mod h1:aQUYkXzVsufM+DwF1aE+0xfcU+56JwCaLick0ClmMTw=\ncloud.google.com/go v0.34.0/go.mod h1:aQUYkXzVsufM+DwF1aE+0xfcU+56JwCaLick0ClmMTw=\ncloud.google.com/go v0.38.0/go.mod h1:990N+gfupTy94rShfmMCWGDn0LpTmnzTp2qbd1dvSRU=\ncloud.google.com/go v0.44.1/go.mod h1:iSa0KzasP4Uvy3f1mN/7PiObzGgflwredwwASm/v6AU=\ncloud.google.com/go v0.44.2/go.mod h1:60680Gw3Yr4ikxnPRS/oxxkBccT6SA1yMk63TGekxKY=\ncloud.google.com/go v0.45.1/go.mod h1:RpBamKRgapWJb87xiFSdk4g1CME7QZg3uwTez+TSTjc=\ncloud.google.com/go v0.46.3/go.mod h1:a6bKKbmY7er1mI7TEI4lsAkts/mkhTSZK8w33B4RAg0=\ncloud.google.com/go v0.50.0/go.mod h1:r9sluTvynVuxRIOHXQEHMFffphuXHOMZMycpNR5e6To=\ncloud.google.com/go v0.52.0/go.mod h1:pXajvRH/6o3+F9jDHZWQ5PbGhn+o8w9qiu/CffaVdO4=\ncloud.google.com/go v0.53.0/go.mod h1:fp/UouUEsRkN6ryDKNW/Upv/JBKnv6WDthjR6+vze6M=\ncloud.google.com/go v0.54.0/go.mod h1:1rq2OEkV3YMf6n/9ZvGWI3GWw0VoqH/1x2nd8Is/bPc=\ncloud.google.com/go v0.56.0/go.mod h1:jr7tqZxxKOVYizybht9+26Z/gUq7tiRzu+ACVAMbKVk=\ncloud.google.com/go v0.57.0/go.mod h1:oXiQ6Rzq3RAkkY7N6t3TcE6jE+CIBBbA36lwQ1JyzZs=\ncloud.google.com/go v0.62.0/go.mod h1:jmCYTdRCQuc1PHIIJ/maLInMho30T/Y0M4hTdTShOYc=\ncloud.google.com/go v0.65.0/go.mod h1:O5N8zS7uWy9vkA9vayVHs65eM1ubvY4h553ofrNHObY=\ncloud.google.com/go/bigquery v1.0.1/go.mod h1:i/xbL2UlR5RvWAURpBYZTtm/cXjCha9lbfbpx4poX+o=\ncloud.google.com/go/bigquery v1.3.0/go.mod h1:PjpwJnslEMmckchkHFfq+HTD2DmtT67aNFKH1/VBDHE=\ncloud.google.com/go/bigquery v1.4.0/go.mod h1:S8dzgnTigyfTmLBfrtrhyYhwRxG72rYxvftPBK2Dvzc=\ncloud.google.com/go/bigquery v1.5.0/go.mod h1:snEHRnqQbz117VIFhE8bmtwIDY80NLUZUMb4Nv6dBIg=\ncloud.google.com/go/bigquery v1.7.0/go.mod h1://okPTzCYNXSlb24MZs83e2Do+h+VXtc4gLoIoXIAPc=\ncloud.google.com/go/bigquery v1.8.0/go.mod h1:J5hqkt3O0uAFnINi6JXValWIb1v0goeZM77hZzJN/fQ=\ncloud.google.com/go/datastore v1.0.0/go.mod h1:LXYbyblFSglQ5pkeyhO+Qmw7ukd3C+pD7TKLgZqpHYE=\ncloud.google.com/go/datastore v1.1.0/go.mod h1:umbIZjpQpHh4hmRpGhH4tLFup+FVzqBi1b3c64qFpCk=\ncloud.google.com/go/pubsub v1.0.1/go.mod h1:R0Gpsv3s54REJCy4fxDixWD93lHJMoZTyQ2kNxGRt3I=\ncloud.google.com/go/pubsub v1.1.0/go.mod h1:EwwdRX2sKPjnvnqCa270oGRyludottCI76h+R3AArQw=\ncloud.google.com/go/pubsub v1.2.0/go.mod h1:jhfEVHT8odbXTkndysNHCcx0awwzvfOlguIAii9o8iA=\ncloud.google.com/go/pubsub v1.3.1/go.mod h1:i+ucay31+CNRpDW4Lu78I4xXG+O1r/MAHgjpRVR+TSU=\ncloud.google.com/go/storage v1.0.0/go.mod h1:IhtSnM/ZTZV8YYJWCY8RULGVqBDmpoyjwiyrjsg+URw=\ncloud.google.com/go/storage v1.5.0/go.mod h1:tpKbwo567HUNpVclU5sGELwQWBDZ8gh0ZeosJ0Rtdos=\ncloud.google.com/go/storage v1.6.0/go.mod h1:N7U0C8pVQ/+NIKOBQyamJIeKQKkZ+mxpohlUTyfDhBk=\ncloud.google.com/go/storage v1.8.0/go.mod h1:Wv1Oy7z6Yz3DshWRJFhqM/UCfaWIRTdp0RXyy7KQOVs=\ncloud.google.com/go/storage v1.10.0/go.mod h1:FLPqc6j+Ki4BU591ie1oL6qBQGu2Bl/tZ9ullr3+Kg0=\ndmitri.shuralyov.com/gpu/mtl v0.0.0-20190408044501-666a987793e9/go.mod h1:H6x//7gZCb22OMCxBHrMx7a5I7Hp++hsVxbQ4BYO7hU=\ngithub.com/BurntSushi/toml v0.3.1/go.mod h1:xHWCNGjB5oqiDr8zfno3MHue2Ht5sIBksp03qcyfWMU=\ngithub.com/BurntSushi/xgb v0.0.0-20160522181843-27f122750802/go.mod h1:IVnqGOEym/WlBOVXweHU+Q+/VP0lqqI8lqeDx9IjBqo=\ngithub.com/alecthomas/template v0.0.0-20160405071501-a0175ee3bccc/go.mod h1:LOuyumcjzFXgccqObfd/Ljyb9UuFJ6TxHnclSeseNhc=\ngithub.com/alecthomas/template v0.0.0-20190718012654-fb15b899a751/go.mod h1:LOuyumcjzFXgccqObfd/Ljyb9UuFJ6TxHnclSeseNhc=\ngithub.com/alecthomas/units v0.0.0-20151022065526-2efee857e7cf/go.mod h1:ybxpYRFXyAe+OPACYpWeL0wqObRcbAqCMya13uyzqw0=\ngithub.com/alecthomas/units v0.0.0-20190717042225-c3de453c63f4/go.mod h1:ybxpYRFXyAe+OPACYpWeL0wqObRcbAqCMya13uyzqw0=\ngithub.com/alecthomas/units v0.0.0-20190924025748-f65c72e2690d/go.mod h1:rBZYJk541a8SKzHPHnH3zbiI+7dagKZ0cgpgrD7Fyho=\ngithub.com/beorn7/perks v0.0.0-20180321164747-3a771d992973/go.mod h1:Dwedo/Wpr24TaqPxmxbtue+5NUziq4I4S80YR8gNf3Q=\ngithub.com/beorn7/perks v1.0.0/go.mod h1:KWe93zE9D1o94FZ5RNwFwVgaQK1VOXiVxmqh+CedLV8=\ngithub.com/beorn7/perks v1.0.1 h1:VlbKKnNfV8bJzeqoa4cOKqO6bYr3WgKZxO8Z16+hsOM=\ngithub.com/beorn7/perks v1.0.1/go.mod h1:G2ZrVWU2WbWT9wwq4/hrbKbnv/1ERSJQ0ibhJ6rlkpw=\ngithub.com/census-instrumentation/opencensus-proto v0.2.1/go.mod h1:f6KPmirojxKA12rnyqOA5BBL4O983OfeGPqjHWSTneU=\ngithub.com/cespare/xxhash/v2 v2.1.1/go.mod h1:VGX0DQ3Q6kWi7AoAeZDth3/j3BFtOZR5XLFGgcrjCOs=\ngithub.com/cespare/xxhash/v2 v2.1.2 h1:YRXhKfTDauu4ajMg1TPgFO5jnlC2HCbmLXMcTG5cbYE=\ngithub.com/cespare/xxhash/v2 v2.1.2/go.mod h1:VGX0DQ3Q6kWi7AoAeZDth3/j3BFtOZR5XLFGgcrjCOs=\ngithub.com/chzyer/logex v1.1.10/go.mod h1:+Ywpsq7O8HXn0nuIou7OrIPyXbp3wmkHB+jjWRnGsAI=\ngithub.com/chzyer/readline v0.0.0-20180603132655-2972be24d48e/go.mod h1:nSuG5e5PlCu98SY8svDHJxuZscDgtXS6KTTbou5AhLI=\ngithub.com/chzyer/test v0.0.0-20180213035817-a1ea475d72b1/go.mod h1:Q3SI9o4m/ZMnBNeIyt5eFwwo7qiLfzFZmjNmxjkiQlU=\ngithub.com/client9/misspell v0.3.4/go.mod h1:qj6jICC3Q7zFZvVWo7KLAzC3yx5G7kyvSDkc90ppPyw=\ngithub.com/cncf/udpa/go v0.0.0-20191209042840-269d4d468f6f/go.mod h1:M8M6+tZqaGXZJjfX53e64911xZQV5JYwmTeXPW+k8Sc=\ngithub.com/davecgh/go-spew v1.1.0/go.mod h1:J7Y8YcW2NihsgmVo/mv3lAwl/skON4iLHjSsI+c5H38=\ngithub.com/davecgh/go-spew v1.1.1 h1:vj9j/u1bqnvCEfJOwUhtlOARqs3+rkHYY13jYWTU97c=\ngithub.com/davecgh/go-spew v1.1.1/go.mod h1:J7Y8YcW2NihsgmVo/mv3lAwl/skON4iLHjSsI+c5H38=\ngithub.com/envoyproxy/go-control-plane v0.9.0/go.mod h1:YTl/9mNaCwkRvm6d1a2C3ymFceY/DCBVvsKhRF0iEA4=\ngithub.com/envoyproxy/go-control-plane v0.9.1-0.20191026205805-5f8ba28d4473/go.mod h1:YTl/9mNaCwkRvm6d1a2C3ymFceY/DCBVvsKhRF0iEA4=\ngithub.com/envoyproxy/go-control-plane v0.9.4/go.mod h1:6rpuAdCZL397s3pYoYcLgu1mIlRU8Am5FuJP05cCM98=\ngithub.com/envoyproxy/protoc-gen-validate v0.1.0/go.mod h1:iSmxcyjqTsJpI2R4NaDN7+kN2VEUnK/pcBlmesArF7c=\ngithub.com/go-gl/glfw v0.0.0-20190409004039-e6da0acd62b1/go.mod h1:vR7hzQXu2zJy9AVAgeJqvqgH9Q5CA+iKCZ2gyEVpxRU=\ngithub.com/go-gl/glfw/v3.3/glfw v0.0.0-20191125211704-12ad95a8df72/go.mod h1:tQ2UAYgL5IevRw8kRxooKSPJfGvJ9fJQFa0TUsXzTg8=\ngithub.com/go-gl/glfw/v3.3/glfw v0.0.0-20200222043503-6f7a984d4dc4/go.mod h1:tQ2UAYgL5IevRw8kRxooKSPJfGvJ9fJQFa0TUsXzTg8=\ngithub.com/go-kit/kit v0.8.0/go.mod h1:xBxKIO96dXMWWy0MnWVtmwkA9/13aqxPnvrjFYMA2as=\ngithub.com/go-kit/kit v0.9.0/go.mod h1:xBxKIO96dXMWWy0MnWVtmwkA9/13aqxPnvrjFYMA2as=\ngithub.com/go-kit/log v0.1.0/go.mod h1:zbhenjAZHb184qTLMA9ZjW7ThYL0H2mk7Q6pNt4vbaY=\ngithub.com/go-kit/log v0.2.0/go.mod h1:NwTd00d/i8cPZ3xOwwiv2PO5MOcx78fFErGNcVmBjv0=\ngithub.com/go-logfmt/logfmt v0.3.0/go.mod h1:Qt1PoO58o5twSAckw1HlFXLmHsOX5/0LbT9GBnD5lWE=\ngithub.com/go-logfmt/logfmt v0.4.0/go.mod h1:3RMwSq7FuexP4Kalkev3ejPJsZTpXXBr9+V4qmtdjCk=\ngithub.com/go-logfmt/logfmt v0.5.0/go.mod h1:wCYkCAKZfumFQihp8CzCvQ3paCTfi41vtzG1KdI/P7A=\ngithub.com/go-logfmt/logfmt v0.5.1/go.mod h1:WYhtIu8zTZfxdn5+rREduYbwxfcBr/Vr6KEVveWlfTs=\ngithub.com/go-logr/logr v1.2.3 h1:2DntVwHkVopvECVRSlL5PSo9eG+cAkDCuckLubN+rq0=\ngithub.com/go-logr/logr v1.2.3/go.mod h1:jdQByPbusPIv2/zmleS9BjJVeZ6kBagPoEUsqbVz/1A=\ngithub.com/go-stack/stack v1.8.0/go.mod h1:v0f6uXyyMGvRgIKkXu+yp6POWl0qKG85gN/melR3HDY=\ngithub.com/gogo/protobuf v1.1.1/go.mod h1:r8qH/GZQm5c6nD/R0oafs1akxWv10x8SbQlK7atdtwQ=\ngithub.com/golang-jwt/jwt/v4 v4.5.0 h1:7cYmW1XlMY7h7ii7UhUyChSgS5wUJEnm9uZVTGqOWzg=\ngithub.com/golang-jwt/jwt/v4 v4.5.0/go.mod h1:m21LjoU+eqJr34lmDMbreY2eSTRJ1cv77w39/MY0Ch0=\ngithub.com/golang/glog v0.0.0-20160126235308-23def4e6c14b/go.mod h1:SBH7ygxi8pfUlaOkMMuAQtPIUF8ecWP5IEl/CR7VP2Q=\ngithub.com/golang/groupcache v0.0.0-20190702054246-869f871628b6/go.mod h1:cIg4eruTrX1D+g88fzRXU5OdNfaM+9IcxsU14FzY7Hc=\ngithub.com/golang/groupcache v0.0.0-20191227052852-215e87163ea7/go.mod h1:cIg4eruTrX1D+g88fzRXU5OdNfaM+9IcxsU14FzY7Hc=\ngithub.com/golang/groupcache v0.0.0-20200121045136-8c9f03a8e57e/go.mod h1:cIg4eruTrX1D+g88fzRXU5OdNfaM+9IcxsU14FzY7Hc=\ngithub.com/golang/mock v1.1.1/go.mod h1:oTYuIxOrZwtPieC+H1uAHpcLFnEyAGVDL/k47Jfbm0A=\ngithub.com/golang/mock v1.2.0/go.mod h1:oTYuIxOrZwtPieC+H1uAHpcLFnEyAGVDL/k47Jfbm0A=\ngithub.com/golang/mock v1.3.1/go.mod h1:sBzyDLLjw3U8JLTeZvSv8jJB+tU5PVekmnlKIyFUx0Y=\ngithub.com/golang/mock v1.4.0/go.mod h1:UOMv5ysSaYNkG+OFQykRIcU/QvvxJf3p21QfJ2Bt3cw=\ngithub.com/golang/mock v1.4.1/go.mod h1:UOMv5ysSaYNkG+OFQykRIcU/QvvxJf3p21QfJ2Bt3cw=\ngithub.com/golang/mock v1.4.3/go.mod h1:UOMv5ysSaYNkG+OFQykRIcU/QvvxJf3p21QfJ2Bt3cw=\ngithub.com/golang/mock v1.4.4/go.mod h1:l3mdAwkq5BuhzHwde/uurv3sEJeZMXNpwsxVWU71h+4=\ngithub.com/golang/protobuf v1.2.0/go.mod h1:6lQm79b+lXiMfvg/cZm0SGofjICqVBUtrP5yJMmIC1U=\ngithub.com/golang/protobuf v1.3.1/go.mod h1:6lQm79b+lXiMfvg/cZm0SGofjICqVBUtrP5yJMmIC1U=\ngithub.com/golang/protobuf v1.3.2/go.mod h1:6lQm79b+lXiMfvg/cZm0SGofjICqVBUtrP5yJMmIC1U=\ngithub.com/golang/protobuf v1.3.3/go.mod h1:vzj43D7+SQXF/4pzW/hwtAqwc6iTitCiVSaWz5lYuqw=\ngithub.com/golang/protobuf v1.3.4/go.mod h1:vzj43D7+SQXF/4pzW/hwtAqwc6iTitCiVSaWz5lYuqw=\ngithub.com/golang/protobuf v1.3.5/go.mod h1:6O5/vntMXwX2lRkT1hjjk0nAC1IDOTvTlVgjlRvqsdk=\ngithub.com/golang/protobuf v1.4.0-rc.1/go.mod h1:ceaxUfeHdC40wWswd/P6IGgMaK3YpKi5j83Wpe3EHw8=\ngithub.com/golang/protobuf v1.4.0-rc.1.0.20200221234624-67d41d38c208/go.mod h1:xKAWHe0F5eneWXFV3EuXVDTCmh+JuBKY0li0aMyXATA=\ngithub.com/golang/protobuf v1.4.0-rc.2/go.mod h1:LlEzMj4AhA7rCAGe4KMBDvJI+AwstrUpVNzEA03Pprs=\ngithub.com/golang/protobuf v1.4.0-rc.4.0.20200313231945-b860323f09d0/go.mod h1:WU3c8KckQ9AFe+yFwt9sWVRKCVIyN9cPHBJSNnbL67w=\ngithub.com/golang/protobuf v1.4.0/go.mod h1:jodUvKwWbYaEsadDk5Fwe5c77LiNKVO9IDvqG2KuDX0=\ngithub.com/golang/protobuf v1.4.1/go.mod h1:U8fpvMrcmy5pZrNK1lt4xCsGvpyWQ/VVv6QDs8UjoX8=\ngithub.com/golang/protobuf v1.4.2/go.mod h1:oDoupMAO8OvCJWAcko0GGGIgR6R6ocIYbsSw735rRwI=\ngithub.com/golang/protobuf v1.4.3/go.mod h1:oDoupMAO8OvCJWAcko0GGGIgR6R6ocIYbsSw735rRwI=\ngithub.com/golang/protobuf v1.5.0/go.mod h1:FsONVRAS9T7sI+LIUmWTfcYkHO4aIWwzhcaSAoJOfIk=\ngithub.com/golang/protobuf v1.5.2 h1:ROPKBNFfQgOUMifHyP+KYbvpjbdoFNs+aK7DXlji0Tw=\ngithub.com/golang/protobuf v1.5.2/go.mod h1:XVQd3VNwM+JqD3oG2Ue2ip4fOMUkwXdXDdiuN0vRsmY=\ngithub.com/google/btree v0.0.0-20180813153112-4030bb1f1f0c/go.mod h1:lNA+9X1NB3Zf8V7Ke586lFgjr2dZNuvo3lPJSGZ5JPQ=\ngithub.com/google/btree v1.0.0/go.mod h1:lNA+9X1NB3Zf8V7Ke586lFgjr2dZNuvo3lPJSGZ5JPQ=\ngithub.com/google/go-cmp v0.2.0/go.mod h1:oXzfMopK8JAjlY9xF4vHSVASa0yLyX7SntLO5aqRK0M=\ngithub.com/google/go-cmp v0.3.0/go.mod h1:8QqcDgzrUqlUb/G2PQTWiueGozuR1884gddMywk6iLU=\ngithub.com/google/go-cmp v0.3.1/go.mod h1:8QqcDgzrUqlUb/G2PQTWiueGozuR1884gddMywk6iLU=\ngithub.com/google/go-cmp v0.4.0/go.mod h1:v8dTdLbMG2kIc/vJvl+f65V22dbkXbowE6jgT/gNBxE=\ngithub.com/google/go-cmp v0.4.1/go.mod h1:v8dTdLbMG2kIc/vJvl+f65V22dbkXbowE6jgT/gNBxE=\ngithub.com/google/go-cmp v0.5.0/go.mod h1:v8dTdLbMG2kIc/vJvl+f65V22dbkXbowE6jgT/gNBxE=\ngithub.com/google/go-cmp v0.5.1/go.mod h1:v8dTdLbMG2kIc/vJvl+f65V22dbkXbowE6jgT/gNBxE=\ngithub.com/google/go-cmp v0.5.4/go.mod h1:v8dTdLbMG2kIc/vJvl+f65V22dbkXbowE6jgT/gNBxE=\ngithub.com/google/go-cmp v0.5.5/go.mod h1:v8dTdLbMG2kIc/vJvl+f65V22dbkXbowE6jgT/gNBxE=\ngithub.com/google/go-cmp v0.5.8 h1:e6P7q2lk1O+qJJb4BtCQXlK8vWEO8V1ZeuEdJNOqZyg=\ngithub.com/google/go-cmp v0.5.8/go.mod h1:17dUlkBOakJ0+DkrSSNjCkIjxS6bF9zb3elmeNGIjoY=\ngithub.com/google/gofuzz v1.0.0/go.mod h1:dBl0BpW6vV/+mYPU4Po3pmUjxk6FQPldtuIdl/M65Eg=\ngithub.com/google/martian v2.1.0+incompatible/go.mod h1:9I4somxYTbIHy5NJKHRl3wXiIaQGbYVAs8BPL6v8lEs=\ngithub.com/google/martian/v3 v3.0.0/go.mod h1:y5Zk1BBys9G+gd6Jrk0W3cC1+ELVxBWuIGO+w/tUAp0=\ngithub.com/google/pprof v0.0.0-20181206194817-3ea8567a2e57/go.mod h1:zfwlbNMJ+OItoe0UupaVj+oy1omPYYDuagoSzA8v9mc=\ngithub.com/google/pprof v0.0.0-20190515194954-54271f7e092f/go.mod h1:zfwlbNMJ+OItoe0UupaVj+oy1omPYYDuagoSzA8v9mc=\ngithub.com/google/pprof v0.0.0-20191218002539-d4f498aebedc/go.mod h1:ZgVRPoUq/hfqzAqh7sHMqb3I9Rq5C59dIz2SbBwJ4eM=\ngithub.com/google/pprof v0.0.0-20200212024743-f11f1df84d12/go.mod h1:ZgVRPoUq/hfqzAqh7sHMqb3I9Rq5C59dIz2SbBwJ4eM=\ngithub.com/google/pprof v0.0.0-20200229191704-1ebb73c60ed3/go.mod h1:ZgVRPoUq/hfqzAqh7sHMqb3I9Rq5C59dIz2SbBwJ4eM=\ngithub.com/google/pprof v0.0.0-20200430221834-fc25d7d30c6d/go.mod h1:ZgVRPoUq/hfqzAqh7sHMqb3I9Rq5C59dIz2SbBwJ4eM=\ngithub.com/google/pprof v0.0.0-20200708004538-1a94d8640e99/go.mod h1:ZgVRPoUq/hfqzAqh7sHMqb3I9Rq5C59dIz2SbBwJ4eM=\ngithub.com/google/renameio v0.1.0/go.mod h1:KWCgfxg9yswjAJkECMjeO8J8rahYeXnNhOm40UhjYkI=\ngithub.com/googleapis/gax-go/v2 v2.0.4/go.mod h1:0Wqv26UfaUD9n4G6kQubkQ+KchISgw+vpHVxEJEs9eg=\ngithub.com/googleapis/gax-go/v2 v2.0.5/go.mod h1:DWXyrwAJ9X0FpwwEdw+IPEYBICEFu5mhpdKc/us6bOk=\ngithub.com/hashicorp/golang-lru v0.5.0/go.mod h1:/m3WP610KZHVQ1SGc6re/UDhFvYD7pJ4Ao+sR/qLZy8=\ngithub.com/hashicorp/golang-lru v0.5.1/go.mod h1:/m3WP610KZHVQ1SGc6re/UDhFvYD7pJ4Ao+sR/qLZy8=\ngithub.com/ianlancetaylor/demangle v0.0.0-20181102032728-5e5cf60278f6/go.mod h1:aSSvb/t6k1mPoxDqO4vJh6VOCGPwU4O0C2/Eqndh1Sc=\ngithub.com/jpillora/backoff v1.0.0/go.mod h1:J/6gKK9jxlEcS3zixgDgUAsiuZ7yrSoa/FX5e0EB2j4=\ngithub.com/json-iterator/go v1.1.6/go.mod h1:+SdeFBvtyEkXs7REEP0seUULqWtbJapLOCVDaaPEHmU=\ngithub.com/json-iterator/go v1.1.10/go.mod h1:KdQUCv79m/52Kvf8AW2vK1V8akMuk1QjK/uOdHXbAo4=\ngithub.com/json-iterator/go v1.1.11/go.mod h1:KdQUCv79m/52Kvf8AW2vK1V8akMuk1QjK/uOdHXbAo4=\ngithub.com/json-iterator/go v1.1.12/go.mod h1:e30LSqwooZae/UwlEbR2852Gd8hjQvJoHmT4TnhNGBo=\ngithub.com/jstemmer/go-junit-report v0.0.0-20190106144839-af01ea7f8024/go.mod h1:6v2b51hI/fHJwM22ozAgKL4VKDeJcHhJFhtBdhmNjmU=\ngithub.com/jstemmer/go-junit-report v0.9.1/go.mod h1:Brl9GWCQeLvo8nXZwPNNblvFj/XSXhF0NWZEnDohbsk=\ngithub.com/julienschmidt/httprouter v1.2.0/go.mod h1:SYymIcj16QtmaHHD7aYtjjsJG7VTCxuUUipMqKk8s4w=\ngithub.com/julienschmidt/httprouter v1.3.0/go.mod h1:JR6WtHb+2LUe8TCKY3cZOxFyyO8IZAc4RVcycCCAKdM=\ngithub.com/kisielk/gotool v1.0.0/go.mod h1:XhKaO+MFFWcvkIS/tQcRk01m1F5IRFswLeQ+oQHNcck=\ngithub.com/konsorten/go-windows-terminal-sequences v1.0.1/go.mod h1:T0+1ngSBFLxvqU3pZ+m/2kptfBszLMUkC4ZK/EgS/cQ=\ngithub.com/konsorten/go-windows-terminal-sequences v1.0.3/go.mod h1:T0+1ngSBFLxvqU3pZ+m/2kptfBszLMUkC4ZK/EgS/cQ=\ngithub.com/kr/logfmt v0.0.0-20140226030751-b84e30acd515/go.mod h1:+0opPa2QZZtGFBFZlji/RkVcI2GknAs/DXo4wKdlNEc=\ngithub.com/kr/pretty v0.1.0/go.mod h1:dAy3ld7l9f0ibDNOQOHHMYYIIbhfbHSm3C4ZsoJORNo=\ngithub.com/kr/pty v1.1.1/go.mod h1:pFQYn66WHrOpPYNljwOMqo10TkYh1fy3cYio2l3bCsQ=\ngithub.com/kr/text v0.1.0/go.mod h1:4Jbv+DJW3UT/LiOwJeYQe1efqtUx/iVham/4vfdArNI=\ngithub.com/matttproud/golang_protobuf_extensions v1.0.1/go.mod h1:D8He9yQNgCq6Z5Ld7szi9bcBfOoFv/3dc6xSMkL2PC0=\ngithub.com/matttproud/golang_protobuf_extensions v1.0.2-0.20181231171920-c182affec369 h1:I0XW9+e1XWDxdcEniV4rQAIOPUGDq67JSCiRCgGCZLI=\ngithub.com/matttproud/golang_protobuf_extensions v1.0.2-0.20181231171920-c182affec369/go.mod h1:BSXmuO+STAnVfrANrmjBb36TMTDstsz7MSK+HVaYKv4=\ngithub.com/modern-go/concurrent v0.0.0-20180228061459-e0a39a4cb421/go.mod h1:6dJC0mAP4ikYIbvyc7fijjWJddQyLn8Ig3JB5CqoB9Q=\ngithub.com/modern-go/concurrent v0.0.0-20180306012644-bacd9c7ef1dd/go.mod h1:6dJC0mAP4ikYIbvyc7fijjWJddQyLn8Ig3JB5CqoB9Q=\ngithub.com/modern-go/reflect2 v0.0.0-20180701023420-4b7aa43c6742/go.mod h1:bx2lNnkwVCuqBIxFjflWJWanXIb3RllmbCylyMrvgv0=\ngithub.com/modern-go/reflect2 v1.0.1/go.mod h1:bx2lNnkwVCuqBIxFjflWJWanXIb3RllmbCylyMrvgv0=\ngithub.com/modern-go/reflect2 v1.0.2/go.mod h1:yWuevngMOJpCy52FWWMvUC8ws7m/LJsjYzDa0/r8luk=\ngithub.com/mwitkow/go-conntrack v0.0.0-20161129095857-cc309e4a2223/go.mod h1:qRWi+5nqEBWmkhHvq77mSJWrCKwh8bxhgT7d/eI7P4U=\ngithub.com/mwitkow/go-conntrack v0.0.0-20190716064945-2f068394615f/go.mod h1:qRWi+5nqEBWmkhHvq77mSJWrCKwh8bxhgT7d/eI7P4U=\ngithub.com/pkg/errors v0.8.0/go.mod h1:bwawxfHBFNV+L2hUp1rHADufV3IMtnDRdf1r5NINEl0=\ngithub.com/pkg/errors v0.8.1/go.mod h1:bwawxfHBFNV+L2hUp1rHADufV3IMtnDRdf1r5NINEl0=\ngithub.com/pkg/errors v0.9.1/go.mod h1:bwawxfHBFNV+L2hUp1rHADufV3IMtnDRdf1r5NINEl0=\ngithub.com/pmezard/go-difflib v1.0.0 h1:4DBwDE0NGyQoBHbLQYPwSUPoCMWR5BEzIk/f1lZbAQM=\ngithub.com/pmezard/go-difflib v1.0.0/go.mod h1:iKH77koFhYxTK1pcRnkKkqfTogsbg7gZNVY4sRDYZ/4=\ngithub.com/prometheus/client_golang v0.9.1/go.mod h1:7SWBe2y4D6OKWSNQJUaRYU/AaXPKyh/dDVn+NZz0KFw=\ngithub.com/prometheus/client_golang v1.0.0/go.mod h1:db9x61etRT2tGnBNRi70OPL5FsnadC4Ky3P0J6CfImo=\ngithub.com/prometheus/client_golang v1.7.1/go.mod h1:PY5Wy2awLA44sXw4AOSfFBetzPP4j5+D6mVACh+pe2M=\ngithub.com/prometheus/client_golang v1.11.0/go.mod h1:Z6t4BnS23TR94PD6BsDNk8yVqroYurpAkEiz0P2BEV0=\ngithub.com/prometheus/client_golang v1.12.1/go.mod h1:3Z9XVyYiZYEO+YQWt3RD2R3jrbd179Rt297l4aS6nDY=\ngithub.com/prometheus/client_golang v1.14.0 h1:nJdhIvne2eSX/XRAFV9PcvFFRbrjbcTUj0VP62TMhnw=\ngithub.com/prometheus/client_golang v1.14.0/go.mod h1:8vpkKitgIVNcqrRBWh1C4TIUQgYNtG/XQE4E/Zae36Y=\ngithub.com/prometheus/client_model v0.0.0-20180712105110-5c3871d89910/go.mod h1:MbSGuTsp3dbXC40dX6PRTWyKYBIrTGTE9sqQNg2J8bo=\ngithub.com/prometheus/client_model v0.0.0-20190129233127-fd36f4220a90/go.mod h1:xMI15A0UPsDsEKsMN9yxemIoYk6Tm2C1GtYGdfGttqA=\ngithub.com/prometheus/client_model v0.0.0-20190812154241-14fe0d1b01d4/go.mod h1:xMI15A0UPsDsEKsMN9yxemIoYk6Tm2C1GtYGdfGttqA=\ngithub.com/prometheus/client_model v0.2.0/go.mod h1:xMI15A0UPsDsEKsMN9yxemIoYk6Tm2C1GtYGdfGttqA=\ngithub.com/prometheus/client_model v0.3.0 h1:UBgGFHqYdG/TPFD1B1ogZywDqEkwp3fBMvqdiQ7Xew4=\ngithub.com/prometheus/client_model v0.3.0/go.mod h1:LDGWKZIo7rky3hgvBe+caln+Dr3dPggB5dvjtD7w9+w=\ngithub.com/prometheus/common v0.4.1/go.mod h1:TNfzLD0ON7rHzMJeJkieUDPYmFC7Snx/y86RQel1bk4=\ngithub.com/prometheus/common v0.10.0/go.mod h1:Tlit/dnDKsSWFlCLTWaA1cyBgKHSMdTB80sz/V91rCo=\ngithub.com/prometheus/common v0.26.0/go.mod h1:M7rCNAaPfAosfx8veZJCuw84e35h3Cfd9VFqTh1DIvc=\ngithub.com/prometheus/common v0.32.1/go.mod h1:vu+V0TpY+O6vW9J44gczi3Ap/oXXR10b+M/gUGO4Hls=\ngithub.com/prometheus/common v0.37.0 h1:ccBbHCgIiT9uSoFY0vX8H3zsNR5eLt17/RQLUvn8pXE=\ngithub.com/prometheus/common v0.37.0/go.mod h1:phzohg0JFMnBEFGxTDbfu3QyL5GI8gTQJFhYO5B3mfA=\ngithub.com/prometheus/procfs v0.0.0-20181005140218-185b4288413d/go.mod h1:c3At6R/oaqEKCNdg8wHV1ftS6bRYblBhIjjI8uT2IGk=\ngithub.com/prometheus/procfs v0.0.2/go.mod h1:TjEm7ze935MbeOT/UhFTIMYKhuLP4wbCsTZCD3I8kEA=\ngithub.com/prometheus/procfs v0.1.3/go.mod h1:lV6e/gmhEcM9IjHGsFOCxxuZ+z1YqCvr4OA4YeYWdaU=\ngithub.com/prometheus/procfs v0.6.0/go.mod h1:cz+aTbrPOrUb4q7XlbU9ygM+/jj0fzG6c1xBZuNvfVA=\ngithub.com/prometheus/procfs v0.7.3/go.mod h1:cz+aTbrPOrUb4q7XlbU9ygM+/jj0fzG6c1xBZuNvfVA=\ngithub.com/prometheus/procfs v0.8.0 h1:ODq8ZFEaYeCaZOJlZZdJA2AbQR98dSHSM1KW/You5mo=\ngithub.com/prometheus/procfs v0.8.0/go.mod h1:z7EfXMXOkbkqb9IINtpCn86r/to3BnA0uaxHdg830/4=\ngithub.com/rogpeppe/go-internal v1.3.0/go.mod h1:M8bDsm7K2OlrFYOpmOWEs/qY81heoFRclV5y23lUDJ4=\ngithub.com/sirupsen/logrus v1.2.0/go.mod h1:LxeOpSwHxABJmUn/MG1IvRgCAasNZTLOkJPxbbu5VWo=\ngithub.com/sirupsen/logrus v1.4.2/go.mod h1:tLMulIdttU9McNUspp0xgXVQah82FyeX6MwdIuYE2rE=\ngithub.com/sirupsen/logrus v1.6.0/go.mod h1:7uNnSEd1DgxDLC74fIahvMZmmYsHGZGEOFrfsX/uA88=\ngithub.com/spf13/pflag v1.0.5 h1:iy+VFUOCP1a+8yFto/drg2CJ5u0yRoB7fZw3DKv/JXA=\ngithub.com/spf13/pflag v1.0.5/go.mod h1:McXfInJRrz4CZXVZOBLb0bTZqETkiAhM9Iw0y3An2Bg=\ngithub.com/stretchr/objx v0.1.0/go.mod h1:HFkY916IF+rwdDfMAkV7OtwuqBVzrE8GR6GFx+wExME=\ngithub.com/stretchr/objx v0.1.1/go.mod h1:HFkY916IF+rwdDfMAkV7OtwuqBVzrE8GR6GFx+wExME=\ngithub.com/stretchr/testify v1.2.2/go.mod h1:a8OnRcib4nhh0OaRAV+Yts87kKdq0PP7pXfy6kDkUVs=\ngithub.com/stretchr/testify v1.3.0/go.mod h1:M5WIy9Dh21IEIfnGCwXGc5bZfKNJtfHm1UVUgZn+9EI=\ngithub.com/stretchr/testify v1.4.0/go.mod h1:j7eGeouHqKxXV5pUuKE4zz7dFj8WfuZ+81PSLYec5m4=\ngithub.com/stretchr/testify v1.8.0 h1:pSgiaMZlXftHpm5L7V1+rVB+AZJydKsMxsQBIJw4PKk=\ngithub.com/stretchr/testify v1.8.0/go.mod h1:yNjHg4UonilssWZ8iaSj1OCr/vHnekPRkoO+kdMU+MU=\ngithub.com/yuin/goldmark v1.1.25/go.mod h1:3hX8gzYuyVAZsxl0MRgGTJEmQBFcNTphYh9decYSb74=\ngithub.com/yuin/goldmark v1.1.27/go.mod h1:3hX8gzYuyVAZsxl0MRgGTJEmQBFcNTphYh9decYSb74=\ngithub.com/yuin/goldmark v1.1.32/go.mod h1:3hX8gzYuyVAZsxl0MRgGTJEmQBFcNTphYh9decYSb74=\ngo.opencensus.io v0.21.0/go.mod h1:mSImk1erAIZhrmZN+AvHh14ztQfjbGwt4TtuofqLduU=\ngo.opencensus.io v0.22.0/go.mod h1:+kGneAE2xo2IficOXnaByMWTGM9T73dGwxeWcUqIpI8=\ngo.opencensus.io v0.22.2/go.mod h1:yxeiOL68Rb0Xd1ddK5vPZ/oVn4vY4Ynel7k9FzqtOIw=\ngo.opencensus.io v0.22.3/go.mod h1:yxeiOL68Rb0Xd1ddK5vPZ/oVn4vY4Ynel7k9FzqtOIw=\ngo.opencensus.io v0.22.4/go.mod h1:yxeiOL68Rb0Xd1ddK5vPZ/oVn4vY4Ynel7k9FzqtOIw=\ngo.uber.org/goleak v1.2.1 h1:NBol2c7O1ZokfZ0LEU9K6Whx/KnwvepVetCUhtKja4A=\ngo.uber.org/goleak v1.2.1/go.mod h1:qlT2yGI9QafXHhZZLxlSuNsMw3FFLxBr+tBRlmO1xH4=\ngolang.org/x/crypto v0.0.0-20180904163835-0709b304e793/go.mod h1:6SG95UA2DQfeDnfUPMdvaQW0Q7yPrPDi9nlGo2tz2b4=\ngolang.org/x/crypto v0.0.0-20190308221718-c2843e01d9a2/go.mod h1:djNgcEr1/C05ACkg1iLfiJU5Ep61QUkGW8qpdssI0+w=\ngolang.org/x/crypto v0.0.0-20190510104115-cbcb75029529/go.mod h1:yigFU9vqHzYiE8UmvKecakEJjdnWj3jj499lnFckfCI=\ngolang.org/x/crypto v0.0.0-20190605123033-f99c8df09eb5/go.mod h1:yigFU9vqHzYiE8UmvKecakEJjdnWj3jj499lnFckfCI=\ngolang.org/x/crypto v0.0.0-20191011191535-87dc89f01550/go.mod h1:yigFU9vqHzYiE8UmvKecakEJjdnWj3jj499lnFckfCI=\ngolang.org/x/crypto v0.0.0-20200622213623-75b288015ac9/go.mod h1:LzIPMQfyMNhhGPhUkYOs5KpL4U8rLKemX1yGLhDgUto=\ngolang.org/x/exp v0.0.0-20190121172915-509febef88a4/go.mod h1:CJ0aWSM057203Lf6IL+f9T1iT9GByDxfZKAQTCR3kQA=\ngolang.org/x/exp v0.0.0-20190306152737-a1d7652674e8/go.mod h1:CJ0aWSM057203Lf6IL+f9T1iT9GByDxfZKAQTCR3kQA=\ngolang.org/x/exp v0.0.0-20190510132918-efd6b22b2522/go.mod h1:ZjyILWgesfNpC6sMxTJOJm9Kp84zZh5NQWvqDGG3Qr8=\ngolang.org/x/exp v0.0.0-20190829153037-c13cbed26979/go.mod h1:86+5VVa7VpoJ4kLfm080zCjGlMRFzhUhsZKEZO7MGek=\ngolang.org/x/exp v0.0.0-20191030013958-a1ab85dbe136/go.mod h1:JXzH8nQsPlswgeRAPE3MuO9GYsAcnJvJ4vnMwN/5qkY=\ngolang.org/x/exp v0.0.0-20191129062945-2f5052295587/go.mod h1:2RIsYlXP63K8oxa1u096TMicItID8zy7Y6sNkU49FU4=\ngolang.org/x/exp v0.0.0-20191227195350-da58074b4299/go.mod h1:2RIsYlXP63K8oxa1u096TMicItID8zy7Y6sNkU49FU4=\ngolang.org/x/exp v0.0.0-20200119233911-0405dc783f0a/go.mod h1:2RIsYlXP63K8oxa1u096TMicItID8zy7Y6sNkU49FU4=\ngolang.org/x/exp v0.0.0-20200207192155-f17229e696bd/go.mod h1:J/WKrq2StrnmMY6+EHIKF9dgMWnmCNThgcyBT1FY9mM=\ngolang.org/x/exp v0.0.0-20200224162631-6cc2880d07d6/go.mod h1:3jZMyOhIsHpP37uCMkUooju7aAi5cS1Q23tOzKc+0MU=\ngolang.org/x/image v0.0.0-20190227222117-0694c2d4d067/go.mod h1:kZ7UVZpmo3dzQBMxlp+ypCbDeSB+sBbTgSJuh5dn5js=\ngolang.org/x/image v0.0.0-20190802002840-cff245a6509b/go.mod h1:FeLwcggjj3mMvU+oOTbSwawSJRM1uh48EjtB4UJZlP0=\ngolang.org/x/lint v0.0.0-20181026193005-c67002cb31c3/go.mod h1:UVdnD1Gm6xHRNCYTkRU2/jEulfH38KcIWyp/GAMgvoE=\ngolang.org/x/lint v0.0.0-20190227174305-5b3e6a55c961/go.mod h1:wehouNa3lNwaWXcvxsM5YxQ5yQlVC4a0KAMCusXpPoU=\ngolang.org/x/lint v0.0.0-20190301231843-5614ed5bae6f/go.mod h1:UVdnD1Gm6xHRNCYTkRU2/jEulfH38KcIWyp/GAMgvoE=\ngolang.org/x/lint v0.0.0-20190313153728-d0100b6bd8b3/go.mod h1:6SW0HCj/g11FgYtHlgUYUwCkIfeOF89ocIRzGO/8vkc=\ngolang.org/x/lint v0.0.0-20190409202823-959b441ac422/go.mod h1:6SW0HCj/g11FgYtHlgUYUwCkIfeOF89ocIRzGO/8vkc=\ngolang.org/x/lint v0.0.0-20190909230951-414d861bb4ac/go.mod h1:6SW0HCj/g11FgYtHlgUYUwCkIfeOF89ocIRzGO/8vkc=\ngolang.org/x/lint v0.0.0-20190930215403-16217165b5de/go.mod h1:6SW0HCj/g11FgYtHlgUYUwCkIfeOF89ocIRzGO/8vkc=\ngolang.org/x/lint v0.0.0-20191125180803-fdd1cda4f05f/go.mod h1:5qLYkcX4OjUUV8bRuDixDT3tpyyb+LUpUlRWLxfhWrs=\ngolang.org/x/lint v0.0.0-20200130185559-910be7a94367/go.mod h1:3xt1FjdF8hUf6vQPIChWIBhFzV8gjjsPE/fR3IyQdNY=\ngolang.org/x/lint v0.0.0-20200302205851-738671d3881b/go.mod h1:3xt1FjdF8hUf6vQPIChWIBhFzV8gjjsPE/fR3IyQdNY=\ngolang.org/x/mobile v0.0.0-20190312151609-d3739f865fa6/go.mod h1:z+o9i4GpDbdi3rU15maQ/Ox0txvL9dWGYEHz965HBQE=\ngolang.org/x/mobile v0.0.0-20190719004257-d2bd2a29d028/go.mod h1:E/iHnbuqvinMTCcRqshq8CkpyQDoeVncDDYHnLhea+o=\ngolang.org/x/mod v0.0.0-20190513183733-4bf6d317e70e/go.mod h1:mXi4GBBbnImb6dmsKGUJ2LatrhH/nqhxcFungHvyanc=\ngolang.org/x/mod v0.1.0/go.mod h1:0QHyrYULN0/3qlju5TqG8bIK38QM8yzMo5ekMj3DlcY=\ngolang.org/x/mod v0.1.1-0.20191105210325-c90efee705ee/go.mod h1:QqPTAvyqsEbceGzBzNggFXnrqF1CaUcvgkdR5Ot7KZg=\ngolang.org/x/mod v0.1.1-0.20191107180719-034126e5016b/go.mod h1:QqPTAvyqsEbceGzBzNggFXnrqF1CaUcvgkdR5Ot7KZg=\ngolang.org/x/mod v0.2.0/go.mod h1:s0Qsj1ACt9ePp/hMypM3fl4fZqREWJwdYDEqhRiZZUA=\ngolang.org/x/mod v0.3.0/go.mod h1:s0Qsj1ACt9ePp/hMypM3fl4fZqREWJwdYDEqhRiZZUA=\ngolang.org/x/net v0.0.0-20180724234803-3673e40ba225/go.mod h1:mL1N/T3taQHkDXs73rZJwtUhF3w3ftmwwsq0BUmARs4=\ngolang.org/x/net v0.0.0-20180826012351-8a410e7b638d/go.mod h1:mL1N/T3taQHkDXs73rZJwtUhF3w3ftmwwsq0BUmARs4=\ngolang.org/x/net v0.0.0-20181114220301-adae6a3d119a/go.mod h1:mL1N/T3taQHkDXs73rZJwtUhF3w3ftmwwsq0BUmARs4=\ngolang.org/x/net v0.0.0-20190108225652-1e06a53dbb7e/go.mod h1:mL1N/T3taQHkDXs73rZJwtUhF3w3ftmwwsq0BUmARs4=\ngolang.org/x/net v0.0.0-20190213061140-3a22650c66bd/go.mod h1:mL1N/T3taQHkDXs73rZJwtUhF3w3ftmwwsq0BUmARs4=\ngolang.org/x/net v0.0.0-20190311183353-d8887717615a/go.mod h1:t9HGtf8HONx5eT2rtn7q6eTqICYqUVnKs3thJo3Qplg=\ngolang.org/x/net v0.0.0-20190404232315-eb5bcb51f2a3/go.mod h1:t9HGtf8HONx5eT2rtn7q6eTqICYqUVnKs3thJo3Qplg=\ngolang.org/x/net v0.0.0-20190501004415-9ce7a6920f09/go.mod h1:t9HGtf8HONx5eT2rtn7q6eTqICYqUVnKs3thJo3Qplg=\ngolang.org/x/net v0.0.0-20190503192946-f4e77d36d62c/go.mod h1:t9HGtf8HONx5eT2rtn7q6eTqICYqUVnKs3thJo3Qplg=\ngolang.org/x/net v0.0.0-20190603091049-60506f45cf65/go.mod h1:HSz+uSET+XFnRR8LxR5pz3Of3rY3CfYBVs4xY44aLks=\ngolang.org/x/net v0.0.0-20190613194153-d28f0bde5980/go.mod h1:z5CRVTTTmAJ677TzLLGU+0bjPO0LkuOLi4/5GtJWs/s=\ngolang.org/x/net v0.0.0-20190620200207-3b0461eec859/go.mod h1:z5CRVTTTmAJ677TzLLGU+0bjPO0LkuOLi4/5GtJWs/s=\ngolang.org/x/net v0.0.0-20190628185345-da137c7871d7/go.mod h1:z5CRVTTTmAJ677TzLLGU+0bjPO0LkuOLi4/5GtJWs/s=\ngolang.org/x/net v0.0.0-20190724013045-ca1201d0de80/go.mod h1:z5CRVTTTmAJ677TzLLGU+0bjPO0LkuOLi4/5GtJWs/s=\ngolang.org/x/net v0.0.0-20191209160850-c0dbc17a3553/go.mod h1:z5CRVTTTmAJ677TzLLGU+0bjPO0LkuOLi4/5GtJWs/s=\ngolang.org/x/net v0.0.0-20200114155413-6afb5195e5aa/go.mod h1:z5CRVTTTmAJ677TzLLGU+0bjPO0LkuOLi4/5GtJWs/s=\ngolang.org/x/net v0.0.0-20200202094626-16171245cfb2/go.mod h1:z5CRVTTTmAJ677TzLLGU+0bjPO0LkuOLi4/5GtJWs/s=\ngolang.org/x/net v0.0.0-20200222125558-5a598a2470a0/go.mod h1:z5CRVTTTmAJ677TzLLGU+0bjPO0LkuOLi4/5GtJWs/s=\ngolang.org/x/net v0.0.0-20200226121028-0de0cce0169b/go.mod h1:z5CRVTTTmAJ677TzLLGU+0bjPO0LkuOLi4/5GtJWs/s=\ngolang.org/x/net v0.0.0-20200301022130-244492dfa37a/go.mod h1:z5CRVTTTmAJ677TzLLGU+0bjPO0LkuOLi4/5GtJWs/s=\ngolang.org/x/net v0.0.0-20200324143707-d3edc9973b7e/go.mod h1:qpuaurCH72eLCgpAm/N6yyVIVM9cpaDIP3A8BGJEC5A=\ngolang.org/x/net v0.0.0-20200501053045-e0ff5e5a1de5/go.mod h1:qpuaurCH72eLCgpAm/N6yyVIVM9cpaDIP3A8BGJEC5A=\ngolang.org/x/net v0.0.0-20200506145744-7e3656a0809f/go.mod h1:qpuaurCH72eLCgpAm/N6yyVIVM9cpaDIP3A8BGJEC5A=\ngolang.org/x/net v0.0.0-20200513185701-a91f0712d120/go.mod h1:qpuaurCH72eLCgpAm/N6yyVIVM9cpaDIP3A8BGJEC5A=\ngolang.org/x/net v0.0.0-20200520182314-0ba52f642ac2/go.mod h1:qpuaurCH72eLCgpAm/N6yyVIVM9cpaDIP3A8BGJEC5A=\ngolang.org/x/net v0.0.0-20200625001655-4c5254603344/go.mod h1:/O7V0waA8r7cgGh81Ro3o1hOxt32SMVPicZroKQ2sZA=\ngolang.org/x/net v0.0.0-20200707034311-ab3426394381/go.mod h1:/O7V0waA8r7cgGh81Ro3o1hOxt32SMVPicZroKQ2sZA=\ngolang.org/x/net v0.0.0-20200822124328-c89045814202/go.mod h1:/O7V0waA8r7cgGh81Ro3o1hOxt32SMVPicZroKQ2sZA=\ngolang.org/x/net v0.0.0-20210525063256-abc453219eb5/go.mod h1:9nx3DQGgdP8bBQD5qxJ1jj9UTztislL4KSBs9R2vV5Y=\ngolang.org/x/net v0.0.0-20220127200216-cd36cc0744dd/go.mod h1:CfG3xpIq0wQ8r1q4Su4UZFWDARRcnwPjda9FqA0JpMk=\ngolang.org/x/net v0.0.0-20220225172249-27dd8689420f/go.mod h1:CfG3xpIq0wQ8r1q4Su4UZFWDARRcnwPjda9FqA0JpMk=\ngolang.org/x/oauth2 v0.0.0-20180821212333-d2e6202438be/go.mod h1:N/0e6XlmueqKjAGxoOufVs8QHGRruUQn6yWY3a++T0U=\ngolang.org/x/oauth2 v0.0.0-20190226205417-e64efc72b421/go.mod h1:gOpvHmFTYa4IltrdGE7lF6nIHvwfUNPOp7c8zoXwtLw=\ngolang.org/x/oauth2 v0.0.0-20190604053449-0f29369cfe45/go.mod h1:gOpvHmFTYa4IltrdGE7lF6nIHvwfUNPOp7c8zoXwtLw=\ngolang.org/x/oauth2 v0.0.0-20191202225959-858c2ad4c8b6/go.mod h1:gOpvHmFTYa4IltrdGE7lF6nIHvwfUNPOp7c8zoXwtLw=\ngolang.org/x/oauth2 v0.0.0-20200107190931-bf48bf16ab8d/go.mod h1:gOpvHmFTYa4IltrdGE7lF6nIHvwfUNPOp7c8zoXwtLw=\ngolang.org/x/oauth2 v0.0.0-20210514164344-f6687ab2804c/go.mod h1:KelEdhl1UZF7XfJ4dDtk6s++YSgaE7mD/BuKKDLBl4A=\ngolang.org/x/oauth2 v0.0.0-20220223155221-ee480838109b/go.mod h1:DAh4E804XQdzx2j+YRIaUnCqCV2RuMz24cGBJ5QYIrc=\ngolang.org/x/sync v0.0.0-20180314180146-1d60e4601c6f/go.mod h1:RxMgew5VJxzue5/jJTE5uejpjVlOe/izrB70Jof72aM=\ngolang.org/x/sync v0.0.0-20181108010431-42b317875d0f/go.mod h1:RxMgew5VJxzue5/jJTE5uejpjVlOe/izrB70Jof72aM=\ngolang.org/x/sync v0.0.0-20181221193216-37e7f081c4d4/go.mod h1:RxMgew5VJxzue5/jJTE5uejpjVlOe/izrB70Jof72aM=\ngolang.org/x/sync v0.0.0-20190227155943-e225da77a7e6/go.mod h1:RxMgew5VJxzue5/jJTE5uejpjVlOe/izrB70Jof72aM=\ngolang.org/x/sync v0.0.0-20190423024810-112230192c58/go.mod h1:RxMgew5VJxzue5/jJTE5uejpjVlOe/izrB70Jof72aM=\ngolang.org/x/sync v0.0.0-20190911185100-cd5d95a43a6e/go.mod h1:RxMgew5VJxzue5/jJTE5uejpjVlOe/izrB70Jof72aM=\ngolang.org/x/sync v0.0.0-20200317015054-43a5402ce75a/go.mod h1:RxMgew5VJxzue5/jJTE5uejpjVlOe/izrB70Jof72aM=\ngolang.org/x/sync v0.0.0-20200625203802-6e8e738ad208/go.mod h1:RxMgew5VJxzue5/jJTE5uejpjVlOe/izrB70Jof72aM=\ngolang.org/x/sync v0.0.0-20201207232520-09787c993a3a/go.mod h1:RxMgew5VJxzue5/jJTE5uejpjVlOe/izrB70Jof72aM=\ngolang.org/x/sys v0.0.0-20180830151530-49385e6e1522/go.mod h1:STP8DvDyc/dI5b8T5hshtkjS+E42TnysNCUPdjciGhY=\ngolang.org/x/sys v0.0.0-20180905080454-ebe1bf3edb33/go.mod h1:STP8DvDyc/dI5b8T5hshtkjS+E42TnysNCUPdjciGhY=\ngolang.org/x/sys v0.0.0-20181116152217-5ac8a444bdc5/go.mod h1:STP8DvDyc/dI5b8T5hshtkjS+E42TnysNCUPdjciGhY=\ngolang.org/x/sys v0.0.0-20190215142949-d0b11bdaac8a/go.mod h1:STP8DvDyc/dI5b8T5hshtkjS+E42TnysNCUPdjciGhY=\ngolang.org/x/sys v0.0.0-20190312061237-fead79001313/go.mod h1:h1NjWce9XRLGQEsW7wpKNCjG9DtNlClVuFLEZdDNbEs=\ngolang.org/x/sys v0.0.0-20190412213103-97732733099d/go.mod h1:h1NjWce9XRLGQEsW7wpKNCjG9DtNlClVuFLEZdDNbEs=\ngolang.org/x/sys v0.0.0-20190422165155-953cdadca894/go.mod h1:h1NjWce9XRLGQEsW7wpKNCjG9DtNlClVuFLEZdDNbEs=\ngolang.org/x/sys v0.0.0-20190502145724-3ef323f4f1fd/go.mod h1:h1NjWce9XRLGQEsW7wpKNCjG9DtNlClVuFLEZdDNbEs=\ngolang.org/x/sys v0.0.0-20190507160741-ecd444e8653b/go.mod h1:h1NjWce9XRLGQEsW7wpKNCjG9DtNlClVuFLEZdDNbEs=\ngolang.org/x/sys v0.0.0-20190606165138-5da285871e9c/go.mod h1:h1NjWce9XRLGQEsW7wpKNCjG9DtNlClVuFLEZdDNbEs=\ngolang.org/x/sys v0.0.0-20190624142023-c5567b49c5d0/go.mod h1:h1NjWce9XRLGQEsW7wpKNCjG9DtNlClVuFLEZdDNbEs=\ngolang.org/x/sys v0.0.0-20190726091711-fc99dfbffb4e/go.mod h1:h1NjWce9XRLGQEsW7wpKNCjG9DtNlClVuFLEZdDNbEs=\ngolang.org/x/sys v0.0.0-20191001151750-bb3f8db39f24/go.mod h1:h1NjWce9XRLGQEsW7wpKNCjG9DtNlClVuFLEZdDNbEs=\ngolang.org/x/sys v0.0.0-20191204072324-ce4227a45e2e/go.mod h1:h1NjWce9XRLGQEsW7wpKNCjG9DtNlClVuFLEZdDNbEs=\ngolang.org/x/sys v0.0.0-20191228213918-04cbcbbfeed8/go.mod h1:h1NjWce9XRLGQEsW7wpKNCjG9DtNlClVuFLEZdDNbEs=\ngolang.org/x/sys v0.0.0-20200106162015-b016eb3dc98e/go.mod h1:h1NjWce9XRLGQEsW7wpKNCjG9DtNlClVuFLEZdDNbEs=\ngolang.org/x/sys v0.0.0-20200113162924-86b910548bc1/go.mod h1:h1NjWce9XRLGQEsW7wpKNCjG9DtNlClVuFLEZdDNbEs=\ngolang.org/x/sys v0.0.0-20200122134326-e047566fdf82/go.mod h1:h1NjWce9XRLGQEsW7wpKNCjG9DtNlClVuFLEZdDNbEs=\ngolang.org/x/sys v0.0.0-20200202164722-d101bd2416d5/go.mod h1:h1NjWce9XRLGQEsW7wpKNCjG9DtNlClVuFLEZdDNbEs=\ngolang.org/x/sys v0.0.0-20200212091648-12a6c2dcc1e4/go.mod h1:h1NjWce9XRLGQEsW7wpKNCjG9DtNlClVuFLEZdDNbEs=\ngolang.org/x/sys v0.0.0-20200223170610-d5e6a3e2c0ae/go.mod h1:h1NjWce9XRLGQEsW7wpKNCjG9DtNlClVuFLEZdDNbEs=\ngolang.org/x/sys v0.0.0-20200302150141-5c8b2ff67527/go.mod h1:h1NjWce9XRLGQEsW7wpKNCjG9DtNlClVuFLEZdDNbEs=\ngolang.org/x/sys v0.0.0-20200323222414-85ca7c5b95cd/go.mod h1:h1NjWce9XRLGQEsW7wpKNCjG9DtNlClVuFLEZdDNbEs=\ngolang.org/x/sys v0.0.0-20200331124033-c3d80250170d/go.mod h1:h1NjWce9XRLGQEsW7wpKNCjG9DtNlClVuFLEZdDNbEs=\ngolang.org/x/sys v0.0.0-20200501052902-10377860bb8e/go.mod h1:h1NjWce9XRLGQEsW7wpKNCjG9DtNlClVuFLEZdDNbEs=\ngolang.org/x/sys v0.0.0-20200511232937-7e40ca221e25/go.mod h1:h1NjWce9XRLGQEsW7wpKNCjG9DtNlClVuFLEZdDNbEs=\ngolang.org/x/sys v0.0.0-20200515095857-1151b9dac4a9/go.mod h1:h1NjWce9XRLGQEsW7wpKNCjG9DtNlClVuFLEZdDNbEs=\ngolang.org/x/sys v0.0.0-20200523222454-059865788121/go.mod h1:h1NjWce9XRLGQEsW7wpKNCjG9DtNlClVuFLEZdDNbEs=\ngolang.org/x/sys v0.0.0-20200615200032-f1bc736245b1/go.mod h1:h1NjWce9XRLGQEsW7wpKNCjG9DtNlClVuFLEZdDNbEs=\ngolang.org/x/sys v0.0.0-20200625212154-ddb9806d33ae/go.mod h1:h1NjWce9XRLGQEsW7wpKNCjG9DtNlClVuFLEZdDNbEs=\ngolang.org/x/sys v0.0.0-20200803210538-64077c9b5642/go.mod h1:h1NjWce9XRLGQEsW7wpKNCjG9DtNlClVuFLEZdDNbEs=\ngolang.org/x/sys v0.0.0-20201119102817-f84b799fce68/go.mod h1:h1NjWce9XRLGQEsW7wpKNCjG9DtNlClVuFLEZdDNbEs=\ngolang.org/x/sys v0.0.0-20210124154548-22da62e12c0c/go.mod h1:h1NjWce9XRLGQEsW7wpKNCjG9DtNlClVuFLEZdDNbEs=\ngolang.org/x/sys v0.0.0-20210423082822-04245dca01da/go.mod h1:h1NjWce9XRLGQEsW7wpKNCjG9DtNlClVuFLEZdDNbEs=\ngolang.org/x/sys v0.0.0-20210603081109-ebe580a85c40/go.mod h1:oPkhp1MJrh7nUepCBck5+mAzfO9JrbApNNgaTdGDITg=\ngolang.org/x/sys v0.0.0-20210615035016-665e8c7367d1/go.mod h1:oPkhp1MJrh7nUepCBck5+mAzfO9JrbApNNgaTdGDITg=\ngolang.org/x/sys v0.0.0-20211216021012-1d35b9e2eb4e/go.mod h1:oPkhp1MJrh7nUepCBck5+mAzfO9JrbApNNgaTdGDITg=\ngolang.org/x/sys v0.0.0-20220114195835-da31bd327af9/go.mod h1:oPkhp1MJrh7nUepCBck5+mAzfO9JrbApNNgaTdGDITg=\ngolang.org/x/sys v0.0.0-20220520151302-bc2c85ada10a h1:dGzPydgVsqGcTRVwiLJ1jVbufYwmzD3LfVPLKsKg+0k=\ngolang.org/x/sys v0.0.0-20220520151302-bc2c85ada10a/go.mod h1:oPkhp1MJrh7nUepCBck5+mAzfO9JrbApNNgaTdGDITg=\ngolang.org/x/term v0.0.0-20201126162022-7de9c90e9dd1/go.mod h1:bj7SfCRtBDWHUb9snDiAeCFNEtKQo2Wmx5Cou7ajbmo=\ngolang.org/x/term v0.0.0-20210927222741-03fcf44c2211/go.mod h1:jbD1KX2456YbFQfuXm/mYQcufACuNUgVhRMnK/tPxf8=\ngolang.org/x/text v0.0.0-20170915032832-14c0d48ead0c/go.mod h1:NqM8EUOU14njkJ3fqMW+pc6Ldnwhi/IjpwHt7yyuwOQ=\ngolang.org/x/text v0.3.0/go.mod h1:NqM8EUOU14njkJ3fqMW+pc6Ldnwhi/IjpwHt7yyuwOQ=\ngolang.org/x/text v0.3.1-0.20180807135948-17ff2d5776d2/go.mod h1:NqM8EUOU14njkJ3fqMW+pc6Ldnwhi/IjpwHt7yyuwOQ=\ngolang.org/x/text v0.3.2/go.mod h1:bEr9sfX3Q8Zfm5fL9x+3itogRgK3+ptLWKqgva+5dAk=\ngolang.org/x/text v0.3.3/go.mod h1:5Zoc/QRtKVWzQhOtBMvqHzDpF6irO9z98xDceosuGiQ=\ngolang.org/x/text v0.3.6/go.mod h1:5Zoc/QRtKVWzQhOtBMvqHzDpF6irO9z98xDceosuGiQ=\ngolang.org/x/text v0.3.7/go.mod h1:u+2+/6zg+i71rQMx5EYifcz6MCKuco9NR6JIITiCfzQ=\ngolang.org/x/time v0.0.0-20181108054448-85acf8d2951c/go.mod h1:tRJNPiyCQ0inRvYxbN9jk5I+vvW/OXSQhTDSoE431IQ=\ngolang.org/x/time v0.0.0-20190308202827-9d24e82272b4/go.mod h1:tRJNPiyCQ0inRvYxbN9jk5I+vvW/OXSQhTDSoE431IQ=\ngolang.org/x/time v0.0.0-20191024005414-555d28b269f0/go.mod h1:tRJNPiyCQ0inRvYxbN9jk5I+vvW/OXSQhTDSoE431IQ=\ngolang.org/x/tools v0.0.0-20180917221912-90fa682c2a6e/go.mod h1:n7NCudcB/nEzxVGmLbDWY5pfWTLqBcC2KZ6jyYvM4mQ=\ngolang.org/x/tools v0.0.0-20190114222345-bf090417da8b/go.mod h1:n7NCudcB/nEzxVGmLbDWY5pfWTLqBcC2KZ6jyYvM4mQ=\ngolang.org/x/tools v0.0.0-20190226205152-f727befe758c/go.mod h1:9Yl7xja0Znq3iFh3HoIrodX9oNMXvdceNzlUR8zjMvY=\ngolang.org/x/tools v0.0.0-20190311212946-11955173bddd/go.mod h1:LCzVGOaR6xXOjkQ3onu1FJEFr0SW1gC7cKk1uF8kGRs=\ngolang.org/x/tools v0.0.0-20190312151545-0bb0c0a6e846/go.mod h1:LCzVGOaR6xXOjkQ3onu1FJEFr0SW1gC7cKk1uF8kGRs=\ngolang.org/x/tools v0.0.0-20190312170243-e65039ee4138/go.mod h1:LCzVGOaR6xXOjkQ3onu1FJEFr0SW1gC7cKk1uF8kGRs=\ngolang.org/x/tools v0.0.0-20190425150028-36563e24a262/go.mod h1:RgjU9mgBXZiqYHBnxXauZ1Gv1EHHAz9KjViQ78xBX0Q=\ngolang.org/x/tools v0.0.0-20190506145303-2d16b83fe98c/go.mod h1:RgjU9mgBXZiqYHBnxXauZ1Gv1EHHAz9KjViQ78xBX0Q=\ngolang.org/x/tools v0.0.0-20190524140312-2c0ae7006135/go.mod h1:RgjU9mgBXZiqYHBnxXauZ1Gv1EHHAz9KjViQ78xBX0Q=\ngolang.org/x/tools v0.0.0-20190606124116-d0a3d012864b/go.mod h1:/rFqwRUd4F7ZHNgwSSTFct+R/Kf4OFW1sUzUTQQTgfc=\ngolang.org/x/tools v0.0.0-20190621195816-6e04913cbbac/go.mod h1:/rFqwRUd4F7ZHNgwSSTFct+R/Kf4OFW1sUzUTQQTgfc=\ngolang.org/x/tools v0.0.0-20190628153133-6cdbf07be9d0/go.mod h1:/rFqwRUd4F7ZHNgwSSTFct+R/Kf4OFW1sUzUTQQTgfc=\ngolang.org/x/tools v0.0.0-20190816200558-6889da9d5479/go.mod h1:b+2E5dAYhXwXZwtnZ6UAqBI28+e2cm9otk0dWdXHAEo=\ngolang.org/x/tools v0.0.0-20190911174233-4f2ddba30aff/go.mod h1:b+2E5dAYhXwXZwtnZ6UAqBI28+e2cm9otk0dWdXHAEo=\ngolang.org/x/tools v0.0.0-20191012152004-8de300cfc20a/go.mod h1:b+2E5dAYhXwXZwtnZ6UAqBI28+e2cm9otk0dWdXHAEo=\ngolang.org/x/tools v0.0.0-20191113191852-77e3bb0ad9e7/go.mod h1:b+2E5dAYhXwXZwtnZ6UAqBI28+e2cm9otk0dWdXHAEo=\ngolang.org/x/tools v0.0.0-20191115202509-3a792d9c32b2/go.mod h1:b+2E5dAYhXwXZwtnZ6UAqBI28+e2cm9otk0dWdXHAEo=\ngolang.org/x/tools v0.0.0-20191119224855-298f0cb1881e/go.mod h1:b+2E5dAYhXwXZwtnZ6UAqBI28+e2cm9otk0dWdXHAEo=\ngolang.org/x/tools v0.0.0-20191125144606-a911d9008d1f/go.mod h1:b+2E5dAYhXwXZwtnZ6UAqBI28+e2cm9otk0dWdXHAEo=\ngolang.org/x/tools v0.0.0-20191130070609-6e064ea0cf2d/go.mod h1:b+2E5dAYhXwXZwtnZ6UAqBI28+e2cm9otk0dWdXHAEo=\ngolang.org/x/tools v0.0.0-20191216173652-a0e659d51361/go.mod h1:TB2adYChydJhpapKDTa4BR/hXlZSLoq2Wpct/0txZ28=\ngolang.org/x/tools v0.0.0-20191227053925-7b8e75db28f4/go.mod h1:TB2adYChydJhpapKDTa4BR/hXlZSLoq2Wpct/0txZ28=\ngolang.org/x/tools v0.0.0-20200117161641-43d50277825c/go.mod h1:TB2adYChydJhpapKDTa4BR/hXlZSLoq2Wpct/0txZ28=\ngolang.org/x/tools v0.0.0-20200122220014-bf1340f18c4a/go.mod h1:TB2adYChydJhpapKDTa4BR/hXlZSLoq2Wpct/0txZ28=\ngolang.org/x/tools v0.0.0-20200130002326-2f3ba24bd6e7/go.mod h1:TB2adYChydJhpapKDTa4BR/hXlZSLoq2Wpct/0txZ28=\ngolang.org/x/tools v0.0.0-20200204074204-1cc6d1ef6c74/go.mod h1:TB2adYChydJhpapKDTa4BR/hXlZSLoq2Wpct/0txZ28=\ngolang.org/x/tools v0.0.0-20200207183749-b753a1ba74fa/go.mod h1:TB2adYChydJhpapKDTa4BR/hXlZSLoq2Wpct/0txZ28=\ngolang.org/x/tools v0.0.0-20200212150539-ea181f53ac56/go.mod h1:TB2adYChydJhpapKDTa4BR/hXlZSLoq2Wpct/0txZ28=\ngolang.org/x/tools v0.0.0-20200224181240-023911ca70b2/go.mod h1:TB2adYChydJhpapKDTa4BR/hXlZSLoq2Wpct/0txZ28=\ngolang.org/x/tools v0.0.0-20200227222343-706bc42d1f0d/go.mod h1:TB2adYChydJhpapKDTa4BR/hXlZSLoq2Wpct/0txZ28=\ngolang.org/x/tools v0.0.0-20200304193943-95d2e580d8eb/go.mod h1:o4KQGtdN14AW+yjsvvwRTJJuXz8XRtIHtEnmAXLyFUw=\ngolang.org/x/tools v0.0.0-20200312045724-11d5b4c81c7d/go.mod h1:o4KQGtdN14AW+yjsvvwRTJJuXz8XRtIHtEnmAXLyFUw=\ngolang.org/x/tools v0.0.0-20200331025713-a30bf2db82d4/go.mod h1:Sl4aGygMT6LrqrWclx+PTx3U+LnKx/seiNR+3G19Ar8=\ngolang.org/x/tools v0.0.0-20200501065659-ab2804fb9c9d/go.mod h1:EkVYQZoAsY45+roYkvgYkIh4xh/qjgUK9TdY2XT94GE=\ngolang.org/x/tools v0.0.0-20200512131952-2bc93b1c0c88/go.mod h1:EkVYQZoAsY45+roYkvgYkIh4xh/qjgUK9TdY2XT94GE=\ngolang.org/x/tools v0.0.0-20200515010526-7d3b6ebf133d/go.mod h1:EkVYQZoAsY45+roYkvgYkIh4xh/qjgUK9TdY2XT94GE=\ngolang.org/x/tools v0.0.0-20200618134242-20370b0cb4b2/go.mod h1:EkVYQZoAsY45+roYkvgYkIh4xh/qjgUK9TdY2XT94GE=\ngolang.org/x/tools v0.0.0-20200729194436-6467de6f59a7/go.mod h1:njjCfa9FT2d7l9Bc6FUM5FLjQPp3cFF28FI3qnDFljA=\ngolang.org/x/tools v0.0.0-20200804011535-6c149bb5ef0d/go.mod h1:njjCfa9FT2d7l9Bc6FUM5FLjQPp3cFF28FI3qnDFljA=\ngolang.org/x/tools v0.0.0-20200825202427-b303f430e36d/go.mod h1:njjCfa9FT2d7l9Bc6FUM5FLjQPp3cFF28FI3qnDFljA=\ngolang.org/x/xerrors v0.0.0-20190717185122-a985d3407aa7/go.mod h1:I/5z698sn9Ka8TeJc9MKroUUfqBBauWjQqLJ2OPfmY0=\ngolang.org/x/xerrors v0.0.0-20191011141410-1b5146add898/go.mod h1:I/5z698sn9Ka8TeJc9MKroUUfqBBauWjQqLJ2OPfmY0=\ngolang.org/x/xerrors v0.0.0-20191204190536-9bdfabe68543/go.mod h1:I/5z698sn9Ka8TeJc9MKroUUfqBBauWjQqLJ2OPfmY0=\ngolang.org/x/xerrors v0.0.0-20200804184101-5ec99f83aff1/go.mod h1:I/5z698sn9Ka8TeJc9MKroUUfqBBauWjQqLJ2OPfmY0=\ngoogle.golang.org/api v0.4.0/go.mod h1:8k5glujaEP+g9n7WNsDg8QP6cUVNI86fCNMcbazEtwE=\ngoogle.golang.org/api v0.7.0/go.mod h1:WtwebWUNSVBH/HAw79HIFXZNqEvBhG+Ra+ax0hx3E3M=\ngoogle.golang.org/api v0.8.0/go.mod h1:o4eAsZoiT+ibD93RtjEohWalFOjRDx6CVaqeizhEnKg=\ngoogle.golang.org/api v0.9.0/go.mod h1:o4eAsZoiT+ibD93RtjEohWalFOjRDx6CVaqeizhEnKg=\ngoogle.golang.org/api v0.13.0/go.mod h1:iLdEw5Ide6rF15KTC1Kkl0iskquN2gFfn9o9XIsbkAI=\ngoogle.golang.org/api v0.14.0/go.mod h1:iLdEw5Ide6rF15KTC1Kkl0iskquN2gFfn9o9XIsbkAI=\ngoogle.golang.org/api v0.15.0/go.mod h1:iLdEw5Ide6rF15KTC1Kkl0iskquN2gFfn9o9XIsbkAI=\ngoogle.golang.org/api v0.17.0/go.mod h1:BwFmGc8tA3vsd7r/7kR8DY7iEEGSU04BFxCo5jP/sfE=\ngoogle.golang.org/api v0.18.0/go.mod h1:BwFmGc8tA3vsd7r/7kR8DY7iEEGSU04BFxCo5jP/sfE=\ngoogle.golang.org/api v0.19.0/go.mod h1:BwFmGc8tA3vsd7r/7kR8DY7iEEGSU04BFxCo5jP/sfE=\ngoogle.golang.org/api v0.20.0/go.mod h1:BwFmGc8tA3vsd7r/7kR8DY7iEEGSU04BFxCo5jP/sfE=\ngoogle.golang.org/api v0.22.0/go.mod h1:BwFmGc8tA3vsd7r/7kR8DY7iEEGSU04BFxCo5jP/sfE=\ngoogle.golang.org/api v0.24.0/go.mod h1:lIXQywCXRcnZPGlsd8NbLnOjtAoL6em04bJ9+z0MncE=\ngoogle.golang.org/api v0.28.0/go.mod h1:lIXQywCXRcnZPGlsd8NbLnOjtAoL6em04bJ9+z0MncE=\ngoogle.golang.org/api v0.29.0/go.mod h1:Lcubydp8VUV7KeIHD9z2Bys/sm/vGKnG1UHuDBSrHWM=\ngoogle.golang.org/api v0.30.0/go.mod h1:QGmEvQ87FHZNiUVJkT14jQNYJ4ZJjdRF23ZXz5138Fc=\ngoogle.golang.org/appengine v1.1.0/go.mod h1:EbEs0AVv82hx2wNQdGPgUI5lhzA/G0D9YwlJXL52JkM=\ngoogle.golang.org/appengine v1.4.0/go.mod h1:xpcJRLb0r/rnEns0DIKYYv+WjYCduHsrkT7/EB5XEv4=\ngoogle.golang.org/appengine v1.5.0/go.mod h1:xpcJRLb0r/rnEns0DIKYYv+WjYCduHsrkT7/EB5XEv4=\ngoogle.golang.org/appengine v1.6.1/go.mod h1:i06prIuMbXzDqacNJfV5OdTW448YApPu5ww/cMBSeb0=\ngoogle.golang.org/appengine v1.6.5/go.mod h1:8WjMMxjGQR8xUklV/ARdw2HLXBOI7O7uCIDZVag1xfc=\ngoogle.golang.org/appengine v1.6.6/go.mod h1:8WjMMxjGQR8xUklV/ARdw2HLXBOI7O7uCIDZVag1xfc=\ngoogle.golang.org/genproto v0.0.0-20180817151627-c66870c02cf8/go.mod h1:JiN7NxoALGmiZfu7CAH4rXhgtRTLTxftemlI0sWmxmc=\ngoogle.golang.org/genproto v0.0.0-20190307195333-5fe7a883aa19/go.mod h1:VzzqZJRnGkLBvHegQrXjBqPurQTc5/KpmUdxsrq26oE=\ngoogle.golang.org/genproto v0.0.0-20190418145605-e7d98fc518a7/go.mod h1:VzzqZJRnGkLBvHegQrXjBqPurQTc5/KpmUdxsrq26oE=\ngoogle.golang.org/genproto v0.0.0-20190425155659-357c62f0e4bb/go.mod h1:VzzqZJRnGkLBvHegQrXjBqPurQTc5/KpmUdxsrq26oE=\ngoogle.golang.org/genproto v0.0.0-20190502173448-54afdca5d873/go.mod h1:VzzqZJRnGkLBvHegQrXjBqPurQTc5/KpmUdxsrq26oE=\ngoogle.golang.org/genproto v0.0.0-20190801165951-fa694d86fc64/go.mod h1:DMBHOl98Agz4BDEuKkezgsaosCRResVns1a3J2ZsMNc=\ngoogle.golang.org/genproto v0.0.0-20190819201941-24fa4b261c55/go.mod h1:DMBHOl98Agz4BDEuKkezgsaosCRResVns1a3J2ZsMNc=\ngoogle.golang.org/genproto v0.0.0-20190911173649-1774047e7e51/go.mod h1:IbNlFCBrqXvoKpeg0TB2l7cyZUmoaFKYIwrEpbDKLA8=\ngoogle.golang.org/genproto v0.0.0-20191108220845-16a3f7862a1a/go.mod h1:n3cpQtvxv34hfy77yVDNjmbRyujviMdxYliBSkLhpCc=\ngoogle.golang.org/genproto v0.0.0-20191115194625-c23dd37a84c9/go.mod h1:n3cpQtvxv34hfy77yVDNjmbRyujviMdxYliBSkLhpCc=\ngoogle.golang.org/genproto v0.0.0-20191216164720-4f79533eabd1/go.mod h1:n3cpQtvxv34hfy77yVDNjmbRyujviMdxYliBSkLhpCc=\ngoogle.golang.org/genproto v0.0.0-20191230161307-f3c370f40bfb/go.mod h1:n3cpQtvxv34hfy77yVDNjmbRyujviMdxYliBSkLhpCc=\ngoogle.golang.org/genproto v0.0.0-20200115191322-ca5a22157cba/go.mod h1:n3cpQtvxv34hfy77yVDNjmbRyujviMdxYliBSkLhpCc=\ngoogle.golang.org/genproto v0.0.0-20200122232147-0452cf42e150/go.mod h1:n3cpQtvxv34hfy77yVDNjmbRyujviMdxYliBSkLhpCc=\ngoogle.golang.org/genproto v0.0.0-20200204135345-fa8e72b47b90/go.mod h1:GmwEX6Z4W5gMy59cAlVYjN9JhxgbQH6Gn+gFDQe2lzA=\ngoogle.golang.org/genproto v0.0.0-20200212174721-66ed5ce911ce/go.mod h1:55QSHmfGQM9UVYDPBsyGGes0y52j32PQ3BqQfXhyH3c=\ngoogle.golang.org/genproto v0.0.0-20200224152610-e50cd9704f63/go.mod h1:55QSHmfGQM9UVYDPBsyGGes0y52j32PQ3BqQfXhyH3c=\ngoogle.golang.org/genproto v0.0.0-20200228133532-8c2c7df3a383/go.mod h1:55QSHmfGQM9UVYDPBsyGGes0y52j32PQ3BqQfXhyH3c=\ngoogle.golang.org/genproto v0.0.0-20200305110556-506484158171/go.mod h1:55QSHmfGQM9UVYDPBsyGGes0y52j32PQ3BqQfXhyH3c=\ngoogle.golang.org/genproto v0.0.0-20200312145019-da6875a35672/go.mod h1:55QSHmfGQM9UVYDPBsyGGes0y52j32PQ3BqQfXhyH3c=\ngoogle.golang.org/genproto v0.0.0-20200331122359-1ee6d9798940/go.mod h1:55QSHmfGQM9UVYDPBsyGGes0y52j32PQ3BqQfXhyH3c=\ngoogle.golang.org/genproto v0.0.0-20200430143042-b979b6f78d84/go.mod h1:55QSHmfGQM9UVYDPBsyGGes0y52j32PQ3BqQfXhyH3c=\ngoogle.golang.org/genproto v0.0.0-20200511104702-f5ebc3bea380/go.mod h1:55QSHmfGQM9UVYDPBsyGGes0y52j32PQ3BqQfXhyH3c=\ngoogle.golang.org/genproto v0.0.0-20200515170657-fc4c6c6a6587/go.mod h1:YsZOwe1myG/8QRHRsmBRE1LrgQY60beZKjly0O1fX9U=\ngoogle.golang.org/genproto v0.0.0-20200526211855-cb27e3aa2013/go.mod h1:NbSheEEYHJ7i3ixzK3sjbqSGDJWnxyFXZblF3eUsNvo=\ngoogle.golang.org/genproto v0.0.0-20200618031413-b414f8b61790/go.mod h1:jDfRM7FcilCzHH/e9qn6dsT145K34l5v+OpcnNgKAAA=\ngoogle.golang.org/genproto v0.0.0-20200729003335-053ba62fc06f/go.mod h1:FWY/as6DDZQgahTzZj3fqbO1CbirC29ZNUFHwi0/+no=\ngoogle.golang.org/genproto v0.0.0-20200804131852-c06518451d9c/go.mod h1:FWY/as6DDZQgahTzZj3fqbO1CbirC29ZNUFHwi0/+no=\ngoogle.golang.org/genproto v0.0.0-20200825200019-8632dd797987/go.mod h1:FWY/as6DDZQgahTzZj3fqbO1CbirC29ZNUFHwi0/+no=\ngoogle.golang.org/grpc v1.19.0/go.mod h1:mqu4LbDTu4XGKhr4mRzUsmM4RtVoemTSY81AxZiDr8c=\ngoogle.golang.org/grpc v1.20.1/go.mod h1:10oTOabMzJvdu6/UiuZezV6QK5dSlG84ov/aaiqXj38=\ngoogle.golang.org/grpc v1.21.1/go.mod h1:oYelfM1adQP15Ek0mdvEgi9Df8B9CZIaU1084ijfRaM=\ngoogle.golang.org/grpc v1.23.0/go.mod h1:Y5yQAOtifL1yxbo5wqy6BxZv8vAUGQwXBOALyacEbxg=\ngoogle.golang.org/grpc v1.25.1/go.mod h1:c3i+UQWmh7LiEpx4sFZnkU36qjEYZ0imhYfXVyQciAY=\ngoogle.golang.org/grpc v1.26.0/go.mod h1:qbnxyOmOxrQa7FizSgH+ReBfzJrCY1pSN7KXBS8abTk=\ngoogle.golang.org/grpc v1.27.0/go.mod h1:qbnxyOmOxrQa7FizSgH+ReBfzJrCY1pSN7KXBS8abTk=\ngoogle.golang.org/grpc v1.27.1/go.mod h1:qbnxyOmOxrQa7FizSgH+ReBfzJrCY1pSN7KXBS8abTk=\ngoogle.golang.org/grpc v1.28.0/go.mod h1:rpkK4SK4GF4Ach/+MFLZUBavHOvF2JJB5uozKKal+60=\ngoogle.golang.org/grpc v1.29.1/go.mod h1:itym6AZVZYACWQqET3MqgPpjcuV5QH3BxFS3IjizoKk=\ngoogle.golang.org/grpc v1.30.0/go.mod h1:N36X2cJ7JwdamYAgDz+s+rVMFjt3numwzf/HckM8pak=\ngoogle.golang.org/grpc v1.31.0/go.mod h1:N36X2cJ7JwdamYAgDz+s+rVMFjt3numwzf/HckM8pak=\ngoogle.golang.org/protobuf v0.0.0-20200109180630-ec00e32a8dfd/go.mod h1:DFci5gLYBciE7Vtevhsrf46CRTquxDuWsQurQQe4oz8=\ngoogle.golang.org/protobuf v0.0.0-20200221191635-4d8936d0db64/go.mod h1:kwYJMbMJ01Woi6D6+Kah6886xMZcty6N08ah7+eCXa0=\ngoogle.golang.org/protobuf v0.0.0-20200228230310-ab0ca4ff8a60/go.mod h1:cfTl7dwQJ+fmap5saPgwCLgHXTUD7jkjRqWcaiX5VyM=\ngoogle.golang.org/protobuf v1.20.1-0.20200309200217-e05f789c0967/go.mod h1:A+miEFZTKqfCUM6K7xSMQL9OKL/b6hQv+e19PK+JZNE=\ngoogle.golang.org/protobuf v1.21.0/go.mod h1:47Nbq4nVaFHyn7ilMalzfO3qCViNmqZ2kzikPIcrTAo=\ngoogle.golang.org/protobuf v1.22.0/go.mod h1:EGpADcykh3NcUnDUJcl1+ZksZNG86OlYog2l/sGQquU=\ngoogle.golang.org/protobuf v1.23.0/go.mod h1:EGpADcykh3NcUnDUJcl1+ZksZNG86OlYog2l/sGQquU=\ngoogle.golang.org/protobuf v1.23.1-0.20200526195155-81db48ad09cc/go.mod h1:EGpADcykh3NcUnDUJcl1+ZksZNG86OlYog2l/sGQquU=\ngoogle.golang.org/protobuf v1.24.0/go.mod h1:r/3tXBNzIEhYS9I1OUVjXDlt8tc493IdKGjtUeSXeh4=\ngoogle.golang.org/protobuf v1.25.0/go.mod h1:9JNX74DMeImyA3h4bdi1ymwjUzf21/xIlbajtzgsN7c=\ngoogle.golang.org/protobuf v1.26.0-rc.1/go.mod h1:jlhhOSvTdKEhbULTjvd4ARK9grFBp09yW+WbY/TyQbw=\ngoogle.golang.org/protobuf v1.26.0/go.mod h1:9q0QmTI4eRPtz6boOQmLYwt+qCgq0jsYwAQnmE0givc=\ngoogle.golang.org/protobuf v1.33.0 h1:uNO2rsAINq/JlFpSdYEKIZ0uKD/R9cpdv0T+yoGwGmI=\ngoogle.golang.org/protobuf v1.33.0/go.mod h1:c6P6GXX6sHbq/GpV6MGZEdwhWPcYBgnhAHhKbcUYpos=\ngopkg.in/alecthomas/kingpin.v2 v2.2.6/go.mod h1:FMv+mEhP44yOT+4EoQTLFTRgOQ1FBLkstjWtayDeSgw=\ngopkg.in/check.v1 v0.0.0-20161208181325-20d25e280405/go.mod h1:Co6ibVJAznAaIkqp8huTwlJQCZ016jof/cbN4VW5Yz0=\ngopkg.in/check.v1 v1.0.0-20180628173108-788fd7840127/go.mod h1:Co6ibVJAznAaIkqp8huTwlJQCZ016jof/cbN4VW5Yz0=\ngopkg.in/check.v1 v1.0.0-20190902080502-41f04d3bba15/go.mod h1:Co6ibVJAznAaIkqp8huTwlJQCZ016jof/cbN4VW5Yz0=\ngopkg.in/errgo.v2 v2.1.0/go.mod h1:hNsd1EY+bozCKY1Ytp96fpM3vjJbqLJn88ws8XvfDNI=\ngopkg.in/yaml.v2 v2.2.1/go.mod h1:hI93XBmqTisBFMUTm0b8Fm+jr3Dg1NNxqwp+5A1VGuI=\ngopkg.in/yaml.v2 v2.2.2/go.mod h1:hI93XBmqTisBFMUTm0b8Fm+jr3Dg1NNxqwp+5A1VGuI=\ngopkg.in/yaml.v2 v2.2.4/go.mod h1:hI93XBmqTisBFMUTm0b8Fm+jr3Dg1NNxqwp+5A1VGuI=\ngopkg.in/yaml.v2 v2.2.5/go.mod h1:hI93XBmqTisBFMUTm0b8Fm+jr3Dg1NNxqwp+5A1VGuI=\ngopkg.in/yaml.v2 v2.3.0/go.mod h1:hI93XBmqTisBFMUTm0b8Fm+jr3Dg1NNxqwp+5A1VGuI=\ngopkg.in/yaml.v2 v2.4.0/go.mod h1:RDklbk79AGWmwhnvt/jBztapEOGDOx6ZbXqjP6csGnQ=\ngopkg.in/yaml.v3 v3.0.1 h1:fxVm/GzAzEWqLHuvctI91KS9hhNmmWOoWu0XTYJS7CA=\ngopkg.in/yaml.v3 v3.0.1/go.mod h1:K4uyk7z7BCEPqu6E+C64Yfv1cQ7kz7rIZviUmN+EgEM=\nhonnef.co/go/tools v0.0.0-20190102054323-c2f93a96b099/go.mod h1:rf3lG4BRIbNafJWhAfAdb/ePZxsR/4RtNHQocxwk9r4=\nhonnef.co/go/tools v0.0.0-20190106161140-3f1c8253044a/go.mod h1:rf3lG4BRIbNafJWhAfAdb/ePZxsR/4RtNHQocxwk9r4=\nhonnef.co/go/tools v0.0.0-20190418001031-e561f6794a2a/go.mod h1:rf3lG4BRIbNafJWhAfAdb/ePZxsR/4RtNHQocxwk9r4=\nhonnef.co/go/tools v0.0.0-20190523083050-ea95bdfd59fc/go.mod h1:rf3lG4BRIbNafJWhAfAdb/ePZxsR/4RtNHQocxwk9r4=\nhonnef.co/go/tools v0.0.1-2019.2.3/go.mod h1:a3bituU0lyd329TUQxRnasdCoJDkEUEAqEt0JzvZhAg=\nhonnef.co/go/tools v0.0.1-2020.1.3/go.mod h1:X/FiERA/W4tHapMX5mGpAtMSVEeEUOyHaw9vFzvIQ3k=\nhonnef.co/go/tools v0.0.1-2020.1.4/go.mod h1:X/FiERA/W4tHapMX5mGpAtMSVEeEUOyHaw9vFzvIQ3k=\nrsc.io/binaryregexp v0.2.0/go.mod h1:qTv7/COck+e2FymRvadv62gMdZztPaShugOCi3I+8D8=\nrsc.io/quote/v3 v3.1.0/go.mod h1:yEA65RcK8LyAZtP9Kv3t0HmxON59tX3rD+tICJqUlj0=\nrsc.io/sampler v1.3.0/go.mod h1:T1hPZKmBbMNahiBKFy5HrXp6adAjACjK9JXDnKaTXpA=\n"
        },
        {
          "name": "main.go",
          "type": "blob",
          "size": 95.5888671875,
          "content": "/*\nCopyright 2014 The Kubernetes Authors All rights reserved.\n\nLicensed under the Apache License, Version 2.0 (the \"License\");\nyou may not use this file except in compliance with the License.\nYou may obtain a copy of the License at\n\n    http://www.apache.org/licenses/LICENSE-2.0\n\nUnless required by applicable law or agreed to in writing, software\ndistributed under the License is distributed on an \"AS IS\" BASIS,\nWITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\nSee the License for the specific language governing permissions and\nlimitations under the License.\n*/\n\n// git-sync is a command that pulls a git repository to a local directory.\n\npackage main // import \"k8s.io/git-sync/cmd/git-sync\"\n\nimport (\n\t\"context\"\n\t\"crypto/md5\"\n\t\"encoding/json\"\n\t\"errors\"\n\t\"fmt\"\n\t\"io\"\n\t\"io/fs\"\n\t\"net\"\n\t\"net/http\"\n\t\"net/http/pprof\"\n\t\"net/url\"\n\t\"os\"\n\t\"os/exec\"\n\t\"os/signal\"\n\t\"os/user\"\n\t\"path/filepath\"\n\t\"strconv\"\n\t\"strings\"\n\t\"sync\"\n\t\"syscall\"\n\t\"time\"\n\n\t\"github.com/golang-jwt/jwt/v4\"\n\t\"github.com/prometheus/client_golang/prometheus\"\n\t\"github.com/prometheus/client_golang/prometheus/promhttp\"\n\t\"github.com/spf13/pflag\"\n\t\"golang.org/x/sys/unix\"\n\t\"k8s.io/git-sync/pkg/cmd\"\n\t\"k8s.io/git-sync/pkg/hook\"\n\t\"k8s.io/git-sync/pkg/logging\"\n\t\"k8s.io/git-sync/pkg/pid1\"\n\t\"k8s.io/git-sync/pkg/version\"\n)\n\nvar (\n\tmetricSyncDuration = prometheus.NewSummaryVec(prometheus.SummaryOpts{\n\t\tName: \"git_sync_duration_seconds\",\n\t\tHelp: \"Summary of git_sync durations\",\n\t}, []string{\"status\"})\n\n\tmetricSyncCount = prometheus.NewCounterVec(prometheus.CounterOpts{\n\t\tName: \"git_sync_count_total\",\n\t\tHelp: \"How many git syncs completed, partitioned by state (success, error, noop)\",\n\t}, []string{\"status\"})\n\n\tmetricFetchCount = prometheus.NewCounter(prometheus.CounterOpts{\n\t\tName: \"git_fetch_count_total\",\n\t\tHelp: \"How many git fetches were run\",\n\t})\n\n\tmetricAskpassCount = prometheus.NewCounterVec(prometheus.CounterOpts{\n\t\tName: \"git_sync_askpass_calls\",\n\t\tHelp: \"How many git askpass calls completed, partitioned by state (success, error)\",\n\t}, []string{\"status\"})\n\n\tmetricRefreshGitHubAppTokenCount = prometheus.NewCounterVec(prometheus.CounterOpts{\n\t\tName: \"git_sync_refresh_github_app_token_count\",\n\t\tHelp: \"How many times the GitHub app token was refreshed, partitioned by state (success, error)\",\n\t}, []string{\"status\"})\n)\n\nfunc init() {\n\tprometheus.MustRegister(metricSyncDuration)\n\tprometheus.MustRegister(metricSyncCount)\n\tprometheus.MustRegister(metricFetchCount)\n\tprometheus.MustRegister(metricAskpassCount)\n\tprometheus.MustRegister(metricRefreshGitHubAppTokenCount)\n}\n\nconst (\n\tmetricKeySuccess = \"success\"\n\tmetricKeyError   = \"error\"\n\tmetricKeyNoOp    = \"noop\"\n)\n\ntype submodulesMode string\n\nconst (\n\tsubmodulesRecursive submodulesMode = \"recursive\"\n\tsubmodulesShallow   submodulesMode = \"shallow\"\n\tsubmodulesOff       submodulesMode = \"off\"\n)\n\ntype gcMode string\n\nconst (\n\tgcAuto       = \"auto\"\n\tgcAlways     = \"always\"\n\tgcAggressive = \"aggressive\"\n\tgcOff        = \"off\"\n)\n\nconst defaultDirMode = os.FileMode(0775) // subject to umask\n\n// repoSync represents the remote repo and the local sync of it.\ntype repoSync struct {\n\tcmd            string         // the git command to run\n\troot           absPath        // absolute path to the root directory\n\trepo           string         // remote repo to sync\n\tref            string         // the ref to sync\n\tdepth          int            // for shallow sync\n\tsubmodules     submodulesMode // how to handle submodules\n\tgc             gcMode         // garbage collection\n\tlink           absPath        // absolute path to the symlink to publish\n\tauthURL        string         // a URL to re-fetch credentials, or \"\"\n\tsparseFile     string         // path to a sparse-checkout file\n\tsyncCount      int            // how many times have we synced?\n\tlog            *logging.Logger\n\trun            cmd.Runner\n\tstaleTimeout   time.Duration // time for worktrees to be cleaned up\n\tappTokenExpiry time.Time     // time when github app auth token expires\n}\n\nfunc main() {\n\t// In case we come up as pid 1, act as init.\n\tif os.Getpid() == 1 {\n\t\tfmt.Fprintf(os.Stderr, \"INFO: detected pid 1, running init handler\\n\")\n\t\tcode, err := pid1.ReRun()\n\t\tif err == nil {\n\t\t\tos.Exit(code)\n\t\t}\n\t\tfmt.Fprintf(os.Stderr, \"FATAL: unhandled pid1 error: %v\\n\", err)\n\t\tos.Exit(127)\n\t}\n\n\t//\n\t// Declare flags inside main() so they are not used as global variables.\n\t//\n\n\tflVersion := pflag.Bool(\"version\", false, \"print the version and exit\")\n\tflHelp := pflag.BoolP(\"help\", \"h\", false, \"print help text and exit\")\n\tpflag.BoolVarP(flHelp, \"__?\", \"?\", false, \"\") // support -? as an alias to -h\n\tmustMarkHidden(\"__?\")\n\tflManual := pflag.Bool(\"man\", false, \"print the full manual and exit\")\n\n\tflVerbose := pflag.IntP(\"verbose\", \"v\",\n\t\tenvInt(0, \"GITSYNC_VERBOSE\"),\n\t\t\"logs at this V level and lower will be printed\")\n\n\tflRepo := pflag.String(\"repo\",\n\t\tenvString(\"\", \"GITSYNC_REPO\", \"GIT_SYNC_REPO\"),\n\t\t\"the git repository to sync (required)\")\n\tflRef := pflag.String(\"ref\",\n\t\tenvString(\"HEAD\", \"GITSYNC_REF\"),\n\t\t\"the git revision (branch, tag, or hash) to sync\")\n\tflDepth := pflag.Int(\"depth\",\n\t\tenvInt(1, \"GITSYNC_DEPTH\", \"GIT_SYNC_DEPTH\"),\n\t\t\"create a shallow clone with history truncated to the specified number of commits\")\n\tflSubmodules := pflag.String(\"submodules\",\n\t\tenvString(\"recursive\", \"GITSYNC_SUBMODULES\", \"GIT_SYNC_SUBMODULES\"),\n\t\t\"git submodule behavior: one of 'recursive', 'shallow', or 'off'\")\n\tflSparseCheckoutFile := pflag.String(\"sparse-checkout-file\",\n\t\tenvString(\"\", \"GITSYNC_SPARSE_CHECKOUT_FILE\", \"GIT_SYNC_SPARSE_CHECKOUT_FILE\"),\n\t\t\"the path to a sparse-checkout file\")\n\n\tflRoot := pflag.String(\"root\",\n\t\tenvString(\"\", \"GITSYNC_ROOT\", \"GIT_SYNC_ROOT\"),\n\t\t\"the root directory for git-sync operations (required)\")\n\tflLink := pflag.String(\"link\",\n\t\tenvString(\"\", \"GITSYNC_LINK\", \"GIT_SYNC_LINK\"),\n\t\t\"the path (absolute or relative to --root) at which to create a symlink to the directory holding the checked-out files (defaults to the leaf dir of --repo)\")\n\tflErrorFile := pflag.String(\"error-file\",\n\t\tenvString(\"\", \"GITSYNC_ERROR_FILE\", \"GIT_SYNC_ERROR_FILE\"),\n\t\t\"the path (absolute or relative to --root) to an optional file into which errors will be written (defaults to disabled)\")\n\tflPeriod := pflag.Duration(\"period\",\n\t\tenvDuration(10*time.Second, \"GITSYNC_PERIOD\", \"GIT_SYNC_PERIOD\"),\n\t\t\"how long to wait between syncs, must be >= 10ms; --wait overrides this\")\n\tflSyncTimeout := pflag.Duration(\"sync-timeout\",\n\t\tenvDuration(120*time.Second, \"GITSYNC_SYNC_TIMEOUT\", \"GIT_SYNC_SYNC_TIMEOUT\"),\n\t\t\"the total time allowed for one complete sync, must be >= 10ms; --timeout overrides this\")\n\tflOneTime := pflag.Bool(\"one-time\",\n\t\tenvBool(false, \"GITSYNC_ONE_TIME\", \"GIT_SYNC_ONE_TIME\"),\n\t\t\"exit after the first sync\")\n\tflSyncOnSignal := pflag.String(\"sync-on-signal\",\n\t\tenvString(\"\", \"GITSYNC_SYNC_ON_SIGNAL\", \"GIT_SYNC_SYNC_ON_SIGNAL\"),\n\t\t\"sync on receipt of the specified signal (e.g. SIGHUP)\")\n\tflMaxFailures := pflag.Int(\"max-failures\",\n\t\tenvInt(0, \"GITSYNC_MAX_FAILURES\", \"GIT_SYNC_MAX_FAILURES\"),\n\t\t\"the number of consecutive failures allowed before aborting (-1 will retry forever\")\n\tflTouchFile := pflag.String(\"touch-file\",\n\t\tenvString(\"\", \"GITSYNC_TOUCH_FILE\", \"GIT_SYNC_TOUCH_FILE\"),\n\t\t\"the path (absolute or relative to --root) to an optional file which will be touched whenever a sync completes (defaults to disabled)\")\n\tflAddUser := pflag.Bool(\"add-user\",\n\t\tenvBool(false, \"GITSYNC_ADD_USER\", \"GIT_SYNC_ADD_USER\"),\n\t\t\"add a record to /etc/passwd for the current UID/GID (needed to use SSH with an arbitrary UID)\")\n\tflGroupWrite := pflag.Bool(\"group-write\",\n\t\tenvBool(false, \"GITSYNC_GROUP_WRITE\", \"GIT_SYNC_GROUP_WRITE\"),\n\t\t\"ensure that all data (repo, worktrees, etc.) is group writable\")\n\tflStaleWorktreeTimeout := pflag.Duration(\"stale-worktree-timeout\", envDuration(0, \"GITSYNC_STALE_WORKTREE_TIMEOUT\"),\n\t\t\"how long to retain non-current worktrees\")\n\n\tflExechookCommand := pflag.String(\"exechook-command\",\n\t\tenvString(\"\", \"GITSYNC_EXECHOOK_COMMAND\", \"GIT_SYNC_EXECHOOK_COMMAND\"),\n\t\t\"an optional command to be run when syncs complete (must be idempotent)\")\n\tflExechookTimeout := pflag.Duration(\"exechook-timeout\",\n\t\tenvDuration(30*time.Second, \"GITSYNC_EXECHOOK_TIMEOUT\", \"GIT_SYNC_EXECHOOK_TIMEOUT\"),\n\t\t\"the timeout for the exechook\")\n\tflExechookBackoff := pflag.Duration(\"exechook-backoff\",\n\t\tenvDuration(3*time.Second, \"GITSYNC_EXECHOOK_BACKOFF\", \"GIT_SYNC_EXECHOOK_BACKOFF\"),\n\t\t\"the time to wait before retrying a failed exechook\")\n\n\tflWebhookURL := pflag.String(\"webhook-url\",\n\t\tenvString(\"\", \"GITSYNC_WEBHOOK_URL\", \"GIT_SYNC_WEBHOOK_URL\"),\n\t\t\"a URL for optional webhook notifications when syncs complete (must be idempotent)\")\n\tflWebhookMethod := pflag.String(\"webhook-method\",\n\t\tenvString(\"POST\", \"GITSYNC_WEBHOOK_METHOD\", \"GIT_SYNC_WEBHOOK_METHOD\"),\n\t\t\"the HTTP method for the webhook\")\n\tflWebhookStatusSuccess := pflag.Int(\"webhook-success-status\",\n\t\tenvInt(200, \"GITSYNC_WEBHOOK_SUCCESS_STATUS\", \"GIT_SYNC_WEBHOOK_SUCCESS_STATUS\"),\n\t\t\"the HTTP status code indicating a successful webhook (0 disables success checks\")\n\tflWebhookTimeout := pflag.Duration(\"webhook-timeout\",\n\t\tenvDuration(1*time.Second, \"GITSYNC_WEBHOOK_TIMEOUT\", \"GIT_SYNC_WEBHOOK_TIMEOUT\"),\n\t\t\"the timeout for the webhook\")\n\tflWebhookBackoff := pflag.Duration(\"webhook-backoff\",\n\t\tenvDuration(3*time.Second, \"GITSYNC_WEBHOOK_BACKOFF\", \"GIT_SYNC_WEBHOOK_BACKOFF\"),\n\t\t\"the time to wait before retrying a failed webhook\")\n\n\tflUsername := pflag.String(\"username\",\n\t\tenvString(\"\", \"GITSYNC_USERNAME\", \"GIT_SYNC_USERNAME\"),\n\t\t\"the username to use for git auth\")\n\tflPassword := envFlagString(\"GITSYNC_PASSWORD\", \"\",\n\t\t\"the password or personal access token to use for git auth\",\n\t\t\"GIT_SYNC_PASSWORD\")\n\tflPasswordFile := pflag.String(\"password-file\",\n\t\tenvString(\"\", \"GITSYNC_PASSWORD_FILE\", \"GIT_SYNC_PASSWORD_FILE\"),\n\t\t\"the file from which the password or personal access token for git auth will be sourced\")\n\tflCredentials := pflagCredentialSlice(\"credential\", envString(\"\", \"GITSYNC_CREDENTIAL\"), \"one or more credentials (see --man for details) available for authentication\")\n\n\tflSSHKeyFiles := pflag.StringArray(\"ssh-key-file\",\n\t\tenvStringArray(\"/etc/git-secret/ssh\", \"GITSYNC_SSH_KEY_FILE\", \"GIT_SYNC_SSH_KEY_FILE\", \"GIT_SSH_KEY_FILE\"),\n\t\t\"the SSH key(s) to use\")\n\tflSSHKnownHosts := pflag.Bool(\"ssh-known-hosts\",\n\t\tenvBool(true, \"GITSYNC_SSH_KNOWN_HOSTS\", \"GIT_SYNC_KNOWN_HOSTS\", \"GIT_KNOWN_HOSTS\"),\n\t\t\"enable SSH known_hosts verification\")\n\tflSSHKnownHostsFile := pflag.String(\"ssh-known-hosts-file\",\n\t\tenvString(\"/etc/git-secret/known_hosts\", \"GITSYNC_SSH_KNOWN_HOSTS_FILE\", \"GIT_SYNC_SSH_KNOWN_HOSTS_FILE\", \"GIT_SSH_KNOWN_HOSTS_FILE\"),\n\t\t\"the known_hosts file to use\")\n\n\tflCookieFile := pflag.Bool(\"cookie-file\",\n\t\tenvBool(false, \"GITSYNC_COOKIE_FILE\", \"GIT_SYNC_COOKIE_FILE\", \"GIT_COOKIE_FILE\"),\n\t\t\"use a git cookiefile (/etc/git-secret/cookie_file) for authentication\")\n\n\tflAskPassURL := pflag.String(\"askpass-url\",\n\t\tenvString(\"\", \"GITSYNC_ASKPASS_URL\", \"GIT_SYNC_ASKPASS_URL\", \"GIT_ASKPASS_URL\"),\n\t\t\"a URL to query for git credentials (username=<value> and password=<value>)\")\n\n\tflGithubBaseURL := pflag.String(\"github-base-url\",\n\t\tenvString(\"https://api.github.com/\", \"GITSYNC_GITHUB_BASE_URL\"),\n\t\t\"the GitHub base URL to use when making requests to GitHub when using GitHub app auth\")\n\tflGithubAppPrivateKey := envFlagString(\"GITSYNC_GITHUB_APP_PRIVATE_KEY\", \"\",\n\t\t\"the private key to use for GitHub app auth\")\n\tflGithubAppPrivateKeyFile := pflag.String(\"github-app-private-key-file\",\n\t\tenvString(\"\", \"GITSYNC_GITHUB_APP_PRIVATE_KEY_FILE\"),\n\t\t\"the file from which the private key for GitHub app auth will be sourced\")\n\tflGithubAppClientID := pflag.String(\"github-app-client-id\",\n\t\tenvString(\"\", \"GITSYNC_GITHUB_APP_CLIENT_ID\"),\n\t\t\"the GitHub app client ID to use for GitHub app auth\")\n\tflGithubAppApplicationID := pflag.Int(\"github-app-application-id\",\n\t\tenvInt(0, \"GITSYNC_GITHUB_APP_APPLICATION_ID\"),\n\t\t\"the GitHub app application ID to use for GitHub app auth\")\n\tflGithubAppInstallationID := pflag.Int(\"github-app-installation-id\",\n\t\tenvInt(0, \"GITSYNC_GITHUB_APP_INSTALLATION_ID\"),\n\t\t\"the GitHub app installation ID to use for GitHub app auth\")\n\n\tflGitCmd := pflag.String(\"git\",\n\t\tenvString(\"git\", \"GITSYNC_GIT\", \"GIT_SYNC_GIT\"),\n\t\t\"the git command to run (subject to PATH search, mostly for testing)\")\n\tflGitConfig := pflag.String(\"git-config\",\n\t\tenvString(\"\", \"GITSYNC_GIT_CONFIG\", \"GIT_SYNC_GIT_CONFIG\"),\n\t\t\"additional git config options in 'section.var1:val1,\\\"section.sub.var2\\\":\\\"val2\\\"' format\")\n\tflGitGC := pflag.String(\"git-gc\",\n\t\tenvString(\"always\", \"GITSYNC_GIT_GC\", \"GIT_SYNC_GIT_GC\"),\n\t\t\"git garbage collection behavior: one of 'auto', 'always', 'aggressive', or 'off'\")\n\n\tflHTTPBind := pflag.String(\"http-bind\",\n\t\tenvString(\"\", \"GITSYNC_HTTP_BIND\", \"GIT_SYNC_HTTP_BIND\"),\n\t\t\"the bind address (including port) for git-sync's HTTP endpoint\")\n\tflHTTPMetrics := pflag.Bool(\"http-metrics\",\n\t\tenvBool(false, \"GITSYNC_HTTP_METRICS\", \"GIT_SYNC_HTTP_METRICS\"),\n\t\t\"enable metrics on git-sync's HTTP endpoint\")\n\tflHTTPprof := pflag.Bool(\"http-pprof\",\n\t\tenvBool(false, \"GITSYNC_HTTP_PPROF\", \"GIT_SYNC_HTTP_PPROF\"),\n\t\t\"enable the pprof debug endpoints on git-sync's HTTP endpoint\")\n\n\t// Obsolete flags, kept for compat.\n\tflDeprecatedBranch := pflag.String(\"branch\", envString(\"\", \"GIT_SYNC_BRANCH\"),\n\t\t\"DEPRECATED: use --ref instead\")\n\tmustMarkDeprecated(\"branch\", \"use --ref instead\")\n\n\tflDeprecatedChmod := pflag.Int(\"change-permissions\", envInt(0, \"GIT_SYNC_PERMISSIONS\"),\n\t\t\"DEPRECATED: use --group-write instead\")\n\tmustMarkDeprecated(\"change-permissions\", \"use --group-write instead\")\n\n\tflDeprecatedDest := pflag.String(\"dest\", envString(\"\", \"GIT_SYNC_DEST\"),\n\t\t\"DEPRECATED: use --link instead\")\n\tmustMarkDeprecated(\"dest\", \"use --link instead\")\n\n\tflDeprecatedMaxSyncFailures := pflag.Int(\"max-sync-failures\", envInt(0, \"GIT_SYNC_MAX_SYNC_FAILURES\"),\n\t\t\"DEPRECATED: use --max-failures instead\")\n\tmustMarkDeprecated(\"max-sync-failures\", \"use --max-failures instead\")\n\n\tflDeprecatedPassword := pflag.String(\"password\", \"\", // the env vars are not deprecated\n\t\t\"DEPRECATED: use --password-file or $GITSYNC_PASSWORD instead\")\n\tmustMarkDeprecated(\"password\", \"use --password-file or $GITSYNC_PASSWORD instead\")\n\n\tflDeprecatedRev := pflag.String(\"rev\", envString(\"\", \"GIT_SYNC_REV\"),\n\t\t\"DEPRECATED: use --ref instead\")\n\tmustMarkDeprecated(\"rev\", \"use --ref instead\")\n\n\t_ = pflag.Bool(\"ssh\", false,\n\t\t\"DEPRECATED: this flag is no longer necessary\")\n\tmustMarkDeprecated(\"ssh\", \"no longer necessary\")\n\n\tflDeprecatedSyncHookCommand := pflag.String(\"sync-hook-command\", envString(\"\", \"GIT_SYNC_HOOK_COMMAND\"),\n\t\t\"DEPRECATED: use --exechook-command instead\")\n\tmustMarkDeprecated(\"sync-hook-command\", \"use --exechook-command instead\")\n\n\tflDeprecatedTimeout := pflag.Int(\"timeout\", envInt(0, \"GIT_SYNC_TIMEOUT\"),\n\t\t\"DEPRECATED: use --sync-timeout instead\")\n\tmustMarkDeprecated(\"timeout\", \"use --sync-timeout instead\")\n\n\tflDeprecatedV := pflag.Int(\"v\", -1,\n\t\t\"DEPRECATED: use -v or --verbose instead\")\n\tmustMarkDeprecated(\"v\", \"use -v or --verbose instead\")\n\n\tflDeprecatedWait := pflag.Float64(\"wait\", envFloat(0, \"GIT_SYNC_WAIT\"),\n\t\t\"DEPRECATED: use --period instead\")\n\tmustMarkDeprecated(\"wait\", \"use --period instead\")\n\n\t// For whatever reason pflag hardcodes stderr for the \"usage\" line when\n\t// using the default FlagSet.  We tweak the output a bit anyway.\n\tusage := func(out io.Writer, msg string) {\n\t\t// When pflag parsing hits an error, it prints a message before and\n\t\t// after the usage, which makes for nice reading.\n\t\tif msg != \"\" {\n\t\t\tfmt.Fprintln(out, msg)\n\t\t}\n\t\tfmt.Fprintf(out, \"Usage: %s [FLAGS...]\\n\", filepath.Base(os.Args[0]))\n\t\tfmt.Fprintln(out, \"\")\n\t\tfmt.Fprintln(out, \" FLAGS:\")\n\t\tpflag.CommandLine.SetOutput(out)\n\t\tpflag.PrintDefaults()\n\t\tfmt.Fprintln(out, \"\")\n\t\tfmt.Fprintln(out, \" ENVIRONMENT VARIABLES:\")\n\t\tprintEnvFlags(out)\n\t\tif msg != \"\" {\n\t\t\tfmt.Fprintln(out, msg)\n\t\t}\n\t}\n\tpflag.Usage = func() { usage(os.Stderr, \"\") }\n\n\t//\n\t// Parse and verify flags.  Errors here are fatal.\n\t//\n\n\tpflag.Parse()\n\n\t// Handle print-and-exit cases.\n\tif *flVersion {\n\t\tfmt.Println(version.VERSION)\n\t\tos.Exit(0)\n\t}\n\tif *flHelp {\n\t\tusage(os.Stdout, \"\")\n\t\tos.Exit(0)\n\t}\n\tif *flManual {\n\t\tprintManPage()\n\t\tos.Exit(0)\n\t}\n\n\t// Make sure we have a root dir in which to work.\n\tif *flRoot == \"\" {\n\t\tusage(os.Stderr, \"required flag: --root must be specified\")\n\t\tos.Exit(1)\n\t}\n\tvar absRoot absPath\n\tif abs, err := absPath(*flRoot).Canonical(); err != nil {\n\t\tfmt.Fprintf(os.Stderr, \"FATAL: can't absolutize --root: %v\\n\", err)\n\t\tos.Exit(1)\n\t} else {\n\t\tabsRoot = abs\n\t}\n\n\t// Init logging very early, so most errors can be written to a file.\n\tif *flDeprecatedV >= 0 {\n\t\t// Back-compat\n\t\t*flVerbose = *flDeprecatedV\n\t}\n\tlog := func() *logging.Logger {\n\t\tdir, file := makeAbsPath(*flErrorFile, absRoot).Split()\n\t\treturn logging.New(dir.String(), file, *flVerbose)\n\t}()\n\tcmdRunner := cmd.NewRunner(log)\n\n\tif *flRepo == \"\" {\n\t\tfatalConfigError(log, true, \"required flag: --repo must be specified\")\n\t}\n\n\tswitch {\n\tcase *flDeprecatedBranch != \"\" && (*flDeprecatedRev == \"\" || *flDeprecatedRev == \"HEAD\"):\n\t\t// Back-compat\n\t\tlog.V(0).Info(\"setting --ref from deprecated --branch\")\n\t\t*flRef = *flDeprecatedBranch\n\tcase *flDeprecatedRev != \"\" && *flDeprecatedBranch == \"\":\n\t\t// Back-compat\n\t\tlog.V(0).Info(\"setting --ref from deprecated --rev\")\n\t\t*flRef = *flDeprecatedRev\n\tcase *flDeprecatedBranch != \"\" && *flDeprecatedRev != \"\":\n\t\tfatalConfigError(log, true, \"deprecated flag combo: can't set --ref from deprecated --branch and --rev (one or the other is OK)\")\n\t}\n\n\tif *flRef == \"\" {\n\t\tfatalConfigError(log, true, \"required flag: --ref must be specified\")\n\t}\n\n\tif *flDepth < 0 { // 0 means \"no limit\"\n\t\tfatalConfigError(log, true, \"invalid flag: --depth must be greater than or equal to 0\")\n\t}\n\n\tswitch submodulesMode(*flSubmodules) {\n\tcase submodulesRecursive, submodulesShallow, submodulesOff:\n\tdefault:\n\t\tfatalConfigError(log, true, \"invalid flag: --submodules must be one of %q, %q, or %q\", submodulesRecursive, submodulesShallow, submodulesOff)\n\t}\n\n\tswitch *flGitGC {\n\tcase gcAuto, gcAlways, gcAggressive, gcOff:\n\tdefault:\n\t\tfatalConfigError(log, true, \"invalid flag: --git-gc must be one of %q, %q, %q, or %q\", gcAuto, gcAlways, gcAggressive, gcOff)\n\t}\n\n\tif *flDeprecatedDest != \"\" {\n\t\t// Back-compat\n\t\tlog.V(0).Info(\"setting --link from deprecated --dest\")\n\t\t*flLink = *flDeprecatedDest\n\t}\n\tif *flLink == \"\" {\n\t\tparts := strings.Split(strings.Trim(*flRepo, \"/\"), \"/\")\n\t\t*flLink = parts[len(parts)-1]\n\t}\n\n\tif *flDeprecatedWait != 0 {\n\t\t// Back-compat\n\t\tlog.V(0).Info(\"setting --period from deprecated --wait\")\n\t\t*flPeriod = time.Duration(int(*flDeprecatedWait*1000)) * time.Millisecond\n\t}\n\tif *flPeriod < 10*time.Millisecond {\n\t\tfatalConfigError(log, true, \"invalid flag: --period must be at least 10ms\")\n\t}\n\n\tif *flDeprecatedChmod != 0 {\n\t\tfatalConfigError(log, true, \"deprecated flag: --change-permissions is no longer supported\")\n\t}\n\n\tvar syncSig syscall.Signal\n\tif *flSyncOnSignal != \"\" {\n\t\tif num, err := strconv.ParseInt(*flSyncOnSignal, 0, 0); err == nil {\n\t\t\t// sync-on-signal value is a number\n\t\t\tsyncSig = syscall.Signal(num)\n\t\t} else {\n\t\t\t// sync-on-signal value is a name\n\t\t\tsyncSig = unix.SignalNum(*flSyncOnSignal)\n\t\t\tif syncSig == 0 {\n\t\t\t\t// last resort - maybe they said \"HUP\", meaning \"SIGHUP\"\n\t\t\t\tsyncSig = unix.SignalNum(\"SIG\" + *flSyncOnSignal)\n\t\t\t}\n\t\t}\n\t\tif syncSig == 0 {\n\t\t\tfatalConfigError(log, true, \"invalid flag: --sync-on-signal must be a valid signal name or number\")\n\t\t}\n\t}\n\n\tif *flDeprecatedTimeout != 0 {\n\t\t// Back-compat\n\t\tlog.V(0).Info(\"setting --sync-timeout from deprecated --timeout\")\n\t\t*flSyncTimeout = time.Duration(*flDeprecatedTimeout) * time.Second\n\t}\n\tif *flSyncTimeout < 10*time.Millisecond {\n\t\tfatalConfigError(log, true, \"invalid flag: --sync-timeout must be at least 10ms\")\n\t}\n\n\tif *flDeprecatedMaxSyncFailures != 0 {\n\t\t// Back-compat\n\t\tlog.V(0).Info(\"setting --max-failures from deprecated --max-sync-failures\")\n\t\t*flMaxFailures = *flDeprecatedMaxSyncFailures\n\t}\n\n\tif *flDeprecatedSyncHookCommand != \"\" {\n\t\t// Back-compat\n\t\tlog.V(0).Info(\"setting --exechook-command from deprecated --sync-hook-command\")\n\t\t*flExechookCommand = *flDeprecatedSyncHookCommand\n\t}\n\tif *flExechookCommand != \"\" {\n\t\tif *flExechookTimeout < time.Second {\n\t\t\tfatalConfigError(log, true, \"invalid flag: --exechook-timeout must be at least 1s\")\n\t\t}\n\t\tif *flExechookBackoff < time.Second {\n\t\t\tfatalConfigError(log, true, \"invalid flag: --exechook-backoff must be at least 1s\")\n\t\t}\n\t}\n\n\tif *flWebhookURL != \"\" {\n\t\tif *flWebhookStatusSuccess == -1 {\n\t\t\t// Back-compat: -1 and 0 mean the same things\n\t\t\t*flWebhookStatusSuccess = 0\n\t\t}\n\t\tif *flWebhookStatusSuccess < 0 {\n\t\t\tfatalConfigError(log, true, \"invalid flag: --webhook-success-status must be a valid HTTP code or 0\")\n\t\t}\n\t\tif *flWebhookTimeout < time.Second {\n\t\t\tfatalConfigError(log, true, \"invalid flag: --webhook-timeout must be at least 1s\")\n\t\t}\n\t\tif *flWebhookBackoff < time.Second {\n\t\t\tfatalConfigError(log, true, \"invalid flag: --webhook-backoff must be at least 1s\")\n\t\t}\n\t}\n\n\tif *flDeprecatedPassword != \"\" {\n\t\tlog.V(0).Info(\"setting $GITSYNC_PASSWORD from deprecated --password\")\n\t\t*flPassword = *flDeprecatedPassword\n\t}\n\tif *flUsername != \"\" {\n\t\tif *flPassword == \"\" && *flPasswordFile == \"\" {\n\t\t\tfatalConfigError(log, true, \"required flag: $GITSYNC_PASSWORD or --password-file must be specified when --username is specified\")\n\t\t}\n\t\tif *flPassword != \"\" && *flPasswordFile != \"\" {\n\t\t\tfatalConfigError(log, true, \"invalid flag: only one of $GITSYNC_PASSWORD and --password-file may be specified\")\n\t\t}\n\t\tif u, err := url.Parse(*flRepo); err == nil { // it may not even parse as a URL, that's OK\n\t\t\tif u.User != nil {\n\t\t\t\tfatalConfigError(log, true, \"invalid flag: credentials may not be specified in --repo when --username is specified\")\n\t\t\t}\n\t\t}\n\t} else {\n\t\tif *flPassword != \"\" {\n\t\t\tfatalConfigError(log, true, \"invalid flag: $GITSYNC_PASSWORD may only be specified when --username is specified\")\n\t\t}\n\t\tif *flPasswordFile != \"\" {\n\t\t\tfatalConfigError(log, true, \"invalid flag: --password-file may only be specified when --username is specified\")\n\t\t}\n\t}\n\n\tif *flGithubAppApplicationID != 0 || *flGithubAppClientID != \"\" {\n\t\tif *flGithubAppApplicationID != 0 && *flGithubAppClientID != \"\" {\n\t\t\tfatalConfigError(log, true, \"invalid flag: only one of --github-app-application-id or --github-app-client-id may be specified\")\n\t\t}\n\t\tif *flGithubAppInstallationID == 0 {\n\t\t\tfatalConfigError(log, true, \"invalid flag: --github-app-installation-id must be specified when --github-app-application-id or --github-app-client-id are specified\")\n\t\t}\n\t\tif *flGithubAppPrivateKey == \"\" && *flGithubAppPrivateKeyFile == \"\" {\n\t\t\tfatalConfigError(log, true, \"invalid flag: $GITSYNC_GITHUB_APP_PRIVATE_KEY or --github-app-private-key-file must be specified when --github-app-application-id or --github-app-client-id are specified\")\n\t\t}\n\t\tif *flGithubAppPrivateKey != \"\" && *flGithubAppPrivateKeyFile != \"\" {\n\t\t\tfatalConfigError(log, true, \"invalid flag: only one of $GITSYNC_GITHUB_APP_PRIVATE_KEY or --github-app-private-key-file may be specified\")\n\t\t}\n\t\tif *flUsername != \"\" {\n\t\t\tfatalConfigError(log, true, \"invalid flag: --username may not be specified when --github-app-private-key-file is specified\")\n\t\t}\n\t\tif *flPassword != \"\" {\n\t\t\tfatalConfigError(log, true, \"invalid flag: --password may not be specified when --github-app-private-key-file is specified\")\n\t\t}\n\t\tif *flPasswordFile != \"\" {\n\t\t\tfatalConfigError(log, true, \"invalid flag: --password-file may not be specified when --github-app-private-key-file is specified\")\n\t\t}\n\t} else {\n\t\tif *flGithubAppApplicationID != 0 {\n\t\t\tfatalConfigError(log, true, \"invalid flag: --github-app-application-id may only be specified when --github-app-private-key-file is specified\")\n\t\t}\n\t\tif *flGithubAppInstallationID != 0 {\n\t\t\tfatalConfigError(log, true, \"invalid flag: --github-app-installation-id may only be specified when --github-app-private-key-file is specified\")\n\t\t}\n\t}\n\n\tif len(*flCredentials) > 0 {\n\t\tfor _, cred := range *flCredentials {\n\t\t\tif cred.URL == \"\" {\n\t\t\t\tfatalConfigError(log, true, \"invalid flag: --credential URL must be specified\")\n\t\t\t}\n\t\t\tif cred.Username == \"\" {\n\t\t\t\tfatalConfigError(log, true, \"invalid flag: --credential username must be specified\")\n\t\t\t}\n\t\t\tif cred.Password == \"\" && cred.PasswordFile == \"\" {\n\t\t\t\tfatalConfigError(log, true, \"invalid flag: --credential password or password-file must be specified\")\n\t\t\t}\n\t\t\tif cred.Password != \"\" && cred.PasswordFile != \"\" {\n\t\t\t\tfatalConfigError(log, true, \"invalid flag: only one of --credential password and password-file may be specified\")\n\t\t\t}\n\t\t}\n\t}\n\n\tif *flHTTPBind == \"\" {\n\t\tif *flHTTPMetrics {\n\t\t\tfatalConfigError(log, true, \"required flag: --http-bind must be specified when --http-metrics is set\")\n\t\t}\n\t\tif *flHTTPprof {\n\t\t\tfatalConfigError(log, true, \"required flag: --http-bind must be specified when --http-pprof is set\")\n\t\t}\n\t}\n\n\t//\n\t// From here on, output goes through logging.\n\t//\n\n\tlog.V(0).Info(\"starting up\",\n\t\t\"version\", version.VERSION,\n\t\t\"pid\", os.Getpid(),\n\t\t\"uid\", os.Getuid(),\n\t\t\"gid\", os.Getgid(),\n\t\t\"home\", os.Getenv(\"HOME\"),\n\t\t\"flags\", logSafeFlags(*flVerbose))\n\n\tif _, err := exec.LookPath(*flGitCmd); err != nil {\n\t\tlog.Error(err, \"FATAL: git executable not found\", \"git\", *flGitCmd)\n\t\tos.Exit(1)\n\t}\n\n\t// If the user asked for group-writable data, make sure the umask allows it.\n\tif *flGroupWrite {\n\t\tsyscall.Umask(0002)\n\t} else {\n\t\tsyscall.Umask(0022)\n\t}\n\n\t// Make sure the root exists.  defaultDirMode ensures that this is usable\n\t// as a volume when the consumer isn't running as the same UID.  We do this\n\t// very early so that we can normalize the path even when there are\n\t// symlinks in play.\n\tif err := os.MkdirAll(absRoot.String(), defaultDirMode); err != nil {\n\t\tlog.Error(err, \"FATAL: can't make root dir\", \"path\", absRoot)\n\t\tos.Exit(1)\n\t}\n\t// Get rid of symlinks in the root path to avoid getting confused about\n\t// them later.  The path must exist for EvalSymlinks to work.\n\tif delinked, err := filepath.EvalSymlinks(absRoot.String()); err != nil {\n\t\tlog.Error(err, \"FATAL: can't normalize root path\", \"path\", absRoot)\n\t\tos.Exit(1)\n\t} else {\n\t\tabsRoot = absPath(delinked)\n\t}\n\tif absRoot.String() != *flRoot {\n\t\tlog.V(0).Info(\"normalized root path\", \"root\", *flRoot, \"result\", absRoot)\n\t}\n\n\t// Convert files into an absolute paths.\n\tabsLink := makeAbsPath(*flLink, absRoot)\n\tabsTouchFile := makeAbsPath(*flTouchFile, absRoot)\n\n\t// Merge credential sources.\n\tif *flUsername == \"\" {\n\t\t// username and user@host URLs are validated as mutually exclusive\n\t\tif u, err := url.Parse(*flRepo); err == nil { // it may not even parse as a URL, that's OK\n\t\t\t// Note that `ssh://user@host/path` URLs need to retain the user\n\t\t\t// field. Out of caution, we only handle HTTP(S) URLs here.\n\t\t\tif u.User != nil && (u.Scheme == \"http\" || u.Scheme == \"https\") {\n\t\t\t\tif user := u.User.Username(); user != \"\" {\n\t\t\t\t\t*flUsername = user\n\t\t\t\t}\n\t\t\t\tif pass, found := u.User.Password(); found {\n\t\t\t\t\t*flPassword = pass\n\t\t\t\t}\n\t\t\t\tu.User = nil\n\t\t\t\t*flRepo = u.String()\n\t\t\t}\n\t\t}\n\t}\n\tif *flUsername != \"\" {\n\t\tcred := credential{\n\t\t\tURL:          *flRepo,\n\t\t\tUsername:     *flUsername,\n\t\t\tPassword:     *flPassword,\n\t\t\tPasswordFile: *flPasswordFile,\n\t\t}\n\t\t*flCredentials = append([]credential{cred}, (*flCredentials)...)\n\t}\n\n\tif *flAddUser {\n\t\tif err := addUser(); err != nil {\n\t\t\tlog.Error(err, \"FATAL: can't add user\")\n\t\t\tos.Exit(1)\n\t\t}\n\t}\n\n\t// Capture the various git parameters.\n\tgit := &repoSync{\n\t\tcmd:          *flGitCmd,\n\t\troot:         absRoot,\n\t\trepo:         *flRepo,\n\t\tref:          *flRef,\n\t\tdepth:        *flDepth,\n\t\tsubmodules:   submodulesMode(*flSubmodules),\n\t\tgc:           gcMode(*flGitGC),\n\t\tlink:         absLink,\n\t\tauthURL:      *flAskPassURL,\n\t\tsparseFile:   *flSparseCheckoutFile,\n\t\tlog:          log,\n\t\trun:          cmdRunner,\n\t\tstaleTimeout: *flStaleWorktreeTimeout,\n\t}\n\n\t// This context is used only for git credentials initialization. There are\n\t// no long-running operations like `git fetch`, so hopefully 30 seconds will be enough.\n\tctx, cancel := context.WithTimeout(context.Background(), 30*time.Second)\n\n\t// Log the git version.\n\tif ver, _, err := cmdRunner.Run(ctx, \"\", nil, *flGitCmd, \"version\"); err != nil {\n\t\tlog.Error(err, \"can't get git version\")\n\t\tos.Exit(1)\n\t} else {\n\t\tlog.V(0).Info(\"git version\", \"version\", ver)\n\t}\n\n\t// Don't pollute the user's .gitconfig if this is being run directly.\n\tif f, err := os.CreateTemp(\"\", \"git-sync.gitconfig.*\"); err != nil {\n\t\tlog.Error(err, \"FATAL: can't create gitconfig file\")\n\t\tos.Exit(1)\n\t} else {\n\t\tgitConfig := f.Name()\n\t\tf.Close()\n\t\tos.Setenv(\"GIT_CONFIG_GLOBAL\", gitConfig)\n\t\tos.Setenv(\"GIT_CONFIG_NOSYSTEM\", \"true\")\n\t\tlog.V(2).Info(\"created private gitconfig file\", \"path\", gitConfig)\n\t}\n\n\t// Set various configs we want, but users might override.\n\tif err := git.SetupDefaultGitConfigs(ctx); err != nil {\n\t\tlog.Error(err, \"can't set default git configs\")\n\t\tos.Exit(1)\n\t}\n\n\t// Finish populating credentials.\n\tfor i := range *flCredentials {\n\t\tcred := &(*flCredentials)[i]\n\t\tif cred.PasswordFile != \"\" {\n\t\t\tpasswordFileBytes, err := os.ReadFile(cred.PasswordFile)\n\t\t\tif err != nil {\n\t\t\t\tlog.Error(err, \"can't read password file\", \"file\", cred.PasswordFile)\n\t\t\t\tos.Exit(1)\n\t\t\t}\n\t\t\tcred.Password = string(passwordFileBytes)\n\t\t}\n\t}\n\n\t// If the --repo or any submodule uses SSH, we need to know which keys.\n\tif err := git.SetupGitSSH(*flSSHKnownHosts, *flSSHKeyFiles, *flSSHKnownHostsFile); err != nil {\n\t\tlog.Error(err, \"can't set up git SSH\", \"keyFiles\", *flSSHKeyFiles, \"useKnownHosts\", *flSSHKnownHosts, \"knownHostsFile\", *flSSHKnownHostsFile)\n\t\tos.Exit(1)\n\t}\n\n\tif *flCookieFile {\n\t\tif err := git.SetupCookieFile(ctx); err != nil {\n\t\t\tlog.Error(err, \"can't set up git cookie file\")\n\t\t\tos.Exit(1)\n\t\t}\n\t}\n\n\t// This needs to be after all other git-related config flags.\n\tif *flGitConfig != \"\" {\n\t\tif err := git.SetupExtraGitConfigs(ctx, *flGitConfig); err != nil {\n\t\t\tlog.Error(err, \"can't set additional git configs\", \"configs\", *flGitConfig)\n\t\t\tos.Exit(1)\n\t\t}\n\t}\n\n\t// The scope of the initialization context ends here, so we call cancel to release resources associated with it.\n\tcancel()\n\n\tif *flHTTPBind != \"\" {\n\t\tln, err := net.Listen(\"tcp\", *flHTTPBind)\n\t\tif err != nil {\n\t\t\tlog.Error(err, \"can't bind HTTP endpoint\", \"endpoint\", *flHTTPBind)\n\t\t\tos.Exit(1)\n\t\t}\n\t\tmux := http.NewServeMux()\n\t\treasons := []string{}\n\n\t\t// This is a dumb liveliness check endpoint. Currently this checks\n\t\t// nothing and will always return 200 if the process is live.\n\t\tmux.HandleFunc(\"/\", func(w http.ResponseWriter, r *http.Request) {\n\t\t\tif !getRepoReady() {\n\t\t\t\thttp.Error(w, \"repo is not ready\", http.StatusServiceUnavailable)\n\t\t\t}\n\t\t\t// Otherwise success\n\t\t})\n\t\treasons = append(reasons, \"liveness\")\n\n\t\tif *flHTTPMetrics {\n\t\t\tmux.Handle(\"/metrics\", promhttp.Handler())\n\t\t\treasons = append(reasons, \"metrics\")\n\t\t}\n\n\t\tif *flHTTPprof {\n\t\t\tmux.HandleFunc(\"/debug/pprof/\", pprof.Index)\n\t\t\tmux.HandleFunc(\"/debug/pprof/cmdline\", pprof.Cmdline)\n\t\t\tmux.HandleFunc(\"/debug/pprof/profile\", pprof.Profile)\n\t\t\tmux.HandleFunc(\"/debug/pprof/symbol\", pprof.Symbol)\n\t\t\tmux.HandleFunc(\"/debug/pprof/trace\", pprof.Trace)\n\t\t\treasons = append(reasons, \"pprof\")\n\t\t}\n\n\t\tlog.V(0).Info(\"serving HTTP\", \"endpoint\", *flHTTPBind, \"reasons\", reasons)\n\t\tgo func() {\n\t\t\terr := http.Serve(ln, mux)\n\t\t\tlog.Error(err, \"HTTP server terminated\")\n\t\t\tos.Exit(1)\n\t\t}()\n\t}\n\n\t// Startup webhooks goroutine\n\tvar webhookRunner *hook.HookRunner\n\tif *flWebhookURL != \"\" {\n\t\tlog := log.WithName(\"webhook\")\n\t\twebhook := hook.NewWebhook(\n\t\t\t*flWebhookURL,\n\t\t\t*flWebhookMethod,\n\t\t\t*flWebhookStatusSuccess,\n\t\t\t*flWebhookTimeout,\n\t\t\tlog,\n\t\t)\n\t\twebhookRunner = hook.NewHookRunner(\n\t\t\twebhook,\n\t\t\t*flWebhookBackoff,\n\t\t\thook.NewHookData(),\n\t\t\tlog,\n\t\t\t*flOneTime,\n\t\t)\n\t\tgo webhookRunner.Run(context.Background())\n\t}\n\n\t// Startup exechooks goroutine\n\tvar exechookRunner *hook.HookRunner\n\tif *flExechookCommand != \"\" {\n\t\tlog := log.WithName(\"exechook\")\n\t\texechook := hook.NewExechook(\n\t\t\tcmd.NewRunner(log),\n\t\t\t*flExechookCommand,\n\t\t\tfunc(hash string) string {\n\t\t\t\treturn git.worktreeFor(hash).Path().String()\n\t\t\t},\n\t\t\t[]string{},\n\t\t\t*flExechookTimeout,\n\t\t\tlog,\n\t\t)\n\t\texechookRunner = hook.NewHookRunner(\n\t\t\texechook,\n\t\t\t*flExechookBackoff,\n\t\t\thook.NewHookData(),\n\t\t\tlog,\n\t\t\t*flOneTime,\n\t\t)\n\t\tgo exechookRunner.Run(context.Background())\n\t}\n\n\t// Setup signal notify channel\n\tsigChan := make(chan os.Signal, 1)\n\tif syncSig != 0 {\n\t\tlog.V(1).Info(\"installing signal handler\", \"signal\", unix.SignalName(syncSig))\n\t\tsignal.Notify(sigChan, syncSig)\n\t}\n\n\t// Craft a function that can be called to refresh credentials when needed.\n\trefreshCreds := func(ctx context.Context) error {\n\t\t// These should all be mutually-exclusive configs.\n\t\tfor _, cred := range *flCredentials {\n\t\t\tif err := git.StoreCredentials(ctx, cred.URL, cred.Username, cred.Password); err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t}\n\t\tif *flAskPassURL != \"\" {\n\t\t\t// When using an auth URL, the credentials can be dynamic, and need\n\t\t\t// to be re-fetched each time.\n\t\t\tif err := git.CallAskPassURL(ctx); err != nil {\n\t\t\t\tmetricAskpassCount.WithLabelValues(metricKeyError).Inc()\n\t\t\t\treturn err\n\t\t\t}\n\t\t\tmetricAskpassCount.WithLabelValues(metricKeySuccess).Inc()\n\t\t}\n\n\t\tif (*flGithubAppPrivateKeyFile != \"\" || *flGithubAppPrivateKey != \"\") && *flGithubAppInstallationID != 0 && (*flGithubAppApplicationID != 0 || *flGithubAppClientID != \"\") {\n\t\t\tif git.appTokenExpiry.Before(time.Now().Add(30 * time.Second)) {\n\t\t\t\tif err := git.RefreshGitHubAppToken(ctx, *flGithubBaseURL, *flGithubAppPrivateKey, *flGithubAppPrivateKeyFile, *flGithubAppClientID, *flGithubAppApplicationID, *flGithubAppInstallationID); err != nil {\n\t\t\t\t\tmetricRefreshGitHubAppTokenCount.WithLabelValues(metricKeyError).Inc()\n\t\t\t\t\treturn err\n\t\t\t\t}\n\t\t\t\tmetricRefreshGitHubAppTokenCount.WithLabelValues(metricKeySuccess).Inc()\n\t\t\t}\n\t\t}\n\n\t\treturn nil\n\t}\n\n\tfailCount := 0\n\tsyncCount := uint64(0)\n\tfor {\n\t\tstart := time.Now()\n\t\tctx, cancel := context.WithTimeout(context.Background(), *flSyncTimeout)\n\n\t\tif changed, hash, err := git.SyncRepo(ctx, refreshCreds); err != nil {\n\t\t\tfailCount++\n\t\t\tupdateSyncMetrics(metricKeyError, start)\n\t\t\tif *flMaxFailures >= 0 && failCount >= *flMaxFailures {\n\t\t\t\t// Exit after too many retries, maybe the error is not recoverable.\n\t\t\t\tlog.Error(err, \"too many failures, aborting\", \"failCount\", failCount)\n\t\t\t\tos.Exit(1)\n\t\t\t}\n\t\t\tlog.Error(err, \"error syncing repo, will retry\", \"failCount\", failCount)\n\t\t} else {\n\t\t\t// this might have been called before, but also might not have\n\t\t\tsetRepoReady()\n\t\t\t// We treat the first loop as a sync, including sending hooks.\n\t\t\tif changed || syncCount == 0 {\n\t\t\t\tif absTouchFile != \"\" {\n\t\t\t\t\tif err := touch(absTouchFile); err != nil {\n\t\t\t\t\t\tlog.Error(err, \"failed to touch touch-file\", \"path\", absTouchFile)\n\t\t\t\t\t} else {\n\t\t\t\t\t\tlog.V(3).Info(\"touched touch-file\", \"path\", absTouchFile)\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tif webhookRunner != nil {\n\t\t\t\t\twebhookRunner.Send(hash)\n\t\t\t\t}\n\t\t\t\tif exechookRunner != nil {\n\t\t\t\t\texechookRunner.Send(hash)\n\t\t\t\t}\n\t\t\t\tupdateSyncMetrics(metricKeySuccess, start)\n\t\t\t} else {\n\t\t\t\tupdateSyncMetrics(metricKeyNoOp, start)\n\t\t\t}\n\t\t\tsyncCount++\n\n\t\t\t// Clean up old worktree(s) and run GC.\n\t\t\tif err := git.cleanup(ctx); err != nil {\n\t\t\t\tlog.Error(err, \"git cleanup failed\")\n\t\t\t}\n\n\t\t\t// Determine if git-sync should terminate for one of several reasons\n\t\t\tif *flOneTime {\n\t\t\t\t// Wait for hooks to complete at least once, if not nil, before\n\t\t\t\t// checking whether to stop program.\n\t\t\t\t// Assumes that if hook channels are not nil, they will have at\n\t\t\t\t// least one value before getting closed\n\t\t\t\texitCode := 0 // is 0 if all hooks succeed, else is 1\n\t\t\t\tif exechookRunner != nil {\n\t\t\t\t\tif err := exechookRunner.WaitForCompletion(); err != nil {\n\t\t\t\t\t\texitCode = 1\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tif webhookRunner != nil {\n\t\t\t\t\tif err := webhookRunner.WaitForCompletion(); err != nil {\n\t\t\t\t\t\texitCode = 1\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tlog.DeleteErrorFile()\n\t\t\t\tlog.V(0).Info(\"exiting after one sync\", \"status\", exitCode)\n\t\t\t\tos.Exit(exitCode)\n\t\t\t}\n\n\t\t\tif hash == git.ref {\n\t\t\t\tlog.V(0).Info(\"ref appears to be a git hash, no further sync needed\", \"ref\", git.ref)\n\t\t\t\tlog.DeleteErrorFile()\n\t\t\t\tsleepForever()\n\t\t\t}\n\n\t\t\tif failCount > 0 {\n\t\t\t\tlog.V(4).Info(\"resetting failure count\", \"failCount\", failCount)\n\t\t\t\tfailCount = 0\n\t\t\t}\n\t\t\tlog.DeleteErrorFile()\n\t\t}\n\n\t\tlog.V(3).Info(\"next sync\", \"waitTime\", flPeriod.String(), \"syncCount\", syncCount)\n\t\tcancel()\n\n\t\t// Sleep until the next sync. If syncSig is set then the sleep may\n\t\t// be interrupted by that signal.\n\t\tt := time.NewTimer(*flPeriod)\n\t\tselect {\n\t\tcase <-t.C:\n\t\tcase <-sigChan:\n\t\t\tlog.V(1).Info(\"caught signal\", \"signal\", unix.SignalName(syncSig))\n\t\t\tt.Stop()\n\t\t}\n\t}\n}\n\n// mustMarkDeprecated is a helper around pflag.CommandLine.MarkDeprecated.\n// It panics if there is an error (as these indicate a coding issue).\n// This makes it easier to keep the linters happy.\nfunc mustMarkDeprecated(name string, usageMessage string) {\n\terr := pflag.CommandLine.MarkDeprecated(name, usageMessage)\n\tif err != nil {\n\t\tpanic(fmt.Sprintf(\"error marking flag %q as deprecated: %v\", name, err))\n\t}\n}\n\n// mustMarkHidden is a helper around pflag.CommandLine.MarkHidden.\n// It panics if there is an error (as these indicate a coding issue).\n// This makes it easier to keep the linters happy.\nfunc mustMarkHidden(name string) {\n\terr := pflag.CommandLine.MarkHidden(name)\n\tif err != nil {\n\t\tpanic(fmt.Sprintf(\"error marking flag %q as hidden: %v\", name, err))\n\t}\n}\n\n// makeAbsPath makes an absolute path from a path which might be absolute\n// or relative.  If the path is already absolute, it will be used.  If it is\n// not absolute, it will be joined with the provided root. If the path is\n// empty, the result will be empty.\nfunc makeAbsPath(path string, root absPath) absPath {\n\tif path == \"\" {\n\t\treturn \"\"\n\t}\n\tif filepath.IsAbs(path) {\n\t\treturn absPath(path)\n\t}\n\treturn root.Join(path)\n}\n\n// touch will try to ensure that the file at the specified path exists and that\n// its timestamps are updated.\nfunc touch(path absPath) error {\n\tdir := path.Dir()\n\tif err := os.MkdirAll(dir, defaultDirMode); err != nil {\n\t\treturn err\n\t}\n\tif err := os.Chtimes(path.String(), time.Now(), time.Now()); errors.Is(err, fs.ErrNotExist) {\n\t\tfile, createErr := os.Create(path.String())\n\t\tif createErr != nil {\n\t\t\treturn createErr\n\t\t}\n\t\treturn file.Close()\n\t} else {\n\t\treturn err\n\t}\n}\n\nconst redactedString = \"REDACTED\"\n\nfunc redactURL(urlstr string) string {\n\tu, err := url.Parse(urlstr)\n\tif err != nil {\n\t\t// May be something like user@git.example.com:path/to/repo\n\t\treturn urlstr\n\t}\n\tif u.User != nil {\n\t\tif _, found := u.User.Password(); found {\n\t\t\tu.User = url.UserPassword(u.User.Username(), redactedString)\n\t\t}\n\t}\n\treturn u.String()\n}\n\n// logSafeFlags makes sure any sensitive args (e.g. passwords) are redacted\n// before logging.  This returns a slice rather than a map so it is always\n// sorted.\nfunc logSafeFlags(v int) []string {\n\tret := []string{}\n\tpflag.VisitAll(func(fl *pflag.Flag) {\n\t\t// Don't log hidden flags\n\t\tif fl.Hidden {\n\t\t\treturn\n\t\t}\n\t\t// Don't log unchanged values\n\t\tif !fl.Changed && v <= 3 {\n\t\t\treturn\n\t\t}\n\n\t\targ := fl.Name\n\t\tval := fl.Value.String()\n\n\t\t// Don't log empty, unchanged values\n\t\tif val == \"\" && !fl.Changed && v < 6 {\n\t\t\treturn\n\t\t}\n\n\t\t// Handle --password\n\t\tif arg == \"password\" {\n\t\t\tval = redactedString\n\t\t}\n\t\t// Handle password embedded in --repo\n\t\tif arg == \"repo\" {\n\t\t\tval = redactURL(val)\n\t\t}\n\t\t// Handle --credential\n\t\tif arg == \"credential\" {\n\t\t\torig := fl.Value.(*credentialSliceValue)\n\t\t\tsl := []credential{} // make a copy of the slice so we can mutate it\n\t\t\tfor _, cred := range orig.value {\n\t\t\t\tif cred.Password != \"\" {\n\t\t\t\t\tcred.Password = redactedString\n\t\t\t\t}\n\t\t\t\tsl = append(sl, cred)\n\t\t\t}\n\t\t\ttmp := *orig // make a copy\n\t\t\ttmp.value = sl\n\t\t\tval = tmp.String()\n\t\t}\n\n\t\tret = append(ret, \"--\"+arg+\"=\"+val)\n\t})\n\treturn ret\n}\n\nfunc updateSyncMetrics(key string, start time.Time) {\n\tmetricSyncDuration.WithLabelValues(key).Observe(time.Since(start).Seconds())\n\tmetricSyncCount.WithLabelValues(key).Inc()\n}\n\n// repoReady indicates that the repo has been synced.\nvar readyLock sync.Mutex\nvar repoReady = false\n\nfunc getRepoReady() bool {\n\treadyLock.Lock()\n\tdefer readyLock.Unlock()\n\treturn repoReady\n}\n\nfunc setRepoReady() {\n\treadyLock.Lock()\n\tdefer readyLock.Unlock()\n\trepoReady = true\n}\n\n// Do no work, but don't do something that triggers go's runtime into thinking\n// it is deadlocked.\nfunc sleepForever() {\n\tc := make(chan os.Signal, 1)\n\tsignal.Notify(c, os.Interrupt)\n\t<-c\n\tos.Exit(0)\n}\n\n// fatalConfigError prints the error to the standard error, prints the usage\n// if the `printUsage` flag is true, exports the error to the error file and\n// exits the process with the exit code.\nfunc fatalConfigError(log *logging.Logger, printUsage bool, format string, a ...interface{}) {\n\ts := fmt.Sprintf(format, a...)\n\tfmt.Fprintln(os.Stderr, s)\n\tif printUsage {\n\t\tpflag.Usage()\n\t\t// pflag prints flag errors both before and after usage\n\t\tfmt.Fprintln(os.Stderr, s)\n\t}\n\tlog.ExportError(s)\n\tos.Exit(1)\n}\n\n// Put the current UID/GID into /etc/passwd so SSH can look it up.  This\n// assumes that we have the permissions to write to it.\nfunc addUser() error {\n\t// Skip if the UID already exists. The Dockerfile already adds the default UID/GID.\n\tif _, err := user.LookupId(strconv.Itoa(os.Getuid())); err == nil {\n\t\treturn nil\n\t}\n\thome := os.Getenv(\"HOME\")\n\tif home == \"\" {\n\t\tcwd, err := os.Getwd()\n\t\tif err != nil {\n\t\t\treturn fmt.Errorf(\"can't get working directory and $HOME is not set: %w\", err)\n\t\t}\n\t\thome = cwd\n\t}\n\n\tf, err := os.OpenFile(\"/etc/passwd\", os.O_APPEND|os.O_WRONLY, 0644)\n\tif err != nil {\n\t\treturn err\n\t}\n\tdefer f.Close()\n\n\tstr := fmt.Sprintf(\"git-sync:x:%d:%d::%s:/sbin/nologin\\n\", os.Getuid(), os.Getgid(), home)\n\t_, err = f.WriteString(str)\n\treturn err\n}\n\n// Run runs `git` with the specified args.\nfunc (git *repoSync) Run(ctx context.Context, cwd absPath, args ...string) (string, string, error) {\n\treturn git.run.WithCallDepth(1).Run(ctx, cwd.String(), nil, git.cmd, args...)\n}\n\n// Run runs `git` with the specified args and stdin.\nfunc (git *repoSync) RunWithStdin(ctx context.Context, cwd absPath, stdin string, args ...string) (string, string, error) {\n\treturn git.run.WithCallDepth(1).RunWithStdin(ctx, cwd.String(), nil, stdin, git.cmd, args...)\n}\n\n// initRepo examines the git repo and determines if it is usable or not.  If\n// not, it will (re)initialize it.  After running this function, callers can\n// assume the repo is valid, though maybe empty.\nfunc (git *repoSync) initRepo(ctx context.Context) error {\n\tneedGitInit := false\n\n\t// Check out the git root, and see if it is already usable.\n\t_, err := os.Stat(git.root.String())\n\tswitch {\n\tcase os.IsNotExist(err):\n\t\t// Probably the first sync.  defaultDirMode ensures that this is usable\n\t\t// as a volume when the consumer isn't running as the same UID.\n\t\tgit.log.V(1).Info(\"repo directory does not exist, creating it\", \"path\", git.root)\n\t\tif err := os.MkdirAll(git.root.String(), defaultDirMode); err != nil {\n\t\t\treturn err\n\t\t}\n\t\tneedGitInit = true\n\tcase err != nil:\n\t\treturn err\n\tdefault:\n\t\t// Make sure the directory we found is actually usable.\n\t\tgit.log.V(3).Info(\"repo directory exists\", \"path\", git.root)\n\t\tif git.sanityCheckRepo(ctx) {\n\t\t\tgit.log.V(4).Info(\"repo directory is valid\", \"path\", git.root)\n\t\t} else {\n\t\t\t// Maybe a previous run crashed?  Git won't use this dir.  We remove\n\t\t\t// the contents rather than the dir itself, because a common use-case\n\t\t\t// is to have a volume mounted at git.root, which makes removing it\n\t\t\t// impossible.\n\t\t\tgit.log.V(0).Info(\"repo directory was empty or failed checks\", \"path\", git.root)\n\t\t\tif err := removeDirContents(git.root, git.log); err != nil {\n\t\t\t\treturn fmt.Errorf(\"can't wipe unusable root directory: %w\", err)\n\t\t\t}\n\t\t\tneedGitInit = true\n\t\t}\n\t}\n\n\tif needGitInit {\n\t\t// Running `git init` in an existing repo is safe (according to git docs).\n\t\tgit.log.V(0).Info(\"initializing repo directory\", \"path\", git.root)\n\t\tif _, _, err := git.Run(ctx, git.root, \"init\", \"-b\", \"git-sync\"); err != nil {\n\t\t\treturn err\n\t\t}\n\t\tif !git.sanityCheckRepo(ctx) {\n\t\t\treturn fmt.Errorf(\"can't initialize git repo directory\")\n\t\t}\n\t}\n\n\t// The \"origin\" remote has special meaning, like in relative-path\n\t// submodules.\n\tif stdout, stderr, err := git.Run(ctx, git.root, \"remote\", \"get-url\", \"origin\"); err != nil {\n\t\tif !strings.Contains(stderr, \"No such remote\") {\n\t\t\treturn err\n\t\t}\n\t\t// It doesn't exist - make it.\n\t\tif _, _, err := git.Run(ctx, git.root, \"remote\", \"add\", \"origin\", git.repo); err != nil {\n\t\t\treturn err\n\t\t}\n\t} else if strings.TrimSpace(stdout) != git.repo {\n\t\t// It exists, but is wrong.\n\t\tif _, _, err := git.Run(ctx, git.root, \"remote\", \"set-url\", \"origin\", git.repo); err != nil {\n\t\t\treturn err\n\t\t}\n\t}\n\n\treturn nil\n}\n\nfunc (git *repoSync) removeStaleWorktrees() (int, error) {\n\tcurrentWorktree, err := git.currentWorktree()\n\tif err != nil {\n\t\treturn 0, err\n\t}\n\n\tgit.log.V(3).Info(\"cleaning up stale worktrees\", \"currentHash\", currentWorktree.Hash())\n\n\tcount := 0\n\terr = removeDirContentsIf(git.worktreeFor(\"\").Path(), git.log, func(fi os.FileInfo) (bool, error) {\n\t\t// delete files that are over the stale time out, and make sure to never delete the current worktree\n\t\tif fi.Name() != currentWorktree.Hash() && time.Since(fi.ModTime()) > git.staleTimeout {\n\t\t\tcount++\n\t\t\treturn true, nil\n\t\t}\n\t\treturn false, nil\n\t})\n\tif err != nil {\n\t\treturn 0, err\n\t}\n\treturn count, nil\n}\n\nfunc hasGitLockFile(gitRoot absPath) (string, error) {\n\tgitLockFiles := []string{\"shallow.lock\"}\n\tfor _, lockFile := range gitLockFiles {\n\t\tlockFilePath := gitRoot.Join(\".git\", lockFile).String()\n\t\t_, err := os.Stat(lockFilePath)\n\t\tif err == nil {\n\t\t\treturn lockFilePath, nil\n\t\t} else if !errors.Is(err, os.ErrNotExist) {\n\t\t\treturn lockFilePath, err\n\t\t}\n\t}\n\treturn \"\", nil\n}\n\n// sanityCheckRepo tries to make sure that the repo dir is a valid git repository.\nfunc (git *repoSync) sanityCheckRepo(ctx context.Context) bool {\n\tgit.log.V(3).Info(\"sanity-checking git repo\", \"repo\", git.root)\n\t// If it is empty, we are done.\n\tif empty, err := dirIsEmpty(git.root); err != nil {\n\t\tgit.log.Error(err, \"can't list repo directory\", \"path\", git.root)\n\t\treturn false\n\t} else if empty {\n\t\tgit.log.V(3).Info(\"repo directory is empty\", \"path\", git.root)\n\t\treturn false\n\t}\n\n\t// Check that this is actually the root of the repo.\n\tif root, _, err := git.Run(ctx, git.root, \"rev-parse\", \"--show-toplevel\"); err != nil {\n\t\tgit.log.Error(err, \"can't get repo toplevel\", \"path\", git.root)\n\t\treturn false\n\t} else {\n\t\troot = strings.TrimSpace(root)\n\t\tif root != git.root.String() {\n\t\t\tgit.log.Error(nil, \"repo directory is under another repo\", \"path\", git.root, \"parent\", root)\n\t\t\treturn false\n\t\t}\n\t}\n\n\t// Consistency-check the repo.  Don't use --verbose because it can be\n\t// REALLY verbose.\n\tif _, _, err := git.Run(ctx, git.root, \"fsck\", \"--no-progress\", \"--connectivity-only\"); err != nil {\n\t\tgit.log.Error(err, \"repo fsck failed\", \"path\", git.root)\n\t\treturn false\n\t}\n\n\t// Check if the repository contains an unreleased lock file. This can happen if\n\t// a previous git invocation crashed.\n\tif lockFile, err := hasGitLockFile(git.root); err != nil {\n\t\tgit.log.Error(err, \"error calling stat on file\", \"path\", lockFile)\n\t\treturn false\n\t} else if len(lockFile) > 0 {\n\t\tgit.log.Error(nil, \"repo contains lock file\", \"path\", lockFile)\n\t\treturn false\n\t}\n\n\treturn true\n}\n\n// sanityCheckWorktree tries to make sure that the dir is a valid git\n// repository.  Note that this does not guarantee that the worktree has all the\n// files checked out - git could have died halfway through and the repo will\n// still pass this check.\nfunc (git *repoSync) sanityCheckWorktree(ctx context.Context, worktree worktree) bool {\n\tgit.log.V(3).Info(\"sanity-checking worktree\", \"repo\", git.root, \"worktree\", worktree)\n\n\t// If it is empty, we are done.\n\tif empty, err := dirIsEmpty(worktree.Path()); err != nil {\n\t\tgit.log.Error(err, \"can't list worktree directory\", \"path\", worktree.Path())\n\t\treturn false\n\t} else if empty {\n\t\tgit.log.V(0).Info(\"worktree is empty\", \"path\", worktree.Path())\n\t\treturn false\n\t}\n\n\t// Make sure it is synced to the right commmit.\n\tstdout, _, err := git.Run(ctx, worktree.Path(), \"rev-parse\", \"HEAD\")\n\tif err != nil {\n\t\tgit.log.Error(err, \"can't get worktree HEAD\", \"path\", worktree.Path())\n\t\treturn false\n\t}\n\tif stdout != worktree.Hash() {\n\t\tgit.log.V(0).Info(\"worktree HEAD does not match worktree\", \"path\", worktree.Path(), \"head\", stdout)\n\t\treturn false\n\t}\n\n\t// Consistency-check the worktree.  Don't use --verbose because it can be\n\t// REALLY verbose.\n\tif _, _, err := git.Run(ctx, worktree.Path(), \"fsck\", \"--no-progress\", \"--connectivity-only\"); err != nil {\n\t\tgit.log.Error(err, \"worktree fsck failed\", \"path\", worktree.Path())\n\t\treturn false\n\t}\n\n\treturn true\n}\n\nfunc dirIsEmpty(dir absPath) (bool, error) {\n\tdirents, err := os.ReadDir(dir.String())\n\tif err != nil {\n\t\treturn false, err\n\t}\n\treturn len(dirents) == 0, nil\n}\n\n// removeDirContents iterated the specified dir and removes all contents\nfunc removeDirContents(dir absPath, log *logging.Logger) error {\n\treturn removeDirContentsIf(dir, log, func(fi os.FileInfo) (bool, error) {\n\t\treturn true, nil\n\t})\n}\n\nfunc removeDirContentsIf(dir absPath, log *logging.Logger, fn func(fi os.FileInfo) (bool, error)) error {\n\tdirents, err := os.ReadDir(dir.String())\n\tif err != nil {\n\t\treturn err\n\t}\n\n\t// Save errors until the end.\n\tvar errs multiError\n\tfor _, fi := range dirents {\n\t\tname := fi.Name()\n\t\tp := filepath.Join(dir.String(), name)\n\t\tstat, err := os.Stat(p)\n\t\tif err != nil {\n\t\t\tlog.Error(err, \"failed to stat path, skipping\", \"path\", p)\n\t\t\tcontinue\n\t\t}\n\t\tif shouldDelete, err := fn(stat); err != nil {\n\t\t\tlog.Error(err, \"predicate function failed for path, skipping\", \"path\", p)\n\t\t\tcontinue\n\t\t} else if !shouldDelete {\n\t\t\tlog.V(4).Info(\"skipping path\", \"path\", p)\n\t\t\tcontinue\n\t\t}\n\t\tif log != nil {\n\t\t\tlog.V(4).Info(\"removing path recursively\", \"path\", p, \"isDir\", fi.IsDir())\n\t\t}\n\t\tif err := os.RemoveAll(p); err != nil {\n\t\t\terrs = append(errs, err)\n\t\t}\n\t}\n\n\tif len(errs) != 0 {\n\t\treturn errs\n\t}\n\treturn nil\n}\n\n// publishSymlink atomically sets link to point at the specified target.  If the\n// link existed, this returns the previous target.\nfunc (git *repoSync) publishSymlink(ctx context.Context, worktree worktree) error {\n\ttargetPath := worktree.Path()\n\tlinkDir, linkFile := git.link.Split()\n\n\t// Make sure the link directory exists.\n\tif err := os.MkdirAll(linkDir.String(), defaultDirMode); err != nil {\n\t\treturn fmt.Errorf(\"error making symlink dir: %w\", err)\n\t}\n\n\t// linkDir is absolute, so we need to change it to a relative path.  This is\n\t// so it can be volume-mounted at another path and the symlink still works.\n\ttargetRelative, err := filepath.Rel(linkDir.String(), targetPath.String())\n\tif err != nil {\n\t\treturn fmt.Errorf(\"error converting to relative path: %w\", err)\n\t}\n\n\tconst tmplink = \"tmp-link\"\n\tgit.log.V(2).Info(\"creating tmp symlink\", \"dir\", linkDir, \"link\", tmplink, \"target\", targetRelative)\n\tif err := os.Symlink(targetRelative, filepath.Join(linkDir.String(), tmplink)); err != nil {\n\t\treturn fmt.Errorf(\"error creating symlink: %w\", err)\n\t}\n\n\tgit.log.V(2).Info(\"renaming symlink\", \"root\", linkDir, \"oldName\", tmplink, \"newName\", linkFile)\n\tif err := os.Rename(filepath.Join(linkDir.String(), tmplink), git.link.String()); err != nil {\n\t\treturn fmt.Errorf(\"error replacing symlink: %w\", err)\n\t}\n\n\treturn nil\n}\n\n// removeWorktree is used to remove a worktree and its folder\nfunc (git *repoSync) removeWorktree(ctx context.Context, worktree worktree) error {\n\t// Clean up worktree, if needed.\n\t_, err := os.Stat(worktree.Path().String())\n\tswitch {\n\tcase os.IsNotExist(err):\n\t\treturn nil\n\tcase err != nil:\n\t\treturn err\n\t}\n\tgit.log.V(1).Info(\"removing worktree\", \"path\", worktree.Path())\n\tif err := os.RemoveAll(worktree.Path().String()); err != nil {\n\t\treturn fmt.Errorf(\"error removing directory: %w\", err)\n\t}\n\tif _, _, err := git.Run(ctx, git.root, \"worktree\", \"prune\", \"--verbose\"); err != nil {\n\t\treturn err\n\t}\n\treturn nil\n}\n\n// createWorktree creates a new worktree and checks out the given hash.  This\n// returns the path to the new worktree.\nfunc (git *repoSync) createWorktree(ctx context.Context, hash string) (worktree, error) {\n\t// Make a worktree for this exact git hash.\n\tworktree := git.worktreeFor(hash)\n\n\t// Avoid wedge cases where the worktree was created but this function\n\t// error'd without cleaning up.  The next time thru the sync loop fails to\n\t// create the worktree and bails out. This manifests as:\n\t//     \"fatal: '/repo/root/nnnn' already exists\"\n\tif err := git.removeWorktree(ctx, worktree); err != nil {\n\t\treturn \"\", err\n\t}\n\n\tgit.log.V(1).Info(\"adding worktree\", \"path\", worktree.Path(), \"hash\", hash)\n\t_, _, err := git.Run(ctx, git.root, \"worktree\", \"add\", \"--force\", \"--detach\", worktree.Path().String(), hash, \"--no-checkout\")\n\tif err != nil {\n\t\treturn \"\", err\n\t}\n\n\treturn worktree, nil\n}\n\n// configureWorktree applies some configuration (e.g. sparse checkout) to\n// the specified worktree and checks out the specified hash and submodules.\nfunc (git *repoSync) configureWorktree(ctx context.Context, worktree worktree) error {\n\thash := worktree.Hash()\n\n\t// The .git file in the worktree directory holds a reference to\n\t// /git/.git/worktrees/<worktree-dir-name>. Replace it with a reference\n\t// using relative paths, so that other containers can use a different volume\n\t// mount name.\n\trootDotGit := \"\"\n\tif rel, err := filepath.Rel(worktree.Path().String(), git.root.String()); err != nil {\n\t\treturn err\n\t} else {\n\t\trootDotGit = filepath.Join(rel, \".git\")\n\t}\n\tgitDirRef := []byte(\"gitdir: \" + filepath.Join(rootDotGit, \"worktrees\", hash) + \"\\n\")\n\tif err := os.WriteFile(worktree.Path().Join(\".git\").String(), gitDirRef, 0644); err != nil {\n\t\treturn err\n\t}\n\n\t// If sparse checkout is requested, configure git for it, otherwise\n\t// unconfigure it.\n\tgitInfoPath := filepath.Join(git.root.String(), \".git/worktrees\", hash, \"info\")\n\tgitSparseConfigPath := filepath.Join(gitInfoPath, \"sparse-checkout\")\n\tif git.sparseFile == \"\" {\n\t\tos.RemoveAll(gitSparseConfigPath)\n\t} else {\n\t\t// This is required due to the undocumented behavior outlined here:\n\t\t// https://public-inbox.org/git/CAPig+cSP0UiEBXSCi7Ua099eOdpMk8R=JtAjPuUavRF4z0R0Vg@mail.gmail.com/t/\n\t\tgit.log.V(1).Info(\"configuring worktree sparse checkout\")\n\t\tcheckoutFile := git.sparseFile\n\n\t\tsource, err := os.Open(checkoutFile)\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\t\tdefer source.Close()\n\n\t\tif _, err := os.Stat(gitInfoPath); os.IsNotExist(err) {\n\t\t\terr := os.Mkdir(gitInfoPath, defaultDirMode)\n\t\t\tif err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t}\n\n\t\tdestination, err := os.Create(gitSparseConfigPath)\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\t\tdefer destination.Close()\n\n\t\t_, err = io.Copy(destination, source)\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\n\t\targs := []string{\"sparse-checkout\", \"init\"}\n\t\tif _, _, err = git.Run(ctx, worktree.Path(), args...); err != nil {\n\t\t\treturn err\n\t\t}\n\t}\n\n\t// Reset the worktree's working copy to the specific ref.\n\tgit.log.V(1).Info(\"setting worktree HEAD\", \"hash\", hash)\n\tif _, _, err := git.Run(ctx, worktree.Path(), \"reset\", \"--hard\", hash, \"--\"); err != nil {\n\t\treturn err\n\t}\n\n\t// Update submodules\n\t// NOTE: this works for repo with or without submodules.\n\tif git.submodules != submodulesOff {\n\t\tgit.log.V(1).Info(\"updating submodules\")\n\t\tsubmodulesArgs := []string{\"submodule\", \"update\", \"--init\"}\n\t\tif git.submodules == submodulesRecursive {\n\t\t\tsubmodulesArgs = append(submodulesArgs, \"--recursive\")\n\t\t}\n\t\tif git.depth != 0 {\n\t\t\tsubmodulesArgs = append(submodulesArgs, \"--depth\", strconv.Itoa(git.depth))\n\t\t}\n\t\tif _, _, err := git.Run(ctx, worktree.Path(), submodulesArgs...); err != nil {\n\t\t\treturn err\n\t\t}\n\t}\n\n\treturn nil\n}\n\n// cleanup removes old worktrees and runs git's garbage collection.  The\n// specified worktree is preserved.\nfunc (git *repoSync) cleanup(ctx context.Context) error {\n\t// Save errors until the end.\n\tvar cleanupErrs multiError\n\n\t// Clean up previous worktree(s).\n\tif n, err := git.removeStaleWorktrees(); err != nil {\n\t\tcleanupErrs = append(cleanupErrs, err)\n\t} else if n == 0 {\n\t\t// We didn't clean up any worktrees, so the rest of this is moot.\n\t\treturn nil\n\t}\n\n\t// Let git know we don't need those old commits any more.\n\tgit.log.V(3).Info(\"pruning worktrees\")\n\tif _, _, err := git.Run(ctx, git.root, \"worktree\", \"prune\", \"--verbose\"); err != nil {\n\t\tcleanupErrs = append(cleanupErrs, err)\n\t}\n\n\t// Expire old refs.\n\tgit.log.V(3).Info(\"expiring unreachable refs\")\n\tif _, _, err := git.Run(ctx, git.root, \"reflog\", \"expire\", \"--expire-unreachable=all\", \"--all\"); err != nil {\n\t\tcleanupErrs = append(cleanupErrs, err)\n\t}\n\n\t// Run GC if needed.\n\tif git.gc != gcOff {\n\t\targs := []string{\"gc\"}\n\t\tswitch git.gc {\n\t\tcase gcAuto:\n\t\t\targs = append(args, \"--auto\")\n\t\tcase gcAlways:\n\t\t\t// no extra flags\n\t\tcase gcAggressive:\n\t\t\targs = append(args, \"--aggressive\")\n\t\t}\n\t\tgit.log.V(3).Info(\"running git garbage collection\")\n\t\tif _, _, err := git.Run(ctx, git.root, args...); err != nil {\n\t\t\tcleanupErrs = append(cleanupErrs, err)\n\t\t}\n\t}\n\n\tif len(cleanupErrs) > 0 {\n\t\treturn cleanupErrs\n\t}\n\treturn nil\n}\n\ntype multiError []error\n\nfunc (m multiError) Error() string {\n\tif len(m) == 0 {\n\t\treturn \"<no error>\"\n\t}\n\tif len(m) == 1 {\n\t\treturn m[0].Error()\n\t}\n\tstrs := make([]string, 0, len(m))\n\tfor _, e := range m {\n\t\tstrs = append(strs, e.Error())\n\t}\n\treturn strings.Join(strs, \"; \")\n}\n\n// worktree represents a git worktree (which may or may not exist on disk).\ntype worktree absPath\n\n// Hash returns the intended commit hash for this worktree.\nfunc (wt worktree) Hash() string {\n\tif wt == \"\" {\n\t\treturn \"\"\n\t}\n\treturn absPath(wt).Base()\n}\n\n// path returns the absolute path to this worktree (which may not actually\n// exist on disk).\nfunc (wt worktree) Path() absPath {\n\treturn absPath(wt)\n}\n\n// worktreeFor returns a worktree value for the given hash, which can be used\n// to find the on-disk path of that worktree.  Caller should not make\n// assumptions about the on-disk location where worktrees are stored.  If hash\n// is \"\", this returns the base worktree directory.\nfunc (git *repoSync) worktreeFor(hash string) worktree {\n\treturn worktree(git.root.Join(\".worktrees\", hash))\n}\n\n// currentWorktree reads the repo's link and returns a worktree value for it.\nfunc (git *repoSync) currentWorktree() (worktree, error) {\n\ttarget, err := os.Readlink(git.link.String())\n\tif err != nil && !os.IsNotExist(err) {\n\t\treturn \"\", err\n\t}\n\tif target == \"\" {\n\t\treturn \"\", nil\n\t}\n\tif filepath.IsAbs(target) {\n\t\treturn worktree(target), nil\n\t}\n\tlinkDir, _ := git.link.Split()\n\treturn worktree(linkDir.Join(target)), nil\n}\n\n// SyncRepo syncs the repository to the desired ref, publishes it via the link,\n// and tries to clean up any detritus.  This function returns whether the\n// current hash has changed and what the new hash is.\nfunc (git *repoSync) SyncRepo(ctx context.Context, refreshCreds func(context.Context) error) (bool, string, error) {\n\tgit.log.V(3).Info(\"syncing\", \"repo\", redactURL(git.repo))\n\n\tif err := refreshCreds(ctx); err != nil {\n\t\treturn false, \"\", fmt.Errorf(\"credential refresh failed: %w\", err)\n\t}\n\n\t// Initialize the repo directory if needed.\n\tif err := git.initRepo(ctx); err != nil {\n\t\treturn false, \"\", err\n\t}\n\n\t// Find out what we currently have synced, if anything.\n\tvar currentWorktree worktree\n\tif wt, err := git.currentWorktree(); err != nil {\n\t\treturn false, \"\", err\n\t} else {\n\t\tcurrentWorktree = wt\n\t}\n\tcurrentHash := currentWorktree.Hash()\n\tgit.log.V(3).Info(\"current state\", \"hash\", currentHash, \"worktree\", currentWorktree)\n\n\t// This should be very fast if we already have the hash we need. Parameters\n\t// like depth are set at fetch time.\n\tif err := git.fetch(ctx, git.ref); err != nil {\n\t\treturn false, \"\", err\n\t}\n\n\t// Figure out what we got.  The ^{} syntax \"peels\" annotated tags to\n\t// their underlying commit hashes, but has no effect if we fetched a\n\t// branch, plain tag, or hash.\n\tremoteHash := \"\"\n\tif output, _, err := git.Run(ctx, git.root, \"rev-parse\", \"FETCH_HEAD^{}\"); err != nil {\n\t\treturn false, \"\", err\n\t} else {\n\t\tremoteHash = strings.Trim(output, \"\\n\")\n\t}\n\n\tif currentHash == remoteHash {\n\t\t// We seem to have the right hash already.  Let's be sure it's good.\n\t\tgit.log.V(3).Info(\"current hash is same as remote\", \"hash\", currentHash)\n\t\tif !git.sanityCheckWorktree(ctx, currentWorktree) {\n\t\t\t// Sanity check failed, nuke it and start over.\n\t\t\tgit.log.V(0).Info(\"worktree failed checks or was empty\", \"path\", currentWorktree)\n\t\t\tif err := git.removeWorktree(ctx, currentWorktree); err != nil {\n\t\t\t\treturn false, \"\", err\n\t\t\t}\n\t\t\tcurrentHash = \"\"\n\t\t}\n\t}\n\n\t// This catches in-place upgrades from older versions where the worktree\n\t// path was different.\n\tchanged := (currentHash != remoteHash) || (currentWorktree != git.worktreeFor(currentHash))\n\n\t// We have to do at least one fetch, to ensure that parameters like depth\n\t// are set properly.  This is cheap when we already have the target hash.\n\tif changed || git.syncCount == 0 {\n\t\tgit.log.V(0).Info(\"update required\", \"ref\", git.ref, \"local\", currentHash, \"remote\", remoteHash, \"syncCount\", git.syncCount)\n\t\tmetricFetchCount.Inc()\n\n\t\t// Reset the repo (note: not the worktree - that happens later) to the new\n\t\t// ref.  This makes subsequent fetches much less expensive.  It uses --soft\n\t\t// so no files are checked out.\n\t\tif _, _, err := git.Run(ctx, git.root, \"reset\", \"--soft\", remoteHash); err != nil {\n\t\t\treturn false, \"\", err\n\t\t}\n\n\t\t// If we have a new hash, make a new worktree\n\t\tnewWorktree := currentWorktree\n\t\tif changed {\n\t\t\t// Create a worktree for this hash in git.root.\n\t\t\tif wt, err := git.createWorktree(ctx, remoteHash); err != nil {\n\t\t\t\treturn false, \"\", err\n\t\t\t} else {\n\t\t\t\tnewWorktree = wt\n\t\t\t}\n\t\t}\n\n\t\t// Even if this worktree existed and passes sanity, it might not have all\n\t\t// the correct settings (e.g. sparse checkout).  The best way to get\n\t\t// it all set is just to re-run the configuration,\n\t\tif err := git.configureWorktree(ctx, newWorktree); err != nil {\n\t\t\treturn false, \"\", err\n\t\t}\n\n\t\t// If we have a new hash, update the symlink to point to the new worktree.\n\t\tif changed {\n\t\t\terr := git.publishSymlink(ctx, newWorktree)\n\t\t\tif err != nil {\n\t\t\t\treturn false, \"\", err\n\t\t\t}\n\t\t\tif currentWorktree != \"\" {\n\t\t\t\t// Start the stale worktree removal timer.\n\t\t\t\terr = touch(currentWorktree.Path())\n\t\t\t\tif err != nil {\n\t\t\t\t\tgit.log.Error(err, \"can't change stale worktree mtime\", \"path\", currentWorktree.Path())\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\n\t\t// Mark ourselves as \"ready\".\n\t\tsetRepoReady()\n\t\tgit.syncCount++\n\t\tgit.log.V(0).Info(\"updated successfully\", \"ref\", git.ref, \"remote\", remoteHash, \"syncCount\", git.syncCount)\n\n\t\t// Regular cleanup will happen in the outer loop, to catch stale\n\t\t// worktrees.\n\n\t\t// We can end up here with no current hash but (the expectation of) a\n\t\t// current worktree (e.g. the hash was synced but the worktree does not\n\t\t// exist).\n\t\tif currentHash != \"\" && currentWorktree != git.worktreeFor(currentHash) {\n\t\t\t// The old worktree might have come from a prior version, and so\n\t\t\t// not get caught by the normal cleanup.\n\t\t\tos.RemoveAll(currentWorktree.Path().String())\n\t\t}\n\t} else {\n\t\tgit.log.V(2).Info(\"update not required\", \"ref\", git.ref, \"remote\", remoteHash, \"syncCount\", git.syncCount)\n\t}\n\n\treturn changed, remoteHash, nil\n}\n\n// fetch retrieves the specified ref from the upstream repo.\nfunc (git *repoSync) fetch(ctx context.Context, ref string) error {\n\tgit.log.V(2).Info(\"fetching\", \"ref\", ref, \"repo\", redactURL(git.repo))\n\n\t// Fetch the ref and do some cleanup, setting or un-setting the repo's\n\t// shallow flag as appropriate.\n\targs := []string{\"fetch\", git.repo, ref, \"--verbose\", \"--no-progress\", \"--prune\", \"--no-auto-gc\"}\n\tif git.depth > 0 {\n\t\targs = append(args, \"--depth\", strconv.Itoa(git.depth))\n\t} else {\n\t\t// If the local repo is shallow and we're not using depth any more, we\n\t\t// need a special case.\n\t\tshallow, err := git.isShallow(ctx)\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\t\tif shallow {\n\t\t\targs = append(args, \"--unshallow\")\n\t\t}\n\t}\n\tif _, _, err := git.Run(ctx, git.root, args...); err != nil {\n\t\treturn err\n\t}\n\n\treturn nil\n}\n\nfunc (git *repoSync) isShallow(ctx context.Context) (bool, error) {\n\tboolStr, _, err := git.Run(ctx, git.root, \"rev-parse\", \"--is-shallow-repository\")\n\tif err != nil {\n\t\treturn false, fmt.Errorf(\"can't determine repo shallowness: %w\", err)\n\t}\n\tboolStr = strings.TrimSpace(boolStr)\n\tswitch boolStr {\n\tcase \"true\":\n\t\treturn true, nil\n\tcase \"false\":\n\t\treturn false, nil\n\t}\n\treturn false, fmt.Errorf(\"unparseable bool: %q\", boolStr)\n}\n\nfunc md5sum(s string) string {\n\th := md5.New()\n\tif _, err := io.WriteString(h, s); err != nil {\n\t\t// Documented as never failing, so panic\n\t\tpanic(fmt.Sprintf(\"md5 WriteString failed: %v\", err))\n\t}\n\treturn fmt.Sprintf(\"%x\", h.Sum(nil))\n}\n\n// StoreCredentials stores a username and password for later use.\nfunc (git *repoSync) StoreCredentials(ctx context.Context, url, username, password string) error {\n\tgit.log.V(1).Info(\"storing git credential\", \"url\", redactURL(url))\n\tgit.log.V(9).Info(\"md5 of credential\", \"url\", url, \"username\", md5sum(username), \"password\", md5sum(password))\n\n\tcreds := fmt.Sprintf(\"url=%v\\nusername=%v\\npassword=%v\\n\", url, username, password)\n\t_, _, err := git.RunWithStdin(ctx, \"\", creds, \"credential\", \"approve\")\n\tif err != nil {\n\t\treturn fmt.Errorf(\"can't configure git credentials: %w\", err)\n\t}\n\n\treturn nil\n}\n\nfunc (git *repoSync) SetupGitSSH(setupKnownHosts bool, pathsToSSHSecrets []string, pathToSSHKnownHosts string) error {\n\tgit.log.V(1).Info(\"setting up git SSH credentials\")\n\n\t// If the user sets GIT_SSH_COMMAND we try to respect it.\n\tsshCmd := os.Getenv(\"GIT_SSH_COMMAND\")\n\tif sshCmd == \"\" {\n\t\tsshCmd = \"ssh\"\n\t}\n\n\t// We can't pre-verify that key-files exist because we call this path\n\t// without knowing whether we actually need SSH or not, in which case the\n\t// files may not exist and that is OK.  But we can make SSH report more.\n\tswitch {\n\tcase git.log.V(9).Enabled():\n\t\tsshCmd += \" -vvv\"\n\tcase git.log.V(7).Enabled():\n\t\tsshCmd += \" -vv\"\n\tcase git.log.V(5).Enabled():\n\t\tsshCmd += \" -v\"\n\t}\n\n\tfor _, p := range pathsToSSHSecrets {\n\t\tsshCmd += fmt.Sprintf(\" -i %s\", p)\n\t}\n\n\tif setupKnownHosts {\n\t\tsshCmd += fmt.Sprintf(\" -o StrictHostKeyChecking=yes -o UserKnownHostsFile=%s\", pathToSSHKnownHosts)\n\t} else {\n\t\tsshCmd += \" -o StrictHostKeyChecking=no\"\n\t}\n\n\tgit.log.V(9).Info(\"setting $GIT_SSH_COMMAND\", \"value\", sshCmd)\n\tif err := os.Setenv(\"GIT_SSH_COMMAND\", sshCmd); err != nil {\n\t\treturn fmt.Errorf(\"can't set $GIT_SSH_COMMAND: %w\", err)\n\t}\n\n\treturn nil\n}\n\nfunc (git *repoSync) SetupCookieFile(ctx context.Context) error {\n\tgit.log.V(1).Info(\"configuring git cookie file\")\n\n\tvar pathToCookieFile = \"/etc/git-secret/cookie_file\"\n\n\t_, err := os.Stat(pathToCookieFile)\n\tif err != nil {\n\t\treturn fmt.Errorf(\"can't access git cookiefile: %w\", err)\n\t}\n\n\tif _, _, err = git.Run(ctx, \"\", \"config\", \"--global\", \"http.cookiefile\", pathToCookieFile); err != nil {\n\t\treturn fmt.Errorf(\"can't configure git cookiefile: %w\", err)\n\t}\n\n\treturn nil\n}\n\n// CallAskPassURL consults the specified URL looking for git credentials in the\n// response.\n//\n// The expected URL callback output is below,\n// see https://git-scm.com/docs/gitcredentials for more examples:\n//\n//\tusername=xxx@example.com\n//\tpassword=xxxyyyzzz\nfunc (git *repoSync) CallAskPassURL(ctx context.Context) error {\n\tgit.log.V(3).Info(\"calling auth URL to get credentials\")\n\n\tvar netClient = &http.Client{\n\t\tTimeout: time.Second * 1,\n\t\tCheckRedirect: func(req *http.Request, via []*http.Request) error {\n\t\t\treturn http.ErrUseLastResponse\n\t\t},\n\t}\n\thttpReq, err := http.NewRequestWithContext(ctx, \"GET\", git.authURL, nil)\n\tif err != nil {\n\t\treturn fmt.Errorf(\"can't create auth request: %w\", err)\n\t}\n\tresp, err := netClient.Do(httpReq)\n\tif err != nil {\n\t\treturn fmt.Errorf(\"can't access auth URL: %w\", err)\n\t}\n\tdefer func() {\n\t\t_ = resp.Body.Close()\n\t}()\n\tif resp.StatusCode != 200 {\n\t\terrMessage, err := io.ReadAll(resp.Body)\n\t\tif err != nil {\n\t\t\treturn fmt.Errorf(\"auth URL returned status %d, failed to read body: %w\", resp.StatusCode, err)\n\t\t}\n\t\treturn fmt.Errorf(\"auth URL returned status %d, body: %q\", resp.StatusCode, string(errMessage))\n\t}\n\tauthData, err := io.ReadAll(resp.Body)\n\tif err != nil {\n\t\treturn fmt.Errorf(\"can't read auth response: %w\", err)\n\t}\n\n\tusername := \"\"\n\tpassword := \"\"\n\tfor _, line := range strings.Split(string(authData), \"\\n\") {\n\t\tkeyValues := strings.SplitN(line, \"=\", 2)\n\t\tif len(keyValues) != 2 {\n\t\t\tcontinue\n\t\t}\n\t\tswitch keyValues[0] {\n\t\tcase \"username\":\n\t\t\tusername = keyValues[1]\n\t\tcase \"password\":\n\t\t\tpassword = keyValues[1]\n\t\t}\n\t}\n\n\tif err := git.StoreCredentials(ctx, git.repo, username, password); err != nil {\n\t\treturn err\n\t}\n\n\treturn nil\n}\n\n// RefreshGitHubAppToken generates a new installation token for a GitHub app and stores it as a credential\nfunc (git *repoSync) RefreshGitHubAppToken(ctx context.Context, githubBaseURL, privateKey, privateKeyFile, clientID string, appID, installationID int) error {\n\tgit.log.V(3).Info(\"refreshing GitHub app token\")\n\n\tprivateKeyBytes := []byte(privateKey)\n\tif privateKey == \"\" {\n\t\tb, err := os.ReadFile(privateKeyFile)\n\t\tif err != nil {\n\t\t\tgit.log.Error(err, \"can't read private key file\", \"file\", privateKeyFile)\n\t\t\tos.Exit(1)\n\t\t}\n\n\t\tprivateKeyBytes = b\n\t}\n\n\tpkey, err := jwt.ParseRSAPrivateKeyFromPEM(privateKeyBytes)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\tnow := time.Now()\n\n\t// either client ID or app ID can be used when minting JWTs\n\tissuer := clientID\n\tif issuer == \"\" {\n\t\tissuer = strconv.Itoa(appID)\n\t}\n\n\tclaims := jwt.RegisteredClaims{\n\t\tIssuer:    issuer,\n\t\tIssuedAt:  jwt.NewNumericDate(now),\n\t\tExpiresAt: jwt.NewNumericDate(now.Add(10 * time.Minute)),\n\t}\n\n\tjwt, err := jwt.NewWithClaims(jwt.SigningMethodRS256, claims).SignedString(pkey)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\turl, err := url.JoinPath(githubBaseURL, fmt.Sprintf(\"app/installations/%d/access_tokens\", installationID))\n\tif err != nil {\n\t\treturn err\n\t}\n\n\treq, err := http.NewRequestWithContext(ctx, http.MethodPost, url, nil)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\treq.Header.Set(\"Authorization\", \"Bearer \"+jwt)\n\treq.Header.Set(\"Accept\", \"application/vnd.github+json\")\n\n\tresp, err := http.DefaultClient.Do(req)\n\tif err != nil {\n\t\treturn err\n\t}\n\tdefer func() {\n\t\t_ = resp.Body.Close()\n\t}()\n\tif resp.StatusCode != 201 {\n\t\terrMessage, err := io.ReadAll(resp.Body)\n\t\tif err != nil {\n\t\t\treturn fmt.Errorf(\"GitHub app installation endpoint returned status %d, failed to read body: %w\", resp.StatusCode, err)\n\t\t}\n\t\treturn fmt.Errorf(\"GitHub app installation endpoint returned status %d, body: %q\", resp.StatusCode, string(errMessage))\n\t}\n\n\ttokenResponse := struct {\n\t\tToken     string    `json:\"token\"`\n\t\tExpiresAt time.Time `json:\"expires_at\"`\n\t}{}\n\tif err := json.NewDecoder(resp.Body).Decode(&tokenResponse); err != nil {\n\t\treturn err\n\t}\n\n\tgit.appTokenExpiry = tokenResponse.ExpiresAt\n\n\t// username must be non-empty\n\tusername := \"-\"\n\tpassword := tokenResponse.Token\n\n\tif err := git.StoreCredentials(ctx, git.repo, username, password); err != nil {\n\t\treturn err\n\t}\n\n\treturn nil\n}\n\n// SetupDefaultGitConfigs configures the global git environment with some\n// default settings that we need.\nfunc (git *repoSync) SetupDefaultGitConfigs(ctx context.Context) error {\n\tconfigs := []keyVal{{\n\t\t// Never auto-detach GC runs.\n\t\tkey: \"gc.autoDetach\",\n\t\tval: \"false\",\n\t}, {\n\t\t// Fairly aggressive GC.\n\t\tkey: \"gc.pruneExpire\",\n\t\tval: \"now\",\n\t}, {\n\t\t// How to manage credentials (for those modes that need it).\n\t\tkey: \"credential.helper\",\n\t\tval: \"cache --timeout 3600\",\n\t}, {\n\t\t// Never prompt for a password.\n\t\tkey: \"core.askPass\",\n\t\tval: \"true\",\n\t}, {\n\t\t// Mark repos as safe (avoid a \"dubious ownership\" error).\n\t\tkey: \"safe.directory\",\n\t\tval: \"*\",\n\t}}\n\n\tfor _, kv := range configs {\n\t\tif _, _, err := git.Run(ctx, \"\", \"config\", \"--global\", kv.key, kv.val); err != nil {\n\t\t\treturn fmt.Errorf(\"error configuring git %q %q: %w\", kv.key, kv.val, err)\n\t\t}\n\t}\n\treturn nil\n}\n\n// SetupExtraGitConfigs configures the global git environment with user-provided\n// override settings.\nfunc (git *repoSync) SetupExtraGitConfigs(ctx context.Context, configsFlag string) error {\n\tconfigs, err := parseGitConfigs(configsFlag)\n\tif err != nil {\n\t\treturn fmt.Errorf(\"can't parse --git-config flag: %w\", err)\n\t}\n\tgit.log.V(1).Info(\"setting additional git configs\", \"configs\", configs)\n\tfor _, kv := range configs {\n\t\tif _, _, err := git.Run(ctx, \"\", \"config\", \"--global\", kv.key, kv.val); err != nil {\n\t\t\treturn fmt.Errorf(\"error configuring additional git configs %q %q: %w\", kv.key, kv.val, err)\n\t\t}\n\t}\n\n\treturn nil\n}\n\ntype keyVal struct {\n\tkey string\n\tval string\n}\n\nfunc parseGitConfigs(configsFlag string) ([]keyVal, error) {\n\t// Use a channel as a FIFO.  We don't expect the input strings to be very\n\t// large, so this simple model should suffice.\n\tch := make(chan rune, len(configsFlag))\n\tgo func() {\n\t\tfor _, r := range configsFlag {\n\t\t\tch <- r\n\t\t}\n\t\tclose(ch)\n\t}()\n\n\tresult := []keyVal{}\n\n\t// This assumes it is at the start of a key.\n\tfor {\n\t\tcur := keyVal{}\n\t\tvar err error\n\n\t\t// Peek and see if we have a key.\n\t\tif r, ok := <-ch; !ok {\n\t\t\tbreak\n\t\t} else {\n\t\t\t// This can accumulate things that git doesn't allow, but we'll\n\t\t\t// just let git handle it, rather than try to pre-validate to their\n\t\t\t// spec.\n\t\t\tif r == '\"' {\n\t\t\t\tcur.key, err = parseGitConfigQKey(ch)\n\t\t\t\tif err != nil {\n\t\t\t\t\treturn nil, err\n\t\t\t\t}\n\t\t\t} else {\n\t\t\t\tcur.key, err = parseGitConfigKey(r, ch)\n\t\t\t\tif err != nil {\n\t\t\t\t\treturn nil, err\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\n\t\t// Peek and see if we have a value.\n\t\tif r, ok := <-ch; !ok {\n\t\t\treturn nil, fmt.Errorf(\"key %q: no value\", cur.key)\n\t\t} else {\n\t\t\tif r == '\"' {\n\t\t\t\tcur.val, err = parseGitConfigQVal(ch)\n\t\t\t\tif err != nil {\n\t\t\t\t\treturn nil, fmt.Errorf(\"key %q: %w\", cur.key, err)\n\t\t\t\t}\n\t\t\t} else {\n\t\t\t\tcur.val, err = parseGitConfigVal(r, ch)\n\t\t\t\tif err != nil {\n\t\t\t\t\treturn nil, fmt.Errorf(\"key %q: %w\", cur.key, err)\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\n\t\tresult = append(result, cur)\n\t}\n\n\treturn result, nil\n}\n\nfunc parseGitConfigQKey(ch <-chan rune) (string, error) {\n\tstr, err := parseQString(ch)\n\tif err != nil {\n\t\treturn \"\", err\n\t}\n\n\t// The next character must be a colon.\n\tr, ok := <-ch\n\tif !ok {\n\t\treturn \"\", fmt.Errorf(\"unexpected end of key: %q\", str)\n\t}\n\tif r != ':' {\n\t\treturn \"\", fmt.Errorf(\"unexpected character after quoted key: %q%c\", str, r)\n\t}\n\treturn str, nil\n}\n\nfunc parseGitConfigKey(r rune, ch <-chan rune) (string, error) {\n\tbuf := make([]rune, 0, 64)\n\tbuf = append(buf, r)\n\n\tfor r := range ch {\n\t\tswitch {\n\t\tcase r == ':':\n\t\t\treturn string(buf), nil\n\t\tdefault:\n\t\t\tbuf = append(buf, r)\n\t\t}\n\t}\n\treturn \"\", fmt.Errorf(\"unexpected end of key: %q\", string(buf))\n}\n\nfunc parseGitConfigQVal(ch <-chan rune) (string, error) {\n\tstr, err := parseQString(ch)\n\tif err != nil {\n\t\treturn \"\", err\n\t}\n\n\t// If there is a next character, it must be a comma.\n\tr, ok := <-ch\n\tif ok && r != ',' {\n\t\treturn \"\", fmt.Errorf(\"unexpected character after quoted value %q%c\", str, r)\n\t}\n\treturn str, nil\n}\n\nfunc parseGitConfigVal(r rune, ch <-chan rune) (string, error) {\n\tbuf := make([]rune, 0, 64)\n\tbuf = append(buf, r)\n\n\tfor r := range ch {\n\t\tswitch r {\n\t\tcase '\\\\':\n\t\t\tif r, err := unescape(ch); err != nil {\n\t\t\t\treturn \"\", err\n\t\t\t} else {\n\t\t\t\tbuf = append(buf, r)\n\t\t\t}\n\t\tcase ',':\n\t\t\treturn string(buf), nil\n\t\tdefault:\n\t\t\tbuf = append(buf, r)\n\t\t}\n\t}\n\t// We ran out of characters, but that's OK.\n\treturn string(buf), nil\n}\n\nfunc parseQString(ch <-chan rune) (string, error) {\n\tbuf := make([]rune, 0, 64)\n\n\tfor r := range ch {\n\t\tswitch r {\n\t\tcase '\\\\':\n\t\t\tif e, err := unescape(ch); err != nil {\n\t\t\t\treturn \"\", err\n\t\t\t} else {\n\t\t\t\tbuf = append(buf, e)\n\t\t\t}\n\t\tcase '\"':\n\t\t\treturn string(buf), nil\n\t\tdefault:\n\t\t\tbuf = append(buf, r)\n\t\t}\n\t}\n\treturn \"\", fmt.Errorf(\"unexpected end of quoted string: %q\", string(buf))\n}\n\n// unescape processes most of the documented escapes that git config supports.\nfunc unescape(ch <-chan rune) (rune, error) {\n\tr, ok := <-ch\n\tif !ok {\n\t\treturn 0, fmt.Errorf(\"unexpected end of escape sequence\")\n\t}\n\tswitch r {\n\tcase 'n':\n\t\treturn '\\n', nil\n\tcase 't':\n\t\treturn '\\t', nil\n\tcase '\"', ',', '\\\\':\n\t\treturn r, nil\n\t}\n\treturn 0, fmt.Errorf(\"unsupported escape character: '%c'\", r)\n}\n\n// This string is formatted for 80 columns.  Please keep it that way.\n// DO NOT USE TABS.\nvar manual = `\nGIT-SYNC\n\nNAME\n    git-sync - sync a remote git repository\n\nSYNOPSIS\n    git-sync --repo=<repo> --root=<path> [OPTIONS]...\n\nDESCRIPTION\n\n    Fetch a remote git repository to a local directory, poll the remote for\n    changes, and update the local copy.\n\n    This is a perfect \"sidecar\" container in Kubernetes.  For example, it can\n    periodically pull files down from a repository so that an application can\n    consume them.\n\n    git-sync can pull one time, or on a regular interval.  It can read from the\n    HEAD of a branch, from a git tag, or from a specific git hash.  It will only\n    re-pull if the target has changed in the remote repository.  When it\n    re-pulls, it updates the destination directory atomically.  In order to do\n    this, it uses a git worktree in a subdirectory of the --root and flips a\n    symlink.\n\n    git-sync can pull over HTTP(S) (with authentication or not) or SSH.\n\n    git-sync can also be configured to make a webhook call upon successful git\n    repo synchronization.  The call is made after the symlink is updated.\n\nCONTRACT\n\n    git-sync has two required flags:\n      --repo: specifies which remote git repo to sync\n      --root: specifies a working directory for git-sync\n\n    The root directory is not the synced data.\n\n    Inside the root directory, git-sync stores the synced git state and other\n    things.  That directory may or may not respond to git commands - it's an\n    implementation detail.\n\n    One of the things in that directory is a symlink (see the --link flag) to\n    the most recently synced data.  This is how the data is expected to be\n    consumed, and is considered to be the \"contract\" between git-sync and\n    consumers.  The exact target of that symlink is an implementation detail,\n    but the leaf component of the target (i.e. basename \"$(readlink <link>)\")\n    is the git hash of the synced revision.  This is also part of the contract.\n\n    Why the symlink?  git checkouts are not \"atomic\" operations.  If you look\n    at the repository while a checkout is happening, you might see data that is\n    neither exactly the old revision nor the new.  git-sync \"publishes\" updates\n    via the symlink to present an atomic interface to consumers.  When the\n    remote repo has changed, git-sync will fetch the data _without_ checking it\n    out, then create a new worktree, then change the symlink to point to that\n    new worktree.\n\n    git-sync looks for changes in the remote repo periodically (see the\n    --period flag) and will attempt to transfer as little data as possible and\n    use as little disk space as possible (see the --depth and --git-gc flags),\n    but this is not part of the contract.\n\nOPTIONS\n\n    Many options can be specified as either a commandline flag or an environment\n    variable, but flags are preferred because a misspelled flag is a fatal\n    error while a misspelled environment variable is silently ignored.  Some\n    options can only be specified as an environment variable.\n\n    --add-user, $GITSYNC_ADD_USER\n            Add a record to /etc/passwd for the current UID/GID.  This is\n            needed to use SSH with an arbitrary UID.  This assumes that\n            /etc/passwd is writable by the current UID.\n\n    --askpass-url <string>, $GITSYNC_ASKPASS_URL\n            A URL to query for git credentials.  The query must return success\n            (200) and produce a series of key=value lines, including\n            \"username=<value>\" and \"password=<value>\".\n\n    --cookie-file <string>, $GITSYNC_COOKIE_FILE\n            Use a git cookiefile (/etc/git-secret/cookie_file) for\n            authentication.\n\n    --credential <string>, $GITSYNC_CREDENTIAL\n            Make one or more credentials available for authentication (see git\n            help credential).  This is similar to --username and\n            $GITSYNC_PASSWORD or --password-file, but for specific URLs, for\n            example when using submodules.  The value for this flag is either a\n            JSON-encoded object (see the schema below) or a JSON-encoded list\n            of that same object type.  This flag may be specified more than\n            once.\n\n            Object schema:\n              - url:            string, required\n              - username:       string, required\n              - password:       string, optional\n              - password-file:  string, optional\n\n            One of password or password-file must be specified.  Users should\n            prefer password-file for better security.\n\n            Example:\n              --credential='{\"url\":\"https://github.com\", \"username\":\"myname\", \"password-file\":\"/creds/mypass\"}'\n\n    --depth <int>, $GITSYNC_DEPTH\n            Create a shallow clone with history truncated to the specified\n            number of commits.  If not specified, this defaults to syncing a\n            single commit.  Setting this to 0 will sync the full history of the\n            repo.\n\n    --error-file <string>, $GITSYNC_ERROR_FILE\n            The path to an optional file into which errors will be written.\n            This may be an absolute path or a relative path, in which case it\n            is relative to --root.\n\n    --exechook-backoff <duration>, $GITSYNC_EXECHOOK_BACKOFF\n            The time to wait before retrying a failed --exechook-command.  If\n            not specified, this defaults to 3 seconds (\"3s\").\n\n    --exechook-command <string>, $GITSYNC_EXECHOOK_COMMAND\n            An optional command to be executed after syncing a new hash of the\n            remote repository.  This command does not take any arguments and\n            executes with the synced repo as its working directory.  The\n            $GITSYNC_HASH environment variable will be set to the git hash that\n            was synced.  If, at startup, git-sync finds that the --root already\n            has the correct hash, this hook will still be invoked.  This means\n            that hooks can be invoked more than one time per hash, so they\n            must be idempotent.  This flag obsoletes --sync-hook-command, but\n            if sync-hook-command is specified, it will take precedence.\n\n    --exechook-timeout <duration>, $GITSYNC_EXECHOOK_TIMEOUT\n            The timeout for the --exechook-command.  If not specifid, this\n            defaults to 30 seconds (\"30s\").\n\n    --git <string>, $GITSYNC_GIT\n            The git command to run (subject to PATH search, mostly for\n            testing).  This defaults to \"git\".\n\n    --git-config <string>, $GITSYNC_GIT_CONFIG\n            Additional git config options in a comma-separated 'key:val'\n            format.  The parsed keys and values are passed to 'git config' and\n            must be valid syntax for that command.\n\n            Both keys and values can be either quoted or unquoted strings.\n            Within quoted keys and all values (quoted or not), the following\n            escape sequences are supported:\n                '\\n' => [newline]\n                '\\t' => [tab]\n                '\\\"' => '\"'\n                '\\,' => ','\n                '\\\\' => '\\'\n            To include a colon within a key (e.g. a URL) the key must be\n            quoted.  Within unquoted values commas must be escaped.  Within\n            quoted values commas may be escaped, but are not required to be.\n            Any other escape sequence is an error.\n\n    --git-gc <string>, $GITSYNC_GIT_GC\n            The git garbage collection behavior: one of \"auto\", \"always\",\n            \"aggressive\", or \"off\".  If not specified, this defaults to\n            \"auto\".\n\n            - auto: Run \"git gc --auto\" once per successful sync.  This mode\n              respects git's gc.* config params.\n            - always: Run \"git gc\" once per successful sync.\n            - aggressive: Run \"git gc --aggressive\" once per successful sync.\n              This mode can be slow and may require a longer --sync-timeout value.\n            - off: Disable explicit git garbage collection, which may be a good\n              fit when also using --one-time.\n\n    --github-base-url <string>, $GITSYNC_GITHUB_BASE_URL\n            The GitHub base URL to use in GitHub requests when GitHub app\n            authentication is used. If not specified, defaults to\n            https://api.github.com/.\n\n    --github-app-private-key-file <string>, $GITSYNC_GITHUB_APP_PRIVATE_KEY_FILE\n            The file from which the private key to use for GitHub app\n            authentication will be read.\n\n    --github-app-installation-id <int>, $GITSYNC_GITHUB_APP_INSTALLATION_ID\n            The installation ID of the GitHub app used for GitHub app\n            authentication.\n\n    --github-app-application-id <int>, $GITSYNC_GITHUB_APP_APPLICATION_ID\n            The app ID of the GitHub app used for GitHub app authentication.\n            One of --github-app-application-id or --github-app-client-id is required\n            when GitHub app authentication is used.\n\n    --github-app-client-id <int>, $GITSYNC_GITHUB_APP_CLIENT_ID\n            The client ID of the GitHub app used for GitHub app authentication.\n            One of --github-app-application-id or --github-app-client-id is required\n            when GitHub app authentication is used.\n\n    --group-write, $GITSYNC_GROUP_WRITE\n            Ensure that data written to disk (including the git repo metadata,\n            checked out files, worktrees, and symlink) are all group writable.\n            This corresponds to git's notion of a \"shared repository\".  This is\n            useful in cases where data produced by git-sync is used by a\n            different UID.  This replaces the older --change-permissions flag.\n\n    -?, -h, --help\n            Print help text and exit.\n\n    --http-bind <string>, $GITSYNC_HTTP_BIND\n            The bind address (including port) for git-sync's HTTP endpoint.\n            The '/' URL of this endpoint is suitable for Kubernetes startup and\n            liveness probes, returning a 5xx error until the first sync is\n            complete, and a 200 status thereafter. If not specified, the HTTP\n            endpoint is not enabled.\n\n            Examples:\n              \":1234\": listen on any IP, port 1234\n              \"127.0.0.1:1234\": listen on localhost, port 1234\n\n    --http-metrics, $GITSYNC_HTTP_METRICS\n            Enable metrics on git-sync's HTTP endpoint at /metrics.  Requires\n            --http-bind to be specified.\n\n    --http-pprof, $GITSYNC_HTTP_PPROF\n            Enable the pprof debug endpoints on git-sync's HTTP endpoint at\n            /debug/pprof.  Requires --http-bind to be specified.\n\n    --link <string>, $GITSYNC_LINK\n            The path to at which to create a symlink which points to the\n            current git directory, at the currently synced hash.  This may be\n            an absolute path or a relative path, in which case it is relative\n            to --root.  Consumers of the synced files should always use this\n            link - it is updated atomically and should always be valid.  The\n            basename of the target of the link is the current hash.  If not\n            specified, this defaults to the leaf dir of --repo.\n\n    --man\n            Print this manual and exit.\n\n    --max-failures <int>, $GITSYNC_MAX_FAILURES\n            The number of consecutive failures allowed before aborting.\n            Setting this to a negative value will retry forever.  If not\n            specified, this defaults to 0, meaning any sync failure will\n            terminate git-sync.\n\n    --one-time, $GITSYNC_ONE_TIME\n            Exit after one sync.\n\n    $GITSYNC_PASSWORD\n            The password or personal access token (see github docs) to use for\n            git authentication (see --username).  See also --password-file.\n\n    --password-file <string>, $GITSYNC_PASSWORD_FILE\n            The file from which the password or personal access token (see\n            github docs) to use for git authentication (see --username) will be\n            read.  See also $GITSYNC_PASSWORD.\n\n    --period <duration>, $GITSYNC_PERIOD\n            How long to wait between sync attempts.  This must be at least\n            10ms.  This flag obsoletes --wait, but if --wait is specified, it\n            will take precedence.  If not specified, this defaults to 10\n            seconds (\"10s\").\n\n    --ref <string>, $GITSYNC_REF\n            The git revision (branch, tag, or hash) to check out.  If not\n            specified, this defaults to \"HEAD\" (of the upstream repo's default\n            branch).\n\n    --repo <string>, $GITSYNC_REPO\n            The git repository to sync.  This flag is required.\n\n    --root <string>, $GITSYNC_ROOT\n            The root directory for git-sync operations, under which --link will\n            be created.  This must be a path that either a) does not exist (it\n            will be created); b) is an empty directory; or c) is a directory\n            which can be emptied by removing all of the contents.  This flag is\n            required.\n\n    --sparse-checkout-file <string>, $GITSYNC_SPARSE_CHECKOUT_FILE\n            The path to a git sparse-checkout file (see git documentation for\n            details) which controls which files and directories will be checked\n            out.  If not specified, the default is to check out the entire repo.\n\n    --ssh-key-file <string>, $GITSYNC_SSH_KEY_FILE\n            The SSH key(s) to use when using git over SSH.  This flag may be\n            specified more than once and the environment variable will be\n            parsed like PATH - using a colon (':') to separate elements.  If\n            not specified, this defaults to \"/etc/git-secret/ssh\".\n\n    --ssh-known-hosts, $GITSYNC_SSH_KNOWN_HOSTS\n            Enable SSH known_hosts verification when using git over SSH.  If\n            not specified, this defaults to true.\n\n    --ssh-known-hosts-file <string>, $GITSYNC_SSH_KNOWN_HOSTS_FILE\n            The known_hosts file to use when --ssh-known-hosts is specified.\n            If not specified, this defaults to \"/etc/git-secret/known_hosts\".\n\n    --stale-worktree-timeout <duration>, $GITSYNC_STALE_WORKTREE_TIMEOUT\n            The length of time to retain stale (not the current link target)\n            worktrees before being removed. Once this duration has elapsed,\n            a stale worktree will be removed during the next sync attempt\n            (as determined by --sync-timeout). If not specified, this defaults\n            to 0, meaning that stale worktrees will be removed immediately.\n\n    --submodules <string>, $GITSYNC_SUBMODULES\n            The git submodule behavior: one of \"recursive\", \"shallow\", or\n            \"off\".  If not specified, this defaults to \"recursive\".\n\n    --sync-on-signal <string>, $GITSYNC_SYNC_ON_SIGNAL\n            Indicates that a sync attempt should occur upon receipt of the\n            specified signal name (e.g. SIGHUP) or number (e.g. 1). If a sync\n            is already in progress, another sync will be triggered as soon as\n            the current one completes. If not specified, signals will not\n            trigger syncs.\n\n    --sync-timeout <duration>, $GITSYNC_SYNC_TIMEOUT\n            The total time allowed for one complete sync.  This must be at least\n            10ms.  This flag obsoletes --timeout, but if --timeout is specified,\n            it will take precedence.  If not specified, this defaults to 120\n            seconds (\"120s\").\n\n    --touch-file <string>, $GITSYNC_TOUCH_FILE\n            The path to an optional file which will be touched whenever a sync\n            completes.  This may be an absolute path or a relative path, in\n            which case it is relative to --root.\n\n    --username <string>, $GITSYNC_USERNAME\n            The username to use for git authentication (see --password-file or\n            $GITSYNC_PASSWORD).  If more than one username and password is\n            required (e.g. with submodules), use --credential.\n\n    -v, --verbose <int>, $GITSYNC_VERBOSE\n            Set the log verbosity level.  Logs at this level and lower will be\n            printed.  Logs follow these guidelines:\n\n            - 0: Minimal, just log updates\n            - 1: More details about updates\n            - 2: Log the sync loop\n            - 3: More details about the sync loop\n            - 4: More details\n            - 5: Log all executed commands\n            - 6: Log stdout/stderr of all executed commands\n            - 9: Tracing and debug messages\n\n    --version\n            Print the version and exit.\n\n    --webhook-backoff <duration>, $GITSYNC_WEBHOOK_BACKOFF\n            The time to wait before retrying a failed --webhook-url.  If not\n            specified, this defaults to 3 seconds (\"3s\").\n\n    --webhook-method <string>, $GITSYNC_WEBHOOK_METHOD\n            The HTTP method for the --webhook-url.  If not specified, this defaults to \"POST\".\n\n    --webhook-success-status <int>, $GITSYNC_WEBHOOK_SUCCESS_STATUS\n            The HTTP status code indicating a successful --webhook-url.  Setting\n            this to 0 disables success checks, which makes webhooks\n            \"fire-and-forget\".  If not specified, this defaults to 200.\n\n    --webhook-timeout <duration>, $GITSYNC_WEBHOOK_TIMEOUT\n            The timeout for the --webhook-url.  If not specified, this defaults\n            to 1 second (\"1s\").\n\n    --webhook-url <string>, $GITSYNC_WEBHOOK_URL\n            A URL for optional webhook notifications when syncs complete.  The\n            header 'Gitsync-Hash' will be set to the git hash that was synced.\n            If, at startup, git-sync finds that the --root already has the\n            correct hash, this hook will still be invoked.  This means that\n            hooks can be invoked more than one time per hash, so they must be\n            idempotent.\n\nEXAMPLE USAGE\n\n    git-sync \\\n        --repo=https://github.com/kubernetes/git-sync \\\n        --ref=HEAD \\\n        --period=10s \\\n        --root=/mnt/git\n\nAUTHENTICATION\n\n    Git-sync offers several authentication options to choose from.  If none of\n    the following are specified, git-sync will try to access the repo in the\n    \"natural\" manner.  For example, \"https://repo\" will try to use plain HTTPS\n    and \"git@example.com:repo\" will try to use SSH.\n\n    username/password\n            The --username ($GITSYNC_USERNAME) and $GITSYNC_PASSWORD or\n            --password-file ($GITSYNC_PASSWORD_FILE) flags will be used.  To\n            prevent password leaks, the --password-file flag or\n            $GITSYNC_PASSWORD environment variable is almost always preferred\n            to the --password flag, which is deprecated.\n\n            A variant of this is --askpass-url ($GITSYNC_ASKPASS_URL), which\n            consults a URL (e.g. http://metadata) to get credentials on each\n            sync.\n\n            When using submodules it may be necessary to specify more than one\n            username and password, which can be done with --credential\n            ($GITSYNC_CREDENTIAL).  All of the username+password pairs, from\n            both --username/$GITSYNC_PASSWORD and --credential are fed into\n            'git credential approve'.\n\n    SSH\n            When an SSH transport is specified, the key(s) defined in\n            --ssh-key-file ($GITSYNC_SSH_KEY_FILE) will be used.  Users are\n            strongly advised to also use --ssh-known-hosts\n            ($GITSYNC_SSH_KNOWN_HOSTS) and --ssh-known-hosts-file\n            ($GITSYNC_SSH_KNOWN_HOSTS_FILE) when using SSH.\n\n    cookies\n            When --cookie-file ($GITSYNC_COOKIE_FILE) is specified, the\n            associated cookies can contain authentication information.\n\n    github app\n           When --github-app-private-key-file ($GITSYNC_GITHUB_APP_PRIVATE_KEY_FILE),\n           --github-app-application-id ($GITSYNC_GITHUB_APP_APPLICATION_ID) or\n           --github-app-client-id ($GITSYNC_GITHUB_APP_CLIENT_ID)\n           and --github-app-installation_id ($GITSYNC_GITHUB_APP_INSTALLATION_ID)\n           are specified, GitHub app authentication will be used.\n\n           These credentials are used to request a short-lived token which\n           is used for authentication. The base URL of the GitHub request made\n           to retrieve the token can also be specified via\n           --github-base-url ($GITSYNC_GITHUB_BASE_URL), which defaults to\n           https://api.github.com/.\n\n           The GitHub app must have sufficient access to the repository to sync.\n           It should be installed to the repository or organization containing\n           the repository, and given read access (see github docs).\n\nHOOKS\n\n    Webhooks and exechooks are executed asynchronously from the main git-sync\n    process.  If a --webhook-url or --exechook-command is configured, they will\n    be invoked whenever a new hash is synced, including when git-sync starts up\n    and find that the --root directory already has the correct hash.  For\n    exechook, that means the command is exec()'ed, and for webhooks that means\n    an HTTP request is sent using the method defined in --webhook-method.\n    Git-sync will retry both forms of hooks until they succeed (exit code 0 for\n    exechooks, or --webhook-success-status for webhooks).  If unsuccessful,\n    git-sync will wait --exechook-backoff or --webhook-backoff (as appropriate)\n    before re-trying the hook.  Git-sync does not ensure that hooks are invoked\n    exactly once, so hooks must be idempotent.\n\n    Hooks are not guaranteed to succeed on every single hash change.  For example,\n    if a hook fails and a new hash is synced during the backoff period, the\n    retried hook will fire for the newest hash.\n`\n\nfunc printManPage() {\n\tfmt.Print(manual)\n}\n"
        },
        {
          "name": "main_test.go",
          "type": "blob",
          "size": 11.6259765625,
          "content": "/*\nCopyright 2015 The Kubernetes Authors All rights reserved.\n\nLicensed under the Apache License, Version 2.0 (the \"License\");\nyou may not use this file except in compliance with the License.\nYou may obtain a copy of the License at\n\n    http://www.apache.org/licenses/LICENSE-2.0\n\nUnless required by applicable law or agreed to in writing, software\ndistributed under the License is distributed on an \"AS IS\" BASIS,\nWITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\nSee the License for the specific language governing permissions and\nlimitations under the License.\n*/\n\npackage main\n\nimport (\n\t\"os\"\n\t\"path/filepath\"\n\t\"reflect\"\n\t\"strings\"\n\t\"testing\"\n\t\"time\"\n\n\t\"go.uber.org/goleak\"\n)\n\nfunc TestMakeAbsPath(t *testing.T) {\n\tcases := []struct {\n\t\tpath string\n\t\troot string\n\t\texp  string\n\t}{{\n\t\tpath: \"\", root: \"\", exp: \"\",\n\t}, {\n\t\tpath: \"\", root: \"/root\", exp: \"\",\n\t}, {\n\t\tpath: \"path\", root: \"/root\", exp: \"/root/path\",\n\t}, {\n\t\tpath: \"p/a/t/h\", root: \"/root\", exp: \"/root/p/a/t/h\",\n\t}, {\n\t\tpath: \"/path\", root: \"/root\", exp: \"/path\",\n\t}, {\n\t\tpath: \"/p/a/t/h\", root: \"/root\", exp: \"/p/a/t/h\",\n\t}}\n\n\tfor _, tc := range cases {\n\t\tres := makeAbsPath(tc.path, absPath(tc.root))\n\t\tif res.String() != tc.exp {\n\t\t\tt.Errorf(\"expected: %q, got: %q\", tc.exp, res)\n\t\t}\n\t}\n}\n\nfunc TestWorktreePath(t *testing.T) {\n\ttestCases := []absPath{\n\t\t\"\",\n\t\t\"/\",\n\t\t\"//\",\n\t\t\"/dir\",\n\t\t\"/dir/\",\n\t\t\"/dir//\",\n\t\t\"/dir/sub\",\n\t\t\"/dir/sub/\",\n\t\t\"/dir//sub\",\n\t\t\"/dir//sub/\",\n\t\t\"dir\",\n\t\t\"dir/sub\",\n\t}\n\n\tfor _, tc := range testCases {\n\t\tif want, got := tc, worktree(tc).Path(); want != got {\n\t\t\tt.Errorf(\"expected %q, got %q\", want, got)\n\t\t}\n\t}\n}\n\nfunc TestWorktreeHash(t *testing.T) {\n\ttestCases := []struct {\n\t\tin  worktree\n\t\texp string\n\t}{{\n\t\tin:  \"\",\n\t\texp: \"\",\n\t}, {\n\t\tin:  \"/\",\n\t\texp: \"\",\n\t}, {\n\t\tin:  \"/one\",\n\t\texp: \"one\",\n\t}, {\n\t\tin:  \"/one/two\",\n\t\texp: \"two\",\n\t}, {\n\t\tin:  \"/one/two/\",\n\t\texp: \"two\",\n\t}, {\n\t\tin:  \"/one//two\",\n\t\texp: \"two\",\n\t}}\n\n\tfor _, tc := range testCases {\n\t\tif want, got := tc.exp, tc.in.Hash(); want != got {\n\t\t\tt.Errorf(\"%q: expected %q, got %q\", tc.in, want, got)\n\t\t}\n\t}\n}\n\nfunc TestManualHasNoTabs(t *testing.T) {\n\tif strings.Contains(manual, \"\\t\") {\n\t\tt.Fatal(\"the manual text contains a tab\")\n\t}\n}\n\nfunc TestParseGitConfigs(t *testing.T) {\n\tcases := []struct {\n\t\tname   string\n\t\tinput  string\n\t\texpect []keyVal\n\t\tfail   bool\n\t}{{\n\t\tname:   \"empty\",\n\t\tinput:  ``,\n\t\texpect: []keyVal{},\n\t}, {\n\t\tname:   \"one-pair\",\n\t\tinput:  `k:v`,\n\t\texpect: []keyVal{keyVal{\"k\", \"v\"}},\n\t}, {\n\t\tname:   \"one-pair-qkey\",\n\t\tinput:  `\"k\":v`,\n\t\texpect: []keyVal{keyVal{\"k\", \"v\"}},\n\t}, {\n\t\tname:   \"one-pair-qval\",\n\t\tinput:  `k:\"v\"`,\n\t\texpect: []keyVal{keyVal{\"k\", \"v\"}},\n\t}, {\n\t\tname:   \"one-pair-qkey-qval\",\n\t\tinput:  `\"k\":\"v\"`,\n\t\texpect: []keyVal{keyVal{\"k\", \"v\"}},\n\t}, {\n\t\tname:   \"multi-pair\",\n\t\tinput:  `k1:v1,\"k2\":v2,k3:\"v3\",\"k4\":\"v4\"`,\n\t\texpect: []keyVal{{\"k1\", \"v1\"}, {\"k2\", \"v2\"}, {\"k3\", \"v3\"}, {\"k4\", \"v4\"}},\n\t}, {\n\t\tname:  \"garbage\",\n\t\tinput: `abc123`,\n\t\tfail:  true,\n\t}, {\n\t\tname:   \"key-section-var\",\n\t\tinput:  `sect.var:v`,\n\t\texpect: []keyVal{keyVal{\"sect.var\", \"v\"}},\n\t}, {\n\t\tname:   \"key-section-subsection-var\",\n\t\tinput:  `sect.sub.var:v`,\n\t\texpect: []keyVal{keyVal{\"sect.sub.var\", \"v\"}},\n\t}, {\n\t\tname:   \"key-subsection-with-space\",\n\t\tinput:  `k.sect.sub section:v`,\n\t\texpect: []keyVal{keyVal{\"k.sect.sub section\", \"v\"}},\n\t}, {\n\t\tname:   \"key-subsection-with-escape\",\n\t\tinput:  `k.sect.sub\\tsection:v`,\n\t\texpect: []keyVal{keyVal{\"k.sect.sub\\\\tsection\", \"v\"}},\n\t}, {\n\t\tname:   \"key-subsection-with-comma\",\n\t\tinput:  `k.sect.sub,section:v`,\n\t\texpect: []keyVal{keyVal{\"k.sect.sub,section\", \"v\"}},\n\t}, {\n\t\tname:   \"qkey-subsection-with-space\",\n\t\tinput:  `\"k.sect.sub section\":v`,\n\t\texpect: []keyVal{keyVal{\"k.sect.sub section\", \"v\"}},\n\t}, {\n\t\tname:   \"qkey-subsection-with-escapes\",\n\t\tinput:  `\"k.sect.sub\\t\\n\\\\section\":v`,\n\t\texpect: []keyVal{keyVal{\"k.sect.sub\\t\\n\\\\section\", \"v\"}},\n\t}, {\n\t\tname:   \"qkey-subsection-with-comma\",\n\t\tinput:  `\"k.sect.sub,section\":v`,\n\t\texpect: []keyVal{keyVal{\"k.sect.sub,section\", \"v\"}},\n\t}, {\n\t\tname:   \"qkey-subsection-with-colon\",\n\t\tinput:  `\"k.sect.sub:section\":v`,\n\t\texpect: []keyVal{keyVal{\"k.sect.sub:section\", \"v\"}},\n\t}, {\n\t\tname:  \"invalid-qkey\",\n\t\tinput: `\"k\\xk\":v\"`,\n\t\tfail:  true,\n\t}, {\n\t\tname:   \"val-spaces\",\n\t\tinput:  `k1:v 1,k2:v 2`,\n\t\texpect: []keyVal{{\"k1\", \"v 1\"}, {\"k2\", \"v 2\"}},\n\t}, {\n\t\tname:   \"qval-spaces\",\n\t\tinput:  `k1:\" v 1 \",k2:\" v 2 \"`,\n\t\texpect: []keyVal{{\"k1\", \" v 1 \"}, {\"k2\", \" v 2 \"}},\n\t}, {\n\t\tname:   \"mix-val-qval\",\n\t\tinput:  `k1:v 1,k2:\" v 2 \"`,\n\t\texpect: []keyVal{{\"k1\", \"v 1\"}, {\"k2\", \" v 2 \"}},\n\t}, {\n\t\tname:  \"garbage-after-qval\",\n\t\tinput: `k1:\"v1\"x,k2:\"v2\"`,\n\t\tfail:  true,\n\t}, {\n\t\tname:   \"dangling-comma\",\n\t\tinput:  `k1:\"v1\",k2:\"v2\",`,\n\t\texpect: []keyVal{{\"k1\", \"v1\"}, {\"k2\", \"v2\"}},\n\t}, {\n\t\tname:   \"val-with-escapes\",\n\t\tinput:  `k1:v\\n\\t\\\\\\\"\\,1`,\n\t\texpect: []keyVal{{\"k1\", \"v\\n\\t\\\\\\\",1\"}},\n\t}, {\n\t\tname:   \"qval-with-escapes\",\n\t\tinput:  `k1:\"v\\n\\t\\\\\\\"\\,1\"`,\n\t\texpect: []keyVal{{\"k1\", \"v\\n\\t\\\\\\\",1\"}},\n\t}, {\n\t\tname:   \"qval-with-comma\",\n\t\tinput:  `k1:\"v,1\"`,\n\t\texpect: []keyVal{{\"k1\", \"v,1\"}},\n\t}, {\n\t\tname:  \"qkey-missing-close\",\n\t\tinput: `\"k1:v1`,\n\t\tfail:  true,\n\t}, {\n\t\tname:  \"qval-missing-close\",\n\t\tinput: `k1:\"v1`,\n\t\tfail:  true,\n\t}}\n\n\tfor _, tc := range cases {\n\t\tt.Run(tc.name, func(t *testing.T) {\n\t\t\tdefer goleak.VerifyNone(t)\n\n\t\t\tkvs, err := parseGitConfigs(tc.input)\n\t\t\tif err != nil && !tc.fail {\n\t\t\t\tt.Errorf(\"unexpected error: %v\", err)\n\t\t\t}\n\t\t\tif err == nil && tc.fail {\n\t\t\t\tt.Errorf(\"unexpected success\")\n\t\t\t}\n\t\t\tif !reflect.DeepEqual(kvs, tc.expect) {\n\t\t\t\tt.Errorf(\"bad result:\\n\\texpected: %#v\\n\\t     got: %#v\", tc.expect, kvs)\n\t\t\t}\n\t\t})\n\t}\n}\n\nfunc TestDirIsEmpty(t *testing.T) {\n\troot := absPath(t.TempDir())\n\n\t// Brand new should be empty.\n\tif empty, err := dirIsEmpty(root); err != nil {\n\t\tt.Fatalf(\"unexpected error: %v\", err)\n\t} else if !empty {\n\t\tt.Errorf(\"expected %q to be deemed empty\", root)\n\t}\n\n\t// Holding normal files should not be empty.\n\tdir := root.Join(\"files\")\n\tif err := os.Mkdir(dir.String(), 0755); err != nil {\n\t\tt.Fatalf(\"failed to make a temp subdir: %v\", err)\n\t}\n\tfor _, file := range []string{\"a\", \"b\", \"c\"} {\n\t\tpath := filepath.Join(dir.String(), file)\n\t\tif err := os.WriteFile(path, []byte{}, 0755); err != nil {\n\t\t\tt.Fatalf(\"failed to write a file: %v\", err)\n\t\t}\n\t\tif empty, err := dirIsEmpty(dir); err != nil {\n\t\t\tt.Fatalf(\"unexpected error: %v\", err)\n\t\t} else if empty {\n\t\t\tt.Errorf(\"expected %q to be deemed not-empty\", dir)\n\t\t}\n\t}\n\n\t// Holding dot-files should not be empty.\n\tdir = root.Join(\"dot-files\")\n\tif err := os.Mkdir(dir.String(), 0755); err != nil {\n\t\tt.Fatalf(\"failed to make a temp subdir: %v\", err)\n\t}\n\tfor _, file := range []string{\".a\", \".b\", \".c\"} {\n\t\tpath := dir.Join(file)\n\t\tif err := os.WriteFile(path.String(), []byte{}, 0755); err != nil {\n\t\t\tt.Fatalf(\"failed to write a file: %v\", err)\n\t\t}\n\t\tif empty, err := dirIsEmpty(dir); err != nil {\n\t\t\tt.Fatalf(\"unexpected error: %v\", err)\n\t\t} else if empty {\n\t\t\tt.Errorf(\"expected %q to be deemed not-empty\", dir)\n\t\t}\n\t}\n\n\t// Holding dirs should not be empty.\n\tdir = root.Join(\"dirs\")\n\tif err := os.Mkdir(dir.String(), 0755); err != nil {\n\t\tt.Fatalf(\"failed to make a temp subdir: %v\", err)\n\t}\n\tfor _, subdir := range []string{\"a\", \"b\", \"c\"} {\n\t\tpath := filepath.Join(dir.String(), subdir)\n\t\tif err := os.Mkdir(path, 0755); err != nil {\n\t\t\tt.Fatalf(\"failed to make a subdir: %v\", err)\n\t\t}\n\t\tif empty, err := dirIsEmpty(dir); err != nil {\n\t\t\tt.Fatalf(\"unexpected error: %v\", err)\n\t\t} else if empty {\n\t\t\tt.Errorf(\"expected %q to be deemed not-empty\", dir)\n\t\t}\n\t}\n\n\t// Test error path.\n\tif _, err := dirIsEmpty(root.Join(\"does-not-exist\")); err == nil {\n\t\tt.Errorf(\"unexpected success for non-existent dir\")\n\t}\n}\n\nfunc TestRemoveDirContents(t *testing.T) {\n\troot := absPath(t.TempDir())\n\n\t// Brand new should be empty.\n\tif empty, err := dirIsEmpty(root); err != nil {\n\t\tt.Fatalf(\"unexpected error: %v\", err)\n\t} else if !empty {\n\t\tt.Errorf(\"expected %q to be deemed empty\", root)\n\t}\n\n\t// Test removal.\n\tif err := removeDirContents(root, nil); err != nil {\n\t\tt.Errorf(\"unexpected error: %v\", err)\n\t}\n\n\t// Populate the dir.\n\tfor _, file := range []string{\"f1\", \"f2\", \".f3\", \".f4\"} {\n\t\tpath := root.Join(file)\n\t\tif err := os.WriteFile(path.String(), []byte{}, 0755); err != nil {\n\t\t\tt.Fatalf(\"failed to write a file: %v\", err)\n\t\t}\n\t}\n\tfor _, subdir := range []string{\"d1\", \"d2\", \"d3\"} {\n\t\tpath := root.Join(subdir)\n\t\tif err := os.Mkdir(path.String(), 0755); err != nil {\n\t\t\tt.Fatalf(\"failed to make a subdir: %v\", err)\n\t\t}\n\t}\n\n\t// It should be deemed not-empty\n\tif empty, err := dirIsEmpty(root); err != nil {\n\t\tt.Fatalf(\"unexpected error: %v\", err)\n\t} else if empty {\n\t\tt.Errorf(\"expected %q to be deemed not-empty\", root)\n\t}\n\n\t// Test removal.\n\tif err := removeDirContents(root, nil); err != nil {\n\t\tt.Errorf(\"unexpected error: %v\", err)\n\t}\n\n\t// Test error path.\n\tif err := removeDirContents(root.Join(\"does-not-exist\"), nil); err == nil {\n\t\tt.Errorf(\"unexpected success for non-existent dir\")\n\t}\n}\n\nfunc TestTouch(t *testing.T) {\n\troot := absPath(t.TempDir())\n\n\t// Make a dir and get info.\n\tdirPath := root.Join(\"dir\")\n\tif err := os.MkdirAll(dirPath.String(), 0755); err != nil {\n\t\tt.Fatalf(\"can't create dir: %v\", err)\n\t}\n\n\t// Make a file and get info.\n\tfilePath := root.Join(\"file\")\n\tif file, err := os.Create(filePath.String()); err != nil {\n\t\tt.Fatalf(\"can't create file: %v\", err)\n\t} else {\n\t\tfile.Close()\n\t}\n\n\t// Make sure a newfile does not exist.\n\tnewfilePath := root.Join(\"newfile\")\n\tif fi, err := os.Stat(newfilePath.String()); err == nil {\n\t\tt.Fatalf(\"unexpected newfile: %v\", fi)\n\t} else if !os.IsNotExist(err) {\n\t\tt.Fatalf(\"can't stat newfile: %v\", err)\n\t}\n\n\ttime.Sleep(500 * time.Millisecond)\n\tstamp := time.Now()\n\ttime.Sleep(100 * time.Millisecond)\n\n\tif err := touch(dirPath); err != nil {\n\t\tt.Fatalf(\"touch(dir) failed: %v\", err)\n\t}\n\tif dirInfo, err := os.Stat(dirPath.String()); err != nil {\n\t\tt.Fatalf(\"can't stat dir: %v\", err)\n\t} else if !dirInfo.IsDir() {\n\t\tt.Errorf(\"touch(dir) is no longer a dir: %v\", dirInfo)\n\t} else if !dirInfo.ModTime().After(stamp) {\n\t\tt.Errorf(\"touch(dir) mtime %v is not after %v\", dirInfo.ModTime(), stamp)\n\t}\n\n\tif err := touch(filePath); err != nil {\n\t\tt.Fatalf(\"touch(file) failed: %v\", err)\n\t}\n\tif fileInfo, err := os.Stat(filePath.String()); err != nil {\n\t\tt.Fatalf(\"can't stat file: %v\", err)\n\t} else if fileInfo.IsDir() {\n\t\tt.Errorf(\"touch(file) is no longer a file: %v\", fileInfo)\n\t} else if !fileInfo.ModTime().After(stamp) {\n\t\tt.Errorf(\"touch(file) mtime %v is not after %v\", fileInfo.ModTime(), stamp)\n\t}\n\n\tif err := touch(newfilePath); err != nil {\n\t\tt.Fatalf(\"touch(newfile) failed: %v\", err)\n\t}\n\tif newfileInfo, err := os.Stat(newfilePath.String()); err != nil {\n\t\tt.Fatalf(\"can't stat newfile: %v\", err)\n\t} else if newfileInfo.IsDir() {\n\t\tt.Errorf(\"touch(newfile) is not a file: %v\", newfileInfo)\n\t} else if !newfileInfo.ModTime().After(stamp) {\n\t\tt.Errorf(\"touch(newfile) mtime %v is not after %v\", newfileInfo.ModTime(), stamp)\n\t}\n}\n\nfunc TestHasGitLockFile(t *testing.T) {\n\ttestCases := map[string]struct {\n\t\tinputFilePath  []string\n\t\texpectLockFile bool\n\t}{\n\t\t\"missing .git directory\": {\n\t\t\texpectLockFile: false,\n\t\t},\n\t\t\"has git directory but no lock files\": {\n\t\t\tinputFilePath:  []string{\".git\", \"HEAD\"},\n\t\t\texpectLockFile: false,\n\t\t},\n\t\t\"shallow.lock file\": {\n\t\t\tinputFilePath:  []string{\".git\", \"shallow.lock\"},\n\t\t\texpectLockFile: true,\n\t\t},\n\t}\n\n\tfor name, tc := range testCases {\n\t\tt.Run(name, func(t *testing.T) {\n\t\t\troot := absPath(t.TempDir())\n\n\t\t\tif len(tc.inputFilePath) > 0 {\n\t\t\t\tif err := touch(root.Join(tc.inputFilePath...)); err != nil {\n\t\t\t\t\tt.Fatal(err)\n\t\t\t\t}\n\t\t\t}\n\n\t\t\tlockFile, err := hasGitLockFile(root)\n\t\t\tif err != nil {\n\t\t\t\tt.Fatal(err)\n\t\t\t}\n\t\t\thasLock := len(lockFile) > 0\n\t\t\tif hasLock != tc.expectLockFile {\n\t\t\t\tt.Fatalf(\"expected hasGitLockFile to return %v, but got %v\", tc.expectLockFile, hasLock)\n\t\t\t}\n\t\t})\n\t}\n}\n"
        },
        {
          "name": "pkg",
          "type": "tree",
          "content": null
        },
        {
          "name": "stage_binaries.sh",
          "type": "blob",
          "size": 14.1513671875,
          "content": "#!/bin/bash\n\n# Copyright 2022 The Kubernetes Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# USAGE: stage-binaries.sh -o <staging-dir> ( -p <package> | -b binary )...\"\n#\n# Stages all the packages or files and their dependencies (+ libraries and\n# copyrights) to the staging dir.\n#\n# This is intended to be used in a multi-stage docker build.\n\nset -o errexit\nset -o nounset\nset -o pipefail\n\n# Dump the call stack.\n#\n# $1: frames to skip\nfunction stack() {\n  local frame=\"${1:-0}\"\n  frame=\"$((frame+1))\" # for this frame\n  local indent=\"\"\n  while [[ -n \"${FUNCNAME[\"${frame}\"]:-}\" ]]; do\n      if [[ -n \"$indent\" ]]; then\n          echo -ne \"  from \"\n      fi\n      indent=\"true\"\n      local file\n      file=\"$(basename \"${BASH_SOURCE[\"${frame}\"]}\")\"\n      local line=\"${BASH_LINENO[\"$((frame-1))\"]}\" # ???\n      local func=\"${FUNCNAME[\"${frame}\"]:-}\"\n      echo -e \"${func}() ${file}:${line}\"\n      frame=\"$((frame+1))\"\n  done\n}\n\n# A handler for when we exit automatically on an error.\n# Borrowed from kubernetes, which was borrowed from\n# https://gist.github.com/ahendrix/7030300\nfunction errexit() {\n  # If the shell we are in doesn't have errexit set (common in subshells) then\n  # don't dump stacks.\n  set +o | grep -qe \"-o errexit\" || return\n\n  # Dump stack\n  echo -n \"FATAL: error at \" >&2\n  stack 1 >&2 # skip this frame\n\n  # Exit, really, right now.\n  local pgid\n  pgid=\"$(awk '{print $5}' /proc/self/stat)\"\n  kill -- -\"${pgid}\"\n}\n\n# trap ERR to provide an error handler whenever a command exits nonzero  this\n# is a more verbose version of set -o errexit\ntrap 'errexit' ERR\n\n# setting errtrace allows our ERR trap handler to be propagated to functions,\n# expansions and subshells\nset -o errtrace\n\nfunction DBG() {\n    if [[ -n \"${DBG:-}\" ]]; then\n        echo \"$@\"\n    fi\n}\n\nfunction grep_allow_nomatch() {\n    # grep exits 0 on match, 1 on no match, 2 on error\n    grep \"$@\" || [[ $? == 1 ]]\n}\n\nfunction _indent() {\n    (\n        IFS=\"\" # preserve spaces in `read`\n        while read -r X; do\n            echo \"  ${X}\"\n        done\n    )\n}\n\n# run \"$@\" and indent the output\n#\n# See the workaround in errexit before you rename this.\nfunction indent() {\n    # This lets us process stderr and stdout without merging them, without\n    # bash-isms.  This MUST NOT be wrapped in a conditional, or else errexit no\n    # longer applies to the executed command.\n    { set -o errexit; \"$@\" 2>&1 1>&3 | _indent; } 3>&1 1>&2 | _indent\n}\n\n# Track these globally so we only load it once.\nROOT_FWD_LINKS=()\nROOT_REV_LINKS=()\n\nfunction load_root_links() {\n    local staging=\"$1\"\n\n    while read -r x; do\n        if [[ -L \"/${x}\" ]]; then\n            ROOT_FWD_LINKS+=(\"/${x}\")\n            ROOT_REV_LINKS+=(\"$(realpath \"/${x}\")\")\n        fi\n    done < <(ls /)\n}\n\n# file_to_package identifies the debian package that provided the file $1\nfunction file_to_package() {\n    local file=\"$1\"\n\n    # Newer versions of debian symlink /lib -> /usr/lib (and others), but dpkg\n    # has some files in its DB as \"/lib/<whatever>\" and others as\n    # \"/usr/lib/<whatever>\".  This causes havoc trying to identify the package\n    # for a library discovered via ldd.\n    #\n    # So, to combat this we build a \"map\" of root links, and their targets, and\n    # try to search for both paths.\n\n    local alt=\"\"\n    local i=0\n    while (( \"${i}\" < \"${#ROOT_FWD_LINKS[@]}\" )); do\n        fwd=\"${ROOT_FWD_LINKS[i]}\"\n        rev=\"${ROOT_REV_LINKS[i]}\"\n        if [[ \"${file}\" =~ ^\"${fwd}/\" ]]; then\n            alt=\"${file/#\"${fwd}\"/\"${rev}\"}\"\n            break\n        elif [[ \"${file}\" =~ ^\"${rev}/\" ]]; then\n            alt=\"${file/#\"${rev}\"/\"${fwd}\"}\"\n            break\n        fi\n        i=$((i+1))\n    done\n\n    local out=\"\"\n    local result=\"\"\n    out=\"$(dpkg-query --search \"${file}\" 2>&1)\"\n    # shellcheck disable=SC2181\n    if [[ $? == 0 ]]; then\n        result=\"${out}\"\n    elif [[ -n \"${alt}\" ]]; then\n        out=\"$(dpkg-query --search \"${alt}\" 2>&1)\"\n        # shellcheck disable=SC2181\n        if [[ $? == 0 ]]; then\n            result=\"${out}\"\n        fi\n    fi\n\n    # If we found no match, let it error out.\n    if [[ -z \"${result}\" ]]; then\n        dpkg-query --search \"${file}\"\n        return 1\n    fi\n\n    # `dpkg-query --search $file-pattern` outputs lines with the format: \"$package: $file-path\"\n    # where $file-path belongs to $package.  Sometimes it has lines that say\n    # \"diversion\" but there's no documented grammar I can find.\n    echo \"${result}\" | grep -v \"diversion\" | cut -d':' -f1\n}\n\nfunction ensure_dir_in_staging() {\n    local staging=\"$1\"\n    local dir=\"$2\"\n\n    if [[ ! -e \"${staging}/${dir}\" ]]; then\n        # Stript the leading /\n        local rel=\"${dir/#\\//}\"\n        tar -C / -c --no-recursion --dereference \"${rel}\" | tar -C \"${staging}\" -x\n    fi\n}\n\n# stage_one_file stages the filepath $2 to $1, following symlinks\nfunction stage_one_file() {\n    local staging=\"$1\"\n    local file=\"$2\"\n\n    # copy the real form of the named path\n    local real\n    real=\"$(realpath \"${file}\")\"\n    cp -a --parents \"${real}\" \"${staging}\"\n\n    # recreate symlinks, even on intermediate path elements\n    if [[ \"${file}\" != \"${real}\" ]]; then\n        if [[ ! -e \"${staging}/${file}\" ]]; then\n            local dir\n            dir=\"$(dirname \"${file}\")\"\n            ensure_dir_in_staging \"${staging}\" \"${dir}\"\n            ln -s \"${real}\" \"${staging}/${file}\"\n        fi\n    fi\n}\n\n# stage_file_and_deps stages the filepath $2 to $1, following symlinks and\n# library deps, and staging copyrights\nfunction stage_file_and_deps() {\n    local staging=\"$1\"\n    local file=\"$2\"\n\n    # short circuit if we have done this file before\n    if [[ -e \"${staging}/${file}\" ]]; then\n        return\n    fi\n\n    # get the package so we can stage package metadata as well\n    local package\n    package=\"$(file_to_package \"${file}\")\"\n    DBG \"staging file ${file} from pkg ${package}\"\n\n    stage_one_file \"${staging}\" \"$file\"\n\n    # stage dependencies of binaries\n    if [[ -x \"$file\" ]]; then\n        DBG \"staging deps of file ${file}\"\n        while read -r lib; do\n            indent stage_file_and_deps \"${staging}\" \"${lib}\"\n        done < <( binary_to_libraries \"${file}\" )\n    fi\n\n    if [[ -n \"${package}\" ]]; then\n        # stage the copyright for the file, if it exists\n        local copyright_src=\"/usr/share/doc/${package}/copyright\"\n        local copyright_dst=\"${staging}/copyright/${package}/copyright.gz\"\n        if [[ -f \"${copyright_src}\" && ! -f \"${copyright_dst}\" ]]; then\n            mkdir -p \"$(dirname \"${copyright_dst}\")\"\n            gzip -9 --to-stdout \"${copyright_src}\" > \"${copyright_dst}\"\n        fi\n\n        # Since apt is not in the final image, stage the package status\n        # (mimicking bazel).  This allows security scanners to run against it.\n        # https://github.com/bazelbuild/rules_docker/commit/f5432b813e0a11491cf2bf83ff1a923706b36420\n        mkdir -p \"${staging}/var/lib/dpkg/status.d/\"\n        dpkg -s \"${package}\" > \"${staging}/var/lib/dpkg/status.d/${package}\"\n    fi\n}\n\nfunction stage_one_package() {\n    local staging=\"$1\"\n    local pkg=\"$2\"\n\n    local names=()\n    local sums=()\n    while read -r file; do\n        if [[ -f \"${file}\" ]]; then\n            local found=\"\"\n            if [[ ! -L \"${file}\" ]]; then\n                sum=\"$(md5sum \"${file}\" | cut -f1 -d' ')\"\n                local i=0\n                for s in \"${sums[@]}\"; do\n                    if [[ \"${sum}\" == \"${s}\" ]]; then\n                        local dir\n                        dir=\"$(dirname \"${file}\")\"\n                        ensure_dir_in_staging \"${staging}\" \"$(dirname \"${file}\")\"\n                        ln -s \"${names[$i]}\" \"${staging}/${file}\"\n                        found=\"true\"\n                        break\n                    fi\n                    i=$((i+1))\n                done\n            fi\n            if [[ -z \"${found}\" ]]; then\n                names+=(\"${file}\")\n                sums+=(\"${sum}\")\n                indent stage_file_and_deps \"${staging}\" \"${file}\"\n            fi\n        fi\n    done < <( dpkg -L \"${pkg}\" \\\n        | grep_allow_nomatch -vE '(/\\.|/usr/share/(man|doc|.*-completion))' )\n}\n\nfunction get_dependent_packages() {\n    local pkg=\"$1\"\n    # There's no documented grammar for the output of this.  Sometimes it says:\n    #    Depends: package\n    # ...and other times it says:\n    #    Depends <package>\n    # ...but those don't really seem to be required.  There's also \"PreDepends\"\n    # which are something else.\n    apt-cache depends \"${pkg}\" \\\n        | grep_allow_nomatch '^ *Depends: [a-zA-Z0-9]' \\\n        | awk -F ':' '{print $2}'\n}\n\n# Args:\n#   $1: path to staging dir\n#   $2+: package names\nfunction stage_packages() {\n    local staging=\"$1\"\n    shift\n\n    indent apt-get -y -qq -o Dpkg::Use-Pty=0 update\n\n    local pkg\n    for pkg; do\n        echo \"staging package ${pkg}\"\n        local du_before\n        du_before=\"$(du -sk \"${staging}\" | cut -f1)\"\n        indent apt-get -y -qq -o Dpkg::Use-Pty=0 --no-install-recommends install \"${pkg}\"\n        stage_one_package \"$staging\" \"${pkg}\"\n        while read -r dep; do\n            DBG \"staging dependent package ${dep}\"\n            indent stage_one_package \"${staging}\" \"${dep}\"\n        done < <( get_dependent_packages \"${pkg}\" )\n        local du_after\n        du_after=\"$(du -sk \"${staging}\" | cut -f1)\"\n        indent echo \"package ${pkg} size: +$(( du_after - du_before )) kB (of ${du_after} kB)\"\n    done\n}\n\n# binary_to_libraries identifies the library files needed by the binary $1 with ldd\nfunction binary_to_libraries() {\n    local bin=\"$1\"\n\n    # see: https://man7.org/linux/man-pages/man1/ldd.1.html\n    # Each output line looks like:\n    #     linux-vdso.so.1 (0x00007fffb11c3000)\n    #   or\n    #     libc.so.6 => /lib/x86_64-linux-gnu/libc.so.6 (0x00007f2f52d26000)\n    #\n    # This is a little funky because ldd treats static binaries as errors (\"not\n    # a dynamic executable\") but static libraries as non-errors (\"statically\n    # linked\").  We want real ldd errors, but static binaries are OK.\n    if [[ \"$(ldd \"${bin}\" 2>&1)\" =~ \"not a dynamic executable\" ]]; then\n        return\n    fi\n    ldd \"${bin}\" \\\n        `# skip static binaries` \\\n        | grep_allow_nomatch -v \"statically linked\" \\\n        `# linux-vdso is a special virtual shared object from the kernel` \\\n        `# see: http://man7.org/linux/man-pages/man7/vdso.7.html` \\\n        | grep_allow_nomatch -v 'linux-vdso' \\\n        `# strip the leading '${name} => ' if any so only '/lib-foo.so (0xf00)' remains` \\\n        | sed -E 's#.* => /#/#' \\\n        `# we want only the path remaining, not the (0x${LOCATION})` \\\n        | awk '{print $1}'\n}\n\nfunction stage_one_binary() {\n    local staging=\"$1\"\n    local bin=\"$2\"\n\n    # locate the path to the binary\n    local binary_path\n    binary_path=\"$(which \"${bin}\")\"\n\n    # stage the binary itself\n    stage_file_and_deps \"${staging}\" \"${binary_path}\"\n}\n\nfunction stage_binaries() {\n    local staging=\"$1\"\n    shift\n\n    local bin\n    for bin; do\n        echo \"staging binary ${bin}\"\n        local du_before\n        du_before=\"$(du -sk \"${staging}\" | cut -f1)\"\n        stage_one_binary \"${staging}\" \"${bin}\"\n        local du_after\n        du_after=\"$(du -sk \"${staging}\" | cut -f1)\"\n        indent echo \"binary ${bin} size: +$(( du_after - du_before )) kB (of ${du_after} kB)\"\n    done\n}\n\nfunction stage_files() {\n    local staging=\"$1\"\n    shift\n\n    local bin\n    for file; do\n        echo \"staging file ${file}\"\n        local du_before\n        du_before=\"$(du -sk \"${staging}\" | cut -f1)\"\n        stage_one_file \"${staging}\" \"${file}\"\n        local du_after\n        du_after=\"$(du -sk \"${staging}\" | cut -f1)\"\n        indent echo \"file ${file} size: +$(( du_after - du_before )) kB (of ${du_after} kB)\"\n    done\n}\n\nfunction usage() {\n    echo \"$0 -o <staging-dir> ( -p <package> | -b binary )...\"\n}\n\nfunction main() {\n    local staging=\"\"\n    local pkgs=()\n    local bins=()\n    local files=()\n\n    while [ \"$#\" -gt 0 ]; do\n    case \"$1\" in\n        \"-?\")\n            usage\n            exit 0\n            ;;\n        \"-b\")\n            if [[ -z \"${2:-}\" ]]; then\n                echo \"error: flag '-b' requires an argument\" >&2\n                usage >&2\n                exit 2\n            fi\n            bins+=(\"$2\")\n            shift 2\n            ;;\n        \"-f\")\n            if [[ -z \"${2:-}\" ]]; then\n                echo \"error: flag '-f' requires an argument\" >&2\n                usage >&2\n                exit 2\n            fi\n            files+=(\"$2\")\n            shift 2\n            ;;\n        \"-p\")\n            if [[ -z \"${2:-}\" ]]; then\n                echo \"error: flag '-p' requires an argument\" >&2\n                usage >&2\n                exit 2\n            fi\n            pkgs+=(\"$2\")\n            shift 2\n            ;;\n        \"-o\")\n            if [[ -z \"${2:-}\" ]]; then\n                echo \"error: flag '-o' requires an argument\" >&2\n                usage >&2\n                exit 2\n            fi\n            staging=\"$2\"\n            shift 2\n            ;;\n        *)\n            echo \"error: unknown argument: $1\" >&2\n            usage >&2\n            exit 3\n            ;;\n    esac\n    done\n\n    if [[ -z \"${staging}\" ]]; then\n        usage >&2\n        exit 4\n    fi\n\n    # Newer versions of debian symlink /bin -> /usr/bin (and lib, and others).\n    # The somewhat naive copying done in this program does not retain that,\n    # which causes some files to be duplicated.  Fortunately, these are all in\n    # the root dir, or we might have to do something more complicated.\n    load_root_links \"${staging}\"\n\n    if (( \"${#pkgs[@]}\" > 0 )); then\n        stage_packages \"${staging}\" \"${pkgs[@]}\"\n    fi\n    if (( \"${#bins[@]}\" > 0 )); then\n        stage_binaries \"${staging}\" \"${bins[@]}\"\n    fi\n    if (( \"${#files[@]}\" > 0 )); then\n        stage_files \"${staging}\" \"${files[@]}\"\n    fi\n\n    echo \"final staged size: $(du -sk \"${staging}\" | cut -f1) kB\"\n    du -xk --max-depth=3 \"${staging}\" | sort -n | _indent\n}\n\nmain \"$@\"\n"
        },
        {
          "name": "test_e2e.sh",
          "type": "blob",
          "size": 115.7197265625,
          "content": "#!/bin/bash\n#\n# Copyright 2016 The Kubernetes Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nset -o errexit\nset -o nounset\nset -o pipefail\n\n# shellcheck disable=SC2120\nfunction caller() {\n  local stack_skip=${1:-0}\n  stack_skip=$((stack_skip + 1))\n  if [[ ${#FUNCNAME[@]} -gt ${stack_skip} ]]; then\n    local i\n    for ((i=1 ; i <= ${#FUNCNAME[@]} - stack_skip ; i++))\n    do\n      local frame_no=$((i - 1 + stack_skip))\n      local source_lineno=${BASH_LINENO[$((frame_no - 1))]}\n      local funcname=${FUNCNAME[${frame_no}]}\n      if [[ \"$funcname\" =~ 'e2e::' ]]; then\n          echo \"${source_lineno}\"\n      fi\n    done\n  fi\n}\n\nfunction fail() {\n    echo \"FAIL: line $(caller):\" \"$@\" >&3\n    return 42\n}\n\nfunction skip() {\n    echo \"SKIP\" >&3\n    return 43\n}\n\nfunction pass() {\n    echo \"PASS\"\n}\n\n# $1: a file/dir name\n# $2: max seconds to wait\nfunction wait_for_file_exists() {\n    local file=$1\n    local ticks=$(($2*10)) # 100ms per tick\n\n    while (( ticks > 0 )); do\n        if [[ -f \"$file\" ]]; then\n            break\n        fi\n        sleep 0.1\n        ticks=$((ticks-1))\n    done\n}\n\nfunction assert_link_exists() {\n    if ! [[ -e \"$1\" ]]; then\n        fail \"$1 does not exist\"\n    fi\n    if ! [[ -L \"$1\" ]]; then\n        fail \"$1 is not a symlink\"\n    fi\n}\n\nfunction assert_link_basename_eq() {\n    if [[ $(basename \"$(readlink \"$1\")\") == \"$2\" ]]; then\n        return\n    fi\n    fail \"$1 does not point to $2: $(readlink \"$1\")\"\n}\n\nfunction assert_file_exists() {\n    if ! [[ -f \"$1\" ]]; then\n        fail \"$1 does not exist\"\n    fi\n}\n\nfunction assert_file_absent() {\n    if [[ -f \"$1\" ]]; then\n        fail \"$1 exists but should not\"\n    fi\n}\n\nfunction assert_file_eq() {\n    if [[ $(cat \"$1\") == \"$2\" ]]; then\n        return\n    fi\n    fail \"$1 does not contain '$2': $(cat \"$1\")\"\n}\n\nfunction assert_file_contains() {\n    if grep -q \"$2\" \"$1\"; then\n        return\n    fi\n    fail \"$1 does not contain '$2': $(cat \"$1\")\"\n}\n\nfunction assert_file_lines_eq() {\n    N=$(wc -l < \"$1\")\n    if (( \"$N\" != \"$2\" )); then\n        fail \"$1 is not $2 lines: $N\"\n    fi\n}\n\nfunction assert_file_lines_ge() {\n    N=$(wc -l < \"$1\")\n    if (( \"$N\" < \"$2\" )); then\n        fail \"$1 is not at least $2 lines: $N\"\n    fi\n}\n\nfunction assert_metric_eq() {\n    local val\n    val=\"$(curl --silent \"http://localhost:$HTTP_PORT/metrics\" \\\n        | grep \"^$1 \" \\\n        | awk '{print $NF}')\"\n    if [[ \"${val}\" == \"$2\" ]]; then\n        return\n    fi\n    fail \"metric $1 was expected to be '$2': ${val}\"\n}\n\nfunction assert_fail() {\n    (\n        set +o errexit\n        \"$@\"\n        RET=$?\n        if [[ \"$RET\" != 0 ]]; then\n            return\n        fi\n        fail \"expected non-zero exit code, got $RET\"\n    )\n}\n\n# Helper: run a docker container.\nfunction docker_run() {\n    RM=\"--rm\"\n    if [[ \"${CLEANUP:-}\" == 0 ]]; then\n        RM=\"\"\n    fi\n    docker run \\\n        -d \\\n        ${RM} \\\n        --label git-sync-e2e=\"$RUNID\" \\\n        \"$@\"\n    sleep 2 # wait for it to come up\n}\n\n# Helper: get the IP of a docker container.\nfunction docker_ip() {\n    if [[ -z \"$1\" ]]; then\n        echo \"usage: $0 <id>\"\n        return 1\n    fi\n    docker inspect \"$1\" | jq -r .[0].NetworkSettings.IPAddress\n}\n\nfunction docker_kill() {\n    if [[ -z \"$1\" ]]; then\n        echo \"usage: $0 <id>\"\n        return 1\n    fi\n    docker kill \"$1\" >/dev/null\n}\n\nfunction docker_signal() {\n    if [[ -z \"$1\" || -z \"$2\" ]]; then\n        echo \"usage: $0 <id> <signal>\"\n        return 1\n    fi\n    docker kill \"--signal=$2\" \"$1\" >/dev/null\n}\n\n# E2E_TAG is the tag used for docker builds.  This is needed because docker\n# tags are system-global, but one might have multiple repos checked out.\nE2E_TAG=$(git rev-parse --show-toplevel | sed 's|/|_|g')\n\n# Setting GIT_SYNC_E2E_IMAGE forces the test to use a specific image instead of the\n# current tree.\nbuild_container=false\nif [[ \"${GIT_SYNC_E2E_IMAGE:-unset}\" == \"unset\" ]]; then\n  GIT_SYNC_E2E_IMAGE=\"e2e/git-sync:${E2E_TAG}__$(go env GOOS)_$(go env GOARCH)\"\n  build_container=true\nfi\n\n# DIR is the directory in which all this test's state lives.\nRUNID=\"${RANDOM}${RANDOM}\"\nDIR=\"/tmp/git-sync-e2e.$RUNID\"\nmkdir \"$DIR\"\nfunction final_cleanup() {\n  if [[ \"${CLEANUP:-}\" == 0 ]]; then\n      echo \"leaving logs in $DIR\"\n  else\n      rm -rf \"$DIR\"\n  fi\n}\n# Set the trap to call the final_cleanup function on exit.\ntrap final_cleanup EXIT\n\nskip_github_app_test=\"${SKIP_GITHUB_APP_TEST:-true}\"\nrequired_env_vars=()\nLOCAL_GITHUB_APP_PRIVATE_KEY_FILE=\"github_app_private_key.pem\"\nGITHUB_APP_PRIVATE_KEY_MOUNT=()\nif [[ \"${skip_github_app_test}\" != \"true\" ]]; then\n  required_env_vars=(\n    \"TEST_GITHUB_APP_AUTH_TEST_REPO\"\n    \"TEST_GITHUB_APP_APPLICATION_ID\"\n    \"TEST_GITHUB_APP_INSTALLATION_ID\"\n    \"TEST_GITHUB_APP_CLIENT_ID\"\n  )\n\n  if [[ -n \"${TEST_GITHUB_APP_PRIVATE_KEY_FILE:-}\" && -n \"${TEST_GITHUB_APP_PRIVATE_KEY:-}\" ]]; then\n      echo \"ERROR: Both TEST_GITHUB_APP_PRIVATE_KEY_FILE and TEST_GITHUB_APP_PRIVATE_KEY were specified.\"\n      exit 1\n  fi\n  if [[ -n \"${TEST_GITHUB_APP_PRIVATE_KEY_FILE:-}\" ]]; then\n    cp \"${TEST_GITHUB_APP_PRIVATE_KEY_FILE}\" \"${DIR}/${LOCAL_GITHUB_APP_PRIVATE_KEY_FILE}\"\n  elif [[ -n \"${TEST_GITHUB_APP_PRIVATE_KEY:-}\" ]]; then\n    echo \"${TEST_GITHUB_APP_PRIVATE_KEY}\" > \"${DIR}/${LOCAL_GITHUB_APP_PRIVATE_KEY_FILE}\"\n  else\n    echo \"ERROR: Neither TEST_GITHUB_APP_PRIVATE_KEY_FILE nor TEST_GITHUB_APP_PRIVATE_KEY was specified.\"\n    echo \"       Either provide a value or skip this test (SKIP_GITHUB_APP_TEST=true).\"\n    exit 1\n  fi\n\n  # Validate all required environment variables for the github-app-auth tests are provided.\n  for var in \"${required_env_vars[@]}\"; do\n    if [[ ! -v \"${var}\" ]]; then\n      echo \"ERROR: Required environment variable '${var}' is not set.\"\n      echo \"       Either provide a value or skip this test (SKIP_GITHUB_APP_TEST=true).\"\n      exit 1\n    fi\n  done\n\n  # Mount the GitHub App private key file to the git-sync container\n  GITHUB_APP_PRIVATE_KEY_MOUNT=(-v \"${DIR}/${LOCAL_GITHUB_APP_PRIVATE_KEY_FILE}\":\"/${LOCAL_GITHUB_APP_PRIVATE_KEY_FILE}\":ro)\nfi\n\n# WORK is temp space and in reset for each testcase.\nWORK=\"$DIR/work\"\nfunction clean_work() {\n    rm -rf \"$WORK\"\n    mkdir -p \"$WORK\"\n}\n\n# REPO and REPO2 are the source repos under test.\nREPO=\"$DIR/repo\"\nREPO2=\"${REPO}2\"\nMAIN_BRANCH=\"e2e-branch\"\nfunction init_repo() {\n    arg=\"${1}\"\n\n    rm -rf \"$REPO\"\n    mkdir -p \"$REPO\"\n    git -C \"$REPO\" init -q -b \"$MAIN_BRANCH\"\n    echo \"$arg\" > \"$REPO/file\"\n    git -C \"$REPO\" add file\n    git -C \"$REPO\" commit -aqm \"init file\"\n\n    rm -rf \"$REPO2\"\n    cp -r \"$REPO\" \"$REPO2\"\n}\n\n# ROOT is the volume (usually) used as --root.\nROOT=\"$DIR/root\"\nfunction clean_root() {\n    rm -rf \"$ROOT\"\n    mkdir -p \"$ROOT\"\n    chmod g+rwx \"$ROOT\"\n}\n\n# How long we wait for sync operations to happen between test steps, in seconds\nMAXWAIT=\"${MAXWAIT:-3}\"\n\n# INTERLOCK is a file, under $ROOT, used to coordinate tests and syncs.\nINTERLOCK=\"_sync_lock\"\nfunction wait_for_sync() {\n    if [[ -z \"$1\" ]]; then\n        echo \"usage: $0 <max-wait-seconds>\"\n        return 1\n    fi\n    local path=\"$ROOT/$INTERLOCK\"\n    wait_for_file_exists \"$path\" \"$1\"\n    rm -f \"$path\"\n}\n\n# Init SSH for test cases.\nDOT_SSH=\"$DIR/dot_ssh\"\nfor i in $(seq 1 3); do\n    mkdir -p \"$DOT_SSH/$i\"\n    ssh-keygen -f \"$DOT_SSH/$i/id_test\" -P \"\" >/dev/null\n    cp -a \"$DOT_SSH/$i/id_test\" \"$DOT_SSH/$i/id_local\" # for outside-of-container use\n    mkdir -p \"$DOT_SSH/server/$i\"\n    cat \"$DOT_SSH/$i/id_test.pub\" > \"$DOT_SSH/server/$i/authorized_keys\"\ndone\n# Allow files to be read inside containers running as a different UID.\n# Note: this does not include the *.local forms.\nchmod g+r \"$DOT_SSH\"/*/id_test* \"$DOT_SSH\"/server/*\n\nTEST_TOOLS=\"_test_tools\"\nSLOW_GIT_FETCH=\"$TEST_TOOLS/git_slow_fetch.sh\"\nASKPASS_GIT=\"$TEST_TOOLS/git_askpass.sh\"\nEXECHOOK_COMMAND=\"$TEST_TOOLS/exechook_command.sh\"\nEXECHOOK_COMMAND_FAIL=\"$TEST_TOOLS/exechook_command_fail.sh\"\nEXECHOOK_COMMAND_SLEEPY=\"$TEST_TOOLS/exechook_command_with_sleep.sh\"\nEXECHOOK_COMMAND_FAIL_SLEEPY=\"$TEST_TOOLS/exechook_command_fail_with_sleep.sh\"\nEXECHOOK_ENVKEY=ENVKEY\nEXECHOOK_ENVVAL=envval\nRUNLOG=\"$DIR/runlog\"\nrm -f \"$RUNLOG\"\ntouch \"$RUNLOG\"\nchmod g+rw \"$RUNLOG\"\nHTTP_PORT=9376\nMETRIC_GOOD_SYNC_COUNT='git_sync_count_total{status=\"success\"}'\nMETRIC_FETCH_COUNT='git_fetch_count_total'\n\nfunction GIT_SYNC() {\n    #./bin/linux_amd64/git-sync \"$@\"\n    RM=\"--rm\"\n    if [[ \"${CLEANUP:-}\" == 0 ]]; then\n        RM=\"\"\n    fi\n    docker run \\\n        -i \\\n        ${RM} \\\n        --label git-sync-e2e=\"$RUNID\" \\\n        --network=\"host\" \\\n        -u git-sync:\"$(id -g)\" `# rely on GID, triggering \"dubious ownership\"` \\\n        -v \"$ROOT\":\"$ROOT\":rw \\\n        -v \"$REPO\":\"$REPO\":ro \\\n        -v \"$REPO2\":\"$REPO2\":ro \\\n        -v \"$WORK\":\"$WORK\":ro \\\n        -v \"$(pwd)/$TEST_TOOLS\":\"/$TEST_TOOLS\":ro \\\n        --env \"$EXECHOOK_ENVKEY=$EXECHOOK_ENVVAL\" \\\n        -v \"$RUNLOG\":/var/log/runs \\\n        -v \"$DOT_SSH/1/id_test\":\"/ssh/secret.1\":ro \\\n        -v \"$DOT_SSH/2/id_test\":\"/ssh/secret.2\":ro \\\n        -v \"$DOT_SSH/3/id_test\":\"/ssh/secret.3\":ro \\\n        \"${GITHUB_APP_PRIVATE_KEY_MOUNT[@]}\" \\\n        \"${GIT_SYNC_E2E_IMAGE}\" \\\n            -v=6 \\\n            --add-user \\\n            --group-write \\\n            --touch-file=\"$INTERLOCK\" \\\n            --git-config='protocol.file.allow:always' \\\n            --http-bind=\":$HTTP_PORT\" \\\n            --http-metrics \\\n            --http-pprof \\\n            \"$@\"\n}\n\nfunction remove_containers() {\n    sleep 2 # Let docker finish saving container metadata\n    docker ps --filter label=\"git-sync-e2e=$RUNID\" --format=\"{{.ID}}\" \\\n        | while read -r CTR; do\n            docker kill \"$CTR\" >/dev/null\n        done\n}\n\n#\n# After all the test functions are defined, we can iterate over them and run\n# them all automatically.  See the end of this file.\n#\n\n##############################################\n# Test init when root doesn't exist\n##############################################\nfunction e2e::init_root_doesnt_exist() {\n    GIT_SYNC \\\n        --one-time \\\n        --repo=\"file://$REPO\" \\\n        --root=\"$ROOT/subdir\" \\\n        --link=\"link\"\n    assert_link_exists \"$ROOT/subdir/link\"\n    assert_file_exists \"$ROOT/subdir/link/file\"\n    assert_file_eq \"$ROOT/subdir/link/file\" \"${FUNCNAME[0]}\"\n}\n\n##############################################\n# Test init when root exists and is empty\n##############################################\nfunction e2e::init_root_exists_empty() {\n    GIT_SYNC \\\n        --one-time \\\n        --repo=\"file://$REPO\" \\\n        --root=\"$ROOT\" \\\n        --link=\"link\"\n    assert_link_exists \"$ROOT/link\"\n    assert_file_exists \"$ROOT/link/file\"\n    assert_file_eq \"$ROOT/link/file\" \"${FUNCNAME[0]}\"\n}\n\n##############################################\n# Test init with a weird --root flag\n##############################################\nfunction e2e::init_root_flag_is_weird() {\n    GIT_SYNC \\\n        --one-time \\\n        --repo=\"file://$REPO\" \\\n        --root=\"../../../../../$ROOT/../../../../../../$ROOT\" \\\n        --link=\"link\"\n    assert_link_exists \"$ROOT/link\"\n    assert_file_exists \"$ROOT/link/file\"\n    assert_file_eq \"$ROOT/link/file\" \"${FUNCNAME[0]}\"\n}\n\n##############################################\n# Test init with a symlink in --root\n##############################################\nfunction e2e::init_root_flag_has_symlink() {\n    mkdir -p \"$ROOT/subdir\"\n    ln -s \"$ROOT/subdir\" \"$ROOT/rootlink\" # symlink to test\n\n    GIT_SYNC \\\n        --one-time \\\n        --repo=\"file://$REPO\" \\\n        --root=\"$ROOT/rootlink\" \\\n        --link=\"link\"\n    assert_link_exists \"$ROOT/subdir/link\"\n    assert_file_exists \"$ROOT/subdir/link/file\"\n    assert_file_eq \"$ROOT/subdir/link/file\" \"${FUNCNAME[0]}\"\n}\n\n##############################################\n# Test init when root is under a git repo\n##############################################\nfunction e2e::init_root_is_under_another_repo() {\n    # Make a parent dir that is a git repo.\n    mkdir -p \"$ROOT/subdir/root\"\n    date > \"$ROOT/subdir/root/file\" # so it is not empty\n    git -C \"$ROOT/subdir\" init -q\n\n    GIT_SYNC \\\n        --one-time \\\n        --repo=\"file://$REPO\" \\\n        --root=\"$ROOT/subdir/root\" \\\n        --link=\"link\"\n    assert_link_exists \"$ROOT/subdir/root/link\"\n    assert_file_exists \"$ROOT/subdir/root/link/file\"\n    assert_file_eq \"$ROOT/subdir/root/link/file\" \"${FUNCNAME[0]}\"\n}\n\n##############################################\n# Test init when root fails sanity\n##############################################\nfunction e2e::init_root_fails_sanity() {\n    # Make an invalid git repo.\n    git -C \"$ROOT\" init -q\n    echo \"ref: refs/heads/nonexist\" > \"$ROOT/.git/HEAD\"\n\n    GIT_SYNC \\\n        --one-time \\\n        --repo=\"file://$REPO\" \\\n        --root=\"$ROOT\" \\\n        --link=\"link\"\n    assert_link_exists \"$ROOT/link\"\n    assert_file_exists \"$ROOT/link/file\"\n    assert_file_eq \"$ROOT/link/file\" \"${FUNCNAME[0]}\"\n}\n\n##############################################\n# Test non-zero exit with a bad ref\n##############################################\nfunction e2e::bad_ref_non_zero_exit() {\n    assert_fail \\\n        GIT_SYNC \\\n            --one-time \\\n            --repo=\"file://$REPO\" \\\n            --ref=does-not-exist \\\n            --root=\"$ROOT\" \\\n            --link=\"link\"\n    assert_file_absent \"$ROOT/link\"\n}\n\n##############################################\n# Test default ref syncing\n##############################################\nfunction e2e::sync_default_ref() {\n    # First sync\n    echo \"${FUNCNAME[0]} 1\" > \"$REPO/file\"\n    git -C \"$REPO\" commit -qam \"${FUNCNAME[0]} 1\"\n    git -C \"$REPO\" checkout -q -b weird-name\n\n    GIT_SYNC \\\n        --period=100ms \\\n        --repo=\"file://$REPO\" \\\n        --root=\"$ROOT\" \\\n        --link=\"link\" \\\n        &\n    wait_for_sync \"${MAXWAIT}\"\n    assert_link_exists \"$ROOT/link\"\n    assert_file_exists \"$ROOT/link/file\"\n    assert_file_eq \"$ROOT/link/file\" \"${FUNCNAME[0]} 1\"\n    assert_metric_eq \"${METRIC_GOOD_SYNC_COUNT}\" 1\n    assert_metric_eq \"${METRIC_FETCH_COUNT}\" 1\n\n    # Move forward\n    echo \"${FUNCNAME[0]} 2\" > \"$REPO/file\"\n    git -C \"$REPO\" commit -qam \"${FUNCNAME[0]} 2\"\n    wait_for_sync \"${MAXWAIT}\"\n    assert_link_exists \"$ROOT/link\"\n    assert_file_exists \"$ROOT/link/file\"\n    assert_file_eq \"$ROOT/link/file\" \"${FUNCNAME[0]} 2\"\n    assert_metric_eq \"${METRIC_GOOD_SYNC_COUNT}\" 2\n    assert_metric_eq \"${METRIC_FETCH_COUNT}\" 2\n\n    # Move backward\n    git -C \"$REPO\" reset -q --hard HEAD^\n    wait_for_sync \"${MAXWAIT}\"\n    assert_link_exists \"$ROOT/link\"\n    assert_file_exists \"$ROOT/link/file\"\n    assert_file_eq \"$ROOT/link/file\" \"${FUNCNAME[0]} 1\"\n    assert_metric_eq \"${METRIC_GOOD_SYNC_COUNT}\" 3\n    assert_metric_eq \"${METRIC_FETCH_COUNT}\" 3\n}\n\n##############################################\n# Test HEAD syncing\n##############################################\nfunction e2e::sync_head() {\n    # First sync\n    echo \"${FUNCNAME[0]} 1\" > \"$REPO/file\"\n    git -C \"$REPO\" commit -qam \"${FUNCNAME[0]} 1\"\n\n    GIT_SYNC \\\n        --period=100ms \\\n        --repo=\"file://$REPO\" \\\n        --ref=HEAD \\\n        --root=\"$ROOT\" \\\n        --link=\"link\" \\\n        &\n    wait_for_sync \"${MAXWAIT}\"\n    assert_link_exists \"$ROOT/link\"\n    assert_file_exists \"$ROOT/link/file\"\n    assert_file_eq \"$ROOT/link/file\" \"${FUNCNAME[0]} 1\"\n    assert_metric_eq \"${METRIC_GOOD_SYNC_COUNT}\" 1\n    assert_metric_eq \"${METRIC_FETCH_COUNT}\" 1\n\n    # Move HEAD forward\n    echo \"${FUNCNAME[0]} 2\" > \"$REPO/file\"\n    git -C \"$REPO\" commit -qam \"${FUNCNAME[0]} 2\"\n    wait_for_sync \"${MAXWAIT}\"\n    assert_link_exists \"$ROOT/link\"\n    assert_file_exists \"$ROOT/link/file\"\n    assert_file_eq \"$ROOT/link/file\" \"${FUNCNAME[0]} 2\"\n    assert_metric_eq \"${METRIC_GOOD_SYNC_COUNT}\" 2\n    assert_metric_eq \"${METRIC_FETCH_COUNT}\" 2\n\n    # Move HEAD backward\n    git -C \"$REPO\" reset -q --hard HEAD^\n    wait_for_sync \"${MAXWAIT}\"\n    assert_link_exists \"$ROOT/link\"\n    assert_file_exists \"$ROOT/link/file\"\n    assert_file_eq \"$ROOT/link/file\" \"${FUNCNAME[0]} 1\"\n    assert_metric_eq \"${METRIC_GOOD_SYNC_COUNT}\" 3\n    assert_metric_eq \"${METRIC_FETCH_COUNT}\" 3\n}\n\n##############################################\n# Test sync with an absolute-path link\n##############################################\nfunction e2e::sync_head_absolute_link() {\n    # First sync\n    echo \"${FUNCNAME[0]} 1\" > \"$REPO/file\"\n    git -C \"$REPO\" commit -qam \"${FUNCNAME[0]} 1\"\n\n    GIT_SYNC \\\n        --period=100ms \\\n        --repo=\"file://$REPO\" \\\n        --ref=HEAD \\\n        --root=\"$ROOT/root\" \\\n        --link=\"$ROOT/other/dir/link\" \\\n        &\n    wait_for_sync \"${MAXWAIT}\"\n    assert_file_absent \"$ROOT/root/link\"\n    assert_link_exists \"$ROOT/other/dir/link\"\n    assert_file_exists \"$ROOT/other/dir/link/file\"\n    assert_file_eq \"$ROOT/other/dir/link/file\" \"${FUNCNAME[0]} 1\"\n    assert_metric_eq \"${METRIC_GOOD_SYNC_COUNT}\" 1\n    assert_metric_eq \"${METRIC_FETCH_COUNT}\" 1\n\n    # Move HEAD forward\n    echo \"${FUNCNAME[0]} 2\" > \"$REPO/file\"\n    git -C \"$REPO\" commit -qam \"${FUNCNAME[0]} 2\"\n    wait_for_sync \"${MAXWAIT}\"\n    assert_file_absent \"$ROOT/root/link\"\n    assert_link_exists \"$ROOT/other/dir/link\"\n    assert_file_exists \"$ROOT/other/dir/link/file\"\n    assert_file_eq \"$ROOT/other/dir/link/file\" \"${FUNCNAME[0]} 2\"\n    assert_metric_eq \"${METRIC_GOOD_SYNC_COUNT}\" 2\n    assert_metric_eq \"${METRIC_FETCH_COUNT}\" 2\n\n    # Move HEAD backward\n    git -C \"$REPO\" reset -q --hard HEAD^\n    wait_for_sync \"${MAXWAIT}\"\n    assert_file_absent \"$ROOT/root/link\"\n    assert_link_exists \"$ROOT/other/dir/link\"\n    assert_file_exists \"$ROOT/other/dir/link/file\"\n    assert_file_eq \"$ROOT/other/dir/link/file\" \"${FUNCNAME[0]} 1\"\n    assert_metric_eq \"${METRIC_GOOD_SYNC_COUNT}\" 3\n    assert_metric_eq \"${METRIC_FETCH_COUNT}\" 3\n}\n\n##############################################\n# Test sync with a subdir-path link\n##############################################\nfunction e2e::sync_head_subdir_link() {\n    # First sync\n    echo \"${FUNCNAME[0]} 1\" > \"$REPO/file\"\n    git -C \"$REPO\" commit -qam \"${FUNCNAME[0]} 1\"\n\n    GIT_SYNC \\\n        --period=100ms \\\n        --repo=\"file://$REPO\" \\\n        --ref=HEAD \\\n        --root=\"$ROOT\" \\\n        --link=\"other/dir/link\" \\\n        &\n    wait_for_sync \"${MAXWAIT}\"\n    assert_file_absent \"$ROOT/link\"\n    assert_link_exists \"$ROOT/other/dir/link\"\n    assert_file_exists \"$ROOT/other/dir/link/file\"\n    assert_file_eq \"$ROOT/other/dir/link/file\" \"${FUNCNAME[0]} 1\"\n    assert_metric_eq \"${METRIC_GOOD_SYNC_COUNT}\" 1\n    assert_metric_eq \"${METRIC_FETCH_COUNT}\" 1\n\n    # Move HEAD forward\n    echo \"${FUNCNAME[0]} 2\" > \"$REPO/file\"\n    git -C \"$REPO\" commit -qam \"${FUNCNAME[0]} 2\"\n    wait_for_sync \"${MAXWAIT}\"\n    assert_file_absent \"$ROOT/link\"\n    assert_link_exists \"$ROOT/other/dir/link\"\n    assert_file_exists \"$ROOT/other/dir/link/file\"\n    assert_file_eq \"$ROOT/other/dir/link/file\" \"${FUNCNAME[0]} 2\"\n    assert_metric_eq \"${METRIC_GOOD_SYNC_COUNT}\" 2\n    assert_metric_eq \"${METRIC_FETCH_COUNT}\" 2\n\n    # Move HEAD backward\n    git -C \"$REPO\" reset -q --hard HEAD^\n    wait_for_sync \"${MAXWAIT}\"\n    assert_file_absent \"$ROOT/link\"\n    assert_link_exists \"$ROOT/other/dir/link\"\n    assert_file_exists \"$ROOT/other/dir/link/file\"\n    assert_file_eq \"$ROOT/other/dir/link/file\" \"${FUNCNAME[0]} 1\"\n    assert_metric_eq \"${METRIC_GOOD_SYNC_COUNT}\" 3\n    assert_metric_eq \"${METRIC_FETCH_COUNT}\" 3\n}\n\n##############################################\n# Test worktree-cleanup\n##############################################\nfunction e2e::worktree_cleanup() {\n    GIT_SYNC \\\n        --period=100ms \\\n        --repo=\"file://$REPO\" \\\n        --root=\"$ROOT\" \\\n        --link=\"link\" \\\n        &\n\n    # wait for first sync\n    wait_for_sync \"${MAXWAIT}\"\n    assert_link_exists \"$ROOT/link\"\n    assert_file_exists \"$ROOT/link/file\"\n    assert_file_eq \"$ROOT/link/file\" \"${FUNCNAME[0]}\"\n    assert_metric_eq \"${METRIC_GOOD_SYNC_COUNT}\" 1\n    assert_metric_eq \"${METRIC_FETCH_COUNT}\" 1\n\n    # suspend time so we can fake corruption\n    docker ps --filter label=\"git-sync-e2e=$RUNID\" --format=\"{{.ID}}\" \\\n        | while read -r CTR; do\n            docker pause \"$CTR\" >/dev/null\n        done\n\n    # make a second commit\n    echo \"${FUNCNAME[0]}-ok\" > \"$REPO/file2\"\n    git -C \"$REPO\" add file2\n    git -C \"$REPO\" commit -qam \"${FUNCNAME[0]} new file\"\n\n    # make a worktree to collide with git-sync\n    SHA=$(git -C \"$REPO\" rev-list -n1 HEAD)\n    git -C \"$REPO\" worktree add -q \"$ROOT/.worktrees/$SHA\" -b e2e --no-checkout\n    chmod g+w \"$ROOT/.worktrees/$SHA\"\n\n    # add some garbage\n    mkdir -p \"$ROOT/.worktrees/not_a_hash/subdir\"\n    touch \"$ROOT/.worktrees/not_a_directory\"\n\n    # resume time\n    docker ps --filter label=\"git-sync-e2e=$RUNID\" --format=\"{{.ID}}\" \\\n        | while read -r CTR; do\n            docker unpause \"$CTR\" >/dev/null\n        done\n\n    wait_for_sync \"${MAXWAIT}\"\n    assert_file_exists \"$ROOT/link/file2\"\n    assert_file_eq \"$ROOT/link/file2\" \"${FUNCNAME[0]}-ok\"\n    assert_metric_eq \"${METRIC_GOOD_SYNC_COUNT}\" 2\n    assert_metric_eq \"${METRIC_FETCH_COUNT}\" 2\n    assert_file_absent \"$ROOT/.worktrees/$SHA\"\n    assert_file_absent \"$ROOT/.worktrees/not_a_hash\"\n    assert_file_absent \"$ROOT/.worktrees/not_a_directory\"\n}\n\n##############################################\n# Test worktree unexpected removal\n##############################################\nfunction e2e::worktree_unexpected_removal() {\n    GIT_SYNC \\\n        --period=100ms \\\n        --repo=\"file://$REPO\" \\\n        --root=\"$ROOT\" \\\n        --link=\"link\" \\\n        &\n\n    # wait for first sync\n    wait_for_sync \"${MAXWAIT}\"\n    assert_link_exists \"$ROOT/link\"\n    assert_file_exists \"$ROOT/link/file\"\n    assert_file_eq \"$ROOT/link/file\" \"${FUNCNAME[0]}\"\n    assert_metric_eq \"${METRIC_GOOD_SYNC_COUNT}\" 1\n    assert_metric_eq \"${METRIC_FETCH_COUNT}\" 1\n\n    # suspend time so we can fake corruption\n    docker ps --filter label=\"git-sync-e2e=$RUNID\" --format=\"{{.ID}}\" \\\n        | while read -r CTR; do\n            docker pause \"$CTR\" >/dev/null\n        done\n\n    # make a unexpected removal\n    WT=$(git -C \"$REPO\" rev-list -n1 HEAD)\n    rm -r \"$ROOT/.worktrees/$WT\"\n\n    # resume time\n    docker ps --filter label=\"git-sync-e2e=$RUNID\" --format=\"{{.ID}}\" \\\n        | while read -r CTR; do\n            docker unpause \"$CTR\" >/dev/null\n        done\n\n    wait_for_sync \"${MAXWAIT}\"\n    assert_link_exists \"$ROOT/link\"\n    assert_file_exists \"$ROOT/link/file\"\n    assert_file_eq \"$ROOT/link/file\" \"${FUNCNAME[0]}\"\n    assert_metric_eq \"${METRIC_GOOD_SYNC_COUNT}\" 2\n    assert_metric_eq \"${METRIC_FETCH_COUNT}\" 2\n}\n\n##############################################\n# Test syncing when the worktree is wrong hash\n##############################################\nfunction e2e::sync_recover_wrong_worktree_hash() {\n    GIT_SYNC \\\n        --period=100ms \\\n        --repo=\"file://$REPO\" \\\n        --root=\"$ROOT\" \\\n        --link=\"link\" \\\n        &\n\n    # wait for first sync\n    wait_for_sync \"${MAXWAIT}\"\n    assert_link_exists \"$ROOT/link\"\n    assert_file_exists \"$ROOT/link/file\"\n    assert_file_eq \"$ROOT/link/file\" \"${FUNCNAME[0]}\"\n    assert_metric_eq \"${METRIC_GOOD_SYNC_COUNT}\" 1\n    assert_metric_eq \"${METRIC_FETCH_COUNT}\" 1\n\n    # suspend time so we can fake corruption\n    docker ps --filter label=\"git-sync-e2e=$RUNID\" --format=\"{{.ID}}\" \\\n        | while read -r CTR; do\n            docker pause \"$CTR\" >/dev/null\n        done\n\n    # Corrupt it\n    echo \"unexpected\" > \"$ROOT/link/file\"\n    git -C \"$ROOT/link\" commit -qam \"corrupt it\"\n\n    # resume time\n    docker ps --filter label=\"git-sync-e2e=$RUNID\" --format=\"{{.ID}}\" \\\n        | while read -r CTR; do\n            docker unpause \"$CTR\" >/dev/null\n        done\n\n    wait_for_sync \"${MAXWAIT}\"\n    assert_link_exists \"$ROOT/link\"\n    assert_file_exists \"$ROOT/link/file\"\n    assert_file_eq \"$ROOT/link/file\" \"${FUNCNAME[0]}\"\n    assert_metric_eq \"${METRIC_GOOD_SYNC_COUNT}\" 2\n    assert_metric_eq \"${METRIC_FETCH_COUNT}\" 2\n}\n\n##############################################\n# Test stale-worktree-timeout\n##############################################\nfunction e2e::stale_worktree_timeout() {\n    echo \"${FUNCNAME[0]} 1\" > \"$REPO\"/file\n    git -C \"$REPO\" commit -qam \"${FUNCNAME[0]}\"\n    WT1=$(git -C \"$REPO\" rev-list -n1 HEAD)\n    GIT_SYNC \\\n        --period=100ms \\\n        --repo=\"file://$REPO\" \\\n        --root=\"$ROOT\" \\\n        --link=\"link\" \\\n        --stale-worktree-timeout=\"5s\" \\\n        &\n\n    # wait for first sync\n    wait_for_sync \"${MAXWAIT}\"\n    assert_link_exists \"$ROOT/link\"\n    assert_file_exists \"$ROOT/link/file\"\n    assert_file_eq \"$ROOT/link/file\" \"${FUNCNAME[0]} 1\"\n\n    # wait 2 seconds and make another commit\n    sleep 2\n    echo \"${FUNCNAME[0]} 2\" > \"$REPO\"/file2\n    git -C \"$REPO\" add file2\n    git -C \"$REPO\" commit -qam \"${FUNCNAME[0]} new file\"\n    WT2=$(git -C \"$REPO\" rev-list -n1 HEAD)\n\n    # wait for second sync\n    wait_for_sync \"${MAXWAIT}\"\n    # at this point both WT1 and WT2 should exist, with\n    # link pointing to the new WT2\n    assert_link_exists \"$ROOT/link\"\n    assert_file_exists \"$ROOT/link/file\"\n    assert_file_exists \"$ROOT/link/file2\"\n    assert_file_exists \"$ROOT/.worktrees/$WT1/file\"\n    assert_file_absent \"$ROOT/.worktrees/$WT1/file2\"\n\n    # wait 2 seconds and make a third commit\n    sleep 2\n    echo \"${FUNCNAME[0]} 3\" > \"$REPO\"/file3\n    git -C \"$REPO\" add file3\n    git -C \"$REPO\" commit -qam \"${FUNCNAME[0]} new file\"\n    WT3=$(git -C \"$REPO\" rev-list -n1 HEAD)\n\n    wait_for_sync \"${MAXWAIT}\"\n\n    # at this point WT1, WT2, WT3 should exist, with\n    # link pointing to WT3\n    assert_link_exists \"$ROOT/link\"\n    assert_file_exists \"$ROOT/link/file\"\n    assert_file_exists \"$ROOT/link/file2\"\n    assert_file_exists \"$ROOT/link/file3\"\n    assert_file_exists \"$ROOT/.worktrees/$WT1/file\"\n    assert_file_absent \"$ROOT/.worktrees/$WT1/file2\"\n    assert_file_absent \"$ROOT/.worktrees/$WT1/file3\"\n    assert_file_exists \"$ROOT/.worktrees/$WT2/file\"\n    assert_file_exists \"$ROOT/.worktrees/$WT2/file2\"\n    assert_file_absent \"$ROOT/.worktrees/$WT2/file3\"\n    assert_file_exists \"$ROOT/.worktrees/$WT3/file\"\n    assert_file_exists \"$ROOT/.worktrees/$WT3/file2\"\n    assert_file_exists \"$ROOT/.worktrees/$WT3/file3\"\n\n    # wait for WT1 to go stale\n    sleep 4\n\n    # now WT1 should be stale and deleted,\n    # WT2 and WT3 should still exist\n    assert_link_exists \"$ROOT/link\"\n    assert_file_exists \"$ROOT/link/file\"\n    assert_file_exists \"$ROOT/link/file2\"\n    assert_file_exists \"$ROOT/link/file3\"\n    assert_file_absent \"$ROOT/.worktrees/$WT1/file\"\n    assert_file_absent \"$ROOT/.worktrees/$WT1/file2\"\n    assert_file_absent \"$ROOT/.worktrees/$WT1/file3\"\n    assert_file_exists \"$ROOT/.worktrees/$WT2/file\"\n    assert_file_exists \"$ROOT/.worktrees/$WT2/file2\"\n    assert_file_absent \"$ROOT/.worktrees/$WT2/file3\"\n    assert_file_exists \"$ROOT/.worktrees/$WT3/file\"\n    assert_file_exists \"$ROOT/.worktrees/$WT3/file2\"\n    assert_file_exists \"$ROOT/.worktrees/$WT3/file3\"\n\n    # wait for WT2 to go stale\n    sleep 2\n\n    # now both WT1 and WT2 are stale, WT3 should be the only\n    # worktree left\n    assert_link_exists \"$ROOT/link\"\n    assert_file_exists \"$ROOT/link/file\"\n    assert_file_exists \"$ROOT/link/file2\"\n    assert_file_exists \"$ROOT/link/file3\"\n    assert_file_absent \"$ROOT/.worktrees/$WT1/file\"\n    assert_file_absent \"$ROOT/.worktrees/$WT1/file2\"\n    assert_file_absent \"$ROOT/.worktrees/$WT1/file3\"\n    assert_file_absent \"$ROOT/.worktrees/$WT2/file\"\n    assert_file_absent \"$ROOT/.worktrees/$WT2/file2\"\n    assert_file_absent \"$ROOT/.worktrees/$WT2/file3\"\n    assert_file_exists \"$ROOT/.worktrees/$WT3/file\"\n    assert_file_exists \"$ROOT/.worktrees/$WT3/file2\"\n    assert_file_exists \"$ROOT/.worktrees/$WT3/file3\"\n}\n\n##############################################\n# Test stale-worktree-timeout with restarts\n##############################################\nfunction e2e::stale_worktree_timeout_restart() {\n    echo \"${FUNCNAME[0]} 1\" > \"$REPO\"/file\n    git -C \"$REPO\" commit -qam \"${FUNCNAME[0]}\"\n    WT1=$(git -C \"$REPO\" rev-list -n1 HEAD)\n    GIT_SYNC \\\n        --repo=\"file://$REPO\" \\\n        --root=\"$ROOT\" \\\n        --link=\"link\" \\\n        --one-time\n\n    assert_link_exists \"$ROOT/link\"\n    assert_file_exists \"$ROOT/link/file\"\n    assert_file_eq \"$ROOT/link/file\" \"${FUNCNAME[0]} 1\"\n\n    # wait 2 seconds and make another commit\n    sleep 2\n    echo \"${FUNCNAME[0]} 2\" > \"$REPO\"/file2\n    git -C \"$REPO\" add file2\n    git -C \"$REPO\" commit -qam \"${FUNCNAME[0]} new file\"\n    WT2=$(git -C \"$REPO\" rev-list -n1 HEAD)\n\n    # restart git-sync\n    GIT_SYNC \\\n            --repo=\"file://$REPO\" \\\n            --root=\"$ROOT\" \\\n            --link=\"link\" \\\n            --stale-worktree-timeout=\"10s\" \\\n            --one-time\n\n    # at this point both WT1 and WT2 should exist, with\n    # link pointing to the new WT2\n    assert_link_exists \"$ROOT/link\"\n    assert_file_exists \"$ROOT/link/file\"\n    assert_file_exists \"$ROOT/link/file2\"\n    assert_file_exists \"$ROOT/.worktrees/$WT1/file\"\n    assert_file_absent \"$ROOT/.worktrees/$WT1/file2\"\n\n    # wait 2 seconds and make a third commit\n    sleep 4\n    echo \"${FUNCNAME[0]} 3\" > \"$REPO\"/file3\n    git -C \"$REPO\" add file3\n    git -C \"$REPO\" commit -qam \"${FUNCNAME[0]} new file\"\n    WT3=$(git -C \"$REPO\" rev-list -n1 HEAD)\n\n    # restart git-sync\n    GIT_SYNC \\\n                --repo=\"file://$REPO\" \\\n                --root=\"$ROOT\" \\\n                --link=\"link\" \\\n                --stale-worktree-timeout=\"10s\" \\\n                --one-time\n\n    # at this point WT1, WT2, WT3 should exist, with\n    # link pointing to WT3\n    assert_link_exists \"$ROOT/link\"\n    assert_file_exists \"$ROOT/link/file\"\n    assert_file_exists \"$ROOT/link/file2\"\n    assert_file_exists \"$ROOT/link/file3\"\n    assert_file_exists \"$ROOT/.worktrees/$WT1/file\"\n    assert_file_absent \"$ROOT/.worktrees/$WT1/file2\"\n    assert_file_absent \"$ROOT/.worktrees/$WT1/file3\"\n    assert_file_exists \"$ROOT/.worktrees/$WT2/file\"\n    assert_file_exists \"$ROOT/.worktrees/$WT2/file2\"\n    assert_file_absent \"$ROOT/.worktrees/$WT2/file3\"\n    assert_file_exists \"$ROOT/.worktrees/$WT3/file\"\n    assert_file_exists \"$ROOT/.worktrees/$WT3/file2\"\n    assert_file_exists \"$ROOT/.worktrees/$WT3/file3\"\n\n    # wait for WT1 to go stale and restart git-sync\n    sleep 8\n    GIT_SYNC \\\n            --repo=\"file://$REPO\" \\\n            --root=\"$ROOT\" \\\n            --link=\"link\" \\\n            --stale-worktree-timeout=\"10s\" \\\n            --one-time\n\n    # now WT1 should be stale and deleted,\n    # WT2 and WT3 should still exist\n    assert_link_exists \"$ROOT/link\"\n    assert_file_exists \"$ROOT/link/file\"\n    assert_file_exists \"$ROOT/link/file2\"\n    assert_file_exists \"$ROOT/link/file3\"\n    assert_file_absent \"$ROOT/.worktrees/$WT1/file\"\n    assert_file_absent \"$ROOT/.worktrees/$WT1/file2\"\n    assert_file_absent \"$ROOT/.worktrees/$WT1/file3\"\n    assert_file_exists \"$ROOT/.worktrees/$WT2/file\"\n    assert_file_exists \"$ROOT/.worktrees/$WT2/file2\"\n    assert_file_absent \"$ROOT/.worktrees/$WT2/file3\"\n    assert_file_exists \"$ROOT/.worktrees/$WT3/file\"\n    assert_file_exists \"$ROOT/.worktrees/$WT3/file2\"\n    assert_file_exists \"$ROOT/.worktrees/$WT3/file3\"\n\n    # wait for WT2 to go stale and restart git-sync\n    sleep 4\n    GIT_SYNC \\\n            --repo=\"file://$REPO\" \\\n            --root=\"$ROOT\" \\\n            --link=\"link\" \\\n            --stale-worktree-timeout=\"10s\" \\\n            --one-time\n\n    # now both WT1 and WT2 are stale, WT3 should be the only\n    # worktree left\n    assert_link_exists \"$ROOT/link\"\n    assert_file_exists \"$ROOT/link/file\"\n    assert_file_exists \"$ROOT/link/file2\"\n    assert_file_exists \"$ROOT/link/file3\"\n    assert_file_absent \"$ROOT/.worktrees/$WT1/file\"\n    assert_file_absent \"$ROOT/.worktrees/$WT1/file2\"\n    assert_file_absent \"$ROOT/.worktrees/$WT1/file3\"\n    assert_file_absent \"$ROOT/.worktrees/$WT2/file\"\n    assert_file_absent \"$ROOT/.worktrees/$WT2/file2\"\n    assert_file_absent \"$ROOT/.worktrees/$WT2/file3\"\n    assert_file_exists \"$ROOT/.worktrees/$WT3/file\"\n    assert_file_exists \"$ROOT/.worktrees/$WT3/file2\"\n    assert_file_exists \"$ROOT/.worktrees/$WT3/file3\"\n}\n\n##############################################\n# Test v3->v4 upgrade\n##############################################\nfunction e2e::v3_v4_upgrade_in_place() {\n    echo \"${FUNCNAME[0]} 1\" > \"$REPO/file\"\n    git -C \"$REPO\" commit -qam \"${FUNCNAME[0]}\"\n\n    # sync once\n    GIT_SYNC \\\n        --one-time \\\n        --repo=\"file://$REPO\" \\\n        --root=\"$ROOT\" \\\n        --link=\"link\"\n\n    assert_link_exists \"$ROOT/link\"\n    assert_file_exists \"$ROOT/link/file\"\n    assert_file_eq \"$ROOT/link/file\" \"${FUNCNAME[0]} 1\"\n\n    # simulate v3's worktrees\n    WT=\"$(readlink \"$ROOT/link\")\"\n    SHA=\"$(basename \"$WT\")\"\n    mv -f \"$ROOT/$WT\" \"$ROOT/$SHA\"\n    ln -sf \"$SHA\" \"$ROOT/link\"\n\n    # make a second commit\n    echo \"${FUNCNAME[0]} 2\" > \"$REPO/file2\"\n    git -C \"$REPO\" add file2\n    git -C \"$REPO\" commit -qam \"${FUNCNAME[0]} new file\"\n\n    # sync again\n    GIT_SYNC \\\n        --one-time \\\n        --repo=\"file://$REPO\" \\\n        --root=\"$ROOT\" \\\n        --link=\"link\"\n\n    assert_link_exists \"$ROOT/link\"\n    assert_file_exists \"$ROOT/link/file\"\n    assert_file_eq \"$ROOT/link/file\" \"${FUNCNAME[0]} 1\"\n    assert_file_exists \"$ROOT/link/file2\"\n    assert_file_eq \"$ROOT/link/file2\" \"${FUNCNAME[0]} 2\"\n    assert_file_absent \"$ROOT/$SHA\"\n}\n\n##############################################\n# Test readlink\n##############################################\nfunction e2e::readlink() {\n    # First sync\n    echo \"${FUNCNAME[0]} 1\" > \"$REPO/file\"\n    git -C \"$REPO\" commit -qam \"${FUNCNAME[0]} 1\"\n\n    GIT_SYNC \\\n        --period=100ms \\\n        --repo=\"file://$REPO\" \\\n        --root=\"$ROOT\" \\\n        --link=\"link\" \\\n        &\n    wait_for_sync \"${MAXWAIT}\"\n    assert_link_exists \"$ROOT/link\"\n    assert_link_basename_eq \"$ROOT/link\" \"$(git -C \"$REPO\" rev-parse HEAD)\"\n\n    # Move HEAD forward\n    echo \"${FUNCNAME[0]} 2\" > \"$REPO/file\"\n    git -C \"$REPO\" commit -qam \"${FUNCNAME[0]} 2\"\n    wait_for_sync \"${MAXWAIT}\"\n    assert_link_exists \"$ROOT/link\"\n    assert_link_basename_eq \"$ROOT/link\" \"$(git -C \"$REPO\" rev-parse HEAD)\"\n\n    # Move HEAD backward\n    git -C \"$REPO\" reset -q --hard HEAD^\n    wait_for_sync \"${MAXWAIT}\"\n    assert_link_exists \"$ROOT/link\"\n    assert_link_basename_eq \"$ROOT/link\" \"$(git -C \"$REPO\" rev-parse HEAD)\"\n}\n\n##############################################\n# Test branch syncing\n##############################################\nfunction e2e::sync_branch() {\n    OTHER_BRANCH=\"other-branch\"\n\n    # First sync\n    git -C \"$REPO\" checkout -q -b \"$OTHER_BRANCH\"\n    echo \"${FUNCNAME[0]} 1\" > \"$REPO/file\"\n    git -C \"$REPO\" commit -qam \"${FUNCNAME[0]} 1\"\n    git -C \"$REPO\" checkout -q \"$MAIN_BRANCH\"\n\n    GIT_SYNC \\\n        --period=100ms \\\n        --repo=\"file://$REPO\" \\\n        --ref=\"$OTHER_BRANCH\" \\\n        --root=\"$ROOT\" \\\n        --link=\"link\" \\\n        &\n    wait_for_sync \"${MAXWAIT}\"\n    assert_link_exists \"$ROOT/link\"\n    assert_file_exists \"$ROOT/link/file\"\n    assert_file_eq \"$ROOT/link/file\" \"${FUNCNAME[0]} 1\"\n    assert_metric_eq \"${METRIC_GOOD_SYNC_COUNT}\" 1\n    assert_metric_eq \"${METRIC_FETCH_COUNT}\" 1\n\n    # Add to the branch.\n    git -C \"$REPO\" checkout -q \"$OTHER_BRANCH\"\n    echo \"${FUNCNAME[0]} 2\" > \"$REPO/file\"\n    git -C \"$REPO\" commit -qam \"${FUNCNAME[0]} 2\"\n    git -C \"$REPO\" checkout -q \"$MAIN_BRANCH\"\n    wait_for_sync \"${MAXWAIT}\"\n    assert_link_exists \"$ROOT/link\"\n    assert_file_exists \"$ROOT/link/file\"\n    assert_file_eq \"$ROOT/link/file\" \"${FUNCNAME[0]} 2\"\n    assert_metric_eq \"${METRIC_GOOD_SYNC_COUNT}\" 2\n    assert_metric_eq \"${METRIC_FETCH_COUNT}\" 2\n\n    # Move the branch backward\n    git -C \"$REPO\" checkout -q \"$OTHER_BRANCH\"\n    git -C \"$REPO\" reset -q --hard HEAD^\n    git -C \"$REPO\" checkout -q \"$MAIN_BRANCH\"\n    wait_for_sync \"${MAXWAIT}\"\n    assert_link_exists \"$ROOT/link\"\n    assert_file_exists \"$ROOT/link/file\"\n    assert_file_eq \"$ROOT/link/file\" \"${FUNCNAME[0]} 1\"\n    assert_metric_eq \"${METRIC_GOOD_SYNC_COUNT}\" 3\n    assert_metric_eq \"${METRIC_FETCH_COUNT}\" 3\n}\n\n##############################################\n# Test switching branch after depth=1 checkout\n##############################################\nfunction e2e::sync_branch_switch() {\n    # First sync\n    echo \"${FUNCNAME[0]} 1\" > \"$REPO/file\"\n    git -C \"$REPO\" commit -qam \"${FUNCNAME[0]} 1\"\n\n    GIT_SYNC \\\n        --one-time \\\n        --repo=\"file://$REPO\" \\\n        --ref=\"$MAIN_BRANCH\" \\\n        --depth=1 \\\n        --root=\"$ROOT\" \\\n        --link=\"link\"\n    assert_link_exists \"$ROOT/link\"\n    assert_file_exists \"$ROOT/link/file\"\n    assert_file_eq \"$ROOT/link/file\" \"${FUNCNAME[0]} 1\"\n\n    OTHER_BRANCH=\"${MAIN_BRANCH}2\"\n    git -C \"$REPO\" checkout -q -b $OTHER_BRANCH\n    echo \"${FUNCNAME[0]} 2\" > \"$REPO/file\"\n    git -C \"$REPO\" commit -qam \"${FUNCNAME[0]} 2\"\n\n    GIT_SYNC \\\n        --one-time \\\n        --repo=\"file://$REPO\" \\\n        --ref=\"$OTHER_BRANCH\" \\\n        --root=\"$ROOT\" \\\n        --link=\"link\"\n    assert_link_exists \"$ROOT/link\"\n    assert_file_exists \"$ROOT/link/file\"\n    assert_file_eq \"$ROOT/link/file\" \"${FUNCNAME[0]} 2\"\n}\n\n##############################################\n# Test tag syncing\n##############################################\nfunction e2e::sync_tag() {\n    TAG=\"e2e-tag\"\n\n    # First sync\n    echo \"${FUNCNAME[0]} 1\" > \"$REPO/file\"\n    git -C \"$REPO\" commit -qam \"${FUNCNAME[0]} 1\"\n    git -C \"$REPO\" tag -f \"$TAG\" >/dev/null\n\n    GIT_SYNC \\\n        --period=100ms \\\n        --repo=\"file://$REPO\" \\\n        --ref=\"$TAG\" \\\n        --root=\"$ROOT\" \\\n        --link=\"link\" \\\n        &\n    wait_for_sync \"${MAXWAIT}\"\n    assert_link_exists \"$ROOT/link\"\n    assert_file_exists \"$ROOT/link/file\"\n    assert_file_eq \"$ROOT/link/file\" \"${FUNCNAME[0]} 1\"\n    assert_metric_eq \"${METRIC_GOOD_SYNC_COUNT}\" 1\n    assert_metric_eq \"${METRIC_FETCH_COUNT}\" 1\n\n    # Add something and move the tag forward\n    echo \"${FUNCNAME[0]} 2\" > \"$REPO/file\"\n    git -C \"$REPO\" commit -qam \"${FUNCNAME[0]} 2\"\n    git -C \"$REPO\" tag -f \"$TAG\" >/dev/null\n    wait_for_sync \"${MAXWAIT}\"\n    assert_link_exists \"$ROOT/link\"\n    assert_file_exists \"$ROOT/link/file\"\n    assert_file_eq \"$ROOT/link/file\" \"${FUNCNAME[0]} 2\"\n    assert_metric_eq \"${METRIC_GOOD_SYNC_COUNT}\" 2\n    assert_metric_eq \"${METRIC_FETCH_COUNT}\" 2\n\n    # Move the tag backward\n    git -C \"$REPO\" reset -q --hard HEAD^\n    git -C \"$REPO\" tag -f \"$TAG\" >/dev/null\n    wait_for_sync \"${MAXWAIT}\"\n    assert_link_exists \"$ROOT/link\"\n    assert_file_exists \"$ROOT/link/file\"\n    assert_file_eq \"$ROOT/link/file\" \"${FUNCNAME[0]} 1\"\n    assert_metric_eq \"${METRIC_GOOD_SYNC_COUNT}\" 3\n    assert_metric_eq \"${METRIC_FETCH_COUNT}\" 3\n\n    # Add something after the tag\n    echo \"${FUNCNAME[0]} 3\" > \"$REPO/file\"\n    git -C \"$REPO\" commit -qam \"${FUNCNAME[0]} 3\"\n    sleep 1 # touch-file will not be touched\n    assert_link_exists \"$ROOT/link\"\n    assert_file_exists \"$ROOT/link/file\"\n    assert_file_eq \"$ROOT/link/file\" \"${FUNCNAME[0]} 1\"\n    assert_metric_eq \"${METRIC_GOOD_SYNC_COUNT}\" 3\n    assert_metric_eq \"${METRIC_FETCH_COUNT}\" 3\n}\n\n##############################################\n# Test tag syncing with annotated tags\n##############################################\nfunction e2e::sync_annotated_tag() {\n    TAG=\"e2e-tag\"\n\n    # First sync\n    echo \"${FUNCNAME[0]} 1\" > \"$REPO/file\"\n    git -C \"$REPO\" commit -qam \"${FUNCNAME[0]} 1\"\n    git -C \"$REPO\" tag -af \"$TAG\" -m \"${FUNCNAME[0]} 1\" >/dev/null\n\n    GIT_SYNC \\\n        --period=100ms \\\n        --repo=\"file://$REPO\" \\\n        --ref=\"$TAG\" \\\n        --root=\"$ROOT\" \\\n        --link=\"link\" \\\n        &\n    wait_for_sync \"${MAXWAIT}\"\n    assert_link_exists \"$ROOT/link\"\n    assert_file_exists \"$ROOT/link/file\"\n    assert_file_eq \"$ROOT/link/file\" \"${FUNCNAME[0]} 1\"\n    assert_metric_eq \"${METRIC_GOOD_SYNC_COUNT}\" 1\n    assert_metric_eq \"${METRIC_FETCH_COUNT}\" 1\n\n    # Add something and move the tag forward\n    echo \"${FUNCNAME[0]} 2\" > \"$REPO/file\"\n    git -C \"$REPO\" commit -qam \"${FUNCNAME[0]} 2\"\n    git -C \"$REPO\" tag -af \"$TAG\" -m \"${FUNCNAME[0]} 2\" >/dev/null\n    wait_for_sync \"${MAXWAIT}\"\n    assert_link_exists \"$ROOT/link\"\n    assert_file_exists \"$ROOT/link/file\"\n    assert_file_eq \"$ROOT/link/file\" \"${FUNCNAME[0]} 2\"\n    assert_metric_eq \"${METRIC_GOOD_SYNC_COUNT}\" 2\n    assert_metric_eq \"${METRIC_FETCH_COUNT}\" 2\n\n    # Move the tag backward\n    git -C \"$REPO\" reset -q --hard HEAD^\n    git -C \"$REPO\" tag -af \"$TAG\" -m \"${FUNCNAME[0]} 3\" >/dev/null\n    wait_for_sync \"${MAXWAIT}\"\n    assert_link_exists \"$ROOT/link\"\n    assert_file_exists \"$ROOT/link/file\"\n    assert_file_eq \"$ROOT/link/file\" \"${FUNCNAME[0]} 1\"\n    assert_metric_eq \"${METRIC_GOOD_SYNC_COUNT}\" 3\n    assert_metric_eq \"${METRIC_FETCH_COUNT}\" 3\n\n    # Add something after the tag\n    echo \"${FUNCNAME[0]} 3\" > \"$REPO/file\"\n    git -C \"$REPO\" commit -qam \"${FUNCNAME[0]} 3\"\n    sleep 1 # touch-file will not be touched\n    assert_link_exists \"$ROOT/link\"\n    assert_file_exists \"$ROOT/link/file\"\n    assert_file_eq \"$ROOT/link/file\" \"${FUNCNAME[0]} 1\"\n    assert_metric_eq \"${METRIC_GOOD_SYNC_COUNT}\" 3\n    assert_metric_eq \"${METRIC_FETCH_COUNT}\" 3\n}\n\n##############################################\n# Test SHA syncing\n##############################################\nfunction e2e::sync_sha() {\n    # First sync\n    echo \"${FUNCNAME[0]} 1\" > \"$REPO/file\"\n    git -C \"$REPO\" commit -qam \"${FUNCNAME[0]} 1\"\n    SHA=$(git -C \"$REPO\" rev-list -n1 HEAD)\n\n    GIT_SYNC \\\n        --period=100ms \\\n        --repo=\"file://$REPO\" \\\n        --ref=\"$SHA\" \\\n        --root=\"$ROOT\" \\\n        --link=\"link\" \\\n        &\n    wait_for_sync \"${MAXWAIT}\"\n    assert_link_exists \"$ROOT/link\"\n    assert_file_exists \"$ROOT/link/file\"\n    assert_file_eq \"$ROOT/link/file\" \"${FUNCNAME[0]} 1\"\n    assert_metric_eq \"${METRIC_GOOD_SYNC_COUNT}\" 1\n    assert_metric_eq \"${METRIC_FETCH_COUNT}\" 1\n\n    # Commit something new\n    echo \"${FUNCNAME[0]} 2\" > \"$REPO/file\"\n    git -C \"$REPO\" commit -qam \"${FUNCNAME[0]} 2\"\n    sleep 1 # touch-file will not be touched\n    assert_link_exists \"$ROOT/link\"\n    assert_file_exists \"$ROOT/link/file\"\n    assert_file_eq \"$ROOT/link/file\" \"${FUNCNAME[0]} 1\"\n    assert_metric_eq \"${METRIC_GOOD_SYNC_COUNT}\" 1\n    assert_metric_eq \"${METRIC_FETCH_COUNT}\" 1\n\n    # Revert the last change\n    git -C \"$REPO\" reset -q --hard HEAD^\n    sleep 1 # touch-file will not be touched\n    assert_link_exists \"$ROOT/link\"\n    assert_file_exists \"$ROOT/link/file\"\n    assert_file_eq \"$ROOT/link/file\" \"${FUNCNAME[0]} 1\"\n    assert_metric_eq \"${METRIC_GOOD_SYNC_COUNT}\" 1\n    assert_metric_eq \"${METRIC_FETCH_COUNT}\" 1\n}\n\n##############################################\n# Test SHA-sync one-time\n##############################################\nfunction e2e::sync_sha_once() {\n    SHA=$(git -C \"$REPO\" rev-list -n1 HEAD)\n\n    GIT_SYNC \\\n        --one-time \\\n        --repo=\"file://$REPO\" \\\n        --ref=\"$SHA\" \\\n        --root=\"$ROOT\" \\\n        --link=\"link\"\n    assert_link_exists \"$ROOT/link\"\n    assert_file_exists \"$ROOT/link/file\"\n    assert_file_eq \"$ROOT/link/file\" \"${FUNCNAME[0]}\"\n}\n\n##############################################\n# Test SHA-sync on a different SHA we already have\n##############################################\nfunction e2e::sync_sha_once_sync_different_sha_known() {\n    # All revs will be known because we check out the branch\n    echo \"${FUNCNAME[0]} 1\" > \"$REPO/file\"\n    git -C \"$REPO\" commit -qam \"${FUNCNAME[0]} 1\"\n    SHA1=$(git -C \"$REPO\" rev-list -n1 HEAD)\n    echo \"${FUNCNAME[0]} 2\" > \"$REPO/file\"\n    git -C \"$REPO\" commit -qam \"${FUNCNAME[0]} 2\"\n    SHA2=$(git -C \"$REPO\" rev-list -n1 HEAD)\n    echo \"${FUNCNAME[0]} 3\" > \"$REPO/file\"\n    git -C \"$REPO\" commit -qam \"${FUNCNAME[0]} 3\"\n\n    # Sync SHA1\n    GIT_SYNC \\\n        --one-time \\\n        --repo=\"file://$REPO\" \\\n        --ref=\"$SHA1\" \\\n        --root=\"$ROOT\" \\\n        --link=\"link\"\n    assert_link_exists \"$ROOT/link\"\n    assert_file_exists \"$ROOT/link/file\"\n    assert_file_eq \"$ROOT/link/file\" \"${FUNCNAME[0]} 1\"\n\n    # Sync SHA2\n    GIT_SYNC \\\n        --one-time \\\n        --repo=\"file://$REPO\" \\\n        --ref=\"$SHA2\" \\\n        --root=\"$ROOT\" \\\n        --link=\"link\"\n    assert_link_exists \"$ROOT/link\"\n    assert_file_exists \"$ROOT/link/file\"\n    assert_file_eq \"$ROOT/link/file\" \"${FUNCNAME[0]} 2\"\n}\n\n##############################################\n# Test SHA-sync on a different SHA we do not have\n##############################################\nfunction e2e::sync_sha_once_sync_different_sha_unknown() {\n    echo \"${FUNCNAME[0]} 1\" > \"$REPO/file\"\n    git -C \"$REPO\" commit -qam \"${FUNCNAME[0]} 1\"\n    SHA1=$(git -C \"$REPO\" rev-list -n1 HEAD)\n\n    # Sync SHA1\n    GIT_SYNC \\\n        --one-time \\\n        --repo=\"file://$REPO\" \\\n        --ref=\"$SHA1\" \\\n        --root=\"$ROOT\" \\\n        --link=\"link\"\n    assert_link_exists \"$ROOT/link\"\n    assert_file_exists \"$ROOT/link/file\"\n    assert_file_eq \"$ROOT/link/file\" \"${FUNCNAME[0]} 1\"\n\n    # The locally synced repo does not know this new SHA.\n    echo \"${FUNCNAME[0]} 2\" > \"$REPO/file\"\n    git -C \"$REPO\" commit -qam \"${FUNCNAME[0]} 2\"\n    SHA2=$(git -C \"$REPO\" rev-list -n1 HEAD)\n    # Make sure the SHA is not at HEAD, to prevent things that only work in\n    # that case.\n    echo \"${FUNCNAME[0]} 3\" > \"$REPO/file\"\n    git -C \"$REPO\" commit -qam \"${FUNCNAME[0]} 3\"\n\n    # Sync SHA2\n    GIT_SYNC \\\n        --one-time \\\n        --repo=\"file://$REPO\" \\\n        --ref=\"$SHA2\" \\\n        --root=\"$ROOT\" \\\n        --link=\"link\"\n    assert_link_exists \"$ROOT/link\"\n    assert_file_exists \"$ROOT/link/file\"\n    assert_file_eq \"$ROOT/link/file\" \"${FUNCNAME[0]} 2\"\n}\n\n##############################################\n# Test syncing after a crash\n##############################################\nfunction e2e::sync_crash_no_link_cleanup_retry() {\n    # First sync\n    GIT_SYNC \\\n        --one-time \\\n        --repo=\"file://$REPO\" \\\n        --root=\"$ROOT\" \\\n        --link=\"link\"\n    assert_link_exists \"$ROOT/link\"\n    assert_file_exists \"$ROOT/link/file\"\n    assert_file_eq \"$ROOT/link/file\" \"${FUNCNAME[0]}\"\n\n    # Corrupt it\n    rm -f \"$ROOT/link\"\n\n    # Try again\n    GIT_SYNC \\\n        --one-time \\\n        --repo=\"file://$REPO\" \\\n        --root=\"$ROOT\" \\\n        --link=\"link\"\n    assert_link_exists \"$ROOT/link\"\n    assert_file_exists \"$ROOT/link/file\"\n    assert_file_eq \"$ROOT/link/file\" \"${FUNCNAME[0]}\"\n}\n\n##############################################\n# Test syncing after a crash\n##############################################\nfunction e2e::sync_crash_no_worktree_cleanup_retry() {\n    # First sync\n    GIT_SYNC \\\n        --one-time \\\n        --repo=\"file://$REPO\" \\\n        --root=\"$ROOT\" \\\n        --link=\"link\"\n    assert_link_exists \"$ROOT/link\"\n    assert_file_exists \"$ROOT/link/file\"\n    assert_file_eq \"$ROOT/link/file\" \"${FUNCNAME[0]}\"\n\n    # Corrupt it\n    rm -rf \"$ROOT/.worktrees/\"\n\n    # Try again\n    GIT_SYNC \\\n        --one-time \\\n        --repo=\"file://$REPO\" \\\n        --root=\"$ROOT\" \\\n        --link=\"link\"\n    assert_link_exists \"$ROOT/link\"\n    assert_file_exists \"$ROOT/link/file\"\n    assert_file_eq \"$ROOT/link/file\" \"${FUNCNAME[0]}\"\n}\n\n##############################################\n# Test changing repos with storage intact\n##############################################\nfunction e2e::sync_repo_switch() {\n    # Prepare first repo\n    echo \"${FUNCNAME[0]} 1\" > \"$REPO/file\"\n    git -C \"$REPO\" commit -qam \"${FUNCNAME[0]} 1\"\n\n    # First sync\n    GIT_SYNC \\\n        --repo=\"file://$REPO\" \\\n        --root=\"$ROOT\" \\\n        --link=\"link\" \\\n        --one-time\n    assert_link_exists \"$ROOT/link\"\n    assert_file_exists \"$ROOT/link/file\"\n    assert_file_eq \"$ROOT/link/file\" \"${FUNCNAME[0]} 1\"\n\n    # Prepare other repo\n    echo \"${FUNCNAME[0]} 2\" > \"$REPO2/file\"\n    git -C \"$REPO2\" commit -qam \"${FUNCNAME[0]} 2\"\n\n    # Now sync the other repo\n    GIT_SYNC \\\n        --repo=\"file://$REPO2\" \\\n        --root=\"$ROOT\" \\\n        --link=\"link\" \\\n        --one-time\n    assert_link_exists \"$ROOT/link\"\n    assert_file_exists \"$ROOT/link/file\"\n    assert_file_eq \"$ROOT/link/file\" \"${FUNCNAME[0]} 2\"\n}\n\n##############################################\n# Test with slow git, short timeout\n##############################################\nfunction e2e::error_slow_git_short_timeout() {\n    assert_fail \\\n        GIT_SYNC \\\n            --git=\"/$SLOW_GIT_FETCH\" \\\n            --one-time \\\n            --sync-timeout=1s \\\n            --repo=\"file://$REPO\" \\\n            --root=\"$ROOT\" \\\n            --link=\"link\"\n    assert_file_absent \"$ROOT/link/file\"\n}\n\n##############################################\n# Test with slow git, long timeout\n##############################################\nfunction e2e::sync_slow_git_long_timeout() {\n    # First sync\n    echo \"${FUNCNAME[0]} 1\" > \"$REPO/file\"\n    git -C \"$REPO\" commit -qam \"${FUNCNAME[0]} 1\"\n\n    # run with slow_git_clone but without timing out\n    GIT_SYNC \\\n        --git=\"/$SLOW_GIT_FETCH\" \\\n        --period=100ms \\\n        --sync-timeout=16s \\\n        --repo=\"file://$REPO\" \\\n        --root=\"$ROOT\" \\\n        --link=\"link\" \\\n        &\n    wait_for_sync \"$((MAXWAIT * 3))\"\n    assert_link_exists \"$ROOT/link\"\n    assert_file_exists \"$ROOT/link/file\"\n    assert_file_eq \"$ROOT/link/file\" \"${FUNCNAME[0]} 1\"\n    assert_metric_eq \"${METRIC_GOOD_SYNC_COUNT}\" 1\n    assert_metric_eq \"${METRIC_FETCH_COUNT}\" 1\n\n    # Move forward\n    echo \"${FUNCNAME[0]} 2\" > \"$REPO/file\"\n    git -C \"$REPO\" commit -qam \"${FUNCNAME[0]} 2\"\n    wait_for_sync \"$((MAXWAIT * 3))\"\n    assert_link_exists \"$ROOT/link\"\n    assert_file_exists \"$ROOT/link/file\"\n    assert_file_eq \"$ROOT/link/file\" \"${FUNCNAME[0]} 2\"\n    assert_metric_eq \"${METRIC_GOOD_SYNC_COUNT}\" 2\n    assert_metric_eq \"${METRIC_FETCH_COUNT}\" 2\n}\n\n##############################################\n# Test sync-on-signal with SIGHUP\n##############################################\nfunction e2e::sync_on_signal_sighup() {\n     # First sync\n    echo \"${FUNCNAME[0]} 1\" > \"$REPO/file\"\n    git -C \"$REPO\" commit -qam \"${FUNCNAME[0]} 1\"\n\n    GIT_SYNC \\\n        --period=100s \\\n        --sync-on-signal=\"SIGHUP\" \\\n        --repo=\"file://$REPO\" \\\n        --root=\"$ROOT\" \\\n        --link=\"link\" \\\n        &\n    wait_for_sync 3\n    assert_link_exists \"$ROOT/link\"\n    assert_file_exists \"$ROOT/link/file\"\n    assert_file_eq \"$ROOT/link/file\" \"${FUNCNAME[0]} 1\"\n\n    # Move HEAD forward\n    echo \"${FUNCNAME[0]} 2\" > \"$REPO/file\"\n    git -C \"$REPO\" commit -qam \"${FUNCNAME[0]} 2\"\n    # Send signal (note --period is 100s, signal should trigger sync)\n    CTR=$(docker ps --filter label=\"git-sync-e2e=$RUNID\" --format=\"{{.ID}}\")\n    docker_signal \"$CTR\" SIGHUP\n    wait_for_sync 3\n    assert_link_exists \"$ROOT/link\"\n    assert_file_exists \"$ROOT/link/file\"\n    assert_file_eq \"$ROOT/link/file\" \"${FUNCNAME[0]} 2\"\n}\n\n##############################################\n# Test sync-on-signal with HUP\n##############################################\nfunction e2e::sync_on_signal_hup() {\n     # First sync\n    echo \"${FUNCNAME[0]} 1\" > \"$REPO/file\"\n    git -C \"$REPO\" commit -qam \"${FUNCNAME[0]} 1\"\n\n    GIT_SYNC \\\n        --period=100s \\\n        --sync-on-signal=\"HUP\" \\\n        --repo=\"file://$REPO\" \\\n        --root=\"$ROOT\" \\\n        --link=\"link\" \\\n        &\n    wait_for_sync 3\n    assert_link_exists \"$ROOT/link\"\n    assert_file_exists \"$ROOT/link/file\"\n    assert_file_eq \"$ROOT/link/file\" \"${FUNCNAME[0]} 1\"\n\n    # Move HEAD forward\n    echo \"${FUNCNAME[0]} 2\" > \"$REPO/file\"\n    git -C \"$REPO\" commit -qam \"${FUNCNAME[0]} 2\"\n    # Send signal (note --period is 100s, signal should trigger sync)\n    CTR=$(docker ps --filter label=\"git-sync-e2e=$RUNID\" --format=\"{{.ID}}\")\n    docker_signal \"$CTR\" SIGHUP\n    wait_for_sync 3\n    assert_link_exists \"$ROOT/link\"\n    assert_file_exists \"$ROOT/link/file\"\n    assert_file_eq \"$ROOT/link/file\" \"${FUNCNAME[0]} 2\"\n}\n\n##############################################\n# Test sync-on-signal with 1 (SIGHUP)\n##############################################\nfunction e2e::sync_on_signal_1() {\n     # First sync\n    echo \"${FUNCNAME[0]} 1\" > \"$REPO/file\"\n    git -C \"$REPO\" commit -qam \"${FUNCNAME[0]} 1\"\n\n    GIT_SYNC \\\n        --period=100s \\\n        --sync-on-signal=1 \\\n        --repo=\"file://$REPO\" \\\n        --root=\"$ROOT\" \\\n        --link=\"link\" \\\n        &\n    wait_for_sync 3\n    assert_link_exists \"$ROOT/link\"\n    assert_file_exists \"$ROOT/link/file\"\n    assert_file_eq \"$ROOT/link/file\" \"${FUNCNAME[0]} 1\"\n\n    # Move HEAD forward\n    echo \"${FUNCNAME[0]} 2\" > \"$REPO/file\"\n    git -C \"$REPO\" commit -qam \"${FUNCNAME[0]} 2\"\n    # Send signal (note --period is 100s, signal should trigger sync)\n    CTR=$(docker ps --filter label=\"git-sync-e2e=$RUNID\" --format=\"{{.ID}}\")\n    docker_signal \"$CTR\" SIGHUP\n    wait_for_sync 3\n    assert_link_exists \"$ROOT/link\"\n    assert_file_exists \"$ROOT/link/file\"\n    assert_file_eq \"$ROOT/link/file\" \"${FUNCNAME[0]} 2\"\n}\n\n##############################################\n# Test depth default is shallow\n##############################################\nfunction e2e::sync_depth_default_shallow() {\n    echo \"${FUNCNAME[0]} 1\" > \"$REPO/file\"\n    git -C \"$REPO\" commit -qam \"${FUNCNAME[0]} 1\"\n    echo \"${FUNCNAME[0]} 2\" > \"$REPO/file\"\n    git -C \"$REPO\" commit -qam \"${FUNCNAME[0]} 2\"\n    echo \"${FUNCNAME[0]} 3\" > \"$REPO/file\"\n    git -C \"$REPO\" commit -qam \"${FUNCNAME[0]} 3\"\n\n    GIT_SYNC \\\n        --one-time \\\n        --repo=\"file://$REPO\" \\\n        --root=\"$ROOT\" \\\n        --link=\"link\"\n    assert_link_exists \"$ROOT/link\"\n    assert_file_exists \"$ROOT/link/file\"\n    depth=$(git -C \"$ROOT/link\" rev-list HEAD | wc -l)\n    if [[ $depth != 1 ]]; then\n        fail \"expected depth 1, got $depth\"\n    fi\n}\n\n##############################################\n# Test depth syncing across updates\n##############################################\nfunction e2e::sync_depth_across_updates() {\n    # First sync\n    expected_depth=\"1\"\n    echo \"${FUNCNAME[0]} 1\" > \"$REPO/file\"\n    git -C \"$REPO\" commit -qam \"${FUNCNAME[0]} 1\"\n\n    GIT_SYNC \\\n        --period=100ms \\\n        --repo=\"file://$REPO\" \\\n        --depth=\"$expected_depth\" \\\n        --root=\"$ROOT\" \\\n        --link=\"link\" \\\n        &\n    wait_for_sync \"${MAXWAIT}\"\n    assert_link_exists \"$ROOT/link\"\n    assert_file_exists \"$ROOT/link/file\"\n    assert_file_eq \"$ROOT/link/file\" \"${FUNCNAME[0]} 1\"\n    assert_metric_eq \"${METRIC_GOOD_SYNC_COUNT}\" 1\n    assert_metric_eq \"${METRIC_FETCH_COUNT}\" 1\n    depth=$(git -C \"$ROOT/link\" rev-list HEAD | wc -l)\n    if [[ \"$expected_depth\" != \"$depth\" ]]; then\n        fail \"initial: expected depth $expected_depth, got $depth\"\n    fi\n\n    # Move forward\n    echo \"${FUNCNAME[0]} 2\" > \"$REPO/file\"\n    git -C \"$REPO\" commit -qam \"${FUNCNAME[0]} 2\"\n    wait_for_sync \"${MAXWAIT}\"\n    assert_link_exists \"$ROOT/link\"\n    assert_file_exists \"$ROOT/link/file\"\n    assert_file_eq \"$ROOT/link/file\" \"${FUNCNAME[0]} 2\"\n    assert_metric_eq \"${METRIC_GOOD_SYNC_COUNT}\" 2\n    assert_metric_eq \"${METRIC_FETCH_COUNT}\" 2\n    depth=$(git -C \"$ROOT/link\" rev-list HEAD | wc -l)\n    if [[ \"$expected_depth\" != \"$depth\" ]]; then\n        fail \"forward: expected depth $expected_depth, got $depth\"\n    fi\n\n    # Move backward\n    git -C \"$REPO\" reset -q --hard HEAD^\n    wait_for_sync \"${MAXWAIT}\"\n    assert_link_exists \"$ROOT/link\"\n    assert_file_exists \"$ROOT/link/file\"\n    assert_file_eq \"$ROOT/link/file\" \"${FUNCNAME[0]} 1\"\n    assert_metric_eq \"${METRIC_GOOD_SYNC_COUNT}\" 3\n    assert_metric_eq \"${METRIC_FETCH_COUNT}\" 3\n    depth=$(git -C \"$ROOT/link\" rev-list HEAD | wc -l)\n    if [[ \"$expected_depth\" != \"$depth\" ]]; then\n        fail \"backward: expected depth $expected_depth, got $depth\"\n    fi\n}\n\n##############################################\n# Test depth switching on back-to-back runs\n##############################################\nfunction e2e::sync_depth_change_on_restart() {\n    echo \"${FUNCNAME[0]} 1\" > \"$REPO/file\"\n    git -C \"$REPO\" commit -qam \"${FUNCNAME[0]} 1\"\n    echo \"${FUNCNAME[0]} 2\" > \"$REPO/file\"\n    git -C \"$REPO\" commit -qam \"${FUNCNAME[0]} 2\"\n    echo \"${FUNCNAME[0]} 3\" > \"$REPO/file\"\n    git -C \"$REPO\" commit -qam \"${FUNCNAME[0]} 3\"\n\n    # Sync depth=1\n    GIT_SYNC \\\n        --one-time \\\n        --repo=\"file://$REPO\" \\\n        --depth=1 \\\n        --root=\"$ROOT\" \\\n        --link=\"link\"\n    wait_for_sync \"${MAXWAIT}\"\n    assert_link_exists \"$ROOT/link\"\n    assert_file_exists \"$ROOT/link/file\"\n    depth=$(git -C \"$ROOT/link\" rev-list HEAD | wc -l)\n    if [[ $depth != 1 ]]; then\n        fail \"expected depth 1, got $depth\"\n    fi\n\n    # Sync depth=2\n    GIT_SYNC \\\n        --one-time \\\n        --repo=\"file://$REPO\" \\\n        --depth=2 \\\n        --root=\"$ROOT\" \\\n        --link=\"link\"\n    wait_for_sync \"${MAXWAIT}\"\n    assert_link_exists \"$ROOT/link\"\n    assert_file_exists \"$ROOT/link/file\"\n    depth=$(git -C \"$ROOT/link\" rev-list HEAD | wc -l)\n    if [[ $depth != 2 ]]; then\n        fail \"expected depth 2, got $depth\"\n    fi\n\n    # Sync depth=1\n    GIT_SYNC \\\n        --one-time \\\n        --repo=\"file://$REPO\" \\\n        --depth=1 \\\n        --root=\"$ROOT\" \\\n        --link=\"link\"\n    wait_for_sync \"${MAXWAIT}\"\n    assert_link_exists \"$ROOT/link\"\n    assert_file_exists \"$ROOT/link/file\"\n    depth=$(git -C \"$ROOT/link\" rev-list HEAD | wc -l)\n    if [[ $depth != 1 ]]; then\n        fail \"expected depth 1, got $depth\"\n    fi\n\n    # Sync depth=0 (full)\n    GIT_SYNC \\\n        --one-time \\\n        --repo=\"file://$REPO\" \\\n        --depth=0 \\\n        --root=\"$ROOT\" \\\n        --link=\"link\"\n    wait_for_sync \"${MAXWAIT}\"\n    assert_link_exists \"$ROOT/link\"\n    assert_file_exists \"$ROOT/link/file\"\n    depth=$(git -C \"$ROOT/link\" rev-list HEAD | wc -l)\n    if [[ $depth != 4 ]]; then\n        fail \"expected depth 4, got $depth\"\n    fi\n}\n\n##############################################\n# Test HTTP basicauth with a password\n##############################################\nfunction e2e::auth_http_password() {\n    # Run a git-over-HTTP server.\n    CTR=$(docker_run \\\n        -v \"$REPO\":/git/repo:ro \\\n        e2e/test/httpd)\n    IP=$(docker_ip \"$CTR\")\n\n    # Try with wrong username\n    assert_fail \\\n        GIT_SYNC \\\n            --one-time \\\n            --repo=\"http://$IP/repo\" \\\n            --root=\"$ROOT\" \\\n            --link=\"link\" \\\n            --username=\"wrong\" \\\n            --__env__GITSYNC_PASSWORD=\"testpass\"\n    assert_file_absent \"$ROOT/link/file\"\n\n    # Try with wrong password\n    assert_fail \\\n        GIT_SYNC \\\n            --one-time \\\n            --repo=\"http://$IP/repo\" \\\n            --root=\"$ROOT\" \\\n            --link=\"link\" \\\n            --username=\"testuser\" \\\n            --__env__GITSYNC_PASSWORD=\"wrong\"\n    assert_file_absent \"$ROOT/link/file\"\n\n    # Try with the right password\n    GIT_SYNC \\\n        --one-time \\\n        --repo=\"http://$IP/repo\" \\\n        --root=\"$ROOT\" \\\n        --link=\"link\" \\\n        --username=\"testuser\" \\\n        --__env__GITSYNC_PASSWORD=\"testpass\" \\\n\n    assert_link_exists \"$ROOT/link\"\n    assert_file_exists \"$ROOT/link/file\"\n    assert_file_eq \"$ROOT/link/file\" \"${FUNCNAME[0]}\"\n}\n\n##############################################\n# Test HTTP basicauth with a password in the URL\n##############################################\nfunction e2e::auth_http_password_in_url() {\n    # Run a git-over-HTTP server.\n    CTR=$(docker_run \\\n        -v \"$REPO\":/git/repo:ro \\\n        e2e/test/httpd)\n    IP=$(docker_ip \"$CTR\")\n\n    # Try with wrong username\n    assert_fail \\\n        GIT_SYNC \\\n            --one-time \\\n            --repo=\"http://wrong:testpass@$IP/repo\" \\\n            --root=\"$ROOT\" \\\n            --link=\"link\"\n    assert_file_absent \"$ROOT/link/file\"\n\n    # Try with wrong password\n    assert_fail \\\n        GIT_SYNC \\\n            --one-time \\\n            --repo=\"http://testuser:wrong@$IP/repo\" \\\n            --root=\"$ROOT\" \\\n            --link=\"link\"\n    assert_file_absent \"$ROOT/link/file\"\n\n    # Try with the right password\n    GIT_SYNC \\\n        --one-time \\\n        --repo=\"http://testuser:testpass@$IP/repo\" \\\n        --root=\"$ROOT\" \\\n        --link=\"link\"\n\n    assert_link_exists \"$ROOT/link\"\n    assert_file_exists \"$ROOT/link/file\"\n    assert_file_eq \"$ROOT/link/file\" \"${FUNCNAME[0]}\"\n}\n\n##############################################\n# Test HTTP basicauth with a password-file\n##############################################\nfunction e2e::auth_http_password_file() {\n    # Run a git-over-HTTP server.\n    CTR=$(docker_run \\\n        -v \"$REPO\":/git/repo:ro \\\n        e2e/test/httpd)\n    IP=$(docker_ip \"$CTR\")\n\n    # Make a password file with a bad password.\n    echo -n \"wrong\" > \"$WORK/password-file\"\n\n    assert_fail \\\n        GIT_SYNC \\\n            --one-time \\\n            --repo=\"http://$IP/repo\" \\\n            --root=\"$ROOT\" \\\n            --link=\"link\" \\\n            --username=\"testuser\" \\\n            --password-file=\"$WORK/password-file\"\n    assert_file_absent \"$ROOT/link/file\"\n\n    # Make a password file the right password.\n    echo -n \"testpass\" > \"$WORK/password-file\"\n\n    GIT_SYNC \\\n        --one-time \\\n        --repo=\"http://$IP/repo\" \\\n        --root=\"$ROOT\" \\\n        --link=\"link\" \\\n        --username=\"testuser\" \\\n        --password-file=\"$WORK/password-file\"\n\n    assert_link_exists \"$ROOT/link\"\n    assert_file_exists \"$ROOT/link/file\"\n    assert_file_eq \"$ROOT/link/file\" \"${FUNCNAME[0]}\"\n}\n\n##############################################\n# Test SSH (user@host:path syntax)\n##############################################\nfunction e2e::auth_ssh() {\n    # Run a git-over-SSH server.  Use key #3 to exercise the multi-key logic.\n    CTR=$(docker_run \\\n        -v \"$DOT_SSH/server/3\":/dot_ssh:ro \\\n        -v \"$REPO\":/git/repo:ro \\\n        e2e/test/sshd)\n    IP=$(docker_ip \"$CTR\")\n\n    # Try to sync with key #1.\n    assert_fail \\\n        GIT_SYNC \\\n            --one-time \\\n            --repo=\"test@$IP:/git/repo\" \\\n            --root=\"$ROOT\" \\\n            --link=\"link\" \\\n            --ssh-known-hosts=false \\\n            --ssh-key-file=\"/ssh/secret.2\"\n    assert_file_absent \"$ROOT/link/file\"\n\n    # Try to sync with multiple keys\n    GIT_SYNC \\\n        --one-time \\\n        --repo=\"test@$IP:/git/repo\" \\\n        --root=\"$ROOT\" \\\n        --link=\"link\" \\\n        --ssh-known-hosts=false \\\n        --ssh-key-file=\"/ssh/secret.1\" \\\n        --ssh-key-file=\"/ssh/secret.2\" \\\n        --ssh-key-file=\"/ssh/secret.3\"\n\n    assert_link_exists \"$ROOT/link\"\n    assert_file_exists \"$ROOT/link/file\"\n    assert_file_eq \"$ROOT/link/file\" \"${FUNCNAME[0]}\"\n}\n\n##############################################\n# Test SSH (ssh://user@host/path syntax)\n##############################################\nfunction e2e::auth_ssh_url() {\n    # Run a git-over-SSH server.  Use key #3 to exercise the multi-key logic.\n    CTR=$(docker_run \\\n        -v \"$DOT_SSH/server/3\":/dot_ssh:ro \\\n        -v \"$REPO\":/git/repo:ro \\\n        e2e/test/sshd)\n    IP=$(docker_ip \"$CTR\")\n\n    # Try to sync with key #1.\n    assert_fail \\\n        GIT_SYNC \\\n            --one-time \\\n            --repo=\"ssh://test@$IP/git/repo\" \\\n            --root=\"$ROOT\" \\\n            --link=\"link\" \\\n            --ssh-known-hosts=false \\\n            --ssh-key-file=\"/ssh/secret.2\"\n    assert_file_absent \"$ROOT/link/file\"\n\n    # Try to sync with multiple keys\n    GIT_SYNC \\\n        --one-time \\\n        --repo=\"ssh://test@$IP/git/repo\" \\\n        --root=\"$ROOT\" \\\n        --link=\"link\" \\\n        --ssh-known-hosts=false \\\n        --ssh-key-file=\"/ssh/secret.1\" \\\n        --ssh-key-file=\"/ssh/secret.2\" \\\n        --ssh-key-file=\"/ssh/secret.3\"\n\n    assert_link_exists \"$ROOT/link\"\n    assert_file_exists \"$ROOT/link/file\"\n    assert_file_eq \"$ROOT/link/file\" \"${FUNCNAME[0]}\"\n}\n\n##############################################\n# Test askpass-url with bad password\n##############################################\nfunction e2e::auth_askpass_url_wrong_password() {\n    # run the askpass_url service with wrong password\n    HITLOG=\"$WORK/hitlog\"\n    cat /dev/null > \"$HITLOG\"\n    CTR=$(docker_run \\\n        -v \"$HITLOG\":/var/log/hits \\\n        e2e/test/ncsvr \\\n        80 'read X\n            echo \"HTTP/1.1 200 OK\"\n            echo\n            echo \"username=my-username\"\n            echo \"password=wrong\"\n            ')\n    IP=$(docker_ip \"$CTR\")\n\n    assert_fail \\\n        GIT_SYNC \\\n            --one-time \\\n            --repo=\"file://$REPO\" \\\n            --root=\"$ROOT\" \\\n            --link=\"link\" \\\n            --git=\"/$ASKPASS_GIT\" \\\n            --askpass-url=\"http://$IP/git_askpass\"\n    assert_file_absent \"$ROOT/link/file\"\n}\n\n##############################################\n# Test askpass-url\n##############################################\nfunction e2e::auth_askpass_url_correct_password() {\n    # run with askpass_url service with correct password\n    HITLOG=\"$WORK/hitlog\"\n    cat /dev/null > \"$HITLOG\"\n    CTR=$(docker_run \\\n        -v \"$HITLOG\":/var/log/hits \\\n        e2e/test/ncsvr \\\n        80 'read X\n            echo \"HTTP/1.1 200 OK\"\n            echo\n            echo \"username=my-username\"\n            echo \"password=my-password\"\n            ')\n    IP=$(docker_ip \"$CTR\")\n\n    GIT_SYNC \\\n        --one-time \\\n        --repo=\"file://$REPO\" \\\n        --root=\"$ROOT\" \\\n        --link=\"link\" \\\n        --git=\"/$ASKPASS_GIT\" \\\n        --askpass-url=\"http://$IP/git_askpass\"\n\n    assert_link_exists \"$ROOT/link\"\n    assert_file_exists \"$ROOT/link/file\"\n    assert_file_eq \"$ROOT/link/file\" \"${FUNCNAME[0]}\"\n}\n\n##############################################\n# Test askpass-url where the URL is sometimes wrong\n##############################################\nfunction e2e::auth_askpass_url_sometimes_wrong() {\n    # run with askpass_url service which alternates good/bad replies.\n    HITLOG=\"$WORK/hitlog\"\n    cat /dev/null > \"$HITLOG\"\n    CTR=$(docker_run \\\n        -v \"$HITLOG\":/var/log/hits \\\n        e2e/test/ncsvr \\\n        80 'read X\n            echo \"HTTP/1.1 200 OK\"\n            echo\n            if [ -f /tmp/flag ]; then\n                echo \"username=my-username\"\n                echo \"password=my-password\"\n                rm /tmp/flag\n            else\n                echo \"username=my-username\"\n                echo \"password=wrong\"\n                touch /tmp/flag\n            fi\n            ')\n    IP=$(docker_ip \"$CTR\")\n\n    # First sync\n    echo \"${FUNCNAME[0]} 1\" > \"$REPO/file\"\n    git -C \"$REPO\" commit -qam \"${FUNCNAME[0]} 1\"\n\n    GIT_SYNC \\\n        --period=100ms \\\n        --repo=\"file://$REPO\" \\\n        --root=\"$ROOT\" \\\n        --link=\"link\" \\\n        --git=\"/$ASKPASS_GIT\" \\\n        --askpass-url=\"http://$IP/git_askpass\" \\\n        --max-failures=2 \\\n        &\n    wait_for_sync \"${MAXWAIT}\"\n    assert_link_exists \"$ROOT/link\"\n    assert_file_exists \"$ROOT/link/file\"\n    assert_file_eq \"$ROOT/link/file\" \"${FUNCNAME[0]} 1\"\n\n    # Move HEAD forward\n    echo \"${FUNCNAME[0]} 2\" > \"$REPO/file\"\n    git -C \"$REPO\" commit -qam \"${FUNCNAME[0]} 2\"\n    wait_for_sync \"${MAXWAIT}\"\n    assert_link_exists \"$ROOT/link\"\n    assert_file_exists \"$ROOT/link/file\"\n    assert_file_eq \"$ROOT/link/file\" \"${FUNCNAME[0]} 2\"\n\n    # Move HEAD backward\n    git -C \"$REPO\" reset -q --hard HEAD^\n    wait_for_sync \"${MAXWAIT}\"\n    assert_link_exists \"$ROOT/link\"\n    assert_file_exists \"$ROOT/link/file\"\n    assert_file_eq \"$ROOT/link/file\" \"${FUNCNAME[0]} 1\"\n}\n\n##############################################\n# Test askpass-url where the URL is flaky\n##############################################\nfunction e2e::auth_askpass_url_flaky() {\n    # run with askpass_url service which alternates good/bad replies.\n    HITLOG=\"$WORK/hitlog\"\n    cat /dev/null > \"$HITLOG\"\n    CTR=$(docker_run \\\n        -v \"$HITLOG\":/var/log/hits \\\n        e2e/test/ncsvr \\\n        80 'read X\n            if [ -f /tmp/flag ]; then\n                echo \"HTTP/1.1 200 OK\"\n                echo\n                echo \"username=my-username\"\n                echo \"password=my-password\"\n                rm /tmp/flag\n            else\n                echo \"HTTP/1.1 503 Service Unavailable\"\n                echo\n                touch /tmp/flag\n            fi\n            ')\n    IP=$(docker_ip \"$CTR\")\n\n    # First sync\n    echo \"${FUNCNAME[0]} 1\" > \"$REPO/file\"\n    git -C \"$REPO\" commit -qam \"${FUNCNAME[0]} 1\"\n\n    GIT_SYNC \\\n        --period=100ms \\\n        --repo=\"file://$REPO\" \\\n        --root=\"$ROOT\" \\\n        --link=\"link\" \\\n        --git=\"/$ASKPASS_GIT\" \\\n        --askpass-url=\"http://$IP/git_askpass\" \\\n        --max-failures=2 \\\n        &\n    wait_for_sync \"${MAXWAIT}\"\n    assert_link_exists \"$ROOT/link\"\n    assert_file_exists \"$ROOT/link/file\"\n    assert_file_eq \"$ROOT/link/file\" \"${FUNCNAME[0]} 1\"\n\n    # Move HEAD forward\n    echo \"${FUNCNAME[0]} 2\" > \"$REPO/file\"\n    git -C \"$REPO\" commit -qam \"${FUNCNAME[0]} 2\"\n    wait_for_sync \"${MAXWAIT}\"\n    assert_link_exists \"$ROOT/link\"\n    assert_file_exists \"$ROOT/link/file\"\n    assert_file_eq \"$ROOT/link/file\" \"${FUNCNAME[0]} 2\"\n\n    # Move HEAD backward\n    git -C \"$REPO\" reset -q --hard HEAD^\n    wait_for_sync \"${MAXWAIT}\"\n    assert_link_exists \"$ROOT/link\"\n    assert_file_exists \"$ROOT/link/file\"\n    assert_file_eq \"$ROOT/link/file\" \"${FUNCNAME[0]} 1\"\n}\n\n##############################################\n# Test askpass-url where the URL fails at startup\n##############################################\nfunction e2e::auth_askpass_url_slow_start() {\n    # run with askpass_url service which takes a while to come up\n    HITLOG=\"$WORK/hitlog\"\n    cat /dev/null > \"$HITLOG\"\n    CTR=$(docker_run \\\n        -v \"$HITLOG\":/var/log/hits \\\n        --entrypoint sh \\\n        e2e/test/ncsvr \\\n        -c \"sleep 4;\n            /ncsvr.sh 80 'read X\n                echo \\\"HTTP/1.1 200 OK\\\"\n                echo\n                echo \\\"username=my-username\\\"\n                echo \\\"password=my-password\\\"\n                '\")\n    IP=$(docker_ip \"$CTR\")\n\n    GIT_SYNC \\\n        --period=1s \\\n        --repo=\"file://$REPO\" \\\n        --root=\"$ROOT\" \\\n        --link=\"link\" \\\n        --git=\"/$ASKPASS_GIT\" \\\n        --askpass-url=\"http://$IP/git_askpass\" \\\n        --max-failures=5 \\\n        &\n    sleep 1\n    assert_file_absent \"$ROOT/link\"\n\n    wait_for_sync 5\n    assert_link_exists \"$ROOT/link\"\n    assert_file_exists \"$ROOT/link/file\"\n    assert_file_eq \"$ROOT/link/file\" \"${FUNCNAME[0]}\"\n}\n\n##############################################\n# Test github app auth\n##############################################\nfunction e2e::auth_github_app_application_id() {\n    if [[ \"${skip_github_app_test}\" == \"true\" ]]; then\n        skip\n    fi\n    GIT_SYNC \\\n        --one-time \\\n        --repo=\"${TEST_GITHUB_APP_AUTH_TEST_REPO}\" \\\n        --github-app-application-id \"${TEST_GITHUB_APP_APPLICATION_ID}\" \\\n        --github-app-installation-id \"${TEST_GITHUB_APP_INSTALLATION_ID}\" \\\n        --github-app-private-key-file \"/${LOCAL_GITHUB_APP_PRIVATE_KEY_FILE}\" \\\n        --root=\"${ROOT}\" \\\n        --link=\"link\"\n    assert_file_exists \"${ROOT}/link/LICENSE\"\n}\n\nfunction e2e::auth_github_app_client_id() {\n    if [[ \"${skip_github_app_test}\" == \"true\" ]]; then\n        skip\n    fi\n    GIT_SYNC \\\n        --one-time \\\n        --repo=\"${TEST_GITHUB_APP_AUTH_TEST_REPO}\" \\\n        --github-app-client-id \"${TEST_GITHUB_APP_CLIENT_ID}\" \\\n        --github-app-installation-id \"${TEST_GITHUB_APP_INSTALLATION_ID}\" \\\n        --github-app-private-key-file \"/${LOCAL_GITHUB_APP_PRIVATE_KEY_FILE}\" \\\n        --root=\"${ROOT}\" \\\n        --link=\"link\"\n    assert_file_exists \"${ROOT}/link/LICENSE\"\n}\n\n##############################################\n# Test exechook-success\n##############################################\nfunction e2e::exechook_success() {\n    cat /dev/null > \"$RUNLOG\"\n\n    # First sync\n    echo \"${FUNCNAME[0]} 1\" > \"$REPO/file\"\n    git -C \"$REPO\" commit -qam \"${FUNCNAME[0]} 1\"\n\n    GIT_SYNC \\\n        --period=100ms \\\n        --repo=\"file://$REPO\" \\\n        --root=\"$ROOT\" \\\n        --link=\"link\" \\\n        --exechook-command=\"/$EXECHOOK_COMMAND\" \\\n        &\n    wait_for_sync \"${MAXWAIT}\"\n    assert_link_exists \"$ROOT/link\"\n    assert_file_exists \"$ROOT/link/file\"\n    assert_file_exists \"$ROOT/link/exechook\"\n    assert_file_eq \"$ROOT/link/file\" \"${FUNCNAME[0]} 1\"\n    assert_file_eq \"$ROOT/link/exechook\" \"${FUNCNAME[0]} 1\"\n    assert_file_eq \"$ROOT/link/exechook-env\" \"$EXECHOOK_ENVKEY=$EXECHOOK_ENVVAL\"\n    assert_file_lines_eq \"$RUNLOG\" 1\n\n    # Move forward\n    echo \"${FUNCNAME[0]} 2\" > \"$REPO/file\"\n    git -C \"$REPO\" commit -qam \"${FUNCNAME[0]} 2\"\n    wait_for_sync \"${MAXWAIT}\"\n    assert_link_exists \"$ROOT/link\"\n    assert_file_exists \"$ROOT/link/file\"\n    assert_file_exists \"$ROOT/link/exechook\"\n    assert_file_eq \"$ROOT/link/file\" \"${FUNCNAME[0]} 2\"\n    assert_file_eq \"$ROOT/link/exechook\" \"${FUNCNAME[0]} 2\"\n    assert_file_eq \"$ROOT/link/exechook-env\" \"$EXECHOOK_ENVKEY=$EXECHOOK_ENVVAL\"\n    assert_file_lines_eq \"$RUNLOG\" 2\n}\n\n##############################################\n# Test exechook-fail-retry\n##############################################\nfunction e2e::exechook_fail_retry() {\n    cat /dev/null > \"$RUNLOG\"\n\n    # First sync - return a failure to ensure that we try again\n    GIT_SYNC \\\n        --period=100ms \\\n        --repo=\"file://$REPO\" \\\n        --root=\"$ROOT\" \\\n        --link=\"link\" \\\n        --exechook-command=\"/$EXECHOOK_COMMAND_FAIL\" \\\n        --exechook-backoff=1s \\\n        &\n    sleep 3 # give it time to retry\n\n    # Check that exechook was called\n    assert_file_lines_ge \"$RUNLOG\" 2\n}\n\n##############################################\n# Test exechook-success with --one-time\n##############################################\nfunction e2e::exechook_success_once() {\n    GIT_SYNC \\\n        --one-time \\\n        --repo=\"file://$REPO\" \\\n        --root=\"$ROOT\" \\\n        --link=\"link\" \\\n        --exechook-command=\"/$EXECHOOK_COMMAND_SLEEPY\"\n\n    wait_for_sync \"${MAXWAIT}\"\n    assert_link_exists \"$ROOT/link\"\n    assert_file_exists \"$ROOT/link/file\"\n    assert_file_exists \"$ROOT/link/exechook\"\n    assert_file_eq \"$ROOT/link/file\" \"${FUNCNAME[0]}\"\n    assert_file_eq \"$ROOT/link/exechook\" \"${FUNCNAME[0]}\"\n    assert_file_eq \"$ROOT/link/exechook-env\" \"$EXECHOOK_ENVKEY=$EXECHOOK_ENVVAL\"\n}\n\n##############################################\n# Test exechook-fail with --one-time\n##############################################\nfunction e2e::exechook_fail_once() {\n    cat /dev/null > \"$RUNLOG\"\n\n    assert_fail \\\n        GIT_SYNC \\\n            --one-time \\\n            --repo=\"file://$REPO\" \\\n            --root=\"$ROOT\" \\\n            --link=\"link\" \\\n            --exechook-command=\"/$EXECHOOK_COMMAND_FAIL_SLEEPY\" \\\n            --exechook-backoff=1s\n\n    assert_link_exists \"$ROOT/link\"\n    assert_file_exists \"$ROOT/link/file\"\n    assert_file_eq \"$ROOT/link/file\" \"${FUNCNAME[0]}\"\n    assert_file_lines_eq \"$RUNLOG\" 1\n}\n\n##############################################\n# Test exechook at startup with correct SHA\n##############################################\nfunction e2e::exechook_startup_after_crash() {\n    GIT_SYNC \\\n        --one-time \\\n        --repo=\"file://$REPO\" \\\n        --ref=\"$MAIN_BRANCH\" \\\n        --root=\"$ROOT\" \\\n        --link=\"link\"\n    assert_link_exists \"$ROOT/link\"\n    assert_file_exists \"$ROOT/link/file\"\n    assert_file_eq \"$ROOT/link/file\" \"${FUNCNAME[0]}\"\n\n    # No changes to repo\n\n    cat /dev/null > \"$RUNLOG\"\n    GIT_SYNC \\\n        --one-time \\\n        --repo=\"file://$REPO\" \\\n        --ref=\"$MAIN_BRANCH\" \\\n        --root=\"$ROOT\" \\\n        --link=\"link\" \\\n        --exechook-command=\"/$EXECHOOK_COMMAND\"\n    assert_link_exists \"$ROOT/link\"\n    assert_file_exists \"$ROOT/link/file\"\n    assert_file_exists \"$ROOT/link/exechook\"\n    assert_file_eq \"$ROOT/link/file\" \"${FUNCNAME[0]}\"\n    assert_file_eq \"$ROOT/link/exechook\" \"${FUNCNAME[0]}\"\n    assert_file_eq \"$ROOT/link/exechook-env\" \"$EXECHOOK_ENVKEY=$EXECHOOK_ENVVAL\"\n    assert_file_lines_eq \"$RUNLOG\" 1\n}\n\n##############################################\n# Test webhook success\n##############################################\nfunction e2e::webhook_success() {\n    HITLOG=\"$WORK/hitlog\"\n\n    # First sync\n    cat /dev/null > \"$HITLOG\"\n    CTR=$(docker_run \\\n        -v \"$HITLOG\":/var/log/hits \\\n        e2e/test/ncsvr \\\n        80 'read X\n            echo \"HTTP/1.1 200 OK\"\n            echo\n           ')\n    IP=$(docker_ip \"$CTR\")\n    echo \"${FUNCNAME[0]} 1\" > \"$REPO/file\"\n    git -C \"$REPO\" commit -qam \"${FUNCNAME[0]} 1\"\n\n    GIT_SYNC \\\n        --period=100ms \\\n        --repo=\"file://$REPO\" \\\n        --root=\"$ROOT\" \\\n        --webhook-url=\"http://$IP\" \\\n        --webhook-success-status=200 \\\n        --link=\"link\" \\\n        &\n\n    # check that basic call works\n    wait_for_sync \"${MAXWAIT}\"\n    sleep 1 # webhooks are async\n    assert_file_lines_eq \"$HITLOG\" 1\n\n    # Move forward\n    echo \"${FUNCNAME[0]} 2\" > \"$REPO/file\"\n    git -C \"$REPO\" commit -qam \"${FUNCNAME[0]} 2\"\n\n    # check that another call works\n    wait_for_sync \"${MAXWAIT}\"\n    sleep 1 # webhooks are async\n    assert_file_lines_eq \"$HITLOG\" 2\n}\n\n##############################################\n# Test webhook fail-retry\n##############################################\nfunction e2e::webhook_fail_retry() {\n    HITLOG=\"$WORK/hitlog\"\n    SCRIPT=\"$WORK/http_resp.sh\"\n    touch \"$SCRIPT\"\n    chmod 755 \"$SCRIPT\"\n\n    # First sync - return a failure to ensure that we try again\n    cat /dev/null > \"$HITLOG\"\n    cat > \"$SCRIPT\" << __EOF__\n#!/bin/sh\nread X\necho \"HTTP/1.1 500 Internal Server Error\"\necho\n__EOF__\n    CTR=$(docker_run \\\n        -v \"$HITLOG\":/var/log/hits \\\n        -v \"$SCRIPT\":/http_resp.sh \\\n        e2e/test/ncsvr \\\n        80 '/http_resp.sh')\n    IP=$(docker_ip \"$CTR\")\n\n    GIT_SYNC \\\n        --period=100ms \\\n        --repo=\"file://$REPO\" \\\n        --root=\"$ROOT\" \\\n        --webhook-url=\"http://$IP\" \\\n        --webhook-success-status=200 \\\n        --link=\"link\" \\\n        &\n\n    # Check that webhook was called\n    wait_for_sync \"${MAXWAIT}\"\n    sleep 1 # webhooks are async\n    assert_file_lines_ge \"$HITLOG\" 1\n\n    # Now return 200, ensure that it gets called\n    cat /dev/null > \"$HITLOG\"\n    cat > \"$SCRIPT\" << __EOF__\n#!/bin/sh\nread X\necho \"HTTP/1.1 200 OK\"\necho\n__EOF__\n    sleep 2 # webhooks are async\n    assert_file_lines_eq \"$HITLOG\" 1\n}\n\n##############################################\n# Test webhook success with --one-time\n##############################################\nfunction e2e::webhook_success_once() {\n    HITLOG=\"$WORK/hitlog\"\n\n    # First sync\n    cat /dev/null > \"$HITLOG\"\n    CTR=$(docker_run \\\n        -v \"$HITLOG\":/var/log/hits \\\n        e2e/test/ncsvr \\\n        80 'read X\n            echo \"HTTP/1.1 200 OK\"\n            echo\n           ')\n    IP=$(docker_ip \"$CTR\")\n\n    GIT_SYNC \\\n        --period=100ms \\\n        --one-time \\\n        --repo=\"file://$REPO\" \\\n        --root=\"$ROOT\" \\\n        --webhook-url=\"http://$IP\" \\\n        --webhook-success-status=200 \\\n        --link=\"link\"\n\n    # check that basic call works\n    assert_file_lines_eq \"$HITLOG\" 1\n}\n\n##############################################\n# Test webhook fail with --one-time\n##############################################\nfunction e2e::webhook_fail_retry_once() {\n    HITLOG=\"$WORK/hitlog\"\n\n    # First sync - return a failure to ensure that we try again\n    cat /dev/null > \"$HITLOG\"\n    CTR=$(docker_run \\\n        -v \"$HITLOG\":/var/log/hits \\\n        e2e/test/ncsvr \\\n        80 'read X\n            echo \"HTTP/1.1 500 Internal Server Error\"\n            echo\n           ')\n    IP=$(docker_ip \"$CTR\")\n\n    assert_fail \\\n        GIT_SYNC \\\n            --period=100ms \\\n            --one-time \\\n            --repo=\"file://$REPO\" \\\n            --root=\"$ROOT\" \\\n            --webhook-url=\"http://$IP\" \\\n            --webhook-success-status=200 \\\n            --link=\"link\"\n\n    assert_link_exists \"$ROOT/link\"\n    assert_file_exists \"$ROOT/link/file\"\n    assert_file_eq \"$ROOT/link/file\" \"${FUNCNAME[0]}\"\n    assert_file_lines_eq \"$HITLOG\" 1\n}\n\n##############################################\n# Test webhook fire-and-forget\n##############################################\nfunction e2e::webhook_fire_and_forget() {\n    HITLOG=\"$WORK/hitlog\"\n\n    cat /dev/null > \"$HITLOG\"\n    CTR=$(docker_run \\\n        -v \"$HITLOG\":/var/log/hits \\\n        e2e/test/ncsvr \\\n        80 'read X\n            echo \"HTTP/1.1 404 Not Found\"\n            echo\n           ')\n    IP=$(docker_ip \"$CTR\")\n\n    GIT_SYNC \\\n        --period=100ms \\\n        --repo=\"file://$REPO\" \\\n        --root=\"$ROOT\" \\\n        --webhook-url=\"http://$IP\" \\\n        --webhook-success-status=0 \\\n        --link=\"link\" \\\n        &\n\n    # check that basic call works\n    wait_for_sync \"${MAXWAIT}\"\n    sleep 1 # webhooks are async\n    assert_file_lines_eq \"$HITLOG\" 1\n}\n\n##############################################\n# Test http handler\n##############################################\nfunction e2e::expose_http() {\n    GIT_SYNC \\\n        --git=\"/$SLOW_GIT_FETCH\" \\\n        --period=100ms \\\n        --repo=\"file://$REPO\" \\\n        --root=\"$ROOT\" \\\n        --link=\"link\" \\\n        &\n\n    # do nothing, just wait for the HTTP to come up\n    for i in $(seq 1 5); do\n        sleep 1\n        if curl --silent --output /dev/null http://localhost:$HTTP_PORT; then\n            break\n        fi\n        if [[ \"$i\" == 5 ]]; then\n            fail \"HTTP server failed to start\"\n        fi\n    done\n\n    # check that health endpoint fails\n    if [[ $(curl --write-out '%{http_code}' --silent --output /dev/null http://localhost:$HTTP_PORT) -ne 503 ]] ; then\n        fail \"health endpoint should have failed: $(curl --write-out '%{http_code}' --silent --output /dev/null http://localhost:$HTTP_PORT)\"\n    fi\n    wait_for_sync \"${MAXWAIT}\"\n\n    # check that health endpoint is alive\n    if [[ $(curl --write-out '%{http_code}' --silent --output /dev/null http://localhost:$HTTP_PORT) -ne 200 ]] ; then\n        fail \"health endpoint failed\"\n    fi\n\n    # check that the metrics endpoint exists\n    if [[ $(curl --write-out '%{http_code}' --silent --output /dev/null http://localhost:$HTTP_PORT/metrics) -ne 200 ]] ; then\n        fail \"metrics endpoint failed\"\n    fi\n\n    # check that the pprof endpoint exists\n    if [[ $(curl --write-out '%{http_code}' --silent --output /dev/null http://localhost:$HTTP_PORT/debug/pprof/) -ne 200 ]] ; then\n        fail \"pprof endpoint failed\"\n    fi\n}\n\n##############################################\n# Test http handler after restart\n##############################################\nfunction e2e::expose_http_after_restart() {\n    # Sync once to set up the repo\n    GIT_SYNC \\\n        --one-time \\\n        --repo=\"file://$REPO\" \\\n        --root=\"$ROOT\" \\\n        --link=\"link\"\n    assert_link_exists \"$ROOT/link\"\n    assert_file_exists \"$ROOT/link/file\"\n    assert_file_eq \"$ROOT/link/file\" \"${FUNCNAME[0]}\"\n\n    # Sync again and prove readiness.\n    GIT_SYNC \\\n        --repo=\"file://$REPO\" \\\n        --root=\"$ROOT\" \\\n        --link=\"link\" \\\n        &\n    # do nothing, just wait for the HTTP to come up\n    for i in $(seq 1 5); do\n        sleep 1\n        if curl --silent --output /dev/null http://localhost:$HTTP_PORT; then\n            break\n        fi\n        if [[ \"$i\" == 5 ]]; then\n            fail \"HTTP server failed to start\"\n        fi\n    done\n\n    sleep 2 # wait for first loop to confirm synced\n\n    # check that health endpoint is alive\n    if [[ $(curl --write-out '%{http_code}' --silent --output /dev/null http://localhost:$HTTP_PORT) -ne 200 ]] ; then\n        fail \"health endpoint failed\"\n    fi\n    assert_link_exists \"$ROOT/link\"\n    assert_file_exists \"$ROOT/link/file\"\n    assert_file_eq \"$ROOT/link/file\" \"${FUNCNAME[0]}\"\n}\n\n##############################################\n# Test submodule sync\n##############################################\nfunction e2e::submodule_sync_default() {\n    # Init submodule repo\n    SUBMODULE_REPO_NAME=\"sub\"\n    SUBMODULE=\"$WORK/$SUBMODULE_REPO_NAME\"\n    mkdir \"$SUBMODULE\"\n\n    git -C \"$SUBMODULE\" init -q -b \"$MAIN_BRANCH\"\n    echo \"submodule\" > \"$SUBMODULE/submodule.file\"\n    git -C \"$SUBMODULE\" add submodule.file\n    git -C \"$SUBMODULE\" commit -aqm \"init submodule.file\"\n\n    # Init nested submodule repo\n    NESTED_SUBMODULE_REPO_NAME=\"nested-sub\"\n    NESTED_SUBMODULE=\"$WORK/$NESTED_SUBMODULE_REPO_NAME\"\n    mkdir \"$NESTED_SUBMODULE\"\n\n    git -C \"$NESTED_SUBMODULE\" init -q -b \"$MAIN_BRANCH\"\n    echo \"nested-submodule\" > \"$NESTED_SUBMODULE/nested-submodule.file\"\n    git -C \"$NESTED_SUBMODULE\" add nested-submodule.file\n    git -C \"$NESTED_SUBMODULE\" commit -aqm \"init nested-submodule.file\"\n\n    # Add submodule\n    git -C \"$REPO\" -c protocol.file.allow=always submodule add -q file://$SUBMODULE \"$SUBMODULE_REPO_NAME\"\n    git -C \"$REPO\" commit -aqm \"add submodule\"\n\n    GIT_SYNC \\\n        --period=100ms \\\n        --repo=\"file://$REPO\" \\\n        --root=\"$ROOT\" \\\n        --link=\"link\" \\\n        &\n    wait_for_sync \"${MAXWAIT}\"\n    assert_link_exists \"$ROOT/link\"\n    assert_file_exists \"$ROOT/link/file\"\n    assert_file_exists \"$ROOT/link/$SUBMODULE_REPO_NAME/submodule.file\"\n    assert_file_eq \"$ROOT/link/$SUBMODULE_REPO_NAME/submodule.file\" \"submodule\"\n    assert_metric_eq \"${METRIC_GOOD_SYNC_COUNT}\" 1\n\n    # Make change in submodule repo\n    echo \"${FUNCNAME[0]} 2\" > \"$SUBMODULE/submodule.file\"\n    git -C \"$SUBMODULE\" commit -qam \"${FUNCNAME[0]} 2\"\n    git -C \"$REPO\" -c protocol.file.allow=always submodule update --recursive --remote > /dev/null 2>&1\n    git -C \"$REPO\" commit -qam \"${FUNCNAME[0]} 2\"\n    wait_for_sync \"${MAXWAIT}\"\n    assert_link_exists \"$ROOT/link\"\n    assert_file_exists \"$ROOT/link/file\"\n    assert_file_exists \"$ROOT/link/$SUBMODULE_REPO_NAME/submodule.file\"\n    assert_file_eq \"$ROOT/link/$SUBMODULE_REPO_NAME/submodule.file\" \"${FUNCNAME[0]} 2\"\n    assert_metric_eq \"${METRIC_GOOD_SYNC_COUNT}\" 2\n\n    # Move backward in submodule repo\n    git -C \"$SUBMODULE\" reset -q --hard HEAD^\n    git -C \"$REPO\" -c protocol.file.allow=always submodule update --recursive --remote > /dev/null 2>&1\n    git -C \"$REPO\" commit -qam \"${FUNCNAME[0]} 3\"\n    wait_for_sync \"${MAXWAIT}\"\n    assert_link_exists \"$ROOT/link\"\n    assert_file_exists \"$ROOT/link/file\"\n    assert_file_exists \"$ROOT/link/$SUBMODULE_REPO_NAME/submodule.file\"\n    assert_file_eq \"$ROOT/link/$SUBMODULE_REPO_NAME/submodule.file\" \"submodule\"\n    assert_metric_eq \"${METRIC_GOOD_SYNC_COUNT}\" 3\n\n    # Add nested submodule to submodule repo\n    git -C \"$SUBMODULE\" -c protocol.file.allow=always submodule add -q file://$NESTED_SUBMODULE \"$NESTED_SUBMODULE_REPO_NAME\"\n    git -C \"$SUBMODULE\" commit -aqm \"add nested submodule\"\n    git -C \"$REPO\" -c protocol.file.allow=always submodule update --recursive --remote > /dev/null 2>&1\n    git -C \"$REPO\" commit -qam \"${FUNCNAME[0]} 4\"\n    wait_for_sync \"${MAXWAIT}\"\n    assert_link_exists \"$ROOT/link\"\n    assert_file_exists \"$ROOT/link/file\"\n    assert_file_exists \"$ROOT/link/$SUBMODULE_REPO_NAME/submodule.file\"\n    assert_file_exists \"$ROOT/link/$SUBMODULE_REPO_NAME/$NESTED_SUBMODULE_REPO_NAME/nested-submodule.file\"\n    assert_file_eq \"$ROOT/link/$SUBMODULE_REPO_NAME/$NESTED_SUBMODULE_REPO_NAME/nested-submodule.file\" \"nested-submodule\"\n    assert_metric_eq \"${METRIC_GOOD_SYNC_COUNT}\" 4\n\n    # Remove nested submodule\n    git -C \"$SUBMODULE\" submodule deinit -q $NESTED_SUBMODULE_REPO_NAME\n    rm -rf \"$SUBMODULE/.git/modules/$NESTED_SUBMODULE_REPO_NAME\"\n    git -C \"$SUBMODULE\" rm -qf $NESTED_SUBMODULE_REPO_NAME\n    git -C \"$SUBMODULE\" commit -aqm \"delete nested submodule\"\n    git -C \"$REPO\" -c protocol.file.allow=always submodule update --recursive --remote > /dev/null 2>&1\n    git -C \"$REPO\" commit -qam \"${FUNCNAME[0]} 5\"\n    wait_for_sync \"${MAXWAIT}\"\n    assert_link_exists \"$ROOT/link\"\n    assert_file_exists \"$ROOT/link/file\"\n    assert_file_exists \"$ROOT/link/$SUBMODULE_REPO_NAME/submodule.file\"\n    assert_file_absent \"$ROOT/link/$SUBMODULE_REPO_NAME/$NESTED_SUBMODULE_REPO_NAME/nested-submodule.file\"\n    assert_metric_eq \"${METRIC_GOOD_SYNC_COUNT}\" 5\n\n    # Remove submodule\n    git -C \"$REPO\" submodule deinit -q $SUBMODULE_REPO_NAME\n    rm -rf \"$REPO/.git/modules/$SUBMODULE_REPO_NAME\"\n    git -C \"$REPO\" rm -qf $SUBMODULE_REPO_NAME\n    git -C \"$REPO\" commit -aqm \"delete submodule\"\n    wait_for_sync \"${MAXWAIT}\"\n    assert_link_exists \"$ROOT/link\"\n    assert_file_exists \"$ROOT/link/file\"\n    assert_file_absent \"$ROOT/link/$SUBMODULE_REPO_NAME/submodule.file\"\n    assert_metric_eq \"${METRIC_GOOD_SYNC_COUNT}\" 6\n\n    rm -rf $SUBMODULE\n    rm -rf $NESTED_SUBMODULE\n}\n\n##############################################\n# Test submodules depth syncing\n##############################################\nfunction e2e::submodule_sync_depth() {\n    # Init submodule repo\n    SUBMODULE_REPO_NAME=\"sub\"\n    SUBMODULE=\"$WORK/$SUBMODULE_REPO_NAME\"\n    mkdir \"$SUBMODULE\"\n\n    git -C \"$SUBMODULE\" init -q -b \"$MAIN_BRANCH\"\n\n    # First sync\n    expected_depth=\"1\"\n    echo \"${FUNCNAME[0]} 1\" > \"$SUBMODULE/submodule.file\"\n    git -C \"$SUBMODULE\" add submodule.file\n    git -C \"$SUBMODULE\" commit -aqm \"submodule ${FUNCNAME[0]} 1\"\n    git -C \"$REPO\" -c protocol.file.allow=always submodule add -q file://$SUBMODULE \"$SUBMODULE_REPO_NAME\"\n    git -C \"$REPO\" config -f \"$REPO/.gitmodules\" \"submodule.$SUBMODULE_REPO_NAME.shallow\" true\n    git -C \"$REPO\" commit -qam \"${FUNCNAME[0]} 1\"\n\n    GIT_SYNC \\\n        --period=100ms \\\n        --repo=\"file://$REPO\" \\\n        --depth=\"$expected_depth\" \\\n        --root=\"$ROOT\" \\\n        --link=\"link\" \\\n        &\n    wait_for_sync \"${MAXWAIT}\"\n    assert_link_exists \"$ROOT/link\"\n    assert_file_exists \"$ROOT/link/$SUBMODULE_REPO_NAME/submodule.file\"\n    assert_file_eq \"$ROOT/link/$SUBMODULE_REPO_NAME/submodule.file\" \"${FUNCNAME[0]} 1\"\n    assert_metric_eq \"${METRIC_GOOD_SYNC_COUNT}\" 1\n    depth=$(git -C \"$ROOT/link\" rev-list HEAD | wc -l)\n    if [[ \"$expected_depth\" != \"$depth\" ]]; then\n        fail \"initial depth mismatch expected=$expected_depth actual=$depth\"\n    fi\n    submodule_depth=$(git -C \"$ROOT/link/$SUBMODULE_REPO_NAME\" rev-list HEAD | wc -l)\n    if [[ \"$expected_depth\" != \"$submodule_depth\" ]]; then\n        fail \"initial submodule depth mismatch expected=$expected_depth actual=$submodule_depth\"\n    fi\n\n    # Move forward\n    echo \"${FUNCNAME[0]} 2\" > \"$SUBMODULE/submodule.file\"\n    git -C \"$SUBMODULE\" commit -aqm \"submodule ${FUNCNAME[0]} 2\"\n    git -C \"$REPO\" -c protocol.file.allow=always submodule update --recursive --remote > /dev/null 2>&1\n    git -C \"$REPO\" commit -qam \"${FUNCNAME[0]} 2\"\n    wait_for_sync \"${MAXWAIT}\"\n    assert_link_exists \"$ROOT/link\"\n    assert_file_exists \"$ROOT/link/$SUBMODULE_REPO_NAME/submodule.file\"\n    assert_file_eq \"$ROOT/link/$SUBMODULE_REPO_NAME/submodule.file\" \"${FUNCNAME[0]} 2\"\n    assert_metric_eq \"${METRIC_GOOD_SYNC_COUNT}\" 2\n    depth=$(git -C \"$ROOT/link\" rev-list HEAD | wc -l)\n    if [[ \"$expected_depth\" != \"$depth\" ]]; then\n        fail \"forward depth mismatch expected=$expected_depth actual=$depth\"\n    fi\n    submodule_depth=$(git -C \"$ROOT/link/$SUBMODULE_REPO_NAME\" rev-list HEAD | wc -l)\n    if [[ \"$expected_depth\" != \"$submodule_depth\" ]]; then\n        fail \"forward submodule depth mismatch expected=$expected_depth actual=$submodule_depth\"\n    fi\n\n    # Move backward\n    git -C \"$SUBMODULE\" reset -q --hard HEAD^\n    git -C \"$REPO\" -c protocol.file.allow=always submodule update --recursive --remote  > /dev/null 2>&1\n    git -C \"$REPO\" commit -qam \"${FUNCNAME[0]} 3\"\n    wait_for_sync \"${MAXWAIT}\"\n    assert_link_exists \"$ROOT/link\"\n    assert_file_exists \"$ROOT/link/$SUBMODULE_REPO_NAME/submodule.file\"\n    assert_file_eq \"$ROOT/link/$SUBMODULE_REPO_NAME/submodule.file\" \"${FUNCNAME[0]} 1\"\n    assert_metric_eq \"${METRIC_GOOD_SYNC_COUNT}\" 3\n    depth=$(git -C \"$ROOT/link\" rev-list HEAD | wc -l)\n    if [[ \"$expected_depth\" != \"$depth\" ]]; then\n        fail \"initial depth mismatch expected=$expected_depth actual=$depth\"\n    fi\n    submodule_depth=$(git -C \"$ROOT/link/$SUBMODULE_REPO_NAME\" rev-list HEAD | wc -l)\n    if [[ \"$expected_depth\" != \"$submodule_depth\" ]]; then\n        fail \"initial submodule depth mismatch expected=$expected_depth actual=$submodule_depth\"\n    fi\n    rm -rf $SUBMODULE\n}\n\n##############################################\n# Test submodules off\n##############################################\nfunction e2e::submodule_sync_off() {\n    # Init submodule repo\n    SUBMODULE_REPO_NAME=\"sub\"\n    SUBMODULE=\"$WORK/$SUBMODULE_REPO_NAME\"\n    mkdir \"$SUBMODULE\"\n\n    git -C \"$SUBMODULE\" init -q -b \"$MAIN_BRANCH\"\n    echo \"submodule\" > \"$SUBMODULE/submodule.file\"\n    git -C \"$SUBMODULE\" add submodule.file\n    git -C \"$SUBMODULE\" commit -aqm \"init submodule file\"\n\n    # Add submodule\n    git -C \"$REPO\" -c protocol.file.allow=always submodule add -q file://$SUBMODULE\n    git -C \"$REPO\" commit -aqm \"add submodule\"\n\n    GIT_SYNC \\\n        --period=100ms \\\n        --repo=\"file://$REPO\" \\\n        --root=\"$ROOT\" \\\n        --link=\"link\" \\\n        --submodules=off \\\n        &\n    wait_for_sync \"${MAXWAIT}\"\n    assert_file_absent \"$ROOT/link/$SUBMODULE_REPO_NAME/submodule.file\"\n    rm -rf $SUBMODULE\n}\n\n##############################################\n# Test submodules shallow\n##############################################\nfunction e2e::submodule_sync_shallow() {\n    # Init submodule repo\n    SUBMODULE_REPO_NAME=\"sub\"\n    SUBMODULE=\"$WORK/$SUBMODULE_REPO_NAME\"\n    mkdir \"$SUBMODULE\"\n\n    git -C \"$SUBMODULE\" init -q -b \"$MAIN_BRANCH\"\n    echo \"submodule\" > \"$SUBMODULE/submodule.file\"\n    git -C \"$SUBMODULE\" add submodule.file\n    git -C \"$SUBMODULE\" commit -aqm \"init submodule file\"\n\n    # Init nested submodule repo\n    NESTED_SUBMODULE_REPO_NAME=\"nested-sub\"\n    NESTED_SUBMODULE=\"$WORK/$NESTED_SUBMODULE_REPO_NAME\"\n    mkdir \"$NESTED_SUBMODULE\"\n\n    git -C \"$NESTED_SUBMODULE\" init -q -b \"$MAIN_BRANCH\"\n    echo \"nested-submodule\" > \"$NESTED_SUBMODULE/nested-submodule.file\"\n    git -C \"$NESTED_SUBMODULE\" add nested-submodule.file\n    git -C \"$NESTED_SUBMODULE\" commit -aqm \"init nested-submodule file\"\n    git -C \"$SUBMODULE\" -c protocol.file.allow=always submodule add -q file://$NESTED_SUBMODULE \"$NESTED_SUBMODULE_REPO_NAME\"\n    git -C \"$SUBMODULE\" commit -aqm \"add nested submodule\"\n\n    # Add submodule\n    git -C \"$REPO\" -c protocol.file.allow=always submodule add -q file://$SUBMODULE \"$SUBMODULE_REPO_NAME\"\n    git -C \"$REPO\" commit -aqm \"add submodule\"\n\n    GIT_SYNC \\\n        --period=100ms \\\n        --repo=\"file://$REPO\" \\\n        --root=\"$ROOT\" \\\n        --link=\"link\" \\\n        --submodules=shallow \\\n        &\n    wait_for_sync \"${MAXWAIT}\"\n    assert_link_exists \"$ROOT/link\"\n    assert_file_exists \"$ROOT/link/file\"\n    assert_file_exists \"$ROOT/link/$SUBMODULE_REPO_NAME/submodule.file\"\n    assert_file_absent \"$ROOT/link/$SUBMODULE_REPO_NAME/$NESTED_SUBMODULE_REPO_NAME/nested-submodule.file\"\n    rm -rf $SUBMODULE\n    rm -rf $NESTED_SUBMODULE\n}\n\n##############################################\n# Test submodule sync with a relative path\n##############################################\nfunction e2e::submodule_sync_relative() {\n    # Init submodule repo\n    SUBMODULE_REPO_NAME=\"sub\"\n    SUBMODULE=\"$WORK/$SUBMODULE_REPO_NAME\"\n    mkdir \"$SUBMODULE\"\n\n    git -C \"$SUBMODULE\" init -q -b \"$MAIN_BRANCH\"\n    echo \"submodule\" > \"$SUBMODULE/submodule.file\"\n    git -C \"$SUBMODULE\" add submodule.file\n    git -C \"$SUBMODULE\" commit -aqm \"init submodule file\"\n\n    # Add submodule\n    REL=\"$(realpath --relative-to \"$REPO\" \"$WORK/$SUBMODULE_REPO_NAME\")\"\n    git -C \"$REPO\" -c protocol.file.allow=always submodule add -q \"$REL\" \"$SUBMODULE_REPO_NAME\"\n    git -C \"$REPO\" commit -aqm \"add submodule\"\n\n    GIT_SYNC \\\n        --period=100ms \\\n        --repo=\"file://$REPO\" \\\n        --root=\"$ROOT\" \\\n        --link=\"link\" \\\n        &\n    wait_for_sync \"${MAXWAIT}\"\n    assert_link_exists \"$ROOT/link\"\n    assert_file_exists \"$ROOT/link/file\"\n    assert_file_exists \"$ROOT/link/$SUBMODULE_REPO_NAME/submodule.file\"\n    assert_file_eq \"$ROOT/link/$SUBMODULE_REPO_NAME/submodule.file\" \"submodule\"\n    assert_metric_eq \"${METRIC_GOOD_SYNC_COUNT}\" 1\n\n    rm -rf $SUBMODULE\n}\n\n##############################################\n# Test submodules over SSH with different keys\n##############################################\nfunction e2e::submodule_sync_over_ssh_different_keys() {\n    # Init nested submodule repo\n    NESTED_SUBMODULE_REPO_NAME=\"nested-sub\"\n    NESTED_SUBMODULE=\"$WORK/$NESTED_SUBMODULE_REPO_NAME\"\n    mkdir \"$NESTED_SUBMODULE\"\n\n    git -C \"$NESTED_SUBMODULE\" init -q -b \"$MAIN_BRANCH\"\n    echo \"nested-submodule\" > \"$NESTED_SUBMODULE/nested-submodule.file\"\n    git -C \"$NESTED_SUBMODULE\" add nested-submodule.file\n    git -C \"$NESTED_SUBMODULE\" commit -aqm \"init nested-submodule.file\"\n\n    # Run a git-over-SSH server.  Use key #1.\n    CTR_SUBSUB=$(docker_run \\\n        -v \"$DOT_SSH/server/1\":/dot_ssh:ro \\\n        -v \"$NESTED_SUBMODULE\":/git/repo:ro \\\n        e2e/test/sshd)\n    IP_SUBSUB=$(docker_ip \"$CTR_SUBSUB\")\n\n    # Tell local git not to do host checking and to use the test keys.\n    export GIT_SSH_COMMAND=\"ssh -F none -o StrictHostKeyChecking=no -o UserKnownHostsFile=/dev/null -i $DOT_SSH/1/id_local -i $DOT_SSH/2/id_local\"\n\n    # Init submodule repo\n    SUBMODULE_REPO_NAME=\"sub\"\n    SUBMODULE=\"$WORK/$SUBMODULE_REPO_NAME\"\n    mkdir \"$SUBMODULE\"\n\n    git -C \"$SUBMODULE\" init -q -b \"$MAIN_BRANCH\"\n    echo \"submodule\" > \"$SUBMODULE/submodule.file\"\n    git -C \"$SUBMODULE\" add submodule.file\n    git -C \"$SUBMODULE\" commit -aqm \"init submodule.file\"\n\n    # Add nested submodule to submodule repo\n    git -C \"$SUBMODULE\" submodule add -q \"test@$IP_SUBSUB:/git/repo\" \"$NESTED_SUBMODULE_REPO_NAME\"\n    git -C \"$SUBMODULE\" commit -aqm \"add nested submodule\"\n\n    # Run a git-over-SSH server.  Use key #2.\n    CTR_SUB=$(docker_run \\\n        -v \"$DOT_SSH/server/2\":/dot_ssh:ro \\\n        -v \"$SUBMODULE\":/git/repo:ro \\\n        e2e/test/sshd)\n    IP_SUB=$(docker_ip \"$CTR_SUB\")\n\n    # Add the submodule to the main repo\n    git -C \"$REPO\" submodule add -q \"test@$IP_SUB:/git/repo\" \"$SUBMODULE_REPO_NAME\"\n    git -C \"$REPO\" commit -aqm \"add submodule\"\n    git -C \"$REPO\" submodule update --recursive --remote > /dev/null 2>&1\n\n    # Run a git-over-SSH server.  Use key #3.\n    CTR=$(docker_run \\\n        -v \"$DOT_SSH/server/3\":/dot_ssh:ro \\\n        -v \"$REPO\":/git/repo:ro \\\n        e2e/test/sshd)\n    IP=$(docker_ip \"$CTR\")\n\n    GIT_SYNC \\\n        --period=100ms \\\n        --repo=\"test@$IP:/git/repo\" \\\n        --root=\"$ROOT\" \\\n        --link=\"link\" \\\n        --ssh-key-file=\"/ssh/secret.1\" \\\n        --ssh-key-file=\"/ssh/secret.2\" \\\n        --ssh-key-file=\"/ssh/secret.3\" \\\n        --ssh-known-hosts=false \\\n        &\n    wait_for_sync \"${MAXWAIT}\"\n    assert_link_exists \"$ROOT/link\"\n    assert_file_exists \"$ROOT/link/file\"\n    assert_file_exists \"$ROOT/link/$SUBMODULE_REPO_NAME/submodule.file\"\n    assert_file_exists \"$ROOT/link/$SUBMODULE_REPO_NAME/$NESTED_SUBMODULE_REPO_NAME/nested-submodule.file\"\n    assert_metric_eq \"${METRIC_GOOD_SYNC_COUNT}\" 1\n\n    rm -rf $SUBMODULE\n    rm -rf $NESTED_SUBMODULE\n}\n\n##############################################\n# Test submodules over HTTP with different passwords\n##############################################\nfunction e2e::submodule_sync_over_http_different_passwords() {\n    # Init nested submodule repo\n    NESTED_SUBMODULE_REPO_NAME=\"nested-sub\"\n    NESTED_SUBMODULE=\"$WORK/$NESTED_SUBMODULE_REPO_NAME\"\n    mkdir \"$NESTED_SUBMODULE\"\n\n    git -C \"$NESTED_SUBMODULE\" init -q -b \"$MAIN_BRANCH\"\n    echo \"nested-submodule\" > \"$NESTED_SUBMODULE/nested-submodule.file\"\n    git -C \"$NESTED_SUBMODULE\" add nested-submodule.file\n    git -C \"$NESTED_SUBMODULE\" commit -aqm \"init nested-submodule.file\"\n\n    # Run a git-over-SSH server.  Use password \"test1\".\n    # shellcheck disable=SC2016\n    echo 'test:$apr1$cXiFWR90$Pmoz7T8kEmlpC9Bpj4MX3.' > \"$WORK/htpasswd.1\"\n    CTR_SUBSUB=$(docker_run \\\n        -v \"$NESTED_SUBMODULE\":/git/repo:ro \\\n        -v \"$WORK/htpasswd.1\":/etc/htpasswd:ro \\\n        e2e/test/httpd)\n    IP_SUBSUB=$(docker_ip \"$CTR_SUBSUB\")\n\n    # Init submodule repo\n    SUBMODULE_REPO_NAME=\"sub\"\n    SUBMODULE=\"$WORK/$SUBMODULE_REPO_NAME\"\n    mkdir \"$SUBMODULE\"\n\n    git -C \"$SUBMODULE\" init -q -b \"$MAIN_BRANCH\"\n    echo \"submodule\" > \"$SUBMODULE/submodule.file\"\n    git -C \"$SUBMODULE\" add submodule.file\n    git -C \"$SUBMODULE\" commit -aqm \"init submodule.file\"\n\n    # Add nested submodule to submodule repo\n    echo -ne \"url=http://$IP_SUBSUB/repo\\nusername=test\\npassword=test1\\n\" | git credential approve\n    git -C \"$SUBMODULE\" submodule add -q \"http://$IP_SUBSUB/repo\" \"$NESTED_SUBMODULE_REPO_NAME\"\n    git -C \"$SUBMODULE\" commit -aqm \"add nested submodule\"\n\n    # Run a git-over-SSH server.  Use password \"test2\".\n    # shellcheck disable=SC2016\n    echo 'test:$apr1$vWBoWUBS$2H.WFxF8T7rH/gZF99Edl/' > \"$WORK/htpasswd.2\"\n    CTR_SUB=$(docker_run \\\n        -v \"$SUBMODULE\":/git/repo:ro \\\n        -v \"$WORK/htpasswd.2\":/etc/htpasswd:ro \\\n        e2e/test/httpd)\n    IP_SUB=$(docker_ip \"$CTR_SUB\")\n\n    # Add the submodule to the main repo\n    echo -ne \"url=http://$IP_SUB/repo\\nusername=test\\npassword=test2\\n\" | git credential approve\n    git -C \"$REPO\" submodule add -q \"http://$IP_SUB/repo\" \"$SUBMODULE_REPO_NAME\"\n    git -C \"$REPO\" commit -aqm \"add submodule\"\n    git -C \"$REPO\" submodule update --recursive --remote > /dev/null 2>&1\n\n    # Run a git-over-SSH server.  Use password \"test3\".\n    # shellcheck disable=SC2016\n    echo 'test:$apr1$oKP2oGwp$ESJ4FESEP/8Sisy02B/vM/' > \"$WORK/htpasswd.3\"\n    CTR=$(docker_run \\\n        -v \"$REPO\":/git/repo:ro \\\n        -v \"$WORK/htpasswd.3\":/etc/htpasswd:ro \\\n        e2e/test/httpd)\n    IP=$(docker_ip \"$CTR\")\n\n    GIT_SYNC \\\n        --period=100ms \\\n        --repo=\"http://$IP/repo\" \\\n        --root=\"$ROOT\" \\\n        --link=\"link\" \\\n        --credential=\"{ \\\"url\\\": \\\"http://$IP_SUBSUB/repo\\\", \\\"username\\\": \\\"test\\\", \\\"password\\\": \\\"test1\\\" }\" \\\n        --credential=\"{ \\\"url\\\": \\\"http://$IP_SUB/repo\\\", \\\"username\\\": \\\"test\\\", \\\"password\\\": \\\"test2\\\" }\" \\\n        --credential=\"{ \\\"url\\\": \\\"http://$IP/repo\\\", \\\"username\\\": \\\"test\\\", \\\"password\\\": \\\"test3\\\" }\" \\\n        &\n    wait_for_sync \"${MAXWAIT}\"\n    assert_link_exists \"$ROOT/link\"\n    assert_file_exists \"$ROOT/link/file\"\n    assert_file_exists \"$ROOT/link/$SUBMODULE_REPO_NAME/submodule.file\"\n    assert_file_exists \"$ROOT/link/$SUBMODULE_REPO_NAME/$NESTED_SUBMODULE_REPO_NAME/nested-submodule.file\"\n    assert_metric_eq \"${METRIC_GOOD_SYNC_COUNT}\" 1\n\n    rm -rf $SUBMODULE\n    rm -rf $NESTED_SUBMODULE\n}\n\n##############################################\n# Test sparse-checkout files\n##############################################\nfunction e2e::sparse_checkout() {\n    echo \"!/*\" > \"$WORK/sparseconfig\"\n    echo \"!/*/\" >> \"$WORK/sparseconfig\"\n    echo \"file2\" >> \"$WORK/sparseconfig\"\n    echo \"${FUNCNAME[0]}\" > \"$REPO/file\"\n    echo \"${FUNCNAME[0]}\" > \"$REPO/file2\"\n    mkdir \"$REPO/dir\"\n    echo \"${FUNCNAME[0]}\" > \"$REPO/dir/file3\"\n    git -C \"$REPO\" add file2\n    git -C \"$REPO\" add dir\n    git -C \"$REPO\" commit -qam \"${FUNCNAME[0]}\"\n\n    GIT_SYNC \\\n        --one-time \\\n        --repo=\"file://$REPO\" \\\n        --root=\"$ROOT\" \\\n        --link=\"link\" \\\n        --sparse-checkout-file=\"$WORK/sparseconfig\"\n    assert_link_exists \"$ROOT/link\"\n    assert_file_exists \"$ROOT/link/file2\"\n    assert_file_absent \"$ROOT/link/file\"\n    assert_file_absent \"$ROOT/link/dir/file3\"\n    assert_file_absent \"$ROOT/link/dir\"\n    assert_file_eq \"$ROOT/link/file2\" \"${FUNCNAME[0]}\"\n}\n\n##############################################\n# Test additional git configs\n##############################################\nfunction e2e::additional_git_configs() {\n    GIT_SYNC \\\n        --one-time \\\n        --repo=\"file://$REPO\" \\\n        --root=\"$ROOT\" \\\n        --link=\"link\" \\\n        --git-config='http.postBuffer:10485760,sect.k1:\"a val\",sect.k2:another val'\n    assert_link_exists \"$ROOT/link\"\n    assert_file_exists \"$ROOT/link/file\"\n    assert_file_eq \"$ROOT/link/file\" \"${FUNCNAME[0]}\"\n}\n\n##############################################\n# Test export-error\n##############################################\nfunction e2e::export_error() {\n    assert_fail \\\n        GIT_SYNC \\\n            --repo=\"file://$REPO\" \\\n            --ref=does-not-exit \\\n            --root=\"$ROOT\" \\\n            --link=\"link\" \\\n            --error-file=\"error.json\"\n        assert_file_absent \"$ROOT/link\"\n        assert_file_absent \"$ROOT/link/file\"\n        assert_file_contains \"$ROOT/error.json\" \"couldn't find remote ref\"\n\n    # the error.json file should be removed if sync succeeds.\n    GIT_SYNC \\\n        --one-time \\\n        --repo=\"file://$REPO\" \\\n        --root=\"$ROOT\" \\\n        --link=\"link\" \\\n        --error-file=\"error.json\"\n    assert_link_exists \"$ROOT/link\"\n    assert_file_exists \"$ROOT/link/file\"\n    assert_file_eq \"$ROOT/link/file\" \"${FUNCNAME[0]}\"\n    assert_file_absent \"$ROOT/error.json\"\n}\n\n##############################################\n# Test export-error with an absolute path\n##############################################\nfunction e2e::export_error_abs_path() {\n    assert_fail \\\n        GIT_SYNC \\\n            --repo=\"file://$REPO\" \\\n            --ref=does-not-exit \\\n            --root=\"$ROOT\" \\\n            --link=\"link\" \\\n            --error-file=\"$ROOT/dir/error.json\"\n        assert_file_absent \"$ROOT/link\"\n        assert_file_absent \"$ROOT/link/file\"\n        assert_file_contains \"$ROOT/dir/error.json\" \"couldn't find remote ref\"\n}\n\n##############################################\n# Test touch-file\n##############################################\nfunction e2e::touch_file() {\n    # First sync\n    echo \"${FUNCNAME[0]} 1\" > \"$REPO/file\"\n    git -C \"$REPO\" commit -qam \"${FUNCNAME[0]} 1\"\n\n    GIT_SYNC \\\n        --period=100ms \\\n        --repo=\"file://$REPO\" \\\n        --root=\"$ROOT\" \\\n        --link=\"link\" \\\n        --touch-file=\"touch.file\" \\\n        &\n    wait_for_file_exists \"$ROOT/touch.file\" 3\n    assert_file_exists \"$ROOT/touch.file\"\n    rm -f \"$ROOT/touch.file\"\n    assert_link_exists \"$ROOT/link\"\n    assert_file_exists \"$ROOT/link/file\"\n    assert_file_eq \"$ROOT/link/file\" \"${FUNCNAME[0]} 1\"\n\n    # It should not come back until we commit again.\n    sleep 1\n    assert_file_absent \"$ROOT/touch.file\"\n\n    # Move HEAD forward\n    echo \"${FUNCNAME[0]} 2\" > \"$REPO/file\"\n    git -C \"$REPO\" commit -qam \"${FUNCNAME[0]} 2\"\n    wait_for_file_exists \"$ROOT/touch.file\" 3\n    assert_file_exists \"$ROOT/touch.file\"\n    rm -f \"$ROOT/touch.file\"\n    assert_link_exists \"$ROOT/link\"\n    assert_file_exists \"$ROOT/link/file\"\n    assert_file_eq \"$ROOT/link/file\" \"${FUNCNAME[0]} 2\"\n\n    # It should not come back until we commit again.\n    sleep 1\n    assert_file_absent \"$ROOT/touch.file\"\n\n    # Move HEAD backward\n    git -C \"$REPO\" reset -q --hard HEAD^\n    wait_for_file_exists \"$ROOT/touch.file\" 3\n    assert_file_exists \"$ROOT/touch.file\"\n    rm -f \"$ROOT/touch.file\"\n    assert_link_exists \"$ROOT/link\"\n    assert_file_exists \"$ROOT/link/file\"\n    assert_file_eq \"$ROOT/link/file\" \"${FUNCNAME[0]} 1\"\n\n    # It should not come back until we commit again.\n    sleep 1\n    assert_file_absent \"$ROOT/touch.file\"\n}\n\n##############################################\n# Test touch-file with an absolute path\n##############################################\nfunction e2e::touch_file_abs_path() {\n    # First sync\n    echo \"${FUNCNAME[0]} 1\" > \"$REPO/file\"\n    git -C \"$REPO\" commit -qam \"${FUNCNAME[0]} 1\"\n\n    GIT_SYNC \\\n        --period=100ms \\\n        --repo=\"file://$REPO\" \\\n        --root=\"$ROOT\" \\\n        --link=\"link\" \\\n        --touch-file=\"$ROOT/dir/touch.file\" \\\n        &\n    wait_for_file_exists \"$ROOT/dir/touch.file\" 3\n    assert_file_exists \"$ROOT/dir/touch.file\"\n    rm -f \"$ROOT/dir/touch.file\"\n    assert_link_exists \"$ROOT/link\"\n    assert_file_exists \"$ROOT/link/file\"\n    assert_file_eq \"$ROOT/link/file\" \"${FUNCNAME[0]} 1\"\n\n    # It should not come back until we commit again.\n    sleep 1\n    assert_file_absent \"$ROOT/dir/touch.file\"\n\n    # Move HEAD forward\n    echo \"${FUNCNAME[0]} 2\" > \"$REPO/file\"\n    git -C \"$REPO\" commit -qam \"${FUNCNAME[0]} 2\"\n    wait_for_file_exists \"$ROOT/dir/touch.file\" 3\n    assert_file_exists \"$ROOT/dir/touch.file\"\n    rm -f \"$ROOT/dir/touch.file\"\n    assert_link_exists \"$ROOT/link\"\n    assert_file_exists \"$ROOT/link/file\"\n    assert_file_eq \"$ROOT/link/file\" \"${FUNCNAME[0]} 2\"\n\n    # It should not come back until we commit again.\n    sleep 1\n    assert_file_absent \"$ROOT/dir/touch.file\"\n\n    # Move HEAD backward\n    git -C \"$REPO\" reset -q --hard HEAD^\n    wait_for_file_exists \"$ROOT/dir/touch.file\" 3\n    assert_file_exists \"$ROOT/dir/touch.file\"\n    rm -f \"$ROOT/dir/touch.file\"\n    assert_link_exists \"$ROOT/link\"\n    assert_file_exists \"$ROOT/link/file\"\n    assert_file_eq \"$ROOT/link/file\" \"${FUNCNAME[0]} 1\"\n\n    # It should not come back until we commit again.\n    sleep 1\n    assert_file_absent \"$ROOT/dir/touch.file\"\n}\n\n##############################################\n# Test github HTTPS\n##############################################\nfunction e2e::github_https() {\n    GIT_SYNC \\\n        --one-time \\\n        --repo=\"https://github.com/kubernetes/git-sync\" \\\n        --root=\"$ROOT\" \\\n        --link=\"link\"\n    assert_file_exists \"$ROOT/link/LICENSE\"\n}\n\n##############################################\n# Test git-gc default\n##############################################\nfunction e2e::gc_default() {\n    SHA1=$(git -C \"$REPO\" rev-parse HEAD)\n    dd if=/dev/urandom of=\"$REPO/big1\" bs=1024 count=4096 >/dev/null\n    git -C \"$REPO\" add .\n    git -C \"$REPO\" commit -qam \"${FUNCNAME[0]} 1\"\n    SHA2=$(git -C \"$REPO\" rev-parse HEAD)\n    dd if=/dev/urandom of=\"$REPO/big2\" bs=1024 count=4096 >/dev/null\n    git -C \"$REPO\" add .\n    git -C \"$REPO\" commit -qam \"${FUNCNAME[0]} 2\"\n    SHA3=$(git -C \"$REPO\" rev-parse HEAD)\n\n    GIT_SYNC \\\n        --one-time \\\n        --repo=\"file://$REPO\" \\\n        --root=\"$ROOT\" \\\n        --link=\"link\" \\\n        --ref=\"$SHA3\" \\\n        --depth=0\n    assert_link_exists \"$ROOT/link\"\n    assert_file_exists \"$ROOT/link/big1\"\n    assert_file_exists \"$ROOT/link/big2\"\n    SIZE=$(du -s \"$ROOT\" | cut -f1)\n    if [ \"$SIZE\" -lt 14000 ]; then\n        fail \"repo is impossibly small: $SIZE\"\n    fi\n    if [ \"$SIZE\" -gt 18000 ]; then\n        fail \"repo is too big: $SIZE\"\n    fi\n\n    GIT_SYNC \\\n        --one-time \\\n        --repo=\"file://$REPO\" \\\n        --root=\"$ROOT\" \\\n        --link=\"link\" \\\n        --ref=\"$SHA3\" \\\n        --depth=1\n    assert_link_exists \"$ROOT/link\"\n    assert_file_exists \"$ROOT/link/big1\"\n    assert_file_exists \"$ROOT/link/big2\"\n    SIZE=$(du -s \"$ROOT\" | cut -f1)\n    if [ \"$SIZE\" -lt 14000 ]; then\n        fail \"repo is impossibly small: $SIZE\"\n    fi\n    if [ \"$SIZE\" -gt 18000 ]; then\n        fail \"repo is too big: $SIZE\"\n    fi\n\n    GIT_SYNC \\\n        --one-time \\\n        --repo=\"file://$REPO\" \\\n        --root=\"$ROOT\" \\\n        --link=\"link\" \\\n        --ref=\"$SHA2\" \\\n        --depth=1\n    assert_link_exists \"$ROOT/link\"\n    assert_file_exists \"$ROOT/link/big1\"\n    assert_file_absent \"$ROOT/link/big2\"\n    SIZE=$(du -s \"$ROOT\" | cut -f1)\n    if [ \"$SIZE\" -lt 7000 ]; then\n        fail \"repo is impossibly small: $SIZE\"\n    fi\n    if [ \"$SIZE\" -gt 9000 ]; then\n        fail \"repo is too big: $SIZE\"\n    fi\n\n    GIT_SYNC \\\n        --one-time \\\n        --repo=\"file://$REPO\" \\\n        --root=\"$ROOT\" \\\n        --link=\"link\" \\\n        --ref=\"$SHA1\" \\\n        --depth=1\n    assert_link_exists \"$ROOT/link\"\n    assert_file_absent \"$ROOT/link/big1\"\n    assert_file_absent \"$ROOT/link/big2\"\n    SIZE=$(du -s \"$ROOT\" | cut -f1)\n    if [ \"$SIZE\" -lt 100 ]; then\n        fail \"repo is impossibly small: $SIZE\"\n    fi\n    if [ \"$SIZE\" -gt 1000 ]; then\n        fail \"repo is too big: $SIZE\"\n    fi\n}\n\n##############################################\n# Test git-gc=auto\n##############################################\nfunction e2e::gc_auto() {\n    GIT_SYNC \\\n        --one-time \\\n        --repo=\"file://$REPO\" \\\n        --root=\"$ROOT\" \\\n        --link=\"link\" \\\n        --git-gc=\"auto\"\n    assert_link_exists \"$ROOT/link\"\n    assert_file_exists \"$ROOT/link/file\"\n    assert_file_eq \"$ROOT/link/file\" \"${FUNCNAME[0]}\"\n}\n\n##############################################\n# Test git-gc=always\n##############################################\nfunction e2e::gc_always() {\n    GIT_SYNC \\\n        --one-time \\\n        --repo=\"file://$REPO\" \\\n        --root=\"$ROOT\" \\\n        --link=\"link\" \\\n        --git-gc=\"always\"\n    assert_link_exists \"$ROOT/link\"\n    assert_file_exists \"$ROOT/link/file\"\n    assert_file_eq \"$ROOT/link/file\" \"${FUNCNAME[0]}\"\n}\n\n##############################################\n# Test git-gc=aggressive\n##############################################\nfunction e2e::gc_aggressive() {\n    GIT_SYNC \\\n        --one-time \\\n        --repo=\"file://$REPO\" \\\n        --root=\"$ROOT\" \\\n        --link=\"link\" \\\n        --git-gc=\"aggressive\"\n    assert_link_exists \"$ROOT/link\"\n    assert_file_exists \"$ROOT/link/file\"\n    assert_file_eq \"$ROOT/link/file\" \"${FUNCNAME[0]}\"\n}\n\n##############################################\n# Test git-gc=off\n##############################################\nfunction e2e::gc_off() {\n    GIT_SYNC \\\n        --one-time \\\n        --repo=\"file://$REPO\" \\\n        --root=\"$ROOT\" \\\n        --link=\"link\" \\\n        --git-gc=\"off\"\n    assert_link_exists \"$ROOT/link\"\n    assert_file_exists \"$ROOT/link/file\"\n    assert_file_eq \"$ROOT/link/file\" \"${FUNCNAME[0]}\"\n}\n\n#\n# main\n#\n\nfunction list_tests() {\n    (\n        shopt -s extdebug\n        declare -F \\\n            | cut -f3 -d' ' \\\n            | grep \"^e2e::\" \\\n            | while read -r X; do declare -F \"$X\"; done \\\n            | sort -n -k2 \\\n            | cut -f1 -d' ' \\\n            | sed 's/^e2e:://'\n    )\n}\n\n# Figure out which, if any, tests to run.\nmapfile -t all_tests < <(list_tests)\ntests_to_run=()\n\nfunction print_tests() {\n    echo \"available tests:\"\n    for t in \"${all_tests[@]}\"; do\n        echo \"    $t\"\n    done\n}\n\n# Validate and accumulate tests to run if args are specified.\nfor arg; do\n    # Use -? to list known tests.\n    if [[ \"${arg}\" == \"-?\" ]]; then\n        print_tests\n        exit 0\n    fi\n    if [[ \"${arg}\" =~ ^- ]]; then\n        echo \"ERROR: unknown flag '${arg}'\"\n        exit 1\n    fi\n    # Make sure each non-flag arg matches at least one test.\n    nmatches=0\n    for t in \"${all_tests[@]}\"; do\n        if [[ \"${t}\" =~ ${arg} ]]; then\n            nmatches=$((nmatches+1))\n            # Don't run tests twice, just keep the first match.\n            if [[ \" ${tests_to_run[*]} \" == *\" ${t} \"* ]]; then\n                continue\n            fi\n            tests_to_run+=(\"${t}\")\n            continue\n        fi\n    done\n    if [[ ${nmatches} == 0 ]]; then\n        echo \"ERROR: no tests match pattern '${arg}'\"\n        echo\n        print_tests\n        exit 1\n    fi\n    tests_to_run+=(\"${matches[@]}\")\ndone\nset -- \"${tests_to_run[@]}\"\n\n# If no tests were specified, run them all.\nif [[ \"$#\" == 0 ]]; then\n    set -- \"${all_tests[@]}\"\nfi\n\n# Build it\n$build_container && make container REGISTRY=e2e VERSION=\"${E2E_TAG}\" ALLOW_STALE_APT=1\nmake test-tools REGISTRY=e2e\n\nfunction finish() {\n    r=$?\n    trap \"\" INT EXIT ERR\n    if [[ $r != 0 ]]; then\n        echo\n        echo \"the directory $DIR was not removed as it contains\"\\\n             \"log files useful for debugging\"\n    fi\n    exit $r\n}\ntrap finish INT EXIT ERR\n\n# Run a test function and return its error code.  This is needed because POSIX\n# dictates that `errexit` does not apply inside a function called in an `if`\n# context.  But if we don't call it with `if`, then it terminates the whole\n# test run as soon as one test fails.  So this jumps through hoops to let the\n# individual test functions run outside of `if` and return a code in a\n# variable.\n#\n# Args:\n#  $1: the name of a variable to populate with the return code\n#  $2+: the test function to run and optional args\nfunction run_test() {\n    retvar=$1\n    shift\n\n    declare -g \"$retvar\"\n    local restore_opts\n    restore_opts=$(set +o)\n    set +o errexit\n    set +o nounset\n    set +o pipefail\n    (\n        set -o errexit\n        set -o nounset\n        set -o pipefail\n        \"$@\"\n    )\n    eval \"$retvar=$?\"\n    eval \"$restore_opts\"\n}\n\n# Override local configs for predictability in this test.\nexport GIT_CONFIG_GLOBAL=\"$DIR/gitconfig\"\nexport GIT_CONFIG_SYSTEM=/dev/null\ngit config --global user.email \"git-sync-test@example.com\"\ngit config --global user.name \"git-sync-test\"\n\n# Make sure files we create can be group writable.\numask 0002\n\n# Mark all repos as safe, to avoid \"dubious ownership\".\ngit config --global --add safe.directory '*'\n\n# Store credentials for the test.\ngit config --global credential.helper \"store --file $DIR/gitcreds\"\n\n# Log some info\nif [[ -n \"${VERBOSE:-}\" ]]; then\n    git version\n    echo\n    docker version\n    echo\nfi\n\nFAILS=()\nFINAL_RET=0\nRUNS=\"${RUNS:-1}\"\n\necho\necho \"test root is $DIR\"\nif (( \"${RUNS}\" > 1 )); then\n    echo \"  RUNS=$RUNS\"\nfi\nif [[ \"${CLEANUP:-}\" == 0 ]]; then\n    echo \"  CLEANUP disabled\"\nfi\nif [[ -n \"${VERBOSE:-}\" ]]; then\n    echo \"  VERBOSE enabled\"\nfi\necho\n\n# Iterate over the chosen tests and run them.\nfor t; do\n    TEST_FN=\"e2e::${t}\"\n    TEST_RET=0\n    RUN=0\n    while (( \"${RUN}\" < \"${RUNS}\" )); do\n        clean_root\n        clean_work\n        init_repo \"${TEST_FN}\"\n\n        sfx=\"\"\n        if (( \"${RUNS}\" > 1 )); then\n            sfx=\" ($((RUN+1))/${RUNS})\"\n        fi\n        echo -n \"testcase ${t}${sfx}: \"\n\n        # Set &3 for our own output, let testcases use &2 and &1.\n        exec 3>&1\n\n        # See comments on run_test for details.\n        RUN_RET=0\n        LOG=\"${DIR}/log.$t\"\n        run_test RUN_RET \"${TEST_FN}\" >\"${LOG}.${RUN}\" 2>&1\n        if [[ \"$RUN_RET\" == 0 ]]; then\n            pass\n        elif [[ \"$RUN_RET\" == 43 ]]; then\n            true # do nothing\n        else\n            TEST_RET=1\n            if [[ \"$RUN_RET\" != 42 ]]; then\n                echo \"FAIL: unknown error\"\n            fi\n            if [[ -n \"${VERBOSE:-}\" ]]; then\n                echo -ne \"\\n\\n\"\n                echo \"LOG ----------------------\"\n                cat \"${LOG}.${RUN}\"\n                echo \"--------------------------\"\n                echo -ne \"\\n\\n\"\n            fi\n        fi\n        remove_containers || true\n        RUN=$((RUN+1))\n    done\n    if [[ \"$TEST_RET\" != 0 ]]; then\n        FINAL_RET=1\n        FAILS+=(\"$t  (log: ${LOG}.*)\")\n    fi\ndone\nif [[ \"$FINAL_RET\" != 0 ]]; then\n    echo\n    echo \"the following tests failed:\"\n    for f in \"${FAILS[@]}\"; do\n        echo \"    $f\"\n    done\n    exit 1\nfi\n\n\n"
        },
        {
          "name": "test_git.sh",
          "type": "blob",
          "size": 28.349609375,
          "content": "#!/bin/bash\n#\n# Copyright 2023 The Kubernetes Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nset -o errexit\nset -o nounset\nset -o pipefail\n\nfunction fail() {\n    echo \"FAIL:\" \"$@\" >&3\n    return 42\n}\n\nfunction pass() {\n    echo \"PASS\"\n}\n\nfunction assert_file_exists() {\n    if ! [[ -f \"$1\" ]]; then\n        fail \"$1 does not exist\"\n    fi\n}\n\nfunction assert_file_absent() {\n    if [[ -f \"$1\" ]]; then\n        fail \"$1 exists but should not\"\n    fi\n}\n\nfunction assert_eq() {\n    if [[ \"$1\" == \"$2\" ]]; then\n        return\n    fi\n    fail \"'$1' does not equal '$2'\"\n}\n\nfunction assert_substr() {\n    if [[ \"$1\" == *\"$2\"* ]]; then\n        return\n    fi\n    fail \"'$1' does not contain '$2'\"\n}\n\n# DIR is the directory in which all this test's state lives.\nRUNID=\"${RANDOM}${RANDOM}\"\nDIR=\"/tmp/git-sync-git.$RUNID\"\nmkdir \"$DIR\"\n\n# WORKDIR is where test cases run\nWORKDIR=\"$DIR/work\"\nfunction clean_workdir() {\n    rm -rf \"$WORKDIR\"\n    mkdir -p \"$WORKDIR\"\n}\n\n#\n# After all the test functions are defined, we can iterate over them and run\n# them all automatically.  See the end of this file.\n#\n\n##############################################\n# Test `git init` on an existing repo\n##############################################\nfunction git::reinit_existing_repo() {\n    git init -b main\n    date > file\n    git add file \n    git commit -qam 'commit_1'\n    TREE1=\"$(git ls-tree HEAD | cut -d' ' -f3 | cut -f1)\"\n    git init\n    TREE2=\"$(git ls-tree HEAD | cut -d' ' -f3 | cut -f1)\"\n    assert_eq \"$TREE1\" \"$TREE2\"\n}\n\n##############################################\n# Test `git fetch` of a branch\n##############################################\nfunction git::fetch_upstream_branch() {\n    mkdir upstream\n    pushd upstream >/dev/null\n    git init -b main\n\n    # A commit on branch 1\n    git checkout -b upstream_branch_1\n    date > file_1\n    git add file_1\n    git commit -qam 'commit_1'\n    SHA1=\"$(git rev-parse HEAD)\"\n\n    # A commit on branch 2\n    git checkout -b upstream_branch_2\n    date > file_2\n    git add file_2\n    git commit -qam 'commit_2'\n    SHA2=\"$(git rev-parse HEAD)\"\n\n    popd >/dev/null\n\n    mkdir clone\n    cd clone\n    git init -b clone_branch\n\n    assert_substr \"$(git cat-file -t \"$SHA1\" 2>&1 || true)\" \"could not get object info\"\n    assert_substr \"$(git cat-file -t \"$SHA2\" 2>&1 || true)\" \"could not get object info\"\n\n    git fetch \"file://$WORKDIR/upstream\" upstream_branch_1\n    assert_eq \"$(git cat-file -t \"$SHA1\")\" \"commit\"\n    assert_substr \"$(git cat-file -t \"$SHA2\" 2>&1 || true)\" \"could not get object info\"\n    git checkout \"$SHA1\"\n    assert_file_exists file_1\n    assert_file_absent file_2\n\n    git fetch \"file://$WORKDIR/upstream\" upstream_branch_2\n    assert_eq \"$(git cat-file -t \"$SHA1\")\" \"commit\"\n    assert_eq \"$(git cat-file -t \"$SHA2\")\" \"commit\"\n    git checkout \"$SHA2\"\n    assert_file_exists file_1\n    assert_file_exists file_2\n}\n\n##############################################\n# Test `git fetch` of a tag\n##############################################\nfunction git::fetch_upstream_tag() {\n    mkdir upstream\n    pushd upstream >/dev/null\n    git init -b main\n\n    # A tag on branch 1 (not at HEAD)\n    git checkout -b upstream_branch_1\n    date > file_1\n    git add file_1\n    git commit -qam 'commit_1'\n    SHA1=\"$(git rev-parse HEAD)\"\n    git tag upstream_tag_1\n\n    # Another tag on branch 1 (at HEAD)\n    date > file_2\n    git add file_2\n    git commit -qam 'commit_2'\n    SHA2=\"$(git rev-parse HEAD)\"\n    git tag upstream_tag_2\n\n    # A tag on branch 2 (not at HEAD)\n    git checkout -b upstream_branch_2\n    date > file_3\n    git add file_3\n    git commit -qam 'commit_3'\n    SHA3=\"$(git rev-parse HEAD)\"\n    git tag upstream_tag_3\n\n    # Another tag on branch 2 (at HEAD)\n    date > file_4\n    git add file_4\n    git commit -qam 'commit_4'\n    SHA4=\"$(git rev-parse HEAD)\"\n    git tag upstream_tag_4\n\n    popd >/dev/null\n\n    mkdir clone\n    pushd clone >/dev/null\n    git init -b clone_branch\n\n    assert_substr \"$(git cat-file -t \"$SHA1\" 2>&1 || true)\" \"could not get object info\"\n    assert_substr \"$(git cat-file -t \"$SHA2\" 2>&1 || true)\" \"could not get object info\"\n    assert_substr \"$(git cat-file -t \"$SHA3\" 2>&1 || true)\" \"could not get object info\"\n    assert_substr \"$(git cat-file -t \"$SHA4\" 2>&1 || true)\" \"could not get object info\"\n\n    git fetch \"file://$WORKDIR/upstream\" upstream_tag_1\n    assert_eq \"$(git cat-file -t \"$SHA1\")\" \"commit\"\n    assert_substr \"$(git cat-file -t \"$SHA2\" 2>&1 || true)\" \"could not get object info\"\n    assert_substr \"$(git cat-file -t \"$SHA3\" 2>&1 || true)\" \"could not get object info\"\n    assert_substr \"$(git cat-file -t \"$SHA4\" 2>&1 || true)\" \"could not get object info\"\n    git checkout \"$SHA1\"\n    assert_file_exists file_1\n    assert_file_absent file_2\n    assert_file_absent file_3\n    assert_file_absent file_4\n\n    git fetch \"file://$WORKDIR/upstream\" upstream_tag_2\n    assert_eq \"$(git cat-file -t \"$SHA1\")\" \"commit\"\n    assert_eq \"$(git cat-file -t \"$SHA2\")\" \"commit\"\n    assert_substr \"$(git cat-file -t \"$SHA3\" 2>&1 || true)\" \"could not get object info\"\n    assert_substr \"$(git cat-file -t \"$SHA4\" 2>&1 || true)\" \"could not get object info\"\n    git checkout \"$SHA2\"\n    assert_file_exists file_1\n    assert_file_exists file_2\n    assert_file_absent file_3\n    assert_file_absent file_4\n\n    git fetch \"file://$WORKDIR/upstream\" upstream_tag_3\n    assert_eq \"$(git cat-file -t \"$SHA1\")\" \"commit\"\n    assert_eq \"$(git cat-file -t \"$SHA2\")\" \"commit\"\n    assert_eq \"$(git cat-file -t \"$SHA3\")\" \"commit\"\n    assert_substr \"$(git cat-file -t \"$SHA4\" 2>&1 || true)\" \"could not get object info\"\n    git checkout \"$SHA3\"\n    assert_file_exists file_1\n    assert_file_exists file_2\n    assert_file_exists file_3\n    assert_file_absent file_4\n\n    git fetch \"file://$WORKDIR/upstream\" upstream_tag_4\n    assert_eq \"$(git cat-file -t \"$SHA1\")\" \"commit\"\n    assert_eq \"$(git cat-file -t \"$SHA2\")\" \"commit\"\n    assert_eq \"$(git cat-file -t \"$SHA3\")\" \"commit\"\n    assert_eq \"$(git cat-file -t \"$SHA4\")\" \"commit\"\n    git checkout \"$SHA4\"\n    assert_file_exists file_1\n    assert_file_exists file_2\n    assert_file_exists file_3\n    assert_file_exists file_4\n}\n\n##############################################\n# Test `git fetch` of an annotated tag\n##############################################\nfunction git::fetch_upstream_tag_annotated() {\n    mkdir upstream\n    pushd upstream >/dev/null\n    git init -b main\n\n    # A tag on branch 1 (not at HEAD)\n    git checkout -b upstream_branch_1\n    date > file_1\n    git add file_1\n    git commit -qam 'commit_1'\n    SHA1=\"$(git rev-parse HEAD)\"\n    git tag -am \"anntag_1\" upstream_anntag_1\n\n    # Another tag on branch 1 (at HEAD)\n    date > file_2\n    git add file_2\n    git commit -qam 'commit_2'\n    SHA2=\"$(git rev-parse HEAD)\"\n    git tag -am \"anntag_2\" upstream_anntag_2\n\n    # A tag on branch 2 (not at HEAD)\n    git checkout -b upstream_branch_2\n    date > file_3\n    git add file_3\n    git commit -qam 'commit_3'\n    SHA3=\"$(git rev-parse HEAD)\"\n    git tag -am \"anntag_3\" upstream_anntag_3\n\n    # Another tag on branch 2 (at HEAD)\n    date > file_4\n    git add file_4\n    git commit -qam 'commit_4'\n    SHA4=\"$(git rev-parse HEAD)\"\n    git tag -am \"anntag_4\" upstream_anntag_4\n\n    popd >/dev/null\n\n    mkdir clone\n    pushd clone >/dev/null\n    git init -b clone_branch\n\n    assert_substr \"$(git cat-file -t \"$SHA1\" 2>&1 || true)\" \"could not get object info\"\n    assert_substr \"$(git cat-file -t \"$SHA2\" 2>&1 || true)\" \"could not get object info\"\n    assert_substr \"$(git cat-file -t \"$SHA3\" 2>&1 || true)\" \"could not get object info\"\n    assert_substr \"$(git cat-file -t \"$SHA4\" 2>&1 || true)\" \"could not get object info\"\n\n    git fetch \"file://$WORKDIR/upstream\" upstream_anntag_1\n    assert_eq \"$(git cat-file -t \"$SHA1\")\" \"commit\"\n    assert_substr \"$(git cat-file -t \"$SHA2\" 2>&1 || true)\" \"could not get object info\"\n    assert_substr \"$(git cat-file -t \"$SHA3\" 2>&1 || true)\" \"could not get object info\"\n    assert_substr \"$(git cat-file -t \"$SHA4\" 2>&1 || true)\" \"could not get object info\"\n    git checkout \"$SHA1\"\n    assert_file_exists file_1\n    assert_file_absent file_2\n    assert_file_absent file_3\n    assert_file_absent file_4\n\n    git fetch \"file://$WORKDIR/upstream\" upstream_anntag_2\n    assert_eq \"$(git cat-file -t \"$SHA1\")\" \"commit\"\n    assert_eq \"$(git cat-file -t \"$SHA2\")\" \"commit\"\n    assert_substr \"$(git cat-file -t \"$SHA3\" 2>&1 || true)\" \"could not get object info\"\n    assert_substr \"$(git cat-file -t \"$SHA4\" 2>&1 || true)\" \"could not get object info\"\n    git checkout \"$SHA2\"\n    assert_file_exists file_1\n    assert_file_exists file_2\n    assert_file_absent file_3\n    assert_file_absent file_4\n\n    git fetch \"file://$WORKDIR/upstream\" upstream_anntag_3\n    assert_eq \"$(git cat-file -t \"$SHA1\")\" \"commit\"\n    assert_eq \"$(git cat-file -t \"$SHA2\")\" \"commit\"\n    assert_eq \"$(git cat-file -t \"$SHA3\")\" \"commit\"\n    assert_substr \"$(git cat-file -t \"$SHA4\" 2>&1 || true)\" \"could not get object info\"\n    git checkout \"$SHA3\"\n    assert_file_exists file_1\n    assert_file_exists file_2\n    assert_file_exists file_3\n    assert_file_absent file_4\n\n    git fetch \"file://$WORKDIR/upstream\" upstream_anntag_4\n    assert_eq \"$(git cat-file -t \"$SHA1\")\" \"commit\"\n    assert_eq \"$(git cat-file -t \"$SHA2\")\" \"commit\"\n    assert_eq \"$(git cat-file -t \"$SHA3\")\" \"commit\"\n    assert_eq \"$(git cat-file -t \"$SHA4\")\" \"commit\"\n    git checkout \"$SHA4\"\n    assert_file_exists file_1\n    assert_file_exists file_2\n    assert_file_exists file_3\n    assert_file_exists file_4\n}\n\n##############################################\n# Test `git fetch` of a SHA\n##############################################\nfunction git::fetch_upstream_sha() {\n    mkdir upstream\n    pushd upstream >/dev/null\n    git init -b main\n\n    # A commit on branch 1 (not at HEAD)\n    git checkout -b upstream_branch_1\n    date > file_1\n    git add file_1\n    git commit -qam 'commit_1'\n    SHA1=\"$(git rev-parse HEAD)\"\n\n    # Another commit on branch 1 (at HEAD)\n    date > file_2\n    git add file_2\n    git commit -qam 'commit_2'\n    SHA2=\"$(git rev-parse HEAD)\"\n\n    # A commit on branch 2 (not at HEAD)\n    git checkout -b upstream_branch_2\n    date > file_3\n    git add file_3\n    git commit -qam 'commit_3'\n    SHA3=\"$(git rev-parse HEAD)\"\n\n    # Another commit on branch 2 (at HEAD)\n    date > file_4\n    git add file_4\n    git commit -qam 'commit_4'\n    SHA4=\"$(git rev-parse HEAD)\"\n\n    popd >/dev/null\n\n    mkdir clone\n    pushd clone >/dev/null\n    git init -b clone_branch\n\n    assert_substr \"$(git cat-file -t \"$SHA1\" 2>&1 || true)\" \"could not get object info\"\n    assert_substr \"$(git cat-file -t \"$SHA2\" 2>&1 || true)\" \"could not get object info\"\n    assert_substr \"$(git cat-file -t \"$SHA3\" 2>&1 || true)\" \"could not get object info\"\n    assert_substr \"$(git cat-file -t \"$SHA4\" 2>&1 || true)\" \"could not get object info\"\n\n    git fetch \"file://$WORKDIR/upstream\" \"$SHA1\"\n    assert_eq \"$(git cat-file -t \"$SHA1\")\" \"commit\"\n    assert_substr \"$(git cat-file -t \"$SHA2\" 2>&1 || true)\" \"could not get object info\"\n    assert_substr \"$(git cat-file -t \"$SHA3\" 2>&1 || true)\" \"could not get object info\"\n    assert_substr \"$(git cat-file -t \"$SHA4\" 2>&1 || true)\" \"could not get object info\"\n    git checkout \"$SHA1\"\n    assert_file_exists file_1\n    assert_file_absent file_2\n    assert_file_absent file_3\n    assert_file_absent file_4\n\n    git fetch \"file://$WORKDIR/upstream\" \"$SHA2\"\n    assert_eq \"$(git cat-file -t \"$SHA1\")\" \"commit\"\n    assert_eq \"$(git cat-file -t \"$SHA2\")\" \"commit\"\n    assert_substr \"$(git cat-file -t \"$SHA3\" 2>&1 || true)\" \"could not get object info\"\n    assert_substr \"$(git cat-file -t \"$SHA4\" 2>&1 || true)\" \"could not get object info\"\n    git checkout \"$SHA2\"\n    assert_file_exists file_1\n    assert_file_exists file_2\n    assert_file_absent file_3\n    assert_file_absent file_4\n\n    git fetch \"file://$WORKDIR/upstream\" \"$SHA3\"\n    assert_eq \"$(git cat-file -t \"$SHA1\")\" \"commit\"\n    assert_eq \"$(git cat-file -t \"$SHA2\")\" \"commit\"\n    assert_eq \"$(git cat-file -t \"$SHA3\")\" \"commit\"\n    assert_substr \"$(git cat-file -t \"$SHA4\" 2>&1 || true)\" \"could not get object info\"\n    git checkout \"$SHA3\"\n    assert_file_exists file_1\n    assert_file_exists file_2\n    assert_file_exists file_3\n    assert_file_absent file_4\n\n    git fetch \"file://$WORKDIR/upstream\" \"$SHA4\"\n    assert_eq \"$(git cat-file -t \"$SHA1\")\" \"commit\"\n    assert_eq \"$(git cat-file -t \"$SHA2\")\" \"commit\"\n    assert_eq \"$(git cat-file -t \"$SHA3\")\" \"commit\"\n    assert_eq \"$(git cat-file -t \"$SHA4\")\" \"commit\"\n    git checkout \"$SHA4\"\n    assert_file_exists file_1\n    assert_file_exists file_2\n    assert_file_exists file_3\n    assert_file_exists file_4\n}\n\n##############################################\n# Test git shallow fetch from a branch\n##############################################\nfunction git::shallow_fetch_branch() {\n    mkdir upstream\n    pushd upstream >/dev/null\n    git init -b upstream_branch\n\n    # Some commits\n    date > file_1\n    git add file_1\n    git commit -qam 'commit_1'\n    date > file_2\n    git add file_2\n    git commit -qam 'commit_2'\n    SHA=\"$(git rev-parse HEAD)\"\n\n    popd >/dev/null\n\n    mkdir clone\n    cd clone\n    git init -b clone_branch\n\n    git fetch \"file://$WORKDIR/upstream\" upstream_branch\n    git checkout \"$SHA\"\n    assert_file_exists file_1\n    assert_file_exists file_2\n    assert_eq \"$(git rev-parse --is-shallow-repository)\" \"false\"\n\n    git fetch \"file://$WORKDIR/upstream\" upstream_branch --depth 1\n    git checkout \"$SHA\"\n    assert_file_exists file_1\n    assert_file_exists file_2\n    assert_eq \"$(git rev-parse --is-shallow-repository)\" \"true\"\n\n    git fetch \"file://$WORKDIR/upstream\" upstream_branch --unshallow\n    git checkout \"$SHA\"\n    assert_file_exists file_1\n    assert_file_exists file_2\n    assert_eq \"$(git rev-parse --is-shallow-repository)\" \"false\"\n}\n\n##############################################\n# Test git shallow fetch from a tag\n##############################################\nfunction git::shallow_fetch_tag() {\n    mkdir upstream\n    pushd upstream >/dev/null\n    git init -b upstream_branch\n\n    # Some commits\n    date > file_1\n    git add file_1\n    git commit -qam 'commit_1'\n    date > file_2\n    git add file_2\n    git commit -qam 'commit_2'\n    SHA=\"$(git rev-parse HEAD)\"\n    git tag upstream_tag\n\n    popd >/dev/null\n\n    mkdir clone\n    cd clone\n    git init -b clone_branch\n\n    git fetch \"file://$WORKDIR/upstream\" upstream_tag\n    git checkout \"$SHA\"\n    assert_file_exists file_1\n    assert_file_exists file_2\n    assert_eq \"$(git rev-parse --is-shallow-repository)\" \"false\"\n\n    git fetch \"file://$WORKDIR/upstream\" upstream_tag --depth 1\n    git checkout \"$SHA\"\n    assert_file_exists file_1\n    assert_file_exists file_2\n    assert_eq \"$(git rev-parse --is-shallow-repository)\" \"true\"\n\n    git fetch \"file://$WORKDIR/upstream\" upstream_tag --unshallow\n    git checkout \"$SHA\"\n    assert_file_exists file_1\n    assert_file_exists file_2\n    assert_eq \"$(git rev-parse --is-shallow-repository)\" \"false\"\n}\n\n##############################################\n# Test git shallow fetch from an annotated tag\n##############################################\nfunction git::shallow_fetch_tag_annotated() {\n    mkdir upstream\n    pushd upstream >/dev/null\n    git init -b upstream_branch\n\n    # Some commits\n    date > file_1\n    git add file_1\n    git commit -qam 'commit_1'\n    date > file_2\n    git add file_2\n    git commit -qam 'commit_2'\n    SHA=\"$(git rev-parse HEAD)\"\n    git tag -am \"upstream_anntag\" upstream_anntag\n\n    popd >/dev/null\n\n    mkdir clone\n    cd clone\n    git init -b clone_branch\n\n    git fetch \"file://$WORKDIR/upstream\" upstream_anntag\n    git checkout \"$SHA\"\n    assert_file_exists file_1\n    assert_file_exists file_2\n    assert_eq \"$(git rev-parse --is-shallow-repository)\" \"false\"\n\n    git fetch \"file://$WORKDIR/upstream\" upstream_anntag --depth 1\n    git checkout \"$SHA\"\n    assert_file_exists file_1\n    assert_file_exists file_2\n    assert_eq \"$(git rev-parse --is-shallow-repository)\" \"true\"\n\n    git fetch \"file://$WORKDIR/upstream\" upstream_anntag --unshallow\n    git checkout \"$SHA\"\n    assert_file_exists file_1\n    assert_file_exists file_2\n    assert_eq \"$(git rev-parse --is-shallow-repository)\" \"false\"\n}\n\n##############################################\n# Test git shallow fetch from a SHA\n##############################################\nfunction git::shallow_fetch_sha() {\n    mkdir upstream\n    pushd upstream >/dev/null\n    git init -b upstream_branch\n\n    # Some commits\n    date > file_1\n    git add file_1\n    git commit -qam 'commit_1'\n    date > file_2\n    git add file_2\n    git commit -qam 'commit_2'\n    SHA=\"$(git rev-parse HEAD)\"\n\n    popd >/dev/null\n\n    mkdir clone\n    cd clone\n    git init -b clone_branch\n\n    git fetch \"file://$WORKDIR/upstream\" \"$SHA\"\n    git checkout \"$SHA\"\n    assert_file_exists file_1\n    assert_file_exists file_2\n    assert_eq \"$(git rev-parse --is-shallow-repository)\" \"false\"\n\n    git fetch \"file://$WORKDIR/upstream\" \"$SHA\" --depth 1\n    git checkout \"$SHA\"\n    assert_file_exists file_1\n    assert_file_exists file_2\n    assert_eq \"$(git rev-parse --is-shallow-repository)\" \"true\"\n\n    git fetch \"file://$WORKDIR/upstream\" \"$SHA\" --unshallow\n    git checkout \"$SHA\"\n    assert_file_exists file_1\n    assert_file_exists file_2\n    assert_eq \"$(git rev-parse --is-shallow-repository)\" \"false\"\n}\n\n##############################################\n# Test git fetch with depth too large\n##############################################\nfunction git::fetch_too_large_depth() {\n    mkdir upstream\n    pushd upstream >/dev/null\n    git init -b upstream_branch\n\n    # Some commits\n    date > file_1\n    git add file_1\n    git commit -qam 'commit_1'\n    date > file_2\n    git add file_2\n    git commit -qam 'commit_2'\n    SHA=\"$(git rev-parse HEAD)\"\n\n    popd >/dev/null\n\n    mkdir clone\n    cd clone\n    git init -b clone_branch\n\n    git fetch \"file://$WORKDIR/upstream\" upstream_branch --depth 1000\n    git checkout \"$SHA\"\n    assert_file_exists file_1\n    assert_file_exists file_2\n    assert_eq \"$(git rev-parse --is-shallow-repository)\" \"false\"\n}\n\n##############################################\n# Test git rev-parse with a branch\n##############################################\nfunction git::rev_parse_branch() {\n    mkdir repo\n    pushd repo >/dev/null\n    git init -b main\n\n    # A commit on branch 1\n    git checkout -b branch_1\n    date > file_1\n    git add file_1\n    git commit -qam 'commit_1'\n    SHA1=\"$(git rev-parse HEAD)\"\n\n    # A commit on branch 2\n    git checkout -b branch_2\n    date > file_2\n    git add file_2\n    git commit -qam 'commit_2'\n    SHA2=\"$(git rev-parse HEAD)\"\n\n    assert_eq \"$(git rev-parse branch_1)\" \"$SHA1\"\n    assert_eq \"$(git rev-parse 'branch_1^{commit}')\" \"$SHA1\"\n    assert_eq \"$(git rev-parse branch_2)\" \"$SHA2\"\n    assert_eq \"$(git rev-parse 'branch_2^{commit}')\" \"$SHA2\"\n}\n\n##############################################\n# Test git rev-parse with a tag\n##############################################\nfunction git::rev_parse_tag() {\n    mkdir repo\n    pushd repo >/dev/null\n    git init -b main\n\n    # A tag on branch 1 (not at HEAD)\n    git checkout -b branch_1\n    date > file_1\n    git add file_1\n    git commit -qam 'commit_1'\n    SHA1=\"$(git rev-parse HEAD)\"\n    git tag tag_1\n\n    # Another tag on branch 1 (at HEAD)\n    date > file_2\n    git add file_2\n    git commit -qam 'commit_2'\n    SHA2=\"$(git rev-parse HEAD)\"\n    git tag tag_2\n\n    # A tag on branch 2 (not at HEAD)\n    git checkout -b branch_2\n    date > file_3\n    git add file_3\n    git commit -qam 'commit_3'\n    SHA3=\"$(git rev-parse HEAD)\"\n    git tag tag_3\n\n    # Another tag on branch 2 (at HEAD)\n    date > file_4\n    git add file_4\n    git commit -qam 'commit_4'\n    SHA4=\"$(git rev-parse HEAD)\"\n    git tag tag_4\n\n    assert_eq \"$(git rev-parse tag_1)\" \"$SHA1\"\n    assert_eq \"$(git rev-parse 'tag_1^{commit}')\" \"$SHA1\"\n    assert_eq \"$(git rev-parse tag_2)\" \"$SHA2\"\n    assert_eq \"$(git rev-parse 'tag_2^{commit}')\" \"$SHA2\"\n    assert_eq \"$(git rev-parse tag_3)\" \"$SHA3\"\n    assert_eq \"$(git rev-parse 'tag_3^{commit}')\" \"$SHA3\"\n    assert_eq \"$(git rev-parse tag_4)\" \"$SHA4\"\n    assert_eq \"$(git rev-parse 'tag_4^{commit}')\" \"$SHA4\"\n}\n\n##############################################\n# Test git rev-parse with an annotated tag\n##############################################\nfunction git::rev_parse_tag_annotated() {\n    mkdir repo\n    pushd repo >/dev/null\n    git init -b main\n\n    # A tag on branch 1 (not at HEAD)\n    git checkout -b branch_1\n    date > file_1\n    git add file_1\n    git commit -qam 'commit_1'\n    SHA1=\"$(git rev-parse HEAD)\"\n    git tag -am \"anntag_1\" anntag_1\n\n    # Another tag on branch 1 (at HEAD)\n    date > file_2\n    git add file_2\n    git commit -qam 'commit_2'\n    SHA2=\"$(git rev-parse HEAD)\"\n    git tag -am \"anntag_2\" anntag_2\n\n    # A tag on branch 2 (not at HEAD)\n    git checkout -b branch_2\n    date > file_3\n    git add file_3\n    git commit -qam 'commit_3'\n    SHA3=\"$(git rev-parse HEAD)\"\n    git tag -am \"anntag_3\" anntag_3\n\n    # Another tag on branch 2 (at HEAD)\n    date > file_4\n    git add file_4\n    git commit -qam 'commit_4'\n    SHA4=\"$(git rev-parse HEAD)\"\n    git tag -am \"anntag_4\" anntag_4\n\n    # Annotated tags have their own SHA, which can be found with rev-parse, but\n    # it doesn't make sense to test rev-parse against itself.\n    assert_eq \"$(git rev-parse 'anntag_1^{commit}')\" \"$SHA1\"\n    assert_eq \"$(git rev-parse 'anntag_2^{commit}')\" \"$SHA2\"\n    assert_eq \"$(git rev-parse 'anntag_3^{commit}')\" \"$SHA3\"\n    assert_eq \"$(git rev-parse 'anntag_4^{commit}')\" \"$SHA4\"\n}\n\n##############################################\n# Test git rev-parse with a SHA\n##############################################\nfunction git::rev_parse_sha() {\n    mkdir repo\n    pushd repo >/dev/null\n    git init -b main\n\n    # A commit on branch 1 (not at HEAD)\n    git checkout -b branch_1\n    date > file_1\n    git add file_1\n    git commit -qam 'commit_1'\n    SHA1=\"$(git rev-parse HEAD)\"\n    SHORT1=\"${SHA1%????????}\"\n\n    # Another commit on branch 1 (at HEAD)\n    date > file_2\n    git add file_2\n    git commit -qam 'commit_2'\n    SHA2=\"$(git rev-parse HEAD)\"\n    SHORT2=\"${SHA2%????????}\"\n\n    # A commit on branch 2 (not at HEAD)\n    git checkout -b branch_2\n    date > file_3\n    git add file_3\n    git commit -qam 'commit_3'\n    SHA3=\"$(git rev-parse HEAD)\"\n    SHORT3=\"${SHA3%????????}\"\n\n    # Another commit on branch 2 (at HEAD)\n    date > file_4\n    git add file_4\n    git commit -qam 'commit_4'\n    SHA4=\"$(git rev-parse HEAD)\"\n    SHORT4=\"${SHA4%????????}\"\n\n    assert_eq \"$(git rev-parse \"$SHA1\")\" \"$SHA1\"\n    assert_eq \"$(git rev-parse \"$SHA1^{commit}\")\" \"$SHA1\"\n    assert_eq \"$(git rev-parse \"$SHORT1\")\" \"$SHA1\"\n    assert_eq \"$(git rev-parse \"$SHA2\")\" \"$SHA2\"\n    assert_eq \"$(git rev-parse \"$SHA2^{commit}\")\" \"$SHA2\"\n    assert_eq \"$(git rev-parse \"$SHORT2\")\" \"$SHA2\"\n    assert_eq \"$(git rev-parse \"$SHA3\")\" \"$SHA3\"\n    assert_eq \"$(git rev-parse \"$SHA3^{commit}\")\" \"$SHA3\"\n    assert_eq \"$(git rev-parse \"$SHORT3\")\" \"$SHA3\"\n    assert_eq \"$(git rev-parse \"$SHA4\")\" \"$SHA4\"\n    assert_eq \"$(git rev-parse \"$SHA4^{commit}\")\" \"$SHA4\"\n    assert_eq \"$(git rev-parse \"$SHORT4\")\" \"$SHA4\"\n}\n\n##############################################\n# Test git rev-parse with a non-existent ref\n##############################################\nfunction git::rev_parse_non_existent_name() {\n    mkdir repo\n    pushd repo >/dev/null\n    git init -b main\n\n    assert_substr \"$(git rev-parse does-not-exist 2>&1 || true)\" \"unknown revision\"\n}\n\n##############################################\n# Test git rev-parse with a non-existent sha\n##############################################\nfunction git::rev_parse_non_existent_sha() {\n    mkdir repo\n    pushd repo >/dev/null\n    git init -b main\n\n    # As long as it tastes like a SHA, rev-parse is happy, but there is no\n    # commit for it.\n    assert_eq \"$(git rev-parse 0123456789abcdef0123456789abcdef01234567)\" \"0123456789abcdef0123456789abcdef01234567\"\n    assert_substr \"$(git rev-parse '0123456789abcdef0123456789abcdef01234567^{commit}' 2>&1 || true)\" \"unknown revision\"\n    # Less-than-full SHAs do not work.\n    assert_substr \"$(git rev-parse 0123456789abcdef 2>&1 || true)\" \"unknown revision\"\n    assert_substr \"$(git rev-parse '0123456789abcdef^{commit}' 2>&1 || true)\" \"unknown revision\"\n}\n\n#\n# main\n#\n\nfunction list_tests() {\n    (\n        shopt -s extdebug\n        declare -F \\\n            | cut -f3 -d' ' \\\n            | grep \"^git::\" \\\n            | while read -r X; do declare -F \"$X\"; done \\\n            | sort -n -k2 \\\n            | cut -f1 -d' ' \\\n            | sed 's/^git:://'\n    )\n}\n\n# Figure out which, if any, tests to run.\nmapfile -t all_tests < <(list_tests)\ntests_to_run=()\n\nfunction print_tests() {\n    echo \"available tests:\"\n    for t in \"${all_tests[@]}\"; do\n        echo \"    $t\"\n    done\n}\n\n# Validate and accumulate tests to run if args are specified.\nfor arg; do\n    # Use -? to list known tests.\n    if [[ \"${arg}\" == \"-?\" ]]; then\n        print_tests\n        exit 0\n    fi\n    if [[ \"${arg}\" =~ ^- ]]; then\n        echo \"ERROR: unknown flag '${arg}'\"\n        exit 1\n    fi\n    # Make sure each non-flag arg matches at least one test.\n    nmatches=0\n    for t in \"${all_tests[@]}\"; do\n        if [[ \"${t}\" =~ ${arg} ]]; then\n            nmatches=$((nmatches+1))\n            # Don't run tests twice, just keep the first match.\n            if [[ \" ${tests_to_run[*]} \" == *\" ${t} \"* ]]; then\n                continue\n            fi\n            tests_to_run+=(\"${t}\")\n            continue\n        fi\n    done\n    if [[ ${nmatches} == 0 ]]; then\n        echo \"ERROR: no tests match pattern '${arg}'\"\n        echo\n        print_tests\n        exit 1\n    fi\n    tests_to_run+=(\"${matches[@]}\")\ndone\nset -- \"${tests_to_run[@]}\"\n\n# If no tests were specified, run them all.\nif [[ \"$#\" == 0 ]]; then\n    set -- \"${all_tests[@]}\"\nfi\n\nfunction finish() {\n  r=$?\n  trap \"\" INT EXIT ERR\n  if [[ $r != 0 ]]; then\n    echo\n    echo \"the directory $DIR was not removed as it contains\"\\\n         \"log files useful for debugging\"\n  fi\n  exit $r\n}\ntrap finish INT EXIT ERR\n\necho\necho \"test root is $DIR\"\necho\n\n# Run a test function and return its error code.  This is needed because POSIX\n# dictates that `errexit` does not apply inside a function called in an `if`\n# context.  But if we don't call it with `if`, then it terminates the whole\n# test run as soon as one test fails.  So this jumps through hoops to let the\n# individual test functions run outside of `if` and return a code in a\n# variable.\n#\n# Args:\n#  $1: the name of a variable to populate with the return code\n#  $2+: the test function to run and optional args\nfunction run_test() {\n    retvar=$1\n    shift\n\n    declare -g \"$retvar\"\n    local restore_opts\n    restore_opts=$(set +o)\n    set +o errexit\n    set +o nounset\n    set +o pipefail\n    (\n        set -o errexit\n        set -o nounset\n        set -o pipefail\n        \"$@\"\n    )\n    eval \"$retvar=$?\"\n    eval \"$restore_opts\"\n}\n\n# Override local configs for predictability in this test.\nexport GIT_CONFIG_GLOBAL=/dev/null\nexport GIT_CONFIG_SYSTEM=/dev/null\n\n# TODO: add a flag to run all the tests inside the git-sync container image\n# Iterate over the chosen tests and run them.\nFAILS=()\nFINAL_RET=0\nRUNS=\"${RUNS:-1}\"\nfor t; do\n    TEST_RET=0\n    RUN=0\n    while (( \"${RUN}\" < \"${RUNS}\" )); do\n        clean_workdir\n\n        pushd \"$WORKDIR\" >/dev/null\n\n        sfx=\"\"\n        if (( \"${RUNS}\" > 1 )); then\n            sfx=\" ($((RUN+1))/${RUNS})\"\n        fi\n        echo -n \"testcase ${t}${sfx}: \"\n\n        # Set &3 for our own output, let testcases use &2 and &1.\n        exec 3>&1\n\n        # See comments on run_test for details.\n        RUN_RET=0\n        LOG=\"${DIR}/log.$t\"\n        run_test RUN_RET \"git::${t}\" >\"${LOG}.${RUN}\" 2>&1\n        if [[ \"$RUN_RET\" == 0 ]]; then\n            pass\n        else\n            TEST_RET=1\n            if [[ \"$RUN_RET\" != 42 ]]; then\n                echo \"FAIL: unknown error\"\n            fi\n        fi\n        RUN=$((RUN+1))\n\n        popd >/dev/null\n    done\n    if [[ \"$TEST_RET\" != 0 ]]; then\n        FINAL_RET=1\n        FAILS+=(\"$t  (log: ${LOG}.*)\")\n    fi\ndone\nif [[ \"$FINAL_RET\" != 0 ]]; then\n    echo\n    echo \"the following tests failed:\"\n    for f in \"${FAILS[@]}\"; do\n        echo \"    $f\"\n    done\n    exit 1\nfi\n\n# Finally...\necho\nif [[ \"${CLEANUP:-}\" == 0 ]]; then\n    echo \"leaving logs in $DIR\"\nelse\n    rm -rf \"$DIR\"\nfi\n\n"
        },
        {
          "name": "tools",
          "type": "tree",
          "content": null
        },
        {
          "name": "v3-to-v4.md",
          "type": "blob",
          "size": 8.013671875,
          "content": "# Converting from git-sync v3.x to v4.x\n\nGit-sync v4 is a significant change from v3.  It includes several flag changes\n(though many of the old flags are kept for backwards compatibility), but more\nimportantly it fundamentally changes the way the internal sync-loop works.\n\nIt should be possible to upgrade a synced repo (e.g. in a volume) from git-sync\nv3 to git-sync v4, but appropriate caution should be used for critical\ndeployments.  We have a test which covers this, but there are many degrees of\nconfig which we simply can't predict.\n\n## The v3 loop\n\nThe way git-sync v3.x works is sort of like how a human might work:\n\n  1) `git clone <repo> <branch>`\n  2) `git fetch <remote>`\n  3) `git checkout <ref>`\n\nThis made the code somewhat complicated, since it had to keep track of whether\nthis was the first pass (clone) or a subsequent pass (fetch).  This led to a\nnumber of bugs related to back-to-back runs of git-sync, and some race\nconditions.\n\n## The v4 loop\n\nIn v4.x the loop is simpler - every pass is the same.  This takes advantage of\nsome idempotent behaviors (e.g. `git init` is safe to re-run) and uses git more\nefficiently.  Instead of cloning a branch, git-sync will now fetch exactly the\ncommit (by SHA) it needs.  This transfers less data and closes the race\ncondition where a symbolic name can change after `git ls-remote` but before\n`git fetch`.\n\n### The v4.2+ loop\n\nThe v4.2 loop refines the v4 loop even further.  Instead of using ls-remote to\nsee what the upstream has and then fetching it, git-sync sill just fetch it by\nref.  If the local sync already has the corresponding hash, nothing more will\nbe synced.  If it did not have that hash before, then it does now and can\nupdate the worktree.\n\n## Flags\n\nThe flag syntax parsing has changed in v4.  git-sync v3 accept flags in Go's\nown style: either `-flag` or `--flag` were accepted.  git-sync v4 only accepts\nlong flag names in the more common two-dash style (`--flag`), and accepts short\n(single-character) flags in the one-dash style (`-v 2`).\n\nThe following does not detail every flag available in v4 - just the ones that\nexisted in v3 and are different in v4.\n\n### Verbosity: `--v` -> `-v` or `--verbose`\n\nThe change in flag parsing affects the old `--v` syntax.  To set verbosity\neither use `-v` or `--verbose`.  For backwards compatibility, `--v` will be\nused if it is specified.\n\n### Sync target: `--branch` and `--rev` -> `--ref`\n\nThe old `--branch` and `--rev` flags are deprecated in favor of the new `--ref`\nflag.  `--ref` can be either a branch name, a tag name, or a commit hash (aka\nSHA).  For backwards compatibility, git-sync will still accept the old flags\nand try to set `--ref` from them.\n\n    |----------|---------|---------|------------------------------|\n    | --branch |  --rev  |  --ref  |            meaning           |\n    |----------|---------|---------|------------------------------|\n    |    \"\"    |   \"\"    | \"HEAD\"  | remote repo's default branch |\n    |  brname  |   \"\"    | brname  | remote branch `brname`       |\n    |  brname  | \"HEAD\"  | brname  | remote branch `brname`       |\n    |    \"\"    | tagname | tagname | remote tag `tagname`         |\n    |   other  |  other  |   \"\"    | error                        |\n    |----------|---------|---------|------------------------------|\n\n#### Default target\n\nIn git-sync v3, if neither `--branch` nor `--rev` were specified, the default\nwas to sync the HEAD of the branch named \"master\".  Many git repos have changed\nto \"main\" or something else as the default branch name, so git-sync v4 changes\nthe default target to be the HEAD of whatever the `--repo`'s default branch is.\nIf that default branch is not \"master\", then the default target will be\ndifferent in v4 than in v3.\n\n#### Abbreviated hashes\n\nBecause of the fetch loop, git-sync v3 allowed a user to specify `--branch` and\n`--rev`, where the rev was a shortened hash (aka SHA), which would be locally\nexpanded to the full hash.  v4 tries hard not to pull extra stuff, which means\nwe don't have enough information locally to do that resolution, and there no\nway to ask the server to do it for us (at least, not as far as we know).\n\nThe net result is that, when using a hash for `--ref`, it must be a full hash,\nand not an abbreviated form.\n\n### Log-related flags\n\ngit-sync v3 exposed a number of log-related flags (e.g. `-logtostderr`).  These\nhave all been removed.  git-sync v4 always logs to stderr, and the only control\noffered is the verbosity level (`-v / --verbose`).\n\n### Symlink: `--dest` -> `--link`\n\nThe old `--dest` flag is deprecated in favor of `--link`, which more clearly\nconveys what it does.  The allowed values remain the same, and for backwards\ncompatibility, `--dest` will be used if it is specified.\n\n### Loop: `--wait` -> `--period`\n\nThe old `--wait` flag took a floating-point number of seconds as an argument\n(e.g. \"0.1\" = 100ms).  The new `--period` flag takes a Go-style duration string\n(e.g. \"100ms\" or \"0.1s\" = 100ms).  For backwards compatibility, `--wait` will\nbe used if it is specified.\n\n### Failures: `--max-sync-failures` -> `--max-failures`\n\nThe new name of this flag is shorter and captures the idea that any\nnon-recoverable error in the sync loop counts as a failure.  For backwards\ncompatibility, `--max-sync-failures` will be used if it is specified.\n\ngit-sync v3 demanded that the first sync succeed, regardless of this flag.\ngit-sync v4 always allows failures up to this maximum, whether it is the first\nsync or any other.\n\n### Timeouts: `--timeout` -> `--sync-timeout`\n\nThe old `--timeout` flag took an integer number of seconds as an argument.  The\nnew `--sync-timeout` flag takes a Go-style duration string (e.g. \"30s\" or\n\"0.5m\").  For backwards compatibility, `--timeout` will be used if it is\nspecified.\n\n### Permissions: `--change-permissions` -> `--group-write`\n\nThe old `--change-permissions` flag was poorly designed and not able to express\nthe real intentions (e.g. \"allow group write\" does not mean \"set everything to\n0775\").  The new `--group-write` flag should cover what most people ACTUALLY\nare trying to do.\n\nThere is one case where `--change-permissions` was useful and `--group-write`\nis not - making non-executable files in the repo executable so they can be run\nas exechooks.  The proper solution here is to make the file executable in the\nrepo, rather than changing it after checkout.\n\nThe `--change-permissions` flag is no longer supported.\n\n### SSH: `--ssh` is optional (after v4.0.0)\n\nThe old `--ssh` flag is no longer needed - the value of `--repo` determines\nwhen SSH is used.  It is still accepted but does nothing.\n\nNOTE: v4.0.0 still requires `--ssh` but all releases beyond that do not.\n\n### Manual: `--man`\n\nThe new `--man` flag prints a man-page style help document and exits.\n\n## Env vars\n\nMost flags can also be configured by environment variables.  In v3 the\nvariables all start with `GIT_SYNC_`.  In v4 they all start with `GITSYNC_`,\nthough the old names are still accepted for compatibility.\n\nIf both an old (`GIT_SYNC_*`) name and a new (`GITSYNC_*`) name are specified,\nthe behavior is:\n* v4.0.x - v4.3.x: the new name is used\n* v4.4.x and up: the old name is used\n\n## Defaults\n\n### Depth\n\ngit-sync v3 would sync the entire history of the remote repo by default.  v4\nsyncs just one commit by default.  This can be a significant performance and\ndisk-space savings for large repos.  Users who want the full history can\nspecify `--depth=0`.\n\n## Logs\n\nThe logging output for v3 was semi-free-form text.  Log output in v4 is\nstructured and rendered as strict JSON.\n\n## Root dir\n\ngit-sync v3 container images defaulted `--root` to \"/tmp/git\".  In v4, that has\nmoved to \"/git\".  Users who mount a volume and expect to use the default\n`--root` must mount it on \"/git\".\n\n## Hooks\n\ngit-sync v3 could \"lose\" exechook and webhook calls in the face of the app\nrestarting.  In v4, app startup is treated as a sync, even if the correct hash\nwas already present, which means that hooks are always called.\n\n## Other changes\n\ngit-sync v3 would allow invalidly formatted env vars (e.g. a value that was\nexpected to be boolean holding an integer) and just ignore them with\na warning.  v4 requires that they parse correctly.\n"
        },
        {
          "name": "vendor",
          "type": "tree",
          "content": null
        }
      ]
    }
  ]
}