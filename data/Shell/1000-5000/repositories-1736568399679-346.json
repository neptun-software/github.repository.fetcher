{
  "metadata": {
    "timestamp": 1736568399679,
    "page": 346,
    "hasNextPage": true,
    "endCursor": "Y3Vyc29yOjM1MA==",
    "completionStatus": "IN_PROGRESS"
  },
  "repositories": [
    {
      "nameWithOwner": "bitnami/minideb",
      "stars": 2103,
      "defaultBranch": "master",
      "files": [
        {
          "name": ".github",
          "type": "tree",
          "content": null
        },
        {
          "name": ".gitignore",
          "type": "blob",
          "size": 0.087890625,
          "content": "/build\n.kvm-images\n.installed-requirements\n.installed-qemu\nnamibase/nami-linux-x64.tar.gz\n"
        },
        {
          "name": "CODE_OF_CONDUCT.md",
          "type": "blob",
          "size": 1.3037109375,
          "content": "# Contributor Code of Conduct\n\nAs contributors and maintainers of this project, we pledge to respect everyone who contributes by posting issues, updating documentation, submitting pull requests, providing feedback in comments, and any other activities.\n\nCommunication through any of Bitnami's channels (GitHub, mailing lists, Twitter, and so on) must be constructive and never resort to personal attacks, trolling, public or private harassment, insults, or other unprofessional conduct.\n\nWe promise to extend courtesy and respect to everyone involved in this project, regardless of gender, gender identity, sexual orientation, disability, age, race, ethnicity, religion, or level of experience. We expect anyone contributing to this project to do the same.\n\nIf any member of the community violates this code of conduct, the maintainers of this project may take action, including removing issues, comments, and PRs or blocking accounts, as deemed appropriate.\n\nIf you are subjected to or witness unacceptable behavior, or have any other concerns, please communicate with us.\n\nIf you have suggestions to improve this Code of Conduct, please submit an issue or PR.\n\n**Attribution**\n\nThis Code of Conduct is adapted from the Angular project available at this page: https://github.com/angular/code-of-conduct/blob/master/CODE_OF_CONDUCT.md\n"
        },
        {
          "name": "CONTRIBUTING.md",
          "type": "blob",
          "size": 1.9189453125,
          "content": "# Contributing Guidelines\n\nContributions are welcome via GitHub Pull Requests. This document outlines the process to help get your contribution accepted.\n\nAny type of contribution is welcome: new features, bug fixes, documentation improvements, etc.\n\n## How to Contribute\n\n1. Fork this repository, develop, and test your changes.\n2. Submit a pull request.\n\n### Requirements\n\nWhen submitting a PR make sure that:\n- It must pass CI jobs for linting and test the changes (if any).\n- The title of the PR is clear enough.\n- If necessary, add information to the repository's `README.md`.\n\n#### Sign Your Work\n\nThe sign-off is a simple line at the end of the explanation for a commit. All commits needs to be signed. Your signature certifies that you wrote the patch or otherwise have the right to contribute the material. The rules are pretty simple, you only need to certify the guidelines from [developercertificate.org](https://developercertificate.org/).\n\nThen you just add a line to every git commit message:\n\n    Signed-off-by: Joe Smith <joe.smith@example.com>\n\nUse your real name (sorry, no pseudonyms or anonymous contributions.)\n\nIf you set your `user.name` and `user.email` git configs, you can sign your commit automatically with `git commit -s`.\n\nNote: If your git config information is set properly then viewing the `git log` information for your commit will look something like this:\n\n```\nAuthor: Joe Smith <joe.smith@example.com>\nDate:   Thu Feb 2 11:41:15 2018 -0800\n\n    Update README\n\n    Signed-off-by: Joe Smith <joe.smith@example.com>\n```\n\nNotice the `Author` and `Signed-off-by` lines match. If they don't your PR will be rejected by the automated DCO check.\n\n### PR Approval and Release Process\n\n1. Changes are manually reviewed by Bitnami team members usually within a business day.\n2. Once the changes are accepted, the PR is tested (if needed) into the Bitnami CI pipeline.\n3. The PR is merged by the reviewer(s) in the GitHub `master` branch.\n"
        },
        {
          "name": "LICENSE.md",
          "type": "blob",
          "size": 11.0947265625,
          "content": "                                 Apache License\n                           Version 2.0, January 2004\n                        http://www.apache.org/licenses/\n\n   TERMS AND CONDITIONS FOR USE, REPRODUCTION, AND DISTRIBUTION\n\n   1. Definitions.\n\n      \"License\" shall mean the terms and conditions for use, reproduction,\n      and distribution as defined by Sections 1 through 9 of this document.\n\n      \"Licensor\" shall mean the copyright owner or entity authorized by\n      the copyright owner that is granting the License.\n\n      \"Legal Entity\" shall mean the union of the acting entity and all\n      other entities that control, are controlled by, or are under common\n      control with that entity. For the purposes of this definition,\n      \"control\" means (i) the power, direct or indirect, to cause the\n      direction or management of such entity, whether by contract or\n      otherwise, or (ii) ownership of fifty percent (50%) or more of the\n      outstanding shares, or (iii) beneficial ownership of such entity.\n\n      \"You\" (or \"Your\") shall mean an individual or Legal Entity\n      exercising permissions granted by this License.\n\n      \"Source\" form shall mean the preferred form for making modifications,\n      including but not limited to software source code, documentation\n      source, and configuration files.\n\n      \"Object\" form shall mean any form resulting from mechanical\n      transformation or translation of a Source form, including but\n      not limited to compiled object code, generated documentation,\n      and conversions to other media types.\n\n      \"Work\" shall mean the work of authorship, whether in Source or\n      Object form, made available under the License, as indicated by a\n      copyright notice that is included in or attached to the work\n      (an example is provided in the Appendix below).\n\n      \"Derivative Works\" shall mean any work, whether in Source or Object\n      form, that is based on (or derived from) the Work and for which the\n      editorial revisions, annotations, elaborations, or other modifications\n      represent, as a whole, an original work of authorship. For the purposes\n      of this License, Derivative Works shall not include works that remain\n      separable from, or merely link (or bind by name) to the interfaces of,\n      the Work and Derivative Works thereof.\n\n      \"Contribution\" shall mean any work of authorship, including\n      the original version of the Work and any modifications or additions\n      to that Work or Derivative Works thereof, that is intentionally\n      submitted to Licensor for inclusion in the Work by the copyright owner\n      or by an individual or Legal Entity authorized to submit on behalf of\n      the copyright owner. For the purposes of this definition, \"submitted\"\n      means any form of electronic, verbal, or written communication sent\n      to the Licensor or its representatives, including but not limited to\n      communication on electronic mailing lists, source code control systems,\n      and issue tracking systems that are managed by, or on behalf of, the\n      Licensor for the purpose of discussing and improving the Work, but\n      excluding communication that is conspicuously marked or otherwise\n      designated in writing by the copyright owner as \"Not a Contribution.\"\n\n      \"Contributor\" shall mean Licensor and any individual or Legal Entity\n      on behalf of whom a Contribution has been received by Licensor and\n      subsequently incorporated within the Work.\n\n   2. Grant of Copyright License. Subject to the terms and conditions of\n      this License, each Contributor hereby grants to You a perpetual,\n      worldwide, non-exclusive, no-charge, royalty-free, irrevocable\n      copyright license to reproduce, prepare Derivative Works of,\n      publicly display, publicly perform, sublicense, and distribute the\n      Work and such Derivative Works in Source or Object form.\n\n   3. Grant of Patent License. Subject to the terms and conditions of\n      this License, each Contributor hereby grants to You a perpetual,\n      worldwide, non-exclusive, no-charge, royalty-free, irrevocable\n      (except as stated in this section) patent license to make, have made,\n      use, offer to sell, sell, import, and otherwise transfer the Work,\n      where such license applies only to those patent claims licensable\n      by such Contributor that are necessarily infringed by their\n      Contribution(s) alone or by combination of their Contribution(s)\n      with the Work to which such Contribution(s) was submitted. If You\n      institute patent litigation against any entity (including a\n      cross-claim or counterclaim in a lawsuit) alleging that the Work\n      or a Contribution incorporated within the Work constitutes direct\n      or contributory patent infringement, then any patent licenses\n      granted to You under this License for that Work shall terminate\n      as of the date such litigation is filed.\n\n   4. Redistribution. You may reproduce and distribute copies of the\n      Work or Derivative Works thereof in any medium, with or without\n      modifications, and in Source or Object form, provided that You\n      meet the following conditions:\n\n      (a) You must give any other recipients of the Work or\n          Derivative Works a copy of this License; and\n\n      (b) You must cause any modified files to carry prominent notices\n          stating that You changed the files; and\n\n      (c) You must retain, in the Source form of any Derivative Works\n          that You distribute, all copyright, patent, trademark, and\n          attribution notices from the Source form of the Work,\n          excluding those notices that do not pertain to any part of\n          the Derivative Works; and\n\n      (d) If the Work includes a \"NOTICE\" text file as part of its\n          distribution, then any Derivative Works that You distribute must\n          include a readable copy of the attribution notices contained\n          within such NOTICE file, excluding those notices that do not\n          pertain to any part of the Derivative Works, in at least one\n          of the following places: within a NOTICE text file distributed\n          as part of the Derivative Works; within the Source form or\n          documentation, if provided along with the Derivative Works; or,\n          within a display generated by the Derivative Works, if and\n          wherever such third-party notices normally appear. The contents\n          of the NOTICE file are for informational purposes only and\n          do not modify the License. You may add Your own attribution\n          notices within Derivative Works that You distribute, alongside\n          or as an addendum to the NOTICE text from the Work, provided\n          that such additional attribution notices cannot be construed\n          as modifying the License.\n\n      You may add Your own copyright statement to Your modifications and\n      may provide additional or different license terms and conditions\n      for use, reproduction, or distribution of Your modifications, or\n      for any such Derivative Works as a whole, provided Your use,\n      reproduction, and distribution of the Work otherwise complies with\n      the conditions stated in this License.\n\n   5. Submission of Contributions. Unless You explicitly state otherwise,\n      any Contribution intentionally submitted for inclusion in the Work\n      by You to the Licensor shall be under the terms and conditions of\n      this License, without any additional terms or conditions.\n      Notwithstanding the above, nothing herein shall supersede or modify\n      the terms of any separate license agreement you may have executed\n      with Licensor regarding such Contributions.\n\n   6. Trademarks. This License does not grant permission to use the trade\n      names, trademarks, service marks, or product names of the Licensor,\n      except as required for reasonable and customary use in describing the\n      origin of the Work and reproducing the content of the NOTICE file.\n\n   7. Disclaimer of Warranty. Unless required by applicable law or\n      agreed to in writing, Licensor provides the Work (and each\n      Contributor provides its Contributions) on an \"AS IS\" BASIS,\n      WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or\n      implied, including, without limitation, any warranties or conditions\n      of TITLE, NON-INFRINGEMENT, MERCHANTABILITY, or FITNESS FOR A\n      PARTICULAR PURPOSE. You are solely responsible for determining the\n      appropriateness of using or redistributing the Work and assume any\n      risks associated with Your exercise of permissions under this License.\n\n   8. Limitation of Liability. In no event and under no legal theory,\n      whether in tort (including negligence), contract, or otherwise,\n      unless required by applicable law (such as deliberate and grossly\n      negligent acts) or agreed to in writing, shall any Contributor be\n      liable to You for damages, including any direct, indirect, special,\n      incidental, or consequential damages of any character arising as a\n      result of this License or out of the use or inability to use the\n      Work (including but not limited to damages for loss of goodwill,\n      work stoppage, computer failure or malfunction, or any and all\n      other commercial damages or losses), even if such Contributor\n      has been advised of the possibility of such damages.\n\n   9. Accepting Warranty or Additional Liability. While redistributing\n      the Work or Derivative Works thereof, You may choose to offer,\n      and charge a fee for, acceptance of support, warranty, indemnity,\n      or other liability obligations and/or rights consistent with this\n      License. However, in accepting such obligations, You may act only\n      on Your own behalf and on Your sole responsibility, not on behalf\n      of any other Contributor, and only if You agree to indemnify,\n      defend, and hold each Contributor harmless for any liability\n      incurred by, or claims asserted against, such Contributor by reason\n      of your accepting any such warranty or additional liability.\n\n   END OF TERMS AND CONDITIONS\n\n   APPENDIX: How to apply the Apache License to your work.\n\n      To apply the Apache License to your work, attach the following\n      boilerplate notice, with the fields enclosed by brackets \"[]\"\n      replaced with your own identifying information. (Don't include\n      the brackets!)  The text should be enclosed in the appropriate\n      comment syntax for the file format. We also recommend that a\n      file or class name and description of purpose be included on the\n      same \"printed page\" as the copyright notice for easier\n      identification within third-party archives.\n\n   Copyright [yyyy] [name of copyright owner]\n\n   Licensed under the Apache License, Version 2.0 (the \"License\");\n   you may not use this file except in compliance with the License.\n   You may obtain a copy of the License at\n\n       http://www.apache.org/licenses/LICENSE-2.0\n\n   Unless required by applicable law or agreed to in writing, software\n   distributed under the License is distributed on an \"AS IS\" BASIS,\n   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n   See the License for the specific language governing permissions and\n   limitations under the License.\n   \n"
        },
        {
          "name": "Makefile",
          "type": "blob",
          "size": 0.6787109375,
          "content": "BUILD_DIR := build\nMKDIR_P = mkdir -p\nRM = rm -rf\n\n.PHONY: build clean clobber\n\nall: build\n\nclean:\n\t${RM} ${CURDIR}/${BUILD_DIR}\n\nclobber: clean\n\t@${RM} .installed-requirements\n\n.installed-qemu:\n\t@echo \"Installing QEMU and required packages...\"\n\t@./install-qemu.sh\n\t@touch $@\n\n.installed-requirements:\n\t@echo \"Installing required packages...\"\n\t@./pre-build.sh\n\t@touch $@\n\nbuild: .installed-requirements\n\t@echo \"Building all supported distros...\"\n\t@./buildall\n\n%:\n\t@echo \"Building $@...\"\n\t@$(MAKE) .installed-requirements\n\t@${MKDIR_P} ${CURDIR}/${BUILD_DIR}\n\t./mkimage ${CURDIR}/${BUILD_DIR}/$@.tar $@\n\ntest-%:\n\t@cat ${CURDIR}/${BUILD_DIR}/$*.tar | docker import - minideb:$*\n\t@./test minideb:$*\n"
        },
        {
          "name": "README.md",
          "type": "blob",
          "size": 6.7431640625,
          "content": "<p align=\"center\">\n    <img width=\"400px\" height=auto src=\"https://bitnami.com/downloads/logos/bitnami-by-vmware.png\" />\n</p>\n\n<p align=\"center\">\n    <a href=\"https://github.com/bitnami/minideb/actions/workflows/main.yml\"><img src=\"https://github.com/bitnami/minideb/actions/workflows/main.yml/badge.svg?branch=master\" /></a>\n    <a href=\"https://hub.docker.com/r/bitnami/minideb/\"><img src=\"https://badgen.net/docker/pulls/bitnami/minideb?icon=docker&label=pulls\" /></a>\n    <a href=\"https://hub.docker.com/r/bitnami/minideb/\"><img src=\"https://badgen.net/docker/stars/bitnami/minideb?icon=docker&label=stars\" /></a>\n    <a href=\"https://github.com/bitnami/minideb\"><img src=\"https://badgen.net/github/forks/bitnami/minideb?icon=github&color=grey\" /></a>\n    <a href=\"https://github.com/bitnami/minideb\"><img src=\"https://badgen.net/github/stars/bitnami/minideb?icon=github&color=grey\" /></a>\n    <a href=\"https://twitter.com/bitnami\"><img src=\"https://badgen.net/badge/twitter/@bitnami/1DA1F2?icon&label\" /></a>\n</p>\n\n# What is Minideb\nA minimalist Debian-based image built specifically to be used as a base image for containers.\n\n# Use Minideb\nYou can use the image directly, e.g.\n```\n$ docker run --rm -it bitnami/minideb:latest\n```\n\nThere are [tags](https://hub.docker.com/r/bitnami/minideb/tags/) for the different Debian releases.\n```\n$ docker run --rm -it bitnami/minideb:bookworm\n```\n\nThe images are built daily and have the security release enabled, so will contain any security updates released more than 24 hours ago.\n\nYou can also use the images as a base for your own `Dockerfile`:\n```\nFROM bitnami/minideb:bookworm\n```\n\n# Why use Minideb\n  * This image aims to strike a good balance between having small images and having many quality packages available for easy integration.\n  * The image is based on glibc for wide compatibility and is using apt for access to a large number of packages. To reduce the size of the image, some things that aren't required in containers are removed:\n    * Packages that aren't often used in containers (hardware-related, init systems, etc.)\n    * Some files that aren't usually required (docs, man pages, locales, caches)\n  * These images also include an `install_packages` command that you can use instead of apt. This takes care of some things for you:\n    * Install the named packages, skipping prompts, etc.\n    * Clean up the apt metadata afterward to keep the image small.\n    * Retrying if apt fails. Sometimes a package will fail to download due to a network issue, and this may fix that, which is particularly useful in an automated build pipeline.\n\n    For example:\n    ```\n    $ install_packages apache2 memcached\n    ```\n\n# Adoption of Minideb\nThe minideb container image is the base image for many Bitnami-maintained language runtimes including [php](https://github.com/bitnami/containers/tree/main/bitnami/php-fpm), [nodejs](https://github.com/bitnami/containers/tree/main/bitnami/node), [ruby](https://github.com/bitnami/containers/tree/main/bitnami/ruby) and infrastructure components including [mariadb](https://github.com/bitnami/containers/tree/main/bitnami/mariadb), [redis](https://github.com/bitnami/containers/tree/main/bitnami/redis), [nginx](https://github.com/bitnami/containers/tree/main/bitnami/nginx) and [mongodb](https://github.com/bitnami/containers/tree/main/bitnami/mongodb).\n\n# Compatibility\nThe image points to the Debian archive, so you are free to install the packages from there that you need. However, because some `Essential` packages have been removed they may not always install or work correctly.\n\nIn those cases, you can figure out which package is needed and manually specify to install it along with your desired packages. Please feel free to submit an issue request so that we can reach out and help you quickly.\n\n# Security\nMinideb is based on Debian and relies on their security updates. The images are built daily and have the security release enabled, so will contain any security updates released more than 24 hours ago.\n\nNote that Debian [does not fix every CVE that affects their packages](https://www.debian.org/security/faq#cvedsa), which means that CVE scanners may detect unfixed vulnerabilities in Minideb images. In those cases, you can check the [Debian security tracker](https://security-tracker.debian.org/tracker/) to see whether Debian intends to release an update to fix it.\n\nTo keep compatibility with Debian, we will not patch any vulnerabilities in Minideb directly. If Debian does not fix the CVE then it will also remain in Minideb. If you find a vulnerability that is fixed in Debian but not in the latest images of Minideb then please file an issue as that is not intentional.\n\nOn [this page](https://docs.bitnami.com/kubernetes/open-cve-policy/), you can find more information about the Bitnami policy regarding CVEs. In the same way, if you find a security issue with how the Minideb images are built or published then please report it to us.\n\n# Building Minideb\nWe provide a Makefile to help you build Minideb locally. It should be run on a Debian-based machine and requires sudo privileges.\n```\n$ sudo make\n```\n\nTo build an individual release (bullseye or bookworm)\n```\n$ sudo make bookworm\n```\n\nTo test the resulting image:\n```\n$ sudo make test-bookworm\n```\n\n## Building Minideb for foreign architecture\nMake commands shown above will build an image for the architecture you are currently working on.\nTo build an image for a foreign architecture (for example to build a multi-arch image), we provide a\nsimple script that runs a QEMU instance for the target architecture and builds the image inside it.\n\nTo build and test a bookworm image for arm64:\n```\n$ ./qemu_build bookworm arm64\n```\n\nThe image will be then imported locally through the docker CLI with the `$distribution-$architecture` tag\n(example: `bitnami/minideb:bookworm-arm64`)\n\nCurrent limitations of the `qemu_build` script:\n\n- Can be run only on Debian-based distributions\n- Support `AMD64` and `ARM64` target architectures only\n\n# Contributing\nWe'd love for you to contribute to this image. You can request new features by creating an [issue](https://github.com/bitnami/minideb/issues), or submit a [pull request](https://github.com/bitnami/minideb/pulls) with your contribution.\n\n# License\n\nCopyright &copy; 2024 Broadcom. The term \"Broadcom\" refers to Broadcom Inc. and/or its subsidiaries.\n\nLicensed under the Apache License, Version 2.0 (the \"License\"); you may not use this file except in compliance with the License. You may obtain a copy of the License at\n\nhttp://www.apache.org/licenses/LICENSE-2.0\n\nUnless required by applicable law or agreed to in writing, software distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License.\n"
        },
        {
          "name": "SECURITY.md",
          "type": "blob",
          "size": 6.0234375,
          "content": "# Security Release Process\n\nThe community has adopted this security disclosure and response policy to ensure we responsibly handle critical issues.\n\n\n## Supported Versions\n\nFor a list of support versions that this project will potentially create security fixes for, please refer to the Releases page on this project's GitHub and/or project related documentation on release cadence and support.\n\n\n## Reporting a Vulnerability - Private Disclosure Process\n\nSecurity is of the highest importance and all security vulnerabilities or suspected security vulnerabilities should be reported to this project privately, to minimize attacks against current users  before they are fixed. Vulnerabilities will be investigated and patched on the next patch (or minor) release as soon as possible. This information could be kept entirely internal to the project.\n\nIf you know of a publicly disclosed security vulnerability for this project, please **IMMEDIATELY** contact the maintainers of this project privately. The use of encrypted email is encouraged.\n\n\n**IMPORTANT: Do not file public issues on GitHub for security vulnerabilities**\n\nTo report a vulnerability or a security-related issue, please contact the maintainers with enough details through one of the following channels: \n* Directly via their individual email addresses\n* Open a [GitHub Security Advisory](https://docs.github.com/en/code-security/security-advisories/guidance-on-reporting-and-writing/privately-reporting-a-security-vulnerability). This allows for anyone to report security vulnerabilities directly and privately to the maintainers via GitHub. Note that this option may not be present for every repository.\n\nThe report will be fielded by the maintainers who have committer and release permissions. Feedback will be sent within 3 business days, including a detailed plan to investigate the issue and any potential workarounds to perform in the meantime. \n\nDo not report non-security-impacting bugs through this channel. Use GitHub issues for all non-security-impacting bugs.\n\n\n## Proposed Report Content\n\nProvide a descriptive title and in the description of the report include the following information:\n\n*   Basic identity information, such as your name and your affiliation or company.\n*   Detailed steps to reproduce the vulnerability  (POC scripts, screenshots, and logs are all helpful to us).\n*   Description of the effects of the vulnerability on this project and the related hardware and software configurations, so that the maintainers can reproduce it.\n*   How the vulnerability affects this project's usage and an estimation of the attack surface, if there is one.\n*   List other projects or dependencies that were used in conjunction with this project to produce the vulnerability.\n\n\n## When to report a vulnerability\n\n*   When you think this project has a potential security vulnerability.\n*   When you suspect a potential vulnerability but you are unsure that it impacts this project.\n*   When you know of or suspect a potential vulnerability on another project that is used by this project.\n\n\n## Patch, Release, and Disclosure\n\nThe maintainers will respond to vulnerability reports as follows:\n\n1. The maintainers will investigate the vulnerability and determine its effects and criticality.\n2. If the issue is not deemed to be a vulnerability, the maintainers will follow up with a detailed reason for rejection.\n3. The maintainers will initiate a conversation with the reporter within 3 business days.\n4. If a vulnerability is acknowledged and the timeline for a fix is determined, the maintainers will work on a plan to communicate with the appropriate community, including identifying mitigating steps that affected users can take to protect themselves until the fix is rolled out.\n5. The maintainers will also create a [Security Advisory](https://docs.github.com/en/code-security/repository-security-advisories/publishing-a-repository-security-advisory) using the [CVSS Calculator](https://www.first.org/cvss/calculator/3.0), if it is not created yet.  The maintainers make the final call on the calculated CVSS; it is better to move quickly than making the CVSS perfect. Issues may also be reported to [Mitre](https://cve.mitre.org/) using this [scoring calculator](https://nvd.nist.gov/vuln-metrics/cvss/v3-calculator). The draft advisory will initially be set to private.\n6. The maintainers will work on fixing the vulnerability and perform internal testing before preparing to roll out the fix.\n7. Once the fix is confirmed, the maintainers will patch the vulnerability in the next patch or minor release, and backport a patch release into all earlier supported releases.\n\n\n## Public Disclosure Process\n\nThe maintainers publish the public advisory to this project's community via GitHub. In most cases, additional communication via Slack, Twitter, mailing lists, blog, and other channels will assist in educating the project's users and rolling out the patched release to affected users.\n\nThe maintainers will also publish any mitigating steps users can take until the fix can be applied to their instances. This project's distributors will handle creating and publishing their own security advisories.\n\n\n## Confidentiality, integrity and availability\n\nWe consider vulnerabilities leading to the compromise of data confidentiality, elevation of privilege, or integrity to be our highest priority concerns. Availability, in particular in areas relating to DoS and resource exhaustion, is also a serious security concern. The maintainer team takes all vulnerabilities, potential vulnerabilities, and suspected vulnerabilities seriously and will investigate them in an urgent and expeditious manner.\n\nNote that we do not currently consider the default settings for this project to be secure-by-default. It is necessary for operators to explicitly configure settings, role based access control, and other resource related features in this project to provide a hardened environment. We will not act on any security disclosure that relates to a lack of safe defaults. Over time, we will work towards improved safe-by-default configuration, taking into account backwards compatibility.\n"
        },
        {
          "name": "buildall",
          "type": "blob",
          "size": 0.2177734375,
          "content": "#!/bin/bash\n\n# Build a minideb image for each supported dist\n\nset -e\nset -u\nset -o pipefail\n\narch=${1:-\"amd64 arm64\"}\n\ndist=\"bullseye\nbookworm\n\"\nfor a in $arch; do\n  for i in $dist; do\n    ./buildone \"$i\" \"$a\"\n  done\ndone\n\n"
        },
        {
          "name": "buildone",
          "type": "blob",
          "size": 3.9501953125,
          "content": "#!/bin/bash\n#\n# Build a minideb image\n#\n# First we build the image as a tarball, then we import it and tag it.\n#\n# However we aim to allow our images to be reproduced. That means\n# we need more control over the import process. We also build and import\n# each image twice to confirm that our images are still reproducible.\n#\n# To reproduce an image you have to:\n#\n#   - Produce exactly the same base tarball. `mkimage` will take care of that\n#     for the same package inputs.\n#   - Import the image with the same config (`CMD` etc.)\n#   - Have the same creation date on the image.\n#\n# That last requirement leads us to some extra work to re-use timestamps.\n#\n# The steps are:\n#\n# 1. Pull image from Dockerhub and save creation date and image_id\n# 2. Build image locally and import it, setting creation date to the pulled one\n# 3. Build the image again and import it, also setting creation date to the pulled one\n# 4. Compare the built image ids. Error if they are not the same (Docker thinks images are different, thanks to checksum)\n# 5. Compare built image id with pulled image id. Both will have same creation date but may differ in checksum so ids may be different\n#    - If the image is the same as the pulled one then nothing changed in this build\n#    - If the image differs from the pulled one then:\n#      - Re-import the locally built image with the current timestamp so it will be shown as a new image\n#      - Tag the built image with the target tag, ready to push.\n\nset -e\nset -u\nset -o pipefail\n\nBASENAME=bitnami/minideb\n\nmkdir -p build\n\nlog() {\n    echo \"$@\" >&2\n}\n\nbuild() {\n    DIST=$1\n    PLATFORM=${2:-amd64}\n    TAG=$DIST-$PLATFORM\n\n    [ -f \"debootstrap/$DIST\" ] || (echo \"buildall: Unknown distribution: $DIST\" && exit 1)\n    current_ts=\"$(date -u +%Y-%m-%dT%H:%M:%S.%NZ)\"\n    if docker pull \"$BASENAME:$TAG\" > /dev/null; then\n        target_ts=\"$(docker inspect \"$BASENAME:$TAG\" | jq --raw-output \".[0].Created\")\"\n        pulled_image_id=\"$(docker inspect \"$BASENAME:$TAG\" | jq --raw-output \".[0].Id\")\"\n    else\n        target_ts=\"$current_ts\"\n        pulled_image_id=\n    fi\n    log \"============================================\"\n    log \"Building $BASENAME:$TAG\"\n    log \"============================================\"\n    ./mkimage \"build/$TAG.tar\" \"$DIST\" \"$PLATFORM\"\n    built_image_id=$(./import \"build/$TAG.tar\" \"$target_ts\" \"$PLATFORM\")\n    log \"============================================\"\n    log \"Running tests for $BASENAME:$TAG\"\n    log \"============================================\"\n    ./test \"$built_image_id\" \"$TAG\" \"$PLATFORM\"\n    log \"============================================\"\n    log \"Rebuilding $BASENAME:$TAG to test reproducibility\"\n    log \"============================================\"\n    ./mkimage \"build/${TAG}-repro.tar\" \"$DIST\" \"$PLATFORM\"\n    repro_image_id=$(./import \"build/${TAG}-repro.tar\" \"$target_ts\" \"$PLATFORM\")\n    if [ \"$repro_image_id\" != \"$built_image_id\" ]; then\n        log \"$BASENAME:$TAG differs after a rebuild. Examine $built_image_id and $repro_image_id\"\n        log \"to find the differences and fix the build to be reproducible again.\"\n        log \"Changes (- first build, + second build):\"\n        ./dockerdiff \"$built_image_id\" \"$repro_image_id\" || true\n        exit 1\n    fi\n    rm \"build/${TAG}-repro.tar\"\n    if [ -n \"$pulled_image_id\" ]; then\n        if [ \"$built_image_id\" != \"$pulled_image_id\" ]; then\n            log \"Image changed $built_image_id (new) != $pulled_image_id (old)\"\n            log \"Changes (- old, + new):\"\n            ./dockerdiff \"$pulled_image_id\" \"$built_image_id\" || true\n            # Re-import with the current timestamp so that the image shows\n            # as new\n            built_image_id=\"$(./import \"build/$TAG.tar\" \"$current_ts\" \"$PLATFORM\")\"\n        else\n            log \"Image didn't change\"\n            return\n        fi\n    fi\n    docker tag \"$built_image_id\" \"$BASENAME:$TAG\"\n    log \"Tagged $built_image_id as $BASENAME:$TAG\"\n}\n\nif [ -z \"$1\" ]; then\n    echo \"You must specify the dist to build\"\n    exit 1\nfi\n\nbuild \"$@\"\n"
        },
        {
          "name": "debootstrap",
          "type": "tree",
          "content": null
        },
        {
          "name": "dockerdiff",
          "type": "blob",
          "size": 0.9853515625,
          "content": "#!/bin/bash\n\n# Compare two docker images, reporting what changed.\n# The script will exit 1 if there are differences between the images\n# other than their tags.\n#\n# It will also try and show what the differences are, comparing\n#  - the image config\n#  - the installed dpkg packages\n#  - changed file metadata\n#  - changed file checksums\n\nset -e\nset -u\nset -o pipefail\n\nIMAGE1=$1\nIMAGE2=$2\n\ninspect() {\n    docker inspect $1 | jq \".[0]|del(.RepoTags,.RepoDigests)\"\n}\n\ndpkgl() {\n    docker run --rm $1 dpkg -l\n}\n\nlslr() {\n    docker run --rm $1 bash -c 'find / -xdev -not -path /proc -a -not -path /sys -print0 | sort -z | xargs -0 ls -ld'\n}\n\nmd5() {\n    docker run --rm $1 bash -c 'find / -xdev -not -path /etc/hosts -a -not -path /etc/hostname -a -type f -print0 | sort -z | xargs -0 md5sum'\n}\n\n_diff() {\n    local cmd=$1\n    diff -u --label $IMAGE1 --label $IMAGE2 <($cmd $IMAGE1)  <($cmd $IMAGE2)\n}\n\nif ! _diff inspect; then\n    _diff dpkgl || true\n    _diff lslr || true\n    _diff md5 || true\n    exit 1\nfi\n"
        },
        {
          "name": "import",
          "type": "blob",
          "size": 2.359375,
          "content": "#!/bin/bash\n\n# Import a tarball as a docker image, specifying the desired image\n# creation date.\n\n# This is useful as there's no other way to manipulate the creation\n# date, and the date is part of the calculation of the image id.\n# This means that the only way to reproduce an image is to specify\n# the same timestamp.\n\nset -e\nset -u\nset -o pipefail\n\nSOURCE=${1:?Specify the tarball to import}\nTIMESTAMP=${2:?Specify the timestamp to use}\nPLATFORM=${3:?Specify the target platform}\n\nCONF_TEMPLATE='{\"architecture\":\"%PLATFORM%\",\"comment\":\"from Bitnami with love\",\"config\":{\"Hostname\":\"\",\"Domainname\":\"\",\"User\":\"\",\"AttachStdin\":false,\"AttachStdout\":false,\"AttachStderr\":false,\"Tty\":false,\"OpenStdin\":false,\"StdinOnce\":false,\"Env\":null,\"Cmd\":[\"/bin/bash\"],\"Image\":\"\",\"Volumes\":null,\"WorkingDir\":\"\",\"Entrypoint\":null,\"OnBuild\":null,\"Labels\":null},\"container_config\":{\"Hostname\":\"\",\"Domainname\":\"\",\"User\":\"\",\"AttachStdin\":false,\"AttachStdout\":false,\"AttachStderr\":false,\"Tty\":false,\"OpenStdin\":false,\"StdinOnce\":false,\"Env\":null,\"Cmd\":null,\"Image\":\"\",\"Volumes\":null,\"WorkingDir\":\"\",\"Entrypoint\":null,\"OnBuild\":null,\"Labels\":null},\"created\":\"%TIMESTAMP%\",\"docker_version\":\"1.13.0\",\"history\":[{\"created\":\"%TIMESTAMP%\",\"comment\":\"from Bitnami with love\"}],\"os\":\"linux\",\"rootfs\":{\"type\":\"layers\",\"diff_ids\":[\"sha256:%LAYERSUM%\"]}}'\nMANIFEST_TEMPLATE='[{\"Config\":\"%CONF_SHA%.json\",\"RepoTags\":null,\"Layers\":[\"%LAYERSUM%/layer.tar\"]}]'\n\nimport() {\n    local TDIR=\"$(mktemp -d)\"\n    local LAYERSUM=\"$(sha256sum $SOURCE | awk '{print $1}')\"\n    mkdir $TDIR/$LAYERSUM\n    cp $SOURCE $TDIR/$LAYERSUM/layer.tar\n    echo -n '1.0' > $TDIR/$LAYERSUM/VERSION\n    local CONF=\"$(echo -n \"$CONF_TEMPLATE\" | sed -e \"s/%PLATFORM%/$PLATFORM/g\" -e \"s/%TIMESTAMP%/$TIMESTAMP/g\" -e \"s/%LAYERSUM%/$LAYERSUM/g\")\"\n    local CONF_SHA=\"$(echo -n \"$CONF\" | sha256sum | awk '{print $1}')\"\n    echo -n \"$CONF\" > \"$TDIR/${CONF_SHA}.json\"\n    local MANIFEST=\"$(echo -n \"$MANIFEST_TEMPLATE\" | sed -e \"s/%CONF_SHA%/$CONF_SHA/g\" -e \"s/%LAYERSUM%/$LAYERSUM/g\")\"\n    echo -n \"$MANIFEST\" > $TDIR/manifest.json\n    tar cf $TDIR/import.tar -C $TDIR manifest.json \"${CONF_SHA}.json\" \"$LAYERSUM\"\n    local ID=$(docker load -i $TDIR/import.tar | awk '{print $4}')\n    if [ \"$ID\" != \"sha256:$CONF_SHA\" ]; then\n        echo \"Failed to load $ID correctly, expected id to be $CONF_SHA, source in $TDIR\" >&2\n        exit 1\n    fi\n    rm -r \"$TDIR\"\n    echo $ID\n}\n\nimport\n"
        },
        {
          "name": "install-qemu.sh",
          "type": "blob",
          "size": 0.40234375,
          "content": "#!/bin/bash\n\nset -eu\n\ndo_sudo() {\n  if [[ \"0\" == \"$(id --user)\" ]]; then\n    \"$@\"\n  else\n    sudo \"$@\"\n  fi\n}\n\nwhile do_sudo fuser /var/{lib/{dpkg,apt/lists},cache/apt/archives}/lock >/dev/null 2>&1; do\n    sleep 1\ndone\n\ndo_sudo apt-get update\ndo_sudo apt-get install -y qemu-kvm libvirt-daemon-system libvirt-clients qemu-utils genisoimage virtinst curl rsync qemu-system-x86 qemu-system-arm cloud-image-utils\n\n"
        },
        {
          "name": "mkimage",
          "type": "blob",
          "size": 11.8583984375,
          "content": "#!/bin/bash\nset -e\nset -u\nset -o pipefail\n\nROOT=$(cd \"$(dirname \"$0\")\" && pwd)\n\nTARGET=${1:?Specify the target filename}\nDIST=${2:-stable}\nPLATFORM=${3:-$(dpkg --print-architecture)}\n\nLOGFILE=${TARGET}.log\n\n:>\"$LOGFILE\"\nexec >  >(tee -ia \"$LOGFILE\")\nexec 2> >(tee -ia \"$LOGFILE\" >&2)\n\nDEBOOTSTRAP_DIR=$(mktemp -d)\ncp -a /usr/share/debootstrap/* \"$DEBOOTSTRAP_DIR\"\ncp -a /usr/share/keyrings/debian-archive-keyring.gpg \"$DEBOOTSTRAP_DIR\"\ncp -a \"${ROOT}/debootstrap/\"* \"${DEBOOTSTRAP_DIR}/scripts\"\n\nKEYRING=$DEBOOTSTRAP_DIR/debian-archive-keyring.gpg\n\nuse_qemu_static() {\n    [[ \"$PLATFORM\" == \"arm64\" && ! ( \"$(uname -m)\" == *arm* || \"$(uname -m)\" == *aarch64* ) ]]\n}\n\nexport DEBIAN_FRONTEND=noninteractive\n\nDIRS_TO_TRIM=\"/usr/share/man\n/var/cache/apt\n/var/lib/apt/lists\n/usr/share/locale\n/var/log\n/usr/share/info\n/dev\n\"\n\ndebootstrap_arch_args=( )\n\nif use_qemu_static ; then\n    debootstrap_arch_args+=( --arch \"$PLATFORM\" )\nfi\n\nrootfsDir=$(mktemp -d)\necho \"Building base in $rootfsDir\"\nDEBOOTSTRAP_DIR=\"$DEBOOTSTRAP_DIR\" debootstrap \"${debootstrap_arch_args[@]}\"  --keyring \"$KEYRING\" --variant container --foreign \"${DIST}\" \"$rootfsDir\"\n\n# get path to \"chroot\" in our current PATH\nchrootPath=\"$(type -P chroot)\"\nrootfs_chroot() {\n    # \"chroot\" doesn't set PATH, so we need to set it explicitly to something our new debootstrap chroot can use appropriately!\n    # set PATH and chroot away!\n    PATH='/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin' \\\n            \"$chrootPath\" \"$rootfsDir\" \"$@\"\n\n}\n\nif use_qemu_static ; then\n    echo \"Setting up qemu static in chroot\"\n    usr_bin_modification_time=$(stat -c %y \"$rootfsDir\"/usr/bin)\n    if [ -f \"/usr/bin/qemu-aarch64-static\" ]; then\n        find /usr/bin/ -type f -name 'qemu-*-static' -exec cp {} \"$rootfsDir\"/usr/bin/. \\;\n    else\n        echo \"Cannot find aarch64 qemu static. Aborting...\" >&2\n        exit 1\n    fi\n    touch -d \"$usr_bin_modification_time\" \"$rootfsDir\"/usr/bin\nfi\n\nrootfs_chroot bash debootstrap/debootstrap --second-stage\n\nrepo_url=\"http://deb.debian.org/debian\"\nsec_repo_url_1=\"${repo_url}-security\"\nsec_repo_url_2=\"http://security.debian.org/debian-security\"\n\necho -e \"deb ${repo_url} $DIST main\" > \"$rootfsDir/etc/apt/sources.list\"\nif [ \"$DIST\" == \"bookworm\" ]; then\n    echo \"deb ${repo_url} $DIST-updates main\" >> \"$rootfsDir/etc/apt/sources.list\"\n    echo \"deb ${sec_repo_url_1} $DIST-security main\" >> \"$rootfsDir/etc/apt/sources.list\"\nelif [ \"$DIST\" == \"bullseye\" ]; then\n    echo \"deb ${repo_url} $DIST-updates main\" >> \"$rootfsDir/etc/apt/sources.list\"\n    echo \"deb ${sec_repo_url_2} $DIST-security main\" >> \"$rootfsDir/etc/apt/sources.list\"\nfi\n\nrootfs_chroot apt-get update\nrootfs_chroot apt-get upgrade -y -o Dpkg::Options::=\"--force-confdef\"\n\nrootfs_chroot dpkg -l | tee \"$TARGET.manifest\"\n\necho \"Applying docker-specific tweaks\"\n# These are copied from the docker contrib/mkimage/debootstrap script.\n# Modifications:\n#  - remove `strings` check for applying the --force-unsafe-io tweak.\n#     This was sometimes wrongly detected as not applying, and we aren't\n#     interested in building versions that this guard would apply to,\n#     so simply apply the tweak unconditionally.\n\n\n# prevent init scripts from running during install/update\necho >&2 \"+ echo exit 101 > '$rootfsDir/usr/sbin/policy-rc.d'\"\ncat > \"$rootfsDir/usr/sbin/policy-rc.d\" <<-'EOF'\n\t#!/bin/sh\n\t# For most Docker users, \"apt-get install\" only happens during \"docker build\",\n\t# where starting services doesn't work and often fails in humorous ways. This\n\t# prevents those failures by stopping the services from attempting to start.\n\texit 101\nEOF\nchmod +x \"$rootfsDir/usr/sbin/policy-rc.d\"\n\n# prevent upstart scripts from running during install/update\n(\n\tset -x\n\trootfs_chroot dpkg-divert --local --rename --add /sbin/initctl\n\tcp -a \"$rootfsDir/usr/sbin/policy-rc.d\" \"$rootfsDir/sbin/initctl\"\n\tsed -i 's/^exit.*/exit 0/' \"$rootfsDir/sbin/initctl\"\n)\n\n# shrink a little, since apt makes us cache-fat (wheezy: ~157.5MB vs ~120MB)\n( set -x; rootfs_chroot apt-get clean )\n\n# this file is one APT creates to make sure we don't \"autoremove\" our currently\n# in-use kernel, which doesn't really apply to debootstraps/Docker images that\n# don't even have kernels installed\nrm -f \"$rootfsDir/etc/apt/apt.conf.d/01autoremove-kernels\"\n\n# force dpkg not to call sync() after package extraction (speeding up installs)\necho >&2 \"+ echo force-unsafe-io > '$rootfsDir/etc/dpkg/dpkg.cfg.d/docker-apt-speedup'\"\ncat > \"$rootfsDir/etc/dpkg/dpkg.cfg.d/docker-apt-speedup\" <<-'EOF'\n# For most Docker users, package installs happen during \"docker build\", which\n# doesn't survive power loss and gets restarted clean afterwards anyhow, so\n# this minor tweak gives us a nice speedup (much nicer on spinning disks,\n# obviously).\nforce-unsafe-io\nEOF\n\nif [ -d \"$rootfsDir/etc/apt/apt.conf.d\" ]; then\n\t# _keep_ us lean by effectively running \"apt-get clean\" after every install\n\taptGetClean='\"rm -f /var/cache/apt/archives/*.deb /var/cache/apt/archives/partial/*.deb /var/cache/apt/*.bin || true\";'\n\techo >&2 \"+ cat > '$rootfsDir/etc/apt/apt.conf.d/docker-clean'\"\n\tcat > \"$rootfsDir/etc/apt/apt.conf.d/docker-clean\" <<-EOF\n\t\t# Since for most Docker users, package installs happen in \"docker build\" steps,\n\t\t# they essentially become individual layers due to the way Docker handles\n\t\t# layering, especially using CoW filesystems.  What this means for us is that\n\t\t# the caches that APT keeps end up just wasting space in those layers, making\n\t\t# our layers unnecessarily large (especially since we'll normally never use\n\t\t# these caches again and will instead just \"docker build\" again and make a brand\n\t\t# new image).\n\t\t# Ideally, these would just be invoking \"apt-get clean\", but in our testing,\n\t\t# that ended up being cyclic and we got stuck on APT's lock, so we get this fun\n\t\t# creation that's essentially just \"apt-get clean\".\n\t\tDPkg::Post-Invoke { ${aptGetClean} };\n\t\tAPT::Update::Post-Invoke { ${aptGetClean} };\n\t\tDir::Cache::pkgcache \"\";\n\t\tDir::Cache::srcpkgcache \"\";\n\t\t# Note that we do realize this isn't the ideal way to do this, and are always\n\t\t# open to better suggestions (https://github.com/docker/docker/issues).\n\tEOF\n\n\t# remove apt-cache translations for fast \"apt-get update\"\n\techo >&2 \"+ echo Acquire::Languages 'none' > '$rootfsDir/etc/apt/apt.conf.d/docker-no-languages'\"\n\tcat > \"$rootfsDir/etc/apt/apt.conf.d/docker-no-languages\" <<-'EOF'\n\t\t# In Docker, we don't often need the \"Translations\" files, so we're just wasting\n\t\t# time and space by downloading them, and this inhibits that.  For users that do\n\t\t# need them, it's a simple matter to delete this file and \"apt-get update\". :)\n\t\tAcquire::Languages \"none\";\n\tEOF\n\n\techo >&2 \"+ echo Acquire::GzipIndexes 'true' > '$rootfsDir/etc/apt/apt.conf.d/docker-gzip-indexes'\"\n\tcat > \"$rootfsDir/etc/apt/apt.conf.d/docker-gzip-indexes\" <<-'EOF'\n\t\t# Since Docker users using \"RUN apt-get update && apt-get install -y ...\" in\n\t\t# their Dockerfiles don't go delete the lists files afterwards, we want them to\n\t\t# be as small as possible on-disk, so we explicitly request \"gz\" versions and\n\t\t# tell Apt to keep them gzipped on-disk.\n\t\t# For comparison, an \"apt-get update\" layer without this on a pristine\n\t\t# \"debian:wheezy\" base image was \"29.88 MB\", where with this it was only\n\t\t# \"8.273 MB\".\n\t\tAcquire::GzipIndexes \"true\";\n\t\tAcquire::CompressionTypes::Order:: \"gz\";\n\tEOF\n\n\t# update \"autoremove\" configuration to be aggressive about removing suggests deps that weren't manually installed\n\techo >&2 \"+ echo Apt::AutoRemove::SuggestsImportant 'false' > '$rootfsDir/etc/apt/apt.conf.d/docker-autoremove-suggests'\"\n\tcat > \"$rootfsDir/etc/apt/apt.conf.d/docker-autoremove-suggests\" <<-'EOF'\n\t\t# Since Docker users are looking for the smallest possible final images, the\n\t\t# following emerges as a very common pattern:\n\t\t#   RUN apt-get update \\\n\t\t#       && apt-get install -y <packages> \\\n\t\t#       && <do some compilation work> \\\n\t\t#       && apt-get purge -y --auto-remove <packages>\n\t\t# By default, APT will actually _keep_ packages installed via Recommends or\n\t\t# Depends if another package Suggests them, even and including if the package\n\t\t# that originally caused them to be installed is removed.  Setting this to\n\t\t# \"false\" ensures that APT is appropriately aggressive about removing the\n\t\t# packages it added.\n\t\t# https://aptitude.alioth.debian.org/doc/en/ch02s05s05.html#configApt-AutoRemove-SuggestsImportant\n\t\tApt::AutoRemove::SuggestsImportant \"false\";\n\tEOF\nfi\n\ncat > \"$rootfsDir/usr/sbin/install_packages\" <<-'EOF'\n#!/bin/sh\nset -e\nset -u\nexport DEBIAN_FRONTEND=noninteractive\nn=0\nmax=2\nuntil [ $n -gt $max ]; do\n    set +e\n    (\n      apt-get update -qq &&\n      apt-get install -y --no-install-recommends \"$@\"\n    )\n    CODE=$?\n    set -e\n    if [ $CODE -eq 0 ]; then\n        break\n    fi\n    if [ $n -eq $max ]; then\n        exit $CODE\n    fi\n    echo \"apt failed, retrying\"\n    n=$(($n + 1))\ndone\nrm -r /var/lib/apt/lists /var/cache/apt/archives\nEOF\nchmod 0755 \"$rootfsDir/usr/sbin/install_packages\"\n\n# Set the password change date to a fixed date, otherwise it defaults to the current\n# date, so we get a different image every day. SOURCE_DATE_EPOCH is designed to do this, but\n# was only implemented recently, so we can't rely on it for all versions we want to build\n# We also have to copy over the backup at /etc/shadow- so that it doesn't change\nchroot \"$rootfsDir\" getent passwd | cut -d: -f1 | xargs -n 1 chroot \"$rootfsDir\" chage -d 17885 && cp \"$rootfsDir/etc/shadow\" \"$rootfsDir/etc/shadow-\"\n\n# Clean /etc/hostname and /etc/resolv.conf as they are based on the current env, so make\n# the chroot different. Docker doesn't care about them, as it fills them when starting\n# a container\necho \"\" > \"$rootfsDir/etc/resolv.conf\"\necho \"host\" > \"$rootfsDir/etc/hostname\"\n\n# Capture the most recent date that a package in the image was changed.\n# We don't care about the particular date, or which package it comes from,\n# we just need a date that isn't very far in the past.\n\n# We get multiple errors like:\n# gzip: stdout: Broken pipe\n# dpkg-parsechangelog: error: gunzip gave error exit status 1\n#\n# TODO: Why?\nset +o pipefail\nBUILD_DATE=\"$(find \"$rootfsDir/usr/share/doc\" -name changelog.Debian.gz -print0 | xargs -0 -n1 -I{} dpkg-parsechangelog -SDate -l'{}' | xargs -l -i date --date=\"{}\" +%s | sort -n | tail -n 1)\"\nset -o pipefail\n\n\necho \"Trimming down\"\nfor DIR in $DIRS_TO_TRIM; do\n  rm -r \"${rootfsDir:?rootfsDir cannot be empty}/$DIR\"/*\ndone\n# Remove the aux-cache as it isn't reproducible. It doesn't seem to\n# cause any problems to remove it.\nrm \"$rootfsDir/var/cache/ldconfig/aux-cache\"\n# Remove /usr/share/doc, but leave copyright files to be sure that we\n# comply with all licenses.\n# `mindepth 2` as we only want to remove files within the per-package\n# directories. Crucially some packages use a symlink to another package\n# dir (e.g. libgcc1), and we don't want to remove those.\nfind \"$rootfsDir/usr/share/doc\" -mindepth 2 -not -name copyright -not -type d -delete\nfind \"$rootfsDir/usr/share/doc\" -mindepth 1 -type d -empty -delete\n# Set the mtime on all files to be no older than $BUILD_DATE.\n# This is required to have the same metadata on files so that the\n# same tarball is produced. We assume that it is not important\n# that any file have a newer mtime than this.\nfind \"$rootfsDir\" -depth -newermt \"@$BUILD_DATE\" -print0 | xargs -0r touch --no-dereference --date=\"@$BUILD_DATE\"\necho \"Total size\"\ndu -skh \"$rootfsDir\"\necho \"Package sizes\"\n# these aren't shell variables, this is a template, so override sc thinking these are the wrong type of quotes\n# shellcheck disable=SC2016\nchroot \"$rootfsDir\" dpkg-query -W -f '${Package} ${Installed-Size}\\n'\necho \"Largest dirs\"\ndu \"$rootfsDir\" | sort -n | tail -n 20\necho \"Built in $rootfsDir\"\n\nif use_qemu_static ; then\n    echo \"Cleaning up qemu static files from image\"\n    usr_bin_modification_time=$(stat -c %y \"$rootfsDir\"/usr/bin)\n    rm -rf \"$rootfsDir\"/usr/bin/qemu-*-static\n    touch -d \"$usr_bin_modification_time\" \"$rootfsDir\"/usr/bin\nfi\n\ntar cf \"$TARGET\" -C \"$rootfsDir\" .\nrm -r \"$rootfsDir\"\nrm -r \"$DEBOOTSTRAP_DIR\"\n\necho \"Image built at ${TARGET}\"\n"
        },
        {
          "name": "pre-build.sh",
          "type": "blob",
          "size": 0.3046875,
          "content": "#!/bin/bash\n\nset -e\nset -u\nset -o pipefail\n\nif [[ ! -f /etc/debian_version ]]; then\n  echo \"minideb can currently only be built on debian based distros, aborting...\"\n  exit 1\nfi\n\napt-get update\napt-get install -y debootstrap debian-archive-keyring jq dpkg-dev gnupg apt-transport-https ca-certificates curl gpg\n\n"
        },
        {
          "name": "pushall",
          "type": "blob",
          "size": 1.455078125,
          "content": "#!/bin/bash\n\nset -e\nset -u\nset -o pipefail\n\nDISTS=\"bullseye\nbookworm\n\"\nLATEST=bookworm\nBASENAME=bitnami/minideb\n\nif [ -n \"${DOCKER_PASSWORD:-}\" ]; then\n    docker login -u \"$DOCKER_USERNAME\" -p \"$DOCKER_PASSWORD\"\nfi\n\nENABLE_DOCKER_CONTENT_TRUST=0\nif [ -n \"${DOCKER_CONTENT_TRUST_REPOSITORY_PASSPHRASE:-}\" ] && [ -n \"${DOCKER_CONTENT_TRUST_REPOSITORY_KEY:-}\" ]; then\n    tmpdir=$(mktemp -d)\n    (cd \"${tmpdir}\" && bash -c 'echo -n \"${DOCKER_CONTENT_TRUST_REPOSITORY_KEY}\" | base64 -d > key')\n    chmod 400 \"${tmpdir}/key\"\n    docker trust key load \"${tmpdir}/key\"\n    rm -rf \"${tmpdir}\"\n    export ENABLE_DOCKER_CONTENT_TRUST=1\nfi\n\npush() {\n    local dist=\"$1\"\n    DOCKER_CONTENT_TRUST=${ENABLE_DOCKER_CONTENT_TRUST} docker push \"${BASENAME}:${dist}\"\n}\n\nfor DIST in $DISTS; do\n    push \"$DIST\"\ndone\n\ndocker tag \"${BASENAME}:${LATEST}\" \"${BASENAME}:latest\"\n\npush latest\n\n# Create and merge a PR to update minideb-extras\nCIRCLE_CI_FUNCTIONS_URL=${CIRCLE_CI_FUNCTIONS_URL:-https://raw.githubusercontent.com/bitnami/test-infra/master/circle/functions}\n# sc can't follow source as it is a remote file\n# shellcheck disable=SC1090\nsource <(curl -sSL \"$CIRCLE_CI_FUNCTIONS_URL\")\nfor DIST in $DISTS; do\n    # Use '.RepoDigests 0' for getting Dockerhub repo digest as it was the first pushed\n    DIST_REPO_DIGEST=$(docker image inspect --format '{{index .RepoDigests 0}}' \"${BASENAME}:${DIST}\")\n    update_minideb_derived \"https://github.com/bitnami/minideb-runtimes\" \"$DIST\" \"$DIST_REPO_DIGEST\"\ndone\n"
        },
        {
          "name": "pushmanifest",
          "type": "blob",
          "size": 1.2939453125,
          "content": "#!/bin/bash\n\nset -e\nset -u\nset -o pipefail\n\nDISTS=${DISTS:-\"bullseye\nbookworm\nlatest\n\"}\n\nBASENAME=bitnami/minideb\nPLATFORMS=${PLATFORMS:-amd64 arm64}\nDRY_RUN=${DRY_RUN:-}\nread -r -a ARCHS <<<\"$PLATFORMS\"\n\nrun_docker() {\n    if [[ -n \"${DRY_RUN:-}\" ]]; then\n        echo \"DRY RUN docker ${*}\"\n    else\n        docker \"$@\"\n    fi\n}\n\nlist_includes() {\n    local list=\"\"\n    local element=\"\"\n    list=${1?You must provide a list}\n    element=${2:?You must provide an element}\n    for candidate in $list; do\n        if [[ \"$candidate\" == \"$element\" ]]; then\n            true\n            return\n        fi\n    done\n    false\n    return\n}\n\nif [ -n \"${DOCKER_PASSWORD:-}\" ]; then\n    echo \"$DOCKER_PASSWORD\" | run_docker login -u \"$DOCKER_USERNAME\" --password-stdin\nfi\n\npush_manifest() {\n    local image=\"\"\n    local archs=\"\"\n    image=\"${1:?You must provide the image base to publish}\"\n    archs=(\"${@:2}\")\n    local arch_images=()\n    for arch in \"${archs[@]}\"; do\n        arch_images+=(\"$image-$arch\")\n    done\n    run_docker manifest create \"$image\" \"${arch_images[@]}\"\n    run_docker manifest push \"$image\"\n}\n\ntags=()\n\nfor DIST in $DISTS; do\n    tags+=(\"$DIST\")\ndone\n\nrepositories=(\"$BASENAME\")\n\nfor tag in \"${tags[@]}\"; do\n    for repo in \"${repositories[@]}\"; do\n        push_manifest \"$repo:$tag\" \"${ARCHS[@]}\"\n    done\ndone\n"
        },
        {
          "name": "pushone",
          "type": "blob",
          "size": 0.7998046875,
          "content": "#!/bin/bash\n\nset -e\nset -u\nset -o pipefail\n\nDIST=${1:?Specify the distrubution name}\nPLATFORM=${2:-amd64}\n\nBASENAME=bitnami/minideb\n\nif [ -n \"${DOCKER_PASSWORD:-}\" ]; then\n    echo \"$DOCKER_PASSWORD\" | docker login -u \"$DOCKER_USERNAME\" --password-stdin\nfi\n\nENABLE_DOCKER_CONTENT_TRUST=0\nif [ -n \"${DOCKER_CONTENT_TRUST_REPOSITORY_PASSPHRASE:-}\" ] && [ -n \"${DOCKER_CONTENT_TRUST_REPOSITORY_KEY:-}\" ]; then\n    tmpdir=$(mktemp -d)\n    (cd \"${tmpdir}\" && bash -c 'echo -n \"${DOCKER_CONTENT_TRUST_REPOSITORY_KEY}\" | base64 -d > key')\n    chmod 400 \"${tmpdir}/key\"\n    docker trust key load \"${tmpdir}/key\"\n    rm -rf \"${tmpdir}\"\n    export ENABLE_DOCKER_CONTENT_TRUST=1\nfi\n\npush() {\n    local dist=\"$1\"\n    DOCKER_CONTENT_TRUST=${ENABLE_DOCKER_CONTENT_TRUST} docker push \"${BASENAME}:${dist}\"\n}\n\npush \"$DIST-${PLATFORM}\"\n"
        },
        {
          "name": "qemu_build",
          "type": "blob",
          "size": 4.3046875,
          "content": "#!/bin/bash\n\nset -e\nset -u\nset -o pipefail\n\nBASENAME=bitnami/minideb\npub_key_dir=\"$(mktemp -d)\"\n\ndo_ssh() {\n  ssh -o \"StrictHostKeyChecking=no\" -o \"UserKnownHostsFile=/dev/null\" root@localhost -t -p 5555 -i \"$pub_key_dir/id_rsa\" \"$@\"\n}\n\nfinish() {\n  echo \"Shutting down QEMU...\"\n\n  n=0\n  until [ \"$n\" -ge 15 ]\n  do\n     do_ssh \"true\" && break\n     n=$((n+1))\n     sleep 30\n  done\n\n  do_ssh \"poweroff\" || true\n\n  sleep 5\n  n=0\n  until [ \"$n\" -ge 5 ]\n  do\n     kill -0 \"$PID\" && break\n     n=$((n+1))\n     sleep 5\n  done\n\n  kill -9 \"$PID\" || true\n  rm -f \"$IMAGE_FILE\" \"$PIDFILE\"\n}\n\nif [[ ! -f /etc/debian_version ]]; then\n  echo \"minideb can currently only be built on debian based distros, aborting...\"\n  exit 1\nfi\n\nif [ -z \"$1\" ]; then\n    echo \"You must specify the dist to build\"\n    exit 1\nfi\n\nDIST=$1\nPLATFORM=${2:-amd64}\n\nmake .installed-qemu\nmkdir -p .kvm-images/{amd64,arm64}\n\nif [[ ! -f .kvm-images/amd64/buster-server-cloudimg-amd64.qcow2 && \"$PLATFORM\" == \"amd64\" ]]; then\n  curl -SL https://cdimage.debian.org/cdimage/openstack/current/debian-10-openstack-amd64.qcow2 > .kvm-images/amd64/buster-server-cloudimg-amd64.qcow2\nfi\n\nif [[ ! -f .kvm-images/arm64/buster-server-cloudimg-arm64.qcow2 && \"$PLATFORM\" == \"arm64\" ]]; then\n  curl -SL https://cdimage.debian.org/cdimage/openstack/current/debian-10-openstack-arm64.qcow2 > .kvm-images/arm64/buster-server-cloudimg-arm64.qcow2\n  curl -SL https://releases.linaro.org/components/kernel/uefi-linaro/latest/release/qemu64/QEMU_EFI.fd > .kvm-images/arm64/QEMU_EFI.fd\nfi\n\nIMAGE_FILE=\"build/$DIST/$PLATFORM/instance.qcow2\"\nPIDFILE=\"build/$DIST/$PLATFORM/instance.pid\"\nTARGET_FILE=\"build/$DIST/$PLATFORM/image.tar\"\n\nmkdir -p \"build/$DIST/$PLATFORM\"\n\nqemu-img create -f qcow2 -o backing_file=\"../../../.kvm-images/$PLATFORM/buster-server-cloudimg-$PLATFORM.qcow2\" \"$IMAGE_FILE\"\nqemu-img resize \"$IMAGE_FILE\" 8G\n\nUSER_DATA='\n#cloud-config\ndisable_root: false\n\n# USEFUL FOR DEBUG SSH CONNECTION ISSUES\n# chpasswd:\n#   list: |\n#     root:root\n#   expire: False\n\nusers:\n    - name: root\n      ssh_authorized_keys:\n        - '\n\ncat /dev/zero | ssh-keygen -q -t rsa -f \"$pub_key_dir/id_rsa\" -N \"\" || true\necho \"$USER_DATA$(cat \"$pub_key_dir/id_rsa.pub\")\" > \"$pub_key_dir/user-data\"\n\ncloud-localds \"$pub_key_dir/user-data.img\" \"$pub_key_dir/user-data\"\n\ncase $PLATFORM in\namd64)\n  qemu-system-x86_64 \\\n    -enable-kvm \\\n    -device virtio-net,netdev=net0 \\\n    -netdev user,id=net0,hostfwd=tcp::5555-:22 \\\n    -boot c \\\n    -pidfile \"$PIDFILE\" \\\n    -m 2G \\\n    -drive \"file=$IMAGE_FILE,format=qcow2\" \\\n    -drive \"file=$pub_key_dir/user-data.img,format=raw\" \\\n    -vga none \\\n    -nographic &\n  ;;\narm64)\n  qemu-system-aarch64 \\\n    -accel tcg,thread=multi \\\n    -machine virt \\\n    -cpu cortex-a57 \\\n    -device virtio-net,netdev=net0 \\\n    -netdev user,id=net0,hostfwd=tcp::5555-:22 \\\n    -boot c \\\n    -pidfile \"$PIDFILE\" \\\n    -m 2G \\\n    -monitor telnet::45454,server,nowait \\\n    -bios .kvm-images/arm64/QEMU_EFI.fd  \\\n    -drive \"file=$IMAGE_FILE,format=qcow2\" \\\n    -drive \"file=$pub_key_dir/user-data.img,format=raw\" \\\n    -vga none \\\n    -nographic &\n  ;;\nesac\n\ntrap finish EXIT\n\nsleep 30\nn=0\nuntil [ \"$n\" -ge 15 ]\ndo\n   do_ssh \"true\" && break\n   n=$((n+1))\n   sleep 30\ndone\n\nPID=\"$(cat \"$PIDFILE\")\"\n\ndo_ssh \"apt-get update && apt-get install -y apt-transport-https make rsync ca-certificates curl gnupg-agent software-properties-common && mkdir /build\"\ndo_ssh \"curl -fsSL https://download.docker.com/linux/ubuntu/gpg | apt-key add -\"\ndo_ssh \"add-apt-repository \\\"deb [arch=$PLATFORM] https://download.docker.com/linux/debian \\$(lsb_release -cs) stable\\\"\"\ndo_ssh \"apt-get update && apt-get install -y docker-ce docker-ce-cli containerd.io\"\nrsync -avz -e \"ssh -o 'StrictHostKeyChecking=no' -o 'UserKnownHostsFile=/dev/null' -p 5555 -i $pub_key_dir/id_rsa\" --exclude \".git\" --exclude \".installed-requirements\" --exclude \".kvm-images\" --exclude \"build\" --exclude \"ssh\" ./ \"root@localhost:/build/.\"\ndo_ssh \"cd /build/ && make .installed-requirements\"\n\ndo_ssh \"cd /build/ && ./buildone \\\"$DIST\\\" \\\"$PLATFORM\\\"\"\nrsync -avz -e \"ssh -o 'StrictHostKeyChecking=no' -o 'UserKnownHostsFile=/dev/null' -p 5555 -i $pub_key_dir/id_rsa\" \"root@localhost:/build/build/$DIST.tar\" \"./$TARGET_FILE\"\n\ncurrent_ts=\"$(date -u +%Y-%m-%dT%H:%M:%S.%NZ)\"\nbuilt_image_id=$(./import \"$TARGET_FILE\" \"$current_ts\" \"$PLATFORM\")\ndocker tag \"$built_image_id\" \"$BASENAME:$DIST-$PLATFORM\"\n\n"
        },
        {
          "name": "shellcheck",
          "type": "blob",
          "size": 0.1259765625,
          "content": "#!/bin/bash\n\nset -eu\nset -o pipefail\n\nSCRIPTS=(shellcheck mkimage buildone buildall pushall)\n\nshellcheck -s bash \"${SCRIPTS[@]}\"\n"
        },
        {
          "name": "test",
          "type": "blob",
          "size": 3.404296875,
          "content": "#!/bin/bash\n\nset -eu\n\nIMAGE_ID=$1\nDIST=$2\nPLATFORM=${3:-amd64}\nfunction desc() {\n    echo \"================================\"\n    echo -n \"TEST: \"\n    echo \"$@\"\n    echo \"================================\"\n}\n\nfunction test() {\n    test_extra_args '' \"$@\"\n}\n\nbind_mounts=( )\ndocker_platform_args=( )\nif [[ \"$PLATFORM\" == \"arm64\" ]]; then\n    if [[ \"$(uname -m)\" == *arm* || \"$(uname -m)\" == *aarch64* ]]; then\n        echo \"Running in arm host. QEMU is not needed\"\n    else\n        echo \"Setting up qemu static\"\n        for qemu_static_file in /usr/bin/qemu-*-static; do\n            bind_mounts+=( -v=\"$qemu_static_file:$qemu_static_file\" )\n        done\n        docker_platform_args+=( --platform \"linux/arm64\" )\n    fi\nfi\n\nfunction test_extra_args() {\n    local extra_args=$1\n    shift\n    docker run \"${docker_platform_args[@]}\" --rm \"${bind_mounts[@]}\" $extra_args -e DEBIAN_FRONTEND=noninteractive \"$IMAGE_ID\" \"$@\"\n    echo \"\"\n    echo TEST: OK\n    echo \"\"\n}\n\ndesc \"Checking that apt is installed\"\ntest dpkg -l apt\n\ndesc \"Arch matches\"\nif [[ \"$PLATFORM\" == \"amd64\" ]]; then\n    test bash -c 'echo \"$(uname -m)\" && [[ \"$(uname -m)\" == *x86_64* ]]'\nelif [[ \"$PLATFORM\" == \"arm64\" ]]; then\n    test bash -c 'echo \"$(uname -m)\" && [[ \"$(uname -m)\" == *arm* || \"$(uname -m)\" == *aarch64* ]]'\nelse\n    echo Unknown platform $PLATFORM >&2\n    exit 1\nfi\ndesc \"Checking that a package can be installed with apt\"\ntest bash -c 'apt-get update && apt-get -y install less && less --help >/dev/null'\n\ndesc \"Checking that a package can be installed with install_packages and that it removes cache dirs\"\ntest bash -c 'install_packages less  && less --help >/dev/null && [ ! -e /var/cache/apt/archives ] && [ ! -e /var/lib/apt/lists ]'\n\ndesc \"Checking that the debootstrap dir wasn't left in the image\"\ntest bash -c '[ ! -e /debootstrap ]'\n\ndesc \"Check that all base packages are correctly installed, including dependencies\"\n# Ask apt to install all packages that are already installed, has the effect of checking the\n# dependencies are correctly available\ntest bash -c 'apt-get update && (dpkg-query -W -f \\${Package} | while read pkg; do apt-get install $pkg; done)'\n\ndesc \"Check that install_packages doesn't loop forever on failures\"\n# This won't install and will fail. The key is that the retry loop will stop after a few iterations.\n# We check that we didn't install the package afterwards, just in case a package gets added with that name.\n# We wrap the whole thing in a timeout so that it doesn't loop forever. It's not ideal to have a timeout as there may be spurious failures if the network is slow.\ntest bash -c 'timeout 360 bash -c \"(install_packages thispackagebetternotexist || true) && ! dpkg -l thispackagebetternotexist\"'\n\n# See https://github.com/bitnami/minideb/issues/17\ndesc \"Checking that the terminfo is valid when running with -t (#17)\"\necho \"\" | test_extra_args '-t' bash -c 'install_packages procps && top -d1 -n1 -b'\n\nMYSQL_PACKAGE=default-mysql-server\n\n# See https://github.com/bitnami/minideb/issues/16\ndesc \"Check that we can install mysql-server (#16)\"\ntest install_packages $MYSQL_PACKAGE\n\nfunction shadow_check() {\n    local path=$1\n    test bash -c \"(! cut -d: -f3 < $path | grep -v 17885 >/dev/null) || (cat $path && false)\"\n}\n\ndesc \"Check that all users have a fixed day as the last password change date in /etc/shadow\"\nshadow_check /etc/shadow\n\ndesc \"Check that all users have a fixed day as the last password change date in /etc/shadow-\"\nshadow_check /etc/shadow-\n"
        }
      ]
    }
  ]
}