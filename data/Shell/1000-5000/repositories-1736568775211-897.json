{
  "metadata": {
    "timestamp": 1736568775211,
    "page": 897,
    "hasNextPage": true,
    "endCursor": "Y3Vyc29yOjkwOQ==",
    "completionStatus": "IN_PROGRESS"
  },
  "repositories": [
    {
      "nameWithOwner": "kubernetes-retired/kubeadm-dind-cluster",
      "stars": 1105,
      "defaultBranch": "master",
      "files": [
        {
          "name": ".circleci",
          "type": "tree",
          "content": null
        },
        {
          "name": ".gitignore",
          "type": "blob",
          "size": 0.013671875,
          "content": "/save.tar.lz4\n"
        },
        {
          "name": ".travis.yml",
          "type": "blob",
          "size": 0.3525390625,
          "content": "sudo: required\nservices: docker\nlanguage: minimal\n\nenv:\n  - TEST_CASE=1.12\n  - TEST_CASE=1.13\n  - TEST_CASE=1.14\n  - TEST_CASE=1.15\n\nbefore_install:\n  - sudo apt-get -qq update\n  - sudo apt-get install -y liblz4-tool\n\nscript:\n  # building k8s may cause Travis to time out w/o output\n  - if [ -n \"${TWAIT:-}\" ]; then travis_wait 35 ./test.sh; else ./test.sh; fi\n"
        },
        {
          "name": "AUTHORS.md",
          "type": "blob",
          "size": 0.357421875,
          "content": "Authors\n-------\n\nA number of persons have contributed to predecessors of this work in one way or another:\n\n- Ivan Shvedunov <ivan4th@gmail.com>\n- Ilya Dmitrichenko <errordeveloper@gmail.com>\n- Maru Newby <marun@redhat.com>\n- Karl Isenberg <karlkfi@yahoo.com>\n- Dr. Stefan Schimanski <sttts@redhat.com>\n- the authors of wrapdocker at https://github.com/jpetazzo/dind\n"
        },
        {
          "name": "CONTRIBUTING.md",
          "type": "blob",
          "size": 1.923828125,
          "content": "# Contributing Guidelines\n\nRead the following guide if you're interested in contributing to kubeadm-dind-cluster.\n\n## Contributor License Agreements\n\nWe'd love to accept your patches! Before we can take them, we have to jump a couple of legal hurdles.\n\nPlease fill out either the individual or corporate Contributor License Agreement (CLA). More information about the CLA and instructions for signing it [can be found here](https://github.com/kubernetes/community/blob/master/CLA.md).\n\n***NOTE***: Only original source code from you and other people that have signed the CLA can be accepted into the repository.\n\n## Finding Things That Need Help\n\nIf you're new to the project and want to help, but don't know where to start, we have a semi-curated list of issues that should not need deep knowledge of the system. [Have a look and see if anything sounds interesting](https://github.com/kubernetes-sigs/kubeadm-dind-cluster/issues?q=is%3Aopen+is%3Aissue+label%3A%22help+wanted%22). Alternatively, read some of the docs on other controllers and try to write your own, file and fix any/all issues that come up, including gaps in documentation!\n\n## Contributing a Patch\n\n1. If you haven't already done so, sign a Contributor License Agreement (see details above).\n1. Fork the desired repo, develop and test your code changes.\n1. Submit a pull request.\n\nAll changes must be code reviewed. Coding conventions and standards are explained in the official [developer docs](https://github.com/kubernetes/community/tree/master/contributors/devel). Expect reviewers to request that you avoid common [go style mistakes](https://github.com/golang/go/wiki/CodeReviewComments) in your PRs.\n\n### Merge Approval\n\nkubeadm-dind-cluster maintainers may add \"LGTM\" (Looks Good To Me) or an equivalent comment to indicate that a PR is acceptable. Any change requires at least one LGTM.  No pull requests can be merged until at least one kubeadm-dind-cluster maintainer signs off with an LGTM.\n"
        },
        {
          "name": "Dockerfile",
          "type": "blob",
          "size": 1.2900390625,
          "content": "FROM mirantis/kubeadm-dind-cluster:bare-v4\n\nLABEL mirantis.kubeadm_dind_cluster_final=1\n\n# the following args should be set for derived images\n\n#Todo: download prebuilt hyperkube (not kubectl!) & kubeadm into /k8s\nARG PREBUILT_KUBEADM_AND_HYPERKUBE\nARG KUBEADM_URL\nARG KUBEADM_SHA1\nARG HYPERKUBE_URL\nARG HYPERKUBE_SHA1\nARG KUBECTL_VERSION\nARG KUBECTL_LINUX_URL\nARG KUBECTL_LINUX_SHA1\nARG KUBECTL_DARWIN_URL\nARG KUBECTL_DARWIN_SHA1\n\nRUN if [ -n \"${KUBEADM_URL}\" ]; then \\\n      mkdir -p /k8s && \\\n      curl -sSL \"${KUBEADM_URL}\" > /k8s/kubeadm && \\\n      if [ -n \"${KUBEADM_SHA1}\" ]; then echo \"${KUBEADM_SHA1}  /k8s/kubeadm\" | sha1sum -c; fi && \\\n      chmod +x /k8s/kubeadm; \\\n    fi; \\\n    if [ -n \"${HYPERKUBE_URL}\" ]; then \\\n      curl -sSL \"${HYPERKUBE_URL}\" > /k8s/hyperkube && \\\n      if [ -n \"${HYPERKUBE_SHA1}\" ]; then echo \"${HYPERKUBE_SHA1}  /k8s/hyperkube\" | sha1sum -c; fi && \\\n      chmod +x /k8s/hyperkube; \\\n    fi && \\\n    ( echo \"export KUBECTL_VERSION=${KUBECTL_VERSION}\" && \\\n      echo \"export KUBECTL_LINUX_SHA1=${KUBECTL_LINUX_SHA1}\" && \\\n      echo \"export KUBECTL_LINUX_URL=${KUBECTL_LINUX_URL}\" && \\\n      echo \"export KUBECTL_DARWIN_SHA1=${KUBECTL_DARWIN_SHA1}\" && \\\n      echo \"export KUBECTL_DARWIN_URL=${KUBECTL_DARWIN_URL}\" ) >/dind-env\nCOPY save.tar.lz4 /\n\nENTRYPOINT [\"/sbin/dind_init\"]\n"
        },
        {
          "name": "LICENSE",
          "type": "blob",
          "size": 11.0908203125,
          "content": "                                 Apache License\n                           Version 2.0, January 2004\n                        http://www.apache.org/licenses/\n\n   TERMS AND CONDITIONS FOR USE, REPRODUCTION, AND DISTRIBUTION\n\n   1. Definitions.\n\n      \"License\" shall mean the terms and conditions for use, reproduction,\n      and distribution as defined by Sections 1 through 9 of this document.\n\n      \"Licensor\" shall mean the copyright owner or entity authorized by\n      the copyright owner that is granting the License.\n\n      \"Legal Entity\" shall mean the union of the acting entity and all\n      other entities that control, are controlled by, or are under common\n      control with that entity. For the purposes of this definition,\n      \"control\" means (i) the power, direct or indirect, to cause the\n      direction or management of such entity, whether by contract or\n      otherwise, or (ii) ownership of fifty percent (50%) or more of the\n      outstanding shares, or (iii) beneficial ownership of such entity.\n\n      \"You\" (or \"Your\") shall mean an individual or Legal Entity\n      exercising permissions granted by this License.\n\n      \"Source\" form shall mean the preferred form for making modifications,\n      including but not limited to software source code, documentation\n      source, and configuration files.\n\n      \"Object\" form shall mean any form resulting from mechanical\n      transformation or translation of a Source form, including but\n      not limited to compiled object code, generated documentation,\n      and conversions to other media types.\n\n      \"Work\" shall mean the work of authorship, whether in Source or\n      Object form, made available under the License, as indicated by a\n      copyright notice that is included in or attached to the work\n      (an example is provided in the Appendix below).\n\n      \"Derivative Works\" shall mean any work, whether in Source or Object\n      form, that is based on (or derived from) the Work and for which the\n      editorial revisions, annotations, elaborations, or other modifications\n      represent, as a whole, an original work of authorship. For the purposes\n      of this License, Derivative Works shall not include works that remain\n      separable from, or merely link (or bind by name) to the interfaces of,\n      the Work and Derivative Works thereof.\n\n      \"Contribution\" shall mean any work of authorship, including\n      the original version of the Work and any modifications or additions\n      to that Work or Derivative Works thereof, that is intentionally\n      submitted to Licensor for inclusion in the Work by the copyright owner\n      or by an individual or Legal Entity authorized to submit on behalf of\n      the copyright owner. For the purposes of this definition, \"submitted\"\n      means any form of electronic, verbal, or written communication sent\n      to the Licensor or its representatives, including but not limited to\n      communication on electronic mailing lists, source code control systems,\n      and issue tracking systems that are managed by, or on behalf of, the\n      Licensor for the purpose of discussing and improving the Work, but\n      excluding communication that is conspicuously marked or otherwise\n      designated in writing by the copyright owner as \"Not a Contribution.\"\n\n      \"Contributor\" shall mean Licensor and any individual or Legal Entity\n      on behalf of whom a Contribution has been received by Licensor and\n      subsequently incorporated within the Work.\n\n   2. Grant of Copyright License. Subject to the terms and conditions of\n      this License, each Contributor hereby grants to You a perpetual,\n      worldwide, non-exclusive, no-charge, royalty-free, irrevocable\n      copyright license to reproduce, prepare Derivative Works of,\n      publicly display, publicly perform, sublicense, and distribute the\n      Work and such Derivative Works in Source or Object form.\n\n   3. Grant of Patent License. Subject to the terms and conditions of\n      this License, each Contributor hereby grants to You a perpetual,\n      worldwide, non-exclusive, no-charge, royalty-free, irrevocable\n      (except as stated in this section) patent license to make, have made,\n      use, offer to sell, sell, import, and otherwise transfer the Work,\n      where such license applies only to those patent claims licensable\n      by such Contributor that are necessarily infringed by their\n      Contribution(s) alone or by combination of their Contribution(s)\n      with the Work to which such Contribution(s) was submitted. If You\n      institute patent litigation against any entity (including a\n      cross-claim or counterclaim in a lawsuit) alleging that the Work\n      or a Contribution incorporated within the Work constitutes direct\n      or contributory patent infringement, then any patent licenses\n      granted to You under this License for that Work shall terminate\n      as of the date such litigation is filed.\n\n   4. Redistribution. You may reproduce and distribute copies of the\n      Work or Derivative Works thereof in any medium, with or without\n      modifications, and in Source or Object form, provided that You\n      meet the following conditions:\n\n      (a) You must give any other recipients of the Work or\n          Derivative Works a copy of this License; and\n\n      (b) You must cause any modified files to carry prominent notices\n          stating that You changed the files; and\n\n      (c) You must retain, in the Source form of any Derivative Works\n          that You distribute, all copyright, patent, trademark, and\n          attribution notices from the Source form of the Work,\n          excluding those notices that do not pertain to any part of\n          the Derivative Works; and\n\n      (d) If the Work includes a \"NOTICE\" text file as part of its\n          distribution, then any Derivative Works that You distribute must\n          include a readable copy of the attribution notices contained\n          within such NOTICE file, excluding those notices that do not\n          pertain to any part of the Derivative Works, in at least one\n          of the following places: within a NOTICE text file distributed\n          as part of the Derivative Works; within the Source form or\n          documentation, if provided along with the Derivative Works; or,\n          within a display generated by the Derivative Works, if and\n          wherever such third-party notices normally appear. The contents\n          of the NOTICE file are for informational purposes only and\n          do not modify the License. You may add Your own attribution\n          notices within Derivative Works that You distribute, alongside\n          or as an addendum to the NOTICE text from the Work, provided\n          that such additional attribution notices cannot be construed\n          as modifying the License.\n\n      You may add Your own copyright statement to Your modifications and\n      may provide additional or different license terms and conditions\n      for use, reproduction, or distribution of Your modifications, or\n      for any such Derivative Works as a whole, provided Your use,\n      reproduction, and distribution of the Work otherwise complies with\n      the conditions stated in this License.\n\n   5. Submission of Contributions. Unless You explicitly state otherwise,\n      any Contribution intentionally submitted for inclusion in the Work\n      by You to the Licensor shall be under the terms and conditions of\n      this License, without any additional terms or conditions.\n      Notwithstanding the above, nothing herein shall supersede or modify\n      the terms of any separate license agreement you may have executed\n      with Licensor regarding such Contributions.\n\n   6. Trademarks. This License does not grant permission to use the trade\n      names, trademarks, service marks, or product names of the Licensor,\n      except as required for reasonable and customary use in describing the\n      origin of the Work and reproducing the content of the NOTICE file.\n\n   7. Disclaimer of Warranty. Unless required by applicable law or\n      agreed to in writing, Licensor provides the Work (and each\n      Contributor provides its Contributions) on an \"AS IS\" BASIS,\n      WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or\n      implied, including, without limitation, any warranties or conditions\n      of TITLE, NON-INFRINGEMENT, MERCHANTABILITY, or FITNESS FOR A\n      PARTICULAR PURPOSE. You are solely responsible for determining the\n      appropriateness of using or redistributing the Work and assume any\n      risks associated with Your exercise of permissions under this License.\n\n   8. Limitation of Liability. In no event and under no legal theory,\n      whether in tort (including negligence), contract, or otherwise,\n      unless required by applicable law (such as deliberate and grossly\n      negligent acts) or agreed to in writing, shall any Contributor be\n      liable to You for damages, including any direct, indirect, special,\n      incidental, or consequential damages of any character arising as a\n      result of this License or out of the use or inability to use the\n      Work (including but not limited to damages for loss of goodwill,\n      work stoppage, computer failure or malfunction, or any and all\n      other commercial damages or losses), even if such Contributor\n      has been advised of the possibility of such damages.\n\n   9. Accepting Warranty or Additional Liability. While redistributing\n      the Work or Derivative Works thereof, You may choose to offer,\n      and charge a fee for, acceptance of support, warranty, indemnity,\n      or other liability obligations and/or rights consistent with this\n      License. However, in accepting such obligations, You may act only\n      on Your own behalf and on Your sole responsibility, not on behalf\n      of any other Contributor, and only if You agree to indemnify,\n      defend, and hold each Contributor harmless for any liability\n      incurred by, or claims asserted against, such Contributor by reason\n      of your accepting any such warranty or additional liability.\n\n   END OF TERMS AND CONDITIONS\n\n   APPENDIX: How to apply the Apache License to your work.\n\n      To apply the Apache License to your work, attach the following\n      boilerplate notice, with the fields enclosed by brackets \"{}\"\n      replaced with your own identifying information. (Don't include\n      the brackets!)  The text should be enclosed in the appropriate\n      comment syntax for the file format. We also recommend that a\n      file or class name and description of purpose be included on the\n      same \"printed page\" as the copyright notice for easier\n      identification within third-party archives.\n\n   Copyright {yyyy} {name of copyright owner}\n\n   Licensed under the Apache License, Version 2.0 (the \"License\");\n   you may not use this file except in compliance with the License.\n   You may obtain a copy of the License at\n\n       http://www.apache.org/licenses/LICENSE-2.0\n\n   Unless required by applicable law or agreed to in writing, software\n   distributed under the License is distributed on an \"AS IS\" BASIS,\n   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n   See the License for the specific language governing permissions and\n   limitations under the License.\n"
        },
        {
          "name": "OWNERS",
          "type": "blob",
          "size": 0.228515625,
          "content": "# See the OWNERS docs: https://git.k8s.io/community/contributors/guide/owners.md\n\napprovers:\n- sig-cluster-lifecycle-leads\n- kubeadm-dind-cluster-maintainers\nreviewers:\n- sig-cluster-lifecycle-leads\n- kubeadm-dind-cluster-maintainers\n"
        },
        {
          "name": "OWNERS_ALIASES",
          "type": "blob",
          "size": 0.2578125,
          "content": "# See the OWNERS docs: https://git.k8s.io/community/contributors/guide/owners.md\n\naliases:\n  sig-cluster-lifecycle-leads:\n  - lukemarsden\n  - luxas\n  - roberthbailey\n  - timothysc\n  kubeadm-dind-cluster-maintainers:\n  - pigmej\n  - ivan4th\n  - lukaszo\n  - jellonek\n"
        },
        {
          "name": "README.md",
          "type": "blob",
          "size": 26.4052734375,
          "content": "# kubeadm-dind-cluster [![CircleCI](https://circleci.com/gh/kubernetes-sigs/kubeadm-dind-cluster/tree/master.svg?style=svg)](https://circleci.com/gh/kubernetes-sigs/kubeadm-dind-cluster/tree/master) [![Travis CI](https://travis-ci.org/kubernetes-sigs/kubeadm-dind-cluster.svg?branch=master)](https://travis-ci.org/kubernetes-sigs/kubeadm-dind-cluster)\n\n**NOTE: This project is deprecated in favor of [kind](https://kind.sigs.k8s.io/).\nTry [kind](https://kind.sigs.k8s.io/) today, it's great!**\n\nA Kubernetes multi-node cluster for developer _of_ Kubernetes and\nprojects that extend Kubernetes. Based on kubeadm and DIND (Docker in\nDocker).\n\nSupports both local workflows and workflows utilizing powerful remote\nmachines/cloud instances for building Kubernetes, starting test\nclusters and running e2e tests.\n\nIf you're an application developer, you may be better off with\n[Minikube](https://github.com/kubernetes/minikube) because it's more\nmature and less dependent on the local environment, but if you're\nfeeling adventurous you may give `kubeadm-dind-cluster` a try, too. In\nparticular you can run `kubeadm-dind-cluster` in CI environment such\nas Travis without having issues with nested virtualization.\n\n## Requirements\nDocker 1.12+ is recommended. If you're not using one of the\npreconfigured scripts (see below) and not building from source, it's\nbetter to have `kubectl` executable in your path matching the\nversion of k8s binaries you're using (i.e. for example better don't\nuse `kubectl` 1.13.x with `hyperkube` 1.12.x). As an alternative,\nyou can set `DOWNLOAD_KUBECTL` to a non-empty string in your\nconfig.sh so `kubeadm-dind-cluster` will download it for you.\n\n`kubeadm-dind-cluster` supports k8s versions 1.12.x through 1.15.x.\n\n**As of now, running `kubeadm-dind-cluster` on Docker with `btrfs`\nstorage driver is not supported.**\n\nThe problems include inability to properly clean up DIND volumes due\nto a [docker bug](https://github.com/docker/docker/issues/9939) which\nis not really fixed and, more importantly, a\n[kubelet problem](https://github.com/kubernetes/kubernetes/issues/38337).\nIf you want to run `kubeadm-dind-cluster` on btrfs anyway, set\n`RUN_ON_BTRFS_ANYWAY` environment variable to a non-empty value.\n\nBy default `kubeadm-dind-cluster` uses dockerized builds, so no Go\ninstallation is necessary even if you're building Kubernetes from\nsource. If you want you can overridde this behavior by setting\n`KUBEADM_DIND_LOCAL` to a non-empty value in [config.sh](config.sh).\n\n### Mac OS X considerations\n\nWhen building Kubernetes from source on Mac OS X, it should be\npossible to build `kubectl` locally, i.e. `make WHAT=cmd/kubectl` must\nwork.\n\nNOTE: Docker on Mac OS X, at the time of this writing, does not support\nIPv6 and thus clusters cannot be formed using IPv6 addresses.\n\n## Using preconfigured scripts\n`kubeadm-dind-cluster` currently provides preconfigured scripts for\nKubernetes versions 1.12 through 1.15 published as part of GitHub\nreleases. Each preconfigured script is pinned to the corresponding\nimage tag and SHA256 digest, so it will not be broken by changes\nin kubeadm-dind-cluster master branch.\n\nThe preconfigured scripts are convenient for use with projects that\nextend or use Kubernetes. For example, you can start Kubernetes 1.14\nlike this:\n\n```shell\n$ wget -O dind-cluster.sh https://github.com/kubernetes-sigs/kubeadm-dind-cluster/releases/download/v0.2.0/dind-cluster-v1.14.sh \n$ chmod +x dind-cluster.sh\n\n$ # start the cluster\n$ ./dind-cluster.sh up\n\n$ # add kubectl directory to PATH\n$ export PATH=\"$HOME/.kubeadm-dind-cluster:$PATH\"\n\n$ kubectl get nodes\nNAME          STATUS    ROLES     AGE       VERSION\nkube-master   Ready     master    4m        v1.14.0\nkube-node-1   Ready     <none>    2m        v1.14.0\nkube-node-2   Ready     <none>    2m        v1.14.0\n\n$ # k8s dashboard available at http://localhost:<DOCKER_EXPOSED_PORT>/api/v1/namespaces/kube-system/services/kubernetes-dashboard:/proxy. See your console for the URL.\n\n$ # restart the cluster, this should happen much quicker than initial startup\n$ ./dind-cluster.sh up\n\n$ # stop the cluster\n$ ./dind-cluster.sh down\n\n$ # remove DIND containers and volumes\n$ ./dind-cluster.sh clean\n```\n\nReplace 1.14 with 1.13 or 1.12 to use older Kubernetes versions.\n**Important note:** you need to do `./dind-cluster.sh clean` when\nyou switch between Kubernetes versions (but no need to do this between\nrebuilds if you use `BUILD_HYPERKUBE=y` like described below).\n\n## Using with Kubernetes source\n```shell\n$ git clone https://github.com/kubernetes-sigs/kubeadm-dind-cluster.git ~/dind\n\n$ cd ~/work/kubernetes/src/k8s.io/kubernetes\n\n$ export BUILD_KUBEADM=y\n$ export BUILD_HYPERKUBE=y\n\n$ # build binaries+images and start the cluster\n$ ~/dind/dind-cluster.sh up\n\n$ kubectl get nodes\nNAME                      STATUS         AGE\nkube-master   Ready,master   1m\nkube-node-1   Ready          34s\nkube-node-2   Ready          34s\n\n$ # k8s dashboard available at http://localhost:8080/ui\n\n$ # run conformance tests\n$ ~/dind/dind-cluster.sh e2e\n\n$ # restart the cluster rebuilding\n$ ~/dind/dind-cluster.sh up\n\n$ # run particular e2e test based on substring\n$ ~/dind/dind-cluster.sh e2e \"existing RC\"\n\n$ # shut down the cluster\n$ ~/dind/dind-cluster.sh down\n```\n\nThe first `dind/dind-cluster.sh up` invocation can be slow because it\nneeds to build the base image and Kubernetes binaries. Subsequent\ninvocations are much faster.\n\n## Controlling network usage\nKubeadm-dind-cluster uses several networks for operation, and allows\nthe user to customize the networks used. Check your network assignments\nfor your setup, and adjust things, if there are conflicts. This section\nwill describe how to adjust settings.\n\nNOTE: Docker will define networks for bridges, which kubeadm-dind-cluster\ntries to avoid by default, but based on your setup, you may need to choose\ndifferent subnets. Typically, docker uses 172.17.0.0/16, 172.18.0.0/16,...\n\n### Management network\nFor the management network, the user can set MGMT_CIDRS to a string\nrepresenting the CIDR to use for the network. This is used in conjunction\nwith the CLUSTER_ID, when creating multple clusters. If single cluster,\nthe cluster ID will be zero.\n\nFor IPv4, this must be a /24 and the third octet is reserved for the\nmulti-cluster number (0 when in single-cluster mode). For example,\nuse 10.192.0.0/24, for an IPv4 cluster that will have nodes 10.192.0.2,\n10.192.0.3, etc. A cluster with ID \"5\" would have nodes 10.192.5.2,\n10.192.5.3, etc.\n\nFor IPv6, the CIDR must have room for a hextet to be reserved for the\nmulti-cluster number. For example, fd00:10:20::/64 would be for an IPv6\ncluster with ID \"10\" (considered in hex) with nodes fd00:10:20:10::2,\nfd00:10:20:10::3, etc. If the cluster ID was \"0\" (single cluster mode),\nthe nodes would be fd00:10:20:0::2, fd00:10:20:0::3, etc.\n\nThe defaults are 10.192.0.0/24 for IPv4, and fd00:20::/64 for IPv6.\n\nFor dual-stack mode, a comma separated list with IPv4 and IPv6 can be\nspecified. Any omitted CIDR will use the default value above, based on\nthe IP mode.\n\n### Service network\nThe service network CIDR, can be specified by SERVICE_CIDR. For IPv4, the\ndefault is 10.96.0.0/12. For IPv6, the default is fd00:30::/110.\n\n### Pod network\nFor the pod network the POD_NETWORK_CIDR environment variable can be set\nto specify the pod sub-networks. One subnet will be created for each node\nin the cluster.\n\nFor IPv4, the value must be a /16, of which this will be split into multiple\n/24 subnets. The master node will set the third octet to 2, and the minion\nnodes will set the third octet to 3+. For example, with 10.244.0.0/16, pods\non the master node will be 10.244.2.X, on minion kube-node-1 will be 10.244.3.Y,\non minion kube-node-2 will be 10.244.4.Z, etc.\n\nFor IPv6, the CIDR will again be split into subnets, eigth bits smaller. For\nexample, with fd00:10:20:30::/72, the master node would have a CIDR of\nfd00:10:20:30:2::/80 with pods fd00:10:20:30:2::X. If the POD_NETWORK_CIDR,\ninstead was fd00:10:20:30::/64, the master node woudl have a CIDR of\nfd00:10:20:30:0200::/72, and pods would be fd00:10:20:30:0200::X.\n\nThe defaults are 10.244.0.0/16 for IPv4, and fd00:40::/72 for IPv6.\n\nFor dual-stack mode, a comma separated list with IPv4 and IPv6 CIDR can be\nspecified. Any omitted CIDR will use the default value above, based on the\nIP mode.\n\n## Kube-router\nInstead of using kube-proxy and static routes (with bridge CNI plugin),\nkube-router can be used. Kube-router uses the bridge plugin, but uses\nIPVS kernel module, instead of iptables. This results in better performance\nand scalability. Kube-router also uses iBGP, so that static routes are not\nrequired for pods to communicate across nodes.\n\nTo use kube-router, set the CNI_PLUGIN environment variable to \"kube-router\".\n\nNOTE: Currently pinning kube-router to v0.2.0, because of issue seen with\ncleanup, when using newer (latest) kube-router.\n\nNOTE: This has only been tested with Kubernetes 1.11, and currently fails\nwhen using Kuberentes 1.12+\n\n## IPv6 Mode\nTo run Kubernetes in IPv6 only mode, set the environment variable IP_MODE\nto \"ipv6\". There are additional customizations that you can make for IPv6,\nto set the prefix used for DNS64, subnet prefix to use for DinD, and\nthe service subnet CIDR (among other settings - see dind-cluster.sh):\n\n```shell\nexport EMBBEDDED_CONFIG=y\nexport DNS64_PREFIX=fd00:77:64:ff9b::\nexport DIND_SUBNET=fd00:77::\nexport SERVICE_CIDR=fd00:77:30::/110\nexport NAT64_V4_SUBNET_PREFIX=172.20\n```\n\nNOTE: The DNS64 and NAT64 containers that are created on the host, persist\nbeyond the `down` operation. This is to reduce startup time, if doing multiple\ndown/up cycles. When `clean` is done, these containers are removed.\n\nNOTE: In multi-cluster, there will be DNS and NAT64 containers for each cluster,\nwith thier names including the cluster suffix (e.g. bind9-cluster-50).\n\nNOTE: At this time, there is no isolation between clusters. Nodes on one cluster\ncan ping nodes on another cluster (appears to be isolation iptables rules, instead\nof ip6tables rules).\n\nNOTE: The IPv4 mapping subnet used by NAT64, can be overridden from the default of\n172.18.0.0/16, by specifying the first two octets in NAT64_V4_SUBNET_PREFIX (you\ncannot change the size). This prefix must be within the 10.0.0.0/8 or 172.16.0.0/12\nprivate network ranges. Be aware, that, in a multi-cluster setup, the cluster ID,\nwhich defaults to zero, will be added to the second octet of the prefix. You must\nensure that the resulting prefix is still within the private network's range. For\nexample, if CLUSTER_ID=\"10\", the default NAT64_V4_SUBNET_PREFIX will be\n\"172.28\", forming a subnet 172.28.0.0/16.\n\nNOTE: If you use `kube-router` for networking, IPv6 is not supported, as of\nJuly 2018.\n\n## Configuration\nYou may edit `config.sh` to override default settings. See comments in\n[the file](config.sh) for more info. In particular, you can specify\nCNI plugin to use via `CNI_PLUGIN` variable (`bridge`, `ptp`,\n`flannel`, `calico`, `calico-kdd`, `weave`, `kube-router`).\n\nYou can also edit the version appropriate kubeadm.conf.#.##.tmpl file\nin the image/ directory, to customize how KubeAdm works. This will require\nthat you build a new image using build/build-local.sh and then setting this\nenvironment variable:\n\n```\nexport DIND_IMAGE=mirantis/kubeadm-dind-cluster:local\n```\n\nNote: the DIND_IMAGE environment variable will work only with `./dind-cluster.sh` script.  \nIt will not work with preconfigured scripts.\n\nJust keep in mind, there are some parameters in double curly-brackets that\nare used to substitue settings, based on other dind-cluster.sh config settings.\n\n## Remote Docker / GCE\nIt's possible to build Kubernetes on a remote machine running Docker.\nkubeadm-dind-cluster can consume binaries directly from the build\ndata container without copying them back to developer's machine.\nAn example utilizing GCE instance is provided in [gce-setup.sh](gce-setup.sh).\nYou may try running it using `source` (`.`) so that docker-machine\nshell environment is preserved, e.g.\n```shell\n. gce-setup.sh\n```\nThe example is based on sample commands from\n[build/README.md](https://github.com/kubernetes/kubernetes/blob/master/build/README.md#really-remote-docker-engine)\nin Kubernetes source.\n\nWhen using a remote machine, you need to use ssh port forwarding\nto forward `KUBE_RSYNC_PORT` and `APISERVER_PORT`.\n\nIf you do not explicitly set `APISERVER_PORT`, that port will be randomized. To\nhelp with that `./dind-cluster.sh` will call a user-defined executable as soon\nas the port is allocated and the kubectl context is set up. For that to happen\nyou need to set `DIND_PORT_FORWARDER` to a path to an executable, which will be\ncalled with the allocated port as a first argument. If you keep\n`DIND_PORT_FORWARDER` empty, that mechanism will not kick in.\n\n## Dumping cluster state\n\nIn case of CI environment such as Travis CI or Circle CI, it's often\ndesirable to get detailed cluster state for a failed job. Moreover, in case\nof e.g. Travis CI there's no way to store the artefacts without using\nan external service such as Amazon S3. Because of this,\nkubeadm-dind-cluster supports dumping cluster state as a text block\nthat can be later split into individual files. For cases where there\nare limits on the log size (e.g. 4 Mb log limit in Travis CI) it's also\npossible to dump the lzma-compressed text block using base64 encoding.\n\nThe following commands can be used to work with cluster state dumps:\n* `./dind-cluster.sh dump` dumps the cluster state as a text block\n* `./dind-cluster.sh dump64` dumps the cluster state as a base64 blob\n* `./dind-cluster.sh split-dump` splits the text block into individual\n  files using `@@@ filename @@@` markers which are generated by\n  `dump`.  The output is stored in `cluster-dump/` subdirectory of the\n  current directory.\n* `./dind-cluster.sh split-dump64` splits the base64 blob into\n  separate files.  The blob has start and end markers so it can be\n  extracted automatically from a build job log. The output is stored\n  in `cluster-dump/` subdirectory of the current directory.\n\nAll of the above commands work with 'fixed' scripts, too.\nkubeadm-dind-cluster's own Travis CI jobs dump base64 blobs in case of\nfailure. Such blocks can be then extracted directly from the output of\n`travis` command line utility, e.g.\n\n```shell\ntravis logs NNN.N | ./dind-cluster.sh split-dump64\n```\n\nThe following information is currently stored in the dump:\n* status and logs for the following systemd units on each DIND node, if the exist:\n  `kubelet.service`, `dindnet.service`, `criproxy.service` and\n  `dockershim.service` (the latter two are used by [CRI Proxy](https://github.com/Mirantis/criproxy))\n* `ps auxww`, `docker ps -a`, `ip a` and `ip r` output for each DIND node\n* the logs of all the containers of each pod in the cluster\n* the output of `kubectl get all --all-namespaces -o wide`,\n  `kubectl describe all --all-namespaces` and `kubectl get nodes -o wide`\n\n## Running multiple clusters in parallel\n\n`dind-cluster.sh` can be used to create and manage multiple dind clusters.\n\nNormally, default names will be used for docker resources and the kubectl context.\nFor example, `kube-master` (container name), `kubeadm-dind-kube-master` (volume name),\n`dind` (context name), etc. Likewise, the management, pod, and service IPs will use\nthe defaults or user specified values (via environment variables). This would occur\nwhen CLUSTER_ID is not set, or set to \"0\".\n\nFor each additional cluster, the user can set a unique CLUSTER_ID to a string that\nrepresents a number from 1..254. The number will be used on all management network IP\naddresses.\n\nFor IPv4, the cluster ID will be used as the third octet of the management address\n(whether default or user specified). For example, with cluster ID \"10\", the default\nmanagement network CIDR will be 10.192.10.0/24. For IPv6, the cluster ID will be\nplaced as the hextet before the double colon, for the management CIDR. For example,\na management ntwork CIDR of fd00:20::/64 will become fd00:20:2::/64, for a cluster\nID of '2'.\n\nNOTE: The cluster ID can be limited in some cases. For IPv6 mode, the cluster ID is\nalso used in the NAT64 prefix, and that prifix must be within one of the RFC-1918\nprivate network ranges. If the 172.16.0.0/12 private network is used, the cluster ID\ncannot be more than 15 (and less, if a higher base prefix is specified by the\nNAT64_V4_SUBNET_PREFIX, like the default 172.18, which would allow cluster IDs up to\n13).\n\nNote: If the MGMT_CIDR (or legacy DIND_SUBNET/DIND_SUBNET_SIZE) environment variables\nare set for the management network, they must be able to accommodate the cluster ID\ninjection.\n\nIn addition to the management network, the resource names will have the suffix\n\"-cluster-#\", where # is the CLUSTER_ID. The context for kubectl will be \"dind-cluster-#\".\n\nFor legacy support (or if a user wants a custom cluster name), setting the DIND_LABEL\nwill create a resource suffix \"-{DIND_LABEL}-#\", where # is the cluster ID. If no\ncluster ID is specified, as would be for backwards-compatibility, or it is zero, the\nresource names will just use the DIND_LABEL, and a pseudo-random number from 1..13 will\nbe used for the cluster ID to be applied to the management network, and in case of IPv6,\nthe NAT64 V4 mapping subnet prefix (hence the limitation).\n\nExample usage:\n\n```shell\n$ # creates a 'default' cluster\n$ ./dind-cluster up\n$ # creates a cluster with an ID of 10\n$ CLUSTER_ID=\"10\" ./dind-cluster.sh up\n$ # creates an additional cluster with the label 'foo' and random cluster ID assigned\n$ DIND_LABEL=\"foo\" ./dind-cluster.sh up\n```\n\nExample containers:\n\n```shell\n$ docker ps  --format '{{ .ID }} - {{ .Names }} -- {{ .Labels }}'\n\n8178227e567c - kube-node-2 -- mirantis.kubeadm_dind_cluster=1,mirantis.kubeadm_dind_cluster_runtime=\n6ea1822303bf - kube-node-1 -- mirantis.kubeadm_dind_cluster=1,mirantis.kubeadm_dind_cluster_runtime=\n7bc6b28be0b4 - kube-master -- mirantis.kubeadm_dind_cluster=1,mirantis.kubeadm_dind_cluster_runtime=\n\nce3fa6eaecfe - kube-node-2-cluster-10 -- cluster-10=,mirantis.kubeadm_dind_cluster=1\n12c18cf3edb7 - kube-node-1-cluster-10 -- cluster-10=,mirantis.kubeadm_dind_cluster=1\n963a6e7c1e40 - kube-master-cluster-10 -- cluster-10=,mirantis.kubeadm_dind_cluster=1\n\nb05926f06642 - kube-node-2-foo -- mirantis.kubeadm_dind_cluster=1,foo=\nddb961f1cc95 - kube-node-1-foo -- mirantis.kubeadm_dind_cluster=1,foo=\n2efc46f9dafd - kube-master-foo -- foo=,mirantis.kubeadm_dind_cluster=1\n```\n\nExample `kubectl` access:\n\n```shell\n$ # to access the 'default' cluster\n$ kubectl --context dind get all\n$ # to access the additional clusters\n$ kubectl --context dind-cluster-10 get all\n$ kubectl --context dind-foo get all\n```\n\n## Dual-stack Operation\nBy setting the `IP_MODE` environment variable to `dual-stack`, the cluster\ncreated will be in dual-stack mode. This means there will be an IPv4 and\nIPv6 address for pods (pod net) and nodes (mgmt net). The service network\nwill still be single mode, based on the CIDR used (default is IPv6 mode\nwith fd00:30::/110).\n\nThe MGMT_CIDRS and POD_NETWORK_CIDR environment variables can be used to\ncustomize the management and pod networks, respectively.\n\nFor this mode, static routes will be created on each node, for both IPv4\nand IPv6, to allow pods to communicate across nodes.\n\n### Limitations\nDual-stack mode for k-d-c is only available when using the bridge or PTP\nCNI plugins.\n\nThe initial version will not be using DNS64/NAT64, meaning that the cluster\nmust have access to the outside via IPv6 (or use an external DNS64/NAT64).\nThis implies that it will not work, out of the box, with GCE, which provides\nonly IPv4 access to the outside world.\n\nThe functionality of the cluster in dual-stack mode, depends on the\nimplementation of the dual-stack KEP. As of this commit, implementation\nof the KEP is only beginning, so some things will not work yet. Consider\nthis commit as support for a WIP.\n\nOne known current limitation is that the service network must use the IPv4\nfamily, as currently IPv4 is preferred, when both are available and logic\ndoesn't force famliy to IPv6. As a result, endpoints are still IPv4, when\nservice network is IPv6 (and doesn't work correctly).\n\n## Motivation\n`hack/local-up-cluster.sh` is widely used for k8s development. It has\na couple of serious issues though. First of all, it only supports\nsingle node clusters, which means that it's hard to use it to work on\ne.g. scheduler-related issues and e2e tests that require several nodes\ncan't be run. Another problem is that it has little resemblance to\nreal clusters.\n\nThere's also k8s vagrant provider, but it's quite slow. Besides,\n`cluster/` directory in k8s source is now considered deprecated.\n\nAnother widely suggested solution for development clusters is\n[minikube](https://github.com/kubernetes/minikube), but currently it's\nnot very well suited for development of Kubernetes itself. Besides,\nit's currently only supports single node, too, unless used with\nadditional DIND layer like [nkube](https://github.com/marun/nkube).\n\n[kubernetes-dind-cluster](https://github.com/sttts/kubernetes-dind-cluster)\nis very nice & useful but uses a custom method of cluster setup\n(same as 2nd problem with local-up-cluster).\n\nThere's also sometimes a need to use a powerful remote machine or a\ncloud instance to build and test Kubernetes. Having Docker as the only\nrequirement for such machine would be nice. Builds and unit tests are\nalready covered by\n[jbeda's work](https://github.com/kubernetes/kubernetes/pull/30787) on\ndockerized builds, but being able to quickly start remote test\nclusters and run e2e tests is also important.\n\nkubeadm-dind-cluster uses kubeadm to create a cluster consisting of\ndocker containers instead of VMs. That's somewhat of a compromise but\nallows one to (re)start clusters quickly which is quite important when\nmaking changes to k8s source.\n\nMoreover, some projects that extend Kubernetes such as\n[Virtlet](https://github.com/Mirantis/virtlet) need a way to start\nkubernetes cluster quickly in CI environment without involving nested\nvirtulization. Current kubeadm-dind-cluster version provides means to\ndo this without the need to build Kubernetes locally.\n\n## Additional notes\nAt the moment, all non-serial `[Conformance]` e2e tests pass for\nclusters created by kubeadm-dind-cluster. `[Serial]...[Conformance]` tests\ncurrently have some issues. You may still try running them though:\n```\n$ dind/dind-cluster.sh e2e-serial\n```\n\nWhen restoring a cluster (either using `restore` or by doing `down` and\nthen `up`), be sure to use the same IP mode. The DinD network that is\ncreated as part of the `up` operation, will persist after a `down`\ncommand and will not have the correct configuration, if the IP mode has\nchanged.\n\n## Contributing to & Testing `kubeadm-dind-cluster`\n\n### Test setup\n\nThere are currently two CI systems in place which automatically test PRs to\nkubeadm-dind-cluster:\n- [CircleCI](https://circleci.com/gh/kubernetes-sigs/kubeadm-dind-cluster)\n- [TravisCI](https://travis-ci.org/kubernetes-sigs/kubeadm-dind-cluster)\n\n#### CircleCI, `./.circleci/config.yml`\n\nAll new tests should run on CircleCI, thus need to be configured in\n`./.circleci/config.yml`.\n\nThere are some tests completely implemented in `./.circleci/config.yml`. There\nare also other tests which are implemented in a script in `./test/` and then\nCircleCI just calls that script. This makes it easier to run a CircleCI test\ncase also locally, by just calling the script:\n\n```shell\n$ DIND_ALLOW_AAAA_USE='true' TEST_K8S_VER='v1.10' ./test/test-ipv6-only.sh\n```\n\nCircleCI config can be re-generated using `build/update-test-matrix.sh`\n\n#### TravisCI, `./test.sh`\n\nThere are some tests in `./test.sh`, those will run on TravisCI.\nNew tests should be added to CircleCI and not to `./test.sh` / the TravisCI\nsetup.\n\nTo run a specific test from `./test.sh` use the following mechanism to discover\nand run a specific test:\n\n```shell\n# See all test cases:\n$ grep 'function test-case-' ./test.sh\n# run a specific test:\n$ TEST_CASE=<test-name> ./test.sh\n```\n\n### IPv6 tests\n\nAll of the IPv6 related tests currently run on\n[CircleCI](https://circleci.com/gh/kubernetes-sigs/kubeadm-dind-cluster).\nThose tests run with the `machine executor` (and not as docker containers), so\nthat we have IPv6 available for the test cases. Note, that while internal IPv6\nis configured, external IPv6 is not available.\n\nThere are two slightly different kind of tests which run for all version\nstarting from `v1.12`:\n\n#### `TEST_K8S_VER='1.x' ./test/test-ipv6-only.sh`\n\nThe cluster is setup with IPv6 support. The tests check if the IP resolution on\nnodes and pods works as expected. DNS64 is always used, and external IPv6\ntraffic goes throught NAT64. Both NAT64 and DNS64 are automatically deployed\nas docker containers, alongside the `kube-master` and `kube-node-X` containers\nrunning in the outer docker daemon.\n\nThese IPv6 tests do not depend on the host machine of the\nouter docker daemon actually having external IPv6 connectivity.\n\nThe tests cover, on pods, nodes and host:\n* IP address lookups\n* internal `ping6`s (pod to pod on different nodes)\n* external `ping6`s (to IPv4-only and IPv6-enabled targets)\n\n#### `TEST_K8S_VER='1.x' DIND_ALLOW_AAAA_USE=true ./test/test-ipv6-only.sh`\n\nThose tests use the public AAAA records when available. Specifically for hosts\nwhich have a AAAA record, the IP address is used, traffic to those hosts does\nnot get routed through NAT64. In that case the host running the outer docker\ndaemon would need to have external IPv6 available to actually communicate with\nexternal IPv6 hosts. Therefore (because none of our CI systems can provide\nexternal IPv6) we skip the external ping tests and instead print a warning\nabout external IPv6 not being available. If a host does not have a public AAAA\nrecord, the IPv4 address is used, embedded into a synthesized IPv6 address, and\nrouted through NAT64.\n\nIn summary:\nThe same test suites as above run, except for external ping tests which are\nintentionally disabled. Internal ping tests still run.\n\n## Related work\n\n* kubeadm-dind-cluster was initially derived from\n  [kubernetes-dind-cluster](https://github.com/sttts/kubernetes-dind-cluster),\n  although as of now the code was completely rewritten.\n  kubernetes-dind-cluster is somewhat faster but uses less standard\n  way of k8s deployment. It also doesn't include support for consuming\n  binaries from remote dockerized builds.\n* [kubeadm-ci-dind](https://github.com/errordeveloper/kubeadm-ci-dind),\n  [kubeadm-ci-packager](https://github.com/errordeveloper/kubeadm-ci-packager) and\n  [kubeadm-ci-tester](https://github.com/errordeveloper/kubeadm-ci-tester).\n  These projects are similar to kubeadm-dind-cluster but are intended primarily for CI.\n  They include packaging step which is too slow for the purpose of having\n  convenient k8s \"playground\". kubeadm-dind-cluster uses Docker images\n  from `kubeadm-ci-dind`.\n* [nkube](https://github.com/marun/nkube) starts\n  Kubernetes-in-Kubernetes clusters.\n"
        },
        {
          "name": "SECURITY_CONTACTS",
          "type": "blob",
          "size": 0.5859375,
          "content": "# Defined below are the security contacts for this repo.\n#\n# They are the contact point for the Product Security Team to reach out\n# to for triaging and handling of incoming issues.\n#\n# The below names agree to abide by the\n# [Embargo Policy](https://github.com/kubernetes/sig-release/blob/master/security-release-process-documentation/security-release-process.md#embargo-policy)\n# and will be removed and replaced if they violate that agreement.\n#\n# DO NOT REPORT SECURITY VULNERABILITIES DIRECTLY TO THESE NAMES, FOLLOW THE\n# INSTRUCTIONS AT https://kubernetes.io/security/\n\npigmej\nivan4th\nlukaszo\n"
        },
        {
          "name": "architecture.md",
          "type": "blob",
          "size": 1.763671875,
          "content": "# Architecture of kubeadm-dind-cluster\n\nBase image:\n\n* contains systemd, docker and helper scripts\n* contains saved+archived pre-pulled images as .tar\n* contains hypokube image in the same .tar as pre-pulled images\n* used as the base for prebuilt images\n* when used directly expects prebuilt binaries\n  * specified either by url\n  * or as [build] to pull them from build containers\n\nImportant points:\n* there's separate volume mounted at /k8s holding hyperkube and\n  kubeadm binaries which is created during initial cluster startup and\n  is updated when k8s is rebuilt from source (we can't just use k8s\n  build data container in the latter case because it may be removed at\n  any moment).\n* kubectl is a symlink to hyperkube binary in that volume\n* loading pre-pulled images is skipped if earlier /dind exists\n* when kubeadm is started, cached docker directories may be reused\n  but filesystem differences are not applied\n* kubeadm is executed\n  * upon the first cluster startup on this particular docker\n  * after ./dind-cluster.sh clean\n  * when k8s binaries are rebuilt\n\nHow binary injection works in `wrapkubeadm`:\n\n1. Start docker daemon\n1. Purge any remaining containers\n1. Remove saved filesystem diffs for the current node\n1. Get a hash of hyperkube binary\n1. Check if hypokube image with tag = hyperkube hash exists\n1. If it doesn't exist, remove any non-base hypokube images and build new one with binaries\n1. Enable kubelet service and start kubeadm\n1. Patch kube-proxy daemonset so it\n   * disables conntrack\n   * mounts /hyperkube from hostPath /k8s/hyperkube\n1. Patch apiserver static pod so it\n   * has necessary feature gates\n   * mounts /hyperkube from hostPath /k8s/hyperkube\n1. Patch controller-manager and scheduler static pods so they mount\n   /hyperkube from hostPath /k8s/hyperkube\n"
        },
        {
          "name": "build",
          "type": "tree",
          "content": null
        },
        {
          "name": "code-of-conduct.md",
          "type": "blob",
          "size": 0.14453125,
          "content": "# Kubernetes Community Code of Conduct\n\nPlease refer to our [Kubernetes Community Code of Conduct](https://git.k8s.io/community/code-of-conduct.md)\n"
        },
        {
          "name": "config.sh",
          "type": "blob",
          "size": 3.9423828125,
          "content": "if [[ ${IP_MODE} = \"ipv4\" ]]; then\n    # DIND_SUBNET=\"10.192.0.0\"\n    # DIND_SUBNET_SIZE=16\n    :\nelse\n    # DinD subnet (expected to be /64)\n    DIND_SUBNET=\"${DIND_SUBNET:-fd00:10::}\"\nfi\n\n# Apiserver port\n# APISERVER_PORT=${APISERVER_PORT:-8080}\n\n# Number of nodes. 0 nodes means just one master node.\n# In case of NUM_NODES=0 'node-role.kubernetes.io/master' taint is removed\n# from the master node.\nNUM_NODES=${NUM_NODES:-2}\n\n# Use non-dockerized build\n# KUBEADM_DIND_LOCAL=\n\n# Image name base for k-d-c\nDIND_IMAGE_BASE=\"${DIND_IMAGE_BASE:-mirantis/kubeadm-dind-cluster}\"\n\n# Specify DIND image to use. mirantis/kubeadm-dind-cluster:local\n# is the one that is built locally using build/build-local.sh\nDIND_IMAGE=\"${DIND_IMAGE:-${DIND_IMAGE_BASE}:local}\"\n\n# Set DOWNLOAD_KUBECTL to non-empty string to download\n# kubectl. Should not be used with BUILD_KUBEADM / BUILD_HYPERKUBE\n# DOWNLOAD_KUBECTL=y\n\n# Set to non-empty string to enable building kubeadm\n# BUILD_KUBEADM=y\n\n# Set to non-empty string to enable building hyperkube\n# BUILD_HYPERKUBE=y\n\n# Use pre-built Kubernetes binaries (hyperkube and kubeadm) on the\n# host, located in the specified directory. When this environment\n# variable is set, BUILD_KUBEADM and BUILD_HYPERKUBE will be ignored.\n# This will not work with a remote docker engine (e.g. started via\n# docker-machine on GCE) unless the file is placed on the target machine.\nDIND_K8S_BIN_DIR=\"${DIND_K8S_BIN_DIR:-}\"\n\n# Set custom URL for Dashboard yaml file\n# DASHBOARD_URL=\"${DASHBOARD_URL:-https://rawgit.com/kubernetes/dashboard/bfab10151f012d1acc5dfb1979f3172e2400aa3c/src/deploy/kubernetes-dashboard.yaml}\"\n# or for versions >= 1.15,\n# DASHBOARD_URL=\"${DASHBOARD_URL:-https://rawgit.com/kubernetes/dashboard/v1.10.1/src/deploy/recommended/kubernetes-dashboard.yaml}\"\n\n# CNI plugin to use (bridge, flannel, calico, calico-kdd, weave). Defaults to 'bridge'\n# In case of 'bridge' plugin, additional hacks are employed to bridge\n# DIND containers together.\nCNI_PLUGIN=\"${CNI_PLUGIN:-bridge}\"\n\n# When using Calico with Kubernetes as the datastore (calico-kdd) your\n# controller manager needs to be started with `--cluster-cidr=192.168.0.0/16`.\n# More information here: http://docs.projectcalico.org/v2.3/getting-started/kubernetes/installation/hosted/kubernetes-datastore/\n# POD_NETWORK_CIDR=\"192.168.0.0/16\"\n\n# Set SKIP_SNAPSHOT to non-empty string to skip making the snapshot.\n# This may be useful for CI environment where the cluster is never\n# restarted after it's created.\n# SKIP_SNAPSHOT=y\n\n# Disable parallel running of e2e tests. Use this if you use a resource\n# constrained machine for e2e tests and get some flakes.\n# DIND_NO_PARALLEL_E2E=y\n\n# Any options to be passed to the docker run both on init and reup.\n# By default it's empty\n# MASTER_EXTRA_OPTS=\"  \"\n\n# Define which DNS service to run\n# possible values are coredns (default) and kube-dns\nDNS_SERVICE=\"${DNS_SERVICE:-coredns}\"\n\n# Feature Gates\n# This value will be passed to kube-apiserver, kube-controller-manager and kube-scheduler\n# you can set special value 'none' not to set any feature gates on them.\n# FEATURE_GATES=\"\"\n\n# Kubelet Feature Gates\n# you can set special value 'none' not to set any feature gates on kubelet.\n# KUBELET_FEATURE_GATES=\"\"\n\n# You can configure extra component args for kube-apiservers\n# APISERVER_underscored_option_name will be converted --hyphenated-option-name\n# e.g. APISERVER_admission_control=xxx,yyy -> --admission-control=xxx,yyy\n# APISERVER_xxx_yyy=zzz\n\n# Extra component args for kube-controller-manager\n# CONTROLLER_MANAGER_underscored_option_name will be converted --hyphenated-option-name\n# CONTROLLER_MANAGER_xxx=yyy\n\n# Extra component args for kube-scheduler\n# SCHEDULER_underscored_option_name will be converted --hyphenated-option-name\n# SCHEDULER_xxx=yyy\n\n# Enable Ceph support. DANGER: you must take care of unmapping all\n# the RBDs (e.g. by removing all the pods that use RBDs) before\n# stopping / restarting the cluster, or they'll get stuck possibly\n# blocking even system reboot.\n# ENABLE_CEPH=y\n"
        },
        {
          "name": "dind-cluster.sh",
          "type": "blob",
          "size": 82.01171875,
          "content": "#!/bin/bash\n# Copyright 2018 Mirantis\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\nset -o errexit\nset -o nounset\nset -o pipefail\nset -o errtrace\n\nif [ $(uname) = Darwin ]; then\n  readlinkf(){ perl -MCwd -e 'print Cwd::abs_path shift' \"$1\";}\nelse\n  readlinkf(){ readlink -f \"$1\"; }\nfi\nDIND_ROOT=\"$(cd $(dirname \"$(readlinkf \"${BASH_SOURCE}\")\"); pwd)\"\n\ndocker_info_output=\"$(docker info)\"\n\nRUN_ON_BTRFS_ANYWAY=\"${RUN_ON_BTRFS_ANYWAY:-}\"\nif [[ ! ${RUN_ON_BTRFS_ANYWAY} ]] && echo \"$docker_info_output\"| grep -q '^ *Storage Driver: btrfs'; then\n  echo \"ERROR: Docker is using btrfs storage driver which is unsupported by kubeadm-dind-cluster\" >&2\n  echo \"Please refer to the documentation for more info.\" >&2\n  echo \"Set RUN_ON_BTRFS_ANYWAY to non-empty string to continue anyway.\" >&2\n  exit 1\nfi\n\n# In case of linuxkit / moby linux, -v will not work so we can't\n# mount /lib/modules and /boot. Also we'll be using localhost\n# to access the apiserver.\nusing_linuxkit=\nif ! echo \"$docker_info_output\"|grep -s '^ *Operating System: .*Docker for Windows' > /dev/null 2>&1 ; then\n    if echo \"$docker_info_output\"|grep -s '^ *Kernel Version: .*-moby$' >/dev/null 2>&1 ||\n         echo \"$docker_info_output\"|grep -s '^ *Kernel Version: .*-linuxkit' > /dev/null 2>&1 ; then\n        using_linuxkit=1\n    fi\nfi\n\n# Determine when using Linux and docker daemon running locally\nusing_local_linuxdocker=\nif [[ $(uname) == Linux && -z ${DOCKER_HOST:-} ]]; then\n    using_local_linuxdocker=1\nfi\n\n#%CONFIG%\n\n# dind::localhost provides the local host IP based on the address family used for service subnet.\nfunction dind::localhost() {\n  if [[ ${SERVICE_NET_MODE} = \"ipv6\" ]]; then\n    echo '[::1]'\n  else\n    echo '127.0.0.1'\n  fi\n}\n\n# dind::family-for indicates whether the CIDR or IP is for an IPv6 or IPv4 family.\nfunction dind::family-for {\n    local addr=$1\n    if [[ \"$addr\" = *\":\"* ]]; then\n        echo \"ipv6\"\n    else\n        echo \"ipv4\"\n    fi\n}\n\n# dind::cluster-suffix builds a suffix used for resources, based on the DIND_LABEL.\nfunction dind::cluster-suffix {\n  if [ \"$DIND_LABEL\" != \"$DEFAULT_DIND_LABEL\" ]; then\n    echo \"-${DIND_LABEL}\"\n  else\n    echo ''\n  fi\n}\n\nfunction dind::net-name {\n  echo \"kubeadm-dind-net$( dind::cluster-suffix )\"\n}\n\n# dind::add-cluster will inject the cluster ID to the IP address. For IPv4, it is\n# assumed that the IP is a /24 with the third part of the address available for cluster ID.\n# For IPv6, it is assumed that there is enough space for the cluster to be added, and the\n# cluster ID will be added to the 16 bits before the double colon. For example:\n#\n# 10.192.0.0/24 => 10.192.5.0/24\n# fd00:77:20::/64 => fd00:77:20:5::/64\n#\n# This function is intended to be used for management networks.\n#\n# TODO: Validate that there is enough space for cluster ID.\n# TODO: For IPv6 could get fancy and handle case where cluster ID is placed in upper 8 bits of hextet\n# TODO: Consider if want to do /16 for IPv4 management subnet.\n#\nfunction dind::add-cluster {\n  local cidr=$1\n  local ip_mode=$2\n\n  if [[ ${ip_mode} = \"ipv4\" ]]; then\n      echo ${cidr} | sed \"s/^\\([0-9]*\\.[0-9]*\\.\\).*\\/24$/\\1${CLUSTER_ID}.0\\/24/\"\n  else  # IPv6\n      echo ${cidr} | sed \"s/^\\(.*\\)\\(\\:\\:\\/[0-9]*\\)$/\\1:${CLUSTER_ID}\\2/\"\n  fi\n}\n\n# dind::get-and-validate-cidrs takes a list of CIDRs and validates them based on the ip\n# mode, returning them. For IPv4 only and IPv6 only modes, only one CIDR is expected. For\n# dual stack, two CIDRS are expected. It verifies that the CIDRs are the right family and\n# will use the provided defaults, when CIDRs are missing. For dual-stack, the IPv4 address\n# will be first.\n#\n# For the management network, the cluster ID will be injected into the CIDR. Also, if no\n# MGMT_CIDRS value is specified, but the legacy DIND_SUBNET/DIND_SUBNET_SIZE is provided,\n# that will be used for the (first) CIDR.\n#\n# NOTE: It is expected that the CIDR size is /24 for IPv4 management networks.\n#\n# For pod CIDRs, the size will be increased by 8, to leave room for the node ID to be\n# injected into the address.\n#\n# NOTE: For IPv4, the pod size is expected to be /16 -> /24 in usage.\n#\nfunction dind::get-and-validate-cidrs {\n  IFS=', ' read -r -a cidrs <<< \"$1\"\n  IFS=', ' read -r -a defaults <<< \"$2\"\n  local is_mgmt=$3\n  case ${IP_MODE} in\n    ipv4)\n      case ${#cidrs[@]} in\n        0)\n          cidrs[0]=\"${defaults[0]}\"\n          ;;\n        1)\n          ;;\n        *)\n          echo \"ERROR! More than one CIDR provided '$1'\"\n          exit 1\n          ;;\n      esac\n      if [[ $( dind::family-for \"${cidrs[0]}\" ) != \"ipv4\" ]]; then\n        echo \"ERROR! CIDR must be IPv4 value\"\n        exit 1\n      fi\n      if [[ ${is_mgmt} = true ]]; then\n        cidrs[0]=\"$( dind::add-cluster \"${cidrs[0]}\" \"${IP_MODE}\" )\"\n      fi\n      ;;\n\n    ipv6)\n      case ${#cidrs[@]} in\n        0)\n          cidrs[0]=\"${defaults[0]}\"\n          ;;\n        1)\n          ;;\n        *)\n          echo \"ERROR! More than one CIDR provided '$1'\"\n          exit 1\n          ;;\n      esac\n      if [[ $( dind::family-for \"${cidrs[0]}\" ) != \"ipv6\" ]]; then\n        echo \"ERROR! CIDR must be IPv6 value\"\n        exit 1\n      fi\n      if [[ ${is_mgmt} = true ]]; then\n        cidrs[0]=\"$( dind::add-cluster \"${cidrs[0]}\" \"${IP_MODE}\" )\"\n      fi\n      ;;\n\n    dual-stack)\n      case ${#cidrs[@]} in\n        0)\n          cidrs[0]=\"${defaults[0]}\"\n          cidrs[1]=\"${defaults[1]}\"\n          ;;\n        1)\n          if [[ $( dind::family-for \"${cidrs[0]}\" ) = \"ipv6\" ]]; then\n            cidrs[1]=${cidrs[0]}\n            cidrs[0]=\"${defaults[0]}\"  # Assuming first default is a V4 address\n          else\n            cidrs[1]=\"${defaults[1]}\"\n          fi\n          ;;\n        2)\n          # Force ordering to have V4 address first\n          if [[ $( dind::family-for \"${cidrs[0]}\" ) = \"ipv6\" ]]; then\n            local temp=${cidrs[0]}\n            cidrs[0]=${cidrs[1]}\n            cidrs[1]=${temp}\n          fi\n          ;;\n        *)\n          echo \"ERROR! More than two CIDRs provided '$1'\"\n          exit 1\n          ;;\n      esac\n      local have_v4=\"\"\n      local have_v6=\"\"\n      for cidr in ${cidrs[@]}; do\n        if [[ $( dind::family-for \"${cidr}\" ) = \"ipv6\" ]]; then\n          have_v6=1\n        else\n          have_v4=1\n        fi\n      done\n      if [[ -z ${have_v4} ]]; then\n        echo \"ERROR! Missing IPv4 CIDR in '$1'\"\n        exit 1\n      fi\n      if [[ -z ${have_v6} ]]; then\n        echo \"ERROR! Missing IPv6 CIDR in '$1'\"\n        exit 1\n      fi\n      if [[ ${is_mgmt} = true ]]; then\n        cidrs[0]=\"$( dind::add-cluster \"${cidrs[0]}\" \"${IP_MODE}\" )\"\n        cidrs[1]=\"$( dind::add-cluster \"${cidrs[1]}\" \"${IP_MODE}\" )\"\n      fi\n      ;;\n  esac\n  echo \"${cidrs[@]}\"\n}\n\n# dind::make-ip-from-cidr  strips off the slash and size, and appends the\n# interface part to the prefix to form an IP. For IPv4, it strips off the\n# fourth part of the prefix, so that it can be replaced. It assumes that the\n# resulting prefix will be of sufficient size. It also will use hex for the\n# appended part for IPv6, and decimal for IPv4.\n#\n# fd00:20::/64 -> fd00:20::a\n# 10.96.0.0/12 -> 10.96.0.10\n#\nfunction dind::make-ip-from-cidr {\n  prefix=\"$(echo $1 | sed 's,/.*,,')\"\n  if [[ $( dind::family-for ${prefix} ) == \"ipv4\" ]]; then\n    printf \"%s%d\" $( echo ${prefix} | sed 's/0$//' ) $2\n  else\n    printf \"%s%x\" ${prefix} $2\n  fi\n}\n\n# dind::add-cluster-id-and-validate-nat64-prefix will modify the IPv4 mapping\n# subnet prefix, by adding the cluster ID (default 0) to the second octet.\n# It will produce an error, if the prefix is not in the 10.0.0.0/8 or\n# 172.16.0.0/12 private networks.\nfunction dind::add-cluster-id-and-validate-nat64-prefix {\n  local parts\n  IFS=\".\" read -a parts <<<${NAT64_V4_SUBNET_PREFIX}\n  if [[ ${#parts[@]} -ne 2 ]]; then\n    echo \"ERROR! NAT64_V4_SUBNET_PREFIX must be two octets (have '${NAT64_V4_SUBNET_PREFIX}')\"\n    exit 1\n  fi\n  (( parts[1]+=${CLUSTER_ID} ))\n  NAT64_V4_SUBNET_PREFIX=\"${parts[0]}.${parts[1]}\"\n  echo \"Added cluster ID offset (${CLUSTER_ID}) to NAT64_V4_SUBNET_PREFIX giving prefix '${NAT64_V4_SUBNET_PREFIX}'\"\n  if [[ ${parts[0]} -eq 10 ]]; then\n    if [[ ${parts[1]} > 253 ]]; then\n      echo \"ERROR! NAT64_V4_SUBNET_PREFIX is too large for 10.0.0.0/8 private net\"\n      exit 1\n    fi\n  elif [[ ${parts[0]} -eq 172 ]]; then\n    if [[ ${parts[1]} -lt 16 || ${parts[1]} -gt 31 ]]; then\n      echo \"ERROR! NAT64_V4_SUBNET_PREFIX is outside of range for 172.16.0.0/12 private net\"\n      exit 1\n    fi\n  else\n      echo \"ERROR! NAT64_V4_SUBNET_PREFIX is not in 10.0.0.0/8 or 172.16.0.0/12 private networks\"\n      exit 1\n  fi\n  echo \"Using NAT64 V4 mapping network prefix: ${NAT64_V4_SUBNET_PREFIX}\"\n}\n\n\n# START OF PROCESSING...\n\nIP_MODE=\"${IP_MODE:-ipv4}\"  # ipv4, ipv6, dual-stack\n# FUTURE: Once dual-stack support is released, check K8s version, and reject for older versions.\nif [[ ! ${EMBEDDED_CONFIG:-} ]]; then\n  source \"${DIND_ROOT}/config.sh\"\nfi\n\n# Multicluster support\n# Users can specify a cluster ID number from 1..254, represented as a string.\n# This will be used to form resource names \"cluster-#\", and will be used in the\n# management subnet to give unique networks for each cluster. If the cluster ID\n# is not specified, or zero, it will be considered a single cluster or the first\n# in the multi-cluster. This is the recommended usage.\n#\n# For legacy support, the user can specify DIND_LABEL, which will be used in the\n# resource names. If a cluster ID is specified (a hybrid case, where people are\n# using the new method, but want custom names), the resourse name will have the\n# suffix \"-#\" with the cluster ID. If no cluster ID is specified (for backward\n# compatibility), then the resource name will be just the DIND_LABEL, and a pseudo-\n# random number from 1..13 will be generated for the cluster ID to be used in\n# management network. The range is limited, because, in IPv6 mode, the cluster ID\n# is used in the NAT64 V4 subnet prefix, which must be in a private network.\n# The default is 172.18, so the cluster ID cannot be larger than 13 to guarantee\n# a valid value.\n#\n# To get around that limitation, you can set the cluster ID, in addition to the\n# DIND_LABEL, and optionally, change the NAT64_V4_SUBNET_PREFIX value.\n#\nDEFAULT_DIND_LABEL='mirantis.kubeadm_dind_cluster_runtime'\nif [[ -z ${DIND_LABEL+x} ]]; then  # No legacy DIND_LABEL set\n  if [[ -z ${CLUSTER_ID+x} ]]; then  # No cluster ID set\n    DIND_LABEL=${DEFAULT_DIND_LABEL}  # Single cluster mode\n    CLUSTER_ID=\"0\"\n  else  # Have cluster ID\n    if [[ ${CLUSTER_ID} = \"0\" ]]; then\n      DIND_LABEL=${DEFAULT_DIND_LABEL}  # Single cluster mode or first cluster of multi-cluster\n    else\n      DIND_LABEL=\"cluster-${CLUSTER_ID}\"  # Multi-cluster\n    fi\n  fi\nelse  # Legacy DIND_LABEL set for multi-cluster\n  if [[ -z ${CLUSTER_ID+x} ]]; then  # No cluster ID set, make one from 1..13, but don't use in resource names\n    CLUSTER_ID=\"$(( ($RANDOM % 12) + 1 ))\"\n  else\n    if [[ ${CLUSTER_ID} = \"0\" ]]; then\n      CLUSTER_ID=\"$(( ($RANDOM % 12) + 1 ))\"  # Force a pseudo-random cluster for additional legacy cluster\n    else\n      DIND_LABEL=\"${DIND_LABEL}-${CLUSTER_ID}\"\n    fi\n  fi\nfi\n\nCNI_PLUGIN=\"${CNI_PLUGIN:-bridge}\"\nGCE_HOSTED=\"${GCE_HOSTED:-}\"\nDIND_ALLOW_AAAA_USE=\"${DIND_ALLOW_AAAA_USE:-}\"  # Default is to use DNS64 always for IPv6 mode\nKUBE_ROUTER_VERSION=\"${KUBE_ROUTER_VERSION:-v0.2.0}\"\n\n# Use legacy DIND_SUBNET/DIND_SUBNET_SIZE, only if MGMT_CIDRS is not set.\nlegacy_mgmt_cidr=\"\"\nif [[ ${DIND_SUBNET:-} && ${DIND_SUBNET_SIZE:-} ]]; then\n  legacy_mgmt_cidr=\"${DIND_SUBNET}/${DIND_SUBNET_SIZE}\"\nfi\n\nif [[ ${IP_MODE} = \"dual-stack\" ]]; then\n  mgmt_net_defaults=\"10.192.0.0/24, fd00:20::/64\"\n\n  KUBE_RSYNC_ADDR=\"${KUBE_RSYNC_ADDR:-::1}\"\n  SERVICE_CIDR=\"${SERVICE_CIDR:-fd00:30::/110}\"  # Will default to IPv6 service net family\n\n  pod_net_defaults=\"10.244.0.0/16, fd00:40::/72\"\n\n  USE_HAIRPIN=\"${USE_HAIRPIN:-true}\"  # Default is to use hairpin for dual-stack\n  DIND_ALLOW_AAAA_USE=true  # Forced, so can access external hosts via IPv6\n  if [[ ${DIND_ALLOW_AAAA_USE} && ${GCE_HOSTED} ]]; then\n    echo \"ERROR! GCE does not support use of IPv6 for external addresses - aborting.\"\n    exit 1\n  fi\nelif [[ ${IP_MODE} = \"ipv6\" ]]; then\n  mgmt_net_defaults=\"fd00:20::/64\"\n\n  KUBE_RSYNC_ADDR=\"${KUBE_RSYNC_ADDR:-::1}\"\n  SERVICE_CIDR=\"${SERVICE_CIDR:-fd00:30::/110}\"\n\n  pod_net_defaults=\"fd00:40::/72\"\n\n  USE_HAIRPIN=\"${USE_HAIRPIN:-true}\"  # Default is to use hairpin for IPv6\n  if [[ ${DIND_ALLOW_AAAA_USE} && ${GCE_HOSTED} ]]; then\n    echo \"ERROR! GCE does not support use of IPv6 for external addresses - aborting.\"\n    exit 1\n  fi\nelse  # IPv4 mode\n  mgmt_net_defaults=\"10.192.0.0/24\"\n\n  KUBE_RSYNC_ADDR=\"${KUBE_RSYNC_ADDR:-127.0.0.1}\"\n  SERVICE_CIDR=\"${SERVICE_CIDR:-10.96.0.0/12}\"\n\n  pod_net_defaults=\"10.244.0.0/16\"\n\n  USE_HAIRPIN=\"${USE_HAIRPIN:-false}\"  # Disabled for IPv4, as issue with Virtlet networking\n  if [[ ${DIND_ALLOW_AAAA_USE} ]]; then\n    echo \"WARNING! The DIND_ALLOW_AAAA_USE option is for IPv6 mode - ignoring setting.\"\n    DIND_ALLOW_AAAA_USE=\n  fi\n  if [[ ${CNI_PLUGIN} = \"calico\" || ${CNI_PLUGIN} = \"calico-kdd\" ]]; then\n    pod_net_defaults=\"192.168.0.0/16\"\n  fi\nfi\n\nIFS=' ' read -r -a mgmt_net_cidrs <<<$( dind::get-and-validate-cidrs \"${MGMT_CIDRS:-${legacy_mgmt_cidr}}\" \"${mgmt_net_defaults[@]}\" true )\n\nREMOTE_DNS64_V4SERVER=\"${REMOTE_DNS64_V4SERVER:-8.8.8.8}\"\nif [[ ${IP_MODE} == \"ipv6\" ]]; then\n  # Uses local DNS64 container\n  dns_server=\"$( dind::make-ip-from-cidr ${mgmt_net_cidrs[0]} 0x100 )\"\n  DNS64_PREFIX=\"${DNS64_PREFIX:-fd00:10:64:ff9b::}\"\n  DNS64_PREFIX_SIZE=\"${DNS64_PREFIX_SIZE:-96}\"\n  DNS64_PREFIX_CIDR=\"${DNS64_PREFIX}/${DNS64_PREFIX_SIZE}\"\n\n  LOCAL_NAT64_SERVER=\"$( dind::make-ip-from-cidr ${mgmt_net_cidrs[0]} 0x200 )\"\n  NAT64_V4_SUBNET_PREFIX=\"${NAT64_V4_SUBNET_PREFIX:-172.18}\"\n  dind::add-cluster-id-and-validate-nat64-prefix\nelse\n  dns_server=\"${REMOTE_DNS64_V4SERVER}\"\nfi\n\nSERVICE_NET_MODE=\"$( dind::family-for ${SERVICE_CIDR} )\"\nDNS_SVC_IP=\"$( dind::make-ip-from-cidr ${SERVICE_CIDR} 10 )\"\n\nETCD_HOST=\"${ETCD_HOST:-$( dind::localhost )}\"\n\nIFS=' ' read -r -a pod_net_cidrs <<<$( dind::get-and-validate-cidrs \"${POD_NETWORK_CIDR:-}\" \"${pod_net_defaults[@]}\" false )\n\ndeclare -a pod_prefixes\ndeclare -a pod_sizes\n# Extract the prefix and size from the provided pod CIDR(s), based on the IP mode of each. The\n# size will be increased by 8, to make room for the node ID to be added to the prefix later.\n# Bridge and PTP plugins can process IPv4 and IPv6 pod CIDRs, other plugins must be IPv4 only.\nfor pod_cidr in \"${pod_net_cidrs[@]}\"; do\n  if [[ $( dind::family-for \"${pod_cidr}\" ) = \"ipv4\" ]]; then\n    actual_size=$( echo ${pod_cidr} | sed 's,.*/,,' )\n    if [[ ${actual_size} -ne 16 ]]; then\n        echo \"ERROR! For IPv4 CIDRs, the size must be /16. Have '${pod_cidr}'\"\n        exit 1\n    fi\n    pod_sizes+=( 24 )\n    pod_prefixes+=( \"$(echo ${pod_cidr} | sed 's/^\\([0-9]*\\.[0-9]*\\.\\).*/\\1/')\" )\n  else  # IPv6\n    if [[ ${CNI_PLUGIN} != \"bridge\" && ${CNI_PLUGIN} != \"ptp\" ]]; then\n      echo \"ERROR! IPv6 pod networks are only supported by bridge and PTP CNI plugins\"\n      exit 1\n    fi\n    # There are several cases to address. First, is normal split of prefix and size:\n    #   fd00:10:20:30::/64  --->  fd00:10:20:30:  /72\n    #\n    # Second, is when the prefix needs to be padded, so that node ID can be added later:\n    #   fd00:10::/64  --->  fd00:10:0:0:  /72\n    #\n    # Third, is when the low order part of the address, must be removed for the prefix,\n    # as the node ID will be placed in the lower byte:\n    #   fd00:10:20:30:4000::/72  --->  fd00:10:20:30:40  /80\n    #\n    # We will attempt to check for three error cases. One is when the address part is\n    # way too big for the size specified:\n    #   fd00:10:20:30:40::/48  --->  fd00:10:20:  /56 desired, but conflict with 30:40:\n    #\n    # Another is when the address part, once trimmed for the size, would loose info:\n    #   fd00:10:20:1234::/56  --->  fd00:10:20:12  /64, but lost 34:, which conflicts\n    #\n    # Lastly, again, trimming would leave high byte in hextet, conflicting with\n    # the node ID:\n    #   fd00:10:20:30:1200::/64  --->  fd00:10:20:30:12  /72, but 12 conflicts\n    #\n    # Note: later, the node ID will be appended to the prefix generated.\n    #\n    cluster_size=\"$(echo ${pod_cidr} | sed 's,.*::/,,')\"\n    pod_sizes+=( $((${cluster_size}+8)) )\n\n    pod_prefix=\"$(echo ${pod_cidr} | sed 's,::/.*,:,')\"\n    num_colons=\"$(grep -o \":\" <<< \"${pod_prefix}\" | wc -l)\"\n    need_zero_pads=$((${cluster_size}/16))\n\n    if [[ ${num_colons} -gt $((need_zero_pads + 1)) ]]; then\n        echo \"ERROR! Address part of CIDR (${pod_prefix}) is too large for /${cluster_size}\"\n        exit 1\n    fi\n    if [[ ${num_colons} -gt ${need_zero_pads} ]]; then\n      # Will be replacing lowest byte with node ID, so pull off lower byte and colon\n        if [[ ${pod_prefix: -3} != \"00:\" ]]; then   # last byte is not zero\n          echo \"ERROR! Cannot trim address part of CIDR (${pod_prefix}) to fit in /${cluster_size}\"\n          exit 1\n        fi\n        pod_prefix=${pod_prefix::-3}\n        if [[ $(( ${cluster_size} % 16 )) -eq 0 && $( ${pod_prefix: -1} ) != \":\" ]]; then  # should not be upper byte for this size CIDR\n          echo \"ERROR! Trimmed address part of CIDR (${pod_prefix}) is still too large for /${cluster_size}\"\n          exit 1\n        fi\n    fi\n    # Add in zeros to pad 16 bits at a time, up to the padding needed, which is\n    # need_zero_pads - num_colons.\n    while [ ${num_colons} -lt ${need_zero_pads} ]; do\n        pod_prefix+=\"0:\"\n      ((num_colons++))\n    done\n    pod_prefixes+=( \"${pod_prefix}\" )\n  fi\ndone\n\nDIND_IMAGE_BASE=\"${DIND_IMAGE_BASE:-mirantis/kubeadm-dind-cluster}\"\nif [[ ${DIND_COMMIT:-} ]]; then\n  if [[ ${DIND_COMMIT} = current ]]; then\n    DIND_COMMIT=\"$(cd \"${DIND_ROOT}\"; git rev-parse HEAD)\"\n  fi\n  DIND_K8S_VERSION=\"${DIND_K8S_VERSION:-v1.13}\"\n  DIND_IMAGE=\"${DIND_IMAGE_BASE}:${DIND_COMMIT}-${DIND_K8S_VERSION}\"\nelse\n  DIND_IMAGE=\"${DIND_IMAGE:-${DIND_IMAGE_BASE}:local}\"\nfi\nif [[ ${DIND_IMAGE_DIGEST:-} ]]; then\n  DIND_IMAGE=\"${DIND_IMAGE}@${DIND_IMAGE_DIGEST}\"\nfi\n\nBUILD_KUBEADM=\"${BUILD_KUBEADM:-}\"\nBUILD_HYPERKUBE=\"${BUILD_HYPERKUBE:-}\"\nif [[ ! -z ${DIND_K8S_BIN_DIR:-} ]]; then\n  BUILD_KUBEADM=\"\"\n  BUILD_HYPERKUBE=\"\"\nfi\nKUBEADM_SOURCE=\"${KUBEADM_SOURCE-}\"\nHYPERKUBE_SOURCE=\"${HYPERKUBE_SOURCE-}\"\nNUM_NODES=${NUM_NODES:-2}\nEXTRA_PORTS=\"${EXTRA_PORTS:-}\"\nKUBECTL_DIR=\"${KUBECTL_DIR:-${HOME}/.kubeadm-dind-cluster}\"\nSKIP_SNAPSHOT=\"${SKIP_SNAPSHOT:-}\"\nE2E_REPORT_DIR=\"${E2E_REPORT_DIR:-}\"\nDIND_NO_PARALLEL_E2E=\"${DIND_NO_PARALLEL_E2E:-}\"\nDNS_SERVICE=\"${DNS_SERVICE:-coredns}\"\nDIND_STORAGE_DRIVER=\"${DIND_STORAGE_DRIVER:-overlay2}\"\n\nDIND_CA_CERT_URL=\"${DIND_CA_CERT_URL:-}\"\nDIND_PROPAGATE_HTTP_PROXY=\"${DIND_PROPAGATE_HTTP_PROXY:-}\"\nDIND_HTTP_PROXY=\"${DIND_HTTP_PROXY:-}\"\nDIND_HTTPS_PROXY=\"${DIND_HTTPS_PROXY:-}\"\nDIND_NO_PROXY=\"${DIND_NO_PROXY:-}\"\n\nDIND_DAEMON_JSON_FILE=\"${DIND_DAEMON_JSON_FILE:-/etc/docker/daemon.json}\"  # can be set to /dev/null\nDIND_REGISTRY_MIRROR=\"${DIND_REGISTRY_MIRROR:-}\"  # plain string format\nDIND_INSECURE_REGISTRIES=\"${DIND_INSECURE_REGISTRIES:-}\"  # json list format\n# comma-separated custom network(s) for cluster nodes to join\nDIND_CUSTOM_NETWORKS=\"${DIND_CUSTOM_NETWORKS:-}\"\n\nSKIP_DASHBOARD=\"${SKIP_DASHBOARD:-}\"\n\n# you can set special value 'none' not to set any FEATURE_GATES / KUBELET_FEATURE_GATES.\nFEATURE_GATES=\"${FEATURE_GATES:-none}\"\nKUBELET_FEATURE_GATES=\"${KUBELET_FEATURE_GATES:-DynamicKubeletConfig=true}\"\n\nENABLE_CEPH=\"${ENABLE_CEPH:-}\"\n\nDIND_CRI=\"${DIND_CRI:-docker}\"\ncase \"${DIND_CRI}\" in\n  docker)\n    CRI_SOCKET=/var/run/dockershim.sock\n    ;;\n  containerd)\n    CRI_SOCKET=/var/run/containerd/containerd.sock\n    ;;\n  *)\n    echo >&2 \"Bad DIND_CRI. Please specify 'docker' or 'containerd'\"\n    ;;\nesac\n\n# TODO: Test multi-cluster for IPv6, before enabling\nif [[ \"${DIND_LABEL}\" != \"${DEFAULT_DIND_LABEL}\"  && \"${IP_MODE}\" == 'dual-stack' ]]; then\n    echo \"Multiple parallel clusters currently not supported for dual-stack mode\" >&2\n    exit 1\nfi\n\n# not configurable for now, would need to setup context for kubectl _inside_ the cluster\nreadonly INTERNAL_APISERVER_PORT=8080\n\nfunction dind::need-source {\n  if [[ ! -f cluster/kubectl.sh ]]; then\n    echo \"$0 must be called from the Kubernetes repository root directory\" 1>&2\n    exit 1\n  fi\n}\n\nbuild_tools_dir=\"build\"\nuse_k8s_source=y\nif [[ ! ${BUILD_KUBEADM} && ! ${BUILD_HYPERKUBE} ]]; then\n  use_k8s_source=\nfi\nif [[ ${use_k8s_source} ]]; then\n  dind::need-source\n  kubectl=cluster/kubectl.sh\n  if [[ ! -f ${build_tools_dir}/common.sh ]]; then\n    build_tools_dir=\"build-tools\"\n  fi\nelse\n  if [[ ! ${DOWNLOAD_KUBECTL:-} ]] && ! hash kubectl 2>/dev/null; then\n    echo \"You need kubectl binary in your PATH to use prebuilt DIND image\" 1>&2\n    exit 1\n  fi\n  kubectl=kubectl\nfi\n\nfunction dind::retry {\n  # based on retry function in hack/jenkins/ scripts in k8s source\n  for i in {1..10}; do\n    \"$@\" && return 0 || sleep ${i}\n  done\n  \"$@\"\n}\n\nbusybox_image=\"busybox:1.30.1\"\ne2e_base_image=\"golang:1.12.4\"\nsys_volume_args=()\nbuild_volume_args=()\n\nfunction dind::set-build-volume-args {\n  if [ ${#build_volume_args[@]} -gt 0 ]; then\n    return 0\n  fi\n  build_container_name=\n  if [ -n \"${KUBEADM_DIND_LOCAL:-}\" ]; then\n    build_volume_args=(-v \"$PWD:/go/src/k8s.io/kubernetes\")\n  else\n    build_container_name=\"$(KUBE_ROOT=${PWD} ETCD_HOST=${ETCD_HOST} &&\n                            . ${build_tools_dir}/common.sh &&\n                            kube::build::verify_prereqs >&2 &&\n                            echo \"${KUBE_DATA_CONTAINER_NAME:-${KUBE_BUILD_DATA_CONTAINER_NAME}}\")\"\n    build_volume_args=(--volumes-from \"${build_container_name}\")\n  fi\n}\n\nfunction dind::volume-exists {\n  local name=\"$1\"\n  if docker volume inspect \"${name}\" >& /dev/null; then\n    return 0\n  fi\n  return 1\n}\n\nfunction dind::create-volume {\n  local name=\"$1\"\n  docker volume create --label \"${DIND_LABEL}\" --name \"${name}\" >/dev/null\n}\n\n# We mount /boot and /lib/modules into the container\n# below to in case some of the workloads need them.\n# This includes virtlet, for instance. Also this may be\n# useful in future if we want DIND nodes to pass\n# preflight checks.\n# Unfortunately we can't do this when using Mac Docker\n# (unless a remote docker daemon on Linux is used)\n# NB: there's no /boot on recent Mac dockers\nfunction dind::prepare-sys-mounts {\n  if [[ ! ${using_linuxkit} ]]; then\n    sys_volume_args=()\n    if [[ -d /boot ]]; then\n      sys_volume_args+=(-v /boot:/boot)\n    fi\n    if [[ -d /lib/modules ]]; then\n      sys_volume_args+=(-v /lib/modules:/lib/modules)\n    fi\n    return 0\n  fi\n  local dind_sys_vol_name\n  dind_sys_vol_name=\"kubeadm-dind-sys$( dind::cluster-suffix )\"\n  if ! dind::volume-exists \"$dind_sys_vol_name\"; then\n    dind::step \"Saving a copy of docker host's /lib/modules\"\n    dind::create-volume \"$dind_sys_vol_name\"\n    # Use a dirty nsenter trick to fool Docker on Mac and grab system\n    # /lib/modules into sys.tar file on kubeadm-dind-sys volume.\n    local nsenter=\"nsenter --mount=/proc/1/ns/mnt --\"\n    docker run \\\n           --rm \\\n           --privileged \\\n           -v \"$dind_sys_vol_name\":/dest \\\n           --pid=host \\\n           \"${busybox_image}\" \\\n           /bin/sh -c \\\n           \"if ${nsenter} test -d /lib/modules; then ${nsenter} tar -C / -c lib/modules >/dest/sys.tar; fi\"\n  fi\n  sys_volume_args=(-v \"$dind_sys_vol_name\":/dind-sys)\n}\n\ntmp_containers=()\n\nfunction dind::cleanup {\n  if [ ${#tmp_containers[@]} -gt 0 ]; then\n    for name in \"${tmp_containers[@]}\"; do\n      docker rm -vf \"${name}\" 2>/dev/null\n    done\n  fi\n}\n\ntrap dind::cleanup EXIT\n\nfunction dind::check-image {\n  local name=\"$1\"\n  if docker inspect --format 'x' \"${name}\" >&/dev/null; then\n    return 0\n  else\n    return 1\n  fi\n}\n\nfunction dind::filter-make-output {\n  # these messages make output too long and make Travis CI choke\n  egrep -v --line-buffered 'I[0-9][0-9][0-9][0-9] .*(parse|conversion|defaulter|deepcopy)\\.go:[0-9]+\\]'\n}\n\nfunction dind::run-build-command {\n    # this is like build/run.sh, but it doesn't rsync back the binaries,\n    # only the generated files.\n    local cmd=(\"$@\")\n    (\n        # The following is taken from build/run.sh and build/common.sh\n        # of Kubernetes source tree. It differs in\n        # --filter='+ /_output/dockerized/bin/**'\n        # being removed from rsync\n        . ${build_tools_dir}/common.sh\n        kube::build::verify_prereqs\n        kube::build::build_image\n        kube::build::run_build_command \"$@\"\n\n        kube::log::status \"Syncing out of container\"\n\n        kube::build::start_rsyncd_container\n\n        local rsync_extra=\"\"\n        if (( ${KUBE_VERBOSE} >= 6 )); then\n            rsync_extra=\"-iv\"\n        fi\n\n        # The filter syntax for rsync is a little obscure. It filters on files and\n        # directories.  If you don't go in to a directory you won't find any files\n        # there.  Rules are evaluated in order.  The last two rules are a little\n        # magic. '+ */' says to go in to every directory and '- /**' says to ignore\n        # any file or directory that isn't already specifically allowed.\n        #\n        # We are looking to copy out all of the built binaries along with various\n        # generated files.\n        kube::build::rsync \\\n            --filter='- /vendor/' \\\n            --filter='- /_temp/' \\\n            --filter='+ zz_generated.*' \\\n            --filter='+ generated.proto' \\\n            --filter='+ *.pb.go' \\\n            --filter='+ types.go' \\\n            --filter='+ */' \\\n            --filter='- /**' \\\n            \"rsync://k8s@${KUBE_RSYNC_ADDR}/k8s/\" \"${KUBE_ROOT}\"\n\n        kube::build::stop_rsyncd_container\n    )\n}\n\nfunction dind::make-for-linux {\n  local copy=\"$1\"\n  shift\n  dind::step \"Building binaries:\" \"$*\"\n  if [ -n \"${KUBEADM_DIND_LOCAL:-}\" ]; then\n    dind::step \"+ make WHAT=\\\"$*\\\"\"\n    make WHAT=\"$*\" 2>&1 | dind::filter-make-output\n  elif [ \"${copy}\" = \"y\" ]; then\n    dind::step \"+ ${build_tools_dir}/run.sh make WHAT=\\\"$*\\\"\"\n    \"${build_tools_dir}/run.sh\" make WHAT=\"$*\" 2>&1 | dind::filter-make-output\n  else\n    dind::step \"+ [using the build container] make WHAT=\\\"$*\\\"\"\n    dind::run-build-command make WHAT=\"$*\" 2>&1 | dind::filter-make-output\n  fi\n}\n\nfunction dind::check-binary {\n  local filename=\"$1\"\n  local dockerized=\"_output/dockerized/bin/linux/amd64/${filename}\"\n  local plain=\"_output/local/bin/linux/amd64/${filename}\"\n  dind::set-build-volume-args\n  # FIXME: don't hardcode amd64 arch\n  if [ -n \"${KUBEADM_DIND_LOCAL:-${force_local:-}}\" ]; then\n    if [ -f \"${dockerized}\" -o -f \"${plain}\" ]; then\n      return 0\n    fi\n  elif docker run --rm \"${build_volume_args[@]}\" \\\n              \"${busybox_image}\" \\\n              test -f \"/go/src/k8s.io/kubernetes/${dockerized}\" >&/dev/null; then\n    return 0\n  fi\n  return 1\n}\n\nfunction dind::ensure-downloaded-kubectl {\n  local kubectl_url\n  local kubectl_sha1\n  local kubectl_sha1_linux\n  local kubectl_sha1_darwin\n  local kubectl_link\n  local kubectl_os\n\n  if [[ ! ${DOWNLOAD_KUBECTL:-} ]]; then\n    return 0\n  fi\n\n  export PATH=\"${KUBECTL_DIR}:$PATH\"\n\n  eval \"$(docker run --entrypoint /bin/bash --rm \"${DIND_IMAGE}\" -c \"cat /dind-env\")\"\n\n  if [ $(uname) = Darwin ]; then\n    kubectl_sha1=\"${KUBECTL_DARWIN_SHA1}\"\n    kubectl_url=\"${KUBECTL_DARWIN_URL}\"\n  else\n    kubectl_sha1=\"${KUBECTL_LINUX_SHA1}\"\n    kubectl_url=\"${KUBECTL_LINUX_URL}\"\n  fi\n  local link_target=\"kubectl-${KUBECTL_VERSION}\"\n  local link_name=\"${KUBECTL_DIR}\"/kubectl\n  if [[ -h \"${link_name}\" && \"$(readlink \"${link_name}\")\" = \"${link_target}\" ]]; then\n    return 0\n  fi\n\n  local path=\"${KUBECTL_DIR}/${link_target}\"\n  if [[ ! -f \"${path}\" ]]; then\n    mkdir -p \"${KUBECTL_DIR}\"\n    curl -sSLo \"${path}\" \"${kubectl_url}\"\n    echo \"${kubectl_sha1}  ${path}\" | sha1sum -c\n    chmod +x \"${path}\"\n  fi\n\n  ln -fs \"${link_target}\" \"${KUBECTL_DIR}/kubectl\"\n}\n\nfunction dind::ensure-kubectl {\n  if [[ ! ${use_k8s_source} ]]; then\n    # already checked on startup\n    dind::ensure-downloaded-kubectl\n    return 0\n  fi\n  if [ $(uname) = Darwin ]; then\n    dind::step \"Building kubectl\"\n    dind::step \"+ make WHAT=cmd/kubectl\"\n    make WHAT=cmd/kubectl 2>&1 | dind::filter-make-output\n  else\n    dind::make-for-linux y cmd/kubectl\n  fi\n}\n\nfunction dind::ensure-binaries {\n  local -a to_build=()\n  for name in \"$@\"; do\n    if ! dind::check-binary \"$(basename \"${name}\")\"; then\n      to_build+=(\"${name}\")\n    fi\n  done\n  if [ \"${#to_build[@]}\" -gt 0 ]; then\n    dind::make-for-linux n \"${to_build[@]}\"\n  fi\n  return 0\n}\n\n# dind::ensure-network creates the management network for the cluster. For IPv4\n# only it will have the management network CIDR. For IPv6 only, it will have\n# the IPv6 management network CIDR and the NAT64 V4 mapping network CIDR. For\n# dual stack, it will have the IPv4 and IPv6 management CIDRs. Each of the\n# management networks (not the NAT64 network) will have a gateway specified.\n#\nfunction dind::ensure-network {\n  if ! docker network inspect $(dind::net-name) >&/dev/null; then\n    local -a args\n    for cidr in \"${mgmt_net_cidrs[@]}\"; do\n      if [[ $( dind::family-for ${cidr} ) = \"ipv6\" ]]; then\n                args+=(--ipv6)\n      fi\n      args+=(--subnet=\"${cidr}\")\n      local gw=$( dind::make-ip-from-cidr ${cidr} 1 )\n      args+=(--gateway=\"${gw}\")\n    done\n    if [[ ${IP_MODE} = \"ipv6\" ]]; then\n      # Need second network for NAT64 V4 mapping network\n      args+=(--subnet=${NAT64_V4_SUBNET_PREFIX}.0.0/16)\n    fi\n    docker network create ${args[@]} $(dind::net-name) >/dev/null\n  fi\n}\n\nfunction dind::ensure-volume {\n  local reuse_volume=\n  if [[ $1 = -r ]]; then\n    reuse_volume=1\n    shift\n  fi\n  local name=\"$1\"\n  if dind::volume-exists \"${name}\"; then\n    if [[ ! ${reuse_volume} ]]; then\n      docker volume rm \"${name}\" >/dev/null\n    fi\n  fi\n  dind::create-volume \"${name}\"\n}\n\nfunction dind::ensure-dns {\n    if [[ ${IP_MODE} = \"ipv6\" ]]; then\n        local dns64_name=\"bind9$( dind::cluster-suffix )\"\n        if ! docker inspect ${dns64_name} >&/dev/null; then\n            local force_dns64_for=\"\"\n            if [[ ! ${DIND_ALLOW_AAAA_USE} ]]; then\n                # Normally, if have an AAAA record, it is used. This clause tells\n                # bind9 to do ignore AAAA records for the specified networks\n                # and/or addresses and lookup A records and synthesize new AAAA\n                # records. In this case, we select \"any\" networks that have AAAA\n                # records meaning we ALWAYS use A records and do NAT64.\n                force_dns64_for=\"exclude { any; };\"\n            fi\n            read -r -d '' bind9_conf <<BIND9_EOF\noptions {\n    directory \"/var/bind\";\n    allow-query { any; };\n    forwarders {\n        ${DNS64_PREFIX}${REMOTE_DNS64_V4SERVER};\n    };\n    auth-nxdomain no;    # conform to RFC1035\n    listen-on-v6 { any; };\n    dns64 ${DNS64_PREFIX_CIDR} {\n        ${force_dns64_for}\n    };\n};\nBIND9_EOF\n            docker run -d --name ${dns64_name} --hostname ${dns64_name} --net \"$(dind::net-name)\" --label \"dind-support$( dind::cluster-suffix )\" \\\n               --sysctl net.ipv6.conf.all.disable_ipv6=0 --sysctl net.ipv6.conf.all.forwarding=1 \\\n               --privileged=true --ip6 ${dns_server} --dns ${dns_server} \\\n               -e bind9_conf=\"${bind9_conf}\" \\\n               diverdane/bind9:latest /bin/sh -c 'echo \"${bind9_conf}\" >/named.conf && named -c /named.conf -g -u named' >/dev/null\n            ipv4_addr=\"$(docker exec ${dns64_name} ip addr list eth0 | grep \"inet\" | awk '$1 == \"inet\" {print $2}')\"\n            docker exec ${dns64_name} ip addr del ${ipv4_addr} dev eth0\n            docker exec ${dns64_name} ip -6 route add ${DNS64_PREFIX_CIDR} via ${LOCAL_NAT64_SERVER}\n        fi\n    fi\n}\n\nfunction dind::ensure-nat {\n    if [[  ${IP_MODE} = \"ipv6\" ]]; then\n        local nat64_name=\"tayga$( dind::cluster-suffix )\"\n        if ! docker ps | grep ${nat64_name} >&/dev/null; then\n            docker run -d --name ${nat64_name} --hostname ${nat64_name} --net \"$(dind::net-name)\" --label \"dind-support$( dind::cluster-suffix )\" \\\n                   --sysctl net.ipv6.conf.all.disable_ipv6=0 --sysctl net.ipv6.conf.all.forwarding=1 \\\n                   --privileged=true --ip ${NAT64_V4_SUBNET_PREFIX}.0.200 --ip6 ${LOCAL_NAT64_SERVER} --dns ${REMOTE_DNS64_V4SERVER} --dns ${dns_server} \\\n                   -e TAYGA_CONF_PREFIX=${DNS64_PREFIX_CIDR} -e TAYGA_CONF_IPV4_ADDR=${NAT64_V4_SUBNET_PREFIX}.0.200 \\\n                   -e TAYGA_CONF_DYNAMIC_POOL=${NAT64_V4_SUBNET_PREFIX}.0.128/25 danehans/tayga:latest >/dev/null\n            # Need to check/create, as \"clean\" may remove route\n            local route=\"$(ip route | egrep \"^${NAT64_V4_SUBNET_PREFIX}.0.128/25\")\"\n            if [[ -z \"${route}\" ]]; then\n                docker run --net=host --rm --privileged ${busybox_image} ip route add ${NAT64_V4_SUBNET_PREFIX}.0.128/25 via ${NAT64_V4_SUBNET_PREFIX}.0.200\n            fi\n        fi\n    fi\n}\n\nfunction dind::run {\n  local reuse_volume=\n  if [[ $1 = -r ]]; then\n    reuse_volume=\"-r\"\n    shift\n  fi\n  local container_name=\"${1:-}\"\n  local node_id=${2:-0}\n  local portforward=\"${3:-}\"\n  if [[ $# -gt 3 ]]; then\n    shift 3\n  else\n    shift $#\n  fi\n\n  local -a opts=(\"$@\")\n  local ip_mode=\"--ip\"\n  for cidr in \"${mgmt_net_cidrs[@]}\"; do\n    if [[ $( dind::family-for ${cidr} ) = \"ipv6\" ]]; then\n      ip_mode=\"--ip6\"\n    fi\n    opts+=(\"${ip_mode}\" \"$( dind::make-ip-from-cidr ${cidr} $((${node_id}+1)) )\")\n  done\n  opts+=(\"$@\")\n\n  local -a args=(\"systemd.setenv=CNI_PLUGIN=${CNI_PLUGIN}\")\n  args+=(\"systemd.setenv=IP_MODE=${IP_MODE}\")\n  args+=(\"systemd.setenv=DIND_STORAGE_DRIVER=${DIND_STORAGE_DRIVER}\")\n  args+=(\"systemd.setenv=DIND_CRI=${DIND_CRI}\")\n\n  if [[ ${IP_MODE} != \"ipv4\" ]]; then\n    opts+=(--sysctl net.ipv6.conf.all.disable_ipv6=0)\n    opts+=(--sysctl net.ipv6.conf.all.forwarding=1)\n  fi\n\n  if [[ ${IP_MODE} = \"ipv6\" ]]; then\n    opts+=(--dns ${dns_server})\n    args+=(\"systemd.setenv=DNS64_PREFIX_CIDR=${DNS64_PREFIX_CIDR}\")\n    args+=(\"systemd.setenv=LOCAL_NAT64_SERVER=${LOCAL_NAT64_SERVER}\")\n  fi\n\n  declare -a pod_nets\n  local i=0\n  if [[ ${IP_MODE} = \"ipv4\" || ${IP_MODE} = \"dual-stack\" ]]; then\n    pod_nets+=(\"${pod_prefixes[$i]}${node_id}\")\n    i=$((i+1))\n  fi\n  if [[ ${IP_MODE} = \"ipv6\" || ${IP_MODE} = \"dual-stack\" ]]; then\n    # For prefix, if node ID will be in the upper byte, push it over\n    if [[ $((${pod_sizes[$i]} % 16)) -ne 0 ]]; then\n      n_id=$(printf \"%02x00\\n\" \"${node_id}\")\n    else\n      if [[ \"${pod_prefixes[$i]: -1}\" = \":\" ]]; then\n        n_id=$(printf \"%x\\n\" \"${node_id}\")\n      else\n        n_id=$(printf \"%02x\\n\" \"${node_id}\")  # In lower byte, so ensure two chars\n      fi\n    fi\n    pod_nets+=(\"${pod_prefixes[$i]}${n_id}\")\n  fi\n\n  args+=(\"systemd.setenv=POD_NET_PREFIX=\\\"${pod_nets[0]}\\\"\")\n  args+=(\"systemd.setenv=POD_NET_SIZE=\\\"${pod_sizes[0]}\\\"\")\n  args+=(\"systemd.setenv=POD_NET2_PREFIX=\\\"${pod_nets[1]:-}\\\"\")\n  args+=(\"systemd.setenv=POD_NET2_SIZE=\\\"${pod_sizes[1]:-}\\\"\")\n  args+=(\"systemd.setenv=SERVICE_NET_MODE=${SERVICE_NET_MODE}\")\n  args+=(\"systemd.setenv=USE_HAIRPIN=${USE_HAIRPIN}\")\n  args+=(\"systemd.setenv=DNS_SVC_IP=${DNS_SVC_IP}\")\n  args+=(\"systemd.setenv=DNS_SERVICE=${DNS_SERVICE}\")\n  if [[ ! \"${container_name}\" ]]; then\n    echo >&2 \"Must specify container name\"\n    exit 1\n  fi\n\n  # remove any previously created containers with the same name\n  docker rm -vf \"${container_name}\" >&/dev/null || true\n\n  if [[ \"${portforward}\" ]]; then\n    IFS=';' read -ra array <<< \"${portforward}\"\n    for element in \"${array[@]}\"; do\n      opts+=(-p \"${element}\")\n    done\n  fi\n\n  opts+=(${sys_volume_args[@]+\"${sys_volume_args[@]}\"})\n\n  dind::step \"Starting DIND container:\" \"${container_name}\"\n\n  if [[ ! -z ${DIND_K8S_BIN_DIR:-} ]]; then\n      opts+=(-v ${DIND_K8S_BIN_DIR}:/k8s)\n  fi\n  if [[ ! ${using_linuxkit} ]]; then\n    opts+=(-v /boot:/boot -v /lib/modules:/lib/modules)\n  fi\n\n  if [[ ${ENABLE_CEPH} ]]; then\n    opts+=(-v /dev:/dev\n           -v /sys/bus:/sys/bus\n           -v /var/run/docker.sock:/opt/outer-docker.sock)\n  fi\n\n  local volume_name=\"kubeadm-dind-${container_name}\"\n  dind::ensure-network\n  dind::ensure-volume ${reuse_volume} \"${volume_name}\"\n  dind::ensure-nat\n  dind::ensure-dns\n\n  # TODO: create named volume for binaries and mount it to /k8s\n  # in case of the source build\n\n  # Start the new container.\n  docker run \\\n         -e IP_MODE=\"${IP_MODE}\" \\\n         -e KUBEADM_SOURCE=\"${KUBEADM_SOURCE}\" \\\n         -e HYPERKUBE_SOURCE=\"${HYPERKUBE_SOURCE}\" \\\n         -d --privileged \\\n         --net \"$(dind::net-name)\" \\\n         --name \"${container_name}\" \\\n         --hostname \"${container_name}\" \\\n         -l \"${DIND_LABEL}\" \\\n         -v \"${volume_name}:/dind\" \\\n         ${opts[@]+\"${opts[@]}\"} \\\n         \"${DIND_IMAGE}\" \\\n         ${args[@]+\"${args[@]}\"}\n\n  if [[ -n ${DIND_CUSTOM_NETWORKS} ]]; then\n    local cust_nets\n    local IFS=','; read -ra cust_nets <<< \"${DIND_CUSTOM_NETWORKS}\"\n    for cust_net in \"${cust_nets[@]}\"; do\n      docker network connect ${cust_net} ${container_name} >/dev/null\n    done\n  fi\n}\n\nfunction dind::kubeadm {\n  local container_id=\"$1\"\n  shift\n  dind::step \"Running kubeadm:\" \"$*\"\n  status=0\n  # See image/bare/wrapkubeadm.\n  # Capturing output is necessary to grab flags for 'kubeadm join'\n  local -a env=(-e KUBELET_FEATURE_GATES=\"${KUBELET_FEATURE_GATES}\"\n                -e DIND_CRI=\"${DIND_CRI}\")\n  if ! docker exec \"${env[@]}\" \"${container_id}\" /usr/local/bin/wrapkubeadm \"$@\" 2>&1 | tee /dev/fd/2; then\n    echo \"*** kubeadm failed\" >&2\n    return 1\n  fi\n  return ${status}\n}\n\n# function dind::bare {\n#   local container_name=\"${1:-}\"\n#   if [[ ! \"${container_name}\" ]]; then\n#     echo >&2 \"Must specify container name\"\n#     exit 1\n#   fi\n#   shift\n#   run_opts=(${@+\"$@\"})\n#   dind::run \"${container_name}\"\n# }\n\nfunction dind::configure-kubectl {\n  dind::step \"Setting cluster config\"\n  local host=\"$(dind::localhost)\"\n  if [[ -z \"$using_local_linuxdocker\" ]]; then\n    host=\"127.0.0.1\"\n  fi\n  local context_name cluster_name\n  context_name=\"$(dind::context-name)\"\n  cluster_name=\"$(dind::context-name)\"\n  \"${kubectl}\" config set-cluster \"$cluster_name\" \\\n    --server=\"http://${host}:$(dind::apiserver-port)\" \\\n    --insecure-skip-tls-verify=true\n  \"${kubectl}\" config set-context \"$context_name\" --cluster=\"$cluster_name\"\n  if [[ ${DIND_LABEL} = \"${DEFAULT_DIND_LABEL}\" ]]; then\n      # Single cluster mode\n      \"${kubectl}\" config use-context \"$context_name\"\n  fi\n}\n\nforce_make_binaries=\nfunction dind::set-master-opts {\n  master_opts=()\n  if [[ ${BUILD_KUBEADM} || ${BUILD_HYPERKUBE} ]]; then\n    # share binaries pulled from the build container between nodes\n    local dind_k8s_bin_vol_name\n    dind_k8s_bin_vol_name=\"dind-k8s-binaries$(dind::cluster-suffix)\"\n    dind::ensure-volume -r \"${dind_k8s_bin_vol_name}\"\n    dind::set-build-volume-args\n    master_opts+=(\"${build_volume_args[@]}\" -v \"${dind_k8s_bin_vol_name}:/k8s\")\n    local -a bins\n    if [[ ${BUILD_KUBEADM} ]]; then\n      master_opts+=(-e KUBEADM_SOURCE=build://)\n      bins+=(cmd/kubeadm)\n    else\n      master_opts+=(-e ${KUBEADM_SOURCE})\n    fi\n    if [[ ${BUILD_HYPERKUBE} ]]; then\n      master_opts+=(-e HYPERKUBE_SOURCE=build://)\n      bins+=(cmd/hyperkube)\n    fi\n    if [[ ${force_make_binaries} ]]; then\n      dind::make-for-linux n \"${bins[@]}\"\n    else\n      dind::ensure-binaries \"${bins[@]}\"\n    fi\n  fi\n  if [[ ${MASTER_EXTRA_OPTS:-} ]]; then\n    master_opts+=( ${MASTER_EXTRA_OPTS} )\n  fi\n}\n\nfunction dind::ensure-dashboard-clusterrolebinding {\n  local ctx\n  ctx=\"$(dind::context-name)\"\n  # 'create' may cause etcd timeout, yet create the clusterrolebinding.\n  # So use 'apply' to actually create it\n  \"${kubectl}\" --context \"$ctx\" create clusterrolebinding add-on-cluster-admin \\\n               --clusterrole=cluster-admin \\\n               --serviceaccount=kube-system:default \\\n               -o json --dry-run |\n    docker exec -i \"$(dind::master-name)\" jq '.apiVersion=\"rbac.authorization.k8s.io/v1beta1\"|.kind|=\"ClusterRoleBinding\"' |\n    \"${kubectl}\" --context \"$ctx\" apply -f -\n}\n\nfunction dind::deploy-dashboard {\n  local url=\"${DASHBOARD_URL:-}\"\n  if [ ! \"$url\" ]; then\n    local cmp_api_to_1_15=0\n    dind::compare-versions 'kubeapi' \"$(dind::kubeapi-version)\" 1 15 || cmp_api_to_1_15=$?\n    if [[ $cmp_api_to_1_15 == 2 ]]; then\n      # API version < 1.15\n      url='https://rawgit.com/kubernetes/dashboard/bfab10151f012d1acc5dfb1979f3172e2400aa3c/src/deploy/kubernetes-dashboard.yaml'\n    else\n      # API version >= 1.15\n      url='https://rawgit.com/kubernetes/dashboard/v1.10.1/src/deploy/recommended/kubernetes-dashboard.yaml'\n    fi\n  fi\n\n  dind::step \"Deploying k8s dashboard from $url\"\n  dind::retry \"${kubectl}\" --context \"$(dind::context-name)\" apply -f \"$url\"\n  # https://kubernetes-io-vnext-staging.netlify.com/docs/admin/authorization/rbac/#service-account-permissions\n  # Thanks @liggitt for the hint\n  dind::retry dind::ensure-dashboard-clusterrolebinding\n}\n\nfunction dind::version-from-source {\n  (cluster/kubectl.sh version --short 2>/dev/null || true) |\n    grep Client |\n    sed 's/^.*: v\\([0-9.]*\\).*/\\1/'\n}\n\nfunction dind::kubeapi-version {\n  if [[ ${use_k8s_source} ]]; then\n    dind::version-from-source\n  else\n    docker exec \"$(dind::master-name)\" \\\n           /bin/bash -c 'kubectl version -o json | jq -r .serverVersion.gitVersion | sed \"s/^v\\([0-9.]*\\).*/\\1/\"'\n  fi\n}\n\nfunction dind::kubeadm-version {\n  if [[ ${use_k8s_source} ]]; then\n    dind::version-from-source\n  else\n    docker exec \"$(dind::master-name)\" \\\n           /bin/bash -c 'kubeadm version -o json | jq -r .clientVersion.gitVersion' |\n      sed 's/^v\\([0-9.]*\\).*/\\1/'\n  fi\n}\n\nfunction dind::kubelet-version {\n  if [[ ${use_k8s_source} ]]; then\n    dind::version-from-source\n  else\n    docker exec \"$(dind::master-name)\" \\\n           /bin/bash -c 'kubelet --version | sed -E \"s/^(kubernetes )?v?([0-9]+(\\.[0-9]+){1,2})/\\2/I\"'\n  fi\n}\n\n# $1 is the name of the software whose version is being compared (eg 'kubeadm')\n# $2 is the version as a string (eg '1.14.5')\n# $3 is the major version it is being compared to\n# $4 is the minor version it is being compared to\n# returns 0 if the 2 versions are equal\n# returns 1 if the string version is greater\n# returns 2 if the other version is greater\n# any other return code is an error\nfunction dind::compare-versions {\n  local name=\"$1\"\n  local version_str=\"$2\"\n  local cmp_to_major=\"$3\"\n  local cmp_to_minor=\"$4\"\n\n  if [[ ! \"$version_str\" =~ ^([0-9]+)\\.([0-9]+) ]]; then\n    echo >&2 \"WARNING: can't parse $name version: $version_str\"\n    return 3\n  fi\n  local major=\"${BASH_REMATCH[1]}\"\n  local minor=\"${BASH_REMATCH[2]}\"\n  if [[ $major -gt $cmp_to_major ]]; then\n    return 1\n  fi\n  if [[ $major -lt $cmp_to_major ]]; then\n    return 2\n  fi\n  if [[ $minor -gt $cmp_to_minor ]]; then\n    return 1\n  fi\n  if [[ $minor -lt $cmp_to_minor ]]; then\n    return 2\n  fi\n  return 0\n}\n\nfunction dind::kubeadm-version-at-least {\n  local major=\"${1}\"\n  local minor=\"${2}\"\n\n  local cmp=0\n  dind::compare-versions 'kubeadm' \"$(dind::kubeadm-version)\" \"$major\" \"$minor\" || cmp=$?\n\n  [[ $cmp -lt 2 ]]\n}\n\nfunction dind::verify-image-compatibility {\n  # We can't tell in advance, if the image selected supports dual-stack,\n  # but will do the next best thing, and check as soon as start up kube-master\n  local master_name=$1\n  if [[ ${IP_MODE} = \"dual-stack\" ]]; then\n    local dual_stack_support=\"$(docker exec ${master_name} cat /node-info 2>/dev/null | grep \"dual-stack-support\" | wc -l)\"\n    if [[ ${dual_stack_support} -eq 0 ]]; then\n      echo \"ERROR! DinD image (${DIND_IMAGE}) does not support dual-stack mode - aborting!\"\n      dind::remove-images \"${DIND_LABEL}\"\n      exit 1\n    fi\n  fi\n}\n\nfunction dind::check-dns-service-type {\n  if [[ ${DNS_SERVICE} = \"kube-dns\" ]] && dind::kubeadm-version-at-least 1 13; then\n    echo >&2 \"WARNING: for 1.13+, only coredns can be used as the DNS service\"\n    DNS_SERVICE=\"coredns\"\n  fi\n}\n\nfunction dind::set-version-specific-flags {\n  local kubelet_version_specific_flags=\"$1\"\n  docker exec \"$(dind::master-name)\" sed -i \"s@KUBELET_VERSION_SPECIFIC_FLAGS=[^\\\"]*\\\"@KUBELET_VERSION_SPECIFIC_FLAGS=$kubelet_version_specific_flags\\\"@\" /lib/systemd/system/kubelet.service\n}\n\nfunction dind::init {\n  local -a opts\n  dind::set-master-opts\n  local local_host master_name container_id\n  master_name=\"$(dind::master-name)\"\n  local_host=\"$( dind::localhost )\"\n  container_id=$(dind::run \"${master_name}\" 1 \"${local_host}:$(dind::apiserver-port):${INTERNAL_APISERVER_PORT}\" ${master_opts[@]+\"${master_opts[@]}\"})\n\n  dind::verify-image-compatibility ${master_name}\n\n  # FIXME: I tried using custom tokens with 'kubeadm ex token create' but join failed with:\n  # 'failed to parse response as JWS object [square/go-jose: compact JWS format must have three parts]'\n  # So we just pick the line from 'kubeadm init' output\n  # Using a template file in the image (based on version) to build a kubeadm.conf file and to customize\n  # it based on CNI plugin, IP mode, and environment settings. User can add additional\n  # customizations to template and then rebuild the image used (build/build-local.sh).\n  local pod_subnet_disable=\"# \"\n  # TODO: May want to specify each of the plugins that require --pod-network-cidr\n  if [[ ${CNI_PLUGIN} != \"bridge\" && ${CNI_PLUGIN} != \"ptp\" ]]; then\n    pod_subnet_disable=\"\"\n  fi\n  local bind_address=\"0.0.0.0\"\n  if [[ ${SERVICE_NET_MODE} = \"ipv6\" ]]; then\n    bind_address=\"::\"\n  fi\n  dind::proxy \"$master_name\"\n  dind::custom-docker-opts \"$master_name\"\n\n  # HACK: Indicating mode, so that wrapkubeadm will not set a cluster CIDR for kube-proxy\n  # in IPv6 (only) mode.\n  if [[ ${SERVICE_NET_MODE} = \"ipv6\" ]]; then\n    docker exec --privileged -i \"$master_name\" touch /v6-mode\n  fi\n\n  feature_gates=\"{CoreDNS: false}\"\n  if [[ ${DNS_SERVICE} == \"coredns\" ]]; then\n    feature_gates=\"{CoreDNS: true}\"\n  fi\n\n  kubeadm_version=\"$(dind::kubeadm-version)\"\n  case \"${kubeadm_version}\" in\n    1\\.12\\.*)\n      template=\"1.12\"\n      ;;\n    *)  # Includes 1.13 master branch\n      # Will make a separate template if/when it becomes incompatible\n      template=\"1.13\"\n      # CoreDNS can no longer be switched off\n      feature_gates=\"{}\"\n      ;;\n  esac\n  dind::check-dns-service-type\n\n  local kubelet_version_specific_flags=()\n  local cmp_kubelet_to_1_15=0\n  dind::compare-versions 'kubelet' \"$(dind::kubelet-version)\" 1 15 || cmp_kubelet_to_1_15=$?\n  if [[ \"$cmp_kubelet_to_1_15\" == 2 ]]; then\n    # this option got deprecated in v 1.15\n    kubelet_version_specific_flags+=('--allow-privileged=true')\n  fi\n  # explicit conversion to a string is needed, as calling ${arr[@]} or ${arr[*]}\n  # on an empty array will trigger an error on bash < 4.4 (and Travis is 4.3...)\n  local kubelet_version_specific_flags_as_str=''\n  if [[ ${#kubelet_version_specific_flags[@]} -gt 0 ]]; then\n    kubelet_version_specific_flags_as_str=\"${kubelet_version_specific_flags[*]}\"\n  fi\n  dind::set-version-specific-flags \"$kubelet_version_specific_flags_as_str\"\n\n  component_feature_gates=\"\"\n  if [ \"${FEATURE_GATES}\" != \"none\" ]; then\n    component_feature_gates=\"feature-gates: \\\\\\\"${FEATURE_GATES}\\\\\\\"\"\n  fi\n\n  apiserver_extra_args=\"\"\n  for e in $(set -o posix ; set | grep -E \"^APISERVER_[a-z_]+=\" | cut -d'=' -f 1); do\n    opt_name=$(echo ${e#APISERVER_} | sed 's/_/-/g')\n    apiserver_extra_args+=\"    ${opt_name}: \\\\\\\"$(eval echo \\$$e)\\\\\\\"\\\\n\"\n  done\n\n  controller_manager_extra_args=\"\"\n  for e in $(set -o posix ; set | grep -E \"^CONTROLLER_MANAGER_[a-z_]+=\" | cut -d'=' -f 1); do\n    opt_name=$(echo ${e#CONTROLLER_MANAGER_} | sed 's/_/-/g')\n    controller_manager_extra_args+=\"    ${opt_name}: \\\\\\\"$(eval echo \\$$e)\\\\\\\"\\\\n\"\n  done\n\n  scheduler_extra_args=\"\"\n  for e in $(set -o posix ; set | grep -E \"^SCHEDULER_[a-z_]+=\" | cut -d'=' -f 1); do\n    opt_name=$(echo ${e#SCHEDULER_} | sed 's/_/-/g')\n    scheduler_extra_args+=\"    ${opt_name}: \\\\\\\"$(eval echo \\$$e)\\\\\\\"\\\\n\"\n  done\n\n  local mgmt_cidr=${mgmt_net_cidrs[0]}\n  if [[ ${IP_MODE} = \"dual-stack\" && ${SERVICE_NET_MODE} = \"ipv6\" ]]; then\n      mgmt_cidr=${mgmt_net_cidrs[1]}\n  fi\n  local master_ip=$( dind::make-ip-from-cidr ${mgmt_cidr} 2 )\n  docker exec -i \"$master_name\" bash <<EOF\nsed -e \"s|{{ADV_ADDR}}|${master_ip}|\" \\\n    -e \"s|{{POD_SUBNET_DISABLE}}|${pod_subnet_disable}|\" \\\n    -e \"s|{{POD_NETWORK_CIDR}}|${pod_net_cidrs[0]}|\" \\\n    -e \"s|{{SVC_SUBNET}}|${SERVICE_CIDR}|\" \\\n    -e \"s|{{BIND_ADDR}}|${bind_address}|\" \\\n    -e \"s|{{BIND_PORT}}|${INTERNAL_APISERVER_PORT}|\" \\\n    -e \"s|{{FEATURE_GATES}}|${feature_gates}|\" \\\n    -e \"s|{{KUBEADM_VERSION}}|${kubeadm_version}|\" \\\n    -e \"s|{{COMPONENT_FEATURE_GATES}}|${component_feature_gates}|\" \\\n    -e \"s|{{APISERVER_EXTRA_ARGS}}|${apiserver_extra_args}|\" \\\n    -e \"s|{{CONTROLLER_MANAGER_EXTRA_ARGS}}|${controller_manager_extra_args}|\" \\\n    -e \"s|{{SCHEDULER_EXTRA_ARGS}}|${scheduler_extra_args}|\" \\\n    -e \"s|{{KUBE_MASTER_NAME}}|${master_name}|\" \\\n    -e \"s|{{DNS_SVC_IP}}|${DNS_SVC_IP}|\" \\\n    -e \"s|{{CRI_SOCKET}}|${CRI_SOCKET}|\" \\\n    /etc/kubeadm.conf.${template}.tmpl > /etc/kubeadm.conf\nEOF\n  init_args=(--config /etc/kubeadm.conf)\n  # required when building from source\n  if [[ ${BUILD_KUBEADM} || ${BUILD_HYPERKUBE} ]]; then\n    docker exec \"$master_name\" mount --make-shared /k8s\n  fi\n  dind::kubeadm \"${container_id}\" init \"${init_args[@]}\" --ignore-preflight-errors=all \"$@\"\n  kubeadm_join_flags=\"$(docker exec \"${container_id}\" kubeadm token create --print-join-command | sed 's/^kubeadm join //')\"\n  dind::configure-kubectl\n  dind::start-port-forwarder\n}\n\nfunction dind::create-node-container {\n  local reuse_volume next_node_index node_name\n  reuse_volume=''\n  if [[ ${1:-} = -r ]]; then\n    reuse_volume=\"-r\"\n    shift\n  fi\n  # if there's just one node currently, it's master, thus we need to use\n  # kube-node-1 hostname, if there are two nodes, we should pick\n  # kube-node-2 and so on\n  next_node_index=${1:-$(docker ps -q --filter=label=\"${DIND_LABEL}\" | wc -l | sed 's/^ *//g')}\n  local -a opts\n  if [[ ${BUILD_KUBEADM} || ${BUILD_HYPERKUBE} ]]; then\n    opts+=(-v \"dind-k8s-binaries$(dind::cluster-suffix)\":/k8s)\n    if [[ ${BUILD_KUBEADM} ]]; then\n      opts+=(-e KUBEADM_SOURCE=build://)\n    fi\n    if [[ ${BUILD_HYPERKUBE} ]]; then\n      opts+=(-e HYPERKUBE_SOURCE=build://)\n    fi\n  fi\n  node_name=\"$(dind::node-name ${next_node_index})\"\n  dind::run ${reuse_volume} \"$node_name\" $((next_node_index + 1)) \"${EXTRA_PORTS}\" ${opts[@]+\"${opts[@]}\"}\n}\n\nfunction dind::join {\n  local container_id=\"$1\"\n  shift\n  dind::proxy \"${container_id}\"\n  dind::custom-docker-opts \"${container_id}\"\n  local -a join_opts=(--ignore-preflight-errors=all\n                      --cri-socket=\"${CRI_SOCKET}\")\n  dind::kubeadm \"${container_id}\" join \"${join_opts[@]}\" \"$@\" >/dev/null\n}\n\nfunction dind::escape-e2e-name {\n    sed 's/[]\\$*.^()[]/\\\\&/g; s/\\s\\+/\\\\s+/g' <<< \"$1\" | tr -d '\\n'\n}\n\nfunction dind::accelerate-kube-dns {\n  if [[ ${DNS_SERVICE} == \"kube-dns\" ]]; then\n     dind::step \"Patching kube-dns deployment to make it start faster\"\n     # Could do this on the host, too, but we don't want to require jq here\n     # TODO: do this in wrapkubeadm\n     docker exec \"$(dind::master-name)\" /bin/bash -c \\\n        \"kubectl get deployment kube-dns -n kube-system -o json | jq '.spec.template.spec.containers[0].readinessProbe.initialDelaySeconds = 3|.spec.template.spec.containers[0].readinessProbe.periodSeconds = 3' | kubectl apply --force -f -\"\n fi\n}\n\nfunction dind::component-ready {\n  local label=\"$1\"\n  local out\n  if ! out=\"$(\"${kubectl}\" --context \"$(dind::context-name)\" get pod -l \"${label}\" -n kube-system \\\n                           -o jsonpath='{ .items[*].status.conditions[?(@.type == \"Ready\")].status }' 2>/dev/null)\"; then\n    return 1\n  fi\n  if ! grep -v False <<<\"${out}\" | grep -q True; then\n    return 1\n  fi\n  return 0\n}\n\nfunction dind::kill-failed-pods {\n  local pods ctx\n  ctx=\"$(dind::context-name)\"\n  # workaround for https://github.com/kubernetes/kubernetes/issues/36482\n  if ! pods=\"$(kubectl --context \"$ctx\" get pod -n kube-system -o jsonpath='{ .items[?(@.status.phase == \"Failed\")].metadata.name }' 2>/dev/null)\"; then\n    return\n  fi\n  for name in ${pods}; do\n    kubectl --context \"$ctx\" delete pod --now -n kube-system \"${name}\" >&/dev/null || true\n  done\n}\n\nfunction dind::create-static-routes {\n  echo \"Creating static routes for bridge/PTP plugin\"\n  for ((i=0; i <= NUM_NODES; i++)); do\n    if [[ ${i} -eq 0 ]]; then\n      node=\"$(dind::master-name)\"\n    else\n      node=\"$(dind::node-name $i)\"\n    fi\n    for ((j=0; j <= NUM_NODES; j++)); do\n      if [[ ${i} -eq ${j} ]]; then\n        continue\n      fi\n      if [[ ${j} -eq 0 ]]; then\n        dest_node=\"$(dind::master-name)\"\n      else\n        dest_node=\"$(dind::node-name $j)\"\n      fi\n      id=$((${j}+1))\n      if [[ ${IP_MODE} = \"ipv4\" || ${IP_MODE} = \"dual-stack\" ]]; then\n        # Assuming pod subnets will all be /24\n        dest=\"${pod_prefixes[0]}${id}.0/24\"\n        gw=`docker exec ${dest_node} ip addr show eth0 | grep -w inet | awk '{ print $2 }' | sed 's,/.*,,'`\n        docker exec \"${node}\" ip route add \"${dest}\" via \"${gw}\"\n      fi\n      if [[ ${IP_MODE} = \"ipv6\" || ${IP_MODE} = \"dual-stack\" ]]; then\n        local position=0\n        if [[ ${IP_MODE} = \"dual-stack\" ]]; then\n            position=1\n        fi\n        instance=$(printf \"%02x\" ${id})\n        if [[ $((${pod_sizes[$position]} % 16)) -ne 0 ]]; then\n          instance+=\"00\" # Move node ID to upper byte\n        fi\n        dest=\"${pod_prefixes[$position]}${instance}::/${pod_sizes[$position]}\"\n        gw=`docker exec ${dest_node} ip addr show eth0 | grep -w inet6 | grep -i global | head -1 | awk '{ print $2 }' | sed 's,/.*,,'`\n        docker exec \"${node}\" ip route add \"${dest}\" via \"${gw}\"\n      fi\n    done\n  done\n}\n\n# If we are allowing AAAA record use, then provide SNAT for IPv6 packets from\n# node containers, and forward packets to bridge used for $(dind::net-name).\n# This gives pods access to external IPv6 sites, when using IPv6 addresses.\nfunction dind::setup_external_access_on_host {\n  if [[ ! ${DIND_ALLOW_AAAA_USE} ]]; then\n    return\n  fi\n  local main_if=`ip route | grep default | awk '{print $5}'`\n  dind::ip6tables-on-hostnet -t nat -A POSTROUTING -o $main_if -j MASQUERADE\n  if [[ ${IP_MODE} = \"dual-stack\" ]]; then\n    return\n  fi\n  local bridge_if=`ip route | grep ${NAT64_V4_SUBNET_PREFIX}.0.0 | awk '{print $3}'`\n  if [[ -n \"$bridge_if\" ]]; then\n    dind::ip6tables-on-hostnet -A FORWARD -i $bridge_if -j ACCEPT\n  else\n    echo \"WARNING! No $(dind::net-name) bridge with NAT64 - unable to setup forwarding/SNAT\"\n  fi\n}\n\n# Remove ip6tables rules for SNAT and forwarding, if they exist.\nfunction dind::remove_external_access_on_host {\n  if [[ ! ${DIND_ALLOW_AAAA_USE} ]]; then\n    return\n  fi\n  local have_rule\n  local main_if=\"$(ip route | grep default | awk '{print $5}')\"\n  have_rule=\"$(dind::ip6tables-on-hostnet -S -t nat | grep \"\\-o $main_if\" || true)\"\n  if [[ -n \"$have_rule\" ]]; then\n    dind::ip6tables-on-hostnet -t nat -D POSTROUTING -o $main_if -j MASQUERADE\n  else\n    echo \"Skipping delete of ip6tables rule for SNAT, as rule non-existent\"\n  fi\n\n  if [[ ${IP_MODE} = \"dual-stack\" ]]; then\n    return\n  fi\n  local bridge_if=\"$(ip route | grep ${NAT64_V4_SUBNET_PREFIX}.0.0 | awk '{print $3}')\"\n  if [[ -n \"$bridge_if\" ]]; then\n    have_rule=\"$(dind::ip6tables-on-hostnet -S | grep \"\\-i $bridge_if\" || true)\"\n    if [[ -n \"$have_rule\" ]]; then\n      dind::ip6tables-on-hostnet -D FORWARD -i $bridge_if -j ACCEPT\n    else\n      echo \"Skipping delete of ip6tables rule for forwarding, as rule non-existent\"\n    fi\n  else\n    echo \"Skipping delete of ip6tables rule for forwarding, as no bridge interface using NAT64\"\n  fi\n}\n\nfunction dind::ip6tables-on-hostnet {\n  local mod_path='/lib/modules'\n  docker run -v \"${mod_path}:${mod_path}\" --entrypoint /sbin/ip6tables --net=host --rm --privileged \"${DIND_IMAGE}\" \"$@\"\n}\n\nfunction dind::component-ready-by-labels {\n  local labels=(\"$@\");\n  for label in ${labels[@]}; do\n    dind::component-ready \"${label}\" && return 0\n  done\n  return 1\n}\n\nfunction dind::wait-for-service-ready {\n  local service=$1\n  local labels=(\"${@:2}\")\n  local ctx=\"$(dind::context-name)\"\n\n  dind::step \"Bringing up ${service}\"\n  # on Travis 'scale' sometimes fails with 'error: Scaling the resource failed with: etcdserver: request timed out; Current resource version 442' here\n  dind::retry \"${kubectl}\" --context \"$ctx\" scale deployment --replicas=1 -n kube-system ${service}\n\n  local ntries=200\n  while ! dind::component-ready-by-labels ${labels[@]}; do\n    if ((--ntries == 0)); then\n      echo \"Error bringing up ${service}\" >&2\n      exit 1\n    fi\n    echo -n \".\" >&2\n    dind::kill-failed-pods\n    sleep 1\n  done\n  echo \"[done]\" >&2\n}\n\nfunction dind::wait-for-ready {\n  local app=\"kube-proxy\"\n  if [[ ${CNI_PLUGIN} = \"kube-router\" ]]; then\n    app=kube-router\n  fi\n  dind::step \"Waiting for ${app} and the nodes\"\n  local app_ready\n  local nodes_ready\n  local n=3\n  local ntries=200\n  local ctx\n  ctx=\"$(dind::context-name)\"\n  while true; do\n    dind::kill-failed-pods\n    if \"${kubectl}\" --context \"$ctx\" get nodes 2>/dev/null | grep -q NotReady; then\n      nodes_ready=\n    else\n      nodes_ready=y\n    fi\n    if dind::component-ready k8s-app=${app}; then\n      app_ready=y\n    else\n      app_ready=\n    fi\n    if [[ ${nodes_ready} && ${app_ready} ]]; then\n      if ((--n == 0)); then\n        echo \"[done]\" >&2\n        break\n      fi\n    else\n      n=3\n    fi\n    if ((--ntries == 0)); then\n      echo \"Error waiting for ${app} and the nodes\" >&2\n      exit 1\n    fi\n    echo -n \".\" >&2\n    sleep 1\n  done\n\n  dind::wait-for-service-ready ${DNS_SERVICE} \"k8s-app=kube-dns\"\n\n  if [[ ! ${SKIP_DASHBOARD} ]]; then\n    local service=\"kubernetes-dashboard\"\n    dind::wait-for-service-ready ${service} \"app=${service}\" \"k8s-app=${service}\"\n  fi\n\n  dind::retry \"${kubectl}\" --context \"$ctx\" get nodes >&2\n\n  if [[ ! ${SKIP_DASHBOARD} ]]; then\n    local local_host\n    local_host=\"$( dind::localhost )\"\n    local base_url=\"http://${local_host}:$(dind::apiserver-port)/api/v1/namespaces/kube-system/services\"\n    dind::step \"Access dashboard at:\" \"${base_url}/kubernetes-dashboard:/proxy\"\n    dind::step \"Access dashboard at:\" \"${base_url}/https:kubernetes-dashboard:/proxy (if version>1.6 and HTTPS enabled)\"\n  fi\n}\n\n# dind::make-kube-router-yaml creates a temp file with contents of the configuration needed for the kube-router CNI\n# plugin at a specific version, instead of using the publically available file, which uses the latest version. This\n# allows us to control the version used. If/when updating, be sure to update the KUBE_ROUTER_VERSION env variable\n# ensure the YAML contents below, reflect the configuration in:\n#\n# https://raw.githubusercontent.com/cloudnativelabs/kube-router/master/daemonset/kubeadm-kuberouter-all-feature.yaml\n#\n# FUTURE: May be able to remove this, if/when kube-router \"latest\" is stable, and use the public YAML file instead.\nfunction dind::make-kube-router-yaml {\n  tmp_yaml=$(mktemp /tmp/kube-router-yaml.XXXXXX)\n  cat >${tmp_yaml} <<KUBE_ROUTER_YAML\napiVersion: v1\nkind: ConfigMap\nmetadata:\n  name: kube-router-cfg\n  namespace: kube-system\n  labels:\n    tier: node\n    k8s-app: kube-router\ndata:\n  cni-conf.json: |\n    {\n      \"name\":\"kubernetes\",\n      \"type\":\"bridge\",\n      \"bridge\":\"kube-bridge\",\n      \"isDefaultGateway\":true,\n      \"ipam\": {\n        \"type\":\"host-local\"\n      }\n    }\n---\napiVersion: extensions/v1beta1\nkind: DaemonSet\nmetadata:\n  labels:\n    k8s-app: kube-router\n    tier: node\n  name: kube-router\n  namespace: kube-system\nspec:\n  template:\n    metadata:\n      labels:\n        k8s-app: kube-router\n        tier: node\n      annotations:\n        scheduler.alpha.kubernetes.io/critical-pod: ''\n    spec:\n      serviceAccountName: kube-router\n      serviceAccount: kube-router\n      containers:\n      - name: kube-router\n        image: cloudnativelabs/kube-router:${KUBE_ROUTER_VERSION}\n        imagePullPolicy: Always\n        args:\n        - --run-router=true\n        - --run-firewall=true\n        - --run-service-proxy=true\n        - --kubeconfig=/var/lib/kube-router/kubeconfig\n        env:\n        - name: NODE_NAME\n          valueFrom:\n            fieldRef:\n              fieldPath: spec.nodeName\n        livenessProbe:\n          httpGet:\n            path: /healthz\n            port: 20244\n          initialDelaySeconds: 10\n          periodSeconds: 3\n        resources:\n          requests:\n            cpu: 250m\n            memory: 250Mi\n        securityContext:\n          privileged: true\n        volumeMounts:\n        - name: lib-modules\n          mountPath: /lib/modules\n          readOnly: true\n        - name: cni-conf-dir\n          mountPath: /etc/cni/net.d\n        - name: kubeconfig\n          mountPath: /var/lib/kube-router\n          readOnly: true\n      initContainers:\n      - name: install-cni\n        image: busybox\n        imagePullPolicy: Always\n        command:\n        - /bin/sh\n        - -c\n        - set -e -x;\n          if [ ! -f /etc/cni/net.d/10-kuberouter.conf ]; then\n            TMP=/etc/cni/net.d/.tmp-kuberouter-cfg;\n            cp /etc/kube-router/cni-conf.json \\${TMP};\n            mv \\${TMP} /etc/cni/net.d/10-kuberouter.conf;\n          fi\n        volumeMounts:\n        - name: cni-conf-dir\n          mountPath: /etc/cni/net.d\n        - name: kube-router-cfg\n          mountPath: /etc/kube-router\n      hostNetwork: true\n      tolerations:\n      - key: CriticalAddonsOnly\n        operator: Exists\n      - effect: NoSchedule\n        key: node-role.kubernetes.io/master\n        operator: Exists\n      volumes:\n      - name: lib-modules\n        hostPath:\n          path: /lib/modules\n      - name: cni-conf-dir\n        hostPath:\n          path: /etc/cni/net.d\n      - name: kube-router-cfg\n        configMap:\n          name: kube-router-cfg\n      - name: kubeconfig\n        configMap:\n          name: kube-proxy\n          items:\n          - key: kubeconfig.conf\n            path: kubeconfig\n---\napiVersion: v1\nkind: ServiceAccount\nmetadata:\n  name: kube-router\n  namespace: kube-system\n---\nkind: ClusterRole\napiVersion: rbac.authorization.k8s.io/v1beta1\nmetadata:\n  name: kube-router\n  namespace: kube-system\nrules:\n  - apiGroups:\n    - \"\"\n    resources:\n      - namespaces\n      - pods\n      - services\n      - nodes\n      - endpoints\n    verbs:\n      - list\n      - get\n      - watch\n  - apiGroups:\n    - \"networking.k8s.io\"\n    resources:\n      - networkpolicies\n    verbs:\n      - list\n      - get\n      - watch\n  - apiGroups:\n    - extensions\n    resources:\n      - networkpolicies\n    verbs:\n      - get\n      - list\n      - watch\n---\nkind: ClusterRoleBinding\napiVersion: rbac.authorization.k8s.io/v1beta1\nmetadata:\n  name: kube-router\nroleRef:\n  apiGroup: rbac.authorization.k8s.io\n  kind: ClusterRole\n  name: kube-router\nsubjects:\n- kind: ServiceAccount\n  name: kube-router\n  namespace: kube-system\nKUBE_ROUTER_YAML\n  echo $tmp_yaml\n}\n\nfunction dind::up {\n  dind::down\n  dind::init\n  local ctx\n  ctx=\"$(dind::context-name)\"\n  # pre-create node containers sequentially so they get predictable IPs\n  local -a node_containers\n  for ((n=1; n <= NUM_NODES; n++)); do\n    dind::step \"Starting node container:\" ${n}\n    if ! container_id=\"$(dind::create-node-container ${n})\"; then\n      echo >&2 \"*** Failed to start node container ${n}\"\n      exit 1\n    else\n      node_containers+=(${container_id})\n      dind::step \"Node container started:\" ${n}\n    fi\n  done\n  dind::fix-mounts\n  status=0\n  local -a pids\n  for ((n=1; n <= NUM_NODES; n++)); do\n    (\n      dind::step \"Joining node:\" ${n}\n      container_id=\"${node_containers[${n}-1]}\"\n      if ! dind::join ${container_id} ${kubeadm_join_flags}; then\n        echo >&2 \"*** Failed to start node container ${n}\"\n        exit 1\n      else\n        dind::step \"Node joined:\" ${n}\n      fi\n    )&\n    pids[${n}]=$!\n  done\n  if ((NUM_NODES > 0)); then\n    for pid in ${pids[*]}; do\n      wait ${pid}\n    done\n  else\n    # FIXME: this may fail depending on k8s/kubeadm version\n    # FIXME: check for taint & retry if it's there\n    \"${kubectl}\" --context \"$ctx\" taint nodes $(dind::master-name) node-role.kubernetes.io/master- || true\n  fi\n  case \"${CNI_PLUGIN}\" in\n    bridge | ptp)\n      dind::create-static-routes\n      dind::setup_external_access_on_host\n      ;;\n    flannel)\n      # without --validate=false this will fail on older k8s versions\n      dind::retry \"${kubectl}\" --context \"$ctx\" apply --validate=false -f \"https://github.com/coreos/flannel/blob/master/Documentation/kube-flannel.yml?raw=true\"\n      ;;\n    calico)\n      manifest_base=https://docs.projectcalico.org/${CALICO_VERSION:-v3.3}/getting-started/kubernetes/installation\n      dind::retry \"${kubectl}\" --context \"$ctx\" apply -f ${manifest_base}/hosted/etcd.yaml\n      if [ \"${CALICO_VERSION:-v3.3}\" != master ]; then\n        dind::retry \"${kubectl}\" --context \"$ctx\" apply -f ${manifest_base}/rbac.yaml\n      fi\n      dind::retry \"${kubectl}\" --context \"$ctx\" apply -f ${manifest_base}/hosted/calico.yaml\n      dind::retry \"${kubectl}\" --context \"$ctx\" apply -f ${manifest_base}/hosted/calicoctl.yaml\n      ;;\n    calico-kdd)\n      manifest_base=https://docs.projectcalico.org/${CALICO_VERSION:-v3.3}/getting-started/kubernetes/installation\n      dind::retry \"${kubectl}\" --context \"$ctx\" apply -f ${manifest_base}/hosted/rbac-kdd.yaml\n      dind::retry \"${kubectl}\" --context \"$ctx\" apply -f ${manifest_base}/hosted/kubernetes-datastore/calico-networking/1.7/calico.yaml\n      ;;\n    weave)\n      dind::retry \"${kubectl}\" --context \"$ctx\" apply -f \"https://cloud.weave.works/k8s/net?k8s-version=$(${kubectl} --context \"$ctx\" version | base64 | tr -d '\\n')\"\n      ;;\n    kube-router)\n      kube_router_config=\"$( dind::make-kube-router-yaml )\"\n      dind::retry \"${kubectl}\" --context \"$ctx\" apply -f ${kube_router_config}\n      rm \"${kube_router_config}\"\n      dind::retry \"${kubectl}\" --context \"$ctx\" -n kube-system delete ds kube-proxy\n      docker run --privileged --net=host k8s.gcr.io/kube-proxy-amd64:v1.10.2 kube-proxy --cleanup\n      ;;\n    *)\n      echo \"Unsupported CNI plugin '${CNI_PLUGIN}'\" >&2\n      ;;\n  esac\n\n  if [[ ! ${SKIP_DASHBOARD} ]]; then\n    dind::deploy-dashboard\n  fi\n\n  dind::accelerate-kube-dns\n  if [[ (${CNI_PLUGIN} != \"bridge\" && ${CNI_PLUGIN} != \"ptp\") || ${SKIP_SNAPSHOT} ]]; then\n    # This is especially important in case of Calico -\n    # the cluster will not recover after snapshotting\n    # (at least not after restarting from the snapshot)\n    # if Calico installation is interrupted\n    dind::wait-for-ready\n  fi\n  dind::step \"Cluster Info\"\n  echo \"Network Mode: ${IP_MODE}\"\n  echo \"Cluster context: $( dind::context-name )\"\n  echo \"Cluster ID: ${CLUSTER_ID}\"\n  echo \"Management CIDR(s): ${mgmt_net_cidrs[@]}\"\n  echo \"Service CIDR/mode: ${SERVICE_CIDR}/${SERVICE_NET_MODE}\"\n  echo \"Pod CIDR(s): ${pod_net_cidrs[@]}\"\n}\n\nfunction dind::fix-mounts {\n  local node_name\n  for ((n=0; n <= NUM_NODES; n++)); do\n    node_name=\"$(dind::master-name)\"\n    if ((n > 0)); then\n      node_name=\"$(dind::node-name $n)\"\n    fi\n    docker exec \"${node_name}\" mount --make-shared /run\n    if [[ ! ${using_linuxkit} ]]; then\n      docker exec \"${node_name}\" mount --make-shared /lib/modules/\n    fi\n    # required when building from source\n    if [[ ${BUILD_KUBEADM} || ${BUILD_HYPERKUBE} ]]; then\n      docker exec \"${node_name}\" mount --make-shared /k8s\n    fi\n    # docker exec \"${node_name}\" mount --make-shared /sys/kernel/debug\n  done\n}\n\nfunction dind::snapshot_container {\n  local container_name=\"$1\"\n  # we must pass DIND_CRI here because in case of containerd\n  # a special care must be taken to stop the containers during\n  # the snapshot\n  docker exec -e DIND_CRI=\"${DIND_CRI}\" -i ${container_name} \\\n         /usr/local/bin/snapshot prepare\n  # remove the hidden *plnk directories\n  docker diff ${container_name} | grep -v plnk | docker exec -i ${container_name} /usr/local/bin/snapshot save\n}\n\nfunction dind::snapshot {\n  dind::step \"Taking snapshot of the cluster\"\n  dind::snapshot_container \"$(dind::master-name)\"\n  for ((n=1; n <= NUM_NODES; n++)); do\n    dind::snapshot_container \"$(dind::node-name $n)\"\n  done\n  dind::wait-for-ready\n}\n\nrestore_cmd=restore\nfunction dind::restore_container {\n  local container_id=\"$1\"\n  docker exec ${container_id} /usr/local/bin/snapshot \"${restore_cmd}\"\n}\n\nfunction dind::restore {\n  local apiserver_port local_host pid pids\n  dind::down\n  dind::check-dns-service-type\n  dind::step \"Restoring containers\"\n  dind::set-master-opts\n  local_host=\"$( dind::localhost )\"\n  apiserver_port=\"$( dind::apiserver-port )\"\n  for ((n=0; n <= NUM_NODES; n++)); do\n    (\n      if [[ n -eq 0 ]]; then\n        dind::step \"Restoring master container\"\n        dind::restore_container \"$(dind::run -r \"$(dind::master-name)\" 1 \"${local_host}:${apiserver_port}:${INTERNAL_APISERVER_PORT}\" ${master_opts[@]+\"${master_opts[@]}\"})\"\n        dind::verify-image-compatibility \"$(dind::master-name)\"\n        dind::step \"Master container restored\"\n      else\n        dind::step \"Restoring node container:\" ${n}\n        if ! container_id=\"$(dind::create-node-container -r ${n})\"; then\n          echo >&2 \"*** Failed to start node container ${n}\"\n          exit 1\n        else\n          dind::restore_container \"${container_id}\"\n          dind::step \"Node container restored:\" ${n}\n        fi\n      fi\n    )&\n    pids[${n}]=$!\n  done\n  for pid in ${pids[*]}; do\n    wait ${pid}\n  done\n  if [[ ${CNI_PLUGIN} = \"bridge\" || ${CNI_PLUGIN} = \"ptp\" ]]; then\n    dind::create-static-routes\n    dind::setup_external_access_on_host\n  fi\n  dind::fix-mounts\n  # Recheck kubectl config. It's possible that the cluster was started\n  # on this docker from different host\n  dind::configure-kubectl\n  dind::start-port-forwarder\n  dind::wait-for-ready\n}\n\nfunction dind::docker-action {\n  action=$1\n  docker $action \"$(dind::master-name)\"\n  for ((n=1; n <= NUM_NODES; n++)); do\n    docker $action \"$(dind::node-name $n)\"\n  done\n}\nfunction dind::pause {\n  dind::step \"Pausing the cluster\"\n  dind::docker-action pause\n}\n\nfunction dind::unpause {\n  dind::step \"Unpausing the cluster\"\n  dind::docker-action unpause\n}\n\nfunction dind::down {\n  dind::remove-images \"${DIND_LABEL}\"\n  if [[ ${CNI_PLUGIN} = \"bridge\" || ${CNI_PLUGIN} = \"ptp\" ]]; then\n    dind::remove_external_access_on_host\n  elif [[ \"${CNI_PLUGIN}\" = \"kube-router\" ]]; then\n    if [[ ${COMMAND} = \"down\" || ${COMMAND} = \"clean\" ]]; then\n      # FUTURE: Updated pinned version, after verifying operation\n      docker run --privileged --net=host cloudnativelabs/kube-router:${KUBE_ROUTER_VERSION} --cleanup-config\n    fi\n  fi\n}\n\nfunction dind::apiserver-port {\n  # APISERVER_PORT is explicitely set\n  if [ -n \"${APISERVER_PORT:-}\" ]\n  then\n    echo \"$APISERVER_PORT\"\n    return\n  fi\n\n  # Get the port from the master\n  local master port\n  master=\"$(dind::master-name)\"\n  # 8080/tcp -> 127.0.0.1:8082  =>  8082\n  port=\"$( docker port \"$master\" 2>/dev/null | awk -F: \"/^${INTERNAL_APISERVER_PORT}/{ print \\$NF }\" )\"\n  if [ -n \"$port\" ]\n  then\n    APISERVER_PORT=\"$port\"\n    echo \"$APISERVER_PORT\"\n    return\n  fi\n\n  # get a random free port\n  APISERVER_PORT=0\n  echo \"$APISERVER_PORT\"\n}\n\nfunction dind::master-name {\n  echo \"kube-master$( dind::cluster-suffix )\"\n}\n\nfunction dind::node-name {\n  local nr=\"$1\"\n  echo \"kube-node-${nr}$( dind::cluster-suffix )\"\n}\n\nfunction dind::context-name {\n  echo \"dind$( dind::cluster-suffix )\"\n}\n\nfunction dind::remove-volumes {\n  # docker 1.13+: docker volume ls -q -f label=\"${DIND_LABEL}\"\n  local nameRE\n  nameRE=\"^kubeadm-dind-(sys|kube-master|kube-node-[0-9]+)$(dind::cluster-suffix)$\"\n  docker volume ls -q | (grep -E \"$nameRE\" || true) | while read -r volume_id; do\n    dind::step \"Removing volume:\" \"${volume_id}\"\n    docker volume rm \"${volume_id}\"\n  done\n}\n\nfunction dind::remove-images {\n  local which=$1\n  docker ps -a -q --filter=label=\"${which}\" | while read container_id; do\n    dind::step \"Removing container:\" \"${container_id}\"\n    docker rm -fv \"${container_id}\"\n  done\n}\n\nfunction dind::remove-cluster {\n  cluster_name=\"dind$(dind::cluster-suffix)\"\n  if ${kubectl} config get-clusters | grep -qE \"^${cluster_name}$\"; then\n    dind::step \"Removing cluster from config:\" \"${cluster_name}\"\n    ${kubectl} config delete-cluster ${cluster_name} 2>/dev/null || true\n  fi\n}\n\nfunction dind::remove-context {\n  context_name=\"$(dind::context-name)\"\n  if ${kubectl} config get-contexts | grep -qE \"${context_name}\\\\s\"; then\n    dind::step \"Removing context from config:\" \"${context_name}\"\n    ${kubectl} config delete-context ${context_name} 2>/dev/null || true\n  fi\n}\n\nfunction dind::start-port-forwarder {\n  local fwdr port\n  fwdr=\"${DIND_PORT_FORWARDER:-}\"\n\n  [ -n \"$fwdr\" ] || return 0\n\n  [ -x \"$fwdr\" ] || {\n    echo \"'${fwdr}' is not executable.\" >&2\n    return 1\n  }\n\n  port=\"$( dind::apiserver-port )\"\n  dind::step \"+ Setting up port-forwarding for :${port}\"\n  \"$fwdr\" \"$port\"\n}\n\nfunction dind::check-for-snapshot {\n  if ! dind::volume-exists \"kubeadm-dind-$(dind::master-name)\"; then\n    return 1\n  fi\n  for ((n=1; n <= NUM_NODES; n++)); do\n    if ! dind::volume-exists \"kubeadm-dind-$(dind::node-name ${n})\"; then\n      return 1\n    fi\n  done\n}\n\nfunction dind::do-run-e2e {\n  local parallel=\"${1:-}\"\n  local focus=\"${2:-}\"\n  local skip=\"${3:-}\"\n  local host=\"$(dind::localhost)\"\n  if [[ -z \"$using_local_linuxdocker\" ]]; then\n    host=\"127.0.0.1\"\n  fi\n  dind::need-source\n  local kubeapi test_args term=\n  local -a e2e_volume_opts=()\n  kubeapi=\"http://${host}:$(dind::apiserver-port)\"\n  test_args=\"--host=${kubeapi}\"\n  if [[ ${focus} ]]; then\n    test_args=\"--ginkgo.focus=${focus} ${test_args}\"\n  fi\n  if [[ ${skip} ]]; then\n    test_args=\"--ginkgo.skip=${skip} ${test_args}\"\n  fi\n  if [[ ${E2E_REPORT_DIR} ]]; then\n    test_args=\"--report-dir=/report ${test_args}\"\n    e2e_volume_opts=(-v \"${E2E_REPORT_DIR}:/report\")\n  fi\n  dind::make-for-linux n \"cmd/kubectl test/e2e/e2e.test vendor/github.com/onsi/ginkgo/ginkgo\"\n  dind::step \"Running e2e tests with args:\" \"${test_args}\"\n  dind::set-build-volume-args\n  if [ -t 1 ] ; then\n    term=\"-it\"\n    test_args=\"--ginkgo.noColor --num-nodes=2 ${test_args}\"\n  fi\n  docker run \\\n         --rm ${term} \\\n         --net=host \\\n         \"${build_volume_args[@]}\" \\\n         -e KUBERNETES_PROVIDER=dind \\\n         -e KUBE_MASTER_IP=\"${kubeapi}\" \\\n         -e KUBE_MASTER=local \\\n         -e KUBERNETES_CONFORMANCE_TEST=y \\\n         -e GINKGO_PARALLEL=${parallel} \\\n         ${e2e_volume_opts[@]+\"${e2e_volume_opts[@]}\"} \\\n         -w /go/src/k8s.io/kubernetes \\\n         \"${e2e_base_image}\" \\\n         bash -c \"cluster/kubectl.sh config set-cluster dind --server='${kubeapi}' --insecure-skip-tls-verify=true &&\n         cluster/kubectl.sh config set-context dind --cluster=dind &&\n         cluster/kubectl.sh config use-context dind &&\n         go run hack/e2e.go -- --v 6 --test --check-version-skew=false --test_args='${test_args}'\"\n}\n\nfunction dind::clean {\n  dind::ensure-downloaded-kubectl\n  dind::down\n  dind::remove-images \"dind-support$( dind::cluster-suffix )\"\n  dind::remove-volumes\n  local net_name\n  net_name=\"$(dind::net-name)\"\n  if docker network inspect \"$net_name\" >&/dev/null; then\n    docker network rm \"$net_name\"\n  fi\n  dind::remove-cluster\n  dind::remove-context\n}\n\nfunction dind::copy-image {\n  local image=\"${2:-}\"\n  local image_path=\"/tmp/save_${image//\\//_}\"\n  if [[ -f \"${image_path}\" ]]; then\n    rm -fr \"${image_path}\"\n  fi\n  docker save \"${image}\" -o \"${image_path}\"\n  docker ps -a -q --filter=label=\"${DIND_LABEL}\" | while read container_id; do\n    cat \"${image_path}\" | docker exec -i \"${container_id}\" docker load\n  done\n  rm -fr \"${image_path}\"\n}\n\nfunction dind::run-e2e {\n  local focus=\"${1:-}\"\n  local skip=\"${2:-[Serial]}\"\n  skip=\"$(dind::escape-e2e-name \"${skip}\")\"\n  if [[ \"$focus\" ]]; then\n    focus=\"$(dind::escape-e2e-name \"${focus}\")\"\n  else\n    focus=\"\\[Conformance\\]\"\n  fi\n  local parallel=y\n  if [[ ${DIND_NO_PARALLEL_E2E} ]]; then\n    parallel=\n  fi\n  dind::do-run-e2e \"${parallel}\" \"${focus}\" \"${skip}\"\n}\n\nfunction dind::run-e2e-serial {\n  local focus=\"${1:-}\"\n  local skip=\"${2:-}\"\n  skip=\"$(dind::escape-e2e-name \"${skip}\")\"\n  dind::need-source\n  if [[ \"$focus\" ]]; then\n    focus=\"$(dind::escape-e2e-name \"${focus}\")\"\n  else\n    focus=\"\\[Serial\\].*\\[Conformance\\]\"\n  fi\n  dind::do-run-e2e n \"${focus}\" \"${skip}\"\n  # TBD: specify filter\n}\n\nfunction dind::step {\n  local OPTS=\"\"\n  if [ \"$1\" = \"-n\" ]; then\n    shift\n    OPTS+=\"-n\"\n  fi\n  GREEN=\"$1\"\n  shift\n  if [ -t 2 ] ; then\n    echo -e ${OPTS} \"\\x1B[97m* \\x1B[92m${GREEN}\\x1B[39m $*\" 1>&2\n  else\n    echo ${OPTS} \"* ${GREEN} $*\" 1>&2\n  fi\n}\n\nfunction dind::dump {\n  set +e\n  echo \"*** Dumping cluster state ***\"\n  for node in $(docker ps --format '{{.Names}}' --filter label=\"${DIND_LABEL}\"); do\n    for service in kubelet.service dindnet.service criproxy.service dockershim.service; do\n      if docker exec \"${node}\" systemctl is-enabled \"${service}\" >&/dev/null; then\n        echo \"@@@ service-${node}-${service}.log @@@\"\n        docker exec \"${node}\" systemctl status \"${service}\"\n        docker exec \"${node}\" journalctl -xe -n all -u \"${service}\"\n      fi\n    done\n    echo \"@@@ psaux-${node}.txt @@@\"\n    docker exec \"${node}\" ps auxww\n    echo \"@@@ dockerps-a-${node}.txt @@@\"\n    docker exec \"${node}\" docker ps -a\n    echo \"@@@ ip-a-${node}.txt @@@\"\n    docker exec \"${node}\" ip a\n    echo \"@@@ ip-r-${node}.txt @@@\"\n    docker exec \"${node}\" ip r\n  done\n  local ctx master_name\n  master_name=\"$(dind::master-name)\"\n  ctx=\"$(dind::context-name)\"\n  docker exec \"$master_name\" kubectl get pods --all-namespaces \\\n          -o go-template='{{range $x := .items}}{{range $x.spec.containers}}{{$x.spec.nodeName}}{{\" \"}}{{$x.metadata.namespace}}{{\" \"}}{{$x.metadata.name}}{{\" \"}}{{.name}}{{\"\\n\"}}{{end}}{{end}}' |\n    while read node ns pod container; do\n      echo \"@@@ pod-${node}-${ns}-${pod}--${container}.log @@@\"\n      docker exec \"$master_name\" kubectl logs -n \"${ns}\" -c \"${container}\" \"${pod}\"\n    done\n  echo \"@@@ kubectl-all.txt @@@\"\n  docker exec \"$master_name\" kubectl get all --all-namespaces -o wide\n  echo \"@@@ describe-all.txt @@@\"\n  docker exec \"$master_name\" kubectl describe all --all-namespaces\n  echo \"@@@ nodes.txt @@@\"\n  docker exec \"$master_name\" kubectl get nodes -o wide\n}\n\nfunction dind::dump64 {\n  echo \"%%% start-base64 %%%\"\n  dind::dump | docker exec -i \"$(dind::master-name)\" /bin/sh -c \"lzma | base64 -w 100\"\n  echo \"%%% end-base64 %%%\"\n}\n\nfunction dind::split-dump {\n  mkdir -p cluster-dump\n  cd cluster-dump\n  awk '!/^@@@ .* @@@$/{print >out}; /^@@@ .* @@@$/{out=$2}' out=/dev/null\n  ls -l\n}\n\nfunction dind::split-dump64 {\n  decode_opt=-d\n  if base64 --help | grep -q '^ *-D'; then\n    # Mac OS X\n    decode_opt=-D\n  fi\n  sed -n '/^%%% start-base64 %%%$/,/^%%% end-base64 %%%$/p' |\n    sed '1d;$d' |\n    base64 \"${decode_opt}\" |\n    lzma -dc |\n    dind::split-dump\n}\n\nfunction dind::proxy {\n  local container_id=\"$1\"\n  if [[ ${DIND_CA_CERT_URL} ]] ; then\n    dind::step \"+ Adding certificate on ${container_id}\"\n    docker exec ${container_id} /bin/sh -c \"cd /usr/local/share/ca-certificates; curl -sSO ${DIND_CA_CERT_URL}\"\n    docker exec ${container_id} update-ca-certificates\n  fi\n  if [[ \"${DIND_PROPAGATE_HTTP_PROXY}\" || \"${DIND_HTTP_PROXY}\" || \"${DIND_HTTPS_PROXY}\" || \"${DIND_NO_PROXY}\" ]]; then\n    dind::step \"+ Setting *_PROXY for docker service on ${container_id}\"\n    local proxy_env=\"[Service]\"$'\\n'\"Environment=\"\n    if [[ \"${DIND_PROPAGATE_HTTP_PROXY}\" ]]; then\n      # take *_PROXY values from container environment\n      proxy_env+=$(docker exec ${container_id} env | grep -i _proxy | awk '{ print \"\\\"\"$0\"\\\"\"}' | xargs -d'\\n')\n    else\n      if [[ \"${DIND_HTTP_PROXY}\" ]] ;  then proxy_env+=\"\\\"HTTP_PROXY=${DIND_HTTP_PROXY}\\\" \"; fi\n      if [[ \"${DIND_HTTPS_PROXY}\" ]] ; then proxy_env+=\"\\\"HTTPS_PROXY=${DIND_HTTPS_PROXY}\\\" \"; fi\n      if [[ \"${DIND_NO_PROXY}\" ]] ;    then proxy_env+=\"\\\"NO_PROXY=${DIND_NO_PROXY}\\\" \"; fi\n    fi\n    docker exec -i ${container_id} /bin/sh -c \"cat > /etc/systemd/system/docker.service.d/30-proxy.conf\" <<< \"${proxy_env}\"\n    docker exec ${container_id} systemctl daemon-reload\n    docker exec ${container_id} systemctl restart docker\n  fi\n}\n\nfunction dind::custom-docker-opts {\n  local container_id=\"$1\"\n  local -a jq=()\n  local got_changes=\"\"\n  if [[ ! -f ${DIND_DAEMON_JSON_FILE} ]] ; then\n    jq[0]=\"{}\"\n  else\n    jq+=(\"$(cat ${DIND_DAEMON_JSON_FILE})\")\n    if [[ ${DIND_DAEMON_JSON_FILE} != \"/etc/docker/daemon.json\" ]]; then\n      got_changes=1\n    fi\n  fi\n  if [[ ${DIND_REGISTRY_MIRROR} ]] ; then\n    dind::step \"+ Setting up registry mirror on ${container_id}\"\n    jq+=(\"{\\\"registry-mirrors\\\": [\\\"${DIND_REGISTRY_MIRROR}\\\"]}\")\n    got_changes=1\n  fi\n  if [[ ${DIND_INSECURE_REGISTRIES} ]] ; then\n    dind::step \"+ Setting up insecure-registries on ${container_id}\"\n    jq+=(\"{\\\"insecure-registries\\\": ${DIND_INSECURE_REGISTRIES}}\")\n    got_changes=1\n  fi\n  if [[ ${got_changes} ]] ; then\n    local json=$(IFS=\"+\"; echo \"${jq[*]}\")\n    docker exec -i ${container_id} /bin/sh -c \"mkdir -p /etc/docker && jq -n '${json}' > /etc/docker/daemon.json\"\n    docker exec ${container_id} systemctl daemon-reload\n    docker exec ${container_id} systemctl restart docker\n  fi\n}\n\nCOMMAND=\"${1:-}\"\n\ncase ${COMMAND} in\n  up)\n    if [[ ! ( ${DIND_IMAGE} =~ local ) && ! ${DIND_SKIP_PULL:-} ]]; then\n      dind::step \"Making sure DIND image is up to date\"\n      docker pull \"${DIND_IMAGE}\" >&2\n    fi\n\n    dind::prepare-sys-mounts\n    dind::ensure-kubectl\n    if [[ ${SKIP_SNAPSHOT} ]]; then\n      force_make_binaries=y dind::up\n    elif ! dind::check-for-snapshot; then\n      force_make_binaries=y dind::up\n      dind::snapshot\n    else\n      dind::restore\n    fi\n    ;;\n  reup)\n    dind::prepare-sys-mounts\n    dind::ensure-kubectl\n    if [[ ${SKIP_SNAPSHOT} ]]; then\n      force_make_binaries=y dind::up\n    elif ! dind::check-for-snapshot; then\n      force_make_binaries=y dind::up\n      dind::snapshot\n    else\n      force_make_binaries=y\n      restore_cmd=update_and_restore\n      dind::restore\n    fi\n    ;;\n  down)\n    dind::down\n    ;;\n  init)\n    shift\n    dind::prepare-sys-mounts\n    dind::ensure-kubectl\n    dind::init \"$@\"\n    ;;\n  join)\n    shift\n    dind::prepare-sys-mounts\n    dind::ensure-kubectl\n    dind::join \"$(dind::create-node-container)\" \"$@\"\n    ;;\n  pause)\n    shift\n    dind::pause\n    ;;\n  unpause)\n    shift\n    dind::unpause\n    ;;\n  snapshot)\n    shift\n    dind::snapshot\n    ;;\n  restore)\n    shift\n    dind::restore\n    ;;\n  clean)\n    dind::clean\n    ;;\n  copy-image)\n    dind::copy-image \"$@\"\n    ;;\n  e2e)\n    shift\n    dind::run-e2e \"$@\"\n    ;;\n  e2e-serial)\n    shift\n    dind::run-e2e-serial \"$@\"\n    ;;\n  dump)\n    dind::dump\n    ;;\n  dump64)\n    dind::dump64\n    ;;\n  split-dump)\n    dind::split-dump\n    ;;\n  split-dump64)\n    dind::split-dump64\n    ;;\n  apiserver-port)\n    dind::apiserver-port\n    ;;\n  *)\n    echo \"usage:\" >&2\n    echo \"  $0 up\" >&2\n    echo \"  $0 reup\" >&2\n    echo \"  $0 down\" >&2\n    echo \"  $0 init kubeadm-args...\" >&2\n    echo \"  $0 join kubeadm-args...\" >&2\n    echo \"  $0 clean\"\n    echo \"  $0 pause\"\n    echo \"  $0 unpause\"\n    echo \"  $0 snapshot\"\n    echo \"  $0 restore\"\n    echo \"  $0 copy-image [image_name]\" >&2\n    echo \"  $0 e2e [test-name-substring]\" >&2\n    echo \"  $0 e2e-serial [test-name-substring]\" >&2\n    echo \"  $0 dump\" >&2\n    echo \"  $0 dump64\" >&2\n    echo \"  $0 split-dump\" >&2\n    echo \"  $0 split-dump64\" >&2\n    exit 1\n    ;;\nesac\n"
        },
        {
          "name": "fixed",
          "type": "tree",
          "content": null
        },
        {
          "name": "gce-setup.sh",
          "type": "blob",
          "size": 2.279296875,
          "content": "#!/bin/bash\n# Copyright 2017 Mirantis\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nif [ $(uname) = Darwin ]; then\n  readlinkf(){ perl -MCwd -e 'print Cwd::abs_path shift' \"$1\";}\nelse\n  readlinkf(){ readlink -f \"$1\"; }\nfi\nDIND_ROOT=\"$(cd $(dirname \"$(readlinkf \"${BASH_SOURCE}\")\"); pwd)\"\nKUBE_DIND_GCE_PROJECT=\"${KUBE_DIND_GCE_PROJECT:-$(gcloud config list --format 'value(core.project)' 2>/dev/null)}\"\nKUBE_DIND_GCE_ZONE=\"${KUBE_DIND_GCE_ZONE:-$(gcloud config list --format 'value(compute.zone)' 2>/dev/null)}\"\n# Based on instructions from k8s build/README.md\nif [ -z \"${KUBE_DIND_GCE_PROJECT:-}\" ]; then\n    echo >&2 \"Please set KUBE_DIND_GCE_PROJECT or use 'gcloud config set project NAME'\"\n    return 1\nfi\n\nset -x\nKUBE_DIND_VM=\"${KUBE_DIND_VM:-k8s-dind}\"\nexport GCE_HOSTED=true\nexport KUBE_RSYNC_PORT=8730\nexport APISERVER_PORT=8899\nIP_MODE=\"${IP_MODE:-ipv4}\"\nopts=(\"-L ${KUBE_RSYNC_PORT}:localhost:${KUBE_RSYNC_PORT}\")\n\nif [[ \"${IP_MODE}\" = \"ipv4\" ]]; then\n    opts+=(\"-L ${APISERVER_PORT}:localhost:${APISERVER_PORT}\")\nelse\n    opts+=(\"-L ${APISERVER_PORT}:[::1]:${APISERVER_PORT}\")\nfi\ndocker-machine create \\\n               --driver=google \\\n               --google-project=${KUBE_DIND_GCE_PROJECT} \\\n               --google-machine-image=ubuntu-os-cloud/global/images/ubuntu-1604-xenial-v20170307 \\\n               --google-zone=${KUBE_DIND_GCE_ZONE} \\\n               --google-machine-type=n1-standard-8 \\\n               --google-disk-size=50 \\\n               --google-disk-type=pd-ssd \\\n               --engine-storage-driver=overlay2 \\\n               ${KUBE_DIND_VM}\neval $(docker-machine env ${KUBE_DIND_VM})\ndocker-machine ssh ${KUBE_DIND_VM} ${opts[*]} -N&\nif [ ! -z \"${DIND_IMAGE:-}\" ]; then\n    place=`pwd`\n    cd \"${DIND_ROOT}\"\n    build/build-local.sh\n    cd \"$place\"\nfi\ntime \"${DIND_ROOT}\"/dind-cluster.sh up\nset +x\n"
        },
        {
          "name": "image",
          "type": "tree",
          "content": null
        },
        {
          "name": "test.sh",
          "type": "blob",
          "size": 5.9072265625,
          "content": "#!/bin/bash -x\n# Copyright 2017 Mirantis\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nset -o errexit\nset -o nounset\nset -o pipefail\nset -o errtrace\n\nif [ $(uname) = Darwin ]; then\n  readlinkf(){ perl -MCwd -e 'print Cwd::abs_path shift' \"$1\";}\nelse\n  readlinkf(){ readlink -f \"$1\"; }\nfi\nDIND_ROOT=\"$(cd $(dirname \"$(readlinkf \"${BASH_SOURCE}\")\"); pwd)\"\n\n. \"${DIND_ROOT}\"/build/buildconf.sh\n\nNOBUILD=\"${NOBUILD:-}\"\nTEST_CASE=\"${TEST_CASE:-}\"\n# pin 'master' tests to a specific PR number\n# (e.g. K8S_PR=44143)\nK8S_PR=\"${K8S_PR:-}\"\n\ntempdir=\"$(mktemp -d)\"\nexport KUBECTL_DIR=\"${tempdir}\"\nexport KUBECONFIG=\"${KUBECTL_DIR}/kube.conf\"\nexport DOWNLOAD_KUBECTL=y\n\nfunction cleanup {\n  if [[ ${TRAVIS:-} && $? -ne 0 ]]; then\n    # Use temp file to avoid mixing error messages from the script\n    # with base64 content\n    export PATH=\"${KUBECTL_DIR}:${PATH}\"\n    \"${DIND_ROOT}\"/dind-cluster.sh dump64 >\"${tempdir}/dump\"\n    cat \"${tempdir}/dump\"\n  fi\n  rm -rf '${tempdir}'\n}\ntrap cleanup EXIT\n\n# FIXME: 192.168.0.0/16 causes problems with Travis(?)\nexport POD_NETWORK_CIDR=\"10.244.0.0/16\"\n\nif [[ ${NOBUILD} ]]; then\n  bash -x \"${DIND_ROOT}\"/dind-cluster.sh clean\nelse\n  export DIND_IMAGE=mirantis/kubeadm-dind-cluster:local\nfi\n\nfunction test-cluster {\n  local kubectl=\"${KUBECTL_DIR}/kubectl\"\n  local defaultContext='dind'\n\n  if [[ ${BUILD_HYPERKUBE:-} ]]; then\n    kubectl=\"${PWD}/cluster/kubectl.sh\"\n  fi\n  if [[ ! ${NOBUILD} ]]; then\n    (\n      cd \"${DIND_ROOT}\"\n      ./build/build-local.sh\n    )\n  fi\n  bash -x \"${DIND_ROOT}\"/dind-cluster.sh clean\n  time bash -x \"${DIND_ROOT}\"/dind-cluster.sh up\n  \"${kubectl}\" --context=\"$defaultContext\" get pods --all-namespaces | egrep 'coredns|kube-dns'\n  time bash -x \"${DIND_ROOT}\"/dind-cluster.sh up\n  \"${kubectl}\" --context=\"$defaultContext\" get pods --all-namespaces | egrep 'coredns|kube-dns'\n  bash -x \"${DIND_ROOT}\"/dind-cluster.sh down\n  bash -x \"${DIND_ROOT}\"/dind-cluster.sh clean\n}\n\nfunction test-cluster-src {\n  (\n    local version=\"${1:-}\"\n    if [[ ! -d \"kubernetes\" ]]; then\n       git clone https://github.com/kubernetes/kubernetes.git\n    fi\n    cd kubernetes\n    if [[ ${version} ]]; then\n      git checkout \"${version}\"\n    elif [[ ${K8S_PR} ]]; then\n      git fetch origin \"pull/${K8S_PR}/head:testbranch\"\n      git checkout testbranch\n    fi\n    export BUILD_KUBEADM=y\n    export BUILD_HYPERKUBE=y\n    test-cluster\n  )\n}\n\nfunction test-case-1.12 {\n  (\n    export KUBEADM_URL=\"${KUBEADM_URL_1_12}\"\n    export KUBEADM_SHA1=\"${KUBEADM_SHA1_1_12}\"\n    export HYPERKUBE_URL=\"${HYPERKUBE_URL_1_12}\"\n    export HYPERKUBE_SHA1=\"${HYPERKUBE_SHA1_1_12}\"\n    export KUBECTL_LINUX_URL=${KUBECTL_LINUX_URL_1_12}\"\n    export KUBECTL_LINUX_SHA1=${KUBECTL_LINUX_SHA1_1_12}\"\n    export KUBECTL_DARWIN_URL=${KUBECTL_DARWIN_URL_1_12}\"\n    export KUBECTL_DARWIN_SHA1=${KUBECTL_DARWIN_SHA1_1_12}\"\n    if [[ ${NOBUILD} ]]; then\n      export DIND_K8S_VERSION=v1.12\n      docker pull \"${DIND_IMAGE}\"\n    fi\n    test-cluster\n  )\n}\n\nfunction test-case-1.13 {\n  (\n    export KUBEADM_URL=\"${KUBEADM_URL_1_13}\"\n    export KUBEADM_SHA1=\"${KUBEADM_SHA1_1_13}\"\n    export HYPERKUBE_URL=\"${HYPERKUBE_URL_1_13}\"\n    export HYPERKUBE_SHA1=\"${HYPERKUBE_SHA1_1_13}\"\n    export KUBECTL_LINUX_URL=${KUBECTL_LINUX_URL_1_13}\"\n    export KUBECTL_LINUX_SHA1=${KUBECTL_LINUX_SHA1_1_13}\"\n    export KUBECTL_DARWIN_URL=${KUBECTL_DARWIN_URL_1_13}\"\n    export KUBECTL_DARWIN_SHA1=${KUBECTL_DARWIN_SHA1_1_13}\"\n    if [[ ${NOBUILD} ]]; then\n      export DIND_K8S_VERSION=v1.13\n      docker pull \"${DIND_IMAGE}\"\n    fi\n    test-cluster\n  )\n}\n\nfunction test-case-1.14 {\n  (\n    export KUBEADM_URL=\"${KUBEADM_URL_1_14}\"\n    export KUBEADM_SHA1=\"${KUBEADM_SHA1_1_14}\"\n    export HYPERKUBE_URL=\"${HYPERKUBE_URL_1_14}\"\n    export HYPERKUBE_SHA1=\"${HYPERKUBE_SHA1_1_14}\"\n    export KUBECTL_LINUX_URL=${KUBECTL_LINUX_URL_1_14}\"\n    export KUBECTL_LINUX_SHA1=${KUBECTL_LINUX_SHA1_1_14}\"\n    export KUBECTL_DARWIN_URL=${KUBECTL_DARWIN_URL_1_14}\"\n    export KUBECTL_DARWIN_SHA1=${KUBECTL_DARWIN_SHA1_1_14}\"\n    if [[ ${NOBUILD} ]]; then\n      export DIND_K8S_VERSION=v1.14\n      docker pull \"${DIND_IMAGE}\"\n    fi\n    test-cluster\n  )\n}\n\nfunction test-case-1.15 {\n  (\n    export KUBEADM_URL=\"${KUBEADM_URL_1_15}\"\n    export KUBEADM_SHA1=\"${KUBEADM_SHA1_1_15}\"\n    export HYPERKUBE_URL=\"${HYPERKUBE_URL_1_15}\"\n    export HYPERKUBE_SHA1=\"${HYPERKUBE_SHA1_1_15}\"\n    export KUBECTL_LINUX_URL=${KUBECTL_LINUX_URL_1_15}\"\n    export KUBECTL_LINUX_SHA1=${KUBECTL_LINUX_SHA1_1_15}\"\n    export KUBECTL_DARWIN_URL=${KUBECTL_DARWIN_URL_1_15}\"\n    export KUBECTL_DARWIN_SHA1=${KUBECTL_DARWIN_SHA1_1_15}\"\n    if [[ ${NOBUILD} ]]; then\n      export DIND_K8S_VERSION=v1.15\n      docker pull \"${DIND_IMAGE}\"\n    fi\n    test-cluster\n  )\n}\n\nfunction test-case-src-master {\n  test-cluster-src master\n}\n\nfunction test-case-dump-succeeds() {\n  local d=\"${DIND_ROOT}/dind-cluster.sh\"\n\n  \"$d\" up\n  \"$d\" dump >/dev/null || {\n    fail \"Expected '$d dump' to succeed\"\n  }\n}\n\nfunction test-case-restore() {\n  local d=\"${DIND_ROOT}/dind-cluster.sh\"\n\n  \"$d\" up\n  APISERVER_PORT=8083 \"$d\" up || {\n    fail 'Expected to be able to restore the cluster with the APIServer listening on 8083'\n  }\n\n  \"$d\" clean\n}\n\nfunction fail() {\n  local msg=\"$1\"\n  echo -e \"\\033[1;31m${msg}\\033[0m\" >&2\n  return 1\n}\n\nif [[ ! ${TEST_CASE} ]]; then\n  test-case-1.12\n  test-case-1.13\n  test-case-1.14\n  test-case-1.15\n  # test-case-src-master\n  test-case-dump-succeeds\n  test-case-restore\nelse\n  \"test-case-${TEST_CASE}\"\nfi\n\necho \"*** OK ***\"\n\n# TODO: build k8s master daily using Travis cron feature\n"
        },
        {
          "name": "test",
          "type": "tree",
          "content": null
        }
      ]
    }
  ]
}