{
  "metadata": {
    "timestamp": 1736568529335,
    "page": 533,
    "hasNextPage": true,
    "endCursor": "Y3Vyc29yOjUzOQ==",
    "completionStatus": "IN_PROGRESS"
  },
  "repositories": [
    {
      "nameWithOwner": "quicwg/base-drafts",
      "stars": 1635,
      "defaultBranch": "main",
      "files": [
        {
          "name": ".editorconfig",
          "type": "blob",
          "size": 0.197265625,
          "content": "# See http://editorconfig.org\n\nroot = true\n\n[*.md]\ncharset = utf-8\nend_of_line = lf\nindent_size = 2\nindent_style = space\ninsert_final_newline = true\nmax_line_length = 80\ntrim_trailing_whitespace = true\n"
        },
        {
          "name": ".gitattributes",
          "type": "blob",
          "size": 0.31640625,
          "content": "# Set the default behavior, in case people don't have core.autocrlf set.\n* text=auto\n\n# Explicitly declare text files you want to always be normalized and converted\n# to native line endings on checkout.\n*.md text\n*.xml text\n\n# Declare files that will always have LF line endings on checkout.\n*.sh text eol=lf\n*.mk txt eol=lf"
        },
        {
          "name": ".github",
          "type": "tree",
          "content": null
        },
        {
          "name": ".gitignore",
          "type": "blob",
          "size": 0.2392578125,
          "content": "*.html\n*.pdf\n*.redxml\n*.swp\n*.txt\n*.upload\n*~\n.refcache\n.tags\n.targets.mk\n/*-[0-9][0-9].xml\n/lib\n/node_modules/\n/old/\nGemfile.lock\narchive.json\npackage-lock.json\nreport.xml\nrfc8999.xml\nrfc9000.xml\nrfc9001.xml\nrfc9002.xml\nrfc9114.xml\nrfc9204.xml\n"
        },
        {
          "name": ".lint.py",
          "type": "blob",
          "size": 1.978515625,
          "content": "#!/usr/bin/env python3\n\nimport sys\nimport argparse\nimport re\n\nparser = argparse.ArgumentParser(description=\"Lint markdown drafts.\")\nparser.add_argument(\"files\", metavar=\"file\", nargs=\"+\", help=\"Files to lint\")\nparser.add_argument(\"-l\", dest=\"maxLineLength\", default=80)\nparser.add_argument(\"-f\", dest=\"maxFigureLineLength\", default=66)\n\nargs = parser.parse_args()\n\nfoundError = False\n\nfor inputfile in args.files:\n    insideFigure = False\n    beforeAbstract = True\n\n    with open(inputfile, mode=\"rt\", newline=None, encoding=\"utf-8\") as draft:\n        linenumber = 0\n        lines = draft.readlines()\n\n        abstract = re.compile(\"^--- abstract\")\n        table = re.compile(\"^\\s*(?:\\||{:)\")\n        figure = re.compile(\"^[~`]{3,}\")\n\n        for line in lines:\n            line = line.rstrip(\"\\r\\n\")\n            linenumber += 1\n\n            def err(msg):\n                global foundError\n                foundError = True\n                sys.stderr.write(\"{0}:{1}: {2}\\n\".format(inputfile, linenumber, msg))\n                sys.stderr.write(\"{0}\\n\".format(line))\n\n            if line.find(\"\\t\") >= 0:\n                err(\"Line contains HTAB\")\n\n            # Skip everything before abstract\n            if beforeAbstract:\n                matchObj = abstract.match(line)\n                if matchObj:\n                    beforeAbstract = False\n                continue\n\n            # Skip tables\n            matchObj = table.match(line)\n            if matchObj:\n                continue\n\n            # Toggle figure state\n            matchObj = figure.match(line)\n            if matchObj:\n                insideFigure = not insideFigure\n                continue\n\n            # Check length\n            length = len(line)\n            limit = (\n                int(args.maxFigureLineLength)\n                if insideFigure\n                else int(args.maxLineLength)\n            )\n            if length > limit:\n                err(\"Line is {0} characters; limit is {1}\".format(length, limit))\n\nsys.exit(1 if foundError else 0)\n"
        },
        {
          "name": ".travis.yml",
          "type": "blob",
          "size": 0.486328125,
          "content": "language: python\nsudo: false\ndist: trusty\n\naddons:\n  apt:\n    packages:\n     - python-pip\n     - xsltproc\n\nenv:\n  global:\n   - GOPATH=\"${TRAVIS_BUILD_DIR}/.go_workspace\"\n   - mmark_src=github.com/miekg/mmark/mmark\n   - mmark=./mmark\n\ninstall:\n - pip install xml2rfc\n - if head -1 -q *.md | grep '^\\-\\-\\-' >/dev/null 2>&1; then gem install --no-doc kramdown-rfc2629; fi\n - if head -1 -q *.md | grep '^%%%' >/dev/null 2>&1; then go get \"$mmark_src\" && go build \"$mmark_src\"; fi\n\nscript: make ghpages\n"
        },
        {
          "name": "CONTRIBUTING.md",
          "type": "blob",
          "size": 4.30078125,
          "content": "# QUIC version 1 is done\n\nThe base-drafts repository is the historical home of the QUIC version 1\nspecifications that were written by the IETF QUIC Working Group.\n\nThe set of documents are described [here](https://github.com/quicwg/base-drafts/blob/main/README.md).\n\n**Be aware that all contributions fall under the \"[NOTE WELL](#note-well)\" terms\noutlined below and our [Code of Conduct](#code-of-conduct) applies.**\n\n# Engaging with the QUIC community\n\nThe scope of work in the QUIC Working Group is described in our\n[charter](https://datatracker.ietf.org/wg/quic/about/) and it extends beyond the\ndevelopment of the documents held in this repository. Anyone is welcome to\ncontribute to the QUIC Working Group; you don't have to join the Working Group,\nbecause there is no \"membership\" -- anyone who participates in the work **is** a\npart of the QUIC Working Group.\n\nBefore doing so, please familiarize yourself with our\n[charter](https://datatracker.ietf.org/wg/quic/about/). If you're new to IETF\nwork, you may also want to read the [Tao of the\nIETF](https://www.ietf.org/tao.html).\n\n## Following Discussion\n\nThe Working Group has a few venues for discussion:\n\n* We plan to meet at all [IETF meetings](https://www.ietf.org/meeting/) for the\n  foreseeable future, and possibly hold interim meetings between them as\n  required. Agendas, minutes, and presentations are available in our [meeting\n  materials repository](https://github.com/quicwg/wg-materials) and the\n  [official proceedings](https://datatracker.ietf.org/wg/quic/meetings/).\n\n* Our [mailing list](https://www.ietf.org/mailman/listinfo/quic) is used for\n  most communication, including notifications of meetings, new drafts, consensus\n  calls and other business, as well as issue discussion.\n\n* We maintain several repositories in our GitHub organization\n  [Github](https://github.com/quicwg/). Specific issues are discussed on the\n  relevant issues list. If you don't want to use Github to follow these\n  discussions, you can subscribe to the [issue announce\n  list](https://www.ietf.org/mailman/listinfo/quic-issues).\n\n* The [quicdev Slack](https://quicdev.slack.com/) is used for more realtime\n  communication, typcially amongst implementers, operators and researchers.\n  Contact the [WG chairs](quic-chairs@ietf.org) for an invitation. Note that\n  discussions on Slack are subject to the contribution guideline described in\n  this document.\n\nTo be active in the Working Group, you can participate in any of these places.\nMost activity takes place on the mailing list, but if you just want to comment\non and raise issues, that's fine too.\n\n## Code of Conduct\n\nThe [IETF Guidelines for Conduct](https://tools.ietf.org/html/rfc7154) applies to all Working Group\ncommunications and meetings.\n\n\n## NOTE WELL\n\nAny submission to the [IETF](https://www.ietf.org/) intended by the Contributor for publication as\nall or part of an IETF Internet-Draft or RFC and any statement made within the context of an IETF\nactivity is considered an \"IETF Contribution\". Such statements include oral statements in IETF\nsessions, as well as written and electronic communications made at any time or place, which are\naddressed to:\n\n * The IETF plenary session\n * The IESG, or any member thereof on behalf of the IESG\n * Any IETF mailing list, including the IETF list itself, any working group\n   or design team list, or any other list functioning under IETF auspices\n * Any IETF working group or portion thereof\n * Any Birds of a Feather (BOF) session\n * The IAB or any member thereof on behalf of the IAB\n * The RFC Editor or the Internet-Drafts function\n * All IETF Contributions are subject to the rules of\n   [RFC 5378](https://tools.ietf.org/html/rfc5378) and\n   [RFC 8179](https://tools.ietf.org/html/rfc8179).\n\nStatements made outside of an IETF session, mailing list or other function, that are clearly not\nintended to be input to an IETF activity, group or function, are not IETF Contributions in the\ncontext of this notice.\n\nPlease consult [RFC 5378](https://tools.ietf.org/html/rfc5378) and [RFC 8179](https://tools.ietf.org/html/rfc8179) for details.\n\nA participant in any IETF activity is deemed to accept all IETF rules of process, as documented in\nBest Current Practices RFCs and IESG Statements.\n\nA participant in any IETF activity acknowledges that written, audio and video records of meetings\nmay be made and may be available to the public.\n"
        },
        {
          "name": "Makefile",
          "type": "blob",
          "size": 0.5078125,
          "content": "MD_PREPROCESSOR := sed -e 's/{DATE}/$(shell date '+%Y-%m-%d')/g'\nTIDY := true\n\nLIBDIR := lib\ninclude $(LIBDIR)/main.mk\n\n$(LIBDIR)/main.mk:\nifneq (,$(shell git submodule status $(LIBDIR) 2>/dev/null))\n\tgit submodule sync\n\tgit submodule update $(CLONE_ARGS) --init\nelse\n\tgit clone -q --depth 10 $(CLONE_ARGS) \\\n\t    -b main https://github.com/martinthomson/i-d-template $(LIBDIR)\nendif\n\nlatest:: lint\n.PHONY: lint\n\nlint::\n\t@$(trace) wslint $(python) ./.lint.py $(addsuffix .md,$(drafts))\n\nshow-next:\n\t@echo $(drafts_next)\n"
        },
        {
          "name": "README.md",
          "type": "blob",
          "size": 1.576171875,
          "content": "# QUIC Protocol Drafts\n\nThe base-drafts repository is the historical home of the QUIC version 1\nspecifications that were written by the QUIC Working Group.\n\n**The documents have now been published as RFCs. Technical or editorial\nerratum can be reported to the RFC Editor using the [errata\ntool](https://www.rfc-editor.org/errata.php).**\n\n**The QUIC Working Group welcomes discussion about new versions of QUIC, and new\nextensions to QUIC, or other proposals related to the QUIC transport. See\n[Engaging with the QUIC\ncommunity](https://github.com/quicwg/base-drafts/blob/main/CONTRIBUTING.md#engaging-with-the-quic-community)\nfor guidance.**\n\n## QUIC Invariants\n\n* [RFC 8999](https://quicwg.org/base-drafts/rfc8999.html)\n* [Datatracker](https://datatracker.ietf.org/doc/html/draft-ietf-quic-invariants)\n\n## Core Transport Protocol\n\n* [RFC 9000](https://quicwg.org/base-drafts/rfc9000.html)\n* [Working Group Draft](https://datatracker.ietf.org/doc/html/draft-ietf-quic-transport)\n\n## Loss Detection & Congestion Control\n\n* [RFC 9002](https://quicwg.org/base-drafts/rfc9002.html)\n* [Working Group Draft](https://datatracker.ietf.org/doc/html/draft-ietf-quic-recovery)\n\n## TLS Mapping\n\n* [RFC 9001](https://quicwg.org/base-drafts/rfc9001.html)\n* [Datatracker](https://datatracker.ietf.org/doc/html/draft-ietf-quic-tls)\n\n## HTTP Mapping\n\n* [RFC 9114](https://quicwg.org/base-drafts/rfc9114.html)\n* [Datatracker](https://datatracker.ietf.org/doc/html/draft-ietf-quic-http)\n\n## QPACK\n\n* [RFC 9204](https://quicwg.org/base-drafts/rfc9204.html)\n* [Datatracker](https://datatracker.ietf.org/doc/html/draft-ietf-quic-qpack)\n"
        },
        {
          "name": "ietf.json",
          "type": "blob",
          "size": 0.2724609375,
          "content": "{\n    \"group\": \"quic\",\n    \"group_info\": {\n        \"name\": \"QUIC\",\n        \"type\": \"wg\",\n        \"email\": \"quic@ietf.org\",\n        \"activity_exclude_labels\": [\"editorial\"]\n    },\n    \"repo_type\": \"specs\",\n    \"revisions_tagged\": true,\n    \"activity_summary_to\": [\"group_email\"]\n}"
        },
        {
          "name": "protection-samples.js",
          "type": "blob",
          "size": 11.46875,
          "content": "#!/bin/sh\n':' //; exec \"$(command -v nodejs || command -v node)\" \"$0\" \"$@\"\n\n// This script performs simple encryption and decryption for Initial packets.\n// It's crude, but it should be sufficient to generate examples.\n\n\n'use strict';\nrequire('buffer');\nconst assert = require('assert');\nconst crypto = require('crypto');\n\nconst INITIAL_SALT = Buffer.from('38762cf7f55934b34d179ae6a4c80cadccbb7f0a', 'hex');\nconst RETRY_KEY = Buffer.from('be0c690b9f66575a1d766b54e368c84e', 'hex');\nconst RETRY_NONCE = Buffer.from('461599d35d632bf2239825bb', 'hex');\nconst SHA256 = 'sha256';\nconst AES_GCM = 'aes-128-gcm';\nconst AES_ECB = 'aes-128-ecb';\n\nconst version = '00000001';\n\nfunction chunk(s, n) {\n  return (new Array(Math.ceil(s.length / n)))\n    .fill()\n    .map((_, i) => s.slice(i * n, i * n + n));\n}\n\nfunction log(m, k) {\n  console.log(m + ' [' + k.length + ']: ' + chunk(k.toString('hex'), 32).join(' '));\n};\n\nclass HMAC {\n  constructor(hash) {\n    this.hash = hash;\n  }\n\n  digest(key, input) {\n    var hmac = crypto.createHmac(this.hash, key);\n    hmac.update(input);\n    return hmac.digest();\n  }\n}\n\n/* HKDF as defined in RFC5869, with HKDF-Expand-Label from RFC8446. */\nclass QHKDF {\n  constructor(hmac, prk) {\n    this.hmac = hmac;\n    this.prk = prk;\n  }\n\n  static extract(hash, salt, ikm) {\n    var hmac = new HMAC(hash);\n    return new QHKDF(hmac, hmac.digest(salt, ikm));\n  }\n\n  expand(info, len) {\n    var output = Buffer.alloc(0);\n    var T = Buffer.alloc(0);\n    info = Buffer.from(info, 'ascii');\n    var counter = 0;\n    var cbuf = Buffer.alloc(1);\n    while (output.length < len) {\n      cbuf.writeUIntBE(++counter, 0, 1);\n      T = this.hmac.digest(this.prk, Buffer.concat([T, info, cbuf]));\n      output = Buffer.concat([output, T]);\n    }\n\n    return output.slice(0, len);\n  }\n\n  expand_label(label, len) {\n    const prefix = \"tls13 \";\n    var info = Buffer.alloc(2 + 1 + prefix.length + label.length + 1);\n    // Note that Buffer.write returns the number of bytes written, whereas\n    // Buffer.writeUIntBE returns the end offset of the write.  Consistency FTW.\n    var offset = info.writeUIntBE(len, 0, 2);\n    offset = info.writeUIntBE(prefix.length + label.length, offset, 1);\n    offset += info.write(prefix + label, offset);\n    info.writeUIntBE(0, offset, 1);\n    log('info for ' + label, info);\n    return this.expand(info, len);\n  }\n}\n\n// XOR b into a.\nfunction xor(a, b) {\n    a.forEach((_, i) => {\n      a[i] ^= b[i];\n    });\n}\n\nfunction applyNonce(iv, counter) {\n  var nonce = Buffer.from(iv);\n  const m = nonce.readUIntBE(nonce.length - 6, 6);\n  const x = ((m ^ counter) & 0xffffff) +\n     ((((m / 0x1000000) ^ (counter / 0x1000000)) & 0xffffff) * 0x1000000);\n  nonce.writeUIntBE(x, nonce.length - 6, 6);\n  return nonce;\n}\n\nclass InitialProtection {\n  constructor(label, cid) {\n    var qhkdf = QHKDF.extract(SHA256, INITIAL_SALT, cid);\n    log('initial_secret', qhkdf.prk);\n    qhkdf = new QHKDF(qhkdf.hmac, qhkdf.expand_label(label, 32));\n    log(label + ' secret', qhkdf.prk);\n    this.key = qhkdf.expand_label(\"quic key\", 16);\n    log(label + ' key', this.key);\n    this.iv = qhkdf.expand_label(\"quic iv\", 12);\n    log(label + ' iv', this.iv);\n    this.hp = qhkdf.expand_label(\"quic hp\", 16);\n    log(label + ' hp', this.hp);\n  }\n\n  generateNonce(counter) {\n    return applyNonce(this.iv, counter);\n  }\n\n  // Returns the encrypted data with authentication tag appended.  The AAD is\n  // used, but not added to the output.\n  encipher(pn, aad, data) {\n    console.log('encipher pn', pn);\n    log('encipher aad', aad);\n    log('encipher data', data);\n    var nonce = this.generateNonce(pn);\n    var gcm = crypto.createCipheriv(AES_GCM, this.key, nonce);\n    gcm.setAAD(aad);\n    var e = gcm.update(data);\n    gcm.final();\n    e = Buffer.concat([e, gcm.getAuthTag()]);\n    log('enciphered', e);\n    return e;\n  }\n\n  decipher(pn, aad, data) {\n    console.log('decipher pn', pn);\n    log('decipher aad', aad);\n    log('decipher data', data);\n    var nonce = this.generateNonce(pn);\n    var gcm = crypto.createDecipheriv(AES_GCM, this.key, nonce);\n    gcm.setAAD(aad);\n    gcm.setAuthTag(data.slice(data.length - 16));\n    var d = gcm.update(data.slice(0, data.length - 16));\n    gcm.final();\n    log('deciphered', d);\n    return d;\n  }\n\n  // Calculates the header protection mask.  Returns 16 bytes of output.\n  hpMask(sample) {\n    log('hp sample', sample);\n    // var ctr = crypto.createCipheriv('aes-128-ctr', this.hp, sample);\n    // var mask = ctr.update(Buffer.alloc(5));\n    var ecb = crypto.createCipheriv(AES_ECB, this.hp, Buffer.alloc(0));\n    var mask = ecb.update(sample);\n    log('hp mask', mask);\n    return mask;\n  }\n\n  // hdr is everything before the length field\n  // hdr[0] has the packet number length already in place\n  // pn is the packet number\n  // data is the payload (i.e., encoded frames)\n  encrypt(hdr, pn, data) {\n    var pn_len = 1 + (hdr[0] & 0x3);\n    if (pn_len + data.length < 4) {\n      throw new Error('insufficient length of packet number and payload');\n    }\n\n    var aad = Buffer.alloc(hdr.length + 2 + pn_len);\n    var offset = hdr.copy(aad);\n    // Add a length that covers the packet number encoding and the auth tag.\n    offset = aad.writeUIntBE(0x4000 | (pn_len + data.length + 16), offset, 2);\n    var pn_offset = offset;\n    var pn_mask = 0xffffffff >> (8 * (4 - pn_len));\n    offset = aad.writeUIntBE(pn & pn_mask, offset, pn_len)\n    log('header', aad);\n\n    var payload = this.encipher(pn, aad, data);\n\n    var mask = this.hpMask(payload.slice(4 - pn_len, 20 - pn_len));\n    aad[0] ^= mask[0] & (0x1f >> (aad[0] >> 7));\n    xor(aad.slice(pn_offset), mask.slice(1));\n    log('masked header', aad);\n    return Buffer.concat([aad, payload]);\n  }\n\n  cidLen(v) {\n    if (!v) {\n      return 0;\n    }\n    return v + 3;\n  }\n\n  decrypt(data) {\n    log('decrypt', data);\n    if (data[0] & 0x40 !== 0x40) {\n      throw new Error('missing QUIC bit');\n    }\n    if (data[0] & 0x80 === 0) {\n      throw new Error('short header unsupported');\n    }\n    var hdr_len = 1 + 4;\n    hdr_len += 1 + data[hdr_len]; // DCID\n    hdr_len += 1 + data[hdr_len]; // SCID\n    if ((data[0] & 0x30) === 0) { // Initial packet: token.\n      if ((data[hdr_len] & 0xc0) !== 0) {\n        throw new Error('multi-byte token length unsupported');\n      }\n      hdr_len += 1 + data[hdr_len];  // oops: this only handles single octet lengths.\n    }\n    // Skip the length.\n    hdr_len += 1 << (data[hdr_len] >> 6);\n    // Now we're at the encrypted bit.\n    var mask = this.hpMask(data.slice(hdr_len + 4, hdr_len + 20));\n\n    var octet0 = data[0] ^ (mask[0] & (0x1f >> (data[0] >> 7)));\n    var pn_len = (octet0 & 3) + 1;\n    var hdr = Buffer.from(data.slice(0, hdr_len + pn_len));\n    hdr[0] = octet0;\n    log('header', hdr);\n    xor(hdr.slice(hdr_len), mask.slice(1));\n    log('unmasked header', hdr);\n    var pn = hdr.readUIntBE(hdr_len, pn_len);\n    // Important: this doesn't recover PN based on expected value.\n    // The expectation being that Initial packets won't ever need that.\n    return this.decipher(pn, hdr, data.slice(hdr.length));\n  }\n}\n\nfunction pad(hdr, body) {\n  var pn_len = (hdr[0] & 3) + 1;\n  var size = 1200 - hdr.length - 2 - pn_len - 16; // Assume 2 byte length.\n  if (size < 0) {\n    return body;\n  }\n  var padded = Buffer.allocUnsafe(size);\n  console.log('pad amount', size);\n  body.copy(padded);\n  padded.fill(0, body.length);\n  log('padded', padded);\n  return padded;\n}\n\nfunction test(role, cid, hdr, pn, body) {\n  cid = Buffer.from(cid, 'hex');\n  log('connection ID', cid);\n  hdr = Buffer.from(hdr, 'hex');\n  log('header', hdr);\n  console.log('packet number = ' + pn);\n  body = Buffer.from(body, 'hex');\n  log('body', hdr);\n\n  if (role === 'client' && (hdr[0] & 0x30) === 0) {\n    body = pad(hdr, body);\n  }\n\n  var endpoint = new InitialProtection(role + ' in', cid);\n  var packet = endpoint.encrypt(hdr, pn, body);\n  log('encrypted packet', packet);\n\n  var content = endpoint.decrypt(packet);\n  log('decrypted content', content);\n  if (content.compare(body) !== 0) {\n    throw new Error('decrypted result not the same as the original');\n  }\n}\n\nfunction hex_cid(cid) {\n  return '0' + (cid.length / 2).toString(16) + cid;\n}\n\n// Verify that the retry keys are correct.\nfunction derive_retry() {\n  let secret = Buffer.from('d9c9943e6101fd200021506bcc02814c73030f25c79d71ce876eca876e6fca8e', 'hex');\n  let qhkdf = new QHKDF(new HMAC(SHA256), secret);\n  let key = qhkdf.expand_label(\"quic key\", 16);\n  log('retry key', key);\n  assert.deepStrictEqual(key, RETRY_KEY);\n  let nonce = qhkdf.expand_label(\"quic iv\", 12);\n  log('retry nonce', nonce);\n  assert.deepStrictEqual(nonce, RETRY_NONCE);\n}\n\nfunction retry(dcid, scid, odcid) {\n  var pfx = Buffer.from(hex_cid(odcid), 'hex');\n  var encoded = Buffer.from('ff' + version + hex_cid(dcid) + hex_cid(scid), 'hex');\n  var token = Buffer.from('token', 'ascii');\n  var header = Buffer.concat([encoded, token]);\n  log('retry header', header);\n  var aad = Buffer.concat([pfx, header]);\n  log('retry aad', aad);\n\n  var gcm = crypto.createCipheriv(AES_GCM, RETRY_KEY, RETRY_NONCE);\n  gcm.setAAD(aad);\n  gcm.update('');\n  gcm.final();\n  log('retry', Buffer.concat([header, gcm.getAuthTag()]));\n}\n\n// A simple ChaCha20-Poly1305 packet.\nfunction chacha20(pn, payload) {\n  log('chacha20poly1305 pn=' + pn.toString(), payload);\n  let header = Buffer.alloc(4);\n  header.writeUIntBE(0x42, 0, 1);\n  header.writeUIntBE(pn & 0xffffff, 1, 3);\n  log('unprotected header', header);\n  const key = Buffer.from('c6d98ff3441c3fe1b2182094f69caa2e' +\n                          'd4b716b65488960a7a984979fb23e1c8', 'hex');\n  const iv = Buffer.from('e0459b3474bdd0e44a41c144', 'hex');\n  const nonce = applyNonce(iv, pn);\n  log('nonce', nonce);\n  let aead = crypto.createCipheriv('ChaCha20-Poly1305', key, nonce, { authTagLength: 16 });\n  aead.setAAD(header);\n  const e = aead.update(payload);\n  aead.final();\n  let ct = Buffer.concat([e, aead.getAuthTag()]);\n  log('ciphertext', ct);\n\n  const sample = ct.slice(1, 17);\n  log('sample', sample);\n  const hp = Buffer.from('25a282b9e82f06f21f488917a4fc8f1b' +\n                         '73573685608597d0efcb076b0ab7a7a4', 'hex');\n  let chacha = crypto.createCipheriv('ChaCha20', hp, sample);\n  const mask = chacha.update(Buffer.alloc(5));\n  log('mask', mask);\n  let packet = Buffer.concat([header, ct]);\n  header[0] ^= mask[0] & 0x1f;\n  xor(header.slice(1), mask.slice(1));\n  log('header', header);\n  log('protected packet', Buffer.concat([header, ct]));\n}\n\nvar cid = '8394c8f03e515708';\n\nvar ci_hdr = 'c3' + version + hex_cid(cid) + '0000';\n// This is a client Initial.\nvar crypto_frame = '060040f1' +\n    '010000ed0303ebf8fa56f12939b9584a3896472ec40bb863cfd3e86804fe3a47' +\n    'f06a2b69484c00000413011302010000c000000010000e00000b6578616d706c' +\n    '652e636f6dff01000100000a00080006001d0017001800100007000504616c70' +\n    '6e000500050100000000003300260024001d00209370b2c9caa47fbabaf4559f' +\n    'edba753de171fa71f50f1ce15d43e994ec74d748002b0003020304000d001000' +\n    '0e0403050306030203080408050806002d00020101001c000240010039003204' +\n    '08ffffffffffffffff05048000ffff07048000ffff0801100104800075300901' +\n    '100f088394c8f03e51570806048000ffff';\n\ntest('client', cid, ci_hdr, 2, crypto_frame);\n\n// This should be a valid server Initial.\nvar frames = '02000000000600405a' +\n    '020000560303eefce7f7b37ba1d163' +\n    '2e96677825ddf73988cfc79825df566dc5430b9a04' +\n    '5a1200130100002e00330024001d00209d3c940d89' +\n    '690b84d08a60993c144eca684d1081287c834d5311' +\n    'bcf32bb9da1a002b00020304';\nvar scid = 'f067a5502a4262b5';\nvar si_hdr = 'c1' + version + '00' + hex_cid(scid) + '00';\ntest('server', cid, si_hdr, 1, frames);\n\nderive_retry();\nretry('', scid, cid);\nchacha20(654360564, Buffer.from('01', 'hex'));\n"
        },
        {
          "name": "rfc8999.md",
          "type": "blob",
          "size": 14.259765625,
          "content": "---\ntitle: \"Version-Independent Properties of QUIC\"\nabbrev: QUIC Invariants\nnumber: 8999\ndocName: draft-ietf-quic-invariants-13\ndate: 2021-05\ncategory: std\nconsensus: true\nipr: trust200902\narea: Transport\nworkgroup: QUIC\nkeyword:\n  - crypto\n  - next generation\n  - protocol\n  - secure\n  - transport\n  - UDP\n\nstand_alone: yes\npi: [toc, sortrefs, symrefs, docmapping]\n\nauthor:\n  -\n    ins: M. Thomson\n    name: Martin Thomson\n    org: Mozilla\n    email: mt@lowentropy.net\n\ninformative:\n\n  QUIC-TRANSPORT:\n    title: \"QUIC: A UDP-Based Multiplexed and Secure Transport\"\n    date: 2021-05\n    seriesinfo:\n      RFC: 9000\n      DOI: 10.17487/RFC9000\n    author:\n      -\n        ins: J. Iyengar\n        name: Jana Iyengar\n        org: Google\n        role: editor\n      -\n        ins: M. Thomson\n        name: Martin Thomson\n        org: Mozilla\n        role: editor\n\n  QUIC-TLS:\n    title: \"Using TLS to Secure QUIC\"\n    date: 2021-05\n    seriesinfo:\n      RFC: 9001\n      DOI: 10.17487/RFC9001\n    author:\n      -\n        ins: M. Thomson\n        name: Martin Thomson\n        org: Mozilla\n        role: editor\n      -\n        ins: S. Turner\n        name: Sean Turner\n        org: sn3rd\n        role: editor\n\n\n--- abstract\n\nThis document defines the properties of the QUIC transport protocol that are\ncommon to all versions of the protocol.\n\n\n--- middle\n\n# An Extremely Abstract Description of QUIC\n\nQUIC is a connection-oriented protocol between two endpoints.  Those endpoints\nexchange UDP datagrams.  These UDP datagrams contain QUIC packets.  QUIC\nendpoints use QUIC packets to establish a QUIC connection, which is shared\nprotocol state between those endpoints.\n\n\n# Fixed Properties of All QUIC Versions\n\nIn addition to providing secure, multiplexed transport, QUIC {{QUIC-TRANSPORT}}\nallows for the option to negotiate a version.  This allows the protocol to\nchange over time in response to new requirements.  Many characteristics of the\nprotocol could change between versions.\n\nThis document describes the subset of QUIC that is intended to remain stable as\nnew versions are developed and deployed.  All of these invariants are\nindependent of the IP version.\n\nThe primary goal of this document is to ensure that it is possible to deploy new\nversions of QUIC.  By documenting the properties that cannot change, this\ndocument aims to preserve the ability for QUIC endpoints to negotiate changes to\nany other aspect of the protocol.  As a consequence, this also guarantees a\nminimal amount of information that is made available to entities other than\nendpoints.  Unless specifically prohibited in this document, any aspect of the\nprotocol can change between different versions.\n\n{{bad-assumptions}} contains a non-exhaustive list of some incorrect assumptions\nthat might be made based on knowledge of QUIC version 1; these do not apply to\nevery version of QUIC.\n\n\n# Conventions and Definitions\n\nThe key words \"MUST\", \"MUST NOT\", \"REQUIRED\", \"SHALL\", \"SHALL NOT\", \"SHOULD\",\n\"SHOULD NOT\", \"RECOMMENDED\", \"NOT RECOMMENDED\", \"MAY\", and \"OPTIONAL\" in this\ndocument are to be interpreted as described in BCP 14 {{!RFC2119}} {{!RFC8174}}\nwhen, and only when, they appear in all capitals, as shown here.\n\nThis document defines requirements on future QUIC versions, even where normative\nlanguage is not used.\n\nThis document uses terms and notational conventions from {{QUIC-TRANSPORT}}.\n\n\n# Notational Conventions\n\nThe format of packets is described using the notation defined in this section.\nThis notation is the same as that used in {{QUIC-TRANSPORT}}.\n\nComplex fields are named and then followed by a list of fields surrounded by a\npair of matching braces. Each field in this list is separated by commas.\n\nIndividual fields include length information, plus indications about fixed\nvalue, optionality, or repetitions. Individual fields use the following\nnotational conventions, with all lengths in bits:\n\nx (A):\n: Indicates that x is A bits long\n\nx (A..B):\n: Indicates that x can be any length from A to B; A can be omitted to indicate\n  a minimum of zero bits, and B can be omitted to indicate no set upper limit;\n  values in this format always end on a byte boundary\n\nx (L) = C:\n: Indicates that x has a fixed value of C; the length of x is described by\n  L, which can use any of the length forms above\n\nx (L) ...:\n: Indicates that x is repeated zero or more times and that each instance has a\n  length of L\n\nThis document uses network byte order (that is, big endian) values.  Fields\nare placed starting from the high-order bits of each byte.\n\n{{fig-ex-format}} shows an example structure:\n\n~~~\nExample Structure {\n  One-bit Field (1),\n  7-bit Field with Fixed Value (7) = 61,\n  Arbitrary-Length Field (..),\n  Variable-Length Field (8..24),\n  Repeated Field (8) ...,\n}\n~~~\n{: #fig-ex-format title=\"Example Format\"}\n\n\n# QUIC Packets\n\nQUIC endpoints exchange UDP datagrams that contain one or more QUIC packets.\nThis section describes the invariant characteristics of a QUIC packet.  A\nversion of QUIC could permit multiple QUIC packets in a single UDP datagram, but\nthe invariant properties only describe the first packet in a datagram.\n\nQUIC defines two types of packet headers: long and short.  Packets with a long\nheader are identified by the most significant bit of the first byte being set;\npackets with a short header have that bit cleared.\n\nQUIC packets might be integrity protected, including the header.  However, QUIC\nVersion Negotiation packets are not integrity protected; see {{vn}}.\n\nAside from the values described here, the payload of QUIC packets is\nversion specific and of arbitrary length.\n\n\n## Long Header\n\nLong headers take the form described in {{fig-long}}.\n\n~~~\nLong Header Packet {\n  Header Form (1) = 1,\n  Version-Specific Bits (7),\n  Version (32),\n  Destination Connection ID Length (8),\n  Destination Connection ID (0..2040),\n  Source Connection ID Length (8),\n  Source Connection ID (0..2040),\n  Version-Specific Data (..),\n}\n~~~\n{: #fig-long title=\"QUIC Long Header\"}\n\nA QUIC packet with a long header has the high bit of the first byte set to 1.\nAll other bits in that byte are version specific.\n\nThe next four bytes include a 32-bit Version field.  Versions are described in\n{{version}}.\n\nThe next byte contains the length in bytes of the Destination Connection ID\nfield that follows it.  This length is encoded as an 8-bit unsigned integer.\nThe Destination Connection ID field follows the Destination Connection ID Length\nfield and is between 0 and 255 bytes in length.  Connection IDs are described in\n{{connection-id}}.\n\nThe next byte contains the length in bytes of the Source Connection ID field\nthat follows it.  This length is encoded as an 8-bit unsigned integer.  The\nSource Connection ID field follows the Source Connection ID Length field and is\nbetween 0 and 255 bytes in length.\n\nThe remainder of the packet contains version-specific content.\n\n\n## Short Header\n\nShort headers take the form described in {{fig-short}}.\n\n~~~~~\nShort Header Packet {\n  Header Form (1) = 0,\n  Version-Specific Bits (7),\n  Destination Connection ID (..),\n  Version-Specific Data (..),\n}\n~~~~~\n{: #fig-short title=\"QUIC Short Header\"}\n\nA QUIC packet with a short header has the high bit of the first byte set to 0.\n\nA QUIC packet with a short header includes a Destination Connection ID\nimmediately following the first byte.  The short header does not include the\nDestination Connection ID Length, Source Connection ID Length, Source Connection\nID, or Version fields.  The length of the Destination Connection ID is not\nencoded in packets with a short header and is not constrained by this\nspecification.\n\nThe remainder of the packet has version-specific semantics.\n\n\n## Connection ID\n\nA connection ID is an opaque field of arbitrary length.\n\nThe primary function of a connection ID is to ensure that changes in addressing\nat lower protocol layers (UDP, IP, and below) do not cause packets for a QUIC\nconnection to be delivered to the wrong QUIC endpoint.  The connection ID\nis used by endpoints and the intermediaries that support them to ensure that\neach QUIC packet can be delivered to the correct instance of an endpoint.  At\nthe endpoint, the connection ID is used to identify the QUIC connection for\nwhich the packet is intended.\n\nThe connection ID is chosen by each endpoint using version-specific methods.\nPackets for the same QUIC connection might use different connection ID values.\n\n\n## Version\n\nThe Version field contains a 4-byte identifier.  This value can be used by\nendpoints to identify a QUIC version.  A Version field with a value of\n0x00000000 is reserved for version negotiation; see {{vn}}.  All other values\nare potentially valid.\n\nThe properties described in this document apply to all versions of QUIC. A\nprotocol that does not conform to the properties described in this document is\nnot QUIC.  Future documents might describe additional properties that apply to\na specific QUIC version or to a range of QUIC versions.\n\n\n# Version Negotiation {#vn}\n\nA QUIC endpoint that receives a packet with a long header and a version it\neither does not understand or does not support might send a Version Negotiation\npacket in response.  Packets with a short header do not trigger version\nnegotiation.\n\nA Version Negotiation packet sets the high bit of the first byte, and thus it\nconforms with the format of a packet with a long header as defined in\n{{long-header}}.  A Version Negotiation packet is identifiable as such by the\nVersion field, which is set to 0x00000000.\n\n~~~\nVersion Negotiation Packet {\n  Header Form (1) = 1,\n  Unused (7),\n  Version (32) = 0,\n  Destination Connection ID Length (8),\n  Destination Connection ID (0..2040),\n  Source Connection ID Length (8),\n  Source Connection ID (0..2040),\n  Supported Version (32) ...,\n}\n~~~\n{: #version-negotiation-format title=\"Version Negotiation Packet\"}\n\nOnly the most significant bit of the first byte of a Version Negotiation packet\nhas any defined value.  The remaining 7 bits, labeled \"Unused\", can be set to\nany value when sending and MUST be ignored on receipt.\n\nAfter the Source Connection ID field, the Version Negotiation packet contains a\nlist of Supported Version fields, each identifying a version that the endpoint\nsending the packet supports.  A Version Negotiation packet contains no other\nfields.  An endpoint MUST ignore a packet that contains no Supported Version\nfields or contains a truncated Supported Version value.\n\nVersion Negotiation packets do not use integrity or confidentiality protection.\nSpecific QUIC versions might include protocol elements that allow endpoints to\ndetect modification or corruption in the set of supported versions.\n\nAn endpoint MUST include the value from the Source Connection ID field of the\npacket it receives in the Destination Connection ID field.  The value for the\nSource Connection ID field MUST be copied from the Destination Connection ID\nfield of the received packet, which is initially randomly selected by a client.\nEchoing both connection IDs gives clients some assurance that the server\nreceived the packet and that the Version Negotiation packet was not generated by\nan attacker that is unable to observe packets.\n\nAn endpoint that receives a Version Negotiation packet might change the version\nthat it decides to use for subsequent packets.  The conditions under which an\nendpoint changes its QUIC version will depend on the version of QUIC that it\nchooses.\n\nSee {{QUIC-TRANSPORT}} for a more thorough description of how an endpoint that\nsupports QUIC version 1 generates and consumes a Version Negotiation packet.\n\n\n# Security and Privacy Considerations\n\nIt is possible that middleboxes could observe traits of a specific version of\nQUIC and assume that when other versions of QUIC exhibit similar traits the same\nunderlying semantic is being expressed.  There are potentially many such traits;\nsee {{bad-assumptions}}.  Some effort has been made to either eliminate or\nobscure some observable traits in QUIC version 1, but many of these remain.\nOther QUIC versions might make different design decisions and so exhibit\ndifferent traits.\n\nThe QUIC version number does not appear in all QUIC packets, which means that\nreliably extracting information from a flow based on version-specific traits\nrequires that middleboxes retain state for every connection ID they see.\n\nThe Version Negotiation packet described in this document is not\nintegrity protected; it only has modest protection against insertion by\nattackers.  An endpoint MUST authenticate the semantic content of a Version\nNegotiation packet if it attempts a different QUIC version as a result.\n\n\n--- back\n\n# Incorrect Assumptions {#bad-assumptions}\n\nThere are several traits of QUIC version 1 {{QUIC-TRANSPORT}} that are not\nprotected from observation but are nonetheless considered to be changeable when\na new version is deployed.\n\nThis section lists a sampling of incorrect assumptions that might be made about\nQUIC based on knowledge of QUIC version 1.  Some of these statements are not\neven true for QUIC version 1.  This is not an exhaustive list; it is intended to\nbe illustrative only.\n\n**Any and all of the following statements can be false for a given QUIC\nversion:**\n\n* QUIC uses TLS {{QUIC-TLS}} and some TLS messages are visible on the wire.\n\n* QUIC long headers are only exchanged during connection establishment.\n\n* Every flow on a given 5-tuple will include a connection establishment phase.\n\n* The first packets exchanged on a flow use the long header.\n\n* The last packet before a long period of quiescence might be assumed\n  to contain only an acknowledgment.\n\n* QUIC uses an Authenticated Encryption with Associated Data (AEAD) function\n  (AEAD_AES_128_GCM; see {{?RFC5116}}) to protect the packets it exchanges\n  during connection establishment.\n\n* QUIC packet numbers are encrypted and appear as the first encrypted bytes.\n\n* QUIC packet numbers increase by one for every packet sent.\n\n* QUIC has a minimum size for the first handshake packet sent by a client.\n\n* QUIC stipulates that a client speak first.\n\n* QUIC packets always have the second bit of the first byte (0x40) set.\n\n* A QUIC Version Negotiation packet is only sent by a server.\n\n* A QUIC connection ID changes infrequently.\n\n* QUIC endpoints change the version they speak if they are sent a Version\n  Negotiation packet.\n\n* The Version field in a QUIC long header is the same in both directions.\n\n* A QUIC packet with a particular value in the Version field means that the\n  corresponding version of QUIC is in use.\n\n* Only one connection at a time is established between any pair of QUIC\n  endpoints.\n"
        },
        {
          "name": "rfc9000.md",
          "type": "blob",
          "size": 359.248046875,
          "content": "---\ntitle: \"QUIC: A UDP-Based Multiplexed and Secure Transport\"\nabbrev: QUIC Transport Protocol\nnumber: 9000\ndocName: draft-ietf-quic-transport-34\ndate: 2021-05\ncategory: std\nconsensus: true\nipr: trust200902\narea: Transport\nworkgroup: QUIC\nkeyword:\n  - multipath\n  - next generations\n  - protocol\n  - \"sctp++\"\n  - secure\n  - smart\n  - \"tcp/2\"\n  - tcpng\n  - transport\n  - transport-ng\n\nstand_alone: yes\npi: [toc, sortrefs, symrefs, docmapping]\n\nauthor:\n  -\n    ins: J. Iyengar\n    name: Jana Iyengar\n    org: Fastly\n    email: jri.ietf@gmail.com\n    role: editor\n  -\n    ins: M. Thomson\n    name: Martin Thomson\n    org: Mozilla\n    email: mt@lowentropy.net\n    role: editor\n\nnormative:\n\n  QUIC-INVARIANTS:\n    title: \"Version-Independent Properties of QUIC\"\n    date: 2021-05\n    seriesinfo:\n      RFC: 8999\n      DOI: 10.17487/RFC8999\n    author:\n      -\n        ins: M. Thomson\n        name: Martin Thomson\n        org: Mozilla\n\n  QUIC-RECOVERY:\n    title: \"QUIC Loss Detection and Congestion Control\"\n    date: 2021-05\n    seriesinfo:\n      RFC: 9002\n      DOI: 10.17487/RFC9002\n    author:\n      -\n        ins: J. Iyengar\n        name: Jana Iyengar\n        org: Fastly\n        role: editor\n      -\n        ins: I. Swett\n        name: Ian Swett\n        org: Google\n        role: editor\n\n  QUIC-TLS:\n    title: \"Using TLS to Secure QUIC\"\n    date: 2021-05\n    seriesinfo:\n      RFC: 9001\n      DOI: 10.17487/RFC9001\n    author:\n      -\n        ins: M. Thomson\n        name: Martin Thomson\n        org: Mozilla\n        role: editor\n      -\n        ins: S. Turner\n        name: Sean Turner\n        org: sn3rd\n        role: editor\n\n  TLS13: RFC8446\n  RFC8126:\n\ninformative:\n\n  EARLY-DESIGN:\n    title: \"QUIC: Multiplexed Stream Transport Over UDP\"\n    author:\n      - ins: J. Roskind\n    date: 2013-12-02\n    target: \"https://docs.google.com/document/d/1RNHkx_VvKWyWg6Lr8SZ-saqsQx7rFV-ev2jRFUoVD34/edit?usp=sharing\"\n\n  SLOWLORIS:\n    title: \"Welcome to Slowloris - the low bandwidth, yet greedy and poisonous HTTP client!\"\n    author:\n      -\n        initials: R.\n        surname: \"\\\"RSnake\\\" Hansen\"\n    date: 2009-06\n    target:\n     \"https://web.archive.org/web/20150315054838/http://ha.ckers.org/slowloris/\"\n\n  GATEWAY:\n    title: \"An experimental study of home gateway characteristics\"\n    author:\n      -\n        initials: S.\n        surname: Hätönen\n        fullname: Seppo Hätönen\n      -\n        initials: A.\n        surname: Nyrhinen\n        fullname: Aki Nyrhinen\n      -\n        initials: L.\n        surname: Eggert\n        fullname: Lars Eggert\n      -\n        initials: S.\n        surname: Strowes\n        fullname: Stephen Strowes\n      -\n        initials: P.\n        surname: Sarolahti\n        fullname: Pasi Sarolahti\n      -\n        initials: M.\n        surname: Kojo\n        fullname: Markku Kojo\n    date: 2010-11\n    refcontent:\n      - \"Proceedings of the 10th ACM SIGCOMM conference on Internet measurement - IMC '10\"\n    seriesinfo:\n      DOI: 10.1145/1879141.1879174\n\n  RFC3449:\n\n\n--- abstract\n\nThis document defines the core of the QUIC transport protocol.  QUIC provides\napplications with flow-controlled streams for structured communication,\nlow-latency connection establishment, and network path migration. QUIC includes\nsecurity measures that ensure confidentiality, integrity, and availability in a\nrange of deployment circumstances.  Accompanying documents describe the\nintegration of TLS for key negotiation, loss detection, and an exemplary\ncongestion control algorithm.\n\n\n--- middle\n\n# Overview\n\nQUIC is a secure general-purpose transport protocol. This\ndocument defines version 1 of QUIC, which conforms to the version-independent\nproperties of QUIC defined in {{QUIC-INVARIANTS}}.\n\nQUIC is a connection-oriented protocol that creates a stateful interaction\nbetween a client and server.\n\nThe QUIC handshake combines negotiation of cryptographic and transport\nparameters. QUIC integrates the TLS handshake {{TLS13}}, although using a\ncustomized framing for protecting packets. The integration of TLS and QUIC is\ndescribed in more detail in {{QUIC-TLS}}. The handshake is structured to permit\nthe exchange of application data as soon as possible. This includes an option\nfor clients to send data immediately (0-RTT), which requires some form of prior\ncommunication or configuration to enable.\n\nEndpoints communicate in QUIC by exchanging QUIC packets. Most packets contain\nframes, which carry control information and application data between endpoints.\nQUIC authenticates the entirety of each packet and encrypts as much of each\npacket as is practical. QUIC packets are carried in UDP datagrams\n{{!UDP=RFC0768}} to better facilitate deployment in existing systems and\nnetworks.\n\nApplication protocols exchange information over a QUIC connection via streams,\nwhich are ordered sequences of bytes. Two types of streams can be created:\nbidirectional streams, which allow both endpoints to send data; and\nunidirectional streams, which allow a single endpoint to send data. A\ncredit-based scheme is used to limit stream creation and to bound the amount of\ndata that can be sent.\n\nQUIC provides the necessary feedback to implement reliable delivery and\ncongestion control. An algorithm for detecting and recovering from loss of data\nis described in {{Section 6 of QUIC-RECOVERY}}. QUIC depends on congestion\ncontrol to avoid network congestion. An exemplary congestion control algorithm\nis described in {{Section 7 of QUIC-RECOVERY}}.\n\nQUIC connections are not strictly bound to a single network path. Connection\nmigration uses connection identifiers to allow connections to transfer to a new\nnetwork path. Only clients are able to migrate in this version of QUIC. This\ndesign also allows connections to continue after changes in network topology or\naddress mappings, such as might be caused by NAT rebinding.\n\nOnce established, multiple options are provided for connection termination.\nApplications can manage a graceful shutdown, endpoints can negotiate a timeout\nperiod, errors can cause immediate connection teardown, and a stateless\nmechanism provides for termination of connections after one endpoint has lost\nstate.\n\n\n## Document Structure\n\nThis document describes the core QUIC protocol and is structured as follows:\n\n* Streams are the basic service abstraction that QUIC provides.\n  - {{streams}} describes core concepts related to streams,\n  - {{stream-states}} provides a reference model for stream states, and\n  - {{flow-control}} outlines the operation of flow control.\n\n* Connections are the context in which QUIC endpoints communicate.\n  - {{connections}} describes core concepts related to connections,\n  - {{version-negotiation}} describes version negotiation,\n  - {{handshake}} details the process for establishing connections,\n  - {{address-validation}} describes address validation and critical\n    denial-of-service mitigations,\n  - {{migration}} describes how endpoints migrate a connection to a new\n    network path,\n  - {{termination}} lists the options for terminating an open connection, and\n  - {{error-handling}} provides guidance for stream and connection error\n    handling.\n\n* Packets and frames are the basic unit used by QUIC to communicate.\n  - {{packets-frames}} describes concepts related to packets and frames,\n  - {{packetization}} defines models for the transmission, retransmission, and\n    acknowledgment of data, and\n  - {{datagram-size}} specifies rules for managing the size of datagrams\n    carrying QUIC packets.\n\n* Finally, encoding details of QUIC protocol elements are described in:\n  - {{versions}} (versions),\n  - {{integer-encoding}} (integer encoding),\n  - {{packet-formats}} (packet headers),\n  - {{transport-parameter-encoding}} (transport parameters),\n  - {{frame-formats}} (frames), and\n  - {{error-codes}} (errors).\n\nAccompanying documents describe QUIC's loss detection and congestion control\n{{QUIC-RECOVERY}}, and the use of TLS and other cryptographic mechanisms\n{{QUIC-TLS}}.\n\nThis document defines QUIC version 1, which conforms to the protocol invariants\nin {{QUIC-INVARIANTS}}.\n\nTo refer to QUIC version 1, cite this document.  References to the limited\nset of version-independent properties of QUIC can cite {{QUIC-INVARIANTS}}.\n\n\n## Terms and Definitions\n\nThe key words \"MUST\", \"MUST NOT\", \"REQUIRED\", \"SHALL\", \"SHALL NOT\", \"SHOULD\",\n\"SHOULD NOT\", \"RECOMMENDED\", \"NOT RECOMMENDED\", \"MAY\", and \"OPTIONAL\" in this\ndocument are to be interpreted as described in BCP 14 {{!RFC2119}} {{!RFC8174}}\nwhen, and only when, they appear in all capitals, as shown here.\n\nCommonly used terms in this document are described below.\n\nQUIC:\n\n: The transport protocol described by this document. QUIC is a name, not an\n  acronym.\n\nEndpoint:\n\n: An entity that can participate in a QUIC connection by generating, receiving,\n  and processing QUIC packets. There are only two types of endpoints in QUIC:\n  client and server.\n\nClient:\n\n: The endpoint that initiates a QUIC connection.\n\nServer:\n\n: The endpoint that accepts a QUIC connection.\n\nQUIC packet:\n\n: A complete processable unit of QUIC that can be encapsulated in a UDP\n  datagram.  One or more QUIC packets can be encapsulated in a single UDP\n  datagram.\n\nAck-eliciting packet:\n\n: A QUIC packet that contains frames other than ACK, PADDING, and\n  CONNECTION_CLOSE. These cause a recipient to send an acknowledgment; see\n  {{sending-acknowledgments}}.\n\nFrame:\n\n: A unit of structured protocol information.  There are multiple frame types,\n  each of which carries different information.  Frames are contained in QUIC\n  packets.\n\nAddress:\n\n: When used without qualification, the tuple of IP version, IP address, and UDP\n  port number that represents one end of a network path.\n\nConnection ID:\n\n: An identifier that is used to identify a QUIC connection at an endpoint.\n  Each endpoint selects one or more connection IDs for its peer to include in\n  packets sent towards the endpoint.  This value is opaque to the peer.\n\nStream:\n\n: A unidirectional or bidirectional channel of ordered bytes within a QUIC\n  connection. A QUIC connection can carry multiple simultaneous streams.\n\nApplication:\n\n: An entity that uses QUIC to send and receive data.\n\nThis document uses the terms \"QUIC packets\", \"UDP datagrams\", and \"IP packets\"\nto refer to the units of the respective protocols. That is, one or more QUIC\npackets can be encapsulated in a UDP datagram, which is in turn encapsulated in\nan IP packet.\n\n\n## Notational Conventions {#notation}\n\nPacket and frame diagrams in this document use a custom format. The purpose of\nthis format is to summarize, not define, protocol elements. Prose defines the\ncomplete semantics and details of structures.\n\nComplex fields are named and then followed by a list of fields surrounded by a\npair of matching braces. Each field in this list is separated by commas.\n\nIndividual fields include length information, plus indications about fixed\nvalue, optionality, or repetitions. Individual fields use the following\nnotational conventions, with all lengths in bits:\n\nx (A):\n: Indicates that x is A bits long\n\nx (i):\n: Indicates that x holds an integer value using the variable-length encoding\n  described in {{integer-encoding}}\n\nx (A..B):\n: Indicates that x can be any length from A to B; A can be omitted to indicate\n  a minimum of zero bits, and B can be omitted to indicate no set upper limit;\n  values in this format always end on a byte boundary\n\nx (L) = C:\n: Indicates that x has a fixed value of C; the length of x is described by\n  L, which can use any of the length forms above\n\nx (L) = C..D:\n: Indicates that x has a value in the range from C to D, inclusive,\n  with the length described by L, as above\n\n\\[x (L)\\]:\n: Indicates that x is optional and has a length of L\n\nx (L) ...:\n: Indicates that x is repeated zero or more times and that each instance has a\n  length of L\n\nThis document uses network byte order (that is, big endian) values.  Fields\nare placed starting from the high-order bits of each byte.\n\nBy convention, individual fields reference a complex field by using the name of\nthe complex field.\n\n{{fig-ex-format}} provides an example:\n\n~~~\nExample Structure {\n  One-bit Field (1),\n  7-bit Field with Fixed Value (7) = 61,\n  Field with Variable-Length Integer (i),\n  Arbitrary-Length Field (..),\n  Variable-Length Field (8..24),\n  Field With Minimum Length (16..),\n  Field With Maximum Length (..128),\n  [Optional Field (64)],\n  Repeated Field (8) ...,\n}\n~~~\n{: #fig-ex-format title=\"Example Format\"}\n\nWhen a single-bit field is referenced in prose, the position of that field can\nbe clarified by using the value of the byte that carries the field with the\nfield's value set. For example, the value 0x80 could be used to refer to the\nsingle-bit field in the most significant bit of the byte, such as One-bit Field\nin {{fig-ex-format}}.\n\n\n# Streams {#streams}\n\nStreams in QUIC provide a lightweight, ordered byte-stream abstraction to an\napplication. Streams can be unidirectional or bidirectional.\n\nStreams can be created by sending data. Other processes associated with stream\nmanagement -- ending, canceling, and managing flow control -- are all designed\nto impose minimal overheads. For instance, a single STREAM frame\n({{frame-stream}}) can open, carry data for, and close a stream. Streams can\nalso be long-lived and can last the entire duration of a connection.\n\nStreams can be created by either endpoint, can concurrently send data\ninterleaved with other streams, and can be canceled. QUIC does not provide any\nmeans of ensuring ordering between bytes on different streams.\n\nQUIC allows for an arbitrary number of streams to operate concurrently and for\nan arbitrary amount of data to be sent on any stream, subject to flow control\nconstraints and stream limits; see {{flow-control}}.\n\n\n## Stream Types and Identifiers {#stream-id}\n\nStreams can be unidirectional or bidirectional.  Unidirectional streams carry\ndata in one direction: from the initiator of the stream to its peer.\nBidirectional streams allow for data to be sent in both directions.\n\nStreams are identified within a connection by a numeric value, referred to as\nthe stream ID.  A stream ID is a 62-bit integer (0 to 2<sup>62</sup>-1) that is\nunique for all streams on a connection.  Stream IDs are encoded as\nvariable-length integers; see {{integer-encoding}}.  A QUIC endpoint MUST NOT\nreuse a stream ID within a connection.\n\nThe least significant bit (0x01) of the stream ID identifies the initiator of\nthe stream.  Client-initiated streams have even-numbered stream IDs (with the\nbit set to 0), and server-initiated streams have odd-numbered stream IDs (with\nthe bit set to 1).\n\nThe second least significant bit (0x02) of the stream ID distinguishes between\nbidirectional streams (with the bit set to 0) and unidirectional streams (with\nthe bit set to 1).\n\nThe two least significant bits from a stream ID therefore identify a stream as\none of four types, as summarized in {{stream-id-types}}.\n\n| Bits | Stream Type                      |\n|:-----|:---------------------------------|\n| 0x00 | Client-Initiated, Bidirectional  |\n| 0x01 | Server-Initiated, Bidirectional  |\n| 0x02 | Client-Initiated, Unidirectional |\n| 0x03 | Server-Initiated, Unidirectional |\n{: #stream-id-types title=\"Stream ID Types\"}\n\nThe stream space for each type begins at the minimum value (0x00 through 0x03,\nrespectively); successive streams of each type are created with numerically\nincreasing stream IDs.  A stream ID that is used out of order results in all\nstreams of that type with lower-numbered stream IDs also being opened.\n\n\n## Sending and Receiving Data\n\nSTREAM frames ({{frame-stream}}) encapsulate data sent by an application. An\nendpoint uses the Stream ID and Offset fields in STREAM frames to place data in\norder.\n\nEndpoints MUST be able to deliver stream data to an application as an ordered\nbyte stream.  Delivering an ordered byte stream requires that an endpoint buffer\nany data that is received out of order, up to the advertised flow control limit.\n\nQUIC makes no specific allowances for delivery of stream data out of\norder. However, implementations MAY choose to offer the ability to deliver data\nout of order to a receiving application.\n\nAn endpoint could receive data for a stream at the same stream offset multiple\ntimes.  Data that has already been received can be discarded.  The data at a\ngiven offset MUST NOT change if it is sent multiple times; an endpoint MAY treat\nreceipt of different data at the same offset within a stream as a connection\nerror of type PROTOCOL_VIOLATION.\n\nStreams are an ordered byte-stream abstraction with no other structure visible\nto QUIC.  STREAM frame boundaries are not expected to be preserved when\ndata is transmitted, retransmitted after packet loss, or delivered to the\napplication at a receiver.\n\nAn endpoint MUST NOT send data on any stream without ensuring that it is within\nthe flow control limits set by its peer.  Flow control is described in detail in\n{{flow-control}}.\n\n\n## Stream Prioritization {#stream-prioritization}\n\nStream multiplexing can have a significant effect on application performance if\nresources allocated to streams are correctly prioritized.\n\nQUIC does not provide a mechanism for exchanging prioritization information.\nInstead, it relies on receiving priority information from the application.\n\nA QUIC implementation SHOULD provide ways in which an application can indicate\nthe relative priority of streams.  An implementation uses information provided\nby the application to determine how to allocate resources to active streams.\n\n## Operations on Streams {#stream-operations}\n\nThis document does not define an API for QUIC; it instead defines a set of\nfunctions on streams that application protocols can rely upon.  An application\nprotocol can assume that a QUIC implementation provides an interface that\nincludes the operations described in this section.  An implementation designed\nfor use with a specific application protocol might provide only those operations\nthat are used by that protocol.\n\nOn the sending part of a stream, an application protocol can:\n\n- write data, understanding when stream flow control credit\n  ({{data-flow-control}}) has successfully been reserved to send the written\n  data;\n- end the stream (clean termination), resulting in a STREAM frame\n  ({{frame-stream}}) with the FIN bit set; and\n- reset the stream (abrupt termination), resulting in a RESET_STREAM frame\n  ({{frame-reset-stream}}) if the stream was not already in a terminal state.\n\nOn the receiving part of a stream, an application protocol can:\n\n- read data; and\n- abort reading of the stream and request closure, possibly resulting in a\n  STOP_SENDING frame ({{frame-stop-sending}}).\n\nAn application protocol can also request to be informed of state changes on\nstreams, including when the peer has opened or reset a stream, when a peer\naborts reading on a stream, when new data is available, and when data can or\ncannot be written to the stream due to flow control.\n\n\n# Stream States {#stream-states}\n\nThis section describes streams in terms of their send or receive components.\nTwo state machines are described: one for the streams on which an endpoint\ntransmits data ({{stream-send-states}}) and another for streams on which an\nendpoint receives data ({{stream-recv-states}}).\n\nUnidirectional streams use either the sending or receiving state machine,\ndepending on the stream type and endpoint role. Bidirectional streams use both\nstate machines at both endpoints. For the most part, the use of these state\nmachines is the same whether the stream is unidirectional or bidirectional. The\nconditions for opening a stream are slightly more complex for a bidirectional\nstream because the opening of either the send or receive side causes the stream\nto open in both directions.\n\nThe state machines shown in this section are largely informative.  This\ndocument uses stream states to describe rules for when and how different types\nof frames can be sent and the reactions that are expected when different types\nof frames are received.  Though these state machines are intended to be useful\nin implementing QUIC, these states are not intended to constrain\nimplementations. An implementation can define a different state machine as long\nas its behavior is consistent with an implementation that implements these\nstates.\n\n<aside markdown=\"block\">\n  Note: In some cases, a single event or action can cause a transition\n  through multiple states.  For instance, sending STREAM with a FIN bit set can\n  cause two state transitions for a sending stream: from the \"Ready\" state to\n  the \"Send\" state, and from the \"Send\" state to the \"Data Sent\" state.\n</aside>\n\n\n## Sending Stream States {#stream-send-states}\n\n{{fig-stream-send-states}} shows the states for the part of a stream that sends\ndata to a peer.\n\n~~~\n       o\n       | Create Stream (Sending)\n       | Peer Creates Bidirectional Stream\n       v\n   +-------+\n   | Ready | Send RESET_STREAM\n   |       |-----------------------.\n   +-------+                       |\n       |                           |\n       | Send STREAM /             |\n       |      STREAM_DATA_BLOCKED  |\n       v                           |\n   +-------+                       |\n   | Send  | Send RESET_STREAM     |\n   |       |---------------------->|\n   +-------+                       |\n       |                           |\n       | Send STREAM + FIN         |\n       v                           v\n   +-------+                   +-------+\n   | Data  | Send RESET_STREAM | Reset |\n   | Sent  |------------------>| Sent  |\n   +-------+                   +-------+\n       |                           |\n       | Recv All ACKs             | Recv ACK\n       v                           v\n   +-------+                   +-------+\n   | Data  |                   | Reset |\n   | Recvd |                   | Recvd |\n   +-------+                   +-------+\n~~~\n{: #fig-stream-send-states title=\"States for Sending Parts of Streams\"}\n\nThe sending part of a stream that the endpoint initiates (types 0\nand 2 for clients, 1 and 3 for servers) is opened by the application.  The\n\"Ready\" state represents a newly created stream that is able to accept data from\nthe application.  Stream data might be buffered in this state in preparation for\nsending.\n\nSending the first STREAM or STREAM_DATA_BLOCKED frame causes a sending part of a\nstream to enter the \"Send\" state.  An implementation might choose to defer\nallocating a stream ID to a stream until it sends the first STREAM frame and\nenters this state, which can allow for better stream prioritization.\n\nThe sending part of a bidirectional stream initiated by a peer (type 0 for a\nserver, type 1 for a client) starts in the \"Ready\" state when the receiving part\nis created.\n\nIn the \"Send\" state, an endpoint transmits -- and retransmits as necessary --\nstream data in STREAM frames.  The endpoint respects the flow control limits set\nby its peer and continues to accept and process MAX_STREAM_DATA frames.  An\nendpoint in the \"Send\" state generates STREAM_DATA_BLOCKED frames if it is\nblocked from sending by stream flow control limits ({{data-flow-control}}).\n\nAfter the application indicates that all stream data has been sent and a STREAM\nframe containing the FIN bit is sent, the sending part of the stream enters the\n\"Data Sent\" state.  From this state, the endpoint only retransmits stream data\nas necessary.  The endpoint does not need to check flow control limits or send\nSTREAM_DATA_BLOCKED frames for a stream in this state.  MAX_STREAM_DATA frames\nmight be received until the peer receives the final stream offset. The endpoint\ncan safely ignore any MAX_STREAM_DATA frames it receives from its peer for a\nstream in this state.\n\nOnce all stream data has been successfully acknowledged, the sending part of the\nstream enters the \"Data Recvd\" state, which is a terminal state.\n\nFrom any state that is one of \"Ready\", \"Send\", or \"Data Sent\", an application\ncan signal that it wishes to abandon transmission of stream data. Alternatively,\nan endpoint might receive a STOP_SENDING frame from its peer.  In either case,\nthe endpoint sends a RESET_STREAM frame, which causes the stream to enter the\n\"Reset Sent\" state.\n\nAn endpoint MAY send a RESET_STREAM as the first frame that mentions a stream;\nthis causes the sending part of that stream to open and then immediately\ntransition to the \"Reset Sent\" state.\n\nOnce a packet containing a RESET_STREAM has been acknowledged, the sending part\nof the stream enters the \"Reset Recvd\" state, which is a terminal state.\n\n\n## Receiving Stream States {#stream-recv-states}\n\n{{fig-stream-recv-states}} shows the states for the part of a stream that\nreceives data from a peer.  The states for a receiving part of a stream mirror\nonly some of the states of the sending part of the stream at the peer.  The\nreceiving part of a stream does not track states on the sending part that cannot\nbe observed, such as the \"Ready\" state.  Instead, the receiving part of a stream\ntracks the delivery of data to the application, some of which cannot be observed\nby the sender.\n\n~~~\n       o\n       | Recv STREAM / STREAM_DATA_BLOCKED / RESET_STREAM\n       | Create Bidirectional Stream (Sending)\n       | Recv MAX_STREAM_DATA / STOP_SENDING (Bidirectional)\n       | Create Higher-Numbered Stream\n       v\n   +-------+\n   | Recv  | Recv RESET_STREAM\n   |       |-----------------------.\n   +-------+                       |\n       |                           |\n       | Recv STREAM + FIN         |\n       v                           |\n   +-------+                       |\n   | Size  | Recv RESET_STREAM     |\n   | Known |---------------------->|\n   +-------+                       |\n       |                           |\n       | Recv All Data             |\n       v                           v\n   +-------+ Recv RESET_STREAM +-------+\n   | Data  |--- (optional) --->| Reset |\n   | Recvd |  Recv All Data    | Recvd |\n   +-------+<-- (optional) ----+-------+\n       |                           |\n       | App Read All Data         | App Read Reset\n       v                           v\n   +-------+                   +-------+\n   | Data  |                   | Reset |\n   | Read  |                   | Read  |\n   +-------+                   +-------+\n~~~\n{: #fig-stream-recv-states title=\"States for Receiving Parts of Streams\"}\n\nThe receiving part of a stream initiated by a peer (types 1 and 3 for a client,\nor 0 and 2 for a server) is created when the first STREAM, STREAM_DATA_BLOCKED,\nor RESET_STREAM frame is received for that stream.  For bidirectional streams\ninitiated by a peer, receipt of a MAX_STREAM_DATA or STOP_SENDING frame for the\nsending part of the stream also creates the receiving part.  The initial state\nfor the receiving part of a stream is \"Recv\".\n\nFor a bidirectional stream, the receiving part enters the \"Recv\" state when the\nsending part initiated by the endpoint (type 0 for a client, type\n1 for a server) enters the \"Ready\" state.\n\nAn endpoint opens a bidirectional stream when a MAX_STREAM_DATA or STOP_SENDING\nframe is received from the peer for that stream.  Receiving a MAX_STREAM_DATA\nframe for an unopened stream indicates that the remote peer has opened the\nstream and is providing flow control credit.  Receiving a STOP_SENDING frame for\nan unopened stream indicates that the remote peer no longer wishes to receive\ndata on this stream.  Either frame might arrive before a STREAM or\nSTREAM_DATA_BLOCKED frame if packets are lost or reordered.\n\nBefore a stream is created, all streams of the same type with lower-numbered\nstream IDs MUST be created.  This ensures that the creation order for streams is\nconsistent on both endpoints.\n\nIn the \"Recv\" state, the endpoint receives STREAM and STREAM_DATA_BLOCKED\nframes.  Incoming data is buffered and can be reassembled into the correct order\nfor delivery to the application.  As data is consumed by the application and\nbuffer space becomes available, the endpoint sends MAX_STREAM_DATA frames to\nallow the peer to send more data.\n\nWhen a STREAM frame with a FIN bit is received, the final size of the stream is\nknown; see {{final-size}}.  The receiving part of the stream then enters the\n\"Size Known\" state.  In this state, the endpoint no longer needs to send\nMAX_STREAM_DATA frames; it only receives any retransmissions of stream data.\n\nOnce all data for the stream has been received, the receiving part enters the\n\"Data Recvd\" state.  This might happen as a result of receiving the same STREAM\nframe that causes the transition to \"Size Known\".  After all data has been\nreceived, any STREAM or STREAM_DATA_BLOCKED frames for the stream can be\ndiscarded.\n\nThe \"Data Recvd\" state persists until stream data has been delivered to the\napplication.  Once stream data has been delivered, the stream enters the \"Data\nRead\" state, which is a terminal state.\n\nReceiving a RESET_STREAM frame in the \"Recv\" or \"Size Known\" state causes the\nstream to enter the \"Reset Recvd\" state.  This might cause the delivery of\nstream data to the application to be interrupted.\n\nIt is possible that all stream data has already been received when a\nRESET_STREAM is received (that is, in the \"Data Recvd\" state).  Similarly, it is\npossible for remaining stream data to arrive after receiving a RESET_STREAM\nframe (the \"Reset Recvd\" state).  An implementation is free to manage this\nsituation as it chooses.\n\nSending a RESET_STREAM means that an endpoint cannot guarantee delivery of\nstream data; however, there is no requirement that stream data not be delivered\nif a RESET_STREAM is received.  An implementation MAY interrupt delivery of\nstream data, discard any data that was not consumed, and signal the receipt of\nthe RESET_STREAM.  A RESET_STREAM signal might be suppressed or withheld if\nstream data is completely received and is buffered to be read by the\napplication.  If the RESET_STREAM is suppressed, the receiving part of the\nstream remains in \"Data Recvd\".\n\nOnce the application receives the signal indicating that the stream\nwas reset, the receiving part of the stream transitions to the \"Reset Read\"\nstate, which is a terminal state.\n\n\n## Permitted Frame Types\n\nThe sender of a stream sends just three frame types that affect the state of a\nstream at either the sender or the receiver: STREAM ({{frame-stream}}),\nSTREAM_DATA_BLOCKED ({{frame-stream-data-blocked}}), and RESET_STREAM\n({{frame-reset-stream}}).\n\nA sender MUST NOT send any of these frames from a terminal state (\"Data Recvd\"\nor \"Reset Recvd\").  A sender MUST NOT send a STREAM or STREAM_DATA_BLOCKED frame\nfor a stream in the \"Reset Sent\" state or any terminal state -- that is, after\nsending a RESET_STREAM frame.  A receiver could receive any of these three\nframes in any state, due to the possibility of delayed delivery of packets\ncarrying them.\n\nThe receiver of a stream sends MAX_STREAM_DATA frames\n({{frame-max-stream-data}}) and STOP_SENDING frames ({{frame-stop-sending}}).\n\nThe receiver only sends MAX_STREAM_DATA frames in the \"Recv\" state.  A receiver\nMAY send a STOP_SENDING frame in any state where it has not received a\nRESET_STREAM frame -- that is, states other than \"Reset Recvd\" or \"Reset Read\".\nHowever, there is little value in sending a STOP_SENDING frame in the \"Data\nRecvd\" state, as all stream data has been received.  A sender could receive\neither of these two types of frames in any state as a result of delayed delivery\nof packets.\n\n\n## Bidirectional Stream States {#stream-bidi-states}\n\nA bidirectional stream is composed of sending and receiving parts.\nImplementations can represent states of the bidirectional stream as composites\nof sending and receiving stream states.  The simplest model presents the stream\nas \"open\" when either sending or receiving parts are in a non-terminal state and\n\"closed\" when both sending and receiving streams are in terminal states.\n\n{{stream-bidi-mapping}} shows a more complex mapping of bidirectional stream\nstates that loosely correspond to the stream states defined in HTTP/2\n{{?HTTP2=RFC7540}}.  This shows that multiple states on sending or receiving\nparts of streams are mapped to the same composite state.  Note that this is just\none possibility for such a mapping; this mapping requires that data be\nacknowledged before the transition to a \"closed\" or \"half-closed\" state.\n\n| Sending Part             | Receiving Part           | Composite State      |\n|:-------------------------|:-------------------------|:---------------------|\n| No Stream / Ready        | No Stream / Recv (*1)    | idle                 |\n| Ready / Send / Data Sent | Recv / Size Known        | open                 |\n| Ready / Send / Data Sent | Data Recvd / Data Read   | half-closed (remote) |\n| Ready / Send / Data Sent | Reset Recvd / Reset Read | half-closed (remote) |\n| Data Recvd               | Recv / Size Known        | half-closed (local)  |\n| Reset Sent / Reset Recvd | Recv / Size Known        | half-closed (local)  |\n| Reset Sent / Reset Recvd | Data Recvd / Data Read   | closed               |\n| Reset Sent / Reset Recvd | Reset Recvd / Reset Read | closed               |\n| Data Recvd               | Data Recvd / Data Read   | closed               |\n| Data Recvd               | Reset Recvd / Reset Read | closed               |\n{: #stream-bidi-mapping title=\"Possible Mapping of Stream States to HTTP/2\"}\n\n<aside markdown=\"block\">\nNote (*1): A stream is considered \"idle\" if it has not yet been created or if\nthe receiving part of the stream is in the \"Recv\" state without yet having\nreceived any frames.\n</aside>\n\n\n## Solicited State Transitions\n\nIf an application is no longer interested in the data it is receiving on a\nstream, it can abort reading the stream and specify an application error code.\n\nIf the stream is in the \"Recv\" or \"Size Known\" state, the transport SHOULD\nsignal this by sending a STOP_SENDING frame to prompt closure of the stream in\nthe opposite direction.  This typically indicates that the receiving application\nis no longer reading data it receives from the stream, but it is not a guarantee\nthat incoming data will be ignored.\n\nSTREAM frames received after sending a STOP_SENDING frame are still counted\ntoward connection and stream flow control, even though these frames can be\ndiscarded upon receipt.\n\nA STOP_SENDING frame requests that the receiving endpoint send a RESET_STREAM\nframe.  An endpoint that receives a STOP_SENDING frame MUST send a RESET_STREAM\nframe if the stream is in the \"Ready\" or \"Send\" state.  If the stream is in the\n\"Data Sent\" state, the endpoint MAY defer sending the RESET_STREAM frame until\nthe packets containing outstanding data are acknowledged or declared lost.  If\nany outstanding data is declared lost, the endpoint SHOULD send a RESET_STREAM\nframe instead of retransmitting the data.\n\nAn endpoint SHOULD copy the error code from the STOP_SENDING frame to the\nRESET_STREAM frame it sends, but it can use any application error code.  An\nendpoint that sends a STOP_SENDING frame MAY ignore the error code in any\nRESET_STREAM frames subsequently received for that stream.\n\nSTOP_SENDING SHOULD only be sent for a stream that has not been reset by the\npeer. STOP_SENDING is most useful for streams in the \"Recv\" or \"Size Known\"\nstate.\n\nAn endpoint is expected to send another STOP_SENDING frame if a packet\ncontaining a previous STOP_SENDING is lost.  However, once either all stream\ndata or a RESET_STREAM frame has been received for the stream -- that is, the\nstream is in any state other than \"Recv\" or \"Size Known\" -- sending a\nSTOP_SENDING frame is unnecessary.\n\nAn endpoint that wishes to terminate both directions of a bidirectional stream\ncan terminate one direction by sending a RESET_STREAM frame, and it can\nencourage prompt termination in the opposite direction by sending a STOP_SENDING\nframe.\n\n\n# Flow Control {#flow-control}\n\nReceivers need to limit the amount of data that they are required to buffer, in\norder to prevent a fast sender from overwhelming them or a malicious sender from\nconsuming a large amount of memory.  To enable a receiver to limit memory\ncommitments for a connection, streams are flow controlled both individually and\nacross a connection as a whole.  A QUIC receiver controls the maximum amount of\ndata the sender can send on a stream as well as across all streams at any time,\nas described in Sections {{<data-flow-control}} and {{<fc-credit}}.\n\nSimilarly, to limit concurrency within a connection, a QUIC endpoint controls\nthe maximum cumulative number of streams that its peer can initiate, as\ndescribed in {{controlling-concurrency}}.\n\nData sent in CRYPTO frames is not flow controlled in the same way as stream\ndata.  QUIC relies on the cryptographic protocol implementation to avoid\nexcessive buffering of data; see {{QUIC-TLS}}. To avoid excessive buffering at\nmultiple layers, QUIC implementations SHOULD provide an interface for the\ncryptographic protocol implementation to communicate its buffering limits.\n\n\n## Data Flow Control {#data-flow-control}\n\nQUIC employs a limit-based flow control scheme where a receiver advertises the\nlimit of total bytes it is prepared to receive on a given stream or for the\nentire connection.  This leads to two levels of data flow control in QUIC:\n\n* Stream flow control, which prevents a single stream from consuming the entire\n  receive buffer for a connection by limiting the amount of data that can be\n  sent on each stream.\n\n* Connection flow control, which prevents senders from exceeding a receiver's\n  buffer capacity for the connection by limiting the total bytes of stream data\n  sent in STREAM frames on all streams.\n\nSenders MUST NOT send data in excess of either limit.\n\nA receiver sets initial limits for all streams through transport parameters\nduring the handshake ({{transport-parameters}}).  Subsequently, a receiver sends\nMAX_STREAM_DATA frames ({{frame-max-stream-data}}) or MAX_DATA frames\n({{frame-max-data}}) to the sender to advertise larger limits.\n\nA receiver can advertise a larger limit for a stream by sending a\nMAX_STREAM_DATA frame with the corresponding stream ID. A MAX_STREAM_DATA frame\nindicates the maximum absolute byte offset of a stream. A receiver could\ndetermine the flow control offset to be advertised based on the current offset\nof data consumed on that stream.\n\nA receiver can advertise a larger limit for a connection by sending a MAX_DATA\nframe, which indicates the maximum of the sum of the absolute byte offsets of\nall streams.  A receiver maintains a cumulative sum of bytes received on all\nstreams, which is used to check for violations of the advertised connection or\nstream data limits. A receiver could determine the maximum data limit to be\nadvertised based on the sum of bytes consumed on all streams.\n\nOnce a receiver advertises a limit for the connection or a stream, it is not an\nerror to advertise a smaller limit, but the smaller limit has no effect.\n\nA receiver MUST close the connection with an error of type FLOW_CONTROL_ERROR if\nthe sender violates the advertised connection or stream data limits; see\n{{error-handling}} for details on error handling.\n\nA sender MUST ignore any MAX_STREAM_DATA or MAX_DATA frames that do not increase\nflow control limits.\n\nIf a sender has sent data up to the limit, it will be unable to send new data\nand is considered blocked.  A sender SHOULD send a STREAM_DATA_BLOCKED or\nDATA_BLOCKED frame to indicate to the receiver that it has data to write but is\nblocked by flow control limits.  If a sender is blocked for a period longer than\nthe idle timeout ({{idle-timeout}}), the receiver might close the connection\neven when the sender has data that is available for transmission.  To keep the\nconnection from closing, a sender that is flow control limited SHOULD\nperiodically send a STREAM_DATA_BLOCKED or DATA_BLOCKED frame when it has no\nack-eliciting packets in flight.\n\n\n## Increasing Flow Control Limits {#fc-credit}\n\nImplementations decide when and how much credit to advertise in MAX_STREAM_DATA\nand MAX_DATA frames, but this section offers a few considerations.\n\nTo avoid blocking a sender, a receiver MAY send a MAX_STREAM_DATA or MAX_DATA\nframe multiple times within a round trip or send it early enough to allow time\nfor loss of the frame and subsequent recovery.\n\nControl frames contribute to connection overhead. Therefore, frequently sending\nMAX_STREAM_DATA and MAX_DATA frames with small changes is undesirable.  On the\nother hand, if updates are less frequent, larger increments to limits are\nnecessary to avoid blocking a sender, requiring larger resource commitments at\nthe receiver.  There is a trade-off between resource commitment and overhead\nwhen determining how large a limit is advertised.\n\nA receiver can use an autotuning mechanism to tune the frequency and amount of\nadvertised additional credit based on a round-trip time estimate and the rate at\nwhich the receiving application consumes data, similar to common TCP\nimplementations.  As an optimization, an endpoint could send frames related to\nflow control only when there are other frames to send, ensuring that flow\ncontrol does not cause extra packets to be sent.\n\nA blocked sender is not required to send STREAM_DATA_BLOCKED or DATA_BLOCKED\nframes. Therefore, a receiver MUST NOT wait for a STREAM_DATA_BLOCKED or\nDATA_BLOCKED frame before sending a MAX_STREAM_DATA or MAX_DATA frame; doing so\ncould result in the sender being blocked for the rest of the connection. Even if\nthe sender sends these frames, waiting for them will result in the sender being\nblocked for at least an entire round trip.\n\nWhen a sender receives credit after being blocked, it might be able to send a\nlarge amount of data in response, resulting in short-term congestion; see\n{{Section 7.7 of QUIC-RECOVERY}} for a discussion of how a sender can avoid this\ncongestion.\n\n\n## Flow Control Performance\n\nIf an endpoint cannot ensure that its peer always has available flow control\ncredit that is greater than the peer's bandwidth-delay product on this\nconnection, its receive throughput will be limited by flow control.\n\nPacket loss can cause gaps in the receive buffer, preventing the application\nfrom consuming data and freeing up receive buffer space.\n\nSending timely updates of flow control limits can improve performance.\nSending packets only to provide flow control updates can increase network\nload and adversely affect performance. Sending flow control updates along with\nother frames, such as ACK frames, reduces the cost of those updates.\n\n\n## Handling Stream Cancellation {#stream-cancellation}\n\nEndpoints need to eventually agree on the amount of flow control credit that has\nbeen consumed on every stream, to be able to account for all bytes for\nconnection-level flow control.\n\nOn receipt of a RESET_STREAM frame, an endpoint will tear down state for the\nmatching stream and ignore further data arriving on that stream.\n\nRESET_STREAM terminates one direction of a stream abruptly.  For a bidirectional\nstream, RESET_STREAM has no effect on data flow in the opposite direction.  Both\nendpoints MUST maintain flow control state for the stream in the unterminated\ndirection until that direction enters a terminal state.\n\n\n## Stream Final Size {#final-size}\n\nThe final size is the amount of flow control credit that is consumed by a\nstream.  Assuming that every contiguous byte on the stream was sent once, the\nfinal size is the number of bytes sent.  More generally, this is one higher\nthan the offset of the byte with the largest offset sent on the stream, or zero\nif no bytes were sent.\n\nA sender always communicates the final size of a stream to the receiver\nreliably, no matter how the stream is terminated. The final size is the sum of\nthe Offset and Length fields of a STREAM frame with a FIN flag, noting that\nthese fields might be implicit.  Alternatively, the Final Size field of a\nRESET_STREAM frame carries this value. This guarantees that both endpoints agree\non how much flow control credit was consumed by the sender on that stream.\n\nAn endpoint will know the final size for a stream when the receiving part of the\nstream enters the \"Size Known\" or \"Reset Recvd\" state ({{stream-states}}).  The\nreceiver MUST use the final size of the stream to account for all bytes sent on\nthe stream in its connection-level flow controller.\n\nAn endpoint MUST NOT send data on a stream at or beyond the final size.\n\nOnce a final size for a stream is known, it cannot change.  If a RESET_STREAM or\nSTREAM frame is received indicating a change in the final size for the stream,\nan endpoint SHOULD respond with an error of type FINAL_SIZE_ERROR; see\n{{error-handling}} for details on error handling.  A receiver SHOULD treat\nreceipt of data at or beyond the final size as an error of type\nFINAL_SIZE_ERROR, even after a stream is closed.  Generating these errors is not\nmandatory, because requiring that an endpoint generate these errors also means\nthat the endpoint needs to maintain the final size state for closed streams,\nwhich could mean a significant state commitment.\n\n\n## Controlling Concurrency {#controlling-concurrency}\n\nAn endpoint limits the cumulative number of incoming streams a peer can open.\nOnly streams with a stream ID less than `(max_streams * 4 +\nfirst_stream_id_of_type)` can be opened; see {{stream-id-types}}.  Initial\nlimits are set in the transport parameters; see\n{{transport-parameter-definitions}}. Subsequent limits are advertised using\nMAX_STREAMS frames; see {{frame-max-streams}}. Separate limits apply to\nunidirectional and bidirectional streams.\n\nIf a max_streams transport parameter or a MAX_STREAMS frame is received with a\nvalue greater than 2<sup>60</sup>, this would allow a maximum stream ID that\ncannot be expressed as a variable-length integer; see {{integer-encoding}}.  If\neither is received, the connection MUST be closed immediately with a connection\nerror of type TRANSPORT_PARAMETER_ERROR if the offending value was received in a\ntransport parameter or of type FRAME_ENCODING_ERROR if it was received in a\nframe; see {{immediate-close}}.\n\nEndpoints MUST NOT exceed the limit set by their peer.  An endpoint that\nreceives a frame with a stream ID exceeding the limit it has sent MUST treat\nthis as a connection error of type STREAM_LIMIT_ERROR; see {{error-handling}}\nfor details on error handling.\n\nOnce a receiver advertises a stream limit using the MAX_STREAMS frame,\nadvertising a smaller limit has no effect.  MAX_STREAMS frames that do not\nincrease the stream limit MUST be ignored.\n\nAs with stream and connection flow control, this document leaves implementations\nto decide when and how many streams should be advertised\nto a peer via MAX_STREAMS.  Implementations might choose to increase limits as\nstreams are closed, to keep the number of streams available to peers roughly\nconsistent.\n\nAn endpoint that is unable to open a new stream due to the peer's limits SHOULD\nsend a STREAMS_BLOCKED frame ({{frame-streams-blocked}}).  This signal is\nconsidered useful for debugging. An endpoint MUST NOT wait to receive this\nsignal before advertising additional credit, since doing so will mean that the\npeer will be blocked for at least an entire round trip, and potentially\nindefinitely if the peer chooses not to send STREAMS_BLOCKED frames.\n\n\n# Connections {#connections}\n\nA QUIC connection is shared state between a client and a server.\n\nEach connection starts with a handshake phase, during which the two endpoints\nestablish a shared secret using the cryptographic handshake protocol\n{{QUIC-TLS}} and negotiate the application protocol. The handshake\n({{handshake}}) confirms that both endpoints are willing to communicate\n({{validate-handshake}}) and establishes parameters for the connection\n({{transport-parameters}}).\n\nAn application protocol can use the connection during the handshake phase with\nsome limitations.  0-RTT allows application data to be sent by a client before\nreceiving a response from the server.  However, 0-RTT provides no protection\nagainst replay attacks; see {{Section 9.2 of QUIC-TLS}}.  A server can also send\napplication data to a client before it receives the final cryptographic\nhandshake messages that allow it to confirm the identity and liveness of the\nclient.  These capabilities allow an application protocol to offer the option of\ntrading some security guarantees for reduced latency.\n\nThe use of connection IDs ({{connection-id}}) allows connections to migrate to a\nnew network path, both as a direct choice of an endpoint and when forced by a\nchange in a middlebox.  {{migration}} describes mitigations for the security and\nprivacy issues associated with migration.\n\nFor connections that are no longer needed or desired, there are several ways for\na client and server to terminate a connection, as described in {{termination}}.\n\n\n## Connection ID {#connection-id}\n\nEach connection possesses a set of connection identifiers, or connection IDs,\neach of which can identify the connection.  Connection IDs are independently\nselected by endpoints; each endpoint selects the connection IDs that its peer\nuses.\n\nThe primary function of a connection ID is to ensure that changes in addressing\nat lower protocol layers (UDP, IP) do not cause packets for a QUIC\nconnection to be delivered to the wrong endpoint.  Each endpoint selects\nconnection IDs using an implementation-specific (and perhaps\ndeployment-specific) method that will allow packets with that connection ID to\nbe routed back to the endpoint and to be identified by the endpoint upon\nreceipt.\n\nMultiple connection IDs are used so that endpoints can send packets that cannot\nbe identified by an observer as being for the same connection without\ncooperation from an endpoint; see {{migration-linkability}}.\n\nConnection IDs MUST NOT contain any information that can be used by an external\nobserver (that is, one that does not cooperate with the issuer) to correlate\nthem with other connection IDs for the same connection.  As a trivial example,\nthis means the same connection ID MUST NOT be issued more than once on the same\nconnection.\n\nPackets with long headers include Source Connection ID and Destination\nConnection ID fields.  These fields are used to set the connection IDs for new\nconnections; see {{negotiating-connection-ids}} for details.\n\nPackets with short headers ({{short-header}}) only include the Destination\nConnection ID and omit the explicit length.  The length of the Destination\nConnection ID field is expected to be known to endpoints.  Endpoints using a\nload balancer that routes based on connection ID could agree with the load\nbalancer on a fixed length for connection IDs or agree on an encoding scheme.\nA fixed portion could encode an explicit length, which allows the entire\nconnection ID to vary in length and still be used by the load balancer.\n\nA Version Negotiation ({{packet-version}}) packet echoes the connection IDs\nselected by the client, both to ensure correct routing toward the client and to\ndemonstrate that the packet is in response to a packet sent by the client.\n\nA zero-length connection ID can be used when a connection ID is not needed to\nroute to the correct endpoint. However, multiplexing connections on the same\nlocal IP address and port while using zero-length connection IDs will cause\nfailures in the presence of peer connection migration, NAT rebinding, and client\nport reuse. An endpoint MUST NOT use the same IP address and port for multiple\nconcurrent connections with zero-length connection IDs, unless it is certain\nthat those protocol features are not in use.\n\nWhen an endpoint uses a non-zero-length connection ID, it needs to ensure that\nthe peer has a supply of connection IDs from which to choose for packets sent to\nthe endpoint.  These connection IDs are supplied by the endpoint using the\nNEW_CONNECTION_ID frame ({{frame-new-connection-id}}).\n\n\n### Issuing Connection IDs {#issue-cid}\n\nEach connection ID has an associated sequence number to assist in detecting when\nNEW_CONNECTION_ID or RETIRE_CONNECTION_ID frames refer to the same value.  The\ninitial connection ID issued by an endpoint is sent in the Source Connection ID\nfield of the long packet header ({{long-header}}) during the handshake.  The\nsequence number of the initial connection ID is 0.  If the preferred_address\ntransport parameter is sent, the sequence number of the supplied connection ID\nis 1.\n\nAdditional connection IDs are communicated to the peer using NEW_CONNECTION_ID\nframes ({{frame-new-connection-id}}).  The sequence number on each newly issued\nconnection ID MUST increase by 1.  The connection ID that a client selects for\nthe first Destination Connection ID field it sends and any connection ID\nprovided by a Retry packet are not assigned sequence numbers.\n\nWhen an endpoint issues a connection ID, it MUST accept packets that carry this\nconnection ID for the duration of the connection or until its peer invalidates\nthe connection ID via a RETIRE_CONNECTION_ID frame\n({{frame-retire-connection-id}}).  Connection IDs that are issued and not\nretired are considered active; any active connection ID is valid for use with\nthe current connection at any time, in any packet type.  This includes the\nconnection ID issued by the server via the preferred_address transport\nparameter.\n\nAn endpoint SHOULD ensure that its peer has a sufficient number of available and\nunused connection IDs.  Endpoints advertise the number of active connection IDs\nthey are willing to maintain using the active_connection_id_limit transport\nparameter.  An endpoint MUST NOT provide more connection IDs than the peer's\nlimit.  An endpoint MAY send connection IDs that temporarily exceed a peer's\nlimit if the NEW_CONNECTION_ID frame also requires the retirement of any excess,\nby including a sufficiently large value in the Retire Prior To field.\n\nA NEW_CONNECTION_ID frame might cause an endpoint to add some active connection\nIDs and retire others based on the value of the Retire Prior To field.  After\nprocessing a NEW_CONNECTION_ID frame and adding and retiring active connection\nIDs, if the number of active connection IDs exceeds the value advertised in its\nactive_connection_id_limit transport parameter, an endpoint MUST close the\nconnection with an error of type CONNECTION_ID_LIMIT_ERROR.\n\nAn endpoint SHOULD supply a new connection ID when the peer retires a connection\nID.  If an endpoint provided fewer connection IDs than the peer's\nactive_connection_id_limit, it MAY supply a new connection ID when it receives a\npacket with a previously unused connection ID.  An endpoint MAY limit the\ntotal number of connection IDs issued for each connection to\navoid the risk of running out of connection IDs; see {{reset-token}}.  An\nendpoint MAY also limit the issuance of connection IDs to reduce the amount of\nper-path state it maintains, such as path validation status, as its peer\nmight interact with it over as many paths as there are issued connection\nIDs.\n\nAn endpoint that initiates migration and requires non-zero-length connection IDs\nSHOULD ensure that the pool of connection IDs available to its peer allows the\npeer to use a new connection ID on migration, as the peer will be unable to\nrespond if the pool is exhausted.\n\nAn endpoint that selects a zero-length connection ID during the handshake\ncannot issue a new connection ID.  A zero-length Destination Connection ID\nfield is used in all packets sent toward such an endpoint over any network\npath.\n\n\n### Consuming and Retiring Connection IDs {#retire-cid}\n\nAn endpoint can change the connection ID it uses for a peer to another available\none at any time during the connection.  An endpoint consumes connection IDs in\nresponse to a migrating peer; see {{migration-linkability}} for more details.\n\nAn endpoint maintains a set of connection IDs received from its peer, any of\nwhich it can use when sending packets.  When the endpoint wishes to remove a\nconnection ID from use, it sends a RETIRE_CONNECTION_ID frame to its peer.\nSending a RETIRE_CONNECTION_ID frame indicates that the connection ID will not\nbe used again and requests that the peer replace it with a new connection ID\nusing a NEW_CONNECTION_ID frame.\n\nAs discussed in {{migration-linkability}}, endpoints limit the use of a\nconnection ID to packets sent from a single local address to a single\ndestination address.  Endpoints SHOULD retire connection IDs when they are no\nlonger actively using either the local or destination address for which the\nconnection ID was used.\n\nAn endpoint might need to stop accepting previously issued connection IDs in\ncertain circumstances.  Such an endpoint can cause its peer to retire connection\nIDs by sending a NEW_CONNECTION_ID frame with an increased Retire Prior To\nfield.  The endpoint SHOULD continue to accept the previously issued connection\nIDs until they are retired by the peer.  If the endpoint can no longer process\nthe indicated connection IDs, it MAY close the connection.\n\nUpon receipt of an increased Retire Prior To field, the peer MUST stop using\nthe corresponding connection IDs and retire them with RETIRE_CONNECTION_ID\nframes before adding the newly provided connection ID to the set of active\nconnection IDs. This ordering allows an endpoint to replace all active\nconnection IDs without the possibility of a peer having no available connection\nIDs and without exceeding the limit the peer sets in the\nactive_connection_id_limit transport parameter; see\n{{transport-parameter-definitions}}. Failure to cease using the connection IDs\nwhen requested can result in connection failures, as the issuing endpoint might\nbe unable to continue using the connection IDs with the active connection.\n\nAn endpoint SHOULD limit the number of connection IDs it has retired locally for\nwhich RETIRE_CONNECTION_ID frames have not yet been acknowledged. An endpoint\nSHOULD allow for sending and tracking a number of RETIRE_CONNECTION_ID frames of\nat least twice the value of the active_connection_id_limit transport parameter.\nAn endpoint MUST NOT forget a connection ID without retiring it, though it MAY\nchoose to treat having connection IDs in need of retirement that exceed this\nlimit as a connection error of type CONNECTION_ID_LIMIT_ERROR.\n\nEndpoints SHOULD NOT issue updates of the Retire Prior To field before receiving\nRETIRE_CONNECTION_ID frames that retire all connection IDs indicated by the\nprevious Retire Prior To value.\n\n## Matching Packets to Connections {#packet-handling}\n\nIncoming packets are classified on receipt.  Packets can either be associated\nwith an existing connection or -- for servers -- potentially create a new\nconnection.\n\nEndpoints try to associate a packet with an existing connection. If the packet\nhas a non-zero-length Destination Connection ID corresponding to an existing\nconnection, QUIC processes that packet accordingly. Note that more than one\nconnection ID can be associated with a connection; see {{connection-id}}.\n\nIf the Destination Connection ID is zero length and the addressing information\nin the packet matches the addressing information the endpoint uses to identify a\nconnection with a zero-length connection ID, QUIC processes the packet as part\nof that connection.  An endpoint can use just destination IP and port or both\nsource and destination addresses for identification, though this makes\nconnections fragile as described in {{connection-id}}.\n\nEndpoints can send a Stateless Reset ({{stateless-reset}}) for any packets that\ncannot be attributed to an existing connection. A Stateless Reset allows a peer\nto more quickly identify when a connection becomes unusable.\n\nPackets that are matched to an existing connection are discarded if the packets\nare inconsistent with the state of that connection.  For example, packets are\ndiscarded if they indicate a different protocol version than that of the\nconnection or if the removal of packet protection is unsuccessful once the\nexpected keys are available.\n\nInvalid packets that lack strong integrity protection, such as Initial, Retry,\nor Version Negotiation, MAY be discarded. An endpoint MUST generate a\nconnection error if processing the contents of these packets prior to\ndiscovering an error, or fully revert any changes made during that processing.\n\n\n### Client Packet Handling {#client-pkt-handling}\n\nValid packets sent to clients always include a Destination Connection ID that\nmatches a value the client selects.  Clients that choose to receive zero-length\nconnection IDs can use the local address and port to identify a connection.\nPackets that do not match an existing connection -- based on Destination\nConnection ID or, if this value is zero length, local IP address and port -- are\ndiscarded.\n\nDue to packet reordering or loss, a client might receive packets for a\nconnection that are encrypted with a key it has not yet computed. The client MAY\ndrop these packets, or it MAY buffer them in anticipation of later packets that\nallow it to compute the key.\n\nIf a client receives a packet that uses a different version than it initially\nselected, it MUST discard that packet.\n\n\n### Server Packet Handling {#server-pkt-handling}\n\nIf a server receives a packet that indicates an unsupported version and if the\npacket is large enough to initiate a new connection for any supported version,\nthe server SHOULD send a Version Negotiation packet as described in {{send-vn}}.\nA server MAY limit the number of packets to which it responds with a Version\nNegotiation packet.  Servers MUST drop smaller packets that specify unsupported\nversions.\n\nThe first packet for an unsupported version can use different semantics and\nencodings for any version-specific field.  In particular, different packet\nprotection keys might be used for different versions.  Servers that do not\nsupport a particular version are unlikely to be able to decrypt the payload of\nthe packet or properly interpret the result.  Servers SHOULD respond with a\nVersion Negotiation packet, provided that the datagram is sufficiently long.\n\nPackets with a supported version, or no Version field, are matched to a\nconnection using the connection ID or -- for packets with zero-length connection\nIDs -- the local address and port.  These packets are processed using the\nselected connection; otherwise, the server continues as described below.\n\nIf the packet is an Initial packet fully conforming with the specification, the\nserver proceeds with the handshake ({{handshake}}). This commits the server to\nthe version that the client selected.\n\nIf a server refuses to accept a new connection, it SHOULD send an Initial packet\ncontaining a CONNECTION_CLOSE frame with error code CONNECTION_REFUSED.\n\nIf the packet is a 0-RTT packet, the server MAY buffer a limited number of these\npackets in anticipation of a late-arriving Initial packet. Clients are not able\nto send Handshake packets prior to receiving a server response, so servers\nSHOULD ignore any such packets.\n\nServers MUST drop incoming packets under all other circumstances.\n\n### Considerations for Simple Load Balancers\n\nA server deployment could load-balance among servers using only source and\ndestination IP addresses and ports. Changes to the client's IP address or port\ncould result in packets being forwarded to the wrong server. Such a server\ndeployment could use one of the following methods for connection continuity\nwhen a client's address changes.\n\n* Servers could use an out-of-band mechanism to forward packets to the correct\n  server based on connection ID.\n\n* If servers can use a dedicated server IP address or port, other than the one\n  that the client initially connects to, they could use the preferred_address\n  transport parameter to request that clients move connections to that dedicated\n  address. Note that clients could choose not to use the preferred address.\n\nA server in a deployment that does not implement a solution to maintain\nconnection continuity when the client address changes SHOULD indicate that\nmigration is not supported by using the disable_active_migration transport\nparameter.  The disable_active_migration transport parameter does not prohibit\nconnection migration after a client has acted on a preferred_address transport\nparameter.\n\nServer deployments that use this simple form of load balancing MUST avoid the\ncreation of a stateless reset oracle; see {{reset-oracle}}.\n\n\n## Operations on Connections\n\nThis document does not define an API for QUIC; it instead defines a set of\nfunctions for QUIC connections that application protocols can rely upon.  An\napplication protocol can assume that an implementation of QUIC provides an\ninterface that includes the operations described in this section.  An\nimplementation designed for use with a specific application protocol might\nprovide only those operations that are used by that protocol.\n\nWhen implementing the client role, an application protocol can:\n\n- open a connection, which begins the exchange described in {{handshake}};\n- enable Early Data when available; and\n- be informed when Early Data has been accepted or rejected by a server.\n\nWhen implementing the server role, an application protocol can:\n\n- listen for incoming connections, which prepares for the exchange described in\n  {{handshake}};\n- if Early Data is supported, embed application-controlled data in the TLS\n  resumption ticket sent to the client; and\n- if Early Data is supported, retrieve application-controlled data from the\n  client's resumption ticket and accept or reject Early Data based on that\n  information.\n\nIn either role, an application protocol can:\n\n- configure minimum values for the initial number of permitted streams of each\n  type, as communicated in the transport parameters ({{transport-parameters}});\n- control resource allocation for receive buffers by setting flow control limits\n  both for streams and for the connection;\n- identify whether the handshake has completed successfully or is still ongoing;\n- keep a connection from silently closing, by either generating PING frames\n  ({{frame-ping}}) or requesting that the transport send additional frames\n  before the idle timeout expires ({{idle-timeout}}); and\n- immediately close ({{immediate-close}}) the connection.\n\n\n# Version Negotiation {#version-negotiation}\n\nVersion negotiation allows a server to indicate that it does not support\nthe version the client used.  A server sends a Version Negotiation packet in\nresponse to each packet that might initiate a new connection; see\n{{packet-handling}} for details.\n\nThe size of the first packet sent by a client will determine whether a server\nsends a Version Negotiation packet. Clients that support multiple QUIC versions\nSHOULD ensure that the first UDP datagram they send is sized to the largest of\nthe minimum datagram sizes from all versions they support, using PADDING frames\n({{frame-padding}}) as necessary. This ensures that the server responds if there\nis a mutually supported version. A server might not send a Version Negotiation\npacket if the datagram it receives is smaller than the minimum size specified in\na different version; see {{initial-size}}.\n\n\n## Sending Version Negotiation Packets {#send-vn}\n\nIf the version selected by the client is not acceptable to the server, the\nserver responds with a Version Negotiation packet; see {{packet-version}}.  This\nincludes a list of versions that the server will accept.  An endpoint MUST NOT\nsend a Version Negotiation packet in response to receiving a Version Negotiation\npacket.\n\nThis system allows a server to process packets with unsupported versions without\nretaining state.  Though either the Initial packet or the Version Negotiation\npacket that is sent in response could be lost, the client will send new packets\nuntil it successfully receives a response or it abandons the connection attempt.\n\nA server MAY limit the number of Version Negotiation packets it sends.  For\ninstance, a server that is able to recognize packets as 0-RTT might choose not\nto send Version Negotiation packets in response to 0-RTT packets with the\nexpectation that it will eventually receive an Initial packet.\n\n\n## Handling Version Negotiation Packets {#handle-vn}\n\nVersion Negotiation packets are designed to allow for functionality to be\ndefined in the future that allows QUIC to negotiate the version of QUIC to use\nfor a connection.  Future Standards Track specifications might change how\nimplementations that support multiple versions of QUIC react to Version\nNegotiation packets received in response to an attempt to establish a\nconnection using this version.\n\nA client that supports only this version of QUIC MUST abandon the current\nconnection attempt if it receives a Version Negotiation packet, with the\nfollowing two exceptions. A client MUST discard any Version Negotiation packet\nif it has received and successfully processed any other packet, including an\nearlier Version Negotiation packet. A client MUST discard a Version Negotiation\npacket that lists the QUIC version selected by the client.\n\nHow to perform version negotiation is left as future work defined by future\nStandards Track specifications.  In particular, that future work will\nensure robustness against version downgrade attacks; see\n{{version-downgrade}}.\n\n\n## Using Reserved Versions\n\nFor a server to use a new version in the future, clients need to correctly\nhandle unsupported versions. Some version numbers (0x?a?a?a?a, as defined in\n{{versions}}) are reserved for inclusion in fields that contain version\nnumbers.\n\nEndpoints MAY add reserved versions to any field where unknown or unsupported\nversions are ignored to test that a peer correctly ignores the value. For\ninstance, an endpoint could include a reserved version in a Version Negotiation\npacket; see {{packet-version}}. Endpoints MAY send packets with a reserved\nversion to test that a peer correctly discards the packet.\n\n\n# Cryptographic and Transport Handshake {#handshake}\n\nQUIC relies on a combined cryptographic and transport handshake to minimize\nconnection establishment latency.  QUIC uses the CRYPTO frame ({{frame-crypto}})\nto transmit the cryptographic handshake.  The version of QUIC defined in this\ndocument is identified as 0x00000001 and uses TLS as described in {{QUIC-TLS}};\na different QUIC version could indicate that a different cryptographic\nhandshake protocol is in use.\n\nQUIC provides reliable, ordered delivery of the cryptographic handshake\ndata. QUIC packet protection is used to encrypt as much of the handshake\nprotocol as possible. The cryptographic handshake MUST provide the following\nproperties:\n\n* authenticated key exchange, where\n\n   * a server is always authenticated,\n\n   * a client is optionally authenticated,\n\n   * every connection produces distinct and unrelated keys, and\n\n   * keying material is usable for packet protection for both 0-RTT and 1-RTT\n     packets.\n\n* authenticated exchange of values for transport parameters of both endpoints,\n  and confidentiality protection for server transport parameters (see\n  {{transport-parameters}}).\n\n* authenticated negotiation of an application protocol (TLS uses\n  Application-Layer Protocol Negotiation (ALPN) {{?ALPN}} for this purpose).\n\nThe CRYPTO frame can be sent in different packet number spaces\n({{packet-numbers}}).  The offsets used by CRYPTO frames to ensure ordered\ndelivery of cryptographic handshake data start from zero in each packet number\nspace.\n\n{{fig-hs}} shows a simplified handshake and the exchange of packets and frames\nthat are used to advance the handshake.  Exchange of application data during the\nhandshake is enabled where possible, shown with an asterisk (\"*\").  Once the\nhandshake is complete, endpoints are able to exchange application data freely.\n\n~~~\nClient                                               Server\n\nInitial (CRYPTO)\n0-RTT (*)              ---------->\n                                           Initial (CRYPTO)\n                                         Handshake (CRYPTO)\n                       <----------                1-RTT (*)\nHandshake (CRYPTO)\n1-RTT (*)              ---------->\n                       <----------   1-RTT (HANDSHAKE_DONE)\n\n1-RTT                  <=========>                    1-RTT\n~~~\n{: #fig-hs title=\"Simplified QUIC Handshake\"}\n\nEndpoints can use packets sent during the handshake to test for Explicit\nCongestion Notification (ECN) support; see {{ecn}}. An endpoint validates\nsupport for ECN by observing whether the ACK frames acknowledging the first\npackets it sends carry ECN counts, as described in {{ecn-validation}}.\n\nEndpoints MUST explicitly negotiate an application protocol.  This avoids\nsituations where there is a disagreement about the protocol that is in use.\n\n\n## Example Handshake Flows\n\nDetails of how TLS is integrated with QUIC are provided in {{QUIC-TLS}}, but\nsome examples are provided here.  An extension of this exchange to support\nclient address validation is shown in {{validate-retry}}.\n\nOnce any address validation exchanges are complete, the\ncryptographic handshake is used to agree on cryptographic keys.  The\ncryptographic handshake is carried in Initial ({{packet-initial}}) and Handshake\n({{packet-handshake}}) packets.\n\n{{tls-1rtt-handshake}} provides an overview of the 1-RTT handshake.  Each line\nshows a QUIC packet with the packet type and packet number shown first, followed\nby the frames that are typically contained in those packets. For instance, the\nfirst packet is of type Initial, with packet number 0, and contains a CRYPTO\nframe carrying the ClientHello.\n\nMultiple QUIC packets -- even of different packet types -- can be coalesced into\na single UDP datagram; see {{packet-coalesce}}. As a result, this handshake\ncould consist of as few as four UDP datagrams, or any number more (subject to\nlimits inherent to the protocol, such as congestion control and\nanti-amplification).  For instance, the server's first flight contains Initial\npackets, Handshake packets, and \"0.5-RTT data\" in 1-RTT packets.\n\n~~~~\nClient                                                  Server\n\nInitial[0]: CRYPTO[CH] ->\n\n                                 Initial[0]: CRYPTO[SH] ACK[0]\n                       Handshake[0]: CRYPTO[EE, CERT, CV, FIN]\n                                 <- 1-RTT[0]: STREAM[1, \"...\"]\n\nInitial[1]: ACK[0]\nHandshake[0]: CRYPTO[FIN], ACK[0]\n1-RTT[0]: STREAM[0, \"...\"], ACK[0] ->\n\n                                          Handshake[1]: ACK[0]\n         <- 1-RTT[1]: HANDSHAKE_DONE, STREAM[3, \"...\"], ACK[0]\n~~~~\n{: #tls-1rtt-handshake title=\"Example 1-RTT Handshake\"}\n\n{{tls-0rtt-handshake}} shows an example of a connection with a 0-RTT handshake\nand a single packet of 0-RTT data. Note that as described in\n{{packet-numbers}}, the server acknowledges 0-RTT data in 1-RTT packets, and\nthe client sends 1-RTT packets in the same packet number space.\n\n~~~~\nClient                                                  Server\n\nInitial[0]: CRYPTO[CH]\n0-RTT[0]: STREAM[0, \"...\"] ->\n\n                                 Initial[0]: CRYPTO[SH] ACK[0]\n                                  Handshake[0] CRYPTO[EE, FIN]\n                          <- 1-RTT[0]: STREAM[1, \"...\"] ACK[0]\n\nInitial[1]: ACK[0]\nHandshake[0]: CRYPTO[FIN], ACK[0]\n1-RTT[1]: STREAM[0, \"...\"] ACK[0] ->\n\n                                          Handshake[1]: ACK[0]\n         <- 1-RTT[1]: HANDSHAKE_DONE, STREAM[3, \"...\"], ACK[1]\n~~~~\n{: #tls-0rtt-handshake title=\"Example 0-RTT Handshake\"}\n\n\n## Negotiating Connection IDs {#negotiating-connection-ids}\n\nA connection ID is used to ensure consistent routing of packets, as described in\n{{connection-id}}.  The long header contains two connection IDs: the Destination\nConnection ID is chosen by the recipient of the packet and is used to provide\nconsistent routing; the Source Connection ID is used to set the Destination\nConnection ID used by the peer.\n\nDuring the handshake, packets with the long header ({{long-header}}) are used\nto establish the connection IDs used by both endpoints. Each endpoint uses the\nSource Connection ID field to specify the connection ID that is used in the\nDestination Connection ID field of packets being sent to them. After processing\nthe first Initial packet, each endpoint sets the Destination Connection ID\nfield in subsequent packets it sends to the value of the Source Connection ID\nfield that it received.\n\nWhen an Initial packet is sent by a client that has not previously received an\nInitial or Retry packet from the server, the client populates the Destination\nConnection ID field with an unpredictable value.  This Destination Connection ID\nMUST be at least 8 bytes in length.  Until a packet is received from the server,\nthe client MUST use the same Destination Connection ID value on all packets in\nthis connection.\n\nThe Destination Connection ID field from the first Initial packet sent by a\nclient is used to determine packet protection keys for Initial packets.  These\nkeys change after receiving a Retry packet; see {{Section 5.2 of QUIC-TLS}}.\n\nThe client populates the Source Connection ID field with a value of its choosing\nand sets the Source Connection ID Length field to indicate the length.\n\n0-RTT packets in the first flight use the same Destination Connection ID and\nSource Connection ID values as the client's first Initial packet.\n\nUpon first receiving an Initial or Retry packet from the server, the client uses\nthe Source Connection ID supplied by the server as the Destination Connection ID\nfor subsequent packets, including any 0-RTT packets.  This means that a client\nmight have to change the connection ID it sets in the Destination Connection ID\nfield twice during connection establishment: once in response to a Retry packet\nand once in response to an Initial packet from the server. Once a client has\nreceived a valid Initial packet from the server, it MUST discard any subsequent\npacket it receives on that connection with a different Source Connection ID.\n\nA client MUST change the Destination Connection ID it uses for sending packets\nin response to only the first received Initial or Retry packet.  A server MUST\nset the Destination Connection ID it uses for sending packets based on the first\nreceived Initial packet. Any further changes to the Destination Connection ID\nare only permitted if the values are taken from NEW_CONNECTION_ID frames; if\nsubsequent Initial packets include a different Source Connection ID, they MUST\nbe discarded.  This avoids unpredictable outcomes that might otherwise result\nfrom stateless processing of multiple Initial packets with different Source\nConnection IDs.\n\nThe Destination Connection ID that an endpoint sends can change over the\nlifetime of a connection, especially in response to connection migration\n({{migration}}); see {{issue-cid}} for details.\n\n\n## Authenticating Connection IDs {#cid-auth}\n\nThe choice each endpoint makes about connection IDs during the handshake is\nauthenticated by including all values in transport parameters; see\n{{transport-parameters}}. This ensures that all connection IDs used for the\nhandshake are also authenticated by the cryptographic handshake.\n\nEach endpoint includes the value of the Source Connection ID field from the\nfirst Initial packet it sent in the initial_source_connection_id transport\nparameter; see {{transport-parameter-definitions}}. A server includes the\nDestination Connection ID field from the first Initial packet it received from\nthe client in the original_destination_connection_id transport parameter; if the\nserver sent a Retry packet, this refers to the first Initial packet received\nbefore sending the Retry packet. If it sends a Retry packet, a server also\nincludes the Source Connection ID field from the Retry packet in the\nretry_source_connection_id transport parameter.\n\nThe values provided by a peer for these transport parameters MUST match the\nvalues that an endpoint used in the Destination and Source Connection ID fields\nof Initial packets that it sent (and received, for servers). Endpoints MUST\nvalidate that received transport parameters match received connection ID values.\nIncluding connection ID values in transport parameters and verifying them\nensures that an attacker cannot influence the choice of connection ID for a\nsuccessful connection by injecting packets carrying attacker-chosen connection\nIDs during the handshake.\n\nAn endpoint MUST treat the absence of the initial_source_connection_id transport\nparameter from either endpoint or the absence of the\noriginal_destination_connection_id transport parameter from the server as a\nconnection error of type TRANSPORT_PARAMETER_ERROR.\n\nAn endpoint MUST treat the following as a connection error of type\nTRANSPORT_PARAMETER_ERROR or PROTOCOL_VIOLATION:\n\n* absence of the retry_source_connection_id transport parameter from the server\n  after receiving a Retry packet,\n\n* presence of the retry_source_connection_id transport parameter when no Retry\n  packet was received, or\n\n* a mismatch between values received from a peer in these transport parameters\n  and the value sent in the corresponding Destination or Source Connection ID\n  fields of Initial packets.\n\nIf a zero-length connection ID is selected, the corresponding transport\nparameter is included with a zero-length value.\n\n{{fig-auth-cid}} shows the connection IDs (with DCID=Destination Connection ID,\nSCID=Source Connection ID) that are used in a complete handshake. The exchange\nof Initial packets is shown, plus the later exchange of 1-RTT packets that\nincludes the connection ID established during the handshake.\n\n~~~\nClient                                                  Server\n\nInitial: DCID=S1, SCID=C1 ->\n                                  <- Initial: DCID=C1, SCID=S3\n                             ...\n1-RTT: DCID=S3 ->\n                                             <- 1-RTT: DCID=C1\n~~~\n{: #fig-auth-cid title=\"Use of Connection IDs in a Handshake\"}\n\n{{fig-auth-cid-retry}} shows a similar handshake that includes a Retry packet.\n\n~~~\nClient                                                  Server\n\nInitial: DCID=S1, SCID=C1 ->\n                                    <- Retry: DCID=C1, SCID=S2\nInitial: DCID=S2, SCID=C1 ->\n                                  <- Initial: DCID=C1, SCID=S3\n                             ...\n1-RTT: DCID=S3 ->\n                                             <- 1-RTT: DCID=C1\n~~~\n{: #fig-auth-cid-retry title=\"Use of Connection IDs in a Handshake with Retry\"}\n\nIn both cases (Figures {{<fig-auth-cid}} and {{<fig-auth-cid-retry}}), the\nclient sets the value of the initial_source_connection_id transport parameter to\n`C1`.\n\nWhen the handshake does not include a Retry ({{fig-auth-cid}}), the server sets\noriginal_destination_connection_id to `S1` (note that this value is chosen by\nthe client) and initial_source_connection_id to `S3`. In this case, the server\ndoes not include a retry_source_connection_id transport parameter.\n\nWhen the handshake includes a Retry ({{fig-auth-cid-retry}}), the server sets\noriginal_destination_connection_id to `S1`, retry_source_connection_id to `S2`,\nand initial_source_connection_id to `S3`.\n\n\n## Transport Parameters {#transport-parameters}\n\nDuring connection establishment, both endpoints make authenticated declarations\nof their transport parameters.  Endpoints are required to comply with the\nrestrictions that each parameter defines; the description of each parameter\nincludes rules for its handling.\n\nTransport parameters are declarations that are made unilaterally by each\nendpoint.  Each endpoint can choose values for transport parameters independent\nof the values chosen by its peer.\n\nThe encoding of the transport parameters is detailed in\n{{transport-parameter-encoding}}.\n\nQUIC includes the encoded transport parameters in the cryptographic handshake.\nOnce the handshake completes, the transport parameters declared by the peer are\navailable.  Each endpoint validates the values provided by its peer.\n\nDefinitions for each of the defined transport parameters are included in\n{{transport-parameter-definitions}}.\n\nAn endpoint MUST treat receipt of a transport parameter with an invalid value as\na connection error of type TRANSPORT_PARAMETER_ERROR.\n\nAn endpoint MUST NOT send a parameter more than once in a given transport\nparameters extension.  An endpoint SHOULD treat receipt of duplicate transport\nparameters as a connection error of type TRANSPORT_PARAMETER_ERROR.\n\nEndpoints use transport parameters to authenticate the negotiation of\nconnection IDs during the handshake; see {{cid-auth}}.\n\nALPN (see {{?ALPN=RFC7301}}) allows clients to offer multiple application\nprotocols during connection establishment. The transport parameters that a\nclient includes during the handshake apply to all application protocols that the\nclient offers. Application protocols can recommend values for transport\nparameters, such as the initial flow control limits. However, application\nprotocols that set constraints on values for transport parameters could make it\nimpossible for a client to offer multiple application protocols if these\nconstraints conflict.\n\n\n### Values of Transport Parameters for 0-RTT {#zerortt-parameters}\n\nUsing 0-RTT depends on both client and server using protocol parameters that\nwere negotiated from a previous connection.  To enable 0-RTT, endpoints store\nthe values of the server transport parameters with any session tickets it\nreceives on the connection.  Endpoints also store any information required by\nthe application protocol or cryptographic handshake; see {{Section 4.6 of\nQUIC-TLS}}.  The values of stored transport parameters are used when attempting\n0-RTT using the session tickets.\n\nRemembered transport parameters apply to the new connection until the handshake\ncompletes and the client starts sending 1-RTT packets.  Once the handshake\ncompletes, the client uses the transport parameters established in the\nhandshake.  Not all transport parameters are remembered, as some do not apply to\nfuture connections or they have no effect on the use of 0-RTT.\n\nThe definition of a new transport parameter ({{new-transport-parameters}}) MUST\nspecify whether storing the transport parameter for 0-RTT is mandatory,\noptional, or prohibited. A client need not store a transport parameter it cannot\nprocess.\n\nA client MUST NOT use remembered values for the following parameters:\nack_delay_exponent, max_ack_delay, initial_source_connection_id,\noriginal_destination_connection_id, preferred_address,\nretry_source_connection_id, and stateless_reset_token. The client MUST use the\nserver's new values in the handshake instead; if the server does not provide new\nvalues, the default values are used.\n\nA client that attempts to send 0-RTT data MUST remember all other transport\nparameters used by the server that it is able to process. The server can\nremember these transport parameters or can store an integrity-protected copy of\nthe values in the ticket and recover the information when accepting 0-RTT data.\nA server uses the transport parameters in determining whether to accept 0-RTT\ndata.\n\nIf 0-RTT data is accepted by the server, the server MUST NOT reduce any\nlimits or alter any values that might be violated by the client with its\n0-RTT data.  In particular, a server that accepts 0-RTT data MUST NOT set\nvalues for the following parameters ({{transport-parameter-definitions}})\nthat are smaller than the remembered values of the parameters.\n\n* active_connection_id_limit\n* initial_max_data\n* initial_max_stream_data_bidi_local\n* initial_max_stream_data_bidi_remote\n* initial_max_stream_data_uni\n* initial_max_streams_bidi\n* initial_max_streams_uni\n\nOmitting or setting a zero value for certain transport parameters can result in\n0-RTT data being enabled but not usable.  The applicable subset of transport\nparameters that permit the sending of application data SHOULD be set to non-zero\nvalues for 0-RTT.  This includes initial_max_data and either (1)\ninitial_max_streams_bidi and initial_max_stream_data_bidi_remote or (2)\ninitial_max_streams_uni and initial_max_stream_data_uni.\n\nA server might provide larger initial stream flow control limits for streams\nthan the remembered values that a client applies when sending 0-RTT.  Once\nthe handshake completes, the client updates the flow control\nlimits on all sending streams using the updated values of\ninitial_max_stream_data_bidi_remote and initial_max_stream_data_uni.\n\nA server MAY store and recover the previously sent values of the\nmax_idle_timeout, max_udp_payload_size, and disable_active_migration parameters\nand reject 0-RTT if it selects smaller values. Lowering the values of these\nparameters while also accepting 0-RTT data could degrade the performance of the\nconnection. Specifically, lowering the max_udp_payload_size could result in\ndropped packets, leading to worse performance compared to rejecting 0-RTT data\noutright.\n\nA server MUST reject 0-RTT data if the restored values for transport\nparameters cannot be supported.\n\nWhen sending frames in 0-RTT packets, a client MUST only use remembered\ntransport parameters; importantly, it MUST NOT use updated values that it learns\nfrom the server's updated transport parameters or from frames received in 1-RTT\npackets.  Updated values of transport parameters from the handshake apply only\nto 1-RTT packets.  For instance, flow control limits from remembered transport\nparameters apply to all 0-RTT packets even if those values are increased by the\nhandshake or by frames sent in 1-RTT packets.  A server MAY treat the use of\nupdated transport parameters in 0-RTT as a connection error of type\nPROTOCOL_VIOLATION.\n\n\n### New Transport Parameters {#new-transport-parameters}\n\nNew transport parameters can be used to negotiate new protocol behavior.  An\nendpoint MUST ignore transport parameters that it does not support.  The absence\nof a transport parameter therefore disables any optional protocol feature that\nis negotiated using the parameter.  As described in\n{{transport-parameter-grease}}, some identifiers are reserved in order to\nexercise this requirement.\n\nA client that does not understand a transport parameter can discard it and\nattempt 0-RTT on subsequent connections. However, if the client adds support for\na discarded transport parameter, it risks violating the constraints that the\ntransport parameter establishes if it attempts 0-RTT. New transport parameters\ncan avoid this problem by setting a default of the most conservative value.\nClients can avoid this problem by remembering all parameters, even those not\ncurrently supported.\n\nNew transport parameters can be registered according to the rules in\n{{iana-transport-parameters}}.\n\n\n## Cryptographic Message Buffering\n\nImplementations need to maintain a buffer of CRYPTO data received out of order.\nBecause there is no flow control of CRYPTO frames, an endpoint could\npotentially force its peer to buffer an unbounded amount of data.\n\nImplementations MUST support buffering at least 4096 bytes of data received in\nout-of-order CRYPTO frames. Endpoints MAY choose to allow more data to be\nbuffered during the handshake. A larger limit during the handshake could allow\nfor larger keys or credentials to be exchanged. An endpoint's buffer size does\nnot need to remain constant during the life of the connection.\n\nBeing unable to buffer CRYPTO frames during the handshake can lead to a\nconnection failure. If an endpoint's buffer is exceeded during the handshake, it\ncan expand its buffer temporarily to complete the handshake. If an endpoint\ndoes not expand its buffer, it MUST close the connection with a\nCRYPTO_BUFFER_EXCEEDED error code.\n\nOnce the handshake completes, if an endpoint is unable to buffer all data in a\nCRYPTO frame, it MAY discard that CRYPTO frame and all CRYPTO frames received in\nthe future, or it MAY close the connection with a CRYPTO_BUFFER_EXCEEDED error\ncode. Packets containing discarded CRYPTO frames MUST be acknowledged because\nthe packet has been received and processed by the transport even though the\nCRYPTO frame was discarded.\n\n\n# Address Validation {#address-validation}\n\nAddress validation ensures that an endpoint cannot be used for a traffic\namplification attack.  In such an attack, a packet is sent to a server with\nspoofed source address information that identifies a victim.  If a server\ngenerates more or larger packets in response to that packet, the attacker can\nuse the server to send more data toward the victim than it would be able to send\non its own.\n\nThe primary defense against amplification attacks is verifying that a peer is\nable to receive packets at the transport address that it claims.  Therefore,\nafter receiving packets from an address that is not yet validated, an endpoint\nMUST limit the amount of data it sends to the unvalidated address to three times\nthe amount of data received from that address.  This limit on the size of\nresponses is known as the anti-amplification limit.\n\nAddress validation is performed both during connection establishment (see\n{{validate-handshake}}) and during connection migration (see\n{{migrate-validate}}).\n\n\n## Address Validation during Connection Establishment {#validate-handshake}\n\nConnection establishment implicitly provides address validation for both\nendpoints.  In particular, receipt of a packet protected with Handshake keys\nconfirms that the peer successfully processed an Initial packet.  Once an\nendpoint has successfully processed a Handshake packet from the peer, it can\nconsider the peer address to have been validated.\n\nAdditionally, an endpoint MAY consider the peer address validated if the peer\nuses a connection ID chosen by the endpoint and the connection ID contains at\nleast 64 bits of entropy.\n\nFor the client, the value of the Destination Connection ID field in its first\nInitial packet allows it to validate the server address as a part of\nsuccessfully processing any packet. Initial packets from the server are\nprotected with keys that are derived from this value (see {{Section 5.2 of\nQUIC-TLS}}). Alternatively, the value is echoed by the server in Version\nNegotiation packets ({{version-negotiation}}) or included in the Integrity Tag\nin Retry packets ({{Section 5.8 of QUIC-TLS}}).\n\nPrior to validating the client address, servers MUST NOT send more than three\ntimes as many bytes as the number of bytes they have received.  This limits the\nmagnitude of any amplification attack that can be mounted using spoofed source\naddresses.  For the purposes of avoiding amplification prior to address\nvalidation, servers MUST count all of the payload bytes received in datagrams\nthat are uniquely attributed to a single connection. This includes datagrams\nthat contain packets that are successfully processed and datagrams that contain\npackets that are all discarded.\n\nClients MUST ensure that UDP datagrams containing Initial packets have UDP\npayloads of at least 1200 bytes, adding PADDING frames as necessary.\nA client that sends padded datagrams allows the server to\nsend more data prior to completing address validation.\n\nLoss of an Initial or Handshake packet from the server can cause a deadlock if\nthe client does not send additional Initial or Handshake packets. A deadlock\ncould occur when the server reaches its anti-amplification limit and the client\nhas received acknowledgments for all the data it has sent.  In this case, when\nthe client has no reason to send additional packets, the server will be unable\nto send more data because it has not validated the client's address. To prevent\nthis deadlock, clients MUST send a packet on a Probe Timeout (PTO); see\n{{Section 6.2 of QUIC-RECOVERY}}. Specifically, the client MUST send an Initial\npacket in a UDP datagram that contains at least 1200 bytes if it does not have\nHandshake keys, and otherwise send a Handshake packet.\n\nA server might wish to validate the client address before starting the\ncryptographic handshake. QUIC uses a token in the Initial packet to provide\naddress validation prior to completing the handshake. This token is delivered to\nthe client during connection establishment with a Retry packet (see\n{{validate-retry}}) or in a previous connection using the NEW_TOKEN frame (see\n{{validate-future}}).\n\nIn addition to sending limits imposed prior to address validation, servers are\nalso constrained in what they can send by the limits set by the congestion\ncontroller.  Clients are only constrained by the congestion controller.\n\n\n### Token Construction {#token-differentiation}\n\nA token sent in a NEW_TOKEN frame or a Retry packet MUST be constructed in a\nway that allows the server to identify how it was provided to a client.  These\ntokens are carried in the same field but require different handling from\nservers.\n\n\n### Address Validation Using Retry Packets {#validate-retry}\n\nUpon receiving the client's Initial packet, the server can request address\nvalidation by sending a Retry packet ({{packet-retry}}) containing a token. This\ntoken MUST be repeated by the client in all Initial packets it sends for that\nconnection after it receives the Retry packet.\n\nIn response to processing an Initial packet containing a token that was provided\nin a Retry packet, a server cannot send another Retry packet; it can only refuse\nthe connection or permit it to proceed.\n\nAs long as it is not possible for an attacker to generate a valid token for\nits own address (see {{token-integrity}}) and the client is able to return\nthat token, it proves to the server that it received the token.\n\nA server can also use a Retry packet to defer the state and processing costs of\nconnection establishment. Requiring the server to provide a different\nconnection ID, along with the original_destination_connection_id transport\nparameter defined in {{transport-parameter-definitions}}, forces the server to\ndemonstrate that it, or an entity it cooperates with, received the original\nInitial packet from the client. Providing a different connection ID also grants\na server some control over how subsequent packets are routed. This can be used\nto direct connections to a different server instance.\n\nIf a server receives a client Initial that contains an invalid Retry token but\nis otherwise valid, it knows the client will not accept another Retry token.\nThe server can discard such a packet and allow the client to time out to\ndetect handshake failure, but that could impose a significant latency penalty on\nthe client.  Instead, the server SHOULD immediately close ({{immediate-close}})\nthe connection with an INVALID_TOKEN error.  Note that a server has not\nestablished any state for the connection at this point and so does not enter the\nclosing period.\n\nA flow showing the use of a Retry packet is shown in {{fig-retry}}.\n\n~~~~\nClient                                                  Server\n\nInitial[0]: CRYPTO[CH] ->\n\n                                                <- Retry+Token\n\nInitial+Token[1]: CRYPTO[CH] ->\n\n                                 Initial[0]: CRYPTO[SH] ACK[1]\n                       Handshake[0]: CRYPTO[EE, CERT, CV, FIN]\n                                 <- 1-RTT[0]: STREAM[1, \"...\"]\n~~~~\n{: #fig-retry title=\"Example Handshake with Retry\"}\n\n\n### Address Validation for Future Connections {#validate-future}\n\nA server MAY provide clients with an address validation token during one\nconnection that can be used on a subsequent connection.  Address validation is\nespecially important with 0-RTT because a server potentially sends a significant\namount of data to a client in response to 0-RTT data.\n\nThe server uses the NEW_TOKEN frame ({{frame-new-token}}) to provide the client\nwith an address validation token that can be used to validate future\nconnections.  In a future connection, the client includes this token in Initial\npackets to provide address validation.  The client MUST include the token in all\nInitial packets it sends, unless a Retry replaces the token with a newer one.\nThe client MUST NOT use the token provided in a Retry for future connections.\nServers MAY discard any Initial packet that does not carry the expected token.\n\nUnlike the token that is created for a Retry packet, which is used immediately,\nthe token sent in the NEW_TOKEN frame can be used after some period of\ntime has passed.  Thus, a token SHOULD have an expiration time, which could\nbe either an explicit expiration time or an issued timestamp that can be\nused to dynamically calculate the expiration time.  A server can store the\nexpiration time or include it in an encrypted form in the token.\n\nA token issued with NEW_TOKEN MUST NOT include information that would allow\nvalues to be linked by an observer to the connection on which it was\nissued. For example, it cannot include the previous connection ID or addressing\ninformation, unless the values are encrypted.  A server MUST ensure that\nevery NEW_TOKEN frame it sends is unique across all clients, with the exception\nof those sent to repair losses of previously sent NEW_TOKEN frames.  Information\nthat allows the server to distinguish between tokens from Retry and NEW_TOKEN\nMAY be accessible to entities other than the server.\n\nIt is unlikely that the client port number is the same on two different\nconnections; validating the port is therefore unlikely to be successful.\n\nA token received in a NEW_TOKEN frame is applicable to any server that the\nconnection is considered authoritative for (e.g., server names included in the\ncertificate).  When connecting to a server for which the client retains an\napplicable and unused token, it SHOULD include that token in the Token field of\nits Initial packet.  Including a token might allow the server to validate the\nclient address without an additional round trip.  A client MUST NOT include a\ntoken that is not applicable to the server that it is connecting to, unless the\nclient has the knowledge that the server that issued the token and the server\nthe client is connecting to are jointly managing the tokens.  A client MAY use a\ntoken from any previous connection to that server.\n\nA token allows a server to correlate activity between the connection where the\ntoken was issued and any connection where it is used.  Clients that want to\nbreak continuity of identity with a server can discard tokens provided using the\nNEW_TOKEN frame.  In comparison, a token obtained in a Retry packet MUST be used\nimmediately during the connection attempt and cannot be used in subsequent\nconnection attempts.\n\nA client SHOULD NOT reuse a token from a NEW_TOKEN frame for different\nconnection attempts.  Reusing a token allows connections to be linked by\nentities on the network path; see {{migration-linkability}}.\n\nClients might receive multiple tokens on a single connection.  Aside from\npreventing linkability, any token can be used in any connection attempt.\nServers can send additional tokens to either enable address validation for\nmultiple connection attempts or replace older tokens that might become invalid.\nFor a client, this ambiguity means that sending the most recent unused token is\nmost likely to be effective.  Though saving and using older tokens have no\nnegative consequences, clients can regard older tokens as being less likely to\nbe useful to the server for address validation.\n\nWhen a server receives an Initial packet with an address validation token, it\nMUST attempt to validate the token, unless it has already completed address\nvalidation.  If the token is invalid, then the server SHOULD proceed as if the\nclient did not have a validated address, including potentially sending a Retry\npacket.  Tokens provided with NEW_TOKEN frames and Retry packets can be\ndistinguished by servers (see {{token-differentiation}}), and the latter can be\nvalidated more strictly.  If the validation succeeds, the server SHOULD then\nallow the handshake to proceed.\n\n<aside markdown=\"block\">\nNote: The rationale for treating the client as unvalidated rather than\n  discarding the packet is that the client might have received the token in a\n  previous connection using the NEW_TOKEN frame, and if the server has lost\n  state, it might be unable to validate the token at all, leading to connection\n  failure if the packet is discarded.\n</aside>\n\nIn a stateless design, a server can use encrypted and authenticated tokens to\npass information to clients that the server can later recover and use to\nvalidate a client address.  Tokens are not integrated into the cryptographic\nhandshake, and so they are not authenticated.  For instance, a client might be\nable to reuse a token.  To avoid attacks that exploit this property, a server\ncan limit its use of tokens to only the information needed to validate client\naddresses.\n\nClients MAY use tokens obtained on one connection for any connection attempt\nusing the same version.  When selecting a token to use, clients do not need to\nconsider other properties of the connection that is being attempted, including\nthe choice of possible application protocols, session tickets, or other\nconnection properties.\n\n\n### Address Validation Token Integrity {#token-integrity}\n\nAn address validation token MUST be difficult to guess.  Including a random\nvalue with at least 128 bits of entropy in the token would be sufficient, but\nthis depends on the server remembering the value it sends to clients.\n\nA token-based scheme allows the server to offload any state associated with\nvalidation to the client.  For this design to work, the token MUST be covered by\nintegrity protection against modification or falsification by clients.  Without\nintegrity protection, malicious clients could generate or guess values for\ntokens that would be accepted by the server.  Only the server requires access to\nthe integrity protection key for tokens.\n\nThere is no need for a single well-defined format for the token because the\nserver that generates the token also consumes it.  Tokens sent in Retry packets\nSHOULD include information that allows the server to verify that the source IP\naddress and port in client packets remain constant.\n\nTokens sent in NEW_TOKEN frames MUST include information that allows the server\nto verify that the client IP address has not changed from when the token was\nissued. Servers can use tokens from NEW_TOKEN frames in deciding not to send a\nRetry packet, even if the client address has changed. If the client IP address\nhas changed, the server MUST adhere to the anti-amplification limit; see\n{{address-validation}}.  Note that in the presence of NAT, this requirement\nmight be insufficient to protect other hosts that share the NAT from\namplification attacks.\n\nAttackers could replay tokens to use servers as amplifiers in DDoS attacks. To\nprotect against such attacks, servers MUST ensure that replay of tokens is\nprevented or limited. Servers SHOULD ensure that tokens sent in Retry packets\nare only accepted for a short time, as they are returned immediately by clients.\nTokens that are provided in NEW_TOKEN frames ({{frame-new-token}}) need to be\nvalid for longer but SHOULD NOT be accepted multiple times. Servers are\nencouraged to allow tokens to be used only once, if possible; tokens MAY include\nadditional information about clients to further narrow applicability or reuse.\n\n\n## Path Validation {#migrate-validate}\n\nPath validation is used by both peers during connection migration\n(see {{migration}}) to verify reachability after a change of address.\nIn path validation, endpoints test reachability between a specific local\naddress and a specific peer address, where an address is the 2-tuple of\nIP address and port.\n\nPath validation tests that packets sent on a path to a peer are\nreceived by that peer. Path validation is used to ensure that packets received\nfrom a migrating peer do not carry a spoofed source address.\n\nPath validation does not validate that a peer can send in the return direction.\nAcknowledgments cannot be used for return path validation because they contain\ninsufficient entropy and might be spoofed. Endpoints independently determine\nreachability on each direction of a path, and therefore return reachability can\nonly be established by the peer.\n\nPath validation can be used at any time by either endpoint.  For instance, an\nendpoint might check that a peer is still in possession of its address after a\nperiod of quiescence.\n\nPath validation is not designed as a NAT traversal mechanism. Though the\nmechanism described here might be effective for the creation of NAT bindings\nthat support NAT traversal, the expectation is that one endpoint is able to\nreceive packets without first having sent a packet on that path. Effective NAT\ntraversal needs additional synchronization mechanisms that are not provided\nhere.\n\nAn endpoint MAY include other frames with the PATH_CHALLENGE and PATH_RESPONSE\nframes used for path validation.  In particular, an endpoint can include PADDING\nframes with a PATH_CHALLENGE frame for Path Maximum Transmission Unit Discovery\n(PMTUD); see {{pmtud}}. An endpoint can also include its own PATH_CHALLENGE\nframe when sending a PATH_RESPONSE frame.\n\nAn endpoint uses a new connection ID for probes sent from a new local address;\nsee {{migration-linkability}}.  When probing a new path, an endpoint can\nensure that its peer has an unused connection ID available for\nresponses. Sending NEW_CONNECTION_ID and PATH_CHALLENGE frames in the same\npacket, if the peer's active_connection_id_limit permits, ensures that an unused\nconnection ID will be available to the peer when sending a response.\n\nAn endpoint can choose to simultaneously probe multiple paths. The number of\nsimultaneous paths used for probes is limited by the number of extra connection\nIDs its peer has previously supplied, since each new local address used for a\nprobe requires a previously unused connection ID.\n\n### Initiating Path Validation\n\nTo initiate path validation, an endpoint sends a PATH_CHALLENGE frame containing\nan unpredictable payload on the path to be validated.\n\nAn endpoint MAY send multiple PATH_CHALLENGE frames to guard against packet\nloss. However, an endpoint SHOULD NOT send multiple PATH_CHALLENGE frames in a\nsingle packet.\n\nAn endpoint SHOULD NOT probe a new path with packets containing a PATH_CHALLENGE\nframe more frequently than it would send an Initial packet. This ensures that\nconnection migration is no more load on a new path than establishing a new\nconnection.\n\nThe endpoint MUST use unpredictable data in every PATH_CHALLENGE frame so that\nit can associate the peer's response with the corresponding PATH_CHALLENGE.\n\nAn endpoint MUST expand datagrams that contain a PATH_CHALLENGE frame to at\nleast the smallest allowed maximum datagram size of 1200 bytes, unless the\nanti-amplification limit for the path does not permit sending a datagram of\nthis size.  Sending UDP datagrams of this size ensures that the network path\nfrom the endpoint to the peer can be used for QUIC; see {{datagram-size}}.\n\nWhen an endpoint is unable to expand the datagram size to 1200 bytes due to the\nanti-amplification limit, the path MTU will not be validated.  To ensure that\nthe path MTU is large enough, the endpoint MUST perform a second path validation\nby sending a PATH_CHALLENGE frame in a datagram of at least 1200 bytes.  This\nadditional validation can be performed after a PATH_RESPONSE is successfully\nreceived or when enough bytes have been received on the path that sending the\nlarger datagram will not result in exceeding the anti-amplification limit.\n\nUnlike other cases where datagrams are expanded, endpoints MUST NOT discard\ndatagrams that appear to be too small when they contain PATH_CHALLENGE or\nPATH_RESPONSE.\n\n\n### Path Validation Responses\n\nOn receiving a PATH_CHALLENGE frame, an endpoint MUST respond by echoing the\ndata contained in the PATH_CHALLENGE frame in a PATH_RESPONSE frame.  An\nendpoint MUST NOT delay transmission of a packet containing a PATH_RESPONSE\nframe unless constrained by congestion control.\n\nA PATH_RESPONSE frame MUST be sent on the network path where the PATH_CHALLENGE\nframe was received.  This ensures that path validation by a peer only succeeds\nif the path is functional in both directions.  This requirement MUST NOT be\nenforced by the endpoint that initiates path validation, as that would enable an\nattack on migration; see {{off-path-forward}}.\n\nAn endpoint MUST expand datagrams that contain a PATH_RESPONSE frame to at\nleast the smallest allowed maximum datagram size of 1200 bytes. This verifies\nthat the path is able to carry datagrams of this size in both directions.\nHowever, an endpoint MUST NOT expand the datagram containing the PATH_RESPONSE\nif the resulting data exceeds the anti-amplification limit. This is expected to\nonly occur if the received PATH_CHALLENGE was not sent in an expanded datagram.\n\nAn endpoint MUST NOT send more than one PATH_RESPONSE frame in response to one\nPATH_CHALLENGE frame; see {{retransmission-of-information}}.  The peer is\nexpected to send more PATH_CHALLENGE frames as necessary to evoke additional\nPATH_RESPONSE frames.\n\n\n### Successful Path Validation\n\nPath validation succeeds when a PATH_RESPONSE frame is received that contains\nthe data that was sent in a previous PATH_CHALLENGE frame.  A PATH_RESPONSE\nframe received on any network path validates the path on which the\nPATH_CHALLENGE was sent.\n\nIf an endpoint sends a PATH_CHALLENGE frame in a datagram that is not expanded\nto at least 1200 bytes and if the response to it validates the peer address,\nthe path is validated but not the path MTU. As a result, the endpoint can now\nsend more than three times the amount of data that has been received. However,\nthe endpoint MUST initiate another path validation with an expanded datagram to\nverify that the path supports the required MTU.\n\nReceipt of an acknowledgment for a packet containing a PATH_CHALLENGE frame is\nnot adequate validation, since the acknowledgment can be spoofed by a malicious\npeer.\n\n\n### Failed Path Validation\n\nPath validation only fails when the endpoint attempting to validate the path\nabandons its attempt to validate the path.\n\nEndpoints SHOULD abandon path validation based on a timer. When setting this\ntimer, implementations are cautioned that the new path could have a longer\nround-trip time than the original.  A value of three times the larger of the\ncurrent PTO or the PTO for the new path (using kInitialRtt, as defined\nin {{QUIC-RECOVERY}}) is RECOMMENDED.\n\nThis timeout allows for multiple PTOs to expire prior to failing path\nvalidation, so that loss of a single PATH_CHALLENGE or PATH_RESPONSE frame\ndoes not cause path validation failure.\n\nNote that the endpoint might receive packets containing other frames on the new\npath, but a PATH_RESPONSE frame with appropriate data is required for path\nvalidation to succeed.\n\nWhen an endpoint abandons path validation, it determines that the path is\nunusable.  This does not necessarily imply a failure of the connection --\nendpoints can continue sending packets over other paths as appropriate.  If no\npaths are available, an endpoint can wait for a new path to become available or\nclose the connection.  An endpoint that has no valid network path to its peer\nMAY signal this using the NO_VIABLE_PATH connection error, noting that this is\nonly possible if the network path exists but does not support the required\nMTU ({{datagram-size}}).\n\nA path validation might be abandoned for other reasons besides\nfailure. Primarily, this happens if a connection migration to a new path is\ninitiated while a path validation on the old path is in progress.\n\n\n# Connection Migration {#migration}\n\nThe use of a connection ID allows connections to survive changes to endpoint\naddresses (IP address and port), such as those caused by an\nendpoint migrating to a new network.  This section describes the process by\nwhich an endpoint migrates to a new address.\n\nThe design of QUIC relies on endpoints retaining a stable address for the\nduration of the handshake.  An endpoint MUST NOT initiate connection migration\nbefore the handshake is confirmed, as defined in {{Section 4.1.2 of QUIC-TLS}}.\n\nIf the peer sent the disable_active_migration transport parameter, an endpoint\nalso MUST NOT send packets (including probing packets; see {{probing}}) from a\ndifferent local address to the address the peer used during the handshake,\nunless the endpoint has acted on a preferred_address transport parameter from\nthe peer. If the peer violates this requirement, the endpoint MUST either drop\nthe incoming packets on that path without generating a Stateless Reset or\nproceed with path validation and allow the peer to migrate. Generating a\nStateless Reset or closing the connection would allow third parties in the\nnetwork to cause connections to close by spoofing or otherwise manipulating\nobserved traffic.\n\nNot all changes of peer address are intentional, or active, migrations. The peer\ncould experience NAT rebinding: a change of address due to a middlebox, usually\na NAT, allocating a new outgoing port or even a new outgoing IP address for a\nflow.  An endpoint MUST perform path validation ({{migrate-validate}}) if it\ndetects any change to a peer's address, unless it has previously validated that\naddress.\n\nWhen an endpoint has no validated path on which to send packets, it MAY discard\nconnection state.  An endpoint capable of connection migration MAY wait for a\nnew path to become available before discarding connection state.\n\nThis document limits migration of connections to new client addresses, except as\ndescribed in {{preferred-address}}. Clients are responsible for initiating all\nmigrations.  Servers do not send non-probing packets (see {{probing}}) toward a\nclient address until they see a non-probing packet from that address.  If a\nclient receives packets from an unknown server address, the client MUST discard\nthese packets.\n\n\n## Probing a New Path {#probing}\n\nAn endpoint MAY probe for peer reachability from a new local address using path\nvalidation ({{migrate-validate}}) prior to migrating the connection to the new\nlocal address.  Failure of path validation simply means that the new path is not\nusable for this connection.  Failure to validate a path does not cause the\nconnection to end unless there are no valid alternative paths available.\n\nPATH_CHALLENGE, PATH_RESPONSE, NEW_CONNECTION_ID, and PADDING frames are\n\"probing frames\", and all other frames are \"non-probing frames\".  A packet\ncontaining only probing frames is a \"probing packet\", and a packet containing\nany other frame is a \"non-probing packet\".\n\n\n## Initiating Connection Migration {#initiating-migration}\n\nAn endpoint can migrate a connection to a new local address by sending packets\ncontaining non-probing frames from that address.\n\nEach endpoint validates its peer's address during connection establishment.\nTherefore, a migrating endpoint can send to its peer knowing that the peer is\nwilling to receive at the peer's current address. Thus, an endpoint can migrate\nto a new local address without first validating the peer's address.\n\nTo establish reachability on the new path, an endpoint initiates path\nvalidation ({{migrate-validate}}) on the new path.  An endpoint MAY defer path\nvalidation until after a peer sends the next non-probing frame to its new\naddress.\n\nWhen migrating, the new path might not support the endpoint's current sending\nrate. Therefore, the endpoint resets its congestion controller and RTT estimate,\nas described in {{migration-cc}}.\n\nThe new path might not have the same ECN capability. Therefore, the endpoint\nvalidates ECN capability as described in {{ecn}}.\n\n\n## Responding to Connection Migration {#migration-response}\n\nReceiving a packet from a new peer address containing a non-probing frame\nindicates that the peer has migrated to that address.\n\nIf the recipient permits the migration, it MUST send subsequent packets\nto the new peer address and MUST initiate path validation ({{migrate-validate}})\nto verify the peer's ownership of the address if validation is not already\nunderway. If the recipient has no unused connection IDs from the peer, it will\nnot be able to send anything on the new path until the peer provides one; see\n{{migration-linkability}}.\n\nAn endpoint only changes the address to which it sends packets in response to\nthe highest-numbered non-probing packet. This ensures that an endpoint does not\nsend packets to an old peer address in the case that it receives reordered\npackets.\n\nAn endpoint MAY send data to an unvalidated peer address, but it MUST protect\nagainst potential attacks as described in Sections {{<address-spoofing}} and\n{{<on-path-spoofing}}.  An endpoint MAY skip validation of a peer address if\nthat address has been seen recently.  In particular, if an endpoint returns to a\npreviously validated path after detecting some form of spurious migration,\nskipping address validation and restoring loss detection and congestion state\ncan reduce the performance impact of the attack.\n\nAfter changing the address to which it sends non-probing packets, an endpoint\ncan abandon any path validation for other addresses.\n\nReceiving a packet from a new peer address could be the result of a NAT\nrebinding at the peer.\n\nAfter verifying a new client address, the server SHOULD send new address\nvalidation tokens ({{address-validation}}) to the client.\n\n\n### Peer Address Spoofing {#address-spoofing}\n\nIt is possible that a peer is spoofing its source address to cause an endpoint\nto send excessive amounts of data to an unwilling host.  If the endpoint sends\nsignificantly more data than the spoofing peer, connection migration might be\nused to amplify the volume of data that an attacker can generate toward a\nvictim.\n\nAs described in {{migration-response}}, an endpoint is required to validate a\npeer's new address to confirm the peer's possession of the new address. Until a\npeer's address is deemed valid, an endpoint limits the amount of data it sends\nto that address; see {{address-validation}}. In the absence of this limit, an\nendpoint risks being used for a denial-of-service attack against an\nunsuspecting victim.\n\nIf an endpoint skips validation of a peer address as described above, it does\nnot need to limit its sending rate.\n\n\n### On-Path Address Spoofing {#on-path-spoofing}\n\nAn on-path attacker could cause a spurious connection migration by copying and\nforwarding a packet with a spoofed address such that it arrives before the\noriginal packet.  The packet with the spoofed address will be seen to come from\na migrating connection, and the original packet will be seen as a duplicate and\ndropped. After a spurious migration, validation of the source address will fail\nbecause the entity at the source address does not have the necessary\ncryptographic keys to read or respond to the PATH_CHALLENGE frame that is sent\nto it even if it wanted to.\n\nTo protect the connection from failing due to such a spurious migration, an\nendpoint MUST revert to using the last validated peer address when validation\nof a new peer address fails.  Additionally, receipt of packets with higher\npacket numbers from the legitimate peer address will trigger another connection\nmigration.  This will cause the validation of the address of the spurious\nmigration to be abandoned, thus containing migrations initiated by the attacker\ninjecting a single packet.\n\nIf an endpoint has no state about the last validated peer address, it MUST close\nthe connection silently by discarding all connection state. This results in new\npackets on the connection being handled generically. For instance, an endpoint\nMAY send a Stateless Reset in response to any further incoming packets.\n\n\n### Off-Path Packet Forwarding {#off-path-forward}\n\nAn off-path attacker that can observe packets might forward copies of genuine\npackets to endpoints.  If the copied packet arrives before the genuine packet,\nthis will appear as a NAT rebinding.  Any genuine packet will be discarded as a\nduplicate.  If the attacker is able to continue forwarding packets, it might be\nable to cause migration to a path via the attacker.  This places the attacker\non-path, giving it the ability to observe or drop all subsequent packets.\n\nThis style of attack relies on the attacker using a path that has approximately\nthe same characteristics as the direct path between endpoints.  The attack is\nmore reliable if relatively few packets are sent or if packet loss coincides\nwith the attempted attack.\n\nA non-probing packet received on the original path that increases the maximum\nreceived packet number will cause the endpoint to move back to that path.\nEliciting packets on this path increases the likelihood that the attack is\nunsuccessful.  Therefore, mitigation of this attack relies on triggering the\nexchange of packets.\n\nIn response to an apparent migration, endpoints MUST validate the previously\nactive path using a PATH_CHALLENGE frame.  This induces the sending of new\npackets on that path.  If the path is no longer viable, the validation attempt\nwill time out and fail; if the path is viable but no longer desired, the\nvalidation will succeed but only results in probing packets being sent on the\npath.\n\nAn endpoint that receives a PATH_CHALLENGE on an active path SHOULD send a\nnon-probing packet in response.  If the non-probing packet arrives before any\ncopy made by an attacker, this results in the connection being migrated back to\nthe original path.  Any subsequent migration to another path restarts this\nentire process.\n\nThis defense is imperfect, but this is not considered a serious problem. If the\npath via the attack is reliably faster than the original path despite multiple\nattempts to use that original path, it is not possible to distinguish between an\nattack and an improvement in routing.\n\nAn endpoint could also use heuristics to improve detection of this style of\nattack.  For instance, NAT rebinding is improbable if packets were recently\nreceived on the old path; similarly, rebinding is rare on IPv6 paths.  Endpoints\ncan also look for duplicated packets.  Conversely, a change in connection ID is\nmore likely to indicate an intentional migration rather than an attack.\n\n\n## Loss Detection and Congestion Control {#migration-cc}\n\nThe capacity available on the new path might not be the same as the old path.\nPackets sent on the old path MUST NOT contribute to congestion control or RTT\nestimation for the new path.\n\nOn confirming a peer's ownership of its new address, an endpoint MUST\nimmediately reset the congestion controller and round-trip time estimator for\nthe new path to initial values (see Appendices {{A.3<QUIC-RECOVERY}} and\n{{B.3<QUIC-RECOVERY}} of {{QUIC-RECOVERY}}) unless the only change in the peer's\naddress is its port number.  Because port-only changes are commonly the result\nof NAT rebinding or other middlebox activity, the endpoint MAY instead retain\nits congestion control state and round-trip estimate in those cases instead of\nreverting to initial values.  In cases where congestion control state retained\nfrom an old path is used on a new path with substantially different\ncharacteristics, a sender could transmit too aggressively until the congestion\ncontroller and the RTT estimator have adapted. Generally, implementations are\nadvised to be cautious when using previous values on a new path.\n\nThere could be apparent reordering at the receiver when an endpoint sends data\nand probes from/to multiple addresses during the migration period, since the two\nresulting paths could have different round-trip times.  A receiver of packets on\nmultiple paths will still send ACK frames covering all received packets.\n\nWhile multiple paths might be used during connection migration, a single\ncongestion control context and a single loss recovery context (as described in\n{{QUIC-RECOVERY}}) could be adequate.  For instance, an endpoint might delay\nswitching to a new congestion control context until it is confirmed that an old\npath is no longer needed (such as the case described in {{off-path-forward}}).\n\nA sender can make exceptions for probe packets so that their loss detection is\nindependent and does not unduly cause the congestion controller to reduce its\nsending rate.  An endpoint might set a separate timer when a PATH_CHALLENGE is\nsent, which is canceled if the corresponding PATH_RESPONSE is received. If the\ntimer fires before the PATH_RESPONSE is received, the endpoint might send a new\nPATH_CHALLENGE and restart the timer for a longer period of time.  This timer\nSHOULD be set as described in {{Section 6.2.1 of QUIC-RECOVERY}} and MUST NOT be\nmore aggressive.\n\n\n## Privacy Implications of Connection Migration {#migration-linkability}\n\nUsing a stable connection ID on multiple network paths would allow a passive\nobserver to correlate activity between those paths.  An endpoint that moves\nbetween networks might not wish to have their activity correlated by any entity\nother than their peer, so different connection IDs are used when sending from\ndifferent local addresses, as discussed in {{connection-id}}.  For this to be\neffective, endpoints need to ensure that connection IDs they provide cannot be\nlinked by any other entity.\n\nAt any time, endpoints MAY change the Destination Connection ID they transmit\nwith to a value that has not been used on another path.\n\nAn endpoint MUST NOT reuse a connection ID when sending from more than one local\naddress -- for example, when initiating connection migration as described in\n{{initiating-migration}} or when probing a new network path as described in\n{{probing}}.\n\nSimilarly, an endpoint MUST NOT reuse a connection ID when sending to more than\none destination address.  Due to network changes outside the control of its\npeer, an endpoint might receive packets from a new source address with the same\nDestination Connection ID field value, in which case it MAY continue to use the\ncurrent connection ID with the new remote address while still sending from the\nsame local address.\n\nThese requirements regarding connection ID reuse apply only to the sending of\npackets, as unintentional changes in path without a change in connection ID are\npossible.  For example, after a period of network inactivity, NAT rebinding\nmight cause packets to be sent on a new path when the client resumes sending.\nAn endpoint responds to such an event as described in {{migration-response}}.\n\nUsing different connection IDs for packets sent in both directions on each new\nnetwork path eliminates the use of the connection ID for linking packets from\nthe same connection across different network paths.  Header protection ensures\nthat packet numbers cannot be used to correlate activity.  This does not prevent\nother properties of packets, such as timing and size, from being used to\ncorrelate activity.\n\nAn endpoint SHOULD NOT initiate migration with a peer that has requested a\nzero-length connection ID, because traffic over the new path might be trivially\nlinkable to traffic over the old one.  If the server is able to associate\npackets with a zero-length connection ID to the right connection, it means that\nthe server is using other information to demultiplex packets.  For example, a\nserver might provide a unique address to every client -- for instance, using\nHTTP alternative services {{?ALTSVC=RFC7838}}.  Information that might allow\ncorrect routing of packets across multiple network paths will also allow\nactivity on those paths to be linked by entities other than the peer.\n\nA client might wish to reduce linkability by switching to a new connection ID,\nsource UDP port, or IP address (see {{?RFC8981}}) when sending traffic after a\nperiod of inactivity.  Changing the address from which it sends packets at the\nsame time might cause the server to detect a connection migration. This\nensures that the mechanisms that support migration are exercised even for\nclients that do not experience NAT rebindings or genuine migrations.  Changing\naddress can cause a peer to reset its congestion control state (see\n{{migration-cc}}), so addresses SHOULD only be changed infrequently.\n\nAn endpoint that exhausts available connection IDs cannot probe new paths or\ninitiate migration, nor can it respond to probes or attempts by its peer to\nmigrate.  To ensure that migration is possible and packets sent on different\npaths cannot be correlated, endpoints SHOULD provide new connection IDs before\npeers migrate; see {{issue-cid}}.  If a peer might have exhausted available\nconnection IDs, a migrating endpoint could include a NEW_CONNECTION_ID frame in\nall packets sent on a new network path.\n\n\n## Server's Preferred Address {#preferred-address}\n\nQUIC allows servers to accept connections on one IP address and attempt to\ntransfer these connections to a more preferred address shortly after the\nhandshake.  This is particularly useful when clients initially connect to an\naddress shared by multiple servers but would prefer to use a unicast address to\nensure connection stability. This section describes the protocol for migrating a\nconnection to a preferred server address.\n\nMigrating a connection to a new server address mid-connection is not supported\nby the version of QUIC specified in this document. If a client receives packets\nfrom a new server address when the client has not initiated a migration to that\naddress, the client SHOULD discard these packets.\n\n### Communicating a Preferred Address\n\nA server conveys a preferred address by including the preferred_address\ntransport parameter in the TLS handshake.\n\nServers MAY communicate a preferred address of each address family (IPv4 and\nIPv6) to allow clients to pick the one most suited to their network attachment.\n\nOnce the handshake is confirmed, the client SHOULD select one of the two\naddresses provided by the server and initiate path validation (see\n{{migrate-validate}}).  A client constructs packets using any previously unused\nactive connection ID, taken from either the preferred_address transport\nparameter or a NEW_CONNECTION_ID frame.\n\nAs soon as path validation succeeds, the client SHOULD begin sending all\nfuture packets to the new server address using the new connection ID and\ndiscontinue use of the old server address.  If path validation fails, the client\nMUST continue sending all future packets to the server's original IP address.\n\n\n### Migration to a Preferred Address\n\nA client that migrates to a preferred address MUST validate the address it\nchooses before migrating; see {{forgery-spa}}.\n\nA server might receive a packet addressed to its preferred IP address at any\ntime after it accepts a connection.  If this packet contains a PATH_CHALLENGE\nframe, the server sends a packet containing a PATH_RESPONSE frame as per\n{{migrate-validate}}.  The server MUST send non-probing packets from its\noriginal address until it receives a non-probing packet from the client at its\npreferred address and until the server has validated the new path.\n\nThe server MUST probe on the path toward the client from its preferred address.\nThis helps to guard against spurious migration initiated by an attacker.\n\nOnce the server has completed its path validation and has received a non-probing\npacket with a new largest packet number on its preferred address, the server\nbegins sending non-probing packets to the client exclusively from its preferred\nIP address. The server SHOULD drop newer packets for this connection that are\nreceived on the old IP address. The server MAY continue to process delayed\npackets that are received on the old IP address.\n\nThe addresses that a server provides in the preferred_address transport\nparameter are only valid for the connection in which they are provided. A\nclient MUST NOT use these for other connections, including connections that are\nresumed from the current connection.\n\n\n### Interaction of Client Migration and Preferred Address\n\nA client might need to perform a connection migration before it has migrated to\nthe server's preferred address.  In this case, the client SHOULD perform path\nvalidation to both the original and preferred server address from the client's\nnew address concurrently.\n\nIf path validation of the server's preferred address succeeds, the client MUST\nabandon validation of the original address and migrate to using the server's\npreferred address.  If path validation of the server's preferred address fails\nbut validation of the server's original address succeeds, the client MAY migrate\nto its new address and continue sending to the server's original address.\n\nIf packets received at the server's preferred address have a different source\naddress than observed from the client during the handshake, the server MUST\nprotect against potential attacks as described in Sections {{<address-spoofing}}\nand {{<on-path-spoofing}}.  In addition to intentional simultaneous migration,\nthis might also occur because the client's access network used a different NAT\nbinding for the server's preferred address.\n\nServers SHOULD initiate path validation to the client's new address upon\nreceiving a probe packet from a different address; see {{address-validation}}.\n\nA client that migrates to a new address SHOULD use a preferred address from the\nsame address family for the server.\n\nThe connection ID provided in the preferred_address transport parameter is not\nspecific to the addresses that are provided. This connection ID is provided to\nensure that the client has a connection ID available for migration, but the\nclient MAY use this connection ID on any path.\n\n\n## Use of IPv6 Flow Label and Migration {#ipv6-flow-label}\n\nEndpoints that send data using IPv6 SHOULD apply an IPv6 flow label in\ncompliance with {{!RFC6437}}, unless the local API does not allow setting IPv6\nflow labels.\n\nThe flow label generation MUST be designed to minimize the chances of\nlinkability with a previously used flow label, as a stable flow label would\nenable correlating activity on multiple paths; see {{migration-linkability}}.\n\n{{?RFC6437}} suggests deriving values using a pseudorandom function to generate\nflow labels.  Including the Destination Connection ID field in addition to\nsource and destination addresses when generating flow labels ensures that\nchanges are synchronized with changes in other observable identifiers.  A\ncryptographic hash function that combines these inputs with a local secret is\none way this might be implemented.\n\n\n# Connection Termination {#termination}\n\nAn established QUIC connection can be terminated in one of three ways:\n\n* idle timeout ({{idle-timeout}})\n* immediate close ({{immediate-close}})\n* stateless reset ({{stateless-reset}})\n\nAn endpoint MAY discard connection state if it does not have a validated path on\nwhich it can send packets; see {{migrate-validate}}.\n\n\n## Idle Timeout {#idle-timeout}\n\nIf a max_idle_timeout is specified by either endpoint in its transport\nparameters ({{transport-parameter-definitions}}), the connection is silently\nclosed and its state is discarded when it remains idle for longer than the\nminimum of the max_idle_timeout value advertised by both endpoints.\n\nEach endpoint advertises a max_idle_timeout, but the effective value\nat an endpoint is computed as the minimum of the two advertised values (or the\nsole advertised value, if only one endpoint advertises a non-zero value). By\nannouncing a max_idle_timeout, an endpoint commits to initiating an immediate\nclose ({{immediate-close}}) if it abandons the connection prior to the effective\nvalue.\n\nAn endpoint restarts its idle timer when a packet from its peer is received and\nprocessed successfully. An endpoint also restarts its idle timer when sending an\nack-eliciting packet if no other ack-eliciting packets have been sent since last\nreceiving and processing a packet. Restarting this timer when sending a packet\nensures that connections are not closed after new activity is initiated.\n\nTo avoid excessively small idle timeout periods, endpoints MUST increase the\nidle timeout period to be at least three times the current Probe Timeout (PTO).\nThis allows for multiple PTOs to expire, and therefore multiple probes to be\nsent and lost, prior to idle timeout.\n\n\n### Liveness Testing\n\nAn endpoint that sends packets close to the effective timeout risks having\nthem be discarded at the peer, since the idle timeout period might have expired\nat the peer before these packets arrive.\n\nAn endpoint can send a PING or another ack-eliciting frame to test the\nconnection for liveness if the peer could time out soon, such as within a PTO;\nsee {{Section 6.2 of QUIC-RECOVERY}}.  This is especially useful if any\navailable application data cannot be safely retried. Note that the application\ndetermines what data is safe to retry.\n\n\n### Deferring Idle Timeout {#defer-idle}\n\nAn endpoint might need to send ack-eliciting packets to avoid an idle timeout if\nit is expecting response data but does not have or is unable to send application\ndata.\n\nAn implementation of QUIC might provide applications with an option to defer an\nidle timeout.  This facility could be used when the application wishes to avoid\nlosing state that has been associated with an open connection but does not\nexpect to exchange application data for some time.  With this option, an\nendpoint could send a PING frame ({{frame-ping}}) periodically, which will cause\nthe peer to restart its idle timeout period.  Sending a packet containing a PING\nframe restarts the idle timeout for this endpoint also if this is the first\nack-eliciting packet sent since receiving a packet.  Sending a PING frame causes\nthe peer to respond with an acknowledgment, which also restarts the idle\ntimeout for the endpoint.\n\nApplication protocols that use QUIC SHOULD provide guidance on when deferring an\nidle timeout is appropriate.  Unnecessary sending of PING frames could have a\ndetrimental effect on performance.\n\nA connection will time out if no packets are sent or received for a period\nlonger than the time negotiated using the max_idle_timeout transport parameter;\nsee {{termination}}.  However, state in middleboxes might time out earlier than\nthat.  Though REQ-5 in {{?RFC4787}} recommends a 2-minute timeout interval,\nexperience shows that sending packets every 30 seconds is necessary to prevent\nthe majority of middleboxes from losing state for UDP flows\n{{GATEWAY}}.\n\n\n## Immediate Close {#immediate-close}\n\nAn endpoint sends a CONNECTION_CLOSE frame ({{frame-connection-close}}) to\nterminate the connection immediately.  A CONNECTION_CLOSE frame causes all\nstreams to immediately become closed; open streams can be assumed to be\nimplicitly reset.\n\nAfter sending a CONNECTION_CLOSE frame, an endpoint immediately enters the\nclosing state; see {{closing}}. After receiving a CONNECTION_CLOSE frame,\nendpoints enter the draining state; see {{draining}}.\n\nViolations of the protocol lead to an immediate close.\n\nAn immediate close can be used after an application protocol has arranged to\nclose a connection.  This might be after the application protocol negotiates a\ngraceful shutdown.  The application protocol can exchange messages that are\nneeded for both application endpoints to agree that the connection can be\nclosed, after which the application requests that QUIC close the connection.\nWhen QUIC consequently closes the connection, a CONNECTION_CLOSE frame with an\napplication-supplied error code will be used to signal closure to the peer.\n\nThe closing and draining connection states exist to ensure that connections\nclose cleanly and that delayed or reordered packets are properly discarded.\nThese states SHOULD persist for at least three times the current PTO interval as\ndefined in {{QUIC-RECOVERY}}.\n\nDisposing of connection state prior to exiting the closing or draining state\ncould result in an endpoint generating a Stateless Reset unnecessarily when it\nreceives a late-arriving packet.  Endpoints that have some alternative means\nto ensure that late-arriving packets do not induce a response, such as those\nthat are able to close the UDP socket, MAY end these states earlier to allow\nfor faster resource recovery.  Servers that retain an open socket for accepting\nnew connections SHOULD NOT end the closing or draining state early.\n\nOnce its closing or draining state ends, an endpoint SHOULD discard all\nconnection state.  The endpoint MAY send a Stateless Reset in response to any\nfurther incoming packets belonging to this connection.\n\n\n### Closing Connection State {#closing}\n\nAn endpoint enters the closing state after initiating an immediate close.\n\nIn the closing state, an endpoint retains only enough information to generate a\npacket containing a CONNECTION_CLOSE frame and to identify packets as belonging\nto the connection. An endpoint in the closing state sends a packet containing a\nCONNECTION_CLOSE frame in response to any incoming packet that it attributes to\nthe connection.\n\nAn endpoint SHOULD limit the rate at which it generates packets in the closing\nstate. For instance, an endpoint could wait for a progressively increasing\nnumber of received packets or amount of time before responding to received\npackets.\n\nAn endpoint's selected connection ID and the QUIC version are sufficient\ninformation to identify packets for a closing connection; the endpoint MAY\ndiscard all other connection state. An endpoint that is closing is not required\nto process any received frame. An endpoint MAY retain packet protection keys for\nincoming packets to allow it to read and process a CONNECTION_CLOSE frame.\n\nAn endpoint MAY drop packet protection keys when entering the closing state and\nsend a packet containing a CONNECTION_CLOSE frame in response to any UDP\ndatagram that is received. However, an endpoint that discards packet protection\nkeys cannot identify and discard invalid packets. To avoid being used for an\namplification attack, such endpoints MUST limit the cumulative size of packets\nit sends to three times the cumulative size of the packets that are received\nand attributed to the connection. To minimize the state that an endpoint\nmaintains for a closing connection, endpoints MAY send the exact same packet in\nresponse to any received packet.\n\n<aside markdown=\"block\">\nNote: Allowing retransmission of a closing packet is an exception to the\n  requirement that a new packet number be used for each packet; see\n  {{packet-numbers}}.  Sending new packet numbers is primarily of advantage to\n  loss recovery and congestion control, which are not expected to be relevant\n  for a closed connection. Retransmitting the final packet requires less state.\n</aside>\n\nWhile in the closing state, an endpoint could receive packets from a new source\naddress, possibly indicating a connection migration; see {{migration}}.  An\nendpoint in the closing state MUST either discard packets received from an\nunvalidated address or limit the cumulative size of packets it sends to an\nunvalidated address to three times the size of packets it receives from that\naddress.\n\nAn endpoint is not expected to handle key updates when it is closing ({{Section\n6 of QUIC-TLS}}). A key update might prevent the endpoint from moving from the\nclosing state to the draining state, as the endpoint will not be able to\nprocess subsequently received packets, but it otherwise has no impact.\n\n\n### Draining Connection State {#draining}\n\nThe draining state is entered once an endpoint receives a CONNECTION_CLOSE\nframe, which indicates that its peer is closing or draining. While otherwise\nidentical to the closing state, an endpoint in the draining state MUST NOT send\nany packets. Retaining packet protection keys is unnecessary once a connection\nis in the draining state.\n\nAn endpoint that receives a CONNECTION_CLOSE frame MAY send a single packet\ncontaining a CONNECTION_CLOSE frame before entering the draining state, using a\nNO_ERROR code if appropriate.  An endpoint MUST NOT send further packets. Doing\nso could result in a constant exchange of CONNECTION_CLOSE frames until one of\nthe endpoints exits the closing state.\n\nAn endpoint MAY enter the draining state from the closing state if it receives a\nCONNECTION_CLOSE frame, which indicates that the peer is also closing or\ndraining. In this case, the draining state ends when the closing state would\nhave ended. In other words, the endpoint uses the same end time but ceases\ntransmission of any packets on this connection.\n\n\n### Immediate Close during the Handshake {#immediate-close-hs}\n\nWhen sending a CONNECTION_CLOSE frame, the goal is to ensure that the peer will\nprocess the frame.  Generally, this means sending the frame in a packet with the\nhighest level of packet protection to avoid the packet being discarded.  After\nthe handshake is confirmed (see {{Section 4.1.2 of QUIC-TLS}}), an endpoint MUST\nsend any CONNECTION_CLOSE frames in a 1-RTT packet.  However, prior to\nconfirming the handshake, it is possible that more advanced packet protection\nkeys are not available to the peer, so another CONNECTION_CLOSE frame MAY be\nsent in a packet that uses a lower packet protection level.  More specifically:\n\n* A client will always know whether the server has Handshake keys (see\n  {{discard-initial}}), but it is possible that a server does not know whether\n  the client has Handshake keys.  Under these circumstances, a server SHOULD\n  send a CONNECTION_CLOSE frame in both Handshake and Initial packets to ensure\n  that at least one of them is processable by the client.\n\n* A client that sends a CONNECTION_CLOSE frame in a 0-RTT packet cannot be\n  assured that the server has accepted 0-RTT.  Sending a CONNECTION_CLOSE frame\n  in an Initial packet makes it more likely that the server can receive the\n  close signal, even if the application error code might not be received.\n\n* Prior to confirming the handshake, a peer might be unable to process 1-RTT\n  packets, so an endpoint SHOULD send a CONNECTION_CLOSE frame in both Handshake\n  and 1-RTT packets.  A server SHOULD also send a CONNECTION_CLOSE frame in an\n  Initial packet.\n\nSending a CONNECTION_CLOSE of type 0x1d in an Initial or Handshake packet could\nexpose application state or be used to alter application state. A\nCONNECTION_CLOSE of type 0x1d MUST be replaced by a CONNECTION_CLOSE of type\n0x1c when sending the frame in Initial or Handshake packets. Otherwise,\ninformation about the application state might be revealed. Endpoints MUST clear\nthe value of the Reason Phrase field and SHOULD use the APPLICATION_ERROR code\nwhen converting to a CONNECTION_CLOSE of type 0x1c.\n\nCONNECTION_CLOSE frames sent in multiple packet types can be coalesced into a\nsingle UDP datagram; see {{packet-coalesce}}.\n\nAn endpoint can send a CONNECTION_CLOSE frame in an Initial packet.  This might\nbe in response to unauthenticated information received in Initial or Handshake\npackets.  Such an immediate close might expose legitimate connections to a\ndenial of service.  QUIC does not include defensive measures for on-path attacks\nduring the handshake; see {{handshake-dos}}.  However, at the cost of reducing\nfeedback about errors for legitimate peers, some forms of denial of service can\nbe made more difficult for an attacker if endpoints discard illegal packets\nrather than terminating a connection with CONNECTION_CLOSE.  For this reason,\nendpoints MAY discard packets rather than immediately close if errors are\ndetected in packets that lack authentication.\n\nAn endpoint that has not established state, such as a server that detects an\nerror in an Initial packet, does not enter the closing state.  An endpoint that\nhas no state for the connection does not enter a closing or draining period on\nsending a CONNECTION_CLOSE frame.\n\n\n## Stateless Reset {#stateless-reset}\n\nA stateless reset is provided as an option of last resort for an endpoint that\ndoes not have access to the state of a connection.  A crash or outage might\nresult in peers continuing to send data to an endpoint that is unable to\nproperly continue the connection.  An endpoint MAY send a Stateless Reset in\nresponse to receiving a packet that it cannot associate with an active\nconnection.\n\nA stateless reset is not appropriate for indicating errors in active\nconnections. An endpoint that wishes to communicate a fatal connection error\nMUST use a CONNECTION_CLOSE frame if it is able.\n\nTo support this process, an endpoint issues a stateless reset token, which is a\n16-byte value that is hard to guess.  If the peer subsequently receives a\nStateless Reset, which is a UDP datagram that ends in that stateless\nreset token, the peer will immediately end the connection.\n\nA stateless reset token is specific to a connection ID. An endpoint issues a\nstateless reset token by including the value in the Stateless Reset Token field\nof a NEW_CONNECTION_ID frame. Servers can also issue a stateless_reset_token\ntransport parameter during the handshake that applies to the connection ID that\nit selected during the handshake. These exchanges are protected by encryption,\nso only client and server know their value. Note that clients cannot use the\nstateless_reset_token transport parameter because their transport parameters do\nnot have confidentiality protection.\n\nTokens are invalidated when their associated connection ID is retired via a\nRETIRE_CONNECTION_ID frame ({{frame-retire-connection-id}}).\n\nAn endpoint that receives packets that it cannot process sends a packet in the\nfollowing layout (see {{notation}}):\n\n~~~\nStateless Reset {\n  Fixed Bits (2) = 1,\n  Unpredictable Bits (38..),\n  Stateless Reset Token (128),\n}\n~~~\n{: #fig-stateless-reset title=\"Stateless Reset\"}\n\nThis design ensures that a Stateless Reset is -- to the extent possible --\nindistinguishable from a regular packet with a short header.\n\nA Stateless Reset uses an entire UDP datagram, starting with the first two bits\nof the packet header.  The remainder of the first byte and an arbitrary number\nof bytes following it are set to values that SHOULD be indistinguishable\nfrom random.  The last 16 bytes of the datagram contain a stateless reset token.\n\nTo entities other than its intended recipient, a Stateless Reset will appear to\nbe a packet with a short header.  For the Stateless Reset to appear as a valid\nQUIC packet, the Unpredictable Bits field needs to include at least 38 bits of\ndata (or 5 bytes, less the two fixed bits).\n\nThe resulting minimum size of 21 bytes does not guarantee that a Stateless Reset\nis difficult to distinguish from other packets if the recipient requires the use\nof a connection ID. To achieve that end, the endpoint SHOULD ensure that all\npackets it sends are at least 22 bytes longer than the minimum connection ID\nlength that it requests the peer to include in its packets, adding PADDING\nframes as necessary.  This ensures that any Stateless Reset sent by the peer\nis indistinguishable from a valid packet sent to the endpoint.  An endpoint that\nsends a Stateless Reset in response to a packet that is 43 bytes or shorter\nSHOULD send a Stateless Reset that is one byte shorter than the packet it\nresponds to.\n\nThese values assume that the stateless reset token is the same length as the\nminimum expansion of the packet protection AEAD.  Additional unpredictable bytes\nare necessary if the endpoint could have negotiated a packet protection scheme\nwith a larger minimum expansion.\n\nAn endpoint MUST NOT send a Stateless Reset that is three times or more larger\nthan the packet it receives to avoid being used for amplification.\n{{reset-looping}} describes additional limits on Stateless Reset size.\n\nEndpoints MUST discard packets that are too small to be valid QUIC packets.  To\ngive an example, with the set of AEAD functions defined in {{QUIC-TLS}}, short\nheader packets that are smaller than 21 bytes are never valid.\n\nEndpoints MUST send Stateless Resets formatted as a packet with a short header.\nHowever, endpoints MUST treat any packet ending in a valid stateless reset token\nas a Stateless Reset, as other QUIC versions might allow the use of a long\nheader.\n\nAn endpoint MAY send a Stateless Reset in response to a packet with a long\nheader.  Sending a Stateless Reset is not effective prior to the stateless reset\ntoken being available to a peer.  In this QUIC version, packets with a long\nheader are only used during connection establishment.   Because the stateless\nreset token is not available until connection establishment is complete or near\ncompletion, ignoring an unknown packet with a long header might be as effective\nas sending a Stateless Reset.\n\nAn endpoint cannot determine the Source Connection ID from a packet with a short\nheader; therefore, it cannot set the Destination Connection ID in the Stateless\nReset.  The Destination Connection ID will therefore differ from the value used\nin previous packets.  A random Destination Connection ID makes the connection ID\nappear to be the result of moving to a new connection ID that was provided using\na NEW_CONNECTION_ID frame; see {{frame-new-connection-id}}.\n\nUsing a randomized connection ID results in two problems:\n\n* The packet might not reach the peer.  If the Destination Connection ID is\n  critical for routing toward the peer, then this packet could be incorrectly\n  routed.  This might also trigger another Stateless Reset in response; see\n  {{reset-looping}}.  A Stateless Reset that is not correctly routed is an\n  ineffective error detection and recovery mechanism.  In this case, endpoints\n  will need to rely on other methods -- such as timers -- to detect that the\n  connection has failed.\n\n* The randomly generated connection ID can be used by entities other than the\n  peer to identify this as a potential Stateless Reset.  An endpoint that\n  occasionally uses different connection IDs might introduce some uncertainty\n  about this.\n\nThis stateless reset design is specific to QUIC version 1.  An endpoint that\nsupports multiple versions of QUIC needs to generate a Stateless Reset that will\nbe accepted by peers that support any version that the endpoint might support\n(or might have supported prior to losing state).  Designers of new versions of\nQUIC need to be aware of this and either (1) reuse this design or (2) use a\nportion of the packet other than the last 16 bytes for carrying data.\n\n\n### Detecting a Stateless Reset\n\nAn endpoint detects a potential Stateless Reset using the trailing 16 bytes of\nthe UDP datagram.  An endpoint remembers all stateless reset tokens associated\nwith the connection IDs and remote addresses for datagrams it has recently sent.\nThis includes Stateless Reset Token field values from NEW_CONNECTION_ID frames\nand the server's transport parameters but excludes stateless reset tokens\nassociated with connection IDs that are either unused or retired.  The endpoint\nidentifies a received datagram as a Stateless Reset by comparing the last 16\nbytes of the datagram with all stateless reset tokens associated with the remote\naddress on which the datagram was received.\n\nThis comparison can be performed for every inbound datagram.  Endpoints MAY skip\nthis check if any packet from a datagram is successfully processed.  However,\nthe comparison MUST be performed when the first packet in an incoming datagram\neither cannot be associated with a connection or cannot be decrypted.\n\nAn endpoint MUST NOT check for any stateless reset tokens associated with\nconnection IDs it has not used or for connection IDs that have been retired.\n\nWhen comparing a datagram to stateless reset token values, endpoints MUST\nperform the comparison without leaking information about the value of the token.\nFor example, performing this comparison in constant time protects the value of\nindividual stateless reset tokens from information leakage through timing side\nchannels.  Another approach would be to store and compare the transformed values\nof stateless reset tokens instead of the raw token values, where the\ntransformation is defined as a cryptographically secure pseudorandom function\nusing a secret key (e.g., block cipher, Hashed Message Authentication Code\n(HMAC) {{?RFC2104}}). An endpoint is not expected to protect information about\nwhether a packet was successfully decrypted or the number of valid stateless\nreset tokens.\n\nIf the last 16 bytes of the datagram are identical in value to a stateless reset\ntoken, the endpoint MUST enter the draining period and not send any further\npackets on this connection.\n\n\n### Calculating a Stateless Reset Token {#reset-token}\n\nThe stateless reset token MUST be difficult to guess.  In order to create a\nstateless reset token, an endpoint could randomly generate {{?RANDOM=RFC4086}} a\nsecret for every connection that it creates.  However, this presents a\ncoordination problem when there are multiple instances in a cluster or a storage\nproblem for an endpoint that might lose state.  Stateless reset specifically\nexists to handle the case where state is lost, so this approach is suboptimal.\n\nA single static key can be used across all connections to the same endpoint by\ngenerating the proof using a pseudorandom function that takes a static key and\nthe connection ID chosen by the endpoint (see {{connection-id}}) as input.  An\nendpoint could use HMAC {{?RFC2104}} (for example, HMAC(static_key,\nconnection_id)) or the HMAC-based Key Derivation Function (HKDF) {{?RFC5869}}\n(for example, using the static key as input keying material, with the connection\nID as salt).  The output of this function is truncated to 16 bytes to produce\nthe stateless reset token for that connection.\n\nAn endpoint that loses state can use the same method to generate a valid\nstateless reset token.  The connection ID comes from the packet that the\nendpoint receives.\n\nThis design relies on the peer always sending a connection ID in its packets so\nthat the endpoint can use the connection ID from a packet to reset the\nconnection.  An endpoint that uses this design MUST either use the same\nconnection ID length for all connections or encode the length of the connection\nID such that it can be recovered without state.  In addition, it cannot provide\na zero-length connection ID.\n\nRevealing the stateless reset token allows any entity to terminate the\nconnection, so a value can only be used once.  This method for choosing the\nstateless reset token means that the combination of connection ID and static key\nMUST NOT be used for another connection.  A denial-of-service attack is possible\nif the same connection ID is used by instances that share a static key or if an\nattacker can cause a packet to be routed to an instance that has no state but\nthe same static key; see {{reset-oracle}}.  A connection ID from a connection\nthat is reset by revealing the stateless reset token MUST NOT be reused for new\nconnections at nodes that share a static key.\n\nThe same stateless reset token MUST NOT be used for multiple connection IDs.\nEndpoints are not required to compare new values against all previous values,\nbut a duplicate value MAY be treated as a connection error of type\nPROTOCOL_VIOLATION.\n\nNote that Stateless Resets do not have any cryptographic protection.\n\n\n### Looping {#reset-looping}\n\nThe design of a Stateless Reset is such that without knowing the stateless reset\ntoken it is indistinguishable from a valid packet.  For instance, if a server\nsends a Stateless Reset to another server, it might receive another Stateless\nReset in response, which could lead to an infinite exchange.\n\nAn endpoint MUST ensure that every Stateless Reset that it sends is smaller than\nthe packet that triggered it, unless it maintains state sufficient to prevent\nlooping.  In the event of a loop, this results in packets eventually being too\nsmall to trigger a response.\n\nAn endpoint can remember the number of Stateless Resets that it has sent and\nstop generating new Stateless Resets once a limit is reached.  Using separate\nlimits for different remote addresses will ensure that Stateless Resets can be\nused to close connections when other peers or connections have exhausted limits.\n\nA Stateless Reset that is smaller than 41 bytes might be identifiable as a\nStateless Reset by an observer, depending upon the length of the peer's\nconnection IDs.  Conversely, not sending a Stateless Reset in response to a\nsmall packet might result in Stateless Resets not being useful in detecting\ncases of broken connections where only very small packets are sent; such\nfailures might only be detected by other means, such as timers.\n\n\n# Error Handling {#error-handling}\n\nAn endpoint that detects an error SHOULD signal the existence of that error to\nits peer.  Both transport-level and application-level errors can affect an\nentire connection; see {{connection-errors}}.  Only application-level\nerrors can be isolated to a single stream; see {{stream-errors}}.\n\nThe most appropriate error code ({{error-codes}}) SHOULD be included in the\nframe that signals the error.  Where this specification identifies error\nconditions, it also identifies the error code that is used; though these are\nworded as requirements, different implementation strategies might lead to\ndifferent errors being reported.  In particular, an endpoint MAY use any\napplicable error code when it detects an error condition; a generic error code\n(such as PROTOCOL_VIOLATION or INTERNAL_ERROR) can always be used in place of\nspecific error codes.\n\nA stateless reset ({{stateless-reset}}) is not suitable for any error that can\nbe signaled with a CONNECTION_CLOSE or RESET_STREAM frame.  A stateless reset\nMUST NOT be used by an endpoint that has the state necessary to send a frame on\nthe connection.\n\n\n## Connection Errors\n\nErrors that result in the connection being unusable, such as an obvious\nviolation of protocol semantics or corruption of state that affects an entire\nconnection, MUST be signaled using a CONNECTION_CLOSE frame\n({{frame-connection-close}}).\n\nApplication-specific protocol errors are signaled using the CONNECTION_CLOSE\nframe with a frame type of 0x1d.  Errors that are specific to the transport,\nincluding all those described in this document, are carried in the\nCONNECTION_CLOSE frame with a frame type of 0x1c.\n\nA CONNECTION_CLOSE frame could be sent in a packet that is lost.  An endpoint\nSHOULD be prepared to retransmit a packet containing a CONNECTION_CLOSE frame if\nit receives more packets on a terminated connection. Limiting the number of\nretransmissions and the time over which this final packet is sent limits the\neffort expended on terminated connections.\n\nAn endpoint that chooses not to retransmit packets containing a CONNECTION_CLOSE\nframe risks a peer missing the first such packet.  The only mechanism available\nto an endpoint that continues to receive data for a terminated connection is to\nattempt the stateless reset process ({{stateless-reset}}).\n\nAs the AEAD for Initial packets does not provide strong authentication, an\nendpoint MAY discard an invalid Initial packet.  Discarding an Initial packet is\npermitted even where this specification otherwise mandates a connection error.\nAn endpoint can only discard a packet if it does not process the frames in the\npacket or reverts the effects of any processing.  Discarding invalid Initial\npackets might be used to reduce exposure to denial of service; see\n{{handshake-dos}}.\n\n\n## Stream Errors\n\nIf an application-level error affects a single stream but otherwise leaves the\nconnection in a recoverable state, the endpoint can send a RESET_STREAM frame\n({{frame-reset-stream}}) with an appropriate error code to terminate just the\naffected stream.\n\nResetting a stream without the involvement of the application protocol could\ncause the application protocol to enter an unrecoverable state.  RESET_STREAM\nMUST only be instigated by the application protocol that uses QUIC.\n\nThe semantics of the application error code carried in RESET_STREAM are\ndefined by the application protocol.  Only the application protocol is able to\ncause a stream to be terminated.  A local instance of the application protocol\nuses a direct API call, and a remote instance uses the STOP_SENDING frame, which\ntriggers an automatic RESET_STREAM.\n\nApplication protocols SHOULD define rules for handling streams that are\nprematurely canceled by either endpoint.\n\n\n# Packets and Frames {#packets-frames}\n\nQUIC endpoints communicate by exchanging packets. Packets have confidentiality\nand integrity protection; see {{packet-protected}}. Packets are carried in UDP\ndatagrams; see {{packet-coalesce}}.\n\nThis version of QUIC uses the long packet header during connection\nestablishment; see {{long-header}}.  Packets with the long header are Initial\n({{packet-initial}}), 0-RTT ({{packet-0rtt}}), Handshake ({{packet-handshake}}),\nand Retry ({{packet-retry}}).  Version negotiation uses a version-independent\npacket with a long header; see {{packet-version}}.\n\nPackets with the short header are designed for minimal overhead and are used\nafter a connection is established and 1-RTT keys are available; see\n{{short-header}}.\n\n\n## Protected Packets {#packet-protected}\n\nQUIC packets have different levels of cryptographic protection based on the\ntype of packet. Details of packet protection are found in {{QUIC-TLS}}; this\nsection includes an overview of the protections that are provided.\n\nVersion Negotiation packets have no cryptographic protection; see\n{{QUIC-INVARIANTS}}.\n\nRetry packets use an AEAD function {{?AEAD=RFC5116}} to protect against\naccidental modification.\n\nInitial packets use an AEAD function, the keys for which are derived using a\nvalue that is visible on the wire. Initial packets therefore do not have\neffective confidentiality protection. Initial protection exists to ensure that\nthe sender of the packet is on the network path. Any entity that receives an\nInitial packet from a client can recover the keys that will allow them to both\nread the contents of the packet and generate Initial packets that will be\nsuccessfully authenticated at either endpoint.  The AEAD also protects Initial\npackets against accidental modification.\n\nAll other packets are protected with keys derived from the cryptographic\nhandshake.  The cryptographic handshake ensures that only the communicating\nendpoints receive the corresponding keys for Handshake, 0-RTT, and 1-RTT\npackets.  Packets protected with 0-RTT and 1-RTT keys have strong\nconfidentiality and integrity protection.\n\nThe Packet Number field that appears in some packet types has alternative\nconfidentiality protection that is applied as part of header protection; see\n{{Section 5.4 of QUIC-TLS}} for details. The underlying packet number increases\nwith each packet sent in a given packet number space; see {{packet-numbers}} for\ndetails.\n\n\n## Coalescing Packets {#packet-coalesce}\n\nInitial ({{packet-initial}}), 0-RTT ({{packet-0rtt}}), and Handshake\n({{packet-handshake}}) packets contain a Length field that determines the end\nof the packet.  The length includes both the Packet Number and Payload\nfields, both of which are confidentiality protected and initially of unknown\nlength. The length of the Payload field is learned once header protection is\nremoved.\n\nUsing the Length field, a sender can coalesce multiple QUIC packets into one UDP\ndatagram.  This can reduce the number of UDP datagrams needed to complete the\ncryptographic handshake and start sending data.  This can also be used to\nconstruct Path Maximum Transmission Unit (PMTU) probes; see\n{{pmtu-probes-src-cid}}.  Receivers MUST be able to process coalesced packets.\n\nCoalescing packets in order of increasing encryption levels (Initial, 0-RTT,\nHandshake, 1-RTT; see {{Section 4.1.4 of QUIC-TLS}}) makes it more likely that\nthe receiver will be able to process all the packets in a single pass. A packet\nwith a short header does not include a length, so it can only be the last packet\nincluded in a UDP datagram.  An endpoint SHOULD include multiple frames in a\nsingle packet if they are to be sent at the same encryption level, instead of\ncoalescing multiple packets at the same encryption level.\n\nReceivers MAY route based on the information in the first packet contained in a\nUDP datagram.  Senders MUST NOT coalesce QUIC packets with different connection\nIDs into a single UDP datagram.  Receivers SHOULD ignore any subsequent packets\nwith a different Destination Connection ID than the first packet in the\ndatagram.\n\nEvery QUIC packet that is coalesced into a single UDP datagram is separate and\ncomplete.  The receiver of coalesced QUIC packets MUST individually process each\nQUIC packet and separately acknowledge them, as if they were received as the\npayload of different UDP datagrams.  For example, if decryption fails (because\nthe keys are not available or for any other reason), the receiver MAY either\ndiscard or buffer the packet for later processing and MUST attempt to process\nthe remaining packets.\n\nRetry packets ({{packet-retry}}), Version Negotiation packets\n({{packet-version}}), and packets with a short header ({{short-header}}) do not\ncontain a Length field and so cannot be followed by other packets in the same\nUDP datagram.  Note also that there is no situation where a Retry or Version\nNegotiation packet is coalesced with another packet.\n\n\n## Packet Numbers {#packet-numbers}\n\nThe packet number is an integer in the range 0 to 2<sup>62</sup>-1.  This number\nis used in determining the cryptographic nonce for packet protection.  Each\nendpoint maintains a separate packet number for sending and receiving.\n\nPacket numbers are limited to this range because they need to be representable\nin whole in the Largest Acknowledged field of an ACK frame ({{frame-ack}}).\nWhen present in a long or short header, however, packet numbers are reduced and\nencoded in 1 to 4 bytes; see {{packet-encoding}}.\n\nVersion Negotiation ({{packet-version}}) and Retry ({{packet-retry}}) packets\ndo not include a packet number.\n\nPacket numbers are divided into three spaces in QUIC:\n\nInitial space:\n: All Initial packets ({{packet-initial}}) are in this space.\n\nHandshake space:\n: All Handshake packets ({{packet-handshake}}) are in this space.\n\nApplication data space:\n: All 0-RTT ({{packet-0rtt}}) and 1-RTT ({{packet-1rtt}}) packets are in this\n  space.\n\nAs described in {{QUIC-TLS}}, each packet type uses different protection keys.\n\nConceptually, a packet number space is the context in which a packet can be\nprocessed and acknowledged.  Initial packets can only be sent with Initial\npacket protection keys and acknowledged in packets that are also Initial\npackets.  Similarly, Handshake packets are sent at the Handshake encryption\nlevel and can only be acknowledged in Handshake packets.\n\nThis enforces cryptographic separation between the data sent in the different\npacket number spaces.  Packet numbers in each space start at packet number 0.\nSubsequent packets sent in the same packet number space MUST increase the packet\nnumber by at least one.\n\n0-RTT and 1-RTT data exist in the same packet number space to make loss recovery\nalgorithms easier to implement between the two packet types.\n\nA QUIC endpoint MUST NOT reuse a packet number within the same packet number\nspace in one connection.  If the packet number for sending reaches\n2<sup>62</sup>-1, the sender MUST close the connection without sending a\nCONNECTION_CLOSE frame or any further packets; an endpoint MAY send a Stateless\nReset ({{stateless-reset}}) in response to further packets that it receives.\n\nA receiver MUST discard a newly unprotected packet unless it is certain that it\nhas not processed another packet with the same packet number from the same\npacket number space. Duplicate suppression MUST happen after removing packet\nprotection for the reasons described in {{Section 9.5 of QUIC-TLS}}.\n\nEndpoints that track all individual packets for the purposes of detecting\nduplicates are at risk of accumulating excessive state.  The data required for\ndetecting duplicates can be limited by maintaining a minimum packet number below\nwhich all packets are immediately dropped.  Any minimum needs to account for\nlarge variations in round-trip time, which includes the possibility that a peer\nmight probe network paths with much larger round-trip times; see {{migration}}.\n\nPacket number encoding at a sender and decoding at a receiver are described in\n{{packet-encoding}}.\n\n\n## Frames and Frame Types {#frames}\n\nThe payload of QUIC packets, after removing packet protection, consists of a\nsequence of complete frames, as shown in {{packet-frames}}.  Version\nNegotiation, Stateless Reset, and Retry packets do not contain frames.\n\n~~~\nPacket Payload {\n  Frame (8..) ...,\n}\n~~~\n{: #packet-frames title=\"QUIC Payload\"}\n\nThe payload of a packet that contains frames MUST contain at least one frame,\nand MAY contain multiple frames and multiple frame types.  An endpoint MUST\ntreat receipt of a packet containing no frames as a connection error of type\nPROTOCOL_VIOLATION.  Frames always fit within a single QUIC packet and cannot\nspan multiple packets.\n\nEach frame begins with a Frame Type, indicating its type, followed by\nadditional type-dependent fields:\n\n~~~\nFrame {\n  Frame Type (i),\n  Type-Dependent Fields (..),\n}\n~~~\n{: #frame-layout title=\"Generic Frame Layout\"}\n\n{{frame-types}} lists and summarizes information about each frame type that is\ndefined in this specification.  A description of this summary is included after\nthe table.\n\n| Type Value | Frame Type Name      | Definition                     | Pkts | Spec |\n|:-----------|:---------------------|:-------------------------------|------|------|\n| 0x00       | PADDING              | {{frame-padding}}              | IH01 | NP   |\n| 0x01       | PING                 | {{frame-ping}}                 | IH01 |      |\n| 0x02-0x03  | ACK                  | {{frame-ack}}                  | IH_1 | NC   |\n| 0x04       | RESET_STREAM         | {{frame-reset-stream}}         | __01 |      |\n| 0x05       | STOP_SENDING         | {{frame-stop-sending}}         | __01 |      |\n| 0x06       | CRYPTO               | {{frame-crypto}}               | IH_1 |      |\n| 0x07       | NEW_TOKEN            | {{frame-new-token}}            | ___1 |      |\n| 0x08-0x0f  | STREAM               | {{frame-stream}}               | __01 | F    |\n| 0x10       | MAX_DATA             | {{frame-max-data}}             | __01 |      |\n| 0x11       | MAX_STREAM_DATA      | {{frame-max-stream-data}}      | __01 |      |\n| 0x12-0x13  | MAX_STREAMS          | {{frame-max-streams}}          | __01 |      |\n| 0x14       | DATA_BLOCKED         | {{frame-data-blocked}}         | __01 |      |\n| 0x15       | STREAM_DATA_BLOCKED  | {{frame-stream-data-blocked}}  | __01 |      |\n| 0x16-0x17  | STREAMS_BLOCKED      | {{frame-streams-blocked}}      | __01 |      |\n| 0x18       | NEW_CONNECTION_ID    | {{frame-new-connection-id}}    | __01 | P    |\n| 0x19       | RETIRE_CONNECTION_ID | {{frame-retire-connection-id}} | __01 |      |\n| 0x1a       | PATH_CHALLENGE       | {{frame-path-challenge}}       | __01 | P    |\n| 0x1b       | PATH_RESPONSE        | {{frame-path-response}}        | ___1 | P    |\n| 0x1c-0x1d  | CONNECTION_CLOSE     | {{frame-connection-close}}     | ih01 | N    |\n| 0x1e       | HANDSHAKE_DONE       | {{frame-handshake-done}}       | ___1 |      |\n{: #frame-types title=\"Frame Types\"}\n\nThe format and semantics of each frame type are explained in more detail in\n{{frame-formats}}.  The remainder of this section provides a summary of\nimportant and general information.\n\nThe Frame Type in ACK, STREAM, MAX_STREAMS, STREAMS_BLOCKED, and\nCONNECTION_CLOSE frames is used to carry other frame-specific flags. For all\nother frames, the Frame Type field simply identifies the frame.\n\nThe \"Pkts\" column in {{frame-types}} lists the types of packets that each frame\ntype could appear in, indicated by the following characters:\n\nI:\n\n: Initial ({{packet-initial}})\n\nH:\n\n: Handshake ({{packet-handshake}})\n\n0:\n\n: 0-RTT ({{packet-0rtt}})\n\n1:\n\n: 1-RTT ({{packet-1rtt}})\n\nih:\n\n: Only a CONNECTION_CLOSE frame of type 0x1c can appear in Initial or Handshake\n  packets.\n{: indent=\"5\"}\n\nFor more details about these restrictions, see {{frames-and-spaces}}.  Note\nthat all frames can appear in 1-RTT packets.  An endpoint MUST treat receipt of\na frame in a packet type that is not permitted as a connection error of type\nPROTOCOL_VIOLATION.\n\nThe \"Spec\" column in  {{frame-types}} summarizes any special rules governing the\nprocessing or generation of the frame type, as indicated by the following\ncharacters:\n\nN:\n: Packets containing only frames with this marking are not ack-eliciting; see\n  {{generating-acks}}.\n\nC:\n: Packets containing only frames with this marking do not count toward bytes\n  in flight for congestion control purposes; see {{QUIC-RECOVERY}}.\n\nP:\n: Packets containing only frames with this marking can be used to probe new\n  network paths during connection migration; see {{probing}}.\n\nF:\n: The contents of frames with this marking are flow controlled; see\n  {{flow-control}}.\n{: indent=\"5\"}\n\nThe \"Pkts\" and \"Spec\" columns in  {{frame-types}} do not form part of the IANA\nregistry; see {{iana-frames}}.\n\nAn endpoint MUST treat the receipt of a frame of unknown type as a connection\nerror of type FRAME_ENCODING_ERROR.\n\nAll frames are idempotent in this version of QUIC.  That is, a valid frame does\nnot cause undesirable side effects or errors when received more than once.\n\nThe Frame Type field uses a variable-length integer encoding (see\n{{integer-encoding}}), with one exception.  To ensure simple and efficient\nimplementations of frame parsing, a frame type MUST use the shortest possible\nencoding.  For frame types defined in this document, this means a single-byte\nencoding, even though it is possible to encode these values as a two-, four-,\nor eight-byte variable-length integer.  For instance, though 0x4001 is\na legitimate two-byte encoding for a variable-length integer with a value\nof 1, PING frames are always encoded as a single byte with the value 0x01.\nThis rule applies to all current and future QUIC frame types.  An endpoint\nMAY treat the receipt of a frame type that uses a longer encoding than\nnecessary as a connection error of type PROTOCOL_VIOLATION.\n\n## Frames and Number Spaces {#frames-and-spaces}\n\nSome frames are prohibited in different packet number spaces. The rules here\ngeneralize those of TLS, in that frames associated with establishing the\nconnection can usually appear in packets in any packet number space, whereas\nthose associated with transferring data can only appear in the application\ndata packet number space:\n\n- PADDING, PING, and CRYPTO frames MAY appear in any packet number space.\n\n- CONNECTION_CLOSE frames signaling errors at the QUIC layer (type 0x1c) MAY\n  appear in any packet number space. CONNECTION_CLOSE frames signaling\n  application errors (type 0x1d) MUST only appear in the application data packet\n  number space.\n\n- ACK frames MAY appear in any packet number space but can only acknowledge\n  packets that appeared in that packet number space.  However, as noted below,\n  0-RTT packets cannot contain ACK frames.\n\n- All other frame types MUST only be sent in the application data packet number\n  space.\n\nNote that it is not possible to send the following frames in 0-RTT packets for\nvarious reasons: ACK, CRYPTO, HANDSHAKE_DONE, NEW_TOKEN, PATH_RESPONSE, and\nRETIRE_CONNECTION_ID.  A server MAY treat receipt of these frames in 0-RTT\npackets as a connection error of type PROTOCOL_VIOLATION.\n\n# Packetization and Reliability {#packetization}\n\nA sender sends one or more frames in a QUIC packet; see {{frames}}.\n\nA sender can minimize per-packet bandwidth and computational costs by including\nas many frames as possible in each QUIC packet.  A sender MAY wait for a short\nperiod of time to collect multiple frames before sending a packet that is not\nmaximally packed, to avoid sending out large numbers of small packets.  An\nimplementation MAY use knowledge about application sending behavior or\nheuristics to determine whether and for how long to wait.  This waiting period\nis an implementation decision, and an implementation should be careful to delay\nconservatively, since any delay is likely to increase application-visible\nlatency.\n\nStream multiplexing is achieved by interleaving STREAM frames from multiple\nstreams into one or more QUIC packets.  A single QUIC packet can include\nmultiple STREAM frames from one or more streams.\n\nOne of the benefits of QUIC is avoidance of head-of-line blocking across\nmultiple streams.  When a packet loss occurs, only streams with data in that\npacket are blocked waiting for a retransmission to be received, while other\nstreams can continue making progress.  Note that when data from multiple streams\nis included in a single QUIC packet, loss of that packet blocks all those\nstreams from making progress.  Implementations are advised to include as few\nstreams as necessary in outgoing packets without losing transmission efficiency\nto underfilled packets.\n\n\n## Packet Processing {#processing}\n\nA packet MUST NOT be acknowledged until packet protection has been successfully\nremoved and all frames contained in the packet have been processed.  For STREAM\nframes, this means the data has been enqueued in preparation to be received by\nthe application protocol, but it does not require that data be delivered and\nconsumed.\n\nOnce the packet has been fully processed, a receiver acknowledges receipt by\nsending one or more ACK frames containing the packet number of the received\npacket.\n\nAn endpoint SHOULD treat receipt of an acknowledgment for a packet it did not\nsend as a connection error of type PROTOCOL_VIOLATION, if it is able to detect\nthe condition.  For further discussion of how this might be achieved, see\n{{optimistic-ack-attack}}.\n\n## Generating Acknowledgments {#generating-acks}\n\nEndpoints acknowledge all packets they receive and process. However, only\nack-eliciting packets cause an ACK frame to be sent within the maximum ack\ndelay.  Packets that are not ack-eliciting are only acknowledged when an ACK\nframe is sent for other reasons.\n\nWhen sending a packet for any reason, an endpoint SHOULD attempt to include an\nACK frame if one has not been sent recently. Doing so helps with timely loss\ndetection at the peer.\n\nIn general, frequent feedback from a receiver improves loss and congestion\nresponse, but this has to be balanced against excessive load generated by a\nreceiver that sends an ACK frame in response to every ack-eliciting packet.  The\nguidance offered below seeks to strike this balance.\n\n### Sending ACK Frames {#sending-acknowledgments}\n\nEvery packet SHOULD be acknowledged at least once, and ack-eliciting packets\nMUST be acknowledged at least once within the maximum delay an endpoint\ncommunicated using the max_ack_delay transport parameter; see\n{{transport-parameter-definitions}}.  max_ack_delay declares an explicit\ncontract: an endpoint promises to never intentionally delay acknowledgments of\nan ack-eliciting packet by more than the indicated value. If it does, any excess\naccrues to the RTT estimate and could result in spurious or delayed\nretransmissions from the peer. A sender uses the receiver's max_ack_delay value\nin determining timeouts for timer-based retransmission, as detailed in {{Section\n6.2 of QUIC-RECOVERY}}.\n\nAn endpoint MUST acknowledge all ack-eliciting Initial and Handshake packets\nimmediately and all ack-eliciting 0-RTT and 1-RTT packets within its advertised\nmax_ack_delay, with the following exception. Prior to handshake confirmation, an\nendpoint might not have packet protection keys for decrypting Handshake, 0-RTT,\nor 1-RTT packets when they are received. It might therefore buffer them and\nacknowledge them when the requisite keys become available.\n\nSince packets containing only ACK frames are not congestion controlled, an\nendpoint MUST NOT send more than one such packet in response to receiving an\nack-eliciting packet.\n\nAn endpoint MUST NOT send a non-ack-eliciting packet in response to a\nnon-ack-eliciting packet, even if there are packet gaps that precede the\nreceived packet. This avoids an infinite feedback loop of acknowledgments,\nwhich could prevent the connection from ever becoming idle.  Non-ack-eliciting\npackets are eventually acknowledged when the endpoint sends an ACK frame in\nresponse to other events.\n\nAn endpoint that is only sending ACK frames will not receive acknowledgments\nfrom its peer unless those acknowledgments are included in packets with\nack-eliciting frames.  An endpoint SHOULD send an ACK frame with other frames\nwhen there are new ack-eliciting packets to acknowledge.  When only\nnon-ack-eliciting packets need to be acknowledged, an endpoint MAY\nchoose not to send an ACK frame with outgoing frames until an\nack-eliciting packet has been received.\n\nAn endpoint that is only sending non-ack-eliciting packets might choose to\noccasionally add an ack-eliciting frame to those packets to ensure that it\nreceives an acknowledgment; see {{ack-tracking}}.  In that case, an endpoint\nMUST NOT send an ack-eliciting frame in all packets that would otherwise be\nnon-ack-eliciting, to avoid an infinite feedback loop of acknowledgments.\n\nIn order to assist loss detection at the sender, an endpoint SHOULD generate\nand send an ACK frame without delay when it receives an ack-eliciting packet\neither:\n\n* when the received packet has a packet number less than another ack-eliciting\n  packet that has been received, or\n* when the packet has a packet number larger than the highest-numbered\n  ack-eliciting packet that has been received and there are missing packets\n  between that packet and this packet.\n\nSimilarly, packets marked with the ECN Congestion Experienced (CE) codepoint in\nthe IP header SHOULD be acknowledged immediately, to reduce the peer's response\ntime to congestion events.\n\nThe algorithms in {{QUIC-RECOVERY}} are expected to be resilient to receivers\nthat do not follow the guidance offered above. However, an implementation\nshould only deviate from these requirements after careful consideration of the\nperformance implications of a change, for connections made by the endpoint and\nfor other users of the network.\n\n\n### Acknowledgment Frequency\n\nA receiver determines how frequently to send acknowledgments in response to\nack-eliciting packets. This determination involves a trade-off.\n\nEndpoints rely on timely acknowledgment to detect loss; see {{Section 6 of\nQUIC-RECOVERY}}. Window-based congestion controllers, such as the one described\nin {{Section 7 of QUIC-RECOVERY}}, rely on acknowledgments to manage their\ncongestion window. In both cases, delaying acknowledgments can adversely affect\nperformance.\n\nOn the other hand, reducing the frequency of packets that carry only\nacknowledgments reduces packet transmission and processing cost at both\nendpoints. It can improve connection throughput on severely asymmetric links\nand reduce the volume of acknowledgment traffic using return path capacity;\nsee {{Section 3 of RFC3449}}.\n\nA receiver SHOULD send an ACK frame after receiving at least two ack-eliciting\npackets. This recommendation is general in nature and consistent with\nrecommendations for TCP endpoint behavior {{?RFC5681}}. Knowledge of network\nconditions, knowledge of the peer's congestion controller, or further research\nand experimentation might suggest alternative acknowledgment strategies with\nbetter performance characteristics.\n\nA receiver MAY process multiple available packets before determining whether to\nsend an ACK frame in response.\n\n\n### Managing ACK Ranges\n\nWhen an ACK frame is sent, one or more ranges of acknowledged packets are\nincluded.  Including acknowledgments for older packets reduces the chance of\nspurious retransmissions caused by losing previously sent ACK frames, at the\ncost of larger ACK frames.\n\nACK frames SHOULD always acknowledge the most recently received packets, and the\nmore out of order the packets are, the more important it is to send an updated\nACK frame quickly, to prevent the peer from declaring a packet as lost and\nspuriously retransmitting the frames it contains.  An ACK frame is expected\nto fit within a single QUIC packet.  If it does not, then older ranges\n(those with the smallest packet numbers) are omitted.\n\nA receiver limits the number of ACK Ranges ({{ack-ranges}}) it remembers and\nsends in ACK frames, both to limit the size of ACK frames and to avoid resource\nexhaustion. After receiving acknowledgments for an ACK frame, the receiver\nSHOULD stop tracking those acknowledged ACK Ranges.  Senders can expect\nacknowledgments for most packets, but QUIC does not guarantee receipt of an\nacknowledgment for every packet that the receiver processes.\n\nIt is possible that retaining many ACK Ranges could cause an ACK frame to become\ntoo large. A receiver can discard unacknowledged ACK Ranges to limit ACK frame\nsize, at the cost of increased retransmissions from the sender. This is\nnecessary if an ACK frame would be too large to fit in a packet.\nReceivers MAY also limit ACK frame size further to preserve space for other\nframes or to limit the capacity that acknowledgments consume.\n\nA receiver MUST retain an ACK Range unless it can ensure that it will not\nsubsequently accept packets with numbers in that range. Maintaining a minimum\npacket number that increases as ranges are discarded is one way to achieve this\nwith minimal state.\n\nReceivers can discard all ACK Ranges, but they MUST retain the largest packet\nnumber that has been successfully processed, as that is used to recover packet\nnumbers from subsequent packets; see {{packet-encoding}}.\n\nA receiver SHOULD include an ACK Range containing the largest received packet\nnumber in every ACK frame. The Largest Acknowledged field is used in ECN\nvalidation at a sender, and including a lower value than what was included in a\nprevious ACK frame could cause ECN to be unnecessarily disabled; see\n{{ecn-validation}}.\n\n{{ack-tracking}} describes an exemplary approach for determining what packets\nto acknowledge in each ACK frame.  Though the goal of this algorithm is to\ngenerate an acknowledgment for every packet that is processed, it is still\npossible for acknowledgments to be lost.\n\n### Limiting Ranges by Tracking ACK Frames {#ack-tracking}\n\nWhen a packet containing an ACK frame is sent, the Largest Acknowledged field in\nthat frame can be saved.  When a packet containing an ACK frame is acknowledged,\nthe receiver can stop acknowledging packets less than or equal to the Largest\nAcknowledged field in the sent ACK frame.\n\nA receiver that sends only non-ack-eliciting packets, such as ACK frames, might\nnot receive an acknowledgment for a long period of time.  This could cause the\nreceiver to maintain state for a large number of ACK frames for a long period of\ntime, and ACK frames it sends could be unnecessarily large.  In such a case, a\nreceiver could send a PING or other small ack-eliciting frame occasionally,\nsuch as once per round trip, to elicit an ACK from the peer.\n\nIn cases without ACK frame loss, this algorithm allows for a minimum of 1 RTT of\nreordering. In cases with ACK frame loss and reordering, this approach does not\nguarantee that every acknowledgment is seen by the sender before it is no longer\nincluded in the ACK frame. Packets could be received out of order, and all\nsubsequent ACK frames containing them could be lost. In this case, the loss\nrecovery algorithm could cause spurious retransmissions, but the sender will\ncontinue making forward progress.\n\n### Measuring and Reporting Host Delay {#host-delay}\n\nAn endpoint measures the delays intentionally introduced between the time the\npacket with the largest packet number is received and the time an acknowledgment\nis sent.  The endpoint encodes this acknowledgment delay in the ACK Delay field\nof an ACK frame; see {{frame-ack}}.  This allows the receiver of the ACK frame\nto adjust for any intentional delays, which is important for getting a better\nestimate of the path RTT when acknowledgments are delayed.\n\nA packet might be held in the OS kernel or elsewhere on the host before being\nprocessed.  An endpoint MUST NOT include delays that it does not control when\npopulating the ACK Delay field in an ACK frame. However, endpoints SHOULD\ninclude buffering delays caused by unavailability of decryption keys, since\nthese delays can be large and are likely to be non-repeating.\n\nWhen the measured acknowledgment delay is larger than its max_ack_delay, an\nendpoint SHOULD report the measured delay. This information is especially useful\nduring the handshake when delays might be large; see\n{{sending-acknowledgments}}.\n\n### ACK Frames and Packet Protection\n\nACK frames MUST only be carried in a packet that has the same packet number\nspace as the packet being acknowledged; see {{packet-protected}}.  For instance,\npackets that are protected with 1-RTT keys MUST be acknowledged in packets that\nare also protected with 1-RTT keys.\n\nPackets that a client sends with 0-RTT packet protection MUST be acknowledged by\nthe server in packets protected by 1-RTT keys.  This can mean that the client is\nunable to use these acknowledgments if the server cryptographic handshake\nmessages are delayed or lost.  Note that the same limitation applies to other\ndata sent by the server protected by the 1-RTT keys.\n\n\n### PADDING Frames Consume Congestion Window\n\nPackets containing PADDING frames are considered to be in flight for congestion\ncontrol purposes {{QUIC-RECOVERY}}. Packets containing only PADDING frames\ntherefore consume congestion window but do not generate acknowledgments that\nwill open the congestion window. To avoid a deadlock, a sender SHOULD ensure\nthat other frames are sent periodically in addition to PADDING frames to elicit\nacknowledgments from the receiver.\n\n\n## Retransmission of Information\n\nQUIC packets that are determined to be lost are not retransmitted whole. The\nsame applies to the frames that are contained within lost packets. Instead, the\ninformation that might be carried in frames is sent again in new frames as\nneeded.\n\nNew frames and packets are used to carry information that is determined to have\nbeen lost.  In general, information is sent again when a packet containing that\ninformation is determined to be lost, and sending ceases when a packet\ncontaining that information is acknowledged.\n\n* Data sent in CRYPTO frames is retransmitted according to the rules in\n  {{QUIC-RECOVERY}}, until all data has been acknowledged.  Data in CRYPTO\n  frames for Initial and Handshake packets is discarded when keys for the\n  corresponding packet number space are discarded.\n\n* Application data sent in STREAM frames is retransmitted in new STREAM frames\n  unless the endpoint has sent a RESET_STREAM for that stream.  Once an endpoint\n  sends a RESET_STREAM frame, no further STREAM frames are needed.\n\n* ACK frames carry the most recent set of acknowledgments and the\n  acknowledgment delay from the largest acknowledged packet, as described in\n  {{sending-acknowledgments}}. Delaying the transmission of packets containing\n  ACK frames or resending old ACK frames can cause the peer to generate an\n  inflated RTT sample or unnecessarily disable ECN.\n\n* Cancellation of stream transmission, as carried in a RESET_STREAM frame, is\n  sent until acknowledged or until all stream data is acknowledged by the peer\n  (that is, either the \"Reset Recvd\" or \"Data Recvd\" state is reached on the\n  sending part of the stream). The content of a RESET_STREAM frame MUST NOT\n  change when it is sent again.\n\n* Similarly, a request to cancel stream transmission, as encoded in a\n  STOP_SENDING frame, is sent until the receiving part of the stream enters\n  either a \"Data Recvd\" or \"Reset Recvd\" state; see\n  {{solicited-state-transitions}}.\n\n* Connection close signals, including packets that contain CONNECTION_CLOSE\n  frames, are not sent again when packet loss is detected. Resending these\n  signals is described in {{termination}}.\n\n* The current connection maximum data is sent in MAX_DATA frames. An updated\n  value is sent in a MAX_DATA frame if the packet containing the most recently\n  sent MAX_DATA frame is declared lost or when the endpoint decides to update\n  the limit.  Care is necessary to avoid sending this frame too often, as the\n  limit can increase frequently and cause an unnecessarily large number of\n  MAX_DATA frames to be sent; see {{fc-credit}}.\n\n* The current maximum stream data offset is sent in MAX_STREAM_DATA frames.\n  Like MAX_DATA, an updated value is sent when the packet containing the most\n  recent MAX_STREAM_DATA frame for a stream is lost or when the limit is\n  updated, with care taken to prevent the frame from being sent too often. An\n  endpoint SHOULD stop sending MAX_STREAM_DATA frames when the receiving part of\n  the stream enters a \"Size Known\" or \"Reset Recvd\" state.\n\n* The limit on streams of a given type is sent in MAX_STREAMS frames.  Like\n  MAX_DATA, an updated value is sent when a packet containing the most recent\n  MAX_STREAMS for a stream type frame is declared lost or when the limit is\n  updated, with care taken to prevent the frame from being sent too often.\n\n* Blocked signals are carried in DATA_BLOCKED, STREAM_DATA_BLOCKED, and\n  STREAMS_BLOCKED frames. DATA_BLOCKED frames have connection scope,\n  STREAM_DATA_BLOCKED frames have stream scope, and STREAMS_BLOCKED frames are\n  scoped to a specific stream type. A new frame is sent if a packet containing\n  the most recent frame for a scope is lost, but only while the endpoint is\n  blocked on the corresponding limit. These frames always include the limit that\n  is causing blocking at the time that they are transmitted.\n\n* A liveness or path validation check using PATH_CHALLENGE frames is sent\n  periodically until a matching PATH_RESPONSE frame is received or until there\n  is no remaining need for liveness or path validation checking. PATH_CHALLENGE\n  frames include a different payload each time they are sent.\n\n* Responses to path validation using PATH_RESPONSE frames are sent just once.\n  The peer is expected to send more PATH_CHALLENGE frames as necessary to evoke\n  additional PATH_RESPONSE frames.\n\n* New connection IDs are sent in NEW_CONNECTION_ID frames and retransmitted if\n  the packet containing them is lost.  Retransmissions of this frame carry the\n  same sequence number value.  Likewise, retired connection IDs are sent in\n  RETIRE_CONNECTION_ID frames and retransmitted if the packet containing them is\n  lost.\n\n* NEW_TOKEN frames are retransmitted if the packet containing them is lost.  No\n  special support is made for detecting reordered and duplicated NEW_TOKEN\n  frames other than a direct comparison of the frame contents.\n\n* PING and PADDING frames contain no information, so lost PING or PADDING frames\n  do not require repair.\n\n* The HANDSHAKE_DONE frame MUST be retransmitted until it is acknowledged.\n\nEndpoints SHOULD prioritize retransmission of data over sending new data, unless\npriorities specified by the application indicate otherwise; see\n{{stream-prioritization}}.\n\nEven though a sender is encouraged to assemble frames containing up-to-date\ninformation every time it sends a packet, it is not forbidden to retransmit\ncopies of frames from lost packets.  A sender that retransmits copies of frames\nneeds to handle decreases in available payload size due to changes in packet\nnumber length, connection ID length, and path MTU.  A receiver MUST accept\npackets containing an outdated frame, such as a MAX_DATA frame carrying a\nsmaller maximum data value than one found in an older packet.\n\nA sender SHOULD avoid retransmitting information from packets once they are\nacknowledged. This includes packets that are acknowledged after being declared\nlost, which can happen in the presence of network reordering. Doing so requires\nsenders to retain information about packets after they are declared lost. A\nsender can discard this information after a period of time elapses that\nadequately allows for reordering, such as a PTO ({{Section 6.2 of\nQUIC-RECOVERY}}), or based on other events, such as reaching a memory limit.\n\nUpon detecting losses, a sender MUST take appropriate congestion control action.\nThe details of loss detection and congestion control are described in\n{{QUIC-RECOVERY}}.\n\n\n## Explicit Congestion Notification {#ecn}\n\nQUIC endpoints can use ECN {{!RFC3168}} to detect and respond to network\ncongestion.  ECN allows an endpoint to set an ECN-Capable Transport (ECT)\ncodepoint in the ECN field of an IP packet. A network node can then indicate\ncongestion by setting the ECN-CE codepoint in the ECN field instead of dropping\nthe packet {{?RFC8087}}.  Endpoints react to reported congestion by reducing\ntheir sending rate in response, as described in {{QUIC-RECOVERY}}.\n\nTo enable ECN, a sending QUIC endpoint first determines whether a path supports\nECN marking and whether the peer reports the ECN values in received IP headers;\nsee {{ecn-validation}}.\n\n\n### Reporting ECN Counts\n\nThe use of ECN requires the receiving endpoint to read the ECN field from an IP\npacket, which is not possible on all platforms. If an endpoint does not\nimplement ECN support or does not have access to received ECN fields, it does\nnot report ECN counts for packets it receives.\n\nEven if an endpoint does not set an ECT field in packets it sends, the endpoint\nMUST provide feedback about ECN markings it receives, if these are accessible.\nFailing to report the ECN counts will cause the sender to disable the use of ECN\nfor this connection.\n\nOn receiving an IP packet with an ECT(0), ECT(1), or ECN-CE codepoint, an\nECN-enabled endpoint accesses the ECN field and increases the corresponding\nECT(0), ECT(1), or ECN-CE count. These ECN counts are included in subsequent ACK\nframes; see Sections {{<generating-acks}} and {{<frame-ack}}.\n\nEach packet number space maintains separate acknowledgment state and separate\nECN counts.  Coalesced QUIC packets (see {{packet-coalesce}}) share the same IP\nheader so the ECN counts are incremented once for each coalesced QUIC packet.\n\nFor example, if one each of an Initial, Handshake, and 1-RTT QUIC packet are\ncoalesced into a single UDP datagram, the ECN counts for all three packet number\nspaces will be incremented by one each, based on the ECN field of the single IP\nheader.\n\nECN counts are only incremented when QUIC packets from the received IP\npacket are processed. As such, duplicate QUIC packets are not processed and\ndo not increase ECN counts; see {{security-ecn}} for relevant security\nconcerns.\n\n\n### ECN Validation {#ecn-validation}\n\nIt is possible for faulty network devices to corrupt or erroneously drop\npackets that carry a non-zero ECN codepoint. To ensure connectivity in the\npresence of such devices, an endpoint validates the ECN counts for each network\npath and disables the use of ECN on that path if errors are detected.\n\nTo perform ECN validation for a new path:\n\n* The endpoint sets an ECT(0) codepoint in the IP header of early outgoing\n  packets sent on a new path to the peer {{!RFC8311}}.\n\n* The endpoint monitors whether all packets sent with an ECT codepoint are\n  eventually deemed lost ({{Section 6 of QUIC-RECOVERY}}), indicating\n  that ECN validation has failed.\n\nIf an endpoint has cause to expect that IP packets with an ECT codepoint might\nbe dropped by a faulty network element, the endpoint could set an ECT codepoint\nfor only the first ten outgoing packets on a path, or for a period of three\nPTOs (see {{Section 6.2 of QUIC-RECOVERY}}). If all packets marked with non-zero\nECN codepoints are subsequently lost, it can disable marking on the assumption\nthat the marking caused the loss.\n\nAn endpoint thus attempts to use ECN and validates this for each new connection,\nwhen switching to a server's preferred address, and on active connection\nmigration to a new path.  {{ecn-alg}} describes one possible algorithm.\n\nOther methods of probing paths for ECN support are possible, as are different\nmarking strategies. Implementations MAY use other methods defined in RFCs; see\n{{?RFC8311}}. Implementations that use the ECT(1) codepoint need to\nperform ECN validation using the reported ECT(1) counts.\n\n\n#### Receiving ACK Frames with ECN Counts {#ecn-ack}\n\nErroneous application of ECN-CE markings by the network can result in degraded\nconnection performance.  An endpoint that receives an ACK frame with ECN counts\ntherefore validates the counts before using them. It performs this validation by\ncomparing newly received counts against those from the last successfully\nprocessed ACK frame. Any increase in the ECN counts is validated based on the\nECN markings that were applied to packets that are newly acknowledged in the ACK\nframe.\n\nIf an ACK frame newly acknowledges a packet that the endpoint sent with either\nthe ECT(0) or ECT(1) codepoint set, ECN validation fails if the corresponding\nECN counts are not present in the ACK frame. This check detects a network\nelement that zeroes the ECN field or a peer that does not report ECN markings.\n\nECN validation also fails if the sum of the increase in ECT(0) and ECN-CE counts\nis less than the number of newly acknowledged packets that were originally sent\nwith an ECT(0) marking.  Similarly, ECN validation fails if the sum of the\nincreases to ECT(1) and ECN-CE counts is less than the number of newly\nacknowledged packets sent with an ECT(1) marking.  These checks can detect\nremarking of ECN-CE markings by the network.\n\nAn endpoint could miss acknowledgments for a packet when ACK frames are lost.\nIt is therefore possible for the total increase in ECT(0), ECT(1), and ECN-CE\ncounts to be greater than the number of packets that are newly acknowledged by\nan ACK frame. This is why ECN counts are permitted to be larger than the total\nnumber of packets that are acknowledged.\n\nValidating ECN counts from reordered ACK frames can result in failure. An\nendpoint MUST NOT fail ECN validation as a result of processing an ACK frame\nthat does not increase the largest acknowledged packet number.\n\nECN validation can fail if the received total count for either ECT(0) or ECT(1)\nexceeds the total number of packets sent with each corresponding ECT codepoint.\nIn particular, validation will fail when an endpoint receives a non-zero ECN\ncount corresponding to an ECT codepoint that it never applied.  This check\ndetects when packets are remarked to ECT(0) or ECT(1) in the network.\n\n\n#### ECN Validation Outcomes\n\nIf validation fails, then the endpoint MUST disable ECN. It stops setting the\nECT codepoint in IP packets that it sends, assuming that either the network path\nor the peer does not support ECN.\n\nEven if validation fails, an endpoint MAY revalidate ECN for the same path at\nany later time in the connection. An endpoint could continue to periodically\nattempt validation.\n\nUpon successful validation, an endpoint MAY continue to set an ECT codepoint in\nsubsequent packets it sends, with the expectation that the path is ECN capable.\nNetwork routing and path elements can change mid-connection; an endpoint MUST\ndisable ECN if validation later fails.\n\n\n# Datagram Size {#datagram-size}\n\nA UDP datagram can include one or more QUIC packets. The datagram size refers to\nthe total UDP payload size of a single UDP datagram carrying QUIC packets. The\ndatagram size includes one or more QUIC packet headers and protected payloads,\nbut not the UDP or IP headers.\n\nThe maximum datagram size is defined as the largest size of UDP payload that can\nbe sent across a network path using a single UDP datagram.  QUIC MUST NOT be\nused if the network path cannot support a maximum datagram size of at least 1200\nbytes.\n\nQUIC assumes a minimum IP packet size of at least 1280 bytes.  This is the IPv6\nminimum size {{?IPv6=RFC8200}} and is also supported by most modern IPv4\nnetworks.  Assuming the minimum IP header size of 40 bytes for IPv6 and 20 bytes\nfor IPv4 and a UDP header size of 8 bytes, this results in a maximum datagram\nsize of 1232 bytes for IPv6 and 1252 bytes for IPv4. Thus, modern IPv4\nand all IPv6 network paths are expected to be able to support QUIC.\n\n<aside markdown=\"block\">\nNote: This requirement to support a UDP payload of 1200 bytes limits the space\n  available for IPv6 extension headers to 32 bytes or IPv4 options to 52 bytes\n  if the path only supports the IPv6 minimum MTU of 1280 bytes.  This affects\n  Initial packets and path validation.\n</aside>\n\nAny maximum datagram size larger than 1200 bytes can be discovered using Path\nMaximum Transmission Unit Discovery (PMTUD) (see {{pmtud}}) or Datagram\nPacketization Layer PMTU Discovery (DPLPMTUD) (see {{dplpmtud}}).\n\nEnforcement of the max_udp_payload_size transport parameter\n({{transport-parameter-definitions}}) might act as an additional limit on the\nmaximum datagram size. A sender can avoid exceeding this limit, once the value\nis known.  However, prior to learning the value of the transport parameter,\nendpoints risk datagrams being lost if they send datagrams larger than the\nsmallest allowed maximum datagram size of 1200 bytes.\n\nUDP datagrams MUST NOT be fragmented at the IP layer.  In IPv4\n{{!IPv4=RFC0791}}, the Don't Fragment (DF) bit MUST be set if possible, to\nprevent fragmentation on the path.\n\nQUIC sometimes requires datagrams to be no smaller than a certain size; see\n{{validate-handshake}} as an example. However, the size of a datagram is not\nauthenticated. That is, if an endpoint receives a datagram of a certain size, it\ncannot know that the sender sent the datagram at the same size. Therefore, an\nendpoint MUST NOT close a connection when it receives a datagram that does not\nmeet size constraints; the endpoint MAY discard such datagrams.\n\n\n## Initial Datagram Size {#initial-size}\n\nA client MUST expand the payload of all UDP datagrams carrying Initial packets\nto at least the smallest allowed maximum datagram size of 1200 bytes by adding\nPADDING frames to the Initial packet or by coalescing the Initial packet; see\n{{packet-coalesce}}.  Initial packets can even be coalesced with invalid\npackets, which a receiver will discard.  Similarly, a server MUST expand the\npayload of all UDP datagrams carrying ack-eliciting Initial packets to at least\nthe smallest allowed maximum datagram size of 1200 bytes.\n\nSending UDP datagrams of this size ensures that the network path supports a\nreasonable Path Maximum Transmission Unit (PMTU), in both directions.\nAdditionally, a client that expands Initial packets helps reduce the amplitude\nof amplification attacks caused by server responses toward an unverified client\naddress; see {{address-validation}}.\n\nDatagrams containing Initial packets MAY exceed 1200 bytes if the sender\nbelieves that the network path and peer both support the size that it chooses.\n\nA server MUST discard an Initial packet that is carried in a UDP datagram with a\npayload that is smaller than the smallest allowed maximum datagram size of 1200\nbytes.  A server MAY also immediately close the connection by sending a\nCONNECTION_CLOSE frame with an error code of PROTOCOL_VIOLATION; see\n{{immediate-close-hs}}.\n\nThe server MUST also limit the number of bytes it sends before validating the\naddress of the client; see {{address-validation}}.\n\n\n## Path Maximum Transmission Unit\n\nThe PMTU is the maximum size of the entire IP packet, including the IP header,\nUDP header, and UDP payload. The UDP payload includes one or more QUIC packet\nheaders and protected payloads. The PMTU can depend on path characteristics and\ncan therefore change over time. The largest UDP payload an endpoint sends at any\ngiven time is referred to as the endpoint's maximum datagram size.\n\nAn endpoint SHOULD use DPLPMTUD ({{dplpmtud}}) or PMTUD ({{pmtud}}) to determine\nwhether the path to a destination will support a desired maximum datagram size\nwithout fragmentation.  In the absence of these mechanisms, QUIC endpoints\nSHOULD NOT send datagrams larger than the smallest allowed maximum datagram\nsize.\n\nBoth DPLPMTUD and PMTUD send datagrams that are larger than the current maximum\ndatagram size, referred to as PMTU probes.  All QUIC packets that are not sent\nin a PMTU probe SHOULD be sized to fit within the maximum datagram size to avoid\nthe datagram being fragmented or dropped {{?RFC8085}}.\n\nIf a QUIC endpoint determines that the PMTU between any pair of local and\nremote IP addresses cannot support the smallest allowed maximum datagram size\nof 1200 bytes, it MUST immediately cease sending QUIC packets, except for those\nin PMTU probes or those containing CONNECTION_CLOSE frames, on the affected\npath. An endpoint MAY terminate the connection if an alternative path cannot be\nfound.\n\nEach pair of local and remote addresses could have a different PMTU.  QUIC\nimplementations that implement any kind of PMTU discovery therefore SHOULD\nmaintain a maximum datagram size for each combination of local and remote IP\naddresses.\n\nA QUIC implementation MAY be more conservative in computing the maximum datagram\nsize to allow for unknown tunnel overheads or IP header options/extensions.\n\n\n### Handling of ICMP Messages by PMTUD {#pmtud}\n\nPMTUD {{!RFC1191}} {{!RFC8201}} relies on reception of ICMP messages (that is,\nIPv6 Packet Too Big (PTB) messages) that indicate when an IP packet is dropped\nbecause it is larger than the local router MTU. DPLPMTUD can also optionally use\nthese messages.  This use of ICMP messages is potentially vulnerable to attacks\nby entities that cannot observe packets but might successfully guess the\naddresses used on the path. These attacks could reduce the PMTU to a\nbandwidth-inefficient value.\n\nAn endpoint MUST ignore an ICMP message that claims the PMTU has decreased below\nQUIC's smallest allowed maximum datagram size.\n\nThe requirements for generating ICMP {{?RFC1812}} {{?RFC4443}} state that the\nquoted packet should contain as much of the original packet as possible without\nexceeding the minimum MTU for the IP version. The size of the quoted packet can\nactually be smaller, or the information unintelligible, as described in\n{{Section 1.1 of DPLPMTUD}}.\n\nQUIC endpoints using PMTUD SHOULD validate ICMP messages to protect from packet\ninjection as specified in {{!RFC8201}} and {{Section 5.2 of RFC8085}}.  This\nvalidation SHOULD use the quoted packet supplied in the payload of an ICMP\nmessage to associate the message with a corresponding transport connection (see\n{{Section 4.6.1 of DPLPMTUD}}).  ICMP message validation MUST include matching\nIP addresses and UDP ports {{!RFC8085}} and, when possible, connection IDs to\nan active QUIC session.  The endpoint SHOULD ignore all ICMP messages that fail\nvalidation.\n\nAn endpoint MUST NOT increase the PMTU based on ICMP messages; see Item 6 in\n{{Section 3 of DPLPMTUD}}.  Any reduction in QUIC's maximum datagram size in\nresponse to ICMP messages MAY be provisional until QUIC's loss detection\nalgorithm determines that the quoted packet has actually been lost.\n\n\n## Datagram Packetization Layer PMTU Discovery {#dplpmtud}\n\nDPLPMTUD {{!DPLPMTUD=RFC8899}} relies on tracking loss or acknowledgment of QUIC\npackets that are carried in PMTU probes.  PMTU probes for DPLPMTUD that use the\nPADDING frame implement \"Probing using padding data\", as defined in {{Section\n4.1 of DPLPMTUD}}.\n\nEndpoints SHOULD set the initial value of BASE_PLPMTU ({{Section 5.1 of\nDPLPMTUD}}) to be consistent with QUIC's smallest allowed maximum datagram\nsize. The MIN_PLPMTU is the same as the BASE_PLPMTU.\n\nQUIC endpoints implementing DPLPMTUD maintain a DPLPMTUD Maximum Packet Size\n(MPS) ({{Section 4.4 of DPLPMTUD}}) for each combination of local and remote IP\naddresses.  This corresponds to the maximum datagram size.\n\n\n### DPLPMTUD and Initial Connectivity\n\nFrom the perspective of DPLPMTUD, QUIC is an acknowledged Packetization Layer\n(PL). A QUIC sender can therefore enter the DPLPMTUD BASE state ({{Section 5.2\nof DPLPMTUD}}) when the QUIC connection handshake has been completed.\n\n\n### Validating the Network Path with DPLPMTUD\n\nQUIC is an acknowledged PL; therefore, a QUIC sender does not implement a\nDPLPMTUD CONFIRMATION_TIMER while in the SEARCH_COMPLETE state; see {{Section\n5.2 of DPLPMTUD}}.\n\n\n### Handling of ICMP Messages by DPLPMTUD\n\nAn endpoint using DPLPMTUD requires the validation of any received ICMP PTB\nmessage before using the PTB information, as defined in {{Section 4.6 of\nDPLPMTUD}}.  In addition to UDP port validation, QUIC validates an ICMP message\nby using other PL information (e.g., validation of connection IDs in the quoted\npacket of any received ICMP message).\n\nThe considerations for processing ICMP messages described in {{pmtud}} also\napply if these messages are used by DPLPMTUD.\n\n\n## Sending QUIC PMTU Probes\n\nPMTU probes are ack-eliciting packets.\n\nEndpoints could limit the content of PMTU probes to PING and PADDING frames,\nsince packets that are larger than the current maximum datagram size are more\nlikely to be dropped by the network.  Loss of a QUIC packet that is carried in a\nPMTU probe is therefore not a reliable indication of congestion and SHOULD NOT\ntrigger a congestion control reaction; see Item 7 in {{Section 3 of DPLPMTUD}}.\nHowever, PMTU probes consume congestion window, which could delay subsequent\ntransmission by an application.\n\n\n### PMTU Probes Containing Source Connection ID {#pmtu-probes-src-cid}\n\nEndpoints that rely on the Destination Connection ID field for routing incoming\nQUIC packets are likely to require that the connection ID be included in PMTU\nprobes to route any resulting ICMP messages ({{pmtud}}) back to the correct\nendpoint.  However, only long header packets ({{long-header}}) contain the\nSource Connection ID field, and long header packets are not decrypted or\nacknowledged by the peer once the handshake is complete.\n\nOne way to construct a PMTU probe is to coalesce (see {{packet-coalesce}}) a\npacket with a long header, such as a Handshake or 0-RTT packet\n({{long-header}}), with a short header packet in a single UDP datagram.  If the\nresulting PMTU probe reaches the endpoint, the packet with the long header will\nbe ignored, but the short header packet will be acknowledged.  If the PMTU probe\ncauses an ICMP message to be sent, the first part of the probe will be quoted in\nthat message.  If the Source Connection ID field is within the quoted portion of\nthe probe, that could be used for routing or validation of the ICMP message.\n\n<aside markdown=\"block\">\nNote: The purpose of using a packet with a long header is only to ensure that\n  the quoted packet contained in the ICMP message contains a Source Connection\n  ID field.  This packet does not need to be a valid packet, and it can be sent\n  even if there is no current use for packets of that type.\n</aside>\n\n\n# Versions {#versions}\n\nQUIC versions are identified using a 32-bit unsigned number.\n\nThe version 0x00000000 is reserved to represent version negotiation.  This\nversion of the specification is identified by the number 0x00000001.\n\nOther versions of QUIC might have different properties from this version.  The\nproperties of QUIC that are guaranteed to be consistent across all versions of\nthe protocol are described in {{QUIC-INVARIANTS}}.\n\nVersion 0x00000001 of QUIC uses TLS as a cryptographic handshake protocol, as\ndescribed in {{QUIC-TLS}}.\n\nVersions with the most significant 16 bits of the version number cleared are\nreserved for use in future IETF consensus documents.\n\nVersions that follow the pattern 0x?a?a?a?a are reserved for use in forcing\nversion negotiation to be exercised -- that is, any version number where the low\nfour bits of all bytes is 1010 (in binary).  A client or server MAY advertise\nsupport for any of these reserved versions.\n\nReserved version numbers will never represent a real protocol; a client MAY use\none of these version numbers with the expectation that the server will initiate\nversion negotiation; a server MAY advertise support for one of these versions\nand can expect that clients ignore the value.\n\n\n# Variable-Length Integer Encoding {#integer-encoding}\n\nQUIC packets and frames commonly use a variable-length encoding for non-negative\ninteger values.  This encoding ensures that smaller integer values need fewer\nbytes to encode.\n\nThe QUIC variable-length integer encoding reserves the two most significant bits\nof the first byte to encode the base-2 logarithm of the integer encoding length\nin bytes.  The integer value is encoded on the remaining bits, in network byte\norder.\n\nThis means that integers are encoded on 1, 2, 4, or 8 bytes and can encode 6-,\n14-, 30-, or 62-bit values, respectively.  {{integer-summary}} summarizes the\nencoding properties.\n\n| 2MSB | Length | Usable Bits | Range                 |\n|:-----|:-------|:------------|:----------------------|\n| 00   | 1      | 6           | 0-63                  |\n| 01   | 2      | 14          | 0-16383               |\n| 10   | 4      | 30          | 0-1073741823          |\n| 11   | 8      | 62          | 0-4611686018427387903 |\n{: #integer-summary title=\"Summary of Integer Encodings\"}\n\nAn example of a decoding algorithm and sample encodings are shown in\n{{sample-varint}}.\n\nValues do not need to be encoded on the minimum number of bytes necessary, with\nthe sole exception of the Frame Type field; see {{frames}}.\n\nVersions ({{versions}}), packet numbers sent in the header\n({{packet-encoding}}), and the length of connection IDs in long header packets\n({{long-header}}) are described using integers but do not use this encoding.\n\n\n# Packet Formats {#packet-formats}\n\nAll numeric values are encoded in network byte order (that is, big endian), and\nall field sizes are in bits.  Hexadecimal notation is used for describing the\nvalue of fields.\n\n\n## Packet Number Encoding and Decoding {#packet-encoding}\n\nPacket numbers are integers in the range 0 to 2<sup>62</sup>-1\n({{packet-numbers}}).  When present in long or short packet headers, they are\nencoded in 1 to 4 bytes.  The number of bits required to represent the packet\nnumber is reduced by including only the least significant bits of the packet\nnumber.\n\nThe encoded packet number is protected as described in\n{{Section 5.4 of QUIC-TLS}}.\n\nPrior to receiving an acknowledgment for a packet number space, the full packet\nnumber MUST be included; it is not to be truncated, as described below.\n\nAfter an acknowledgment is received for a packet number space, the sender MUST\nuse a packet number size able to represent more than twice as large a range as\nthe difference between the largest acknowledged packet number and the packet\nnumber being sent.  A peer receiving the packet will then correctly decode the\npacket number, unless the packet is delayed in transit such that it arrives\nafter many higher-numbered packets have been received.  An endpoint SHOULD use a\nlarge enough packet number encoding to allow the packet number to be recovered\neven if the packet arrives after packets that are sent afterwards.\n\nAs a result, the size of the packet number encoding is at least one bit more\nthan the base-2 logarithm of the number of contiguous unacknowledged packet\nnumbers, including the new packet.  Pseudocode and an example for packet number\nencoding can be found in {{sample-packet-number-encoding}}.\n\nAt a receiver, protection of the packet number is removed prior to recovering\nthe full packet number. The full packet number is then reconstructed based on\nthe number of significant bits present, the value of those bits, and the largest\npacket number received in a successfully authenticated packet. Recovering the\nfull packet number is necessary to successfully complete the removal of packet\nprotection.\n\nOnce header protection is removed, the packet number is decoded by finding the\npacket number value that is closest to the next expected packet.  The next\nexpected packet is the highest received packet number plus one.  Pseudocode and\nan example for packet number decoding can be found in\n{{sample-packet-number-decoding}}.\n\n\n## Long Header Packets {#long-header}\n\n~~~~~\nLong Header Packet {\n  Header Form (1) = 1,\n  Fixed Bit (1) = 1,\n  Long Packet Type (2),\n  Type-Specific Bits (4),\n  Version (32),\n  Destination Connection ID Length (8),\n  Destination Connection ID (0..160),\n  Source Connection ID Length (8),\n  Source Connection ID (0..160),\n  Type-Specific Payload (..),\n}\n~~~~~\n{: #fig-long-header title=\"Long Header Packet Format\"}\n\nLong headers are used for packets that are sent prior to the establishment\nof 1-RTT keys. Once 1-RTT keys are available,\na sender switches to sending packets using the short header\n({{short-header}}).  The long form allows for special packets -- such as the\nVersion Negotiation packet -- to be represented in this uniform fixed-length\npacket format. Packets that use the long header contain the following fields:\n\nHeader Form:\n\n: The most significant bit (0x80) of byte 0 (the first byte) is set to 1 for\n  long headers.\n\nFixed Bit:\n\n: The next bit (0x40) of byte 0 is set to 1, unless the packet is a Version\n  Negotiation packet.  Packets containing a zero value for this bit are not\n  valid packets in this version and MUST be discarded.  A value of 1 for this\n  bit allows QUIC to coexist with other protocols; see {{?RFC7983}}.\n\nLong Packet Type:\n\n: The next two bits (those with a mask of 0x30) of byte 0 contain a packet type.\n  Packet types are listed in {{long-packet-types}}.\n\nType-Specific Bits:\n\n: The semantics of the lower four bits (those with a mask of 0x0f) of byte 0 are\n  determined by the packet type.\n\nVersion:\n\n: The QUIC Version is a 32-bit field that follows the first byte.  This field\n  indicates the version of QUIC that is in use and determines how the rest of\n  the protocol fields are interpreted.\n\nDestination Connection ID Length:\n\n: The byte following the version contains the length in bytes of the Destination\n  Connection ID field that follows it.  This length is encoded as an 8-bit\n  unsigned integer.  In QUIC version 1, this value MUST NOT exceed 20 bytes.\n  Endpoints that receive a version 1 long header with a value larger than 20\n  MUST drop the packet.  In order to properly form a Version Negotiation packet,\n  servers SHOULD be able to read longer connection IDs from other QUIC versions.\n\nDestination Connection ID:\n\n: The Destination Connection ID field follows the Destination Connection ID\n  Length field, which indicates the length of this field.\n  {{negotiating-connection-ids}} describes the use of this field in more detail.\n\nSource Connection ID Length:\n\n: The byte following the Destination Connection ID contains the length in bytes\n  of the Source Connection ID field that follows it.  This length is encoded as\n  an 8-bit unsigned integer.  In QUIC version 1, this value MUST NOT exceed 20\n  bytes.  Endpoints that receive a version 1 long header with a value larger\n  than 20 MUST drop the packet.  In order to properly form a Version Negotiation\n  packet, servers SHOULD be able to read longer connection IDs from other QUIC\n  versions.\n\nSource Connection ID:\n\n: The Source Connection ID field follows the Source Connection ID Length field,\n  which indicates the length of this field. {{negotiating-connection-ids}}\n  describes the use of this field in more detail.\n\nType-Specific Payload:\n\n: The remainder of the packet, if any, is type specific.\n\nIn this version of QUIC, the following packet types with the long header are\ndefined:\n\n| Type  | Name                          | Section                     |\n|------:|:------------------------------|:----------------------------|\n|  0x00 | Initial                       | {{packet-initial}}          |\n|  0x01 | 0-RTT                         | {{packet-0rtt}}             |\n|  0x02 | Handshake                     | {{packet-handshake}}        |\n|  0x03 | Retry                         | {{packet-retry}}            |\n{: #long-packet-types title=\"Long Header Packet Types\"}\n\nThe header form bit, Destination and Source Connection ID lengths, Destination\nand Source Connection ID fields, and Version fields of a long header packet are\nversion independent. The other fields in the first byte are version specific.\nSee {{QUIC-INVARIANTS}} for details on how packets from different versions of\nQUIC are interpreted.\n\nThe interpretation of the fields and the payload are specific to a version and\npacket type.  While type-specific semantics for this version are described in\nthe following sections, several long header packets in this version of QUIC\ncontain these additional fields:\n\nReserved Bits:\n\n: Two bits (those with a mask of 0x0c) of byte 0 are reserved across multiple\n  packet types.  These bits are protected using header protection; see {{Section\n  5.4 of QUIC-TLS}}. The value included prior to protection MUST be set to 0.\n  An endpoint MUST treat receipt of a packet that has a non-zero value for these\n  bits after removing both packet and header protection as a connection error\n  of type PROTOCOL_VIOLATION. Discarding such a packet after only removing\n  header protection can expose the endpoint to attacks; see\n  {{Section 9.5 of QUIC-TLS}}.\n\nPacket Number Length:\n\n: In packet types that contain a Packet Number field, the least significant two\n  bits (those with a mask of 0x03) of byte 0 contain the length of the Packet\n  Number field, encoded as an unsigned two-bit integer that is one less than the\n  length of the Packet Number field in bytes.  That is, the length of the Packet\n  Number field is the value of this field plus one.  These bits are protected\n  using header protection; see {{Section 5.4 of QUIC-TLS}}.\n\nLength:\n\n: This is the length of the remainder of the packet (that is, the Packet Number\n  and Payload fields) in bytes, encoded as a variable-length integer\n  ({{integer-encoding}}).\n\nPacket Number:\n\n: This field is 1 to 4 bytes long. The packet number is protected using header\n  protection; see {{Section 5.4 of QUIC-TLS}}.  The length of the Packet Number\n  field is encoded in the Packet Number Length bits of byte 0; see above.\n\nPacket Payload:\n\n: This is the payload of the packet -- containing a sequence of frames -- that\n  is protected using packet protection.\n\n\n### Version Negotiation Packet {#packet-version}\n\nA Version Negotiation packet is inherently not version specific. Upon receipt by\na client, it will be identified as a Version Negotiation packet based on the\nVersion field having a value of 0.\n\nThe Version Negotiation packet is a response to a client packet that contains a\nversion that is not supported by the server.  It is only sent by servers.\n\nThe layout of a Version Negotiation packet is:\n\n~~~\nVersion Negotiation Packet {\n  Header Form (1) = 1,\n  Unused (7),\n  Version (32) = 0,\n  Destination Connection ID Length (8),\n  Destination Connection ID (0..2040),\n  Source Connection ID Length (8),\n  Source Connection ID (0..2040),\n  Supported Version (32) ...,\n}\n~~~\n{: #version-negotiation-format title=\"Version Negotiation Packet\"}\n\nThe value in the Unused field is set to an arbitrary value by the server.\nClients MUST ignore the value of this field.  Where QUIC might be multiplexed\nwith other protocols (see {{?RFC7983}}), servers SHOULD set the most significant\nbit of this field (0x40) to 1 so that Version Negotiation packets appear to have\nthe Fixed Bit field.  Note that other versions of QUIC might not make a similar\nrecommendation.\n\nThe Version field of a Version Negotiation packet MUST be set to 0x00000000.\n\nThe server MUST include the value from the Source Connection ID field of the\npacket it receives in the Destination Connection ID field.  The value for Source\nConnection ID MUST be copied from the Destination Connection ID of the received\npacket, which is initially randomly selected by a client.  Echoing both\nconnection IDs gives clients some assurance that the server received the packet\nand that the Version Negotiation packet was not generated by an entity that\ndid not observe the Initial packet.\n\nFuture versions of QUIC could have different requirements for the lengths of\nconnection IDs. In particular, connection IDs might have a smaller minimum\nlength or a greater maximum length.  Version-specific rules for the connection\nID therefore MUST NOT influence a decision about whether to send a Version\nNegotiation packet.\n\nThe remainder of the Version Negotiation packet is a list of 32-bit versions\nthat the server supports.\n\nA Version Negotiation packet is not acknowledged.  It is only sent in response\nto a packet that indicates an unsupported version; see {{server-pkt-handling}}.\n\nThe Version Negotiation packet does not include the Packet Number and Length\nfields present in other packets that use the long header form.  Consequently,\na Version Negotiation packet consumes an entire UDP datagram.\n\nA server MUST NOT send more than one Version Negotiation packet in response to a\nsingle UDP datagram.\n\nSee {{version-negotiation}} for a description of the version negotiation\nprocess.\n\n### Initial Packet {#packet-initial}\n\nAn Initial packet uses long headers with a type value of 0x00.  It carries the\nfirst CRYPTO frames sent by the client and server to perform key exchange, and\nit carries ACK frames in either direction.\n\n~~~\nInitial Packet {\n  Header Form (1) = 1,\n  Fixed Bit (1) = 1,\n  Long Packet Type (2) = 0,\n  Reserved Bits (2),\n  Packet Number Length (2),\n  Version (32),\n  Destination Connection ID Length (8),\n  Destination Connection ID (0..160),\n  Source Connection ID Length (8),\n  Source Connection ID (0..160),\n  Token Length (i),\n  Token (..),\n  Length (i),\n  Packet Number (8..32),\n  Packet Payload (8..),\n}\n~~~\n{: #initial-format title=\"Initial Packet\"}\n\nThe Initial packet contains a long header as well as the Length and Packet\nNumber fields; see {{long-header}}.  The first byte contains the Reserved and\nPacket Number Length bits; see also {{long-header}}.  Between the Source\nConnection ID and Length fields, there are two additional fields specific to\nthe Initial packet.\n\nToken Length:\n\n: A variable-length integer specifying the length of the Token field, in bytes.\n  This value is 0 if no token is present.  Initial packets sent by the server\n  MUST set the Token Length field to 0; clients that receive an Initial\n  packet with a non-zero Token Length field MUST either discard the packet or\n  generate a connection error of type PROTOCOL_VIOLATION.\n\nToken:\n\n: The value of the token that was previously provided in a Retry packet or\n  NEW_TOKEN frame; see {{validate-handshake}}.\n\nIn order to prevent tampering by version-unaware middleboxes, Initial packets\nare protected with connection- and version-specific keys (Initial keys) as\ndescribed in {{QUIC-TLS}}.  This protection does not provide confidentiality or\nintegrity against attackers that can observe packets, but it does prevent\nattackers that cannot observe packets from spoofing Initial packets.\n\nThe client and server use the Initial packet type for any packet that contains\nan initial cryptographic handshake message. This includes all cases where a new\npacket containing the initial cryptographic message needs to be created, such as\nthe packets sent after receiving a Retry packet; see {{packet-retry}}.\n\nA server sends its first Initial packet in response to a client Initial.  A\nserver MAY send multiple Initial packets.  The cryptographic key exchange could\nrequire multiple round trips or retransmissions of this data.\n\nThe payload of an Initial packet includes a CRYPTO frame (or frames) containing\na cryptographic handshake message, ACK frames, or both.  PING, PADDING, and\nCONNECTION_CLOSE frames of type 0x1c are also permitted.  An endpoint that\nreceives an Initial packet containing other frames can either discard the\npacket as spurious or treat it as a connection error.\n\nThe first packet sent by a client always includes a CRYPTO frame that contains\nthe start or all of the first cryptographic handshake message.  The first\nCRYPTO frame sent always begins at an offset of 0; see {{handshake}}.\n\nNote that if the server sends a TLS HelloRetryRequest (see {{Section 4.7 of\nQUIC-TLS}}), the client will send another series of Initial packets. These\nInitial packets will continue the cryptographic handshake and will contain\nCRYPTO frames starting at an offset matching the size of the CRYPTO frames sent\nin the first flight of Initial packets.\n\n\n#### Abandoning Initial Packets {#discard-initial}\n\nA client stops both sending and processing Initial packets when it sends its\nfirst Handshake packet.  A server stops sending and processing Initial packets\nwhen it receives its first Handshake packet.  Though packets might still be in\nflight or awaiting acknowledgment, no further Initial packets need to be\nexchanged beyond this point.  Initial packet protection keys are discarded (see\n{{Section 4.9.1 of QUIC-TLS}}) along with any loss recovery and congestion\ncontrol state; see {{Section 6.4 of QUIC-RECOVERY}}.\n\nAny data in CRYPTO frames is discarded -- and no longer retransmitted -- when\nInitial keys are discarded.\n\n### 0-RTT {#packet-0rtt}\n\nA 0-RTT packet uses long headers with a type value of 0x01, followed by the\nLength and Packet Number fields; see {{long-header}}.  The first byte contains\nthe Reserved and Packet Number Length bits; see {{long-header}}.  A 0-RTT packet\nis used to carry \"early\" data from the client to the server as part of the\nfirst flight, prior to handshake completion.  As part of the TLS handshake, the\nserver can accept or reject this early data.\n\nSee {{Section 2.3 of TLS13}} for a discussion of 0-RTT data and its\nlimitations.\n\n~~~\n0-RTT Packet {\n  Header Form (1) = 1,\n  Fixed Bit (1) = 1,\n  Long Packet Type (2) = 1,\n  Reserved Bits (2),\n  Packet Number Length (2),\n  Version (32),\n  Destination Connection ID Length (8),\n  Destination Connection ID (0..160),\n  Source Connection ID Length (8),\n  Source Connection ID (0..160),\n  Length (i),\n  Packet Number (8..32),\n  Packet Payload (8..),\n}\n~~~\n{: #0rtt-format title=\"0-RTT Packet\"}\n\nPacket numbers for 0-RTT protected packets use the same space as 1-RTT protected\npackets.\n\nAfter a client receives a Retry packet, 0-RTT packets are likely to have been\nlost or discarded by the server.  A client SHOULD attempt to resend data in\n0-RTT packets after it sends a new Initial packet.  New packet numbers MUST be\nused for any new packets that are sent; as described in {{retry-continue}},\nreusing packet numbers could compromise packet protection.\n\nA client only receives acknowledgments for its 0-RTT packets once the handshake\nis complete, as defined in {{Section 4.1.1 of QUIC-TLS}}.\n\nA client MUST NOT send 0-RTT packets once it starts processing 1-RTT packets\nfrom the server.  This means that 0-RTT packets cannot contain any response to\nframes from 1-RTT packets.  For instance, a client cannot send an ACK frame in a\n0-RTT packet, because that can only acknowledge a 1-RTT packet.  An\nacknowledgment for a 1-RTT packet MUST be carried in a 1-RTT packet.\n\nA server SHOULD treat a violation of remembered limits ({{zerortt-parameters}})\nas a connection error of an appropriate type (for instance, a FLOW_CONTROL_ERROR\nfor exceeding stream data limits).\n\n\n### Handshake Packet {#packet-handshake}\n\nA Handshake packet uses long headers with a type value of 0x02, followed by the\nLength and Packet Number fields; see {{long-header}}.  The first byte contains\nthe Reserved and Packet Number Length bits; see {{long-header}}.  It is used\nto carry cryptographic handshake messages and acknowledgments from the server\nand client.\n\n~~~\nHandshake Packet {\n  Header Form (1) = 1,\n  Fixed Bit (1) = 1,\n  Long Packet Type (2) = 2,\n  Reserved Bits (2),\n  Packet Number Length (2),\n  Version (32),\n  Destination Connection ID Length (8),\n  Destination Connection ID (0..160),\n  Source Connection ID Length (8),\n  Source Connection ID (0..160),\n  Length (i),\n  Packet Number (8..32),\n  Packet Payload (8..),\n}\n~~~\n{: #handshake-format title=\"Handshake Protected Packet\"}\n\nOnce a client has received a Handshake packet from a server, it uses Handshake\npackets to send subsequent cryptographic handshake messages and acknowledgments\nto the server.\n\nThe Destination Connection ID field in a Handshake packet contains a connection\nID that is chosen by the recipient of the packet; the Source Connection ID\nincludes the connection ID that the sender of the packet wishes to use; see\n{{negotiating-connection-ids}}.\n\nHandshake packets have their own packet number space, and thus the first\nHandshake packet sent by a server contains a packet number of 0.\n\nThe payload of this packet contains CRYPTO frames and could contain PING,\nPADDING, or ACK frames. Handshake packets MAY contain CONNECTION_CLOSE frames\nof type 0x1c. Endpoints MUST treat receipt of Handshake packets with other\nframes as a connection error of type PROTOCOL_VIOLATION.\n\nLike Initial packets (see {{discard-initial}}), data in CRYPTO frames for\nHandshake packets is discarded -- and no longer retransmitted -- when Handshake\nprotection keys are discarded.\n\n### Retry Packet {#packet-retry}\n\nAs shown in {{retry-format}}, a Retry packet uses a long packet header with a\ntype value of 0x03. It carries an address validation token created by the\nserver. It is used by a server that wishes to perform a retry; see\n{{validate-handshake}}.\n\n~~~\nRetry Packet {\n  Header Form (1) = 1,\n  Fixed Bit (1) = 1,\n  Long Packet Type (2) = 3,\n  Unused (4),\n  Version (32),\n  Destination Connection ID Length (8),\n  Destination Connection ID (0..160),\n  Source Connection ID Length (8),\n  Source Connection ID (0..160),\n  Retry Token (..),\n  Retry Integrity Tag (128),\n}\n~~~\n{: #retry-format title=\"Retry Packet\"}\n\nA Retry packet does not contain any protected\nfields.  The value in the Unused field is set to an arbitrary value by the\nserver; a client MUST ignore these bits.  In addition to the fields from the\nlong header, it contains these additional fields:\n\nRetry Token:\n\n: An opaque token that the server can use to validate the client's address.\n\nRetry Integrity Tag:\n\n: Defined in Section [\"Retry Packet Integrity\"](#QUIC-TLS){: section=\"5.8\"\n  sectionFormat=\"bare\"} of {{QUIC-TLS}}.\n\n\n#### Sending a Retry Packet\n\nThe server populates the Destination Connection ID with the connection ID that\nthe client included in the Source Connection ID of the Initial packet.\n\nThe server includes a connection ID of its choice in the Source Connection ID\nfield.  This value MUST NOT be equal to the Destination Connection ID field of\nthe packet sent by the client.  A client MUST discard a Retry packet that\ncontains a Source Connection ID field that is identical to the Destination\nConnection ID field of its Initial packet.  The client MUST use the value from\nthe Source Connection ID field of the Retry packet in the Destination Connection\nID field of subsequent packets that it sends.\n\nA server MAY send Retry packets in response to Initial and 0-RTT packets.  A\nserver can either discard or buffer 0-RTT packets that it receives.  A server\ncan send multiple Retry packets as it receives Initial or 0-RTT packets.  A\nserver MUST NOT send more than one Retry packet in response to a single UDP\ndatagram.\n\n\n#### Handling a Retry Packet\n\nA client MUST accept and process at most one Retry packet for each connection\nattempt.  After the client has received and processed an Initial or Retry packet\nfrom the server, it MUST discard any subsequent Retry packets that it receives.\n\nClients MUST discard Retry packets that have a Retry Integrity Tag that cannot\nbe validated; see {{Section 5.8 of QUIC-TLS}}. This diminishes an attacker's\nability to inject a Retry packet and protects against accidental corruption of\nRetry packets.  A client MUST discard a Retry packet with a zero-length Retry\nToken field.\n\nThe client responds to a Retry packet with an Initial packet that includes the\nprovided Retry token to continue connection establishment.\n\nA client sets the Destination Connection ID field of this Initial packet to the\nvalue from the Source Connection ID field in the Retry packet. Changing the\nDestination Connection ID field also results in a change to the keys used to\nprotect the Initial packet. It also sets the Token field to the token provided\nin the Retry packet. The client MUST NOT change the Source Connection ID because\nthe server could include the connection ID as part of its token validation\nlogic; see {{token-integrity}}.\n\nA Retry packet does not include a packet number and cannot be explicitly\nacknowledged by a client.\n\n\n#### Continuing a Handshake after Retry {#retry-continue}\n\nSubsequent Initial packets from the client include the connection ID and token\nvalues from the Retry packet. The client copies the Source Connection ID field\nfrom the Retry packet to the Destination Connection ID field and uses this\nvalue until an Initial packet with an updated value is received; see\n{{negotiating-connection-ids}}. The value of the Token field is copied to all\nsubsequent Initial packets; see {{validate-retry}}.\n\nOther than updating the Destination Connection ID and Token fields, the Initial\npacket sent by the client is subject to the same restrictions as the first\nInitial packet.  A client MUST use the same cryptographic handshake message it\nincluded in this packet.  A server MAY treat a packet that contains a different\ncryptographic handshake message as a connection error or discard it.  Note that\nincluding a Token field reduces the available space for the cryptographic\nhandshake message, which might result in the client needing to send multiple\nInitial packets.\n\nA client MAY attempt 0-RTT after receiving a Retry packet by sending 0-RTT\npackets to the connection ID provided by the server.\n\nA client MUST NOT reset the packet number for any packet number space after\nprocessing a Retry packet. In particular, 0-RTT packets contain confidential\ninformation that will most likely be retransmitted on receiving a Retry packet.\nThe keys used to protect these new 0-RTT packets will not change as a result of\nresponding to a Retry packet. However, the data sent in these packets could be\ndifferent than what was sent earlier. Sending these new packets with the same\npacket number is likely to compromise the packet protection for those packets\nbecause the same key and nonce could be used to protect different content.\nA server MAY abort the connection if it detects that the client reset the\npacket number.\n\nThe connection IDs used in Initial and Retry packets exchanged between client\nand server are copied to the transport parameters and validated as described\nin {{cid-auth}}.\n\n\n## Short Header Packets {#short-header}\n\nThis version of QUIC defines a single packet type that uses the short packet\nheader.\n\n### 1-RTT Packet {#packet-1rtt}\n\nA 1-RTT packet uses a short packet header. It is used after the version and\n1-RTT keys are negotiated.\n\n~~~\n1-RTT Packet {\n  Header Form (1) = 0,\n  Fixed Bit (1) = 1,\n  Spin Bit (1),\n  Reserved Bits (2),\n  Key Phase (1),\n  Packet Number Length (2),\n  Destination Connection ID (0..160),\n  Packet Number (8..32),\n  Packet Payload (8..),\n}\n~~~~~\n{: #1rtt-format title=\"1-RTT Packet\"}\n\n1-RTT packets contain the following fields:\n\nHeader Form:\n\n: The most significant bit (0x80) of byte 0 is set to 0 for the short header.\n\nFixed Bit:\n\n: The next bit (0x40) of byte 0 is set to 1.  Packets containing a zero value\n  for this bit are not valid packets in this version and MUST be discarded.  A\n  value of 1 for this bit allows QUIC to coexist with other protocols; see\n  {{?RFC7983}}.\n\nSpin Bit:\n\n: The third most significant bit (0x20) of byte 0 is the latency spin bit, set\n  as described in {{spin-bit}}.\n\nReserved Bits:\n\n: The next two bits (those with a mask of 0x18) of byte 0 are reserved. These\nbits are protected using header protection; see {{Section 5.4 of QUIC-TLS}}.\nThe value included prior to protection MUST be set to 0. An endpoint MUST treat\nreceipt of a packet that has a non-zero value for these bits, after removing\nboth packet and header protection, as a connection error of type\nPROTOCOL_VIOLATION. Discarding such a packet after only removing header\nprotection can expose the endpoint to attacks; see {{Section 9.5 of QUIC-TLS}}.\n\nKey Phase:\n\n: The next bit (0x04) of byte 0 indicates the key phase, which allows a\n  recipient of a packet to identify the packet protection keys that are used to\n  protect the packet.  See {{QUIC-TLS}} for details.  This bit is protected\n  using header protection; see {{Section 5.4 of QUIC-TLS}}.\n\nPacket Number Length:\n\n: The least significant two bits (those with a mask of 0x03) of byte 0 contain\n  the length of the Packet Number field, encoded as an unsigned two-bit integer\n  that is one less than the length of the Packet Number field in bytes.  That\n  is, the length of the Packet Number field is the value of this field plus one.\n  These bits are protected using header protection; see {{Section 5.4 of\n  QUIC-TLS}}.\n\nDestination Connection ID:\n\n: The Destination Connection ID is a connection ID that is chosen by the\n  intended recipient of the packet.  See {{connection-id}} for more details.\n\nPacket Number:\n\n: The Packet Number field is 1 to 4 bytes long. The packet number is protected\n  using header protection; see\n  {{Section 5.4 of QUIC-TLS}}. The length of the Packet Number field is encoded\n  in Packet Number Length field. See {{packet-encoding}} for details.\n\nPacket Payload:\n\n: 1-RTT packets always include a 1-RTT protected payload.\n\nThe header form bit and the Destination Connection ID field of a short header\npacket are version independent.  The remaining fields are specific to the\nselected QUIC version.  See {{QUIC-INVARIANTS}} for details on how packets from\ndifferent versions of QUIC are interpreted.\n\n\n## Latency Spin Bit {#spin-bit}\n\nThe latency spin bit, which is defined for 1-RTT packets ({{packet-1rtt}}),\nenables passive latency monitoring from observation points on the network path\nthroughout the duration of a connection. The server reflects the spin value\nreceived, while the client \"spins\" it after one RTT. On-path observers can\nmeasure the time between two spin bit toggle events to estimate the end-to-end\nRTT of a connection.\n\nThe spin bit is only present in 1-RTT packets, since it is possible to measure\nthe initial RTT of a connection by observing the handshake. Therefore, the spin\nbit is available after version negotiation and connection establishment are\ncompleted. On-path measurement and use of the latency spin bit are further\ndiscussed in {{?QUIC-MANAGEABILITY=I-D.ietf-quic-manageability}}.\n\nThe spin bit is an OPTIONAL feature of this version of QUIC. An endpoint that\ndoes not support this feature MUST disable it, as defined below.\n\nEach endpoint unilaterally decides if the spin bit is enabled or disabled for a\nconnection. Implementations MUST allow administrators of clients and servers to\ndisable the spin bit either globally or on a per-connection basis. Even when the\nspin bit is not disabled by the administrator, endpoints MUST disable their use\nof the spin bit for a random selection of at least one in every 16 network\npaths, or for one in every 16 connection IDs, in order to ensure that QUIC\nconnections that disable the spin bit are commonly observed on the network.  As\neach endpoint disables the spin bit independently, this ensures that the spin\nbit signal is disabled on approximately one in eight network paths.\n\nWhen the spin bit is disabled, endpoints MAY set the spin bit to any value and\nMUST ignore any incoming value. It is RECOMMENDED that endpoints set the spin\nbit to a random value either chosen independently for each packet or chosen\nindependently for each connection ID.\n\nIf the spin bit is enabled for the connection, the endpoint maintains a spin\nvalue for each network path and sets the spin bit in the packet header to the\ncurrently stored value when a 1-RTT packet is sent on that path. The spin value\nis initialized to 0 in the endpoint for each network path. Each endpoint also\nremembers the highest packet number seen from its peer on each path.\n\nWhen a server receives a 1-RTT packet that increases the highest packet number\nseen by the server from the client on a given network path, it sets the spin\nvalue for that path to be equal to the spin bit in the received packet.\n\nWhen a client receives a 1-RTT packet that increases the highest packet number\nseen by the client from the server on a given network path, it sets the spin\nvalue for that path to the inverse of the spin bit in the received packet.\n\nAn endpoint resets the spin value for a network path to 0 when changing the\nconnection ID being used on that network path.\n\n\n# Transport Parameter Encoding {#transport-parameter-encoding}\n\nThe extension_data field of the quic_transport_parameters extension defined in\n{{QUIC-TLS}} contains the QUIC transport parameters. They are encoded as a\nsequence of transport parameters, as shown in {{transport-parameter-sequence}}:\n\n~~~\nTransport Parameters {\n  Transport Parameter (..) ...,\n}\n~~~\n{: #transport-parameter-sequence title=\"Sequence of Transport Parameters\"}\n\nEach transport parameter is encoded as an (identifier, length, value) tuple,\nas shown in {{transport-parameter-encoding-fig}}:\n\n~~~\nTransport Parameter {\n  Transport Parameter ID (i),\n  Transport Parameter Length (i),\n  Transport Parameter Value (..),\n}\n~~~\n{: #transport-parameter-encoding-fig title=\"Transport Parameter Encoding\"}\n\nThe Transport Parameter Length field contains the length of the Transport\nParameter Value field in bytes.\n\nQUIC encodes transport parameters into a sequence of bytes, which is then\nincluded in the cryptographic handshake.\n\n\n## Reserved Transport Parameters {#transport-parameter-grease}\n\nTransport parameters with an identifier of the form `31 * N + 27` for integer\nvalues of N are reserved to exercise the requirement that unknown transport\nparameters be ignored.  These transport parameters have no semantics and can\ncarry arbitrary values.\n\n\n## Transport Parameter Definitions {#transport-parameter-definitions}\n\nThis section details the transport parameters defined in this document.\n\nMany transport parameters listed here have integer values.  Those transport\nparameters that are identified as integers use a variable-length integer\nencoding; see {{integer-encoding}}.  Transport parameters have a default value\nof 0 if the transport parameter is absent, unless otherwise stated.\n\nThe following transport parameters are defined:\n\noriginal_destination_connection_id (0x00):\n\n: This parameter is the value of the Destination Connection ID field from the\n  first Initial packet sent by the client; see {{cid-auth}}.  This transport\n  parameter is only sent by a server.\n\nmax_idle_timeout (0x01):\n\n: The maximum idle timeout is a value in milliseconds that is encoded as an\n  integer; see ({{idle-timeout}}).  Idle timeout is disabled when both endpoints\n  omit this transport parameter or specify a value of 0.\n\nstateless_reset_token (0x02):\n\n: A stateless reset token is used in verifying a stateless reset; see\n  {{stateless-reset}}.  This parameter is a sequence of 16 bytes.  This\n  transport parameter MUST NOT be sent by a client but MAY be sent by a server.\n  A server that does not send this transport parameter cannot use stateless\n  reset ({{stateless-reset}}) for the connection ID negotiated during the\n  handshake.\n\nmax_udp_payload_size (0x03):\n\n: The maximum UDP payload size parameter is an integer value that limits the\n  size of UDP payloads that the endpoint is willing to receive.  UDP datagrams\n  with payloads larger than this limit are not likely to be processed by the\n  receiver.\n\n: The default for this parameter is the maximum permitted UDP payload of 65527.\n  Values below 1200 are invalid.\n\n: This limit does act as an additional constraint on datagram size in the same\n  way as the path MTU, but it is a property of the endpoint and not the path;\n  see {{datagram-size}}.  It is expected that this is the space an endpoint\n  dedicates to holding incoming packets.\n\ninitial_max_data (0x04):\n\n: The initial maximum data parameter is an integer value that contains the\n  initial value for the maximum amount of data that can be sent on the\n  connection.  This is equivalent to sending a MAX_DATA ({{frame-max-data}}) for\n  the connection immediately after completing the handshake.\n\ninitial_max_stream_data_bidi_local (0x05):\n\n: This parameter is an integer value specifying the initial flow control limit\n  for locally initiated bidirectional streams.  This limit applies to newly\n  created bidirectional streams opened by the endpoint that sends the transport\n  parameter.  In client transport parameters, this applies to streams with an\n  identifier with the least significant two bits set to 0x00; in server\n  transport parameters, this applies to streams with the least significant two\n  bits set to 0x01.\n\ninitial_max_stream_data_bidi_remote (0x06):\n\n: This parameter is an integer value specifying the initial flow control limit\n  for peer-initiated bidirectional streams.  This limit applies to newly created\n  bidirectional streams opened by the endpoint that receives the transport\n  parameter.  In client transport parameters, this applies to streams with an\n  identifier with the least significant two bits set to 0x01; in server\n  transport parameters, this applies to streams with the least significant two\n  bits set to 0x00.\n\ninitial_max_stream_data_uni (0x07):\n\n: This parameter is an integer value specifying the initial flow control limit\n  for unidirectional streams.  This limit applies to newly created\n  unidirectional streams opened by the endpoint that receives the transport\n  parameter.  In client transport parameters, this applies to streams with an\n  identifier with the least significant two bits set to 0x03; in server\n  transport parameters, this applies to streams with the least significant two\n  bits set to 0x02.\n\ninitial_max_streams_bidi (0x08):\n\n: The initial maximum bidirectional streams parameter is an integer value that\n  contains the initial maximum number of bidirectional streams the endpoint\n  that receives this transport parameter is\n  permitted to initiate.  If this parameter is absent or zero, the peer cannot\n  open bidirectional streams until a MAX_STREAMS frame is sent.  Setting this\n  parameter is equivalent to sending a MAX_STREAMS ({{frame-max-streams}}) of\n  the corresponding type with the same value.\n\ninitial_max_streams_uni (0x09):\n\n: The initial maximum unidirectional streams parameter is an integer value that\n  contains the initial maximum number of unidirectional streams the endpoint\n  that receives this transport parameter is\n  permitted to initiate.  If this parameter is absent or zero, the peer cannot\n  open unidirectional streams until a MAX_STREAMS frame is sent.  Setting this\n  parameter is equivalent to sending a MAX_STREAMS ({{frame-max-streams}}) of\n  the corresponding type with the same value.\n\nack_delay_exponent (0x0a):\n\n: The acknowledgment delay exponent is an integer value indicating an exponent\n  used to decode the ACK Delay field in the ACK frame ({{frame-ack}}). If this\n  value is absent, a default value of 3 is assumed (indicating a multiplier of\n  8). Values above 20 are invalid.\n\nmax_ack_delay (0x0b):\n\n: The maximum acknowledgment delay is an integer value indicating the maximum\n  amount of time in milliseconds by which the endpoint will delay sending\n  acknowledgments.  This value SHOULD include the receiver's expected delays in\n  alarms firing.  For example, if a receiver sets a timer for 5ms and alarms\n  commonly fire up to 1ms late, then it should send a max_ack_delay of 6ms.  If\n  this value is absent, a default of 25 milliseconds is assumed. Values of\n  2<sup>14</sup> or greater are invalid.\n\ndisable_active_migration (0x0c):\n\n: The disable active migration transport parameter is included if the endpoint\n  does not support active connection migration ({{migration}}) on the address\n  being used during the handshake.  An endpoint that receives this transport\n  parameter MUST NOT use a new local address when sending to the address that\n  the peer used during the handshake.  This transport parameter does not\n  prohibit connection migration after a client has acted on a preferred_address\n  transport parameter.  This parameter is a zero-length value.\n\npreferred_address (0x0d):\n\n: The server's preferred address is used to effect a change in server address at\n  the end of the handshake, as described in {{preferred-address}}.  This\n  transport parameter is only sent by a server.  Servers MAY choose to only send\n  a preferred address of one address family by sending an all-zero address and\n  port (0.0.0.0:0 or \\[::]:0) for the other family. IP addresses are encoded in\n  network byte order.\n\n: The preferred_address transport parameter contains an address and port for\n  both IPv4 and IPv6.  The four-byte IPv4 Address field is followed by the\n  associated two-byte IPv4 Port field.  This is followed by a 16-byte IPv6\n  Address field and two-byte IPv6 Port field.  After address and port pairs, a\n  Connection ID Length field describes the length of the following Connection ID\n  field.  Finally, a 16-byte Stateless Reset Token field includes the stateless\n  reset token associated with the connection ID.  The format of this transport\n  parameter is shown in {{fig-preferred-address}} below.\n\n: The Connection ID field and the Stateless Reset Token field contain an\n  alternative connection ID that has a sequence number of 1; see {{issue-cid}}.\n  Having these values sent alongside the preferred address ensures that there\n  will be at least one unused active connection ID when the client initiates\n  migration to the preferred address.\n\n: The Connection ID and Stateless Reset Token fields of a preferred address are\n  identical in syntax and semantics to the corresponding fields of a\n  NEW_CONNECTION_ID frame ({{frame-new-connection-id}}).  A server that chooses\n  a zero-length connection ID MUST NOT provide a preferred address.  Similarly,\n  a server MUST NOT include a zero-length connection ID in this transport\n  parameter.  A client MUST treat a violation of these requirements as a\n  connection error of type TRANSPORT_PARAMETER_ERROR.\n\n~~~\nPreferred Address {\n  IPv4 Address (32),\n  IPv4 Port (16),\n  IPv6 Address (128),\n  IPv6 Port (16),\n  Connection ID Length (8),\n  Connection ID (..),\n  Stateless Reset Token (128),\n}\n~~~\n{: #fig-preferred-address title=\"Preferred Address Format\"}\n\nactive_connection_id_limit (0x0e):\n\n: This is an integer value specifying the maximum number of connection IDs from\n  the peer that an endpoint is willing to store. This value includes the\n  connection ID received during the handshake, that received in the\n  preferred_address transport parameter, and those received in NEW_CONNECTION_ID\n  frames.\n  The value of the active_connection_id_limit parameter MUST be at least 2.\n  An endpoint that receives a value less than 2 MUST close the connection\n  with an error of type TRANSPORT_PARAMETER_ERROR.\n  If this transport parameter is absent, a default of 2 is assumed.  If an\n  endpoint issues a zero-length connection ID, it will never send a\n  NEW_CONNECTION_ID frame and therefore ignores the active_connection_id_limit\n  value received from its peer.\n\ninitial_source_connection_id (0x0f):\n\n: This is the value that the endpoint included in the Source Connection ID field\n  of the first Initial packet it sends for the connection; see {{cid-auth}}.\n\nretry_source_connection_id (0x10):\n\n: This is the value that the server included in the Source Connection ID field\n  of a Retry packet; see {{cid-auth}}.  This transport parameter is only sent by\n  a server.\n\nIf present, transport parameters that set initial per-stream flow control limits\n(initial_max_stream_data_bidi_local, initial_max_stream_data_bidi_remote, and\ninitial_max_stream_data_uni) are equivalent to sending a MAX_STREAM_DATA frame\n({{frame-max-stream-data}}) on every stream of the corresponding type\nimmediately after opening.  If the transport parameter is absent, streams of\nthat type start with a flow control limit of 0.\n\nA client MUST NOT include any server-only transport parameter:\noriginal_destination_connection_id, preferred_address,\nretry_source_connection_id, or stateless_reset_token. A server MUST treat\nreceipt of any of these transport parameters as a connection error of type\nTRANSPORT_PARAMETER_ERROR.\n\n\n# Frame Types and Formats {#frame-formats}\n\nAs described in {{frames}}, packets contain one or more frames. This section\ndescribes the format and semantics of the core QUIC frame types.\n\n\n## PADDING Frames {#frame-padding}\n\nA PADDING frame (type=0x00) has no semantic value.  PADDING frames can be used\nto increase the size of a packet.  Padding can be used to increase an Initial\npacket to the minimum required size or to provide protection against traffic\nanalysis for protected packets.\n\nPADDING frames are formatted as shown in {{padding-format}}, which shows that\nPADDING frames have no content. That is, a PADDING frame consists of the single\nbyte that identifies the frame as a PADDING frame.\n\n~~~\nPADDING Frame {\n  Type (i) = 0x00,\n}\n~~~\n{: #padding-format title=\"PADDING Frame Format\"}\n\n\n## PING Frames {#frame-ping}\n\nEndpoints can use PING frames (type=0x01) to verify that their peers are still\nalive or to check reachability to the peer.\n\nPING frames are formatted as shown in {{ping-format}}, which shows that PING\nframes have no content.\n\n~~~\nPING Frame {\n  Type (i) = 0x01,\n}\n~~~\n{: #ping-format title=\"PING Frame Format\"}\n\nThe receiver of a PING frame simply needs to acknowledge the packet containing\nthis frame.\n\nThe PING frame can be used to keep a connection alive when an application or\napplication protocol wishes to prevent the connection from timing out; see\n{{defer-idle}}.\n\n\n## ACK Frames {#frame-ack}\n\nReceivers send ACK frames (types 0x02 and 0x03) to inform senders of packets\nthey have received and processed. The ACK frame contains one or more ACK Ranges.\nACK Ranges identify acknowledged packets. If the frame type is 0x03, ACK frames\nalso contain the cumulative count of QUIC packets with associated ECN marks\nreceived on the connection up until this point.  QUIC implementations MUST\nproperly handle both types, and, if they have enabled ECN for packets they send,\nthey SHOULD use the information in the ECN section to manage their congestion\nstate.\n\nQUIC acknowledgments are irrevocable.  Once acknowledged, a packet remains\nacknowledged, even if it does not appear in a future ACK frame.  This is unlike\nreneging for TCP Selective Acknowledgments (SACKs) {{?RFC2018}}.\n\nPackets from different packet number spaces can be identified using the same\nnumeric value. An acknowledgment for a packet needs to indicate both a packet\nnumber and a packet number space. This is accomplished by having each ACK frame\nonly acknowledge packet numbers in the same space as the packet in which the\nACK frame is contained.\n\nVersion Negotiation and Retry packets cannot be acknowledged because they do not\ncontain a packet number.  Rather than relying on ACK frames, these packets are\nimplicitly acknowledged by the next Initial packet sent by the client.\n\nACK frames are formatted as shown in {{ack-format}}.\n\n~~~\nACK Frame {\n  Type (i) = 0x02..0x03,\n  Largest Acknowledged (i),\n  ACK Delay (i),\n  ACK Range Count (i),\n  First ACK Range (i),\n  ACK Range (..) ...,\n  [ECN Counts (..)],\n}\n~~~\n{: #ack-format title=\"ACK Frame Format\"}\n\nACK frames contain the following fields:\n\nLargest Acknowledged:\n\n: A variable-length integer representing the largest packet number the peer is\n  acknowledging; this is usually the largest packet number that the peer has\n  received prior to generating the ACK frame.  Unlike the packet number in the\n  QUIC long or short header, the value in an ACK frame is not truncated.\n\nACK Delay:\n\n: A variable-length integer encoding the acknowledgment delay in\n  microseconds; see {{host-delay}}. It is decoded by multiplying the\n  value in the field by 2 to the power of the ack_delay_exponent transport\n  parameter sent by the sender of the ACK frame; see\n  {{transport-parameter-definitions}}. Compared to simply expressing\n  the delay as an integer, this encoding allows for a larger range of\n  values within the same number of bytes, at the cost of lower resolution.\n\nACK Range Count:\n\n: A variable-length integer specifying the number of ACK Range fields in\n  the frame.\n\nFirst ACK Range:\n\n: A variable-length integer indicating the number of contiguous packets\n  preceding the Largest Acknowledged that are being acknowledged.  That is, the\n  smallest packet acknowledged in the range is determined by subtracting the\n  First ACK Range value from the Largest Acknowledged field.\n\nACK Ranges:\n\n: Contains additional ranges of packets that are alternately not\n  acknowledged (Gap) and acknowledged (ACK Range); see {{ack-ranges}}.\n\nECN Counts:\n\n: The three ECN counts; see {{ack-ecn-counts}}.\n\n\n### ACK Ranges {#ack-ranges}\n\nEach ACK Range consists of alternating Gap and ACK Range Length values in\ndescending packet number order. ACK Ranges can be repeated. The number of Gap\nand ACK Range Length values is determined by the ACK Range Count field; one of\neach value is present for each value in the ACK Range Count field.\n\nACK Ranges are structured as shown in {{ack-range-format}}.\n\n~~~\nACK Range {\n  Gap (i),\n  ACK Range Length (i),\n}\n~~~\n{: #ack-range-format title=\"ACK Ranges\"}\n\nThe fields that form each ACK Range are:\n\nGap:\n\n: A variable-length integer indicating the number of contiguous unacknowledged\n  packets preceding the packet number one lower than the smallest in the\n  preceding ACK Range.\n\nACK Range Length:\n\n: A variable-length integer indicating the number of contiguous acknowledged\n  packets preceding the largest packet number, as determined by the\n  preceding Gap.\n\nGap and ACK Range Length values use a relative integer encoding for efficiency.\nThough each encoded value is positive, the values are subtracted, so that each\nACK Range describes progressively lower-numbered packets.\n\nEach ACK Range acknowledges a contiguous range of packets by indicating the\nnumber of acknowledged packets that precede the largest packet number in that\nrange.  A value of 0 indicates that only the largest packet number is\nacknowledged.  Larger ACK Range values indicate a larger range, with\ncorresponding lower values for the smallest packet number in the range.  Thus,\ngiven a largest packet number for the range, the smallest value is determined by\nthe following formula:\n\n~~~\n   smallest = largest - ack_range\n~~~\n\nAn ACK Range acknowledges all packets between the smallest packet number and the\nlargest, inclusive.\n\nThe largest value for an ACK Range is determined by cumulatively subtracting the\nsize of all preceding ACK Range Lengths and Gaps.\n\nEach Gap indicates a range of packets that are not being acknowledged.  The\nnumber of packets in the gap is one higher than the encoded value of the Gap\nfield.\n\nThe value of the Gap field establishes the largest packet number value for the\nsubsequent ACK Range using the following formula:\n\n~~~\n   largest = previous_smallest - gap - 2\n~~~\n\nIf any computed packet number is negative, an endpoint MUST generate a\nconnection error of type FRAME_ENCODING_ERROR.\n\n\n### ECN Counts {#ack-ecn-counts}\n\nThe ACK frame uses the least significant bit of the type value (that is, type\n0x03) to indicate ECN feedback and report receipt of QUIC packets with\nassociated ECN codepoints of ECT(0), ECT(1), or ECN-CE in the packet's IP\nheader.  ECN counts are only present when the ACK frame type is 0x03.\n\nWhen present, there are three ECN counts, as shown in {{ecn-count-format}}.\n\n~~~\nECN Counts {\n  ECT0 Count (i),\n  ECT1 Count (i),\n  ECN-CE Count (i),\n}\n~~~\n{: #ecn-count-format title=\"ECN Count Format\"}\n\nThe ECN count fields are:\n\nECT0 Count:\n: A variable-length integer representing the total number of packets received\n  with the ECT(0) codepoint in the packet number space of the ACK frame.\n\nECT1 Count:\n: A variable-length integer representing the total number of packets received\n  with the ECT(1) codepoint in the packet number space of the ACK frame.\n\nECN-CE Count:\n: A variable-length integer representing the total number of packets received\n  with the ECN-CE codepoint in the packet number space of the ACK frame.\n\nECN counts are maintained separately for each packet number space.\n\n\n## RESET_STREAM Frames {#frame-reset-stream}\n\nAn endpoint uses a RESET_STREAM frame (type=0x04) to abruptly terminate the\nsending part of a stream.\n\nAfter sending a RESET_STREAM, an endpoint ceases transmission and retransmission\nof STREAM frames on the identified stream.  A receiver of RESET_STREAM can\ndiscard any data that it already received on that stream.\n\nAn endpoint that receives a RESET_STREAM frame for a send-only stream MUST\nterminate the connection with error STREAM_STATE_ERROR.\n\nRESET_STREAM frames are formatted as shown in {{fig-reset-stream}}.\n\n~~~\nRESET_STREAM Frame {\n  Type (i) = 0x04,\n  Stream ID (i),\n  Application Protocol Error Code (i),\n  Final Size (i),\n}\n~~~\n{: #fig-reset-stream title=\"RESET_STREAM Frame Format\"}\n\nRESET_STREAM frames contain the following fields:\n\nStream ID:\n\n: A variable-length integer encoding of the stream ID of the stream being\n  terminated.\n\nApplication Protocol Error Code:\n\n: A variable-length integer containing the application protocol error\n  code (see {{app-error-codes}}) that indicates why the stream is being\n  closed.\n\nFinal Size:\n\n: A variable-length integer indicating the final size of the stream by the\n  RESET_STREAM sender, in units of bytes; see {{final-size}}.\n\n\n## STOP_SENDING Frames {#frame-stop-sending}\n\nAn endpoint uses a STOP_SENDING frame (type=0x05) to communicate that incoming\ndata is being discarded on receipt per application request.  STOP_SENDING\nrequests that a peer cease transmission on a stream.\n\nA STOP_SENDING frame can be sent for streams in the \"Recv\" or \"Size Known\"\nstates; see {{stream-recv-states}}.  Receiving a STOP_SENDING frame for a\nlocally initiated stream that has not yet been created MUST be treated as a\nconnection error of type STREAM_STATE_ERROR.  An endpoint that receives a\nSTOP_SENDING frame for a receive-only stream MUST terminate the connection with\nerror STREAM_STATE_ERROR.\n\nSTOP_SENDING frames are formatted as shown in {{fig-stop-sending}}.\n\n~~~\nSTOP_SENDING Frame {\n  Type (i) = 0x05,\n  Stream ID (i),\n  Application Protocol Error Code (i),\n}\n~~~\n{: #fig-stop-sending title=\"STOP_SENDING Frame Format\"}\n\nSTOP_SENDING frames contain the following fields:\n\nStream ID:\n\n: A variable-length integer carrying the stream ID of the stream being ignored.\n\nApplication Protocol Error Code:\n\n: A variable-length integer containing the application-specified reason the\n  sender is ignoring the stream; see {{app-error-codes}}.\n\n\n## CRYPTO Frames {#frame-crypto}\n\nA CRYPTO frame (type=0x06) is used to transmit cryptographic handshake messages.\nIt can be sent in all packet types except 0-RTT. The CRYPTO frame offers the\ncryptographic protocol an in-order stream of bytes.  CRYPTO frames are\nfunctionally identical to STREAM frames, except that they do not bear a stream\nidentifier; they are not flow controlled; and they do not carry markers for\noptional offset, optional length, and the end of the stream.\n\nCRYPTO frames are formatted as shown in {{fig-crypto}}.\n\n~~~\nCRYPTO Frame {\n  Type (i) = 0x06,\n  Offset (i),\n  Length (i),\n  Crypto Data (..),\n}\n~~~\n{: #fig-crypto title=\"CRYPTO Frame Format\"}\n\nCRYPTO frames contain the following fields:\n\nOffset:\n\n: A variable-length integer specifying the byte offset in the stream for the\n  data in this CRYPTO frame.\n\nLength:\n\n: A variable-length integer specifying the length of the Crypto Data field in\n  this CRYPTO frame.\n\nCrypto Data:\n\n: The cryptographic message data.\n\nThere is a separate flow of cryptographic handshake data in each encryption\nlevel, each of which starts at an offset of 0. This implies that each encryption\nlevel is treated as a separate CRYPTO stream of data.\n\nThe largest offset delivered on a stream -- the sum of the offset and data\nlength -- cannot exceed 2<sup>62</sup>-1.  Receipt of a frame that exceeds this\nlimit MUST be treated as a connection error of type FRAME_ENCODING_ERROR or\nCRYPTO_BUFFER_EXCEEDED.\n\nUnlike STREAM frames, which include a stream ID indicating to which stream the\ndata belongs, the CRYPTO frame carries data for a single stream per encryption\nlevel. The stream does not have an explicit end, so CRYPTO frames do not have a\nFIN bit.\n\n\n## NEW_TOKEN Frames {#frame-new-token}\n\nA server sends a NEW_TOKEN frame (type=0x07) to provide the client with a token\nto send in the header of an Initial packet for a future connection.\n\nNEW_TOKEN frames are formatted as shown in {{fig-new-token}}.\n\n~~~\nNEW_TOKEN Frame {\n  Type (i) = 0x07,\n  Token Length (i),\n  Token (..),\n}\n~~~\n{: #fig-new-token title=\"NEW_TOKEN Frame Format\"}\n\nNEW_TOKEN frames contain the following fields:\n\nToken Length:\n\n: A variable-length integer specifying the length of the token in bytes.\n\nToken:\n\n: An opaque blob that the client can use with a future Initial packet. The token\n  MUST NOT be empty.  A client MUST treat receipt of a NEW_TOKEN frame with\n  an empty Token field as a connection error of type FRAME_ENCODING_ERROR.\n\nA client might receive multiple NEW_TOKEN frames that contain the same token\nvalue if packets containing the frame are incorrectly determined to be lost.\nClients are responsible for discarding duplicate values, which might be used\nto link connection attempts; see {{validate-future}}.\n\nClients MUST NOT send NEW_TOKEN frames.  A server MUST treat receipt of a\nNEW_TOKEN frame as a connection error of type PROTOCOL_VIOLATION.\n\n\n## STREAM Frames {#frame-stream}\n\nSTREAM frames implicitly create a stream and carry stream data.  The Type field\nin the STREAM frame takes the form 0b00001XXX (or the set of values from 0x08 to\n0x0f).  The three low-order bits of the frame type determine the fields that are\npresent in the frame:\n\n* The OFF bit (0x04) in the frame type is set to indicate that there is an\n  Offset field present.  When set to 1, the Offset field is present.  When set\n  to 0, the Offset field is absent and the Stream Data starts at an offset of 0\n  (that is, the frame contains the first bytes of the stream, or the end of a\n  stream that includes no data).\n\n* The LEN bit (0x02) in the frame type is set to indicate that there is a Length\n  field present.  If this bit is set to 0, the Length field is absent and the\n  Stream Data field extends to the end of the packet.  If this bit is set to 1,\n  the Length field is present.\n\n* The FIN bit (0x01) indicates that the frame marks the end of the stream. The\n  final size of the stream is the sum of the offset and the length of this\n  frame.\n\nAn endpoint MUST terminate the connection with error STREAM_STATE_ERROR if it\nreceives a STREAM frame for a locally initiated stream that has not yet been\ncreated, or for a send-only stream.\n\nSTREAM frames are formatted as shown in {{fig-stream}}.\n\n~~~\nSTREAM Frame {\n  Type (i) = 0x08..0x0f,\n  Stream ID (i),\n  [Offset (i)],\n  [Length (i)],\n  Stream Data (..),\n}\n~~~\n{: #fig-stream title=\"STREAM Frame Format\"}\n\nSTREAM frames contain the following fields:\n\nStream ID:\n\n: A variable-length integer indicating the stream ID of the stream; see\n  {{stream-id}}.\n\nOffset:\n\n: A variable-length integer specifying the byte offset in the stream for the\n  data in this STREAM frame.  This field is present when the OFF bit is set to\n  1.  When the Offset field is absent, the offset is 0.\n\nLength:\n\n: A variable-length integer specifying the length of the Stream Data field in\n  this STREAM frame.  This field is present when the LEN bit is set to 1.  When\n  the LEN bit is set to 0, the Stream Data field consumes all the remaining\n  bytes in the packet.\n\nStream Data:\n\n: The bytes from the designated stream to be delivered.\n\nWhen a Stream Data field has a length of 0, the offset in the STREAM frame is\nthe offset of the next byte that would be sent.\n\nThe first byte in the stream has an offset of 0.  The largest offset delivered\non a stream -- the sum of the offset and data length -- cannot exceed\n2<sup>62</sup>-1, as it is not possible to provide flow control credit for that\ndata.  Receipt of a frame that exceeds this limit MUST be treated as a\nconnection error of type FRAME_ENCODING_ERROR or FLOW_CONTROL_ERROR.\n\n\n## MAX_DATA Frames {#frame-max-data}\n\nA MAX_DATA frame (type=0x10) is used in flow control to inform the peer of the\nmaximum amount of data that can be sent on the connection as a whole.\n\nMAX_DATA frames are formatted as shown in {{fig-max-data}}.\n\n~~~\nMAX_DATA Frame {\n  Type (i) = 0x10,\n  Maximum Data (i),\n}\n~~~\n{: #fig-max-data title=\"MAX_DATA Frame Format\"}\n\nMAX_DATA frames contain the following field:\n\nMaximum Data:\n\n: A variable-length integer indicating the maximum amount of data that can be\n  sent on the entire connection, in units of bytes.\n\nAll data sent in STREAM frames counts toward this limit.  The sum of the final\nsizes on all streams -- including streams in terminal states -- MUST NOT exceed\nthe value advertised by a receiver.  An endpoint MUST terminate a connection\nwith an error of type FLOW_CONTROL_ERROR if it receives more data than the\nmaximum data value that it has sent.  This includes violations of remembered\nlimits in Early Data; see {{zerortt-parameters}}.\n\n\n## MAX_STREAM_DATA Frames {#frame-max-stream-data}\n\nA MAX_STREAM_DATA frame (type=0x11) is used in flow control to inform a peer\nof the maximum amount of data that can be sent on a stream.\n\nA MAX_STREAM_DATA frame can be sent for streams in the \"Recv\" state; see\n{{stream-recv-states}}. Receiving a MAX_STREAM_DATA frame for a\nlocally initiated stream that has not yet been created MUST be treated as a\nconnection error of type STREAM_STATE_ERROR.  An endpoint that receives a\nMAX_STREAM_DATA frame for a receive-only stream MUST terminate the connection\nwith error STREAM_STATE_ERROR.\n\nMAX_STREAM_DATA frames are formatted as shown in {{fig-max-stream-data}}.\n\n~~~\nMAX_STREAM_DATA Frame {\n  Type (i) = 0x11,\n  Stream ID (i),\n  Maximum Stream Data (i),\n}\n~~~\n{: #fig-max-stream-data title=\"MAX_STREAM_DATA Frame Format\"}\n\nMAX_STREAM_DATA frames contain the following fields:\n\nStream ID:\n\n: The stream ID of the affected stream, encoded as a variable-length integer.\n\nMaximum Stream Data:\n\n: A variable-length integer indicating the maximum amount of data that can be\n  sent on the identified stream, in units of bytes.\n\nWhen counting data toward this limit, an endpoint accounts for the largest\nreceived offset of data that is sent or received on the stream.  Loss or\nreordering can mean that the largest received offset on a stream can be greater\nthan the total size of data received on that stream.  Receiving STREAM frames\nmight not increase the largest received offset.\n\nThe data sent on a stream MUST NOT exceed the largest maximum stream data value\nadvertised by the receiver.  An endpoint MUST terminate a connection with an\nerror of type FLOW_CONTROL_ERROR if it receives more data than the largest\nmaximum stream data that it has sent for the affected stream.  This includes\nviolations of remembered limits in Early Data; see {{zerortt-parameters}}.\n\n\n## MAX_STREAMS Frames {#frame-max-streams}\n\nA MAX_STREAMS frame (type=0x12 or 0x13) informs the peer of the cumulative\nnumber of streams of a given type it is permitted to open.  A MAX_STREAMS frame\nwith a type of 0x12 applies to bidirectional streams, and a MAX_STREAMS frame\nwith a type of 0x13 applies to unidirectional streams.\n\nMAX_STREAMS frames are formatted as shown in {{fig-max-streams}}.\n\n~~~\nMAX_STREAMS Frame {\n  Type (i) = 0x12..0x13,\n  Maximum Streams (i),\n}\n~~~\n{: #fig-max-streams title=\"MAX_STREAMS Frame Format\"}\n\nMAX_STREAMS frames contain the following field:\n\nMaximum Streams:\n\n: A count of the cumulative number of streams of the corresponding type that can\n  be opened over the lifetime of the connection.  This value cannot exceed\n  2<sup>60</sup>, as it is not possible to encode stream IDs larger than\n  2<sup>62</sup>-1.  Receipt of a frame that permits opening of a stream larger\n  than this limit MUST be treated as a connection error of type\n  FRAME_ENCODING_ERROR.\n\nLoss or reordering can cause an endpoint to receive a MAX_STREAMS frame with a\nlower stream limit than was previously received.  MAX_STREAMS frames that do not\nincrease the stream limit MUST be ignored.\n\nAn endpoint MUST NOT open more streams than permitted by the current stream\nlimit set by its peer.  For instance, a server that receives a unidirectional\nstream limit of 3 is permitted to open streams 3, 7, and 11, but not stream 15.\nAn endpoint MUST terminate a connection with an error of type STREAM_LIMIT_ERROR\nif a peer opens more streams than was permitted.  This includes violations of\nremembered limits in Early Data; see {{zerortt-parameters}}.\n\nNote that these frames (and the corresponding transport parameters) do not\ndescribe the number of streams that can be opened concurrently.  The limit\nincludes streams that have been closed as well as those that are open.\n\n\n## DATA_BLOCKED Frames {#frame-data-blocked}\n\nA sender SHOULD send a DATA_BLOCKED frame (type=0x14) when it wishes to send\ndata but is unable to do so due to connection-level flow control; see\n{{flow-control}}.  DATA_BLOCKED frames can be used as input to tuning of flow\ncontrol algorithms; see {{fc-credit}}.\n\nDATA_BLOCKED frames are formatted as shown in {{fig-data-blocked}}.\n\n~~~\nDATA_BLOCKED Frame {\n  Type (i) = 0x14,\n  Maximum Data (i),\n}\n~~~\n{: #fig-data-blocked title=\"DATA_BLOCKED Frame Format\"}\n\nDATA_BLOCKED frames contain the following field:\n\nMaximum Data:\n\n: A variable-length integer indicating the connection-level limit at which\n  blocking occurred.\n\n\n## STREAM_DATA_BLOCKED Frames {#frame-stream-data-blocked}\n\nA sender SHOULD send a STREAM_DATA_BLOCKED frame (type=0x15) when it wishes to\nsend data but is unable to do so due to stream-level flow control.  This frame\nis analogous to DATA_BLOCKED ({{frame-data-blocked}}).\n\nAn endpoint that receives a STREAM_DATA_BLOCKED frame for a send-only stream\nMUST terminate the connection with error STREAM_STATE_ERROR.\n\nSTREAM_DATA_BLOCKED frames are formatted as shown in\n{{fig-stream-data-blocked}}.\n\n~~~\nSTREAM_DATA_BLOCKED Frame {\n  Type (i) = 0x15,\n  Stream ID (i),\n  Maximum Stream Data (i),\n}\n~~~\n{: #fig-stream-data-blocked title=\"STREAM_DATA_BLOCKED Frame Format\"}\n\nSTREAM_DATA_BLOCKED frames contain the following fields:\n\nStream ID:\n\n: A variable-length integer indicating the stream that is blocked due to flow\n  control.\n\nMaximum Stream Data:\n\n: A variable-length integer indicating the offset of the stream at which the\n  blocking occurred.\n\n\n## STREAMS_BLOCKED Frames {#frame-streams-blocked}\n\nA sender SHOULD send a STREAMS_BLOCKED frame (type=0x16 or 0x17) when it wishes\nto open a stream but is unable to do so due to the maximum stream limit set by\nits peer; see {{frame-max-streams}}.  A STREAMS_BLOCKED frame of type 0x16 is\nused to indicate reaching the bidirectional stream limit, and a STREAMS_BLOCKED\nframe of type 0x17 is used to indicate reaching the unidirectional stream limit.\n\nA STREAMS_BLOCKED frame does not open the stream, but informs the peer that a\nnew stream was needed and the stream limit prevented the creation of the stream.\n\nSTREAMS_BLOCKED frames are formatted as shown in {{fig-streams-blocked}}.\n\n~~~\nSTREAMS_BLOCKED Frame {\n  Type (i) = 0x16..0x17,\n  Maximum Streams (i),\n}\n~~~\n{: #fig-streams-blocked title=\"STREAMS_BLOCKED Frame Format\"}\n\nSTREAMS_BLOCKED frames contain the following field:\n\nMaximum Streams:\n\n: A variable-length integer indicating the maximum number of streams allowed at\n  the time the frame was sent.  This value cannot exceed 2<sup>60</sup>, as it\n  is not possible to encode stream IDs larger than 2<sup>62</sup>-1.  Receipt of\n  a frame that encodes a larger stream ID MUST be treated as a connection error\n  of type STREAM_LIMIT_ERROR or FRAME_ENCODING_ERROR.\n\n\n## NEW_CONNECTION_ID Frames {#frame-new-connection-id}\n\nAn endpoint sends a NEW_CONNECTION_ID frame (type=0x18) to provide its peer with\nalternative connection IDs that can be used to break linkability when migrating\nconnections; see {{migration-linkability}}.\n\nNEW_CONNECTION_ID frames are formatted as shown in {{fig-new-connection-id}}.\n\n~~~\nNEW_CONNECTION_ID Frame {\n  Type (i) = 0x18,\n  Sequence Number (i),\n  Retire Prior To (i),\n  Length (8),\n  Connection ID (8..160),\n  Stateless Reset Token (128),\n}\n~~~\n{: #fig-new-connection-id title=\"NEW_CONNECTION_ID Frame Format\"}\n\nNEW_CONNECTION_ID frames contain the following fields:\n\nSequence Number:\n\n: The sequence number assigned to the connection ID by the sender, encoded as a\n  variable-length integer; see {{issue-cid}}.\n\nRetire Prior To:\n\n: A variable-length integer indicating which connection IDs should be retired;\n  see {{retire-cid}}.\n\nLength:\n\n: An 8-bit unsigned integer containing the length of the connection ID.  Values\n  less than 1 and greater than 20 are invalid and MUST be treated as a\n  connection error of type FRAME_ENCODING_ERROR.\n\nConnection ID:\n\n: A connection ID of the specified length.\n\nStateless Reset Token:\n\n: A 128-bit value that will be used for a stateless reset when the associated\n  connection ID is used; see {{stateless-reset}}.\n\nAn endpoint MUST NOT send this frame if it currently requires that its peer send\npackets with a zero-length Destination Connection ID.  Changing the length of a\nconnection ID to or from zero length makes it difficult to identify when the\nvalue of the connection ID changed.  An endpoint that is sending packets with a\nzero-length Destination Connection ID MUST treat receipt of a NEW_CONNECTION_ID\nframe as a connection error of type PROTOCOL_VIOLATION.\n\nTransmission errors, timeouts, and retransmissions might cause the same\nNEW_CONNECTION_ID frame to be received multiple times.  Receipt of the same\nframe multiple times MUST NOT be treated as a connection error.  A receiver can\nuse the sequence number supplied in the NEW_CONNECTION_ID frame to handle\nreceiving the same NEW_CONNECTION_ID frame multiple times.\n\nIf an endpoint receives a NEW_CONNECTION_ID frame that repeats a previously\nissued connection ID with a different Stateless Reset Token field value or a\ndifferent Sequence Number field value, or if a sequence number is used for\ndifferent connection IDs, the endpoint MAY treat that receipt as a connection\nerror of type PROTOCOL_VIOLATION.\n\nThe Retire Prior To field applies to connection IDs established during\nconnection setup and the preferred_address transport parameter; see\n{{retire-cid}}. The value in the Retire Prior To field MUST be less than or\nequal to the value in the Sequence Number field. Receiving a value in the Retire\nPrior To field that is greater than that in the Sequence Number field MUST be\ntreated as a connection error of type FRAME_ENCODING_ERROR.\n\nOnce a sender indicates a Retire Prior To value, smaller values sent in\nsubsequent NEW_CONNECTION_ID frames have no effect. A receiver MUST ignore any\nRetire Prior To fields that do not increase the largest received Retire Prior To\nvalue.\n\nAn endpoint that receives a NEW_CONNECTION_ID frame with a sequence number\nsmaller than the Retire Prior To field of a previously received\nNEW_CONNECTION_ID frame MUST send a corresponding RETIRE_CONNECTION_ID frame\nthat retires the newly received connection ID, unless it has already done so\nfor that sequence number.\n\n\n## RETIRE_CONNECTION_ID Frames {#frame-retire-connection-id}\n\nAn endpoint sends a RETIRE_CONNECTION_ID frame (type=0x19) to indicate that it\nwill no longer use a connection ID that was issued by its peer. This includes\nthe connection ID provided during the handshake.  Sending a RETIRE_CONNECTION_ID\nframe also serves as a request to the peer to send additional connection IDs for\nfuture use; see {{connection-id}}.  New connection IDs can be delivered to a\npeer using the NEW_CONNECTION_ID frame ({{frame-new-connection-id}}).\n\nRetiring a connection ID invalidates the stateless reset token associated with\nthat connection ID.\n\nRETIRE_CONNECTION_ID frames are formatted as shown in\n{{fig-retire-connection-id}}.\n\n~~~\nRETIRE_CONNECTION_ID Frame {\n  Type (i) = 0x19,\n  Sequence Number (i),\n}\n~~~\n{: #fig-retire-connection-id title=\"RETIRE_CONNECTION_ID Frame Format\"}\n\nRETIRE_CONNECTION_ID frames contain the following field:\n\nSequence Number:\n\n: The sequence number of the connection ID being retired; see {{retire-cid}}.\n\nReceipt of a RETIRE_CONNECTION_ID frame containing a sequence number greater\nthan any previously sent to the peer MUST be treated as a connection error of\ntype PROTOCOL_VIOLATION.\n\nThe sequence number specified in a RETIRE_CONNECTION_ID frame MUST NOT refer\nto the Destination Connection ID field of the packet in which the frame is\ncontained.  The peer MAY treat this as a connection error of type\nPROTOCOL_VIOLATION.\n\nAn endpoint cannot send this frame if it was provided with a zero-length\nconnection ID by its peer.  An endpoint that provides a zero-length connection\nID MUST treat receipt of a RETIRE_CONNECTION_ID frame as a connection error of\ntype PROTOCOL_VIOLATION.\n\n\n## PATH_CHALLENGE Frames {#frame-path-challenge}\n\nEndpoints can use PATH_CHALLENGE frames (type=0x1a) to check reachability to the\npeer and for path validation during connection migration.\n\nPATH_CHALLENGE frames are formatted as shown in {{fig-path-challenge}}.\n\n~~~\nPATH_CHALLENGE Frame {\n  Type (i) = 0x1a,\n  Data (64),\n}\n~~~\n{: #fig-path-challenge title=\"PATH_CHALLENGE Frame Format\"}\n\nPATH_CHALLENGE frames contain the following field:\n\nData:\n\n: This 8-byte field contains arbitrary data.\n\nIncluding 64 bits of entropy in a PATH_CHALLENGE frame ensures that it is easier\nto receive the packet than it is to guess the value correctly.\n\nThe recipient of this frame MUST generate a PATH_RESPONSE frame\n({{frame-path-response}}) containing the same Data value.\n\n\n## PATH_RESPONSE Frames {#frame-path-response}\n\nA PATH_RESPONSE frame (type=0x1b) is sent in response to a PATH_CHALLENGE frame.\n\nPATH_RESPONSE frames are formatted as shown in {{fig-path-response}}. The format\nof a PATH_RESPONSE frame is identical to that of the PATH_CHALLENGE frame; see\n{{frame-path-challenge}}.\n\n~~~\nPATH_RESPONSE Frame {\n  Type (i) = 0x1b,\n  Data (64),\n}\n~~~\n{: #fig-path-response title=\"PATH_RESPONSE Frame Format\"}\n\nIf the content of a PATH_RESPONSE frame does not match the content of a\nPATH_CHALLENGE frame previously sent by the endpoint, the endpoint MAY generate\na connection error of type PROTOCOL_VIOLATION.\n\n\n## CONNECTION_CLOSE Frames {#frame-connection-close}\n\nAn endpoint sends a CONNECTION_CLOSE frame (type=0x1c or 0x1d) to notify its\npeer that the connection is being closed.  The CONNECTION_CLOSE frame with a\ntype of 0x1c is used to signal errors at only the QUIC layer, or the absence of\nerrors (with the NO_ERROR code).  The CONNECTION_CLOSE frame with a type of 0x1d\nis used to signal an error with the application that uses QUIC.\n\nIf there are open streams that have not been explicitly closed, they are\nimplicitly closed when the connection is closed.\n\nCONNECTION_CLOSE frames are formatted as shown in {{fig-connection-close}}.\n\n~~~\nCONNECTION_CLOSE Frame {\n  Type (i) = 0x1c..0x1d,\n  Error Code (i),\n  [Frame Type (i)],\n  Reason Phrase Length (i),\n  Reason Phrase (..),\n}\n~~~\n{: #fig-connection-close title=\"CONNECTION_CLOSE Frame Format\"}\n\nCONNECTION_CLOSE frames contain the following fields:\n\nError Code:\n\n: A variable-length integer that indicates the reason for closing this\n  connection.  A CONNECTION_CLOSE frame of type 0x1c uses codes from the space\n  defined in {{transport-error-codes}}.  A CONNECTION_CLOSE frame of type 0x1d\n  uses codes defined by the application protocol; see\n  {{app-error-codes}}.\n\nFrame Type:\n\n: A variable-length integer encoding the type of frame that triggered the error.\n  A value of 0 (equivalent to the mention of the PADDING frame) is used when the\n  frame type is unknown.  The application-specific variant of CONNECTION_CLOSE\n  (type 0x1d) does not include this field.\n\nReason Phrase Length:\n\n: A variable-length integer specifying the length of the reason phrase in bytes.\n  Because a CONNECTION_CLOSE frame cannot be split between packets, any limits\n  on packet size will also limit the space available for a reason phrase.\n\nReason Phrase:\n\n: Additional diagnostic information for the closure.  This can be zero length if\n  the sender chooses not to give details beyond the Error Code value.  This\n  SHOULD be a UTF-8 encoded string {{!RFC3629}}, though the frame does not carry\n  information, such as language tags, that would aid comprehension by any entity\n  other than the one that created the text.\n\nThe application-specific variant of CONNECTION_CLOSE (type 0x1d) can only be\nsent using 0-RTT or 1-RTT packets; see {{frames-and-spaces}}.  When an\napplication wishes to abandon a connection during the handshake, an endpoint\ncan send a CONNECTION_CLOSE frame (type 0x1c) with an error code of\nAPPLICATION_ERROR in an Initial or Handshake packet.\n\n\n## HANDSHAKE_DONE Frames {#frame-handshake-done}\n\nThe server uses a HANDSHAKE_DONE frame (type=0x1e) to signal confirmation of\nthe handshake to the client.\n\nHANDSHAKE_DONE frames are formatted as shown in {{handshake-done-format}}, which\nshows that HANDSHAKE_DONE frames have no content.\n\n~~~\nHANDSHAKE_DONE Frame {\n  Type (i) = 0x1e,\n}\n~~~\n{: #handshake-done-format title=\"HANDSHAKE_DONE Frame Format\"}\n\nA HANDSHAKE_DONE frame can only be sent by the server. Servers MUST NOT send a\nHANDSHAKE_DONE frame before completing the handshake.  A server MUST treat\nreceipt of a HANDSHAKE_DONE frame as a connection error of type\nPROTOCOL_VIOLATION.\n\n\n## Extension Frames\n\nQUIC frames do not use a self-describing encoding.  An endpoint therefore needs\nto understand the syntax of all frames before it can successfully process a\npacket.  This allows for efficient encoding of frames, but it means that an\nendpoint cannot send a frame of a type that is unknown to its peer.\n\nAn extension to QUIC that wishes to use a new type of frame MUST first ensure\nthat a peer is able to understand the frame.  An endpoint can use a transport\nparameter to signal its willingness to receive extension frame types. One\ntransport parameter can indicate support for one or more extension frame types.\n\nExtensions that modify or replace core protocol functionality (including frame\ntypes) will be difficult to combine with other extensions that modify or\nreplace the same functionality unless the behavior of the combination is\nexplicitly defined.  Such extensions SHOULD define their interaction with\npreviously defined extensions modifying the same protocol components.\n\nExtension frames MUST be congestion controlled and MUST cause an ACK frame to\nbe sent.  The exception is extension frames that replace or supplement the ACK\nframe.  Extension frames are not included in flow control unless specified\nin the extension.\n\nAn IANA registry is used to manage the assignment of frame types; see\n{{iana-frames}}.\n\n\n# Error Codes {#error-codes}\n\nQUIC transport error codes and application error codes are 62-bit unsigned\nintegers.\n\n## Transport Error Codes {#transport-error-codes}\n\nThis section lists the defined QUIC transport error codes that can be used in a\nCONNECTION_CLOSE frame with a type of 0x1c.  These errors apply to the entire\nconnection.\n\nNO_ERROR (0x00):\n\n: An endpoint uses this with CONNECTION_CLOSE to signal that the connection is\n  being closed abruptly in the absence of any error.\n\nINTERNAL_ERROR (0x01):\n\n: The endpoint encountered an internal error and cannot continue with the\n  connection.\n\nCONNECTION_REFUSED (0x02):\n\n: The server refused to accept a new connection.\n\nFLOW_CONTROL_ERROR (0x03):\n\n: An endpoint received more data than it permitted in its advertised data\n  limits; see {{flow-control}}.\n\nSTREAM_LIMIT_ERROR (0x04):\n\n: An endpoint received a frame for a stream identifier that exceeded its\n  advertised stream limit for the corresponding stream type.\n\nSTREAM_STATE_ERROR (0x05):\n\n: An endpoint received a frame for a stream that was not in a state that\n  permitted that frame; see {{stream-states}}.\n\nFINAL_SIZE_ERROR (0x06):\n\n: (1) An endpoint received a STREAM frame containing data that exceeded the\n  previously established final size, (2) an endpoint received a STREAM frame or\n  a RESET_STREAM frame containing a final size that was lower than the size of\n  stream data that was already received, or (3) an endpoint received a STREAM\n  frame or a RESET_STREAM frame containing a different final size to the one\n  already established.\n\nFRAME_ENCODING_ERROR (0x07):\n\n: An endpoint received a frame that was badly formatted -- for instance, a frame\n  of an unknown type or an ACK frame that has more acknowledgment ranges than\n  the remainder of the packet could carry.\n\nTRANSPORT_PARAMETER_ERROR (0x08):\n\n: An endpoint received transport parameters that were badly formatted, included\n  an invalid value, omitted a mandatory transport parameter, included a\n  forbidden transport parameter, or were otherwise in error.\n\nCONNECTION_ID_LIMIT_ERROR (0x09):\n\n: The number of connection IDs provided by the peer exceeds the advertised\n  active_connection_id_limit.\n\nPROTOCOL_VIOLATION (0x0a):\n\n: An endpoint detected an error with protocol compliance that was not covered by\n  more specific error codes.\n\nINVALID_TOKEN (0x0b):\n: A server received a client Initial that contained an invalid Token field.\n\nAPPLICATION_ERROR (0x0c):\n\n: The application or application protocol caused the connection to be closed.\n\nCRYPTO_BUFFER_EXCEEDED (0x0d):\n\n: An endpoint has received more data in CRYPTO frames than it can buffer.\n\nKEY_UPDATE_ERROR (0x0e):\n\n: An endpoint detected errors in performing key updates; see\n  {{Section 6 of QUIC-TLS}}.\n\nAEAD_LIMIT_REACHED (0x0f):\n\n: An endpoint has reached the confidentiality or integrity limit for the AEAD\n  algorithm used by the given connection.\n\nNO_VIABLE_PATH (0x10):\n\n: An endpoint has determined that the network path is incapable of supporting\n  QUIC.  An endpoint is unlikely to receive a CONNECTION_CLOSE frame carrying\n  this code except when the path does not support a large enough MTU.\n\nCRYPTO_ERROR (0x0100-0x01ff):\n\n: The cryptographic handshake failed.  A range of 256 values is reserved for\n  carrying error codes specific to the cryptographic handshake that is used.\n  Codes for errors occurring when TLS is used for the cryptographic handshake\n  are described in {{Section 4.8 of QUIC-TLS}}.\n\nSee {{iana-error-codes}} for details on registering new error codes.\n\nIn defining these error codes, several principles are applied.  Error conditions\nthat might require specific action on the part of a recipient are given unique\ncodes.  Errors that represent common conditions are given specific codes.\nAbsent either of these conditions, error codes are used to identify a general\nfunction of the stack, like flow control or transport parameter handling.\nFinally, generic errors are provided for conditions where implementations are\nunable or unwilling to use more specific codes.\n\n\n## Application Protocol Error Codes {#app-error-codes}\n\nThe management of application error codes is left to application protocols.\nApplication protocol error codes are used for the RESET_STREAM frame\n({{frame-reset-stream}}), the STOP_SENDING frame ({{frame-stop-sending}}), and\nthe CONNECTION_CLOSE frame with a type of 0x1d ({{frame-connection-close}}).\n\n\n# Security Considerations\n\nThe goal of QUIC is to provide a secure transport connection.\n{{security-properties}} provides an overview of those properties; subsequent\nsections discuss constraints and caveats regarding these properties, including\ndescriptions of known attacks and countermeasures.\n\n## Overview of Security Properties {#security-properties}\n\nA complete security analysis of QUIC is outside the scope of this document.\nThis section provides an informal description of the desired security properties\nas an aid to implementers and to help guide protocol analysis.\n\nQUIC assumes the threat model described in {{?SEC-CONS=RFC3552}} and provides\nprotections against many of the attacks that arise from that model.\n\nFor this purpose, attacks are divided into passive and active attacks.  Passive\nattackers have the ability to read packets from the network, while active\nattackers also have the ability to write packets into the network.  However, a\npassive attack could involve an attacker with the ability to cause a routing\nchange or other modification in the path taken by packets that comprise a\nconnection.\n\nAttackers are additionally categorized as either on-path attackers or off-path\nattackers.  An on-path attacker can read, modify, or remove any packet it\nobserves such that the packet no longer reaches its destination, while an\noff-path attacker observes the packets but cannot prevent the original packet\nfrom reaching its intended destination.  Both types of attackers can also\ntransmit arbitrary packets.  This definition differs from that of {{Section 3.5\nof SEC-CONS}} in that an off-path attacker is able to observe packets.\n\nProperties of the handshake, protected packets, and connection migration are\nconsidered separately.\n\n\n### Handshake {#handshake-properties}\n\nThe QUIC handshake incorporates the TLS 1.3 handshake and inherits the\ncryptographic properties described in {{Section E.1 of TLS13}}. Many\nof the security properties of QUIC depend on the TLS handshake providing these\nproperties. Any attack on the TLS handshake could affect QUIC.\n\nAny attack on the TLS handshake that compromises the secrecy or uniqueness\nof session keys, or the authentication of the participating peers, affects other\nsecurity guarantees provided by QUIC that depend on those keys. For instance,\nmigration ({{migration}}) depends on the efficacy of confidentiality\nprotections, both for the negotiation of keys using the TLS handshake and for\nQUIC packet protection, to avoid linkability across network paths.\n\nAn attack on the integrity of the TLS handshake might allow an attacker to\naffect the selection of application protocol or QUIC version.\n\nIn addition to the properties provided by TLS, the QUIC handshake provides some\ndefense against DoS attacks on the handshake.\n\n\n#### Anti-Amplification\n\nAddress validation ({{address-validation}}) is used to verify that an entity\nthat claims a given address is able to receive packets at that address. Address\nvalidation limits amplification attack targets to addresses for which an\nattacker can observe packets.\n\nPrior to address validation, endpoints are limited in what they are able to\nsend.  Endpoints cannot send data toward an unvalidated address in excess of\nthree times the data received from that address.\n\n<aside markdown=\"block\">\nNote: The anti-amplification limit only applies when an endpoint responds to\n  packets received from an unvalidated address. The anti-amplification limit\n  does not apply to clients when establishing a new connection or when\n  initiating connection migration.\n</aside>\n\n\n#### Server-Side DoS\n\nComputing the server's first flight for a full handshake is potentially\nexpensive, requiring both a signature and a key exchange computation. In order\nto prevent computational DoS attacks, the Retry packet provides a cheap token\nexchange mechanism that allows servers to validate a client's IP address prior\nto doing any expensive computations at the cost of a single round trip. After a\nsuccessful handshake, servers can issue new tokens to a client, which will allow\nnew connection establishment without incurring this cost.\n\n\n#### On-Path Handshake Termination\n\nAn on-path or off-path attacker can force a handshake to fail by replacing or\nracing Initial packets. Once valid Initial packets have been exchanged,\nsubsequent Handshake packets are protected with the Handshake keys, and an\non-path attacker cannot force handshake failure other than by dropping packets\nto cause endpoints to abandon the attempt.\n\nAn on-path attacker can also replace the addresses of packets on either side and\ntherefore cause the client or server to have an incorrect view of the remote\naddresses. Such an attack is indistinguishable from the functions performed by a\nNAT.\n\n\n#### Parameter Negotiation\n\nThe entire handshake is cryptographically protected, with the Initial packets\nbeing encrypted with per-version keys and the Handshake and later packets being\nencrypted with keys derived from the TLS key exchange.  Further, parameter\nnegotiation is folded into the TLS transcript and thus provides the same\nintegrity guarantees as ordinary TLS negotiation.  An attacker can observe\nthe client's transport parameters (as long as it knows the version-specific\nsalt) but cannot observe the server's transport parameters and cannot influence\nparameter negotiation.\n\nConnection IDs are unencrypted but integrity protected in all packets.\n\nThis version of QUIC does not incorporate a version negotiation mechanism;\nimplementations of incompatible versions will simply fail to establish a\nconnection.\n\n\n### Protected Packets {#protected-packet-properties}\n\nPacket protection ({{packet-protected}}) applies authenticated encryption\nto all packets except Version Negotiation packets, though Initial and Retry\npackets have limited protection due to the use of version-specific\nkeying material; see {{QUIC-TLS}} for more details. This section considers\npassive and active attacks against protected packets.\n\nBoth on-path and off-path attackers can mount a passive attack in which they\nsave observed packets for an offline attack against packet protection at a\nfuture time; this is true for any observer of any packet on any network.\n\nAn attacker that injects packets without being able to observe valid packets for\na connection is unlikely to be successful, since packet protection ensures that\nvalid packets are only generated by endpoints that possess the key material\nestablished during the handshake; see Sections {{<handshake}} and\n{{<handshake-properties}}. Similarly, any active attacker that observes packets\nand attempts to insert new data or modify existing data in those packets should\nnot be able to generate packets deemed valid by the receiving endpoint, other\nthan Initial packets.\n\nA spoofing attack, in which an active attacker rewrites unprotected parts of a\npacket that it forwards or injects, such as the source or destination\naddress, is only effective if the attacker can forward packets to the original\nendpoint.  Packet protection ensures that the packet payloads can only be\nprocessed by the endpoints that completed the handshake, and invalid\npackets are ignored by those endpoints.\n\nAn attacker can also modify the boundaries between packets and UDP datagrams,\ncausing multiple packets to be coalesced into a single datagram or splitting\ncoalesced packets into multiple datagrams. Aside from datagrams containing\nInitial packets, which require padding, modification of how packets are\narranged in datagrams has no functional effect on a connection, although it\nmight change some performance characteristics.\n\n\n### Connection Migration {#migration-properties}\n\nConnection migration ({{migration}}) provides endpoints with the ability to\ntransition between IP addresses and ports on multiple paths, using one path at a\ntime for transmission and receipt of non-probing frames.  Path validation\n({{migrate-validate}}) establishes that a peer is both willing and able\nto receive packets sent on a particular path.  This helps reduce the effects of\naddress spoofing by limiting the number of packets sent to a spoofed address.\n\nThis section describes the intended security properties of connection migration\nunder various types of DoS attacks.\n\n\n#### On-Path Active Attacks\n\nAn attacker that can cause a packet it observes to no longer reach its intended\ndestination is considered an on-path attacker. When an attacker is present\nbetween a client and server, endpoints are required to send packets through the\nattacker to establish connectivity on a given path.\n\nAn on-path attacker can:\n\n- Inspect packets\n- Modify IP and UDP packet headers\n- Inject new packets\n- Delay packets\n- Reorder packets\n- Drop packets\n- Split and merge datagrams along packet boundaries\n\nAn on-path attacker cannot:\n\n- Modify an authenticated portion of a packet and cause the recipient to accept\n  that packet\n\nAn on-path attacker has the opportunity to modify the packets that it observes;\nhowever, any modifications to an authenticated portion of a packet will cause it\nto be dropped by the receiving endpoint as invalid, as packet payloads are both\nauthenticated and encrypted.\n\nQUIC aims to constrain the capabilities of an on-path attacker as follows:\n\n1. An on-path attacker can prevent the use of a path for a connection,\n   causing the connection to fail if it cannot use a different path\n   that does not contain the attacker. This can be achieved by\n   dropping all packets, modifying them so that they fail to decrypt,\n   or other methods.\n\n2. An on-path attacker can prevent migration to a new path for which the\n   attacker is also on-path by causing path validation to fail on the new path.\n\n3. An on-path attacker cannot prevent a client from migrating to a path for\n   which the attacker is not on-path.\n\n4. An on-path attacker can reduce the throughput of a connection by delaying\n   packets or dropping them.\n\n5. An on-path attacker cannot cause an endpoint to accept a packet for which it\n   has modified an authenticated portion of that packet.\n\n\n#### Off-Path Active Attacks\n\nAn off-path attacker is not directly on the path between a client and server\nbut could be able to obtain copies of some or all packets sent between the\nclient and the server. It is also able to send copies of those packets to\neither endpoint.\n\nAn off-path attacker can:\n\n- Inspect packets\n- Inject new packets\n- Reorder injected packets\n\nAn off-path attacker cannot:\n\n- Modify packets sent by endpoints\n- Delay packets\n- Drop packets\n- Reorder original packets\n\nAn off-path attacker can create modified copies of packets that it has observed\nand inject those copies into the network, potentially with spoofed source and\ndestination addresses.\n\nFor the purposes of this discussion, it is assumed that an off-path attacker has\nthe ability to inject a modified copy of a packet into the network that will\nreach the destination endpoint prior to the arrival of the original packet\nobserved by the attacker. In other words, an attacker has the ability to\nconsistently \"win\" a race with the legitimate packets between the endpoints,\npotentially causing the original packet to be ignored by the recipient.\n\nIt is also assumed that an attacker has the resources necessary to affect NAT\nstate. In particular, an attacker can cause an endpoint to lose its NAT binding\nand then obtain the same port for use with its own traffic.\n\nQUIC aims to constrain the capabilities of an off-path attacker as follows:\n\n1. An off-path attacker can race packets and attempt to become a \"limited\"\n   on-path attacker.\n\n2. An off-path attacker can cause path validation to succeed for forwarded\n   packets with the source address listed as the off-path attacker as long as\n   it can provide improved connectivity between the client and the server.\n\n3. An off-path attacker cannot cause a connection to close once the handshake\n   has completed.\n\n4. An off-path attacker cannot cause migration to a new path to fail if it\n   cannot observe the new path.\n\n5. An off-path attacker can become a limited on-path attacker during migration\n   to a new path for which it is also an off-path attacker.\n\n6. An off-path attacker can become a limited on-path attacker by affecting\n   shared NAT state such that it sends packets to the server from the same IP\n   address and port that the client originally used.\n\n\n#### Limited On-Path Active Attacks\n\nA limited on-path attacker is an off-path attacker that has offered improved\nrouting of packets by duplicating and forwarding original packets between the\nserver and the client, causing those packets to arrive before the original\ncopies such that the original packets are dropped by the destination endpoint.\n\nA limited on-path attacker differs from an on-path attacker in that it is not on\nthe original path between endpoints, and therefore the original packets sent by\nan endpoint are still reaching their destination.  This means that a future\nfailure to route copied packets to the destination faster than their original\npath will not prevent the original packets from reaching the destination.\n\nA limited on-path attacker can:\n\n- Inspect packets\n- Inject new packets\n- Modify unencrypted packet headers\n- Reorder packets\n\nA limited on-path attacker cannot:\n\n- Delay packets so that they arrive later than packets sent on the original path\n- Drop packets\n- Modify the authenticated and encrypted portion of a packet and cause the\n recipient to accept that packet\n\nA limited on-path attacker can only delay packets up to the point that the\noriginal packets arrive before the duplicate packets, meaning that it cannot\noffer routing with worse latency than the original path.  If a limited on-path\nattacker drops packets, the original copy will still arrive at the destination\nendpoint.\n\nQUIC aims to constrain the capabilities of a limited off-path attacker as\nfollows:\n\n1. A limited on-path attacker cannot cause a connection to close once the\n   handshake has completed.\n\n2. A limited on-path attacker cannot cause an idle connection to close if the\n   client is first to resume activity.\n\n3. A limited on-path attacker can cause an idle connection to be deemed lost if\n   the server is the first to resume activity.\n\nNote that these guarantees are the same guarantees provided for any NAT, for the\nsame reasons.\n\n\n## Handshake Denial of Service {#handshake-dos}\n\nAs an encrypted and authenticated transport, QUIC provides a range of\nprotections against denial of service.  Once the cryptographic handshake is\ncomplete, QUIC endpoints discard most packets that are not authenticated,\ngreatly limiting the ability of an attacker to interfere with existing\nconnections.\n\nOnce a connection is established, QUIC endpoints might accept some\nunauthenticated ICMP packets (see {{pmtud}}), but the use of these packets is\nextremely limited.  The only other type of packet that an endpoint might accept\nis a stateless reset ({{stateless-reset}}), which relies on the token being kept\nsecret until it is used.\n\nDuring the creation of a connection, QUIC only provides protection against\nattacks from off the network path.  All QUIC packets contain proof that the\nrecipient saw a preceding packet from its peer.\n\nAddresses cannot change during the handshake, so endpoints can discard packets\nthat are received on a different network path.\n\nThe Source and Destination Connection ID fields are the primary means of\nprotection against an off-path attack during the handshake; see\n{{validate-handshake}}.  These are required to match those set by a peer.\nExcept for Initial packets and Stateless Resets, an endpoint only accepts\npackets that include a Destination Connection ID field that matches a value the\nendpoint previously chose.  This is the only protection offered for Version\nNegotiation packets.\n\nThe Destination Connection ID field in an Initial packet is selected by a client\nto be unpredictable, which serves an additional purpose.  The packets that carry\nthe cryptographic handshake are protected with a key that is derived from this\nconnection ID and a salt specific to the QUIC version.  This allows endpoints to\nuse the same process for authenticating packets that they receive as they use\nafter the cryptographic handshake completes.  Packets that cannot be\nauthenticated are discarded.  Protecting packets in this fashion provides a\nstrong assurance that the sender of the packet saw the Initial packet and\nunderstood it.\n\nThese protections are not intended to be effective against an attacker that is\nable to receive QUIC packets prior to the connection being established.  Such an\nattacker can potentially send packets that will be accepted by QUIC endpoints.\nThis version of QUIC attempts to detect this sort of attack, but it expects that\nendpoints will fail to establish a connection rather than recovering.  For the\nmost part, the cryptographic handshake protocol {{QUIC-TLS}} is responsible for\ndetecting tampering during the handshake.\n\nEndpoints are permitted to use other methods to detect and attempt to recover\nfrom interference with the handshake.  Invalid packets can be identified and\ndiscarded using other methods, but no specific method is mandated in this\ndocument.\n\n\n## Amplification Attack\n\nAn attacker might be able to receive an address validation token\n({{address-validation}}) from a server and then release the IP address it used\nto acquire that token.  At a later time, the attacker can initiate a 0-RTT\nconnection with a server by spoofing this same address, which might now address\na different (victim) endpoint.  The attacker can thus potentially cause the\nserver to send an initial congestion window's worth of data towards the victim.\n\nServers SHOULD provide mitigations for this attack by limiting the usage and\nlifetime of address validation tokens; see {{validate-future}}.\n\n\n## Optimistic ACK Attack {#optimistic-ack-attack}\n\nAn endpoint that acknowledges packets it has not received might cause a\ncongestion controller to permit sending at rates beyond what the network\nsupports.  An endpoint MAY skip packet numbers when sending packets to detect\nthis behavior.  An endpoint can then immediately close the connection with a\nconnection error of type PROTOCOL_VIOLATION; see {{immediate-close}}.\n\n\n## Request Forgery Attacks\n\nA request forgery attack occurs where an endpoint causes its peer to issue a\nrequest towards a victim, with the request controlled by the endpoint. Request\nforgery attacks aim to provide an attacker with access to capabilities of its\npeer that might otherwise be unavailable to the attacker. For a networking\nprotocol, a request forgery attack is often used to exploit any implicit\nauthorization conferred on the peer by the victim due to the peer's location in\nthe network.\n\nFor request forgery to be effective, an attacker needs to be able to influence\nwhat packets the peer sends and where these packets are sent. If an attacker\ncan target a vulnerable service with a controlled payload, that service might\nperform actions that are attributed to the attacker's peer but are decided by\nthe attacker.\n\nFor example, cross-site request forgery {{?CSRF=DOI.10.1145/1455770.1455782}}\nexploits on the Web cause a client to issue requests that include authorization\ncookies {{?COOKIE=RFC6265}}, allowing one site access to information and\nactions that are intended to be restricted to a different site.\n\nAs QUIC runs over UDP, the primary attack modality of concern is one where an\nattacker can select the address to which its peer sends UDP datagrams and can\ncontrol some of the unprotected content of those packets. As much of the data\nsent by QUIC endpoints is protected, this includes control over ciphertext. An\nattack is successful if an attacker can cause a peer to send a UDP datagram to\na host that will perform some action based on content in the datagram.\n\nThis section discusses ways in which QUIC might be used for request forgery\nattacks.\n\nThis section also describes limited countermeasures that can be implemented by\nQUIC endpoints. These mitigations can be employed unilaterally by a QUIC\nimplementation or deployment, without potential targets for request forgery\nattacks taking action. However, these countermeasures could be insufficient if\nUDP-based services do not properly authorize requests.\n\nBecause the migration attack described in\n{{request-forgery-with-spoofed-migration}} is quite powerful and does not have\nadequate countermeasures, QUIC server implementations should assume that\nattackers can cause them to generate arbitrary UDP payloads to arbitrary\ndestinations. QUIC servers SHOULD NOT be deployed in networks that do not deploy\ningress filtering {{!BCP38}} and also have inadequately secured UDP endpoints.\n\nAlthough it is not generally possible to ensure that clients are not co-located\nwith vulnerable endpoints, this version of QUIC does not allow servers to\nmigrate, thus preventing spoofed migration attacks on clients.  Any future\nextension that allows server migration MUST also define countermeasures for\nforgery attacks.\n\n\n### Control Options for Endpoints\n\nQUIC offers some opportunities for an attacker to influence or control where\nits peer sends UDP datagrams:\n\n* initial connection establishment ({{handshake}}), where a server is able to\n  choose where a client sends datagrams -- for example, by populating DNS\n  records;\n\n* preferred addresses ({{preferred-address}}), where a server is able to choose\n  where a client sends datagrams;\n\n* spoofed connection migrations ({{address-spoofing}}), where a client is able\n  to use source address spoofing to select where a server sends subsequent\n  datagrams; and\n\n* spoofed packets that cause a server to send a Version Negotiation packet\n  ({{vn-spoofing}}).\n\nIn all cases, the attacker can cause its peer to send datagrams to a\nvictim that might not understand QUIC. That is, these packets are sent by\nthe peer prior to address validation; see {{address-validation}}.\n\nOutside of the encrypted portion of packets, QUIC offers an endpoint several\noptions for controlling the content of UDP datagrams that its peer sends. The\nDestination Connection ID field offers direct control over bytes that appear\nearly in packets sent by the peer; see {{connection-id}}. The Token field in\nInitial packets offers a server control over other bytes of Initial packets;\nsee {{packet-initial}}.\n\nThere are no measures in this version of QUIC to prevent indirect control over\nthe encrypted portions of packets. It is necessary to assume that endpoints are\nable to control the contents of frames that a peer sends, especially those\nframes that convey application data, such as STREAM frames. Though this depends\nto some degree on details of the application protocol, some control is possible\nin many protocol usage contexts. As the attacker has access to packet\nprotection keys, they are likely to be capable of predicting how a peer will\nencrypt future packets. Successful control over datagram content then only\nrequires that the attacker be able to predict the packet number and placement\nof frames in packets with some amount of reliability.\n\nThis section assumes that limiting control over datagram content is not\nfeasible. The focus of the mitigations in subsequent sections is on limiting\nthe ways in which datagrams that are sent prior to address validation can be\nused for request forgery.\n\n\n### Request Forgery with Client Initial Packets\n\nAn attacker acting as a server can choose the IP address and port on which it\nadvertises its availability, so Initial packets from clients are assumed to be\navailable for use in this sort of attack. The address validation implicit in the\nhandshake ensures that -- for a new connection -- a client will not send other\ntypes of packets to a destination that does not understand QUIC or is not\nwilling to accept a QUIC connection.\n\nInitial packet protection ({{Section 5.2 of QUIC-TLS}}) makes it difficult for\nservers to control the content of Initial packets sent by clients. A client\nchoosing an unpredictable Destination Connection ID ensures that servers are\nunable to control any of the encrypted portion of Initial packets from clients.\n\nHowever, the Token field is open to server control and does allow a server to\nuse clients to mount request forgery attacks. The use of tokens provided with\nthe NEW_TOKEN frame ({{validate-future}}) offers the only option for request\nforgery during connection establishment.\n\nClients, however, are not obligated to use the NEW_TOKEN frame. Request forgery\nattacks that rely on the Token field can be avoided if clients send an empty\nToken field when the server address has changed from when the NEW_TOKEN frame\nwas received.\n\nClients could avoid using NEW_TOKEN if the server address changes. However, not\nincluding a Token field could adversely affect performance. Servers could rely\non NEW_TOKEN to enable the sending of data in excess of the three-times limit on\nsending data; see {{validate-handshake}}. In particular, this affects cases\nwhere clients use 0-RTT to request data from servers.\n\nSending a Retry packet ({{packet-retry}}) offers a server the option to change\nthe Token field. After sending a Retry, the server can also control the\nDestination Connection ID field of subsequent Initial packets from the client.\nThis also might allow indirect control over the encrypted content of Initial\npackets. However, the exchange of a Retry packet validates the server's\naddress, thereby preventing the use of subsequent Initial packets for request\nforgery.\n\n\n### Request Forgery with Preferred Addresses {#forgery-spa}\n\nServers can specify a preferred address, which clients then migrate to after\nconfirming the handshake; see {{preferred-address}}. The Destination Connection\nID field of packets that the client sends to a preferred address can be used\nfor request forgery.\n\nA client MUST NOT send non-probing frames to a preferred address prior to\nvalidating that address; see {{address-validation}}. This greatly reduces the\noptions that a server has to control the encrypted portion of datagrams.\n\nThis document does not offer any additional countermeasures that are specific to\nthe use of preferred addresses and can be implemented by endpoints. The generic\nmeasures described in {{forgery-generic}} could be used as further mitigation.\n\n\n### Request Forgery with Spoofed Migration\n\nClients are able to present a spoofed source address as part of an apparent\nconnection migration to cause a server to send datagrams to that address.\n\nThe Destination Connection ID field in any packets that a server subsequently\nsends to this spoofed address can be used for request forgery. A client might\nalso be able to influence the ciphertext.\n\nA server that only sends probing packets ({{probing}}) to an address prior to\naddress validation provides an attacker with only limited control over the\nencrypted portion of datagrams. However, particularly for NAT rebinding, this\ncan adversely affect performance. If the server sends frames carrying\napplication data, an attacker might be able to control most of the content of\ndatagrams.\n\nThis document does not offer specific countermeasures that can be implemented by\nendpoints, aside from the generic measures described in {{forgery-generic}}.\nHowever, countermeasures for address spoofing at the network level -- in\nparticular, ingress filtering {{?BCP38}} -- are especially effective against\nattacks that use spoofing and originate from an external network.\n\n\n### Request Forgery with Version Negotiation {#vn-spoofing}\n\nClients that are able to present a spoofed source address on a packet can cause\na server to send a Version Negotiation packet ({{packet-version}}) to that\naddress.\n\nThe absence of size restrictions on the connection ID fields for packets of an\nunknown version increases the amount of data that the client controls from the\nresulting datagram.  The first byte of this packet is not under client control\nand the next four bytes are zero, but the client is able to control up to 512\nbytes starting from the fifth byte.\n\nNo specific countermeasures are provided for this attack, though generic\nprotections ({{forgery-generic}}) could apply.  In this case, ingress filtering\n{{?BCP38}} is also effective.\n\n\n### Generic Request Forgery Countermeasures {#forgery-generic}\n\nThe most effective defense against request forgery attacks is to modify\nvulnerable services to use strong authentication. However, this is not always\nsomething that is within the control of a QUIC deployment. This section outlines\nsome other steps that QUIC endpoints could take unilaterally. These additional\nsteps are all discretionary because, depending on circumstances, they could\ninterfere with or prevent legitimate uses.\n\nServices offered over loopback interfaces often lack proper authentication.\nEndpoints MAY prevent connection attempts or migration to a loopback address.\nEndpoints SHOULD NOT allow connections or migration to a loopback address if the\nsame service was previously available at a different interface or if the address\nwas provided by a service at a non-loopback address. Endpoints that depend on\nthese capabilities could offer an option to disable these protections.\n\nSimilarly, endpoints could regard a change in address to a link-local address\n{{?RFC4291}} or an address in a private-use range {{?RFC1918}} from a global,\nunique-local {{?RFC4193}}, or non-private address as a potential attempt at\nrequest forgery. Endpoints could refuse to use these addresses entirely, but\nthat carries a significant risk of interfering with legitimate uses. Endpoints\nSHOULD NOT refuse to use an address unless they have specific knowledge about\nthe network indicating that sending datagrams to unvalidated addresses in a\ngiven range is not safe.\n\nEndpoints MAY choose to reduce the risk of request forgery by not including\nvalues from NEW_TOKEN frames in Initial packets or by only sending probing\nframes in packets prior to completing address validation. Note that this does\nnot prevent an attacker from using the Destination Connection ID field for an\nattack.\n\nEndpoints are not expected to have specific information about the location of\nservers that could be vulnerable targets of a request forgery attack. However,\nit might be possible over time to identify specific UDP ports that are common\ntargets of attacks or particular patterns in datagrams that are used for\nattacks. Endpoints MAY choose to avoid sending datagrams to these ports or not\nsend datagrams that match these patterns prior to validating the destination\naddress. Endpoints MAY retire connection IDs containing patterns known to be\nproblematic without using them.\n\n<aside markdown=\"block\">\nNote: Modifying endpoints to apply these protections is more efficient than\n  deploying network-based protections, as endpoints do not need to perform any\n  additional processing when sending to an address that has been validated.\n</aside>\n\n\n## Slowloris Attacks\n\nThe attacks commonly known as Slowloris {{SLOWLORIS}} try to keep many\nconnections to the target endpoint open and hold them open as long as possible.\nThese attacks can be executed against a QUIC endpoint by generating the minimum\namount of activity necessary to avoid being closed for inactivity.  This might\ninvolve sending small amounts of data, gradually opening flow control windows in\norder to control the sender rate, or manufacturing ACK frames that simulate a\nhigh loss rate.\n\nQUIC deployments SHOULD provide mitigations for the Slowloris attacks, such as\nincreasing the maximum number of clients the server will allow, limiting the\nnumber of connections a single IP address is allowed to make, imposing\nrestrictions on the minimum transfer speed a connection is allowed to have, and\nrestricting the length of time an endpoint is allowed to stay connected.\n\n\n## Stream Fragmentation and Reassembly Attacks\n\nAn adversarial sender might intentionally not send portions of the stream data,\ncausing the receiver to commit resources for the unsent data. This could\ncause a disproportionate receive buffer memory commitment and/or the creation of\na large and inefficient data structure at the receiver.\n\nAn adversarial receiver might intentionally not acknowledge packets containing\nstream data in an attempt to force the sender to store the unacknowledged stream\ndata for retransmission.\n\nThe attack on receivers is mitigated if flow control windows correspond to\navailable memory.  However, some receivers will overcommit memory and advertise\nflow control offsets in the aggregate that exceed actual available memory.  The\novercommitment strategy can lead to better performance when endpoints are well\nbehaved, but renders endpoints vulnerable to the stream fragmentation attack.\n\nQUIC deployments SHOULD provide mitigations for stream fragmentation attacks.\nMitigations could consist of avoiding overcommitting memory, limiting the size\nof tracking data structures, delaying reassembly of STREAM frames, implementing\nheuristics based on the age and duration of reassembly holes, or some\ncombination of these.\n\n\n## Stream Commitment Attack\n\nAn adversarial endpoint can open a large number of streams, exhausting state on\nan endpoint.  The adversarial endpoint could repeat the process on a large\nnumber of connections, in a manner similar to SYN flooding attacks in TCP.\n\nNormally, clients will open streams sequentially, as explained in {{stream-id}}.\nHowever, when several streams are initiated at short intervals, loss or\nreordering can cause STREAM frames that open streams to be received out of\nsequence.  On receiving a higher-numbered stream ID, a receiver is required to\nopen all intervening streams of the same type; see {{stream-recv-states}}.\nThus, on a new connection, opening stream 4000000 opens 1 million and 1\nclient-initiated bidirectional streams.\n\nThe number of active streams is limited by the initial_max_streams_bidi and\ninitial_max_streams_uni transport parameters as updated by any received\nMAX_STREAMS frames, as explained in\n{{controlling-concurrency}}.  If chosen judiciously, these limits mitigate the\neffect of the stream commitment attack.  However, setting the limit too low\ncould affect performance when applications expect to open a large number of\nstreams.\n\n\n## Peer Denial of Service {#useless}\n\nQUIC and TLS both contain frames or messages that have legitimate uses in some\ncontexts, but these frames or messages can be abused to cause a peer to expend\nprocessing resources without having any observable impact on the state of the\nconnection.\n\nMessages can also be used to change and revert state in small or inconsequential\nways, such as by sending small increments to flow control limits.\n\nIf processing costs are disproportionately large in comparison to bandwidth\nconsumption or effect on state, then this could allow a malicious peer to\nexhaust processing capacity.\n\nWhile there are legitimate uses for all messages, implementations SHOULD track\ncost of processing relative to progress and treat excessive quantities of any\nnon-productive packets as indicative of an attack.  Endpoints MAY respond to\nthis condition with a connection error or by dropping packets.\n\n\n## Explicit Congestion Notification Attacks {#security-ecn}\n\nAn on-path attacker could manipulate the value of ECN fields in the IP header\nto influence the sender's rate. {{!RFC3168}} discusses manipulations and their\neffects in more detail.\n\nA limited on-path attacker can duplicate and send packets with modified ECN\nfields to affect the sender's rate. If duplicate packets are discarded by a\nreceiver, an attacker will need to race the duplicate packet against the\noriginal to be successful in this attack. Therefore, QUIC endpoints ignore the\nECN field in an IP packet unless at least one QUIC packet in that IP packet is\nsuccessfully processed; see {{ecn}}.\n\n\n## Stateless Reset Oracle {#reset-oracle}\n\nStateless resets create a possible denial-of-service attack analogous to a TCP\nreset injection. This attack is possible if an attacker is able to cause a\nstateless reset token to be generated for a connection with a selected\nconnection ID. An attacker that can cause this token to be generated can reset\nan active connection with the same connection ID.\n\nIf a packet can be routed to different instances that share a static key -- for\nexample, by changing an IP address or port -- then an attacker can cause the\nserver to send a stateless reset.  To defend against this style of denial of\nservice, endpoints that share a static key for stateless resets (see\n{{reset-token}}) MUST be arranged so that packets with a given connection ID\nalways arrive at an instance that has connection state, unless that connection\nis no longer active.\n\nMore generally, servers MUST NOT generate a stateless reset if a connection with\nthe corresponding connection ID could be active on any endpoint using the same\nstatic key.\n\nIn the case of a cluster that uses dynamic load balancing, it is possible that a\nchange in load-balancer configuration could occur while an active instance\nretains connection state.  Even if an instance retains connection state, the\nchange in routing and resulting stateless reset will result in the connection\nbeing terminated.  If there is no chance of the packet being routed to the\ncorrect instance, it is better to send a stateless reset than wait for the\nconnection to time out.  However, this is acceptable only if the routing cannot\nbe influenced by an attacker.\n\n\n## Version Downgrade {#version-downgrade}\n\nThis document defines QUIC Version Negotiation packets\n({{version-negotiation}}), which can be used to negotiate the QUIC version used\nbetween two endpoints. However, this document does not specify how this\nnegotiation will be performed between this version and subsequent future\nversions.  In particular, Version Negotiation packets do not contain any\nmechanism to prevent version downgrade attacks.  Future versions of QUIC that\nuse Version Negotiation packets MUST define a mechanism that is robust against\nversion downgrade attacks.\n\n\n## Targeted Attacks by Routing\n\nDeployments should limit the ability of an attacker to target a new connection\nto a particular server instance.  Ideally, routing decisions are made\nindependently of client-selected values, including addresses.  Once an instance\nis selected, a connection ID can be selected so that later packets are routed to\nthe same instance.\n\n\n## Traffic Analysis\n\nThe length of QUIC packets can reveal information about the length of the\ncontent of those packets.  The PADDING frame is provided so that endpoints have\nsome ability to obscure the length of packet content; see {{frame-padding}}.\n\nDefeating traffic analysis is challenging and the subject of active research.\nLength is not the only way that information might leak.  Endpoints might also\nreveal sensitive information through other side channels, such as the timing of\npackets.\n\n\n# IANA Considerations {#iana}\n\nThis document establishes several registries for the management of codepoints in\nQUIC.  These registries operate on a common set of policies as defined in\n{{iana-policy}}.\n\n\n## Registration Policies for QUIC Registries {#iana-policy}\n\nAll QUIC registries allow for both provisional and permanent registration of\ncodepoints.  This section documents policies that are common to these\nregistries.\n\n\n### Provisional Registrations {#iana-provisional}\n\nProvisional registrations of codepoints are intended to allow for private use\nand experimentation with extensions to QUIC.  Provisional registrations only\nrequire the inclusion of the codepoint value and contact information.  However,\nprovisional registrations could be reclaimed and reassigned for another purpose.\n\nProvisional registrations require Expert Review, as defined in {{Section 4.5 of\nRFC8126}}. The designated expert or experts are advised that only registrations\nfor an excessive proportion of remaining codepoint space or the very first\nunassigned value (see {{iana-random}}) can be rejected.\n\nProvisional registrations will include a Date field that indicates when the\nregistration was last updated.  A request to update the date on any provisional\nregistration can be made without review from the designated expert(s).\n\nAll QUIC registries include the following fields to support provisional\nregistration:\n\nValue:\n: The assigned codepoint.\n\nStatus:\n: \"permanent\" or \"provisional\".\n\nSpecification:\n: A reference to a publicly available specification for the value.\n\nDate:\n: The date of the last update to the registration.\n\nChange Controller:\n: The entity that is responsible for the definition of the registration.\n\nContact:\n: Contact details for the registrant.\n\nNotes:\n: Supplementary notes about the registration.\n{: spacing=\"compact\"}\n\nProvisional registrations MAY omit the Specification and Notes fields, plus any\nadditional fields that might be required for a permanent registration.  The Date\nfield is not required as part of requesting a registration, as it is set to the\ndate the registration is created or updated.\n\n\n### Selecting Codepoints {#iana-random}\n\nNew requests for codepoints from QUIC registries SHOULD use a randomly selected\ncodepoint that excludes both existing allocations and the first unallocated\ncodepoint in the selected space.  Requests for multiple codepoints MAY use a\ncontiguous range.  This minimizes the risk that differing semantics are\nattributed to the same codepoint by different implementations.\n\nThe use of the first unassigned codepoint is reserved for allocation using the\nStandards Action policy; see {{Section 4.9 of RFC8126}}.  The early codepoint\nassignment process {{!EARLY-ASSIGN=RFC7120}} can be used for these values.\n\nFor codepoints that are encoded in variable-length integers\n({{integer-encoding}}), such as frame types, codepoints that encode to four or\neight bytes (that is, values 2<sup>14</sup> and above) SHOULD be used unless the\nusage is especially sensitive to having a longer encoding.\n\nApplications to register codepoints in QUIC registries MAY include a\nrequested codepoint\nas part of the registration.  IANA MUST allocate the selected codepoint if the\ncodepoint is unassigned and the requirements of the registration policy are met.\n\n\n### Reclaiming Provisional Codepoints\n\nA request might be made to remove an unused provisional registration from the\nregistry to reclaim space in a registry, or a portion of the registry (such as\nthe 64-16383 range for codepoints that use variable-length encodings).  This\nSHOULD be done only for the codepoints with the earliest recorded date, and\nentries that have been updated less than a year prior SHOULD NOT be reclaimed.\n\nA request to remove a codepoint MUST be reviewed by the designated experts.  The\nexperts MUST attempt to determine whether the codepoint is still in use.\nExperts are advised to contact the listed contacts for the registration, plus as\nwide a set of protocol implementers as possible in order to determine whether\nany use of the codepoint is known.  The experts are also advised to allow at\nleast four weeks for responses.\n\nIf any use of the codepoints is identified by this search or a request to update\nthe registration is made, the codepoint MUST NOT be reclaimed.  Instead, the\ndate on the registration is updated.  A note might be added for the registration\nrecording relevant information that was learned.\n\nIf no use of the codepoint was identified and no request was made to update the\nregistration, the codepoint MAY be removed from the registry.\n\nThis review and consultation process also applies to requests to change a\nprovisional registration into a permanent registration, except that the goal is\nnot to determine whether there is no use of the codepoint but to determine that\nthe registration is an accurate representation of any deployed usage.\n\n\n### Permanent Registrations {#iana-permanent}\n\nPermanent registrations in QUIC registries use the Specification Required policy\n({{Section 4.6 of RFC8126}}), unless otherwise specified.  The designated expert\nor experts verify that a specification exists and is readily accessible.\nExperts are encouraged to be biased towards approving registrations unless they\nare abusive, frivolous, or actively harmful (not merely aesthetically\ndispleasing or architecturally dubious).  The creation of a registry MAY specify\nadditional constraints on permanent registrations.\n\nThe creation of a registry MAY identify a range of codepoints where\nregistrations are governed by a different registration policy.  For instance,\nthe \"QUIC Frame Types\" registry ({{iana-frames}}) has a stricter policy for\ncodepoints in the range from 0 to 63.\n\nAny stricter requirements for permanent registrations do not prevent provisional\nregistrations for affected codepoints.  For instance, a provisional registration\nfor a frame type of 61 could be requested.\n\nAll registrations made by Standards Track publications MUST be permanent.\n\nAll registrations in this document are assigned a permanent status and list a\nchange controller of the IETF and a contact of the QUIC Working Group\n(quic@ietf.org).\n\n\n## QUIC Versions Registry {#iana-version}\n\nIANA has added a registry for \"QUIC Versions\" under a \"QUIC\" heading.\n\nThe \"QUIC Versions\" registry governs a 32-bit space; see {{versions}}. This\nregistry follows the registration policy from {{iana-policy}}. Permanent\nregistrations in this registry are assigned using the Specification Required\npolicy ({{Section 4.6 of RFC8126}}).\n\nThe codepoint of 0x00000001 for the protocol is assigned with permanent status\nto the protocol defined in this document. The codepoint of 0x00000000 is\npermanently reserved; the note for this codepoint indicates that this version is\nreserved for version negotiation.\n\nAll codepoints that follow the pattern 0x?a?a?a?a are reserved, MUST NOT be\nassigned by IANA, and MUST NOT appear in the listing of assigned values.\n\n\n## QUIC Transport Parameters Registry {#iana-transport-parameters}\n\nIANA has added a registry for \"QUIC Transport Parameters\" under a \"QUIC\"\nheading.\n\nThe \"QUIC Transport Parameters\" registry governs a 62-bit space.  This registry\nfollows the registration policy from {{iana-policy}}.  Permanent registrations\nin this registry are assigned using the Specification Required policy ({{Section\n4.6 of RFC8126}}), except for values between 0x00 and 0x3f (in hexadecimal),\ninclusive, which are assigned using Standards Action or IESG Approval as defined\nin {{Sections 4.9 and 4.10 of RFC8126}}.\n\nIn addition to the fields listed in {{iana-provisional}}, permanent\nregistrations in this registry MUST include the following field:\n\nParameter Name:\n\n: A short mnemonic for the parameter.\n\nThe initial contents of this registry are shown in {{iana-tp-table}}.\n\n| Value| Parameter Name              | Specification                       |\n|:-----|:----------------------------|:------------------------------------|\n| 0x00 | original_destination_connection_id | {{transport-parameter-definitions}} |\n| 0x01 | max_idle_timeout            | {{transport-parameter-definitions}} |\n| 0x02 | stateless_reset_token       | {{transport-parameter-definitions}} |\n| 0x03 | max_udp_payload_size        | {{transport-parameter-definitions}} |\n| 0x04 | initial_max_data            | {{transport-parameter-definitions}} |\n| 0x05 | initial_max_stream_data_bidi_local | {{transport-parameter-definitions}} |\n| 0x06 | initial_max_stream_data_bidi_remote | {{transport-parameter-definitions}} |\n| 0x07 | initial_max_stream_data_uni | {{transport-parameter-definitions}} |\n| 0x08 | initial_max_streams_bidi    | {{transport-parameter-definitions}} |\n| 0x09 | initial_max_streams_uni     | {{transport-parameter-definitions}} |\n| 0x0a | ack_delay_exponent          | {{transport-parameter-definitions}} |\n| 0x0b | max_ack_delay               | {{transport-parameter-definitions}} |\n| 0x0c | disable_active_migration    | {{transport-parameter-definitions}} |\n| 0x0d | preferred_address           | {{transport-parameter-definitions}} |\n| 0x0e | active_connection_id_limit  | {{transport-parameter-definitions}} |\n| 0x0f | initial_source_connection_id | {{transport-parameter-definitions}} |\n| 0x10 | retry_source_connection_id  | {{transport-parameter-definitions}} |\n{: #iana-tp-table title=\"Initial QUIC Transport Parameters Registry Entries\"}\n\nEach value of the form `31 * N + 27` for integer values of N (that is, 27, 58,\n89, ...) are reserved; these values MUST NOT be assigned by IANA and MUST NOT\nappear in the listing of assigned values.\n\n\n## QUIC Frame Types Registry {#iana-frames}\n\nIANA has added a registry for \"QUIC Frame Types\" under a \"QUIC\" heading.\n\nThe \"QUIC Frame Types\" registry governs a 62-bit space. This registry follows\nthe registration policy from {{iana-policy}}. Permanent registrations in this\nregistry are assigned using the Specification Required policy ({{Section 4.6 of\nRFC8126}}), except for values between 0x00 and 0x3f (in hexadecimal), inclusive,\nwhich are assigned using Standards Action or IESG Approval as defined in\n{{Sections 4.9 and 4.10 of RFC8126}}.\n\nIn addition to the fields listed in {{iana-provisional}}, permanent\nregistrations in this registry MUST include the following field:\n\nFrame Type Name:\n\n: A short mnemonic for the frame type.\n\nIn addition to the advice in {{iana-policy}}, specifications for new permanent\nregistrations SHOULD describe the means by which an endpoint might determine\nthat it can send the identified type of frame.  An accompanying transport\nparameter registration is expected for most registrations; see\n{{iana-transport-parameters}}.  Specifications for permanent registrations also\nneed to describe the format and assigned semantics of any fields in the frame.\n\nThe initial contents of this registry are tabulated in {{frame-types}}.  Note\nthat the registry does not include the \"Pkts\" and \"Spec\" columns from\n{{frame-types}}.\n\n\n## QUIC Transport Error Codes Registry {#iana-error-codes}\n\nIANA has added a registry for \"QUIC Transport Error Codes\" under a \"QUIC\"\nheading.\n\nThe \"QUIC Transport Error Codes\" registry governs a 62-bit space.  This space is\nsplit into three ranges that are governed by different policies.  Permanent\nregistrations in this registry are assigned using the Specification Required\npolicy ({{Section 4.6 of RFC8126}}), except for values between 0x00 and 0x3f (in\nhexadecimal), inclusive, which are assigned using Standards Action or IESG\nApproval as defined in {{Sections 4.9 and 4.10 of RFC8126}}.\n\nIn addition to the fields listed in {{iana-provisional}}, permanent\nregistrations in this registry MUST include the following fields:\n\nCode:\n\n: A short mnemonic for the parameter.\n\nDescription:\n\n: A brief description of the error code semantics, which MAY be a summary if a\n  specification reference is provided.\n\nThe initial contents of this registry are shown in {{iana-error-table}}.\n\n| Value | Code                      | Description                   | Specification   |\n|:------|:--------------------------|:------------------------------|:----------------|\n| 0x00  | NO_ERROR                  | No error                      | {{error-codes}} |\n| 0x01  | INTERNAL_ERROR            | Implementation error          | {{error-codes}} |\n| 0x02  | CONNECTION_REFUSED        | Server refuses a connection   | {{error-codes}} |\n| 0x03  | FLOW_CONTROL_ERROR        | Flow control error            | {{error-codes}} |\n| 0x04  | STREAM_LIMIT_ERROR        | Too many streams opened       | {{error-codes}} |\n| 0x05  | STREAM_STATE_ERROR        | Frame received in invalid stream state | {{error-codes}} |\n| 0x06  | FINAL_SIZE_ERROR          | Change to final size          | {{error-codes}} |\n| 0x07  | FRAME_ENCODING_ERROR      | Frame encoding error          | {{error-codes}} |\n| 0x08  | TRANSPORT_PARAMETER_ERROR | Error in transport parameters | {{error-codes}} |\n| 0x09  | CONNECTION_ID_LIMIT_ERROR | Too many connection IDs received | {{error-codes}} |\n| 0x0a  | PROTOCOL_VIOLATION        | Generic protocol violation    | {{error-codes}} |\n| 0x0b  | INVALID_TOKEN             | Invalid Token received        | {{error-codes}} |\n| 0x0c  | APPLICATION_ERROR         | Application error             | {{error-codes}} |\n| 0x0d  | CRYPTO_BUFFER_EXCEEDED    | CRYPTO data buffer overflowed | {{error-codes}} |\n| 0x0e  | KEY_UPDATE_ERROR          | Invalid packet protection update | {{error-codes}} |\n| 0x0f  | AEAD_LIMIT_REACHED        | Excessive use of packet protection keys | {{error-codes}} |\n| 0x10  | NO_VIABLE_PATH            | No viable network path exists | {{error-codes}} |\n| 0x0100-​0x01ff | CRYPTO_ERROR      | TLS alert code                | {{error-codes}} |\n{: #iana-error-table title=\"Initial QUIC Transport Error Codes Registry Entries\"}\n\n\n--- back\n\n# Pseudocode\n\nThe pseudocode in this section describes sample algorithms.  These algorithms\nare intended to be correct and clear, rather than being optimally performant.\n\nThe pseudocode segments in this section are licensed as Code Components; see the\nCopyright Notice.\n\n\n## Sample Variable-Length Integer Decoding {#sample-varint}\n\nThe pseudocode in {{alg-varint}} shows how a variable-length integer can be read\nfrom a stream of bytes.  The function ReadVarint takes a single argument -- a\nsequence of bytes, which can be read in network byte order.\n\n~~~pseudocode\nReadVarint(data):\n  // The length of variable-length integers is encoded in the\n  // first two bits of the first byte.\n  v = data.next_byte()\n  prefix = v >> 6\n  length = 1 << prefix\n\n  // Once the length is known, remove these bits and read any\n  // remaining bytes.\n  v = v & 0x3f\n  repeat length-1 times:\n    v = (v << 8) + data.next_byte()\n  return v\n~~~\n{: #alg-varint title=\"Sample Variable-Length Integer Decoding Algorithm\"}\n\nFor example, the eight-byte sequence 0xc2197c5eff14e88c decodes to the decimal\nvalue 151,288,809,941,952,652; the four-byte sequence 0x9d7f3e7d decodes to\n494,878,333; the two-byte sequence 0x7bbd decodes to 15,293; and the single byte\n0x25 decodes to 37 (as does the two-byte sequence 0x4025).\n\n\n## Sample Packet Number Encoding Algorithm {#sample-packet-number-encoding}\n\nThe pseudocode in {{alg-encode-pn}} shows how an implementation can select\nan appropriate size for packet number encodings.\n\nThe EncodePacketNumber function takes two arguments:\n\n* full_pn is the full packet number of the packet being sent.\n* largest_acked is the largest packet number that has been acknowledged by the\n  peer in the current packet number space, if any.\n\n~~~pseudocode\nEncodePacketNumber(full_pn, largest_acked):\n\n  // The number of bits must be at least one more\n  // than the base-2 logarithm of the number of contiguous\n  // unacknowledged packet numbers, including the new packet.\n  if largest_acked is None:\n    num_unacked = full_pn + 1\n  else:\n    num_unacked = full_pn - largest_acked\n\n  min_bits = log(num_unacked, 2) + 1\n  num_bytes = ceil(min_bits / 8)\n\n  // Encode the integer value and truncate to\n  // the num_bytes least significant bytes.\n  return encode(full_pn, num_bytes)\n~~~\n{: #alg-encode-pn title=\"Sample Packet Number Encoding Algorithm\"}\n\nFor example, if an endpoint has received an acknowledgment for packet 0xabe8b3\nand is sending a packet with a number of 0xac5c02, there are 29,519 (0x734f)\noutstanding packet numbers.  In order to represent at least twice this range\n(59,038 packets, or 0xe69e), 16 bits are required.\n\nIn the same state, sending a packet with a number of 0xace8fe uses the 24-bit\nencoding, because at least 18 bits are required to represent twice the range\n(131,222 packets, or 0x020096).\n\n\n## Sample Packet Number Decoding Algorithm {#sample-packet-number-decoding}\n\nThe pseudocode in {{alg-decode-pn}} includes an example algorithm for decoding\npacket numbers after header protection has been removed.\n\nThe DecodePacketNumber function takes three arguments:\n\n* largest_pn is the largest packet number that has been successfully\n  processed in the current packet number space.\n* truncated_pn is the value of the Packet Number field.\n* pn_nbits is the number of bits in the Packet Number field (8, 16, 24, or 32).\n\n~~~pseudocode\nDecodePacketNumber(largest_pn, truncated_pn, pn_nbits):\n   expected_pn  = largest_pn + 1\n   pn_win       = 1 << pn_nbits\n   pn_hwin      = pn_win / 2\n   pn_mask      = pn_win - 1\n   // The incoming packet number should be greater than\n   // expected_pn - pn_hwin and less than or equal to\n   // expected_pn + pn_hwin\n   //\n   // This means we cannot just strip the trailing bits from\n   // expected_pn and add the truncated_pn because that might\n   // yield a value outside the window.\n   //\n   // The following code calculates a candidate value and\n   // makes sure it's within the packet number window.\n   // Note the extra checks to prevent overflow and underflow.\n   candidate_pn = (expected_pn & ~pn_mask) | truncated_pn\n   if candidate_pn <= expected_pn - pn_hwin and\n      candidate_pn < (1 << 62) - pn_win:\n      return candidate_pn + pn_win\n   if candidate_pn > expected_pn + pn_hwin and\n      candidate_pn >= pn_win:\n      return candidate_pn - pn_win\n   return candidate_pn\n~~~\n{: #alg-decode-pn title=\"Sample Packet Number Decoding Algorithm\"}\n\nFor example, if the highest successfully authenticated packet had a packet\nnumber of 0xa82f30ea, then a packet containing a 16-bit value of 0x9b32 will be\ndecoded as 0xa82f9b32.\n\n\n## Sample ECN Validation Algorithm {#ecn-alg}\n\nEach time an endpoint commences sending on a new network path, it determines\nwhether the path supports ECN; see {{ecn}}.  If the path supports ECN, the goal\nis to use ECN.  Endpoints might also periodically reassess a path that was\ndetermined to not support ECN.\n\nThis section describes one method for testing new paths.  This algorithm is\nintended to show how a path might be tested for ECN support.  Endpoints can\nimplement different methods.\n\nThe path is assigned an ECN state that is one of \"testing\", \"unknown\", \"failed\",\nor \"capable\".  On paths with a \"testing\" or \"capable\" state, the endpoint sends\npackets with an ECT marking -- ECT(0) by default; otherwise, the endpoint sends\nunmarked packets.\n\nTo start testing a path, the ECN state is set to \"testing\", and existing ECN\ncounts are remembered as a baseline.\n\nThe testing period runs for a number of packets or a limited time, as determined\nby the endpoint.  The goal is not to limit the duration of the testing period\nbut to ensure that enough marked packets are sent for received ECN counts to\nprovide a clear indication of how the path treats marked packets.\n{{ecn-validation}} suggests limiting this to ten packets or three times the PTO.\n\nAfter the testing period ends, the ECN state for the path becomes \"unknown\".\nFrom the \"unknown\" state, successful validation of the ECN counts in an ACK\nframe (see {{ecn-ack}}) causes the ECN state for the path to become \"capable\",\nunless no marked packet has been acknowledged.\n\nIf validation of ECN counts fails at any time, the ECN state for the affected\npath becomes \"failed\".  An endpoint can also mark the ECN state for a path as\n\"failed\" if marked packets are all declared lost or if they are all ECN-CE\nmarked.\n\nFollowing this algorithm ensures that ECN is rarely disabled for paths that\nproperly support ECN.  Any path that incorrectly modifies markings will cause\nECN to be disabled.  For those rare cases where marked packets are discarded by\nthe path, the short duration of the testing period limits the number of losses\nincurred.\n\n\n# Contributors\n{:numbered=\"false\"}\n\nThe original design and rationale behind this protocol draw significantly from\nwork by {{{Jim Roskind}}} {{EARLY-DESIGN}}.\n\nThe IETF QUIC Working Group received an enormous amount of support from many\npeople. The following people provided substantive contributions to this\ndocument:\n\n<ul spacing=\"compact\">\n<li><t><contact fullname=\"Alessandro Ghedini\"/></t></li>\n<li><t><contact fullname=\"Alyssa Wilk\"/></t></li>\n<li><t><contact fullname=\"Antoine Delignat-Lavaud\"/></t></li>\n<li><t><contact fullname=\"Brian Trammell\"/></t></li>\n<li><t><contact fullname=\"Christian Huitema\"/></t></li>\n<li><t><contact fullname=\"Colin Perkins\"/></t></li>\n<li><t><contact fullname=\"David Schinazi\"/></t></li>\n<li><t><contact fullname=\"Dmitri Tikhonov\"/></t></li>\n<li><t><contact fullname=\"Eric Kinnear\"/></t></li>\n<li><t><contact fullname=\"Eric Rescorla\"/></t></li>\n<li><t><contact fullname=\"Gorry Fairhurst\"/></t></li>\n<li><t><contact fullname=\"Ian Swett\"/></t></li>\n<li><t><contact fullname=\"Igor Lubashev\"/></t></li>\n<li><t><contact asciiFullname=\"Kazuho Oku\" fullname=\"奥 一穂\"/></t></li>\n<li><t><contact fullname=\"Lars Eggert\"/></t></li>\n<li><t><contact fullname=\"Lucas Pardue\"/></t></li>\n<li><t><contact fullname=\"Magnus Westerlund\"/></t></li>\n<li><t><contact fullname=\"Marten Seemann\"/></t></li>\n<li><t><contact fullname=\"Martin Duke\"/></t></li>\n<li><t><contact fullname=\"Mike Bishop\"/></t></li>\n<li><t><contact fullname=\"Mikkel Fahnøe Jørgensen\"/></t></li>\n<li><t><contact fullname=\"Mirja Kühlewind\"/></t></li>\n<li><t><contact fullname=\"Nick Banks\"/></t></li>\n<li><t><contact fullname=\"Nick Harper\"/></t></li>\n<li><t><contact fullname=\"Patrick McManus\"/></t></li>\n<li><t><contact fullname=\"Roberto Peon\"/></t></li>\n<li><t><contact fullname=\"Ryan Hamilton\"/></t></li>\n<li><t><contact fullname=\"Subodh Iyengar\"/></t></li>\n<li><t><contact fullname=\"Tatsuhiro Tsujikawa\"/></t></li>\n<li><t><contact fullname=\"Ted Hardie\"/></t></li>\n<li><t><contact fullname=\"Tom Jones\"/></t></li>\n<li><t><contact fullname=\"Victor Vasiliev\"/></t></li>\n</ul>\n"
        },
        {
          "name": "rfc9001.md",
          "type": "blob",
          "size": 112.7998046875,
          "content": "---\ntitle: Using TLS to Secure QUIC\nnumber: 9001\ndocName: draft-ietf-quic-tls-34\ndate: 2021-05\ncategory: std\nconsensus: true\nipr: trust200902\narea: Transport\nworkgroup: QUIC\nkeyword:\n  - crypto\n  - opportunistic encryption\n  - plaintext quic\n\nstand_alone: yes\npi: [toc, sortrefs, symrefs, docmapping]\n\nauthor:\n  -\n    ins: M. Thomson\n    name: Martin Thomson\n    org: Mozilla\n    email: mt@lowentropy.net\n    role: editor\n  -\n    ins: S. Turner\n    name: Sean Turner\n    org: sn3rd\n    email: sean@sn3rd.com\n    role: editor\n\nnormative:\n\n  QUIC-TRANSPORT:\n    title: \"QUIC: A UDP-Based Multiplexed and Secure Transport\"\n    date: 2021-05\n    seriesinfo:\n      RFC: 9000\n      DOI: 10.17487/RFC9000\n    author:\n      -\n        ins: J. Iyengar\n        name: Jana Iyengar\n        org: Fastly\n        role: editor\n      -\n        ins: M. Thomson\n        name: Martin Thomson\n        org: Mozilla\n        role: editor\n\n  QUIC-RECOVERY:\n    title: \"QUIC Loss Detection and Congestion Control\"\n    date: 2021-05\n    seriesinfo:\n      RFC: 9002\n      DOI: 10.17487/RFC9002\n    author:\n      -\n        ins: J. Iyengar\n        name: Jana Iyengar\n        org: Fastly\n        role: editor\n      -\n        ins: I. Swett\n        name: Ian Swett\n        org: Google\n        role: editor\n\n  HKDF: RFC5869\n\ninformative:\n\n  AEBounds:\n    title: \"Limits on Authenticated Encryption Use in TLS\"\n    author:\n      - ins: A. Luykx\n      - ins: K. Paterson\n    date: 2017-08-28\n    target: \"https://www.isg.rhul.ac.uk/~kp/TLS-AEbounds.pdf\"\n\n  IMC:\n    title: \"Introduction to Modern Cryptography, Second Edition\"\n    author:\n      - ins: J. Katz\n      - ins: Y. Lindell\n    date: 2014-11-06\n    seriesinfo:\n      ISBN: 978-1466570269\n\n  QUIC-HTTP:\n    title: \"Hypertext Transfer Protocol Version 3 (HTTP/3)\"\n    date: {DATE}\n    seriesinfo:\n      Internet-Draft: draft-ietf-quic-http-latest\n    author:\n      -\n        ins: M. Bishop\n        name: Mike Bishop\n        org: Akamai Technologies\n        role: editor\n\n  ROBUST:\n    title: \"Robust Channels: Handling Unreliable Networks in the Record Layers of QUIC and DTLS 1.3\"\n    author:\n      - ins: M. Fischlin\n      - ins: F. Günther\n      - ins: C. Janson\n    date: 2020-05-16\n    target: \"https://eprint.iacr.org/2020/718\"\n\n  CCM-ANALYSIS:\n    title: \"On the Security of CTR + CBC-MAC\"\n    author:\n      -\n        initials: J.\n        surname: Jonsson\n        name: Jakob Jonsson\n    date: 2003\n    refcontent:\n      - \"Selected Areas in Cryptography\"\n      - \"SAC 2002\"\n      - \"Lecture Notes in Computer Science, vol 2595\"\n      - \"pp. 76-93\"\n    seriesinfo:\n      DOI: 10.1007/3-540-36492-7_7\n\n  NAN:\n    title: \"Nonces Are Noticed: AEAD Revisited\"\n    author:\n      -\n        initials: M.\n        surname: Bellare\n        name: Mihir Bellare\n      -\n        initials: R.\n        surname: Ng\n        name: Ruth Ng\n      -\n        initials: B.\n        surname: Tackmann\n        name: Björn Tackmann\n    date: 2019\n    refcontent:\n      - \"Advances in Cryptology - CRYPTO 2019\"\n      - \"Lecture Notes in Computer Science, vol 11692\"\n      - \"pp. 235-265\"\n    seriesinfo:\n      DOI: 10.1007/978-3-030-26948-7_9\n\n  GCM-MU:\n    title: \"The Multi-user Security of GCM, Revisited: Tight Bounds for Nonce Randomization\"\n    author:\n      -\n        initials: V.\n        surname: Hoang\n        name: Viet Tung Hoang\n      -\n        initials: S.\n        surname: Tessaro\n        name: Stefano Tessaro\n      -\n        initials: A.\n        surname: Thiruvengadam\n        name: Aishwarya Thiruvengadam\n    date: 2018\n    refcontent:\n      - \"CCS '18: Proceedings of the 2018 ACM SIGSAC Conference on Computer and Communications Security\"\n      - \"pp. 1429-1440\"\n    seriesinfo:\n      DOI: 10.1145/3243734.3243816\n\n\n--- abstract\n\nThis document describes how Transport Layer Security (TLS) is used to secure\nQUIC.\n\n\n--- middle\n\n# Introduction\n\nThis document describes how QUIC {{QUIC-TRANSPORT}} is secured using TLS\n{{!TLS13=RFC8446}}.\n\nTLS 1.3 provides critical latency improvements for connection establishment over\nprevious versions.  Absent packet loss, most new connections can be established\nand secured within a single round trip; on subsequent connections between the\nsame client and server, the client can often send application data immediately,\nthat is, using a zero round-trip setup.\n\nThis document describes how TLS acts as a security component of QUIC.\n\n\n# Notational Conventions\n\nThe key words \"MUST\", \"MUST NOT\", \"REQUIRED\", \"SHALL\", \"SHALL NOT\", \"SHOULD\",\n\"SHOULD NOT\", \"RECOMMENDED\", \"NOT RECOMMENDED\", \"MAY\", and \"OPTIONAL\" in this\ndocument are to be interpreted as described in BCP 14 {{!RFC2119}} {{!RFC8174}}\nwhen, and only when, they appear in all capitals, as shown here.\n\nThis document uses the terminology established in {{QUIC-TRANSPORT}}.\n\nFor brevity, the acronym TLS is used to refer to TLS 1.3, though a newer version\ncould be used; see {{tls-version}}.\n\n\n## TLS Overview\n\nTLS provides two endpoints with a way to establish a means of communication over\nan untrusted medium (for example, the Internet). TLS enables authentication of\npeers and provides confidentiality and integrity protection for messages that\nendpoints exchange.\n\nInternally, TLS is a layered protocol, with the structure shown in\n{{tls-layers}}.\n\n~~~~\n          +-------------+------------+--------------+---------+\nContent   |             |            |  Application |         |\nLayer     |  Handshake  |   Alerts   |     Data     |   ...   |\n          |             |            |              |         |\n          +-------------+------------+--------------+---------+\nRecord    |                                                   |\nLayer     |                      Records                      |\n          |                                                   |\n          +---------------------------------------------------+\n~~~~\n{: #tls-layers title=\"TLS Layers\"}\n\nEach content-layer message (e.g., handshake, alerts, and application data) is\ncarried as a series of typed TLS records by the record layer.  Records are\nindividually cryptographically protected and then transmitted over a reliable\ntransport (typically TCP), which provides sequencing and guaranteed delivery.\n\nThe TLS authenticated key exchange occurs between two endpoints: client and\nserver.  The client initiates the exchange and the server responds.  If the key\nexchange completes successfully, both client and server will agree on a secret.\nTLS supports both pre-shared key (PSK) and Diffie-Hellman over either finite\nfields or elliptic curves ((EC)DHE) key exchanges.  PSK is the basis for Early\nData (0-RTT); the latter provides forward secrecy (FS) when the (EC)DHE\nkeys are destroyed.  The two modes can also be combined to provide forward\nsecrecy while using the PSK for authentication.\n\nAfter completing the TLS handshake, the client will have learned and\nauthenticated an identity for the server, and the server is optionally able to\nlearn and authenticate an identity for the client.  TLS supports X.509\n{{?RFC5280}} certificate-based authentication for both server and client.\nWhen PSK key exchange is used (as in resumption), knowledge of the PSK\nserves to authenticate the peer.\n\nThe TLS key exchange is resistant to tampering by attackers, and it produces\nshared secrets that cannot be controlled by either participating peer.\n\nTLS provides two basic handshake modes of interest to QUIC:\n\n * A full 1-RTT handshake, in which the client is able to send application data\n   after one round trip and the server immediately responds after receiving the\n   first handshake message from the client.\n\n * A 0-RTT handshake, in which the client uses information it has previously\n   learned about the server to send application data immediately.  This\n   application data can be replayed by an attacker, so 0-RTT is not suitable for\n   carrying instructions that might initiate any action that could cause\n   unwanted effects if replayed.\n\nA simplified TLS handshake with 0-RTT application data is shown in {{tls-full}}.\n\n~~~\n    Client                                             Server\n\n    ClientHello\n   (0-RTT Application Data)  -------->\n                                                  ServerHello\n                                         {EncryptedExtensions}\n                                                    {Finished}\n                             <--------      [Application Data]\n   {Finished}                -------->\n\n   [Application Data]        <------->      [Application Data]\n\n    () Indicates messages protected by Early Data (0-RTT) Keys\n    {} Indicates messages protected using Handshake Keys\n    [] Indicates messages protected using Application Data\n       (1-RTT) Keys\n~~~\n{: #tls-full title=\"TLS Handshake with 0-RTT\"}\n\n{{tls-full}} omits the EndOfEarlyData message, which is not used in QUIC; see\n{{remove-eoed}}. Likewise, neither ChangeCipherSpec nor KeyUpdate messages are\nused by QUIC. ChangeCipherSpec is redundant in TLS 1.3; see {{compat-mode}}.\nQUIC has its own key update mechanism; see {{key-update}}.\n\nData is protected using a number of encryption levels:\n\n- Initial keys\n- Early data (0-RTT) keys\n- Handshake keys\n- Application data (1-RTT) keys\n\nApplication data can only appear in the early data and application data\nlevels. Handshake and alert messages may appear in any level.\n\nThe 0-RTT handshake can be used if the client and server have previously\ncommunicated.  In the 1-RTT handshake, the client is unable to send protected\napplication data until it has received all of the handshake messages sent by the\nserver.\n\n\n# Protocol Overview\n\nQUIC {{QUIC-TRANSPORT}} assumes responsibility for the confidentiality and\nintegrity protection of packets.  For this it uses keys derived from a TLS\nhandshake {{!TLS13}}, but instead of carrying TLS records over QUIC (as with\nTCP), TLS handshake and alert messages are carried directly over the QUIC\ntransport, which takes over the responsibilities of the TLS record layer, as\nshown in {{quic-layers}}.\n\n~~~~\n+--------------+--------------+ +-------------+\n|     TLS      |     TLS      | |    QUIC     |\n|  Handshake   |    Alerts    | | Applications|\n|              |              | |  (h3, etc.) |\n+--------------+--------------+-+-------------+\n|                                             |\n|                QUIC Transport               |\n|   (streams, reliability, congestion, etc.)  |\n|                                             |\n+---------------------------------------------+\n|                                             |\n|            QUIC Packet Protection           |\n|                                             |\n+---------------------------------------------+\n~~~~\n{: #quic-layers title=\"QUIC Layers\"}\n\nQUIC also relies on TLS for authentication and negotiation of parameters that\nare critical to security and performance.\n\nRather than a strict layering, these two protocols cooperate: QUIC uses the TLS\nhandshake; TLS uses the reliability, ordered delivery, and record layer provided\nby QUIC.\n\nAt a high level, there are two main interactions between the TLS and QUIC\ncomponents:\n\n* The TLS component sends and receives messages via the QUIC component, with\n  QUIC providing a reliable stream abstraction to TLS.\n\n* The TLS component provides a series of updates to the QUIC component,\n  including (a) new packet protection keys to install and (b) state changes such\n  as handshake completion, the server certificate, etc.\n\n{{schematic}} shows these interactions in more detail, with the QUIC packet\nprotection being called out specially.\n\n~~~\n+------------+                               +------------+\n|            |<---- Handshake Messages ----->|            |\n|            |<- Validate 0-RTT Parameters ->|            |\n|            |<--------- 0-RTT Keys ---------|            |\n|    QUIC    |<------- Handshake Keys -------|    TLS     |\n|            |<--------- 1-RTT Keys ---------|            |\n|            |<------- Handshake Done -------|            |\n+------------+                               +------------+\n |         ^\n | Protect | Protected\n v         | Packet\n+------------+\n|   QUIC     |\n|  Packet    |\n| Protection |\n+------------+\n~~~\n{: #schematic title=\"QUIC and TLS Interactions\"}\n\nUnlike TLS over TCP, QUIC applications that want to send data do not send it\nusing TLS Application Data records. Rather, they send it as QUIC STREAM\nframes or other frame types, which are then carried in QUIC packets.\n\n# Carrying TLS Messages {#carrying-tls}\n\nQUIC carries TLS handshake data in CRYPTO frames, each of which consists of a\ncontiguous block of handshake data identified by an offset and length. Those\nframes are packaged into QUIC packets and encrypted under the current\nencryption level.  As with TLS over TCP, once TLS handshake data has been\ndelivered to QUIC, it is QUIC's responsibility to deliver it reliably. Each\nchunk of data that is produced by TLS is associated with the set of keys that\nTLS is currently using.  If QUIC needs to retransmit that data, it MUST use the\nsame keys even if TLS has already updated to newer keys.\n\nEach encryption level corresponds to a packet number space. The packet number\nspace that is used determines the semantics of frames. Some frames are\nprohibited in different packet number spaces; see {{Section 12.5 of\nQUIC-TRANSPORT}}.\n\nBecause packets could be reordered on the wire, QUIC uses the packet type to\nindicate which keys were used to protect a given packet, as shown in\n{{packet-types-keys}}. When packets of different types need to be sent,\nendpoints SHOULD use coalesced packets to send them in the same UDP datagram.\n\n<table anchor=\"packet-types-keys\" align=\"center\">\n<name>Encryption Keys by Packet Type</name>\n<thead>\n<tr><th>Packet Type</th><th>Encryption Keys</th><th>PN Space</th></tr>\n</thead>\n<tbody>\n<tr><th>Initial</th><td>Initial secrets</td><td>Initial</td></tr>\n<tr><th>0-RTT Protected</th><td>0-RTT</td><td>Application data</td></tr>\n<tr><th>Handshake</th><td>Handshake</td><td>Handshake</td></tr>\n<tr><th>Retry</th><td>Retry</td><td>N/A</td></tr>\n<tr><th>Version Negotiation</th><td>N/A</td><td>N/A</td></tr>\n<tr><th>Short Header</th><td>1-RTT</td><td>Application data</td></tr>\n</tbody>\n</table>\n\n{{Section 17 of QUIC-TRANSPORT}} shows how packets at the various encryption\nlevels fit into the handshake process.\n\n\n## Interface to TLS\n\nAs shown in {{schematic}}, the interface from QUIC to TLS consists of four\nprimary functions:\n\n- Sending and receiving handshake messages\n- Processing stored transport and application state from a resumed session\n  and determining if it is valid to generate or accept early data\n- Rekeying (both transmit and receive)\n- Updating handshake state\n\nAdditional functions might be needed to configure TLS.  In particular, QUIC and\nTLS need to agree on which is responsible for validation of peer credentials,\nsuch as certificate validation {{?RFC5280}}.\n\n\n### Handshake Complete {#handshake-complete}\n\nIn this document, the TLS handshake is considered complete when the TLS stack\nhas reported that the handshake is complete.  This happens when the TLS stack\nhas both sent a Finished message and verified the peer's Finished message.\nVerifying the peer's Finished message provides the endpoints with an assurance\nthat previous handshake messages have not been modified.  Note that the\nhandshake does not complete at both endpoints simultaneously.  Consequently, any\nrequirement that is based on the completion of the handshake depends on the\nperspective of the endpoint in question.\n\n\n### Handshake Confirmed {#handshake-confirmed}\n\nIn this document, the TLS handshake is considered confirmed at the server when\nthe handshake completes.  The server MUST send a HANDSHAKE_DONE frame as soon as\nthe handshake is complete.  At the client, the handshake is considered confirmed\nwhen a HANDSHAKE_DONE frame is received.\n\nAdditionally, a client MAY consider the handshake to be confirmed when it\nreceives an acknowledgment for a 1-RTT packet.  This can be implemented by\nrecording the lowest packet number sent with 1-RTT keys and comparing it to the\nLargest Acknowledged field in any received 1-RTT ACK frame: once the latter is\ngreater than or equal to the former, the handshake is confirmed.\n\n\n### Sending and Receiving Handshake Messages\n\nIn order to drive the handshake, TLS depends on being able to send and receive\nhandshake messages. There are two basic functions on this interface: one where\nQUIC requests handshake messages and one where QUIC provides bytes that comprise\nhandshake messages.\n\nBefore starting the handshake, QUIC provides TLS with the transport parameters\n(see {{quic_parameters}}) that it wishes to carry.\n\nA QUIC client starts TLS by requesting TLS handshake bytes from TLS.  The client\nacquires handshake bytes before sending its first packet.  A QUIC server starts\nthe process by providing TLS with the client's handshake bytes.\n\nAt any time, the TLS stack at an endpoint will have a current sending encryption\nlevel and a receiving encryption level. TLS encryption levels determine the QUIC\npacket type and keys that are used for protecting data.\n\nEach encryption level is associated with a different sequence of bytes, which is\nreliably transmitted to the peer in CRYPTO frames. When TLS provides handshake\nbytes to be sent, they are appended to the handshake bytes for the current\nencryption level. The encryption level then determines the type of packet that\nthe resulting CRYPTO frame is carried in; see {{packet-types-keys}}.\n\nFour encryption levels are used, producing keys for Initial, 0-RTT, Handshake,\nand 1-RTT packets. CRYPTO frames are carried in just three of these levels,\nomitting the 0-RTT level. These four levels correspond to three packet number\nspaces: Initial and Handshake encrypted packets use their own separate spaces;\n0-RTT and 1-RTT packets use the application data packet number space.\n\nQUIC takes the unprotected content of TLS handshake records as the content of\nCRYPTO frames. TLS record protection is not used by QUIC. QUIC assembles\nCRYPTO frames into QUIC packets, which are protected using QUIC packet\nprotection.\n\nQUIC CRYPTO frames only carry TLS handshake messages.  TLS\nalerts are turned into QUIC CONNECTION_CLOSE error codes; see {{tls-errors}}.\nTLS application data and other content types cannot be carried by QUIC at any\nencryption level; it is an error if they are received from the TLS stack.\n\nWhen an endpoint receives a QUIC packet containing a CRYPTO frame from the\nnetwork, it proceeds as follows:\n\n- If the packet uses the current TLS receiving encryption level, sequence the\n  data into the input flow as usual. As with STREAM frames, the offset is used\n  to find the proper location in the data sequence.  If the result of this\n  process is that new data is available, then it is delivered to TLS in order.\n\n- If the packet is from a previously installed encryption level, it MUST NOT\n  contain data that extends past the end of previously received data in that\n  flow. Implementations MUST treat any violations of this requirement as a\n  connection error of type PROTOCOL_VIOLATION.\n\n- If the packet is from a new encryption level, it is saved for later processing\n  by TLS.  Once TLS moves to receiving from this encryption level, saved data\n  can be provided to TLS.  When TLS provides keys for a higher encryption level,\n  if there is data from a previous encryption level that TLS has not consumed,\n  this MUST be treated as a connection error of type PROTOCOL_VIOLATION.\n\nEach time that TLS is provided with new data, new handshake bytes are requested\nfrom TLS.  TLS might not provide any bytes if the handshake messages it has\nreceived are incomplete or it has no data to send.\n\nThe content of CRYPTO frames might either be processed incrementally by TLS or\nbuffered until complete messages or flights are available.  TLS is responsible\nfor buffering handshake bytes that have arrived in order.  QUIC is responsible\nfor buffering handshake bytes that arrive out of order or for encryption levels\nthat are not yet ready.  QUIC does not provide any means of flow control for\nCRYPTO frames; see {{Section 7.5 of QUIC-TRANSPORT}}.\n\nOnce the TLS handshake is complete, this is indicated to QUIC along with any\nfinal handshake bytes that TLS needs to send.  At this stage, the transport\nparameters that the peer advertised during the handshake are authenticated;\nsee {{quic_parameters}}.\n\nOnce the handshake is complete, TLS becomes passive.  TLS can still receive data\nfrom its peer and respond in kind, but it will not need to send more data unless\nspecifically requested -- either by an application or QUIC.  One reason to send\ndata is that the server might wish to provide additional or updated session\ntickets to a client.\n\nWhen the handshake is complete, QUIC only needs to provide TLS with any data\nthat arrives in CRYPTO streams.  In the same manner that is used during the\nhandshake, new data is requested from TLS after providing received data.\n\n\n### Encryption Level Changes\n\nAs keys at a given encryption level become available to TLS, TLS indicates to\nQUIC that reading or writing keys at that encryption level are available.\n\nThe availability of new keys is always a result of providing inputs to TLS.  TLS\nonly provides new keys after being initialized (by a client) or when provided\nwith new handshake data.\n\nHowever, a TLS implementation could perform some of its processing\nasynchronously. In particular, the process of validating a certificate can take\nsome time. While waiting for TLS processing to complete, an endpoint SHOULD\nbuffer received packets if they might be processed using keys that aren't yet\navailable. These packets can be processed once keys are provided by TLS. An\nendpoint SHOULD continue to respond to packets that can be processed during this\ntime.\n\nAfter processing inputs, TLS might produce handshake bytes, keys for new\nencryption levels, or both.\n\nTLS provides QUIC with three items as a new encryption level becomes available:\n\n* A secret\n\n* An Authenticated Encryption with Associated Data (AEAD) function\n\n* A Key Derivation Function (KDF)\n\nThese values are based on the values that TLS negotiates and are used by QUIC to\ngenerate packet and header protection keys; see {{packet-protection}} and\n{{header-protect}}.\n\nIf 0-RTT is possible, it is ready after the client sends a TLS ClientHello\nmessage or the server receives that message.  After providing a QUIC client with\nthe first handshake bytes, the TLS stack might signal the change to 0-RTT\nkeys. On the server, after receiving handshake bytes that contain a ClientHello\nmessage, a TLS server might signal that 0-RTT keys are available.\n\nAlthough TLS only uses one encryption level at a time, QUIC may use more than\none level. For instance, after sending its Finished message (using a CRYPTO\nframe at the Handshake encryption level) an endpoint can send STREAM data (in\n1-RTT encryption). If the Finished message is lost, the endpoint uses the\nHandshake encryption level to retransmit the lost message.  Reordering or loss\nof packets can mean that QUIC will need to handle packets at multiple encryption\nlevels.  During the handshake, this means potentially handling packets at higher\nand lower encryption levels than the current encryption level used by TLS.\n\nIn particular, server implementations need to be able to read packets at the\nHandshake encryption level at the same time as the 0-RTT encryption level.  A\nclient could interleave ACK frames that are protected with Handshake keys with\n0-RTT data, and the server needs to process those acknowledgments in order to\ndetect lost Handshake packets.\n\nQUIC also needs access to keys that might not ordinarily be available to a TLS\nimplementation.  For instance, a client might need to acknowledge Handshake\npackets before it is ready to send CRYPTO frames at that encryption level.  TLS\ntherefore needs to provide keys to QUIC before it might produce them for its own\nuse.\n\n\n### TLS Interface Summary\n\n{{exchange-summary}} summarizes the exchange between QUIC and TLS for both\nclient and server. Solid arrows indicate packets that carry handshake data;\ndashed arrows show where application data can be sent.  Each arrow is tagged\nwith the encryption level used for that transmission.\n\n~~~\nClient                                                    Server\n======                                                    ======\n\nGet Handshake\n                     Initial ------------->\nInstall tx 0-RTT keys\n                     0-RTT - - - - - - - ->\n\n                                              Handshake Received\n                                                   Get Handshake\n                     <------------- Initial\n                                           Install rx 0-RTT keys\n                                          Install Handshake keys\n                                                   Get Handshake\n                     <----------- Handshake\n                                           Install tx 1-RTT keys\n                     <- - - - - - - - 1-RTT\n\nHandshake Received (Initial)\nInstall Handshake keys\nHandshake Received (Handshake)\nGet Handshake\n                     Handshake ----------->\nHandshake Complete\nInstall 1-RTT keys\n                     1-RTT - - - - - - - ->\n\n                                              Handshake Received\n                                              Handshake Complete\n                                             Handshake Confirmed\n                                           Install rx 1-RTT keys\n                     <--------------- 1-RTT\n                           (HANDSHAKE_DONE)\nHandshake Confirmed\n~~~\n{: #exchange-summary title=\"Interaction Summary between QUIC and TLS\"}\n\n{{exchange-summary}} shows the multiple packets that form a single \"flight\" of\nmessages being processed individually, to show what incoming messages trigger\ndifferent actions. This shows multiple \"Get Handshake\" invocations to retrieve\nhandshake messages at different encryption levels. New handshake messages are\nrequested after incoming packets have been processed.\n\n{{exchange-summary}} shows one possible structure for a simple handshake\nexchange. The exact process varies based on the structure of endpoint\nimplementations and the order in which packets arrive. Implementations could\nuse a different number of operations or execute them in other orders.\n\n\n## TLS Version {#tls-version}\n\nThis document describes how TLS 1.3 {{!TLS13}} is used with QUIC.\n\nIn practice, the TLS handshake will negotiate a version of TLS to use.  This\ncould result in a version of TLS newer than 1.3 being negotiated if both\nendpoints support that version.  This is acceptable provided that the features\nof TLS 1.3 that are used by QUIC are supported by the newer version.\n\nClients MUST NOT offer TLS versions older than 1.3.  A badly configured TLS\nimplementation could negotiate TLS 1.2 or another older version of TLS.  An\nendpoint MUST terminate the connection if a version of TLS older than 1.3 is\nnegotiated.\n\n\n## ClientHello Size {#clienthello-size}\n\nThe first Initial packet from a client contains the start or all of its first\ncryptographic handshake message, which for TLS is the ClientHello.  Servers\nmight need to parse the entire ClientHello (e.g., to access extensions such as\nServer Name Identification (SNI) or Application-Layer Protocol Negotiation\n(ALPN)) in order to decide whether to accept the new incoming QUIC connection.\nIf the ClientHello spans multiple Initial packets, such servers would need to\nbuffer the first received fragments, which could consume excessive resources if\nthe client's address has not yet been validated.  To avoid this, servers MAY\nuse the Retry feature (see {{Section 8.1 of QUIC-TRANSPORT}}) to only buffer\npartial ClientHello messages from clients with a validated address.\n\nQUIC packet and framing add at least 36 bytes of overhead to the ClientHello\nmessage.  That overhead increases if the client chooses a Source Connection ID\nfield longer than zero bytes.  Overheads also do not include the token or a\nDestination Connection ID longer than 8 bytes, both of which might be required\nif a server sends a Retry packet.\n\nA typical TLS ClientHello can easily fit into a 1200-byte packet.  However, in\naddition to the overheads added by QUIC, there are several variables that could\ncause this limit to be exceeded.  Large session tickets, multiple or large key\nshares, and long lists of supported ciphers, signature algorithms, versions,\nQUIC transport parameters, and other negotiable parameters and extensions could\ncause this message to grow.\n\nFor servers, in addition to connection IDs and tokens, the size of TLS session\ntickets can have an effect on a client's ability to connect efficiently.\nMinimizing the size of these values increases the probability that clients can\nuse them and still fit their entire ClientHello message in their first Initial\npacket.\n\nThe TLS implementation does not need to ensure that the ClientHello is large\nenough to meet QUIC's requirements for datagrams that carry Initial packets; see\n{{Section 14.1 of QUIC-TRANSPORT}}. QUIC implementations use PADDING frames or\npacket coalescing to ensure that datagrams are large enough.\n\n\n## Peer Authentication\n\nThe requirements for authentication depend on the application protocol that is\nin use.  TLS provides server authentication and permits the server to request\nclient authentication.\n\nA client MUST authenticate the identity of the server.  This typically involves\nverification that the identity of the server is included in a certificate and\nthat the certificate is issued by a trusted entity (see for example\n{{?RFC2818}}).\n\n<aside markdown=\"block\">\nNote: Where servers provide certificates for authentication, the size of the\n  certificate chain can consume a large number of bytes.  Controlling the size\n  of certificate chains is critical to performance in QUIC as servers are\n  limited to sending 3 bytes for every byte received prior to validating the\n  client address; see {{Section 8.1 of QUIC-TRANSPORT}}.  The size of a\n  certificate chain can be managed by limiting the number of names or\n  extensions; using keys with small public key representations, like ECDSA; or\n  by using certificate compression {{?COMPRESS=RFC8879}}.\n</aside>\n\nA server MAY request that the client authenticate during the handshake. A server\nMAY refuse a connection if the client is unable to authenticate when requested.\nThe requirements for client authentication vary based on application protocol\nand deployment.\n\nA server MUST NOT use post-handshake client authentication (as defined in\n{{Section 4.6.2 of TLS13}}) because the multiplexing offered by QUIC prevents\nclients from correlating the certificate request with the application-level\nevent that triggered it (see {{?HTTP2-TLS13=RFC8740}}).  More specifically,\nservers MUST NOT send post-handshake TLS CertificateRequest messages, and\nclients MUST treat receipt of such messages as a connection error of type\nPROTOCOL_VIOLATION.\n\n\n## Session Resumption {#resumption}\n\nQUIC can use the session resumption feature of TLS 1.3. It does this by\ncarrying NewSessionTicket messages in CRYPTO frames after the handshake is\ncomplete. Session resumption can be used to provide 0-RTT and can also be\nused when 0-RTT is disabled.\n\nEndpoints that use session resumption might need to remember some information\nabout the current connection when creating a resumed connection. TLS requires\nthat some information be retained; see {{Section 4.6.1 of TLS13}}. QUIC itself\ndoes not depend on any state being retained when resuming a connection unless\n0-RTT is also used; see {{Section 7.4.1 of QUIC-TRANSPORT}} and\n{{enable-0rtt}}. Application protocols could depend on state that is retained\nbetween resumed connections.\n\nClients can store any state required for resumption along with the session\nticket. Servers can use the session ticket to help carry state.\n\nSession resumption allows servers to link activity on the original connection\nwith the resumed connection, which might be a privacy issue for clients.\nClients can choose not to enable resumption to avoid creating this correlation.\nClients SHOULD NOT reuse tickets as that allows entities other than the server\nto correlate connections; see {{Section C.4 of TLS13}}.\n\n\n## 0-RTT\n\nThe 0-RTT feature in QUIC allows a client to send application data before the\nhandshake is complete.  This is made possible by reusing negotiated parameters\nfrom a previous connection.  To enable this, 0-RTT depends on the client\nremembering critical parameters and providing the server with a TLS session\nticket that allows the server to recover the same information.\n\nThis information includes parameters that determine TLS state, as governed by\n{{!TLS13}}, QUIC transport parameters, the chosen application protocol, and any\ninformation the application protocol might need; see {{app-0rtt}}.  This\ninformation determines how 0-RTT packets and their contents are formed.\n\nTo ensure that the same information is available to both endpoints, all\ninformation used to establish 0-RTT comes from the same connection.  Endpoints\ncannot selectively disregard information that might alter the sending or\nprocessing of 0-RTT.\n\n{{!TLS13}} sets a limit of seven days on the time between the original\nconnection and any attempt to use 0-RTT.  There are other constraints on 0-RTT\nusage, notably those caused by the potential exposure to replay attack; see\n{{replay}}.\n\n\n### Enabling 0-RTT {#enable-0rtt}\n\nThe TLS early_data extension in the NewSessionTicket message is defined to\nconvey (in the max_early_data_size parameter) the amount of TLS 0-RTT data the\nserver is willing to accept.  QUIC does not use TLS 0-RTT data.  QUIC uses 0-RTT\npackets to carry early data.  Accordingly, the max_early_data_size parameter is\nrepurposed to hold a sentinel value 0xffffffff to indicate that the server is\nwilling to accept QUIC 0-RTT data.  To indicate that the server does not accept\n0-RTT data, the early_data extension is omitted from the NewSessionTicket.  The\namount of data that the client can send in QUIC 0-RTT is controlled by the\ninitial_max_data transport parameter supplied by the server.\n\nServers MUST NOT send the early_data extension with a max_early_data_size field\nset to any value other than 0xffffffff.  A client MUST treat receipt of a\nNewSessionTicket that contains an early_data extension with any other value as\na connection error of type PROTOCOL_VIOLATION.\n\nA client that wishes to send 0-RTT packets uses the early_data extension in the\nClientHello message of a subsequent handshake; see {{Section 4.2.10 of TLS13}}.\nIt then sends application data in 0-RTT packets.\n\nA client that attempts 0-RTT might also provide an address validation token if\nthe server has sent a NEW_TOKEN frame; see {{Section 8.1 of QUIC-TRANSPORT}}.\n\n\n### Accepting and Rejecting 0-RTT\n\nA server accepts 0-RTT by sending an early_data extension in the\nEncryptedExtensions; see {{Section 4.2.10 of TLS13}}.  The server then\nprocesses and acknowledges the 0-RTT packets that it receives.\n\nA server rejects 0-RTT by sending the EncryptedExtensions without an early_data\nextension.  A server will always reject 0-RTT if it sends a TLS\nHelloRetryRequest.  When rejecting 0-RTT, a server MUST NOT process any 0-RTT\npackets, even if it could.  When 0-RTT was rejected, a client SHOULD treat\nreceipt of an acknowledgment for a 0-RTT packet as a connection error of type\nPROTOCOL_VIOLATION, if it is able to detect the condition.\n\nWhen 0-RTT is rejected, all connection characteristics that the client assumed\nmight be incorrect.  This includes the choice of application protocol, transport\nparameters, and any application configuration.  The client therefore MUST reset\nthe state of all streams, including application state bound to those streams.\n\nA client MAY reattempt 0-RTT if it receives a Retry or Version Negotiation\npacket.  These packets do not signify rejection of 0-RTT.\n\n\n### Validating 0-RTT Configuration {#app-0rtt}\n\nWhen a server receives a ClientHello with the early_data extension, it has to\ndecide whether to accept or reject early data from the client. Some of this\ndecision is made by the TLS stack (e.g., checking that the cipher suite being\nresumed was included in the ClientHello; see {{Section 4.2.10 of TLS13}}). Even\nwhen the TLS stack has no reason to reject early data, the QUIC stack or the\napplication protocol using QUIC might reject early data because the\nconfiguration of the transport or application associated with the resumed\nsession is not compatible with the server's current configuration.\n\nQUIC requires additional transport state to be associated with a 0-RTT session\nticket. One common way to implement this is using stateless session tickets and\nstoring this state in the session ticket. Application protocols that use QUIC\nmight have similar requirements regarding associating or storing state. This\nassociated state is used for deciding whether early data must be rejected. For\nexample, HTTP/3 settings {{QUIC-HTTP}} determine how early data from the\nclient is interpreted. Other applications using QUIC could have different\nrequirements for determining whether to accept or reject early data.\n\n\n## HelloRetryRequest\n\nThe HelloRetryRequest message (see {{Section 4.1.4 of TLS13}}) can be used to\nrequest that a client provide new information, such as a key share, or to\nvalidate some characteristic of the client.  From the perspective of QUIC,\nHelloRetryRequest is not differentiated from other cryptographic handshake\nmessages that are carried in Initial packets. Although it is in principle\npossible to use this feature for address verification, QUIC implementations\nSHOULD instead use the Retry feature; see {{Section 8.1 of QUIC-TRANSPORT}}.\n\n\n## TLS Errors {#tls-errors}\n\nIf TLS experiences an error, it generates an appropriate alert as defined in\n{{Section 6 of TLS13}}.\n\nA TLS alert is converted into a QUIC connection error. The AlertDescription\nvalue is\nadded to 0x0100 to produce a QUIC error code from the range reserved for\nCRYPTO_ERROR; see {{Section 20.1 of QUIC-TRANSPORT}}. The resulting value is\nsent in a QUIC CONNECTION_CLOSE frame of type 0x1c.\n\nQUIC is only able to convey an alert level of \"fatal\". In TLS 1.3, the only\nexisting uses for the \"warning\" level are to signal connection close; see\n{{Section 6.1 of TLS13}}. As QUIC provides alternative mechanisms for\nconnection termination and the TLS connection is only closed if an error is\nencountered, a QUIC endpoint MUST treat any alert from TLS as if it were at the\n\"fatal\" level.\n\nQUIC permits the use of a generic code in place of a specific error code; see\n{{Section 11 of QUIC-TRANSPORT}}. For TLS alerts, this includes replacing any\nalert with a generic alert, such as handshake_failure (0x0128 in QUIC).\nEndpoints MAY use a generic error code to avoid possibly exposing confidential\ninformation.\n\n\n## Discarding Unused Keys\n\nAfter QUIC has completed a move to a new encryption level, packet protection\nkeys for previous encryption levels can be discarded.  This occurs several times\nduring the handshake, as well as when keys are updated; see {{key-update}}.\n\nPacket protection keys are not discarded immediately when new keys are\navailable.  If packets from a lower encryption level contain CRYPTO frames,\nframes that retransmit that data MUST be sent at the same encryption level.\nSimilarly, an endpoint generates acknowledgments for packets at the same\nencryption level as the packet being acknowledged.  Thus, it is possible that\nkeys for a lower encryption level are needed for a short time after keys for a\nnewer encryption level are available.\n\nAn endpoint cannot discard keys for a given encryption level unless it has\nreceived all the cryptographic handshake messages from its peer at that\nencryption level and its peer has done the same.  Different methods for\ndetermining this are provided for Initial keys ({{discard-initial}}) and\nHandshake keys ({{discard-handshake}}).  These methods do not prevent packets\nfrom being received or sent at that encryption level because a peer might not\nhave received all the acknowledgments necessary.\n\nThough an endpoint might retain older keys, new data MUST be sent at the highest\ncurrently available encryption level.  Only ACK frames and retransmissions of\ndata in CRYPTO frames are sent at a previous encryption level.  These packets\nMAY also include PADDING frames.\n\n\n### Discarding Initial Keys {#discard-initial}\n\nPackets protected with Initial secrets ({{initial-secrets}}) are not\nauthenticated, meaning that an attacker could spoof packets with the intent to\ndisrupt a connection.  To limit these attacks, Initial packet protection keys\nare discarded more aggressively than other keys.\n\nThe successful use of Handshake packets indicates that no more Initial packets\nneed to be exchanged, as these keys can only be produced after receiving all\nCRYPTO frames from Initial packets.  Thus, a client MUST discard Initial keys\nwhen it first sends a Handshake packet and a server MUST discard Initial keys\nwhen it first successfully processes a Handshake packet.  Endpoints MUST NOT\nsend Initial packets after this point.\n\nThis results in abandoning loss recovery state for the Initial encryption level\nand ignoring any outstanding Initial packets.\n\n\n### Discarding Handshake Keys {#discard-handshake}\n\nAn endpoint MUST discard its Handshake keys when the TLS handshake is confirmed\n({{handshake-confirmed}}).\n\n\n### Discarding 0-RTT Keys\n\n0-RTT and 1-RTT packets share the same packet number space, and clients do not\nsend 0-RTT packets after sending a 1-RTT packet ({{using-early-data}}).\n\nTherefore, a client SHOULD discard 0-RTT keys as soon as it installs 1-RTT\nkeys as they have no use after that moment.\n\nAdditionally, a server MAY discard 0-RTT keys as soon as it receives a 1-RTT\npacket.  However, due to packet reordering, a 0-RTT packet could arrive after\na 1-RTT packet.  Servers MAY temporarily retain 0-RTT keys to allow decrypting\nreordered packets without requiring their contents to be retransmitted with\n1-RTT keys.  After receiving a 1-RTT packet, servers MUST discard 0-RTT keys\nwithin a short time; the RECOMMENDED time period is three times the Probe\nTimeout (PTO, see {{QUIC-RECOVERY}}).  A server MAY discard 0-RTT keys earlier\nif it determines that it has received all 0-RTT packets, which can be done by\nkeeping track of missing packet numbers.\n\n\n# Packet Protection {#packet-protection}\n\nAs with TLS over TCP, QUIC protects packets with keys derived from the TLS\nhandshake, using the AEAD algorithm {{!AEAD}} negotiated by TLS.\n\nQUIC packets have varying protections depending on their type:\n\n* Version Negotiation packets have no cryptographic protection.\n\n* Retry packets use AEAD_AES_128_GCM to provide protection against accidental\n  modification and to limit the entities that can produce a valid Retry;\n  see {{retry-integrity}}.\n\n* Initial packets use AEAD_AES_128_GCM with keys derived from the Destination\n  Connection ID field of the first Initial packet sent by the client; see\n  {{initial-secrets}}.\n\n* All other packets have strong cryptographic protections for confidentiality\n  and integrity, using keys and algorithms negotiated by TLS.\n\nThis section describes how packet protection is applied to Handshake packets,\n0-RTT packets, and 1-RTT packets. The same packet protection process is applied\nto Initial packets. However, as it is trivial to determine the keys used for\nInitial packets, these packets are not considered to have confidentiality or\nintegrity protection. Retry packets use a fixed key and so similarly lack\nconfidentiality and integrity protection.\n\n\n## Packet Protection Keys {#protection-keys}\n\nQUIC derives packet protection keys in the same way that TLS derives record\nprotection keys.\n\nEach encryption level has separate secret values for protection of packets sent\nin each direction. These traffic secrets are derived by TLS (see {{Section 7.1\nof TLS13}}) and are used by QUIC for all encryption levels except the Initial\nencryption level. The secrets for the Initial encryption level are computed\nbased on the client's initial Destination Connection ID, as described in\n{{initial-secrets}}.\n\nThe keys used for packet protection are computed from the TLS secrets using the\nKDF provided by TLS.  In TLS 1.3, the HKDF-Expand-Label function described in\n{{Section 7.1 of TLS13}} is used, using the hash function from the negotiated\ncipher suite.  All uses of HKDF-Expand-Label in QUIC use a zero-length Context.\n\nNote that labels, which are described using strings, are encoded\nas bytes using ASCII {{?ASCII=RFC0020}} without quotes or any trailing NUL\nbyte.\n\nOther versions of TLS MUST provide a similar function in order to be\nused with QUIC.\n\nThe current encryption level secret and the label \"quic key\" are input to the\nKDF to produce the AEAD key; the label \"quic iv\" is used to derive the\nInitialization Vector (IV); see {{aead}}.  The header protection key uses the\n\"quic hp\" label; see {{header-protect}}.  Using these labels provides key\nseparation between QUIC and TLS; see {{key-diversity}}.\n\nBoth \"quic key\" and \"quic hp\" are used to produce keys, so the Length provided\nto HKDF-Expand-Label along with these labels is determined by the size of keys\nin the AEAD or header protection algorithm. The Length provided with \"quic iv\"\nis the minimum length of the AEAD nonce or 8 bytes if that is larger; see\n{{!AEAD}}.\n\nThe KDF used for initial secrets is always the HKDF-Expand-Label function from\nTLS 1.3; see {{initial-secrets}}.\n\n\n## Initial Secrets {#initial-secrets}\n\nInitial packets apply the packet protection process, but use a secret derived\nfrom the Destination Connection ID field from the client's first Initial\npacket.\n\nThis secret is determined by using HKDF-Extract (see {{Section 2.2 of HKDF}})\nwith a salt of 0x38762cf7f55934b34d179ae6a4c80cadccbb7f0a and the input keying\nmaterial (IKM) of the Destination Connection ID field. This produces an\nintermediate pseudorandom key (PRK) that is used to derive two separate secrets\nfor sending and receiving.\n\nThe secret used by clients to construct Initial packets uses the PRK and the\nlabel \"client in\" as input to the HKDF-Expand-Label function from TLS\n{{!TLS13}} to produce a 32-byte secret.  Packets constructed by the server use\nthe same process with the label \"server in\".  The hash function for HKDF when\nderiving initial secrets and keys is SHA-256\n{{!SHA=DOI.10.6028/NIST.FIPS.180-4}}.\n\nThis process in pseudocode is:\n\n~~~\ninitial_salt = 0x38762cf7f55934b34d179ae6a4c80cadccbb7f0a\ninitial_secret = HKDF-Extract(initial_salt,\n                              client_dst_connection_id)\n\nclient_initial_secret = HKDF-Expand-Label(initial_secret,\n                                          \"client in\", \"\",\n                                          Hash.length)\nserver_initial_secret = HKDF-Expand-Label(initial_secret,\n                                          \"server in\", \"\",\n                                          Hash.length)\n~~~\n\nThe connection ID used with HKDF-Expand-Label is the Destination Connection ID\nin the Initial packet sent by the client.  This will be a randomly selected\nvalue unless the client creates the Initial packet after receiving a Retry\npacket, where the Destination Connection ID is selected by the server.\n\nFuture versions of QUIC SHOULD generate a new salt value, thus ensuring that\nthe keys are different for each version of QUIC.  This prevents a middlebox that\nrecognizes only one version of QUIC from seeing or modifying the contents of\npackets from future versions.\n\nThe HKDF-Expand-Label function defined in TLS 1.3 MUST be used for Initial\npackets even where the TLS versions offered do not include TLS 1.3.\n\nThe secrets used for constructing subsequent Initial packets change when a\nserver sends a Retry packet to use the connection ID value selected by the\nserver.  The secrets do not change when a client changes the Destination\nConnection ID it uses in response to an Initial packet from the server.\n\n<aside markdown=\"block\">\nNote: The Destination Connection ID field could be any length up to 20 bytes,\n  including zero length if the server sends a Retry packet with a zero-length\n  Source Connection ID field. After a Retry, the Initial keys provide the client\n  no assurance that the server received its packet, so the client has to rely on\n  the exchange that included the Retry packet to validate the server address;\n  see {{Section 8.1 of QUIC-TRANSPORT}}.\n</aside>\n\n{{test-vectors}} contains sample Initial packets.\n\n\n## AEAD Usage {#aead}\n\nThe Authenticated Encryption with Associated Data (AEAD) function (see\n{{!AEAD}}) used for QUIC packet protection is the AEAD that is negotiated for\nuse with the TLS connection.  For example, if TLS is using the\nTLS_AES_128_GCM_SHA256 cipher suite, the AEAD_AES_128_GCM function is used.\n\nQUIC can use any of the cipher suites defined in {{!TLS13}} with the exception\nof TLS_AES_128_CCM_8_SHA256.  A cipher suite MUST NOT be negotiated unless a\nheader protection scheme is defined for the cipher suite.  This document defines\na header protection scheme for all cipher suites defined in {{!TLS13}} aside\nfrom TLS_AES_128_CCM_8_SHA256.  These cipher suites have a 16-byte\nauthentication tag and produce an output 16 bytes larger than their input.\n\nAn endpoint MUST NOT reject a ClientHello that offers a cipher suite that it\ndoes not support, or it would be impossible to deploy a new cipher suite.  This\nalso applies to TLS_AES_128_CCM_8_SHA256.\n\nWhen constructing packets, the AEAD function is applied prior to applying\nheader protection; see {{header-protect}}. The unprotected packet header is part\nof the associated data (A). When processing packets, an endpoint first\nremoves the header protection.\n\nThe key and IV for the packet are computed as described in {{protection-keys}}.\nThe nonce, N, is formed by combining the packet protection IV with the packet\nnumber.  The 62 bits of the reconstructed QUIC packet number in network byte\norder are left-padded with zeros to the size of the IV.  The exclusive OR of the\npadded packet number and the IV forms the AEAD nonce.\n\nThe associated data, A, for the AEAD is the contents of the QUIC header,\nstarting from the first byte of either the short or long header, up to and\nincluding the unprotected packet number.\n\nThe input plaintext, P, for the AEAD is the payload of the QUIC packet, as\ndescribed in {{QUIC-TRANSPORT}}.\n\nThe output ciphertext, C, of the AEAD is transmitted in place of P.\n\nSome AEAD functions have limits for how many packets can be encrypted under the\nsame key and IV; see {{aead-limits}}.  This might be lower than the packet\nnumber limit.  An endpoint MUST initiate a key update ({{key-update}}) prior to\nexceeding any limit set for the AEAD that is in use.\n\n\n## Header Protection {#header-protect}\n\nParts of QUIC packet headers, in particular the Packet Number field, are\nprotected using a key that is derived separately from the packet protection key\nand IV.  The key derived using the \"quic hp\" label is used to provide\nconfidentiality protection for those fields that are not exposed to on-path\nelements.\n\nThis protection applies to the least significant bits of the first byte, plus\nthe Packet Number field.  The four least significant bits of the first byte are\nprotected for packets with long headers; the five least significant bits of the\nfirst byte are protected for packets with short headers.  For both header forms,\nthis covers the reserved bits and the Packet Number Length field; the Key Phase\nbit is also protected for packets with a short header.\n\nThe same header protection key is used for the duration of the connection, with\nthe value not changing after a key update (see {{key-update}}).  This allows\nheader protection to be used to protect the key phase.\n\nThis process does not apply to Retry or Version Negotiation packets, which do\nnot contain a protected payload or any of the fields that are protected by this\nprocess.\n\n\n### Header Protection Application\n\nHeader protection is applied after packet protection is applied (see {{aead}}).\nThe ciphertext of the packet is sampled and used as input to an encryption\nalgorithm.  The algorithm used depends on the negotiated AEAD.\n\nThe output of this algorithm is a 5-byte mask that is applied to the protected\nheader fields using exclusive OR.  The least significant bits of the first byte\nof the packet are masked by the least significant bits of the first mask byte,\nand the packet number is masked with the remaining bytes.  Any unused bytes of\nmask that might result from a shorter packet number encoding are unused.\n\n{{pseudo-hp}} shows a sample algorithm for applying header protection. Removing\nheader protection only differs in the order in which the packet number length\n(pn_length) is determined (here \"^\" is used to represent exclusive OR).\n\n~~~pseudocode\nmask = header_protection(hp_key, sample)\n\npn_length = (packet[0] & 0x03) + 1\nif (packet[0] & 0x80) == 0x80:\n   # Long header: 4 bits masked\n   packet[0] ^= mask[0] & 0x0f\nelse:\n   # Short header: 5 bits masked\n   packet[0] ^= mask[0] & 0x1f\n\n# pn_offset is the start of the Packet Number field.\npacket[pn_offset:pn_offset+pn_length] ^= mask[1:1+pn_length]\n~~~\n{: #pseudo-hp title=\"Header Protection Pseudocode\"}\n\nSpecific header protection functions are defined based on the selected cipher\nsuite; see {{hp-aes}} and {{hp-chacha}}.\n\n{{fig-sample}} shows an example long header packet (Initial) and a short header\npacket (1-RTT). {{fig-sample}} shows the fields in each header that are covered\nby header protection and the portion of the protected packet payload that is\nsampled.\n\n~~~\nInitial Packet {\n  Header Form (1) = 1,\n  Fixed Bit (1) = 1,\n  Long Packet Type (2) = 0,\n  Reserved Bits (2),         # Protected\n  Packet Number Length (2),  # Protected\n  Version (32),\n  DCID Len (8),\n  Destination Connection ID (0..160),\n  SCID Len (8),\n  Source Connection ID (0..160),\n  Token Length (i),\n  Token (..),\n  Length (i),\n  Packet Number (8..32),     # Protected\n  Protected Payload (0..24), # Skipped Part\n  Protected Payload (128),   # Sampled Part\n  Protected Payload (..)     # Remainder\n}\n\n1-RTT Packet {\n  Header Form (1) = 0,\n  Fixed Bit (1) = 1,\n  Spin Bit (1),\n  Reserved Bits (2),         # Protected\n  Key Phase (1),             # Protected\n  Packet Number Length (2),  # Protected\n  Destination Connection ID (0..160),\n  Packet Number (8..32),     # Protected\n  Protected Payload (0..24), # Skipped Part\n  Protected Payload (128),   # Sampled Part\n  Protected Payload (..),    # Remainder\n}\n~~~\n{: #fig-sample title=\"Header Protection and Ciphertext Sample\"}\n\nBefore a TLS cipher suite can be used with QUIC, a header protection algorithm\nMUST be specified for the AEAD used with that cipher suite.  This document\ndefines algorithms for AEAD_AES_128_GCM, AEAD_AES_128_CCM, AEAD_AES_256_GCM (all\nthese AES AEADs are defined in {{!AEAD=RFC5116}}), and AEAD_CHACHA20_POLY1305\n(defined in {{!CHACHA=RFC8439}}).  Prior to TLS selecting a cipher suite, AES\nheader protection is used ({{hp-aes}}), matching the AEAD_AES_128_GCM packet\nprotection.\n\n\n### Header Protection Sample {#hp-sample}\n\nThe header protection algorithm uses both the header protection key and a sample\nof the ciphertext from the packet Payload field.\n\nThe same number of bytes are always sampled, but an allowance needs to be made\nfor the removal of protection by a receiving endpoint, which will not know the\nlength of the Packet Number field.  The sample of ciphertext is taken starting\nfrom an offset of 4 bytes after the start of the Packet Number field.  That is,\nin sampling packet ciphertext for header protection, the Packet Number field is\nassumed to be 4 bytes long (its maximum possible encoded length).\n\nAn endpoint MUST discard packets that are not long enough to contain a complete\nsample.\n\nTo ensure that sufficient data is available for sampling, packets are padded so\nthat the combined lengths of the encoded packet number and protected payload is\nat least 4 bytes longer than the sample required for header protection.  The\ncipher suites defined in {{!TLS13}} -- other than TLS_AES_128_CCM_8_SHA256, for\nwhich a header protection scheme is not defined in this document -- have 16-byte\nexpansions and 16-byte header protection samples.  This results in needing at\nleast 3 bytes of frames in the unprotected payload if the packet number is\nencoded on a single byte, or 2 bytes of frames for a 2-byte packet number\nencoding.\n\nThe sampled ciphertext can be determined by the following pseudocode:\n\n~~~pseudocode\n# pn_offset is the start of the Packet Number field.\nsample_offset = pn_offset + 4\n\nsample = packet[sample_offset..sample_offset+sample_length]\n~~~\n\nWhere the packet number offset of a short header packet can be calculated as:\n\n~~~pseudocode\npn_offset = 1 + len(connection_id)\n~~~\n\nAnd the packet number offset of a long header packet can be calculated as:\n\n~~~pseudocode\npn_offset = 7 + len(destination_connection_id) +\n                len(source_connection_id) +\n                len(payload_length)\nif packet_type == Initial:\n    pn_offset += len(token_length) +\n                 len(token)\n~~~\n\nFor example, for a packet with a short header, an 8-byte connection ID, and\nprotected with AEAD_AES_128_GCM, the sample takes bytes 13 to 28 inclusive\n(using zero-based indexing).\n\nMultiple QUIC packets might be included in the same UDP datagram. Each packet\nis handled separately.\n\n\n### AES-Based Header Protection {#hp-aes}\n\nThis section defines the packet protection algorithm for AEAD_AES_128_GCM,\nAEAD_AES_128_CCM, and AEAD_AES_256_GCM. AEAD_AES_128_GCM and AEAD_AES_128_CCM\nuse 128-bit AES in Electronic Codebook (ECB) mode. AEAD_AES_256_GCM uses\n256-bit AES in ECB mode.  AES is defined in {{!AES=DOI.10.6028/NIST.FIPS.197}}.\n\nThis algorithm samples 16 bytes from the packet ciphertext. This value is used\nas the input to AES-ECB.  In pseudocode, the header protection function is\ndefined as:\n\n~~~pseudocode\nheader_protection(hp_key, sample):\n  mask = AES-ECB(hp_key, sample)\n~~~\n\n\n### ChaCha20-Based Header Protection {#hp-chacha}\n\nWhen AEAD_CHACHA20_POLY1305 is in use, header protection uses the raw ChaCha20\nfunction as defined in {{Section 2.4 of CHACHA}}.  This uses a 256-bit key and\n16 bytes sampled from the packet protection output.\n\nThe first 4 bytes of the sampled ciphertext are the block counter.  A ChaCha20\nimplementation could take a 32-bit integer in place of a byte sequence, in\nwhich case, the byte sequence is interpreted as a little-endian value.\n\nThe remaining 12 bytes are used as the nonce. A ChaCha20 implementation might\ntake an array of three 32-bit integers in place of a byte sequence, in which\ncase, the nonce bytes are interpreted as a sequence of 32-bit little-endian\nintegers.\n\nThe encryption mask is produced by invoking ChaCha20 to protect 5 zero bytes. In\npseudocode, the header protection function is defined as:\n\n~~~pseudocode\nheader_protection(hp_key, sample):\n  counter = sample[0..3]\n  nonce = sample[4..15]\n  mask = ChaCha20(hp_key, counter, nonce, {0,0,0,0,0})\n~~~\n\n\n## Receiving Protected Packets\n\nOnce an endpoint successfully receives a packet with a given packet number, it\nMUST discard all packets in the same packet number space with higher packet\nnumbers if they cannot be successfully unprotected with either the same key, or\n-- if there is a key update -- a subsequent packet protection key; see\n{{key-update}}.  Similarly, a packet that appears to trigger a key update but\ncannot be unprotected successfully MUST be discarded.\n\nFailure to unprotect a packet does not necessarily indicate the existence of a\nprotocol error in a peer or an attack.  The truncated packet number encoding\nused in QUIC can cause packet numbers to be decoded incorrectly if they are\ndelayed significantly.\n\n\n## Use of 0-RTT Keys {#using-early-data}\n\nIf 0-RTT keys are available (see {{enable-0rtt}}), the lack of replay protection\nmeans that restrictions on their use are necessary to avoid replay attacks on\nthe protocol.\n\nOf the frames defined in {{QUIC-TRANSPORT}}, the STREAM, RESET_STREAM,\nSTOP_SENDING, and CONNECTION_CLOSE frames are potentially unsafe for use with\n0-RTT as they carry application data. Application data that is received in\n0-RTT could cause an application at the server to process the data multiple\ntimes rather than just once. Additional actions taken by a server as a result\nof processing replayed application data could have unwanted consequences. A\nclient therefore MUST NOT use 0-RTT for application data unless specifically\nrequested by the application that is in use.\n\nAn application protocol that uses QUIC MUST include a profile that defines\nacceptable use of 0-RTT; otherwise, 0-RTT can only be used to carry QUIC frames\nthat do not carry application data. For example, a profile for HTTP is\ndescribed in {{?HTTP-REPLAY=RFC8470}} and used for HTTP/3; see\n{{Section 10.9 of QUIC-HTTP}}.\n\nThough replaying packets might result in additional connection attempts, the\neffect of processing replayed frames that do not carry application data is\nlimited to changing the state of the affected connection. A TLS handshake\ncannot be successfully completed using replayed packets.\n\nA client MAY wish to apply additional restrictions on what data it sends prior\nto the completion of the TLS handshake.\n\nA client otherwise treats 0-RTT keys as equivalent to 1-RTT keys, except that\nit cannot send certain frames with 0-RTT keys; see\n{{Section 12.5 of QUIC-TRANSPORT}}.\n\nA client that receives an indication that its 0-RTT data has been accepted by a\nserver can send 0-RTT data until it receives all of the server's handshake\nmessages.  A client SHOULD stop sending 0-RTT data if it receives an indication\nthat 0-RTT data has been rejected.\n\nA server MUST NOT use 0-RTT keys to protect packets; it uses 1-RTT keys to\nprotect acknowledgments of 0-RTT packets.  A client MUST NOT attempt to\ndecrypt 0-RTT packets it receives and instead MUST discard them.\n\nOnce a client has installed 1-RTT keys, it MUST NOT send any more 0-RTT\npackets.\n\n<aside markdown=\"block\">\nNote: 0-RTT data can be acknowledged by the server as it receives it, but any\n  packets containing acknowledgments of 0-RTT data cannot have packet protection\n  removed by the client until the TLS handshake is complete.  The 1-RTT keys\n  necessary to remove packet protection cannot be derived until the client\n  receives all server handshake messages.\n</aside>\n\n\n## Receiving Out-of-Order Protected Packets {#pre-hs-protected}\n\nDue to reordering and loss, protected packets might be received by an endpoint\nbefore the final TLS handshake messages are received.  A client will be unable\nto decrypt 1-RTT packets from the server, whereas a server will be able to\ndecrypt 1-RTT packets from the client.  Endpoints in either role MUST NOT\ndecrypt 1-RTT packets from their peer prior to completing the handshake.\n\nEven though 1-RTT keys are available to a server after receiving the first\nhandshake messages from a client, it is missing assurances on the client state:\n\n- The client is not authenticated, unless the server has chosen to use a\n  pre-shared key and validated the client's pre-shared key binder; see {{Section\n  4.2.11 of TLS13}}.\n\n- The client has not demonstrated liveness, unless the server has validated the\n  client's address with a Retry packet or other means; see\n  {{Section 8.1 of QUIC-TRANSPORT}}.\n\n- Any received 0-RTT data that the server responds to might be due to a replay\n  attack.\n\nTherefore, the server's use of 1-RTT keys before the handshake is complete is\nlimited to sending data.  A server MUST NOT process incoming 1-RTT protected\npackets before the TLS handshake is complete.  Because sending acknowledgments\nindicates that all frames in a packet have been processed, a server cannot send\nacknowledgments for 1-RTT packets until the TLS handshake is complete.  Received\npackets protected with 1-RTT keys MAY be stored and later decrypted and used\nonce the handshake is complete.\n\n<aside markdown=\"block\">\nNote: TLS implementations might provide all 1-RTT secrets prior to handshake\n  completion.  Even where QUIC implementations have 1-RTT read keys, those keys\n  are not to be used prior to completing the handshake.\n</aside>\n\nThe requirement for the server to wait for the client Finished message creates\na dependency on that message being delivered.  A client can avoid the\npotential for head-of-line blocking that this implies by sending its 1-RTT\npackets coalesced with a Handshake packet containing a copy of the CRYPTO frame\nthat carries the Finished message, until one of the Handshake packets is\nacknowledged.  This enables immediate server processing for those packets.\n\nA server could receive packets protected with 0-RTT keys prior to receiving a\nTLS ClientHello.  The server MAY retain these packets for later decryption in\nanticipation of receiving a ClientHello.\n\nA client generally receives 1-RTT keys at the same time as the handshake\ncompletes.  Even if it has 1-RTT secrets, a client MUST NOT process\nincoming 1-RTT protected packets before the TLS handshake is complete.\n\n\n## Retry Packet Integrity {#retry-integrity}\n\nRetry packets (see {{Section 17.2.5 of QUIC-TRANSPORT}}) carry a Retry Integrity\nTag that provides two properties: it allows the discarding of packets that have\naccidentally been corrupted by the network, and only an entity that observes an\nInitial packet can send a valid Retry packet.\n\nThe Retry Integrity Tag is a 128-bit field that is computed as the output of\nAEAD_AES_128_GCM {{!AEAD}} used with the following inputs:\n\n- The secret key, K, is 128 bits equal to 0xbe0c690b9f66575a1d766b54e368c84e.\n- The nonce, N, is 96 bits equal to 0x461599d35d632bf2239825bb.\n- The plaintext, P, is empty.\n- The associated data, A, is the contents of the Retry Pseudo-Packet, as\n  illustrated in {{retry-pseudo}}:\n\nThe secret key and the nonce are values derived by calling HKDF-Expand-Label\nusing 0xd9c9943e6101fd200021506bcc02814c73030f25c79d71ce876eca876e6fca8e as the\nsecret, with labels being \"quic key\" and \"quic iv\" ({{protection-keys}}).\n\n~~~\nRetry Pseudo-Packet {\n  ODCID Length (8),\n  Original Destination Connection ID (0..160),\n  Header Form (1) = 1,\n  Fixed Bit (1) = 1,\n  Long Packet Type (2) = 3,\n  Unused (4),\n  Version (32),\n  DCID Len (8),\n  Destination Connection ID (0..160),\n  SCID Len (8),\n  Source Connection ID (0..160),\n  Retry Token (..),\n}\n~~~\n{: #retry-pseudo title=\"Retry Pseudo-Packet\"}\n\nThe Retry Pseudo-Packet is not sent over the wire. It is computed by taking\nthe transmitted Retry packet, removing the Retry Integrity Tag, and prepending\nthe two following fields:\n\nODCID Length:\n\n: The ODCID Length field contains the length in bytes of the Original\n  Destination Connection ID field that follows it, encoded as an 8-bit unsigned\n  integer.\n\nOriginal Destination Connection ID:\n\n: The Original Destination Connection ID contains the value of the Destination\n  Connection ID from the Initial packet that this Retry is in response to. The\n  length of this field is given in ODCID Length. The presence of this field\n  ensures that a valid Retry packet can only be sent by an entity that\n  observes the Initial packet.\n\n\n# Key Update\n\nOnce the handshake is confirmed (see {{handshake-confirmed}}), an endpoint MAY\ninitiate a key update.\n\nThe Key Phase bit indicates which packet protection keys are used to protect the\npacket.  The Key Phase bit is initially set to 0 for the first set of 1-RTT\npackets and toggled to signal each subsequent key update.\n\nThe Key Phase bit allows a recipient to detect a change in keying material\nwithout needing to receive the first packet that triggered the change.  An\nendpoint that notices a changed Key Phase bit updates keys and decrypts the\npacket that contains the changed value.\n\nInitiating a key update results in both endpoints updating keys.  This differs\nfrom TLS where endpoints can update keys independently.\n\nThis mechanism replaces the key update mechanism of TLS, which relies on\nKeyUpdate messages sent using 1-RTT encryption keys.  Endpoints MUST NOT send a\nTLS KeyUpdate message.  Endpoints MUST treat the receipt of a TLS KeyUpdate\nmessage as a connection error of type 0x010a, equivalent to a\nfatal TLS alert of unexpected_message; see {{tls-errors}}.\n\n{{ex-key-update}} shows a key update process, where the initial set of keys used\n(identified with @M) are replaced by updated keys (identified with @N).  The\nvalue of the Key Phase bit is indicated in brackets \\[].\n\n~~~\n   Initiating Peer                    Responding Peer\n\n@M [0] QUIC Packets\n\n... Update to @N\n@N [1] QUIC Packets\n                      -------->\n                                         Update to @N ...\n                                      QUIC Packets [1] @N\n                      <--------\n                                      QUIC Packets [1] @N\n                                    containing ACK\n                      <--------\n... Key Update Permitted\n\n@N [1] QUIC Packets\n         containing ACK for @N packets\n                      -------->\n                                 Key Update Permitted ...\n~~~\n{: #ex-key-update title=\"Key Update\"}\n\n\n## Initiating a Key Update {#key-update-initiate}\n\nEndpoints maintain separate read and write secrets for packet protection.  An\nendpoint initiates a key update by updating its packet protection write secret\nand using that to protect new packets.  The endpoint creates a new write secret\nfrom the existing write secret as performed in {{Section 7.2 of TLS13}}.  This\nuses the KDF function provided by TLS with a label of \"quic ku\".  The\ncorresponding key and IV are created from that secret as defined in\n{{protection-keys}}.  The header protection key is not updated.\n\nFor example, to update write keys with TLS 1.3, HKDF-Expand-Label is used as:\n\n~~~pseudocode\nsecret_<n+1> = HKDF-Expand-Label(secret_<n>, \"quic ku\",\n                                 \"\", Hash.length)\n~~~\n\nThe endpoint toggles the value of the Key Phase bit and uses the updated key and\nIV to protect all subsequent packets.\n\nAn endpoint MUST NOT initiate a key update prior to having confirmed the\nhandshake ({{handshake-confirmed}}).  An endpoint MUST NOT initiate a subsequent\nkey update unless it has received an acknowledgment for a packet that was sent\nprotected with keys from the current key phase.  This ensures that keys are\navailable to both peers before another key update can be initiated.  This can be\nimplemented by tracking the lowest packet number sent with each key phase and\nthe highest acknowledged packet number in the 1-RTT space: once the latter is\nhigher than or equal to the former, another key update can be initiated.\n\n<aside markdown=\"block\">\nNote: Keys of packets other than the 1-RTT packets are never updated; their keys\n  are derived solely from the TLS handshake state.\n</aside>\n\nThe endpoint that initiates a key update also updates the keys that it uses for\nreceiving packets.  These keys will be needed to process packets the peer sends\nafter updating.\n\nAn endpoint MUST retain old keys until it has successfully unprotected a packet\nsent using the new keys.  An endpoint SHOULD retain old keys for some time\nafter unprotecting a packet sent using the new keys.  Discarding old keys too\nearly can cause delayed packets to be discarded.  Discarding packets will be\ninterpreted as packet loss by the peer and could adversely affect performance.\n\n\n## Responding to a Key Update\n\nA peer is permitted to initiate a key update after receiving an acknowledgment\nof a packet in the current key phase.  An endpoint detects a key update when\nprocessing a packet with a key phase that differs from the value used to protect\nthe last packet it sent.  To process this packet, the endpoint uses the next\npacket protection key and IV.  See {{receive-key-generation}} for considerations\nabout generating these keys.\n\nIf a packet is successfully processed using the next key and IV, then the peer\nhas initiated a key update.  The endpoint MUST update its send keys to the\ncorresponding key phase in response, as described in {{key-update-initiate}}.\nSending keys MUST be updated before sending an acknowledgment for the packet\nthat was received with updated keys.  By acknowledging the packet that triggered\nthe key update in a packet protected with the updated keys, the endpoint signals\nthat the key update is complete.\n\nAn endpoint can defer sending the packet or acknowledgment according to its\nnormal packet sending behavior; it is not necessary to immediately generate a\npacket in response to a key update.  The next packet sent by the endpoint will\nuse the updated keys.  The next packet that contains an acknowledgment will\ncause the key update to be completed.  If an endpoint detects a second update\nbefore it has sent any packets with updated keys containing an\nacknowledgment for the packet that initiated the key update, it indicates that\nits peer has updated keys twice without awaiting confirmation.  An endpoint MAY\ntreat such consecutive key updates as a connection error of type\nKEY_UPDATE_ERROR.\n\nAn endpoint that receives an acknowledgment that is carried in a packet\nprotected with old keys where any acknowledged packet was protected with newer\nkeys MAY treat that as a connection error of type KEY_UPDATE_ERROR.  This\nindicates that a peer has received and acknowledged a packet that initiates a\nkey update, but has not updated keys in response.\n\n\n## Timing of Receive Key Generation {#receive-key-generation}\n\nEndpoints responding to an apparent key update MUST NOT generate a timing\nside-channel signal that might indicate that the Key Phase bit was invalid (see\n{{hp-side-channel}}).  Endpoints can use randomized packet protection keys in\nplace of discarded keys when key updates are not yet permitted.  Using\nrandomized keys ensures that attempting to remove packet protection does not\nresult in timing variations, and results in packets with an invalid Key Phase\nbit being rejected.\n\nThe process of creating new packet protection keys for receiving packets could\nreveal that a key update has occurred. An endpoint MAY generate new keys as\npart of packet processing, but this creates a timing signal that could be used\nby an attacker to learn when key updates happen and thus leak the value of the\nKey Phase bit.\n\nEndpoints are generally expected to have current and next receive packet\nprotection keys available. For a short period after a key update completes, up\nto the PTO, endpoints MAY defer generation of the next set of\nreceive packet protection keys. This allows endpoints\nto retain only two sets of receive keys; see {{old-keys-recv}}.\n\nOnce generated, the next set of packet protection keys SHOULD be retained, even\nif the packet that was received was subsequently discarded.  Packets containing\napparent key updates are easy to forge, and while the process of key update does\nnot require significant effort, triggering this process could be used by an\nattacker for DoS.\n\nFor this reason, endpoints MUST be able to retain two sets of packet protection\nkeys for receiving packets: the current and the next.  Retaining the previous\nkeys in addition to these might improve performance, but this is not essential.\n\n\n## Sending with Updated Keys {#old-keys-send}\n\nAn endpoint never sends packets that are protected with old keys.  Only the\ncurrent keys are used.  Keys used for protecting packets can be discarded\nimmediately after switching to newer keys.\n\nPackets with higher packet numbers MUST be protected with either the same or\nnewer packet protection keys than packets with lower packet numbers.  An\nendpoint that successfully removes protection with old keys when newer keys were\nused for packets with lower packet numbers MUST treat this as a connection error\nof type KEY_UPDATE_ERROR.\n\n\n## Receiving with Different Keys {#old-keys-recv}\n\nFor receiving packets during a key update, packets protected with older keys\nmight arrive if they were delayed by the network.  Retaining old packet\nprotection keys allows these packets to be successfully processed.\n\nAs packets protected with keys from the next key phase use the same Key Phase\nvalue as those protected with keys from the previous key phase, it is necessary\nto distinguish between the two if packets protected with old keys are to be\nprocessed.  This can be done using packet numbers.  A recovered packet number\nthat is lower than any packet number from the current key phase uses the\nprevious packet protection keys; a recovered packet number that is higher than\nany packet number from the current key phase requires the use of the next packet\nprotection keys.\n\nSome care is necessary to ensure that any process for selecting between\nprevious, current, and next packet protection keys does not expose a timing side\nchannel that might reveal which keys were used to remove packet protection.  See\n{{hp-side-channel}} for more information.\n\nAlternatively, endpoints can retain only two sets of packet protection keys,\nswapping previous for next after enough time has passed to allow for reordering\nin the network.  In this case, the Key Phase bit alone can be used to select\nkeys.\n\nAn endpoint MAY allow a period of approximately the Probe Timeout (PTO; see\n{{QUIC-RECOVERY}}) after promoting the next set of receive keys to be current\nbefore it creates the subsequent set of packet protection keys. These updated\nkeys MAY replace the previous keys at that time. With the caveat that PTO is a\nsubjective measure -- that is, a peer could have a different view of the RTT --\nthis time is expected to be long enough that any reordered packets would be\ndeclared lost by a peer even if they were acknowledged and short enough to allow\na peer to initiate further key updates.\n\nEndpoints need to allow for the possibility that a peer might not be able to\ndecrypt packets that initiate a key update during the period when the peer\nretains old keys.  Endpoints SHOULD wait three times the PTO before initiating a\nkey update after receiving an acknowledgment that confirms that the previous key\nupdate was received.  Failing to allow sufficient time could lead to packets\nbeing discarded.\n\nAn endpoint SHOULD retain old read keys for no more than three times the PTO\nafter having received a packet protected using the new keys. After this period,\nold read keys and their corresponding secrets SHOULD be discarded.\n\n\n## Limits on AEAD Usage {#aead-limits}\n\nThis document sets usage limits for AEAD algorithms to ensure that overuse does\nnot give an adversary a disproportionate advantage in attacking the\nconfidentiality and integrity of communications when using QUIC.\n\nThe usage limits defined in TLS 1.3 exist for protection against attacks\non confidentiality and apply to successful applications of AEAD protection. The\nintegrity protections in authenticated encryption also depend on limiting the\nnumber of attempts to forge packets. TLS achieves this by closing connections\nafter any record fails an authentication check. In comparison, QUIC ignores any\npacket that cannot be authenticated, allowing multiple forgery attempts.\n\nQUIC accounts for AEAD confidentiality and integrity limits separately. The\nconfidentiality limit applies to the number of packets encrypted with a given\nkey. The integrity limit applies to the number of packets decrypted within a\ngiven connection. Details on enforcing these limits for each AEAD algorithm\nfollow below.\n\nEndpoints MUST count the number of encrypted packets for each set of keys. If\nthe total number of encrypted packets with the same key exceeds the\nconfidentiality limit for the selected AEAD, the endpoint MUST stop using those\nkeys. Endpoints MUST initiate a key update before sending more protected packets\nthan the confidentiality limit for the selected AEAD permits. If a key update\nis not possible or integrity limits are reached, the endpoint MUST stop using\nthe connection and only send stateless resets in response to receiving packets.\nIt is RECOMMENDED that endpoints immediately close the connection with a\nconnection error of type AEAD_LIMIT_REACHED before reaching a state where key\nupdates are not possible.\n\nFor AEAD_AES_128_GCM and AEAD_AES_256_GCM, the confidentiality limit is\n2<sup>23</sup> encrypted packets; see {{gcm-bounds}}. For\nAEAD_CHACHA20_POLY1305, the confidentiality limit is greater than the number of\npossible packets (2<sup>62</sup>) and so can be disregarded. For\nAEAD_AES_128_CCM, the confidentiality limit is 2<sup>21.5</sup> encrypted\npackets; see {{ccm-bounds}}. Applying a limit reduces the probability that an\nattacker can distinguish the AEAD in use from a random permutation; see\n{{AEBounds}}, {{ROBUST}}, and {{GCM-MU}}.\n\nIn addition to counting packets sent, endpoints MUST count the number of\nreceived packets that fail authentication during the lifetime of a connection.\nIf the total number of received packets that fail authentication within the\nconnection, across all keys, exceeds the integrity limit for the selected AEAD,\nthe endpoint MUST immediately close the connection with a connection error of\ntype AEAD_LIMIT_REACHED and not process any more packets.\n\nFor AEAD_AES_128_GCM and AEAD_AES_256_GCM, the integrity limit is 2<sup>52</sup>\ninvalid packets; see {{gcm-bounds}}. For AEAD_CHACHA20_POLY1305, the integrity\nlimit is 2<sup>36</sup> invalid packets; see {{AEBounds}}. For AEAD_AES_128_CCM,\nthe integrity limit is 2<sup>21.5</sup> invalid packets; see\n{{ccm-bounds}}. Applying this limit reduces the probability that an attacker can\nsuccessfully forge a packet; see {{AEBounds}}, {{ROBUST}}, and {{GCM-MU}}.\n\nEndpoints that limit the size of packets MAY use higher confidentiality and\nintegrity limits; see {{aead-analysis}} for details.\n\nFuture analyses and specifications MAY relax confidentiality or integrity limits\nfor an AEAD.\n\nAny TLS cipher suite that is specified for use with QUIC MUST define limits on\nthe use of the associated AEAD function that preserves margins for\nconfidentiality and integrity. That is, limits MUST be specified for the number\nof packets that can be authenticated and for the number of packets that can fail\nauthentication.  Providing a reference to any analysis upon which values are\nbased -- and any assumptions used in that analysis -- allows limits to be\nadapted to varying usage conditions.\n\n\n## Key Update Error Code {#key-update-error}\n\nThe KEY_UPDATE_ERROR error code (0x0e) is used to signal errors related to key\nupdates.\n\n\n# Security of Initial Messages\n\nInitial packets are not protected with a secret key, so they are subject to\npotential tampering by an attacker.  QUIC provides protection against attackers\nthat cannot read packets but does not attempt to provide additional protection\nagainst attacks where the attacker can observe and inject packets.  Some forms\nof tampering -- such as modifying the TLS messages themselves -- are detectable,\nbut some -- such as modifying ACKs -- are not.\n\nFor example, an attacker could inject a packet containing an ACK frame to\nmake it appear that a packet had not been received or to create a false\nimpression of the state of the connection (e.g., by modifying the ACK Delay).\nNote that such a packet could cause a legitimate packet to be dropped as a\nduplicate.  Implementations SHOULD use caution in relying on any data that is\ncontained in Initial packets that is not otherwise authenticated.\n\nIt is also possible for the attacker to tamper with data that is carried in\nHandshake packets, but because that sort of tampering requires modifying TLS\nhandshake messages, any such tampering will cause the TLS handshake to fail.\n\n\n# QUIC-Specific Adjustments to the TLS Handshake\n\nCertain aspects of the TLS handshake are different when used with QUIC.\n\nQUIC also requires additional features from TLS.  In addition to negotiation of\ncryptographic parameters, the TLS handshake carries and authenticates values for\nQUIC transport parameters.\n\n\n## Protocol Negotiation {#protocol-negotiation}\n\nQUIC requires that the cryptographic handshake provide authenticated protocol\nnegotiation.  TLS uses Application-Layer Protocol Negotiation\n{{!ALPN=RFC7301}} to select an application protocol.  Unless another mechanism\nis used for agreeing on an application protocol, endpoints MUST use ALPN for\nthis purpose.\n\nWhen using ALPN, endpoints MUST immediately close a connection (see {{Section\n10.2 of QUIC-TRANSPORT}}) with a no_application_protocol TLS alert (QUIC error\ncode 0x0178; see {{tls-errors}}) if an application protocol is not negotiated.\nWhile {{!ALPN}} only specifies that servers use this alert, QUIC clients MUST\nuse error 0x0178 to terminate a connection when ALPN negotiation fails.\n\nAn application protocol MAY restrict the QUIC versions that it can operate over.\nServers MUST select an application protocol compatible with the QUIC version\nthat the client has selected.  The server MUST treat the inability to select a\ncompatible application protocol as a connection error of type 0x0178\n(no_application_protocol).  Similarly, a client MUST treat the selection of an\nincompatible application protocol by a server as a connection error of type\n0x0178.\n\n\n## QUIC Transport Parameters Extension {#quic_parameters}\n\nQUIC transport parameters are carried in a TLS extension. Different versions of\nQUIC might define a different method for negotiating transport configuration.\n\nIncluding transport parameters in the TLS handshake provides integrity\nprotection for these values.\n\n~~~tls-presentation\n   enum {\n      quic_transport_parameters(0x39), (65535)\n   } ExtensionType;\n~~~\n\nThe extension_data field of the quic_transport_parameters extension contains a\nvalue that is defined by the version of QUIC that is in use.\n\nThe quic_transport_parameters extension is carried in the ClientHello and the\nEncryptedExtensions messages during the handshake. Endpoints MUST send the\nquic_transport_parameters extension; endpoints that receive ClientHello or\nEncryptedExtensions messages without the quic_transport_parameters extension\nMUST close the connection with an error of type 0x016d (equivalent to a fatal\nTLS missing_extension alert, see {{tls-errors}}).\n\nTransport parameters become available prior to the completion of the handshake.\nA server might use these values earlier than handshake completion. However, the\nvalue of transport parameters is not authenticated until the handshake\ncompletes, so any use of these parameters cannot depend on their authenticity.\nAny tampering with transport parameters will cause the handshake to fail.\n\nEndpoints MUST NOT send this extension in a TLS connection that does not use\nQUIC (such as the use of TLS with TCP defined in {{!TLS13}}).  A fatal\nunsupported_extension alert MUST be sent by an implementation that supports this\nextension if the extension is received when the transport is not QUIC.\n\nNegotiating the quic_transport_parameters extension causes the EndOfEarlyData to\nbe removed; see {{remove-eoed}}.\n\n\n## Removing the EndOfEarlyData Message {#remove-eoed}\n\nThe TLS EndOfEarlyData message is not used with QUIC.  QUIC does not rely on\nthis message to mark the end of 0-RTT data or to signal the change to Handshake\nkeys.\n\nClients MUST NOT send the EndOfEarlyData message.  A server MUST treat receipt\nof a CRYPTO frame in a 0-RTT packet as a connection error of type\nPROTOCOL_VIOLATION.\n\nAs a result, EndOfEarlyData does not appear in the TLS handshake transcript.\n\n\n## Prohibit TLS Middlebox Compatibility Mode {#compat-mode}\n\nAppendix D.4 of {{!TLS13}} describes an alteration to the TLS 1.3 handshake as\na workaround for bugs in some middleboxes. The TLS 1.3 middlebox compatibility\nmode involves setting the legacy_session_id field to a 32-byte value in the\nClientHello and ServerHello, then sending a change_cipher_spec record. Both\nfield and record carry no semantic content and are ignored.\n\nThis mode has no use in QUIC as it only applies to middleboxes that interfere\nwith TLS over TCP. QUIC also provides no means to carry a change_cipher_spec\nrecord. A client MUST NOT request the use of the TLS 1.3 compatibility mode. A\nserver SHOULD treat the receipt of a TLS ClientHello with a non-empty\nlegacy_session_id field as a connection error of type PROTOCOL_VIOLATION.\n\n\n# Security Considerations\n\nAll of the security considerations that apply to TLS also apply to the use of\nTLS in QUIC. Reading all of {{!TLS13}} and its appendices is the best way to\ngain an understanding of the security properties of QUIC.\n\nThis section summarizes some of the more important security aspects specific to\nthe TLS integration, though there are many security-relevant details in the\nremainder of the document.\n\n\n## Session Linkability\n\nUse of TLS session tickets allows servers and possibly other entities to\ncorrelate connections made by the same client; see {{resumption}} for details.\n\n\n## Replay Attacks with 0-RTT {#replay}\n\nAs described in {{Section 8 of TLS13}}, use of TLS early data comes with an\nexposure to replay attack.  The use of 0-RTT in QUIC is similarly vulnerable to\nreplay attack.\n\nEndpoints MUST implement and use the replay protections described in {{!TLS13}},\nhowever it is recognized that these protections are imperfect.  Therefore,\nadditional consideration of the risk of replay is needed.\n\nQUIC is not vulnerable to replay attack, except via the application protocol\ninformation it might carry.  The management of QUIC protocol state based on the\nframe types defined in {{QUIC-TRANSPORT}} is not vulnerable to replay.\nProcessing of QUIC frames is idempotent and cannot result in invalid connection\nstates if frames are replayed, reordered, or lost.  QUIC connections do not\nproduce effects that last beyond the lifetime of the connection, except for\nthose produced by the application protocol that QUIC serves.\n\nTLS session tickets and address validation tokens are used to carry QUIC\nconfiguration information between connections, specifically, to enable a server\nto efficiently recover state that is used in connection establishment and\naddress validation.  These MUST NOT be used to communicate application semantics\nbetween endpoints; clients MUST treat them as opaque values.  The potential for\nreuse of these tokens means that they require stronger protections against\nreplay.\n\nA server that accepts 0-RTT on a connection incurs a higher cost than accepting\na connection without 0-RTT.  This includes higher processing and computation\ncosts.  Servers need to consider the probability of replay and all associated\ncosts when accepting 0-RTT.\n\nUltimately, the responsibility for managing the risks of replay attacks with\n0-RTT lies with an application protocol.  An application protocol that uses QUIC\nMUST describe how the protocol uses 0-RTT and the measures that are employed to\nprotect against replay attack.  An analysis of replay risk needs to consider\nall QUIC protocol features that carry application semantics.\n\nDisabling 0-RTT entirely is the most effective defense against replay attack.\n\nQUIC extensions MUST either describe how replay attacks affect their operation\nor prohibit the use of the extension in 0-RTT.  Application protocols MUST\neither prohibit the use of extensions that carry application semantics in 0-RTT\nor provide replay mitigation strategies.\n\n\n## Packet Reflection Attack Mitigation {#reflection}\n\nA small ClientHello that results in a large block of handshake messages from a\nserver can be used in packet reflection attacks to amplify the traffic generated\nby an attacker.\n\nQUIC includes three defenses against this attack. First, the packet containing\na ClientHello MUST be padded to a minimum size. Second, if responding to an\nunverified source address, the server is forbidden to send more than three\ntimes as many bytes as the number of bytes it has received (see {{Section 8.1\nof QUIC-TRANSPORT}}). Finally, because acknowledgments of Handshake packets are\nauthenticated, a blind attacker cannot forge them. Put together, these defenses\nlimit the level of amplification.\n\n\n## Header Protection Analysis {#header-protect-analysis}\n\n{{NAN}} analyzes authenticated encryption\nalgorithms that provide nonce privacy, referred to as \"Hide Nonce\" (HN)\ntransforms. The general header protection construction in this document is\none of those algorithms (HN1). Header protection is applied after the packet\nprotection AEAD, sampling a set of bytes (`sample`) from the AEAD output and\nencrypting the header field using a pseudorandom function (PRF) as follows:\n\n~~~pseudocode\nprotected_field = field XOR PRF(hp_key, sample)\n~~~\n\nThe header protection variants in this document use a pseudorandom permutation\n(PRP) in place of a generic PRF. However, since all PRPs are also PRFs {{IMC}},\nthese variants do not deviate from the HN1 construction.\n\nAs `hp_key` is distinct from the packet protection key, it follows that header\nprotection achieves AE2 security as defined in {{NAN}} and therefore guarantees\nprivacy of `field`, the protected packet header. Future header protection\nvariants based on this construction MUST use a PRF to ensure equivalent\nsecurity guarantees.\n\nUse of the same key and ciphertext sample more than once risks compromising\nheader protection. Protecting two different headers with the same key and\nciphertext sample reveals the exclusive OR of the protected fields.  Assuming\nthat the AEAD acts as a PRF, if L bits are sampled, the odds of two ciphertext\nsamples being identical approach 2<sup>-L/2</sup>, that is, the birthday bound.\nFor the algorithms described in this document, that probability is one in\n2<sup>64</sup>.\n\nTo prevent an attacker from modifying packet headers, the header is transitively\nauthenticated using packet protection; the entire packet header is part of the\nauthenticated additional data.  Protected fields that are falsified or modified\ncan only be detected once the packet protection is removed.\n\n\n## Header Protection Timing Side Channels {#hp-side-channel}\n\nAn attacker could guess values for packet numbers or Key Phase and have an\nendpoint confirm guesses through timing side channels.  Similarly, guesses for\nthe packet number length can be tried and exposed.  If the recipient of a packet\ndiscards packets with duplicate packet numbers without attempting to remove\npacket protection, they could reveal through timing side channels that the\npacket number matches a received packet.  For authentication to be free from\nside channels, the entire process of header protection removal, packet number\nrecovery, and packet protection removal MUST be applied together without timing\nand other side channels.\n\nFor the sending of packets, construction and protection of packet payloads and\npacket numbers MUST be free from side channels that would reveal the packet\nnumber or its encoded size.\n\nDuring a key update, the time taken to generate new keys could reveal through\ntiming side channels that a key update has occurred.  Alternatively, where an\nattacker injects packets, this side channel could reveal the value of the Key\nPhase on injected packets.  After receiving a key update, an endpoint SHOULD\ngenerate and save the next set of receive packet protection keys, as described\nin {{receive-key-generation}}.  By generating new keys before a key update is\nreceived, receipt of packets will not create timing signals that leak the value\nof the Key Phase.\n\nThis depends on not doing this key generation during packet processing, and it\ncan require that endpoints maintain three sets of packet protection keys for\nreceiving: for the previous key phase, for the current key phase, and for the\nnext key phase.  Endpoints can instead choose to defer generation of the next\nreceive packet protection keys until they discard old keys so that only two sets\nof receive keys need to be retained at any point in time.\n\n\n## Key Diversity\n\nIn using TLS, the central key schedule of TLS is used.  As a result of the TLS\nhandshake messages being integrated into the calculation of secrets, the\ninclusion of the QUIC transport parameters extension ensures that the handshake\nand 1-RTT keys are not the same as those that might be produced by a server\nrunning TLS over TCP.  To avoid the possibility of cross-protocol key\nsynchronization, additional measures are provided to improve key separation.\n\nThe QUIC packet protection keys and IVs are derived using a different label than\nthe equivalent keys in TLS.\n\nTo preserve this separation, a new version of QUIC SHOULD define new labels for\nkey derivation for packet protection key and IV, plus the header protection\nkeys.  This version of QUIC uses the string \"quic\".  Other versions can use a\nversion-specific label in place of that string.\n\nThe initial secrets use a key that is specific to the negotiated QUIC version.\nNew QUIC versions SHOULD define a new salt value used in calculating initial\nsecrets.\n\n\n## Randomness\n\nQUIC depends on endpoints being able to generate secure random numbers, both\ndirectly for protocol values such as the connection ID, and transitively via\nTLS. See {{!RFC4086}} for guidance on secure random number generation.\n\n\n# IANA Considerations\n\nIANA has registered a codepoint of 57 (or 0x39) for the\nquic_transport_parameters extension (defined in {{quic_parameters}}) in the \"TLS\nExtensionType Values\" registry {{!TLS-REGISTRIES=RFC8447}}.\n\nThe Recommended column for this extension is marked Yes. The TLS 1.3 Column\nincludes CH (ClientHello) and EE (EncryptedExtensions).\n\n| Value | Extension Name            | TLS 1.3 | Recommended | Reference     |\n|------:|:--------------------------|:--------|:------------|:--------------|\n| 57    | quic_transport_parameters | CH, EE  | Y           | This document |\n{: #iana-tls-ext title=\"TLS ExtensionType Values Registry Entry\" cols=\"r l l l l\"}\n\n\n--- back\n\n# Sample Packet Protection {#test-vectors}\n\nThis section shows examples of packet protection so that implementations can be\nverified incrementally. Samples of Initial packets from both client and server\nplus a Retry packet are defined. These packets use an 8-byte client-chosen\nDestination Connection ID of 0x8394c8f03e515708. Some intermediate values are\nincluded. All values are shown in hexadecimal.\n\n\n## Keys\n\nThe labels generated during the execution of the HKDF-Expand-Label function\n(that is, HkdfLabel.label) and part of the value given to the HKDF-Expand\nfunction in order to produce its output are:\n\nclient in:\n: 00200f746c73313320636c69656e7420696e00\n\nserver in:\n: 00200f746c7331332073657276657220696e00\n\nquic key:\n: 00100e746c7331332071756963206b657900\n\nquic iv:\n: 000c0d746c733133207175696320697600\n\nquic hp:\n: 00100d746c733133207175696320687000\n\nThe initial secret is common:\n\n~~~\ninitial_secret = HKDF-Extract(initial_salt, cid)\n    = 7db5df06e7a69e432496adedb0085192\n      3595221596ae2ae9fb8115c1e9ed0a44\n~~~\n\nThe secrets for protecting client packets are:\n\n~~~\nclient_initial_secret\n    = HKDF-Expand-Label(initial_secret, \"client in\", \"\", 32)\n    = c00cf151ca5be075ed0ebfb5c80323c4\n      2d6b7db67881289af4008f1f6c357aea\n\nkey = HKDF-Expand-Label(client_initial_secret, \"quic key\", \"\", 16)\n    = 1f369613dd76d5467730efcbe3b1a22d\n\niv  = HKDF-Expand-Label(client_initial_secret, \"quic iv\", \"\", 12)\n    = fa044b2f42a3fd3b46fb255c\n\nhp  = HKDF-Expand-Label(client_initial_secret, \"quic hp\", \"\", 16)\n    = 9f50449e04a0e810283a1e9933adedd2\n~~~\n\nThe secrets for protecting server packets are:\n\n~~~\nserver_initial_secret\n    = HKDF-Expand-Label(initial_secret, \"server in\", \"\", 32)\n    = 3c199828fd139efd216c155ad844cc81\n      fb82fa8d7446fa7d78be803acdda951b\n\nkey = HKDF-Expand-Label(server_initial_secret, \"quic key\", \"\", 16)\n    = cf3a5331653c364c88f0f379b6067e37\n\niv  = HKDF-Expand-Label(server_initial_secret, \"quic iv\", \"\", 12)\n    = 0ac1493ca1905853b0bba03e\n\nhp  = HKDF-Expand-Label(server_initial_secret, \"quic hp\", \"\", 16)\n    = c206b8d9b9f0f37644430b490eeaa314\n~~~\n\n\n## Client Initial {#sample-client-initial}\n\nThe client sends an Initial packet.  The unprotected payload of this packet\ncontains the following CRYPTO frame, plus enough PADDING frames to make a\n1162-byte payload:\n\n~~~\n060040f1010000ed0303ebf8fa56f129 39b9584a3896472ec40bb863cfd3e868\n04fe3a47f06a2b69484c000004130113 02010000c000000010000e00000b6578\n616d706c652e636f6dff01000100000a 00080006001d00170018001000070005\n04616c706e0005000501000000000033 00260024001d00209370b2c9caa47fba\nbaf4559fedba753de171fa71f50f1ce1 5d43e994ec74d748002b000302030400\n0d0010000e0403050306030203080408 050806002d00020101001c0002400100\n3900320408ffffffffffffffff050480 00ffff07048000ffff08011001048000\n75300901100f088394c8f03e51570806 048000ffff\n~~~\n\nThe unprotected header indicates a length of 1182 bytes: the 4-byte packet\nnumber, 1162 bytes of frames, and the 16-byte authentication tag.  The header\nincludes the connection ID and a packet number of 2:\n\n~~~\nc300000001088394c8f03e5157080000449e00000002\n~~~\n\nProtecting the payload produces output that is sampled for header protection.\nBecause the header uses a 4-byte packet number encoding, the first 16 bytes of\nthe protected payload is sampled and then applied to the header as follows:\n\n~~~\nsample = d1b1c98dd7689fb8ec11d242b123dc9b\n\nmask = AES-ECB(hp, sample)[0..4]\n     = 437b9aec36\n\nheader[0] ^= mask[0] & 0x0f\n     = c0\nheader[18..21] ^= mask[1..4]\n     = 7b9aec34\nheader = c000000001088394c8f03e5157080000449e7b9aec34\n~~~\n\nThe resulting protected packet is:\n\n~~~\nc000000001088394c8f03e5157080000 449e7b9aec34d1b1c98dd7689fb8ec11\nd242b123dc9bd8bab936b47d92ec356c 0bab7df5976d27cd449f63300099f399\n1c260ec4c60d17b31f8429157bb35a12 82a643a8d2262cad67500cadb8e7378c\n8eb7539ec4d4905fed1bee1fc8aafba1 7c750e2c7ace01e6005f80fcb7df6212\n30c83711b39343fa028cea7f7fb5ff89 eac2308249a02252155e2347b63d58c5\n457afd84d05dfffdb20392844ae81215 4682e9cf012f9021a6f0be17ddd0c208\n4dce25ff9b06cde535d0f920a2db1bf3 62c23e596d11a4f5a6cf3948838a3aec\n4e15daf8500a6ef69ec4e3feb6b1d98e 610ac8b7ec3faf6ad760b7bad1db4ba3\n485e8a94dc250ae3fdb41ed15fb6a8e5 eba0fc3dd60bc8e30c5c4287e53805db\n059ae0648db2f64264ed5e39be2e20d8 2df566da8dd5998ccabdae053060ae6c\n7b4378e846d29f37ed7b4ea9ec5d82e7 961b7f25a9323851f681d582363aa5f8\n9937f5a67258bf63ad6f1a0b1d96dbd4 faddfcefc5266ba6611722395c906556\nbe52afe3f565636ad1b17d508b73d874 3eeb524be22b3dcbc2c7468d54119c74\n68449a13d8e3b95811a198f3491de3e7 fe942b330407abf82a4ed7c1b311663a\nc69890f4157015853d91e923037c227a 33cdd5ec281ca3f79c44546b9d90ca00\nf064c99e3dd97911d39fe9c5d0b23a22 9a234cb36186c4819e8b9c5927726632\n291d6a418211cc2962e20fe47feb3edf 330f2c603a9d48c0fcb5699dbfe58964\n25c5bac4aee82e57a85aaf4e2513e4f0 5796b07ba2ee47d80506f8d2c25e50fd\n14de71e6c418559302f939b0e1abd576 f279c4b2e0feb85c1f28ff18f58891ff\nef132eef2fa09346aee33c28eb130ff2 8f5b766953334113211996d20011a198\ne3fc433f9f2541010ae17c1bf202580f 6047472fb36857fe843b19f5984009dd\nc324044e847a4f4a0ab34f719595de37 252d6235365e9b84392b061085349d73\n203a4a13e96f5432ec0fd4a1ee65accd d5e3904df54c1da510b0ff20dcc0c77f\ncb2c0e0eb605cb0504db87632cf3d8b4 dae6e705769d1de354270123cb11450e\nfc60ac47683d7b8d0f811365565fd98c 4c8eb936bcab8d069fc33bd801b03ade\na2e1fbc5aa463d08ca19896d2bf59a07 1b851e6c239052172f296bfb5e724047\n90a2181014f3b94a4e97d117b4381303 68cc39dbb2d198065ae3986547926cd2\n162f40a29f0c3c8745c0f50fba3852e5 66d44575c29d39a03f0cda721984b6f4\n40591f355e12d439ff150aab7613499d bd49adabc8676eef023b15b65bfc5ca0\n6948109f23f350db82123535eb8a7433 bdabcb909271a6ecbcb58b936a88cd4e\n8f2e6ff5800175f113253d8fa9ca8885 c2f552e657dc603f252e1a8e308f76f0\nbe79e2fb8f5d5fbbe2e30ecadd220723 c8c0aea8078cdfcb3868263ff8f09400\n54da48781893a7e49ad5aff4af300cd8 04a6b6279ab3ff3afb64491c85194aab\n760d58a606654f9f4400e8b38591356f bf6425aca26dc85244259ff2b19c41b9\nf96f3ca9ec1dde434da7d2d392b905dd f3d1f9af93d1af5950bd493f5aa731b4\n056df31bd267b6b90a079831aaf579be 0a39013137aac6d404f518cfd4684064\n7e78bfe706ca4cf5e9c5453e9f7cfd2b 8b4c8d169a44e55c88d4a9a7f9474241\ne221af44860018ab0856972e194cd934\n~~~\n\n\n## Server Initial\n\nThe server sends the following payload in response, including an ACK frame, a\nCRYPTO frame, and no PADDING frames:\n\n~~~\n02000000000600405a020000560303ee fce7f7b37ba1d1632e96677825ddf739\n88cfc79825df566dc5430b9a045a1200 130100002e00330024001d00209d3c94\n0d89690b84d08a60993c144eca684d10 81287c834d5311bcf32bb9da1a002b00\n020304\n~~~\n\nThe header from the server includes a new connection ID and a 2-byte packet\nnumber encoding for a packet number of 1:\n\n~~~\nc1000000010008f067a5502a4262b50040750001\n~~~\n\nAs a result, after protection, the header protection sample is taken starting\nfrom the third protected byte:\n\n~~~\nsample = 2cd0991cd25b0aac406a5816b6394100\nmask   = 2ec0d8356a\nheader = cf000000010008f067a5502a4262b5004075c0d9\n~~~\n\nThe final protected packet is then:\n\n~~~\ncf000000010008f067a5502a4262b500 4075c0d95a482cd0991cd25b0aac406a\n5816b6394100f37a1c69797554780bb3 8cc5a99f5ede4cf73c3ec2493a1839b3\ndbcba3f6ea46c5b7684df3548e7ddeb9 c3bf9c73cc3f3bded74b562bfb19fb84\n022f8ef4cdd93795d77d06edbb7aaf2f 58891850abbdca3d20398c276456cbc4\n2158407dd074ee\n~~~\n\n\n## Retry\n\nThis shows a Retry packet that might be sent in response to the Initial packet\nin {{sample-client-initial}}. The integrity check includes the client-chosen\nconnection ID value of 0x8394c8f03e515708, but that value is not\nincluded in the final Retry packet:\n\n~~~\nff000000010008f067a5502a4262b574 6f6b656e04a265ba2eff4d829058fb3f\n0f2496ba\n~~~\n\n\n## ChaCha20-Poly1305 Short Header Packet\n\nThis example shows some of the steps required to protect a packet with\na short header.  This example uses AEAD_CHACHA20_POLY1305.\n\nIn this example, TLS produces an application write secret from which a server\nuses HKDF-Expand-Label to produce four values: a key, an IV, a header\nprotection key, and the secret that will be used after keys are updated (this\nlast value is not used further in this example).\n\n~~~\nsecret\n    = 9ac312a7f877468ebe69422748ad00a1\n      5443f18203a07d6060f688f30f21632b\n\nkey = HKDF-Expand-Label(secret, \"quic key\", \"\", 32)\n    = c6d98ff3441c3fe1b2182094f69caa2e\n      d4b716b65488960a7a984979fb23e1c8\n\niv  = HKDF-Expand-Label(secret, \"quic iv\", \"\", 12)\n    = e0459b3474bdd0e44a41c144\n\nhp  = HKDF-Expand-Label(secret, \"quic hp\", \"\", 32)\n    = 25a282b9e82f06f21f488917a4fc8f1b\n      73573685608597d0efcb076b0ab7a7a4\n\nku  = HKDF-Expand-Label(secret, \"quic ku\", \"\", 32)\n    = 1223504755036d556342ee9361d25342\n      1a826c9ecdf3c7148684b36b714881f9\n~~~\n\nThe following shows the steps involved in protecting a minimal packet with an\nempty Destination Connection ID. This packet contains a single PING frame (that\nis, a payload of just 0x01) and has a packet number of 654360564. In this\nexample, using a packet number of length 3 (that is, 49140 is encoded) avoids\nhaving to pad the payload of the packet; PADDING frames would be needed if the\npacket number is encoded on fewer bytes.\n\n~~~\npn                 = 654360564 (decimal)\nnonce              = e0459b3474bdd0e46d417eb0\nunprotected header = 4200bff4\npayload plaintext  = 01\npayload ciphertext = 655e5cd55c41f69080575d7999c25a5bfb\n~~~\n\nThe resulting ciphertext is the minimum size possible. One byte is skipped to\nproduce the sample for header protection.\n\n~~~\nsample = 5e5cd55c41f69080575d7999c25a5bfb\nmask   = aefefe7d03\nheader = 4cfe4189\n~~~\n\nThe protected packet is the smallest possible packet size of 21 bytes.\n\n~~~\npacket = 4cfe4189655e5cd55c41f69080575d7999c25a5bfb\n~~~\n\n\n# AEAD Algorithm Analysis {#aead-analysis}\n\nThis section documents analyses used in deriving AEAD algorithm limits for\nAEAD_AES_128_GCM, AEAD_AES_128_CCM, and AEAD_AES_256_GCM. The analyses that\nfollow use symbols for multiplication (*), division (/), and exponentiation (^),\nplus parentheses for establishing precedence. The following symbols are also\nused:\n\nt:\n\n: The size of the authentication tag in bits. For these ciphers, t is 128.\n\nn:\n\n: The size of the block function in bits. For these ciphers, n is 128.\n\nk:\n\n: The size of the key in bits. This is 128 for AEAD_AES_128_GCM and\n  AEAD_AES_128_CCM; 256 for AEAD_AES_256_GCM.\n\nl:\n\n: The number of blocks in each packet (see below).\n\nq:\n\n: The number of genuine packets created and protected by endpoints. This value\n  is the bound on the number of packets that can be protected before updating\n  keys.\n\nv:\n\n: The number of forged packets that endpoints will accept. This value is the\n  bound on the number of forged packets that an endpoint can reject before\n  updating keys.\n\no:\n\n: The amount of offline ideal cipher queries made by an adversary.\n\nThe analyses that follow rely on a count of the number of block operations\ninvolved in producing each message. This analysis is performed for packets of\nsize up to 2<sup>11</sup> (l = 2<sup>7</sup>) and 2<sup>16</sup> (l =\n2<sup>12</sup>). A size of 2<sup>11</sup> is expected to be a limit that matches\ncommon deployment patterns, whereas the 2<sup>16</sup> is the maximum possible\nsize of a QUIC packet. Only endpoints that strictly limit packet size can use\nthe larger confidentiality and integrity limits that are derived using the\nsmaller packet size.\n\nFor AEAD_AES_128_GCM and AEAD_AES_256_GCM, the message length (l) is the length\nof the associated data in blocks plus the length of the plaintext in blocks.\n\nFor AEAD_AES_128_CCM, the total number of block cipher operations is the sum of\nthe following: the length of the associated data in blocks, the length of the\nciphertext in blocks, the length of the plaintext in blocks, plus 1. In this\nanalysis, this is simplified to a value of twice the length of the packet in\nblocks (that is, <tt>2l = 2<sup>8</sup></tt> for packets that are limited to\n2<sup>11</sup> bytes, or <tt>2l = 2<sup>13</sup></tt> otherwise). This\nsimplification is based on the packet containing all of the associated data and\nciphertext. This results in a one to three block overestimation of the number of\noperations per packet.\n\n\n## Analysis of AEAD_AES_128_GCM and AEAD_AES_256_GCM Usage Limits {#gcm-bounds}\n\n{{GCM-MU}} specifies concrete bounds for AEAD_AES_128_GCM and AEAD_AES_256_GCM\nas used in TLS 1.3 and QUIC. This section documents this analysis using several\nsimplifying assumptions:\n\n- The number of ciphertext blocks an attacker uses in forgery attempts is\n  bounded by v * l, which is the number of forgery attempts multiplied by the\n  size of each packet (in blocks).\n\n- The amount of offline work done by an attacker does not dominate other factors\n  in the analysis.\n\nThe bounds in {{GCM-MU}} are tighter and more complete than those used in\n{{AEBounds}}, which allows for larger limits than those described in\n{{?TLS13}}.\n\n\n### Confidentiality Limit\n\nFor confidentiality, Theorem (4.3) in {{GCM-MU}} establishes that, for a single\nuser that does not repeat nonces, the dominant term in determining the\ndistinguishing advantage between a real and random AEAD algorithm gained by an\nattacker is:\n\n~~~\n2 * (q * l)^2 / 2^n\n~~~\n\nFor a target advantage of 2<sup>-57</sup>, this results in the relation:\n\n~~~\nq <= 2^35 / l\n~~~\n\nThus, endpoints that do not send packets larger than 2<sup>11</sup> bytes cannot\nprotect more than 2<sup>28</sup> packets in a single connection without causing\nan attacker to gain a more significant advantage than the target of\n2<sup>-57</sup>. The limit for endpoints that allow for the packet size to be as\nlarge as 2<sup>16</sup> is instead 2<sup>23</sup>.\n\n\n### Integrity Limit\n\nFor integrity, Theorem (4.3) in {{GCM-MU}} establishes that an attacker gains\nan advantage in successfully forging a packet of no more than the following:\n\n~~~\n(1 / 2^(8 * n)) + ((2 * v) / 2^(2 * n))\n        + ((2 * o * v) / 2^(k + n)) + (n * (v + (v * l)) / 2^k)\n~~~\n\nThe goal is to limit this advantage to 2<sup>-57</sup>.  For AEAD_AES_128_GCM,\nthe fourth term in this inequality dominates the rest, so the others can be\nremoved without significant effect on the result. This produces the following\napproximation:\n\n~~~\nv <= 2^64 / l\n~~~\n\nEndpoints that do not attempt to remove protection from packets larger than\n2<sup>11</sup> bytes can attempt to remove protection from at most\n2<sup>57</sup> packets. Endpoints that do not restrict the size of processed\npackets can attempt to remove protection from at most 2<sup>52</sup> packets.\n\nFor AEAD_AES_256_GCM, the same term dominates, but the larger value of k\nproduces the following approximation:\n\n~~~\nv <= 2^192 / l\n~~~\n\nThis is substantially larger than the limit for AEAD_AES_128_GCM.  However, this\ndocument recommends that the same limit be applied to both functions as either\nlimit is acceptably large.\n\n\n## Analysis of AEAD_AES_128_CCM Usage Limits {#ccm-bounds}\n\nTLS {{?TLS13}} and {{AEBounds}} do not specify limits on usage\nfor AEAD_AES_128_CCM. However, any AEAD that is used with QUIC requires limits\non use that ensure that both confidentiality and integrity are preserved. This\nsection documents that analysis.\n\n{{CCM-ANALYSIS}} is used as the basis of this\nanalysis. The results of that analysis are used to derive usage limits that are\nbased on those chosen in {{?TLS13}}.\n\nFor confidentiality, Theorem 2 in {{CCM-ANALYSIS}} establishes that an attacker\ngains a distinguishing advantage over an ideal pseudorandom permutation (PRP) of\nno more than the following:\n\n~~~\n(2l * q)^2 / 2^n\n~~~\n\nThe integrity limit in Theorem 1 in {{CCM-ANALYSIS}} provides an attacker a\nstrictly higher advantage for the same number of messages. As the targets for\nthe confidentiality advantage and the integrity advantage are the same, only\nTheorem 1 needs to be considered.\n\nTheorem 1 establishes that an attacker gains an advantage over an\nideal PRP of no more than the following:\n\n~~~\nv / 2^t + (2l * (v + q))^2 / 2^n\n~~~\n\nAs `t` and `n` are both 128, the first term is negligible relative to the\nsecond, so that term can be removed without a significant effect on the result.\n\nThis produces a relation that combines both encryption and decryption attempts\nwith the same limit as that produced by the theorem for confidentiality alone.\nFor a target advantage of 2<sup>-57</sup>, this results in the following:\n\n~~~\nv + q <= 2^34.5 / l\n~~~\n\nBy setting `q = v`, values for both confidentiality and integrity limits can be\nproduced. Endpoints that limit packets to 2<sup>11</sup> bytes therefore have\nboth confidentiality and integrity limits of 2<sup>26.5</sup> packets. Endpoints\nthat do not restrict packet size have a limit of 2<sup>21.5</sup>.\n\n\n# Contributors\n{:numbered=\"false\"}\n\nThe IETF QUIC Working Group received an enormous amount of support from many\npeople. The following people provided substantive contributions to this\ndocument:\n\n<ul spacing=\"compact\">\n<li><t><contact fullname=\"Adam Langley\"/></t></li>\n<li><t><contact fullname=\"Alessandro Ghedini\"/></t></li>\n<li><t><contact fullname=\"Christian Huitema\"/></t></li>\n<li><t><contact fullname=\"Christopher Wood\"/></t></li>\n<li><t><contact fullname=\"David Schinazi\"/></t></li>\n<li><t><contact fullname=\"Dragana Damjanovic\"/></t></li>\n<li><t><contact fullname=\"Eric Rescorla\"/></t></li>\n<li><t><contact fullname=\"Felix Günther\"/></t></li>\n<li><t><contact fullname=\"Ian Swett\"/></t></li>\n<li><t><contact fullname=\"Jana Iyengar\"/></t></li>\n<li><t><contact asciiFullname=\"Kazuho Oku\" fullname=\"奥 一穂\"/></t></li>\n<li><t><contact fullname=\"Marten Seemann\"/></t></li>\n<li><t><contact fullname=\"Martin Duke\"/></t></li>\n<li><t><contact fullname=\"Mike Bishop\"/></t></li>\n<li><t><contact fullname=\"Mikkel Fahnøe Jørgensen\"/></t></li>\n<li><t><contact fullname=\"Nick Banks\"/></t></li>\n<li><t><contact fullname=\"Nick Harper\"/></t></li>\n<li><t><contact fullname=\"Roberto Peon\"/></t></li>\n<li><t><contact fullname=\"Rui Paulo\"/></t></li>\n<li><t><contact fullname=\"Ryan Hamilton\"/></t></li>\n<li><t><contact fullname=\"Victor Vasiliev\"/></t></li>\n</ul>\n"
        },
        {
          "name": "rfc9002.md",
          "type": "blob",
          "size": 75.56640625,
          "content": "---\ntitle: QUIC Loss Detection and Congestion Control\nabbrev: QUIC Loss Detection\nnumber: 9002\ndocName: draft-ietf-quic-recovery-34\ndate: 2021-05\ncategory: std\nconsensus: true\nipr: trust200902\narea: Transport\nworkgroup: QUIC\nkeyword:\n  - bbr\n  - delay-sensitive congestion control\n  - fec\n  - loss-tolerant congestion control\n  - next generation\n\nstand_alone: yes\npi: [toc, sortrefs, symrefs, docmapping]\n\nauthor:\n -\n    ins: J. Iyengar\n    name: Jana Iyengar\n    org: Fastly\n    email: jri.ietf@gmail.com\n    role: editor\n -\n    ins: I. Swett\n    name: Ian Swett\n    org: Google\n    email: ianswett@google.com\n    role: editor\n\nnormative:\n\n  QUIC-TRANSPORT:\n    title: \"QUIC: A UDP-Based Multiplexed and Secure Transport\"\n    date: 2021-05\n    seriesinfo:\n      RFC: 9000\n      DOI: 10.17487/RFC9000\n    author:\n      -\n        ins: J. Iyengar\n        name: Jana Iyengar\n        org: Fastly\n        role: editor\n      -\n        ins: M. Thomson\n        name: Martin Thomson\n        org: Mozilla\n        role: editor\n\n  QUIC-TLS:\n    title: \"Using TLS to Secure QUIC\"\n    date: 2021-05\n    seriesinfo:\n      RFC: 9001\n      DOI: 10.17487/RFC9001\n    author:\n      -\n        ins: M. Thomson\n        name: Martin Thomson\n        org: Mozilla\n        role: editor\n      -\n        ins: S. Turner\n        name: Sean Turner\n        org: sn3rd\n        role: editor\n\n  RFC8085:\n\ninformative:\n\n  FACK:\n    title: \"Forward acknowledgement: Refining TCP Congestion Control\"\n    author:\n      -\n        initials: M.\n        surname: Mathis\n      -\n        initials: J.\n        surname: Mahdavi\n    date: 1996-08\n    refcontent: ACM SIGCOMM Computer Communication Review\n    seriesinfo:\n      DOI: 10.1145/248157.248181\n\n  RETRANSMISSION:\n    title: \"Improving Round-Trip Time Estimates in Reliable Transport Protocols\"\n    author:\n      -\n        initials: P.\n        surname: Karn\n      -\n        initials: C.\n        surname: Partridge\n    date: 1991-11\n    refcontent: ACM Transactions on Computer Systems\n    seriesinfo:\n       DOI: 10.1145/118544.118549\n\n  RFC3465:\n\n--- abstract\n\nThis document describes loss detection and congestion control mechanisms for\nQUIC.\n\n\n--- middle\n\n# Introduction\n\n\nQUIC is a secure, general-purpose transport protocol, described in\n{{QUIC-TRANSPORT}}. This document describes loss detection and congestion\ncontrol mechanisms for QUIC.\n\n# Conventions and Definitions\n\nThe key words \"MUST\", \"MUST NOT\", \"REQUIRED\", \"SHALL\", \"SHALL NOT\", \"SHOULD\",\n\"SHOULD NOT\", \"RECOMMENDED\", \"NOT RECOMMENDED\", \"MAY\", and \"OPTIONAL\" in this\ndocument are to be interpreted as described in BCP 14 {{!RFC2119}} {{!RFC8174}}\nwhen, and only when, they appear in all capitals, as shown here.\n\nDefinitions of terms that are used in this document:\n\nAck-eliciting frames:\n\n: All frames other than ACK, PADDING, and CONNECTION_CLOSE are considered\n  ack-eliciting.\n\nAck-eliciting packets:\n\n: Packets that contain ack-eliciting frames elicit an ACK from the receiver\n  within the maximum acknowledgment delay and are called ack-eliciting packets.\n\nIn-flight packets:\n\n: Packets are considered in flight when they are ack-eliciting or contain a\n  PADDING frame, and they have been sent but are not acknowledged, declared\n  lost, or discarded along with old keys.\n\n# Design of the QUIC Transmission Machinery\n\nAll transmissions in QUIC are sent with a packet-level header, which indicates\nthe encryption level and includes a packet sequence number (referred to below as\na packet number).  The encryption level indicates the packet number space, as\ndescribed in {{Section 12.3 of QUIC-TRANSPORT}}.  Packet numbers never repeat\nwithin a packet number space for the lifetime of a connection.  Packet numbers\nare sent in monotonically increasing order within a space, preventing ambiguity.\nIt is permitted for some packet numbers to never be used, leaving intentional\ngaps.\n\nThis design obviates the need for disambiguating between transmissions and\nretransmissions; this eliminates significant complexity from QUIC's\ninterpretation of TCP loss detection mechanisms.\n\nQUIC packets can contain multiple frames of different types. The recovery\nmechanisms ensure that data and frames that need reliable delivery are\nacknowledged or declared lost and sent in new packets as necessary. The types\nof frames contained in a packet affect recovery and congestion control logic:\n\n* All packets are acknowledged, though packets that contain no\n  ack-eliciting frames are only acknowledged along with ack-eliciting\n  packets.\n\n* Long header packets that contain CRYPTO frames are critical to the\n  performance of the QUIC handshake and use shorter timers for\n  acknowledgment.\n\n* Packets containing frames besides ACK or CONNECTION_CLOSE frames count toward\n  congestion control limits and are considered to be in flight.\n\n* PADDING frames cause packets to contribute toward bytes in flight without\n  directly causing an acknowledgment to be sent.\n\n# Relevant Differences Between QUIC and TCP\n\nReaders familiar with TCP's loss detection and congestion control will find\nalgorithms here that parallel well-known TCP ones. However, protocol differences\nbetween QUIC and TCP contribute to algorithmic differences. These protocol\ndifferences are briefly described below.\n\n## Separate Packet Number Spaces\n\nQUIC uses separate packet number spaces for each encryption level,\nexcept 0-RTT and all generations of 1-RTT keys use the same packet\nnumber space.  Separate packet number spaces ensures that the\nacknowledgment of packets sent with one level of encryption will not\ncause spurious retransmission of packets sent with a different\nencryption level.  Congestion control and round-trip time (RTT)\nmeasurement are unified across packet number spaces.\n\n## Monotonically Increasing Packet Numbers\n\nTCP conflates transmission order at the sender with delivery order at the\nreceiver, resulting in the retransmission ambiguity problem\n{{RETRANSMISSION}}.  QUIC separates transmission order from delivery order:\npacket numbers indicate transmission order, and delivery order is determined by\nthe stream offsets in STREAM frames.\n\nQUIC's packet number is strictly increasing within a packet number space\nand directly encodes transmission order.  A higher packet number signifies\nthat the packet was sent later, and a lower packet number signifies that\nthe packet was sent earlier.  When a packet containing ack-eliciting\nframes is detected lost, QUIC includes necessary frames in a new packet\nwith a new packet number, removing ambiguity about which packet is\nacknowledged when an ACK is received.  Consequently, more accurate RTT\nmeasurements can be made, spurious retransmissions are trivially detected, and\nmechanisms such as Fast Retransmit can be applied universally, based only on\npacket number.\n\nThis design point significantly simplifies loss detection mechanisms for QUIC.\nMost TCP mechanisms implicitly attempt to infer transmission ordering based on\nTCP sequence numbers -- a nontrivial task, especially when TCP timestamps are\nnot available.\n\n## Clearer Loss Epoch\n\nQUIC starts a loss epoch when a packet is lost. The loss epoch ends when any\npacket sent after the start of the epoch is acknowledged.  TCP waits for the gap\nin the sequence number space to be filled, and so if a segment is lost multiple\ntimes in a row, the loss epoch may not end for several round trips. Because both\nshould reduce their congestion windows only once per epoch, QUIC will do it once\nfor every round trip that experiences loss, while TCP may only do it once across\nmultiple round trips.\n\n## No Reneging\n\nQUIC ACK frames contain information similar to that in TCP Selective\nAcknowledgments (SACKs) {{?RFC2018}}. However, QUIC does not allow a packet\nacknowledgment to be reneged, greatly simplifying implementations on both sides\nand reducing memory pressure on the sender.\n\n## More ACK Ranges\n\nQUIC supports many ACK ranges, as opposed to TCP's three SACK ranges.  In\nhigh-loss environments, this speeds recovery, reduces spurious retransmits, and\nensures forward progress without relying on timeouts.\n\n## Explicit Correction For Delayed Acknowledgments\n\nQUIC endpoints measure the delay incurred between when a packet is received and\nwhen the corresponding acknowledgment is sent, allowing a peer to maintain a\nmore accurate RTT estimate; see {{Section 13.2 of QUIC-TRANSPORT}}.\n\n## Probe Timeout Replaces RTO and TLP\n\nQUIC uses a probe timeout (PTO; see {{pto}}), with a timer based on TCP's\nretransmission timeout (RTO) computation; see {{?RFC6298}}.  QUIC's PTO includes\nthe peer's maximum expected acknowledgment delay instead of using a fixed\nminimum timeout.\n\nSimilar to the RACK-TLP loss detection algorithm for TCP {{?RFC8985}}, QUIC does\nnot collapse the congestion window when the PTO expires, since a single packet\nloss at the tail does not indicate persistent congestion.  Instead, QUIC\ncollapses the congestion window when persistent congestion is declared; see\n{{persistent-congestion}}. In doing this, QUIC avoids unnecessary congestion\nwindow reductions, obviating the need for correcting mechanisms such as Forward\nRTO-Recovery (F-RTO) {{?RFC5682}}. Since QUIC does not collapse the congestion\nwindow on a PTO expiration, a QUIC sender is not limited from sending more\nin-flight packets after a PTO expiration if it still has available congestion\nwindow. This occurs when a sender is application limited and the PTO timer\nexpires. This is more aggressive than TCP's RTO mechanism when application\nlimited, but identical when not application limited.\n\nQUIC allows probe packets to temporarily exceed the congestion window whenever\nthe timer expires.\n\n## The Minimum Congestion Window Is Two Packets\n\nTCP uses a minimum congestion window of one packet. However, loss of that single\npacket means that the sender needs to wait for a PTO to recover ({{pto}}), which\ncan be much longer than an RTT.  Sending a single ack-eliciting packet also\nincreases the chances of incurring additional latency when a receiver delays its\nacknowledgment.\n\nQUIC therefore recommends that the minimum congestion window be two\npackets. While this increases network load, it is considered safe since the\nsender will still reduce its sending rate exponentially under persistent\ncongestion ({{pto}}).\n\n## Handshake Packets Are Not Special\n\nTCP treats the loss of SYN or SYN-ACK packet as persistent congestion and\nreduces the congestion window to one packet; see {{?RFC5681}}. QUIC treats loss\nof a packet containing handshake data the same as other losses.\n\n# Estimating the Round-Trip Time {#compute-rtt}\n\nAt a high level, an endpoint measures the time from when a packet was sent to\nwhen it is acknowledged as an RTT sample. The endpoint uses RTT samples and\npeer-reported host delays (see {{Section 13.2 of QUIC-TRANSPORT}}) to generate a\nstatistical description of the network path's RTT. An endpoint computes the\nfollowing three values for each path: the minimum value over a period of time\n(min_rtt), an exponentially weighted moving average (smoothed_rtt), and the mean\ndeviation (referred to as \"variation\" in the rest of this document) in the\nobserved RTT samples (rttvar).\n\n## Generating RTT Samples {#latest-rtt}\n\nAn endpoint generates an RTT sample on receiving an ACK frame that meets the\nfollowing two conditions:\n\n- the largest acknowledged packet number is newly acknowledged, and\n\n- at least one of the newly acknowledged packets was ack-eliciting.\n\nThe RTT sample, latest_rtt, is generated as the time elapsed since the largest\nacknowledged packet was sent:\n\n~~~pseudocode\nlatest_rtt = ack_time - send_time_of_largest_acked\n~~~\n\nAn RTT sample is generated using only the largest acknowledged packet in the\nreceived ACK frame.  This is because a peer reports acknowledgment delays for\nonly the largest acknowledged packet in an ACK frame.  While the reported\nacknowledgment delay is not used by the RTT sample measurement, it is used to\nadjust the RTT sample in subsequent computations of smoothed_rtt and rttvar\n({{smoothed-rtt}}).\n\nTo avoid generating multiple RTT samples for a single packet, an ACK frame\nSHOULD NOT be used to update RTT estimates if it does not newly acknowledge the\nlargest acknowledged packet.\n\nAn RTT sample MUST NOT be generated on receiving an ACK frame that does not\nnewly acknowledge at least one ack-eliciting packet. A peer usually does not\nsend an ACK frame when only non-ack-eliciting packets are received. Therefore,\nan ACK frame that contains acknowledgments for only non-ack-eliciting packets\ncould include an arbitrarily large ACK Delay value.  Ignoring\nsuch ACK frames avoids complications in subsequent smoothed_rtt and rttvar\ncomputations.\n\nA sender might generate multiple RTT samples per RTT when multiple ACK frames\nare received within an RTT.  As suggested in {{?RFC6298}}, doing so might result\nin inadequate history in smoothed_rtt and rttvar.  Ensuring that RTT estimates\nretain sufficient history is an open research question.\n\n## Estimating min_rtt {#min-rtt}\n\nmin_rtt is the sender's estimate of the minimum RTT observed for a given network\npath over a period of time. In this document, min_rtt is used by loss detection\nto reject implausibly small RTT samples.\n\nmin_rtt MUST be set to the latest_rtt on the first RTT sample. min_rtt MUST be\nset to the lesser of min_rtt and latest_rtt ({{latest-rtt}}) on all other\nsamples.\n\nAn endpoint uses only locally observed times in computing the min_rtt and does\nnot adjust for acknowledgment delays reported by the peer. Doing so allows the\nendpoint to set a lower bound for the smoothed_rtt based entirely on what it\nobserves (see {{smoothed-rtt}}) and limits potential underestimation due to\nerroneously reported delays by the peer.\n\nThe RTT for a network path may change over time. If a path's actual RTT\ndecreases, the min_rtt will adapt immediately on the first low sample.  If the\npath's actual RTT increases, however, the min_rtt will not adapt to it, allowing\nfuture RTT samples that are smaller than the new RTT to be included in\nsmoothed_rtt.\n\nEndpoints SHOULD set the min_rtt to the newest RTT sample after persistent\ncongestion is established. This avoids repeatedly declaring persistent\ncongestion when the RTT increases. This also allows a connection to reset\nits estimate of min_rtt and smoothed_rtt after a disruptive network event;\nsee {{smoothed-rtt}}.\n\nEndpoints MAY reestablish the min_rtt at other times in the connection, such as\nwhen traffic volume is low and an acknowledgment is received with a low\nacknowledgment delay. Implementations SHOULD NOT refresh the min_rtt\nvalue too often since the actual minimum RTT of the path is not\nfrequently observable.\n\n\n## Estimating smoothed_rtt and rttvar {#smoothed-rtt}\n\nsmoothed_rtt is an exponentially weighted moving average of an endpoint's RTT\nsamples, and rttvar estimates the variation in the RTT samples using a mean\nvariation.\n\nThe calculation of smoothed_rtt uses RTT samples after adjusting them for\nacknowledgment delays. These delays are decoded from the ACK Delay field of\nACK frames as described in {{Section 19.3 of QUIC-TRANSPORT}}.\n\nThe peer might report acknowledgment delays that are larger than the peer's\nmax_ack_delay during the handshake ({{Section 13.2.1 of QUIC-TRANSPORT}}). To\naccount for this, the endpoint SHOULD ignore max_ack_delay until the handshake\nis confirmed, as defined in {{Section 4.1.2 of QUIC-TLS}}. When they occur,\nthese large acknowledgment delays are likely to be non-repeating and limited to\nthe handshake. The endpoint can therefore use them without limiting them to the\nmax_ack_delay, avoiding unnecessary inflation of the RTT estimate.\n\nNote that a large acknowledgment delay can result in a substantially inflated\nsmoothed_rtt if there is an error either in the peer's reporting of the\nacknowledgment delay or in the endpoint's min_rtt estimate.  Therefore, prior\nto handshake confirmation, an endpoint MAY ignore RTT samples if adjusting\nthe RTT sample for acknowledgment delay causes the sample to be less than the\nmin_rtt.\n\nAfter the handshake is confirmed, any acknowledgment delays reported by the\npeer that are greater than the peer's max_ack_delay are attributed to\nunintentional but potentially repeating delays, such as scheduler latency at the\npeer or loss of previous acknowledgments.  Excess delays could also be due to\na noncompliant receiver.  Therefore, these extra delays are considered\neffectively part of path delay and incorporated into the RTT estimate.\n\nTherefore, when adjusting an RTT sample using peer-reported acknowledgment\ndelays, an endpoint:\n\n- MAY ignore the acknowledgment delay for Initial packets, since these\n  acknowledgments are not delayed by the peer ({{Section 13.2.1 of\n  QUIC-TRANSPORT}});\n\n- SHOULD ignore the peer's max_ack_delay until the handshake is confirmed;\n\n- MUST use the lesser of the acknowledgment delay and the peer's max_ack_delay\n  after the handshake is confirmed; and\n\n- MUST NOT subtract the acknowledgment delay from the RTT sample if the\n  resulting value is smaller than the min_rtt.  This limits the underestimation\n  of the smoothed_rtt due to a misreporting peer.\n\nAdditionally, an endpoint might postpone the processing of acknowledgments when\nthe corresponding decryption keys are not immediately available. For example, a\nclient might receive an acknowledgment for a 0-RTT packet that it cannot\ndecrypt because 1-RTT packet protection keys are not yet available to it. In\nsuch cases, an endpoint SHOULD subtract such local delays from its RTT sample\nuntil the handshake is confirmed.\n\nSimilar to {{?RFC6298}}, smoothed_rtt and rttvar are computed as follows.\n\nAn endpoint initializes the RTT estimator during connection establishment and\nwhen the estimator is reset during connection migration; see {{Section 9.4 of\nQUIC-TRANSPORT}}. Before any RTT samples are available for a new path or when\nthe estimator is reset, the estimator is initialized using the initial RTT; see\n{{pto-handshake}}.\n\nsmoothed_rtt and rttvar are initialized as follows, where kInitialRtt contains\nthe initial RTT value:\n\n~~~pseudocode\nsmoothed_rtt = kInitialRtt\nrttvar = kInitialRtt / 2\n~~~\n\nRTT samples for the network path are recorded in latest_rtt; see\n{{latest-rtt}}. On the first RTT sample after initialization, the estimator is\nreset using that sample. This ensures that the estimator retains no history of\npast samples.  Packets sent on other paths do not contribute RTT samples to the\ncurrent path, as described in {{Section 9.4 of QUIC-TRANSPORT}}.\n\nOn the first RTT sample after initialization, smoothed_rtt and rttvar are set as\nfollows:\n\n~~~pseudocode\nsmoothed_rtt = latest_rtt\nrttvar = latest_rtt / 2\n~~~\n\nOn subsequent RTT samples, smoothed_rtt and rttvar evolve as follows:\n\n~~~pseudocode\nack_delay = decoded acknowledgment delay from ACK frame\nif (handshake confirmed):\n  ack_delay = min(ack_delay, max_ack_delay)\nadjusted_rtt = latest_rtt\nif (latest_rtt >= min_rtt + ack_delay):\n  adjusted_rtt = latest_rtt - ack_delay\nsmoothed_rtt = 7/8 * smoothed_rtt + 1/8 * adjusted_rtt\nrttvar_sample = abs(smoothed_rtt - adjusted_rtt)\nrttvar = 3/4 * rttvar + 1/4 * rttvar_sample\n~~~\n\n# Loss Detection {#loss-detection}\n\nQUIC senders use acknowledgments to detect lost packets and a PTO to ensure\nacknowledgments are received; see {{pto}}. This section provides a description\nof these algorithms.\n\nIf a packet is lost, the QUIC transport needs to recover from that loss, such\nas by retransmitting the data, sending an updated frame, or discarding the\nframe.  For more information, see {{Section 13.3 of QUIC-TRANSPORT}}.\n\nLoss detection is separate per packet number space, unlike RTT measurement and\ncongestion control, because RTT and congestion control are properties of the\npath, whereas loss detection also relies upon key availability.\n\n## Acknowledgment-Based Detection {#ack-loss-detection}\n\nAcknowledgment-based loss detection implements the spirit of TCP's Fast\nRetransmit {{?RFC5681}}, Early Retransmit {{?RFC5827}}, Forward Acknowledgment\n{{FACK}}, SACK loss recovery {{?RFC6675}}, and RACK-TLP {{?RFC8985}}. This\nsection provides an overview of how these algorithms are implemented in QUIC.\n\nA packet is declared lost if it meets all of the following conditions:\n\n* The packet is unacknowledged, in flight, and was sent prior to an\n  acknowledged packet.\n\n* The packet was sent kPacketThreshold packets before an acknowledged packet\n  ({{packet-threshold}}), or it was sent long enough in the past\n  ({{time-threshold}}).\n\nThe acknowledgment indicates that a packet sent later was delivered, and the\npacket and time thresholds provide some tolerance for packet reordering.\n\nSpuriously declaring packets as lost leads to unnecessary retransmissions and\nmay result in degraded performance due to the actions of the congestion\ncontroller upon detecting loss.  Implementations can detect spurious\nretransmissions and increase the packet or time reordering threshold to\nreduce future spurious retransmissions and loss events. Implementations with\nadaptive time thresholds MAY choose to start with smaller initial reordering\nthresholds to minimize recovery latency.\n\n### Packet Threshold {#packet-threshold}\n\nThe RECOMMENDED initial value for the packet reordering threshold\n(kPacketThreshold) is 3, based on best practices for TCP loss detection\n{{?RFC5681}} {{?RFC6675}}.  In order to remain similar to TCP,\nimplementations SHOULD NOT use a packet threshold less than 3; see {{?RFC5681}}.\n\nSome networks may exhibit higher degrees of packet reordering, causing a sender\nto detect spurious losses. Additionally, packet reordering could be more common\nwith QUIC than TCP because network elements that could observe and reorder TCP\npackets cannot do that for QUIC and also because QUIC packet numbers are\nencrypted.  Algorithms that increase the reordering threshold after spuriously\ndetecting losses, such as RACK {{?RFC8985}}, have proven to be useful in TCP and\nare expected to be at least as useful in QUIC.\n\n### Time Threshold {#time-threshold}\n\nOnce a later packet within the same packet number space has been acknowledged,\nan endpoint SHOULD declare an earlier packet lost if it was sent a threshold\namount of time in the past. To avoid declaring packets as lost too early, this\ntime threshold MUST be set to at least the local timer granularity, as\nindicated by the kGranularity constant.  The time threshold is:\n\n~~~pseudocode\nmax(kTimeThreshold * max(smoothed_rtt, latest_rtt), kGranularity)\n~~~\n\nIf packets sent prior to the largest acknowledged packet cannot yet be declared\nlost, then a timer SHOULD be set for the remaining time.\n\nUsing max(smoothed_rtt, latest_rtt) protects from the two following cases:\n\n* the latest RTT sample is lower than the smoothed RTT, perhaps due to\n  reordering where the acknowledgment encountered a shorter path;\n\n* the latest RTT sample is higher than the smoothed RTT, perhaps due to a\n  sustained increase in the actual RTT, but the smoothed RTT has not yet caught\n  up.\n\nThe RECOMMENDED time threshold (kTimeThreshold), expressed as an RTT multiplier,\nis 9/8. The RECOMMENDED value of the timer granularity (kGranularity) is 1\nmillisecond.\n\n<aside markdown=\"block\">\nNote: TCP's RACK {{?RFC8985}} specifies a slightly larger threshold, equivalent\nto 5/4, for a similar purpose. Experience with QUIC shows that 9/8 works well.\n</aside>\n\nImplementations MAY experiment with absolute thresholds, thresholds from\nprevious connections, adaptive thresholds, or the including of RTT variation.\nSmaller thresholds reduce reordering resilience and increase spurious\nretransmissions, and larger thresholds increase loss detection delay.\n\n\n## Probe Timeout {#pto}\n\nA Probe Timeout (PTO) triggers the sending of one or two probe datagrams when\nack-eliciting packets are not acknowledged within the expected period of\ntime or the server may not have validated the client's address.  A PTO enables\na connection to recover from loss of tail packets or acknowledgments.\n\nAs with loss detection, the PTO is per packet number space. That is, a\nPTO value is computed per packet number space.\n\nA PTO timer expiration event does not indicate packet loss and MUST NOT cause\nprior unacknowledged packets to be marked as lost. When an acknowledgment is\nreceived that newly acknowledges packets, loss detection proceeds as dictated\nby the packet and time threshold mechanisms; see {{ack-loss-detection}}.\n\nThe PTO algorithm used in QUIC implements the reliability functions of Tail Loss\nProbe {{?RFC8985}}, RTO {{?RFC5681}}, and F-RTO algorithms for TCP\n{{?RFC5682}}. The timeout computation is based on TCP's RTO period {{?RFC6298}}.\n\n### Computing PTO\n\nWhen an ack-eliciting packet is transmitted, the sender schedules a timer for\nthe PTO period as follows:\n\n~~~pseudocode\nPTO = smoothed_rtt + max(4*rttvar, kGranularity) + max_ack_delay\n~~~\n\nThe PTO period is the amount of time that a sender ought to wait for an\nacknowledgment of a sent packet.  This time period includes the estimated\nnetwork RTT (smoothed_rtt), the variation in the estimate (4*rttvar),\nand max_ack_delay, to account for the maximum time by which a receiver might\ndelay sending an acknowledgment.\n\nWhen the PTO is armed for Initial or Handshake packet number spaces, the\nmax_ack_delay in the PTO period computation is set to 0, since the peer is\nexpected to not delay these packets intentionally; see {{Section 13.2.1 of\nQUIC-TRANSPORT}}.\n\nThe PTO period MUST be at least kGranularity to avoid the timer expiring\nimmediately.\n\nWhen ack-eliciting packets in multiple packet number spaces are in flight, the\ntimer MUST be set to the earlier value of the Initial and Handshake packet\nnumber spaces.\n\nAn endpoint MUST NOT set its PTO timer for the Application Data packet number\nspace until the handshake is confirmed. Doing so prevents the endpoint from\nretransmitting information in packets when either the peer does not yet have the\nkeys to process them or the endpoint does not yet have the keys to process their\nacknowledgments. For example, this can happen when a client sends 0-RTT packets\nto the server; it does so without knowing whether the server will be able to\ndecrypt them. Similarly, this can happen when a server sends 1-RTT packets\nbefore confirming that the client has verified the server's certificate and can\ntherefore read these 1-RTT packets.\n\nA sender SHOULD restart its PTO timer every time an ack-eliciting packet is\nsent or acknowledged, or when Initial or Handshake keys are discarded\n({{Section 4.9 of QUIC-TLS}}). This ensures the PTO is always set based on the\nlatest estimate of the RTT and for the correct packet across packet\nnumber spaces.\n\nWhen a PTO timer expires, the PTO backoff MUST be increased, resulting in the\nPTO period being set to twice its current value. The PTO backoff factor is reset\nwhen an acknowledgment is received, except in the following case. A server\nmight take longer to respond to packets during the handshake than otherwise.  To\nprotect such a server from repeated client probes, the PTO backoff is not reset\nat a client that is not yet certain that the server has finished validating the\nclient's address. That is, a client does not reset the PTO backoff factor on\nreceiving acknowledgments in Initial packets.\n\nThis exponential reduction in the sender's rate is important because consecutive\nPTOs might be caused by loss of packets or acknowledgments due to severe\ncongestion.  Even when there are ack-eliciting packets in flight in multiple\npacket number spaces, the exponential increase in PTO occurs across all spaces\nto prevent excess load on the network.  For example, a timeout in the Initial\npacket number space doubles the length of the timeout in the Handshake packet\nnumber space.\n\nThe total length of time over which consecutive PTOs expire is limited by the\nidle timeout.\n\nThe PTO timer MUST NOT be set if a timer is set for time threshold\nloss detection; see {{time-threshold}}.  A timer that is set for time\nthreshold loss detection will expire earlier than the PTO timer\nin most cases and is less likely to spuriously retransmit data.\n\n### Handshakes and New Paths {#pto-handshake}\n\nResumed connections over the same network MAY use the previous connection's\nfinal smoothed RTT value as the resumed connection's initial RTT.  When no\nprevious RTT is available, the initial RTT SHOULD be set to 333 milliseconds.\nThis results in handshakes starting with a PTO of 1 second, as recommended for\nTCP's initial RTO; see {{Section 2 of RFC6298}}.\n\nA connection MAY use the delay between sending a PATH_CHALLENGE and receiving a\nPATH_RESPONSE to set the initial RTT (see kInitialRtt in\n{{constants-of-interest}}) for a new path, but the delay SHOULD NOT be\nconsidered an RTT sample.\n\nWhen the Initial keys and Handshake keys are discarded (see\n{{discarding-packets}}), any Initial packets and Handshake packets can\nno longer be acknowledged, so they are removed from bytes in\nflight. When Initial or Handshake keys are discarded, the PTO and loss\ndetection timers MUST be reset, because discarding keys indicates\nforward progress and the loss detection timer might have been set for\na now-discarded packet number space.\n\n#### Before Address Validation\n\nUntil the server has validated the client's address on the path, the amount of\ndata it can send is limited to three times the amount of data received,\nas specified in {{Section 8.1 of QUIC-TRANSPORT}}. If no additional data can be\nsent, the server's PTO timer MUST NOT be armed until datagrams have been\nreceived from the client because packets sent on PTO count against the\nanti-amplification limit.\n\nWhen the server receives a datagram from the client, the amplification limit is\nincreased and the server resets the PTO timer.  If the PTO timer is then set to\na time in the past, it is executed immediately. Doing so avoids sending new\n1-RTT packets prior to packets critical to the completion of the handshake.\nIn particular, this can happen when 0-RTT is accepted but the server fails to\nvalidate the client's address.\n\nSince the server could be blocked until more datagrams are received from the\nclient, it is the client's responsibility to send packets to unblock the server\nuntil it is certain that the server has finished its address validation (see\n{{Section 8 of QUIC-TRANSPORT}}). That is, the client MUST set the PTO timer\nif the client has not received an acknowledgment for any of its Handshake\npackets and the handshake is not confirmed (see {{Section 4.1.2 of QUIC-TLS}}),\neven if there are no packets in flight. When the PTO fires, the client MUST\nsend a Handshake packet if it has Handshake keys, otherwise it MUST send an\nInitial packet in a UDP datagram with a payload of at least 1200 bytes.\n\n### Speeding up Handshake Completion\n\nWhen a server receives an Initial packet containing duplicate CRYPTO data,\nit can assume the client did not receive all of the server's CRYPTO data sent\nin Initial packets, or the client's estimated RTT is too small. When a\nclient receives Handshake or 1-RTT packets prior to obtaining Handshake keys,\nit may assume some or all of the server's Initial packets were lost.\n\nTo speed up handshake completion under these conditions, an endpoint MAY, for a\nlimited number of times per connection, send a packet containing\nunacknowledged CRYPTO data earlier than the PTO expiry, subject to the address\nvalidation limits in {{Section 8.1 of QUIC-TRANSPORT}}. Doing so at most once\nfor each connection is adequate to quickly recover from a single packet loss.\nAn endpoint that always retransmits packets in response to receiving packets\nthat it cannot process risks creating an infinite exchange of packets.\n\nEndpoints can also use coalesced packets (see {{Section 12.2 of\nQUIC-TRANSPORT}}) to ensure that each datagram elicits at least one\nacknowledgment. For example, a client can coalesce an Initial packet containing\nPING and PADDING frames with a 0-RTT data packet, and a server can coalesce an\nInitial packet containing a PING frame with one or more packets in its first\nflight.\n\n### Sending Probe Packets\n\nWhen a PTO timer expires, a sender MUST send at least one ack-eliciting packet\nin the packet number space as a probe.  An endpoint MAY send up to two\nfull-sized datagrams containing ack-eliciting packets to avoid an expensive\nconsecutive PTO expiration due to a single lost datagram or to transmit data\nfrom multiple packet number spaces. All probe packets sent on a PTO MUST be\nack-eliciting.\n\nIn addition to sending data in the packet number space for which the timer\nexpired, the sender SHOULD send ack-eliciting packets from other packet number\nspaces with in-flight data, coalescing packets if possible.  This is\nparticularly valuable when the server has both Initial and Handshake data in\nflight or when the client has both Handshake and Application Data in flight\nbecause the peer might only have receive keys for one of the two packet number\nspaces.\n\nIf the sender wants to elicit a faster acknowledgment on PTO, it can skip a\npacket number to eliminate the acknowledgment delay.\n\nAn endpoint SHOULD include new data in packets that are sent on PTO expiration.\nPreviously sent data MAY be sent if no new data can be sent. Implementations\nMAY use alternative strategies for determining the content of probe packets,\nincluding sending new or retransmitted data based on the application's\npriorities.\n\nIt is possible the sender has no new or previously sent data to send.\nAs an example, consider the following sequence of events: new application data\nis sent in a STREAM frame, deemed lost, then retransmitted in a new packet,\nand then the original transmission is acknowledged.  When there is no data to\nsend, the sender SHOULD send a PING or other ack-eliciting frame in a single\npacket, rearming the PTO timer.\n\nAlternatively, instead of sending an ack-eliciting packet, the sender MAY mark\nany packets still in flight as lost.  Doing so avoids sending an additional\npacket but increases the risk that loss is declared too aggressively, resulting\nin an unnecessary rate reduction by the congestion controller.\n\nConsecutive PTO periods increase exponentially, and as a result, connection\nrecovery latency increases exponentially as packets continue to be dropped in\nthe network.  Sending two packets on PTO expiration increases resilience to\npacket drops, thus reducing the probability of consecutive PTO events.\n\nWhen the PTO timer expires multiple times and new data cannot be sent,\nimplementations must choose between sending the same payload every time\nor sending different payloads.  Sending the same payload may be simpler\nand ensures the highest priority frames arrive first.  Sending different\npayloads each time reduces the chances of spurious retransmission.\n\n\n## Handling Retry Packets\n\nA Retry packet causes a client to send another Initial packet, effectively\nrestarting the connection process.  A Retry packet indicates that the Initial\npacket was received but not processed.  A Retry packet cannot be treated as an\nacknowledgment because it does not indicate that a packet was processed or\nspecify the packet number.\n\nClients that receive a Retry packet reset congestion control and loss recovery\nstate, including resetting any pending timers.  Other connection state, in\nparticular cryptographic handshake messages, is retained; see\n{{Section 17.2.5 of QUIC-TRANSPORT}}.\n\nThe client MAY compute an RTT estimate to the server as the time period from\nwhen the first Initial packet was sent to when a Retry or a Version Negotiation\npacket is received.  The client MAY use this value in place of its default for\nthe initial RTT estimate.\n\n## Discarding Keys and Packet State {#discarding-packets}\n\nWhen Initial and Handshake packet protection keys are discarded\n(see {{Section 4.9 of QUIC-TLS}}), all packets that were sent with those keys\ncan no longer be acknowledged because their acknowledgments cannot be processed.\nThe sender MUST discard all recovery state associated with those packets\nand MUST remove them from the count of bytes in flight.\n\nEndpoints stop sending and receiving Initial packets once they start exchanging\nHandshake packets; see {{Section 17.2.2.1 of QUIC-TRANSPORT}}. At this point,\nrecovery state for all in-flight Initial packets is discarded.\n\nWhen 0-RTT is rejected, recovery state for all in-flight 0-RTT packets is\ndiscarded.\n\nIf a server accepts 0-RTT, but does not buffer 0-RTT packets that arrive\nbefore Initial packets, early 0-RTT packets will be declared lost, but that\nis expected to be infrequent.\n\nIt is expected that keys are discarded at some time after the packets\nencrypted with them are either acknowledged or declared lost. However,\nInitial and Handshake secrets are discarded as soon as Handshake and\n1-RTT keys are proven to be available to both client and server; see\n{{Section 4.9.1 of QUIC-TLS}}.\n\n# Congestion Control {#congestion-control}\n\nThis document specifies a sender-side congestion controller for QUIC similar to\nTCP NewReno {{?RFC6582}}.\n\nThe signals QUIC provides for congestion control are generic and are designed to\nsupport different sender-side algorithms. A sender can unilaterally choose a\ndifferent algorithm to use, such as CUBIC {{?RFC8312}}.\n\nIf a sender uses a different controller than that specified in this document,\nthe chosen controller MUST conform to the congestion control guidelines\nspecified in {{Section 3.1 of RFC8085}}.\n\nSimilar to TCP, packets containing only ACK frames do not count toward bytes\nin flight and are not congestion controlled.  Unlike TCP, QUIC can detect the\nloss of these packets and MAY use that information to adjust the congestion\ncontroller or the rate of ACK-only packets being sent, but this document does\nnot describe a mechanism for doing so.\n\nThe congestion controller is per path, so packets sent on other paths do not\nalter the current path's congestion controller, as described in\n{{Section 9.4 of QUIC-TRANSPORT}}.\n\nThe algorithm in this document specifies and uses the controller's congestion\nwindow in bytes.\n\nAn endpoint MUST NOT send a packet if it would cause bytes_in_flight (see\n{{vars-of-interest}}) to be larger than the congestion window, unless the packet\nis sent on a PTO timer expiration (see {{pto}}) or when entering recovery\n(see {{recovery-period}}).\n\n## Explicit Congestion Notification {#congestion-ecn}\n\nIf a path has been validated to support Explicit Congestion Notification (ECN)\n{{!RFC3168}} {{?RFC8311}}, QUIC treats a Congestion Experienced (CE) codepoint\nin the IP header as a signal of congestion. This document specifies an\nendpoint's response when the peer-reported ECN-CE count increases; see {{Section\n13.4.2 of QUIC-TRANSPORT}}.\n\n## Initial and Minimum Congestion Window {#initial-cwnd}\n\nQUIC begins every connection in slow start with the congestion window set to an\ninitial value.  Endpoints SHOULD use an initial congestion window of ten times\nthe maximum datagram size (max_datagram_size), while limiting the window to the\nlarger of 14,720 bytes or twice the maximum datagram size. This follows the\nanalysis and recommendations in {{?RFC6928}}, increasing the byte limit to\naccount for the smaller 8-byte overhead of UDP compared to the 20-byte overhead\nfor TCP.\n\nIf the maximum datagram size changes during the connection, the initial\ncongestion window SHOULD be recalculated with the new size.  If the maximum\ndatagram size is decreased in order to complete the handshake, the\ncongestion window SHOULD be set to the new initial congestion window.\n\nPrior to validating the client's address, the server can be further limited by\nthe anti-amplification limit as specified in {{Section 8.1 of QUIC-TRANSPORT}}.\nThough the anti-amplification limit can prevent the congestion window from\nbeing fully utilized and therefore slow down the increase in congestion window,\nit does not directly affect the congestion window.\n\nThe minimum congestion window is the smallest value the congestion window can\nattain in response to loss, an increase in the peer-reported ECN-CE count,\nor persistent congestion.  The RECOMMENDED value is 2 * max_datagram_size.\n\n## Congestion Control States\n\nThe NewReno congestion controller described in this document has three\ndistinct states, as shown in {{fig-cc-fsm}}.\n\n~~~\n                 New path or      +------------+\n            persistent congestion |   Slow     |\n        (O)---------------------->|   Start    |\n                                  +------------+\n                                        |\n                                Loss or |\n                        ECN-CE increase |\n                                        v\n +------------+     Loss or       +------------+\n | Congestion |  ECN-CE increase  |  Recovery  |\n | Avoidance  |------------------>|   Period   |\n +------------+                   +------------+\n           ^                            |\n           |                            |\n           +----------------------------+\n              Acknowledgment of packet\n                sent during recovery\n~~~\n{: #fig-cc-fsm title=\"Congestion Control States and Transitions\"}\n\nThese states and the transitions between them are described in subsequent\nsections.\n\n### Slow Start\n\nA NewReno sender is in slow start any time the congestion window is below the\nslow start threshold. A sender begins in slow start because the slow start\nthreshold is initialized to an infinite value.\n\nWhile a sender is in slow start, the congestion window increases by the number\nof bytes acknowledged when each acknowledgment is processed. This results in\nexponential growth of the congestion window.\n\nThe sender MUST exit slow start and enter a recovery period when a packet is\nlost or when the ECN-CE count reported by its peer increases.\n\nA sender reenters slow start any time the congestion window is less than the\nslow start threshold, which only occurs after persistent congestion is\ndeclared.\n\n### Recovery {#recovery-period}\n\nA NewReno sender enters a recovery period when it detects the loss of a packet\nor when the ECN-CE count reported by its peer increases. A sender that is\nalready in a recovery period stays in it and does not reenter it.\n\nOn entering a recovery period, a sender MUST set the slow start threshold to\nhalf the value of the congestion window when loss is detected. The congestion\nwindow MUST be set to the reduced value of the slow start threshold before\nexiting the recovery period.\n\nImplementations MAY reduce the congestion window immediately upon entering a\nrecovery period or use other mechanisms, such as Proportional Rate Reduction\n{{?PRR=RFC6937}}, to reduce the congestion window more gradually. If the\ncongestion window is reduced immediately, a single packet can be sent prior to\nreduction. This speeds up loss recovery if the data in the lost packet is\nretransmitted and is similar to TCP as described in {{Section 5 of RFC6675}}.\n\nThe recovery period aims to limit congestion window reduction to once per round\ntrip. Therefore, during a recovery period, the congestion window does not change\nin response to new losses or increases in the ECN-CE count.\n\nA recovery period ends and the sender enters congestion avoidance when a packet\nsent during the recovery period is acknowledged. This is slightly different\nfrom TCP's definition of recovery, which ends when the lost segment that\nstarted recovery is acknowledged {{?RFC5681}}.\n\n### Congestion Avoidance\n\nA NewReno sender is in congestion avoidance any time the congestion window is\nat or above the slow start threshold and not in a recovery period.\n\nA sender in congestion avoidance uses an Additive Increase Multiplicative\nDecrease (AIMD) approach that MUST limit the increase to the congestion window\nto at most one maximum datagram size for each congestion window that is\nacknowledged.\n\nThe sender exits congestion avoidance and enters a recovery period when a\npacket is lost or when the ECN-CE count reported by its peer increases.\n\n## Ignoring Loss of Undecryptable Packets\n\nDuring the handshake, some packet protection keys might not be available when\na packet arrives, and the receiver can choose to drop the packet. In particular,\nHandshake and 0-RTT packets cannot be processed until the Initial packets\narrive, and 1-RTT packets cannot be processed until the handshake completes.\nEndpoints MAY ignore the loss of Handshake, 0-RTT, and 1-RTT packets that might\nhave arrived before the peer had packet protection keys to process those\npackets. Endpoints MUST NOT ignore the loss of packets that were sent after\nthe earliest acknowledged packet in a given packet number space.\n\n## Probe Timeout\n\nProbe packets MUST NOT be blocked by the congestion controller.  A sender MUST\nhowever count these packets as being additionally in flight, since these packets\nadd network load without establishing packet loss.  Note that sending probe\npackets might cause the sender's bytes in flight to exceed the congestion window\nuntil an acknowledgment is received that establishes loss or delivery of\npackets.\n\n## Persistent Congestion {#persistent-congestion}\n\nWhen a sender establishes loss of all packets sent over a long enough duration,\nthe network is considered to be experiencing persistent congestion.\n\n### Duration {#pc-duration}\n\nThe persistent congestion duration is computed as follows:\n\n~~~pseudocode\n(smoothed_rtt + max(4*rttvar, kGranularity) + max_ack_delay) *\n    kPersistentCongestionThreshold\n~~~\n\nUnlike the PTO computation in {{pto}}, this duration includes the max_ack_delay\nirrespective of the packet number spaces in which losses are established.\n\nThis duration allows a sender to send as many packets before establishing\npersistent congestion, including some in response to PTO expiration, as TCP does\nwith Tail Loss Probes {{?RFC8985}} and an RTO {{?RFC5681}}.\n\nLarger values of kPersistentCongestionThreshold cause the sender to become less\nresponsive to persistent congestion in the network, which can result in\naggressive sending into a congested network. Too small a value can result in a\nsender declaring persistent congestion unnecessarily, resulting in reduced\nthroughput for the sender.\n\nThe RECOMMENDED value for kPersistentCongestionThreshold is 3, which results in\nbehavior that is approximately equivalent to a TCP sender declaring an RTO after\ntwo TLPs.\n\nThis design does not use consecutive PTO events to establish persistent\ncongestion, since application patterns impact PTO expiration. For example, a\nsender that sends small amounts of data with silence periods between them\nrestarts the PTO timer every time it sends, potentially preventing the PTO timer\nfrom expiring for a long period of time, even when no acknowledgments are being\nreceived. The use of a duration enables a sender to establish persistent\ncongestion without depending on PTO expiration.\n\n### Establishing Persistent Congestion\n\nA sender establishes persistent congestion after the receipt of an\nacknowledgment if two packets that are ack-eliciting are declared lost, and:\n\n* across all packet number spaces, none of the packets sent between the send\n  times of these two packets are acknowledged;\n\n* the duration between the send times of these two packets exceeds the\n  persistent congestion duration ({{pc-duration}}); and\n\n* a prior RTT sample existed when these two packets were sent.\n\nThese two packets MUST be ack-eliciting, since a receiver is required to\nacknowledge only ack-eliciting packets within its maximum acknowledgment delay;\nsee {{Section 13.2 of QUIC-TRANSPORT}}.\n\nThe persistent congestion period SHOULD NOT start until there is at least one\nRTT sample. Before the first RTT sample, a sender arms its PTO timer based on\nthe initial RTT ({{pto-handshake}}), which could be substantially larger than\nthe actual RTT. Requiring a prior RTT sample prevents a sender from establishing\npersistent congestion with potentially too few probes.\n\nSince network congestion is not affected by packet number spaces, persistent\ncongestion SHOULD consider packets sent across packet number spaces. A sender\nthat does not have state for all packet number spaces or an implementation that\ncannot compare send times across packet number spaces MAY use state for just the\npacket number space that was acknowledged. This might result in erroneously\ndeclaring persistent congestion, but it will not lead to a failure to detect\npersistent congestion.\n\nWhen persistent congestion is declared, the sender's congestion window MUST be\nreduced to the minimum congestion window (kMinimumWindow), similar to a TCP\nsender's response on an RTO {{RFC5681}}.\n\n### Example\n\nThe following example illustrates how a sender might establish persistent\ncongestion. Assume:\n\n~~~pseudocode\nsmoothed_rtt + max(4*rttvar, kGranularity) + max_ack_delay = 2\nkPersistentCongestionThreshold = 3\n~~~\n\nConsider the following sequence of events:\n\n| Time   |              Action               |\n|:-------|:----------------------------------|\n| t=0    | Send packet #1 (application data) |\n| t=1    | Send packet #2 (application data) |\n| t=1.2  | Receive acknowledgment of #1      |\n| t=2    | Send packet #3 (application data) |\n| t=3    | Send packet #4 (application data) |\n| t=4    | Send packet #5 (application data) |\n| t=5    | Send packet #6 (application data) |\n| t=6    | Send packet #7 (application data) |\n| t=8    | Send packet #8 (PTO 1)            |\n| t=12   | Send packet #9 (PTO 2)            |\n| t=12.2 | Receive acknowledgment of #9      |\n\nPackets 2 through 8 are declared lost when the acknowledgment for packet 9 is\nreceived at `t = 12.2`.\n\nThe congestion period is calculated as the time between the oldest and newest\nlost packets: `8 - 1 = 7`.  The persistent congestion duration is `2 * 3 = 6`.\nBecause the threshold was reached and because none of the packets between the\noldest and the newest lost packets were acknowledged, the network is considered\nto have experienced persistent congestion.\n\nWhile this example shows PTO expiration, they are not required for persistent\ncongestion to be established.\n\n\n## Pacing {#pacing}\n\nA sender SHOULD pace sending of all in-flight packets based on input from the\ncongestion controller.\n\nSending multiple packets into the network without any delay between them creates\na packet burst that might cause short-term congestion and losses. Senders MUST\neither use pacing or limit such bursts. Senders SHOULD limit bursts to the\ninitial congestion window; see {{initial-cwnd}}. A sender with knowledge that\nthe network path to the receiver can absorb larger bursts MAY use a higher\nlimit.\n\nAn implementation should take care to architect its congestion controller to\nwork well with a pacer.  For instance, a pacer might wrap the congestion\ncontroller and control the availability of the congestion window, or a pacer\nmight pace out packets handed to it by the congestion controller.\n\nTimely delivery of ACK frames is important for efficient loss recovery. To avoid\ndelaying their delivery to the peer, packets containing only ACK frames SHOULD\ntherefore not be paced.\n\nEndpoints can implement pacing as they choose. A perfectly paced sender spreads\npackets exactly evenly over time. For a window-based congestion controller, such\nas the one in this document, that rate can be computed by averaging the\ncongestion window over the RTT. Expressed as a rate in units of\nbytes per time, where congestion_window is in bytes:\n\n~~~pseudocode\nrate = N * congestion_window / smoothed_rtt\n~~~\n\nOr expressed as an inter-packet interval in units of time:\n\n~~~pseudocode\ninterval = ( smoothed_rtt * packet_size / congestion_window ) / N\n~~~\n\nUsing a value for `N` that is small, but at least 1 (for example, 1.25) ensures\nthat variations in RTT do not result in underutilization of the\ncongestion window.\n\nPractical considerations, such as packetization, scheduling delays, and\ncomputational efficiency, can cause a sender to deviate from this rate over time\nperiods that are much shorter than an RTT.\n\nOne possible implementation strategy for pacing uses a leaky bucket algorithm,\nwhere the capacity of the \"bucket\" is limited to the maximum burst size and the\nrate the \"bucket\" fills is determined by the above function.\n\n## Underutilizing the Congestion Window\n\nWhen bytes in flight is smaller than the congestion window and sending is not\npacing limited, the congestion window is underutilized. This can happen due to\ninsufficient application data or flow control limits. When this occurs,\nthe congestion window SHOULD NOT be increased in either slow start or\ncongestion avoidance.\n\nA sender that paces packets (see {{pacing}}) might delay sending packets\nand not fully utilize the congestion window due to this delay. A sender\nSHOULD NOT consider itself application limited if it would have fully\nutilized the congestion window without pacing delay.\n\nA sender MAY implement alternative mechanisms to update its congestion window\nafter periods of underutilization, such as those proposed for TCP in\n{{?RFC7661}}.\n\n\n# Security Considerations\n\n## Loss and Congestion Signals\n\nLoss detection and congestion control fundamentally involve the consumption of\nsignals, such as delay, loss, and ECN markings, from unauthenticated\nentities. An attacker can cause endpoints to reduce their sending rate by\nmanipulating these signals: by dropping packets, by altering path delay\nstrategically, or by changing ECN codepoints.\n\n## Traffic Analysis\n\nPackets that carry only ACK frames can be heuristically identified by observing\npacket size.  Acknowledgment patterns may expose information about link\ncharacteristics or application behavior.  To reduce leaked information,\nendpoints can bundle acknowledgments with other frames, or they can use PADDING\nframes at a potential cost to performance.\n\n## Misreporting ECN Markings\n\nA receiver can misreport ECN markings to alter the congestion response of a\nsender.  Suppressing reports of ECN-CE markings could cause a sender to\nincrease their send rate.  This increase could result in congestion and loss.\n\nA sender can detect suppression of reports by marking occasional packets that it\nsends with an ECN-CE marking. If a packet sent with an ECN-CE marking is not\nreported as having been CE marked when the packet is acknowledged, then the\nsender can disable ECN for that path by not setting ECN-Capable Transport (ECT)\ncodepoints in subsequent packets sent on that path {{!RFC3168}}.\n\nReporting additional ECN-CE markings will cause a sender to reduce their sending\nrate, which is similar in effect to advertising reduced connection flow control\nlimits and so no advantage is gained by doing so.\n\nEndpoints choose the congestion controller that they use. Congestion controllers\nrespond to reports of ECN-CE by reducing their rate, but the response may vary.\nMarkings can be treated as equivalent to loss {{!RFC3168}}, but other\nresponses can be specified, such as {{?RFC8511}} or {{?RFC8311}}.\n\n\n--- back\n\n# Loss Recovery Pseudocode\n\nWe now describe an example implementation of the loss detection mechanisms\ndescribed in {{loss-detection}}.\n\nThe pseudocode segments in this section are licensed as Code Components; see the\ncopyright notice.\n\n## Tracking Sent Packets {#tracking-sent-packets}\n\nTo correctly implement congestion control, a QUIC sender tracks every\nack-eliciting packet until the packet is acknowledged or lost.\nIt is expected that implementations will be able to access this information by\npacket number and crypto context and store the per-packet fields\n({{sent-packets-fields}}) for loss recovery and congestion control.\n\nAfter a packet is declared lost, the endpoint can still maintain state for it\nfor an amount of time to allow for packet reordering; see {{Section 13.3 of\nQUIC-TRANSPORT}}. This enables a sender to detect spurious retransmissions.\n\nSent packets are tracked for each packet number space, and ACK\nprocessing only applies to a single space.\n\n### Sent Packet Fields {#sent-packets-fields}\n\npacket_number:\n: The packet number of the sent packet.\n\nack_eliciting:\n: A Boolean that indicates whether a packet is ack-eliciting.\n  If true, it is expected that an acknowledgment will be received,\n  though the peer could delay sending the ACK frame containing it\n  by up to the max_ack_delay.\n\nin_flight:\n: A Boolean that indicates whether the packet counts toward bytes in\n  flight.\n\nsent_bytes:\n: The number of bytes sent in the packet, not including UDP or IP\n  overhead, but including QUIC framing overhead.\n\ntime_sent:\n: The time the packet was sent.\n\n\n## Constants of Interest {#constants-of-interest}\n\nConstants used in loss recovery are based on a combination of RFCs, papers, and\ncommon practice.\n\nkPacketThreshold:\n: Maximum reordering in packets before packet threshold loss detection\n  considers a packet lost. The value recommended in {{packet-threshold}} is 3.\n\nkTimeThreshold:\n\n: Maximum reordering in time before time threshold loss detection\n  considers a packet lost. Specified as an RTT multiplier. The value\n  recommended in {{time-threshold}} is 9/8.\n\nkGranularity:\n\n: Timer granularity. This is a system-dependent value, and {{time-threshold}}\n  recommends a value of 1 ms.\n\nkInitialRtt:\n: The RTT used before an RTT sample is taken. The value recommended in\n{{pto-handshake}} is 333 ms.\n\nkPacketNumberSpace:\n: An enum to enumerate the three packet number spaces:\n\n~~~\nenum kPacketNumberSpace {\n  Initial,\n  Handshake,\n  ApplicationData,\n}\n~~~\n\n## Variables of Interest {#ld-vars-of-interest}\n\nVariables required to implement the congestion control mechanisms\nare described in this section.\n\nlatest_rtt:\n: The most recent RTT measurement made when receiving an acknowledgment for\n  a previously unacknowledged packet.\n\nsmoothed_rtt:\n: The smoothed RTT of the connection, computed as described in\n  {{smoothed-rtt}}.\n\nrttvar:\n: The RTT variation, computed as described in {{smoothed-rtt}}.\n\nmin_rtt:\n: The minimum RTT seen over a period of time, ignoring acknowledgment delay, as\n  described in {{min-rtt}}.\n\nfirst_rtt_sample:\n: The time that the first RTT sample was obtained.\n\nmax_ack_delay:\n: The maximum amount of time by which the receiver intends to delay\n  acknowledgments for packets in the Application Data packet number\n  space, as defined by the eponymous transport parameter ({{Section 18.2\n  of QUIC-TRANSPORT}}). Note that the actual ack_delay in a received\n  ACK frame may be larger due to late timers, reordering, or loss.\n\nloss_detection_timer:\n: Multi-modal timer used for loss detection.\n\npto_count:\n: The number of times a PTO has been sent without receiving an acknowledgment.\n\ntime_of_last_ack_eliciting_packet\\[kPacketNumberSpace]:\n: The time the most recent ack-eliciting packet was sent.\n\nlargest_acked_packet\\[kPacketNumberSpace]:\n: The largest packet number acknowledged in the packet number space so far.\n\nloss_time\\[kPacketNumberSpace]:\n: The time at which the next packet in that packet number space can be\n  considered lost based on exceeding the reordering window in time.\n\nsent_packets\\[kPacketNumberSpace]:\n: An association of packet numbers in a packet number space to information\n  about them.  Described in detail above in {{tracking-sent-packets}}.\n\n\n## Initialization\n\nAt the beginning of the connection, initialize the loss detection variables as\nfollows:\n\n~~~pseudocode\nloss_detection_timer.reset()\npto_count = 0\nlatest_rtt = 0\nsmoothed_rtt = kInitialRtt\nrttvar = kInitialRtt / 2\nmin_rtt = 0\nfirst_rtt_sample = 0\nfor pn_space in [ Initial, Handshake, ApplicationData ]:\n  largest_acked_packet[pn_space] = infinite\n  time_of_last_ack_eliciting_packet[pn_space] = 0\n  loss_time[pn_space] = 0\n~~~\n\n\n## On Sending a Packet\n\nAfter a packet is sent, information about the packet is stored.  The parameters\nto OnPacketSent are described in detail above in {{sent-packets-fields}}.\n\nPseudocode for OnPacketSent follows:\n\n~~~pseudocode\nOnPacketSent(packet_number, pn_space, ack_eliciting,\n             in_flight, sent_bytes):\n  sent_packets[pn_space][packet_number].packet_number =\n                                           packet_number\n  sent_packets[pn_space][packet_number].time_sent = now()\n  sent_packets[pn_space][packet_number].ack_eliciting =\n                                           ack_eliciting\n  sent_packets[pn_space][packet_number].in_flight = in_flight\n  sent_packets[pn_space][packet_number].sent_bytes = sent_bytes\n  if (in_flight):\n    if (ack_eliciting):\n      time_of_last_ack_eliciting_packet[pn_space] = now()\n    OnPacketSentCC(sent_bytes)\n    SetLossDetectionTimer()\n~~~\n\n## On Receiving a Datagram\n\nWhen a server is blocked by anti-amplification limits, receiving\na datagram unblocks it, even if none of the packets in the\ndatagram are successfully processed. In such a case, the PTO\ntimer will need to be rearmed.\n\nPseudocode for OnDatagramReceived follows:\n\n~~~pseudocode\nOnDatagramReceived(datagram):\n  // If this datagram unblocks the server, arm the\n  // PTO timer to avoid deadlock.\n  if (server was at anti-amplification limit):\n    SetLossDetectionTimer()\n    if loss_detection_timer.timeout < now():\n      // Execute PTO if it would have expired\n      // while the amplification limit applied.\n      OnLossDetectionTimeout()\n~~~\n\n## On Receiving an Acknowledgment\n\nWhen an ACK frame is received, it may newly acknowledge any number of packets.\n\nPseudocode for OnAckReceived and UpdateRtt follow:\n\n~~~pseudocode\nIncludesAckEliciting(packets):\n  for packet in packets:\n    if (packet.ack_eliciting):\n      return true\n  return false\n\nOnAckReceived(ack, pn_space):\n  if (largest_acked_packet[pn_space] == infinite):\n    largest_acked_packet[pn_space] = ack.largest_acked\n  else:\n    largest_acked_packet[pn_space] =\n        max(largest_acked_packet[pn_space], ack.largest_acked)\n\n  // DetectAndRemoveAckedPackets finds packets that are newly\n  // acknowledged and removes them from sent_packets.\n  newly_acked_packets =\n      DetectAndRemoveAckedPackets(ack, pn_space)\n  // Nothing to do if there are no newly acked packets.\n  if (newly_acked_packets.empty()):\n    return\n\n  // Update the RTT if the largest acknowledged is newly acked\n  // and at least one ack-eliciting was newly acked.\n  if (newly_acked_packets.largest().packet_number ==\n          ack.largest_acked &&\n      IncludesAckEliciting(newly_acked_packets)):\n    latest_rtt =\n      now() - newly_acked_packets.largest().time_sent\n    UpdateRtt(ack.ack_delay)\n\n  // Process ECN information if present.\n  if (ACK frame contains ECN information):\n      ProcessECN(ack, pn_space)\n\n  lost_packets = DetectAndRemoveLostPackets(pn_space)\n  if (!lost_packets.empty()):\n    OnPacketsLost(lost_packets)\n  OnPacketsAcked(newly_acked_packets)\n\n  // Reset pto_count unless the client is unsure if\n  // the server has validated the client's address.\n  if (PeerCompletedAddressValidation()):\n    pto_count = 0\n  SetLossDetectionTimer()\n\n\nUpdateRtt(ack_delay):\n  if (first_rtt_sample == 0):\n    min_rtt = latest_rtt\n    smoothed_rtt = latest_rtt\n    rttvar = latest_rtt / 2\n    first_rtt_sample = now()\n    return\n\n  // min_rtt ignores acknowledgment delay.\n  min_rtt = min(min_rtt, latest_rtt)\n  // Limit ack_delay by max_ack_delay after handshake\n  // confirmation.\n  if (handshake confirmed):\n    ack_delay = min(ack_delay, max_ack_delay)\n\n  // Adjust for acknowledgment delay if plausible.\n  adjusted_rtt = latest_rtt\n  if (latest_rtt >= min_rtt + ack_delay):\n    adjusted_rtt = latest_rtt - ack_delay\n\n  rttvar = 3/4 * rttvar + 1/4 * abs(smoothed_rtt - adjusted_rtt)\n  smoothed_rtt = 7/8 * smoothed_rtt + 1/8 * adjusted_rtt\n~~~\n\n## Setting the Loss Detection Timer\n\nQUIC loss detection uses a single timer for all timeout loss detection.  The\nduration of the timer is based on the timer's mode, which is set in the packet\nand timer events further below.  The function SetLossDetectionTimer defined\nbelow shows how the single timer is set.\n\nThis algorithm may result in the timer being set in the past, particularly if\ntimers wake up late. Timers set in the past fire immediately.\n\nPseudocode for SetLossDetectionTimer follows (where the \"^\" operator represents\nexponentiation):\n\n~~~pseudocode\nGetLossTimeAndSpace():\n  time = loss_time[Initial]\n  space = Initial\n  for pn_space in [ Handshake, ApplicationData ]:\n    if (time == 0 || loss_time[pn_space] < time):\n      time = loss_time[pn_space];\n      space = pn_space\n  return time, space\n\nGetPtoTimeAndSpace():\n  duration = (smoothed_rtt + max(4 * rttvar, kGranularity))\n      * (2 ^ pto_count)\n  // Anti-deadlock PTO starts from the current time\n  if (no ack-eliciting packets in flight):\n    assert(!PeerCompletedAddressValidation())\n    if (has handshake keys):\n      return (now() + duration), Handshake\n    else:\n      return (now() + duration), Initial\n  pto_timeout = infinite\n  pto_space = Initial\n  for space in [ Initial, Handshake, ApplicationData ]:\n    if (no ack-eliciting packets in flight in space):\n        continue;\n    if (space == ApplicationData):\n      // Skip Application Data until handshake confirmed.\n      if (handshake is not confirmed):\n        return pto_timeout, pto_space\n      // Include max_ack_delay and backoff for Application Data.\n      duration += max_ack_delay * (2 ^ pto_count)\n\n    t = time_of_last_ack_eliciting_packet[space] + duration\n    if (t < pto_timeout):\n      pto_timeout = t\n      pto_space = space\n  return pto_timeout, pto_space\n\nPeerCompletedAddressValidation():\n  // Assume clients validate the server's address implicitly.\n  if (endpoint is server):\n    return true\n  // Servers complete address validation when a\n  // protected packet is received.\n  return has received Handshake ACK ||\n       handshake confirmed\n\nSetLossDetectionTimer():\n  earliest_loss_time, _ = GetLossTimeAndSpace()\n  if (earliest_loss_time != 0):\n    // Time threshold loss detection.\n    loss_detection_timer.update(earliest_loss_time)\n    return\n\n  if (server is at anti-amplification limit):\n    // The server's timer is not set if nothing can be sent.\n    loss_detection_timer.cancel()\n    return\n\n  if (no ack-eliciting packets in flight &&\n      PeerCompletedAddressValidation()):\n    // There is nothing to detect lost, so no timer is set.\n    // However, the client needs to arm the timer if the\n    // server might be blocked by the anti-amplification limit.\n    loss_detection_timer.cancel()\n    return\n\n  timeout, _ = GetPtoTimeAndSpace()\n  loss_detection_timer.update(timeout)\n~~~\n\n\n## On Timeout\n\nWhen the loss detection timer expires, the timer's mode determines the action\nto be performed.\n\nPseudocode for OnLossDetectionTimeout follows:\n\n~~~pseudocode\nOnLossDetectionTimeout():\n  earliest_loss_time, pn_space = GetLossTimeAndSpace()\n  if (earliest_loss_time != 0):\n    // Time threshold loss Detection\n    lost_packets = DetectAndRemoveLostPackets(pn_space)\n    assert(!lost_packets.empty())\n    OnPacketsLost(lost_packets)\n    SetLossDetectionTimer()\n    return\n\n  if (no ack-eliciting packets in flight):\n    assert(!PeerCompletedAddressValidation())\n    // Client sends an anti-deadlock packet: Initial is padded\n    // to earn more anti-amplification credit,\n    // a Handshake packet proves address ownership.\n    if (has Handshake keys):\n      SendOneAckElicitingHandshakePacket()\n    else:\n      SendOneAckElicitingPaddedInitialPacket()\n  else:\n    // PTO. Send new data if available, else retransmit old data.\n    // If neither is available, send a single PING frame.\n    _, pn_space = GetPtoTimeAndSpace()\n    SendOneOrTwoAckElicitingPackets(pn_space)\n\n  pto_count++\n  SetLossDetectionTimer()\n~~~\n\n\n## Detecting Lost Packets\n\nDetectAndRemoveLostPackets is called every time an ACK is received or the time\nthreshold loss detection timer expires. This function operates on the\nsent_packets for that packet number space and returns a list of packets newly\ndetected as lost.\n\nPseudocode for DetectAndRemoveLostPackets follows:\n\n~~~pseudocode\nDetectAndRemoveLostPackets(pn_space):\n  assert(largest_acked_packet[pn_space] != infinite)\n  loss_time[pn_space] = 0\n  lost_packets = []\n  loss_delay = kTimeThreshold * max(latest_rtt, smoothed_rtt)\n\n  // Minimum time of kGranularity before packets are deemed lost.\n  loss_delay = max(loss_delay, kGranularity)\n\n  // Packets sent before this time are deemed lost.\n  lost_send_time = now() - loss_delay\n\n  foreach unacked in sent_packets[pn_space]:\n    if (unacked.packet_number > largest_acked_packet[pn_space]):\n      continue\n\n    // Mark packet as lost, or set time when it should be marked.\n    // Note: The use of kPacketThreshold here assumes that there\n    // were no sender-induced gaps in the packet number space.\n    if (unacked.time_sent <= lost_send_time ||\n        largest_acked_packet[pn_space] >=\n          unacked.packet_number + kPacketThreshold):\n      sent_packets[pn_space].remove(unacked.packet_number)\n      lost_packets.insert(unacked)\n    else:\n      if (loss_time[pn_space] == 0):\n        loss_time[pn_space] = unacked.time_sent + loss_delay\n      else:\n        loss_time[pn_space] = min(loss_time[pn_space],\n                                  unacked.time_sent + loss_delay)\n  return lost_packets\n~~~\n\n\n## Upon Dropping Initial or Handshake Keys\n\nWhen Initial or Handshake keys are discarded, packets from the space\nare discarded and loss detection state is updated.\n\nPseudocode for OnPacketNumberSpaceDiscarded follows:\n\n~~~pseudocode\nOnPacketNumberSpaceDiscarded(pn_space):\n  assert(pn_space != ApplicationData)\n  RemoveFromBytesInFlight(sent_packets[pn_space])\n  sent_packets[pn_space].clear()\n  // Reset the loss detection and PTO timer\n  time_of_last_ack_eliciting_packet[pn_space] = 0\n  loss_time[pn_space] = 0\n  pto_count = 0\n  SetLossDetectionTimer()\n~~~\n\n\n# Congestion Control Pseudocode\n\nWe now describe an example implementation of the congestion controller described\nin {{congestion-control}}.\n\nThe pseudocode segments in this section are licensed as Code Components; see the\ncopyright notice.\n\n## Constants of Interest {#cc-consts-of-interest}\n\nConstants used in congestion control are based on a combination of RFCs, papers,\nand common practice.\n\nkInitialWindow:\n: Default limit on the initial bytes in flight as described in {{initial-cwnd}}.\n\nkMinimumWindow:\n: Minimum congestion window in bytes as described in {{initial-cwnd}}.\n\nkLossReductionFactor:\n: Scaling factor applied to reduce the congestion window when a new loss event\n  is detected. {{congestion-control}} recommends a value of 0.5.\n\nkPersistentCongestionThreshold:\n: Period of time for persistent congestion to be established, specified as a PTO\n  multiplier. {{persistent-congestion}} recommends a value of 3.\n\n\n## Variables of Interest {#vars-of-interest}\n\nVariables required to implement the congestion control mechanisms\nare described in this section.\n\nmax_datagram_size:\n: The sender's current maximum payload size. This does not include UDP or IP\n  overhead.  The max datagram size is used for congestion window\n  computations. An endpoint sets the value of this variable based on its Path\n  Maximum Transmission Unit (PMTU; see {{Section 14.2 of QUIC-TRANSPORT}}), with\n  a minimum value of 1200 bytes.\n\necn_ce_counters\\[kPacketNumberSpace]:\n: The highest value reported for the ECN-CE counter in the packet number space\n  by the peer in an ACK frame. This value is used to detect increases in the\n  reported ECN-CE counter.\n\nbytes_in_flight:\n: The sum of the size in bytes of all sent packets that contain at least one\n  ack-eliciting or PADDING frame and have not been acknowledged or declared\n  lost. The size does not include IP or UDP overhead, but does include the QUIC\n  header and Authenticated Encryption with Associated Data (AEAD) overhead.\n  Packets only containing ACK frames do not count toward bytes_in_flight to\n  ensure congestion control does not impede congestion feedback.\n\ncongestion_window:\n: Maximum number of bytes allowed to be in flight.\n\ncongestion_recovery_start_time:\n: The time the current recovery period started due to the detection of loss\n  or ECN. When a packet sent after this time is acknowledged, QUIC exits\n  congestion recovery.\n\nssthresh:\n: Slow start threshold in bytes.  When the congestion window is below ssthresh,\n  the mode is slow start and the window grows by the number of bytes\n  acknowledged.\n\nThe congestion control pseudocode also accesses some of the variables from the\nloss recovery pseudocode.\n\n## Initialization\n\nAt the beginning of the connection, initialize the congestion control\nvariables as follows:\n\n~~~pseudocode\ncongestion_window = kInitialWindow\nbytes_in_flight = 0\ncongestion_recovery_start_time = 0\nssthresh = infinite\nfor pn_space in [ Initial, Handshake, ApplicationData ]:\n  ecn_ce_counters[pn_space] = 0\n~~~\n\n\n## On Packet Sent\n\nWhenever a packet is sent and it contains non-ACK frames, the packet\nincreases bytes_in_flight.\n\n~~~pseudocode\nOnPacketSentCC(sent_bytes):\n  bytes_in_flight += sent_bytes\n~~~\n\n\n## On Packet Acknowledgment\n\nThis is invoked from loss detection's OnAckReceived and is supplied with the\nnewly acked_packets from sent_packets.\n\nIn congestion avoidance, implementers that use an integer representation\nfor congestion_window should be careful with division and can use\nthe alternative approach suggested in {{Section 2.1 of RFC3465}}.\n\n~~~pseudocode\nInCongestionRecovery(sent_time):\n  return sent_time <= congestion_recovery_start_time\n\nOnPacketsAcked(acked_packets):\n  for acked_packet in acked_packets:\n    OnPacketAcked(acked_packet)\n\nOnPacketAcked(acked_packet):\n  if (!acked_packet.in_flight):\n    return;\n  // Remove from bytes_in_flight.\n  bytes_in_flight -= acked_packet.sent_bytes\n  // Do not increase congestion_window if application\n  // limited or flow control limited.\n  if (IsAppOrFlowControlLimited())\n    return\n  // Do not increase congestion window in recovery period.\n  if (InCongestionRecovery(acked_packet.time_sent)):\n    return\n  if (congestion_window < ssthresh):\n    // Slow start.\n    congestion_window += acked_packet.sent_bytes\n  else:\n    // Congestion avoidance.\n    congestion_window +=\n      max_datagram_size * acked_packet.sent_bytes\n      / congestion_window\n~~~\n\n\n## On New Congestion Event\n\nThis is invoked from ProcessECN and OnPacketsLost when a new congestion event is\ndetected. If not already in recovery, this starts a recovery period and\nreduces the slow start threshold and congestion window immediately.\n\n~~~pseudocode\nOnCongestionEvent(sent_time):\n  // No reaction if already in a recovery period.\n  if (InCongestionRecovery(sent_time)):\n    return\n\n  // Enter recovery period.\n  congestion_recovery_start_time = now()\n  ssthresh = congestion_window * kLossReductionFactor\n  congestion_window = max(ssthresh, kMinimumWindow)\n  // A packet can be sent to speed up loss recovery.\n  MaybeSendOnePacket()\n~~~\n\n\n## Process ECN Information\n\nThis is invoked when an ACK frame with an ECN section is received from the peer.\n\n~~~pseudocode\nProcessECN(ack, pn_space):\n  // If the ECN-CE counter reported by the peer has increased,\n  // this could be a new congestion event.\n  if (ack.ce_counter > ecn_ce_counters[pn_space]):\n    ecn_ce_counters[pn_space] = ack.ce_counter\n    sent_time = sent_packets[ack.largest_acked].time_sent\n    OnCongestionEvent(sent_time)\n~~~\n\n\n## On Packets Lost\n\nThis is invoked when DetectAndRemoveLostPackets deems packets lost.\n\n~~~pseudocode\nOnPacketsLost(lost_packets):\n  sent_time_of_last_loss = 0\n  // Remove lost packets from bytes_in_flight.\n  for lost_packet in lost_packets:\n    if lost_packet.in_flight:\n      bytes_in_flight -= lost_packet.sent_bytes\n      sent_time_of_last_loss =\n        max(sent_time_of_last_loss, lost_packet.time_sent)\n  // Congestion event if in-flight packets were lost\n  if (sent_time_of_last_loss != 0):\n    OnCongestionEvent(sent_time_of_last_loss)\n\n  // Reset the congestion window if the loss of these\n  // packets indicates persistent congestion.\n  // Only consider packets sent after getting an RTT sample.\n  if (first_rtt_sample == 0):\n    return\n  pc_lost = []\n  for lost in lost_packets:\n    if lost.time_sent > first_rtt_sample:\n      pc_lost.insert(lost)\n  if (InPersistentCongestion(pc_lost)):\n    congestion_window = kMinimumWindow\n    congestion_recovery_start_time = 0\n~~~\n\n\n## Removing Discarded Packets from Bytes in Flight\n\nWhen Initial or Handshake keys are discarded, packets sent in that space no\nlonger count toward bytes in flight.\n\nPseudocode for RemoveFromBytesInFlight follows:\n\n~~~pseudocode\nRemoveFromBytesInFlight(discarded_packets):\n  // Remove any unacknowledged packets from flight.\n  foreach packet in discarded_packets:\n    if packet.in_flight\n      bytes_in_flight -= size\n~~~\n\n\n# Contributors\n{: numbered=\"false\"}\n\nThe IETF QUIC Working Group received an enormous amount of support from many\npeople. The following people provided substantive contributions to this\ndocument:\n\n<ul spacing=\"compact\">\n<li><t><contact fullname=\"Alessandro Ghedini\"/></t></li>\n<li><t><contact fullname=\"Benjamin Saunders\"/></t></li>\n<li><t><contact fullname=\"Gorry Fairhurst\"/></t></li>\n<li><t><contact asciiFullname=\"Kazu Yamamoto\" fullname=\"山本和彦\"/></t></li>\n<li><t><contact asciiFullname=\"Kazuho Oku\" fullname=\"奥 一穂\"/></t></li>\n<li><t><contact fullname=\"Lars Eggert\"/></t></li>\n<li><t><contact fullname=\"Magnus Westerlund\"/></t></li>\n<li><t><contact fullname=\"Marten Seemann\"/></t></li>\n<li><t><contact fullname=\"Martin Duke\"/></t></li>\n<li><t><contact fullname=\"Martin Thomson\"/></t></li>\n<li><t><contact fullname=\"Mirja Kühlewind\"/></t></li>\n<li><t><contact fullname=\"Nick Banks\"/></t></li>\n<li><t><contact fullname=\"Praveen Balasubramanian\"/></t></li>\n</ul>\n"
        },
        {
          "name": "rfc9114.md",
          "type": "blob",
          "size": 123.5205078125,
          "content": "---\ntitle: HTTP/3\nnumber: 9114\ndocname: draft-ietf-quic-http-latest\ndate: 2022-06\ncategory: std\nipr: trust200902\narea: Transport\nworkgroup: QUIC\nkeyword:\n  - \"HTTP/2\"\n  - HPACK\n  - QPACK\n  - Web\n\nstand_alone: yes\nautolink-iref-cleanup: true\npi: [toc, sortrefs, symrefs, docmapping]\n\nauthor:\n-\n    ins: M. Bishop\n    name: Mike Bishop\n    org: Akamai\n    email: mbishop@evequefou.be\n    role: editor\n\nnormative:\n  RFC9204:\n    display: QPACK\n  RFC9110:\n    display: HTTP\n  RFC9111:\n    display: HTTP-CACHING\n  URI: RFC3986\n\ninformative:\n  RFC9112:\n    display: HTTP/1.1\n  RFC9113:\n    display: HTTP/2\n\n  BREACH:\n    title: \"BREACH: Reviving the CRIME Attack\"\n    date: \"July 2013\"\n    target: http://breachattack.com/resources/BREACH%20-%20SSL,%20gone%20in%2030%20seconds.pdf\n    author:\n      -\n        ins: Y. Gluck\n      -\n        ins: N. Harris\n      -\n        ins: A. Prado\n\n--- abstract\n\nThe QUIC transport protocol has several features that are desirable in a\ntransport for HTTP, such as stream multiplexing, per-stream flow control, and\nlow-latency connection establishment.  This document describes a mapping of HTTP\nsemantics over QUIC.  This document also identifies HTTP/2 features that are\nsubsumed by QUIC and describes how HTTP/2 extensions can be ported to HTTP/3.\n\n\n--- middle\n\n\n# Introduction\n\nHTTP semantics ({{RFC9110}}) are used for a broad range of services on the\nInternet. These semantics have most commonly been used with HTTP/1.1 and HTTP/2.\nHTTP/1.1 has been used over a variety of transport and session layers, while\nHTTP/2 has been used primarily with TLS over TCP. HTTP/3 supports the same\nsemantics over a new transport protocol: QUIC.\n\n## Prior Versions of HTTP\n\nHTTP/1.1 ({{RFC9112}}) uses whitespace-delimited text fields to convey HTTP\nmessages.  While these exchanges are human readable, using whitespace for\nmessage formatting leads to parsing complexity and excessive tolerance of\nvariant behavior.\n\nBecause HTTP/1.1 does not include a multiplexing layer, multiple TCP connections\nare often used to service requests in parallel. However, that has a negative\nimpact on congestion control and network efficiency, since TCP does not share\ncongestion control across multiple connections.\n\nHTTP/2 ({{RFC9113}}) introduced a binary framing and multiplexing layer\nto improve latency without modifying the transport layer.  However, because the\nparallel nature of HTTP/2's multiplexing is not visible to TCP's loss recovery\nmechanisms, a lost or reordered packet causes all active transactions to\nexperience a stall regardless of whether that transaction was directly impacted\nby the lost packet.\n\n## Delegation to QUIC\n\nThe QUIC transport protocol incorporates stream multiplexing and per-stream flow\ncontrol, similar to that provided by the HTTP/2 framing layer. By providing\nreliability at the stream level and congestion control across the entire\nconnection, QUIC has the capability to improve the performance of HTTP compared\nto a TCP mapping.  QUIC also incorporates TLS 1.3 ({{?TLS=RFC8446}}) at the\ntransport layer, offering comparable confidentiality and integrity to running\nTLS over TCP, with the improved connection setup latency of TCP Fast Open\n({{?TFO=RFC7413}}).\n\nThis document defines HTTP/3: a mapping of HTTP semantics over the QUIC\ntransport protocol, drawing heavily on the design of HTTP/2.  HTTP/3 relies on\nQUIC to provide confidentiality and integrity protection of data; peer\nauthentication; and reliable, in-order, per-stream delivery. While delegating\nstream lifetime and flow-control issues to QUIC, a binary framing similar to the\nHTTP/2 framing is used on each stream. Some HTTP/2 features are subsumed by\nQUIC, while other features are implemented atop QUIC.\n\nQUIC is described in {{!QUIC-TRANSPORT=RFC9000}}.  For a full description of\nHTTP/2, see {{RFC9113}}.\n\n# HTTP/3 Protocol Overview\n\nHTTP/3 provides a transport for HTTP semantics using the QUIC transport protocol\nand an internal framing layer similar to HTTP/2.\n\nOnce a client knows that an HTTP/3 server exists at a certain endpoint, it opens\na QUIC connection. QUIC provides protocol negotiation, stream-based\nmultiplexing, and flow control.  Discovery of an HTTP/3 endpoint is described in\n{{discovery}}.\n\nWithin each stream, the basic unit of HTTP/3 communication is a frame\n({{frames}}).  Each frame type serves a different purpose.  For example, HEADERS\nand DATA frames form the basis of HTTP requests and responses\n({{request-response}}).  Frames that apply to the entire connection are\nconveyed on a dedicated control stream.\n\nMultiplexing of requests is performed using the QUIC stream abstraction, which\nis described in {{Section 2 of QUIC-TRANSPORT}}.  Each request-response pair\nconsumes a single QUIC stream.  Streams are independent of each other, so one\nstream that is blocked or suffers packet loss does not prevent progress on other\nstreams.\n\nServer push is an interaction mode introduced in HTTP/2 ({{RFC9113}}) that\npermits a server to push a request-response exchange to a client in anticipation\nof the client making the indicated request.  This trades off network usage\nagainst a potential latency gain.  Several HTTP/3 frames are used to manage\nserver push, such as PUSH_PROMISE, MAX_PUSH_ID, and CANCEL_PUSH.\n\nAs in HTTP/2, request and response fields are compressed for transmission.\nBecause HPACK ({{?HPACK=RFC7541}}) relies on in-order transmission of\ncompressed field sections (a guarantee not provided by QUIC), HTTP/3 replaces\nHPACK with QPACK ({{RFC9204}}). QPACK uses separate unidirectional streams to\nmodify and track field table state, while encoded field sections refer to the\nstate of the table without modifying it.\n\n## Document Organization\n\nThe following sections provide a detailed overview of the lifecycle of an HTTP/3\nconnection:\n\n- \"{{<<connection-setup}}\" ({{connection-setup}}) covers how an HTTP/3\n  endpoint is discovered and an HTTP/3 connection is established.\n- \"{{<<http-request-lifecycle}}\" ({{http-request-lifecycle}}) describes how HTTP\n  semantics are expressed using frames.\n- \"{{<<connection-closure}}\" ({{connection-closure}}) describes how HTTP/3\n  connections are terminated, either gracefully or abruptly.\n\nThe details of the wire protocol and interactions with the transport are\ndescribed in subsequent sections:\n\n- \"{{<<stream-mapping}}\" ({{stream-mapping}}) describes the way QUIC streams\n  are used.\n- \"{{<<http-framing-layer}}\" ({{http-framing-layer}}) describes the frames used\n  on most streams.\n- \"{{<<errors}}\" ({{errors}}) describes how error conditions are handled and\n  expressed, either on a particular stream or for the connection as a whole.\n\nAdditional resources are provided in the final sections:\n\n- \"{{<<extensions}}\" ({{extensions}}) describes how new capabilities can be\n  added in future documents.\n- A more detailed comparison between HTTP/2 and HTTP/3 can be found in\n  {{h2-considerations}}.\n\n## Conventions and Terminology\n\n{::boilerplate bcp14-tagged}\n\nThis document uses the variable-length integer encoding from\n{{QUIC-TRANSPORT}}.\n\nThe following terms are used:\n\nabort:\n: An abrupt termination of a connection or stream, possibly due to an error\n  condition.\n\nclient:\n: The endpoint that initiates an HTTP/3 connection.  Clients send HTTP requests\n  and receive HTTP responses.\n\nconnection:\n: A transport-layer connection between two endpoints using QUIC as the\n  transport protocol.\n\nconnection error:\n: An error that affects the entire HTTP/3 connection.\n\nendpoint:\n: Either the client or server of the connection.\n\nframe:\n: The smallest unit of communication on a stream in HTTP/3, consisting of a\n  header and a variable-length sequence of bytes structured according to the\n  frame type.\n\n  Protocol elements called \"frames\" exist in both this document and\n  {{QUIC-TRANSPORT}}. Where frames from {{QUIC-TRANSPORT}} are referenced, the\n  frame name will be prefaced with \"QUIC\".  For example, \"QUIC CONNECTION_CLOSE\n  frames\".  References without this preface refer to frames defined in\n  {{frames}}.\n\nHTTP/3 connection:\n: A QUIC connection where the negotiated application protocol is HTTP/3.\n\npeer:\n: An endpoint.  When discussing a particular endpoint, \"peer\" refers to the\n  endpoint that is remote to the primary subject of discussion.\n\nreceiver:\n: An endpoint that is receiving frames.\n\nsender:\n: An endpoint that is transmitting frames.\n\nserver:\n: The endpoint that accepts an HTTP/3 connection.  Servers receive HTTP requests\n  and send HTTP responses.\n\nstream:\n: A bidirectional or unidirectional bytestream provided by the QUIC transport.\n  All streams within an HTTP/3 connection can be considered \"HTTP/3 streams\",\n  but multiple stream types are defined within HTTP/3.\n\nstream error:\n: An application-level error on the individual stream.\n\nThe term \"content\" is defined in {{Section 6.4 of RFC9110}}.\n\nFinally, the terms \"resource\", \"message\", \"user agent\", \"origin server\",\n\"gateway\", \"intermediary\", \"proxy\", and \"tunnel\" are defined in {{Section 3 of\nRFC9110}}.\n\nPacket diagrams in this document use the format defined in\n{{Section 1.3 of QUIC-TRANSPORT}} to illustrate the order and size of fields.\n\n*[malformed]: #\n\n# Connection Setup and Management {#connection-setup}\n\n## Discovering an HTTP/3 Endpoint {#discovery}\n\nHTTP relies on the notion of an authoritative response: a response that has been\ndetermined to be the most appropriate response for that request given the state\nof the target resource at the time of response message origination by (or at the\ndirection of) the origin server identified within the target URI.  Locating an\nauthoritative server for an HTTP URI is discussed in {{Section 4.3 of RFC9110}}.\n\nThe \"https\" scheme associates authority with possession of a certificate that\nthe client considers to be trustworthy for the host identified by the authority\ncomponent of the URI.  Upon receiving a server certificate in the TLS handshake,\nthe client MUST verify that the certificate is an acceptable match for the URI's\norigin server using the process described in {{Section 4.3.4 of RFC9110}}. If\nthe certificate cannot be verified with respect to the URI's origin server, the\nclient MUST NOT consider the server authoritative for that origin.\n\nA client MAY attempt access to a resource with an \"https\" URI by resolving the\nhost identifier to an IP address, establishing a QUIC connection to that address\non the indicated port (including validation of the server certificate as\ndescribed above), and sending an HTTP/3 request message targeting the URI\nto the server over that secured connection.  Unless some other mechanism is used\nto select HTTP/3, the token \"h3\" is used in the Application-Layer Protocol\nNegotiation (ALPN; see {{!RFC7301}}) extension during the TLS handshake.\n\nConnectivity problems (e.g., blocking UDP) can result in a failure to establish\na QUIC connection; clients SHOULD attempt to use TCP-based versions of HTTP\nin this case.\n\nServers MAY serve HTTP/3 on any UDP port; an alternative service advertisement\nalways includes an explicit port, and URIs contain either an explicit port or a\ndefault port associated with the scheme.\n\n### HTTP Alternative Services {#alt-svc}\n\nAn HTTP origin can advertise the availability of an equivalent HTTP/3 endpoint\nvia the Alt-Svc HTTP response header field or the HTTP/2 ALTSVC frame\n({{?ALTSVC}}) using the \"h3\" ALPN token.\n\nFor example, an origin could indicate in an HTTP response that HTTP/3 was\navailable on UDP port 50781 at the same hostname by including the following\nheader field:\n\n~~~ http-message\nAlt-Svc: h3=\":50781\"\n~~~\n\nOn receipt of an Alt-Svc record indicating HTTP/3 support, a client MAY attempt\nto establish a QUIC connection to the indicated host and port; if this\nconnection is successful, the client can send HTTP requests using the mapping\ndescribed in this document.\n\n### Other Schemes\n\nAlthough HTTP is independent of the transport protocol, the \"http\" scheme\nassociates authority with the ability to receive TCP connections on the\nindicated port of whatever host is identified within the authority component.\nBecause HTTP/3 does not use TCP, HTTP/3 cannot be used for direct access to the\nauthoritative server for a resource identified by an \"http\" URI.  However,\nprotocol extensions such as {{?ALTSVC=RFC7838}} permit the authoritative server\nto identify other services that are also authoritative and that might be\nreachable over HTTP/3.\n\nPrior to making requests for an origin whose scheme is not \"https\", the client\nMUST ensure the server is willing to serve that scheme. For origins whose scheme\nis \"http\", an experimental method to accomplish this is described in\n{{?RFC8164}}. Other mechanisms might be defined for various schemes in the\nfuture.\n\n\n## Connection Establishment {#connection-establishment}\n\nHTTP/3 relies on QUIC version 1 as the underlying transport.  The use of other\nQUIC transport versions with HTTP/3 MAY be defined by future specifications.\n\nQUIC version 1 uses TLS version 1.3 or greater as its handshake protocol.\nHTTP/3 clients MUST support a mechanism to indicate the target host to the\nserver during the TLS handshake.  If the server is identified by a domain name\n({{?DNS-TERMS=RFC8499}}), clients MUST send the Server Name Indication (SNI;\n{{!RFC6066}}) TLS extension unless an alternative mechanism to indicate the\ntarget host is used.\n\nQUIC connections are established as described in {{QUIC-TRANSPORT}}. During\nconnection establishment, HTTP/3 support is indicated by selecting the ALPN\ntoken \"h3\" in the TLS handshake.  Support for other application-layer protocols\nMAY be offered in the same handshake.\n\nWhile connection-level options pertaining to the core QUIC protocol are set in\nthe initial crypto handshake, settings specific to HTTP/3 are conveyed in the\nSETTINGS frame. After the QUIC connection is established, a\nSETTINGS frame MUST be sent by each endpoint as the initial frame of their\nrespective HTTP control stream.\n\n## Connection Reuse\n\nHTTP/3 connections are persistent across multiple requests.  For best\nperformance, it is expected that clients will not close connections until it is\ndetermined that no further communication with a server is necessary (for\nexample, when a user navigates away from a particular web page) or until the\nserver closes the connection.\n\nOnce a connection to a server endpoint exists, this connection MAY be reused for\nrequests with multiple different URI authority components.  To use an existing\nconnection for a new origin, clients MUST validate the certificate presented by\nthe server for the new origin server using the process described in {{Section\n4.3.4 of RFC9110}}.  This implies that clients will need to retain the\nserver certificate and any additional information needed to verify that\ncertificate; clients that do not do so will be unable to reuse the connection\nfor additional origins.\n\nIf the certificate is not acceptable with regard to the new origin for any\nreason, the connection MUST NOT be reused and a new connection SHOULD be\nestablished for the new origin.  If the reason the certificate cannot be\nverified might apply to other origins already associated with the connection,\nthe client SHOULD revalidate the server certificate for those origins. For\ninstance, if validation of a certificate fails because the certificate has\nexpired or been revoked, this might be used to invalidate all other origins for\nwhich that certificate was used to establish authority.\n\nClients SHOULD NOT open more than one HTTP/3 connection to a given IP address\nand UDP port, where the IP address and port might be derived from a URI, a\nselected alternative service ({{!ALTSVC}}), a configured proxy, or name\nresolution of any of these. A client MAY open multiple HTTP/3 connections to the\nsame IP address and UDP port using different transport or TLS configurations but\nSHOULD avoid creating multiple connections with the same configuration.\n\nServers are encouraged to maintain open HTTP/3 connections for as long as\npossible but are permitted to terminate idle connections if necessary.  When\neither endpoint chooses to close the HTTP/3 connection, the terminating endpoint\nSHOULD first send a GOAWAY frame ({{connection-shutdown}}) so that both\nendpoints can reliably determine whether previously sent frames have been\nprocessed and gracefully complete or terminate any necessary remaining tasks.\n\nA server that does not wish clients to reuse HTTP/3 connections for a particular\norigin can indicate that it is not authoritative for a request by sending a 421\n(Misdirected Request) status code in response to the request; see {{Section 7.4\nof RFC9110}}.\n\n\n# Expressing HTTP Semantics in HTTP/3 {#http-request-lifecycle}\n\n## HTTP Message Framing {#request-response}\n\nA client sends an HTTP request on a request stream, which is a client-initiated\nbidirectional QUIC stream; see {{request-streams}}.  A client MUST send only a\nsingle request on a given stream.  A server sends zero or more interim HTTP\nresponses on the same stream as the request, followed by a single final HTTP\nresponse, as detailed below. See {{Section 15 of RFC9110}} for a description\nof interim and final HTTP responses.\n\nPushed responses are sent on a server-initiated unidirectional QUIC stream; see\n{{push-streams}}.  A server sends zero or more interim HTTP responses, followed\nby a single final HTTP response, in the same manner as a standard response.\nPush is described in more detail in {{server-push}}.\n\nOn a given stream, receipt of multiple requests or receipt of an additional HTTP\nresponse following a final HTTP response MUST be treated as malformed.\n\nAn HTTP message (request or response) consists of:\n\n1. the header section, including message control data, sent as a single HEADERS\n   frame,\n\n2. optionally, the content, if present, sent as a series of DATA frames, and\n\n3. optionally, the trailer section, if present, sent as a single HEADERS frame.\n\nHeader and trailer sections are described in {{Sections 6.3 and 6.5 of\nRFC9110}}; the content is described in {{Section 6.4 of RFC9110}}.\n\nReceipt of an invalid sequence of frames MUST be treated as a connection error\nof type H3_FRAME_UNEXPECTED.  In particular, a DATA frame before\nany HEADERS frame, or a HEADERS or DATA frame after the trailing HEADERS frame,\nis considered invalid.  Other frame types, especially unknown frame types,\nmight be permitted subject to their own rules; see {{extensions}}.\n\nA server MAY send one or more PUSH_PROMISE frames\nbefore, after, or interleaved with the frames of a response message. These\nPUSH_PROMISE frames are not part of the response; see {{server-push}} for more\ndetails.  PUSH_PROMISE frames are not permitted on push streams; a pushed\nresponse that includes PUSH_PROMISE frames MUST be treated as a connection error\nof type H3_FRAME_UNEXPECTED.\n\nFrames of unknown types ({{extensions}}), including reserved frames\n({{frame-reserved}}) MAY be sent on a request or push stream before, after, or\ninterleaved with other frames described in this section.\n\nThe HEADERS and PUSH_PROMISE frames might reference updates to the QPACK dynamic\ntable. While these updates are not directly part of the message exchange, they\nmust be received and processed before the message can be consumed.  See\n{{header-formatting}} for more details.\n\nTransfer codings (see {{Section 7 of RFC9112}}) are not defined for HTTP/3;\nthe Transfer-Encoding header field MUST NOT be used.\n\nA response MAY consist of multiple messages when and only when one or more\ninterim responses (1xx; see {{Section 15.2 of RFC9110}}) precede a final\nresponse to the same request.  Interim responses do not contain content\nor trailer sections.\n\nAn HTTP request/response exchange fully consumes a client-initiated\nbidirectional QUIC stream. After sending a request, a client MUST close the\nstream for sending.  Unless using the CONNECT method (see {{connect}}), clients\nMUST NOT make stream closure dependent on receiving a response to their request.\nAfter sending a final response, the server MUST close the stream for sending. At\nthis point, the QUIC stream is fully closed.\n\nWhen a stream is closed, this indicates the end of the final HTTP message.\nBecause some messages are large or unbounded, endpoints SHOULD begin processing\npartial HTTP messages once enough of the message has been received to make\nprogress.  If a client-initiated stream terminates without enough of the HTTP\nmessage to provide a complete response, the server SHOULD abort its response\nstream with the error code H3_REQUEST_INCOMPLETE.\n\nA server can send a complete response prior to the client sending an entire\nrequest if the response does not depend on any portion of the request that has\nnot been sent and received. When the server does not need to receive the\nremainder of the request, it MAY abort reading the request stream, send a\ncomplete response, and cleanly close the sending part of the stream.  The error\ncode H3_NO_ERROR SHOULD be used when requesting that the client stop sending on\nthe request stream.  Clients MUST NOT discard complete responses as a result of\nhaving their request terminated abruptly, though clients can always discard\nresponses at their discretion for other reasons.  If the server sends a partial\nor complete response but does not abort reading the request, clients SHOULD\ncontinue sending the content of the request and close the stream normally.\n\n### Request Cancellation and Rejection {#request-cancellation}\n\nOnce a request stream has been opened, the request MAY be cancelled by either\nendpoint.  Clients cancel requests if the response is no longer of interest;\nservers cancel requests if they are unable to or choose not to respond.  When\npossible, it is RECOMMENDED that servers send an HTTP response with an\nappropriate status code rather than cancelling a request it has already begun\nprocessing.\n\nImplementations SHOULD cancel requests by abruptly terminating any directions of\na stream that are still open.  To do so, an implementation resets the sending\nparts of streams and aborts reading on the receiving parts of streams; see\n{{Section 2.4 of QUIC-TRANSPORT}}.\n\nWhen the server cancels a request without performing any application processing,\nthe request is considered \"rejected\".  The server SHOULD abort its response\nstream with the error code H3_REQUEST_REJECTED. In this context, \"processed\"\nmeans that some data from the stream was passed to some higher layer of software\nthat might have taken some action as a result. The client can treat requests\nrejected by the server as though they had never been sent at all, thereby\nallowing them to be retried later.\n\nServers MUST NOT use the H3_REQUEST_REJECTED error code for requests that were\npartially or fully processed.  When a server abandons a response after partial\nprocessing, it SHOULD abort its response stream with the error code\nH3_REQUEST_CANCELLED.\n\nClient SHOULD use the error code H3_REQUEST_CANCELLED to cancel requests.  Upon\nreceipt of this error code, a server MAY abruptly terminate the response using\nthe error code H3_REQUEST_REJECTED if no processing was performed.  Clients MUST\nNOT use the H3_REQUEST_REJECTED error code, except when a server has requested\nclosure of the request stream with this error code.\n\nIf a stream is cancelled after receiving a complete response, the client MAY\nignore the cancellation and use the response.  However, if a stream is cancelled\nafter receiving a partial response, the response SHOULD NOT be used. Only\nidempotent actions such as GET, PUT, or DELETE can be safely retried; a client\nSHOULD NOT automatically retry a request with a non-idempotent method unless it\nhas some means to know that the request semantics are idempotent\nindependent of the method or some means to detect that the original request was\nnever applied.  See {{Section 9.2.2 of RFC9110}} for more details.\n\n### Malformed Requests and Responses {#malformed}\n\nA malformed request or response is one that is an otherwise valid sequence of\nframes but is invalid due to:\n\n- the presence of prohibited fields or pseudo-header fields,\n- the absence of mandatory pseudo-header fields,\n- invalid values for pseudo-header fields,\n- pseudo-header fields after fields,\n- an invalid sequence of HTTP messages,\n- the inclusion of uppercase field names, or\n- the inclusion of invalid characters in field names or values.\n\nA request or response that is defined as having content when it contains a\nContent-Length header field ({{Section 8.6 of RFC9110}}) is malformed if the\nvalue of the Content-Length header field does not equal the sum of the DATA\nframe lengths received. A response that is defined as never having content, even\nwhen a Content-Length is present, can have a non-zero Content-Length header\nfield even though no content is included in DATA frames.\n\nIntermediaries that process HTTP requests or responses (i.e., any intermediary\nnot acting as a tunnel) MUST NOT forward a malformed request or response.\nMalformed requests or responses that are detected MUST be treated as a stream\nerror of type H3_MESSAGE_ERROR.\n\nFor malformed requests, a server MAY send an HTTP response indicating the error\nprior to closing or resetting the stream.  Clients MUST NOT accept a malformed\nresponse.  Note that these requirements are intended to protect against several\ntypes of common attacks against HTTP; they are deliberately strict because being\npermissive can expose implementations to these vulnerabilities.\n\n\n## HTTP Fields {#header-formatting}\n\nHTTP messages carry metadata as a series of key-value pairs called \"HTTP\nfields\"; see {{Sections 6.3 and 6.5 of RFC9110}}. For a listing of registered\nHTTP fields, see the \"Hypertext Transfer Protocol (HTTP) Field Name Registry\"\nmaintained at [](https://www.iana.org/assignments/http-fields/){:\nbrackets=\"angle\"}.  Like HTTP/2, HTTP/3 has additional considerations related to\nthe use of characters in field names, the Connection header field, and\npseudo-header fields.\n\nField names are strings containing a subset of ASCII characters. Properties of\nHTTP field names and values are discussed in more detail in {{Section 5.1 of\nRFC9110}}. Characters in field names MUST be converted to lowercase prior to\ntheir encoding. A request or response containing uppercase characters in field\nnames MUST be treated as malformed.\n\nHTTP/3 does not use the Connection header field to indicate connection-specific\nfields; in this protocol, connection-specific metadata is conveyed by other\nmeans.  An endpoint MUST NOT generate an HTTP/3 field section containing\nconnection-specific fields; any message containing connection-specific fields\nMUST be treated as malformed.\n\nThe only exception to this is the TE header field, which MAY be present in an\nHTTP/3 request header; when it is, it MUST NOT contain any value other than\n\"trailers\".\n\nAn intermediary transforming an HTTP/1.x message to HTTP/3 MUST remove\nconnection-specific header fields as discussed in {{Section 7.6.1 of\nRFC9110}}, or their messages will be treated by other HTTP/3 endpoints as\nmalformed.\n\n### Field Compression\n\n{{RFC9204}} describes a variation of HPACK that gives an encoder some control\nover how much head-of-line blocking can be caused by compression.  This allows\nan encoder to balance compression efficiency with latency.  HTTP/3 uses QPACK to\ncompress header and trailer sections, including the control data present in the\nheader section.\n\nTo allow for better compression efficiency, the Cookie header field\n({{!COOKIES=RFC6265}}) MAY be split into separate field lines, each with one or\nmore cookie-pairs, before compression. If a decompressed field section contains\nmultiple cookie field lines, these MUST be concatenated into a single byte\nstring using the two-byte delimiter of `; ` (ASCII 0x3b, 0x20) before being\npassed into a context other than HTTP/2 or HTTP/3, such as an HTTP/1.1\nconnection, or a generic HTTP server application.\n\n### Header Size Constraints\n\nAn HTTP/3 implementation MAY impose a limit on the maximum size of the message\nheader it will accept on an individual HTTP message.  A server that receives a\nlarger header section than it is willing to handle can send an HTTP 431 (Request\nHeader Fields Too Large) status code ({{?RFC6585}}).  A client can discard\nresponses that it cannot process.  The size of a field list is calculated based\non the uncompressed size of fields, including the length of the name and value\nin bytes plus an overhead of 32 bytes for each field.\n\nIf an implementation wishes to advise its peer of this limit, it can be conveyed\nas a number of bytes in the SETTINGS_MAX_FIELD_SECTION_SIZE parameter. An\nimplementation that has received this parameter SHOULD NOT send an HTTP message\nheader that exceeds the indicated size, as the peer will likely refuse to\nprocess it.  However, an HTTP message can traverse one or more intermediaries\nbefore reaching the origin server; see {{Section 3.7 of RFC9110}}.  Because\nthis limit is applied separately by each implementation that processes the\nmessage, messages below this limit are not guaranteed to be accepted.\n\n## HTTP Control Data\n\nLike HTTP/2, HTTP/3 employs a series of pseudo-header fields, where the field\nname begins with the `:` character (ASCII 0x3a).  These pseudo-header fields\nconvey message control data; see {{Section 6.2 of RFC9110}}.\n\nPseudo-header fields are not HTTP fields.  Endpoints MUST NOT generate\npseudo-header fields other than those defined in this document. However, an\nextension could negotiate a modification of this restriction; see\n{{extensions}}.\n\nPseudo-header fields are only valid in the context in which they are defined.\nPseudo-header fields defined for requests MUST NOT appear in responses;\npseudo-header fields defined for responses MUST NOT appear in requests.\nPseudo-header fields MUST NOT appear in trailer sections. Endpoints MUST treat a\nrequest or response that contains undefined or invalid pseudo-header fields as\nmalformed.\n\nAll pseudo-header fields MUST appear in the header section before regular header\nfields.  Any request or response that contains a pseudo-header field that\nappears in a header section after a regular header field MUST be treated as\nmalformed.\n\n### Request Pseudo-Header Fields\n\nThe following pseudo-header fields are defined for requests:\n\n  \":method\":\n\n  : Contains the HTTP method ({{Section 9 of RFC9110}})\n\n  \":scheme\":\n\n  : Contains the scheme portion of the target URI ({{Section 3.1 of URI}}).\n\n  : The :scheme pseudo-header is not restricted to URIs with scheme \"http\" and\n    \"https\". A proxy or gateway can translate requests for non-HTTP schemes,\n    enabling the use of HTTP to interact with non-HTTP services.\n\n  : See {{other-schemes}} for guidance on using a scheme other than \"https\".\n\n  \":authority\":\n\n  : Contains the authority portion of the target URI ({{Section 3.2 of URI}}).\n    The authority MUST NOT include the deprecated userinfo\n    subcomponent for URIs of scheme \"http\" or \"https\".\n\n  : To ensure that the HTTP/1.1 request line can be reproduced accurately, this\n    pseudo-header field MUST be omitted when translating from an HTTP/1.1\n    request that has a request target in a method-specific form; see {{Section\n    7.1 of RFC9110}}.  Clients that generate HTTP/3 requests directly SHOULD use\n    the :authority pseudo-header field instead of the Host header field. An\n    intermediary that converts an HTTP/3 request to HTTP/1.1 MUST create a Host\n    field if one is not present in a request by copying the value of the\n    :authority pseudo-header field.\n\n  \":path\":\n\n  : Contains the path and query parts of the target URI (the \"path-absolute\"\n    production and optionally a `?` character (ASCII 0x3f) followed by the\n    \"query\" production; see {{Sections 3.3 and 3.4 of URI}}.\n\n  : This pseudo-header field MUST NOT be empty for \"http\" or \"https\" URIs;\n    \"http\" or \"https\" URIs that do not contain a path component MUST include a\n    value of `/` (ASCII 0x2f).  An OPTIONS request that does not include a path\n    component includes the value `*` (ASCII 0x2a) for the :path pseudo-header\n    field; see {{Section 7.1 of RFC9110}}.\n\nAll HTTP/3 requests MUST include exactly one value for the :method, :scheme,\nand :path pseudo-header fields, unless the request is a CONNECT request; see\n{{connect}}.\n\nIf the :scheme pseudo-header field identifies a scheme that has a mandatory\nauthority component (including \"http\" and \"https\"), the request MUST contain\neither an :authority pseudo-header field or a Host header field.  If these\nfields are present, they MUST NOT be empty.  If both fields are present, they\nMUST contain the same value.  If the scheme does not have a mandatory authority\ncomponent and none is provided in the request target, the request MUST NOT\ncontain the :authority pseudo-header or Host header fields.\n\nAn HTTP request that omits mandatory pseudo-header fields or contains invalid\nvalues for those pseudo-header fields is malformed.\n\nHTTP/3 does not define a way to carry the version identifier that is included in\nthe HTTP/1.1 request line.  HTTP/3 requests implicitly have a protocol version\nof \"3.0\".\n\n### Response Pseudo-Header Fields\n\nFor responses, a single \":status\" pseudo-header field is defined that carries\nthe HTTP status code; see {{Section 15 of RFC9110}}.  This pseudo-header\nfield MUST be included in all responses; otherwise, the response is malformed\n(see {{malformed}}).\n\nHTTP/3 does not define a way to carry the version or reason phrase that is\nincluded in an HTTP/1.1 status line. HTTP/3 responses implicitly have a protocol\nversion of \"3.0\".\n\n\n## The CONNECT Method {#connect}\n\nThe CONNECT method requests that the recipient establish a tunnel to the\ndestination origin server identified by the request-target; see {{Section 9.3.6\nof RFC9110}}. It is primarily used with HTTP proxies to establish a TLS\nsession with an origin server for the purposes of interacting with \"https\"\nresources.\n\nIn HTTP/1.x, CONNECT is used to convert an entire HTTP connection into a tunnel\nto a remote host. In HTTP/2 and HTTP/3, the CONNECT method is used to establish\na tunnel over a single stream.\n\nA CONNECT request MUST be constructed as follows:\n\n- The :method pseudo-header field is set to \"CONNECT\"\n- The :scheme and :path pseudo-header fields are omitted\n- The :authority pseudo-header field contains the host and port to connect to\n  (equivalent to the authority-form of the request-target of CONNECT requests;\n  see {{Section 7.1 of RFC9110}}).\n\nThe request stream remains open at the end of the request to carry the data to\nbe transferred.  A CONNECT request that does not conform to these restrictions\nis malformed.\n\nA proxy that supports CONNECT establishes a TCP connection ({{!RFC0793}}) to the\nserver identified in the :authority pseudo-header field.  Once this connection\nis successfully established, the proxy sends a HEADERS frame containing a 2xx\nseries status code to the client, as defined in {{Section 15.3 of RFC9110}}.\n\nAll DATA frames on the stream correspond to data sent or received on the TCP\nconnection. The payload of any DATA frame sent by the client is transmitted by\nthe proxy to the TCP server; data received from the TCP server is packaged into\nDATA frames by the proxy. Note that the size and number of TCP segments is not\nguaranteed to map predictably to the size and number of HTTP DATA or QUIC STREAM\nframes.\n\nOnce the CONNECT method has completed, only DATA frames are permitted to be sent\non the stream.  Extension frames MAY be used if specifically permitted by the\ndefinition of the extension.  Receipt of any other known frame type MUST be\ntreated as a connection error of type H3_FRAME_UNEXPECTED.\n\nThe TCP connection can be closed by either peer. When the client ends the\nrequest stream (that is, the receive stream at the proxy enters the \"Data Recvd\"\nstate), the proxy will set the FIN bit on its connection to the TCP server. When\nthe proxy receives a packet with the FIN bit set, it will close the send stream\nthat it sends to the client. TCP connections that remain half closed in a\nsingle direction are not invalid, but are often handled poorly by servers, so\nclients SHOULD NOT close a stream for sending while they still expect to receive\ndata from the target of the CONNECT.\n\nA TCP connection error is signaled by abruptly terminating the stream. A proxy\ntreats any error in the TCP connection, which includes receiving a TCP segment\nwith the RST bit set, as a stream error of type H3_CONNECT_ERROR.\n\nCorrespondingly, if a proxy detects an error with the stream or the QUIC\nconnection, it MUST close the TCP connection.  If the proxy detects that the\nclient has reset the stream or aborted reading from the stream, it MUST close\nthe TCP connection.  If the stream is reset or reading is aborted by the client,\na proxy SHOULD perform the same operation on the other direction in order to\nensure that both directions of the stream are cancelled. In all these cases, if\nthe underlying TCP implementation permits it, the proxy SHOULD send a TCP\nsegment with the RST bit set.\n\nSince CONNECT creates a tunnel to an arbitrary server, proxies that support\nCONNECT SHOULD restrict its use to a set of known ports or a list of safe\nrequest targets; see {{Section 9.3.6 of RFC9110}} for more details.\n\n## HTTP Upgrade\n\nHTTP/3 does not support the HTTP Upgrade mechanism ({{Section 7.8 of\nRFC9110}}) or the 101 (Switching Protocols) informational status code\n({{Section 15.2.2 of RFC9110}}).\n\n## Server Push\n\nServer push is an interaction mode that permits a server to push a\nrequest-response exchange to a client in anticipation of the client making the\nindicated request.  This trades off network usage against a potential latency\ngain.  HTTP/3 server push is similar to what is described in\n{{Section 8.2 of RFC9113}}, but it uses different mechanisms.\n\nEach server push is assigned a unique push ID by the server.  The push ID is\nused to refer to the push in various contexts throughout the lifetime of the\nHTTP/3 connection.\n\nThe push ID space begins at zero and ends at a maximum value set by the\nMAX_PUSH_ID frame.  In particular, a server is not\nable to push until after the client sends a MAX_PUSH_ID frame.  A client sends\nMAX_PUSH_ID frames to control the number of pushes that a server can promise.  A\nserver SHOULD use push IDs sequentially, beginning from zero.  A client MUST\ntreat receipt of a push stream as a connection error of type H3_ID_ERROR\nwhen no MAX_PUSH_ID frame has been sent or when the stream\nreferences a push ID that is greater than the maximum push ID.\n\nThe push ID is used in one or more PUSH_PROMISE frames that carry the control\ndata and header fields of the request message.  These frames are sent on the\nrequest stream that generated the push.  This allows the server push to be\nassociated with a client request.  When the same push ID is promised on multiple\nrequest streams, the decompressed request field sections MUST contain the same\nfields in the same order, and both the name and the value in each field MUST be\nidentical.\n\nThe push ID is then included with the push stream that ultimately fulfills\nthose promises.  The push stream identifies the push ID of\nthe promise that it fulfills, then contains a response to the promised request\nas described in {{request-response}}.\n\nFinally, the push ID can be used in CANCEL_PUSH frames; see\n{{frame-cancel-push}}.  Clients use this frame to indicate they do not wish to\nreceive a promised resource.  Servers use this frame to indicate they will not\nbe fulfilling a previous promise.\n\nNot all requests can be pushed.  A server MAY push requests that have the\nfollowing properties:\n\n- cacheable; see {{Section 9.2.3 of RFC9110}}\n- safe; see {{Section 9.2.1 of RFC9110}}\n- does not include request content or a trailer section\n\nThe server MUST include a value in the :authority pseudo-header field for\nwhich the server is authoritative.  If the client has not yet validated the\nconnection for the origin indicated by the pushed request, it MUST perform the\nsame verification process it would do before sending a request for that origin\non the connection; see {{connection-reuse}}.  If this verification fails,\nthe client MUST NOT consider the server authoritative for that origin.\n\nClients SHOULD send a CANCEL_PUSH frame upon receipt of a PUSH_PROMISE frame\ncarrying a request that is not cacheable, is not known to be safe, that\nindicates the presence of request content, or for which it does not consider the\nserver authoritative.  Any corresponding responses MUST NOT be used or cached.\n\nEach pushed response is associated with one or more client requests.  The push\nis associated with the request stream on which the PUSH_PROMISE frame was\nreceived.  The same server push can be associated with additional client\nrequests using a PUSH_PROMISE frame with the same push ID on multiple request\nstreams.  These associations do not affect the operation of the protocol, but\nthey MAY be considered by user agents when deciding how to use pushed resources.\n\nOrdering of a PUSH_PROMISE frame in relation to certain parts of the response is\nimportant. The server SHOULD send PUSH_PROMISE frames prior to sending HEADERS\nor DATA frames that reference the promised responses.  This reduces the chance\nthat a client requests a resource that will be pushed by the server.\n\nDue to reordering, push stream data can arrive before the corresponding\nPUSH_PROMISE frame.  When a client receives a new push stream with an\nas-yet-unknown push ID, both the associated client request and the pushed\nrequest header fields are unknown.  The client can buffer the stream data in\nexpectation of the matching PUSH_PROMISE. The client can use stream flow control\n({{Section 4.1 of QUIC-TRANSPORT}}) to limit the amount of data a server may\ncommit to the pushed stream.  Clients SHOULD abort reading and discard data\nalready read from push streams if no corresponding PUSH_PROMISE frame is\nprocessed in a reasonable amount of time.\n\nPush stream data can also arrive after a client has cancelled a push. In this\ncase, the client can abort reading the stream with an error code of\nH3_REQUEST_CANCELLED. This asks the server not to transfer additional data and\nindicates that it will be discarded upon receipt.\n\nPushed responses that are cacheable (see {{Section 3 of RFC9111}}) can be\nstored by the client, if it implements an HTTP cache. Pushed responses are\nconsidered successfully validated on the origin server (e.g., if the \"no-cache\"\ncache response directive is present; see {{Section 5.2.2.4 of RFC9111}}) at the\ntime the pushed response is received.\n\nPushed responses that are not cacheable MUST NOT be stored by any HTTP cache.\nThey MAY be made available to the application separately.\n\n*[push ID]: #server-push\n\n# Connection Closure\n\nOnce established, an HTTP/3 connection can be used for many requests and\nresponses over time until the connection is closed.  Connection closure can\nhappen in any of several different ways.\n\n## Idle Connections\n\nEach QUIC endpoint declares an idle timeout during the handshake.  If the QUIC\nconnection remains idle (no packets received) for longer than this duration, the\npeer will assume that the connection has been closed.  HTTP/3 implementations\nwill need to open a new HTTP/3 connection for new requests if the existing\nconnection has been idle for longer than the idle timeout negotiated during the\nQUIC handshake, and they SHOULD do so if approaching the idle timeout; see\n{{Section 10.1 of QUIC-TRANSPORT}}.\n\nHTTP clients are expected to request that the transport keep connections open\nwhile there are responses outstanding for requests or server pushes, as\ndescribed in {{Section 10.1.2 of QUIC-TRANSPORT}}. If the client is not\nexpecting a response from the server, allowing an idle connection to time out is\npreferred over expending effort maintaining a connection that might not be\nneeded.  A gateway MAY maintain connections in anticipation of need rather than\nincur the latency cost of connection establishment to servers. Servers SHOULD\nNOT actively keep connections open.\n\n## Connection Shutdown\n\nEven when a connection is not idle, either endpoint can decide to stop using the\nconnection and initiate a graceful connection close.  Endpoints initiate the\ngraceful shutdown of an HTTP/3 connection by sending a GOAWAY frame. The GOAWAY\nframe contains an identifier that indicates to the receiver the range of\nrequests or pushes that were or might be processed in this connection.  The\nserver sends a client-initiated bidirectional stream ID; the client sends a push\nID.  Requests or pushes with the indicated identifier or greater are rejected\n({{request-cancellation}}) by the sender of the GOAWAY. This identifier MAY be\nzero if no requests or pushes were processed.\n\nThe information in the GOAWAY frame enables a client and server to agree on\nwhich requests or pushes were accepted prior to the shutdown of the HTTP/3\nconnection. Upon sending a GOAWAY frame, the endpoint SHOULD explicitly cancel\n(see Sections {{<request-cancellation}} and {{<frame-cancel-push}}) any requests\nor pushes that have identifiers greater than or equal to the one indicated, in\norder to clean up transport state for the affected streams. The endpoint SHOULD\ncontinue to do so as more requests or pushes arrive.\n\nEndpoints MUST NOT initiate new requests or promise new pushes on the connection\nafter receipt of a GOAWAY frame from the peer.  Clients MAY establish a new\nconnection to send additional requests.\n\nSome requests or pushes might already be in transit:\n\n  - Upon receipt of a GOAWAY frame, if the client has already sent requests with\n    a stream ID greater than or equal to the identifier contained in the GOAWAY\n    frame, those requests will not be processed.  Clients can safely retry\n    unprocessed requests on a different HTTP connection.  A client that is\n    unable to retry requests loses all requests that are in flight when the\n    server closes the connection.\n\n    Requests on stream IDs less than the stream ID in a GOAWAY frame from the\n    server might have been processed; their status cannot be known until a\n    response is received, the stream is reset individually, another GOAWAY is\n    received with a lower stream ID than that of the request in question,\n    or the connection terminates.\n\n    Servers MAY reject individual requests on streams below the indicated ID if\n    these requests were not processed.\n\n  - If a server receives a GOAWAY frame after having promised pushes with a push\n    ID greater than or equal to the identifier contained in the GOAWAY frame,\n    those pushes will not be accepted.\n\nServers SHOULD send a GOAWAY frame when the closing of a connection is known\nin advance, even if the advance notice is small, so that the remote peer can\nknow whether or not a request has been partially processed.  For example, if an\nHTTP client sends a POST at the same time that a server closes a QUIC\nconnection, the client cannot know if the server started to process that POST\nrequest if the server does not send a GOAWAY frame to indicate what streams it\nmight have acted on.\n\nAn endpoint MAY send multiple GOAWAY frames indicating different identifiers,\nbut the identifier in each frame MUST NOT be greater than the identifier in any\nprevious frame, since clients might already have retried unprocessed requests on\nanother HTTP connection.  Receiving a GOAWAY containing a larger identifier than\npreviously received MUST be treated as a connection error of type H3_ID_ERROR.\n\nAn endpoint that is attempting to gracefully shut down a connection can send a\nGOAWAY frame with a value set to the maximum possible value (2<sup>62</sup>-4\nfor servers, 2<sup>62</sup>-1 for clients). This ensures that the peer stops\ncreating new requests or pushes. After allowing time for any in-flight requests\nor pushes to arrive, the endpoint can send another GOAWAY frame indicating which\nrequests or pushes it might accept before the end of the connection. This\nensures that a connection can be cleanly shut down without losing requests.\n\nA client has more flexibility in the value it chooses for the Push ID field in a\nGOAWAY that it sends.  A value of 2<sup>62</sup>-1 indicates that the server can\ncontinue fulfilling pushes that have already been promised. A smaller value\nindicates the client will reject pushes with push IDs greater than or equal to\nthis value.  Like the server, the client MAY send subsequent GOAWAY frames so\nlong as the specified push ID is no greater than any previously sent value.\n\nEven when a GOAWAY indicates that a given request or push will not be processed\nor accepted upon receipt, the underlying transport resources still exist.  The\nendpoint that initiated these requests can cancel them to clean up transport\nstate.\n\nOnce all accepted requests and pushes have been processed, the endpoint can\npermit the connection to become idle, or it MAY initiate an immediate closure of\nthe connection.  An endpoint that completes a graceful shutdown SHOULD use the\nH3_NO_ERROR error code when closing the connection.\n\nIf a client has consumed all available bidirectional stream IDs with requests,\nthe server need not send a GOAWAY frame, since the client is unable to make\nfurther requests.\n\n## Immediate Application Closure\n\nAn HTTP/3 implementation can immediately close the QUIC connection at any time.\nThis results in sending a QUIC CONNECTION_CLOSE frame to the peer indicating\nthat the application layer has terminated the connection.  The application error\ncode in this frame indicates to the peer why the connection is being closed.\nSee {{errors}} for error codes that can be used when closing a connection in\nHTTP/3.\n\nBefore closing the connection, a GOAWAY frame MAY be sent to allow the client to\nretry some requests.  Including the GOAWAY frame in the same packet as the QUIC\nCONNECTION_CLOSE frame improves the chances of the frame being received by\nclients.\n\nIf there are open streams that have not been explicitly closed, they are\nimplicitly closed when the connection is closed; see\n{{Section 10.2 of QUIC-TRANSPORT}}.\n\n## Transport Closure\n\nFor various reasons, the QUIC transport could indicate to the application layer\nthat the connection has terminated.  This might be due to an explicit closure\nby the peer, a transport-level error, or a change in network topology that\ninterrupts connectivity.\n\nIf a connection terminates without a GOAWAY frame, clients MUST assume that any\nrequest that was sent, whether in whole or in part, might have been processed.\n\n\n# Stream Mapping and Usage {#stream-mapping}\n\nA QUIC stream provides reliable in-order delivery of bytes, but makes no\nguarantees about order of delivery with regard to bytes on other streams. In\nversion 1 of QUIC, the stream data containing HTTP frames is carried by QUIC\nSTREAM frames, but this framing is invisible to the HTTP framing layer. The\ntransport layer buffers and orders received stream data, exposing a reliable\nbyte stream to the application. Although QUIC permits out-of-order delivery\nwithin a stream, HTTP/3 does not make use of this feature.\n\nQUIC streams can be either unidirectional, carrying data only from initiator to\nreceiver, or bidirectional, carrying data in both directions.  Streams can be\ninitiated by either the client or the server.  For more detail on QUIC streams,\nsee {{Section 2 of QUIC-TRANSPORT}}.\n\nWhen HTTP fields and data are sent over QUIC, the QUIC layer handles most of\nthe stream management.  HTTP does not need to do any separate multiplexing when\nusing QUIC: data sent over a QUIC stream always maps to a particular HTTP\ntransaction or to the entire HTTP/3 connection context.\n\n*[control stream]: #control-streams\n*[control streams]: #control-streams (((control stream)))\n*[push stream]: #push-streams\n*[push streams]: #push-streams (((push stream)))\n*[request stream]: #request-streams\n*[request streams]: #request-streams (((request stream)))\n\n## Bidirectional Streams {#request-streams}\n\nAll client-initiated bidirectional streams are used for HTTP requests and\nresponses.  A bidirectional stream ensures that the response can be readily\ncorrelated with the request.  These streams are referred to as request streams.\n\nThis means that the client's first request occurs on QUIC stream 0, with\nsubsequent requests on streams 4, 8, and so on. In order to permit these streams\nto open, an HTTP/3 server SHOULD configure non-zero minimum values for the\nnumber of permitted streams and the initial stream flow-control window.  So as\nto not unnecessarily limit parallelism, at least 100 request streams SHOULD be\npermitted at a time.\n\nHTTP/3 does not use server-initiated bidirectional streams, though an extension\ncould define a use for these streams.  Clients MUST treat receipt of a\nserver-initiated bidirectional stream as a connection error of type\nH3_STREAM_CREATION_ERROR unless such an extension has been\nnegotiated.\n\n## Unidirectional Streams\n\nUnidirectional streams, in either direction, are used for a range of purposes.\nThe purpose is indicated by a stream type, which is sent as a variable-length\ninteger at the start of the stream. The format and structure of data that\nfollows this integer is determined by the stream type.\n\n~~~~~~~~~~ ascii-art\nUnidirectional Stream Header {\n  Stream Type (i),\n}\n~~~~~~~~~~\n{: title=\"Unidirectional Stream Header\"}\n\nTwo stream types are defined in this document: control streams\n({{control-streams}}) and push streams ({{push-streams}}). {{RFC9204}} defines\ntwo additional stream types. Other stream types can be defined by extensions to\nHTTP/3; see {{extensions}} for more details. Some stream types are reserved\n({{stream-grease}}).\n\nThe performance of HTTP/3 connections in the early phase of their lifetime is\nsensitive to the creation and exchange of data on unidirectional streams.\nEndpoints that excessively restrict the number of streams or the flow-control\nwindow of these streams will increase the chance that the remote peer reaches\nthe limit early and becomes blocked. In particular, implementations should\nconsider that remote peers may wish to exercise reserved stream behavior\n({{stream-grease}}) with some of the unidirectional streams they are permitted\nto use.\n\nEach endpoint needs to create at least one unidirectional stream for the HTTP\ncontrol stream. QPACK requires two additional unidirectional streams, and other\nextensions might require further streams. Therefore, the transport parameters\nsent by both clients and servers MUST allow the peer to create at least three\nunidirectional streams. These transport parameters SHOULD also provide at least\n1,024 bytes of flow-control credit to each unidirectional stream.\n\nNote that an endpoint is not required to grant additional credits to create more\nunidirectional streams if its peer consumes all the initial credits before\ncreating the critical unidirectional streams. Endpoints SHOULD create the HTTP\ncontrol stream as well as the unidirectional streams required by mandatory\nextensions (such as the QPACK encoder and decoder streams) first, and then\ncreate additional streams as allowed by their peer.\n\nIf the stream header indicates a stream type that is not supported by the\nrecipient, the remainder of the stream cannot be consumed as the semantics are\nunknown. Recipients of unknown stream types MUST either abort reading of the\nstream or discard incoming data without further processing.  If reading is\naborted, the recipient SHOULD use the H3_STREAM_CREATION_ERROR error code or a\nreserved error code ({{http-error-codes}}). The recipient MUST NOT consider\nunknown stream types to be a connection error of any kind.\n\nAs certain stream types can affect connection state, a recipient SHOULD NOT\ndiscard data from incoming unidirectional streams prior to reading the stream\ntype.\n\nImplementations MAY send stream types before knowing whether the peer supports\nthem.  However, stream types that could modify the state or semantics of\nexisting protocol components, including QPACK or other extensions, MUST NOT be\nsent until the peer is known to support them.\n\nA sender can close or reset a unidirectional stream unless otherwise specified.\nA receiver MUST tolerate unidirectional streams being closed or reset prior to\nthe reception of the unidirectional stream header.\n\n### Control Streams\n\nA control stream is indicated by a stream type of 0x00.  Data on this stream\nconsists of HTTP/3 frames, as defined in {{frames}}.\n\nEach side MUST initiate a single control stream at the beginning of the\nconnection and send its SETTINGS frame as the first frame on this stream.  If\nthe first frame of the control stream is any other frame type, this MUST be\ntreated as a connection error of type H3_MISSING_SETTINGS. Only one control\nstream per peer is permitted; receipt of a second stream claiming to be a\ncontrol stream MUST be treated as a connection error of type\nH3_STREAM_CREATION_ERROR.  The sender MUST NOT close the control stream, and the\nreceiver MUST NOT request that the sender close the control stream.  If either\ncontrol stream is closed at any point, this MUST be treated as a connection\nerror of type H3_CLOSED_CRITICAL_STREAM.  Connection errors are described in\n{{errors}}.\n\nBecause the contents of the control stream are used to manage the behavior of\nother streams, endpoints SHOULD provide enough flow-control credit to keep the\npeer's control stream from becoming blocked.\n\nA pair of unidirectional streams is used rather than a single bidirectional\nstream.  This allows either peer to send data as soon as it is able.  Depending\non whether 0-RTT is available on the QUIC connection, either client or server\nmight be able to send stream data first.\n\n### Push Streams\n\nServer push is an optional feature introduced in HTTP/2 that allows a server to\ninitiate a response before a request has been made.  See {{server-push}} for\nmore details.\n\nA push stream is indicated by a stream type of 0x01, followed by the push ID\nof the promise that it fulfills, encoded as a variable-length integer. The\nremaining data on this stream consists of HTTP/3 frames, as defined in\n{{frames}}, and fulfills a promised server push by zero or more interim HTTP\nresponses followed by a single final HTTP response, as defined in\n{{request-response}}.  Server push and push IDs are described in\n{{server-push}}.\n\nOnly servers can push; if a server receives a client-initiated push stream, this\nMUST be treated as a connection error of type H3_STREAM_CREATION_ERROR.\n\n~~~~~~~~~~ ascii-art\nPush Stream Header {\n  Stream Type (i) = 0x01,\n  Push ID (i),\n}\n~~~~~~~~~~\n{: title=\"Push Stream Header\"}\n\nA client SHOULD NOT abort reading on a push stream prior to reading the push\nstream header, as this could lead to disagreement between client and server on\nwhich push IDs have already been consumed.\n\nEach push ID MUST only be used once in a push stream header. If a client detects\nthat a push stream header includes a push ID that was used in another push\nstream header, the client MUST treat this as a connection error of type\nH3_ID_ERROR.\n\n### Reserved Stream Types {#stream-grease}\n\nStream types of the format `0x1f * N + 0x21` for non-negative integer values of\n`N` are reserved to exercise the requirement that unknown types be ignored.\nThese streams have no semantics, and they can be sent when application-layer\npadding is desired. They MAY also be sent on connections where no data is\ncurrently being transferred. Endpoints MUST NOT consider these streams to have\nany meaning upon receipt.\n\nThe payload and length of the stream are selected in any manner the sending\nimplementation chooses.  When sending a reserved stream type, the implementation\nMAY either terminate the stream cleanly or reset it.  When resetting the stream,\neither the H3_NO_ERROR error code or a reserved error code\n({{http-error-codes}}) SHOULD be used.\n\n\n# HTTP Framing Layer {#http-framing-layer}\n\nHTTP frames are carried on QUIC streams, as described in {{stream-mapping}}.\nHTTP/3 defines three stream types: control stream, request stream, and push\nstream. This section describes HTTP/3 frame formats and their permitted stream\ntypes; see {{stream-frame-mapping}} for an overview.  A comparison between\nHTTP/2 and HTTP/3 frames is provided in {{h2-frames}}.\n\n| Frame        | Control Stream | Request Stream | Push Stream | Section                |\n| ------------ | -------------- | -------------- | ----------- | ---------------------- |\n| DATA         | No             | Yes            | Yes         | {{frame-data}}         |\n| HEADERS      | No             | Yes            | Yes         | {{frame-headers}}      |\n| CANCEL_PUSH  | Yes            | No             | No          | {{frame-cancel-push}}  |\n| SETTINGS     | Yes (1)        | No             | No          | {{frame-settings}}     |\n| PUSH_PROMISE | No             | Yes            | No          | {{frame-push-promise}} |\n| GOAWAY       | Yes            | No             | No          | {{frame-goaway}}       |\n| MAX_PUSH_ID  | Yes            | No             | No          | {{frame-max-push-id}}  |\n| Reserved     | Yes            | Yes            | Yes         | {{frame-reserved}}     |\n{: #stream-frame-mapping title=\"HTTP/3 Frames and Stream Type Overview\"}\n\n*[DATA]: #frame-data\n*[HEADERS]: #frame-headers\n*[CANCEL_PUSH]: #frame-cancel-push\n*[SETTINGS]: #frame-settings\n*[PUSH_PROMISE]: #frame-push-promise\n*[GOAWAY]: #frame-goaway\n*[MAX_PUSH_ID]: #frame-max-push-id\n\nThe SETTINGS frame can only occur as the first frame of a Control stream; this\nis indicated in {{stream-frame-mapping}} with a (1).  Specific guidance\nis provided in the relevant section.\n\nNote that, unlike QUIC frames, HTTP/3 frames can span multiple packets.\n\n## Frame Layout\n\nAll frames have the following format:\n\n~~~~~~~~~~ ascii-art\nHTTP/3 Frame Format {\n  Type (i),\n  Length (i),\n  Frame Payload (..),\n}\n~~~~~~~~~~\n{: title=\"HTTP/3 Frame Format\"}\n\nA frame includes the following fields:\n\n  Type:\n  : A variable-length integer that identifies the frame type.\n\n  Length:\n  : A variable-length integer that describes the length in bytes of\n    the Frame Payload.\n\n  Frame Payload:\n  : A payload, the semantics of which are determined by the Type field.\n\nEach frame's payload MUST contain exactly the fields identified in its\ndescription.  A frame payload that contains additional bytes after the\nidentified fields or a frame payload that terminates before the end of the\nidentified fields MUST be treated as a connection error of type\nH3_FRAME_ERROR.  In particular, redundant length encodings MUST\nbe verified to be self-consistent; see {{frame-parsing}}.\n\nWhen a stream terminates cleanly, if the last frame on the stream was truncated,\nthis MUST be treated as a connection error of type H3_FRAME_ERROR. Streams that\nterminate abruptly may be reset at any point in a frame.\n\n## Frame Definitions {#frames}\n\n### DATA {#frame-data}\n\nDATA frames (type=0x00) convey arbitrary, variable-length sequences of bytes\nassociated with HTTP request or response content.\n\nDATA frames MUST be associated with an HTTP request or response.  If a DATA\nframe is received on a control stream, the recipient MUST respond with a\nconnection error of type H3_FRAME_UNEXPECTED.\n\n~~~~~~~~~~ ascii-art\nDATA Frame {\n  Type (i) = 0x00,\n  Length (i),\n  Data (..),\n}\n~~~~~~~~~~\n{: title=\"DATA Frame\"}\n\n### HEADERS {#frame-headers}\n\nThe HEADERS frame (type=0x01) is used to carry an HTTP field section that is\nencoded using QPACK. See {{RFC9204}} for more details.\n\n~~~~~~~~~~ ascii-art\nHEADERS Frame {\n  Type (i) = 0x01,\n  Length (i),\n  Encoded Field Section (..),\n}\n~~~~~~~~~~\n{: title=\"HEADERS Frame\"}\n\nHEADERS frames can only be sent on request streams or push streams.  If a\nHEADERS frame is received on a control stream, the recipient MUST respond with a\nconnection error of type H3_FRAME_UNEXPECTED.\n\n### CANCEL_PUSH {#frame-cancel-push}\n\nThe CANCEL_PUSH frame (type=0x03) is used to request cancellation of a server\npush prior to the push stream being received.  The CANCEL_PUSH frame identifies\na server push by push ID (see {{server-push}}), encoded as a variable-length\ninteger.\n\nWhen a client sends a CANCEL_PUSH frame, it is indicating that it does not wish\nto receive the promised resource.  The server SHOULD abort sending the resource,\nbut the mechanism to do so depends on the state of the corresponding push\nstream.  If the server has not yet created a push stream, it does not create\none.  If the push stream is open, the server SHOULD abruptly terminate that\nstream.  If the push stream has already ended, the server MAY still abruptly\nterminate the stream or MAY take no action.\n\nA server sends a CANCEL_PUSH frame to indicate that it will not be fulfilling a\npromise that was previously sent.  The client cannot expect the corresponding\npromise to be fulfilled, unless it has already received and processed the\npromised response. Regardless of whether a push stream has been opened, a server\nSHOULD send a CANCEL_PUSH frame when it determines that promise will not be\nfulfilled.  If a stream has already been opened, the server can abort sending on\nthe stream with an error code of H3_REQUEST_CANCELLED.\n\nSending a CANCEL_PUSH frame has no direct effect on the state of existing push\nstreams. A client SHOULD NOT send a CANCEL_PUSH frame when it has already\nreceived a corresponding push stream.  A push stream could arrive after a client\nhas sent a CANCEL_PUSH frame, because a server might not have processed the\nCANCEL_PUSH. The client SHOULD abort reading the stream with an error code of\nH3_REQUEST_CANCELLED.\n\nA CANCEL_PUSH frame is sent on the control stream.  Receiving a CANCEL_PUSH\nframe on a stream other than the control stream MUST be treated as a connection\nerror of type H3_FRAME_UNEXPECTED.\n\n~~~~~~~~~~ ascii-art\nCANCEL_PUSH Frame {\n  Type (i) = 0x03,\n  Length (i),\n  Push ID (i),\n}\n~~~~~~~~~~\n{: title=\"CANCEL_PUSH Frame\"}\n\nThe CANCEL_PUSH frame carries a push ID encoded as a variable-length integer.\nThe Push ID field identifies the server push that is being cancelled; see\n{{server-push}}.  If a CANCEL_PUSH frame is received that references a push ID\ngreater than currently allowed on the connection, this MUST be treated as a\nconnection error of type H3_ID_ERROR.\n\nIf the client receives a CANCEL_PUSH frame, that frame might identify a push ID\nthat has not yet been mentioned by a PUSH_PROMISE frame due to reordering.  If a\nserver receives a CANCEL_PUSH frame for a push ID that has not yet been\nmentioned by a PUSH_PROMISE frame, this MUST be treated as a connection error of\ntype H3_ID_ERROR.\n\n\n### SETTINGS {#frame-settings}\n\nThe SETTINGS frame (type=0x04) conveys configuration parameters that affect how\nendpoints communicate, such as preferences and constraints on peer behavior.\nIndividually, a SETTINGS parameter can also be referred to as a \"setting\"; the\nidentifier and value of each setting parameter can be referred to as a \"setting\nidentifier\" and a \"setting value\".\n\nSETTINGS frames always apply to an entire HTTP/3 connection, never a single\nstream.  A SETTINGS frame MUST be sent as the first frame of each control stream\n(see {{control-streams}}) by each peer, and it MUST NOT be sent subsequently. If\nan endpoint receives a second SETTINGS frame on the control stream, the endpoint\nMUST respond with a connection error of type H3_FRAME_UNEXPECTED.\n\nSETTINGS frames MUST NOT be sent on any stream other than the control stream.\nIf an endpoint receives a SETTINGS frame on a different stream, the endpoint\nMUST respond with a connection error of type H3_FRAME_UNEXPECTED.\n\nSETTINGS parameters are not negotiated; they describe characteristics of the\nsending peer that can be used by the receiving peer. However, a negotiation\ncan be implied by the use of SETTINGS: each peer uses SETTINGS to advertise a\nset of supported values. The definition of the setting would describe how each\npeer combines the two sets to conclude which choice will be used.  SETTINGS does\nnot provide a mechanism to identify when the choice takes effect.\n\nDifferent values for the same parameter can be advertised by each peer. For\nexample, a client might be willing to consume a very large response field\nsection, while servers are more cautious about request size.\n\nThe same setting identifier MUST NOT occur more than once in the SETTINGS frame.\nA receiver MAY treat the presence of duplicate setting identifiers as a\nconnection error of type H3_SETTINGS_ERROR.\n\nThe payload of a SETTINGS frame consists of zero or more parameters.  Each\nparameter consists of a setting identifier and a value, both encoded as QUIC\nvariable-length integers.\n\n~~~~~~~~~~~~~~~ ascii-art\nSetting {\n  Identifier (i),\n  Value (i),\n}\n\nSETTINGS Frame {\n  Type (i) = 0x04,\n  Length (i),\n  Setting (..) ...,\n}\n~~~~~~~~~~~~~~~\n{: title=\"SETTINGS Frame\"}\n\nAn implementation MUST ignore any parameter with an identifier it does\nnot understand.\n\n\n#### Defined SETTINGS Parameters {#settings-parameters}\n\nThe following settings are defined in HTTP/3:\n\n  SETTINGS_MAX_FIELD_SECTION_SIZE (0x06):\n  : The default value is unlimited.  See {{header-size-constraints}} for usage.\n    {: anchor=\"SETTINGS_MAX_FIELD_SECTION_SIZE\"}\n\n*[SETTINGS_MAX_FIELD_SECTION_SIZE]: #\n\nSetting identifiers of the format `0x1f * N + 0x21` for non-negative integer\nvalues of `N` are reserved to exercise the requirement that unknown identifiers\nbe ignored.  Such settings have no defined meaning. Endpoints SHOULD include at\nleast one such setting in their SETTINGS frame. Endpoints MUST NOT consider such\nsettings to have any meaning upon receipt.\n\nBecause the setting has no defined meaning, the value of the setting can be any\nvalue the implementation selects.\n\nSetting identifiers that were defined in {{RFC9113}} where there is no\ncorresponding HTTP/3 setting have also been reserved ({{iana-settings}}). These\nreserved settings MUST NOT be sent, and their receipt MUST be treated as a\nconnection error of type H3_SETTINGS_ERROR.\n\nAdditional settings can be defined by extensions to HTTP/3; see {{extensions}}\nfor more details.\n\n#### Initialization {#settings-initialization}\n\nAn HTTP implementation MUST NOT send frames or requests that would be invalid\nbased on its current understanding of the peer's settings.\n\nAll settings begin at an initial value.  Each endpoint SHOULD use these initial\nvalues to send messages before the peer's SETTINGS frame has arrived, as packets\ncarrying the settings can be lost or delayed.  When the SETTINGS frame arrives,\nany settings are changed to their new values.\n\nThis removes the need to wait for the SETTINGS frame before sending messages.\nEndpoints MUST NOT require any data to be received from the peer prior to\nsending the SETTINGS frame; settings MUST be sent as soon as the transport is\nready to send data.\n\nFor servers, the initial value of each client setting is the default value.\n\nFor clients using a 1-RTT QUIC connection, the initial value of each server\nsetting is the default value.  1-RTT keys will always become available prior to\nthe packet containing SETTINGS being processed by QUIC, even if the server sends\nSETTINGS immediately.  Clients SHOULD NOT wait indefinitely for SETTINGS to\narrive before sending requests, but they SHOULD process received datagrams in\norder to increase the likelihood of processing SETTINGS before sending the first\nrequest.\n\nWhen a 0-RTT QUIC connection is being used, the initial value of each server\nsetting is the value used in the previous session. Clients SHOULD store the\nsettings the server provided in the HTTP/3 connection where resumption\ninformation was provided, but they MAY opt not to store settings in certain\ncases (e.g., if the session ticket is received before the SETTINGS frame). A\nclient MUST comply with stored settings -- or default values if no values are\nstored -- when attempting 0-RTT. Once a server has provided new settings,\nclients MUST comply with those values.\n\nA server can remember the settings that it advertised or store an\nintegrity-protected copy of the values in the ticket and recover the information\nwhen accepting 0-RTT data. A server uses the HTTP/3 settings values in\ndetermining whether to accept 0-RTT data.  If the server cannot determine that\nthe settings remembered by a client are compatible with its current settings, it\nMUST NOT accept 0-RTT data.  Remembered settings are compatible if a client\ncomplying with those settings would not violate the server's current settings.\n\nA server MAY accept 0-RTT and subsequently provide different settings in its\nSETTINGS frame. If 0-RTT data is accepted by the server, its SETTINGS frame MUST\nNOT reduce any limits or alter any values that might be violated by the client\nwith its 0-RTT data.  The server MUST include all settings that differ from\ntheir default values.  If a server accepts 0-RTT but then sends settings that\nare not compatible with the previously specified settings, this MUST be treated\nas a connection error of type H3_SETTINGS_ERROR. If a server accepts 0-RTT but\nthen sends a SETTINGS frame that omits a setting value that the client\nunderstands (apart from reserved setting identifiers) that was previously\nspecified to have a non-default value, this MUST be treated as a connection\nerror of type H3_SETTINGS_ERROR.\n\n\n### PUSH_PROMISE {#frame-push-promise}\n\nThe PUSH_PROMISE frame (type=0x05) is used to carry a promised request header\nsection from server to client on a request stream.\n\n~~~~~~~~~~ ascii-art\nPUSH_PROMISE Frame {\n  Type (i) = 0x05,\n  Length (i),\n  Push ID (i),\n  Encoded Field Section (..),\n}\n~~~~~~~~~~\n{: title=\"PUSH_PROMISE Frame\"}\n\nThe payload consists of:\n\nPush ID:\n: A variable-length integer that identifies the server push operation.  A push\n  ID is used in push stream headers ({{server-push}}) and CANCEL_PUSH frames.\n\nEncoded Field Section:\n: QPACK-encoded request header fields for the promised response.  See\n  {{RFC9204}} for more details.\n\nA server MUST NOT use a push ID that is larger than the client has provided in a\nMAX_PUSH_ID frame ({{frame-max-push-id}}). A client MUST treat receipt of a\nPUSH_PROMISE frame that contains a larger push ID than the client has advertised\nas a connection error of H3_ID_ERROR.\n\nA server MAY use the same push ID in multiple PUSH_PROMISE frames. If so, the\ndecompressed request header sets MUST contain the same fields in the same order,\nand both the name and the value in each field MUST be exact matches. Clients\nSHOULD compare the request header sections for resources promised multiple\ntimes. If a client receives a push ID that has already been promised and detects\na mismatch, it MUST respond with a connection error of type\nH3_GENERAL_PROTOCOL_ERROR. If the decompressed field sections match exactly, the\nclient SHOULD associate the pushed content with each stream on which a\nPUSH_PROMISE frame was received.\n\nAllowing duplicate references to the same push ID is primarily to reduce\nduplication caused by concurrent requests.  A server SHOULD avoid reusing a push\nID over a long period.  Clients are likely to consume server push responses and\nnot retain them for reuse over time.  Clients that see a PUSH_PROMISE frame that\nuses a push ID that they have already consumed and discarded are forced to\nignore the promise.\n\nIf a PUSH_PROMISE frame is received on the control stream, the client MUST\nrespond with a connection error of type H3_FRAME_UNEXPECTED.\n\nA client MUST NOT send a PUSH_PROMISE frame.  A server MUST treat the receipt of\na PUSH_PROMISE frame as a connection error of type H3_FRAME_UNEXPECTED.\n\nSee {{server-push}} for a description of the overall server push mechanism.\n\n### GOAWAY {#frame-goaway}\n\nThe GOAWAY frame (type=0x07) is used to initiate graceful shutdown of an HTTP/3\nconnection by either endpoint.  GOAWAY allows an endpoint to stop accepting new\nrequests or pushes while still finishing processing of previously received\nrequests and pushes.  This enables administrative actions, like server\nmaintenance.  GOAWAY by itself does not close a connection.\n\n~~~~~~~~~~ ascii-art\nGOAWAY Frame {\n  Type (i) = 0x07,\n  Length (i),\n  Stream ID/Push ID (i),\n}\n~~~~~~~~~~\n{: title=\"GOAWAY Frame\"}\n\nThe GOAWAY frame is always sent on the control stream.  In the server-to-client\ndirection, it carries a QUIC stream ID for a client-initiated bidirectional\nstream encoded as a variable-length integer.  A client MUST treat receipt of a\nGOAWAY frame containing a stream ID of any other type as a connection error of\ntype H3_ID_ERROR.\n\nIn the client-to-server direction, the GOAWAY frame carries a push ID encoded as\na variable-length integer.\n\nThe GOAWAY frame applies to the entire connection, not a specific stream.  A\nclient MUST treat a GOAWAY frame on a stream other than the control stream as a\nconnection error of type H3_FRAME_UNEXPECTED.\n\nSee {{connection-shutdown}} for more information on the use of the GOAWAY frame.\n\n### MAX_PUSH_ID {#frame-max-push-id}\n\nThe MAX_PUSH_ID frame (type=0x0d) is used by clients to control the number of\nserver pushes that the server can initiate.  This sets the maximum value for a\npush ID that the server can use in PUSH_PROMISE and CANCEL_PUSH frames.\nConsequently, this also limits the number of push streams that the server can\ninitiate in addition to the limit maintained by the QUIC transport.\n\nThe MAX_PUSH_ID frame is always sent on the control stream.  Receipt of a\nMAX_PUSH_ID frame on any other stream MUST be treated as a connection error of\ntype H3_FRAME_UNEXPECTED.\n\nA server MUST NOT send a MAX_PUSH_ID frame.  A client MUST treat the receipt of\na MAX_PUSH_ID frame as a connection error of type H3_FRAME_UNEXPECTED.\n\nThe maximum push ID is unset when an HTTP/3 connection is created, meaning that\na server cannot push until it receives a MAX_PUSH_ID frame.  A client that\nwishes to manage the number of promised server pushes can increase the maximum\npush ID by sending MAX_PUSH_ID frames as the server fulfills or cancels server\npushes.\n\n~~~~~~~~~~ ascii-art\nMAX_PUSH_ID Frame {\n  Type (i) = 0x0d,\n  Length (i),\n  Push ID (i),\n}\n~~~~~~~~~~\n{: title=\"MAX_PUSH_ID Frame\"}\n\nThe MAX_PUSH_ID frame carries a single variable-length integer that identifies\nthe maximum value for a push ID that the server can use; see {{server-push}}.  A\nMAX_PUSH_ID frame cannot reduce the maximum push ID; receipt of a MAX_PUSH_ID\nframe that contains a smaller value than previously received MUST be treated as\na connection error of type H3_ID_ERROR.\n\n### Reserved Frame Types {#frame-reserved}\n\nFrame types of the format `0x1f * N + 0x21` for non-negative integer values of\n`N` are reserved to exercise the requirement that unknown types be ignored\n({{extensions}}).  These frames have no semantics, and they MAY be sent on any\nstream where frames are allowed to be sent. This enables their use for\napplication-layer padding.  Endpoints MUST NOT consider these frames to have any\nmeaning upon receipt.\n\nThe payload and length of the frames are selected in any manner the\nimplementation chooses.\n\nFrame types that were used in HTTP/2 where there is no corresponding HTTP/3\nframe have also been reserved ({{iana-frames}}).  These frame types MUST NOT be\nsent, and their receipt MUST be treated as a connection error of type\nH3_FRAME_UNEXPECTED.\n\n\n# Error Handling {#errors}\n\nWhen a stream cannot be completed successfully, QUIC allows the application to\nabruptly terminate (reset) that stream and communicate a reason; see {{Section\n2.4 of QUIC-TRANSPORT}}. This is referred to as a \"stream error\". An HTTP/3\nimplementation can decide to close a QUIC stream and communicate the type of\nerror. Wire encodings of error codes are defined in {{http-error-codes}}.\nStream errors are distinct from HTTP status codes that indicate error\nconditions. Stream errors indicate that the sender did not transfer or consume\nthe full request or response, while HTTP status codes indicate the result of a\nrequest that was successfully received.\n\nIf an entire connection needs to be terminated, QUIC similarly provides\nmechanisms to communicate a reason; see {{Section 5.3 of QUIC-TRANSPORT}}.  This\nis referred to as a \"connection error\".  Similar to stream errors, an HTTP/3\nimplementation can terminate a QUIC connection and communicate the reason using\nan error code from {{http-error-codes}}.\n\nAlthough the reasons for closing streams and connections are called \"errors\",\nthese actions do not necessarily indicate a problem with the connection or\neither implementation. For example, a stream can be reset if the requested\nresource is no longer needed.\n\nAn endpoint MAY choose to treat a stream error as a connection error under\ncertain circumstances, closing the entire connection in response to a condition\non a single stream.  Implementations need to consider the impact on outstanding\nrequests before making this choice.\n\nBecause new error codes can be defined without negotiation (see {{extensions}}),\nuse of an error code in an unexpected context or receipt of an unknown error\ncode MUST be treated as equivalent to H3_NO_ERROR.  However, closing a stream\ncan have other effects regardless of the error code; for example, see\n{{request-response}}.\n\n*[stream error]: #errors\n*[stream errors]: #errors (((stream error)))\n*[connection error]: #errors\n*[connection errors]: #errors (((connection error)))\n\n## HTTP/3 Error Codes {#http-error-codes}\n\nThe following error codes are defined for use when abruptly terminating streams,\naborting reading of streams, or immediately closing HTTP/3 connections.\n\nH3_NO_ERROR (0x0100):\n: No error.  This is used when the connection or stream needs to be closed, but\n  there is no error to signal.\n  {: anchor=\"H3_NO_ERROR\"}\n\nH3_GENERAL_PROTOCOL_ERROR (0x0101):\n: Peer violated protocol requirements in a way that does not match a more\n  specific error code or endpoint declines to use the more specific error code.\n  {: anchor=\"H3_GENERAL_PROTOCOL_ERROR\"}\n\nH3_INTERNAL_ERROR (0x0102):\n: An internal error has occurred in the HTTP stack.\n  {: anchor=\"H3_INTERNAL_ERROR\"}\n\nH3_STREAM_CREATION_ERROR (0x0103):\n: The endpoint detected that its peer created a stream that it will not accept.\n  {: anchor=\"H3_STREAM_CREATION_ERROR\"}\n\nH3_CLOSED_CRITICAL_STREAM (0x0104):\n: A stream required by the HTTP/3 connection was closed or reset.\n  {: anchor=\"H3_CLOSED_CRITICAL_STREAM\"}\n\nH3_FRAME_UNEXPECTED (0x0105):\n: A frame was received that was not permitted in the current state or on the\n  current stream.\n  {: anchor=\"H3_FRAME_UNEXPECTED\"}\n\nH3_FRAME_ERROR (0x0106):\n: A frame that fails to satisfy layout requirements or with an invalid size\n  was received.\n  {: anchor=\"H3_FRAME_ERROR\"}\n\nH3_EXCESSIVE_LOAD (0x0107):\n: The endpoint detected that its peer is exhibiting a behavior that might be\n  generating excessive load.\n  {: anchor=\"H3_EXCESSIVE_LOAD\"}\n\nH3_ID_ERROR (0x0108):\n: A stream ID or push ID was used incorrectly, such as exceeding a limit,\n  reducing a limit, or being reused.\n  {: anchor=\"H3_ID_ERROR\"}\n\nH3_SETTINGS_ERROR (0x0109):\n: An endpoint detected an error in the payload of a SETTINGS frame.\n  {: anchor=\"H3_SETTINGS_ERROR\"}\n\nH3_MISSING_SETTINGS (0x010a):\n: No SETTINGS frame was received at the beginning of the control stream.\n  {: anchor=\"H3_MISSING_SETTINGS\"}\n\nH3_REQUEST_REJECTED (0x010b):\n: A server rejected a request without performing any application processing.\n  {: anchor=\"H3_REQUEST_REJECTED\"}\n\nH3_REQUEST_CANCELLED (0x010c):\n: The request or its response (including pushed response) is cancelled.\n  {: anchor=\"H3_REQUEST_CANCELLED\"}\n\nH3_REQUEST_INCOMPLETE (0x010d):\n: The client's stream terminated without containing a fully formed request.\n  {: anchor=\"H3_REQUEST_INCOMPLETE\"}\n\nH3_MESSAGE_ERROR (0x010e):\n: An HTTP message was malformed and cannot be processed.\n  {: anchor=\"H3_MESSAGE_ERROR\"}\n\nH3_CONNECT_ERROR (0x010f):\n: The TCP connection established in response to a CONNECT request was reset or\n  abnormally closed.\n  {: anchor=\"H3_CONNECT_ERROR\"}\n\nH3_VERSION_FALLBACK (0x0110):\n: The requested operation cannot be served over HTTP/3.  The peer should\n  retry over HTTP/1.1.\n  {: anchor=\"H3_VERSION_FALLBACK\"}\n\n*[H3_NO_ERROR]: #\n*[H3_GENERAL_PROTOCOL_ERROR]: #\n*[H3_INTERNAL_ERROR]: #\n*[H3_STREAM_CREATION_ERROR]: #\n*[H3_CLOSED_CRITICAL_STREAM]: #\n*[H3_FRAME_UNEXPECTED]: #\n*[H3_FRAME_ERROR]: #\n*[H3_EXCESSIVE_LOAD]: #\n*[H3_ID_ERROR]: #\n*[H3_SETTINGS_ERROR]: #\n*[H3_MISSING_SETTINGS]: #\n*[H3_REQUEST_REJECTED]: #\n*[H3_REQUEST_CANCELLED]: #\n*[H3_REQUEST_INCOMPLETE]: #\n*[H3_MESSAGE_ERROR]: #\n*[H3_CONNECT_ERROR]: #\n*[H3_VERSION_FALLBACK]: #\n\nError codes of the format `0x1f * N + 0x21` for non-negative integer values of\n`N` are reserved to exercise the requirement that unknown error codes be treated\nas equivalent to H3_NO_ERROR ({{extensions}}). Implementations SHOULD select an\nerror code from this space with some probability when they would have sent\nH3_NO_ERROR.\n\n# Extensions to HTTP/3 {#extensions}\n\nHTTP/3 permits extension of the protocol.  Within the limitations described in\nthis section, protocol extensions can be used to provide additional services or\nalter any aspect of the protocol.  Extensions are effective only within the\nscope of a single HTTP/3 connection.\n\nThis applies to the protocol elements defined in this document.  This does not\naffect the existing options for extending HTTP, such as defining new methods,\nstatus codes, or fields.\n\nExtensions are permitted to use new frame types ({{frames}}), new settings\n({{settings-parameters}}), new error codes ({{errors}}), or new unidirectional\nstream types ({{unidirectional-streams}}).  Registries are established for\nmanaging these extension points: frame types ({{iana-frames}}), settings\n({{iana-settings}}), error codes ({{iana-error-codes}}), and stream types\n({{iana-stream-types}}).\n\nImplementations MUST ignore unknown or unsupported values in all extensible\nprotocol elements.  Implementations MUST discard data or abort reading on\nunidirectional streams that have unknown or unsupported types.  This means that\nany of these extension points can be safely used by extensions without prior\narrangement or negotiation.  However, where a known frame type is required to be\nin a specific location, such as the SETTINGS frame as the first frame of the\ncontrol stream (see {{control-streams}}), an unknown frame type does not satisfy\nthat requirement and SHOULD be treated as an error.\n\nExtensions that could change the semantics of existing protocol components MUST\nbe negotiated before being used.  For example, an extension that changes the\nlayout of the HEADERS frame cannot be used until the peer has given a positive\nsignal that this is acceptable.  Coordinating when such a revised layout comes\ninto effect could prove complex.  As such, allocating new identifiers for\nnew definitions of existing protocol elements is likely to be more effective.\n\nThis document does not mandate a specific method for negotiating the use of an\nextension, but it notes that a setting ({{settings-parameters}}) could be used\nfor that purpose.  If both peers set a value that indicates willingness to use\nthe extension, then the extension can be used.  If a setting is used for\nextension negotiation, the default value MUST be defined in such a fashion that\nthe extension is disabled if the setting is omitted.\n\n\n# Security Considerations\n\nThe security considerations of HTTP/3 should be comparable to those of HTTP/2\nwith TLS.  However, many of the considerations from {{Section 10 of RFC9113}}\napply to {{QUIC-TRANSPORT}} and are discussed in that document.\n\n## Server Authority\n\nHTTP/3 relies on the HTTP definition of authority. The security considerations\nof establishing authority are discussed in {{Section 17.1 of RFC9110}}.\n\n## Cross-Protocol Attacks\n\nThe use of ALPN in the TLS and QUIC handshakes establishes the target\napplication protocol before application-layer bytes are processed.  This ensures\nthat endpoints have strong assurances that peers are using the same protocol.\n\nThis does not guarantee protection from all cross-protocol attacks. {{Section\n21.5 of QUIC-TRANSPORT}} describes some ways in which the plaintext of QUIC\npackets can be used to perform request forgery against endpoints that don't use\nauthenticated transports.\n\n## Intermediary-Encapsulation Attacks\n\nThe HTTP/3 field encoding allows the expression of names that are not valid\nfield names in the syntax used by HTTP ({{Section 5.1 of RFC9110}}). Requests or\nresponses containing invalid field names MUST be treated as malformed.\nTherefore, an intermediary cannot translate an HTTP/3 request or response\ncontaining an invalid field name into an HTTP/1.1 message.\n\nSimilarly, HTTP/3 can transport field values that are not valid. While most\nvalues that can be encoded will not alter field parsing, carriage return (ASCII\n0x0d), line feed (ASCII 0x0a), and the null character (ASCII 0x00) might be\nexploited by an attacker if they are translated verbatim. Any request or\nresponse that contains a character not permitted in a field value MUST be\ntreated as malformed.  Valid characters are defined by the\n\"field-content\" ABNF rule in {{Section 5.5 of RFC9110}}.\n\n## Cacheability of Pushed Responses\n\nPushed responses do not have an explicit request from the client; the request is\nprovided by the server in the PUSH_PROMISE frame.\n\nCaching responses that are pushed is possible based on the guidance provided by\nthe origin server in the Cache-Control header field. However, this can cause\nissues if a single server hosts more than one tenant.  For example, a server\nmight offer multiple users each a small portion of its URI space.\n\nWhere multiple tenants share space on the same server, that server MUST ensure\nthat tenants are not able to push representations of resources that they do not\nhave authority over.  Failure to enforce this would allow a tenant to provide a\nrepresentation that would be served out of cache, overriding the actual\nrepresentation that the authoritative tenant provides.\n\nClients are required to reject pushed responses for which an origin server is\nnot authoritative; see {{server-push}}.\n\n## Denial-of-Service Considerations\n\nAn HTTP/3 connection can demand a greater commitment of resources to operate\nthan an HTTP/1.1 or HTTP/2 connection.  The use of field compression and flow\ncontrol depend on a commitment of resources for storing a greater amount of\nstate.  Settings for these features ensure that memory commitments for these\nfeatures are strictly bounded.\n\nThe number of PUSH_PROMISE frames is constrained in a similar fashion.  A client\nthat accepts server push SHOULD limit the number of push IDs it issues at a\ntime.\n\nProcessing capacity cannot be guarded as effectively as state capacity.\n\nThe ability to send undefined protocol elements that the peer is required to\nignore can be abused to cause a peer to expend additional processing time.  This\nmight be done by setting multiple undefined SETTINGS parameters, unknown frame\ntypes, or unknown stream types.  Note, however, that some uses are entirely\nlegitimate, such as optional-to-understand extensions and padding to increase\nresistance to traffic analysis.\n\nCompression of field sections also offers some opportunities to waste processing\nresources; see {{Section 7 of RFC9204}} for more details on potential abuses.\n\nAll these features -- i.e., server push, unknown protocol elements, field\ncompression -- have legitimate uses.  These features become a burden only when\nthey are used unnecessarily or to excess.\n\nAn endpoint that does not monitor such behavior exposes itself to a risk of\ndenial-of-service attack.  Implementations SHOULD track the use of these\nfeatures and set limits on their use.  An endpoint MAY treat activity that is\nsuspicious as a connection error of type H3_EXCESSIVE_LOAD, but\nfalse positives will result in disrupting valid connections and requests.\n\n### Limits on Field Section Size\n\nA large field section ({{request-response}}) can cause an implementation to\ncommit a large amount of state.  Header fields that are critical for routing can\nappear toward the end of a header section, which prevents streaming of the\nheader section to its ultimate destination.  This ordering and other reasons,\nsuch as ensuring cache correctness, mean that an endpoint likely needs to buffer\nthe entire header section.  Since there is no hard limit to the size of a field\nsection, some endpoints could be forced to commit a large amount of available\nmemory for header fields.\n\nAn endpoint can use the SETTINGS_MAX_FIELD_SECTION_SIZE\n({{header-size-constraints}}) setting to advise peers of limits that might apply\non the size of field sections. This setting is only advisory, so endpoints MAY\nchoose to send field sections that exceed this limit and risk having the request\nor response being treated as malformed.  This setting is specific to an HTTP/3\nconnection, so any request or response could encounter a hop with a lower,\nunknown limit.  An intermediary can attempt to avoid this problem by passing on\nvalues presented by different peers, but they are not obligated to do so.\n\nA server that receives a larger field section than it is willing to handle can\nsend an HTTP 431 (Request Header Fields Too Large) status code ({{?RFC6585}}).\nA client can discard responses that it cannot process.\n\n### CONNECT Issues\n\nThe CONNECT method can be used to create disproportionate load on a proxy, since\nstream creation is relatively inexpensive when compared to the creation and\nmaintenance of a TCP connection.  Therefore, a proxy that supports CONNECT might\nbe more conservative in the number of simultaneous requests it accepts.\n\nA proxy might also maintain some resources for a TCP connection beyond the\nclosing of the stream that carries the CONNECT request, since the outgoing TCP\nconnection remains in the TIME_WAIT state.  To account for this, a proxy might\ndelay increasing the QUIC stream limits for some time after a TCP connection\nterminates.\n\n## Use of Compression\n\nCompression can allow an attacker to recover secret data when it is compressed\nin the same context as data under attacker control. HTTP/3 enables compression\nof fields ({{header-formatting}}); the following concerns also apply to the use\nof HTTP compressed content-codings; see {{Section 8.4.1 of RFC9110}}.\n\nThere are demonstrable attacks on compression that exploit the characteristics\nof the web (e.g., {{BREACH}}).  The attacker induces multiple requests\ncontaining varying plaintext, observing the length of the resulting ciphertext\nin each, which reveals a shorter length when a guess about the secret is\ncorrect.\n\nImplementations communicating on a secure channel MUST NOT compress content that\nincludes both confidential and attacker-controlled data unless separate\ncompression contexts are used for each source of data.  Compression MUST NOT be\nused if the source of data cannot be reliably determined.\n\nFurther considerations regarding the compression of field sections are\ndescribed in {{RFC9204}}.\n\n## Padding and Traffic Analysis\n\nPadding can be used to obscure the exact size of frame content and is provided\nto mitigate specific attacks within HTTP, for example, attacks where compressed\ncontent includes both attacker-controlled plaintext and secret data (e.g.,\n{{BREACH}}).\n\nWhere HTTP/2 employs PADDING frames and Padding fields in other frames to make a\nconnection more resistant to traffic analysis, HTTP/3 can either rely on\ntransport-layer padding or employ the reserved frame and stream types discussed\nin Sections {{<frame-reserved}} and {{<stream-grease}}.  These methods of\npadding produce different results in terms of the granularity of padding, how\npadding is arranged in relation to the information that is being protected,\nwhether padding is applied in the case of packet loss, and how an implementation\nmight control padding.\n\nReserved stream types can be used to give the appearance of sending traffic even\nwhen the connection is idle.  Because HTTP traffic often occurs in bursts,\napparent traffic can be used to obscure the timing or duration of such bursts,\neven to the point of appearing to send a constant stream of data.  However, as\nsuch traffic is still flow controlled by the receiver, a failure to promptly\ndrain such streams and provide additional flow-control credit can limit the\nsender's ability to send real traffic.\n\nTo mitigate attacks that rely on compression, disabling or limiting compression\nmight be preferable to padding as a countermeasure.\n\nUse of padding can result in less protection than might seem immediately\nobvious.  Redundant padding could even be counterproductive.  At best, padding\nonly makes it more difficult for an attacker to infer length information by\nincreasing the number of frames an attacker has to observe.  Incorrectly\nimplemented padding schemes can be easily defeated.  In particular, randomized\npadding with a predictable distribution provides very little protection;\nsimilarly, padding payloads to a fixed size exposes information as payload sizes\ncross the fixed-sized boundary, which could be possible if an attacker can\ncontrol plaintext.\n\n## Frame Parsing\n\nSeveral protocol elements contain nested length elements, typically in the form\nof frames with an explicit length containing variable-length integers.  This\ncould pose a security risk to an incautious implementer.  An implementation MUST\nensure that the length of a frame exactly matches the length of the fields it\ncontains.\n\n## Early Data\n\nThe use of 0-RTT with HTTP/3 creates an exposure to replay attack.  The\nanti-replay mitigations in {{!HTTP-REPLAY=RFC8470}} MUST be applied when using\nHTTP/3 with 0-RTT.  When applying {{!HTTP-REPLAY}} to HTTP/3, references to the\nTLS layer refer to the handshake performed within QUIC, while all references to\napplication data refer to the contents of streams.\n\n## Migration\n\nCertain HTTP implementations use the client address for logging or\naccess-control purposes.  Since a QUIC client's address might change during a\nconnection (and future versions might support simultaneous use of multiple\naddresses), such implementations will need to either actively retrieve the\nclient's current address or addresses when they are relevant or explicitly\naccept that the original address might change.\n\n## Privacy Considerations\n\nSeveral characteristics of HTTP/3 provide an observer an opportunity to\ncorrelate actions of a single client or server over time.  These include the\nvalue of settings, the timing of reactions to stimulus, and the handling of any\nfeatures that are controlled by settings.\n\nAs far as these create observable differences in behavior, they could be used as\na basis for fingerprinting a specific client.\n\nHTTP/3's preference for using a single QUIC connection allows correlation of a\nuser's activity on a site.  Reusing connections for different origins allows\nfor correlation of activity across those origins.\n\nSeveral features of QUIC solicit immediate responses and can be used by an\nendpoint to measure latency to their peer; this might have privacy implications\nin certain scenarios.\n\n# IANA Considerations\n\nThis document registers a new ALPN protocol ID ({{iana-alpn}}) and creates new\nregistries that manage the assignment of code points in HTTP/3.\n\n## Registration of HTTP/3 Identification String {#iana-alpn}\n\nThis document creates a new registration for the identification of\nHTTP/3 in the \"TLS Application-Layer Protocol Negotiation (ALPN)\nProtocol IDs\" registry established in {{?RFC7301}}.\n\nThe \"h3\" string identifies HTTP/3:\n\n  Protocol:\n  : HTTP/3\n\n  Identification Sequence:\n  : 0x68 0x33 (\"h3\")\n\n  Specification:\n  : This document\n\n## New Registries {#iana-policy}\n\nNew registries created in this document operate under the QUIC registration\npolicy documented in {{Section 22.1 of QUIC-TRANSPORT}}.  These registries all\ninclude the common set of fields listed in {{Section 22.1.1 of QUIC-TRANSPORT}}.\nThese registries are collected under the \"Hypertext Transfer Protocol version 3\n(HTTP/3)\" heading.\n\nThe initial allocations in these registries are all assigned permanent status\nand list a change controller of the IETF and a contact of the HTTP working group\n(ietf-http-wg@w3.org).\n\n### Frame Types {#iana-frames}\n\nThis document establishes a registry for HTTP/3 frame type codes. The \"HTTP/3\nFrame Types\" registry governs a 62-bit space.  This registry follows the QUIC\nregistry policy; see {{iana-policy}}.  Permanent registrations in this registry\nare assigned using the Specification Required policy ({{!RFC8126}}), except for\nvalues between 0x00 and 0x3f (in hexadecimal; inclusive), which are assigned\nusing Standards Action or IESG Approval as defined in\n{{Sections 4.9 and 4.10 of RFC8126}}.\n\nWhile this registry is separate from the \"HTTP/2 Frame Type\" registry defined in\n{{RFC9113}}, it is preferable that the assignments parallel each other where the\ncode spaces overlap.  If an entry is present in only one registry, every effort\nSHOULD be made to avoid assigning the corresponding value to an unrelated\noperation.  Expert reviewers MAY reject unrelated registrations that would\nconflict with the same value in the corresponding registry.\n\nIn addition to common fields as described in {{iana-policy}}, permanent\nregistrations in this registry MUST include the following field:\n\nFrame Type:\n: A name or label for the frame type.\n\nSpecifications of frame types MUST include a description of the frame layout and\nits semantics, including any parts of the frame that are conditionally present.\n\nThe entries in {{iana-frame-table}} are registered by this document.\n\n| ------------ | ------- | -------------------------- |\n| Frame Type   |  Value  | Specification              |\n| ------------ | :-----: | -------------------------- |\n| DATA         |  0x00   | {{frame-data}}             |\n| HEADERS      |  0x01   | {{frame-headers}}          |\n| Reserved     |  0x02   | This document              |\n| CANCEL_PUSH  |  0x03   | {{frame-cancel-push}}      |\n| SETTINGS     |  0x04   | {{frame-settings}}         |\n| PUSH_PROMISE |  0x05   | {{frame-push-promise}}     |\n| Reserved     |  0x06   | This document              |\n| GOAWAY       |  0x07   | {{frame-goaway}}           |\n| Reserved     |  0x08   | This document              |\n| Reserved     |  0x09   | This document              |\n| MAX_PUSH_ID  |  0x0d   | {{frame-max-push-id}}      |\n| ------------ | ------- | -------------------------- |\n{: #iana-frame-table title=\"Initial HTTP/3 Frame Types\"}\n\nEach code of the format `0x1f * N + 0x21` for non-negative integer values of `N`\n(that is, 0x21, 0x40, ..., through 0x3ffffffffffffffe) MUST NOT be assigned by\nIANA and MUST NOT appear in the listing of assigned values.\n\n### Settings Parameters {#iana-settings}\n\nThis document establishes a registry for HTTP/3 settings.  The \"HTTP/3 Settings\"\nregistry governs a 62-bit space.  This registry follows the QUIC registry\npolicy; see {{iana-policy}}.  Permanent registrations in this registry are\nassigned using the Specification Required policy ({{!RFC8126}}), except for\nvalues between 0x00 and 0x3f (in hexadecimal; inclusive), which are assigned\nusing Standards Action or IESG Approval as defined in\n{{Sections 4.9 and 4.10 of RFC8126}}.\n\nWhile this registry is separate from the \"HTTP/2 Settings\" registry defined in\n{{RFC9113}}, it is preferable that the assignments parallel each other.  If an\nentry is present in only one registry, every effort SHOULD be made to avoid\nassigning the corresponding value to an unrelated operation. Expert reviewers\nMAY reject unrelated registrations that would conflict with the same value in\nthe corresponding registry.\n\nIn addition to common fields as described in {{iana-policy}}, permanent\nregistrations in this registry MUST include the following fields:\n\nSetting Name:\n: A symbolic name for the setting.  Specifying a setting name is optional.\n\nDefault:\n: The value of the setting unless otherwise indicated. A default SHOULD be the\n  most restrictive possible value.\n\nThe entries in {{iana-setting-table}} are registered by this document.\n\n| ----------------------- | ------- | ----------------------- | --------- |\n| Setting Name            |  Value  | Specification           | Default   |\n| ----------------------- | :-----: | ----------------------- | --------- |\n| Reserved                |  0x00   | This document           | N/A       |\n| Reserved                |  0x02   | This document           | N/A       |\n| Reserved                |  0x03   | This document           | N/A       |\n| Reserved                |  0x04   | This document           | N/A       |\n| Reserved                |  0x05   | This document           | N/A       |\n| MAX_FIELD_SECTION_SIZE  |  0x06   | {{settings-parameters}} | Unlimited |\n| ----------------------- | ------- | ----------------------- | --------- |\n{: #iana-setting-table title=\"Initial HTTP/3 Settings\"}\n\nFor formatting reasons, setting names can be abbreviated by removing the\n'SETTINGS_' prefix.\n\nEach code of the format `0x1f * N + 0x21` for non-negative integer values of `N`\n(that is, 0x21, 0x40, ..., through 0x3ffffffffffffffe) MUST NOT be assigned by\nIANA and MUST NOT appear in the listing of assigned values.\n\n### Error Codes {#iana-error-codes}\n\nThis document establishes a registry for HTTP/3 error codes. The \"HTTP/3 Error\nCodes\" registry manages a 62-bit space.  This registry follows the QUIC registry\npolicy; see {{iana-policy}}.  Permanent registrations in this registry are\nassigned using the Specification Required policy ({{!RFC8126}}), except for\nvalues between 0x00 and 0x3f (in hexadecimal; inclusive), which are assigned\nusing Standards Action or IESG Approval as defined in\n{{Sections 4.9 and 4.10 of RFC8126}}.\n\nRegistrations for error codes are required to include a description of the error\ncode.  An expert reviewer is advised to examine new registrations for possible\nduplication with existing error codes.  Use of existing registrations is to be\nencouraged, but not mandated.  Use of values that are registered in the \"HTTP/2\nError Code\" registry is discouraged, and expert reviewers MAY reject such\nregistrations.\n\nIn addition to common fields as described in {{iana-policy}}, this registry\nincludes two additional fields.  Permanent registrations in this registry MUST\ninclude the following field:\n\nName:\n: A name for the error code.\n\nDescription:\n: A brief description of the error code semantics.\n\nThe entries in {{iana-error-table}} are registered by this document. These\nerror codes were selected from the range that operates on a Specification\nRequired policy to avoid collisions with HTTP/2 error codes.\n\n| --------------------------------- | ---------- | ---------------------------------------- | ---------------------- |\n| Name                              | Value      | Description                              | Specification          |\n| --------------------------------- | ---------- | ---------------------------------------- | ---------------------- |\n| H3_NO_ERROR                       | 0x0100     | No error                                 | {{http-error-codes}}   |\n| H3_GENERAL_PROTOCOL_ERROR         | 0x0101     | General protocol error                   | {{http-error-codes}}   |\n| H3_INTERNAL_ERROR                 | 0x0102     | Internal error                           | {{http-error-codes}}   |\n| H3_STREAM_CREATION_ERROR          | 0x0103     | Stream creation error                    | {{http-error-codes}}   |\n| H3_CLOSED_CRITICAL_STREAM         | 0x0104     | Critical stream was closed               | {{http-error-codes}}   |\n| H3_FRAME_UNEXPECTED               | 0x0105     | Frame not permitted in the current state | {{http-error-codes}}   |\n| H3_FRAME_ERROR                    | 0x0106     | Frame violated layout or size rules      | {{http-error-codes}}   |\n| H3_EXCESSIVE_LOAD                 | 0x0107     | Peer generating excessive load           | {{http-error-codes}}   |\n| H3_ID_ERROR                       | 0x0108     | An identifier was used incorrectly       | {{http-error-codes}}   |\n| H3_SETTINGS_ERROR                 | 0x0109     | SETTINGS frame contained invalid values  | {{http-error-codes}}   |\n| H3_MISSING_SETTINGS               | 0x010a     | No SETTINGS frame received               | {{http-error-codes}}   |\n| H3_REQUEST_REJECTED               | 0x010b     | Request not processed                    | {{http-error-codes}}   |\n| H3_REQUEST_CANCELLED              | 0x010c     | Data no longer needed                    | {{http-error-codes}}   |\n| H3_REQUEST_INCOMPLETE             | 0x010d     | Stream terminated early                  | {{http-error-codes}}   |\n| H3_MESSAGE_ERROR                  | 0x010e     | Malformed message                        | {{http-error-codes}}   |\n| H3_CONNECT_ERROR                  | 0x010f     | TCP reset or error on CONNECT request    | {{http-error-codes}}   |\n| H3_VERSION_FALLBACK               | 0x0110     | Retry over HTTP/1.1                      | {{http-error-codes}}   |\n| --------------------------------- | ---------- | ---------------------------------------- | ---------------------- |\n{: #iana-error-table title=\"Initial HTTP/3 Error Codes\"}\n\nEach code of the format `0x1f * N + 0x21` for non-negative integer values of `N`\n(that is, 0x21, 0x40, ..., through 0x3ffffffffffffffe) MUST NOT be assigned by\nIANA and MUST NOT appear in the listing of assigned values.\n\n### Stream Types {#iana-stream-types}\n\nThis document establishes a registry for HTTP/3 unidirectional stream types. The\n\"HTTP/3 Stream Types\" registry governs a 62-bit space.  This registry follows\nthe QUIC registry policy; see {{iana-policy}}.  Permanent registrations in this\nregistry are assigned using the Specification Required policy ({{!RFC8126}}),\nexcept for values between 0x00 and 0x3f (in hexadecimal; inclusive), which are\nassigned using Standards Action or IESG Approval as defined in {{Sections 4.9\nand 4.10 of RFC8126}}.\n\nIn addition to common fields as described in {{iana-policy}}, permanent\nregistrations in this registry MUST include the following fields:\n\nStream Type:\n: A name or label for the stream type.\n\nSender:\n: Which endpoint on an HTTP/3 connection may initiate a stream of this type.\n  Values are \"Client\", \"Server\", or \"Both\".\n\nSpecifications for permanent registrations MUST include a description of the\nstream type, including the layout and semantics of the stream contents.\n\nThe entries in {{iana-stream-type-table}} are registered by this document.\n\n| ---------------- | ------ | -------------------------- | ------ |\n| Stream Type      | Value  | Specification              | Sender |\n| ---------------- | :----: | -------------------------- | ------ |\n| Control Stream   |  0x00  | {{control-streams}}        | Both   |\n| Push Stream      |  0x01  | {{server-push}}            | Server |\n| ---------------- | ------ | -------------------------- | ------ |\n{: #iana-stream-type-table title=\"Initial Stream Types\"}\n\nEach code of the format `0x1f * N + 0x21` for non-negative integer values of `N`\n(that is, 0x21, 0x40, ..., through 0x3ffffffffffffffe) MUST NOT be assigned by\nIANA and MUST NOT appear in the listing of assigned values.\n\n\n--- back\n\n# Considerations for Transitioning from HTTP/2 {#h2-considerations}\n\nHTTP/3 is strongly informed by HTTP/2, and it bears many similarities.  This\nsection describes the approach taken to design HTTP/3, points out important\ndifferences from HTTP/2, and describes how to map HTTP/2 extensions into HTTP/3.\n\nHTTP/3 begins from the premise that similarity to HTTP/2 is preferable, but not\na hard requirement.  HTTP/3 departs from HTTP/2 where QUIC differs from TCP,\neither to take advantage of QUIC features (like streams) or to accommodate\nimportant shortcomings (such as a lack of total ordering). While HTTP/3 is\nsimilar to HTTP/2 in key aspects, such as the relationship of requests and\nresponses to streams, the details of the HTTP/3 design are substantially\ndifferent from HTTP/2.\n\nSome important departures are noted in this section.\n\n## Streams {#h2-streams}\n\nHTTP/3 permits use of a larger number of streams (2<sup>62</sup>-1) than HTTP/2.\nThe same considerations about exhaustion of stream identifier space apply,\nthough the space is significantly larger such that it is likely that other\nlimits in QUIC are reached first, such as the limit on the connection\nflow-control window.\n\nIn contrast to HTTP/2, stream concurrency in HTTP/3 is managed by QUIC.  QUIC\nconsiders a stream closed when all data has been received and sent data has been\nacknowledged by the peer.  HTTP/2 considers a stream closed when the frame\ncontaining the END_STREAM bit has been committed to the transport. As a result,\nthe stream for an equivalent exchange could remain \"active\" for a longer period\nof time.  HTTP/3 servers might choose to permit a larger number of concurrent\nclient-initiated bidirectional streams to achieve equivalent concurrency to\nHTTP/2, depending on the expected usage patterns.\n\nIn HTTP/2, only request and response bodies (the frame payload of DATA frames)\nare subject to flow control.  All HTTP/3 frames are sent on QUIC streams, so all\nframes on all streams are flow controlled in HTTP/3.\n\nDue to the presence of other unidirectional stream types, HTTP/3 does not rely\nexclusively on the number of concurrent unidirectional streams to control the\nnumber of concurrent in-flight pushes.  Instead, HTTP/3 clients use the\nMAX_PUSH_ID frame to control the number of pushes received from an HTTP/3\nserver.\n\n## HTTP Frame Types {#h2-frames}\n\nMany framing concepts from HTTP/2 can be elided on QUIC, because the transport\ndeals with them. Because frames are already on a stream, they can omit the\nstream number. Because frames do not block multiplexing (QUIC's multiplexing\noccurs below this layer), the support for variable-maximum-length packets can be\nremoved. Because stream termination is handled by QUIC, an END_STREAM flag is\nnot required.  This permits the removal of the Flags field from the generic\nframe layout.\n\nFrame payloads are largely drawn from {{RFC9113}}. However, QUIC includes many\nfeatures (e.g., flow control) that are also present in HTTP/2. In these cases,\nthe HTTP mapping does not re-implement them. As a result, several HTTP/2 frame\ntypes are not required in HTTP/3. Where an HTTP/2-defined frame is no longer\nused, the frame ID has been reserved in order to maximize portability between\nHTTP/2 and HTTP/3 implementations. However, even frame types that appear in\nboth mappings do not have identical semantics.\n\nMany of the differences arise from the fact that HTTP/2 provides an absolute\nordering between frames across all streams, while QUIC provides this guarantee\non each stream only.  As a result, if a frame type makes assumptions that frames\nfrom different streams will still be received in the order sent, HTTP/3 will\nbreak them.\n\nSome examples of feature adaptations are described below, as well as general\nguidance to extension frame implementors converting an HTTP/2 extension to\nHTTP/3.\n\n### Prioritization Differences {#h2-diff-priority}\n\nHTTP/2 specifies priority assignments in PRIORITY frames and (optionally) in\nHEADERS frames. HTTP/3 does not provide a means of signaling priority.\n\nNote that, while there is no explicit signaling for priority, this does not mean\nthat prioritization is not important for achieving good performance.\n\n### Field Compression Differences\n\nHPACK was designed with the assumption of in-order delivery. A sequence of\nencoded field sections must arrive (and be decoded) at an endpoint in the same\norder in which they were encoded. This ensures that the dynamic state at the two\nendpoints remains in sync.\n\nBecause this total ordering is not provided by QUIC, HTTP/3 uses a modified\nversion of HPACK, called QPACK.  QPACK uses a single unidirectional stream to\nmake all modifications to the dynamic table, ensuring a total order of updates.\nAll frames that contain encoded fields merely reference the table state at a\ngiven time without modifying it.\n\n{{RFC9204}} provides additional details.\n\n### Flow-Control Differences\n\nHTTP/2 specifies a stream flow-control mechanism. Although all HTTP/2 frames are\ndelivered on streams, only the DATA frame payload is subject to flow control.\nQUIC provides flow control for stream data and all HTTP/3 frame types defined in\nthis document are sent on streams. Therefore, all frame headers and payload are\nsubject to flow control.\n\n### Guidance for New Frame Type Definitions\n\nFrame type definitions in HTTP/3 often use the QUIC variable-length integer\nencoding.  In particular, stream IDs use this encoding, which allows for a\nlarger range of possible values than the encoding used in HTTP/2.  Some frames\nin HTTP/3 use an identifier other than a stream ID (e.g., push IDs).\nRedefinition of the encoding of extension frame types might be necessary if the\nencoding includes a stream ID.\n\nBecause the Flags field is not present in generic HTTP/3 frames, those frames\nthat depend on the presence of flags need to allocate space for flags as part\nof their frame payload.\n\nOther than these issues, frame type HTTP/2 extensions are typically portable to\nQUIC simply by replacing stream 0 in HTTP/2 with a control stream in HTTP/3.\nHTTP/3 extensions will not assume ordering, but would not be harmed by ordering,\nand are expected to be portable to HTTP/2.\n\n### Comparison of HTTP/2 and HTTP/3 Frame Types\n\nDATA (0x00):\n: Padding is not defined in HTTP/3 frames.  See {{frame-data}}.\n\nHEADERS (0x01):\n: The PRIORITY region of HEADERS is not defined in HTTP/3 frames. Padding is not\n  defined in HTTP/3 frames.  See {{frame-headers}}.\n\nPRIORITY (0x02):\n: As described in {{h2-diff-priority}}, HTTP/3 does not provide a means of\n  signaling priority.\n\nRST_STREAM (0x03):\n: RST_STREAM frames do not exist in HTTP/3, since QUIC provides stream lifecycle\n  management.  The same code point is used for the CANCEL_PUSH frame\n  ({{frame-cancel-push}}).\n\nSETTINGS (0x04):\n: SETTINGS frames are sent only at the beginning of the connection.  See\n  {{frame-settings}} and {{h2-settings}}.\n\nPUSH_PROMISE (0x05):\n: The PUSH_PROMISE frame does not reference a stream; instead, the push stream\n  references the PUSH_PROMISE frame using a push ID.  See\n  {{frame-push-promise}}.\n\nPING (0x06):\n: PING frames do not exist in HTTP/3, as QUIC provides equivalent\n  functionality.\n\nGOAWAY (0x07):\n: GOAWAY does not contain an error code.  In the client-to-server direction,\n  it carries a push ID instead of a server-initiated stream ID.\n  See {{frame-goaway}}.\n\nWINDOW_UPDATE (0x08):\n: WINDOW_UPDATE frames do not exist in HTTP/3, since QUIC provides flow control.\n\nCONTINUATION (0x09):\n: CONTINUATION frames do not exist in HTTP/3; instead, larger\n  HEADERS/PUSH_PROMISE frames than HTTP/2 are permitted.\n\nFrame types defined by extensions to HTTP/2 need to be separately registered for\nHTTP/3 if still applicable.  The IDs of frames defined in {{RFC9113}} have been\nreserved for simplicity.  Note that the frame type space in HTTP/3 is\nsubstantially larger (62 bits versus 8 bits), so many HTTP/3 frame types have no\nequivalent HTTP/2 code points.  See {{iana-frames}}.\n\n## HTTP/2 SETTINGS Parameters {#h2-settings}\n\nAn important difference from HTTP/2 is that settings are sent once, as the first\nframe of the control stream, and thereafter cannot change.  This eliminates many\ncorner cases around synchronization of changes.\n\nSome transport-level options that HTTP/2 specifies via the SETTINGS frame are\nsuperseded by QUIC transport parameters in HTTP/3.  The HTTP-level setting that\nis retained in HTTP/3 has the same value as in HTTP/2.  The superseded\nsettings are reserved, and their receipt is an error.  See\n{{settings-parameters}} for discussion of both the retained and reserved values.\n\nBelow is a listing of how each HTTP/2 SETTINGS parameter is mapped:\n\nSETTINGS_HEADER_TABLE_SIZE (0x01):\n: See {{RFC9204}}.\n\nSETTINGS_ENABLE_PUSH (0x02):\n: This is removed in favor of the MAX_PUSH_ID frame, which provides a more\n  granular control over server push.  Specifying a setting with the identifier\n  0x02 (corresponding to the SETTINGS_ENABLE_PUSH parameter) in the HTTP/3\n  SETTINGS frame is an error.\n\nSETTINGS_MAX_CONCURRENT_STREAMS (0x03):\n: QUIC controls the largest open stream ID as part of its flow-control logic.\n  Specifying a setting with the identifier 0x03 (corresponding to the\n  SETTINGS_MAX_CONCURRENT_STREAMS parameter) in the HTTP/3 SETTINGS frame is an\n  error.\n\nSETTINGS_INITIAL_WINDOW_SIZE (0x04):\n: QUIC requires both stream and connection flow-control window sizes to be\n  specified in the initial transport handshake.  Specifying a setting with the\n  identifier 0x04 (corresponding to the SETTINGS_INITIAL_WINDOW_SIZE parameter)\n  in the HTTP/3 SETTINGS frame is an error.\n\nSETTINGS_MAX_FRAME_SIZE (0x05):\n: This setting has no equivalent in HTTP/3.  Specifying a setting with the\n  identifier 0x05 (corresponding to the SETTINGS_MAX_FRAME_SIZE parameter) in\n  the HTTP/3 SETTINGS frame is an error.\n\nSETTINGS_MAX_HEADER_LIST_SIZE (0x06):\n: This setting identifier has been renamed SETTINGS_MAX_FIELD_SECTION_SIZE.\n\nIn HTTP/3, setting values are variable-length integers (6, 14, 30, or 62 bits\nlong) rather than fixed-length 32-bit fields as in HTTP/2.  This will often\nproduce a shorter encoding, but can produce a longer encoding for settings that\nuse the full 32-bit space.  Settings ported from HTTP/2 might choose to redefine\ntheir value to limit it to 30 bits for more efficient encoding or to make use\nof the 62-bit space if more than 30 bits are required.\n\nSettings need to be defined separately for HTTP/2 and HTTP/3. The IDs of\nsettings defined in {{RFC9113}} have been reserved for simplicity.  Note that\nthe settings identifier space in HTTP/3 is substantially larger (62 bits versus\n16 bits), so many HTTP/3 settings have no equivalent HTTP/2 code point. See\n{{iana-settings}}.\n\nAs QUIC streams might arrive out of order, endpoints are advised not to wait for\nthe peers' settings to arrive before responding to other streams.  See\n{{settings-initialization}}.\n\n\n## HTTP/2 Error Codes\n\nQUIC has the same concepts of \"stream\" and \"connection\" errors that HTTP/2\nprovides. However, the differences between HTTP/2 and HTTP/3 mean that error\ncodes are not directly portable between versions.\n\nThe HTTP/2 error codes defined in {{Section 7 of RFC9113}} logically map to\nthe HTTP/3 error codes as follows:\n\nNO_ERROR (0x00):\n: H3_NO_ERROR in {{http-error-codes}}.\n\nPROTOCOL_ERROR (0x01):\n: This is mapped to H3_GENERAL_PROTOCOL_ERROR except in cases where more\n  specific error codes have been defined. Such cases include\n  H3_FRAME_UNEXPECTED, H3_MESSAGE_ERROR, and H3_CLOSED_CRITICAL_STREAM defined\n  in {{http-error-codes}}.\n\nINTERNAL_ERROR (0x02):\n: H3_INTERNAL_ERROR in {{http-error-codes}}.\n\nFLOW_CONTROL_ERROR (0x03):\n: Not applicable, since QUIC handles flow control.\n\nSETTINGS_TIMEOUT (0x04):\n: Not applicable, since no acknowledgment of SETTINGS is defined.\n\nSTREAM_CLOSED (0x05):\n: Not applicable, since QUIC handles stream management.\n\nFRAME_SIZE_ERROR (0x06):\n: H3_FRAME_ERROR error code defined in {{http-error-codes}}.\n\nREFUSED_STREAM (0x07):\n: H3_REQUEST_REJECTED (in {{http-error-codes}}) is used to indicate that a\n  request was not processed. Otherwise, not applicable because QUIC handles\n  stream management.\n\nCANCEL (0x08):\n: H3_REQUEST_CANCELLED in {{http-error-codes}}.\n\nCOMPRESSION_ERROR (0x09):\n: Multiple error codes are defined in {{RFC9204}}.\n\nCONNECT_ERROR (0x0a):\n: H3_CONNECT_ERROR in {{http-error-codes}}.\n\nENHANCE_YOUR_CALM (0x0b):\n: H3_EXCESSIVE_LOAD in {{http-error-codes}}.\n\nINADEQUATE_SECURITY (0x0c):\n: Not applicable, since QUIC is assumed to provide sufficient security on all\n  connections.\n\nHTTP_1_1_REQUIRED (0x0d):\n: H3_VERSION_FALLBACK in {{http-error-codes}}.\n\nError codes need to be defined for HTTP/2 and HTTP/3 separately.  See\n{{iana-error-codes}}.\n\n### Mapping between HTTP/2 and HTTP/3 Errors\n\nAn intermediary that converts between HTTP/2 and HTTP/3 may encounter error\nconditions from either upstream. It is useful to communicate the occurrence of\nerrors to the downstream, but error codes largely reflect connection-local\nproblems that generally do not make sense to propagate.\n\nAn intermediary that encounters an error from an upstream origin can indicate\nthis by sending an HTTP status code such as 502 (Bad Gateway), which is suitable\nfor a broad class of errors.\n\nThere are some rare cases where it is beneficial to propagate the error by\nmapping it to the closest matching error type to the receiver. For example, an\nintermediary that receives an HTTP/2 stream error of type REFUSED_STREAM from\nthe origin has a clear signal that the request was not processed and that the\nrequest is safe to retry. Propagating this error condition to the client as an\nHTTP/3 stream error of type H3_REQUEST_REJECTED allows the client to take the\naction it deems most appropriate. In the reverse direction, the intermediary\nmight deem it beneficial to pass on client request cancellations that are\nindicated by terminating a stream with H3_REQUEST_CANCELLED; see\n{{request-cancellation}}.\n\nConversion between errors is described in the logical mapping. The error codes\nare defined in non-overlapping spaces in order to protect against accidental\nconversion that could result in the use of inappropriate or unknown error codes\nfor the target version. An intermediary is permitted to promote stream errors to\nconnection errors but they should be aware of the cost to the HTTP/3 connection\nfor what might be a temporary or intermittent error.\n\n\n# Acknowledgments\n{:numbered=\"false\"}\n\n{{{Robbie Shade}}} and {{{Mike Warres}}} were the authors of\ndraft-shade-quic-http2-mapping, a precursor of this document.\n\nThe IETF QUIC Working Group received an enormous amount of support from many\npeople. Among others, the following people provided substantial contributions to\nthis document:\n\n{:compact}\n- <t>{{{Bence Béky}}}</t>\n- <t>{{{Daan De Meyer}}}</t>\n- <t>{{{Martin Duke}}}</t>\n- <t>{{{Roy Fielding}}}</t>\n- <t>{{{Alan Frindell}}}</t>\n- <t>{{{Alessandro Ghedini}}}</t>\n- <t>{{{Nick Harper}}}</t>\n- <t>{{{Ryan Hamilton}}}</t>\n- <t>{{{Christian Huitema}}}</t>\n- <t>{{{Subodh Iyengar}}}</t>\n- <t>{{{Robin Marx}}}</t>\n- <t>{{{Patrick McManus}}}</t>\n- <t>{{{Luca Niccolini}}}</t>\n- <t>{{{Kazuho Oku}{奥 一穂}}}</t>\n- <t>{{{Lucas Pardue}}}</t>\n- <t>{{{Roberto Peon}}}</t>\n- <t>{{{Julian Reschke}}}</t>\n- <t>{{{Eric Rescorla}}}</t>\n- <t>{{{Martin Seemann}}}</t>\n- <t>{{{Ben Schwartz}}}</t>\n- <t>{{{Ian Swett}}}</t>\n- <t>{{{Willy Taureau}}}</t>\n- <t>{{{Martin Thomson}}}</t>\n- <t>{{{Dmitri Tikhonov}}}</t>\n- <t>{{{Tatsuhiro Tsujikawa}}}</t>\n\nA portion of {{{Mike Bishop}}}'s contribution was supported by Microsoft during\nhis employment there.\n"
        },
        {
          "name": "rfc9204.md",
          "type": "blob",
          "size": 84.15625,
          "content": "---\ntitle: \"QPACK: Field Compression for HTTP/3\"\nabbrev: QPACK\nnumber: 9204\ndocname: draft-ietf-quic-qpack-latest\ndate: 2022-06\ncategory: std\nipr: trust200902\narea: Transport\nworkgroup: QUIC\nkeyword:\n  - compression\n  - \"HTTP/3\"\n  - HPACK\n  - header\n  - field\n  - trailer\n\nstand_alone: yes\nautolink-iref-cleanup: true\npi: [toc, sortrefs, symrefs, docmapping]\n\nauthor:\n -\n    ins: C. Krasic\n    name: Charles 'Buck' Krasic\n    email: krasic@acm.org\n -\n    ins: M. Bishop\n    name: Mike Bishop\n    org: Akamai Technologies\n    email: mbishop@evequefou.be\n -\n    ins: A. Frindell\n    name: Alan Frindell\n    org: Facebook\n    email: afrind@fb.com\n    role: editor\n\n\nnormative:\n\n  RFC9114:\n    display: HTTP/3\n  RFC9110:\n    display: HTTP\n  RFC2360:\n\ninformative:\n\n  RFC9113:\n    display: HTTP/2\n\n  CRIME:\n    target: http://en.wikipedia.org/w/index.php?title=CRIME&amp;oldid=660948120\n    title: \"CRIME\"\n    author:\n      -\n        org: Wikipedia\n    date: May, 2015\n\n\n  PETAL:\n    target: http://www.pdl.cmu.edu/PDL-FTP/associated/CMU-PDL-13-106.pdf\n    title: \"PETAL: Preset Encoding Table Information Leakage\"\n    author:\n      -\n        ins: J. Tan\n        name: Jiaqi Tan\n      -\n        ins: J. Nahata\n        name: Jayvardhan Nahata\n    date: April, 2013\n\n\n\n--- abstract\n\nThis specification defines QPACK: a compression format for efficiently\nrepresenting HTTP fields that is to be used in HTTP/3. This is a variation of\nHPACK compression that seeks to reduce head-of-line blocking.\n\n\n--- middle\n\n# Introduction\n\nThe QUIC transport protocol ({{!QUIC-TRANSPORT=RFC9000}}) is designed to support\nHTTP semantics, and its design subsumes many of the features of HTTP/2\n({{?RFC9113}}). HTTP/2 uses HPACK ({{!RFC7541}}) for compression of the header\nand trailer sections.  If HPACK were used for HTTP/3 ({{RFC9114}}), it would\ninduce head-of-line blocking for field sections due to built-in assumptions of a\ntotal ordering across frames on all streams.\n\nQPACK reuses core concepts from HPACK, but is redesigned to allow correctness in\nthe presence of out-of-order delivery, with flexibility for implementations to\nbalance between resilience against head-of-line blocking and optimal compression\nratio.  The design goals are to closely approach the compression ratio of HPACK\nwith substantially less head-of-line blocking under the same loss conditions.\n\n## Conventions and Definitions\n\nThe key words \"MUST\", \"MUST NOT\", \"REQUIRED\", \"SHALL\", \"SHALL NOT\", \"SHOULD\",\n\"SHOULD NOT\", \"RECOMMENDED\", \"NOT RECOMMENDED\", \"MAY\", and \"OPTIONAL\" in this\ndocument are to be interpreted as described in BCP 14 {{!RFC2119}} {{!RFC8174}}\nwhen, and only when, they appear in all capitals, as shown here.\n\nThe following terms are used in this document:\n\nHTTP fields:\n\n: Metadata sent as part of an HTTP message.  The term encompasses both header\n  and trailer fields. Colloquially, the term \"headers\" has often been used to\n  refer to HTTP header fields and trailer fields; this document uses \"fields\"\n  for generality.\n\nHTTP field line:\n\n: A name-value pair sent as part of an HTTP field section. See {{Sections 6.3\n  and 6.5 of RFC9110}}.\n\nHTTP field value:\n\n: Data associated with a field name, composed from all field line values with\n  that field name in that section, concatenated together with\n  comma separators.\n\nField section:\n\n: An ordered collection of HTTP field lines associated with an HTTP message.  A\n  field section can contain multiple field lines with the same name.  It can\n  also contain duplicate field lines.  An HTTP message can include both header\n  and trailer sections.\n\nRepresentation:\n\n: An instruction that represents a field line, possibly by reference to the\n  dynamic and static tables.\n\nEncoder:\n\n: An implementation that encodes field sections.\n\nDecoder:\n\n: An implementation that decodes encoded field sections.\n\nAbsolute Index:\n\n: A unique index for each entry in the dynamic table.\n\nBase:\n\n: A reference point for relative and post-Base indices.  Representations that\n  reference dynamic table entries are relative to a Base.\n\nInsert Count:\n\n: The total number of entries inserted in the dynamic table.\n\nNote that QPACK is a name, not an abbreviation.\n\n## Notational Conventions\n\nDiagrams in this document use the format described in {{Section 3.1 of\nRFC2360}}, with the following additional conventions:\n\nx (A)\n: Indicates that x is A bits long.\n\nx (A+)\n: Indicates that x uses the prefixed integer encoding defined in\n  {{prefixed-integers}}, beginning with an A-bit prefix.\n\nx ...\n: Indicates that x is variable length and extends to the end of the region.\n\n# Compression Process Overview\n\nLike HPACK, QPACK uses two tables for associating field lines (\"headers\") to\nindices.  The static table ({{header-table-static}}) is predefined and contains\ncommon header field lines (some of them with an empty value).  The dynamic table\n({{header-table-dynamic}}) is built up over the course of the connection and can\nbe used by the encoder to index both header and trailer field lines in the\nencoded field sections.\n\nQPACK defines unidirectional streams for sending instructions from encoder to\ndecoder and vice versa.\n\n## Encoder\n\nAn encoder converts a header or trailer section into a series of representations\nby emitting either an indexed or a literal representation for each field line in\nthe list; see {{field-line-representations}}.  Indexed representations achieve\nhigh compression by replacing the literal name and possibly the value with an\nindex to either the static or dynamic table.  References to the static table and\nliteral representations do not require any dynamic state and never risk\nhead-of-line blocking.  References to the dynamic table risk head-of-line\nblocking if the encoder has not received an acknowledgment indicating the entry\nis available at the decoder.\n\nAn encoder MAY insert any entry in the dynamic table it chooses; it is not\nlimited to field lines it is compressing.\n\nQPACK preserves the ordering of field lines within each field section.  An\nencoder MUST emit field representations in the order they appear in the input\nfield section.\n\nQPACK is designed to place the burden of optional state tracking on the encoder,\nresulting in relatively simple decoders.\n\n### Limits on Dynamic Table Insertions {#blocked-insertion}\n\nInserting entries into the dynamic table might not be possible if the table\ncontains entries that cannot be evicted.\n\nA dynamic table entry cannot be evicted immediately after insertion, even if it\nhas never been referenced. Once the insertion of a dynamic table entry has been\nacknowledged and there are no outstanding references to the entry in\nunacknowledged representations, the entry becomes evictable.  Note that\nreferences on the encoder stream never preclude the eviction of an entry,\nbecause those references are guaranteed to be processed before the instruction\nevicting the entry.\n\nIf the dynamic table does not contain enough room for a new entry without\nevicting other entries, and the entries that would be evicted are not\nevictable, the encoder MUST NOT insert that entry into the dynamic table\n(including duplicates of existing entries). In order to avoid this, an encoder\nthat uses the dynamic table has to keep track of each dynamic table entry\nreferenced by each field section until those representations are acknowledged by\nthe decoder; see {{header-acknowledgment}}.\n\n#### Avoiding Prohibited Insertions\n\nTo ensure that the encoder is not prevented from adding new entries, the encoder\ncan avoid referencing entries that are close to eviction.  Rather than\nreference such an entry, the encoder can emit a Duplicate instruction\n({{duplicate}}) and reference the duplicate instead.\n\nDetermining which entries are too close to eviction to reference is an encoder\npreference.  One heuristic is to target a fixed amount of available space in the\ndynamic table: either unused space or space that can be reclaimed by evicting\nnon-blocking entries.  To achieve this, the encoder can maintain a draining\nindex, which is the smallest absolute index ({{indexing}}) in the dynamic table\nthat it will emit a reference for.  As new entries are inserted, the encoder\nincreases the draining index to maintain the section of the table that it will\nnot reference.  If the encoder does not create new references to entries with an\nabsolute index lower than the draining index, the number of unacknowledged\nreferences to those entries will eventually become zero, allowing them to be\nevicted.\n\n~~~~~~~~~~  ascii-art\n             <-- Newer Entries          Older Entries -->\n               (Larger Indicies)      (Smaller Indicies)\n   +--------+---------------------------------+----------+\n   | Unused |          Referenceable          | Draining |\n   | Space  |             Entries             | Entries  |\n   +--------+---------------------------------+----------+\n            ^                                 ^          ^\n            |                                 |          |\n      Insertion Point                 Draining Index  Dropping\n                                                       Point\n~~~~~~~~~~\n{:#fig-draining-index title=\"Draining Dynamic Table Entries\"}\n\n\n### Blocked Streams\n\nBecause QUIC does not guarantee order between data on different streams, a\ndecoder might encounter a representation that references a dynamic table entry\nthat it has not yet received.\n\nEach encoded field section contains a Required Insert Count ({{header-prefix}}),\nthe lowest possible value for the Insert Count with which the field section can\nbe decoded. For a field section encoded using references to the dynamic table,\nthe Required Insert Count is one larger than the largest absolute index of all\nreferenced dynamic table entries. For a field section encoded with no references\nto the dynamic table, the Required Insert Count is zero.\n\nWhen the decoder receives an encoded field section with a Required Insert Count\ngreater than its own Insert Count, the stream cannot be processed immediately\nand is considered \"blocked\"; see {{blocked-decoding}}.\n\nThe decoder specifies an upper bound on the number of streams that can be\nblocked using the SETTINGS_QPACK_BLOCKED_STREAMS setting; see {{configuration}}.\nAn encoder MUST limit the number of streams that could become blocked to the\nvalue of SETTINGS_QPACK_BLOCKED_STREAMS at all times. If a decoder encounters\nmore blocked streams than it promised to support, it MUST treat this as a\nconnection error of type QPACK_DECOMPRESSION_FAILED.\n\nNote that the decoder might not become blocked on every stream that risks\nbecoming blocked.\n\nAn encoder can decide whether to risk having a stream become blocked. If\npermitted by the value of SETTINGS_QPACK_BLOCKED_STREAMS, compression efficiency\ncan often be improved by referencing dynamic table entries that are still in\ntransit, but if there is loss or reordering, the stream can become blocked at\nthe decoder.  An encoder can avoid the risk of blocking by only referencing\ndynamic table entries that have been acknowledged, but this could mean using\nliterals. Since literals make the encoded field section larger, this can result\nin the encoder becoming blocked on congestion or flow-control limits.\n\n### Avoiding Flow-Control Deadlocks\n\nWriting instructions on streams that are limited by flow control can produce\ndeadlocks.\n\nA decoder might stop issuing flow-control credit on the stream that carries an\nencoded field section until the necessary updates are received on the encoder\nstream. If the granting of flow-control credit on the encoder stream (or the\nconnection as a whole) depends on the consumption and release of data on the\nstream carrying the encoded field section, a deadlock might result.\n\nMore generally, a stream containing a large instruction can become deadlocked if\nthe decoder withholds flow-control credit until the instruction is completely\nreceived.\n\nTo avoid these deadlocks, an encoder SHOULD NOT write an instruction unless\nsufficient stream and connection flow-control credit is available for the entire\ninstruction.\n\n### Known Received Count\n\nThe Known Received Count is the total number of dynamic table insertions and\nduplications acknowledged by the decoder.  The encoder tracks the Known Received\nCount in order to identify which dynamic table entries can be referenced without\npotentially blocking a stream.  The decoder tracks the Known Received Count in\norder to be able to send Insert Count Increment instructions.\n\nA Section Acknowledgment instruction ({{header-acknowledgment}}) implies that\nthe decoder has received all dynamic table state necessary to decode the field\nsection.  If the Required Insert Count of the acknowledged field section is\ngreater than the current Known Received Count, the Known Received Count is\nupdated to that Required Insert Count value.\n\nAn Insert Count Increment instruction ({{insert-count-increment}}) increases the\nKnown Received Count by its Increment parameter.  See {{new-table-entries}} for\nguidance.\n\n## Decoder\n\nAs in HPACK, the decoder processes a series of representations and emits the\ncorresponding field sections. It also processes instructions received on the\nencoder stream that modify the dynamic table.  Note that encoded field sections\nand encoder stream instructions arrive on separate streams.  This is unlike\nHPACK, where encoded field sections (header blocks) can contain instructions\nthat modify the dynamic table, and there is no dedicated stream of HPACK\ninstructions.\n\nThe decoder MUST emit field lines in the order their representations appear in\nthe encoded field section.\n\n### Blocked Decoding\n\nUpon receipt of an encoded field section, the decoder examines the Required\nInsert Count. When the Required Insert Count is less than or equal to the\ndecoder's Insert Count, the field section can be processed immediately.\nOtherwise, the stream on which the field section was received becomes blocked.\n\nWhile blocked, encoded field section data SHOULD remain in the blocked stream's\nflow-control window. This data is unusable until the stream becomes unblocked,\nand releasing the flow control prematurely makes the decoder vulnerable to\nmemory exhaustion attacks. A stream becomes unblocked when the Insert Count\nbecomes greater than or equal to the Required Insert Count for all encoded\nfield sections the decoder has started reading from the stream.\n\nWhen processing encoded field sections, the decoder expects the Required Insert\nCount to equal the lowest possible value for the Insert Count with which the\nfield section can be decoded, as prescribed in {{blocked-streams}}. If it\nencounters a Required Insert Count smaller than expected, it MUST treat this as\na connection error of type QPACK_DECOMPRESSION_FAILED; see\n{{invalid-references}}. If it encounters a Required Insert Count larger than\nexpected, it MAY treat this as a connection error of type\nQPACK_DECOMPRESSION_FAILED.\n\n### State Synchronization\n\nThe decoder signals the following events by emitting decoder instructions\n({{decoder-instructions}}) on the decoder stream.\n\n#### Completed Processing of a Field Section\n\nAfter the decoder finishes decoding a field section encoded using\nrepresentations containing dynamic table references, it MUST emit a Section\nAcknowledgment instruction ({{header-acknowledgment}}).  A stream may carry\nmultiple field sections in the case of intermediate responses, trailers, and\npushed requests.  The encoder interprets each Section Acknowledgment\ninstruction as acknowledging the earliest unacknowledged field section\ncontaining dynamic table references sent on the given stream.\n\n#### Abandonment of a Stream\n\nWhen an endpoint receives a stream reset before the end of a stream or before\nall encoded field sections are processed on that stream, or when it abandons\nreading of a stream, it generates a Stream Cancellation instruction; see\n{{stream-cancellation}}.  This signals to the encoder that all references to the\ndynamic table on that stream are no longer outstanding.  A decoder with a\nmaximum dynamic table capacity ({{maximum-dynamic-table-capacity}}) equal to\nzero MAY omit sending Stream Cancellations, because the encoder cannot have any\ndynamic table references.  An encoder cannot infer from this instruction that\nany updates to the dynamic table have been received.\n\nThe Section Acknowledgment and Stream Cancellation instructions permit the\nencoder to remove references to entries in the dynamic table.  When an entry\nwith an absolute index lower than the Known Received Count has zero references,\nthen it is considered evictable; see {{blocked-insertion}}.\n\n#### New Table Entries\n\nAfter receiving new table entries on the encoder stream, the decoder chooses\nwhen to emit Insert Count Increment instructions; see\n{{insert-count-increment}}. Emitting this instruction after adding each new\ndynamic table entry will provide the timeliest feedback to the encoder, but\ncould be redundant with other decoder feedback. By delaying an Insert Count\nIncrement instruction, the decoder might be able to coalesce multiple Insert\nCount Increment instructions or replace them entirely with Section\nAcknowledgments; see {{header-acknowledgment}}. However, delaying too long\nmay lead to compression inefficiencies if the encoder waits for an entry to be\nacknowledged before using it.\n\n### Invalid References\n\nIf the decoder encounters a reference in a field line representation to a\ndynamic table entry that has already been evicted or that has an absolute\nindex greater than or equal to the declared Required Insert Count\n({{header-prefix}}), it MUST treat this as a connection error of type\nQPACK_DECOMPRESSION_FAILED.\n\nIf the decoder encounters a reference in an encoder instruction to a dynamic\ntable entry that has already been evicted, it MUST treat this as a connection\nerror of type QPACK_ENCODER_STREAM_ERROR.\n\n\n# Reference Tables\n\nUnlike in HPACK, entries in the QPACK static and dynamic tables are addressed\nseparately.  The following sections describe how entries in each table are\naddressed.\n\n## Static Table {#header-table-static}\n\nThe static table consists of a predefined list of field lines, each of which has\na fixed index over time.  Its entries are defined in {{static-table}}.\n\nAll entries in the static table have a name and a value.  However, values can be\nempty (that is, have a length of 0).  Each entry is identified by a unique\nindex.\n\nNote that the QPACK static table is indexed from 0, whereas the HPACK static\ntable is indexed from 1.\n\nWhen the decoder encounters an invalid static table index in a field line\nrepresentation, it MUST treat this as a connection error of type\nQPACK_DECOMPRESSION_FAILED.  If this index is received on the encoder stream,\nthis MUST be treated as a connection error of type QPACK_ENCODER_STREAM_ERROR.\n\n## Dynamic Table {#header-table-dynamic}\n\nThe dynamic table consists of a list of field lines maintained in first-in,\nfirst-out order.  A QPACK encoder and decoder share a dynamic table that is\ninitially empty.  The encoder adds entries to the dynamic table and sends them\nto the decoder via instructions on the encoder stream; see\n{{encoder-instructions}}.\n\nThe dynamic table can contain duplicate entries (i.e., entries with the same\nname and same value).  Therefore, duplicate entries MUST NOT be treated as an\nerror by the decoder.\n\nDynamic table entries can have empty values.\n\n### Dynamic Table Size\n\nThe size of the dynamic table is the sum of the size of its entries.\n\nThe size of an entry is the sum of its name's length in bytes, its value's\nlength in bytes, and 32 additional bytes.  The size of an entry is calculated\nusing the length of its name and value without Huffman encoding applied.\n\n### Dynamic Table Capacity and Eviction {#eviction}\n\nThe encoder sets the capacity of the dynamic table, which serves as the upper\nlimit on its size.  The initial capacity of the dynamic table is zero.  The\nencoder sends a Set Dynamic Table Capacity instruction\n({{set-dynamic-capacity}}) with a non-zero capacity to begin using the dynamic\ntable.\n\nBefore a new entry is added to the dynamic table, entries are evicted from the\nend of the dynamic table until the size of the dynamic table is less than or\nequal to (table capacity - size of new entry). The encoder MUST NOT cause a\ndynamic table entry to be evicted unless that entry is evictable; see\n{{blocked-insertion}}.  The new entry is then added to the table.  It is an\nerror if the encoder attempts to add an entry that is larger than the dynamic\ntable capacity; the decoder MUST treat this as a connection error of type\nQPACK_ENCODER_STREAM_ERROR.\n\nA new entry can reference an entry in the dynamic table that will be evicted\nwhen adding this new entry into the dynamic table.  Implementations are\ncautioned to avoid deleting the referenced name or value if the referenced entry\nis evicted from the dynamic table prior to inserting the new entry.\n\nWhenever the dynamic table capacity is reduced by the encoder\n({{set-dynamic-capacity}}), entries are evicted from the end of the dynamic\ntable until the size of the dynamic table is less than or equal to the new table\ncapacity.  This mechanism can be used to completely clear entries from the\ndynamic table by setting a capacity of 0, which can subsequently be restored.\n\n\n### Maximum Dynamic Table Capacity\n\nTo bound the memory requirements of the decoder, the decoder limits the maximum\nvalue the encoder is permitted to set for the dynamic table capacity.  In\nHTTP/3, this limit is determined by the value of\nSETTINGS_QPACK_MAX_TABLE_CAPACITY sent by the decoder; see {{configuration}}.\nThe encoder MUST NOT set a dynamic table capacity that exceeds this maximum, but\nit can choose to use a lower dynamic table capacity; see\n{{set-dynamic-capacity}}.\n\nFor clients using 0-RTT data in HTTP/3, the server's maximum table capacity is\nthe remembered value of the setting or zero if the value was not previously\nsent.  When the client's 0-RTT value of the SETTING is zero, the server MAY set\nit to a non-zero value in its SETTINGS frame. If the remembered value is\nnon-zero, the server MUST send the same non-zero value in its SETTINGS frame. If\nit specifies any other value, or omits SETTINGS_QPACK_MAX_TABLE_CAPACITY from\nSETTINGS, the encoder must treat this as a connection error of type\nQPACK_DECODER_STREAM_ERROR.\n\nFor clients not using 0-RTT data (whether 0-RTT is not attempted or is rejected)\nand for all HTTP/3 servers, the maximum table capacity is 0 until the encoder\nprocesses a SETTINGS frame with a non-zero value of\nSETTINGS_QPACK_MAX_TABLE_CAPACITY.\n\nWhen the maximum table capacity is zero, the encoder MUST NOT insert entries\ninto the dynamic table and MUST NOT send any encoder instructions on the encoder\nstream.\n\n\n### Absolute Indexing {#indexing}\n\nEach entry possesses an absolute index that is fixed for the lifetime of that\nentry. The first entry inserted has an absolute index of 0; indices increase\nby one with each insertion.\n\n\n### Relative Indexing\n\nRelative indices begin at zero and increase in the opposite direction from the\nabsolute index.  Determining which entry has a relative index of 0 depends on\nthe context of the reference.\n\nIn encoder instructions ({{encoder-instructions}}), a relative index of 0\nrefers to the most recently inserted value in the dynamic table.  Note that this\nmeans the entry referenced by a given relative index will change while\ninterpreting instructions on the encoder stream.\n\n~~~~~ ascii-art\n      +-----+---------------+-------+\n      | n-1 |      ...      |   d   |  Absolute Index\n      + - - +---------------+ - - - +\n      |  0  |      ...      | n-d-1 |  Relative Index\n      +-----+---------------+-------+\n      ^                             |\n      |                             V\nInsertion Point               Dropping Point\n\nn = count of entries inserted\nd = count of entries dropped\n~~~~~\n{: title=\"Example Dynamic Table Indexing - Encoder Stream\"}\n\nUnlike in encoder instructions, relative indices in field line representations\nare relative to the Base at the beginning of the encoded field section; see\n{{header-prefix}}. This ensures that references are stable even if encoded field\nsections and dynamic table updates are processed out of order.\n\nIn a field line representation, a relative index of 0 refers to the entry with\nabsolute index equal to Base - 1.\n\n~~~~~ ascii-art\n               Base\n                |\n                V\n    +-----+-----+-----+-----+-------+\n    | n-1 | n-2 | n-3 | ... |   d   |  Absolute Index\n    +-----+-----+  -  +-----+   -   +\n                |  0  | ... | n-d-3 |  Relative Index\n                +-----+-----+-------+\n\nn = count of entries inserted\nd = count of entries dropped\nIn this example, Base = n - 2\n~~~~~\n{: title=\"Example Dynamic Table Indexing - Relative Index in Representation\"}\n\n\n### Post-Base Indexing {#post-base}\n\nPost-Base indices are used in field line representations for entries with\nabsolute indices greater than or equal to Base, starting at 0 for the entry with\nabsolute index equal to Base and increasing in the same direction as the\nabsolute index.\n\nPost-Base indices allow an encoder to process a field section in a single pass\nand include references to entries added while processing this (or other) field\nsections.\n\n~~~~~ ascii-art\n               Base\n                |\n                V\n    +-----+-----+-----+-----+-----+\n    | n-1 | n-2 | n-3 | ... |  d  |  Absolute Index\n    +-----+-----+-----+-----+-----+\n    |  1  |  0  |                    Post-Base Index\n    +-----+-----+\n\nn = count of entries inserted\nd = count of entries dropped\nIn this example, Base = n - 2\n~~~~~\n{: title=\"Example Dynamic Table Indexing - Post-Base Index in Representation\"}\n\n\n# Wire Format\n\n## Primitives\n\n### Prefixed Integers\n\nThe prefixed integer from {{Section 5.1 of RFC7541}} is used heavily throughout\nthis document.  The format from {{RFC7541}} is used unmodified.  Note, however,\nthat QPACK uses some prefix sizes not actually used in HPACK.\n\nQPACK implementations MUST be able to decode integers up to and including 62\nbits long.\n\n### String Literals\n\nThe string literal defined by {{Section 5.2 of RFC7541}} is also used\nthroughout. This string format includes optional Huffman encoding.\n\nHPACK defines string literals to begin on a byte boundary.  They begin with a\nsingle bit flag, denoted as 'H' in this document (indicating whether the string\nis Huffman encoded), followed by the string length encoded as a 7-bit prefix\ninteger, and finally the indicated number of bytes of data. When Huffman\nencoding is enabled, the Huffman table from {{Section B of RFC7541}} is used\nwithout modification and the indicated length is the size of the string after\nencoding.\n\nThis document expands the definition of string literals by permitting them to\nbegin other than on a byte boundary.  An \"N-bit prefix string literal\" begins\nmid-byte, with the first (8-N) bits allocated to a previous field. The string\nuses one bit for the Huffman flag, followed by the length of the encoded string\nas a (N-1)-bit prefix integer.  The prefix size, N, can have a value between 2\nand 8, inclusive. The remainder of the string literal is unmodified.\n\nA string literal without a prefix length noted is an 8-bit prefix string literal\nand follows the definitions in {{RFC7541}} without modification.\n\n## Encoder and Decoder Streams {#enc-dec-stream-def}\n\nQPACK defines two unidirectional stream types:\n\n - An encoder stream is a unidirectional stream of type 0x02.\n   It carries an unframed sequence of encoder instructions from encoder\n   to decoder.\n\n - A decoder stream is a unidirectional stream of type 0x03.\n   It carries an unframed sequence of decoder instructions from decoder\n   to encoder.\n\nHTTP/3 endpoints contain a QPACK encoder and decoder. Each endpoint MUST\ninitiate, at most, one encoder stream and, at most, one decoder stream. Receipt\nof a second instance of either stream type MUST be treated as a connection error\nof type H3_STREAM_CREATION_ERROR.\n\nThe sender MUST NOT close either of these streams, and the receiver MUST NOT\nrequest that the sender close either of these streams. Closure of either\nunidirectional stream type MUST be treated as a connection error of type\nH3_CLOSED_CRITICAL_STREAM.\n\nAn endpoint MAY avoid creating an encoder stream if it will not be used (for\nexample, if its encoder does not wish to use the dynamic table or if the maximum\nsize of the dynamic table permitted by the peer is zero).\n\nAn endpoint MAY avoid creating a decoder stream if its decoder sets the maximum\ncapacity of the dynamic table to zero.\n\nAn endpoint MUST allow its peer to create an encoder stream and a decoder stream\neven if the connection's settings prevent their use.\n\n## Encoder Instructions {#encoder-instructions}\n\nAn encoder sends encoder instructions on the encoder stream to set the capacity\nof the dynamic table and add dynamic table entries.  Instructions adding table\nentries can use existing entries to avoid transmitting redundant information.\nThe name can be transmitted as a reference to an existing entry in the static or\nthe dynamic table or as a string literal.  For entries that already exist in\nthe dynamic table, the full entry can also be used by reference, creating a\nduplicate entry.\n\n### Set Dynamic Table Capacity {#set-dynamic-capacity}\n\nAn encoder informs the decoder of a change to the dynamic table capacity using\nan instruction that starts with the '001' 3-bit pattern.  This is followed\nby the new dynamic table capacity represented as an integer with a 5-bit prefix;\nsee {{prefixed-integers}}.\n\n~~~~~~~~~~ ascii-art\n  0   1   2   3   4   5   6   7\n+---+---+---+---+---+---+---+---+\n| 0 | 0 | 1 |   Capacity (5+)   |\n+---+---+---+-------------------+\n~~~~~~~~~~\n{:#fig-set-capacity title=\"Set Dynamic Table Capacity\"}\n\nThe new capacity MUST be lower than or equal to the limit described in\n{{maximum-dynamic-table-capacity}}.  In HTTP/3, this limit is the value of the\nSETTINGS_QPACK_MAX_TABLE_CAPACITY parameter ({{configuration}}) received from\nthe decoder.  The decoder MUST treat a new dynamic table capacity value that\nexceeds this limit as a connection error of type QPACK_ENCODER_STREAM_ERROR.\n\nReducing the dynamic table capacity can cause entries to be evicted; see\n{{eviction}}.  This MUST NOT cause the eviction of entries that are not\nevictable; see {{blocked-insertion}}.  Changing the capacity of the dynamic\ntable is not acknowledged as this instruction does not insert an entry.\n\n### Insert with Name Reference\n\nAn encoder adds an entry to the dynamic table where the field name matches the\nfield name of an entry stored in the static or the dynamic table using an\ninstruction that starts with the '1' 1-bit pattern.  The second ('T') bit\nindicates whether the reference is to the static or dynamic table. The 6-bit\nprefix integer ({{prefixed-integers}}) that follows is used to locate the table\nentry for the field name.  When T=1, the number represents the static table\nindex; when T=0, the number is the relative index of the entry in the dynamic\ntable.\n\nThe field name reference is followed by the field value represented as a string\nliteral; see {{string-literals}}.\n\n~~~~~~~~~~ ascii-art\n     0   1   2   3   4   5   6   7\n   +---+---+---+---+---+---+---+---+\n   | 1 | T |    Name Index (6+)    |\n   +---+---+-----------------------+\n   | H |     Value Length (7+)     |\n   +---+---------------------------+\n   |  Value String (Length bytes)  |\n   +-------------------------------+\n~~~~~~~~~~\n{: title=\"Insert Field Line -- Indexed Name\"}\n\n\n### Insert with Literal Name\n\nAn encoder adds an entry to the dynamic table where both the field name and the\nfield value are represented as string literals using an instruction that starts\nwith the '01' 2-bit pattern.\n\nThis is followed by the name represented as a 6-bit prefix string literal and\nthe value represented as an 8-bit prefix string literal; see\n{{string-literals}}.\n\n~~~~~~~~~~ ascii-art\n     0   1   2   3   4   5   6   7\n   +---+---+---+---+---+---+---+---+\n   | 0 | 1 | H | Name Length (5+)  |\n   +---+---+---+-------------------+\n   |  Name String (Length bytes)   |\n   +---+---------------------------+\n   | H |     Value Length (7+)     |\n   +---+---------------------------+\n   |  Value String (Length bytes)  |\n   +-------------------------------+\n~~~~~~~~~~\n{: title=\"Insert Field Line -- New Name\"}\n\n\n### Duplicate {#duplicate}\n\nAn encoder duplicates an existing entry in the dynamic table using an\ninstruction that starts with the '000' 3-bit pattern.  This is followed by\nthe relative index of the existing entry represented as an integer with a 5-bit\nprefix; see {{prefixed-integers}}.\n\n~~~~~~~~~~ ascii-art\n     0   1   2   3   4   5   6   7\n   +---+---+---+---+---+---+---+---+\n   | 0 | 0 | 0 |    Index (5+)     |\n   +---+---+---+-------------------+\n~~~~~~~~~~\n{:#fig-index-with-duplication title=\"Duplicate\"}\n\nThe existing entry is reinserted into the dynamic table without resending\neither the name or the value. This is useful to avoid adding a reference to an\nolder entry, which might block inserting new entries.\n\n\n## Decoder Instructions {#decoder-instructions}\n\nA decoder sends decoder instructions on the decoder stream to inform the encoder\nabout the processing of field sections and table updates to ensure consistency\nof the dynamic table.\n\n### Section Acknowledgment {#header-acknowledgment}\n\nAfter processing an encoded field section whose declared Required Insert Count\nis not zero, the decoder emits a Section Acknowledgment instruction.  The\ninstruction starts with the '1' 1-bit pattern, followed by the field\nsection's associated stream ID encoded as a 7-bit prefix integer; see\n{{prefixed-integers}}.\n\nThis instruction is used as described in Sections {{<known-received-count}} and\n{{<state-synchronization}}.\n\n~~~~~~~~~~ ascii-art\n  0   1   2   3   4   5   6   7\n+---+---+---+---+---+---+---+---+\n| 1 |      Stream ID (7+)       |\n+---+---------------------------+\n~~~~~~~~~~\n{:#fig-header-ack title=\"Section Acknowledgment\"}\n\nIf an encoder receives a Section Acknowledgment instruction referring to a\nstream on which every encoded field section with a non-zero Required Insert\nCount has already been acknowledged, this MUST be treated as a connection error\nof type QPACK_DECODER_STREAM_ERROR.\n\nThe Section Acknowledgment instruction might increase the Known Received Count;\nsee {{known-received-count}}.\n\n\n### Stream Cancellation\n\nWhen a stream is reset or reading is abandoned, the decoder emits a Stream\nCancellation instruction. The instruction starts with the '01' 2-bit\npattern, followed by the stream ID of the affected stream encoded as a\n6-bit prefix integer.\n\nThis instruction is used as described in {{state-synchronization}}.\n\n~~~~~~~~~~ ascii-art\n  0   1   2   3   4   5   6   7\n+---+---+---+---+---+---+---+---+\n| 0 | 1 |     Stream ID (6+)    |\n+---+---+-----------------------+\n~~~~~~~~~~\n{:#fig-stream-cancel title=\"Stream Cancellation\"}\n\n### Insert Count Increment\n\nThe Insert Count Increment instruction starts with the '00' 2-bit pattern,\nfollowed by the Increment encoded as a 6-bit prefix integer.  This instruction\nincreases the Known Received Count ({{known-received-count}}) by the value of\nthe Increment parameter.  The decoder should send an Increment value that\nincreases the Known Received Count to the total number of dynamic table\ninsertions and duplications processed so far.\n\n~~~~~~~~~~ ascii-art\n  0   1   2   3   4   5   6   7\n+---+---+---+---+---+---+---+---+\n| 0 | 0 |     Increment (6+)    |\n+---+---+-----------------------+\n~~~~~~~~~~\n{:#fig-size-sync title=\"Insert Count Increment\"}\n\nAn encoder that receives an Increment field equal to zero, or one that increases\nthe Known Received Count beyond what the encoder has sent, MUST treat this as a\nconnection error of type QPACK_DECODER_STREAM_ERROR.\n\n\n## Field Line Representations\n\nAn encoded field section consists of a prefix and a possibly empty sequence of\nrepresentations defined in this section.  Each representation corresponds to a\nsingle field line.  These representations reference the static table or the\ndynamic table in a particular state, but they do not modify that state.\n\nEncoded field sections are carried in frames on streams defined by the enclosing\nprotocol.\n\n### Encoded Field Section Prefix {#header-prefix}\n\nEach encoded field section is prefixed with two integers.  The Required Insert\nCount is encoded as an integer with an 8-bit prefix using the encoding described\nin {{ric}}.  The Base is encoded as a Sign bit ('S') and a Delta Base value\nwith a 7-bit prefix; see {{base}}.\n\n~~~~~~~~~~  ascii-art\n  0   1   2   3   4   5   6   7\n+---+---+---+---+---+---+---+---+\n|   Required Insert Count (8+)  |\n+---+---------------------------+\n| S |      Delta Base (7+)      |\n+---+---------------------------+\n|      Encoded Field Lines    ...\n+-------------------------------+\n~~~~~~~~~~\n{:#fig-base-index title=\"Encoded Field Section\"}\n\n\n#### Required Insert Count {#ric}\n\nRequired Insert Count identifies the state of the dynamic table needed to\nprocess the encoded field section.  Blocking decoders use the Required Insert\nCount to determine when it is safe to process the rest of the field section.\n\nThe encoder transforms the Required Insert Count as follows before encoding:\n\n~~~ pseudocode\n   if ReqInsertCount == 0:\n      EncInsertCount = 0\n   else:\n      EncInsertCount = (ReqInsertCount mod (2 * MaxEntries)) + 1\n~~~\n\nHere `MaxEntries` is the maximum number of entries that the dynamic table can\nhave.  The smallest entry has empty name and value strings and has the size of\n32.  Hence, `MaxEntries` is calculated as:\n\n~~~ pseudocode\n   MaxEntries = floor( MaxTableCapacity / 32 )\n~~~\n\n`MaxTableCapacity` is the maximum capacity of the dynamic table as specified by\nthe decoder; see {{maximum-dynamic-table-capacity}}.\n\nThis encoding limits the length of the prefix on long-lived connections.\n\nThe decoder can reconstruct the Required Insert Count using an algorithm such as\nthe following.  If the decoder encounters a value of EncodedInsertCount that\ncould not have been produced by a conformant encoder, it MUST treat this as a\nconnection error of type QPACK_DECOMPRESSION_FAILED.\n\n`TotalNumberOfInserts` is the total number of inserts into the decoder's dynamic\ntable.\n\n~~~ pseudocode\n   FullRange = 2 * MaxEntries\n   if EncodedInsertCount == 0:\n      ReqInsertCount = 0\n   else:\n      if EncodedInsertCount > FullRange:\n         Error\n      MaxValue = TotalNumberOfInserts + MaxEntries\n\n      # MaxWrapped is the largest possible value of\n      # ReqInsertCount that is 0 mod 2 * MaxEntries\n      MaxWrapped = floor(MaxValue / FullRange) * FullRange\n      ReqInsertCount = MaxWrapped + EncodedInsertCount - 1\n\n      # If ReqInsertCount exceeds MaxValue, the Encoder's value\n      # must have wrapped one fewer time\n      if ReqInsertCount > MaxValue:\n         if ReqInsertCount <= FullRange:\n            Error\n         ReqInsertCount -= FullRange\n\n      # Value of 0 must be encoded as 0.\n      if ReqInsertCount == 0:\n         Error\n~~~\n\nFor example, if the dynamic table is 100 bytes, then the Required Insert Count\nwill be encoded modulo 6.  If a decoder has received 10 inserts, then an encoded\nvalue of 4 indicates that the Required Insert Count is 9 for the field section.\n\n#### Base {#base}\n\nThe Base is used to resolve references in the dynamic table as described in\n{{relative-indexing}}.\n\nTo save space, the Base is encoded relative to the Required Insert Count using a\none-bit Sign ('S' in {{fig-base-index}}) and the Delta Base value.  A Sign bit\nof 0 indicates that the Base is greater than or equal to the value of the\nRequired Insert Count; the decoder adds the value of Delta Base to the Required\nInsert Count to determine the value of the Base.  A Sign bit of 1 indicates that\nthe Base is less than the Required Insert Count; the decoder subtracts the value\nof Delta Base from the Required Insert Count and also subtracts one to determine\nthe value of the Base. That is:\n\n~~~ pseudocode\n   if Sign == 0:\n      Base = ReqInsertCount + DeltaBase\n   else:\n      Base = ReqInsertCount - DeltaBase - 1\n~~~\n\nA single-pass encoder determines the Base before encoding a field section.  If\nthe encoder inserted entries in the dynamic table while encoding the field\nsection and is referencing them, Required Insert Count will be greater than the\nBase, so the encoded difference is negative and the Sign bit is set to 1.  If\nthe field section was not encoded using representations that reference the most\nrecent entry in the table and did not insert any new entries, the Base will be\ngreater than the Required Insert Count, so the encoded difference will be\npositive and the Sign bit is set to 0.\n\nThe value of Base MUST NOT be negative. Though the protocol might operate\ncorrectly with a negative Base using post-Base indexing, it is unnecessary and\ninefficient. An endpoint MUST treat a field block with a Sign bit of 1 as\ninvalid if the value of Required Insert Count is less than or equal to the value\nof Delta Base.\n\nAn encoder that produces table updates before encoding a field section might set\nBase to the value of Required Insert Count.  In such a case, both the Sign bit\nand the Delta Base will be set to zero.\n\nA field section that was encoded without references to the dynamic table can use\nany value for the Base; setting Delta Base to zero is one of the most efficient\nencodings.\n\nFor example, with a Required Insert Count of 9, a decoder receives a Sign bit\nof 1 and a Delta Base of 2.  This sets the Base to 6 and enables post-Base\nindexing for three entries.  In this example, a relative index of 1 refers to\nthe fifth entry that was added to the table; a post-Base index of 1 refers to\nthe eighth entry.\n\n\n### Indexed Field Line\n\nAn indexed field line representation identifies an entry in the static table\nor an entry in the dynamic table with an absolute index less than the value of\nthe Base.\n\n~~~~~~~~~~ ascii-art\n  0   1   2   3   4   5   6   7\n+---+---+---+---+---+---+---+---+\n| 1 | T |      Index (6+)       |\n+---+---+-----------------------+\n~~~~~~~~~~\n{: title=\"Indexed Field Line\"}\n\nThis representation starts with the '1' 1-bit pattern, followed by the 'T' bit,\nindicating whether the reference is into the static or dynamic table.  The 6-bit\nprefix integer ({{prefixed-integers}}) that follows is used to locate the\ntable entry for the field line.  When T=1, the number represents the static\ntable index; when T=0, the number is the relative index of the entry in the\ndynamic table.\n\n\n### Indexed Field Line with Post-Base Index\n\nAn indexed field line with post-Base index representation identifies an entry\nin the dynamic table with an absolute index greater than or equal to the value\nof the Base.\n\n~~~~~~~~~~ ascii-art\n  0   1   2   3   4   5   6   7\n+---+---+---+---+---+---+---+---+\n| 0 | 0 | 0 | 1 |  Index (4+)   |\n+---+---+---+---+---------------+\n~~~~~~~~~~\n{: title=\"Indexed Field Line with Post-Base Index\"}\n\nThis representation starts with the '0001' 4-bit pattern.  This is followed\nby the post-Base index ({{post-base}}) of the matching field line, represented\nas an integer with a 4-bit prefix; see {{prefixed-integers}}.\n\n\n### Literal Field Line with Name Reference {#literal-name-reference}\n\nA literal field line with name reference representation encodes a field line\nwhere the field name matches the field name of an entry in the static table or\nthe field name of an entry in the dynamic table with an absolute index less than\nthe value of the Base.\n\n~~~~~~~~~~ ascii-art\n     0   1   2   3   4   5   6   7\n   +---+---+---+---+---+---+---+---+\n   | 0 | 1 | N | T |Name Index (4+)|\n   +---+---+---+---+---------------+\n   | H |     Value Length (7+)     |\n   +---+---------------------------+\n   |  Value String (Length bytes)  |\n   +-------------------------------+\n~~~~~~~~~~\n{: title=\"Literal Field Line with Name Reference\"}\n\nThis representation starts with the '01' 2-bit pattern.  The following bit,\n'N', indicates whether an intermediary is permitted to add this field line to\nthe dynamic table on subsequent hops. When the 'N' bit is set, the encoded field\nline MUST always be encoded with a literal representation. In particular, when a\npeer sends a field line that it received represented as a literal field line\nwith the 'N' bit set, it MUST use a literal representation to forward this field\nline.  This bit is intended for protecting field values that are not to be put\nat risk by compressing them; see {{probing-dynamic-table-state}} for more\ndetails.\n\nThe fourth ('T') bit indicates whether the reference is to the static or dynamic\ntable.  The 4-bit prefix integer ({{prefixed-integers}}) that follows is used to\nlocate the table entry for the field name.  When T=1, the number represents the\nstatic table index; when T=0, the number is the relative index of the entry in\nthe dynamic table.\n\nOnly the field name is taken from the dynamic table entry; the field value is\nencoded as an 8-bit prefix string literal; see {{string-literals}}.\n\n\n### Literal Field Line with Post-Base Name Reference\n\nA literal field line with post-Base name reference representation encodes a\nfield line where the field name matches the field name of a dynamic table entry\nwith an absolute index greater than or equal to the value of the Base.\n\n~~~~~~~~~~ ascii-art\n     0   1   2   3   4   5   6   7\n   +---+---+---+---+---+---+---+---+\n   | 0 | 0 | 0 | 0 | N |NameIdx(3+)|\n   +---+---+---+---+---+-----------+\n   | H |     Value Length (7+)     |\n   +---+---------------------------+\n   |  Value String (Length bytes)  |\n   +-------------------------------+\n~~~~~~~~~~\n{: title=\"Literal Field Line with Post-Base Name Reference\"}\n\nThis representation starts with the '0000' 4-bit pattern.  The fifth bit is\nthe 'N' bit as described in {{literal-name-reference}}.  This is followed by a\npost-Base index of the dynamic table entry ({{post-base}}) encoded as an\ninteger with a 3-bit prefix; see {{prefixed-integers}}.\n\nOnly the field name is taken from the dynamic table entry; the field value is\nencoded as an 8-bit prefix string literal; see {{string-literals}}.\n\n\n### Literal Field Line with Literal Name\n\nThe literal field line with literal name representation encodes a\nfield name and a field value as string literals.\n\n~~~~~~~~~~ ascii-art\n     0   1   2   3   4   5   6   7\n   +---+---+---+---+---+---+---+---+\n   | 0 | 0 | 1 | N | H |NameLen(3+)|\n   +---+---+---+---+---+-----------+\n   |  Name String (Length bytes)   |\n   +---+---------------------------+\n   | H |     Value Length (7+)     |\n   +---+---------------------------+\n   |  Value String (Length bytes)  |\n   +-------------------------------+\n~~~~~~~~~~\n{: title=\"Literal Field Line with Literal Name\"}\n\nThis representation starts with the '001' 3-bit pattern.  The fourth bit is\nthe 'N' bit as described in {{literal-name-reference}}.  The name follows,\nrepresented as a 4-bit prefix string literal, then the value, represented as an\n8-bit prefix string literal; see {{string-literals}}.\n\n\n#  Configuration\n\nQPACK defines two settings for the HTTP/3 SETTINGS frame:\n\n  SETTINGS_QPACK_MAX_TABLE_CAPACITY (0x01):\n  : The default value is zero.  See {{header-table-dynamic}} for usage.  This is\n    the equivalent of the SETTINGS_HEADER_TABLE_SIZE from HTTP/2.\n\n  SETTINGS_QPACK_BLOCKED_STREAMS (0x07):\n  : The default value is zero.  See {{blocked-streams}}.\n\n\n# Error Handling {#error-handling}\n\nThe following error codes are defined for HTTP/3 to indicate failures of\nQPACK that prevent the stream or connection from continuing:\n\nQPACK_DECOMPRESSION_FAILED (0x0200):\n: The decoder failed to interpret an encoded field section and is not able to\n  continue decoding that field section.\n\nQPACK_ENCODER_STREAM_ERROR (0x0201):\n: The decoder failed to interpret an encoder instruction received on the\n  encoder stream.\n\nQPACK_DECODER_STREAM_ERROR (0x0202):\n: The encoder failed to interpret a decoder instruction received on the\n  decoder stream.\n\n\n# Security Considerations\n\nThis section describes potential areas of security concern with QPACK:\n\n * Use of compression as a length-based oracle for verifying guesses about\n   secrets that are compressed into a shared compression context.\n * Denial of service resulting from exhausting processing or memory capacity at\n   a decoder.\n\n## Probing Dynamic Table State\n\nQPACK reduces the encoded size of field sections by exploiting the redundancy\ninherent in protocols like HTTP. The ultimate goal of this is to reduce the\namount of data that is required to send HTTP requests or responses.\n\nThe compression context used to encode header and trailer fields can be probed\nby an attacker who can both define fields to be encoded and transmitted and\nobserve the length of those fields once they are encoded. When an attacker can\ndo both, they can adaptively modify requests in order to confirm guesses about\nthe dynamic table state. If a guess is compressed into a shorter length, the\nattacker can observe the encoded length and infer that the guess was correct.\n\nThis is possible even over the Transport Layer Security Protocol\n({{?TLS=RFC8446}}) and the QUIC Transport Protocol ({{QUIC-TRANSPORT}}), because\nwhile TLS and QUIC provide confidentiality protection for content, they only\nprovide a limited amount of protection for the length of that content.\n\n{:aside}\n> Note: Padding schemes only provide limited protection against an attacker with\nthese capabilities, potentially only forcing an increased number of guesses to\nlearn the length associated with a given guess. Padding schemes also work\ndirectly against compression by increasing the number of bits that are\ntransmitted.\n\nAttacks like CRIME ({{CRIME}}) demonstrated the existence of these general\nattacker capabilities. The specific attack exploited the fact that DEFLATE\n({{?RFC1951}}) removes redundancy based on prefix matching. This permitted the\nattacker to confirm guesses a character at a time, reducing an exponential-time\nattack into a linear-time attack.\n\n### Applicability to QPACK and HTTP\n\nQPACK mitigates, but does not completely prevent, attacks modeled on CRIME\n({{CRIME}}) by forcing a guess to match an entire field line rather than\nindividual characters. An attacker can only learn whether a guess is correct or\nnot, so the attacker is reduced to a brute-force guess for the field values\nassociated with a given field name.\n\nTherefore, the viability of recovering specific field values depends on the\nentropy of values. As a result, values with high entropy are unlikely to be\nrecovered successfully. However, values with low entropy remain vulnerable.\n\nAttacks of this nature are possible any time that two mutually distrustful\nentities control requests or responses that are placed onto a single HTTP/3\nconnection. If the shared QPACK compressor permits one entity to add entries to\nthe dynamic table, and the other to refer to those entries while encoding\nchosen field lines, then the attacker (the second entity) can learn the state\nof the table by observing the length of the encoded output.\n\nFor example, requests or responses from mutually distrustful entities can occur\nwhen an intermediary either:\n\n * sends requests from multiple clients on a single connection toward an origin\n   server, or\n\n * takes responses from multiple origin servers and places them on a shared\n   connection toward a client.\n\nWeb browsers also need to assume that requests made on the same connection by\ndifferent web origins ({{?RFC6454}}) are made by mutually distrustful entities.\nOther scenarios involving mutually distrustful entities are also possible.\n\n### Mitigation\n\nUsers of HTTP that require confidentiality for header or trailer fields can use\nvalues with entropy sufficient to make guessing infeasible. However, this is\nimpractical as a general solution because it forces all users of HTTP to take\nsteps to mitigate attacks. It would impose new constraints on how HTTP is used.\n\nRather than impose constraints on users of HTTP, an implementation of QPACK can\ninstead constrain how compression is applied in order to limit the potential for\ndynamic table probing.\n\nAn ideal solution segregates access to the dynamic table based on the entity\nthat is constructing the message. Field values that are added to the table are\nattributed to an entity, and only the entity that created a particular value can\nextract that value.\n\nTo improve compression performance of this option, certain entries might be\ntagged as being public. For example, a web browser might make the values of the\nAccept-Encoding header field available in all requests.\n\nAn encoder without good knowledge of the provenance of field values might\ninstead introduce a penalty for many field lines with the same field name and\ndifferent values.  This penalty could cause a large number of attempts to guess\na field value to result in the field not being compared to the dynamic table\nentries in future messages, effectively preventing further guesses.\n\nThis response might be made inversely proportional to the length of the\nfield value. Disabling access to the dynamic table for a given field name might\noccur for shorter values more quickly or with higher probability than for longer\nvalues.\n\nThis mitigation is most effective between two endpoints. If messages are\nre-encoded by an intermediary without knowledge of which entity constructed a\ngiven message, the intermediary could inadvertently merge compression contexts\nthat the original encoder had specifically kept separate.\n\n<aside><t>\nNote: Simply removing entries corresponding to the field from the dynamic table\ncan be ineffectual if the attacker has a reliable way of causing values to be\nreinstalled. For example, a request to load an image in a web browser typically\nincludes the Cookie header field (a potentially highly valued target for this\nsort of attack), and websites can easily force an image to be loaded, thereby\nrefreshing the entry in the dynamic table.\n</t></aside>\n\n### Never-Indexed Literals\n\nImplementations can also choose to protect sensitive fields by not compressing\nthem and instead encoding their value as literals.\n\nRefusing to insert a field line into the dynamic table is only effective if\ndoing so is avoided on all hops. The never-indexed literal bit (see\n{{literal-name-reference}}) can be used to signal to intermediaries that a\nparticular value was intentionally sent as a literal.\n\nAn intermediary MUST NOT re-encode a value that uses a literal representation\nwith the 'N' bit set with another representation that would index it. If QPACK\nis used for re-encoding, a literal representation with the 'N' bit set MUST be\nused.  If HPACK is used for re-encoding, the never-indexed literal\nrepresentation (see {{Section 6.2.3 of RFC7541}}) MUST be used.\n\nThe choice to mark that a field value should never be indexed depends on several\nfactors. Since QPACK does not protect against guessing an entire field value,\nshort or low-entropy values are more readily recovered by an adversary.\nTherefore, an encoder might choose not to index values with low entropy.\n\nAn encoder might also choose not to index values for fields that are considered\nto be highly valuable or sensitive to recovery, such as the Cookie or\nAuthorization header fields.\n\nOn the contrary, an encoder might prefer indexing values for fields that have\nlittle or no value if they were exposed. For instance, a User-Agent header field\ndoes not commonly vary between requests and is sent to any server. In that case,\nconfirmation that a particular User-Agent value has been used provides little\nvalue.\n\nNote that these criteria for deciding to use a never-indexed literal\nrepresentation will evolve over time as new attacks are discovered.\n\n## Static Huffman Encoding\n\nThere is no currently known attack against a static Huffman encoding. A study\nhas shown that using a static Huffman encoding table created an information\nleakage; however, this same study concluded that an attacker could not take\nadvantage of this information leakage to recover any meaningful amount of\ninformation (see {{PETAL}}).\n\n## Memory Consumption\n\nAn attacker can try to cause an endpoint to exhaust its memory. QPACK is\ndesigned to limit both the peak and stable amounts of memory allocated by an\nendpoint.\n\nQPACK uses the definition of the maximum size of the dynamic table and the\nmaximum number of blocking streams to limit the amount of memory the encoder can\ncause the decoder to consume. In HTTP/3, these values are controlled by the\ndecoder through the settings parameters SETTINGS_QPACK_MAX_TABLE_CAPACITY and\nSETTINGS_QPACK_BLOCKED_STREAMS, respectively (see\n{{maximum-dynamic-table-capacity}} and {{blocked-streams}}). The limit on the\nsize of the dynamic table takes into account the size of the data stored in the\ndynamic table, plus a small allowance for overhead.  The limit on the number of\nblocked streams is only a proxy for the maximum amount of memory required by the\ndecoder.  The actual maximum amount of memory will depend on how much memory the\ndecoder uses to track each blocked stream.\n\nA decoder can limit the amount of state memory used for the dynamic table by\nsetting an appropriate value for the maximum size of the dynamic table. In\nHTTP/3, this is realized by setting an appropriate value for the\nSETTINGS_QPACK_MAX_TABLE_CAPACITY parameter. An encoder can limit the amount of\nstate memory it uses by choosing a smaller dynamic table size than the decoder\nallows and signaling this to the decoder (see {{set-dynamic-capacity}}).\n\nA decoder can limit the amount of state memory used for blocked streams by\nsetting an appropriate value for the maximum number of blocked streams.  In\nHTTP/3, this is realized by setting an appropriate value for the\nSETTINGS_QPACK_BLOCKED_STREAMS parameter.  Streams that risk becoming blocked\nconsume no additional state memory on the encoder.\n\nAn encoder allocates memory to track all dynamic table references in\nunacknowledged field sections.  An implementation can directly limit the amount\nof state memory by only using as many references to the dynamic table as it\nwishes to track; no signaling to the decoder is required.  However, limiting\nreferences to the dynamic table will reduce compression effectiveness.\n\nThe amount of temporary memory consumed by an encoder or decoder can be limited\nby processing field lines sequentially. A decoder implementation does not need\nto retain a complete list of field lines while decoding a field section. An\nencoder implementation does not need to retain a complete list of field lines\nwhile encoding a field section if it is using a single-pass algorithm.  Note\nthat it might be necessary for an application to retain a complete list of field\nlines for other reasons; even if QPACK does not force this to occur, application\nconstraints might make this necessary.\n\nWhile the negotiated limit on the dynamic table size accounts for much of the\nmemory that can be consumed by a QPACK implementation, data that cannot be\nimmediately sent due to flow control is not affected by this limit.\nImplementations should limit the size of unsent data, especially on the decoder\nstream where flexibility to choose what to send is limited.  Possible responses\nto an excess of unsent data might include limiting the ability of the peer to\nopen new streams, reading only from the encoder stream, or closing the\nconnection.\n\n\n## Implementation Limits\n\nAn implementation of QPACK needs to ensure that large values for integers, long\nencoding for integers, or long string literals do not create security\nweaknesses.\n\nAn implementation has to set a limit for the values it accepts for integers, as\nwell as for the encoded length; see {{prefixed-integers}}. In the same way, it\nhas to set a limit to the length it accepts for string literals; see\n{{string-literals}}.  These limits SHOULD be large enough to process the\nlargest individual field the HTTP implementation can be configured to accept.\n\nIf an implementation encounters a value larger than it is able to decode, this\nMUST be treated as a stream error of type QPACK_DECOMPRESSION_FAILED if on a\nrequest stream or a connection error of the appropriate type if on the encoder\nor decoder stream.\n\n\n# IANA Considerations\n\nThis document makes multiple registrations in the registries defined by\n{{RFC9114}}. The allocations created by this document are all assigned permanent\nstatus and list a change controller of the IETF and a contact of the HTTP\nworking group (ietf-http-wg@w3.org).\n\n## Settings Registration\n\nThis document specifies two settings. The entries in the following table are\nregistered in the \"HTTP/3 Settings\" registry established in {{RFC9114}}.\n\n|------------------------------|--------|---------------------------| ------- |\n| Setting Name                 |  Code  | Specification             | Default |\n| ---------------------------- | :----: | ------------------------- | ------- |\n| QPACK_MAX_TABLE_CAPACITY     |  0x01  | {{configuration}}         | 0       |\n| QPACK_BLOCKED_STREAMS        |  0x07  | {{configuration}}         | 0       |\n| ---------------------------- | ------ | ------------------------- | ------- |\n{: title=\"Additions to the HTTP/3 Settings Registry\"}\n\nFor formatting reasons, the setting names here are abbreviated by removing the\n'SETTINGS_' prefix.\n\n## Stream Type Registration\n\nThis document specifies two stream types. The entries in the following table are\nregistered in the \"HTTP/3 Stream Types\" registry established in {{RFC9114}}.\n\n| ---------------------------- | ------ | ------------------------- | ------ |\n| Stream Type                  |  Code  | Specification             | Sender |\n| ---------------------------- | :----: | ------------------------- | ------ |\n| QPACK Encoder Stream         |  0x02  | {{enc-dec-stream-def}}    | Both   |\n| QPACK Decoder Stream         |  0x03  | {{enc-dec-stream-def}}    | Both   |\n| ---------------------------- | ------ | ------------------------- | ------ |\n{: title=\"Additions to the HTTP/3 Stream Types Registry\"}\n\n## Error Code Registration\n\nThis document specifies three error codes. The entries in the following table\nare registered in the \"HTTP/3 Error Codes\" registry established in {{RFC9114}}.\n\n| --------------------------------- | ------ | ---------------------------------------- | ---------------------- |\n| Name                              | Code   | Description                              | Specification          |\n| --------------------------------- | ------ | ---------------------------------------- | ---------------------- |\n| QPACK_DECOMPRESSION_FAILED        | 0x0200 | Decoding of a field section failed       | {{error-handling}}     |\n| QPACK_ENCODER_STREAM_ERROR        | 0x0201 | Error on the encoder stream              | {{error-handling}}     |\n| QPACK_DECODER_STREAM_ERROR        | 0x0202 | Error on the decoder stream              | {{error-handling}}     |\n| --------------------------------- | ------ | ---------------------------------------- | ---------------------- |\n{: title=\"Additions to the HTTP/3 Error Codes Registry\"}\n\n--- back\n\n# Static Table\n\nThis table was generated by analyzing actual Internet traffic in 2018 and\nincluding the most common header fields, after filtering out some unsupported\nand non-standard values. Due to this methodology, some of the entries may be\ninconsistent or appear multiple times with similar but not identical values. The\norder of the entries is optimized to encode the most common header fields with\nthe smallest number of bytes.\n\n| Index | Name                             | Value                                                       |\n| ----- | -------------------------------- | ----------------------------------------------------------- |\n| 0     | :authority                       |                                                             |\n| 1     | :path                            | /                                                           |\n| 2     | age                              | 0                                                           |\n| 3     | content-disposition              |                                                             |\n| 4     | content-length                   | 0                                                           |\n| 5     | cookie                           |                                                             |\n| 6     | date                             |                                                             |\n| 7     | etag                             |                                                             |\n| 8     | if-modified-since                |                                                             |\n| 9     | if-none-match                    |                                                             |\n| 10    | last-modified                    |                                                             |\n| 11    | link                             |                                                             |\n| 12    | location                         |                                                             |\n| 13    | referer                          |                                                             |\n| 14    | set-cookie                       |                                                             |\n| 15    | :method                          | CONNECT                                                     |\n| 16    | :method                          | DELETE                                                      |\n| 17    | :method                          | GET                                                         |\n| 18    | :method                          | HEAD                                                        |\n| 19    | :method                          | OPTIONS                                                     |\n| 20    | :method                          | POST                                                        |\n| 21    | :method                          | PUT                                                         |\n| 22    | :scheme                          | http                                                        |\n| 23    | :scheme                          | https                                                       |\n| 24    | :status                          | 103                                                         |\n| 25    | :status                          | 200                                                         |\n| 26    | :status                          | 304                                                         |\n| 27    | :status                          | 404                                                         |\n| 28    | :status                          | 503                                                         |\n| 29    | accept                           | \\*/\\*                                                       |\n| 30    | accept                           | application/dns-message                                     |\n| 31    | accept-encoding                  | gzip, deflate, br                                           |\n| 32    | accept-ranges                    | bytes                                                       |\n| 33    | access-control-allow-headers     | cache-control                                               |\n| 34    | access-control-allow-headers     | content-type                                                |\n| 35    | access-control-allow-origin      | \\*                                                          |\n| 36    | cache-control                    | max-age=0                                                   |\n| 37    | cache-control                    | max-age=2592000                                             |\n| 38    | cache-control                    | max-age=604800                                              |\n| 39    | cache-control                    | no-cache                                                    |\n| 40    | cache-control                    | no-store                                                    |\n| 41    | cache-control                    | public, max-age=31536000                                    |\n| 42    | content-encoding                 | br                                                          |\n| 43    | content-encoding                 | gzip                                                        |\n| 44    | content-type                     | application/dns-message                                     |\n| 45    | content-type                     | application/javascript                                      |\n| 46    | content-type                     | application/json                                            |\n| 47    | content-type                     | application/x-www-form-urlencoded                           |\n| 48    | content-type                     | image/gif                                                   |\n| 49    | content-type                     | image/jpeg                                                  |\n| 50    | content-type                     | image/png                                                   |\n| 51    | content-type                     | text/css                                                    |\n| 52    | content-type                     | text/html; charset=utf-8                                    |\n| 53    | content-type                     | text/plain                                                  |\n| 54    | content-type                     | text/plain;charset=utf-8                                    |\n| 55    | range                            | bytes=0-                                                    |\n| 56    | strict-transport-security        | max-age=31536000                                            |\n| 57    | strict-transport-security        | max-age=31536000; includesubdomains                         |\n| 58    | strict-transport-security        | max-age=31536000; includesubdomains; preload                |\n| 59    | vary                             | accept-encoding                                             |\n| 60    | vary                             | origin                                                      |\n| 61    | x-content-type-options           | nosniff                                                     |\n| 62    | x-xss-protection                 | 1; mode=block                                               |\n| 63    | :status                          | 100                                                         |\n| 64    | :status                          | 204                                                         |\n| 65    | :status                          | 206                                                         |\n| 66    | :status                          | 302                                                         |\n| 67    | :status                          | 400                                                         |\n| 68    | :status                          | 403                                                         |\n| 69    | :status                          | 421                                                         |\n| 70    | :status                          | 425                                                         |\n| 71    | :status                          | 500                                                         |\n| 72    | accept-language                  |                                                             |\n| 73    | access-control-allow-credentials | FALSE                                                       |\n| 74    | access-control-allow-credentials | TRUE                                                        |\n| 75    | access-control-allow-headers     | \\*                                                          |\n| 76    | access-control-allow-methods     | get                                                         |\n| 77    | access-control-allow-methods     | get, post, options                                          |\n| 78    | access-control-allow-methods     | options                                                     |\n| 79    | access-control-expose-headers    | content-length                                              |\n| 80    | access-control-request-headers   | content-type                                                |\n| 81    | access-control-request-method    | get                                                         |\n| 82    | access-control-request-method    | post                                                        |\n| 83    | alt-svc                          | clear                                                       |\n| 84    | authorization                    |                                                             |\n| 85    | content-security-policy          | script-src \\'none\\'; object-src \\'none\\'; base-uri \\'none\\' |\n| 86    | early-data                       | 1                                                           |\n| 87    | expect-ct                        |                                                             |\n| 88    | forwarded                        |                                                             |\n| 89    | if-range                         |                                                             |\n| 90    | origin                           |                                                             |\n| 91    | purpose                          | prefetch                                                    |\n| 92    | server                           |                                                             |\n| 93    | timing-allow-origin              | \\*                                                          |\n| 94    | upgrade-insecure-requests        | 1                                                           |\n| 95    | user-agent                       |                                                             |\n| 96    | x-forwarded-for                  |                                                             |\n| 97    | x-frame-options                  | deny                                                        |\n| 98    | x-frame-options                  | sameorigin                                                  |\n{: title=\"Static Table\"}\n\nAny line breaks that appear within field names or values are due to formatting.\n\n\n# Encoding and Decoding Examples\n\nThe following examples represent a series of exchanges between an encoder and a\ndecoder.  The exchanges are designed to exercise most QPACK instructions and\nhighlight potentially common patterns and their impact on dynamic table state.\nThe encoder sends three encoded field sections containing one field line each,\nas well as two speculative inserts that are not referenced.\n\nThe state of the encoder's dynamic table is shown, along with its\ncurrent size.  Each entry is shown with the Absolute Index of the entry (Abs),\nthe current number of outstanding encoded field sections with references to that\nentry (Ref), along with the name and value.  Entries above the 'acknowledged'\nline have been acknowledged by the decoder.\n\n## Literal Field Line with Name Reference\n\nThe encoder sends an encoded field section containing a literal representation\nof a field with a static name reference.\n\n~~~\nData                | Interpretation\n                             | Encoder's Dynamic Table\n\nStream: 0\n0000                | Required Insert Count = 0, Base = 0\n510b 2f69 6e64 6578 | Literal Field Line with Name Reference\n2e68 746d 6c        |  Static Table, Index=1\n                    |  (:path=/index.html)\n\n                              Abs Ref Name        Value\n                              ^-- acknowledged --^\n                              Size=0\n~~~\n\n## Dynamic Table\n\nThe encoder sets the dynamic table capacity, inserts a header with a dynamic\nname reference, then sends a potentially blocking, encoded field section\nreferencing this new entry.  The decoder acknowledges processing the encoded\nfield section, which implicitly acknowledges all dynamic table insertions up to\nthe Required Insert Count.\n\n~~~\nStream: Encoder\n3fbd01              | Set Dynamic Table Capacity=220\nc00f 7777 772e 6578 | Insert With Name Reference\n616d 706c 652e 636f | Static Table, Index=0\n6d                  |  (:authority=www.example.com)\nc10c 2f73 616d 706c | Insert With Name Reference\n652f 7061 7468      |  Static Table, Index=1\n                    |  (:path=/sample/path)\n\n                              Abs Ref Name        Value\n                              ^-- acknowledged --^\n                               0   0  :authority  www.example.com\n                               1   0  :path       /sample/path\n                              Size=106\n\nStream: 4\n0381                | Required Insert Count = 2, Base = 0\n10                  | Indexed Field Line With Post-Base Index\n                    |  Absolute Index = Base(0) + Index(0) = 0\n                    |  (:authority=www.example.com)\n11                  | Indexed Field Line With Post-Base Index\n                    |  Absolute Index = Base(0) + Index(1) = 1\n                    |  (:path=/sample/path)\n\n                              Abs Ref Name        Value\n                              ^-- acknowledged --^\n                               0   1  :authority  www.example.com\n                               1   1  :path       /sample/path\n                              Size=106\n\nStream: Decoder\n84                  | Section Acknowledgment (stream=4)\n\n                              Abs Ref Name        Value\n                               0   0  :authority  www.example.com\n                               1   0  :path       /sample/path\n                              ^-- acknowledged --^\n                              Size=106\n~~~\n\n## Speculative Insert\n\nThe encoder inserts a header into the dynamic table with a literal name.\nThe decoder acknowledges receipt of the entry.  The encoder does not send\nany encoded field sections.\n\n~~~\nStream: Encoder\n4a63 7573 746f 6d2d | Insert With Literal Name\n6b65 790c 6375 7374 |  (custom-key=custom-value)\n6f6d 2d76 616c 7565 |\n\n                              Abs Ref Name        Value\n                               0   0  :authority  www.example.com\n                               1   0  :path       /sample/path\n                              ^-- acknowledged --^\n                               2   0  custom-key  custom-value\n                              Size=160\n\nStream: Decoder\n01                  | Insert Count Increment (1)\n\n                              Abs Ref Name        Value\n                               0   0  :authority  www.example.com\n                               1   0  :path       /sample/path\n                               2   0  custom-key  custom-value\n                              ^-- acknowledged --^\n                              Size=160\n\n~~~\n\n## Duplicate Instruction, Stream Cancellation\n\nThe encoder duplicates an existing entry in the dynamic table, then sends an\nencoded field section referencing the dynamic table entries including the\nduplicated entry.  The packet containing the encoder stream data is delayed.\nBefore the packet arrives, the decoder cancels the stream and notifies the\nencoder that the encoded field section was not processed.\n\n~~~\nStream: Encoder\n02                  | Duplicate (Relative Index = 2)\n                    |  Absolute Index =\n                    |   Insert Count(3) - Index(2) - 1 = 0\n\n                              Abs Ref Name        Value\n                               0   0  :authority  www.example.com\n                               1   0  :path       /sample/path\n                               2   0  custom-key  custom-value\n                              ^-- acknowledged --^\n                               3   0  :authority  www.example.com\n                              Size=217\n\nStream: 8\n0500                | Required Insert Count = 4, Base = 4\n80                  | Indexed Field Line, Dynamic Table\n                    |  Absolute Index = Base(4) - Index(0) - 1 = 3\n                    |  (:authority=www.example.com)\nc1                  | Indexed Field Line, Static Table Index = 1\n                    |  (:path=/)\n81                  | Indexed Field Line, Dynamic Table\n                    |  Absolute Index = Base(4) - Index(1) - 1 = 2\n                    |  (custom-key=custom-value)\n\n                              Abs Ref Name        Value\n                               0   0  :authority  www.example.com\n                               1   0  :path       /sample/path\n                               2   1  custom-key  custom-value\n                              ^-- acknowledged --^\n                               3   1  :authority  www.example.com\n                              Size=217\n\nStream: Decoder\n48                  | Stream Cancellation (Stream=8)\n\n                              Abs Ref Name        Value\n                               0   0  :authority  www.example.com\n                               1   0  :path       /sample/path\n                               2   0  custom-key  custom-value\n                              ^-- acknowledged --^\n                               3   0  :authority  www.example.com\n                              Size=217\n~~~\n\n## Dynamic Table Insert, Eviction\n\nThe encoder inserts another header into the dynamic table, which evicts the\noldest entry.  The encoder does not send any encoded field sections.\n\n~~~\nStream: Encoder\n810d 6375 7374 6f6d | Insert With Name Reference\n2d76 616c 7565 32   |  Dynamic Table, Relative Index = 1\n                    |  Absolute Index =\n                    |   Insert Count(4) - Index(1) - 1 = 2\n                    |  (custom-key=custom-value2)\n\n                              Abs Ref Name        Value\n                               1   0  :path       /sample/path\n                               2   0  custom-key  custom-value\n                              ^-- acknowledged --^\n                               3   0  :authority  www.example.com\n                               4   0  custom-key  custom-value2\n                              Size=215\n~~~\n\n# Sample Single-Pass Encoding Algorithm\n\nPseudocode for single-pass encoding, excluding handling of duplicates,\nnon-blocking mode, available encoder stream flow control and reference tracking.\n\n~~~ pseudocode\n# Helper functions:\n# ====\n# Encode an integer with the specified prefix and length\nencodeInteger(buffer, prefix, value, prefixLength)\n\n# Encode a dynamic table insert instruction with optional static\n# or dynamic name index (but not both)\nencodeInsert(buffer, staticNameIndex, dynamicNameIndex, fieldLine)\n\n# Encode a static index reference\nencodeStaticIndexReference(buffer, staticIndex)\n\n# Encode a dynamic index reference relative to Base\nencodeDynamicIndexReference(buffer, dynamicIndex, base)\n\n# Encode a literal with an optional static name index\nencodeLiteral(buffer, staticNameIndex, fieldLine)\n\n# Encode a literal with a dynamic name index relative to Base\nencodeDynamicLiteral(buffer, dynamicNameIndex, base, fieldLine)\n\n# Encoding Algorithm\n# ====\nbase = dynamicTable.getInsertCount()\nrequiredInsertCount = 0\nfor line in fieldLines:\n  staticIndex = staticTable.findIndex(line)\n  if staticIndex is not None:\n    encodeStaticIndexReference(streamBuffer, staticIndex)\n    continue\n\n  dynamicIndex = dynamicTable.findIndex(line)\n  if dynamicIndex is None:\n    # No matching entry.  Either insert+index or encode literal\n    staticNameIndex = staticTable.findName(line.name)\n    if staticNameIndex is None:\n       dynamicNameIndex = dynamicTable.findName(line.name)\n\n    if shouldIndex(line) and dynamicTable.canIndex(line):\n      encodeInsert(encoderBuffer, staticNameIndex,\n                   dynamicNameIndex, line)\n      dynamicIndex = dynamicTable.add(line)\n\n  if dynamicIndex is None:\n    # Could not index it, literal\n    if dynamicNameIndex is not None:\n      # Encode literal with dynamic name, possibly above Base\n      encodeDynamicLiteral(streamBuffer, dynamicNameIndex,\n                           base, line)\n      requiredInsertCount = max(requiredInsertCount,\n                                dynamicNameIndex)\n    else:\n      # Encodes a literal with a static name or literal name\n      encodeLiteral(streamBuffer, staticNameIndex, line)\n  else:\n    # Dynamic index reference\n    assert(dynamicIndex is not None)\n    requiredInsertCount = max(requiredInsertCount, dynamicIndex)\n    # Encode dynamicIndex, possibly above Base\n    encodeDynamicIndexReference(streamBuffer, dynamicIndex, base)\n\n# encode the prefix\nif requiredInsertCount == 0:\n  encodeInteger(prefixBuffer, 0x00, 0, 8)\n  encodeInteger(prefixBuffer, 0x00, 0, 7)\nelse:\n  wireRIC = (\n    requiredInsertCount\n    % (2 * getMaxEntries(maxTableCapacity))\n  ) + 1;\n  encodeInteger(prefixBuffer, 0x00, wireRIC, 8)\n  if base >= requiredInsertCount:\n    encodeInteger(prefixBuffer, 0x00,\n                  base - requiredInsertCount, 7)\n  else:\n    encodeInteger(prefixBuffer, 0x80,\n                  requiredInsertCount - base - 1, 7)\n\nreturn encoderBuffer, prefixBuffer + streamBuffer\n~~~\n\n\n# Acknowledgments\n{:numbered=\"false\"}\n\nThe IETF QUIC Working Group received an enormous amount of support from many\npeople.\n\nThe compression design team did substantial work exploring the problem space and\ninfluencing the initial draft version of this document.  The contributions of\ndesign team members {{{Roberto Peon}}}, {{{Martin Thomson}}}, and\n{{{Dmitri Tikhonov}}} are gratefully acknowledged.\n\nThe following people also provided substantial contributions to this document:\n\n{:compact}\n- <t>{{{Bence Béky}}}</t>\n- <t>{{{Alessandro Ghedini}}}</t>\n- <t>{{{Ryan Hamilton}}}</t>\n- <t>{{{Robin Marx}}}</t>\n- <t>{{{Patrick McManus}}}</t>\n- <t>{{{Kazuho Oku}{奥 一穂}}}</t>\n- <t>{{{Lucas Pardue}}}</t>\n- <t>{{{Biren Roy}}}</t>\n- <t>{{{Ian Swett}}}</t>\n\nThis document draws heavily on the text of {{!RFC7541}}.  The indirect input of\nthose authors is also gratefully acknowledged.\n\n{{{Buck Krasic}}}'s contribution was supported by Google during his employment\nthere.\n\nA portion of {{{Mike Bishop}}}'s contribution was supported by Microsoft during\nhis employment there.\n"
        },
        {
          "name": "tag.sh",
          "type": "blob",
          "size": 1.1240234375,
          "content": "# Tag files for submission.\n#\n# You shouldn't need to use this unless you are tagging files for which you are\n# not an author.  Use `git tag -a` instead.\n#\n# This script exists because\n# https://trac.tools.ietf.org/tools/ietfdb/ticket/2390 still isn't fixed.\n\nif [[ $# -eq 0 ]]; then\n    files=(invariants transport tls recovery http qpack)\nelse\n    files=(\"$@\")\nfi\n\nenabled() {\n    r=\"$1\"; shift\n    for e; do [[ \"$e\" == \"$r\" ]] && return 0; done\n    return 1\n}\n\ndeclare -A authors=( \\\n    [transport]=mt@lowentropy.net \\\n    [tls]=mt@lowentropy.net \\\n    [recovery]=ianswett@google.com \\\n    [http]=mbishop@evequefou.be \\\n    [invariants]=mt@lowentropy.net \\\n    [qpack]=afrind@fb.com \\\n)\n\nif ! make; then\n    echo \"FAILED TO BUILD STOP\" 1>&2\n    exit 1\nfi\n\nall=($(make show-next))\ntags=()\nthisuser=$(git config --get user.name)\n\nfor t in \"${all[@]}\"; do\n    r=\"${t%-[0-9][0-9]}\"\n    r=\"${r#draft-ietf-quic-}\"\n    if enabled \"$r\" \"${files[@]}\"; then\n        message=\"Tag for $t created by $thisuser\"\n        git -c user.email=\"${authors[$r]}\" tag -am \"$message\" \"$t\"\n\ttags+=(\"$t\")\n    fi\ndone\nfor t in \"${tags[@]}\"; do\n    git push origin \"$t\"\ndone\n"
        },
        {
          "name": "writeups",
          "type": "tree",
          "content": null
        },
        {
          "name": "xml2rfc-tidy.py",
          "type": "blob",
          "size": 3.6416015625,
          "content": "#!/usr/bin/env python3\n# Tidy an xml2rfc file.\n#\n# This:\n# * removes non-semantic content (comments, processing instructions, DOCTYPE\n#   declarations, broken entity references)\n# * wraps BCP 14 language in <bcp14> elements\n# * indents elements neatly\n\nimport sys\nimport xml.sax\nimport re\nfrom xml.sax.saxutils import escape, quoteattr\n\n\nclass Tidy(xml.sax.handler.ContentHandler):\n    pattern = re.compile(\n        r\"\\b((?:(?:MUST|SHOULD|SHALL)(?:\\s+NOT)?)|(?:(?:NOT\\s+)?RECOMMENDED)|MAY|OPTIONAL|REQUIRED)\\b\"\n    )\n\n    def __init__(self):\n        self.tags = []\n        self.nesting = 0\n        self.c = \"\"\n        self.state = \"\"\n\n    def startDocument(self):\n        print('<?xml version=\"1.0\" encoding=\"UTF-8\"?>')\n\n    def preserve(tag):\n        return tag in [\"artwork\", \"sourcecode\"]\n\n    def textElement(tag):\n        return tag in [\n            \"annotation\",\n            \"blockquote\",\n            \"dd\",\n            \"dt\",\n            \"em\",\n            \"li\",\n            \"preamble\",\n            \"refcontent\",\n            \"strong\",\n            \"sub\",\n            \"sup\",\n            \"t\",\n            \"td\",\n            \"th\",\n            \"tt\",\n        ]\n\n    def inline(tag):\n        return tag in [\n            \"code\",\n            \"contact\",\n            \"cref\",\n            \"em\",\n            \"eref\",\n            \"iref\",\n            \"sub\",\n            \"sup\",\n            \"tt\",\n            \"xref\",\n        ]\n\n    def flush(self, tag, start=None):\n        if Tidy.preserve(tag):\n            c = f\"<![CDATA[{self.c}]]>\"\n        else:\n            c = escape(self.c)\n            if Tidy.textElement(tag):\n                if self.state == \"open\":\n                    # The element is opening, so strip left is safe.\n                    c = c.lstrip()\n                if start is None or not Tidy.inline(start):\n                    # The element is closing, or the element that is starting\n                    # isn't inline, so strip right is safe.\n                    c = c.rstrip()\n                c = Tidy.pattern.sub(r\"<bcp14>\\1</bcp14>\", c)\n            else:\n                c = c.strip()\n\n        if c != \"\":\n            if self.state == \"open\":\n                print(\">\", end=\"\")\n            print(c, end=\"\")\n            self.state = \"text\"\n            self.nl = False\n\n        self.c = \"\"\n\n    def currentTag(self):\n        return next(reversed(self.tags), False)\n\n    def startElement(self, tag, attributes):\n        parent = self.currentTag()\n        self.flush(parent, tag)\n\n        if self.state == \"open\":\n            print(\">\", end=\"\")\n            if not Tidy.inline(tag):\n                print()\n\n        self.tags.append(tag)\n        if not Tidy.inline(tag):\n            print(\"  \" * self.nesting, end=\"\")\n            self.nesting = self.nesting + 1\n\n        print(f\"<{tag}\", end=\"\")\n        for name, value in attributes.items():\n            print(f\" {name}={quoteattr(value)}\", end=\"\")\n\n        self.state = \"open\"\n        self.nl = False\n\n    def endElement(self, tag):\n        self.flush(self.tags.pop())\n\n        if not Tidy.inline(tag):\n            self.nesting = self.nesting - 1\n            if self.nl and not Tidy.inline(self.currentTag()):\n                print(\"  \" * self.nesting, end=\"\")\n        if self.state == \"open\":\n            print(\"/>\", end=\"\")\n        else:\n            print(f\"</{tag}>\", end=\"\")\n        self.nl = not Tidy.inline(tag)\n        if self.nl:\n            print()\n        self.state = \"close\"\n\n    def characters(self, content):\n        self.c = self.c + content\n\n    def processingInstruction(self, target, data):\n        pass\n\n\nparser = xml.sax.make_parser()\nparser.setContentHandler(Tidy())\nif len(sys.argv) >= 2:\n    parser.parse(sys.argv[1])\nelse:\n    parser.parse(sys.stdin)\n"
        }
      ]
    }
  ]
}