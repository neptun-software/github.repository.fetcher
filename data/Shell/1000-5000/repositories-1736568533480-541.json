{
  "metadata": {
    "timestamp": 1736568533480,
    "page": 541,
    "hasNextPage": true,
    "endCursor": "Y3Vyc29yOjU0OQ==",
    "completionStatus": "IN_PROGRESS"
  },
  "repositories": [
    {
      "nameWithOwner": "kward/shunit2",
      "stars": 1620,
      "defaultBranch": "master",
      "files": [
        {
          "name": ".editorconfig",
          "type": "blob",
          "size": 0.2060546875,
          "content": "# EditorConfig for shUnit2.\n# https://EditorConfig.org\n\nroot = true\n\n[*]\ncharset = utf-8\nend_of_line = lf\ninsert_final_newline = true\ntrim_trailing_whitespace = true\n\n[*.sh]\nindent_style = space\nindent_size = 2\n"
        },
        {
          "name": ".githooks",
          "type": "tree",
          "content": null
        },
        {
          "name": ".gitignore",
          "type": "blob",
          "size": 0.0478515625,
          "content": "# Hidden files generated by macOS.\n.DS_Store\n._*\n"
        },
        {
          "name": ".shellcheckrc",
          "type": "blob",
          "size": 0.2626953125,
          "content": "# ShellCheck (https://www.shellcheck.net/)\n#\n# This file is supported as of shellcheck v0.7.0.\n#\n# TODO(kward): Remove equivalent references in `*_test.sh` from file once\n#   Travis CI upgrades its shellcheck version.\n\n# Disable source following.\ndisable=SC1090,SC1091\n"
        },
        {
          "name": ".travis.yml",
          "type": "blob",
          "size": 1.0234375,
          "content": "language: bash\n\nenv:\n  - SHUNIT_COLOR='always'\n\nscript:\n  # Execute the unit tests.\n  - ./test_runner\n\naddons:\n  apt:\n    packages:\n      - ksh\n      - mksh\n      - zsh\n\nmatrix:\n  include:\n    ### Ubuntu (https://en.wikipedia.org/wiki/Ubuntu).\n    - os: linux\n      # Support Ubuntu Focal 20.04 through at least Apr 2025.\n      dist: focal\n    - os: linux\n      # Support Ubuntu Bionic 18.04 through at least Apr 2023.\n      dist: bionic\n    - os: linux\n      # Support Ubuntu Xenial 16.04 through at least Apr 2021.\n      dist: xenial\n    - os: linux\n      # Support Ubuntu Trusty 14.04 through at least Apr 2019.\n      dist: trusty\n\n    ### Other OSes.\n    # [2021-10-22 kward] Disable FreeBSD builds until they actually work.\n    #- os: freebsd\n    - os: osx\n\n    ### Run the source through ShellCheck (http://www.shellcheck.net).\n    - os: linux\n      script:\n        - shellcheck shunit2 *_test.sh\n        - shellcheck -s sh shunit2_test_helpers\n\nbranches:\n  only:\n  - master\n  - 2.1.x\n  # Tags, e.g. v.2.1.8.\n  - /^v\\d+\\.\\d+(\\.\\d+)?(-\\S*)?$/\n"
        },
        {
          "name": "CODE_OF_CONDUCT.md",
          "type": "blob",
          "size": 3.14453125,
          "content": "# Contributor Covenant Code of Conduct\n\n## Our Pledge\n\nIn the interest of fostering an open and welcoming environment, we as contributors and maintainers pledge to making participation in our project and our community a harassment-free experience for everyone, regardless of age, body size, disability, ethnicity, gender identity and expression, level of experience, nationality, personal appearance, race, religion, or sexual identity and orientation.\n\n## Our Standards\n\nExamples of behavior that contributes to creating a positive environment include:\n\n* Using welcoming and inclusive language\n* Being respectful of differing viewpoints and experiences\n* Gracefully accepting constructive criticism\n* Focusing on what is best for the community\n* Showing empathy towards other community members\n\nExamples of unacceptable behavior by participants include:\n\n* The use of sexualized language or imagery and unwelcome sexual attention or advances\n* Trolling, insulting/derogatory comments, and personal or political attacks\n* Public or private harassment\n* Publishing others' private information, such as a physical or electronic address, without explicit permission\n* Other conduct which could reasonably be considered inappropriate in a professional setting\n\n## Our Responsibilities\n\nProject maintainers are responsible for clarifying the standards of acceptable behavior and are expected to take appropriate and fair corrective action in response to any instances of unacceptable behavior.\n\nProject maintainers have the right and responsibility to remove, edit, or reject comments, commits, code, wiki edits, issues, and other contributions that are not aligned to this Code of Conduct, or to ban temporarily or permanently any contributor for other behaviors that they deem inappropriate, threatening, offensive, or harmful.\n\n## Scope\n\nThis Code of Conduct applies both within project spaces and in public spaces when an individual is representing the project or its community. Examples of representing a project or community include using an official project e-mail address, posting via an official social media account, or acting as an appointed representative at an online or offline event. Representation of a project may be further defined and clarified by project maintainers.\n\n## Enforcement\n\nInstances of abusive, harassing, or otherwise unacceptable behavior may be reported by contacting the project team at kate.ward@forestent.com. The project team will review and investigate all complaints, and will respond in a way that it deems appropriate to the circumstances. The project team is obligated to maintain confidentiality with regard to the reporter of an incident. Further details of specific enforcement policies may be posted separately.\n\nProject maintainers who do not follow or enforce the Code of Conduct in good faith may face temporary or permanent repercussions as determined by other members of the project's leadership.\n\n## Attribution\n\nThis Code of Conduct is adapted from the [Contributor Covenant][homepage], version 1.4, available at [http://contributor-covenant.org/version/1/4][version]\n\n[homepage]: http://contributor-covenant.org\n[version]: http://contributor-covenant.org/version/1/4/\n"
        },
        {
          "name": "CONTRIBUTING.md",
          "type": "blob",
          "size": 4.7939453125,
          "content": "Coding Standards\n================\n\nshFlags is more than just a simple 20 line shell script. It is a pretty\nsignificant library of shell code that at first glance is not that easy to\nunderstand. To improve code readability and usability, some guidelines have been\nset down to make the code more understandable for anyone who wants to read or\nmodify it.\n\nFunction declaration\n--------------------\n\nDeclare functions using the following form:\n\n```sh\ndoSomething() {\n  echo 'done!'\n}\n```\n\nOne-line functions are allowed if they can fit within the 80 char line limit.\n\n```sh\ndoSomething() { echo 'done!'; }\n```\n\nFunction documentation\n----------------------\n\nEach function should be preceded by a header that provides the following:\n\n1. A one-sentence summary of what the function does.\n\n1. (optional) A longer description of what the function does, and perhaps some\n   special information that helps convey its usage better.\n\n1. Args: a one-line summary of each argument of the form:\n\n   `name: type: description`\n\n1. Output: a one-line summary of the output provided. Only output to STDOUT\n   must be documented, unless the output to STDERR is of significance (i.e. not\n   just an error message). The output should be of the form:\n\n   `type: description`\n\n1. Returns: a one-line summary of the value returned. Returns in shell are\n   always integers, but if the output is a true/false for success (i.e. a\n   boolean), it should be noted. The output should be of the form:\n\n   `type: description`\n\nHere is a sample header:\n\n```\n# Return valid getopt options using currently defined list of long options.\n#\n# This function builds a proper getopt option string for short (and long)\n# options, using the current list of long options for reference.\n#\n# Args:\n#   _flags_optStr: integer: option string type (__FLAGS_OPTSTR_*)\n# Output:\n#   string: generated option string for getopt\n# Returns:\n#   boolean: success of operation (always returns True)\n```\n\nVariable and function names\n---------------------------\n\nAll shFlags specific constants, variables, and functions will be prefixed\nappropriately with 'flags'. This is to distinguish usage in the shFlags code\nfrom users own scripts so that the shell name space remains predictable to\nusers. The exceptions here are the standard `assertEquals`, etc. functions.\n\nAll non built-in constants and variables will be surrounded with squiggle\nbrackets, e.g. `${flags_someVariable}` to improve code readability.\n\nDue to some shells not supporting local variables in functions, care in the\nnaming and use of variables, both public and private, is very important.\nAccidental overriding of the variables can occur easily if care is not taken as\nall variables are technically global variables in some shells.\n\nType | Sample\n---- | ------\nglobal public constant           | `FLAGS_TRUE`\nglobal private constant          | `__FLAGS_SHELL_FLAGS`\nglobal public variable           | `flags_variable`\nglobal private variable          | `__flags_variable`\nglobal macro                     | `_FLAGS_SOME_MACRO_`\npublic function                  | `flags_function`\npublic function, local variable  | `flags_variable_`\nprivate function                 | `_flags_function`\nprivate function, local variable | `_flags_variable_`\n\nWhere it makes sense to improve readability, variables can have the first\nletter of the second and later words capitalized. For example, the local\nvariable name for the help string length is `flags_helpStrLen_`.\n\nThere are three special-case global public variables used. They are used due to\novercome the limitations of shell scoping or to prevent forking. The three\nvariables are:\n\n- `flags_error`\n- `flags_output`\n- `flags_return`\n\nLocal variable cleanup\n----------------------\n\nAs many shells do not support local variables, no support for cleanup of\nvariables is present either. As such, all variables local to a function must be\ncleared up with the `unset` built-in command at the end of each function.\n\nIndentation\n-----------\n\nCode block indentation is two (2) spaces, and tabs may not be used.\n\n```sh\nif [ -z 'some string' ]; then\n  someFunction\nfi\n```\n\nLines of code should be no longer than 80 characters unless absolutely\nnecessary. When lines are wrapped using the backslash character '\\', subsequent\nlines should be indented with four (4) spaces so as to differentiate from the\nstandard spacing of two characters, and tabs may not be used.\n\n```sh\nfor x in some set of very long set of arguments that make for a very long \\\n    that extends much too long for one line\ndo\n  echo ${x}\ndone\n```\n\nWhen a conditional expression is written using the built-in [ command, and that\nline must be wrapped, place the control || or && operators on the same line as\nthe expression where possible, with the list to be executed on its own line.\n\n```sh\n[ -n 'some really long expression' -a -n 'some other long expr' ] && \\\n    echo 'that was actually true!'\n```\n"
        },
        {
          "name": "LICENSE",
          "type": "blob",
          "size": 11.0908203125,
          "content": "                                 Apache License\n                           Version 2.0, January 2004\n                        http://www.apache.org/licenses/\n\n   TERMS AND CONDITIONS FOR USE, REPRODUCTION, AND DISTRIBUTION\n\n   1. Definitions.\n\n      \"License\" shall mean the terms and conditions for use, reproduction,\n      and distribution as defined by Sections 1 through 9 of this document.\n\n      \"Licensor\" shall mean the copyright owner or entity authorized by\n      the copyright owner that is granting the License.\n\n      \"Legal Entity\" shall mean the union of the acting entity and all\n      other entities that control, are controlled by, or are under common\n      control with that entity. For the purposes of this definition,\n      \"control\" means (i) the power, direct or indirect, to cause the\n      direction or management of such entity, whether by contract or\n      otherwise, or (ii) ownership of fifty percent (50%) or more of the\n      outstanding shares, or (iii) beneficial ownership of such entity.\n\n      \"You\" (or \"Your\") shall mean an individual or Legal Entity\n      exercising permissions granted by this License.\n\n      \"Source\" form shall mean the preferred form for making modifications,\n      including but not limited to software source code, documentation\n      source, and configuration files.\n\n      \"Object\" form shall mean any form resulting from mechanical\n      transformation or translation of a Source form, including but\n      not limited to compiled object code, generated documentation,\n      and conversions to other media types.\n\n      \"Work\" shall mean the work of authorship, whether in Source or\n      Object form, made available under the License, as indicated by a\n      copyright notice that is included in or attached to the work\n      (an example is provided in the Appendix below).\n\n      \"Derivative Works\" shall mean any work, whether in Source or Object\n      form, that is based on (or derived from) the Work and for which the\n      editorial revisions, annotations, elaborations, or other modifications\n      represent, as a whole, an original work of authorship. For the purposes\n      of this License, Derivative Works shall not include works that remain\n      separable from, or merely link (or bind by name) to the interfaces of,\n      the Work and Derivative Works thereof.\n\n      \"Contribution\" shall mean any work of authorship, including\n      the original version of the Work and any modifications or additions\n      to that Work or Derivative Works thereof, that is intentionally\n      submitted to Licensor for inclusion in the Work by the copyright owner\n      or by an individual or Legal Entity authorized to submit on behalf of\n      the copyright owner. For the purposes of this definition, \"submitted\"\n      means any form of electronic, verbal, or written communication sent\n      to the Licensor or its representatives, including but not limited to\n      communication on electronic mailing lists, source code control systems,\n      and issue tracking systems that are managed by, or on behalf of, the\n      Licensor for the purpose of discussing and improving the Work, but\n      excluding communication that is conspicuously marked or otherwise\n      designated in writing by the copyright owner as \"Not a Contribution.\"\n\n      \"Contributor\" shall mean Licensor and any individual or Legal Entity\n      on behalf of whom a Contribution has been received by Licensor and\n      subsequently incorporated within the Work.\n\n   2. Grant of Copyright License. Subject to the terms and conditions of\n      this License, each Contributor hereby grants to You a perpetual,\n      worldwide, non-exclusive, no-charge, royalty-free, irrevocable\n      copyright license to reproduce, prepare Derivative Works of,\n      publicly display, publicly perform, sublicense, and distribute the\n      Work and such Derivative Works in Source or Object form.\n\n   3. Grant of Patent License. Subject to the terms and conditions of\n      this License, each Contributor hereby grants to You a perpetual,\n      worldwide, non-exclusive, no-charge, royalty-free, irrevocable\n      (except as stated in this section) patent license to make, have made,\n      use, offer to sell, sell, import, and otherwise transfer the Work,\n      where such license applies only to those patent claims licensable\n      by such Contributor that are necessarily infringed by their\n      Contribution(s) alone or by combination of their Contribution(s)\n      with the Work to which such Contribution(s) was submitted. If You\n      institute patent litigation against any entity (including a\n      cross-claim or counterclaim in a lawsuit) alleging that the Work\n      or a Contribution incorporated within the Work constitutes direct\n      or contributory patent infringement, then any patent licenses\n      granted to You under this License for that Work shall terminate\n      as of the date such litigation is filed.\n\n   4. Redistribution. You may reproduce and distribute copies of the\n      Work or Derivative Works thereof in any medium, with or without\n      modifications, and in Source or Object form, provided that You\n      meet the following conditions:\n\n      (a) You must give any other recipients of the Work or\n          Derivative Works a copy of this License; and\n\n      (b) You must cause any modified files to carry prominent notices\n          stating that You changed the files; and\n\n      (c) You must retain, in the Source form of any Derivative Works\n          that You distribute, all copyright, patent, trademark, and\n          attribution notices from the Source form of the Work,\n          excluding those notices that do not pertain to any part of\n          the Derivative Works; and\n\n      (d) If the Work includes a \"NOTICE\" text file as part of its\n          distribution, then any Derivative Works that You distribute must\n          include a readable copy of the attribution notices contained\n          within such NOTICE file, excluding those notices that do not\n          pertain to any part of the Derivative Works, in at least one\n          of the following places: within a NOTICE text file distributed\n          as part of the Derivative Works; within the Source form or\n          documentation, if provided along with the Derivative Works; or,\n          within a display generated by the Derivative Works, if and\n          wherever such third-party notices normally appear. The contents\n          of the NOTICE file are for informational purposes only and\n          do not modify the License. You may add Your own attribution\n          notices within Derivative Works that You distribute, alongside\n          or as an addendum to the NOTICE text from the Work, provided\n          that such additional attribution notices cannot be construed\n          as modifying the License.\n\n      You may add Your own copyright statement to Your modifications and\n      may provide additional or different license terms and conditions\n      for use, reproduction, or distribution of Your modifications, or\n      for any such Derivative Works as a whole, provided Your use,\n      reproduction, and distribution of the Work otherwise complies with\n      the conditions stated in this License.\n\n   5. Submission of Contributions. Unless You explicitly state otherwise,\n      any Contribution intentionally submitted for inclusion in the Work\n      by You to the Licensor shall be under the terms and conditions of\n      this License, without any additional terms or conditions.\n      Notwithstanding the above, nothing herein shall supersede or modify\n      the terms of any separate license agreement you may have executed\n      with Licensor regarding such Contributions.\n\n   6. Trademarks. This License does not grant permission to use the trade\n      names, trademarks, service marks, or product names of the Licensor,\n      except as required for reasonable and customary use in describing the\n      origin of the Work and reproducing the content of the NOTICE file.\n\n   7. Disclaimer of Warranty. Unless required by applicable law or\n      agreed to in writing, Licensor provides the Work (and each\n      Contributor provides its Contributions) on an \"AS IS\" BASIS,\n      WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or\n      implied, including, without limitation, any warranties or conditions\n      of TITLE, NON-INFRINGEMENT, MERCHANTABILITY, or FITNESS FOR A\n      PARTICULAR PURPOSE. You are solely responsible for determining the\n      appropriateness of using or redistributing the Work and assume any\n      risks associated with Your exercise of permissions under this License.\n\n   8. Limitation of Liability. In no event and under no legal theory,\n      whether in tort (including negligence), contract, or otherwise,\n      unless required by applicable law (such as deliberate and grossly\n      negligent acts) or agreed to in writing, shall any Contributor be\n      liable to You for damages, including any direct, indirect, special,\n      incidental, or consequential damages of any character arising as a\n      result of this License or out of the use or inability to use the\n      Work (including but not limited to damages for loss of goodwill,\n      work stoppage, computer failure or malfunction, or any and all\n      other commercial damages or losses), even if such Contributor\n      has been advised of the possibility of such damages.\n\n   9. Accepting Warranty or Additional Liability. While redistributing\n      the Work or Derivative Works thereof, You may choose to offer,\n      and charge a fee for, acceptance of support, warranty, indemnity,\n      or other liability obligations and/or rights consistent with this\n      License. However, in accepting such obligations, You may act only\n      on Your own behalf and on Your sole responsibility, not on behalf\n      of any other Contributor, and only if You agree to indemnify,\n      defend, and hold each Contributor harmless for any liability\n      incurred by, or claims asserted against, such Contributor by reason\n      of your accepting any such warranty or additional liability.\n\n   END OF TERMS AND CONDITIONS\n\n   APPENDIX: How to apply the Apache License to your work.\n\n      To apply the Apache License to your work, attach the following\n      boilerplate notice, with the fields enclosed by brackets \"{}\"\n      replaced with your own identifying information. (Don't include\n      the brackets!)  The text should be enclosed in the appropriate\n      comment syntax for the file format. We also recommend that a\n      file or class name and description of purpose be included on the\n      same \"printed page\" as the copyright notice for easier\n      identification within third-party archives.\n\n   Copyright {yyyy} {name of copyright owner}\n\n   Licensed under the Apache License, Version 2.0 (the \"License\");\n   you may not use this file except in compliance with the License.\n   You may obtain a copy of the License at\n\n       http://www.apache.org/licenses/LICENSE-2.0\n\n   Unless required by applicable law or agreed to in writing, software\n   distributed under the License is distributed on an \"AS IS\" BASIS,\n   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n   See the License for the specific language governing permissions and\n   limitations under the License.\n"
        },
        {
          "name": "README.md",
          "type": "blob",
          "size": 23.8642578125,
          "content": "# shUnit2\n\nshUnit2 is a [xUnit](http://en.wikipedia.org/wiki/XUnit) unit test framework for\nBourne based shell scripts, and it is designed to work in a similar manner to\n[JUnit](http://www.junit.org), [PyUnit](http://pyunit.sourceforge.net), etc.. If\nyou have ever had the desire to write a unit test for a shell script, shUnit2\ncan do the job.\n\n[![Travis CI](https://api.travis-ci.com/kward/shunit2.svg)](https://app.travis-ci.com/github/kward/shunit2)\n\n## Table of Contents\n\n* [Introduction](#introduction)\n  * [Credits / Contributors](#credits-contributors)\n  * [Feedback](#feedback)\n* [Quickstart](#quickstart)\n* [Function Reference](#function-reference)\n  * [General Info](#general-info)\n  * [Asserts](#asserts)\n  * [Failures](#failures)\n  * [Setup/Teardown](#setup-teardown)\n  * [Skipping](#skipping)\n  * [Suites](#suites)\n* [Advanced Usage](#advanced-usage)\n  * [Some constants you can use](#some-constants-you-can-use)\n  * [Error Handling](#error-handling)\n  * [Including Line Numbers in Asserts (Macros)](#including-line-numbers-in-asserts-macros)\n  * [Test Skipping](#test-skipping)\n  * [Running specific tests from the command line](#cmd-line-args)\n  * [Generating test results in JUnit format](#junit-reports)\n* [Appendix](#appendix)\n  * [Getting help](#getting-help)\n  * [Zsh](#zsh)\n\n---\n\n## <a name=\"introduction\"></a> Introduction\n\nshUnit2 was originally developed to provide a consistent testing solution for\n[log4sh][log4sh], a shell based logging framework similar to\n[log4j](http://logging.apache.org). During the development of that product, a\nrepeated problem of having things work just fine under one shell (`/bin/bash` on\nLinux to be specific), and then not working under another shell (`/bin/sh` on\nSolaris) kept coming up. Although several simple tests were run, they were not\nadequate and did not catch some corner cases. The decision was finally made to\nwrite a proper unit test framework after multiple brown-bag releases were made.\n_Research was done to look for an existing product that met the testing\nrequirements, but no adequate product was found._\n\n### Tested software\n\n**Tested Operating Systems** (varies over time)\n\nOS                                  | Support   | Verified\n----------------------------------- | --------- | --------\nUbuntu Linux (14.04.05 LTS)         | Travis CI | continuous\nmacOS High Sierra (10.13.3)         | Travis CI | continuous\nFreeBSD                             | user      | unknown\nSolaris 8, 9, 10 (inc. OpenSolaris) | user      | unknown\nCygwin                              | user      | unknown\n\n**Tested Shells**\n\n* Bourne Shell (__sh__)\n* BASH - GNU Bourne Again SHell (__bash__)\n* DASH - Debian Almquist Shell (__dash__)\n* Korn Shell - AT&T version of the Korn shell (__ksh__)\n* mksh - MirBSD Korn Shell (__mksh__)\n* zsh - Zsh (__zsh__) (since 2.1.2) _please see the Zsh shell errata for more information_\n\nSee the appropriate Release Notes for this release\n(`doc/RELEASE_NOTES-X.X.X.txt`) for the list of actual versions tested.\n\n### <a name=\"credits-contributors\"></a> Credits / Contributors\n\nA list of contributors to shUnit2 can be found in `doc/contributors.md`. Many\nthanks go out to all those who have contributed to make this a better tool.\n\nshUnit2 is the original product of many hours of work by Kate Ward, the primary\nauthor of the code. For related software, check out https://github.com/kward.\n\n### <a name=\"feedback\"></a> Feedback\n\nFeedback is most certainly welcome for this document. Send your questions,\ncomments, and criticisms via the\n[shunit2-users](https://groups.google.com/a/forestent.com/forum/#!forum/shunit2-users/new)\nforum (created 2018-12-09), or file an issue via\nhttps://github.com/kward/shunit2/issues.\n\n---\n\n## <a name=\"quickstart\"></a> Quickstart\n\nThis section will give a very quick start to running unit tests with shUnit2.\nMore information is located in later sections.\n\nHere is a quick sample script to show how easy it is to write a unit test in\nshell. _Note: the script as it stands expects that you are running it from the\n\"examples\" directory._\n\n```sh\n#! /bin/sh\n# file: examples/equality_test.sh\n\ntestEquality() {\n  assertEquals 1 1\n}\n\n# Load shUnit2.\n. ../shunit2\n```\n\nRunning the unit test should give results similar to the following.\n\n```console\n$ cd examples\n$ ./equality_test.sh\ntestEquality\n\nRan 1 test.\n\nOK\n```\n\nW00t! You've just run your first successful unit test. So, what just happened?\nQuite a bit really, and it all happened simply by sourcing the `shunit2`\nlibrary. The basic functionality for the script above goes like this:\n\n* When shUnit2 is sourced, it will walk through any functions defined whose name\n  starts with the string `test`, and add those to an internal list of tests to\n  execute. Once a list of test functions to be run has been determined, shunit2\n  will go to work.\n* Before any tests are executed, shUnit2 again looks for a function, this time\n  one named `oneTimeSetUp()`. If it exists, it will be run. This function is\n  normally used to setup the environment for all tests to be run. Things like\n  creating directories for output or setting environment variables are good to\n  place here. Just so you know, you can also declare a corresponding function\n  named `oneTimeTearDown()` function that does the same thing, but once all the\n  tests have been completed. It is good for removing temporary directories, etc.\n* shUnit2 is now ready to run tests. Before doing so though, it again looks for\n  another function that might be declared, one named `setUp()`. If the function\n  exists, it will be run before each test. It is good for resetting the\n  environment so that each test starts with a clean slate. **At this stage, the\n  first test is finally run.** The success of the test is recorded for a report\n  that will be generated later. After the test is run, shUnit2 looks for a final\n  function that might be declared, one named `tearDown()`. If it exists, it will\n  be run after each test. It is a good place for cleaning up after each test,\n  maybe doing things like removing files that were created, or removing\n  directories. This set of steps, `setUp() > test() > tearDown()`, is repeated\n  for all of the available tests.\n* Once all the work is done, shUnit2 will generate the nice report you saw\n  above. A summary of all the successes and failures will be given so that you\n  know how well your code is doing.\n\nWe should now try adding a test that fails. Change your unit test to look like\nthis.\n\n```sh\n#! /bin/sh\n# file: examples/party_test.sh\n\ntestEquality() {\n  assertEquals 1 1\n}\n\ntestPartyLikeItIs1999() {\n  year=`date '+%Y'`\n  assertEquals \"It's not 1999 :-(\" '1999' \"${year}\"\n}\n\n# Load shUnit2.\n. ../shunit2\n```\n\nSo, what did you get? I guess it told you that this isn't 1999. Bummer, eh?\nHopefully, you noticed a couple of things that were different about the second\ntest. First, we added an optional message that the user will see if the assert\nfails. Second, we did comparisons of strings instead of integers as in the first\ntest. It doesn't matter whether you are testing for equality of strings or\nintegers. Both work equally well with shUnit2.\n\nHopefully, this is enough to get you started with unit testing. If you want a\nton more examples, take a look at the tests provided with [log4sh][log4sh] or\n[shFlags][shflags]. Both provide excellent examples of more advanced usage.\nshUnit2 was after all written to meet the unit testing need that\n[log4sh][log4sh] had.\n\nIf you are using distribution packaged shUnit2 which is accessible from\n`/usr/bin/shunit2` such as Debian, you can load shUnit2 without specifying its\npath.  So the last 2 lines in the above can be replaced by:\n\n```sh\n# Load shUnit2.\n. shunit2\n```\n\n---\n\n## <a name=\"function-reference\"></a> Function Reference\n\n### <a name=\"general-info\"></a> General Info\n\nAny string values passed should be properly quoted -- they should be\nsurrounded by single-quote (`'`) or double-quote (`\"`) characters -- so that the\nshell will properly parse them.\n\n### <a name=\"asserts\"></a> Asserts\n\n    assertEquals [message] expected actual\n\nAsserts that _expected_ and _actual_ are equal to one another. The _expected_\nand _actual_ values can be either strings or integer values as both will be\ntreated as strings. The _message_ is optional, and must be quoted.\n\n    assertNotEquals [message] unexpected actual\n\nAsserts that _unexpected_ and _actual_ are not equal to one another. The\n_unexpected_ and _actual_ values can be either strings or integer values as both\nwill be treated as strings. The _message_ is optional, and must be quoted.\n\n    assertSame [message] expected actual\n\nThis function is functionally equivalent to `assertEquals`.\n\n    assertNotSame [message] unexpected actual\n\nThis function is functionally equivalent to `assertNotEquals`.\n\n    assertContains [message] container content\n\nAsserts that _container_ contains _content_. The _container_ and _content_\nvalues can be either strings or integer values as both will be treated as\nstrings. The _message_ is optional, and must be quoted.\n\n    assertNotContains [message] container content\n\nAsserts that _container_ does not contain _content_. The _container_ and\n_content_ values can be either strings or integer values as both will be treated\nas strings. The _message_ is optional, and must be quoted.\n\n    assertNull [message] value\n\nAsserts that _value_ is _null_, or in shell terms, a zero-length string. The\n_value_ must be a string as an integer value does not translate into a zero-\nlength string. The _message_ is optional, and must be quoted.\n\n    assertNotNull [message] value\n\nAsserts that _value_ is _not null_, or in shell terms, a non-empty string. The\n_value_ may be a string or an integer as the latter will be parsed as a non-empty\nstring value. The _message_ is optional, and must be quoted.\n\n    assertTrue [message] condition\n\nAsserts that a given shell test _condition_ is _true_. The condition can be as\nsimple as a shell _true_ value (the value `0` -- equivalent to\n`${SHUNIT_TRUE}`), or a more sophisticated shell conditional expression. The\n_message_ is optional, and must be quoted.\n\nA sophisticated shell conditional expression is equivalent to what the __if__ or\n__while__ shell built-ins would use (more specifically, what the __test__\ncommand would use). Testing for example whether some value is greater than\nanother value can be done this way.\n\n    assertTrue \"[ 34 -gt 23 ]\"\n\nTesting for the ability to read a file can also be done. This particular test\nwill fail.\n\n    assertTrue 'test failed' \"[ -r /some/non-existant/file ]\"\n\nAs the expressions are standard shell __test__ expressions, it is possible to\nstring multiple expressions together with `-a` and `-o` in the standard fashion.\nThis test will succeed as the entire expression evaluates to _true_.\n\n    assertTrue 'test failed' '[ 1 -eq 1 -a 2 -eq 2 ]'\n\n<i>One word of warning: be very careful with your quoting as shell is not the\nmost forgiving of bad quoting, and things will fail in strange ways.</i>\n\n    assertFalse [message] condition\n\nAsserts that a given shell test _condition_ is _false_. The condition can be as\nsimple as a shell _false_ value (the value `1` -- equivalent to\n`${SHUNIT_FALSE}`), or a more sophisticated shell conditional expression. The\n_message_ is optional, and must be quoted.\n\n_For examples of more sophisticated expressions, see `assertTrue`._\n\n### <a name=\"failures\"></a> Failures\n\nJust to clarify, failures __do not__ test the various arguments against one\nanother. Failures simply fail, optionally with a message, and that is all they\ndo. If you need to test arguments against one another, use asserts.\n\nIf all failures do is fail, why might one use them? There are times when you may\nhave some very complicated logic that you need to test, and the simple asserts\nprovided are simply not adequate. You can do your own validation of the code,\nuse an `assertTrue ${SHUNIT_TRUE}` if your own tests succeeded, and use a\nfailure to record a failure.\n\n    fail [message]\n\nFails the test immediately. The _message_ is optional, and must be quoted.\n\n    failNotEquals [message] unexpected actual\n\nFails the test immediately, reporting that the _unexpected_ and _actual_ values\nare not equal to one another. The _message_ is optional, and must be quoted.\n\n_Note: no actual comparison of unexpected and actual is done._\n\n    failSame [message] expected actual\n\nFails the test immediately, reporting that the _expected_ and _actual_ values\nare the same. The _message_ is optional, and must be quoted.\n\n_Note: no actual comparison of expected and actual is done._\n\n    failNotSame [message] expected actual\n\nFails the test immediately, reporting that the _expected_ and _actual_ values\nare not the same. The _message_ is optional, and must be quoted.\n\n_Note: no actual comparison of expected and actual is done._\n\n    failFound [message] content\n\nFails the test immediately, reporting that the _content_ was found. The\n_message_ is optional, and must be quoted.\n\n_Note: no actual search of content is done._\n\n    failNotFound [message] content\n\nFails the test immediately, reporting that the _content_ was not found. The\n_message_ is optional, and must be quoted.\n\n_Note: no actual search of content is done._\n\n### <a name=\"setup-teardown\"></a> Setup/Teardown\n\n    oneTimeSetUp\n\nThis function can be optionally overridden by the user in their test suite.\n\nIf this function exists, it will be called once before any tests are run. It is\nuseful to prepare a common environment for all tests.\n\n    oneTimeTearDown\n\nThis function can be optionally overridden by the user in their test suite.\n\nIf this function exists, it will be called once after all tests are completed.\nIt is useful to clean up the environment after all tests.\n\n    setUp\n\nThis function can be optionally overridden by the user in their test suite.\n\nIf this function exists, it will be called before each test is run. It is useful\nto reset the environment before each test.\n\n    tearDown\n\nThis function can be optionally overridden by the user in their test suite.\n\nIf this function exists, it will be called after each test completes. It is\nuseful to clean up the environment after each test.\n\n### <a name=\"skipping\"></a> Skipping\n\n    startSkipping\n\nThis function forces the remaining _assert_ and _fail_ functions to be\n\"skipped\", i.e. they will have no effect. Each function skipped will be recorded\nso that the total of asserts and fails will not be altered.\n\n    endSkipping\n\nThis function returns calls to the _assert_ and _fail_ functions to their\ndefault behavior, i.e. they will be called.\n\n    isSkipping\n\nThis function returns the current state of skipping. It can be compared against\n`${SHUNIT_TRUE}` or `${SHUNIT_FALSE}` if desired.\n\n### <a name=\"suites\"></a> Suites\n\nThe default behavior of shUnit2 is that all tests will be found dynamically. If\nyou have a specific set of tests you want to run, or you don't want to use the\nstandard naming scheme of prefixing your tests with `test`, these functions are\nfor you. Most users will never use them though.\n\n    suite\n\nThis function can be optionally overridden by the user in their test suite.\n\nIf this function exists, it will be called when `shunit2` is sourced. If it does\nnot exist, shUnit2 will search the parent script for all functions beginning\nwith the word `test`, and they will be added dynamically to the test suite.\n\n    suite_addTest name\n\nThis function adds a function named _name_ to the list of tests scheduled for\nexecution as part of this test suite. This function should only be called from\nwithin the `suite()` function.\n\n---\n\n## <a name=\"advanced-usage\"></a> Advanced Usage\n\n### <a name=\"some-constants-you-can-use\"></a> Some constants you can use\n\nThere are several constants provided by shUnit2 as variables that might be of\nuse to you.\n\n*Predefined*\n\n| Constant        | Value |\n| --------------- | ----- |\n| SHUNIT\\_TRUE    | Standard shell `true` value (the integer value 0). |\n| SHUNIT\\_FALSE   | Standard shell `false` value (the integer value 1). |\n| SHUNIT\\_ERROR   | The integer value 2. |\n| SHUNIT\\_TMPDIR  | Path to temporary directory that will be automatically cleaned up upon exit of shUnit2. |\n| SHUNIT\\_VERSION | The version of shUnit2 you are running. |\n\n*User defined*\n\n| Constant          | Value |\n| ----------------- | ----- |\n| SHUNIT\\_CMD\\_EXPR | Override which `expr` command is used. By default `expr` is used, except on BSD systems where `gexpr` is used. |\n| SHUNIT\\_COLOR     | Enable colorized output. Options are 'auto', 'always', or 'none', with 'auto' being the default. |\n| SHUNIT\\_PARENT    | The filename of the shell script containing the tests. This is needed specifically for Zsh support. |\n| SHUNIT\\_TEST\\_PREFIX | Define this variable to add a prefix in front of each test name that is output in the test report. |\n\n### <a name=\"error-handling\"></a> Error handling\n\nThe constants values `SHUNIT_TRUE`, `SHUNIT_FALSE`, and `SHUNIT_ERROR` are\nreturned from nearly every function to indicate the success or failure of the\nfunction. Additionally the variable `flags_error` is filled with a detailed\nerror message if any function returns with a `SHUNIT_ERROR` value.\n\n### <a name=\"including-line-numbers-in-asserts-macros\"></a> Including Line Numbers in Asserts (Macros)\n\nIf you include lots of assert statements in an individual test function, it can\nbecome difficult to determine exactly which assert was thrown unless your\nmessages are unique. To help somewhat, line numbers can be included in the\nassert messages. To enable this, a special shell \"macro\" must be used rather\nthan the standard assert calls. _Shell doesn't actually have macros; the name is\nused here as the operation is similar to a standard macro._\n\nFor example, to include line numbers for a `assertEquals()` function call,\nreplace the `assertEquals()` with `${_ASSERT_EQUALS_}`.\n\n_**Example** -- Asserts with and without line numbers_\n\n```shell\n#! /bin/sh\n# file: examples/lineno_test.sh\n\ntestLineNo() {\n  # This assert will have line numbers included (e.g. \"ASSERT:[123] ...\").\n  echo \"ae: ${_ASSERT_EQUALS_}\"\n  ${_ASSERT_EQUALS_} 'not equal' 1 2\n\n  # This assert will not have line numbers included (e.g. \"ASSERT: ...\").\n  assertEquals 'not equal' 1 2\n}\n\n# Load shUnit2.\n. ../shunit2\n```\n\nNotes:\n\n1. Due to how shell parses command-line arguments, _**all strings used with\n   macros should be quoted twice**_. Namely, single-quotes must be converted to single-double-quotes, and vice-versa.<br/>\n   <br/>\n   Normal `assertEquals` call.<br/>\n   `assertEquals 'some message' 'x' ''`<br/>\n   <br/>\n   Macro `_ASSERT_EQUALS_` call. Note the extra quoting around the _message_ and\n   the _null_ value.<br/>\n   `_ASSERT_EQUALS_ '\"some message\"' 'x' '\"\"'`\n\n1. Line numbers are not supported in all shells. If a shell does not support\n   them, no errors will be thrown. Supported shells include: __bash__ (>=3.0),\n   __ksh__, __mksh__, and __zsh__.\n\n### <a name=\"test-skipping\"></a> Test Skipping\n\nThere are times where the test code you have written is just not applicable to\nthe system you are running on. This section describes how to skip these tests\nbut maintain the total test count.\n\nProbably the easiest example would be shell code that is meant to run under the\n__bash__ shell, but the unit test is running under the Bourne shell. There are\nthings that just won't work. The following test code demonstrates two sample\nfunctions, one that will be run under any shell, and the another that will run\nonly under the __bash__ shell.\n\n_**Example** -- math include_\n```sh\n# file: examples/math.inc.\n\nadd_generic() {\n  num_a=$1\n  num_b=$2\n\n  expr $1 + $2\n}\n\nadd_bash() {\n  num_a=$1\n  num_b=$2\n\n  echo $(($1 + $2))\n}\n```\n\nAnd here is a corresponding unit test that correctly skips the `add_bash()` function when the unit test is not running under the __bash__ shell.\n\n_**Example** -- math unit test_\n```sh\n#! /bin/sh\n# file: examples/math_test.sh\n\ntestAdding() {\n  result=`add_generic 1 2`\n  assertEquals \\\n      \"the result of '${result}' was wrong\" \\\n      3 \"${result}\"\n\n  # Disable non-generic tests.\n  [ -z \"${BASH_VERSION:-}\" ] && startSkipping\n\n  result=`add_bash 1 2`\n  assertEquals \\\n      \"the result of '${result}' was wrong\" \\\n      3 \"${result}\"\n}\n\noneTimeSetUp() {\n  # Load include to test.\n  . ./math.inc\n}\n\n# Load and run shUnit2.\n. ../shunit2\n```\n\nRunning the above test under the __bash__ shell will result in the following\noutput.\n\n```console\n$ /bin/bash math_test.sh\ntestAdding\n\nRan 1 test.\n\nOK\n```\n\nBut, running the test under any other Unix shell will result in the following\noutput.\n\n```console\n$ /bin/ksh math_test.sh\ntestAdding\n\nRan 1 test.\n\nOK (skipped=1)\n```\n\nAs you can see, the total number of tests has not changed, but the report\nindicates that some tests were skipped.\n\nSkipping can be controlled with the following functions: `startSkipping()`,\n`endSkipping()`, and `isSkipping()`. Once skipping is enabled, it will remain\nenabled until the end of the current test function call, after which skipping is\ndisabled.\n\n### <a name=\"cmd-line-args\"></a> Running specific tests from the command line.\n\nWhen running a test script, you may override the default set of tests, or the suite-specified set of tests, by providing additional arguments on the command line.  Each additional argument after the `--` marker is assumed to be the name of a test function to be run in the order specified.  e.g.\n\n```console\ntest-script.sh -- testOne testTwo otherFunction\n```\n\nor\n\n```console\nshunit2 test-script.sh testOne testTwo otherFunction\n```\n\nIn either case, three functions will be run as tests, `testOne`, `testTwo`, and `otherFunction`.  Note that the function `otherFunction` would not normally be run by `shunit2` as part of the implicit collection of tests as it's function name does not match the test function name pattern `test*`.\n\nIf a specified test function does not exist, `shunit2` will still attempt to run that function and thereby cause a failure which `shunit2` will catch and mark as a failed test.  All other tests will run normally.\n\nThe specification of tests does not affect how `shunit2` looks for and executes the setup and tear down functions, which will still run as expected.\n\n### <a name=\"junit-reports\"></a> Generating test results in JUnit format.\n\nMost continuous integration tools like CircleCI, are capable to interpret test results in JUnit format, helping you with spacilized sections and triggers tailored to identify faster a failing test. This functionality is still unreleased but you can test it right away, installing shunit2 from source.\n\nGiven that you execute your test script in the following way\n\n```sh\ntest-script.sh\n```\n\nYou can generate the JUnit report like this\n\n```sh\nmkdir -p results\ntest-script.sh -- --output-junit-xml=results/test-script.xml\n```\n\nIt will generate something like\n\n```xml\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<testsuite\n  failures=\"0\"\n  name=\"test-script.sh\"\n  tests=\"1\"\n  assertions=\"1\"\n>\n  <testcase\n    classname=\"test-script.sh\"\n    name=\"testOne\"\n    assertions=\"1\"\n  >\n  </testcase>\n</testsuite>\n```\n\nYou can also specify a more verbose suite name\n\n```sh\ntest-script.sh -- --output-junit-xml=results/test-script.xml --suite-name=Test_Script\n```\n\nThen say to your CI tool where the results are. In the case of CircleCI is like the following\n\n```yaml\n- store_test_results:\n    path: results\n```\n\n---\n\n## <a name=\"appendix\"></a> Appendix\n\n### <a name=\"getting-help\"></a> Getting Help\n\nFor help, please send requests to either the shunit2-users@forestent.com mailing\nlist (archives available on the web at\nhttps://groups.google.com/a/forestent.com/forum/#!forum/shunit2-users) or\ndirectly to Kate Ward <kate dot ward at forestent dot com>.\n\n### <a name=\"zsh\"></a> Zsh\n\nFor compatibility with Zsh, there is one requirement that must be met -- the\n`shwordsplit` option must be set. There are three ways to accomplish this.\n\n1. In the unit-test script, add the following shell code snippet before sourcing\n   the `shunit2` library.\n\n   ```sh\n   setopt shwordsplit\n   ```\n\n2. When invoking __zsh__ from either the command-line or as a script with `#!`,\n   add the `-y` parameter.\n\n    ```sh\n    #! /bin/zsh -y\n    ```\n\n3. When invoking __zsh__ from the command-line, add `-o shwordsplit --` as\n   parameters before the script name.\n\n   ```console\n   $ zsh -o shwordsplit -- some_script\n   ```\n\n[log4sh]: https://github.com/kward/log4sh\n[shflags]: https://github.com/kward/shflags\n"
        },
        {
          "name": "doc",
          "type": "tree",
          "content": null
        },
        {
          "name": "examples",
          "type": "tree",
          "content": null
        },
        {
          "name": "init_githooks.sh",
          "type": "blob",
          "size": 0.900390625,
          "content": "#! /bin/sh\n#\n# Initialize the local git hooks this repository.\n# https://git-scm.com/docs/githooks\n\ntopLevel=$(git rev-parse --show-toplevel)\nif ! cd \"${topLevel}\"; then\n  echo \"filed to cd into topLevel directory '${topLevel}'\"\n  exit 1\nfi\n\nhooksDir=\"${topLevel}/.githooks\"\nif ! hooksPath=$(git config core.hooksPath); then\n  hooksPath=\"${topLevel}/.git/hooks\"\nfi\n\nsrc=\"${hooksDir}/generic\"\necho \"linking hooks...\"\nfor hook in \\\n  applypatch-msg \\\n  pre-applypatch \\\n  post-applypatch \\\n  pre-commit \\\n  pre-merge-commit \\\n  prepare-commit-msg \\\n  commit-msg \\\n  post-commit \\\n  pre-rebase \\\n  post-checkout \\\n  post-merge \\\n  pre-push \\\n  pre-receive \\\n  update \\\n  post-receive \\\n  post-update \\\n  push-to-checkout \\\n  pre-auto-gc \\\n  post-rewrite \\\n  sendemail-validate \\\n  fsmonitor-watchman \\\n  p4-pre-submit \\\n  post-index-change\ndo\n  echo \"  ${hook}\"\n  dest=\"${hooksPath}/${hook}\"\n  ln -sf \"${src}\" \"${dest}\"\ndone\n"
        },
        {
          "name": "lib",
          "type": "tree",
          "content": null
        },
        {
          "name": "shunit2",
          "type": "blob",
          "size": 42.0380859375,
          "content": "#! /bin/sh\n# vim:et:ft=sh:sts=2:sw=2\n#\n# shUnit2 -- Unit testing framework for Unix shell scripts.\n#\n# Copyright 2008-2021 Kate Ward. All Rights Reserved.\n# Released under the Apache 2.0 license.\n# http://www.apache.org/licenses/LICENSE-2.0\n#\n# Author: kate.ward@forestent.com (Kate Ward)\n# https://github.com/kward/shunit2\n#\n# shUnit2 is a xUnit based unit test framework for Bourne shell scripts. It is\n# based on the popular JUnit unit testing framework for Java.\n#\n# `expr` may be antiquated, but it is the only solution in some cases.\n#   shellcheck disable=SC2003\n# Allow usage of legacy backticked `...` notation instead of $(...).\n#   shellcheck disable=SC2006\n\n# Return if shunit2 already loaded.\nif test -n \"${SHUNIT_VERSION:-}\"; then\n  exit 0\nfi\nSHUNIT_VERSION='2.1.9pre'\n\n# Return values that scripts can use.\nSHUNIT_TRUE=0\nSHUNIT_FALSE=1\nSHUNIT_ERROR=2\n\n# Determine if `builtin` command exists.\n__SHUNIT_BUILTIN='builtin'\n# shellcheck disable=2039\nif ! (\"${__SHUNIT_BUILTIN}\" echo 123 >/dev/null 2>&1); then\n  __SHUNIT_BUILTIN=''\nfi\n\n# Determine some reasonable command defaults.\n__SHUNIT_CMD_ECHO_ESC='echo -e'\n# shellcheck disable=SC2039,SC3037\nif ${__SHUNIT_BUILTIN} [ \"`echo -e test`\" = '-e test' ]; then\n  __SHUNIT_CMD_ECHO_ESC='echo'\nfi\n\n# Commands a user can override if needed.\n__SHUNIT_CMD_TPUT='tput'\nSHUNIT_CMD_TPUT=${SHUNIT_CMD_TPUT:-${__SHUNIT_CMD_TPUT}}\n\n# Enable color output. Options are 'auto', 'always', or 'never'.\nSHUNIT_COLOR=${SHUNIT_COLOR:-auto}\n\n#\n# Internal constants.\n#\n\n__SHUNIT_MODE_SOURCED='sourced'\n__SHUNIT_MODE_STANDALONE='standalone'\n__SHUNIT_PARENT=${SHUNIT_PARENT:-$0}\n\n# User provided test prefix to display in front of the name of the test being\n# executed. Define by setting the SHUNIT_TEST_PREFIX variable.\n__SHUNIT_TEST_PREFIX=${SHUNIT_TEST_PREFIX:-}\n\n# ANSI colors.\n__SHUNIT_ANSI_NONE='\\033[0m'\n__SHUNIT_ANSI_RED='\\033[1;31m'\n__SHUNIT_ANSI_GREEN='\\033[1;32m'\n__SHUNIT_ANSI_YELLOW='\\033[1;33m'\n__SHUNIT_ANSI_CYAN='\\033[1;36m'\n\n#\n# Internal variables.\n#\n\n# Variables.\n__shunit_lineno=''  # Line number of executed test.\n__shunit_mode=${__SHUNIT_MODE_SOURCED}  # Operating mode.\n__shunit_reportGenerated=${SHUNIT_FALSE}  # Is report generated.\n__shunit_script=''  # Filename of unittest script (standalone mode).\n__shunit_skip=${SHUNIT_FALSE}  # Is skipping enabled.\n__shunit_suite=''  # Suite of tests to execute.\n__shunit_clean=${SHUNIT_FALSE}  # _shunit_cleanup() was already called.\n__shunit_suiteName=''  # Text name of current test suite.\n__shunit_xmlSuiteName=''  # XML-ready text name of current test suite.\n\n# JUnit XML variables.\n__shunit_junitXmlOutputFile=''  # File to use for JUnit XML output in addition to stdout.\n__shunit_junitXmlTestCases=''  # Test cases info in the JUnit XML format for output\n__shunit_junitXmlCurrentTestCaseErrors=''  # Current test case error info in the JUnit XML format for output\n\n# ANSI colors (populated by _shunit_configureColor()).\n__shunit_ansi_none=''\n__shunit_ansi_red=''\n__shunit_ansi_green=''\n__shunit_ansi_yellow=''\n__shunit_ansi_cyan=''\n\n# Counts of tests.\n__shunit_testSuccess=${SHUNIT_TRUE}\n__shunit_testsTotal=0\n__shunit_testsPassed=0\n__shunit_testsFailed=0\n\n# Counts of asserts.\n__shunit_assertsTotal=0\n__shunit_assertsPassed=0\n__shunit_assertsFailed=0\n__shunit_assertsSkipped=0\n__shunit_assertsCurrentTest=0\n\n#\n# Internal functions.\n#\n\n# Logging.\n_shunit_warn() {\n  ${__SHUNIT_CMD_ECHO_ESC} \"${__shunit_ansi_yellow}shunit2:WARN${__shunit_ansi_none} $*\" >&2\n}\n_shunit_error() {\n  ${__SHUNIT_CMD_ECHO_ESC} \"${__shunit_ansi_red}shunit2:ERROR${__shunit_ansi_none} $*\" >&2\n}\n_shunit_fatal() {\n  ${__SHUNIT_CMD_ECHO_ESC} \"${__shunit_ansi_red}shunit2:FATAL${__shunit_ansi_none} $*\" >&2\n  exit ${SHUNIT_ERROR}\n}\n\n#\n# Macros.\n#\n\n# shellcheck disable=SC2016,SC2089\n_SHUNIT_LINENO_='eval __shunit_lineno=\"\"; if ${__SHUNIT_BUILTIN} [ \"${1:-}\" = \"--lineno\" ] && ${__SHUNIT_BUILTIN} [ -n \"${2:-}\" ]; then __shunit_lineno=\"[${2}]\"; shift 2; fi;'\n\n#\n# Setup.\n#\n\n# Specific shell checks.\nif ${__SHUNIT_BUILTIN} [ -n \"${ZSH_VERSION:-}\" ]; then\n  setopt |grep \"^shwordsplit$\" >/dev/null\n  if ${__SHUNIT_BUILTIN} [ $? -ne ${SHUNIT_TRUE} ]; then\n    _shunit_fatal 'zsh shwordsplit option is required for proper operation'\n  fi\n  if ${__SHUNIT_BUILTIN} [ -z \"${SHUNIT_PARENT:-}\" ]; then\n    _shunit_fatal \"zsh does not pass \\$0 through properly. please declare \\\n\\\"SHUNIT_PARENT=\\$0\\\" before calling shUnit2\"\n  fi\nfi\n\n# Set the constants readonly.\n__shunit_constants=`set |grep '^__SHUNIT_' |cut -d= -f1`\necho \"${__shunit_constants}\" |grep '^Binary file' >/dev/null && \\\n    __shunit_constants=`set |grep -a '^__SHUNIT_' |cut -d= -f1`\nfor __shunit_const in ${__shunit_constants}; do\n  if ${__SHUNIT_BUILTIN} [ -z \"${ZSH_VERSION:-}\" ]; then\n    readonly \"${__shunit_const}\"\n  else\n    case ${ZSH_VERSION} in\n      [123].*) readonly \"${__shunit_const}\" ;;\n      *)\n        # Declare readonly constants globally.\n        # shellcheck disable=SC2039,SC3045\n        readonly -g \"${__shunit_const}\"\n    esac\n  fi\ndone\nunset __shunit_const __shunit_constants\n\n#-----------------------------------------------------------------------------\n# Assertion functions.\n#\n\n# Assert that two values are equal to one another.\n#\n# Args:\n#   message: string: failure message [optional]\n#   expected: string: expected value\n#   actual: string: actual value\n# Returns:\n#   integer: success (TRUE/FALSE/ERROR constant)\nassertEquals() {\n  # shellcheck disable=SC2090\n  ${_SHUNIT_LINENO_}\n  if ${__SHUNIT_BUILTIN} [ $# -lt 2 -o $# -gt 3 ]; then\n    _shunit_error \"assertEquals() requires two or three arguments; $# given\"\n    _shunit_assertFail\n    return ${SHUNIT_ERROR}\n  fi\n  if _shunit_shouldSkip; then\n    return ${SHUNIT_TRUE}\n  fi\n\n  shunit_message_=${__shunit_lineno}\n  if ${__SHUNIT_BUILTIN} [ $# -eq 3 ]; then\n    shunit_message_=\"${shunit_message_}$1\"\n    shift\n  fi\n  shunit_expected_=$1\n  shunit_actual_=$2\n\n  shunit_return=${SHUNIT_TRUE}\n  if ${__SHUNIT_BUILTIN} [ \"${shunit_expected_}\" = \"${shunit_actual_}\" ]; then\n    _shunit_assertPass\n  else\n    failNotEquals \"${shunit_message_}\" \"${shunit_expected_}\" \"${shunit_actual_}\"\n    shunit_return=${SHUNIT_FALSE}\n  fi\n\n  unset shunit_message_ shunit_expected_ shunit_actual_\n  return ${shunit_return}\n}\n# shellcheck disable=SC2016,SC2034\n_ASSERT_EQUALS_='eval assertEquals --lineno \"${LINENO:-}\"'\n\n# Assert that two values are not equal to one another.\n#\n# Args:\n#   message: string: failure message [optional]\n#   expected: string: expected value\n#   actual: string: actual value\n# Returns:\n#   integer: success (TRUE/FALSE/ERROR constant)\nassertNotEquals() {\n  # shellcheck disable=SC2090\n  ${_SHUNIT_LINENO_}\n  if ${__SHUNIT_BUILTIN} [ $# -lt 2 -o $# -gt 3 ]; then\n    _shunit_error \"assertNotEquals() requires two or three arguments; $# given\"\n    _shunit_assertFail\n    return ${SHUNIT_ERROR}\n  fi\n  if _shunit_shouldSkip; then\n    return ${SHUNIT_TRUE}\n  fi\n\n  shunit_message_=${__shunit_lineno}\n  if ${__SHUNIT_BUILTIN} [ $# -eq 3 ]; then\n    shunit_message_=\"${shunit_message_}$1\"\n    shift\n  fi\n  shunit_expected_=$1\n  shunit_actual_=$2\n\n  shunit_return=${SHUNIT_TRUE}\n  if ${__SHUNIT_BUILTIN} [ \"${shunit_expected_}\" != \"${shunit_actual_}\" ]; then\n    _shunit_assertPass\n  else\n    failSame \"${shunit_message_}\" \"${shunit_expected_}\" \"${shunit_actual_}\"\n    shunit_return=${SHUNIT_FALSE}\n  fi\n\n  unset shunit_message_ shunit_expected_ shunit_actual_\n  return ${shunit_return}\n}\n# shellcheck disable=SC2016,SC2034\n_ASSERT_NOT_EQUALS_='eval assertNotEquals --lineno \"${LINENO:-}\"'\n\n# Assert that a container contains a content.\n#\n# Args:\n#   message: string: failure message [optional]\n#   container: string: container to analyze\n#   content: string: content to find\n# Returns:\n#   integer: success (TRUE/FALSE/ERROR constant)\nassertContains() {\n  # shellcheck disable=SC2090\n  ${_SHUNIT_LINENO_}\n  if ${__SHUNIT_BUILTIN} [ $# -lt 2 -o $# -gt 3 ]; then\n    _shunit_error \"assertContains() requires two or three arguments; $# given\"\n    _shunit_assertFail\n    return ${SHUNIT_ERROR}\n  fi\n  if _shunit_shouldSkip; then\n    return ${SHUNIT_TRUE}\n  fi\n\n  shunit_message_=${__shunit_lineno}\n  if ${__SHUNIT_BUILTIN} [ $# -eq 3 ]; then\n    shunit_message_=\"${shunit_message_}$1\"\n    shift\n  fi\n  shunit_container_=$1\n  shunit_content_=$2\n  shunit_return=${SHUNIT_TRUE}\n  if echo \"${shunit_container_}\" |grep -F -- \"${shunit_content_}\" >/dev/null; then\n    _shunit_assertPass\n  else\n    failNotFound \"${shunit_message_}\" \"${shunit_content_}\"\n    shunit_return=${SHUNIT_FALSE}\n  fi\n\n  unset shunit_message_ shunit_container_ shunit_content_\n  return ${shunit_return}\n}\n# shellcheck disable=SC2016,SC2034\n_ASSERT_CONTAINS_='eval assertContains --lineno \"${LINENO:-}\"'\n\n# Assert that a container does not contain a content.\n#\n# Args:\n#   message: string: failure message [optional]\n#   container: string: container to analyze\n#   content: string: content to look for\n# Returns:\n#   integer: success (TRUE/FALSE/ERROR constant)\nassertNotContains() {\n  # shellcheck disable=SC2090\n  ${_SHUNIT_LINENO_}\n  if ${__SHUNIT_BUILTIN} [ $# -lt 2 -o $# -gt 3 ]; then\n    _shunit_error \"assertNotContains() requires two or three arguments; $# given\"\n    _shunit_assertFail\n    return ${SHUNIT_ERROR}\n  fi\n  if _shunit_shouldSkip; then\n    return ${SHUNIT_TRUE}\n  fi\n\n  shunit_message_=${__shunit_lineno}\n  if ${__SHUNIT_BUILTIN} [ $# -eq 3 ]; then\n    shunit_message_=\"${shunit_message_}$1\"\n    shift\n  fi\n  shunit_container_=$1\n  shunit_content_=$2\n\n  shunit_return=${SHUNIT_TRUE}\n  if echo \"$shunit_container_\" |grep -F -- \"$shunit_content_\" > /dev/null; then\n    failFound \"${shunit_message_}\" \"${shunit_content_}\"\n    shunit_return=${SHUNIT_FALSE}\n  else\n    _shunit_assertPass\n  fi\n\n  unset shunit_message_ shunit_container_ shunit_content_\n  return ${shunit_return}\n}\n# shellcheck disable=SC2016,SC2034\n_ASSERT_NOT_CONTAINS_='eval assertNotContains --lineno \"${LINENO:-}\"'\n\n# Assert that a value is null (i.e. an empty string).\n#\n# Args:\n#   message: string: failure message [optional]\n#   actual: string: actual value\n# Returns:\n#   integer: success (TRUE/FALSE/ERROR constant)\nassertNull() {\n  # shellcheck disable=SC2090\n  ${_SHUNIT_LINENO_}\n  if ${__SHUNIT_BUILTIN} [ $# -gt 2 ]; then\n    # Allowing 0 arguments as $1 might actually be null.\n    _shunit_error \"assertNull() requires one or two arguments; $# given\"\n    _shunit_assertFail\n    return ${SHUNIT_ERROR}\n  fi\n  if _shunit_shouldSkip; then\n    return ${SHUNIT_TRUE}\n  fi\n\n  shunit_message_=${__shunit_lineno}\n  if ${__SHUNIT_BUILTIN} [ $# -eq 2 ]; then\n    shunit_message_=\"${shunit_message_}$1\"\n    shift\n  fi\n\n  ${__SHUNIT_BUILTIN} test -z \"${1:-}\"\n  assertTrue \"${shunit_message_}\" $?\n  shunit_return=$?\n\n  unset shunit_message_\n  return ${shunit_return}\n}\n# shellcheck disable=SC2016,SC2034\n_ASSERT_NULL_='eval assertNull --lineno \"${LINENO:-}\"'\n\n# Assert that a value is not null (i.e. a non-empty string).\n#\n# Args:\n#   message: string: failure message [optional]\n#   actual: string: actual value\n# Returns:\n#   integer: success (TRUE/FALSE/ERROR constant)\nassertNotNull() {\n  # shellcheck disable=SC2090\n  ${_SHUNIT_LINENO_}\n  if ${__SHUNIT_BUILTIN} [ $# -gt 2 ]; then\n    # Allowing 0 arguments as $1 might actually be null.\n    _shunit_error \"assertNotNull() requires one or two arguments; $# given\"\n    _shunit_assertFail\n    return ${SHUNIT_ERROR}\n  fi\n  if _shunit_shouldSkip; then\n    return ${SHUNIT_TRUE}\n  fi\n\n  shunit_message_=${__shunit_lineno}\n  if ${__SHUNIT_BUILTIN} [ $# -eq 2 ]; then\n    shunit_message_=\"${shunit_message_}$1\"\n    shift\n  fi\n\n  ${__SHUNIT_BUILTIN} test -n \"${1:-}\"\n  assertTrue \"${shunit_message_}\" $?\n  shunit_return=$?\n\n  unset shunit_message_\n  return ${shunit_return}\n}\n# shellcheck disable=SC2016,SC2034\n_ASSERT_NOT_NULL_='eval assertNotNull --lineno \"${LINENO:-}\"'\n\n# Assert that two values are the same (i.e. equal to one another).\n#\n# Args:\n#   message: string: failure message [optional]\n#   expected: string: expected value\n#   actual: string: actual value\n# Returns:\n#   integer: success (TRUE/FALSE/ERROR constant)\nassertSame() {\n  # shellcheck disable=SC2090\n  ${_SHUNIT_LINENO_}\n  if ${__SHUNIT_BUILTIN} [ $# -lt 2 -o $# -gt 3 ]; then\n    _shunit_error \"assertSame() requires two or three arguments; $# given\"\n    _shunit_assertFail\n    return ${SHUNIT_ERROR}\n  fi\n  if _shunit_shouldSkip; then\n    return ${SHUNIT_TRUE}\n  fi\n\n  shunit_message_=${__shunit_lineno}\n  if ${__SHUNIT_BUILTIN} [ $# -eq 3 ]; then\n    shunit_message_=\"${shunit_message_}$1\"\n    shift\n  fi\n  assertEquals \"${shunit_message_}\" \"$1\" \"$2\"\n  shunit_return=$?\n\n  unset shunit_message_\n  return ${shunit_return}\n}\n# shellcheck disable=SC2016,SC2034\n_ASSERT_SAME_='eval assertSame --lineno \"${LINENO:-}\"'\n\n# Assert that two values are not the same (i.e. not equal to one another).\n#\n# Args:\n#   message: string: failure message [optional]\n#   expected: string: expected value\n#   actual: string: actual value\n# Returns:\n#   integer: success (TRUE/FALSE/ERROR constant)\nassertNotSame() {\n  # shellcheck disable=SC2090\n  ${_SHUNIT_LINENO_}\n  if ${__SHUNIT_BUILTIN} [ $# -lt 2 -o $# -gt 3 ]; then\n    _shunit_error \"assertNotSame() requires two or three arguments; $# given\"\n    _shunit_assertFail\n    return ${SHUNIT_ERROR}\n  fi\n  if _shunit_shouldSkip; then\n    return ${SHUNIT_TRUE}\n  fi\n\n  shunit_message_=${__shunit_lineno}\n  if ${__SHUNIT_BUILTIN} [ $# -eq 3 ]; then\n    shunit_message_=\"${shunit_message_:-}$1\"\n    shift\n  fi\n  assertNotEquals \"${shunit_message_}\" \"$1\" \"$2\"\n  shunit_return=$?\n\n  unset shunit_message_\n  return ${shunit_return}\n}\n# shellcheck disable=SC2016,SC2034\n_ASSERT_NOT_SAME_='eval assertNotSame --lineno \"${LINENO:-}\"'\n\n# Assert that a value or shell test condition is true.\n#\n# In shell, a value of 0 is true and a non-zero value is false. Any integer\n# value passed can thereby be tested.\n#\n# Shell supports much more complicated tests though, and a means to support\n# them was needed. As such, this function tests that conditions are true or\n# false through evaluation rather than just looking for a true or false.\n#\n# The following test will succeed:\n#   assertTrue 0\n#   assertTrue \"[ 34 -gt 23 ]\"\n# The following test will fail with a message:\n#   assertTrue 123\n#   assertTrue \"test failed\" \"[ -r '/non/existent/file' ]\"\n#\n# Args:\n#   message: string: failure message [optional]\n#   condition: string: integer value or shell conditional statement\n# Returns:\n#   integer: success (TRUE/FALSE/ERROR constant)\nassertTrue() {\n  # shellcheck disable=SC2090\n  ${_SHUNIT_LINENO_}\n  if ${__SHUNIT_BUILTIN} [ $# -lt 1 -o $# -gt 2 ]; then\n    _shunit_error \"assertTrue() takes one or two arguments; $# given\"\n    _shunit_assertFail\n    return ${SHUNIT_ERROR}\n  fi\n  if _shunit_shouldSkip; then\n    return ${SHUNIT_TRUE}\n  fi\n\n  shunit_message_=${__shunit_lineno}\n  if ${__SHUNIT_BUILTIN} [ $# -eq 2 ]; then\n    shunit_message_=\"${shunit_message_}$1\"\n    shift\n  fi\n  shunit_condition_=$1\n\n  # See if condition is an integer, i.e. a return value.\n  shunit_return=${SHUNIT_TRUE}\n  if ${__SHUNIT_BUILTIN} [ -z \"${shunit_condition_}\" ]; then\n    # Null condition.\n    shunit_return=${SHUNIT_FALSE}\n  elif (expr \\( \"${shunit_condition_}\" + '0' \\) '=' \"${shunit_condition_}\" >/dev/null 2>&1)\n  then\n    # Possible return value. Treating 0 as true, and non-zero as false.\n    if ${__SHUNIT_BUILTIN} [ \"${shunit_condition_}\" -ne 0 ]; then\n      shunit_return=${SHUNIT_FALSE}\n    fi\n  else\n    # Hopefully... a condition.\n    if ! eval \"${shunit_condition_}\" >/dev/null 2>&1; then\n      shunit_return=${SHUNIT_FALSE}\n    fi\n  fi\n\n  # Record the test.\n  if ${__SHUNIT_BUILTIN} [ ${shunit_return} -eq ${SHUNIT_TRUE} ]; then\n    _shunit_assertPass\n  else\n    _shunit_assertFail \"${shunit_message_}\"\n  fi\n\n  unset shunit_message_ shunit_condition_\n  return ${shunit_return}\n}\n# shellcheck disable=SC2016,SC2034\n_ASSERT_TRUE_='eval assertTrue --lineno \"${LINENO:-}\"'\n\n# Assert that a value or shell test condition is false.\n#\n# In shell, a value of 0 is true and a non-zero value is false. Any integer\n# value passed can thereby be tested.\n#\n# Shell supports much more complicated tests though, and a means to support\n# them was needed. As such, this function tests that conditions are true or\n# false through evaluation rather than just looking for a true or false.\n#\n# The following test will succeed:\n#   assertFalse 1\n#   assertFalse \"[ 'apples' = 'oranges' ]\"\n# The following test will fail with a message:\n#   assertFalse 0\n#   assertFalse \"test failed\" \"[ 1 -eq 1 -a 2 -eq 2 ]\"\n#\n# Args:\n#   message: string: failure message [optional]\n#   condition: string: integer value or shell conditional statement\n# Returns:\n#   integer: success (TRUE/FALSE/ERROR constant)\nassertFalse() {\n  # shellcheck disable=SC2090\n  ${_SHUNIT_LINENO_}\n  if ${__SHUNIT_BUILTIN} [ $# -lt 1 -o $# -gt 2 ]; then\n    _shunit_error \"assertFalse() requires one or two arguments; $# given\"\n    _shunit_assertFail\n    return ${SHUNIT_ERROR}\n  fi\n  if _shunit_shouldSkip; then\n    return ${SHUNIT_TRUE}\n  fi\n\n  shunit_message_=${__shunit_lineno}\n  if ${__SHUNIT_BUILTIN} [ $# -eq 2 ]; then\n    shunit_message_=\"${shunit_message_}$1\"\n    shift\n  fi\n  shunit_condition_=$1\n\n  # See if condition is an integer, i.e. a return value.\n  shunit_return=${SHUNIT_TRUE}\n  if ${__SHUNIT_BUILTIN} [ -z \"${shunit_condition_}\" ]; then\n    # Null condition.\n    shunit_return=${SHUNIT_TRUE}\n  elif (expr \\( \"${shunit_condition_}\" + '0' \\) '=' \"${shunit_condition_}\" >/dev/null 2>&1); then\n    # Possible return value. Treating 0 as true, and non-zero as false.\n    if ${__SHUNIT_BUILTIN} [ \"${shunit_condition_}\" -eq 0 ]; then\n      shunit_return=${SHUNIT_FALSE}\n    fi\n  else\n    # Hopefully... a condition.\n    # shellcheck disable=SC2086\n    if eval ${shunit_condition_} >/dev/null 2>&1; then\n      shunit_return=${SHUNIT_FALSE}\n    fi\n  fi\n\n  # Record the test.\n  if ${__SHUNIT_BUILTIN} [ \"${shunit_return}\" -eq \"${SHUNIT_TRUE}\" ]; then\n    _shunit_assertPass\n  else\n    _shunit_assertFail \"${shunit_message_}\"\n  fi\n\n  unset shunit_message_ shunit_condition_\n  return \"${shunit_return}\"\n}\n# shellcheck disable=SC2016,SC2034\n_ASSERT_FALSE_='eval assertFalse --lineno \"${LINENO:-}\"'\n\n#-----------------------------------------------------------------------------\n# Failure functions.\n#\n\n# Records a test failure.\n#\n# Args:\n#   message: string: failure message [optional]\n# Returns:\n#   integer: success (TRUE/FALSE/ERROR constant)\nfail() {\n  # shellcheck disable=SC2090\n  ${_SHUNIT_LINENO_}\n  if ${__SHUNIT_BUILTIN} [ $# -gt 1 ]; then\n    _shunit_error \"fail() requires zero or one arguments; $# given\"\n    return ${SHUNIT_ERROR}\n  fi\n  if _shunit_shouldSkip; then\n    return ${SHUNIT_TRUE}\n  fi\n\n  shunit_message_=${__shunit_lineno}\n  if ${__SHUNIT_BUILTIN} [ $# -eq 1 ]; then\n    shunit_message_=\"${shunit_message_}$1\"\n    shift\n  fi\n\n  _shunit_assertFail \"${shunit_message_}\"\n\n  unset shunit_message_\n  return ${SHUNIT_FALSE}\n}\n# shellcheck disable=SC2016,SC2034\n_FAIL_='eval fail --lineno \"${LINENO:-}\"'\n\n# Records a test failure, stating two values were not equal.\n#\n# Args:\n#   message: string: failure message [optional]\n#   expected: string: expected value\n#   actual: string: actual value\n# Returns:\n#   integer: success (TRUE/FALSE/ERROR constant)\nfailNotEquals() {\n  # shellcheck disable=SC2090\n  ${_SHUNIT_LINENO_}\n  if ${__SHUNIT_BUILTIN} [ $# -lt 2 -o $# -gt 3 ]; then\n    _shunit_error \"failNotEquals() requires one or two arguments; $# given\"\n    return ${SHUNIT_ERROR}\n  fi\n  if _shunit_shouldSkip; then\n    return ${SHUNIT_TRUE}\n  fi\n\n  shunit_message_=${__shunit_lineno}\n  if ${__SHUNIT_BUILTIN} [ $# -eq 3 ]; then\n    shunit_message_=\"${shunit_message_}$1\"\n    shift\n  fi\n  shunit_expected_=$1\n  shunit_actual_=$2\n\n  shunit_message_=${shunit_message_%% }\n  _shunit_assertFail \"${shunit_message_:+${shunit_message_} }expected:<${shunit_expected_}> but was:<${shunit_actual_}>\"\n\n  unset shunit_message_ shunit_expected_ shunit_actual_\n  return ${SHUNIT_FALSE}\n}\n# shellcheck disable=SC2016,SC2034\n_FAIL_NOT_EQUALS_='eval failNotEquals --lineno \"${LINENO:-}\"'\n\n# Records a test failure, stating a value was found.\n#\n# Args:\n#   message: string: failure message [optional]\n#   content: string: found value\n# Returns:\n#   integer: success (TRUE/FALSE/ERROR constant)\nfailFound() {\n  # shellcheck disable=SC2090\n  ${_SHUNIT_LINENO_}\n  if ${__SHUNIT_BUILTIN} [ $# -lt 1 -o $# -gt 2 ]; then\n    _shunit_error \"failFound() requires one or two arguments; $# given\"\n    return ${SHUNIT_ERROR}\n  fi\n  if _shunit_shouldSkip; then\n    return ${SHUNIT_TRUE}\n  fi\n\n  shunit_message_=${__shunit_lineno}\n  if ${__SHUNIT_BUILTIN} [ $# -eq 2 ]; then\n    shunit_message_=\"${shunit_message_}$1\"\n    shift\n  fi\n  shunit_content_=$1\n\n  shunit_message_=${shunit_message_%% }\n  _shunit_assertFail \"${shunit_message_:+${shunit_message_} }found:<${shunit_content_}>\"\n\n  unset shunit_message_ shunit_content_\n  return ${SHUNIT_FALSE}\n}\n# shellcheck disable=SC2016,SC2034\n_FAIL_FOUND_='eval failFound --lineno \"${LINENO:-}\"'\n\n# Records a test failure, stating a content was not found.\n#\n# Args:\n#   message: string: failure message [optional]\n#   content: string: content not found\n# Returns:\n#   integer: success (TRUE/FALSE/ERROR constant)\nfailNotFound() {\n  # shellcheck disable=SC2090\n  ${_SHUNIT_LINENO_}\n  if ${__SHUNIT_BUILTIN} [ $# -lt 1 -o $# -gt 2 ]; then\n    _shunit_error \"failNotFound() requires one or two arguments; $# given\"\n    return ${SHUNIT_ERROR}\n  fi\n  if _shunit_shouldSkip; then\n    return ${SHUNIT_TRUE}\n  fi\n\n  shunit_message_=${__shunit_lineno}\n  if ${__SHUNIT_BUILTIN} [ $# -eq 2 ]; then\n    shunit_message_=\"${shunit_message_}$1\"\n    shift\n  fi\n  shunit_content_=$1\n\n  shunit_message_=${shunit_message_%% }\n  _shunit_assertFail \"${shunit_message_:+${shunit_message_} }not found:<${shunit_content_}>\"\n\n  unset shunit_message_ shunit_content_\n  return ${SHUNIT_FALSE}\n}\n# shellcheck disable=SC2016,SC2034\n_FAIL_NOT_FOUND_='eval failNotFound --lineno \"${LINENO:-}\"'\n\n# Records a test failure, stating two values should have been the same.\n#\n# Args:\n#   message: string: failure message [optional]\n#   expected: string: expected value\n#   actual: string: actual value\n# Returns:\n#   integer: success (TRUE/FALSE/ERROR constant)\nfailSame() {\n  # shellcheck disable=SC2090\n  ${_SHUNIT_LINENO_}\n  if ${__SHUNIT_BUILTIN} [ $# -lt 2 -o $# -gt 3 ]; then\n    _shunit_error \"failSame() requires two or three arguments; $# given\"\n    return ${SHUNIT_ERROR}\n  fi\n  if _shunit_shouldSkip; then\n    return ${SHUNIT_TRUE}\n  fi\n\n  shunit_message_=${__shunit_lineno}\n  if ${__SHUNIT_BUILTIN} [ $# -eq 3 ]; then\n    shunit_message_=\"${shunit_message_}$1\"\n    shift\n  fi\n\n  shunit_message_=${shunit_message_%% }\n  _shunit_assertFail \"${shunit_message_:+${shunit_message_} }expected not same\"\n\n  unset shunit_message_\n  return ${SHUNIT_FALSE}\n}\n# shellcheck disable=SC2016,SC2034\n_FAIL_SAME_='eval failSame --lineno \"${LINENO:-}\"'\n\n# Records a test failure, stating two values were not equal.\n#\n# This is functionally equivalent to calling failNotEquals().\n#\n# Args:\n#   message: string: failure message [optional]\n#   expected: string: expected value\n#   actual: string: actual value\n# Returns:\n#   integer: success (TRUE/FALSE/ERROR constant)\nfailNotSame() {\n  # shellcheck disable=SC2090\n  ${_SHUNIT_LINENO_}\n  if ${__SHUNIT_BUILTIN} [ $# -lt 2 -o $# -gt 3 ]; then\n    _shunit_error \"failNotSame() requires one or two arguments; $# given\"\n    return ${SHUNIT_ERROR}\n  fi\n  if _shunit_shouldSkip; then\n    return ${SHUNIT_TRUE}\n  fi\n\n  shunit_message_=${__shunit_lineno}\n  if ${__SHUNIT_BUILTIN} [ $# -eq 3 ]; then\n    shunit_message_=\"${shunit_message_}$1\"\n    shift\n  fi\n  failNotEquals \"${shunit_message_}\" \"$1\" \"$2\"\n  shunit_return=$?\n\n  unset shunit_message_\n  return ${shunit_return}\n}\n# shellcheck disable=SC2016,SC2034\n_FAIL_NOT_SAME_='eval failNotSame --lineno \"${LINENO:-}\"'\n\n#-----------------------------------------------------------------------------\n# Skipping functions.\n#\n\n# Force remaining assert and fail functions to be \"skipped\".\n#\n# This function forces the remaining assert and fail functions to be \"skipped\",\n# i.e. they will have no effect. Each function skipped will be recorded so that\n# the total of asserts and fails will not be altered.\n#\n# Args:\n#   message: string: message to provide to user [optional]\nstartSkipping() {\n  if ${__SHUNIT_BUILTIN} [ $# -gt 0 ]; then _shunit_warn \"[skipping] $*\"; fi\n  __shunit_skip=${SHUNIT_TRUE}\n}\n\n# Resume the normal recording behavior of assert and fail calls.\n#\n# Args:\n#   None\nendSkipping() { __shunit_skip=${SHUNIT_FALSE}; }\n\n# Returns the state of assert and fail call skipping.\n#\n# Args:\n#   None\n# Returns:\n#   boolean: (TRUE/FALSE constant)\nisSkipping() { return ${__shunit_skip}; }\n\n#-----------------------------------------------------------------------------\n# Suite functions.\n#\n\n# Stub. This function should contains all unit test calls to be made.\n#\n# DEPRECATED (as of 2.1.0)\n#\n# This function can be optionally overridden by the user in their test suite.\n#\n# If this function exists, it will be called when shunit2 is sourced. If it\n# does not exist, shunit2 will search the parent script for all functions\n# beginning with the word 'test', and they will be added dynamically to the\n# test suite.\n#\n# This function should be overridden by the user in their unit test suite.\n# Note: see _shunit_mktempFunc() for actual implementation\n#\n# Args:\n#   None\n#suite() { :; }  # DO NOT UNCOMMENT THIS FUNCTION\n\n# Adds a function name to the list of tests schedule for execution.\n#\n# This function should only be called from within the suite() function.\n#\n# Args:\n#   function: string: name of a function to add to current unit test suite\nsuite_addTest() {\n  shunit_func_=${1:-}\n\n  __shunit_suite=\"${__shunit_suite:+${__shunit_suite} }${shunit_func_}\"\n  __shunit_testsTotal=`expr \"${__shunit_testsTotal}\" + 1`\n\n  unset shunit_func_\n}\n\n# Stub. This function will be called once before any tests are run.\n#\n# Common one-time environment preparation tasks shared by all tests can be\n# defined here.\n#\n# This function should be overridden by the user in their unit test suite.\n# Note: see _shunit_mktempFunc() for actual implementation\n#\n# Args:\n#   None\n#oneTimeSetUp() { :; }  # DO NOT UNCOMMENT THIS FUNCTION\n\n# Stub. This function will be called once after all tests are finished.\n#\n# Common one-time environment cleanup tasks shared by all tests can be defined\n# here.\n#\n# This function should be overridden by the user in their unit test suite.\n# Note: see _shunit_mktempFunc() for actual implementation\n#\n# Args:\n#   None\n#oneTimeTearDown() { :; }  # DO NOT UNCOMMENT THIS FUNCTION\n\n# Stub. This function will be called before each test is run.\n#\n# Common environment preparation tasks shared by all tests can be defined here.\n#\n# This function should be overridden by the user in their unit test suite.\n# Note: see _shunit_mktempFunc() for actual implementation\n#\n# Args:\n#   None\n#setUp() { :; }  # DO NOT UNCOMMENT THIS FUNCTION\n\n# Note: see _shunit_mktempFunc() for actual implementation\n# Stub. This function will be called after each test is run.\n#\n# Common environment cleanup tasks shared by all tests can be defined here.\n#\n# This function should be overridden by the user in their unit test suite.\n# Note: see _shunit_mktempFunc() for actual implementation\n#\n# Args:\n#   None\n#tearDown() { :; }  # DO NOT UNCOMMENT THIS FUNCTION\n\n#------------------------------------------------------------------------------\n# Internal shUnit2 functions.\n#\n\n# Create a temporary directory to store various run-time files in.\n#\n# This function is a cross-platform temporary directory creation tool. Not all\n# OSes have the `mktemp` function, so one is included here.\n#\n# Args:\n#   None\n# Outputs:\n#   string: the temporary directory that was created\n_shunit_mktempDir() {\n  # Try the standard `mktemp` function.\n  if ( exec mktemp -dqt shunit.XXXXXX 2>/dev/null ); then\n    return\n  fi\n\n  # The standard `mktemp` didn't work. Use our own.\n  # shellcheck disable=SC2039,SC3028\n  if ${__SHUNIT_BUILTIN} [ -r '/dev/urandom' -a -x '/usr/bin/od' ]; then\n    _shunit_random_=`/usr/bin/od -vAn -N4 -tx4 </dev/urandom |command sed 's/^[^0-9a-f]*//'`\n  elif ${__SHUNIT_BUILTIN} [ -n \"${RANDOM:-}\" ]; then\n    # $RANDOM works\n    _shunit_random_=${RANDOM}${RANDOM}${RANDOM}$$\n  else\n    # `$RANDOM` doesn't work.\n    _shunit_date_=`date '+%Y%m%d%H%M%S'`\n    _shunit_random_=`expr \"${_shunit_date_}\" / $$`\n  fi\n\n  _shunit_tmpDir_=\"${TMPDIR:-/tmp}/shunit.${_shunit_random_}\"\n  if ! ( umask 077 && command mkdir \"${_shunit_tmpDir_}\" ); then\n    _shunit_fatal 'could not create temporary directory! exiting'\n  fi\n\n  echo \"${_shunit_tmpDir_}\"\n  unset _shunit_date_ _shunit_random_ _shunit_tmpDir_\n}\n\n# This function is here to work around issues in Cygwin.\n#\n# Args:\n#   None\n_shunit_mktempFunc() {\n  for _shunit_func_ in oneTimeSetUp oneTimeTearDown setUp tearDown suite noexec\n  do\n    _shunit_file_=\"${__shunit_tmpDir}/${_shunit_func_}\"\n    command cat <<EOF >\"${_shunit_file_}\"\n#! /bin/sh\nexit ${SHUNIT_TRUE}\nEOF\n    command chmod +x \"${_shunit_file_}\"\n  done\n\n  unset _shunit_file_\n}\n\n# Final cleanup function to leave things as we found them.\n#\n# Besides removing the temporary directory, this function is in charge of the\n# final exit code of the unit test. The exit code is based on how the script\n# was ended (e.g. normal exit, or via Ctrl-C).\n#\n# Args:\n#   name: string: name of the trap called (specified when trap defined)\n_shunit_cleanup() {\n  _shunit_name_=$1\n\n  _shunit_signal_=0\n  case \"${_shunit_name_}\" in\n    EXIT) ;;\n    INT) _shunit_signal_=130 ;;  # 2+128\n    TERM) _shunit_signal_=143 ;;  # 15+128\n    *)\n      _shunit_error \"unrecognized trap value (${_shunit_name_})\"\n      ;;\n  esac\n  if ${__SHUNIT_BUILTIN} [ \"${_shunit_name_}\" != 'EXIT' ]; then\n    _shunit_warn \"trapped and now handling the (${_shunit_name_}) signal\"\n  fi\n\n  # Do our work.\n  if ${__SHUNIT_BUILTIN} [ ${__shunit_clean} -eq ${SHUNIT_FALSE} ]; then\n    # Ensure tear downs are only called once.\n    __shunit_clean=${SHUNIT_TRUE}\n\n    tearDown || _shunit_warn 'tearDown() returned non-zero return code.'\n    oneTimeTearDown || \\\n        _shunit_warn 'oneTimeTearDown() returned non-zero return code.'\n\n    command rm -fr \"${__shunit_tmpDir}\"\n  fi\n\n  if ${__SHUNIT_BUILTIN} [ \"${_shunit_name_}\" != 'EXIT' ]; then\n    # Handle all non-EXIT signals.\n    trap - 0  # Disable EXIT trap.\n    exit ${_shunit_signal_}\n  elif ${__SHUNIT_BUILTIN} [ ${__shunit_reportGenerated} -eq ${SHUNIT_FALSE} ]; then\n    _shunit_assertFail 'unknown failure encountered running a test'\n    _shunit_generateReport\n    exit ${SHUNIT_ERROR}\n  fi\n\n  unset _shunit_name_ _shunit_signal_\n}\n\n# configureColor based on user color preference.\n#\n# Args:\n#   color: string: color mode (one of `always`, `auto`, or `never`).\n_shunit_configureColor() {\n  _shunit_color_=${SHUNIT_FALSE}  # By default, no color.\n  case $1 in\n    'always') _shunit_color_=${SHUNIT_TRUE} ;;\n    'auto')\n      if ${__SHUNIT_BUILTIN} [ \"`_shunit_colors`\" -ge 8 ]; then\n        _shunit_color_=${SHUNIT_TRUE}\n      fi\n      ;;\n    'never'|'none') ;;  # Support 'none' to support legacy usage.\n    *) _shunit_fatal \"unrecognized color option '$1'\" ;;\n  esac\n\n  # shellcheck disable=SC2254\n  case ${_shunit_color_} in\n    ${SHUNIT_TRUE})\n      __shunit_ansi_none=${__SHUNIT_ANSI_NONE}\n      __shunit_ansi_red=${__SHUNIT_ANSI_RED}\n      __shunit_ansi_green=${__SHUNIT_ANSI_GREEN}\n      __shunit_ansi_yellow=${__SHUNIT_ANSI_YELLOW}\n      __shunit_ansi_cyan=${__SHUNIT_ANSI_CYAN}\n      ;;\n    ${SHUNIT_FALSE})\n      __shunit_ansi_none=''\n      __shunit_ansi_red=''\n      __shunit_ansi_green=''\n      __shunit_ansi_yellow=''\n      __shunit_ansi_cyan=''\n      ;;\n  esac\n\n  unset _shunit_color_ _shunit_tput_\n}\n\n# colors returns the number of supported colors for the TERM.\n_shunit_colors() {\n  if _shunit_tput_=`${SHUNIT_CMD_TPUT} colors 2>/dev/null`; then\n    echo \"${_shunit_tput_}\"\n  else\n    echo 16\n  fi\n  unset _shunit_tput_\n}\n\n# The actual running of the tests happens here.\n#\n# Args:\n#   None\n_shunit_execSuite() {\n  for _shunit_test_ in ${__shunit_suite}; do\n    __shunit_testSuccess=${SHUNIT_TRUE}\n\n    # Reset per-test info\n    __shunit_assertsCurrentTest=0\n    __shunit_junitXmlCurrentTestCaseErrors=''\n\n    # Disable skipping.\n    endSkipping\n\n    # Execute the per-test setUp() function.\n    if ! setUp; then\n      _shunit_fatal \"setUp() returned non-zero return code.\"\n    fi\n\n    # Execute the test.\n    echo \"${__SHUNIT_TEST_PREFIX}${_shunit_test_}\"\n    # shellcheck disable=SC2086\n    if ! eval ${_shunit_test_}; then\n      _shunit_error \"${_shunit_test_}() returned non-zero return code.\"\n      __shunit_testSuccess=${SHUNIT_ERROR}\n    fi\n\n    # Execute the per-test tearDown() function.\n    if ! tearDown; then\n      _shunit_fatal \"tearDown() returned non-zero return code.\"\n    fi\n\n    # Store current test case info in JUnit XML.\n    __shunit_junitXmlTestCases=\"${__shunit_junitXmlTestCases}\n  <testcase\n    classname=\\\"${__shunit_xmlSuiteName}\\\"\n    name=\\\"${_shunit_test_}\\\"\n    assertions=\\\"${__shunit_assertsCurrentTest}\\\"\n  >${__shunit_junitXmlCurrentTestCaseErrors}\n  </testcase>\"\n\n    # Update stats.\n    if ${__SHUNIT_BUILTIN} [ ${__shunit_testSuccess} -eq ${SHUNIT_TRUE} ]; then\n      __shunit_testsPassed=`expr \"${__shunit_testsPassed}\" + 1`\n    else\n      __shunit_testsFailed=`expr \"${__shunit_testsFailed}\" + 1`\n    fi\n  done\n\n  unset _shunit_test_\n}\n\n# Generates the user friendly report with appropriate OK/FAILED message.\n#\n# Args:\n#   None\n# Output:\n#   string: the report of successful and failed tests, as well as totals.\n_shunit_generateReport() {\n  if ${__SHUNIT_BUILTIN} [ \"${__shunit_reportGenerated}\" -eq ${SHUNIT_TRUE} ]; then\n    return\n  fi\n\n  _shunit_ok_=${SHUNIT_TRUE}\n\n  # If no exit code was provided, determine an appropriate one.\n  if ${__SHUNIT_BUILTIN} [ \"${__shunit_testsFailed}\" -gt 0 -o ${__shunit_testSuccess} -eq ${SHUNIT_FALSE} ]; then\n    _shunit_ok_=${SHUNIT_FALSE}\n  fi\n\n  echo\n  _shunit_msg_=\"Ran ${__shunit_ansi_cyan}${__shunit_testsTotal}${__shunit_ansi_none}\"\n  if ${__SHUNIT_BUILTIN} [ \"${__shunit_testsTotal}\" -eq 1 ]; then\n    ${__SHUNIT_CMD_ECHO_ESC} \"${_shunit_msg_} test.\"\n  else\n    ${__SHUNIT_CMD_ECHO_ESC} \"${_shunit_msg_} tests.\"\n  fi\n\n  if ${__SHUNIT_BUILTIN} [ -n \"${__shunit_junitXmlOutputFile}\" ]; then\n    echo \"<?xml version=\\\"1.0\\\" encoding=\\\"UTF-8\\\"?>\n<testsuite\n  failures=\\\"${__shunit_testsFailed}\\\"\n  name=\\\"${__shunit_xmlSuiteName}\\\"\n  tests=\\\"${__shunit_testsTotal}\\\"\n  assertions=\\\"${__shunit_assertsTotal}\\\"\n>${__shunit_junitXmlTestCases}\n</testsuite>\" > \"${__shunit_junitXmlOutputFile}\"\n    echo\n    echo \"JUnit XML file ${__shunit_junitXmlOutputFile} was saved.\"\n  fi\n\n  if ${__SHUNIT_BUILTIN} [ ${_shunit_ok_} -eq ${SHUNIT_TRUE} ]; then\n    _shunit_msg_=\"${__shunit_ansi_green}OK${__shunit_ansi_none}\"\n    if ${__SHUNIT_BUILTIN} [ \"${__shunit_assertsSkipped}\" -gt 0 ]; then\n      _shunit_msg_=\"${_shunit_msg_} (${__shunit_ansi_yellow}skipped=${__shunit_assertsSkipped}${__shunit_ansi_none})\"\n    fi\n  else\n    _shunit_msg_=\"${__shunit_ansi_red}FAILED${__shunit_ansi_none}\"\n    _shunit_msg_=\"${_shunit_msg_} (${__shunit_ansi_red}failures=${__shunit_assertsFailed}${__shunit_ansi_none}\"\n    if ${__SHUNIT_BUILTIN} [ \"${__shunit_assertsSkipped}\" -gt 0 ]; then\n      _shunit_msg_=\"${_shunit_msg_},${__shunit_ansi_yellow}skipped=${__shunit_assertsSkipped}${__shunit_ansi_none}\"\n    fi\n    _shunit_msg_=\"${_shunit_msg_})\"\n  fi\n\n  echo\n  ${__SHUNIT_CMD_ECHO_ESC} \"${_shunit_msg_}\"\n  __shunit_reportGenerated=${SHUNIT_TRUE}\n\n  unset _shunit_msg_ _shunit_ok_\n}\n\n# Test for whether a function should be skipped.\n#\n# Args:\n#   None\n# Returns:\n#   boolean: whether the test should be skipped (TRUE/FALSE constant)\n_shunit_shouldSkip() {\n  if ${__SHUNIT_BUILTIN} test ${__shunit_skip} -eq ${SHUNIT_FALSE}; then\n    return ${SHUNIT_FALSE}\n  fi\n  _shunit_assertSkip\n}\n\n# Records a successful test.\n#\n# Args:\n#   None\n_shunit_assertPass() {\n  __shunit_assertsPassed=`expr \"${__shunit_assertsPassed}\" + 1`\n  __shunit_assertsTotal=`expr \"${__shunit_assertsTotal}\" + 1`\n  __shunit_assertsCurrentTest=`expr \"${__shunit_assertsCurrentTest}\" + 1`\n}\n\n# Records a test failure.\n#\n# Args:\n#   message: string: failure message to provide user\n_shunit_assertFail() {\n  __shunit_testSuccess=${SHUNIT_FALSE}\n  _shunit_incFailedCount\n\n  _shunit_xml_message_=\"`_shunit_escapeXmlData \"$@\"`\"\n\n  __shunit_junitXmlCurrentTestCaseErrors=\"${__shunit_junitXmlCurrentTestCaseErrors}\n    <failure\n      type=\\\"shunit.assertFail\\\"\n      message=\\\"${_shunit_xml_message_}\\\"\n    />\"\n\n  if ${__SHUNIT_BUILTIN} [ $# -gt 0 ]; then\n    ${__SHUNIT_CMD_ECHO_ESC} \"${__shunit_ansi_red}ASSERT:${__shunit_ansi_none}$*\"\n  fi\n\n  unset _shunit_xml_message_\n}\n\n# Increment the count of failed asserts.\n#\n# Args:\n#   none\n_shunit_incFailedCount() {\n  __shunit_assertsFailed=`expr \"${__shunit_assertsFailed}\" + 1`\n  __shunit_assertsTotal=`expr \"${__shunit_assertsTotal}\" + 1`\n  __shunit_assertsCurrentTest=`expr \"${__shunit_assertsCurrentTest}\" + 1`\n}\n\n# Records a skipped test.\n#\n# Args:\n#   None\n_shunit_assertSkip() {\n  __shunit_assertsSkipped=`expr \"${__shunit_assertsSkipped}\" + 1`\n  __shunit_assertsTotal=`expr \"${__shunit_assertsTotal}\" + 1`\n  __shunit_assertsCurrentTest=`expr \"${__shunit_assertsCurrentTest}\" + 1`\n}\n\n# Dump the current test metrics.\n#\n# Args:\n#   none\n_shunit_metrics() {\n  echo \"< \\\ntotal: ${__shunit_assertsTotal} \\\npassed: ${__shunit_assertsPassed} \\\nfailed: ${__shunit_assertsFailed} \\\nskipped: ${__shunit_assertsSkipped} \\\n>\"\n}\n\n# Prepare a script filename for sourcing.\n#\n# Args:\n#   script: string: path to a script to source\n# Returns:\n#   string: filename prefixed with ./ (if necessary)\n_shunit_prepForSourcing() {\n  _shunit_script_=$1\n  case \"${_shunit_script_}\" in\n    /*|./*) echo \"${_shunit_script_}\" ;;\n    *) echo \"./${_shunit_script_}\" ;;\n  esac\n  unset _shunit_script_\n}\n\n# Extract list of functions to run tests against.\n#\n# Args:\n#   script: string: name of script to extract functions from\n# Returns:\n#   string: of function names\n_shunit_extractTestFunctions() {\n  _shunit_script_=$1\n\n  # Extract the lines with test function names, strip of anything besides the\n  # function name, and output everything on a single line.\n  _shunit_regex_='^\\s*((function test[A-Za-z0-9_-]*)|(test[A-Za-z0-9_-]* *\\(\\)))'\n  grep -E \"${_shunit_regex_}\" \"${_shunit_script_}\" \\\n  |command sed 's/^[^A-Za-z0-9_-]*//;s/^function //;s/\\([A-Za-z0-9_-]*\\).*/\\1/g' \\\n  |xargs\n\n  unset _shunit_regex_ _shunit_script_\n}\n\n# Escape XML data.\n#\n# Args:\n#   data: string: data to escape\n# Returns:\n#   string: escaped data\n_shunit_escapeXmlData() {\n  # Required XML characters to escape are described here:\n  # http://www.w3.org/TR/REC-xml/#syntax\n  # https://www.liquid-technologies.com/Reference/Glossary/XML_EscapingData.html\n  echo \"$*\" \\\n  |command sed 's/&/\\&amp;/g;s/</\\&lt;/g;s/>/\\&gt;/g;s/\"/\\&quot;/g'\";s/'/\\&apos;/g\"\n}\n\n#------------------------------------------------------------------------------\n# Main.\n#\n\n# Determine the operating mode.\nif ${__SHUNIT_BUILTIN} [ $# -eq 0 -o \"${1:-}\" = '--' ]; then\n  __shunit_script=${__SHUNIT_PARENT}\n  __shunit_mode=${__SHUNIT_MODE_SOURCED}\nelse\n  __shunit_script=$1\n  if ! ${__SHUNIT_BUILTIN} [ -r \"${__shunit_script}\" ]; then\n    _shunit_fatal \"unable to read from ${__shunit_script}\"\n  fi\n  __shunit_mode=${__SHUNIT_MODE_STANDALONE}\nfi\n\n# Create a temporary storage location.\n__shunit_tmpDir=`_shunit_mktempDir`\n\n# Provide a public temporary directory for unit test scripts.\n# TODO(kward): document this.\nSHUNIT_TMPDIR=\"${__shunit_tmpDir}/tmp\"\nif ! command mkdir \"${SHUNIT_TMPDIR}\"; then\n  _shunit_fatal \"error creating SHUNIT_TMPDIR '${SHUNIT_TMPDIR}'\"\nfi\n\n# Configure traps to clean up after ourselves.\ntrap '_shunit_cleanup EXIT' 0\ntrap '_shunit_cleanup INT' 2\ntrap '_shunit_cleanup TERM' 15\n\n# Create phantom functions to work around issues with Cygwin.\n_shunit_mktempFunc\nPATH=\"${__shunit_tmpDir}:${PATH}\"\n\n# Make sure phantom functions are executable. This will bite if `/tmp` (or the\n# current `$TMPDIR`) points to a path on a partition that was mounted with the\n# 'noexec' option. The noexec command was created with `_shunit_mktempFunc()`.\nnoexec 2>/dev/null || _shunit_fatal \\\n    'Please declare TMPDIR with path on partition with exec permission.'\n\n# We must manually source the tests in standalone mode.\nif ${__SHUNIT_BUILTIN} [ \"${__shunit_mode}\" = \"${__SHUNIT_MODE_STANDALONE}\" ]; then\n  # shellcheck disable=SC1090\n  ${__SHUNIT_BUILTIN} . \"`_shunit_prepForSourcing \\\"${__shunit_script}\\\"`\"\nfi\n\n# Configure default output coloring behavior.\n_shunit_configureColor \"${SHUNIT_COLOR}\"\n\n# Execute the oneTimeSetUp function (if it exists).\nif ! oneTimeSetUp; then\n  _shunit_fatal \"oneTimeSetUp() returned non-zero return code.\"\nfi\n\n# Command line selected tests or suite selected tests\nif ${__SHUNIT_BUILTIN} [ \"$#\" -ge 2 ]; then\n  # Argument $1 is either the filename of tests or '--'; either way, skip it.\n  shift\n  # Remaining arguments ($2 .. $#) are assumed to be:\n  #   - test function names.\n  #   - configuration options, that is started with the `--` prefix.\n  # Interate through all remaining args in \"$@\" in a POSIX (likely portable) way.\n  # Helpful tip: https://unix.stackexchange.com/questions/314032/how-to-use-arguments-like-1-2-in-a-for-loop\n  for _shunit_arg_ do\n    case \"${_shunit_arg_}\" in\n      --output-junit-xml=*)\n        # It is a request for JUnit XML output.\n        __shunit_junitXmlOutputFile=\"${_shunit_arg_#--output-junit-xml=}\"\n        ;;\n      --suite-name=*)\n        # It is a request for a custom suite name.\n        __shunit_suiteName=\"${_shunit_arg_#--suite-name=}\"\n        ;;\n      --*)\n        _shunit_fatal \"unrecognized option \\\"${_shunit_arg_}\\\"\"\n        ;;\n      *)\n        # It is the test name, process it in a usual way.\n        suite_addTest \"${_shunit_arg_}\"\n        ;;\n    esac\n  done\n  unset _shunit_arg_\nelse\n  # Execute the suite function defined in the parent test script.\n  # DEPRECATED as of 2.1.0.\n  suite\nfi\n\n# If no tests or suite specified, dynamically build a list of functions.\nif ${__SHUNIT_BUILTIN} [ -z \"${__shunit_suite}\" ]; then\n  shunit_funcs_=`_shunit_extractTestFunctions \"${__shunit_script}\"`\n  for shunit_func_ in ${shunit_funcs_}; do\n    suite_addTest \"${shunit_func_}\"\n  done\nfi\nunset shunit_func_ shunit_funcs_\n\n# If suite name is not defined, dynamically generate it from the script name.\nif ${__SHUNIT_BUILTIN} [ -z \"${__shunit_suiteName}\" ]; then\n  __shunit_suiteName=\"${__shunit_script##*/}\"\nfi\n\n# Prepare the suite name for XML output.\n__shunit_xmlSuiteName=\"`_shunit_escapeXmlData \"${__shunit_suiteName}\"`\"\n\n# Execute the suite of unit tests.\n_shunit_execSuite\n\n# Execute the oneTimeTearDown function (if it exists).\nif ! oneTimeTearDown; then\n  _shunit_fatal \"oneTimeTearDown() returned non-zero return code.\"\nfi\n\n# Generate a report summary.\n_shunit_generateReport\n\n# That's it folks.\nif ! ${__SHUNIT_BUILTIN} [ \"${__shunit_testsFailed}\" -eq 0 ]; then\n  return ${SHUNIT_FALSE}\nfi\n"
        },
        {
          "name": "shunit2_args_test.sh",
          "type": "blob",
          "size": 2.0048828125,
          "content": "#!/bin/sh\n# vim:et:ft=sh:sts=2:sw=2\n#\n# shunit2 unit test for running subset(s) of tests based upon command line args.\n#\n# Copyright 2008-2021 Kate Ward. All Rights Reserved.\n# Released under the Apache 2.0 license.\n# http://www.apache.org/licenses/LICENSE-2.0\n#\n# https://github.com/kward/shunit2\n#\n# Also shows how non-default tests or a arbitrary subset of tests can be run.\n#\n# Disable source following.\n#   shellcheck disable=SC1090,SC1091\n\n# Load test helpers.\n. ./shunit2_test_helpers\n\nCUSTOM_TEST_RAN=''\n\n# This test does not normally run because it does not begin \"test*\". Will be\n# run by setting the arguments to the script to include the name of this test.\ncustom_test() {\n  # Arbitrary assert.\n  assertTrue 0\n  # The true intent is to set this variable, which will be tested below.\n  CUSTOM_TEST_RAN='yup, we ran'\n}\n\n# Verify that `customTest()` ran.\ntestCustomTestRan() {\n  assertNotNull \"'custom_test()' did not run\" \"${CUSTOM_TEST_RAN}\"\n}\n\n# Fail if this test runs, which is shouldn't if arguments are set correctly.\ntestShouldFail() {\n  fail 'testShouldFail should not be run if argument parsing works'\n}\n\noneTimeSetUp() {\n  th_oneTimeSetUp\n}\n\n# If zero/one argument(s) are provided, this test is being run in it's\n# entirety, and therefore we want to set the arguments to the script to\n# (simulate and) test the processing of command-line specified tests.  If we\n# don't, then the \"test_will_fail\" test will run (by default) and the overall\n# test will fail.\n#\n# However, if two or more arguments are provided, then assume this test script\n# is being run by hand to experiment with command-line test specification, and\n# then don't override the user provided arguments.\nif [ \"$#\" -le 1 ]; then\n  # We set the arguments in a POSIX way, inasmuch as we can;\n  # helpful tip:\n  #   https://unix.stackexchange.com/questions/258512/how-to-remove-a-positional-parameter-from\n  set -- '--' 'custom_test' 'testCustomTestRan'\nfi\n\n# Load and run shunit2.\n# shellcheck disable=SC2034\n[ -n \"${ZSH_VERSION:-}\" ] && SHUNIT_PARENT=$0\n. \"${TH_SHUNIT}\"\n"
        },
        {
          "name": "shunit2_asserts_test.sh",
          "type": "blob",
          "size": 10.4560546875,
          "content": "#! /bin/sh\n# vim:et:ft=sh:sts=2:sw=2\n#\n# shunit2 unit test for assert functions.\n#\n# Copyright 2008-2021 Kate Ward. All Rights Reserved.\n# Released under the Apache 2.0 license.\n# http://www.apache.org/licenses/LICENSE-2.0\n#\n# Author: kate.ward@forestent.com (Kate Ward)\n# https://github.com/kward/shunit2\n#\n# In this file, all assert calls under test must be wrapped in () so they do not\n# influence the metrics of the test itself.\n#\n# Disable source following.\n#   shellcheck disable=SC1090,SC1091\n\n# These variables will be overridden by the test helpers.\nstdoutF=\"${TMPDIR:-/tmp}/STDOUT\"\nstderrF=\"${TMPDIR:-/tmp}/STDERR\"\n\n# Load test helpers.\n. ./shunit2_test_helpers\n\ncommonEqualsSame() {\n  fn=$1\n\n  # These should succeed.\n\n  desc='equal'\n  if (${fn} 'x' 'x' >\"${stdoutF}\" 2>\"${stderrF}\"); then\n    th_assertTrueWithNoOutput \"${desc}\" $? \"${stdoutF}\" \"${stderrF}\"\n  else\n    fail \"${desc}: unexpected failure\"\n    _showTestOutput\n  fi\n\n  desc='equal_with_message'\n  if (${fn} 'some message' 'x' 'x' >\"${stdoutF}\" 2>\"${stderrF}\"); then\n    th_assertTrueWithNoOutput \"${desc}\" $? \"${stdoutF}\" \"${stderrF}\"\n  else\n    fail \"${desc}: unexpected failure\"\n    _showTestOutput\n  fi\n\n  desc='equal_with_spaces'\n  if (${fn} 'abc def' 'abc def' >\"${stdoutF}\" 2>\"${stderrF}\"); then\n    th_assertTrueWithNoOutput \"${desc}\" $? \"${stdoutF}\" \"${stderrF}\"\n  else\n    fail \"${desc}: unexpected failure\"\n    _showTestOutput\n  fi\n\n  desc='equal_null_values'\n  if (${fn} '' '' >\"${stdoutF}\" 2>\"${stderrF}\"); then\n    th_assertTrueWithNoOutput \"${desc}\" $? \"${stdoutF}\" \"${stderrF}\"\n  else\n    fail \"${desc}: unexpected failure\"\n    _showTestOutput\n  fi\n\n  # These should fail.\n\n  desc='not_equal'\n  if (${fn} 'x' 'y' >\"${stdoutF}\" 2>\"${stderrF}\"); then\n    fail \"${desc}: expected a failure\"\n    _showTestOutput\n  else\n    th_assertFalseWithOutput \"${desc}\" $? \"${stdoutF}\" \"${stderrF}\"\n  fi\n}\n\ncommonNotEqualsSame() {\n  fn=$1\n\n  # These should succeed.\n\n  desc='not_same'\n  if (${fn} 'x' 'y' >\"${stdoutF}\" 2>\"${stderrF}\"); then\n    th_assertTrueWithNoOutput \"${desc}\" $? \"${stdoutF}\" \"${stderrF}\"\n  else\n    fail \"${desc}: unexpected failure\"\n    _showTestOutput\n  fi\n\n  desc='not_same_with_message'\n  if (${fn} 'some message' 'x' 'y' >\"${stdoutF}\" 2>\"${stderrF}\"); then\n    th_assertTrueWithNoOutput \"${desc}\" $? \"${stdoutF}\" \"${stderrF}\"\n  else\n    fail \"${desc}: unexpected failure\"\n    _showTestOutput\n  fi\n\n  # These should fail.\n\n  desc='same'\n  if (${fn} 'x' 'x' >\"${stdoutF}\" 2>\"${stderrF}\"); then\n    fail \"${desc}: expected a failure\"\n    _showTestOutput\n  else\n    th_assertFalseWithOutput \"${desc}\" $? \"${stdoutF}\" \"${stderrF}\"\n  fi\n\n  desc='unequal_null_values'\n  if (${fn} '' '' >\"${stdoutF}\" 2>\"${stderrF}\"); then\n    fail \"${desc}: expected a failure\"\n    _showTestOutput\n  else\n    th_assertFalseWithOutput \"${desc}\" $? \"${stdoutF}\" \"${stderrF}\"\n  fi\n}\n\ntestAssertEquals()    { commonEqualsSame 'assertEquals'; }\ntestAssertNotEquals() { commonNotEqualsSame 'assertNotEquals'; }\ntestAssertSame()      { commonEqualsSame 'assertSame'; }\ntestAssertNotSame()   { commonNotEqualsSame 'assertNotSame'; }\n\ntestAssertContains() {\n  # Content is present.\n  while read -r desc container content; do\n    if (assertContains \"${container}\" \"${content}\" >\"${stdoutF}\" 2>\"${stderrF}\"); then\n      th_assertTrueWithNoOutput \"${desc}\" $? \"${stdoutF}\" \"${stderrF}\"\n    else\n      fail \"${desc}: unexpected failure\"\n      _showTestOutput\n    fi\n  done <<EOF\nabc_at_start  abcdef abc\nbcd_in_middle abcdef bcd\ndef_at_end    abcdef def\nEOF\n\n  # Content missing.\n  while read -r desc container content; do\n    if (assertContains \"${container}\" \"${content}\" >\"${stdoutF}\" 2>\"${stderrF}\"); then\n      fail \"${desc}: unexpected failure\"\n      _showTestOutput\n    else\n      th_assertFalseWithOutput \"${desc}\" $? \"${stdoutF}\" \"${stderrF}\"\n    fi\n  done <<EOF\nxyz_not_present    abcdef xyz\nzab_contains_start abcdef zab\nefg_contains_end   abcdef efg\nacf_has_parts      abcdef acf\nEOF\n\n  desc=\"content_starts_with_dash\"\n  if (assertContains 'abc -Xabc def' '-Xabc' >\"${stdoutF}\" 2>\"${stderrF}\"); then\n    th_assertTrueWithNoOutput \"${desc}\" $? \"${stdoutF}\" \"${stderrF}\"\n  else\n    fail \"${desc}: unexpected failure\"\n    _showTestOutput\n  fi\n\n  desc=\"contains_with_message\"\n  if (assertContains 'some message' 'abcdef' 'abc' >\"${stdoutF}\" 2>\"${stderrF}\"); then\n    th_assertTrueWithNoOutput \"${desc}\" $? \"${stdoutF}\" \"${stderrF}\"\n  else\n    fail \"${desc}: unexpected failure\"\n    _showTestOutput\n  fi\n}\n\ntestAssertNotContains() {\n  # Content not present.\n  while read -r desc container content; do\n    if (assertNotContains \"${container}\" \"${content}\" >\"${stdoutF}\" 2>\"${stderrF}\"); then\n      th_assertTrueWithNoOutput \"${desc}\" $? \"${stdoutF}\" \"${stderrF}\"\n    else\n      fail \"${desc}: unexpected failure\"\n      _showTestOutput\n    fi\n  done <<EOF\nxyz_not_present    abcdef xyz\nzab_contains_start abcdef zab\nefg_contains_end   abcdef efg\nacf_has_parts      abcdef acf\nEOF\n\n  # Content present.\n  while read -r desc container content; do\n    if (assertNotContains \"${container}\" \"${content}\" >\"${stdoutF}\" 2>\"${stderrF}\"); then\n      fail \"${desc}: expected a failure\"\n      _showTestOutput\n    else\n      th_assertFalseWithOutput \"${desc}\" $? \"${stdoutF}\" \"${stderrF}\"\n    fi\n  done <<EOF\nabc_is_present abcdef abc\nEOF\n\n  desc='not_contains_with_message'\n  if (assertNotContains 'some message' 'abcdef' 'xyz' >\"${stdoutF}\" 2>\"${stderrF}\"); then\n    th_assertTrueWithNoOutput \"${desc}\" $? \"${stdoutF}\" \"${stderrF}\"\n  else\n    fail \"${desc}: unexpected failure\"\n    _showTestOutput\n  fi\n}\n\ntestAssertNull() {\n  while read -r desc value; do\n    if (assertNull \"${value}\" >\"${stdoutF}\" 2>\"${stderrF}\"); then\n      fail \"${desc}: unexpected failure\"\n      _showTestOutput\n    else\n      th_assertFalseWithOutput \"${desc}\" $? \"${stdoutF}\" \"${stderrF}\"\n    fi\n  done <<'EOF'\nx_alone          x\nx_double_quote_a x\"a\nx_single_quote_a x'a\nx_dollar_a       x$a\nx_backtick_a     x`a\nEOF\n\n  desc='null_without_message'\n  if (assertNull '' >\"${stdoutF}\" 2>\"${stderrF}\"); then\n    th_assertTrueWithNoOutput \"${desc}\" $? \"${stdoutF}\" \"${stderrF}\"\n  else\n    fail \"${desc}: unexpected failure\"\n    _showTestOutput\n  fi\n\n  desc='null_with_message'\n  if (assertNull 'some message' '' >\"${stdoutF}\" 2>\"${stderrF}\"); then\n    th_assertTrueWithNoOutput \"${desc}\" $? \"${stdoutF}\" \"${stderrF}\"\n  else\n    fail \"${desc}: unexpected failure\"\n    _showTestOutput\n  fi\n\n  desc='x_is_not_null'\n  if (assertNull 'x' >\"${stdoutF}\" 2>\"${stderrF}\"); then\n    fail \"${desc}: expected a failure\"\n    _showTestOutput\n  else\n    th_assertFalseWithOutput \"${desc}\" $? \"${stdoutF}\" \"${stderrF}\"\n  fi\n}\n\ntestAssertNotNull() {\n  while read -r desc value; do\n    if (assertNotNull \"${value}\" >\"${stdoutF}\" 2>\"${stderrF}\"); then\n      th_assertTrueWithNoOutput \"${desc}\" $? \"${stdoutF}\" \"${stderrF}\"\n    else\n      fail \"${desc}: unexpected failure\"\n      _showTestOutput\n    fi\n  done <<'EOF'\nx_alone          x\nx_double_quote_b x\"b\nx_single_quote_b x'b\nx_dollar_b       x$b\nx_backtick_b     x`b\nEOF\n\n  desc='not_null_with_message'\n  if (assertNotNull 'some message' 'x' >\"${stdoutF}\" 2>\"${stderrF}\"); then\n    th_assertTrueWithNoOutput \"${desc}\" $? \"${stdoutF}\" \"${stderrF}\"\n  else\n    fail \"${desc}: unexpected failure\"\n    _showTestOutput\n  fi\n\n  desc=\"double_ticks_are_null\"\n  if (assertNotNull '' >\"${stdoutF}\" 2>\"${stderrF}\"); then\n    fail \"${desc}: expected a failure\"\n    _showTestOutput\n  else\n    th_assertFalseWithOutput \"${desc}\" $? \"${stdoutF}\" \"${stderrF}\"\n  fi\n}\n\ntestAssertTrue() {\n  # True values.\n  while read -r desc value; do\n    if (assertTrue \"${value}\" >\"${stdoutF}\" 2>\"${stderrF}\"); then\n      th_assertTrueWithNoOutput \"${desc}\" $? \"${stdoutF}\" \"${stderrF}\"\n    else\n      fail \"${desc}: unexpected failure\"\n      _showTestOutput\n    fi\n  done <<'EOF'\nzero         0\nzero_eq_zero [ 0 -eq 0 ]\nEOF\n\n  # Not true values.\n  while read -r desc value; do\n    if (assertTrue \"${value}\" >\"${stdoutF}\" 2>\"${stderrF}\"); then\n      fail \"${desc}: expected a failure\"\n      _showTestOutput\n    else\n      th_assertFalseWithOutput \"${desc}\" $? \"${stdoutF}\" \"${stderrF}\"\n    fi\n  done <<EOF\none       1\nzero_eq_1 [ 0 -eq 1 ]\nnull\nEOF\n\n  desc='true_with_message'\n  if (assertTrue 'some message' 0 >\"${stdoutF}\" 2>\"${stderrF}\"); then\n    th_assertTrueWithNoOutput \"${desc}\" $? \"${stdoutF}\" \"${stderrF}\"\n  else\n    fail \"${desc}: unexpected failure\"\n    _showTestOutput\n  fi\n}\n\ntestAssertFalse() {\n  # False values.\n  while read -r desc value; do\n    if (assertFalse \"${value}\" >\"${stdoutF}\" 2>\"${stderrF}\"); then\n      th_assertTrueWithNoOutput \"${desc}\" $? \"${stdoutF}\" \"${stderrF}\"\n    else\n      fail \"${desc}: unexpected failure\"\n      _showTestOutput\n    fi\n  done <<EOF\none       1\nzero_eq_1 [ 0 -eq 1 ]\nnull\nEOF\n\n  # Not true values.\n  while read -r desc value; do\n    if (assertFalse \"${value}\" >\"${stdoutF}\" 2>\"${stderrF}\"); then\n      fail \"${desc}: expected a failure\"\n      _showTestOutput\n    else\n      th_assertFalseWithOutput \"${desc}\" $? \"${stdoutF}\" \"${stderrF}\"\n    fi\n  done <<'EOF'\nzero         0\nzero_eq_zero [ 0 -eq 0 ]\nEOF\n\n  desc='false_with_message'\n  if (assertFalse 'some message' 1 >\"${stdoutF}\" 2>\"${stderrF}\"); then\n    th_assertTrueWithNoOutput \"${desc}\" $? \"${stdoutF}\" \"${stderrF}\"\n  else\n    fail \"${desc}: unexpected failure\"\n    _showTestOutput\n  fi\n}\n\nFUNCTIONS='\nassertEquals assertNotEquals\nassertSame assertNotSame\nassertContains assertNotContains\nassertNull assertNotNull\nassertTrue assertFalse\n'\n\ntestTooFewArguments() {\n  for fn in ${FUNCTIONS}; do\n    # These functions support zero arguments.\n    case \"${fn}\" in\n      assertNull) continue ;;\n      assertNotNull) continue ;;\n    esac\n\n    desc=\"${fn}\"\n    if (${fn} >\"${stdoutF}\" 2>\"${stderrF}\"); then\n      fail \"${desc}: expected a failure\"\n      _showTestOutput\n    else\n      got=$? want=${SHUNIT_ERROR}\n      assertEquals \"${desc}: incorrect return code\" \"${got}\" \"${want}\"\n      th_assertFalseWithError \"${desc}\" \"${got}\" \"${stdoutF}\" \"${stderrF}\"\n    fi\n  done\n}\n\ntestTooManyArguments() {\n  for fn in ${FUNCTIONS}; do\n    desc=\"${fn}\"\n    if (${fn} arg1 arg2 arg3 arg4 >\"${stdoutF}\" 2>\"${stderrF}\"); then\n      fail \"${desc}: expected a failure\"\n      _showTestOutput\n    else\n      got=$? want=${SHUNIT_ERROR}\n      assertEquals \"${desc}: incorrect return code\" \"${got}\" \"${want}\"\n      th_assertFalseWithError \"${desc}\" \"${got}\" \"${stdoutF}\" \"${stderrF}\"\n    fi\n  done\n}\n\noneTimeSetUp() {\n  th_oneTimeSetUp\n}\n\n# showTestOutput for the most recently run test.\n_showTestOutput() { th_showOutput \"${SHUNIT_FALSE}\" \"${stdoutF}\" \"${stderrF}\"; }\n\n# Load and run shunit2.\n# shellcheck disable=SC2034\n[ -n \"${ZSH_VERSION:-}\" ] && SHUNIT_PARENT=$0\n. \"${TH_SHUNIT}\"\n"
        },
        {
          "name": "shunit2_failures_test.sh",
          "type": "blob",
          "size": 3.40625,
          "content": "#! /bin/sh\n# vim:et:ft=sh:sts=2:sw=2\n#\n# shUnit2 unit test for failure functions. These functions do not test values.\n#\n# Copyright 2008-2021 Kate Ward. All Rights Reserved.\n# Released under the Apache 2.0 license.\n# http://www.apache.org/licenses/LICENSE-2.0\n#\n# Author: kate.ward@forestent.com (Kate Ward)\n# https://github.com/kward/shunit2\n#\n# Disable source following.\n#   shellcheck disable=SC1090,SC1091\n\n# These variables will be overridden by the test helpers.\nstdoutF=\"${TMPDIR:-/tmp}/STDOUT\"\nstderrF=\"${TMPDIR:-/tmp}/STDERR\"\n\n# Load test helpers.\n. ./shunit2_test_helpers\n\ntestFail() {\n  # Test without a message.\n  desc='fail_without_message'\n  if ( fail >\"${stdoutF}\" 2>\"${stderrF}\" ); then\n    fail \"${desc}: expected a failure\"\n    th_showOutput\n  else\n    th_assertFalseWithOutput \"${desc}\" $? \"${stdoutF}\" \"${stderrF}\"\n  fi\n\n  # Test with a message.\n  desc='fail_with_message'\n  if ( fail 'some message' >\"${stdoutF}\" 2>\"${stderrF}\" ); then\n    fail \"${desc}: expected a failure\"\n    th_showOutput\n  else\n    th_assertFalseWithOutput \"${desc}\" $? \"${stdoutF}\" \"${stderrF}\"\n  fi\n}\n\n# FN_TESTS hold all the functions to be tested.\n# shellcheck disable=SC2006\nFN_TESTS=`\n# fn num_args pattern\ncat <<EOF\nfail          1\nfailNotEquals 3 but was:\nfailFound     2 found:\nfailNotFound  2 not found:\nfailSame      3 not same\nfailNotSame   3 but was:\nEOF\n`\n\ntestFailsWithArgs() {\n  echo \"${FN_TESTS}\" |\\\n  while read -r fn num_args pattern; do\n    case \"${fn}\" in\n      fail) continue ;;\n    esac\n\n    # Test without a message.\n    desc=\"${fn}_without_message\"\n    if ( ${fn} arg1 arg2 >\"${stdoutF}\" 2>\"${stderrF}\" ); then\n      fail \"${desc}: expected a failure\"\n      th_showOutput\n    else\n      th_assertFalseWithOutput \"${desc}\" $? \"${stdoutF}\" \"${stderrF}\"\n    fi\n\n    # Test with a message.\n    arg1='' arg2=''\n    case ${num_args} in\n      1) ;;\n      2) arg1='arg1' ;;\n      3) arg1='arg1' arg2='arg2' ;;\n    esac\n\n    desc=\"${fn}_with_message\"\n    if ( ${fn} 'some message' ${arg1} ${arg2} >\"${stdoutF}\" 2>\"${stderrF}\" ); then\n      fail \"${desc}: expected a failure\"\n      th_showOutput\n    else\n      th_assertFalseWithOutput \"${desc}\" $? \"${stdoutF}\" \"${stderrF}\"\n      if ! grep -- \"${pattern}\" \"${stdoutF}\" >/dev/null; then\n        fail \"${desc}: incorrect message to STDOUT\"\n        th_showOutput\n      fi\n    fi\n  done\n}\n\ntestTooFewArguments() {\n  echo \"${FN_TESTS}\" \\\n  |while read -r fn num_args pattern; do\n    # Skip functions that support a single message argument.\n    if [ \"${num_args}\" -eq 1 ]; then\n      continue\n    fi\n\n    desc=\"${fn}\"\n    if (${fn} >\"${stdoutF}\" 2>\"${stderrF}\"); then\n      fail \"${desc}: expected a failure\"\n      _showTestOutput\n    else\n      got=$? want=${SHUNIT_ERROR}\n      assertEquals \"${desc}: incorrect return code\" \"${got}\" \"${want}\"\n      th_assertFalseWithError \"${desc}\" \"${got}\" \"${stdoutF}\" \"${stderrF}\"\n    fi\n  done\n}\n\ntestTooManyArguments() {\n  echo \"${FN_TESTS}\" \\\n  |while read -r fn num_args pattern; do\n    desc=\"${fn}\"\n    if (${fn} arg1 arg2 arg3 arg4 >\"${stdoutF}\" 2>\"${stderrF}\"); then\n      fail \"${desc}: expected a failure\"\n      _showTestOutput\n    else\n      got=$? want=${SHUNIT_ERROR}\n      assertEquals \"${desc}: incorrect return code\" \"${got}\" \"${want}\"\n      th_assertFalseWithError \"${desc}\" \"${got}\" \"${stdoutF}\" \"${stderrF}\"\n    fi\n  done\n}\n\noneTimeSetUp() {\n  th_oneTimeSetUp\n}\n\n# Load and run shUnit2.\n# shellcheck disable=SC2034\n[ -n \"${ZSH_VERSION:-}\" ] && SHUNIT_PARENT=$0\n. \"${TH_SHUNIT}\"\n"
        },
        {
          "name": "shunit2_general_test.sh",
          "type": "blob",
          "size": 2.5615234375,
          "content": "#! /bin/sh\n# vim:et:ft=sh:sts=2:sw=2\n#\n# shUnit2 unit tests for general commands.\n#\n# Copyright 2008-2021 Kate Ward. All Rights Reserved.\n# Released under the Apache 2.0 license.\n# http://www.apache.org/licenses/LICENSE-2.0\n#\n# Author: kate.ward@forestent.com (Kate Ward)\n# https://github.com/kward/shunit2\n#\n# Disable source following.\n#   shellcheck disable=SC1090,SC1091\n\n# These variables will be overridden by the test helpers.\nstdoutF=\"${TMPDIR:-/tmp}/STDOUT\"\nstderrF=\"${TMPDIR:-/tmp}/STDERR\"\n\n# Load test helpers.\n. ./shunit2_test_helpers\n\ntestSkipping() {\n  # We shouldn't be skipping to start.\n  if isSkipping; then\n    th_error 'skipping *should not be* enabled'\n    return\n  fi\n\n  startSkipping\n  was_skipping_started=${SHUNIT_FALSE}\n  if isSkipping; then was_skipping_started=${SHUNIT_TRUE}; fi\n\n  endSkipping\n  was_skipping_ended=${SHUNIT_FALSE}\n  if isSkipping; then was_skipping_ended=${SHUNIT_TRUE}; fi\n\n  assertEquals \"skipping wasn't started\" \"${was_skipping_started}\" \"${SHUNIT_TRUE}\"\n  assertNotEquals \"skipping wasn't ended\" \"${was_skipping_ended}\" \"${SHUNIT_TRUE}\"\n  return 0\n}\n\ntestStartSkippingWithMessage() {\n  unittestF=\"${SHUNIT_TMPDIR}/unittest\"\n  sed 's/^#//' >\"${unittestF}\" <<\\EOF\n## Start skipping with a message.\n#testSkipping() {\n#  startSkipping 'SKIP-a-Dee-Doo-Dah'\n#}\n#SHUNIT_COLOR='none'\n#. ${TH_SHUNIT}\nEOF\n  # Ignoring errors with `|| :` as we only care about `FAILED` in the output.\n  ( exec \"${SHELL:-sh}\" \"${unittestF}\" >\"${stdoutF}\" 2>\"${stderrF}\" ) || :\n  if ! grep '\\[skipping\\] SKIP-a-Dee-Doo-Dah' \"${stderrF}\" >/dev/null; then\n    fail 'skipping message was not generated'\n  fi\n  return 0\n}\n\ntestStartSkippingWithoutMessage() {\n  unittestF=\"${SHUNIT_TMPDIR}/unittest\"\n  sed 's/^#//' >\"${unittestF}\" <<\\EOF\n## Start skipping with a message.\n#testSkipping() {\n#  startSkipping\n#}\n#SHUNIT_COLOR='none'\n#. ${TH_SHUNIT}\nEOF\n  # Ignoring errors with `|| :` as we only care about `FAILED` in the output.\n  ( exec \"${SHELL:-sh}\" \"${unittestF}\" >\"${stdoutF}\" 2>\"${stderrF}\" ) || :\n  if grep '\\[skipping\\]' \"${stderrF}\" >/dev/null; then\n    fail 'skipping message was unexpectedly generated'\n  fi\n  return 0\n}\n\nsetUp() {\n  for f in \"${stdoutF}\" \"${stderrF}\"; do\n    cp /dev/null \"${f}\"\n  done\n\n  # Reconfigure coloring as some tests override default behavior.\n  _shunit_configureColor \"${SHUNIT_COLOR_DEFAULT}\"\n\n  # shellcheck disable=SC2034,SC2153\n  SHUNIT_CMD_TPUT=${__SHUNIT_CMD_TPUT}\n}\n\noneTimeSetUp() {\n  SHUNIT_COLOR_DEFAULT=\"${SHUNIT_COLOR}\"\n  th_oneTimeSetUp\n}\n\n# Load and run shUnit2.\n# shellcheck disable=SC2034\n[ -n \"${ZSH_VERSION:-}\" ] && SHUNIT_PARENT=$0\n. \"${TH_SHUNIT}\"\n"
        },
        {
          "name": "shunit2_macros_test.sh",
          "type": "blob",
          "size": 6.7470703125,
          "content": "#! /bin/sh\n# vim:et:ft=sh:sts=2:sw=2\n#\n# shunit2 unit test for macros.\n#\n# Copyright 2008-2021 Kate Ward. All Rights Reserved.\n# Released under the Apache 2.0 license.\n# http://www.apache.org/licenses/LICENSE-2.0\n#\n# Author: kate.ward@forestent.com (Kate Ward)\n# https://github.com/kward/shunit2\n#\n# Disable source following.\n#   shellcheck disable=SC1090,SC1091\n\n# These variables will be overridden by the test helpers.\nstdoutF=\"${TMPDIR:-/tmp}/STDOUT\"\nstderrF=\"${TMPDIR:-/tmp}/STDERR\"\n\n# Load test helpers.\n. ./shunit2_test_helpers\n\ntestAssertEquals() {\n  isLinenoWorking || startSkipping\n\n  ( ${_ASSERT_EQUALS_} 'x' 'y' >\"${stdoutF}\" 2>\"${stderrF}\" )\n  if ! wasAssertGenerated; then\n    fail '_ASSERT_EQUALS_ failed to produce an ASSERT message'\n    showTestOutput\n  fi\n\n  ( ${_ASSERT_EQUALS_} '\"some msg\"' 'x' 'y' >\"${stdoutF}\" 2>\"${stderrF}\" )\n  if ! wasAssertGenerated; then\n    fail '_ASSERT_EQUALS_ (with a message) failed to produce an ASSERT message'\n    showTestOutput\n  fi\n}\n\ntestAssertNotEquals() {\n  isLinenoWorking || startSkipping\n\n  ( ${_ASSERT_NOT_EQUALS_} 'x' 'x' >\"${stdoutF}\" 2>\"${stderrF}\" )\n  if ! wasAssertGenerated; then\n    fail '_ASSERT_NOT_EQUALS_ failed to produce an ASSERT message'\n    showTestOutput\n  fi\n\n  ( ${_ASSERT_NOT_EQUALS_} '\"some msg\"' 'x' 'x' >\"${stdoutF}\" 2>\"${stderrF}\" )\n  if ! wasAssertGenerated; then\n    fail '_ASSERT_NOT_EQUALS_ (with a message) failed to produce an ASSERT message'\n    showTestOutput\n  fi\n}\n\ntestSame() {\n  isLinenoWorking || startSkipping\n\n  ( ${_ASSERT_SAME_} 'x' 'y' >\"${stdoutF}\" 2>\"${stderrF}\" )\n  if ! wasAssertGenerated; then\n    fail '_ASSERT_SAME_ failed to produce an ASSERT message'\n    showTestOutput\n  fi\n\n  ( ${_ASSERT_SAME_} '\"some msg\"' 'x' 'y' >\"${stdoutF}\" 2>\"${stderrF}\" )\n  if ! wasAssertGenerated; then\n    fail '_ASSERT_SAME_ (with a message) failed to produce an ASSERT message'\n    showTestOutput\n  fi\n}\n\ntestNotSame() {\n  isLinenoWorking || startSkipping\n\n  ( ${_ASSERT_NOT_SAME_} 'x' 'x' >\"${stdoutF}\" 2>\"${stderrF}\" )\n  if ! wasAssertGenerated; then\n    fail '_ASSERT_NOT_SAME_ failed to produce an ASSERT message'\n    showTestOutput\n  fi\n\n  ( ${_ASSERT_NOT_SAME_} '\"some msg\"' 'x' 'x' >\"${stdoutF}\" 2>\"${stderrF}\" )\n  if ! wasAssertGenerated; then\n    fail '_ASSERT_NOT_SAME_ (with a message) failed to produce an ASSERT message'\n    showTestOutput\n  fi\n}\n\ntestNull() {\n  isLinenoWorking || startSkipping\n\n  ( ${_ASSERT_NULL_} 'x' >\"${stdoutF}\" 2>\"${stderrF}\" )\n  if ! wasAssertGenerated; then\n    fail '_ASSERT_NULL_ failed to produce an ASSERT message'\n    showTestOutput\n  fi\n\n  ( ${_ASSERT_NULL_} '\"some msg\"' 'x' >\"${stdoutF}\" 2>\"${stderrF}\" )\n  if ! wasAssertGenerated; then\n    fail '_ASSERT_NULL_ (with a message) failed to produce an ASSERT message'\n    showTestOutput\n  fi\n}\n\ntestNotNull() {\n  isLinenoWorking || startSkipping\n\n  ( ${_ASSERT_NOT_NULL_} '' >\"${stdoutF}\" 2>\"${stderrF}\" )\n  if ! wasAssertGenerated; then\n    fail '_ASSERT_NOT_NULL_ failed to produce an ASSERT message'\n    showTestOutput\n  fi\n\n  ( ${_ASSERT_NOT_NULL_} '\"some msg\"' '\"\"' >\"${stdoutF}\" 2>\"${stderrF}\" )\n  if ! wasAssertGenerated; then\n    fail '_ASSERT_NOT_NULL_ (with a message) failed to produce an ASSERT message'\n    showTestOutput\n  fi\n}\n\ntestAssertTrue() {\n  isLinenoWorking || startSkipping\n\n  ( ${_ASSERT_TRUE_} \"${SHUNIT_FALSE}\" >\"${stdoutF}\" 2>\"${stderrF}\" )\n  if ! wasAssertGenerated; then\n    fail '_ASSERT_TRUE_ failed to produce an ASSERT message'\n    showTestOutput\n  fi\n\n  ( ${_ASSERT_TRUE_} '\"some msg\"' \"${SHUNIT_FALSE}\" >\"${stdoutF}\" 2>\"${stderrF}\" )\n  if ! wasAssertGenerated; then\n    fail '_ASSERT_TRUE_ (with a message) failed to produce an ASSERT message'\n    showTestOutput\n  fi\n}\n\ntestAssertFalse() {\n  isLinenoWorking || startSkipping\n\n  ( ${_ASSERT_FALSE_} \"${SHUNIT_TRUE}\" >\"${stdoutF}\" 2>\"${stderrF}\" )\n  if ! wasAssertGenerated; then\n    fail '_ASSERT_FALSE_ failed to produce an ASSERT message'\n    showTestOutput\n  fi\n\n  ( ${_ASSERT_FALSE_} '\"some msg\"' \"${SHUNIT_TRUE}\" >\"${stdoutF}\" 2>\"${stderrF}\" )\n  if ! wasAssertGenerated; then\n    fail '_ASSERT_FALSE_ (with a message) failed to produce an ASSERT message'\n    showTestOutput\n  fi\n}\n\ntestFail() {\n  isLinenoWorking || startSkipping\n\n  ( ${_FAIL_} >\"${stdoutF}\" 2>\"${stderrF}\" )\n  if ! wasAssertGenerated; then\n    fail '_FAIL_ failed to produce an ASSERT message'\n    showTestOutput\n  fi\n\n  ( ${_FAIL_} '\"some msg\"' >\"${stdoutF}\" 2>\"${stderrF}\" )\n  if ! wasAssertGenerated; then\n    fail '_FAIL_ (with a message) failed to produce an ASSERT message'\n    showTestOutput\n  fi\n}\n\ntestFailNotEquals() {\n  isLinenoWorking || startSkipping\n\n  ( ${_FAIL_NOT_EQUALS_} 'x' 'y' >\"${stdoutF}\" 2>\"${stderrF}\" )\n  if ! wasAssertGenerated; then\n    fail '_FAIL_NOT_EQUALS_ failed to produce an ASSERT message'\n    showTestOutput\n  fi\n\n  ( ${_FAIL_NOT_EQUALS_} '\"some msg\"' 'x' 'y' >\"${stdoutF}\" 2>\"${stderrF}\" )\n  if ! wasAssertGenerated; then\n    fail '_FAIL_NOT_EQUALS_ (with a message) failed to produce an ASSERT message'\n    showTestOutput\n  fi\n}\n\ntestFailSame() {\n  isLinenoWorking || startSkipping\n\n  ( ${_FAIL_SAME_} 'x' 'x' >\"${stdoutF}\" 2>\"${stderrF}\" )\n  if ! wasAssertGenerated; then\n    fail '_FAIL_SAME_ failed to produce an ASSERT message'\n    showTestOutput\n  fi\n\n  ( ${_FAIL_SAME_} '\"some msg\"' 'x' 'x' >\"${stdoutF}\" 2>\"${stderrF}\" )\n  if ! wasAssertGenerated; then\n    fail '_FAIL_SAME_ (with a message) failed to produce an ASSERT message'\n    showTestOutput\n  fi\n}\n\ntestFailNotSame() {\n  isLinenoWorking || startSkipping\n\n  ( ${_FAIL_NOT_SAME_} 'x' 'y' >\"${stdoutF}\" 2>\"${stderrF}\" )\n  if ! wasAssertGenerated; then\n    fail '_FAIL_NOT_SAME_ failed to produce an ASSERT message'\n    showTestOutput\n  fi\n\n  ( ${_FAIL_NOT_SAME_} '\"some msg\"' 'x' 'y' >\"${stdoutF}\" 2>\"${stderrF}\" )\n  if ! wasAssertGenerated; then\n    fail '_FAIL_NOT_SAME_ (with a message) failed to produce an ASSERT message'\n    showTestOutput\n  fi\n}\n\noneTimeSetUp() {\n  th_oneTimeSetUp\n\n  if ! isLinenoWorking; then\n    # shellcheck disable=SC2016\n    th_warn '${LINENO} is not working for this shell. Tests will be skipped.'\n  fi\n}\n\n# isLinenoWorking returns true if the `$LINENO` shell variable works properly.\nisLinenoWorking() {\n  # shellcheck disable=SC2016\n  ln='eval echo \"${LINENO:-}\"'\n  case ${ln} in\n    [0-9]*) return \"${SHUNIT_TRUE}\" ;;\n    -[0-9]*) return \"${SHUNIT_FALSE}\" ;; # The dash shell produces negative values.\n  esac\n  return \"${SHUNIT_FALSE}\"\n}\n\n# showTestOutput for the most recently run test.\nshowTestOutput() { th_showOutput \"${SHUNIT_FALSE}\" \"${stdoutF}\" \"${stderrF}\"; }\n\n# wasAssertGenerated returns true if an ASSERT was generated to STDOUT.\nwasAssertGenerated() { grep '^ASSERT:\\[[0-9]*\\] *' \"${stdoutF}\" >/dev/null; }\n\n# Disable output coloring as it breaks the tests.\nSHUNIT_COLOR='none'; export SHUNIT_COLOR\n\n# Load and run shUnit2.\n# shellcheck disable=SC2034\n[ -n \"${ZSH_VERSION:-}\" ] && SHUNIT_PARENT=\"$0\"\n. \"${TH_SHUNIT}\"\n"
        },
        {
          "name": "shunit2_misc_test.sh",
          "type": "blob",
          "size": 9.1943359375,
          "content": "#! /bin/sh\n# vim:et:ft=sh:sts=2:sw=2\n#\n# shUnit2 unit tests of miscellaneous things\n#\n# Copyright 2008-2023 Kate Ward. All Rights Reserved.\n# Released under the Apache 2.0 license.\n# http://www.apache.org/licenses/LICENSE-2.0\n#\n# Author: kate.ward@forestent.com (Kate Ward)\n# https://github.com/kward/shunit2\n#\n# Allow usage of legacy backticked `...` notation instead of $(...).\n#  shellcheck disable=SC2006\n# Disable source following.\n#   shellcheck disable=SC1090,SC1091\n\n# These variables will be overridden by the test helpers.\nstdoutF=\"${TMPDIR:-/tmp}/STDOUT\"\nstderrF=\"${TMPDIR:-/tmp}/STDERR\"\n\n# Load test helpers.\n. ./shunit2_test_helpers\n\n# Note: the test script is prefixed with '#' chars so that shUnit2 does not\n# incorrectly interpret the embedded functions as real functions.\ntestUnboundVariable() {\n  unittestF=\"${SHUNIT_TMPDIR}/unittest\"\n  sed 's/^#//' >\"${unittestF}\" <<EOF\n## Treat unset variables as an error when performing parameter expansion.\n#set -u\n#\n#boom() { x=\\$1; }  # This function goes boom if no parameters are passed!\n#test_boom() {\n#  assertEquals 1 1\n#  boom  # No parameter given\n#  assertEquals 0 \\$?\n#}\n#SHUNIT_COLOR='none'\n#. ${TH_SHUNIT}\nEOF\n  if ( exec \"${SHELL:-sh}\" \"${unittestF}\" >\"${stdoutF}\" 2>\"${stderrF}\" ); then\n    fail 'expected a non-zero exit value'\n  fi\n  if ! grep '^ASSERT:unknown failure' \"${stdoutF}\" >/dev/null; then\n    fail 'assert message was not generated'\n  fi\n  if ! grep '^Ran [0-9]* test' \"${stdoutF}\" >/dev/null; then\n    fail 'test count message was not generated'\n  fi\n  if ! grep '^FAILED' \"${stdoutF}\" >/dev/null; then\n    fail 'failure message was not generated'\n  fi\n}\n\n# assertEquals repeats message argument.\n# https://github.com/kward/shunit2/issues/7\ntestIssue7() {\n  # Disable coloring so 'ASSERT:' lines can be matched correctly.\n  _shunit_configureColor 'none'\n\n  # Ignoring errors with `|| :` as we only care about the message in this test.\n  ( assertEquals 'Some message.' 1 2 >\"${stdoutF}\" 2>\"${stderrF}\" ) || :\n  diff \"${stdoutF}\" - >/dev/null <<EOF\nASSERT:Some message. expected:<1> but was:<2>\nEOF\n  rtrn=$?\n  assertEquals \"${SHUNIT_TRUE}\" \"${rtrn}\"\n  [ \"${rtrn}\" -eq \"${SHUNIT_TRUE}\" ] || cat \"${stderrF}\" >&2\n}\n\n# Support prefixes on test output.\n# https://github.com/kward/shunit2/issues/29\ntestIssue29() {\n  unittestF=\"${SHUNIT_TMPDIR}/unittest\"\n  sed 's/^#//' >\"${unittestF}\" <<EOF\n## Support test prefixes.\n#test_assert() { assertTrue ${SHUNIT_TRUE}; }\n#SHUNIT_COLOR='none'\n#SHUNIT_TEST_PREFIX='--- '\n#. ${TH_SHUNIT}\nEOF\n  ( exec \"${SHELL:-sh}\" \"${unittestF}\" >\"${stdoutF}\" 2>\"${stderrF}\" )\n  grep '^--- test_assert' \"${stdoutF}\" >/dev/null\n  rtrn=$?\n  assertEquals \"${SHUNIT_TRUE}\" \"${rtrn}\"\n  [ \"${rtrn}\" -eq \"${SHUNIT_TRUE}\" ] || cat \"${stdoutF}\" >&2\n}\n\n# Test that certain external commands sometimes \"stubbed\" by users are escaped.\ntestIssue54() {\n  for c in mkdir rm cat chmod sed; do\n    if grep \"^[^#]*${c} \" \"${TH_SHUNIT}\" | grep -qv \"command ${c}\"; then\n      fail \"external call to ${c} not protected somewhere\"\n    fi\n  done\n  # shellcheck disable=2016\n  if grep '^[^#]*[^ ]  *\\[' \"${TH_SHUNIT}\" | grep -qv '${__SHUNIT_BUILTIN} \\['; then\n    fail 'call to [ not protected somewhere'\n  fi\n  # shellcheck disable=2016\n  if grep '^[^#]*  *\\.' \"${TH_SHUNIT}\" | grep -qv '${__SHUNIT_BUILTIN} \\.'; then\n    fail 'call to . not protected somewhere'\n  fi\n}\n\n# shUnit2 should not exit with 0 when it has syntax errors.\n# https://github.com/kward/shunit2/issues/69\ntestIssue69() {\n  unittestF=\"${SHUNIT_TMPDIR}/unittest\"\n\n  # Note: assertNull not tested as zero arguments == null, which is valid.\n  for t in Equals NotEquals NotNull Same NotSame True False; do\n    assert=\"assert${t}\"\n    sed 's/^#//' >\"${unittestF}\" <<EOF\n## Asserts with invalid argument counts should be counted as failures.\n#test_assert() { ${assert}; }\n#SHUNIT_COLOR='none'\n#. ${TH_SHUNIT}\nEOF\n    # Ignoring errors with `|| :` as we only care about `FAILED` in the output.\n    ( exec \"${SHELL:-sh}\" \"${unittestF}\" >\"${stdoutF}\" 2>\"${stderrF}\" ) || :\n    grep '^FAILED' \"${stdoutF}\" >/dev/null\n    assertTrue \"failure message for ${assert} was not generated\" $?\n  done\n}\n\n# Ensure that test fails if setup/teardown functions fail.\ntestIssue77() {\n  unittestF=\"${SHUNIT_TMPDIR}/unittest\"\n  for func in oneTimeSetUp setUp tearDown oneTimeTearDown; do\n    sed 's/^#//' >\"${unittestF}\" <<EOF\n## Environment failure should end test.\n#${func}() { return ${SHUNIT_FALSE}; }\n#test_true() { assertTrue ${SHUNIT_TRUE}; }\n#SHUNIT_COLOR='none'\n#. ${TH_SHUNIT}\nEOF\n    # Ignoring errors with `|| :` as we only care about `FAILED` in the output.\n    ( exec \"${SHELL:-sh}\" \"${unittestF}\" ) >\"${stdoutF}\" 2>\"${stderrF}\" || :\n    grep '^FAILED' \"${stdoutF}\" >/dev/null\n    assertTrue \"failure of ${func}() did not end test\" $?\n  done\n}\n\n# Ensure a test failure is recorded for code containing syntax errors.\n# https://github.com/kward/shunit2/issues/84\ntestIssue84() {\n  unittestF=\"${SHUNIT_TMPDIR}/unittest\"\n  sed 's/^#//' >\"${unittestF}\" <<\\EOF\n## Function with syntax error.\n#syntax_error() { ${!#3442} -334 a$@2[1]; }\n#test_syntax_error() {\n#  syntax_error\n#  assertTrue ${SHUNIT_TRUE}\n#}\n#SHUNIT_COLOR='none'\n#SHUNIT_TEST_PREFIX='--- '\n#. ${TH_SHUNIT}\nEOF\n  # Ignoring errors with `|| :` as we only care about `FAILED` in the output.\n  ( exec \"${SHELL:-sh}\" \"${unittestF}\" >\"${stdoutF}\" 2>\"${stderrF}\" ) || :\n  if ! grep '^FAILED' \"${stdoutF}\" >/dev/null; then\n    fail 'failure message was not generated'\n  fi\n}\n\n# Demonstrate that asserts are no longer executed in subshells.\n# https://github.com/kward/shunit2/issues/123\n#\n# NOTE: this test only works if the `${BASH_SUBSHELL}` variable is present.\ntestIssue123() {\n  if [ -z \"${BASH_SUBSHELL:-}\" ]; then\n    # shellcheck disable=SC2016\n    startSkipping 'The ${BASH_SUBSHELL} variable is unavailable in this shell.'\n  fi\n  # shellcheck disable=SC2016\n  assertTrue 'not in subshell' '[[ ${BASH_SUBSHELL} -eq 0 ]]'\n}\n\ntestPrepForSourcing() {\n  assertEquals '/abc' \"`_shunit_prepForSourcing '/abc'`\"\n  assertEquals './abc' \"`_shunit_prepForSourcing './abc'`\"\n  assertEquals './abc' \"`_shunit_prepForSourcing 'abc'`\"\n}\n\n# Test the various ways of declaring functions.\n#\n# Prefixing (then stripping) with comment symbol so these functions aren't\n# treated as real functions by shUnit2.\ntestExtractTestFunctions() {\n  f=\"${SHUNIT_TMPDIR}/extract_test_functions\"\n  sed 's/^#//' <<EOF >\"${f}\"\n## Function on a single line.\n#testABC() { echo 'ABC'; }\n## Multi-line function with '{' on next line.\n#test_def()\n# {\n#  echo 'def'\n#}\n## Multi-line function with '{' on first line.\n#testG3 () {\n#  echo 'G3'\n#}\n## Function with numerical values in name.\n#function test4() { echo '4'; }\n## Leading space in front of function.\n#\ttest5() { echo '5'; }\n## Function with '_' chars in name.\n#some_test_function() { echo 'some func'; }\n## Function that sets variables.\n#func_with_test_vars() {\n#  testVariable=1234\n#}\n## Function with keyword but no parenthesis\n#function test6 { echo '6'; }\n## Function with keyword but no parenthesis, multi-line\n#function test7 {\n#  echo '7';\n#}\n## Function with no parenthesis, '{' on next line\n#function test8\n#{\n#  echo '8'\n#}\n## Function with hyphenated name\n#test-9() {\n#  echo '9';\n#}\n## Function without parenthesis or keyword\n#test_foobar { echo 'hello world'; }\n## Function with multiple function keywords\n#function function test_test_test() { echo 'lorem'; }\nEOF\n\n  actual=`_shunit_extractTestFunctions \"${f}\"`\n  assertEquals 'testABC test_def testG3 test4 test5 test6 test7 test8 test-9' \"${actual}\"\n}\n\ntestColors() {\n  while read -r cmd colors desc; do\n    SHUNIT_CMD_TPUT=${cmd}\n    want=${colors} got=`_shunit_colors`\n    assertEquals \"${desc}: incorrect number of colors;\" \\\n        \"${got}\" \"${want}\"\n  done <<'EOF'\nmissing_tput 16  missing tput command\nmock_tput    256 mock tput command\nEOF\n}\n\ntestColorsWitoutTERM() {\n  SHUNIT_CMD_TPUT='mock_tput'\n  got=`TERM='' _shunit_colors`\n  want=16\n  assertEquals \"${got}\" \"${want}\"\n}\n\nmock_tput() {\n  if [ -z \"${TERM}\" ]; then\n    # shellcheck disable=SC2016\n    echo 'tput: No value for $TERM and no -T specified'\n    return 2\n  fi\n  if [ \"$1\" = 'colors' ]; then\n    echo 256\n    return 0\n  fi\n  return 1\n}\n\n# Note: the test script is prefixed with '#' chars so that shUnit2 does not\n# incorrectly interpret the embedded functions as real functions.\ntestPipefail() {\n  unittestF=\"${SHUNIT_TMPDIR}/unittest\"\n  sed 's/^#//' >\"${unittestF}\" <<EOF\n## Test that using 'set -o pipefail' does not break shunit2.\n#set -o pipefail\n#\n#pipefail() { true; }  # shunit2 should remain happy with this simple test.\n#test_pipefail() {\n#  assertEquals 1 1\n#  pipefail\n#  assertEquals 0 \\$?\n#}\n#SHUNIT_COLOR='none'\n#. ${TH_SHUNIT}\nEOF\n  if ! ( exec \"${SHELL:-sh}\" \"${unittestF}\" >\"${stdoutF}\" 2>\"${stderrF}\" ); then\n    fail 'expected a zero exit value'\n  fi\n  if ! grep '^Ran [0-9]* test' \"${stdoutF}\" >/dev/null; then\n    fail 'test count message was not generated'\n  fi\n}\n\nsetUp() {\n  for f in \"${stdoutF}\" \"${stderrF}\"; do\n    cp /dev/null \"${f}\"\n  done\n\n  # Reconfigure coloring as some tests override default behavior.\n  _shunit_configureColor \"${SHUNIT_COLOR_DEFAULT}\"\n\n  # shellcheck disable=SC2034,SC2153\n  SHUNIT_CMD_TPUT=${__SHUNIT_CMD_TPUT}\n}\n\noneTimeSetUp() {\n  SHUNIT_COLOR_DEFAULT=\"${SHUNIT_COLOR}\"\n  th_oneTimeSetUp\n}\n\n# Load and run shUnit2.\n# shellcheck disable=SC2034\n[ -n \"${ZSH_VERSION:-}\" ] && SHUNIT_PARENT=$0\n. \"${TH_SHUNIT}\"\n"
        },
        {
          "name": "shunit2_shopt_test.sh",
          "type": "blob",
          "size": 1.4365234375,
          "content": "#! /bin/sh\n# vim:et:ft=sh:sts=2:sw=2\n#\n# shUnit2 unit tests for `shopt` support.\n#\n# Copyright 2008-2021 Kate Ward. All Rights Reserved.\n# Released under the Apache 2.0 license.\n# http://www.apache.org/licenses/LICENSE-2.0\n#\n# Author: kate.ward@forestent.com (Kate Ward)\n# https://github.com/kward/shunit2\n#\n# Disable source following.\n#   shellcheck disable=SC1090,SC1091\n\n# Load test helpers.\n. ./shunit2_test_helpers\n\n# Call shopt from a variable so it can be mocked if it doesn't work.\nSHOPT_CMD='shopt'\n\ntestNullglob() {\n  isShoptWorking || startSkipping\n\n  nullglob=$(${SHOPT_CMD} nullglob |cut -f2)\n\n  # Test without nullglob.\n  ${SHOPT_CMD} -u nullglob\n  assertEquals 'test without nullglob' 0 0\n\n  # Test with nullglob.\n  ${SHOPT_CMD} -s nullglob\n  assertEquals 'test with nullglob' 1 1\n\n  # Reset nullglob.\n  if [ \"${nullglob}\" = \"on\" ]; then\n    ${SHOPT_CMD} -s nullglob\n  else\n    ${SHOPT_CMD} -u nullglob\n  fi\n\n  unset nullglob\n}\n\noneTimeSetUp() {\n  th_oneTimeSetUp\n\n  if ! isShoptWorking; then\n    SHOPT_CMD='mock_shopt'\n  fi\n}\n\n# isShoptWorking returns true if the `shopt` shell command is available.\n# NOTE: `shopt` is not defined as part of the POSIX standard.\nisShoptWorking() {\n  # shellcheck disable=SC2039,SC3044\n  ( shopt >/dev/null 2>&1 );\n}\n\nmock_shopt() {\n  if [ $# -eq 0 ]; then\n    echo \"nullglob         off\"\n  fi\n  return\n}\n\n# Load and run shUnit2.\n# shellcheck disable=SC2034\n[ -n \"${ZSH_VERSION:-}\" ] && SHUNIT_PARENT=\"$0\"\n. \"${TH_SHUNIT}\"\n"
        },
        {
          "name": "shunit2_standalone_test.sh",
          "type": "blob",
          "size": 0.8662109375,
          "content": "#! /bin/sh\n# vim:et:ft=sh:sts=2:sw=2\n#\n# shUnit2 unit test for standalone operation.\n#\n# Copyright 2008-2021 Kate Ward. All Rights Reserved.\n# Released under the Apache 2.0 license.\n# http://www.apache.org/licenses/LICENSE-2.0\n#\n# Author: kate.ward@forestent.com (Kate Ward)\n# https://github.com/kward/shunit2\n#\n# This unit test is purely to test that calling shunit2 directly, while passing\n# the name of a unit test script, works. When run, this script determines if it\n# is running as a standalone program, and calls main() if it is.\n#\n# Disable source following.\n#   shellcheck disable=SC1090,SC1091\n\nARGV0=$(basename \"$0\")\n\n# Load test helpers.\n. ./shunit2_test_helpers\n\ntestStandalone() {\n  assertTrue \"${SHUNIT_TRUE}\"\n}\n\nmain() {\n  ${TH_SHUNIT} \"${ARGV0}\"\n}\n\n# Run main() if are running as a standalone script.\nif [ \"${ARGV0}\" = 'shunit2_standalone_test.sh' ]; then\n\tmain \"$@\"\nfi\n"
        },
        {
          "name": "shunit2_test_helpers",
          "type": "blob",
          "size": 6.8388671875,
          "content": "# vim:et:ft=sh:sts=2:sw=2\n#\n# shUnit2 unit test common functions\n#\n# Copyright 2008-2021 Kate Ward. All Rights Reserved.\n# Released under the Apache 2.0 license.\n# http://www.apache.org/licenses/LICENSE-2.0\n#\n# Author: kate.ward@forestent.com (Kate Ward)\n# https://github.com/kward/shunit2\n#\n### ShellCheck (http://www.shellcheck.net/)\n# expr may be antiquated, but it is the only solution in some cases.\n#   shellcheck disable=SC2003\n# $() are not fully portable (POSIX != portable).\n#   shellcheck disable=SC2006\n\n# Exit immediately if a simple command exits with a non-zero status.\nset -e\n\n# Treat unset variables as an error when performing parameter expansion.\nset -u\n\n# Set shwordsplit for zsh.\n[ -n \"${ZSH_VERSION:-}\" ] && setopt shwordsplit\n\n#\n# Constants.\n#\n\n# Path to shUnit2 library. Can be overridden by setting SHUNIT_INC.\nTH_SHUNIT=${SHUNIT_INC:-./shunit2}; export TH_SHUNIT\n\n# Configure debugging. Set the DEBUG environment variable to any\n# non-empty value to enable debug output, or TRACE to enable trace\n# output.\nTRACE=${TRACE:+'th_trace '}\n[ -n \"${TRACE}\" ] && DEBUG=1\n[ -z \"${TRACE}\" ] && TRACE=':'\n\nDEBUG=${DEBUG:+'th_debug '}\n[ -z \"${DEBUG}\" ] && DEBUG=':'\n\n#\n# Variables.\n#\n\nth_RANDOM=0\n\n#\n# Functions.\n#\n\n# Logging functions.\nth_trace() { echo \"test:TRACE $*\" >&2; }\nth_debug() { echo \"test:DEBUG $*\" >&2; }\nth_info()  { echo \"test:INFO $*\" >&2; }\nth_warn()  { echo \"test:WARN $*\" >&2; }\nth_error() { echo \"test:ERROR $*\" >&2; }\nth_fatal() { echo \"test:FATAL $*\" >&2; }\n\n# Output subtest name.\nth_subtest() { echo \" $*\" >&2; }\n\nth_oneTimeSetUp() {\n  # These files will be cleaned up automatically by shUnit2.\n  stdoutF=\"${SHUNIT_TMPDIR}/stdout\"\n  stderrF=\"${SHUNIT_TMPDIR}/stderr\"\n  returnF=\"${SHUNIT_TMPDIR}/return\"\n  expectedF=\"${SHUNIT_TMPDIR}/expected\"\n  export stdoutF stderrF returnF expectedF\n}\n\n# Generate a random number.\nth_generateRandom() {\n  tfgr_random=${th_RANDOM}\n\n  while [ \"${tfgr_random}\" = \"${th_RANDOM}\" ]; do\n    # shellcheck disable=SC2039\n    if [ -n \"${RANDOM:-}\" ]; then\n      # $RANDOM works\n      # shellcheck disable=SC2039\n      tfgr_random=${RANDOM}${RANDOM}${RANDOM}$$\n    elif [ -r '/dev/urandom' ]; then\n      tfgr_random=`od -vAn -N4 -tu4 </dev/urandom |sed 's/^[^0-9]*//'`\n    else\n      tfgr_date=`date '+%H%M%S'`\n      tfgr_random=`expr \"${tfgr_date}\" \\* $$`\n      unset tfgr_date\n    fi\n    [ \"${tfgr_random}\" = \"${th_RANDOM}\" ] && sleep 1\n  done\n\n  th_RANDOM=${tfgr_random}\n  unset tfgr_random\n}\n\n# This section returns the data section from the specified section of a file. A\n# data section is defined by a [header], one or more lines of data, and then a\n# blank line.\nth_getDataSect() {\n  th_sgrep \"\\\\[$1\\\\]\" \"$2\" |sed '1d'\n}\n\n# This function greps a section from a file. a section is defined as a group of\n# lines preceded and followed by blank lines..\nth_sgrep() {\n  th_pattern_=$1\n  shift\n\n  # shellcheck disable=SC2068\n  sed -e '/./{H;$!d;}' -e \"x;/${th_pattern_}/\"'!d;' $@ |sed '1d'\n\n  unset th_pattern_\n}\n\n# Custom assert that checks for true return value (0), and no output to STDOUT\n# or STDERR. If a non-zero return value is encountered, the output of STDERR\n# will be output.\n#\n# Args:\n#  th_test_: string: name of the subtest\n#  th_rtrn_: integer: the return value of the subtest performed\n#  th_stdout_: string: filename where stdout was redirected to\n#  th_stderr_: string: filename where stderr was redirected to\nth_assertTrueWithNoOutput() {\n  th_test_=$1\n  th_rtrn_=$2\n  th_stdout_=$3\n  th_stderr_=$4\n\n  assertEquals \"${th_test_}: expected return value of true\" \"${SHUNIT_TRUE}\" \"${th_rtrn_}\"\n  assertFalse \"${th_test_}: expected no output to STDOUT\" \"[ -s '${th_stdout_}' ]\"\n  assertFalse \"${th_test_}: expected no output to STDERR\" \"[ -s '${th_stderr_}' ]\"\n  # shellcheck disable=SC2166\n  if [ -s \"${th_stdout_}\" -o -s \"${th_stderr_}\" ]; then\n    _th_showOutput \"${SHUNIT_FALSE}\" \"${th_stdout_}\" \"${th_stderr_}\"\n  fi\n\n  unset th_test_ th_rtrn_ th_stdout_ th_stderr_\n}\n\n# Custom assert that checks for non-zero return value, output to STDOUT, but no\n# output to STDERR.\n#\n# Args:\n#  th_test_: string: name of the subtest\n#  th_rtrn_: integer: the return value of the subtest performed\n#  th_stdout_: string: filename where stdout was redirected to\n#  th_stderr_: string: filename where stderr was redirected to\nth_assertFalseWithOutput()\n{\n  th_test_=$1\n  th_rtrn_=$2\n  th_stdout_=$3\n  th_stderr_=$4\n\n  assertNotEquals \"${th_test_}: expected non-true return value\" \"${SHUNIT_TRUE}\" \"${th_rtrn_}\"\n  assertTrue \"${th_test_}: expected output to STDOUT\" \"[ -s '${th_stdout_}' ]\"\n  assertFalse \"${th_test_}: expected no output to STDERR\" \"[ -s '${th_stderr_}' ]\"\n  # shellcheck disable=SC2166\n  if ! [ -s \"${th_stdout_}\" -a ! -s \"${th_stderr_}\" ]; then\n    _th_showOutput \"${SHUNIT_FALSE}\" \"${th_stdout_}\" \"${th_stderr_}\"\n  fi\n\n  unset th_test_ th_rtrn_ th_stdout_ th_stderr_\n}\n\n# Custom assert that checks for non-zero return value, no output to STDOUT, but\n# output to STDERR.\n#\n# Args:\n#  th_test_: string: name of the subtest\n#  th_rtrn_: integer: the return value of the subtest performed\n#  th_stdout_: string: filename where stdout was redirected to\n#  th_stderr_: string: filename where stderr was redirected to\nth_assertFalseWithError() {\n  th_test_=$1\n  th_rtrn_=$2\n  th_stdout_=$3\n  th_stderr_=$4\n\n  assertFalse \"${th_test_}: expected non-zero return value\" \"${th_rtrn_}\"\n  assertFalse \"${th_test_}: expected no output to STDOUT\" \"[ -s '${th_stdout_}' ]\"\n  assertTrue \"${th_test_}: expected output to STDERR\" \"[ -s '${th_stderr_}' ]\"\n  # shellcheck disable=SC2166\n  if ! [ ! -s \"${th_stdout_}\" -a -s \"${th_stderr_}\" ]; then\n    _th_showOutput \"${SHUNIT_FALSE}\" \"${th_stdout_}\" \"${th_stderr_}\"\n  fi\n\n  unset th_test_ th_rtrn_ th_stdout_ th_stderr_\n}\n\n# Some shells, zsh on Solaris in particular, return immediately from a sub-shell\n# when a non-zero return value is encountered. To properly catch these values,\n# they are either written to disk, or recognized as an error the file is empty.\nth_clearReturn() { cp /dev/null \"${returnF}\"; }\nth_queryReturn() {\n  if [ -s \"${returnF}\" ]; then\n    th_return=`cat \"${returnF}\"`\n  else\n    th_return=${SHUNIT_ERROR}\n  fi\n  export th_return\n}\n\n# Providing external and internal calls to the showOutput helper function.\nth_showOutput() { _th_showOutput \"$@\"; }\n_th_showOutput() {\n  if isSkipping; then\n    return\n  fi\n\n  _th_return_=\"${1:-${returnF}}\"\n  _th_stdout_=\"${2:-${stdoutF}}\"\n  _th_stderr_=\"${3:-${stderrF}}\"\n\n  if [ \"${_th_return_}\" != \"${SHUNIT_TRUE}\" ]; then\n    # shellcheck disable=SC2166\n    if [ -n \"${_th_stdout_}\" -a -s \"${_th_stdout_}\" ]; then\n      echo '>>> STDOUT' >&2\n      cat \"${_th_stdout_}\" >&2\n      echo '<<< STDOUT' >&2\n    fi\n    # shellcheck disable=SC2166\n    if [ -n \"${_th_stderr_}\" -a -s \"${_th_stderr_}\" ]; then\n      echo '>>> STDERR' >&2\n      cat \"${_th_stderr_}\" >&2\n      echo '<<< STDERR' >&2\n    fi\n  fi\n\n  unset _th_return_ _th_stdout_ _th_stderr_\n}\n\n#\n# Main.\n#\n\n${TRACE} 'trace output enabled'\n${DEBUG} 'debug output enabled'\n"
        },
        {
          "name": "shunit2_xml_test.sh",
          "type": "blob",
          "size": 6.2939453125,
          "content": "#!/bin/sh\n# vim:et:ft=sh:sts=2:sw=2\n#\n# shunit2 unit test for running subset(s) of tests based upon junit XML generator.\n#\n# Copyright 2023 AxxonSoft. All Rights Reserved.\n# Released under the Apache 2.0 license.\n# http://www.apache.org/licenses/LICENSE-2.0\n#\n# https://github.com/kward/shunit2\n#\n# Also shows how JUnit XML may be generated.\n#\n# Disable source following.\n#   shellcheck disable=SC1090,SC1091\n\n# These variables will be overridden by the test helpers.\nstdoutF=\"\"\nstderrF=\"\"\n\n# Load test helpers.\n. ./shunit2_test_helpers\n\n# Run test and check XML output is correct.\n# Arguments:\n#   isSuccess: bool: true if the test should succeed. Default is true.\n#   $@: additional arguments to pass to shunit2\ncommonRunAndCheck() {\n  _common_test_should_succeed=true\n  if [ $# -gt 0 ]; then\n    case \"$1\" in\n      --*) ;;\n      *) _common_test_should_succeed=\"$1\"; shift ;;\n    esac\n  fi\n\n  _common_test_succeed=true\n  ( exec \"${SHELL:-sh}\" \"${unittestF}\" -- \"--output-junit-xml=${currentXmlF}\" \"$@\" >\"${stdoutF}\" 2>\"${stderrF}\" ) || {\n    _common_test_succeed=false\n  }\n\n  assertEquals \"Test exit status\" \"${_common_test_should_succeed}\" \"${_common_test_succeed}\"\n\n  if ! grep '^Ran [0-9]* test' \"${stdoutF}\" >/dev/null; then\n    fail 'test count message was not generated'\n    th_showOutput\n  fi\n\n  if ! diff \"${idealXmlF}\" \"${currentXmlF}\" >/dev/null; then\n    fail 'XML output is not equal'\n    echo '>>> Ideal' >&2\n    cat \"${idealXmlF}\" >&2\n    echo '<<< Ideal' >&2\n    echo '>>> Actual' >&2\n    cat \"${currentXmlF}\" >&2\n    echo '<<< Actual' >&2\n  fi\n}\n\n###\n# XML messages escaping logic\n###\ntestEscapeXmlDataAmp() {\n  assertEquals \"&amp;\" \"$(_shunit_escapeXmlData \"&\")\"\n}\n\ntestEscapeXmlDataLess() {\n  assertEquals \"&lt;\" \"$(_shunit_escapeXmlData \"<\")\"\n}\n\ntestEscapeXmlDataGreater() {\n  assertEquals \"&gt;\" \"$(_shunit_escapeXmlData \">\")\"\n}\n\ntestEscapeXmlDataQuote() {\n  assertEquals \"&quot;\" \"$(_shunit_escapeXmlData '\"')\"\n}\n\ntestEscapeXmlDataApostrophe() {\n  assertEquals \"&apos;\" \"$(_shunit_escapeXmlData \"'\")\"\n}\n\ntestEscapeXmlDataMultiple() {\n  assertEquals \"&amp;&lt;&apos;&gt;&quot;\" \"$(_shunit_escapeXmlData \"&<'>\\\"\")\"\n}\n\ntestEscapeXmlDataInverseMultiple() {\n  assertEquals \"&quot;&gt;&apos;&lt;&amp;\" \"$(_shunit_escapeXmlData \"\\\">'<&\")\"\n}\n\n###\n# XML tests passing/erroring.\n###\ntestSingleSuccess() {\n  sed 's/^#//' >\"${unittestF}\" <<EOF\n#testSuccess() {\n#  assertEquals 1 1\n#}\n#SHUNIT_COLOR='none'\n#. ${TH_SHUNIT}\nEOF\n\n  cat >\"${idealXmlF}\" <<EOF\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<testsuite\n  failures=\"0\"\n  name=\"unittest\"\n  tests=\"1\"\n  assertions=\"1\"\n>\n  <testcase\n    classname=\"unittest\"\n    name=\"testSuccess\"\n    assertions=\"1\"\n  >\n  </testcase>\n</testsuite>\nEOF\n\n  commonRunAndCheck\n}\n\ntestFewSuccess() {\n  sed 's/^#//' >\"${unittestF}\" <<EOF\n#testSuccess() {\n#  assertEquals 1 1\n#}\n#testS2() {\n#  assertEquals 1 1\n#}\n#testSSS() {\n#  assertEquals 1 1\n#}\n#SHUNIT_COLOR='none'\n#. ${TH_SHUNIT}\nEOF\n\n  cat >\"${idealXmlF}\" <<EOF\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<testsuite\n  failures=\"0\"\n  name=\"unittest\"\n  tests=\"3\"\n  assertions=\"3\"\n>\n  <testcase\n    classname=\"unittest\"\n    name=\"testSuccess\"\n    assertions=\"1\"\n  >\n  </testcase>\n  <testcase\n    classname=\"unittest\"\n    name=\"testS2\"\n    assertions=\"1\"\n  >\n  </testcase>\n  <testcase\n    classname=\"unittest\"\n    name=\"testSSS\"\n    assertions=\"1\"\n  >\n  </testcase>\n</testsuite>\nEOF\n\n  commonRunAndCheck\n}\n\ntestMultipleAsserts() {\n  sed 's/^#//' >\"${unittestF}\" <<EOF\n#testSuccess() {\n#  assertEquals 1 1\n#  assertEquals 1 1\n#  assertEquals 1 1\n#}\n#testS2() {\n#  assertEquals 1 1\n#  assertEquals 1 1\n#}\n#SHUNIT_COLOR='none'\n#. ${TH_SHUNIT}\nEOF\n\n  cat >\"${idealXmlF}\" <<EOF\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<testsuite\n  failures=\"0\"\n  name=\"unittest\"\n  tests=\"2\"\n  assertions=\"5\"\n>\n  <testcase\n    classname=\"unittest\"\n    name=\"testSuccess\"\n    assertions=\"3\"\n  >\n  </testcase>\n  <testcase\n    classname=\"unittest\"\n    name=\"testS2\"\n    assertions=\"2\"\n  >\n  </testcase>\n</testsuite>\nEOF\n\n  commonRunAndCheck\n}\n\ntestFailures() {\n  sed 's/^#//' >\"${unittestF}\" <<EOF\n#testSuccess() {\n#  assertEquals 0 1\n#  assertEquals 1 1\n#  assertEquals \"My message\" 0 1\n#}\n#testSSS() {\n#  assertEquals 1 1\n#}\n#testS2() {\n#  assertEquals 1 1\n#  assertEquals \"Hello, World\" 0 1\n#}\n#SHUNIT_COLOR='none'\n#. ${TH_SHUNIT}\nEOF\n\n  cat >\"${idealXmlF}\" <<EOF\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<testsuite\n  failures=\"2\"\n  name=\"unittest\"\n  tests=\"3\"\n  assertions=\"6\"\n>\n  <testcase\n    classname=\"unittest\"\n    name=\"testSuccess\"\n    assertions=\"3\"\n  >\n    <failure\n      type=\"shunit.assertFail\"\n      message=\"expected:&lt;0&gt; but was:&lt;1&gt;\"\n    />\n    <failure\n      type=\"shunit.assertFail\"\n      message=\"My message expected:&lt;0&gt; but was:&lt;1&gt;\"\n    />\n  </testcase>\n  <testcase\n    classname=\"unittest\"\n    name=\"testSSS\"\n    assertions=\"1\"\n  >\n  </testcase>\n  <testcase\n    classname=\"unittest\"\n    name=\"testS2\"\n    assertions=\"2\"\n  >\n    <failure\n      type=\"shunit.assertFail\"\n      message=\"Hello, World expected:&lt;0&gt; but was:&lt;1&gt;\"\n    />\n  </testcase>\n</testsuite>\nEOF\n\n  commonRunAndCheck false\n}\n\n###\n# Custom suite name cases.\n###\ntestCustomSuiteName() {\n  sed 's/^#//' >\"${unittestF}\" <<EOF\n#testSuccess() {\n#  assertEquals 1 1\n#}\n#SHUNIT_COLOR='none'\n#. ${TH_SHUNIT}\nEOF\n\n  cat >\"${idealXmlF}\" <<EOF\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<testsuite\n  failures=\"0\"\n  name=\"mySuiteName\"\n  tests=\"1\"\n  assertions=\"1\"\n>\n  <testcase\n    classname=\"mySuiteName\"\n    name=\"testSuccess\"\n    assertions=\"1\"\n  >\n  </testcase>\n</testsuite>\nEOF\n\n  commonRunAndCheck --suite-name=mySuiteName\n}\n\ntestCustomSuiteNameEscaping() {\n  sed 's/^#//' >\"${unittestF}\" <<EOF\n#testSuccess() {\n#  assertEquals 1 1\n#}\n#SHUNIT_COLOR='none'\n#. ${TH_SHUNIT}\nEOF\n\n  cat >\"${idealXmlF}\" <<EOF\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<testsuite\n  failures=\"0\"\n  name=\"Custom name with spaces &amp; some special chars!\"\n  tests=\"1\"\n  assertions=\"1\"\n>\n  <testcase\n    classname=\"Custom name with spaces &amp; some special chars!\"\n    name=\"testSuccess\"\n    assertions=\"1\"\n  >\n  </testcase>\n</testsuite>\nEOF\n\n  commonRunAndCheck \"--suite-name=Custom name with spaces & some special chars!\"\n}\n\noneTimeSetUp() {\n  th_oneTimeSetUp\n  unittestF=\"${SHUNIT_TMPDIR}/unittest\"\n  idealXmlF=\"${SHUNIT_TMPDIR}/ideal.xml\"\n  currentXmlF=\"${SHUNIT_TMPDIR}/current.xml\"\n}\n\n# Load and run shunit2.\n# shellcheck disable=SC2034\n[ -n \"${ZSH_VERSION:-}\" ] && SHUNIT_PARENT=$0\n. \"${TH_SHUNIT}\"\n"
        },
        {
          "name": "test_runner",
          "type": "blob",
          "size": 5.005859375,
          "content": "#! /bin/sh\n# vim:et:ft=sh:sts=2:sw=2\n#\n# Unit test suite runner.\n#\n# Copyright 2008-2020 Kate Ward. All Rights Reserved.\n# Released under the Apache 2.0 license.\n#\n# Author: kate.ward@forestent.com (Kate Ward)\n# https://github.com/kward/shlib\n#\n# This script runs all the unit tests that can be found, and generates a nice\n# report of the tests.\n#\n### Sample usage:\n#\n# Run all tests for all shells.\n# $ ./test_runner\n#\n# Run all tests for single shell.\n# $ ./test_runner -s /bin/bash\n#\n# Run single test for all shells.\n# $ ./test_runner -t shunit_asserts_test.sh\n#\n# Run single test for single shell.\n# $ ./test_runner -s /bin/bash -t shunit_asserts_test.sh\n#\n### ShellCheck (http://www.shellcheck.net/)\n# Disable source following.\n#   shellcheck disable=SC1090,SC1091\n# expr may be antiquated, but it is the only solution in some cases.\n#   shellcheck disable=SC2003\n# $() are not fully portable (POSIX != portable).\n#   shellcheck disable=SC2006\n\n# Return if test_runner already loaded.\n[ -z \"${RUNNER_LOADED:-}\" ] || return 0\nRUNNER_LOADED=0\n\nRUNNER_ARGV0=`basename \"$0\"`\nRUNNER_SHELLS='/bin/sh ash /bin/bash /bin/dash /bin/ksh /bin/mksh /bin/zsh'\nRUNNER_TEST_SUFFIX='_test.sh'\ntrue; RUNNER_TRUE=$?\nfalse; RUNNER_FALSE=$?\n\nrunner_warn() { echo \"runner:WARN $*\" >&2; }\nrunner_error() { echo \"runner:ERROR $*\" >&2; }\nrunner_fatal() { echo \"runner:FATAL $*\" >&2; exit 1; }\n\nrunner_usage() {\n  echo \"usage: ${RUNNER_ARGV0} [-e key=val ...] [-s shell(s)] [-t test(s)]\"\n}\n\n_runner_tests() { echo ./*${RUNNER_TEST_SUFFIX} |sed 's#\\./##g'; }\n_runner_testName() {\n  # shellcheck disable=SC1117\n  _runner_testName_=`expr \"${1:-}\" : \"\\(.*\\)${RUNNER_TEST_SUFFIX}\"`\n  if [ -n \"${_runner_testName_}\" ]; then\n    echo \"${_runner_testName_}\"\n  else\n    echo 'unknown'\n  fi\n  unset _runner_testName_\n}\n\nmain() {\n  # Find and load versions library.\n  for _runner_dir_ in . ${LIB_DIR:-lib}; do\n    if [ -r \"${_runner_dir_}/versions\" ]; then\n      _runner_lib_dir_=\"${_runner_dir_}\"\n      break\n    fi\n  done\n  [ -n \"${_runner_lib_dir_}\" ] || runner_fatal 'Unable to find versions library.'\n  . \"${_runner_lib_dir_}/versions\" || runner_fatal 'Unable to load versions library.'\n  unset _runner_dir_ _runner_lib_dir_\n\n  # Process command line flags.\n  env=''\n  while getopts 'e:hs:t:' opt; do\n    case ${opt} in\n      e)  # set an environment variable\n        key=`expr \"${OPTARG}\" : '\\([^=]*\\)='`\n        val=`expr \"${OPTARG}\" : '[^=]*=\\(.*\\)'`\n        # shellcheck disable=SC2166\n        if [ -z \"${key}\" -o -z \"${val}\" ]; then\n          runner_usage\n          exit 1\n        fi\n        eval \"${key}='${val}'\"\n        eval \"export ${key}\"\n        env=\"${env:+${env} }${key}\"\n        ;;\n      h) runner_usage; exit 0 ;;  # help output\n      s) shells=${OPTARG} ;;  # list of shells to run\n      t) tests=${OPTARG} ;;  # list of tests to run\n      *) runner_usage; exit 1 ;;\n    esac\n  done\n  shift \"`expr ${OPTIND} - 1`\"\n\n  # Fill shells and/or tests.\n  shells=${shells:-${RUNNER_SHELLS}}\n  [ -z \"${tests}\" ] && tests=`_runner_tests`\n\n  # Error checking.\n  if [ -z \"${tests}\" ]; then\n    runner_error 'no tests found to run; exiting'\n    exit 1\n  fi\n\n  cat <<EOF\n#------------------------------------------------------------------------------\n# System data.\n#\n\n$ uname -mprsv\n`uname -mprsv`\n\nOS Name: `versions_osName`\nOS Version: `versions_osVersion`\n\n### Test run info.\nshells: ${shells}\ntests: ${tests}\nEOF\nfor key in ${env}; do\n  eval \"echo \\\"${key}=\\$${key}\\\"\"\ndone\n\n# Run tests.\nrunner_passing_=${RUNNER_TRUE}\nfor shell in ${shells}; do\n  echo\n\n  cat <<EOF\n\n#------------------------------------------------------------------------------\n# Running the test suite with ${shell}.\n#\nEOF\n\n    # Check for existence of shell.\n    shell_bin=${shell}\n    shell_name=''\n    shell_present=${RUNNER_FALSE}\n    case ${shell} in\n      ash)\n        shell_bin=`command -v busybox`\n        [ $? -eq \"${RUNNER_TRUE}\" ] && shell_present=\"${RUNNER_TRUE}\"\n        shell_bin=\"${shell_bin:+${shell_bin} }ash\"\n        shell_name=${shell}\n        ;;\n      *)\n        [ -x \"${shell_bin}\" ] && shell_present=\"${RUNNER_TRUE}\"\n        shell_name=`basename \"${shell}\"`\n        ;;\n    esac\n    if [ \"${shell_present}\" -eq \"${RUNNER_FALSE}\" ]; then\n      runner_warn \"unable to run tests with the ${shell_name} shell\"\n      continue\n    fi\n\n    shell_version=`versions_shellVersion \"${shell}\"`\n\n    echo \"shell name: ${shell_name}\"\n    echo \"shell version: ${shell_version}\"\n\n    # Execute the tests.\n    for t in ${tests}; do\n      echo\n      echo \"--- Executing the '`_runner_testName \"${t}\"`' test suite. ---\"\n      # ${shell_bin} needs word splitting.\n      #   shellcheck disable=SC2086\n      ( exec ${shell_bin} \"./${t}\" 2>&1; )\n      shell_passing=$?\n      if [ \"${shell_passing}\" -ne \"${RUNNER_TRUE}\" ]; then\n        runner_warn \"${shell_bin} not passing\"\n      fi\n      test \"${runner_passing_}\" -eq ${RUNNER_TRUE} -a ${shell_passing} -eq ${RUNNER_TRUE}\n      runner_passing_=$?\n    done\n  done\n  return ${runner_passing_}\n}\n\n# Execute main() if this is run in standalone mode (i.e. not from a unit test).\nif [ -z \"${SHUNIT_VERSION}\" ]; then\n  main \"$@\"\nfi\n"
        }
      ]
    }
  ]
}