{
  "metadata": {
    "timestamp": 1736568237775,
    "page": 107,
    "hasNextPage": true,
    "endCursor": "Y3Vyc29yOjExMA==",
    "completionStatus": "IN_PROGRESS"
  },
  "repositories": [
    {
      "nameWithOwner": "snori74/linuxupskillchallenge",
      "stars": 3395,
      "defaultBranch": "master",
      "files": [
        {
          "name": "00-AWS-Free-Tier.md",
          "type": "blob",
          "size": 4.4501953125,
          "content": "# Day 0 - Creating Your Own Server - with AWS Free Tier\n\n## INTRO\n\nFirst, you need a server. You can't really learn about administering a remote Linux server without having one of your own - so today we're going get one - completely free!\n\nThrough the magic of Linux and virtualization, it's now possible to get a small Internet server setup almost instantly - and at very low cost. Technically, what you'll be doing is creating and renting a VPS (\"Virtual Private Server\"). In a datacentre somewhere, a single physical server running Linux will be split into a dozen or more Virtual servers, using the KVM (Kernel-based Virtual Machine) feature that's been part of Linux since early 2007.\n\nIn addition to a hosting provider, we also need to choose which \"flavour\" of Linux to install on our server. If you're new to Linux then the range of \"distributions\" available can be confusing - but the latest LTS (\"Long Term Support\") version of Ubuntu Server is a popular choice, and what you'll need for this course.\n\nThese instructions will walk you through using Amazon's AWS \"Free Tier\" (<http://aws.amazon.com>) as your VPS hosting provider. They are rated highly, with a very simple and slick interface. Although we'll be using the Free Tier, be warned that you will need to provide valid credit card information. (Of course, if you have a strong reason to use another provider, then by all means do so, but be sure to choose Ubuntu Server 20.04)\n\n## Signing up with AWS\n\nSign-up is fairly simple - just provide your email address and a password of your choosing - along with a phone number for a 2FA - a second method of authentication.\nYou will need to also provide your VISA or other credit card information.\n\n* For Support Plan, choose \"Basic Plan/Free\"\n\nLogout, then login again, and then select:\n\n* Services - from the top menu\n* EC2 - from the list of services\n\nIn \"AWS speak\" the server we'll create will be an \"EC2 compute instance\" - so now choose \"Launch Instance\". You will be presented with several image options - choose one with \"Ubuntu Server 20.04 LTS\" in the name.\nAt the next screen you'll have options for the type - typically only \"t2.micro\" is eligible for the Free Tier, but this is fine, so select to \"review and Launch\"\nAt the review screen there will be an option \"Security Groups\" - this is in fact a firewall configuration which AWS provides by default. While a good thing in general, for our purposes we want our server completely exposed, so we'll edit this to effectively disable it, like this:\n\n* Select \"Configure Security Group\"\n* Select \"Add Rule\"\n* Type: \"All traffic\", Source: \"Anywhere\"\n\nThis opens all ports and protocols to access from anywhere. While this might be unwise for a production server, it is what we want for this course.\n\nNow select \"Launch\". When prompted for a key pair, create one.\n\nYour server instance should now launch, and you can login to it by:\n\n* Services, EC2, Running instances, Connect\n\n## Remote access via SSH\n\nYou should see an \"IPv4\" entry for your server, this is its unique Internet IP address, and is how you'll connect to it via SSH (the Secure Shell protocol) - something we'll be covering in the first lesson.\n\nThis video, \"How to Set Up AWS EC2 and Connect to Linux Instance with PuTTY\" (<https://www.youtube.com/watch?v=kARWT4ETcCs>), gives a good overview of the process.\n\nYou will be logging in as the user *ubuntu*. It has been added to the 'adm' and 'sudo' groups, which on an Ubuntu system gives it access to read various logs - and to \"become root\" as required via the _sudo_ command.\n\n## You are now a sysadmin\n\nConfirm that you can do administrative tasks by typing:\n\n`sudo apt update`\n\n(Normally you'd expect this would prompt you to confirm your password, but because you're using public key authentication the system hasn't prompted you to set up a password - and AWS have configured *sudo* to not request one for \"ubuntu\").\n\nThen:\n\n`sudo apt upgrade`\n\nDon't worry too much about the output and messages from these commands, but it should be clear whether they succeeded or not. (Reply to any prompts by taking the default option). These commands are how you force the installation of updates on an Ubuntu Linux system, and only an administrator can do them.\n\nTo logout, type _logout_ or _exit_.\n\nYour server is now all set up and ready for the course!\n\nNote that:\n\n* This server is now running, and completely exposed to the whole of the Internet\n* You alone are responsible for managing it\n* You have just installed the latest updates, so it should be secure for now\n"
        },
        {
          "name": "00-Azure-Free-Tier.md",
          "type": "blob",
          "size": 4.5390625,
          "content": "# Day 0 - Creating Your Own Server - with Azure Free Credits\n\n## INTRO\n\nFirst, you need a server. You can't really learn about administering a remote Linux server without having a one of your own - so today we're going get one - completely free!\n\nThrough the magic of Linux and virtualisation, it's now possible to get a small Internet server setup almost instantly - and at very low cost. Technically, what you'll be doing is creating and renting a VPS  (\"Virtual Private Server\"). In a datacentre somewhere a single physical server running Linux will be split into a dozen or more Virtual servers using the KVM (Kernel-based Virtual Machine) feature that's been part of Linux since early 2007.\n\nAs well as a hosting provider, we also need to choose which \"flavour\" of Linux to install on our server. If you're new to Linux then the range of \"distributions\" available can be confusing - but the latest LTS (\"Long Term Support\") version of Ubuntu Server is a popular choice, and what you'll need for this course.\n\nThese instructions will walk you through using Azure's free credits.\n\n## Signing up with Azure\n\nSign-up is fairly simple - just provide your email address and a password of your choosing - along with a phone number for a 2FA - a second method of authentication. Azure can be a bit funny about 'corporate' email addresses, eg using a work address or your own domain. Create a new @outlook or @gmail.com account if so using the link on the sign-up page.\nYou will need to also provide your VISA or other credit card information.\n\n- Click 'start building in azure'\n- Click 'Deploy a virtual machine'\n- Click 'Create a linux virtual machine'\n- Search and select Ubuntu Server 20.04 LTS\n- Use the Standard _D2s_v3 size - this should be comfortably covered by your trial credits for the duration of the course\n- Ensure 'SSH Public Key' for authentication and 'generate new key pair' for SSH Public Key source are selected\n- Leave 'allow selected ports' as 'ssh (22)' for now\n- Click 'Review + Create'\n- Azure will generate and download the private key file to SSH onto the box -\n- (Windows) double-click this to open on Windows and it will be added to your cert store on the machine\n- (Mac OS X and Linux) run the command 'sudo ssh-add -K /link-to-downloaded-file'\n- Connect to the machine using `ssh azureuser@PUBLICIP`\n\nNow to fully expose the machine and all ports to the internet:\n\n- Navigate to <https://portal.azure.com/#home>\n- Select 'Virtual Machines'\n- Select your created virtual machine and select 'Networking' from the settings pane\n- Click 'Inbound Port Rules' and 'Add inbound port rule'\n- Set 'source port ranges' and 'destination port ranges' to '*' and set 'Source' and 'Destination' to 'any'. Ensure protocol is set to 'any' and action is set to 'allow'. Set the priority to '100' and create an appropriate name\n- Click 'Outbound port rules' and 'add outbound port rule'\n- Set 'source port ranges' and 'destination port ranges' to '*' and set 'Source' and 'Destination' to 'any'. Ensure protocol is set to 'any' and action is set to 'allow'. Set the priority to '101' and create an appropriate name\n\nThis opens all ports and protocols to access from anywhere. While this might be unwise for a production server, it is what we want for this course.\n\n## Remote access via SSH\n\nEnsure your machine is 'running' (if not, click 'start') and connect using the 'connect -> ssh' dropdown and following instructions\n\nYou will be logging in as the user *azureuser*. It has been added to the 'adm' and 'sudo' groups, which on an Ubuntu system gives it access to read various logs - and to \"become root\" as required via the _sudo_ command.\n\n## You are now a sysadmin\n\nConfirm that you can do administrative tasks by typing:\n\n`sudo apt update`\n\n(Normally you'd expect this would prompt you to confirm your password, but because you're using public key authentication the system hasn't prompted you to set up a password - and Azure have configured *sudo* to not request one for \"azureuser\").\n\nThen:\n\n`sudo apt upgrade`\n\nDon't worry too much about the output and messages from these commands, but it should be clear whether they succeeded or not. (Reply to any prompts by taking the default option). These commands are how you force the installation of updates on an Ubuntu Linux system, and only an administrator can do them.\n\nTo logout, type _logout_ or _exit_.\n\nYour server is now all set up and ready for the course!\n\nNote that:\n\n* This server is now running, and completely exposed to the whole of the Internet\n* You alone are responsible for managing it\n* You have just installed the latest updates, so it should be secure for now\n"
        },
        {
          "name": "00-Digital-Ocean.md",
          "type": "blob",
          "size": 4.833984375,
          "content": "# Day 0 - Creating Your Own Server - with a $5 Digital Ocean plan\n\n## INTRO\n\nFirst, you need a server. You can't really learn about administering a remote Linux server without having one of your own - so today we're going to buy one!\n\nThrough the magic of Linux and virtualization, it's now possible to get a small Internet server setup almost instantly - and at very low cost. Technically, what you'll be doing is creating and renting a VPS  (\"Virtual Private Server\"). In a datacentre somewhere, a single physical server running Linux will be split into a dozen or more Virtual servers, using the KVM (Kernel-based Virtual Machine) feature that's been part of Linux since early 2007.\n\nIn addition to a hosting provider, we also need to choose which \"flavour\" of Linux to install on our server. If you're new to Linux then the range of \"distributions\" available can be confusing - but the latest LTS (\"Long Term Support\") version of Ubuntu Server is a popular choice, and what you'll need for this course.\n\nThese instructions will walk you through using Digital Ocean (<http://digitalocean.com>) as your VPS hosting provider. They are rated highly, with a very simple and slick interface - and low cost of $5 (USD) per month for the minimal server that you'll be creating. (Of course, if you have a strong reason to use another provider, then by all means do so, but be sure to choose Ubuntu Server 20.04)\n\n## Signing up with Digital Ocean\n\nSign-up is immediate - just provide your email address and a password of your choosing and you're in!\n\n* Choose \"Manage, Droplets\" from the left-hand sidebar. (a \"droplet\" is Digital Ocean's cute name for a server!)\n* Select the image \"Ubuntu 20.04 LTS\"\n* For plan, choose \"Starter\"\n* You'll be prompted to start a $40/mo. plan, but select \"Show all plans\", and select the $5/mo. one - that's fine for this course.\n* You don't need to add any block storage.\n* Select whichever region you wish.\n* Authentication - choose \"Password\"\n* Choose a strong password for the root account.\n* Note that since the server is on the Internet it will be under immediate attack from bots attempting to \"brute force\" the root password. Make it strong!\n* Choose a hostname because the default ones are pretty ugly.\n\n## Logging in for the first time\n\nSelect your droplet and \"Access\" from the left-hand sidebar and you should be able to login to the console using this. Use the login name \"root\", and the password you selected. Note that the password won't show as you type or paste it.\n\n## Creating a working admin account\n\nWe want to follow the Best Practice of not logging as \"root\" remotely, so we'll create an ordinary user account, but one with the power to \"become root\" as necessary, like this:\n\n`adduser snori74`\n\n`usermod -a -G adm snori74`\n\n`usermod -a -G sudo snori74`\n\n(Of course, replace 'snori74' with your name!)\n\n*This* will be the account that you use to login and work with your server. It has been added to the 'adm' and 'sudo' groups, which on an Ubuntu system gives it access to read various logs and to \"become root\" as required via the _sudo_ command.\n\n## You are now a sysadmin\n\nLogout as *root*, by typing logout or *exit*, then login as your new sysadmin user, and confirm that you can do administrative tasks by typing:\n\n`sudo apt update`\n\n(you'll be asked to confirm your password)\n\nThen:\n\n`sudo apt upgrade`\n\nDon't worry too much about the output and messages from these commands, but it should be clear whether they succeeded or not. These commands are how you force the installation of updates on an Ubuntu Linux system, and only an administrator can do them.\n\n## We can now safely disable login as the *root* user\n\nWith our new working user able to perform all sysadmin tasks, there is no reason for us to login user *root*. Our server is exposed to all the internet, and we can expect continuous attempts to login from malicious bots - most of which will be attempting to login as *root*. While we did set a very secure password just before, it would be nice to know that remote login as *root* is actually *impossible* - and it's possible to do that with this command:\n\n`sudo usermod -p \"!\" root`\n\nThis disables direct login access, while still allowing approved logged in users to \"become root' as necessary - and is the normal default configuration of an Ubuntu system. (Digital Ocean's choice to enable \"root\" in their image is non-standard).  \n\nTo logout, type _logout_ or _exit_.\n\nYour server is now all set up and ready for the course!\n\n## Remote access via SSH\n\nYou should see an \"IPv4\" entry for your server, this is its unique Internet IP address, and is how you'll connect to it via SSH (the Secure Shell protocol) - something we'll be covering in the first lesson.\n\nNote that:\n\n* This server is now running, and completely exposed to the whole of the Internet\n* You alone are responsible for managing it\n* You have just installed the latest updates, so it should be secure for now\n"
        },
        {
          "name": "00-Google-Cloud.md",
          "type": "blob",
          "size": 3.8212890625,
          "content": "# Day 0 - Creating Your Own Server - with Google Cloud Platform Free Tier\n\n_(DRAFT: Use this as a guide, but it has not been fully tested. Please let us know of any issues with it)_\n\n## INTRO\n\nFirst, you need a server. You can't really learn about administering a remote Linux server without having a one of your own - so today we're going get one - completely free!\n\nThrough the magic of Linux and virtualisation, it's now possible to get a small Internet server setup almost instantly - and at very low cost. Technically, what you'll be doing is creating and renting a VPS  (\"Virtual Private Server\"). In a datacentre somewhere a single physical server running Linux will be split into a dozen or more Virtual servers using the KVM (Kernel-based Virtual Machine) feature that's been part of Linux since early 2007.\n\nAs well as a hosting provider, we also need to choose which \"flavour\" of Linux to install on our server. If you're new to Linux then the range of \"distributions\" available can be confusing - but the latest LTS (\"Long Term Support\") version of Ubuntu Server is a popular choice, and what you'll need for this course.\n\nThese instruction will walk you through using Google Cloud \"Free Tier\" (<https://cloud.google.com>) as your VPS hosting provider. They are rated highly, with a very simple and slick interface. Although we'll be using the Free Tier, be warned that you will need to provide valid credit card information. (Of course, if you have a strong reason to use another provider, then by all means do so, but be sure to choose Ubuntu Server 20.04)\n\n## Signing up with GCP\n\nSign-up is fairly simple - just provide your email address and a password of your choosing - along with a phone number for a 2FA - a second method of authentication.\nYou will need to also provide your VISA or other credit card information.\n\n* Choose \"Compute Engine\" and click \"VM Instances\".\n* Create a new instance.\n* Select whichever regions you want.\n* For Machine Configuration select series and set to \"E2\" and Machine type to \"e2-micro\".\n* Change boot disk to \"Ubuntu 20.04 LTS\"\n\nNow after we create our own server, we need to open all ports and protocols to access from anywhere. While this might be unwise for a production server, it is what we want for this course.\n\nNavigate to your GCP home page and goto Networking > VPC Network > Firewall > Create Firewall\n\nSet \"Direction of Traffic\" to \"Ingress\"\nSet \"Target\" to \"All instances in the network\"\nSet \"Source Filter\" to \"IP Ranges\"\nSet \"Source IP Ranges\" to  \"0.0.0.0/0\"\nSet \"Protocols and Ports\" to \"Allow All\"\nCreate and repeat the steps by creating a new Firewall and setting \"Direction of Traffic\" to \"Egress\"\n\n## Logging in for the first time\n\nSelect your instance and click \"ssh\" it will open a new window console. To access the root, type \"sudo -i passwd\" in the command line then set your own password. Log in by typing \"su\" and \"password\". Note that the password won't show as you type or paste it.\n\n## Setting up SSH\n\nYou can also refer to <https://cloud.google.com/compute/docs/instances/connecting-advanced#thirdpartytools> if you intend to access your server via third-party tools (e.g. Putty).\n\n## You are now a sysadmin\n\nConfirm that you can do administrative tasks by typing:\n\n`sudo apt update`\n\nThen:\n\n`sudo apt upgrade`\n\nDon't worry too much about the output and messages from these commands, but it should be clear whether they succeeded or not. (Reply to any prompts by taking the default option). These commands are how you force the installation of updates on an Ubuntu Linux system, and only an administrator can do them.\n\nTo logout, type _logout_ or _exit_.\n\nYour server is now all set up and ready for the course!\n\nNote that:\n\n* This server is now running, and completely exposed to the whole of the Internet\n* You alone are responsible for managing it\n* You have just installed the latest updates, so it should be secure for now\n"
        },
        {
          "name": "00-Remote-server-without-Credit-Card.md",
          "type": "blob",
          "size": 2.89453125,
          "content": "# Day 0 - Creating Your Own Server - without a credit card\n\n## INTRO\n\nWe normally recommend using Amazon's AWS \"Free Tier\" (<http://aws.amazon.com>) or Digital Ocean (<https://digitalocean.com>) - but both require that you have a credit card. The same is true of the Microsoft Azure, Google's GCP and the vast majority of providers listed at Low End Box (<https://lowendbox.com/>).\n\nSome will accept PayPal, or Bitcoin - but typically those who don't have a credit card don't have these either.\n\nNote that many will also require you to be over 18 (but not all), and this is true also of some of the options blow.\n\n**WARNING:** If you go searching too deeply for options in this area, you're very likely to come across a range of scammy, fake, or fraudulent sites. While we've tried to eliminate these from the links below, please do be careful! It should go without saying that none of these are \"affiliate\" links, and we get no kick-backs from any of them :-)\n\nSo, if you are in this situation, below are some of your options:\n\n## Free Trial\n\n* <https://www.ibm.com/cloud/free> - no credit card or student email required, 30 days trial. (VPS service known as Hyper Protect Virtual Server)\n\n## Educational packs\n\n* <https://azure.microsoft.com/en-gb/free/students/> - explicitly no credit card required, just needs an \"educational email address\")\n\n* <https://education.github.com/pack?sort=popularity&tag=Cloud> - Github Educate, Requires student email and a proof of being a student, Activation is NOT instant. Includes \\$100 AWS credits and/or \\$50 Digital Ocean credits.\n\n* <https://aws.amazon.com/education/awseducate/> - AWS Educate (can apply without Github Student Pack) - \\$100 free credits\n\n* Digital Ocean (Part Of Github Student Pack) - \\$50 free credits\n\n### Comparison\n\n| Provider      | Instant Activation? | Must be a student?        | VPS ram       | VPS cpu count | Time                         | Credits |\n| ------------- | ------------------- | ------------------------- | ------------- | ------------- | ---------------------------- | ------- |\n| Azure         | Yes                 | Yes                       | 1gb/ 512mb\\*2 | 1/2           | 1 year, renewed up to 4 years | \\$100   |\n| *IBM Cloud*   | Yes                 | No                        | 2gb           | 1             | 30 days                      | N/A     |\n| AWS educate   | No                  | Yes (Github student pack) | ???           | ???           | ???                          | \\$100   |\n| Digital Ocean | No                  | Yes (Github student pack) | ???           | ???           | ???                          | \\$50    |\n\n## Cards that work as, or like, credit cards\n\n* Debit cards\n* <https://www.paysafecard.com/>\n* privacy.com (US-only)\n\nNote that:\n\n* This server is now running, and completely exposed to the whole of the Internet\n* You alone are responsible for managing it\n* You have just installed the latest updates, so it should be secure for now\n"
        },
        {
          "name": "01-Welcome.md",
          "type": "blob",
          "size": 0.162109375,
          "content": "# Welcome to the challenge!\n\n## Congratulatons on making the commitment!\n\nToday is the first day of a month-long commitment to gain new knowledge, skills and habits.\n"
        },
        {
          "name": "01.md",
          "type": "blob",
          "size": 7.0068359375,
          "content": "# Day 1 - Accessing your server\n\n## INTRO\n\nYou should now have a remote server setup running the latest Ubuntu Server LTS (Long Term Support) version. You alone will be administering it. To become a fully-rounded Linux server admin you should become comfortable working with different versions of Linux, but for now Ubuntu is a good choice.\n\nOnce you have reached a level of comfort at the command-line then you'll find your skills transfer not only to all the standard Linux variants, but also to Android, Apple's OSX, OpenBSD, Solaris and IBM AIX. Throughout the course you'll be working on Linux - but in fact most of what is covered is applicable to any system in the \"UNIX family\" - and the major differences between them are with their graphic user interfaces such as Gnome, Unity, KDE etc - none of which you’ll be using!\n\nAlthough there is a \"root\" user, you will be logging in and working from the user account that you setup. Because this is a member of the group \"sudo\" it is able to run commands \"as root\" by preceding them with \"sudo\".\n\n## YOUR TASKS TODAY:\n\n* Connect and login remotely to your server\n* Run a few simple simple commands to check the status of your server\n* Change your password\n\n## INSTRUCTIONS\n\nRemote access used to be done by the simple *telnet* protocol, but now the much more secure SSH (“Secure SHell) protocol is always used.\n\nIf you're using any Linux or Unix system, including Apple's MacOS, then you can simply open up a \"terminal\" session and use your command-line *ssh* client like this:\n\n`ssh user@<ip address>`\n\nFor example:\n\n`ssh support@192.123.321.99`\n\nOn Linux distributions with a menu you'll typically find the terminal under \"Applications menu -> Accessories -> Terminal\", \"Applications menu -> System -> Terminal\" or \"Menu -> System -> Terminal Program (Konsole)\"- or you can simply search for your terminal application. In many cases Ctrl+Alt+T will also bring up a terminal windows.\n\nIf you have configured the remote server with your SSH public key (see \"Password-less SSH login\" in the EXTENSION section of this post), then you'll need to point to the location of the private part as proof of identity with the \"_-i_\" switch, typically like this:\n\n`ssh -i ~/.ssh/id_rsa support@192.123.321.99`\n\nA very slick connection process can be setup with the _.ssh/config_ feature - see the \"SSH client configuration\" link in the EXTENSION section below.\n\nOn an MacOS machine you'll normally access the command line via Terminal.app - it's in the Utilities sub-folder of Applications.\n\nOn recent Windows 10 versions, the same command-line client is now available, but must be enabled (via \"Settings\", \"Apps\", \"Apps & features\", \"Manage optional features\", \"Add a feature\", \"OpenSSH client\".\n\nAlternatively, you can install the [Windows Subsystem for Linux](https://docs.microsoft.com/en-us/windows/wsl/install-win10) which gives you a full local command-line Linux environment, including an SSH client - _ssh_.\n\nThere are also GUI SSH clients for Windows (PuTTY, MobaXterm) and MacOS (Terminal.app, iTerm2).  \n\nRegardless of which client you use, the first time you connect to your server, you may receive a warning that you're connecting to a new server - and be asked if you wish to \"cache the host key\". Do this. Now, if you get a warning in future connections it means that either: (a) you are being fooled into connecting to a different machine or (b) someone may be trying a \"man in the middle\" attack.\n\nSo, now login to your server as your user - and remember that Linux is case-sensitive regarding user names, as well as passwords.\n\nOnce logged in, notice that the \"command prompt” that you receive ends in  *$* - this is the convention for an ordinary user, whereas the \"root\" user with full administrative power has a *#* prompt.\n\nTry these simple commands:\n\n`ls`\n\n`uptime`\n\n`free`\n\n`df -h`\n\n`uname -a`\n\nIf you're using a password to login (rather than public key), then now is a good time to ensure that this is very strong and unique - i.e. At least 10 characters - because your server is fully exposed to bots that will be continuously attempting to break in. Use the *passwd* command to change your password. To do this, think of a new, secure password, then simply type *passwd*, press “Enter” and give your current password when prompted, then the new one you've chosen, confirm it  - and then WRITE IT DOWN somewhere. In a production system of course, public keys and/or two factor authentication would be more appropriate.\n\nIt's very handy to be able to cut and paste text between your remote session and your local desktop, so spend some time getting confident with how to do this in your setup.\n\nLog out by typing *exit*.\n\nYou'll be spending a lot of time in your SSH client, so it pays to spend some time customizing it. At the very least try \"black on white\" and \"green on black\" - and experiment with different monospaced fonts, (\"Ubuntu Mono\" is free to download, and very nice).\n\n## POSTING YOUR PROGRESS\n\nRegularly posting your progress can be a helpful motivator. Feel free to post to the subreddit a small introduction of yourself, and your Linux background for your \"classmates\" - and notes on how each day has gone.\n\nOf course, also drop in a note if you get stuck or spot errors in these notes.\n\n## WRAP\n\nYou now have the ability to login remotely to your own server. Perhaps you might now try logging in from home and work - even from your smartphone! - using an ssh client app such as \"Termux\". As a server admin you'll need to be comfortable logging in from all over. You can also potentially use JavaScript ssh clients (search for \"consolefish\"), or from a cybercafe - but these options involve putting more trust in third-parties than most sysadmins would be comfortable with when accessing production systems.\n\n## A NOTE ON \"HARDENING\"\n\nYour server is protected by the fact that its security updates are up to date, and that you've set Long Strong Unique passwords - or are using public keys. While exposed to the world, and very likely under continuous attack, it should be perfectly secure. Next week we'll look at how we can view those attacks, but for now it's simply important to state that while it's OK to read up on \"SSH hardening\", things such as changing the default port and `fail2ban` are unnecessary and unhelpful when we're trying to learn - and you are perfectly safe without them.\n\n## EXTENSION\n\nIf this is all too easy, then spend some time reading up on:\n\n* [SSH Tunneling](https://linuxize.com/post/how-to-setup-ssh-tunneling/)\n* [Password-less SSH login](https://linuxize.com/post/how-to-setup-passwordless-ssh-login/)\n* [SSH client configuration](https://linuxize.com/post/using-the-ssh-config-file/)\n\n## RESOURCES\n\n* [\"Using PuTTY for SSH (Windows)\"](http://kb.mediatemple.net/questions/1595/Using+SSH+in+PuTTY+%28Windows%29#gs )\n* [Comparing CENTOS and Ubuntu for servers](http://serverfault.com/questions/53954/centos-vs-ubuntu)\n* [A Beginners Guide to SSH](https://www.youtube.com/watch?v=qWKK_PNHnnA)\n\n*Copyright 2012-2021 @snori74 (Steve Brorens). Can be reused under the terms of the Creative Commons Attribution 4.0 International Licence (CC BY 4.0).*\n"
        },
        {
          "name": "02.md",
          "type": "blob",
          "size": 7.2294921875,
          "content": "# Day 2 - Basic navigation\n\n## INTRO\n\nMost computer users outside of the Linux and Unix world don't spend much time at the command-line now, but as a Linux sysadmin this is your default working environment - so you need to be skilled in it.\n\nWhen you use a graphic desktop such as Windows or Apple's macOS (or even the latest Linux flavors), then increasingly you are presented with simple \"places\" where your stuff is stored - \"Pictures\" \"Music\" etc but if you're even moderately technical then you'll realize that underneath all this is a hierarchical  \"directory structure\" of \"folders\" (e.g. *C:\\\\Users\\\\Steve\\\\Desktop* on Windows or */Users/Steve/Desktop* on macOS - and on a Desktop Linux system */home/steve/Desktop*)\n\n_From now on, the course will point you to a range of good online resources for a topic, and then set you a simple set of tasks to achieve. It’s perfectly fine to google for other online resources, refer to any books you have etc - and in fact a *fundamental element* of the design of this course is to force you to do a bit of your own research. Even the most experienced sysadmins will do an online search to find advice for how to use commands - so the sooner you too get into that habit the better!_\n\n## YOUR TASKS TODAY\n\n* Use the provided resources to check out the basic commands and concepts\n* Login to your server via SSH and move about the directory structure at the command-line\n* Take note of how your “prompt” changes as you change directory\n* Be sure to understand how `cd` on its own takes you back to your “home directory”\n* Understand what `cd ~` and `cd ..` do\n* Use the `ls` command to list the contents of directories, and try several of the “switches” - in particular `ls -ltr` to show the most recently altered file last\n* Use the `mkdir` command to create a new directory (folder) `test` in your home folder ( e.g `/home/support/test`)\n\n## STEP-BY-STEP\n\n* Login to your server using ssh\n* `/` is the \"root\" of a branching tree of folders (also known as directories)\n* At all times you are \"in\" one part of the system - the command `pwd` (\"print working directory\") will show you where you are\n* Generally your prompt is also configured to give you at least some of this information, so if I'm \"in\" the _/etc_ directory then the prompt might be \"steve@202.203.203.22: /etc>$\" or simply \"/etc: $\"\n* `cd` moves to different areas - so `cd /var/log` will take you into the `/var/log` folder - do this and then check with `pwd` - and look to see if your prompt changes to reflect your location.\n* You can move \"up\" the structure by typing `cd ..` ( \"cee dee dot dot \") try this out by first `cd`'ing to `/var/log/` then `cd ..` and then `cd ..` again - watching your prompt carefully, or typing pwd each time, to clarify your present working directory.\n* A \"relative\" location is based on your present working directory - e.g. if you first `cd /var` then pwd will confirm that you are \"in\" `/var`, and you can move to `/var/log` in two ways - either by providing the full path with `cd /var/log` or simply the \"relative\" path with the command `cd log`\n* A simple `cd` will always return you to your own defined \"home directory\", also referred to as `~` (the \"tilde\" character) [NB: this differs from DOS/Windows]\n* What files are in a folder? The `ls` (list) command will give you a list of the files, and sub folders. Like many Linux commands, there are options (known as \"switches\") to alter the meaning of the command or the output format. Try a simple  `ls`, then  `ls -l -t`  and then try  `ls -l -t -r -a`\n* By convention, files with a starting character of \".\" are considered hidden and the `ls`, and many other commands, will ignore them. The `-a` switch includes them. You should see a number of hidden files in your home directory.\n* A note on switches: Generally most Linux command will accept one or more \"parameters\", and one or more \"switches\". So, when we say `ls -l  /var/log` the \"`-l`\" is a switch to say \"long format\" and the \"`/var/log`\" is the \"parameter\". Many commands accept a large number of switches, and these can generally be combined (so from now on, use `ls -ltra`, rather than `ls -l -t -r -a`\n* In your home directory type `ls -ltra` and look at the far left hand column - those entries with a \"d\" as the first character on the line are directories (folders) rather than files. They may also be shown in a different color or font - if not, then adding the \"--color=auto\" switch should do this (i.e.  `ls -ltra --color=auto`)\n* You can make a new folder/directory with the `mkdir` command, so move to your home directory, type `pwd` to check that you are indeed in the correct place, and then create a directory, for example to create one called \"test\", simply type `mkdir test`. Now use the `ls` command to see the result.\n\n## RTFM\n\nThis is a good time to mention that Linux comes with a fine on-line manual - invoked with the `man` command. Each application installed comes with its own page in this manual, so that you can look at the page for _pwd_ to see the full detail on the syntax like this:\n\n`man pwd`\n\nYou might also try:\n\n```bash\nman cp\nman mv\nman grep\nman ls\nman man\n```\n\nAs you’ll see, these are excellent for the detailed syntax of a command, but many are extremely terse, and for others the amount of detail can be somewhat daunting!\n\n## WRAP\n\nBeing able to move confidently around the directory structure at the command line is important, so don’t think you can skip it! However, these skills are something that you’ll be constantly using over the twenty days of the course, so don’t despair if this doesn’t immediately “click”.\n\n## EXTENSION\n\nIf this is already something that you’re very familiar with, then:\n\n* Learn about `pushd` and `popd` to navigate around multiple directories easily. Running `pushd /var/log` moves you to to the `/var/log`, but keeps track of where you were. You can `pushd` more than one directory at a time. Try it out: `pushd /var/log`, `pushd /dev`, `pushd /etc`, `pushd`, `popd`, `popd`. Note how `pushd` with no arguments switches between the last two _pushed_ directories but\n[more complex navigation is also possible](https://opensource.com/article/19/8/navigating-bash-shell-pushd-popd). Finally, `cd -` also moves you the last visited directory.\n* Take the time today to understand how the environment variable PS1 etc work (this article: [Bash Shell: Take Control of PS1, PS2, PS3, PS4 and PROMPT_COMMAND\n](http://www.thegeekstuff.com/2008/09/bash-shell-take-control-of-ps1-ps2-ps3-ps4-and-prompt_command/) is a good start).\n* Set yourself up with a custom prompt using the information in [Bash Shell PS1: 10 Examples to Make Your Linux Prompt like Angelina Jolie](http://www.thegeekstuff.com/2008/09/bash-shell-ps1-10-examples-to-make-your-linux-prompt-like-angelina-jolie/)\n\n## RESOURCES\n\n* [Explore the Linux file system](https://www.digitalocean.com/community/tutorials/how-to-use-cd-pwd-and-ls-to-explore-the-file-system-on-a-linux-server)\n* [Linux File System](https://www.youtube.com/watch?v=2qQTXp4rBEE)\n* [Simple Terminal Commands on Ubuntu](http://www.youtube.com/watch?v=CGBsurVdLGY)\n* [Solaris Unix Commands](http://www.gsp.com/support/virtual/admin/unix/solaris/commands.html)\n\n*Copyright 2012-2021 @snori74 (Steve Brorens). Can be reused under the terms of the Creative Commons Attribution 4.0 International Licence (CC BY 4.0).*\n"
        },
        {
          "name": "03.md",
          "type": "blob",
          "size": 5.138671875,
          "content": "# Day 3 - Power trip!\n\n## INTRO\n\nYou've been logging in as an ordinary user at your server, yet you're probably aware that `root` is the power user on a Linux system. This administrative or \"superuser\" account, is all powerful - and a typo in a command could potentially cripple your server. As a sysadmin you're typically working on systems that are both important and remote, so avoiding such mistakes is A Very Good Idea.  \n\nOn many older production systems all sysadmins login as “root”, but it’s now common Best Practice to discourage or disallow login directly by `root` - and instead to give specified trusted users the permission to run root-only commands via the `sudo` command.\n\nThis is the way that your server has been set-up, with your “ordinary” login given the ability to run any root-only command  - but only if you precede it with `sudo`.\n\n(Normally on an Ubuntu system this will ask you to re-confirm your identity with your password.\nHowever, the standard AWS Ubuntu Server image does `not` prompt for a password).\n\n## YOUR TASKS TODAY:\n\n* Use the links in the \"Resources\" section below to understand how `sudo` works\n* Use `ls -l` to check the permissions of `/etc/shadow` - notice that only `root` has any access. Can you use `cat`, `less` or `nano` to view it?\n* This file is where the hashed passwords are kept. It is a prime target for intruders - who aim to grab it and use offline password crackers to discover the passwords.\n* Now try with `sudo`, e.g. `sudo less /etc/shadow`\n* Test running the `reboot` command, and then via `sudo` (i.e. `sudo reboot`)\n\nOnce you've reconnected back:\n\n* Use the `uptime` command to confirm that your server did actually fully restart\n* Test fully “becoming root” by the command `sudo -i`  This can be handy if you have a series of commands to do \"as root\". Note the change to your prompt.\n* Type `exit` or `logout` to get back to your own normal “support” login.\n* Use `less` to view the file `/var/log/auth.log`, where any use of `sudo` is logged\n* You could \"filter\" this by typing: `grep \"sudo\" /var/log/auth.log`\n\nIf you wish to, you can now rename your server. Traditionally you would do this by editing two files, `/etc/hostname` and `/etc/hosts` and then rebooting - but the more modern, and recommended, way is to use the `hostnamectl` command; like this:\n\n`sudo hostnamectl set-hostname mylittlecloudbox`\n\nNo reboot is required.\n\nFor a cloud server, you might find that the hostname changes after a reboot. To prevent this, edit `/etc/cloud/cloud.cfg` and change the \"preserve_hostname\" line to read:\n\n`preserve_hostname: true`\n\nYou might also consider changing the timezone your server uses. By default this is likely to be UTC (i.e. GMT) - which is pretty appropriate for a worldwide fleet of servers. You could also set it to the zone the server is in, or where you and your headquarters are. For a company this is a decision not to be taken lightly, but for now you can simply change as you please!\n\nFirst check the current setting with:\n\n`timedatectl`\n\nThen get a a list of available timezones:\n\n`timedatectl list-timezones`\n\nAnd finally select one, like this:\n\n`sudo timedatectl set-timezone Australia/Sydney`\n\nConfirm:\n\n`timedatectl`\n\nThe major practical effects of this are (1) the timing of scheduled tasks, and (2) the timestamping of the logs files kept under `/var/log`. If you make a change, there will naturally be a \"jump\" in the dates and time recorded.\n\n## WRAP\n\nAs a Linux sysadmin you may be working on client or custom systems where you have little control, and many of these will default to doing everything as `root`. You need to be able to safely work on such systems - where your only protection is to double check before pressing `Enter`.\n\nOn the other hand, for any systems where you have full control, setting up a \"normal\" account for yourself (and any co-admins) with permission to run `sudo`  is recommended. While this is standard with Ubuntu, it's also easy to configure with other  popular server distros such as Debian, CentOS and RHEL.\n\n## A NOTE ON \"HARDENING\"\n\nYour server is protected by the fact that its security updates are up to date, and that you've set Long Strong Unique passwords - or are using public keys. While exposed to the world, and very likely under continuous attack, it should be perfectly secure. Next week we'll look at how we can view those attacks, but for now it's simply important to state that while it's OK to read up on \"SSH hardening\", things such as changing the default port and `fail2ban` are unnecessary and unhelpful when we're trying to learn - and you are perfectly safe without them.\n\n## EXTENSION\n\n* Read [Hardening SSH](https://medium.com/@jasonrigden/hardening-ssh-1bcb99cd4cef)\n\n## RESOURCES\n\n* [This cartoon explains it nicely!](http://xkcd.com/149/)\n* [Sudo in Ubuntu](https://help.ubuntu.com/community/RootSudo)\n* [How to use \"sudo\"](https://www.howtoforge.com/tutorial/sudo-beginners-guide/)\n* [This is how password cracking is done](https://null-byte.wonderhowto.com/how-to/crack-shadow-hashes-after-getting-root-linux-system-0186386/)\n\n*Copyright 2012-2021 @snori74 (Steve Brorens). Can be reused under the terms of the Creative Commons Attribution 4.0 International Licence (CC BY 4.0).*\n"
        },
        {
          "name": "04.md",
          "type": "blob",
          "size": 3.529296875,
          "content": "# Day 4 - Installing software, exploring the file structure\n\n## INTRO\n\nAs a sysadmin, one of your key tasks is to install new software as required. You’ll also need to be very familiar with the layout of the standard directories in a Linux system.\n\nYou’ll be getting practice in both of these areas in today’s session.\n\n## Your tasks today\n\n* Install a new application from the online repositories \n* Become familiar with some of the standard directories\n* Look at the format and content of some configuration files.\n\nIf you've used a smartphone \"app store \" or \"market\", then you'll immediately understand the normal installation of Linux software from the standard repositories. As long as we know what the name or description of a package (=app) is, then we  can search for it:\n\n     apt search \"midnight commander\"\n\nThis will show a range of matching \"packages\", and we can then install them with `apt install` command. So to install package `mc` (Midnight Commander) on Ubuntu:\n\n```bash\nsudo apt install mc\n```\n\n(Unless you're already logged in as the `root` user you need to use `sudo` before the installation commands - because an ordinary user is not permitted to install software that could impact a whole server).\n\nNow that you have `mc` installed, start it by simply typing `mc` and pressing *Enter*.\n\nThis isn't a \"classic\" Unix application, but once you get over the retro interface you should find navigation fairly easy, so go looking for these directories:\n\n`/root`  \n`/home`  \n`/sbin`  \n`/etc`  \n`/var/log`  \n\n...and use the links in the Resources section below to begin to understand how these are used. You can also read the official manual on this hierarchy by typing `man hier`.\n\nMost key configuration files are kept under `/etc` and subdirectories of that. These files, and the logs under `/var/log` are almost invariably simple text files. In the coming days you'll be spending a lot of time with these - but for now simply use F3 to look into their contents.\n\nSome interesting files to look at are: `/etc/passwd`, `/etc/ssh/sshd_config` and `/var/log/auth.log`\n\nUse F3 again to exit from viewing a file.\n\nF10 will exit `mc`, although you may need to use your mouse to select it.\n\n(On an Apple Mac in Terminal, you may need to use ESC+3 to get F3 and ESC+0 for F10)\n\nNow use `apt search` to search for and install some more packages: Try searching for “hangman”. You will probably find that an old text-based version is included in a package called `bsdgames`. Install and play a couple of rounds...\n\n## Posting your progress\n\n* Post your progress, comments and questions to the forum.\n\n## EXTENSION\n\n* Use `mc` to view `/etc/apt/sources.list` where the actual locations of the repositories are specified. Often these will be “mirror” sites that are closer to your server than the main Ubuntu servers.\n* Read [Repositories - CommandLine\n](https://help.ubuntu.com/community/Repositories/CommandLine) for more of the gory details.\n\n## RESOURCES\n\n* [Ubuntu and Red Hat/CentOS package management comparison]( https://help.ubuntu.com/community/SwitchingToUbuntu/FromLinux/RedHatEnterpriseLinuxAndFedora)\n* [Ubuntu Server Guide - Package Management](https://ubuntu.com/server/docs/package-management)\n* [Midnight Commander vs Ranger](https://www.slant.co/versus/6822/7576/~midnight-commander_vs_ranger)\n* [Linux directory system explained](https://www.howtogeek.com/117435/htg-explains-the-linux-directory-structure-explained/)\n\n*Copyright 2012-2021 @snori74 (Steve Brorens). Can be reused under the terms of the Creative Commons Attribution 4.0 International Licence (CC BY 4.0).*\n"
        },
        {
          "name": "05.md",
          "type": "blob",
          "size": 3.3974609375,
          "content": "# Day 5 - More or less...\n\n## INTRO\n\nToday we'll end with a bang - with a quick introduction to five different topics. Mastery isn't required today - you'll be getting plenty of practice with all these in the sessions to come!\n\nDon’t be misled by how simplistic some of these commands may seem - they all have hidden depths and many sysadmins will be using several of these every day.\n\n## TASKS\n\nUse the links in the Resources section to complete these tasks:\n\n* Get familiar with using `more` and `less` for viewing files, including being able to get to the top or bottom of a file in `less`, and searching for some text\n\n* Test how “tab completion” works - this is a handy feature that helps you enter commands correctly. It helps find both the command and also file name parameters (so typing `les` then hitting “Tab” will complete the command `less`, but also typing `less /etc/serv` and pressing “Tab” will complete to `less /etc/services`. Try typing `less /etc/s` then pressing “Tab”, and again, to see how the feature handles ambiguity.\n\n* Now that you've typed in quite a few commands, try pressing the “Up arrow” to scroll back through them. What you should notice is that not only can you see your most recent commands - but even those from the last time you logged in. Now try the `history`  command - this lists out the whole of your cached command history - often 100 or more entries. There are number of clever things that can be done with this. The simplest is to repeat a command - pick one line to repeat (say number 20)  and repeat it by typing !20 and pressing “Enter”. Later when you'll  be typing long, complex, commands this can be *very* handy. You can also press `Ctrl + r`, then start typing any part of the command that you are looking for. You'll see an autocomplete of a past command at your prompt. If you keep typing, you'll get more specific options appear.  You can either run it by pressing return, or editing it first by pressing arrows or other movement keys.\n\n* Look for “hidden” files in your home directory. In Linux the convention is simply that any file starting with a \".\" character is hidden. So, type `cd` to return to your \"home directory\" then `ls -l` to show what files are there. Now type `ls -la` or `ls -ltra` (the \"a\" is for \"all\") to show all the files - including those starting with a dot. By far the most common use of \"dot files\" is to keep personal settings in a home directory. So use your new skills with `less` to look at the contents of  `.bashrc` ,  `.bash_history` and others.\n\n* Finally, use the `nano` editor to create a file in your home directory and type up a summary of how the last five days have worked for you.\n\n## RESOURCES\n\n* [Unix Less Command: 10 Tips for Effective Navigation](http://www.thegeekstuff.com/2010/02/unix-less-command-10-tips-for-effective-navigation/)\n* [How To Use Bash History Commands and Expansions...](https://www.digitalocean.com/community/tutorials/how-to-use-bash-history-commands-and-expansions-on-a-linux-vps)\n* [BASH Shell commands less](http://www.youtube.com/watch?v=ZQTt0LEoj3k)\n* [Tab completion](https://www.youtube.com/watch?v=7V-fovVlCvA)\n* [What are dotfiles?](http://thegeekyway.com/what-are-dotfiles/)\n* [Nano editor tutorials](http://www.debianadmin.com/nano-editor-tutorials.html)\n\n*Copyright 2012-2021 @snori74 (Steve Brorens). Can be reused under the terms of the Creative Commons Attribution 4.0 International Licence (CC BY 4.0).*\n"
        },
        {
          "name": "06.md",
          "type": "blob",
          "size": 6.5634765625,
          "content": "# Day 6 - Editing with \"vim\"\n\n## INTRO\n\nSimple text files are at the heart of Linux, so editing these is a key sysadmin skill. There are a range of simple editors aimed at beginners such as: `nano`, `pico`, `joe` or `jed`. These all look as if they were written for DOS back in the 1980's - but are pretty easy to \"just figure out\".\n\nThe Real Sysadmin however, uses `vi`  - this is the editor that's always installed - and today you'll get started using it.\n\nBill Joy wrote `vi` back in the mid 1970's - and even the \"modern\" descendant `vim` that we'll concentrate on is over 20 years old, but despite their age, these remain the standard editors on command-line server boxes. Additionally, they have a loyal following among programmers, and even some writers.\n\nVery often when you type `vi`, what the system actually starts is `vim`. To see if this is true of your system type:\n\n     vi --version\n\nto check.\n\n## THE TWO THINGS YOU NEED TO KNOW\n\n* There are two \"modes\" - with very different behaviours\n* Little or nothing onscreen lets you know which mode you're currently in!\n\nThe two modes are \"normal mode\" and \"insert mode\", and as a beginner, simply remember:\n\n`\"Press Esc twice or more to return to normal mode\"`\n\nThe \"normal mode\" is used to input commands, and \"insert mode\" for writing text - similar to a regular text editor's default behaviour.\n\n## INSTRUCTIONS\n\nSo, first grab a text file to edit. A copy of `/etc/services` will do nicely:\n\n     cd   \n     pwd\n     cp -v /etc/services testfile   \n     vim testfile\n\nAt this point we have the file on screen, and we are in \"normal mode\". Unlike `nano`, however, there’s no onscreen menu and it's not at all obvious how anything works!\n\nStart by pressing _Esc_ once or twice to ensure that we are in normal mode (remember this trick from above), then type `:q!` and press _Enter_. This quits without saving any changes - a _vital_ first skill when you don't yet know what you're doing!\nNow let's go in again and play around, seeing how powerful and dangerous `vim` is - then again, quit without saving:\n\n     vim testfile\n\nUse the keys _h_ _j_ _k_ and _l_ to move around (this is the traditional `vi` method) then try using the arrow keys - if these work, then feel free to use them - but remember those _hjkl_ keys because one day you may be on a system with just the traditional `vi` and the arrow keys won't work.\n\nNow play around moving through the file. Then exit with _Esc_  _Esc_  `:q!` as discussed earlier.\n\nNow that you've mastered that, lets get more advanced.\n\n     vim testfile\n\nThis time, move down a few lines into the file and press _3_ then _3_ again, then _d_ and _d_ again - and suddenly 33 lines of the file are deleted! \n\nWhy? Well, you are in normal mode and _33dd_ is a command that says \"delete 33 lines\". Now, you're still in normal mode, so press _u_ - and you've magically undone the last change you made. Neat huh?\n\nNow you know the three basic tricks for a newbie to `vim`:\n\n* _Esc_ _Esc_ always gets you back to \"normal mode\"\n* From normal mode  `:q!` will always quit without saving anything you've done, and\n* From normal mode `u` will undo the last action\n\nSo, here's some useful, productive things to do:\n\n* Finding things: From normal mode, type `G` to get to the bottom of the file, then `gg` to get to the top. Let's search for references to \"sun\", type `/sun` to find the first instance, then press _n_ repeatedly to step through all the next occurrences. Now go to the top of the file (_gg_ remember) and try searching for \"_Apple_\" or \"_Microsoft_\".\n* Cutting and pasting: Go back up to the top of the file (with _gg_) and look at the first few lines of comments (the ones with \"#\" as the first character).  Play around with cutting some of these out, and pasting them back. To do this simply position the cursor on a line, then (for example),  type _11dd_ to delete 11 lines, then immediately paste them back in by pressing _P_ - and then move down the file a bit and paste the same 11 lines in there again with _P_\n* Inserting text: Move anywhere in the file and press _i_ to get into \"insert mode\" (it may show at the bottom of the screen) and start typing - and _Esc_ _Esc_ to get back into normal mode when you're done.\n* Writing your changes to disk: From normal mode type `:w` to \"write\" but stay in `vim`, or `:wq` to “write and quit”.\n\nThis is as much as you ever _need_ to learn about `vi` - but there's an enormous amount more you _could_ learn if you had the time. Your next step should be to run `vimtutor` - this official tutorial should always be installed, and takes only 30 minutes.\n\nHowever, if you're serious about becoming a sysadmin, it's important that you _commit_ to using `vim` for all your editing from now on.\n\nOne last thing, you may see reference to _\"vi versus emacs\"_ . This is a long running argument for programmers, not system administrators - `vi/vim`  is what you need to learn.\n\n## WHY CAN'T I JUST STICK WITH NANO?\n\n* In many situations as a professional, you'll be working on other people's systems, and they're often very paranoid about stability. You may not have the authority to just \"sudo apt install <your.favorite.editor>\" - even if technically you could.\n\n* However, `vi` is always installed on any Unix or Linux box from tiny IoT devices to supercomputer clusters. It is actually required by the Single Unix Specification and POSIX.\n\n* And frankly it's a [shibboleth](https://en.wikipedia.org/wiki/Shibboleth) for Linux pros. As a newbie in an interview it's fine to say you're \"only a beginner with vi/vim\" - but very risky to say you hate it and can never remember how to exit.\n\nSo, it makes sense if you're aiming to do Linux professionally, but if you're just working on your own systems then by all means choose `nano` or `joe` etc.\n\n## POSTING YOUR PROGRESS\n\nLet the forum know how you went.\n\n## EXTENSION\n\nIf you're already familiar with `vi` / `vim` then use today's hour to research and test some customisation via your `~/.vimrc` file. The link below is specifically for sysadmins:\n\n* [Getting more out of Vim](https://www.linux.com/news/sysadmin-sysadmin-getting-more-out-vim)\n\n## RESOURCES\n\n* [Here is why `vim` uses the _hjkl_ keys as arrow keys](http://www.catonmat.net/blog/why-vim-uses-hjkl-as-arrow-keys/)\n* [Graphical vi-vim Cheat Sheet and Tutorial](http://www.viemu.com/a_vi_vim_graphical_cheat_sheet_tutorial.html)\n* [Vi - Vim Tutorial](http://www.youtube.com/watch?v=71YTkxUNwmg) (video)\n* [How to Copy, Cut and Paste in Vim / Vi](https://linuxize.com/post/how-to-copy-cut-paste-in-vim/)\n\n*Copyright 2012-2021 @snori74 (Steve Brorens). Can be reused under the terms of the Creative Commons Attribution 4.0 International Licence (CC BY 4.0).*\n"
        },
        {
          "name": "07.md",
          "type": "blob",
          "size": 4.4326171875,
          "content": "# Day 7 - Installing Apache\n\n## INTRO\n\nToday you'll install a common server application - the Apache2 web server - also known as *httpd* - the \"Hyper Text Transport Protocol Daemon\"!\n\nIf you’re a website professional then you might do things slightly differently, but our focus with this is not on Apache itself, or the website content, but to get a better understanding of:\n\n* application installation\n* configuration files\n* services\n* logs\n\n## TASKS\n\n* Refresh your list of available packages (apps) by: `sudo apt update` - this takes a moment or two, but ensures that you'll be getting the latest versions.\n* Install Apache from the repository with a simple:  `sudo apt install apache2`\n* Confirm that it’s running by browsing to _http://[external IP of your server]_  - where you should see a confirmation page.\n* Apache is installed as a \"service\" - a program that starts automatically when the server starts and keeps running whether anyone is logged in or not. Try stopping it with the command: `sudo systemctl stop apache2` - check that the webpage goes dead - then re-start it with `sudo systemctl start apache2` - and check its status with: `systemctl status apache2`.\n* As with the vast majority of Linux software, configuration is controlled by files under the _/etc_ directory - check the configuration files under `/etc/apache2`  especially `/etc/apache2/apache2.conf` - you can use `less` to simply view them, or the `vim` editor to view and edit as you wish.\n* In `/etc/apache2/apache2.conf` there's the line with the text: \"IncludeOptional conf-enabled/\\*.conf\". This tells Apache that the \\*.conf files in the subdirectory *conf-enabled* should be merged in with those from `/etc/apache2/apache2.conf` at load. This approach of lots of small specific config files is common.\n* If you're familiar with configuring web servers, then go crazy, setup some virtual hosts, or add in some mods etc.\n* The location of the default webpage is defined by the *DocumentRoot* parameter in the file `/etc/apache2/sites-enabled/000-default.conf`.\n* Use `less` or `vim` to view the code of the default page - normally at `/var/www/html/index.html`. This uses fairly complex modern web design - so you might like to browse to http://178.128.120.26/sample where you'll see a much simpler page. Use View Source in your browser to see the code of this, copy it, and then, in your ssh session `sudo vim /var/www/html/index.html` to first delete the existing content, then paste in this simple example - and then edit to your own taste. View the result with your workstation browser by again going to _http://[external IP of your server]_\n* As with most Linux services, Apache keeps its logs under the `/var/log` directory - look at the logs in `/var/log/apache2` - in the `access.log` file you should be able to see your session from when you browsed to the test page. Notice that there's an overwhelming amount of detail - this is typical, but in a later lesson you'll learn how to filter out just what you want. Notice the `error.log` file too - hopefully this one will be empty!\n\n## Posting your progress\n\nPractice your text-editing skills, and allow your \"classmates\" to judge your progress by editing `/var/www/html/index.html` with `vim` and posting the URL to access it to the forum. (It doesn’t have to be pretty!)\n\n## Security\n\n* As the sysadmin of this server, responsible for its security, you need to be very aware that you've now increased the \"attack surface\" of your server. In addition to *ssh* on port 22, you are now also exposing the *apache2* code on port 80. Over time the logs may reveal access from a wide range of visiting search engines, and attackers - and that’s perfectly normal.\n* If you run the commands: `sudo apt update`, then `sudo apt upgrade`, and accept the suggested upgrades, then you'll have all the latest security updates, and be secure enough for a test environment - but you should re-run this regularly.\n\n## EXTENSION\n\nRead up on:\n\n* [Using *systemctl* to manage services](https://www.digitalocean.com/community/tutorials/how-to-use-systemctl-to-manage-systemd-services-and-units)\n\n## RESOURCES\n\n* [HTTPD - Apache2 Web Server](https://ubuntu.com/server/docs/web-servers-apache)\n* [The Apache HTTP Server](http://docs.redhat.com/docs/en-US/Red_Hat_Enterprise_Linux/6/html/Deployment_Guide/ch-Web_Servers.html#s1-The_Apache_HTTP_Server)\n\n*Copyright 2012-2021 @snori74 (Steve Brorens). Can be reused under the terms of the Creative Commons Attribution 4.0 International Licence (CC BY 4.0).*\n"
        },
        {
          "name": "08.md",
          "type": "blob",
          "size": 4.078125,
          "content": "# Day 8 - the infamous \"grep\"...\n\n## INTRO\n\nYour server is now running two services: the *sshd* (Secure Shell Daemon) service that you use to login; and the Apache2 web server. Both of these services are generating logs as you and others access your server - and these are text files which we can analyse using some simple tools.\n\nPlain text files are a key part of \"the Unix way\" and there are many small \"tools\" to allow you to easily edit, sort, search and otherwise manipulate them. Today we’ll use `grep`, `cat`, `more`, `less`, `cut`, `awk` and `tail` to slice and dice your logs.\n\nThe `grep` command is famous for being extremely powerful and handy, but also because its \"nerdy\" name is typical of Unix/Linux conventions.\n\n## TASKS\n\n* Dump out the complete contents of a file with `cat` like this: `cat /var/log/apache2/access.log`\n* Use `less` to open the same file, like this: `less /var/log/apache2/access.log` - and move up and down through the file with your arrow keys, then use “q” to quit.\n* Again using `less`, look at a file, but practice confidently moving around using  *gg*, *GG* and */*,  *n* and *N* (to go to the top of the file, bottom of the file, to search for something and to hop to the next \"hit\" or back to the previous one)\n* View recent logins and `sudo` usage by viewing `/var/log/auth.log` with `less`\n* Look at just the tail end of the file with `tail /var/log/apache2/access.log` (yes, there's also a `head` command!)\n* Follow a log in real-time with: `tail -f /var/log/apache2/access.log`  (while accessing your server’s web page in a browser)\n* You can take the output of one command and \"pipe\" it in as the input to another by using the `|` (pipe) symbol\n* So, dump out a file with `cat`, but pipe that output to `grep` with a search term - like this: `cat /var/log/auth.log  | grep \"authenticating\"`\n* Simplify this to: `grep \"authenticating\" /var/log/auth.log`\n* Piping allows you to narrow your search, e.g.  `grep \"authenticating\" /var/log/auth.log | grep \"root\"`\n* Use the `cut` command to select out most interesting portions of each line by specifying \"-d\" (delimiter) and \"-f\" (field) - like: `grep \"authenticating\" /var/log/auth.log| grep \"root\"| cut -f 10- -d\" \"`   (field 10 onwards, where the delimiter between field is the \" \" character). This approach can be very useful in extracting useful information from log data.\n* Use the `-v` option to invert the selection and find attempts to login with other users: `grep \"authenticating\" /var/log/auth.log| grep -v \"root\"| cut -f 10- -d\" \"`\n\nThe output of any command can be \"redirected\" to a file with the \">\" operator. The command: `ls -ltr > listing.txt` wouldn't list the directory contents to your screen, but instead redirect into the file \"listing.txt\" (creating that file if it didn't exist, or overwriting the contents if it did).\n\n## POSTING YOUR PROGRESS\n\nRe-run the command to list all the IP's that have unsuccessfully tried to login to your server as *root* - but this time, use the the \">\" operator to redirect it to the file: `~/attackers.txt`. You might like to share and compare with others doing the course how heavily you're \"under attack\"!\n\n## EXTENSION\n\n* See if you can extend your filtering of `auth.log` to select just the IP addresses, then pipe this to  `sort`, and then further to `uniq` to get a list of all those IP addresses that have been \"auditing\" your server security for you.\n* Investigate the `awk` and `sed` commands. When you're having difficulty figuring out how to do something with `grep` and `cut`, then you may need to step up to using these. Googling for \"linux sed tricks\" or \"awk one liners\" will get you many examples.\n* Aim to learn at least one simple useful trick with both `awk` and `sed`\n\n## RESOURCES\n\n* [Text processing commands](https://www.youtube.com/watch?v=nLa6jAbULe8&t=97s)\n* [OSTechNix grep tutorial](https://www.ostechnix.com/the-grep-command-tutorial-with-examples-for-beginners/)\n* [Where GREP came from](https://www.youtube.com/watch?v=NTfOnGZUZDk)\n\n*Copyright 2012-2021 @snori74 (Steve Brorens). Can be reused under the terms of the Creative Commons Attribution 4.0 International Licence (CC BY 4.0).*\n"
        },
        {
          "name": "09.md",
          "type": "blob",
          "size": 6.7587890625,
          "content": "# Day 9 - Ports, open and closed\n\n## INTRO\n\nThe two services your server is now running are *sshd* for remote login, and *apache2* for web access. These are both \"open to the world\" via the TCP/IP “ports” - 22  and 80.\n\nAs a sysadmin, you need to understand what ports you have open on your servers because each open port is also a potential focus of attacks. You need to be be able to put in place appropriate monitoring and controls.\n\n## INSTRUCTIONS\n\nFirst we'll look at a couple of ways of determining what ports are open on your server:\n\n* `ss` - this, \"socket status\", is a standard utility - replacing the older `netstat`\n* `nmap` - this \"port scanner\" won't normally be installed by default\n\nThere are a wide range of options that can be used with *ss*, but first try: *ss -ltpn*\n\nThe output lines show which ports are open on which interfaces:\n\n    sudo ss -ltp\n    State   Recv-Q  Send-Q   Local Address:Port     Peer Address:Port  Process\n    LISTEN  0       4096     127.0.0.53%lo:53        0.0.0.0:*      users:((\"systemd-resolve\",pid=364,fd=13))\n    LISTEN  0       128            0.0.0.0:22           0.0.0.0:*      users:((\"sshd\",pid=625,fd=3))\n    LISTEN  0       128               [::]:22              [::]:*      users:((\"sshd\",pid=625,fd=4))\n    LISTEN  0       511                  *:80                *:*      users:((\"apache2\",pid=106630,fd=4),(\"apache2\",pid=106629,fd=4),(\"apache2\",pid=106627,fd=4))         \n\nThe network notation can be a little confusing, but the lines above show ports 80 and 22 open \"to the world\" on all local IP addresses - and port 53 (DNS) open only on a special local address.\n\nNow install `nmap` with `apt install`. This works rather differently, actively probing 1,000 or more ports to check whether they're open. It's most famously used to scan remote machines - please don't - but it's also very handy to check your own configuration, by scanning your server:\n\n    $ nmap localhost\n\n    Starting Nmap 5.21 ( http://nmap.org ) at 2013-03-17 02:18 UTC\n    Nmap scan report for localhost (127.0.0.1)\n    Host is up (0.00042s latency).\n    Not shown: 998 closed ports\n    PORT   STATE SERVICE\n    22/tcp open  ssh\n    80/tcp open  http\n\n    Nmap done: 1 IP address (1 host up) scanned in 0.08 seconds\n\nPort 22 is providing the *ssh* service, which is how you're connected, so that will be open. If you have Apache running then port 80/http will also be open. Every open port is an increase in the \"attack surface\", so it's Best Practice to shut down services that you don't need.\n\nNote that however that \"localhost\" (127.0.0.1), is the loopback network device. Services \"bound\" _only_ to this will only be available on this local machine. To see what's actually exposed to others, first use the `ip a` command to find the IP address of your actual network card, and then `nmap` that.\n\n## Host firewall\n\nThe Linux kernel has built-in firewall functionality called \"netfilter\". We configure and query this via various utilities,  the most low-level of which are the `iptables` command, and the newer `nftables`. These are powerful, but also complex - so we'll use a more friendly alternative - `ufw` - the \"uncomplicated firewall\".\n\nFirst let's list what rules are in place by typing `sudo iptables -L`\n\nYou will see something like this:\n\n    Chain INPUT (policy ACCEPT)\n    target  prot opt source             destination\n\n    Chain FORWARD (policy ACCEPT)\n    target  prot opt source             destination\n\n    Chain OUTPUT (policy ACCEPT)\n    target  prot opt source             destination\n\nSo, essentially no firewalling - any traffic is accepted to anywhere.\n\nUsing `ufw` is very simple. First we need to install it with:\n\n    sudo apt install ufw\n\nThen, to allow SSH, but disallow HTTP we would type:\n\n    sudo ufw allow ssh\n    sudo ufw deny http\n\n(BEWARE - do _not_ “deny” ssh, or you’ll lose all contact with your server!)\n\nand then enable this with:\n\n    sudo ufw enable\n\nTyping `sudo iptables -L` now will list the detailed rules generated by this - one of these should now be:\n\n    “DROP       tcp  --  anywhere             anywhere             tcp dpt:http” \n\nThe effect of this is that although your server is still running Apache, it's no longer accessible from the \"outside\" - all incoming traffic to the destination port of http/80 being DROPed. Test for yourself! You will probably want to reverse this with:\n\n    sudo ufw allow http\n    sudo ufw enable\n\nIn practice, ensuring that you're not running unnecessary services is often enough protection, and a host-based firewall is unnecessary, but this very much depends on the type of server you are configuring. Regardless, hopefully this session has given you some insight into the concepts.\n\nBTW: For this test/learning server you should allow http/80 access again now, because those `access.log` files will give you a real feel for what it's like to run a server in a hostile world.\n\n## Using non-standard ports\n\nOccasionally it may be reasonable to re-configure a service so that it’s provided on a non-standard port - this is particularly common advice for *ssh/22* - and would be done by altering the configuration in `/etc/ssh/sshd_config`\n\nSome call this “security by obscurity” - equivalent to moving the keyhole on your front door to an unusual place rather than improving the lock itself, or camouflaging your tank rather than improving its armour - but it *does* effectively eliminate attacks by opportunistic hackers, which is the main threat for most servers.\n\n## POSTING YOUR PROGRESS\n\n* As always, feel free to post your progress, or questions, to the forum.\n\n## EXTENSION\n\nEven after denying access, it might be useful to know who's been *trying* to gain entry. Check out these discussions of logging and more complex setups:\n\n* [How to Log Linux IPTables Firewall Dropped Packets to a Log File](http://www.thegeekstuff.com/2012/08/iptables-log-packets/)\n* [Firewalling with iptables - One approach](http://www.pettingers.org/code/firewall.html)\n\n## RESOURCES\n\n* [12 ss Command Examples to Monitor Network Connections](https://www.tecmint.com/ss-command-examples-in-linux/)\n* [UFW - Uncomplicated Firewall](https://help.ubuntu.com/community/UFW)\n* [Collection of basic Linux Firewall iptables rules](http://linuxconfig.org/collection-of-basic-linux-firewall-iptables-rules)\n* [10 Netstat Command Example](http://www.thegeekstuff.com/2010/03/netstat-command-examples/)\n* [UFW Uncomplicated Firewall](http://www.youtube.com/watch?v=nc3A5Dy4xE0&feature=relmfu) (video)\n* [How to install nftables in Ubuntu](https://www.liquidweb.com/kb/how-to-install-nftables-in-ubuntu/)\n* [No, moving your ssh port isn't security by obscurity](https://danielmiessler.com/blog/no-moving-your-ssh-port-isnt-security-by-obscurity/)\n\n*Copyright 2012-2021 @snori74 (Steve Brorens). Can be reused under the terms of the Creative Commons Attribution 4.0 International Licence (CC BY 4.0).*\n"
        },
        {
          "name": "10.md",
          "type": "blob",
          "size": 3.33203125,
          "content": "# Day 10 - Getting the computer to do your work for you\n\n## INTRO\n\nLinux has a rich set of features for running scheduled tasks. One of the key attributes of a good sysadmin is getting the computer to do your work for you (sometimes misrepresented as laziness!) -  and a well configured set of scheduled tasks is key to keeping your server running well.\n\n## CRON\n\nEach user potentially has their own set of scheduled task which can be listed with the `crontab` command (list out your user crontab entry with `crontab -l` and then that for *root* with `sudo crontab -l` ).\n\nHowever, there’s also a system-wide crontab defined in `/etc/crontab` - use `less` to look at this. Here's example, along with an explanation:\n\n\tSHELL=/bin/sh\n\tPATH=/usr/local/sbin:/usr/local/bin:/sbin:/bin:/usr/sbin:/usr/bin\n\n\t# m h dom mon dow user  command\n\t17 *\t* * *   root\tcd / && run-parts --report /etc/cron.hourly\n\t25 6\t* * *   root\ttest -x /usr/sbin/anacron || ( cd / && run-parts --report /etc/cron.daily )\n\t47 6\t* * 7   root\ttest -x /usr/sbin/anacron || ( cd / && run-parts --report /etc/cron.weekly )\n\t52 6\t1 * *   root\ttest -x /usr/sbin/anacron || ( cd / && run-parts --report /etc/cron.monthly )\n\nLines beginning with \"#\" are comments, so `# m h dom mon dow user  command` defines the meanings of the columns.\n\nAlthough the detail is a bit complex, it's pretty clear what this does. The first line says that at 17mins after every hour, on every day, the credential for \"root\" will be used to run any scripts in the `/etc/cron.hourly` folder - and similar logic kicks off daily, weekly and monthly scripts. This is a tidy way to organise things, and many Linux distributions use this approach. It does mean we have to look in those `/etc/cron.*` folders to see what’s actually scheduled.\n\nOn your system type: `ls  /etc/cron.daily` - you'll see something like this:\n\n\t$ ls /etc/cron.daily\n\tapache2  apt  aptitude  bsdmainutils  locate  logrotate  man-db  mlocate  standard  sysklog\n\nEach of these files is a script or a shortcut to a script to do some regular task, and they're run in alphabetic order by `run-parts`. So in this case *apache2* will run first. Use `less` to view some of the scripts on your system - many will look very complex and are best left well alone, but others may be just a few lines of simple commands.\n\nLook at the articles in the resources section - you should be aware of `at` and `anacron` but are not likely to use them in a server.\n\nGoogle for \"logrotate\", and then look at the logs in your own server to see how they've been \"rotated\".\n\n## SYSTEMD TIMERS\n\nAll major Linux distributions now include \"systemd\". As well as starting and stopping services, this can *also* be used to run tasks at specific times via \"timers\". See which ones are already configured on your server with:\n\n`systemctl list-timers`\n\nUse the links in the RESOURCES section to read up about how these timers work.\n\n## RESOURCES\n\n* [Job scheduling with \"cron\" and \"at\"](http://www.ibm.com/developerworks/linux/library/l-job-scheduling/index.html)\n* [A good overview of systemd/Timers](https://wiki.archlinux.org/index.php/Systemd/Timers)\n* [\"How to Use Systemd Timers as a Cron Replacement\"](https://www.maketecheasier.com/use-systemd-timers-as-cron-replacement/)\n\n*Copyright 2012-2021 @snori74 (Steve Brorens). Can be reused under the terms of the Creative Commons Attribution 4.0 International Licence (CC BY 4.0).*\n"
        },
        {
          "name": "11.md",
          "type": "blob",
          "size": 4.4150390625,
          "content": "# Day 11 - Finding things...\n\n## INTRO\n\nToday we’ll look at how you find files, and text inside these files, quickly and efficiently. \n\nIt can be very frustrating to know that a file or setting exists, but not be able to track it down! Master today’s commands and you’ll be much more confident as you administer your systems. \n\nToday you’ll look at four useful tools:\n\n* `locate`\n* `find`\n* `grep`\n* `which`\n\n## INSTRUCTIONS\n\n### _locate_\n\nIf you're looking for a file called `access.log` then the quickest approach is to use \"locate\" like this:\n\n\t$ locate access.log\n\t/var/log/apache2/access.log\n\t/var/log/apache2/access.log.1\n\t/var/log/apache2/access.log.2.gz\n\n(If `locate` is not installed, do so with `sudo apt install mlocate`)\n\nAs you can see, by default it treats a search for _\"something\"_ as a search for _\"\\*something\\*\"_. It’s very fast because it searches an index, but if this index is out of date or missing it may not give you the answer you’re looking for.  This is because the index is created by the `updatedb` command - typically run only nightly by `cron`.  It may therefore be out of date for recently added files, so it can be worthwhile updating the index by manually running: `sudo updatedb`.\n\n### _find_\n\nThe `find` command searches down through a directory structure looking for files which match some criteria - which could be name, but also size, or when last updated etc. Try these examples:\n\n\tfind /var -name access.log\n\tfind /home -mtime -3\n\nThe first searches for files with the name \"access.log\", the second for any file under `/home` with a last-modified date in the last 3 days.\n\nThese will take longer than `locate` did because they search through the filesystem directly rather from an index. Also, because `find` uses the permissions of the logged-in user you’ll get “permission denied” messages for many directories if you search the whole system. Starting the command with `sudo` of course will run it as *root* - or you could filter the errors with `grep` like this: `find /var -name access.log 2>&1 | grep -vi \"Permission denied\"`.\n\nThese examples are just the tip of a very large iceberg, check the articles in the RESOURCES section and work through as many examples as you can - time spent getting really comfortable with `find` is not wasted.\n\n### _grep -R_\n\nRather than asking \"grep\" to search for text within a specific file, you can give it a whole directory structure, and ask it to recursively search down through it, including following all symbolic links (which `-r` does not).\nThis trick is particularly handy when you \"just know\" that an item appears \"somewhere\" - but are not sure where.\n\nAs an example, you know that “PermitRootLogin” is an ssh parameter in a config file somewhere under /etc, but can’t recall exactly where it is kept:\n\n `grep -R -i \"PermitRootLogin\" /etc/*`\n\nBecause this only works on plain text files, it's most useful for the `/etc` and `/var/log` folders. (Notice the `-i` which makes the search “case insensitive”, finding the setting even if it’s been entered as “Permitrootlogin”\n\nYou may now have logs like `/var/log/access.log.2.gz` - these are older logs that have been compressed to save disk space - so you can't read them with `less`, or search them with `grep`. However, there are `zless` and `zgrep`, which do work, and on ordinary as well as compressed files.\n\n### _which_\n\nIt's sometimes useful to know where a command is being run from. If you type `nano`, and it starts, where is the `nano` binary coming from? The general rule is that the system will search through the locations setup in your \"path\". To see this type:\n\n`echo $PATH`\n\nTo see where `nano` comes from, type:\n\n`which nano`\n\nTry this for `grep`, `vi` and `service` and `reboot`. You'll notice that they’re typically always in subfolders named `bin`, but that there are several different ones.\n\n## EXTENSION\n\nThe \"-exec\" feature of the \"find\" command is extremely powerful. Test some examples of this from the RESOURCES links.\n\n## RESOURCES\n\n* [25 find command examples...](https://www.linuxtechi.com/25-find-command-examples-for-linux-beginners/)\n* [10 Tips for using \"find\"](https://www.linux.com/tutorials/10-tips-using-gnu-find/)\n* [Five simple recipes for \"grep\"](http://arstechnica.com/open-source/news/2009/05/command-line-made-easy-five-simple-recipes-for-grep.ars)\n\n*Copyright 2012-2021 @snori74 (Steve Brorens). Can be reused under the terms of the Creative Commons Attribution 4.0 International Licence (CC BY 4.0).*\n"
        },
        {
          "name": "12.md",
          "type": "blob",
          "size": 4.708984375,
          "content": "# Day 12 - Copying with SFTP\n\n## INTRO\n\nYou've now had a working Internet server of your own for some time, and seen how you can create and edit small files there. You've created a web server where you've been able to edit a simple web page.\n\nToday we'll be looking at how you can move files between your other systems and this server - tasks like:\n\n* Taking a copy of some files from your server onto your desktop machine\n* Copying up some text to your server to put on your webpage\n* Uploading some photos and logos for your webpage\n\n## PROTOCOLS\n\nThere are a wide range of ways a Linux server can share files, including:\n\n* SMB: Microsoft's file sharing, useful on a local network of Windows machines\n* AFP: Apple’s file sharing, useful on a local network of Apple machines\n* WebDAV: Sharing over web (http) protocols\n* FTP: Traditional Internet sharing protocol\n* scp: Simple support for copying files\n* rsync: Fast, very efficient file copying\n* SFTP: file access and copying over the SSH protocol (Despite the name, the SFTP protocol at a technical level is completely unrelated to traditional FTP)\n\nEach of these have their place, but for copying files back and forth from your local desktop to your server, SFTP has a number of key advantages:\n\n* No extra setup is required on your server\n* Top quality security\n* Allows browsing through the directory structure\n* You can create and delete folders\n\nIf you’re successfully logging in via _ssh_ from your home, work or a cybercafe then you'll also be able to use SFTP from this same location because the same underlying protocol is being used.\n\nBy contrast, setting up your server for any of the other protocols will require extra work. Not only that, enabling extra protocols also increases the \"attack surface\" - and there's always a chance that you’ll mis-configure something in a way that allows an attacker in. It's also very likely that restrictive firewall policies at a workplace will interfere with or block these protocols. Finally, while old-style FTP is still very commonly used, it sends login credentials \"in clear\", so that your flatmates, cafe buddies or employer may be able to grab them off the network by \"packet sniffing\". Not a big issue with your \"classroom\" server - but it's an unacceptable risk if you're remotely administering production servers.\n\n## SFTP client software\n\nWhat’s required to use SFTP is some client software. A command-line client (unsurprisingly called _sftp_) comes standard on every Apple OSX or Linux system. If you're using a Linux desktop, you also have a built-in GUI client via your file manager. This will allow you to easily attach to remote servers via SFTP. (For the Nautilus file manager for example, press ctrl + L to bring up the 'location window\" and type: _sftp://username@myserver-address_).\n\nAlthough Windows and Apple macOS have no built-in GUI client there are  a wide range of third-party options available, both free and commercial. If you don't already have such a client installed, then choose one such as:\n\n* WinSCP or FileZilla  - for Windows users\n* CyberDuck or FileZilla  - for macOS users\n\nDownload locations are under the RESOURCES section.\n\nConfiguring and using your choice of these should be straightforward. The only real potential for confusion is that these clients generally support a wide range of protocols such as scp and FTP that we're not going to use. When you're asked for SERVER, give your server's IP address, PORT will be 22, and PROTOCOL will be SFTP or SSH.\n\n## INSTRUCTIONS\n\n* Configure your chosen SFTP client to login to your server as your username\n* Copy some files from your server down to your local desktop (try files from your \"home\" folder, and from `/var/log`)\n* Create an \"`images`\" folder under your \"home\" folder on the server, and upload some images to it from your desktop machine\n* Go up to the root directory. You should see `/etc`, `/bin` and other folders. Try to create an \"`images`\" folder here too - this should fail because you are logging in as an ordinary use, so you won't have permission to create new files or folders. In your own \"home\" directory you of course have full permission.\n\nOnce the files are uploaded you can login via _ssh_ and use `sudo` to give yourself the necessary power to move files about.\n\n## POSTING YOUR PROGRESS\n\n* Post a note to the forum.\n\n## RESOURCES\n\n* [CyberDuck](http://cyberduck.io/)\n* [FileZilla](http://filezilla-project.org/download.php?type=client)\n* [SFTP – SSH Secure File Transfer Program](https://www.ssh.com/ssh/sftp/)\n* [sftp File From One Server To Another](http://www.cyberciti.biz/faq/sftp-file-from-server-to-another-in-unix-linux/)\n\n*Copyright 2012-2021 @snori74 (Steve Brorens). Can be reused under the terms of the Creative Commons Attribution 4.0 International Licence (CC BY 4.0).*\n"
        },
        {
          "name": "13.md",
          "type": "blob",
          "size": 5.41796875,
          "content": "# Day 13 -  Who has permission?\n\n## INTRO\n\nFiles on a Linux system always have associated \"permissions\" - controlling who has access and what sort of access. You'll have bumped into this in various ways already - as an example, yesterday while logged in as your \"ordinary\" user, you could not upload files directly into _/var/www_ or create a new folder at _/_.\n\nThe Linux permission system is quite simple, but it does have some quirky and subtle aspects, so today is simply an introduction to some of the basic concepts.\n\nThis time you really _do_ need to work your way through the material in the RESOURCES section!\n\n## OWNERSHIP\n\nFirst let's look at \"ownership\". All files are tagged with both the name of the user and the group that owns them, so if we type \"ls -l\" and see a file listing like this:\n\n\t-rw------- \t1 steve  staff  \t4478979  6 Feb  2011 private.txt\n\t-rw-rw-r-- \t1 steve  staff  \t4478979  6 Feb  2011 press.txt\n\t-rwxr-xr-x \t1 steve  staff  \t4478979  6 Feb  2011 upload.bin\n\nThen these files are owned by user \"steve\", and the group \"staff\".\n\n## PERMISSIONS\n\nLooking at the '-rw-r--r--\" at the start of a directory listing line, (ignore the first \"-\" for now), and see these as potentially three groups of \"rwx\": the permission granted to the user who owns the file, the \"group\", and \"other people\".\n\nFor the example list above:\n\n* _private.txt_   - Steve has \"rw\" (ie Read and Write) permission, but neither the group \"staff\" nor \"other people\" have any permission at all\n* _press.txt_  - Steve can Read and Write to this file too, but so can any member of the group \"staff\"  - and _anyone_ can read it\n* _upload.bin_  - Steve can write to the file, all others can read it. Additionally all can \"execute\" the file - ie run this program\n\nYou can change the permissions on any file with the `chmod` utility. Create a simple text file in your home directory with `vim` (e.g. _tuesday.txt_) and check that you can list its contents by typing: `cat tuesday.txt` or `less tuesday.txt`.\n\nNow look at its permissions by doing: `ls -ltr tuesday.txt`\n\n\t-rw-rw-r-- 1 ubuntu ubuntu   12 Nov 19 14:48 tuesday.txt\n\nSo, the file is owned by the user \"ubuntu\", and group \"ubuntu\", who are the only ones that can write to the file - but any other user can read it.\n\nNow let’s remove the permission of the user and \"ubuntu\" group to write their own file:\n\n`chmod u-w tuesday.txt`\n\n`chmod g-w tuesday.txt`\n\n...and remove the permission for \"others\" to read the file:\n\n`chmod o-r tuesday.txt`\n\nDo a listing to check the result:\n\n\t-r--r----- 1 ubuntu ubuntu   12 Nov 19 14:48 tuesday.txt\n\n...and confirm by trying to edit the file with `nano` or `vim`. You'll find that you appear to be able to edit it - but can't save any changes. (In this case, as the owner, you have \"permission to override permissions\", so can can write with `:w!`). You can of course easily give yourself back the permission to write to the file by:\n\n`chmod u+w tuesday.txt`\n\n## GROUPS\n\nOn most modern Linux systems there is a group created for each user, so user \"ubuntu\" is a member of the group \"ubuntu\". However, groups can be added as required, and users added to several groups.\n\nTo see what groups you're a member of, simply type: `groups`\n\nOn an Ubuntu system the first user created (in your case `ubuntu`), should be a member of the groups: `ubuntu`, `sudo` and `adm` - and if you list the `/var/log` folder you'll see your membership of the `adm` group is why you can use `less` to read and view the contents of `/var/log/auth.log`\n\nThe \"root\" user can add a user to an existing group with the command:\n\n`usermod -a -G group user`\n\nso your `ubuntu` user can do the same simply by prefixing the command with `sudo`. For example, you could add a new user `fred` like this:\n\n`adduser fred`\n\nBecause this user is not the first user created, they don't have the power to run `sudo` - which _your_ user has by being a member of the group `sudo`.\n\nSo, to check which groups `fred` is a member of, first \"become fred\" - like this:\n\n`sudo su fred`\n\nThen:\n\n`groups`\n\nNow  type \"exit\" to return to your normal user, and you can add `fred` to this group with:\n\n`sudo usermod -a -G sudo fred`\n\nAnd of course, you should then check by \"becoming fred\" again and running the `groups` command.\n\n## POSTING YOUR PROGRESS\n\nJust for fun, create a file: _secret.txt_ in your home folder, take away all permissions from it for the user, group and others - and see what happens when you try to edit it with `vim`.\n\n## EXTENSION\n\nResearch:\n\n* `umask` and test to see how it's setup on your server\n* the classic _octal_ mode of describing and setting file permissions. (e.g. `chmod 664 myfile`)\n\nLook into Linux ACLs:\n\n* [How to manage ACLs on Linux](https://linuxconfig.org/how-to-manage-acls-on-linux)\n* [Linux Access Control Lists](https://www.redhat.com/sysadmin/linux-access-control-lists)\n\nAlso, SELinux and AppArmour:\n\n* [SELinux – development, architecture and operating principles](https://www.ibm.com/developerworks/library/l-secure-linux-ru/)\n* [SELinux For Mere Mortals](https://craigmbooth.com/blog/selinux-for-mortals/)\n* [Securing Ubuntu 18 04 with Apparmor](https://www.youtube.com/watch?v=lJFxexGZ-DY)\n\n## RESOURCES\n\n* [File Security](http://tldp.org/LDP/intro-linux/html/sect_03_04.html)\n* [chmod Tutorial](http://catcode.com/teachmod/)\n* [File and Directory Permissions](http://www.youtube.com/watch?v=vKTg1ATHl4E)\n\n*Copyright 2012-2021 @snori74 (Steve Brorens). Can be reused under the terms of the Creative Commons Attribution 4.0 International Licence (CC BY 4.0).*\n"
        },
        {
          "name": "14.md",
          "type": "blob",
          "size": 4.79296875,
          "content": "# Day 14 - Your little helper...\n\n## INTRO\n\nToday you're going to set-up another user on your system. You're going to imagine that this is a help-desk person that you trust to do just a few simple tasks:\n\n* check that the system is running\n* check disk space with: `df -h`\n\n...but you also want them to be able to reboot the system, because you believe that \"turning it off and on again\" resolves most problems :-)\n\nYou'll be covering a several new areas, so have fun!\n\n## ADDING A USER\nChoose a name for your new user - we'll use \"helen\" in the examples, so to add this new user:\n\n`sudo adduser helen`\n\n(Names are case-sensitive in Linux, so \"Helen\" would be a completely different user)\n\nThe \"adduser\" command works very slightly differently in each distro - if it didn't ask you for a password for your new user, then set it manually now by:\n\n`sudo passwd helen`\n\nYou will now have a new entry in the simple text database of users: `/etc/passwd` (check it out with: `less`), and a group of the same name in the file: `/etc/group`. A hash of the password for the user is in: `/etc/shadow` (you can read this too if you use \"sudo\" - check the permissions to see how they're set. For obvious reasons it's not readable to just everyone). \n\nIf you're used to other operating systems it may be hard to believe, but these simple text files are the whole Linux user database and you could even create your users and groups by directly editing these files - although this isn’t normally recommended.\n\nAdditionally, `adduser` will have created a home directory, `/home/helen` for example, with the correct permissions.\n\nLogin as your new user to confirm that everything works. Now while logged in as this user try to run `reboot` - then `sudo reboot`.\n\n## CLEVER SUDO TRICKS\n\nYour new user is just an ordinary user and so can't use `sudo` to run commands with elevated privileges - until we set them up. We could simply add them to a group that's pre-defined to be able to use sudo to do _anything_ as root - but we don't want to give \"helen\" quite that amount of power.\n\nUse `ls -l` to look at the permissions for the file: `/etc/sudoers`  This is where the magic is defined, and you'll see that it's tightly controlled, but you should be able to view it with: `sudo less /etc/sudoers`  You want to add a new entry in there for your new user, and for this you need to run a special utility: `visudo`\n\nTo run this, you can temporarily \"become root\" by running:\n\n`sudo -i`\n\nNotice that your prompt has changed to a \"#\" \n\nNow simply run  `visudo` to begin editing `/etc/sudoers` - typically this will use `nano`.\n\nAll lines in `/etc/sudoers` beginning with \"#\" are optional comments. You'll want to add some lines like this:\n\n\t# Allow user \"helen\" to run \"sudo reboot\"\n\t# ...and don't prompt for a password\n\t#\n\thelen ALL = NOPASSWD:/sbin/reboot\n\nYou can add these line in wherever seems reasonable. The `visudo` command will automatically check your syntax, and won't allow you to save if there are mistakes - because a  corrupt sudoers file could lock you out of your server!\n\nType `exit` to remove your magic hat and become your normal user again - and notice that your prompt reverts to: $\n\n## TESTING\n\nTest by logging in as your test user and typing: `sudo reboot`\nNote that you can \"become\" helen by:\n\n`sudo su helen`\n\nIf your ssh config allows login only with public keys, you'll need to setup `/home/helen/.ssh/authorized_keys` - including getting the owner and permissions correct. A little challenge of your understanding of this area!\n\n## EXTENSION\n\nIf you find this all pretty familiar, then you might like to check and update your knowledge on a couple of related areas:\n\n* [Restricting shell access](http://www.cyberciti.biz/tips/howto-linux-shell-restricting-access.html)\n* [Linux Password & Shadow File Formats](https://www.tldp.org/LDP/lame/LAME/linux-admin-made-easy/shadow-file-formats.html))\n* [What's the difference between 'useradd' and 'adduser'?](https://serverfault.com/questions/218993/whats-the-difference-between-useradd-and-adduser)\n* [How to create users and groups in Linux from the command line](https://www.techrepublic.com/article/how-to-create-users-and-groups-in-linux-from-the-command-line/)\n* [Learn how to use the $EDITOR environmental variable to set your default editor to `vim`](https://www.a2hosting.com/kb/developer-corner/linux/setting-the-default-text-editor-in-linux). With this done, ''visudo'' will use ''vim'' rather than ''nano'' for editing.\n\n## RESOURCES\n\n* [Sudo – An Advanced Howto](https://centoshelp.org/security/sudo-an-advanced-howto/)\n* [A cartoon that should now make sense!](http://xkcd.com/149/ )\n* [Basic Linux Permissions: sudo and sudoers](http://www.youtube.com/watch?v=YSSIm0g00m4)   (video)\n\n*Copyright 2012-2021 @snori74 (Steve Brorens). Can be reused under the terms of the Creative Commons Attribution 4.0 International Licence (CC BY 4.0).*\n"
        },
        {
          "name": "15.md",
          "type": "blob",
          "size": 6.5849609375,
          "content": "# Day 15 - Deeper into repositories...\n\n## INTRO\n\nEarly on you installed some software packages to your server using `apt install`. That was fairly painless, and we explained how the Linux model of software installation is very similar to how \"app stores\" work on Android, iPhone, and increasingly in MacOS and Windows.\n\nToday however, you'll be looking \"under the covers\" to see how this works; better understand the advantages (and disadvantages!) - and to see how you can safely extend the system beyond the main official sources.\n\n## REPOSITORIES AND VERSIONS\n\nAny particular Linux installation has a number of important characteristics:\n\n* Version - e.g. Ubuntu 20.04, CentOS 5, RHEL 6\n* \"Bit size\"  - 32-bit or 64-bit\n* Chip - Intel, AMD, PowerPC, ARM\n\nThe version number is particularly important because it controls the versions of application that you can install. When Ubuntu 18.04 was released (in April 2018 - hence the version number!), it came out with Apache 2.4.29. So, if your server runs 18.04, then even if you installed Apache with `apt` five years later that is still the version you would receive. This provides stability, but at an obvious cost for web designers who hanker after some feature which later versions provide. (Security patches _are_ made to the repositories, but by \"backporting\" security fixes from later versions into the old stable version that was first shipped).\n\n## WHERE IS ALL THIS SETUP?\n\nWe'll be discussing the \"package manager\" used by the Debian and Ubuntu distributions, and dozens of derivatives. This uses the `apt` command, but for most purposes the competing `yum` and `dnf` commands used by Fedora, RHEL, CentOS and Scientific Linux work in a very similar way - as do the equivalent utilities in  other versions.\n\nThe configuration is done with files under the _/etc/apt_ directory, and to see where the packages you install are coming from, use `less` to view _/etc/apt/sources.list_ where you'll see lines that are clearly specifying URLs to a “repository” for your specific version:\n\n     deb http://archive.ubuntu.com/ubuntu precise-security main restricted universe\n\nThere's no need to be concerned with the exact syntax of this for now, but what’s fairly common is to want to add extra repositories - and this is what we'll deal with next.\n\n## EXTRA REPOSITORIES\n\nWhile there's an amazing amount of software available in the \"standard\" repositories (more than 3,000 for CentOS and ten times that number for Ubuntu), there are often packages not available - typically for one of two reasons:\n\n* Stability   -   CentOS is based on RHEL (Red Hat Enterprise Linux), which is firmly focussed on stability in large commercial server installations, so games and many minor packages are not included\n* Ideology   -   Ubuntu and Debian have a strong \"software freedom\" ethic (this refers to freedom, not price), which means that certain packages you may need are unavailable by default\n\nSo, next you’ll adding an extra repository to your system, and install software from it.\n\n## ENABLING EXTRA REPOSITORIES\n\nFirst do a quick check to see how many packages you *could* already install. You can get the full list and details by running:\n\n`apt-cache dump`\n\n...but you'll want to press Ctrl-c a few times to stop that, as it's far too long-winded.\n\nInstead, filter out just the packages names using `grep`, and count them using: `wc -l` (`wc` is \"word count\", and the \"-l\" makes it count lines rather than words) - like this:\n\n`apt-cache dump | grep \"Package:\" | wc -l`\n\nThese are all the packages you could now install. Sometimes there are extra packages available in if you enable extra repositories. Most Linux distros have a similar concept, but in Ubuntu, often the \"Universe\" and \"Multiverse\" repositories are disabled by default. These are hosted at Ubuntu, but with less support, and Multiverse: _\"contains software which has been classified as non-free ...may not include security updates\"_. Examples of useful tools in Multiverse might include the compression utilities `rar` and `lha`, and the network performance tool `netperf`.\n\nTo enable the \"Multiverse\" repository, follow the guide at:\n\n* [Community wiki for command line](https://help.ubuntu.com/community/Repositories/CommandLine)\n\nAfter adding this, update your local cache of available applications:\n\n`sudo apt update`\n\nOnce done, you should be able to install `netperf` like this:\n\n`sudo apt install netperf`\n\n...and the output will show that it's coming from Multiverse.\n\n## EXTENSION - Ubuntu PPAs\n\nUbuntu also allows users to register an account and setup software in a Personal Package Archive (PPA) - typically these are setup by enthusiastic developers, and allow you to install the latest \"cutting edge\" software.\n\nAs an example, install and run the `neofetch` utility. When run, this prints out a summary of your configuration and hardware.\nThis is in the standard repositories, and `neofetch --version` will show the version. If for some reason you wanted to be have a later version you could install a developer's Neofetch PPA to your software sources by:\n\n`sudo add-apt-repository ppa:dawidd0811/neofetch`\n\nAs always, after adding a repository, update your local cache of available applications:\n\n`sudo apt update`\n\nThen install the package with:\n\n`sudo apt install neofetch`\n\nCheck with `neofetch --version` to see what version you have now.\n\nWhen you next run \"sudo apt upgrade\" you'll likely be prompted to install a new version of `neofetch` - because the developers are sometimes literally making changes every day. (And if it's not obvious, when the developers have a bad day your software will stop working until they make a fix - that's the real \"cutting edge\"!)\n\n## SUMMARY\n\nInstalling only from the default repositories is clearly the safest, but there are often good reasons for going beyond them. As a sysadmin you need to judge the risks, but in the example we came up with a realistic scenario where connecting to an unstable working developer’s version made sense.\n\nAs general rule however you:\n\n* Will seldom have good reasons for hooking into more than one or two extra repositories\n* Need to read up about a repository first, to understand any potential disadvantages.\n\n## RESOURCES\n\n* [Package management command comparison](https://wiki.archlinux.org/index.php/Pacman/Rosetta)\n* [How to use yum - Introduction](http://fedoranews.org/tchung/howto/2003-11-09-yum-intro.shtml)\n* [Package management with APT](https://help.ubuntu.com/community/AptGet/Howto)\n* [What do you mean by Free Software?](http://www.debian.org/intro/free)\n\n*Copyright 2012-2021 @snori74 (Steve Brorens). Can be reused under the terms of the Creative Commons Attribution 4.0 International Licence (CC BY 4.0).*\n"
        },
        {
          "name": "16.md",
          "type": "blob",
          "size": 3.0615234375,
          "content": "# Day 16 - 'tar' and friends...\n\n## INTRO\n\nAs a system administrator, you need to be able to confidently work with compressed “archives” of files. In particular two of your key responsibilities; installing new software, and managing backups, often require this.\n\n## CREATING ARCHIVES\n\nOn other operating systems, applications like WinZip, and pkzip before it, have long been used to gather a series of files and folders into one compressed file - with a .zip extension. Linux takes a slightly different approach, with the \"gathering\" of files and folders done in one step, and the compression in another.\n\nSo, you could create a \"snapshot\" of the current files in your _/etc/init.d_ folder like this:\n\n`tar  -cvf  myinits.tar  /etc/init.d/`\n\nThis creates _myinits.tar_ in your current directory.\n\nNote 1: The `-v` switch  (verbose) is included to give some feedback - traditionally many utilities provide no feedback unless they fail.\nNote 2: The `-f` switch specifies that _“the output should go to the filename which follows”_ - so in this case the order of the switches is important.\n\n(The cryptic “tar” name? - originally short for \"tape archive\")\n\nYou could then compress this file with GnuZip like this:\n\n`gzip myinits.tar`\n\n...which will create `myinits.tar.gz`. A compressed tar archive like this is known as a \"tarball\". You will also sometimes see tarballs with a  _.tgz_ extension - at the Linux commandline this doesn't have any meaning to the system, but is simply helpful to humans.\n\nIn practice you can do the two steps in one with the \"-z\" switch, like this:\n\n`tar -cvzf myinits.tgz /etc/init.d/`\n\nThis uses the `-c` switch to say that we're creating an archive; `-v` to make the command \"verbose\"; `-z` to compress the result - and `-f` to specify the output file.\n\n## TASKS FOR TODAY\n\n* Check the links under \"Resources\" to better understand this - and to find out how to extract files from an archive!\n* Use `tar` to create an archive copy of some files and check the resulting size\n* Run the same command, but this time use `-z` to compress - and check the file size\n* Copy your archives to _/tmp_ (with: `cp`) and extract each there to test that it works\n\n\n## POSTING YOUR PROGRESS\n\nNothing to post today - but make sure you understand this stuff, because we'll be using it for real in the next day's session!\n\n## EXTENSION\n\n* What is a .bz2 file - and how would you extract the files from it?\n* Research how absolute and relative paths are handled in tar - and why you need to be careful extracting from archives when logged in as root\n* You might notice that some tutorials write \"tar cvf\" rather than \"tar -cvf\" with the switch character - do you know why?\n\n## RESOURCES\n\n* [18 Tar Command Examples in Linux](https://www.tecmint.com/18-tar-command-examples-in-linux/)\n* [Linux TAR Command](http://linuxbasiccommands.wordpress.com/2008/04/04/linux-tar-command/)\n* [Linux tar command tutorial](https://www.youtube.com/watch?v=CUdwDEKlDrw) (video)\n\n*Copyright 2012-2021 @snori74 (Steve Brorens). Can be reused under the terms of the Creative Commons Attribution 4.0 International Licence (CC BY 4.0).*\n"
        },
        {
          "name": "17.md",
          "type": "blob",
          "size": 9.408203125,
          "content": "# Day 17 - From the source\n\n## INTRO\n\nA few days ago we saw how to authorise extra repositories for `apt-cache` to search when we need unusual applications, or perhaps more recent versions than those in the standard repositories.\n\nToday we're going one step further - literally going to \"go to the source\". This is not something to be done lightly - the whole reason for package managers is to make your life easy - but occasionally it is justified, and it is something you need to be aware of and comfortable with.\n\nThe applications we've been installing up to this point have come from repositories. The files there are \"binaries\" - pre-compiled, and often customised by your distro. What might not be clear is that your distro gets these applications from a diverse range of un-coordinated development projects  (the \"upstream\"), and these developers are continuously working on new versions. We’ll go to one of these, download the source, compile and install it.\n\n(Another big part of what package managers like `apt` do, is to identify and install any required \"dependencies\". In the Linux world many open source apps take advantage of existing infrastructure in this way, but it can be a very tricky thing to resolve manually. However, the app we're installing today from source is relatively unusual in being completly standalone).\n\n## FIRST WE NEED THE ESSENTIALS\n\nProjects normally provide their applications as \"source files\", written in the C, C++ or other computer languages. We're going to pull down such a source file, but it won't be any use to us until we compile it into an \"executable\" - a program that our server can execute. So, we'll need to first install a standard bundle of common compilers and similar tools. On Ubuntu, the package of such tools is called “build-essential\". Install it like this:\n\n`sudo apt install build-essential`\n\n## GETTING THE SOURCE\n\nFirst, test that you already have `nmap` installed, and type `nmap -V`  to see what version you have. This is the version installed from your standard repositories. Next, type: `which nmap` - to see where the executable is stored.\n\nNow let’s go to the \"Project Page\" for the developers  _http://nmap.org/_ and grab the very latest cutting-edge version. Look for the download page, then the section “Source Code Distribution” and the link for the \"Latest development nmap release tarball\" and note the URL for it - something like:\n\n     https://nmap.org/dist/nmap-7.70.tar.bz2\n\nThis is version 7.70, the latest development release when these notes were written, but it may be different now. So now we'll pull this down to your server. The first question is where to put it - we'll put it in your home directory, so change to your home directory with:\n\n`cd`\n\nthen simply using `wget` (\"web get\"), to download the file like this:\n\n`wget -v https://nmap.org/dist/nmap-7.70.tar.bz2`\n\nThe -v (for verbose), gives some feedback so that you can see what's happening. Once it's finished, check by listing your directory contents:\n\n`ls -ltr`\n\nAs we’ve learnt, the end of the filename is typically a clue to the file’s format - in this case  \".bz2\" signals that it's a tarball compressed with the bz2 algorithm. While we could uncompress this then un-combine the files in two steps, it can be done with one command - like this:\n\n`tar -j -x -v -f   nmap-7.70.tar.bz2`\n\n....where the -j means \"uncompress a bz2 file first\", -x is extract, -v is verbose - and -f says \"the filename comes next\". Normally we'd actually do this more concisely as:\n\n`tar -jxvf  nmap-7.70.tar.bz2`\n\nSo, lets see the results,\n\n`ls -ltr`\n\nRemembering that directories have a leading \"d\" in the listing, you'll see that a directory has been created :\n\n     -rw-r--r--  1 steve  steve  21633731    2011-10-01 06:46 nmap-7.70.tar.bz2\n     drwxr-xr-x 20 steve  steve  4096        2011-10-01 06:06 nmap-7.70\n\nNow explore the contents of this with `mc` or simply `cd nmap.org/dist/nmap-7.70` - you should be able to use `ls` and `less` find and read the actual source code. Even if you know no programming, the comments can be entertaining reading.\n\nBy convention, source files will typically include in their root directory a series of text files in uppercase such as: README and INSTALLATION. Look for these, and read them using `more` or `less`. It's important to realise that the programmers of the \"upstream\" project are not writing for Ubuntu, CentOS  - or even Linux. They have written a correct working program in C or C++ etc and made it available, but it's up to us to figure out how to compile it for our operating system, chip type etc. (This hopefully gives a little insight into the value that distributions such as CentOS, Ubuntu and utilities such as `apt`, `yum` etc add, and how tough it would be to create your own Linux From Scratch)\n\nSo, in this case we see an INSTALL file that says something terse like:\n\n     Ideally, you should be able to just type:\n\n     ./configure\n     make\n     make install\n\n     For far more in-depth compilation, installation, and removal notes\n     read the Nmap Install Guide at http://nmap.org/install/ .\n\nIn fact, this is fairly standard for many packages. Here's what each of the steps does:\n\n* `./configure` - is a script which checks your server (ie to see whether it's ARM or Intel based, 32 or 64-bit, which compiler you have etc). It can also be given parameters to tailor the compilation of the software, such as to not include any extra support for running in a GUI environment - something that would make sense on a \"headless\" (remote text-only server), or to optimize for minimum memory use at the expense of speed - as might make sense if your server has very little RAM. If asked any questions, just take the defaults - and don't panic if you get some WARNING messages, chances are that all will be well.\n* `make`  - compiles the software, typically calling the GNU compiler `gcc`. This may generate lots of scary looking text, and take a minute or two - or as much as an hour or two for very large packages like LibreOffice.\n* `make install` - this step takes the compiled files, and installs that plus documentation to your system and in some cases will setup services and scheduled tasks etc. Until now you've just been working in your home directory, but this step installs to the system for all users, so requires `root` privileges. Because of this, you'll need to actually run: `sudo make install`. If asked any questions, just take the defaults.\n\nNow, potentially this last step will have overwritten the `nmap` you already had, but more likely this new one has been installed into a different place.\n\nIn general  _/bin_ is for key parts of the operating system,  _/usr/bin_ for less critical utilities and _/usr/local/bin_ for software you've chosed to manually install yourself. When you type a command it will search through each of the directories given in your PATH environment variable, and start the first match. So, if _/bin/nmap_ exists, it will run instead of _/usr/local/bin_ - but if you give the \"full path\" to the version you want - such as _/usr/local/bin/nmap_ - it will run that version instead.\n\nThe “locate” command allows very fast searching for files, but because these files have only just been added, we'll need to manually update the index of files:\n\n`sudo updatedb`\n\nThen to search the index:\n\n`locate bin/nmap`\n\nThis should find both your old and copies of `nmap`\n\nNow try running each, for example:\n\n`/usr/bin/nmap -V`\n\n`/usr/local/bin/nmap -V`\n\nThe `nmap` utility relies on no other package or library, so is very easy to install from source. Most other packages have many \"dependencies\", so installing them from source by hand can be pretty challenging even when well explained (look at: <http://oss.oetiker.ch/smokeping/doc/smokeping_install.en.html> for a good example).\n\nNOTE: Because you've done all this outside of the `apt` system, this binary won't get updates when you run `apt update`. Not a big issue with a utility like `nmap` probably, but for anything that runs as an exposed service it's important that you understand that you now have to track security alerts for the application (and all of its dependencies), and install the later fixed versions when they're available. This is a significant pain/risk for a production server.\n\n## POSTING YOUR PROGRESS\n\nPat yourself on the back if you succeeded today - and let us know in the forum.\n\n## EXTENSION\n\nResearch some distributions where “from source” is normal:\n\n* [What is Linux From Scratch?](http://www.linuxfromscratch.org/lfs/)\n* [What is Gentoo?](http://www.gentoo.org/main/en/about.xml)\n* [The Arch Build System](https://wiki.archlinux.org/index.php/Arch_Build_System)\n\nNone of these is typically used in production servers, but investigating any of them will certainly increase your knowledge of how Linux works \"under the covers\" - asking you to make many choices that the production-ready distros such as RHEL and Ubuntu do on your behalf by choosing what they see as sensible defaults.\n\n## RESOURCES\n\n* [The magic behind configure, make, make install](https://thoughtbot.com/blog/the-magic-behind-configure-make-make-install)\n* [Installing From Tarballs](http://linux.byexamples.com/archives/156/installing-from-tarballs/)\n* [How to rebuild an existing package from source](http://raphaelhertzog.com/2010/12/15/howto-to-rebuild-debian-packages/)\n* [Compiling things on Ubuntu the Easy Way](https://help.ubuntu.com/community/CompilingEasyHowTo)\n\n*Copyright 2012-2021 @snori74 (Steve Brorens). Can be reused under the terms of the Creative Commons Attribution 4.0 International Licence (CC BY 4.0).*\n"
        },
        {
          "name": "18.md",
          "type": "blob",
          "size": 2.8134765625,
          "content": "# Day 18 - Log rotation\n\n## INTRO\n\nWhen you’re administering a remote server, logs are your best friend, but disk space problems can be your worst enemy - so while Linux applications are generally very good at generating logs, they need to be controlled.\n\nThe `logrotate` application keeps your logs in check. Using this, you can define how many days of logs you wish to keep; split them into manageable files; compress them to save space, or even keep them on a totally separate server.\n\nGood sysadmins love automation - having the computer automatically do the boring repetitive stuff Just Makes Sense.\n\n## ARE YOUR LOGS ROTATING?\n\nLook into your logs directories - _/var/log_, and subdirectories like _/var/log/apache2_. Can you see that your logs are already being rotated? You should see a _/var/log/syslog_ file, but also a series of older compressed versions with names like _/var/log/syslog.1.gz_\n\n## WHEN DO THEY ROTATE?\n\nYou will recall that `cron` is generally setup to run scripts in _/etc/cron.daily_ - so look in there and you should see a script called `logrotate` - or possibly _00logrotate_ to force it to be the first task to run.\n\n## CONFIGURING LOGROTATE\n\nThe overall configuration is set in _/etc/logrotate.conf_ - have a look at that, but then also look at the files under the directory _/etc/logrotate.d_, as the contents of these are merged in to create the full configuration.\nYou will probably see one called _apache2_, with contents like this:\n\n     /var/log/apache2/*.log {\n     weekly\n     missingok\n     rotate 52\n     compress\n     delaycompress\n     notifempty\n     create 640 root adm\n     }\n\nMuch of this is fairly clear: any apache2 .log file will be rotated each week, with 52 compressed copies being kept.\n\nTypically when you install an application a suitable logrotate “recipe” is installed for you, so you’ll not normally be creating these from scratch. However, the default settings won’t always match your requirements, so it’s perfectly reasonable for you as the sysadmin to edit these - for example, the default _apache2_ recipe above creates 52 weekly logs, but you might find it more useful to have logs rotated daily, a copy automatically emailed to an auditor, and just 30 days worth kept on the server.\n\n## YOUR TASK TODAY\n\n* Edit your logrotate configuration for _apache2_ to rotate daily\n* Make whatever other changes you wish\n* Check the next day to see that it’s worked\n\n## RESOURCES\n\n* [The Ultimate Logrotate Command Tutorial](http://www.thegeekstuff.com/2010/07/logrotate-examples/)\n* [LINUX: openSUSE and logrotate](http://www.youtube.com/watch?v=UoHmj3ef3Is)\n* [Use logrotate to Manage Log Files](http://library.linode.com/linux-tools/utilities/logrotate)\n\n*Copyright 2012-2021 @snori74 (Steve Brorens). Can be reused under the terms of the Creative Commons Attribution 4.0 International Licence (CC BY 4.0).*\n"
        },
        {
          "name": "19.md",
          "type": "blob",
          "size": 4.177734375,
          "content": "# Day 19 - Inodes, symlinks and stat\n\n## INTRO\n\nToday's topic gives a peek “under the covers” at the technical detail of how files are stored.\n\nLinux supports a large number of different “filesystems” - although on a server you’ll typically be dealing with just _ext3_ or _ext4_  and perhaps _btrfs_ - but today we’ll not be dealing with any of these; instead with the layer of Linux that sits _above_ all of these - the Linux Virtual Filesystem. \n\nThe VFS is a key part of Linux, and an overview of it and some of the surrounding concepts is very useful in confidently administering a system.\n\n## THE NEXT LAYER DOWN\n\nLinux has an extra layer between the filename and the file's actual data on the disk - this is the _inode_. This has a numerical value which you can see most easily in two ways:\n\nThe `-i` switch on the `ls` command:\n\n     ls -li /etc/hosts\n     35356766 -rw------- 1 root root 260 Nov 25 04:59 /etc/hosts\n\nThe `stat` command:\n\n     stat /etc/hosts\n     File: `/etc/hosts'\n     Size: 260           Blocks: 8           IO Block: 4096   regular file\n     Device: 2ch/44d     Inode: 35356766     Links: 1\n     Access: (0600/-rw-------)  Uid: (  0/   root)   Gid: (\t0/\troot)\n     Access: 2012-11-28 13:09:10.000000000 +0400\n     Modify: 2012-11-25 04:59:55.000000000 +0400\n     Change: 2012-11-25 04:59:55.000000000 +0400\n\nEvery file name \"points\" to an inode, which in turn points to the actual data on the disk. This means that several filenames could point to the same inode - and hence have exactly the same contents. In fact this is a standard technique - called a \"hard link\". The other important thing to note is that when we view the permissions, ownership and dates of filenames, these attributes are actually kept at the inode level, _not_ the filename. Much of the time this distinction is just theoretical, but it can be very important.\n\n## TWO SORTS OF LINKS\n\nWork through the steps below to get familiar with hard and soft linking:\n\nFirst move to your home directory with:\n\n`cd`\n\nThen use the `ln` (\"link\") command to create a “hard link”, like this:\n\n`ln /etc/passwd link1`\n\nand now a \"symbolic link\" (or “symlink”), like this:\n\n`ln -s /etc/passwd link2`\n\nNow use `ls -li` to view the resulting files, and `less` or `cat` to view them.\n\nNote that the permissions on a symlink generally show as allowing everthing - but what matters is the permission of the file it points to.\n\nBoth hard and symlinks are widely used in Linux, but symlinks are especially common - for example:\n\n`ls -ltr /etc/rc2.d/*`\n\nThis directory holds all the scripts that start when your machine changes to “runlevel 2” (its normal running state) - but you'll see that in fact most of them are symlinks to the real scripts in _/etc/init.d_\n\nIt's also very common to have something like :\n\n     prog\n     prog-v3\n     prog-v4\n\nwhere the program \"prog\", is a symlink - originally to v3, but now points to v4 (and could be pointed back if required)\n\nRead up in the resources provided, and test on your server to gain a better understanding. In particular, see how permissions and file sizes work with symbolic links versus hard links or simple files\n\n## The Differences\n\nHard links:\n\n* Only link to a file, not a directory\n* Can't reference a file on a different disk/volume\n* Links will reference a file even if it is moved\n* Links reference inode/physical locations on the disk\n\nSymbolic (soft) links:\n\n* Can link to directories\n* Can reference a file/folder on a different hard disk/volume\n* Links remain if the original file is deleted\n* Links will NOT reference the file anymore if it is moved\n* Links reference abstract filenames/directories and NOT physical locations.\n* They have their own inode\n\n## EXTENSION\n\n* [Anatomy of the Linux file system](https://developer.ibm.com/tutorials/l-linux-filesystem/)\n\n## RESOURCES\n\n* [Hard and soft links](http://linuxgazette.net/105/pitcher.html)\n* [What's an inode?](http://www.linux-mag.com/id/8658/)\n* [Everything You Ever Wanted to Know About inodes on Linux](https://www.howtogeek.com/465350/everything-you-ever-wanted-to-know-about-inodes-on-linux/)\n\n*Copyright 2012-2021 @snori74 (Steve Brorens). Can be reused under the terms of the Creative Commons Attribution 4.0 International Licence (CC BY 4.0).*\n"
        },
        {
          "name": "20.md",
          "type": "blob",
          "size": 5.228515625,
          "content": "# Day 20 - Scripting\n\n## INTRO\n\nToday is the final session for the course. Pat yourself on the back if you worked your way through all lessons!\n\nYou’ve seen that a continual emphasis for a sysadmin is to automate as much as possible, and also how in Linux the system is very “transparent” - once you know where to look!\n\nToday, on this final session for the course, we’ll cover how to write small programs or “shell scripts” to help manage your system.\n\nWhen typing at the Linux command-line you're directly communicating with \"the command interpreter\", also known as \"the shell\". Normally this shell is _bash_, so when you string commands together to make a script the result can be called either a '\"shell script\", or a \"bash script\".\n\nWhy make a script rather than just typing commands in manually?\n\n* It saves typing. Remember when we searched through the logs with a long string of `grep`, `cut` and `sort` commands? If you need to do something like that more than a few times then turning it into a script saves typing - and typos!\n* Parameters. One script can be used to do several things depending on what parameters you provide\n* Automation. Pop your script in _/etc/cron.daily_ and it will run each day, or install a symlink to it in the appropriate _/etc/rc.d_ folder and you can have it run each time the system is shut down or booted up.\n\n## START WITH A SHEBANG!\n\nScripts are just simple text files, but if you set the \"execute\" permissions on them then the system will look for a special line starting with the two characters “#” and “!” - referred to as the \"shebang\" (or \"crunchbang\") at the top of the file.\n\nThis line typically looks like this:\n\n     #!/bin/bash\n\nNormally anything starting with a \"#\" character would be treated as a comment, but in the first line and followed by a \"!\", it's interpreted as: _\"please feed the rest of this to the /bin/bash program, which will interpret it as a script\"_. All of our scripts will be written in the _bash_ language - the same as you’ve been typing at the command line throughout this course - but scripts can also be written in many other \"scripting languages\", so a script in the Perl language might start with `#!/usr/bin/perl` and one in Python `#!/usr/bin/env python3`\n\n## YOUR FIRST SCRIPT\n\nYou'll write a small script to list out who's been most recently unsuccessfully trying to login to your server, using the entries in _/var/log/auth.log_.  \n\nUse `vim` to create a file, `attacker`, in your home directory with this content:\n\n     #!/bin/bash\n     #\n     #   attacker - prints out the last failed login attempt\n     #\n     echo \"The last failed login attempt came from IP address:\"\n     grep -i \"disconnected from\" /var/log/auth.log|tail -1| cut -d: -f4| cut -f7 -d\" \"\n\nPutting comments at the top of the script like this isn't strictly necessary (the computer ignores them), but it's a good professional habit to get into.\n\nTo make it executable type:\n\n`chmod +x attacker`\n\nNow to run this script, you just need to refer to it by name - but the current directory is (deliberately) not in your $PATH, so you need to do this either of two ways:\n\n     /home/support/attacker\n     ./attacker\n\nOnce you're happy with a script, and want to have it easily available, you'll probably want to move it somewhere on your $PATH - and _/usr/local/bin_ is a normally the appropriate place, so try this:\n\n`sudo mv attacker /usr/local/bin/attacker`\n\n...and now it will Just Work whenever you type `attacker`\n\n## EXTENDING THE SCRIPT\n\nYou can expand this script so that it requires a parameter and prints out some syntax help when you don't give one. There are a few new tricks in this, so it's worth studying:\n\n     #\n     ##   topattack - list the most persistent attackers\n     #\n     if [ -z \"$1\" ]; then\n     echo -e \"\\nUsage: `basename $0` <num> - Lists the top <num> attackers by IP\"\n     exit 0\n     fi\n     echo \" \"\n     echo \"Persistant recent attackers\"\n     echo \" \"\n     echo \"Attempts      IP \"\n     echo \"-----------------------\"\n     grep \"Disconnected from authenticating user root\" /var/log/auth.log|cut -d: -f 4 | cut -d\" \" -f7|sort |uniq -c |sort -nr |head -$1\n\nAgain, use vim to create `\"topattack\"`, `chmod` to make it executable and `mv` to move it into _/usr/local/bin_ once you have it working correctly.\n\n(BTW, you can use `whois` to find details on any of these IPs - just be aware that the system that is \"attacking\" you may be an innocent party that's been hacked into).\n\nA collection of simple scripts like this is something that you can easily create to make your sysadmin tasks simpler, quicker and less error prone.\n\nAnd yes, this is the last lesson - so please, feel free to write a review on how the course went for you and what you plan to do with your new knowledge and skills!\n\n## RESOURCES\n\n* [Learn Bash Scripts - Tutorial (video)](http://www.youtube.com/watch?v=QGvvJO5UIs4)\n* [Bash scripting tutorial](http://linuxconfig.org/Bash_scripting_Tutorial)\n* [BASH Programming - Introduction HOW-TO](http://tldp.org/HOWTO/Bash-Prog-Intro-HOWTO.html)\n* [How to be a good (and lazy) System Administrator](http://www.linuxjournal.com/content/how-be-good-and-lazy-system-administrator)\n\n*Copyright 2012-2021 @snori74 (Steve Brorens). Can be reused under the terms of the Creative Commons Attribution 4.0 International Licence (CC BY 4.0).*\n"
        },
        {
          "name": "21.md",
          "type": "blob",
          "size": 2.4765625,
          "content": "# Day 21 - What next? \n\nWhat is this madness – surely the course was for just 20 days?\n\nYes, but hopefully you’ll go on learning, so here’s a few suggestions for directions that you might take\n\n## Play with your server\n\nYou’re familiar with the server you used during the course, so keep working with it. Maybe uninstall Apache2 and install NGINX, a competing webserver. Keep a running stat on ssh “attackers”. Whatever. A free AWS will last a year, and a $5/mo server should be something you can easily justify.\n\n## Add services that you’ll use\n\nYou should now be capable of following tutorials on installing and running your own instance of Minecraft, Wordpress, WireGuard VPN, or Mediawiki. Expect to have some problems – it's all good experience!\n\n## Extend your learning\n\nStop browsing articles on Gnome, KDE or i3 – and start checking out any articles like “*20 Linux commands every sysadmin should know*”. Try these out, delve into the options. Like learning a foreign vocabulary, you will only be able to use these “words” if you know them!\n\n## Certs\n\nIf you’re looking to do Linux professionally, and you don’t have an impressive CV or resume already, then you should be aiming at getting a cert. There are really just three certs/tracks that count:\n\n* [CompTIA Linux+](https://www.comptia.org/certifications/linux)\n\n* [LPI LPIC-1: Linux Administrator](https://wiki.lpi.org/wiki/Main_Page) – Very extensive description of the coverage of their various certs/courses.\n\n* [Red Hat](https://www.redhat.com/en/services/all-certifications-exams) – You could spend a lot of time and money here! (but it might well pay off)\n\nEven if you don’t want/need certs, the outline of the topics in these references can give you a good idea of areas to focus on in your self-learning.\n\n## Affordable professional training\n\n* [LinkedIn Learning](https://www.linkedin.com/learning/search?keywords=linux)\n* [Udemy](https://www.udemy.com/topic/linux/)\n\n* [CBT Nuggets](https://www.cbtnuggets.com/it-training/linux-found-cert-sys-admin)\n\nAll the best!\n\n - Steve (@snori74)\n\nPS: It's traditional to show your appreciation by sending me a real old-fashioned \"Snail Mail\" postcard, with a stamp - this may be one of the last times you use that ancient tech!\n\n    Steve Brorens\n    49/60 Port Hills Road\n    Heathcote Valley\n    Christchurch 8022\n    NEW ZEALAND\n\n*Copyright 2012-2021 @snori74 (Steve Brorens). Can be reused under the terms of the Creative Commons Attribution 4.0 International Licence (CC BY 4.0).*\n"
        },
        {
          "name": "LICENSE",
          "type": "blob",
          "size": 0.0888671875,
          "content": "Copyright (c) 2012-2010 @snori74 (Steve Brorens)\nAttribution 4.0 International (CC BY 4.0)\n"
        },
        {
          "name": "README.md",
          "type": "blob",
          "size": 0.7744140625,
          "content": "**HISTORICAL INTEREST ONLY**\n\n**Livia's fork at https://github.com/livialima/linuxupskillchallenge is now where the action happens.**\n***\n\n\n*Introduction to Linux Server Administration!*\n\nThis includes all the source material for the 20 lessons of what was previously a commercial online Linux server admin course - now free for you to learn with! (If you spot any typos or \"dead links\" simply raise a GitHub \"issue\").\n\n* Website of the course: https://LinuxUpskillChallenge.org\n\n* Monthly \"Linux Upskill Challenge\": https://www.reddit.com/r/linuxupskillchallenge/\n\n* Lesson \"source\": https://github.com/snori74/linuxupskillchallenge\n\n* Chat at: https://discordapp.com/invite/wd4Zqyk\n\nYou are free to use this under the terms of the license, but copyright remains with the author.\n  \n - Steve\n"
        },
        {
          "name": "TOC.md",
          "type": "blob",
          "size": 2.169921875,
          "content": "# Overview of the Linux Upskill Challenge\n\n## Day 1\n\nStarting with `ssh`-ing in and some simple commands like: `ls`, `uptime`, `free`, `df -h`, `uname -a`. Extensions on doing passwordless login with public keys and and an `ssh` config file.\n\n## Day 2\n\nBasic navigation, the \"man\" pages, file hierarchy\n\n## Day 3 \n\nWorking with `sudo`, `uptime`, `timezones`, changing your hostname\n\n## Day 4\n\nUsing 'apt' to find and install sotware. Use of `mc` to explore the filesystem. Looking at the contents of: `/etc/passwd`, `/etc/ssh/sshd_config` and `/var/log/auth.log`\n\n## Day 5\n\nUsing `more`, `less` and navigating in these. Dotfiles, history, tab completion, and using the `nano` txt editor\n\n## Day 6\n\nLearning `vim`, the minimal knowledge, but also via `vimtutor`\n\n## Day 7\n\nInstalling Apache2, stopping and starting, altering the content, reading logs\n\n## Day 8\n\nHands-on with text tools like `grep`, `cat`, `more`, `less`, `cut`, `awk` and `tail` - and piping of course. (and a wave to `awk` and `sed`)\n\n ## Day 9\n\nLooking at open ports with with `ss`, and a nod to `netstat`, install `nmap` and test. Install `ufw`, set up, enable and test etc. Discuss security resonsibilities as the sysadmin.\n\n ## Day 10\n\n Covering `cron`, `at`, and systemd timers\n\n## Day 11\n\nFinding things with: `locate`, `find`, `grep`, `which`\n\n## Day 12\n\nSFTP, the technology, clients, and copying up and down\n\n## Day 13\n\nPermissions, users, groups, (ACLS and SELinux in the Extension)\n\n## Day 14\n\nUsing `adduser`, `visudo` to setup up a restricted \"helper\" to manage our host\n\n## Day 15\n\nRepositories in more detail, how to enable \"Multiverse\", the role of PPAs in Ubuntu, enabling and installing from them\n\n## Day 16\n\nUnderstanding and using `tar` and `gzip`\n\n## Day 17\n\nInstalling from source. Discussion, using `wget` to get a tarball, `tar` to extract and then configure, make and install. Discussion of security, maintenance issues.\n\n## Day 18\n\nLog management and rotation, `logrotate`\n\n## Day 19\n\nInodes, hard links symlinks and `stat`\n\n ## Day 20\n\nUnderstanding how scripting work in Linux, the shebang, permissons and $PATH. A couple of simple sample scripts based on the filtering of logs we've been doing. Resources to explore further.\n"
        },
        {
          "name": "_config.yml",
          "type": "blob",
          "size": 0.025390625,
          "content": "theme: jekyll-theme-cayman"
        },
        {
          "name": "build",
          "type": "blob",
          "size": 0.4013671875,
          "content": "#!/bin/bash\n# \n# This will build one big PDF file from the course files.\n# \n# You may need to install some packages first for this to work:\n#\n#   sudo apt install pandoc\n#   sudo apt-get install texlive-latex-base\n#   sudo apt-get install texlive-fonts-recommended\n\npandoc -o book.pdf 01.md 02.md 03.md 04.md 05.md 06.md 07.md 08.md 09.md 10.md 11.md 12.md 13.md 14.md 15.md 16.md 17.md 18.md 19.md 20.md 21.md\n"
        },
        {
          "name": "day1-short-video.md",
          "type": "blob",
          "size": 0.1171875,
          "content": "# Day 1 - a short video\n\nA [short vid on using ssh](https://www.youtube.com/watch?v=lMMOUSRPfJc) in a work environment.\n"
        },
        {
          "name": "how-this-works.md",
          "type": "blob",
          "size": 2.9873046875,
          "content": "# HOW THIS WORKS...\n\n* [Website of the course](https://LinuxUpskillChallenge.org)\n* [Monthly \"Linux Upskill Challenge\"](https://www.reddit.com/r/linuxupskillchallenge/)\n* [Overview of the course content](https://github.com/snori74/linuxupskillchallenge/blob/master/TOC.md)\n* [Full lesson \"source\"](https://github.com/snori74/linuxupskillchallenge) \n* [Chat with Discord](https://discordapp.com/invite/wd4Zqyk)\n* [Recent feedback...](https://www.reddit.com/r/linuxupskillchallenge/comments/j3g2s0/thoughts_and_comments_day_20/)\n\n## You'll need to setup a cloud-based server\n\nDo I *really* need a cloud-based server?\n\nYes, if you’re in the target audience (see below) you definitely should. The fact that such a server is very remote, and open to attack from the whole Internet, “makes it real”. Learning how to setup such a VPS is also a handy skill for any sysadmin.\n\nInstructions for setting up a suitable server with a couple of providers are in the \"Day 0\" posts. By all means use a different provider, but ensure you use Ubuntu LTS (preferably 20.04), and either use public key authentication or a Long, Strong, Unique password.\n\nOf course, you’re perfectly entitled to use a local VM, an old laptop in the corner or a Raspberry Pi instead – and all of these will work fine for the course material.\n\n## Why Ubuntu, can I use another distro?\n\nThe notes assume Ubuntu Server LTS 20.04 and it would be messy to include instructions/variations for every other distro. If you use Debian or CentOS (also good server choices), you yourself will need to understand and cope with any differences (e.g. apt vs yum).\n\n## Target audience\n\nThis course is squarely aimed at two groups: (1) Linux users who aspire to get Linux-related jobs in industry, such as junior Linux sysadmin, devops-related work and similar, and (2) Windows server admins who want to expand their knowledge to be able to work with Linux servers.\n\nHowever, many others have happily used the course simply to improve their Linux command line skills – and that’s just fine too.\n\n## A daily lesson\n\nOne of the key elements of the course is that the material is delivered in 20 bite-sized lessons, one each workday into this subreddit. At any one time, just the last four lessons are available (we remove the older ones) – this gives you a bit of an incentive to “keep up”.\n\nThe course always starts on the first Monday of the month. The first few days are pretty basic, but there's generally some \"Extension\" items for the more experienced.\n\nExpect to spend 1-2 hours going through each. Some find it handy to read the notes through quickly in the day, then do the practical stuff in the evening – but do whatever suits you.\n\n## Support\n\nFeel free to post questions or comments here in the subreddit – or chat using the Discord server (<https://discordapp.com/invite/wd4Zqyk>) run by u/cobaltrune.\n\n## Patreon?\n\nNo, but there are [a number of ways you can support and show your appreciation](http://snori74.blogspot.com/2020/09/how-can-you-support-linuxupskillchallen.html).\n"
        },
        {
          "name": "index.md",
          "type": "blob",
          "size": 1.9326171875,
          "content": "  <body>\n    <section class=\"page-header\">\n      <h1 class=\"project-name\">linuxupskillchallenge</h1>\n      <h2 class=\"project-tagline\">Learn the skills required to sysadmin a remote Linux server from the commandline.</h2>\n      \n        <a href=\"https://github.com/snori74/linuxupskillchallenge\" class=\"btn\">View on GitHub</a>\n      \n      \n    </section>\n\n    <section class=\"main-content\">\n      <h1 id=\"linux-upskill-challenge\">Linux Upskill Challenge</h1>\n\n<p>A month-long course aimed at those who aspire to get Linux-related jobs in industry - junior Linux sysadmin, devops-related work and similar. Server focussed and commandline, but assumes essentially no prior knowledge, and starts off very gently - designed to be well-suited to a Windows or Apple person as well as those that already\nusing Linux in some form.</p>\n\n<p>The course is run via Reddit, so you will need a Reddit login, and to subscribe to: <a href=\"https://reddit.com/r/linuxupskillchallenge\">r/linuxupskillchallenge</a>\n\n<p>Each weekday a new lesson is posted there, and it allows a great forum-style interface to discuss and get help.</p>\n\n<p>This was a $250 paid course, but is now free and fully open source - so costs you nothing but your time!</p>\n\n<p>Note:</p>\n<ul>\n  <li>The focus is on practical skills</li>\n  <li>Heavily hands-on</li>\n  <li>Requires a daily commitment of 1-2 hours each day for a month</li>\n  <li>Often points to curated external links.</li>\n  <li>Much less ‘formal’ than RHEL or Linux Foundation training</li>\n</ul>\n\n<p>If you’re keen to do this, then you will need your own Internet-exposed server - but full\ninstructions on how to set this up for free or cheap are now up as ‘Day 0’ posts in the\nsubreddit.</p>\n\n<p>The next course starts on Monday 06 March. As each new lesson gets posted, we’ll be trimming an earlier one - so make sure you keep up!</p>\n\n<p>Each month we’ll ‘reset’, with “Day 1” again going up on the first Monday of the month.</p>\n"
        },
        {
          "name": "metadata.xml",
          "type": "blob",
          "size": 0.3046875,
          "content": "<dc:title>Linux Upskill Challange</dc:title> \n<dc:language>en-US</dc:language> \n<dc:creator opf:file-as=\"Brorens, Steve\" opf:role=\"aut\">Steve Brorens</dc:creator> \n<dc:publisher>snori74</dc:publisher>\n<dc:date opf:event=\"publication\">2014-02-14</dc:date>\n<dc:rights>Copyright ©2014 by Steve Brorens</dc:rights>\n"
        },
        {
          "name": "text-for-devops-subreddit.md",
          "type": "blob",
          "size": 0.4453125,
          "content": "TITLE: Free intro to Linux commandline/server course starts first Monday of next month\n\nThis course has been running successfully now every month since February 2020 - more detail at: https://LinuxUpskillChallenge.org - daily lessons appear in the sub-reddit r/linuxupskillchallenge - which is also used for support/discussion.\n\nSuitable whatever your background, and aims to provide that \"base layer\" of traditional Linux skills in a fun interactive way.\n"
        },
        {
          "name": "thoughts-and-comments.md",
          "type": "blob",
          "size": 0.404296875,
          "content": "# Questions and chat, Day X...\n\nPosting your questions, chat etc. here keeps things tidier...\n\nYour contribution will 'live on' longer too, because we delete lessons after 4-5 days - along with their comments.\n\n(By the way, if _you_ can answer a query, please feel free to chip in. While Steve, (@snori74), is the official tutor, he's on a different timezone than most, and sometimes busy, unwell or on holiday!) \n"
        },
        {
          "name": "txt-for-commandline-subreddit.md",
          "type": "blob",
          "size": 0.5263671875,
          "content": "TITLE: Free Linux commandline \"upskill\" course starting shortly...\n\nThis free month-long course is re-starting again on the first Monday of next month.\n\nDaily lessons appear in the sub-reddit r/linuxupskillchallenge - which is also used for support/discussion.\n\nHas been running successfully now every month since February 2020 - more detail at: https://LinuxUpskillChallenge.org\n\nAs you'll see, it's aimed at those wanting to admin servers, but 100% of the content is classic Linux commandline stuff just as applicable to a desktop user.\n"
        },
        {
          "name": "txt-for-linux-subreddit.md",
          "type": "blob",
          "size": 0.392578125,
          "content": "TITLE: The junior sysadmin course at r/LinuxUpskillChallenge restarts shortly\n\nThis free month-long course is re-starting again on the first Monday of next month.\n\nDaily lessons appear in the sub-reddit /r/linuxupskillchallenge - which is also used for support/discussion. \n\nHas been running successfully now every month since February 2020 - more detail at: https://LinuxUpskillChallenge.org\n\n- Steve\n"
        },
        {
          "name": "txt-for-linux4noobs-subreddit.md",
          "type": "blob",
          "size": 0.376953125,
          "content": "TITLE: Linux commandline/sysadmin course restarting the first Monday of next month\n\nDaily lessons appear in  the sub-reddit /r/linuxupskillchallenge  - which is also used for support/discussion. This is a 'rolling' course repeated each month. Announcing now to give you plenty of time to set up your server if you want to participate.  More detail at: http://linuxupskillchallenge.org \n"
        },
        {
          "name": "txt-for-linux_mentor-subreddit.md",
          "type": "blob",
          "size": 0.37890625,
          "content": "TITLE: The junior sysadmin course at r/LinuxUpskillChallenge restarts soon\n\nThis free month-long course is re-starting again on the first Monday of next month.\n\nDaily lessons appear in the sub-reddit r/linuxupskillchallenge - which is also used for support/discussion.\n\nHas been running successfully now every month since February 2020 - more detail at: https://LinuxUpskillChallenge.org\n"
        },
        {
          "name": "txt-for-linuxadmin-subreddit.md",
          "type": "blob",
          "size": 0.623046875,
          "content": "TITLE: A month-long challenge for anyone wanting to build Linux sysadmin skills\n\nThe http://linuxupskillchallenge.org Linux commandline/sysadmin \"challenge\" course starts again soon on the first Monday of next month.\n\nDaily lessons will appear in the sub-reddit r/linuxupskillchallenge - which will also be used for support/discussion. This is a \"rolling\" course, restarted each month.\n\nDoes require some commitment - but if gaining/growing these skills is important to you, then you now have no excuse! \n\nRequires a (free or cheap) remote server, so it's nice to get that sorted now if you - or some of your staff or friends - are keen.\n"
        },
        {
          "name": "txt-for-linuxmasterrace-subreddit.md",
          "type": "blob",
          "size": 0.45703125,
          "content": "TITLE: Linux upskill challenge\n\nA month-long challenge for anyone wanting to build Linux sysadmin skills - http://linuxupskillchallenge.org\n\nStarting the first Monday of the month, daily lessons will appear in the sub-reddit r/linuxupskillchallenge - which will also be used for support/discussion. This is a \"rolling\" course, restarted each month.\n\nDoes require some commitment - but if gaining/growing these skills is important to you, then you now have no excuse! \n"
        },
        {
          "name": "txt-for-sysadminblogs-subreddit.md",
          "type": "blob",
          "size": 0.5146484375,
          "content": "TITLE: Commandline/sysadmin course in r/linuxupskillchallenge\n\nThis month-long challenge for anyone wanting to build Linux sysadmin skills is re-starting again the first Monday of next month.\n\nDaily lessons appear in  the sub-reddit /r/linuxupskillchallenge  - which is also be used for support/discussion.  This is a 'rolling' course repeated each month. Does require some serious commitment, but if gaining/growing these skills is something you've been meaning to do, then you now have no excuse!\n\nAny feedback very welcome.\n"
        },
        {
          "name": "txt-for-ubuntu-subreddit.md",
          "type": "blob",
          "size": 0.3818359375,
          "content": "TITLE Month-long Ubuntu commandline/sysadmin course starts soon\n\nThis course restarts the first Monday of next month. Based around Ubuntu 20.04 LTS, it's free, and daily lessons appear in the sub-reddit r/linuxupskillchallenge - which is also used for support/discussion.\n\nHas been running successfully now every month since February 2020 - more detail at: https://LinuxUpskillChallenge.org\n"
        }
      ]
    }
  ]
}