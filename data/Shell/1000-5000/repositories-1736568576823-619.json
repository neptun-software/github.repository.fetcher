{
  "metadata": {
    "timestamp": 1736568576823,
    "page": 619,
    "hasNextPage": true,
    "endCursor": "Y3Vyc29yOjYyOQ==",
    "completionStatus": "IN_PROGRESS"
  },
  "repositories": [
    {
      "nameWithOwner": "pypa/manylinux",
      "stars": 1484,
      "defaultBranch": "main",
      "files": [
        {
          "name": ".github",
          "type": "tree",
          "content": null
        },
        {
          "name": ".gitignore",
          "type": "blob",
          "size": 0.7529296875,
          "content": "# Byte-compiled / optimized / DLL files\n__pycache__/\n*.py[cod]\n\n# C extensions\n*.so\n\n# Distribution / packaging\n.Python\nenv/\nbuild/\ndevelop-eggs/\ndist/\ndownloads/\neggs/\n.eggs/\nlib/\nlib64/\nparts/\nsdist/\nvar/\n*.egg-info/\n.installed.cfg\n*.egg\n\n# PyInstaller\n#  Usually these files are written by a python script from a template\n#  before PyInstaller builds the exe, so as to inject date/other infos into it.\n*.manifest\n*.spec\n\n# Installer logs\npip-log.txt\npip-delete-this-directory.txt\n\n# Unit test / coverage reports\nhtmlcov/\n.tox/\n.coverage\n.coverage.*\n.cache\nnosetests.xml\ncoverage.xml\n*,cover\n\n# Translations\n*.mo\n*.pot\n\n# Django stuff:\n*.log\n\n# Sphinx documentation\ndocs/_build/\n\n# PyBuilder\ntarget/\n\n# Prefetched source\ndocker/sources\n\n# buildx cache\n.buildx-cache-*/\n"
        },
        {
          "name": ".pre-commit-config.yaml",
          "type": "blob",
          "size": 1.2861328125,
          "content": "repos:\n\n- repo: https://github.com/pre-commit/pre-commit-hooks\n  rev: v5.0.0\n  hooks:\n  - id: check-case-conflict\n  - id: check-merge-conflict\n  - id: check-yaml\n  - id: check-toml\n  - id: debug-statements\n  - id: end-of-file-fixer\n    exclude: docker/build_scripts/python_versions.json\n  - id: mixed-line-ending\n  - id: trailing-whitespace\n\n- repo: https://github.com/shellcheck-py/shellcheck-py\n  rev: v0.10.0.1\n  hooks:\n  - id: shellcheck\n\n- repo: https://github.com/astral-sh/ruff-pre-commit\n  rev: v0.8.0\n  hooks:\n  - id: ruff\n    args: [\"--fix\", \"--show-fixes\", \"--target-version=py37\"]\n    exclude: ^tools/.*.py|docker/build_scripts/manylinux-interpreters.py$\n  - id: ruff-format\n    args: [\"--target-version=py37\"]\n    exclude: ^tools/.*.py|docker/build_scripts/manylinux-interpreters.py$\n  - id: ruff\n    name: ruff on python 3.12 tools\n    files: ^tools/.*.py|docker/build_scripts/manylinux-interpreters.py$\n    args: [\"--fix\", \"--show-fixes\", \"--target-version=py312\"]\n  - id: ruff-format\n    name: ruff-format on python 3.12 tools\n    files: ^tools/.*.py|docker/build_scripts/manylinux-interpreters.py$\n    args: [\"--target-version=py312\"]\n\n- repo: https://github.com/codespell-project/codespell\n  rev: v2.3.0\n  hooks:\n  - id: codespell\n    args: [\"-w\"]\n    exclude: ^docker/build_scripts/.*pubkey.*.txt$\n"
        },
        {
          "name": ".travis.yml",
          "type": "blob",
          "size": 4.126953125,
          "content": "language: c\nos: linux\ndist: focal\naddons:\n  apt:\n    sources:\n      - sourceline: 'deb https://download.docker.com/linux/ubuntu $(lsb_release -cs) stable'\n        key_url: 'https://download.docker.com/linux/ubuntu/gpg'\n    packages:\n    - docker-ce docker-ce-cli containerd.io docker-buildx-plugin\nservices:\n  - docker\n\n# Don't build the update-dependencies-pr branch; it's redundant\n# with the PR builds that Travis also does.\nbranches:\n  except:\n    - /^update-dependencies-pr/\n\ncache:\n  directories:\n    - ${HOME}/buildx-cache/\n\nenv:\n  global:\n    # QUAY_USERNAME and QUAY_PASSWORD for docker image upload\n    - secure: \"lKaTzEL6UNiEfp+BWLOUILG9BMtjwEMpwt6Yag0cQGHix7qJ/ElZ0t3oFw6ZwuDmA5qceAXIdxHLUK9HGVI2MloLk8czGhjvtfJ4XhOxtEJRQ0VkDGPsKN4cfhB4ZjGo6GAPtNqStMyNiY7BZuTrZa7coDLCoUeYcOmTpi6pmd1rrkk725B9QCTuhFHbPhkuL2yu/Jk6WxkHJBKjmuZek+iQa7lRItgMrG0/319PXLvwIGGl00nLFy+Ly5Ciwzux4wuHLTySZQKu0H9FX81A7smM0FW/42kg3ckGa2qLxRw/Pi8Nm/aIk8LD0QXzI5N7HhFfidOTgDS8Mt1HgfxmTk4wUXZ/KvCCshqjimzMc/s9i9wPZX9UqqcfrpZkmwz8dzhm1bndN45ZOCy6xAYT6dzf8T4mLMDjVWSW4+DUoW4sYHRLVujjcMk7ybcwGV43VruPTJnc8XVAhT+VIMQkoPjhQmTOn8h82LRNGYtLa5RReCh9OPKVYB2Quz18FXMWgFt7A6VWudL0c7/8CusLvuo+pLcxt9pnV40rvu1YEohpEj8qR/qTSaDUBZM0J9SVf5zrZR80pZUnXkDF8nm+mcLOTley3YWipU19lCR7dzVyCAiQdVAuNPdnyem3Yk8enGkAJbfLd6eaIDs+p73D0JXh1Nx1px1movVLQH3ohIw=\"\n    - secure: \"w1614pomHLltkBhqWM2bOvbymFWIWKqSqqIBDvaNn9tbQScioItJoELBT7g7+cD7nyU7OvpQ1U2fk0xVkCeNvYU0xS1vP4o/VnZRpup7f7Tkiq+2rf4fjwYr3HHnJjwak1l9bsw6FkgzKaVvSdiUJHMVxiIuLd3fVozR7qjBBhTDxSlWGOpSgd+ttpgMZwU5zQjdaVQr1D7E8M0979ZnWMrNRyLiAUeHaPILS815b+ijgqR+i5nmu0/FTCGM9Ik4KIzIfWq8AdfPdbRiq8c+LrrTPfyKcIQJaHmfduYRM4LycGWwzkXFBNtLrJ7uFLG9RDVemOHuHOWIJX8qCUIV4XuESXxH3fUQr6r+yxquTJbzXxNtoaLa6tBOTQWKDrRjT4z9Mf9Im14F2V59EUDoQowHx5bjunOH5wg3ruYNKYYBFRYra5kx0CkKrqFBzyl8fTUEQLyx1HWTVUC1WTXEeD/aFKOSIxW5DxZr5W4LLlW2+Raa52ZzY28Q6AdueFQCRzoJ70/GsJRlSsBdWNOHN4gSp1cZuToLWY15y64QhAMVDpikB+V4hmkbceLiTqeWzTStNL1sa32RHr6i/9zeFZw1pMD1+eOg9x6fgODfh2sqr/zPbu2oONsHnc4D2jwsEax4o+Dv5QHLvK7jdyWUmu47a9QReoexXK60jZXs3CA=\"\n\njobs:\n   include:\n    - arch: arm64-graviton2\n      virt: vm\n      group: edge\n      env: POLICY=\"manylinux2014\" PLATFORM=\"aarch64\"\n    - arch: s390x\n      env: POLICY=\"manylinux2014\" PLATFORM=\"s390x\"\n    - arch: ppc64le\n      env: POLICY=\"manylinux2014\" PLATFORM=\"ppc64le\"\n    - arch: arm64-graviton2\n      virt: vm\n      group: edge\n      env: POLICY=\"manylinux_2_28\" PLATFORM=\"aarch64\"\n    - arch: s390x\n      env: POLICY=\"manylinux_2_28\" PLATFORM=\"s390x\"\n    - arch: ppc64le\n      env: POLICY=\"manylinux_2_28\" PLATFORM=\"ppc64le\"\n    - arch: arm64-graviton2\n      virt: vm\n      group: edge\n      env: POLICY=\"manylinux_2_34\" PLATFORM=\"aarch64\"\n    - arch: s390x\n      env: POLICY=\"manylinux_2_34\" PLATFORM=\"s390x\"\n    - arch: ppc64le\n      env: POLICY=\"manylinux_2_34\" PLATFORM=\"ppc64le\"\n    - arch: arm64-graviton2\n      virt: vm\n      group: edge\n      env: POLICY=\"musllinux_1_2\" PLATFORM=\"aarch64\"\n    - arch: arm64-graviton2\n      virt: vm\n      group: edge\n      env: POLICY=\"musllinux_1_2\" PLATFORM=\"armv7l\"\n    - arch: s390x\n      env: POLICY=\"musllinux_1_2\" PLATFORM=\"s390x\"\n    - arch: ppc64le\n      env: POLICY=\"musllinux_1_2\" PLATFORM=\"ppc64le\"\n\nbefore_install:\n  - if [ -d \"${HOME}/buildx-cache/.buildx-cache-${POLICY}_${PLATFORM}\" ]; then cp -rlf ${HOME}/buildx-cache/.buildx-cache-${POLICY}_${PLATFORM} ./; fi\n\ninstall:\n  - docker version\n  - docker buildx version\n  - docker buildx create --name builder-manylinux --driver docker-container --use\n  - docker buildx inspect --bootstrap --builder builder-manylinux 2>&1 | tee /dev/null\n\nscript: |\n  BUILD_STATUS=success\n  (while true; do echo \"travis_wait\"; docker stats --no-stream; free; df -h; sleep 30; done) &\n  WAIT_PID=$!\n  COMMIT_SHA=${TRAVIS_COMMIT} ./build.sh || BUILD_STATUS=failed\n  kill -9 ${WAIT_PID}\n  if [ \"${BUILD_STATUS}\" != \"success\" ]; then\n    exit 1\n  fi\n  if [ -d \"${HOME}/buildx-cache\" ]; then\n    rm -rf ${HOME}/buildx-cache\n  fi\n  mkdir ${HOME}/buildx-cache\n  if [ \"${MANYLINUX_BUILD_FRONTEND}\" != \"docker\" ]; then\n    cp -rlf ./.buildx-cache-* ${HOME}/buildx-cache/\n  fi\n\ndeploy:\n  provider: script\n  dpl_version: 1.10.16\n  script: COMMIT_SHA=${TRAVIS_COMMIT} ./deploy.sh\n  on:\n    branch: main\n    repo: pypa/manylinux\n"
        },
        {
          "name": "LICENSE",
          "type": "blob",
          "size": 1.05078125,
          "content": "The MIT License (MIT)\n\nCopyright (c) 2016 manylinux\n\nPermission is hereby granted, free of charge, to any person obtaining a copy\nof this software and associated documentation files (the \"Software\"), to deal\nin the Software without restriction, including without limitation the rights\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\ncopies of the Software, and to permit persons to whom the Software is\nfurnished to do so, subject to the following conditions:\n\nThe above copyright notice and this permission notice shall be included in all\ncopies or substantial portions of the Software.\n\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\nSOFTWARE.\n"
        },
        {
          "name": "README.rst",
          "type": "blob",
          "size": 16.4560546875,
          "content": "manylinux\n=========\n\nOlder archives: https://groups.google.com/forum/#!forum/manylinux-discuss\n\nThe goal of the manylinux project is to provide a convenient way to\ndistribute binary Python extensions as wheels on Linux.\nThis effort has produced `PEP 513 <https://www.python.org/dev/peps/pep-0513/>`_ (manylinux1),\n`PEP 571 <https://www.python.org/dev/peps/pep-0571/>`_ (manylinux2010),\n`PEP 599 <https://www.python.org/dev/peps/pep-0599/>`_ (manylinux2014),\n`PEP 600 <https://www.python.org/dev/peps/pep-0600/>`_ (manylinux_x_y) and\n`PEP 656 <https://www.python.org/dev/peps/pep-0656/>`_ (musllinux_x_y).\n\nPEP 513 defined ``manylinux1_x86_64`` and ``manylinux1_i686`` platform tags\nand the wheels were built on Centos5. Centos5 reached End of Life (EOL) on\nMarch 31st, 2017.\n\nPEP 571 defined ``manylinux2010_x86_64`` and ``manylinux2010_i686`` platform\ntags and the wheels were built on Centos6. Centos6 reached End of Life (EOL)\non November 30th, 2020.\n\nPEP 599 defines the following platform tags: ``manylinux2014_x86_64``,\n``manylinux2014_i686``, ``manylinux2014_aarch64``, ``manylinux2014_armv7l``,\n``manylinux2014_ppc64``, ``manylinux2014_ppc64le`` and ``manylinux2014_s390x``.\nWheels are built on CentOS 7 which will reach End of Life (EOL) on June 30th,\n2024.\n\nPEP 600 has been designed to be \"future-proof\" and does not enforce specific symbols and a specific distro to build.\nIt only states that a wheel tagged ``manylinux_x_y`` shall work on any distro based on ``glibc>=x.y``. PEP 656 added\n``musllinux_x_y`` tags for ``musl>=x.y``.\n\nAn overview of distros per glibc version is available at `pep600_compliance <https://github.com/mayeut/pep600_compliance?tab=readme-ov-file#distro-compatibility>`_.\n\nThe manylinux project supports:\n\n- ``manylinux2014`` images for ``x86_64``, ``i686``, ``aarch64``, ``ppc64le`` and ``s390x``.\n\n- ``manylinux_2_28`` images for ``x86_64``, ``aarch64``, ``ppc64le`` and ``s390x``.\n\n- ``manylinux_2_34`` images for ``x86_64``, ``aarch64``, ``ppc64le`` and ``s390x``.\n\n- ``musllinux_1_2`` images for ``x86_64``, ``i686``, ``aarch64``, ``ppc64le``, ``s390x`` and ``armv7l``.\n\n\nWheel packages compliant with those tags can be uploaded to\n`PyPI <https://pypi.python.org>`_ (for instance with `twine\n<https://pypi.python.org/pypi/twine>`_) and can be installed with\npip:\n\n+-------------------+------------------+----------------------------+-------------------------------------------+\n| ``manylinux`` tag | Client-side pip  | CPython (sources) version  | Distribution default pip compatibility    |\n|                   | version required | embedding a compatible pip |                                           |\n+===================+==================+============================+===========================================+\n| ``manylinux_x_y`` | pip >= 20.3      | 3.8.10+, 3.9.5+, 3.10.0+   | ALT Linux 10+, RHEL 9+, Debian 11+,       |\n|                   |                  |                            | Fedora 34+, Mageia 8+,                    |\n|                   |                  |                            | Photon OS 3.0 with updates,               |\n|                   |                  |                            | Ubuntu 21.04+                             |\n+-------------------+------------------+----------------------------+-------------------------------------------+\n| ``manylinux2014`` | pip >= 19.3      | 3.7.8+, 3.8.4+, 3.9.0+     | CentOS 7 rh-python38, CentOS 8 python38,  |\n|                   |                  |                            | Fedora 32+, Mageia 8+, openSUSE 15.3+,    |\n|                   |                  |                            | Photon OS 4.0+ (3.0+ with updates),       |\n|                   |                  |                            | Ubuntu 20.04+                             |\n+-------------------+------------------+----------------------------+-------------------------------------------+\n| ``manylinux2010`` | pip >= 19.0      | 3.7.3+, 3.8.0+             | ALT Linux 9+, CentOS 7 rh-python38,       |\n|                   |                  |                            | CentOS 8 python38, Fedora 30+, Mageia 7+, |\n|                   |                  |                            | openSUSE 15.3+,                           |\n|                   |                  |                            | Photon OS 4.0+ (3.0+ with updates),       |\n|                   |                  |                            | Ubuntu 20.04+                             |\n+-------------------+------------------+----------------------------+-------------------------------------------+\n| ``manylinux1``    | pip >= 8.1.0     | 3.5.2+, 3.6.0+             | ALT Linux 8+, Amazon Linux 1+, CentOS 7+, |\n|                   |                  |                            | Debian 9+, Fedora 25+, openSUSE 15.2+,    |\n|                   |                  |                            | Mageia 7+, Photon OS 1.0+, Ubuntu 16.04+  |\n+-------------------+------------------+----------------------------+-------------------------------------------+\n\nThe various manylinux tags allow projects to distribute wheels that are\nautomatically installed (and work!) on the vast majority of desktop\nand server Linux distributions.\n\nThis repository hosts several manylinux-related things:\n\n\nDocker images\n-------------\n\nBuilding manylinux-compatible wheels is not trivial; as a general\nrule, binaries built on one Linux distro will only work on other Linux\ndistros that are the same age or newer. Therefore, if we want to make\nbinaries that run on most Linux distros, we have to use an old enough\ndistro.\n\n\nRather than forcing you to install an old distro yourself, install Python,\netc., we provide `Docker <https://docker.com/>`_ images where we've\ndone the work for you. The images are uploaded to `quay.io`_ and are tagged\nfor repeatable builds.\n\nmanylinux_2_34 (AlmaLinux 9 based)\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n\nCaveat:\nOn x86_64, RHEL 9+ derivatives are using x86-64-v2 target architecture.\nWhile manylinux worked around that when building from sources by intercepting compiler calls to target\nx86_64 instead, every library installed with dnf will most likely target the more recent x86-64-v2 which, if\ngrafted into a wheel, will fail to run on older hardware. There's no PEP to handle micro-architecture variants\nyet when it comes to packaging or installing wheels. Auditwheel doesn't detect this either.\nSee https://github.com/pypa/manylinux/issues/1725\n\nToolchain: GCC 14\n\n- x86_64 image: ``quay.io/pypa/manylinux_2_34_x86_64``\n- aarch64 image: ``quay.io/pypa/manylinux_2_34_aarch64``\n- ppc64le image: ``quay.io/pypa/manylinux_2_34_ppc64le``\n- s390x image: ``quay.io/pypa/manylinux_2_34_s390x``\n\nBuilt wheels are also expected to be compatible with other\ndistros using glibc 2.34 or later, including:\n\n- Debian 12+\n- Ubuntu 21.10+\n- Fedora 35+\n- CentOS/RHEL 9+\n\n\nmanylinux_2_28 (AlmaLinux 8 based)\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n\nToolchain: GCC 14\n\n- x86_64 image: ``quay.io/pypa/manylinux_2_28_x86_64``\n- aarch64 image: ``quay.io/pypa/manylinux_2_28_aarch64``\n- ppc64le image: ``quay.io/pypa/manylinux_2_28_ppc64le``\n- s390x image: ``quay.io/pypa/manylinux_2_28_s390x``\n\nBuilt wheels are also expected to be compatible with other\ndistros using glibc 2.28 or later, including:\n\n- Debian 10+\n- Ubuntu 18.10+\n- Fedora 29+\n- CentOS/RHEL 8+\n\n\nmanylinux2014 (CentOS 7 based, glibc 2.17)\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n\nToolchain: GCC 10\n\n- x86_64 image: ``quay.io/pypa/manylinux2014_x86_64``\n- i686 image: ``quay.io/pypa/manylinux2014_i686``\n- aarch64 image: ``quay.io/pypa/manylinux2014_aarch64``\n- ppc64le image: ``quay.io/pypa/manylinux2014_ppc64le``\n- s390x image: ``quay.io/pypa/manylinux2014_s390x``\n\nBuilt wheels are also expected to be compatible with other\ndistros using glibc 2.17 or later, including:\n\n- Debian 8+\n- Ubuntu 13.10+\n- Fedora 19+\n- RHEL 7+\n\n\nmanylinux_2_24 (Debian 9 based) - EOL\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n\nSupport for ``manylinux_2_24`` has `ended on January 1st, 2023 <https://github.com/pypa/manylinux/issues/1332>`_.\n\nThese images have some caveats mentioned in different issues.\n\nToolchain: GCC 6\n\n- x86_64 image: ``quay.io/pypa/manylinux_2_24_x86_64``\n- i686 image: ``quay.io/pypa/manylinux_2_24_i686``\n- aarch64 image: ``quay.io/pypa/manylinux_2_24_aarch64``\n- ppc64le image: ``quay.io/pypa/manylinux_2_24_ppc64le``\n- s390x image: ``quay.io/pypa/manylinux_2_24_s390x``\n\n\nmanylinux2010 (CentOS 6 based, glibc 2.12 - EOL)\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n\nSupport for ``manylinux2010`` has `ended on August 1st, 2022 <https://github.com/pypa/manylinux/issues/1281>`_.\n\nToolchain: GCC 8\n\n- x86-64 image: ``quay.io/pypa/manylinux2010_x86_64``\n- i686 image: ``quay.io/pypa/manylinux2010_i686``\n\n\nmanylinux1 (CentOS 5 based, glibc 2.5 - EOL)\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n\nCode and details regarding ``manylinux1`` can be found in the `manylinux1 tag <https://github.com/pypa/manylinux/tree/v2024.04.29-manylinux1>`_.\n\nSupport for ``manylinux1`` has `ended on January 1st, 2022 <https://github.com/pypa/manylinux/issues/994>`_.\n\nToolchain: GCC 4.8\n\n- x86-64 image: ``quay.io/pypa/manylinux1_x86_64``\n- i686 image: ``quay.io/pypa/manylinux1_i686``\n\n\nmusllinux_1_2 (Alpine Linux 3.20 based, 3.13+ compatible)\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n\nToolchain: GCC 13\n\n- x86_64 image: ``quay.io/pypa/musllinux_1_2_x86_64``\n- i686 image: ``quay.io/pypa/musllinux_1_2_i686``\n- aarch64 image: ``quay.io/pypa/musllinux_1_2_aarch64``\n- ppc64le image: ``quay.io/pypa/musllinux_1_2_ppc64le``\n- s390x image: ``quay.io/pypa/musllinux_1_2_s390x``\n- armv7l image: ``quay.io/pypa/musllinux_1_2_armv7l``\n\n\nmusllinux_1_1 (Alpine Linux 3.12 based - EOL)\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n\nSupport for ``musllinux_1_1`` has `ended on November 1st, 2024 <https://github.com/pypa/manylinux/issues/1629>`_.\n\nToolchain: GCC 9\n\n- x86_64 image: ``quay.io/pypa/musllinux_1_1_x86_64``\n- i686 image: ``quay.io/pypa/musllinux_1_1_i686``\n- aarch64 image: ``quay.io/pypa/musllinux_1_1_aarch64``\n- ppc64le image: ``quay.io/pypa/musllinux_1_1_ppc64le``\n- s390x image: ``quay.io/pypa/musllinux_1_1_s390x``\n\n\nAll supported images are rebuilt using GitHub Actions / Travis-CI on every commit to this\nrepository; see the\n`docker/ <https://github.com/pypa/manylinux/tree/main/docker>`_\ndirectory for source code.\n\n\nImage content\n~~~~~~~~~~~~~\n\nAll supported images currently contain:\n\n- CPython 3.6, 3.7, 3.8, 3.9, 3.10, 3.11, 3.12, 3.13, 3.13t and PyPy 3.7, 3.8, 3.9, 3.10 installed in\n  ``/opt/python/<python tag>-<abi tag>``. The directories are named\n  after the PEP 425 tags for each environment --\n  e.g. ``/opt/python/cp37-cp37m`` contains a CPython 3.7 build, and\n  can be used to produce wheels named like\n  ``<pkg>-<version>-cp37-cp37m-<arch>.whl``.\n\n- Development packages for all the libraries that PEP 571/599 list. One should not assume the presence of any other development package.\n\n- The following development tools, installed via `pipx <https://pypi.org/p/pipx>`_ (which is also available):\n   - `auditwheel <https://pypi.org/p/auditwheel>`_\n   - `cmake <https://pypi.org/p/cmake>`_\n   - `patchelf <https://pypi.org/p/patchelf>`_\n   - `swig <https://pypi.org/p/swig>`_\n   - `uv <https://pypi.org/p/uv>`_ (not available on ``musllinux ppc64le`` & ``musllinux s390x`` yet due to Rust limitations)\n\n- All Python interpreters have the following packages pre-installed:\n   - `pip <https://pypi.org/p/pip>`_\n   - `build <https://pypi.org/p/build>`_\n   - `packaging <https://pypi.org/p/packaging>`_\n   - Before Python 3.12, `setuptools <https://pypi.org/p/setuptools>`_ and `wheel <https://pypi.org/p/wheel>`_ are also available.\n\n- The manylinux-interpreters tool which allows to list all available interpreters & install ones missing from the image\n\n  3 commands are available:\n\n  - ``manylinux-interpreters list``\n\n    .. code-block:: bash\n\n      usage: manylinux-interpreters list [-h] [-v] [-i] [--format {text,json}]\n\n      list available or installed interpreters\n\n      options:\n        -h, --help            show this help message and exit\n        -v, --verbose         display additional information (--format=text only, ignored for --format=json)\n        -i, --installed       only list installed interpreters\n        --format {text,json}  text is not meant to be machine readable (i.e. the format is not stable)\n\n  - ``manylinux-interpreters ensure-all``\n\n    .. code-block:: bash\n\n      usage: manylinux-interpreters ensure-all [-h]\n\n      make sure all interpreters are installed\n\n      options:\n        -h, --help  show this help message and exit\n\n  - ``manylinux-interpreters ensure``\n\n    .. code-block:: bash\n\n      usage: manylinux-interpreters ensure [-h] TAG [TAG ...]\n\n      make sure a list of interpreters are installed\n\n      positional arguments:\n        TAG         tag with format '<python tag>-<abi tag>' e.g. 'pp310-pypy310_pp73'\n\n      options:\n        -h, --help  show this help message and exit\n\nNote that less common or virtually unheard of flag combinations\n(such as ``--with-pydebug`` (``d``) and ``--without-pymalloc`` (absence of ``m``)) are not provided.\n\nNote that `starting with CPython 3.8 <https://docs.python.org/dev/whatsnew/3.8.html#build-and-c-api-changes>`_,\ndefault ``sys.abiflags`` became an empty string: the ``m`` flag for pymalloc\nbecame useless (builds with and without pymalloc are ABI compatible) and so has\nbeen removed. (e.g. ``/opt/python/cp38-cp38``)\n\nNote that PyPy is not available on ppc64le & s390x or on the musllinux images.\n\nBuilding Docker images\n----------------------\n\nTo build the Docker images, please run the following command from the\ncurrent (root) directory:\n\n    $ PLATFORM=$(uname -m) POLICY=manylinux2014 COMMIT_SHA=latest ./build.sh\n\nPlease note that the default Docker build is using `buildx <https://github.com/docker/buildx>`_.\nOther frontends can be selected by defining `MANYLINUX_BUILD_FRONTEND`. See `build.sh` for\ndetails.\n\nUpdating the requirements\n-------------------------\n\nThe requirement files are pinned and controlled by uv compile. To update\nthe pins, run:\n\n    $ nox -s update_python_dependencies\n\nUpdating the native dependencies\n--------------------------------\n\nNative dependencies are all pinned in the Dockerfile. To update the pins, run the dedicated\nnox session. This will add a commit for each update. If you only want to see what would be\nupdated, you can do a dry run:\n\n    $ nox -s update_native_dependencies [-- --dry-run]\n\n\n\nExample\n-------\n\nAn example project which builds x86_64 wheels for each Python interpreter\nversion can be found here: https://github.com/pypa/python-manylinux-demo. The\nrepository also contains demo to build i686 and x86_64 wheels with ``manylinux1``\ntags.\n\nThis demonstrates how to use these docker images in conjunction with auditwheel\nto build manylinux-compatible wheels using the free `travis ci <https://travis-ci.org/>`_\ncontinuous integration service.\n\n(NB: for the i686 images running on a x86_64 host machine, it's necessary to run\neverything under the command line program `linux32`, which changes reported architecture\nin new program environment. See `this example invocation\n<https://github.com/pypa/python-manylinux-demo/blob/master/.travis.yml#L14>`_)\n\nThe PEP itself\n--------------\n\nThe official version of `PEP 513\n<https://www.python.org/dev/peps/pep-0513/>`_ is stored in the `PEP\nrepository <https://github.com/python/peps>`_, but we also have our\n`own copy here\n<https://github.com/pypa/manylinux/tree/main/pep-513.rst>`_. This is\nwhere the PEP was originally written, so if for some reason you really\nwant to see the full history of edits it went through, then this is\nthe place to look.\n\nThe proposal to upgrade ``manylinux1`` to ``manylinux2010`` after Centos5\nreached EOL was discussed in `PEP 571 <https://www.python.org/dev/peps/pep-0571/>`_.\n\nThe proposal to upgrade ``manylinux2010`` to ``manylinux2014`` was\ndiscussed in `PEP 599 <https://www.python.org/dev/peps/pep-0599/>`_.\n\nThe proposal for a \"future-proof\" ``manylinux_x_y`` definition was\ndiscussed in `PEP 600 <https://www.python.org/dev/peps/pep-0600/>`_.\n\nThis repo also has some analysis code that was used when putting\ntogether the original proposal in the ``policy-info/`` directory.\n\nIf you want to read the full discussion that led to the original\npolicy, then lots of that is here:\nhttps://groups.google.com/forum/#!forum/manylinux-discuss\n\nThe distutils-sig archives for January 2016 also contain several\nthreads.\n\n\nCode of Conduct\n===============\n\nEveryone interacting in the manylinux project's codebases, issue\ntrackers, chat rooms, and mailing lists is expected to follow the\n`PSF Code of Conduct`_.\n\n.. _PSF Code of Conduct: https://github.com/pypa/.github/blob/main/CODE_OF_CONDUCT.md\n.. _`quay.io`: https://quay.io/organization/pypa\n"
        },
        {
          "name": "build.sh",
          "type": "blob",
          "size": 3.6083984375,
          "content": "#!/bin/bash\n\n# Stop at any error, show all commands\nset -exuo pipefail\n\nif [ \"${MANYLINUX_BUILD_FRONTEND:-}\" == \"\" ]; then\n\tMANYLINUX_BUILD_FRONTEND=\"docker-buildx\"\nfi\n\n# Export variable needed by 'docker build --build-arg'\nexport POLICY\nexport PLATFORM\n\n# get docker default multiarch image prefix for PLATFORM\ncase \"${PLATFORM}\" in\n\tx86_64) GOARCH=\"amd64\";;\n\ti686) GOARCH=\"386\";;\n\taarch64) GOARCH=\"arm64\";;\n\tppc64le) GOARCH=\"ppc64le\";;\n\ts390x) GOARCH=\"s390x\";;\n\tarmv7l) GOARCH=\"arm/v7\";;\n\t*) echo \"Unsupported platform: '${PLATFORM}'\"; exit 1;;\nesac\n\n# setup BASEIMAGE and its specific properties\nif [ \"${POLICY}\" == \"manylinux2014\" ]; then\n\tBASEIMAGE=\"quay.io/pypa/manylinux2014_base:2024.11.03-3\"\n\tDEVTOOLSET_ROOTPATH=\"/opt/rh/devtoolset-10/root\"\n\tPREPEND_PATH=\"${DEVTOOLSET_ROOTPATH}/usr/bin:\"\n\tif [ \"${PLATFORM}\" == \"i686\" ]; then\n\t\tLD_LIBRARY_PATH_ARG=\"${DEVTOOLSET_ROOTPATH}/usr/lib:${DEVTOOLSET_ROOTPATH}/usr/lib/dyninst\"\n\telse\n\t\tLD_LIBRARY_PATH_ARG=\"${DEVTOOLSET_ROOTPATH}/usr/lib64:${DEVTOOLSET_ROOTPATH}/usr/lib:${DEVTOOLSET_ROOTPATH}/usr/lib64/dyninst:${DEVTOOLSET_ROOTPATH}/usr/lib/dyninst:/usr/local/lib64\"\n\tfi\nelif [ \"${POLICY}\" == \"manylinux_2_28\" ]; then\n\tBASEIMAGE=\"almalinux:8\"\n\tDEVTOOLSET_ROOTPATH=\"/opt/rh/gcc-toolset-14/root\"\n\tPREPEND_PATH=\"${DEVTOOLSET_ROOTPATH}/usr/bin:\"\n\tLD_LIBRARY_PATH_ARG=\"${DEVTOOLSET_ROOTPATH}/usr/lib64:${DEVTOOLSET_ROOTPATH}/usr/lib:${DEVTOOLSET_ROOTPATH}/usr/lib64/dyninst:${DEVTOOLSET_ROOTPATH}/usr/lib/dyninst\"\nelif [ \"${POLICY}\" == \"manylinux_2_34\" ]; then\n\tBASEIMAGE=\"almalinux:9\"\n\tDEVTOOLSET_ROOTPATH=\"/opt/rh/gcc-toolset-14/root\"\n\tPREPEND_PATH=\"/usr/local/bin:${DEVTOOLSET_ROOTPATH}/usr/bin:\"\n\tLD_LIBRARY_PATH_ARG=\"${DEVTOOLSET_ROOTPATH}/usr/lib64:${DEVTOOLSET_ROOTPATH}/usr/lib:${DEVTOOLSET_ROOTPATH}/usr/lib64/dyninst:${DEVTOOLSET_ROOTPATH}/usr/lib/dyninst\"\nelif [ \"${POLICY}\" == \"musllinux_1_2\" ]; then\n\tBASEIMAGE=\"alpine:3.20\"\n\tDEVTOOLSET_ROOTPATH=\n\tPREPEND_PATH=\n\tLD_LIBRARY_PATH_ARG=\nelse\n\techo \"Unsupported policy: '${POLICY}'\"\n\texit 1\nfi\nexport BASEIMAGE\nexport DEVTOOLSET_ROOTPATH\nexport PREPEND_PATH\nexport LD_LIBRARY_PATH_ARG\n\nBUILD_ARGS_COMMON=(\n\t\"--platform=linux/${GOARCH}\"\n\t--build-arg POLICY --build-arg PLATFORM --build-arg BASEIMAGE\n\t--build-arg DEVTOOLSET_ROOTPATH --build-arg PREPEND_PATH --build-arg LD_LIBRARY_PATH_ARG\n\t--rm -t \"quay.io/pypa/${POLICY}_${PLATFORM}:${COMMIT_SHA}\"\n\t-f docker/Dockerfile docker/\n)\n\nif [ \"${CI:-}\" == \"true\" ]; then\n\t# Force plain output on CI\n\tBUILD_ARGS_COMMON=(--progress plain \"${BUILD_ARGS_COMMON[@]}\")\n\t# Workaround issue on ppc64le\n\tif [ \"${PLATFORM}\" == \"ppc64le\" ] && [ \"${MANYLINUX_BUILD_FRONTEND}\" == \"docker\" ]; then\n\t\tBUILD_ARGS_COMMON=(--network host \"${BUILD_ARGS_COMMON[@]}\")\n\tfi\nfi\n\nUSE_LOCAL_CACHE=0\nif [ \"${MANYLINUX_BUILD_FRONTEND}\" == \"docker\" ]; then\n\tdocker build \"${BUILD_ARGS_COMMON[@]}\"\nelif [ \"${MANYLINUX_BUILD_FRONTEND}\" == \"podman\" ]; then\n\tpodman build \"${BUILD_ARGS_COMMON[@]}\"\nelif [ \"${MANYLINUX_BUILD_FRONTEND}\" == \"docker-buildx\" ]; then\n\tUSE_LOCAL_CACHE=1\n\tdocker buildx build \\\n\t\t--load \\\n\t\t\"--cache-from=type=local,src=$(pwd)/.buildx-cache-${POLICY}_${PLATFORM}\" \\\n\t\t\"--cache-to=type=local,dest=$(pwd)/.buildx-cache-staging-${POLICY}_${PLATFORM},mode=max\" \\\n\t\t\"${BUILD_ARGS_COMMON[@]}\"\nelse\n\techo \"Unsupported build frontend: '${MANYLINUX_BUILD_FRONTEND}'\"\n\texit 1\nfi\n\ndocker run --rm -v \"$(pwd)/tests:/tests:ro\" \"quay.io/pypa/${POLICY}_${PLATFORM}:${COMMIT_SHA}\" /tests/run_tests.sh\n\nif [ ${USE_LOCAL_CACHE} -ne 0 ]; then\n\tif [ -d \"$(pwd)/.buildx-cache-${POLICY}_${PLATFORM}\" ]; then\n\t\trm -rf \"$(pwd)/.buildx-cache-${POLICY}_${PLATFORM}\"\n\tfi\n\tmv \"$(pwd)/.buildx-cache-staging-${POLICY}_${PLATFORM}\" \"$(pwd)/.buildx-cache-${POLICY}_${PLATFORM}\"\nfi\n"
        },
        {
          "name": "deploy.sh",
          "type": "blob",
          "size": 0.9912109375,
          "content": "#!/bin/bash\n\nset -euo pipefail\n\nexport TZ=UTC0\n\nDRY_RUN=0\nif [ \"${1:-}\" == \"--dry-run\" ]; then\n  DRY_RUN=1\nfi\n\nset -x\n\nTAG=\"quay.io/pypa/${POLICY}_${PLATFORM}\"\nCOMMIT_ABBREV_SHA=$(git show -s --format=%h \"${COMMIT_SHA}\")\nCOMMIT_DATE=$(git show -s --format=%cd --date=short \"${COMMIT_SHA}\")\nBUILD_ID=${COMMIT_DATE}-${COMMIT_ABBREV_SHA}\n# Dependabot does not work with the BUILD_ID format\n# Use a version like tag\nif eval \"$(git rev-parse --is-shallow-repository)\"; then\n  git fetch --unshallow\nfi\nBUILD_NUMBER=$(git rev-list \"--since=${COMMIT_DATE}T00:00:00Z\" --first-parent --count \"${COMMIT_SHA}\")\nBUILD_ID2=${COMMIT_DATE//-/.}-${BUILD_NUMBER}\n\ndocker tag \"${TAG}:${COMMIT_SHA}\" \"${TAG}:${BUILD_ID}\"\ndocker tag \"${TAG}:${COMMIT_SHA}\" \"${TAG}:${BUILD_ID2}\"\ndocker tag \"${TAG}:${COMMIT_SHA}\" \"${TAG}:latest\"\n\nset +x\n\nif [ $DRY_RUN -eq 0 ]; then\n  docker login -u \"${QUAY_USERNAME}\" -p \"${QUAY_PASSWORD}\" quay.io\n  docker push \"${TAG}:${BUILD_ID}\"\n  docker push \"${TAG}:${BUILD_ID2}\"\n  docker push \"${TAG}:latest\"\nfi\n"
        },
        {
          "name": "docker",
          "type": "tree",
          "content": null
        },
        {
          "name": "noxfile.py",
          "type": "blob",
          "size": 2.7802734375,
          "content": "import os\nfrom pathlib import Path\n\nimport nox\n\nnox.needs_version = \">=2024.4.15\"\nnox.options.default_venv_backend = \"uv|virtualenv\"\nnox.options.sessions = [\"lint\"]\n\n\n@nox.session\ndef update_python_dependencies(session):\n    \"\"\"Update the base and per-python dependencies lock files\"\"\"\n    if getattr(session.virtualenv, \"venv_backend\", \"\") != \"uv\":\n        session.install(\"uv>=0.1.23\")\n\n    env = os.environ.copy()\n    # CUSTOM_COMPILE_COMMAND is a pip-compile option that tells users how to\n    # regenerate the constraints files\n    env[\"UV_CUSTOM_COMPILE_COMMAND\"] = f\"nox -s {session.name}\"\n\n    for python_minor in range(7, 14):\n        python_version = f\"3.{python_minor}\"\n        session.run(\n            \"uv\",\n            \"pip\",\n            \"compile\",\n            f\"--python-version={python_version}\",\n            \"--generate-hashes\",\n            \"--no-strip-markers\",\n            \"requirements.in\",\n            \"--upgrade\",\n            \"--output-file\",\n            f\"docker/build_scripts/requirements{python_version}.txt\",\n            env=env,\n        )\n\n    # tools\n    python_version = \"3.12\"\n    session.run(\n        \"uv\",\n        \"pip\",\n        \"compile\",\n        f\"--python-version={python_version}\",\n        \"--generate-hashes\",\n        \"requirements-base-tools.in\",\n        \"--upgrade\",\n        \"--output-file\",\n        \"docker/build_scripts/requirements-base-tools.txt\",\n        env=env,\n    )\n    tools = Path(\"requirements-tools.in\").read_text().split(\"\\n\")\n    for tool in tools:\n        if tool.strip() == \"\":\n            continue\n        tmp_file = Path(session.create_tmp()) / f\"{tool}.in\"\n        tmp_file.write_text(f\"{tool}\\n\")\n        session.run(\n            \"uv\",\n            \"pip\",\n            \"compile\",\n            f\"--python-version={python_version}\",\n            \"--generate-hashes\",\n            str(tmp_file),\n            \"--upgrade\",\n            \"--output-file\",\n            f\"docker/build_scripts/requirements-tools/{tool}\",\n            env=env,\n        )\n\n\n@nox.session(python=\"3.12\", reuse_venv=True)\ndef update_native_dependencies(session):\n    \"\"\"Update the native dependencies\"\"\"\n    script = \"tools/update_native_dependencies.py\"\n    deps = nox.project.load_toml(script)[\"dependencies\"]\n    session.install(*deps)\n    session.run(\"python\", script, *session.posargs)\n\n\n@nox.session(python=\"3.12\", reuse_venv=True)\ndef update_interpreters_download(session):\n    \"\"\"Update all the Python interpreters\"\"\"\n    script = \"tools/update_interpreters_download.py\"\n    deps = nox.project.load_toml(script)[\"dependencies\"]\n    session.install(*deps)\n    session.run(\"python\", script, *session.posargs)\n\n\n@nox.session(python=\"3.12\", reuse_venv=True)\ndef lint(session: nox.Session) -> None:\n    \"\"\"Run linters on the codebase.\"\"\"\n    session.install(\"pre-commit\")\n    session.run(\"pre-commit\", \"run\", \"--all-files\")\n"
        },
        {
          "name": "pep-513.rst",
          "type": "blob",
          "size": 26.7724609375,
          "content": "PEP: 513\nTitle: A Platform Tag for Portable Linux Built Distributions\nVersion: $Revision$\nLast-Modified: $Date$\nAuthor: Robert T. McGibbon <rmcgibbo@gmail.com>, Nathaniel J. Smith <njs@pobox.com>\nBDFL-Delegate: Nick Coghlan <ncoghlan@gmail.com>\nDiscussions-To: Distutils SIG <distutils-sig@python.org>\nStatus: Active\nType: Informational\nContent-Type: text/x-rst\nCreated: 19-Jan-2016\nPost-History: 19-Jan-2016, 25-Jan-2016, 29-Jan-2016\nResolution: https://mail.python.org/pipermail/distutils-sig/2016-January/028211.html\n\n\nAbstract\n========\n\nThis PEP proposes the creation of a new platform tag for Python package built\ndistributions, such as wheels, called ``manylinux1_{x86_64,i686}`` with\nexternal dependencies limited to a standardized, restricted subset of\nthe Linux kernel and core userspace ABI. It proposes that PyPI support\nuploading and distributing wheels with this platform tag, and that ``pip``\nsupport downloading and installing these packages on compatible platforms.\n\n\nRationale\n=========\n\nCurrently, distribution of binary Python extensions for Windows and OS X is\nstraightforward. Developers and packagers build wheels [1]_ [2]_, which are\nassigned platform tags such as ``win32`` or ``macosx_10_6_intel``, and upload\nthese wheels to PyPI. Users can download and install these wheels using tools\nsuch as ``pip``.\n\nFor Linux, the situation is much more delicate. In general, compiled Python\nextension modules built on one Linux distribution will not work on other Linux\ndistributions, or even on different machines running the same Linux\ndistribution with different system libraries installed.\n\nBuild tools using PEP 425 platform tags [3]_ do not track information about the\nparticular Linux distribution or installed system libraries, and instead assign\nall wheels the too-vague ``linux_i686`` or ``linux_x86_64`` tags. Because of\nthis ambiguity, there is no expectation that ``linux``-tagged built\ndistributions compiled on one machine will work properly on another, and for\nthis reason, PyPI has not permitted the uploading of wheels for Linux.\n\nIt would be ideal if wheel packages could be compiled that would work on *any*\nlinux system. But, because of the incredible diversity of Linux systems -- from\nPCs to Android to embedded systems with custom libcs -- this cannot\nbe guaranteed in general.\n\nInstead, we define a standard subset of the kernel+core userspace ABI that,\nin practice, is compatible enough that packages conforming to this standard\nwill work on *many* linux systems, including essentially all of the desktop\nand server distributions in common use. We know this because there are\ncompanies who have been distributing such widely-portable pre-compiled Python\nextension modules for Linux -- e.g. Enthought with Canopy [4]_ and Continuum\nAnalytics with Anaconda [5]_.\n\nBuilding on the compatibility lessons learned from these companies, we thus\ndefine a baseline ``manylinux1`` platform tag for use by binary Python\nwheels, and introduce the implementation of preliminary tools to aid in the\nconstruction of these ``manylinux1`` wheels.\n\n\nKey Causes of Inter-Linux Binary Incompatibility\n================================================\n\nTo properly define a standard that will guarantee that wheel packages meeting\nthis specification will operate on *many* linux platforms, it is necessary to\nunderstand the root causes which often prevent portability of pre-compiled\nbinaries on Linux. The two key causes are dependencies on shared libraries\nwhich are not present on users' systems, and dependencies on particular\nversions of certain core libraries like ``glibc``.\n\n\nExternal Shared Libraries\n-------------------------\n\nMost desktop and server linux distributions come with a system package manager\n(examples include ``APT`` on Debian-based systems, ``yum`` on\n``RPM``-based systems, and ``pacman`` on Arch linux) that manages, among other\nresponsibilities, the installation of shared libraries installed to system\ndirectories such as ``/usr/lib``. Most non-trivial Python extensions will depend\non one or more of these shared libraries, and thus function properly only on\nsystems where the user has the proper libraries (and the proper\nversions thereof), either installed using their package manager, or installed\nmanually by setting certain environment variables such as ``LD_LIBRARY_PATH``\nto notify the runtime linker of the location of the depended-upon shared\nlibraries.\n\n\nVersioning of Core Shared Libraries\n-----------------------------------\n\nEven if the developers a Python extension module wish to use no\nexternal shared libraries, the modules will generally have a dynamic runtime\ndependency on the GNU C library, ``glibc``. While it is possible, statically\nlinking ``glibc`` is usually a bad idea because certain important C functions\nlike ``dlopen()`` cannot be called from code that statically links ``glibc``. A\nruntime shared library dependency on a system-provided ``glibc`` is unavoidable\nin practice.\n\nThe maintainers of the GNU C library follow a strict symbol versioning scheme\nfor backward compatibility. This ensures that binaries compiled against an older\nversion of ``glibc`` can run on systems that have a newer ``glibc``. The\nopposite is generally not true -- binaries compiled on newer Linux\ndistributions tend to rely upon versioned functions in ``glibc`` that are not\navailable on older systems.\n\nThis generally prevents wheels compiled on the latest Linux distributions\nfrom being portable.\n\n\nThe ``manylinux1`` policy\n=========================\n\nFor these reasons, to achieve broad portability, Python wheels\n\n* should depend only on an extremely limited set of external shared\n  libraries; and\n* should depend only on \"old\" symbol versions in those external shared\n  libraries; and\n* should depend only on a widely-compatible kernel ABI.\n\nTo be eligible for the ``manylinux1`` platform tag, a Python wheel must\ntherefore both (a) contain binary executables and compiled code that links\n*only* to libraries with SONAMEs\nincluded in the following list: ::\n\n    libpanelw.so.5\n    libncursesw.so.5\n    libgcc_s.so.1\n    libstdc++.so.6\n    libm.so.6\n    libdl.so.2\n    librt.so.1\n    libcrypt.so.1\n    libc.so.6\n    libnsl.so.1\n    libutil.so.1\n    libpthread.so.0\n    libX11.so.6\n    libXext.so.6\n    libXrender.so.1\n    libICE.so.6\n    libSM.so.6\n    libGL.so.1\n    libgobject-2.0.so.0\n    libgthread-2.0.so.0\n    libglib-2.0.so.0\n\nand, (b) work on a stock CentOS 5.11 [6]_ system that contains the system\npackage manager's provided versions of these libraries.\n\nBecause CentOS 5 is only available for x86_64 and i686 architectures,\nthese are the only architectures currently supported by the ``manylinux1``\npolicy.\n\nOn Debian-based systems, these libraries are provided by the packages ::\n\n    libncurses5 libgcc1 libstdc++6 libc6 libx11-6 libxext6\n    libxrender1 libice6 libsm6 libgl1-mesa-glx libglib2.0-0\n\nOn RPM-based systems, these libraries are provided by the packages ::\n\n    ncurses libgcc libstdc++ glibc libXext libXrender\n    libICE libSM mesa-libGL glib2\n\nThis list was compiled by checking the external shared library dependencies of\nthe Canopy [4]_ and Anaconda [5]_ distributions, which both include a wide array\nof the most popular Python modules and have been confirmed in practice to work\nacross a wide swath of Linux systems in the wild.\n\nMany of the permitted system libraries listed above use symbol versioning\nschemes for backward compatibility. The latest symbol versions provided with\nthe CentOS 5.11 versions of these libraries are: ::\n\n    GLIBC_2.5\n    CXXABI_3.4.8\n    GLIBCXX_3.4.9\n    GCC_4.2.0\n\nTherefore, as a consequence of requirement (b), any wheel that depends on\nversioned symbols from the above shared libraries may depend only on symbols\nwith the following versions: ::\n\n    GLIBC <= 2.5\n    CXXABI <= 3.4.8\n    GLIBCXX <= 3.4.9\n    GCC <= 4.2.0\n\nThese recommendations are the outcome of the relevant discussions in January\n2016 [7]_, [8]_.\n\nNote that in our recommendations below, we do not suggest that ``pip``\nor PyPI should attempt to check for and enforce the details of this\npolicy (just as they don't check for and enforce the details of\nexisting platform tags like ``win32``). The text above is provided (a)\nas advice to package builders, and (b) as a method for allocating\nblame if a given wheel doesn't work on some system: if it satisfies\nthe policy above, then this is a bug in the spec or the installation\ntool; if it does not satisfy the policy above, then it's a bug in the\nwheel. One useful consequence of this approach is that it leaves open\nthe possibility of further updates and tweaks as we gain more\nexperience, e.g., we could have a \"manylinux 1.1\" policy which targets\nthe same systems and uses the same ``manylinux1`` platform tag (and\nthus requires no further changes to ``pip`` or PyPI), but that adjusts\nthe list above to remove libraries that have turned out to be\nproblematic or add libraries that have turned out to be safe.\n\n\nlibpythonX.Y.so.1\n-----------------\n\nNote that ``libpythonX.Y.so.1`` is *not* on the list of libraries that\na ``manylinux1`` extension is allowed to link to. Explicitly linking\nto ``libpythonX.Y.so.1`` is unnecessary in almost all cases: the way\nELF linking works, extension modules that are loaded into the\ninterpreter automatically get access to all of the interpreter's\nsymbols, regardless of whether or not the extension itself is\nexplicitly linked against libpython. Furthermore, explicit linking to\nlibpython creates problems in the common configuration where Python is\nnot built with ``--enable-shared``. In particular, on Debian and\nUbuntu systems, ``apt install pythonX.Y`` does not even install\n``libpythonX.Y.so.1``, meaning that any wheel that *did* depend on\n``libpythonX.Y.so.1`` could fail to import.\n\nThere is one situation where extensions that are linked in this way\ncan fail to work: if a host program (e.g., ``apache2``) uses\n``dlopen()`` to load a module (e.g., ``mod_wsgi``) that embeds the\nCPython interpreter, and the host program does *not* pass the\n``RTLD_GLOBAL`` flag to ``dlopen()``, then the embedded CPython will\nbe unable to load any extension modules that do not themselves link\nexplicitly to ``libpythonX.Y.so.1``. Fortunately, ``apache2`` *does*\nset the ``RTLD_GLOBAL`` flag, as do all the other programs that\nembed-CPython-via-a-dlopened-plugin that we could locate, so this does\nnot seem to be a serious problem in practice. The incompatibility with\nDebian/Ubuntu is more of an issue than the theoretical incompatibility\nwith a rather obscure corner case.\n\nThis is a rather complex and subtle issue that extends beyond\nthe scope of ``manylinux1``; for more discussion see: [9]_, [10]_,\n[11]_.\n\nUCS-2 vs UCS-4 builds\n---------------------\n\nAll versions of CPython 2.x, plus CPython 3.0-3.2 inclusive, can be\nbuilt in two ABI-incompatible modes: builds using the\n``--enable-unicode=ucs2`` configure flag store Unicode data in UCS-2\n(or really UTF-16) format, while builds using the\n``--enable-unicode=ucs4`` configure flag store Unicode data in\nUCS-4. (CPython 3.3 and greater use a different storage method that\nalways supports UCS-4.) If we want to make sure ``ucs2`` wheels don't\nget installed into ``ucs4`` CPythons and vice-versa, then something\nmust be done.\n\nAn earlier version of this PEP included a requirement that\n``manylinux1`` wheels targeting these older CPython versions should\nalways use the ``ucs4`` ABI. But then, in between the PEP's initial\nacceptance and its implementation, ``pip`` and ``wheel`` gained\nfirst-class support for tracking and checking this aspect of ABI\ncompatibility for the relevant CPython versions, which is a better\nsolution. So we now allow the ``manylinux1`` platform tags to be used\nin combination with any ABI tag. However, to maintain compatibility it\nis crucial to ensure that all ``manylinux1`` wheels include a\nnon-trivial abi tag. For example, a wheel built against a ``ucs4``\nCPython might have a name like::\n\n  PKG-VERSION-cp27-cp27mu-manylinux1_x86_64.whl\n                   ^^^^^^ Good!\n\nWhile a wheel built against the ``ucs2`` ABI might have a name like::\n\n  PKG-VERSION-cp27-cp27m-manylinux1_x86_64.whl\n                   ^^^^^ Okay!\n\nBut you should never have a wheel with a name like::\n\n  PKG-VERSION-cp27-none-manylinux1_x86_64.whl\n                   ^^^^ BAD! Don't do this!\n\nWe note for information that the ``ucs4`` ABI appears to be much more\nwidespread among Linux CPython distributors.\n\n\nCompilation of Compliant Wheels\n===============================\n\nThe way glibc, libgcc, and libstdc++ manage their symbol versioning\nmeans that in practice, the compiler toolchains that most developers\nuse to do their daily work are incapable of building\n``manylinux1``-compliant wheels. Therefore we do not attempt to change\nthe default behavior of ``pip wheel`` / ``bdist_wheel``: they will\ncontinue to generate regular ``linux_*`` platform tags, and developers\nwho wish to use them to generate ``manylinux1``-tagged wheels will\nhave to change the tag as a second post-processing step.\n\nTo support the compilation of wheels meeting the ``manylinux1`` standard, we\nprovide initial drafts of two tools.\n\n\nDocker Image\n------------\n\nThe first tool is a Docker image based on CentOS 5.11, which is recommended as\nan easy to use self-contained build box for compiling ``manylinux1`` wheels\n[12]_. Compiling on a more recently-released linux distribution will generally\nintroduce dependencies on too-new versioned symbols. The image comes with a\nfull compiler suite installed (``gcc``, ``g++``, and ``gfortran`` 4.8.2) as\nwell as the latest releases of Python and ``pip``.\n\nAuditwheel\n----------\n\nThe second tool is a command line executable called ``auditwheel`` [13]_ that\nmay aid in package maintainers in dealing with third-party external\ndependencies.\n\nThere are at least three methods for building wheels that use third-party\nexternal libraries in a way that meets the above policy.\n\n1. The third-party libraries can be statically linked.\n2. The third-party shared libraries can be distributed in\n   separate packages on PyPI which are depended upon by the wheel.\n3. The third-party shared libraries can be bundled inside the wheel\n   libraries, linked with a relative path.\n\nAll of these are valid option which may be effectively used by different\npackages and communities. Statically linking generally requires\npackage-specific modifications to the build system, and distributing\nthird-party dependencies on PyPI may require some coordination of the\ncommunity of users of the package.\n\nAs an often-automatic alternative to these options, we introduce ``auditwheel``.\nThe tool inspects all of the ELF files  inside a wheel to check for\ndependencies on versioned symbols or external  shared libraries, and verifies\nconformance with the ``manylinux1`` policy. This  includes the ability to add\nthe new platform tag to conforming wheels. More importantly, ``auditwheel`` has\nthe ability to automatically modify wheels that depend on external shared\nlibraries by copying those shared libraries from the system into the wheel\nitself, and modifying the appropriate ``RPATH`` entries such that these\nlibraries will be picked up at runtime. This accomplishes a similar result as\nif the libraries had been statically linked without requiring changes to the\nbuild system. Packagers are advised that bundling, like static linking, may\nimplicate copyright concerns.\n\n\nBundled Wheels on Linux\n=======================\n\nWhile we acknowledge many approaches for dealing with third-party library\ndependencies within ``manylinux1`` wheels, we recognize that the ``manylinux1``\npolicy encourages bundling external dependencies, a practice\nwhich runs counter to  the package management policies of many linux\ndistributions' system package  managers [14]_, [15]_. The primary purpose of\nthis is cross-distro compatibility.  Furthermore, ``manylinux1`` wheels on PyPI\noccupy a different  niche than the Python packages available through the\nsystem package manager.\n\nThe decision in this PEP to encourage departure from general Linux distribution\nunbundling policies is informed by the following concerns:\n\n1. In these days of automated continuous integration and deployment\n   pipelines, publishing new versions and updating dependencies is easier\n   than it was when those policies were defined.\n2. ``pip`` users remain free to use the ``\"--no-binary\"`` option if they want\n   to force local builds rather than using pre-built wheel files.\n3. The popularity of modern container based deployment and \"immutable\n   infrastructure\" models involve substantial bundling at the application\n   layer anyway.\n4. Distribution of bundled wheels through PyPI is currently the norm for\n   Windows and OS X.\n5. This PEP doesn't rule out the idea of offering more targeted binaries for\n   particular Linux distributions in the future.\n\nThe model described in this PEP is most ideally suited for cross-platform\nPython packages, because it means they can reuse much of the\nwork that they're already doing to make static Windows and OS X wheels. We\nrecognize that it is less optimal for Linux-specific packages that might\nprefer to interact more closely with Linux's unique package management\nfunctionality and only care about targeting a small set of particular distos.\n\n\nSecurity Implications\n---------------------\n\nOne of the advantages of dependencies on centralized libraries in Linux is\nthat bugfixes and security updates can be deployed system-wide, and\napplications which depend on these libraries will automatically feel the\neffects of these patches when the underlying libraries are updated. This can\nbe particularly important for security updates in packages engaged in\ncommunication across the network or cryptography.\n\n``manylinux1`` wheels distributed through PyPI that bundle security-critical\nlibraries like OpenSSL will thus assume responsibility for prompt updates in\nresponse disclosed vulnerabilities and patches. This closely parallels the\nsecurity implications of the distribution of binary wheels on Windows that,\nbecause the platform lacks a system package manager, generally bundle their\ndependencies. In particular, because it lacks a stable ABI, OpenSSL cannot be\nincluded in the ``manylinux1`` profile.\n\n\n\nPlatform Detection for Installers\n=================================\n\nAbove, we defined what it means for a *wheel* to be\n``manylinux1``-compatible. Here we discuss what it means for a *Python\ninstallation* to be ``manylinux1``-compatible. In particular, this is\nimportant for tools like ``pip`` to know when deciding whether or not\nthey should consider ``manylinux1``-tagged wheels for installation.\n\nBecause the ``manylinux1`` profile is already known to work for the\nmany thousands of users of popular commercial Python distributions, we\nsuggest that installation tools should error on the side of assuming\nthat a system *is* compatible, unless there is specific reason to\nthink otherwise.\n\nWe know of four main sources of potential incompatibility that are\nlikely to arise in practice:\n\n* Eventually, in the future, there may exist distributions that break\n  compatibility with this profile (e.g., if one of the libraries in\n  the profile changes its ABI in a backwards-incompatible way)\n* A linux distribution that is too old (e.g. RHEL 4)\n* A linux distribution that does not use ``glibc`` (e.g. Alpine Linux, which is\n  based on musl ``libc``, or Android)\n\nTo address these we propose a two-pronged\napproach. To handle potential future incompatibilities, we standardize\na mechanism for a Python distributor to signal that a particular\nPython install definitely is or is not compatible with ``manylinux1``:\nthis is done by installing a module named ``_manylinux``, and setting\nits ``manylinux1_compatible`` attribute. We do not propose adding any\nsuch module to the standard library -- this is merely a well-known\nname by which distributors and installation tools can\nrendezvous. However, if a distributor does add this module, *they\nshould add it to the standard library* rather than to a\n``site-packages/`` directory, because the standard library is\ninherited by virtualenvs (which we want), and ``site-packages/`` in\ngeneral is not.\n\nThen, to handle the last two cases for existing Python\ndistributions, we suggest a simple and reliable method to check for\nthe presence and version of ``glibc`` (basically using it as a \"clock\"\nfor the overall age of the distribution).\n\nSpecifically, the algorithm we propose is::\n\n    def is_manylinux1_compatible():\n        # Only Linux, and only x86-64 / i686\n        from distutils.util import get_platform\n        if get_platform() not in [\"linux-x86_64\", \"linux-i686\"]:\n            return False\n\n        # Check for presence of _manylinux module\n        try:\n            import _manylinux\n            return bool(_manylinux.manylinux1_compatible)\n        except (ImportError, AttributeError):\n            # Fall through to heuristic check below\n            pass\n\n        # Check glibc version. CentOS 5 uses glibc 2.5.\n        return have_compatible_glibc(2, 5)\n\n    def have_compatible_glibc(major, minimum_minor):\n        import ctypes\n\n        process_namespace = ctypes.CDLL(None)\n        try:\n            gnu_get_libc_version = process_namespace.gnu_get_libc_version\n        except AttributeError:\n            # Symbol doesn't exist -> therefore, we are not linked to\n            # glibc.\n            return False\n\n        # Call gnu_get_libc_version, which returns a string like \"2.5\".\n        gnu_get_libc_version.restype = ctypes.c_char_p\n        version_str = gnu_get_libc_version()\n        # py2 / py3 compatibility:\n        if not isinstance(version_str, str):\n            version_str = version_str.decode(\"ascii\")\n\n        # Parse string and check against requested version.\n        version = [int(piece) for piece in version_str.split(\".\")]\n        assert len(version) == 2\n        if major != version[0]:\n            return False\n        if minimum_minor > version[1]:\n            return False\n        return True\n\n**Rejected alternatives:** We also considered using a configuration\nfile, e.g. ``/etc/python/compatibility.cfg``. The problem with this is\nthat a single filesystem might contain many different interpreter\nenvironments, each with their own ABI profile -- the ``manylinux1``\ncompatibility of a system-installed x86_64 CPython might not tell us\nmuch about the ``manylinux1`` compatibility of a user-installed i686\nPyPy. Locating this configuration information within the Python\nenvironment itself ensures that it remains attached to the correct\nbinary, and dramatically simplifies lookup code.\n\nWe also considered using a more elaborate structure, like a list of\nall platform tags that should be considered compatible, together with\ntheir preference ordering, for example: ``_binary_compat.compatible =\n[\"manylinux1_x86_64\", \"centos5_x86_64\", \"linux_x86_64\"]``. However,\nthis introduces several complications. For example, we want to be able\nto distinguish between the state of \"doesn't support ``manylinux1``\"\n(or eventually ``manylinux2``, etc.) versus \"doesn't specify either\nway whether it supports ``manylinux1``\", which is not entirely obvious\nin the above representation; and, it's not at all clear what features\nare really needed vis a vis preference ordering given that right now\nthe only possible platform tags are ``manylinux1`` and ``linux``.  So\nwe're deferring a more complete solution here for a separate PEP, when\n/ if Linux gets more platform tags.\n\nFor the library compatibility check, we also considered much more\nelaborate checks (e.g. checking the kernel version, searching for and\nchecking the versions of all the individual libraries listed in the\n``manylinux1`` profile, etc.), but ultimately decided that this would\nbe more likely to introduce confusing bugs than actually help the\nuser. (For example: different distributions vary in where they\nactually put these libraries, and if our checking code failed to use\nthe correct path search then it could easily return incorrect\nanswers.)\n\n\n\nPyPI Support\n============\n\nPyPI should permit wheels containing the ``manylinux1`` platform tag to be\nuploaded. PyPI should not attempt to formally verify that wheels containing\nthe ``manylinux1`` platform tag adhere to the ``manylinux1`` policy described\nin this document. This verification tasks should be left to other tools, like\n``auditwheel``, that are developed separately.\n\n\nRejected Alternatives\n=====================\n\nOne alternative would be to provide separate platform tags for each Linux\ndistribution (and each version thereof), e.g. ``RHEL6``, ``ubuntu14_10``,\n``debian_jessie``, etc. Nothing in this proposal rules out the possibility of\nadding such platform tags in the future, or of further extensions to wheel\nmetadata that would allow wheels to declare dependencies on external\nsystem-installed packages. However, such extensions would require substantially\nmore work than this proposal, and still might not be appreciated by package\ndevelopers who would prefer not to have to maintain multiple build environments\nand build multiple wheels in order to cover all the common Linux distributions.\nTherefore we consider such proposals to be out-of-scope for this PEP.\n\n\nFuture updates\n==============\n\nWe anticipate that at some point in the future there will be a\n``manylinux2`` specifying a more modern baseline environment (perhaps\nbased on CentOS 6), and someday a ``manylinux3`` and so forth, but we\ndefer specifying these until we have more experience with the initial\n``manylinux1`` proposal.\n\n\nReferences\n==========\n\n.. [1] PEP 0427 -- The Wheel Binary Package Format 1.0\n   (https://www.python.org/dev/peps/pep-0427/)\n.. [2] PEP 0491 -- The Wheel Binary Package Format 1.9\n   (https://www.python.org/dev/peps/pep-0491/)\n.. [3] PEP 425 -- Compatibility Tags for Built Distributions\n   (https://www.python.org/dev/peps/pep-0425/)\n.. [4] Enthought Canopy Python Distribution\n   (https://store.enthought.com/downloads/)\n.. [5] Continuum Analytics Anaconda Python Distribution\n   (https://www.continuum.io/downloads)\n.. [6] CentOS 5.11 Release Notes\n   (https://wiki.centos.org/Manuals/ReleaseNotes/CentOS5.11)\n.. [7] manylinux-discuss mailing list discussion\n   (https://groups.google.com/forum/#!topic/manylinux-discuss/-4l3rrjfr9U)\n.. [8] distutils-sig discussion\n   (https://mail.python.org/pipermail/distutils-sig/2016-January/027997.html)\n.. [9] distutils-sig discussion\n   (https://mail.python.org/pipermail/distutils-sig/2016-February/028275.html)\n.. [10] github issue discussion\n   (https://github.com/pypa/manylinux/issues/30)\n.. [11] python bug tracker discussion\n   (https://bugs.python.org/issue21536)\n.. [12] manylinux1 docker images\n   (Source: https://github.com/pypa/manylinux;\n   x86-64: https://quay.io/repository/pypa/manylinux1_x86_64;\n   x86-32: https://quay.io/repository/pypa/manylinux1_i686)\n.. [13] auditwheel tool\n   (https://pypi.python.org/pypi/auditwheel)\n.. [14] Fedora Bundled Software Policy\n   (https://fedoraproject.org/wiki/Bundled_Software_policy)\n.. [15] Debian Policy Manual -- 4.13: Convenience copies of code\n    (https://www.debian.org/doc/debian-policy/ch-source.html#s-embeddedfiles)\n\n\nCopyright\n=========\n\nThis document has been placed into the public domain.\n\n..\n   Local Variables:\n   mode: indented-text\n   indent-tabs-mode: nil\n   sentence-end-double-space: t\n   fill-column: 70\n   coding: utf-8\n   End:\n"
        },
        {
          "name": "requirements-base-tools.in",
          "type": "blob",
          "size": 0.0126953125,
          "content": "certifi\npipx\n"
        },
        {
          "name": "requirements-tools.in",
          "type": "blob",
          "size": 0.033203125,
          "content": "auditwheel\ncmake\npatchelf\nswig\nuv\n"
        },
        {
          "name": "requirements.in",
          "type": "blob",
          "size": 0.1572265625,
          "content": "pip ; implementation_name != 'graalpy'\nsetuptools ; python_version < '3.12' and implementation_name != 'graalpy'\nwheel ; python_version < '3.12'\nbuild\npackaging\n"
        },
        {
          "name": "ruff.toml",
          "type": "blob",
          "size": 0.8330078125,
          "content": "line-length = 100\n\n[lint]\nextend-select = [\n  \"B\",           # flake8-bugbear\n  \"I\",           # isort\n  \"ARG\",         # flake8-unused-arguments\n  \"C4\",          # flake8-comprehensions\n  \"EM\",          # flake8-errmsg\n  \"ICN\",         # flake8-import-conventions\n  \"ISC\",         # flake8-implicit-str-concat\n  \"G\",           # flake8-logging-format\n  \"PGH\",         # pygrep-hooks\n  \"PIE\",         # flake8-pie\n  \"PL\",          # pylint\n  \"PT\",          # flake8-pytest-style\n  \"RET\",         # flake8-return\n  \"RUF\",         # Ruff-specific\n  \"SIM\",         # flake8-simplify\n  \"TID251\",      # flake8-tidy-imports.banned-api\n  \"UP\",          # pyupgrade\n  \"YTT\",         # flake8-2020\n  \"EXE\",         # flake8-executable\n  \"PYI\",         # flake8-pyi\n]\nignore = [\n  \"PLR\",    # Design related pylint codes\n  \"ISC001\", # Conflicts with formatter\n]\n"
        },
        {
          "name": "tests",
          "type": "tree",
          "content": null
        },
        {
          "name": "tools",
          "type": "tree",
          "content": null
        }
      ]
    }
  ]
}