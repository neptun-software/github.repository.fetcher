{
  "metadata": {
    "timestamp": 1736568547831,
    "page": 566,
    "hasNextPage": true,
    "endCursor": "Y3Vyc29yOjU2OQ==",
    "completionStatus": "IN_PROGRESS"
  },
  "repositories": [
    {
      "nameWithOwner": "archlinuxcn/repo",
      "stars": 1565,
      "defaultBranch": "master",
      "files": [
        {
          "name": ".github",
          "type": "tree",
          "content": null
        },
        {
          "name": "README.md",
          "type": "blob",
          "size": 1.072265625,
          "content": "Arch Linux Chinese Community Repository\n====\n\n[![Packaging consistency check](https://github.com/archlinuxcn/repo/actions/workflows/test.yml/badge.svg)](https://github.com/archlinuxcn/repo/actions/workflows/test.yml)\n\nFor detailed information in Chinese, [visit here](https://www.archlinuxcn.org/archlinux-cn-repo-and-mirror/).\n中文介绍[请看这里](https://www.archlinuxcn.org/archlinux-cn-repo-and-mirror/)。\n\n### Usage\n\nAdd repo:\n\n```\n[archlinuxcn]\nServer = https://repo.archlinuxcn.org/$arch\n```\nto your /etc/pacman.conf .\n\nFor mirrors (strongly recommended for users in China), see https://github.com/archlinuxcn/mirrorlist-repo.\n\nImport PGP Keys:\n\n```bash\nsudo pacman -Sy && sudo pacman -S archlinuxcn-keyring\n```\n\n### Issues\n\n* Flag package OUT-OF-DATE by submiting new issues (please follow the template).\n  * If the new release is within less than a day, please be patient and wait for up to one day; our bot is likely going to build a new one soon.\n* If there is something wrong with provided packages, please submit issues of desired type.\n* Please contact us via issues or email.\n"
        },
        {
          "name": "alarmcn",
          "type": "tree",
          "content": null
        },
        {
          "name": "archlinuxcn",
          "type": "tree",
          "content": null
        },
        {
          "name": "lilac-yaml-schema.yaml",
          "type": "blob",
          "size": 4.3994140625,
          "content": "$schema: http://json-schema.org/draft-07/schema#\n$id: http://example.com/product.schema.json\ntitle: lilac.yaml\ndescription: Descriptive configuration data for lilac packaging\ntype: object\nproperties:\n  build_prefix:\n    description: The prefix of build command to be used. E.g. extra-x86_64, multilib or archlinuxcn-x86_64.\n    type: string\n    default: \"extra-$(uname -m)\"\n    enum:\n      - extra-x86_64\n      - archlinuxcn-x86_64\n      - multilib\n      - multilib-archlinuxcn\n      - extra-aarch64\n  pre_build:\n    description: Name of function to be used as the pre_build function.\n    type: string\n  post_build:\n    description: Name of function to be used as the post_build function.\n    type: string\n  post_build_always:\n    description: Name of function to be used as the post_build_always function.\n    type: string\n  pre_build_script:\n    description: Body of the pre_build function. lilac2.api functions are available.\n    type: string\n  post_build_script:\n    description: Body of the post_build function. lilac2.api functions are available.\n    type: string\n  post_build_always_script:\n    description: Body of the post_build_always function. lilac2.api functions are available.\n    type: string\n  time_limit_hours:\n    description: Time limit in hours. The build will be aborted if it doesn't finish in time. Default is one hour.\n    type: number\n  repo_depends:\n    description: Packages in the repo that are direct dependencies of the current package.\n    type: array\n    items:\n      anyOf:\n        - type: string\n          description: Package (directory) name\n        - type: object\n          description: Package base (directory) as key and package name as value\n          minProperties: 1\n          maxProperties: 1\n          additionalProperties:\n            type: string\n  repo_makedepends:\n    description: Packages in the repo that are in makedepends or checkdepends of the current package.\n    type: array\n    items:\n      anyOf:\n        - type: string\n          description: Package (directory) name\n        - type: object\n          description: Package base (directory) as key and package name as value\n          minProperties: 1\n          maxProperties: 1\n          additionalProperties:\n            type: string\n  update_on:\n    description: Configure how nvchecker should check for updates / rebuilds? The first should check for updates and others for rebuilds.\n    type: array\n    items:\n      anyOf:\n        - type: object\n          description: nvchecker configuration section\n          properties:\n            source:\n              type: string\n              description: nvchecker source name\n          required:\n            - source\n        - type: object\n          description: use an alias for nvchecker configuration section\n          properties:\n            alias:\n              type: string\n              description: alias name\n          required:\n            - alias\n    minItems: 1\n  update_on_build:\n    description: Build this package if the configured packages are built in the same batch. Note that the packages should also be added to \"repo_depends\".\n    type: array\n    items:\n      type: object\n      description: on_build configuration\n      properties:\n        pkgbase:\n          type: string\n          description: pkgbase to build on\n        from_pattern:\n          type: string\n          description: a regex to transform pkgbase's version\n        to_pattern:\n          type: string\n          description: a replacement string to transform pkgbase's version to\n      required:\n        - pkgbase\n    minItems: 0\n  maintainers:\n    description: List of maintainers for receiving email notifications\n    type: array\n    items:\n      anyOf:\n        - type: object\n          description: GitHub username with a public email address\n          properties:\n            github:\n              type: string\n          required:\n            - github\n        - type: object\n          description: GitHub username and an email address in the form \"Name <user@host>\". The GitHub public email does not matter.\n          properties:\n            github:\n              type: string\n            email:\n              type: string\n          required:\n            - github\n            - email\n    minItems: 0\n  staging:\n    description: Whether to stage the package in a \"staging\" subdirectory\n    type: boolean\n    default: false\n  managed:\n    description: Whether the package should be built by lilac or not\n    type: boolean\n    default: true\nrequired:\n  - maintainers\n"
        },
        {
          "name": "parse-pkgbuild",
          "type": "blob",
          "size": 8.263671875,
          "content": "#!/bin/bash\n\n## Script to extract .SRCINFO without having pacman installed\n## code are copied from libmakepkg\n## usage: ./parse-pkgbuild package-name/PKGBUILD\n\n##############################################################\n# commands to ignore in PKGBUILD\n\nmsg() {\n\ttrue\n}\n\nmsg2() {\n\ttrue\n}\n\ncheck_option() {\n\ttrue\n}\n\n\ncheck_buildoption() {\n\ttrue\n}\n\npacman() {\n\ttrue\n}\n\n##############################################################\n# copied from libmakepkg\n\nsource_safe() {\n\tshopt -u extglob\n\tif ! source \"$@\"; then\n\t\tprintf \"Failed to source %s\\n\" \"$1\"\n\t\texit $E_MISSING_FILE\n\tfi\n\tshopt -s extglob\n}\n\nsource_buildfile() {\n\tsource_safe \"$@\"\n}\n\n\nsrcinfo_open_section() {\n\tprintf '%s = %s\\n' \"$1\" \"$2\"\n}\n\nsrcinfo_close_section() {\n\techo\n}\n\nsrcinfo_write_attr() {\n\t# $1: attr name\n\t# $2: attr values\n\n\tlocal attrname=$1 attrvalues=(\"${@:2}\")\n\n\t# normalize whitespace, strip leading and trailing\n\tattrvalues=(\"${attrvalues[@]//+([[:space:]])/ }\")\n\tattrvalues=(\"${attrvalues[@]#[[:space:]]}\")\n\tattrvalues=(\"${attrvalues[@]%[[:space:]]}\")\n\n\tprintf \"\\t$attrname = %s\\n\" \"${attrvalues[@]}\"\n}\n\npkgbuild_extract_to_srcinfo() {\n\t# $1: pkgname\n\t# $2: attr name\n\t# $3: multivalued\n\n\tlocal pkgname=$1 attrname=$2 isarray=$3 outvalue=\n\n\tif get_pkgbuild_attribute \"$pkgname\" \"$attrname\" \"$isarray\" 'outvalue'; then\n\t\tsrcinfo_write_attr \"$attrname\" \"${outvalue[@]}\"\n\tfi\n}\n\nsrcinfo_write_section_details() {\n\tlocal attr package_arch a\n\tlocal multivalued_arch_attrs=(source provides conflicts depends replaces\n\t                              optdepends makedepends checkdepends\n\t                              {md5,sha{1,224,256,384,512}}sums)\n\n\tfor attr in \"${singlevalued[@]}\"; do\n\t\tpkgbuild_extract_to_srcinfo \"$1\" \"$attr\" 0\n\tdone\n\n\tfor attr in \"${multivalued[@]}\"; do\n\t\tpkgbuild_extract_to_srcinfo \"$1\" \"$attr\" 1\n\tdone\n\n\tget_pkgbuild_attribute \"$1\" 'arch' 1 'package_arch'\n\tfor a in \"${package_arch[@]}\"; do\n\t\t# 'any' is special. there's no support for, e.g. depends_any.\n\t\t[[ $a = any ]] && continue\n\n\t\tfor attr in \"${multivalued_arch_attrs[@]}\"; do\n\t\t\tpkgbuild_extract_to_srcinfo \"$1\" \"${attr}_$a\" 1\n\t\tdone\n\tdone\n}\n\nsrcinfo_write_global() {\n\tlocal singlevalued=(pkgdesc pkgver pkgrel epoch url install changelog)\n\tlocal multivalued=(arch groups license checkdepends makedepends\n\t                   depends optdepends provides conflicts replaces\n\t                   noextract options backup\n\t                   source validpgpkeys {md5,sha{1,224,256,384,512}}sums)\n\n\tsrcinfo_open_section 'pkgbase' \"${pkgbase:-$pkgname}\"\n\tsrcinfo_write_section_details ''\n\tsrcinfo_close_section\n}\n\nsrcinfo_write_package() {\n\tlocal singlevalued=(pkgdesc url install changelog)\n\tlocal multivalued=(arch groups license checkdepends depends optdepends\n\t                   provides conflicts replaces options backup)\n\n\tsrcinfo_open_section 'pkgname' \"$1\"\n\tsrcinfo_write_section_details \"$1\"\n\tsrcinfo_close_section\n}\n\nwrite_srcinfo_header() {\n\tprintf \"# Generated by makepkg %s\\n\" \"$makepkg_version\"\n\tprintf \"# %s\\n\" \"$(LC_ALL=C date -u)\"\n}\n\nwrite_srcinfo_content() {\n\tlocal pkg\n\n\tsrcinfo_write_global\n\n\tfor pkg in \"${pkgname[@]}\"; do\n\t\tsrcinfo_write_package \"$pkg\"\n\tdone\n}\n\nwrite_srcinfo() {\n\twrite_srcinfo_header\n\twrite_srcinfo_content\n}\n\ngrep_function() {\n\t{ declare -f \"$1\" || declare -f package; } 2>/dev/null | grep -E \"$2\"\n}\n\narray_build() {\n\tlocal dest=$1 src=$2 i keys values\n\n\t# it's an error to try to copy a value which doesn't exist.\n\tdeclare -p \"$2\" &>/dev/null || return 1\n\n\t# Build an array of the indicies of the source array.\n\teval \"keys=(\\\"\\${!$2[@]}\\\")\"\n\n\t# Clear the destination array\n\teval \"$dest=()\"\n\n\t# Read values indirectly via their index. This approach gives us support\n\t# for associative arrays, sparse arrays, and empty strings as elements.\n\tfor i in \"${keys[@]}\"; do\n\t\tvalues+=(\"printf -v '$dest[$i]' %s \\\"\\${$src[$i]}\\\";\")\n\tdone\n\n\teval \"${values[*]}\"\n}\n\nextract_global_variable() {\n\t# $1: variable name\n\t# $2: multivalued\n\t# $3: name of output var\n\n\tlocal attr=$1 isarray=$2 outputvar=$3 ref\n\n\tif (( isarray )); then\n\t\tarray_build ref \"$attr\"\n\t\t[[ ${ref[@]} ]] && array_build \"$outputvar\" \"$attr\"\n\telse\n\t\t[[ ${!attr} ]] && printf -v \"$outputvar\" %s \"${!attr}\"\n\tfi\n}\n\nextract_function_variable() {\n\t# $1: function name\n\t# $2: variable name\n\t# $3: multivalued\n\t# $4: name of output var\n\n\tlocal funcname=$1 attr=$2 isarray=$3 outputvar=$4 attr_regex= decl= r=1\n\n\tif (( isarray )); then\n\t\tprintf -v attr_regex '^[[:space:]]* %s\\+?=\\(' \"$2\"\n\telse\n\t\tprintf -v attr_regex '^[[:space:]]* %s\\+?=[^(]' \"$2\"\n\tfi\n\n\t# this function requires extglob - save current status to restore later\n\tlocal shellopts=$(shopt -p extglob)\n\tshopt -s extglob\n\n\twhile read -r; do\n\t\t# strip leading whitespace and any usage of declare\n\t\tdecl=${REPLY##*([[:space:]])}\n\t\teval \"${decl/#$attr/$outputvar}\"\n\n\t\t# entering this loop at all means we found a match, so notify the caller.\n\t\tr=0\n\tdone < <(grep_function \"$funcname\" \"$attr_regex\")\n\n\teval \"$shellopts\"\n\n\treturn $r\n}\n\nget_pkgbuild_attribute() {\n\t# $1: package name\n\t# $2: attribute name\n\t# $3: multivalued\n\t# $4: name of output var\n\n\tlocal pkgname=$1 attrname=$2 isarray=$3 outputvar=$4\n\n\tif (( isarray )); then\n\t\teval \"$outputvar=()\"\n\telse\n\t\tprintf -v \"$outputvar\" %s ''\n\tfi\n\n\tif [[ $pkgname ]]; then\n\t\textract_global_variable \"$attrname\" \"$isarray\" \"$outputvar\"\n\t\textract_function_variable \"package_$pkgname\" \"$attrname\" \"$isarray\" \"$outputvar\"\n\telse\n\t\textract_global_variable \"$attrname\" \"$isarray\" \"$outputvar\"\n\tfi\n}\n\nget_pkgbuild_all_split_attributes() {\n\tlocal attrname=$1 outputvar=$2 all_list list\n\n\tif extract_global_variable \"$attrname\" 1 list; then\n\t\tall_list+=(\"${list[@]}\")\n\tfi\n\tfor a in \"${arch[@]}\"; do\n\t\tif extract_global_variable \"${attrname}_$a\" 1 list; then\n\t\t\tall_list+=(\"${list[@]}\")\n\t\tfi\n\tdone\n\n\tfor name in \"${pkgname[@]}\"; do\n\t\tif extract_function_variable \"package_$name\" \"$attrname\" 1 list; then\n\t\t\tall_list+=(\"${list[@]}\")\n\t\tfi\n\n\t\tfor a in \"${arch[@]}\"; do\n\t\t\tif extract_function_variable \"package_$name\" \"${attrname}_$a\" 1 list; then\n\t\t\t\tall_list+=(\"${list[@]}\")\n\t\t\tfi\n\t\tdone\n\tdone\n\n\t[[ ${all_list[@]} ]] && array_build \"$outputvar\" all_list\n}\n\n##\n#  usage : get_full_version()\n# return : full version spec, including epoch (if necessary), pkgver, pkgrel\n##\nget_full_version() {\n\tif (( epoch > 0 )); then\n\t\tprintf \"%s\\n\" \"$epoch:$pkgver-$pkgrel\"\n\telse\n\t\tprintf \"%s\\n\" \"$pkgver-$pkgrel\"\n\tfi\n}\n\n##\n#  usage : get_pkg_arch( [$pkgname] )\n# return : architecture of the package\n##\nget_pkg_arch() {\n\tif [[ -z $1 ]]; then\n\t\tif [[ $arch = \"any\" ]]; then\n\t\t\tprintf \"%s\\n\" \"any\"\n\t\telse\n\t\t\tprintf \"%s\\n\" \"$CARCH\"\n\t\tfi\n\telse\n\t\tlocal arch_override\n\t\tget_pkgbuild_attribute \"$1\" arch 1 arch_override\n\t\t(( ${#arch_override[@]} == 0 )) && arch_override=(\"${arch[@]}\")\n\t\tif [[ $arch_override = \"any\" ]]; then\n\t\t\tprintf \"%s\\n\" \"any\"\n\t\telse\n\t\t\tprintf \"%s\\n\" \"$CARCH\"\n\t\tfi\n\tfi\n}\n\nprint_all_package_names() {\n\tlocal version=$(get_full_version)\n\tlocal architecture pkg opts a\n\tfor pkg in ${pkgname[@]}; do\n\t\tarchitecture=$(get_pkg_arch $pkg)\n\t\tprintf \"%s/%s-%s-%s%s\\n\" \"$PKGDEST\" \"$pkg\" \"$version\" \"$architecture\" \"$PKGEXT\"\n\tdone\n\t# if check_option \"debug\" \"y\" && check_option \"strip\" \"y\"; then\n\t# \tarchitecture=$(get_pkg_arch)\n\t# \tprintf \"%s/%s-%s-%s-%s%s\\n\" \"$PKGDEST\" \"$pkgbase\" \"debug\" \"$version\" \"$architecture\" \"$PKGEXT\"\n\t# fi\n}\n\nget_all_sources() {\n\tlocal aggregate l a\n\n\tif array_build l 'source'; then\n\t\taggregate+=(\"${l[@]}\")\n\tfi\n\n\tfor a in \"${arch[@]}\"; do\n\t\tif array_build l \"source_$a\"; then\n\t\t\taggregate+=(\"${l[@]}\")\n\t\tfi\n\tdone\n\n\tarray_build \"$1\" \"aggregate\"\n}\n\nget_all_sources_for_arch() {\n\tlocal aggregate l\n\n\tif array_build l 'source'; then\n\t\taggregate+=(\"${l[@]}\")\n\tfi\n\n\tif array_build l \"source_$CARCH\"; then\n\t\taggregate+=(\"${l[@]}\")\n\tfi\n\n\tarray_build \"$1\" \"aggregate\"\n}\n\nget_integlist() {\n\tlocal integ\n\tlocal integlist=()\n\n\tfor integ in \"${known_hash_algos[@]}\"; do\n\t\t# check for e.g. \"sha256sums\"\n\t\tlocal sumname=\"${integ}sums[@]\"\n\t\tif [[ -n ${!sumname} ]]; then\n\t\t\tinteglist+=(\"$integ\")\n\t\t\tcontinue\n\t\tfi\n\n\t\t# check for e.g. \"sha256sums_x86_64\"\n\t\tfor a in \"${arch[@]}\"; do\n\t\t\tlocal sumname=\"${integ}sums_${a}[@]\"\n\t\t\tif [[ -n ${!sumname} ]]; then\n\t\t\t\tinteglist+=(\"$integ\")\n\t\t\t\tbreak\n\t\t\tfi\n\t\tdone\n\tdone\n\n\tif (( ${#integlist[@]} > 0 )); then\n\t\tprintf \"%s\\n\" \"${integlist[@]}\"\n\telse\n\t\tprintf \"%s\\n\" \"${INTEGRITY_CHECK[@]}\"\n\tfi\n}\n\n##############################################################\n# source PKGBUILD and write srcinfo\n\nCARCH=\"x86_64\"\nsource_buildfile \"$@\"\npkgbase=${pkgbase:-${pkgname[0]}}\nwrite_srcinfo_content\n"
        },
        {
          "name": "pre-commit",
          "type": "blob",
          "size": 17.4248046875,
          "content": "#!/usr/bin/env python\n\n\"\"\"\npre-commit hook to check repo tree\n\nTo use it normally as git pre-commit hook,\nmake a symlink and install dependencies:\n$ ln -s ../../pre-commit .git/hooks\n$ pacman -Syu --needed python-yaml python-jsonschema pyalpm\n\nTo check modified packages, run without options:\n$ ./pre-commit\n\nTo fully test all packages, run with \"-a\" option:\n$ ./pre-commit -a\n\"\"\"\n\nimport os\nimport sys\nimport ast\nimport gzip\nimport json\nfrom time import strftime\nfrom subprocess import Popen, PIPE\nfrom unittest import TestCase, TestLoader, TextTestRunner, skip\nfrom io import StringIO\nfrom typing import Generator\n\n# need python-yaml package\nimport yaml\n\n# need python-jsonschema package\nimport jsonschema\n\nDIRS, FILES, COMMITS = None, None, None\nGIT_BRANCH = 'HEAD'\nORIGIN_BRANCH = 'origin/master'\nCHANGED_PACKAGES = set()\nSUBFOLDER = 'archlinuxcn'\n\n# URL for downloading latest database of packages and groups in official repos\nDUMP_GROUPS_URL = 'https://build.archlinuxcn.org/~farseerfc/dump-groups.gz'\nDUMP_GROUPS_TMP = '/tmp/dump-groups-%s.gz'\n# Cache downloaded database for 1 hour\nDUMP_GROUPS_TIMEFORMAT = '%Y%m%d%H%z'\n\nGROUPS, PACKAGES = {}, {}\n\nYAML_SCHEMA = None\n\nCHECK_ALL = False\nIGNORE_SRCINFO = False\n\n\ndef readutf8(st):\n    return st.read().decode('utf-8')\n\n\ndef git_write_tree_index():\n    global GIT_BRANCH\n    cmd = ['git', 'write-tree']\n    with Popen(cmd, stdout=PIPE) as p:\n        GIT_BRANCH = readutf8(p.stdout).rstrip()\n\n\ndef git_diff_tree():\n    global GIT_BRANCH, ORIGIN_BRANCH, CHANGED_PACKAGES\n    # git diff-tree\n    # -r Recurse into sub-trees.\n    # -z \\0 line termination on output and do not quote filenames.\n    cmd = ['git', 'diff-tree', ORIGIN_BRANCH + '..' + GIT_BRANCH,\n           '-r', '-z', '--name-only']\n    with Popen(cmd, stdout=PIPE) as p:\n        changed_tree = readutf8(p.stdout)\n        for line in changed_tree.split('\\0')[:-1]:  # ignore last \\0\n            paths = line.strip().split('/')\n            if git_isdir(SUBFOLDER):\n                if len(paths) > 2:\n                    if git_isdir(os.path.join(SUBFOLDER, paths[1])):\n                        CHANGED_PACKAGES.add(paths[1])\n            else:\n                if len(paths) > 1:\n                    if git_isdir(paths[0]):\n                        CHANGED_PACKAGES.add(paths[0])\n\n\ndef git_ls_tree():\n    cmd = ['git', 'ls-tree', '-rtz', '--full-name', GIT_BRANCH]\n    # git ls-tree\n    # -r Recurse into sub-trees.\n    # -t Show tree entries even when going to recurse them.\n    # -z \\0 line termination on output and do not quote filenames.\n    dirs = []\n    files = []\n    commits = []\n    with Popen(cmd, stdout=PIPE) as p:\n        alllines = readutf8(p.stdout)\n        for line in alllines.split('\\0')[:-1]:  # ignore last \\0\n            # OUTPUT FORMAT\n            # <mode> SP <type> SP <object> TAB <file>\n            first, _, path = line.partition('\\t')\n            _, t, _ = first.split(' ')\n            if t == 'tree':\n                dirs.append(path)\n            elif t == 'blob':\n                files.append(path)\n            elif t == 'commit':\n                commits.append(path)\n        return dirs, files, commits\n\n\ndef git_open(filename, decode_errors='strict'):\n    cmd = ['git', 'cat-file', 'blob', f'{GIT_BRANCH}:{filename}']\n    with Popen(cmd, stdout=PIPE) as p:\n        return StringIO(p.stdout.read().decode('utf-8', errors=decode_errors))\n\n\ndef git_listdir(path):\n    cmd = ['git', 'ls-tree', '--name-only',\n           (f'{GIT_BRANCH}:{path}' if path != '.' else GIT_BRANCH)]\n    with Popen(cmd, stdout=PIPE) as p:\n        return readutf8(p.stdout).split(\"\\n\")[:-1]\n\n\ndef git_isdir(path):\n    global DIRS\n    return path in DIRS\n\n\ndef git_isfile(path, name):\n    global FILES\n    return os.path.join(path, name) in FILES\n\n\ndef pkgpath(pkgname):\n    if git_isdir(SUBFOLDER):\n        return os.path.join(SUBFOLDER, pkgname)\n    else:\n        return pkgname\n\n\ndef lilac_py_has_field(pkgname, field, testcase):\n    if not git_isfile(pkgpath(pkgname), 'lilac.py'):\n        return False\n    lilac_path = os.path.join(pkgpath(pkgname), 'lilac.py')\n    with git_open(lilac_path) as lilac_py:\n        try:\n            lilac_ast = ast.parse(lilac_py.read())\n            # For simplicity we only check top level assignments\n            # to find field such as `update_on`, which shoud be enough\n            for block in lilac_ast.body:\n                if isinstance(block, ast.Assign):\n                    for target in block.targets:\n                        if target.id == field:\n                            return True\n        except:\n            testcase.fail(msg=\"{} can not parse\".format(lilac_path))\n    return False\n\ndef lilac_py_has_field_value(pkgname, field, value, testcase):\n    if not git_isfile(pkgpath(pkgname), 'lilac.py'):\n        return False\n    lilac_path = os.path.join(pkgpath(pkgname), 'lilac.py')\n    with git_open(lilac_path) as lilac_py:\n        try:\n            lilac_ast = ast.parse(lilac_py.read())\n            # For simplicity we only check top level assignments\n            # to find field such as `update_on`, which shoud be enough\n            for block in lilac_ast.body:\n                if isinstance(block, ast.Assign):\n                    for target in block.targets:\n                        if target.id == field:\n                            return target.value == value\n        except:\n            testcase.fail(msg=\"{} can not parse\".format(lilac_path))\n    return False\n\ndef lilac_py_has_update_on(pkgname, testcase):\n    return lilac_py_has_field(pkgname, 'update_on', testcase)\n\ndef lilac_py_has_managed_false(pkgname, testcase):\n    return lilac_py_has_field_value(pkgname, 'managed', 'False', testcase)\n\ndef lilac_yaml_has_field(pkgname, field, testcase):\n    if not git_isfile(pkgpath(pkgname), 'lilac.yaml'):\n        return False\n    lilac_path = os.path.join(pkgpath(pkgname), 'lilac.yaml')\n    with git_open(lilac_path) as lilac_yaml:\n        try:\n            lilac_ast = yaml.load(lilac_yaml.read(), Loader=yaml.SafeLoader)\n            if field in lilac_ast:\n                return True\n        except:\n            testcase.fail(msg=\"{} can not parse\".format(lilac_path))\n    return False\n\ndef lilac_yaml_has_field_value(pkgname, field, value, testcase):\n    if not git_isfile(pkgpath(pkgname), 'lilac.yaml'):\n        return False\n    lilac_path = os.path.join(pkgpath(pkgname), 'lilac.yaml')\n    with git_open(lilac_path) as lilac_yaml:\n        try:\n            lilac_ast = yaml.load(lilac_yaml.read(), Loader=yaml.SafeLoader)\n            if field in lilac_ast:\n                return lilac_ast[field] == value\n        except:\n            testcase.fail(msg=\"{} can not parse\".format(lilac_path))\n    return False\n\ndef lilac_yaml_has_update_on(pkgname, testcase):\n    return lilac_yaml_has_field(pkgname, 'update_on', testcase)\n\ndef lilac_yaml_has_managed_false(pkgname, testcase):\n    return lilac_yaml_has_field_value(pkgname, 'managed', False, testcase)\n\ndef extract_srcinfo(pkgbuild):\n    dir_path = os.path.dirname(os.path.realpath(__file__))\n    with Popen(['bash', dir_path + '/parse-pkgbuild', '/dev/stdin'],\n               stdin=PIPE, stdout=PIPE) as p:\n        outs,_ = p.communicate(input=pkgbuild.encode('UTF-8'))\n        return outs.decode('UTF-8')\n\n\ndef depends_strip_version(depends):\n    if '>' in depends:\n        return depends[:depends.rfind('>')].strip()\n    if '<' in depends:\n        return depends[:depends.rfind('<')].strip()\n    if depends.count('=') > 1:\n        return depends[:depends.rfind('=')].strip()\n    return depends.strip()\n\n\ndef dump_groups():\n    global GROUPS, PACKAGES\n    try:\n        import pycman\n        # now that we are running on archlinux so dump from pacman's syncdb\n        handle = pycman.config.init_with_config('/etc/pacman.conf')\n        OFFICIAL = ['core', 'extra']\n        syncdbs = [db for db in handle.get_syncdbs() if db.name in OFFICIAL]\n        for db in syncdbs:\n            for pkg in db.pkgcache:\n                name = pkg.name\n                if name in PACKAGES:\n                    PACKAGES[name].append(db.name)\n                else:\n                    PACKAGES[name] = [db.name, ]\n            for grp in db.grpcache:\n                name,_ = grp\n                if name in GROUPS:\n                    GROUPS[name].append(db.name)\n                else:\n                    GROUPS[name] = [db.name, ]\n    except ImportError:\n        # not running on an archlinux/pacman so download from URL\n        def refresh_dump_groups():\n            dump_groups_path = DUMP_GROUPS_TMP % (strftime(DUMP_GROUPS_TIMEFORMAT))\n            if os.path.exists(dump_groups_path):\n                return gzip.open(dump_groups_path, 'rt')\n            import urllib.request\n            urllib.request.urlretrieve(DUMP_GROUPS_URL, dump_groups_path)\n            return gzip.open(dump_groups_path, 'rt')\n\n        with refresh_dump_groups() as dump:\n            result = json.loads(dump.read())\n            if result['format_version'] != 2:\n                raise ValueError('dump-groups format mismatch')\n            GROUPS = result['groups']\n            PACKAGES = result['packages']\n\n\ndef load_lilac_yaml_schema():\n    global YAML_SCHEMA\n    with open('lilac-yaml-schema.yaml', 'r') as schema:\n        YAML_SCHEMA = yaml.load(schema, Loader=yaml.SafeLoader)\n\n\ndef iter_packages(all_pkgs: bool = False) -> Generator[str, None, None]:\n    packagesfolder = SUBFOLDER\n    if not git_isdir(packagesfolder):\n        packagesfolder = '.'\n    for package in git_listdir(packagesfolder):\n        if not git_isdir(pkgpath(package)):\n            continue\n        if package[0] == '.':\n            continue\n        if not(package in CHANGED_PACKAGES or CHECK_ALL or all_pkgs):\n            continue\n        yield package\n\n\nclass DuplicateKeyError(Exception):\n    pass\n\nclass UniqueKeyLoader(yaml.SafeLoader):\n    def construct_mapping(self, node, deep=False):\n        mapping = []\n        for key_node, value_node in node.value:\n            key = self.construct_object(key_node, deep=deep)\n            if key in mapping:\n                raise DuplicateKeyError(key)\n            mapping.append(key)\n        return super().construct_mapping(node, deep)\n\nclass RepoTreeTest(TestCase):\n\n    @skip(\"PKGBUILDs may be added later by lilac\")\n    def test_pkgbuild_exists(self):\n        for package in iter_packages():\n            with self.subTest(package=package):\n                self.assertTrue(git_isfile(pkgpath(package), \"PKGBUILD\"),\n                                msg=('package \"\\033[1;31m{0}\\033[m\" does '\n                                     'not have PKGBUILD').format(package))\n\n    @skip(\"lilac can now check and drop packages in official repos\")\n    def test_package_in_official(self):\n        for package in iter_packages():\n            with self.subTest(package=package):\n                self.assertFalse(package in PACKAGES,\n                                msg=('package \"\\033[1;31m{0}\\033[m\" exists in '\n                                     'official repo').format(package))\n\n\n    def test_lilac_yaml_schema(self):\n        for package in iter_packages():\n            if not git_isfile(pkgpath(package), 'lilac.yaml'):\n                continue\n            with self.subTest(package=package):\n                self.assertTrue(lilac_yaml_has_field(package, 'maintainers', self),\n                                msg=('package \"\\033[1;31m{0}\\033[m\" does not have '\n                                   '\"maintainers\" in '\n                                   '\"\\033[1;31m{0}/lilac.yaml\\033[m\" '\n                                   'file').format(package))\n            with self.subTest(package=package):\n                lilac_yaml_path = os.path.join(pkgpath(package), 'lilac.yaml')\n                with git_open(lilac_yaml_path) as lilac_yaml_file:\n                    try:\n                        lilac_yaml = yaml.load(lilac_yaml_file.read(), Loader=UniqueKeyLoader)\n                    except Exception:\n                        self.fail(msg='package \"\\033[1;31m{0}\\033[m\"\\'s lilac.yaml'\n                                  'contains invalid YAML'.format(package))\n                    try:\n                        jsonschema.validate(lilac_yaml, YAML_SCHEMA)\n                    except jsonschema.exceptions.ValidationError:\n                        self.fail(msg='package \"\\033[1;31m{0}\\033[m\" contains '\n                                  'invalid \"\\033[1;31mlilac.yaml\\033[m\"'\n                                  ''.format(package))\n\n    def test_lilac_py_has_update_on_or_managed_false(self):\n        for package in iter_packages():\n            #if not any([git_isfile(pkgpath(package), 'lilac.py'),\n            #            git_isfile(pkgpath(package), 'lilac.yaml')]):\n            #    continue\n            with self.subTest(package=package):\n                self.assertTrue(any([\n                                     lilac_py_has_update_on(package, self),\n                                     lilac_yaml_has_update_on(package, self),\n                                     lilac_py_has_managed_false(package, self),\n                                     lilac_yaml_has_managed_false(package, self),\n                                    ]),\n                                msg=('package \"\\033[1;31m{0}\\033[m\" does not have '\n                                   '\"update_on\" or \"managed: false\" in '\n                                   '\"\\033[1;31m{0}/lilac.py\\033[m\" or '\n                                   '\"\\033[1;31m{0}/lilac.yaml\\033[m\" '\n                                   'files').format(package))\n\n    def test_pkgbuild(self):\n        def check_var_srcinfo(var, package, against, line):\n            if (var + ' = ') not in line:\n                return\n            with self.subTest(package=package, line=line.strip()):\n                for pkg in against.keys():\n                    self.assertNotEqual(var + ' = ' + pkg,\n                        depends_strip_version(line),\n                        msg=('PKGBUILD of package \"\\033[1;31m{0}\\033[m\" '\n                                'contains \"\\033[1;31m{1} = {2}\\033[m\" in '\n                                '\"{3}\" repo').format(package, var, pkg,\n                                                     ','.join(against[pkg])))\n        for package in iter_packages():\n            if IGNORE_SRCINFO:\n                continue\n            if not git_isfile(pkgpath(package), 'PKGBUILD'):\n                # PKGBUILD may be added later by lilac\n                continue\n            pkgbuild_path = os.path.join(pkgpath(package), 'PKGBUILD')\n            print('checking', pkgbuild_path)\n            with git_open(pkgbuild_path, decode_errors='replace') as pkgbuild_file:\n                pkgbuild = pkgbuild_file.read()\n                if not (('replaces' in pkgbuild) or ('groups' in pkgbuild)):\n                    # only parse pkgbuild as srcinfo when necessory\n                    continue\n                srcinfo = extract_srcinfo(pkgbuild)\n                for line in srcinfo.split('\\n'):\n                    check_var_srcinfo('replaces', package, PACKAGES, line)\n                    check_var_srcinfo('groups', package, GROUPS, line)\n\n    def test_repo_depends_valid(self):\n        pkgs = list(iter_packages())\n        all_pkgs = list(iter_packages(all_pkgs=True))\n        for package in pkgs:\n            with self.subTest(package=package):\n                self.assertFalse(\n                    lilac_py_has_field(package, 'repo_depends', self),\n                    msg=('package \"\\033[1;31m{0}\\033[m\" has repo_depends '\n                         'in lilac.py').format(package))\n                lilac_yaml_path = os.path.join(pkgpath(package), 'lilac.yaml')\n                with git_open(lilac_yaml_path) as lilac_yaml_file:\n                    lilac_yaml = yaml.load(lilac_yaml_file.read(), Loader=yaml.SafeLoader)\n                    for dep in lilac_yaml.get('repo_depends', []):\n                        if isinstance(dep, dict):\n                            # When `dep` is a dict, this repo_depends entry\n                            # has the form `pkgbase: pkgname`. Here I assume\n                            # split packages are successfully packaged. so only\n                            # the pkgbase needs to be checked.\n                            dep_package = list(dep.keys())[0]\n                        else:\n                            dep_package = dep\n                        self.assertTrue(\n                            dep_package in all_pkgs,\n                            msg=('package \"\\033[1;31m{0}\\033[m\" depends on '\n                                 '\"\\033[1;31m{1}\\033[m\", which does not exist '\n                                 'or is unmanaged').format(package, dep_package))\n\n    def test_no_commit_objects(self):\n        # Fails if an embedded git repo (e.g., a submodule) is commited\n        self.assertFalse(COMMITS, msg='Unexpected commit objects: {!r}'.format(COMMITS))\n\n\ndef run_test(testcase, msg):\n    output = StringIO()\n    suite = TestLoader().loadTestsFromTestCase(testcase)\n    runner = TextTestRunner(output, verbosity=0)\n    results = runner.run(suite)\n    if not results.wasSuccessful():\n        print(output.getvalue())\n        print(msg.format(len(results.failures)))\n        sys.exit(1)\n\n\ndef usage():\n    print(__doc__)\n\n\nif __name__ == '__main__':\n    if '-h' in sys.argv or '--help' in sys.argv:\n        usage()\n        sys.exit(0)\n    if '-a' in sys.argv or '--all' in sys.argv:\n        CHECK_ALL = True\n    if '--no-srcinfo' in sys.argv:\n        IGNORE_SRCINFO = True\n\n    dump_groups()\n    load_lilac_yaml_schema()\n    git_write_tree_index()\n    DIRS, FILES, COMMITS = git_ls_tree()\n    if not CHECK_ALL:\n        git_diff_tree()\n    run_test(RepoTreeTest,\n             msg=('\\033[1;31mThere are {0} error(s) inside repo, ' +\n                  'blocking git commit. Please fix the errors and commit ' +\n                  'again\\033[m'))\n"
        }
      ]
    }
  ]
}