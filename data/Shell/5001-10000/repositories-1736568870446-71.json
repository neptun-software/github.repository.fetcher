{
  "metadata": {
    "timestamp": 1736568870446,
    "page": 71,
    "hasNextPage": true,
    "endCursor": "Y3Vyc29yOjgw",
    "completionStatus": "IN_PROGRESS"
  },
  "repositories": [
    {
      "nameWithOwner": "wurstmeister/kafka-docker",
      "stars": 6939,
      "defaultBranch": "master",
      "files": [
        {
          "name": ".travis.yml",
          "type": "blob",
          "size": 2.81640625,
          "content": "sudo: required\n\nlanguage: scala\n\nservices:\n  - docker\n\n# This version will be also tagged as 'latest'\nenv:\n  global:\n    - LATEST=\"2.13-2.8.1\"\n\n# Build recommended versions based on: http://kafka.apache.org/downloads\nmatrix:\n  include:\n  - scala: 2.12\n    env: KAFKA_VERSION=2.1.1\n  - scala: 2.12\n    env: KAFKA_VERSION=2.2.2\n  - scala: 2.12\n    env: KAFKA_VERSION=2.3.1\n  - scala: 2.12\n    env: KAFKA_VERSION=2.4.1\n  - scala: 2.12\n    env: KAFKA_VERSION=2.5.1\n  - scala: 2.13\n    env: KAFKA_VERSION=2.6.3\n  - scala: 2.13\n    env: KAFKA_VERSION=2.7.2\n  - scala: 2.13\n    env: KAFKA_VERSION=2.8.1\n\n# Upgrade Docker Engine so we can use buildx\nbefore_install:\n  - curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo apt-key add -\n  - sudo add-apt-repository \"deb [arch=amd64] https://download.docker.com/linux/ubuntu $(lsb_release -cs) stable\"\n  - sudo apt-get update\n  - sudo apt-get -y -o Dpkg::Options::=\"--force-confnew\" install docker-ce\n\ninstall:\n  - docker --version\n  - docker buildx version\n  - docker-compose --version\n  - echo \"KAFKA VERSION  $KAFKA_VERSION\"\n  - echo \"SCALA VERSION  $TRAVIS_SCALA_VERSION\"\n  - echo \"LATEST VERSION $LATEST\"\n  - if [ -z ${DOCKER_PASSWORD+x} ]; then echo \"Using unauthenticated pulls on PR\"; else echo \"$DOCKER_PASSWORD\" | docker login -u \"$DOCKER_USERNAME\" --password-stdin; fi\n  - export CURRENT=${TRAVIS_SCALA_VERSION}-${KAFKA_VERSION}\n\n  # Prepare the environment for multi-arch builds\n  - docker run --rm --privileged multiarch/qemu-user-static --reset -p yes\n  - docker buildx create --use\n\n  # Build all of the platforms and cache the result\n  - bash docker_buildx\n\n  # Using the multi-arch build cache, load the current architecture image into docker for the\n  # subsequent docker-compose/test stuff.\n  - bash docker_buildx --load\n  - docker pull confluentinc/cp-kafkacat\n\nbefore_script:\n  - docker-compose -f test/docker-compose.yml up -d zookeeper kafka_1 kafka_2\n\nscript:\n  # Shellcheck main source files\n  - shellcheck -s bash broker-list.sh create-topics.sh start-kafka.sh download-kafka.sh versions.sh\n  - cd test\n  # Shellcheck the tests\n  - shellcheck -x -e SC1090 -s bash *.sh **/*.sh\n  - ./verifyImageLabels.sh # Verify docker image's label\n  - sleep 5 # Wait for containers to start\n  - docker-compose logs\n  - docker ps -a\n  - ./runAllTests.sh\n  # End-to-End scenario tests\n  - cd scenarios\n  - ./runJmxScenario.sh\n  - cd $TRAVIS_BUILD_DIR\n\nafter_script:\n  - docker-compose stop\n\n# This will deploy from master. Might want to have a single release branch for a little more control\ndeploy:\n  - provider: script\n    script: bash docker_push latest\n    on:\n      repo: wurstmeister/kafka-docker\n      branch: master\n      condition: $CURRENT = $LATEST\n  - provider: script\n    script: bash docker_push \"${TRAVIS_SCALA_VERSION}-${KAFKA_VERSION}\"\n    on:\n      repo: wurstmeister/kafka-docker\n      # branch: release\n"
        },
        {
          "name": "CHANGELOG.md",
          "type": "blob",
          "size": 2.92578125,
          "content": "Changelog\n=========\n\nKafka features are not tied to a specific kafka-docker version (ideally all changes will be merged into all branches). Therefore, this changelog will track changes to the image by date.\n\n09-Apr-2022\n----------\n\n-\tSwitched to openjdk:11-jre-slim for multi-arch support. \n-\tDrop support for Kafka `2.0.1` due to JDK upgrade.\n\n04-Oct-2021\n----------\n\n-\tAdd support for Kafka `2.8.1`\n\n19-July-2021\n----------\n\n-\tAdd support for Kafka `2.7.1`\n\n06-Jun-2021\n----------\n- Add support for darwin arm by to azul/zulu-openjdk-alpine base image\n\n05-Jun-2021\n-----------\n\n- Dropped support for versions < 2.0.1\n\n30-Dec-2020\n-----------\n\n-\tAdd support for Kafka `2.7.0`\n\n06-Aug-2020\n-----------\n\n-\tAdd support for Kafka `2.6.0`\n\n20-Apr-2020\n-----------\n\n-\tAdd support for Kafka `2.5.0`\n\n16-Mar-2020\n-----------\n\n-\tAdd support for Kafka `2.4.1`\n-\tUpdate glibc to `2.31-r0`\n\n20-Dec-2019\n-----------\n\n-\tAdd support for Kafka `2.2.2`\n-\tUpdate glibc to 2.30-r0\n\n17-Dec-2019\n-----------\n\n-\tAdd support for Kafka `2.4.0`\n\n26-Oct-2019\n-----------\n\n-\tAdd support for Kafka `2.3.1`\n\n28-Jun-2019\n-----------\n\n-\tAdd support for Kafka `2.3.0`\n\n04-Jun-2019\n-----------\n\n-\tUpdated `2.2.x` version to Kafka `2.2.1`\n-\tUpdate base image to openjdk:8u212-jre-alpine\n\n15-Apr-2019\n-----------\n\n-\tUpdate base image to openjdk:8u201-jre-alpine\n\n27-Mar-2019\n-----------\n\n-\tAdd support for Kafka `2.2.0`\n\n21-Feb-2019\n-----------\n\n-\tUpdate to latest Kafka: `2.1.1`\n-\tUpdate glibc to `2.29-r0`\n\n21-Nov-2018\n-----------\n\n-\tUpdate to latest Kafka: `2.1.0`\n-\tSet scala version for Kafka `2.1.0` and `2.0.1` to recommended `2.12`\n\n10-Nov-2018\n-----------\n\n-\tUpdate to Kafka `2.0.0` -> `2.0.1`.\n-\tUpdate glibc to `2.28-r0`\n-\tUpdate base image to openjdk:8u181-jre-alpine\n\n29-Jun-2018\n-----------\n\n-\t**MAJOR:** Use new docker image labelling (`<scala-version>-<kafka-version>`) and use travis to publish images.\n-\tUpdate base image to openjdk:8u171-jre-alpine\n\n20-Apr-2018\n-----------\n\n-\tIssue #312 - Fix conflict between KAFKA_xxx broker config values (e.g. KAFKA_JMX_OPTS) and container configuration options (e.g. KAFKA_CREATE_TOPICS)\n\n19-Apr-2018\n-----------\n\n-\tIssue #310 - Only return Apache download mirrors that can supply required kafka/scala version\n\n11-Apr-2018\n-----------\n\n-\tIssue #313 - Fix parsing of environment value substitution when spaces included.\n\n08-Apr-2018\n-----------\n\n-\tIssue #208 - Add `KAFKA_CREATE_TOPICS_SEPARATOR` to allow custom input, such as multi-line YAML.\n-\tIssue #298 - Fix SNAPPY compression support by adding glibc port back into image (removed when switching to openjdk base image in #7a25ade)\n\n04-Apr-2018\n-----------\n\n-\tSupport `_{PORT_COMMAND}` placeholder.\n\n03-Apr-2018\n-----------\n\n-\t**BREAKING:** removed `KAFKA_ADVERTISED_PROTOCOL_NAME` and `KAFKA_PROTOCOL_NAME`. Use the canonical [Kafka Configuration](http://kafka.apache.org/documentation.html#brokerconfigs) instead.\n-\tSupport `_{HOSTNAME_COMMAND}` placeholder.\n-\t**BREAKING:** Make `KAFKA_ZOOKEEPER_CONNECT` mandatory\n"
        },
        {
          "name": "Dockerfile",
          "type": "blob",
          "size": 2.2421875,
          "content": "FROM openjdk:11-jre-slim\n\nARG kafka_version=2.8.1\nARG scala_version=2.13\nARG vcs_ref=unspecified\nARG build_date=unspecified\n\nLABEL org.label-schema.name=\"kafka\" \\\n      org.label-schema.description=\"Apache Kafka\" \\\n      org.label-schema.build-date=\"${build_date}\" \\\n      org.label-schema.vcs-url=\"https://github.com/wurstmeister/kafka-docker\" \\\n      org.label-schema.vcs-ref=\"${vcs_ref}\" \\\n      org.label-schema.version=\"${scala_version}_${kafka_version}\" \\\n      org.label-schema.schema-version=\"1.0\" \\\n      maintainer=\"wurstmeister\"\n\nENV KAFKA_VERSION=$kafka_version \\\n    SCALA_VERSION=$scala_version \\\n    KAFKA_HOME=/opt/kafka\n\nENV PATH=${PATH}:${KAFKA_HOME}/bin\n\nCOPY download-kafka.sh start-kafka.sh broker-list.sh create-topics.sh versions.sh /tmp2/\n\nRUN set -eux ; \\\n    apt-get update ; \\\n    apt-get upgrade -y ; \\\n    apt-get install -y --no-install-recommends jq net-tools curl wget ; \\\n### BEGIN docker for CI tests\n    apt-get install -y --no-install-recommends gnupg lsb-release ; \\\n\tcurl -fsSL https://download.docker.com/linux/debian/gpg | gpg --dearmor -o /usr/share/keyrings/docker-archive-keyring.gpg ; \\\n\techo \\\n  \t\t\"deb [arch=$(dpkg --print-architecture) signed-by=/usr/share/keyrings/docker-archive-keyring.gpg] https://download.docker.com/linux/debian \\\n  \t\t$(lsb_release -cs) stable\" | tee /etc/apt/sources.list.d/docker.list > /dev/null ; \\\n    apt-get update ; \\\n    apt-get install -y --no-install-recommends docker-ce-cli ; \\\n    apt remove -y gnupg lsb-release ; \\\n    apt clean ; \\\n    apt autoremove -y ; \\\n    apt -f install ; \\\n### END docker for CI tests\n### BEGIN other for CI tests\n    apt-get install -y --no-install-recommends netcat ; \\\n### END other for CI tests\n    chmod a+x /tmp2/*.sh ; \\\n    mv /tmp2/start-kafka.sh /tmp2/broker-list.sh /tmp2/create-topics.sh /tmp2/versions.sh /usr/bin ; \\\n    sync ; \\\n    /tmp2/download-kafka.sh ; \\\n    tar xfz /tmp2/kafka_${SCALA_VERSION}-${KAFKA_VERSION}.tgz -C /opt ; \\\n    rm /tmp2/kafka_${SCALA_VERSION}-${KAFKA_VERSION}.tgz ; \\\n    ln -s /opt/kafka_${SCALA_VERSION}-${KAFKA_VERSION} ${KAFKA_HOME} ; \\\n    rm -rf /tmp2 ; \\\n    rm -rf /var/lib/apt/lists/*\n\nCOPY overrides /opt/overrides\n\nVOLUME [\"/kafka\"]\n\n# Use \"exec\" form so that it runs as PID 1 (useful for graceful shutdown)\nCMD [\"start-kafka.sh\"]\n"
        },
        {
          "name": "LICENSE",
          "type": "blob",
          "size": 11.0595703125,
          "content": "Apache License\n                           Version 2.0, January 2004\n                        http://www.apache.org/licenses/\n\n   TERMS AND CONDITIONS FOR USE, REPRODUCTION, AND DISTRIBUTION\n\n   1. Definitions.\n\n      \"License\" shall mean the terms and conditions for use, reproduction,\n      and distribution as defined by Sections 1 through 9 of this document.\n\n      \"Licensor\" shall mean the copyright owner or entity authorized by\n      the copyright owner that is granting the License.\n\n      \"Legal Entity\" shall mean the union of the acting entity and all\n      other entities that control, are controlled by, or are under common\n      control with that entity. For the purposes of this definition,\n      \"control\" means (i) the power, direct or indirect, to cause the\n      direction or management of such entity, whether by contract or\n      otherwise, or (ii) ownership of fifty percent (50%) or more of the\n      outstanding shares, or (iii) beneficial ownership of such entity.\n\n      \"You\" (or \"Your\") shall mean an individual or Legal Entity\n      exercising permissions granted by this License.\n\n      \"Source\" form shall mean the preferred form for making modifications,\n      including but not limited to software source code, documentation\n      source, and configuration files.\n\n      \"Object\" form shall mean any form resulting from mechanical\n      transformation or translation of a Source form, including but\n      not limited to compiled object code, generated documentation,\n      and conversions to other media types.\n\n      \"Work\" shall mean the work of authorship, whether in Source or\n      Object form, made available under the License, as indicated by a\n      copyright notice that is included in or attached to the work\n      (an example is provided in the Appendix below).\n\n      \"Derivative Works\" shall mean any work, whether in Source or Object\n      form, that is based on (or derived from) the Work and for which the\n      editorial revisions, annotations, elaborations, or other modifications\n      represent, as a whole, an original work of authorship. For the purposes\n      of this License, Derivative Works shall not include works that remain\n      separable from, or merely link (or bind by name) to the interfaces of,\n      the Work and Derivative Works thereof.\n\n      \"Contribution\" shall mean any work of authorship, including\n      the original version of the Work and any modifications or additions\n      to that Work or Derivative Works thereof, that is intentionally\n      submitted to Licensor for inclusion in the Work by the copyright owner\n      or by an individual or Legal Entity authorized to submit on behalf of\n      the copyright owner. For the purposes of this definition, \"submitted\"\n      means any form of electronic, verbal, or written communication sent\n      to the Licensor or its representatives, including but not limited to\n      communication on electronic mailing lists, source code control systems,\n      and issue tracking systems that are managed by, or on behalf of, the\n      Licensor for the purpose of discussing and improving the Work, but\n      excluding communication that is conspicuously marked or otherwise\n      designated in writing by the copyright owner as \"Not a Contribution.\"\n\n      \"Contributor\" shall mean Licensor and any individual or Legal Entity\n      on behalf of whom a Contribution has been received by Licensor and\n      subsequently incorporated within the Work.\n\n   2. Grant of Copyright License. Subject to the terms and conditions of\n      this License, each Contributor hereby grants to You a perpetual,\n      worldwide, non-exclusive, no-charge, royalty-free, irrevocable\n      copyright license to reproduce, prepare Derivative Works of,\n      publicly display, publicly perform, sublicense, and distribute the\n      Work and such Derivative Works in Source or Object form.\n\n   3. Grant of Patent License. Subject to the terms and conditions of\n      this License, each Contributor hereby grants to You a perpetual,\n      worldwide, non-exclusive, no-charge, royalty-free, irrevocable\n      (except as stated in this section) patent license to make, have made,\n      use, offer to sell, sell, import, and otherwise transfer the Work,\n      where such license applies only to those patent claims licensable\n      by such Contributor that are necessarily infringed by their\n      Contribution(s) alone or by combination of their Contribution(s)\n      with the Work to which such Contribution(s) was submitted. If You\n      institute patent litigation against any entity (including a\n      cross-claim or counterclaim in a lawsuit) alleging that the Work\n      or a Contribution incorporated within the Work constitutes direct\n      or contributory patent infringement, then any patent licenses\n      granted to You under this License for that Work shall terminate\n      as of the date such litigation is filed.\n\n   4. Redistribution. You may reproduce and distribute copies of the\n      Work or Derivative Works thereof in any medium, with or without\n      modifications, and in Source or Object form, provided that You\n      meet the following conditions:\n\n      (a) You must give any other recipients of the Work or\n          Derivative Works a copy of this License; and\n\n      (b) You must cause any modified files to carry prominent notices\n          stating that You changed the files; and\n\n      (c) You must retain, in the Source form of any Derivative Works\n          that You distribute, all copyright, patent, trademark, and\n          attribution notices from the Source form of the Work,\n          excluding those notices that do not pertain to any part of\n          the Derivative Works; and\n\n      (d) If the Work includes a \"NOTICE\" text file as part of its\n          distribution, then any Derivative Works that You distribute must\n          include a readable copy of the attribution notices contained\n          within such NOTICE file, excluding those notices that do not\n          pertain to any part of the Derivative Works, in at least one\n          of the following places: within a NOTICE text file distributed\n          as part of the Derivative Works; within the Source form or\n          documentation, if provided along with the Derivative Works; or,\n          within a display generated by the Derivative Works, if and\n          wherever such third-party notices normally appear. The contents\n          of the NOTICE file are for informational purposes only and\n          do not modify the License. You may add Your own attribution\n          notices within Derivative Works that You distribute, alongside\n          or as an addendum to the NOTICE text from the Work, provided\n          that such additional attribution notices cannot be construed\n          as modifying the License.\n\n      You may add Your own copyright statement to Your modifications and\n      may provide additional or different license terms and conditions\n      for use, reproduction, or distribution of Your modifications, or\n      for any such Derivative Works as a whole, provided Your use,\n      reproduction, and distribution of the Work otherwise complies with\n      the conditions stated in this License.\n\n   5. Submission of Contributions. Unless You explicitly state otherwise,\n      any Contribution intentionally submitted for inclusion in the Work\n      by You to the Licensor shall be under the terms and conditions of\n      this License, without any additional terms or conditions.\n      Notwithstanding the above, nothing herein shall supersede or modify\n      the terms of any separate license agreement you may have executed\n      with Licensor regarding such Contributions.\n\n   6. Trademarks. This License does not grant permission to use the trade\n      names, trademarks, service marks, or product names of the Licensor,\n      except as required for reasonable and customary use in describing the\n      origin of the Work and reproducing the content of the NOTICE file.\n\n   7. Disclaimer of Warranty. Unless required by applicable law or\n      agreed to in writing, Licensor provides the Work (and each\n      Contributor provides its Contributions) on an \"AS IS\" BASIS,\n      WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or\n      implied, including, without limitation, any warranties or conditions\n      of TITLE, NON-INFRINGEMENT, MERCHANTABILITY, or FITNESS FOR A\n      PARTICULAR PURPOSE. You are solely responsible for determining the\n      appropriateness of using or redistributing the Work and assume any\n      risks associated with Your exercise of permissions under this License.\n\n   8. Limitation of Liability. In no event and under no legal theory,\n      whether in tort (including negligence), contract, or otherwise,\n      unless required by applicable law (such as deliberate and grossly\n      negligent acts) or agreed to in writing, shall any Contributor be\n      liable to You for damages, including any direct, indirect, special,\n      incidental, or consequential damages of any character arising as a\n      result of this License or out of the use or inability to use the\n      Work (including but not limited to damages for loss of goodwill,\n      work stoppage, computer failure or malfunction, or any and all\n      other commercial damages or losses), even if such Contributor\n      has been advised of the possibility of such damages.\n\n   9. Accepting Warranty or Additional Liability. While redistributing\n      the Work or Derivative Works thereof, You may choose to offer,\n      and charge a fee for, acceptance of support, warranty, indemnity,\n      or other liability obligations and/or rights consistent with this\n      License. However, in accepting such obligations, You may act only\n      on Your own behalf and on Your sole responsibility, not on behalf\n      of any other Contributor, and only if You agree to indemnify,\n      defend, and hold each Contributor harmless for any liability\n      incurred by, or claims asserted against, such Contributor by reason\n      of your accepting any such warranty or additional liability.\n\n   END OF TERMS AND CONDITIONS\n\n   APPENDIX: How to apply the Apache License to your work.\n\n      To apply the Apache License to your work, attach the following\n      boilerplate notice, with the fields enclosed by brackets \"{}\"\n      replaced with your own identifying information. (Don't include\n      the brackets!)  The text should be enclosed in the appropriate\n      comment syntax for the file format. We also recommend that a\n      file or class name and description of purpose be included on the\n      same \"printed page\" as the copyright notice for easier\n      identification within third-party archives.\n\n   Copyright {yyyy} {name of copyright owner}\n\n   Licensed under the Apache License, Version 2.0 (the \"License\");\n   you may not use this file except in compliance with the License.\n   You may obtain a copy of the License at\n\n       http://www.apache.org/licenses/LICENSE-2.0\n\n   Unless required by applicable law or agreed to in writing, software\n   distributed under the License is distributed on an \"AS IS\" BASIS,\n   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n   See the License for the specific language governing permissions and\n   limitations under the License.\n\n"
        },
        {
          "name": "README.md",
          "type": "blob",
          "size": 10.861328125,
          "content": "[![Docker Pulls](https://img.shields.io/docker/pulls/wurstmeister/kafka.svg)](https://hub.docker.com/r/wurstmeister/kafka/)\n[![Docker Stars](https://img.shields.io/docker/stars/wurstmeister/kafka.svg)](https://hub.docker.com/r/wurstmeister/kafka/)\n[![](https://images.microbadger.com/badges/version/wurstmeister/kafka.svg)](https://microbadger.com/images/wurstmeister/kafka \"Get your own version badge on microbadger.com\")\n[![](https://images.microbadger.com/badges/image/wurstmeister/kafka.svg)](https://microbadger.com/images/wurstmeister/kafka \"Get your own image badge on microbadger.com\")\n[![Build Status](https://app.travis-ci.com/wurstmeister/kafka-docker.svg?branch=master)](https://app.travis-ci.com/wurstmeister/kafka-docker)\n\n\nkafka-docker\n============\n\nDockerfile for [Apache Kafka](http://kafka.apache.org/)\n\nThe image is available directly from [Docker Hub](https://hub.docker.com/r/wurstmeister/kafka/)\n\nTags and releases\n-----------------\n\nAll versions of the image are built from the same set of scripts with only minor variations (i.e. certain features are not supported on older versions). The version format mirrors the Kafka format, `<scala version>-<kafka version>`. Initially, all images are built with the recommended version of scala documented on [http://kafka.apache.org/downloads](http://kafka.apache.org/downloads). To list all available tags:\n\n```\ncurl -s https://registry.hub.docker.com/v2/repositories/wurstmeister/kafka/tags\\?page_size\\=1024 | jq -r '.results[].name' | sort -u | egrep '\\d.\\d{2}-.*'\n```\n\nEverytime the image is updated, all tags will be pushed with the latest updates. This should allow for greater consistency across tags, as well as any security updates that have been made to the base image.\n\n---\n\n## Announcements\n\n* **04-Jun-2019** - Update base image to openjdk 212 ([Release notes](https://www.oracle.com/technetwork/java/javase/8u212-relnotes-5292913.html). Please force pull to get these latest updates - including security patches etc.\n\n---\n\n## Pre-Requisites\n\n- install docker-compose [https://docs.docker.com/compose/install/](https://docs.docker.com/compose/install/)\n- modify the ```KAFKA_ADVERTISED_HOST_NAME``` in [docker-compose.yml](https://raw.githubusercontent.com/wurstmeister/kafka-docker/master/docker-compose.yml) to match your docker host IP (Note: Do not use localhost or 127.0.0.1 as the host ip if you want to run multiple brokers.)\n- if you want to customize any Kafka parameters, simply add them as environment variables in ```docker-compose.yml```, e.g. in order to increase the ```message.max.bytes``` parameter set the environment to ```KAFKA_MESSAGE_MAX_BYTES: 2000000```. To turn off automatic topic creation set ```KAFKA_AUTO_CREATE_TOPICS_ENABLE: 'false'```\n- Kafka's log4j usage can be customized by adding environment variables prefixed with ```LOG4J_```. These will be mapped to ```log4j.properties```. For example: ```LOG4J_LOGGER_KAFKA_AUTHORIZER_LOGGER=DEBUG, authorizerAppender```\n\n**NOTE:** There are several 'gotchas' with configuring networking. If you are not sure about what the requirements are, please check out the [Connectivity Guide](https://github.com/wurstmeister/kafka-docker/wiki/Connectivity) in the [Wiki](https://github.com/wurstmeister/kafka-docker/wiki)\n\n## Usage\n\nStart a cluster:\n\n- ```docker-compose up -d ```\n\nAdd more brokers:\n\n- ```docker-compose scale kafka=3```\n\nDestroy a cluster:\n\n- ```docker-compose stop```\n\n## Note\n\nThe default ```docker-compose.yml``` should be seen as a starting point. By default each broker will get a new port number and broker id on restart. Depending on your use case this might not be desirable. If you need to use specific ports and broker ids, modify the docker-compose configuration accordingly, e.g. [docker-compose-single-broker.yml](https://github.com/wurstmeister/kafka-docker/blob/master/docker-compose-single-broker.yml):\n\n- ```docker-compose -f docker-compose-single-broker.yml up```\n\n## Broker IDs\n\nYou can configure the broker id in different ways\n\n1. explicitly, using ```KAFKA_BROKER_ID```\n2. via a command, using ```BROKER_ID_COMMAND```, e.g. ```BROKER_ID_COMMAND: \"hostname | awk -F'-' '{print $$2}'\"```\n\nIf you don't specify a broker id in your docker-compose file, it will automatically be generated (see [https://issues.apache.org/jira/browse/KAFKA-1070](https://issues.apache.org/jira/browse/KAFKA-1070). This allows scaling up and down. In this case it is recommended to use the ```--no-recreate``` option of docker-compose to ensure that containers are not re-created and thus keep their names and ids.\n\n\n## Automatically create topics\n\nIf you want to have kafka-docker automatically create topics in Kafka during\ncreation, a ```KAFKA_CREATE_TOPICS``` environment variable can be\nadded in ```docker-compose.yml```.\n\nHere is an example snippet from ```docker-compose.yml```:\n\n        environment:\n          KAFKA_CREATE_TOPICS: \"Topic1:1:3,Topic2:1:1:compact\"\n\n```Topic 1``` will have 1 partition and 3 replicas, ```Topic 2``` will have 1 partition, 1 replica and a `cleanup.policy` set to `compact`. Also, see FAQ: [Topic compaction does not work](https://github.com/wurstmeister/kafka-docker/wiki#topic-compaction-does-not-work)\n\nIf you wish to use multi-line YAML or some other delimiter between your topic definitions, override the default `,` separator by specifying the `KAFKA_CREATE_TOPICS_SEPARATOR` environment variable.\n\nFor example, `KAFKA_CREATE_TOPICS_SEPARATOR: \"$$'\\n'\"` would use a newline to split the topic definitions. Syntax has to follow docker-compose escaping rules, and [ANSI-C](https://www.gnu.org/software/bash/manual/html_node/ANSI_002dC-Quoting.html) quoting.\n\n## Advertised hostname\n\nYou can configure the advertised hostname in different ways\n\n1. explicitly, using ```KAFKA_ADVERTISED_HOST_NAME```\n2. via a command, using ```HOSTNAME_COMMAND```, e.g. ```HOSTNAME_COMMAND: \"route -n | awk '/UG[ \\t]/{print $$2}'\"```\n\nWhen using commands, make sure you review the \"Variable Substitution\" section in [https://docs.docker.com/compose/compose-file/](https://docs.docker.com/compose/compose-file/#variable-substitution)\n\nIf ```KAFKA_ADVERTISED_HOST_NAME``` is specified, it takes precedence over ```HOSTNAME_COMMAND```\n\nFor AWS deployment, you can use the Metadata service to get the container host's IP:\n```\nHOSTNAME_COMMAND=wget -t3 -T2 -qO-  http://169.254.169.254/latest/meta-data/local-ipv4\n```\nReference: http://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ec2-instance-metadata.html\n\n### Injecting HOSTNAME_COMMAND into configuration\n\nIf you require the value of `HOSTNAME_COMMAND` in any of your other `KAFKA_XXX` variables, use the `_{HOSTNAME_COMMAND}` string in your variable value, i.e.\n\n```\nKAFKA_ADVERTISED_LISTENERS=SSL://_{HOSTNAME_COMMAND}:9093,PLAINTEXT://9092\n```\n\n## Advertised port\n\nIf the required advertised port is not static, it may be necessary to determine this programatically. This can be done with the `PORT_COMMAND` environment variable.\n\n```\nPORT_COMMAND: \"docker port $$(hostname) 9092/tcp | cut -d: -f2\"\n```\n\nThis can be then interpolated in any other `KAFKA_XXX` config using the `_{PORT_COMMAND}` string, i.e.\n\n```\nKAFKA_ADVERTISED_LISTENERS: PLAINTEXT://1.2.3.4:_{PORT_COMMAND}\n```\n\n## Listener Configuration\n\nIt may be useful to have the [Kafka Documentation](https://kafka.apache.org/documentation/) open, to understand the various broker listener configuration options.\n\nSince 0.9.0, Kafka has supported [multiple listener configurations](https://issues.apache.org/jira/browse/KAFKA-1809) for brokers to help support different protocols and discriminate between internal and external traffic. Later versions of Kafka have deprecated ```advertised.host.name``` and ```advertised.port```.\n\n**NOTE:** ```advertised.host.name``` and ```advertised.port``` still work as expected, but should not be used if configuring the listeners.\n\n### Example\n\nThe example environment below:\n\n```\nHOSTNAME_COMMAND: curl http://169.254.169.254/latest/meta-data/public-hostname\nKAFKA_ADVERTISED_LISTENERS: INSIDE://:9092,OUTSIDE://_{HOSTNAME_COMMAND}:9094\nKAFKA_LISTENERS: INSIDE://:9092,OUTSIDE://:9094\nKAFKA_LISTENER_SECURITY_PROTOCOL_MAP: INSIDE:PLAINTEXT,OUTSIDE:PLAINTEXT\nKAFKA_INTER_BROKER_LISTENER_NAME: INSIDE\n```\n\nWill result in the following broker config:\n\n```\nadvertised.listeners = OUTSIDE://ec2-xx-xx-xxx-xx.us-west-2.compute.amazonaws.com:9094,INSIDE://:9092\nlisteners = OUTSIDE://:9094,INSIDE://:9092\ninter.broker.listener.name = INSIDE\n```\n\n### Rules\n\n* No listeners may share a port number.\n* An advertised.listener must be present by protocol name and port number in the list of listeners.\n\n## Broker Rack\n\nYou can configure the broker rack affinity in different ways\n\n1. explicitly, using ```KAFKA_BROKER_RACK```\n2. via a command, using ```RACK_COMMAND```, e.g. ```RACK_COMMAND: \"curl http://169.254.169.254/latest/meta-data/placement/availability-zone\"```\n\nIn the above example the AWS metadata service is used to put the instance's availability zone in the ```broker.rack``` property.\n\n## JMX\n\nFor monitoring purposes you may wish to configure JMX. Additional to the standard JMX parameters, problems could arise from the underlying RMI protocol used to connect\n\n* java.rmi.server.hostname - interface to bind listening port\n* com.sun.management.jmxremote.rmi.port - The port to service RMI requests\n\nFor example, to connect to a kafka running locally (assumes exposing port 1099)\n\n      KAFKA_JMX_OPTS: \"-Dcom.sun.management.jmxremote -Dcom.sun.management.jmxremote.authenticate=false -Dcom.sun.management.jmxremote.ssl=false -Djava.rmi.server.hostname=127.0.0.1 -Dcom.sun.management.jmxremote.rmi.port=1099\"\n      JMX_PORT: 1099\n\nJconsole can now connect at ```jconsole 192.168.99.100:1099```\n\n## Docker Swarm Mode\n\nThe listener configuration above is necessary when deploying Kafka in a Docker Swarm using an overlay network. By separating OUTSIDE and INSIDE listeners, a host can communicate with clients outside the overlay network while still benefiting from it from within the swarm.\n\nIn addition to the multiple-listener configuration, additional best practices for operating Kafka in a Docker Swarm include:\n\n* Use \"deploy: global\" in a compose file to launch one and only one Kafka broker per swarm node.\n* Use compose file version '3.2' (minimum Docker version 16.04) and the \"long\" port definition with the port in \"host\" mode instead of the default \"ingress\" load-balanced port binding. This ensures that outside requests are always routed to the correct broker. For example:\n\n```\nports:\n   - target: 9094\n     published: 9094\n     protocol: tcp\n     mode: host\n```\n\nOlder compose files using the short-version of port mapping may encounter Kafka client issues if their connection to individual brokers cannot be guaranteed.\n\nSee the included sample compose file ```docker-compose-swarm.yml```\n\n## Release process\n\nSee the [wiki](https://github.com/wurstmeister/kafka-docker/wiki/ReleaseProcess) for information on adding or updating versions to release to Dockerhub.\n\n## Tutorial\n\n[http://wurstmeister.github.io/kafka-docker/](http://wurstmeister.github.io/kafka-docker/)\n"
        },
        {
          "name": "broker-list.sh",
          "type": "blob",
          "size": 0.2060546875,
          "content": "#!/bin/bash\n\nCONTAINERS=$(docker ps | grep 9092 | awk '{print $1}')\nBROKERS=$(for CONTAINER in ${CONTAINERS}; do docker port \"$CONTAINER\" 9092 | sed -e \"s/0.0.0.0:/$HOST_IP:/g\"; done)\necho \"${BROKERS//$'\\n'/,}\"\n"
        },
        {
          "name": "create-topics.sh",
          "type": "blob",
          "size": 1.482421875,
          "content": "#!/bin/bash\n\nif [[ -z \"$KAFKA_CREATE_TOPICS\" ]]; then\n    exit 0\nfi\n\nif [[ -z \"$START_TIMEOUT\" ]]; then\n    START_TIMEOUT=600\nfi\n\nstart_timeout_exceeded=false\ncount=0\nstep=10\nwhile netstat -lnt | awk '$4 ~ /:'\"$KAFKA_PORT\"'$/ {exit 1}'; do\n    echo \"waiting for kafka to be ready\"\n    sleep $step;\n    count=$((count + step))\n    if [ $count -gt $START_TIMEOUT ]; then\n        start_timeout_exceeded=true\n        break\n    fi\ndone\n\nif $start_timeout_exceeded; then\n    echo \"Not able to auto-create topic (waited for $START_TIMEOUT sec)\"\n    exit 1\nfi\n\n# introduced in 0.10. In earlier versions, this will fail because the topic already exists.\n# shellcheck disable=SC1091\nsource \"/usr/bin/versions.sh\"\nif [[ \"$MAJOR_VERSION\" == \"0\" && \"$MINOR_VERSION\" -gt \"9\" ]] || [[ \"$MAJOR_VERSION\" -gt \"0\" ]]; then\n    KAFKA_0_10_OPTS=\"--if-not-exists\"\nfi\n\n# Expected format:\n#   name:partitions:replicas:cleanup.policy\nIFS=\"${KAFKA_CREATE_TOPICS_SEPARATOR-,}\"; for topicToCreate in $KAFKA_CREATE_TOPICS; do\n    echo \"creating topics: $topicToCreate\"\n    IFS=':' read -r -a topicConfig <<< \"$topicToCreate\"\n    config=\n    if [ -n \"${topicConfig[3]}\" ]; then\n        config=\"--config=cleanup.policy=${topicConfig[3]}\"\n    fi\n\n    COMMAND=\"JMX_PORT='' ${KAFKA_HOME}/bin/kafka-topics.sh \\\\\n\t\t--create \\\\\n\t\t--zookeeper ${KAFKA_ZOOKEEPER_CONNECT} \\\\\n\t\t--topic ${topicConfig[0]} \\\\\n\t\t--partitions ${topicConfig[1]} \\\\\n\t\t--replication-factor ${topicConfig[2]} \\\\\n\t\t${config} \\\\\n\t\t${KAFKA_0_10_OPTS} &\"\n    eval \"${COMMAND}\"\ndone\n\nwait\n"
        },
        {
          "name": "docker-compose-single-broker.yml",
          "type": "blob",
          "size": 0.3583984375,
          "content": "version: '2'\nservices:\n  zookeeper:\n    image: wurstmeister/zookeeper\n    ports:\n      - \"2181:2181\"\n  kafka:\n    build: .\n    ports:\n      - \"9092:9092\"\n    environment:\n      KAFKA_ADVERTISED_HOST_NAME: 192.168.99.100\n      KAFKA_CREATE_TOPICS: \"test:1:1\"\n      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181\n    volumes:\n      - /var/run/docker.sock:/var/run/docker.sock\n"
        },
        {
          "name": "docker-compose-swarm.yml",
          "type": "blob",
          "size": 0.6884765625,
          "content": "version: '3.2'\nservices:\n  zookeeper:\n    image: wurstmeister/zookeeper\n    ports:\n      - \"2181:2181\"\n  kafka:\n    image: wurstmeister/kafka:latest\n    ports:\n      - target: 9094\n        published: 9094\n        protocol: tcp\n        mode: host\n    environment:\n      HOSTNAME_COMMAND: \"docker info | grep ^Name: | cut -d' ' -f 2\"\n      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181\n      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: INSIDE:PLAINTEXT,OUTSIDE:PLAINTEXT\n      KAFKA_ADVERTISED_LISTENERS: INSIDE://:9092,OUTSIDE://_{HOSTNAME_COMMAND}:9094\n      KAFKA_LISTENERS: INSIDE://:9092,OUTSIDE://:9094\n      KAFKA_INTER_BROKER_LISTENER_NAME: INSIDE\n    volumes:\n      - /var/run/docker.sock:/var/run/docker.sock\n"
        },
        {
          "name": "docker-compose.yml",
          "type": "blob",
          "size": 0.40234375,
          "content": "version: '2'\nservices:\n  zookeeper:\n    image: wurstmeister/zookeeper\n    ports:\n      - \"2181:2181\"\n    restart: unless-stopped\n\n  kafka:\n    build: .\n    ports:\n      - \"9092\"\n    environment:\n      DOCKER_API_VERSION: 1.22\n      KAFKA_ADVERTISED_HOST_NAME: 192.168.99.100\n      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181\n    volumes:\n      - /var/run/docker.sock:/var/run/docker.sock\n    restart: unless-stopped\n"
        },
        {
          "name": "docker_buildx",
          "type": "blob",
          "size": 1.1083984375,
          "content": "#!/bin/bash -e\n\n# Build for amd64 and arm64\nPLATFORMS=\"linux/amd64,linux/arm64\"\n\nEXTRA_BUILDX_ARGS=$@\nCACHE_LOCATION=\"/tmp/docker-cache\"\n\nif [[ \"${EXTRA_BUILDX_ARGS}\" == *\"--load\"* ]]; then\n    # We have to load the image for the current architecture only in order to run tests, so let's\n    # pull FROM the multi-arch build that happened previously\n    PLATFORMS=\"linux/${TRAVIS_CPU_ARCH}\"\n    CACHE=\"--cache-from=type=local,src=${CACHE_LOCATION}\"\nelif [[ \"${EXTRA_BUILDX_ARGS}\" == *\"--push\"* ]]; then\n    # Push ALL architectures FROM the multi-arch build cache that happened previously\n    CACHE=\"--cache-from=type=local,src=${CACHE_LOCATION}\"\nelse\n    # This is the multi-arch build that we should cache and use later\n    CACHE=\"--cache-to=type=local,dest=${CACHE_LOCATION}\"\nfi\n\ndocker buildx build \\\n    $CACHE \\\n    --platform \"${PLATFORMS}\" \\\n    --progress=plain \\\n    --build-arg kafka_version=$KAFKA_VERSION \\\n    --build-arg scala_version=$TRAVIS_SCALA_VERSION \\\n    --build-arg vcs_ref=$TRAVIS_COMMIT \\\n    --build-arg build_date=$(date -u +\"%Y-%m-%dT%H:%M:%SZ\") \\\n    -t wurstmeister/kafka \\\n    $EXTRA_BUILDX_ARGS \\\n    ."
        },
        {
          "name": "docker_push",
          "type": "blob",
          "size": 0.3115234375,
          "content": "#!/bin/bash -e\n\nBASE_IMAGE=\"wurstmeister/kafka\"\nIMAGE_VERSION=\"$1\"\n\nif [ -z \"$IMAGE_VERSION\" ]; then\n  echo \"No IMAGE_VERSION var specified\"\n  exit 1\nfi\n\necho \"$DOCKER_PASSWORD\" | docker login -u \"$DOCKER_USERNAME\" --password-stdin\nTARGET=\"$BASE_IMAGE:$IMAGE_VERSION\"\nbash docker_buildx \\\n    -t \"$TARGET\" \\\n    --push\n"
        },
        {
          "name": "download-kafka.sh",
          "type": "blob",
          "size": 0.7216796875,
          "content": "#!/bin/sh -e\n\n# shellcheck disable=SC1091\n. \"/usr/bin/versions.sh\"\n\nFILENAME=\"kafka_${SCALA_VERSION}-${KAFKA_VERSION}.tgz\"\n\nurl=$(curl --stderr /dev/null \"https://www.apache.org/dyn/closer.cgi?path=/kafka/${KAFKA_VERSION}/${FILENAME}&as_json=1\" | jq -r '\"\\(.preferred)\\(.path_info)\"')\n\n# Test to see if the suggested mirror has this version, currently pre 2.1.1 versions\n# do not appear to be actively mirrored. This may also be useful if closer.cgi is down.\nif [ ! \"$(curl -f -s -r 0-1 \"${url}\")\" ]; then\n    echo \"Mirror does not have desired version, downloading direct from Apache\"\n    url=\"https://archive.apache.org/dist/kafka/${KAFKA_VERSION}/${FILENAME}\"\nfi\n\necho \"Downloading Kafka from $url\"\nwget \"${url}\" -O \"/tmp2/${FILENAME}\"\n"
        },
        {
          "name": "overrides",
          "type": "tree",
          "content": null
        },
        {
          "name": "start-kafka-shell.sh",
          "type": "blob",
          "size": 0.1279296875,
          "content": "#!/bin/bash\ndocker run --rm -v /var/run/docker.sock:/var/run/docker.sock -e HOST_IP=$1 -e ZK=$2 -i -t wurstmeister/kafka /bin/bash\n"
        },
        {
          "name": "start-kafka.sh",
          "type": "blob",
          "size": 4.859375,
          "content": "#!/bin/bash -e\n\n# Allow specific kafka versions to perform any unique bootstrap operations\nOVERRIDE_FILE=\"/opt/overrides/${KAFKA_VERSION}.sh\"\nif [[ -x \"$OVERRIDE_FILE\" ]]; then\n    echo \"Executing override file $OVERRIDE_FILE\"\n    eval \"$OVERRIDE_FILE\"\nfi\n\n# Store original IFS config, so we can restore it at various stages\nORIG_IFS=$IFS\n\nif [[ -z \"$KAFKA_ZOOKEEPER_CONNECT\" ]]; then\n    echo \"ERROR: missing mandatory config: KAFKA_ZOOKEEPER_CONNECT\"\n    exit 1\nfi\n\nif [[ -z \"$KAFKA_PORT\" ]]; then\n    export KAFKA_PORT=9092\nfi\n\ncreate-topics.sh &\nunset KAFKA_CREATE_TOPICS\n\nif [[ -z \"$KAFKA_ADVERTISED_PORT\" && \\\n  -z \"$KAFKA_LISTENERS\" && \\\n  -z \"$KAFKA_ADVERTISED_LISTENERS\" && \\\n  -S /var/run/docker.sock ]]; then\n    KAFKA_ADVERTISED_PORT=$(docker port \"$(hostname)\" $KAFKA_PORT | sed -r 's/.*:(.*)/\\1/g' | head -n1) \n    export KAFKA_ADVERTISED_PORT\nfi\n\nif [[ -z \"$KAFKA_BROKER_ID\" ]]; then\n    if [[ -n \"$BROKER_ID_COMMAND\" ]]; then\n        KAFKA_BROKER_ID=$(eval \"$BROKER_ID_COMMAND\")\n        export KAFKA_BROKER_ID\n    else\n        # By default auto allocate broker ID\n        export KAFKA_BROKER_ID=-1\n    fi\nfi\n\nif [[ -z \"$KAFKA_LOG_DIRS\" ]]; then\n    export KAFKA_LOG_DIRS=\"/kafka/kafka-logs-$HOSTNAME\"\nfi\n\nif [[ -n \"$KAFKA_HEAP_OPTS\" ]]; then\n    sed -r -i 's/(export KAFKA_HEAP_OPTS)=\"(.*)\"/\\1=\"'\"$KAFKA_HEAP_OPTS\"'\"/g' \"$KAFKA_HOME/bin/kafka-server-start.sh\"\n    unset KAFKA_HEAP_OPTS\nfi\n\nif [[ -n \"$HOSTNAME_COMMAND\" ]]; then\n    HOSTNAME_VALUE=$(eval \"$HOSTNAME_COMMAND\")\n\n    # Replace any occurrences of _{HOSTNAME_COMMAND} with the value\n    IFS=$'\\n'\n    for VAR in $(env); do\n        if [[ $VAR =~ ^KAFKA_ && \"$VAR\" =~ \"_{HOSTNAME_COMMAND}\" ]]; then\n            eval \"export ${VAR//_\\{HOSTNAME_COMMAND\\}/$HOSTNAME_VALUE}\"\n        fi\n    done\n    IFS=$ORIG_IFS\nfi\n\nif [[ -n \"$PORT_COMMAND\" ]]; then\n    PORT_VALUE=$(eval \"$PORT_COMMAND\")\n\n    # Replace any occurrences of _{PORT_COMMAND} with the value\n    IFS=$'\\n'\n    for VAR in $(env); do\n        if [[ $VAR =~ ^KAFKA_ && \"$VAR\" =~ \"_{PORT_COMMAND}\" ]]; then\n\t    eval \"export ${VAR//_\\{PORT_COMMAND\\}/$PORT_VALUE}\"\n        fi\n    done\n    IFS=$ORIG_IFS\nfi\n\nif [[ -n \"$RACK_COMMAND\" && -z \"$KAFKA_BROKER_RACK\" ]]; then\n    KAFKA_BROKER_RACK=$(eval \"$RACK_COMMAND\")\n    export KAFKA_BROKER_RACK\nfi\n\n# Try and configure minimal settings or exit with error if there isn't enough information\nif [[ -z \"$KAFKA_ADVERTISED_HOST_NAME$KAFKA_LISTENERS\" ]]; then\n    if [[ -n \"$KAFKA_ADVERTISED_LISTENERS\" ]]; then\n        echo \"ERROR: Missing environment variable KAFKA_LISTENERS. Must be specified when using KAFKA_ADVERTISED_LISTENERS\"\n        exit 1\n    elif [[ -z \"$HOSTNAME_VALUE\" ]]; then\n        echo \"ERROR: No listener or advertised hostname configuration provided in environment.\"\n        echo \"       Please define KAFKA_LISTENERS / (deprecated) KAFKA_ADVERTISED_HOST_NAME\"\n        exit 1\n    fi\n\n    # Maintain existing behaviour\n    # If HOSTNAME_COMMAND is provided, set that to the advertised.host.name value if listeners are not defined.\n    export KAFKA_ADVERTISED_HOST_NAME=\"$HOSTNAME_VALUE\"\nfi\n\n#Issue newline to config file in case there is not one already\necho \"\" >> \"$KAFKA_HOME/config/server.properties\"\n\n(\n    function updateConfig() {\n        key=$1\n        value=$2\n        file=$3\n\n        # Omit $value here, in case there is sensitive information\n        echo \"[Configuring] '$key' in '$file'\"\n\n        # If config exists in file, replace it. Otherwise, append to file.\n        if grep -E -q \"^#?$key=\" \"$file\"; then\n            sed -r -i \"s@^#?$key=.*@$key=$value@g\" \"$file\" #note that no config values may contain an '@' char\n        else\n            echo \"$key=$value\" >> \"$file\"\n        fi\n    }\n\n    # Fixes #312\n    # KAFKA_VERSION + KAFKA_HOME + grep -rohe KAFKA[A-Z0-0_]* /opt/kafka/bin | sort | uniq | tr '\\n' '|'\n    EXCLUSIONS=\"|KAFKA_VERSION|KAFKA_HOME|KAFKA_DEBUG|KAFKA_GC_LOG_OPTS|KAFKA_HEAP_OPTS|KAFKA_JMX_OPTS|KAFKA_JVM_PERFORMANCE_OPTS|KAFKA_LOG|KAFKA_OPTS|\"\n\n    # Read in env as a new-line separated array. This handles the case of env variables have spaces and/or carriage returns. See #313\n    IFS=$'\\n'\n    for VAR in $(env)\n    do\n        env_var=$(echo \"$VAR\" | cut -d= -f1)\n        if [[ \"$EXCLUSIONS\" = *\"|$env_var|\"* ]]; then\n            echo \"Excluding $env_var from broker config\"\n            continue\n        fi\n\n        if [[ $env_var =~ ^KAFKA_ ]]; then\n            kafka_name=$(echo \"$env_var\" | cut -d_ -f2- | tr '[:upper:]' '[:lower:]' | tr _ .)\n            updateConfig \"$kafka_name\" \"${!env_var}\" \"$KAFKA_HOME/config/server.properties\"\n        fi\n\n        if [[ $env_var =~ ^LOG4J_ ]]; then\n            log4j_name=$(echo \"$env_var\" | tr '[:upper:]' '[:lower:]' | tr _ .)\n            updateConfig \"$log4j_name\" \"${!env_var}\" \"$KAFKA_HOME/config/log4j.properties\"\n        fi\n    done\n)\n\nif [[ -n \"$CUSTOM_INIT_SCRIPT\" ]] ; then\n  eval \"$CUSTOM_INIT_SCRIPT\"\nfi\n\nexec \"$KAFKA_HOME/bin/kafka-server-start.sh\" \"$KAFKA_HOME/config/server.properties\"\n"
        },
        {
          "name": "test",
          "type": "tree",
          "content": null
        },
        {
          "name": "versions.sh",
          "type": "blob",
          "size": 0.1611328125,
          "content": "#!/bin/bash -e\n\nMAJOR_VERSION=$(echo \"$KAFKA_VERSION\" | cut -d. -f1)\nexport MAJOR_VERSION\n\nMINOR_VERSION=$(echo \"$KAFKA_VERSION\" | cut -d. -f2)\nexport MINOR_VERSION\n"
        }
      ]
    }
  ]
}