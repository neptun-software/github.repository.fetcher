{
  "metadata": {
    "timestamp": 1736568891369,
    "page": 98,
    "hasNextPage": true,
    "endCursor": "Y3Vyc29yOjEwMA==",
    "completionStatus": "IN_PROGRESS"
  },
  "repositories": [
    {
      "nameWithOwner": "holman/spark",
      "stars": 6015,
      "defaultBranch": "master",
      "files": [
        {
          "name": ".travis.yml",
          "type": "blob",
          "size": 0.216796875,
          "content": "language: bash\n\nbefore_script:\n    - curl -L https://github.com/bmizerany/roundup/tarball/v0.0.5 | tar xvzf -\n    - cd bmizerany-roundup-5c5dcb1 && ./configure && make && sudo make install\n    - cd -\n\nscript:\n    - ./test\n"
        },
        {
          "name": "CHANGELOG.md",
          "type": "blob",
          "size": 0.29296875,
          "content": "# changes\n\n## 1.0.0\n\nHey! A 1.0! Now's a decent time as any. Starting to cut versions just for the\nsake of things like Homebrew. So, might as well start with 1.0.\n\n1.0 encompasses things that happened during\n[the first week](https://zachholman.com/posts/from-hack-to-popular-project/)\nof development."
        },
        {
          "name": "LICENSE.md",
          "type": "blob",
          "size": 1.0654296875,
          "content": "The MIT License\n\nCopyright (c) Zach Holman, https://zachholman.com\n\nPermission is hereby granted, free of charge, to any person obtaining a copy\nof this software and associated documentation files (the \"Software\"), to deal\nin the Software without restriction, including without limitation the rights\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\ncopies of the Software, and to permit persons to whom the Software is\nfurnished to do so, subject to the following conditions:\n\nThe above copyright notice and this permission notice shall be included in\nall copies or substantial portions of the Software.\n\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN\nTHE SOFTWARE.\n"
        },
        {
          "name": "README.md",
          "type": "blob",
          "size": 3.2041015625,
          "content": "# spark\n### sparklines for your shell\n\nSee? Here's a graph of your productivity gains after using spark: ▁▂▃▅▇\n\n## install\n\nspark is a [shell script][bin], so drop it somewhere and make sure it's added\nto your `$PATH`. It's helpful if you have a super-neat collection of dotfiles,\n[like mine][dotfiles]. Or you can use the following one-liner:\n\n```sh\nsudo sh -c \"curl https://raw.githubusercontent.com/holman/spark/master/spark -o /usr/local/bin/spark && chmod +x /usr/local/bin/spark\"\n```\n\nIf you're on OS X, spark is also on [Homebrew][brew]:\n\n    brew install spark\n\nDepending on the fonts you have in your system and you use in the\nterminal, you might end up with irregular blocks. This is due to some\nfonts providing only part of the blocks, while the others are taken from\na different, fallback font.\n\n## usage\n\nJust run `spark` and pass it a list of numbers (comma-delimited, spaces,\nwhatever you'd like). It's designed to be used in conjunction with other\nscripts that can output in that format.\n\n    spark 0 30 55 80 33 150\n    ▁▂▃▅▂▇\n\nInvoke help with `spark -h`.\n\n## cooler usage\n\nThere's a lot of stuff you can do.\n\nNumber of commits to the github/github Git repository, by author:\n\n```sh\n› git shortlog -s |\n      cut -f1 |\n      spark\n  ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▃▁▁▁▁▁▁▁▁▂▁▁▅▁▂▁▁▁▂▁▁▁▁▁▁▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n```\n\nMagnitude of earthquakes worldwide 2.5 and above in the last 24 hours:\n\n```sh\n› curl -s https://earthquake.usgs.gov/earthquakes/feed/v1.0/summary/2.5_day.csv |\n  sed '1d' |\n  cut -d, -f5 |\n  spark\n▃█▅▅█▅▃▃▅█▃▃▁▅▅▃▃▅▁▁▃▃▃▃▃▅▃█▅▁▃▅▃█▃▁\n```\n\nCode visualization. The number of characters of `spark` itself, by line, ignoring empty lines:\n\n```sh\n› awk '{ print length($0) }' spark |\n  grep -Ev 0 |\n  spark\n  ▁▁▁▁▅▁▇▁▁▅▁▁▁▁▁▂▂▁▃▃▁▁▃▁▃▁▂▁▁▂▂▅▂▃▂▃▃▁▆▃▃▃▁▇▁▁▂▂▂▇▅▁▂▂▁▇▁▃▁▇▁▂▁▇▁▁▆▂▁▇▁▂▁▁▂▅▁▂▁▆▇▇▂▁▂▁▁▁▂▂▁▅▁▂▁▁▃▁▃▁▁▁▃▂▂▂▁▁▅▂▁▁▁▁▂▂▁▁▁▂▂\n```\n\nSince it's just a shell script, you could pop it in your prompt, too:\n\n```\nruby-1.8.7-p334 in spark/ on master with history: ▂▅▇▂\n›\n```\n\n## wicked cool usage\n\nSounds like a wiki is a great place to collect all of your\n[wicked cool usage][wiki] for spark.\n\n## contributing\n\nContributions welcome! Like seriously, I think contributions are real nifty.\n\nMake your changes and be sure the tests all pass:\n\n    ./test\n\nThat also means you should probably be adding your own tests as well as changing\nthe code. Wouldn't want to lose all your good work down the line, after all!\n\nOnce everything looks good, open a pull request.\n\n## ▇▁ ⟦⟧ ▇▁\n\nThis is a [@holman][holman] joint.\n\n[dotfiles]: https://github.com/holman/dotfiles\n[brew]:     https://github.com/mxcl/homebrew\n[bin]:      https://github.com/holman/spark/blob/master/spark\n[wiki]:     https://github.com/holman/spark/wiki/Wicked-Cool-Usage\n[holman]:   https://twitter.com/holman\n"
        },
        {
          "name": "VERSION",
          "type": "blob",
          "size": 0.0048828125,
          "content": "1.0.0"
        },
        {
          "name": "spark",
          "type": "blob",
          "size": 1.990234375,
          "content": "#!/usr/bin/env bash\n#\n# spark\n# https://github.com/holman/spark\n#\n# Generates sparklines for a set of data.\n#\n# Here's a good web-based sparkline generator that was a bit of inspiration\n# for spark:\n#\n#   https://datacollective.org/sparkblocks\n#\n# spark takes a comma-separated or space-separated list of data and then prints\n# a sparkline out of it.\n#\n# Examples:\n#\n#   spark 1 5 22 13 53\n#   # => ▁▁▃▂▇\n#\n#   spark 0 30 55 80 33 150\n#   # => ▁▂▃▅▂▇\n#\n#   spark -h\n#   # => Prints the spark help text.\n\n# Generates sparklines.\n#\n# $1 - The data we'd like to graph.\n_echo()\n{\n  if [ \"X$1\" = \"X-n\" ]; then\n    shift\n    printf \"%s\" \"$*\"\n  else\n    printf \"%s\\n\" \"$*\"\n  fi\n}\n\nspark()\n{\n  local n numbers=\n\n  # find min/max values\n  local min=0xffffffff max=0\n\n  for n in ${@//,/ }\n  do\n    # on Linux (or with bash4) we could use `printf %.0f $n` here to\n    # round the number but that doesn't work on OS X (bash3) nor does\n    # `awk '{printf \"%.0f\",$1}' <<< $n` work, so just cut it off\n    n=${n%.*}\n    (( n < min )) && min=$n\n    (( n > max )) && max=$n\n    numbers=$numbers${numbers:+ }$n\n  done\n\n  # print ticks\n  local ticks=(▁ ▂ ▃ ▄ ▅ ▆ ▇ █)\n\n  # use a high tick if data is constant\n  (( min == max )) && ticks=(▅ ▆)\n\n  local f=$(( (($max-$min)<<8)/(${#ticks[@]}-1) ))\n  (( f < 1 )) && f=1\n\n  for n in $numbers\n  do\n    _echo -n ${ticks[$(( ((($n-$min)<<8)/$f) ))]}\n  done\n  _echo\n}\n\n# If we're being sourced, don't worry about such things\nif [ \"$BASH_SOURCE\" == \"$0\" ]; then\n  # Prints the help text for spark.\n  help()\n  {\n    local spark=$(basename $0)\n    cat <<EOF\n\n    USAGE:\n      $spark [-h|--help] VALUE,...\n\n    EXAMPLES:\n      $spark 1 5 22 13 53\n      ▁▁▃▂█\n      $spark 0,30,55,80,33,150\n      ▁▂▃▄▂█\n      echo 9 13 5 17 1 | $spark\n      ▄▆▂█▁\nEOF\n  }\n\n  # show help for no arguments if stdin is a terminal\n  if { [ -z \"$1\" ] && [ -t 0 ] ; } || [ \"$1\" == '-h' ] || [ \"$1\" == '--help' ]\n  then\n    help\n    exit 0\n  fi\n\n  spark ${@:-`cat`}\nfi\n"
        },
        {
          "name": "spark-test.sh",
          "type": "blob",
          "size": 1.2607421875,
          "content": "#!/usr/bin/env roundup\n\ndescribe \"spark: Generates sparklines for a set of data.\"\n\nspark=\"./spark\"\n\nit_shows_help_with_no_argv() {\n  $spark | grep USAGE\n}\n\nit_graphs_argv_data() {\n  graph=\"$($spark 1,5,22,13,5)\"\n\n  test $graph = '▁▂█▅▂'\n}\n\nit_charts_pipe_data() {\n  data=\"0,30,55,80,33,150\"\n  graph=\"$(echo $data | $spark)\"\n\n  test $graph = '▁▂▃▄▂█'\n}\n\nit_charts_spaced_data() {\n  data=\"0 30 55 80 33 150\"\n  graph=\"$($spark $data)\"\n\n  test $graph = '▁▂▃▄▂█'\n}\n\nit_charts_way_spaced_data() {\n  data=\"0 30               55 80 33     150\"\n  graph=\"$($spark $data)\"\n\n  test $graph = '▁▂▃▄▂█'\n}\n\nit_handles_decimals() {\n  data=\"5.5,20\"\n  graph=\"$($spark $data)\"\n\n  test $graph = '▁█'\n}\n\nit_charts_100_lt_300() {\n  data=\"1,2,3,4,100,5,10,20,50,300\"\n  graph=\"$($spark $data)\"\n\n  test $graph = '▁▁▁▁▃▁▁▁▂█'\n}\n\nit_charts_50_lt_100() {\n  data=\"1,50,100\"\n  graph=\"$($spark $data)\"\n\n  test $graph = '▁▄█'\n}\n\nit_charts_4_lt_8() {\n  data=\"2,4,8\"\n  graph=\"$($spark $data)\"\n\n  test $graph = '▁▃█'\n}\n\nit_charts_no_tier_0() {\n  data=\"1,2,3,4,5\"\n  graph=\"$($spark $data)\"\n\n  test $graph = '▁▂▄▆█'\n}\n\nit_equalizes_at_midtier_on_same_data() {\n  data=\"1,1,1,1\"\n  graph=\"$($spark $data)\"\n\n  test $graph = '▅▅▅▅'\n}\n"
        },
        {
          "name": "test",
          "type": "blob",
          "size": 0.265625,
          "content": "#!/bin/sh\n#\n# Run roundup tests for spark.\n#\n\nroundup=$(which roundup)\n\n[ ! -z $roundup ] || {\n  cat <<MESSAGE 1>&2 ;\nerror: roundup missing\n\nCheck out https://github.com/bmizerany/roundup for instructions on installing roundup.\nMESSAGE\n\n  exit 1;\n}\n\n$roundup ./*-test.sh\n"
        }
      ]
    }
  ]
}