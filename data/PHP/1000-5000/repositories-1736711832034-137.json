{
  "metadata": {
    "timestamp": 1736711832034,
    "page": 137,
    "hasNextPage": true,
    "endCursor": "Y3Vyc29yOjE0MA==",
    "completionStatus": "IN_PROGRESS"
  },
  "repositories": [
    {
      "nameWithOwner": "booksbyus/zguide",
      "stars": 3449,
      "defaultBranch": "master",
      "files": [
        {
          "name": ".bookmarks",
          "type": "blob",
          "size": 13.794921875,
          "content": "Step-Draw-a-Rough-Architecture Step 2: Draw a Rough Architecture\nSerialization-Languages Serialization Languages\nGetting-the-Context-Right Getting the Context Right\nThe-Simple-Reply-Envelope The Simple Reply Envelope\nDesign-Notes Design Notes\nDetecting-Disappearances Detecting Disappearances\nGoals Goals\nThe-CZMQ-High-Level-API The CZMQ High-Level API\nPatterns-for-Success Patterns for Success\nA-Load-Balancing-Message-Broker A Load Balancing Message Broker\nPsychology-of-Software-Architecture Psychology of Software Architecture\npostface Postface\nTransferring-Files Transferring Files\nThe-Social-Engineer The Social Engineer\nRepublishing-Updates-from-Clients Republishing Updates from Clients\nZeroMQ-Framing ZeroMQ Framing\nThe-Secret-Life-of-WiFi The Secret Life of WiFi\nThe-DEALER-to-ROUTER-Combination The DEALER to ROUTER Combination\nChange-Latency Change Latency\nProgramming-with-ZeroMQ Programming with ZeroMQ\nTrue-Peer-Connectivity-Harmony-Pattern True Peer Connectivity (Harmony Pattern)\nWhy-make-FileMQ Why make FileMQ?\nAbstraction-Level Abstraction Level\nChapter-Advanced-Architecture-using-ZeroMQ Chapter 7 - Advanced Architecture using ZeroMQ\nThe-Request-Reply-Mechanisms The Request-Reply Mechanisms\nBinary-Logging-Protocol Binary Logging Protocol\nWarning-Unstable-Paradigms Warning: Unstable Paradigms!\nCost-of-Failure Cost of Failure\nVadim-Shalts-s-Story Vadim Shalts's Story\nThe-Importance-of-Contracts The Importance of Contracts\nThe-Hangman The Hangman\nSymbolic-Links Symbolic Links\nThe-Use-Case The Use Case\nHandling-Interrupt-Signals Handling Interrupt Signals\nBurnout Burnout\nAsk-and-Ye-Shall-Receive Ask and Ye Shall Receive\nPreliminaries Preliminaries\nSerialization-Libraries Serialization Libraries\nSpinning-Off-a-Library-Project Spinning Off a Library Project\nScaling-to-Multiple-Clusters Scaling to Multiple Clusters\nInternal-Architecture Internal Architecture\nContent-Distribution Content Distribution\nGetting-the-Message-Out Getting the Message Out\nArchitecture-of-a-Single-Cluster Architecture of a Single Cluster\nWhat-s-the-Current-Status What's the Current Status?\nLearning-Curve Learning Curve\nArchitecture-of-the-ZeroMQ-Community Architecture of the ZeroMQ Community\nSerializing-Your-Data Serializing Your Data\nUsing-a-Reactor Using a Reactor\nA-Real-Life-Example A Real-Life Example\nI-O-Threads I/O Threads\nBrokerless-Reliability-Freelance-Pattern Brokerless Reliability (Freelance Pattern)\nChapter-Advanced-Request-Reply-Patterns Chapter 3 - Advanced Request-Reply Patterns\nMultipart-Messages Multipart Messages\nbasics Chapter 1 - Basics\nPreface Preface\nWorking-with-Subtrees Working with Subtrees\nWhat-is-Reliability What is \"Reliability\"?\nEphemeral-Values Ephemeral Values\nThe-Canary-Watcher The Canary Watcher\nThe-Provocateur The Provocateur\nHandling-Errors-and-ETERM Handling Errors and ETERM\nHow-ZeroMQ-Lost-Its-Road-Map How ZeroMQ Lost Its Road Map\nThe-Earth-and-Sky The Earth and Sky\nWhy-We-Needed-ZeroMQ Why We Needed ZeroMQ\nRemoving-Friction Removing Friction\nThe-Naming-Ceremony The Naming Ceremony\nSimplicity-Versus-Complexity Simplicity Versus Complexity\nTom-van-Leeuwen-s-Story Tom van Leeuwen's Story\nRecap-of-Request-Reply-Sockets Recap of Request-Reply Sockets\nRepresenting-State-as-Key-Value-Pairs Representing State as Key-Value Pairs\nThe-Historian The Historian\nDivide-and-Conquer Divide and Conquer\nreliable-request-reply Chapter 4 - Reliable Request-Reply Patterns\nThe-Rolling-Stone The Rolling Stone\nA-Self-Healing-P-P-Network-in-Seconds A Self-Healing P2P Network in 30 Seconds\nRequest-Reply-Combinations Request-Reply Combinations\nHeartbeating Heartbeating\nZeroMQ-s-Built-In-Proxy-Function ZeroMQ's Built-In Proxy Function\nThe-Asynchronous-Client-Server-Pattern The Asynchronous Client/Server Pattern\nChapter-A-Framework-for-Distributed-Computing Chapter 8 - A Framework for Distributed Computing\nContracts-and-Protocols Contracts and Protocols\nWhy-Mesh-Isn-t-Here-Yet Why Mesh Isn't Here Yet\nTest-Results Test Results\nThe-Flash-Mob The Flash Mob\nExploring-ROUTER-Sockets Exploring ROUTER Sockets\nPlugging-Sockets-into-the-Topology Plugging Sockets into the Topology\nEconomics-of-Participation Economics of Participation\nmoving-pieces Chapter 8 - A Framework for Distributed Computing\nHow-This-Book-Happened How This Book Happened\nPoint-to-Point-Messaging Point-to-Point Messaging\nROUTER-Broker-and-DEALER-Workers ROUTER Broker and DEALER Workers\nThe-Constant-Gardener The Constant Gardener\nReliable-Pub-Sub-Clone-Pattern Reliable Pub-Sub (Clone Pattern)\nCare-and-Feeding Care and Feeding\nGetting-an-Official-Port-Number Getting an Official Port Number\nStranger-Meet-Stranger Stranger, Meet Stranger\nDevelopment-Process Development Process\nRecovery-and-Late-Joiners Recovery and Late Joiners\nMaking-a-Clean-Exit Making a Clean Exit\nthe-community Chapter 6 - The ZeroMQ Community\nMultithreading-with-ZeroMQ Multithreading with ZeroMQ\nProject-Administration Project Administration\nDetecting-Memory-Leaks Detecting Memory Leaks\nClient-Side-Reliability-Lazy-Pirate-Pattern Client-Side Reliability (Lazy Pirate Pattern)\nLanguage Language\nLast-Value-Caching Last Value Caching\nService-Oriented-Reliable-Queuing-Majordomo-Pattern Service-Oriented Reliable Queuing (Majordomo Pattern)\nBuilding-a-Multithreaded-Stack-and-API Building a Multithreaded Stack and API\nInitial-Design-Cut-the-API Initial Design Cut: the API\nAdding-the-Binary-Star-Pattern-for-Reliability Adding the Binary Star Pattern for Reliability\nHandling-Multiple-Sockets Handling Multiple Sockets\nZeroMQ-in-a-Hundred-Words ZeroMQ in a Hundred Words\nDesigning-for-Innovation Designing for Innovation\nRobust-Reliable-Queuing-Paranoid-Pirate-Pattern Robust Reliable Queuing (Paranoid Pirate Pattern)\nState-Machines State Machines\nBinary-Star-Implementation Binary Star Implementation\nNetwork-Discovery Network Discovery\nDistributed-Logging-and-Monitoring Distributed Logging and Monitoring\nSome-Physics Some Physics\nThe-DEALER-to-DEALER-Combination The DEALER to DEALER Combination\nStep-Decide-on-the-Contracts Step 3: Decide on the Contracts\nTechnical-Requirements Technical Requirements\nThe-ZeroMQ-Process-C The ZeroMQ Process: C4\nThe-REQ-to-REP-Combination The REQ to REP Combination\nPreemptive-Discovery-over-Raw-Sockets Preemptive Discovery over Raw Sockets\nA-Plausible-Minimal-Implementation A Plausible Minimal Implementation\nOn-Up-Front-Testing On Up-Front Testing\nConclusion Conclusion\nThe-Lazy-Perfectionist The Lazy Perfectionist\nPrototyping-the-State-Flow Prototyping the State Flow\nModel-Three-Complex-and-Nasty Model Three: Complex and Nasty\nPreventing-Split-Brain-Syndrome Preventing Split-Brain Syndrome\nAuthentication-Using-SASL Authentication Using SASL\nHigh-Availability-Pair-Binary-Star-Pattern High-Availability Pair (Binary Star Pattern)\nDealing-with-Blocked-Peers Dealing with Blocked Peers\nPub-Sub-Tracing-Espresso-Pattern Pub-Sub Tracing (Espresso Pattern)\nChapter-Advanced-Pub-Sub-Patterns Chapter 5 - Advanced Pub-Sub Patterns\nCooperative-Discovery-Using-UDP-Broadcasts Cooperative Discovery Using UDP Broadcasts\nDesigning-the-API Designing the API\nChapter-The-ZeroMQ-Community Chapter 6 - The ZeroMQ Community\nChapter-Basics Chapter 1 - Basics\nGuarantees-of-Isolation Guarantees of Isolation\nStep-Internalize-the-Semantics Step 1: Internalize the Semantics\nContracts-Are-Hard Contracts Are Hard\nBuilding-and-Trying-FileMQ Building and Trying FileMQ\nThe-Dynamic-Discovery-Problem The Dynamic Discovery Problem\nHigh-Level-Messaging-Patterns High-Level Messaging Patterns\nStep-Write-a-Minimal-End-to-End-Solution Step 4: Write a Minimal End-to-End Solution\nThe-Mindful-General The Mindful General\nPatch-Requirements Patch Requirements\nDesigning-Reliability Designing Reliability\nMultiple-Nodes-on-One-Device Multiple Nodes on One Device\nZeroMQ-is-Not-a-Neutral-Carrier ZeroMQ is Not a Neutral Carrier\nA-Minor-Note-on-Strings A Minor Note on Strings\nOn-Assertions On Assertions\nPros-and-Cons-of-Pub-Sub Pros and Cons of Pub-Sub\nShared-Queue-DEALER-and-ROUTER-sockets Shared Queue (DEALER and ROUTER sockets)\nExample-Zyre-Application Example Zyre Application\nWhat-s-This-Good-For What's This Good For?\nHow-to-Make-Really-Large-Architectures How to Make Really Large Architectures\nCrazy-Beautiful-and-Easy Crazy, Beautiful, and Easy\nAsynchronous-Majordomo-Pattern Asynchronous Majordomo Pattern\nThe-DEALER-to-REP-Combination The DEALER to REP Combination\nFixing-the-World Fixing the World\nEstablishing-the-Details Establishing the Details\nHigh-Water-Marks High-Water Marks\nUp-front-Coordination Up-front Coordination\nSimplicity-Oriented-Design Simplicity Oriented Design\nHow-to-Write-Unprotocols How to Write Unprotocols\nModel-Two-Brutal-Shotgun-Massacre Model Two: Brutal Shotgun Massacre\nThe-Extended-Reply-Envelope The Extended Reply Envelope\nadvanced-pub-sub Chapter 5 - Advanced Pub-Sub Patterns\nStep-Solve-One-Problem-and-Repeat Step 5: Solve One Problem and Repeat\nSignaling-Between-Threads-PAIR-Sockets Signaling Between Threads (PAIR Sockets)\nGetting-the-Examples Getting the Examples\nComplexity-Oriented-Design Complexity-Oriented Design\nShrugging-It-Off Shrugging It Off\nUnicast-Transports Unicast Transports\nChapter-Reliable-Request-Reply-Patterns Chapter 4 - Reliable Request-Reply Patterns\nService-Discovery Service Discovery\nTracing-Activity Tracing Activity\nChapter-Sockets-and-Patterns Chapter 2 - Sockets and Patterns\nConfiguration Configuration\nThe-Open-Door The Open Door\nThe-Mystic The Mystic\nThe-Laughing-Clown The Laughing Clown\nThe-Zen-of-Zero The Zen of Zero\nSocket-Scalability Socket Scalability\nadvanced-architecture Chapter 7 - Advanced Architecture using ZeroMQ\nDisconnected-Reliability-Titanic-Pattern Disconnected Reliability (Titanic Pattern)\nTesting-and-Simulation Testing and Simulation\nWriting-the-Unprotocol Writing the Unprotocol\nThe-Process The Process\nPub-Sub-Message-Envelopes Pub-Sub Message Envelopes\nIdentities-and-Addresses Identities and Addresses\nIdempotent-Services Idempotent Services\nVisibility Visibility\nFederation-Versus-Peering Federation Versus Peering\nLicensing Licensing\nUDP-Beacon-Framing UDP Beacon Framing\nThe-Load-Balancing-Pattern The Load Balancing Pattern\nNode-Coordination Node Coordination\nThe-Clustered-Hashmap-Protocol The Clustered Hashmap Protocol\nCreating-Stable-Releases Creating Stable Releases\nProtocol-Assertions Protocol Assertions\nEvolution-of-Public-Contracts Evolution of Public Contracts\nIncompatible-Changes Incompatible Changes\nPostface Postface\nROUTER-Broker-and-REQ-Workers ROUTER Broker and REQ Workers\nSurprise-and-Expectations Surprise and Expectations\nDesign-for-The-Real-World Design for The Real World\nOne-Way-Heartbeats One-Way Heartbeats\nEat-Me Eat Me\nadvanced-request-reply Chapter 3 - Advanced Request-Reply Patterns\nA-Note-on-the-Naming-Convention A Note on the Naming Convention\nBinary-Star-Reactor Binary Star Reactor\nInitial-Design-Cut-the-Protocol Initial Design Cut: the Protocol\nHigh-Speed-Subscribers-Black-Box-Pattern High-Speed Subscribers (Black Box Pattern)\nSlow-Subscriber-Detection-Suicidal-Snail-Pattern Slow Subscriber Detection (Suicidal Snail Pattern)\nAcknowledgements Acknowledgements\nWorked-Example-Inter-Broker-Routing Worked Example: Inter-Broker Routing\nMore-About-UDP More About UDP\nScalability Scalability\nSuggested-Shim-Macros Suggested Shim Macros\nSending-and-Receiving-Messages Sending and Receiving Messages\nThe-Zyre-Tester The Zyre Tester\nGroup-Messaging Group Messaging\nMichael-Jakl-s-Story Michael Jakl's Story\nLarge-Scale-File-Publishing-FileMQ Large-Scale File Publishing: FileMQ\nDelivery-Notifications Delivery Notifications\nInfinite-Property Infinite Property\nWhy-use-the-GPLv-for-Public-Specifications Why use the GPLv3 for Public Specifications?\nUnprotocols Unprotocols\nError-Handling Error Handling\nUpgrading-from-ZeroMQ-v-to-ZeroMQ-v Upgrading from ZeroMQ v2.2 to ZeroMQ v3.2\nHow-It-Began How It Began\nThe-Benevolent-Tyrant The Benevolent Tyrant\nLicensing-and-Ownership Licensing and Ownership\nCentralized-Versus-Decentralized Centralized Versus Decentralized\nStarting-Assumptions Starting Assumptions\nPrototyping-the-Local-and-Cloud-Flows Prototyping the Local and Cloud Flows\nModel-One-Simple-Retry-and-Failover Model One: Simple Retry and Failover\nWorking-with-Messages Working with Messages\nThe-ROUTER-to-ROUTER-Combination The ROUTER to ROUTER Combination\nBasic-Reliable-Queuing-Simple-Pirate-Pattern Basic Reliable Queuing (Simple Pirate Pattern)\nProtocols-Without-The-Goats Protocols Without The Goats\nGetting-an-Out-of-Band-Snapshot Getting an Out-of-Band Snapshot\nThe-Tale-of-Two-Bridges The Tale of Two Bridges\nRobustness-in-Conflict Robustness in Conflict\nZero-Copy Zero-Copy\nCode-Generation Code Generation\nMessage-Oriented-Pattern-for-Elastic-Design Message-Oriented Pattern for Elastic Design\nTransport-Bridging Transport Bridging\nROUTER-Error-Handling ROUTER Error Handling\nConclusions Conclusions\nTrash-Oriented-Design Trash-Oriented Design\nTest-Use-Case-The-Track-Tool Test Use Case: The Track Tool\nInvalid-Combinations Invalid Combinations\nVersion-Reporting Version Reporting\nMissing-Message-Problem-Solver Missing Message Problem Solver\nTales-from-Out-There Tales from Out There\nCompatible-Changes Compatible Changes\nPing-Pong-Heartbeats Ping-Pong Heartbeats\nThe-Socket-API The Socket API\nMessaging-Patterns Messaging Patterns\nFeatures-of-a-Higher-Level-API Features of a Higher-Level API\nRob-Gagnon-s-Story Rob Gagnon's Story\nHandwritten-Binary-Serialization Handwritten Binary Serialization\nPublic-API Public API\nsockets-and-patterns Chapter 2 - Sockets and Patterns\nThe-Cheap-or-Nasty-Pattern The Cheap or Nasty Pattern\nThe-Pirate-Gang The Pirate Gang\nGit-Branches-Considered-Harmful Git Branches Considered Harmful\nDetailed-Requirements Detailed Requirements\nAudience Audience\nFile-Stability File Stability\nHeartbeating-for-Paranoid-Pirate Heartbeating for Paranoid Pirate\nPutting-it-All-Together Putting it All Together\nIntermediaries-and-Proxies Intermediaries and Proxies\nThe-REQ-to-ROUTER-Combination The REQ to ROUTER Combination\nUsing-ABNF Using ABNF\nA-High-Level-API-for-ZeroMQ A High-Level API for ZeroMQ\nDiscovery Discovery\n"
        },
        {
          "name": ".cache_cs",
          "type": "blob",
          "size": 0.57421875,
          "content": "8df2993edef61a4d7b8f550ed932246455f3651b  all.wd\n32a2d64b8f5b097a903d63aa408c3f19d252a0d9  preface.wd\n373f4a9958b9e5556e06aaa318c5d476f182f9ee  chapter1.wd\n9e621b536d10060f0bc9038464c7cbfedee0d97a  chapter2.wd\n254e2c5dc662a4b688996527d221bc2a671a828a  chapter3.wd\n6ea834549675360f05982924c50f0da4a3a15e4a  chapter4.wd\n95a31e865011a1ba5aa7b4966806466aa4ea6875  chapter5.wd\n8b388ad0f78145a3e9602566db75c5e8313e207f  chapter6.wd\n581bea110d332a4a466d1f97cef66bb46c4231b6  chapter7.wd\n09569551e446727a5c5339c77bd419fd67d40de4  chapter8.wd\n0780774136cc1bd4657b0f29cfc0441d15c36f6f  postface.wd\n"
        },
        {
          "name": ".cache_hx",
          "type": "blob",
          "size": 0.57421875,
          "content": "c5c3b37b6dbed1f8974d788182f886ff939171cf  all.wd\n32a2d64b8f5b097a903d63aa408c3f19d252a0d9  preface.wd\n4fa52f6409d03a99be1c102b359eca5cd33cb637  chapter1.wd\n2170fe9f7b7612744a06362dd4dc50c41c37d799  chapter2.wd\n3beb4c4115d523627500047064232b8995296c1b  chapter3.wd\ned13319dba68365cefb49f91df972b56aac8991c  chapter4.wd\ncd1a1d518d091dd1f7a5bfe9143824178376babf  chapter5.wd\n8b388ad0f78145a3e9602566db75c5e8313e207f  chapter6.wd\n3494525e1ab4b2a874894a18b3335696dd8a6126  chapter7.wd\n02c181b4ddf34815026193d8a25ba03fa8db9cc0  chapter8.wd\n0780774136cc1bd4657b0f29cfc0441d15c36f6f  postface.wd\n"
        },
        {
          "name": ".cache_java",
          "type": "blob",
          "size": 0.57421875,
          "content": "7bdc50eb2a3a4229d00f7f59a7bc60dfefa60055  all.wd\n32a2d64b8f5b097a903d63aa408c3f19d252a0d9  preface.wd\n07fbaa6de9efa3cfef455129daad00b4e56ccdc8  chapter1.wd\n5e321c4ea27c865496c014045275e0b680070d27  chapter2.wd\n0b21e79fe4761a4f934538872f927dc7319b7d1e  chapter3.wd\nac9dd946673db8d54b94f9a0b9592749bd5ad884  chapter4.wd\n491adb6c65f752f7176fa5dadac11a3121e507c1  chapter5.wd\n8b388ad0f78145a3e9602566db75c5e8313e207f  chapter6.wd\n1bec8cb67e6e5433b2bc5540cf659d4673afbdec  chapter7.wd\n2e10bddba20bc2da285888917c0193a6d9d021cb  chapter8.wd\n0780774136cc1bd4657b0f29cfc0441d15c36f6f  postface.wd\n"
        },
        {
          "name": ".cache_lua",
          "type": "blob",
          "size": 0.57421875,
          "content": "60456bf61f72f010982487fc0e2f6da6d8fcbdfd  all.wd\n32a2d64b8f5b097a903d63aa408c3f19d252a0d9  preface.wd\n3bd44b5468020e0f3164295f3867e3aa3dbd9dc4  chapter1.wd\nb1c220aa76a8486bd2d96fbd877d4a2c44c1da0a  chapter2.wd\nbcc21637b1b45ba67f7eb23576caed65ecbe3cf8  chapter3.wd\nc2266dd7cee216920ea88047bbcf04f7090128eb  chapter4.wd\n2cea47a16a36406c73a55a0903e3f5ce1bf88541  chapter5.wd\n8b388ad0f78145a3e9602566db75c5e8313e207f  chapter6.wd\n113a0f622eb8ef0da3e7b894f8f90ce4e3b9cb9f  chapter7.wd\n7acbb6354171c5dbab16d2d625ea547ed5f55e3f  chapter8.wd\n0780774136cc1bd4657b0f29cfc0441d15c36f6f  postface.wd\n"
        },
        {
          "name": ".cache_main",
          "type": "blob",
          "size": 0.0546875,
          "content": "042eab97f54eaf590435111cf23b8067e388d3d0  scoreboard.wd\n"
        },
        {
          "name": ".cache_page",
          "type": "blob",
          "size": 0.57421875,
          "content": "43c0dfa50dd8c2ac4c6bd2b10fbb2924aa0adfb6  all.wd\n32a2d64b8f5b097a903d63aa408c3f19d252a0d9  preface.wd\nb22d126c6e9735d137786599ef1faca0416a6cbd  chapter1.wd\naa069b1decb9199dae5fe6d55d87b2417e47e15b  chapter2.wd\n0fea6e8a7236a009420571ee67d6ce1e6ecf8342  chapter3.wd\n680f3e227ab31065d03f7276beb27451e168e954  chapter4.wd\n14f6c1ab5f5ec885a27dab067da115373706d5b6  chapter5.wd\n0e0608f25b8451764dd025575044c2e393922651  chapter6.wd\n59946daa2eb3a24d3068ba0dcb0d9bc537670130  chapter7.wd\nf96d584d3188bc309f3b4656f6f9cf6de3d25ccf  chapter8.wd\n0780774136cc1bd4657b0f29cfc0441d15c36f6f  postface.wd\n"
        },
        {
          "name": ".cache_php",
          "type": "blob",
          "size": 0.57421875,
          "content": "84556de2857c949e1f80be42c499e6a4482a4c2d  all.wd\n32a2d64b8f5b097a903d63aa408c3f19d252a0d9  preface.wd\n262274bb1a2e45baaebcbfa4b67ee05c7d34df86  chapter1.wd\nc6bf245fe477ab2670ccd54522af738208e170a1  chapter2.wd\n004452391ba2b6cf0a07409b366ba1167f3713df  chapter3.wd\nfd08083d3c0402199282209436a72f305dc554ed  chapter4.wd\na44e910bebf7e662282dc1eb4db90a942cd8bcac  chapter5.wd\n8b388ad0f78145a3e9602566db75c5e8313e207f  chapter6.wd\na8ba90bc1ae459d5fa01edda0ac2cd565918c0ac  chapter7.wd\n0fe9acf0375251d4c90f78ff8d8eca0e0d57a47e  chapter8.wd\n0780774136cc1bd4657b0f29cfc0441d15c36f6f  postface.wd\n"
        },
        {
          "name": ".cache_py",
          "type": "blob",
          "size": 0.57421875,
          "content": "1ed1f82517a1901947eb9e824ff2e9f2e9eb09a3  all.wd\n32a2d64b8f5b097a903d63aa408c3f19d252a0d9  preface.wd\n1618534505d123f758789a61dbe4389a2c1e8182  chapter1.wd\n9890fcbe89278d64c115260848ac4bda7ba29b84  chapter2.wd\n583722a2ed7928761e992ffc9aa280c4631c170d  chapter3.wd\na25d1aca8b13abade23c82faa0415b53921b80dc  chapter4.wd\nb36f4fee329996aff90209205e69bd589d0a4af8  chapter5.wd\n8b388ad0f78145a3e9602566db75c5e8313e207f  chapter6.wd\nbcdc3d60c78c29a9a8b2788be887d9da4ac1ad87  chapter7.wd\n37b5f5c7bc077974ed16f048e2cb22399a15f4bf  chapter8.wd\n0780774136cc1bd4657b0f29cfc0441d15c36f6f  postface.wd\n"
        },
        {
          "name": ".gitignore",
          "type": "blob",
          "size": 0.2109375,
          "content": "wdtemp.txt\ntmp_*\n*.wd\nnode_modules\n*.ipc\n*.pdf\n*.epub\n*.pyc\n*.pyo\n*.o\n.DS_Store\n*~\nebook.xml\n/book\nbook.ps\nbook.xml\nbook.tex\nupload.sh\nchanges.txt\n*.swp\ntestdata*\n\nsite/resources/*\nsite/public/*\n\n.venv # python venv\n"
        },
        {
          "name": ".signatures",
          "type": "blob",
          "size": 82.5322265625,
          "content": "6f2ad075a095a1852d2e70f88e35df1d8019a218 examples/Go/psenvsub.go\nca5cd3acb3c26eb9aa84717721f56dd3bc5058d6 examples/Java/Wuserver.java\n8eac75eec1dd73f7a265cd280a20da14eb548401 examples/Java/Flclient1.java\nb4721bcee53fd72bbca0bbe21643dbbb6a96050a examples/Q/mtserver.q\n0c57d32059f95798b4e79c5843c71ab0633ac697 examples/Erlang/msgqueue.es\na82fe18ff02f8aeaba24a7ac8b71c8541387cb96 examples/Python/pathosub.py\nae475a12b99273599a214d56bf703775ff140768 fragments/C/interrupt.c\n390a19eb1112bc0b41a746fe4f6ceb5d90d0df7e examples/C/tasksink.c\n5e59ab353eadfe29009543865492c710342be0e5 examples/Java/identity.java\na30e34b77ff1ef4e136c061c186999d6e43865c2 examples/F#/psenvpub.fsx\n90e1a424b7a43f3fbf884cf564e3ccebae3cf8bb examples/Java/fileio2.java\na7f0b4cd03e10516cea4d5b13bb6d665cc9ef3ae images/fig15.txt\n56278e593754201464dd1e2aeaac1d90300eb957 examples/Java/interrupt.java\nc26d17db157dc84eae2a9ba1719c6cfc17614170 examples/C/version.c\n2520d1cabf0172062f0c4b6a87145e6b5b399e44 examples/Lua/flserver1.lua\ndd4b5b19cee7347e8e6838feec0fe08b1edf7c52 examples/C++/pathosub.cpp\n9b3939bda8d0528b898341cfa3b48db4ef16abd9 examples/C/bstarsrv2.c\n4e1b9431eeaef286a9be29b33dc6a2cb5efce264 examples/C/clonecli4.c\ndd52ad88f301b0728681f965b6bb76a0780e1655 examples/Scala/rrbroker.scala\nde20414c2e7f53393cc560eaf9f700664f5fd748 examples/Node.js/rrworker.js\n0a61527edffceed7e11ae96d603f256b88209787 examples/Java/psenvsub.java\n965300b9d87fd3a060d859f6d6c8e30f79ef149d examples/Java/Peering3.java\n9aa75f775de177fe937c603fd4038acda1f61301 examples/C++/psenvpub.cpp\n81a3bcee90c566acc4406aeb9198df98ac473f23 examples/Haskell/syncsub.hs\n3cc56e09576313028939f15b8f663d5f55830b95 examples/Java/Dechat.java\n416573a6b7df7bdc8af295c1c55754d9504ed899 examples/Scala/identity.scala\n28b49ef3458db97ff3e067ffbe82e679dcdbc85d examples/CL/msgqueue.lisp\n1c6e59e3f700354e2466e3a83ecda8f0807e9100 examples/C++/mtserver.cpp\nfb9efb83e0e971686021368aa84034d628ab5f33 examples/Java/bstarsrv.java\n9fa2ebb1ef4e874495f7a7544524c3b4fe73ba88 examples/Go/wuclient.go\n52f6c50f023069cc74ab39f8a7f3688ee05bfc51 images/fig63.txt\n5fc46df75d94c1612171ad68fdda9c6a72b37b71 examples/Java/Clonecli2.java\nc2a3f244552b39b5b30e0ce1a36349cec64454fe examples/Java/Mdclient.java\nc602966fe99f3bf1df1cc4438479d755189a4eb9 examples/Go/mdbroker.go\n3db1df68f9f7478f1c9e0f3b2e84c266a19d25f5 images/fig36.txt\n86f6a9e7dd463ad949bf40a167919a0b5043d1c3 examples/Go/mspoller.go\n092084c7b09e9c9804001956213d6804b7be5f1f examples/Perl/psenvsub.pl\nbc711f83b01dce9d7c46be4ff5021fb6370d0597 examples/Elixir/wuserver.exs\n030637f70515212ce10ce3ad52ba57874ee6dfef examples/CL/taskwork.lisp\na9fe928bac87fca23f0549bad0255878427a75b6 examples/C/clonesrv4.c\nf418746002b37dab7ef1819aa707876e831ffc6e examples/Java/Mdclient2.java\n654962eec97c61bf81bd22b7e71f55b81d73bf46 examples/Q/version.q\nbc82562d6bd351cff9348608296c846ac409bf18 examples/Perl/interrupt.pl\nb1a7225f6430caf874fded28122f1081d19e8161 examples/Java/syncsub.java\nf46472f682416d1dd0f0e0d2225f9a9ee5f30344 examples/Delphi/asyncsrv.dpr\n48ccb680a6bf92291611cb11785507a4de7f8197 examples/C#/syncsub.cs\nd8d3f4f5268cedd8ae10ada3c818b8ca94b97bb7 examples/Java/flclient1.java\n78f575cf0dced40352692aad0bf6b044c5b38401 examples/C++/wuclient.cpp\nc5d85a4576d527716afc0e2c22c7091a3cdfe582 examples/Delphi/interrupt.dpr\n00ce57ecfe6a27917774bb1f8794ec378dfd73c9 examples/Python/bstar.py\nead3d1d246a7eb0d17e82e4539b4ba24dd214b65 examples/C/syncsub.c\nd89583bf0ecc6284bea5eb764b875be3bc38836e examples/Haxe/peering1.hx\nf3c38a888d740612c7b8b4f8d1609888ffa97217 examples/Perl/rrworker.pl\n37896104542c4888b89d126479f0812651c03170 examples/Elixir/identity.exs\n5e90b5a8f6bc94947fae43e668b9e8ddafe21183 examples/Ruby/lpserver.rb\nb5679661210b1e253698acd3137b5449f9caf82a examples/Delphi/msgqueue.dpr\n48ac5e3720a67fc044b25eded92b5ba5c99f1b1e examples/Node.js/taskwork2.js\nd08db2f494327c9a65b666e87870036eb427825d examples/Haxe/lbbroker.hx\nbe1675522415917024e893c987eb2bfa3cea6497 examples/CL/psenvpub.lisp\n072d925a8aed611420134f6b017ea75ab429f168 examples/Java/Ticlient.java\n2945d59f821888f68ee58799b98bc83bf90242a3 examples/Java/tasksink2.java\n75416fa51db142d451c603fd795e31ccc37ec2f9 examples/Java/mdcliapi2.java\nf2b8c0a38b1486dbdc8d5e9f78b653436339fcaa examples/Clojure/rrworker.clj\ne2c74f2d25aeebe27d6087db3d43a552abdb7394 examples/C/taskwork2.c\n589fdcb8cfb8bf3dc92385693d14e9d2a705bc06 examples/Clojure/syncsub.clj\ndcf237c025b0dc79d6da7850fbb01bc91380c8c7 examples/Python/flclient3.py\n0e48c8600556573a5cd00c7446b2556a3c9eeb9d examples/Scala/rtreq.scala\nd2e45aa9033781b88afe3c9fe2e5f9c5de74da8d examples/Ruby/lpclient.rb\n62b540a77f37b5e185713a05d99b742f936ab003 examples/Ruby/interrupt.rb\nac017506bf3fb0bc69b342a1c08b7af18922087c examples/Python/hwclient.py\n9dab739f561e816c12002bfd6a3bfde46e1df976 examples/Scala/syncpub.scala\ndd154b1823b1d0c1973878e75eb555a1b39b22a1 examples/Erlang/wuclient.es\ne9b3b9ee9af8678996034bb90960ee813c9ca223 examples/Ruby/peering2.rb\n8b65426c42bbd8524b4ea69bdf20302a3335a2b3 examples/Java/clonecli3.java\n692a045a05e2ad3682e91893ad38b248793115b4 examples/Java/Asyncsrv.java\n62f0018be9dff9f0fe31a5c7709a7c195294c451 examples/CL/wuclient.lisp\n2c48e7a49e24e61be74d90e60c50c0ee48d9a46e examples/Python/psenvsub.py\ne19c69119e03f4df9c58a81b7ab1ee23f46251e6 examples/Java/Tasksink2.java\n04041d3560ace95b8f235d9d9d14ebc081b53395 examples/Java/Tripping.java\n6d4ecf1f4120583bd9439857a04d4ca097c86697 examples/Java/mdcliapi.java\na0442c714bf2989dfb7ad40c6240f109a6c78351 examples/Java/flclient3.java\n07107376f82162ea1e2254a132edaf842519d72c examples/Python/clonecli2.py\na4bbb1f64cc196c0d28bb8de02adb6e98d5b9e46 images/fig8.txt\nceebcdba5aed54e7db291505ac5f1399a9c23d94 examples/Tcl/flclient2.tcl\nef8365a0d51f0ee54f7bf58ddd400dc21ac25ca9 examples/Java/peering2.java\n5b1deb0c265639e66c0460b33cfdde651529bdda examples/Scala/asyncsrv.scala\nacd021c800e8567f2269b530da7be2b254505cca examples/Racket/peering1.rkt\n42b9e6234bb6905654685c2f9d399daa5d502ba2 examples/C/ticlient.c\nb1685118df3fa4d3b601ac88937eaad94a0d069b examples/Delphi/tasksink2.dpr\n4a12410f03667af7cba83c24707f50ef331ecaf7 examples/PHP/flclient1.php\nf5d703809e7a577231e35f969b3354042a035537 examples/Haxe/rtdealer.hx\nf38a17f3d6d7d26a9c62ef5866549841e1d8f90d examples/Scala/wuproxy.scala\ne88a19370d726c2a8f7c0c41e5bebda41df2debb examples/Lua/lbbroker.lua\n4da36746c6cf7aae4aaa11ae7dc40e8be45c8fbc examples/PHP/mdworker.php\nc30fac20cf35bc9d585597d0a7ecc7ef05793c46 examples/PHP/wuserver.php\ne63eff17ab9bb5345c3261b3c3b5cbdc4ab4af69 examples/Tcl/lbbroker.tcl\nc4a39f8d24f178007c1b865f97ebbad123de9e94 examples/Python/rtdealer.py\nd2f5d618cc9b0faddeef3a228e1118dfe2dc0df0 examples/C#/lpclient.cs\n4220bd4f440a1eb7762db8dce5ab26fe51bb33be examples/Python/udpping1.py\n7d4c9722fd1802478dc1e56645c0f74bd19cc693 images/fig3.txt\n2f659f7c4734c9bb3d2f3f9798f541608259d4e5 examples/C#/asyncsrv.cs\n4f238a0bef95f632b2cc6db76c218f35082ba66b examples/Haskell/lpclient.hs\n08bb4375e2325af8605470dc29410aadffb232fa examples/F#/identity.fsx\n69ebd1d969000595a151d24106653eb474db7097 examples/Objective-C/hwserver.m\n0fe1535a3d83ac91e2032162a5c0bab396659392 fragments/C/gsl-client-fsm.c\n04ec3cbdc742b244508905d2230d7024beefadc8 examples/C++/syncsub.cpp\n5ead8e955ffd3aef093962fedf4728d31ba9b8c3 examples/Lua/mdworker.lua\ne81bfbb70ca6c5b63e990ab5cac5b89d17282509 examples/Python/clone.py\n5921a1d177e65c8b9189da1732df5ebb46750eb2 fragments/C/send-deliver.c\n181c3ed344dcc4b42262a6eaab52adc119254384 examples/Haxe/ppworker.hx\n49915810325d208d29baafbf68c7b1ea0a9b075e examples/PHP/wuproxy.php\n1ea8c44d0520c36a732a59d8bb30e09a59f20e62 examples/Java/udpping2.java\n89084b3f9396ed35e9f2ed97fd74177fdba99ada examples/C++/mtrelay.cpp\n95c94536721e46967930374828620a8f950e2af6 examples/Tcl/peering3.tcl\n8ebd711770ccf4764f57d1e530100dfde3c2c084 examples/Ruby/mdbroker.rb\ne13bd7a009d1317ba51281f3f0bb2e70431be099 examples/C/rrclient.c\na3d31e1155e1e94a2f94f4511f8b159376120390 examples/PHP/psenvsub.php\n5984cc28c759a3854939957279d32a4f7c68355a examples/Java/clonesrv6.java\nc59c670c9508490fa6fea0d8557f1b089f569d35 examples/Python/ppworker.py\nb723f0e4e0f368a68e1482cae82e4d83470ab2bc examples/C++/wuserver.cpp\n10d4e1c58f3ede843eec6b5985674e77deae61ee examples/Python/clonecli6.py\nb2302979d8ad55bb74cd4c53a20ec0f463289b75 examples/Java/Clonesrv4.java\ne7f5126be2694eed700205e24166d59ad9fd02ac examples/Perl/hwclient.pl\n656ec1dc776ba91333314b5aed7b3a2fa4a53170 examples/Go/ppworker.go\n7695e7a19444434ac0e17c780133cb69ceaadcbc examples/Python/interface.py\n4f646deb9e582ca39ec51ff3a209b76d0e57563b examples/Node.js/mspoller.js\ncd189e6187770398345581eb07420f74adf97416 images/fig12.txt\nab2b79c546e78b2a39a043db0d55e273d9f6d5e2 examples/Java/clonesrv5.java\nb63c7ba7f580a975a0c666256c09491f409917d8 examples/PHP/titanic.php\n1a27f51fdb5d3923cebf10798bc053a9bbaca5e3 examples/Clojure/identity.clj\n98139b18cf6574d32c78fa52bca7b3d605ea19e8 examples/Java/Fileio1.java\n864068ab4392325bc8f8e17ce5149e49a5c232b9 examples/C/clonecli2.c\nf52d42cfc896b7e421bb30a24965bddae5636eac examples/Delphi/peering2.dpr\n32a913037a05f02edcd2fca79966976c9096deb0 examples/Go/tripping.go\n0154c43e11ead89cc8626061dabb13cc83a8d758 examples/Ruby/titanic.rb\n54b3b21e16eb35779ef72e548b852ff2dea30ccf examples/Python/flserver3.py\n69ee8ec8ac6b80900eec9db9a733fbc91ec04755 examples/Tcl/psenvsub.tcl\ncf0ae0c61431641b75f967fa773614ff66cc4b8b examples/CL/rrbroker.lisp\n7504c8a9d91e9d935541f135701161bff5c0cec3 examples/Ruby/taskvent.rb\n75822daab29031d5af8cad20491ca60315b1b201 examples/C#/lbbroker.cs\nf55d3deb95c86e88817ce97ad98dc09ab4fbf8b7 examples/Go/mtserver.go\n937d691438f722a7b74763c3b5a60bc3f1aff18c examples/Haxe/spworker.hx\n3bd1d7c7b39d4710f5b450cd78fa2460ad116e36 examples/C++/lpclient.cpp\nd6d70ca5c3eb2c4f9d8522b601f7bf55c6caa209 examples/F#/peering1.fsx\na9864c27c88961d22c1de2802975fa7bec95c78a examples/Elixir/version.exs\ndf52136a676be5ef962e24b266f1988eaa0d6df7 examples/Python/mspoller.py\nd01070edf3b90d3a4476d7a4001ab13be72e3144 images/fig30.txt\na7e00a7c16d60da7e8b85e22a5096bc407689dd3 examples/Haxe/lpserver.hx\nd8151daee7a7511e25f09ba2e2b24dc4b463e91d examples/Ruby/wuclient.rb\nad40093a4276cdcb238dad6fd6b3d3444586163a examples/Haxe/peering3.hx\n6f6101425256e535b1408cee97da6095b5de1b9d examples/C/clonesrv2.c\nf520237500b7e1a64ed29371f254011cc201e600 images/fig11.txt\n90877649e4669b98fc04f34af3428f29b1c39882 images/fig37.txt\nbd0fd793b556edda513c3aa952952e26defe3bbd examples/Haskell/psenvsub.hs\n0f86274ad9050f66a8146a7d2f69d832a569af50 examples/Java/clonesrv1.java\nf56e5aa14083821e04add53e78c30b05b83727f6 examples/Tcl/mdcliapi2.tcl\nb02005487696f2e75f5fe6ebc2a9d6f34d425425 examples/Erlang/hwclient.es\nb460b2169ce490fa5221aa768775cd3ecaa30b95 examples/Java/mspoller.java\n99189c875a19222e0e33791e1f65bf28d831ddc4 examples/Clojure/lpserver.clj\nd72181e0749885e136b405f31e65820a036aa3fd examples/Java/mdworker.java\nbe36eeeab63ecc6a3ac894f7ce853c8dd61cd815 examples/Scala/psenvpub.scala\n18002ff3f8038b4af846d8ca7d257d979366a821 examples/C/kvsimple.c\n38b68c720cec633389e0d5a5b3f520936fadf397 fragments/C/bstar.c\n7e06a158261a8b6fa946acb419e97f432b41b18e examples/Java/flserver2.java\n2d42224f2936b92ee2a0e3223f478992f77b8067 examples/Java/Wuproxy.java\n97172663ee4af7c63ce0e7e662874125c4e99b62 examples/CL/wuproxy.lisp\n359305593ebd9905f9768c724dffe060ce1e7dfe images/fig43.txt\ncf771c56bcc2cfb37210b06c0c216b1014f04a48 examples/CL/tasksink.lisp\nd056c4329053d697d79138ac2a39036a6998b12e examples/Java/bstar.java\n83527aac9fc627e4ba525d7660f30436ad9396f8 examples/Delphi/syncsub.dpr\n8d65609f4c5a245f18abdf39ea5f17378ebe7949 examples/Python/clonecli1.py\n744dc1ce8da1bf89458a458845cc84c811c48561 examples/Delphi/rrworker.dpr\n77c1cf2ae283341f8d5e4e0de294c7227a3dbf2d examples/Clojure/mspoller.clj\nd84e8b658ad2ef53c785cb41e78fa36395a1eba7 examples/Haskell/ppqueue.hs\n64a36c0c79268ac9c4ed8585721add3177896c73 examples/Delphi/spworker.dpr\nae49804afca1123975717706669b1ea7c37a2494 examples/Haxe/mdclient2.hx\ne9b63dda4251764f1802b5eabe771fa2f7f5f482 fragments/C/lbreader.c\nd44819f8712638cc1ecf1b0136e6ef4d0b48c8f8 examples/Node.js/taskvent.js\nbf3233ddb2e9bfc83683d17c3ea21fddb8d9320f examples/Perl/mtserver.pl\ne401bbc295490d46d4bc2faf43e18d83ecc347c8 examples/Tcl/tripping.tcl\n59530e89de1f8081d3a99467fd550f5004f60158 examples/C++/spworker.cpp\n699d7abe14efacc40072d93e22a7aa08f25001d6 examples/Tcl/taskwork.tcl\nc02a4d556e87de4294e6f40522b09a61b8642686 examples/C#/peering2.cs\n2c281d5da3a127ea46d88f14e07e1a070956dae2 examples/PHP/mdclient2.php\n2d351ffa3caaeae0a4ab6636768c50c6ed631f3c examples/Elixir/tasksink2.exs\n62bd98f4adb84e2c2cd8a95da67e6a5658457126 examples/Java/ppqueue.java\n5e3753cd2921a6e580d17ec6d54450bb91924106 examples/PHP/peering3.php\n2da56fff02ab6a02d1529d3975fa80d15216972f examples/Scala/lpserver.scala\nc648fb7a5aa4f32b2e2f6fb756b48951500f8ee7 examples/C/syncpub.c\na314686a31de063064d3b4d69f7e3f47dd9e8511 examples/Delphi/hwclient.dpr\ne5773a6d6a475dda095d4ab0fbb44bfd379be7ab examples/C/fileio1.c\n7a1c3db3b0401371e0bf4188878813d29c949b2f examples/Haxe/interrupt.hx\nf434d7d404be5dd39ac87e07b22bd0e5e9b2aac2 examples/F#/taskwork.fsx\nee774e13cae3a8b453436491047368021229c058 examples/Felix/tasksink.flx\n34780580f1105cfa0bc3be1e58d544ac71fc3341 examples/C/mdcliapi2.c\n8769a46603fb2b8be9e02742b1afe0e4d2c957cd examples/C#/spqueue.cs\n3c580b484052b00d38842b7b90eee845eab8b6b2 examples/Elixir/asyncsrv.exs\n5dece82f7143ea2d38141898af5a5a24c48878c9 examples/Python/suisnail.py\n22218b0f7630055f9456eaf7c0b6628202aadbf5 examples/C++/hwclient.cpp\neaed4ec0fb89d551bbd13bbd0f72a2997dd63308 examples/C/suisnail.c\n9603292c9309cf6c1eac503a6aee87dd14eb5eae examples/Java/Flclient3.java\n13b93afc9fdce597b792f1f7471fa7fc7c56c418 examples/Tcl/mdwrkapi.tcl\n71cb7e61963bc3eddaa7c670156cf2a90e9bccef examples/C#/lvcache.cs\n7582277f9d6d059630b82330d789b716cf5390e9 examples/PHP/tasksink.php\n22284bee68b3f07153d883f1a71e3c477d5eea9d examples/Erlang/rrclient.es\n67de9145c8bcdae5b272e4aa0fa8d72b798b62aa images/fig16.txt\n1ea49b8aced92abac19a04cd95d8ea790993b18d examples/Python/msgqueue.py\nec100b5ec89b188d0f280b5bf6d072238c40eb0c examples/Java/Clonesrv6.java\n23775e4b3cdccade0bd5b6829cad0b9b541b4353 examples/Elixir/psenvsub.exs\n68f4d275ac4c6dd2eb5cc1ce98cf0dd114a74ec3 examples/Q/identity.q\n661566ab4b32d2e51d0e9a8c297fce5fb6590d39 examples/C/ppqueue.c\ne0bcf4ee878c574d35eea19bc7f140fa0cb7ecae examples/Ruby/identity.rb\n4b31ce38ae50c343af437aef319e959f3dcf73b7 examples/Lua/mdclient2.lua\ne1ba004366f0920d8e20ac9e419cabb9c38607df examples/Delphi/taskvent.dpr\nfa700ff24cce3ee108d52353010305530955d62a examples/Clojure/syncpub.clj\naa08eecc0c17fc62ede2b94fa68634b180fa191f examples/Python/flserver1.py\n9371cb5b48bdef635b8b678b3d9dad68eb7aedb6 images/fig35.txt\n457e2cfcf319c5ac541743141fc6c293885d668a examples/C#/flclient2.cs\n1de227372609fe7a702519a0c6ab2950a6e1ffcf examples/Lua/spqueue.lua\n95fe11fc7b08593e3b239420b684ca17ef515494 examples/Java/mdclient2.java\n7f09f8028cf4b5a73865d34628868e503ca1622c examples/Go/hwserver.go\n93067a630fc4940a82466c789a105be765359c36 fragments/C/nomserver.c\n3a1ca94dc9f92fb9920f8ebfea5a25d50cc0d694 examples/Go/mdworker.go\nb42c1d6d1c4ffafeddf3195ebd8d32454a31d131 examples/PHP/flclient2.php\n2daec3f253492bdb7a46577e9cf0ff59be263902 examples/PHP/identity.php\n84272fcf9c344b8c217f1195a45081fdbcc41063 examples/C#/rtdealer.cs\n3fdf68862bf76082d6222d4e8b3f14a2f969b709 examples/Haxe/mdcliapi.hx\nbeee50db438e369d853001862811be60915843e1 examples/Java/Clonesrv5.java\nbda7500f94705fb75e5b3bd919f96322396a53b7 examples/Python/lbbroker.py\n06c48b0da266de82c4649bf008e65076641da888 examples/C++/mdclient.cpp\n5679c7231ddd229b3d7be26cfeecd0ff85eca182 examples/Go/mdclient.go\n81db8dedb39e8bc6dff203e2ce168100ea9455cc examples/C/mmiecho.c\n0bed98b2771029b665a634b7c44c4257c4c29a48 images/fig31.txt\n433b0a90987dbf4f2ca560f1afbc98855899355e images/fig17.txt\n4cf23003f992710f47da7679c101ff2e923cf89c images/fig10.txt\n6eb889be88ae17105813a3d50f360745e1c2e9bf examples/Java/Lpserver.java\nb3c1a31e20c95762b0544ef2ef1196918b9124a3 examples/Perl/wuclient.pl\na99fc828954bca4c08e077a9147ca1a99b3a29d0 examples/F#/peering3.fsx\n7b5dac82a4ac491a5bd39b7da26b5e1940b6adee images/fig32.txt\n37bc92528a15cdbeb8302bc27d29bbed9202fbfe examples/PHP/suisnail.php\n6cb2a6cbbae18c5edeb323ea367e19a7a09866ba examples/Ruby/mdwrkapi.rb\na499a5a3b552c82477e5ea8d703b2648db9c4e4b examples/Perl/identity.pl\nbcbf3df1c3a7b6177e2fb9c4b23fbef2c04fe453 examples/Tcl/tasksink2.tcl\n5bf1e12366fccd3b09c6f670bf7586b5ad9b6607 examples/Go/taskwork2.go\nfe366b408e9a1da73e5e7db62480957a1fa6441f examples/Java/lvcache.java\n125886522dfca69e232101255846b5d5290f5e60 examples/Python/lpclient.py\n00a7b8d6c651cf7636eae2c0994c560e5e814bcd examples/Ruby/taskwork2.rb\nbd02cf534bcc5adecdd9f767c359adf30319a551 examples/Python/msreader.py\n3f31a9f39e78f7297ee9489675e8a46f4fb33819 examples/Elixir/mspoller.exs\nd5249a7b3730505d6dfb11ea9eb2836410eccebe examples/Objective-C/taskvent.m\nfe1c3e8b1e5c31e8884c8d5d7b670ef237d69841 examples/C#/msreader.cs\n476c98660e7b449433af9b5aba00feafb48a89e8 examples/Elixir/interrupt.exs\nf9e357527d4523f3372e8225fb582c4df0a1f859 fragments/C/zyre-sender.c\n24dc35e9d56cb8307bf6a13349296883a4b20e24 examples/CL/syncpub.lisp\na32ab8cfc2b4d0dc740706f77a1d5f4da34ddb12 examples/Lua/msgqueue.lua\nd2f61a3bcb2d8a75479212719c0e6fea11943466 examples/Elixir/msreader.exs\n95a4d3b51c07d0a5e7c180021022fe61d2f0b464 examples/C/psenvpub.c\n5fecf9a27a5152a346eab9fba55050d0cf5700f8 examples/Scala/taskwork.scala\n026df16d4e0a52c63cb4e1c4392df6f359775b4c examples/Scala/taskwork2.scala\nf4cf80a2bf64c54a32f6b4a963c283673e592120 examples/Perl/lpserver.pl\n295e1f12ed1c66b7772b05f0af9b1cf85002e7fa fragments/C/heartbeats.c\n8ed5e8f28ea8a6753e808ec10eb66cd1cf91cf9e examples/CL/taskvent.lisp\nab4b616635d13e9a0e617f345f163215eecfb95d examples/Ruby/msreader.rb\n5dce19be254edb8a13e9a2365649c57a84d53887 examples/Java/Taskvent.java\nb6c81bf75ecdf3f67ba5755ea20400d0418bebe4 examples/Tcl/flcliapi.tcl\nf29224468cd3a41a6c49e15473255a03ccc714a1 examples/Tcl/spqueue.tcl\n4628eae5d9be2536e08dce7c38ad47f290e5cee8 examples/PHP/mdbroker.php\nabc5b940ec7fb8173966d59adf005e2b14119424 examples/Delphi/tasksink.dpr\n73d4018726fed0765ce6483e972449e3de81357f examples/C#/interrupt.cs\n44a7ad928e0c8e5da0e3b2b0fbde043ee88a55b9 examples/Ruby/msgqueue.rb\n04af1c7b629c704c3567b341d6fadcade5b4623e examples/PHP/lbbroker.php\na7f61dfff848578ea04d053380e24c979ead378a images/fig23.txt\nf9d3db71208dc03564589c1e010886f33577b64f examples/PHP/tripping.php\n654330c013533fe0edacc4e5819af56280de6d30 examples/C++/mdbroker.cpp\na01840913da9ea7a27914edac9c6502f6e38f7ce examples/Python/pathopub.py\n477ef6e58f6391233ebcc09b5d7f63e2d71baf24 examples/Ruby/peering1.rb\n57c8d8d059e820e05d45c4bc9751e6f493b810f3 examples/C++/taskvent.cpp\nb17b94dba2f9af3f4382a9b1c4b282fa9dc0b624 examples/C/clonesrv5.c\nc11b757f1cdbadce8b1d0237df588ee0759293b5 examples/Java/hwclient.java\n7bfb8809cd3f12d07d8ae8bac7b20669ebae696a examples/Haxe/mdclient.hx\n4b0ef7fccf47c3c6603522f231c2c3d04dfbb6f8 examples/Haxe/rtreq.hx\n669224eb4e34e7ca77851db9c421dd40239896fb examples/Python/spqueue.py\ncf6fc64851754d7eab3a990f5f11d1c3533e7ece examples/PHP/tasksink2.php\n3f37a4ee524ff08b2bc609cd748d4336dc29e3e2 examples/Tcl/clonesrv3.tcl\n34518306d05d90990bb64b2cb1f0a7ef80e8b6dc examples/Python/taskwork2.py\n594489762e5f929ecd4428e5de205c8b2131cc40 examples/Haxe/bstarsrv2.hx\n86de846f01c7257073d69d26630ae8a8deaa30cc examples/Haxe/taskvent.hx\nd1f8bc2846855fc0898894ecf33fbcf738d23d9b examples/Java/rrbroker.java\n194a4976288688772541b112b8748d68b0d4c42d examples/Erlang/mtrelay.es\nd6092fdc83d0f5d448933827c7dba419c44e845f examples/Node.js/wuproxy.js\nef4560ab16e0cd8a548387da9cf206e803b6ea13 images/fig1.txt\na0325006d0a5013b9771ff85f2895d0d051fcab6 examples/Scala/hwclient.scala\ne71942b68df43182dcc45fbe2b86580418f6d5b8 examples/Node.js/rrclient.js\nc8955dc80afb117f06ac51be6e0f008ac1847413 examples/Java/Clonesrv1.java\n42e5fc373abdc64b2f650c826af354ccab1b9702 examples/Perl/rtdealer.pl\n1fdc3165143882c9c8db0537af0e097a5b7f52ea examples/Delphi/rrclient.dpr\n1e9fb680d88712a80fb7e4abe5176b7a8889ad45 examples/PHP/hwserver.php\nd11eeafddd91aa9d8001b18baf0c9d7445cf1305 examples/CL/rtreq.lisp\n9502a4b7f019daa5c568ac4e321024549a60e0fb examples/Perl/syncpub.pl\n08ff035f92bf543f376d754760a2c70c33d67395 examples/Clojure/psenvsub.clj\n19533a103b5c9954888c904a35a32a68940895a6 examples/Node.js/rtdealer.js\need0719e9abdd3903c9d60f7e4f283d1babec888 examples/CL/mtrelay.lisp\nd5fbea85f42e96cd6ce39282e7b0cecf68db1f5a examples/Lua/lbbroker2.lua\n400c2403423823314f9e54b3b91653424b4cd17f examples/Elixir/wuclient.exs\nba9217ee9d727f4cd34649c6dd6358db6688c607 images/fig55.txt\n4b7c444789cb4d87d9f5e7fe095c447ae6be27e4 examples/Scala/peering2.scala\n775da39ca34fd7747b9996ca5a3814fc7b20cc4e fragments/C/filemq-outbox.c\nbd5af62b96626a9b4490740c13b2baa3f0095819 examples/Python/taskwork.py\n6ef57b5faf642c15823ba56e2eb3d792fa9cac1f examples/Delphi/psenvsub.dpr\n210f333dbfed61b4b623b8194c6e79cc4ae726b7 examples/Java/Spqueue.java\nf97927e37c7701cf6358b1830265cd1579ff586f examples/Perl/wuproxy.pl\n00904b45d52c2ebfa3c4ccbdb050e59a0d3c8b75 examples/PHP/version.php\n7cb56e69471f4f9ac238b980f7650ca2bffff0c5 examples/Python/lpserver.py\n799ec47ae262903d145090ec5d710eeb8072b016 examples/Clojure/version.clj\n7a3affdf030ad06bbf3e6f62c3060a95bc31cfe0 examples/Felix/wuserver.flx\n103a6a5f0667e21caafcdd7e54b1fa81ae28ab55 examples/Go/spqueue.go\n517fbf4531bbc0f0a8e4cfbae7a66143087c6d82 examples/F#/rtdealer.fsx\n80b404ce66630dddcbd8b7bdb1fc3443bcfe8b72 examples/Java/Espresso.java\n8636d39599e9e1c9c03e29b72e874314115d1a48 examples/Lua/ppworker.lua\ne910e71c36afc37b67c42b05a33f47409e86a053 examples/Ruby/taskwork.rb\ne08efd08698a331180a3c529a9c5fe33a2fbf414 examples/Haskell/spworker.hs\n37fec12dbdcedf2da599e88d3aee12ca54a28d40 examples/C++/rrclient.cpp\n8b6a70d897e062a77f9b64db14b1b6d7a10d56a9 examples/Java/wuproxy.java\n9d92b84a575b76ee5fdac5a8aead948ff30642ef examples/Clojure/taskwork2.clj\n9fe6b368ed6176ec6b813a001275162bac222ec3 examples/Delphi/rtdealer.dpr\n3f89d54388f5d1f6f8049180f6af7df76f7405f6 examples/Java/Rrbroker.java\n944b1f6aec4e513e135d2ea4ef4e4aded05f08f3 examples/Go/wuserver.go\n34083411e5fe36ea54dc817ed3f6d211a4976102 examples/Clojure/wuproxy.clj\nf9b0162f2b35fac0e376713f2e3a8022632b62fd examples/Tcl/bstarsrv2.tcl\n60b9e752dd07f084d3c46397e529e9a7d72670f6 examples/Felix/hwserver.flx\nd40a37ecd7d04465330e46517ab4791930236c11 examples/Go/mdcliapi.go\n9e8c49a1800d479043106d162e5b18aba213dd78 examples/PHP/syncpub.php\n71bc80bde20f46269857081ab2d1358eac8fec9c examples/Erlang/wuproxy.es\n587ddc20486b8a8bbecbf9f827990413a0202276 examples/Scala/psenvsub.scala\ne983584ce60b8ae1422b44c2aa15c5006e30e396 examples/C++/tasksink.cpp\n2bf7d738f33eb7fbb1e555513dc85860dc7c17a2 examples/Haskell/rrbroker.hs\n13a196b358782d3b14cf3f1d91d1e8a9b54b8b19 examples/Erlang/rrbroker.es\n9cfea546a8163469dbce50342655c83b22280656 examples/Python/dechat.py\nab03e4daf137c1777844839149ba1b8bb1940aaa examples/F#/msreader.fsx\n5e0bb0b8da5f01b361f968afd6c95ba4661f458f examples/C/lpclient.c\n841a8838ba92dce163407b65f8c9a1f31af98b6e examples/PHP/msgqueue.php\n3a4ab391911a42a1b77aa5e2f4612c1689dde91c examples/Lua/hwclient.lua\n7adda76fecc085c27825914ff7eae4d6f4a1e26b examples/C++/tasksink2.cpp\n00a332b2a5cb286055f721b5ebe275dd8c0b31f4 examples/Haskell/wuserver.hs\n4219a689f5822159574d07ac23af97688ec7424b examples/Objective-C/taskwork.m\ne6b2e32fbb696e90a3ab2fab1207abdce434cfef examples/Ruby/mdclient2.rb\n52cc881361f3b10cffe8e1e865692b0a2c2648af examples/Ruby/bstarcli.rb\n8313229e329be84714221313618bf3f5978ad0a7 examples/C/hwclient.c\ncb844752c01c134fafc1e3ac31b1597ee203c786 examples/Elixir/mtserver.exs\n89b222a39351ecf2da7cb09d011c37f6e57069fd examples/Delphi/hwserver.dpr\nc3f7d84614f2a43e034a083353675ed48edf7813 images/fig69.txt\ndf6068b3945cd078d63d7543ec9d9786e10c5c3f examples/Delphi/lbbroker2.dpr\nb1738d9abc5e9575c4e747cbd6d2e6e7a8c5999d examples/C/rtdealer.c\n206154a961e75476262ea0e692a02a117d1bcbcd listings/Python/listing_2.py\na2ab4b661f1da77d469a2bf1c74f39b9d43a94c1 fragments/C/clone-methods.c\na126dbcb2fe0b75726170ae4fc1f2e7891740e11 examples/Tcl/flserver1.tcl\n84825a7e73e138f2e73fd7bda343c03b2083a140 examples/C/spworker.c\nf0483625a32ff6ece37d3550f317a9929f2d0f59 examples/Tcl/syncsub.tcl\n528f1728e6585d3520c1c224239e2a6ba197949e examples/Python/taskvent.py\n85927880815359f4236fa1dd0a3020ef00b79e87 examples/Java/Syncsub.java\n90e1a424b7a43f3fbf884cf564e3ccebae3cf8bb examples/Java/Fileio2.java\nb3a41cfa1a1b009bc9e6d9f2b22f2c2288e45042 examples/C/taskvent.c\nf4db958750cbf06e97acc4b565c46678208b671a examples/Java/mtrelay.java\n6965e1895e1ad0514a9914ad275f6aadf87bba24 examples/Java/lbbroker.java\nd87ebf2495519e9e51536c8af6d7009f4bc4af7f examples/Java/clonecli4.java\nc589caafe8d257fc4958d8a85fd646c90fd0814d examples/Haxe/asyncsrv.hx\nb05c73c655f0eda82bd3b1c598d31b54f92f6270 examples/C#/suisnail.cs\n036055dfc94340022db1463b0a089665a609ea0b examples/Python/bstarcli.py\n79fe8886e6a175879eb7eb4fa019d038231d106f examples/Java/wuclient.java\n15b0e7caa3237f01c37d0f3eacd7fe714e147237 examples/C++/udpping1.cpp\n7b02ed1c93fd786a89a471708c7ef4802c79891b examples/PHP/asyncsrv.php\naeacc2169932a79b2878a7632bdc74f56feb2dd4 examples/Tcl/rtreq.tcl\nd9ed5d2f514fb389a8915499f4840a1f5ba9034c examples/CL/identity.lisp\nb5c13fef347f9166b29f6f833d2dc786720761f3 images/fig44.txt\n07659836afded85c063c602002af8b4fda65637a examples/Java/udpping3.java\nb3e55b02995eed2dfae430fdc0d54fe9ce3d9820 examples/PHP/flserver1.php\nad548452afddc01daee4bdb98975c4a59c9f707d examples/Clojure/mtserver.clj\na36512389d3c14c2cf9271dc947c340e968b911e examples/Ruby/pathosub.rb\ndb2ac0d4710d8efe65110a2ff66b0ed7e7ba0590 examples/Haxe/mmiecho.hx\n510b790e9b8f71a73e83af2ffd6810c71731941c examples/Delphi/mspoller.dpr\ne33689c849c20b2b3f560f3b5b542211f2c51cbb examples/Java/Fileio3.java\nd1be79009b1e8286d12464bd49475a486cdeb298 examples/Java/Mdcliapi2.java\n7adeac0c791e19168f44c751cba6c468533b1f30 examples/Lua/mdwrkapi.lua\nf81acc3dd6a3a9e426bb38aa9972682fc8cc0fc2 examples/Delphi/lbbroker.dpr\na9b336c3ebdc9631440a50f5cd01782cd112c904 examples/Python/wuclient.py\n7aa71544758a30593ab6713b15df01c77c5fc18c examples/C/clonecli1.c\n50fcbfe98df4d0871af7d661b81ff27e2e6a3185 images/fig68.txt\nda4f91e4b7fde4f2de478da6e0357358175412b4 examples/Erlang/psenvpub.es\nd638d2c3acf8a319bae767b1e7ee2b92ad310f00 examples/Perl/version.pl\n189a00fa6ec82be236501914ec7cdf59f5ad10b2 examples/F#/rtreq.fsx\n6e64fef009a39a79b7f24d4e7dd9a950e15bcc02 examples/C#/pathopub.cs\n2d4a10859e6122ad687f0dceb5ef9cb9195167da examples/Python/mtrelay.py\nfb42d050d97a3c738ea6d1f38cb42e14b0d0f781 examples/Java/Flserver3.java\n50196d44d781d1c8298b3dd48f7e23fd70cb2da2 examples/C#/taskwork2.cs\n1fc3f5b3655478259afe445f251c936518b82201 examples/C#/lpserver.cs\n08e8dd0a41c891decc852204007b1dde051a4d89 examples/Java/Mdcliapi.java\n216e512d99bfe5bf2e4026ebf4d939b5e3937f1f fragments/C/forward-deliver.c\nc1dc660f16df01a4f750287708ea835ccc972df3 examples/C#/flcliapi.cs\n643e0a25fa76bad04e49b3a1dbe1307580dd327c examples/Objective-C/wuclient.m\n9a14d89ee3133939587623501482a371bc01b44f examples/Objective-C/tasksink2.m\nd3184f12d45c8a872019cb1062e6a0053c96c48c examples/Java/lbbroker2.java\ne36ceb93cd7503297a9821d7e51357c9f77599bc examples/PHP/taskwork2.php\n014260833dc5623f1c7c5ba7fe614c8ed5ede071 examples/PHP/msreader.php\n0e6001f88a2a7d35c8be962ce1a0c6a6e1977ea2 examples/C/kvmsg.c\n4aa903582072d691c70f133736f2c5e09f5f6b63 examples/Erlang/msreader.es\nb61b8da556d21bf4b5d48dbfe88ef680a4607a95 examples/Haskell/hwserver.hs\n68dabf338100ed1e09d82e6bddfc94537eb933ad examples/C/clonesrv1.c\n41599b9d90390f7d27164e6f38ea8412417acc56 examples/Lua/lpserver.lua\naf11e39c163f8e53a4c76f4c7cbc85272e4ece67 examples/Scala/peering1.scala\n255c9b09a8e0ba36a91a66188e0ed1e3451ab5fb examples/Java/Taskwork.java\n4a4f4e2f4f754147cbf7a0ab70473641baa0eb33 examples/Tcl/peering2.tcl\n95df650992aab1b8372698d1225a2105cab02acf examples/Clojure/taskvent.clj\n28b755b1679230d0ba8e8be9f796f98b1956cbc1 examples/Perl/rrbroker.pl\ndb779be92d075e133bfde76599ab14a29b40f5be examples/Ruby/wuserver.rb\nfa475caf424cc1f719fadec35ebb22ef96f74bff examples/Java/version.java\n05930495b09eb242a7c95dcc8352f3a4ef633dfc fragments/C/fmq-server-api.c\n7fb44ebca6f4cf6d5e04ef72f522be3e2ac0dc92 images/fig24.txt\nb4feff8a129abe704d2b6e50dda8619a44db1dd7 examples/F#/peering2.fsx\nd7e46210eb9df18f7192ba045b12f39218cc6922 examples/Q/msgqueue.q\nf057951b46c170184748e1928959358058a16e6a examples/Elixir/taskwork2.exs\ne1389503d088f80b2780b4ac71cb2f618110d279 examples/Erlang/taskvent.es\n809a5188c6e18895cb63caadfa5a7fd19a7dbdaa examples/C++/identity.cpp\n2190d07bc151cd13ac4bbf566915d3ba27ceb3b6 examples/Java/Taskwork2.java\n7eecdb8dd0439f2e3ccfd373207e4a347b633fcb examples/Scala/mtserver.scala\n8f956cb9bd1fd48fba8919e5ac819f1ea61823c3 examples/C/mspoller.c\nb6e3e8f9cc8c748a992e7d5ad8d11cde4f9e80d5 fragments/C/publish-file.c\na7f93211ef6aaf3bc9119b9cd6d909fcbb48a5ea examples/Elixir/taskvent.exs\n2c625b99bc938a87f755318fe285e7f2bb3c0811 examples/C/udpping3.c\n81ca7b3c974d97c050af18a864a0f160aad94b28 examples/Haxe/rrclient.hx\n2691f5943fbcec806f93dc92e13a00a85213cbab examples/C++/pathopub.cpp\n88e64a2b702937d1f84a6f2d87e12f856c4f0ef0 examples/Java/lpserver.java\n3dcfacc2efc3015e6bde468bd341b4787a8590f9 examples/Java/Spworker.java\nfcd69a949ec06c296aa1cb6e838b25505eb34cbf examples/Haxe/mdwrkapi.hx\n1b5778ddbed6e238f15b375d6e4188d7dfe6cb82 examples/Haxe/rrworker.hx\n8ef8ae705854de5c94b4094fb1b64660562bb2f1 examples/Haskell/lpserver.hs\ne87190cc269079528b7bfb14d8cbef18383a83dc examples/Scala/wuclient.scala\n507669400f73bb174a7413edbd8da59f1a531d09 images/fig52.txt\n699b532c440dbd6963ecdd8d913e015f2a5033f4 examples/Lua/mdbroker.lua\n27d19ebba3c0617c3e46fba79374b452d917d09b examples/Haskell/mdworker.hs\n96c72ecc8bf0c1067611dded21b3674f208a91eb examples/Elixir/tasksink.exs\na10bc92fca18a6507cb669562cf7bcfa25b28c76 examples/C#/taskwork.cs\nc61b2f5e7e1f0f22b9f7b79c30911308a62ce1c6 examples/Scala/rtdealer.scala\nd8481c31426c5d10d2bae3b859f937b8c20b23af examples/Lua/rtreq.lua\n3fcbc9778cafa6ab50b0b85ec68e69b7d92e859f fragments/C/zyre-beacon-recv.c\n7495c65841f59543d897d0ce2f18fac1aeb2d778 examples/Ruby/mtrelay.rb\ned2ed3e4d8238145ad8da8c6f355d047e128882c examples/C/pathopub.c\nc5bb745a84a6dc9cb0a08c0aa6534d627763c6d6 examples/Haskell/identity.hs\nd1de6d22811bb4fcd6844be1b0628780825299fb examples/Python/kvsimple.py\n32c85cfe37395192112a469f29e8cd93a1cf836c fragments/C/lowreader.c\ne6981411339bc4434b1351eaa9ca909b3dbd3738 fragments/C/track.c\n8d2724251e540d8b4f0809c18038f101b64420cf examples/Python/rrworker.py\na769f42069f38ea3be830505d974d56ffeb38c8d examples/C++/rtdealer.cpp\nf7023ea53229a6975e967d8c5ec0119259b54d76 examples/Java/Lbbroker2.java\n332e0b599532346debfaa2541810563edbb30e52 images/fig51.txt\n17e459c9891d231d8cf52d9ca1bfa777dfe67e5d examples/Lua/syncsub.lua\ne23c587b6c3a0c3b0454f209ac4af94fcd425d98 examples/Python/mdclient.py\n8b478d2ee0ed9760bfca9fe7a444accb1729419c examples/F#/syncsub.fsx\na125413e2b9b557bb3e8f4529b4431a3537d34d3 examples/CL/lbbroker.lisp\nb5adb151d9261bf29736db8a224f2546db19c945 examples/Go/interrupt.go\n458c676862b497f9d72e51b9770ef9de4d55a479 examples/Python/spworker.py\n1f927cfcf0c8b38bdce939d1edbfb125ccb22284 examples/Haskell/peering2.hs\n44c2b949bd9b6862bdae2c17007e8f3e7857ef5e examples/Go/rrbroker.go\n8484a21c39c40f47fa84a19cf621bf36b5d2fccc examples/PHP/mdcliapi.php\n0cea5df6c6c3f7abb5ceec0830f6700dc244b055 examples/Python/fileio1.py\n9c5d2c00443d76cea00dd1d1c62fc6f2c1a316ad examples/Python/tasksink.py\n76c6c629091b2f5a67bd4894c7fb7317c8f648c1 examples/C/peering3.c\n32c1da80334b7082e5bd6637fff90c3ce3a49f2f examples/Lua/flserver2.lua\nd4c19277f6e8d43d79c7408396bd6aa56823189c examples/Lua/mtrelay.lua\na865beb305aa1135aec78f557be8ce9dac99fc29 fragments/C/zyre-peer-send.c\n6c9e789b2121030e7e4e45d5ed806571cafe891b fragments/C/reactor.c\nfdff2a5c91a358451088e2456006c8a8980e2d7e examples/Clojure/rrbroker.clj\nd251388b5ba4d264c9692db7604c8d093f69bbe3 examples/Racket/wuserver.rkt\n501eb2114abc8d3c680b65e47868cd12804e1951 examples/Haxe/syncsub.hx\n0ff24453a15c6a82a3038bf94be04e2c05ce9f9d examples/Ruby/peering3.rb\n3492d6695e632cdad1ef6607f685b420abcb511d examples/Python/bstarsrv2.py\nd66f1ce02cc1343b664d79834ba05a1f722ec83f examples/Java/tasksink.java\nb315f1a379447e6711a1375a995db97a022dfbed examples/F#/asyncsrv.fsx\n624d8c49efa3cbbbf331485e868e67ec1f63429c examples/C/mdclient.c\n3c6a9991700252ff4bf317ea30374b89f5397369 examples/PHP/ppqueue.php\n06166b811305de2ee97b632732dfbfeef3ccf9e4 examples/Tcl/lpserver.tcl\n33d7598d371bb22cfa13b3b6f1ec2afdca2376c7 examples/Haxe/lpclient.hx\n1398808aa65adea8af702c6f717fc9faef98dba7 examples/C/mdwrkapi.c\ne8dcec2e962eff848e2993fff8992ab20d4df703 examples/Scala/wuserver.scala\n28b2b15746d80f3871d749d7de62a66947758b77 fragments/C/fsm-instance.c\nf5e535256abcd3b49093dbf7be17e7b34f727f4e examples/Go/syncsub.go\n62efd3736579f807e949de40b6925d96e324452c examples/Java/Clonesrv2.java\n9bc6d0c344d3b3214d8eb9237fbe6e1879208488 examples/C/hwserver.c\n95fcd92a5ab1d934fa75e8f25762ba9d43ce58f4 examples/Python/hwserver.py\n018e2676e32e9fbd9b8c7b6751b06d72b844fca4 examples/Scala/mspoller.scala\n673360bedd9d26fef40b37ff5f181037c8fb74a1 fragments/C/zyre-tester-main.c\n9eb085975aef91411e38717a580eefce15645b65 examples/Java/Clone.java\ne411104c50a29c7764f1c06daa197fc26fee9fda examples/Haskell/mtrelay.hs\n8af285fe331095feff99a0a49a72da5e7b288b12 examples/C#/mdwrkapi.cs\ncd3d1a0701bbc1652d2f786e4b0e6f2723cf98e5 examples/Delphi/identity.dpr\n896c07c9dd97ee47573871fe927c4c7ab1419607 examples/Java/Interrupt.java\nbccbdf4e1045c7334a4d2c971a8858869290d464 examples/Haxe/tripping.hx\n202faaa48ee9b3ec31acae86e700f64eb0f0caae examples/C/lbbroker.c\n071d607c921d8da70cbbc60ef2f9a09cc7670842 examples/Haskell/tasksink2.hs\n7a6b8c0466610a88d369310331a89c0f53051126 fragments/C/polling.c\n1f7f69f6a3c16a6ac06f9fa8fd203855b4a175f5 examples/C#/identity.cs\n9722302266537f13bdf041303cee09d4b99069bf examples/Java/Rrworker.java\n31e0ca176286eaa3d492dd780f2e7951aff87054 examples/C++/spqueue.cpp\n71f104b3b6f9da917858444c75f87c186ad6fd58 examples/F#/taskwork2.fsx\n37f7554a516a5318d6deb00d0186cf0674235ecc examples/CL/version.lisp\n0b3644921f7285246535e540623d4277ca2386f5 examples/Python/tasksink2.py\n76665b7c3eb0c2f84fe8e832071701e0d5fa49f2 images/fig56.txt\nac1156ba2f953b3997550affe245164d50925024 examples/PHP/lbbroker2.php\nb58f93dbfdf53fec0e651167e082be41c730d8a5 examples/Perl/mspoller.pl\na58205f1c01de5d47369f89122249fc195baf1c3 examples/Perl/syncsub.pl\n52f09c5c8d5538e796e5f3e7647b0d5fd40e2474 examples/Go/rrworker.go\n771607c0bdd670a2e63733b1ac1ef4267bb513b3 examples/Ruby/rtdealer.rb\n2c9783c77a710d18107edcf43a081943bb9a6251 examples/Java/flcliapi.java\n1d10929f8ffa7ab9e2dba0d17eb47c0773eed7c9 examples/Python/rtreq.py\nab514f30c9435df55684a4efea822b8e24e9b81c examples/Racket/syncpub.rkt\n5923be948014f0702607b0432be09f2d96ad6617 images/fig64.txt\n50f50929a3d63a8481425ac0ee85a5d48b0e05da fragments/C/recvmore.c\n575729ca65a51a0943a2b9a4dcb9f601094b7d14 examples/Go/rrclient.go\nfd149c96ca1756223433a4d1431f76249bed0343 examples/C#/spworker.cs\n1ba798e9b2a7f1737c9293344618b9f417a92846 examples/PHP/lpserver.php\n7fde080e8f4508f2f03341eef29d6fc1f79e0f66 examples/Java/Clonecli6.java\nb5cc458bdf83c2c3c04facf6ea17919e94ff025e examples/Java/Lpclient.java\n050c9a52a5e95e34019579a68f6d69ac4593e074 examples/Haxe/psenvpub.hx\n18bd61de83270d56380966dbdc02095551bab537 fragments/C/mdclient.c\n2ca7c499e4bfba3dcf661a78c931e721f6b5cd0a examples/Java/kvsimple.java\n118b3324fe649a6f3a3f59af01a5cb1fb45851f7 examples/Node.js/syncpub.js\n0cc46e3a077187d3316462e881b2a55a812b39fd images/fig49.txt\nb45991ccef7115fde477022ec626f70f30a4df0e examples/Python/mdworker.py\n9cd364e7e6e03e18b4cc9e2e2d827dd1761d3e63 examples/Haskell/wuproxy.hs\n356658177b6fdc3cf9314ef7458af076d0bd786d images/fig28.txt\nef71e3522fc9e7967d1b9e773776e8dfe5d21b38 examples/Elixir/rtreq.exs\n95ce2c4b104f25887e32d52eb8d37ca96af8bf74 examples/Elixir/rrworker.exs\nf556ef14bed7f97bc4029c5fb0fa950b1c99bca9 examples/C/lpserver.c\n1c73d2833ca6209e4b88c3416b40b4ef3aea73e4 fragments/C/mdworker.c\ne141db5b4e7df84dbbce54667dabe2e7ac15d5ee examples/Node.js/lbbroker.js\n984c536d1462d38471bc7d0f3291552ddf496b90 examples/C++/rrworker.cpp\n7fab697f4da9c4b44dc5ffb9d0faedc487d7c385 examples/Haxe/mtserver.hx\n513a5190bea8aef397ddc21748abd992a9b82e84 examples/F#/lbbroker.fsx\ncc8c05356711e67d77b38e1c4a196b850890afcc examples/C#/flserver2.cs\ne6b9b1a9aa818ea53f147962ffb33ccd7df37c21 examples/Tcl/spworker.tcl\nc340152d90bea07b5a07be4cd13fb09c156e9d8f examples/C#/peering1.cs\n64917f6ea6742597b8a26bdaacbc264f2f5d7fc5 examples/C#/psenvpub.cs\n331984fa6930299e1fd0e828b0a1191bb8146295 examples/Go/hwclient.go\n980cf75580b8f904e80d78850df2d1179fd04b38 images/fig50.txt\n605467ed0920b734207dad970d90b81ff0b2cd15 examples/Tcl/bstarsrv.tcl\ndbde7211baf3706cbaaf74cf2e8aa979e4df4945 examples/Python/titanic.py\nc6d237de889db300cd8f15499ac225e536e7d8a8 examples/Java/taskvent.java\nc669774b3e00101d8f9d2a5ced7bfdc39e9c13b4 examples/PHP/interrupt.php\n2b7d9e0bebc3b4d7435ce6832aa31757db86cf3a examples/Lua/rrbroker.lua\n6d48735b9287d355b4ee8312969b7f213c672d11 images/fig57.txt\n3e9c994103f803bd46ea4ec951c3214ffa292ae5 examples/PHP/mspoller.php\na54719e02a88eb69c8d1181988409c2e1728376d examples/C/eagain.c\n3879ce596a21a78b34f8d033aebe25d7dc51098a examples/Clojure/peering1.clj\nb45dbabb39940e7f341ef33ae64260a062c5f1cf examples/Java/clonesrv2.java\n3c8b2e92c6d3e8c908b3dc09909ccadccf26b017 examples/Go/tasksink.go\na251a4698822d4ad3925a018c4e5893ef2e72c17 examples/Go/msgqueue.go\n11fe28a0fe0e80a82aa1e82828fdf8148f2dd773 examples/Java/Flserver1.java\n09361c8d47254fa8e8547644b27efa22c68a8522 examples/Elixir/rrclient.exs\n7fbadac5dea4bf8b4008408a5739158a0b76e73e examples/Ruby/pathopub.rb\n46fa0c2b0dbd5435f4b613d25051ff663f4028bc examples/Erlang/rrworker.es\n3dd24a89abc142240e9d1866c0dd1793f6525eca examples/CL/rrclient.lisp\n5823cb8a50a2842cf4595d3d29fe65db5372cd31 examples/Tcl/flserver3.tcl\n41cf357ad67c29439494576d8d6713d0cfd983e3 fragments/C/zyre-beacon.c\nbe5cbdd415ea09a43ad430973c040873af8b1716 examples/Java/lbbroker3.java\nc416903da6d1ee6cb2ac35379d11eba5c3c8e7a4 examples/Lua/mdcliapi.lua\nb647647a23ad6f52291058437ba544d8ea9cba15 examples/Haxe/wuproxy.hx\n60cfd0d7983fbe3612342a82a84abada8db6c797 images/fig48.txt\n785455fe8f5ad5646fcdfddc31f9aa42d48923e2 images/fig29.txt\n7f0019b2d0f8249f75e57ad562fcf01205c9eb83 examples/Elixir/taskwork.exs\n8c1ecd0d543358734087158cf299ffa98f960cda examples/Go/taskvent.go\n395ba6fde81cbf225bfc69735e16b50e4843a1e5 examples/Java/clonesrv3.java\nbc27efff0fd7583806454146039789d3573aa985 examples/Node.js/version.js\nd5d9a238539e552ca4e16769b18580f5b09abc65 examples/Haxe/lbbroker3.hx\n304315bf28011c811f657ad49aaaaec595e82837 examples/Lua/wuclient.lua\nf0f1b6f7e4cb2db2683bcaacd32265eb427a0336 examples/Python/udpping3.py\n6f54996a67ca9c36ff242d444dd6308421734228 fragments/C/upgrade-shim.c\n8696aa34d6f7a2b5e2fd1a382c7cd89d617011cc examples/Haxe/syncpub.hx\nbd93715338fe685fb1ed63266327e47b2648237c examples/Java/msreader.java\nbdb7605cb2247e66b2f459e59f200ed1edf7309d examples/C/clonecli3.c\na66f5602bb4ff578df2e662e22ff823595910dc4 examples/Ruby/rrbroker.rb\nb21499445c58cb553aed2c5b8414e2c5efea2ce0 examples/Haxe/identity.hx\ne230764924bd8db8231b80059797efe170d28c81 examples/Erlang/syncpub.es\nfd49d36267654e53689c6846b90ab06488966214 examples/PHP/mmiecho.php\n3a3b1aa3506b37ca11cebbe451c1931057e184c5 examples/Node.js/interrupt.js\n971e90d0b9fa8a54b7952be9a06f9eac6987db7e examples/Haxe/mdbroker.hx\n637fe63633f131a096b97c958dcc6b21afef1fcb examples/Erlang/psenvsub.es\nbc5b5d2f377721cb4100ccd9c802af61327f440e examples/Haskell/mtserver.hs\nf310f944b8decd4995435a38dab66e769df52730 examples/Elixir/wuproxy.exs\nfd88e273aa6aa83d6e57ba7b5f6e79c2a587fa35 examples/Lua/taskvent.lua\naec90032762b5344d433893e9229001b112bc8fe examples/C/clonesrv3.c\nde2e3b1fe95a83de75583b7591b896971561678d examples/Java/flserver1.java\n5df24f1dde4fab995982f07ffac0bb73d3fcfc4d examples/CL/tasksink2.lisp\nd14f70bdecddfd884f1c0cdc592517c684377c3a examples/Ruby/mdworker.rb\n8e636c1772843986c290c680361eb88fb98eeadf examples/Python/clonesrv3.py\nd50c97ecd4fdfc0c982323734e4f7a3554366b0b fragments/C/endpoint-hashing.c\nd6548f2f9b642a1ac7e68624f4b2384e8d76f7f5 images/fig5.txt\n28ef6d97eb36de4ba8c67b7a56bcd3fd03477dd6 examples/Java/flserver3.java\nbde4c8de6a498cb01b13077939246438f2bea09e examples/Tcl/clonesrv5.tcl\n3aa920ae6cd5f786800eeba5c3dbf5b465e5eacb examples/Haskell/version.hs\n70095ffc6257f23a67854230ad4bbbfdfba9e62d examples/Node.js/asyncsrv.js\n1cf7cc068f6c4baaca4bec885ba5e5fb821cfd89 examples/Elixir/syncpub.exs\n9010fdaa6ef086a04144e47060c48048718e15c4 examples/Clojure/spworker.clj\n134b0e80fdba2f0d759f3afa39e3dc23e3e14aa6 examples/Perl/hwserver.pl\nd4a9334aedf99b5a80c6aa8d4bad7c4a78a95bf6 examples/Erlang/asyncsrv.es\nbc000aa2fefba4658aedc3f45daddc58b54f8acc examples/PHP/hwclient.php\n2839f303e38a0b5887ed7389857d1e529bcab83b examples/Lua/mdclient.lua\n1e5de703b293766d36d9875d6ce38fa3233e4964 examples/C#/pathosub.cs\n11ce5703085fce2f0ca1698fac7cbedbc4e40586 examples/Haxe/ppqueue.hx\n632adecc796e39d07d1fa2a47b7902f24e16642e examples/Delphi/rrbroker.dpr\neb3950d7d520d5af950e84db93ceaa29f7f9a56a examples/PHP/mdcliapi2.php\n9806d055c7c4df58841399c365ed929c79a179a8 examples/Felix/taskvent.flx\n96bcd85aef715249232215825e81f206493b08af examples/Node.js/hwserver.js\n6d3eb2c3d6aecc2255b97edefc6f91058fd9f26c examples/Erlang/rtreq.es\nebede19e31b664de8250a6e6c2aa69f51a9b37aa examples/Perl/rtreq.pl\n581d186b143c6d5c9231635f3162a48eafe2ba9f examples/C/clonesrv6.c\n3fbc601c94b9a21ab2ba76f7ce7b1cf923638860 examples/Lua/tasksink2.lua\ne0262047664aeec36e21064043def139c1fc9155 images/fig70.txt\n056236f473847efea64df7ce78e93095700057d2 examples/C++/lbbroker.cpp\n2cce8f8f96d47a1cf591689b02c4400efc024b34 examples/Haxe/bstar.hx\n04b62bdeaeb81b021a26f0a9a1b5d05e65809b0d images/fig67.txt\n03afd1fb192476f7f6a906987a1f16dbab169fd4 examples/Java/Lbbroker.java\n23979fc87f7714c9fe9656a6c89c2c399ff12f5a images/fig60.txt\n2097b0e90675c7368978b07f7bbcf913abc034eb examples/Lua/mdcliapi2.lua\n731fd6ceff990c7dffea6bad5abeebfe1c38f41e examples/C++/asyncsrv.cpp\n96b8e2b619951bfc349a90a5e627267689672016 examples/Java/Hwserver.java\n5283b49ebb1977b970ce62068ace561a5131fa65 examples/C#/flserver3.cs\n76b818fd39c3f8510eaf295050ea36ddf509461c examples/Ruby/hwserver.rb\nabf89204ea9a06221532aa245cd54a777110c027 examples/Tcl/clonecli3.tcl\n2b6156bce9cb596bb25ae2b853f25f85d584e733 examples/Lua/taskwork2.lua\n0b39326d241dcabd65819a79cafd61112b527eee examples/Haskell/lbbroker.hs\n3f383b74fad461eb0df6d47389423f2a47c47867 examples/Java/clone.java\ncdc429a6a307669bfc42e2a0ea1cd900c0f1f4b3 examples/Objective-C/mspoller.m\n6e4b1eae30ca26e1429c75a47272978d28a9f7c5 examples/C/taskwork.c\n87d0a08a70e13cac09f877943e31c0f57c687621 examples/Scala/msreader.scala\n453bd45a01ad126831bb34b7341ddb802c798446 examples/C/clonecli6.c\na79f085e2c53f04b9a10889addc1a2c835039b91 examples/Ruby/mspoller.rb\n98913d674c40172faadc26833ee49e6b298c507c fragments/C/proxy.c\ne9294e086e02bbeccfb7044f7b485818606f09ac examples/Haxe/bstarsrv.hx\n8e4bf942e304097bce573d2ff93de05a54554ea7 examples/PHP/taskwork.php\n6df760c1cd3835bc0776605c7856d30b15279183 examples/Tcl/suisnail.tcl\n2ec6143a61202c4319c2f150ba5adbb5e61acafa examples/Tcl/peering1.tcl\n52d9e457f949c67fdb3acd2f64d6ce53686c0b80 examples/Erlang/taskwork2.es\nd4d78e058dea896095e5e35ebcbedfe4fb411fe6 examples/C++/msgqueue.cpp\n9d4b1727f18b8280ead534c0236dbe5e060b1d6b examples/Go/peering2.go\n608375cf069921ecdff11739100d7243a9d2abfb examples/C/wuserver.c\n69fde2ec444f09b9324d8fe86d4416532f4d9909 examples/Java/Rtdealer.java\n1a8b298e8bcf3a7725d7322219bb751ac831f36f examples/PHP/mdwrkapi.php\n2ad28109ca060ad17f62a38432f0639823960ac9 examples/CL/msreader.lisp\ne4f82fcc83b035388f0ee36651e9456922ccad23 examples/Python/clonesrv1.py\n6baadcc6afb23367f5f175a69cb6d791e46f7605 examples/Haskell/hwclient.hs\n080ea32c8b53a009ca67494c673b7f1e7cd5fb31 examples/Python/wuproxy.py\nc2676475f8fda872393cce58dc7df21c62cced03 examples/C++/suisnail.cpp\ndbea6f88e76f7b5406b5b616e427a7c844ecc160 fragments/C/kvsetttl.c\ne810d38492c0bdef7be8fbf6a5f0c1e427316da6 examples/C/tasksink2.c\n2d753fbefce2e109940f2bb2838e61aafac95460 examples/Tcl/rrclient.tcl\nd670b7af7e2d7aae905885ce0221d97163445a9b examples/Java/Pathopub.java\nbf7d3b7f524767c7c645d5ca0a70e0727e6b1cd2 examples/Clojure/hwserver.clj\n4baf479ddfc5a529436508b7c526991dfbff242b examples/Node.js/rrbroker.js\n12a1cd89cc9461df278f9fd025d704a34d948f35 examples/Perl/rrclient.pl\n0083560330baa0b391319b6f277f50ebc460989d examples/C/identity.c\n0d4e1c57fd64d769ca8569cdb7ea89726e05c2cd examples/Tcl/ticlient.tcl\n136e94da93d20f7d4b5488f98362aecd21c7aeab images/fig41.txt\nc67e504f32bbe436d9bb5c35634443bf89306287 examples/Java/Rtreq.java\n78818a12c8fa38273dba97530231d58c8438cdf9 examples/C/bstarsrv.c\n2fd07614cf3d592062bb2da2b2fa525ec96005d3 examples/Lua/version.lua\nd363b4fd752513f77cef05b4f7314940f6a90308 examples/Haxe/peering2.hx\n3498ed2d3870b2add6313553535eee1616166c71 examples/Racket/wuclient.rkt\n5e9183c46c366554b847c32da206a73333025a6c images/fig7.txt\n4a26a658cbd28ed91ea969fd943b4f6b548f6853 examples/Delphi/wuclient.dpr\n65408d8836a7f75b3dcf516a6b957e6bf5f5da78 examples/Go/syncpub.go\n61921f916d68a29e03e7a241d78814cce13e3f42 examples/CL/psenvsub.lisp\n175078fb32ee834bf69f5801e730bef8e360a3b5 examples/C/lbbroker3.c\n07d5bfa117f6c0ad867baf9a3b5c3a789f4fa828 images/fig42.txt\na98102b1ffc758891bb9ecba7738283b49e6fe3d examples/F#/rrbroker.fsx\ne5479d5f8d24c0a3423f645f9502c68c71d829e1 images/fig25.txt\n88831f7447da7e28f764beacc0f5b4275e43639d examples/Lua/lpclient.lua\nd01df7f414c08e94e9290028fe2bb09856f6c15b images/fig6.txt\n3976ce5013d62a0138bf0ad63c02cf7fc3607ac9 examples/Python/mdbroker.py\n19d199668252c2efd204b5a1b8a5f78e4d281b17 examples/Scala/tasksink2.scala\n6730727e3e93540a392daa8ac06c1cceae883699 examples/Haskell/rrclient.hs\nd12093fccdea7822cb2297918ae7b0b53b4be160 examples/Lua/syncpub.lua\n64f6fd53515fc496e838b288d86ab7f5eca3a5b9 examples/Clojure/wuserver.clj\na151c97a69b15bfab5cbc0fb8b0a7fec8a6a7421 examples/Python/rrclient.py\nc321b613828d0e2f40461a9d1a2229e23566c4e3 examples/C/bstarcli.c\n3a1fb35b6dcd41ddcad578e19b6c44a7b04a09e5 examples/C#/titanic.cs\n842a6d15e4ff075a116a18e54e19decbe5c0d24d examples/Java/taskwork.java\n98139b18cf6574d32c78fa52bca7b3d605ea19e8 examples/Java/fileio1.java\n70f78a553b0ce661932abed8aea9c29b3a7cd246 examples/Haxe/msgqueue.hx\na119708d7c235212f71314ddc118ac75ee8f86b5 examples/C#/mdclient.cs\n8df869e3dcbf52bbcbc7ec5d6e7b64f990f78944 examples/Node.js/lvcache.js\n5dc8321c91f84c3936abd97e5b13a1c93252ce9d examples/C/flserver1.c\na7d19cbf1ab02b4badaa2e7e8e59d55508af2a39 examples/Erlang/tasksink.es\n5c0d98d9c242f96cd5ffe22aa94ef4042ae051d4 examples/Java/asyncsrv.java\nd6907f0b57aef972532d29b3aab45ae0824173e1 examples/Java/Peering1.java\n74a76b0353ab42fb10755017376410b59289add4 examples/C#/mtrelay.cs\nd57ccbe787977ff744f80d4f1a79197ecebf06f5 examples/Tcl/flclient3.tcl\n2b6aac0176713fc4ed4088a2a72e50907e7eb7fd examples/Delphi/taskwork.dpr\n07e14a2b83478e4490275d8616c878ca51b935f0 examples/Tcl/hwclient.tcl\n9c16a8a18db9fbbc5036757978743c23c8cfc811 examples/C#/hwserver.cs\n6039cf0db47fa48246cf5d6aa3ac4f92b05280ce examples/C#/mdworker.cs\nd483dd7e80d571a155c5169daf5552d3086b928a examples/C/flclient3.c\nc369802302510aea6e642b80e0965393b103cf19 examples/Java/Lbbroker3.java\n84eceb3c48d60777c753b2f69a4d8c287dfc45bd examples/Clojure/msreader.clj\n757c637e8ce0b9cdedceab28224d7081baef0172 examples/Tcl/rtdealer.tcl\n981eeee4795618c3a01739039d0d4fd8dc1811e3 examples/Go/ppqueue.go\n2397e8fac50a7a417a5571f230b9594c45d79f7d examples/Perl/taskwork2.pl\n7a44905a0af6a43725138ad1ae07031366cfa201 examples/Java/tripping.java\n325abcda1d66d586acf38ee823509f707dc6f431 examples/Go/rtdealer.go\n0f5e70c9fd423cf462d85149a52c45426a3986f2 examples/C++/tripping.cpp\n7357eb20808733c5155cb280808f2b8e67155d16 examples/C#/flserver1.cs\n7bbcbfa6e402a93dce17abd61a2f18f570614546 images/fig21.txt\n21c7861ad5ac104cca450b97f4b94831cb1a183c examples/Haskell/mdbroker.hs\ne3bf6fbcc642f0d03a30c21540725c8a033a8b0a examples/Clojure/rtreq.clj\n9fd2471fbdb204c1014b85127c88619fe1609c2d fragments/C/filemq-main.c\n74eb1533786c80da0bed4a1e944539a3f49a59c8 examples/Erlang/taskwork.es\ne3b95ea8ee2eadea277631c3c16dd7d5b8da37f6 examples/PHP/mdclient.php\nd142f8a97b6290af9cefa2f213636d1f0b570241 examples/Java/Wuclient.java\n6e6ffb3b7f04c4edaca67800eb05adc759ead7d4 examples/C++/wuproxy.cpp\nd51cc6873f74e66eb89900107a7d924df2e27ea9 examples/PHP/syncsub.php\nea7cebaa22c690d35be647dc817560785833fa34 examples/Java/msgqueue.java\na78379db5024d38c42eb0024db2495f2673f4159 examples/Tcl/hwserver.tcl\ne33689c849c20b2b3f560f3b5b542211f2c51cbb examples/Java/fileio3.java\naf6339dc23cf063fc168f4740832b954b9157540 images/fig22.txt\nf800d0fba27d579046470d7f59351d2a545c1ca7 examples/F#/wuserver.fsx\n93a0a72016be4bd3efcf29923aa79821a6cc4323 examples/Java/peering1.java\n49d8e81d1a2a15f28797329da96cf4357c0295b5 listings/Tcl/listing_52.tcl\n756b67dbc5a7089d39a78ddc61201fbcb17de822 examples/Erlang/rtdealer.es\na7b286d9eae1b53d969b532ebca7691b42671b23 examples/Python/lbbroker3.py\n613062094df4320e81d63a93bbb040cb062750f0 images/fig45.txt\nf26d7d10b4034cb2f398c334da4881efc9f27d73 examples/Elixir/psenvpub.exs\nd616d648dd01b99b208d3ef4dbebca1b1af008b8 examples/Go/msreader.go\nec7c9e16c7574be93c8b2a52070f3c511e8146cd examples/PHP/mtrelay.php\nf6097aefad82e399cfb61cbd6c5e4b751cf7fd0d examples/Lua/peering2.lua\ndeb27abf6cc546bd06981369f1b6b857ed2b433f examples/PHP/rrbroker.php\nf40c8598540a80e5c0faa3cd3bc173065254bbde examples/Erlang/mtserver.es\n1f5d28b2a50e885f05ff984c8e17504b271edff3 examples/Java/clonecli1.java\n5a42eda1924e3f58953be34864057784855a5fe1 examples/C++/rrbroker.cpp\n7b18169a34b846dd2c4f7b15f616eae947358234 images/fig33.txt\nd462ee86e0cda76fa9baa2eee736b57328e48e06 examples/Haxe/rrbroker.hx\neee27cebfc3430bb721105e5d820b5820960f8b8 examples/Tcl/syncpub.tcl\nd9828bb02de0429c0ea66c5285e30f9caf680b60 examples/C#/mdclient2.cs\nc5d332f8cac39fe217e200a734cefa75ebf1b75e examples/Java/rtreq.java\n3f8a218b52eb47b789c995025e4a4f01979ba753 fragments/C/binding.c\n2520d7b1dd0eb5a5c962382a0e0731c64eb4711f examples/Tcl/mspoller.tcl\ndb84f4bf59f22912968e573333fb5b4104da3172 examples/Go/wuproxy.go\n4e105ebdf8b49bd693abad3b5ba489b07bbf6891 images/fig54.txt\n575cf3371c761a750ad3490ab934fbbe1273511d examples/Ruby/asyncsrv.rb\n9b886d5d31988cb5256d2dab0a94e81d782fe6c5 examples/C++/rtreq.cpp\n400808157824816af2e899e558c9d758e59059ab examples/Python/identity.py\n9bfc7d4827164f5d225542fc6b3da651fd1c87de examples/Perl/msgqueue.pl\nc235606b60bc33afbaad3aebe95e11b076387607 examples/Tcl/kvsimple.tcl\n1a24e823e7936c1d5b88dd27c9415f1b5a2ead15 images/fig66.txt\n8700a3e6a55ef3693ea7d77f9178ca2610929544 examples/Java/psenvpub.java\nea967c3c1529f777a87c5d594ef7c67ca6007d07 examples/Tcl/version.tcl\nae220c2e1a11071b333299bcb14219b95f123e9b examples/Python/ticlient.py\n37e5178f8f85d079b3a57ff68447eeafe7b00abf examples/Delphi/spqueue.dpr\nb4fcfce66a9e788574d6955d2e1aa76cf677db6f examples/Java/mdwrkapi.java\nd475b3cef1761b7fe82087363c65402d3fd35ecd examples/Scala/syncsub.scala\nad87afff92524ae5bbb1bcc6ff1a53b51cd84ecc examples/Haskell/mspoller.hs\n5aa8cf2c9fd46bd7721a2896820f62e573fde368 examples/C++/taskwork2.cpp\nc46ed06f24c8c02b88fe21827695773b32a3e167 examples/Python/eagain.py\n4c3f834c1b1d3a06781c5c95a6a5288fad990899 examples/Python/rrbroker.py\n8d074242619d27f6e08e2ddbd1cc7aea40fcc7e3 examples/Delphi/version.dpr\ne571c5139b2421c11e1d1a6a8f3fceb3e46c57d5 examples/Python/flclient1.py\nc1460f884568380ade196d868c6148411ef37352 examples/CL/hwclient.lisp\nc82e265e75da0e3cbecf215efad1718cfe317bdf examples/Haxe/hwserver.hx\nff987d5886f6180ba605183447404d8a43a7ddc4 fragments/C/brute-force-discovery.c\n7ba829a64f6ab4bb9cb3c1280273359bc88f7834 examples/Java/Kvsimple.java\nb0e8cc6d5b4f90a52c19292d0e4b60994726018b examples/Elixir/rrbroker.exs\n5f8efad2a8476391e8c779b30842fcf4ad049aa7 examples/F#/hwclient.fsx\nfabd3d51aa4249bf54e34e42ecd77c0f4148152b examples/Java/mdbroker.java\nddfc2281b409a383f380b8bbd2ef8b63916740e3 examples/Clojure/tasksink2.clj\ncd98570a06ed10ce0abacf89eaef07d2bf373152 examples/Python/mtserver.py\n690cf30e54ed93949c0340a272b2114213ae1d4e examples/Java/Mtrelay.java\ne9989001a3da2b2ce3140b621a69c0b2bc5d7ec2 examples/Elixir/hwclient.exs\n5a342b6200968e056ec5c93e2898103a204cfe9e examples/Java/Peering2.java\na5378ed1c502b83757ab96d1213dbb632237c466 examples/C++/ppworker.cpp\nb9b9cf8c095061dfb6f3943d4827472a95ba6074 fragments/C/zyre-peer-new-socket.c\n714c97ce6df4dc9e4bb9c9026aacd171c584ef67 examples/Node.js/wuserver.js\n6ceae71b17dd3e09e3c624148efd05d9205bfaeb examples/C/mdcliapi.c\n2f8af60596c48cd50917ddb9aa3ba00ffa126e48 examples/Haskell/ppworker.hs\ncad63adfd83669a3412d63dcf8f4eb459d6a2883 images/fig58.txt\n7b49705bf529a9b4f3b279a8c80b8440c68b9f2d examples/C#/psenvsub.cs\nb017af091a2c48efcd5f73c3ad29feaa620f3f73 examples/F#/msgqueue.fsx\n0f488291ac2513bfbb310a501e3fbdd51586645d examples/Java/Bstar.java\nb81c5daae5af78bf186862209dfdd23cbd259c9b examples/F#/tasksink.fsx\nfff732bea2b6bafb5bbd911e831bf902db09af4c examples/Delphi/peering1.dpr\n7635d56efdcffb6a8fe31d87956d9a47b0fae589 examples/Ruby/psenvsub.rb\n39bc3b1a1841b7ffca2b171a19d61663bd076d00 examples/C/interrupt.c\n69b63f88a34bbff783a715b36731633a01069f53 examples/C#/mdbroker.cs\n1ba13ef5d50279d39bac2d12559b4bf6457f41a2 examples/C++/mdworker.cpp\n493e521811c34b2393b27cdb05d455100b9210fd examples/C#/mmiecho.cs\n12d4cd74d3ce8fc12baef8afa8701d42b7ebee46 examples/C#/mspoller.cs\nc29f21ff0d1fb6a9ee98814df7be5788f3d8592e fragments/C/zyre-beacon-send.c\na550d182b95ffc3e1e66ee9d0fab3efee906f488 examples/Java/Clonecli4.java\nfa95dfcab3baaa6d2c315b48cdac8c2eea59cb01 examples/Node.js/peering1.js\nefaaea4f20b6854a2139eed6a27cb98701ec18a6 examples/Clojure/rtdealer.clj\n6d8cfa13a8038b19871b24ab7ea880579d7f981a examples/Objective-C/taskwork2.m\n04d2daee4249febab53e58787dc44d1a18d2e368 examples/Java/Mtserver.java\n261335063778f7117da81a0fcefd0ea5e7ba4f01 examples/F#/taskvent.fsx\nb62ab76932bfd7f709c440e08288073e85f58293 examples/C/mtserver.c\ne7fd2103dcbb97306ca04f84ba1a8693404538df images/fig47.txt\nb8d37248d8b6f3d5b75236d1bb9912d9d18322de examples/F#/wuproxy.fsx\n170b7b293429291d8ca14312effa05f5959f9fa9 examples/PHP/wuclient.php\n50a057f09d4aeb0233f2e4ac1a47381f4ba7faab examples/Java/Bstarcli.java\nb8efa73893a24a7f46c38d656803372865a5d3e9 examples/Java/ticlient.java\necb71c5db9aa051d94a08c6ce4cec21f6be68da9 examples/Lua/taskwork.lua\n2143b41b6660ce468d574f6bc458d02270a88e9d fragments/C/zerocopy.c\n4d33d2fe83d7f2b506e02c3e6bbd1789888ba4aa images/fig40.txt\n8e4e30e4e224edd0c4a78420a6ddb3c0589e1cfb images/fig26.txt\n97281518b39a4f34097724b5c770798b54d1688d examples/Lua/tasksink.lua\n1a8c84cde8bc82946c6ccd643ba4e34e7329949c examples/Tcl/mmiecho.tcl\n831cbd27da4d2640d2138376c68fdf727f39fc90 examples/CL/rtdealer.lisp\n1913a211146f4e69913c331684b110640f92e8e9 examples/C#/wuclient.cs\n9e7a484d9158ce1c39385da250ed30ce06231555 examples/C/udpping1.c\na00ef46913f0fe1ba0239a08897eac54734d33e9 examples/Lua/ppqueue.lua\n79d7a9eede8c27b75ff0d5bd06b345a0b1505bf3 examples/Haskell/syncpub.hs\n34169d317fb92457e6213af3517d011b9099f813 examples/Lua/rrworker.lua\nbe809074101eb90d10417050180b2584fe19c1b0 examples/Java/pathopub.java\n5f7f8171839d70f220f9586836f66a6d40162a13 images/fig62.txt\n911ddf23851f9190af1a2a3901025aac7cf5ad96 examples/Delphi/lpclient.dpr\n1dd7a2c209674a83ee9059b31aaec201b173451d examples/Lua/suisnail.lua\n75c3a45c8853b365dcf59bb887284b2f5280e330 examples/Java/Mmiecho.java\n6094db7eeabe82bd65264d74086cad4aefd57859 examples/Objective-C/msreader.m\n7b36da4cfba46a19dfbf7e74b216d4757be8ce60 examples/Tcl/mdclient.tcl\n3505522b83dc283a63a9ce5654cd9d7071612314 images/fig4.txt\n54d92b89b1c055f1422c23adc03020c45d1bac98 examples/Haxe/mdcliapi2.hx\n5462b878719ba377e4db46f158fcd4fb5afc5c7e examples/C/titanic.c\n9e5c5f5a52b0d1dcb0258530e21bf125c4058329 fragments/C/zyre-udp.c\n37e4319192f965b42c08f890c3714ae1aa2f8ac5 examples/C/ppworker.c\n6e2deb814a4f50a235f414a670a84eacab55def2 examples/Python/clonesrv4.py\n64f8f5575487ce1b58a391b7c6184cc91326ee86 examples/Haskell/msgqueue.hs\nd57882dcfe22baf322c43b5cbacb384e79265f73 examples/Python/syncsub.py\n6548f54857b37fdfb9b6c588f392a23e4fcb8943 examples/C/fileio3.c\na28c0a0bc911325efbd87732d0f166835a0f583a examples/C/wuclient.c\ncd86f0bd02ae9321389fc1abd98fea6425851a54 examples/Clojure/psenvpub.clj\n85d9fe10048eb5e6b4cb4fedbf0ee382f8601a55 examples/Haskell/tripping.hs\nf6078d239e39c558ee4d40b0c78336fb2e093ea6 examples/Clojure/taskwork.clj\n174d1391cc48e181a848dc26e0e81780c8c1be1f examples/Tcl/mdworker.tcl\n5d759e02848f82a23e4af96b67e3e80c904fd565 examples/Haskell/spqueue.hs\n475db08e2b2dd6088f0f0f9db273dad36b6c0f4d examples/Felix/taskwork.flx\n155cad94526415f4fe9550d08dccaa185f4a9f28 examples/Python/peering3.py\ned414eedbfcc0296e92644b1b3ac8d180a1f7dfb examples/Lua/hwserver.lua\ndce9a71bc9f7d07d19b9b93ce8918bab563567cc examples/Haxe/mdworker.hx\nd35e584a8d149636b431cdfc37aceb2a58216d7a examples/PHP/lpclient.php\n837e6a3ed82110185183dd8f564dbd7511896ead examples/C/peering1.c\n0071d2e8e92e35899fe06ee5e1502205aaec68be examples/C/dechat.c\n6c0a554c64cff58dedc3bc71bcc52dce65346924 examples/Java/rrclient.java\nf4bd53526abee410907718901f433ccefe2d1120 images/fig61.txt\n8216f6f8047f8dfb1b32fdf6e3b9e8782f4e1268 examples/Lua/mmiecho.lua\n3ad2d99173172b57ae2a9945bc80a282050ed818 examples/Haskell/wuclient.hs\n8baf7592263d466e3b5be2e91d958eb5d0cbc342 examples/Objective-C/hwclient.m\n65b4d978bf4886a572528070033613e93d8ac8c6 examples/C/mtrelay.c\n9ac433a6bf5e85fc6c684ec22d64141aae1b79e0 examples/Scala/rrworker.scala\nb4efea8c04f495c1473ba4067c6bcd2d599024aa examples/C/peering2.c\n01b4e42e62a69f086b0902cdc9cf7eda6d21f1cc examples/Go/lpclient.go\nd8995c2e7780b693551b7b9a68980348a343f135 examples/Go/asyncsrv.go\n8783250fa206ed187024724856f51b2035a03c85 examples/Java/suisnail.java\nf747cd04574a3729903cdfdf48a0de7a4de2b8bf examples/Delphi/msreader.dpr\n5f49442d90c86cf49fc5f8cae81c240c88836dbf images/fig2.txt\nbeaa4fd92bef17228d5616ff7962ac66c091d443 fragments/C/errorhandling.c\ne6f57e313fdd8018f805bc10a6f553858f48b1f8 examples/Lua/identity.lua\n89e13f078c635c5e0065956a079fa9771a24cf07 examples/Tcl/mdbroker.tcl\nd6ad631c9f7b00b53f50a6563f4d81389406e29a examples/Delphi/mtserver.dpr\ne3ed573c5543252df58a630756b80d730d6f64a0 examples/Ruby/tasksink2.rb\n5b9eec6d9932e3210bd9ad1e3fd96dd18412eefd images/fig65.txt\ndfe97e2297014f74a9941bbe0d28d6021de0eb51 examples/F#/syncpub.fsx\n6fa2706b7452079b5064f3b10ecf13b046e04315 examples/Erlang/wuserver.es\n85b417ed0eee07c66cc6b520997509d25b1d7aed examples/Racket/syncsub.rkt\n4baea52ccf44615160be18da5823e6bfb6ed566e examples/Clojure/spqueue.clj\n08754afb5e0bb5ce0016ba64faa3504e53dabd3b examples/Ruby/hwclient.rb\n1c71462cd6cc443abb7f53bfac2602486ea4ad6b examples/Java/Syncpub.java\n55f68d5fe3f08646069acf6eb0d253d5507371d0 examples/C++/lpserver.cpp\nf9dc879afb428151379e0d73e9b2f24e81015dda examples/Lua/mspoller.lua\nefd06bd3efcd72816bb803cc4a7e0ec99c5b0fab examples/Lua/psenvpub.lua\nb9451c87752d39c6e95cf1a1cf0a8346f0a0b868 examples/Java/spqueue.java\nb96fbbbbdc3046d60a282e68e4d27cb4d7877ac9 examples/Scala/hwserver.scala\n3fd28983dc9e7547a905e498f1c843b4d01f5d4a examples/Node.js/hwclient.js\n25418a9d043603f51f8942274a25d8cf6e455c08 examples/C/pathosub.c\nd4c299f39c8ebea3a07adc2572c4dd443a79b4a5 examples/Python/version.py\nb8d5f229f67f5e84437cb6c4a0ba3e93f4794cdc examples/Java/peering3.java\ne6e95cb491fff43298e3da024de5e61ca424fef4 examples/Java/mdclient.java\n06c93955952c996ebc4fffead2310203eee0ba5a images/fig13.txt\n38659557bcd2a0a16f437209b34276e763806d0d examples/Tcl/msreader.tcl\nef9136628f5af5723a2e29a702db5730c2602462 examples/Scala/version.scala\n6f356d1d98158e5ded441b702cca208aca02f052 examples/Haxe/wuclient.hx\n01c041010a97498a5d6054db0253c6e3f1c31609 examples/Haskell/psenvpub.hs\nde6b3e92d19b0e971bfd5eb3191e167d5329eea6 examples/C/udpping2.c\n758a6946554aac3b3321fde26e77637870c2d2a6 examples/C/mdbroker.c\n4c909b7b69fe8b6c9e25b5306b8540d4517b024b examples/Tcl/taskvent.tcl\ndd01999d445541312b4cc63e838392a6a09657b6 examples/Java/Identity.java\nebf331e82e58248bcd07768c40245dbb98588a4e examples/C/tripping.c\ncc2696aa9845e31fef32a2b920909ee8d4828f97 examples/F#/rrworker.fsx\n91540456fabe1388971f7bd15d99df1029869550 examples/C/flserver3.c\n0f105facc27b5e6e69c735577bc2e3b69a839f9f examples/C#/tripping.cs\n21045a8035a54064030364d694e249b9fcc5c209 examples/Tcl/clonecli2.tcl\n40c4e55793311176f393060e7ae85ef56c9c9ba3 examples/Java/Clonecli3.java\nb161619e056f0f52a24c2b20f62ac3aee039c9c8 examples/Java/pathosub.java\na9aaa1bbc4fcc045ca68181f0d6aeb83d6d08520 examples/Haxe/lbbroker2.hx\neb2cb9e9b9d6b4198dbe21c879a7aa34e049c243 examples/C/flcliapi.c\n5de8c49403652a90560157a1fbb38076e69655c5 examples/Node.js/syncsub.js\n051a5771f9fece84837c2948aa50fdf9e97452c6 examples/Q/mtrelay.q\n7fb8490751f5e11ede97b6ebd9bfa7de1e2b4c85 examples/Ruby/psenvpub.rb\n90239ee4bc59d992256c618dda028c16f55ebfd2 examples/Erlang/mspoller.es\nd9dac0c15b955107b7bb17045212eedc47a9a83b examples/F#/rrclient.fsx\n459b6cc9cb357f4606785d1c168a0bf628933436 examples/C#/version.cs\nbb19155e8ff8ccb952a772c9f8b46b129c736ed1 examples/Tcl/bstar.tcl\nc4893a4e3c2f4cdd6b158bfade025d1ab0583a4e images/fig59.txt\n9cba59d77e5bc58e54d2f31b46e03006fffecacd examples/Python/flcliapi.py\n380d06fdc0e1741e15485e8aa900bda0a873bb0a examples/Python/peering1.py\nfb48e0bae67b1862306797745204a0452bbc6c35 examples/C/flclient1.c\n94a7cd642aa97ff83b3af1e9694a4ee4e2f807b8 examples/C++/mspoller.cpp\n252e4246ac77c5f91d35a5f3a19a1cdc66e34198 examples/C#/ppworker.cs\nb521034fd7f591715362648b5ced1353eebb0b16 examples/Delphi/taskwork2.dpr\nb0e55c0d613a902727434237a2b90769f64e8713 examples/Lua/psenvsub.lua\n73ee4b49c4c999d28a0bb3578e172936195a1b3f examples/PHP/rtreq.php\n13276c6fe6faf8a91134745baa57c3a7c768f4e6 examples/Lua/peering1.lua\n4124da33a2604b47a34c0956e9529ac81c8d3335 examples/Java/Lvcache.java\nf9b721147fb33f01278b778ac89840ba9b26e2ae examples/Haskell/rrworker.hs\ncfb4edae479730927c81eeb5abfcc4f2194dcf79 examples/C/mdworker.c\n723817c7deb25c72a2728c3c986c67df2137d1d4 examples/Clojure/wuclient.clj\n921aeb5a7186f3732988cc06349cea5687e141c5 examples/Felix/version.flx\n662ee12aff93e09b3ef94b310c20a0b9977e603d examples/C++/interrupt.cpp\n51eb67ac717cb906b195b866a14495fc8763d09d examples/C/interface.c\n3104553d24dfdb1c56ac22af4fb6d84ac685927e examples/Go/tasksink2.go\nf276da91df65ba794fcd8889b5b63755df6a8c63 images/fig27.txt\n43f40086e8d86e16f6f24069f268e2b3fd7a81b2 examples/Go/lbbroker.go\n546d5cdc3e83417afad1b3cbd8d9f6039f1173c7 examples/C#/mtserver.cs\nc410d3af3592d2be77fc80aa4fbca11d3d45cb7e examples/Haxe/titanic.hx\nb31cbf444b37ae7cfc46451c09d792a85afd0546 examples/Go/rtreq.go\nfe82660cb9ec7f88119cfe65c5f224ad3ca8b9ee examples/Tcl/ppqueue.tcl\nf0da6a9cf7449e7a70dbc1cf49a058c6c9325348 examples/Perl/tasksink.pl\n4fd5b671fbf59b989eba6999daaf5040cbc9c97a images/fig46.txt\n7f92a00456d93edd4c7960ef7e25dc96f23e8a6b images/fig20.txt\n2d1f2ff484a788d1f3b9d7994ebe4d8e30a31361 examples/Java/clonecli6.java\n36cda5620755f602beba63badc3430177348e045 examples/Elixir/msgqueue.exs\n583d6a3192030d6249f46fb3abb55da557e1277f examples/Java/bstarcli.java\n55c61e8ddbc0557243f9607d86719104e5d5fa31 examples/Haskell/taskwork2.hs\n7984fc0f7d2de95df53ead4b5e5a47c820a4fa21 examples/Lua/interrupt.lua\nd56849079c6febe5435dc8e9d80efc6cd3bc0b57 examples/Tcl/psenvpub.tcl\n43cabd49b3cc80d4b7f062b21f0c683c43ae1304 examples/C#/rtreq.cs\n5e53f164abf421c2006fa3a693d0e89f4bf70701 examples/PHP/rrclient.php\n5bec284770a7b1b4194888193b4ecbffaad48e86 examples/Ruby/version.rb\n3e031c7e12aa6cfff05976e0a2e00899a452ce98 examples/Racket/rrclient.rkt\ne38cf7594895740e4a0c0eea7393185477c31287 examples/C/rrbroker.c\ne30bb9c17138a5525355a9cf108e8497e4fd6c26 examples/Tcl/mdcliapi.tcl\n2d5cc4ed4a4c24667e68e6dd1e61598d3d430ba2 examples/Python/psenvpub.py\ncc48e8f883913e278b07212dab4d45f9b4c5bc17 examples/Java/udpping1.java\n682ea396cbc1b90a4008422e98768f6b6a44f560 examples/Clojure/lbbroker.clj\n78a06c0b8f7d02d0e076bff3dc7e89b742f18848 examples/Haxe/wuserver.hx\n1aee9d4150be5dbf04cc97cc807d8c7d5f5acd51 examples/Ruby/rrworker.rb\needfc0785e908f374ae33bb5201a19ffa5af2024 examples/Perl/wuserver.pl\nf0a36dcfb514055163abeb5c186348d489ab80e0 examples/C++/version.cpp\n1f4a2b21732d633e38a14bef05202b95e4af30d7 examples/Ruby/tasksink.rb\n258672c43e95c9fe8f5fb4bc82c170f297e82966 examples/C#/flclient3.cs\na0f206b68544e1567e09962c50664e82e065be43 examples/Tcl/titanic.tcl\n66c18b7c9301454706948a48eecb1110de6b8c4f examples/Objective-C/tasksink.m\nb92770732a672d489c3f17d75192e9b09b9d4e79 examples/Haskell/rtdealer.hs\n34678bc191ec33d0bc9c55fe317c90d721873071 examples/Java/wuserver.java\nd487010bf7f60b53184d507f60d47b358801ba8e examples/Go/identity.go\nabb8ce37b7d3a289074f71f803b65ae28f9829f8 examples/Tcl/clonesrv4.tcl\nf17a8ccad9917b4a854460ec01b9480a6f12ab2b examples/Q/hwserver.q\n90d7d3452a8a54df93657c90ce37a830ae6224ef examples/Perl/psenvpub.pl\nbffd7cc265e72f1a7644c0e401ab8774c007f467 examples/Delphi/wuproxy.dpr\ncf1096819739109978750503e0e9525b0585aedb examples/Java/Version.java\n74387f93dc93535ea14e4f4bd1638240572976a1 examples/C++/taskwork.cpp\ne07b2d3b69f6a6c88f4f121467d751d471d7db7b examples/Java/mmiecho.java\n166c1e57fa6caff39be3afb36b0787db7f519f7a examples/Java/Titanic.java\n628203f68759322dbc36e87effb0732bec1aba34 examples/Go/mdwrkapi.go\n65621f3c0823e6234264623258c14f2a749cdc0e examples/Node.js/tasksink.js\n81fa719a69bfd49a2906759b8f3342787416f061 examples/Perl/lbbroker.pl\n2e2597cdb67625c3605417fc9b251f98309d9cc8 examples/F#/mtrelay.fsx\n804945b7d2e9e3d68cf930abb21bbea39c76a8a1 examples/C++/syncpub.cpp\n85b5419e79f1ef9186cee3fbb84853e20d71a54d examples/Java/Flclient2.java\n777a8a48b02160dbedf8dde303811ac50bdf9b4b examples/C#/eagain.cs\n8064b2bd86ad59b24a6c88e8deec196283650d64 examples/Haskell/rtreq.hs\nda43f33ebf0ca745a53e5aea79f4ba404f5987d7 examples/Java/mtserver.java\n3d8b85139a4008916796dd8235de4b90cd09f6fb examples/CL/hwserver.lisp\nddbfb0c0c4632683952075a4028a609a06afb3a7 examples/Delphi/psenvpub.dpr\n786897c8ebde59b10088dde8d437d285073d9cbb examples/Erlang/interrupt.es\nd4b641143e21da83f61c9ce702f2d3ed2b3c30ec examples/C#/ticlient.cs\n22f6e9ef446f2c442299d046532b51b749736444 examples/C#/rrclient.cs\nbb8a364dafa13cc58fb7beea5660706604fd9bd6 fragments/C/mdclient-async.c\n6b79cd33c353e0c22d6a660b3edcc0861f4de43f examples/Java/Msreader.java\nfc71f2ea8e007f02e1e0199cad988076e27f88d8 examples/Go/spworker.go\n1e57bb46cc6483e97c5007a9a6f8eb34ff800fd3 examples/Haxe/spqueue.hx\n8aa4b0bcbf4a6ad58ccff0bbb23dcc556cd748e2 examples/Scala/tasksink.scala\n00ddf2f67043f4dec7330b26534126761f4d4a8d examples/Perl/mtrelay.pl\n0324863d873bbe0f6830c7e39f07684109ff9e1a examples/Java/Tasksink.java\n2c92b992bc7fc3b9e6a2390ba2ceb8383f93e14b examples/Ruby/lbbroker.rb\n325a47f4e2d7512a975a33418fc4b0877b1757db examples/Erlang/lbbroker.es\n750c4b192983d7255cb344f1dbdef4e1c206ff77 fragments/C/connect-command.c\n96e0642210a536e841a2b8caf350354f5c2557e1 examples/Tcl/rrbroker.tcl\n56cb8b5ccbe3d89d2512b9945a2f0aa0b51d9b73 examples/C#/rrworker.cs\nf489620e9bb5cfbfe4ac5615d68ff3c4738b0d92 examples/C/rrworker.c\n7bd3e7bec716f58b445c5aa362487cb561ac8197 examples/Scala/interrupt.scala\n014919f68d6ec5a501157ef55a2dc4b2fe1c4110 examples/Tcl/bstarcli.tcl\nf4af00be91271b9272102f6785d9dd8696e64ca2 examples/Python/clonesrv5.py\nf7c91c878219506f2b817fe8cb593d11c61b699e examples/Tcl/kvmsg.tcl\n7927b14bf1a77676a81431ade47db6244ce0e5d7 examples/Delphi/lpserver.dpr\n2d0d39e83a4aedbb0a2636d1f1af339a13ff0b5d examples/Tcl/wuproxy.tcl\n233d80259bb25d4a5733cdf80984353b3193ebbb examples/Java/Flcliapi.java\n8801069611ff33d5395e7effe72e85e7bd33d482 examples/Java/clonecli2.java\naf90ec601fc420125f15f9f490e1691990907d86 examples/Delphi/peering3.dpr\nc1222e20eae6005cbb9bbda228bd6a1dc2bf5fe9 images/fig38.txt\n35f0f5b397ddec7b54708bac0d4beae3253e5be2 examples/F#/mtserver.fsx\n78cea4c633ad9d85ac5f1669fde10bdd5e024de7 fragments/C/filemq-connect.c\nf2f7ccc5e65d3b35bac5814196c4c832e4f74c1f examples/Python/mdcliapi2.py\nafb8244ec12f926f56eeac5c3bee868b982464c1 examples/Go/peering1.go\n7e7f6b3b819cebfe48cbeb79aaaa0200e9c1ce0f examples/Java/flclient2.java\n3091466db64aaca3410b5ff12c86a0718ca012ea examples/Scala/rrclient.scala\ne4544fc8ae8d4ae60b65d8ff5b70bb6b30bf77b5 examples/C/spqueue.c\n0a1e42de46d8743c85841046ba87592f9ceca5a0 examples/Go/mmiecho.go\nc4f77206176aa5521161c1c3339f9721544386a1 examples/Lua/spworker.lua\n9eef260e88d3e49278f6fa792e2ad5dc5dd0dc89 examples/Haskell/asyncsrv.hs\ne09770716d02317767d31be123858109e2423d97 examples/Scala/mtrelay.scala\n0e3e1d307e331dbe392309b02c1230c9779c70c6 examples/C/rtreq.c\n2b2df695fcc86d71a8c0ea56bbe7a43d71ca7b65 examples/PHP/flserver2.php\nf46d84d67c783fdfdc1c89d25b784b0c14912c2c examples/Haskell/tasksink.hs\n72f0ab41ac23d1f977d5d2b3f9aa6f0bcd5678b0 examples/Tcl/wuserver.tcl\n02aa9702398835ce4a90d1a32bc8c447bf3cdcbd examples/Java/Pathosub.java\n8dc30d63dc3bf9792aab68d299a322ee0966403d examples/F#/psenvsub.fsx\n2d39db83ecbfc17e5777d8d2fc4c902dc5ce14c1 examples/C#/tasksink.cs\n063d1d7efef3fa058deb17a238185470712903d9 examples/Ruby/wuproxy.rb\n0a47c27d1122cf9c966510be8773e1e45a50e129 examples/PHP/peering2.php\nb23138dc4864efe5088034fc784a958432c4f327 examples/Go/version.go\n78359f01efad3d3ff3efed9f286849ad945ea5fb examples/C#/msgqueue.cs\n47169b7effb428d5bc83019443f9c85aed6e476c examples/Haskell/peering1.hs\n3d3b810f90a9d3b7e051b6ea63c4b322376a16f9 examples/Clojure/msgqueue.clj\n23227ea1b8a2c71cdb9f8eaba5a1e37e5f61db10 examples/Java/Flserver2.java\n0c98273d235a4fc13e2597b64afe6268f914fd6e examples/Ruby/mtserver.rb\nb34b2c8e02016b6b06fc86b29ffac4d3c634a789 examples/Tcl/rrworker.tcl\n60d0c25ccd5c071a454fd5e0c28eb9d582fe1c5a examples/Python/lvcache.py\nb09185c1f969dd40e5970a6ffdfe103ac6c2224b examples/PHP/spworker.php\n918feb4c76b89464b69800eb33be1332de16d65b examples/Perl/taskvent.pl\nb18bfe2c3a7590d8e8b36dbf7e0f2ecec13713e7 examples/Go/psenvpub.go\n6d8ce13a7bf05f7ad52f2fccb3168da0d4f8915c examples/C/fileio2.c\n58663eefcd97dc45e865bb368818f7f33684b063 examples/C#/hwclient.cs\n7b4d708320e083cf52ec8a1b352e16b31dcc9efd examples/Java/Psenvsub.java\neefcaeda5b5089925bf063a4c438ca8c681f881f examples/Python/syncpub.py\n85dc5c6a675c64952068e60bdc287c2a5777dabe examples/Java/bstarsrv2.java\n0164322fc2f9cf78075d27f1483889a207a7f48b examples/Ruby/lvcache.rb\n2c120a122557047b369588687c8617331a446e54 examples/Ruby/syncpub.rb\n2a06aec1122afde677cba5398254c3dde3592169 examples/Node.js/identity.js\n356e568c343e9ac7502c2acddd1dbc86a50777cd examples/PHP/taskvent.php\n7d66598a80398e4cfe74ca05247112d96821bc94 examples/Elixir/mtrelay.exs\n77f664273f6d15ac5266034b2ca06b4dd72c872d examples/C#/flclient1.cs\n63353b489713214251eeb0752b13151be67c53c1 examples/C++/lvcache.cpp\nce1b0ff8570cfaccf4da8d1616efa7a9832691c0 examples/Erlang/tasksink2.es\nb286005dff4cc6930d42379017f6c45e8ede9a1b examples/C#/taskvent.cs\n0a09709cb0f70a54906cae69a710a1a82f9df360 examples/Lua/peering3.lua\n2962fe940bac9cafea678af9b3be22d1e13d9062 images/fig39.txt\na428787953c2cd01ef622011b3135e80082d18ab examples/Java/kvmsg.java\nfac1a99357d1f4a909df0a1b729831f053782955 examples/Delphi/mtrelay.dpr\n94ddfbd85c7df344b099863bd25d7f5212747c86 examples/Tcl/identity.tcl\n2e50c5373588182d2aada26edd7cf9aacffc3d9d examples/Java/Msgqueue.java\na637555966486970246f849cf536b0d6dd1afb65 examples/Delphi/syncpub.dpr\n3ae23360e41e190e1d55fb656fca0fda8f22877d examples/Node.js/rtreq.js\n1ca069bacbf49b3d30303f9bf8f1abf62195b9f7 examples/F#/wuclient.fsx\n49267c7cdd989e1d94fc037b77efdcfb0e9ce8a1 examples/C++/lbbroker2.cpp\nbd737c0e81f3c78792359c055f56d20d89126da1 examples/Python/flserver2.py\n86f96e5b18e101004c902ba2a8db33c307b11bc4 examples/Python/kvmsg.py\naa0b63ac85f2f0d2a47453de004da54b6e35c0b1 examples/Lua/rrclient.lua\n880a97667e3465a2dced8dbde99c9f71c8ac9c53 examples/Tcl/ppworker.tcl\nd8582e3fb3e2f71c88c178f7de1637eeb9fb6f39 examples/F#/mspoller.fsx\n4af311808112a5120e831860d11c26b2557c0753 examples/Python/wuserver.py\nee9a1c94b5f978f6592c468aa0d6caedc7f827d3 examples/Tcl/wuclient.tcl\na3c78d15e03ff754a35ad2d4d9c5129bd6e0781b examples/Erlang/syncsub.es\n3851d5691287c49ff72ab77c11ba8bd55b0ab91b examples/Java/lpclient.java\n70b335b807ca7bf9ffd8cff13effa7af5e2ec636 examples/CL/taskwork2.lisp\n03f92c355e10b3464c75e9c3b201c21ea6ec681c examples/Ruby/mdcliapi2.rb\nc2e5818c670b5999a3a1de96b1080932df2ec612 examples/Felix/wuclient.flx\n407c9e54301603080960119e2a7711dbc4d49d40 examples/Node.js/taskwork.js\n6c00b6105deaf40e891c5ebeb6d3aabd184ae79f examples/CL/mtserver.lisp\n87db816b76e8d5d1f8f10e8e055981e78e6c5794 examples/C++/hwserver.cpp\naf3d72a3dd615769775249428cb4326cd626fdf8 fragments/C/zyre-listener.c\n8085ca1c76460428ee1dd6b12ec7b78de15d1239 examples/Haxe/ticlient.hx\n0b372b995a3eec3e53801435e0aca8ec791b3efb examples/C#/tasksink2.cs\n8a8dafaeb5cab2b99ec9ef857a77d5d575a7c242 examples/Perl/msreader.pl\n8084a0619a5dbdb924f2c87c306f2cf8b72ae328 examples/Python/fileio3.py\na95fd317406de85b7259e01c567dfade59f2e725 images/fig9.txt\n3c5cedb98d387f39b69653e517092b3a8e83efd3 examples/Perl/taskwork.pl\ncc60a0090360f79ce04636c4b68ef084d3401db7 examples/Haskell/interrupt.hs\n2e3854d5063437c62d8f72a45540b1029659d7ce examples/Java/titanic.java\ned2b28f8cee287285490912a4f9a05c0b8090a3d examples/C/psenvsub.c\n53735e3764293bf48c438f830e461d55c22be831 examples/Tcl/asyncsrv.tcl\n0ee5c237dde2dcf6b20c4fc30bb8ecf38a8d3699 examples/Ruby/bstarsrv.rb\nf09e9cd4fc4706a3280fd87ab691bc716d55afc7 examples/Node.js/wuclient.js\n717c8a25e9c645b0bab80ba01589371690be3948 examples/CL/syncsub.lisp\ndde99606c4d27135205a9adb6df695b721fa2de3 examples/Clojure/tasksink.clj\na09c94918961aca7865d81091f1c13d68128feba images/fig14.txt\nb55d6909f384e41673a0ac08c2fc383af38378d3 examples/Haxe/tasksink2.hx\n0059f7f429f9c372acfe715a50ba9856ff24b7ee examples/C++/psenvsub.cpp\n6e380b8ab0c1328367eebb09ca8898061300ea0c examples/Scala/taskvent.scala\n74301d9bd007aea5b878240b996fa5cb24a71386 examples/Java/Rrclient.java\n45e372bbd69237f77bda4cd8ebfcb6b322624993 examples/Tcl/lpclient.tcl\nbd4328049776eabf4b132c10edffa149df76d74b examples/Racket/hwserver.rkt\nbfe7df58c003c3ed2a1d6a028bc2838c440f125b examples/Java/eagain.java\nd87aaf766aa463af25f9eeaeb14e1b9aaeebfda3 examples/C/flserver2.c\n664e3b3bf37343cf25fc9493c08ea0ecbea96238 examples/CL/rrworker.lisp\nf7665b3c745137d93f01bec00c1f3cd5ada9777e examples/Lua/wuproxy.lua\n36e5cfa4e087534ee2b5210a84da17590e34546e examples/Haxe/taskwork2.hx\n28474bb198d026945549367392cb382d93ea5f43 examples/Tcl/tasksink.tcl\n3b2db9bd992b5e49e27787ec012a518b71f194b6 examples/Node.js/tasksink2.js\n6f500d37d0b8af5b8f70193b8963bb0e20d12ac1 examples/Felix/mspoller.flx\nab0a2a2e4104987e4f51ad3fe9edd0754fbcbf1d examples/Haxe/bstarcli.hx\n525134463432ced524d2093c4d278c57a4710727 examples/Delphi/wuserver.dpr\n9d2a87bf53a4d8cef8b553f6d3860a0ac492634c examples/Objective-C/version.m\n184649a1557b9586718d7ef315368c87ce124d1f examples/Haxe/hwclient.hx\n97b20381222ce64ee6528b9dbbd8337d8dab6cc2 examples/Java/taskwork2.java\n963470419d7c957b98e8bfa7800713c8a663dce0 listings/C/listing_3.c\n90c96bfd1e30968d85624f75d7bb774b863dcffa examples/Haxe/tasksink.hx\n87171fa82828d9cc6d211235ede21b0ee6f22aea fragments/C/iothreads.c\nac462c00c097d23fb0efebabc2c05e24b1fa0046 examples/Haskell/peering3.hs\ncb990ae7c17f286112b5bf854fdff34bd1928f1b examples/Scala/lbbroker.scala\n3b6d4525a42e93a330e3477340822168b4ca8f75 examples/Python/flclient2.py\n92c09035e4623e735643f4cfc0d853bf192b045c examples/Java/Hwclient.java\nc0a19e0d8f3e2be217d2b7273cd21d7d6409475b examples/Python/ppqueue.py\n3fd97708e044d54e71873466f219e083a237cf3b examples/Python/peering2.py\n053955c7a5da4b42a85be15633670cf3942e530c examples/Python/clonesrv2.py\n670708b0fbae6ffef28f048eaa69722da95cbe72 examples/Tcl/taskwork2.tcl\n254d74723d839130f38073b4248aeaef0d512b94 examples/PHP/ticlient.php\n14c06c54cecfed468cef5fd0d28d13113013be02 examples/Haskell/taskvent.hs\n349bffb8204fc8609fc492e471ed368fd97732ac examples/Ruby/ticlient.rb\n68a079d5cec3a6fc371963f9e20db19636eafbaf examples/Node.js/psenvsub.js\n5c700dee38dbaace61adb7b81ad24cfc67b93ebb examples/Python/udpping2.py\nfb790e1ea404b1aa3022cbde8d88477ea31b9435 examples/PHP/ppworker.php\nf0ff7dee1e32c853b89e57e1868696ad480ac846 examples/F#/hwserver.fsx\na6d48d55891f0c36ee0cdc3207801c0871383ee6 examples/C++/ppqueue.cpp\nd16d9deb056a39d66f98a1b669a017edd2ad4c9c examples/Python/bstarsrv.py\nfe7eb2506f5e793e2acdc9d6d2e605623c87dfc6 examples/Tcl/clonesrv2.tcl\nb20eef22a2eb404f50a16ab964312d02e98e582c examples/Lua/msreader.lua\nacf30149127fac9ca2c198a2f5569406f46d05c8 examples/Tcl/clonecli1.tcl\nbb18896e4f319f76c6c8998398c1457f908b2069 images/fig18.txt\n7d7616b7442f351c698232f31637f163ca580916 examples/Ruby/rrclient.rb\n03e21f2d6542a348e8b87a7b036d4189cc0e6125 examples/Lua/rtdealer.lua\nb0b44e140da9109eba6721be274cfa9dbe6398ef examples/Tcl/flserver2.tcl\n3b563bd23414326005fdb193d7b9a454a0d185c3 examples/Java/Mspoller.java\nd2b84013543f0c5cecd8c40e1c96df54866145da examples/Tcl/clonecli4.tcl\n118f298f2946cb1f42be47ba69b76462f5a0e8d6 examples/Go/peering3.go\n7ee59cbdada85a613ed060f9eaf7f33519dbdab0 examples/C#/mdcliapi.cs\n052d80eac38a42f8a9deb0ab42a3d5c18011cde1 examples/Java/Clonecli1.java\n6c4e9dc79171984aa8bf05e856ef36af460d63ba examples/C/msreader.c\n565f16fc3228837d97457efd994c5a5cabad1180 examples/Node.js/msgqueue.js\na00d1e38d216e70ae718f479ce56ed6e2248340a examples/Java/Psenvpub.java\n3dce90835a28094cb8a6f60ebb24f41542ea6449 examples/PHP/spqueue.php\n05cee87881deb0470871ee37c3c28f79848d8667 examples/C++/msreader.cpp\n08e331390a51964ee1232291b99fe34ff3d41aeb examples/C++/mdclient2.cpp\n10bd7d03eb4e79762bd58819f6de596ba9c50768 examples/Python/clonesrv6.py\ne50f04b94451b3726bad9f8c5061c2346e996c41 examples/Python/mdwrkapi.py\n9d21afbe047df83cf028ee33e786bd65f53a526d examples/C/espresso.c\nc4557a45b722f7431dfebe1bcc3d3e488602458d examples/Python/fileio2.py\ne1efb9be0af2f0f32eacaf861f12c2f00ac8c6f3 examples/C#/syncpub.cs\n966fd89e463f52e05b95643c706b2721aa17a7e5 examples/Scala/lbbroker2.scala\n1c9b61b978f7b4866badc0624dc864c867637f91 examples/Elixir/hwserver.exs\n9a3a70bf4c47959bb07032ad2f7b1f1ef94daef0 examples/Elixir/syncsub.exs\n9444216473ef93064be5d771cb02a2ea280627a0 examples/C#/wuserver.cs\n3313d1812d89d2320fb5268750f79a415b06dec7 examples/C/clone.c\neb6539677dd65479a42f6ed8b67a1e6b42b4c2aa examples/Haskell/taskwork.hs\n7339fd5a192f4b4e26ad1a34a5e2b68720463159 examples/Clojure/asyncsrv.clj\n3f474e8a34285335c5de2f7a5f75bc6ca2cda93e examples/Python/asyncsrv.py\n3260382f919c5b9bb57e6c9c9033cb5a5aa280cf examples/C/mdclient2.c\nf25e14b3c9eb49df377b95dc6402cf05cee7b3cd examples/Java/Bstarsrv2.java\nca4d78f6b48d8bde06d7d685c977df0009702837 examples/Ruby/rtreq.rb\nede3eb3fee0360425dd960bf6b29157981b53b87 examples/PHP/rtdealer.php\na8c83e9c57ea37977b002b40dbad5056145592d2 examples/Java/ppworker.java\n6cdd40de05599e4bf2d066aa232cb054f8129ba6 examples/Ruby/mmiecho.rb\n96c7718feb254cf09dc2030fa13142e5e66f07fd examples/C/lvcache.c\nbe92bf332cf997e801a2cf84c9edbee9b509e0d9 examples/Python/mdclient2.py\n657e020ac3b90e2de25858497d6e3ae5a4095662 examples/Java/clonesrv4.java\n0507a537f464bd77ce04e4eed6d102ce2a752492 examples/Clojure/mtrelay.clj\n4e83709e78f4563e4a96e85441c7469642684f64 examples/C#/mdcliapi2.cs\n2bb6b83b15db9e14b77ec13e74b35336e34284ee examples/Python/tripping.py\n8f74fafe26d24e942273d113e48df557be712885 examples/Haxe/taskwork.hx\n7a2457de72416fa3d44371b5fdd9c6bf38f2e0ba examples/Haxe/psenvsub.hx\n7ebb282a75957fa83f7bf90b37d45058b432e28f examples/Java/interface.java\n4f6b02addf92602f48cec666d6ad781107005587 examples/Objective-C/wuserver.m\ne584abff170270462fe88f96e6499b1933409db4 examples/Java/Kvmsg.java\n618a143731b5c0d0cc7923fbe79708bf503d5df5 examples/Java/Ppworker.java\n4bafea7d78460d31f291341e95a133755f82a67c examples/C/lbbroker2.c\n70315103d72c47fabda26f824fdfa9f0e03507c4 examples/F#/version.fsx\na64321fd57eb6457d6b022f4cd500224ddd39cfe examples/Q/hwclient.q\nc9aa1cea8ad4b225bfaeaae56d2388db2a4bbe13 listings/Lua/listing_53.lua\n8b68729b25a0e4a746be73f74f27938ef73ab6b4 examples/Java/Bstarsrv.java\n8f8986abfc39b91a8e2c5d020560cd2890d4c759 examples/CL/wuserver.lisp\n912dcd6d50b2de75fc73a2b9558c24264cb3e0f4 examples/Felix/msreader.flx\nce11487c92b25457062d16cfa03aaee428dadc96 examples/Tcl/flclient1.tcl\nc9281b3b9599454bd01a7bd6b0df4ba89ab9456a examples/Java/hwserver.java\n37fc9d8f2938be653e487a829fc1884d62a94e7c examples/Go/lpserver.go\n9d0232b308be91b5b762987d563d7b516ff3f0b0 examples/Node.js/psenvpub.js\n2f4fd01e3b5ea68f3441672498b9baaeaa18b554 examples/Racket/rrworker.rkt\n4397bdcd9547fd9c9572d105a0651a592ed78c71 fragments/C/highreader.c\n540caca4f597470e28ee3cb6f7d77437f3a8366b examples/C/flclient2.c\n62b4e9d04c2e79e9795dc6448a6428d3d522615a examples/C/msgqueue.c\n0024258b385c22bf6947af35cd566711fad78dad examples/Java/Clonesrv3.java\n9b177699c79b45447c15aa2c9f0baada6b1999ed examples/Racket/hwclient.rkt\n772bd7feaf1afbff0a49417803abb51f8c08ea71 fragments/C/killsignal.c\nda0678d5e95eb79bce037b5a942a21a7e5ad5e67 examples/Felix/hwclient.flx\n5749da0d2c7a5e101cdbf5c20a9fc785c4715663 examples/Lua/asyncsrv.lua\n9a0a0a6e468becc7ecd99851272d72c7a25163b6 examples/Clojure/rrclient.clj\n83557ec3aa4356b306f5b35dfd3478e236843fb4 examples/Python/clonecli4.py\na50b0e757917f8e148936f34ab5ff239fc12b276 examples/Elixir/lbbroker.exs\nf74b26d45017a2d40ca198d077031051c32f9c4d examples/C#/espresso.cs\nf992eba1939c3056bd1420c9ab03528dc19c3c9e examples/C#/wuproxy.cs\n3326cb58bac4c4f1984e8270de0b27cd73789088 examples/C/asyncsrv.c\n223024a5402ade184eddf55db02bbe15bc8bfb4f examples/CL/mspoller.lisp\nc32b5e8add2a6b43051447608042c14689a56dc7 examples/Clojure/hwclient.clj\nec847d09a3e116def0b9b75dd156a48852a3e740 examples/Java/syncpub.java\nf1eb864e45ca2e730cc6e7e56296c33b703f7c5b examples/Clojure/lpclient.clj\n513d70335b439f1342b902355ebd375cf09d3637 listings/C/listing_1.c\n8de96d7c83874341df47af49192b5720fdfcd194 examples/F#/tasksink2.fsx\n43c45b47bb915086d91e4bf83b0de97fce61bb76 examples/Java/rrworker.java\nd6ede4eb947bde09909c51c13f7dcab48baf2da1 examples/Perl/tasksink2.pl\nf4ebef67f78def23c465213177901fa35ea12823 examples/PHP/mtserver.php\nbe8a8b974f0502d05740e83b0607a4025d58d914 examples/C/bstar.c\ne45acbb3cdc6b0b38765d7161eeba598e6c67799 examples/Python/mdcliapi.py\na0752a9cd1cecea192f96b3731e3871a2bce40b0 examples/Lua/mtserver.lua\n8b7bdd78f4020234073531a92538e27ee6aa49b9 examples/Erlang/version.es\nc1e4cb30a6bf2e910dc706bda0e935e448ab3b4b listings/C/listing_7.c\n47c969a03583bcee7f23cde6563cc5d468e21356 examples/Python/lbbroker2.py\ndab6b84c5feee87a09ace593567e148b3141eccd examples/Lua/wuserver.lua\n0ce0fbbb4b6bfa326d7aa2cbb9bf3ddbcdd3210e examples/Java/Mdwrkapi.java\nc74db724c2d76fe0eeb06980d2dcfc56ff935079 images/fig53.txt\n9359b58ae32f30dd5969a034b9758a6e5b1062ce examples/Erlang/identity.es\n66fa7c4c03bd9550224f93b72ecc9dcce3cbd9f7 examples/Perl/lpclient.pl\n4a39ab9dcffe45ee068128e8bb2b79071c654c70 images/fig34.txt\nc53660f1a5ff1265eba286b3aaa298124eabf4dd examples/Python/mmiecho.py\n0d14895fa0f090d8725de23e24f9ec80d7fb2fe1 examples/Go/mtrelay.go\n078603055d1ed7ee51eae678e245b581327563e6 examples/Erlang/hwserver.es\n946313d5ee2fd52bdb68c9d680037b1e6c0f82e3 examples/Go/taskwork.go\nebce2615a33afe2b3712c46056a2636a085777ff examples/Java/espresso.java\n88ea5b797aaec82328f17a29750f0453e449c856 examples/C#/ppqueue.cs\nbf7dca281e272216c02b175c314c6c6c2d3829b1 examples/C/wuproxy.c\n40cd594a92cfd975f93c4b49281ce1726365a361 images/fig19.txt\n7d203c73e3266709566a8204bb19bfd83d407d34 examples/Python/interrupt.py\n25bd0f108f2a3a3b61cba7d8d968b39306c63eba examples/Java/Suisnail.java\n675871c632fd5028ab98f44f9ec14d9d7d53530c examples/Python/espresso.py\n5f2ef1d0e9b906dc41082d21437e27dc07e15266 examples/PHP/psenvpub.php\n1ef2d9f02fa71fae5837dcf2dd4d6abe60cd0df0 examples/Ruby/syncsub.rb\ne2c1e7fec539abd99dea0b9117506d8a7c353e21 examples/Java/spworker.java\nd67f9d486521c36c3be880408041c2f67a124d57 examples/PHP/peering1.php\nfb142caac74aca22f5e3d37fbc1472c73bc7f011 fragments/C/sendmore.c\n454aaf49cf11eb196137db4b526ade21a29b9678 examples/PHP/rrworker.php\n5424213fd099dff80a0ef2af899414d44cdde7ab examples/Lua/flserver3.lua\n33b9df8314d8e964a5ccdfd3adcfbe94afb7e68d examples/Tcl/clonesrv1.tcl\nc03b2f9fc1cd7bdb870028cff8a2f10406330a03 examples/Java/Ppqueue.java\n91f166400d7fad4e70bd2a92187037ea6dcfb23a examples/Elixir/rtdealer.exs\n21acacc65a73df2ac098f8a215bf68887d22c3c2 examples/C#/rrbroker.cs\n7acd052749b75afbf8dc1bcc6307598c842d5762 fragments/C/zyre-peer-disconnect.c\n2c76d6025104bb5962ad110e2026e63c4319b02b examples/Java/Mdbroker.java\n73b605b59ab67e24f5bdf894012ac409ab4d7cbd fragments/C/fmq-server-methods.c\nebde87f6fb5be32c48a9dd94ba7a40b82496b294 examples/Delphi/rtreq.dpr\n14cd35c4c95a9da984384b0ce67b1d1ffbfb9eb3 examples/Haskell/mdclient.hs\n6e5443998a6fa4b03e430fbee338825b2eca0a6e examples/Java/Mdworker.java\n1e3f4efadd93de801c25c5ae8a0d2cd51fd96834 examples/Python/clonecli3.py\n073a42ebad1b366801557f2eb0285f87943d153c examples/Haxe/mtrelay.hx\ncc48e8f883913e278b07212dab4d45f9b4c5bc17 examples/Java/Udpping1.java\n3cc56e09576313028939f15b8f663d5f55830b95 examples/Java/dechat.java\n79b96c22822e604f261fce908affa1ac2609662d examples/Java/rtdealer.java\n5e6cdb16402ca8b761d291544b0641006f754d03 examples/Lua/tripping.lua\n15807412876d207a7b744b378ec0d830c05e8c92 examples/Tcl/msgqueue.tcl\n80fa778b782013d5858483c6bbc60cac5ac02e2f examples/Tcl/mdclient2.tcl\n"
        },
        {
          "name": ".travis.yml",
          "type": "blob",
          "size": 0.71484375,
          "content": "sudo: false\naddons:\n  apt:\n    packages:\n    - dblatex\n    - dbtoepub\n    - ditaa\n    - doc-base\n    - docbook\n    - docbook-dsssl\n    - docbook-utils\n    - docbook-xml\n    - docbook-xsl\n    - docbook2odf\n    - ghostscript\n    - libbatik-java\n    - pstoedit\n    - python-pygments\nnotifications:\n  email: false\nscript:\n- \"./examples/build all\"\n- export PATH=$PATH:./bin/asciitosvg/\n- if [ \"$TRAVIS_PULL_REQUEST\" = \"false\" ]; then bash ./bin/buildguide; fi\n- if [ \"$TRAVIS_PULL_REQUEST\" = \"false\" ]; then bash ./bin/buildpdfs; fi\nenv:\n  global:\n    - secure: \"IT/2HxHCMwKukSlkv9b2b9J+5YtSM1xmVW0K4eMbnbDICiFHYNXvaVxqzE/rQ7MGNgFiwnwixix+2nbBSOpB2ZqnUeGWdTsxtAuBm+FJ7aXRPZ6vr/q/5VhiXa21WB6U7hqTwAwrWZDhEZFoatAApWEhAj/q5399QzAxD+2Mi9M=\"\n"
        },
        {
          "name": "CONTRIBUTORS",
          "type": "blob",
          "size": 4.8916015625,
          "content": "Contributors of Examples\n------------------------\n\nPieter Hintjens <ph@imatix.com> (C, Python)\nMartin Sustrik <sutrik@imatix.com> (C++)\nOlivier Chamoux <olive.mail@gmx.fr> (C++)\nNaveen Chawla <naveen.chwl@gmail.com> (Java)\nNicola Peduzzi <thenikso@gmail.com> (Java)\nIsa Hekmatizadeh <esa.hekmat@gmail.com> (Java)\nHunter Ford <hunterford@gmail.com> (Python)\nMike Castleman <m@mlcastle.net> (Ruby)\nBrian Dorsey <briandorsey@gmail.com> (Python)\nRandy Dryburgh <me@rwd.im> (C#)\nEric Desgranges <eric@vcardprocessor.com> (C#)\nKamil Shakirov <kamils80@gmail.com> (Common Lisp, C, C++)\nBill Desmarais <bill@witsaid.com> (Ruby)\nPiero Cornice <piero.cornice@gmail.com> (Python)\nJohn Unwin <john@kaitrade.com> (C#)\nAlec Thomas <alec@swapoff.org> (Go)\nJay McCarthy <jay.mccarthy@gmail.com> (Racket)\nJeremy Avnet <spork-zmq@theory.org> (Python)\nLev Givon <lev@columbia.edu> (Python)\nMichael Compton <michael.compton@littleedge.co.uk> (C#)\nKamil Kisiel <kamil@kamilkisiel.net> (Python)\nMark Kharitonov <Mark.Kharitonov@shunra.co.il>\nGuillaume Aubert <guillaume.aubert@gmail.com> (Python)\nIan Barber <ian.barber@gmail.com> (PHP)\nMike Sheridan <mike@westforkconsulting.com> (C#)\nFaruk Akgul <faakgul@gmail.com> (Java)\nOleg Sidorov <i4pcbr@gmail.com> (Ruby)\nLev Givon <lev@columbia.edu> (Python)\nAllister MacLeod <allister.macleod@gmail.com> (Java)\nAlexander D'Archangel <darksuji@gmail.com> (Perl)\nHoelzlwimmer Andreas <Andreas.Hoelzlwimmer@fh-hagenberg.at> (C++)\nHan Holl <han.holl@pobox.com> (Ruby)\nRobert G. Jakabosky <bobby@sharedrealm.com> (Lua)\nFelipe Cruz <felipecruz@loogica.net> (Python)\nMarcus McCurdy <marcus.mccurdy@gmail.com> (Java)\nMikhail Kulemin <mihkulemin@gmail.com> (Erlang)\nDr. Gergő Érdi <gergo@erdi.hu> (Haskell)\nPavel Zhukov <pavel@zhukoff.net> (Ada)\nAlexander Else <aelse@else.id.au> (perl)\nGiovanni Ruggiero <giovanni.ruggiero@gmail.com> (Scala)\nRick \"Technoweenie\" <technoweenie+contact@gmail.com> (Node.js)\nZed Shaw <zedshaw@zedshaw.com> (Text)\nDaniel Lundin <dln@eintr.org> (Python)\nDave Hoover <dave.hoover@gmail.com> (Ruby)\nSimon Jefford <@simonj> (Go)\nBenjamin Peterson <benjamin@python.org>\nJustin Case <justin@playelite.com> (Ruby)\nDevon Weller <dweller@devonweller.com> (PHP)\nRichard Smith <rsmith@rsbatechnology.co.uk> (Haxe)\nAlexander Morland <alek.morland@gmail.com> (PHP)\nWadim Grasza <wadim.grasza@gmail.com> (PHP, Lua, C, C++)\nMichael Jakl <jakl.michael@gmail.com> (Java)\nUwe Dauernheim <uwe@dauernheim.net> (Erlang)\nSebastian Nowicki <sebnow@gmail.com> (Haskell)\nSimone Deponti <shywolf9982@gmail.com> (Python)\nAaron Raddon <araddon@gmail.com> (Go)\nDan Colish <dcolish@gmail.com> (Python)\nMarkus Schirp <mbj@seonic.net> (Ruby)\nBenoit Larroque (Ruby)\nJonathan Palardy <jonathan.palardy@gmail.com> (text)\nIsaiah Peng <issaria@gmail.com> (Clojure)\nArkadiusz Orzechowski (Java)\nUmut Aydin\nJeremy W. Sherman (Objective-C)\nEric Pugh <epugh@opensourceconnections.com> (Python)\nTyler Sellon <tsellon@gmail.com> (Python)\nJohn E. Vincent <lusis.org+github.com@gmail.com> (Ruby)\nPavel Mitin (Ruby)\nMin RK <benjaminrk@gmail.com> (Python)\nIgor Wiedler \nOlof Åkesson (Java)\nPatrick Lucas (tools)\nHeow Goodman (Clojure)\nSenthil Palanisami <spenthil@gmail.com> (Python)\nJohn Gallagher (C, Python)\nTomas Roos (C#)\nStephen McQuay <stephen@mcquay.me> (C++)\nRob Gagnon <rgagnon24@gmail.com> (PHP)\nErik Allik <eallik@gmail.com> (Python)\nArnaud Cogoluègnes (Java)\nDan Williams <me@deedubs.com> (Node.js)\nJames Tucker <jftucker@gmail.com> (C)\nKristian Kristensen (C#)\nJos Decoster (Tcl)\nVadim Shalts <vshalts@gmail.com> (Java, Scala)\nMartin Trojer (Clojure)\nTom van Leeuwen <tom@vleeuwen.eu> (Ruby) \nHarm Aarts <harmaarts@gmail.com> (Go)\nMarc Harter <wavded@gmail.com> (Node.js)\nIskren Ivov Chernev <iskren.chernev@gmail.com> (C++)\nJay Han <hanjaeheum@shortmail.com> (Q)\nSonia Hamilton <sonia@snowfrog.net> (Perl)\nYan Cui (C#)\nNaveen Palli (C++)\nBalazs Varga <bb.varga@gmail.com> (Delphi)\nMohit Jaggi <mohitjaggi@gmail.com> (C++)\nBrian Palmer (Ruby)\nZaytsev Roman Borisovich <roman.zaytsev.borisovich@gmail.com> (C++)\nTrevor Bernard <trevor.bernard@gmail.com> (Clojure)\nygrek <ygrek@autistici.org> (OCaml)\nMatthew Wraith <wraithm@gmail.com> (Haskell, OCaml)\nPieter du Preez <pdupreez@gmail.com> (C, Java, Python, Ruby)\nDavid Hauri <chubbson@gmail.com> (C, C#)\nOsiris Pedroso <opedroso@gmail.com>\nDave Kuhlman <dkuhlman@davekuhlman.org> (Python: tornado, asyncio)\nAbel Allison <abel.allison@gmail.com> (Node.js)\nTom Kwong <tk3369@gmail.com> (Julia)\nPrateek Agarwal <pratekag@gmail.com> (C++)\n\nErrata and Suggestions\n----------------------\n\nGonzalo Diethelm <gdiethelm@dcv.cl>\nGuido Goldstein <guido.goldstein@a-nugget.de>\nOliver Smith <oliver@kfs.org>\nPierre Rouleau\nPeter Alexander\nDaniel Lin <dlin.tw@gmail.com>\nEdward Smith <esmith@stardotstar.org>\nPandya Hiten <hiten.pandya@gmail.com>\nMatthew Horsfall <WolfSage@gmail.com>\nNathan Stocks\nOndrej Kupka <ondra.cap@gmail.com>\nSebastian Thiel <byronimo@gmail.com>\nScott Watson\nAndriy Drozdyuk <drozzy@gmail.com>\nMateusz Piotrowski <0mp@FreeBSD.org>\n"
        },
        {
          "name": "Figure_list",
          "type": "blob",
          "size": 4.3662109375,
          "content": "Chapter 1\n\nFigure 1-1 (images/fig1.eps): Request-Reply\nFigure 1-2 (images/fig2.eps): A terrible accident...\nFigure 1-3 (images/fig3.eps): A 0MQ string\nFigure 1-4 (images/fig4.eps): Publish-Subscribe\nFigure 1-5 (images/fig5.eps): Parallel Pipeline\nFigure 1-6 (images/fig6.eps): Fair Queuing\nFigure 1-7 (images/fig7.eps): Messaging as it Starts\nFigure 1-8 (images/fig8.eps): Messaging as it Becomes\nFigure 1-9 (images/fig9.eps): Missing Message Problem Solver\n\n__________\n\nChapter 2\n\nFigure 2-1 (images/fig10.eps): TCP sockets are 1 to 1\nFigure 2-2 (images/fig11.eps): 0MQ Sockets are N to N\nFigure 2-3 (images/fig12.eps): HTTP On the Wire\nFigure 2-4 (images/fig13.eps): 0MQ On the Wire\nFigure 2-5 (images/fig14.eps): Parallel Pipeline with Kill Signaling\nFigure 2-6 (images/fig15.eps): Small-scale Pub-Sub Network\nFigure 2-7 (images/fig16.eps): Pub-Sub Network with a Proxy\nFigure 2-8 (images/fig17.eps): Extended Publish-Subscribe\nFigure 2-9 (images/fig18.eps): Load-balancing of Requests\nFigure 2-10 (images/fig19.eps): Extended Request-reply\nFigure 2-11 (images/fig20.eps): Request-reply Broker\nFigure 2-12 (images/fig21.eps): Pub-Sub Forwarder Proxy\nFigure 2-13 (images/fig22.eps): Multithreaded Server\nFigure 2-14 (images/fig23.eps): The Relay Race\nFigure 2-15 (images/fig24.eps): Pub-Sub Synchronization\nFigure 2-16 (images/fig25.eps): Pub-Sub Envelope with Separate Key\nFigure 2-17 (images/fig26.eps): Pub-Sub Envelope with Sender Address\n\n__________\n\nChapter 3\n\nFigure 3-1 (none): ROUTER-DEALER proxy in a request-reply pattern\nFigure 3-2 (images/fig27.eps): Single-hop Request-reply Envelope\nFigure 3-3 (images/fig28.eps): Multihop Request-reply Envelope\nFigure 3-4 (images/fig29.eps): ROUTER Invents a UUID\nFigure 3-5 (images/fig30.eps): ROUTER uses Identity If It knows It\nFigure 3-6 (images/fig31.eps): ROUTER-to-DEALER Custom Routing\nFigure 3-7 (images/fig32.eps): Routing Envelope for DEALER\nFigure 3-8 (images/fig33.eps): ROUTER to REQ Custom Routing\nFigure 3-9 (images/fig34.eps): Routing Envelope for REQ\nFigure 3-10 (images/fig35.eps): ROUTER-to-REP Custom Routing\nFigure 3-11 (images/fig36.eps): Routing Envelope for REP\nFigure 3-12 (images/fig37.eps): Basic Request-reply\nFigure 3-13 (images/fig38.eps): Stretched Request-reply\nFigure 3-14 (images/fig39.eps): Stretched Request-reply with LRU\nFigure 3-15 (images/fig40.eps): Message that Client Sends\nFigure 3-16 (images/fig41.eps): Message Coming in on Frontend\nFigure 3-17 (images/fig42.eps): Message Sent to Backend\nFigure 3-18 (images/fig43.eps): Message Delivered to Worker\nFigure 3-19 (images/fig44.eps): Asynchronous Client-Server\nFigure 3-20 (images/fig45.eps): Detail of Asynchronous Server\nFigure 3-21 (images/fig46.eps): Cluster Architecture\nFigure 3-22 (images/fig47.eps): Multiple Clusters\nFigure 3-23 (images/fig48.eps): Idea 1 - Cross-connected Workers\nFigure 3-24 (images/fig49.eps): Idea 2 - Brokers Talking to Each Other\nFigure 3-25 (images/fig50.eps): Cross-connected Brokers in Federation Model\nFigure 3-26 (images/fig51.eps): Broker Socket Arrangement\nFigure 3-27 (images/fig52.eps): The State Flow\nFigure 3-28 (images/fig53.eps): The Flow of Tasks\n\n__________\n\nChapter 4\n\nFigure 4-1 (images/fig54.eps): The Lazy Pirate Pattern\nFigure 4-2 (images/fig55.eps): The Simple Pirate Pattern\nFigure 4-3 (images/fig56.eps): The Paranoid Pirate Pattern\nFigure 4-4 (images/fig57.eps): The Majordomo Pattern\nFigure 4-5 (images/fig58.eps): The Titanic Pattern\nFigure 4-6 (images/fig59.eps): High-availability Pair, Normal Operation\nFigure 4-7 (images/fig60.eps): High-availability Pair During Failover\nFigure 4-8 (images/fig61.eps): Binary Star Finite State Machine\nFigure 4-9 (images/fig62.eps): The Freelance Pattern\n\n__________\n\nChapter 5\n\nFigure 5-1 (images/fig63.eps): The Simple Black Box Pattern\nFigure 5-2 (images/fig64.eps): Mad Black Box Pattern\nFigure 5-3 (images/fig65.eps): Simplest Clone Model\nFigure 5-4 (images/fig66.eps): State Replication\nFigure 5-5 (images/fig67.eps): Republishing Updates\nFigure 5-6 (images/fig68.eps): Clone Client Finite State Machine\nFigure 5-7 (images/fig69.eps): High-availability Clone Server Pair\n\n__________\n\nChapter 6\n\nFigure 6-1 (images/fig70.eps): The 'Start' State\nFigure 6-2 (images/fig71.eps): The 'Authenticated' State\nFigure 6-3 (images/fig72.eps): The 'Ready' State\n\n__________\n\nChapter 7\n\nNo figures\n\n__________\n\nChapter 8\n\nFigure 8-1 (images/fig73.eps): ZRE discovery message\nFigure 8-2 (images/fig74.eps): ZyRE Tester Tool\n\n__________\n\n"
        },
        {
          "name": "LICENSE",
          "type": "blob",
          "size": 0.146484375,
          "content": "The Guide is copyright (c) 2010-2011 Pieter Hintjens.  It is licensed under \nthe Creative Commons Attribution-Non-Commercial-Share Alike 3.0 License.\n"
        },
        {
          "name": "Makefile",
          "type": "blob",
          "size": 0.31640625,
          "content": "serve:\n\tcd site && \\\n\thugo server \\\n\t--buildDrafts \\\n\t--buildFuture \\\n\t--disableFastRender \\\n\t--ignoreCache \\\n\t--theme book\n\nproduction-build:\n\tcd site && \\\n\thugo --theme book && \\\n\trm -rf public/examples\n\npreview-build:\n\tcd site && \\\n\thugo \\\n\t--baseURL $(DEPLOY_PRIME_URL) \\\n\t--buildDrafts \\\n\t--buildFuture \\\n\t--theme book\n"
        },
        {
          "name": "README.md",
          "type": "blob",
          "size": 1.3837890625,
          "content": "\n<A name=\"toc1-4\" title=\"ØMQ - The Guide\" />\nØMQ - The Guide\n===============\n\nWritten by Pieter Hintjens <ph@imatix.com>, CEO iMatix Corporation.\n\nA ØMQ socket is what you get when you take a normal TCP socket, inject it with a mix of radioactive isotopes stolen from a secret Soviet atomic research project, bombard it with 1950-era cosmic rays, and put it into the hands of a drug-addled comic book author with a badly-disguised fetish for bulging muscles clad in spandex.  Yes, ØMQ sockets are the world-saving superheros of the networking world.\n\n<center>\n<img src=\"https://github.com/imatix/zguide/raw/master/images/fig1.png\" alt=\"1\">\n</center>\n\n<A name=\"toc2-34\" title=\"License\" />\nLicense\n-------\n\nThe text of \"ØMQ - The Guide\" is copyright (c) 2009-2012 Pieter Hintjens, and is licensed under the Creative Commons Attribution-Share Alike 3.0 License. The source code examples are licensed under MIT/X11 unless otherwise specified in the code. The tools in /bin are placed into the public domain.\n\n<A name=\"toc2-40\" title=\"Contributions\" />\nContributions\n-------------\n\nAll contributions to the Guide example source code is governed by the [C4 process](https://rfc.zeromq.org/spec/42/).\n\n<A name=\"toc2-46\" title=\"Thanks\" />\nThanks\n------\n\nThanks to all the contributors, listed in CONTRIBUTORS.\n\n_This documentation was generated from zguide/README.txt using [Gitdown](https://github.com/zeromq/gitdown)_\n"
        },
        {
          "name": "README.txt",
          "type": "blob",
          "size": 1.572265625,
          "content": ".set GIT=https://github.com/imatix/zguide\n.sub 0MQ=ØMQ\n\n0MQ - The Guide\n===============\n\nWritten by Pieter Hintjens <ph@imatix.com>, CEO iMatix Corporation.\n\nA 0MQ socket is what you get when you take a normal TCP socket, inject it with a mix of radioactive isotopes stolen from a secret Soviet atomic research project, bombard it with 1950-era cosmic rays, and put it into the hands of a drug-addled comic book author with a badly-disguised fetish for bulging muscles clad in spandex.  Yes, 0MQ sockets are the world-saving superheros of the networking world.\n\n[diagram]\n +------------+        +------------+\n |            |        |            | Zap!\n | TCP socket +------->| 0MQ socket |\n |            | BOOM!  |     cC00   |  POW!!\n +------------+        +------------+\n   ^    ^    ^\n   |    |    |\n   |    |    \\---------\\\n   |    |              |\n   |    \\----------\\   |\n  Illegal          |   |\n  radioisotopes    |   |\n  from secret      |   |\n  Soviet atomic    | Spandex\n  city             |\n               Cosmic rays\n\n\n        A terrible accident...\n[/diagram]\n\nLicense\n-------\n\nThe text of \"0MQ - The Guide\" is copyright (c) 2009-2012 Pieter Hintjens, and is licensed under the Creative Commons Attribution-Share Alike 3.0 License. The source code examples are licensed under MIT/X11 unless otherwise specified in the code. The tools in /bin are placed into the public domain.\n\nContributions\n-------------\n\nAll contributions to the Guide example source code is governed by the [C4 process](http://rfc.zeromq.org/spec:16).\n\nThanks\n------\n\nThanks to all the contributors, listed in CONTRIBUTORS.\n"
        },
        {
          "name": "articles",
          "type": "tree",
          "content": null
        },
        {
          "name": "bin",
          "type": "tree",
          "content": null
        },
        {
          "name": "builds",
          "type": "tree",
          "content": null
        },
        {
          "name": "chapter1.txt",
          "type": "blob",
          "size": 45.173828125,
          "content": ".output chapter1.wd\n.bookmark basics\n+ Basics\n\n++ Fixing the World\n\nHow to explain ZeroMQ? Some of us start by saying all the wonderful things it does. //It's sockets on steroids. It's like mailboxes with routing. It's fast!//  Others try to share their moment of enlightenment, that zap-pow-kaboom satori paradigm-shift moment when it all became obvious. //Things just become simpler. Complexity goes away. It opens the mind.//  Others try to explain by comparison. //It's smaller, simpler, but still looks familiar.//  Personally, I like to remember why we made ZeroMQ at all, because that's most likely where you, the reader, still are today.\n\nProgramming is science dressed up as art because most of us don't understand the physics of software and it's rarely, if ever, taught. The physics of software is not algorithms, data structures, languages and abstractions. These are just tools we make, use, throw away. The real physics of software is the physics of people--specifically, our limitations when it comes to complexity, and our desire to work together to solve large problems in pieces. This is the science of programming: make building blocks that people can understand and use //easily//, and people will work together to solve the very largest problems.\n\nWe live in a connected world, and modern software has to navigate this world. So the building blocks for tomorrow's very largest solutions are connected and massively parallel. It's not enough for code to be \"strong and silent\" any more. Code has to talk to code. Code has to be chatty, sociable, well-connected. Code has to run like the human brain, trillions of individual neurons firing off messages to each other, a massively parallel network with no central control, no single point of failure, yet able to solve immensely difficult problems. And it's no accident that the future of code looks like the human brain, because the endpoints of every network are, at some level, human brains.\n\nIf you've done any work with threads, protocols, or networks, you'll realize this is pretty much impossible. It's a dream. Even connecting a few programs across a few sockets is plain nasty when you start to handle real life situations. Trillions? The cost would be unimaginable. Connecting computers is so difficult that software and services to do this is a multi-billion dollar business.\n\nSo we live in a world where the wiring is years ahead of our ability to use it. We had a software crisis in the 1980s, when leading software engineers like Fred Brooks believed [http://en.wikipedia.org/wiki/No_Silver_Bullet there was no \"Silver Bullet\"] to \"promise even one order of magnitude of improvement in productivity, reliability, or simplicity\".\n\nBrooks missed free and open source software, which solved that crisis, enabling us to share knowledge efficiently. Today we face another software crisis, but it's one we don't talk about much. Only the largest, richest firms can afford to create connected applications. There is a cloud, but it's proprietary. Our data and our knowledge is disappearing from our personal computers into clouds that we cannot access and with which we cannot compete. Who owns our social networks? It is like the mainframe-PC revolution in reverse.\n\nWe can leave the political philosophy [http://cultureandempire.com for another book]. The point is that while the Internet offers the potential of massively connected code, the reality is that this is out of reach for most of us, and so large interesting problems (in health, education, economics, transport, and so on) remain unsolved because there is no way to connect the code, and thus no way to connect the brains that could work together to solve these problems.\n\nThere have been many attempts to solve the challenge of connected code. There are thousands of IETF specifications, each solving part of the puzzle. For application developers, HTTP is perhaps the one solution to have been simple enough to work, but it arguably makes the problem worse by encouraging developers and architects to think in terms of big servers and thin, stupid clients.\n\nSo today people are still connecting applications using raw UDP and TCP, proprietary protocols, HTTP, and Websockets. It remains painful, slow, hard to scale, and essentially centralized. Distributed P2P architectures are mostly for play, not work. How many applications use Skype or Bittorrent to exchange data?\n\nWhich brings us back to the science of programming. To fix the world, we needed to do two things. One, to solve the general problem of \"how to connect any code to any code, anywhere\". Two, to wrap that up in the simplest possible building blocks that people could understand and use //easily//.\n\nIt sounds ridiculously simple. And maybe it is. That's kind of the whole point.\n\n++ Starting Assumptions\n\nWe assume you are using at least version 3.2 of ZeroMQ. We assume you are using a Linux box or something similar. We assume you can read C code, more or less, as that's the default language for the examples. We assume that when we write constants like PUSH or SUBSCRIBE, you can imagine they are really called {{ZMQ_PUSH}} or {{ZMQ_SUBSCRIBE}} if the programming language needs it.\n\n++ Getting the Examples\n\nThe examples live in a public [https://github.com/imatix/zguide GitHub repository]. The simplest way to get all the examples is to clone this repository:\n\n[[code]]\ngit clone --depth=1 https://github.com/imatix/zguide.git\n[[/code]]\n\nNext, browse the examples subdirectory. You'll find examples by language. If there are examples missing in a language you use, you're encouraged to [http://zguide.zeromq.org/main:translate submit a translation]. This is how this text became so useful, thanks to the work of many people. All examples are licensed under MIT/X11.\n\n++ Ask and Ye Shall Receive\n\nSo let's start with some code. We start of course with a Hello World example. We'll make a client and a server. The client sends \"Hello\" to the server, which replies with \"World\"[figure]. Here's the server in C, which opens a ZeroMQ socket on port 5555, reads requests on it, and replies with \"World\" to each request:\n\n[[code type=\"example\" title=\"Hello World server\" name=\"hwserver\"]]\n[[/code]]\n\n[[code type=\"textdiagram\" title=\"Request-Reply\"]]\n  #------------#\n  |   Client   |\n  +------------+\n  |    REQ     |\n  '---+--------'\n      |    ^\n      |    |\nHello |    | World\n      |    |\n      v    |\n  .--------+---.\n  |    REP     |\n  +------------+\n  |   Server   |\n  #------------#\n[[/code]]\n\nThe REQ-REP socket pair is in lockstep. The client issues {{zmq_send[3]}} and then {{zmq_recv[3]}}, in a loop (or once if that's all it needs). Doing any other sequence (e.g., sending two messages in a row) will result in a return code of -1 from the {{send}} or {{recv}} call. Similarly, the service issues {{zmq_recv[3]}} and then {{zmq_send[3]}} in that order, as often as it needs to.\n\nZeroMQ uses C as its reference language and this is the main language we'll use for examples. If you're reading this online, the link below the example takes you to translations into other programming languages. Let's compare the same server in C++:\n\n[[code type=\"example\" title=\"Hello World server\" name=\"hwserver\" language=\"C++\"]]\n[[/code]]\n\nYou can see that the ZeroMQ API is similar in C and C++. In a language like PHP or Java, we can hide even more and the code becomes even easier to read:\n\n[[code type=\"example\" title=\"Hello World server\" name=\"hwserver\" language=\"PHP\"]]\n[[/code]]\n\n[[code type=\"example\" title=\"Hello World server\" name=\"hwserver\" language=\"Java\"]]\n[[/code]]\n\n\nThe server in other languages:\n\n[[code type=\"example\" title=\"Hello World server\" name=\"hwserver\"]]\n[[/code]]\n\nHere's the client code:\n\n[[code type=\"example\" title=\"Hello World client\" name=\"hwclient\"]]\n[[/code]]\n\nNow this looks too simple to be realistic, but ZeroMQ sockets have, as we already learned, superpowers. You could throw thousands of clients at this server, all at once, and it would continue to work happily and quickly. For fun, try starting the client and //then// starting the server, see how it all still works, then think for a second what this means.\n\nLet us explain briefly what these two programs are actually doing. They create a ZeroMQ context to work with, and a socket. Don't worry what the words mean. You'll pick it up. The server binds its REP (reply) socket to port 5555. The server waits for a request in a loop, and responds each time with a reply. The client sends a request and reads the reply back from the server.\n\nIf you kill the server (Ctrl-C) and restart it, the client won't recover properly. Recovering from crashing processes isn't quite that easy. Making a reliable request-reply flow is complex enough that we won't cover it until [#reliable-request-reply].\n\nThere is a lot happening behind the scenes but what matters to us programmers is how short and sweet the code is, and how often it doesn't crash, even under a heavy load. This is the request-reply pattern, probably the simplest way to use ZeroMQ. It maps to RPC and the classic client/server model.\n\n++ A Minor Note on Strings\n\nZeroMQ doesn't know anything about the data you send except its size in bytes. That means you are responsible for formatting it safely so that applications can read it back. Doing this for objects and complex data types is a job for specialized libraries like Protocol Buffers. But even for strings, you need to take care.\n\nIn C and some other languages, strings are terminated with a null byte. We could send a string like \"HELLO\" with that extra null byte:\n\n[[code language=\"C\"]]\nzmq_send (requester, \"Hello\", 6, 0);\n[[/code]]\n\nHowever, if you send a string from another language, it probably will not include that null byte. For example, when we send that same string in Python, we do this:\n\n[[code language=\"Python\"]]\nsocket.send (\"Hello\")\n[[/code]]\n\nThen what goes onto the wire is a length (one byte for shorter strings) and the string contents as individual characters[figure].\n\n[[code type=\"textdiagram\" title=\"A ZeroMQ string\"]]\n#-----#  #-----+-----+-----+-----+-----#\n|  5  |  |  H  |  e  |  l  |  l  |  o  |\n#-----#  #-----+-----+-----+-----+-----#\n[[/code]]\n\nAnd if you read this from a C program, you will get something that looks like a string, and might by accident act like a string (if by luck the five bytes find themselves followed by an innocently lurking null), but isn't a proper string. When your client and server don't agree on the string format, you will get weird results.\n\nWhen you receive string data from ZeroMQ in C, you simply cannot trust that it's safely terminated. Every single time you read a string, you should allocate a new buffer with space for an extra byte, copy the string, and terminate it properly with a null.\n\nSo let's establish the rule that **ZeroMQ strings are length-specified and are sent on the wire //without// a trailing null**. In the simplest case (and we'll do this in our examples), a ZeroMQ string maps neatly to a ZeroMQ message frame, which looks like the above figure--a length and some bytes.\n\nHere is what we need to do, in C, to receive a ZeroMQ string and deliver it to the application as a valid C string:\n\n[[code language=\"C\"]]\n//  Receive ZeroMQ string from socket and convert into C string\n//  Chops string at 255 chars, if it's longer\nstatic char *\ns_recv (void *socket) {\n    char buffer [256];\n    int size = zmq_recv (socket, buffer, 255, 0);\n    if (size == -1)\n        return NULL;\n    if (size > 255)\n        size = 255;\n    buffer [size] = \\0;\n    /* use strndup(buffer, sizeof(buffer)-1) in *nix */\n    return strdup (buffer);\n}\n[[/code]]\n\nThis makes a handy helper function and in the spirit of making things we can reuse profitably, let's write a similar {{s_send}} function that sends strings in the correct ZeroMQ format, and package this into a header file we can reuse.\n\nThe result is {{zhelpers.h}}, which lets us write sweeter and shorter ZeroMQ applications in C. It is a fairly long source, and only fun for C developers, so [https://github.com/imatix/zguide/blob/master/examples/C/zhelpers.h read it at leisure].\n\n++ A Note on the Naming Convention\n\nThe prefix {{s_}} used in {{zhelpers.h}} and the examples which follow in this guide is an indicator for static methods or variables.\n\n++ Version Reporting\n\nZeroMQ does come in several versions and quite often, if you hit a problem, it'll be something that's been fixed in a later version. So it's a useful trick to know //exactly// what version of ZeroMQ you're actually linking with.\n\nHere is a tiny program that does that:\n\n[[code type=\"example\" title=\"ZeroMQ version reporting\" name=\"version\"]]\n[[/code]]\n\n++ Getting the Message Out\n\nThe second classic pattern is one-way data distribution, in which a server pushes updates to a set of clients. Let's see an example that pushes out weather updates consisting of a zip code, temperature, and relative humidity. We'll generate random values, just like the real weather stations do.\n\nHere's the server. We'll use port 5556 for this application:\n\n[[code type=\"example\" title=\"Weather update server\" name=\"wuserver\"]]\n[[/code]]\n\nThere's no start and no end to this stream of updates, it's like a never ending broadcast[figure].\n\nHere is the client application, which listens to the stream of updates and grabs anything to do with a specified zip code, by default New York City because that's a great place to start any adventure:\n\n[[code type=\"example\" title=\"Weather update client\" name=\"wuclient\"]]\n[[/code]]\n\n[[code type=\"textdiagram\" title=\"Publish-Subscribe\"]]\n               #-------------#\n               |  Publisher  |\n               +-------------+\n               |     PUB     |\n               '-------------'\n                    bind\n                      |\n                      |\n                   updates\n                      |\n      .---------------+---------------.\n      |               |               |\n   updates         updates         updates\n      |               |               |\n      |               |               |\n      v               v               v\n   connect         connect         connect\n.------------.  .------------.  .------------.\n|    SUB     |  |    SUB     |  |    SUB     |\n+------------+  +------------+  +------------+\n| Subscriber |  | Subscriber |  | Subscriber |\n#------------#  #------------#  #------------#\n[[/code]]\n\nNote that when you use a SUB socket you **must** set a subscription using {{zmq_setsockopt[3]}} and SUBSCRIBE, as in this code. If you don't set any subscription, you won't get any messages. It's a common mistake for beginners. The subscriber can set many subscriptions, which are added together. That is, if an update matches ANY subscription, the subscriber receives it. The subscriber can also cancel specific subscriptions. A subscription is often, but not always, a printable string. See {{zmq_setsockopt[3]}} for how this works.\n\nThe PUB-SUB socket pair is asynchronous. The client does {{zmq_recv[3]}}, in a loop (or once if that's all it needs). Trying to send a message to a SUB socket will cause an error. Similarly, the service does {{zmq_send[3]}} as often as it needs to, but must not do {{zmq_recv[3]}} on a PUB socket.\n\nIn theory with ZeroMQ sockets, it does not matter which end connects and which end binds. However, in practice there are undocumented differences that I'll come to later. For now, bind the PUB and connect the SUB, unless your network design makes that impossible.\n\nThere is one more important thing to know about PUB-SUB sockets: you do not know precisely when a subscriber starts to get messages. Even if you start a subscriber, wait a while, and then start the publisher, **the subscriber will always miss the first messages that the publisher sends**. This is because as the subscriber connects to the publisher (something that takes a small but non-zero time), the publisher may already be sending messages out.\n\nThis \"slow joiner\" symptom hits enough people often enough that we're going to explain it in detail. Remember that ZeroMQ does asynchronous I/O, i.e., in the background. Say you have two nodes doing this, in this order:\n\n* Subscriber connects to an endpoint and receives and counts messages.\n* Publisher binds to an endpoint and immediately sends 1,000 messages.\n\nThen the subscriber will most likely not receive anything. You'll blink, check that you set a correct filter and try again, and the subscriber will still not receive anything.\n\nMaking a TCP connection involves to and from handshaking that takes several milliseconds depending on your network and the number of hops between peers. In that time, ZeroMQ can send many messages. For sake of argument assume it takes 5 msecs to establish a connection, and that same link can handle 1M messages per second. During the 5 msecs that the subscriber is connecting to the publisher, it takes the publisher only 1 msec to send out those 1K messages.\n\nIn [#sockets-and-patterns] we'll explain how to synchronize a publisher and subscribers so that you don't start to publish data until the subscribers really are connected and ready. There is a simple and stupid way to delay the publisher, which is to sleep. Don't do this in a real application, though, because it is extremely fragile as well as inelegant and slow. Use sleeps to prove to yourself what's happening, and then wait for [#sockets-and-patterns] to see how to do this right.\n\nThe alternative to synchronization is to simply assume that the published data stream is infinite and has no start and no end. One also assumes that the subscriber doesn't care what transpired before it started up. This is how we built our weather client example.\n\nSo the client subscribes to its chosen zip code and collects 100 updates for that zip code. That means about ten million updates from the server, if zip codes are randomly distributed. You can start the client, and then the server, and the client will keep working. You can stop and restart the server as often as you like, and the client will keep working. When the client has collected its hundred updates, it calculates the average, prints it, and exits.\n\nSome points about the publish-subscribe (pub-sub) pattern:\n\n* A subscriber can connect to more than one publisher, using one connect call each time. Data will then arrive and be interleaved (\"fair-queued\") so that no single publisher drowns out the others.\n\n* If a publisher has no connected subscribers, then it will simply drop all messages.\n\n* If you're using TCP and a subscriber is slow, messages will queue up on the publisher. We'll look at how to protect publishers against this using the \"high-water mark\" later.\n\n* From ZeroMQ v3.x, filtering happens at the publisher side when using a connected protocol ({{tcp:@<//>@}} or {{ipc:@<//>@}}). Using the {{epgm:@<//>@}} protocol, filtering happens at the subscriber side. In ZeroMQ v2.x, all filtering happened at the subscriber side.\n\nThis is how long it takes to receive and filter 10M messages on my laptop, which is an 2011-era Intel i5, decent but nothing special:\n\n[[code]]\n$ time wuclient\nCollecting updates from weather server...\nAverage temperature for zipcode '10001 ' was 28F\n\nreal    0m4.470s\nuser    0m0.000s\nsys     0m0.008s\n[[/code]]\n\n++ Divide and Conquer\n\n[[code type=\"textdiagram\" title=\"Parallel Pipeline\"]]\n            #-------------#\n            |  Ventilator |\n            +-------------+\n            |    PUSH     |\n            '------+------'\n                   |\n                   | tasks\n                   |\n      .------------+-------------.\n      |            |             |\n      v            v             v\n.----------.  .----------.  .----------.\n|   PULL   |  |   PULL   |  |   PULL   |\n+----------+  +----------+  +----------+\n|  Worker  |  |  Worker  |  |  Worker  |\n+----------+  +----------+  +----------+\n|   PUSH   |  |   PUSH   |  |   PUSH   |\n'----+-----'  '----+-----'  '----+-----'\n      |            |             |\n      '------------+-------------'\n                   |\n                   | results\n                   |\n                   v\n            .-------------.\n            |    PULL     |\n            +-------------+\n            |    Sink     |\n            #-------------#\n[[/code]]\n\nAs a final example (you are surely getting tired of juicy code and want to delve back into philological discussions about comparative abstractive norms), let's do a little supercomputing. Then coffee. Our supercomputing application is a fairly typical parallel processing model[figure]. We have:\n\n* A ventilator that produces tasks that can be done in parallel\n* A set of workers that process tasks\n* A sink that collects results back from the worker processes\n\nIn reality, workers run on superfast boxes, perhaps using GPUs (graphic processing units) to do the hard math. Here is the ventilator. It generates 100 tasks, each a message telling the worker to sleep for some number of milliseconds:\n\n[[code type=\"example\" title=\"Parallel task ventilator\" name=\"taskvent\"]]\n[[/code]]\n\nHere is the worker application. It receives a message, sleeps for that number of seconds, and then signals that it's finished:\n\n[[code type=\"example\" title=\"Parallel task worker\" name=\"taskwork\"]]\n[[/code]]\n\nHere is the sink application. It collects the 100 tasks, then calculates how long the overall processing took, so we can confirm that the workers really were running in parallel if there are more than one of them:\n\n[[code type=\"example\" title=\"Parallel task sink\" name=\"tasksink\"]]\n[[/code]]\n\nThe average cost of a batch is 5 seconds. When we start 1, 2, or 4 workers we get results like this from the sink:\n\n* 1 worker: total elapsed time: 5034 msecs.\n* 2 workers: total elapsed time: 2421 msecs.\n* 4 workers: total elapsed time: 1018 msecs.\n\nLet's look at some aspects of this code in more detail:\n\n* The workers connect upstream to the ventilator, and downstream to the sink. This means you can add workers arbitrarily. If the workers bound to their endpoints, you would need (a) more endpoints and (b) to modify the ventilator and/or the sink each time you added a worker. We say that the ventilator and sink are //stable// parts of our architecture and the workers are //dynamic// parts of it.\n\n* We have to synchronize the start of the batch with all workers being up and running. This is a fairly common gotcha in ZeroMQ and there is no easy solution. The {{zmq_connect}} method takes a certain time. So when a set of workers connect to the ventilator, the first one to successfully connect will get a whole load of messages in that short time while the others are also connecting. If you don't synchronize the start of the batch somehow, the system won't run in parallel at all. Try removing the wait in the ventilator, and see what happens.\n\n* The ventilator's PUSH socket distributes tasks to workers (assuming they are all connected //before// the batch starts going out) evenly. This is called //load balancing// and it's something we'll look at again in more detail.\n\n* The sink's PULL socket collects results from workers evenly. This is called //fair-queuing//[figure].\n\n[[code type=\"textdiagram\" title=\"Fair Queuing\"]]\n#---------#   #---------#   #---------#\n|  PUSH   |   |  PUSH   |   |  PUSH   |\n'----+----'   '----+----'   '----+----'\n     |             |             |\n  R1,| R2, R3      | R4       R5,| R6\n     |             |             |\n     '-------------+-------------'\n                   |\n               fair| queuing\n        R1, R4, R5,| R2, R6, R3\n                   |\n                   v\n            .-------------.\n            |     PULL    |\n            #-------------#\n[[/code]]\n\nThe pipeline pattern also exhibits the \"slow joiner\" syndrome, leading to accusations that PUSH sockets don't load balance properly. If you are using PUSH and PULL, and one of your workers gets way more messages than the others, it's because that PULL socket has joined faster than the others, and grabs a lot of messages before the others manage to connect. If you want proper load balancing, you probably want to look at the load balancing pattern in [#advanced-request-reply].\n\n++ Programming with ZeroMQ\n\nHaving seen some examples, you must be eager to start using ZeroMQ in some apps. Before you start that, take a deep breath, chillax, and reflect on some basic advice that will save you much stress and confusion.\n\n* Learn ZeroMQ step-by-step. It's just one simple API, but it hides a world of possibilities. Take the possibilities slowly and master each one.\n\n* Write nice code. Ugly code hides problems and makes it hard for others to help you. You might get used to meaningless variable names, but people reading your code won't. Use names that are real words, that say something other than \"I'm too careless to tell you what this variable is really for\". Use consistent indentation and clean layout. Write nice code and your world will be more comfortable.\n\n* Test what you make as you make it. When your program doesn't work, you should know what five lines are to blame. This is especially true when you do ZeroMQ magic, which just //won't// work the first few times you try it.\n\n* When you find that things don't work as expected, break your code into pieces, test each one, see which one is not working. ZeroMQ lets you make essentially modular code; use that to your advantage.\n\n* Make abstractions (classes, methods, whatever) as you need them. If you copy/paste a lot of code, you're going to copy/paste errors, too.\n\n+++ Getting the Context Right\n\nZeroMQ applications always start by creating a //context//, and then using that for creating sockets. In C, it's the {{zmq_ctx_new[3]}} call. You should create and use exactly one context in your process. Technically, the context is the container for all sockets in a single process, and acts as the transport for {{inproc}} sockets, which are the fastest way to connect threads in one process. If at runtime a process has two contexts, these are like separate ZeroMQ instances. If that's explicitly what you want, OK, but otherwise remember:\n\n**Call {{zmq_ctx_new[3]}} once at the start of a process, and {{zmq_ctx_destroy[3]}} once at the end.**\n\nIf you're using the {{fork()}} system call, do {{zmq_ctx_new[3]}} //after// the fork and at the beginning of the child process code. In general, you want to do interesting (ZeroMQ) stuff in the children, and boring process management in the parent.\n\n+++ Making a Clean Exit\n\nClassy programmers share the same motto as classy hit men: always clean-up when you finish the job. When you use ZeroMQ in a language like Python, stuff gets automatically freed for you. But when using C, you have to carefully free objects when you're finished with them or else you get memory leaks, unstable applications, and generally bad karma.\n\nMemory leaks are one thing, but ZeroMQ is quite finicky about how you exit an application. The reasons are technical and painful, but the upshot is that if you leave any sockets open, the {{zmq_ctx_destroy[3]}} function will hang forever. And even if you close all sockets, {{zmq_ctx_destroy[3]}} will by default wait forever if there are pending connects or sends unless you set the LINGER to zero on those sockets before closing them.\n\nThe ZeroMQ objects we need to worry about are messages, sockets, and contexts. Luckily it's quite simple, at least in simple programs:\n\n* Use {{zmq_send[3]}} and {{zmq_recv[3]}} when you can, as it avoids the need to work with zmq_msg_t objects.\n\n* If you do use {{zmq_msg_recv[3]}}, always release the received message as soon as you're done with it, by calling {{zmq_msg_close[3]}}.\n\n* If you are opening and closing a lot of sockets, that's probably a sign that you need to redesign your application. In some cases socket handles won't be freed until you destroy the context.\n\n* When you exit the program, close your sockets and then call {{zmq_ctx_destroy[3]}}. This destroys the context.\n\nThis is at least the case for C development. In a language with automatic object destruction, sockets and contexts will be destroyed as you leave the scope. If you use exceptions you'll have to do the clean-up in something like a \"final\" block, the same as for any resource.\n\nIf you're doing multithreaded work, it gets rather more complex than this. We'll get to multithreading in the next chapter, but because some of you will, despite warnings, try to run before you can safely walk, below is the quick and dirty guide to making a clean exit in a //multithreaded// ZeroMQ application.\n\nFirst, do not try to use the same socket from multiple threads. Please don't explain why you think this would be excellent fun, just please don't do it. Next, you need to shut down each socket that has ongoing requests. The proper way is to set a low LINGER value (1 second), and then close the socket. If your language binding doesn't do this for you automatically when you destroy a context, I'd suggest sending a patch.\n\nFinally, destroy the context. This will cause any blocking receives or polls or sends in attached threads (i.e., which share the same context) to return with an error. Catch that error, and then set linger on, and close sockets in //that// thread, and exit. Do not destroy the same context twice. The {{zmq_ctx_destroy}} in the main thread will block until all sockets it knows about are safely closed.\n\nVoila! It's complex and painful enough that any language binding author worth his or her salt will do this automatically and make the socket closing dance unnecessary.\n\n++ Why We Needed ZeroMQ\n\nNow that you've seen ZeroMQ in action, let's go back to the \"why\".\n\nMany applications these days consist of components that stretch across some kind of network, either a LAN or the Internet. So many application developers end up doing some kind of messaging. Some developers use message queuing products, but most of the time they do it themselves, using TCP or UDP. These protocols are not hard to use, but there is a great difference between sending a few bytes from A to B, and doing messaging in any kind of reliable way.\n\nLet's look at the typical problems we face when we start to connect pieces using raw TCP. Any reusable messaging layer would need to solve all or most of these:\n\n* How do we handle I/O? Does our application block, or do we handle I/O in the background? This is a key design decision. Blocking I/O creates architectures that do not scale well. But background I/O can be very hard to do right.\n\n* How do we handle dynamic components, i.e., pieces that go away temporarily? Do we formally split components into \"clients\" and \"servers\" and mandate that servers cannot disappear? What then if we want to connect servers to servers? Do we try to reconnect every few seconds?\n\n* How do we represent a message on the wire? How do we frame data so it's easy to write and read, safe from buffer overflows, efficient for small messages, yet adequate for the very largest videos of dancing cats wearing party hats?\n\n* How do we handle messages that we can't deliver immediately? Particularly, if we're waiting for a component to come back online? Do we discard messages, put them into a database, or into a memory queue?\n\n* Where do we store message queues? What happens if the component reading from a queue is very slow and causes our queues to build up? What's our strategy then?\n\n* How do we handle lost messages? Do we wait for fresh data, request a resend, or do we build some kind of reliability layer that ensures messages cannot be lost? What if that layer itself crashes?\n\n* What if we need to use a different network transport. Say, multicast instead of TCP unicast? Or IPv6? Do we need to rewrite the applications, or is the transport abstracted in some layer?\n\n* How do we route messages? Can we send the same message to multiple peers? Can we send replies back to an original requester?\n\n* How do we write an API for another language? Do we re-implement a wire-level protocol or do we repackage a library? If the former, how can we guarantee efficient and stable stacks? If the latter, how can we guarantee interoperability?\n\n* How do we represent data so that it can be read between different architectures? Do we enforce a particular encoding for data types? How far is this the job of the messaging system rather than a higher layer?\n\n* How do we handle network errors? Do we wait and retry, ignore them silently, or abort?\n\nTake a typical open source project like [https://zookeeper.apache.org/ Hadoop Zookeeper] and read the C API code in {{[http://github.com/apache/zookeeper/blob/trunk/src/c/src/zookeeper.c src/c/src/zookeeper.c]}}. When I read this code, in January 2013, it was 4,200 lines of mystery and in there is an undocumented, client/server network communication protocol. I see it's efficient because it uses {{poll}} instead of {{select}}. But really, Zookeeper should be using a generic messaging layer and an explicitly documented wire level protocol. It is incredibly wasteful for teams to be building this particular wheel over and over.\n\nBut how to make a reusable messaging layer? Why, when so many projects need this technology, are people still doing it the hard way by driving TCP sockets in their code, and solving the problems in that long list over and over[figure]?\n\nIt turns out that building reusable messaging systems is really difficult, which is why few FOSS projects ever tried, and why commercial messaging products are complex, expensive, inflexible, and brittle. In 2006, iMatix designed [http://www.amqp.org AMQP] which started to give FOSS developers perhaps the first reusable recipe for a messaging system. AMQP works better than many other designs, [https://web.archive.org/web/20190620095529/www.imatix.com/articles:whats-wrong-with-amqp but remains relatively complex, expensive, and brittle]. It takes weeks to learn to use, and months to create stable architectures that don't crash when things get hairy.\n\n[[code type=\"textdiagram\" title=\"Messaging as it Starts\"]]\n.------------.\n|            |\n|  Piece A   |\n|            |\n'------------'\n      ^\n      |\n      | TCP\n      |\n      v\n.------------.\n|            |\n|  Piece B   |\n|            |\n'------------'\n[[/code]]\n\nMost messaging projects, like AMQP, that try to solve this long list of problems in a reusable way do so by inventing a new concept, the \"broker\", that does addressing, routing, and queuing. This results in a client/server protocol or a set of APIs on top of some undocumented protocol that allows applications to speak to this broker. Brokers are an excellent thing in reducing the complexity of large networks. But adding broker-based messaging to a product like Zookeeper would make it worse, not better. It would mean adding an additional big box, and a new single point of failure. A broker rapidly becomes a bottleneck and a new risk to manage. If the software supports it, we can add a second, third, and fourth broker and make some failover scheme. People do this. It creates more moving pieces, more complexity, and more things to break.\n\nAnd a broker-centric setup needs its own operations team. You literally need to watch the brokers day and night, and beat them with a stick when they start misbehaving. You need boxes, and you need backup boxes, and you need people to manage those boxes. It is only worth doing for large applications with many moving pieces, built by several teams of people over several years.\n\n[[code type=\"textdiagram\" title=\"Messaging as it Becomes\"]]\n        .---.             .---.\n.---.   |   |   .---.  ^  |   |\n|   +-->|   |<--|   |  |  |   |\n|   |   '---'   |   |  |  '-+-'\n'-+-'           '-+-'  |    |\n  |               ^    |    |\n  |       .-------+----+----'\n  |       |       |    |\n  '-------+-------+----+--.\n          |       |    |  |\n  .-------+-------+----+--+-----.\n  |       v       |       v     |\n.-+-.   .---.     |     .---.   |\n|   |   |   |   .-+-.   |   |-->|\n|   +-->|   +-->|   +-->|   |   |\n'---'   '---'   |   |   '---'   |\n          ^     '-+-'     ^     |\n          |       |       |     |\n  .-------+-------+-------'     |\n  |       |       |             |\n  v     .-+-.     v     .---.   |\n.---.   |   |   .---.   |   |   |\n|   |<--|   |<--|   |<--|   |<--'\n|   |   '---'   |   |   '---'\n'---'           '---'\n[[/code]]\n\nSo small to medium application developers are trapped. Either they avoid network programming and make monolithic applications that do not scale. Or they jump into network programming and make brittle, complex applications that are hard to maintain. Or they bet on a messaging product, and end up with scalable applications that depend on expensive, easily broken technology. There has been no really good choice, which is maybe why messaging is largely stuck in the last century and stirs strong emotions: negative ones for users, gleeful joy for those selling support and licenses[figure].\n\nWhat we need is something that does the job of messaging, but does it in such a simple and cheap way that it can work in any application, with close to zero cost. It should be a library which you just link, without any other dependencies. No additional moving pieces, so no additional risk. It should run on any OS and work with any programming language.\n\nAnd this is ZeroMQ: an efficient, embeddable library that solves most of the problems an application needs to become nicely elastic across a network, without much cost.\n\nSpecifically:\n\n* It handles I/O asynchronously, in background threads. These communicate with application threads using lock-free data structures, so concurrent ZeroMQ applications need no locks, semaphores, or other wait states.\n\n* Components can come and go dynamically and ZeroMQ will automatically reconnect (except for PAIR sockets). This means you can start components in any order. You can create \"service-oriented architectures\" (SOAs) where services can join and leave the network at any time.\n\n* It queues messages automatically when needed. It does this intelligently, pushing messages as close as possible to the receiver before queuing them.\n\n* It has ways of dealing with over-full queues (called \"high water mark\"). When a queue is full, ZeroMQ automatically blocks senders, or throws away messages, depending on the kind of messaging you are doing (the so-called \"pattern\").\n\n* It lets your applications talk to each other over arbitrary transports: TCP, multicast, in-process, inter-process. You don't need to change your code to use a different transport.\n\n* It handles slow/blocked readers safely, using different strategies that depend on the messaging pattern.\n\n* It lets you route messages using a variety of patterns such as request-reply and pub-sub. These patterns are how you create the topology, the structure of your network.\n\n* It lets you create proxies to queue, forward, or capture messages with a single call. Proxies can reduce the interconnection complexity of a network.\n\n* It delivers whole messages exactly as they were sent, using a simple framing on the wire. If you write a 10k message, you will receive a 10k message.\n\n* It does not impose any format on messages. They are blobs from zero to gigabytes large. When you want to represent data you choose some other product on top, such as msgpack, Google's protocol buffers, and others.\n\n* It handles network errors intelligently, by retrying automatically in cases where it makes sense.\n\n* It reduces your carbon footprint. Doing more with less CPU means your boxes use less power, and you can keep your old boxes in use for longer. Al Gore would love ZeroMQ.\n\nActually ZeroMQ does rather more than this. It has a subversive effect on how you develop network-capable applications. Superficially, it's a socket-inspired API on which you do {{zmq_recv[3]}} and {{zmq_send[3]}}. But message processing rapidly becomes the central loop, and your application soon breaks down into a set of message processing tasks. It is elegant and natural. And it scales: each of these tasks maps to a node, and the nodes talk to each other across arbitrary transports. Two nodes in one process (node is a thread), two nodes on one box (node is a process), or two nodes on one network (node is a box)--it's all the same, with no application code changes.\n\n++ Socket Scalability\n\nLet's see ZeroMQ's scalability in action. Here is a shell script that starts the weather server and then a bunch of clients in parallel:\n\n[[code]]\nwuserver &\nwuclient 12345 &\nwuclient 23456 &\nwuclient 34567 &\nwuclient 45678 &\nwuclient 56789 &\n[[/code]]\n\nAs the clients run, we take a look at the active processes using the {{top}} command', and we see something like (on a 4-core box):\n\n[[code]]\nPID  USER  PR  NI  VIRT  RES  SHR S %CPU %MEM   TIME+  COMMAND\n7136  ph   20   0 1040m 959m 1156 R  157 12.0 16:25.47 wuserver\n7966  ph   20   0 98608 1804 1372 S   33  0.0  0:03.94 wuclient\n7963  ph   20   0 33116 1748 1372 S   14  0.0  0:00.76 wuclient\n7965  ph   20   0 33116 1784 1372 S    6  0.0  0:00.47 wuclient\n7964  ph   20   0 33116 1788 1372 S    5  0.0  0:00.25 wuclient\n7967  ph   20   0 33072 1740 1372 S    5  0.0  0:00.35 wuclient\n[[/code]]\n\nLet's think for a second about what is happening here. The weather server has a single socket, and yet here we have it sending data to five clients in parallel. We could have thousands of concurrent clients. The server application doesn't see them, doesn't talk to them directly. So the ZeroMQ socket is acting like a little server, silently accepting client requests and shoving data out to them as fast as the network can handle it. And it's a multithreaded server, squeezing more juice out of your CPU.\n\n++ Upgrading from ZeroMQ v2.2 to ZeroMQ v3.2\n\n+++ Compatible Changes\n\nThese changes don't impact existing application code directly:\n\n* Pub-sub filtering is now done at the publisher side instead of subscriber side. This improves performance significantly in many pub-sub use cases. You can mix v3.2 and v2.1/v2.2 publishers and subscribers safely.\n\n* ZeroMQ v3.2 has many new API methods ({{zmq_disconnect[3]}}, {{zmq_unbind[3]}}, {{zmq_monitor[3]}}, {{zmq_ctx_set[3]}}, etc.)\n\n+++ Incompatible Changes\n\nThese are the main areas of impact on applications and language bindings:\n\n* Changed send/recv methods: {{zmq_send[3]}} and {{zmq_recv[3]}} have a different, simpler interface, and the old functionality is now provided by {{zmq_msg_send[3]}} and {{zmq_msg_recv[3]}}. Symptom: compile errors. Solution: fix up your code.\n\n* These two methods return positive values on success, and -1 on error. In v2.x they always returned zero on success. Symptom: apparent errors when things actually work fine. Solution: test strictly for return code = -1, not non-zero.\n\n* {{zmq_poll[3]}} now waits for milliseconds, not microseconds. Symptom: application stops responding (in fact responds 1000 times slower). Solution: use the {{ZMQ_POLL_MSEC}} macro defined below, in all {{zmq_poll}} calls.\n\n* {{ZMQ_NOBLOCK}} is now called {{ZMQ_DONTWAIT}}. Symptom: compile failures on the {{ZMQ_NOBLOCK}} macro.\n\n* The {{ZMQ_HWM}} socket option is now broken into {{ZMQ_SNDHWM}} and {{ZMQ_RCVHWM}}.  Symptom: compile failures on the {{ZMQ_HWM}} macro.\n\n* Most but not all {{zmq_getsockopt[3]}} options are now integer values. Symptom: runtime error returns on {{zmq_setsockopt}} and {{zmq_getsockopt}}.\n\n* The {{ZMQ_SWAP}} option has been removed. Symptom: compile failures on {{ZMQ_SWAP}}. Solution: redesign any code that uses this functionality.\n\n+++ Suggested Shim Macros\n\nFor applications that want to run on both v2.x and v3.2, such as language bindings, our advice is to emulate v3.2 as far as possible. Here are C macro definitions that help your C/C++ code to work across both versions (taken from [http://czmq.zeromq.org CZMQ]):\n\n[[code type=\"fragment\" name=\"upgrade-shim\"]]\n#ifndef ZMQ_DONTWAIT\n#   define ZMQ_DONTWAIT     ZMQ_NOBLOCK\n#endif\n#if ZMQ_VERSION_MAJOR == 2\n#   define zmq_msg_send(msg,sock,opt) zmq_send (sock, msg, opt)\n#   define zmq_msg_recv(msg,sock,opt) zmq_recv (sock, msg, opt)\n#   define zmq_ctx_destroy(context) zmq_term(context)\n#   define ZMQ_POLL_MSEC    1000        //  zmq_poll is usec\n#   define ZMQ_SNDHWM ZMQ_HWM\n#   define ZMQ_RCVHWM ZMQ_HWM\n#elif ZMQ_VERSION_MAJOR == 3\n#   define ZMQ_POLL_MSEC    1           //  zmq_poll is msec\n#endif\n[[/code]]\n\n++ Warning: Unstable Paradigms!\n\nTraditional network programming is built on the general assumption that one socket talks to one connection, one peer. There are multicast protocols, but these are exotic. When we assume \"one socket = one connection\", we scale our architectures in certain ways. We create threads of logic where each thread work with one socket, one peer. We place intelligence and state in these threads.\n\nIn the ZeroMQ universe, sockets are doorways to fast little background communications engines that manage a whole set of connections automagically for you. You can't see, work with, open, close, or attach state to these connections. Whether you use blocking send or receive, or poll, all you can talk to is the socket, not the connections it manages for you. The connections are private and invisible, and this is the key to ZeroMQ's scalability.\n\nThis is because your code, talking to a socket, can then handle any number of connections across whatever network protocols are around, without change. A messaging pattern sitting in ZeroMQ scales more cheaply than a messaging pattern sitting in your application code.\n\nSo the general assumption no longer applies. As you read the code examples, your brain will try to map them to what you know. You will read \"socket\" and think \"ah, that represents a connection to another node\". That is wrong. You will read \"thread\" and your brain will again think, \"ah, a thread represents a connection to another node\", and again your brain will be wrong.\n\nIf you're reading this Guide for the first time, realize that until you actually write ZeroMQ code for a day or two (and maybe three or four days), you may feel confused, especially by how simple ZeroMQ makes things for you, and you may try to impose that general assumption on ZeroMQ, and it won't work. And then you will experience your moment of enlightenment and trust, that //zap-pow-kaboom// satori paradigm-shift moment when it all becomes clear.\n"
        },
        {
          "name": "chapter2.txt",
          "type": "blob",
          "size": 81.501953125,
          "content": ".output chapter2.wd\n.bookmark sockets-and-patterns\n+ Sockets and Patterns\n\nIn [#basics] we took ZeroMQ for a drive, with some basic examples of the main ZeroMQ patterns: request-reply, pub-sub, and pipeline. In this chapter, we're going to get our hands dirty and start to learn how to use these tools in real programs.\n\nWe'll cover:\n\n* How to create and work with ZeroMQ sockets.\n* How to send and receive messages on sockets.\n* How to build your apps around ZeroMQ's asynchronous I/O model.\n* How to handle multiple sockets in one thread.\n* How to handle fatal and nonfatal errors properly.\n* How to handle interrupt signals like Ctrl-C.\n* How to shut down a ZeroMQ application cleanly.\n* How to check a ZeroMQ application for memory leaks.\n* How to send and receive multipart messages.\n* How to forward messages across networks.\n* How to build a simple message queuing broker.\n* How to write multithreaded applications with ZeroMQ.\n* How to use ZeroMQ to signal between threads.\n* How to use ZeroMQ to coordinate a network of nodes.\n* How to create and use message envelopes for pub-sub.\n* Using the HWM (high-water mark) to protect against memory overflows.\n\n++ The Socket API\n\nTo be perfectly honest, ZeroMQ does a kind of switch-and-bait on you, for which we don't apologize. It's for your own good and it hurts us more than it hurts you. ZeroMQ presents a familiar socket-based API, which requires great effort for us to hide a bunch of message-processing engines. However, the result will slowly fix your world view about how to design and write distributed software.\n\nSockets are the de facto standard API for network programming, as well as being useful for stopping your eyes from falling onto your cheeks. One thing that makes ZeroMQ especially tasty to developers is that it uses sockets and messages instead of some other arbitrary set of concepts. Kudos to Martin Sustrik for pulling this off. It turns \"Message Oriented Middleware\", a phrase guaranteed to send the whole room off to Catatonia, into \"Extra Spicy Sockets!\", which leaves us with a strange craving for pizza and a desire to know more.\n\nLike a favorite dish, ZeroMQ sockets are easy to digest. Sockets have a life in four parts, just like BSD sockets:\n\n* Creating and destroying sockets, which go together to form a karmic circle of socket life (see {{zmq_socket[3]}}, {{zmq_close[3]}}).\n\n* Configuring sockets by setting options on them and checking them if necessary (see {{zmq_setsockopt[3]}}, {{zmq_getsockopt[3]}}).\n\n* Plugging sockets into the network topology by creating ZeroMQ connections to and from them (see {{zmq_bind[3]}}, {{zmq_connect[3]}}).\n\n* Using the sockets to carry data by writing and receiving messages on them (see {{zmq_msg_send[3]}}, {{zmq_msg_recv[3]}}).\n\nNote that sockets are always void pointers, and messages (which we'll come to very soon) are structures. So in C you pass sockets as-such, but you pass addresses of messages in all functions that work with messages, like {{zmq_msg_send[3]}} and {{zmq_msg_recv[3]}}. As a mnemonic, realize that \"in ZeroMQ, all your sockets are belong to us\", but messages are things you actually own in your code.\n\nCreating, destroying, and configuring sockets works as you'd expect for any object. But remember that ZeroMQ is an asynchronous, elastic fabric. This has some impact on how we plug sockets into the network topology and how we use the sockets after that.\n\n+++ Plugging Sockets into the Topology\n\nTo create a connection between two nodes, you use {{zmq_bind[3]}} in one node and {{zmq_connect[3]}} in the other.  As a general rule of thumb, the node that does {{zmq_bind[3]}} is a \"server\", sitting on a well-known network address, and the node which does {{zmq_connect[3]}} is a \"client\", with unknown or arbitrary network addresses. Thus we say that we \"bind a socket to an endpoint\" and \"connect a socket to an endpoint\", the endpoint being that well-known network address.\n\nZeroMQ connections are somewhat different from classic TCP connections. The main notable differences are:\n\n* They go across an arbitrary transport ({{inproc}}, {{ipc}}, {{tcp}}, {{pgm}}, or {{epgm}}). See {{zmq_inproc[7]}}, {{zmq_ipc[7]}}, {{zmq_tcp[7]}}, {{zmq_pgm[7]}}, and {{zmq_epgm[7]}}.\n\n* One socket may have many outgoing and many incoming connections.\n\n* There is no {{zmq_accept}}() method. When a socket is bound to an endpoint it automatically starts accepting connections.\n\n* The network connection itself happens in the background, and ZeroMQ will automatically reconnect (except for PAIR sockets) if the network connection is broken (e.g., if the peer disappears and then comes back).\n\n* Your application code cannot work with these connections directly; they are encapsulated under the socket.\n\nMany architectures follow some kind of client/server model, where the server is the component that is most static, and the clients are the components that are most dynamic, i.e., they come and go the most. There are sometimes issues of addressing: servers will be visible to clients, but not necessarily vice versa. So mostly it's obvious which node should be doing {{zmq_bind[3]}} (the server) and which should be doing {{zmq_connect[3]}} (the client). It also depends on the kind of sockets you're using, with some exceptions for unusual network architectures. We'll look at socket types later.\n\nNow, imagine we start the client //before// we start the server. In traditional networking, we get a big red Fail flag. But ZeroMQ lets us start and stop pieces arbitrarily. As soon as the client node does {{zmq_connect[3]}}, the connection exists and that node can start to write messages to the socket. At some stage (hopefully before messages queue up so much that they start to get discarded, or the client blocks), the server comes alive, does a {{zmq_bind[3]}}, and ZeroMQ starts to deliver messages.\n\nA server node can bind to many endpoints (that is, a combination of protocol and address) and it can do this using a single socket. This means it will accept connections across different transports:\n\n[[code type=\"fragment\" name=\"binding\"]]\nzmq_bind (socket, \"tcp://*:5555\");\nzmq_bind (socket, \"tcp://*:9999\");\nzmq_bind (socket, \"inproc://somename\");\n[[/code]]\n\nWith most transports, you cannot bind to the same endpoint twice, unlike for example in UDP. The {{ipc}} transport does, however, let one process bind to an endpoint already used by a first process. It's meant to allow a process to recover after a crash.\n\nAlthough ZeroMQ tries to be neutral about which side binds and which side connects, there are differences. We'll see these in more detail later. The upshot is that you should usually think in terms of \"servers\" as static parts of your topology that bind to more or less fixed endpoints, and \"clients\" as dynamic parts that come and go and connect to these endpoints. Then, design your application around this model. The chances that it will \"just work\" are much better like that.\n\nSockets have types. The socket type defines the semantics of the socket, its policies for routing messages inwards and outwards, queuing, etc. You can connect certain types of socket together, e.g., a publisher socket and a subscriber socket. Sockets work together in \"messaging patterns\". We'll look at this in more detail later.\n\nIt's the ability to connect sockets in these different ways that gives ZeroMQ its basic power as a message queuing system. There are layers on top of this, such as proxies, which we'll get to later. But essentially, with ZeroMQ you define your network architecture by plugging pieces together like a child's construction toy.\n\n+++ Sending and Receiving Messages\n\nTo send and receive messages you use the {{zmq_msg_send[3]}} and {{zmq_msg_recv[3]}} methods. The names are conventional, but ZeroMQ's I/O model is different enough from the classic TCP model[figure] that you will need time to get your head around it.\n\n[[code type=\"textdiagram\" title=\"TCP sockets are 1 to 1\"]]\n#------------#\n|    Node    |\n+------------+\n|   Socket   |\n'------------'\n      ^\n      |\n      | 1 to 1\n      |\n      v\n.------------.\n|   Socket   |\n+------------+\n|    Node    |\n#------------#\n[[/code]]\n\nLet's look at the main differences between TCP sockets and ZeroMQ sockets when it comes to working with data:\n\n* ZeroMQ sockets carry messages, like UDP, rather than a stream of bytes as TCP does. A ZeroMQ message is length-specified binary data. We'll come to messages shortly; their design is optimized for performance and so a little tricky.\n\n* ZeroMQ sockets do their I/O in a background thread. This means that messages arrive in local input queues and are sent from local output queues, no matter what your application is busy doing.\n\n* ZeroMQ sockets have one-to-N routing behavior built-in, according to the socket type.\n\nThe {{zmq_msg_send[3]}} method does not actually send the message to the socket connection(s). It queues the message so that the I/O thread can send it asynchronously. It does not block except in some exception cases. So the message is not necessarily sent when {{zmq_msg_send[3]}} returns to your application.\n\n+++ Unicast Transports\n\nZeroMQ provides a set of unicast transports ({{inproc}}, {{ipc}}, and {{tcp}}) and multicast transports (epgm, pgm). Multicast is an advanced technique that we'll come to later. Don't even start using it unless you know that your fan-out ratios will make 1-to-N unicast impossible.\n\nFor most common cases, use **{{tcp}}**, which is a //disconnected TCP// transport. It is elastic, portable, and fast enough for most cases. We call this disconnected because ZeroMQ's {{tcp}} transport doesn't require that the endpoint exists before you connect to it. Clients and servers can connect and bind at any time, can go and come back, and it remains transparent to applications.\n\nThe inter-process {{ipc}} transport is disconnected, like {{tcp}}. It has one limitation: it does not yet work on Windows. By convention we use endpoint names with an \".ipc\" extension to avoid potential conflict with other file names. On UNIX systems, if you use {{ipc}} endpoints you need to create these with appropriate permissions otherwise they may not be shareable between processes running under different user IDs. You must also make sure all processes can access the files, e.g., by running in the same working directory.\n\nThe inter-thread transport, **{{inproc}}**, is a connected signaling transport. It is much faster than {{tcp}} or {{ipc}}. This transport has a specific limitation compared to {{tcp}} and {{ipc}}: **the server must issue a bind before any client issues a connect**. This is something future versions of ZeroMQ may fix, but at present this defines how you use {{inproc}} sockets. We create and bind one socket and start the child threads, which create and connect the other sockets.\n\n+++ ZeroMQ is Not a Neutral Carrier\n\nA common question that newcomers to ZeroMQ ask (it's one I've asked myself) is, \"how do I write an XYZ server in ZeroMQ?\" For example, \"how do I write an HTTP server in ZeroMQ?\" The implication is that if we use normal sockets to carry HTTP requests and responses, we should be able to use ZeroMQ sockets to do the same, only much faster and better.\n\nThe answer used to be \"this is not how it works\". ZeroMQ is not a neutral carrier: it imposes a framing on the transport protocols it uses. This framing is not compatible with existing protocols, which tend to use their own framing. For example, compare an HTTP request and a ZeroMQ request, both over TCP/IP.\n\n[[code type=\"textdiagram\" title=\"HTTP on the Wire\"]]\n#----------------+----+----+----+----#\n| GET /index.html| 13 | 10 | 13 | 10 |\n#----------------+----+----+----+----#\n[[/code]]\n\nThe HTTP request uses CR-LF as its simplest framing delimiter[figure], whereas ZeroMQ uses a length-specified frame[figure]. So you could write an HTTP-like protocol using ZeroMQ, using for example the request-reply socket pattern. But it would not be HTTP.\n\n[[code type=\"textdiagram\" title=\"ZeroMQ on the Wire\"]]\n#---+---+---+---+---+---#\n| 5 | H | E | L | L | O |\n#---+---+---+---+---+---#\n[[/code]]\n\nSince v3.3, however, ZeroMQ has a socket option called {{ZMQ_ROUTER_RAW}} that lets you read and write data without the ZeroMQ framing. You could use this to read and write proper HTTP requests and responses. Hardeep Singh contributed this change so that he could connect to Telnet servers from his ZeroMQ application. At time of writing this is still somewhat experimental, but it shows how ZeroMQ keeps evolving to solve new problems. Maybe the next patch will be yours.\n\n+++ I/O Threads\n\nWe said that ZeroMQ does I/O in a background thread. One I/O thread (for all sockets) is sufficient for all but the most extreme applications. When you create a new context, it starts with one I/O thread. The general rule of thumb is to allow one I/O thread per gigabyte of data in or out per second. To raise the number of I/O threads, use the {{zmq_ctx_set[3]}} call //before// creating any sockets:\n\n[[code type=\"fragment\" name=\"iothreads\"]]\nint io_threads = 4;\nvoid *context = zmq_ctx_new ();\nzmq_ctx_set (context, ZMQ_IO_THREADS, io_threads);\nassert (zmq_ctx_get (context, ZMQ_IO_THREADS) == io_threads);\n[[/code]]\n\nWe've seen that one socket can handle dozens, even thousands of connections at once. This has a fundamental impact on how you write applications. A traditional networked application has one process or one thread per remote connection, and that process or thread handles one socket. ZeroMQ lets you collapse this entire structure into a single process and then break it up as necessary for scaling.\n\nIf you are using ZeroMQ for inter-thread communications only (i.e., a multithreaded application that does no external socket I/O) you can set the I/O threads to zero. It's not a significant optimization though, more of a curiosity.\n\n++ Messaging Patterns\n\nUnderneath the brown paper wrapping of ZeroMQ's socket API lies the world of messaging patterns. If you have a background in enterprise messaging, or know UDP well, these will be vaguely familiar. But to most ZeroMQ newcomers, they are a surprise. We're so used to the TCP paradigm where a socket maps one-to-one to another node.\n\nLet's recap briefly what ZeroMQ does for you. It delivers blobs of data (messages) to nodes, quickly and efficiently. You can map nodes to threads, processes, or nodes. ZeroMQ gives your applications a single socket API to work with, no matter what the actual transport (like in-process, inter-process, TCP, or multicast). It automatically reconnects (except for PAIR sockets) to peers as they come and go. It queues messages at both sender and receiver, as needed. It limits these queues to guard processes against running out of memory. It handles socket errors. It does all I/O in background threads. It uses lock-free techniques for talking between nodes, so there are never locks, waits, semaphores, or deadlocks.\n\nBut cutting through that, it routes and queues messages according to precise recipes called //patterns//. It is these patterns that provide ZeroMQ's intelligence. They encapsulate our hard-earned experience of the best ways to distribute data and work. ZeroMQ's patterns are hard-coded but future versions may allow user-definable patterns.\n\nZeroMQ patterns are implemented by pairs of sockets with matching types. In other words, to understand ZeroMQ patterns you need to understand socket types and how they work together. Mostly, this just takes study; there is little that is obvious at this level.\n\nThe built-in core ZeroMQ patterns are:\n\n* **Request-reply**, which connects a set of clients to a set of services. This is a remote procedure call and task distribution pattern.\n\n* **Pub-sub**, which connects a set of publishers to a set of subscribers. This is a data distribution pattern.\n\n* **Pipeline**, which connects nodes in a fan-out/fan-in pattern that can have multiple steps and loops. This is a parallel task distribution and collection pattern.\n\n* **Exclusive pair**, which connects two sockets exclusively. This is a pattern for connecting two threads in a process, not to be confused with \"normal\" pairs of sockets.\n\nWe looked at the first three of these in [#basics], and we'll see the exclusive pair pattern later in this chapter. The {{zmq_socket[3]}} man page is fairly clear about the patterns -- it's worth reading several times until it starts to make sense. These are the socket combinations that are valid for a connect-bind pair (either side can bind):\n\n* PUB and SUB\n* REQ and REP\n* REQ and ROUTER (take care, REQ inserts an extra null frame)\n* DEALER and REP (take care, REP assumes a null frame)\n* DEALER and ROUTER\n* DEALER and DEALER\n* ROUTER and ROUTER\n* PUSH and PULL\n* PAIR and PAIR\n\nYou'll also see references to XPUB and XSUB sockets, which we'll come to later (they're like raw versions of PUB and SUB). Any other combination will produce undocumented and unreliable results, and future versions of ZeroMQ will probably return errors if you try them. You can and will, of course, bridge other socket types via code, i.e., read from one socket type and write to another.\n\n+++ High-Level Messaging Patterns\n\nThese four core patterns are cooked into ZeroMQ. They are part of the ZeroMQ API, implemented in the core C++ library, and are guaranteed to be available in all fine retail stores.\n\nOn top of those, we add //high-level messaging patterns//. We build these high-level patterns on top of ZeroMQ and implement them in whatever language we're using for our application. They are not part of the core library, do not come with the ZeroMQ package, and exist in their own space as part of the ZeroMQ community. For example the Majordomo pattern, which we explore in [#reliable-request-reply], sits in the GitHub Majordomo project in the ZeroMQ organization.\n\nOne of the things we aim to provide you with in this book are a set of such high-level patterns, both small (how to handle messages sanely) and large (how to make a reliable pub-sub architecture).\n\n+++ Working with Messages\n\nThe {{libzmq}} core library has in fact two APIs to send and receive messages. The {{zmq_send[3]}} and {{zmq_recv[3]}} methods that we've already seen and used are simple one-liners. We will use these often, but {{zmq_recv[3]}} is bad at dealing with arbitrary message sizes: it truncates messages to whatever buffer size you provide. So there's a second API that works with zmq_msg_t structures, with a richer but more difficult API:\n\n* Initialise a message: {{zmq_msg_init[3]}}, {{zmq_msg_init_size[3]}}, {{zmq_msg_init_data[3]}}.\n* Sending and receiving a message: {{zmq_msg_send[3]}}, {{zmq_msg_recv[3]}}.\n* Release a message: {{zmq_msg_close[3]}}.\n* Access message content: {{zmq_msg_data[3]}}, {{zmq_msg_size[3]}}, {{zmq_msg_more[3]}}.\n* Work with message properties: {{zmq_msg_get[3]}}, {{zmq_msg_set[3]}}.\n* Message manipulation: {{zmq_msg_copy[3]}}, {{zmq_msg_move[3]}}.\n\nOn the wire, ZeroMQ messages are blobs of any size from zero upwards that fit in memory. You do your own serialization using protocol buffers, msgpack, JSON, or whatever else your applications need to speak. It's wise to choose a data representation that is portable, but you can make your own decisions about trade-offs.\n\nIn memory, ZeroMQ messages are {{zmq_msg_t}} structures (or classes depending on your language). Here are the basic ground rules for using ZeroMQ messages in C:\n\n* You create and pass around {{zmq_msg_t}} objects, not blocks of data.\n\n* To read a message, you use {{zmq_msg_init[3]}} to create an empty message, and then you pass that to {{zmq_msg_recv[3]}}.\n\n* To write a message from new data, you use {{zmq_msg_init_size[3]}} to create a message and at the same time allocate a block of data of some size. You then fill that data using {{memcpy}}, and pass the message to {{zmq_msg_send[3]}}.\n\n* To release (not destroy) a message, you call {{zmq_msg_close[3]}}. This drops a reference, and eventually ZeroMQ will destroy the message.\n\n* To access the message content, you use {{zmq_msg_data[3]}}. To know how much data the message contains, use {{zmq_msg_size[3]}}.\n\n* Do not use {{zmq_msg_move[3]}}, {{zmq_msg_copy[3]}}, or {{zmq_msg_init_data[3]}} unless you read the man pages and know precisely why you need these.\n\n* After you pass a message to {{zmq_msg_send[3]}}, ØMQ will clear the message, i.e., set the size to zero. You cannot send the same message twice, and you cannot access the message data after sending it.\n\n* These rules don't apply if you use {{zmq_send[3]}} and {{zmq_recv[3]}}, to which you pass byte arrays, not message structures.\n\nIf you want to send the same message more than once, and it's sizable, create a second message, initialize it using {{zmq_msg_init[3]}}, and then use {{zmq_msg_copy[3]}} to create a copy of the first message. This does not copy the data but copies a reference. You can then send the message twice (or more, if you create more copies) and the message will only be finally destroyed when the last copy is sent or closed.\n\nZeroMQ also supports //multipart// messages, which let you send or receive a list of frames as a single on-the-wire message. This is widely used in real applications and we'll look at that later in this chapter and in [#advanced-request-reply].\n\nFrames (also called \"message parts\" in the ZeroMQ reference manual pages) are the basic wire format for ZeroMQ messages. A frame is a length-specified block of data. The length can be zero upwards. If you've done any TCP programming you'll appreciate why frames are a useful answer to the question \"how much data am I supposed to read of this network socket now?\"\n\nThere is a wire-level [http://rfc.zeromq.org/spec:15 protocol called ZMTP] that defines how ZeroMQ reads and writes frames on a TCP connection. If you're interested in how this works, the spec is quite short.\n\nOriginally, a ZeroMQ message was one frame, like UDP. We later extended this with multipart messages, which are quite simply series of frames with a \"more\" bit set to one, followed by one with that bit set to zero. The ZeroMQ API then lets you write messages with a \"more\" flag and when you read messages, it lets you check if there's \"more\".\n\nIn the low-level ZeroMQ API and the reference manual, therefore, there's some fuzziness about messages versus frames. So here's a useful lexicon:\n\n* A message can be one or more parts.\n* These parts are also called \"frames\".\n* Each part is a {{zmq_msg_t}} object.\n* You send and receive each part separately, in the low-level API.\n* Higher-level APIs provide wrappers to send entire multipart messages.\n\nSome other things that are worth knowing about messages:\n\n* You may send zero-length messages, e.g., for sending a signal from one thread to another.\n\n* ZeroMQ guarantees to deliver all the parts (one or more) for a message, or none of them.\n\n* ZeroMQ does not send the message (single or multipart) right away, but at some indeterminate later time. A multipart message must therefore fit in memory.\n\n* A message (single or multipart) must fit in memory. If you want to send files of arbitrary sizes, you should break them into pieces and send each piece as separate single-part messages. //Using multipart data will not reduce memory consumption.//\n\n* You must call {{zmq_msg_close[3]}} when finished with a received message, in languages that don't automatically destroy objects when a scope closes. You don't call this method after sending a message.\n\nAnd to be repetitive, do not use {{zmq_msg_init_data[3]}} yet. This is a zero-copy method and is guaranteed to create trouble for you. There are far more important things to learn about ZeroMQ before you start to worry about shaving off microseconds.\n\nThis rich API can be tiresome to work with. The methods are optimized for performance, not simplicity. If you start using these you will almost definitely get them wrong until you've read the man pages with some care. So one of the main jobs of a good language binding is to wrap this API up in classes that are easier to use.\n\n+++ Handling Multiple Sockets\n\nIn all the examples so far, the main loop of most examples has been:\n\n# Wait for message on socket.\n# Process message.\n# Repeat.\n\nWhat if we want to read from multiple endpoints at the same time? The simplest way is to connect one socket to all the endpoints and get ZeroMQ to do the fan-in for us. This is legal if the remote endpoints are in the same pattern, but it would be wrong to connect a PULL socket to a PUB endpoint.\n\nTo actually read from multiple sockets all at once, use {{zmq_poll[3]}}. An even better way might be to wrap {{zmq_poll[3]}} in a framework that turns it into a nice event-driven //reactor//, but it's significantly more work than we want to cover here.\n\nLet's start with a dirty hack, partly for the fun of not doing it right, but mainly because it lets me show you how to do nonblocking socket reads. Here is a simple example of reading from two sockets using nonblocking reads. This rather confused program acts both as a subscriber to weather updates, and a worker for parallel tasks:\n\n[[code type=\"example\" title=\"Multiple socket reader\" name=\"msreader\"]]\n[[/code]]\n\nThe cost of this approach is some additional latency on the first message (the sleep at the end of the loop, when there are no waiting messages to process). This would be a problem in applications where submillisecond latency was vital. Also, you need to check the documentation for nanosleep() or whatever function you use to make sure it does not busy-loop.\n\nYou can treat the sockets fairly by reading first from one, then the second rather than prioritizing them as we did in this example.\n\nNow let's see the same senseless little application done right, using {{zmq_poll[3]}}:\n\n[[code type=\"example\" title=\"Multiple socket poller\" name=\"mspoller\"]]\n[[/code]]\n\nThe items structure has these four members:\n\n[[code language=\"C\"]]\ntypedef struct {\n    void *socket;       //  ZeroMQ socket to poll on\n    int fd;             //  OR, native file handle to poll on\n    short events;       //  Events to poll on\n    short revents;      //  Events returned after poll\n} zmq_pollitem_t;\n[[/code]]\n\n+++ Multipart Messages\n\nZeroMQ lets us compose a message out of several frames, giving us a \"multipart message\". Realistic applications use multipart messages heavily, both for wrapping messages with address information and for simple serialization. We'll look at reply envelopes later.\n\nWhat we'll learn now is simply how to blindly and safely read and write multipart messages in any application (such as a proxy) that needs to forward messages without inspecting them.\n\nWhen you work with multipart messages, each part is a {{zmq_msg}} item. E.g., if you are sending a message with five parts, you must construct, send, and destroy five {{zmq_msg}} items. You can do this in advance (and store the {{zmq_msg}} items in an array or other structure), or as you send them, one-by-one.\n\nHere is how we send the frames in a multipart message (we receive each frame into a message object):\n\n[[code type=\"fragment\" name=\"sendmore\"]]\nzmq_msg_send (&message, socket, ZMQ_SNDMORE);\n...\nzmq_msg_send (&message, socket, ZMQ_SNDMORE);\n...\nzmq_msg_send (&message, socket, 0);\n[[/code]]\n\nHere is how we receive and process all the parts in a message, be it single part or multipart:\n\n[[code type=\"fragment\" name=\"recvmore\"]]\nwhile (1) {\n    zmq_msg_t message;\n    zmq_msg_init (&message);\n    zmq_msg_recv (&message, socket, 0);\n    //  Process the message frame\n    ...\n    zmq_msg_close (&message);\n    if (!zmq_msg_more (&message))\n        break;      //  Last message frame\n}\n[[/code]]\n\nSome things to know about multipart messages:\n\n* When you send a multipart message, the first part (and all following parts) are only actually sent on the wire when you send the final part.\n* If you are using {{zmq_poll[3]}}, when you receive the first part of a message, all the rest has also arrived.\n* You will receive all parts of a message, or none at all.\n* Each part of a message is a separate {{zmq_msg}} item.\n* You will receive all parts of a message whether or not you check the more property.\n* On sending, ZeroMQ queues message frames in memory until the last is received, then sends them all.\n* There is no way to cancel a partially sent message, except by closing the socket.\n\n+++ Intermediaries and Proxies\n\nZeroMQ aims for decentralized intelligence, but that doesn't mean your network is empty space in the middle. It's filled with message-aware infrastructure and quite often, we build that infrastructure with ZeroMQ. The ZeroMQ plumbing can range from tiny pipes to full-blown service-oriented brokers. The messaging industry calls this //intermediation//, meaning that the stuff in the middle deals with either side. In ZeroMQ, we call these proxies, queues, forwarders, device, or brokers, depending on the context.\n\nThis pattern is extremely common in the real world and is why our societies and economies are filled with intermediaries who have no other real function than to reduce the complexity and scaling costs of larger networks. Real-world intermediaries are typically called wholesalers, distributors, managers, and so on.\n\n+++ The Dynamic Discovery Problem\n\nOne of the problems you will hit as you design larger distributed architectures is discovery. That is, how do pieces know about each other? It's especially difficult if pieces come and go, so we call this the \"dynamic discovery problem\".\n\nThere are several solutions to dynamic discovery. The simplest is to entirely avoid it by hard-coding (or configuring) the network architecture so discovery is done by hand. That is, when you add a new piece, you reconfigure the network to know about it.\n\n[[code type=\"textdiagram\" title=\"Small-Scale Pub-Sub Network\"]]\n                 #-----------#\n                 | Publisher |\n                 +-----------+\n                 |    PUB    |\n                 '-----------'\n                     bind\n           tcp://192.168.55.210:5556\n                       |\n                       |\n      .----------------+----------------.\n      |                |                |\n      |                |                |\n   connect           connect          connect\n.------------.   .------------.   .------------.\n|    SUB     |   |    SUB     |   |    SUB     |\n+------------+   +------------+   +------------+\n| Subscriber |   | Subscriber |   | Subscriber |\n#------------#   #------------#   #------------#\n[[/code]]\n\nIn practice, this leads to increasingly fragile and unwieldy architectures. Let's say you have one publisher and a hundred subscribers. You connect each subscriber to the publisher by configuring a publisher endpoint in each subscriber. That's easy[figure]. Subscribers are dynamic; the publisher is static. Now say you add more publishers. Suddenly, it's not so easy any more. If you continue to connect each subscriber to each publisher, the cost of avoiding dynamic discovery gets higher and higher.\n\n[[code type=\"textdiagram\" title=\"Pub-Sub Network with a Proxy\"]]\n#------------#   #------------#   #------------#\n| Publisher  |   | Publisher  |   | Publisher  |\n+------------+   +------------+   +------------+\n|    PUB     |   |    PUB     |   |    PUB     |\n'------------'   '------------'   '------------'\n   connect          connect          connect\n      |                |                |\n      '----------------+----------------'\n                       |\n                      bind\n                 .------------.\n                 |    XSUB    |\n                 +------------+\n                 |   Proxy    |\n                 +------------+\n                 |    XPUB    |\n                 '------------'\n                      bind\n                       |\n      .----------------+----------------.\n      |                |                |\n   connect           connect          connect\n.------------.   .------------.   .------------.\n|    SUB     |   |    SUB     |   |    SUB     |\n+------------+   +------------+   +------------+\n| Subscriber |   | Subscriber |   | Subscriber |\n#------------#   #------------#   #------------#\n[[/code]]\n\nThere are quite a few answers to this, but the very simplest answer is to add an intermediary; that is, a static point in the network to which all other nodes connect. In classic messaging, this is the job of the message broker. ZeroMQ doesn't come with a message broker as such, but it lets us build intermediaries quite easily.\n\nYou might wonder, if all networks eventually get large enough to need intermediaries, why don't we simply have a message broker in place for all applications? For beginners, it's a fair compromise. Just always use a star topology, forget about performance, and things will usually work. However, message brokers are greedy things; in their role as central intermediaries, they become too complex, too stateful, and eventually a problem.\n\nIt's better to think of intermediaries as simple stateless message switches. A good analogy is an HTTP proxy; it's there, but doesn't have any special role. Adding a pub-sub proxy solves the dynamic discovery problem in our example. We set the proxy in the \"middle\" of the network[figure]. The proxy opens an XSUB socket, an XPUB socket, and binds each to well-known IP addresses and ports. Then, all other processes connect to the proxy, instead of to each other. It becomes trivial to add more subscribers or publishers.\n\n[[code type=\"textdiagram\" title=\"Extended Pub-Sub\"]]\n#---------#   #---------#   #---------#\n|   PUB   |   |   PUB   |   |   PUB   |\n'----+----'   '----+----'   '----+----'\n     |             |             |\n     '-------------+-------------'\n                   |\n             .-----+-----.\n             |   XSUB    |\n             +-----------+\n             |   code    |\n             +-----------+\n             |   XPUB    |\n             '-----+-----'\n                   |\n     .-------------+-------------.\n     |             |             |\n.----+----.   .----+----.   .----+----.\n|   SUB   |   |   SUB   |   |   SUB   |\n#---------#   #---------#   #---------#\n[[/code]]\n\nWe need XPUB and XSUB sockets because ZeroMQ does subscription forwarding from subscribers to publishers. XSUB and XPUB are exactly like SUB and PUB except they expose subscriptions as special messages. The proxy has to forward these subscription messages from subscriber side to publisher side, by reading them from the XPUB socket and writing them to the XSUB socket. This is the main use case for XSUB and XPUB[figure].\n\n+++ Shared Queue (DEALER and ROUTER sockets)\n\nIn the Hello World client/server application, we have one client that talks to one service. However, in real cases we usually need to allow multiple services as well as multiple clients. This lets us scale up the power of the service (many threads or processes or nodes rather than just one). The only constraint is that services must be stateless, all state being in the request or in some shared storage such as a database.\n\n[[code type=\"textdiagram\" title=\"Request Distribution\"]]\n             #-----------#\n             |  Client   |\n             +-----------+\n             |    REQ    |\n             '-----+-----'\n                   |\n            R1, R2,| R3, R4\n                   |\n     .-------------+-------------.\n     |             |             |\n R1, | R4          | R2          | R3\n     |             |             |\n     v             v             v\n.---------.   .---------.   .---------.\n|   REP   |   |   REP   |   |   REP   |\n+---------+   +---------+   +---------+\n| Service |   | Service |   | Service |\n|    A    |   |    B    |   |    C    |\n#---------#   #---------#   #---------#\n[[/code]]\n\nThere are two ways to connect multiple clients to multiple servers. The brute force way is to connect each client socket to multiple service endpoints. One client socket can connect to multiple service sockets, and the REQ socket will then distribute requests among these services. Let's say you connect a client socket to three service endpoints; A, B, and C. The client makes requests R1, R2, R3, R4. R1 and R4 go to service A, R2 goes to B, and R3 goes to service C[figure].\n\nThis design lets you add more clients cheaply. You can also add more services. Each client will distribute its requests to the services. But each client has to know the service topology. If you have 100 clients and then you decide to add three more services, you need to reconfigure and restart 100 clients in order for the clients to know about the three new services.\n\nThat's clearly not the kind of thing we want to be doing at 3 a.m. when our supercomputing cluster has run out of resources and we desperately need to add a couple of hundred of new service nodes. Too many static pieces are like liquid concrete: knowledge is distributed and the more static pieces you have, the more effort it is to change the topology. What we want is something sitting in between clients and services that centralizes all knowledge of the topology. Ideally, we should be able to add and remove services or clients at any time without touching any other part of the topology.\n\nSo we'll write a little message queuing broker that gives us this flexibility. The broker binds to two endpoints, a frontend for clients and a backend for services. It then uses {{zmq_poll[3]}} to monitor these two sockets for activity and when it has some, it shuttles messages between its two sockets. It doesn't actually manage any queues explicitly--ZeroMQ does that automatically on each socket.\n\nWhen you use REQ to talk to REP, you get a strictly synchronous request-reply dialog. The client sends a request. The service reads the request and sends a reply. The client then reads the reply. If either the client or the service try to do anything else (e.g., sending two requests in a row without waiting for a response), they will get an error.\n\nBut our broker has to be nonblocking. Obviously, we can use {{zmq_poll[3]}} to wait for activity on either socket, but we can't use REP and REQ.\n\n[[code type=\"textdiagram\" title=\"Extended Request-Reply\"]]\n#---------#   #---------#   #---------#\n|   REQ   |   |   REQ   |   |   REQ   |\n'----+----'   '----+----'   '----+----'\n     |             |             |\n     '-------------+-------------'\n                   |\n             .-----+-----.\n             |  ROUTER   |\n             +-----------+\n             |   code    |\n             +-----------+\n             |  DEALER   |\n             '-----+-----'\n                   |\n     .-------------+-------------.\n     |             |             |\n     v             v             v\n.---------.   .---------.   .---------.\n|   REP   |   |   REP   |   |   REP   |\n#---------#   #---------#   #---------#\n[[/code]]\n\nLuckily, there are two sockets called DEALER and ROUTER that let you do nonblocking request-response. You'll see in [#advanced-request-reply] how DEALER and ROUTER sockets let you build all kinds of asynchronous request-reply flows. For now, we're just going to see how DEALER and ROUTER let us extend REQ-REP across an intermediary, that is, our little broker.\n\nIn this simple extended request-reply pattern, REQ talks to ROUTER and DEALER talks to REP. In between the DEALER and ROUTER, we have to have code (like our broker) that pulls messages off the one socket and shoves them onto the other[figure].\n\nThe request-reply broker binds to two endpoints, one for clients to connect to (the frontend socket) and one for workers to connect to (the backend). To test this broker, you will want to change your workers so they connect to the backend socket. Here is a client that shows what I mean:\n\n[[code type=\"example\" title=\"Request-reply client\" name=\"rrclient\"]]\n[[/code]]\n\nHere is the worker:\n\n[[code type=\"example\" title=\"Request-reply worker\" name=\"rrworker\"]]\n[[/code]]\n\nAnd here is the broker, which properly handles multipart messages:\n\n[[code type=\"example\" title=\"Request-reply broker\" name=\"rrbroker\"]]\n[[/code]]\n\n[[code type=\"textdiagram\" title=\"Request-Reply Broker\"]]\n#---------#   #---------#   #---------#\n| Client  |   | Client  |   | Client  |\n+---------+   +---------+   +---------+\n|   REQ   |   |   REQ   |   |   REQ   |\n'----+----'   '----+----'   '----+----'\n     |             |             |\n     '-------------+-------------'\n                   |\n                   v\n             .-----------.\n             |  ROUTER   |\n             +-----------+\n             |  Broker   |\n             +-----------+\n             |  DEALER   |\n             '-----+-----'\n                   |\n     .-------------+-------------.\n     |             |             |\n     v             v             v\n.---------.   .---------.   .---------.\n|   REP   |   |   REP   |   |   REP   |\n+---------+   +---------+   +---------+\n| Service |   | Service |   | Service |\n|    A    |   |    B    |   |    C    |\n#---------#   #---------#   #---------#\n[[/code]]\n\nUsing a request-reply broker makes your client/server architectures easier to scale because clients don't see workers, and workers don't see clients. The only static node is the broker in the middle[figure].\n\n+++ ZeroMQ's Built-In Proxy Function\n\nIt turns out that the core loop in the previous section's {{rrbroker}} is very useful, and reusable. It lets us build pub-sub forwarders and shared queues and other little intermediaries with very little effort. ZeroMQ wraps this up in a single method, {{zmq_proxy[3]}}:\n\n[[code type=\"fragment\" name=\"proxy\"]]\nzmq_proxy (frontend, backend, capture);\n[[/code]]\n\nThe two (or three sockets, if we want to capture data) must be properly connected, bound, and configured. When we call the {{zmq_proxy}} method, it's exactly like starting the main loop of {{rrbroker}}. Let's rewrite the request-reply broker to call {{zmq_proxy}}, and re-badge this as an expensive-sounding \"message queue\" (people have charged houses for code that did less):\n\n[[code type=\"example\" title=\"Message queue broker\" name=\"msgqueue\"]]\n[[/code]]\n\nIf you're like most ZeroMQ users, at this stage your mind is starting to think, \"What kind of evil stuff can I do if I plug random socket types into the proxy?\"  The short answer is: try it and work out what is happening. In practice, you would usually stick to ROUTER/DEALER, XSUB/XPUB, or PULL/PUSH.\n\n+++ Transport Bridging\n\nA frequent request from ZeroMQ users is, \"How do I connect my ZeroMQ network with technology X?\" where X is some other networking or messaging technology.\n\n[[code type=\"textdiagram\" title=\"Pub-Sub Forwarder Proxy\"]]\n               #-----------#\n               | Publisher |\n               +-----------+\n               |    PUB    |\n               '-----------'\n                   bind\n        tcp://192.168.55.210:5556\n                    |\n     .--------------+--------------.\n     |              |              |\n     v              v              v\n.----------.   .----------.   .----------.\n|   SUB    |   |   SUB    |   |   XSUB   |\n+----------+   +----------+   +----------+\n|Subscriber|   |Subscriber|   |  Proxy   |\n#----------#   #----------#   +----------+\n                              |   XPUB   |\n                              '-----+----'\n Internal network                   |\n====================================+=============\n External network                  bind\n                           tcp://10.1.1.0:8100\n                                    |\n                            .-------+-------.\n                            |               |\n                            v               v\n                       .----------.   .----------.\n                       |   SUB    |   |   SUB    |\n                       +----------+   +----------+\n                       |Subscriber|   |Subscriber|\n                       #----------#   #----------#\n[[/code]]\n\nThe simple answer is to build a //bridge//. A bridge is a small application that speaks one protocol at one socket, and converts to/from a second protocol at another socket. A protocol interpreter, if you like. A common bridging problem in ZeroMQ is to bridge two transports or networks.\n\nAs an example, we're going to write a little proxy that sits in between a publisher and a set of subscribers, bridging two networks. The frontend socket (XSUB) faces the internal network where the weather server is sitting, and the backend (XPUB) faces subscribers on the external network. It subscribes to the weather service on the frontend socket, and republishes its data on the backend socket.\n\n[[code type=\"example\" title=\"Weather update proxy\" name=\"wuproxy\"]]\n[[/code]]\n\nIt looks very similar to the earlier proxy example, but the key part is that the frontend and backend sockets are on two different networks[figure]. We can use this model for example to connect a multicast network ({{pgm}} transport) to a {{tcp}} publisher.\n\n++ Handling Errors and ETERM\n\nZeroMQ's error handling philosophy is a mix of fail-fast and resilience. Processes, we believe, should be as vulnerable as possible to internal errors, and as robust as possible against external attacks and errors. To give an analogy, a living cell will self-destruct if it detects a single internal error, yet it will resist attack from the outside by all means possible.\n\nAssertions, which pepper the ZeroMQ code, are absolutely vital to robust code; they just have to be on the right side of the cellular wall. And there should be such a wall. If it is unclear whether a fault is internal or external, that is a design flaw to be fixed. In C/C++, assertions stop the application immediately with an error. In other languages, you may get exceptions or halts.\n\nWhen ZeroMQ detects an external fault it returns an error to the calling code. In some rare cases, it drops messages silently if there is no obvious strategy for recovering from the error.\n\nIn most of the C examples we've seen so far there's been no error handling. **Real code should do error handling on every single ZeroMQ call**. If you're using a language binding other than C, the binding may handle errors for you. In C, you do need to do this yourself. There are some simple rules, starting with POSIX conventions:\n\n* Methods that create objects return NULL if they fail.\n* Methods that process data may return the number of bytes processed, or -1 on an error or failure.\n* Other methods return 0 on success and -1 on an error or failure.\n* The error code is provided in {{errno}} or {{zmq_errno[3]}}.\n* A descriptive error text for logging is provided by {{zmq_strerror[3]}}.\n\nFor example:\n\n[[code type=\"fragment\" name=\"errorhandling\"]]\nvoid *context = zmq_ctx_new ();\nassert (context);\nvoid *socket = zmq_socket (context, ZMQ_REP);\nassert (socket);\nint rc = zmq_bind (socket, \"tcp://*:5555\");\nif (rc == -1) {\n    printf (\"E: bind failed: %s\\n\", strerror (errno));\n    return -1;\n}\n[[/code]]\n\nThere are two main exceptional conditions that you should handle as nonfatal:\n\n* When your code receives a message with the {{ZMQ_DONTWAIT}} option and there is no waiting data, ZeroMQ will return -1 and set {{errno}} to {{EAGAIN}}.\n\n* When one thread calls {{zmq_ctx_destroy[3]}}, and other threads are still doing blocking work, the {{zmq_ctx_destroy[3]}} call closes the context and all blocking calls exit with -1, and {{errno}} set to {{ETERM}}.\n\nIn C/C++, asserts can be removed entirely in optimized code, so don't make the mistake of wrapping the whole ZeroMQ call in an {{assert()}}. It looks neat; then the optimizer removes all the asserts and the calls you want to make, and your application breaks in impressive ways.\n\n[[code type=\"textdiagram\" title=\"Parallel Pipeline with Kill Signaling\"]]\n             #-------------#\n             |  Ventilator |\n             +-------------+\n             |    PUSH     |\n             '------+------'\n                    |\n                    | tasks\n                    |\n    .---------------+---------------.\n    |               |               |\n    |     .=========+=====+=========+=====+======.\n    |     :         |     :         |     :      :\n    v     v         v     v         v     v      :\n.------+-----.  .------+-----.  .------+-----.   :\n| PULL | SUB |  | PULL | SUB |  | PULL | SUB |   :\n+------+-----+  +------+-----+  +------+-----+   :\n|   Worker   |  |   Worker   |  |   Worker   |   :\n+------------+  +------------+  +------------+   :\n|    PUSH    |  |    PUSH    |  |    PUSH    |   :\n'-----+------'  '-----+------'  '-----+------'   :\n      |               |               |          :\n      '---------------+---------------'          :\n                      |                          :\n                      | results                  :\n                      |                          :\n                      v                          :\n               .-------------.                   :\n               |    PULL     |                   :\n               +-------------+                   :\n               |    Sink     |                   :\n               +-------------+                   :\n               |     PUB     +==== KILL signal==='\n               '-------------'\n[[/code]]\n\nLet's see how to shut down a process cleanly. We'll take the parallel pipeline example from the previous section. If we've started a whole lot of workers in the background, we now want to kill them when the batch is finished. Let's do this by sending a kill message to the workers. The best place to do this is the sink because it really knows when the batch is done.\n\nHow do we connect the sink to the workers? The PUSH/PULL sockets are one-way only. We could switch to another socket type, or we could mix multiple socket flows. Let's try the latter: using a pub-sub model to send kill messages to the workers[figure]:\n\n* The sink creates a PUB socket on a new endpoint.\n* Workers connect their input socket to this endpoint.\n* When the sink detects the end of the batch, it sends a kill to its PUB socket.\n* When a worker detects this kill message, it exits.\n\nIt doesn't take much new code in the sink:\n\n[[code type=\"fragment\" name=\"killsignal\"]]\nvoid *controller = zmq_socket (context, ZMQ_PUB);\nzmq_bind (controller, \"tcp://*:5559\");\n...\n//  Send kill signal to workers\ns_send (controller, \"KILL\");\n[[/code]]\n\nHere is the worker process, which manages two sockets (a PULL socket getting tasks, and a SUB socket getting control commands), using the {{zmq_poll[3]}} technique we saw earlier:\n\n[[code type=\"example\" title=\"Parallel task worker with kill signaling\" name=\"taskwork2\"]]\n[[/code]]\n\nHere is the modified sink application. When it's finished collecting results, it broadcasts a kill message to all workers:\n\n[[code type=\"example\" title=\"Parallel task sink with kill signaling\" name=\"tasksink2\"]]\n[[/code]]\n\n++ Handling Interrupt Signals\n\nRealistic applications need to shut down cleanly when interrupted with Ctrl-C or another signal such as {{SIGTERM}}. By default, these simply kill the process, meaning messages won't be flushed, files won't be closed cleanly, and so on.\n\nHere is how we handle a signal in various languages:\n\n[[code type=\"example\" title=\"Handling Ctrl-C cleanly\" name=\"interrupt\"]]\n[[/code]]\n\nThe program provides {{s_catch_signals()}}, which traps Ctrl-C ({{SIGINT}}) and {{SIGTERM}}. When either of these signals arrive, the {{s_signal_handler()}} handler writes a single byte to the self pipe created in the main function startup code. Thanks to your signal handler, your application will not die automatically. Instead, you have a chance to clean up and exit gracefully. You have to now explicitly check for an interrupt and handle it properly. Do this by checking if the self pipe contains any data (copy this from {{interrupt.c}}) in the mainloop of your code. The interrupt will affect ZeroMQ calls as follows:\n\n* If your code is blocking in a blocking call (sending a message, receiving a message, or polling), then when a signal arrives, the call will return with {{EINTR}}.\n* Wrappers like {{s_recv()}} return NULL if they are interrupted.\n\nSo check for an {{EINTR}} return code, a NULL return, and/or if the self pipe has any data in its queue.\n\nIf you call {{s_catch_signals()}} and don't test the self pipe for interrupts, then your application will become immune to Ctrl-C and {{SIGTERM}}, which may be useful, but is usually not.\n\n++ Detecting Memory Leaks\n\nAny long-running application has to manage memory correctly, or eventually it'll use up all available memory and crash. If you use a language that handles this automatically for you, congratulations. If you program in C or C++ or any other language where you're responsible for memory management, here's a short tutorial on using valgrind, which among other things will report on any leaks your programs have.\n\n* To install valgrind, e.g., on Ubuntu or Debian, issue this command:\n\n[[code]]\nsudo apt-get install valgrind\n[[/code]]\n\n* By default, ZeroMQ will cause valgrind to complain a lot. To remove these warnings, create a file called {{vg.supp}} that contains this:\n\n[[code]]\n{\n   <socketcall_sendto>\n   Memcheck:Param\n   socketcall.sendto(msg)\n   fun:send\n   ...\n}\n{\n   <socketcall_sendto>\n   Memcheck:Param\n   socketcall.send(msg)\n   fun:send\n   ...\n}\n[[/code]]\n\n* Fix your applications to exit cleanly after Ctrl-C. For any application that exits by itself, that's not needed, but for long-running applications, this is essential, otherwise valgrind will complain about all currently allocated memory.\n\n* Build your application with {{-DDEBUG}} if it's not your default setting. That ensures valgrind can tell you exactly where memory is being leaked.\n\n* Finally, run valgrind thus:\n\n[[code]]\nvalgrind --tool=memcheck --leak-check=full --suppressions=vg.supp someprog\n[[/code]]\n\nAnd after fixing any errors it reported, you should get the pleasant message:\n\n[[code]]\n==30536== ERROR SUMMARY: 0 errors from 0 contexts...\n[[/code]]\n\n++ Multithreading with ZeroMQ\n\nZeroMQ is perhaps the nicest way ever to write multithreaded (MT) applications. Whereas ZeroMQ sockets require some readjustment if you are used to traditional sockets, ZeroMQ multithreading will take everything you know about writing MT applications, throw it into a heap in the garden, pour gasoline over it, and set it alight. It's a rare book that deserves burning, but most books on concurrent programming do.\n\nTo make utterly perfect MT programs (and I mean that literally), **we don't need mutexes, locks, or any other form of inter-thread communication except messages sent across ZeroMQ sockets.**\n\nBy \"perfect MT programs\", I mean code that's easy to write and understand, that works with the same design approach in any programming language, and on any operating system, and that scales across any number of CPUs with zero wait states and no point of diminishing returns.\n\nIf you've spent years learning tricks to make your MT code work at all, let alone rapidly, with locks and semaphores and critical sections, you will be disgusted when you realize it was all for nothing. If there's one lesson we've learned from 30+ years of concurrent programming, it is: //just don't share state//. It's like two drunkards trying to share a beer. It doesn't matter if they're good buddies. Sooner or later, they're going to get into a fight. And the more drunkards you add to the table, the more they fight each other over the beer. The tragic majority of MT applications look like drunken bar fights.\n\nThe list of weird problems that you need to fight as you write classic shared-state MT code would be hilarious if it didn't translate directly into stress and risk, as code that seems to work suddenly fails under pressure. A large firm with world-beating experience in buggy code released its list of \"11 Likely Problems In Your Multithreaded Code\", which covers forgotten synchronization, incorrect granularity, read and write tearing, lock-free reordering, lock convoys, two-step dance, and priority inversion.\n\nYeah, we counted seven problems, not eleven. That's not the point though. The point is, do you really want that code running the power grid or stock market to start getting two-step lock convoys at 3 p.m. on a busy Thursday? Who cares what the terms actually mean? This is not what turned us on to programming, fighting ever more complex side effects with ever more complex hacks.\n\nSome widely used models, despite being the basis for entire industries, are fundamentally broken, and shared state concurrency is one of them. Code that wants to scale without limit does it like the Internet does, by sending messages and sharing nothing except a common contempt for broken programming models.\n\nYou should follow some rules to write happy multithreaded code with ZeroMQ:\n\n* Isolate data privately within its thread and never share data in multiple threads. The only exception to this are ZeroMQ contexts, which are threadsafe.\n\n* Stay away from the classic concurrency mechanisms like as mutexes, critical sections, semaphores, etc. These are an anti-pattern in ZeroMQ applications.\n\n* Create one ZeroMQ context at the start of your process, and pass that to all threads that you want to connect via {{inproc}} sockets.\n\n* Use //attached// threads to create structure within your application, and connect these to their parent threads using PAIR sockets over {{inproc}}. The pattern is: bind parent socket, then create child thread which connects its socket.\n\n* Use //detached// threads to simulate independent tasks, with their own contexts. Connect these over {{tcp}}. Later you can move these to stand-alone processes without changing the code significantly.\n\n* All interaction between threads happens as ZeroMQ messages, which you can define more or less formally.\n\n* Don't share ZeroMQ sockets between threads. ZeroMQ sockets are not threadsafe. Technically it's possible to migrate a socket from one thread to another but it demands skill. The only place where it's remotely sane to share sockets between threads are in language bindings that need to do magic like garbage collection on sockets.\n\nIf you need to start more than one proxy in an application, for example, you will want to run each in their own thread. It is easy to make the error of creating the proxy frontend and backend sockets in one thread, and then passing the sockets to the proxy in another thread. This may appear to work at first but will fail randomly in real use. Remember: //Do not use or close sockets except in the thread that created them.//\n\nIf you follow these rules, you can quite easily build elegant multithreaded applications, and later split off threads into separate processes as you need to. Application logic can sit in threads, processes, or nodes: whatever your scale needs.\n\nZeroMQ uses native OS threads rather than virtual \"green\" threads. The advantage is that you don't need to learn any new threading API, and that ZeroMQ threads map cleanly to your operating system. You can use standard tools like Intel's ThreadChecker to see what your application is doing. The disadvantages are that native threading APIs are not always portable, and that if you have a huge number of threads (in the thousands), some operating systems will get stressed.\n\nLet's see how this works in practice. We'll turn our old Hello World server into something more capable. The original server ran in a single thread. If the work per request is low, that's fine: one ØMQ thread can run at full speed on a CPU core, with no waits, doing an awful lot of work. But realistic servers have to do nontrivial work per request. A single core may not be enough when 10,000 clients hit the server all at once. So a realistic server will start multiple worker threads. It then accepts requests as fast as it can and distributes these to its worker threads. The worker threads grind through the work and eventually send their replies back.\n\nYou can, of course, do all this using a proxy broker and external worker processes, but often it's easier to start one process that gobbles up sixteen cores than sixteen processes, each gobbling up one core. Further, running workers as threads will cut out a network hop, latency, and network traffic.\n\nThe MT version of the Hello World service basically collapses the broker and workers into a single process:\n\n[[code type=\"example\" title=\"Multithreaded service\" name=\"mtserver\"]]\n[[/code]]\n\n[[code type=\"textdiagram\" title=\"Multithreaded Server\"]]\n               #------------#\n               |   Client   |\n               +------------+\n               |    REQ     |\n               '---+--------'\n                   |    ^\n                   |    |\n           \"Hello\" |    | \"World\"\n.----------------= | -= | =----------------.\n|                  v    |                  :\n|              .--------+---.              |\n|              |   ROUTER   |              |\n|              +------------+              |\n|              |   Server   |              |\n|              +------------+              |\n|              |   Queue    |              |\n|              |   proxy    |              |\n|              +------------+              |\n|              |   DEALER   |              |\n|              '------------'              |\n|                    ^                     |\n|                    |                     |\n|        .-----------+-----------.         |\n|        |           |           |         |\n|        v           v           v         |\n|    .--------.  .--------.  .--------.    |\n|    |  REP   |  |  REP   |  |  REP   |    |\n|    +--------+  +--------+  +--------+    |\n|    | Worker |  | Worker |  | Worker |    |\n|    #--------#  #--------#  #--------#    |\n'------------------------------------------'\n[[/code]]\n\nAll the code should be recognizable to you by now. How it works:\n\n* The server starts a set of worker threads. Each worker thread creates a REP socket and then processes requests on this socket. Worker threads are just like single-threaded servers. The only differences are the transport ({{inproc}} instead of {{tcp}}), and the bind-connect direction.\n\n* The server creates a ROUTER socket to talk to clients and binds this to its external interface (over {{tcp}}).\n\n* The server creates a DEALER socket to talk to the workers and binds this to its internal interface (over {{inproc}}).\n\n* The server starts a proxy that connects the two sockets. The proxy pulls incoming requests fairly from all clients, and distributes those out to workers. It also routes replies back to their origin.\n\nNote that creating threads is not portable in most programming languages. The POSIX library is pthreads, but on Windows you have to use a different API. In our example, the {{pthread_create}} call starts up a new thread running the {{worker_routine}} function we defined. We'll see in [#advanced-request-reply] how to wrap this in a portable API.\n\nHere the \"work\" is just a one-second pause. We could do anything in the workers, including talking to other nodes. This is what the MT server looks like in terms of ØMQ sockets and nodes. Note how the request-reply chain is {{REQ-ROUTER-queue-DEALER-REP}}[figure].\n\n++ Signaling Between Threads (PAIR Sockets)\n\nWhen you start making multithreaded applications with ZeroMQ, you'll encounter the question of how to coordinate your threads. Though you might be tempted to insert \"sleep\" statements, or use multithreading techniques such as semaphores or mutexes, **the only mechanism that you should use are ZeroMQ messages**. Remember the story of The Drunkards and The Beer Bottle.\n\nLet's make three threads that signal each other when they are ready[figure]. In this example, we use PAIR sockets over the {{inproc}} transport:\n\n[[code type=\"example\" title=\"Multithreaded relay\" name=\"mtrelay\"]]\n[[/code]]\n\n[[code type=\"textdiagram\" title=\"The Relay Race\"]]\n#------------#\n|   Step 1   |\n+------------+\n|    PAIR    |\n'-----+------'\n      |\n      | Ready!\n      |\n      v\n.------------.\n|    PAIR    |\n+------------+\n|   Step 2   |\n+------------+\n|    PAIR    |\n'-----+------'\n      |\n      | Ready!\n      |\n      v\n.------------.\n|    PAIR    |\n+------------+\n|   Step 3   |\n#------------#\n[[/code]]\n\n\nThis is a classic pattern for multithreading with ZeroMQ:\n\n# Two threads communicate over {{inproc}}, using a shared context.\n# The parent thread creates one socket, binds it to an {{inproc:@<//>@}} endpoint, and //then// starts the child thread, passing the context to it.\n# The child thread creates the second socket, connects it to that {{inproc:@<//>@}} endpoint, and //then// signals to the parent thread that it's ready.\n\nNote that multithreading code using this pattern is not scalable out to processes. If you use {{inproc}} and socket pairs, you are building a tightly-bound application, i.e., one where your threads are structurally interdependent. Do this when low latency is really vital. The other design pattern is a loosely bound application, where threads have their own context and communicate over {{ipc}} or {{tcp}}. You can easily break loosely bound threads into separate processes.\n\nThis is the first time we've shown an example using PAIR sockets. Why use PAIR? Other socket combinations might seem to work, but they all have side effects that could interfere with signaling:\n\n* You can use PUSH for the sender and PULL for the receiver. This looks simple and will work, but remember that PUSH will distribute messages to all available receivers. If you by accident start two receivers (e.g., you already have one running and you start a second), you'll \"lose\" half of your signals. PAIR has the advantage of refusing more than one connection; the pair is //exclusive//.\n\n* You can use DEALER for the sender and ROUTER for the receiver. ROUTER, however, wraps your message in an \"envelope\", meaning your zero-size signal turns into a multipart message. If you don't care about the data and treat anything as a valid signal, and if you don't read more than once from the socket, that won't matter. If, however, you decide to send real data, you will suddenly find ROUTER providing you with \"wrong\" messages. DEALER also distributes outgoing messages, giving the same risk as PUSH.\n\n* You can use PUB for the sender and SUB for the receiver. This will correctly deliver your messages exactly as you sent them and PUB does not distribute as PUSH or DEALER do. However, you need to configure the subscriber with an empty subscription, which is annoying.\n\nFor these reasons, PAIR makes the best choice for coordination between pairs of threads.\n\n++ Node Coordination\n\nWhen you want to coordinate a set of nodes on a network, PAIR sockets won't work well any more. This is one of the few areas where the strategies for threads and nodes are different. Principally, nodes come and go whereas threads are usually static. PAIR sockets do not automatically reconnect if the remote node goes away and comes back.\n\n[[code type=\"textdiagram\" title=\"Pub-Sub Synchronization\"]]\n#------------#\n| Publisher  |\n+-----+------+\n| PUB | REP  |\n'--+--+----+-'\n   |    ^  |\n(3)| (1)|  |(2)\n   |    |  |\n   v    |  v\n.-----+-+----.\n| SUB | REQ  |\n+-----+------+\n| Subscriber |\n#------------#\n[[/code]]\n\nThe second significant difference between threads and nodes is that you typically have a fixed number of threads but a more variable number of nodes. Let's take one of our earlier scenarios (the weather server and clients) and use node coordination to ensure that subscribers don't lose data when starting up.\n\nThis is how the application will work:\n\n* The publisher knows in advance how many subscribers it expects. This is just a magic number it gets from somewhere.\n\n* The publisher starts up and waits for all subscribers to connect. This is the node coordination part. Each subscriber subscribes and then tells the publisher it's ready via another socket.\n\n* When the publisher has all subscribers connected, it starts to publish data.\n\nIn this case, we'll use a REQ-REP socket flow to synchronize subscribers and publisher[figure]. Here is the publisher:\n\n[[code type=\"example\" title=\"Synchronized publisher\" name=\"syncpub\"]]\n[[/code]]\n\nAnd here is the subscriber:\n\n[[code type=\"example\" title=\"Synchronized subscriber\" name=\"syncsub\"]]\n[[/code]]\n\nThis Bash shell script will start ten subscribers and then the publisher:\n\n[[code]]\necho \"Starting subscribers...\"\nfor ((a=0; a<10; a++)); do\n    syncsub &\ndone\necho \"Starting publisher...\"\nsyncpub\n[[/code]]\n\nWhich gives us this satisfying output:\n\n[[code]]\nStarting subscribers...\nStarting publisher...\nReceived 1000000 updates\nReceived 1000000 updates\n...\nReceived 1000000 updates\nReceived 1000000 updates\n[[/code]]\n\nWe can't assume that the SUB connect will be finished by the time the REQ/REP dialog is complete. There are no guarantees that outbound connects will finish in any order whatsoever, if you're using any transport except {{inproc}}. So, the example does a brute force sleep of one second between subscribing, and sending the REQ/REP synchronization.\n\nA more robust model could be:\n\n* Publisher opens PUB socket and starts sending \"Hello\" messages (not data).\n* Subscribers connect SUB socket and when they receive a Hello message they tell the publisher via a REQ/REP socket pair.\n* When the publisher has had all the necessary confirmations, it starts to send real data.\n\n++ Zero-Copy\n\nZeroMQ's message API lets you send and receive messages directly from and to application buffers without copying data. We call this //zero-copy//, and it can improve performance in some applications.\n\nYou should think about using zero-copy in the specific case where you are sending large blocks of memory (thousands of bytes), at a high frequency. For short messages, or for lower message rates, using zero-copy will make your code messier and more complex with no measurable benefit. Like all optimizations, use this when you know it helps, and //measure// before and after.\n\nTo do zero-copy, you use {{zmq_msg_init_data[3]}} to create a message that refers to a block of data already allocated with {{malloc()}} or some other allocator, and then you pass that to {{zmq_msg_send[3]}}. When you create the message, you also pass a function that ZeroMQ will call to free the block of data, when it has finished sending the message. This is the simplest example, assuming {{buffer}} is a block of 1,000 bytes allocated on the heap:\n\n[[code type=\"fragment\" name=\"zerocopy\"]]\nvoid my_free (void *data, void *hint) {\n    free (data);\n}\n//  Send message from buffer, which we allocate and ZeroMQ will free for us\nzmq_msg_t message;\nzmq_msg_init_data (&message, buffer, 1000, my_free, NULL);\nzmq_msg_send (&message, socket, 0);\n[[/code]]\n\nNote that you don't call {{zmq_msg_close[3]}} after sending a message--{{libzmq}} will do this automatically when it's actually done sending the message.\n\nThere is no way to do zero-copy on receive: ZeroMQ delivers you a buffer that you can store as long as you wish, but it will not write data directly into application buffers.\n\nOn writing, ZeroMQ's multipart messages work nicely together with zero-copy. In traditional messaging, you need to marshal different buffers together into one buffer that you can send. That means copying data. With ZeroMQ, you can send multiple buffers coming from different sources as individual message frames. Send each field as a length-delimited frame. To the application, it looks like a series of send and receive calls. But internally, the multiple parts get written to the network and read back with single system calls, so it's very efficient.\n\n++ Pub-Sub Message Envelopes\n\nIn the pub-sub pattern, we can split the key into a separate message frame that we call an //envelope//[figure]. If you want to use pub-sub envelopes, make them yourself. It's optional, and in previous pub-sub examples we didn't do this. Using a pub-sub envelope is a little more work for simple cases, but it's cleaner especially for real cases, where the key and the data are naturally separate things.\n\n[[code type=\"textdiagram\" title=\"Pub-Sub Envelope with Separate Key\"]]\n          #--------#\nFrame 1   | Key    |   Message envelope\n          +--------+\nFrame 2   | Data   |   Actual message body\n          #--------#\n[[/code]]\n\nSubscriptions do a prefix match. That is, they look for \"all messages starting with XYZ\". The obvious question is: how to delimit keys from data so that the prefix match doesn't accidentally match data. The best answer is to use an envelope because the match won't cross a frame boundary. Here is a minimalist example of how pub-sub envelopes look in code. This publisher sends messages of two types, A and B.\n\nThe envelope holds the message type:\n\n[[code type=\"example\" title=\"Pub-Sub envelope publisher\" name=\"psenvpub\"]]\n[[/code]]\n\nThe subscriber wants only messages of type B:\n\n[[code type=\"example\" title=\"Pub-Sub envelope subscriber\" name=\"psenvsub\"]]\n[[/code]]\n\nWhen you run the two programs, the subscriber should show you this:\n\n[[code]]\n[B] We would like to see this\n[B] We would like to see this\n[B] We would like to see this\n...\n[[/code]]\n\nThis example shows that the subscription filter rejects or accepts the entire multipart message (key plus data). You won't get part of a multipart message, ever. If you subscribe to multiple publishers and you want to know their address so that you can send them data via another socket (and this is a typical use case), create a three-part message[figure].\n\n[[code type=\"textdiagram\" title=\"Pub-Sub Envelope with Sender Address\"]]\n          #---------#\nFrame 1   | Key     |   Subscription key\n          +---------+\nFrame 2   | Address |   Address of publisher\n          +---------+\nFrame 3   | Data    |   Actual message body\n          #---------#\n[[/code]]\n\n++ High-Water Marks\n\nWhen you can send messages rapidly from process to process, you soon discover that memory is a precious resource, and one that can be trivially filled up. A few seconds of delay somewhere in a process can turn into a backlog that blows up a server unless you understand the problem and take precautions.\n\nThe problem is this: imagine you have process A sending messages at high frequency to process B, which is processing them. Suddenly B gets very busy (garbage collection, CPU overload, whatever), and can't process the messages for a short period. It could be a few seconds for some heavy garbage collection, or it could be much longer, if there's a more serious problem. What happens to the messages that process A is still trying to send frantically? Some will sit in B's network buffers. Some will sit on the Ethernet wire itself. Some will sit in A's network buffers. And the rest will accumulate in A's memory, as rapidly as the application behind A sends them. If you don't take some precaution, A can easily run out of memory and crash.\n\nIt is a consistent, classic problem with message brokers. What makes it hurt more is that it's B's fault, superficially, and B is typically a user-written application which A has no control over.\n\nWhat are the answers? One is to pass the problem upstream. A is getting the messages from somewhere else. So tell that process, \"Stop!\" And so on. This is called //flow control//. It sounds plausible, but what if you're sending out a Twitter feed? Do you tell the whole world to stop tweeting while B gets its act together?\n\nFlow control works in some cases, but not in others. The transport layer can't tell the application layer to \"stop\" any more than a subway system can tell a large business, \"please keep your staff at work for another half an hour. I'm too busy\". The answer for messaging is to set limits on the size of buffers, and then when we reach those limits, to take some sensible action. In some cases (not for a subway system, though), the answer is to throw away messages. In others, the best strategy is to wait.\n\nZeroMQ uses the concept of HWM (high-water mark) to define the capacity of its internal pipes. Each connection out of a socket or into a socket has its own pipe, and HWM for sending, and/or receiving, depending on the socket type. Some sockets (PUB, PUSH) only have send buffers. Some (SUB, PULL, REQ, REP) only have receive buffers. Some (DEALER, ROUTER, PAIR) have both send and receive buffers.\n\nIn ZeroMQ v2.x, the HWM was infinite by default. This was easy but also typically fatal for high-volume publishers. In ZeroMQ v3.x, it's set to 1,000 by default, which is more sensible. If you're still using ZeroMQ v2.x, you should always set a HWM on your sockets, be it 1,000 to match ZeroMQ v3.x or another figure that takes into account your message sizes and expected subscriber performance.\n\nWhen your socket reaches its HWM, it will either block or drop data depending on the socket type. PUB and ROUTER sockets will drop data if they reach their HWM, while other socket types will block. Over the {{inproc}} transport, the sender and receiver share the same buffers, so the real HWM is the sum of the HWM set by both sides.\n\nLastly, the HWMs are not exact; while you may get //up to// 1,000 messages by default, the real buffer size may be much lower (as little as half), due to the way {{libzmq}} implements its queues.\n\n++ Missing Message Problem Solver\n\nAs you build applications with ZeroMQ, you will come across this problem more than once: losing messages that you expect to receive. We have put together a diagram[figure] that walks through the most common causes for this.\n\n[[code type=\"textdiagram\" title=\"Missing Message Problem Solver\"]]\n.---------------.        .---------------.        .----------------.\n| So you're not |        | Do you set a  |        | On SUB sockets |\n| getting every |    .-->| subscription  +------->| you have to    |\n| message?      |    |   | for messages? | No     | subscribe to   |\n'--------+------'    |   '-------+-------'        | get messages   |\n         | Yes       |           | Yes            '----------------'\n         v           |           v\n.----------------.   |   .----------------.        .---------------.\n| Are you losing |   |   | Do you start   |        | Start all SUB |\n| messages in a  +---'   | the SUB socket +------->| sockets first |\n| SUB socket?    | Yes   | after the PUB? | Yes    | then the PUB  |\n'--------+-------'       '--------+-------'        '---------------'\n         | No                     | No\n         v                        v             .------------------.\n.---------------.       .-----------------.     | Send and recv in |\n| Are you using | Yes   | See explanation |     | a loop and check |\n| REQ and REP?  +---.   | of slow joiners |  .->| return codes.    |\n'--------+------'   |   | in the text     |  |  | With REP, recv   |\n         | No       |   '-----------------'  |  | and send         |\n         v          '------------------------'  '------------------'\n.-----------------.      .----------------.                          \n|  Are you using  +--.   | First PULL can |       .---------------.\n|  PUSH sockets?  |  '-->| grab many msgs |       | Use the load  |\n'--------+--------' Yes  | while others   +--.    | balancing     |\n         | No            | are still busy |  '--->| pattern and   |\n         v               | connecting     |       | ROUTER/DEALER |\n.-----------------.      '----------------'       | sockets       |\n|  Do you check   | No                            '---------------'\n| return codes on +---.   .----------------.\n|  all methods?   |   |   | Check each 0MQ |   .------------------.\n'--------+--------'   '-->| method call    |   | Use sockets only |\n         | Yes            '----------------'   | in their owning  |\n         v                                     | threads unless   |\n.-----------------.      .---.      .--------->| you know about   |\n| Are you using a |      |   |      |          | memory barriers  |\n| socket in more  +------'   |      |          '------------------'\n| than 1 thread?  | Yes      '------'         \n'--------+--------'                               .---------------.\n         | No             .----------------.      | To use inproc |\n         v                | Do you call    |      | your sockets  |\n.---------------.   .---->| zmq_ctx_new    +----->| must be in    |\n| Are you using |   |     | twice or more? | Yes  | the same 0MQ  |\n| the inproc:// +---'     '--------+-------'      | context       |\n| transport?    | Yes              | No           '---------------'\n'--------+------'                  v                              \n         | No             .-----------------.\n         v                | Check that you  |\n.-----------------.       | bind before you |\n|  Are you using  | Yes   | connect         |\n| ROUTER sockets? +---.   '-----------------'\n'--------+--------'   |                      \n         | No         |   .----------------.     .------------.\n         v            |   | Check that the |     | If you use |\n.----------------.    |   | reply address  |     | identities |\n| Make a minimal |    '-->| is valid. 0MQ  +---->| set them   |\n| test case, ask |        | drops messages |     | before you |\n| on IRC channel |        | it can't route |     | connect    |\n'----------------'        '----------------'     '------------'\n[[/code]]\n\nHere's a summary of what the graphic says:\n\n* On SUB sockets, set a subscription using {{zmq_setsockopt[3]}} with {{ZMQ_SUBSCRIBE}}, or you won't get messages. Because you subscribe to messages by prefix, if you subscribe to \"\" (an empty subscription), you will get everything.\n\n* If you start the SUB socket (i.e., establish a connection to a PUB socket) //after// the PUB socket has started sending out data, you will lose whatever it published before the connection was made. If this is a problem, set up your architecture so the SUB socket starts first, then the PUB socket starts publishing.\n\n* Even if you synchronize a SUB and PUB socket, you may still lose messages. It's due to the fact that internal queues aren't created until a connection is actually created. If you can switch the bind/connect direction so the SUB socket binds, and the PUB socket connects, you may find it works more as you'd expect.\n\n* If you're using REP and REQ sockets, and you're not sticking to the synchronous send/recv/send/recv order, ZeroMQ will report errors, which you might ignore. Then, it would look like you're losing messages. If you use REQ or REP, stick to the send/recv order, and always, in real code, check for errors on ZeroMQ calls.\n\n* If you're using PUSH sockets, you'll find that the first PULL socket to connect will grab an unfair share of messages. The accurate rotation of messages only happens when all PULL sockets are successfully connected, which can take some milliseconds. As an alternative to PUSH/PULL, for lower data rates, consider using ROUTER/DEALER and the load balancing pattern.\n\n* If you're sharing sockets across threads, don't. It will lead to random weirdness, and crashes.\n\n* If you're using {{inproc}}, make sure both sockets are in the same context. Otherwise the connecting side will in fact fail. Also, bind first, then connect. {{inproc}} is not a disconnected transport like {{tcp}}.\n\n* If you're using ROUTER sockets, it's remarkably easy to lose messages by accident, by sending malformed identity frames (or forgetting to send an identity frame). In general setting the {{ZMQ_ROUTER_MANDATORY}} option on ROUTER sockets is a good idea, but do also check the return code on every send call.\n\n* Lastly, if you really can't figure out what's going wrong, make a //minimal// test case that reproduces the problem, and ask for help from the ZeroMQ community.\n"
        },
        {
          "name": "chapter3.txt",
          "type": "blob",
          "size": 73.6083984375,
          "content": ".output chapter3.wd\n.bookmark advanced-request-reply\n+ Advanced Request-Reply Patterns\n\nIn [#sockets-and-patterns] we worked through the basics of using ZeroMQ by developing a series of small applications, each time exploring new aspects of ZeroMQ. We'll continue this approach in this chapter as we explore advanced patterns built on top of ZeroMQ's core request-reply pattern.\n\nWe'll cover:\n\n* How the request-reply mechanisms work\n* How to combine REQ, REP, DEALER, and ROUTER sockets\n* How ROUTER sockets work, in detail\n* The load balancing pattern\n* Building a simple load balancing message broker\n* Designing a high-level API for ZeroMQ\n* Building an asynchronous request-reply server\n* A detailed inter-broker routing example\n\n++ The Request-Reply Mechanisms\n\nWe already looked briefly at multipart messages. Let's now look at a major use case, which is //reply message envelopes//. An envelope is a way of safely packaging up data with an address, without touching the data itself. By separating reply addresses into an envelope we make it possible to write general purpose intermediaries such as APIs and proxies that create, read, and remove addresses no matter what the message payload or structure is.\n\nIn the request-reply pattern, the envelope holds the return address for replies. It is how a ZeroMQ network with no state can create round-trip request-reply dialogs.\n\nWhen you use REQ and REP sockets you don't even see envelopes; these sockets deal with them automatically. But for most of the interesting request-reply patterns, you'll want to understand envelopes and particularly ROUTER sockets. We'll work through this step-by-step.\n\n+++ The Simple Reply Envelope\n\nA request-reply exchange consists of a //request// message, and an eventual //reply// message. In the simple request-reply pattern, there's one reply for each request. In more advanced patterns, requests and replies can flow asynchronously. However, the reply envelope always works the same way.\n\nThe ZeroMQ reply envelope formally consists of zero or more reply addresses, followed by an empty frame (the envelope delimiter), followed by the message body (zero or more frames). The envelope is created by multiple sockets working together in a chain. We'll break this down.\n\nWe'll start by sending \"Hello\" through a REQ socket. The REQ socket creates the simplest possible reply envelope, which has no addresses, just an empty delimiter frame and the message frame containing the \"Hello\" string. This is a two-frame message[figure].\n\n[[code type=\"textdiagram\" title=\"Request with Minimal Envelope\"]]\n          #---#\nFrame 1   | 0 |            Empty delimiter frame\n          #---#-------#\nFrame 2   | 5 | Hello |    Data frame\n          #---+-------#\n[[/code]]\n\nThe REP socket does the matching work: it strips off the envelope, up to and including the delimiter frame, saves the whole envelope, and passes the \"Hello\" string up the application. Thus our original Hello World example used request-reply envelopes internally, but the application never saw them.\n\nIf you spy on the network data flowing between {{hwclient}} and {{hwserver}}, this is what you'll see: every request and every reply is in fact two frames, an empty frame and then the body. It doesn't seem to make much sense for a simple REQ-REP dialog. However you'll see the reason when we explore how ROUTER and DEALER handle envelopes.\n\n+++ The Extended Reply Envelope\n\nNow let's extend the REQ-REP pair with a ROUTER-DEALER proxy in the middle and see how this affects the reply envelope. This is the //extended request-reply pattern// we already saw in [#sockets-and-patterns]. We can, in fact, insert any number of proxy steps[figure]. The mechanics are the same.\n\n[[code type=\"textdiagram\" title=\"Extended Request-Reply Pattern\"]]\n#-------#     #-------#\n|  REQ  |<--->|  REP  |\n#-------#     #-------#\n\n\n#-------#     #--------+--------#     #-------#\n|  REQ  |<--->| ROUTER | DEALER |<--->|  REP  |\n#-------#     #--------+--------#     #-------#\n\n\n#-------#     #--------+--------#     #--------+--------#     #-------#\n|  REQ  |<--->| ROUTER | DEALER |<--->| ROUTER | DEALER |<--->|  REP  |\n#-------#     #--------+--------#     #--------+--------#     #-------#\n[[/code]]\n\nThe proxy does this, in pseudo-code:\n\n[[code]]\nprepare context, frontend and backend sockets\nwhile true:\n    poll on both sockets\n    if frontend had input:\n        read all frames from frontend\n        send to backend\n    if backend had input:\n        read all frames from backend\n        send to frontend\n[[/code]]\n\nThe ROUTER socket, unlike other sockets, tracks every connection it has, and tells the caller about these. The way it tells the caller is to stick the connection //identity// in front of each message received. An identity, sometimes called an //address//, is just a binary string with no meaning except \"this is a unique handle to the connection\". Then, when you send a message via a ROUTER socket, you first send an identity frame.\n\nThe {{zmq_socket[3]}} man page describes it thus:\n\n> When receiving messages a ZMQ_ROUTER socket shall prepend a message part containing the identity of the originating peer to the message before passing it to the application. Messages received are fair-queued from among all connected peers. When sending messages a ZMQ_ROUTER socket shall remove the first part of the message and use it to determine the identity of the peer the message shall be routed to.\n\nAs a historical note, ZeroMQ v2.2 and earlier use UUIDs as identities. ZeroMQ v3.0 and later generate a 5 byte identity by default (0 + a random 32bit integer). There's some impact on network performance, but only when you use multiple proxy hops, which is rare. Mostly the change was to simplify building {{libzmq}} by removing the dependency on a UUID library.\n\nIdentities are a difficult concept to understand, but it's essential if you want to become a ZeroMQ expert. The ROUTER socket //invents// a random identity for each connection with which it works. If there are three REQ sockets connected to a ROUTER socket, it will invent three random identities, one for each REQ socket.\n\nSo if we continue our worked example, let's say the REQ socket has a 3-byte identity {{ABC}}. Internally, this means the ROUTER socket keeps a hash table where it can search for {{ABC}} and find the TCP connection for the REQ socket.\n\nWhen we receive the message off the ROUTER socket, we get three frames[figure].\n\n[[code type=\"textdiagram\" title=\"Request with One Address\"]]\n          #---+-----#\nFrame 1   | 3 | ABC |      Identity of connection\n          #---#-----#\nFrame 2   | 0 |            Empty delimiter frame\n          #---#-------#\nFrame 3   | 5 | Hello |    Data frame\n          #---+-------#\n[[/code]]\n\nThe core of the proxy loop is \"read from one socket, write to the other\", so we literally send these three frames out on the DEALER socket. If you now sniffed the network traffic, you would see these three frames flying from the DEALER socket to the REP socket. The REP socket does as before, strips off the whole envelope including the new reply address, and once again delivers the \"Hello\" to the caller.\n\nIncidentally the REP socket can only deal with one request-reply exchange at a time, which is why if you try to read multiple requests or send multiple replies without sticking to a strict recv-send cycle, it gives an error.\n\nYou should now be able to visualize the return path. When {{hwserver}} sends \"World\" back, the REP socket wraps that with the envelope it saved, and sends a three-frame reply message across the wire to the DEALER socket[figure].\n\n[[code type=\"textdiagram\" title=\"Reply with one Address\"]]\n          #---+-----#\nFrame 1   | 3 | ABC |      Identity of connection\n          #---#-----#\nFrame 2   | 0 |            Empty delimiter frame\n          #---#-------#\nFrame 3   | 5 | World |    Data frame\n          #---+-------#\n[[/code]]\n\nNow the DEALER reads these three frames, and sends all three out via the ROUTER socket. The ROUTER takes the first frame for the message, which is the {{ABC}} identity, and looks up the connection for this. If it finds that, it then pumps the next two frames out onto the wire[figure].\n\n[[code type=\"textdiagram\" title=\"Reply with Minimal Envelope\"]]\n          #---#\nFrame 1   | 0 |            Empty delimiter frame\n          #---#-------#\nFrame 2   | 5 | World |    Data frame\n          #---+-------#\n[[/code]]\n\nThe REQ socket picks this message up, and checks that the first frame is the empty delimiter, which it is. The REQ socket discards that frame and passes \"World\" to the calling application, which prints it out to the amazement of the younger us looking at ZeroMQ for the first time.\n\n+++ What's This Good For?\n\nTo be honest, the use cases for strict request-reply or extended request-reply are somewhat limited. For one thing, there's no easy way to recover from common failures like the server crashing due to buggy application code. We'll see more about this in [#reliable-request-reply]. However once you grasp the way these four sockets deal with envelopes, and how they talk to each other, you can do very useful things. We saw how ROUTER uses the reply envelope to decide which client REQ socket to route a reply back to. Now let's express this another way:\n\n* Each time ROUTER gives you a message, it tells you what peer that came from, as an identity.\n* You can use this with a hash table (with the identity as key) to track new peers as they arrive.\n* ROUTER will route messages asynchronously to any peer connected to it, if you prefix the identity as the first frame of the message.\n\nROUTER sockets don't care about the whole envelope. They don't know anything about the empty delimiter. All they care about is that one identity frame that lets them figure out which connection to send a message to.\n\n+++ Recap of Request-Reply Sockets\n\nLet's recap this:\n\n* The REQ socket sends, to the network, an empty delimiter frame in front of the message data. REQ sockets are synchronous. REQ sockets always send one request and then wait for one reply. REQ sockets talk to one peer at a time. If you connect a REQ socket to multiple peers, requests are distributed to and replies expected from each peer one turn at a time.\n\n* The REP socket reads and saves all identity frames up to and including the empty delimiter, then passes the following frame or frames to the caller. REP sockets are synchronous and talk to one peer at a time. If you connect a REP socket to multiple peers, requests are read from peers in fair fashion, and replies are always sent to the same peer that made the last request.\n\n* The DEALER socket is oblivious to the reply envelope and handles this like any multipart message. DEALER sockets are asynchronous and like PUSH and PULL combined. They distribute sent messages among all connections, and fair-queue received messages from all connections.\n\n* The ROUTER socket is oblivious to the reply envelope, like DEALER. It creates identities for its connections, and passes these identities to the caller as a first frame in any received message. Conversely, when the caller sends a message, it uses the first message frame as an identity to look up the connection to send to. ROUTERS are asynchronous.\n\n++ Request-Reply Combinations\n\nWe have four request-reply sockets, each with a certain behavior. We've seen how they connect in simple and extended request-reply patterns. But these sockets are building blocks that you can use to solve many problems.\n\nThese are the legal combinations:\n\n* REQ to REP\n* DEALER to REP\n* REQ to ROUTER\n* DEALER to ROUTER\n* DEALER to DEALER\n* ROUTER to ROUTER\n\nAnd these combinations are invalid (and I'll explain why):\n\n* REQ to REQ\n* REQ to DEALER\n* REP to REP\n* REP to ROUTER\n\nHere are some tips for remembering the semantics. DEALER is like an asynchronous REQ socket, and ROUTER is like an asynchronous REP socket. Where we use a REQ socket, we can use a DEALER; we just have to read and write the envelope ourselves. Where we use a REP socket, we can stick a ROUTER; we just need to manage the identities ourselves.\n\nThink of REQ and DEALER sockets as \"clients\" and REP and ROUTER sockets as \"servers\". Mostly, you'll want to bind REP and ROUTER sockets, and connect REQ and DEALER sockets to them. It's not always going to be this simple, but it is a clean and memorable place to start.\n\n+++ The REQ to REP Combination\n\nWe've already covered a REQ client talking to a REP server but let's take one aspect: the REQ client //must// initiate the message flow. A REP server cannot talk to a REQ client that hasn't first sent it a request. Technically, it's not even possible, and the API also returns an {{EFSM}} error if you try it.\n\n+++ The DEALER to REP Combination\n\nNow, let's replace the REQ client with a DEALER. This gives us an asynchronous client that can talk to multiple REP servers. If we rewrote the \"Hello World\" client using DEALER, we'd be able to send off any number of \"Hello\" requests without waiting for replies.\n\nWhen we use a DEALER to talk to a REP socket, we //must// accurately emulate the envelope that the REQ socket would have sent, or the REP socket will discard the message as invalid. So, to send a message, we:\n\n* Send an empty message frame with the MORE flag set; then\n* Send the message body.\n\nAnd when we receive a message, we:\n\n* Receive the first frame and if it's not empty, discard the whole message;\n* Receive the next frame and pass that to the application.\n\n+++ The REQ to ROUTER Combination\n\nIn the same way that we can replace REQ with DEALER, we can replace REP with ROUTER. This gives us an asynchronous server that can talk to multiple REQ clients at the same time. If we rewrote the \"Hello World\" server using ROUTER, we'd be able to process any number of \"Hello\" requests in parallel. We saw this in the [#sockets-and-patterns] {{mtserver}} example.\n\nWe can use ROUTER in two distinct ways:\n\n* As a proxy that switches messages between frontend and backend sockets.\n* As an application that reads the message and acts on it.\n\nIn the first case, the ROUTER simply reads all frames, including the artificial identity frame, and passes them on blindly. In the second case the ROUTER //must// know the format of the reply envelope it's being sent. As the other peer is a REQ socket, the ROUTER gets the identity frame, an empty frame, and then the data frame.\n\n+++ The DEALER to ROUTER Combination\n\nNow we can switch out both REQ and REP with DEALER and ROUTER to get the most powerful socket combination, which is DEALER talking to ROUTER. It gives us asynchronous clients talking to asynchronous servers, where both sides have full control over the message formats.\n\nBecause both DEALER and ROUTER can work with arbitrary message formats, if you hope to use these safely, you have to become a little bit of a protocol designer. At the very least you must decide whether you wish to emulate the REQ/REP reply envelope. It depends on whether you actually need to send replies or not.\n\n+++ The DEALER to DEALER Combination\n\nYou can swap a REP with a ROUTER, but you can also swap a REP with a DEALER, if the DEALER is talking to one and only one peer.\n\nWhen you replace a REP with a DEALER, your worker can suddenly go full asynchronous, sending any number of replies back. The cost is that you have to manage the reply envelopes yourself, and get them right, or nothing at all will work. We'll see a worked example later. Let's just say for now that DEALER to DEALER is one of the trickier patterns to get right, and happily it's rare that we need it.\n\n+++ The ROUTER to ROUTER Combination\n\nThis sounds perfect for N-to-N connections, but it's the most difficult combination to use. You should avoid it until you are well advanced with ZeroMQ. We'll see one example it in the Freelance pattern in [#reliable-request-reply], and an alternative DEALER to ROUTER design for peer-to-peer work in [#moving-pieces].\n\n+++ Invalid Combinations\n\nMostly, trying to connect clients to clients, or servers to servers is a bad idea and won't work. However, rather than give general vague warnings, I'll explain in detail:\n\n* REQ to REQ: both sides want to start by sending messages to each other, and this could only work if you timed things so that both peers exchanged messages at the same time. It hurts my brain to even think about it.\n\n* REQ to DEALER: you could in theory do this, but it would break if you added a second REQ because DEALER has no way of sending a reply to the original peer. Thus the REQ socket would get confused, and/or return messages meant for another client.\n\n* REP to REP: both sides would wait for the other to send the first message.\n\n* REP to ROUTER: the ROUTER socket can in theory initiate the dialog and send a properly-formatted request, if it knows the REP socket has connected //and// it knows the identity of that connection. It's messy and adds nothing over DEALER to ROUTER.\n\nThe common thread in this valid versus invalid breakdown is that a ZeroMQ socket connection is always biased towards one peer that binds to an endpoint, and another that connects to that. Further, that which side binds and which side connects is not arbitrary, but follows natural patterns. The side which we expect to \"be there\" binds: it'll be a server, a broker, a publisher, a collector. The side that \"comes and goes\" connects: it'll be clients and workers. Remembering this will help you design better ZeroMQ architectures.\n\n++ Exploring ROUTER Sockets\n\nLet's look at ROUTER sockets a little closer. We've already seen how they work by routing individual messages to specific connections. I'll explain in more detail how we identify those connections, and what a ROUTER socket does when it can't send a message.\n\n+++ Identities and Addresses\n\nThe //identity// concept in ZeroMQ refers specifically to ROUTER sockets and how they identify the connections they have to other sockets. More broadly, identities are used as addresses in the reply envelope. In most cases, the identity is arbitrary and local to the ROUTER socket: it's a lookup key in a hash table. Independently, a peer can have an address that is physical (a network endpoint like \"tcp://192.168.55.117:5670\") or logical (a UUID or email address or other unique key).\n\nAn application that uses a ROUTER socket to talk to specific peers can convert a logical address to an identity if it has built the necessary hash table. Because ROUTER sockets only announce the identity of a connection (to a specific peer) when that peer sends a message, you can only really reply to a message, not spontaneously talk to a peer.\n\nThis is true even if you flip the rules and make the ROUTER connect to the peer rather than wait for the peer to connect to the ROUTER. However you can force the ROUTER socket to use a logical address in place of its identity. The {{zmq_setsockopt}} reference page calls this //setting the socket identity//. It works as follows:\n\n* The peer application sets the {{ZMQ_IDENTITY}} option of its peer socket (DEALER or REQ) //before// binding or connecting.\n* Usually the peer then connects to the already-bound ROUTER socket. But the ROUTER can also connect to the peer.\n* At connection time, the peer socket tells the router socket, \"please use this identity for this connection\".\n* If the peer socket doesn't say that, the router generates its usual arbitrary random identity for the connection.\n* The ROUTER socket now provides this logical address to the application as a prefix identity frame for any messages coming in from that peer.\n* The ROUTER also expects the logical address as the prefix identity frame for any outgoing messages.\n\nHere is a simple example of two peers that connect to a ROUTER socket, one that imposes a logical address \"PEER2\":\n\n[[code type=\"example\" title=\"Identity check\" name=\"identity\"]]\n[[/code]]\n\nHere is what the program prints:\n\n[[code]]\n----------------------------------------\n[005] 006B8B4567\n[000]\n[039] ROUTER uses a generated 5 byte identity\n----------------------------------------\n[005] PEER2\n[000]\n[038] ROUTER uses REQ's socket identity\n[[/code]]\n\n+++ ROUTER Error Handling\n\nROUTER sockets do have a somewhat brutal way of dealing with messages they can't send anywhere: they drop them silently. It's an attitude that makes sense in working code, but it makes debugging hard. The \"send identity as first frame\" approach is tricky enough that we often get this wrong when we're learning, and the ROUTER's stony silence when we mess up isn't very constructive.\n\nSince ZeroMQ v3.2 there's a socket option you can set to catch this error: {{ZMQ_ROUTER_MANDATORY}}. Set that on the ROUTER socket and then when you provide an unroutable identity on a send call, the socket will signal an {{EHOSTUNREACH}} error.\n\n++ The Load Balancing Pattern\n\nNow let's look at some code. We'll see how to connect a ROUTER socket to a REQ socket, and then to a DEALER socket. These two examples follow the same logic, which is a //load balancing// pattern. This pattern is our first exposure to using the ROUTER socket for deliberate routing, rather than simply acting as a reply channel.\n\nThe load balancing pattern is very common and we'll see it several times in this book. It solves the main problem with simple round robin routing (as PUSH and DEALER offer) which is that round robin becomes inefficient if tasks do not all roughly take the same time.\n\nIt's the post office analogy. If you have one queue per counter, and you have some people buying stamps (a fast, simple transaction), and some people opening new accounts (a very slow transaction), then you will find stamp buyers getting unfairly stuck in queues. Just as in a post office, if your messaging architecture is unfair, people will get annoyed.\n\nThe solution in the post office is to create a single queue so that even if one or two counters get stuck with slow work, other counters will continue to serve clients on a first-come, first-serve basis.\n\nOne reason PUSH and DEALER use the simplistic approach is sheer performance. If you arrive in any major US airport, you'll find long queues of people waiting at immigration. The border patrol officials will send people in advance to queue up at each counter, rather than using a single queue. Having people walk fifty yards in advance saves a minute or two per passenger. And because every passport check takes roughly the same time, it's more or less fair. This is the strategy for PUSH and DEALER: send work loads ahead of time so that there is less travel distance.\n\nThis is a recurring theme with ZeroMQ: the world's problems are diverse and you can benefit from solving different problems each in the right way. The airport isn't the post office and one size fits no one, really well.\n\nLet's return to the scenario of a worker (DEALER or REQ) connected to a broker (ROUTER). The broker has to know when the worker is ready, and keep a list of workers so that it can take the //least recently used// worker each time.\n\nThe solution is really simple, in fact: workers send a \"ready\" message when they start, and after they finish each task. The broker reads these messages one-by-one. Each time it reads a message, it is from the last used worker. And because we're using a ROUTER socket, we get an identity that we can then use to send a task back to the worker.\n\nIt's a twist on request-reply because the task is sent with the reply, and any response for the task is sent as a new request. The following code examples should make it clearer.\n\n+++ ROUTER Broker and REQ Workers\n\nHere is an example of the load balancing pattern using a ROUTER broker talking to a set of REQ workers:\n\n[[code type=\"example\" title=\"ROUTER-to-REQ\" name=\"rtreq\"]]\n[[/code]]\n\nThe example runs for five seconds and then each worker prints how many tasks they handled. If the routing worked, we'd expect a fair distribution of work:\n\n[[code]]\nCompleted: 20 tasks\nCompleted: 18 tasks\nCompleted: 21 tasks\nCompleted: 23 tasks\nCompleted: 19 tasks\nCompleted: 21 tasks\nCompleted: 17 tasks\nCompleted: 17 tasks\nCompleted: 25 tasks\nCompleted: 19 tasks\n[[/code]]\n\nTo talk to the workers in this example, we have to create a REQ-friendly envelope consisting of an identity plus an empty envelope delimiter frame[figure].\n\n[[code type=\"textdiagram\" title=\"Routing Envelope for REQ\"]]\n          #---+-------#\nFrame 1   | n | ...   |     Identity of connection\n          #---#-------#\nFrame 2   | 0 |             Empty delimiter frame\n          #---#--------#\nFrame 3   | n | ...    |    Data frame\n          #---+--------#\n[[/code]]\n\n+++ ROUTER Broker and DEALER Workers\n\nAnywhere you can use REQ, you can use DEALER. There are two specific differences:\n\n* The REQ socket always sends an empty delimiter frame before any data frames; the DEALER does not.\n* The REQ socket will send only one message before it receives a reply; the DEALER is fully asynchronous.\n\nThe synchronous versus asynchronous behavior has no effect on our example because we're doing strict request-reply. It is more relevant when we address recovering from failures, which we'll come to in [#reliable-request-reply].\n\nNow let's look at exactly the same example but with the REQ socket replaced by a DEALER socket:\n\n[[code type=\"example\" title=\"ROUTER-to-DEALER\" name=\"rtdealer\"]]\n[[/code]]\n\nThe code is almost identical except that the worker uses a DEALER socket, and reads and writes that empty frame before the data frame. This is the approach I use when I want to keep compatibility with REQ workers.\n\nHowever, remember the reason for that empty delimiter frame: it's to allow multihop extended requests that terminate in a REP socket, which uses that delimiter to split off the reply envelope so it can hand the data frames to its application.\n\nIf we never need to pass the message along to a REP socket, we can simply drop the empty delimiter frame at both sides, which makes things simpler. This is usually the design I use for pure DEALER to ROUTER protocols.\n\n+++ A Load Balancing Message Broker\n\nThe previous example is half-complete. It can manage a set of workers with dummy requests and replies, but it has no way to talk to clients. If we add a second //frontend// ROUTER socket that accepts client requests, and turn our example into a proxy that can switch messages from frontend to backend, we get a useful and reusable tiny load balancing message broker[figure].\n\n[[code type=\"textdiagram\" title=\"Load Balancing Broker\"]]\n#--------#  #--------#  #--------#\n| Client |  | Client |  | Client |\n+--------+  +--------+  +--------+\n|  REQ   |  |  REQ   |  |  REQ   |\n'---+----'  '---+----'  '---+----'\n    |           |           |\n    '-----------+-----------'\n                |\n            .---+----.\n            | ROUTER |  Frontend\n            +--------+\n            | Proxy  |  Load balancer\n            +--------+\n            | ROUTER |  Backend\n            '---+----'\n                |\n    .-----------+-----------.\n    |           |           |\n.---+----.  .---+----.  .---+----.\n|  REQ   |  |  REQ   |  |  REQ   |\n+--------+  +--------+  +--------+\n| Worker |  | Worker |  | Worker |\n#--------#  #--------#  #--------#\n[[/code]]\n\nThis broker does the following:\n\n* Accepts connections from a set of clients.\n* Accepts connections from a set of workers.\n* Accepts requests from clients and holds these in a single queue.\n* Sends these requests to workers using the load balancing pattern.\n* Receives replies back from workers.\n* Sends these replies back to the original requesting client.\n\nThe broker code is fairly long, but worth understanding:\n\n[[code type=\"example\" title=\"Load balancing broker\" name=\"lbbroker\"]]\n[[/code]]\n\nThe difficult part of this program is (a) the envelopes that each socket reads and writes, and (b) the load balancing algorithm. We'll take these in turn, starting with the message envelope formats.\n\nLet's walk through a full request-reply chain from client to worker and back. In this code we set the identity of client and worker sockets to make it easier to trace the message frames. In reality, we'd allow the ROUTER sockets to invent identities for connections. Let's assume the client's identity is \"CLIENT\" and the worker's identity is \"WORKER\". The client application sends a single frame containing \"Hello\"[figure].\n\n[[code type=\"textdiagram\" title=\"Message that Client Sends\"]]\n          #---+-------#\nFrame 1   | 5 | Hello |   Data frame\n          #---+-------#\n[[/code]]\n\nBecause the REQ socket adds its empty delimiter frame and the ROUTER socket adds its connection identity, the proxy reads off the frontend ROUTER socket the client address, empty delimiter frame, and the data part[figure].\n\n[[code type=\"textdiagram\" title=\"Message Coming in on Frontend\"]]\n          #---+--------#\nFrame 1   | 6 | CLIENT |   Client address\n          #---#--------#\nFrame 2   | 0 |            Empty delimiter frame\n          #---#-------#\nFrame 3   | 5 | Hello |    Data frame\n          #---+-------#\n[[/code]]\n\nThe broker sends this to the worker, prefixed by the address of the chosen worker, plus an additional empty part to keep the REQ at the other end happy[figure].\n\n[[code type=\"textdiagram\" title=\"Message Sent to Backend\"]]\n          #---+--------#\nFrame 1   | 6 | WORKER |   Address of worker\n          #---#--------#\nFrame 2   | 0 |            Empty delimiter frame\n          #---#--------#\nFrame 3   | 6 | CLIENT |   Identity of client\n          #---#--------#\nFrame 4   | 0 |            Empty delimiter frame\n          #---#-------#\nFrame 5   | 5 | Hello |    Data frame\n          #---+-------#\n[[/code]]\n\nThis complex envelope stack gets chewed up first by the backend ROUTER socket, which removes the first frame. Then the REQ socket in the worker removes the empty part, and provides the rest to the worker application[figure].\n\n[[code type=\"textdiagram\" title=\"Message Delivered to Worker\"]]\n          #---+--------#\nFrame 1   | 6 | CLIENT |   Identity of client\n          #---#--------#\nFrame 2   | 0 |            Empty delimiter frame\n          #---#-------#\nFrame 3   | 5 | Hello |    Data frame\n          #---+-------#\n[[/code]]\n\nThe worker has to save the envelope (which is all the parts up to and including the empty message frame) and then it can do what's needed with the data part. Note that a REP socket would do this automatically, but we're using the REQ-ROUTER pattern so that we can get proper load balancing.\n\nOn the return path, the messages are the same as when they come in, i.e., the backend socket gives the broker a message in five parts, and the broker sends the frontend socket a message in three parts, and the client gets a message in one part.\n\nNow let's look at the load balancing algorithm. It requires that both clients and workers use REQ sockets, and that workers correctly store and replay the envelope on messages they get. The algorithm is:\n\n* Create a pollset that always polls the backend, and polls the frontend only if there are one or more workers available.\n\n* Poll for activity with infinite timeout.\n\n* If there is activity on the backend, we either have a \"ready\" message or a reply for a client. In either case, we store the worker address (the first part) on our worker queue, and if the rest is a client reply, we send it back to that client via the frontend.\n\n* If there is activity on the frontend, we take the client request, pop the next worker (which is the last used), and send the request to the backend. This means sending the worker address, empty part, and then the three parts of the client request.\n\nYou should now see that you can reuse and extend the load balancing algorithm with variations based on the information the worker provides in its initial \"ready\" message. For example, workers might start up and do a performance self test, then tell the broker how fast they are. The broker can then choose the fastest available worker rather than the oldest.\n\n++ A High-Level API for ZeroMQ\n\nWe're going to push request-reply onto the stack and open a different area, which is the ZeroMQ API itself. There's a reason for this detour: as we write more complex examples, the low-level ZeroMQ API starts to look increasingly clumsy. Look at the core of the worker thread from our load balancing broker:\n\n[[code type=\"fragment\" name=\"lbreader\"]]\nwhile (true) {\n    //  Get one address frame and empty delimiter\n    char *address = s_recv (worker);\n    char *empty = s_recv (worker);\n    assert (*empty == 0);\n    free (empty);\n\n    //  Get request, send reply\n    char *request = s_recv (worker);\n    printf (\"Worker: %s\\n\", request);\n    free (request);\n\n    s_sendmore (worker, address);\n    s_sendmore (worker, \"\");\n    s_send     (worker, \"OK\");\n    free (address);\n}\n[[/code]]\n\nThat code isn't even reusable because it can only handle one reply address in the envelope, and it already does some wrapping around the ZeroMQ API. If we used the {{libzmq}} simple message API this is what we'd have to write:\n\n[[code type=\"fragment\" name=\"lowreader\"]]\nwhile (true) {\n    //  Get one address frame and empty delimiter\n    char address [255];\n    int address_size = zmq_recv (worker, address, 255, 0);\n    if (address_size == -1)\n        break;\n\n    char empty [1];\n    int empty_size = zmq_recv (worker, empty, 1, 0);\n    assert (empty_size <= 0);\n    if (empty_size == -1)\n        break;\n\n    //  Get request, send reply\n    char request [256];\n    int request_size = zmq_recv (worker, request, 255, 0);\n    if (request_size == -1)\n        return NULL;\n    request [request_size] = 0;\n    printf (\"Worker: %s\\n\", request);\n    \n    zmq_send (worker, address, address_size, ZMQ_SNDMORE);\n    zmq_send (worker, empty, 0, ZMQ_SNDMORE);\n    zmq_send (worker, \"OK\", 2, 0);\n}\n[[/code]]\n\nAnd when code is too long to write quickly, it's also too long to understand. Up until now, I've stuck to the native API because, as ZeroMQ users, we need to know that intimately. But when it gets in our way, we have to treat it as a problem to solve.\n\nWe can't of course just change the ZeroMQ API, which is a documented public contract on which thousands of people agree and depend. Instead, we construct a higher-level API on top based on our experience so far, and most specifically, our experience from writing more complex request-reply patterns.\n\nWhat we want is an API that lets us receive and send an entire message in one shot, including the reply envelope with any number of reply addresses. One that lets us do what we want with the absolute least lines of code.\n\nMaking a good message API is fairly difficult. We have a problem of terminology: ZeroMQ uses \"message\" to describe both multipart messages, and individual message frames. We have a problem of expectations: sometimes it's natural to see message content as printable string data, sometimes as binary blobs. And we have technical challenges, especially if we want to avoid copying data around too much.\n\nThe challenge of making a good API affects all languages, though my specific use case is C. Whatever language you use, think about how you could contribute to your language binding to make it as good (or better) than the C binding I'm going to describe.\n\n+++ Features of a Higher-Level API\n\nMy solution is to use three fairly natural and obvious concepts: //string// (already the basis for our {{s_send}} and {{s_recv}}) helpers, //frame// (a message frame), and //message// (a list of one or more frames). Here is the worker code, rewritten onto an API using these concepts:\n\n[[code type=\"fragment\" name=\"highreader\"]]\nwhile (true) {\n    zmsg_t *msg = zmsg_recv (worker);\n    zframe_reset (zmsg_last (msg), \"OK\", 2);\n    zmsg_send (&msg, worker);\n}\n[[/code]]\n\nCutting the amount of code we need to read and write complex messages is great: the results are easy to read and understand. Let's continue this process for other aspects of working with ZeroMQ. Here's a wish list of things I'd like in a higher-level API, based on my experience with ZeroMQ so far:\n\n* //Automatic handling of sockets.// I find it cumbersome to have to close sockets manually, and to have to explicitly define the linger timeout in some (but not all) cases. It'd be great to have a way to close sockets automatically when I close the context.\n\n* //Portable thread management.// Every nontrivial ZeroMQ application uses threads, but POSIX threads aren't portable. So a decent high-level API should hide this under a portable layer.\n\n* //Piping from parent to child threads.// It's a recurrent problem: how to signal between parent and child threads. Our API should provide a ZeroMQ message pipe (using PAIR sockets and {{inproc}} automatically).\n\n* //Portable clocks.// Even getting the time to a millisecond resolution, or sleeping for some milliseconds, is not portable. Realistic ZeroMQ applications need portable clocks, so our API should provide them.\n\n* //A reactor to replace {{zmq_poll[3]}}.// The poll loop is simple, but clumsy. Writing a lot of these, we end up doing the same work over and over: calculating timers, and calling code when sockets are ready. A simple reactor with socket readers and timers would save a lot of repeated work.\n\n* //Proper handling of Ctrl-C.// We already saw how to catch an interrupt. It would be useful if this happened in all applications.\n\n+++ The CZMQ High-Level API\n\nTurning this wish list into reality for the C language gives us [http://zero.mq/c CZMQ], a ZeroMQ language binding for C. This high-level binding, in fact, developed out of earlier versions of the examples. It combines nicer semantics for working with ZeroMQ with some portability layers, and (importantly for C, but less for other languages) containers like hashes and lists. CZMQ also uses an elegant object model that leads to frankly lovely code.\n\nHere is the load balancing broker rewritten to use a higher-level API (CZMQ for the C case):\n\n[[code type=\"example\" title=\"Load balancing broker using high-level API\" name=\"lbbroker2\"]]\n[[/code]]\n\nOne thing CZMQ provides is clean interrupt handling. This means that Ctrl-C will cause any blocking ZeroMQ call to exit with a return code -1 and errno set to {{EINTR}}. The high-level recv methods will return NULL in such cases. So, you can cleanly exit a loop like this:\n\n[[code type=\"fragment\" name=\"interrupt\"]]\nwhile (true) {\n    zstr_send (client, \"Hello\");\n    char *reply = zstr_recv (client);\n    if (!reply)\n        break;              //  Interrupted\n    printf (\"Client: %s\\n\", reply);\n    free (reply);\n    sleep (1);\n}\n[[/code]]\n\nOr, if you're calling {{zmq_poll[3]}}, test on the return code:\n\n[[code type=\"fragment\" name=\"polling\"]]\nif (zmq_poll (items, 2, 1000 * 1000) == -1)\n    break;              //  Interrupted\n[[/code]]\n\nThe previous example still uses {{zmq_poll[3]}}. So how about reactors? The CZMQ {{zloop}} reactor is simple but functional. It lets you:\n\n* Set a reader on any socket, i.e., code that is called whenever the socket has input.\n* Cancel a reader on a socket.\n* Set a timer that goes off once or multiple times at specific intervals.\n* Cancel a timer.\n\n{{zloop}} of course uses {{zmq_poll[3]}} internally. It rebuilds its poll set each time you add or remove readers, and it calculates the poll timeout to match the next timer. Then, it calls the reader and timer handlers for each socket and timer that need attention.\n\nWhen we use a reactor pattern, our code turns inside out. The main logic looks like this:\n\n[[code type=\"fragment\" name=\"reactor\"]]\nzloop_t *reactor = zloop_new ();\nzloop_reader (reactor, self->backend, s_handle_backend, self);\nzloop_start (reactor);\nzloop_destroy (&reactor);\n[[/code]]\n\nThe actual handling of messages sits inside dedicated functions or methods. You may not like the style--it's a matter of taste. What it does help with is mixing timers and socket activity. In the rest of this text, we'll use {{zmq_poll[3]}} in simpler cases, and {{zloop}} in more complex examples.\n\nHere is the load balancing broker rewritten once again, this time to use {{zloop}}:\n\n[[code type=\"example\" title=\"Load balancing broker using zloop\" name=\"lbbroker3\"]]\n[[/code]]\n\nGetting applications to properly shut down when you send them Ctrl-C can be tricky. If you use the {{zctx}} class it'll automatically set up signal handling, but your code still has to cooperate. You must break any loop if {{zmq_poll}} returns -1 or if any of the {{zstr_recv}}, {{zframe_recv}}, or {{zmsg_recv}} methods return NULL. If you have nested loops, it can be useful to make the outer ones conditional on {{!zctx_interrupted}}.\n\nIf you're using child threads, they won't receive the interrupt. To tell them to shutdown, you can either:\n\n* Destroy the context, if they are sharing the same context, in which case any blocking calls they are waiting on will end with ETERM.\n* Send them shutdown messages, if they are using their own contexts. For this you'll need some socket plumbing.\n\n++ The Asynchronous Client/Server Pattern\n\nIn the ROUTER to DEALER example, we saw a 1-to-N use case where one server talks asynchronously to multiple workers. We can turn this upside down to get a very useful N-to-1 architecture where various clients talk to a single server, and do this asynchronously[figure].\n\n[[code type=\"textdiagram\" title=\"Asynchronous Client/Server\"]]\n#----------#   #----------#\n|  Client  |   |  Client  |\n+----------+   +----------+\n|  DEALER  |   |  DEALER  |\n'----------'   '----------'\n      ^              ^\n      |              |\n      '------+-------'\n             |\n             v\n      .-------------.\n      |   ROUTER    |\n      +-------------+\n      |   Server    |\n      #-------------#\n[[/code]]\n\nHere's how it works:\n\n* Clients connect to the server and send requests.\n* For each request, the server sends 0 or more replies.\n* Clients can send multiple requests without waiting for a reply.\n* Servers can send multiple replies without waiting for new requests.\n\nHere's code that shows how this works:\n\n[[code type=\"example\" title=\"Asynchronous client/server\" name=\"asyncsrv\"]]\n[[/code]]\n\nThe example runs in one process, with multiple threads simulating a real multiprocess architecture. When you run the example, you'll see three clients (each with a random ID), printing out the replies they get from the server. Look carefully and you'll see each client task gets 0 or more replies per request.\n\nSome comments on this code:\n\n* The clients send a request once per second, and get zero or more replies back. To make this work using {{zmq_poll[3]}}, we can't simply poll with a 1-second timeout, or we'd end up sending a new request only one second //after we received the last reply//. So we poll at a high frequency (100 times at 1/100th of a second per poll), which is approximately accurate.\n\n* The server uses a pool of worker threads, each processing one request synchronously. It connects these to its frontend socket using an internal queue[figure]. It connects the frontend and backend sockets using a {{zmq_proxy[3]}} call.\n\n[[code type=\"textdiagram\" title=\"Detail of Asynchronous Server\"]]\n   #---------#   #---------#   #---------#\n   | Client  |   | Client  |   | Client  |\n   +---------+   +---------+   +---------+\n   | DEALER  |   | DEALER  |   | DEALER  |\n   '---------'   '---------'   '---------'\n     connect       connect       connect\n        |             |             |\n        '-------------+-------------'\n                      |\n.-------------------- | --------------------.\n:                     v                     :\n:                   bind                    :\n:               .-----------.               :\n:               |  ROUTER   |               :\n:               +-----------+               :\n:               |  Server   |               :\n:               +-----------+               :\n:               |  DEALER   |               :\n:               '-----------'               :\n:                   bind                    :\n:                     |                     :\n:       .-------------+-------------.       :\n:       |             |             |       :\n:       v             v             v       :\n:    connect       connect       connect    :\n:  .---------.   .---------.   .---------.  :\n:  | DEALER  |   | DEALER  |   | DEALER  |  :\n:  +---------+   +---------+   +---------+  :\n:  | Worker  |   | Worker  |   | Worker  |  :\n:  #---------#   #---------#   #---------#  :\n'-------------------------------------------'\n[[/code]]\n\nNote that we're doing DEALER to ROUTER dialog between client and server, but internally between the server main thread and workers, we're doing DEALER to DEALER. If the workers were strictly synchronous, we'd use REP. However, because we want to send multiple replies, we need an async socket. We do //not// want to route replies, they always go to the single server thread that sent us the request.\n\nLet's think about the routing envelope. The client sends a message consisting of a single frame. The server thread receives a two-frame message (original message prefixed by client identity). We send these two frames on to the worker, which treats it as a normal reply envelope, returns that to us as a two frame message. We then use the first frame as an identity to route the second frame back to the client as a reply.\n\nIt looks something like this:\n\n[[code]]\n     client          server       frontend       worker\n   [ DEALER ]<---->[ ROUTER <----> DEALER <----> DEALER ]\n             1 part         2 parts       2 parts\n[[/code]]\n\nNow for the sockets: we could use the load balancing ROUTER to DEALER pattern to talk to workers, but it's extra work. In this case, a DEALER to DEALER pattern is probably fine: the trade-off is lower latency for each request, but higher risk of unbalanced work distribution. Simplicity wins in this case.\n\nWhen you build servers that maintain stateful conversations with clients, you will run into a classic problem. If the server keeps some state per client, and clients keep coming and going, eventually it will run out of resources. Even if the same clients keep connecting, if you're using default identities, each connection will look like a new one.\n\nWe cheat in the above example by keeping state only for a very short time (the time it takes a worker to process a request) and then throwing away the state. But that's not practical for many cases. To properly manage client state in a stateful asynchronous server, you have to:\n\n* Do heartbeating from client to server. In our example, we send a request once per second, which can reliably be used as a heartbeat.\n\n* Store state using the client identity (whether generated or explicit) as key.\n\n* Detect a stopped heartbeat. If there's no request from a client within, say, two seconds, the server can detect this and destroy any state it's holding for that client.\n\n++ Worked Example: Inter-Broker Routing\n\nLet's take everything we've seen so far, and scale things up to a real application. We'll build this step-by-step over several iterations. Our best client calls us urgently and asks for a design of a large cloud computing facility. He has this vision of a cloud that spans many data centers, each a cluster of clients and workers, and that works together as a whole. Because we're smart enough to know that practice always beats theory, we propose to make a working simulation using ZeroMQ. Our client, eager to lock down the budget before his own boss changes his mind, and having read great things about ZeroMQ on Twitter, agrees.\n\n+++ Establishing the Details\n\nSeveral espressos later, we want to jump into writing code, but a little voice tells us to get more details before making a sensational solution to entirely the wrong problem. \"What kind of work is the cloud doing?\", we ask.\n\nThe client explains:\n\n* Workers run on various kinds of hardware, but they are all able to handle any task. There are several hundred workers per cluster, and as many as a dozen clusters in total.\n\n* Clients create tasks for workers. Each task is an independent unit of work and all the client wants is to find an available worker, and send it the task, as soon as possible. There will be a lot of clients and they'll come and go arbitrarily.\n\n* The real difficulty is to be able to add and remove clusters at any time. A cluster can leave or join the cloud instantly, bringing all its workers and clients with it.\n\n* If there are no workers in their own cluster, clients' tasks will go off to other available workers in the cloud.\n\n* Clients send out one task at a time, waiting for a reply. If they don't get an answer within X seconds, they'll just send out the task again. This isn't our concern; the client API does it already.\n\n* Workers process one task at a time; they are very simple beasts. If they crash, they get restarted by whatever script started them.\n\nSo we double-check to make sure that we understood this correctly:\n\n* \"There will be some kind of super-duper network interconnect between clusters, right?\", we ask. The client says, \"Yes, of course, we're not idiots.\"\n\n* \"What kind of volumes are we talking about?\", we ask. The client replies, \"Up to a thousand clients per cluster, each doing at most ten requests per second. Requests are small, and replies are also small, no more than 1K bytes each.\"\n\nSo we do a little calculation and see that this will work nicely over plain TCP. 2,500 clients x 10/second x 1,000 bytes x 2 directions = 50MB/sec or 400Mb/sec, not a problem for a 1Gb network.\n\nIt's a straightforward problem that requires no exotic hardware or protocols, just some clever routing algorithms and careful design. We start by designing one cluster (one data center) and then we figure out how to connect clusters together.\n\n+++ Architecture of a Single Cluster\n\nWorkers and clients are synchronous. We want to use the load balancing pattern to route tasks to workers. Workers are all identical; our facility has no notion of different services. Workers are anonymous; clients never address them directly. We make no attempt here to provide guaranteed delivery, retry, and so on.\n\nFor reasons we already examined, clients and workers won't speak to each other directly. It makes it impossible to add or remove nodes dynamically. So our basic model consists of the request-reply message broker we saw earlier[figure].\n\n[[code type=\"textdiagram\" title=\"Cluster Architecture\"]]\n#--------#  #--------#  #--------#\n| Client |  | Client |  | Client |\n+--------+  +--------+  +--------+\n|  REQ   |  |  REQ   |  |  REQ   |\n'---+----'  '---+----'  '---+----'\n    |           |           |\n    '-----------+-----------'\n                |\n          .-----+------.\n          |   ROUTER   |\n          +------------+\n          |    Load    |\n          |  balancer  |  Broker\n          +------------+\n          |   ROUTER   |\n          '-----+------'\n                |\n    .-----------+-----------.\n    |           |           |\n.---+----.  .---+----.  .---+----.\n|  REQ   |  |  REQ   |  |  REQ   |\n+--------+  +--------+  +--------+\n| Worker |  | Worker |  | Worker |\n#--------#  #--------#  #--------#\n[[/code]]\n\n+++ Scaling to Multiple Clusters\n\nNow we scale this out to more than one cluster. Each cluster has a set of clients and workers, and a broker that joins these together[figure].\n\n[[code type=\"textdiagram\" title=\"Multiple Clusters\"]]\n     Cluster 1          :          Cluster 2\n                        :\n.---.  .---.  .---.     :     .---.  .---.  .---.\n| C |  | C |  | C |     :     | C |  | C |  | C |\n'-+-'  '-+-'  '-+-'     :     '-+-'  '-+-'  #-+-'\n  |      |      |       :       |      |      |\n  |      |      |       :       |      |      |\n#-+------+------+-#     :     #-+------+------+-#\n|     Broker      |     :     |     Broker      |\n#-+------+------+-#     :     #-+------+------+-#\n  |      |      |       :       |      |      |\n  |      |      |       :       |      |      |\n.-+-.  .-+-.  .-+-.     :     .-+-.  .-+-.  .-+-.\n| W |  | W |  | W |     :     | W |  | W |  | W |\n'---'  '---'  '---'     :     '---'  '---'  '---'\n[[/code]]\n\nThe question is: how do we get the clients of each cluster talking to the workers of the other cluster? There are a few possibilities, each with pros and cons:\n\n* Clients could connect directly to both brokers. The advantage is that we don't need to modify brokers or workers. But clients get more complex and become aware of the overall topology. If we want to add a third or forth cluster, for example, all the clients are affected. In effect we have to move routing and failover logic into the clients and that's not nice.\n\n* Workers might connect directly to both brokers. But REQ workers can't do that, they can only reply to one broker. We might use REPs but REPs don't give us customizable broker-to-worker routing like load balancing does, only the built-in load balancing. That's a fail; if we want to distribute work to idle workers, we precisely need load balancing. One solution would be to use ROUTER sockets for the worker nodes. Let's label this \"Idea #1\".\n\n* Brokers could connect to each other. This looks neatest because it creates the fewest additional connections. We can't add clusters on the fly, but that is probably out of scope. Now clients and workers remain ignorant of the real network topology, and brokers tell each other when they have spare capacity. Let's label this \"Idea #2\".\n\nLet's explore Idea #1. In this model, we have workers connecting to both brokers and accepting jobs from either one[figure].\n\n[[code type=\"textdiagram\" title=\"Idea 1: Cross-connected Workers\"]]\n            Cluster 1               :  Cluster 2\n                                    :\n            #--------#              :  #--------#\n            |        |              :  |        |\n            +--------+              :  +--------+\n            | ROUTER |              :  | ROUTER |\n            '---+----'              :  '---+----'\n                |                   :      |\n      .---------+-+-----------+-----+------'\n      |         | |           |     :\n    .-+---------+-+---------. |     :\n    | |         | |         | |     :\n    | |         | |         | |     :\n.---+-+--.  .---+-+--.  .---+-+--.  :\n| ROUTER |  | ROUTER |  | ROUTER |  :\n+--------+  +--------+  +--------+  :\n| Worker |  | Worker |  | Worker |  :\n#--------#  #--------#  #--------#  :\n[[/code]]\n\nIt looks feasible. However, it doesn't provide what we wanted, which was that clients get local workers if possible and remote workers only if it's better than waiting. Also workers will signal \"ready\" to both brokers and can get two jobs at once, while other workers remain idle. It seems this design fails because again we're putting routing logic at the edges.\n\nSo, idea #2 then. We interconnect the brokers and don't touch the clients or workers, which are REQs like we're used to[figure].\n\n[[code type=\"textdiagram\" title=\"Idea 2: Brokers Talking to Each Other\"]]\n     Cluster 1         :         Cluster 2\n                       :\n.---.  .---.  .---.    :    .---.  .---.  .---.\n| C |  | C |  | C |    :    | C |  | C |  | C |\n'-+-'  '-+-'  '-+-'    :    '-+-'  '-+-'  '-+-'\n  |      |      |      :      |      |      |\n  |      |      |      :      |      |      |\n#-+------+------+-#    :    #-+------+------+-#\n|     Broker      |<---+--->|     Broker      |\n#-+------+------+-#    :    #-+------+------+-#\n  |      |      |      :      |      |      |\n  |      |      |      :      |      |      |\n.-+-.  .-+-.  .-+-.    :    .-+-.  .-+-.  .-+-.\n| W |  | W |  | W |    :    | W |  | W |  | W |\n'---'  '---'  '---'    :    '---'  '---'  '---'\n[[/code]]\n\nThis design is appealing because the problem is solved in one place, invisible to the rest of the world. Basically, brokers open secret channels to each other and whisper, like camel traders, \"Hey, I've got some spare capacity. If you have too many clients, give me a shout and we'll deal\".\n\nIn effect it is just a more sophisticated routing algorithm: brokers become subcontractors for each other. There are other things to like about this design, even before we play with real code:\n\n* It treats the common case (clients and workers on the same cluster) as default and does extra work for the exceptional case (shuffling jobs between clusters).\n\n* It lets us use different message flows for the different types of work. That means we can handle them differently, e.g., using different types of network connection.\n\n* It feels like it would scale smoothly. Interconnecting three or more brokers doesn't get overly complex. If we find this to be a problem, it's easy to solve by adding a super-broker.\n\nWe'll now make a worked example. We'll pack an entire cluster into one process. That is obviously not realistic, but it makes it simple to simulate, and the simulation can accurately scale to real processes. This is the beauty of ZeroMQ--you can design at the micro-level and scale that up to the macro-level. Threads become processes, and then become boxes and the patterns and logic remain the same. Each of our \"cluster\" processes contains client threads, worker threads, and a broker thread.\n\nWe know the basic model well by now:\n\n* The REQ client (REQ) threads create workloads and pass them to the broker (ROUTER).\n* The REQ worker (REQ) threads process workloads and return the results to the broker (ROUTER).\n* The broker queues and distributes workloads using the load balancing pattern.\n\n+++ Federation Versus Peering\n\nThere are several possible ways to interconnect brokers. What we want is to be able to tell other brokers, \"we have capacity\", and then receive multiple tasks. We also need to be able to tell other brokers, \"stop, we're full\". It doesn't need to be perfect; sometimes we may accept jobs we can't process immediately, then we'll do them as soon as possible.\n\nThe simplest interconnect is //federation//, in which brokers simulate clients and workers for each other. We would do this by connecting our frontend to the other broker's backend socket[figure]. Note that it is legal to both bind a socket to an endpoint and connect it to other endpoints.\n\n[[code type=\"textdiagram\" title=\"Cross-connected Brokers in Federation Model\"]]\n     Cluster 1          :         Cluster 2\n                        :\n.---.  .---.            :            .---.  .---.\n| C |  | C |            :            | C |  | C |\n'-+-'  '-+-'    .----.  :  .====.    '-+-'  '-+-'\n  |      |      |    |  :  :    |      |      |\n  |      |      |    |  :  :    |      |      |\n#-+------+------+-#  |  :  :  #-+------+------+-#\n|     Broker      |  |  :  :  |     Broker      |\n#-+------+--------#  |  :  :  #--------+------+-#\n  |      |      ^    |  :  :    ^      |      |\n  |      |      :    |  :  :    |      |      |\n.-+-.  .-+-.    :    '--+--+----'    .-+-.  .-+-.\n| W |  | W |    :       :  :         | W |  | W |\n'---'  '---'    :       :  :         '---'  '---'\n                '=======+=='\n                        :\n                        :\n[[/code]]\n\nThis would give us simple logic in both brokers and a reasonably good mechanism: when there are no workers, tell the other broker \"ready\", and accept one job from it. The problem is also that it is too simple for this problem. A federated broker would be able to handle only one task at a time. If the broker emulates a lock-step client and worker, it is by definition also going to be lock-step, and if it has lots of available workers they won't be used. Our brokers need to be connected in a fully asynchronous fashion.\n\nThe federation model is perfect for other kinds of routing, especially service-oriented architectures (SOAs), which route by service name and proximity rather than load balancing or round robin. So don't dismiss it as useless, it's just not right for all use cases.\n\nInstead of federation, let's look at a //peering// approach in which brokers are explicitly aware of each other and talk over privileged channels. Let's break this down, assuming we want to interconnect N brokers. Each broker has (N - 1) peers, and all brokers are using exactly the same code and logic. There are two distinct flows of information between brokers:\n\n* Each broker needs to tell its peers how many workers it has available at any time. This can be fairly simple information--just a quantity that is updated regularly. The obvious (and correct) socket pattern for this is pub-sub. So every broker opens a PUB socket and publishes state information on that, and every broker also opens a SUB socket and connects that to the PUB socket of every other broker to get state information from its peers.\n\n* Each broker needs a way to delegate tasks to a peer and get replies back, asynchronously. We'll do this using ROUTER sockets; no other combination works. Each broker has two such sockets: one for tasks it receives and one for tasks it delegates. If we didn't use two sockets, it would be more work to know whether we were reading a request or a reply each time. That would mean adding more information to the message envelope.\n\nAnd there is also the flow of information between a broker and its local clients and workers.\n\n+++ The Naming Ceremony\n\nThree flows x two sockets for each flow = six sockets that we have to manage in the broker.  Choosing good names is vital to keeping a multisocket juggling act reasonably coherent in our minds. Sockets //do// something and what they do should form the basis for their names. It's about being able to read the code several weeks later on a cold Monday morning before coffee, and not feel any pain.\n\nLet's do a shamanistic naming ceremony for the sockets. The three flows are:\n\n* A //local// request-reply flow between the broker and its clients and workers.\n* A //cloud// request-reply flow between the broker and its peer brokers.\n* A //state// flow between the broker and its peer brokers.\n\nFinding meaningful names that are all the same length means our code will align nicely. It's not a big thing, but attention to details helps. For each flow the broker has two sockets that we can orthogonally call the //frontend// and //backend//. We've used these names quite often. A frontend receives information or tasks. A backend sends those out to other peers. The conceptual flow is from front to back (with replies going in the opposite direction from back to front).\n\nSo in all the code we write for this tutorial, we will use these socket names:\n\n* //localfe// and //localbe// for the local flow.\n* //cloudfe// and //cloudbe// for the cloud flow.\n* //statefe// and //statebe// for the state flow.\n\nFor our transport and because we're simulating the whole thing on one box, we'll use {{ipc}} for everything. This has the advantage of working like {{tcp}} in terms of connectivity (i.e., it's a disconnected transport, unlike {{inproc}}), yet we don't need IP addresses or DNS names, which would be a pain here. Instead, we will use {{ipc}} endpoints called //something//-{{local}}, //something//-{{cloud}}, and //something//-{{state}}, where //something// is the name of our simulated cluster.\n\nYou might be thinking that this is a lot of work for some names. Why not call them s1, s2, s3, s4, etc.? The answer is that if your brain is not a perfect machine, you need a lot of help when reading code, and we'll see that these names do help. It's easier to remember \"three flows, two directions\" than \"six different sockets\"[figure].\n\n[[code type=\"textdiagram\" title=\"Broker Socket Arrangement\"]]\n#---------#  #---------#  #---------#\n| Client  |  | Broker  |  | Broker  |\n|         |  | cloudbe |  | statebe |\n+---------+  +---------+  +---------+\n| connect |  | connect |  |  bind   |\n'---------'  '---------'  '---------'\n  request      request       state\n     \\            |            \n      \\           |           /\n       v          v          v\n   .---------+---------+---------.\n   |  bind   |  bind   | connect |\n   +---------+---------+---------+\n   | localfe | cloudfe | statefe |   Frontends\n   | ROUTER  | ROUTER  |   SUB   |   (incoming)\n   +---------+---------+---------+\n   |           Broker            |\n   +---------+---------+---------+\n   | ROUTER  | ROUTER  |   PUB   |   Backends\n   | localbe | cloudbe | statebe |   (outgoing)\n   +---------+---------+---------+\n   |  bind   | connect |  bind   |\n   '---------+---------+---------'\n     request    request   state\n                  |          \\\n      /           |           \\\n     v            v            v\n.---------.  .---------.  .---------.\n| connect |  |  bind   |  | connect |\n+---------+  +---------+  +---------+\n| Worker  |  | Broker  |  | Broker  |\n|         |  | cloudfe |  | statefe |\n#---------#  #---------#  #---------#\n[[/code]]\n\nNote that we connect the cloudbe in each broker to the cloudfe in every other broker, and likewise we connect the statebe in each broker to the statefe in every other broker.\n\n+++ Prototyping the State Flow\n\nBecause each socket flow has its own little traps for the unwary, we will test them in real code one-by-one, rather than try to throw the whole lot into code in one go. When we're happy with each flow, we can put them together into a full program. We'll start with the state flow[figure].\n\n[[code type=\"textdiagram\" title=\"The State Flow\"]]\n           #---------#\n           | Broker  |\n           | statebe |\n           +---------+\n           |  bind   |\n           '---------'\n              state\n                \n               /\n              v\n.--------+---------.\n|        | connect |\n|        +---------+\n|        | statefe |\n|        |   SUB   |\n+--------+---------+\n|     Broker       |\n+--------+---------+\n|        |   PUB   |\n|        | statebe |\n|        +---------+\n|        |  bind   |\n'--------+---------'\n            state\n              \\\n               \\\n                v\n           .---------.\n           | connect |\n           +---------+\n           | statefe |\n           | Broker  |\n           #---------#\n[[/code]]\n\nHere is how this works in code:\n\n[[code type=\"example\" title=\"Prototype state flow\" name=\"peering1\"]]\n[[/code]]\n\nNotes about this code:\n\n* Each broker has an identity that we use to construct {{ipc}} endpoint names. A real broker would need to work with TCP and a more sophisticated configuration scheme. We'll look at such schemes later in this book, but for now, using generated {{ipc}} names lets us ignore the problem of where to get TCP/IP addresses or names.\n\n* We use a {{zmq_poll[3]}} loop as the core of the program. This processes incoming messages and sends out state messages. We send a state message //only// if we did not get any incoming messages //and// we waited for a second. If we send out a state message each time we get one in, we'll get message storms.\n\n* We use a two-part pub-sub message consisting of sender address and data. Note that we will need to know the address of the publisher in order to send it tasks, and the only way is to send this explicitly as a part of the message.\n\n* We don't set identities on subscribers because if we did then we'd get outdated state information when connecting to running brokers.\n\n* We don't set a HWM on the publisher, but if we were using ZeroMQ v2.x that would be a wise idea.\n\nWe can build this little program and run it three times to simulate three clusters. Let's call them DC1, DC2, and DC3 (the names are arbitrary). We run these three commands, each in a separate window:\n\n[[code]]\npeering1 DC1 DC2 DC3  #  Start DC1 and connect to DC2 and DC3\npeering1 DC2 DC1 DC3  #  Start DC2 and connect to DC1 and DC3\npeering1 DC3 DC1 DC2  #  Start DC3 and connect to DC1 and DC2\n[[/code]]\n\nYou'll see each cluster report the state of its peers, and after a few seconds they will all happily be printing random numbers once per second. Try this and satisfy yourself that the three brokers all match up and synchronize to per-second state updates.\n\nIn real life, we'd not send out state messages at regular intervals, but rather whenever we had a state change, i.e., whenever a worker becomes available or unavailable. That may seem like a lot of traffic, but state messages are small and we've established that the inter-cluster connections are super fast.\n\nIf we wanted to send state messages at precise intervals, we'd create a child thread and open the {{statebe}} socket in that thread. We'd then send irregular state updates to that child thread from our main thread and allow the child thread to conflate them into regular outgoing messages. This is more work than we need here.\n\n+++ Prototyping the Local and Cloud Flows\n\nLet's now prototype the flow of tasks via the local and cloud sockets[figure]. This code pulls requests from clients and then distributes them to local workers and cloud peers on a random basis.\n\n[[code type=\"textdiagram\" title=\"The Flow of Tasks\"]]\n#---------#  #---------#\n| Client  |  | Broker  |\n|         |  | cloudbe |\n+---------+  +---------+\n| connect |  | connect |\n'---------'  '---------'\n  request      request\n     \\            |\n      \\           |\n       v          v\n   .---------+---------+---.\n   |  bind   |  bind   |   |\n   +---------+---------+   |\n   | localfe | cloudfe |   |\n   | ROUTER  | ROUTER  |   |\n   +---------+---------+---+\n   |         Broker        |\n   +---------+---------+---+\n   | ROUTER  | ROUTER  |   |\n   | localbe | cloudbe |   |\n   +---------+---------+   |\n   |  bind   | connect |   |\n   '---------+---------+---'\n     request    request\n                  |\n      /           |\n     v            v\n.---------.  .---------.\n| connect |  |  bind   |\n+---------+  +---------+\n|         |  | cloudfe |\n| Worker  |  | Broker  |\n#---------#  #---------#\n[[/code]]\n\nBefore we jump into the code, which is getting a little complex, let's sketch the core routing logic and break it down into a simple yet robust design.\n\nWe need two queues, one for requests from local clients and one for requests from cloud clients. One option would be to pull messages off the local and cloud frontends, and pump these onto their respective queues. But this is kind of pointless because ZeroMQ sockets //are// queues already. So let's use the ZeroMQ socket buffers as queues.\n\nThis was the technique we used in the load balancing broker, and it worked nicely. We only read from the two frontends when there is somewhere to send the requests. We can always read from the backends, as they give us replies to route back. As long as the backends aren't talking to us, there's no point in even looking at the frontends.\n\nSo our main loop becomes:\n\n* Poll the backends for activity. When we get a message, it may be \"ready\" from a worker or it may be a reply. If it's a reply, route back via the local or cloud frontend.\n\n* If a worker replied, it became available, so we queue it and count it.\n\n* While there are workers available, take a request, if any, from either frontend and route to a local worker, or randomly, to a cloud peer.\n\nRandomly sending tasks to a peer broker rather than a worker simulates work distribution across the cluster. It's dumb, but that is fine for this stage.\n\nWe use broker identities to route messages between brokers. Each broker has a name that we provide on the command line in this simple prototype. As long as these names don't overlap with the ZeroMQ-generated UUIDs used for client nodes, we can figure out whether to route a reply back to a client or to a broker.\n\nHere is how this works in code. The interesting part starts around the comment \"Interesting part\".\n\n[[code type=\"example\" title=\"Prototype local and cloud flow\" name=\"peering2\"]]\n[[/code]]\n\nRun this by, for instance, starting two instances of the broker in two windows:\n\n[[code]]\npeering2 me you\npeering2 you me\n[[/code]]\n\nSome comments on this code:\n\n* In the C code at least, using the zmsg class makes life much easier, and our code much shorter. It's obviously an abstraction that works. If you build ZeroMQ applications in C, you should use CZMQ.\n\n* Because we're not getting any state information from peers, we naively assume they are running. The code prompts you to confirm when you've started all the brokers. In the real case, we'd not send anything to brokers who had not told us they exist.\n\nYou can satisfy yourself that the code works by watching it run forever. If there were any misrouted messages, clients would end up blocking, and the brokers would stop printing trace information. You can prove that by killing either of the brokers. The other broker tries to send requests to the cloud, and one-by-one its clients block, waiting for an answer.\n\n+++ Putting it All Together\n\nLet's put this together into a single package. As before, we'll run an entire cluster as one process. We're going to take the two previous examples and merge them into one properly working design that lets you simulate any number of clusters.\n\nThis code is the size of both previous prototypes together, at 270 LoC. That's pretty good for a simulation of a cluster that includes clients and workers and cloud workload distribution. Here is the code:\n\n[[code type=\"example\" title=\"Full cluster simulation\" name=\"peering3\"]]\n[[/code]]\n\nIt's a nontrivial program and took about a day to get working. These are the highlights:\n\n* The client threads detect and report a failed request. They do this by polling for a response and if none arrives after a while (10 seconds), printing an error message.\n\n* Client threads don't print directly, but instead send a message to a monitor socket (PUSH) that the main loop collects (PULL) and prints off. This is the first case we've seen of using ZeroMQ sockets for monitoring and logging; this is a big use case that we'll come back to later.\n\n* Clients simulate varying loads to get the cluster 100% at random moments, so that tasks are shifted over to the cloud. The number of clients and workers, and delays in the client and worker threads control this. Feel free to play with them to see if you can make a more realistic simulation.\n\n* The main loop uses two pollsets. It could in fact use three: information, backends, and frontends. As in the earlier prototype, there is no point in taking a frontend message if there is no backend capacity.\n\nThese are some of the problems that arose during development of this program:\n\n* Clients would freeze, due to requests or replies getting lost somewhere. Recall that the ROUTER socket drops messages it can't route. The first tactic here was to modify the client thread to detect and report such problems. Secondly, I put {{zmsg_dump()}} calls after every receive and before every send in the main loop, until the origin of the problems was clear.\n\n* The main loop was mistakenly reading from more than one ready socket. This caused the first message to be lost. I fixed that by reading only from the first ready socket.\n\n* The {{zmsg}} class was not properly encoding UUIDs as C strings. This caused UUIDs that contain 0 bytes to be corrupted. I fixed that by modifying {{zmsg}} to encode UUIDs as printable hex strings.\n\nThis simulation does not detect disappearance of a cloud peer. If you start several peers and stop one, and it was broadcasting capacity to the others, they will continue to send it work even if it's gone. You can try this, and you will get clients that complain of lost requests. The solution is twofold: first, only keep the capacity information for a short time so that if a peer does disappear, its capacity is quickly set to zero. Second, add reliability to the request-reply chain. We'll look at reliability in the next chapter.\n"
        },
        {
          "name": "chapter4.txt",
          "type": "blob",
          "size": 86.2509765625,
          "content": ".output chapter4.wd\n.bookmark reliable-request-reply\n+ Reliable Request-Reply Patterns\n\n[#advanced-request-reply] covered advanced uses of ZeroMQ's request-reply pattern with working examples. This chapter looks at the general question of reliability and builds a set of reliable messaging patterns on top of ZeroMQ's core request-reply pattern.\n\nIn this chapter, we focus heavily on user-space request-reply //patterns//, reusable models that help you design your own ZeroMQ architectures:\n\n* The //Lazy Pirate// pattern: reliable request-reply from the client side\n* The //Simple Pirate// pattern: reliable request-reply using load balancing\n* The //Paranoid Pirate// pattern: reliable request-reply with heartbeating\n* The //Majordomo// pattern: service-oriented reliable queuing\n* The //Titanic// pattern: disk-based/disconnected reliable queuing\n* The //Binary Star// pattern: primary-backup server failover\n* The //Freelance// pattern: brokerless reliable request-reply\n\n++ What is \"Reliability\"?\n\nMost people who speak of \"reliability\" don't really know what they mean. We can only define reliability in terms of failure. That is, if we can handle a certain set of well-defined and understood failures, then we are reliable with respect to those failures. No more, no less. So let's look at the possible causes of failure in a distributed ZeroMQ application, in roughly descending order of probability:\n\n* Application code is the worst offender. It can crash and exit, freeze and stop responding to input, run too slowly for its input, exhaust all memory, and so on.\n\n* System code--such as brokers we write using ZeroMQ--can die for the same reasons as application code. System code //should// be more reliable than application code, but it can still crash and burn, and especially run out of memory if it tries to queue messages for slow clients.\n\n* Message queues can overflow, typically in system code that has learned to deal brutally with slow clients. When a queue overflows, it starts to discard messages. So we get \"lost\" messages.\n\n* Networks can fail (e.g., WiFi gets switched off or goes out of range). ZeroMQ will automatically reconnect in such cases, but in the meantime, messages may get lost.\n\n* Hardware can fail and take with it all the processes running on that box.\n\n* Networks can fail in exotic ways, e.g., some ports on a switch may die and those parts of the network become inaccessible.\n\n* Entire data centers can be struck by lightning, earthquakes, fire, or more mundane power or cooling failures.\n\nTo make a software system fully reliable against //all// of these possible failures is an enormously difficult and expensive job and goes beyond the scope of this book.\n\nBecause the first five cases in the above list cover 99.9% of real world requirements outside large companies (according to a highly scientific study I just ran, which also told me that 78% of statistics are made up on the spot, and moreover never to trust a statistic that we didn't falsify ourselves), that's what we'll examine. If you're a large company with money to spend on the last two cases, contact my company immediately! There's a large hole behind my beach house waiting to be converted into an executive swimming pool.\n\n++ Designing Reliability\n\nSo to make things brutally simple, reliability is \"keeping things working properly when code freezes or crashes\", a situation we'll shorten to \"dies\". However, the things we want to keep working properly are more complex than just messages. We need to take each core ZeroMQ messaging pattern and see how to make it work (if we can) even when code dies.\n\nLet's take them one-by-one:\n\n* Request-reply: if the server dies (while processing a request), the client can figure that out because it won't get an answer back. Then it can give up in a huff, wait and try again later, find another server, and so on. As for the client dying, we can brush that off as \"someone else's problem\" for now.\n\n* Pub-sub: if the client dies (having gotten some data), the server doesn't know about it. Pub-sub doesn't send any information back from client to server. But the client can contact the server out-of-band, e.g., via request-reply, and ask, \"please resend everything I missed\". As for the server dying, that's out of scope for here. Subscribers can also self-verify that they're not running too slowly, and take action (e.g., warn the operator and die) if they are.\n\n* Pipeline: if a worker dies (while working), the ventilator doesn't know about it. Pipelines, like the grinding gears of time, only work in one direction. But the downstream collector can detect that one task didn't get done, and send a message back to the ventilator saying, \"hey, resend task 324!\" If the ventilator or collector dies, whatever upstream client originally sent the work batch can get tired of waiting and resend the whole lot. It's not elegant, but system code should really not die often enough to matter.\n\nIn this chapter we'll focus just on request-reply, which is the low-hanging fruit of reliable messaging.\n\nThe basic request-reply pattern (a REQ client socket doing a blocking send/receive to a REP server socket) scores low on handling the most common types of failure. If the server crashes while processing the request, the client just hangs forever. If the network loses the request or the reply, the client hangs forever.\n\nRequest-reply is still much better than TCP, thanks to ZeroMQ's ability to reconnect peers silently, to load balance messages, and so on. But it's still not good enough for real work. The only case where you can really trust the basic request-reply pattern is between two threads in the same process where there's no network or separate server process to die.\n\nHowever, with a little extra work, this humble pattern becomes a good basis for real work across a distributed network, and we get a set of reliable request-reply (RRR) patterns that I like to call the //Pirate// patterns (you'll eventually get the joke, I hope).\n\nThere are, in my experience, roughly three ways to connect clients to servers. Each needs a specific approach to reliability:\n\n* Multiple clients talking directly to a single server. Use case: a single well-known server to which clients need to talk. Types of failure we aim to handle: server crashes and restarts, and network disconnects.\n\n* Multiple clients talking to a broker proxy that distributes work to multiple workers. Use case: service-oriented transaction processing. Types of failure we aim to handle: worker crashes and restarts, worker busy looping, worker overload, queue crashes and restarts, and network disconnects.\n\n* Multiple clients talking to multiple servers with no intermediary proxies. Use case: distributed services such as name resolution. Types of failure we aim to handle: service crashes and restarts, service busy looping, service overload, and network disconnects.\n\nEach of these approaches has its trade-offs and often you'll mix them. We'll look at all three in detail.\n\n++ Client-Side Reliability (Lazy Pirate Pattern)\n\nWe can get very simple reliable request-reply with some changes to the client. We call this the Lazy Pirate pattern[figure]. Rather than doing a blocking receive, we:\n\n* Poll the REQ socket and receive from it only when it's sure a reply has arrived.\n* Resend a request, if no reply has arrived within a timeout period.\n* Abandon the transaction if there is still no reply after several requests.\n\nIf you try to use a REQ socket in anything other than a strict send/receive fashion, you'll get an error (technically, the REQ socket implements a small finite-state machine to enforce the send/receive ping-pong, and so the error code is called \"EFSM\"). This is slightly annoying when we want to use REQ in a pirate pattern, because we may send several requests before getting a reply.\n\nThe pretty good brute force solution is to close and reopen the REQ socket after an error:\n\n[[code type=\"example\" title=\"Lazy Pirate client\" name=\"lpclient\"]]\n[[/code]]\n\nRun this together with the matching server:\n\n[[code type=\"example\" title=\"Lazy Pirate server\" name=\"lpserver\"]]\n[[/code]]\n\n[[code type=\"textdiagram\" title=\"The Lazy Pirate Pattern\"]]\n#-----------#   #-----------#   #-----------#\n|  Client   |   |  Client   |   |  Client   |\n+-----------+   +-----------+   +-----------+\n|   Retry   |   |   Retry   |   |   Retry   |\n+-----------+   +-----------+   +-----------+\n|    REQ    |   |    REQ    |   |    REQ    |\n'-----------'   '-----------'   '-----------'\n      ^               ^               ^\n      |               |               |\n      '---------------+---------------'\n                      |\n                      v\n               .-------------.\n               |     REP     |\n               +-------------+\n               |             |\n               |    Server   |\n               |             |\n               #-------------#\n[[/code]]\n\nTo run this test case, start the client and the server in two console windows. The server will randomly misbehave after a few messages. You can check the client's response. Here is typical output from the server:\n\n[[code]]\nI: normal request (1)\nI: normal request (2)\nI: normal request (3)\nI: simulating CPU overload\nI: normal request (4)\nI: simulating a crash\n[[/code]]\n\nAnd here is the client's response:\n\n[[code]]\nI: connecting to server...\nI: server replied OK (1)\nI: server replied OK (2)\nI: server replied OK (3)\nW: no response from server, retrying...\nI: connecting to server...\nW: no response from server, retrying...\nI: connecting to server...\nE: server seems to be offline, abandoning\n[[/code]]\n\nThe client sequences each message and checks that replies come back exactly in order: that no requests or replies are lost, and no replies come back more than once, or out of order. Run the test a few times until you're convinced that this mechanism actually works. You don't need sequence numbers in a production application; they just help us trust our design.\n\nThe client uses a REQ socket, and does the brute force close/reopen because REQ sockets impose that strict send/receive cycle. You might be tempted to use a DEALER instead, but it would not be a good decision. First, it would mean emulating the secret sauce that REQ does with envelopes (if you've forgotten what that is, it's a good sign you don't want to have to do it). Second, it would mean potentially getting back replies that you didn't expect.\n\nHandling failures only at the client works when we have a set of clients talking to a single server. It can handle a server crash, but only if recovery means restarting that same server. If there's a permanent error, such as a dead power supply on the server hardware, this approach won't work. Because the application code in servers is usually the biggest source of failures in any architecture, depending on a single server is not a great idea.\n\nSo, pros and cons:\n\n* Pro: simple to understand and implement.\n* Pro: works easily with existing client and server application code.\n* Pro: ZeroMQ automatically retries the actual reconnection until it works.\n* Con: doesn't failover to backup or alternate servers.\n\n++ Basic Reliable Queuing (Simple Pirate Pattern)\n\nOur second approach extends the Lazy Pirate pattern with a queue proxy that lets us talk, transparently, to multiple servers, which we can more accurately call \"workers\". We'll develop this in stages, starting with a minimal working model, the Simple Pirate pattern.\n\nIn all these Pirate patterns, workers are stateless. If the application requires some shared state, such as a shared database, we don't know about it as we design our messaging framework. Having a queue proxy means workers can come and go without clients knowing anything about it. If one worker dies, another takes over. This is a nice, simple topology with only one real weakness, namely the central queue itself, which can become a problem to manage, and a single point of failure.\n\n[[code type=\"textdiagram\" title=\"The Simple Pirate Pattern\"]]\n#-----------#   #-----------#   #-----------#\n|  Client   |   |  Client   |   |  Client   |\n+-----------+   +-----------+   +-----------+\n|   Retry   |   |   Retry   |   |   Retry   |\n+-----------+   +-----------+   +-----------+\n|    REQ    |   |    REQ    |   |    REQ    |\n'-----+-----'   '-----+-----'   '-----+-----'\n      |               |               |\n      '---------------+---------------'\n                      |\n                      v\n                .-----------.\n                |  ROUTER   |\n                +-----------+\n                |   Load    |\n                |  balancer |\n                +-----------+\n                |  ROUTER   |\n                '-----------'\n                      ^\n                      |\n      .---------------+---------------.\n      |               |               |\n.-----+-----.   .-----+-----.   .-----+-----.\n|    REQ    |   |    REQ    |   |    REQ    |\n+-----------+   +-----------+   +-----------+\n|   Worker  |   |   Worker  |   |   Worker  |\n#-----------#   #-----------#   #-----------#\n[[/code]]\n\nThe basis for the queue proxy is the load balancing broker from [#advanced-request-reply]. What is the very //minimum// we need to do to handle dead or blocked workers? Turns out, it's surprisingly little. We already have a retry mechanism in the client. So using the load balancing pattern will work pretty well. This fits with ZeroMQ's philosophy that we can extend a peer-to-peer pattern like request-reply by plugging naive proxies in the middle[figure].\n\nWe don't need a special client; we're still using the Lazy Pirate client. Here is the queue, which is identical to the main task of the load balancing broker:\n\n[[code type=\"example\" title=\"Simple Pirate queue\" name=\"spqueue\"]]\n[[/code]]\n\nHere is the worker, which takes the Lazy Pirate server and adapts it for the load balancing pattern (using the REQ \"ready\" signaling):\n\n[[code type=\"example\" title=\"Simple Pirate worker\" name=\"spworker\"]]\n[[/code]]\n\nTo test this, start a handful of workers, a Lazy Pirate client, and the queue, in any order. You'll see that the workers eventually all crash and burn, and the client retries and then gives up. The queue never stops, and you can restart workers and clients ad nauseam. This model works with any number of clients and workers.\n\n++ Robust Reliable Queuing (Paranoid Pirate Pattern)\n\n[[code type=\"textdiagram\" title=\"The Paranoid Pirate Pattern\"]]\n#-----------#   #-----------#   #-----------#\n|  Client   |   |  Client   |   |  Client   |\n+-----------+   +-----------+   +-----------+\n|   Retry   |   |   Retry   |   |   Retry   |\n+-----------+   +-----------+   +-----------+\n|    REQ    |   |    REQ    |   |    REQ    |\n'-----+-----'   '-----+-----'   '-----+-----'\n      |               |               |\n      '---------------+---------------'\n                      |\n                      v\n                .-----------.\n                |  ROUTER   |\n                +-----------+\n                |   Queue   |\n                +-----------+\n                | Heartbeat |\n                +-----------+\n                |  ROUTER   |\n                '-----------'\n                      ^\n                      |\n      .---------------+---------------.\n      |               |               |\n.-----+-----.   .-----+-----.   .-----+-----.\n|  DEALER   |   |  DEALER   |   |  DEALER   |\n+-----------+   +-----------+   +-----------+\n| Heartbeat |   | Heartbeat |   | Heartbeat |\n+-----------+   +-----------+   +-----------+\n|   Worker  |   |   Worker  |   |   Worker  |\n#-----------#   #-----------#   #-----------#\n[[/code]]\n\nThe Simple Pirate Queue pattern works pretty well, especially because it's just a combination of two existing patterns. Still, it does have some weaknesses:\n\n* It's not robust in the face of a queue crash and restart. The client will recover, but the workers won't. While ZeroMQ will reconnect workers' sockets automatically, as far as the newly started queue is concerned, the workers haven't signaled ready, so don't exist. To fix this, we have to do heartbeating from queue to worker so that the worker can detect when the queue has gone away.\n\n* The queue does not detect worker failure, so if a worker dies while idle, the queue can't remove it from its worker queue until the queue sends it a request. The client waits and retries for nothing. It's not a critical problem, but it's not nice. To make this work properly, we do heartbeating from worker to queue, so that the queue can detect a lost worker at any stage.\n\nWe'll fix these in a properly pedantic Paranoid Pirate Pattern.\n\nWe previously used a REQ socket for the worker. For the Paranoid Pirate worker, we'll switch to a DEALER socket[figure]. This has the advantage of letting us send and receive messages at any time, rather than the lock-step send/receive that REQ imposes. The downside of DEALER is that we have to do our own envelope management (re-read [#advanced-request-reply] for background on this concept).\n\nWe're still using the Lazy Pirate client. Here is the Paranoid Pirate queue proxy:\n\n[[code type=\"example\" title=\"Paranoid Pirate queue\" name=\"ppqueue\"]]\n[[/code]]\n\nThe queue extends the load balancing pattern with heartbeating of workers. Heartbeating is one of those \"simple\" things that can be difficult to get right. I'll explain more about that in a second.\n\nHere is the Paranoid Pirate worker:\n\n[[code type=\"example\" title=\"Paranoid Pirate worker\" name=\"ppworker\"]]\n[[/code]]\n\nSome comments about this example:\n\n* The code includes simulation of failures, as before. This makes it (a) very hard to debug, and (b) dangerous to reuse. When you want to debug this, disable the failure simulation.\n\n* The worker uses a reconnect strategy similar to the one we designed for the Lazy Pirate client, with two major differences: (a) it does an exponential back-off, and (b) it retries indefinitely (whereas the client retries a few times before reporting a failure).\n\nTry the client, queue, and workers, such as by using a script like this:\n\n[[code]]\nppqueue &\nfor i in 1 2 3 4; do\n    ppworker &\n    sleep 1\ndone\nlpclient &\n[[/code]]\n\nYou should see the workers die one-by-one as they simulate a crash, and the client eventually give up. You can stop and restart the queue and both client and workers will reconnect and carry on. And no matter what you do to queues and workers, the client will never get an out-of-order reply: the whole chain either works, or the client abandons.\n\n++ Heartbeating\n\nHeartbeating solves the problem of knowing whether a peer is alive or dead. This is not an issue specific to ZeroMQ. TCP has a long timeout (30 minutes or so), that means that it can be impossible to know whether a peer has died, been disconnected, or gone on a weekend to Prague with a case of vodka, a redhead, and a large expense account.\n\nIt's not easy to get heartbeating right. When writing the Paranoid Pirate examples, it took about five hours to get the heartbeating working properly. The rest of the request-reply chain took perhaps ten minutes. It is especially easy to create \"false failures\", i.e., when peers decide that they are disconnected because the heartbeats aren't sent properly.\n\nWe'll look at the three main answers people use for heartbeating with ZeroMQ.\n\n+++ Shrugging It Off\n\nThe most common approach is to do no heartbeating at all and hope for the best. Many if not most ZeroMQ applications do this. ZeroMQ encourages this by hiding peers in many cases. What problems does this approach cause?\n\n* When we use a ROUTER socket in an application that tracks peers, as peers disconnect and reconnect, the application will leak memory (resources that the application holds for each peer) and get slower and slower.\n\n* When we use SUB- or DEALER-based data recipients, we can't tell the difference between good silence (there's no data) and bad silence (the other end died). When a recipient knows the other side died, it can for example switch over to a backup route.\n\n* If we use a TCP connection that stays silent for a long while, it will, in some networks, just die. Sending something (technically, a \"keep-alive\" more than a heartbeat), will keep the network alive.\n\n+++ One-Way Heartbeats\n\nA second option is to send a heartbeat message from each node to its peers every second or so. When one node hears nothing from another within some timeout (several seconds, typically), it will treat that peer as dead. Sounds good, right? Sadly, no. This works in some cases but has nasty edge cases in others.\n\nFor pub-sub, this does work, and it's the only model you can use. SUB sockets cannot talk back to PUB sockets, but PUB sockets can happily send \"I'm alive\" messages to their subscribers.\n\nAs an optimization, you can send heartbeats only when there is no real data to send. Furthermore, you can send heartbeats progressively slower and slower, if network activity is an issue (e.g., on mobile networks where activity drains the battery). As long as the recipient can detect a failure (sharp stop in activity), that's fine.\n\nHere are the typical problems with this design:\n\n* It can be inaccurate when we send large amounts of data, as heartbeats will be delayed behind that data. If heartbeats are delayed, you can get false timeouts and disconnections due to network congestion. Thus, always treat //any// incoming data as a heartbeat, whether or not the sender optimizes out heartbeats.\n\n* While the pub-sub pattern will drop messages for disappeared recipients, PUSH and DEALER sockets will queue them. So if you send heartbeats to a dead peer and it comes back, it will get all the heartbeats you sent, which can be thousands. Whoa, whoa!\n\n* This design assumes that heartbeat timeouts are the same across the whole network. But that won't be accurate. Some peers will want very aggressive heartbeating in order to detect faults rapidly. And some will want very relaxed heartbeating, in order to let sleeping networks lie and save power.\n\n+++ Ping-Pong Heartbeats\n\nThe third option is to use a ping-pong dialog. One peer sends a ping command to the other, which replies with a pong command. Neither command has any payload. Pings and pongs are not correlated. Because the roles of \"client\" and \"server\" are arbitrary in some networks, we usually specify that either peer can in fact send a ping and expect a pong in response. However, because the timeouts depend on network topologies known best to dynamic clients, it is usually the client that pings the server.\n\nThis works for all ROUTER-based brokers. The same optimizations we used in the second model make this work even better: treat any incoming data as a pong, and only send a ping when not otherwise sending data.\n\n+++ Heartbeating for Paranoid Pirate\n\nFor Paranoid Pirate, we chose the second approach. It might not have been the simplest option: if designing this today, I'd probably try a ping-pong approach instead. However the principles are similar. The heartbeat messages flow asynchronously in both directions, and either peer can decide the other is \"dead\" and stop talking to it.\n\nIn the worker, this is how we handle heartbeats from the queue:\n\n* We calculate a //liveness//, which is how many heartbeats we can still miss before deciding the queue is dead. It starts at three and we decrement it each time we miss a heartbeat.\n* We wait, in the {{zmq_poll}} loop, for one second each time, which is our heartbeat interval.\n* If there's any message from the queue during that time, we reset our liveness to three.\n* If there's no message during that time, we count down our liveness.\n* If the liveness reaches zero, we consider the queue dead.\n* If the queue is dead, we destroy our socket, create a new one, and reconnect.\n* To avoid opening and closing too many sockets, we wait for a certain interval before reconnecting, and we double the interval each time until it reaches 32 seconds.\n\nAnd this is how we handle heartbeats //to// the queue:\n\n* We calculate when to send the next heartbeat; this is a single variable because we're talking to one peer, the queue.\n* In the {{zmq_poll}} loop, whenever we pass this time, we send a heartbeat to the queue.\n\nHere's the essential heartbeating code for the worker:\n\n[[code type=\"fragment\" name=\"heartbeats\"]]\n#define HEARTBEAT_LIVENESS  3       //  3-5 is reasonable\n#define HEARTBEAT_INTERVAL  1000    //  msecs\n#define INTERVAL_INIT       1000    //  Initial reconnect\n#define INTERVAL_MAX       32000    //  After exponential backoff\n\n...\n//  If liveness hits zero, queue is considered disconnected\nsize_t liveness = HEARTBEAT_LIVENESS;\nsize_t interval = INTERVAL_INIT;\n\n//  Send out heartbeats at regular intervals\nuint64_t heartbeat_at = zclock_time () + HEARTBEAT_INTERVAL;\n\nwhile (true) {\n    zmq_pollitem_t items [] = { { worker,  0, ZMQ_POLLIN, 0 } };\n    int rc = zmq_poll (items, 1, HEARTBEAT_INTERVAL * ZMQ_POLL_MSEC);\n\n    if (items [0].revents & ZMQ_POLLIN) {\n        //  Receive any message from queue\n        liveness = HEARTBEAT_LIVENESS;\n        interval = INTERVAL_INIT;\n    }\n    else\n    if (--liveness == 0) {\n        zclock_sleep (interval);\n        if (interval < INTERVAL_MAX)\n            interval *= 2;\n        zsocket_destroy (ctx, worker);\n        ...\n        liveness = HEARTBEAT_LIVENESS;\n    }\n    //  Send heartbeat to queue if it's time\n    if (zclock_time () > heartbeat_at) {\n        heartbeat_at = zclock_time () + HEARTBEAT_INTERVAL;\n        //  Send heartbeat message to queue\n    }\n}\n[[/code]]\n\nThe queue does the same, but manages an expiration time for each worker.\n\nHere are some tips for your own heartbeating implementation:\n\n* Use {{zmq_poll}} or a reactor as the core of your application's main task.\n\n* Start by building the heartbeating between peers, test it by simulating failures, and //then// build the rest of the message flow. Adding heartbeating afterwards is much trickier.\n\n* Use simple tracing, i.e., print to console, to get this working. To help you trace the flow of messages between peers, use a dump method such as zmsg offers, and number your messages incrementally so you can see if there are gaps.\n\n* In a real application, heartbeating must be configurable and usually negotiated with the peer. Some peers will want aggressive heartbeating, as low as 10 msecs. Other peers will be far away and want heartbeating as high as 30 seconds.\n\n* If you have different heartbeat intervals for different peers, your poll timeout should be the lowest (shortest time) of these. Do not use an infinite timeout.\n\n* Do heartbeating on the same socket you use for messages, so your heartbeats also act as a //keep-alive// to stop the network connection from going stale (some firewalls can be unkind to silent connections).\n\n++ Contracts and Protocols\n\nIf you're paying attention, you'll realize that Paranoid Pirate is not interoperable with Simple Pirate, because of the heartbeats. But how do we define \"interoperable\"? To guarantee interoperability, we need a kind of contract, an agreement that lets different teams in different times and places write code that is guaranteed to work together. We call this a \"protocol\".\n\nIt's fun to experiment without specifications, but that's not a sensible basis for real applications. What happens if we want to write a worker in another language? Do we have to read code to see how things work? What if we want to change the protocol for some reason? Even a simple protocol will, if it's successful, evolve and become more complex.\n\nLack of contracts is a sure sign of a disposable application. So let's write a contract for this protocol. How do we do that?\n\nThere's a wiki at [http://rfc.zeromq.org rfc.zeromq.org] that we made especially as a home for public ZeroMQ contracts.\nTo create a new specification, register on the wiki if needed, and follow the instructions. It's fairly straightforward, though writing technical texts is not everyone's cup of tea.\n\nIt took me about fifteen minutes to draft the new [http://rfc.zeromq.org/spec:6 Pirate Pattern Protocol]. It's not a big specification, but it does capture enough to act as the basis for arguments (\"your queue isn't PPP compatible; please fix it!\").\n\nTurning PPP into a real protocol would take more work:\n\n* There should be a protocol version number in the READY command so that it's possible to distinguish between different versions of PPP.\n\n* Right now, READY and HEARTBEAT are not entirely distinct from requests and replies. To make them distinct, we would need a message structure that includes a \"message type\" part.\n\n++ Service-Oriented Reliable Queuing (Majordomo Pattern)\n\n[[code type=\"textdiagram\" title=\"The Majordomo Pattern\"]]\n#-----------#   #-----------#   #-----------#\n|  Client   |   |  Client   |   |  Client   |\n'-----+-----'   '-----+-----'   '-----+-----'\n      |               |               |\n      '---------------+---------------'\n\"Give me coffee\"      |         \"Give me tea\"\n                      v\n                .-----------.\n                |  Broker   |\n                '-----------'\n                      ^\n                      |\n      .---------------+---------------.\n      |               |               |\n.-----+-----.   .-----+-----.   .-----+-----.\n|  \"Water\"  |   |   \"Tea\"   |   | \"Coffee\"  |\n+-----------+   +-----------+   +-----------+\n|  Worker   |   |  Worker   |   |  Worker   |\n#-----------#   #-----------#   #-----------#\n[[/code]]\n\nThe nice thing about progress is how fast it happens when lawyers and committees aren't involved. The [http://rfc.zeromq.org/spec:7 one-page MDP specification] turns PPP into something more solid[figure]. This is how we should design complex architectures: start by writing down the contracts, and only //then// write software to implement them.\n\nThe Majordomo Protocol (MDP) extends and improves on PPP in one interesting way: it adds a \"service name\" to requests that the client sends, and asks workers to register for specific services. Adding service names turns our Paranoid Pirate queue into a service-oriented broker. The nice thing about MDP is that it came out of working code, a simpler ancestor protocol (PPP), and a precise set of improvements that each solved a clear problem. This made it easy to draft.\n\nTo implement Majordomo, we need to write a framework for clients and workers. It's really not sane to ask every application developer to read the spec and make it work, when they could be using a simpler API that does the work for them.\n\nSo while our first contract (MDP itself) defines how the pieces of our distributed architecture talk to each other, our second contract defines how user applications talk to the technical framework we're going to design.\n\nMajordomo has two halves, a client side and a worker side. Because we'll write both client and worker applications, we will need two APIs. Here is a sketch for the client API, using a simple object-oriented approach:\n\n[[code type=\"fragment\" name=\"mdclient\"]]\nmdcli_t *mdcli_new     (char *broker);\nvoid     mdcli_destroy (mdcli_t **self_p);\nzmsg_t  *mdcli_send    (mdcli_t *self, char *service, zmsg_t **request_p);\n[[/code]]\n\nThat's it. We open a session to the broker, send a request message, get a reply message back, and eventually close the connection. Here's a sketch for the worker API:\n\n[[code type=\"fragment\" name=\"mdworker\"]]\nmdwrk_t *mdwrk_new     (char *broker,char *service);\nvoid     mdwrk_destroy (mdwrk_t **self_p);\nzmsg_t  *mdwrk_recv    (mdwrk_t *self, zmsg_t *reply);\n[[/code]]\n\nIt's more or less symmetrical, but the worker dialog is a little different. The first time a worker does a recv(), it passes a null reply. Thereafter, it passes the current reply, and gets a new request.\n\nThe client and worker APIs were fairly simple to construct because they're heavily based on the Paranoid Pirate code we already developed. Here is the client API:\n\n[[code type=\"example\" title=\"Majordomo client API\" name=\"mdcliapi\"]]\n[[/code]]\n\nLet's see how the client API looks in action, with an example test program that does 100K request-reply cycles:\n\n[[code type=\"example\" title=\"Majordomo client application\" name=\"mdclient\"]]\n[[/code]]\n\nAnd here is the worker API:\n\n[[code type=\"example\" title=\"Majordomo worker API\" name=\"mdwrkapi\"]]\n[[/code]]\n\nLet's see how the worker API looks in action, with an example test program that implements an echo service:\n\n[[code type=\"example\" title=\"Majordomo worker application\" name=\"mdworker\"]]\n[[/code]]\n\nHere are some things to note about the worker API code:\n\n* The APIs are single-threaded. This means, for example, that the worker won't send heartbeats in the background. Happily, this is exactly what we want: if the worker application gets stuck, heartbeats will stop and the broker will stop sending requests to the worker.\n\n* The worker API doesn't do an exponential back-off; it's not worth the extra complexity.\n\n* The APIs don't do any error reporting. If something isn't as expected, they raise an assertion (or exception depending on the language). This is ideal for a reference implementation, so any protocol errors show immediately. For real applications, the API should be robust against invalid messages.\n\nYou might wonder why the worker API is manually closing its socket and opening a new one, when ZeroMQ will automatically reconnect a socket if the peer disappears and comes back. Look back at the Simple Pirate and Paranoid Pirate workers to understand. Although ZeroMQ will automatically reconnect workers if the broker dies and comes back up, this isn't sufficient to re-register the workers with the broker. I know of at least two solutions. The simplest, which we use here, is for the worker to monitor the connection using heartbeats, and if it decides the broker is dead, to close its socket and start afresh with a new socket. The alternative is for the broker to challenge unknown workers when it gets a heartbeat from the worker and ask them to re-register. That would require protocol support.\n\nNow let's design the Majordomo broker. Its core structure is a set of queues, one per service. We will create these queues as workers appear (we could delete them as workers disappear, but forget that for now because it gets complex). Additionally, we keep a queue of workers per service.\n\nAnd here is the broker:\n\n[[code type=\"example\" title=\"Majordomo broker\" name=\"mdbroker\"]]\n[[/code]]\n\nThis is by far the most complex example we've seen. It's almost 500 lines of code. To write this and make it somewhat robust took two days. However, this is still a short piece of code for a full service-oriented broker.\n\nHere are some things to note about the broker code:\n\n* The Majordomo Protocol lets us handle both clients and workers on a single socket. This is nicer for those deploying and managing the broker: it just sits on one ZeroMQ endpoint rather than the two that most proxies need.\n\n* The broker implements all of MDP/0.1 properly (as far as I know), including disconnection if the broker sends invalid commands, heartbeating, and the rest.\n\n* It can be extended to run multiple threads, each managing one socket and one set of clients and workers. This could be interesting for segmenting large architectures. The C code is already organized around a broker class to make this trivial.\n\n* A primary/failover or live/live broker reliability model is easy, as the broker essentially has no state except service presence. It's up to clients and workers to choose another broker if their first choice isn't up and running.\n\n* The examples use five-second heartbeats, mainly to reduce the amount of output when you enable tracing. Realistic values would be lower for most LAN applications. However, any retry has to be slow enough to allow for a service to restart, say 10 seconds at least.\n\nWe later improved and extended the protocol and the Majordomo implementation, which now sits in its own Github project. If you want a properly usable Majordomo stack, use the GitHub project.\n\n++ Asynchronous Majordomo Pattern\n\nThe Majordomo implementation in the previous section is simple and stupid. The client is just the original Simple Pirate, wrapped up in a sexy API. When I fire up a client, broker, and worker on a test box, it can process 100,000 requests in about 14 seconds. That is partially due to the code, which cheerfully copies message frames around as if CPU cycles were free. But the real problem is that we're doing network round-trips. ZeroMQ disables [http://en.wikipedia.org/wiki/Nagles_algorithm Nagle's algorithm], but round-tripping is still slow.\n\nTheory is great in theory, but in practice, practice is better. Let's measure the actual cost of round-tripping with a simple test program. This sends a bunch of messages, first waiting for a reply to each message, and second as a batch, reading all the replies back as a batch. Both approaches do the same work, but they give very different results. We mock up a client, broker, and worker:\n\n[[code type=\"example\" title=\"Round-trip demonstrator\" name=\"tripping\"]]\n[[/code]]\n\nOn my development box, this program says:\n\n[[code]]\nSetting up test...\nSynchronous round-trip test...\n 9057 calls/second\nAsynchronous round-trip test...\n 173010 calls/second\n[[/code]]\n\nNote that the client thread does a small pause before starting. This is to get around one of the \"features\" of the router socket: if you send a message with the address of a peer that's not yet connected, the message gets discarded. In this example we don't use the load balancing mechanism, so without the sleep, if the worker thread is too slow to connect, it will lose messages, making a mess of our test.\n\nAs we see, round-tripping in the simplest case is 20 times slower than the  asynchronous, \"shove it down the pipe as fast as it'll go\" approach. Let's see if we can apply this to Majordomo to make it faster.\n\nFirst, we modify the client API to send and receive in two separate methods:\n\n[[code type=\"fragment\" name=\"mdclient-async\"]]\nmdcli_t *mdcli_new     (char *broker);\nvoid     mdcli_destroy (mdcli_t **self_p);\nint      mdcli_send    (mdcli_t *self, char *service, zmsg_t **request_p);\nzmsg_t  *mdcli_recv    (mdcli_t *self);\n[[/code]]\n\nIt's literally a few minutes' work to refactor the synchronous client API to become asynchronous:\n\n[[code type=\"example\" title=\"Majordomo asynchronous client API\" name=\"mdcliapi2\"]]\n[[/code]]\n\nThe differences are:\n\n* We use a DEALER socket instead of REQ, so we emulate REQ with an empty delimiter frame before each request and each response.\n* We don't retry requests; if the application needs to retry, it can do this itself.\n* We break the synchronous {{send}} method into separate {{send}} and {{recv}} methods.\n* The {{send}} method is asynchronous and returns immediately after sending. The caller can thus send a number of messages before getting a response.\n* The {{recv}} method waits for (with a timeout) one response and returns that to the caller.\n\nAnd here's the corresponding client test program, which sends 100,000 messages and then receives 100,000 back:\n\n[[code type=\"example\" title=\"Majordomo client application\" name=\"mdclient2\"]]\n[[/code]]\n\nThe broker and worker are unchanged because we've not modified the protocol at all. We see an immediate improvement in performance. Here's the synchronous client chugging through 100K request-reply cycles:\n\n[[code]]\n$ time mdclient\n100000 requests/replies processed\n\nreal    0m14.088s\nuser    0m1.310s\nsys     0m2.670s\n[[/code]]\n\nAnd here's the asynchronous client, with a single worker:\n\n[[code]]\n$ time mdclient2\n100000 replies received\n\nreal    0m8.730s\nuser    0m0.920s\nsys     0m1.550s\n[[/code]]\n\nTwice as fast. Not bad, but let's fire up 10 workers and see how it handles the traffic\n\n[[code]]\n$ time mdclient2\n100000 replies received\n\nreal    0m3.863s\nuser    0m0.730s\nsys     0m0.470s\n[[/code]]\n\nIt isn't fully asynchronous because workers get their messages on a strict last-used basis. But it will scale better with more workers. On my PC, after eight or so workers, it doesn't get any faster. Four cores only stretches so far. But we got a 4x improvement in throughput with just a few minutes' work. The broker is still unoptimized. It spends most of its time copying message frames around, instead of doing zero-copy, which it could. But we're getting 25K reliable request/reply calls a second, with pretty low effort.\n\nHowever, the asynchronous Majordomo pattern isn't all roses. It has a fundamental weakness, namely that it cannot survive a broker crash without more work. If you look at the {{mdcliapi2}} code you'll see it does not attempt to reconnect after a failure. A proper reconnect would require the following:\n\n* A number on every request and a matching number on every reply, which would ideally require a change to the protocol to enforce.\n* Tracking and holding onto all outstanding requests in the client API, i.e., those for which no reply has yet been received.\n* In case of failover, for the client API to //resend// all outstanding requests to the broker.\n\nIt's not a deal breaker, but it does show that performance often means complexity. Is this worth doing for Majordomo? It depends on your use case. For a name lookup service you call once per session, no. For a web frontend serving thousands of clients, probably yes.\n\n++ Service Discovery\n\nSo, we have a nice service-oriented broker, but we have no way of knowing whether a particular service is available or not. We know whether a request failed, but we don't know why. It is useful to be able to ask the broker, \"is the echo service running?\" The most obvious way would be to modify our MDP/Client protocol to add commands to ask this. But MDP/Client has the great charm of being simple. Adding service discovery to it would make it as complex as the MDP/Worker protocol.\n\nAnother option is to do what email does, and ask that undeliverable requests be returned. This can work well in an asynchronous world, but it also adds complexity. We need ways to distinguish returned requests from replies and to handle these properly.\n\nLet's try to use what we've already built, building on top of MDP instead of modifying it. Service discovery is, itself, a service. It might indeed be one of several management services, such as \"disable service X\", \"provide statistics\", and so on. What we want is a general, extensible solution that doesn't affect the protocol or existing applications.\n\nSo here's a small RFC that layers this on top of MDP: [http://rfc.zeromq.org/spec:8 the Majordomo Management Interface (MMI)]. We already implemented it in the broker, though unless you read the whole thing you probably missed that. I'll explain how it works in the broker:\n\n* When a client requests a service that starts with {{mmi.}}, instead of routing this to a worker, we handle it internally.\n\n* We handle just one service in this broker, which is {{mmi.service}}, the service discovery service.\n\n* The payload for the request is the name of an external service (a real one, provided by a worker).\n\n* The broker returns \"200\" (OK) or \"404\" (Not found), depending on whether there are workers registered for that service or not.\n\nHere's how we use the service discovery in an application:\n\n[[code type=\"example\" title=\"Service discovery over Majordomo\" name=\"mmiecho\"]]\n[[/code]]\n\nTry this with and without a worker running, and you should see the little program report \"200\" or \"404\" accordingly. The implementation of MMI in our example broker is flimsy. For example, if a worker disappears, services remain \"present\". In practice, a broker should remove services that have no workers after some configurable timeout.\n\n++ Idempotent Services\n\nIdempotency is not something you take a pill for. What it means is that it's safe to repeat an operation. Checking the clock is idempotent. Lending ones credit card to ones children is not. While many client-to-server use cases are idempotent, some are not. Examples of idempotent use cases include:\n\n* Stateless task distribution, i.e., a pipeline where the servers are stateless workers that compute a reply based purely on the state provided by a request. In such a case, it's safe (though inefficient) to execute the same request many times.\n\n* A name service that translates logical addresses into endpoints to bind or connect to. In such a case, it's safe to make the same lookup request many times.\n\nAnd here are examples of a non-idempotent use cases:\n\n* A logging service. One does not want the same log information recorded more than once.\n\n* Any service that has impact on downstream nodes, e.g., sends on information to other nodes. If that service gets the same request more than once, downstream nodes will get duplicate information.\n\n* Any service that modifies shared data in some non-idempotent way; e.g., a service that debits a bank account is not idempotent without extra work.\n\nWhen our server applications are not idempotent, we have to think more carefully about when exactly they might crash. If an application dies when it's idle, or while it's processing a request, that's usually fine. We can use database transactions to make sure a debit and a credit are always done together, if at all. If the server dies while sending its reply, that's a problem, because as far as it's concerned, it has done its work.\n\nIf the network dies just as the reply is making its way back to the client, the same problem arises. The client will think the server died and will resend the request, and the server will do the same work twice, which is not what we want.\n\nTo handle non-idempotent operations, use the fairly standard solution of detecting and rejecting duplicate requests. This means:\n\n* The client must stamp every request with a unique client identifier and a unique message number.\n\n* The server, before sending back a reply, stores it using the combination of client ID and message number as a key.\n\n* The server, when getting a request from a given client, first checks whether it has a reply for that client ID and message number. If so, it does not process the request, but just resends the reply.\n\n++ Disconnected Reliability (Titanic Pattern)\n\nOnce you realize that Majordomo is a \"reliable\" message broker, you might be tempted to add some spinning rust (that is, ferrous-based hard disk platters). After all, this works for all the enterprise messaging systems. It's such a tempting idea that it's a little sad to have to be negative toward it. But brutal cynicism is one of my specialties. So, some reasons you don't want rust-based brokers sitting in the center of your architecture are:\n\n* As you've seen, the Lazy Pirate client performs surprisingly well. It works across a whole range of architectures, from direct client-to-server to distributed queue proxies. It does tend to assume that workers are stateless and idempotent. But we can work around that limitation without resorting to rust.\n\n* Rust brings a whole set of problems, from slow performance to additional pieces that you have to manage, repair, and handle 6 a.m. panics from, as they inevitably break at the start of daily operations. The beauty of the Pirate patterns in general is their simplicity. They won't crash. And if you're still worried about the hardware, you can move to a peer-to-peer pattern that has no broker at all. I'll explain later in this chapter.\n\nHaving said this, however, there is one sane use case for rust-based reliability, which is an asynchronous disconnected network. It solves a major problem with Pirate, namely that a client has to wait for an answer in real time. If clients and workers are only sporadically connected (think of email as an analogy), we can't use a stateless network between clients and workers. We have to put state in the middle.\n\nSo, here's the Titanic pattern[figure], in which we write messages to disk to ensure they never get lost, no matter how sporadically clients and workers are connected. As we did for service discovery, we're going to layer Titanic on top of MDP rather than extend it. It's wonderfully lazy because it means we can implement our fire-and-forget reliability in a specialized worker, rather than in the broker. This is excellent for several reasons:\n\n* It is //much// easier because we divide and conquer: the broker handles message routing and the worker handles reliability.\n* It lets us mix brokers written in one language with workers written in another.\n* It lets us evolve the fire-and-forget technology independently.\n\nThe only downside is that there's an extra network hop between broker and hard disk. The benefits are easily worth it.\n\nThere are many ways to make a persistent request-reply architecture. We'll aim for one that is simple and painless. The simplest design I could come up with, after playing with this for a few hours, is a \"proxy service\". That is, Titanic doesn't affect workers at all. If a client wants a reply immediately, it talks directly to a service and hopes the service is available. If a client is happy to wait a while, it talks to Titanic instead and asks, \"hey, buddy, would you take care of this for me while I go buy my groceries?\"\n\n[[code type=\"textdiagram\" title=\"The Titanic Pattern\"]]\n#-----------#   #-----------#   #-----------#\n|           |   |           |   |           |\n|  Client   |   |  Client   |   |  Client   |\n|           |   |           |   |           |\n'-----------'   '-----------'   '-----------'\n      ^               ^               ^\n      |               |               |\n      '---------------+---------------'\n\"Titanic,             |         \"Titanic,\n give me coffee\"      |          give me tea\"\n                      v                                \n                .-----------.     #---------#     .-------.\n                |           |     |         |     |       |\n                |  Broker   |<--->| Titanic |<--->| Disk  |\n                |           |     |         |     |       |\n                '-----------'     #---------#     '-------'\n                      ^\n                      |\n      .---------------+---------------.\n      |               |               |\n      v               v               v\n.-----------.   .-----------.   .-----------.\n|  \"Water\"  |   |   \"Tea\"   |   | \"Coffee\"  |\n+-----------+   +-----------+   +-----------+\n|  Worker   |   |  Worker   |   |  Worker   |\n#-----------#   #-----------#   #-----------#\n[[/code]]\n\nTitanic is thus both a worker and a client. The dialog between client and Titanic goes along these lines:\n\n* Client: Please accept this request for me. Titanic: OK, done.\n* Client: Do you have a reply for me? Titanic: Yes, here it is. Or, no, not yet.\n* Client: OK, you can wipe that request now, I'm happy. Titanic: OK, done.\n\nWhereas the dialog between Titanic and broker and worker goes like this:\n\n* Titanic: Hey, Broker, is there an coffee service? Broker: Uhm, Yeah, seems like.\n* Titanic: Hey, coffee service, please handle this for me.\n* Coffee: Sure, here you are.\n* Titanic: Sweeeeet!\n\nYou can work through this and the possible failure scenarios. If a worker crashes while processing a request, Titanic retries indefinitely. If a reply gets lost somewhere, Titanic will retry. If the request gets processed but the client doesn't get the reply, it will ask again. If Titanic crashes while processing a request or a reply, the client will try again. As long as requests are fully committed to safe storage, work can't get lost.\n\nThe handshaking is pedantic, but can be pipelined, i.e., clients can use the asynchronous Majordomo pattern to do a lot of work and then get the responses later.\n\nWe need some way for a client to request //its// replies. We'll have many clients asking for the same services, and clients disappear and reappear with different identities. Here is a simple, reasonably secure solution:\n\n* Every request generates a universally unique ID (UUID), which Titanic returns to the client after it has queued the request.\n* When a client asks for a reply, it must specify the UUID for the original request.\n\nIn a realistic case, the client would want to store its request UUIDs safely, e.g., in a local database.\n\nBefore we jump off and write yet another formal specification (fun, fun!), let's consider how the client talks to Titanic. One way is to use a single service and send it three different request types. Another way, which seems simpler, is to use three services:\n\n* {{titanic.request}}: store a request message, and return a UUID for the request.\n* {{titanic.reply}}: fetch a reply, if available, for a given request UUID.\n* {{titanic.close}}: confirm that a reply has been stored and processed.\n\nWe'll just make a multithreaded worker, which as we've seen from our multithreading experience with ZeroMQ, is trivial. However, let's first sketch what Titanic would look like in terms of ZeroMQ messages and frames. This gives us the [http://rfc.zeromq.org/spec:9 Titanic Service Protocol (TSP)].\n\nUsing TSP is clearly more work for client applications than accessing a service directly via MDP. Here's the shortest robust \"echo\" client example:\n\n[[code type=\"example\" title=\"Titanic client example\" name=\"ticlient\"]]\n[[/code]]\n\nOf course this can be, and should be, wrapped up in some kind of framework or API. It's not healthy to ask average application developers to learn the full details of messaging: it hurts their brains, costs time, and offers too many ways to make buggy complexity. Additionally, it makes it hard to add intelligence. \n\nFor example, this client blocks on each request whereas in a real application, we'd want to be doing useful work while tasks are executed. This requires some nontrivial plumbing to build a background thread and talk to that cleanly. It's the kind of thing you want to wrap in a nice simple API that the average developer cannot misuse. It's the same approach that we used for Majordomo.\n\nHere's the Titanic implementation. This server handles the three services using three threads, as proposed. It does full persistence to disk using the most brutal approach possible: one file per message. It's so simple, it's scary. The only complex part is that it keeps a separate queue of all requests, to avoid reading the directory over and over:\n\n[[code type=\"example\" title=\"Titanic broker example\" name=\"titanic\"]]\n[[/code]]\n\nTo test this, start {{mdbroker}} and {{titanic}}, and then run {{ticlient}}. Now start {{mdworker}} arbitrarily, and you should see the client getting a response and exiting happily.\n\nSome notes about this code:\n\n* Note that some loops start by sending, others by receiving messages. This is because Titanic acts both as a client and a worker in different roles.\n* The Titanic broker uses the MMI service discovery protocol to send requests only to services that appear to be running. Since the MMI implementation in our little Majordomo broker is quite poor, this won't work all the time.\n* We use an inproc connection to send new request data from the {{titanic.request}} service through to the main dispatcher. This saves the dispatcher from having to scan the disk directory, load all request files, and sort them by date/time.\n\nThe important thing about this example is not performance (which, although I haven't tested it, is surely terrible), but how well it implements the reliability contract. To try it, start the mdbroker and titanic programs. Then start the ticlient, and then start the mdworker echo service. You can run all four of these using the {{-v}} option to do verbose activity tracing. You can stop and restart any piece //except the client// and nothing will get lost.\n\nIf you want to use Titanic in real cases, you'll rapidly be asking \"how do we make this faster?\"\n\nHere's what I'd do, starting with the example implementation:\n\n* Use a single disk file for all data, rather than multiple files. Operating systems are usually better at handling a few large files than many smaller ones.\n* Organize that disk file as a circular buffer so that new requests can be written contiguously (with very occasional wraparound). One thread, writing full speed to a disk file, can work rapidly.\n* Keep the index in memory and rebuild the index at startup time, from the disk buffer. This saves the extra disk head flutter needed to keep the index fully safe on disk. You would want an fsync after every message, or every N milliseconds if you were prepared to lose the last M messages in case of a system failure.\n* Use a solid-state drive rather than spinning iron oxide platters.\n* Pre-allocate the entire file, or allocate it in large chunks, which allows the circular buffer to grow and shrink as needed. This avoids fragmentation and ensures that most reads and writes are contiguous.\n\nAnd so on. What I'd not recommend is storing messages in a database, not even a \"fast\" key/value store, unless you really like a specific database and don't have performance worries. You will pay a steep price for the abstraction, ten to a thousand times over a raw disk file.\n\nIf you want to make Titanic //even more reliable//, duplicate the requests to a second server, which you'd place in a second location just far away enough to survive a nuclear attack on your primary location, yet not so far that you get too much latency.\n\nIf you want to make Titanic //much faster and less reliable//, store requests and replies purely in memory. This will give you the functionality of a disconnected network, but requests won't survive a crash of the Titanic server itself.\n\n++ High-Availability Pair (Binary Star Pattern)\n\n[[code type=\"textdiagram\" title=\"High-Availability Pair, Normal Operation\"]]\n#------------#           #------------#\n|            |           |            |\n|  Primary   |<--------->|   Backup   |\n|  \"active\"  |           |  \"passive\" |\n|            |           |            |\n#------------#           #------------#\n      ^\n      |\n      |\n      |\n#-----+------#\n|            |\n|   Client   |\n|            |\n#------------#\n[[/code]]\n\nThe Binary Star pattern puts two servers in a primary-backup high-availability pair[figure]. At any given time, one of these (the active) accepts connections from client applications. The other (the passive) does nothing, but the two servers monitor each other. If the active disappears from the network, after a certain time the passive takes over as active.\n\nWe developed the Binary Star pattern at iMatix for our [http://www.openamq.org OpenAMQ server]. We designed it:\n\n* To provide a straightforward high-availability solution.\n* To be simple enough to actually understand and use.\n* To fail over reliably when needed, and only when needed.\n\nAssuming we have a Binary Star pair running, here are the different scenarios that will result in a failover[figure]:\n\n* The hardware running the primary server has a fatal problem (power supply explodes, machine catches fire, or someone simply unplugs it by mistake), and disappears. Applications see this, and reconnect to the backup server.\n* The network segment on which the primary server sits crashes--perhaps a router gets hit by a power spike--and applications start to reconnect to the backup server.\n* The primary server crashes or is killed by the operator and does not restart automatically.\n\n[[code type=\"textdiagram\" title=\"High-availability Pair During Failover\"]]\n#------------#           #------------#\n|            |           |            |\n|  Primary   |<--------->|   Backup   |\n| \"passive\"  |           |  \"active\"  |\n|            |           |            |\n#------------#           #------------#\n                                ^\n                                |\n      .-------------------------'\n      |\n#-----+------#\n|            |\n|   Client   |\n|            |\n#------------#\n[[/code]]\n\nRecovery from failover works as follows:\n\n* The operators restart the primary server and fix whatever problems were causing it to disappear from the network.\n* The operators stop the backup server at a moment when it will cause minimal disruption to applications.\n* When applications have reconnected to the primary server, the operators restart the backup server.\n\nRecovery (to using the primary server as active) is a manual operation. Painful experience teaches us that automatic recovery is undesirable. There are several reasons:\n\n* Failover creates an interruption of service to applications, possibly lasting 10-30 seconds. If there is a real emergency, this is much better than total outage. But if recovery creates a further 10-30 second outage, it is better that this happens off-peak, when users have gone off the network.\n\n* When there is an emergency, the absolute first priority is certainty for those trying to fix things. Automatic recovery creates uncertainty for system administrators, who can no longer be sure which server is in charge without double-checking.\n\n* Automatic recovery can create situations where networks fail over and then recover, placing operators in the difficult position of analyzing what happened. There was an interruption of service, but the cause isn't clear.\n\nHaving said this, the Binary Star pattern will fail back to the primary server if this is running (again) and the backup server fails. In fact, this is how we provoke recovery.\n\nThe shutdown process for a Binary Star pair is to either:\n\n# Stop the passive server and then stop the active server at any later time, or\n# Stop both servers in any order but within a few seconds of each other.\n\nStopping the active and then the passive server with any delay longer than the failover timeout will cause applications to disconnect, then reconnect, and then disconnect again, which may disturb users.\n\n+++ Detailed Requirements\n\nBinary Star is as simple as it can be, while still working accurately. In fact, the current design is the third complete redesign. Each of the previous designs we found to be too complex, trying to do too much, and we stripped out functionality until we came to a design that was understandable, easy to use, and reliable enough to be worth using.\n\nThese are our requirements for a high-availability architecture:\n\n* The failover is meant to provide insurance against catastrophic system failures, such as hardware breakdown, fire, accident, and so on. There are simpler ways to recover from ordinary server crashes and we already covered these.\n\n* Failover time should be under 60 seconds and preferably under 10 seconds.\n\n* Failover has to happen automatically, whereas recovery must happen manually. We want applications to switch over to the backup server automatically, but we do not want them to switch back to the primary server except when the operators have fixed whatever problem there was and decided that it is a good time to interrupt applications again.\n\n* The semantics for client applications should be simple and easy for developers to understand. Ideally, they should be hidden in the client API.\n\n* There should be clear instructions for network architects on how to avoid designs that could lead to //split brain syndrome//, in which both servers in a Binary Star pair think they are the active server.\n\n* There should be no dependencies on the order in which the two servers are started.\n\n* It must be possible to make planned stops and restarts of either server without stopping client applications (though they may be forced to reconnect).\n\n* Operators must be able to monitor both servers at all times.\n\n* It must be possible to connect the two servers using a high-speed dedicated network connection. That is, failover synchronization must be able to use a specific IP route.\n\nWe make the following assumptions:\n\n* A single backup server provides enough insurance; we don't need multiple levels of backup.\n\n* The primary and backup servers are equally capable of carrying the application load. We do not attempt to balance load across the servers.\n\n* There is sufficient budget to cover a fully redundant backup server that does nothing almost all the time.\n\nWe don't attempt to cover the following:\n\n* The use of an active backup server or load balancing. In a Binary Star pair, the backup server is inactive and does no useful work until the primary server goes offline.\n\n* The handling of persistent messages or transactions in any way. We assume the existence of a network of unreliable (and probably untrusted) servers or Binary Star pairs.\n\n* Any automatic exploration of the network. The Binary Star pair is manually and explicitly defined in the network and is known to applications (at least in their configuration data).\n\n* Replication of state or messages between servers. All server-side state must be recreated by applications when they fail over.\n\nHere is the key terminology that we use in Binary Star:\n\n* //Primary//: the server that is normally or initially active.\n\n* //Backup//: the server that is normally passive. It will become active if and when the primary server disappears from the network, and when client applications ask the backup server to connect.\n\n* //Active//: the server that accepts client connections. There is at most one active server.\n\n* //Passive//: the server that takes over if the active disappears. Note that when a Binary Star pair is running normally, the primary server is active, and the backup is passive. When a failover has happened, the roles are switched.\n\nTo configure a Binary Star pair, you need to:\n\n# Tell the primary server where the backup server is located. \n# Tell the backup server where the primary server is located.\n# Optionally, tune the failover response times, which must be the same for both servers.\n\nThe main tuning concern is how frequently you want the servers to check their peering status, and how quickly you want to activate failover. In our example, the failover timeout value defaults to 2,000 msec. If you reduce this, the backup server will take over as active more rapidly but may take over in cases where the primary server could recover. For example, you may have wrapped the primary server in a shell script that restarts it if it crashes. In that case, the timeout should be higher than the time needed to restart the primary server.\n\nFor client applications to work properly with a Binary Star pair, they must:\n\n# Know both server addresses.\n# Try to connect to the primary server, and if that fails, to the backup server.\n# Detect a failed connection, typically using heartbeating.\n# Try to reconnect to the primary, and then backup (in that order), with a delay between retries that is at least as high as the server failover timeout.\n# Recreate all of the state they require on a server.\n# Retransmit messages lost during a failover, if messages need to be reliable.\n\nIt's not trivial work, and we'd usually wrap this in an API that hides it from real end-user applications.\n\nThese are the main limitations of the Binary Star pattern:\n\n* A server process cannot be part of more than one Binary Star pair.\n* A primary server can have a single backup server, and no more.\n* The passive server does no useful work, and is thus wasted.\n* The backup server must be capable of handling full application loads.\n* Failover configuration cannot be modified at runtime.\n* Client applications must do some work to benefit from failover.\n\n+++ Preventing Split-Brain Syndrome\n\n//Split-brain syndrome// occurs when different parts of a cluster think they are active at the same time. It causes applications to stop seeing each other. Binary Star has an algorithm for detecting and eliminating split brain, which is based on a three-way decision mechanism (a server will not decide to become active until it gets application connection requests and it cannot see its peer server).\n\nHowever, it is still possible to (mis)design a network to fool this algorithm. A typical scenario would be a Binary Star pair, that is distributed between two buildings, where each building also had a set of applications and where there was a single network link between both buildings. Breaking this link would create two sets of client applications, each with half of the Binary Star pair, and each failover server would become active.\n\nTo prevent split-brain situations, we must connect a Binary Star pair using a dedicated network link, which can be as simple as plugging them both into the same switch or, better, using a crossover cable directly between two machines.\n\nWe must not split a Binary Star architecture into two islands, each with a set of applications. While this may be a common type of network architecture, you should use federation, not high-availability failover, in such cases.\n\nA suitably paranoid network configuration would use two private cluster interconnects, rather than a single one. Further, the network cards used for the cluster would be different from those used for message traffic, and possibly even on different paths on the server hardware. The goal is to separate possible failures in the network from possible failures in the cluster. Network ports can have a relatively high failure rate.\n\n+++ Binary Star Implementation\n\nWithout further ado, here is a proof-of-concept implementation of the Binary Star server. The primary and backup servers run the same code, you choose their roles when you run the code:\n\n[[code type=\"example\" title=\"Binary Star server\" name=\"bstarsrv\"]]\n[[/code]]\n\nAnd here is the client:\n\n[[code type=\"example\" title=\"Binary Star client\" name=\"bstarcli\"]]\n[[/code]]\n\nTo test Binary Star, start the servers and client in any order:\n\n[[code]]\nbstarsrv -p     # Start primary\nbstarsrv -b     # Start backup\nbstarcli\n[[/code]]\n\nYou can then provoke failover by killing the primary server, and recovery by restarting the primary and killing the backup. Note how it's the client vote that triggers failover, and recovery.\n\nBinary star is driven by a finite state machine[figure]. Events are the peer state, so \"Peer Active\" means the other server has told us it's active. \"Client Request\" means we've received a client request. \"Client Vote\" means we've received a client request AND our peer is inactive for two heartbeats.\n\nNote that the servers use PUB-SUB sockets for state exchange. No other socket combination will work here. PUSH and DEALER block if there is no peer ready to receive a message. PAIR does not reconnect if the peer disappears and comes back. ROUTER needs the address of the peer before it can send it a message.\n\n[[code type=\"textdiagram\" title=\"Binary Star Finite State Machine\"]]\n    Start .-----------------------.   .----------.               Start\n          |                       |   |          |                   \n      |   |Client Request         |   |    Client| Request         |\n      v   |                       v   v          |                 v\n.---------+-.                 .-----------.      |           .-----------.\n|           | Peer Backup     |           +------'           |           |\n|  Primary  +---------------->|  Active   |<--------------.  |  Backup   |\n|           |         .------>|           |<-----.        |  |           |\n'-----+-----'         |       '-----+-----'      |        |  '-----+-----'\n      |               |             |            |        |        |\n  Peer| Active        |         Peer| Active     |        |    Peer| Active\n      |               |             v            |        |        |\n      |               |       .-----------.      |        |        |\n      |               |       |           |      |        |        |\n      |           Peer| Backup|  Error!   |  Peer| Primary|        |\n      |               |       |           |      |        |        |\n      |               |       '-----------'      |        |        |\n      |               |             ^            |        |        |\n      |               |         Peer| Passive    |  Client| Vote   |\n      |               |             |            |        |        |\n      |               |       .-----+-----.      |        |        |\n      |               |       |           +------'        |        |\n      |               '-------+  Passive  +---------------'        |\n      '---------------------->|           |<-----------------------'\n                              '-----------'\n[[/code]]\n\n+++ Binary Star Reactor\n\nBinary Star is useful and generic enough to package up as a reusable reactor class. The reactor then runs and calls our code whenever it has a message to process. This is much nicer than copying/pasting the Binary Star code into each server where we want that capability.\n\nIn C, we wrap the CZMQ {{zloop}} class that we saw before. {{zloop}} lets you register handlers to react on socket and timer events. In the Binary Star reactor, we provide handlers for voters and for state changes (active to passive, and vice versa). Here is the {{bstar}} API:\n\n[[code type=\"fragment\" name=\"bstar\"]]\n//  Create a new Binary Star instance, using local (bind) and\n//  remote (connect) endpoints to set up the server peering.\nbstar_t *bstar_new (int primary, char *local, char *remote);\n\n//  Destroy a Binary Star instance\nvoid bstar_destroy (bstar_t **self_p);\n\n//  Return underlying zloop reactor, for timer and reader\n//  registration and cancelation.\nzloop_t *bstar_zloop (bstar_t *self);\n\n//  Register voting reader\nint bstar_voter (bstar_t *self, char *endpoint, int type,\n                 zloop_fn handler, void *arg);\n\n//  Register main state change handlers\nvoid bstar_new_active (bstar_t *self, zloop_fn handler, void *arg);\nvoid bstar_new_passive (bstar_t *self, zloop_fn handler, void *arg);\n\n//  Start the reactor, which ends if a callback function returns -1, \n//  or the process received SIGINT or SIGTERM.\nint bstar_start (bstar_t *self);\n[[/code]]\n\nAnd here is the class implementation:\n\n[[code type=\"example\" title=\"Binary Star core class\" name=\"bstar\"]]\n[[/code]]\n\nThis gives us the following short main program for the server:\n\n[[code type=\"example\" title=\"Binary Star server, using core class\" name=\"bstarsrv2\"]]\n[[/code]]\n\n++ Brokerless Reliability (Freelance Pattern)\n\nIt might seem ironic to focus so much on broker-based reliability, when we often explain ZeroMQ as \"brokerless messaging\". However, in messaging, as in real life, the middleman is both a burden and a benefit. In practice, most messaging architectures benefit from a mix of distributed and brokered messaging. You get the best results when you can decide freely what trade-offs you want to make. This is why I can drive twenty minutes to a wholesaler to buy five cases of wine for a party, but I can also walk ten minutes to a corner store to buy one bottle for a dinner. Our highly context-sensitive relative valuations of time, energy, and cost are essential to the real world economy. And they are essential to an optimal message-based architecture.\n\nThis is why ZeroMQ does not //impose// a broker-centric architecture, though it does give you the tools to build brokers, aka //proxies//, and we've built a dozen or so different ones so far, just for practice.\n\nSo we'll end this chapter by deconstructing the broker-based reliability we've built so far, and turning it back into a distributed peer-to-peer architecture I call the Freelance pattern. Our use case will be a name resolution service. This is a common problem with ZeroMQ architectures: how do we know the endpoint to connect to? Hard-coding TCP/IP addresses in code is insanely fragile. Using configuration files creates an administration nightmare. Imagine if you had to hand-configure your web browser, on every PC or mobile phone you used, to realize that \"google.com\" was \"74.125.230.82\".\n\nA ZeroMQ name service (and we'll make a simple implementation) must do the following:\n\n* Resolve a logical name into at least a bind endpoint, and a connect endpoint. A realistic name service would provide multiple bind endpoints, and possibly multiple connect endpoints as well.\n\n* Allow us to manage multiple parallel environments, e.g., \"test\" versus \"production\", without modifying code.\n\n* Be reliable, because if it is unavailable, applications won't be able to connect to the network.\n\nPutting a name service behind a service-oriented Majordomo broker is clever from some points of view. However, it's simpler and much less surprising to just expose the name service as a server to which clients can connect directly. If we do this right, the name service becomes the //only// global network endpoint we need to hard-code in our code or configuration files.\n\n[[code type=\"textdiagram\" title=\"The Freelance Pattern\"]]\n#-----------#   #-----------#   #-----------#\n|  Client   |   |  Client   |   |  Client   |\n'-----------'   '-----------'   '-----------'\n   connect         connect         connect\n      |               |               |\n      |               |               |\n      +---------------+---------------+\n      |               |               |\n      |               |               |\n    bind            bind            bind\n.-----------.   .-----------.   .-----------.\n|  Server   |   |  Server   |   |  Server   |\n#-----------#   #-----------#   #-----------#\n[[/code]]\n\nThe types of failure we aim to handle are server crashes and restarts, server busy looping, server overload, and network issues. To get reliability, we'll create a pool of name servers so if one crashes or goes away, clients can connect to another, and so on. In practice, two would be enough. But for the example, we'll assume the pool can be any size[figure].\n\nIn this architecture, a large set of clients connect to a small set of servers directly. The servers bind to their respective addresses. It's fundamentally different from a broker-based approach like Majordomo, where workers connect to the broker. Clients have a couple of options:\n\n* Use REQ sockets and the Lazy Pirate pattern. Easy, but would need some additional intelligence so clients don't stupidly try to reconnect to dead servers over and over.\n\n* Use DEALER sockets and blast out requests (which will be load balanced to all connected servers) until they get a reply. Effective, but not elegant.\n\n* Use ROUTER sockets so clients can address specific servers. But how does the client know the identity of the server sockets? Either the server has to ping the client first (complex), or the server has to use a hard-coded, fixed identity known to the client (nasty).\n\nWe'll develop each of these in the following subsections.\n\n+++ Model One: Simple Retry and Failover\n\nSo our menu appears to offer: simple, brutal, complex, or nasty. Let's start with simple and then work out the kinks. We take Lazy Pirate and rewrite it to work with multiple server endpoints.\n\nStart one or several servers first, specifying a bind endpoint as the argument:\n\n[[code type=\"example\" title=\"Freelance server, Model One\" name=\"flserver1\"]]\n[[/code]]\n\nThen start the client, specifying one or more connect endpoints as arguments:\n\n[[code type=\"example\" title=\"Freelance client, Model One\" name=\"flclient1\"]]\n[[/code]]\n\nA sample run is:\n\n[[code]]\nflserver1 tcp://*:5555 &\nflserver1 tcp://*:5556 &\nflclient1 tcp://localhost:5555 tcp://localhost:5556\n[[/code]]\n\nAlthough the basic approach is Lazy Pirate, the client aims to just get one successful reply. It has two techniques, depending on whether you are running a single server or multiple servers:\n\n* With a single server, the client will retry several times, exactly as for Lazy Pirate.\n* With multiple servers, the client will try each server at most once until it's received a reply or has tried all servers.\n\nThis solves the main weakness of Lazy Pirate, namely that it could not fail over to backup or alternate servers.\n\nHowever, this design won't work well in a real application. If we're connecting many sockets and our primary name server is down, we're going to experience this painful timeout each time.\n\n+++ Model Two: Brutal Shotgun Massacre\n\nLet's switch our client to using a DEALER socket. Our goal here is to make sure we get a reply back within the shortest possible time, no matter whether a particular server is up or down. Our client takes this approach:\n\n* We set things up, connecting to all servers.\n* When we have a request, we blast it out as many times as we have servers.\n* We wait for the first reply, and take that.\n* We ignore any other replies.\n\nWhat will happen in practice is that when all servers are running, ZeroMQ will distribute the requests so that each server gets one request and sends one reply. When any server is offline and disconnected, ZeroMQ will distribute the requests to the remaining servers. So a server may in some cases get the same request more than once.\n\nWhat's more annoying for the client is that we'll get multiple replies back, but there's no guarantee we'll get a precise number of replies. Requests and replies can get lost (e.g., if the server crashes while processing a request).\n\nSo we have to number requests and ignore any replies that don't match the request number. Our Model One server will work because it's an echo server, but coincidence is not a great basis for understanding. So we'll make a Model Two server that chews up the message and returns a correctly numbered reply with the content \"OK\". We'll use messages consisting of two parts: a sequence number and a body.\n\nStart one or more servers, specifying a bind endpoint each time:\n\n[[code type=\"example\" title=\"Freelance server, Model Two\" name=\"flserver2\"]]\n[[/code]]\n\nThen start the client, specifying the connect endpoints as arguments:\n\n[[code type=\"example\" title=\"Freelance client, Model Two\" name=\"flclient2\"]]\n[[/code]]\n\nHere are some things to note about the client implementation:\n\n* The client is structured as a nice little class-based API that hides the dirty work of creating ZeroMQ contexts and sockets and talking to the server. That is, if a shotgun blast to the midriff can be called \"talking\".\n\n* The client will abandon the chase if it can't find //any// responsive server within a few seconds.\n\n* The client has to create a valid REP envelope, i.e., add an empty message frame to the front of the message.\n\nThe client performs 10,000 name resolution requests (fake ones, as our server does essentially nothing) and measures the average cost. On my test box, talking to one server, this requires about 60 microseconds. Talking to three servers, it takes about 80 microseconds.\n\nThe pros and cons of our shotgun approach are:\n\n* Pro: it is simple, easy to make and easy to understand.\n* Pro: it does the job of failover, and works rapidly, so long as there is at least one server running.\n* Con: it creates redundant network traffic.\n* Con: we can't prioritize our servers, i.e., Primary, then Secondary.\n* Con: the server can do at most one request at a time, period.\n\n+++ Model Three: Complex and Nasty\n\nThe shotgun approach seems too good to be true. Let's be scientific and work through all the alternatives. We're going to explore the complex/nasty option, even if it's only to finally realize that we preferred brutal. Ah, the story of my life.\n\nWe can solve the main problems of the client by switching to a ROUTER socket. That lets us send requests to specific servers, avoid servers we know are dead, and in general be as smart as we want to be. We can also solve the main problem of the server (single-threadedness) by switching to a ROUTER socket.\n\nBut doing ROUTER to ROUTER between two anonymous sockets (which haven't set an identity) is not possible. Both sides generate an identity (for the other peer) only when they receive a first message, and thus neither can talk to the other until it has first received a message. The only way out of this conundrum is to cheat, and use hard-coded identities in one direction. The proper way to cheat, in a client/server case, is to let the client \"know\" the identity of the server. Doing it the other way around would be insane, on top of complex and nasty, because any number of clients should be able to arise independently. Insane, complex, and nasty are great attributes for a genocidal dictator, but terrible ones for software.\n\nRather than invent yet another concept to manage, we'll use the connection endpoint as identity. This is a unique string on which both sides can agree without more prior knowledge than they already have for the shotgun model. It's a sneaky and effective way to connect two ROUTER sockets.\n\nRemember how ZeroMQ identities work. The server ROUTER socket sets an identity before it binds its socket. When a client connects, they do a little handshake to exchange identities, before either side sends a real message. The client ROUTER socket, having not set an identity, sends a null identity to the server. The server generates a random UUID to designate the client for its own use. The server sends its identity (which we've agreed is going to be an endpoint string) to the client.\n\nThis means that our client can route a message to the server (i.e., send on its ROUTER socket, specifying the server endpoint as identity) as soon as the connection is established. That's not //immediately// after doing a {{zmq_connect[3]}}, but some random time thereafter. Herein lies one problem: we don't know when the server will actually be available and complete its connection handshake. If the server is online, it could be after a few milliseconds. If the server is down and the sysadmin is out to lunch, it could be an hour from now.\n\nThere's a small paradox here. We need to know when servers become connected and available for work. In the Freelance pattern, unlike the broker-based patterns we saw earlier in this chapter, servers are silent until spoken to. Thus we can't talk to a server until it's told us it's online, which it can't do until we've asked it.\n\nMy solution is to mix in a little of the shotgun approach from model 2, meaning we'll fire (harmless) shots at anything we can, and if anything moves, we know it's alive. We're not going to fire real requests, but rather a kind of ping-pong heartbeat.\n\nThis brings us to the realm of protocols again, so here's a [http://rfc.zeromq.org/spec:10 short spec that defines how a Freelance client and server exchange ping-pong commands and request-reply commands].\n\nIt is short and sweet to implement as a server. Here's our echo server, Model Three, now speaking FLP:\n\n[[code type=\"example\" title=\"Freelance server, Model Three\" name=\"flserver3\"]]\n[[/code]]\n\nThe Freelance client, however, has gotten large. For clarity, it's split into an example application and a class that does the hard work. Here's the top-level application:\n\n[[code type=\"example\" title=\"Freelance client, Model Three\" name=\"flclient3\"]]\n[[/code]]\n\nAnd here, almost as complex and large as the Majordomo broker, is the client API class:\n\n[[code type=\"example\" title=\"Freelance client API\" name=\"flcliapi\"]]\n[[/code]]\n\nThis API implementation is fairly sophisticated and uses a couple of techniques that we've not seen before.\n\n* **Multithreaded API**: the client API consists of two parts, a synchronous {{flcliapi}} class that runs in the application thread, and an asynchronous //agent// class that runs as a background thread. Remember how ZeroMQ makes it easy to create multithreaded apps. The flcliapi and agent classes talk to each other with messages over an {{inproc}} socket. All ZeroMQ aspects (such as creating and destroying a context) are hidden in the API. The agent in effect acts like a mini-broker, talking to servers in the background, so that when we make a request, it can make a best effort to reach a server it believes is available.\n\n* **Tickless poll timer**: in previous poll loops we always used a fixed tick interval, e.g., 1 second, which is simple enough but not excellent on power-sensitive clients (such as notebooks or mobile phones), where waking the CPU costs power. For fun, and to help save the planet, the agent uses a //tickless timer//, which calculates the poll delay based on the next timeout we're expecting. A proper implementation would keep an ordered list of timeouts. We just check all timeouts and calculate the poll delay until the next one.\n\n++ Conclusion\n\nIn this chapter, we've seen a variety of reliable request-reply mechanisms, each with certain costs and benefits. The example code is largely ready for real use, though it is not optimized. Of all the different patterns, the two that stand out for production use are the Majordomo pattern, for broker-based reliability, and the Freelance pattern, for brokerless reliability.\n"
        },
        {
          "name": "chapter5.txt",
          "type": "blob",
          "size": 61.115234375,
          "content": ".output chapter5.wd\n.bookmark advanced-pub-sub\n+ Advanced Pub-Sub Patterns\n\nIn [#advanced-request-reply] and [#reliable-request-reply] we looked at advanced use of ZeroMQ's request-reply pattern. If you managed to digest all that, congratulations. In this chapter we'll focus on publish-subscribe and extend ZeroMQ's core pub-sub pattern with higher-level patterns for performance, reliability, state distribution, and monitoring.\n\nWe'll cover:\n\n* When to use publish-subscribe\n* How to handle too-slow subscribers (the //Suicidal Snail// pattern)\n* How to design high-speed subscribers (the //Black Box// pattern)\n* How to monitor a pub-sub network (the //Espresso// pattern)\n* How to build a shared key-value store (the //Clone// pattern)\n* How to use reactors to simplify complex servers\n* How to use the Binary Star pattern to add failover to a server\n\n++ Pros and Cons of Pub-Sub\n\nZeroMQ's low-level patterns have their different characters. Pub-sub addresses an old messaging problem, which is //multicast// or //group messaging//. It has that unique mix of meticulous simplicity and brutal indifference that characterizes ZeroMQ. It's worth understanding the trade-offs that pub-sub makes, how these benefit us, and how we can work around them if needed.\n\nFirst, PUB sends each message to \"all of many\", whereas PUSH and DEALER rotate messages to \"one of many\". You cannot simply replace PUSH with PUB or vice versa and hope that things will work. This bears repeating because people seem to quite often suggest doing this.\n\nMore profoundly, pub-sub is aimed at scalability. This means large volumes of data, sent rapidly to many recipients. If you need millions of messages per second sent to thousands of points, you'll appreciate pub-sub a lot more than if you need a few messages a second sent to a handful of recipients.\n\nTo get scalability, pub-sub uses the same trick as push-pull, which is to get rid of back-chatter. This means that recipients don't talk back to senders. There are some exceptions, e.g., SUB sockets will send subscriptions to PUB sockets, but it's anonymous and infrequent.\n\nKilling back-chatter is essential to real scalability. With pub-sub, it's how the pattern can map cleanly to the PGM multicast protocol, which is handled by the network switch. In other words, subscribers don't connect to the publisher at all, they connect to a multicast //group// on the switch, to which the publisher sends its messages.\n\nWhen we remove back-chatter, our overall message flow becomes //much// simpler, which lets us make simpler APIs, simpler protocols, and in general reach many more people. But we also remove any possibility to coordinate senders and receivers. What this means is:\n\n* Publishers can't tell when subscribers are successfully connected, both on initial connections, and on reconnections after network failures.\n\n* Subscribers can't tell publishers anything that would allow publishers to control the rate of messages they send. Publishers only have one setting, which is //full-speed//, and subscribers must either keep up or lose messages.\n\n* Publishers can't tell when subscribers have disappeared due to processes crashing, networks breaking, and so on.\n\nThe downside is that we actually need all of these if we want to do reliable multicast. The ZeroMQ pub-sub pattern will lose messages arbitrarily when a subscriber is connecting, when a network failure occurs, or just if the subscriber or network can't keep up with the publisher.\n\nThe upside is that there are many use cases where //almost// reliable multicast is just fine. When we need this back-chatter, we can either switch to using ROUTER-DEALER (which I tend to do for most normal volume cases), or we can add a separate channel for synchronization (we'll see an example of this later in this chapter).\n\nPub-sub is like a radio broadcast; you miss everything before you join, and then how much information you get depends on the quality of your reception. Surprisingly, this model is useful and widespread because it maps perfectly to real world distribution of information. Think of Facebook and Twitter, the BBC World Service, and the sports results.\n\nAs we did for request-reply, let's define //reliability// in terms of what can go wrong. Here are the classic failure cases for pub-sub:\n\n* Subscribers join late, so they miss messages the server already sent.\n* Subscribers can fetch messages too slowly, so queues build up and then overflow.\n* Subscribers can drop off and lose messages while they are away.\n* Subscribers can crash and restart, and lose whatever data they already received.\n* Networks can become overloaded and drop data (specifically, for PGM).\n* Networks can become too slow, so publisher-side queues overflow and publishers crash.\n\nA lot more can go wrong but these are the typical failures we see in a realistic system. Since v3.x, ZeroMQ forces default limits on its internal buffers (the so-called high-water mark or HWM), so publisher crashes are rarer unless you deliberately set the HWM to infinite.\n\nAll of these failure cases have answers, though not always simple ones. Reliability requires complexity that most of us don't need, most of the time, which is why ZeroMQ doesn't attempt to provide it out of the box (even if there was one global design for reliability, which there isn't).\n\n++ Pub-Sub Tracing (Espresso Pattern)\n\nLet's start this chapter by looking at a way to trace pub-sub networks. In [#sockets-and-patterns] we saw a simple proxy that used these to do transport bridging. The {{zmq_proxy[3]}} method has three arguments: a //frontend// and //backend// socket that it bridges together, and a //capture// socket to which it will send all messages.\n\nThe code is deceptively simple:\n\n[[code type=\"example\" title=\"Espresso Pattern\" name=\"espresso\"]]\n[[/code]]\n\nEspresso works by creating a listener thread that reads a PAIR socket and prints anything it gets. That PAIR socket is one end of a pipe; the other end (another PAIR) is the socket we pass to {{zmq_proxy[3]}}. In practice, you'd filter interesting messages to get the essence of what you want to track (hence the name of the pattern).\n\nThe subscriber thread subscribes to \"A\" and \"B\", receives five messages, and then destroys its socket. When you run the example, the listener prints two subscription messages, five data messages, two unsubscribe messages, and then silence:\n\n[[code]]\n[002] 0141\n[002] 0142\n[007] B-91164\n[007] B-12979\n[007] A-52599\n[007] A-06417\n[007] A-45770\n[002] 0041\n[002] 0042\n[[/code]]\n\nThis shows neatly how the publisher socket stops sending data when there are no subscribers for it. The publisher thread is still sending messages. The socket just drops them silently.\n\n++ Last Value Caching\n\nIf you've used commercial pub-sub systems, you may be used to some features that are missing in the fast and cheerful ZeroMQ pub-sub model. One of these is //last value caching// (LVC). This solves the problem of how a new subscriber catches up when it joins the network. The theory is that publishers get notified when a new subscriber joins and subscribes to some specific topics. The publisher can then rebroadcast the last message for those topics.\n\nI've already explained why publishers don't get notified when there are new subscribers, because in large pub-sub systems, the volumes of data make it pretty much impossible. To make really large-scale pub-sub networks, you need a protocol like PGM that exploits an upscale Ethernet switch's ability to multicast data to thousands of subscribers. Trying to do a TCP unicast from the publisher to each of thousands of subscribers just doesn't scale. You get weird spikes, unfair distribution (some subscribers getting the message before others), network congestion, and general unhappiness.\n\nPGM is a one-way protocol: the publisher sends a message to a multicast address at the switch, which then rebroadcasts that to all interested subscribers. The publisher never sees when subscribers join or leave: this all happens in the switch, which we don't really want to start reprogramming.\n\nHowever, in a lower-volume network with a few dozen subscribers and a limited number of topics, we can use TCP and then the XSUB and XPUB sockets //do// talk to each other as we just saw in the Espresso pattern.\n\nCan we make an LVC using ZeroMQ? The answer is yes, if we make a proxy that sits between the publisher and subscribers; an analog for the PGM switch, but one we can program ourselves.\n\nI'll start by making a publisher and subscriber that highlight the worst case scenario. This publisher is pathological. It starts by immediately sending messages to each of a thousand topics, and then it sends one update a second to a random topic. A subscriber connects, and subscribes to a topic. Without LVC, a subscriber would have to wait an average of 500 seconds to get any data. To add some drama, let's pretend there's an escaped convict called Gregor threatening to rip the head off Roger the toy bunny if we can't fix that 8.3 minutes' delay.\n\nHere's the publisher code. Note that it has the command line option to connect to some address, but otherwise binds to an endpoint. We'll use this later to connect to our last value cache:\n\n[[code type=\"example\" title=\"Pathologic Publisher\" name=\"pathopub\"]]\n[[/code]]\n\nAnd here's the subscriber:\n\n[[code type=\"example\" title=\"Pathologic Subscriber\" name=\"pathosub\"]]\n[[/code]]\n\nTry building and running these: first the subscriber, then the publisher. You'll see the subscriber reports getting \"Save Roger\" as you'd expect:\n\n[[code]]\n./pathosub &\n./pathopub\n[[/code]]\n\nIt's when you run a second subscriber that you understand Roger's predicament. You have to leave it an awful long time before it reports getting any data. So, here's our last value cache. As I promised, it's a proxy that binds to two sockets and then handles messages on both:\n\n[[code type=\"example\" title=\"Last Value Caching Proxy\" name=\"lvcache\"]]\n[[/code]]\n\nNow, run the proxy, and then the publisher:\n\n[[code]]\n./lvcache &\n./pathopub tcp://localhost:5557\n[[/code]]\n\nAnd now run as many instances of the subscriber as you want to try, each time connecting to the proxy on port 5558:\n\n[[code]]\n./pathosub tcp://localhost:5558\n[[/code]]\n\nEach subscriber happily reports \"Save Roger\", and Gregor the Escaped Convict slinks back to his seat for dinner and a nice cup of hot milk, which is all he really wanted in the first place.\n\nOne note: by default, the XPUB socket does not report duplicate subscriptions, which is what you want when you're naively connecting an XPUB to an XSUB. Our example sneakily gets around this by using random topics so the chance of it not working is one in a million. In a real LVC proxy, you'll want to use the {{ZMQ_XPUB_VERBOSE}} option that we implement in [#the-community] as an exercise.\n\n++ Slow Subscriber Detection (Suicidal Snail Pattern)\n\nA common problem you will hit when using the pub-sub pattern in real life is the slow subscriber. In an ideal world, we stream data at full speed from publishers to subscribers. In reality, subscriber applications are often written in interpreted languages, or just do a lot of work, or are just badly written, to the extent that they can't keep up with publishers.\n\nHow do we handle a slow subscriber? The ideal fix is to make the subscriber faster, but that might take work and time. Some of the classic strategies for handling a slow subscriber are:\n\n* **Queue messages on the publisher**. This is what Gmail does when I don't read my email for a couple of hours. But in high-volume messaging, pushing queues upstream has the thrilling but unprofitable result of making publishers run out of memory and crash--especially if there are lots of subscribers and it's not possible to flush to disk for performance reasons.\n\n* **Queue messages on the subscriber**. This is much better, and it's what ZeroMQ does by default if the network can keep up with things. If anyone's going to run out of memory and crash, it'll be the subscriber rather than the publisher, which is fair. This is perfect for \"peaky\" streams where a subscriber can't keep up for a while, but can catch up when the stream slows down. However, it's no answer to a subscriber that's simply too slow in general.\n\n* **Stop queuing new messages after a while**. This is what Gmail does when my mailbox overflows its precious gigabytes of space. New messages just get rejected or dropped. This is a great strategy from the perspective of the publisher, and it's what ZeroMQ does when the publisher sets a HWM. However, it still doesn't help us fix the slow subscriber. Now we just get gaps in our message stream.\n\n* **Punish slow subscribers with disconnect**. This is what Hotmail (remember that?) did when I didn't log in for two weeks, which is why I was on my fifteenth Hotmail account when it hit me that there was perhaps a better way. It's a nice brutal strategy that forces subscribers to sit up and pay attention and would be ideal, but ZeroMQ doesn't do this, and there's no way to layer it on top because subscribers are invisible to publisher applications.\n\nNone of these classic strategies fit, so we need to get creative. Rather than disconnect the publisher, let's convince the subscriber to kill itself. This is the Suicidal Snail pattern. When a subscriber detects that it's running too slowly (where \"too slowly\" is presumably a configured option that really means \"so slowly that if you ever get here, shout really loudly because I need to know, so I can fix this!\"), it croaks and dies.\n\nHow can a subscriber detect this? One way would be to sequence messages (number them in order) and use a HWM at the publisher. Now, if the subscriber detects a gap (i.e., the numbering isn't consecutive), it knows something is wrong. We then tune the HWM to the \"croak and die if you hit this\" level.\n\nThere are two problems with this solution. One, if we have many publishers, how do we sequence messages? The solution is to give each publisher a unique ID and add that to the sequencing. Second, if subscribers use {{ZMQ_SUBSCRIBE}} filters, they will get gaps by definition. Our precious sequencing will be for nothing.\n\nSome use cases won't use filters, and sequencing will work for them. But a more general solution is that the publisher timestamps each message. When a subscriber gets a message, it checks the time, and if the difference is more than, say, one second, it does the \"croak and die\" thing, possibly firing off a squawk to some operator console first.\n\nThe Suicide Snail pattern works especially when subscribers have their own clients and service-level agreements and need to guarantee certain maximum latencies. Aborting a subscriber may not seem like a constructive way to guarantee a maximum latency, but it's the assertion model. Abort today, and the problem will be fixed. Allow late data to flow downstream, and the problem may cause wider damage and take longer to appear on the radar.\n\nHere is a minimal example of a Suicidal Snail:\n\n[[code type=\"example\" title=\"Suicidal Snail\" name=\"suisnail\"]]\n[[/code]]\n\nHere are some things to note about the Suicidal Snail example:\n\n* The message here consists simply of the current system clock as a number of milliseconds. In a realistic application, you'd have at least a message header with the timestamp and a message body with data.\n\n* The example has subscriber and publisher in a single process as two threads. In reality, they would be separate processes. Using threads is just convenient for the demonstration.\n\n++ High-Speed Subscribers (Black Box Pattern)\n\nNow lets look at one way to make our subscribers faster. A common use case for pub-sub is distributing large data streams like market data coming from stock exchanges. A typical setup would have a publisher connected to a stock exchange, taking price quotes, and sending them out to a number of subscribers. If there are a handful of subscribers, we could use TCP. If we have a larger number of subscribers, we'd probably use reliable multicast, i.e., PGM.\n\n[[code type=\"textdiagram\" title=\"The Simple Black Box Pattern\"]]\n               #-----------#\n               | Publisher |\n               +-----------+\n               |    PUB    |\n               '-----+-----'\n                     |\n.--------------------|-------------------.\n:                    |          Fast box :\n:                    v                   :\n:              .-----------.             :\n:              |    SUB    |             :\n:              +-----------+             :\n:              | Subscriber|             :\n:              +-----------+             :\n:              |   PUSH    |             :\n:              '-----+-----'             :\n:                    |                   :\n:       .------------+------------.      :\n:       |            |            |      :\n:       v            v            v      :\n:  .--------.   .--------.   .--------.  :\n:  |  PULL  |   |  PULL  |   |  PULL  |  :\n:  +--------+   +--------+   +--------+  :\n:  | Worker |   | Worker |   | Worker |  :\n:  #--------#   #--------#   #--------#  :\n'----------------------------------------'\n[[/code]]\n\nLet's imagine our feed has an average of 100,000 100-byte messages a second. That's a typical rate, after filtering market data we don't need to send on to subscribers. Now we decide to record a day's data (maybe 250 GB in 8 hours), and then replay it to a simulation network, i.e., a small group of subscribers. While 100K messages a second is easy for a ZeroMQ application, we want to replay it //much faster//.\n\nSo we set up our architecture with a bunch of boxes--one for the publisher and one for each subscriber. These are well-specified boxes--eight cores, twelve for the publisher.\n\nAnd as we pump data into our subscribers, we notice two things:\n\n# When we do even the slightest amount of work with a message, it slows down our subscriber to the point where it can't catch up with the publisher again.\n\n# We're hitting a ceiling, at both publisher and subscriber, to around 6M messages a second, even after careful optimization and TCP tuning.\n\nThe first thing we have to do is break our subscriber into a multithreaded design so that we can do work with messages in one set of threads, while reading messages in another. Typically, we don't want to process every message the same way. Rather, the subscriber will filter some messages, perhaps by prefix key. When a message matches some criteria, the subscriber will call a worker to deal with it. In ZeroMQ terms, this means sending the message to a worker thread.\n\nSo the subscriber looks something like a queue device. We could use various sockets to connect the subscriber and workers. If we assume one-way traffic and workers that are all identical, we can use PUSH and PULL and delegate all the routing work to ZeroMQ[figure]. This is the simplest and fastest approach.\n\nThe subscriber talks to the publisher over TCP or PGM. The subscriber talks to its workers, which are all in the same process, over {{inproc:@<//>@}}.\n\n[[code type=\"textdiagram\" title=\"Mad Black Box Pattern\"]]\n               #-----------#\n               | Publisher |\n               +-----+-----+\n               | PUB | PUB |\n               '--+--+--+--'\n                  |     |\n.------------=--- | -=- | ---------------.\n:                 |     |      Fast box  :\n:                 v     v                :\n:              .-----+-----.             :\n:              | SUB | SUB |             :\n:              +-----+-----+             :\n:              | Subscriber|             :\n:              +-----+-----+             :\n:              |PUSH | PUSH|             :\n:              '--+--+--+--'             :\n:                 |     |                :\n:      .----------+-.   '--------.       :\n:      |            |            |       :\n:      v            v            v       :\n:  .--------.   .--------.   .--------.  :\n:  |  PULL  |   |  PULL  |   |  PULL  |  :\n:  +--------+   +--------+   +--------+  :\n:  | Worker |   | Worker |   | Worker |  :\n:  #--------#   #--------#   #--------#  :\n'----------------------------------------'\n[[/code]]\n\nNow to break that ceiling. The subscriber thread hits 100% of CPU and because it is one thread, it cannot use more than one core. A single thread will always hit a ceiling, be it at 2M, 6M, or more messages per second. We want to split the work across multiple threads that can run in parallel.\n\nThe approach used by many high-performance products, which works here, is //sharding//. Using sharding, we split the work into parallel and independent streams, such as half of the topic keys in one stream, and half in another. We could use many streams, but performance won't scale unless we have free cores. So let's see how to shard into two streams[figure].\n\nWith two streams, working at full speed, we would configure ZeroMQ as follows:\n\n* Two I/O threads, rather than one.\n* Two network interfaces (NIC), one per subscriber.\n* Each I/O thread bound to a specific NIC.\n* Two subscriber threads, bound to specific cores.\n* Two SUB sockets, one per subscriber thread.\n* The remaining cores assigned to worker threads.\n* Worker threads connected to both subscriber PUSH sockets.\n\nIdeally, we want to match the number of fully-loaded threads in our architecture with the number of cores. When threads start to fight for cores and CPU cycles, the cost of adding more threads outweighs the benefits. There would be no benefit, for example, in creating more I/O threads.\n\n++ Reliable Pub-Sub (Clone Pattern)\n\nAs a larger worked example, we'll take the problem of making a reliable pub-sub architecture. We'll develop this in stages. The goal is to allow a set of applications to share some common state. Here are our technical challenges:\n\n* We have a large set of client applications, say thousands or tens of thousands.\n* They will join and leave the network arbitrarily.\n* These applications must share a single eventually-consistent //state//.\n* Any application can update the state at any point in time.\n\nLet's say that updates are reasonably low-volume. We don't have real time goals. The whole state can fit into memory. Some plausible use cases are:\n\n* A configuration that is shared by a group of cloud servers.\n* Some game state shared by a group of players.\n* Exchange rate data that is updated in real time and available to applications.\n\n+++ Centralized Versus Decentralized\n\nA first decision we have to make is whether we work with a central server or not. It makes a big difference in the resulting design. The trade-offs are these:\n\n* Conceptually, a central server is simpler to understand because networks are not naturally symmetrical. With a central server, we avoid all questions of discovery, bind versus connect, and so on.\n\n* Generally, a fully-distributed architecture is technically more challenging but ends up with simpler protocols. That is, each node must act as server and client in the right way, which is delicate. When done right, the results are simpler than using a central server. We saw this in the Freelance pattern in [#reliable-request-reply].\n\n* A central server will become a bottleneck in high-volume use cases. If handling scale in the order of millions of messages a second is required, we should aim for decentralization right away.\n\n* Ironically, a centralized architecture will scale to more nodes more easily than a decentralized one. That is, it's easier to connect 10,000 nodes to one server than to each other.\n\nSo, for the Clone pattern we'll work with a //server// that publishes state updates and a set of //clients// that represent applications.\n\n+++ Representing State as Key-Value Pairs\n\nWe'll develop Clone in stages, solving one problem at a time. First, let's look at how to update a shared state across a set of clients. We need to decide how to represent our state, as well as the updates. The simplest plausible format is a key-value store, where one key-value pair represents an atomic unit of change in the shared state.\n\nWe have a simple pub-sub example in [#basics], the weather server and client. Let's change the server to send key-value pairs, and the client to store these in a hash table. This lets us send updates from one server to a set of clients using the classic pub-sub model[figure].\n\nAn update is either a new key-value pair, a modified value for an existing key, or a deleted key. We can assume for now that the whole store fits in memory and that applications access it by key, such as by using a hash table or dictionary. For larger stores and some kind of persistence we'd probably store the state in a database, but that's not relevant here.\n\nThis is the server:\n\n[[code type=\"example\" title=\"Clone server, Model One\" name=\"clonesrv1\"]]\n[[/code]]\n\nAnd here is the client:\n\n[[code type=\"example\" title=\"Clone client, Model One\" name=\"clonecli1\"]]\n[[/code]]\n\n[[code type=\"textdiagram\" title=\"Publishing State Updates\"]]\n          #-----------#\n          |  Server   |\n          +-----------+\n          |    PUB    |\n          '-----+-----'\n                |\n                |\n                |updates\n    .-----------+-----------.\n    |           |           |\n    v           v           v\n.--------.  .--------.  .--------.\n|  SUB   |  |  SUB   |  |  SUB   |\n+--------+  +--------+  +--------+\n| Client |  | Client |  | Client |\n#--------#  #--------#  #--------#\n[[/code]]\n\nHere are some things to note about this first model:\n\n* All the hard work is done in a {{kvmsg}} class. This class works with key-value message objects, which are multipart ZeroMQ messages structured as three frames: a key (a ZeroMQ string), a sequence number (64-bit value, in network byte order), and a binary body (holds everything else).\n\n* The server generates messages with a randomized 4-digit key, which lets us simulate a large but not enormous hash table (10K entries).\n\n* We don't implement deletions in this version: all messages are inserts or updates.\n\n* The server does a 200 millisecond pause after binding its socket. This is to prevent //slow joiner syndrome//, where the subscriber loses messages as it connects to the server's socket. We'll remove that in later versions of the Clone code.\n\n* We'll use the terms //publisher// and //subscriber// in the code to refer to sockets. This will help later when we have multiple sockets doing different things.\n\nHere is the {{kvmsg}} class, in the simplest form that works for now:\n\n[[code type=\"example\" title=\"Key-value message class\" name=\"kvsimple\"]] [[/code]]\n[[/code]]\n\nLater, we'll make a more sophisticated {{kvmsg}} class that will work in real applications.\n\nBoth the server and client maintain hash tables, but this first model only works properly if we start all clients before the server and the clients never crash. That's very artificial.\n\n+++ Getting an Out-of-Band Snapshot\n\nSo now we have our second problem: how to deal with late-joining clients or clients that crash and then restart.\n\nIn order to allow a late (or recovering) client to catch up with a server, it has to get a snapshot of the server's state. Just as we've reduced \"message\" to mean \"a sequenced key-value pair\", we can reduce \"state\" to mean \"a hash table\". To get the server state, a client opens a DEALER socket and asks for it explicitly[figure].\n\nTo make this work, we have to solve a problem of timing. Getting a state snapshot will take a certain time, possibly fairly long if the snapshot is large. We need to correctly apply updates to the snapshot. But the server won't know when to start sending us updates. One way would be to start subscribing, get a first update, and then ask for \"state for update N\". This would require the server storing one snapshot for each update, which isn't practical.\n\n[[code type=\"textdiagram\" title=\"State Replication\"]]\n                   #--------------#\n                   |   Server     |\n                   +-----+--------+\n                   | PUB | ROUTER |\n                   '--+--+--------'\n                      |      ^\n                      |      | state request\n                      |      '------------------.\n                      | updates                 |\n   .------------------+-------------------.     |\n   |                  |                   |     |\n   |                  |                   |     |\n   v                  v                   v     |\n.-----+--------.   .-----+--------.   .-----+---+----.\n| SUB | DEALER |   | SUB | DEALER |   | SUB | DEALER |\n+-----+--------+   +-----+--------+   +-----+--------+\n|   Client     |   |   Client     |   |   Client     |\n#--------------#   #--------------#   #--------------#\n[[/code]]\n\nSo we will do the synchronization in the client, as follows:\n\n* The client first subscribes to updates and then makes a state request. This guarantees that the state is going to be newer than the oldest update it has.\n\n* The client waits for the server to reply with state, and meanwhile queues all updates. It does this simply by not reading them: ZeroMQ keeps them queued on the socket queue.\n\n* When the client receives its state update, it begins once again to read updates. However, it discards any updates that are older than the state update. So if the state update includes updates up to 200, the client will discard updates up to 201.\n\n* The client then applies updates to its own state snapshot.\n\nIt's a simple model that exploits ZeroMQ's own internal queues. Here's the server:\n\n[[code type=\"example\" title=\"Clone server, Model Two\" name=\"clonesrv2\"]]\n[[/code]]\n\nAnd here is the client:\n\n[[code type=\"example\" title=\"Clone client, Model Two\" name=\"clonecli2\"]]\n[[/code]]\n\nHere are some things to note about these two programs:\n\n* The server uses two tasks. One thread produces the updates (randomly) and sends these to the main PUB socket, while the other thread handles state requests on the ROUTER socket. The two communicate across PAIR sockets over an {{inproc:@<//>@}} connection.\n\n* The client is really simple. In C, it consists of about fifty lines of code. A lot of the heavy lifting is done in the {{kvmsg}} class. Even so, the basic Clone pattern is easier to implement than it seemed at first.\n\n* We don't use anything fancy for serializing the state. The hash table holds a set of {{kvmsg}} objects, and the server sends these, as a batch of messages, to the client requesting state. If multiple clients request state at once, each will get a different snapshot.\n\n* We assume that the client has exactly one server to talk to. The server must be running; we do not try to solve the question of what happens if the server crashes.\n\nRight now, these two programs don't do anything real, but they correctly synchronize state. It's a neat example of how to mix different patterns: PAIR-PAIR, PUB-SUB, and ROUTER-DEALER.\n\n+++ Republishing Updates from Clients\n\nIn our second model, changes to the key-value store came from the server itself. This is a centralized model that is useful, for example if we have a central configuration file we want to distribute, with local caching on each node. A more interesting model takes updates from clients, not the server. The server thus becomes a stateless broker. This gives us some benefits:\n\n* We're less worried about the reliability of the server. If it crashes, we can start a new instance and feed it new values.\n\n* We can use the key-value store to share knowledge between active peers.\n\nTo send updates from clients back to the server, we could use a variety of socket patterns. The simplest plausible solution is a PUSH-PULL combination[figure].\n\nWhy don't we allow clients to publish updates directly to each other? While this would reduce latency, it would remove the guarantee of consistency. You can't get consistent shared state if you allow the order of updates to change depending on who receives them. Say we have two clients, changing different keys. This will work fine. But if the two clients try to change the same key at roughly the same time, they'll end up with different notions of its value.\n\nThere are a few strategies for obtaining consistency when changes happen in multiple places at once. We'll use the approach of centralizing all change. No matter the precise timing of the changes that clients make, they are all pushed through the server, which enforces a single sequence according to the order in which it gets updates.\n\n[[code type=\"textdiagram\" title=\"Republishing Updates\"]]\n               #----------------------#\n               |        Server        |\n               +------+--------+------+\n               | PUB  | ROUTER | PULL |\n               '--+---+--------+------'\n                  |       ^        ^\n                  |       |        | state update\n                  |       |        '----------.\n                  |       | state request     |\n                  |       '-----------.       |\n                  | updates           |       |\n   .--------------+------------.      |       |\n   |                           |      |       |\n   |      ^       ^            |      |       |\n   v      |       |            v      |       |\n.-----+---+----+--+---.     .-----+---+----+--+---.\n| SUB | DEALER | PUSH |     | SUB | DEALER | PUSH |\n+-----+--------+------+     +-----+--------+------+\n|       Client        |     |       Client        |\n#---------------------#     #---------------------#\n[[/code]]\n\nBy mediating all changes, the server can also add a unique sequence number to all updates. With unique sequencing, clients can detect the nastier failures, including network congestion and queue overflow. If a client discovers that its incoming message stream has a hole, it can take action. It seems sensible that the client contact the server and ask for the missing messages, but in practice that isn't useful. If there are holes, they're caused by network stress, and adding more stress to the network will make things worse. All the client can do is warn its users that it is \"unable to continue\", stop, and not restart until someone has manually checked the cause of the problem.\n\nWe'll now generate state updates in the client. Here's the server:\n\n[[code type=\"example\" title=\"Clone server, Model Three\" name=\"clonesrv3\"]]\n[[/code]]\n\nAnd here is the client:\n\n[[code type=\"example\" title=\"Clone client, Model Three\" name=\"clonecli3\"]]\n[[/code]]\n\nHere are some things to note about this third design:\n\n* The server has collapsed to a single task. It manages a PULL socket for incoming updates, a ROUTER socket for state requests, and a PUB socket for outgoing updates.\n\n* The client uses a simple tickless timer to send a random update to the server once a second. In a real implementation, we would drive updates from application code.\n\n+++ Working with Subtrees\n\nAs we grow the number of clients, the size of our shared store will also grow. It stops being reasonable to send everything to every client. This is the classic story with pub-sub: when you have a very small number of clients, you can send every message to all clients. As you grow the architecture, this becomes inefficient. Clients specialize in different areas.\n\nSo even when working with a shared store, some clients will want to work only with a part of that store, which we call a //subtree//. The client has to request the subtree when it makes a state request, and it must specify the same subtree when it subscribes to updates.\n\nThere are a couple of common syntaxes for trees. One is the //path hierarchy//, and another is the //topic tree//. These look like this:\n\n* Path hierarchy: {{/some/list/of/paths}}\n* Topic tree: {{some.list.of.topics}}\n\nWe'll use the path hierarchy, and extend our client and server so that a client can work with a single subtree. Once you see how to work with a single subtree you'll be able to extend this yourself to handle multiple subtrees, if your use case demands it.\n\nHere's the server implementing subtrees, a small variation on Model Three:\n\n[[code type=\"example\" title=\"Clone server, Model Four\" name=\"clonesrv4\"]]\n[[/code]]\n\nAnd here is the corresponding client:\n\n[[code type=\"example\" title=\"Clone client, Model Four\" name=\"clonecli4\"]]\n[[/code]]\n\n+++ Ephemeral Values\n\nAn ephemeral value is one that expires automatically unless regularly refreshed. If you think of Clone being used for a registration service, then ephemeral values would let you do dynamic values. A node joins the network, publishes its address, and refreshes this regularly. If the node dies, its address eventually gets removed.\n\nThe usual abstraction for ephemeral values is to attach them to a //session//, and delete them when the session ends. In Clone, sessions would be defined by clients, and would end if the client died. A simpler alternative is to attach a //time to live// (TTL) to ephemeral values, which the server uses to expire values that haven't been refreshed in time.\n\nA good design principle that I use whenever possible is to //not invent concepts that are not absolutely essential//. If we have very large numbers of ephemeral values, sessions will offer better performance. If we use a handful of ephemeral values, it's fine to set a TTL on each one. If we use masses of ephemeral values, it's more efficient to attach them to sessions and expire them in bulk. This isn't a problem we face at this stage, and may never face, so sessions go out the window.\n\nNow we will implement ephemeral values. First, we need a way to encode the TTL in the key-value message. We could add a frame. The problem with using ZeroMQ frames for properties is that each time we want to add a new property, we have to change the message structure. It breaks compatibility. So let's add a properties frame to the message, and write the code to let us get and put property values.\n\nNext, we need a way to say, \"delete this value\". Up until now, servers and clients have always blindly inserted or updated new values into their hash table. We'll say that if the value is empty, that means \"delete this key\".\n\nHere's a more complete version of the {{kvmsg}} class, which implements the properties frame (and adds a UUID frame, which we'll need later on). It also handles empty values by deleting the key from the hash, if necessary:\n\n[[code type=\"example\" title=\"Key-value message class: full\" name=\"kvmsg\"]]\n[[/code]]\n\nThe Model Five client is almost identical to Model Four. It uses the full {{kvmsg}} class now, and sets a randomized {{ttl}} property (measured in seconds) on each message:\n\n[[code type=\"fragment\" name=\"kvsetttl\"]]\nkvmsg_set_prop (kvmsg, \"ttl\", \"%d\", randof (30));\n[[/code]]\n\n+++ Using a Reactor\n\nUntil now, we have used a poll loop in the server. In this next model of the server, we switch to using a reactor. In C, we use CZMQ's {{zloop}} class. Using a reactor makes the code more verbose, but easier to understand and build out because each piece of the server is handled by a separate reactor handler.\n\nWe use a single thread and pass a server object around to the reactor handlers. We could have organized the server as multiple threads, each handling one socket or timer, but that works better when threads don't have to share data. In this case all work is centered around the server's hashmap, so one thread is simpler.\n\nThere are three reactor handlers:\n\n* One to handle snapshot requests coming on the ROUTER socket;\n* One to handle incoming updates from clients, coming on the PULL socket;\n* One to expire ephemeral values that have passed their TTL.\n\n[[code type=\"example\" title=\"Clone server, Model Five\" name=\"clonesrv5\"]]\n[[/code]]\n\n+++ Adding the Binary Star Pattern for Reliability\n\nThe Clone models we've explored up to now have been relatively simple. Now we're going to get into unpleasantly complex territory, which has me getting up for another espresso. You should appreciate that making \"reliable\" messaging is complex enough that you always need to ask, \"Do we actually need this?\" before jumping into it. If you can get away with unreliable or with \"good enough\" reliability, you can make a huge win in terms of cost and complexity. Sure, you may lose some data now and then. It is often a good trade-off. Having said, that, and... sips... because the espresso is really good, let's jump in.\n\nAs you play with the last model, you'll stop and restart the server. It might look like it recovers, but of course it's applying updates to an empty state instead of the proper current state. Any new client joining the network will only get the latest updates instead of the full historical record.\n\nWhat we want is a way for the server to recover from being killed, or crashing. We also need to provide backup in case the server is out of commission for any length of time. When someone asks for \"reliability\", ask them to list the failures they want to handle. In our case, these are:\n\n* The server process crashes and is automatically or manually restarted. The process loses its state and has to get it back from somewhere.\n\n* The server machine dies and is offline for a significant time. Clients have to switch to an alternate server somewhere.\n\n* The server process or machine gets disconnected from the network, e.g., a switch dies or a datacenter gets knocked out. It may come back at some point, but in the meantime clients need an alternate server.\n\nOur first step is to add a second server. We can use the Binary Star pattern from [#reliable-request-reply] to organize these into primary and backup. Binary Star is a reactor, so it's useful that we already refactored the last server model into a reactor style.\n\nWe need to ensure that updates are not lost if the primary server crashes. The simplest technique is to send them to both servers. The backup server can then act as a client, and keep its state synchronized by receiving updates as all clients do. It'll also get new updates from clients. It can't yet store these in its hash table, but it can hold onto them for a while.\n\nSo, Model Six introduces the following changes over Model Five:\n\n* We use a pub-sub flow instead of a push-pull flow for client updates sent to the servers. This takes care of fanning out the updates to both servers. Otherwise we'd have to use two DEALER sockets.\n\n* We add heartbeats to server updates (to clients), so that a client can detect when the primary server has died. It can then switch over to the backup server.\n\n* We connect the two servers using the Binary Star {{bstar}} reactor class. Binary Star relies on the clients to vote by making an explicit request to the server they consider active. We'll use snapshot requests as the voting mechanism.\n\n* We make all update messages uniquely identifiable by adding a UUID field. The client generates this, and the server propagates it back on republished updates.\n\n* The passive server keeps a \"pending list\" of updates that it has received from clients, but not yet from the active server; or updates it's received from the active server, but not yet from the clients. The list is ordered from oldest to newest, so that it is easy to remove updates off the head.\n\n[[code type=\"textdiagram\" title=\"Clone Client Finite State Machine\"]]\n #-----------#\n |           |<----------------------.\n |  Initial  |<-------------------.  |\n |           |                    |  |\n #-----+-----#                    |  |\nRequest| snapshot                 |  |\n       |   .-------------------.  |  |\n       |   |                   |  |  |\n       v   v                   |  |  |\n #-----------#                 |  |  |\n |           +- INPUT----------'  |  |\n |  Syncing  |  Store snapshot    |  |\n |           +- SILENCE-----------'  |\n #-----+-----#  Failover to next     |\n     KTHXBAI                         |\n       |   .-------------------.     |\n       |   |                   |     |\n       v   v                   |     |\n #-----------#                 |     |\n |           +- INPUT----------'     |\n |  Active   |  Store update         |\n |           +- SILENCE--------------'\n #-----------#  Failover to next\n[[/code]]\n\nIt's useful to design the client logic as a finite state machine. The client cycles through three states:\n\n* The client opens and connects its sockets, and then requests a snapshot from the first server. To avoid request storms, it will ask any given server only twice. One request might get lost, which would be bad luck. Two getting lost would be carelessness.\n\n* The client waits for a reply (snapshot data) from the current server, and if it gets it, it stores it. If there is no reply within some timeout, it fails over to the next server.\n\n* When the client has gotten its snapshot, it waits for and processes updates. Again, if it doesn't hear anything from the server within some timeout, it fails over to the next server.\n\nThe client loops forever. It's quite likely during startup or failover that some clients may be trying to talk to the primary server while others are trying to talk to the backup server. The Binary Star state machine handles this[figure], hopefully accurately. It's hard to prove software correct; instead we hammer it until we can't prove it wrong.\n\nFailover happens as follows:\n\n* The client detects that primary server is no longer sending heartbeats, and concludes that it has died. The client connects to the backup server and requests a new state snapshot.\n\n* The backup server starts to receive snapshot requests from clients, and detects that primary server has gone, so it takes over as primary.\n\n* The backup server applies its pending list to its own hash table, and then starts to process state snapshot requests.\n\nWhen the primary server comes back online, it will:\n\n* Start up as passive server, and connect to the backup server as a Clone client.\n\n* Start to receive updates from clients, via its SUB socket.\n\nWe make a few assumptions:\n\n* At least one server will keep running. If both servers crash, we lose all server state and there's no way to recover it.\n\n* Multiple clients do not update the same hash keys at the same time. Client updates will arrive at the two servers in a different order. Therefore, the backup server may apply updates from its pending list in a different order than the primary server would or did. Updates from one client will always arrive in the same order on both servers, so that is safe.\n\nThus the architecture for our high-availability server pair using the Binary Star pattern has two servers and a set of clients that talk to both servers[figure].\n\n[[code type=\"textdiagram\" title=\"High-availability Clone Server Pair\"]]\n#--------------------#                 #--------------------#\n|                    |      Binary     |                    |\n|       Primary      |<--------------->|       Backup       |\n|                    |       Star      |                    |\n+-----+--------+-----+                 +-----+--------+-----+\n| PUB | ROUTER | SUB |                 | PUB | ROUTER | SUB |\n'--+--+--------+-----'                 '-----+--------+-----'\n   |       ^      ^                                      ^\n   |       |      |                                      |\n   |       |      |                                      |\n   |       |      +--------------------------------------'\n   |       |      |\n   v       |      |\n.-----+----+---+--+--.\n| SUB | DEALER | PUB |\n+-----+--------+-----+\n|       Client       |\n#--------------------#\n[[/code]]\n\nHere is the sixth and last model of the Clone server:\n\n[[code type=\"example\" title=\"Clone server, Model Six\" name=\"clonesrv6\"]]\n[[/code]]\n\nThis model is only a few hundred lines of code, but it took quite a while to get working. To be accurate, building Model Six took about a full week of \"Sweet god, this is just too complex for an example\" hacking. We've assembled pretty much everything and the kitchen sink into this small application. We have failover, ephemeral values, subtrees, and so on. What surprised me was that the up-front design was pretty accurate. Still the details of writing and debugging so many socket flows is quite challenging.\n\nThe reactor-based design removes a lot of the grunt work from the code, and what remains is simpler and easier to understand. We reuse the bstar reactor from [#reliable-request-reply]. The whole server runs as one thread, so there's no inter-thread weirdness going on--just a structure pointer ({{self}}) passed around to all handlers, which can do their thing happily. One nice side effect of using reactors is that the code, being less tightly integrated into a poll loop, is much easier to reuse. Large chunks of Model Six are taken from Model Five.\n\nI built it piece by piece, and got each piece working //properly// before going onto the next one. Because there are four or five main socket flows, that meant quite a lot of debugging and testing. I debugged just by dumping messages to the console. Don't use classic debuggers to step through ZeroMQ applications; you need to see the message flows to make any sense of what is going on.\n\nFor testing, I always try to use Valgrind, which catches memory leaks and invalid memory accesses. In C, this is a major concern, as you can't delegate to a garbage collector. Using proper and consistent abstractions like kvmsg and CZMQ helps enormously.\n\n+++ The Clustered Hashmap Protocol\n\nWhile the server is pretty much a mashup of the previous model plus the Binary Star pattern, the client is quite a lot more complex. But before we get to that, let's look at the final protocol. I've written this up as a specification on the ZeroMQ RFC website as the [http://rfc.zeromq.org/spec:12 Clustered Hashmap Protocol].\n\nRoughly, there are two ways to design a complex protocol such as this one. One way is to separate each flow into its own set of sockets. This is the approach we used here. The advantage is that each flow is simple and clean. The disadvantage is that managing multiple socket flows at once can be quite complex. Using a reactor makes it simpler, but still, it makes a lot of moving pieces that have to fit together correctly.\n\nThe second way to make such a protocol is to use a single socket pair for everything. In this case, I'd have used ROUTER for the server and DEALER for the clients, and then done everything over that connection. It makes for a more complex protocol but at least the complexity is all in one place. In [#advanced-architecture] we'll look at an example of a protocol done over a ROUTER-DEALER combination.\n\nLet's take a look at the CHP specification. Note that \"SHOULD\", \"MUST\" and \"MAY\" are key words we use in protocol specifications to indicate requirement levels.\n\n**Goals**\n\nCHP is meant to provide a basis for reliable pub-sub across a cluster of clients connected over a ZeroMQ network. It defines a \"hashmap\" abstraction consisting of key-value pairs. Any client can modify any key-value pair at any time, and changes are propagated to all clients. A client can join the network at any time.\n\n**Architecture**\n\nCHP connects a set of client applications and a set of servers. Clients connect to the server. Clients do not see each other. Clients can come and go arbitrarily.\n\n**Ports and Connections**\n\nThe server MUST open three ports as follows:\n\n* A SNAPSHOT port (ZeroMQ ROUTER socket) at port number P.\n* A PUBLISHER port (ZeroMQ PUB socket) at port number P + 1.\n* A COLLECTOR port (ZeroMQ SUB socket) at port number P + 2.\n\nThe client SHOULD open at least two connections:\n\n* A SNAPSHOT connection (ZeroMQ DEALER socket) to port number P.\n* A SUBSCRIBER connection (ZeroMQ SUB socket) to port number P + 1.\n\nThe client MAY open a third connection, if it wants to update the hashmap:\n\n* A PUBLISHER connection (ZeroMQ PUB socket) to port number P + 2.\n\nThis extra frame is not shown in the commands explained below.\n\n**State Synchronization**\n\nThe client MUST start by sending a ICANHAZ command to its snapshot connection. This command consists of two frames as follows:\n\n[[code]]\nICANHAZ command\n-----------------------------------\nFrame 0: \"ICANHAZ?\"\nFrame 1: subtree specification\n[[/code]]\n\nBoth frames are ZeroMQ strings. The subtree specification MAY be empty. If not empty, it consists of a slash followed by one or more path segments, ending in a slash.\n\nThe server MUST respond to a ICANHAZ command by sending zero or more KVSYNC commands to its snapshot port, followed with a KTHXBAI command. The server MUST prefix each command with the identity of the client, as provided by ZeroMQ with the ICANHAZ command. The KVSYNC command specifies a single key-value pair as follows:\n\n[[code]]\nKVSYNC command\n-----------------------------------\nFrame 0: key, as ZeroMQ string\nFrame 1: sequence number, 8 bytes in network order\nFrame 2: <empty>\nFrame 3: <empty>\nFrame 4: value, as blob\n[[/code]]\n\nThe sequence number has no significance and may be zero.\n\nThe KTHXBAI command takes this form:\n\n[[code]]\nKTHXBAI command\n-----------------------------------\nFrame 0: \"KTHXBAI\"\nFrame 1: sequence number, 8 bytes in network order\nFrame 2: <empty>\nFrame 3: <empty>\nFrame 4: subtree specification\n[[/code]]\n\nThe sequence number MUST be the highest sequence number of the KVSYNC commands previously sent.\n\nWhen the client has received a KTHXBAI command, it SHOULD start to receive messages from its subscriber connection and apply them.\n\n**Server-to-Client Updates**\n\nWhen the server has an update for its hashmap it MUST broadcast this on its publisher socket as a KVPUB command. The KVPUB command has this form:\n\n[[code]]\nKVPUB command\n-----------------------------------\nFrame 0: key, as ZeroMQ string\nFrame 1: sequence number, 8 bytes in network order\nFrame 2: UUID, 16 bytes\nFrame 3: properties, as ZeroMQ string\nFrame 4: value, as blob\n[[/code]]\n\nThe sequence number MUST be strictly incremental. The client MUST discard any KVPUB commands whose sequence numbers are not strictly greater than the last KTHXBAI or KVPUB command received.\n\nThe UUID is optional and frame 2 MAY be empty (size zero). The properties field is formatted as zero or more instances of \"name=value\" followed by a newline character. If the key-value pair has no properties, the properties field is empty.\n\nIf the value is empty, the client SHOULD delete its key-value entry with the specified key.\n\nIn the absence of other updates the server SHOULD send a HUGZ command at regular intervals, e.g., once per second. The HUGZ command has this format:\n\n[[code]]\nHUGZ command\n-----------------------------------\nFrame 0: \"HUGZ\"\nFrame 1: 00000000\nFrame 2: <empty>\nFrame 3: <empty>\nFrame 4: <empty>\n[[/code]]\n\nThe client MAY treat the absence of HUGZ as an indicator that the server has crashed (see Reliability below).\n\n**Client-to-Server Updates**\n\nWhen the client has an update for its hashmap, it MAY send this to the server via its publisher connection as a KVSET command. The KVSET command has this form:\n\n[[code]]\nKVSET command\n-----------------------------------\nFrame 0: key, as ZeroMQ string\nFrame 1: sequence number, 8 bytes in network order\nFrame 2: UUID, 16 bytes\nFrame 3: properties, as ZeroMQ string\nFrame 4: value, as blob\n[[/code]]\n\nThe sequence number has no significance and may be zero. The UUID SHOULD be a universally unique identifier, if a reliable server architecture is used.\n\nIf the value is empty, the server MUST delete its key-value entry with the specified key.\n\nThe server SHOULD accept the following properties:\n\n* {{ttl}}: specifies a time-to-live in seconds. If the KVSET command has a {{ttl}} property, the server SHOULD delete the key-value pair and broadcast a KVPUB with an empty value in order to delete this from all clients when the TTL has expired.\n\n**Reliability**\n\nCHP may be used in a dual-server configuration where a backup server takes over if the primary server fails. CHP does not specify the mechanisms used for this failover but the Binary Star pattern may be helpful.\n\nTo assist server reliability, the client MAY:\n\n* Set a UUID in every KVSET command.\n* Detect the lack of HUGZ over a time period and use this as an indicator that the current server has failed.\n* Connect to a backup server and re-request a state synchronization.\n\n**Scalability and Performance**\n\nCHP is designed to be scalable to large numbers (thousands) of clients, limited only by system resources on the broker. Because all updates pass through a single server, the overall throughput will be limited to some millions of updates per second at peak, and probably less.\n\n**Security**\n\nCHP does not implement any authentication, access control, or encryption mechanisms and should not be used in any deployment where these are required.\n\n+++ Building a Multithreaded Stack and API\n\nThe client stack we've used so far isn't smart enough to handle this protocol properly. As soon as we start doing heartbeats, we need a client stack that can run in a background thread. In the Freelance pattern at the end of [#reliable-request-reply] we used a multithreaded API but didn't explain it in detail. It turns out that multithreaded APIs are quite useful when you start to make more complex ZeroMQ protocols like CHP.\n\n[[code type=\"textdiagram\" title=\"Multithreaded API\"]]\n         #--------------#\n         |   Calling    |\n         | Application  |\n.------- +--------------+ --------.\n:        |  Frontend    |         :\n:        |   Object     |         :\n:        +--------------+         :\n:        |    PAIR      |         :\n:        '------+-------'         :\n:               |                 :\n:               |                 :\n:               v                 :\n:        .--------------.         :\n:        |    PAIR      |         :\n:        +--------------+         :\n:        |   Backend    |         :\n:        |    Agent     |         :\n:        +--------+-----+         :\n:        | DEALER | SUB |         :\n:        #--------+-----#         :\n:                                 :\n'---------------------------------'\n            Clone class\n[[/code]]\n\nIf you make a nontrivial protocol and you expect applications to implement it properly, most developers will get it wrong most of the time. You're going to be left with a lot of unhappy people complaining that your protocol is too complex, too fragile, and too hard to use. Whereas if you give them a simple API to call, you have some chance of them buying in.\n\nOur multithreaded API consists of a frontend object and a background agent, connected by two PAIR sockets[figure]. Connecting two PAIR sockets like this is so useful that your high-level binding should probably do what CZMQ does, which is package a \"create new thread with a pipe that I can use to send messages to it\" method.\n\nThe multithreaded APIs that we see in this book all take the same form:\n\n* The constructor for the object ({{clone_new}}) creates a context and starts a background thread connected with a pipe. It holds onto one end of the pipe so it can send commands to the background thread.\n\n* The background thread starts an //agent// that is essentially a {{zmq_poll}} loop reading from the pipe socket and any other sockets (here, the DEALER and SUB sockets).\n\n* The main application thread and the background thread now communicate only via ZeroMQ messages. By convention, the frontend sends string commands so that each method on the class turns into a message sent to the backend agent, like this:\n\n[[code type=\"fragment\" name=\"connect-command\"]]\nvoid\nclone_connect (clone_t *self, char *address, char *service)\n{\n    assert (self);\n    zmsg_t *msg = zmsg_new ();\n    zmsg_addstr (msg, \"CONNECT\");\n    zmsg_addstr (msg, address);\n    zmsg_addstr (msg, service);\n    zmsg_send (&msg, self->pipe);\n}\n[[/code]]\n\n* If the method needs a return code, it can wait for a reply message from the agent.\n\n* If the agent needs to send asynchronous events back to the frontend, we add a {{recv}} method to the class, which waits for messages on the frontend pipe.\n\n* We may want to expose the frontend pipe socket handle to allow the class to be integrated into further poll loops. Otherwise any {{recv}} method would block the application.\n\nThe clone class has the same structure as the {{flcliapi}} class from [#reliable-request-reply] and adds the logic from the last model of the Clone client. Without ZeroMQ, this kind of multithreaded API design would be weeks of really hard work. With ZeroMQ, it was a day or two of work.\n\nThe actual API methods for the clone class are quite simple:\n\n[[code type=\"fragment\" name=\"clone-methods\"]]\n//  Create a new clone class instance\nclone_t *\n    clone_new (void);\n\n//  Destroy a clone class instance\nvoid\n    clone_destroy (clone_t **self_p);\n\n//  Define the subtree, if any, for this clone class\nvoid\n    clone_subtree (clone_t *self, char *subtree);\n\n//  Connect the clone class to one server\nvoid\n    clone_connect (clone_t *self, char *address, char *service);\n\n//  Set a value in the shared hashmap\nvoid\n    clone_set (clone_t *self, char *key, char *value, int ttl);\n\n//  Get a value from the shared hashmap\nchar *\n    clone_get (clone_t *self, char *key);\n[[/code]]\n\nSo here is Model Six of the clone client, which has now become just a thin shell using the clone class:\n\n[[code type=\"example\" title=\"Clone client, Model Six\" name=\"clonecli6\"]]\n[[/code]]\n\nNote the connect method, which specifies one server endpoint. Under the hood, we're in fact talking to three ports. However, as the CHP protocol says, the three ports are on consecutive port numbers:\n\n* The server state router (ROUTER) is at port P.\n* The server updates publisher (PUB) is at port P + 1.\n* The server updates subscriber (SUB) is at port P + 2.\n\nSo we can fold the three connections into one logical operation (which we implement as three separate ZeroMQ connect calls).\n\nLet's end with the source code for the clone stack. This is a complex piece of code, but easier to understand when you break it into the frontend object class and the backend agent. The frontend sends string commands (\"SUBTREE\", \"CONNECT\", \"SET\", \"GET\") to the agent, which handles these commands as well as talking to the server(s). Here is the agent's logic:\n\n# Start up by getting a snapshot from the first server\n# When we get a snapshot switch to reading from the subscriber socket.\n# If we don't get a snapshot then fail over to the second server.\n# Poll on the pipe and the subscriber socket.\n# If we got input on the pipe, handle the control message from the frontend object.\n# If we got input on the subscriber, store or apply the update.\n# If we didn't get anything from the server within a certain time, fail over.\n# Repeat until the process is interrupted by Ctrl-C.\n\nAnd here is the actual clone class implementation:\n\n[[code type=\"example\" title=\"Clone class\" name=\"clone\"]]\n[[/code]]\n"
        },
        {
          "name": "chapter6.txt",
          "type": "blob",
          "size": 119.3505859375,
          "content": ".output chapter6.wd\n.bookmark the-community\n+ The ZeroMQ Community\n\nPeople sometimes ask me what's so special about ZeroMQ. My standard answer is that ZeroMQ is arguably the best answer we have to the vexing question of \"How do we make the distributed software that the 21st century demands?\" But more than that, ZeroMQ is special because of its community. This is ultimately what separates the wolves from the sheep.\n\nThere are three main open source patterns. The first is the large firm dumping code to break the market for others. This is the Apache Foundation model. The second is tiny teams or small firms building their dream. This is the most common open source model, which can be very successful commercially. The last is aggressive and diverse communities that swarm over a problem landscape. This is the Linux model, and the one to which we aspire with ZeroMQ.\n\nIt's hard to overemphasize the power and persistence of a working open source community. There really does not seem to be a better way of making software for the long term. Not only does the community choose the best problems to solve, it solves them minimally, carefully, and it then looks after these answers for years, decades, until they're no longer relevant, and then it quietly puts them away.\n\nTo really benefit from ZeroMQ, you need to understand the community. At some point down the road you'll want to submit a patch, an issue, or an add-on. You might want to ask someone for help. You will probably want to bet a part of your business on ZeroMQ, and when I tell you that the community is much, much more important than the company that backs the product, even though I'm CEO of that company, this should be significant.\n\nIn this chapter I'm going to look at our community from several angles and conclude by explaining in detail our contract for collaboration, which [http://rfc.zeromq.org/spec:22 we call \"C4\"]. You should find the discussion useful for your own work. We've also adapted the ZeroMQ C4 process for closed source projects with good success.\n\nWe'll cover:\n\n* The rough structure of ZeroMQ as a set of projects\n* What \"software architecture\" is really about\n* Why we use the LGPL and not the BSD license\n* How we designed and grew the ZeroMQ community\n* The business that backs ZeroMQ\n* Who owns the ZeroMQ source code\n* How to make and submit a patch to ZeroMQ\n* Who controls what patches actually go into ZeroMQ\n* How we guarantee compatibility with old code\n* Why we don't use public git branches\n* Who decides on the ZeroMQ road map\n* A worked example of a change to {{libzmq}}\n\n++ Architecture of the ZeroMQ Community\n\nYou know that ZeroMQ is an LGPL-licensed project. In fact it's a collection of projects, built around the core library, {{libzmq}}. I'll visualize these projects as an expanding galaxy:\n\n* At the core, {{libzmq}} is the ZeroMQ core library. It's written in C++, with a low-level C API. The code is nasty, mainly because it's highly optimized but also because it's written in C++, a language that lends itself to subtle and deep nastiness. Martin Sustrik wrote the bulk of this code. Today it has dozens of people who maintain different parts of it.\n\n* Around {{libzmq}}, there are about 50 //bindings//. These are individual projects that create higher-level APIs for ZeroMQ, or at least map the low-level API into other languages. The bindings vary in quality from experimental to utterly awesome. Probably the most impressive binding is [https://github.com/zeromq/pyzmq PyZMQ], which was one of the first community projects on top of ZeroMQ. If you are a binding author, you should really study PyZMQ and aspire to making your code and community as great.\n\n* A lot of languages have multiple bindings (Erlang, Ruby, C#, at least) written by different people over time, or taking varying approaches. We don't regulate these in any way. There are no \"official\" bindings. You vote by using one or the other, contributing to it, or ignoring it.\n\n* There are a series of reimplementations of {{libzmq}}, starting with JeroMQ, a full Java translation of the library, which is now the basis for NetMQ, a C# stack. These native stacks offer similar or identical APIs, and speak the same protocol (ZMTP) as {{libzmq}}.\n\n* On top of the bindings are a lot of projects that use ZeroMQ or build on it. See the \"Labs\" page on the wiki for a long list of projects and proto-projects that use ZeroMQ in some way. There are frameworks, web servers like Mongrel2, brokers like Majordomo, and enterprise open source tools like Storm.\n\n{{Libzmq}}, most of the bindings, and some of the outer projects sit in the [https://github.com/organizations/zeromq ZeroMQ community \"organization\"] on GitHub. This organization is \"run\" by a group consisting of the most senior binding authors. There's very little to run as it's almost all self-managing and there's zero conflict these days.\n\niMatix, my firm, plays a specific role in the community. We own the trademarks and enforce them discretely in order to make sure that if you download a package calling itself \"ZeroMQ\", you can trust what you are getting. People have on rare occasion tried to hijack the name, maybe believing that \"free software\" means there is no property at stake and no one willing to defend it. One thing you'll understand from this chapter is how seriously we take the process behind our software (and I mean \"us\" as a community, not a company). iMatix backs the community by enforcing that process on anything calling itself \"ZeroMQ\" or \"ZeroMQ\". We also put money and time into the software and packaging for reasons I'll explain later.\n\nIt is not a charity exercise. ZeroMQ is a for-profit project, and a very profitable one. The profits are widely distributed among all those who invest in it. It's really that simple: take the time to become an expert in ZeroMQ, or build something useful on top of ZeroMQ, and you'll find your value as an individual, or team, or company increasing. iMatix enjoys the same benefits as everyone else in the community. It's win-win to everyone except our competitors, who find themselves facing a threat they can't beat and can't really escape. ZeroMQ dominates the future world of massively distributed software.\n\nMy firm doesn't just have the community's back--we also built the community. This was deliberate work; in the original ZeroMQ white paper from 2007, there were two projects. One was technical, how to make a better messaging system. The second was how to build a community that could take the software to dominant success. Software dies, but community survives.\n\n++ How to Make Really Large Architectures\n\nThere are, it has been said (at least by people reading this sentence out loud), two ways to make really large-scale software. Option One is to throw massive amounts of money and problems at empires of smart people, and hope that what emerges is not yet another career killer. If you're very lucky and are building on lots of experience, have kept your teams solid, and are not aiming for technical brilliance, and are furthermore incredibly lucky, it works.\n\nBut gambling with hundreds of millions of others' money isn't for everyone. For the rest of us who want to build large-scale software, there's Option Two, which is open source, and more specifically, //free software//. If you're asking how the choice of software license is relevant to the scale of the software you build, that's the right question.\n\nThe brilliant and visionary Eben Moglen once said, roughly, that a free software license is the contract on which a community builds. When I heard this, about ten years ago, the idea came to me--//Can we deliberately grow free software communities//?\n\nTen years later, the answer is \"yes\", and there is almost a science to it. I say \"almost\" because we don't yet have enough evidence of people doing this deliberately with a documented, reproducible process. It is what I'm trying to do with [http://cultureandempire.com/cande.html#/4/6 Social Architecture]. ZeroMQ came after Wikidot, after the [http://www.digistan.org Digital Standards Organization] (Digistan) and after the [http://www.ffii.org Foundation for a Free Information Infrastructure] (aka the FFII, an NGO that fights against software patents). This all came after a lot of less successful community projects like Xitami and Libero. My main takeaway from a long career of projects of every conceivable format is: if you want to build truly large-scale and long-lasting software, aim to build a free software community.\n\n+++ Psychology of Software Architecture\n\nDirkjan Ochtman pointed me to [http://en.wikipedia.org/wiki/Software_architecture Wikipedia's definition of Software Architecture] as \"the set of structures needed to reason about the system, which comprise software elements, relations among them, and properties of both\". For me this vapid and circular jargon is a good example of how miserably little we understand what actually makes a successful large scale software architecture.\n\nArchitecture is the art and science of making large artificial structures for human use. If there is one thing I've learned and applied successfully in 30 years of making larger and larger software systems, it is this: //software is about people//. Large structures in themselves are meaningless. It's how they function for //human use// that matters. And in software, human use starts with the programmers who make the software itself.\n\nThe core problems in software architecture are driven by human psychology, not technology. There are many ways our psychology affects our work. I could point to the way teams seem to get stupider as they get larger or when they have to work across larger distances. Does that mean the smaller the team, the more effective? How then does a large global community like ZeroMQ manage to work successfully?\n\nThe ZeroMQ community wasn't accidental. It was a deliberate design, my contribution to the early days when the code came out of a cellar in Bratislava. The design was based on my pet science of \"Social Architecture\", which [http://en.wikipedia.org/wiki/Social_architecture Wikipedia defines] as \"the conscious design of an environment that encourages a desired range of social behaviors leading towards some goal or set of goals.\" I define this as more specifically as \"the process, and the product, of planning, designing, and growing an online community.\"\n\nOne of the tenets of Social Architecture is that //how we organize// is more significant than //who we are//. The same group, organized differently, can produce wholly different results. We are like peers in a ZeroMQ network, and our communication patterns have a dramatic impact on our performance. Ordinary people, well connected, can far outperform a team of experts using poor patterns. If you're the architect of a larger ZeroMQ application, you're going to have to help others find the right patterns for working together. Do this right, and your project can succeed. Do it wrong, and your project will fail.\n\nThe two most important psychological elements are that we're really bad at understanding complexity and that we are so good at working together to divide and conquer large problems. We're highly social apes, and kind of smart, but only in the right kind of crowd.\n\nSo here is my short list of the Psychological Elements of Software Architecture:\n\n* **Stupidity**: our mental bandwidth is limited, so we're all stupid at some point. The architecture has to be simple to understand. This is the number one rule: simplicity beats functionality, every single time. If you can't understand an architecture on a cold gray Monday morning before coffee, it is too complex.\n\n* **Selfishness**: we act only out of self-interest, so the architecture must create space and opportunity for selfish acts that benefit the whole. Selfishness is often indirect and subtle. For example, I'll spend hours helping someone else understand something because that could be worth days to me later.\n\n* **Laziness**: we make lots of assumptions, many of which are wrong. We are happiest when we can spend the least effort to get a result or to test an assumption quickly, so the architecture has to make this possible. Specifically, that means it must be simple.\n\n* **Jealousy**: we're jealous of others, which means we'll overcome our stupidity and laziness to prove others wrong and beat them in competition. The architecture thus has to create space for public competition based on fair rules that anyone can understand.\n\n* **Fear**: we're unwilling to take risks, especially if it makes us look stupid. Fear of failure is a major reason people conform and follow the group in mass stupidity. The architecture should make silent experimentation easy and cheap, giving people opportunity for success without punishing failure.\n\n* **Reciprocity**: we'll pay extra in terms of hard work, even money, to punish cheats and enforce fair rules. The architecture should be heavily rule-based, telling people how to work together, but not what to work on.\n\n* **Conformity**: we're happiest to conform, out of fear and laziness, which means if the patterns are good, clearly explained and documented, and fairly enforced, we'll naturally choose the right path every time.\n\n* **Pride**: we're intensely aware of our social status, and we'll work hard to avoid looking stupid or incompetent in public. The architecture has to make sure every piece we make has our name on it, so we'll have sleepless nights stressing about what others will say about our work.\n\n* **Greed**: we're ultimately economic animals (see selfishness), so the architecture has to give us economic incentive to invest in making it happen. Maybe it's polishing our reputation as experts, maybe it's literally making money from some skill or component. It doesn't matter what it is, but there must be economic incentive. Think of architecture as a market place, not an engineering design.\n\nThese strategies work on a large scale but also on a small scale, within an organization or team.\n\n+++ The Importance of Contracts\n\nLet me discuss a contentious but important area, which is what license to choose. I'll say \"BSD\" to cover MIT, X11, BSD, Apache, and similar licenses, and \"GPL\" to cover GPLv3, LGPLv3, and AGPLv3. The significant difference is the obligation to share back any forked versions, which prevents any entity from capturing the software, and thus keeps it \"free\".\n\nA software license isn't technically a contract since you don't sign anything. But broadly, calling it a contract is useful since it takes the obligations of each party, and makes them legally enforceable in court, under copyright law.\n\nYou might ask, why do we need contracts at all to make open source? Surely it's all about decency, goodwill, people working together for selfless motives. Surely the principle of \"less is more\" applies here of all places? Don't more rules mean less freedom? Do we really need lawyers to tell us how to work together? It seems cynical and even counter-productive to force a restrictive set of rules on the happy communes of free and open source software.\n\nBut the truth about human nature is not that pretty. We're not really angels, nor devils, just self-interested winners descended from a billion-year unbroken line of winners. In business, marriage, and collective works, sooner or later, we either stop caring, or we fight and we argue.\n\nPut this another way: a collective work has two extreme outcomes. Either it's a failure, irrelevant, and worthless, in which case every sane person walks away, without a fight. Or, it's a success, relevant, and valuable, in which case we start jockeying for power, control, and often, money.\n\nWhat a well-written contract does is to protect those valuable relationships from conflict. A marriage where the terms of divorce are clearly agreed up-front is much less likely to end in divorce. A business deal where both parties agree how to resolve various classic conflicts--such as one party stealing the others' clients or staff--is much less likely to end in conflict.\n\nSimilarly, a software project that has a well-written contract that defines the terms of breakup clearly is much less likely to end in breakup. The alternative seems to be to immerse the project into a larger organization that can assert pressure on teams to work together (or lose the backing and branding of the organization). This is for example how the Apache Foundation works. In my experience organization building has its own costs, and ends up favoring wealthier participants (who can afford those sometimes huge costs).\n\nIn an open source or free software project, breakup usually takes the form of a fork, where the community splits into two or more groups, each with different visions of the future. During the honeymoon period of a project, which can last years, there's no question of a breakup. It is as a project begins to be worth money, or as the main authors start to burn out, that the goodwill and generosity tends to dry up.\n\nSo when discussing software licenses, for the code you write or the code you use, a little cynicism helps. Ask yourself, not \"which license will attract more contributors?\" because the answer to that lies in the mission statement and contribution process. Ask yourself, \"if this project had a big fight, and split three ways, which license would save us?\" Or, \"if the whole team was bought by a hostile firm that wanted to turn this code into a proprietary product, which license would save us?\"\n\nLong-term survival means enduring the bad times, as well as enjoying the good ones.\n\nWhen BSD projects fork, they cannot easily merge again. Indeed, one-way forking of BSD projects is quite systematic: every time BSD code ends up in a commercial project, this is what's happened. When GPL projects fork, however, re-merging is trivial.\n\nThe GPL's story is relevant here. Though communities of programmers sharing their code openly were already significant by the 1980's, they tended to use minimal licenses that worked as long as no real money got involved. There was an important language stack called Emacs, originally built in Lisp by Richard Stallman. Another programmer, James Gosling (who later gave us Java), rewrote Emacs in C with the help of many contributors, on the assumption that it would be open. Stallman got that code and used it as the basis for his own C version. Gosling then sold the code to a firm which turned around and blocked anyone distributing a competing product. Stallman found this sale of the common work hugely unethical, and began developing a reusable license that would protect communities from this.\n\nWhat eventually emerged was the GNU General Public License, which used traditional copyright to force remixability. It was a neat hack that spread to other domains, for instance the Creative Commons for photography and music. In 2007, we saw version 3 of the license, which was a response to belated attacks from Microsoft and others on the concept. It has become a long and complex document but corporate copyright lawyers have become familiar with it and in my experience, few companies mind using GPL software and libraries, so long as the boundaries are clearly defined.\n\nThus, a good contract--and I consider the modern GPL to be the best for software--lets programmers work together without upfront agreements, organizations, or assumptions of decency and goodwill. It makes it cheaper to collaborate, and turns conflict into healthy competition. GPL doesn't just define what happens with a fork, it actively encourages forks as a tool for experimentation and learning. Whereas a fork can kill a project with a \"more liberal\" license, GPL projects thrive on forks since successful experiments can, by contract, be remixed back into the mainstream.\n\nYes, there are many thriving BSD projects and many dead GPL ones. It's always wrong to generalize. A project will thrive or die for many reasons. However, in a competitive sport, one needs every advantage.\n\nThe other important part of the BSD vs. GPL story is what I call \"leakage\", which is the effect of pouring water into a pot with a small but real hole in the bottom.\n\n+++ Eat Me\n\nHere is a story. It happened to the eldest brother-in-law of the cousin of a friend of mine's colleague at work. His name was, and still is, Patrick.\n\nPatrick was a computer scientist with a PhD in advanced network topologies. He spent two years and his savings building a new product, and choose the BSD license because he believed that would get him more adoption. He worked in his attic, at great personal cost, and proudly published his work. People applauded, for it was truly fantastic, and his mailing lists were soon abuzz with activity and patches and happy chatter. Many companies told him how they were saving millions using his work. Some of them even paid him for consultancy and training. He was invited to speak at conferences and started collecting badges with his name on them. He started a small business, hired a friend to work with him, and dreamed of making it big.\n\nThen one day, someone pointed him to a new project, GPL licensed, which had forked his work and was improving on it. He was irritated and upset, and asked how people--fellow open sourcers, no less!--would so shamelessly steal his code. There were long arguments on the list about whether it was even legal to relicense their BSD code as GPL code. Turned out, it was. He tried to ignore the new project, but then he soon realized that new patches coming from that project //couldn't even be merged back// into his work!\n\nWorse, the GPL project got popular and some of his core contributors made first small, and then larger patches to it. Again, he couldn't use those changes, and he felt abandoned. Patrick went into a depression, his girlfriend left him for an international currency dealer called, weirdly, Patrice, and he stopped all work on the project. He felt betrayed, and utterly miserable. He fired his friend, who took it rather badly and told everyone that Patrick was a closet banjo player. Finally, Patrick took a job as a project manager for a cloud company, and by the age of forty, he had stopped programming even for fun.\n\nPoor Patrick. I almost felt sorry for him. Then I asked him, \"Why didn't you choose the GPL?\" \"Because it's a restrictive viral license\", he replied. I told him, \"You may have a PhD, and you may be the eldest brother-in-law of the cousin of a friend of my colleague, but you are an idiot and Monique was smart to leave you. You published your work inviting people to please steal your code as long as they kept this 'please steal my code' statement in the resulting work\", and when people did exactly that, you got upset. Worse, you were a hypocrite because when they did it in secret, you were happy, but when they did it openly, you felt betrayed.\"\n\nSeeing your hard work captured by a smarter team and then used against you is enormously painful, so why even make that possible? Every proprietary project that uses BSD code is capturing it. A public GPL fork is perhaps more humiliating, but it's fully self-inflicted.\n\nBSD is like food. It literally (and I mean that metaphorically) whispers \"eat me\" in the little voice one imagines a cube of cheese might use when it's sitting next to an empty bottle of the best beer in the world, which is of course Orval, brewed by an ancient and almost extinct order of silent Belgian monks called //Les Gars Labas Qui Fabrique l'Orval//. The BSD license, like its near clone MIT/X11, was designed specifically by a university (Berkeley) with no profit motive to leak work and effort. It is a way to push subsidized technology at below its cost price, a dumping of under-priced code in the hope that it will break the market for others. BSD is an //excellent// strategic tool, but only if you're a large well-funded institution that can afford to use Option One. The Apache license is BSD in a suit.\n\nFor us small businesses who aim our investments like precious bullets, leaking work and effort is unacceptable. Breaking the market is great, but we cannot afford to subsidize our competitors. The BSD networking stack ended up putting Windows on the Internet. We cannot afford battles with those we should naturally be allies with. We cannot afford to make fundamental business errors because in the end, that means we have to fire people.\n\nIt comes down to behavioral economics and game theory. //The license we choose modifies the economics of those who use our work//. In the software industry, there are friends, foes, and food. BSD makes most people see us as lunch. Closed source makes most people see us as enemies (do you //like// paying people for software?) GPL, however, makes most people, with the exception of the Patricks of the world, our allies. Any fork of ZeroMQ is license compatible with ZeroMQ, to the point where we //encourage// forks as a valuable tool for experimentation. Yes, it can be weird to see someone try to run off with the ball but here's the secret, //I can get it back any time I want.//\n\n+++ The Process\n\nIf you've accepted my thesis up to now, great! Now, I'll explain the rough process by which we actually build an open source community. This was how we built or grew or gently steered the ZeroMQ community into existence.\n\nYour goal as leader of a community is to motivate people to get out there and explore; to ensure they can do so safely and without disturbing others; to reward them when they make successful discoveries; and to ensure they share their knowledge with everyone else (and not because we ask them, not because they feel generous, but because it's The Law).\n\nIt is an iterative process. You make a small product, at your own cost, but in public view. You then build a small community around that product. If you have a small but real hit, the community then helps design and build the next version, and grows larger. And then that community builds the next version, and so on. It's evident that you remain part of the community, maybe even a majority contributor, but the more control you try to assert over the material results, the less people will want to participate. Plan your own retirement well before someone decides you are their next problem.\n\n+++ Crazy, Beautiful, and Easy\n\nYou need a goal that's crazy and simple enough to get people out of bed in the morning. Your community has to attract the very best people and that demands something special. With ZeroMQ, we said we were going to make \"the Fastest. Messaging. Ever.\", which qualifies as a good motivator. If we'd said, we're going to make \"a smart transport layer that'll connect your moving pieces cheaply and flexibly across your enterprise\", we'd have failed.\n\nThen your work must be beautiful, immediately useful, and attractive. Your contributors are users who want to explore just a little beyond where they are now. Make it simple, elegant, and brutally clean. The experience when people run or use your work should be an emotional one. They should //feel// something, and if you accurately solved even just one big problem that until then they didn't quite realize they faced, you'll have a small part of their soul.\n\nIt must be easy to understand, use, and join. Too many projects have barriers to access: put yourself in the other person's mind and see all the reasons they come to your site, thinking \"Um, interesting project, but...\" and then leave. You want them to stay and try it, just once. Use GitHub and put the issue tracker right there.\n\nIf you do these things well, your community will be smart but more importantly, it will be intellectually and geographically diverse. This is really important. A group of like-minded experts cannot explore the problem landscape well. They tend to make big mistakes. Diversity beats education any time.\n\n+++ Stranger, Meet Stranger\n\nHow much up-front agreement do two people need to work together on something? In most organizations, a lot. But you can bring this cost down to near-zero, and then people can collaborate without having ever met, done a phone conference, meeting, or business trip to discuss Roles and Responsibilities over way too many bottles of cheap Korean rice wine.\n\nYou need well-written rules that are designed by cynical people like me to force strangers into mutually beneficial collaboration instead of conflict. The GPL is a good start. GitHub and its fork/merge strategy is a good follow-up. And then you want something like our [http://rfc.zeromq.org/spec:22 C4 rulebook] to control how work actually happens.\n\nC4 (which I now use for every new open source project) has detailed and tested answers to a lot of common mistakes people make, such as the sin of working offline in a corner with others \"because it's faster\". Transparency is essential to get trust, which is essential to get scale. By forcing every single change through a single transparent process, you build real trust in the results.\n\nAnother cardinal sin that many open source developers make is to place themselves above others. \"I founded this project thus my intellect is superior to that of others\". It's not just immodest and rude, and usually inaccurate, it's also poor business. The rules must apply equally to everyone, without distinction. You are part of the community. Your job, as founder of a project, is not to impose your vision of the product over others, but to make sure the rules are good, honest, and //enforced//.\n\n+++ Infinite Property\n\nOne of the saddest myths of the knowledge business is that ideas are a sensible form of property. It's medieval nonsense that should have been junked along with slavery, but sadly it's still making too many powerful people too much money.\n\nIdeas are cheap. What does work sensibly as property is the hard work we do in building a market. \"You eat what you kill\" is the right model for encouraging people to work hard. Whether it's moral authority over a project, money from consulting, or the sale of a trademark to some large, rich firm: if you make it, you own it. But what you really own is \"footfall\", participants in your project, which ultimately defines your power.\n\nTo do this requires infinite free space. Thankfully, GitHub solved this problem for us, for which I will die a grateful person (there are many reasons to be grateful in life, which I won't list here because we only have a hundred or so pages left, but this is one of them).\n\nYou cannot scale a single project with many owners like you can scale a collection of many small projects, each with fewer owners. When we embrace forks, a person can become an \"owner\" with a single click. Now they just have to convince others to join by demonstrating their unique value.\n\nSo in ZeroMQ, we aimed to make it easy to write bindings on top of the core library, and we stopped trying to make those bindings ourselves. This created space for others to make those, become their owners, and get that credit.\n\n+++ Care and Feeding\n\nI wish a community could be 100% self-steering, and perhaps one day this will work, but today it's not the case. We're very close with ZeroMQ, but from my experience a community needs four types of care and feeding:\n\n* First, simply because most people are too nice, we need some kind of symbolic leadership or owners who provide ultimate authority in case of conflict. Usually it's the founders of the community. I've seen it work with self-elected groups of \"elders\", but old men like to talk a lot. I've seen communities split over the question \"who is in charge?\", and setting up legal entities with boards and such seems to make arguments over control worse, not better. Maybe because there seems to be more to fight over. One of the real benefits of free software is that it's always remixable, so instead of fighting over a pie, one simply forks the pie.\n\n* Second, communities need living rules, and thus they need a lawyer able to formulate and write these down. Rules are critical; when done right, they remove friction. When done wrong, or neglected, we see real friction and argument that can drive away the nice majority, leaving the argumentative core in charge of the burning house. One thing I've tried to do with the ZeroMQ and previous communities is create reusable rules, which perhaps means we don't need lawyers as much.\n\n* Thirdly, communities need some kind of financial backing. This is the jagged rock that breaks most ships. If you starve a community, it becomes more creative but the core contributors burn out. If you pour too much money into it, you attract the professionals, who never say \"no\", and the community loses its diversity and creativity. If you create a fund for people to share, they will fight (bitterly) over it. With ZeroMQ, we (iMatix) spend our time and money on marketing and packaging (like this book), and the basic care, like bug fixes, releases, and websites.\n\n* Lastly, sales and commercial mediation are important. There is a natural market between expert contributors and customers, but both are somewhat incompetent at talking to each other. Customers assume that support is free or very cheap because the software is free. Contributors are shy at asking a fair rate for their work. It makes for a difficult market. A growing part of my work and my firm's profits is simply connecting ZeroMQ users who want help with experts from the community able to provide it, and ensuring both sides are happy with the results.\n\nI've seen communities of brilliant people with noble goals dying because the founders got some or all of these four things wrong. The core problem is that you can't expect consistently great leadership from any one company, person, or group. What works today often won't work tomorrow, yet structures become more solid, not more flexible, over time.\n\nThe best answer I can find is a mix of two things. One, the GPL and its guarantee of remixability. No matter how bad the authority, no matter how much they try to privatize and capture the community's work, if it's GPL licensed, that work can walk away and find a better authority. Before you say, \"all open source offers this,\" think it through. I can kill a BSD-licensed project by hiring the core contributors and not releasing any new patches. But even with a billion of dollars, I //cannot// kill a GPL-licensed project. Two, the philosophical anarchist model of authority, which is that we choose it, it does not own us.\n\n++ The ZeroMQ Process: C4\n\nWhen we say ZeroMQ we sometimes mean {{libzmq}}, the core library. In early 2012, we synthesized the {{libzmq}} process into a formal protocol for collaboration that we called the [http://rfc.zeromq.org/spec:22 Collective Code Construction Contract], or C4. You can see this as a layer above the GPL. These are our rules, and I'll explain the reasoning behind each one.\n\nC4 is an evolution of the GitHub [https://help.github.com/articles/about-pull-requests/ Fork + Pull Model]. You may get the feeling I'm a fan of git and GitHub. This would be accurate: these two tools have made such a positive impact on our work over the last years, especially when it comes to building community.\n\n+++ Language\n\n> The key words \"MUST\", \"MUST NOT\", \"REQUIRED\", \"SHALL\", \"SHALL NOT\", \"SHOULD\", \"SHOULD NOT\", \"RECOMMENDED\",  \"MAY\", and \"OPTIONAL\" in this document are to be interpreted as described in RFC 2119.\n\nBy starting with the RFC 2119 language, the C4 text makes very clear its intention to act as a protocol rather than a randomly written set of recommendations. A protocol is a contract between parties that defines the rights and obligations of each party. These can be peers in a network or they can be strangers working in the same project.\n\nI think C4 is the first time anyone has attempted to codify a community's rulebook as a formal and reusable protocol spec. Previously, our rules were spread out over several wiki pages, and were quite specific to {{libzmq}} in many ways. But experience teaches us that the more formal, accurate, and reusable the rules, the easier it is for strangers to collaborate up-front. And less friction means a more scalable community. At the time of C4, we also had some disagreement in the {{libzmq}} project over precisely what process we were using. Not everyone felt bound by the same rules. Let's just say some people felt they had a special status, which created friction with the rest of the community. So codification made things clear.\n\nIt's easy to use C4: just host your project on GitHub, get one other person to join, and open the floor to pull requests. In your README, put a link to C4 and that's it. We've done this in quite a few projects and it does seem to work. I've been pleasantly surprised a few times just applying these rules to my own work, like CZMQ. None of us are so amazing that we can work without others.\n\n+++ Goals\n\n> C4 is meant to provide a reusable optimal collaboration model for open source software projects.\n\nThe short term reason for writing C4 was to end arguments over the {{libzmq}} contribution process. The dissenters went off elsewhere. [https://github.com/zeromq/libzmq/graphs/contributors The ZeroMQ community blossomed] smoothly and easily, as I'd predicted. Most people were surprised, but gratified. There's been no real criticisms of C4 except its branching policy, which I'll come to later as it deserves its own discussion.\n\nThere's a reason I'm reviewing history here: as founder of a community, you are asking people to invest in your property, trademark, and branding. In return, and this is what we do with ZeroMQ, you can use that branding to set a bar for quality. When you download a product labeled \"ZeroMQ\", you know that it's been produced to certain standards. It's a basic rule of quality: write down your process; otherwise you cannot improve it. Our processes aren't perfect, nor can they ever be. But any flaw in them can be fixed, and tested.\n\nMaking C4 reusable is therefore really important. To learn more about the best possible process, we need to get results from the widest range of projects.\n\n> It has these specific goals:\n> To maximize the scale of the community around a project, by reducing the friction for new Contributors and creating a scaled participation model with strong positive feedbacks;\n\nThe number one goal is size and health of the community--not technical quality, not profits, not performance, not market share. The goal is simply the number of people who contribute to the project. The science here is simple: the larger the community, the more accurate the results.\n\n> To relieve dependencies on key individuals by separating different skill sets so that there is a larger pool of competence in any required domain;\n\nPerhaps the worst problem we faced in {{libzmq}} was dependence on people who could understand the code, manage GitHub branches, and make clean releases--all at the same time. It's like looking for athletes who can run marathons and sprint, swim, and also lift weights. We humans are really good at specialization. Asking us to be really good at two contradictory things reduces the number of candidates sharply, which is a Bad Thing for any project. We had this problem severely in {{libzmq}} in 2009 or so, and fixed it by splitting the role of maintainer into two: one person makes patches and another makes releases.\n\n> To allow the project to develop faster and more accurately, by increasing the diversity of the decision making process;\n\nThis is theory--not fully proven, but not falsified. The diversity of the community and the number of people who can weigh in on discussions, without fear of being criticized or dismissed, the faster and more accurately the software develops. Speed is quite subjective here. Going very fast in the wrong direction is not just useless, it's actively damaging (and we suffered a lot of that in {{libzmq}} before we switched to C4).\n\n> To support the natural life cycle of project versions from experimental through to stable, by allowing safe experimentation, rapid failure, and isolation of stable code;\n\nTo be honest, this goal seems to be fading into irrelevance. It's quite an interesting effect of the process: //the git master is almost always perfectly stable//. This has to do with the size of changes and their //latency//, i.e., the time between someone writing the code and someone actually using it fully. However, people still expect \"stable\" releases, so we'll keep this goal there for a while.\n\n> To reduce the internal complexity of project repositories, thus making it easier for Contributors to participate and reducing the scope for error;\n\nCurious observation: people who thrive in complex situations like to create complexity because it keeps their value high. It's the Cobra Effect (Google it). Git made branches easy and left us with the all too common syndrome of \"git is easy once you understand that a git branch is just a folded five-dimensional lepton space that has a detached history with no intervening cache\". Developers should not be made to feel stupid by their tools. I've seen too many top-class developers confused by repository structures to accept conventional wisdom on git branches. We'll come back to dispose of git branches shortly, dear reader.\n\n> To enforce collective ownership of the project, which increases economic incentive to Contributors and reduces the risk of hijack by hostile entities.\n\nUltimately, we're economic creatures, and the sense that \"we own this, and our work can never be used against us\" makes it much easier for people to invest in an open source project like ZeroMQ. And it can't be just a feeling, it has to be real. There are a number of aspects to making collective ownership work, we'll see these one-by-one as we go through C4.\n\n+++ Preliminaries\n\n> The project SHALL use the git distributed revision control system.\n\nGit has its faults. Its command-line API is horribly inconsistent, and it has a complex, messy internal model that it shoves in your face at the slightest provocation. But despite doing its best to make its users feel stupid, git does its job really, really well. More pragmatically, I've found that if you stay away from certain areas (branches!), people learn git rapidly and don't make many mistakes. That works for me.\n\n> The project SHALL be hosted on github.com or equivalent, herein called the \"Platform\".\n\nI'm sure one day some large firm will buy GitHub and break it, and another platform will rise in its place. Until then, Github serves up a near-perfect set of minimal, fast, simple tools. I've thrown hundreds of people at it, and they all stick like flies stuck in a dish of honey.\n\n> The project SHALL use the Platform issue tracker.\n\nWe made the mistake in {{libzmq}} of switching to Jira because we hadn't learned yet how to properly use the GitHub issue tracker. Jira is a great example of how to turn something useful into a complex mess because the business depends on selling more \"features\". But even without criticizing Jira, keeping the issue tracker on the same platform means one less UI to learn, one less login, and smooth integration between issues and patches.\n\n> The project SHOULD have clearly documented guidelines for code style.\n\nThis is a protocol plug-in: insert code style guidelines here. If you don't document the code style you use, you have no basis except prejudice to reject patches.\n\n> A \"Contributor\" is a person who wishes to provide a patch, being a set of commits that solve some clearly identified problem.\n> A \"Maintainer\" is a person who merge patches to the project. Maintainers are not developers; their job is to enforce process.\n\nNow we move on to definitions of the parties, and the splitting of roles that saved us from the sin of structural dependency on rare individuals. This worked well in {{libzmq}}, but as you will see it depends on the rest of the process. C4 isn't a buffet; you will need the whole process (or something very like it), or it won't hold together.\n\n> Contributors SHALL NOT have commit access to the repository unless they are also Maintainers.\n> Maintainers SHALL have commit access to the repository.\n\nWhat we wanted to avoid was people pushing their changes directly to master. This was the biggest source of trouble in {{libzmq}} historically: large masses of raw code that took months or years to fully stabilize. We eventually followed other ZeroMQ projects like PyZMQ in using pull requests. We went further, and stipulated that //all// changes had to follow the same path. No exceptions for \"special people\".\n\n> Everyone, without distinction or discrimination, SHALL have an equal right to become a Contributor under the terms of this contract.\n\nWe had to state this explicitly. It used to be that the {{libzmq}} maintainers would reject patches simply because they didn't like them. Now, that may sound reasonable to the author of a library (though {{libzmq}} was not written by any one person), but let's remember our goal of creating a work that is owned by as many people as possible. Saying \"I don't like your patch so I'm going to reject it\" is equivalent to saying, \"I claim to own this and I think I'm better than you, and I don't trust you\". Those are toxic messages to give to others who are thinking of becoming your co-investors.\n\nI think this fight between individual expertise and collective intelligence plays out in other areas. It defined Wikipedia, and still does, a decade after that work surpassed anything built by small groups of experts. For me, we make software by slowly synthesizing the most accurate knowledge, much as we make Wikipedia articles.\n\n+++ Licensing and Ownership\n\n> The project SHALL use the GPLv3 or a variant thereof (LGPL, AGPL).\n\nI've already explained how full remixability creates better scale and why the GPL and its variants seems the optimal contract for remixable software. If you're a large business aiming to dump code on the market, you won't want C4, but then you won't really care about community either.\n\n> All contributions to the project source code (\"patches\") SHALL use the same license as the project.\n\nThis removes the need for any specific license or contribution agreement for patches. You fork the GPL code, you publish your remixed version on GitHub, and you or anyone else can then submit that as a patch to the original code. BSD doesn't allow this. Any work that contains BSD code may also contain unlicensed proprietary code so you need explicit action from the author of the code before you can remix it.\n\n> All patches are owned by their authors. There SHALL NOT be any copyright assignment process.\n\nHere we come to the key reason people trust their investments in ZeroMQ: it's logistically impossible to buy the copyrights to create a closed source competitor to ZeroMQ. iMatix can't do this either. And the more people that send patches, the harder it becomes. ZeroMQ isn't just free and open today--this specific rule means it will remain so forever. Note that it's not the case in all GPL projects, many of which still ask for copyright transfer back to the maintainers.\n\n> The project SHALL be owned collectively by all its Contributors.\n\nThis is perhaps redundant, but worth saying: if everyone owns their patches, then the resulting whole is also owned by every contributor. There's no legal concept of owning lines of code: the \"work\" is at least a source file.\n\n> Each Contributor SHALL be responsible for identifying themselves in the project Contributor list.\n\nIn other words, the maintainers are not karma accountants. Anyone who wants credit has to claim it themselves.\n\n+++ Patch Requirements\n\nIn this section, we define the obligations of the contributor: specifically, what constitutes a \"valid\" patch, so that maintainers have rules they can use to accept or reject patches.\n\n> Maintainers and Contributors MUST have a Platform account and SHOULD use their real names or a well-known alias.\n\nIn the worst case scenario, where someone has submitted toxic code (patented, or owned by someone else), we need to be able to trace who and when, so we can remove the code. Asking for real names or a well-known alias is a theoretical strategy for reducing the risk of bogus patches. We don't know if this actually works because we haven't had the problem yet.\n\n> A patch SHOULD be a minimal and accurate answer to exactly one identified and agreed problem.\n\nThis implements the Simplicity Oriented Design process that I'll come to later in this chapter. One clear problem, one minimal solution, apply, test, repeat.\n\n> A patch MUST adhere to the code style guidelines of the project if these are defined.\n\nThis is just sanity. I've spent time cleaning up other peoples' patches because they insisted on putting the {{else}} beside the {{if}} instead of just below as Nature intended. Consistent code is healthier.\n\n> A patch MUST adhere to the \"Evolution of Public Contracts\" guidelines defined below.\n\nAh, the pain, the pain. I'm not speaking of the time at age eight when I stepped on a plank with a 4-inch nail protruding from it. That was relatively OK. I'm speaking of 2010-2011 when we had multiple parallel releases of ZeroMQ, each with different //incompatible// APIs or wire protocols. It was an exercise in bad rules, pointlessly enforced, that still hurts us today. The rule was, \"If you change the API or protocol, you SHALL create a new major version\". Give me the nail through the foot; that hurt less.\n\nOne of the big changes we made with C4 was simply to ban, outright, this kind of sanctioned sabotage. Amazingly, it's not even hard. We just don't allow the breaking of existing public contracts, period, unless everyone agrees, in which case no period. As Linus Torvalds famously put it on 23 December 2012, \"WE DO NOT BREAK USERSPACE!\"\n\n> A patch SHALL NOT include nontrivial code from other projects unless the Contributor is the original author of that code.\n\nThis rule has two effects. The first is that it forces people to make minimal solutions because they cannot simply import swathes of existing code. In the cases where I've seen this happen to projects, it's always bad unless the imported code is very cleanly separated. The second is that it avoids license arguments. You write the patch, you are allowed to publish it as LGPL, and we can merge it back in. But you find a 200-line code fragment on the web, and try to paste that, we'll refuse.\n\n> A patch MUST compile cleanly and pass project self-tests on at least the principle target platform.\n\nFor cross-platform projects, it is fair to ask that the patch works on the development box used by the contributor.\n\n> A patch commit message SHOULD consist of a single short (less than 50 character) line summarizing the change, optionally followed by a blank line and then a more thorough description. \n\nThis is a good format for commit messages that fits into email (the first line becomes the subject, and the rest becomes the email body).\n\n> A \"Correct Patch\" is one that satisfies the above requirements.\n\nJust in case it wasn't clear, we're back to legalese and definitions.\n\n+++ Development Process\n\nIn this section, we aim to describe the actual development process, step-by-step.\n\n> Change on the project SHALL be governed by the pattern of accurately identifying problems and applying minimal, accurate solutions to these problems.\n\nThis is a unapologetic ramming through of thirty years' software design experience. It's a profoundly simple approach to design: make minimal, accurate solutions to real problems, nothing more or less. In ZeroMQ, we don't have feature requests. Treating new features the same as bugs confuses some newcomers. But this process works, and not just in open source. Enunciating the problem we're trying to solve, with every single change, is key to deciding whether the change is worth making or not.\n\n> To initiate changes, a user SHALL log an issue on the project Platform issue tracker.\n\nThis is meant to stop us from going offline and working in a ghetto, either by ourselves or with others. Although we tend to accept pull requests that have clear argumentation, this rule lets us say \"stop\" to confused or too-large patches.\n\n> The user SHOULD write the issue by describing the problem they face or observe.\n\n\"Problem: we need feature X. Solution: make it\" is not a good issue. \"Problem: user cannot do common tasks A or B except by using a complex workaround. Solution: make feature X\" is a decent explanation. Because everyone I've ever worked with has needed to learn this, it seems worth restating: document the real problem first, solution second.\n\n> The user SHOULD seek consensus on the accuracy of their observation, and the value of solving the problem.\n\nAnd because many apparent problems are illusionary, by stating the problem explicitly we give others a chance to correct our logic. \"You're only using A and B a lot because function C is unreliable. Solution: make function C work properly.\"\n\n> Users SHALL NOT log feature requests, ideas, suggestions, or any solutions to problems that are not explicitly documented and provable.\n\nThere are several reasons for not logging ideas, suggestions, or feature requests. In our experience, these just accumulate in the issue tracker until someone deletes them. But more profoundly, when we treat all change as problem solutions, we can prioritize trivially. Either the problem is real and someone wants to solve it now, or it's not on the table. Thus, wish lists are off the table.\n\n> Thus, the release history of the project SHALL be a list of meaningful issues logged and solved.\n\nI'd love the GitHub issue tracker to simply list all the issues we solved in each release. Today we still have to write that by hand. If one puts the issue number in each commit, and if one uses the GitHub issue tracker, which we sadly don't yet do for ZeroMQ, this release history is easier to produce mechanically.\n\n> To work on an issue, a Contributor SHALL fork the project repository and then work on their forked repository.\n\nHere we explain the GitHub fork + pull request model so that newcomers only have to learn one process (C4) in order to contribute.\n\n> To submit a patch, a Contributor SHALL create a Platform pull request back to the project.\n\nGitHub has made this so simple that we don't need to learn git commands to do it, for which I'm deeply grateful. Sometimes, I'll tell people who I don't particularly like that command-line git is awesome and all they need to do is learn git's internal model in detail before trying to use it on real work. When I see them several months later they look... changed.\n\n> A Contributor SHALL NOT commit changes directly to the project.\n\nAnyone who submits a patch is a contributor, and all contributors follow the same rules. No special privileges to the original authors, because otherwise we're not building a community, only boosting our egos.\n\n> To discuss a patch, people MAY comment on the Platform pull request, on the commit, or elsewhere.\n\nRandomly distributed discussions may be confusing if you're walking up for the first time, but GitHub solves this for all current participants by sending emails to those who need to follow what's going on. We had the same experience and the same solution in Wikidot, and it works. There's no evidence that discussing in different places has any negative effect.\n\n> To accept or reject a patch, a Maintainer SHALL use the Platform interface.\n\nWorking via the GitHub web user interface means pull requests are logged as issues, with workflow and discussion. I'm sure there are more complex ways to work. Complexity is easy; it's simplicity that's incredibly hard.\n\n> Maintainers SHALL NOT accept their own patches.\n\nThere was a rule we defined in the FFII years ago to stop people burning out: no less than two people on any project. One-person projects tend to end in tears, or at least bitter silence. We have quite a lot of data on burnout, why it happens, and how to prevent it (even cure it). I'll explore this later in the chapter, because if you work with or on open source you need to be aware of the risks. The \"no merging your own patch\" rule has two goals. First, if you want your project to be C4-certified, you have to get at least one other person to help. If no one wants to help you, perhaps you need to rethink your project. Second, having a control for every patch makes it much more satisfying, keeps us more focused, and stops us breaking the rules because we're in a hurry, or just feeling lazy.\n\n> Maintainers SHALL NOT make value judgments on correct patches.\n\nWe already said this but it's worth repeating: the role of Maintainer is not to judge a patch's substance, only its technical quality. The substantive worth of a patch only emerges over time: people use it, and like it, or they do not. And if no one is using a patch, eventually it'll annoy someone else who will remove it, and no one will complain.\n\n> Maintainers SHALL merge correct patches rapidly.\n\nThere is a criteria I call //change latency//, which is the round-trip time from identifying a problem to testing a solution. The faster the better. If maintainers cannot respond to pull requests as rapidly as people expect, they're not doing their job (or they need more hands).\n\n> The Contributor MAY tag an issue as \"Ready\" after making a pull request for the issue.\n\nBy default, GitHub offers the usual variety of issues, but with C4 we don't use them. Instead, we need just two labels, \"Urgent\" and \"Ready\". A contributor who wants another user to test an issue can then label it as \"Ready\".\n\n> The user who created an issue SHOULD close the issue after checking the patch is successful.\n\nWhen one person opens an issue, and another works on it, it's best to allow the original person to close the issue. That acts as a double-check that the issue was properly resolved.\n\n> Maintainers SHOULD ask for improvements to incorrect patches and SHOULD reject incorrect patches if the Contributor does not respond constructively.\n\nInitially, I felt it was worth merging all patches, no matter how poor. There's an element of trolling involved. Accepting even obviously bogus patches could, I felt, pull in more contributors. But people were uncomfortable with this so we defined the \"correct patch\" rules, and the Maintainer's role in checking for quality. On the negative side, I think we didn't take some interesting risks, which could have paid off with more participants. On the positive side, this has led to {{libzmq}} master (and in all projects that use C4) being practically production quality, practically all the time.\n\n> Any Contributor who has value judgments on a correct patch SHOULD express these via their own patches.\n\nIn essence, the goal here is to allow users to try patches rather than to spend time arguing pros and cons. As easy as it is to make a patch, it's as easy to revert it with another patch. You might think this would lead to \"patch wars\", but that hasn't happened. We've had a handful of cases in {{libzmq}} where patches by one contributor were killed by another person who felt the experimentation wasn't going in the right direction. It is easier than seeking up-front consensus.\n\n> Maintainers MAY commit changes to non-source documentation directly to the project.\n\nThis exit allows maintainers who are making release notes to push those without having to create an issue which would then affect the release notes, leading to stress on the space time fabric and possibly involuntary rerouting backwards in the fourth dimension to before the invention of cold beer. Shudder. It is simpler to agree that release notes aren't technically software.\n\n+++ Creating Stable Releases\n\nWe want some guarantee of stability for a production system. In the past, this meant taking unstable code and then over months hammering out the bugs and faults until it was safe to trust. iMatix's job, for years, has been to do this to {{libzmq}}, turning raw code into packages by allowing only bug fixes and no new code into a \"stabilization branch\". It's surprisingly not as thankless as it sounds.\n\nNow, since we went full speed with C4, we've found that git master of {{libzmq}} is mostly perfect, most of the time. This frees our time to do more interesting things, such as building new open source layers on top of {{libzmq}}. However, people still want that guarantee: many users will simply not install except from an \"official\" release. So a stable release today means two things. First, a snapshot of the master taken at a time when there were no new changes for a while, and no dramatic open bugs. Second, a way to fine tune that snapshot to fix the critical issues remaining in it.\n\nThis is the process we explain in this section.\n\n> The project SHALL have one branch (\"master\") that always holds the latest in-progress version and SHOULD always build.\n\nThis is redundant because every patch always builds but it's worth restating. If the master doesn't build (and pass its tests), someone needs waking up.\n\n> The project SHALL NOT use topic branches for any reason. Personal forks MAY use topic branches.\n\nI'll come to branches soon. In short (or \"tl;dr\", as they say on the webs), branches make the repository too complex and fragile, and require up-front agreement, all of which are expensive and avoidable.\n\n> To make a stable release someone SHALL fork the repository by copying it and thus become maintainer of this repository.\n> Forking a project for stabilization MAY be done unilaterally and without agreement of project maintainers.\n\nIt's free software. No one has a monopoly on it. If you think the maintainers aren't producing stable releases right, fork the repository and do it yourself. Forking isn't a failure, it's an essential tool for competition. You can't do this with branches, which means a branch-based release policy gives the project maintainers a monopoly. And that's bad because they'll become lazier and more arrogant than if real competition is chasing their heels.\n\n> A stabilization project SHOULD be maintained by the same process as the main project.\n\nStabilization projects have maintainers and contributors like any project. In practice we usually cherry pick patches from the main project to the stabilization project, but that's just a convenience.\n\n> A patch to a repository declared \"stable\" SHALL be accompanied by a reproducible test case.\n\nBeware of a one-size-fits-all process. New code does not need the same paranoia as code that people are trusting for production use. In the normal development process, we did not mention test cases. There's a reason for this. While I love testable patches, many changes aren't easily or at all testable. However, to stabilize a code base you want to fix only serious bugs, and you want to be 100% sure every change is accurate. This means before and after tests for every change.\n\n+++ Evolution of Public Contracts\n\nBy \"public contracts\", I mean APIs and protocols. Up until the end of 2011, {{libzmq}}'s naturally happy state was marred by broken promises and broken contracts. We stopped making promises (aka \"road maps\") for {{libzmq}} completely, and our dominant theory of change is now that it emerges carefully and accurately over time. At a 2012 Chicago meetup, Garrett Smith and Chuck Remes called this the \"drunken stumble to greatness\", which is how I think of it now.\n\nWe stopped breaking public contracts simply by banning the practice. Before then it had been \"OK\" (as in we did it and everyone complained bitterly, and we ignored them) to break the API or protocol so long as we changed the major version number. Sounds fine, until you get ZeroMQ v2.0, v3.0, and v4.0 all in development at the same time, and not speaking to each other.\n\n> All Public Contracts (APIs or protocols) SHOULD be documented.\n\nYou'd think this was a given for professional software engineers but no, it's not. So, it's a rule. You want C4 certification for your project, you make sure your public contracts are documented. No \"It's specified in the code\" excuses. Code is not a contract. (Yes, I intend at some point to create a C4 certification process to act as a quality indicator for open source projects.)\n\n> All Public Contracts SHALL use Semantic Versioning.\n\nThis rule is mainly here because people asked for it. I've no real love for it, as Semantic Versioning is what led to the so-called \"Why does ZeroMQ not speak to itself?!\" debacle. I've never seen the problem that this solved. Something about runtime validation of library versions, or some-such.\n\n> All Public Contracts SHOULD have space for extensibility and experimentation.\n\nNow, the real thing is that public contracts //do change//. It's not about not changing them. It's about changing them safely. This means educating (especially protocol) designers to create that space up-front.\n\n> A patch that modifies a stable Public Contract SHOULD not break existing applications unless there is overriding consensus on the value of doing this.\n\nSometimes the patch is fixing a bad API that no one is using. It's a freedom we need, but it should be based on consensus, not one person's dogma. However, making random changes \"just because\" is not good. In ZeroMQ v3.x, did we benefit from renaming {{ZMQ_NOBLOCK}} to {{ZMQ_DONTWAIT}}? Sure, it's closer to the POSIX socket {{recv()}} call, but is that worth breaking thousands of applications? No one ever reported it as an issue. To misquote Stallman: \"your freedom to create an ideal world stops one inch from my application.\"\n\n> A patch that introduces new features to a Public Contract SHOULD do so using new names.\n\nWe had the experience in ZeroMQ once or twice of new features using old names (or worse, using names that were //still in use// elsewhere). ZeroMQ v3.0 had a newly introduced \"ROUTER\" socket that was totally different from the existing ROUTER socket in 2.x. Dear lord, you should be face-palming, why? The reason: apparently, even smart people sometimes need regulation to stop them doing silly things.\n\n> Old names SHOULD be deprecated in a systematic fashion by marking new names as \"experimental\" until they are stable, then marking the old names as \"deprecated\".\n\nThis life cycle notation has the great benefit of actually telling users what is going on with a consistent direction. \"Experimental\" means \"we have introduced this and intend to make it stable if it works\". It does not mean, \"we have introduced this and will remove it at any time if we feel like it\". One assumes that code that survives more than one patch cycle is meant to be there. \"Deprecated\" means \"we have replaced this and intend to remove it\".\n\n> When sufficient time has passed, old deprecated names SHOULD be marked \"legacy\" and eventually removed.\n\nIn theory this gives applications time to move onto stable new contracts without risk. You can upgrade first, make sure things work, and then, over time, fix things up to remove dependencies on deprecated and legacy APIs and protocols.\n\n> Old names SHALL NOT be reused by new features.\n\nAh, yes, the joy when ZeroMQ v3.x renamed the top-used API functions ({{zmq_send[3]}} and {{zmq_recv[3]}}) and then recycled the old names for new methods that were utterly incompatible (and which I suspect few people actually use). You should be slapping yourself in confusion again, but really, this is what happened and I was as guilty as anyone. After all, we did change the version number! The only benefit of that experience was to get this rule.\n\n> When old names are removed, their implementations MUST provoke an exception (assertion) if used by applications.\n\nI've not tested this rule to be certain it makes sense. Perhaps what it means is \"if you can't provoke a compile error because the API is dynamic, provoke an assertion\".\n\n+++ Project Administration\n\n> The project founders SHALL act as Administrators to manage the set of project Maintainers.\n\nSomeone needs to administer the project, and it makes sense that the original founders start this ball rolling.\n\n> The Administrators SHALL ensure their own succession over time by promoting the most effective Maintainers.\n\nAt the same time, as founder of a project you really want to get out of the way before you become over-attached to it. Promoting the most active and consistent maintainers is good for everyone.\n\n> A new Contributor who makes a correct patch SHALL be invited to become a Maintainer.\n\nI met Felix Geisendörfer in Lyons in 2012 at the [http://www.mix-it.fr Mix-IT conference] where I presented Social Architecture and one thing that came out of this was Felix's now famous [http://felixge.de/2013/03/11/the-pull-request-hack.html Pull Request Hack]. It fits elegantly into C4 and solves the problem of maintainers dropping out over time.\n\n> Administrators MAY remove Maintainers who are inactive for an extended period of time, or who repeatedly fail to apply this process accurately.\n\nThis was Ian Barber's suggestion: we need a way to crop inactive maintainers. Originally maintainers were self-elected but that makes it hard to drop troublemakers (who are rare, but not unknown).\n\nC4 is not perfect. Few things are. The process for changing it (Digistan's COSS) is a little outdated now: it relies on a single-editor workflow with the ability to fork, but not merge. This seems to work but it could be better to use C4 for protocols like C4.\n\n++ A Real-Life Example\n\nIn [https://lists.zeromq.org/pipermail/zeromq-dev/2012-October/018470.html this email thread], Dan Goes asks how to make a publisher that knows when a new client subscribes, and sends out previous matching messages. It's a standard pub-sub technique called \"last value caching\". Now over a 1-way transport like pgm (where subscribers literally send no packets back to publishers), this can't be done. But over TCP, it can, if we use an XPUB socket and if that socket didn't cleverly filter out duplicate subscriptions to reduce upstream traffic.\n\nThough I'm not an expert contributor to {{libzmq}}, this seems like a fun problem to solve. How hard could it be? I start by forking the {{libzmq}} repository to my own GitHub account and then clone it to my laptop, where I build it:\n\n[[code]]\ngit clone git@github.com:hintjens/libzmq.git\ncd libzmq\n./autogen.sh\n./configure\nmake\n[[/code]]\n\nBecause the {{libzmq}} code is neat and well-organized, it was quite easy to find the main files to change ({{xpub.cpp}} and {{xpub.hpp}}). Each socket type has its own source file and class. They inherit from {{socket_base.cpp}}, which has this hook for socket-specific options:\n\n[[code]]\n//  First, check whether specific socket type overloads the option.\nint rc = xsetsockopt (option_, optval_, optvallen_);\nif (rc == 0 || errno != EINVAL)\n    return rc;\n\n//  If the socket type doesn't support the option, pass it to\n//  the generic option parser.\nreturn options.setsockopt (option_, optval_, optvallen_);\n[[/code]]\n\nThen I check where the XPUB socket filters out duplicate subscriptions, in its {{xread_activated}} method:\n\n[[code]]\nbool unique;\nif (*data == 0)\n    unique = subscriptions.rm (data + 1, size - 1, pipe_);\nelse\n    unique = subscriptions.add (data + 1, size - 1, pipe_);\n\n//  If the subscription is not a duplicate store it so that it can be\n//  passed to used on next recv call.\nif (unique && options.type != ZMQ_PUB)\n    pending.push_back (blob_t (data, size));\n[[/code]]\n\nAt this stage, I'm not too concerned with the details of how {{subscriptions.rm}} and {{subscriptions.add}} work. The code seems obvious except that \"subscription\" also includes unsubscription, which confused me for a few seconds. If there's anything else weird in the rm and add methods, that's a separate issue to fix later. Time to make an issue for this change. I head over to the {{zeromq.jira.com}} site, log in, and create a new entry.\n\nJira kindly offers me the traditional choice between \"bug\" and \"new feature\" and I spend thirty seconds wondering where this counterproductive historical distinction came from. Presumably, the \"we'll fix bugs for free, but you pay for new features\" commercial proposal, which stems from the \"you tell us what you want and we'll make it for $X\" model of software development, and which generally leads to \"we spent three times $X and we got what?!\" email Fists of Fury.\n\nPutting such thoughts aside, I create [https://zeromq.jira.com/browse/LIBZMQ-443 an issue #443] and described the problem and plausible solution:\n\n> Problem: XPUB socket filters out duplicate subscriptions (deliberate design). However this makes it impossible to do subscription-based intelligence. See http://lists.zeromq.org/pipermail/zeromq-dev/2012-October/018838.html for a use case.\n> Solution: make this behavior configurable with a socket option.\n\nIt's naming time. The API sits in {{include/zmq.h}}, so this is where I added the option name. When you invent a concept in an API or anywhere, //please// take a moment to choose a name that is explicit and short and obvious. Don't fall back on generic names that need additional context to understand. You have one chance to tell the reader what your concept is and does. A name like {{ZMQ_SUBSCRIPTION_FORWARDING_FLAG}} is terrible. It technically kind of aims in the right direction, but is miserably long and obscure. I chose {{ZMQ_XPUB_VERBOSE}}: short and explicit and clearly an on/off switch with \"off\" being the default setting.\n\nSo, it's time to add a private property to the {{xpub}} class definition in {{xpub.hpp}}:\n\n[[code]]\n// If true, send all subscription messages upstream, not just\n// unique ones\nbool verbose;\n[[/code]]\n\nAnd then lift some code from {{router.cpp}} to implement the {{xsetsockopt}} method. Finally, change the {{xread_activated}} method to use this new option, and while at it, make that test on socket type more explicit too:\n\n[[code]]\n//  If the subscription is not a duplicate store it so that it can be\n//  passed to used on next recv call.\nif (options.type == ZMQ_XPUB && (unique || verbose))\n    pending.push_back (blob_t (data, size));\n[[/code]]\n\nThe thing builds nicely the first time. This makes me a little suspicious, but being lazy and jet-lagged I don't immediately make a test case to actually try out the change. The process doesn't demand that, even if usually I'd do it just to catch that inevitable 10% of mistakes we all make. I do however document this new option on the {{doc/zmq_setsockopt.txt}} man page. In the worst case, I added a patch that wasn't really useful. But I certainly didn't break anything.\n\nI don't implement a matching {{zmq_getsockopt}} because \"minimal\" means what it says. There's no obvious use case for getting the value of an option that you presumably just set, in code. Symmetry isn't a valid reason to double the size of a patch. I did have to document the new option because the process says, \"All Public Contracts SHOULD be documented.\"\n\nCommitting the code, I push the patch to my forked repository (the \"origin\"):\n\n[[code]]\ngit commit -a -m \"Fixed issue #443\"\ngit push origin master\n[[/code]]\n\nSwitching to the GitHub web interface, I go to my {{libzmq}} fork, and press the big \"Pull Request\" button at the top. GitHub asks me for a title, so I enter \"Added ZMQ_XPUB_VERBOSE option\". I'm not sure why it asks this as I made a neat commit message but hey, let's go with the flow here.\n\nThis makes a nice little pull request with two commits; the one I'd made a month ago on the release notes to prepare for the v3.2.1 release (a month passes so quickly when you spend most of it in airports), and my fix for issue #443 (37 new lines of code). GitHub lets you continue to make commits after you've kicked off a pull request. They get queued up and merged in one go. That is easy, but the maintainer may refuse the whole bundle based on one patch that doesn't look valid.\n\nBecause Dan is waiting (at least in my highly optimistic imagination) for this fix, I go back to the zeromq-dev list and tell him I've made the patch, with a link to the commit. The faster I get feedback, the better. It's 1 a.m. in South Korea as I make this patch, so early evening in Europe, and morning in the States. You learn to count timezones when you work with people across the world. Ian is in a conference, Mikko is getting on a plane, and Chuck is probably in the office, but three hours later, Ian merges the pull request.\n\nAfter Ian merges the pull request, I resynchronize my fork with the upstream {{libzmq}} repository. First, I add a //remote// that tells git where this repository sits (I do this just once in the directory where I'm working):\n\n[[code]]\ngit remote add upstream git://github.com/zeromq/libzmq.git\n[[/code]]\n\nAnd then I pull changes back from the upstream master and check the git log to double-check:\n\n[[code]]\ngit pull --rebase upstream master\ngit log\n[[/code]]\n\nAnd that is pretty much it, in terms of how much git one needs to learn and use to contribute patches to {{libzmq}}. Six git commands and some clicking on web pages. Most importantly to me as a naturally lazy, stupid, and easily confused developer, I don't have to learn git's internal models, and never have to do anything involving those infernal engines of structural complexity we call \"git branches\". Next up, the attempted assassination of git branches. Let's live dangerously!\n\n++ Git Branches Considered Harmful\n\nOne of git's most popular features is its branches. Almost all projects that use git use branches, and the selection of the \"best\" branching strategy is like a rite of passage for an open source project. Vincent Driessen's [http://nvie.com/posts/a-successful-git-branching-model/ git-flow] may be the best known. It has //base// branches (master, develop), //feature// branches, //release// branches, //hotfix// branches, and //support// branches. Many teams have adopted git-flow, which even has git extensions to support it. I'm a great believer in popular wisdom, but sometimes you have to recognize mass delusion for what it is.\n\nHere is a section of C4 that might have shocked you when you first read it:\n\n> The project SHALL NOT use topic branches for any reason. Personal forks MAY use topic branches.\n\nTo be clear, it's //public branches in shared repositories// that I'm talking about. Using branches for private work, e.g., to work on different issues, appears to work well enough, though it's more complexity than I personally enjoy. To channel Stallman again: \"your freedom to create complexity ends one inch from our shared workspace.\"\n\nLike the rest of C4, the rules on branches are not accidental. They came from our experience making ZeroMQ, starting when Martin Sustrik and I rethought how to make stable releases. We both love and appreciate simplicity (some people seem to have a remarkable tolerance for complexity). We chatted for a while... I asked him, \"I'm going to start making a stable release. Would it be OK for me to make a branch in the git you're working in?\" Martin didn't like the idea. \"OK, if I fork the repository, I can move patches from your repo to that one\". That felt much better to both of us.\n\nThe response from many in the ZeroMQ community was shock and horror. People felt we were being lazy and making contributors work harder to find the \"right\" repository. Still, this seemed simple, and indeed it worked smoothly. The best part was that we each worked as we wanted to. Whereas before, the ZeroMQ repository had felt horribly complex (and it wasn't even anything like git-flow), this felt simple. And it worked. The only downside was that we lost a single unified history. Now, perhaps historians will feel robbed, but I honestly can't see that the historical minutiae of who changed what, when, including every branch and experiment, are worth any significant pain or friction.\n\nPeople have gotten used to the \"multiple repositories\" approach in ZeroMQ and we've started using that in other projects quite successfully. My own opinion is that history will judge git branches and patterns like git-flow as a complex solution to imaginary problems inherited from the days of Subversion and monolithic repositories.\n\nMore profoundly, and perhaps this is why the majority seems to be \"wrong\": I think the branches versus forks argument is really a deeper design versus evolve argument about how to make software optimally. I'll address that deeper argument in the next section. For now, I'll try to be scientific about my irrational hatred of branches, by looking at a number of criteria, and comparing branches and forks in each one.\n\n+++ Simplicity Versus Complexity\n\n//The simpler, the better.//\n\nThere is no inherent reason why branches are more complex than forks. However, git-flow uses //five types// of branch, whereas C4 uses two types of fork (development, and stable) and one branch (master). Circumstantial evidence is thus that branches lead to more complexity than forks. For new users, it is definitely, and we've measured this in practice, easier to learn to work with many repositories and no branches except master.\n\n+++ Change Latency\n\n//The smaller and more rapid the delivery, the better.//\n\nDevelopment branches seem to correlate strongly with large, slow, risky deliveries. \"Sorry, I have to merge this branch before we can test the new version\" signals a breakdown in process. It's certainly not how C4 works, which is by focusing tightly on individual problems and their minimal solutions. Allowing branches in development raises change latency. Forks have a different outcome: it's up to the forker to ensure that his changes merge cleanly, and to keep them simple so they won't be rejected.\n\n+++ Learning Curve\n\n//The smoother the learning curve, the better.//\n\nEvidence definitely shows that learning to use git branches is complex. For some people, this is OK. For most developers, every cycle spent learning git is a cycle lost on more productive things. I've been told several times, by different people that I do not like branches because I \"never properly learned git\". That is fair, but it is a criticism of the tool, not the human.\n\n+++ Cost of Failure\n\n//The lower the cost of failure, the better.//\n\nBranches demand more perfection from developers because mistakes potentially affect others. This raises the cost of failure. Forks make failure extremely cheap because literally nothing that happens in a fork can affect others not using that fork.\n\n+++ Up-front Coordination\n\n//The less need for up-front coordination, the better.//\n\nYou can do a hostile fork. You cannot do a hostile branch. Branches depend on up-front coordination, which is expensive and fragile. One person can veto the desires of a whole group. For example in the ZeroMQ community we were unable to agree on a git branching model for a year. We solved that by using forking instead. The problem went away.\n\n+++ Scalability\n\n//The more you can scale a project, the better.//\n\nThe strong assumption in all branch strategies is that the repository //is// the project. But there is a limit to how many people you can get to agree to work together in one repository. As I explained, the cost of up-front coordination can become fatal. A more realistic project scales by allowing anyone to start their own repositories, and ensuring these can work together. A project like ZeroMQ has dozens of repositories. Forking looks more scalable than branching.\n\n+++ Surprise and Expectations\n\n//The less surprising, the better.//\n\nPeople expect branches and find forks to be uncommon and thus confusing. This is the one aspect where branches win. If you use branches, a single patch will have the same commit hash tag, whereas across forks the patch will have different hash tags. That makes it harder to track patches as they cross forks, true. But seriously, //having to track hexadecimal hash tags is not a feature//. It's a bug. Sometimes better ways of working are surprising at first.\n\n+++ Economics of Participation\n\n//The more tangible the rewards, the better.//\n\nPeople like to own their work and get credit for it. This is much easier with forks than with branches. Forks create more competition in a healthy way, while branches suppress competition and force people to collaborate and share credit. This sounds positive but in my experience it demotivates people. A branch isn't a product you can \"own\", whereas a fork can be.\n\n+++ Robustness in Conflict\n\n//The more a model can survive conflict, the better.//\n\nLike it or not, people fight over ego, status, beliefs, and theories of the world. Challenge is a necessary part of science. If your organizational model depends on agreement, you won't survive the first real fight. Branches do not survive real arguments and fights, whereas forks can be hostile, and still benefit all parties. And this is indeed how free software works.\n\n+++ Guarantees of Isolation\n\n//The stronger the isolation between production code and experiment, the better.//\n\nPeople make mistakes. I've seen experimental code pushed to mainline production by error. I've seen people make bad panic changes under stress. But the real fault is in allowing two entirely separate generations of product to exist in the same protected space. If you can push to random-branch-x, you can push to master. Branches do not guarantee isolation of production critical code. Forks do.\n\n+++ Visibility\n\n//The more visible our work, the better.//\n\nForks have watchers, issues, a README, and a wiki. Branches have none of these. People try forks, build them, break them, patch them. Branches sit there until someone remembers to work on them. Forks have downloads and tarballs. Branches do not. When we look for self-organization, the more visible and declarative the problems, the faster and more accurately we can work.\n\n+++ Conclusions\n\nIn this section, I've listed a series of arguments, most of which came from fellow team members. Here's how it seems to break down: git veterans insist that branches are the way to work, whereas newcomers tend to feel intimidated when asked to navigate git branches. Git is not an easy tool to master. What we've discovered, accidentally, is that when you stop using branches //at all//, git becomes trivial to use. It literally comes down to six commands ({{clone}}, {{remote}}, {{commit}}, {{log}}, {{push}}, and {{pull}}). Furthermore, a branch-free process actually works, we've used it for a couple of years now, and no visible downside except surprise to the veterans and growth of \"single\" projects over multiple repositories.\n\nIf you can't use forks, perhaps because your firm doesn't trust GitHub's private repositories, then you can perhaps use topic branches, one per issue. You'll still suffer the costs of getting up-front consensus, low competitiveness, and risk of human error.\n\n++ Designing for Innovation\n\nLet's look at innovation, which Wikipedia defines as, \"the development of new values through solutions that meet new requirements, inarticulate needs, or old customer and market needs in value adding new ways.\" This really just means solving problems more cheaply. It sounds straight-forward, but the history of collapsed tech giants proves that it's not. I'll try to explain how teams so often get it wrong, and suggest a way for doing innovation right.\n\n+++ The Tale of Two Bridges\n\nTwo old engineers were talking of their lives and boasting of their greatest projects. One of the engineers explained how he had designed one of the greatest bridges ever made.\n\n\"We built it across a river gorge,\" he told his friend. \"It was wide and deep. We spent two years studying the land, and choosing designs and materials. We hired the best engineers and designed the bridge, which took another five years. We contracted the largest engineering firms to build the structures, the towers, the tollbooths, and the roads that would connect the bridge to the main highways. Dozens died during the construction. Under the road level we had trains, and a special path for cyclists. That bridge represented years of my life.\"\n\nThe second man reflected for a while, then spoke. \"One evening me and a friend got drunk on vodka, and we threw a rope across a gorge,\" he said. \"Just a rope, tied to two trees. There were two villages, one at each side. At first, people pulled packages across that rope with a pulley and string. Then someone threw a second rope, and built a foot walk. It was dangerous, but the kids loved it. A group of men then rebuilt that, made it solid, and women started to cross, everyday, with their produce. A market grew up on one side of the bridge, and slowly that became a large town, because there was a lot of space for houses. The rope bridge got replaced with a wooden bridge, to allow horses and carts to cross. Then the town built a real stone bridge, with metal beams. Later, they replaced the stone part with steel, and today there's a suspension bridge standing in that same spot.\"\n\nThe first engineer was silent. \"Funny thing,\" he said, \"my bridge was demolished about ten years after we built it. Turns out it was built in the wrong place and no one wanted to use it. Some guys had thrown a rope across the gorge, a few miles further downstream, and that's where everyone went.\"\n\n+++ How ZeroMQ Lost Its Road Map\n\nPresenting ZeroMQ at the Mix-IT conference in Lyon in early 2012, I was asked several times for the \"road map\". My answer was: there is no road map any longer. We had road maps, and we deleted them. Instead of a few experts trying to lay out the next steps, we were allowing this to happen organically. The audience didn't really like my answer. So un-French.\n\nHowever, the history of ZeroMQ makes it quite clear why road maps were problematic. In the beginning, we had a small team making the library, with few contributors, and no documented road map. As ZeroMQ grew more popular and we switched to more contributors, users asked for road maps. So we collected our plans together and tried to organize them into releases. Here, we wrote, is what will come in the next release.\n\nAs we rolled out releases, we hit the problem that it's very easy to promise stuff, and rather harder to make it as planned. For one thing, much of the work was voluntary, and it's not clear how you force volunteers to commit to a road map. But also, priorities can shift dramatically over time. So we were making promises we could not keep, and the real deliveries didn't match the road maps.\n\nThe second problem was that by defining the road map, we in effect claimed territory, making it harder for others to participate. People do prefer to contribute to changes they believe were their idea. Writing down a list of things to do turns contribution into a chore rather than an opportunity.\n\nFinally, we saw changes in ZeroMQ that were quite traumatic, and the road maps didn't help with this, despite a lot of discussion and effort to \"do it right\". Examples of this were incompatible changes in APIs and protocols. It was quite clear that we needed a different approach for defining the change process.\n\nSoftware engineers don't like the notion that powerful, effective solutions can come into existence without an intelligent designer actively thinking things through. And yet no one in that room in Lyon would have questioned evolution. A strange irony, and one I wanted to explore further as it underpins the direction the ZeroMQ community has taken since the start of 2012.\n\nIn the dominant theory of innovation, brilliant individuals reflect on large problem sets and then carefully and precisely create a solution. Sometimes they will have \"eureka\" moments where they \"get\" brilliantly simple answers to whole large problem sets. The inventor, and the process of invention are rare, precious, and can command a monopoly. History is full of such heroic individuals. We owe them our modern world.\n\nLooking more closely, however, and you will see that the facts don't match. History doesn't show lone inventors. It shows lucky people who steal or claim ownership of ideas that are being worked on by many. It shows brilliant people striking lucky once, and then spending decades on fruitless and pointless quests. The best known large-scale inventors like Thomas Edison were in fact just very good at systematic broad research done by large teams. It's like claiming that Steve Jobs invented every device made by Apple. It is a nice myth, good for marketing, but utterly useless as practical science.\n\nRecent history, much better documented and less easy to manipulate, shows this well. The Internet is surely one of the most innovative and fast-moving areas of technology, and one of the best documented. It has no inventor. Instead, it has a massive economy of people who have carefully and progressively solved a long series of immediate problems, documented their answers, and made those available to all. The innovative nature of the Internet comes not from a small, select band of Einsteins. It comes from RFCs anyone can use and improve, made by hundreds and thousands of smart, but not uniquely smart, individuals. It comes from open source software anyone can use and improve. It comes from sharing, scale of community, and the continuous accretion of good solutions and disposal of bad ones.\n\nHere thus is an alternative theory of innovation:\n\n# There is an infinite problem/solution terrain.\n# This terrain changes over time according to external conditions.\n# We can only accurately perceive problems to which we are close.\n# We can rank the cost/benefit economics of problems using a market for solutions.\n# There is an optimal solution to any solvable problem.\n# We can approach this optimal solution heuristically, and mechanically.\n# Our intelligence can make this process faster, but does not replace it.\n\nThere are a few corollaries to this:\n\n* //Individual creativity matters less than process.// Smarter people may work faster, but they may also work in the wrong direction. It's the collective vision of reality that keeps us honest and relevant.\n\n* //We don't need road maps if we have a good process.// Functionality will emerge and evolve over time as solutions compete for market share.\n\n* //We don't invent solutions so much as discover them.// All sympathies to the creative soul. It's just an information processing machine that likes to polish its own ego and collect karma.\n\n* //Intelligence is a social effect, though it feels personal.// A person cut off from others eventually stops thinking. We can neither collect problems nor measure solutions without other people.\n\n* //The size and diversity of the community is a key factor.// Larger, more diverse communities collect more relevant problems, and solve them more accurately, and do this faster, than a small expert group.\n\nSo, when we trust the solitary experts, they make classic mistakes. They focus on ideas, not problems. They focus on the wrong problems. They make misjudgments about the value of solving problems. They don't use their own work.\n\nCan we turn the above theory into a reusable process? In late 2011, I started documenting C4 and similar contracts, and using them both in ZeroMQ and in closed source projects. The underlying process is something I call \"Simplicity Oriented Design\", or SOD. This is a reproducible way of developing simple and elegant products. It organizes people into flexible supply chains that are able to navigate a problem landscape rapidly and cheaply. They do this by building, testing, and keeping or discarding minimal plausible solutions, called \"patches\". Living products consist of long series of patches, applied one atop the other.\n\nSOD is relevant first because it's how we evolve ZeroMQ. It's also the basis for the design process we will use in [#advanced-architecture] to develop larger-scale ZeroMQ applications. Of course, you can use any software architecture methodology with ZeroMQ.\n\nTo best understand how we ended up with SOD, let's look at the alternatives.\n\n+++ Trash-Oriented Design\n\nThe most popular design process in large businesses seems to be //Trash-Oriented Design//, or TOD. TOD feeds off the belief that all we need to make money are great ideas. It's tenacious nonsense, but a powerful crutch for people who lack imagination. The theory goes that ideas are rare, so the trick is to capture them. It's like non-musicians being awed by a guitar player, not realizing that great talent is so cheap it literally plays on the streets for coins.\n\nThe main output of TODs is expensive \"ideation\": concepts, design documents, and products that go straight into the trash can. It works as follows:\n\n* The Creative People come up with long lists of \"we could do X and Y\". I've seen endlessly detailed lists of everything amazing a product could do. We've all been guilty of this. Once the creative work of idea generation has happened, it's just a matter of execution, of course.\n\n* So the managers and their consultants pass their brilliant ideas to designers who create acres of preciously refined design documents. The designers take the tens of ideas the managers came up with, and turn them into hundreds of world-changing designs.\n\n* These designs get given to engineers who scratch their heads and wonder who the heck came up with such nonsense. They start to argue back, but the designs come from up high, and really, it's not up to engineers to argue with creative people and expensive consultants.\n\n* So the engineers creep back to their cubicles, humiliated and threatened into building the gigantic but oh-so-elegant junk heap. It is bone-breaking work because the designs take no account of practical costs. Minor whims might take weeks of work to build. As the project gets delayed, the managers bully the engineers into giving up their evenings and weekends.\n\n* Eventually, something resembling a working product makes it out of the door. It's creaky and fragile, complex and ugly. The designers curse the engineers for their incompetence and pay more consultants to put lipstick onto the pig, and slowly the product starts to look a little nicer.\n\n* By this time, the managers have started to try to sell the product and they find, shockingly, that no one wants it. Undaunted, they courageously build million-dollar web sites and ad campaigns to explain to the public why they absolutely need this product. They do deals with other businesses to force the product on the lazy, stupid, and ungrateful market.\n\n* After twelve months of intense marketing, the product still isn't making profits. Worse, it suffers dramatic failures and gets branded in the press as a disaster. The company quietly shelves it, fires the consultants, buys a competing product from a small startup and rebrands that as its own Version 2. Hundreds of millions of dollars end up in the trash.\n\n* Meanwhile, another visionary manager somewhere in the organization drinks a little too much tequila with some marketing people and has a Brilliant Idea.\n\nTrash-Oriented Design would be a caricature if it wasn't so common. Something like 19 out of 20 market-ready products built by large firms are failures (yes, 87% of statistics are made up on the spot). The remaining 1 in 20 probably only succeeds because the competitors are so bad and the marketing is so aggressive.\n\nThe main lessons of TOD are quite straightforward but hard to swallow. They are:\n\n* Ideas are cheap. No exceptions. There are no brilliant ideas. Anyone who tries to start a discussion with \"oooh, we can do this too!\" should be beaten down with all the passion one reserves for traveling evangelists. It is like sitting in a cafe at the foot of a mountain, drinking a hot chocolate and telling others, \"Hey, I have a great idea, we can climb that mountain! And build a chalet on top! With two saunas! And a garden! Hey, and we can make it solar powered! Dude, that's awesome! What color should we paint it? Green! No, blue! OK, go and make it, I'll stay here and make spreadsheets and graphics!\"\n\n* The starting point for a good design process is to collect real problems that confront real people. The second step is to evaluate these problems with the basic question, \"How much is it worth to solve this problem?\" Having done that, we can collect that set of problems that are worth solving.\n\n* Good solutions to real problems will succeed as products. Their success will depend on how good and cheap the solution is, and how important the problem is (and sadly, how big the marketing budgets are). But their success will also depend on how much they demand in effort to use--in other words, how simple they are.\n\nNow, after slaying the dragon of utter irrelevance, we attack the demon of complexity.\n\n+++ Complexity-Oriented Design\n\nReally good engineering teams and small firms can usually build decent products. But the vast majority of products still end up being too complex and less successful than they might be. This is because specialist teams, even the best, often stubbornly apply a process I call //Complexity-Oriented Design//, or COD, which works as follows:\n\n* Management correctly identifies some interesting and difficult problem with economic value. In doing so, they already leapfrog over any TOD team.\n\n* The team with enthusiasm starts to build prototypes and core layers. These work as designed and thus encouraged, the team go off into intense design and architecture discussions, coming up with elegant schemas that look beautiful and solid.\n\n* Management comes back and challenges the team with yet more difficult problems. We tend to equate cost with value, so the harder and more expensive to solve, the more the solution should be worth, in their minds.\n\n* The team, being engineers and thus loving to build stuff, build stuff. They build and build and build and end up with massive, perfectly-designed complexity.\n\n* The products go to market, and the market scratches its head and asks, \"Seriously, is this the best you can do?\" People do use the products, especially if they aren't spending their own money in climbing the learning curve.\n\n* Management gets positive feedback from its larger customers, who share the same idea that high cost (in training and use) means high value, and so continues to push the process.\n\n* Meanwhile somewhere across the world, a small team is solving the same problem using a better process, and a year later smashes the market to little pieces.\n\nCOD is characterized by a team obsessively solving the wrong problems in a form of collective delusion. COD products tend to be large, ambitious, complex, and unpopular. Much open source software is the output of COD processes. It is insanely hard for engineers to //stop// extending a design to cover more potential problems. They argue, \"What if someone wants to do X?\" but never ask themselves, \"What is the real value of solving X?\"\n\nA good example of COD in practice is Bluetooth, a complex, over-designed set of protocols that users hate. It continues to exist only because in a massively-patented industry there are no real alternatives. Bluetooth is perfectly secure, which is close to pointless for a proximity protocol. At the same time, it lacks a standard API for developers, meaning it's really costly to use Bluetooth in applications.\n\nOn the #zeromq IRC channel, Wintre once wrote of how enraged he was many years ago when he \"found that XMMS 2 had a working plugin system, but could not actually play music.\"\n\nCOD is a form of large-scale \"rabbit-holing\", in which designers and engineers cannot distance themselves from the technical details of their work. They add more and more features, utterly misreading the economics of their work.\n\nThe main lessons of COD are also simple, but hard for experts to swallow. They are:\n\n* Making stuff that you don't immediately have a need for is pointless. Doesn't matter how talented or brilliant you are, if you just sit down and make stuff people are not actually asking for, you are most likely wasting your time.\n\n* Problems are not equal. Some are simple, and some are complex. Ironically, solving the simpler problems often has more value to more people than solving the really hard ones. So if you allow engineers to just work on random things, they'll mostly focus on the most interesting but least worthwhile things.\n\n* Engineers and designers love to make stuff and decoration, and this inevitably leads to complexity. It is crucial to have a \"stop mechanism\", a way to set short, hard deadlines that force people to make smaller, simpler answers to just the most crucial problems.\n\n+++ Simplicity Oriented Design\n\nFinally, we come to the rare but precious //Simplicity Oriented Design//, or SOD. This process starts with a realization: we do not know what we have to make until after we start making it. Coming up with ideas or large-scale designs isn't just wasteful, it's a direct hindrance to designing the truly accurate solutions. The really juicy problems are hidden like far valleys, and any activity except active scouting creates a fog that hides those distant valleys. You need to keep mobile, pack light, and move fast.\n\nSOD works as follows:\n\n* We collect a set of interesting problems (by looking at how people use technology or other products) and we line these up from simple to complex, looking for and identifying patterns of use.\n\n* We take the simplest, most dramatic problem and we solve this with a minimal plausible solution, or \"patch\". Each patch solves exactly a genuine and agreed-upon problem in a brutally minimal fashion.\n\n* We apply one measure of quality to patches, namely \"Can this be done any simpler while still solving the stated problem?\" We can measure complexity in terms of concepts and models that the user has to learn or guess in order to use the patch. The fewer, the better. A perfect patch solves a problem with zero learning required by the user.\n\n* Our product development consists of a patch that solves the problem \"we need a proof of concept\" and then evolves in an unbroken line to a mature series of products, through hundreds or thousands of patches piled on top of each other.\n\n* We do not do //anything// that is not a patch. We enforce this rule with formal processes that demand that every activity or task is tied to a genuine and agreed-upon problem, explicitly enunciated and documented.\n\n* We build our projects into a supply chain where each project can provide problems to its \"suppliers\" and receive patches in return. The supply chain creates the \"stop mechanism\" because when people are impatiently waiting for an answer, we necessarily cut our work short.\n\n* Individuals are free to work on any projects, and provide patches at any place they feel it's worthwhile. No individuals \"own\" any project, except to enforce the formal processes. A single project can have many variations, each a collection of different, competing patches.\n\n* Projects export formal and documented interfaces so that upstream (client) projects are unaware of change happening in supplier projects. Thus multiple supplier projects can compete for client projects, in effect creating a free and competitive market.\n\n* We tie our supply chain to real users and external clients and we drive the whole process by rapid cycles so that a problem received from outside users can be analyzed, evaluated, and solved with a patch in a few hours.\n\n* At every moment from the very first patch, our product is shippable. This is essential, because a large proportion of patches will be wrong (10-30%) and only by giving the product to users can we know which patches have become problems that need solving.\n\nSOD is a //hill-climbing algorithm//, a reliable way of finding optimal solutions to the most significant problems in an unknown landscape. You don't need to be a genius to use SOD successfully, you just need to be able to see the difference between the fog of activity and the progress towards new real problems.\n\nPeople have pointed out that hill-climbing algorithms have known limitations. One gets stuck on local peaks, mainly. But this is nonetheless how life itself works: collecting tiny incremental improvements over long periods of time. There is no intelligent designer. We reduce the risk of local peaks by spreading out widely across the landscape, but it is somewhat moot. The limitations aren't optional, they are physical laws. The theory says, //this is how innovation really works, so better embrace it and work with it than try to work on the basis of magical thinking//.\n\nAnd in fact once you see all innovation as more or less successful hill-climbing, you realize why some teams and companies and products get stuck in a never-never land of diminishing prospects. They simply don't have the diversity and collective intelligence to find better hills to climb. When Nokia killed their open source projects, they cut their own throat.\n\nA really good designer with a good team can use SOD to build world-class products, rapidly and accurately. To get the most out of SOD the designer has to use the product continuously, from day one, and develop his or her ability to smell out problems such as inconsistency, surprising behavior, and other forms of friction. We naturally overlook many annoyances, but a good designer picks these up and thinks about how to patch them. Design is about removing friction in the use of a product.\n\nIn an open source setting, we do this work in public. There's no \"let's open the code\" moment. Projects that do this are in my view missing the point of open source, which is to engage your users in your exploration, and to build community around the seed of the architecture.\n\n++ Burnout\n\nThe ZeroMQ community has been and still is heavily dependent on pro bono individual efforts. I'd like to think that everyone was compensated in some way for their contributions, and I believe that with ZeroMQ, contributing means gaining expertise in an extraordinarily valuable technology, which leads to improved professional options.\n\nHowever, not all projects will be so lucky and if you work with or in open source, you should understand the risk of burnout that volunteers face. This applies to all pro bono communities. In this section, I'll explain what causes burnout, how to recognize it, how to prevent it, and (if it happens) how to try to treat it. Disclaimer: I'm not a psychiatrist and this article is based on my own experiences of working in pro bono contexts for the last 20 years, including free software projects, and NGOs such as the [http://www.ffii.org FFII].\n\nIn a pro bono context, we're expected to work without direct or obvious economic incentive. That is, we sacrifice family life, professional advancement, free time, and health in order to accomplish some goal we have decided to accomplish. In any project, we need some kind of reward to make it worth continuing each day. In most pro bono projects the rewards are very indirect, superficially not economical at all. Mostly, we do things because people say, \"Hey, great!\" Karma is a powerful motivator.\n\nHowever, we are economic beings, and sooner or later, if a project costs us a great deal and does not bring economic rewards of some kind (money, fame, a new job), we start to suffer. At a certain stage, it seems our subconscious simply gets disgusted and says, \"Enough is enough!\" and refuses to go any further. If we try to force ourselves, we can literally get sick.\n\nThis is what I call \"burnout\", though the term is also used for other kinds of exhaustion. Too much investment on a project with too little economic reward, for too long. We are great at manipulating ourselves and others, and this is often part of the process that leads to burnout. We tell ourselves that it's for a good cause and that the other guy is doing OK, so we should be able to as well.\n\nWhen I got burned out on open source projects like Xitami, I remember clearly how I felt. I simply stopped working on it, refused to answer any more emails, and told people to forget about it. You can tell when someone's burned out. They go offline, and everyone starts saying, \"He's acting strange... depressed, or tired...\"\n\nDiagnosis is simple. Has someone worked a lot on a project that was not paying back in any way? Did she make exceptional sacrifices? Did he lose or abandon his job or studies to do the project? If you're answering \"yes\", it's burnout.\n\nThere are three simple techniques I've developed over the years to reduce the risk of burnout in the teams I work with:\n\n* //No one is irreplaceable.// Working solo on a critical or popular project--the concentration of responsibility on one person who cannot set their own limits--is probably the main factor. It's a management truism: if someone in your organization is irreplaceable, get rid of him or her.\n\n* //We need day jobs to pay the bills.// This can be hard, but seems necessary. Getting money from somewhere else makes it much easier to sustain a sacrificial project.\n\n* //Teach people about burnout.// This should be a basic course in colleges and universities, as pro bono work becomes a more common way for young people to experiment professionally.\n\nWhen someone is working alone on a critical project, you //know// they are going blow their fuses sooner or later. It's actually fairly predictable: something like 18-36 months depending on the individual and how much economic stress they face in their private lives. I've not seen anyone burn-out after half a year, nor last five years in a unrewarding project.\n\nThere is a simple cure for burnout that works in at least some cases: get paid decently for your work. However, this pretty much destroys the freedom of movement (across that infinite problem landscape) that the volunteer enjoys.\n\n++ Patterns for Success\n\nI'll end this code-free chapter with a series of patterns for success in software engineering. They aim to capture the essence of what divides glorious success from tragic failure. They were described as \"religious maniacal dogma\" by a manager, and \"anything else would be effing insane\" by a colleague, in a single day. For me, they are science. But treat the Lazy Perfectionist and others as tools to use, sharpen, and throw away if something better comes along.\n\n+++ The Lazy Perfectionist\n\n//Never design anything that's not a precise minimal answer to a problem we can identify and have to solve.//\n\nThe Lazy Perfectionist spends his idle time observing others and identifying problems that are worth solving. He looks for agreement on those problems, always asking, \"What is the //real// problem\". Then he moves, precisely and minimally, to build, or get others to build, a usable answer to one problem. He uses, or gets others to use those solutions. And he repeats this until there are no problems left to solve, or time or money runs out.\n\n+++ The Benevolent Tyrant\n\n//The control of a large force is the same principle as the control of a few men: it is merely a question of dividing up their numbers.// -- Sun Tzu\n\nThe Benevolent Tyrant divides large problems into smaller ones and throws them at groups to focus on. She brokers contracts between these groups, in the form of APIs and the \"unprotocols\" we'll read about in the next chapter. The Benevolent Tyrant constructs a supply chain that starts with problems, and results in usable solutions. She is ruthless about how the supply chain works, but does not tell people what to work on, nor how to do their work.\n\n+++ The Earth and Sky\n\n//The ideal team consists of two sides: one writing code, and one providing feedback.//\n\nThe Earth and Sky work together as a whole, in close proximity, but they communicate formally through issue tracking. Sky seeks out problems from others and from their own use of the product and feeds these to Earth. Earth rapidly answers with testable solutions. Earth and Sky can work through dozens of issues in a day. Sky talks to other users, and Earth talks to other developers. Earth and Sky may be two people, or two small groups.\n\n+++ The Open Door\n\n//The accuracy of knowledge comes from diversity.//\n\nThe Open Door accepts contributions from almost anyone. She does not argue quality or direction, instead allowing others to argue that and get more engaged. She calculates that even a troll will bring more diverse opinion to the group. She lets the group form its opinion about what goes into stable code, and she enforces this opinion with help of a Benevolent Tyrant.\n\n+++ The Laughing Clown\n\n//Perfection precludes participation.//\n\nThe Laughing Clown, often acting as the Happy Failure, makes no claim to high competence. Instead his antics and bumbling attempts provoke others into rescuing him from his own tragedy. Somehow however, he always identifies the right problems to solve. People are so busy proving him wrong they don't realize they're doing valuable work.\n\n+++ The Mindful General\n\n//Make no plans. Set goals, develop strategies and tactics.//\n\nThe Mindful General operates in unknown territory, solving problems that are hidden until they are nearby. Thus she makes no plans, but seeks opportunities, then exploits them rapidly and accurately. She develops tactics and strategies in the field, and teaches these to her soldiers so they can move independently, and together.\n\n+++ The Social Engineer\n\n//If you know the enemy and know yourself, you need not fear the result of a hundred battles.// -- Sun Tzu\n\nThe Social Engineer reads the hearts and minds of those he works with and for. He asks, of everyone, \"What makes this person angry, insecure, argumentative, calm, happy?\" He studies their moods and dispositions. With this knowledge he can encourage those who are useful, and discourage those who are not. The Social Engineer never acts on his own emotions.\n\n+++ The Constant Gardener\n\n//He will win whose army is animated by the same spirit throughout all its ranks.// -- Sun Tzu\n\nThe Constant Gardener grows a process from a small seed, step-by-step as more people come into the project. She makes every change for a precise reason, with agreement from everyone. She never imposes a process from above but lets others come to consensus, and then he enforces that consensus. In this way, everyone owns the process together and by owning it, they are attached to it.\n\n+++ The Rolling Stone\n\n//After crossing a river, you should get far away from it.// -- Sun Tzu\n\nThe Rolling Stone accepts his own mortality and transience. He has no attachment to his past work. He accepts that all that we make is destined for the trash can, it is just a matter of time. With precise, minimal investments, he can move rapidly away from the past and stay focused on the present and near future. Above all, he has no ego and no pride to be hurt by the actions of others.\n\n+++ The Pirate Gang\n\n//Code, like all knowledge, works best as collective--not private--property.//\n\nThe Pirate Gang organizes freely around problems. It accepts authority insofar as authority provides goals and resources. The Pirate Gang owns and shares all it makes: every work is fully remixable by others in the Pirate Gang. The gang moves rapidly as new problems emerge, and is quick to abandon old solutions if those stop being relevant. No persons or groups can monopolize any part of the supply chain.\n\n+++ The Flash Mob\n\n//Water shapes its course according to the nature of the ground over which it flows.// -- Sun Tzu\n\nThe Flash Mob comes together in space and time as needed, then disperses as soon as they can. Physical closeness is essential for high-bandwidth communications. But over time it creates technical ghettos, where Earth gets separated from Sky. The Flash Mob tends to collect a lot of frequent flier miles.\n\n+++ The Canary Watcher\n\n//Pain is not, generally, a Good Sign.//\n\nThe Canary Watcher measures the quality of an organization by their own pain level, and the observed pain levels of those with whom he works. He brings new participants into existing organizations so they can express the raw pain of the innocent. He may use alcohol to get others to verbalize their pain points. He asks others, and himself, \"Are you happy in this process, and if not, why not?\" When an organization causes pain in himself or others, he treats that as a problem to be fixed. People should feel joy in their work.\n\n+++ The Hangman\n\n//Never interrupt others when they are making mistakes.//\n\nThe Hangman knows that we learn only by making mistakes, and she gives others copious rope with which to learn. She only pulls the rope gently, when it's time. A little tug to remind the other of their precarious position. Allowing others to learn by failure gives the good reason to stay, and the bad excuse to leave. The Hangman is endlessly patient, because there is no shortcut to the learning process.\n\n+++ The Historian\n\n//Keeping the public record may be tedious, but it's the only way to prevent collusion.//\n\nThe Historian forces discussion into the public view, to prevent collusion to own areas of work. The Pirate Gang depends on full and equal communications that do not depend on momentary presence. No one really reads the archives, but the simply possibility stops most abuses. The Historian encourages the right tool for the job: email for transient discussions, IRC for chatter, wikis for knowledge, issue tracking for recording opportunities.\n\n+++ The Provocateur\n\n//When a man knows he is to be hanged in a fortnight, it concentrates his mind wonderfully.// -- Samuel Johnson\n\nThe Provocateur creates deadlines, enemies, and the occasional impossibility. Teams work best when they don't have time for the crap. Deadlines bring people together and focus the collective mind. An external enemy can move a passive team into action. The Provocateur never takes the deadline too seriously. The product is //always// ready to ship. But she gently reminds the team of the stakes: fail, and we all look for other jobs.\n\n+++ The Mystic\n\n//When people argue or complain, just write them a Sun Tzu quotation// -- Mikko Koppanen\n\nThe Mystic never argues directly. He knows that to argue with an emotional person only creates more emotion. Instead he side-steps the discussion. It's hard to be angry at a Chinese general, especially when he has been dead for 2,400 years. The Mystic plays Hangman when people insist on the right to get it wrong.\n"
        },
        {
          "name": "chapter7.txt",
          "type": "blob",
          "size": 110.9111328125,
          "content": ".output chapter7.wd\n.bookmark advanced-architecture\n+ Advanced Architecture using ZeroMQ\n\nOne of the effects of using ZeroMQ at large scale is that because we can build distributed architectures so much faster than before, the limitations of our software engineering processes become more visible. Mistakes in slow motion are often harder to see (or rather, easier to rationalize away).\n\nMy experience when teaching ZeroMQ to groups of engineers is that it's rarely sufficient to just explain how ZeroMQ works and then just expect them to start building successful products. Like any technology that removes friction, ZeroMQ opens the door to big blunders. If ZeroMQ is the ACME rocket-propelled shoe of distributed software development, a lot of us are like Wile E. Coyote, slamming full speed into the proverbial desert cliff.\n\nWe saw in [#the-community] that ZeroMQ itself uses a formal process for changes. One reason we built this process, over some years, was to stop the repeated cliff-slamming that happened in the library itself.\n\nPartly, it's about slowing down and partially, it's about ensuring that when you move fast, you go--and this is essential Dear Reader--in the //right direction//. It's my standard interview riddle: what's the rarest property of any software system, the absolute hardest thing to get right, the lack of which causes the slow or fast death of the vast majority of projects? The answer is not code quality, funding, performance, or even (though it's a close answer), popularity. The answer is //accuracy//.\n\nAccuracy is half the challenge, and applies to any engineering work. The other half is distributed computing itself, which sets up a whole range of problems that we need to solve if we are going to create architectures. We need to encode and decode data; we need to define protocols to connect clients and servers; we need to secure these protocols against attackers; and we need to make stacks that are robust. Asynchronous messaging is hard to get right.\n\nThis chapter will tackle these challenges, starting with a basic reappraisal of how to design and build software and ending with a fully formed example of a distributed application for large-scale file distribution.\n\nWe'll cover the following juicy topics:\n\n* How to go from idea to working prototype safely (the MOPED pattern)\n* Different ways to serialize your data as ZeroMQ messages\n* How to code-generate binary serialization codecs\n* How to build custom code generators using the GSL tool\n* How to write and license a protocol specification\n* How to build fast restartable file transfer over ZeroMQ\n* How to use credit-based flow control for nonblocking transfers\n* How to build protocol servers and clients as state machines\n* How to make a secure protocol over ZeroMQ\n* A large-scale file publishing system (FileMQ)\n\n++ Message-Oriented Pattern for Elastic Design\n\nI'll introduce Message-Oriented Pattern for Elastic Design (MOPED), a software engineering pattern for ZeroMQ architectures. It was either \"MOPED\" or \"BIKE\", the Backronym-Induced Kinetic Effect. That's short for \"BICICLE\", the Backronym-Inflated See if I Care Less Effect. In life, one learns to go with the least embarrassing choice.\n\nIf you've read this book carefully, you'll have seen MOPED in action already. The development of Majordomo in [#reliable-request-reply] is a near-perfect case. But cute names are worth a thousand words.\n\nThe goal of MOPED is to define a process by which we can take a rough use case for a new distributed application, and go from \"Hello World\" to fully-working prototype in any language in under a week.\n\nUsing MOPED, you grow, more than build, a working ZeroMQ architecture from the ground-up with minimal risk of failure. By focusing on the contracts rather than the implementations, you avoid the risk of premature optimization. By driving the design process through ultra-short test-based cycles, you can be more certain that what you have works before you add more.\n\nWe can turn this into five real steps:\n\n* Step 1: internalize the ZeroMQ semantics.\n* Step 2: draw a rough architecture.\n* Step 3: decide on the contracts.\n* Step 4: make a minimal end-to-end solution.\n* Step 5: solve one problem and repeat.\n\n+++ Step 1: Internalize the Semantics\n\nYou must learn and digest ZeroMQ's \"language\", that is, the socket patterns and how they work. The only way to learn a language is to use it. There's no way to avoid this investment, no tapes you can play while you sleep, no chips you can plug in to magically become smarter. Read this book from the start, work through the code examples in whatever language you prefer, understand what's going on, and (most importantly) write some examples yourself and then throw them away.\n\nAt a certain point, you'll feel a clicking noise in your brain. Maybe you'll have a weird chili-induced dream where little ZeroMQ tasks run around trying to eat you alive. Maybe you'll just think \"aaahh, so //that's// what it means!\" If we did our work right, it should take two to three days. However long it takes, until you start thinking in terms of ZeroMQ sockets and patterns, you're not ready for step 2.\n\n+++ Step 2: Draw a Rough Architecture\n\nFrom my experience, it's essential to be able to draw the core of your architecture. It helps others understand what you are thinking, and it also helps you think through your ideas. There is really no better way to design a good architecture than to explain your ideas to your colleagues, using a whiteboard.\n\nYou don't need to get it right, and you don't need to make it complete. What you do need to do is break your architecture into pieces that make sense. The nice thing about software architecture (as compared to constructing bridges) is that you really can replace entire layers cheaply if you've isolated them.\n\nStart by choosing the core problem that you are going to solve. Ignore anything that's not essential to that problem: you will add it in later. The problem should be an end-to-end problem: the rope across the gorge.\n\nFor example, a client asked us to make a supercomputing cluster with ZeroMQ. Clients create bundles of work, which are sent to a broker that distributes them to workers (running on fast graphics processors), collects the results back, and returns them to the client.\n\nThe rope across the gorge is one client talking to a broker talking to one worker. We draw three boxes: client, broker, worker. We draw arrows from box to box showing the request flowing one way and the response flowing back. It's just like the many diagrams we saw in earlier chapters.\n\nBe minimalistic. Your goal is not to define a //real// architecture, but to throw a rope across the gorge to bootstrap your process. We make the architecture successfully more complete and realistic over time: e.g., adding multiple workers, adding client and worker APIs, handling failures, and so on.\n\n+++ Step 3: Decide on the Contracts\n\nA good software architecture depends on contracts, and the more explicit they are, the better things scale. You don't care //how// things happen; you only care about the results. If I send an email, I don't care how it arrives at its destination, as long as the contract is respected. The email contract is: it arrives within a few minutes, no-one modifies it, and it doesn't get lost.\n\nAnd to build a large system that works well, you must focus on the contracts before the implementations. It may sound obvious but all too often, people forget or ignore this, or are just too shy to impose themselves. I wish I could say ZeroMQ had done this properly, but for years our public contracts were second-rate afterthoughts instead of primary in-your-face pieces of work.\n\nSo what is a contract in a distributed system? There are, in my experience, two types of contract:\n\n* The APIs to client applications. Remember the Psychological Elements. The APIs need to be as absolutely //simple//, //consistent//, and //familiar// as possible. Yes, you can generate API documentation from code, but you must first design it, and designing an API is often hard.\n\n* The protocols that connect the pieces. It sounds like rocket science, but it's really just a simple trick, and one that ZeroMQ makes particularly easy. In fact they're so simple to write, and need so little bureaucracy that I call them //unprotocols//.\n\nYou write minimal contracts that are mostly just place markers. Most messages and most API methods will be missing or empty. You also want to write down any known technical requirements in terms of throughput, latency, reliability, and so on. These are the criteria on which you will accept or reject any particular piece of work.\n\n+++ Step 4: Write a Minimal End-to-End Solution\n\nThe goal is to test out the overall architecture as rapidly as possible. Make skeleton applications that call the APIs, and skeleton stacks that implement both sides of every protocol. You want to get a working end-to-end \"Hello World\" as soon as you can. You want to be able to test code as you write it, so that you can weed out the broken assumptions and inevitable errors you make. Do not go off and spend six months writing a test suite! Instead, make a minimal bare-bones application that uses our still-hypothetical API.\n\nIf you design an API wearing the hat of the person who implements it, you'll start to think of performance, features, options, and so on. You'll make it more complex, more irregular, and more surprising than it should be. But, and here's the trick (it's a cheap one, was big in Japan): if you design an API while wearing the hat of the person who has to actually write apps that use it, you use all that laziness and fear to your advantage.\n\nWrite down the protocols on a wiki or shared document in such a way that you can explain every command clearly without too much detail. Strip off any real functionality, because it will only create inertia that makes it harder to move stuff around. You can always add weight. Don't spend effort defining formal message structures: pass the minimum around in the simplest possible fashion using ZeroMQ's multipart framing.\n\nOur goal is to get the simplest test case working, without any avoidable functionality. Everything you can chop off the list of things to do, you chop. Ignore the groans from colleagues and bosses. I'll repeat this once again: you can //always// add functionality, that's relatively easy. But aim to keep the overall weight to a minimum.\n\n+++ Step 5: Solve One Problem and Repeat\n\nYou're now in the happy cycle of issue-driven development where you can start to solve tangible problems instead of adding features. Write issues that each state a clear problem, and propose a solution. As you design the API, keep in mind your standards for names, consistency, and behavior. Writing these down in prose often helps keep them sane.\n\nFrom here, every single change you make to the architecture and code can be proven by running the test case, watching it not work, making the change, and then watching it work.\n\nNow you go through the whole cycle (extending the test case, fixing the API, updating the protocol, and extending the code, as needed), taking problems one at a time and testing the solutions individually. It should take about 10-30 minutes for each cycle, with the occasional spike due to random confusion.\n\n++ Unprotocols\n\n+++ Protocols Without The Goats\n\nWhen this man thinks of protocols, this man thinks of massive documents written by committees, over years. This man thinks of the IETF, W3C, ISO, Oasis, regulatory capture, FRAND patent license disputes, and soon after, this man thinks of retirement to a nice little farm in northern Bolivia up in the mountains where the only other needlessly stubborn beings are the goats chewing up the coffee plants.\n\nNow, I've nothing personal against committees. The useless folk need a place to sit out their lives with minimal risk of reproducing; after all, that only seems fair. But most committee protocols tend towards complexity (the ones that work), or trash (the ones we don't talk about). There's a few reasons for this. One is the amount of money at stake. More money means more people who want their particular prejudices and assumptions expressed in prose. But two is the lack of good abstractions on which to build. People have tried to build reusable protocol abstractions, like BEEP. Most did not stick, and those that did, like SOAP and XMPP, are on the complex side of things.\n\nIt used to be, decades ago, when the Internet was a young modest thing, that protocols were short and sweet. They weren't even \"standards\", but \"requests for comments\", which is as modest as you can get. It's been one of my goals since we started iMatix in 1995 to find a way for ordinary people like me to write small, accurate protocols without the overhead of the committees.\n\nNow, ZeroMQ does appear to provide a living, successful protocol abstraction layer with its \"we'll carry multipart messages over random transports\" way of working. Because ZeroMQ deals silently with framing, connections, and routing, it's surprisingly easy to write full protocol specs on top of ZeroMQ, and in [#reliable-request-reply] and [#advanced-pub-sub] I showed how to do this.\n\nSomewhere around mid-2007, I kicked off the Digital Standards Organization to define new simpler ways of producing little standards, protocols, and specifications. In my defense, it was a quiet summer. At the time, I wrote that a new specification should take [http://www.digistan.org/spec:1 \"minutes to explain, hours to design, days to write, weeks to prove, months to become mature, and years to replace.\"]\n\nIn 2010, we started calling such little specifications //unprotocols//, which some people might mistake for a dastardly plan for world domination by a shadowy international organization, but which really just means \"protocols without the goats\".\n\n+++ Contracts Are Hard\n\nWriting contracts is perhaps the most difficult part of large-scale architecture. With unprotocols, we remove as much of the unnecessary friction as possible. What remains is still a hard set of problems to solve. A good contract (be it an API, a protocol, or a rental agreement) has to be simple, unambiguous, technically sound, and easy to enforce.\n\nLike any technical skill, it's something you have to learn and practice. There are a series of specifications on the\n[http://rfc.zeromq.org ZeroMQ RFC site], which are worth reading and using them as a basis for your own specifications when you find yourself in need.\n\nI'll try to summarize my experience as a protocol writer:\n\n* Start simple, and develop your specifications step-by-step. Don't solve problems you don't have in front of you.\n\n* Use very clear and consistent language. A protocol may often break down into commands and fields; use clear short names for these entities.\n\n* Try to avoid inventing concepts. Reuse anything you can from existing specifications. Use terminology that is obvious and clear to your audience.\n\n* Make //nothing// for which you cannot demonstrate an immediate need. Your specification solves problems; it does not provide features. Make the simplest plausible solution for each problem that you identify.\n\n* Implement your protocol //as you build it//, so that you are aware of the technical consequences of each choice. Use a language that makes it hard (like C) and not one that makes it easy (like Python).\n\n* Test your specification //as you build it// on other people. Your best feedback on a specification is when someone else tries to implement it without the assumptions and knowledge that you have in your head.\n\n* Cross-test rapidly and consistently, throwing others' clients against your servers and vice versa.\n\n* Be prepared to throw it out and start again as often as needed. Plan for this, by layering your architecture so that e.g., you can keep an API but change the underlying protocols.\n\n* Only use constructs that are independent of programming language and operating system.\n\n* Solve a large problem in layers, making each layer an independent specification. Beware of creating monolithic protocols. Think about how reusable each layer is. Think about how different teams could build competing specifications at each layer.\n\nAnd above all, //write it down//. Code is not a specification. The point about a written specification is that no matter how weak it is, it can be systematically improved. By writing down a specification, you will also spot inconsistencies and gray areas that are impossible to see in code.\n\nIf this sounds hard, don't worry too much. One of the less obvious benefits of using ZeroMQ is that it cuts the effort necessary to write a protocol spec by perhaps 90% or more because it already handles framing, routing, queuing, and so on. This means that you can experiment rapidly, make mistakes cheaply, and thus learn rapidly.\n\n+++ How to Write Unprotocols\n\nWhen you start to write an unprotocol specification document, stick to a consistent structure so that your readers know what to expect. Here is the structure I use:\n\n* Cover section: with a 1-line summary, URL to the spec, formal name, version, who to blame.\n* License for the text: absolutely needed for public specifications.\n* The change process: i.e., how can I as a reader fix problems in the specification?\n* Use of language: MUST, MAY, SHOULD, and so on, with a reference to RFC 2119.\n* Maturity indicator: is this an experimental, draft, stable, legacy, or retired?\n* Goals of the protocol: what problems is it trying to solve?\n* Formal grammar: prevents arguments due to different interpretations of the text.\n* Technical explanation: semantics of each message, error handling, and so on.\n* Security discussion: explicitly, how secure the protocol is.\n* References: to other documents, protocols, and so on.\n\nWriting clear, expressive text is hard. Do avoid trying to describe implementations of the protocol. Remember that you're writing a contract. You describe in clear language the obligations and expectations of each party, the level of obligation, and the penalties for breaking the rules. You do not try to define //how// each party honors its part of the deal.\n\nHere are some key points about unprotocols:\n\n* As long as your process is open, then you don't need a committee: just make clean minimal designs and make sure anyone is free to improve them.\n\n* If use an existing license, then you don't have legal worries afterwards. I use GPLv3 for my public specifications and advise you to do the same. For in-house work, standard copyright is perfect.\n\n* Formality is valuable. That is, learn to write a formal grammar such as ABNF (Augmented Backus-Naur Form) and use this to fully document your messages.\n\n* Use a market-driven life cycle process like [http://www.digistan.org/spec:1 Digistan's COSS] so that people place the right weight on your specs as they mature (or don't).\n\n+++ Why use the GPLv3 for Public Specifications?\n\nThe license you choose is particularly crucial for public specifications. Traditionally, protocols are published under custom licenses, where the authors own the text and derived works are forbidden. This sounds great (after all, who wants to see a protocol forked?), but it's in fact highly risky. A protocol committee is vulnerable to capture, and if the protocol is important and valuable, the incentive for capture grows.\n\nOnce captured, like some wild animals, an important protocol will often die. The real problem is that there's no way to //free// a captive protocol published under a conventional license. The word \"free\" isn't just an adjective to describe speech or air, it's also a verb, and the right to fork a work //against the wishes of the owner// is essential to avoiding capture.\n\nLet me explain this in shorter words. Imagine that iMatix writes a protocol today that's really amazing and popular. We publish the spec and many people implement it. Those implementations are fast and awesome, and free as in beer. They start to threaten an existing business. Their expensive commercial product is slower and can't compete. So one day they come to our iMatix office in Maetang-Dong, South Korea, and offer to buy our firm. Because we're spending vast amounts on sushi and beer, we accept gratefully. With evil laughter, the new owners of the protocol stop improving the public version, close the specification, and add patented extensions. Their new products support this new protocol version, but the open source versions are legally blocked from doing so. The company takes over the whole market, and competition ends.\n\nWhen you contribute to an open source project, you really want to know your hard work won't be used against you by a closed source competitor. This is why the GPL beats the \"more permissive\" BSD/MIT/X11 licenses for most contributors. These licenses give permission to cheat. This applies just as much to protocols as to source code.\n\nWhen you implement a GPLv3 specification, your applications are of course yours, and licensed any way you like. But you can be certain of two things. One, that specification will //never// be embraced and extended into proprietary forms. Any derived forms of the specification must also be GPLv3. Two, no one who ever implements or uses the protocol will ever launch a patent attack on anything it covers, nor can they add their patented technology to it without granting the world a free license.\n\n+++ Using ABNF\n\nMy advice when writing protocol specs is to learn and use a formal grammar. It's just less hassle than allowing others to interpret what you mean, and then recover from the inevitable false assumptions. The target of your grammar is other people, engineers, not compilers.\n\nMy favorite grammar is ABNF, as defined by [http://www.ietf.org/rfc/rfc2234.txt RFC 2234], because it is probably the simplest and most widely used formal language for defining bidirectional communications protocols. Most IETF (Internet Engineering Task Force) specifications use ABNF, which is good company to be in.\n\nI'll give a 30-second crash course in writing ABNF. It may remind you of regular expressions. You write the grammar as rules. Each rule takes the form \"name = elements\". An element can be another rule (which you define below as another rule) or a pre-defined //terminal// like {{CRLF}}, {{OCTET}}, or a number. [http://www.ietf.org/rfc/rfc2234.txt The RFC] lists all the terminals. To define alternative elements, separate with a slash. To define repetition, use an asterisk. To group elements, use parentheses. Read the RFC because it's not intuitive.\n\nI'm not sure if this extension is proper, but I then prefix elements with \"C:\" and \"S:\" to indicate whether they come from the client or server.\n\nHere's a piece of ABNF for an unprotocol called NOM that we'll come back to later in this chapter:\n\n[[code]]\nnom-protocol    = open-peering *use-peering\n\nopen-peering    = C:OHAI ( S:OHAI-OK / S:WTF )\n\nuse-peering     = C:ICANHAZ\n                / S:CHEEZBURGER\n                / C:HUGZ S:HUGZ-OK\n                / S:HUGZ C:HUGZ-OK\n[[/code]]\n\nI've actually used these keywords ({{OHAI}}, {{WTF}}) in commercial projects. They make developers giggly and happy. They confuse management. They're good in first drafts that you want to throw away later.\n\n+++ The Cheap or Nasty Pattern\n\nThere is a general lesson I've learned over a couple of decades of writing protocols small and large. I call this the //Cheap or Nasty// pattern: you can often split your work into two aspects or layers and solve these separately--one using a \"cheap\" approach, the other using a \"nasty\" approach.\n\nThe key insight to making Cheap or Nasty work is to realize that many protocols mix a low-volume chatty part for control, and a high-volume asynchronous part for data. For instance, HTTP has a chatty dialog to authenticate and get pages, and an asynchronous dialog to stream data. FTP actually splits this over two ports; one port for control and one port for data.\n\nProtocol designers who don't separate control from data tend to make horrid protocols, because the trade-offs in the two cases are almost totally opposed. What is perfect for control is bad for data, and what's ideal for data just doesn't work for control. It's especially true when we want high performance at the same time as extensibility and good error checking.\n\nLet's break this down using a classic client/server use case. The client connects to the server and authenticates. It then asks for some resource. The server chats back, then starts to send data back to the client. Eventually, the client disconnects or the server finishes, and the conversation is over.\n\nNow, before starting to design these messages, stop and think, and let's compare the control dialog and the data flow:\n\n* The control dialog lasts a short time and involves very few messages. The data flow could last for hours or days, and involve billions of messages.\n\n* The control dialog is where all the \"normal\" errors happen, e.g., not authenticated, not found, payment required, censored, and so on. In contrast, any errors that happen during the data flow are exceptional (disk full, server crashed).\n\n* The control dialog is where things will change over time as we add more options, parameters, and so on. The data flow should barely change over time because the semantics of a resource are fairly constant over time.\n\n* The control dialog is essentially a synchronous request/reply dialog. The data flow is essentially a one-way asynchronous flow.\n\nThese differences are critical. When we talk about performance, it applies //only// to data flows. It's pathological to design a one-time control dialog to be fast. Thus when we talk about the cost of serialization, this only applies to the data flow. The cost of encoding/decoding the control flow could be huge, and for many cases it would not change a thing. So we encode control using Cheap, and we encode data flows using Nasty.\n\nCheap is essentially synchronous, verbose, descriptive, and flexible. A Cheap message is full of rich information that can change for each application. Your goal as designer is to make this information easy to encode and parse, trivial to extend for experimentation or growth, and highly robust against change both forwards and backwards. The Cheap part of a protocol looks like this:\n\n* It uses a simple self-describing structured encoding for data, be it XML, JSON, HTTP-style headers, or some other. Any encoding is fine as long as there are standard simple parsers for it in your target languages.\n\n* It uses a straight request-reply model where each request has a success/failure reply. This makes it trivial to write correct clients and servers for a Cheap dialog.\n\n* It doesn't try, even marginally, to be fast. Performance doesn't matter when you do something only once or a few times per session.\n\nA Cheap parser is something you take off the shelf and throw data at. It shouldn't crash, shouldn't leak memory, should be highly tolerant, and should be relatively simple to work with. That's it.\n\nNasty however is essentially asynchronous, terse, silent, and inflexible. A Nasty message carries minimal information that practically never changes. Your goal as designer is to make this information ultrafast to parse, and possibly even impossible to extend and experiment with. The ideal Nasty pattern looks like this:\n\n* It uses a hand-optimized binary layout for data, where every bit is precisely crafted.\n\n* It uses a pure asynchronous model where one or both peers send data without acknowledgments (or if they do, they use sneaky asynchronous techniques like credit-based flow control).\n\n* It doesn't try, even marginally, to be friendly. Performance is all that matters when you are doing something several million times per second.\n\nA Nasty parser is something you write by hand, which writes or reads bits, bytes, words, and integers individually and precisely. It rejects anything it doesn't like, does no memory allocations at all, and never crashes.\n\nCheap or Nasty isn't a universal pattern; not all protocols have this dichotomy. Also, how you use Cheap or Nasty will depend on the situation. In some cases, it can be two parts of a single protocol. In other cases, it can be two protocols, one layered on top of the other.\n\n+++ Error Handling\n\nUsing Cheap or Nasty makes error handling rather simpler. You have two kinds of commands and two ways to signal errors:\n\n* Synchronous control commands: errors are normal: every request has a response that is either OK or an error response.\n* Asynchronous data commands: errors are exceptional: bad commands are either discarded silently, or cause the whole connection to be closed.\n\nIt's usually good to distinguish a few kinds of errors, but as always keep it minimal and add only what you need. \n\n++ Serializing Your Data\n\nWhen we start to design a protocol, one of the first questions we face is how we encode data on the wire. There is no universal answer. There are a half-dozen different ways to serialize data, each with pros and cons. We'll explore some of these.\n\n+++ Abstraction Level\n\nBefore looking at how to put data onto the wire, it's worth asking what data we actually want to exchange between applications. If we don't use any abstraction, we literally serialize and deserialize our internal state. That is, the objects and structures we use to implement our functionality.\n\nPutting internal state onto the wire is however a really bad idea. It's like exposing internal state in an API. When you do this, you are hard-coding your implementation decisions into your protocols. You are also going to produce protocols that are significantly more complex than they need to be.\n\nIt's perhaps the main reason so many older protocols and APIs are so complex: their designers did not think about how to abstract them into simpler concepts. There is of course no guarantee than an abstraction will be //simpler//; that's where the hard work comes in.\n\nA good protocol or API abstraction encapsulates natural patterns of use, and gives them name and properties that are predictable and regular. It chooses sensible defaults so that the main use cases can be specified minimally. It aims to be simple for the simple cases, and expressive for the rarer complex cases. It does not make any statements or assumptions about the internal implementation unless that is absolutely needed for interoperability.\n\n+++ ZeroMQ Framing\n\nThe simplest and most widely used serialization format for ZeroMQ applications is ZeroMQ's own multipart framing. For example, here is how the [http://rfc.zeromq.org/spec:7 Majordomo Protocol] defines a request:\n\n[[code]]\nFrame 0: Empty frame\nFrame 1: \"MDPW01\" (six bytes, representing MDP/Worker v0.1)\nFrame 2: 0x02 (one byte, representing REQUEST)\nFrame 3: Client address (envelope stack)\nFrame 4: Empty (zero bytes, envelope delimiter)\nFrames 5+: Request body (opaque binary)\n[[/code]]\n\nTo read and write this in code is easy, but this is a classic example of a control flow (the whole of MDP is really, as it's a chatty request-reply protocol). When we came to improve MDP for the second version, we had to change this framing. Excellent, we broke all existing implementations!\n\nBackwards compatibility is hard, but using ZeroMQ framing for control flows //does not help//. Here's how I should have designed this protocol if I'd followed my own advice (and I'll fix this in the next version). It's split into a Cheap part and a Nasty part, and uses the ZeroMQ framing to separate these:\n\n[[code]]\nFrame 0: \"MDP/2.0\" for protocol name and version\nFrame 1: command header\nFrame 2: command body\n[[/code]]\n\nWhere we'd expect to parse the command header in the various intermediaries (client API, broker, and worker API), and pass the command body untouched from application to application.\n\n+++ Serialization Languages\n\nSerialization languages have their fashions. XML used to be big as in popular, then it got big as in over-engineered, and then it fell into the hands of \"Enterprise Information Architects\" and it's not been seen alive since. Today's XML is the epitome of \"somewhere in that mess is a small, elegant language trying to escape\".\n\nStill XML was way, way better than its predecessors, which included such monsters as the Standard Generalized Markup Language (SGML), which in turn was a cool breeze compared to mind-torturing beasts like EDIFACT. So the history of serialization languages seems to be of gradually emerging sanity, hidden by waves of revolting EIAs doing their best to hold onto their jobs.\n\nJSON popped out of the JavaScript world as a quick-and-dirty \"I'd rather resign than use XML here\" way to throw data onto the wire and get it back again. JSON is just minimal XML expressed, sneakily, as JavaScript source code.\n\nHere's a simple example of using JSON in a Cheap protocol:\n\n[[code]]\n\"protocol\": {\n    \"name\": \"MTL\",\n    \"version\": 1\n},\n\"virtual-host\": \"test-env\"\n[[/code]]\n\nThe same data in XML would be (XML forces us to invent a single top-level entity):\n\n[[code]]\n<command>\n    <protocol name = \"MTL\" version = \"1\" />\n    <virtual-host>test-env</virtual-host>\n</command>\n[[/code]]\n\nAnd here it is using plain-old HTTP-style headers:\n\n[[code]]\nProtocol: MTL/1.0\nVirtual-host: test-env\n[[/code]]\n\nThese are all pretty equivalent as long as you don't go overboard with validating parsers, schemas, and other \"trust us, this is all for your own good\" nonsense. A Cheap serialization language gives you space for experimentation for free (\"ignore any elements/attributes/headers that you don't recognize\"), and it's simple to write generic parsers that, for example, thunk a command into a hash table, or vice versa.\n\nHowever, it's not all roses. While modern scripting languages support JSON and XML easily enough, older languages do not. If you use XML or JSON, you create nontrivial dependencies. It's also somewhat of a pain to work with tree-structured data in a language like C.\n\nSo you can drive your choice according to the languages for which you're aiming. If your universe is a scripting language, then go for JSON. If you are aiming to build protocols for wider system use, keep things simple for C developers and stick to HTTP-style headers.\n\n+++ Serialization Libraries\n\nThe {{msgpack.org}} site says:\n\n> It's like JSON, but fast and small. MessagePack is an efficient binary serialization format. It lets you exchange data among multiple languages like JSON, but it's faster and smaller. For example, small integers (like flags or error code) are encoded into a single byte, and typical short strings only require an extra byte in addition to the strings themselves.\n\nI'm going to make the perhaps unpopular claim that \"fast and small\" are features that solve non-problems. The only real problem that serialization libraries solve is, as far as I can tell, the need to document the message contracts and actually serialize data to and from the wire.\n\nLet's start by debunking \"fast and small\". It's based on a two-part argument. First, that making your messages smaller and reducing CPU cost for encoding and decoding will make a significant difference to your application's performance. Second, that this equally valid across-the-board to all messages.\n\nBut most real applications tend to fall into one of two categories. Either the speed of serialization and size of encoding is marginal compared to other costs, such as database access or application code performance. Or, network performance really is critical, and then all significant costs occur in a few specific message types.\n\nThus, aiming for \"fast and small\" across the board is a false optimization. You neither get the easy flexibility of Cheap for your infrequent control flows, nor do you get the brutal efficiency of Nasty for your high-volume data flows. Worse, the assumption that all messages are equal in some way can corrupt your protocol design. Cheap or Nasty isn't only about serialization strategies, it's also about synchronous versus asynchronous, error handling and the cost of change.\n\nMy experience is that most performance problems in message-based applications can be solved by (a) improving the application itself and (b) hand-optimizing the high-volume data flows. And to hand-optimize your most critical data flows, you need to cheat; to learn exploit facts about your data, something general purpose serializers cannot do.\n\nNow let's address documentation and the need to write our contracts explicitly and formally, rather than only in code. This is a valid problem to solve, indeed one of the main ones if we're to build a long-lasting, large-scale message-based architecture.\n\nHere is how we describe a typical message using the MessagePack interface definition language (IDL):\n\n[[code]]\nmessage Person {\n  1: string surname\n  2: string firstname\n  3: optional string email\n}\n[[/code]]\n\nNow, the same message using the Google protocol buffers IDL:\n\n[[code]]\nmessage Person {\n  required string surname = 1;\n  required string firstname = 2;\n  optional string email = 3;\n}\n[[/code]]\n\nIt works, but in most practical cases wins you little over a serialization language backed by decent specifications written by hand or produced mechanically (we'll come to this). The price you'll pay is an extra dependency and quite probably, worse overall performance than if you used Cheap or Nasty.\n\n+++ Handwritten Binary Serialization\n\nAs you'll gather from this book, my preferred language for systems programming is C (upgraded to C99, with a constructor/destructor API model and generic containers). There are two reasons I like this modernized C language. First, I'm too weak-minded to learn a big language like C++. Life just seems filled with more interesting things to understand. Second, I find that this specific level of manual control lets me produce better results, faster.\n\nThe point here isn't C versus C++, but the value of manual control for high-end professional users. It's no accident that the best cars, cameras, and espresso machines in the world have manual controls. That level of on-the-spot fine tuning often makes the difference between world class success, and being second best.\n\nWhen you are really, truly concerned about the speed of serialization and/or the size of the result (often these contradict each other), you need handwritten binary serialization. In other words, let's hear it for Mr. Nasty!\n\nYour basic process for writing an efficient Nasty encoder/decoder (codec) is:\n\n* Build representative data sets and test applications that can stress test your codec.\n* Write a first dumb version of the codec.\n* Test, measure, improve, and repeat until you run out of time and/or money.\n\nHere are some of the techniques we use to make our codecs better:\n\n* //Use a profiler.// There's simply no way to know what your code is doing until you've profiled it for function counts and for CPU cost per function. When you find your hot spots, fix them.\n\n* //Eliminate memory allocations.// The heap is very fast on a modern Linux kernel, but it's still the bottleneck in most naive codecs. On older kernels, the heap can be tragically slow. Use local variables (the stack) instead of the heap where you can.\n\n* //Test on different platforms and with different compilers and compiler options.// Apart from the heap, there are many other differences. You need to learn the main ones, and allow for them.\n\n* //Use state to compress better.// If you are concerned about codec performance, you are almost definitely sending the same kinds of data many times. There will be redundancy between instances of data. You can detect these and use that to compress (e.g., a short value that means \"same as last time\").\n\n* //Know your data.// The best compression techniques (in terms of CPU cost for compactness) require knowing about the data. For example, the techniques used to compress a word list, a video, and a stream of stock market data are all different.\n\n* //Be ready to break the rules.// Do you really need to encode integers in big-endian network byte order? x86 and ARM account for almost all modern CPUs, yet use little-endian (ARM is actually bi-endian but Android, like Windows and iOS, is little-endian).\n\n+++ Code Generation\n\nReading the previous two sections, you might have wondered, \"could I write my own IDL generator that was better than a general purpose one?\" If this thought wandered into your mind, it probably left pretty soon after, chased by dark calculations about how much work that actually involved.\n\nWhat if I told you of a way to build custom IDL generators cheaply and quickly? You can have a way to get perfectly documented contracts, code that is as evil and domain-specific as you need it to be, and all you need to do is sign away your soul (//who ever really used that, am I right?//) just here...\n\nAt iMatix, until a few years ago, we used code generation to build ever larger and more ambitious systems until we decided the technology (GSL) was too dangerous for common use, and we sealed the archive and locked it with heavy chains in a deep dungeon. We actually posted it on GitHub. If you want to try the examples that are coming up, grab [https://github.com/imatix/gsl the repository] and build yourself a {{gsl}} command. Typing \"make\" in the src subdirectory should do it (and if you're that guy who loves Windows, I'm sure you'll send a patch with project files).\n\nThis section isn't really about GSL at all, but about a useful and little-known trick that's useful for ambitious architects who want to scale themselves, as well as their work. Once you learn the trick, you can whip up your own code generators in a short time. The code generators most software engineers know about come with a single hard-coded model. For instance, Ragel \"compiles executable finite state machines from regular languages\", i.e., Ragel's model is a regular language. This certainly works for a good set of problems, but it's far from universal. How do you describe an API in Ragel? Or a project makefile? Or even a finite-state machine like the one we used to design the Binary Star pattern in [#reliable-request-reply]?\n\nAll these would benefit from code generation, but there's no universal model. So the trick is to design your own models as you need them, and then make code generators as cheap compilers for that model. You need some experience in how to make good models, and you need a technology that makes it cheap to build custom code generators. A scripting language, like Perl and Python, is a good option. However, we actually built GSL specifically for this, and that's what I prefer.\n\nLet's take a simple example that ties into what we already know. We'll see more extensive examples later, because I really do believe that code generation is crucial knowledge for large-scale work. In [#reliable-request-reply], we developed the [http://rfc.zeromq.org/spec:7 Majordomo Protocol (MDP)], and wrote clients, brokers, and workers for that. Now could we generate those pieces mechanically, by building our own interface description language and code generators?\n\nWhen we write a GSL model, we can use //any// semantics we like, in other words we can invent domain-specific languages on the spot. I'll invent a couple--see if you can guess what they represent:\n\n[[code]]\nslideshow\n    name = Cookery level 3\n    page\n        title = French Cuisine\n        item = Overview\n        item = The historical cuisine\n        item = The nouvelle cuisine\n        item = Why the French live longer\n    page\n        title = Overview\n        item = Soups and salads\n        item = Le plat principal\n        item = Béchamel and other sauces\n        item = Pastries, cakes, and quiches\n        item = Soufflé: cheese to strawberry\n[[/code]]\n\nHow about this one:\n\n[[code]]\ntable\n    name = person\n    column\n        name = firstname\n        type = string\n    column\n        name = lastname\n        type = string\n    column\n        name = rating\n        type = integer\n[[/code]]\n\nWe could compile the first into a presentation. The second, we could compile into SQL to create and work with a database table. So for this exercise, our domain language, our //model//, consists of \"classes\" that contain \"messages\" that contain \"fields\" of various types. It's deliberately familiar. Here is the MDP client protocol:\n\n[[code]]\n<class name = \"mdp_client\">\n    MDP/Client\n    <header>\n        <field name = \"empty\" type = \"string\" value = \"\"\n            >Empty frame</field>\n        <field name = \"protocol\" type = \"string\" value = \"MDPC01\"\n            >Protocol identifier</field>\n    </header>\n    <message name = \"request\">\n        Client request to broker\n        <field name = \"service\" type = \"string\">Service name</field>\n        <field name = \"body\" type = \"frame\">Request body</field>\n    </message>\n    <message name = \"reply\">\n        Response back to client\n        <field name = \"service\" type = \"string\">Service name</field>\n        <field name = \"body\" type = \"frame\">Response body</field>\n    </message>\n</class>\n[[/code]]\n\nAnd here is the MDP worker protocol:\n\n[[code]]\n<class name = \"mdp_worker\">\n    MDP/Worker\n    <header>\n        <field name = \"empty\" type = \"string\" value = \"\"\n            >Empty frame</field>\n        <field name = \"protocol\" type = \"string\" value = \"MDPW01\"\n            >Protocol identifier</field>\n        <field name = \"id\" type = \"octet\">Message identifier</field>\n    </header>\n    <message name = \"ready\" id = \"1\">\n        Worker tells broker it is ready\n        <field name = \"service\" type = \"string\">Service name</field>\n    </message>\n    <message name = \"request\" id = \"2\">\n        Client request to broker\n        <field name = \"client\" type = \"frame\">Client address</field>\n        <field name = \"body\" type = \"frame\">Request body</field>\n    </message>\n    <message name = \"reply\" id = \"3\">\n        Worker returns reply to broker\n        <field name = \"client\" type = \"frame\">Client address</field>\n        <field name = \"body\" type = \"frame\">Request body</field>\n    </message>\n    <message name = \"hearbeat\" id = \"4\">\n        Either peer tells the other it's still alive\n    </message>\n    <message name = \"disconnect\" id = \"5\">\n        Either peer tells other the party is over\n    </message>\n</class>\n[[/code]]\n\nGSL uses XML as its modeling language. XML has a poor reputation, having been dragged through too many enterprise sewers to smell sweet, but it has some strong positives, as long as you keep it simple. Any way to write a self-describing hierarchy of items and attributes would work.\n\nNow here is a short IDL generator written in GSL that turns our protocol models into documentation:\n\n[[code]]\n.#  Trivial IDL generator (specs.gsl)\n.#\n.output \"$(class.name).md\"\n## The $(string.trim (class.?''):left) Protocol\n.for message\n.   frames = count (class->header.field) + count (field)\n\nA $(message.NAME) command consists of a multipart message of $(frames)\nframes:\n\n.   for class->header.field\n.       if name = \"id\"\n* Frame $(item ()): 0x$(message.id:%02x) (1 byte, $(message.NAME))\n.       else\n* Frame $(item ()): \"$(value:)\" ($(string.length (\"$(value)\")) \\\nbytes, $(field.:))\n.       endif\n.   endfor\n.   index = count (class->header.field) + 1\n.   for field\n* Frame $(index): $(field.?'') \\\n.       if type = \"string\"\n(printable string)\n.       elsif type = \"frame\"\n(opaque binary)\n.           index += 1\n.       else\n.           echo \"E: unknown field type: $(type)\"\n.       endif\n.       index += 1\n.   endfor\n.endfor\n[[/code]]\n\nThe XML models and this script are in the subdirectory examples/models. To do the code generation, I give this command:\n\n[[code]]\ngsl -script:specs mdp_client.xml mdp_worker.xml\n[[/code]]\n\nHere is the Markdown text we get for the worker protocol:\n\n[[code]]\n## The MDP/Worker Protocol\n\nA READY command consists of a multipart message of 4 frames:\n\n* Frame 1: \"\" (0 bytes, Empty frame)\n* Frame 2: \"MDPW01\" (6 bytes, Protocol identifier)\n* Frame 3: 0x01 (1 byte, READY)\n* Frame 4: Service name (printable string)\n\nA REQUEST command consists of a multipart message of 5 frames:\n\n* Frame 1: \"\" (0 bytes, Empty frame)\n* Frame 2: \"MDPW01\" (6 bytes, Protocol identifier)\n* Frame 3: 0x02 (1 byte, REQUEST)\n* Frame 4: Client address (opaque binary)\n* Frame 6: Request body (opaque binary)\n\nA REPLY command consists of a multipart message of 5 frames:\n\n* Frame 1: \"\" (0 bytes, Empty frame)\n* Frame 2: \"MDPW01\" (6 bytes, Protocol identifier)\n* Frame 3: 0x03 (1 byte, REPLY)\n* Frame 4: Client address (opaque binary)\n* Frame 6: Request body (opaque binary)\n\nA HEARBEAT command consists of a multipart message of 3 frames:\n\n* Frame 1: \"\" (0 bytes, Empty frame)\n* Frame 2: \"MDPW01\" (6 bytes, Protocol identifier)\n* Frame 3: 0x04 (1 byte, HEARBEAT)\n\nA DISCONNECT command consists of a multipart message of 3 frames:\n\n* Frame 1: \"\" (0 bytes, Empty frame)\n* Frame 2: \"MDPW01\" (6 bytes, Protocol identifier)\n* Frame 3: 0x05 (1 byte, DISCONNECT)\n[[/code]]\n\nThis, as you can see, is close to what I wrote by hand in the original spec. Now, if you have cloned the {{zguide}} repository and you are looking at the code in {{examples/models}}, you can generate the MDP client and worker codecs. We pass the same two models to a different code generator:\n\n[[code]]\ngsl -script:codec_c mdp_client.xml mdp_worker.xml\n[[/code]]\n\nWhich gives us {{mdp_client}} and {{mdp_worker}} classes. Actually MDP is so simple that it's barely worth the effort of writing the code generator. The profit comes when we want to change the protocol (which we did for the standalone Majordomo project). You modify the protocol, run the command, and out pops more perfect code.\n\nThe {{codec_c.gsl}} code generator is not short, but the resulting codecs are much better than the handwritten code I originally put together for Majordomo. For instance, the handwritten code had no error checking and would die if you passed it bogus messages.\n\nI'm now going to explain the pros and cons of GSL-powered model-oriented code generation. Power does not come for free and one of the greatest traps in our business is the ability to invent concepts out of thin air. GSL makes this particularly easy, so it can be an equally dangerous tool.\n\n//Do not invent concepts//. The job of a designer is to remove problems, not add features.\n\nFirstly, I will lay out the advantages of model-oriented code generation:\n\n* You can create near-perfect abstractions that map to your real world. So, our protocol model maps 100% to the \"real world\" of Majordomo. This would be impossible without the freedom to tune and change the model in any way.\n* You can develop these perfect models quickly and cheaply.\n* You can generate //any// text output. From a single model, you can create documentation, code in any language, test tools--literally any output you can think of.\n* You can generate (and I mean this literally) //perfect// output because it's cheap to improve your code generators to any level you want.\n* You get a single source that combines specifications and semantics.\n* You can leverage a small team to a massive size. At iMatix, we produced the million-line OpenAMQ messaging product out of perhaps 85K lines of input models, including the code generation scripts themselves.\n\nNow let's look at the disadvantages:\n\n* You add tool dependencies to your project.\n* You may get carried away and create models for the pure joy of creating them.\n* You may alienate newcomers, who will see \"strange stuff\", from your work.\n* You may give people a strong excuse not to invest in your project.\n\nCynically, model-oriented abuse works great in environments where you want to produce huge amounts of perfect code that you can maintain with little effort and which //no one can ever take away from you.// Personally, I like to cross my rivers and move on. But if long-term job security is your thing, this is almost perfect.\n\nSo if you do use GSL and want to create open communities around your work, here is my advice:\n\n* Use it only where you would otherwise be writing tiresome code by hand.\n* Design natural models that are what people would expect to see.\n* Write the code by hand first so you know what to generate.\n* Do not overuse. Keep it simple! //Do not get too meta!!//\n* Introduce gradually into a project.\n* Put the generated code into your repositories.\n\nWe're already using GSL in some projects around ZeroMQ. For example, the high-level C binding, CZMQ, uses GSL to generate the socket options class ({{zsockopt}}). A 300-line code generator turns 78 lines of XML model into 1,500 lines of perfect, but really boring code. That's a good win.\n\n++ Transferring Files\n\nLet's take a break from the lecturing and get back to our first love and the reason for doing all of this: code.\n\n\"How do I send a file?\" is a common question on the ZeroMQ mailing lists. This should not be surprising, because file transfer is perhaps the oldest and most obvious type of messaging. Sending files around networks has lots of use cases apart from annoying the copyright cartels. ZeroMQ is very good out of the box at sending events and tasks, but less good at sending files.\n\nI've promised, for a year or two, to write a proper explanation. Here's a gratuitous piece of information to brighten your morning: the word \"proper\" comes from the archaic French //propre//, which means \"clean\". The dark age English common folk, not being familiar with hot water and soap, changed the word to mean \"foreign\" or \"upper-class\", as in \"that's proper food!\", but later the word came to mean just \"real\", as in \"that's a proper mess you've gotten us into!\"\n\nSo, file transfer. There are several reasons you can't just pick up a random file, blindfold it, and shove it whole into a message. The most obvious reason being that despite decades of determined growth in RAM sizes (and who among us old-timers doesn't fondly remember saving up for that 1024-byte memory extension card?!), disk sizes obstinately remain much larger. Even if we could send a file with one instruction (say, using a system call like sendfile), we'd hit the reality that networks are not infinitely fast nor perfectly reliable. After trying to upload a large file several times on a slow flaky network (WiFi, anyone?), you'll realize that a proper file transfer protocol needs a way to recover from failures. That is, it needs a way to send only the part of a file that wasn't yet received.\n\nFinally, after all this, if you build a proper file server, you'll notice that simply sending massive amounts of data to lots of clients creates that situation we like to call, in the technical parlance, \"server went belly-up due to all available heap memory being eaten by a poorly designed application\". A proper file transfer protocol needs to pay attention to memory use.\n\nWe'll solve these problems properly, one-by-one, which should hopefully get us to a good and proper file transfer protocol running over ZeroMQ. First, let's generate a 1GB test file with random data (real power-of-two-giga-like-Von-Neumman-intended, not the fake silicon ones the memory industry likes to sell):\n\n[[code]]\ndd if=/dev/urandom of=testdata bs=1M count=1024\n[[/code]]\n\nThis is large enough to be troublesome when we have lots of clients asking for the same file at once, and on many machines, 1GB is going to be too large to allocate in memory anyhow. As a base reference, let's measure how long it takes to copy this file from disk back to disk. This will tell us how much our file transfer protocol adds on top (including network costs):\n\n[[code]]\n$ time cp testdata testdata2\n\nreal    0m7.143s\nuser    0m0.012s\nsys     0m1.188s\n[[/code]]\n\nThe 4-figure precision is misleading; expect variations of 25% either way. This is just an \"order of magnitude\" measurement.\n\nHere's our first cut at the code, where the client asks for the test data and the server just sends it, without stopping for breath, as a series of messages, where each message holds one //chunk//:\n\n[[code type=\"example\" title=\"File transfer test, model 1\" name=\"fileio1\"]]\n[[/code]]\n\nIt's pretty simple, but we already run into a problem: if we send too much data to the ROUTER socket, we can easily overflow it. The simple but stupid solution is to put an infinite high-water mark on the socket. It's stupid because we now have no protection against exhausting the server's memory. Yet without an infinite HWM, we risk losing chunks of large files.\n\nTry this: set the HWM to 1,000 (in ZeroMQ v3.x this is the default) and then reduce the chunk size to 100K so we send 10K chunks in one go. Run the test, and you'll see it never finishes. As the {{zmq_socket[3]}} man page says with cheerful brutality, for the ROUTER socket: \"ZMQ_HWM option action: Drop\".\n\nWe have to control the amount of data the server sends up-front. There's no point in it sending more than the network can handle. Let's try sending one chunk at a time. In this version of the protocol, the client will explicitly say, \"Give me chunk N\", and the server will fetch that specific chunk from disk and send it.\n\nHere's the improved second model, where the client asks for one chunk at a time, and the server only sends one chunk for each request it gets from the client:\n\n[[code type=\"example\" title=\"File transfer test, model 2\" name=\"fileio2\"]]\n[[/code]]\n\nIt is much slower now, because of the to-and-fro chatting between client and server. We pay about 300 microseconds for each request-reply round-trip, on a local loop connection (client and server on the same box). It doesn't sound like much but it adds up quickly:\n\n[[code]]\n$ time ./fileio1\n4296 chunks received, 1073741824 bytes\n\nreal    0m0.669s\nuser    0m0.056s\nsys     0m1.048s\n\n$ time ./fileio2\n4295 chunks received, 1073741824 bytes\n\nreal    0m2.389s\nuser    0m0.312s\nsys     0m2.136s\n[[/code]]\n\nThere are two valuable lessons here. First, while request-reply is easy, it's also too slow for high-volume data flows. Paying that 300 microseconds once would be fine. Paying it for every single chunk isn't acceptable, particularly on real networks with latencies of perhaps 1,000 times higher.\n\nThe second point is something I've said before but will repeat: it's incredibly easy to experiment, measure, and improve a protocol over ZeroMQ. And when the cost of something comes way down, you can afford a lot more of it. Do learn to develop and prove your protocols in isolation: I've seen teams waste time trying to improve poorly designed protocols that are too deeply embedded in applications to be easily testable or fixable.\n\nOur model two file transfer protocol isn't so bad, apart from performance:\n\n* It completely eliminates any risk of memory exhaustion. To prove that, we set the high-water mark to 1 in both sender and receiver.\n* It lets the client choose the chunk size, which is useful because if there's any tuning of the chunk size to be done, for network conditions, for file types, or to reduce memory consumption further, it's the client that should be doing this.\n* It gives us fully restartable file transfers.\n* It allows the client to cancel the file transfer at any point in time.\n\nIf we just didn't have to do a request for each chunk, it'd be a usable protocol. What we need is a way for the server to send multiple chunks without waiting for the client to request or acknowledge each one. What are our choices?\n\n* The server could send 10 chunks at once, then wait for a single acknowledgment. That's exactly like multiplying the chunk size by 10, so it's pointless. And yes, it's just as pointless for all values of 10.\n\n* The server could send chunks without any chatter from the client but with a slight delay between each send, so that it would send chunks only as fast as the network could handle them. This would require the server to know what's happening at the network layer, which sounds like hard work. It also breaks layering horribly. And what happens if the network is really fast, but the client itself is slow? Where are chunks queued then?\n\n* The server could try to spy on the sending queue, i.e., see how full it is, and send only when the queue isn't full. Well, ZeroMQ doesn't allow that because it doesn't work, for the same reason as throttling doesn't work. The server and network may be more than fast enough, but the client may be a slow little device.\n\n* We could modify {{libzmq}} to take some other action on reaching HWM. Perhaps it could block? That would mean that a single slow client would block the whole server, so no thank you. Maybe it could return an error to the caller? Then the server could do something smart like... well, there isn't really anything it could do that's any better than dropping the message.\n\nApart from being complex and variously unpleasant, none of these options would even work. What we need is a way for the client to tell the server, asynchronously and in the background, that it's ready for more. We need some kind of asynchronous flow control. If we do this right, data should flow without interruption from the server to the client, but only as long as the client is reading it. Let's review our three protocols. This was the first one:\n\n[[code]]\nC: fetch\nS: chunk 1\nS: chunk 2\nS: chunk 3\n....\n[[/code]]\n\nAnd the second introduced a request for each chunk:\n\n[[code]]\nC: fetch chunk 1\nS: send chunk 1\nC: fetch chunk 2\nS: send chunk 2\nC: fetch chunk 3\nS: send chunk 3\nC: fetch chunk 4\n....\n[[/code]]\n\nNow--waves hands mysteriously--here's a changed protocol that fixes the performance problem:\n\n[[code]]\nC: fetch chunk 1\nC: fetch chunk 2\nC: fetch chunk 3\nS: send chunk 1\nC: fetch chunk 4\nS: send chunk 2\nS: send chunk 3\n....\n[[/code]]\n\nIt looks suspiciously similar. In fact, it's identical except that we send multiple requests without waiting for a reply for each one. This is a technique called \"pipelining\" and it works because our DEALER and ROUTER sockets are fully asynchronous.\n\nHere's the third model of our file transfer test-bench, with pipelining. The client sends a number of requests ahead (the \"credit\") and then each time it processes an incoming chunk, it sends one more credit. The server will never send more chunks than the client has asked for:\n\n[[code type=\"example\" title=\"File transfer test, model 3\" name=\"fileio3\"]]\n[[/code]]\n\nThat tweak gives us full control over the end-to-end pipeline including all network buffers and ZeroMQ queues at sender and receiver. We ensure the pipeline is always filled with data while never growing beyond a predefined limit. More than that, the client decides exactly when to send \"credit\" to the sender. It could be when it receives a chunk, or when it has fully processed a chunk. And this happens asynchronously, with no significant performance cost.\n\nIn the third model, I chose a pipeline size of 10 messages (each message is a chunk). This will cost a maximum of 2.5MB memory per client. So with 1GB of memory we can handle at least 400 clients. We can try to calculate the ideal pipeline size. It takes about 0.7 seconds to send the 1GB file, which is about 160 microseconds for a chunk. A round trip is 300 microseconds, so the pipeline needs to be at least 3-5 chunks to keep the server busy. In practice, I still got performance spikes with a pipeline of 5 chunks, probably because the credit messages sometimes get delayed by outgoing data. So at 10 chunks, it works consistently.\n\n[[code]]\n$ time ./fileio3\n4291 chunks received, 1072741824 bytes\n\nreal    0m0.777s\nuser    0m0.096s\nsys     0m1.120s\n[[/code]]\n\nDo measure rigorously. Your calculations may be good, but the real world tends to have its own opinions.\n\nWhat we've made is clearly not yet a real file transfer protocol, but it proves the pattern and I think it is the simplest plausible design. For a real working protocol, we might want to add some or all of:\n\n* Authentication and access controls, even without encryption: the point isn't to protect sensitive data, but to catch errors like sending test data to production servers.\n\n* A Cheap-style request including file path, optional compression, and other stuff we've learned is useful from HTTP (such as If-Modified-Since).\n\n* A Cheap-style response, at least for the first chunk, that provides meta data such as file size (so the client can pre-allocate, and avoid unpleasant disk-full situations).\n\n* The ability to fetch a set of files in one go, otherwise the protocol becomes inefficient for large sets of small files.\n\n* Confirmation from the client when it's fully received a file, to recover from chunks that might be lost if the client disconnects unexpectedly.\n\nSo far, our semantic has been \"fetch\"; that is, the recipient knows (somehow) that they need a specific file, so they ask for it. The knowledge of which files exist and where they are is then passed out-of-band (e.g., in HTTP, by links in the HTML page).\n\nHow about a \"push\" semantic? There are two plausible use cases for this. First, if we adopt a centralized architecture with files on a main \"server\" (not something I'm advocating, but people do sometimes like this), then it's very useful to allow clients to upload files to the server. Second, it lets us do a kind of pub-sub for files, where the client asks for all new files of some type; as the server gets these, it forwards them to the client.\n\nA fetch semantic is synchronous, while a push semantic is asynchronous. Asynchronous is less chatty, so faster. Also, you can do cute things like \"subscribe to this path\" thus creating a pub-sub file transfer architecture. That is so obviously awesome that I shouldn't need to explain what problem it solves.\n\nStill, here is the problem with the fetch semantic: that out-of-band route to tell clients what files exist. No matter how you do this, it ends up being complex. Either clients have to poll, or you need a separate pub-sub channel to keep clients up-to-date, or you need user interaction.\n\nThinking this through a little more, though, we can see that fetch is just a special case of pub-sub. So we can get the best of both worlds. Here is the general design:\n\n* Fetch this path\n* Here is credit (repeat)\n\nTo make this work (and we will, my dear readers), we need to be a little more explicit about how we send credit to the server. The cute trick of treating a pipelined \"fetch chunk\" request as credit won't fly because the client doesn't know any longer what files actually exist, how large they are, anything. If the client says, \"I'm good for 250,000 bytes of data\", this should work equally for 1 file of 250K bytes, or 100 files of 2,500 bytes.\n\nAnd this gives us \"credit-based flow control\", which effectively removes the need for high-water marks, and any risk of memory overflow.\n\n++ State Machines\n\nSoftware engineers tend to think of (finite) state machines as a kind of intermediary interpreter. That is, you take a regular language and compile that into a state machine, then execute the state machine. The state machine itself is rarely visible to the developer: it's an internal representation--optimized, compressed, and bizarre.\n\nHowever, it turns out that state machines are also valuable as a first-class modeling languages for protocol handlers, e.g., ZeroMQ clients and servers. ZeroMQ makes it rather easy to design protocols, but we've never defined a good pattern for writing those clients and servers properly.\n\nA protocol has at least two levels:\n\n* How we represent individual messages on the wire.\n* How messages flow between peers, and the significance of each message.\n\nWe've seen in this chapter how to produce codecs that handle serialization. That's a good start. But if we leave the second job to developers, that gives them a lot of room to interpret. As we make more ambitious protocols (file transfer + heartbeating + credit + authentication), it becomes less and less sane to try to implement clients and servers by hand.\n\nYes, people do this almost systematically. But the costs are high, and they're avoidable. I'll explain how to model protocols using state machines, and how to generate neat and solid code from those models.\n\nMy experience with using state machines as a software construction tool dates to 1985 and my first real job making tools for application developers. In 1991, I turned that knowledge into a free software tool called Libero, which spat out executable state machines from a simple text model.\n\nThe thing about Libero's model was that it was readable. That is, you described your program logic as named states, each accepting a set of events, each doing some real work. The resulting state machine hooked into your application code, driving it like a boss.\n\nLibero was charmingly good at its job, fluent in many languages, and modestly popular given the enigmatic nature of state machines. We used Libero in anger in dozens of large distributed applications, one of which was finally switched off in 2011 after 20 years of operation. State-machine driven code construction worked so well that it's somewhat impressive that this approach never hit the mainstream of software engineering.\n\nSo in this section I'm going to explain Libero's model, and demonstrate how to use it to generate ZeroMQ clients and servers. We'll use GSL again, but like I said, the principles are general and you can put together code generators using any scripting language.\n\nAs a worked example, let's see how to carry-on a stateful dialog with a peer on a ROUTER socket. We'll develop the server using a state machine (and the client by hand). We have a simple protocol that I'll call \"NOM\". I'm using the oh-so-very-serious [http://unprotocols.org/blog:2 keywords for unprotocols] proposal:\n\n[[code]]\nnom-protocol    = open-peering *use-peering\n\nopen-peering    = C:OHAI ( S:OHAI-OK / S:WTF )\n\nuse-peering     = C:ICANHAZ\n                / S:CHEEZBURGER\n                / C:HUGZ S:HUGZ-OK\n                / S:HUGZ C:HUGZ-OK\n[[/code]]\n\nI've not found a quick way to explain the true nature of state machine programming. In my experience, it invariably takes a few days of practice. After three or four days' exposure to the idea, there is a near-audible \"click!\" as something in the brain connects all the pieces together. We'll make it concrete by looking at the state machine for our NOM server.\n\nA useful thing about state machines is that you can read them state by state. Each state has a unique descriptive name and one or more //events//, which we list in any order. For each event, we perform zero or more //actions// and we then move to a //next state// (or stay in the same state).\n\nIn a ZeroMQ protocol server, we have a state machine instance //per client//. That sounds complex but it isn't, as we'll see. We describe our first state, {{Start}}, as having one valid event: {{OHAI}}. We check the user's credentials and then arrive in the Authenticated state[figure].\n\n[[code type=\"textdiagram\" title=\"The Start State\"]]\n.-------------------.\n| Start             |\n'-+-----------------'\n  |\n  #-------------#                    .-------------------.\n  | OHAI        +------------------->| Authenticated     |\n  #-------------#                    '-------------------'\n                   Check Credentials\n[[/code]]\n\nThe {{Check Credentials}} action produces either an {{ok}} or an {{error}} event. It's in the Authenticated state that we handle these two possible events by sending an appropriate reply back to the client[figure]. If authentication failed, we return to the {{Start}} state where the client can try again.\n\n[[code type=\"textdiagram\" title=\"The Authenticated State\"]]\n.-------------------.\n| Authenticated     |\n'-+-----------------'\n  |\n  #-------------#                    .-------------------.\n  | ok          +------------------->| Ready             |\n  #-------------#                    '-------------------'\n  |                Send OHAI-OK\n  |\n  #-------------#                    .-------------------.\n  | error       +------------------->| Start             |\n  #-------------#                    '-------------------'\n                   Send WTF\n[[/code]]\n\nWhen authentication has succeeded, we arrive in the Ready state. Here we have three possible events: an ICANHAZ or HUGZ message from the client, or a heartbeat timer event[figure].\n\n[[code type=\"textdiagram\" title=\"The Ready State\"]]\n.-------------------.\n| Ready             |\n'-+-----------------'\n  |\n  #-------------#                    .-------------------.\n  | ICANHAZ     +------------------->| Ready             |\n  #-------------#                    '-------------------'\n  |                Send CHEEZBURGER\n  |\n  #-------------#                    .-------------------.\n  | HUGZ        +------------------->| Ready             |\n  #-------------#                    '-------------------'\n  |                Send HUGZ-OK\n  |\n  #-------------#                    .-------------------.\n  | heartbeat   +------------------->| Ready             |\n  #-------------#                    '-------------------'\n                   Send HUGZ\n[[/code]]\n\nThere are a few more things about this state machine model that are worth knowing:\n\n* Events in upper case (like \"HUGZ\") are //external events// that come from the client as messages.\n* Events in lower case (like \"heartbeat\") are //internal events//, produced by code in the server.\n* The \"Send SOMETHING\" actions are shorthand for sending a specific reply back to the client.\n* Events that aren't defined in a particular state are silently ignored.\n\nNow, the original source for these pretty pictures is an XML model:\n\n[[code]]\n<class name = \"nom_server\" script = \"server_c\">\n\n<state name = \"start\">\n    <event name = \"OHAI\" next = \"authenticated\">\n        <action name = \"check credentials\" />\n    </event>\n</state>\n\n<state name = \"authenticated\">\n    <event name = \"ok\" next = \"ready\">\n        <action name = \"send\" message =\"OHAI-OK\" />\n    </event>\n    <event name = \"error\" next = \"start\">\n        <action name = \"send\" message = \"WTF\" />\n    </event>\n</state>\n\n<state name = \"ready\">\n    <event name = \"ICANHAZ\">\n        <action name = \"send\" message = \"CHEEZBURGER\" />\n    </event>\n    <event name = \"HUGZ\">\n        <action name = \"send\" message = \"HUGZ-OK\" />\n    </event>\n    <event name = \"heartbeat\">\n        <action name = \"send\" message = \"HUGZ\" />\n    </event>\n</state>\n</class>\n[[/code]]\n\nThe code generator is in {{examples/models/server_c.gsl}}. It is a fairly complete tool that I'll use and expand for more serious work later. It generates:\n\n* A server class in C ({{nom_server.c}}, {{nom_server.h}}) that implements the whole protocol flow.\n* A selftest method that runs the selftest steps listed in the XML file.\n* Documentation in the form of graphics (the pretty pictures).\n\nHere's a simple main program that starts the generated NOM server:\n\n[[code type=\"fragment\" name=\"nomserver\"]]\n#include \"czmq.h\"\n#include \"nom_server.h\"\n\nint main (int argc, char *argv [])\n{\n    printf (\"Starting NOM protocol server on port 5670...\\n\");\n    nom_server_t *server = nom_server_new ();\n    nom_server_bind (server, \"tcp://*:5670\");\n    nom_server_wait (server);\n    nom_server_destroy (&server);\n    return 0;\n}\n[[/code]]\n\nThe generated nom_server class is a fairly classic model. It accepts client messages on a ROUTER socket, so the first frame on every request is the client's connection identity. The server manages a set of clients, each with state. As messages arrive, it feeds these as //events// to the state machine. Here's the core of the state machine, as a mix of GSL commands and the C code we intend to generate:\n\n[[code type=\"fragment\" name=\"gsl-client-fsm\"]]\nclient_execute (client_t *self, int event)\n{\n    self->next_event = event;\n    while (self->next_event) {\n        self->event = self->next_event;\n        self->next_event = 0;\n        switch (self->state) {\n.for class.state\n            case $(name:c)_state:\n.   for event\n.       if index () > 1\n                else\n.       endif\n                if (self->event == $(name:c)_event) {\n.       for action\n.           if name = \"send\"\n                    zmsg_addstr (self->reply, \"$(message:)\");\n.           else\n                $(name:c)_action (self);\n.           endif\n.       endfor\n.       if defined (event.next)\n                    self->state = $(next:c)_state;\n.       endif\n                }\n.   endfor\n                break;\n.endfor\n        }\n        if (zmsg_size (self->reply) > 1) {\n            zmsg_send (&self->reply, self->router);\n            self->reply = zmsg_new ();\n            zmsg_add (self->reply, zframe_dup (self->address));\n        }\n    }\n}\n[[/code]]\n\nEach client is held as an object with various properties, including the variables we need to represent a state machine instance:\n\n[[code type=\"fragment\" name=\"fsm-instance\"]]\nevent_t next_event;         //  Next event\nstate_t state;              //  Current state\nevent_t event;              //  Current event\n[[/code]]\n\nYou will see by now that we are generating technically-perfect code that has the precise design and shape we want. The only clue that the {{nom_server}} class isn't handwritten is that the code is //too good//. People who complain that code generators produce poor code are accustomed to poor code generators. It is trivial to extend our model as we need it. For example, here's how we generate the selftest code.\n\nFirst, we add a \"selftest\" item to the state machine and write our tests. We're not using any XML grammar or validation so it really is just a matter of opening the editor and adding half-a-dozen lines of text:\n\n[[code]]\n<selftest>\n    <step send = \"OHAI\" body = \"Sleepy\" recv = \"WTF\" />\n    <step send = \"OHAI\" body = \"Joe\" recv = \"OHAI-OK\" />\n    <step send = \"ICANHAZ\" recv = \"CHEEZBURGER\" />\n    <step send = \"HUGZ\" recv = \"HUGZ-OK\" />\n    <step recv = \"HUGZ\" />\n</selftest>\n[[/code]]\n\nDesigning on the fly, I decided that \"send\" and \"recv\" were a nice way to express \"send this request, then expect this reply\". Here's the GSL code that turns this model into real code:\n\n[[code]]\n.for class->selftest.step\n.   if defined (send)\n    msg = zmsg_new ();\n    zmsg_addstr (msg, \"$(send:)\");\n.       if defined (body)\n    zmsg_addstr (msg, \"$(body:)\");\n.       endif\n    zmsg_send (&msg, dealer);\n\n.   endif\n.   if defined (recv)\n    msg = zmsg_recv (dealer);\n    assert (msg);\n    command = zmsg_popstr (msg);\n    assert (streq (command, \"$(recv:)\"));\n    free (command);\n    zmsg_destroy (&msg);\n\n.   endif\n.endfor\n[[/code]]\n\nFinally, one of the more tricky but absolutely essential parts of any state machine generator is //how do I plug this into my own code?// As a minimal example for this exercise I wanted to implement the \"check credentials\" action by accepting all OHAIs from my friend Joe (Hi Joe!) and reject everyone else's OHAIs. After some thought, I decided to grab code directly from the state machine model, i.e., embed action bodies in the XML file. So in {{nom_server.xml}}, you'll see this:\n\n[[code]]\n<action name = \"check credentials\">\n    char *body = zmsg_popstr (self->request);\n    if (body && streq (body, \"Joe\"))\n        self->next_event = ok_event;\n    else\n        self->next_event = error_event;\n    free (body);\n</action>\n[[/code]]\n\nAnd the code generator grabs that C code and inserts it into the generated {{nom_server.c}} file:\n\n[[code]]\n.for class.action\nstatic void\n$(name:c)_action (client_t *self) {\n$(string.trim (.):)\n}\n.endfor\n[[/code]]\n\nAnd now we have something quite elegant: a single source file that describes my server state machine and also contains the native implementations for my actions. A nice mix of high-level and low-level that is about 90% smaller than the C code.\n\nBeware, as your head spins with notions of all the amazing things you could produce with such leverage. While this approach gives you real power, it also moves you away from your peers, and if you go too far, you'll find yourself working alone.\n\nBy the way, this simple little state machine design exposes just three variables to our custom code:\n\n* {{self->next_event}}\n* {{self->request}}\n* {{self->reply}}\n\nIn the Libero state machine model, there are a few more concepts that we've not used here, but which we will need when we write larger state machines:\n\n* Exceptions, which lets us write terser state machines. When an action raises an exception, further processing on the event stops. The state machine can then define how to handle exception events.\n* The {{Defaults}} state, where we can define default handling for events (especially useful for exception events).\n\n++ Authentication Using SASL\n\nWhen we designed AMQP in 2007, we chose the [http://en.wikipedia.org/wiki/Simple_Authentication_and_Security_Layer Simple Authentication and Security Layer] (SASL) for the authentication layer, one of the ideas we took from the [http://www.rfc-editor.org/rfc/rfc3080.txt BEEP protocol framework]. SASL looks complex at first, but it's actually simple and fits neatly into a ZeroMQ-based protocol. What I especially like about SASL is that it's scalable. You can start with anonymous access or plain text authentication and no security, and grow to more secure mechanisms over time without changing your protocol.\n\nI'm not going to give a deep explanation now because we'll see SASL in action somewhat later. But I'll explain the principle so you're already somewhat prepared.\n\nIn the NOM protocol, the client started with an OHAI command, which the server either accepted (\"Hi Joe!\") or rejected. This is simple but not scalable because server and client have to agree up-front on the type of authentication they're going to do.\n\nWhat SASL introduced, which is genius, is a fully abstracted and negotiable security layer that's still easy to implement at the protocol level. It works as follows:\n\n* The client connects.\n* The server challenges the client, passing a list of security \"mechanisms\" that it knows about.\n* The client chooses a security mechanism that it knows about, and answers the server's challenge with a blob of opaque data that (and here's the neat trick) some generic security library calculates and gives to the client.\n* The server takes the security mechanism the client chose, and that blob of data, and passes it to its own security library.\n* The library either accepts the client's answer, or the server challenges again.\n\nThere are a number of free SASL libraries. When we come to real code, we'll implement just two mechanisms, ANONYMOUS and PLAIN, which don't need any special libraries.\n\nTo support SASL, we have to add an optional challenge/response step to our \"open-peering\" flow. Here is what the resulting protocol grammar looks like (I'm modifying NOM to do this):\n\n[[code]]\nsecure-nom      = open-peering *use-peering\n\nopen-peering    = C:OHAI *( S:ORLY C:YARLY ) ( S:OHAI-OK / S:WTF )\n\nORLY            = 1*mechanism challenge\nmechanism       = string\nchallenge       = *OCTET\n\nYARLY           = mechanism response\nresponse        = *OCTET\n[[/code]]\n\nWhere ORLY and YARLY contain a string (a list of mechanisms in ORLY, one mechanism in YARLY) and a blob of opaque data. Depending on the mechanism, the initial challenge from the server may be empty. We don't care: we just pass this to the security library to deal with.\n\nThe SASL [http://tools.ietf.org/html/rfc4422 RFC] goes into detail about other features (that we don't need), the kinds of ways SASL could be attacked, and so on.\n\n++ Large-Scale File Publishing: FileMQ\n\nLet's put all these techniques together into a file distribution system that I'll call FileMQ. This is going to be a real product, living on [https://github.com/zeromq/filemq GitHub]. What we'll make here is a first version of FileMQ, as a training tool. If the concept works, the real thing may eventually get its own book.\n\n+++ Why make FileMQ?\n\nWhy make a file distribution system? I already explained how to send large files over ZeroMQ, and it's really quite simple. But if you want to make messaging accessible to a million times more people than can use ZeroMQ, you need another kind of API. An API that my five-year old son can understand. An API that is universal, requires no programming, and works with just about every single application.\n\nYes, I'm talking about the file system. It's the DropBox pattern: chuck your files somewhere and they get magically copied somewhere else when the network connects again.\n\nHowever, what I'm aiming for is a fully decentralized architecture that looks more like git, that doesn't need any cloud services (though we could put FileMQ in the cloud), and that does multicast, i.e., can send files to many places at once.\n\nFileMQ must be secure(able), easily hooked into random scripting languages, and as fast as possible across our domestic and office networks.\n\nI want to use it to back up photos from my mobile phone to my laptop over WiFi. To share presentation slides in real time across 50 laptops in a conference. To share documents with colleagues in a meeting. To send earthquake data from sensors to central clusters. To back up video from my phone as I take it, during protests or riots. To synchronize configuration files across a cloud of Linux servers.\n\nA visionary idea, isn't it? Well, ideas are cheap. The hard part is making this, and making it simple.\n\n+++ Initial Design Cut: the API\n\nHere's the way I see the first design. FileMQ has to be distributed, which means that every node can be a server and a client at the same time. But I don't want the protocol to be symmetrical, because that seems forced. We have a natural flow of files from point A to point B, where A is the \"server\" and B is the \"client\". If files flow back the other way, then we have two flows. FileMQ is not yet directory synchronization protocol, but we'll bring it quite close.\n\nThus, I'm going to build FileMQ as two pieces: a client and a server. Then, I'll put these together in a main application (the {{filemq}} tool) that can act both as client and server. The two pieces will look quite similar to the {{nom_server}}, with the same kind of API:\n\n[[code type=\"fragment\" name=\"filemq-main\"]]\nfmq_server_t *server = fmq_server_new ();\nfmq_server_bind (server, \"tcp://*:5670\");\nfmq_server_publish (server, \"/home/ph/filemq/share\", \"/public\");\nfmq_server_publish (server, \"/home/ph/photos/stream\", \"/photostream\");\n\nfmq_client_t *client = fmq_client_new ();\nfmq_client_connect (client, \"tcp://pieter.filemq.org:5670\");\nfmq_client_subscribe (server, \"/public/\", \"/home/ph/filemq/share\");\nfmq_client_subscribe (server, \"/photostream/\", \"/home/ph/photos/stream\");\n\nwhile (!zctx_interrupted)\n    sleep (1);\n\nfmq_server_destroy (&server);\nfmq_client_destroy (&client);\n[[/code]]\n\nIf we wrap this C API in other languages, we can easily script FileMQ, embed it applications, port it to smartphones, and so on.\n\n+++ Initial Design Cut: the Protocol\n\nThe full name for the protocol is the \"File Message Queuing Protocol\", or FILEMQ in uppercase to distinguish it from the software. To start with, we write down the protocol as an ABNF grammar. Our grammar starts with the flow of commands between the client and server. You should recognize these as a combination of the various techniques we've seen already:\n\n[[code]]\nfilemq-protocol = open-peering *use-peering [ close-peering ]\n\nopen-peering    = C:OHAI *( S:ORLY C:YARLY ) ( S:OHAI-OK / error )\n\nuse-peering     = C:ICANHAZ ( S:ICANHAZ-OK / error )\n                / C:NOM\n                / S:CHEEZBURGER\n                / C:HUGZ S:HUGZ-OK\n                / S:HUGZ C:HUGZ-OK\n\nclose-peering   = C:KTHXBAI / S:KTHXBAI\n\nerror           = S:SRSLY / S:RTFM\n[[/code]]\n\nHere are the commands to and from the server:\n\n[[code]]\n;   The client opens peering to the server\nOHAI            = signature %x01 protocol version\nsignature       = %xAA %xA3\nprotocol        = string        ; Must be \"FILEMQ\"\nstring          = size *VCHAR\nsize            = OCTET\nversion         = %x01\n\n;   The server challenges the client using the SASL model\nORLY            = signature %x02 mechanisms challenge\nmechanisms      = size 1*mechanism\nmechanism       = string\nchallenge       = *OCTET        ; ZeroMQ frame\n\n;   The client responds with SASL authentication information\nYARLY           = %signature x03 mechanism response\nresponse        = *OCTET        ; ZeroMQ frame\n\n;   The server grants the client access\nOHAI-OK         = signature %x04\n\n;   The client subscribes to a virtual path\nICANHAZ         = signature %x05 path options cache\npath            = string        ; Full path or path prefix\noptions         = dictionary\ndictionary      = size *key-value\nkey-value       = string        ; Formatted as name=value\ncache           = dictionary    ; File SHA-1 signatures\n\n;   The server confirms the subscription\nICANHAZ-OK      = signature %x06\n\n;   The client sends credit to the server\nNOM             = signature %x07 credit\ncredit          = 8OCTET        ; 64-bit integer, network order\nsequence        = 8OCTET        ; 64-bit integer, network order\n\n;   The server sends a chunk of file data\nCHEEZBURGER     = signature %x08 sequence operation filename\n                  offset headers chunk\nsequence        = 8OCTET        ; 64-bit integer, network order\noperation       = OCTET\nfilename        = string\noffset          = 8OCTET        ; 64-bit integer, network order\nheaders         = dictionary\nchunk           = FRAME\n\n;   Client or server sends a heartbeat\nHUGZ            = signature %x09\n\n;   Client or server responds to a heartbeat\nHUGZ-OK         = signature %x0A\n\n;   Client closes the peering\nKTHXBAI         = signature %x0B\n[[/code]]\n\nAnd here are the different ways the server can tell the client things went wrong:\n\n[[code]]\n;   Server error reply - refused due to access rights\nS:SRSLY         = signature %x80 reason\n\n;   Server error reply - client sent an invalid command\nS:RTFM          = signature %x81 reason\n[[/code]]\n\nFILEMQ lives on the [http://rfc.zeromq.org/spec:19 ZeroMQ unprotocols website] and has a registered TCP port with IANA (the Internet Assigned Numbers Authority), which is port 5670.\n\n+++ Building and Trying FileMQ\n\nThe FileMQ stack is [https://github.com/zeromq/filemq on GitHub]. It works like a classic C/C++ project:\n\n[[code]]\ngit clone git://github.com/zeromq/filemq.git\ncd filemq\n./autogen.sh\n./configure\nmake check\n[[/code]]\n\nYou want to be using the latest CZMQ master for this. Now try running the {{track}} command, which is a simple tool that uses FileMQ to track changes in one directory in another:\n\n[[code]]\ncd src\n./track ./fmqroot/send ./fmqroot/recv\n[[/code]]\n\nAnd open two file navigator windows, one into {{src/fmqroot/send}} and one into {{src/fmqroot/recv}}. Drop files into the send folder and you'll see them arrive in the recv folder. The server checks once per second for new files. Delete files in the send folder, and they're deleted in the recv folder similarly.\n\nI use track for things like updating my MP3 player mounted as a USB drive. As I add or remove files in my laptop's Music folder, the same changes happen on the MP3 player. FILEMQ isn't a full replication protocol yet, but we'll fix that later.\n\n+++ Internal Architecture\n\nTo build FileMQ I used a lot of code generation, possibly too much for a tutorial. However the code generators are all reusable in other stacks and will be important for our final project in [#moving-pieces]. They are an evolution of the set we saw earlier:\n\n* {{codec_c.gsl}}: generates a message codec for a given protocol.\n* {{server_c.gsl}}: generates a server class for a protocol and state machine.\n* {{client_c.gsl}}: generates a client class for a protocol and state machine.\n\nThe best way to learn to use GSL code generation is to translate these into a language of your choice and make your own demo protocols and stacks. You'll find it fairly easy. FileMQ itself doesn't try to support multiple languages. It could, but it'd make things needlessly complex.\n\nThe FileMQ architecture actually slices into two layers. There's a generic set of classes to handle chunks, directories, files, patches, SASL security, and configuration files. Then, there's the generated stack: messages, client, and server. If I was creating a new project I'd fork the whole FileMQ project, and go and modify the three models:\n\n* {{fmq_msg.xml}}: defines the message formats\n* {{fmq_client.xml}}: defines the client state machine, API, and implementation.\n* {{fmq_server.xml}}: does the same for the server.\n\nYou'd want to rename things to avoid confusion. Why didn't I make the reusable classes into a separate library? The answer is two-fold. First, no one actually needs this (yet). Second, it'd make things more complex for you as you build and play with FileMQ. It's never worth adding complexity to solve a theoretical problem.\n\nAlthough I wrote FileMQ in C, it's easy to map to other languages. It is quite amazing how nice C becomes when you add CZMQ's generic zlist and zhash containers and class style. Let me go through the classes quickly:\n\n* {{fmq_sasl}}: encodes and decodes a SASL challenge. I only implemented the PLAIN mechanism, which is enough to prove the concept.\n\n* {{fmq_chunk}}: works with variable sized blobs. Not as efficient as ZeroMQ's messages but they do less weirdness and so are easier to understand. The chunk class has methods to read and write chunks from disk.\n\n* {{fmq_file}}: works with files, which may or may not exist on disk. Gives you information about a file (like size), lets you read and write to files, remove files, check if a file exists, and check if a file is \"stable\" (more on that later).\n\n* {{fmq_dir}}: works with directories, reading them from disk and comparing two directories to see what changed. When there are changes, returns a list of \"patches\".\n\n* {{fmq_patch}}: works with one patch, which really just says \"create this file\" or \"delete this file\" (referring to a fmq_file item each time).\n\n* {{fmq_config}}: works with configuration data. I'll come back to client and server configuration later.\n\nEvery class has a test method, and the main development cycle is \"edit, test\". These are mostly simple self tests, but they make the difference between code I can trust and code I know will still break. It's a safe bet that any code that isn't covered by a test case will have undiscovered errors. I'm not a fan of external test harnesses. But internal test code that you write as you write your functionality... that's like the handle on a knife.\n\nYou should, really, be able to read the source code and rapidly understand what these classes are doing. If you can't read the code happily, tell me. If you want to port the FileMQ implementation into other languages, start by forking the whole repository and later we'll see if it's possible to do this in one overall repo.\n\n+++ Public API\n\nThe public API consists of two classes (as we sketched earlier):\n\n* {{fmq_client}}: provides the client API, with methods to connect to a server, configure the client, and subscribe to paths.\n\n* {{fmq_server}}: provides the server API, with methods to bind to a port, configure the server, and publish a path.\n\nThese classes provide an //multithreaded API//, a model we've used a few times now. When you create an API instance (i.e., {{fmq_server_new()}} or {{fmq_client_new()}}), this method kicks off a background thread that does the real work, i.e., runs the server or the client. The other API methods then talk to this thread over ZeroMQ sockets (a //pipe// consisting of two PAIR sockets over inproc://).\n\nIf I was a keen young developer eager to use FileMQ in another language, I'd probably spend a happy weekend writing a binding for this public API, then stick it in a subdirectory of the filemq project called, say, {{bindings/}}, and make a pull request.\n\nThe actual API methods come from the state machine description, like this (for the server):\n\n[[code]]\n<method name = \"publish\">\n<argument name = \"location\" type = \"string\" />\n<argument name = \"alias\" type = \"string\" />\nmount_t *mount = mount_new (location, alias);\nzlist_append (self->mounts, mount);\n</method>\n[[/code]]\n\nWhich gets turned into this code:\n\n[[code type=\"fragment\" name=\"fmq-server-methods\"]]\nvoid\nfmq_server_publish (fmq_server_t *self, char *location, char *alias)\n{\n    assert (self);\n    assert (location);\n    assert (alias);\n    zstr_sendm (self->pipe, \"PUBLISH\");\n    zstr_sendfm (self->pipe, \"%s\", location);\n    zstr_sendf (self->pipe, \"%s\", alias);\n}\n[[/code]]\n\n+++ Design Notes\n\nThe hardest part of making FileMQ wasn't implementing the protocol, but maintaining accurate state internally. An FTP or HTTP server is essentially stateless. But a publish/subscribe server //has// to maintain subscriptions, at least.\n\nSo I'll go through some of the design aspects:\n\n* The client detects if the server has died by the lack of heartbeats ({{HUGZ}}) coming from the server. It then restarts its dialog by sending an {{OHAI}}. There's no timeout on the {{OHAI}} because the ZeroMQ DEALER socket will queue an outgoing message indefinitely.\n\n* If a client stops replying with ({{HUGZ-OK}}) to the heartbeats that the server sends, the server concludes that the client has died and deletes all state for the client including its subscriptions.\n\n* The client API holds subscriptions in memory and replays them when it has connected successfully. This means the caller can subscribe at any time (and doesn't care when connections and authentication actually happen).\n\n* The server and client use virtual paths, much like an HTTP or FTP server. You publish one or more //mount points//, each corresponding to a directory on the server. Each of these maps to some virtual path, for instance \"/\" if you have only one mount point. Clients then subscribe to virtual paths, and files arrive in an inbox directory. We don't send physical file names across the network.\n\n* There are some timing issues: if the server is creating its mount points while clients are connected and subscribing, the subscriptions won't attach to the right mount points. So, we bind the server port as last thing.\n\n* Clients can reconnect at any point; if the client sends {{OHAI}}, that signals the end of any previous conversation and the start of a new one. I might one day make subscriptions durable on the server, so they survive a disconnection. The client stack, after reconnecting, replays any subscriptions the caller application already made.\n\n+++ Configuration\n\nI've built several large server products, like the Xitami web server that was popular in the late 90's, and the [http://www.openamq.org OpenAMQ messaging server]. Getting configuration easy and obvious was a large part of making these servers fun to use.\n\nWe typically aim to solve a number of problems:\n\n* Ship default configuration files with the product.\n* Allow users to add custom configuration files that are never overwritten.\n* Allow users to configure from the command-line.\n\nAnd then layer these one on the other, so command-line settings override custom settings, which override default settings. It can be a lot of work to do this right. For FileMQ, I've taken a somewhat simpler approach: all configuration is done from the API.\n\nThis is how we start and configure the server, for example:\n\n[[code type=\"fragment\" name=\"fmq-server-api\"]]\nserver = fmq_server_new ();\nfmq_server_configure (server, \"server_test.cfg\");\nfmq_server_publish (server, \"./fmqroot/send\", \"/\");\nfmq_server_publish (server, \"./fmqroot/logs\", \"/logs\");\nfmq_server_bind (server, \"tcp://*:5670\");\n[[/code]]\n\nWe do use a specific format for the config files, which is [http://rfc.zeromq.org/spec:4 ZPL], a minimalist syntax that we started using for ZeroMQ \"devices\" a few years ago, but which works well for any server:\n\n[[code]]\n#   Configure server for plain access\n#\nserver\n    monitor = 1             #   Check mount points\n    heartbeat = 1           #   Heartbeat to clients\n\npublish\n    location = ./fmqroot/logs\n    virtual = /logs\n\nsecurity\n    echo = I: use guest/guest to login to server\n    #   These are SASL mechanisms we accept\n    anonymous = 0\n    plain = 1\n        account\n            login = guest\n            password = guest\n            group = guest\n        account\n            login = super\n            password = secret\n            group = admin\n[[/code]]\n\nOne cute thing (which seems useful) the generated server code does is to parse this config file (when you use the {{fmq_server_configure()}} method) and execute any section that matches an API method. Thus the {{publish}} section works as a {{fmq_server_publish()}} method.\n\n+++ File Stability\n\nIt is quite common to poll a directory for changes and then do something \"interesting\" with new files. But as one process is writing to a file, other processes have no idea when the file has been fully written. One solution is to add a second \"indicator\" file that we create after creating the first file. This is intrusive, however.\n\nThere is a neater way, which is to detect when a file is \"stable\", i.e., no one is writing to it any longer. FileMQ does this by checking the modification time of the file. If it's more than a second old, then the file is considered stable, at least stable enough to be shipped off to clients. If a process comes along after five minutes and appends to the file, it'll be shipped off again.\n\nFor this to work, and this is a requirement for any application hoping to use FileMQ successfully, do not buffer more than a second's worth of data in memory before writing. If you use very large block sizes, the file may look stable when it's not.\n\n+++ Delivery Notifications\n\nOne of the nice things about the multithreaded API model we're using is that it's essentially message based. This makes it ideal for returning events back to the caller. A more conventional API approach would be to use callbacks. But callbacks that cross thread boundaries are somewhat delicate. Here's how the client sends a message back when it has received a complete file:\n\n[[code type=\"fragment\" name=\"send-deliver\"]]\nzstr_sendm (self->pipe, \"DELIVER\");\nzstr_sendm (self->pipe, filename);\nzstr_sendf (self->pipe, \"%s/%s\", inbox, filename);\n[[/code]]\n\nWe can now add a _recv() method to the API that waits for events back from the client. It makes a clean style for the caller: create the client object, configure it, and then receive and process any events it returns.\n\n+++ Symbolic Links\n\nWhile using a staging area is a nice, simple API, it also creates costs for senders. If I already have a 2GB video file on a camera, and want to send it via FileMQ, the current implementation asks that I copy it to a staging area before it will be sent to subscribers.\n\nOne option is to mount the whole content directory (e.g., {{/home/me/Movies}}), but this is fragile because it means the application can't decide to send individual files. It's everything or nothing.\n\nA simple answer is to implement portable symbolic links. As Wikipedia explains: \"A symbolic link contains a text string that is automatically interpreted and followed by the operating system as a path to another file or directory. This other file or directory is called the //target//. The symbolic link is a second file that exists independently of its target. If a symbolic link is deleted, its target remains unaffected.\"\n\nThis doesn't affect the protocol in any way; it's an optimization in the server implementation. Let's make a simple portable implementation:\n\n* A symbolic link consists of a file with the extension {{.ln}}.\n* The filename without {{.ln}} is the published file name.\n* The link file contains one line, which is the real path to the file.\n\nBecause we've collected all operations on files in a single class ({{fmq_file}}), it's a clean change. When we create a new file object, we check if it's a symbolic link and then all read-only actions (get file size, read file) operate on the target file, not the link.\n\n+++ Recovery and Late Joiners\n\nAs it stands now, FileMQ has one major remaining problem: it provides no way for clients to recover from failures. The scenario is that a client, connected to a server, starts to receive files and then disconnects for some reason. The network may be too slow, or breaks. The client may be on a laptop which is shut down, then resumed. The WiFi may be disconnected. As we move to a more mobile world (see [#moving-pieces]) this use case becomes more and more frequent. In some ways it's becoming a dominant use case.\n\nIn the classic ZeroMQ pub-sub pattern, there are two strong underlying assumptions, both of which are usually wrong in FileMQ's real world. First, that data expires very rapidly so that there's no interest in asking from old data. Second, that networks are stable and rarely break (so it's better to invest more in improving the infrastructure and less in addressing recovery).\n\nTake any FileMQ use case and you'll see that if the client disconnects and reconnects, then it should get anything it missed. A further improvement would be to recover from partial failures, like HTTP and FTP do. But one thing at a time.\n\nOne answer to recovery is \"durable subscriptions\", and the first drafts of the FILEMQ protocol aimed to support this, with client identifiers that the server could hold onto and store. So if a client reappears after a failure, the server would know what files it had not received.\n\nStateful servers are, however, nasty to make and difficult to scale. How do we, for example, do failover to a secondary server? Where does it get its subscriptions from? It's far nicer if each client connection works independently and carries all necessary state with it.\n\nAnother nail in the coffin of durable subscriptions is that it requires up-front coordination. Up-front coordination is always a red flag, whether it's in a team of people working together, or a bunch of processes talking to each other. What about late joiners? In the real world, clients do not neatly line up and then all say \"Ready!\" at the same time. In the real world, they come and go arbitrarily, and it's valuable if we can treat a brand new client in the same way as a client that went away and came back.\n\nTo address this I will add two concepts to the protocol: a //resynchronization// option and a {{cache}} field (a dictionary). If the client wants recovery, it sets the resynchronization option, and tells the server what files it already has via the {{cache}} field. We need both, because there's no way in the protocol to distinguish between an empty field and a null field. The FILEMQ RFC describes these fields as follows:\n\n> The {{options}} field provides additional information to the server. The server SHOULD implement these options: {{RESYNC=1}} - if the client sets this, the server SHALL send the full contents of the virtual path to the client, except files the client already has, as identified by their SHA-1 digest in the {{cache}} field.\n\nAnd:\n\n> When the client specifies the {{RESYNC}} option, the {{cache}} dictionary field tells the server which files the client already has. Each entry in the {{cache}} dictionary is a \"filename=digest\" key/value pair where the digest SHALL be a SHA-1 digest in printable hexadecimal format. If the filename starts with \"/\" then it SHOULD start with the path, otherwise the server MUST ignore it. If the filename does not start with \"/\" then the server SHALL treat it as relative to the path.\n\nClients that know they are in the classic pub-sub use case just don't provide any cache data, and clients that want recovery provide their cache data. It requires no state in the server, no up-front coordination, and works equally well for brand new clients (which may have received files via some out-of-band means), and clients that received some files and were then disconnected for a while.\n\nI decided to use SHA-1 digests for several reasons. First, it's fast enough: 150msec to digest a 25MB core dump on my laptop. Second, it's reliable: the chance of getting the same hash for different versions of one file is close enough to zero. Third, it's the widest supported digest algorithm. A cyclic-redundancy check (e.g., CRC-32) is faster but not reliable. More recent SHA versions (SHA-256, SHA-512) are more secure but take 50% more CPU cycles, and are overkill for our needs.\n\nHere is what a typical ICANHAZ message looks like when we use both caching and resyncing (this is output from the {{dump}} method of the generated codec class):\n\n[[code]]\nICANHAZ:\n    path='/photos'\n    options={\n        RESYNC=1\n    }\n    cache={\n        DSCF0001.jpg=1FABCD4259140ACA99E991E7ADD2034AC57D341D\n        DSCF0006.jpg=01267C7641C5A22F2F4B0174FFB0C94DC59866F6\n        DSCF0005.jpg=698E88C05B5C280E75C055444227FEA6FB60E564\n        DSCF0004.jpg=F0149101DD6FEC13238E6FD9CA2F2AC62829CBD0\n        DSCF0003.jpg=4A49F25E2030B60134F109ABD0AD9642C8577441\n        DSCF0002.jpg=F84E4D69D854D4BF94B5873132F9892C8B5FA94E\n    }\n[[/code]]\n\nAlthough we don't do this in FileMQ, the server can use the cache information to help the client catch up with deletions that it missed. To do this, it would have to log deletions, and then compare this log with the client cache when a client subscribes.\n\n+++ Test Use Case: The Track Tool\n\nTo properly test something like FileMQ we need a test case that plays with live data. One of my sysadmin tasks is to manage the MP3 tracks on my music player, which is, by the way, a Sansa Clip reflashed with Rock Box, which I highly recommend. As I download tracks into my Music folder, I want to copy these to my player, and as I find tracks that annoy me, I delete them in the Music folder and want those gone from my player too.\n\nThis is kind of overkill for a powerful file distribution protocol. I could write this using a bash or Perl script, but to be honest the hardest work in FileMQ was the directory comparison code and I want to benefit from that. So I put together a simple tool called {{track}}, which calls the FileMQ API. From the command line this runs with two arguments; the sending and the receiving directories:\n\n[[code]]\n./track /home/ph/Music /media/3230-6364/MUSIC\n[[/code]]\n\nThe code is a neat example of how to use the FileMQ API to do local file distribution. Here is the full program, minus the license text (it's MIT/X11 licensed):\n\n[[code type=\"fragment\" name=\"track\"]]\n#include \"czmq.h\"\n#include \"../include/fmq.h\"\n\nint main (int argc, char *argv [])\n{\n    fmq_server_t *server = fmq_server_new ();\n    fmq_server_configure (server, \"anonymous.cfg\");\n    fmq_server_publish (server, argv [1], \"/\");\n    fmq_server_set_anonymous (server, true);\n    fmq_server_bind (server, \"tcp://*:5670\");\n\n    fmq_client_t *client = fmq_client_new ();\n    fmq_client_connect (client, \"tcp://localhost:5670\");\n    fmq_client_set_inbox (client, argv [2]);\n    fmq_client_set_resync (client, true);\n    fmq_client_subscribe (client, \"/\");\n\n    while (true) {\n        //  Get message from fmq_client API\n        zmsg_t *msg = fmq_client_recv (client);\n        if (!msg)\n            break;              //  Interrupted\n        char *command = zmsg_popstr (msg);\n        if (streq (command, \"DELIVER\")) {\n            char *filename = zmsg_popstr (msg);\n            char *fullname = zmsg_popstr (msg);\n            printf (\"I: received %s (%s)\\n\", filename, fullname);\n            free (filename);\n            free (fullname);\n        }\n        free (command);\n        zmsg_destroy (&msg);\n    }\n    fmq_server_destroy (&server);\n    fmq_client_destroy (&client);\n    return 0;\n}\n[[/code]]\n\nNote how we work with physical paths in this tool. The server publishes the physical path {{/home/ph/Music}} and maps this to the virtual path {{/}}. The client subscribes to {{/}} and receives all files in {{/media/3230-6364/MUSIC}}. I could use any structure within the server directory, and it would be copied faithfully to the client's inbox. Note the API method {{fmq_client_set_resync()}}, which causes a server-to-client synchronization.\n\n++ Getting an Official Port Number\n\nWe've been using port 5670 in the examples for FILEMQ. Unlike all the previous examples in this book, this port isn't arbitrary but [http://www.iana.org/assignments/service-names-port-numbers/service-names-port-numbers.txt was assigned] by the Internet [http://www.iana.org Assigned Numbers Authority (IANA)], which \"is responsible for the global coordination of the DNS Root, IP addressing, and other Internet protocol resources\".\n\nI'll explain very briefly when and how to request registered port numbers for your application protocols. The main reason is to ensure that your applications can run in the wild without conflict with other protocols. Technically, if you ship any software that uses port numbers between 1024 and 49151, you should be using only IANA registered port numbers. Many products don't bother with this, however, and tend instead to use the IANA list as \"ports to avoid\".\n\nIf you aim to make a public protocol of any importance, such as FILEMQ, you're going to want an IANA-registered port. I'll explain briefly how to do this:\n\n* Document your protocol clearly, as IANA will want a specification of how you intend to use the port. It does not have to be a fully-formed protocol specification, but must be solid enough to pass expert review.\n\n* Decide what transport protocols you want: UDP, TCP, SCTP, and so on. With ZeroMQ you will usually only want TCP.\n\n* Fill in the application on iana.org, providing all the necessary information.\n\n* IANA will then continue the process by email until your application is accepted or rejected.\n\nNote that you don't request a specific port number; IANA will assign you one. It's therefore wise to start this process before you ship software, not afterwards.\n"
        },
        {
          "name": "chapter8.txt",
          "type": "blob",
          "size": 121.9755859375,
          "content": ".output chapter8.wd\n.bookmark moving-pieces\n+ A Framework for Distributed Computing\n\nWe've gone though a journey of understanding ZeroMQ in its many aspects. By now you may have started to build your own products using the techniques I explained, as well as others you've figured out yourself. You will start to face questions about how to make these products work in the real world.\n\nBut what is that \"real world\"? I'll argue that it is becoming a world of ever increasing numbers of moving pieces. Some people use the phrase the \"Internet of Things\", suggesting that we'll see a new category of devices that are more numerous but also more stupid than our current smart phones, tablets, laptops, and servers. However, I don't think the data points this way at all. Yes, there are more and more devices, but they're not stupid at all. They're smart and powerful and getting more so all the time.\n\nThe mechanism at work is something I call \"Cost Gravity\" and it has the effect of reducing the cost of technology by half every 18-24 months. Put another way, our global computing capacity doubles every two years, over and over and over. The future is filled with trillions of devices that are fully powerful multi-core computers: they don't run a cut-down \"operating system for things\" but full operating systems and full applications.\n\nAnd this is the world we're targeting with ZeroMQ. When we talk of \"scale\", we don't mean hundreds of computers, or even thousands. Think of clouds of tiny smart and perhaps self-replicating machines surrounding every person, filling every space, covering every wall, filling the cracks and eventually, becoming so much a part of us that we get them before birth and they follow us to death.\n\nThese clouds of tiny machines talk to each other, all the time, over short-range wireless links using the Internet Protocol. They create mesh networks, pass information and tasks around like nervous signals. They augment our memory, vision, every aspect of our communications, and physical functions. And it's ZeroMQ that powers their conversations and events and exchanges of work and information.\n\nNow, to make even a thin imitation of this come true today, we need to solve a set of technical problems. These include: How do peers discover each other? How do they talk to existing networks like the Web? How do they protect the information they carry? How do we track and monitor them, to get some idea of what they're doing? Then we need to do what most engineers forget about: package this solution into a framework that is dead easy for ordinary developers to use.\n\nThis is what we'll attempt in this chapter: to build a framework for distributed applications as an API, protocols, and implementations. It's not a small challenge but I've claimed often that ZeroMQ makes such problems simple, so let's see if that's still true.\n\nWe'll cover:\n\n* Requirements for distributed computing\n* The pros and cons of WiFi for proximity networking\n* Discovery using UDP and TCP\n* A message-based API\n* Creating a new open source project\n* Peer-to-peer connectivity (the Harmony pattern)\n* Tracking peer presence and disappearance\n* Group messaging without central coordination\n* Large-scale testing and simulation\n* Dealing with high-water marks and blocked peers\n* Distributed logging and monitoring\n\n++ Design for The Real World\n\nWhether we're connecting a roomful of mobile devices over WiFi or a cluster of virtual boxes over simulated Ethernet, we will hit the same kinds of problems. These are:\n\n* //Discovery//: how do we learn about other nodes on the network? Do we use a discovery service, centralized mediation, or some kind of broadcast beacon?\n\n* //Presence//: how do we track when other nodes come and go? Do we use some kind of central registration service, or heartbeating or beacons?\n\n* //Connectivity//: how do we actually connect one node to another? Do we use local networking, wide-area networking, or do we use a central message broker to do the forwarding?\n\n* //Point-to-point messaging//: how do we send a message from one node to another? Do we send this to the node's network address, or do we use some indirect addressing via a centralized message broker?\n\n* //Group messaging//: how do we send a message from one node to a group of others? Do we work via a centralized message broker, or do we use a pub-sub model like ZeroMQ?\n\n* //Testing and simulation//: how do we simulate large numbers of nodes so we can test performance properly? Do we have to buy two dozen Android tablets, or can we use pure software simulation?\n\n* //Distributed Logging//: how do we track what this cloud of nodes is doing so we can detect performance problems and failures? Do we create a main logging service, or do we allow every device to log the world around it?\n\n* //Content distribution//: how do we send content from one node to another? Do we use server-centric protocols like FTP or HTTP, or do we use decentralized protocols like FileMQ?\n\nIf we can solve these problems reasonably well, and the further problems that will emerge (like security and wide-area bridging), we get something like a framework for what I might call \"Really Cool Distributed Applications\", or as my grandkids call it, \"the software our world runs on\".\n\nYou should have guessed from my rhetorical questions that there are two broad directions in which we can go. One is to centralize everything. The other is to distribute everything. I'm going to bet on decentralization. If you want centralization, you don't really need ZeroMQ; there are other options you can use.\n\nSo very roughly, here's the story. One, the number of moving pieces increases exponentially over time (doubles every 24 months). Two, these pieces stop using wires because dragging cables everywhere gets //really// boring. Three, future applications run across clusters of these pieces using the Benevolent Tyrant pattern from [#the-community]. Four, today it's really difficult, nay still rather impossible, to build such applications. Five, let's make it cheap and easy using all the techniques and tools we've built up. Six, partay!\n\n++ The Secret Life of WiFi\n\nThe future is clearly wireless, and while many big businesses live by concentrating data in their clouds, the future doesn't look quite so centralized. The devices at the edges of our networks get smarter every year, not dumber. They're hungry for work and information to digest and from which to profit. And they don't drag cables around, except once a night for power. It's all wireless and more and more, it's 802.11-branded WiFi of different alphabetical flavors.\n\n+++ Why Mesh Isn't Here Yet\n\nAs such a vital part of our future, WiFi has a big problem that's not often discussed, but that anyone betting on it needs to be aware of. The phone companies of the world have built themselves nice profitable mobile phone cartels in nearly every country with a functioning government, based on convincing governments that without monopoly rights to airwaves and ideas, the world would fall apart. Technically, we call this \"regulatory capture\" and \"patents\", but in fact it's just a form of blackmail and corruption. If you, the state, give me, a business, the right to overcharge, tax the market, and ban all real competitors, I'll give you 5%. Not enough? How about 10%? OK, 15% plus snacks. If you refuse, we pull service.\n\nBut WiFi snuck past this, borrowing unlicensed airspace and riding on the back of the open and unpatented and remarkably innovative Internet Protocol stack. So today, we have the curious situation where it costs me several Euro a minute to call from Seoul to Brussels if I use the state-backed infrastructure that we've subsidized over decades, but nothing at all if I can find an unregulated WiFi access point. Oh, and I can do video, send files and photos, and download entire home movies all for the same amazing price point of precisely zero point zero zero (in any currency you like). God help me if I try to send just one photo home using the service for which I actually pay. That would cost me more than the camera I took it on.\n\nIt is the price we pay for having tolerated the \"trust us, we're the experts\" patent system for so long. But more than that, it's a massive economic incentive to chunks of the technology sector--and especially chipset makers who own patents on the anti-Internet GSM, GPRS, 3G, and LTE stacks, and who treat the telcos as prime clients--to actively throttle WiFi development. And of course it's these firms that bulk out the IEEE committees that define WiFi.\n\nThe reason for this rant against lawyer-driven \"innovation\" is to steer your thinking towards \"what if WiFi were really free?\" This will happen one day, not too far off, and it's worth betting on. We'll see several things happen. First, much more aggressive use of airspace especially for near-distance communications where there is no risk of interference. Second, big capacity improvements as we learn to use more airspace in parallel. Third, acceleration of the standardization process. Last, broader support in devices for really interesting connectivity.\n\nRight now, streaming a movie from your phone to your TV is considered \"leading edge\". This is ridiculous. Let's get truly ambitious. How about a stadium of people watching a game, sharing photos and HD video with each other in real time, creating an ad-hoc event that literally saturates the airspace with a digital frenzy. I should be able to collect terabytes of imagery from those around me, in an hour. Why does this have to go through Twitter or Facebook and that tiny expensive mobile data connection? How about a home with hundreds of devices all talking to each other over mesh, so when someone rings the doorbell, the porch lights stream video through to your phone or TV? How about a car that can talk to your phone and play your dubstep playlist //without you plugging in wires//.\n\nTo get more serious, why is our digital society in the hands of central points that are monitored, censored, logged, used to track who we talk to, collect evidence against us, and then shut down when the authorities decide we have too much free speech? The loss of privacy we're living through is only a problem when it's one-sided, but then the problem is calamitous. A truly wireless world would bypass all central censorship. It's how the Internet was designed, and it's quite feasible, technically (which is the best kind of feasible).\n\n+++ Some Physics\n\nNaive developers of distributed software treat the network as infinitely fast and perfectly reliable. While this is approximately true for simple applications over Ethernet, WiFi rapidly proves the difference between magical thinking and science. That is, WiFi breaks so easily and dramatically under stress that I sometimes wonder how anyone would dare use it for real work. The ceiling moves up as WiFi gets better, but never fast enough to stop us hitting it.\n\nTo understand how WiFi performs technically, you need to understand a basic law of physics: the power required to connect two points increases according to the square of the distance. People who grow up in larger houses have exponentially louder voices, as I learned in Dallas. For a WiFi network, this means that as two radios get further apart, they have to either use more power or lower their signal rate.\n\nThere's only so much power you can pull out of a battery before users treat the device as hopelessly broken. Thus even though a WiFi network may be rated at a certain speed, the real bit rate between the access point (AP) and a client depends on how far apart the two are. As you move your WiFi-enabled phone away from the AP, the two radios trying to talk to each other will first increase their power and then reduce their bit rate.\n\nThis effect has some consequences of which we should be aware if we want to build robust distributed applications that don't dangle wires behind them like puppets:\n\n* If you have a group of devices talking to an AP, when the AP is talking to the slowest device, the //whole network has to wait//. It's like having to repeat a joke at a party to the designated driver who has no sense of humor, is still fully and tragically sober, and has a poor grasp of the language.\n\n* If you use unicast TCP and send a message to multiple devices, the AP must send the packets to each device separately, Yes, and you knew this, it's also how Ethernet works. But now understand that one distant (or low-powered) device means everything waits for that slowest device to catch up.\n\n* If you use multicast or broadcast (which work the same, in most cases), the AP will send single packets to the whole network at once, which is awesome, but it will do it at the slowest possible bit rate (usually 1Mbps). You can adjust this rate manually in some APs. That just reduces the reach of your AP. You can also buy more expensive APs that have a little more intelligence and will figure out the highest bit rate they can safely use. You can also use enterprise APs with IGMP (Internet Group Management Protocol) support and ZeroMQ's PGM transport to send only to subscribed clients. I'd not, however, bet on such APs being widely available, ever.\n\nAs you try to put more devices onto an AP, performance rapidly gets worse to the point where adding one more device can break the whole network for everyone. Many APs solve this by randomly disconnecting clients when they reach some limit, such as four to eight devices for a mobile hotspot, 30-50 devices for a consumer AP, perhaps 100 devices for an enterprise AP.\n\n+++ What's the Current Status?\n\nDespite its uncomfortable role as enterprise technology that somehow escaped into the wild, WiFi is already useful for more than getting a free Skype call. It's not ideal, but it works well enough to let us solve some interesting problems. Let me give you a rapid status report.\n\nFirst, point-to-point versus access point-to-client. Traditional WiFi is all AP-client. Every packet has to go from client A to AP, then to client B. You cut your bandwidth by 50%, but that's only half the problem. I explained about the inverse power law. If A and B are very close together, but both are far from the AP, they'll both be using a low bit rate. Imagine your AP is in the garage, and you're in the living room trying to stream video from your phone to your TV. Good luck!\n\nThere is an old \"ad-hoc\" mode that lets A and B talk to each other, but it's way too slow for anything fun, and of course, it's disabled on all mobile chipsets. Actually, it's disabled in the top secret drivers that the chipset makers kindly provide to hardware makers. There is a new //Tunneled Direct Link Setup// (TDLS) protocol that lets two devices create a direct link, using an AP for discovery but not for traffic. And there's a \"5G\" WiFi standard (it's a marketing term, so it goes in quotes) that boosts link speeds to a gigabit. TDLS and 5G together make HD movie streaming from your phone to your TV a plausible reality. I assume TDLS will be restricted in various ways so as to placate the telcos.\n\nLastly, we saw standardization of the 802.11s mesh protocol in 2012, after a remarkably speedy ten years or so of work. Mesh removes the access point completely, at least in the imaginary future where it exists and is widely used. Devices talk to each other directly, and maintain little routing tables of neighbors that let them forward packets. Imagine the AP software embedded into every device, but smart enough (it's not as impressive as it sounds) to do multiple hops.\n\nNo one who is making money from the mobile data extortion racket wants to see 802.11s available because city-wide mesh is such a nightmare for the bottom line, so it's happening as slowly as possible. The only large organization with the power (and, I assume the surface-to-surface missiles) to get mesh technology into wide use is the US Army. But mesh will emerge and I'd bet on 802.11s being widely available in consumer electronics by 2020 or so.\n\nSecond, if we don't have point-to-point, how far can we trust APs today? Well, if you go to a Starbucks in the US and try the ZeroMQ \"Hello World\" example using two laptops connected via the free WiFi, you'll find they cannot connect. Why? Well, the answer is in the name: \"attwifi\". AT&T is a good old incumbent telco that hates WiFi and presumably provides the service cheaply to Starbucks and others so that independents can't get into the market. But any access point you buy will support client-to-AP-to-client access, and outside the US I've never found a public AP locked-down the AT&T way.\n\nThird, performance. The AP is clearly a bottleneck; you cannot get better than half of its advertised speed even if you put A and B literally beside the AP. Worse, if there are other APs in the same airspace, they'll shout each other out. In my home, WiFi barely works at all because the neighbors two houses down have an AP which they've amplified. Even on a different channel, it interferes with our home WiFi. In the cafe where I'm sitting now there are over a dozen networks. Realistically, as long as we're dependent on AP-based WiFi, we're subject to random interference and unpredictable performance.\n\nFourth, battery life. There's no inherent reason that WiFi, when idle, is hungrier than Bluetooth, for example. They use the same radios and low-level framing. The main difference is tuning and in the protocols. For wireless power-saving to work well, devices have to mostly sleep and beacon out to other devices only once every so often. For this to work, they need to synchronize their clocks. This happens properly for the mobile phone part, which is why my old flip phone can run five days on a charge. When WiFi is working, it will use more power. Current power amplifier technology is also inefficient, meaning you draw a lot more energy from your battery than you pump into the air (the waste turns into a hot phone). Power amplifiers are improving as people focus more on mobile WiFi.\n\nLastly, mobile access points. If we can't trust centralized APs, and if our devices are smart enough to run full operating systems, can't we make them work as APs? I'm //so glad// you asked that question. Yes, we can, and it works quite nicely. Especially because you can switch this on and off in software, on a modern OS like Android. Again, the villains of the peace are the US telcos, who mostly detest this feature and kill it or cripple it on the phones they control. Smarter telcos realize that it's a way to amplify their \"last mile\" and bring higher-value products to more users, but crooks don't compete on smarts.\n\n+++ Conclusions\n\nWiFi is not Ethernet and although I believe future ZeroMQ applications will have a very important decentralized wireless presence, it's not going to be an easy road. Much of the basic reliability and capacity that you expect from Ethernet is missing. When you run a distributed application over WiFi, you must allow for frequent timeouts, random latencies, arbitrary disconnections, whole interfaces going down and coming up, and so on.\n\nThe technological evolution of wireless networking is best described as \"slow and joyless\". Applications and frameworks that try to exploit decentralized wireless are mostly absent or poor. The only existing open source framework for proximity networking is [https://www.alljoyn.org AllJoyn] from Qualcomm. But with ZeroMQ, we proved that the inertia and decrepit incompetence of existing players was no reason for us to sit still. When we accurately understand problems, we can solve them. What we imagine, we can make real.\n\n++ Discovery\n\nDiscovery is an essential part of network programming and a first-class problem for ZeroMQ developers. Every {{zmq_connect ()}} call provides an endpoint string, and that has to come from somewhere. The examples we've seen so far don't do discovery: the endpoints they connect to are hard-coded as strings in the code. While this is fine for example code, it's not ideal for real applications. Networks don't behave that nicely. Things change, and it's how well we handle change that defines our long-term success.\n\n+++ Service Discovery\n\nLet's start with definitions. Network discovery is finding out what other peers are on the network. Service discovery is learning what those peers can do for us. Wikipedia defines a \"network service\" as \"a service that is hosted on a computer network\", and \"service\" as \"a set of related software functionalities that can be reused for different purposes, together with the policies that should control its usage\". It's not very helpful. Is Facebook a network service?\n\nIn fact the concept of \"network service\" has changed over time. The number of moving pieces keeps doubling every 18-24 months, breaking old conceptual models and pushing for ever simpler, more scalable ones. A service is, for me, a system-level application that other programs can talk to. A network service is one accessible remotely (as compared to, e.g., the \"grep\" command, which is a command-line service).\n\nIn the classic BSD socket model, a service maps 1-to-1 to a network port. A computer system offers a number of services like \"FTP\", and \"HTTP\", each with assigned ports. The BSD API has functions like {{getservbyname}} to map a service name to a port number. So a classic service maps to a network endpoint: if you know a server's IP address and then you can find its FTP service, if that is running.\n\nIn modern messaging, however, services don't map 1-to-1 to endpoints. One endpoint can lead to many services, and services can move around over time, between ports, or even between systems. Where is my cloud storage today? In a realistic large distributed application, therefore, we need some kind of service discovery mechanism.\n\nThere are many ways to do this and I won't try to provide an exhaustive list. However there are a few classic patterns:\n\n* We can force the old 1-to-1 mapping from endpoint to service, and simply state up-front that a certain TCP port number represents a certain service. Our protocol then should let us check this (\"Are the first 4 bytes of the request 'HTTP'?\").\n\n* We can bootstrap one service off another; connecting to a well-known endpoint and service, asking for the \"real\" service, and getting an endpoint back in return. This gives us a service lookup service. If the lookup service allows it, services can then move around as long as they update their location.\n\n* We can proxy one service through another, so that a well-known endpoint and service will provide other services indirectly (i.e. by forwarding messages to them). This is for instance how our Majordomo service-oriented broker works.\n\n* We can exchange lists of known services and endpoints, that change over time, using a gossip approach or a centralized approach (like the Clone pattern), so that each node in a distributed network can build-up an eventually consistent map of the whole network.\n\n* We can create further abstract layers in between network endpoints and services, e.g. assigning each node a unique identifier, so we get a \"network of nodes\" where each node may offer some services, and may appear on random network endpoints.\n\n* We can discover services opportunistically, e.g. by connecting to endpoints and then asking them what services they offer. \"Hi, do you offer a shared printer? If so, what's the maker and model?\"\n\nThere's no \"right answer\". The range of options is huge, and changes over time as the scale of our networks grows. In some networks the knowledge of what services run where can literally become political power. ZeroMQ imposes no specific model but makes it easy to design and build the ones that suit us best. However, to build service discovery, we must start by solving network discovery.\n\n+++ Network Discovery\n\nHere is a list of the solutions I know for network discovery:\n\n* //Use hard-coded endpoint strings//, i.e., fixed IP addresses and agreed ports. This worked in internal networks a decade ago when there were a few \"big servers\" and they were so important they got static IP addresses. These days however it's no use except in examples or for in-process work (threads are the new Big Iron). You can make it hurt a little less by using DNS but this is still painful for anyone who's not also doing system administration as a side-job.\n\n* //Get endpoint strings from configuration files//. This shoves name resolution into user space, which hurts less than DNS but that's like saying a punch in the face hurts less than a kick in the groin. You now get a non-trivial management problem. Who updates the configuration files, and when? Where do they live? Do we install a distributed management tool like Salt Stack?\n\n* //Use a message broker//. You still need a hard-coded or configured endpoint string to connect to the broker, but this approach reduces the number of different endpoints in the network to one. That makes a real impact, and broker-based networks do scale nicely. However, brokers are single points of failure, and they bring their own set of worries about management and performance.\n\n* //Use an addressing broker//. In other words use a central service to mediate address information (like a dynamic DNS setup) but allow nodes to send each other messages directly. It's a good model but still creates a point of failure and management costs.\n\n* //Use helper libraries, like ZeroConf//, that provide DNS services without any centralized infrastructure. It's a good answer for certain applications but your mileage will vary. Helper libraries aren't zero cost: they make it more complex to build the software, they have their own restrictions, and they aren't necessarily portable.\n\n* //Build system-level discovery// by sending out ARP or ICMP ECHO packets and then querying every node that responds. You can query through a TCP connection, for example, or by sending UDP messages. Some products do this, like the Eye-Fi wireless card.\n\n* //Do user-level brute-force discovery// by trying to connect to every single address in the network segment. You can do this trivially in ZeroMQ since it handles connections in the background. You don't even need multiple threads. It's brutal but fun, and works very well in demos and workshops. However it doesn't scale, and annoys decent-thinking engineers.\n\n* //Roll your own UDP-based discovery protocol//. Lots of people do this (I counted about 80 questions on this topic on StackOverflow). UDP works well for this and it's technically clear. But it's technically tricky to get right, to the point where any developer doing this the first few times will get it dramatically wrong.\n\n* //Gossip discovery protocols//. A fully-interconnected network is quite effective for smaller numbers of nodes (say, up to 100 or 200). For large numbers of nodes, we need some kind of gossip protocol. That is, where the nodes we can reasonable discover (say, on the same segment as us), tell us about nodes that are further away. Gossip protocols go beyond what we need these days with ZeroMQ, but will likely be more common in the future. One example of a wide-area gossip model is mesh networking.\n\n+++ The Use Case\n\nLet's define our use case more explicitly. After all, all these different approaches have worked and still work to some extent. What interests me as architect is the future, and finding designs that can continue to work for more than a few years. This means identifying long term trends. Our use case isn't here and now, it's ten or twenty years from today.\n\nHere are the long term trends I see in distributed applications:\n\n* //The overall number of moving pieces keeps increasing//. My estimate is that it doubles every 24 months, but how fast it increases matters less than the fact that we keep adding more and more nodes to our networks. They're not just boxes but also processes and threads. The driver here is cost, [http://cultureandempire.com/ which keeps falling]. In a decade, the average teenager will carry 30-50 devices, all the time.\n\n* //Control shifts away from the center//. Possibly data too, though we're still far from understanding how to build simple decentralized information stores. In any case, the star topology is slowly dying and being replaced by clouds of clouds. In the future there's going to be much more traffic within a local environment (home, office, school, bar) than between remote nodes and the center. The maths here are simple: remote communications cost more, run more slowly and are less natural than close-range communications. It's more accurate both technically and socially to share a holiday video with your friend over local WiFi than via Facebook.\n\n* //Networks are increasingly collaborative, less controlled//. This means people bringing their own devices and expecting them to work seamlessly. The Web showed one way to make this work but we're reaching the limits of what the Web can do, as we start to exceed the average of one device per person.\n\n* //The cost of connecting a new node to a network must fall proportionally//, if the network is to scale. This means reducing the amount of configuration a node needs: less pre-shared state, less context. Again, the Web solved this problem but at the cost of centralization. We want the same plug and play experience but without a central agency.\n\nIn a world of trillions of nodes, the ones you talk to most are the ones closest to you. This is how it works in the real world and it's the sanest way of scaling large-scale architectures. Groups of nodes, logically or physically close, connected by bridges to other groups of nodes. A local group will be anything from half-a-dozen nodes to a few thousand nodes.\n\nSo we have two basic use cases:\n\n* **Discovery for proximity networks**, that is, a set of nodes that find themselves close to each other. We can define \"close to each other\" as being \"on the same network segment\". It's not going to be true in all cases but it's true enough to be a useful place to start.\n\n* **Discovery across wide area networks**, that is, bridging of proximity networks together. We sometimes call this \"federation\". There are many ways to do federation but it's complex and something to cover elsewhere. For now, let's assume we do federation using a centralized broker or service.\n\nSo we are left with the problem of proximity networking. I want to just plug things into the network and have them talking to each other. Whether they're tablets in a school or a bunch of servers in a cloud, the less upfront agreement and coordination, the cheaper it is to scale. So configuration files and brokers and any kind of centralized service are all out.\n\nI also want to allow any number of applications on a box, both because that's how the real world works (people download apps), and so that I can simulate large networks on my laptop. Upfront simulation is the only way I know to be sure a system will work when it's loaded in real-life. You'd be surprised how engineers just hope things will work. \"Oh, I'm sure that bridge will stay up when we open it to traffic\". If you haven't simulated and fixed the three most likely failures, they'll still be there on opening day.\n\nRunning multiple instances of a service on the same machine - without upfront coordination - means we have to use ephemeral ports, i.e., ports assigned randomly for services. Ephemeral ports rule out brute-force TCP discovery and any DNS solution including ZeroConf.\n\nFinally, discovery has to happen in user space because the apps we're building will be running on random boxes that we do not necessarily own and control. For example, other people's mobile devices. So any discovery that needs root permissions is excluded. This rules out ARP and ICMP and once again ZeroConf since that also needs root permissions for the service parts.\n\n+++ Technical Requirements\n\nLet's recap the requirements:\n\n* //The simplest possible solution that works//. There are so many edge cases in ad-hoc networks that every extra feature or functionality becomes a risk.\n\n* //Supports ephemeral ports//, so that we can run realistic simulations. If the only way to test is to use real devices, it becomes impossibly expensive and slow to run tests.\n\n* //No root access needed//, it must run 100% in user space. We want to ship fully-packaged applications onto devices like mobile phones that we don't own and where root access isn't available.\n\n* //Invisible to system administrators//, so we do not need their help to run our applications. Whatever technique we use should be friendly to the network and available by default.\n\n* //Zero configuration// apart from installing the applications themselves. Asking the users to do any configuration is giving them an excuse to not use the applications.\n\n* //Fully portable// to all modern operating systems. We can't assume we'll be running on any specific OS. We can't assume any support from the operating system except standard user-space networking. We can assume ZeroMQ and CZMQ are available.\n\n* //Friendly to WiFi networks// with up to 100-150 participants. This means keeping messages small and being aware of how WiFi networks scale and how they break under pressure.\n\n* //Protocol-neutral//, i.e., our beaconing should not impose any specific discovery protocol. I'll explain what this means a little later.\n\n* //Easy to re-implement in any given language//. Sure, we have a nice C implementation, but if it takes too long to re-implement in another language, that excludes large chunks of the ZeroMQ community. So, again, simple.\n\n* //Fast response time//. By this, I mean a new node should be visible to its peers in a very short time, a second or two at most. Networks change shape rapidly. It's OK to take longer, even 30 seconds, to realize a peer has disappeared.\n\nFrom the list of possible solutions I collected, the only option that isn't disqualified for one or more reasons is to build our own UDP-based discovery stack. It's a little disappointing that after so many decades of research into network discovery, this is where we end up. But the history of computing does seem to go from complex to simple, so maybe it's normal.\n\n+++ A Self-Healing P2P Network in 30 Seconds\n\nI mentioned brute-force discovery. Let's see how that works. One nice thing about software is to brute-force your way through the learning experience. As long as we're happy to throw away work, we can learn rapidly simply by trying things that may seem insane from the safety of the armchair.\n\nI'll explain a brute-force discovery approach for ZeroMQ that emerged from a workshop in 2012. It is remarkably simple and stupid: connect to every IP address in the room. If your network segment is 192.168.55.x, for instance, you do this:\n\n[[code]]\nconnect to tcp://192.168.55.1:9000\nconnect to tcp://192.168.55.2:9000\nconnect to tcp://192.168.55.3:9000\n...\nconnect to tcp://192.168.55.254:9000\n[[/code]]\n\nWhich in ZeroMQ-speak looks like this:\n\n[[code type=\"fragment\" name=\"brute-force-discovery\"]]\nint address;\nfor (address = 1; address < 255; address++)\n    zsocket_connect (listener, \"tcp://192.168.55.%d:9000\", address);\n[[/code]]\n\nThe stupid part is where we assume that connecting to ourselves is fine, where we assume that all peers are on the same network segment, where we waste file handles as if they were free. Luckily these assumptions are often totally accurate. At least, often enough to let us do fun things.\n\nThe loop works because ZeroMQ connect calls are //asynchronous and opportunistic//. They lie in the shadows like hungry cats, waiting patiently to pounce on any innocent mouse that dared start up a service on port 9000. It's simple, effective, and worked first time.\n\nIt gets better: as peers leave and join the network, they'll automatically reconnect. We've designed a self-healing peer to peer network, in 30 seconds and three lines of code.\n\nIt won't work for real cases though. Poorer operating systems tend to run out of file handles, and networks tend to be more complex than one segment. And if one node squats a couple of hundred file handles, large-scale simulations (with many nodes on one box or in one process) are out of the question.\n\nStill, let's see how far we can go with this approach before we throw it out. Here's a tiny decentralized chat program that lets you talk to anyone else on the same network segment. The code has two threads: a listener and a broadcaster. The listener creates a SUB socket and does the brute-force connection to all peers in the network. The broadcaster accepts input from the console and sends it on a PUB socket:\n\n[[code type=\"example\" title=\"Decentralized Chat\" name=\"dechat\"]]\n[[/code]]\n\nThe {{dechat}} program needs to know the current IP address, the interface, and an alias. We could get these in code from the operating system, but that's grunky non-portable code. So we provide this information on the command line:\n\n[[code]]\ndechat 192.168.55.122 eth0 Joe\n[[/code]]\n\n+++ Preemptive Discovery over Raw Sockets\n\nOne of the great things about short-range wireless is the proximity. WiFi maps closely to the physical space, which maps closely to how we naturally organize. In fact, the Internet is quite abstract and this confuses a lot of people who kind of \"get it\" but in fact don't really. With WiFi, we have technical connectivity that is potentially super-tangible. You see what you get and you get what you see. Tangible means easy to understand and that should mean love from users instead of the typical frustration and seething hatred.\n\nProximity is the key. We have a bunch of WiFi radios in a room, happily beaconing to each other. For lots of applications, it makes sense that they can find each other and start chatting without any user input. After all, most real world data isn't private, it's just highly localized.\n\nI'm in a hotel room in Gangnam, Seoul, with a 4G wireless hotspot, a Linux laptop, and an couple of Android phones. The phones and laptop are talking to the hotspot. The {{ifconfig}} command says my IP address is 192.168.1.2. Let me try some {{ping}} commands. DHCP servers tend to dish out addresses in sequence, so my phones are probably close by, numerically speaking:\n\n[[code]]\n$ ping 192.168.1.1\nPING 192.168.1.1 (192.168.1.1) 56(84) bytes of data.\n64 bytes from 192.168.1.1: icmp_req=1 ttl=64 time=376 ms\n64 bytes from 192.168.1.1: icmp_req=2 ttl=64 time=358 ms\n64 bytes from 192.168.1.1: icmp_req=4 ttl=64 time=167 ms\n^C\n--- 192.168.1.1 ping statistics ---\n3 packets transmitted, 2 received, 33% packet loss, time 2001ms\nrtt min/avg/max/mdev = 358.077/367.522/376.967/9.445 ms\n[[/code]]\n\nFound one! 150-300 msec round-trip latency... that's a surprisingly high figure, something to keep in mind for later. Now I ping myself, just to try to double-check things:\n\n[[code]]\n$ ping 192.168.1.2\nPING 192.168.1.2 (192.168.1.2) 56(84) bytes of data.\n64 bytes from 192.168.1.2: icmp_req=1 ttl=64 time=0.054 ms\n64 bytes from 192.168.1.2: icmp_req=2 ttl=64 time=0.055 ms\n64 bytes from 192.168.1.2: icmp_req=3 ttl=64 time=0.061 ms\n^C\n--- 192.168.1.2 ping statistics ---\n3 packets transmitted, 3 received, 0% packet loss, time 1998ms\nrtt min/avg/max/mdev = 0.054/0.056/0.061/0.009 ms\n[[/code]]\n\nThe response time is a bit faster now, which is what we'd expect. Let's try the next couple of addresses:\n\n[[code]]\n$ ping 192.168.1.3\nPING 192.168.1.3 (192.168.1.3) 56(84) bytes of data.\n64 bytes from 192.168.1.3: icmp_req=1 ttl=64 time=291 ms\n64 bytes from 192.168.1.3: icmp_req=2 ttl=64 time=271 ms\n64 bytes from 192.168.1.3: icmp_req=3 ttl=64 time=132 ms\n^C\n--- 192.168.1.3 ping statistics ---\n3 packets transmitted, 3 received, 0% packet loss, time 2001ms\nrtt min/avg/max/mdev = 132.781/231.914/291.851/70.609 ms\n[[/code]]\n\nThat's the second phone, with the same kind of latency as the first one. Let's continue and see if there are any other devices connected to the hotspot:\n\n[[code]]\n$ ping 192.168.1.4\nPING 192.168.1.4 (192.168.1.4) 56(84) bytes of data.\n^C\n--- 192.168.1.4 ping statistics ---\n3 packets transmitted, 0 received, 100% packet loss, time 2016ms\n[[/code]]\n\nAnd that is it. Now, {{ping}} uses raw IP sockets to send {{ICMP_ECHO}} messages. The useful thing about {{ICMP_ECHO}} is that it gets a response from any IP stack that has not deliberately had echo switched off. That's still a common practice on corporate websites who fear the old \"ping of death\" exploit where malformed messages could crash the machine.\n\nI call this //preemptive discovery// because it doesn't take any cooperation from the device. We don't rely on any cooperation from the phones to see them sitting there; as long as they're not actively ignoring us, we can see them.\n\nYou might ask why this is useful. We don't know that the peers responding to {{ICMP_ECHO}} run ZeroMQ, that they are interested in talking to us, that they have any services we can use, or even what kind of device they are. However, knowing that there's //something// on address 192.168.1.3 is already useful. We also know how far away the device is, relatively, we know how many devices are on the network, and we know the rough state of the network (as in, good, poor, or terrible).\n\nIt isn't even hard to create {{ICMP_ECHO}} messages and send them. A few dozen lines of code, and we could use ZeroMQ multithreading to do this in parallel for addresses stretching out above and below our own IP address. Could be kind of fun.\n\nHowever, sadly, there's a fatal flaw in my idea of using {{ICMP_ECHO}} to discover devices. To open a raw IP socket requires root privileges on a POSIX box. It stops rogue programs getting data meant for others. We can get the power to open raw sockets on Linux by giving sudo privileges to our command (ping has the so-called //sticky bit// set). On a mobile OS like Android, it requires root access, i.e., rooting the phone or tablet. That's out of the question for most people and so {{ICMP_ECHO}} is out of reach for most devices.\n\n//Expletive deleted!// Let's try something in user space. The next step most people take is UDP multicast or broadcast. Let's follow that trail.\n\n+++ Cooperative Discovery Using UDP Broadcasts\n\nMulticast tends to be seen as more modern and \"better\" than broadcast. In IPv6, broadcast doesn't work at all: you must always use multicast. Nonetheless, all IPv4 local network discovery protocols end up using UDP broadcast anyhow. The reasons: broadcast and multicast end up working much the same, except broadcast is simpler and less risky. Multicast is seen by network admins as kind of dangerous, as it can leak over network segments.\n\nIf you've never used UDP, you'll discover it's quite a nice protocol. In some ways, it reminds us of ZeroMQ, sending whole messages to peers using a two different patterns: one-to-one, and one-to-many. The main problems with UDP are that (a) the POSIX socket API was designed for universal flexibility, not simplicity, (b) UDP messages are limited for practical purposes to about 1,500 bytes on LANs and 512 bytes on the Internet, and (c) when you start to use UDP for real data, you find that messages get dropped, especially as infrastructure tends to favor TCP over UDP.\n\nHere is a minimal ping program that uses UDP instead of {{ICMP_ECHO}}:\n\n[[code type=\"example\" title=\"UDP discovery, model 1\" name=\"udpping1\"]]\n[[/code]]\n\nThis code uses a single socket to broadcast 1-byte messages and receive anything that other nodes are broadcasting. When I run it, it shows just one node, which is itself:\n\n[[code]]\nPinging peers...\nFound peer 192.168.1.2:9999\nPinging peers...\nFound peer 192.168.1.2:9999\n[[/code]]\n\nIf I switch off all networking and try again, sending a message fails, as I'd expect:\n\n[[code]]\nPinging peers...\nsendto: Network is unreachable\n[[/code]]\n\nWorking on the basis of //solve the problems currently aiming at your throat//, let's fix the most urgent issues in this first model. These issues are:\n\n* Using the 255.255.255.255 broadcast address is a bit dubious. On the one hand, this broadcast address means precisely \"send to all nodes on the local network, and don't forward\". However, if you have several interfaces (wired Ethernet, WiFi) then broadcasts will go out on your default route only, and via just one interface. What we want to do is either send our broadcast on each interface's broadcast address, or find the WiFi interface and its broadcast address.\n\n* Like many aspects of socket programming, getting information on network interfaces is not portable. Do we want to write nonportable code in our applications? No, this is better hidden in a library.\n\n* There's no handling for errors except \"abort\", which is too brutal for transient problems like \"your WiFi is switched off\". The code should distinguish between soft errors (ignore and retry) and hard errors (assert).\n\n* The code needs to know its own IP address and ignore beacons that it sent out. Like finding the broadcast address, this requires inspecting the available interfaces.\n\nThe simplest answer to these issues is to push the UDP code into a separate library that provides a clean API, like this:\n\n[[code type=\"fragment\" name=\"zyre-udp\"]]\n//  Constructor\nstatic udp_t *\n    udp_new (int port_nbr);\n\n//  Destructor\nstatic void\n    udp_destroy (udp_t **self_p);\n\n//  Returns UDP socket handle\nstatic int\n    udp_handle (udp_t *self);\n\n//  Send message using UDP broadcast\nstatic void\n    udp_send (udp_t *self, byte *buffer, size_t length);\n\n//  Receive message from UDP broadcast\nstatic ssize_t\n    udp_recv (udp_t *self, byte *buffer, size_t length);\n[[/code]]\n\nHere is the refactored UDP ping program that calls this library, which is much cleaner and nicer:\n\n[[code type=\"example\" title=\"UDP discovery, model 2\" name=\"udpping2\"]]\n[[/code]]\n\nThe library, {{udplib}}, hides a lot of the unpleasant code (which will become uglier as we make this work on more systems). I'm not going to print that code here. You can read it [https://github.com/imatix/zguide/blob/master/examples/C/udplib.c in the repository].\n\nNow, there are more problems sizing us up and wondering if they can make lunch out of us. First, IPv4 versus IPv6 and multicast versus broadcast. In IPv6, broadcast doesn't exist at all; one uses multicast. From my experience with WiFi, IPv4 multicast and broadcast work identically except that multicast breaks in some situations where broadcast works fine. Some access points do not forward multicast packets. When you have a device (e.g., a tablet) that acts as a mobile AP, then it's possible it won't get multicast packets. Meaning, it won't see other peers on the network.\n\nThe simplest plausible solution is simply to ignore IPv6 for now, and use broadcast. A perhaps smarter solution would be to use multicast and deal with asymmetric beacons if they happen.\n\nWe'll stick with stupid and simple for now. There's always time to make it more complex.\n\n+++ Multiple Nodes on One Device\n\nSo we can discover nodes on the WiFi network, as long as they're sending out beacons as we expect. So I try to test with two processes. But when I run udpping2 twice, the second instance complains \"'Address already in use' on bind\" and exits. Oh, right. UDP and TCP both return an error if you try to bind two different sockets to the same port. This is right. The semantics of two readers on one socket would be weird to say the least. Odd/even bytes? You get all the 1s, I get all the 0's?\n\nHowever, a quick check of stackoverflow.com and some memory of a socket option called {{SO_REUSEADDR}} turns up gold. If I use that, I can bind several processes to the same UDP port, and they will all receive any message arriving on that port. It's almost as if the guys who designed this were reading my mind! (That's way more plausible than the chance that I may be reinventing the wheel.)\n\nA quick test shows that {{SO_REUSEADDR}} works as promised. This is great because the next thing I want to do is design an API and then start dozens of nodes to see them discovering each other. It would be really cumbersome to have to test each node on a separate device. And when we get to testing how real traffic behaves on a large, flaky network, the two alternatives are simulation or temporary insanity.\n\nAnd I speak from experience: we were, this summer, testing on dozens of devices at once. It takes about an hour to set up a full test run, and you need a space shielded from WiFi interference if you want any kind of reproducibility (unless your test case is \"prove that interference kills WiFi networks faster than Orval can kill a thirst\".\n\nIf I were a whiz Android developer with a free weekend, I'd immediately (as in, it would take me two days) port this code to my phone and get it sending beacons to my PC. But sometimes lazy is more profitable. I //like// my Linux laptop. I like being able to start a dozen threads from one process, and have each thread acting like an independent node. I like not having to work in a real Faraday cage when I can simulate one on my laptop.\n\n+++ Designing the API\n\nI'm going to run N nodes on a device, and they are going to have to discover each other, as well as a bunch of other nodes out there on the local network. I can use UDP for local discovery as well as remote discovery. It's arguably not as efficient as using, e.g., the ZeroMQ inproc:// transport, but it has the great advantage that the exact same code will work in simulation and in real deployment.\n\nIf I have multiple nodes on one device, we clearly can't use the IP address and port number as node address. I need some logical node identifier. Arguably, the node identifier only has to be unique within the context of the device. My mind fills with complex stuff I could make, like supernodes that sit on real UDP ports and forward messages to internal nodes. I hit my head on the table until the idea of //inventing new concepts// leaves it.\n\nExperience tells us that WiFi does things like disappear and reappear while applications are running. Users click on things, which does interesting things like change the IP address halfway through a session. We cannot depend on IP addresses, nor on established connections (in the TCP fashion). We need some long-lasting addressing mechanism that survives interfaces and connections being torn down and then recreated.\n\nHere's the simplest solution I can see: we give every node a UUID, and specify that nodes, represented by their UUIDs, can appear or reappear at certain IP address:port endpoints, and then disappear again. We'll deal with recovery from lost messages later. A UUID is 16 bytes. So if I have 100 nodes on a WiFi network, that's (double it for other random stuff) 3,200 bytes a second of beacon data that the air has to carry just for discovery and presence. Seems acceptable.\n\nBack to concepts. We do need some names for our API. At the least we need a way to distinguish between the node object that is \"us\", and node objects that are our peers.  We'll be doing things like creating an \"us\" and then asking it how many peers it knows about and who they are. The term \"peer\" is clear enough.\n\nFrom the developer point of view, a node (the application) needs a way to talk to the outside world. Let's borrow a term from networking and call this an \"interface\". The interface represents us to the rest of the world and presents the rest of the world to us, as a set of other peers. It automatically does whatever discovery it must. When we want to talk to a peer, we get the interface to do that for us. And when a peer talks to us, it's the interface that delivers us the message.\n\nThis seems like a clean API design. How about the internals?\n\n* The interface must be multithreaded so that one thread can do I/O in the background, while the foreground API talks to the application. We used this design in the Clone and Freelance client APIs.\n\n* The interface background thread does the discovery business; bind to the UDP port, send out UDP beacons, and receive beacons.\n\n* We need to at least send UUIDs in the beacon message so that we can distinguish our own beacons from those of our peers.\n\n* We need to track peers that appear, and that disappear. For this, I'll use a hash table that stores all known peers and expire peers after some timeout.\n\n* We need a way to report peers and events to the caller. Here we get into a juicy question. How does a background I/O thread tell a foreground API thread that stuff is happening? Callbacks maybe? //Heck no.// We'll use ZeroMQ messages, of course.\n\nThe third iteration of the UDP ping program is even simpler and more beautiful than the second. The main body, in C, is just ten lines of code.\n\n[[code type=\"example\" title=\"UDP discovery, model 3\" name=\"udpping3\"]]\n[[/code]]\n\nThe interface code should be familiar if you've studied how we make multithreaded API classes:\n\n[[code type=\"example\" title=\"UDP ping interface\" name=\"interface\"]]\n[[/code]]\n\nWhen I run this in two windows, it reports one peer joining the network. I kill that peer and a few seconds later, it tells me the peer left:\n\n[[code]]\n--------------------------------------\n[006] JOINED\n[032] 418E98D4B7184844B7D5E0EE5691084C\n--------------------------------------\n[004] LEFT\n[032] 418E98D4B7184844B7D5E0EE5691084C\n[[/code]]\n\nWhat's nice about a ZeroMQ-message based API is that I can wrap this any way I like. For instance, I can turn it into callbacks if I really want those. I can also trace all activity on the API very easily.\n\nSome notes about tuning. On Ethernet, five seconds (the expiry time I used in this code) seems like a lot. On a badly stressed WiFi network, you can get ping latencies of 30 seconds or more. If you use a too-aggressive value for the expiry, you'll disconnect nodes that are still there. On the other side, end user applications expect a certain liveliness. If it takes 30 seconds to report that a node has gone, users will get annoyed.\n\nA decent strategy is to detect and report disappeared nodes rapidly, but only delete them after a longer interval. Visually, a node would be green when it's alive, then gray for a while as it went out of reach, then finally disappear. We're not doing this now, but will do it in the real implementation of the as-yet-unnamed framework we're making.\n\nAs we will also see later, we have to treat any input from a node, not just UDP beacons, as a sign of life. UDP may get squashed when there's a lot of TCP traffic. This is perhaps the main reason we're not using an existing UDP discovery library: it's necessary to integrate this tightly with our ZeroMQ messaging for it to work.\n\n+++ More About UDP\n\nSo we have discovery and presence working over UDP IPv4 broadcasts. It's not ideal, but it works for the local networks we have today. However we can't use UDP for real work, not without additional work to make it reliable. There's a joke about UDP but sometimes you'll get it, and sometimes you won't.\n\nWe'll stick to TCP for all one-to-one messaging. There is one more use case for UDP after discovery, which is multicast file distribution. I'll explain why and how, then shelve that for another day. The why is simple: what we call \"social networks\" is just augmented culture. We create culture by sharing, and this means more and more sharing works that we make or remix. Photos, documents, contracts, tweets. The clouds of devices we're aiming towards do more of this, not less.\n\nNow, there are two principal patterns for sharing content. One is the pub-sub pattern where one node sends out content to a set of other nodes simultaneously. Second is the \"late joiner\" pattern, where a node arrives somewhat later and wants to catch up to the conversation. We can deal with the late joiner using TCP unicast. But doing TCP unicast to a group of clients at the same time has some disadvantages. First, it can be slower than multicast. Second, it's unfair because some will get the content before others.\n\nBefore you jump off to design a UDP multicast protocol, realize that it's not a simple calculation. When you send a multicast packet, the WiFi access point uses a low bit rate to ensure that even the furthest devices will get it safely. Most normal APs don't do the obvious optimization, which is to measure the distance of the furthest device and use that bit rate. Instead, they just use a fixed value. So if you have a few devices close to the AP, multicast will be insanely slow. But if you have a roomful of devices which all want to get the next chapter of the textbook, multicast can be insanely effective.\n\nThe curves cross at about 6-12 devices depending on the network. In theory, you could measure the curves in real time and create an adaptive protocol. That would be cool but probably too hard for even the smartest of us.\n\nIf you do sit down and sketch out a UDP multicast protocol, realize that you need a channel for recovery, to get lost packets. You'd probably want to do this over TCP, using ZeroMQ. For now, however, we'll forget about multicast UDP and assume all traffic goes over TCP.\n\n++ Spinning Off a Library Project\n\nAt this stage, however, the code is growing larger than an example should be, so it's time to create a proper GitHub project. It's a rule: build your projects in public view, and tell people about them as you go so your marketing and community building starts on Day 1. I'll walk through what this involves. I explained in [#the-community] about growing communities around projects. We need a few things:\n\n* A name\n* A slogan\n* A public github repository\n* A README that links to the C4 process\n* License files\n* An issue tracker\n* Two maintainers\n* A first bootstrap version\n\nThe name and slogan first. The trademarks of the 21st century are domain names. So the first thing I do when spinning off a project is to look for a domain name that might work. Quite randomly, one of our old messaging projects was called \"Zyre\" and I have the domain name for it. The full name is a backronym: the ZeroMQ Realtime Exchange framework.\n\nI'm somewhat shy about pushing new projects into the ZeroMQ community too aggressively, and normally would start a project in either my personal account or the iMatix organization. But we've learned that moving projects after they become popular is counterproductive. My predictions of a future filled with moving pieces are either valid or wrong. If this chapter is valid, we might as well launch this as a ZeroMQ project from the start. If it's wrong, we can delete the repository later or let it sink to the bottom of a long list of forgotten starts.\n\nStart with the basics. The protocol (UDP and ZeroMQ/TCP) will be ZRE (ZeroMQ Realtime Exchange protocol) and the project will be Zyre. I need a second maintainer, so I invite my friend Dong Min (the Korean hacker behind JeroMQ, a pure-Java ZeroMQ stack) to join. He's been working on very similar ideas so is enthusiastic. We discuss this and we get the idea of building Zyre on top of JeroMQ, as well as on top of CZMQ and {{libzmq}}. This would make it a lot easier to run Zyre on Android. It would also give us two fully separate implementations from the start, which is always a good thing for a protocol.\n\nSo we take the FileMQ project I built in [#advanced-architecture] as a template for a new GitHub project. The GNU autoconf tools are quite decent, but have a painful syntax. It's easiest to copy existing project files and modify them. The FileMQ project builds a library, has test tools, license files, man pages, and so on. It's not too large so it's a good starting point.\n\nI put together a README to summarize the goals of the project and point to C4. The issue tracker is enabled by default on new GitHub projects, so once we've pushed the UDP ping code as a first version, we're ready to go. However, it's always good to recruit more maintainers, so I create an issue \"Call for maintainers\" that says:\n\n> If you'd like to help click that lovely green \"Merge Pull Request\" button and get eternal good karma, add a comment confirming that you've read and understand the C4 process at http://rfc.zeromq.org/spec:22.\n\nFinally, I change the issue tracker labels. By default, GitHub offers the usual variety of issue types, but with C4 we don't use them. Instead, we need just two labels (\"Urgent\", in red, and \"Ready\", in black).\n\n++ Point-to-Point Messaging\n\nI'm going to take the last UDP ping program and build a point-to-point messaging layer on top of that. Our goal is that we can detect peers as they join and leave the network, that we can send messages to them, and that we can get replies. It is a nontrivial problem to solve and takes Min and me two days to get a \"Hello World\" version working.\n\nWe had to solve a number of issues:\n\n* What information to send in the UDP beacon, and how to format it.\n* What ZeroMQ socket types to use to interconnect nodes.\n* What ZeroMQ messages to send, and how to format them.\n* How to send a message to a specific node.\n* How to know the sender of any message so we could send a reply.\n* How to recover from lost UDP beacons.\n* How to avoid overloading the network with beacons.\n\nI'll explain these in enough detail so that you understand why we made each choice we did, with some code fragments to illustrate. We tagged this code as [https://github.com/zeromq/zyre/zipball/v0.1.0 version 0.1.0] so you can look at the code: most of the hard work is done in {{zre_interface.c}}.\n\n+++ UDP Beacon Framing\n\nSending UUIDs across the network is the bare minimum for a logical addressing scheme. However, we have a few more aspects to get working before this will work in real use:\n\n* We need some protocol identification so that we can check for and reject invalid packets.\n* We need some version information so that we can change this protocol over time.\n* We need to tell other nodes how to reach us via TCP, i.e., a ZeroMQ port they can talk to us on.\n\nLet's start with the beacon message format. We probably want a fixed protocol header that will never change in future versions and a body that depends on the version[figure].\n\n[[code type=\"textdiagram\" title=\"ZRE discovery message\"]]\n#---+---+---+------#  #------+------#\n| Z | R | E | %x01 |  | UUID | port |\n#---+---+---+------#  #------+------#\n\n       Header               Body\n[[/code]]\n\nThe version can be a 1-byte counter starting at 1. The UUID is 16 bytes and the port is a 2-byte port number because UDP nicely tells us the sender's IP address for every message we receive. This gives us a 22-byte frame.\n\nThe C language (and a few others like Erlang) make it simple to read and write binary structures. We define the beacon frame structure:\n\n[[code type=\"fragment\" name=\"zyre-beacon\"]]\n#define BEACON_PROTOCOL     \"ZRE\"\n#define BEACON_VERSION      0x01\n\ntypedef struct {\n    byte protocol [3];\n    byte version;\n    uuid_t uuid;\n    uint16_t port;\n} beacon_t;\n[[/code]]\n\nThis makes sending and receiving beacons quite simple. Here is how we send a beacon, using the {{zre_udp}} class to do the nonportable network calls:\n\n[[code type=\"fragment\" name=\"zyre-beacon-send\"]]\n//  Beacon object\nbeacon_t beacon;\n\n//  Format beacon fields\nbeacon.protocol [0] = 'Z';\nbeacon.protocol [1] = 'R';\nbeacon.protocol [2] = 'E';\nbeacon.version = BEACON_VERSION;\nmemcpy (beacon.uuid, self->uuid, sizeof (uuid_t));\nbeacon.port = htons (self->port);\n\n//  Broadcast the beacon to anyone who is listening\nzre_udp_send (self->udp, (byte *) &beacon, sizeof (beacon_t));\n[[/code]]\n\nWhen we receive a beacon, we need to guard against bogus data. We're not going to be paranoid against, for example, denial-of-service attacks. We just want to make sure that we're not going to crash when a bad ZRE implementation sends us erroneous frames.\n\nTo validate a frame, we check its size and header. If those are OK, we assume the body is usable. When we get a UUID that isn't ourselves (recall, we'll get our own UDP broadcasts back), we can treat this as a peer:\n\n[[code type=\"fragment\" name=\"zyre-beacon-recv\"]]\n//  Get beacon frame from network\nbeacon_t beacon;\nssize_t size = zre_udp_recv (self->udp,\n    (byte *) &beacon, sizeof (beacon_t));\n\n//  Basic validation on the frame\nif (size != sizeof (beacon_t)\n||  beacon.protocol [0] != 'Z'\n||  beacon.protocol [1] != 'R'\n||  beacon.protocol [2] != 'E'\n||  beacon.version != BEACON_VERSION)\n    return 0;               //  Ignore invalid beacons\n\n//  If we got a UUID and it's not our own beacon, we have a peer\nif (memcmp (beacon.uuid, self->uuid, sizeof (uuid_t))) {\n    char *identity = s_uuid_str (beacon.uuid);\n    s_require_peer (self, identity,\n        zre_udp_from (self->udp), ntohs (beacon.port));\n    free (identity);\n}\n[[/code]]\n\n+++ True Peer Connectivity (Harmony Pattern)\n\nBecause ZeroMQ is designed to make distributed messaging easy, people often ask how to interconnect a set of true peers (as compared to obvious clients and servers). It is a thorny question and ZeroMQ doesn't really provide a single clear answer.\n\nTCP, which is the most commonly-used transport in ZeroMQ, is not symmetric; one side must bind and one must connect and though ZeroMQ tries to be neutral about this, it's not. When you connect, you create an outgoing message pipe. When you bind, you do not. When there is no pipe, you cannot write messages (ZeroMQ will return {{EAGAIN}}).\n\nDevelopers who study ZeroMQ and then try to create N-to-N connections between sets of equal peers often try a ROUTER-to-ROUTER flow. It's obvious why: each peer needs to address a set of peers, which requires ROUTER. It usually ends with a plaintive email to the list.\n\nExperience teaches us that ROUTER-to-ROUTER is particularly difficult to use successfully. At a minimum, one peer must bind and one must connect, meaning the architecture is not symmetrical. But also because you simply can't tell when you are allowed to safely send a message to a peer. It's a Catch-22: you can talk to a peer after it's talked to you, but the peer can't talk to you until you've talked to it. One side or the other will be losing messages and thus has to retry, which means the peers cannot be equal.\n\nI'm going to explain the Harmony pattern, which solves this problem, and which we use in Zyre.\n\nWe want a guarantee that when a peer \"appears\" on our network, we can talk to it safely without ZeroMQ dropping messages. For this, we have to use a DEALER or PUSH socket that //connects out to the peer// so that even if that connection takes some non-zero time, there is immediately a pipe and ZeroMQ will accept outgoing messages.\n\nA DEALER socket cannot address multiple peers individually. But if we have one DEALER per peer, and we connect that DEALER to the peer, we can safely send messages to a peer as soon as we've connected to it.\n\nNow, the next problem is to know who sent us a particular message. We need a reply address that is the UUID of the node who sent any given message. DEALER can't do this unless we prefix every single message with that 16-byte UUID, which would be wasteful. ROUTER does do it if we set the identity properly before connecting to the router.\n\nAnd so the Harmony pattern comes down to these components:\n\n* One ROUTER socket that we bind to a ephemeral port, which we broadcast in our beacons.\n* One DEALER socket //per peer// that we connect to the peer's ROUTER socket.\n* Reading from our ROUTER socket.\n* Writing to the peer's DEALER socket.\n\nThe next problem is that discovery isn't neatly synchronized. We can get the first beacon from a peer //after// we start to receive messages from it. A message comes in on the ROUTER socket and has a nice UUID attached to it, but no physical IP address and port. We have to force discovery over TCP. To do this, our first command to any new peer to which we connect is an {{OHAI}} command with our IP address and port. This ensure that the receiver connects back to us before trying to send us any command.\n\nHere it is, broken down into steps:\n\n* If we receive a UDP beacon from a new peer, we connect to the peer through a DEALER socket.\n* We read messages from our ROUTER socket, and each message comes with the UUID of the sender.\n* If it's an {{OHAI}} message, we connect back to that peer if not already connected to it.\n* If it's any other message, we //must// already be connected to the peer (a good place for an assertion).\n* We send messages to each peer using the per-peer DEALER socket, which //must// be connected.\n* When we connect to a peer, we also tell our application that the peer exists.\n* Every time we get a message from a peer, we treat that as a heartbeat (it's alive).\n\nIf we were not using UDP but some other discovery mechanism, I'd still use the Harmony pattern for a true peer network: one ROUTER for input from all peers, and one DEALER per peer for output. Bind the ROUTER, connect the DEALER, and start each conversation with an {{OHAI}} equivalent that provides the return IP address and port. You would need some external mechanism to bootstrap each connection.\n\n+++ Detecting Disappearances\n\nHeartbeating sounds simple but it's not. UDP packets get dropped when there's a lot of TCP traffic, so if we depend on UDP beacons, we'll get false disconnections. TCP traffic can be delayed for 5, 10, even 30 seconds if the network is really busy. So if we kill peers when they go quiet, we'll have false disconnections.\n\nBecause UDP beacons aren't reliable, it's tempting to add in TCP beacons. After all, TCP will deliver them reliably. However, there's one little problem. Imagine that you have 100 nodes on a network, and each node sends a TCP beacon once a second. Each beacon is 22 bytes, not counting TCP's framing overhead. That is 100 * 99 * 22 bytes per second, or 217,000 bytes/second just for heartbeating. That's about 1-2% of a typical WiFi network's ideal capacity, which sounds OK. But when a network is stressed or fighting other networks for airspace, that extra 200K a second will break what's left. UDP broadcasts are at least low cost.\n\nSo what we do is switch to TCP heartbeats only when a specific peer hasn't sent us any UDP beacons in a while. And then we send TCP heartbeats only to that one peer. If the peer continues to be silent, we conclude it's gone away. If the peer comes back with a different IP address and/or port, we have to disconnect our DEALER socket and reconnect to the new port.\n\nThis gives us a set of states for each peer, though at this stage the code doesn't use a formal state machine:\n\n* Peer visible thanks to UDP beacon (we connect using IP address and port from beacon)\n* Peer visible thanks to {{OHAI}} command (we connect using IP address and port from command)\n* Peer seems alive (we got a UDP beacon or command over TCP recently)\n* Peer seems quiet (no activity in some time, so we send a {{HUGZ}} command)\n* Peer has disappeared (no reply to our {{HUGZ}} commands, so we destroy peer)\n\nThere's one remaining scenario we didn't address in the code at this stage. It's possible for a peer to change IP addresses and ports without actually triggering a disappearance event. For example, if the user switches off WiFi and then switches it back on, the access point can assign the peer a new IP address. We'll need to handle a disappeared WiFi interface on our node by unbinding the ROUTER socket and rebinding it when we can. Because this is not central to the design now, I decide to log an issue on the GitHub tracker and leave it for a rainy day.\n\n++ Group Messaging\n\nGroup messaging is a common and very useful pattern. The concept is simple: instead of talking to a single node, you talk to a \"group\" of nodes. The group is just a name, a string that you agree on in the application. It's precisely like using the pub-sub prefixes in PUB and SUB sockets. In fact, the only reason I say \"group messaging\" and not \"pub-sub\" is to prevent confusion, because we're not going to use PUB-SUB sockets for this.\n\nPUB-SUB sockets would almost work. But we've just done such a lot of work to solve the late joiner problem. Applications are inevitably going to wait for peers to arrive before sending messages to groups, so we have to build on the Harmony pattern rather than start again beside it.\n\nLet's look at the operations we want to do on groups:\n\n* We want to join and leave groups.\n* We want to know what other nodes are in any given group.\n* We want to send a message to (all nodes in) a group.\n\nThese look familiar to anyone who's used Internet Relay Chat, except that we have no server. Every node will need to keep track of what each group represents. This information will not always be fully consistent across the network, but it will be close enough.\n\nOur interface will track a set of groups (each an object). These are all the known groups with one or more member node, excluding ourselves. We'll track nodes as they leave and join groups. Because nodes can join the network at any time, we have to tell new peers what groups we're in. When a peer disappears, we'll remove it from all groups we know about.\n\nThis gives us some new protocol commands:\n\n* {{JOIN}} - we send this to all peers when we join a group.\n* {{LEAVE}} - we send this to all peers when we leave a group.\n\nPlus, we add a {{groups}} field to the first command we send (renamed from {{OHAI}} to {{HELLO}} at this point because I need a larger lexicon of command verbs).\n\nLastly, let's add a way for peers to double-check the accuracy of their group data. The risk is that we miss one of the above messages. Though we are using Harmony to avoid the typical message loss at startup, it's worth being paranoid. For now, all we need is a way to detect such a failure. We'll deal with recovery later, if the problem actually happens.\n\nI'll use the UDP beacon for this. What we want is a rolling counter that simply tells how many join and leave operations (\"transitions\") there have been for a node. It starts at 0 and increments for each group we join or leave. We can use a minimal 1-byte value because that will catch all failures except the astronomically rare \"we lost precisely 256 messages in a row\" failure (this is the one that hits during the first demo). We will also put the transitions counter into the {{JOIN}}, {{LEAVE}}, and {{HELLO}} commands. And to try to provoke the problem, we'll test by joining/leaving several hundred groups with a high-water mark set to 10 or so.\n\nIt's time to choose verbs for the group messaging. We need a command that means \"talk to one peer\" and one that means \"talk to many peers\". After some attempts, my best choices are {{WHISPER}} and {{SHOUT}}, and this is what the code uses. The {{SHOUT}} command needs to tell the user the group name, as well as the sender peer.\n\nBecause groups are like pub-sub, you might be tempted to use this to broadcast the {{JOIN}} and {{LEAVE}} commands as well, perhaps by creating a \"global\" group that all nodes join. My advice is to keep groups purely as user-space concepts for two reasons. First, how do you join the global group if you need the global group to send out a {{JOIN}} command? Second, it creates special cases (reserved names) which are messy.\n\nIt's simpler just to send {{JOIN}}s and {{LEAVE}}s explicitly to all connected peers, period.\n\nI'm not going to work through the implementation of group messaging in detail because it's fairly pedantic and not too exciting. The data structures for group and peer management aren't optimal, but they're workable. We use the following:\n\n* A list of groups for our interface, which we can send to new peers in a {{HELLO}} command;\n* A hash of groups for other peers, which we update with information from {{HELLO}}, {{JOIN}}, and {{LEAVE}} commands;\n* A hash of peers for each group, which we update with the same three commands.\n\nAt this stage, I'm starting to get pretty happy with the binary serialization (our codec generator from [#advanced-architecture]), which handles lists and dictionaries as well as strings and integers.\n\nThis version is tagged in the repository as v0.2.0 and you can [https://github.com/zeromq/zyre/tags download the tarball] if you want to check what the code looked like at this stage.\n\n++ Testing and Simulation\n\nWhen you build a product out of pieces, and this includes a distributed framework like Zyre, the only way to know that it will work properly in real life is to simulate real activity on each piece.\n\n+++ On Assertions\n\nThe proper use of assertions is one of the hallmarks of a professional programmer.\n\nOur confirmation bias as creators makes it hard to test our work properly. We tend to write tests to prove the code works, rather than trying to prove it doesn't. There are many reasons for this. We pretend to ourselves and others that we can be (could be) perfect, when in fact we consistently make mistakes. Bugs in code are seen as \"bad\", rather than \"inevitable\", so psychologically we want to see fewer of them, not uncover more of them. \"He writes perfect code\" is a compliment rather than a euphemism for \"he never takes risks so his code is as boring and heavily used as cold spaghetti\".\n\nSome cultures teach us to aspire to perfection and punish mistakes in education and work, which makes this attitude worse. To accept that we're fallible, and then to learn how to turn that into profit rather than shame is one of the hardest intellectual exercises in any profession. We leverage our fallibilities by working with others and by challenging our own work sooner, not later.\n\nOne trick that makes it easier is to use assertions. Assertions are not a form of error handling. They are executable theories of fact. The code asserts, \"At this point, such and such must be true\" and if the assertion fails, the code kills itself.\n\nThe faster you can prove code incorrect, the faster and more accurately you can fix it. Believing that code works and proving that it behaves as expected is less science, more magical thinking. It's far better to be able to say, \"{{libzmq}} has five hundred assertions and despite all my efforts, not one of them fails\".\n\nSo the Zyre code base is scattered with assertions, and particularly a couple on the code that deals with the state of peers. This is the hardest aspect to get right: peers need to track each other and exchange state accurately or things stop working. The algorithms depend on asynchronous messages flying around and I'm pretty sure the initial design has flaws. It always does.\n\nAnd as I test the original Zyre code by starting and stopping instances of {{zre_ping}} by hand, every so often I get an assertion failure. Running by hand doesn't reproduce these often enough, so let's make a proper tester tool.\n\n+++ On Up-Front Testing\n\nBeing able to fully test the real behavior of individual components in the laboratory can make a 10x or 100x difference to the cost of your project. That confirmation bias engineers have to their own work makes up-front testing incredibly profitable, and late-stage testing incredibly expensive.\n\nI'll tell you a short story about a project we worked on in the late 1990's. We provided the software and other teams provided the hardware for a factory automation project. Three or four teams brought their experts on-site, which was a remote factory (funny how the polluting factories are always in remote border country).\n\nOne of these teams, a firm specializing in industrial automation, built ticket machines: kiosks, and software to run on them. Nothing unusual: swipe a badge, choose an option, receive a ticket. They assembled two of these kiosks on-site, each week bringing some more bits and pieces. Ticket printers, monitor screens, special keypads from Israel. The stuff had to be resistant against dust because the kiosks sat outside. Nothing worked. The screens were unreadable in the sun. The ticket printers continually jammed and misprinted. The internals of the kiosk just sat on wooden shelving. The kiosk software crashed regularly. It was comedic except that the project really, //really// had to work and so we spent weeks and then months on-site helping the other teams debug their bits and pieces until it worked.\n\nA year later, there was a second factory, and the same story. By this time the client, was getting impatient. So when they came to the third and largest factory, a year later, we jumped up and said, \"please let us make the kiosks and the software and everything\".\n\nWe made a detailed design for the software and hardware and found suppliers for all the pieces. It took us three months to search the Internet for each component (in those days, the Internet was a lot slower), and another two months to get them assembled into stainless-steel bricks each weighing about twenty kilos. These bricks were two feet square and eight inches deep, with a large flat-screen panel behind unbreakable glass, and two connectors: one for power, one for Ethernet. You loaded up the paper bin with enough for six months, then screwed the brick into a housing, and it automatically booted, found its DNS server, loaded its Linux OS and then application software. It connected to the real server, and showed the main menu. You got access to the configuration screens by swiping a special badge and then entering a code.\n\nThe software was portable so we could test that as we wrote it, and as we collected the pieces from our suppliers we kept one of each so we had a disassembled kiosk to play with. When we got our finished kiosks, they all worked immediately. We shipped them to the client, who plugged them into their housing, switched them on, and went to business. We spent a week or so on-site, and in ten years, one kiosk broke (the screen died, and was replaced).\n\nLesson is, test upfront so that when you plug the thing in, you know precisely how it's going to behave. If you haven't tested it upfront, you're going to be spending weeks and months in the field ironing out problems that should never have been there.\n\n+++ The Zyre Tester\n\nDuring manual testing, I did hit an assertion rarely. It then disappeared. Because I don't believe in magic, I know that meant the code was still wrong somewhere. So, the next step was heavy-duty testing of the Zyre v0.2.0 code to try to break its assertions, and get a good idea of how it will behave in the field.\n\nWe packaged the discovery and messaging functionality as an //interface// object that the main program creates, works with, and then destroys. We don't use any global variables. This makes it easy to start large numbers of interfaces and simulate real activity, all within one process. And if there's one thing we've learned from writing lots of examples, it's that ZeroMQ's ability to orchestrate multiple threads in a single process is //much// easier to work with than multiple processes.\n\nThe first version of the tester consists of a main thread that starts and stops a set of child threads, each running one interface, each with a ROUTER, DEALER, and UDP socket (R, D, and U in the diagram)[figure].\n\n[[code type=\"textdiagram\" title=\"Zyre Tester Tool\"]]\n                        #----------#\n                        |   Main   |\n                        |  thread  |\n                        #-----+----#\n                              |\n                              |\n      .---------------+-------+-------+---------------.\n      |               |               |               |\n      v               v               v               v\n#-----------#   #-----------#   #-----------#   #-----------#\n|  Child    |   |  Child    |   |  Child    |   |  Child    |\n|  thread   |   |  thread   |   |  thread   |   |  thread   |\n#-----+-----#   #-----+-----#   #-----+-----#   #-----+-----#\n      |               |               |               |\n      v               v               v               v\n#-----------#   #-----------#   #-----------#   #-----------#\n| Interface |   | Interface |   | Interface |   | Interface |\n+---+---+---+   +---+---+---+   +---+---+---+   +---+---+---+\n| R | D | U |   | R | D | U |   | R | D | U |   | R | D | U |\n#---+---+---#   #---+---+---#   #---+---+---#   #---+---+---#\n[[/code]]\n\nThe nice thing is that when I am connected to a WiFi access point, all Zyre traffic (even between two interfaces in the same process) goes across the AP. This means I can fully stress test any WiFi infrastructure with just a couple of PCs running in a room. It's hard to emphasize how valuable this is: if we had built Zyre as, say, a dedicated service for Android, we'd literally need dozens of Android tablets or phones to do any large-scale testing. Kiosks, and all that.\n\nThe focus is now on breaking the current code, trying to prove it wrong. There's //no point// at this stage in testing how well it runs, how fast it is, how much memory it uses, or anything else. We'll work up to trying (and failing) to break each individual functionality, but first, we try to break some of the core assertions I've put into the code.\n\nThese are:\n\n* The first command that any node receives from a peer MUST be {{HELLO}}. In other words, messages //cannot// be lost during the peer-to-peer connection process.\n\n* The state each node calculates for its peers matches the state each peer calculates for itself. In other words, again, no messages are lost in the network.\n\n* When my application sends a message to a peer, we have a connection to that peer. In other words, the application only \"sees\" a peer after we have established a ZeroMQ connection to it.\n\nWith ZeroMQ, there are several cases where we may lose messages. One is the \"late joiner\" syndrome. Two is when we close sockets without sending everything. Three is when we overflow the high-water mark on a ROUTER or PUB socket. Four is when we use an unknown address with a ROUTER socket.\n\nNow, I //think// Harmony gets around all these potential cases. But we're also adding UDP to the mix. So the first version of the tester simulates an unstable and dynamic network, where nodes come and go randomly. It's here that things will break.\n\nHere is the main thread of the tester, which manages a pool of 100 threads, starting and stopping each one randomly. Every ~750 msecs it either starts or stops one random thread. We randomize the timing so that threads aren't all synchronized. After a few minutes, we have an average of 50 threads happily chatting to each other like Korean teenagers in the Gangnam subway station:\n\n[[code type=\"fragment\" name=\"zyre-tester-main\"]]\nint main (int argc, char *argv [])\n{\n    //  Initialize context for talking to tasks\n    zctx_t *ctx = zctx_new ();\n    zctx_set_linger (ctx, 100);\n\n    //  Get number of interfaces to simulate, default 100\n    int max_interface = 100;\n    int nbr_interfaces = 0;\n    if (argc > 1)\n        max_interface = atoi (argv [1]);\n\n    //  We address interfaces as an array of pipes\n    void **pipes = zmalloc (sizeof (void *) * max_interface);\n\n    //  We will randomly start and stop interface threads\n    while (!zctx_interrupted) {\n        uint index = randof (max_interface);\n        //  Toggle interface thread\n        if (pipes [index]) {\n            zstr_send (pipes [index], \"STOP\");\n            zsocket_destroy (ctx, pipes [index]);\n            pipes [index] = NULL;\n            zclock_log (\"I: Stopped interface (%d running)\",\n                --nbr_interfaces);\n        }\n        else {\n            pipes [index] = zthread_fork (ctx, interface_task, NULL);\n            zclock_log (\"I: Started interface (%d running)\",\n                ++nbr_interfaces);\n        }\n        //  Sleep ~750 msecs randomly so we smooth out activity\n        zclock_sleep (randof (500) + 500);\n    }\n    zctx_destroy (&ctx);\n    return 0;\n}\n[[/code]]\n\nNote that we maintain a //pipe// to each child thread (CZMQ creates the pipe automatically when we use the {{zthread_fork}} method). It's via this pipe that we tell child threads to stop when it's time for them to leave. The child threads do the following (I'm switching to pseudo-code for clarity):\n\n[[code]]\ncreate an interface\nwhile true:\n    poll on pipe to parent, and on interface\n    if parent sent us a message:\n        break\n    if interface sent us a message:\n        if message is ENTER:\n            send a WHISPER to the new peer\n        if message is EXIT:\n            send a WHISPER to the departed peer\n        if message is WHISPER:\n            send back a WHISPER 1/2 of the time\n        if message is SHOUT:\n            send back a WHISPER 1/3 of the time\n            send back a SHOUT 1/3 of the time\n    once per second:\n        join or leave one of 10 random groups\ndestroy interface\n[[/code]]\n\n+++ Test Results\n\nYes, we broke the code. Several times, in fact. This was satisfying. I'll work through the different things we found.\n\nGetting nodes to agree on consistent group status was the most difficult. Every node needs to track the group membership of the whole network, as I already explained in the section \"Group Messaging\". Group messaging is a pub-sub pattern. {{JOIN}}s and {{LEAVE}}s are analogous to subscribe and unsubscribe messages. It's essential that none of these ever get lost, or we'll find nodes dropping randomly off groups.\n\nSo each node counts the total number of {{JOIN}}s and {{LEAVE}}s it's ever done, and broadcasts this status (as 1-byte rolling counter) in its UDP beacon. Other nodes pick up the status, compare it to their own calculations, and if there's a difference, the code asserts.\n\nThe first problem was that UDP beacons get delayed randomly, so they're useless for carrying the status. When a beacons arrives late, the status is inaccurate and we get a //false negative//. To fix this, we moved the status information into the {{JOIN}} and {{LEAVE}} commands. We also added it to the {{HELLO}} command. The logic then becomes:\n\n* Get initial status for a peer from its {{HELLO}} command.\n* When getting a {{JOIN}} or {{LEAVE}} from a peer, increment the status counter.\n* Check that the new status counter matches the value in the {{JOIN}} or {{LEAVE}} command\n* If it doesn't, assert.\n\nNext problem we got was that messages were arriving unexpectedly on new connections. The Harmony pattern connects, then sends {{HELLO}} as the first command. This means the receiving peer should always get {{HELLO}} as the first command from a new peer. We were seeing {{PING}}, {{JOIN}}, and other commands arriving.\n\nThis turned out to be due to CZMQ's ephemeral port logic. An ephemeral port is just a dynamically assigned port that a service can get rather than asking for a fixed port number. A POSIX system usually assigns ephemeral ports in the range 0xC000 to 0xFFFF. CZMQ's logic is to look for a free port in this range, bind to that, and return the port number to the caller.\n\nThis sounds fine, until you get one node stopping and another node starting close together, and the new node getting the port number of the old node. Remember that ZeroMQ tries to re-establish a broken connection. So when the first node stopped, its peers would retry to connect. When the new node appears on that same port, suddenly all the peers connect to it and start chatting like they're old buddies.\n\nIt's a general problem that affects any larger-scale dynamic ZeroMQ application. There are a number of plausible answers. One is to not reuse ephemeral ports, which is easier said than done when you have multiple processes on one system. Another solution would be to select a random port each time, which at least reduces the risk of hitting a just-freed port. This brings the risk of a garbage connection down to perhaps 1/1000 but it's still there. Perhaps the best solution is to accept that this can happen, understand the causes, and deal with it on the application level.\n\nWe have a stateful protocol that always starts with a {{HELLO}} command. We know that it's possible for peers to connect to us, thinking we're an existing node that went away and came back, and send us other commands. Step one is when we discover a new peer, to destroy any existing peer connected to the same endpoint. It's not a full answer but at least it's polite. Step two is to ignore anything coming in from a new peer until that peer says {{HELLO}}.\n\nThis doesn't require any change to the protocol, but it must be specified in the protocol when we come to it: due to the way ZeroMQ connections work, it's possible to receive unexpected commands from a //well-behaving// peer and there is no way to return an error code or otherwise tell that peer to reset its connection. Thus, a peer must discard any command from a peer until it receives {{HELLO}}.\n    \nIn fact, if you draw this on a piece of paper and think it through, you'll see that you never get a {{HELLO}} from such a connection. The peer will send {{PING}}s and {{JOIN}}s and {{LEAVE}}s and then eventually time out and close, as it fails to get any heartbeats back from us.\n\nYou'll also see that there's no risk of confusion, no way for commands from two peers to get mixed into a single stream on our DEALER socket.\n\nWhen you are satisfied that this works, we're ready to move on. This version is tagged in the repository as v0.3.0 and you can [https://github.com/zeromq/zyre/tags download the tarball] if you want to check what the code looked like at this stage.\n\nNote that doing heavy simulation of lots of nodes will probably cause your process to run out of file handles, giving an assertion failure in {{libzmq}}. I raised the per-process limit to 30,000 by running (on my Linux box):\n\n[[code]]\nulimit -n 30000\n[[/code]]\n\n+++ Tracing Activity\n\nTo debug the kinds of problems we saw here, we need extensive logging. There's a lot happening in parallel, but every problem can be traced down to a specific exchange between two nodes, consisting of a set of events that happen in strict sequence. We know how to make very sophisticated logging, but as usual it's wiser to make just what we need and no more. We have to capture:\n\n* Time and date for each event.\n* In which node the event occurred.\n* The peer node, if any.\n* What the event was (e.g., which command arrived).\n* Event data, if any.\n\nThe very simplest technique is to print the necessary information to the console, with a timestamp. That's the approach I used. Then it's simple to find the nodes affected by a failure, filter the log file for only messages referring to them, and see exactly what happened.\n\n+++ Dealing with Blocked Peers\n\nIn any performance-sensitive ZeroMQ architecture, you need to solve the problem of flow control. You cannot simply send unlimited messages to a socket and hope for the best. At the one extreme, you can exhaust memory. This is a classic failure pattern for a message broker: one slow client stops receiving messages; the broker starts to queue them, and eventually exhausts memory and the whole process dies. At the other extreme, the socket drops messages, or blocks, as you hit the high-water mark.\n\nWith Zyre we want to distribute messages to a set of peers, and we want to do this fairly. Using a single ROUTER socket for output would be problematic because any one blocked peer would block outgoing traffic to all peers. TCP does have good algorithms for spreading the network capacity across a set of connections. And we're using a separate DEALER socket to talk to each peer, so in theory each DEALER socket will send its queued messages in the background reasonably fairly.\n\nThe normal behavior of a DEALER socket that hits its high-water mark is to block. This is usually ideal, but it's a problem for us here. Our current interface design uses one thread that distributes messages to all peers. If one of those send calls were to block, all output would block.\n\nThere are a few options to avoid blocking. One is to use {{zmq_poll[3]}} on the whole set of DEALER sockets, and only write to sockets that are ready. I don't like this for a couple of reasons. First, the DEALER socket is hidden inside the peer class, and it is cleaner to allow each class to handle this opaquely. Second, what do we do with messages we can't yet deliver to a DEALER socket? Where do we queue them? Third, it seems to be side-stepping the issue. If a peer is really so busy it can't read its messages, something is wrong. Most likely, it's dead.\n\nSo no polling for output. The second option is to use one thread per peer. I quite like the idea of this because it fits into the ZeroMQ design pattern of \"do one thing in one thread\". But this is going to create //a lot// of threads (square of the number of nodes we start) in the simulation, and we're already running out of file handles.\n\nA third option is to use a nonblocking send. This is nicer and it's the solution I choose. We can then provide each peer with a reasonable outgoing queue (the HWM) and if that gets full, treat it as a fatal error on that peer. This will work for smaller messages. If we're sending large chunks--e.g., for content distribution--we'll need a credit-based flow control on top.\n\nTherefore the first step is to prove to ourselves that we can turn the normal blocking DEALER socket into a nonblocking socket. This example creates a normal DEALER socket, connects it to some endpoint (so that there's an outgoing pipe and the socket will accept messages), sets the high-water mark to four, and then sets the send timeout to zero:\n\n[[code type=\"example\" title=\"Checking EAGAIN on DEALER socket\" name=\"eagain\"]]\n[[/code]]\n\nWhen we run this, we send four messages successfully (they go nowhere, the socket just queues them), and then we get a nice {{EAGAIN}} error:\n\n[[code]]\nSending message 0\nSending message 1\nSending message 2\nSending message 3\nSending message 4\nResource temporarily unavailable\n[[/code]]\n\nThe next step is to decide what a reasonable high-water mark would be for a peer. Zyre is meant for human interactions; that is, applications that chat at a low frequency, such as two games or a shared drawing program. I'd expect a hundred messages per second to be quite a lot. Our \"peer is really dead\" timeout is 10 seconds. So a high-water mark of 1,000 seems fair.\n\nRather than set a fixed HWM or use the default (which randomly also happens to be 1,000), we calculate it as 100 * the timeout. Here's how we configure a new DEALER socket for a peer:\n\n[[code type=\"fragment\" name=\"zyre-peer-new-socket\"]]\n//  Create new outgoing socket (drop any messages in transit)\nself->mailbox = zsocket_new (self->ctx, ZMQ_DEALER);\n\n//  Set our caller \"From\" identity so that receiving node knows\n//  who each message came from.\nzsocket_set_identity (self->mailbox, reply_to);\n\n//  Set a high-water mark that allows for reasonable activity\nzsocket_set_sndhwm (self->mailbox, PEER_EXPIRED * 100);\n\n//  Send messages immediately or return EAGAIN\nzsocket_set_sndtimeo (self->mailbox, 0);\n\n//  Connect through to peer node\nzsocket_connect (self->mailbox, \"tcp://%s\", endpoint);\n[[/code]]\n\nAnd finally, what do we do when we get an {{EAGAIN}} on a peer? We don't need to go through all the work of destroying the peer because the interface will do this automatically if it doesn't get any message from the peer within the expiration timeout. Just dropping the last message seems very weak; it will give the receiving peer gaps.\n\nI'd prefer a more brutal response. Brutal is good because it forces the design to a \"good\" or \"bad\" decision rather than a fuzzy \"should work but to be honest there are a lot of edge cases so let's worry about it later\". Destroy the socket, disconnect the peer, and stop sending anything to it. The peer will eventually have to reconnect and re-initialize any state. It's kind of an assertion that 100 messages a second is enough for anyone. So, in the {{zre_peer_send}} method:\n\n[[code type=\"fragment\" name=\"zyre-peer-send\"]]\nint\nzre_peer_send (zre_peer_t *self, zre_msg_t **msg_p)\n{\n    assert (self);\n    if (self->connected) {\n        if (zre_msg_send (msg_p, self->mailbox) && errno == EAGAIN) {\n            zre_peer_disconnect (self);\n            return -1;\n        }\n    }\n    return 0;\n}\n[[/code]]\n\nWhere the disconnect method looks like this:\n\n[[code type=\"fragment\" name=\"zyre-peer-disconnect\"]]\nvoid\nzre_peer_disconnect (zre_peer_t *self)\n{\n    //  If connected, destroy socket and drop all pending messages\n    assert (self);\n    if (self->connected) {\n        zsocket_destroy (self->ctx, self->mailbox);\n        free (self->endpoint);\n        self->endpoint = NULL;\n        self->connected = false;\n    }\n}\n[[/code]]\n\n++ Distributed Logging and Monitoring\n\nLet's look at logging and monitoring. If you've ever managed a real server (like a web server), you know how vital it is to have a capture of what is going on. There are a long list of reasons, not least:\n\n* To measure the performance of the system over time.\n* To see what kinds of work are done the most, to optimize performance.\n* To track errors and how often they occur.\n* To do postmortems of failures.\n* To provide an audit trail in case of dispute.\n\nLet's scope this in terms of the problems we think we'll have to solve:\n\n* We want to track key events (such as nodes leaving and rejoining the network).\n* For each event, we want to track a consistent set of data: the date/time, node that observed the event, peer that created the event, type of event itself, and other event data.\n* We want to be able to switch logging on and off at any time.\n* We want to be able to process log data mechanically because it will be sizable.\n* We want to be able to monitor a running system; that is, collect logs and analyze in real time.\n* We want log traffic to have minimal effect on the network.\n* We want to be able to collect log data at a single point on the network.\n\nAs in any design, some of these requirements are hostile to each other. For example, collecting log data in real time means sending it over the network, which will affect network traffic to some extent. However, as in any design, these requirements are also hypothetical until we have running code so we can't take them too seriously. We'll aim for //plausibly good enough// and improve over time.\n\n+++ A Plausible Minimal Implementation\n\nArguably, just dumping log data to disk is one solution, and it's what most mobile applications do (using \"debug logs\"). But most failures require correlation of events from two nodes. This means searching lots of debug logs by hand to find the ones that matter. It's not a very clever approach.\n\nWe want to send log data somewhere central, either immediately, or opportunistically (i.e., store and forward). For now, let's focus on immediate logging. My first idea when it comes to sending data is to use Zyre for this. Just send log data to a group called \"LOG\", and hope someone collects it.\n\nBut using Zyre to log Zyre itself is a Catch-22. Who logs the logger? What if we want a verbose log of every message sent? Do we include logging messages in that or not? It quickly gets messy. We want a logging protocol that's independent of Zyre's main ZRE protocol. The simplest approach is a pub-sub protocol, where all nodes publish log data on a PUB socket and a collector picks that up via a SUB socket[figure].\n\n[[code type=\"textdiagram\" title=\"Distributed Log Collection\"]]\n#--------#      #--------#      #--------#\n|  Node  |      |  Node  |      |  Node  |\n+--------+      +--------+      +--------+\n|  PUB   |      |  PUB   |      |  PUB   |\n'---+----'      '---+----'      '---+----'\n    |               |               |\n    '---------------+---------------'\n                    |\n                    v\n              .-----------.\n              |    SUB    |\n              +-----------+\n              | Collector |\n              #-----------#\n[[/code]]\n\nThe collector can, of course, run on any node. This gives us a nice range of use cases:\n\n* A passive log collector that stores log data on disk for eventual statistical analysis; this would be a PC with sufficient hard disk space for weeks or months of log data.\n\n* A collector that stores log data into a database where it can be used in real time by other applications. This might be overkill for a small workgroup, but would be snazzy for tracking the performance of larger groups. The collector could collect log data over WiFi and then forward it over Ethernet to a database somewhere.\n\n* A live meter application that joined the Zyre network and then collected log data from nodes, showing events and statistics in real time.\n\nThe next question is how to interconnect the nodes and collector. Which side binds, and which connects? Both ways will work here, but it's marginally better if the PUB sockets connect to the SUB socket. If you recall, ZeroMQ's internal buffers only pop into existence when there are connections. It means as soon as a node connects to the collector, it can start sending log data without loss.\n\nHow do we tell nodes what endpoint to connect to? We may have any number of collectors on the network, and they'll be using arbitrary network addresses and ports. We need some kind of service announcement mechanism, and here we can use Zyre to do the work for us. We could use group messaging, but it seems neater to build service discovery into the ZRE protocol itself. It's nothing complex: if a node provides a service X, it can tell other nodes about that when it sends them a {{HELLO}} command.\n\nWe'll extend the {{HELLO}} command with a //headers// field that holds a set of name=value pairs. Let's define that the header {{X-ZRELOG}} specifies the collector endpoint (the SUB socket). A node that acts as a collector can add a header like this (for example):\n\n[[code]]\nX-ZRELOG=tcp://192.168.1.122:9992\n[[/code]]\n\nWhen another node sees this header, it simply connects its PUB socket to that endpoint. Log data now gets distributed to all collectors (zero or more) on the network.\n\nMaking this first version was fairly simple and took half a day. Here are the pieces we had to make or change:\n\n* We made a new class {{zre_log}} that accepts log data and manages the connection to the collector, if any.\n* We added some basic management for peer headers, taken from the {{HELLO}} command.\n* When a peer has the {{X-ZRELOG}} header, we connect to the endpoint it specifies.\n* Where we were logging to stdout, we switched to logging via the {{zre_log}} class.\n* We extended the interface API with a method that lets the application set headers.\n* We wrote a simple logger application that manages the SUB socket and sets the {{X-ZRELOG}} header.\n* We send our own headers when we send a {{HELLO}} command.\n\nThis version is tagged in the Zyre repository as v0.4.0 and you can [https://github.com/zeromq/zyre/tags download the tarball] if you want to see what the code looked like at this stage.\n\nAt this stage, the log message is just a string. We'll make more professionally structured log data in a little while.\n\nFirst, a note on dynamic ports. In the {{zre_tester}} app that we use for testing, we create and destroy interfaces aggressively. One consequence is that a new interface can easily reuse a port that was just freed by another application. If there's a ZeroMQ socket somewhere trying to connect this port, the results can be hilarious.\n\nHere's the scenario I had, which caused a few minutes' confusion. The logger was running on a dynamic port:\n\n* Start logger application\n* Start tester application\n* Stop logger\n* Tester receives invalid message (and asserts as designed)\n\nAs the tester created a new interface, that reused the dynamic port freed by the (just stopped) logger, and suddenly the interface began to receive log data from nodes on its mailbox. We saw a similar situation before, where a new interface could reuse the port freed by an old interface and start getting old data.\n\nThe lesson is, if you use dynamic ports, be prepared to receive random data from ill-informed applications that are reconnecting to you. Switching to a static port stopped the misbehaving connection. That's not a full solution though. There are two more weaknesses:\n\n* As I write this, {{libzmq}} doesn't check socket types when connecting. The [http://rfc.zeromq.org/spec:15 ZMTP/2.0 protocol] does announce each peer's socket type, so this check is doable.\n\n* The ZRE protocol has no fail-fast (assertion) mechanism; we need to read and parse a whole message before realizing that it's invalid.\n\nLet's address the second one. Socket pair validation wouldn't solve this fully anyway.\n\n+++ Protocol Assertions\n\nAs Wikipedia puts it, \"Fail-fast systems are usually designed to stop normal operation rather than attempt to continue a possibly flawed process.\" A protocol like HTTP has a fail-fast mechanism in that the first four bytes that a client sends to an HTTP server must be \"HTTP\". If they're not, the server can close the connection without reading anything more.\n\nOur ROUTER socket is not connection-oriented so there's no way to \"close the connection\" when we get bad incoming messages. However, we can throw out the entire message if it's not valid. The problem is going to be worse when we use ephemeral ports, but it applies broadly to all protocols.\n\nSo let's define a //protocol assertion// as being a unique signature that we place at the start of each message and which identities the intended protocol. When we read a message, we check the signature and if it's not what we expect, we discard the message silently. A good signature should be hard to confuse with regular data and give us enough space for a number of protocols.\n\nI'm going to use a 16-bit signature consisting of a 12-bit pattern and a 4-bit protocol ID[figure]. The pattern %xAAA is meant to stay away from values we might otherwise expect to see at the start of a message: %x00, %xFF, and printable characters.\n\n[[code type=\"textdiagram\" title=\"Protocol Signature\"]]\n#---+---+---+---+---+---+---+---#  #---+---+---+---+---------------#\n| 1 | 0 | 1 | 0 | 1 | 0 | 1 | 0 |  | 1 | 0 | 1 | 0 |   Signature   |\n#---+---+---+---+---+---+---+---#  #---+---+---+---+---------------#\n\n             Byte 0                             Byte 1\n[[/code]]\n\nAs our protocol codec is generated, it's relatively easy to add this assertion. The logic is:\n\n* Get first frame of message.\n* Check if first two bytes are %xAAA with expected 4-bit signature.\n* If so, continue to parse rest of message.\n* If not, skip all \"more\" frames, get first frame, and repeat.\n\nTo test this, I switched the logger back to using an ephemeral port. The interface now properly detects and discards any messages that don't have a valid signature. If the message has a valid signature and is //still// wrong, that's a proper bug.\n\n+++ Binary Logging Protocol\n\nNow that we have the logging framework working properly, let's look at the protocol itself. Sending strings around the network is simple, but when it comes to WiFi we really cannot afford to waste bandwidth. We have the tools to work with efficient binary protocols, so let's design one for logging.\n\nThis is going to be a pub-sub protocol and in ZeroMQ v3.x we do publisher-side filtering. This means we can do multi-level logging (errors, warnings, information) if we put the logging level at the start of the message. So our message starts with a protocol signature (two bytes), a logging level (one byte), and an event type (one byte).\n\nIn the first version, we send UUID strings to identify each node. As text, these are 32 characters each. We can send binary UUIDs, but it's still verbose and wasteful. We don't care about the node identifiers in the log files. All we need is some way to correlate events. So what's the shortest identifier we can use that's going to be unique enough for logging? I say \"unique enough\" because while we really want zero chance of duplicate UUIDs in the live code, log files are not so critical.\n\nThe simplest plausible answer is to hash the IP address and port into a 2-byte value. We'll get some collisions, but they'll be rare. How rare? As a quick sanity check, I write a small program that generates a bunch of addresses and hashes them into 16-bit values, looking for collisions. To be sure, I generate 10,000 addresses across a small number of IP addresses (matching a simulation setup), and then across a large number of addresses (matching a real-life setup). The hashing algorithm is a //modified Bernstein//:\n\n[[code type=\"fragment\" name=\"endpoint-hashing\"]]\nuint16_t hash = 0;\nwhile (*endpoint)\n    hash = 33 * hash ^ *endpoint++;\n[[/code]]\n\nI don't get any collisions over several runs, so this will work as identifier for the log data. This adds four bytes (two for the node recording the event, and two for its peer in events that come from a peer).\n\nNext, we want to store the date and time of the event. The POSIX {{time_t}} type was previously 32 bits, but because this overflows in 2038, it's a 64-bit value. We'll use this; there's no need for millisecond resolution in a log file: events are sequential, clocks are unlikely to be that tightly synchronized, and network latencies mean that precise times aren't that meaningful.\n\nWe're up to 16 bytes, which is decent. Finally, we want to allow some additional data, formatted as text and depending on the type of event. Putting this all together gives the following message specification:\n\n[[code]]\n<class\n    name = \"zre_log_msg\"\n    script = \"codec_c.gsl\"\n    signature = \"2\"\n>\nThis is the ZRE logging protocol - raw version.\n<include filename = \"license.xml\" />\n\n<!-- Protocol constants -->\n<define name = \"VERSION\" value = \"1\" />\n\n<define name = \"LEVEL_ERROR\" value = \"1\" />\n<define name = \"LEVEL_WARNING\" value = \"2\" />\n<define name = \"LEVEL_INFO\" value = \"3\" />\n\n<define name = \"EVENT_JOIN\" value = \"1\" />\n<define name = \"EVENT_LEAVE\" value = \"2\" />\n<define name = \"EVENT_ENTER\" value = \"3\" />\n<define name = \"EVENT_EXIT\" value = \"4\" />\n\n<message name = \"LOG\" id = \"1\">\n    <field name = \"level\" type = \"number\" size = \"1\" />\n    <field name = \"event\" type = \"number\" size = \"1\" />\n    <field name = \"node\" type = \"number\" size = \"2\" />\n    <field name = \"peer\" type = \"number\" size = \"2\" />\n    <field name = \"time\" type = \"number\" size = \"8\" />\n    <field name = \"data\" type = \"string\" />\nLog an event\n</message>\n\n</class>\n[[/code]]\n\nThis generates 800 lines of perfect binary codec (the {{zre_log_msg}} class). The codec does protocol assertions just like the main ZRE protocol does. Code generation has a fairly steep starting curve, but it makes it so much easier to push your designs past \"amateur\" into \"professional\".\n\n++ Content Distribution\n\nWe now have a robust framework for creating groups of nodes, letting them chat to each other, and monitoring the resulting network. Next step is to allow them to distribute content as files.\n\nAs usual, we'll aim for the very simplest plausible solution and then improve that step-by-step. At the very least we want the following:\n\n* An application can tell the Zyre API, \"Publish this file\", and provide the path to a file that exists somewhere in the file system.\n* Zyre will distribute that file to all peers, both those that are on the network at that time, and those that arrive later.\n* Each time an interface receives a file it tells its application, \"Here is this file\".\n\nWe might eventually want more discrimination, e.g., publishing to specific groups. We can add that later if it's needed. In [#advanced-architecture] we developed a file distribution system (FileMQ) designed to be plugged into ZeroMQ applications. So let's use that.\n\nEach node is going to be a file publisher and a file subscriber. We bind the publisher to an ephemeral port (if we use the standard FileMQ port 5670, we can't run multiple interfaces on one box), and we broadcast the publisher's endpoint in the {{HELLO}} message, as we did for the log collector. This lets us interconnect all nodes so that all subscribers talk to all publishers.\n\nWe need to ensure that each node has its own directory for sending and receiving files (the outbox and the inbox). Again, it's so we can run multiple nodes on one box. Because we already have a unique ID per node, we just use that in the directory name.\n\nHere's how we set up the FileMQ API when we create a new interface:\n\n[[code type=\"fragment\" name=\"filemq-outbox\"]]\nsprintf (self->fmq_outbox, \".outbox/%s\", self->identity);\nmkdir (self->fmq_outbox, 0775);\n\nsprintf (self->fmq_inbox, \".inbox/%s\", self->identity);\nmkdir (self->fmq_inbox, 0775);\n\nself->fmq_server = fmq_server_new ();\nself->fmq_service = fmq_server_bind (self->fmq_server, \"tcp://*:*\");\nfmq_server_publish (self->fmq_server, self->fmq_outbox, \"/\");\nfmq_server_set_anonymous (self->fmq_server, true);\nchar publisher [32];\nsprintf (publisher, \"tcp://%s:%d\", self->host, self->fmq_service);\nzhash_update (self->headers, \"X-FILEMQ\", strdup (publisher));\n\n//  Client will connect as it discovers new nodes\nself->fmq_client = fmq_client_new ();\nfmq_client_set_inbox (self->fmq_client, self->fmq_inbox);\nfmq_client_set_resync (self->fmq_client, true);\nfmq_client_subscribe (self->fmq_client, \"/\");\n[[/code]]\n\nAnd when we process a {{HELLO}} command, we check for the {{X-FILEMQ}} header field:\n\n[[code type=\"fragment\" name=\"filemq-connect\"]]\n//  If peer is a FileMQ publisher, connect to it\nchar *publisher = zre_msg_headers_string (msg, \"X-FILEMQ\", NULL);\nif (publisher)\n    fmq_client_connect (self->fmq_client, publisher);\n[[/code]]\n\nThe last thing is to expose content distribution in the Zyre API. We need two things:\n\n* A way for the application to say, \"Publish this file\"\n* A way for the interface to tell the application, \"We received this file\".\n\nIn theory, the application can publish a file just by creating a symbolic link in the outbox directory, but as we're using a hidden outbox, this is a little difficult. So we add an API method {{publish}}:\n\n[[code type=\"fragment\" name=\"publish-file\"]]\n//  Publish file into virtual space\nvoid\nzre_interface_publish (zre_interface_t *self,\n                       char *filename, char *external)\n{\n    zstr_sendm (self->pipe, \"PUBLISH\");\n    zstr_sendm (self->pipe, filename);  //  Real file name\n    zstr_send  (self->pipe, external);  //  Location in virtual space\n}\n[[/code]]\n\nThe API passes this to the interface thread, which creates the file in the outbox directory so that the FileMQ server will pick it up and broadcast it. We could literally copy file data into this directory, but because FileMQ supports symbolic links, we use that instead. The file has a \".ln\" extension and contains one line, which contains the actual pathname.\n\nFinally, how do we notify the recipient that a file has arrived? The FileMQ {{fmq_client}} API has a message, \"DELIVER\", for this, so all we have to do in {{zre_interface}} is grab this message from the {{fmq_client}} API and pass it on to our own API:\n\n[[code type=\"fragment\" name=\"forward-deliver\"]]\nzmsg_t *msg = fmq_client_recv (fmq_client_handle (self->fmq_client));\nzmsg_send (&msg, self->pipe);\n[[/code]]\n\nThis is complex code that does a lot at once. But we're only at around 10K lines of code for FileMQ and Zyre together. The most complex Zyre class, {{zre_interface}}, is 800 lines of code. This is compact. Message-based applications do keep their shape if you're careful to organize them properly.\n\n++ Writing the Unprotocol\n\nWe have all the pieces for a formal protocol specification and it's time to put the protocol on paper. There are two reasons for this. First, to make sure that any other implementations talk to each other properly. Second, because I want to get an official port for the UDP discovery protocol and that means doing the paperwork.\n\nLike all the other unprotocols we developed in this book, the protocol lives on [http://rfc.zeromq.org/spec:20 the ZeroMQ RFC site]. The core of the protocol specification is the ABNF grammar for the commands and fields:\n\n[[code]]\nzre-protocol    = greeting *traffic\n\ngreeting        = S:HELLO\ntraffic         = S:WHISPER\n                / S:SHOUT\n                / S:JOIN\n                / S:LEAVE\n                / S:PING R:PING-OK\n\n;   Greet a peer so it can connect back to us\nS:HELLO         = header %x01 ipaddress mailbox groups status headers\nheader          = signature sequence\nsignature       = %xAA %xA1\nsequence        = 2OCTET        ; Incremental sequence number\nipaddress       = string        ; Sender IP address\nstring          = size *VCHAR\nsize            = OCTET\nmailbox         = 2OCTET        ; Sender mailbox port number\ngroups          = strings       ; List of groups sender is in\nstrings         = size *string\nstatus          = OCTET         ; Sender group status sequence\nheaders         = dictionary    ; Sender header properties\ndictionary      = size *key-value\nkey-value       = string        ; Formatted as name=value\n\n; Send a message to a peer\nS:WHISPER       = header %x02 content\ncontent         = FRAME         ; Message content as ZeroMQ frame\n\n; Send a message to a group\nS:SHOUT         = header %x03 group content\ngroup           = string        ; Name of group\ncontent         = FRAME         ; Message content as ZeroMQ frame\n\n; Join a group\nS:JOIN          = header %x04 group status\nstatus          = OCTET         ; Sender group status sequence\n\n; Leave a group\nS:LEAVE         = header %x05 group status\n\n; Ping a peer that has gone silent\nS:PING          = header %06\n\n; Reply to a peer's ping\nR:PING-OK       = header %07\n[[/code]]\n\n++ Example Zyre Application\n\nLet's now make a minimal example that uses Zyre to broadcast files around a distributed network. This example consists of two programs:\n\n* A //listener// that joins the Zyre network and reports whenever it receives a file.\n* A //sender// that joins a Zyre network and broadcasts exactly one file.\n\nThe listener is quite short:\n\n[[code type=\"fragment\" name=\"zyre-listener\"]]\n#include <zre.h>\n\nint main (int argc, char *argv [])\n{\n    zre_interface_t *interface = zre_interface_new ();\n    while (true) {\n        zmsg_t *incoming = zre_interface_recv (interface);\n        if (!incoming)\n            break;\n        zmsg_dump (incoming);\n        zmsg_destroy (&incoming);\n    }\n    zre_interface_destroy (&interface);\n    return 0;\n}\n[[/code]]\n\nAnd the sender isn't much longer:\n\n[[code type=\"fragment\" name=\"zyre-sender\"]]\n#include <zre.h>\n\nint main (int argc, char *argv [])\n{\n    if (argc < 2) {\n        puts (\"Syntax: sender filename virtualname\");\n        return 0;\n    }\n    printf (\"Publishing %s as %s\\n\", argv [1], argv [2]);\n    zre_interface_t *interface = zre_interface_new ();\n    zre_interface_publish (interface, argv [1], argv [2]);\n    while (true) {\n        zmsg_t *incoming = zre_interface_recv (interface);\n        if (!incoming)\n            break;\n        zmsg_dump (incoming);\n        zmsg_destroy (&incoming);\n    }\n    zre_interface_destroy (&interface);\n    return 0;\n}\n[[/code]]\n\n++ Conclusions\n\nBuilding applications for unstable decentralized networks is one of the end games for ZeroMQ. As the cost of computing falls every year, such networks become more and more common, be it consumer electronics or virtual boxes in the cloud. In this chapter, we've pulled together many of the techniques from the book to build Zyre, a framework for proximity computing over a local network. Zyre isn't unique; there are and have been many attempts to open this area for applications: ZeroConf, SLP, SSDP, UPnP, DDS. But these all seem to end up too complex or otherwise too difficult for application developers to build on.\n\nZyre isn't finished. Like many of the projects in this book, it's an ice breaker for others. There are some major unfinished areas, which we may address in later editions of this book or versions of the software.\n\n* High-level APIs: the message-based API that Zyre offers now is usable but still rather more complex than I'd like for average developers. If there's one target we absolutely cannot miss, it's raw //simplicity//. This means we should build high-level APIs, in lots of languages, which hide all the messaging, and which come down to simple methods like start, join/leave group, get message, publish file, stop.\n\n* Security: how do we build a fully decentralized security system? We might be able to leverage public key infrastructure for some work, but that requires that nodes have their own Internet access, which isn't guaranteed. The answer is, as far as we can tell, to use any existing secure peer-to-peer link (TLS, BlueTooth, perhaps NFC) to exchange a session key and use a symmetric cipher. Symmetric ciphers have their advantages and disadvantages.\n\n* Nomadic content: how do I, as a user, manage my content across multiple devices? The Zyre + FileMQ combination might help, for local network use, but I'd like to be able to do this across the Internet as well. Are there cloud services I could use? Is there something I could make using ZeroMQ?\n\n* Federation: how do we scale a local-area distributed application across the globe? One plausible answer is federation, which means creating clusters of clusters. If 100 nodes can join together to create a local cluster, then perhaps 100 clusters can join together to create a wide-area cluster. The challenges are then quite similar: discovery, presence, and group messaging.\n"
        },
        {
          "name": "examples",
          "type": "tree",
          "content": null
        },
        {
          "name": "fragments",
          "type": "tree",
          "content": null
        },
        {
          "name": "images",
          "type": "tree",
          "content": null
        },
        {
          "name": "listings",
          "type": "tree",
          "content": null
        },
        {
          "name": "netlify.toml",
          "type": "blob",
          "size": 4.9072265625,
          "content": "[build]\npublish = \"site/public\"\ncommand = \"make production-build\"\n\n[build.environment]\nHUGO_VERSION = \"0.72.0\"\n\n[context.deploy-preview]\ncommand = \"make preview-build\"\n\n[context.branch-deploy]\ncommand = \"make preview-build\"\n\n# Page redirects\n\n[[redirects]]\nfrom = \"/page:all\"\nto = \"/\"\nforce = true\n\n[[redirects]]\nfrom = \"/page:preface\"\nto = \"/docs/preface\"\nforce = true\n\n[[redirects]]\nfrom = \"/page:chapter1\"\nto = \"/docs/chapter1\"\nforce = true\n\n[[redirects]]\nfrom = \"/page:chapter2\"\nto = \"/docs/chapter2\"\nforce = true\n\n[[redirects]]\nfrom = \"/page:chapter3\"\nto = \"/docs/chapter3\"\nforce = true\n\n[[redirects]]\nfrom = \"/page:chapter4\"\nto = \"/docs/chapter4\"\nforce = true\n\n[[redirects]]\nfrom = \"/page:chapter5\"\nto = \"/docs/chapter5\"\nforce = true\n\n[[redirects]]\nfrom = \"/page:chapter6\"\nto = \"/docs/chapter6\"\nforce = true\n\n[[redirects]]\nfrom = \"/page:chapter7\"\nto = \"/docs/chapter7\"\nforce = true\n\n[[redirects]]\nfrom = \"/page:chapter8\"\nto = \"/docs/chapter8\"\nforce = true\n\n[[redirects]]\nfrom = \"/page:postface\"\nto = \"/docs/postface\"\nforce = true\n\n# Java redirects\n[[redirects]]\nfrom = \"/java:all\"\nto = \"/\"\nforce = true\n\n[[redirects]]\nfrom = \"/java:preface\"\nto = \"/docs/preface\"\nforce = true\n\n[[redirects]]\nfrom = \"/java:chapter1\"\nto = \"/docs/chapter1\"\nforce = true\n\n[[redirects]]\nfrom = \"/java:chapter2\"\nto = \"/docs/chapter2\"\nforce = true\n\n[[redirects]]\nfrom = \"/java:chapter3\"\nto = \"/docs/chapter3\"\nforce = true\n\n[[redirects]]\nfrom = \"/java:chapter4\"\nto = \"/docs/chapter4\"\nforce = true\n\n[[redirects]]\nfrom = \"/java:chapter5\"\nto = \"/docs/chapter5\"\nforce = true\n\n[[redirects]]\nfrom = \"/java:chapter6\"\nto = \"/docs/chapter6\"\nforce = true\n\n[[redirects]]\nfrom = \"/java:chapter7\"\nto = \"/docs/chapter7\"\nforce = true\n\n[[redirects]]\nfrom = \"/java:chapter8\"\nto = \"/docs/chapter8\"\nforce = true\n\n[[redirects]]\nfrom = \"/java:postface\"\nto = \"/docs/postface\"\nforce = true\n\n# PHP redirects\n[[redirects]]\nfrom = \"/php:all\"\nto = \"/\"\nforce = true\n\n[[redirects]]\nfrom = \"/php:preface\"\nto = \"/docs/preface\"\nforce = true\n\n[[redirects]]\nfrom = \"/php:chapter1\"\nto = \"/docs/chapter1\"\nforce = true\n\n[[redirects]]\nfrom = \"/php:chapter2\"\nto = \"/docs/chapter2\"\nforce = true\n\n[[redirects]]\nfrom = \"/php:chapter3\"\nto = \"/docs/chapter3\"\nforce = true\n\n[[redirects]]\nfrom = \"/php:chapter4\"\nto = \"/docs/chapter4\"\nforce = true\n\n[[redirects]]\nfrom = \"/php:chapter5\"\nto = \"/docs/chapter5\"\nforce = true\n\n[[redirects]]\nfrom = \"/php:chapter6\"\nto = \"/docs/chapter6\"\nforce = true\n\n[[redirects]]\nfrom = \"/php:chapter7\"\nto = \"/docs/chapter7\"\nforce = true\n\n[[redirects]]\nfrom = \"/php:chapter8\"\nto = \"/docs/chapter8\"\nforce = true\n\n[[redirects]]\nfrom = \"/php:postface\"\nto = \"/docs/postface\"\nforce = true\n\n# Lua redirects\n[[redirects]]\nfrom = \"/lua:all\"\nto = \"/\"\nforce = true\n\n[[redirects]]\nfrom = \"/lua:preface\"\nto = \"/docs/preface\"\nforce = true\n\n[[redirects]]\nfrom = \"/lua:chapter1\"\nto = \"/docs/chapter1\"\nforce = true\n\n[[redirects]]\nfrom = \"/lua:chapter2\"\nto = \"/docs/chapter2\"\nforce = true\n\n[[redirects]]\nfrom = \"/lua:chapter3\"\nto = \"/docs/chapter3\"\nforce = true\n\n[[redirects]]\nfrom = \"/lua:chapter4\"\nto = \"/docs/chapter4\"\nforce = true\n\n[[redirects]]\nfrom = \"/lua:chapter5\"\nto = \"/docs/chapter5\"\nforce = true\n\n[[redirects]]\nfrom = \"/lua:chapter6\"\nto = \"/docs/chapter6\"\nforce = true\n\n[[redirects]]\nfrom = \"/lua:chapter7\"\nto = \"/docs/chapter7\"\nforce = true\n\n[[redirects]]\nfrom = \"/lua:chapter8\"\nto = \"/docs/chapter8\"\nforce = true\n\n[[redirects]]\nfrom = \"/lua:postface\"\nto = \"/docs/postface\"\nforce = true\n\n# Python redirects\n[[redirects]]\nfrom = \"/py:all\"\nto = \"/\"\nforce = true\n\n[[redirects]]\nfrom = \"/py:preface\"\nto = \"/docs/preface\"\nforce = true\n\n[[redirects]]\nfrom = \"/py:chapter1\"\nto = \"/docs/chapter1\"\nforce = true\n\n[[redirects]]\nfrom = \"/py:chapter2\"\nto = \"/docs/chapter2\"\nforce = true\n\n[[redirects]]\nfrom = \"/py:chapter3\"\nto = \"/docs/chapter3\"\nforce = true\n\n[[redirects]]\nfrom = \"/py:chapter4\"\nto = \"/docs/chapter4\"\nforce = true\n\n[[redirects]]\nfrom = \"/py:chapter5\"\nto = \"/docs/chapter5\"\nforce = true\n\n[[redirects]]\nfrom = \"/py:chapter6\"\nto = \"/docs/chapter6\"\nforce = true\n\n[[redirects]]\nfrom = \"/py:chapter7\"\nto = \"/docs/chapter7\"\nforce = true\n\n[[redirects]]\nfrom = \"/py:chapter8\"\nto = \"/docs/chapter8\"\nforce = true\n\n[[redirects]]\nfrom = \"/py:postface\"\nto = \"/docs/postface\"\nforce = true\n\n# Haxe redirects\n[[redirects]]\nfrom = \"/hx:all\"\nto = \"/\"\nforce = true\n\n[[redirects]]\nfrom = \"/hx:preface\"\nto = \"/docs/preface\"\nforce = true\n\n[[redirects]]\nfrom = \"/hx:chapter1\"\nto = \"/docs/chapter1\"\nforce = true\n\n[[redirects]]\nfrom = \"/hx:chapter2\"\nto = \"/docs/chapter2\"\nforce = true\n\n[[redirects]]\nfrom = \"/hx:chapter3\"\nto = \"/docs/chapter3\"\nforce = true\n\n[[redirects]]\nfrom = \"/hx:chapter4\"\nto = \"/docs/chapter4\"\nforce = true\n\n[[redirects]]\nfrom = \"/hx:chapter5\"\nto = \"/docs/chapter5\"\nforce = true\n\n[[redirects]]\nfrom = \"/hx:chapter6\"\nto = \"/docs/chapter6\"\nforce = true\n\n[[redirects]]\nfrom = \"/hx:chapter7\"\nto = \"/docs/chapter7\"\nforce = true\n\n[[redirects]]\nfrom = \"/hx:chapter8\"\nto = \"/docs/chapter8\"\nforce = true\n\n[[redirects]]\nfrom = \"/hx:postface\"\nto = \"/docs/postface\"\nforce = true\n"
        },
        {
          "name": "notes.txt",
          "type": "blob",
          "size": 3.4580078125,
          "content": "Chapter 5:\n\n    -> how to make async APIs\n    -> adapting Clone for Zyre\n    -> state in HELLO\n    -> update messages\n\n- hacks\n    - mass opening\n\n+++ Security\n\n+++ Connecting over Internet\n\n* public IP addresses and testing reachability\n* security\n* bridging\n\n\n\n\n\n\n\n==1742== Syscall param write(buf) points to uninitialised byte(s)\n==1742==    at 0x5372100: __write_nocancel (syscall-template.S:82)\n==1742==    by 0x5306312: _IO_file_write@@GLIBC_2.2.5 (fileops.c:1289)\n==1742==    by 0x53061D9: new_do_write (fileops.c:543)\n==1742==    by 0x5307944: _IO_do_write@@GLIBC_2.2.5 (fileops.c:516)\n==1742==    by 0x5306E6F: _IO_file_close_it@@GLIBC_2.2.5 (fileops.c:170)\n==1742==    by 0x52FB2CF: fclose@@GLIBC_2.2.5 (iofclose.c:62)\n==1742==    by 0x4060FF: fmq_file_test (fmq_file.c:342)\n==1742==    by 0x4021E6: main (fmq_selftest.c:38)\n==1742==  Address 0x4027000 is not stack'd, malloc'd or (recently) free'd\n\n    FILE *handle = fopen (\"testdata\", \"w\");\n    zmq_msg_t msg;\n    zmq_msg_init_size (&msg, 100);\n    size_t items = fwrite (zmq_msg_data (&msg), 1, 100, handle);\n    fclose (handle);\n    zmq_msg_close (&msg);\n\n+++ Bridging\n\n- why and how\n- semantic compatibility\n- example 0MQ to HTTP\n- using zxxx library?\n\n+++ Disconnected Security\n    \nChapter 9 topics\n\n- the wire level protocol\n- a minimal TCP stack\n- internals of 0MQ\n- generate bindings in\n    Python\n    C#\n    Java\n    Ruby\n\n\n\n++++ \n\n0MQ's pipeline pattern (using PUSH and PULL sockets) is reliable to the extent that:\n\n* Workers and collectors don't crash;\n* Workers and collectors read their data fast enough to avoid queue overflows.\n\nAs with all our reliability patterns, we'll ignore what happens if an upstream node (the ventilator for a pipeline pattern) dies. In practice a ventilator will be the client of another reliability pattern, e.g. Clone.\n\nThe Xyz pattern takes pipeline and makes it robust against the only failure we can reasonably handle, namely workers and (less commonly) collectors that crash and lose messages or work.\n\n- assume workers are idempotent\n- assume batch size is known in advance (because...)\n- assume memory enough to hold full batch\n- batch: start (address of collector), tasks, end\n- messages numbered 0 upwards inside batch\n- assume multiple ventilators for same cluster\n- assume collector talks to ventilator, (not same to allow walk-up-and use by ventilators)\n- call ventilator the 'client'\n- if task missing, resend\n- if end of batch missing, resend from last response\n\n\n/*\n * Threadsafe basename implementation\n *\n * Returns the path component following the final slash ('/'), excluding\n * any trailing slashes, which are dropped. If the pathname does not\n * contain a slash, returns NULL (unlike POSIX basename which returns the\n * whole path). And which is not re-entrant. If successful, allocates a\n * new string that the caller must free when done with.\n */\n\nchar *safe_basename (char *path)\n{\n    if (!path)\n        return NULL;\n\n    //  Strip off any trailing slashes\n    char *path_copy = strdup (path);\n    while (path_copy [strlen (path_copy) - 1] == '/')\n        path_copy [strlen (path_copy) - 1] = '\\0';\n\n    //  Find last slash and take filename after that\n    char *last_slash = strrchr (path_copy, '/');\n    char *filename = NULL;\n    if (last_slash && last_slash > path_copy)\n        filename = strdup (last_slash + 1);\n    else\n    //  Or, take the whole filename unless it's dotted\n    if (*path_copy && *path_copy != '.')\n        filename = strdup (path_copy);\n\n    free (path_copy);\n    return filename;\n}\n\n"
        },
        {
          "name": "part1.txt",
          "type": "blob",
          "size": 0.3154296875,
          "content": "+ Part 1 - Learning 0MQ\n\nIn the first part of this book, you'll learn how to use 0MQ. We'll cover the basics, the API, the different socket types and how they work, reliability, and a host of patterns you can use in your applications. You'll get the best results by working through the examples and text from start to end.\n"
        },
        {
          "name": "part2.txt",
          "type": "blob",
          "size": 0.3681640625,
          "content": "+ Part 2 - Advanced 0MQ\n\nThe second part of this book is about software engineering using 0MQ. I'll introduce a set of techniques of software development, and demonstrate them with worked examples, starting with 0MQ itself and ending with a general purpose framework for distributed applications. These techniques are independent of license, though open source amplifies them.\n"
        },
        {
          "name": "postface.txt",
          "type": "blob",
          "size": 12.80859375,
          "content": ".output postface.wd\n.bookmark postface\n+ Postface\n\n++ Tales from Out There\n\nI asked some of the contributors to this book to tell us what they were doing with ZeroMQ. Here are their stories.\n\n+++ Rob Gagnon's Story\n\n\"We use ZeroMQ to assist in aggregating thousands of events occurring every minute across our global network of telecommunications servers so that we can accurately report and monitor for situations that require our attention. ZeroMQ made the development of the system not only easier, but faster to develop and more robust and fault-tolerant than we had originally planned in our original design.\n\n\"We're able to easily add and remove clients from the network without the loss of any message. If we need to enhance the server portion of our system, we can stop and restart it as well without having to worry about stopping all of the clients first. The built-in buffering of ZeroMQ makes this all possible.\"\n\n+++ Tom van Leeuwen's Story\n\n\"I was looking at creating some kind of service bus connecting all kinds of services together. There were already some products that implemented a broker, but they did not have the functionality I needed. By accident, I stumbled upon ZeroMQ, which is awesome. It's very lightweight, lean, simple and easy to follow because the guide is very complete and reads very well. I've actually implemented the Titanic pattern and the Majordomo broker with some additions (client/worker authentication and workers sending a catalog explaining what they provide and how they should be addressed).\n\n\"The beautiful thing about ZeroMQ is the fact that it is a library and not an application. You can mold it however you like and it simply puts boring things like queuing, reconnecting, TCP sockets and such to the background, making sure you can concentrate on what is important to you. I've implemented all kinds of workers/clients and the broker in Ruby, because that is the main language we use for development, but also some PHP clients to connect to the bus from existing PHP webapps. We use this service bus for cloud services, connecting all kinds of platform devices to a service bus exposing functionality for automation.\n\n\"ZeroMQ is very easy to understand and if you spend a day with the guide, you'll have good knowledge of how it works. I'm a network engineer, not a software developer, but managed to create a very nice solution for our automation needs! ZeroMQ: Thank you very much!\"\n\n+++ Michael Jakl's Story\n\n\"We use ZeroMQ for distributing millions of documents per day in our distributed processing pipeline. We started out with big message queuing brokers that had their own respective issues and problems. In the quest of simplifying our architecture, we chose ZeroMQ to do the wiring. So far it had a huge impact in how our architecture scales and how easy it is to change and move the components. The plethora of language bindings lets us choose the right tool for the job without sacrificing interoperability in our system. We don't use a lot of sockets (less than 10 in our whole application), but that's all we needed to split a huge monolithic application into small independent parts.\n\n\"All in all, ZeroMQ lets me keep my sanity and helps my customers stay within budget.\"\n\n+++ Vadim Shalts's Story\n\n\"I am team leader in the company ActForex, which develops software for financial markets. Due to the nature of our domain, we need to process large volumes of prices quickly. In addition, it's extremely critical to minimize latency in processing orders and prices. Achieving a high throughput is not enough. Everything must be handled in a soft real time with a predictable ultra low latency per price. The system consists of multiple components exchanging messages. Each price can take a lot of processing stages, each of which increases total latency. As a consequence, low and predictable latency of messaging between components becomes a key factor of our architecture.\n\n\"We investigated different solutions to find something suitable for our needs. We tried different message brokers (RabbitMQ, ActiveMQ Apollo, Kafka), but failed to reach a low and predictable latency with any of them. In the end, we chose ZeroMQ used in conjunction with ZooKeeper for service discovery. Complex coordination with ZeroMQ requires a relatively large effort and a good understanding, as a result of the natural complexity of multithreading. We found that an external agent like ZooKeeper is better choice for service discovery and coordination while ZeroMQ can be used primarily for simple messaging. ZeroMQ fit perfectly into our architecture. It allowed us to achieve the desired latency using minimal efforts. It saved us from a bottleneck in the processing of messages and made processing time very stable and predictable.\n\n\"I can decidedly recommend ZeroMQ for solutions where low latency is important.\"\n\n++ How This Book Happened\n\nWhen I set out to write a ZeroMQ book, we were still debating the pros and cons of forks and pull requests in the ZeroMQ community. Today, for what it's worth, this argument seems settled: the \"liberal\" policy that we adopted for {{libzmq}} in early 2012 broke our dependency on a single prime author, and opened the floor to dozens of new contributors. More profoundly, it allowed us to move to a gently organic evolutionary model that was very different from the older forced-march model.\n\nThe reason I was confident this would work was that our work on the Guide had, for a year or more, shown the way. True, the text is my own work, which is perhaps as it should be. Writing is not programming. When we write, we tell a story and one doesn't want different voices telling one tale; it feels strange.\n\nFor me the real long-term value of the book is the repository of examples: about 65,000 lines of code in 24 different languages. It's partly about making ZeroMQ accessible to more people. People already refer to the Python and PHP example repositories--two of the most complete--when they want to tell others how to learn ZeroMQ. But it's also about learning programming languages.\n\nHere's a loop of code in Tcl:\n\n[[code language=\"Tcl\"]]\nwhile {1} {\n    # Process all parts of the message\n    zmq message message\n    frontend recv_msg message\n    set more [frontend getsockopt RCVMORE]\n    backend send_msg message [expr {$more?\"SNDMORE\":\"\"}]\n    message close\n    if {!$more} {\n        break ; # Last message part\n    }\n}\n[[/code]]\n\nAnd here's the same loop in Lua:\n\n[[code language=\"Lua\"]]\nwhile true do\n    --  Process all parts of the message\n    local msg = frontend:recv()\n    if (frontend:getopt(zmq.RCVMORE) == 1) then\n        backend:send(msg, zmq.SNDMORE)\n    else\n        backend:send(msg, 0)\n        break;      --  Last message part\n    end\nend\n[[/code]]\n\nAnd this particular example ({{rrbroker}}) exists in C#, C++, CL, Clojure, Erlang, F#, Go, Haskell, Haxe, Java, Julia, Lua, Node.js, Perl, PHP, Python, Ruby, Scala, Tcl, and of course C. This code base, all provided as open source under the MIT/X11 license, may form the basis for other books or projects.\n\nBut what this collection of translations says most profoundly is this: the language you choose is a detail, even a distraction. The power of ZeroMQ lies in the patterns it gives you and lets you build, and these transcend the comings and goings of languages. My goal as a software and social architect is to build structures that can last generations. There seems no point in aiming for mere decades.\n\n++ Removing Friction\n\nI'll explain the technical tool chain we used in terms of the friction we removed. In this book we're telling a story and the goal is to reach as many people as possible, as cheaply and smoothly as we can.\n\nThe core idea was to host the text and examples on GitHub and make it easy for anyone to contribute. It turned out to be more complex than that, however.\n\nLet's start with the division of labor. I'm a good writer and can produce endless amounts of decent text quickly. But what was impossible for me was to provide the examples in other languages. Because the core ZeroMQ API is in C, it seemed logical to write the original examples in C. Also, C is a neutral choice; it's perhaps the only language that doesn't create strong emotions.\n\nHow to encourage people to make translations of the examples? We tried a few approaches and finally what worked best was to offer a \"choose your language\" link on every single example in the text, which took people either to the translation or to a page explaining how they could contribute. The way it usually works is that as people learn ZeroMQ in their preferred language, they contribute a handful of translations or fixes to the existing ones.\n\nAt the same time, I noticed a few people quite determinedly translating //every single// example. This was mainly binding authors who realized that the examples were a great way to encourage people to use their bindings. For their efforts, I extended the scripts to produce language-specific versions of the book. Instead of including the C code, we'd include the Python, or PHP code. Lua and Haxe also got their dedicated versions.\n\nOnce we have an idea of who works on what, we know how to structure the work itself. It's clear that to write and test an example, what you want to work on is //source code//. So we import this source code when we build the book, and that's how we make language-specific versions.\n\nI like to write in a plain text format. It's fast and works well with source control systems like git. Because the main platform for our websites is Wikidot, I write using Wikidot's very readable markup format.\n\nAt least in the first chapters, it was important to draw pictures to explain the flow of messages between peers. Making diagrams by hand is a lot of work, and when we want to get final output in different formats, image conversion becomes a chore. I started with Ditaa, which turns text diagrams into PNGs, then later switched to asciitosvg, which produces SVG files, which are rather better. Since the figures are text diagrams, embedded in the prose, it's remarkably easy to work with them.\n\nBy now you'll realize that the toolchain we use is highly customized, though it uses a lot of external tools. All are available on Ubuntu, which is a mercy, and the whole custom toolchain is in the zguide repository in the bin subdirectory.\n\nLet's walk through the editing and publishing process. Here is how we produce the online version:\n\n[[code]]\nbin/buildguide\n[[/code]]\n\nWhich works as follows:\n\n* The original text sits in a series of text files (one per chapter).\n* The examples sit in the examples subdirectory, classified per language.\n* We take the text and process this using a custom Perl script, mkwikidot, into a set of Wikidot-ready files.\n* We do this for each of the languages that get their own version.\n* We extract the graphics and call asciitosvg and rasterize on each one to produce image files, which we store in the images subdirectory.\n* We extract inline listings (which are not translated) and stores these in the listings subdirectory.\n* We use pygmentize on each example and listing to create a marked-up page in Wikidot format.\n* We upload all changed files to the online wiki using the Wikidot API.\n\nDoing this from scratch takes a while. So we store the SHA1 signatures of every image, listing, example, and text file, and only process and upload changes, and that makes it easy to publish a new version of the text when people make new contributions.\n\nTo produce the PDF and Epub formats, we do the following:\n\n[[code]]\nbin/buildpdfs\n[[/code]]\n\nWhich works as follows:\n\n* We use the custom mkdocbook Perl program on the input files to produce a DocBook output.\n* We push the DocBook format through docbook2ps and ps2pdf to create clean PDFs in each language.\n* We push the DocBook format through db2epub to create Epub books and in each language.\n* We upload the PDFs to the public wiki using the Wikidot API.\n\nWhen creating a community project, it's important to lower the \"change latency\", which is the time it takes for people to see their work live or, at least, to see that you've accepted their pull request. If that is more than a day or two, you've often lost your contributor's interest.\n\n++ Licensing\n\nI want people to reuse this text in their own work: in presentations, articles, and even other books. However, the deal is that if they remix my work, others can remix theirs. I'd like credit, and have no argument against others making money from their remixes. Thus, the text is licensed under cc-by-sa.\n\nFor the examples, we started with GPL, but it rapidly became clear this wasn't workable. The point of examples is to give people reusable code fragments so they will use ZeroMQ more widely, and if these are GPL, that won't happen. We switched to MIT/X11, even for the larger and more complex examples that conceivably would work as LGPL.\n\nHowever, when we started turning the examples into standalone projects (as with Majordomo), we used the LGPL. Again, remixability trumps dissemination. Licenses are tools; use them with intent, not ideology.\n"
        },
        {
          "name": "preface_print.txt",
          "type": "blob",
          "size": 6.5009765625,
          "content": "+ Preface\n\n++ ZeroMQ in a Hundred Words\n\nZeroMQ (also known as 0MQ, 0\\MQ, or zmq) looks like an embeddable networking library but acts like a concurrency framework. It gives you sockets that carry atomic messages across various transports like in-process, inter-process, TCP, and multicast. You can connect sockets N-to-N with patterns like fan-out, pub-sub, task distribution, and request-reply. It's fast enough to be the fabric for clustered products. Its asynchronous I/O model gives you scalable multicore applications, built as asynchronous message-processing tasks. It has a score of language APIs and runs on most operating systems. ZeroMQ is from [http://www.imatix.com iMatix] and is LGPLv3 open source.\n\n++ How It Began\n\nWe took a normal TCP socket, injected it with a mix of radioactive isotopes stolen from a secret Soviet atomic research project, bombarded it with 1950-era cosmic rays, and put it into the hands of a drug-addled comic book author with a badly-disguised fetish for bulging muscles clad in spandex[figure]. Yes, ZeroMQ sockets are the world-saving superheroes of the networking world.\n\n++ The Zen of Zero\n\n[[code type=\"textdiagram\" title=\"A terrible accident...\"]]\n.------------.        .-------------.\n|            |        |             |\n| TCP socket +------->|   ZeroMQ    | ZAP!\n|            | BOOM!  |             |\n'------------'        |   Socket    |  POW!!\n  ^    ^    ^         |             |\n  |    |    |         '-------------'\n  |    |    |\n  |    |    |\n  |    |    '--------- Spandex\n  |    |\n  |    '-------------- Cosmic rays\n\n Illegal radioisotopes from\n secret Soviet atomic city\n[[/code]]\n\nThe Ø in ZeroMQ is all about tradeoffs. On the one hand this strange name lowers ZeroMQ's visibility on Google and Twitter. On the other hand it annoys the heck out of some Danish folk who write us things like \"ØMG røtfl\", and \"Ø is not a funny looking zero!\" and \"//Rødgrød med fløde!//\", which is apparently an insult that means \"may your neighbours be the direct descendants of Grendel!\"  Seems like a fair trade.\n\nOriginally the zero in ZeroMQ was meant as \"zero broker\" and (as close to) \"zero latency\" (as possible). Since then, it has come to encompass different goals: zero administration, zero cost, zero waste. More generally, \"zero\" refers to the culture of minimalism that permeates the project. We add power by removing complexity rather than by exposing new functionality.\n\n++ How This Book Came To Be\n\nIn the summer of 2010, ZeroMQ was still a little-known niche library described by its rather terse reference manual and a living but sparse wiki. Martin Sustrik and myself were sitting in the bar of the Hotel Kyjev in Bratislava plotting how to make ZeroMQ more widely popular. Martin had written most of the ZeroMQ code, and I'd put up the funding and organized the community. Over some Zlaty Bazants, we agreed that ZeroMQ needed a new, simpler web site and a basic guide for new users.\n\nMartin collected some ideas for topics to explain. I'd never written a line of ZeroMQ code before this, so it became a live learning documentary. As I worked through simple examples to more complex ones, I tried to answer many of the questions I'd seen on the mailing list. Because I'd been building large-scale architectures for 30 years, there were a lot of problems at which I was keen to throw ZeroMQ. Amazingly the results were mostly simple and elegant, even when working in C. I felt a pure joy learning ZeroMQ and using it to solve real problems, which brought me back to programming after a few years' pause. And often, not knowing how it was \"supposed\" to be done, we improved ZeroMQ as we went along.\n\nFrom the start, I wanted the ZeroMQ guide to be a community project, so I put it onto GitHub and let others contribute with pull requests. This was considered a radical, even vulgar approach by some. We came to a division of labor: I'd do the writing and make the original C examples, and others would help fix the text and translate the examples into other languages.\n\nThis worked better than I dared hope. You can now find all the examples in several languages and many in a dozen languages. It's a kind of programming language Rosetta stone and a valuable outcome in itself. We set up a high score: reach 80% translation and your language got its own Guide. PHP, Python, Lua, and Haxe reached this goal. People asked for PDFs, and we created those. People asked for ebooks, and got those. About a hundred people contributed to the examples to date.\n\nThe book, in its on-line version \"The Guide\", achieved its goal of popularizing ZeroMQ. The style pleases most and annoys some, which is how it should be. In December 2010, my work on ZeroMQ and this guide stopped, as I found myself going through late-stage cancer, heavy surgery, and six months of chemotherapy. When I picked up work again in mid-2011, it was to start using ZeroMQ in anger for one of the largest use cases imaginable: on the mobile phones and tablets of the world's biggest electronics company.\n\nBut the goal of the ZeroMQ book was, from the start, a printed work. So it was exciting to get an email from Bill Lubanovic in January 2012 introducing me to his editor, Andy Oram, at O'Reilly, suggesting a ZeroMQ book. Of course! Where do I sign? How much do I have to pay? Oh, I //get money// for this? All I have to do is finish it?\n\nOf course as soon as O'Reilly announced a ZeroMQ book, other publishers started sending out emails to potential authors. You'll probably see a rash of ZeroMQ books coming out next year. That's good. Our niche library has hit the mainstream and deserves its six inches of shelf space. My apologies to the other ZeroMQ authors. We've set the bar horribly high, and my advice is to make your books complementary. Perhaps focus on a specific language, platform, or pattern.\n\nThis is the magic and power of communities: be the first community in a space, stay healthy, and you own that space for ever.\n\n++ Audience\n\nThis book is written for professional programmers who want to learn how to make the massively distributed software that will dominate the future of computing. We assume you can read C code, because most of the examples here are in C even though ZeroMQ is used in many languages. We assume you care about scale, because ZeroMQ solves that problem above all others. We assume you need the best possible results with the least possible cost, because otherwise you won't appreciate the trade-offs that ZeroMQ makes. Other than that basic background, we try to present all the concepts in networking and distributed computing you will need to use ZeroMQ.\n\n.inbook preface.xml\n"
        },
        {
          "name": "preface_web.txt",
          "type": "blob",
          "size": 5.3984375,
          "content": ".-  Instructions for mkwikidot\n.set GIT=https://github.com/booksbyus/zguide\n.set BRANCH=master\n.output preface.wd\n\n**By Pieter Hintjens, CEO of iMatix**\n\nPlease use the [$(GIT)/issues issue tracker] for all comments and errata. This version covers the latest stable release of ZeroMQ (3.2). If you are using older versions of ZeroMQ then some of the examples and explanations won't be accurate.\n\nThe Guide is originally [/page:all in C], but also in [/php:all PHP], [/java:all Java], [/py:all Python], [/lua:all Lua], and [/hx:all Haxe]. We've also translated most of the examples into C++, C#, CL, Delphi, Erlang, F#, Felix, Haskell, Julia, Objective-C, Ruby, Ada, Basic, Clojure, Go, Haxe, Node.js, ooc, Perl, and Scala.\n\n+ Preface\n\n++ ZeroMQ in a Hundred Words\n\nZeroMQ (also known as 0MQ, 0\\MQ, or zmq) looks like an embeddable networking library but acts like a concurrency framework. It gives you sockets that carry atomic messages across various transports like in-process, inter-process, TCP, and multicast. You can connect sockets N-to-N with patterns like fan-out, pub-sub, task distribution, and request-reply. It's fast enough to be the fabric for clustered products. Its asynchronous I/O model gives you scalable multicore applications, built as asynchronous message-processing tasks. It has a score of language APIs and runs on most operating systems. ZeroMQ is from [http://www.imatix.com iMatix] and is LGPLv3 open source.\n\n++ How It Began\n\nWe took a normal TCP socket, injected it with a mix of radioactive isotopes stolen from a secret Soviet atomic research project, bombarded it with 1950-era cosmic rays, and put it into the hands of a drug-addled comic book author with a badly-disguised fetish for bulging muscles clad in spandex[figure]. Yes, ZeroMQ sockets are the world-saving superheroes of the networking world.\n\n[[code type=\"textdiagram\" title=\"A terrible accident...\"]]\n.------------.        .------------.\n|            |        |            |\n| TCP socket +------->|   ZeroMQ   | ZAP!\n|            | BOOM!  |            |\n'------------'        |   Socket   |  POW!!\n  ^    ^    ^         |            |\n  |    |    |         '------------'\n  |    |    |\n  |    |    |\n  |    |    '--------- Spandex\n  |    |\n  |    '-------------- Cosmic rays\n\n Illegal radioisotopes from\n secret Soviet atomic city\n[[/code]]\n\n++ The Zen of Zero\n\nThe Ø in ZeroMQ is all about tradeoffs. On the one hand this strange name lowers ZeroMQ's visibility on Google and Twitter. On the other hand it annoys the heck out of some Danish folk who write us things like \"ØMG røtfl\", and \"Ø is not a funny looking zero!\" and \"//Rødgrød med fløde!//\", which is apparently an insult that means \"may your neighbours be the direct descendants of Grendel!\"  Seems like a fair trade.\n\nOriginally the zero in ZeroMQ was meant as \"zero broker\" and (as close to) \"zero latency\" (as possible). Since then, it has come to encompass different goals: zero administration, zero cost, zero waste. More generally, \"zero\" refers to the culture of minimalism that permeates the project. We add power by removing complexity rather than by exposing new functionality.\n\n++ Audience\n\nThis book is written for professional programmers who want to learn how to make the massively distributed software that will dominate the future of computing. We assume you can read C code, because most of the examples here are in C even though ZeroMQ is used in many languages. We assume you care about scale, because ZeroMQ solves that problem above all others. We assume you need the best possible results with the least possible cost, because otherwise you won't appreciate the trade-offs that ZeroMQ makes. Other than that basic background, we try to present all the concepts in networking and distributed computing you will need to use ZeroMQ.\n\n++ Acknowledgements\n\nThanks to Andy Oram for making [http://shop.oreilly.com/product/0636920026136.do the O'Reilly book] happen, and editing this text.\n\nThanks to Bill Desmarais, Brian Dorsey, Daniel Lin, Eric Desgranges, Gonzalo Diethelm, Guido Goldstein, Hunter Ford, Kamil Shakirov, Martin Sustrik, Mike Castleman, Naveen Chawla, Nicola Peduzzi, Oliver Smith, Olivier Chamoux, Peter Alexander, Pierre Rouleau, Randy Dryburgh, John Unwin, Alex Thomas, Mihail Minkov, Jeremy Avnet, Michael Compton, Kamil Kisiel, Mark Kharitonov, Guillaume Aubert, Ian Barber, Mike Sheridan, Faruk Akgul, Oleg Sidorov, Lev Givon, Allister MacLeod, Alexander D'Archangel, Andreas Hoelzlwimmer, Han Holl, Robert G. Jakabosky, Felipe Cruz, Marcus McCurdy, Mikhail Kulemin, Dr. Gergő Érdi, Pavel Zhukov, Alexander Else, Giovanni Ruggiero, Rick \"Technoweenie\", Daniel Lundin, Dave Hoover, Simon Jefford, Benjamin Peterson, Justin Case, Devon Weller, Richard Smith, Alexander Morland, Wadim Grasza, Michael Jakl, Uwe Dauernheim, Sebastian Nowicki, Simone Deponti, Aaron Raddon, Dan Colish, Markus Schirp, Benoit Larroque, Jonathan Palardy, Isaiah Peng, Arkadiusz Orzechowski, Umut Aydin, Matthew Horsfall, Jeremy W. Sherman, Eric Pugh, Tyler Sellon, John E. Vincent, Pavel Mitin, Min RK, Igor Wiedler, Olof Åkesson, Patrick Lucas, Heow Goodman, Senthil Palanisami, John Gallagher, Tomas Roos, Stephen McQuay, Erik Allik, Arnaud Cogoluègnes, Rob Gagnon, Dan Williams, Edward Smith, James Tucker, Kristian Kristensen, Vadim Shalts, Martin Trojer, Tom van Leeuwen, Hiten Pandya, Harm Aarts, Marc Harter, Iskren Ivov Chernev, Jay Han, Sonia Hamilton, Nathan Stocks, Naveen Palli, and Zed Shaw for their contributions to this work.\n"
        },
        {
          "name": "site",
          "type": "tree",
          "content": null
        },
        {
          "name": "styles.txt",
          "type": "blob",
          "size": 1.0166015625,
          "content": "Style Guide\n\nHyphenated:\n\n    fan-out\n    fan-in\n    single-part\n    in-process (adj)\n    inter-broker\n    inter-thread\n    load-balancing\n    publish-subscribe\n    pub-sub\n    request-reply\n    step-by-step\n    zero-copy\n    double-check\n    connect-bind pair\n\nNo hyphens in:\n\n    frontend\n    backend\n    single socket API\n    timeout\n    online\n    multicast\n    multipart\n    nonfatal\n    general purpose\n    round robin\n    no one\n    side effect\n    use case\n    wish list\n    nontrivial\n    setup (n)\n    set up (v)\n    shut down\n    straightforward\n    failover (n)\n    fail over (v)\n    heartbeating\n    real time\n    upfront\n\nOther notes:\n\n    \"1 a.m.\", \"2.30p.m\".\n    PUB or SUB in capitals when preceding socket\n    \"client/server\"\n    Always make sure that i.e. and e.g. are followed by a comma.\n    When referring to version numbers use \"0MQ v2.x\", \"0MQ v3.x\"\n    Use \"because\" not \"since\" for causation\n    Commas after introductory participles\n    No commas in conjunctions\n    \"versus\", not \"vs.\"\n    \"and so on\", not \"etc.\""
        },
        {
          "name": "xl8n",
          "type": "tree",
          "content": null
        },
        {
          "name": "zguide.book",
          "type": "blob",
          "size": 0.2392578125,
          "content": "FILENAME=zguide\nAUTHOR=Pieter Hintjens\nTITLE=ZeroMQ Guide\nSUBTITLE=\nTITLENOTE=\n\n#   Content\n./preface_web.txt\n./chapter1.txt\n./chapter2.txt\n./chapter3.txt\n./chapter4.txt\n./chapter5.txt\n./chapter6.txt\n./chapter7.txt\n./chapter8.txt\n./postface.txt\n"
        }
      ]
    }
  ]
}