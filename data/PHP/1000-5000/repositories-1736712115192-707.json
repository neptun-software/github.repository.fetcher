{
  "metadata": {
    "timestamp": 1736712115192,
    "page": 707,
    "hasNextPage": true,
    "endCursor": "Y3Vyc29yOjcxMA==",
    "completionStatus": "IN_PROGRESS"
  },
  "repositories": [
    {
      "nameWithOwner": "fossasia/feed.api.fossasia.net",
      "stars": 1531,
      "defaultBranch": "master",
      "files": [
        {
          "name": ".gitignore",
          "type": "blob",
          "size": 0.0185546875,
          "content": "cache/\nconfig.json\n"
        },
        {
          "name": "JsonpHelper.php",
          "type": "blob",
          "size": 1.193359375,
          "content": "<?php\nclass JsonpHelper {\n\n\tprivate static function is_valid_callback($subject)\n\t{\n\t    $identifier_syntax\n\t      = '/^[$_\\p{L}][$_\\p{L}\\p{Mn}\\p{Mc}\\p{Nd}\\p{Pc}\\x{200C}\\x{200D}]*+$/u';\n\n\t    $reserved_words = array('break', 'do', 'instanceof', 'typeof', 'case',\n\t      'else', 'new', 'var', 'catch', 'finally', 'return', 'void', 'continue', \n\t      'for', 'switch', 'while', 'debugger', 'function', 'this', 'with', \n\t      'default', 'if', 'throw', 'delete', 'in', 'try', 'class', 'enum', \n\t      'extends', 'super', 'const', 'export', 'import', 'implements', 'let', \n\t      'private', 'public', 'yield', 'interface', 'package', 'protected', \n\t      'static', 'null', 'true', 'false');\n\n\t    return preg_match($identifier_syntax, $subject)\n\t        && ! in_array(mb_strtolower($subject, 'UTF-8'), $reserved_words);\n\t}\n\n\tpublic static function outputXML($string) {\n\t\t# JSON if no callback\n\t\tif( ! isset($_GET['callback']) )\n\t\t    exit($string);\n\t\t$string = str_replace(\"\\n\", \" \", str_replace(\"'\", '\"', $string));\n\t\t# JSONP if valid callback\n\t\tif(JsonpHelper::is_valid_callback($_GET['callback']))\n\t\t    exit(\"{$_GET['callback']}('$string')\");\n\n\t\t# Otherwise, bad request\n\t\theader('status: 400 Bad Request', true, 400);\n\t}\n}"
        },
        {
          "name": "README.md",
          "type": "blob",
          "size": 2.8623046875,
          "content": "FOSSASIA Feed Merger\n===========\nRSS blog feed merger for FOSSASIA API communities\n\n[![Join the chat at https://gitter.im/fossasia/api.fossasia.net](https://badges.gitter.im/Join%20Chat.svg)](https://gitter.im/fossasia/api.fossasia.net?utm_source=badge&utm_medium=badge&utm_campaign=pr-badge&utm_content=badge)\n\n## Setup\n\n* Clone the repo :\n\n\t```sh\n\tgit clone https://github.com/fossasia/feed.api.fossasia.net.git\n\tcd feed.api.fossasia.net\n\t```\n\n* Create `config.json` from `config.json.sample`, and modify it as you need.\n\n\t```sh\n\tcp config.json.sample config.json\n\t```\n\n* Create a `cache` folder to store cached feeds\n\n* Run `feed.php` (or access it from a php web server)\n\n\t```sh\n\tphp feed.php\n\t```\n\n## How to use\n\nFrom a web browser or a terminal, call `feed.php`, with these parameters : \n\n* `source` : shortname of the community to get feeds from. Set `source` to `all` to get feeds from all communities.\n\n You can find a community shortname here (keys) : https://github.com/fossasia/directory.api.fossasia.net/blob/master/directory.json\n* `limit` : maximum number of results. Default to `1`.\n\n* `category` : type of feed (blog, podcast, ics, ..). Default to `blog`.\n\n## How it works\n\nInformation about communities feeds is read from `ffGeoJson.json`. This service retrieves blog feeds from provided links, sort by publication, send back to users as rss feed and cache them in folder `cache` at project's directory root.\n\n## History\n\nOur goal is to collect information about Open Source Communities and Hackspaces all over Asia. This information will be used to aggregate contact data, locations, news feeds and events.\nWe adopted this API from the Hackerspaces and Freifunk API, invented years before to collect decentralized data.\n\nAt the Wireless Community Weekend 2013 in Berlin there was a first meeting to relaunch freifunk.net. To represent local communities without collecting and storing data centrally, a way had to be found. Another requirement was to enable local communities to keep their data up to date easily.\n\nBased on the Hackerspaces API (http://hackerspaces.nl/spaceapi/) the idea of the freifunk API was born: Each community provides its data in a well defined format, hosted on their places (web space, wiki, web servers) and contributes a link to the directory. This directory only consists of the name and an url per community. First services supported by our freifunk API are the global community map and a community feed aggregator.\n\nThe freifunk API is designed to collect metadata of communities in a decentral way and make it available to other users. It's not designated to be a freifunk node database or a directory of individual community firmware settings.\n\n[FOSSASIA API repo](https://github.com/fossasia/api.fossasia.net)\n\n## Contribute\n\nIssues & Pull Requests are highly appreciated. Check out our issues for contribution opportunities.\n\n## Requirements\n\n* `ffGeoJson.json`\n* PHP >= 5.4"
        },
        {
          "name": "TODO.md",
          "type": "blob",
          "size": 0.525390625,
          "content": "TODO\n====\n\ndirectory\n---------\n- find a space to put the directory file\n- give a possibility to add new communities via web form (maybe ask the SpaceAPI developers)\n- provide a way to cache the json file, if the communities web server is weak\n\ngenerator\n---------\n- build a validator to approve given json files (as of now, we can only generate a file from a web form)\n- use the directory to load and approve the json files\n\napi\n---\n- use links instead of copying files between directories\n- create a cache mode for collectCommunities.py\n"
        },
        {
          "name": "config.json.sample",
          "type": "blob",
          "size": 1.0009765625,
          "content": "{\n\t\"ffGeoJsonUrl\": \"http://freifunk.net/map/ffGeoJson.json\",\n\t\"defaultLimit\" : 20,\n\t\"additionalFeeds\" : \n\t[\n\t\t{\n\t\t\t\"category\" : \"blog\",\n\t\t\t\"url\" : \"http://blog.freifunk.net/rss.xml\",\n\t\t\t\"name\" : \"blog.freifunk.net\",\n\t\t\t\"homepage\" : \"http://blog.freifunk.net\"\n\t\t},\n\t\t{\n\t\t\t\"category\" : \"blog\",\n\t\t\t\"url\" : \"http://freifunkstattangst.de/feed/\",\n\t\t\t\"name\" : \"freifunk statt Angst\",\n\t\t\t\"homepage\" : \"http://freifunkstattangst.de\"\n\t\t},\n\t\t{\n\t\t\t\"category\" : \"blog\",\n\t\t\t\"url\" : \"http://radio.freifunk-bno.de/freifunk_radio_feedfeed.xml\",\n\t\t\t\"name\" : \"Freifunk Radio\",\n\t\t\t\"homepage\" : \"http://wiki.freifunk.net/Freifunk.radio\"\n\t\t},\n\t\t{\n\t\t\t\"category\" : \"podcast\",\n\t\t\t\"url\" : \"http://radio.freifunk-bno.de/freifunk_radio_feedfeed.xml\",\n\t\t\t\"name\" : \"Freifunk Radio\",\n\t\t\t\"homepage\" : \"http://wiki.freifunk.net/Freifunk.radio\"\n\t\t},\n\t\t{\n\t\t\t\"category\" : \"podcast\",\n\t\t\t\"url\" : \"http://rss.freifunk.net/tags/podcast.rss\",\n\t\t\t\"name\" : \"Freifunk - zusammengetragene Audiobeiträge\",\n\t\t\t\"homepage\" : \"http://rss.freifunk.net/tags/podcast\"\n\t\t}\n\t]\n}\n"
        },
        {
          "name": "feed.php",
          "type": "blob",
          "size": 1.927734375,
          "content": "<?php\ninclude_once(\"mergedrss.php\");\ninclude_once(\"JsonpHelper.php\");\nif ( ! empty($_GET[\"category\"]) ) {\n\t$category = $_GET[\"category\"];\n} else {\n\t$category = \"blog\";\n}\n\n$configs = file_get_contents(\"config.json\");\n$configs = json_decode($configs, true);\n$communities = $configs['ffGeoJsonUrl'];\n$limit = $configs['defaultLimit'];\nif ( ! empty($_GET[\"items\"]) ) {\n\t$limit = $_GET[\"items\"];\n}\n$feeds = array();\n$urls = array();\n\n//load combined api file\n$api = file_get_contents($communities);\n$json = json_decode($api, true);\n$geofeatures = $json['features'];\n\n// get additional feeds from config\nforeach($configs['additionalFeeds'] as $additionalFeed) {\n\tif ($additionalFeed['category'] == $category) {\n\t\t$feeds[$additionalFeed['name']] = array($additionalFeed['url'], $additionalFeed['name'], $additionalFeed['homepage']);\n\t}\n}\n\n// get feeds from API\nforeach($geofeatures as $feature)\n{\n\tif ( ! empty($feature['properties']['feeds'] ) ) {\n\t\tforeach($feature['properties']['feeds'] as $feed )\n\t\t{\n\t\t\tif ( ! array_key_exists($feature['properties']['url'], $urls) && ! empty($feed['category']) && $feed['category'] == $category && !empty($feed['type']) && $feed['type'] == \"rss\" ) {\n\t\t\t\t$feeds[$feature['properties']['shortname']] = array($feed['url'],$feature['properties']['name'], $feature['properties']['url']);\n\t\t\t\t$urls[$feature['properties']['url']] = \"1\";\n\t\t\t}\n\t\t}\n\t}\n}\n\n// set the header type\nheader(\"Content-type: text/xml\");\n// set an arbitrary feed date\n$feed_date = date(\"r\", mktime(10,0,0,9,8,2010));\n\n// Create new MergedRSS object with desired parameters\n$MergedRSS = new MergedRSS($feeds, \"Fossasia Community Feeds\", \"http://www.fossasia.net/\", \"This the merged RSS feed of RSS feeds of our community\", $feed_date);\n\n//Export the first 10 items to screen\n$result = $MergedRSS->export(true, false, (array_key_exists('limit', $_GET) ? $_GET['limit'] : $limit), (array_key_exists('source', $_GET) ? $_GET['source'] : 'all'));\n\nJsonpHelper::outputXML($result);\n"
        },
        {
          "name": "mergedrss.php",
          "type": "blob",
          "size": 5.896484375,
          "content": "<?php\nclass MergedRSS {\n\tprivate $myFeeds = null;\n\tprivate $myTitle = null;\n\tprivate $myLink = null;\n\tprivate $myDescription = null;\n\tprivate $myPubDate = null;\n\tprivate $myCacheTime = null;\n\tprivate $fetch_timeout = null; //timeout for fetching urls in seconds (floating point)\n\n\t// create our Merged RSS Feed\n\tpublic function __construct($feeds = null, $channel_title = null, $channel_link = null, $channel_description = null, $channel_pubdate = null, $cache_time_in_seconds = 3600, $fetch_timeout = '1.2') {\n\t\t// set variables\n\t\t$this->myTitle = $channel_title;\n\t\t$this->myLink = $channel_link;\n\t\t$this->myDescription = $channel_description;\n\t\t$this->myPubDate = $channel_pubdate;\n\t\t$this->myCacheTime = $cache_time_in_seconds;\n\t\t$this->fetch_timeout = $fetch_timeout;\n\n\t\t// initialize feed variable\n\t\t$this->myFeeds = array();\n\n\t\tif (isset($feeds)) {\n\t\t\t// check if it's an array.  if so, merge it into our existing array.  if it's a single feed, just push it into the array\n\t\t\tif (is_array($feeds)) {\n\t\t\t\t$this->myFeeds = array_merge($feeds);\n\t\t\t} else { \n\t\t\t\t$this->myFeeds[] = $feeds;\n\t\t\t}\n\t\t}\n\t}\n\n\t// exports the data as a returned value and/or outputted to the screen\n\tpublic function export($return_as_string = true, $output = false, $limit = null, $community = 'all') {\n\t\t// initialize a combined item array for later\n\t\t$items = array();\t\n\n\t\t// loop through each feed\n\t\tforeach ($this->myFeeds as $key => $feed_array) {\n\t\t\tif ($community !== 'all' && $key !== $community) {\n\t\t\t\tcontinue;\n\t\t\t}\n\n\t\t\t$results = null;\n\t\t\t$feed_url = $feed_array[0];\n\t\t\t// determine my cache file name.  for now i assume they're all kept in a file called \"cache\"\n\t\t\t$cache_file = \"cache/\" . $this->__create_feed_key($feed_url);\n\n\t\t\t// determine whether or not I should use the cached version of the xml\n\t\t\t$use_cache = false;\n\t\t\tif (file_exists($cache_file)) { \n\t\t\t\tif (time() - filemtime($cache_file) < $this->myCacheTime) { \n\t\t\t\t\t$use_cache = true;\n\t\t\t\t}\n\t\t\t}\n\n\t\t\tif ($use_cache) {\n\t\t\t\t// retrieve cached version\n\t\t\t\t$sxe = $this->__fetch_rss_from_cache($cache_file); \n\t\t\t\t$results = $sxe->channel->item;\n\t\t\t} else { \n\t\t\t\t// retrieve updated rss feed\n\t\t\t\t$sxe = $this->__fetch_rss_from_url($feed_url);\n\t\t\t\tif ( is_object($sxe) ) {\n\t\t\t\t\t$results = $sxe->channel->item;\n\t\t\t\t}\n\n\t\t\t\tif (!isset($results)) { \n\t\t\t\t\t// couldn't fetch from the url. grab a cached version if we can\n\t\t\t\t\tif (file_exists($cache_file)) { \n\t\t\t\t\t\t$sxe = $this->__fetch_rss_from_cache($cache_file); \n\t\t\t\t\t\t$results = $sxe->channel->item;\n\t\t\t\t\t}\n\t\t\t\t} else { \n\t\t\t\t\t// we need to update the cache file\n\t\t\t\t\tif (is_object($sxe)) {\n\t\t\t\t\t\t$sxe->asXML($cache_file);\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\n\t\t\tif (isset($results)) { \n\t\t\t\t// add each item to the master item list\n\t\t\t\tforeach ($results as $item) {\n\t\t\t\t\tif (trim($item->title) == '') {\n\t\t\t\t\t\tcontinue;\n\t\t\t\t\t}\n\t\t\t\t\t//convert title to utf-8 (i.e. from facebook feeds)\n\t\t\t\t\t$item->title = html_entity_decode($item->title, ENT_QUOTES,  'UTF-8');\n\t\t\t\t\t$source = $item->addChild('source', '' . $feed_array[1]);\n\t\t\t\t\t$source->addAttribute('url', $feed_array[2]);\n\t\t\t\t\t$items[] = $item;\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\n\n\t\t// set all the initial, necessary xml data\n\t\t$xml =  \"<?xml version=\\\"1.0\\\" encoding=\\\"UTF-8\\\"?>\\n\";\n\t\t$xml .= \"<rss version=\\\"2.0\\\" xmlns:content=\\\"http://purl.org/rss/1.0/modules/content/\\\" xmlns:wfw=\\\"http://wellformedweb.org/CommentAPI/\\\" xmlns:dc=\\\"http://purl.org/dc/elements/1.1/\\\" xmlns:atom=\\\"http://www.w3.org/2005/Atom\\\" xmlns:sy=\\\"http://purl.org/rss/1.0/modules/syndication/\\\" xmlns:slash=\\\"http://purl.org/rss/1.0/modules/slash/\\\" xmlns:itunes=\\\"http://www.itunes.com/DTDs/Podcast-1.0.dtd\\\" >\\n\";\n\t\t$xml .= \"<channel>\\n\";\n\t\tif (isset($this->myTitle)) { $xml .= \"\\t<title>\".$this->myTitle.\"</title>\\n\"; }\n\t\t$xml .= \"\\t<atom:link href=\\\"http://\".$_SERVER['HTTP_HOST'].$_SERVER['PHP_SELF'].\"\\\" rel=\\\"self\\\" type=\\\"application/rss+xml\\\" />\\n\";\n\t\tif (isset($this->myLink)) { $xml .= \"\\t<link>\".$this->myLink.\"</link>\\n\"; }\n\t\tif (isset($this->myDescription)) { $xml .= \"\\t<description>\".$this->myDescription.\"</description>\\n\"; }\n\t\tif (isset($this->myPubDate)) { $xml .= \"\\t<pubDate>\".$this->myPubDate.\"</pubDate>\\n\"; }\n\n\t\t// if there are any items to add to the feed, let's do it\n\t\tif (sizeof($items) >0) { \n\n\t\t\t// sort items\n\t\t\tusort($items, array($this,\"__compare_items\"));\t\t\n\t\n\t\t\t// if desired, splice items into an array of the specified size\n\t\t\tif (isset($limit)) { array_splice($items, intval($limit)); }\n\n\t\t\t// now let's convert all of our items to XML\t\n\t\t\tfor ($i=0; $i<sizeof($items); $i++) { \n\t\t\t\t$xml .= $items[$i]->asXML() .\"\\n\";\n\t\t\t}\n\t\t\t\n\n\t\t}\n\t\t$xml .= \"</channel>\\n</rss>\";\n\n\t\t// if output is desired print to screen\n\t\tif ($output) { echo $xml; }\n\t\t\n\t\t// if user wants results returned as a string, do so\n\t\tif ($return_as_string) { return $xml; }\n\t\t\n\t}\n\n\n\t// compares two items based on \"pubDate\"\t\n\tprivate function __compare_items($a,$b) {\n\t\treturn strtotime($b->pubDate) - strtotime($a->pubDate);\n\t}\n\n\t// retrieves contents from a cache file ; returns null on error\n\tprivate function __fetch_rss_from_cache($cache_file) { \n\t\tif (file_exists($cache_file)) { \n\t\t\treturn simplexml_load_file($cache_file);\n\t\t}\n\t\treturn null;\n\t}\n\n\t// retrieves contents of an external RSS feed ; implicitly returns null on error\n\tprivate function __fetch_rss_from_url($url) {\n\t\t// Create new SimpleXMLElement instance\n\t\ttry {\n\t\t\t//set user agent, i.e. facebook.com doesn't deliver feeds to unknown browsers\n\t\t\tini_set('user_agent', 'Mozilla/5.0 (Windows NT 6.3; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/37.0.2049.0 Safari/537.36');\n\t\t\t$fp = fopen($url, 'r', false , stream_context_create(array('http' => array('timeout' => $this->fetch_timeout))));\n\n\t\t\tif ($fp) {\n\t\t\t\t$sxe = simplexml_load_string(stream_get_contents($fp));\n\t\t\t} else {\n\t\t\t\t$sxe = false;\n\t\t\t}\n\t\t\treturn $sxe;\n\t\t} catch (Exception $e) {\n\t\t\treturn null;\n\t\t}\n\t}\n\n\t// creates a key for a specific feed url (used for creating friendly file names)\n\tprivate function __create_feed_key($url) { \n\t\treturn preg_replace('/[^a-zA-Z0-9\\.]/', '_', $url) . 'cache';\n\t}\n\n}\n\n"
        }
      ]
    }
  ]
}