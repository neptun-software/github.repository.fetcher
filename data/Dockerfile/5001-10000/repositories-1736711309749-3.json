{
  "metadata": {
    "timestamp": 1736711309749,
    "page": 3,
    "hasNextPage": false,
    "endCursor": "Y3Vyc29yOjQ=",
    "completionStatus": "IN_PROGRESS"
  },
  "repositories": [
    {
      "nameWithOwner": "nodejs/docker-node",
      "stars": 8309,
      "defaultBranch": "main",
      "files": [
        {
          "name": ".editorconfig",
          "type": "blob",
          "size": 0.1435546875,
          "content": "root = true\n\n[*]\ncharset = utf-8\nend_of_line = lf\nindent_size = 2\nindent_style = space\ninsert_final_newline = true\ntrim_trailing_whitespace = true\n"
        },
        {
          "name": ".gitattributes",
          "type": "blob",
          "size": 0.0751953125,
          "content": "* text=auto eol=lf\n/Dockerfile*.template        linguist-language=Dockerfile\n"
        },
        {
          "name": ".github",
          "type": "tree",
          "content": null
        },
        {
          "name": "18",
          "type": "tree",
          "content": null
        },
        {
          "name": "20",
          "type": "tree",
          "content": null
        },
        {
          "name": "22",
          "type": "tree",
          "content": null
        },
        {
          "name": "23",
          "type": "tree",
          "content": null
        },
        {
          "name": "CONTRIBUTING.md",
          "type": "blob",
          "size": 2.017578125,
          "content": "# Contributing to docker-node\n\nThank you for your contribution. Here are a set of guidelines for contributing to the docker-node project.\n\n## Version Updates\n\nNew **Node.js** releases are released as soon as possible.\n\nNew **NPM** releases are not tracked. We simply use the NPM version bundled in the corresponding Node.js release.\n\n**Yarn** is updated to the latest version only when there is a new Node.js SemVer PATCH release (unless Yarn has received a security update), and it's updated only in the branch with the new release, preferably in the same PR. The `update.sh` script does this automatically when invoked with a specific branch, e.g. `./update.sh 6.10`.\n\n### Submitting a PR for a version update\n\nIf you'd like to help us by submitting a PR for a version update, please do the following:\n\n1. [Fork this project.](https://docs.github.com/en/get-started/quickstart/fork-a-repo)\n1. [Clone the forked repository.](https://docs.github.com/en/github/creating-cloning-and-archiving-repositories/cloning-a-repository)\n1. Create a branch for the update PR. For example, `git checkout main; git checkout -b version-update`.\n1. Run `./update.sh`. You can see additional options by using accessing the built-in help documentation with `./update.sh -h`. This script will automatically update the appropriate files with the latest versions and checksums.\n1. Commit the modified files to the `version-update` branch and push the branch to your fork.\n1. [Create a PR to merge the branch from your fork into this project's default branch.](https://docs.github.com/en/pull-requests/collaborating-with-pull-requests/proposing-changes-to-your-work-with-pull-requests/creating-a-pull-request-from-a-fork).\n\n## Adding dependencies to the base images\n\nNodeJS is a big ecosystem with a variety of different use cases. The docker images for node are designed to provide the minimum for running core node.  Additional dependencies (including dependencies for npm or yarn such as git) will not be included in these base images and will need to be included in descendent image.\n"
        },
        {
          "name": "Dockerfile-alpine.template",
          "type": "blob",
          "size": 4.1513671875,
          "content": "FROM alpine:0.0\n\nENV NODE_VERSION 0.0.0\n\nRUN addgroup -g 1000 node \\\n    && adduser -u 1000 -G node -s /bin/sh -D node \\\n    && apk add --no-cache \\\n        libstdc++ \\\n    && apk add --no-cache --virtual .build-deps \\\n        curl \\\n    && ARCH= OPENSSL_ARCH='linux*' && alpineArch=\"$(apk --print-arch)\" \\\n      && case \"${alpineArch##*-}\" in \\\n        x86_64) ARCH='x64' CHECKSUM=CHECKSUM_x64 OPENSSL_ARCH=linux-x86_64;; \\\n        x86) OPENSSL_ARCH=linux-elf;; \\\n        aarch64) OPENSSL_ARCH=linux-aarch64;; \\\n        arm*) OPENSSL_ARCH=linux-armv4;; \\\n        ppc64le) OPENSSL_ARCH=linux-ppc64le;; \\\n        s390x) OPENSSL_ARCH=linux-s390x;; \\\n        *) ;; \\\n      esac \\\n  && if [ -n \"${CHECKSUM}\" ]; then \\\n    set -eu; \\\n    curl -fsSLO --compressed \"https://unofficial-builds.nodejs.org/download/release/v$NODE_VERSION/node-v$NODE_VERSION-linux-$ARCH-musl.tar.xz\"; \\\n    echo \"$CHECKSUM  node-v$NODE_VERSION-linux-$ARCH-musl.tar.xz\" | sha256sum -c - \\\n      && tar -xJf \"node-v$NODE_VERSION-linux-$ARCH-musl.tar.xz\" -C /usr/local --strip-components=1 --no-same-owner \\\n      && ln -s /usr/local/bin/node /usr/local/bin/nodejs; \\\n  else \\\n    echo \"Building from source\" \\\n    # backup build\n    && apk add --no-cache --virtual .build-deps-full \\\n        binutils-gold \\\n        g++ \\\n        gcc \\\n        gnupg \\\n        libgcc \\\n        linux-headers \\\n        make \\\n        python3 \\\n        py-setuptools \\\n    # use pre-existing gpg directory, see https://github.com/nodejs/docker-node/pull/1895#issuecomment-1550389150\n    && export GNUPGHOME=\"$(mktemp -d)\" \\\n    # gpg keys listed at https://github.com/nodejs/node#release-keys\n    && for key in \\\n      \"${NODE_KEYS[@]}\"\n    ; do \\\n      gpg --batch --keyserver hkps://keys.openpgp.org --recv-keys \"$key\" || \\\n      gpg --batch --keyserver keyserver.ubuntu.com --recv-keys \"$key\" ; \\\n    done \\\n    && curl -fsSLO --compressed \"https://nodejs.org/dist/v$NODE_VERSION/node-v$NODE_VERSION.tar.xz\" \\\n    && curl -fsSLO --compressed \"https://nodejs.org/dist/v$NODE_VERSION/SHASUMS256.txt.asc\" \\\n    && gpg --batch --decrypt --output SHASUMS256.txt SHASUMS256.txt.asc \\\n    && gpgconf --kill all \\\n    && rm -rf \"$GNUPGHOME\" \\\n    && grep \" node-v$NODE_VERSION.tar.xz\\$\" SHASUMS256.txt | sha256sum -c - \\\n    && tar -xf \"node-v$NODE_VERSION.tar.xz\" \\\n    && cd \"node-v$NODE_VERSION\" \\\n    && ./configure \\\n    && make -j$(getconf _NPROCESSORS_ONLN) V= \\\n    && make install \\\n    && apk del .build-deps-full \\\n    && cd .. \\\n    && rm -Rf \"node-v$NODE_VERSION\" \\\n    && rm \"node-v$NODE_VERSION.tar.xz\" SHASUMS256.txt.asc SHASUMS256.txt; \\\n  fi \\\n  && rm -f \"node-v$NODE_VERSION-linux-$ARCH-musl.tar.xz\" \\\n  # Remove unused OpenSSL headers to save ~34MB. See this NodeJS issue: https://github.com/nodejs/node/issues/46451\n  && find /usr/local/include/node/openssl/archs -mindepth 1 -maxdepth 1 ! -name \"$OPENSSL_ARCH\" -exec rm -rf {} \\; \\\n  && apk del .build-deps \\\n  # smoke tests\n  && node --version \\\n  && npm --version\n\nENV YARN_VERSION 0.0.0\n\nRUN apk add --no-cache --virtual .build-deps-yarn curl gnupg tar \\\n  # use pre-existing gpg directory, see https://github.com/nodejs/docker-node/pull/1895#issuecomment-1550389150\n  && export GNUPGHOME=\"$(mktemp -d)\" \\\n  && for key in \\\n    \"${YARN_KEYS[@]}\"\n  ; do \\\n    gpg --batch --keyserver hkps://keys.openpgp.org --recv-keys \"$key\" || \\\n    gpg --batch --keyserver keyserver.ubuntu.com --recv-keys \"$key\" ; \\\n  done \\\n  && curl -fsSLO --compressed \"https://yarnpkg.com/downloads/$YARN_VERSION/yarn-v$YARN_VERSION.tar.gz\" \\\n  && curl -fsSLO --compressed \"https://yarnpkg.com/downloads/$YARN_VERSION/yarn-v$YARN_VERSION.tar.gz.asc\" \\\n  && gpg --batch --verify yarn-v$YARN_VERSION.tar.gz.asc yarn-v$YARN_VERSION.tar.gz \\\n  && gpgconf --kill all \\\n  && rm -rf \"$GNUPGHOME\" \\\n  && mkdir -p /opt \\\n  && tar -xzf yarn-v$YARN_VERSION.tar.gz -C /opt/ \\\n  && ln -s /opt/yarn-v$YARN_VERSION/bin/yarn /usr/local/bin/yarn \\\n  && ln -s /opt/yarn-v$YARN_VERSION/bin/yarnpkg /usr/local/bin/yarnpkg \\\n  && rm yarn-v$YARN_VERSION.tar.gz.asc yarn-v$YARN_VERSION.tar.gz \\\n  && apk del .build-deps-yarn \\\n  # smoke test\n  && yarn --version \\\n  && rm -rf /tmp/*\n\nCOPY docker-entrypoint.sh /usr/local/bin/\nENTRYPOINT [\"docker-entrypoint.sh\"]\n\nCMD [ \"node\" ]\n"
        },
        {
          "name": "Dockerfile-debian.template",
          "type": "blob",
          "size": 2.7509765625,
          "content": "FROM buildpack-deps:name\n\nRUN groupadd --gid 1000 node \\\n  && useradd --uid 1000 --gid node --shell /bin/bash --create-home node\n\nENV NODE_VERSION 0.0.0\n\nRUN ARCH= && dpkgArch=\"$(dpkg --print-architecture)\" \\\n  && case \"${dpkgArch##*-}\" in \\\n    amd64) ARCH='x64';; \\\n    ppc64el) ARCH='ppc64le';; \\\n    s390x) ARCH='s390x';; \\\n    arm64) ARCH='arm64';; \\\n    armhf) ARCH='armv7l';; \\\n    i386) ARCH='x86';; \\\n    *) echo \"unsupported architecture\"; exit 1 ;; \\\n  esac \\\n  # use pre-existing gpg directory, see https://github.com/nodejs/docker-node/pull/1895#issuecomment-1550389150\n  && export GNUPGHOME=\"$(mktemp -d)\" \\\n  # gpg keys listed at https://github.com/nodejs/node#release-keys\n  && set -ex \\\n  && for key in \\\n    \"${NODE_KEYS[@]}\"\n  ; do \\\n      gpg --batch --keyserver hkps://keys.openpgp.org --recv-keys \"$key\" || \\\n      gpg --batch --keyserver keyserver.ubuntu.com --recv-keys \"$key\" ; \\\n  done \\\n  && curl -fsSLO --compressed \"https://nodejs.org/dist/v$NODE_VERSION/node-v$NODE_VERSION-linux-$ARCH.tar.xz\" \\\n  && curl -fsSLO --compressed \"https://nodejs.org/dist/v$NODE_VERSION/SHASUMS256.txt.asc\" \\\n  && gpg --batch --decrypt --output SHASUMS256.txt SHASUMS256.txt.asc \\\n  && gpgconf --kill all \\\n  && rm -rf \"$GNUPGHOME\" \\\n  && grep \" node-v$NODE_VERSION-linux-$ARCH.tar.xz\\$\" SHASUMS256.txt | sha256sum -c - \\\n  && tar -xJf \"node-v$NODE_VERSION-linux-$ARCH.tar.xz\" -C /usr/local --strip-components=1 --no-same-owner \\\n  && rm \"node-v$NODE_VERSION-linux-$ARCH.tar.xz\" SHASUMS256.txt.asc SHASUMS256.txt \\\n  && ln -s /usr/local/bin/node /usr/local/bin/nodejs \\\n  # smoke tests\n  && node --version \\\n  && npm --version\n\nENV YARN_VERSION 0.0.0\n\nRUN set -ex \\\n  # use pre-existing gpg directory, see https://github.com/nodejs/docker-node/pull/1895#issuecomment-1550389150\n  && export GNUPGHOME=\"$(mktemp -d)\" \\\n  && for key in \\\n    \"${YARN_KEYS[@]}\"\n  ; do \\\n    gpg --batch --keyserver hkps://keys.openpgp.org --recv-keys \"$key\" || \\\n    gpg --batch --keyserver keyserver.ubuntu.com --recv-keys \"$key\" ; \\\n  done \\\n  && curl -fsSLO --compressed \"https://yarnpkg.com/downloads/$YARN_VERSION/yarn-v$YARN_VERSION.tar.gz\" \\\n  && curl -fsSLO --compressed \"https://yarnpkg.com/downloads/$YARN_VERSION/yarn-v$YARN_VERSION.tar.gz.asc\" \\\n  && gpg --batch --verify yarn-v$YARN_VERSION.tar.gz.asc yarn-v$YARN_VERSION.tar.gz \\\n  && gpgconf --kill all \\\n  && rm -rf \"$GNUPGHOME\" \\\n  && mkdir -p /opt \\\n  && tar -xzf yarn-v$YARN_VERSION.tar.gz -C /opt/ \\\n  && ln -s /opt/yarn-v$YARN_VERSION/bin/yarn /usr/local/bin/yarn \\\n  && ln -s /opt/yarn-v$YARN_VERSION/bin/yarnpkg /usr/local/bin/yarnpkg \\\n  && rm yarn-v$YARN_VERSION.tar.gz.asc yarn-v$YARN_VERSION.tar.gz \\\n  # smoke test\n  && yarn --version \\\n  && rm -rf /tmp/*\n\nCOPY docker-entrypoint.sh /usr/local/bin/\nENTRYPOINT [\"docker-entrypoint.sh\"]\n\nCMD [ \"node\" ]\n"
        },
        {
          "name": "Dockerfile-slim.template",
          "type": "blob",
          "size": 4.5068359375,
          "content": "FROM debian:name-slim\n\nRUN groupadd --gid 1000 node \\\n  && useradd --uid 1000 --gid node --shell /bin/bash --create-home node\n\nENV NODE_VERSION 0.0.0\n\nRUN ARCH= OPENSSL_ARCH= && dpkgArch=\"$(dpkg --print-architecture)\" \\\n    && case \"${dpkgArch##*-}\" in \\\n      amd64) ARCH='x64' OPENSSL_ARCH='linux-x86_64';; \\\n      ppc64el) ARCH='ppc64le' OPENSSL_ARCH='linux-ppc64le';; \\\n      s390x) ARCH='s390x' OPENSSL_ARCH='linux*-s390x';; \\\n      arm64) ARCH='arm64' OPENSSL_ARCH='linux-aarch64';; \\\n      armhf) ARCH='armv7l' OPENSSL_ARCH='linux-armv4';; \\\n      i386) ARCH='x86' OPENSSL_ARCH='linux-elf';; \\\n      *) echo \"unsupported architecture\"; exit 1 ;; \\\n    esac \\\n    && set -ex \\\n    # libatomic1 for arm\n    && apt-get update && apt-get install -y ca-certificates curl wget gnupg dirmngr xz-utils libatomic1 --no-install-recommends \\\n    && rm -rf /var/lib/apt/lists/* \\\n    # use pre-existing gpg directory, see https://github.com/nodejs/docker-node/pull/1895#issuecomment-1550389150\n    && export GNUPGHOME=\"$(mktemp -d)\" \\\n    # gpg keys listed at https://github.com/nodejs/node#release-keys\n    && for key in \\\n      \"${NODE_KEYS[@]}\"\n    ; do \\\n      gpg --batch --keyserver hkps://keys.openpgp.org --recv-keys \"$key\" || \\\n      gpg --batch --keyserver keyserver.ubuntu.com --recv-keys \"$key\" ; \\\n    done \\\n    && curl -fsSLO --compressed \"https://nodejs.org/dist/v$NODE_VERSION/node-v$NODE_VERSION-linux-$ARCH.tar.xz\" \\\n    && curl -fsSLO --compressed \"https://nodejs.org/dist/v$NODE_VERSION/SHASUMS256.txt.asc\" \\\n    && gpg --batch --decrypt --output SHASUMS256.txt SHASUMS256.txt.asc \\\n    && gpgconf --kill all \\\n    && rm -rf \"$GNUPGHOME\" \\\n    && grep \" node-v$NODE_VERSION-linux-$ARCH.tar.xz\\$\" SHASUMS256.txt | sha256sum -c - \\\n    && tar -xJf \"node-v$NODE_VERSION-linux-$ARCH.tar.xz\" -C /usr/local --strip-components=1 --no-same-owner \\\n    && rm \"node-v$NODE_VERSION-linux-$ARCH.tar.xz\" SHASUMS256.txt.asc SHASUMS256.txt \\\n    # Remove unused OpenSSL headers to save ~34MB. See this NodeJS issue: https://github.com/nodejs/node/issues/46451\n    && find /usr/local/include/node/openssl/archs -mindepth 1 -maxdepth 1 ! -name \"$OPENSSL_ARCH\" -exec rm -rf {} \\; \\\n    && apt-mark auto '.*' > /dev/null \\\n    && find /usr/local -type f -executable -exec ldd '{}' ';' \\\n      | awk '/=>/ { so = $(NF-1); if (index(so, \"/usr/local/\") == 1) { next }; gsub(\"^/(usr/)?\", \"\", so); print so }' \\\n      | sort -u \\\n      | xargs -r dpkg-query --search \\\n      | cut -d: -f1 \\\n      | sort -u \\\n      | xargs -r apt-mark manual \\\n    && apt-get purge -y --auto-remove -o APT::AutoRemove::RecommendsImportant=false \\\n    && ln -s /usr/local/bin/node /usr/local/bin/nodejs \\\n    # smoke tests\n    && node --version \\\n    && npm --version\n\nENV YARN_VERSION 0.0.0\n\nRUN set -ex \\\n  && savedAptMark=\"$(apt-mark showmanual)\" \\\n  && apt-get update && apt-get install -y ca-certificates curl wget gnupg dirmngr --no-install-recommends \\\n  && rm -rf /var/lib/apt/lists/* \\\n  # use pre-existing gpg directory, see https://github.com/nodejs/docker-node/pull/1895#issuecomment-1550389150\n  && export GNUPGHOME=\"$(mktemp -d)\" \\\n  && for key in \\\n    \"${YARN_KEYS[@]}\"\n  ; do \\\n    gpg --batch --keyserver hkps://keys.openpgp.org --recv-keys \"$key\" || \\\n    gpg --batch --keyserver keyserver.ubuntu.com --recv-keys \"$key\" ; \\\n  done \\\n  && curl -fsSLO --compressed \"https://yarnpkg.com/downloads/$YARN_VERSION/yarn-v$YARN_VERSION.tar.gz\" \\\n  && curl -fsSLO --compressed \"https://yarnpkg.com/downloads/$YARN_VERSION/yarn-v$YARN_VERSION.tar.gz.asc\" \\\n  && gpg --batch --verify yarn-v$YARN_VERSION.tar.gz.asc yarn-v$YARN_VERSION.tar.gz \\\n  && gpgconf --kill all \\\n  && rm -rf \"$GNUPGHOME\" \\\n  && mkdir -p /opt \\\n  && tar -xzf yarn-v$YARN_VERSION.tar.gz -C /opt/ \\\n  && ln -s /opt/yarn-v$YARN_VERSION/bin/yarn /usr/local/bin/yarn \\\n  && ln -s /opt/yarn-v$YARN_VERSION/bin/yarnpkg /usr/local/bin/yarnpkg \\\n  && rm yarn-v$YARN_VERSION.tar.gz.asc yarn-v$YARN_VERSION.tar.gz \\\n  && apt-mark auto '.*' > /dev/null \\\n  && { [ -z \"$savedAptMark\" ] || apt-mark manual $savedAptMark > /dev/null; } \\\n  && find /usr/local -type f -executable -exec ldd '{}' ';' \\\n    | awk '/=>/ { so = $(NF-1); if (index(so, \"/usr/local/\") == 1) { next }; gsub(\"^/(usr/)?\", \"\", so); print so }' \\\n    | sort -u \\\n    | xargs -r dpkg-query --search \\\n    | cut -d: -f1 \\\n    | sort -u \\\n    | xargs -r apt-mark manual \\\n  && apt-get purge -y --auto-remove -o APT::AutoRemove::RecommendsImportant=false \\\n  # smoke test\n  && yarn --version \\\n  && rm -rf /tmp/*\n\nCOPY docker-entrypoint.sh /usr/local/bin/\nENTRYPOINT [\"docker-entrypoint.sh\"]\n\nCMD [ \"node\" ]\n"
        },
        {
          "name": "GOVERNANCE.md",
          "type": "blob",
          "size": 5.984375,
          "content": "# Docker Working Group\n\nThe Node.js Docker project is jointly governed by a Working Group (WG)\nthat is responsible for high-level guidance of the project.\n\nThe WG has final authority over this project including:\n\n* Technical direction\n* Project governance and process (including this policy)\n* Contribution policy\n* GitHub repository hosting\n* Conduct guidelines\n* Maintaining the list of additional Collaborators\n\nFor the current list of WG members, see the project\n[README.md](./README.md#people).\n\n## Collaborators\n\nThe [nodejs/docker-node](https://github.com/nodejs/docker-node) GitHub\nrepository is maintained by the WG and additional Collaborators who\nare added by the WG on an ongoing basis.\n\nIndividuals making significant and valuable contributions are made\nCollaborators and given commit-access to the project.  These\nindividuals are identified by the WG and their addition as\nCollaborators is discussed as a pull request to this project's\n[README.md](./README.md#people).\n\n_Note:_ If you make a significant contribution and are not considered\nfor commit-access log an issue or contact a WG member directly.\n\nModifications of the contents of the\n[nodejs/docker-node](https://github.com/nodejs/docker-node) repository\nare made on a collaborative basis.  Anybody with a GitHub account may\npropose a modification via pull request and it will be considered by\nthe project Collaborators.  All pull requests must be reviewed and\naccepted by a Collaborator with sufficient expertise who is able to\ntake full responsibility for the change.  In the case of pull requests\nproposed by an existing Collaborator, an additional Collaborator is\nrequired for sign-off.  Consensus should be sought if additional\nCollaborators participate and there is disagreement around a\nparticular modification.  See _Consensus Seeking Process_ below for\nfurther detail on the consensus model used for governance.\n\nCollaborators may opt to elevate significant or controversial\nmodifications, or modifications that have not found consensus to the\nWG for discussion by assigning the ***WG-agenda*** label to a pull\nrequest or issue.  The WG should serve as the final arbiter where\nrequired.\n\nFor the current list of Collaborators, see the project\n[README.md](./README.md#people).\n\n## WG Membership\n\nWG seats are not time-limited.  There is no fixed size of the WG.\nHowever, the expected target is between 6 and 12, to ensure adequate\ncoverage of important areas of expertise, balanced with the ability to\nmake decisions efficiently.\n\nThere is no specific set of requirements or qualifications for WG\nmembership beyond these rules.\n\nThe WG may add, or remove, members to and from the WG. A WG member may\nchoose to be removed from the WG by voluntary resignation.\n\nChanges to WG membership should be posted in the\n[nodejs/docker-node](https://github.com/nodejs/docker-node) repository\nas an issue or pull request with the ***WG-agenda*** label followed by\nthe consensus seeking process described below.\n\nNo more than 1/3 of the WG members may be affiliated with the same\nemployer.  If removal or resignation of a WG member, or a change of\nemployment by a WG member, creates a situation where more than 1/3 of\nthe WG membership shares an employer, then the situation must be\nimmediately remedied by the resignation or removal of one or more WG\nmembers affiliated with the over-represented employer(s).\n\n## WG Meetings\n\nThis working group does not meet.  All discussions and decisions\nhappen in the\n[nodejs/docker-node](https://github.com/nodejs/docker-node) repository\nin issues and pull requests.  Items that requires a decision by the\nWG can be flagged with the ***WG-agenda*** label.\n\nWhen an issue is tagged with ***WG-agenda***, the WG may invite\npersons or representatives from certain projects to participate in the\ndiscussion in a non-voting capacity.\n\n## Consensus Seeking Process\n\nThe WG follows a [Consensus\nSeeking](http://en.wikipedia.org/wiki/Consensus-seeking_decision-making)\ndecision-making model.\n\nAll proposed changes to the project must be made in the form of a pull\nrequest to the repository (directly committing to a production branch\nof the repository is not permitted).  The consensus seeking process\nwill then follow via discussion by the WG members on that pull\nrequest.  Changes deemed trivial by WG members may be merged instantly\nby any WG member, without waiting for consensus, so long as they leave\na note explaining the reason for the merge.\n\nWhen an agenda item has appeared to reach a consensus any WG member\nmay ask \"Does anyone object?\" as a final call for dissent from the\nconsensus.\n\nIf an agenda item cannot reach a consensus a WG member can call for a\nclosing vote.  The call for a vote must be seconded by a majority of\nthe WG or else the discussion will continue.  Simple majority wins.\n\n<a id=\"developers-certificate-of-origin\"></a>\n\n## Developer's Certificate of Origin 1.1\n\nBy making a contribution to this project, I certify that:\n\n* (a) The contribution was created in whole or in part by me and I\n  have the right to submit it under the open source license\n  indicated in the file; or\n\n* (b) The contribution is based upon previous work that, to the best\n  of my knowledge, is covered under an appropriate open source\n  license and I have the right under that license to submit that\n  work with modifications, whether created in whole or in part\n  by me, under the same open source license (unless I am\n  permitted to submit under a different license), as indicated\n  in the file; or\n\n* (c) The contribution was provided directly to me by some other\n  person who certified (a), (b) or (c) and I have not modified\n  it.\n\n* (d) I understand and agree that this project and the contribution\n  are public and that a record of the contribution (including all\n  personal information I submit with it, including my sign-off) is\n  maintained indefinitely and may be redistributed consistent with\n  this project or the open source license(s) involved.\n\n## Code of Conduct\n\nThe Node.js Code of Conduct, which applies to this project, can be found at\n<https://github.com/nodejs/admin/blob/master/CODE_OF_CONDUCT.md>.\n"
        },
        {
          "name": "LICENSE",
          "type": "blob",
          "size": 1.0927734375,
          "content": "The MIT License (MIT)\n\nCopyright (c) 2015 Joyent, Inc.\nCopyright (c) 2015 Node.js contributors\n\nPermission is hereby granted, free of charge, to any person obtaining a copy\nof this software and associated documentation files (the \"Software\"), to deal\nin the Software without restriction, including without limitation the rights\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\ncopies of the Software, and to permit persons to whom the Software is\nfurnished to do so, subject to the following conditions:\n\nThe above copyright notice and this permission notice shall be included in all\ncopies or substantial portions of the Software.\n\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\nSOFTWARE.\n"
        },
        {
          "name": "README.md",
          "type": "blob",
          "size": 9.974609375,
          "content": "# Node.js\n\n[![dockeri.co](https://dockerico.blankenship.io/image/node)](https://hub.docker.com/_/node)\n\n[![GitHub issues](https://img.shields.io/github/issues/nodejs/docker-node.svg \"GitHub issues\")](https://github.com/nodejs/docker-node)\n[![GitHub stars](https://img.shields.io/github/stars/nodejs/docker-node.svg \"GitHub stars\")](https://github.com/nodejs/docker-node)\n\nThe official Node.js docker image, made with love by the node community.\n\n<!-- START doctoc generated TOC please keep comment here to allow auto update -->\n<!-- DON'T EDIT THIS SECTION, INSTEAD RE-RUN doctoc TO UPDATE -->\n## Table of Contents\n\n- [What is Node.js?](#what-is-nodejs)\n- [How to use this image](#how-to-use-this-image)\n  - [Create a `Dockerfile` in your Node.js app project](#create-a-dockerfile-in-your-nodejs-app-project)\n  - [Best Practices](#best-practices)\n  - [Run a single Node.js script](#run-a-single-nodejs-script)\n  - [Verbosity](#verbosity)\n    - [Dockerfile](#dockerfile)\n    - [Docker Run](#docker-run)\n    - [NPM run](#npm-run)\n- [Image Variants](#image-variants)\n  - [`node:<version>`](#nodeversion)\n  - [`node:alpine`](#nodealpine)\n  - [`node:bullseye`](#nodebullseye)\n  - [`node:bookworm`](#nodebookworm)\n  - [`node:slim`](#nodeslim)\n- [License](#license)\n- [Supported Docker versions](#supported-docker-versions)\n- [Supported Node.js versions](#supported-nodejs-versions)\n- [Governance and Current Members](#governance-and-current-members)\n  - [Docker Working Group Members](#docker-working-group-members)\n  - [Docker Working Group Collaborators](#docker-working-group-collaborators)\n  - [Emeritus](#emeritus)\n    - [Docker Working Group Members](#docker-working-group-members-1)\n\n<!-- END doctoc generated TOC please keep comment here to allow auto update -->\n\n## What is Node.js?\n\nNode.js is a platform built on Chrome's JavaScript runtime for easily building\nfast, scalable network applications. Node.js uses an event-driven, non-blocking\nI/O model that makes it lightweight and efficient, perfect for data-intensive\nreal-time applications that run across distributed devices.\n\nSee: http://nodejs.org\n\n## How to use this image\n\n### Create a `Dockerfile` in your Node.js app project\n\n```dockerfile\n# specify the node base image with your desired version node:<version>\nFROM node:16\n# replace this with your application's default port\nEXPOSE 8888\n```\n\nYou can then build and run the Docker image:\n\n```console\n$ docker build -t my-nodejs-app .\n$ docker run -it --rm --name my-running-app my-nodejs-app\n```\n\nIf you prefer Docker Compose:\n\n```yml\nversion: \"2\"\nservices:\n  node:\n    image: \"node:8\"\n    user: \"node\"\n    working_dir: /home/node/app\n    environment:\n      - NODE_ENV=production\n    volumes:\n      - ./:/home/node/app\n    expose:\n      - \"8081\"\n    ports: # use if it is necessary to expose the container to the host machine\n      - \"8001:8001\"\n    command: \"npm start\"\n```\n\nYou can then run using Docker Compose:\n\n```console\n$ docker-compose up -d\n```\n\nDocker Compose example mounts your current directory (including node_modules) to the container.\nIt assumes that your application has a file named [`package.json`](https://docs.npmjs.com/files/package.json)\ndefining [start script](https://docs.npmjs.com/misc/scripts#default-values).\n\n### Best Practices\n\nWe have assembled a [Best Practices Guide](./docs/BestPractices.md) for those using these images on a daily basis.\n\n### Run a single Node.js script\n\nFor many simple, single file projects, you may find it inconvenient to write a\ncomplete `Dockerfile`. In such cases, you can run a Node.js script by using the\nNode.js Docker image directly:\n\n```console\n$ docker run -it --rm --name my-running-script -v \"$PWD\":/usr/src/app -w /usr/src/app node:8 node your-daemon-or-script.js\n```\n\n### Verbosity\n\nPrior to 8.7.0 and 6.11.4, the docker images overrode the default npm log\nlevel from `warn` to `info`. However, due to improvements to npm and new Docker\npatterns (e.g. multi-stage builds) the working group reached a [consensus](https://github.com/nodejs/docker-node/issues/528)\nto revert the log level to npm defaults. If you need more verbose output, please\nuse one of the following methods to change the verbosity level.\n\n#### Dockerfile\n\nIf you create your own `Dockerfile` which inherits from the `node` image, you can\nsimply use `ENV` to override `NPM_CONFIG_LOGLEVEL`.\n\n```dockerfile\nFROM node\nENV NPM_CONFIG_LOGLEVEL info\n...\n```\n\n#### Docker Run\n\nIf you run the node image using `docker run`, you can use the `-e` flag to\noverride `NPM_CONFIG_LOGLEVEL`.\n\n```console\n$ docker run -e NPM_CONFIG_LOGLEVEL=info node ...\n```\n\n#### NPM run\n\nIf you are running npm commands, you can use `--loglevel` to control the\nverbosity of the output.\n\n```console\n$ docker run node npm --loglevel=warn ...\n```\n\n## Image Variants\n\nThe `node` images come in many flavors, each designed for a specific use case.\nAll of the images contain pre-installed versions of `node`,\n[`npm`](https://www.npmjs.com/), and [`yarn`](https://yarnpkg.com). For each\nsupported architecture, the supported variants are different. In the file:\n[versions.json](./versions.json), it lists all supported variants for all of\nthe architectures that we support now.\n\n### `node:<version>`\n\nThis is the defacto image. If you are unsure about what your needs are, you\nprobably want to use this one. It is designed to be used both as a throw away\ncontainer (mount your source code and start the container to start your app), as\nwell as the base to build other images off of. This tag is based off of\n[`buildpack-deps`](https://registry.hub.docker.com/_/buildpack-deps/).\n`buildpack-deps` is designed for the average user of docker who has many images\non their system. It, by design, has a large number of extremely common Debian\npackages. This reduces the number of packages that images that derive from it\nneed to install, thus reducing the overall size of all images on your system.\n\n### `node:alpine`\n\nThis image is based on the popular\n[Alpine Linux project](http://alpinelinux.org), available in\n[the `alpine` official image](https://hub.docker.com/_/alpine). Alpine Linux is\nmuch smaller than most distribution base images (~5MB), and thus leads to much\nslimmer images in general.\n\nThis variant is highly recommended when final image size being as small as\npossible is desired. The main caveat to note is that it does use\n[musl libc](http://www.musl-libc.org) instead of\n[glibc and friends](http://www.etalabs.net/compare_libcs.html), so certain\nsoftware might run into issues depending on the depth of their libc\nrequirements. However, most software doesn't have an issue with this, so this\nvariant is usually a very safe choice. See\n[this Hacker News comment thread](https://news.ycombinator.com/item?id=10782897)\nfor more discussion of the issues that might arise and some pro/con comparisons\nof using Alpine-based images.\n\nOne common issue that may arise is a missing shared library required for use of\n`process.dlopen`. To add the missing shared libraries to your image:\n\n- For Alpine v3.18 and earlier, adding the\n[`libc6-compat`](https://pkgs.alpinelinux.org/package/v3.18/main/x86/libc6-compat)\npackage in your Dockerfile is recommended: `apk add --no-cache libc6-compat`\n\n- Starting from Alpine v3.19, you can use the\n[`gcompat`](https://pkgs.alpinelinux.org/package/v3.19/main/x86/gcompat) package\nto add the missing shared libraries: `apk add --no-cache gcompat`\n\nTo minimize image size, it's uncommon for additional related tools\n(such as `git` or `bash`) to be included in Alpine-based images. Using this\nimage as a base, add the things you need in your own Dockerfile\n(see the [`alpine` image description](https://hub.docker.com/_/alpine/) for\nexamples of how to install packages if you are unfamiliar).\n\nTo make the image size even smaller, you can [bundle without npm/yarn](./docs/BestPractices.md#smaller-images-without-npmyarn).\n\n### `node:bullseye`\n\nThis image is based on version 11 of\n[Debian](http://debian.org), available in\n[the `debian` official image](https://hub.docker.com/_/debian).\n\n### `node:bookworm`\n\nThis image is based on version 12 of\n[Debian](http://debian.org), available in\n[the `debian` official image](https://hub.docker.com/_/debian).\n\n### `node:slim`\n\nThis image does not contain the common packages contained in the default tag and\nonly contains the minimal packages needed to run `node`. Unless you are working\nin an environment where *only* the Node.js image will be deployed and you have\nspace constraints, we highly recommend using the default image of this\nrepository.\n\n## License\n\n[License information](https://github.com/nodejs/node/blob/master/LICENSE) for\nthe software contained in this image. [License information](LICENSE) for the\nNode.js Docker project.\n\n## Supported Docker versions\n\nThis image is officially supported on Docker version 1.9.1.\n\nSupport for older versions (down to 1.6) is provided on a best-effort basis.\n\nPlease see [the Docker installation\ndocumentation](https://docs.docker.com/installation/) for details on how to\nupgrade your Docker daemon.\n\n## Supported Node.js versions\n\nThis project will support Node.js versions as still under active support as per the [Node.js release schedule](https://github.com/nodejs/Release).\n\n## Governance and Current Members\n\nThe Node.js Docker Image is governed by the Docker Working Group. See\n[GOVERNANCE.md](GOVERNANCE.md)\nto learn more about the group's structure and [CONTRIBUTING.md](CONTRIBUTING.md) for guidance\nabout the expectations for all contributors to this project.\n\n### Docker Working Group Members\n\n- Hans Kristian Flaatten ([starefossen](https://github.com/starefossen))\n- Hugues Malphettes ([hmalphettes](https://github.com/hmalphettes))\n- John Mitchell ([jlmitch5](https://github.com/jlmitch5))\n\n### Docker Working Group Collaborators\n\n- Mikeal Rogers ([mikeal](https://github.com/mikeal))\n- Laurent Goderre ([LaurentGoderre](https://github.com/LaurentGoderre))\n- Simen Bekkhus ([SimenB](https://github.com/SimenB))\n- Peter Dave Hello ([PeterDaveHello](https://github.com/PeterDaveHello))\n\n### Emeritus\n\n#### Docker Working Group Members\n\n- Christopher Horrell ([chorrell](https://github.com/chorrell))\n- Peter Petrov ([pesho](https://github.com/pesho))\n"
        },
        {
          "name": "SECURITY.md",
          "type": "blob",
          "size": 0.6865234375,
          "content": "# Security Policy\n\n## Reporting a Vulnerability\n\nSecurity issues relating to Node.js project should follow the process documented on <https://nodejs.org/en/security/>.\n\nCVEs for the base image packages should be reported to those repositories. Nothing to address those CVEs is in the hands of this repos.\n\n- [Alpine](https://github.com/alpinelinux/docker-alpine)\n- [Debian (bullseye, bookworm)](https://github.com/debuerreotype/docker-debian-artifacts)\n\nWhen base images are patched, the images are rebuilt and rolled out to the Docker hub without intervention by this repo. This process is explained in <https://github.com/docker-library/faq/#why-does-my-security-scanner-show-that-an-image-has-cves>.\n"
        },
        {
          "name": "architectures",
          "type": "blob",
          "size": 0.4560546875,
          "content": "bashbrew-arch  variants\namd64          alpine3.20,alpine3.21,bookworm,bookworm-slim,bullseye,bullseye-slim\narm32v6        alpine3.20,alpine3.21\narm32v7        alpine3.20,alpine3.21,bookworm,bookworm-slim,bullseye,bullseye-slim\narm64v8        alpine3.20,alpine3.21,bookworm,bookworm-slim,bullseye,bullseye-slim\ni386           alpine3.20,alpine3.21\nppc64le        alpine3.20,alpine3.21,bookworm,bookworm-slim\ns390x          alpine3.20,alpine3.21,bookworm,bookworm-slim\n"
        },
        {
          "name": "build-automation.mjs",
          "type": "blob",
          "size": 4.4306640625,
          "content": "import { promisify } from \"util\";\n\nimport child_process from \"child_process\";\n\nconst exec = promisify(child_process.exec);\n\n// a function that queries the Node.js release website for new versions,\n// compare the available ones with the ones we use in this repo\n// and returns whether we should update or not\nconst checkIfThereAreNewVersions = async (github) => {\n  try {\n    const { stdout: versionsOutput } = await exec(\". ./functions.sh && get_versions\", { shell: \"bash\" });\n\n    const supportedVersions = versionsOutput.trim().split(\" \");\n\n    let latestSupportedVersions = {};\n\n    for (let supportedVersion of supportedVersions) {\n      const { stdout } = await exec(`ls ${supportedVersion}`);\n\n      const { stdout: fullVersionOutput } = await exec(`. ./functions.sh && get_full_version ./${supportedVersion}/${stdout.trim().split(\"\\n\")[0]}`, { shell: \"bash\" });\n\n      console.log(fullVersionOutput);\n\n      latestSupportedVersions[supportedVersion] = { fullVersion: fullVersionOutput.trim() };\n    }\n\n    const { data: availableVersionsJson } = await github.request('https://nodejs.org/download/release/index.json');\n\n    // filter only more recent versions of availableVersionsJson for each major version in latestSupportedVersions' keys\n    // e.g. if latestSupportedVersions = { \"12\": \"12.22.10\", \"14\": \"14.19.0\", \"16\": \"16.14.0\", \"17\": \"17.5.0\" }\n    // and availableVersions = [\"Node.js 12.22.10\", \"Node.js 12.24.0\", \"Node.js 14.19.0\", \"Node.js 14.22.0\", \"Node.js 16.14.0\", \"Node.js 16.16.0\", \"Node.js 17.5.0\", \"Node.js 17.8.0\"]\n    // return { \"12\": \"12.24.0\", \"14\": \"14.22.0\", \"16\": \"16.16.0\", \"17\": \"17.8.0\" }\n\n    let filteredNewerVersions = {};\n\n    for (let availableVersion of availableVersionsJson) {\n      const [availableMajor, availableMinor, availablePatch] = availableVersion.version.split(\"v\")[1].split(\".\");\n      if (latestSupportedVersions[availableMajor] == null) {\n        continue;\n      }\n      const [_latestMajor, latestMinor, latestPatch] = latestSupportedVersions[availableMajor].fullVersion.split(\".\");\n      if (latestSupportedVersions[availableMajor] && (Number(availableMinor) > Number(latestMinor) || (availableMinor === latestMinor && Number(availablePatch) > Number(latestPatch)))) {\n        filteredNewerVersions[availableMajor] = { fullVersion: `${availableMajor}.${availableMinor}.${availablePatch}` };\n      }\n    }\n\n    return {\n      shouldUpdate: Object.keys(filteredNewerVersions).length > 0 && JSON.stringify(filteredNewerVersions) !== JSON.stringify(latestSupportedVersions),\n      versions: filteredNewerVersions,\n    }\n  } catch (error) {\n    console.error(error);\n    process.exit(1);\n  }\n};\n\n// a function that queries the Node.js unofficial release website for new musl versions and security releases,\n// and returns relevant information\nconst checkForMuslVersionsAndSecurityReleases = async (github, versions) => {\n  try {\n    const { data: unofficialBuildsIndexText } = await github.request('https://unofficial-builds.nodejs.org/download/release/index.json');\n\n    for (let version of Object.keys(versions)) {\n      const buildVersion = unofficialBuildsIndexText.find(indexVersion => indexVersion.version === `v${versions[version].fullVersion}`);\n\n      versions[version].muslBuildExists = buildVersion?.files.includes(\"linux-x64-musl\") ?? false;\n      versions[version].isSecurityRelease = buildVersion?.security ?? false;\n    }\n    return versions;\n  } catch (error) {\n    console.error(error);\n    process.exit(1);\n  }\n};\n\nexport default async function(github) {\n// if there are no new versions, exit gracefully\n// if there are new versions,\n// check for musl builds\n// then run update.sh\n  const { shouldUpdate, versions } = await checkIfThereAreNewVersions(github);\n\n  if (!shouldUpdate) {\n    console.log(\"No new versions found. No update required.\");\n    process.exit(0);\n  } else {\n    const newVersions = await checkForMuslVersionsAndSecurityReleases(github, versions);\n    let updatedVersions = [];\n    for (const [version, newVersion] of Object.entries(newVersions)) {\n      if (newVersion.muslBuildExists) {\n        const { stdout } = await exec(`./update.sh ${newVersion.isSecurityRelease ? \"-s \" : \"\"}${version}`);\n        console.log(stdout);\n        updatedVersions.push(newVersion.fullVersion);\n      } else {\n        console.log(`There's no musl build for version ${newVersion.fullVersion} yet.`);\n        process.exit(0);\n      }\n    }\n    const { stdout } = (await exec(`git diff`));\n    console.log(stdout);\n\n    return updatedVersions.join(', ');\n  }\n}\n"
        },
        {
          "name": "config",
          "type": "blob",
          "size": 0.11328125,
          "content": "baseuri     https://nodejs.org/dist\ndefault_variant bookworm\nalpine_version  3.19\ndebian_versions bookworm bullseye\n"
        },
        {
          "name": "docker-entrypoint.sh",
          "type": "blob",
          "size": 0.37890625,
          "content": "#!/bin/sh\nset -e\n\n# Run command with node if the first argument contains a \"-\" or is not a system command. The last\n# part inside the \"{}\" is a workaround for the following bug in ash/dash:\n# https://bugs.debian.org/cgi-bin/bugreport.cgi?bug=874264\nif [ \"${1#-}\" != \"${1}\" ] || [ -z \"$(command -v \"${1}\")\" ] || { [ -f \"${1}\" ] && ! [ -x \"${1}\" ]; }; then\n  set -- node \"$@\"\nfi\n\nexec \"$@\"\n"
        },
        {
          "name": "docs",
          "type": "tree",
          "content": null
        },
        {
          "name": "functions.sh",
          "type": "blob",
          "size": 7.6298828125,
          "content": "#!/usr/bin/env bash\n#\n# Utlity functions\n# Don't change this file unless needed\n# The GitHub Action for automating new builds rely on this file\n\ninfo() {\n  printf \"%s\\\\n\" \"$@\"\n}\n\nfatal() {\n  printf \"**********\\\\n\"\n  printf \"Fatal Error: %s\\\\n\" \"$@\"\n  printf \"**********\\\\n\"\n  exit 1\n}\n\n# Get system architecture\n#\n# This is used to get the target architecture for docker image.\n# For crossing building, we need a way to specify the target\n# architecutre manually.\nfunction get_arch() {\n  local arch\n  case $(uname -m) in\n    x86_64)\n      arch=\"amd64\"\n      ;;\n    ppc64le)\n      arch=\"ppc64le\"\n      ;;\n    s390x)\n      arch=\"s390x\"\n      ;;\n    aarch64 | arm64)\n      arch=\"arm64\"\n      ;;\n    armv7l)\n      arch=\"arm32v7\"\n      ;;\n    *)\n      echo \"$0 does not support architecture ${arch:-unknown} ... aborting\"\n      exit 1\n      ;;\n  esac\n\n  echo \"${arch}\"\n}\n\n# Get corresponding variants based on the architecture.\n# All supported variants of each supported architecture are listed in a\n# file - 'architectures'. Its format is:\n#   <architecture 1> <supported variant 1 >,<supported variant 2>...\n#   <architecture 2> <supported variant 1 >,<supported variant 2>...\nfunction get_variants() {\n  local dir\n  dir=${1:-.}\n  shift\n\n  local arch\n  local availablevariants\n  local variantsfilter\n  local variants=()\n\n  arch=$(get_arch)\n  variantsfilter=(\"$@\")\n  IFS=' ' read -ra availablevariants <<< \"$(grep \"^${arch}\" \"${dir}/architectures\" | sed -E 's/'\"${arch}\"'[[:space:]]*//' | sed -E 's/,/ /g')\"\n\n  if [ ${#variantsfilter[@]} -gt 0 ]; then\n    for variant1 in \"${availablevariants[@]}\"; do\n      for variant2 in \"${variantsfilter[@]}\"; do\n        if [ \"${variant1}\" = \"${variant2}\" ]; then\n          variants+=(\"${variant1}\")\n        fi\n      done\n    done\n\n    if [ ${#variants[@]} -gt 0 ]; then\n      echo \"${variants[@]}\"\n    fi\n  else\n    echo \"${availablevariants[@]}\"\n  fi\n}\n\n# Get supported architectures for a specific version and variant\n#\n# Get default supported architectures from 'architectures'. Then go to the version folder\n# to see if there is a local architectures file. The local architectures will override the\n# default architectures. This will give us some benefits:\n# - a specific version may or may not support some architectures\n# - if there is no specialization for a version, just don't provide local architectures\nfunction get_supported_arches() {\n  local version\n  local variant\n  local arches\n  local lines\n  local line\n  version=\"$1\"\n  shift\n  variant=\"$1\"\n  shift\n\n  # Get default supported arches\n  lines=$(grep \"${variant}\" \"$(dirname \"${version}\")\"/architectures 2> /dev/null | cut -d' ' -f1)\n\n  # Get version specific supported architectures if there is specialized information\n  if [ -a \"${version}\"/architectures ]; then\n    lines=$(grep \"${variant}\" \"${version}\"/architectures 2> /dev/null | cut -d' ' -f1)\n  fi\n\n  while IFS='' read -r line; do\n    arches+=(\"${line}\")\n  done <<< \"${lines}\"\n\n  echo \"${arches[@]}\"\n}\n\n# Get configuration values from the config file\n#\n# The configuration entries are simple key/value pairs which are whitespace separated.\nfunction get_config() {\n  local dir\n  dir=${1:-.}\n  shift\n\n  local name\n  name=${1}\n  shift\n\n  local value\n  value=$(grep \"^${name}\" \"${dir}/config\" | sed -E 's/'\"${name}\"'[[:space:]]*//')\n  echo \"${value}\"\n}\n\n# Get available versions for a given path\n#\n# The result is a list of valid versions.\n# shellcheck disable=SC2120\nfunction get_versions() {\n  shift\n\n  local versions=()\n  local dirs=(\"$@\")\n\n  local default_variant\n  default_variant=$(get_config \"./\" \"default_variant\")\n  if [ ${#dirs[@]} -eq 0 ]; then\n    IFS=' ' read -ra dirs <<< \"$(echo \"./\"*/)\"\n  fi\n\n  for dir in \"${dirs[@]}\"; do\n    if [ -a \"${dir}/Dockerfile\" ] || [ -a \"${dir}/${default_variant}/Dockerfile\" ]; then\n      versions+=(\"${dir#./}\")\n    fi\n  done\n\n  if [ ${#versions[@]} -gt 0 ]; then\n    echo \"${versions[@]%/}\"\n  fi\n}\n\nfunction is_alpine() {\n  local variant\n  variant=${1}\n  shift\n\n  if [ \"${variant}\" = \"${variant#alpine}\" ]; then\n    return 1\n  fi\n}\n\nfunction is_debian() {\n  local variant\n  variant=$1\n  shift\n\n  IFS=' ' read -ra debianVersions <<< \"$(get_config \"./\" \"debian_versions\")\"\n  for d in \"${debianVersions[@]}\"; do\n    if [ \"${d}\" = \"${variant}\" ]; then\n      return 0\n    fi\n  done\n  return 1\n}\n\nfunction is_debian_slim() {\n  local variant\n  variant=$1\n  shift\n\n  IFS=' ' read -ra debianVersions <<< \"$(get_config \"./\" \"debian_versions\")\"\n  for d in \"${debianVersions[@]}\"; do\n    if [ \"${d}-slim\" = \"${variant}\" ]; then\n      return 0\n    fi\n  done\n  return 1\n}\n\nfunction get_fork_name() {\n  local version\n  version=$1\n  shift\n\n  IFS='/' read -ra versionparts <<< \"${version}\"\n  if [ ${#versionparts[@]} -gt 1 ]; then\n    echo \"${versionparts[0]}\"\n  fi\n}\n\nfunction get_full_tag() {\n  local variant\n  local tag\n  local full_tag\n  variant=\"$1\"\n  shift\n  tag=\"$1\"\n  shift\n  if [ -z \"${variant}\" ]; then\n    full_tag=\"${tag}\"\n  elif [ \"${variant}\" = \"default\" ]; then\n    full_tag=\"${tag}\"\n  else\n    full_tag=\"${tag}-${variant}\"\n  fi\n  echo \"${full_tag}\"\n}\n\nfunction get_full_version() {\n  local version\n  version=$1\n  shift\n\n  local default_dockerfile\n  if [ -f \"${version}/${default_variant}/Dockerfile\" ]; then\n    default_dockerfile=\"${version}/${default_variant}/Dockerfile\"\n  else\n    default_dockerfile=\"${version}/Dockerfile\"\n  fi\n\n  grep -m1 'ENV NODE_VERSION ' \"${default_dockerfile}\" | cut -d' ' -f3\n}\n\nfunction get_major_minor_version() {\n  local version\n  version=$1\n  shift\n\n  local fullversion\n  fullversion=$(get_full_version \"${version}\")\n\n  echo \"$(echo \"${fullversion}\" | cut -d'.' -f1).$(echo \"${fullversion}\" | cut -d'.' -f2)\"\n}\n\nfunction get_path() {\n  local version\n  local variant\n  local path\n  version=\"$1\"\n  shift\n  variant=\"$1\"\n  shift\n\n  if [ -z \"${variant}\" ]; then\n    path=\"${version}/${variant}\"\n  elif [ \"${variant}\" = \"default\" ]; then\n    path=\"${version}\"\n  else\n    path=\"${version}/${variant}\"\n  fi\n  echo \"${path}\"\n}\n\nfunction get_tag() {\n  local version\n  version=$1\n  shift\n\n  local versiontype\n  versiontype=${1:-full}\n  shift\n\n  local tagversion\n  if [ \"${versiontype}\" = full ]; then\n    tagversion=$(get_full_version \"${version}\")\n  elif [ \"${versiontype}\" = majorminor ]; then\n    tagversion=$(get_major_minor_version \"${version}\")\n  fi\n\n  local tagparts\n  IFS=' ' read -ra tagparts <<< \"$(get_fork_name \"${version}\") ${tagversion}\"\n  IFS='-'\n  echo \"${tagparts[*]}\"\n  unset IFS\n}\n\nfunction sort_versions() {\n  local versions=(\"$@\")\n  local sorted\n  local lines\n  local line\n\n  IFS=$'\\n'\n  lines=\"${versions[*]}\"\n  unset IFS\n\n  while IFS='' read -r line; do\n    sorted+=(\"${line}\")\n  done <<< \"$(echo \"${lines}\" | grep \"^[0-9]\" | sort -r)\"\n\n  while IFS='' read -r line; do\n    sorted+=(\"${line}\")\n  done <<< \"$(echo \"${lines}\" | grep -v \"^[0-9]\" | sort -r)\"\n\n  echo \"${sorted[@]}\"\n}\n\nfunction commit_range() {\n  local commit_id_end=${1}\n  shift\n  local commit_id_start=${1}\n\n  if [ -z \"${commit_id_start}\" ]; then\n    if [ -z \"${commit_id_end}\" ]; then\n      echo \"HEAD~1..HEAD\"\n    elif [[ \"${commit_id_end}\" =~ .. ]]; then\n      echo \"${commit_id_end}\"\n    else\n      echo \"${commit_id_end}~1..${commit_id_end}\"\n    fi\n  else\n    echo \"${commit_id_end}..${commit_id_start}\"\n  fi\n}\n\nfunction images_updated() {\n  local commit_range\n  local versions\n  local images_changed\n\n  commit_range=\"$(commit_range \"$@\")\"\n\n  IFS=' ' read -ra versions <<< \"$(\n    IFS=','\n    get_versions\n  )\"\n  images_changed=$(git diff --name-only \"${commit_range}\" \"${versions[@]}\")\n\n  if [ -z \"${images_changed}\" ]; then\n    return 1\n  fi\n  return 0\n}\n\nfunction tests_updated() {\n  local commit_range\n  local test_changed\n\n  commit_range=\"$(commit_range \"$@\")\"\n\n  test_changed=$(git diff --name-only \"${commit_range}\" test*)\n\n  if [ -z \"${test_changed}\" ]; then\n    return 1\n  fi\n  return 0\n}\n"
        },
        {
          "name": "genMatrix.js",
          "type": "blob",
          "size": 2.4560546875,
          "content": "'use strict';\nconst path = require('path');\nconst fs = require('fs');\n\nconst testFiles = [\n  'genMatrix.js',\n  '.github/workflows/build-test.yml',\n];\n\nconst nodeDirRegex = /^\\d+$/;\n\nconst areTestFilesChanged = (changedFiles) => changedFiles\n  .some((file) => testFiles.includes(file));\n\n// Returns a list of the child directories in the given path\nconst getChildDirectories = (parent) => fs.readdirSync(parent, { withFileTypes: true })\n  .filter((dirent) => dirent.isDirectory())\n  .map(({ name }) => path.resolve(parent, name));\n\nconst getNodeVerionDirs = (base) => getChildDirectories(base)\n  .filter((childPath) => nodeDirRegex.test(path.basename(childPath)));\n\n// Returns the paths of Dockerfiles that are at: base/*/Dockerfile\nconst getDockerfilesInChildDirs = (base) => getChildDirectories(base)\n  .map((childDir) => path.resolve(childDir, 'Dockerfile'));\n\nconst getAllDockerfiles = (base) => getNodeVerionDirs(base).flatMap(getDockerfilesInChildDirs);\n\nconst getAffectedDockerfiles = (filesAdded, filesModified, filesRenamed) => {\n  const files = [\n    ...filesAdded,\n    ...filesModified,\n    ...filesRenamed,\n  ];\n\n  // If the test files were changed, include everything\n  if (areTestFilesChanged(files)) {\n    console.log('Test files changed so scheduling all Dockerfiles');\n    return getAllDockerfiles(__dirname);\n  }\n\n  const modifiedDockerfiles = files.filter((file) => file.endsWith('/Dockerfile'));\n\n  // Get Dockerfiles affected by modified docker-entrypoint.sh files\n  const entrypointAffectedDockerfiles = files\n    .filter((file) => file.endsWith('/docker-entrypoint.sh'))\n    .map((file) => path.resolve(path.dirname(file), 'Dockerfile'));\n\n  return [\n    ...modifiedDockerfiles,\n    ...entrypointAffectedDockerfiles,\n  ];\n};\n\nconst getFullNodeVersionFromDockerfile = (file) => fs.readFileSync(file, 'utf8')\n  .match(/^ENV NODE_VERSION (\\d*\\.*\\d*\\.\\d*)/m)[1];\n\nconst getDockerfileMatrixEntry = (file) => {\n  const [variant] = path.dirname(file).split(path.sep).slice(-1);\n\n  const version = getFullNodeVersionFromDockerfile(file);\n\n  return {\n    version,\n    variant,\n  };\n};\n\nconst generateBuildMatrix = (filesAdded, filesModified, filesRenamed) => {\n  const dockerfiles = [...new Set(getAffectedDockerfiles(filesAdded, filesModified, filesRenamed))];\n\n  const entries = dockerfiles.map(getDockerfileMatrixEntry);\n\n  // Return null if there are no entries so we can skip the matrix step\n  return entries.length\n    ? { include: entries }\n    : null;\n};\n\nmodule.exports = generateBuildMatrix;\n"
        },
        {
          "name": "keys",
          "type": "tree",
          "content": null
        },
        {
          "name": "markdown_link_check_config.json",
          "type": "blob",
          "size": 0.16796875,
          "content": "{\n  \"httpHeaders\": [\n    {\n      \"urls\": [\n        \"https://docs.github.com\"\n      ],\n      \"headers\": {\n        \"Accept-Encoding\": \"br, gzip, deflate\"\n      }\n    }\n  ]\n}\n"
        },
        {
          "name": "stackbrew.js",
          "type": "blob",
          "size": 5.2099609375,
          "content": "#!/usr/bin/env node\n\nconst fs = require('fs');\nconst path = require('path');\n\n// Grab last git commit\nfunction getCommitHasForPath(path) {\n  return require('child_process')\n  .execSync(`git log -1 --format=%H HEAD -- ${path}`)\n  .toString().trim()\n}\n\nconst stackbrewPath = path.basename(__filename);\n\n// Header\nlet stackbrew = `# this file is generated via https://github.com/nodejs/docker-node/blob/${getCommitHasForPath(stackbrewPath)}/${stackbrewPath}\n\nMaintainers: The Node.js Docker Team <https://github.com/nodejs/docker-node> (@nodejs)\nGitRepo: https://github.com/nodejs/docker-node.git\nGitFetch: refs/heads/main\\n`;\n\n// Loop versions\n\nconst config = require('./versions.json');\n\nconst versions = Object.keys(config).reverse()\n\nlet midnight = new Date()\nmidnight.setHours(0, 0, 0, 0)\nconst now = midnight.getTime()\nconst aplineRE = new RegExp(/alpine*/);\nconst slimRE = new RegExp(/\\*-slim/);\nlet foundLTS = false;\nlet foundCurrent = false;\n\nfor (version of versions) {\n  let lts = new Date(`${config[version].lts}T00:00:00.00`).getTime();\n  let maintenance = new Date(`${config[version].maintenance}T00:00:00.00`).getTime();\n  let isCurrent = foundCurrent ? false : isNaN(lts) || lts >= now;\n  foundCurrent = isCurrent || foundCurrent;\n  let isLTS = foundLTS ? false : (now >= lts);\n  foundLTS = isLTS || foundLTS;\n  let codename = config[version].codename\n  let defaultAlpine = config[version]['alpine-default']\n  let defaultDebian = config[version]['debian-default']\n  let variants = config[version].variants\n  let fullversion;\n  for (variant in variants) {\n    let dockerfilePath = path.join(version, variant, 'Dockerfile');\n    let isAlpine = aplineRE.test(variant)\n    let isSlim = slimRE.test(variant)\n    let isDefaultSlim = new RegExp(`${defaultDebian}-slim`).test(variant)\n\n    // Get full version from the first Dockerfile\n    if (!fullversion) {\n      let dockerfile = fs.readFileSync(dockerfilePath, 'utf-8')\n      fullversion = dockerfile.match(/ENV NODE_VERSION (?<major>\\d+)\\.(?<minor>\\d+)\\.(?<patch>\\d+)/)\n    }\n    let tags = [\n      `${fullversion.groups.major}.${fullversion.groups.minor}.${fullversion.groups.patch}-${variant}`,\n      `${fullversion.groups.major}.${fullversion.groups.minor}-${variant}`,\n      `${fullversion.groups.major}-${variant}`,\n    ]\n\n    if (codename) {\n      tags.push(`${codename}-${variant}`)\n    }\n\n    if (variant === defaultAlpine) {\n      tags.push(`${fullversion.groups.major}.${fullversion.groups.minor}.${fullversion.groups.patch}-alpine`)\n      tags.push(`${fullversion.groups.major}.${fullversion.groups.minor}-alpine`)\n      tags.push(`${fullversion.groups.major}-alpine`)\n      if (codename) {\n        tags.push(`${codename}-alpine`)\n      }\n    }\n\n    if (variant === defaultDebian) {\n      tags.push(`${fullversion.groups.major}.${fullversion.groups.minor}.${fullversion.groups.patch}`)\n      tags.push(`${fullversion.groups.major}.${fullversion.groups.minor}`)\n      tags.push(`${fullversion.groups.major}`)\n      if (isSlim) {\n        tags.push(`${fullversion.groups.major}.${fullversion.groups.minor}.${fullversion.groups.patch}-slim`)\n        tags.push(`${fullversion.groups.major}.${fullversion.groups.minor}-slim`)\n        tags.push(`${fullversion.groups.major}-slim`)\n      }\n      if (codename) {\n        tags.push(`${codename}`)\n      }\n    }\n    if (isDefaultSlim) {\n      tags.push(`${fullversion.groups.major}.${fullversion.groups.minor}.${fullversion.groups.patch}-slim`)\n      tags.push(`${fullversion.groups.major}.${fullversion.groups.minor}-slim`)\n      tags.push(`${fullversion.groups.major}-slim`)\n      if (codename) {\n        tags.push(`${codename}-slim`)\n      }\n    }\n\n    if (isCurrent) {\n      if (variant === defaultAlpine) {\n        tags.push(variant)\n        tags.push(`${fullversion.groups.major}.${fullversion.groups.minor}.${fullversion.groups.patch}-alpine`)\n        tags.push(`${fullversion.groups.major}.${fullversion.groups.minor}-alpine`)\n        tags.push(`${fullversion.groups.major}-alpine`)\n        tags.push('alpine')\n        tags.push('current-alpine')\n      }\n      if (variant === defaultDebian) {\n        tags.push(variant)\n        tags.push('latest')\n        tags.push('current')\n      }\n      if (isAlpine) {\n        tags.push(`${variant}`)\n        tags.push(`current-${variant}`)\n      }\n      if (!isAlpine) {\n        tags.push(`${variant}`)\n        tags.push(`current-${variant}`)\n      }\n      if (isDefaultSlim) {\n        tags.push('slim')\n        tags.push('current-slim')\n      }\n    }\n\n    if (isLTS) {\n      tags.push(`lts-${variant}`)\n      if (variant === defaultAlpine) {\n      }\n      if (variant === defaultDebian) {\n        tags.push('lts')\n        if (codename) {\n          tags.push(`lts-${codename}`)\n        }\n      }\n      if (isDefaultSlim) {\n        tags.push(`lts-slim`)\n      }\n      if (variant === defaultAlpine) {\n        tags.push(`lts-alpine`)\n      }\n    }\n\n    // remove duplicates\n    tags = tags.filter((x, i, a) => a.indexOf(x) == i)\n    tags = tags.sort()\n    let directory = `${version}/${variant}`\n    stackbrew += `\\nTags: ${tags.join(', ')}\\n`\n    stackbrew += `Architectures: ${config[version].variants[variant].join(', ')}\\n`\n    stackbrew += `GitCommit: ${getCommitHasForPath(directory)}\\n`\n    stackbrew += `Directory: ${directory}\\n`\n  }\n}\n\n// output\nconsole.log(stackbrew)\n"
        },
        {
          "name": "update-keys.sh",
          "type": "blob",
          "size": 0.1865234375,
          "content": "#!/bin/sh -ex\n\ncurl -fsSLo- --compressed https://github.com/nodejs/node/raw/main/README.md | awk '/--recv-keys.*#/{ gsub(/^.*--recv-keys\\s+/,\"\");gsub(/\\s+#.*$/,\"\"); print }' > keys/node.keys\n"
        },
        {
          "name": "update.sh",
          "type": "blob",
          "size": 6.9443359375,
          "content": "#!/usr/bin/env bash\n\nset -ue\n\nfunction usage() {\n  cat << EOF\n\n  Update the node docker images.\n\n  Usage:\n    $0 [-s] [MAJOR_VERSION(S)] [VARIANT(S)]\n\n  Examples:\n    - update.sh                      # Update all images\n    - update.sh -s                   # Update all images, skip updating Alpine and Yarn\n    - update.sh 8,10                 # Update all variants of version 8 and 10\n    - update.sh -s 8                 # Update version 8 and variants, skip updating Alpine and Yarn\n    - update.sh 8 alpine             # Update only alpine's variants for version 8\n    - update.sh -s 8 bullseye        # Update only bullseye variant for version 8, skip updating Alpine and Yarn\n    - update.sh . alpine             # Update the alpine variant for all versions\n\n  OPTIONS:\n    -s Security update; skip updating the yarn and alpine versions.\n    -b CI config update only\n    -h Show this message\n\nEOF\n}\n\nSKIP=false\nwhile getopts \"sh\" opt; do\n  case \"${opt}\" in\n    s)\n      SKIP=true\n      shift\n      ;;\n    h)\n      usage\n      exit\n      ;;\n    \\?)\n      usage\n      exit\n      ;;\n  esac\ndone\n\n. functions.sh\n\ncd \"$(cd \"${0%/*}\" && pwd -P)\"\n\nIFS=',' read -ra versions_arg <<< \"${1:-}\"\nIFS=',' read -ra variant_arg <<< \"${2:-}\"\n\nIFS=' ' read -ra versions <<< \"$(get_versions .)\"\nIFS=' ' read -ra update_versions <<< \"$(get_versions . \"${versions_arg[@]:-}\")\"\nIFS=' ' read -ra update_variants <<< \"$(get_variants . \"${variant_arg[@]:-}\")\"\nif [ ${#versions[@]} -eq 0 ]; then\n  fatal \"No valid versions found!\"\nfi\n\n# Global variables\n# Get architecure and use this as target architecture for docker image\n# See details in function.sh\n# TODO: Should be able to specify target architecture manually\narch=$(get_arch)\n\nif [ \"${SKIP}\" != true ]; then\n  alpine_version=$(get_config \"./\" \"alpine_version\")\n  yarnVersion=\"$(curl -sSL --compressed https://yarnpkg.com/latest-version)\"\nfi\n\nfunction in_versions_to_update() {\n  local version=$1\n\n  if [ \"${#update_versions[@]}\" -eq 0 ]; then\n    echo 0\n    return\n  fi\n\n  for version_to_update in \"${update_versions[@]}\"; do\n    if [ \"${version_to_update}\" = \"${version}\" ]; then\n      echo 0\n      return\n    fi\n  done\n\n  echo 1\n}\n\nfunction in_variants_to_update() {\n  local variant=$1\n\n  if [ \"${#update_variants[@]}\" -eq 0 ]; then\n    echo 0\n    return\n  fi\n\n  for variant_to_update in \"${update_variants[@]}\"; do\n    if [ \"${variant_to_update}\" = \"${variant}\" ]; then\n      echo 0\n      return\n    fi\n  done\n\n  echo 1\n}\n\nfunction update_node_version() {\n\n  local baseuri=${1}\n  shift\n  local version=${1}\n  shift\n  local template=${1}\n  shift\n  local dockerfile=${1}\n  shift\n  local variant=\"\"\n  if [ $# -eq 1 ]; then\n    variant=${1}\n    shift\n  fi\n\n  fullVersion=\"$(curl -sSL --compressed \"${baseuri}\" | grep '<a href=\"v'\"${version}.\" | sed -E 's!.*<a href=\"v([^\"/]+)/?\".*!\\1!' | cut -d'.' -f2,3 | sort -V | tail -1)\"\n  (\n    cp \"${template}\" \"${dockerfile}-tmp\"\n    local fromprefix=\"\"\n    if [ \"${arch}\" != \"amd64\" ] && [ \"${arch}\" != \"arm64\" ]; then\n      fromprefix=\"${arch}\\\\/\"\n    fi\n\n    nodeVersion=\"${version}.${fullVersion:-0}\"\n\n    sed -Ei -e 's/^FROM (.*)/FROM '\"$fromprefix\"'\\1/' \"${dockerfile}-tmp\"\n    sed -Ei -e 's/^(ENV NODE_VERSION ).*/\\1'\"${nodeVersion}\"'/' \"${dockerfile}-tmp\"\n\n    currentYarnVersion=\"$(grep \"ENV YARN_VERSION\" \"${dockerfile}\" | cut -d' ' -f3)\"\n    sed -Ei -e 's/^(ENV YARN_VERSION ).*/\\1'\"${currentYarnVersion}\"'/' \"${dockerfile}-tmp\"\n\n    # shellcheck disable=SC1004\n    new_line=' \\\\\\\n'\n\n    # Add GPG keys\n    for key_type in \"node\" \"yarn\"; do\n      while read -r line; do\n        pattern='\"\\$\\{'$(echo \"${key_type}\" | tr '[:lower:]' '[:upper:]')'_KEYS\\[@\\]\\}\"'\n        sed -Ei -e \"s/([ \\\\t]*)(${pattern})/\\\\1${line}${new_line}\\\\1\\\\2/\" \"${dockerfile}-tmp\"\n      done < \"keys/${key_type}.keys\"\n      sed -Ei -e \"/${pattern}/d\" \"${dockerfile}-tmp\"\n    done\n\n    if is_alpine \"${variant}\"; then\n      alpine_version=\"${variant#*alpine}\"\n      checksum=$(\n        curl -sSL --compressed \"https://unofficial-builds.nodejs.org/download/release/v${nodeVersion}/SHASUMS256.txt\" | grep \"node-v${nodeVersion}-linux-x64-musl.tar.xz\" | cut -d' ' -f1\n      )\n      if [ -z \"$checksum\" ]; then\n        rm -f \"${dockerfile}-tmp\"\n        fatal \"Failed to fetch checksum for version ${nodeVersion}\"\n      fi\n      sed -Ei -e \"s/(alpine:)0.0/\\\\1${alpine_version}/\" \"${dockerfile}-tmp\"\n      sed -Ei -e \"s/CHECKSUM=CHECKSUM_x64/CHECKSUM=\\\"${checksum}\\\"/\" \"${dockerfile}-tmp\"\n\n    elif is_debian \"${variant}\"; then\n      sed -Ei -e \"s/(buildpack-deps:)name/\\\\1${variant}/\" \"${dockerfile}-tmp\"\n    elif is_debian_slim \"${variant}\"; then\n      sed -Ei -e \"s/(debian:)name-slim/\\\\1${variant}/\" \"${dockerfile}-tmp\"\n    fi\n\n    if diff -q \"${dockerfile}-tmp\" \"${dockerfile}\" > /dev/null; then\n      echo \"${dockerfile} is already up to date!\"\n    else\n      if [ \"${SKIP}\" = true ]; then\n        # Get the currently used Yarn version\n        yarnVersion=\"$(grep \"ENV YARN_VERSION\" \"${dockerfile}\" | cut -d' ' -f3)\"\n      fi\n      sed -Ei -e 's/^(ENV YARN_VERSION ).*/\\1'\"${yarnVersion}\"'/' \"${dockerfile}-tmp\"\n      echo \"${dockerfile} updated!\"\n    fi\n\n    # Required for POSIX sed\n    if [ -f \"${dockerfile}-tmp-e\" ]; then\n      rm \"${dockerfile}-tmp-e\"\n    fi\n\n    mv -f \"${dockerfile}-tmp\" \"${dockerfile}\"\n  )\n}\n\npids=()\n\nfor version in \"${versions[@]}\"; do\n  parentpath=$(dirname \"${version}\")\n  versionnum=$(basename \"${version}\")\n  baseuri=$(get_config \"${parentpath}\" \"baseuri\")\n  update_version=$(in_versions_to_update \"${version}\")\n\n  [ \"${update_version}\" -eq 0 ] && info \"Updating version ${version}...\"\n\n  # Get supported variants according the target architecture\n  # See details in function.sh\n  IFS=' ' read -ra variants <<< \"$(get_variants \"${parentpath}\")\"\n\n  if [ -f \"${version}/Dockerfile\" ]; then\n    if [ \"${update_version}\" -eq 0 ]; then\n      update_node_version \"${baseuri}\" \"${versionnum}\" \"${parentpath}/Dockerfile.template\" \"${version}/Dockerfile\" &\n      pids+=($!)\n    fi\n  fi\n\n  for variant in \"${variants[@]}\"; do\n    # Skip non-docker directories\n    [ -f \"${version}/${variant}/Dockerfile\" ] || continue\n\n    update_variant=$(in_variants_to_update \"${variant}\")\n    template_file=\"${parentpath}/Dockerfile-${variant}.template\"\n\n    if is_debian \"${variant}\"; then\n      template_file=\"${parentpath}/Dockerfile-debian.template\"\n    elif is_debian_slim \"${variant}\"; then\n      template_file=\"${parentpath}/Dockerfile-slim.template\"\n    elif is_alpine \"${variant}\"; then\n      template_file=\"${parentpath}/Dockerfile-alpine.template\"\n    fi\n\n    cp \"${parentpath}/docker-entrypoint.sh\" \"${version}/${variant}/docker-entrypoint.sh\"\n    if [ \"${update_version}\" -eq 0 ] && [ \"${update_variant}\" -eq 0 ]; then\n      update_node_version \"${baseuri}\" \"${versionnum}\" \"${template_file}\" \"${version}/${variant}/Dockerfile\" \"${variant}\" &\n      pids+=($!)\n    fi\n  done\ndone\n\n# The reason we explicitly wait on each pid is so the return status of this script is set properly\n# if one of the jobs fails. If we just called \"wait\", the exit status would always be 0\nfor pid in \"${pids[@]}\"; do\n  wait \"$pid\"\ndone\n\ninfo \"Done!\"\n"
        },
        {
          "name": "versions.json",
          "type": "blob",
          "size": 3.57421875,
          "content": "{\n  \"23\": {\n    \"start\": \"2024-10-15\",\n    \"lts\": \"\",\n    \"maintenance\": \"2025-04-01\",\n    \"end\": \"2025-06-01\",\n    \"codename\": \"\",\n    \"alpine-default\": \"alpine3.21\",\n    \"debian-default\": \"bookworm\",\n    \"variants\": {\n      \"alpine3.20\": [\n        \"amd64\",\n        \"arm32v6\",\n        \"arm32v7\",\n        \"arm64v8\",\n        \"s390x\"\n      ],\n      \"alpine3.21\": [\n        \"amd64\",\n        \"arm32v6\",\n        \"arm32v7\",\n        \"arm64v8\",\n        \"s390x\"\n      ],\n      \"bookworm\": [\n        \"amd64\",\n        \"arm32v7\",\n        \"arm64v8\",\n        \"ppc64le\",\n        \"s390x\"\n      ],\n      \"bookworm-slim\": [\n        \"amd64\",\n        \"arm32v7\",\n        \"arm64v8\",\n        \"ppc64le\",\n        \"s390x\"\n      ],\n      \"bullseye\": [\n        \"amd64\",\n        \"arm32v7\",\n        \"arm64v8\"\n      ],\n      \"bullseye-slim\": [\n        \"amd64\",\n        \"arm32v7\",\n        \"arm64v8\"\n      ]\n    }\n  },\n  \"22\": {\n    \"start\": \"2024-04-23\",\n    \"lts\": \"2024-10-29\",\n    \"maintenance\": \"2025-10-21\",\n    \"end\": \"2027-04-30\",\n    \"codename\": \"jod\",\n    \"alpine-default\": \"alpine3.21\",\n    \"debian-default\": \"bookworm\",\n    \"variants\": {\n      \"alpine3.20\": [\n        \"amd64\",\n        \"arm32v6\",\n        \"arm32v7\",\n        \"arm64v8\",\n        \"s390x\"\n      ],\n      \"alpine3.21\": [\n        \"amd64\",\n        \"arm32v6\",\n        \"arm32v7\",\n        \"arm64v8\",\n        \"s390x\"\n      ],\n      \"bookworm\": [\n        \"amd64\",\n        \"arm32v7\",\n        \"arm64v8\",\n        \"ppc64le\",\n        \"s390x\"\n      ],\n      \"bookworm-slim\": [\n        \"amd64\",\n        \"arm32v7\",\n        \"arm64v8\",\n        \"ppc64le\",\n        \"s390x\"\n      ],\n      \"bullseye\": [\n        \"amd64\",\n        \"arm32v7\",\n        \"arm64v8\"\n      ],\n      \"bullseye-slim\": [\n        \"amd64\",\n        \"arm32v7\",\n        \"arm64v8\"\n      ]\n    }\n  },\n  \"20\": {\n    \"start\": \"2023-04-18\",\n    \"lts\": \"2023-10-24\",\n    \"maintenance\": \"2024-10-22\",\n    \"end\": \"2026-04-30\",\n    \"codename\": \"iron\",\n    \"alpine-default\": \"alpine3.21\",\n    \"debian-default\": \"bookworm\",\n    \"variants\": {\n      \"alpine3.20\": [\n        \"amd64\",\n        \"arm32v6\",\n        \"arm32v7\",\n        \"arm64v8\",\n        \"ppc64le\",\n        \"s390x\"\n      ],\n      \"alpine3.21\": [\n        \"amd64\",\n        \"arm32v6\",\n        \"arm32v7\",\n        \"arm64v8\",\n        \"ppc64le\",\n        \"s390x\"\n      ],\n      \"bookworm\": [\n        \"amd64\",\n        \"arm32v7\",\n        \"arm64v8\",\n        \"ppc64le\",\n        \"s390x\"\n      ],\n      \"bookworm-slim\": [\n        \"amd64\",\n        \"arm32v7\",\n        \"arm64v8\",\n        \"ppc64le\",\n        \"s390x\"\n      ],\n      \"bullseye\": [\n        \"amd64\",\n        \"arm32v7\",\n        \"arm64v8\"\n      ],\n      \"bullseye-slim\": [\n        \"amd64\",\n        \"arm32v7\",\n        \"arm64v8\"\n      ]\n    }\n  },\n  \"18\": {\n    \"start\": \"2022-04-19\",\n    \"lts\": \"2022-10-25\",\n    \"maintenance\": \"2023-10-18\",\n    \"end\": \"2025-04-30\",\n    \"codename\": \"hydrogen\",\n    \"alpine-default\": \"alpine3.21\",\n    \"debian-default\": \"bookworm\",\n    \"variants\": {\n      \"alpine3.20\": [\n        \"amd64\",\n        \"arm32v6\",\n        \"arm32v7\",\n        \"arm64v8\",\n        \"ppc64le\",\n        \"s390x\"\n      ],\n      \"alpine3.21\": [\n        \"amd64\",\n        \"arm32v6\",\n        \"arm32v7\",\n        \"arm64v8\",\n        \"ppc64le\",\n        \"s390x\"\n      ],\n      \"bookworm\": [\n        \"amd64\",\n        \"arm32v7\",\n        \"arm64v8\",\n        \"ppc64le\",\n        \"s390x\"\n      ],\n      \"bookworm-slim\": [\n        \"amd64\",\n        \"arm32v7\",\n        \"arm64v8\",\n        \"ppc64le\",\n        \"s390x\"\n      ],\n      \"bullseye\": [\n        \"amd64\",\n        \"arm32v7\",\n        \"arm64v8\"\n      ],\n      \"bullseye-slim\": [\n        \"amd64\",\n        \"arm32v7\",\n        \"arm64v8\"\n      ]\n    }\n  }\n}\n"
        }
      ]
    }
  ]
}