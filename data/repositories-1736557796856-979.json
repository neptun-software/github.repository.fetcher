{
  "metadata": {
    "timestamp": 1736557796856,
    "page": 979,
    "hasNextPage": false,
    "endCursor": "Y3Vyc29yOjEwMDA=",
    "completionStatus": "IN_PROGRESS"
  },
  "repositories": [
    {
      "nameWithOwner": "envoyproxy/envoy",
      "stars": 25300,
      "defaultBranch": "main",
      "files": [
        {
          "name": ".bazelci",
          "type": "tree",
          "content": null
        },
        {
          "name": ".bazelignore",
          "type": "blob",
          "size": 0.15,
          "content": "# only directories can be ignored, and no globbing\napi\nexamples/grpc-bridge/script\nmobile\ntools/clang_tools\ntools/dev/src\n.project\nenvoy-filter-example\n"
        },
        {
          "name": ".bazelrc",
          "type": "blob",
          "size": 26.19,
          "content": "# Envoy specific Bazel build/test options.\n\n# Bazel doesn't need more than 200MB of memory for local build based on memory profiling:\n# https://docs.bazel.build/versions/master/skylark/performance.html#memory-profiling\n# The default JVM max heapsize is 1/4 of physical memory up to 32GB which could be large\n# enough to consume all memory constrained by cgroup in large host.\n# Limiting JVM heapsize here to let it do GC more when approaching the limit to\n# leave room for compiler/linker.\n# The number 3G is chosen heuristically to both support large VM and small VM with RBE.\n# Startup options cannot be selected via config.\nstartup --host_jvm_args=-Xmx3g\n\ncommon --noenable_bzlmod\n\nfetch --color=yes\nrun --color=yes\n\nbuild --color=yes\nbuild --jobs=HOST_CPUS-1\nbuild --workspace_status_command=\"bash bazel/get_workspace_status\"\nbuild --incompatible_strict_action_env\nbuild --java_runtime_version=remotejdk_11\nbuild --tool_java_runtime_version=remotejdk_11\nbuild --platform_mappings=bazel/platform_mappings\n# silence absl logspam.\nbuild --copt=-DABSL_MIN_LOG_LEVEL=4\nbuild --define envoy_mobile_listener=enabled\nbuild --experimental_repository_downloader_retries=2\nbuild --enable_platform_specific_config\nbuild --incompatible_merge_fixed_and_default_shell_env\n\n# Pass CC, CXX and LLVM_CONFIG variables from the environment.\n# We assume they have stable values, so this won't cause action cache misses.\nbuild --action_env=CC --host_action_env=CC\nbuild --action_env=CXX --host_action_env=CXX\nbuild --action_env=LLVM_CONFIG --host_action_env=LLVM_CONFIG\n# Do not pass through PATH however.\n# It tends to have machine-specific values, such as dynamically created temp folders.\n# This would make it impossible to share remote action cache hits among machines.\n# build --action_env=PATH --host_action_env=PATH\n# To make our own CI green, we do need that flag on Windows though.\nbuild:windows --action_env=PATH --host_action_env=PATH\n\n# Allow stamped caches to bust when local filesystem changes.\n# Requires setting `BAZEL_VOLATILE_DIRTY` in the env.\nbuild --action_env=BAZEL_VOLATILE_DIRTY --host_action_env=BAZEL_VOLATILE_DIRTY\n\nbuild --test_summary=terse\n\nbuild:docs-ci --action_env=DOCS_RST_CHECK=1 --host_action_env=DOCS_RST_CHECK=1\n\n# TODO(keith): Remove once these 2 are the default\nbuild --incompatible_config_setting_private_default_visibility\nbuild --incompatible_enforce_config_setting_visibility\n\ntest --test_verbose_timeout_warnings\ntest --experimental_ui_max_stdouterr_bytes=11712829 #default 1048576\n\n# Allow tags to influence execution requirements\ncommon --experimental_allow_tags_propagation\n\nbuild:linux --copt=-fdebug-types-section\n# Enable position independent code (this is the default on macOS and Windows)\n# (Workaround for https://github.com/bazelbuild/rules_foreign_cc/issues/421)\nbuild:linux --copt=-fPIC\nbuild:linux --copt=-Wno-deprecated-declarations\nbuild:linux --cxxopt=-std=c++20 --host_cxxopt=-std=c++20\nbuild:linux --cxxopt=-fsized-deallocation --host_cxxopt=-fsized-deallocation\nbuild:linux --conlyopt=-fexceptions\nbuild:linux --fission=dbg,opt\nbuild:linux --features=per_object_debug_info\nbuild:linux --action_env=BAZEL_LINKLIBS=-l%:libstdc++.a\nbuild:linux --action_env=BAZEL_LINKOPTS=-lm\n\n# We already have absl in the build, define absl=1 to tell googletest to use absl for backtrace.\nbuild --define absl=1\n\n# Disable ICU linking for googleurl.\nbuild --@com_googlesource_googleurl//build_config:system_icu=0\n\n# Common flags for sanitizers\nbuild:sanitizer --define tcmalloc=disabled\nbuild:sanitizer --linkopt -ldl\n\n# Common flags for Clang\nbuild:clang --action_env=BAZEL_COMPILER=clang\nbuild:clang --linkopt=-fuse-ld=lld\nbuild:clang --action_env=CC=clang --host_action_env=CC=clang\nbuild:clang --action_env=CXX=clang++ --host_action_env=CXX=clang++\nbuild:clang --incompatible_enable_cc_toolchain_resolution=false\n\n# Flags for Clang + PCH\nbuild:clang-pch --spawn_strategy=local\nbuild:clang-pch --define=ENVOY_CLANG_PCH=1\n\n# Use gold linker for gcc compiler.\nbuild:gcc --linkopt=-fuse-ld=gold --host_linkopt=-fuse-ld=gold\nbuild:gcc --test_env=HEAPCHECK=\nbuild:gcc --action_env=BAZEL_COMPILER=gcc\nbuild:gcc --action_env=CC=gcc --action_env=CXX=g++\n# This is to work around a bug in GCC that makes debug-types-section\n# option not play well with fission:\n# https://gcc.gnu.org/bugzilla/show_bug.cgi?id=110885\nbuild:gcc --copt=-fno-debug-types-section\n# These trigger errors in multiple places both in Envoy dependecies\n# and in Envoy code itself when using GCC.\n# And in all cases the reports appear to be clear false positives.\nbuild:gcc --copt=-Wno-error=restrict\nbuild:gcc --copt=-Wno-error=uninitialized\nbuild:gcc --cxxopt=-Wno-missing-requires\n# We need this because -Wno-missing-requires options is rather new\n# in GCC, so flags -Wno-missing-requires exists in GCC 12, but does\n# not in GCC 11 and GCC 11 is what is used in docker-gcc\n# configuration currently\nbuild:gcc --cxxopt=-Wno-unknown-warning\nbuild:gcc --incompatible_enable_cc_toolchain_resolution=false\n\n# Clang-tidy\n# TODO(phlax): enable this, its throwing some errors as well as finding more issues\n# build:clang-tidy --@envoy_toolshed//format/clang_tidy:executable=@envoy//tools/clang-tidy\nbuild:clang-tidy --@envoy_toolshed//format/clang_tidy:config=//:clang_tidy_config\nbuild:clang-tidy --aspects @envoy_toolshed//format/clang_tidy:clang_tidy.bzl%clang_tidy_aspect\nbuild:clang-tidy --output_groups=report\nbuild:clang-tidy --build_tag_filters=-notidy\n\n# Basic ASAN/UBSAN that works for gcc\nbuild:asan --config=sanitizer\n# ASAN install its signal handler, disable ours so the stacktrace will be printed by ASAN\nbuild:asan --define signal_trace=disabled\nbuild:asan --define ENVOY_CONFIG_ASAN=1\nbuild:asan --build_tag_filters=-no_san\nbuild:asan --test_tag_filters=-no_san\nbuild:asan --copt -fsanitize=address,undefined\nbuild:asan --linkopt -fsanitize=address,undefined\n# vptr and function sanitizer are enabled in clang-asan if it is set up via bazel/setup_clang.sh.\nbuild:asan --copt -fno-sanitize=vptr,function\nbuild:asan --linkopt -fno-sanitize=vptr,function\nbuild:asan --copt -DADDRESS_SANITIZER=1\nbuild:asan --copt -DUNDEFINED_SANITIZER=1\nbuild:asan --copt -D__SANITIZE_ADDRESS__\nbuild:asan --test_env=ASAN_OPTIONS=handle_abort=1:allow_addr2line=true:check_initialization_order=true:strict_init_order=true:detect_odr_violation=1\nbuild:asan --test_env=UBSAN_OPTIONS=halt_on_error=true:print_stacktrace=1\nbuild:asan --test_env=ASAN_SYMBOLIZER_PATH\n# ASAN needs -O1 to get reasonable performance.\nbuild:asan --copt -O1\nbuild:asan --copt -fno-optimize-sibling-calls\n\n# Clang ASAN/UBSAN\nbuild:clang-asan-common --config=clang\nbuild:clang-asan-common --config=asan\nbuild:clang-asan-common --linkopt -fuse-ld=lld\nbuild:clang-asan-common --linkopt --rtlib=compiler-rt\nbuild:clang-asan-common --linkopt --unwindlib=libgcc\n\nbuild:clang-asan --config=clang-asan-common\nbuild:clang-asan --linkopt=-l:libclang_rt.ubsan_standalone.a\nbuild:clang-asan --linkopt=-l:libclang_rt.ubsan_standalone_cxx.a\nbuild:clang-asan --action_env=ENVOY_UBSAN_VPTR=1\nbuild:clang-asan --copt=-fsanitize=vptr,function\nbuild:clang-asan --linkopt=-fsanitize=vptr,function\n\n# macOS\nbuild:macos --cxxopt=-std=c++20 --host_cxxopt=-std=c++20\nbuild:macos --copt=-Wno-deprecated-declarations\nbuild:macos --action_env=PATH=/opt/homebrew/bin:/opt/local/bin:/usr/local/bin:/usr/bin:/bin\nbuild:macos --host_action_env=PATH=/opt/homebrew/bin:/opt/local/bin:/usr/local/bin:/usr/bin:/bin\nbuild:macos --define tcmalloc=disabled\n\n# macOS ASAN/UBSAN\nbuild:macos-asan --config=asan\n# Workaround, see https://github.com/bazelbuild/bazel/issues/6932\nbuild:macos-asan --copt -Wno-macro-redefined\nbuild:macos-asan --copt -D_FORTIFY_SOURCE=0\n# Workaround, see https://github.com/bazelbuild/bazel/issues/4341\nbuild:macos-asan --copt -DGRPC_BAZEL_BUILD\n# Dynamic link cause issues like: `dyld: malformed mach-o: load commands size (59272) > 32768`\nbuild:macos-asan --dynamic_mode=off\n\n# Clang TSAN\nbuild:clang-tsan --action_env=ENVOY_TSAN=1\nbuild:clang-tsan --config=sanitizer\nbuild:clang-tsan --define ENVOY_CONFIG_TSAN=1\nbuild:clang-tsan --copt -fsanitize=thread\nbuild:clang-tsan --linkopt -fsanitize=thread\nbuild:clang-tsan --linkopt -fuse-ld=lld\nbuild:clang-tsan --copt -DTHREAD_SANITIZER=1\nbuild:clang-tsan --build_tag_filters=-no_san,-no_tsan\nbuild:clang-tsan --test_tag_filters=-no_san,-no_tsan\n# Needed due to https://github.com/libevent/libevent/issues/777\nbuild:clang-tsan --copt -DEVENT__DISABLE_DEBUG_MODE\n# https://github.com/abseil/abseil-cpp/issues/760\n# https://github.com/google/sanitizers/issues/953\nbuild:clang-tsan --test_env=\"TSAN_OPTIONS=report_atomic_races=0\"\nbuild:clang-tsan --test_timeout=120,600,1500,4800\n\n# Clang MSAN - this is the base config for remote-msan and docker-msan. To run this config without\n# our build image, follow https://github.com/google/sanitizers/wiki/MemorySanitizerLibcxxHowTo\n# with libc++ instruction and provide corresponding `--copt` and `--linkopt` as well.\nbuild:clang-msan --action_env=ENVOY_MSAN=1\nbuild:clang-msan --config=sanitizer\nbuild:clang-msan --build_tag_filters=-no_san\nbuild:clang-msan --test_tag_filters=-no_san\nbuild:clang-msan --define ENVOY_CONFIG_MSAN=1\nbuild:clang-msan --copt -fsanitize=memory\nbuild:clang-msan --linkopt -fsanitize=memory\nbuild:clang-msan --linkopt -fuse-ld=lld\nbuild:clang-msan --copt -fsanitize-memory-track-origins=2\nbuild:clang-msan --copt -DMEMORY_SANITIZER=1\nbuild:clang-msan --test_env=MSAN_SYMBOLIZER_PATH\n# MSAN needs -O1 to get reasonable performance.\nbuild:clang-msan --copt -O1\nbuild:clang-msan --copt -fno-optimize-sibling-calls\n\n# Clang with libc++\nbuild:libc++ --config=clang\nbuild:libc++ --action_env=CXXFLAGS=-stdlib=libc++\nbuild:libc++ --action_env=LDFLAGS=-stdlib=libc++\nbuild:libc++ --action_env=BAZEL_CXXOPTS=-stdlib=libc++\nbuild:libc++ --action_env=BAZEL_LINKLIBS=-l%:libc++.a:-l%:libc++abi.a\nbuild:libc++ --action_env=BAZEL_LINKOPTS=-lm:-pthread\nbuild:libc++ --define force_libcpp=enabled\nbuild:clang-libc++ --config=libc++\nbuild:clang-libc++ --action_env=ARFLAGS=r\n\nbuild:libc++20 --config=libc++\n# gRPC has a lot of deprecated-enum-enum-conversion warning. Remove once it is addressed\nbuild:libc++20 --copt=-Wno-error=deprecated-enum-enum-conversion\n\n# Optimize build for binary size reduction.\nbuild:sizeopt -c opt --copt -Os\n\n# Test options\nbuild --test_env=HEAPCHECK=normal --test_env=PPROF_PATH\n\n# Coverage options\ncoverage --config=coverage\ncoverage --build_tests_only\n\nbuild:coverage --action_env=BAZEL_USE_LLVM_NATIVE_COVERAGE=1\nbuild:coverage --action_env=GCOV=llvm-profdata\nbuild:coverage --copt=-DNDEBUG\n# 1.5x original timeout + 300s for trace merger in all categories\nbuild:coverage --test_timeout=390,750,1500,5700\nbuild:coverage --define=dynamic_link_tests=true\nbuild:coverage --define=ENVOY_CONFIG_COVERAGE=1\nbuild:coverage --cxxopt=\"-DENVOY_CONFIG_COVERAGE=1\"\nbuild:coverage --test_env=HEAPCHECK=\nbuild:coverage --combined_report=lcov\nbuild:coverage --strategy=TestRunner=remote,sandboxed,local\nbuild:coverage --strategy=CoverageReport=sandboxed,local\nbuild:coverage --experimental_use_llvm_covmap\nbuild:coverage --experimental_generate_llvm_lcov\nbuild:coverage --experimental_split_coverage_postprocessing\nbuild:coverage --experimental_fetch_all_coverage_outputs\nbuild:coverage --collect_code_coverage\nbuild:coverage --instrumentation_filter=\"^//source(?!/common/quic/platform)[/:],^//envoy[/:],^//contrib(?!/.*/test)[/:]\"\nbuild:coverage --remote_download_minimal\nbuild:coverage --define=tcmalloc=gperftools\nbuild:coverage --define=no_debug_info=1\n# `--no-relax` is required for coverage to not err with `relocation R_X86_64_REX_GOTPCRELX`\nbuild:coverage --linkopt=-Wl,-s,--no-relax\nbuild:coverage --test_env=ENVOY_IP_TEST_VERSIONS=v4only\n\nbuild:test-coverage --test_arg=\"-l trace\"\nbuild:test-coverage --test_arg=\"--log-path /dev/null\"\nbuild:test-coverage --test_tag_filters=-nocoverage,-fuzz_target\nbuild:fuzz-coverage --config=plain-fuzzer\nbuild:fuzz-coverage --run_under=@envoy//bazel/coverage:fuzz_coverage_wrapper.sh\nbuild:fuzz-coverage --test_tag_filters=-nocoverage\n\nbuild:cache-local --remote_cache=grpc://localhost:9092\n\n# Remote execution: https://docs.bazel.build/versions/master/remote-execution.html\nbuild:rbe-toolchain --action_env=BAZEL_DO_NOT_DETECT_CPP_TOOLCHAIN=1\nbuild:rbe-toolchain --incompatible_enable_cc_toolchain_resolution=false\n\nbuild:rbe-toolchain-clang --config=rbe-toolchain\nbuild:rbe-toolchain-clang --platforms=@envoy//bazel/rbe/toolchains:rbe_linux_clang_platform\nbuild:rbe-toolchain-clang --host_platform=@envoy//bazel/rbe/toolchains:rbe_linux_clang_platform\nbuild:rbe-toolchain-clang --crosstool_top=@envoy//bazel/rbe/toolchains/configs/linux/clang/cc:toolchain\nbuild:rbe-toolchain-clang --extra_toolchains=@envoy//bazel/rbe/toolchains/configs/linux/clang/config:cc-toolchain\nbuild:rbe-toolchain-clang --action_env=CC=clang --action_env=CXX=clang++\n\nbuild:rbe-toolchain-clang-libc++ --config=rbe-toolchain\nbuild:rbe-toolchain-clang-libc++ --platforms=@envoy//bazel/rbe/toolchains:rbe_linux_clang_libcxx_platform\nbuild:rbe-toolchain-clang-libc++ --host_platform=@envoy//bazel/rbe/toolchains:rbe_linux_clang_libcxx_platform\nbuild:rbe-toolchain-clang-libc++ --crosstool_top=@envoy//bazel/rbe/toolchains/configs/linux/clang_libcxx/cc:toolchain\nbuild:rbe-toolchain-clang-libc++ --extra_toolchains=@envoy//bazel/rbe/toolchains/configs/linux/clang_libcxx/config:cc-toolchain\nbuild:rbe-toolchain-clang-libc++ --action_env=CC=clang --action_env=CXX=clang++\nbuild:rbe-toolchain-clang-libc++ --action_env=CXXFLAGS=-stdlib=libc++\nbuild:rbe-toolchain-clang-libc++ --action_env=LDFLAGS=-stdlib=libc++\nbuild:rbe-toolchain-clang-libc++ --define force_libcpp=enabled\n\nbuild:rbe-toolchain-asan --config=clang-asan\nbuild:rbe-toolchain-asan --linkopt -fuse-ld=lld\nbuild:rbe-toolchain-asan --action_env=ENVOY_UBSAN_VPTR=1\nbuild:rbe-toolchain-asan --copt=-fsanitize=vptr,function\nbuild:rbe-toolchain-asan --linkopt=-fsanitize=vptr,function\nbuild:rbe-toolchain-asan --linkopt='-L/opt/llvm/lib/clang/14.0.0/lib/x86_64-unknown-linux-gnu'\nbuild:rbe-toolchain-asan --linkopt=-l:libclang_rt.ubsan_standalone.a\nbuild:rbe-toolchain-asan --linkopt=-l:libclang_rt.ubsan_standalone_cxx.a\n\nbuild:rbe-toolchain-msan --linkopt=-L/opt/libcxx_msan/lib\nbuild:rbe-toolchain-msan --linkopt=-Wl,-rpath,/opt/libcxx_msan/lib\nbuild:rbe-toolchain-msan --config=clang-msan\n\nbuild:rbe-toolchain-tsan --linkopt=-L/opt/libcxx_tsan/lib\nbuild:rbe-toolchain-tsan --linkopt=-Wl,-rpath,/opt/libcxx_tsan/lib\nbuild:rbe-toolchain-tsan --config=clang-tsan\n\nbuild:rbe-toolchain-gcc --config=rbe-toolchain\nbuild:rbe-toolchain-gcc --platforms=@envoy//bazel/rbe/toolchains:rbe_linux_gcc_platform\nbuild:rbe-toolchain-gcc --host_platform=@envoy//bazel/rbe/toolchains:rbe_linux_gcc_platform\nbuild:rbe-toolchain-gcc --crosstool_top=@envoy//bazel/rbe/toolchains/configs/linux/gcc/cc:toolchain\nbuild:rbe-toolchain-gcc --extra_toolchains=@envoy//bazel/rbe/toolchains/configs/linux/gcc/config:cc-toolchain\n\nbuild:remote --spawn_strategy=remote,sandboxed,local\nbuild:remote --strategy=Javac=remote,sandboxed,local\nbuild:remote --strategy=Closure=remote,sandboxed,local\nbuild:remote --strategy=Genrule=remote,sandboxed,local\n\n# Windows bazel does not allow sandboxed as a spawn strategy\nbuild:remote-windows --spawn_strategy=remote,local\nbuild:remote-windows --strategy=Javac=remote,local\nbuild:remote-windows --strategy=Closure=remote,local\nbuild:remote-windows --strategy=Genrule=remote,local\nbuild:remote-windows --strategy=CppLink=local\nbuild:remote-windows --remote_timeout=7200\nbuild:remote-windows --google_default_credentials=true\nbuild:remote-windows --remote_download_toplevel\n\nbuild:remote-clang --config=remote\nbuild:remote-clang --config=rbe-toolchain-clang\n\nbuild:remote-clang-libc++ --config=remote\nbuild:remote-clang-libc++ --config=rbe-toolchain-clang-libc++\n\nbuild:remote-gcc --config=remote\nbuild:remote-gcc --config=gcc\nbuild:remote-gcc --config=rbe-toolchain-gcc\n\nbuild:remote-asan --config=remote\nbuild:remote-asan --config=rbe-toolchain-clang-libc++\nbuild:remote-asan --config=rbe-toolchain-asan\n\nbuild:remote-msan --config=remote\nbuild:remote-msan --config=rbe-toolchain-clang-libc++\nbuild:remote-msan --config=rbe-toolchain-msan\n\nbuild:remote-tsan --config=remote\nbuild:remote-tsan --config=rbe-toolchain-clang-libc++\nbuild:remote-tsan --config=rbe-toolchain-tsan\n\nbuild:remote-msvc-cl --config=remote-windows\nbuild:remote-msvc-cl --config=msvc-cl\nbuild:remote-msvc-cl --config=rbe-toolchain-msvc-cl\n\nbuild:remote-clang-cl --config=remote-windows\nbuild:remote-clang-cl --config=clang-cl\nbuild:remote-clang-cl --config=rbe-toolchain-clang-cl\n\n## Compile-time-options testing\n# Right now, none of the available compile-time options conflict with each other. If this\n# changes, this build type may need to be broken up.\nbuild:compile-time-options --define=admin_html=disabled\nbuild:compile-time-options --define=signal_trace=disabled\nbuild:compile-time-options --define=hot_restart=disabled\nbuild:compile-time-options --define=google_grpc=disabled\nbuild:compile-time-options --define=boringssl=fips\nbuild:compile-time-options --define=log_debug_assert_in_release=enabled\nbuild:compile-time-options --define=path_normalization_by_default=true\nbuild:compile-time-options --define=deprecated_features=disabled\nbuild:compile-time-options --define=tcmalloc=gperftools\nbuild:compile-time-options --define=zlib=ng\nbuild:compile-time-options --define=uhv=enabled\nbuild:compile-time-options --config=libc++20\nbuild:compile-time-options --test_env=ENVOY_HAS_EXTRA_EXTENSIONS=true\nbuild:compile-time-options --@envoy//bazel:http3=False\nbuild:compile-time-options --@envoy//source/extensions/filters/http/kill_request:enabled\n\n# Docker sandbox\n# NOTE: Update this from https://github.com/envoyproxy/envoy-build-tools/blob/main/toolchains/rbe_toolchains_config.bzl#L8\nbuild:docker-sandbox --experimental_docker_image=envoyproxy/envoy-build-ubuntu:d2be0c198feda0c607fa33209da01bf737ef373f@sha256:026fb6710a3e55716cc1aba129f613f9834212d2deb4ea875ac9d2c37ca19aa3\nbuild:docker-sandbox --spawn_strategy=docker\nbuild:docker-sandbox --strategy=Javac=docker\nbuild:docker-sandbox --strategy=Closure=docker\nbuild:docker-sandbox --strategy=Genrule=docker\nbuild:docker-sandbox --define=EXECUTOR=remote\nbuild:docker-sandbox --experimental_docker_verbose\nbuild:docker-sandbox --experimental_enable_docker_sandbox\n\nbuild:docker-clang --config=docker-sandbox\nbuild:docker-clang --config=rbe-toolchain-clang\n\nbuild:docker-clang-libc++ --config=docker-sandbox\nbuild:docker-clang-libc++ --config=rbe-toolchain-clang-libc++\n\nbuild:docker-gcc --config=docker-sandbox\nbuild:docker-gcc --config=gcc\nbuild:docker-gcc --config=rbe-toolchain-gcc\n\nbuild:docker-asan --config=docker-sandbox\nbuild:docker-asan --config=rbe-toolchain-clang-libc++\nbuild:docker-asan --config=rbe-toolchain-asan\n\nbuild:docker-msan --config=docker-sandbox\nbuild:docker-msan --config=rbe-toolchain-clang-libc++\nbuild:docker-msan --config=rbe-toolchain-msan\n\nbuild:docker-tsan --config=docker-sandbox\nbuild:docker-tsan --config=rbe-toolchain-clang-libc++\nbuild:docker-tsan --config=rbe-toolchain-tsan\n\n# CI configurations\nbuild:remote-ci --config=ci\nbuild:remote-ci --remote_download_minimal\n\n# Note this config is used by mobile CI also.\ncommon:ci --noshow_progress\ncommon:ci --noshow_loading_progress\ncommon:ci --test_output=errors\n\n# Fuzz builds\n\n# Shared fuzzing configuration.\nbuild:fuzzing --define=ENVOY_CONFIG_ASAN=1\nbuild:fuzzing --copt=-DFUZZING_BUILD_MODE_UNSAFE_FOR_PRODUCTION\nbuild:fuzzing --config=libc++\n\n# Fuzzing without ASAN. This is useful for profiling fuzzers without any ASAN artifacts.\nbuild:plain-fuzzer --config=fuzzing\nbuild:plain-fuzzer --define=FUZZING_ENGINE=libfuzzer\n# The fuzzing rules provide their own instrumentation, but it is currently\n# disabled due to bazelbuild/bazel#12888. Instead, we provide instrumentation at\n# the top level through these options.\nbuild:plain-fuzzer --copt=-fsanitize=fuzzer-no-link\nbuild:plain-fuzzer --linkopt=-fsanitize=fuzzer-no-link\n\nbuild:asan-fuzzer --config=plain-fuzzer\nbuild:asan-fuzzer --config=clang-asan\nbuild:asan-fuzzer --copt=-fno-omit-frame-pointer\n# Remove UBSAN halt_on_error to avoid crashing on protobuf errors.\nbuild:asan-fuzzer --test_env=UBSAN_OPTIONS=print_stacktrace=1\n\nbuild:oss-fuzz --config=fuzzing\nbuild:oss-fuzz --define=FUZZING_ENGINE=oss-fuzz\nbuild:oss-fuzz --@rules_fuzzing//fuzzing:cc_engine_instrumentation=oss-fuzz\nbuild:oss-fuzz --@rules_fuzzing//fuzzing:cc_engine_sanitizer=none\nbuild:oss-fuzz --dynamic_mode=off\nbuild:oss-fuzz --strip=never\nbuild:oss-fuzz --copt=-fno-sanitize=vptr\nbuild:oss-fuzz --linkopt=-fno-sanitize=vptr\nbuild:oss-fuzz --define=tcmalloc=disabled\nbuild:oss-fuzz --define=signal_trace=disabled\nbuild:oss-fuzz --copt=-D_LIBCPP_DISABLE_DEPRECATION_WARNINGS\nbuild:oss-fuzz --define=force_libcpp=enabled\nbuild:oss-fuzz --linkopt=-lc++\nbuild:oss-fuzz --linkopt=-pthread\n\n# Compile database generation config\nbuild:compdb --build_tag_filters=-nocompdb\n\n# Windows build quirks\nbuild:windows --action_env=TMPDIR\nbuild:windows --define signal_trace=disabled\nbuild:windows --define hot_restart=disabled\nbuild:windows --define tcmalloc=disabled\nbuild:windows --define wasm=disabled\nbuild:windows --define manual_stamp=manual_stamp\nbuild:windows --cxxopt=\"/std:c++20\"\nbuild:windows --output_groups=+pdb_file\n\n# TODO(wrowe,sunjayBhatia): Resolve bugs upstream in curl and rules_foreign_cc\n# See issue https://github.com/bazelbuild/rules_foreign_cc/issues/301\nbuild:windows --copt=\"-DCARES_STATICLIB\"\nbuild:windows --copt=\"-DNGHTTP2_STATICLIB\"\nbuild:windows --copt=\"-DCURL_STATICLIB\"\n\n# Override any clang preference if building msvc-cl\n# Drop the determinism feature (-DDATE etc are a no-op in msvc-cl)\nbuild:msvc-cl --action_env=USE_CLANG_CL=\"\"\nbuild:msvc-cl --define clang_cl=0\nbuild:msvc-cl --features=-determinism\n\n# Windows build behaviors when using clang-cl\nbuild:clang-cl --action_env=USE_CLANG_CL=1\nbuild:clang-cl --define clang_cl=1\n\n# Required to work around Windows clang-cl build defects\n# Ignore conflicting definitions of _WIN32_WINNT\n# Override determinism flags (DATE etc) is valid on clang-cl compiler\nbuild:clang-cl --copt=\"-Wno-macro-redefined\"\nbuild:clang-cl --copt=\"-Wno-builtin-macro-redefined\"\n# Workaround problematic missing override declarations of mocks\n# TODO: resolve this class of problematic mocks, e.g.\n# ./test/mocks/http/stream.h(16,21): error: 'addCallbacks'\n#     overrides a member function but is not marked 'override'\n#   MOCK_METHOD(void, addCallbacks, (StreamCallbacks & callbacks));\nbuild:clang-cl --copt=\"-Wno-inconsistent-missing-override\"\n\n# Defaults to 'auto' - Off for windows, so override to linux behavior\nbuild:windows --enable_runfiles=yes\n\n# This should become adopted by bazel as the default\nbuild:windows --features=compiler_param_file\n\n# These options attempt to force a monolithic binary including the CRT\nbuild:windows --features=fully_static_link\nbuild:windows --features=static_link_msvcrt\nbuild:windows --dynamic_mode=off\n\n# RBE (Google)\nbuild:cache-google --google_default_credentials=true\nbuild:cache-google --remote_cache=grpcs://remotebuildexecution.googleapis.com\nbuild:cache-google --remote_instance_name=projects/envoy-ci/instances/default_instance\nbuild:cache-google --remote_timeout=7200\nbuild:rbe-google --remote_executor=grpcs://remotebuildexecution.googleapis.com\nbuild:rbe-google --config=cache-google\n\nbuild:rbe-google-bes --bes_backend=grpcs://buildeventservice.googleapis.com\nbuild:rbe-google-bes --bes_results_url=https://source.cloud.google.com/results/invocations/\nbuild:rbe-google-bes --bes_upload_mode=fully_async\n\n# RBE (Engflow mobile)\nbuild:rbe-engflow --google_default_credentials=false\nbuild:rbe-engflow --remote_cache=grpcs://envoy.cluster.engflow.com\nbuild:rbe-engflow --remote_executor=grpcs://envoy.cluster.engflow.com\nbuild:rbe-engflow --bes_backend=grpcs://envoy.cluster.engflow.com/\nbuild:rbe-engflow --bes_results_url=https://envoy.cluster.engflow.com/invocation/\nbuild:rbe-engflow --credential_helper=*.engflow.com=%workspace%/bazel/engflow-bazel-credential-helper.sh\nbuild:rbe-engflow --grpc_keepalive_time=60s\nbuild:rbe-engflow --grpc_keepalive_timeout=30s\nbuild:rbe-engflow --remote_timeout=3600s\nbuild:rbe-engflow --bes_timeout=3600s\nbuild:rbe-engflow --bes_upload_mode=fully_async\nbuild:rbe-engflow --nolegacy_important_outputs\n\n# RBE (Engflow Envoy)\ncommon:common-envoy-engflow --google_default_credentials=false\ncommon:common-envoy-engflow --credential_helper=*.engflow.com=%workspace%/bazel/engflow-bazel-credential-helper.sh\ncommon:common-envoy-engflow --grpc_keepalive_time=60s\ncommon:common-envoy-engflow --grpc_keepalive_timeout=30s\n\ncommon:cache-envoy-engflow --remote_cache=grpcs://mordenite.cluster.engflow.com\ncommon:cache-envoy-engflow --remote_timeout=3600s\ncommon:bes-envoy-engflow --bes_backend=grpcs://mordenite.cluster.engflow.com/\ncommon:bes-envoy-engflow --bes_results_url=https://mordenite.cluster.engflow.com/invocation/\ncommon:bes-envoy-engflow --bes_timeout=3600s\ncommon:bes-envoy-engflow --bes_upload_mode=fully_async\ncommon:bes-envoy-engflow --nolegacy_important_outputs\ncommon:rbe-envoy-engflow --remote_executor=grpcs://mordenite.cluster.engflow.com\ncommon:rbe-envoy-engflow --remote_default_exec_properties=container-image=docker://gcr.io/envoy-ci/envoy-build@sha256:6e494ff9bcfa96868cb43f1200f2126cdab39d62db52a5dda80c8ec1694a93ee\ncommon:rbe-envoy-engflow --jobs=200\ncommon:rbe-envoy-engflow --define=engflow_rbe=true\n\ncommon:remote-envoy-engflow --config=common-envoy-engflow\ncommon:remote-envoy-engflow --config=cache-envoy-engflow\ncommon:remote-envoy-engflow --config=rbe-envoy-engflow\n\ncommon:remote-cache-envoy-engflow --config=common-envoy-engflow\ncommon:remote-cache-envoy-engflow --config=cache-envoy-engflow\n\n# Specifies the rustfmt.toml for all rustfmt_test targets.\nbuild --@rules_rust//rust/settings:rustfmt.toml=//:rustfmt.toml\n\n#############################################################################\n# debug: Various Bazel debugging flags\n#############################################################################\n# debug/bazel\ncommon:debug-bazel --announce_rc\ncommon:debug-bazel -s\n# debug/sandbox\ncommon:debug-sandbox --verbose_failures\ncommon:debug-sandbox --sandbox_debug\n# debug/coverage\ncommon:debug-coverage --action_env=VERBOSE_COVERAGE=true\ncommon:debug-coverage --test_env=VERBOSE_COVERAGE=true\ncommon:debug-coverage --test_env=DISPLAY_LCOV_CMD=true\ncommon:debug-coverage --config=debug-tests\n# debug/tests\ncommon:debug-tests --test_output=all\n# debug/everything\ncommon:debug --config=debug-bazel\ncommon:debug --config=debug-sandbox\ncommon:debug --config=debug-coverage\ncommon:debug --config=debug-tests\n\ntry-import %workspace%/repo.bazelrc\ntry-import %workspace%/clang.bazelrc\ntry-import %workspace%/user.bazelrc\ntry-import %workspace%/local_tsan.bazelrc\n"
        },
        {
          "name": ".bazelversion",
          "type": "blob",
          "size": 0.01,
          "content": "7.4.0\n"
        },
        {
          "name": ".clang-format",
          "type": "blob",
          "size": 0.3,
          "content": "---\nLanguage: Cpp\nAccessModifierOffset: -2\nColumnLimit: 100\nDerivePointerAlignment: false\nPointerAlignment: Left\nSortIncludes: false\nTypenameMacros: ['STACK_OF']\n...\n\n---\nLanguage: Proto\nColumnLimit: 100\nSpacesInContainerLiterals: false\nAllowShortFunctionsOnASingleLine: false\nReflowComments: false\n...\n"
        },
        {
          "name": ".clang-tidy",
          "type": "blob",
          "size": 3.69,
          "content": "Checks: >\n  -clang-analyzer-core.NonNullParamChecker,\n  -clang-analyzer-optin.cplusplus.UninitializedObject,\n  -clang-diagnostic-builtin-macro-redefined,\n  abseil-duration-*,\n  abseil-faster-strsplit-delimiter,\n  abseil-no-namespace,\n  abseil-redundant-strcat-calls,\n  abseil-str-cat-append,\n  abseil-string-find-startswith,\n  abseil-upgrade-duration-conversions,\n  bugprone-assert-side-effect,\n  bugprone-unused-raii,\n  bugprone-use-after-move,\n  clang-analyzer-core.DivideZero,\n  misc-unused-using-decls,\n  modernize-deprecated-headers,\n  modernize-loop-convert,\n  modernize-make-shared,\n  modernize-make-unique,\n  modernize-return-braced-init-list,\n  modernize-use-default-member-init,\n  modernize-use-equals-default,\n  modernize-use-nullptr,\n  modernize-use-override,\n  modernize-use-using,\n  performance-faster-string-find,\n  performance-for-range-copy,\n  performance-inefficient-algorithm,\n  performance-inefficient-vector-operation,\n  performance-noexcept-move-constructor,\n  performance-move-constructor-init,\n  performance-type-promotion-in-math-fn,\n  performance-unnecessary-copy-initialization,\n  readability-braces-around-statements,\n  readability-container-size-empty,\n  readability-identifier-naming,\n  readability-redundant-control-flow,\n  readability-redundant-member-init,\n  readability-redundant-smartptr-get,\n  readability-redundant-string-cstr\n\nCheckOptions:\n- key: cppcoreguidelines-unused-variable.IgnorePattern\n  value: \"^_$\"\n- key: bugprone-assert-side-effect.AssertMacros\n  value: 'ASSERT'\n- key: bugprone-dangling-handle.HandleClasses\n  value: 'std::basic_string_view;std::experimental::basic_string_view;absl::string_view'\n- key: modernize-use-auto.MinTypeNameLength\n  value: '10'\n- key: readability-identifier-naming.ClassCase\n  value: 'CamelCase'\n- key: readability-identifier-naming.EnumCase\n  value: 'CamelCase'\n- key: readability-identifier-naming.EnumConstantCase\n  value: 'CamelCase'\n# Ignore GoogleTest function macros.\n- key: readability-identifier-naming.FunctionIgnoredRegexp\n  # To have the regex chomped correctly fence all items with `|` (other than first/last)\n  value: >-\n    (^AbslHashValue$|\n    |^called_count$|\n    |^case_sensitive$|\n    |^Create$|\n    |^envoy_resolve_dns$|\n    |^evconnlistener_free$|\n    |^event_base_free$|\n    |^(get|set)EVP_PKEY$|\n    |^has_value$|\n    |^value_or$|\n    |^Ip6(ntohl|htonl)$|\n    |^get_$|\n    |^HeaderHasValue(Ref)?$|\n    |^HeaderValueOf$|\n    |^Is(Superset|Subset)OfHeaders$|\n    |^LLVMFuzzerInitialize$|\n    |^LLVMFuzzerTestOneInput$|\n    |^Locality$|\n    |^MOCK_METHOD$|\n    |^PrepareCall$|\n    |^PrintTo$|\n    |^resolve_dns$|\n    |^result_type$|\n    |Returns(Default)?WorkerId$|\n    |^sched_getaffinity$|\n    |^shutdownThread_$|\n    |^envoy_dynamic_module(.*)$|\n    |TEST|\n    |^use_count$)\n- key: readability-identifier-naming.ParameterCase\n  value: 'lower_case'\n- key: readability-identifier-naming.ParameterIgnoredRegexp\n  value: (^cname_ttl_$)\n- key: readability-identifier-naming.PrivateMemberCase\n  value: 'lower_case'\n- key: readability-identifier-naming.PrivateMemberSuffix\n  value: '_'\n- key: readability-identifier-naming.StructCase\n  value: 'CamelCase'\n- key: readability-identifier-naming.TypeAliasCase\n  value: 'CamelCase'\n- key: readability-identifier-naming.TypeAliasIgnoredRegexp\n  value: '(result_type)'\n- key: readability-identifier-naming.UnionCase\n  value: 'CamelCase'\n- key: readability-identifier-naming.FunctionCase\n  value: 'camelBack'\n\nHeaderFilterRegex: '^./source/.*|^./contrib/.*|^./test/.*|^./envoy/.*'\n\nUseColor: true\n\nWarningsAsErrors: '*'\n\n## The version here is arbitrary since any change to this file will\n## trigger a full run of clang-tidy against all files.\n## It can be useful as it seems some header changes may not trigger the\n## expected rerun.\n# v0\n"
        },
        {
          "name": ".coveragerc",
          "type": "blob",
          "size": 0.17,
          "content": "[run]\nomit =\n     tools/\n     */pytest_*.py\n\n[report]\nexclude_lines =\n        pragma: no cover\n        raise NotImplementedError\n        pass\n        if __name__ == .__main__.:\n"
        },
        {
          "name": ".devcontainer",
          "type": "tree",
          "content": null
        },
        {
          "name": ".dockerignore",
          "type": "blob",
          "size": 0.31,
          "content": "/*\n!/VERSION.txt\n!/build_envoy\n!/ci\n!/configs/google-vrp\n!/configs/*yaml\n!/linux/amd64/release.tar.zst\n!/linux/amd64/schema_validator_tool\n!/linux/amd64/router_check_tool\n!/linux/arm64/release.tar.zst\n!/linux/arm64/schema_validator_tool\n!/linux/arm64/router_check_tool\n!/local\n!/test/config/integration/certs\n!/windows\n"
        },
        {
          "name": ".flake8",
          "type": "blob",
          "size": 0.26,
          "content": "\n[flake8]\n\n# TODO(phlax): ignore less\nignore = W503,W504,E121,E126,E241,E125,E127,E129,E251,E265,E303,E306,E402,E501,E502,E711,E713,E722,E741,F523,F541,F841,N803,N806,N817,W605\n\n# TODO(phlax): exclude less\nexclude = build_docs,.git,generated,test,examples,venv,tools/dev\n"
        },
        {
          "name": ".gitattributes",
          "type": "blob",
          "size": 0.33,
          "content": "* text=auto eol=lf\n\n/generated_api_shadow/envoy/** linguist-generated=true\n/generated_api_shadow/bazel/** linguist-generated=true\n*.svg binary\n/test/common/tls/test_data/aes_128_key binary\n/test/common/tls/test_data/ticket_key_* binary\n/test/**/*_corpus/* linguist-generated=true\nrequirements.txt binary\npackage.lock binary\nyarn.lock binary\n"
        },
        {
          "name": ".github",
          "type": "tree",
          "content": null
        },
        {
          "name": ".gitignore",
          "type": "blob",
          "size": 1.06,
          "content": "# Dot files, disallow by default, and enable explicitly\n\\.*\n!\\.azure-pipelines\n!\\.bazelci\n!\\.bazelignore\n!\\.bazelrc\n!\\.bazelproject\n!\\.bazelversion\n!\\.circleci\n!\\.clang-format\n!\\.clang-tidy\n!\\.coveragerc\n!\\.devcontainer\n!\\.dockerignore\n!\\.eslintrc.yml\n!\\.flake8\n!\\.gitattributes\n!\\.github\n!\\.gitignore\n!\\.python-version\n!\\.style.yapf\n!\\.yamllint\n!\\.yapfignore\n!\\.zuul\n!\\.zuul.yaml\n\n/bazel-*\n/mobile/bazel-*\nBROWSE\n/build\n/build_*\n*.bzlc\n/ci/bazel-*\ncompile_commands.json\ncscope.*\n/docs/landing_source/.bundle\n/generated\n*.pyc\n**/pyformat\nSOURCE_VERSION\n*.swap*\ntags\nTAGS\n/test/coverage/BUILD\n/tools/spelling/.aspell.en.pws\nclang-tidy-fixes.yaml\nclang.bazelrc\nuser.bazelrc\nCMakeLists.txt\ncmake-build-debug\n/linux\nbazel.output.txt\n*~\n**/.DS_Store\n**/*.iml\ntools/dev/src\ndistribution/custom\nexamples/websocket/certs\n/contrib/golang/**/test_data/go.sum\n/contrib/golang/**/test_data/*/go.sum\n\nexamples/single-page-app/xds/lds.yml\n!examples/single-page-app/ui/.env\n# Logs\nlogs\n*.log\nnpm-debug.log*\nyarn-debug.log*\nyarn-error.log*\npnpm-debug.log*\nlerna-debug.log*\nnode_modules\ndist\n*.bak\n"
        },
        {
          "name": ".style.yapf",
          "type": "blob",
          "size": 0.52,
          "content": "# The Google Python styles can be found here: https://github.com/google/styleguide/blob/gh-pages/pyguide.md\n# TODO: Look into enforcing single vs double quote.\n[style]\nbased_on_style=Google\nindent_width=4\ncolumn_limit=100\nsplit_before_first_argument=True\ncoalesce_brackets=True\nsplit_before_logical_operator=True\nsplit_complex_comprehension=True\nsplit_before_expression_after_opening_paren=True\nsplit_before_dict_set_generator=True\nsplit_before_arithmetic_operator=True\nsplit_before_bitwise_operator=True\n# blank_line_before_nested_def_\n"
        },
        {
          "name": ".vscode",
          "type": "tree",
          "content": null
        },
        {
          "name": ".yamllint",
          "type": "blob",
          "size": 0.59,
          "content": "extends: default\n\nrules:\n  document-start: false\n  indentation:\n    spaces: consistent\n    indent-sequences: false\n  line-length:\n    # This can be adjusted if there is a very good reason.\n    max: 140\n    level: error\n    allow-non-breakable-words: true\n  truthy:\n    allowed-values:\n    - \"yes\"\n    - \"no\"\n    - \"true\"\n    - \"false\"\n    # https://github.com/adrienverge/yamllint/issues/430\n    - \"on\"\n    - \"off\"\n\nyaml-files:\n- .clang-format\n- \"*.yml\"\n- \"*.yaml\"\n\nignore:\n- \"**/*template.yaml\"\n- examples/single-page-app/_github-clusters.yml\n- test/config/integration/server_xds.cds.with_unknown_field.yaml\n"
        },
        {
          "name": ".yapfignore",
          "type": "blob",
          "size": 0.07,
          "content": "*generated*\n*venv*\n*protos*\n*~\n*_pb2.py\n*tests*\n*#*\n*intersphinx_custom.py\n"
        },
        {
          "name": "API_VERSION.txt",
          "type": "blob",
          "size": 0.01,
          "content": "3.0.0\n"
        },
        {
          "name": "BACKPORTS.md",
          "type": "blob",
          "size": 2.24,
          "content": "As documented in [RELEASES.md](RELEASES.md), the individual(s) on backports rotation are responsible for doing backports for security releases, and other qualifying backports.\n\nBackports rotation folks should make sure they have [triage](https://github.com/orgs/envoyproxy/teams/envoy-triage) rights (ask one of the [admins](https://github.com/orgs/envoyproxy/teams/admins) to give you access if you do not otherwise have it), and regularly triage [backports-review](https://github.com/pulls?q=+label%3Abackport%2Freview+) issues, either removing the backports-review tag and adding backports-approved, or pushing back in comments for why the issue does not qualify based on [RELEASES.md](RELEASES.md)\n\nFor approved PRs, the person on rotation should backport them to supported binaries, based on the support window also in [RELEASES.md](RELEASES.md)\n\nThe individual [branches](https://github.com/envoyproxy/envoy/branches) can be checked out per normal github workflow, and reviews for backport PRs sent to the original PR author and/or reviewers for approval.\n\nSee [#17814](https://github.com/envoyproxy/envoy/pull/17814) as an example backport, referencing the original PR\n\nSee the [fix lead checklist](https://docs.google.com/document/d/1cuU0m9hTQ73Te3i06-8LjQkFVn83IL22FbCoc_4IFEY/edit#heading=h.ioqzv16eyrfa) for git commands to backport an example patch.  Backports rotation assignee may or may not be the fix lead for a given security release.\n\nWhen the maintainer team kicks off a security release, the fix lead should add backports rotation to the release-specific slack channel for general coordination, and one of the [admins](https://github.com/orgs/envoyproxy/teams/admins) should grant access to [envoy-setec](https://github.com/envoyproxy/envoy-setec) repo.  As issues tagged [cve-next](https://github.com/envoyproxy/envoy-setec/issues?q=is%3Aissue+is%3Aopen+label%3Acve%2Fnext) are merged into main, the backports folks are responsible for backporting to the supported releases.  In this case, fix lead is responsible for kicking off the actual release branches.\n\nFor security backports best-practices include creating a patch per backport to make sure they individually pass CI, and then creating one rollup patch which is those patches combined, to make sure they merge cleanly.\n"
        },
        {
          "name": "BUILD",
          "type": "blob",
          "size": 1.72,
          "content": "load(\"//tools/python:namespace.bzl\", \"envoy_py_namespace\")\n\nlicenses([\"notice\"])  # Apache 2\n\nenvoy_py_namespace()\n\nexports_files([\n    \"VERSION.txt\",\n    \"API_VERSION.txt\",\n    \".clang-format\",\n    \"pytest.ini\",\n    \".coveragerc\",\n    \"CODEOWNERS\",\n    \"OWNERS.md\",\n    \".github/config.yml\",\n    \"reviewers.yaml\",\n])\n\nalias(\n    name = \"envoy\",\n    actual = \"//source/exe:envoy\",\n    visibility = [\"//visibility:public\"],\n)\n\nalias(\n    name = \"envoy.stripped\",\n    actual = \"//source/exe:envoy-static.stripped\",\n    visibility = [\"//visibility:public\"],\n)\n\nfilegroup(\n    name = \"clang_tidy_config\",\n    srcs = [\".clang-tidy\"],\n    visibility = [\"//visibility:public\"],\n)\n\n# These two definitions exist to help reduce Envoy upstream core code depending on extensions.\n# To avoid visibility problems, see notes in source/extensions/extensions_build_config.bzl\n#\n# TODO(#9953) //test/config_test:__pkg__ should probably be split up and removed.\n# TODO(#9953) the config fuzz tests should be moved somewhere local and //test/config_test and //test/server removed.\npackage_group(\n    name = \"extension_config\",\n    packages = [\n        \"//source/exe\",\n        \"//source/extensions/...\",\n        \"//test/config_test\",\n        \"//test/extensions/...\",\n        \"//test/server\",\n        \"//test/server/config_validation\",\n        \"//test/tools/...\",\n        \"//tools/extensions/...\",\n    ],\n)\n\npackage_group(\n    name = \"extension_library\",\n    packages = [\n        \"//source/extensions/...\",\n        \"//test/extensions/...\",\n    ],\n)\n\npackage_group(\n    name = \"contrib_library\",\n    packages = [\n        \"//contrib/...\",\n    ],\n)\n\npackage_group(\n    name = \"mobile_library\",\n    packages = [\n        \"//mobile/...\",\n    ],\n)\n\nexports_files([\n    \"rustfmt.toml\",\n])\n"
        },
        {
          "name": "CODEOWNERS",
          "type": "blob",
          "size": 20.46,
          "content": "# TODO(zuercher): determine how we want to deal with auto-assignment\n# By default, @envoyproxy/maintainers own everything.\n#*       @envoyproxy/maintainers\n\n# api\n/api/ @envoyproxy/api-shepherds\n\n# docs/examples\n/docs/ @envoyproxy/docs-shepherds\n/examples/ @envoyproxy/docs-shepherds\n/changelogs/ @envoyproxy/docs-shepherds\n\n# access loggers\n/*/extensions/access_loggers/common @auni53 @zuercher\n/*/extensions/access_loggers/open_telemetry @itamarkam @yanavlasov\n/*/extensions/access_loggers/stream @mattklein123 @davinci26\n# alternate protocols cache extensions\n/*/extensions/filters/http/alternate_protocols_cache @RyanTheOptimist @alyssawilk\n# csrf extension\n/*/extensions/filters/http/csrf @dschaller @mattklein123\n# original_src http filter extension\n/*/extensions/filters/http/original_src @klarose @mattklein123\n# original_src listener filter extension\n/*/extensions/filters/listener/original_src @klarose @mattklein123\n# original_src common extension\nextensions/filters/common/original_src @klarose @mattklein123\n# dubbo_proxy extension\n/*/extensions/filters/network/dubbo_proxy @zyfjeff @wbpcode\n# cdn_loop extension\n/*/extensions/filters/http/cdn_loop @justin-mp @penguingao @alyssawilk\n# external processing filter\n/*/extensions/filters/http/ext_proc @gbrail @stevenzzzz @tyxia @mattklein123 @yanavlasov @yanjunxiang-google\n/*/extensions/filters/common/mutation_rules @gbrail @tyxia @mattklein123 @yanavlasov\n# jwt_authn http filter extension\n/*/extensions/filters/http/jwt_authn @taoxuy @lizan @tyxia @yanavlasov\n# grpc_field_extraction http filter extension\n/*/extensions/filters/http/grpc_field_extraction @taoxuy @nareddyt @yanavlasov\n# proto_message_extraction http filter extension\n/*/extensions/filters/http/proto_message_extraction @dchakarwarti @taoxuy @shuoyang2016 @yanavlasov\n# grpc_http1_reverse_bridge http filter extension\n/*/extensions/filters/http/grpc_http1_reverse_bridge @zuercher @mattklein123\n# alts transport socket extension\n/*/extensions/transport_sockets/alts @adisuissa @matthewstevenson88\n# tcp_stats transport socket extension\n/*/extensions/transport_sockets/tcp_stats @ggreenway @mattklein123\n# tls transport socket extension\n/*/extensions/transport_sockets/tls @RyanTheOptimist @ggreenway @botengyao\n# tls SPIFFE certificate validator extension\n/*/extensions/transport_sockets/tls/cert_validator/spiffe @mathetake @botengyao @tyxia\n# proxy protocol socket extension\n/*/extensions/transport_sockets/proxy_protocol @alyssawilk @wez470\n# common transport socket\n/*/extensions/transport_sockets/common @alyssawilk @wez470\n# starttls transport socket\n/*/extensions/transport_sockets/starttls @cpakulski @botengyao @ggreenway\n# proxy transport socket\n/*extensions/transport_sockets/http_11_proxy @alyssawilk @ryantheoptimist\n# internal upstream transport socket\n/*/extensions/transport_sockets/internal_upstream @kyessenov @alyssawilk\n# sni_cluster extension\n/*/extensions/filters/network/sni_cluster @rshriram @ggreenway\n# sni_dynamic_forward_proxy extension\n/*/extensions/filters/network/sni_dynamic_forward_proxy @rshriram @soulxu\n# tracers.datadog extension\n/*/extensions/tracers/datadog @dmehala @mattklein123\n# tracers.xray extension\n/*/extensions/tracers/xray @suniltheta @mattklein123 @nbaws\n# tracers.skywalking extension\n/*/extensions/tracers/skywalking @wbpcode @Shikugawa\n# tracers.opentelemetry extension\n/*/extensions/tracers/opentelemetry @alexanderellis @yanavlasov\n# quic extension\n/*/extensions/quic/ @alyssawilk @danzh2010 @mattklein123 @mpwarres @wu-bin @ggreenway\n# UDP packet writer\n/*/extensions/udp_packet_writer/ @danzh2010 @RyanTheOptimist @alyssawilk\n# redis cluster extension\n/*/extensions/clusters/redis @msukalski @henryyyang @mattklein123 @weisisea\n/*/extensions/common/redis @msukalski @henryyyang @mattklein123 @weisisea\n/*/extensions/health_checkers/redis @weisisea @mattklein123\n/*/extensions/filters/network/redis_proxy @weisisea @mattklein123\n/*/extensions/filters/network/common/redis @weisisea @mattklein123\n# dynamic forward proxy\n/*/extensions/clusters/dynamic_forward_proxy @mattklein123 @alyssawilk\n/*/extensions/common/dynamic_forward_proxy @mattklein123 @alyssawilk\n/*/extensions/filters/http/dynamic_forward_proxy @mattklein123 @alyssawilk\n/*/extensions/filters/http/composite @mattklein123 @tyxia @yanavlasov\n# omit_canary_hosts retry predicate\n/*/extensions/retry/host/omit_canary_hosts @sriduth @mattklein123\n# previous hosts\n/*/extensions/retry/host/previous_hosts @alyssawilk @mattklein123\n# HTTP caching extension\n/*/extensions/filters/http/cache @toddmgreer @jmarantz @penguingao @mpwarres @capoferro\n/*/extensions/http/cache/simple_http_cache @toddmgreer @jmarantz @penguingao @mpwarres @capoferro\n# aws_iam grpc credentials\n/*/extensions/grpc_credentials/aws_iam @suniltheta @mattklein123 @nbaws\n/*/extensions/common/aws @suniltheta @mattklein123 @nbaws\n# adaptive concurrency limit extension.\n/*/extensions/filters/http/adaptive_concurrency @tonya11en @mattklein123\n# admission control extension.\n/*/extensions/filters/http/admission_control @tonya11en @mattklein123\n# http inspector\n/*/extensions/filters/listener/http_inspector @yxue @wbpcode\n# attribute context\n/*/extensions/filters/common/expr @kyessenov @yangminzhu @tyxia\n# webassembly access logger extensions\n/*/extensions/access_loggers/wasm @mpwarres @kyessenov @lizan\n# webassembly bootstrap extensions\n/*/extensions/bootstrap/wasm @mpwarres @kyessenov @lizan\n# webassembly http extensions\n/*/extensions/filters/http/wasm @mpwarres @kyessenov @lizan\n# webassembly network extensions\n/*/extensions/filters/network/wasm @mpwarres @kyessenov @lizan\n# webassembly common extension\n/*/extensions/common/wasm @mpwarres @kyessenov @lizan\n# webassembly runtimes\n/*/extensions/wasm_runtime/ @mpwarres @kyessenov @lizan\n# common matcher\n/*/extensions/common/matcher @mattklein123 @yangminzhu\n/*/extensions/common/proxy_protocol @alyssawilk @wez470\n/*/extensions/filters/http/grpc_http1_bridge @jose @mattklein123\n/*/extensions/filters/http/fault @rshriram @alyssawilk\n/*/extensions/filters/common/fault @rshriram @alyssawilk\n/*/extensions/filters/http/grpc_json_reverse_transcoder @numanelahi @yanavlasov\n/*/extensions/filters/http/grpc_json_transcoder @taoxuy @nareddyt @alyssawilk\n/*/extensions/filters/http/router @alyssawilk @mattklein123\n/*/extensions/filters/common/rbac/matchers @conqerAtapple @ggreenway @alyssawilk\n/*/extensions/filters/http/grpc_web @fengli79 @lizan @alyssawilk\n/*/extensions/filters/http/grpc_stats @kyessenov @botengyao @nezdolik\n/*/extensions/filters/http/connect_grpc_bridge @jchadwick-buf @mattklein123\n/*/extensions/filters/common/original_src @klarose @mattklein123\n/*/extensions/filters/listener/tls_inspector @ggreenway @KBaichoo\n/*/extensions/grpc_credentials/example @wozz @yanavlasov\n/*/extensions/grpc_credentials/file_based_metadata @wozz @yanavlasov\n/*/extensions/internal_redirect @alyssawilk @penguingao\n/*/extensions/stat_sinks/dog_statsd @taiki45 @jmarantz\n/*/extensions/stat_sinks/graphite_statsd @vaccarium @mattklein123\n/*/extensions/stat_sinks/hystrix @trabetti @jmarantz\n/*/extensions/stat_sinks/metrics_service @ramaraochavali @jmarantz\n/*/extensions/stat_sinks/open_telemetry @ohadvano @mattklein123\n# webassembly stat-sink extensions\n/*/extensions/stat_sinks/wasm @mpwarres @kyessenov @lizan\n/*/extensions/resource_monitors/injected_resource @eziskind @yanavlasov\n/*/extensions/resource_monitors/common @eziskind @yanavlasov @nezdolik\n/*/extensions/resource_monitors/fixed_heap @eziskind @yanavlasov @nezdolik\n/*/extensions/resource_monitors/downstream_connections @nezdolik @mattklein123\n/*/extensions/resource_monitors/cpu_utilization @cancecen @kbaichoo\n/*/extensions/retry/priority @alyssawilk @mattklein123\n/*/extensions/retry/priority/previous_priorities @alyssawilk @mattklein123\n/*/extensions/retry/host @alyssawilk @mattklein123\n/*/extensions/filters/network/http_connection_manager @alyssawilk @mattklein123\n/*/extensions/filters/network/tcp_proxy @alyssawilk @zuercher @ggreenway\n/*/extensions/filters/network/echo @yanavlasov @alyssawilk\n/*/extensions/filters/udp/dns_filter @mattklein123 @yanjunxiang-google\n/*/extensions/filters/network/direct_response @kyessenov @zuercher\n/*/extensions/filters/udp/udp_proxy @mattklein123 @danzh2010\n/*/extensions/clusters/aggregate @yxue @mattklein123\n# support for on-demand VHDS requests\n/*/extensions/filters/http/on_demand @dmitri-d @yanavlasov @kyessenov\n/*/extensions/filters/network/connection_limit @mattklein123 @alyssawilk @delong-coder\n/*/extensions/filters/http/aws_request_signing @derekargueta @suniltheta @mattklein123 @marcomagdy @nbaws\n/*/extensions/filters/http/aws_lambda @suniltheta @mattklein123 @marcomagdy @nbaws\n/*/extensions/filters/http/buffer @alyssawilk @mattklein123\n/*/extensions/transport_sockets/raw_buffer @alyssawilk @mattklein123\n# Watchdog Extensions\n/*/extensions/watchdog/profile_action @kbaichoo @alyssawilk\n# Core upstream code\nextensions/upstreams/http @alyssawilk @mattklein123\nextensions/upstreams/tcp @alyssawilk @ggreenway @mattklein123\n# OAuth2\nextensions/filters/http/oauth2 @derekargueta @mattklein123\n# HTTP Local Rate Limit\n/*/extensions/filters/http/local_ratelimit @mattklein123 @wbpcode\n/*/extensions/filters/common/local_ratelimit @mattklein123 @wbpcode\n# HTTP Kill Request\n/*/extensions/filters/http/kill_request @qqustc @yanavlasov\n# Rate limit expression descriptor\n/*/extensions/rate_limit_descriptors/expr @kyessenov @cpakulski\n# hash input matcher\n/*/extensions/matching/input_matchers/consistent_hashing @donyu @mattklein123\n# runtime fraction input matcher\n/*/extensions/matching/input_matchers/runtime_fraction @ravenblackx @sergkir85\n# CEL input matcher\n/*/extensions/matching/input_matchers/cel_matcher @tyxia @yanavlasov\n# dynamic metadata input matcher\n/*/extensions/matching/input_matchers/metadata @vikaschoudhary16 @kyessenov\n# environment generic input\n/*/extensions/matching/common_inputs/environment @donyu @mattklein123\n# format string matching\n/*/extensions/matching/actions/format_string @kyessenov @cpakulski\n# CEL data input\n/*/extensions/matching/http/cel_input @tyxia @yanavlasov\n# dynamic metadata input\n/*/extensions/matching/http/metadata_input @vikaschoudhary16 @kyessenov\n# user space socket pair, event, connection and listener\n/*/extensions/io_socket/user_space @kyessenov @lambdai @soulxu\n/*/extensions/bootstrap/internal_listener @kyessenov @adisuissa\n# Default UUID4 request ID extension\n/*/extensions/request_id/uuid @mattklein123 @alyssawilk\n# HTTP header formatters\n/*/extensions/http/header_formatters/preserve_case @mattklein123 @jmarantz\n# External Rate Limit\n/*/extensions/filters/common/ratelimit @esmet @mattklein123\n/*/extensions/filters/http/ratelimit @esmet @mattklein123\n/*/extensions/filters/network/ratelimit @esmet @mattklein123\n# HTTP Quota Based Rate Limit\n/*/extensions/filters/http/rate_limit_quota @tyxia @yanavlasov @bsurber\n# HTTP Bandwidth Limit\n/*/extensions/filters/http/bandwidth_limit @nitgoy @mattklein123 @yanavlasov @tonya11en\n# HTTP Basic Auth\n/*/extensions/filters/http/basic_auth @zhaohuabing @wbpcode\n# HTTP API Key Auth\n/*/extensions/filters/http/api_key_auth @wbpcode @sanposhiho\n# Original IP detection\n/*/extensions/http/original_ip_detection/custom_header @alyssawilk @mattklein123\n/*/extensions/http/original_ip_detection/xff @alyssawilk @mattklein123\n# set_filter_state extension\n/*/extensions/filters/common/set_filter_state @kyessenov @wbpcode\n/*/extensions/filters/http/set_filter_state @kyessenov @wbpcode\n/*/extensions/filters/network/set_filter_state @kyessenov @wbpcode\n# set_metadata extension\n/*/extensions/filters/http/set_metadata @aguinet @mattklein123\n# Formatters\n/*/extensions/formatter/metadata @cpakulski @ravenblackx @nezdolik\n/*/extensions/formatter/cel @kyessenov @zirain\n# IP address input matcher\n/*/extensions/matching/input_matchers/ip @aguinet @mattklein123\n# Key Value store\n/*/extensions/key_value @alyssawilk @ryantheoptimist\n# Config Validators\n/*/extensions/config/validators/minimum_clusters @adisuissa @yanavlasov\n# File system based extensions\n/*/extensions/common/async_files @mattklein123 @ravenblackx\n/*/extensions/filters/http/file_system_buffer @mattklein123 @ravenblackx\n/*/extensions/http/cache/file_system_http_cache @jmarantz @ravenblackx\n# Google Cloud Platform Authentication Filter\n/*/extensions/filters/http/gcp_authn @tyxia @yanavlasov\n# DNS resolution\n/*/extensions/network/dns_resolver/cares @yanavlasov @mattklein123\n/*/extensions/network/dns_resolver/apple @yanavlasov @mattklein123\n/*/extensions/network/dns_resolver/getaddrinfo @alyssawilk @mattklein123\n# compression code\n/*/extensions/filters/http/decompressor @kbaichoo @mattklein123\n/*/extensions/filters/http/compressor @kbaichoo @mattklein123\n/*/extensions/compression/brotli @kbaichoo @mattklein123\n/*/extensions/compression/common @kbaichoo @mattklein123\n/*/extensions/compression/gzip/decompressor @kbaichoo @mattklein123\n/*/extensions/compression/gzip/compressor @kbaichoo @mattklein123\n/*/extensions/compression/gzip/common @kbaichoo @mattklein123\n/*/extensions/compression/zstd @rainingmaster @mattklein123\n# cel\n/*/extensions/access_loggers/filters/cel @kyessenov @douglas-reid @adisuissa\n# health cehck\n/*/extensions/filters/http/health_check @mattklein123 @adisuissa\n# lua\n/*/extensions/filters/http/lua @mattklein123 @wbpcode\n/*/extensions/filters/common/lua @mattklein123 @wbpcode\n# rbac\n/*/extensions/filters/network/rbac @yangminzhu @yanavlasov\n/*/extensions/filters/http/rbac @yangminzhu @yanavlasov\n/*/extensions/filters/common/rbac @yangminzhu @yanavlasov\n# tap\n/*/extensions/filters/http/tap @mattklein123 @xu1zhou\n/*/extensions/common/tap @mattklein123 @xu1zhou\n/*/extensions/transport_sockets/tap @mattklein123 @xu1zhou\n# local rate limit\n/*/extensions/filters/network/local_ratelimit @mattklein123 @wbpcode\n/*/extensions/filters/listener/local_ratelimit @mattklein123 @JuniorHsu\n# proxy protocol\n/*/extensions/filters/listener/proxy_protocol @ggreenway @soulxu\n# access loggers\n/*/extensions/access_loggers/fluentd @ohadvano @wbpcode\n/*/extensions/access_loggers/grpc @wbpcode @cpakulski @giantcroc @gyohuangxin\n# stats\n/*/extensions/stat_sinks/statsd @mattklein123 @suniltheta\n/*/extensions/stat_sinks/common @mattklein123 @suniltheta\n/*/extensions/stat_sinks/common/statsd @mattklein123 @suniltheta\n# access loggers\n/*/extensions/access_loggers/file @wbpcode @cpakulski @giantcroc\n# Stateful session\n/*/extensions/http/stateful_session/cookie @wbpcode @cpakulski\n/*/extensions/http/stateful_session/header @ramaraochavali @wbpcode @cpakulski\n/*/extensions/filters/http/stateful_session @wbpcode @cpakulski @adisuissa\n# tracers\n/*/extensions/tracers/zipkin @wbpcode @Shikugawa @basvanbeek\n/*/extensions/tracers/dynamic_ot @wbpcode @Shikugawa @basvanbeek\n/*/extensions/tracers/common @wbpcode @Shikugawa @basvanbeek\n/*/extensions/tracers/common/ot @wbpcode @Shikugawa @basvanbeek\n# ext_authz\n/*/extensions/filters/common/ext_authz @esmet @tyxia @ggreenway\n/*/extensions/filters/http/ext_authz @esmet @tyxia @ggreenway\n/*/extensions/filters/network/ext_authz @esmet @tyxia @ggreenway\n# original dst\n/*/extensions/filters/listener/original_dst @kyessenov @cpakulski @lambdai @nezdolik\n# mongo proxy\n/*/extensions/filters/network/mongo_proxy @mythra @giantcroc @mattklein123\n# formatter\n/*/extensions/formatter/req_without_query @alyssawilk @tsaarni @giantcroc\n# cors\n/*/extensions/filters/http/cors @wbpcode @daixiang0\n# Header Validators\n/*/extensions/http/header_validators/envoy_default @yanavlasov @alyssawilk\n# Thrift\n/*/extensions/filters/network/thrift_proxy @zuercher @JuniorHsu\n/*/extensions/health_checkers/thrift @zuercher @JuniorHsu\n# Thrift to metadata\n/*/extensions/filters/http/thrift_to_metadata @JuniorHsu @zuercher\n# IP tagging\n/*/extensions/filters/http/ip_tagging @alyssawilk @JuniorHsu\n# Header to metadata\n/*/extensions/filters/http/header_to_metadata @zuercher @JuniorHsu\n# Json to metadata\n/*/extensions/filters/http/json_to_metadata @JuniorHsu @kbaichoo\n# zookeeper\n/*/extensions/filters/network/zookeeper_proxy @JuniorHsu @Winbobob @mattklein123\n# Custom response filter\n/*/extensions/filters/http/custom_response @pradeepcrao @yanavlasov\n/*/extensions/http/custom_response/redirect_policy @pradeepcrao @yanavlasov\n/*/extensions/http/custom_response/local_response_policy @pradeepcrao @yanavlasov\n# path match by pattern\n/*/extensions/path/match/uri_template @alyssawilk @yanjunxiang-google\n# path rewrite by pattern\n/*/extensions/path/rewrite/uri_template @alyssawilk @yanjunxiang-google\n# Dubbo codec\n/*/extensions/common/dubbo @wbpcode @UNOWNED\n# upstream load balancing policies\n/*/extensions/load_balancing_policies/common @wbpcode @tonya11en @nezdolik\n/*/extensions/load_balancing_policies/least_request @wbpcode @tonya11en @nezdolik\n/*/extensions/load_balancing_policies/random @wbpcode @tonya11en\n/*/extensions/load_balancing_policies/round_robin @wbpcode @tonya11en @nezdolik\n/*/extensions/load_balancing_policies/ring_hash @wbpcode @nezdolik\n/*/extensions/load_balancing_policies/maglev @wbpcode @nezdolik\n/*/extensions/load_balancing_policies/subset @wbpcode @zuercher @nezdolik\n/*/extensions/load_balancing_policies/cluster_provided @wbpcode @zuercher\n/*/extensions/load_balancing_policies/client_side_weighted_round_robin @wbpcode @adisuissa @efimki\n# Early header mutation\n/*/extensions/http/early_header_mutation/header_mutation @wbpcode @tyxia\n# Network matching extensions\n/*/extensions/matching/network/ @kyessenov @mattklein123\n# String matching extensions\n/*/extensions/string_matcher/ @ggreenway @cpakulski\n# Header mutation\n/*/extensions/filters/http/header_mutation @wbpcode @yanavlasov @soulxu\n# Health checkers\n/*/extensions/health_checkers/grpc @zuercher @botengyao\n/*/extensions/health_checkers/http @zuercher @botengyao\n/*/extensions/health_checkers/tcp @zuercher @botengyao\n/*/extensions/health_checkers/common @zuercher @botengyao\n# Health check event sinks\n/*/extensions/health_check/event_sinks/file @botengyao @yanavlasov\n# IP Geolocation\n/*/extensions/filters/http/geoip @nezdolik @ravenblackx\n/*/extensions/geoip_providers/common @nezdolik @ravenblackx\n# Maxmind geolocation provider\n/*/extensions/geoip_providers/maxmind @nezdolik @ravenblackx\n# Match delegate extension\n/*/extensions/filters/http/match_delegate @wbpcode @jstraceski @tyxia\n# Generic proxy and related extensions\n/*/extensions/filters/network/generic_proxy/ @wbpcode @soulxu\n# Dynamic Modules\n/*/extensions/dynamic_modules @mattklein123 @mathetake @marc-barry\n/*/extensions/filters/http/dynamic_modules @mattklein123 @mathetake @marc-barry\n\n# HTTP credential injector\n/*/extensions/filters/http/credential_injector @zhaohuabing @kyessenov\n/*/extensions/http/injected_credentials/common @zhaohuabing @kyessenov\n/*/extensions/http/injected_credentials/generic @zhaohuabing @kyessenov\n/*/extensions/http/injected_credentials/oauth2 @vikaschoudhary16 @wbpcode\n\n# Lua cluster specifier\n/*/extensions/router/cluster_specifiers/lua @StarryVae @wbpcode\n\n# Intentionally exempt (treated as core code)\n/*/extensions/filters/common @UNOWNED @UNOWNED\n/*/extensions/filters/http/common @UNOWNED @UNOWNED\n/*/extensions/filters/network/common @UNOWNED @UNOWNED\n/*/extensions/clusters/static @UNOWNED @UNOWNED\n/*/extensions/clusters/strict_dns @UNOWNED @UNOWNED\n/*/extensions/clusters/original_dst @UNOWNED @UNOWNED\n/*/extensions/clusters/logical_dns/ @UNOWNED @UNOWNED\n/*/extensions/clusters/common/ @UNOWNED @UNOWNED\n/*/extensions/clusters/eds/ @UNOWNED @UNOWNED\n/*/extensions/clusters/dns @UNOWNED @UNOWNED\n/*/source/extensions/listener_managers/listener_manager @alyssawilk @ggreenway\n/*/source/extensions/listener_managers/validation_listener_manager @alyssawilk @ggreenway\n/*/source/extensions/config_subscription/ @adisuissa @UNOWNED\n/*/source/extensions/config_subscription/grpc @adisuissa @UNOWNED\n\n# URL Pattern Match and Rewrite Library\n/*/extensions/path/uri_template_lib @alyssawilk @yanjunxiang-google\n/*/extensions/path/uri_template_lib/proto @alyssawilk @yanjunxiang-google\n\n# mobile\n/mobile/ @RyanTheOptimist @alyssawilk @abeyad @fredyw\n\n# Contrib\n/contrib/exe/ @mattklein123 @alyssawilk\n/contrib/client_ssl_auth/ @ggreenway @UNOWNED\n/contrib/checksum/ @ravenblackx @phlax\n/contrib/common/sqlutils/ @cpakulski @cpakulski\n/contrib/dynamo/ @UNOWNED @UNOWNED\n/contrib/golang/ @doujiang24 @wangfakang @StarryVae @spacewander @antJack\n/contrib/squash/ @yuval-k @alyssawilk\n/contrib/kafka/ @mattklein123 @adamkotwasinski\n/contrib/rocketmq_proxy/ @aaron-ai @lizhanhui\n/contrib/mysql_proxy/ @rshriram @venilnoronha\n/contrib/postgres_proxy/ @fabriziomello @cpakulski\n/contrib/sxg/ @cpapazian @alyssawilk\n/contrib/sip_proxy/ @durd07 @nearbyfly @dorisd0102\n/contrib/cryptomb/ @giantcroc @soulxu\n/contrib/vcl/ @florincoras @KfreeZ\n/contrib/hyperscan/ @zhxie @soulxu\n/contrib/language/ @realtimetodie @realtimetodie\n/contrib/dlb @mattklein123 @daixiang0\n/contrib/qat/ @giantcroc @soulxu\n/contrib/generic_proxy/ @wbpcode @UNOWNED\n"
        },
        {
          "name": "CODE_OF_CONDUCT.md",
          "type": "blob",
          "size": 0.14,
          "content": "## Community Code of Conduct\n\nEnvoy follows the [CNCF Code of Conduct](https://github.com/cncf/foundation/blob/master/code-of-conduct.md).\n"
        },
        {
          "name": "CONTRIBUTING.md",
          "type": "blob",
          "size": 22.14,
          "content": "We welcome contributions from the community. Please read the following guidelines carefully to\nmaximize the chances of your PR being merged.\n\n# Communication\n\n* Before starting work on a major feature, please reach out to us via GitHub, Slack,\n  email, etc. We will make sure no one else is already working on it and ask you to open a\n  GitHub issue.\n* A \"major feature\" is defined as any change that is > 100 LOC altered (not including tests), or\n  changes any user-facing behavior. We will use the GitHub issue to discuss the feature and come to\n  agreement. This is to prevent your time being wasted, as well as ours. The GitHub review process\n  for major features is also important so that [organizations with commit access](OWNERS.md) can\n  come to agreement on design. If it is appropriate to write a design document, the document must\n  be hosted either in the GitHub tracking issue, or linked to from the issue and hosted in a\n  world-readable location.\n* Specifically, if the goal is to add a new [extension](REPO_LAYOUT.md#sourceextensions-layout),\n  please read the [extension policy](GOVERNANCE.md#extension-addition-policy).\n* Small patches and bug fixes don't need prior communication.\n\n# Coding style\n\n* See [STYLE.md](STYLE.md)\n\n# Inclusive language policy\n\nThe Envoy community has an explicit goal to be inclusive to all. As such, all PRs must adhere to the\nfollowing guidelines for all code, APIs, and documentation:\n\n* The following words and phrases are not allowed:\n  * *Whitelist*: use allowlist instead.\n  * *Blacklist*: use denylist or blocklist instead.\n  * *Master*: use primary or main instead.\n  * *Slave*: use secondary or replica instead.\n* Documentation should be written in an inclusive style. The [Google developer\n  documentation](https://developers.google.com/style/inclusive-documentation) contains an excellent\n  reference on this topic.\n* The above policy is not considered definitive and may be amended in the future as industry best\n  practices evolve. Additional comments on this topic may be provided by maintainers during code\n  review.\n\n# Breaking change policy\n\nBoth API and implementation stability are important to Envoy. Since the API is consumed by clients\nbeyond Envoy, it has a distinct set of [versioning guidelines](api/API_VERSIONING.md). Below, we\narticulate the Envoy implementation stability rules, which operate within the context of the API\nversioning guidelines:\n\n* Features may be marked as deprecated in a given versioned API at any point in time, but this may\n  only be done when a replacement implementation and configuration path is available in Envoy on\n  main. Deprecators must implement a conversion from the deprecated configuration to the latest\n  `vNalpha` (with the deprecated field) that Envoy uses internally. A field may be deprecated if\n  this tool would be able to perform the conversion. For example, removing a field to describe\n  HTTP/2 window settings is valid if a more comprehensive HTTP/2 protocol options field is being\n  introduced to replace it. The PR author deprecating the old configuration is responsible for\n  updating all tests and canonical configuration, or guarding them with the\n  `DEPRECATED_FEATURE_TEST()` macro. This will be validated by the `bazel.compile_time_options`\n  target, which will hard-fail when deprecated configuration is used. The majority of tests and\n  configuration for a feature should be expressed in terms of the latest Envoy internal\n  configuration (i.e. `vNalpha`), only a minimal number of tests necessary to validate configuration\n  translation should be guarded via the `DEPRECATED_FEATURE_TEST()` macro.\n* We will delete deprecated configuration across major API versions. E.g. a field marked deprecated\n  in v2 will be removed in v3.\n* Unless the community and Envoy maintainer team agrees on an exception, during the\n  first release cycle after a feature has been deprecated, use of that feature\n  will cause a logged warning, and incrementing the\n  [runtime](https://www.envoyproxy.io/docs/envoy/latest/configuration/operations/runtime#statistics)\n  `runtime.deprecated_feature_use` stat.\n  During the second release cycle, use of the deprecated configuration will\n  cause a configuration load failure, unless the feature in question is\n  explicitly overridden in\n  [runtime](https://www.envoyproxy.io/docs/envoy/latest/configuration/operations/runtime#using-runtime-overrides-for-deprecated-features)\n  config ([example](configs/using_deprecated_config.yaml)), or if\n  `envoy.features.enable_all_deprecated_features` is set to true. Finally, following the deprecation\n  of the API major version where the field was first marked deprecated, the entire implementation\n  code will be removed from the Envoy implementation.\n* If the runtime key `envoy.features.fail_on_any_deprecated_feature` is enabled,\n  use of deprecated fields will trigger a configuration load failure\n  rather than a logged warning.\n* This policy means that organizations deploying main should have some time to get ready for\n  breaking changes at the next major API version. This is typically a window of at least 12 months\n  or until the organization moves to the next major API version.\n* The breaking change policy also applies to source level extensions (e.g., filters). Code that\n  conforms to the public interface documentation should continue to compile and work within the\n  deprecation window. Within this window, a warning of deprecation should be carefully logged (some\n  features might need rate limiting for logging this). We make no guarantees about code or deployments\n  that rely on undocumented behavior. See [extension removal policy](./EXTENSION_POLICY.md#removing-existing-extensions)\n  for more information.\n* All deprecations/breaking changes will be clearly listed in the [version history](docs/root/version_history/).\n* High risk deprecations/breaking changes may be announced to the\n  [envoy-announce](https://groups.google.com/forum/#!forum/envoy-announce) email list but by default\n  it is expected the multi-phase warn-by-default/fail-by-default is sufficient to warn users to move\n  away from deprecated features.\n\n# Submitting a PR\n\n* Fork the repo.\n* In your local repo, install the git hooks that implement various important pre-commit and\n  pre-push checks:\n\n  ```\n  ./support/bootstrap\n  ```\n\n  Please see [support/README.md](support/README.md) for more information on these hooks.\n\n* Create your PR. If your PR adds new code, it should include tests [covering](source/docs/coverage.md) the new code. Please note that draft PRs may not be reviewed and will likely not be triaged, so do not create your PR as a draft if you want prompt reviews!\n* Tests will automatically run for you.\n* We will **not** merge any PR that is not passing tests.\n* PRs are expected to have 100% test coverage for added code. This can be verified with a coverage\n  build. If your PR cannot have 100% coverage for some reason please clearly explain why when you\n  open it.\n* Any PR that changes user-facing behavior **must** have associated documentation in [docs](docs) as\n  well as [release notes](changelogs/current.yaml). API changes should be documented\n  inline with protos as per the [API contribution guidelines](api/CONTRIBUTING.md). If a change applies\n  to multiple sections of the release notes, it should be noted in the first (most important) section\n  that applies. For instance, a bug fix that introduces incompatible behavior should be noted in\n  `Incompatible Behavior Changes` but not in `Bug Fixes`.\n* All code comments and documentation are expected to have proper English grammar and punctuation.\n  If you are not a fluent English speaker (or a bad writer ;-)) please let us know and we will try\n  to find some help but there are no guarantees.\n* Your PR title should be descriptive, and generally start with a subsystem name followed by a\n  colon. Examples:\n  * \"docs: fix grammar error\"\n  * \"http conn man: add new feature\"\n* Your PR commit message will be used as the commit message when your PR is merged. You should\n  update this field if your PR diverges during review.\n* Your PR description should have details on what the PR does. If it fixes an existing issue it\n  should end with \"Fixes #XXX\".\n* If your PR is co-authored or based on an earlier PR from another contributor,\n  please attribute them with `Co-authored-by: name <name@example.com>`. See\n  GitHub's [multiple author\n  guidance](https://help.github.com/en/github/committing-changes-to-your-project/creating-a-commit-with-multiple-authors)\n  for further details.\n* When all of the tests are passing and all other conditions described herein are satisfied, a\n  maintainer will be assigned to review and merge the PR.\n* Once your PR is under review, *please do not rebase it*. If you rebase, you will need to force push to\n  github, and github's user interface will force your reviewer to review the PR\n  from scratch rather than simply look at your latest changes.  It's much easier to review\n  new commits and/or merges. We squash rebase the final merged commit so the number of commits\n  you have in the PR don't matter. Again once your PR is assigned a reviewer, unless you need to fix DCO\n  *please do not force push*.  If you need to pull recent changes you can run\n  ```\n  branch=$(git status|head -1|cut -f3 -d\\ )\n  git checkout main\n  git pull\n  git checkout \"$branch\"\n  git merge main\n  ```\n* We expect that once a PR is opened, it will be actively worked on until it is merged or closed.\n  We reserve the right to close PRs that are not making progress. This is generally defined as no\n  changes for 7 days. Obviously PRs that are closed due to lack of activity can be reopened later.\n  Closing stale PRs helps us to keep on top of all of the work currently in flight.\n* If a commit deprecates a feature, the commit message must mention what has been deprecated.\n  Additionally, the [version history](changelogs/current.yaml) must be updated with\n  relevant RST links for fields and messages as part of the commit.\n* Please consider joining the [envoy-dev](https://groups.google.com/forum/#!forum/envoy-dev)\n  mailing list.\n* If your PR involves any changes to\n  [envoy-filter-example](https://github.com/envoyproxy/envoy-filter-example) (for example making a new\n  branch so that CI can pass) it is your responsibility to follow through with merging those\n  changes back to main once the CI dance is done.\n* If your PR is a high risk change, the reviewer may ask that you runtime guard\n  it. See the section on runtime guarding below.\n\n\n# Runtime guarding\n\nSome changes in Envoy are deemed worthy of runtime guarding. Instead of just replacing\nold code with new code, both code paths are supported for between one Envoy release (if it is\nguarded due to performance concerns) and a full deprecation cycle (if it is a high risk behavioral\nchange). Generally as a community we try to guard both high risk changes (major\nrefactors such as replacing Envoy's buffer implementation) and most user-visible\nnon-config-guarded changes to protocol processing (for example additions or changes to HTTP headers or\nhow HTTP is serialized out) for non-alpha features. Feel free to tag @envoyproxy/maintainers\nif you aren't sure if a given change merits runtime guarding.\n\nThe canonical way to runtime guard a feature is\n```\nif (Runtime::runtimeFeatureEnabled(\"envoy.reloadable_features.my_feature_name\")) {\n  [new code path]\n} else {\n  [old_code_path]\n}\n```\nRuntime guarded features named with the \"envoy.reloadable_features.\" prefix must be safe to flip\ntrue or false on running Envoy instances. In some situations it may make more sense to\nlatch the value in a member variable on class creation, for example:\n\n```\nbool use_new_code_path_ =\n    Runtime::runtimeFeatureEnabled(\"envoy.reloadable_features.my_feature_name\")\n```\n\nThis should only be done if the lifetime of the object in question is relatively short compared to\nthe lifetime of most Envoy instances, i.e. latching state on creation of the\nHttp::ConnectionManagerImpl or all Network::ConnectionImpl classes, to ensure that the new behavior\nwill be exercised as the runtime value is flipped, and that the old behavior will trail off over\ntime.\n\nRuntime guarded features may either set true (running the new code by default) in the initial PR,\nafter a testing interval, or during the next release cycle, at the PR author's and reviewing\nmaintainer's discretion. Generally all runtime guarded features will be set true when a\nrelease is cut. Old code paths for refactors can be cleaned up after a release and there has been\nsome production run time. Old code for behavioral changes will be deprecated after six months if no\nEnvoy operators have raised concerns. If the behavioral change is problematic for any Envoy users,\nthe maintainers team will work to find a satisfactory resolution, generally in the form of a permanent\nconfiguration knob for the behavioral differences.\n\nRuntime features are set true by default by inclusion in\n[source/common/runtime/runtime_features.cc](https://github.com/envoyproxy/envoy/blob/main/source/common/runtime/runtime_features.cc)\n\nThere are four suggested options for testing new runtime features:\n\n1. Create a per-test Runtime::LoaderSingleton as done in [DeprecatedFieldsTest.IndividualFieldDisallowedWithRuntimeOverride](https://github.com/envoyproxy/envoy/blob/main/test/common/protobuf/utility_test.cc)\n2. Create a [parameterized test](https://github.com/google/googletest/blob/master/docs/advanced.md#how-to-write-value-parameterized-tests)\n   where the set up of the test sets the new runtime value explicitly to\n   GetParam() as outlined in (1).\n3. Set up integration tests with custom runtime defaults as documented in the\n   [integration test README](https://github.com/envoyproxy/envoy/blob/main/test/integration/README.md)\n4. Run a given unit test with the new runtime value explicitly set true or false as done\n   for [runtime_flag_override_test](https://github.com/envoyproxy/envoy/blob/main/test/common/runtime/BUILD)\n\nRuntime code is held to the same standard as regular Envoy code, so both the old\npath and the new should have 100% coverage both with the feature defaulting true\nand false.\n\nPlease note that if adding a runtime guarded feature, your [release notes](changelogs/current.yaml) should include both the functional change, and how to revert it, for example\n\n```yaml\n- area: config\n  change: |\n      type URL is used to lookup extensions regardless of the name field. This may cause problems for empty filter configurations or mis-matched protobuf as the typed configurations. This behavioral change can be temporarily reverted by setting runtime guard ``envoy.reloadable_features.no_extension_lookup_by_name`` to false.\n```\n\n# PR review policy for maintainers\n\n* Typically we try to turn around reviews within one business day.\n* See [OWNERS.md](OWNERS.md) for the current list of maintainers.\n* It is generally expected that a senior maintainer should review every PR to\n  core code. Changes which only touch tests, extensions, tools, docs or comments\n  need only be reviewed by a maintainer, or senior extension maintainer.\n* It is also generally expected that a \"domain expert\" for the code the PR touches should review the\n  PR. This person does not necessarily need to have commit access.\n* For new extensions (contrib or otherwise) and features, at least one of the approvals should be *from an\n  organization different from the PR author.* E.g., if Lyft authors a PR, at least one approver\n  should be from an organization other than Lyft. This helps us make sure that we aren't putting\n  organization specific shortcuts into the code.\n  new HTTP/3 features are largely exempt from cross-company approvals as all of the\n  area experts work at a single company, but HTTP/3 changes which impact general\n  functionality still merit a cross-company check.\n* contrib extensions do not need senior maintainer or maintainer review only contrib owner review and\n  a maintainer stamp to merge.\n* If there is a question on who should review a PR please discuss in Slack.\n* Anyone is welcome to review any PR that they want, whether they are a maintainer or not.\n* Please make sure that the PR title, commit message, and description are updated if the PR changes\n  significantly during review.\n* Please **clean up the title and body** before merging. By default, GitHub fills the squash merge\n  title with the original title, and the commit body with every individual commit from the PR.\n  The maintainer doing the merge should make sure the title follows the guidelines above and should\n  overwrite the body with the original commit message from the PR (cleaning it up if necessary)\n  while preserving the PR author's final DCO sign-off.\n* If a PR includes a deprecation/breaking change, notification should be sent to the\n  [envoy-announce](https://groups.google.com/forum/#!forum/envoy-announce) email list.\n\n# API changes\n\nIf you change anything in the [api tree](https://github.com/envoyproxy/envoy/tree/main/api),\nplease read the [API Review\nChecklist](https://github.com/envoyproxy/envoy/tree/main/api/review_checklist.md)\nand make sure that your changes have addressed all of the considerations listed there.\n\n# Adding new extensions\n\nFor developers adding a new extension, one can take an existing extension as the starting point.\n\nExtension configuration should be located in a directory structure like\n`api/envoy/extensions/area/plugin/`, for example `api/envoy/extensions/access_loggers/file/`\n\nThe code for the extension should be located under the equivalent\n`source/extensions/area/plugin`, and include an *envoy_cc_extension* with the\nconfiguration and tagged with the appropriate security posture, and an\n*envoy_cc_library* with the code.\n\nMore details on how to add a new extension API can be found [here](api/STYLE.md#adding-an-extension-configuration-to-the-api):\n\n# Adding contrib extensions\n\nSee [EXTENSION_POLICY.md](EXTENSION_POLICY.md) for more information on contrib. Adding a contrib\nextension mostly mirrors adding a normal extension above. Some differences are noted here:\n\n* API files should be added in `api/contrib/envoy/`, but the protos' namespaces should still be as\n  in normal extensions (which will make file movement easier later if the extension gets promoted\n  to core).\n* Build config and metadata should be included in [contrib/contrib_build_config.bzl](contrib/contrib_build_config.bzl)\n  and [contrib/extensions_metadata.yaml](contrib/extensions_metadata.yaml).\n* An entrypoint should be added in `docs/root/api-v3/config/contrib/contrib.rst`\n\n# DCO: Sign your work\n\nEnvoy ships commit hooks that allow you to auto-generate the DCO signoff line if\nit doesn't exist when you run `git commit`. Simply navigate to the Envoy project\nroot and run:\n\n```bash\n./support/bootstrap\n```\n\nFrom here, simply commit as normal, and you will see the signoff at the bottom\nof each commit.\n\nThe sign-off is a simple line at the end of the explanation for the\npatch, which certifies that you wrote it or otherwise have the right to\npass it on as an open-source patch. The rules are pretty simple: if you\ncan certify the below (from\n[developercertificate.org](https://developercertificate.org/)):\n\n```\nDeveloper Certificate of Origin\nVersion 1.1\n\nCopyright (C) 2004, 2006 The Linux Foundation and its contributors.\n660 York Street, Suite 102,\nSan Francisco, CA 94110 USA\n\nEveryone is permitted to copy and distribute verbatim copies of this\nlicense document, but changing it is not allowed.\n\n\nDeveloper's Certificate of Origin 1.1\n\nBy making a contribution to this project, I certify that:\n\n(a) The contribution was created in whole or in part by me and I\n    have the right to submit it under the open source license\n    indicated in the file; or\n\n(b) The contribution is based upon previous work that, to the best\n    of my knowledge, is covered under an appropriate open source\n    license and I have the right under that license to submit that\n    work with modifications, whether created in whole or in part\n    by me, under the same open source license (unless I am\n    permitted to submit under a different license), as indicated\n    in the file; or\n\n(c) The contribution was provided directly to me by some other\n    person who certified (a), (b) or (c) and I have not modified\n    it.\n\n(d) I understand and agree that this project and the contribution\n    are public and that a record of the contribution (including all\n    personal information I submit with it, including my sign-off) is\n    maintained indefinitely and may be redistributed consistent with\n    this project or the open source license(s) involved.\n```\n\nthen you just add a line to every git commit message:\n\n    Signed-off-by: Joe Smith <joe@gmail.com>\n\nusing your real name (sorry, no pseudonyms or anonymous contributions.)\n\nYou can add the sign off when creating the git commit via `git commit -s`.\n\nIf you want this to be automatic you can set up some aliases:\n\n```bash\ngit config --add alias.amend \"commit -s --amend\"\ngit config --add alias.c \"commit -s\"\n```\n\n## Fixing DCO\n\nIf your PR fails the DCO check, it's necessary to fix the entire commit history in the PR. Best\npractice is to [squash](https://gitready.com/advanced/2009/02/10/squashing-commits-with-rebase.html)\nthe commit history to a single commit, append the DCO sign-off as described above, and [force\npush](https://git-scm.com/docs/git-push#git-push---force). For example, if you have 2 commits in\nyour history:\n\n```bash\ngit rebase -i HEAD^^\n(interactive squash + DCO append)\ngit push origin -f\n```\n\nNote, that in general rewriting history in this way is a hindrance to the review process and this\nshould only be done to correct a DCO mistake.\n\n## Triggering CI re-run without making changes\n\nTo rerun failed tasks in Azure pipelines, add a comment with the line\n\n```\n/retest\n```\n\nin it. This should rebuild only the failed tasks.\n\nSometimes tasks will be stuck in CI and won't be marked as failed, which means\nthe above command won't work. Should this happen, pushing an empty commit should\nre-run all the CI tasks. Consider adding an alias into your `.gitconfig` file:\n\n```\n[alias]\n    kick-ci = !\"git commit -s --allow-empty -m 'Kick CI' && git push\"\n```\n\nOnce you add this alias you can issue the command `git kick-ci` and the PR\nwill be sent back for a retest.\n\n# Repo Etiquette\n\nContributors with push-access to the Envoy project should prefer pushing changes to a personal fork,\nincluding when creating branches for pull requests.\n\nThis helps keep the Envoy repo as lean as possible, which can speed up cloning and synchronizing\noperations for both developers and CI.\n"
        },
        {
          "name": "DCO",
          "type": "blob",
          "size": 1.39,
          "content": "Developer Certificate of Origin\nVersion 1.1\n\nCopyright (C) 2004, 2006 The Linux Foundation and its contributors.\n1 Letterman Drive\nSuite D4700\nSan Francisco, CA, 94129\n\nEveryone is permitted to copy and distribute verbatim copies of this\nlicense document, but changing it is not allowed.\n\n\nDeveloper's Certificate of Origin 1.1\n\nBy making a contribution to this project, I certify that:\n\n(a) The contribution was created in whole or in part by me and I\n    have the right to submit it under the open source license\n    indicated in the file; or\n\n(b) The contribution is based upon previous work that, to the best\n    of my knowledge, is covered under an appropriate open source\n    license and I have the right under that license to submit that\n    work with modifications, whether created in whole or in part\n    by me, under the same open source license (unless I am\n    permitted to submit under a different license), as indicated\n    in the file; or\n\n(c) The contribution was provided directly to me by some other\n    person who certified (a), (b) or (c) and I have not modified\n    it.\n\n(d) I understand and agree that this project and the contribution\n    are public and that a record of the contribution (including all\n    personal information I submit with it, including my sign-off) is\n    maintained indefinitely and may be redistributed consistent with\n    this project or the open source license(s) involved.\n"
        },
        {
          "name": "DEPENDENCY_POLICY.md",
          "type": "blob",
          "size": 9.35,
          "content": "# Envoy External Dependency Policy\n\nEnvoy has an evolving policy on external dependencies, tracked at\nhttps://github.com/envoyproxy/envoy/issues/10471. This will become stricter over time, below we\ndetail the policy as it currently applies.\n\n## External dependencies dashboard\n\nThe list of external dependencies in Envoy with their current version is available at\nhttps://www.envoyproxy.io/docs/envoy/latest/intro/arch_overview/security/external_deps\n\n## Declaring external dependencies\n\nIn general, all external dependencies for the Envoy proxy binary build and test should be declared\nin either [bazel/repository_locations.bzl](bazel/repository_locations.bzl) or\n[api/bazel/repository_locations.bzl](api/bazel/repository_locations.bzl), unless listed under\n[policy exceptions](#policy-exceptions).\n\nAn example entry for the `nghttp2` dependency is:\n\n```python\ncom_github_nghttp2_nghttp2 = dict(\n    project_name = \"Nghttp2\",\n    project_desc = \"Implementation of HTTP/2 and its header compression ...\",\n    project_url = \"https://nghttp2.org\",\n    version = \"1.41.0\",\n    sha256 = \"eacc6f0f8543583ecd659faf0a3f906ed03826f1d4157b536b4b385fe47c5bb8\",\n    strip_prefix = \"nghttp2-{version}\",\n    urls = [\"https://github.com/nghttp2/nghttp2/releases/download/v{version}/nghttp2-{version}.tar.gz\"],\n    use_category = [\"dataplane\"],\n    last_updated = \"2020-06-02\",\n    cpe = \"cpe:2.3:a:nghttp2:nghttp2:*\",\n),\n```\n\nDependency declarations must:\n\n* Provide a meaningful project name and URL.\n* State the version in the `version` field. String interpolation should be used in `strip_prefix`\n  and `urls` to reference the version. If you need to reference version `X.Y.Z` as `X_Y_Z`, this\n  may appear in a string as `{underscore_version}`, similarly for `X-Y-Z` you can use\n  `{dash_version}`.\n* Versions should prefer release versions over main branch GitHub SHA tarballs. A comment is\n  necessary if the latter is used. This comment should contain the reason that a non-release\n  version is being used.\n* Provide accurate entries for `use_category`. Please think carefully about whether there are data\n  or control plane implications of the dependency.\n* Reflect the UTC date (YYYY-MM-DD format) for the dependency release. This is when\n  the dependency was updated in its repository. For dependencies that have\n  releases, this is the date of the release. For dependencies without releases\n  or for scenarios where we temporarily need to use a commit, this date should\n  be the date of the commit in UTC.\n* CPEs are compulsory for all dependencies that are not purely build/test.\n  [CPEs](https://en.wikipedia.org/wiki/Common_Platform_Enumeration) provide metadata that allow us\n  to correlate with related CVEs in dashboards and other tooling, and also provide a machine\n  consumable join key. You can consult [CPE\n  search](https://nvd.nist.gov/products/cpe/search) to find a CPE for a dependency.`\"N/A\"` should only\n  be used if no CPE for the project is available in the CPE database. CPEs should be _versionless_\n  with a `:*` suffix, since the version can be computed from `version`.\n\nWhen build or test code references Python modules, they should be specified via `pip_install` in\n[bazel/repositories_extra.bzl](bazel/repositories_extra.bzl). Python modules should not be listed in\n`repository_locations.bzl` entries. `requirements.txt` files for Python dependencies must pin to\nexact versions, e.g. `PyYAML==5.4.1` and ideally also include a [SHA256\nchecksum](https://davidwalsh.name/hashin).\n\nPure developer tooling and documentation builds may reference Python via standalone\n`requirements.txt`, following the above policy.\n\n## New external dependencies\n\nAny new dependency on the Envoy data or control plane that impacts Envoy core (i.e. is not\nspecific to a single non-core extension) must be cleared with the Envoy dependency shepherds and\nsecurity team, please file an issue and tag both [dependency\nshepherds](https://github.com/orgs/envoyproxy/teams/dependency-shepherds) and\nthe [@envoyproxy/security-team](https://github.com/orgs/envoyproxy/teams/security-team).\n\nThe criteria below are used to evaluate new dependencies on the data, control\nand observability plane. They apply to all core dependencies and any extension\nthat is robust to untrusted downstream or upstream traffic. The criteria are\nguidelines, exceptions may be granted with solid rationale. Precedent from\nexisting extensions does not apply; there are extant extensions in violation of\nthis policy which we will be addressing over time, they do not provide grounds\nto ignore policy criteria below.\n\n|Criteria|Requirement|Mnemonic|Weight|Rationale|\n|--------|-----------|--------|------|---------|\n|Cloud Native Computing Foundation (CNCF) [approved license](https://github.com/cncf/foundation/blob/master/allowed-third-party-license-policy.md#approved-licenses-for-allowlist)|MUST|License|High||\n|Dependencies must not substantially increase the binary size unless they are optional (i.e. confined to specific extensions)|MUST|BinarySize|High|Envoy Mobile is sensitive to binary size. We should pick dependencies that are used in core with this criteria in mind.|\n|No duplication of existing dependencies|MUST|NoDuplication|High|Avoid maintenance cost of multiple JSON parsers etc|\n|Hosted on a git repository and the archive fetch must directly reference this repository. We will NOT support intermediate artifacts built by-hand located on GCS, S3, etc.|MUST|Source|High|Flows based on manual updates are fragile (they are not tested until needed), often suffer from missing documentation and shared exercise, may fail during emergency zero day updates and have no audit trail (i.e. it's unclear how the artifact we depend upon came to be at a later date).|\n|CVE history appears reasonable, no pathological CVE arcs|MUST|SoundCVEs|High|Avoid dependencies that are CVE heavy in the same area (e.g. buffer overflow)\n|Code review (ideally PRs) before merge|MUST|Code-Review|Normal|Consistent code reviews|\n|Security vulnerability process exists, with contact details and reporting/disclosure process|MUST|SecPolicy|High|Lack of a policy implies security bugs are open zero days|\n|> 1 contributor responsible for a non-trivial number of commits|MUST|Contributors|Normal|Avoid bus factor of 1|\n|Tests run in CI|MUST|CI-Tests|Normal|Changes gated on tests|\n|High test coverage (also static/dynamic analysis, fuzzing)|SHOULD|Test-Coverage|Normal|Key dependencies must meet the same quality bar as Envoy|\n|Envoy can obtain advanced notification of vulnerabilities or of security releases|SHOULD|SecPolicy-Compat|High|Coordinated security releases possible, but most dependencies do not feature this.|\n|Do other significant projects have shared fate by using this dependency?|SHOULD|SharedFate|High|Increased likelihood of security community interest, many eyes.|\n|Releases (with release notes)|SHOULD|Releases|Normal|Discrete upgrade points, clear understanding of security implications. We have many counterexamples today (e.g. CEL, re2).|\n|Commits/releases in last 90 days|SHOULD|Active|Normal|Avoid unmaintained deps, not compulsory since some code bases are “done”|\n\nThe rationale behind this policy is tracked\n[here](https://docs.google.com/document/d/1HbREo7pv7rgeIIjQn6mNpySzQE5rx2Yv9dXm5NqR2N8/edit#).\n\n## Maintaining existing dependencies\n\nWe rely on community volunteers to help track the latest versions of dependencies. On a best effort\nbasis:\n\n* Core Envoy dependencies will be updated by the Envoy maintainers/security team.\n\n* Extension [CODEOWNERS](CODEOWNERS) should update extension specific dependencies.\n\nWhere possible, we prefer the latest release version for external dependencies, rather than main\nbranch GitHub SHA tarballs.\n\nAvailable updates for most of our dependencies can be tracked on the Github issue tracker here:\n\nhttps://github.com/envoyproxy/envoy/issues?q=is%3Aissue+is%3Aopen+newer+release+available\n\nIf you intend to update a dependency, please assign the relevant ticket to yourself and/or associate\nany Pull Request (eg by adding `Fix #1234`) with the issue.\n\n## Dependency shepherds\n\nSign-off from the [dependency\nshepherds](https://github.com/orgs/envoyproxy/teams/dependency-shepherds) is\nrequired for every PR that modifies external dependencies. The shepherds will\nlook to see that the policy in this document is enforced and that metadata is\nkept up-to-date.\n\n## Dependency patches\n\nOccasionally it is necessary to introduce an Envoy-side patch to a dependency in a `.patch` file.\nThese are typically applied in [bazel/repositories.bzl](bazel/repositories.bzl). Our policy on this\nis as follows:\n\n* Patch files impede dependency updates. They are expedient at creation time but are a maintenance\n  penalty. They reduce the velocity and increase the effort of upgrades in response to security\n  vulnerabilities in external dependencies.\n\n* No patch will be accepted without a sincere and sustained effort to upstream the patch to the\n  dependency's canonical repository.\n\n* There should exist a plan-of-record, filed as an issue in Envoy or the upstream GitHub tracking\n  elimination of the patch.\n\n* Every patch must have comments at its point-of-use in [bazel/repositories.bzl](bazel/repositories.bzl)\n  providing a rationale and detailing the tracking issue.\n\n## Policy exceptions\n\nThe following dependencies are exempt from the policy:\n\n* Any developer-only facing tooling or the documentation build.\n\n* Transitive build time dependencies, e.g. Go projects vendored into\n  [protoc-gen-validate](https://github.com/bufbuild/protoc-gen-validate).\n"
        },
        {
          "name": "DEPRECATED.md",
          "type": "blob",
          "size": 0.18,
          "content": "# DEPRECATED\n\nThe [deprecated log](https://www.envoyproxy.io/docs/envoy/latest/version_history/version_history)\nfor each version can be found in the official Envoy developer documentation.\n"
        },
        {
          "name": "DEVELOPER.md",
          "type": "blob",
          "size": 2.5,
          "content": "# Developer documentation\n\nEnvoy is built using the Bazel build system. Our CI on Azure Pipelines builds, tests, and runs coverage against\nall pull requests and the main branch.\n\nTo get started building Envoy locally, see the [Bazel quick start](https://github.com/envoyproxy/envoy/blob/main/bazel/README.md#quick-start-bazel-build-for-developers).\nTo run tests, there are Bazel [targets](https://github.com/envoyproxy/envoy/blob/main/bazel/README.md#testing-envoy-with-bazel) for Google Test.\nTo generate a coverage report, there is a [coverage build script](https://github.com/envoyproxy/envoy/blob/main/bazel/README.md#coverage-builds).\n\nIf you plan to contribute to Envoy, you may find it useful to install the Envoy [development support toolchain](https://github.com/envoyproxy/envoy/blob/main/support/README.md), which helps automate parts of the development process, particularly those involving code review.\n\nBelow is a list of additional documentation to aid the development process:\n\n- [General build and installation documentation](https://www.envoyproxy.io/docs/envoy/latest/start/start)\n\n- [Building and testing Envoy with Bazel](https://github.com/envoyproxy/envoy/blob/main/bazel/README.md)\n\n- [Managing external dependencies with Bazel](https://github.com/envoyproxy/envoy/blob/main/bazel/EXTERNAL_DEPS.md)\n\n- [Guide to Envoy Bazel rules (managing `BUILD` files)](https://github.com/envoyproxy/envoy/blob/main/bazel/DEVELOPER.md)\n\n- [Guide to setup development environment with Visual Studio Code](https://github.com/envoyproxy/envoy/blob/main/tools/vscode/README.md)\n\n- [Using Docker for building and testing](https://github.com/envoyproxy/envoy/tree/main/ci#readme)\n\n- [Guide to contributing to Envoy](https://github.com/envoyproxy/envoy/blob/main/CONTRIBUTING.md)\n\n- [Overview of Envoy's testing frameworks](https://github.com/envoyproxy/envoy/blob/main/test/README.md)\n\n- [Overview of how to write integration tests for new code](https://github.com/envoyproxy/envoy/blob/main/test/integration/README.md)\n\n- [Envoy filter example project (how to consume and extend Envoy as a submodule)](https://github.com/envoyproxy/envoy-filter-example#readme)\n\n- [Performance testing Envoy with `tcmalloc`/`pprof`](https://github.com/envoyproxy/envoy/blob/main/bazel/PPROF.md)\n\nAnd some documents on components of Envoy architecture:\n\n- [Envoy flow control](https://github.com/envoyproxy/envoy/blob/main/source/docs/flow_control.md)\n\n- [Envoy's subset load balancer](https://github.com/envoyproxy/envoy/blob/main/source/docs/subset_load_balancer.md)\n"
        },
        {
          "name": "EXTENSION_POLICY.md",
          "type": "blob",
          "size": 10.19,
          "content": "# Envoy Extension Policy\n\n## Quality requirements\n\nAll extensions contained in the main Envoy repository will be held to the same quality bar as the\ncore Envoy code. This includes coding style, code reviews, test coverage, etc. In the future we\nmay consider creating a sandbox repository for extensions that are not compiled/tested by default\nand held to a lower quality standard, but that is out of scope currently.\n\n## Adding new extensions\n\nThe following procedure will be used when proposing new extensions for inclusion in the repository:\n  1. A GitHub issue should be opened describing the proposed extension as with any major feature\n  proposal.\n  2. All extensions must be sponsored by an existing maintainer. Sponsorship means that the\n  maintainer will shepherd the extension through design/code reviews. Maintainers can self-sponsor\n  extensions if they are going to write them, shepherd them, and maintain them.\n\n     Sponsorship serves two purposes:\n     * It ensures that the extension will ultimately meet the Envoy quality bar.\n     * It makes sure that incentives are aligned and that extensions are not added to the repo without\n     sufficient thought put into future maintenance.\n\n     *If sponsorship cannot be found from an existing maintainer, an organization can consider\n     [doing the work to become a maintainer](./GOVERNANCE.md#process-for-becoming-a-maintainer) in\n     order to be able to self-sponsor extensions.*\n\n  3. Each extension must have two reviewers proposed for reviewing PRs to the extension. Neither of\n  the reviewers must be a senior maintainer. Existing maintainers (including the sponsor) and other\n  contributors can count towards this number. The initial reviewers will be codified in the\n  [CODEOWNERS](./CODEOWNERS) file for long term maintenance. These reviewers can be swapped out as\n  needed.\n  4. Any extension added via this process becomes a full part of the repository. This means that any\n  API breaking changes in the core code will be automatically fixed as part of the normal PR process\n  by other contributors.\n  5. Any new dependencies added for this extension must comply with\n  [DEPENDENCY_POLICY.md](DEPENDENCY_POLICY.md), please follow the steps detailed there.\n  6. If an extension depends on platform specific functionality, be sure to guard it in the build\n  system. See [platform specific features](./PULL_REQUESTS.md#platform-specific-features).\n  Add the extension to the necessary `*_SKIP_TARGETS` in [bazel/repositories.bzl](bazel/repositories.bzl)\n  and tag tests to be skipped/failed on the unsupported platform.\n\n## Removing existing extensions\n\nAs stated in the previous section, once an extension becomes part of the repository it will be\nmaintained by the collective set of Envoy contributors as needed.\n\nHowever, if an extension has known issues that are not being rectified by the original sponsor and\nreviewers or new contributors that are willing to step into the role of extension owner, a\n[vote of the maintainers](./GOVERNANCE.md#conflict-resolution-and-voting) can be called to remove the\nextension from the repository.\n\nExtension removal process:\n\n  1. A GitHub Issue is opened listing the reason for extension removal and any available replacements.\n  2. Extension factory is modified to emit a deprecation warning.\n  3. This starts a 6 month deprecation interval, after which extension is decommissioned.\n  4. An announcement about extension deprecation is sent to the\n     [envoy-announce](https://groups.google.com/forum/#!forum/envoy-announce) email list, with the\n     instruction to comment on the GitHub issue to extend the deprecation interval. Heavily used\n     extensions may have their deprecation interval extended by 6 more months.\n  5. After the deprecation interval has expired the extension source code is removed.\n\n## Extension pull request reviews\n\nExtension PRs must not modify core Envoy code. In the event that an extension requires changes to core\nEnvoy code, those changes should be submitted as a separate PR and will undergo the normal code review\nprocess, as documented in the [contributor's guide](./CONTRIBUTING.md).\n\nExtension PRs must be approved by at least one sponsoring maintainer and an extension reviewer. These\nmay be a single individual, but it is always preferred to have multiple reviewers when feasible.\n\nIn the event that the Extension PR author is a sponsoring maintainer and no other sponsoring maintainer\nis available, another maintainer may be enlisted to perform a minimal review for style and common C++\nanti-patterns. The Extension PR must still be approved by a non-maintainer reviewer.\n\n## Wasm extensions\n\nWasm extensions are not allowed in the main envoyproxy/envoy repository unless\npart of the Wasm implementation validation. The rationale for this policy:\n* Wasm extensions should not depend upon Envoy implementation specifics as\n  they exist behind a version independent ABI. Hence, there is little value in\n  qualifying Wasm extensions in the main repository.\n* Wasm extensions introduce extensive dependencies via crates, etc. We would\n  prefer to keep the envoyproxy/envoy repository dependencies minimal, easy\n  to reason about and maintain.\n* We do not implement any core extensions in Wasm and do not plan to in the\n  medium term.\n\n## Extension stability and security posture\n\nEvery extension is expected to be tagged with a `status` and `security_posture` in its\n`envoy_cc_extension` rule.\n\nThe `status` is one of:\n* `stable`: The extension is stable and is expected to be production usable. This is the default if\n  no `status` is specified.\n* `alpha`: The extension is functional but has not had substantial production burn time, use only\n  with this caveat.\n* `wip`: The extension is work-in-progress. Functionality is incomplete and it is not intended for\n  production use.\n\nThe extension status may be adjusted by the extension [CODEOWNERS](./CODEOWNERS) and/or Envoy\nmaintainers based on an assessment of the above criteria. Note that the status of the extension\nreflects the implementation status. It is orthogonal to the API stability, for example, an extension\nAPI marked with `(xds.annotations.v3.file_status).work_in_progress` might have a `stable` implementation and\nand an extension with a stable config proto can have a `wip` implementation.\n\nThe `security_posture` is one of:\n* `robust_to_untrusted_downstream`: The extension is hardened against untrusted downstream traffic. It\n   assumes that the upstream is trusted.\n* `robust_to_untrusted_downstream_and_upstream`: The extension is hardened against both untrusted\n   downstream and upstream traffic.\n* `requires_trusted_downstream_and_upstream`: The extension is not hardened and should only be used in deployments\n   where both the downstream and upstream are trusted.\n* `unknown`: This is functionally equivalent to `requires_trusted_downstream_and_upstream`, but acts\n  as a placeholder to allow us to identify extensions that need classifying.\n* `data_plane_agnostic`: Not relevant to data plane threats, e.g. stats sinks.\n\nAn assessment of a robust security posture for an extension is subject to the following guidelines:\n\n* Does the extension have fuzz coverage? If it's only receiving fuzzing\n  courtesy of the generic listener/network/HTTP filter fuzzers, does it have a\n  dedicated fuzzer for any parts of the code that would benefit?\n* Does the extension have unbounded internal buffering? Does it participate in\n  flow control via watermarking as needed?\n* Does the extension have at least one deployment with live untrusted traffic\n  for a period of time, N months?\n* Does the extension rely on dependencies that meet our [extension maturity\n  model](https://github.com/envoyproxy/envoy/issues/10471)?\n* Is the extension reasonable to audit by Envoy security team?\n* Is the extension free of obvious scary things, e.g. `memcpy`, does it have gnarly parsing code, etc?\n* Does the extension have active [CODEOWNERS](CODEOWNERS) who are willing to\n  vouch for the robustness of the extension?\n* Is the extension absent a [low coverage\n  exception](https://github.com/envoyproxy/envoy/blob/main/test/per_file_coverage.sh#L5)?\n\nThe current stability and security posture of all extensions can be seen\n[here](https://www.envoyproxy.io/docs/envoy/latest/intro/arch_overview/security/threat_model#core-and-extensions).\n\n## Adding Extension Points\n\nEnvoy might lack the extension point necessary for an extension. In that\ncase we need to install an extension point, which can be done as follows:\n\n  1. Open a GitHub issue describing the proposed extension point and use cases.\n  2. Make changes in core Envoy for the extension point.\n  3. Update [extending envoy](docs/root/extending/extending.rst) to list the new\n     extension point and add any documentation explaining the extension point.\n     At the very least this should link to the corresponding proto.\n\n## Contrib extensions\n\nAs described in [this document](https://docs.google.com/document/d/1yl7GOZK1TDm_7vxQvt8UQEAu07UQFru1uEKXM6ZZg_g/edit#),\nEnvoy allows an alternate path to adding extensions called `contrib/`. The barrier to entry for a\ncontrib extension is lower than a core extension, with the tradeoff that contrib extensions are not\nincluded by default in the main image builds. Consumers need to pull directly from the contrib\nimages described in the installation guide. Please read the linked document in detail to determine\nwhether contrib extensions are the right choice for a newly proposed extension.\n\n**NOTE:** Contrib extensions **require** an end-user sponsor. The sponsor is someone who will run\nthe extension at sufficient scale as to make the build maintenance and other overhead worthwhile.\nThe definition of \"sufficient scale\" is up to the maintainers and can change at any time. The\nend-user sponsor *does not* have to author the extension, but the end-user sponsor will need to make\nan \"on the record\" attestation of their planned usage of the extension. This attestation should\noccur in a GitHub issue opened to discuss the new extension. In this context \"end user\" has the\nsame definition as the one specified in the [security policy](SECURITY.md#membership-criteria)\nmembership criteria (point 1.3.5).\n\n**NOTE:** Contrib extensions are not eligible for Envoy security team coverage.\n\n**NOTE:** As per the linked Google Doc, contrib extensions generally should use `v3alpha` to avoid\nrequiring API shepherd reviews.\n"
        },
        {
          "name": "GOVERNANCE.md",
          "type": "blob",
          "size": 7.92,
          "content": "# Process for becoming a maintainer\n\nBecoming a maintainer generally means that you are going to be spending substantial time on\nEnvoy for the foreseeable future. You should have domain expertise and be extremely proficient in C++.\n\n* Express interest to the\n  [envoy-maintainers](https://groups.google.com/forum/#!forum/envoy-maintainers)\n  that you are interested in becoming a maintainer and, if your company does not have pre-existing maintainers,\n  that your organization is interested in and willing to sponsoring a maintainer.\n* We will expect you to start contributing increasingly complicated PRs, under the guidance\n  of the existing maintainers.\n* We may ask you to fix some issues from our backlog.\n* As you gain experience with the code base and our standards, we will ask you to do code reviews\n  for incoming PRs (i.e., all maintainers are expected to shoulder a proportional share of\n  community reviews).\n* After a period of approximately 2-3 months of contributions demonstrating understanding of (at least parts of)\n  the Envoy code base, reach back out to the maintainers list asking for feedback.  At this point, you will either\n  be granted maintainer status, or be given actionable feedback on any remaining gaps between the contributions\n  demonstrated and those expected of maintainers, at which point you can close those gaps and reach back out.\n\n## Maintainer responsibilities\n\n* Monitor email aliases.\n* Monitor Slack (delayed response is perfectly acceptable).\n* Triage GitHub issues and perform pull request reviews for other maintainers and the community.\n  The areas of specialization listed in [OWNERS.md](OWNERS.md) can be used to help with routing\n  an issue/question to the right person.\n* Triage build and CI issues. Monitor #envoy-ci and file issues for flaking or failing builds,\n  or new bugs, and either fix or find someone to fix any main build breakages.\n* During GitHub issue triage, apply all applicable [labels](https://github.com/envoyproxy/envoy/labels)\n  to each new issue. Labels are extremely useful for future issue follow up. Which labels to apply\n  is somewhat subjective so just use your best judgment. A few of the most important labels that are\n  not self explanatory are:\n  * **beginner**: Mark any issue that can reasonably be accomplished by a new contributor with\n    this label.\n  * **help wanted**: Unless it is immediately obvious that someone is going to work on an issue (and\n    if so assign it), mark it help wanted.\n  * **question**: If it's unclear if an issue is immediately actionable, mark it with the\n    question label. Questions are easy to search for and close out at a later time. Questions\n    can be promoted to other issue types once it's clear they are actionable (at which point the\n    question label should be removed).\n* Make sure that ongoing PRs are moving forward at the right pace or closing them.\n* Participate when called upon in the [security release process](SECURITY.md). Note that although\n  this should be a rare occurrence, if a serious vulnerability is found, the process may take up to\n  several full days of work to implement. This reality should be taken into account when discussing\n  time commitment obligations with employers.\n* In general continue to be willing to spend at least 25% of ones time working on Envoy (~1.25\n  business days per week).\n* We currently maintain an \"on-call\" rotation within the maintainers. Each on-call is 1 week.\n  Although all maintainers are welcome to perform all of the above tasks, it is the on-call\n  maintainer's responsibility to triage incoming issues/questions and marshal ongoing work\n  forward. To reiterate, it is *not* the responsibility of the on-call maintainer to answer all\n  questions and do all reviews, but it is their responsibility to make sure that everything is\n  being actively covered by someone.\n* The on-call rotation is tracked at Opsgenie. The calendar is visible\n[here](https://calendar.google.com/calendar/embed?src=d6glc0l5rc3v235q9l2j29dgovh3dn48%40import.calendar.google.com&ctz=America%2FNew_York)\nor you can subscribe to the iCal feed [here](webcal://kubernetes.app.opsgenie.com/webapi/webcal/getRecentSchedule?webcalToken=39dd1a892faa8d0d689f889b9d09ae787355ddff894396546726a5a02bac5b26&scheduleId=a3505963-c064-4c97-8865-947dfcb06060)\n\n## When does a maintainer lose maintainer status\n\nIf a maintainer is no longer interested or cannot perform the maintainer duties listed above, they\nshould volunteer to be moved to emeritus status. In extreme cases this can also occur by a vote of\nthe maintainers per the voting process below.\n\n# xDS API shepherds\n\nThe [xDS API shepherds](https://github.com/orgs/envoyproxy/teams/api-shepherds) are responsible for\napproving any PR that modifies the [api/](api/) tree. They ensure that API [style](api/STYLE.md) and\n[versioning](api/API_VERSIONING.md) policies are enforced and that a consistent approach is taken\ntowards API evolution.\n\nThe xDS API shepherds are also the xDS API maintainers; they work collaboratively with the community\nto drive the xDS API roadmap and review major proposed design changes. The API shepherds are\nintended to be representative of xDS client and control plane developers who are actively working on\nxDS development and evolution.\n\nAs with maintainers, an API shepherd should be spending at least 25% of their time working on xDS\ndevelopments and expect to be active in this space in the near future. API shepherds are expected to\ntake on API shepherd review load and participate in meetings. They should be active on Slack `#xds`\nand responsive to GitHub issues and PRs on which they are tagged.\n\nThe API shepherds are distinct to the [xDS working\ngroup](https://github.com/cncf/xds/blob/main/README.md), which aims to evolve xDS directionally\ntowards a universal dataplane API. API shepherds are responsible for the execution of the xDS\nday-to-day and guiding xDS implementation changes. Proposals from xDS-WG will be aligned with the\nxDS API shepherds to ensure that xDS is heading towards the xDS goal of client and server neutral\nxDS. xDS API shepherds operate under the [envoyproxy](https://github.com/envoyproxy) organization\nbut are expected to keep in mind the needs of all xDS clients (currently Envoy and gRPC, but we are\naware of other in-house implementations) and the goals of xDS-WG.\n\nIf you wish to become an API shepherd and satisfy the above criteria, please contact an existing\nAPI shepherd. We will factor in PR and review history to determine if the above API shepherd\nrequirements are met. We may ask you to shadow an existing API shepherd for a period of time to\nbuild confidence in consistent application of the API guidelines to PRs.\n\n# Extension addition policy\n\nAdding new [extensions](REPO_LAYOUT.md#sourceextensions-layout) has a dedicated policy. Please\nsee [this](./EXTENSION_POLICY.md) document for more information.\n\n# External dependency policy\n\nAdding new external dependencies has a dedicated policy. Please see [this](DEPENDENCY_POLICY.md)\ndocument for more information.\n\n# Conflict resolution and voting\n\nIn general, we prefer that technical issues and maintainer membership are amicably worked out\nbetween the persons involved. If a dispute cannot be decided independently, the maintainers can be\ncalled in to decide an issue. If the maintainers themselves cannot decide an issue, the issue will\nbe resolved by voting. The voting process is a simple majority in which each senior maintainer\nreceives two votes and each normal maintainer receives one vote.\n\n# Adding new projects to the envoyproxy GitHub organization\n\nNew projects will be added to the envoyproxy organization via GitHub issue discussion in one of the\nexisting projects in the organization. Once sufficient discussion has taken place (~3-5 business\ndays but depending on the volume of conversation), the maintainers of *the project where the issue\nwas opened* (since different projects in the organization may have different maintainers) will\ndecide whether the new project should be added. See the section above on voting if the maintainers\ncannot easily decide.\n"
        },
        {
          "name": "LICENSE",
          "type": "blob",
          "size": 11.09,
          "content": "\n                                 Apache License\n                           Version 2.0, January 2004\n                        http://www.apache.org/licenses/\n\n   TERMS AND CONDITIONS FOR USE, REPRODUCTION, AND DISTRIBUTION\n\n   1. Definitions.\n\n      \"License\" shall mean the terms and conditions for use, reproduction,\n      and distribution as defined by Sections 1 through 9 of this document.\n\n      \"Licensor\" shall mean the copyright owner or entity authorized by\n      the copyright owner that is granting the License.\n\n      \"Legal Entity\" shall mean the union of the acting entity and all\n      other entities that control, are controlled by, or are under common\n      control with that entity. For the purposes of this definition,\n      \"control\" means (i) the power, direct or indirect, to cause the\n      direction or management of such entity, whether by contract or\n      otherwise, or (ii) ownership of fifty percent (50%) or more of the\n      outstanding shares, or (iii) beneficial ownership of such entity.\n\n      \"You\" (or \"Your\") shall mean an individual or Legal Entity\n      exercising permissions granted by this License.\n\n      \"Source\" form shall mean the preferred form for making modifications,\n      including but not limited to software source code, documentation\n      source, and configuration files.\n\n      \"Object\" form shall mean any form resulting from mechanical\n      transformation or translation of a Source form, including but\n      not limited to compiled object code, generated documentation,\n      and conversions to other media types.\n\n      \"Work\" shall mean the work of authorship, whether in Source or\n      Object form, made available under the License, as indicated by a\n      copyright notice that is included in or attached to the work\n      (an example is provided in the Appendix below).\n\n      \"Derivative Works\" shall mean any work, whether in Source or Object\n      form, that is based on (or derived from) the Work and for which the\n      editorial revisions, annotations, elaborations, or other modifications\n      represent, as a whole, an original work of authorship. For the purposes\n      of this License, Derivative Works shall not include works that remain\n      separable from, or merely link (or bind by name) to the interfaces of,\n      the Work and Derivative Works thereof.\n\n      \"Contribution\" shall mean any work of authorship, including\n      the original version of the Work and any modifications or additions\n      to that Work or Derivative Works thereof, that is intentionally\n      submitted to Licensor for inclusion in the Work by the copyright owner\n      or by an individual or Legal Entity authorized to submit on behalf of\n      the copyright owner. For the purposes of this definition, \"submitted\"\n      means any form of electronic, verbal, or written communication sent\n      to the Licensor or its representatives, including but not limited to\n      communication on electronic mailing lists, source code control systems,\n      and issue tracking systems that are managed by, or on behalf of, the\n      Licensor for the purpose of discussing and improving the Work, but\n      excluding communication that is conspicuously marked or otherwise\n      designated in writing by the copyright owner as \"Not a Contribution.\"\n\n      \"Contributor\" shall mean Licensor and any individual or Legal Entity\n      on behalf of whom a Contribution has been received by Licensor and\n      subsequently incorporated within the Work.\n\n   2. Grant of Copyright License. Subject to the terms and conditions of\n      this License, each Contributor hereby grants to You a perpetual,\n      worldwide, non-exclusive, no-charge, royalty-free, irrevocable\n      copyright license to reproduce, prepare Derivative Works of,\n      publicly display, publicly perform, sublicense, and distribute the\n      Work and such Derivative Works in Source or Object form.\n\n   3. Grant of Patent License. Subject to the terms and conditions of\n      this License, each Contributor hereby grants to You a perpetual,\n      worldwide, non-exclusive, no-charge, royalty-free, irrevocable\n      (except as stated in this section) patent license to make, have made,\n      use, offer to sell, sell, import, and otherwise transfer the Work,\n      where such license applies only to those patent claims licensable\n      by such Contributor that are necessarily infringed by their\n      Contribution(s) alone or by combination of their Contribution(s)\n      with the Work to which such Contribution(s) was submitted. If You\n      institute patent litigation against any entity (including a\n      cross-claim or counterclaim in a lawsuit) alleging that the Work\n      or a Contribution incorporated within the Work constitutes direct\n      or contributory patent infringement, then any patent licenses\n      granted to You under this License for that Work shall terminate\n      as of the date such litigation is filed.\n\n   4. Redistribution. You may reproduce and distribute copies of the\n      Work or Derivative Works thereof in any medium, with or without\n      modifications, and in Source or Object form, provided that You\n      meet the following conditions:\n\n      (a) You must give any other recipients of the Work or\n          Derivative Works a copy of this License; and\n\n      (b) You must cause any modified files to carry prominent notices\n          stating that You changed the files; and\n\n      (c) You must retain, in the Source form of any Derivative Works\n          that You distribute, all copyright, patent, trademark, and\n          attribution notices from the Source form of the Work,\n          excluding those notices that do not pertain to any part of\n          the Derivative Works; and\n\n      (d) If the Work includes a \"NOTICE\" text file as part of its\n          distribution, then any Derivative Works that You distribute must\n          include a readable copy of the attribution notices contained\n          within such NOTICE file, excluding those notices that do not\n          pertain to any part of the Derivative Works, in at least one\n          of the following places: within a NOTICE text file distributed\n          as part of the Derivative Works; within the Source form or\n          documentation, if provided along with the Derivative Works; or,\n          within a display generated by the Derivative Works, if and\n          wherever such third-party notices normally appear. The contents\n          of the NOTICE file are for informational purposes only and\n          do not modify the License. You may add Your own attribution\n          notices within Derivative Works that You distribute, alongside\n          or as an addendum to the NOTICE text from the Work, provided\n          that such additional attribution notices cannot be construed\n          as modifying the License.\n\n      You may add Your own copyright statement to Your modifications and\n      may provide additional or different license terms and conditions\n      for use, reproduction, or distribution of Your modifications, or\n      for any such Derivative Works as a whole, provided Your use,\n      reproduction, and distribution of the Work otherwise complies with\n      the conditions stated in this License.\n\n   5. Submission of Contributions. Unless You explicitly state otherwise,\n      any Contribution intentionally submitted for inclusion in the Work\n      by You to the Licensor shall be under the terms and conditions of\n      this License, without any additional terms or conditions.\n      Notwithstanding the above, nothing herein shall supersede or modify\n      the terms of any separate license agreement you may have executed\n      with Licensor regarding such Contributions.\n\n   6. Trademarks. This License does not grant permission to use the trade\n      names, trademarks, service marks, or product names of the Licensor,\n      except as required for reasonable and customary use in describing the\n      origin of the Work and reproducing the content of the NOTICE file.\n\n   7. Disclaimer of Warranty. Unless required by applicable law or\n      agreed to in writing, Licensor provides the Work (and each\n      Contributor provides its Contributions) on an \"AS IS\" BASIS,\n      WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or\n      implied, including, without limitation, any warranties or conditions\n      of TITLE, NON-INFRINGEMENT, MERCHANTABILITY, or FITNESS FOR A\n      PARTICULAR PURPOSE. You are solely responsible for determining the\n      appropriateness of using or redistributing the Work and assume any\n      risks associated with Your exercise of permissions under this License.\n\n   8. Limitation of Liability. In no event and under no legal theory,\n      whether in tort (including negligence), contract, or otherwise,\n      unless required by applicable law (such as deliberate and grossly\n      negligent acts) or agreed to in writing, shall any Contributor be\n      liable to You for damages, including any direct, indirect, special,\n      incidental, or consequential damages of any character arising as a\n      result of this License or out of the use or inability to use the\n      Work (including but not limited to damages for loss of goodwill,\n      work stoppage, computer failure or malfunction, or any and all\n      other commercial damages or losses), even if such Contributor\n      has been advised of the possibility of such damages.\n\n   9. Accepting Warranty or Additional Liability. While redistributing\n      the Work or Derivative Works thereof, You may choose to offer,\n      and charge a fee for, acceptance of support, warranty, indemnity,\n      or other liability obligations and/or rights consistent with this\n      License. However, in accepting such obligations, You may act only\n      on Your own behalf and on Your sole responsibility, not on behalf\n      of any other Contributor, and only if You agree to indemnify,\n      defend, and hold each Contributor harmless for any liability\n      incurred by, or claims asserted against, such Contributor by reason\n      of your accepting any such warranty or additional liability.\n\n   END OF TERMS AND CONDITIONS\n\n   APPENDIX: How to apply the Apache License to your work.\n\n      To apply the Apache License to your work, attach the following\n      boilerplate notice, with the fields enclosed by brackets \"[]\"\n      replaced with your own identifying information. (Don't include\n      the brackets!)  The text should be enclosed in the appropriate\n      comment syntax for the file format. We also recommend that a\n      file or class name and description of purpose be included on the\n      same \"printed page\" as the copyright notice for easier\n      identification within third-party archives.\n\n   Copyright [yyyy] [name of copyright owner]\n\n   Licensed under the Apache License, Version 2.0 (the \"License\");\n   you may not use this file except in compliance with the License.\n   You may obtain a copy of the License at\n\n       http://www.apache.org/licenses/LICENSE-2.0\n\n   Unless required by applicable law or agreed to in writing, software\n   distributed under the License is distributed on an \"AS IS\" BASIS,\n   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n   See the License for the specific language governing permissions and\n   limitations under the License.\n"
        },
        {
          "name": "NOTICE",
          "type": "blob",
          "size": 0.1,
          "content": "Envoy\nCopyright The Envoy Project Authors\n\nLicensed under Apache License 2.0.  See LICENSE for terms.\n"
        },
        {
          "name": "OWNERS.md",
          "type": "blob",
          "size": 6.81,
          "content": "* See [CONTRIBUTING.md](CONTRIBUTING.md) for general contribution guidelines.\n* See [GOVERNANCE.md](GOVERNANCE.md) for governance guidelines and maintainer responsibilities.\n* See [CODEOWNERS](CODEOWNERS) for a detailed list of owners for the various source directories.\n\nThis page lists all active maintainers and their areas of expertise. This can be used for\nrouting PRs, questions, etc. to the right place.\n\n# Senior maintainers\n<!--- If you modify senior maintainers list, please update the core-maintainers section of SECURITY-INSIGHTS.yml  -->\n\n* Matt Klein ([mattklein123](https://github.com/mattklein123)) (mattklein123@gmail.com)\n  * Catch-all, \"all the things\", and generally trying to make himself obsolete as fast as\n    possible.\n* Alyssa Wilk ([alyssawilk](https://github.com/alyssawilk)) (alyssar@google.com)\n  * HTTP, flow control, cluster manager, load balancing, and core networking (listeners,\n    connections, etc.), Envoy Mobile.\n* Stephan Zuercher ([zuercher](https://github.com/zuercher)) (zuercher@gmail.com)\n  * Load balancing, upstream clusters and cluster manager, logging, complex HTTP routing\n    (metadata, etc.), and macOS build.\n* Greg Greenway ([ggreenway](https://github.com/ggreenway)) (ggreenway@apple.com)\n  * TLS, TCP proxy, listeners, and HTTP proxy/connection pooling.\n* Yan Avlasov ([yanavlasov](https://github.com/yanavlasov)) (yavlasov@google.com)\n  * Data plane, codecs, security, configuration.\n* Ryan Northey ([phlax](https://github.com/phlax)) (ryan@synca.io)\n  * Docs, tooling, CI, containers and sandbox examples\n* Ryan Hamilton ([RyanTheOptimist](https://github.com/ryantheoptimist)) (rch@google.com)\n  * HTTP/3, upstream connection management, Envoy Mobile.\n* Baiping Wang ([wbpcode](https://github.com/wbpcode)) (wbphub@live.com)\n  * Upstream, LB, tracing, logging, performance, and generic/dubbo proxy.\n\n# Maintainers\n<!--- If you modify maintainers list, please update the core-maintainers section of SECURITY-INSIGHTS.yml -->\n\n* Joshua Marantz ([jmarantz](https://github.com/jmarantz)) (jmarantz@google.com)\n  * Stats, abseil, scalability, and performance.\n* Adi Peleg ([adisuissa](https://github.com/adisuissa)) (adip@google.com)\n  * xDS APIs, configuration, control plane, fuzzing.\n* Kevin Baichoo ([KBaichoo](https://github.com/KBaichoo)) (envoy@kevinbaichoo.com)\n  * Data plane, overload management, flow control.\n* Keith Smiley ([keith](https://github.com/keith)) (keithbsmiley@gmail.com)\n  * Bazel, CI, compilers, linkers, general build issues, etc.\n* Kuat Yessenov ([kyessenov](https://github.com/kyessenov)) (kuat@google.com)\n  * Listeners, RBAC, CEL, matching, Istio.\n* Raven Black ([ravenblackx](https://github.com/ravenblackx)) (ravenblack@dropbox.com)\n  * Caches, file filters, and file I/O.\n* Alex Xu ([soulxu](https://github.com/soulxu)) (hejie.xu@intel.com)\n  * Listeners, iouring, data plane.\n* Kateryna Nezdolii ([nezdolik](https://github.com/nezdolik)) (kateryna.nezdolii@gmail.com)\n  * Load balancing, GeoIP, overload manager, security.\n* Tianyu Xia ([tyxia](https://github.com/tyxia)) (tyxia@google.com)\n  * ext_proc, data plane, flow control, CEL.\n* Boteng Yao ([botengyao](https://github.com/botengyao)) (boteng@google.com)\n  * Overload manager, security, logging, wasm, data plane.\n\n# Envoy mobile maintainers\n\nThe following Envoy maintainers have final say over any changes only affecting /mobile\n\n* Ali Beyad ([abeyad](https://github.com/abeyad)) (abeyad@google.com)\n  * xDS, C++ integration tests.\n* Fredy Wijaya ([fredyw](https://github.com/fredyw)) (fredyw@google.com)\n  * Android, Java, Kotlin, JNI.\n\n# Senior extension maintainers\n\nThe following extension maintainers have final say over the extensions mentioned below. Once they\napprove an extension PR, it will be merged by the maintainer on-call (or any other maintainer)\nwithout further review.\n\n* Michael Warres ([mpwarres] (https://github.com/mpwarres)) (mpw@google.com)\n  * Wasm\n* doujiang24 ([doujiang24] https://github.com/doujiang24) (doujiang24@gmail.com)\n  * Golang\n* Lizan Zhou ([lizan](https://github.com/lizan)) (lizan.j@gmail.com)\n  * Wasm, JWT, gRPC-JSON transcoder\n\n# Envoy security team\n\n* All senior maintainers\n* Tony Allen ([tonya11en](https://github.com/tonya11en)) (tony@allen.gg)\n* Tim Walsh ([twghu](https://github.com/twghu)) (twalsh@redhat.com)\n* Pradeep Rao ([pradeepcrao](https://github.com/pradeepcrao)) (pcrao@google.com)\n* Kateryna Nezdolii ([nezdolik](https://github.com/nezdolik)) (kateryna.nezdolii@gmail.com)\n* Boteng Yao ([botengyao](https://github.com/botengyao)) (boteng@google.com)\n* Kevin Baichoo ([KBaichoo](https://github.com/KBaichoo)) (envoy@kevinbaichoo.com)\n* Tianyu Xia ([tyxia](https://github.com/tyxia)) (tyxia@google.com)\n* Kirtimaan Rajshiva ([krajshiva](https://github.com/krajshiva))\n* Yanjun Xiang ([yanjunxiang-google](https://github.com/yanjunxiang-google)) (yanjunxiang@google.com)\n\n# Emeritus maintainers\n\n* Constance Caramanolis ([ccaraman](https://github.com/ccaraman)) (ccaramanolis@lyft.com)\n* Roman Dzhabarov ([RomanDzhabarov](https://github.com/RomanDzhabarov)) (rdzhabarov@lyft.com)\n* Bill Gallagher ([wgallagher](https://github.com/wgallagher)) (bgallagher@lyft.com)\n* Dan Noé ([dnoe](https://github.com/dnoe)) (dpn@google.com)\n* Sotiris Nanopoulos ([davinci26](https://github.com/davinci26)) (Sotiris.Nanopoulos@microsoft.com)\n* Asra Ali ([asraa](https://github.com/asraa)) (asraa@google.com)\n* Jose Nino ([junr03](https://github.com/junr03)) (recruiting@junr03.com)\n* Dhi Aurrahman ([dio](https://github.com/dio)) (dio@rockybars.com)\n* Dmitry Rozhkov ([rojkov](https://github.com/rojkov)) (dmitry.rozhkov@intel.com)\n* Michael Rebello ([rebello95](https://github.com/rebello95)) (mrebello@lyft.com)\n* Alan Chiu ([buildbreaker](https://github.com/buildbreaker)) (achiu@lyft.com)\n* Charles Le Borgne ([carloseltuerto](https://github.com/carloseltuerto)) (cleborgne@google.com)\n* William A Rowe Jr ([wrowe](https://github.com/wrowe)) (wrowe@rowe-clan.net)\n* Antonio Vicente ([antoniovicente](https://github.com/antoniovicente)) (avd@google.com)\n* JP Simard ([jpsim](https://github.com/jpsim)) (jp@lyft.com)\n* Rafal Augustyniak ([Augustyniak](https://github.com/Augustyniak)) (raugustyniak@lyft.com)\n* Snow Pettersen ([snowp](https://github.com/snowp)) (aickck@gmail.com)\n* Lizan Zhou ([lizan](https://github.com/lizan)) (lizan.j@gmail.com)\n* Harvey Tuch ([htuch](https://github.com/htuch)) (htuch@google.com)\n\n# Friends of Envoy\n\nThis section lists a few people that are not maintainers but typically help out with subject\nmatter expert reviews. Feel free to loop them in as needed.\n\n* Yuchen Dai ([lambdai](https://github.com/lambdai)) (lambdai@google.com)\n  * v2 xDS, listeners, filter chain discovery service.\n* Michael Payne ([moderation](https://github.com/moderation)) (m@m17e.org)\n  * External dependencies, Envoy's supply chain and documentation.\n* Cerek Hillen ([crockeo](https://github.com/crockeo)) (chillen@lyft.com)\n  * Python and C++ platform bindings.\n"
        },
        {
          "name": "PULL_REQUESTS.md",
          "type": "blob",
          "size": 5.7,
          "content": "When creating an Envoy pull request (PR) the text box will automatically be filled\nin with the basic fields from the [pull request template](PULL_REQUEST_TEMPLATE.md). The following\nis a more detailed explanation of what should go in each field.\n\n### <a name=\"title\"></a>Title\n\nThe title of the PR should brief (one line) noting the subsystem or the aspect this PR applies to and\nexplaining the overall change. Both the component and the explanation must be lower case. For example:\n\n* ci: update build image to 44d539cb\n* docs: fix indent, buffer: add copyOut() method\n* router:add x-envoy-overloaded header\n* tls: add support for specifying TLS session ticket keys\n\n### <a name=\"desc\"></a>Commit Message\n\nThe commit message field should include an explanation of what this PR\ndoes. This will be used as the final commit message that maintainers will use to\npopulate the commit message when merging. If this PR causes a change in behavior\nit should document the behavior before and after. If fixing a bug, please\ndescribe what the original issue is and how the change resolves it. If it is\nconfiguration controlled, it should note how the feature is enabled etc...\n\n\n### <a name=\"desc\"></a>Additional Description\n\nThe additional description field should include information of what this PR does\nthat may be out of scope for a commit message. This could include additional\ninformation or context useful to reviewers.\n\n### <a name=\"risk\"></a>Risk\n\nRisk Level is one of: Low | Medium | High\n\nLow: Small bug fix or small optional feature.\n\nMedium: New features that are not enabled(for example: new filter). Small-medium\nfeatures added to existing components(for example: modification to an existing\nfilter).\n\nHigh: Complicated changes such as flow control, rewrites of critical\ncomponents, etc.\n\nNote: The above is only a rough guide for choosing a level,\nplease ask if you have any concerns about the risk of the PR.\n\n### <a name=\"testing\"></a>Testing\n\nThe testing section should include an explanation of what testing was done, for example: unit test,\nintegration, manual testing, etc.\n\nNote: It isn’t expected to do all forms of testing, please use your best judgement or ask for\nguidance if you are unsure. A good rule of thumb is the riskier the change, the\nmore comprehensive the testing should be.\n\n### <a name=\"docs\"></a>Documentation\n\nIf there are documentation changes, please include a brief description of what they are. Docs\nchanges may be in [docs/root](docs/root) and/or inline with the API protos. Please write in\nN/A if there were no documentation changes.\n\nAny PRs with structural changes to the dataplane should also update the [Life of a\nRequest](https://www.envoyproxy.io/docs/envoy/latest/intro/life_of_a_request) documentation as appropriate.\n\n### <a name=\"relnotes\"></a>Release notes\n\nIf this change is user impacting OR extension developer impacting (filter API, etc.) you **must**\nadd a release note to the [version history](changelogs/current.yaml) for the\ncurrent version. Please include any relevant links. Each release note should be prefixed with the\nrelevant subsystem in **alphabetical order** (see existing examples as a guide) and include links\nto relevant parts of the documentation. Thank you! Please write in N/A if there are no release notes.\n\n### <a name=\"platform_specific_features\"></a>Platform Specific Features\n\nIf this change involves any platform specific features (e.g. utilizing OS-specific socket options)\nor only implements new features for a limited set of platforms (e.g. Linux amd64 only), please\ninclude an explanation that addresses the reasoning behind this. Please also open a new tracking\nissue for each platform this change is not implemented on (and link them in the PR) to enable\nmaintainers and contributors to triage. Reviewers will look for the change to avoid\n`#ifdef <OSNAME>` and rather prefer feature guards to not enable the change on a given platform\nusing the build system.\n\n### <a name=\"runtime_guard\"></a>Runtime guard\n\nIf this PR has a user-visible behavioral change, or otherwise falls under the\nguidelines for runtime guarding in the [contributing doc](CONTRIBUTING.md)\nit should have a runtime guard, which should be documented both in the release\nnotes and here in the PR description.\n\nFor new feature additions guarded by configs, no-op refactors, docs changes etc.\nthis field can be disregarded and/or removed.\n\n### <a name=\"issues\"></a>Issues\n\nIf this PR fixes an outstanding issue, please add a line of the form:\n\nFixes #Issue\n\nThis will result in the linked issue being automatically closed when the PR is\nmerged. If you want to associate an issue with a PR without closing the issue,\nyou may instead just tag the PR with the issue:\n\n\\#Issue\n\n### <a name=\"commit\"></a>Commit\n\nIf this PR fixes or reverts a buggy commit, please add a line of the form:\n\nFixes commit #PR\n\nor\n\nFixes commit SHA\n\nThis will allow automated tools to detect tainted commit ranges on the main branch when the PR is\nmerged.\n\n### <a name=\"deprecated\"></a>Deprecated\n\nIf this PR deprecates existing Envoy APIs or code, it should include an update to the deprecated\nsection of the [version history](changelogs/current.yaml) and a one line note in the\nPR description.\n\nIf you mark existing APIs or code as deprecated, when the next release is cut, the\ndeprecation script will create and assign an issue to you for\ncleaning up the deprecated code path.\n\n### <a name=\"api\"></a>API Changes\n\nIf this PR changes anything in the [api tree](https://github.com/envoyproxy/envoy/tree/main/api),\nplease read the [API Review\nChecklist](https://github.com/envoyproxy/envoy/tree/main/api/review_checklist.md)\nand make sure that your changes have addressed all of the considerations listed there.\nAny relevant considerations should be documented under \"API Considerations\" in the PR description.\n"
        },
        {
          "name": "PULL_REQUEST_TEMPLATE.md",
          "type": "blob",
          "size": 0.8,
          "content": "<!--\n!!!ATTENTION!!!\n\nIf you are fixing *any* crash or *any* potential security issue, *do not*\nopen a pull request in this repo. Please report the issue via emailing\nenvoy-security@googlegroups.com where the issue will be triaged appropriately.\nThank you in advance for helping to keep Envoy secure.\n\n!!!ATTENTION!!!\n\nFor an explanation of how to fill out the fields, please see the relevant section\nin [PULL_REQUESTS.md](https://github.com/envoyproxy/envoy/blob/main/PULL_REQUESTS.md)\n-->\n\nCommit Message:\nAdditional Description:\nRisk Level:\nTesting:\nDocs Changes:\nRelease Notes:\nPlatform Specific Features:\n[Optional Runtime guard:]\n[Optional Fixes #Issue]\n[Optional Fixes commit #PR or SHA]\n[Optional Deprecated:]\n[Optional [API Considerations](https://github.com/envoyproxy/envoy/blob/main/api/review_checklist.md):]\n"
        },
        {
          "name": "README.md",
          "type": "blob",
          "size": 6.18,
          "content": "![Envoy Logo](https://github.com/envoyproxy/artwork/blob/main/PNG/Envoy_Logo_Final_PANTONE.png)\n\n[Cloud-native high-performance edge/middle/service proxy](https://www.envoyproxy.io/)\n\nEnvoy is hosted by the [Cloud Native Computing Foundation](https://cncf.io) (CNCF). If you are a\ncompany that wants to help shape the evolution of technologies that are container-packaged,\ndynamically-scheduled and microservices-oriented, consider joining the CNCF. For details about who's\ninvolved and how Envoy plays a role, read the CNCF\n[announcement](https://www.cncf.io/blog/2017/09/13/cncf-hosts-envoy/).\n\n[![CII Best Practices](https://bestpractices.coreinfrastructure.org/projects/1266/badge)](https://bestpractices.coreinfrastructure.org/projects/1266)\n[![OpenSSF Scorecard](https://api.securityscorecards.dev/projects/github.com/envoyproxy/envoy/badge)](https://securityscorecards.dev/viewer/?uri=github.com/envoyproxy/envoy)\n[![CLOMonitor](https://img.shields.io/endpoint?url=https://clomonitor.io/api/projects/cncf/envoy/badge)](https://clomonitor.io/projects/cncf/envoy)\n[![Azure Pipelines](https://dev.azure.com/cncf/envoy/_apis/build/status/11?branchName=main)](https://dev.azure.com/cncf/envoy/_build/latest?definitionId=11&branchName=main)\n[![Fuzzing Status](https://oss-fuzz-build-logs.storage.googleapis.com/badges/envoy.svg)](https://bugs.chromium.org/p/oss-fuzz/issues/list?sort=-opened&can=1&q=proj:envoy)\n[![Jenkins](https://powerci.osuosl.org/buildStatus/icon?job=build-envoy-static-master&subject=ppc64le%20build)](https://powerci.osuosl.org/job/build-envoy-static-master/)\n[![Jenkins](https://ibmz-ci.osuosl.org/buildStatus/icon?job=Envoy_IBMZ_CI&subject=s390x%20build)](https://ibmz-ci.osuosl.org/job/Envoy_IBMZ_CI/)\n\n## Documentation\n\n* [Official documentation](https://www.envoyproxy.io/)\n* [FAQ](https://www.envoyproxy.io/docs/envoy/latest/faq/overview)\n* [Unofficial Chinese documentation](https://cloudnative.to/envoy/)\n* [Example documentation](https://github.com/envoyproxy/examples/)\n* [Blog](https://medium.com/@mattklein123/envoy-threading-model-a8d44b922310) about the threading model\n* [Blog](https://medium.com/@mattklein123/envoy-hot-restart-1d16b14555b5) about hot restart\n* [Blog](https://medium.com/@mattklein123/envoy-stats-b65c7f363342) about stats architecture\n* [Blog](https://medium.com/@mattklein123/the-universal-data-plane-api-d15cec7a) about universal data plane API\n* [Blog](https://medium.com/@mattklein123/lyfts-envoy-dashboards-5c91738816b1) on Lyft's Envoy dashboards\n\n## Related\n\n* [data-plane-api](https://github.com/envoyproxy/data-plane-api): v2 API definitions as a standalone\n  repository. This is a read-only mirror of [api](api/).\n* [envoy-perf](https://github.com/envoyproxy/envoy-perf): Performance testing framework.\n* [envoy-filter-example](https://github.com/envoyproxy/envoy-filter-example): Example of how to add new filters\n  and link to the main repository.\n\n## Contact\n\n* [envoy-announce](https://groups.google.com/forum/#!forum/envoy-announce): Low frequency mailing\n  list where we will email announcements only.\n* [envoy-security-announce](https://groups.google.com/forum/#!forum/envoy-security-announce): Low frequency mailing\n  list where we will email security related announcements only.\n* [envoy-users](https://groups.google.com/forum/#!forum/envoy-users): General user discussion.\n* [envoy-dev](https://groups.google.com/forum/#!forum/envoy-dev): Envoy developer discussion (APIs,\n  feature design, etc.).\n* [envoy-maintainers](https://groups.google.com/forum/#!forum/envoy-maintainers): Use this list\n  to reach all core Envoy maintainers.\n* [Twitter](https://twitter.com/EnvoyProxy/): Follow along on Twitter!\n* [Slack](https://envoyproxy.slack.com/): Slack, to get invited go [here](https://communityinviter.com/apps/envoyproxy/envoy).\n  * NOTE: Response to user questions is best effort on Slack. For a \"guaranteed\" response please email\n    envoy-users@ per the guidance in the following linked thread.\n\nPlease see [this](https://groups.google.com/forum/#!topic/envoy-announce/l9zjYsnS3TY) email thread\nfor information on email list usage.\n\n## Contributing\n\nContributing to Envoy is fun and modern C++ is a lot less scary than you might think if you don't\nhave prior experience. To get started:\n\n* [Contributing guide](CONTRIBUTING.md)\n* [Beginner issues](https://github.com/envoyproxy/envoy/issues?q=is%3Aopen+is%3Aissue+label%3Abeginner)\n* [Build/test quick start using docker](ci#building-and-running-tests-as-a-developer)\n* [Developer guide](DEVELOPER.md)\n* Consider installing the Envoy [development support toolchain](https://github.com/envoyproxy/envoy/blob/main/support/README.md), which helps automate parts of the development process, particularly those involving code review.\n* Please make sure that you let us know if you are working on an issue so we don't duplicate work!\n\n## Community Meeting\n\nThe Envoy team has a scheduled meeting time twice per month on Tuesday at 9am PT. The public\nGoogle calendar is [here](https://goo.gl/PkDijT).  The meeting will only be held\nif there are agenda items listed in the [meeting\nminutes](https://goo.gl/5Cergb).  Any member of the community should be able to\npropose agenda items by adding to the minutes.  The maintainers will either confirm\nthe additions to the agenda, or will cancel the meeting within 24 hours of the scheduled\ndate if there is no confirmed agenda.\n\n## Security\n\n### Security Audit\n\nThere has been several third party engagements focused on Envoy security:\n* In 2018 Cure53 performed a security audit, [full report](docs/security/audit_cure53_2018.pdf).\n* In 2021 Ada Logics performed an audit on our fuzzing infrastructure with recommendations for improvements, [full report](docs/security/audit_fuzzer_adalogics_2021.pdf).\n\n### Reporting security vulnerabilities\n\nIf you've found a vulnerability or a potential vulnerability in Envoy please let us know at\n[envoy-security](mailto:envoy-security@googlegroups.com). We'll send a confirmation\nemail to acknowledge your report, and we'll send an additional email when we've identified the issue\npositively or negatively.\n\nFor further details please see our complete [security release process](SECURITY.md).\n\n## Releases\n\nFor further details please see our [release process](https://github.com/envoyproxy/envoy/blob/main/RELEASES.md).\n"
        },
        {
          "name": "RELEASES.md",
          "type": "blob",
          "size": 9.78,
          "content": "# Release Process\n\n## Active development\n\nActive development is happening on the `main` branch, and a new version is released from it.\n\n## Stable releases\n\nStable releases of Envoy include:\n\n* Major releases in which a new version a created directly from the `main` branch.\n* Minor releases for versions covered by the extended maintenance window (any version released in the last 12 months).\n  * Security fixes backported from the `main` branch (including those deemed not worthy\n    of creating a CVE).\n  * Stability fixes backported from the `main` branch (anything that can result in a crash,\n    including crashes triggered by a trusted control plane).\n  * Bugfixes, deemed worthwhile by the maintainers of stable releases.\n\nMajor releases happen quartely and follow the schedule below. Security fixes typically happen\nquarterly as well, but this depends on the number and severity of security bugs. Other releases\nare ad-hoc and best-effort.\n\n### Security releases\n\nCritical security fixes are owned by the Envoy security team, which provides fixes for the\n`main` branch. Once those fixes are ready, the maintainers\nof stable releases backport them to the remaining supported stable releases.\n\n### Backports\n\nAll other security and reliability fixes can be nominated for backporting to stable releases\nby Envoy maintainers, Envoy security team, the change author, or members of the Envoy community\nby adding the `backport/review` or `backport/approved` label (this can be done using [repokitteh]'s\n`/backport` command). Changes nominated by the change author and/or members of the Envoy community\nare evaluated for backporting on a case-by-case basis, and require approval from either the release\nmanager of stable release, Envoy maintainers, or Envoy security team. Once approved, those fixes\nare backported from the `main` branch to all supported stable branches by the maintainers of\nstable releases. New stable versions from non-critical security fixes are released on a regular\nschedule, initially aiming for the bi-weekly releases.\n\n### Release management\n\nMajor releases are handled by the maintainer on-call and do not involve any backports.\nThe details are outlined in the \"Cutting a major release\" section below.\nSecurity releases are handled by a Release Manager and a Fix Lead. The Release Manager is\nresponsible for approving and merging backports, with responsibilties outlined\nin [BACKPORTS.md](BACKPORTS.md).\nThe Fix Lead is a member of the security\nteam and is responsible for coordinating the overall release. This includes identifying\nissues to be fixed in the release, communications with the Envoy community, and the\nactual mechanics of the release itself.\n\n| Quarter |       Release Manager                                          |         Fix Lead                                                         |\n|:-------:|:--------------------------------------------------------------:|:-------------------------------------------------------------------------|\n| 2020 Q1 | Piotr Sikora ([PiotrSikora](https://github.com/PiotrSikora))   |                                                                          |\n| 2020 Q2 | Piotr Sikora ([PiotrSikora](https://github.com/PiotrSikora))   |                                                                          |\n| 2020 Q3 | Yuchen Dai ([lambdai](https://github.com/lambdai))             |                                                                          |\n| 2020 Q4 | Christoph Pakulski ([cpakulski](https://github.com/cpakulski)) |                                                                          |\n| 2021 Q1 | Rei Shimizu ([Shikugawa](https://github.com/Shikugawa))        |                                                                          |\n| 2021 Q2 | Dmitri Dolguikh ([dmitri-d](https://github.com/dmitri-d))      |                                                                          |\n| 2021 Q3 | Takeshi Yoneda ([mathetake](https://github.com/mathetake))     |                                                                          |\n| 2021 Q4 | Otto van der Schaaf ([oschaaf](https://github.com/oschaaf))    |                                                                          |\n| 2022 Q1 | Otto van der Schaaf ([oschaaf](https://github.com/oschaaf))    | Ryan Hamilton ([RyanTheOptimist](https://github.com/RyanTheOptimist))    |\n| 2022 Q2 | Pradeep Rao ([pradeepcrao](https://github.com/pradeepcrao))    | Matt Klein ([mattklein123](https://github.com/mattklein123))             |\n| 2022 Q4 | Can Cecen ([cancecen](https://github.com/cancecen))            | Tony Allen ([tonya11en](https://github.com/tonya11en))                   |\n| 2023 Q3 | Boteng Yao ([botengyao](https://github.com/botengyao))         | Kateryna Nezdolii ([nezdolik](https://github.com/nezdolik))              |\n| 2023 Q4 | Paul Merrison ([pmerrison](https://github.com/pmerrison))      | Brian Sonnenberg ([briansonnenberg](https://github.com/briansonnenberg)) |\n| 2024 Q2 | Ryan Northey ([phlax](https://github.com/phlax))               | Boteng Yao ([botengyao](https://github.com/botengyao))                   |\n| 2024 Q3 | Ryan Northey ([phlax](https://github.com/phlax))               | Boteng Yao ([botengyao](https://github.com/botengyao))                   |\n\n## Major release schedule\n\nIn order to accommodate downstream projects, new Envoy releases are produced on a fixed release\nschedule (the 15th day of each quarter), with an acceptable delay of up to 2 weeks, with a hard\ndeadline of 3 weeks.\n\n| Version |  Expected  |   Actual   | Difference | End of Life |\n|:-------:|:----------:|:----------:|:----------:|:-----------:|\n| 1.12.0  | 2019/09/30 | 2019/10/31 |  +31 days  | 2020/10/31  |\n| 1.13.0  | 2019/12/31 | 2020/01/20 |  +20 days  | 2021/01/20  |\n| 1.14.0  | 2020/03/31 | 2020/04/08 |   +8 days  | 2021/04/08  |\n| 1.15.0  | 2020/06/30 | 2020/07/07 |   +7 days  | 2021/07/07  |\n| 1.16.0  | 2020/09/30 | 2020/10/08 |   +8 days  | 2021/10/08  |\n| 1.17.0  | 2020/12/31 | 2021/01/11 |  +11 days  | 2022/01/11  |\n| 1.18.0  | 2021/03/31 | 2021/04/15 |  +15 days  | 2022/04/15  |\n| 1.19.0  | 2021/06/30 | 2021/07/13 |  +13 days  | 2022/07/13  |\n| 1.20.0  | 2021/09/30 | 2021/10/05 |   +5 days  | 2022/10/05  |\n| 1.21.0  | 2022/01/15 | 2022/01/12 |   -3 days  | 2023/01/12  |\n| 1.22.0  | 2022/04/15 | 2022/04/15 |    0 days  | 2023/04/15  |\n| 1.23.0  | 2022/07/15 | 2022/07/15 |    0 days  | 2023/07/15  |\n| 1.24.0  | 2022/10/15 | 2022/10/19 |   +4 days  | 2023/10/19  |\n| 1.25.0  | 2023/01/15 | 2023/01/18 |   +3 days  | 2024/01/18  |\n| 1.26.0  | 2023/04/15 | 2023/04/18 |   +3 days  | 2024/04/18  |\n| 1.27.0  | 2023/07/14 | 2023/07/27 |  +13 days  | 2024/07/27  |\n| 1.28.0  | 2023/10/16 | 2023/10/19 |   +3 days  | 2024/10/19  |\n| 1.29.0  | 2024/01/16 | 2024/01/16 |    0 days  | 2025/01/16  |\n| 1.30.0  | 2024/04/16 | 2024/04/16 |    0 days  | 2025/04/16  |\n| 1.31.0  | 2024/07/16 | 2024/07/19 |   +3 days  | 2025/07/19  |\n| 1.32.0  | 2024/10/15 | 2024/10/15 |    0 days  | 2025/10/15  |\n| 1.33.0  | 2025/01/14 |            |            |             |\n\n### Cutting a major release\n\n* Take a look at open issues tagged with the current release, by\n  [searching](https://github.com/envoyproxy/envoy/issues) for\n  \"is:open is:issue milestone:[current milestone]\" and either hold off until\n  they are fixed or bump them to the next milestone.\n* Begin marshalling the ongoing PR flow in this repo. Ask maintainers to hold off merging any\n  particularly risky PRs until after the release is tagged. This is because we aim for main to be\n  at release candidate quality at all times.\n* Do a final check of the [release notes](changelogs/current.yaml):\n  * Make any needed corrections (grammar, punctuation, formatting, etc.).\n  * Check to see if any security/stable version release notes are duplicated in\n    the major version release notes. These should not be duplicated.\n  * Switch the repo to \"release\" mode by running `bazel run @envoy_repo//:release`. This tool\n    will create a commit with the necessary changes for a release.\n  * Update the [RELEASES](RELEASES.md) doc with the relevant dates. Now, or after you cut the\n    release, please also make sure there's a stable maintainer signed up for next quarter,\n    and the deadline for the next release is documented in the release schedule.\n  * Get a review and merge.\n* Create a pull request with that commit and **wait for tests to pass**.\n* Once the tests have passed, and the PR has landed, CI will automatically create the tagged release and corresponding release branch.\n* Switch the repo back to \"dev\" mode by running `bazel run @envoy_repo//:dev`. This tool will create a commit with the\n  necessary changes to continue development.\n* Create a pull request with that commit.\n* Run the deprecate_guards.py script (`bazel run //tools/deprecate_guards:deprecate_guards`)\n* If you haven't done this before, request posting permission from admins for all the groups in the next bullet.\n* Craft a witty/uplifting email and send it to all the email aliases:\nenvoy-announce@googlegroups.com\nenvoy-users@googlegroups.com\nenvoy-dev@googlegroups.com\nenvoy-maintainers@googlegroups.com -\ninclude in this email a link to the latest [release page](https://github.com/envoyproxy/envoy/releases) (ending in `tag/[version]`)\n* Announce in [#envoy-dev](https://envoyproxy.slack.com/archives/C78HA81DH) and [#envoy-users](https://envoyproxy.slack.com/archives/C78M4KW76) slack channels.\n\n## Security release schedule\n\nSecurity releases are published on a 3-monthly cycle, around the mid point between major releases.\n\n| Quarter |  Expected  |   Actual   | Difference |\n|:-------:|:----------:|:----------:|:----------:|\n| 2024 Q2 | 2024/06/04 | 2024/06/04 |   0 days   |\n| 2024 Q3 | 2024/09/03 | 2024/09/19 |  16 days   |\n| 2024 Q4 | 2024/12/03 | 2024/12/18 |  15 days   |\n| 2025 Q1 | 2025/03/04 |\n\nNOTE: Zero-day vulnerabilities, and upstream vulnerabilities disclosed to us under embargo, may necessitate an emergency release with little or no warning.\n"
        },
        {
          "name": "REPO_LAYOUT.md",
          "type": "blob",
          "size": 8.71,
          "content": "# Repository layout overview\n\nThis is a high level overview of how the repository is laid out to both aid in code investigation,\nas well as to clearly specify how extensions are added to the repository. The top level directories\nare:\n\n* [.azure-pipelines/](.azure-pipelines/): Configuration for\n[Azure Pipelines](https://azure.microsoft.com/en-us/services/devops/pipelines/).\n* [api/](api/): Envoy data plane API.\n* [bazel/](bazel/): Configuration for Envoy's use of [Bazel](https://bazel.build/).\n* [ci/](ci/): Scripts used both during CI as well as to build Docker containers.\n* [configs/](configs/): Example Envoy configurations.\n* [docs/](docs/): End user facing Envoy proxy and data plane API documentation as well as scripts\n  for publishing final docs during releases.\n* [examples/](examples/): Larger Envoy examples using Docker and Docker Compose.\n* [envoy/](envoy/): \"Public\" interface headers for \"core\" Envoy. In general,\n  these are almost entirely 100% abstract classes. There are a few cases of not-abstract classes in\n  the \"public\" headers, typically for performance reasons. Note that \"core\" includes some\n  \"extensions\" such as the HTTP connection manager filter and associated functionality which are\n  so fundamental to Envoy that they will likely never be optional from a compilation perspective.\n* [restarter/](restarter/): Envoy's hot restart wrapper Python script.\n* [security/](security/): Some templates for reporting security issues of Envoy. Historical security issues can also be found here.\n* [source/](source/): Source code for core Envoy as well as extensions. The layout of this directory\n  is discussed in further detail below.\n* [support/](support/): Development support scripts (pre-commit Git hooks, etc.)\n* [test/](test/): Test code for core Envoy as well as extensions. The layout of this directory is\n  discussed in further detail below.\n* [tools/](tools/): Miscellaneous tools that have not found a home somewhere else.\n\n## [source/](source/)\n\n* [common/](source/common/): Core Envoy code (not specific to extensions) that is also not\n  specific to a standalone server implementation. I.e., this is the code that could be used if Envoy\n  were eventually embedded as a library.\n* [docs/](source/docs/): Miscellaneous developer/design documentation that is not relevant for\n  the public user documentation.\n* [exe/](source/exe/): Code specific to building the final production Envoy server binary. This is\n  the only code that is not shared by integration and unit tests.\n* [extensions/](source/extensions/): Extensions to the core Envoy code. The layout of this\n  directory is discussed in further detail below.\n* [server/](source/server/): Code specific to running Envoy as a standalone server. E.g,\n  configuration, server startup, workers, etc. Over time, the line between `common/` and `server/`\n  has become somewhat blurred. Use best judgment as to where to place something.\n\n## [test/](test/)\n\nNot every directory within test is described below, but a few highlights:\n\n* Unit tests are found in directories matching their [source/](source/) equivalents. E.g.,\n  [common/](test/common/), [exe/](test/exe/), and [server/](test/server/).\n* Extension unit tests also match their source equivalents in [extensions/](test/extensions/).\n* [integration/](test/integration/) holds end-to-end integration tests using roughly the real\n  Envoy server code, fake downstream clients, and fake upstream servers. Integration tests also\n  test some of the extensions found in the repository. Note that in the future, we would like to\n  allow integration tests that are specific to extensions and are not required for covering\n  \"core\" Envoy functionality. Those integration tests will likely end up in the\n  [extensions/](test/extensions/) directory but further work and thinking is required before\n  we get to that point.\n* [mocks/](test/mocks/) contains mock implementations of all of the core Envoy interfaces found in\n  [include/](include/).\n* Other directories include tooling used for configuration testing, coverage testing, fuzz testing,\n  common test code, etc.\n\n## [source/extensions](source/extensions/) layout\n\nWe maintain a very specific code and namespace layout for extensions. This aids in discovering\ncode/extensions, and allows us specify extension owners in [CODEOWNERS](CODEOWNERS).\n\n* All extensions are either registered in [all_extensions.bzl](source/extensions/all_extensions.bzl)\n  or [extensions_build_config.bzl](source/extensions/extensions_build_config.bzl). The former is\n  for extensions that cannot be removed from the primary Envoy build. The latter is for extensions\n  that can be removed on a site specific basis. See [bazel/README.md](bazel/README.md) for how to\n  compile out extensions on a site specific basis. Note that by default extensions should be\n  removable from the build unless there is a very good reason.\n* These are the top level extension directories and associated namespaces:\n  * [access_loggers/](/source/extensions/access_loggers): Access log implementations which use\n    the `Envoy::Extensions::AccessLoggers` namespace.\n  * [bootstrap/](/source/extensions/bootstrap): Bootstrap extensions which use\n    the `Envoy::Extensions::Bootstrap` namespace.\n  * [clusters/](/source/extensions/clusters): Cluster extensions which use the\n    `Envoy::Extensions::Clusters` namespace.\n  * [compression/](/source/extensions/compression): Compression extensions\n    which use `Envoy::Extensions::Compression` namespace.\n  * [fatal_actions/](/source/extensions/fatal_actions): Fatal Action extensions\n    which use the `Envoy::Extensions::FatalActions` namespace.\n  * [filters/http/](/source/extensions/filters/http): HTTP L7 filters which use the\n    `Envoy::Extensions::HttpFilters` namespace.\n  * [filters/listener/](/source/extensions/filters/listener): Listener filters which use the\n    `Envoy::Extensions::ListenerFilters` namespace.\n  * [filters/network/](/source/extensions/filters/network): L4 network filters which use the\n    `Envoy::Extensions::NetworkFilters` namespace.\n  * [formatters/](/source/extensions/formatters): Access log formatters which use the\n    `Envoy::Extensions::Formatters` namespace.\n  * [grpc_credentials/](/source/extensions/grpc_credentials): Custom gRPC credentials which use the\n    `Envoy::Extensions::GrpcCredentials` namespace.\n  * [health_checker/](/source/extensions/health_checker): Custom health checkers which use the\n    `Envoy::Extensions::HealthCheckers` namespace.\n  * [internal_redirect/](/source/extensions/internal_redirect): Internal Redirect\n    extensions which use the `Envoy::Extensions::InternalRedirect` namespace.\n  * [quic_listeners/](/source/extensions/quic_listeners): QUIC extensions which\n    use the `Envoy::Quic` namespace.\n  * [resource_monitors/](/source/extensions/resource_monitors): Resource monitor\n    extensions which use the `Envoy::Extensions::ResourceMonitors` namespace.\n  * [retry/](/source/extensions/retry): Retry extensions which use the\n    `Envoy::Extensions::Retry` namespace.\n  * [stat_sinks/](/source/extensions/stat_sinks): Stat sink implementations which use the\n    `Envoy::Extensions::StatSinks` namespace.\n  * [tracers/](/source/extensions/tracers): Tracers which use the\n    `Envoy::Extensions::Tracers` namespace.\n  * [transport_sockets/](/source/extensions/transport_sockets): Transport socket implementations\n    which use the `Envoy::Extensions::TransportSockets` namespace.\n  * [upstreams/](/source/extensions/upstreams): Upstream extensions use the\n    `Envoy::Extensions::Upstreams` namespace.\n  * [watchdog/](/source/extensions/watchdog): Watchdog extensions use the\n    `Envoy::Extensions::Watchdog` namespace.\n  * [rate_limit_descriptors/](/source/extensions/rate_limit_descriptors): Rate limit\n    descriptor extensions use the `Envoy::Extensions::RateLimitDescriptors`\n    namespace.\n* Each extension is contained wholly in its own namespace. E.g.,\n  `Envoy::Extensions::NetworkFilters::Echo`.\n* Common code that is used by multiple extensions should be in a `common/` directory as close to\n  the extensions as possible. E.g., [filters/common/](/source/extensions/filters/common) for common\n  code that is used by both HTTP and network filters. Common code used only by two HTTP filters\n  would be found in `filters/http/common/`. Common code should be placed in a common namespace.\n  E.g., `Envoy::Extensions::Filters::Common`.\n\n## [contrib](contrib/) layout\n\nThis directory contains contrib extensions. See [EXTENSION_POLICY.md](EXTENSION_POLICY.md) for\nmore information.\n\n* [contrib/exe/](contrib/exe/): The default executable for contrib. This is similar to the\n  `envoy-static` target but also includes all contrib extensions, and is used to produce the\n  contrib image targets.\n* [contrib/...](contrib/): The rest of this directory mirrors the [source/extensions](source/extensions/)\n  layout. Contrib extensions are placed here.\n"
        },
        {
          "name": "SECURITY-INSIGHTS.yml",
          "type": "blob",
          "size": 1.91,
          "content": "header:\n  schema-version: '1.0.0'\n  expiration-date: '2025-01-24T01:00:00.000Z'\n  last-updated: '2024-01-24'\n  last-reviewed: '2024-01-24'\n  project-url: https://github.com/envoyproxy/envoy\n  changelog: https://www.envoyproxy.io/docs/envoy/latest/version_history/version_history#version-history\n  license: https://github.com/envoyproxy/envoy/blob/main/LICENSE\nproject-lifecycle:\n  status: active\n  bug-fixes-only: false\n  core-maintainers:  # from https://github.com/envoyproxy/envoy/blob/main/OWNERS.md\n  # Senior maintainers\n  - github:mattklein123\n  - github:alyssawilk\n  - github:zuercher\n  - github:lizan\n  - github:ggreenway\n  - github:yanavlasov\n  - github:phlax\n  - github:RyanTheOptimist\n  - github:wbpcode\n  # Maintainers\n  - github:jmarantz\n  - github:adisuissa\n  - github:KBaichoo\n  - github:keith\n  - github:kyessenov\n  - github:ravenblackx\n  - github:soulxu\n  - github:nezdolik\n  - github:tyxia\ncontribution-policy:\n  accepts-pull-requests: true\n  accepts-automated-pull-requests: true\n  code-of-conduct: https://github.com/envoyproxy/envoy/blob/main/CODE_OF_CONDUCT.md\ndependencies:\n  third-party-packages: true\n  dependencies-lists:\n  - https://www.envoyproxy.io/docs/envoy/latest/intro/arch_overview/security/external_deps\n  env-dependencies-policy:\n    policy-url: https://github.com/envoyproxy/envoy/blob/main/DEPENDENCY_POLICY.md\ndistribution-points:\n- https://github.com/envoyproxy/envoy\ndocumentation:\n- https://www.envoyproxy.io/docs\nsecurity-contacts:\n- type: email\n  value: envoy-security@googlegroups.com\nsecurity-testing:\n- tool-type: sca\n  tool-name: Dependabot\n  tool-version: latest\n  integration:\n    ad-hoc: false\n    ci: true\n    before-release: true\n- tool-type: sast\n  tool-name: CodeQL\n  tool-version: '2.13.4'\n  integration:\n    ad-hoc: false\n    ci: true\n    before-release: true\nvulnerability-reporting:\n  accepts-vulnerability-reports: true\n  security-policy: https://github.com/envoyproxy/envoy/security/policy\n"
        },
        {
          "name": "SECURITY.md",
          "type": "blob",
          "size": 26.41,
          "content": "# Security Reporting Process\n\nPlease report any security issue or Envoy crash report to\nenvoy-security@googlegroups.com where the issue will be triaged appropriately.\nThank you in advance for helping to keep Envoy secure.\n\n# Security Release Process\n\nEnvoy is a large growing community of volunteers, users, and vendors. The Envoy community has\nadopted this security disclosure and response policy to ensure we responsibly handle critical\nissues.\n\n## Product Security Team (PST)\n\nSecurity vulnerabilities should be handled quickly and sometimes privately. The primary goal of this\nprocess is to reduce the total time users are vulnerable to publicly known exploits.\n\nThe Product Security Team (PST) is responsible for organizing the entire response including internal\ncommunication and external disclosure but will need help from relevant developers to successfully\nrun this process.\n\nThe initial Product Security Team will consist of all [maintainers](OWNERS.md) in the private\n[envoy-security](https://groups.google.com/forum/#!forum/envoy-security) list. In the future we may\ndecide to have a subset of maintainers work on security response given that this process is time\nconsuming.\n\n## Disclosures\n\n### Private Disclosure Processes\n\nThe Envoy community asks that all suspected vulnerabilities be privately and responsibly disclosed\nvia the [reporting policy](README.md#reporting-security-vulnerabilities).\n\n### Public Disclosure Processes\n\nIf you know of a publicly disclosed security vulnerability please IMMEDIATELY email\n[envoy-security](https://groups.google.com/forum/#!forum/envoy-security) to inform the Product\nSecurity Team (PST) about the vulnerability so they may start the patch, release, and communication\nprocess.\n\nIf possible the PST will ask the person making the public report if the issue can be handled via a\nprivate disclosure process (for example if the full exploit details have not yet been published). If\nthe reporter denies the request for private disclosure, the PST will move swiftly with the fix and\nrelease process. In extreme cases GitHub can be asked to delete the issue but this generally isn't\nnecessary and is unlikely to make a public disclosure less damaging.\n\n## Patch, Release, and Public Communication\n\nFor each vulnerability a member of the PST will volunteer to lead coordination with the \"Fix Team\"\nand is responsible for sending disclosure emails to the rest of the community. This lead will be\nreferred to as the \"Fix Lead.\" The detailed list of responsibilities is outlined on the\n[Fix Lead Checklist](https://docs.google.com/document/d/1cuU0m9hTQ73Te3i06-8LjQkFVn83IL22FbCoc_4IFEY/edit#heading=h.c6thx0zc0gtz)\n\nThe role of Fix Lead should rotate round-robin across the PST.\n\nNote that given the current size of the Envoy community it is likely that the PST is the same as\nthe \"Fix team.\" (I.e., all maintainers). The PST may decide to bring in additional contributors\nfor added expertise depending on the area of the code that contains the vulnerability.\n\nAll of the timelines below are suggestions and assume a private disclosure. The Fix Lead drives the\nschedule using their best judgment based on severity and development time. If the Fix Lead is\ndealing with a public disclosure all timelines become ASAP (assuming the vulnerability has a CVSS\nscore >= 4; see below). If the fix relies on another upstream project's disclosure timeline, that\nwill adjust the process as well. We will work with the upstream project to fit their timeline and\nbest protect our users.\n\n### Released versions and main branch\n\nIf the vulnerability affects the last point release version, e.g. 1.10, then the full security\nrelease process described in this document will be activated. A security point release will be\ncreated for each currently supported Envoy version, as described in [stable releases](RELEASES.md#stable-releases),\ntogether with a fix to main if necessary. Older point releases,\ne.g. 1.5, are not supported by the Envoy project and will not have any security release created.\n\nIf a security vulnerability affects only these older versions but not main or the last supported\npoint release, the Envoy security team will share this information with the private distributor\nlist, following the standard embargo process, but not create a security release. After the embargo\nexpires, the vulnerability will be described as a GitHub issue. A CVE will be filed if warranted by\nseverity.\n\nIf a vulnerability does not affect any point release but only main, additional caveats apply:\n\n* If the issue is detected and a fix is available within 7 days of the introduction of the\n  vulnerability, or the issue is deemed a low severity vulnerability by the Envoy maintainer and\n  security teams, the fix will be publicly reviewed and landed on main. If the severity is at least\n  medium or at maintainer discretion a courtesy e-mail will be sent to envoy-users@googlegroups.com,\n  envoy-dev@googlegroups.com, envoy-security-announce@googlegroups.com and\n  cncf-envoy-distributors-announce@lists.cncf.io.\n* If the vulnerability has been in existence for more than 7 days and is medium or higher, we will\n  activate the security release process.\n\nWe advise distributors and operators working from the main branch to allow at least 5 days soak\ntime after cutting a binary release before distribution or rollout, to allow time for our fuzzers to\ndetect issues during their execution on ClusterFuzz. A soak period of 7 days provides an even stronger\nguarantee, since we will invoke the security release process for medium or higher severity issues\nfor these older bugs.\n\n**NOTE:** Contrib extensions are not eligible for Envoy security team coverage.\n\n### Threat model\n\nSee https://www.envoyproxy.io/docs/envoy/latest/intro/arch_overview/security/threat_model.\nVulnerabilities are evaluated against this threat model when deciding whether to activate the Envoy\nsecurity release process.\n\n### Fix Team Organization\n\nThese steps should be completed within the first 24 hours of disclosure.\n\n- The Fix Lead will work quickly to identify relevant engineers from the affected projects and\n  packages and CC those engineers into the disclosure thread. These selected developers are the Fix\n  Team.\n- The Fix Lead will get the Fix Team access to private security repos to develop the fix.\n\n### Fix Development Process\n\nThese steps should be completed within the 1-7 days of Disclosure.\n\n- The Fix Lead and the Fix Team will create a\n  [CVSS](https://www.first.org/cvss/specification-document) using the [CVSS\n  Calculator](https://www.first.org/cvss/calculator/3.0). The Fix Lead makes the final call on the\n  calculated CVSS; it is better to move quickly than making the CVSS perfect.\n- The Fix Team will notify the Fix Lead that work on the fix branch is complete once there are LGTMs\n  on all commits in the private repo from one or more maintainers.\n\nIf the CVSS score is under 4.0 ([a low severity\nscore](https://www.first.org/cvss/specification-document#i5)) the Fix Team can decide to slow the\nrelease process down in the face of holidays, developer bandwidth, etc. These decisions must be\ndiscussed on the envoy-security mailing list.\n\nA three week window will be provided to members of the private distributor list from candidate patch\navailability until the security release date. It is expected that distributors will normally be able\nto perform a release within this time window. If there are exceptional circumstances, the Envoy\nsecurity team will raise this window to four weeks. The release window will be reduced if the\nsecurity issue is public or embargo is broken.\n\nWe will endeavor not to overlap this three week window with or place it adjacent to major corporate\nholiday periods or end-of-quarter (e.g. impacting downstream Istio releases), where possible.\n\n### Fix and disclosure SLOs\n\n* All reports to envoy-security@googlegroups.com will be triaged and have an\n  initial response within 1 business day.\n\n* Privately disclosed issues will be fixed or publicly disclosed within 90 days\n  by the Envoy security team. In exceptional circumstances we reserve the right\n  to work with the discloser to coordinate on an extension, but this will be\n  rarely used.\n\n* Any issue discovered by the Envoy security team and raised in our private bug\n  tracker will be converted to a public issue within 90 days. We will regularly\n  audit these issues to ensure that no major vulnerability (from the perspective\n  of the threat model) is accidentally leaked.\n\n* Fuzz bugs are subject to a 90 day disclosure deadline.\n\n* Three weeks notice will be provided to private distributors from patch\n  availability until the embargo deadline.\n\n* Public zero days which affect the optimized binary will be fixed ASAP, but there is\n  no SLO for this, since this will depend on the severity and impact to the\n  organizations backing the Envoy security team. After a zero day bug fix is in, the\n  PST will kick off point releases unless the bug is deemed unlikely to be encountered\n  in production (e.g. only triggered by trace logs) at which point there will instead be an email\n  to envoy-announce and users can request point releases if they believe they will be affected.\n  Publicly announced bugs which only affect debug binaries will neither trigger point\n  releases nor announce emails.\n\n### Fix Disclosure Process\n\nWith the fix development underway, the Fix Lead needs to come up with an overall communication plan\nfor the wider community. This Disclosure process should begin after the Fix Team has developed a Fix\nor mitigation so that a realistic timeline can be communicated to users.\n\n**Disclosure of Forthcoming Fix to Users** (Completed within 1-7 days of Disclosure)\n\n- The Fix Lead will email [envoy-security-announce@googlegroups.com](https://groups.google.com/forum/#!forum/envoy-security-announce)\n  (CC [envoy-announce@googlegroups.com](https://groups.google.com/forum/#!forum/envoy-announce))\n  informing users that a security vulnerability has been disclosed and that a fix will be made\n  available at YYYY-MM-DD HH:MM UTC in the future via this list. This time is the Release Date.\n- The Fix Lead will include any mitigating steps users can take until a fix is available.\n\nThe communication to users should be actionable. They should know when to block time to apply\npatches, understand exact mitigation steps, etc.\n\n**Optional Fix Disclosure to Private Distributors List** (Completed within 1-14 days of Disclosure):\n\n- The Fix Lead will make a determination with the help of the Fix Team if an issue is critical enough\n  to require early disclosure to distributors. Generally this Private Distributor Disclosure process\n  should be reserved for remotely exploitable or privilege escalation issues. Otherwise, this\n  process can be skipped.\n- The Fix Lead will email the patches to cncf-envoy-distributors-announce@lists.cncf.io so\n  distributors can prepare builds to be available to users on the day of the issue's announcement. Any\n  patches against main will be updated and resent weekly.\n  Distributors should read about the [Private Distributors List](#private-distributors-list) to find\n  out the requirements for being added to this list.\n- **What if a vendor breaks embargo?** The PST will assess the damage. The Fix Lead will make the\n  call to release earlier or continue with the plan. When in doubt push forward and go public ASAP.\n\n**Fix Release Day** (Completed within 1-21 days of Disclosure)\n\n- The maintainers will create a new patch release branch from the latest patch release tag + the fix\n  from the security branch. As a practical example if v1.5.3 is the latest patch release in Envoy.git\n  a new branch will be created called v1.5.4 which includes only patches required to fix the issue.\n- The Fix Lead will cherry-pick the patches onto the main branch and all relevant release branches.\n  The Fix Team will LGTM and merge. Maintainers will merge these PRs as quickly as possible. Changes\n  shouldn't be made to the commits even for a typo in the CHANGELOG as this will change the git sha\n  of the commits leading to confusion and potentially conflicts as the fix is cherry-picked around\n  branches.\n- The Fix Lead will request a CVE from [DWF](https://github.com/distributedweaknessfiling/DWF-Documentation)\n  and include the CVSS and release details.\n- The Fix Lead will email envoy-{dev,users,announce}@googlegroups.com now that everything is public\n  announcing the new releases, the CVE number, and the relevant merged PRs to get wide distribution\n  and user action. As much as possible this email should be actionable and include links on how to apply\n  the fix to user's environments; this can include links to external distributor documentation.\n- The Fix Lead will remove the Fix Team from the private security repo.\n\nThe reporter of a vulnerability will be granted early access to fix patches upon\nrequest, prior to the general disclosure of patches to the Private Distributors\nList for the purpose of testing and internal vulnerability mitigation. They must\naccept the embargo policy below in order for this to occur. If the vulnerability\nreporter is also responsible for developing fix patches, they may make use of\nthe patches internally in their organization at any point in the fix cycle.\n\n### Retrospective\n\nThese steps should be completed 1-3 days after the Release Date. The retrospective process\n[should be blameless](https://landing.google.com/sre/book/chapters/postmortem-culture.html).\n\n- The Fix Lead will send a retrospective of the process to envoy-dev@googlegroups.com including\n  details on everyone involved, the timeline of the process, links to relevant PRs that introduced\n  the issue, if relevant, and any critiques of the response and release process.\n- Maintainers and Fix Team are also encouraged to send their own feedback on the process to\n  envoy-dev@googlegroups.com. Honest critique is the only way we are going to get good at this as a\n  community.\n\n## Private Distributors List\n\nThis list is intended to be used primarily to provide actionable information to\nmultiple distribution vendors as well as a *limited* set of high impact end users at once. *This\nlist is not intended in the general case for end users to find out about security issues*.\n\n### Embargo Policy\n\nThe information members receive on cncf-envoy-distributors-announce must not be made public, shared, nor\neven hinted at anywhere beyond the need-to-know within your specific team except with the list's\nexplicit approval. This holds true until the public disclosure date/time that was agreed upon by the\nlist. Members of the list and others may not use the information for anything other than getting the\nissue fixed for your respective users.\n\nBefore any information from the list is shared with respective members of your team required to fix\nsaid issue, they must agree to the same terms and only find out information on a need-to-know basis.\n\nWe typically expect a single point-of-contact (PoC) at any given legal entity. Within the\norganization, it is the responsibility of the PoC to share CVE and related patches internally. This\nshould be performed on a strictly need-to-know basis with affected groups to the extent that this is\ntechnically plausible. All teams should be aware of the embargo conditions and accept them.\nUltimately, if an organization breaks embargo transitively through such sharing, they will lose\nthe early disclosure privilege, so it's in their best interest to carefully share information internally,\nfollowing best practices and use their judgement in balancing the tradeoff between protecting users\nand maintaining confidentiality.\n\nThe embargo applies to information shared, source code and binary images. **It is a violation of the\nembargo policy to share binary distributions of the security fixes before the public release date.**\nThis includes, but is not limited to, Envoy binaries and Docker images. It is expected that\ndistributors have a method to stage and validate new binaries without exposing them publicly.\n\nIf the information shared is under embargo from a third party, where Envoy is one of many projects\nthat a disclosure is shared with, it is critical to consider that the ramifications of any leak will\nextend beyond the Envoy community and will leave us in a position in which we will be less likely to\nreceive embargoed reports in the future.\n\nIn the unfortunate event you share the information beyond what is allowed by this policy, you _must_\nurgently inform the envoy-security@googlegroups.com mailing list of exactly what information leaked\nand to whom. A retrospective will take place after the leak so we can assess how to prevent making the\nsame mistake in the future.\n\nIf you continue to leak information and break the policy outlined here, you will be removed from the\nlist.\n\n### Contributing Back\n\nThis is a team effort. As a member of the list you must carry some water. This\ncould be in the form of the following:\n\n**Technical**\n\n- Review and/or test the proposed patches and point out potential issues with\n  them (such as incomplete fixes for the originally reported issues, additional\n  issues you might notice, and newly introduced bugs), and inform the list of the\n  work done even if no issues were encountered.\n\n**Administrative**\n\n- Help draft emails to the public disclosure mailing list.\n- Help with release notes.\n\n### Membership Criteria\n\nTo be eligible for the cncf-envoy-distributors-announce mailing list, your\nuse of Envoy should:\n\n1. Be either:\n   1. An actively maintained distribution of Envoy components. An example is\n      \"SuperAwesomeLinuxDistro\" which offers Envoy pre-built packages. Another\n      example is \"SuperAwesomeServiceMesh\" which offers a service mesh product\n      that includes Envoy as a component.\n\n   OR\n\n   2. Offer Envoy as a publicly available infrastructure or platform service, in\n      which the product clearly states (e.g. public documentation, blog posts,\n      marketing copy, etc.) that it is built on top of Envoy. E.g.,\n      \"SuperAwesomeCloudProvider's Envoy as a Service (EaaS)\". An infrastructure\n      service that uses Envoy for a product but does not publicly say they are\n      using Envoy does not *generally* qualify (see option 3 that follows). This is essentially IaaS\n      or PaaS. If you use Envoy to support a SaaS, e.g. \"SuperAwesomeCatVideoService\", this does not\n      *generally* qualify.\n\n   OR\n\n   3. An end user of Envoy that satisfies the following requirements:\n       1. Is \"well known\" to the Envoy community. Being \"well known\" is fully subjective and\n          determined by the Envoy maintainers and security team. Becoming \"well known\" would\n          generally be achieved by activities such as: PR contributions, either code or\n          documentation; helping other end users on Slack, GitHub, and the mailing lists; speaking\n          about use of Envoy at conferences; writing about use of Envoy in blog posts; sponsoring\n          Envoy conferences, meetups, and other activities; etc. This is a more strict variant of\n          item 5 below.\n       2. Is of sufficient size, scale, and impact to make your inclusion on the list\n          worthwhile. The definition of size, scale, and impact is fully subjective and\n          determined by the Envoy maintainers and security team. The definition will not be\n          discussed further in this document.\n       3. You *must* smoke test and then widely deploy security patches promptly and report back\n          success or failure ASAP. Furthermore, the Envoy maintainers may occasionally ask you to\n          smoke test especially risky public PRs before they are merged. Not performing these tasks\n          in a reasonably prompt timeframe will result in removal from the list. This is a more\n          strict variant of item 7 below.\n       4. In order to balance inclusion in the list versus a greater chance of accidental\n          disclosure, end users added to the list via this option will be limited to a total of\n          **10** slots. Periodic review (see below) may allow new slots to open, so please continue\n          to apply if it seems your organization would otherwise qualify. The security team also\n          reserves the right to change this limit in the future.\n       5. Note that in this context \"end user\" is defined as an organization that *directly*\n          operates Envoy in order to serve traffic for 1st party use cases. The 1st party use case\n          can be either internal or external facing. Critically, vendors of cloud native software\n          and solutions can *also* be end users. Being a vendor does not preclude an organization\n          from being an end user as long as it satisfies the 1st party usage criteria.\n2. Have a user or customer base not limited to your own organization (except for option 3 above).\n   We will use the size of the user or customer base as part of the criteria to determine\n   eligibility.\n3. Have a publicly verifiable track record up to present day of fixing security\n   issues.\n4. Not be a downstream or rebuild of another distribution.\n5. Be a participant and active contributor in the community.\n6. Accept the [Embargo Policy](#embargo-policy) that is outlined above. You must\n   have a way to privately stage and validate your updates that does not violate\n   the embargo.\n7. Be willing to [contribute back](#contributing-back) as outlined above.\n8. Be able to perform a security release of your product within a three week window from candidate fix\n   patch availability.\n9. Have someone already on the list vouch for the person requesting membership\n   on behalf of your distribution.\n10. Nominate an e-mail alias or list for your organization to receive updates. This should not be\n    an individual user address, but instead a list that can be maintained by your organization as\n    individuals come and go. A good example is envoy-security@seven.com, a bad example is\n    acidburn@seven.com. You must accept the invite sent to this address or you will not receive any\n    e-mail updates. This e-mail address will be [shared with the Envoy community](#Members).\n\nNote that Envoy maintainers are members of the Envoy security team. [Members of the Envoy security\nteam](OWNERS.md#envoy-security-team) and the organizations that they represent are implicitly\nincluded in the private distributor list. These organizations do not need to meet the above list of\ncriteria with the exception of the acceptance of the embargo policy.\n\n### Requesting to Join\n\nNew membership requests are sent to envoy-security@googlegroups.com.\n\nIn the body of your request please specify how you qualify and fulfill each\ncriterion listed in [Membership Criteria](#membership-criteria).\n\nHere is a pseudo example:\n\n```\nTo: envoy-security@googlegroups.com\nSubject: Seven-Corp Membership to cncf-envoy-distributors-announce\n\nBelow are each criterion and why I think we, Seven-Corp, qualify.\n\n> 1. Be an actively maintained distribution of Envoy components OR offer Envoy as a publicly\n     available service in which the product clearly states that it is built on top of Envoy OR\n     be a well known end user of sufficient size, scale, and impact to make your\n     inclusion worthwhile.\n\nWe distribute the \"Seven\" distribution of Envoy [link]. We have been doing\nthis since 1999 before proxies were even cool.\n\nOR\n\nWe use Envoy for our #1 rated cat video service and have 40 billion MAU, proxying 40 trillion^2 RPS\nthrough Envoy at the edge. Secure cat videos are our top priority. We also contribute a lot to the Envoy\ncommunity by implementing features, not making Matt ask for documentation or tests, and writing blog\nposts about efficient Envoy cat video serving.\n\n> 2. Have a user or customer base not limited to your own organization. Please specify an\n>    approximate size of your user or customer base, including the number of\n>    production deployments.\n\nOur user base spans of the extensive \"Seven\" community. We have a slack and\nGitHub repos and mailing lists where the community hangs out. We have ~2000\ncustomers, of which approximately 400 are using Seven in production. [links]\n\n> 3. Have a publicly verifiable track record up to present day of fixing security\n     issues.\n\nWe announce on our blog all upstream patches we apply to \"Seven.\" [link to blog\nposts]\n\n> 4. Not be a downstream or rebuild of another distribution. If you offer Envoy as a publicly\n>    available infrastructure or platform service, this condition does not need to apply.\n\nThis does not apply, \"Seven\" is a unique snowflake distribution.\n\n> 5. Be a participant and active contributor in the community.\n\nOur members, Acidburn, Cereal, and ZeroCool are outstanding members and are well\nknown throughout the Envoy community. Especially for their contributions\nin hacking the Gibson.\n\n> 6. Accept the Embargo Policy that is outlined above. You must\n     have a way to privately stage and validate your updates that does not violate\n     the embargo.\n\nWe accept.\n\n> 7. Be willing to contribute back as outlined above.\n\nWe are definitely willing to help!\n\n> 8. Be able to perform a security release of your product within a three week window from candidate fix\n     patch availability.\n\nWe affirm we can spin out new security releases within a 2 week window.\n\n> 9. Have someone already on the list vouch for the person requesting membership\n>    on behalf of your distribution.\n\nCrashOverride will vouch for the \"Seven\" distribution joining the distribution list.\n\n> 10. Nominate an e-mail alias or list for your organization to receive updates. This should not be\n      an individual user address, but instead a list that can be maintained by your organization as\n      individuals come and go. A good example is envoy-security@seven.com, a bad example is\n      acidburn@seven.com. You must accept the invite sent to this address or you will not receive any\n      e-mail updates. This e-mail address will be shared with the Envoy community.\n\nenvoy-security@seven.com\n```\n\n### Review of membership criteria\n\nIn all cases, members of the distribution list will be reviewed on a yearly basis by the maintainers\nand security team to ensure they still qualify for inclusion on the list.\n\n### Members\n\n| Organization  | End User | Last Review |\n|:-------------:|:--------:|:-----------:|\n| AWS           | No       | 07/24       |\n| Cilium        | No       | 07/24       |\n| Cloud Foundry | No       | 07/24       |\n| F5            | No       | 07/24       |\n| Google        | No       | 07/24       |\n| Istio         | No       | 07/24       |\n| Microsoft     | No       | 07/24       |\n| Red Hat       | No       | 07/24       |\n| VMware        | No       | 07/24       |\n| Tetrate       | No       | 07/24       |\n| solo.io       | No       | 07/24       |\n| Pinterest     | Yes      | 07/24       |\n| Dropbox       | Yes      | 07/24       |\n| Apple         | Yes      | 07/24       |\n| Spotify       | Yes      | 02/21       |\n| Netflix       | Yes      | 07/24       |\n| Slack         | Yes      | 07/24       |\n"
        },
        {
          "name": "STYLE.md",
          "type": "blob",
          "size": 16.97,
          "content": "# C++ coding style\n\n* The Envoy source code is formatted using clang-format. Thus all white spaces, etc.\n  issues are taken care of automatically. The Azure Pipelines will automatically check\n  the code format and fail. There are make targets that can both check the format\n  (check_format) as well as fix the code format for you (fix_format). Errors in\n  .clang-tidy are enforced while other warnings are suggestions. Note that code and\n  comment blocks designated `clang-format off` must be closed with `clang-format on`.\n  To run these checks locally, see [Support Tools](support/README.md).\n* Beyond code formatting, for the most part Envoy uses the\n  [Google C++ style guidelines](https://google.github.io/styleguide/cppguide.html).\n  The following section covers the major areas where we deviate from the Google\n  guidelines.\n\n# Repository file layout\n\n* Please see [REPO_LAYOUT.md](REPO_LAYOUT.md).\n\n# Documentation\n\n* If you are modifying the data plane structurally, please keep the [Life of a\n  Request](https://www.envoyproxy.io/docs/envoy/latest/intro/life_of_a_request) documentation up-to-date.\n\n# Deviations from Google C++ style guidelines\n\n* Exceptions are allowed on the control plane, though now discouraged in new code. Adding exceptions is disallowed on the data plane.\n* References are always preferred over pointers when the reference cannot be null. This\n  includes both const and non-const references.\n* Function names should all use camel case starting with a lower case letter (e.g., `doFoo()`).\n* Struct/Class member variables have a `_` postfix (e.g., `int foo_;`).\n* Enum values using PascalCase (e.g., `RoundRobin`).\n* 100 columns is the line limit.\n* Use your GitHub name in TODO comments, e.g. `TODO(foobar): blah`.\n* Smart pointers are type aliased:\n  * `using FooPtr = std::unique_ptr<Foo>;`\n  * `using BarSharedPtr = std::shared_ptr<Bar>;`\n  * `using BlahConstSharedPtr = std::shared_ptr<const Blah>;`\n  * Regular pointers (e.g. `int* foo`) should not be type aliased.\n* `absl::optional<std::reference_wrapper<T>>` has a helper class in `envoy/common/optref.h`, and is type aliased:\n  * `using FooOptRef = OptRef<T>;`\n  * `using FooOptConstRef = OptRef<const T>;`\n* If move semantics are intended, prefer specifying function arguments with `&&`.\n  E.g., `void onHeaders(Http::HeaderMapPtr&& headers, ...)`. The rationale for this is that it\n  forces the caller to specify `std::move(...)` or pass a temporary and makes the intention at\n  the callsite clear. Otherwise, it's difficult to tell if a const reference is actually being\n  passed to the called function. This is true even for `std::unique_ptr`.\n* Prefer `unique_ptr` over `shared_ptr` wherever possible. `unique_ptr` makes ownership in\n  production code easier to reason about. Note that this creates some test oddities where\n  production code requires a `unique_ptr` but the test must still have access to the memory\n  the production code is using (mock or otherwise). In these cases it is acceptable to allocate\n  raw memory in a test and return it to the production code with the expectation that the\n  production code will hold it in a `unique_ptr` and free it. Envoy uses the factory pattern\n  quite a bit for these cases. (Search the code for \"factory\").\n* Prefer explicitly sized integer types, such as uint64_t rather than size_t. In particular, use\n  explicitly sized integers for data that is written to disk or involved in math that might overflow.\n* The Google C++ style guide points out that [non-PoD static and global variables are forbidden](https://google.github.io/styleguide/cppguide.html#Static_and_Global_Variables).\n  This _includes_ types such as `std::string`. We encourage the use of the\n  advice in the [C++ FAQ on the static initialization\n  fiasco](https://isocpp.org/wiki/faq/ctors#static-init-order-on-first-use) for\n  how to best handle this.\n* The Google C++ style guide points out that [constant vars should be named `kConstantVar`](https://google.github.io/styleguide/cppguide.html#Constant_Names).\n  In the Envoy codebase we use `ConstantVar` or `CONSTANT_VAR`. If you pick `CONSTANT_VAR`,\n  please be certain the name is globally significant to avoid potential conflicts with #defines,\n  which are not namespace-scoped, and may appear in externally controlled header files.\n* API-level comments should follow normal Doxygen conventions. Use `@param` to describe\n  parameters and `@return <return-type>` for return values. Internal comments for\n  methods and member variables may be regular C++ `//` comments or Doxygen at\n  developer discretion. Where possible, methods should have meaningful\n  documentation on expected input and state preconditions.\n* Header guards should use `#pragma once`.\n* All code should be inside a top-level Envoy namespace. There are some\n  exceptions such as `main()` functions. When code cannot be placed inside the\n  Envoy namespace there should be a comment of the form `// NOLINT(namespace-envoy)` at\n  the top of the file.\n* If a method that must be defined outside the `test` directory is intended to be called only\n  from test code then it should have a name that ends in `ForTest()` such as `aMethodForTest()`.\n  In most cases tests can and should be structured so this is not necessary.\n* Tests default to StrictMock so will fail if hitting unexpected warnings. Feel free to use\n  NiceMock for mocks whose behavior is not the focus of a test.\n* [Thread\n  annotations](https://github.com/abseil/abseil-cpp/blob/master/absl/base/thread_annotations.h),\n  such as `ABSL_GUARDED_BY`, should be used for shared state guarded by\n  locks/mutexes.\n* Functions intended to be local to a cc file should be declared in an anonymous namespace,\n  rather than using the 'static' keyword. Note that the\n  [Google C++ style guide](https://google.github.io/styleguide/cppguide.html#Unnamed_Namespaces_and_Static_Variables)\n   allows either, but in Envoy we prefer anonymous namespaces.\n* Braces are required for all control statements include single line if, while, etc. statements.\n* Don't use [mangled Protobuf enum\n  names](https://developers.google.com/protocol-buffers/docs/reference/cpp-generated#enum).\n\n# Error handling\n\nA few general notes on our error handling philosophy:\n\n* All error code returns should be checked.\n* At a very high level, our philosophy is that errors should be handled gracefully when caused by:\n  - Untrusted network traffic (from downstream, upstream, or extensions like filters)\n  - Raised by the Envoy process environment and are *likely* to happen\n  - Third party dependency return codes\n* Examples of likely environnmental errors include any type of network error, disk IO error, bad\n  data returned by an API call, bad data read from runtime files, etc. This includes loading\n  configuration at runtime.\n* Third party dependency return codes should be checked and gracefully handled. Examples include\n  HTTP/2 or JSON parsers. Some return codes may be handled by continuing, for example, in case of an\n  out of process RPC failure.\n* Testing should cover any serious cases that may result in infinite loops, crashes, or serious\n  errors. Non-trivial invariants are also encouraged to have testing. Internal, localized invariants\n  may not need testing.\n* Errors in the Envoy environment that are *unlikely* to happen after process initialization, should\n  lead to process death, under the assumption that the additional burden of defensive coding and\n  testing is not an effective use of time for an error that should not happen given proper system\n  setup. Examples of these types of errors include not being able to open the shared memory region,\n  system calls that should not fail assuming correct parameters (which should be validated via\n  tests), etc. Examples of system calls that should not fail when passed valid parameters include\n  the kernel returning a valid `sockaddr` after a successful call to `accept()`, `pthread_create()`,\n  `pthread_join()`, etc. However, system calls that require permissions may cause likely errors in\n  some deployments and need graceful error handling.\n* OOM events (both memory and FDs) or ENOMEM errors are considered fatal crashing errors. An OOM\n  error should never silently be ignored and should crash the process either via the C++ allocation\n  error exception, an explicit `RELEASE_ASSERT` following a third party library call, or an obvious\n  crash on a subsequent line via null pointer dereference. This rule is again based on the\n  philosophy that the engineering costs of properly handling these cases are not worth it. Time is\n  better spent designing proper system controls that shed load if resource usage becomes too high,\n  etc.\n* The \"less is more\" error handling philosophy described in the previous points is primarily\n  based on the fact that restarts are designed to be fast, reliable and cheap.\n* Although we strongly recommend that any type of startup error leads to a fatal error, since this\n  is almost always a result of faulty configuration which should be caught during a canary process,\n  there may be cases in which we want some classes of startup errors to be non-fatal. For example,\n  if a misconfigured option is not necessary for server operation. Although this is discouraged, we\n  will discuss these on a case by case basis during code review (an example of this\n  is the `--admin-address-path` option). **If degraded mode error handling is implemented, we require\n  that there is complete test coverage for the degraded case.** Additionally, the user should be\n  aware of the degraded state minimally via an error log of level warn or greater and via the\n  increment of a stat.\n* If you do need to log a non-fatal warning or error, you can unit-test it with EXPECT_LOG_CONTAINS\n  or EXPECT_NO_LOGS from [logging.h](test/test_common/logging.h). It's generally bad practice to\n  test by depending on log messages unless the actual behavior being validated is logging.\n  It's preferable to export statistics to enable consumption by external monitoring for any\n  behavior that should be externally consumed or to introduce appropriate internal interfaces\n  such as mocks for internal behavior.\n* The error handling philosophy described herein is based on the assumption that Envoy is deployed\n  using industry best practices (primarily canary). Major and obvious errors should always be\n  caught in canary. If a low rate error leads to periodic crash cycling when deployed to\n  production, the error rate should allow for rollback without large customer impact.\n* Tip: If the thought of adding the extra test coverage, logging, and stats to handle an error and\n  continue seems ridiculous because *\"this should never happen\"*, it's a very good indication that\n  the appropriate behavior is to terminate the process and not handle the error. When in doubt,\n  please discuss.\n\n# Macro Usage\n\n* The following macros are available:\n  - `RELEASE_ASSERT`: fatal check.\n  - `ASSERT`: fatal check in debug-only builds. These should be used to document (and check in\n    debug-only builds) program invariants.\n  - `ENVOY_BUG`: logs and increments a stat in release mode, fatal check in debug builds. These\n    should be used where it may be useful to detect if an efficient condition is violated in\n    production (and fatal check in debug-only builds). This will also log a stack trace\n    of the previous calls leading up to `ENVOY_BUG`.\n\n* Sub-macros alias the macros above and can be used to annotate specific situations:\n  - `ENVOY_BUG_ALPHA` (alias `ENVOY_BUG`): Used for alpha or rapidly changing protocols that need\n  detectability on probable conditions or invariants.\n\n* Per above it's acceptable to turn failures into crash semantics via `RELEASE_ASSERT(condition)` or\n  `PANIC(message)` if there is no other sensible behavior, e.g. in OOM (memory/FD) scenarios.\n* Do not `ASSERT` on conditions imposed by the external environment. Either add error handling\n  (potentially with an `ENVOY_BUG` for detectability) or `RELEASE_ASSERT` if the condition indicates\n  that the process is unrecoverable.\n* Use `ASSERT` and `ENVOY_BUG` liberally, but do not use them for things that will crash in an obvious\n  way in a subsequent line. E.g., do not do `ASSERT(foo != nullptr); foo->doSomething();`.\n* Use `ASSERT`s for true invariants and well-defined conditions that are useful for tests,\n  debug-only checks and documentation. They may be `ENVOY_BUG`s if performance allows, see point\n  below.\n* `ENVOY_BUG`s provide detectability and more confidence than an `ASSERT`. They are useful for\n  non-trivial conditions, those with complex control flow, and rapidly changing protocols. Testing\n  should be added to ensure that Envoy can continue to operate even if an `ENVOY_BUG` condition is\n  violated.\n* Annotate conditions with comments on belief or reasoning, for example `Condition is guaranteed by\n  caller foo` or `Condition is likely to hold after processing through external library foo`.\n* Macro usage should be understandable to a reader. Add comments if not. They should be robust to\n  future changes.\n* Note that there is a gray line between external environment failures and program invariant\n  violations. For example, memory corruption due to a security issue (a bug, deliberate buffer\n  overflow etc.) might manifest as a violation of program invariants or as a detectable condition in\n  the external environment (e.g. some library returning a highly unexpected error code or buffer\n  contents). Unfortunately no rule can cleanly cover when to use `RELEASE_ASSERT` vs. `ASSERT`. In\n  general we view `ASSERT` as the common case and `RELEASE_ASSERT` as the uncommon case, but\n  experience and judgment may dictate a particular approach depending on the situation. The risk of\n  process death from `RELEASE_ASSERT` should be justified with the severity and possibility of the\n  condition to avoid unintentional crashes. You may use the following guide:\n    * If a violation is high risk (will cause a crash in subsequent data processing or indicates a\n      failure state beyond recovery), use `RELEASE_ASSERT`.\n    * If a violation is medium or low risk (Envoy can continue safely) and is not expensive,\n      consider `ENVOY_BUG`.\n    * Otherwise (if a condition is expensive or test-only), use `ASSERT`.\n\nBelow is a guideline for macro usage. The left side of the table has invariants and the right side\nhas error conditions that can be triggered and should be gracefully handled. `ENVOY_BUG` represents\na middle ground that can be used for uncertain conditions that need detectability. `ENVOY_BUG`s can\nalso be added for errors if they warrant detection.\n\n| `ASSERT`/`RELEASE_ASSERT` | `ENVOY_BUG` | Error handling and Testing |\n| --- | --- | --- |\n| Low level invariants in data structures | | |\n| Simple, provable internal class invariants | Complex, uncertain internal class invariants (e.g. need detectability if violated) | |\n| Provable (pre/post)-conditions | Complicated but likely (pre-/post-) conditions that are low-risk (Envoy can continue safely) | Triggerable or uncertain conditions, may be based on untrusted data plane traffic or an extensions’ contract. |\n|                                                                                     | Conditions in alpha or changing extensions that need detectability. (`ENVOY_BUG_ALPHA`) | |\n| Unlikely environment errors after process initialization that would otherwise crash | | Likely environment errors, e.g. return codes from untrusted extensions, dependencies or system calls, network error, bad data read, permission based errors, etc. |\n| Fatal crashing events. e.g. OOMs, deadlocks, no process recovery possible | | |\n\n# Hermetic and deterministic tests\n\nTests should be hermetic, i.e. have all dependencies explicitly captured and not depend on the local\nenvironment. In general, there should be no non-local network access. In addition:\n\n* Port numbers should not be hardcoded. Tests should bind to port zero and then discover the bound\n  port when needed. This avoids flakes due to conflicting ports and allows tests to be executed\n  concurrently by Bazel. See\n  [`test/integration/integration_test.h`](test/integration/integration_test.h) and\n  [`test/common/network/listener_impl_test.cc`](test/common/network/listener_impl_test.cc)\n  for examples of tests that do this.\n\n* Paths should be constructed using:\n  * The methods in [`TestEnvironment`](test/test_common/environment.h) for C++ tests.\n  * With `${TEST_TMPDIR}` (for writable temporary space) or `${TEST_SRCDIR}` for read-only access to\n    test inputs in shell tests.\n  * With `{{ test_tmpdir }}`, `{{ test_rundir }}` and `{{ test_udsdir }}` respectively for JSON templates.\n    `{{ test_udsdir }}` is provided for pathname based Unix Domain Sockets, which must fit within a\n    108 character limit on Linux, a property that might not hold for `{{ test_tmpdir }}`.\n\nTests should be deterministic. They should not rely on randomness or details\nsuch as the current time. Instead, mocks such as\n[`MockRandomGenerator`](test/mocks/common.h) and\n[`SimulatedTimeSystem`](test/test_common/simulated_time_system.h) should be used.\n\n# Google style guides for other languages\n\n* [Python](https://google.github.io/styleguide/pyguide.html)\n* [Bash](https://google.github.io/styleguide/shell.xml)\n* [Bazel](https://bazel.build/versions/master/docs/skylark/build-style.html)\n"
        },
        {
          "name": "VERSION.txt",
          "type": "blob",
          "size": 0.01,
          "content": "1.33.0-dev\n"
        },
        {
          "name": "WORKSPACE",
          "type": "blob",
          "size": 0.71,
          "content": "workspace(name = \"envoy\")\n\nload(\"//bazel:api_binding.bzl\", \"envoy_api_binding\")\n\nenvoy_api_binding()\n\nload(\"//bazel:api_repositories.bzl\", \"envoy_api_dependencies\")\n\nenvoy_api_dependencies()\n\nload(\"//bazel:repo.bzl\", \"envoy_repo\")\n\nenvoy_repo()\n\nload(\"//bazel:repositories.bzl\", \"envoy_dependencies\")\n\nenvoy_dependencies()\n\nload(\"//bazel:repositories_extra.bzl\", \"envoy_dependencies_extra\")\n\nenvoy_dependencies_extra()\n\nload(\"//bazel:python_dependencies.bzl\", \"envoy_python_dependencies\")\n\nenvoy_python_dependencies()\n\nload(\"//bazel:dependency_imports.bzl\", \"envoy_dependency_imports\")\n\nenvoy_dependency_imports()\n\nload(\"//bazel:dependency_imports_extra.bzl\", \"envoy_dependency_imports_extra\")\n\nenvoy_dependency_imports_extra()\n"
        },
        {
          "name": "api",
          "type": "tree",
          "content": null
        },
        {
          "name": "bazel",
          "type": "tree",
          "content": null
        },
        {
          "name": "changelogs",
          "type": "tree",
          "content": null
        },
        {
          "name": "ci",
          "type": "tree",
          "content": null
        },
        {
          "name": "configs",
          "type": "tree",
          "content": null
        },
        {
          "name": "contrib",
          "type": "tree",
          "content": null
        },
        {
          "name": "distribution",
          "type": "tree",
          "content": null
        },
        {
          "name": "docs",
          "type": "tree",
          "content": null
        },
        {
          "name": "envoy",
          "type": "tree",
          "content": null
        },
        {
          "name": "go.mod",
          "type": "blob",
          "size": 0.14,
          "content": "module github.com/envoyproxy/envoy\n\ngo 1.22\n\nrequire google.golang.org/protobuf v1.36.1\n\nrequire github.com/google/go-cmp v0.5.9 // indirect\n"
        },
        {
          "name": "go.sum",
          "type": "blob",
          "size": 0.33,
          "content": "github.com/google/go-cmp v0.5.9 h1:O2Tfq5qg4qc4AmwVlvv0oLiVAGB7enBSJ2x2DqQFi38=\ngithub.com/google/go-cmp v0.5.9/go.mod h1:17dUlkBOakJ0+DkrSSNjCkIjxS6bF9zb3elmeNGIjoY=\ngoogle.golang.org/protobuf v1.36.1 h1:yBPeRvTftaleIgM3PZ/WBIZ7XM/eEYAaEyCwvyjq/gk=\ngoogle.golang.org/protobuf v1.36.1/go.mod h1:9fA7Ob0pmnwhb644+1+CVWFRbNajQ6iRojtC/QF5bRE=\n"
        },
        {
          "name": "maintainer",
          "type": "tree",
          "content": null
        },
        {
          "name": "mobile",
          "type": "tree",
          "content": null
        },
        {
          "name": "pytest.ini",
          "type": "blob",
          "size": 0.21,
          "content": "[pytest]\naddopts = -raq --ignore=tools/testing/external/*,__init__.py,testing/conf --color=yes --cov-append -p  tools.testing.plugin --cov-config=.coveragerc -Werror -vv tools\ntestpaths =\n\t  tests\nasyncio_mode = auto\n"
        },
        {
          "name": "releases.asc",
          "type": "blob",
          "size": 3.08,
          "content": "-----BEGIN PGP PUBLIC KEY BLOCK-----\n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\nxn73SlvaQy7ttkC8vuPiVI6g\n=YtjB\n-----END PGP PUBLIC KEY BLOCK-----\n"
        },
        {
          "name": "repokitteh.star",
          "type": "blob",
          "size": 2.36,
          "content": "pin(\"github.com/repokitteh/modules\", \"4ee2ed0c3622aad7fcddc04cb5dc866e44a541e6\")\n\nuse(\"github.com/repokitteh/modules/assign.star\")\nuse(\"github.com/repokitteh/modules/review.star\")\nuse(\"github.com/repokitteh/modules/wait.star\")\nuse(\"github.com/envoyproxy/envoy/ci/repokitteh/modules/azure_pipelines.star\", secret_token=get_secret('azp_token'))\nuse(\"github.com/envoyproxy/envoy/ci/repokitteh/modules/coverage.star\")\nuse(\"github.com/envoyproxy/envoy/ci/repokitteh/modules/docs.star\")\nuse(\"github.com/envoyproxy/envoy/ci/repokitteh/modules/newpr.star\")\nuse(\n  \"github.com/envoyproxy/envoy/ci/repokitteh/modules/ownerscheck.star\",\n  paths=[\n    {\n      \"owner\": \"envoyproxy/api-shepherds!\",\n      \"path\":\n      \"(api/envoy[\\w/]*/(v1alpha\\d?|v1|v2alpha\\d?|v2))|(api/envoy/type/(matcher/)?\\w+.proto)\",\n      \"label\": \"v2-freeze\",\n      \"allow_global_approval\": False,\n      \"github_status_label\": \"v2 freeze violations\",\n    },\n    {\n       \"owner\": \"envoyproxy/coverage-shephards\",\n       \"path\": \"(test/per_file_coverage.sh)\",\n       \"github_status_label\": \"changes to Envoy coverage scripts\",\n       \"auto_assign\": True,\n    },\n    {\n       \"owner\": \"envoyproxy/runtime-guard-changes\",\n       \"path\": \"(source/common/runtime/runtime_features.cc)\",\n       \"github_status_label\": \"changes to Envoy runtime guards\",\n    },\n    {\n      \"owner\": \"envoyproxy/api-shepherds!\",\n      \"path\": \"(api/envoy/|docs/root/api-docs/)\",\n      \"label\": \"api\",\n      \"github_status_label\": \"any API change\",\n      \"auto_assign\": True,\n    },\n    {\n      \"owner\": \"envoyproxy/api-watchers\",\n      \"path\": \"(api/envoy/|docs/root/api-docs/)\",\n    },\n    {\n      \"owner\": \"envoyproxy/dependency-shepherds!\",\n      \"path\":\n      \"(bazel/.*repos.*\\.bzl)|(bazel/dependency_imports\\.bzl)|(api/bazel/.*\\.bzl)|(.*/requirements\\.txt)|(.*\\.patch)\",\n      \"label\": \"deps\",\n      \"github_status_label\": \"any dependency change\",\n      \"auto_assign\": True,\n    },\n  ],\n)\nuse(\"github.com/envoyproxy/envoy/ci/repokitteh/modules/versionchange.star\")\nuse(\"github.com/envoyproxy/envoy/ci/repokitteh/modules/workflows.star\")\n\ndef _backport():\n  github.issue_label('backport/review')\n\nhandlers.command(name='backport', func=_backport)\n\ndef _milestone():\n  github.issue_label('milestone/review')\n\nhandlers.command(name='milestone', func=_milestone)\n\ndef _nostalebot():\n  github.issue_label('no stalebot')\n\nhandlers.command(name='nostalebot', func=_nostalebot)\n"
        },
        {
          "name": "restarter",
          "type": "tree",
          "content": null
        },
        {
          "name": "reviewers.yaml",
          "type": "blob",
          "size": 1.33,
          "content": "adisuissa:\n  maintainer: true\n  opsgenie: Adi\n  slack: UT17EMMTP\nalyssawilk:\n  maintainer: true\n  opsgenie: Alyssa\n  slack: U78RP48V9\nbotengyao:\n  maintainer: true\n  opsgenie: Boteng\n  slack: U037YUAK147\ndaixiang0:\n  first-pass: true\n  slack: U020CJG6UU8\nggreenway:\n  maintainer: true\n  opsgenie: Greg\n  slack: U78MBV869\njmarantz:\n  maintainer: true\n  opsgenie: Joshua\n  slack: U80HPLBPG\nKBaichoo:\n  maintainer: true\n  opsgenie: Kevin\n  slack: U016ZPU8KBK\nkeith:\n  maintainer: true\n  opsgenie: Keith\n  slack: UGS5P90CF\nkyessenov:\n  opsgenie: kuat\n  slack: U7KTRAA8M\n  maintainer: true\nmarkdroth:\n  api: true\n  slack: UMN8K55A6\nmattklein123:\n  maintainer: true\n  opsgenie: Matt\n  slack: U5CALEVSL\nnezdolik:\n  maintainer: true\n  opsgenie: Kateryna\n  slack: UDYUWRL13\nphlax:\n  maintainer: true\n  opsgenie: phlax\n  slack: U017PLM0GNQ\nravenblackx:\n  maintainer: true\n  opsgenie: Raven\n  slack: U02MJHFEX35\nRyanTheOptimist:\n  maintainer: true\n  opsgenie: Ryan\n  slack: U01SW3JC8GP\nsilverstar194:\n  first-pass: true\n  slack: U03LNPC8JN9\nsoulxu:\n  maintainer: true\n  opsgenie: Hejie\n  slack: U01GNQ3B8AY\ntyxia:\n  maintainer: true\n  opsgenie: Tianyu\n  slack: U023U1ZN9SP\nwbpcode:\n  maintainer: true\n  opsgenie: Baiping\n  slack: U017KF5C0Q6\nyanavlasov:\n  maintainer: true\n  opsgenie: Yan\n  slack: UJHLR5KFS\nzuercher:\n  maintainer: true\n  opsgenie: Stephan\n  slack: U78J72Q82\n"
        },
        {
          "name": "rustfmt.toml",
          "type": "blob",
          "size": 2.29,
          "content": "# This config is copied from https://github.com/bitdriftlabs/shared-core/blob/4114708cafb80103092b7e585987ef275a136f87/rustfmt.toml\n\n# Rust Autoformatter Config\n# =========================\n#\n# Note that most of rustfmt's configurable settings are nightly-only,\n# so we tend to run that. Typically we don't rely on unstable features,\n# but in this case there's honestly not a lot to configure that _isn't_\n# behind the `unstable_features` gate, unfortunately.\n\nedition           = \"2021\"\nunstable_features = true\n\n# Try to use inline annotations before using this -- disabling autoformatting\n# for a file makes it harder for everyone to share their work in that file and\n# invites bikeshedding about how code in there should look.\nignore = []\n\n# Features are broken up into Stable and Unstable features, listed in order of\n# appearance in the Configuring Rustfmt document:\n# https://github.com/rust-lang-nursery/rustfmt/blob/master/Configurations.md\n\n## Stable Features\n\nforce_explicit_abi       = true      # Default\nhard_tabs                = false     # Default\nmax_width                = 100\nmerge_derives            = true      # Default\nnewline_style            = \"Auto\"    # Default\nremove_nested_parens     = true      # Default\nreorder_imports          = true      # Default\nreorder_modules          = true      # Default\ntab_spaces               = 2\nuse_field_init_shorthand = false     # Default\nuse_small_heuristics     = \"Default\" # Default\nuse_try_shorthand        = true\n\n## Features that were \"unstable\" when we configured them\nblank_lines_lower_bound      = 0\nblank_lines_upper_bound      = 3\ncombine_control_expr         = false\ncomment_width                = 100\ncondense_wildcard_suffixes   = true\nenum_discrim_align_threshold = 20\nerror_on_line_overflow       = true\nerror_on_unformatted         = false\nformat_code_in_doc_comments  = true\nformat_macro_bodies          = true\nformat_macro_matchers        = true\nformat_strings               = true\ngroup_imports                = \"One\"\nimports_granularity          = \"Module\"\nimports_layout               = \"HorizontalVertical\"\nmatch_block_trailing_comma   = true\nnormalize_comments           = false\nnormalize_doc_attributes     = true\nskip_children                = false\nspaces_around_ranges         = true\nstruct_field_align_threshold = 0\nwrap_comments                = true\n"
        },
        {
          "name": "security",
          "type": "tree",
          "content": null
        },
        {
          "name": "source",
          "type": "tree",
          "content": null
        },
        {
          "name": "support",
          "type": "tree",
          "content": null
        },
        {
          "name": "test",
          "type": "tree",
          "content": null
        },
        {
          "name": "third_party",
          "type": "tree",
          "content": null
        },
        {
          "name": "tools",
          "type": "tree",
          "content": null
        }
      ]
    }
  ]
}